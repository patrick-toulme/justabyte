// Slow dumping with stack traces? Try building with --dynamic_mode=fully
$region0: #{fusion.21}
  #allocation3 [shape = 's32[1]{0}', space=sflag, size = 0x4, offset = 0, tag = 'scoped memory for fusion.21'] (stack0)
  #allocation154_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0, tag = 'spilled sreg/preg'] (stack1)
  #allocation155_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x4, tag = 'spilled sreg/preg'] (stack1)
  #allocation156_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x8, tag = 'spilled sreg/preg'] (stack1)
  // region range: [0, 12610)
  %s156435_s0 = inlined_call_operand.<no memory space> [shape: u32[], index: 0, kind: input, shape index: {}] /* operand 0 */ (stack2)
  %s156436_s1 = inlined_call_operand.<no memory space> [shape: u32[], index: 1, kind: input, shape index: {}] /* operand 1 */ (stack2)
  %s156437_s2 = inlined_call_operand.<no memory space> [shape: u32[], index: 2, kind: input, shape index: {}] /* operand 2 */ (stack2)
  %s156438_s3 = inlined_call_operand.vmem [shape: u32[2048], index: 3, kind: input, shape index: {}] /* operand 3 */ (stack2)
  %s156439_s4 = inlined_call_operand.vmem [shape: u32[8], index: 4, kind: input, shape index: {}] (stack2)
  %s156440_s5 = inlined_call_operand.vmem [shape: u32[2048], index: 5, kind: input, shape index: {}] /* operand 5 */ (stack2)
  %s156441_s6 = inlined_call_operand.vmem [shape: u32[8], index: 6, kind: input, shape index: {}] (stack2)
  %s156442_s7 = inlined_call_operand.hbm [shape: bf16[8,2048,128], index: 7, kind: output, shape index: {}] /* operand 7 */ (stack3)
  %156665 = sst [smem:[#allocation154_spill]] %s156439_s4 (stack4)
  %156666 = sst [smem:[#allocation155_spill]] %s156441_s6 (stack4)
  %156667 = sst [smem:[#allocation156_spill]] %s156442_s7 (stack4)
  %v121564_v0 = vstv %s156435_s0 (stack5)
  %v121569_v1 = vstv %s156436_s1 (stack5)
  %v121574_v2 = vstv %s156437_s2 (stack5)
  $region1: #{fusion.21} parent=0
    #allocation0 [shape = 'u8[1048576]{0}', space=vmem, size = 0x100000, offset = 0, tag = 'operand span for operand 7'] (stack6)
    #allocation1 [shape = 's32[2]{0}', space=sflag, size = 0x8, offset = 0x4, tag = 'scoped memory for fusion.21'] (stack7)
    #allocation2 [shape = 's32[2]{0}', space=sflag, size = 0x8, offset = 0xc, tag = 'scoped memory for fusion.21'] (stack8)
    #allocation5_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xc, tag = 'spilled sreg/preg'] (stack9)
    #allocation7_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x10, tag = 'spilled sreg/preg'] (stack9)
    // region range: [4, 12610)
    %11 = vsyncpa [#allocation2], 0 (stack10)
    %13 = vsyncpa [#allocation2 + $0x1], 0 (stack10)
    loop: start=0, step=1, limit=10
    $region45: #{fusion.21} parent=1 // loop_pre_header
      // region range: [5, 7)
      %s121576_s2 = smov 0 /* copy for cssa */ (stack11)
      %s121578_s28 = smov 0 /* copy for cssa */ (stack11)
      %s121580_s29 = smov 0 /* copy for cssa */ (stack11)
    $region50: #{fusion.21} parent=1 // loop_body
      #allocation4_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x14, tag = 'spilled sreg/preg'] (stack9)
      #allocation6_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x18, tag = 'spilled sreg/preg'] (stack9)
      // region range: [7, 12601)
      %s121505_s29 = sphi %s121580_s29, %s19_s29 /* phi copy :: iteration index, stage = 0 */ (stack12)
      %s121501_s28 = sphi %s121578_s28, %s157862_s28 /* copy for cssa :: phi copy :: iteration index, stage = 0 iter bound = 1 */ (stack12)
      %s121497_s2 = sphi %s121576_s2, %s157861_s2 /* phi copy :: iteration index, stage = 1 iter bound = 1 */ (stack12)
      %156668 = sst [smem:[#allocation4_spill]] %s121497_s2 (stack4)
      %156669 = sst [smem:[#allocation5_spill]] %s121501_s28 (stack4)
      %156670 = sst [smem:[#allocation6_spill]] %s121505_s29 (stack4)
      %s34_s30 = sadd.s32 1, %s121501_s28 (stack13)
      %p119738_p0 = scmp.ge.s32.totalorder %s121505_s29, 1 (stack14)
      %p36_p1 = scmp.ge.s32.totalorder %s34_s30, 8 (stack15)
      %p232_p2 = scmp.lt.s32.totalorder %s121505_s29, 9 (stack16)
      %s157864_s30 = smov (%p36_p1, %s34_s30), 0 (stack17)
      %156671 = sst [smem:[#allocation7_spill]] %s157864_s30 (stack4)
      %p233_p3 = pnand %p119738_p0, %p232_p2 (stack18)
      // Predicated region
      $region33: #{fusion.21} parent=50 // pred_check
        // region range: [7, 13)
      $region34: #{fusion.21} parent=50 // pred_check_branch
        // region range: [7, 19)
        %236 = sbr.rel (%p233_p3) target bundleno = 12590 (0x312e), region = 36 (stack19)
      $region35: #{fusion.21} parent=50 // pred_region
        #allocation8_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x1c, tag = 'spilled sreg/preg'] (stack9)
        #allocation9_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x20, tag = 'spilled sreg/preg'] (stack9)
        #allocation10_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x24, tag = 'spilled sreg/preg'] (stack9)
        #allocation11_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x28, tag = 'spilled sreg/preg'] (stack9)
        #allocation12_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x2c, tag = 'spilled sreg/preg'] (stack9)
        #allocation13_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x30, tag = 'spilled sreg/preg'] (stack9)
        #allocation14_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x34, tag = 'spilled sreg/preg'] (stack9)
        #allocation15_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x38, tag = 'spilled sreg/preg'] (stack9)
        #allocation16_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x3c, tag = 'spilled sreg/preg'] (stack9)
        #allocation17_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x40, tag = 'spilled sreg/preg'] (stack9)
        #allocation18_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x44, tag = 'spilled sreg/preg'] (stack9)
        #allocation19_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x48, tag = 'spilled sreg/preg'] (stack9)
        #allocation20_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x4c, tag = 'spilled sreg/preg'] (stack9)
        #allocation21_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x50, tag = 'spilled sreg/preg'] (stack9)
        #allocation22_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x54, tag = 'spilled sreg/preg'] (stack9)
        #allocation23_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x58, tag = 'spilled sreg/preg'] (stack9)
        #allocation24_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x5c, tag = 'spilled sreg/preg'] (stack9)
        #allocation25_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x60, tag = 'spilled sreg/preg'] (stack9)
        #allocation26_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x64, tag = 'spilled sreg/preg'] (stack9)
        #allocation27_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x68, tag = 'spilled sreg/preg'] (stack9)
        #allocation28_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x6c, tag = 'spilled sreg/preg'] (stack9)
        #allocation29_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x70, tag = 'spilled sreg/preg'] (stack9)
        #allocation30_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x74, tag = 'spilled sreg/preg'] (stack9)
        #allocation31_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x78, tag = 'spilled sreg/preg'] (stack9)
        #allocation32_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x7c, tag = 'spilled sreg/preg'] (stack9)
        #allocation33_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x80, tag = 'spilled sreg/preg'] (stack9)
        #allocation34_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x84, tag = 'spilled sreg/preg'] (stack9)
        #allocation35_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x88, tag = 'spilled sreg/preg'] (stack9)
        #allocation36_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x8c, tag = 'spilled sreg/preg'] (stack9)
        #allocation37_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x90, tag = 'spilled sreg/preg'] (stack9)
        #allocation38_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x94, tag = 'spilled sreg/preg'] (stack9)
        #allocation39_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x98, tag = 'spilled sreg/preg'] (stack9)
        #allocation40_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x9c, tag = 'spilled sreg/preg'] (stack9)
        #allocation41_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xa0, tag = 'spilled sreg/preg'] (stack9)
        #allocation42_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xa4, tag = 'spilled sreg/preg'] (stack9)
        #allocation43_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x100000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation44_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x101000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation45_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xa8, tag = 'spilled sreg/preg'] (stack9)
        #allocation46_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xac, tag = 'spilled sreg/preg'] (stack9)
        #allocation47_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x102000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation48_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x103000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation49_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xb0, tag = 'spilled sreg/preg'] (stack9)
        #allocation50_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xb4, tag = 'spilled sreg/preg'] (stack9)
        #allocation51_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x104000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation52_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xb8, tag = 'spilled sreg/preg'] (stack9)
        #allocation53_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x105000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation54_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x106000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation55_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xbc, tag = 'spilled sreg/preg'] (stack9)
        #allocation56_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xc0, tag = 'spilled sreg/preg'] (stack9)
        #allocation57_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x107000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation58_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x108000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation59_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xc4, tag = 'spilled sreg/preg'] (stack9)
        #allocation60_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xc8, tag = 'spilled sreg/preg'] (stack9)
        #allocation61_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x109000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation62_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xcc, tag = 'spilled sreg/preg'] (stack9)
        #allocation63_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xd0, tag = 'spilled sreg/preg'] (stack9)
        #allocation64_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x10a000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation65_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xd4, tag = 'spilled sreg/preg'] (stack9)
        #allocation66_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xd8, tag = 'spilled sreg/preg'] (stack9)
        #allocation67_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xdc, tag = 'spilled sreg/preg'] (stack9)
        #allocation68_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x10b000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation69_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xe0, tag = 'spilled sreg/preg'] (stack9)
        #allocation70_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xe4, tag = 'spilled sreg/preg'] (stack9)
        #allocation71_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xe8, tag = 'spilled sreg/preg'] (stack9)
        #allocation72_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x10c000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation73_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xec, tag = 'spilled sreg/preg'] (stack9)
        #allocation74_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xf0, tag = 'spilled sreg/preg'] (stack9)
        #allocation75_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xf4, tag = 'spilled sreg/preg'] (stack9)
        #allocation76_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x10d000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation77_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xf8, tag = 'spilled sreg/preg'] (stack9)
        #allocation78_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0xfc, tag = 'spilled sreg/preg'] (stack9)
        #allocation79_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x100, tag = 'spilled sreg/preg'] (stack9)
        #allocation80_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x10e000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation81_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x104, tag = 'spilled sreg/preg'] (stack9)
        #allocation82_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x108, tag = 'spilled sreg/preg'] (stack9)
        #allocation83_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x10c, tag = 'spilled sreg/preg'] (stack9)
        #allocation84_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x10f000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation85_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x110, tag = 'spilled sreg/preg'] (stack9)
        #allocation86_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x114, tag = 'spilled sreg/preg'] (stack9)
        #allocation87_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x118, tag = 'spilled sreg/preg'] (stack9)
        #allocation88_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x110000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation89_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x11c, tag = 'spilled sreg/preg'] (stack9)
        #allocation90_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x120, tag = 'spilled sreg/preg'] (stack9)
        #allocation91_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x111000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation92_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x124, tag = 'spilled sreg/preg'] (stack9)
        #allocation93_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x128, tag = 'spilled sreg/preg'] (stack9)
        #allocation94_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x12c, tag = 'spilled sreg/preg'] (stack9)
        #allocation95_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x112000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation96_spill [shape = 'u32[1]{0}', space=smem, size = 0x4, offset = 0x130, tag = 'spilled sreg/preg'] (stack9)
        #allocation97_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x113000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation98_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x114000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation99_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x115000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation100_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x116000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation101_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x117000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation102_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x118000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation103_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x119000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation104_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x11a000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation105_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x11b000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation106_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x11c000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation107_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x11d000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation108_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x11e000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation109_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x11f000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation110_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x120000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation111_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x121000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation112_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x122000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation113_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x123000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation114_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x124000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation115_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x125000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation116_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x126000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation117_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x127000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation118_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x128000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation119_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x129000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation120_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x12a000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation121_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x12b000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation122_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x12c000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation123_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x12d000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation124_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x12e000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation125_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x12f000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation126_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x130000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation127_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x131000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation128_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x132000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation129_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x133000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation130_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x134000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation131_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x135000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation132_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x136000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation133_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x137000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation134_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x138000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation135_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x139000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation136_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x13a000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation137_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x13b000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation138_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x13c000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation139_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x13d000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation140_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x13e000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation141_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x13f000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation142_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x140000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation143_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x141000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation144_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x142000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation145_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x143000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation146_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x144000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation147_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x145000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation148_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x146000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation149_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x147000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation150_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x148000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation151_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x149000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation152_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x14a000, tag = 'spilled vreg/vmreg'] (stack20)
        #allocation153_spill [shape = 'u32[8,128]{1,0}', space=vmem, size = 0x1000, offset = 0x14b000, tag = 'spilled vreg/vmreg'] (stack20)
        // region range: [19, 12590)
        %s156672_s4 = sld [smem:[#allocation154_spill]] (stack21)
        %v879_v3 = vld [vmem:[%s156672_s4] ss:$0 sm:$0xff] (stack22)
        %s121600_s10 = sshll.u32 %s121497_s2, 8 (stack23)
        %880 = vbcast.lane.b32.xlu1 %v879_v3, 1 (stack24)
        %379 = vbcast.lane.b32.xlu0 %v879_v3, 0 (stack24)
        %s353_s11 = sshrl.u32 %s121600_s10, 10 (stack25)
        %s356_s12 = sand.u32 1023, %s121600_s10 /* smod.u32 w/div 1024 */ (stack26)
        %p119745_p4 = scmp.gt.s32.totalorder %s353_s11, 1 (stack27)
        %s121604_s13 = sshrl.u32 %s356_s12, 7 (stack28)
        %s358_s14 = sand.u32 127, %s356_s12 /* smod.u32 w/div 128 */ (stack29)
        %s4278_s15 = sadd.s32 8, %s121600_s10 (stack30)
        %s157866_s11 = smov (%p119745_p4, %s353_s11), 1 (stack17)
        %1367 = vbcast.lane.b32.xlu1 %v879_v3, 2 (stack24)
        %1854 = vbcast.lane.b32.xlu0 %v879_v3, 3 (stack24)
        %s364_s16 = sand.u32 255, %s358_s14 (stack31)
        %s4279_s17 = sshrl.u32 %s4278_s15, 10 (stack25)
        %s156452_s18 = sshll.u32 %s157866_s11, 3 (stack32)
        %s121610_s19 = sor.u32 256, %s364_s16 (stack33)
        %s360_s22 = scalar_lea.vmem %s156438_s3, %s156452_s18 (stack34)
        %p119764_p5 = scmp.gt.s32.totalorder %s4279_s17, 1 (stack27)
        %s362_s23 = scalar_lea.vmem %s360_s22, %s121604_s13 (stack35)
        %s121618_s24 = sand.u32 1023, %s4278_s15 /* smod.u32 w/div 1024 */ (stack26)
        %2341 = vbcast.lane.b32.xlu1 %v879_v3, 4 (stack24)
        %v363_v4 = vld [vmem:[%s362_s23] ss:$0 sm:$0xff] (stack22)
        %s157868_s17 = smov (%p119764_p5, %s4279_s17), 1 (stack17)
        %367 = vbcast.lane.b32.xlu0 %v363_v4, %s121610_s19 (stack36)
        %s156450_s25 = sshrl.u32 %s121618_s24, 7 (stack28)
        %s4284_s0 = sand.u32 127, %s121618_s24 /* smod.u32 w/div 128 */ (stack29)
        %s156451_s26 = sshll.u32 %s157868_s17, 3 (stack32)
        %s121626_s1 = sand.u32 255, %s4284_s0 (stack31)
        %s4286_s9 = scalar_lea.vmem %s156438_s3, %s156451_s26 (stack34)
        %s156444_s12 = sor.u32 256, %s121626_s1 (stack33)
        %3315 = vbcast.lane.b32.xlu1 %v879_v3, 6 (stack24)
        %s4288_s14 = scalar_lea.vmem %s4286_s9, %s156450_s25 (stack35)
        %s11722_s15 = sadd.s32 24, %s121600_s10 (stack30)
        %2828 = vbcast.lane.b32.xlu0 %v879_v3, 5 (stack24)
        %v4289_v5 = vld [vmem:[%s4288_s14] ss:$0 sm:$0xff] (stack22)
        %s11723_s16 = sshrl.u32 %s11722_s15, 10 (stack25)
        %s121637_s20 = sand.u32 1023, %s11722_s15 /* smod.u32 w/div 1024 */ (stack26)
        %p119804_p6 = scmp.gt.s32.totalorder %s11723_s16, 1 (stack27)
        %s156448_s21 = sshrl.u32 %s121637_s20, 7 (stack28)
        %s11728_s22 = sand.u32 127, %s121637_s20 /* smod.u32 w/div 128 */ (stack29)
        %s8000_s23 = sadd.s32 16, %s121600_s10 (stack30)
        %4293 = vbcast.lane.b32.xlu1 %v4289_v5, %s156444_s12 (stack36)
        %s157870_s16 = smov (%p119804_p6, %s11723_s16), 1 (stack17)
        %3802 = vbcast.lane.b32.xlu0 %v879_v3, 7 (stack24)
        %s121646_s0 = sand.u32 255, %s11728_s22 (stack31)
        %s8001_s27 = sshrl.u32 %s8000_s23, 10 (stack25)
        %s156449_s8 = sshll.u32 %s157870_s16, 3 (stack32)
        %s156443_s9 = sor.u32 256, %s121646_s0 (stack33)
        %s11730_s22 = scalar_lea.vmem %s156438_s3, %s156449_s8 (stack34)
        %p119784_p7 = scmp.gt.s32.totalorder %s8001_s27, 1 (stack27)
        %s11732_s14 = scalar_lea.vmem %s11730_s22, %s156448_s21 (stack35)
        %s121657_s23 = sand.u32 1023, %s8000_s23 /* smod.u32 w/div 1024 */ (stack26)
        %v11733_v6 = vld [vmem:[%s11732_s14] ss:$0 sm:$0xff] (stack22)
        %s157872_s27 = smov (%p119784_p7, %s8001_s27), 1 (stack17)
        %11737 = vbcast.lane.b32.xlu1 %v11733_v6, %s156443_s9 (stack36)
        %s156445_s15 = sshrl.u32 %s121657_s23, 7 (stack28)
        %s8006_s22 = sand.u32 127, %s121657_s23 /* smod.u32 w/div 128 */ (stack29)
        %s156447_s14 = sshll.u32 %s157872_s27, 3 (stack32)
        %s121666_s22 = sand.u32 255, %s8006_s22 (stack31)
        %156673 = sst [smem:[#allocation8_spill]] %s121666_s22 (stack4)
        %s8008_s12 = scalar_lea.vmem %s156438_s3, %s156447_s14 (stack34)
        %s156446_s9 = sor.u32 256, %s121666_s22 (stack33)
        %s8010_s12 = scalar_lea.vmem %s8008_s12, %s156445_s15 (stack35)
        %s19166_s15 = sadd.s32 40, %s121600_s10 (stack30)
        %v8011_v7 = vld [vmem:[%s8010_s12] ss:$0 sm:$0xff] (stack22)
        %s19167_s12 = sshrl.u32 %s19166_s15, 10 (stack25)
        %s121677_s15 = sand.u32 1023, %s19166_s15 /* smod.u32 w/div 1024 */ (stack26)
        %8015 = vbcast.lane.b32.xlu0 %v8011_v7, %s156446_s9 (stack36)
        %p119844_p8 = scmp.gt.s32.totalorder %s19167_s12, 1 (stack27)
        %s156453_s9 = sshrl.u32 %s121677_s15, 7 (stack28)
        %s19172_s14 = sand.u32 127, %s121677_s15 /* smod.u32 w/div 128 */ (stack29)
        %s15444_s21 = sadd.s32 32, %s121600_s10 (stack30)
        %s157874_s12 = smov (%p119844_p8, %s19167_s12), 1 (stack17)
        %s121686_s14 = sand.u32 255, %s19172_s14 (stack31)
        %156674 = sst [smem:[#allocation9_spill]] %s121686_s14 (stack4)
        %s15445_s8 = sshrl.u32 %s15444_s21, 10 (stack25)
        %s156454_s25 = sshll.u32 %s157874_s12, 3 (stack32)
        %s19174_s18 = scalar_lea.vmem %s156438_s3, %s156454_s25 (stack34)
        %p119824_p9 = scmp.gt.s32.totalorder %s15445_s8, 1 (stack27)
        %s19176_s26 = scalar_lea.vmem %s19174_s18, %s156453_s9 (stack35)
        %s121697_s21 = sand.u32 1023, %s15444_s21 /* smod.u32 w/div 1024 */ (stack26)
        %156675 = sst [smem:[#allocation10_spill]] %s121697_s21 (stack4)
        %v19177_v8 = vld [vmem:[%s19176_s26] ss:$0 sm:$0xff] (stack22)
        %s157876_s8 = smov (%p119824_p9, %s15445_s8), 1 (stack17)
        %s156676_s18 = sor.u32 256, %s121686_s14 (stack33)
        %19181 = vbcast.lane.b32.xlu1 %v19177_v8, %s156676_s18 (stack36)
        %s15450_s18 = sand.u32 127, %s121697_s21 /* smod.u32 w/div 128 */ (stack29)
        %s156455_s9 = sshll.u32 %s157876_s8, 3 (stack32)
        %s121706_s18 = sand.u32 255, %s15450_s18 (stack31)
        %156677 = sst [smem:[#allocation11_spill]] %s121706_s18 (stack4)
        %s15452_s25 = scalar_lea.vmem %s156438_s3, %s156455_s9 (stack34)
        %s156456_s26 = sor.u32 256, %s121706_s18 (stack33)
        %s156678_s9 = sshrl.u32 %s121697_s21, 7 (stack28)
        %s15454_s9 = scalar_lea.vmem %s15452_s25, %s156678_s9 (stack35)
        %s26610_s25 = sadd.s32 56, %s121600_s10 (stack30)
        %v15455_v9 = vld [vmem:[%s15454_s9] ss:$0 sm:$0xff] (stack22)
        %s26611_s9 = sshrl.u32 %s26610_s25, 10 (stack25)
        %s121717_s25 = sand.u32 1023, %s26610_s25 /* smod.u32 w/div 1024 */ (stack26)
        %15459 = vbcast.lane.b32.xlu0 %v15455_v9, %s156456_s26 (stack36)
        %p119884_p10 = scmp.gt.s32.totalorder %s26611_s9, 1 (stack27)
        %s26616_s26 = sand.u32 127, %s121717_s25 /* smod.u32 w/div 128 */ (stack29)
        %s22888_s4 = sadd.s32 48, %s121600_s10 (stack30)
        %s157878_s9 = smov (%p119884_p10, %s26611_s9), 1 (stack17)
        %s121726_s26 = sand.u32 255, %s26616_s26 (stack31)
        %156679 = sst [smem:[#allocation12_spill]] %s121726_s26 (stack4)
        %s22889_s30 = sshrl.u32 %s22888_s4, 10 (stack25)
        %s156680_s28 = sshll.u32 %s157878_s9, 3 (stack32)
        %s26618_s7 = scalar_lea.vmem %s156438_s3, %s156680_s28 (stack34)
        %p119864_p11 = scmp.gt.s32.totalorder %s22889_s30, 1 (stack27)
        %s156681_s2 = sshrl.u32 %s121717_s25, 7 (stack28)
        %s26620_s28 = scalar_lea.vmem %s26618_s7, %s156681_s2 (stack35)
        %s121737_s4 = sand.u32 1023, %s22888_s4 /* smod.u32 w/div 1024 */ (stack26)
        %156682 = sst [smem:[#allocation13_spill]] %s121737_s4 (stack4)
        %v26621_v10 = vld [vmem:[%s26620_s28] ss:$0 sm:$0xff] (stack22)
        %s157880_s30 = smov (%p119864_p11, %s22889_s30), 1 (stack17)
        %s156683_s7 = sor.u32 256, %s121726_s26 (stack33)
        %26625 = vbcast.lane.b32.xlu1 %v26621_v10, %s156683_s7 (stack36)
        %s22894_s28 = sand.u32 127, %s121737_s4 /* smod.u32 w/div 128 */ (stack29)
        %s156462_s7 = sshll.u32 %s157880_s30, 3 (stack32)
        %s121746_s28 = sand.u32 255, %s22894_s28 (stack31)
        %156684 = sst [smem:[#allocation14_spill]] %s121746_s28 (stack4)
        %s22896_s29 = scalar_lea.vmem %s156438_s3, %s156462_s7 (stack34)
        %s156463_s2 = sor.u32 256, %s121746_s28 (stack33)
        %s156685_s7 = sshrl.u32 %s121737_s4, 7 (stack28)
        %s22898_s7 = scalar_lea.vmem %s22896_s29, %s156685_s7 (stack35)
        %s34054_s29 = sadd.s32 72, %s121600_s10 (stack30)
        %v22899_v11 = vld [vmem:[%s22898_s7] ss:$0 sm:$0xff] (stack22)
        %s34055_s7 = sshrl.u32 %s34054_s29, 10 (stack25)
        %s121757_s29 = sand.u32 1023, %s34054_s29 /* smod.u32 w/div 1024 */ (stack26)
        %156686 = sst [smem:[#allocation15_spill]] %s121757_s29 (stack4)
        %22903 = vbcast.lane.b32.xlu0 %v22899_v11, %s156463_s2 (stack36)
        %p119924_p12 = scmp.gt.s32.totalorder %s34055_s7, 1 (stack27)
        %s34060_s2 = sand.u32 127, %s121757_s29 /* smod.u32 w/div 128 */ (stack29)
        %s30332_s28 = sadd.s32 64, %s121600_s10 (stack30)
        %s157882_s7 = smov (%p119924_p12, %s34055_s7), 1 (stack17)
        %s121766_s2 = sand.u32 255, %s34060_s2 (stack31)
        %156687 = sst [smem:[#allocation16_spill]] %s121766_s2 (stack4)
        %s30333_s18 = sshrl.u32 %s30332_s28, 10 (stack25)
        %s156688_s26 = sshll.u32 %s157882_s7, 3 (stack32)
        %s34062_s22 = scalar_lea.vmem %s156438_s3, %s156688_s26 (stack34)
        %p119904_p13 = scmp.gt.s32.totalorder %s30333_s18, 1 (stack27)
        %s156689_s14 = sshrl.u32 %s121757_s29, 7 (stack28)
        %s34064_s26 = scalar_lea.vmem %s34062_s22, %s156689_s14 (stack35)
        %s121777_s28 = sand.u32 1023, %s30332_s28 /* smod.u32 w/div 1024 */ (stack26)
        %156690 = sst [smem:[#allocation17_spill]] %s121777_s28 (stack4)
        %v34065_v12 = vld [vmem:[%s34064_s26] ss:$0 sm:$0xff] (stack22)
        %s157884_s18 = smov (%p119904_p13, %s30333_s18), 1 (stack17)
        %s156691_s22 = sor.u32 256, %s121766_s2 (stack33)
        %34069 = vbcast.lane.b32.xlu1 %v34065_v12, %s156691_s22 (stack36)
        %s30338_s26 = sand.u32 127, %s121777_s28 /* smod.u32 w/div 128 */ (stack29)
        %s156470_s22 = sshll.u32 %s157884_s18, 3 (stack32)
        %s121786_s26 = sand.u32 255, %s30338_s26 (stack31)
        %156692 = sst [smem:[#allocation18_spill]] %s121786_s26 (stack4)
        %s30340_s2 = scalar_lea.vmem %s156438_s3, %s156470_s22 (stack34)
        %s156471_s14 = sor.u32 256, %s121786_s26 (stack33)
        %s156693_s22 = sshrl.u32 %s121777_s28, 7 (stack28)
        %s30342_s22 = scalar_lea.vmem %s30340_s2, %s156693_s22 (stack35)
        %s41498_s2 = sadd.s32 88, %s121600_s10 (stack30)
        %v30343_v13 = vld [vmem:[%s30342_s22] ss:$0 sm:$0xff] (stack22)
        %s41499_s22 = sshrl.u32 %s41498_s2, 10 (stack25)
        %s121797_s2 = sand.u32 1023, %s41498_s2 /* smod.u32 w/div 1024 */ (stack26)
        %156694 = sst [smem:[#allocation19_spill]] %s121797_s2 (stack4)
        %30347 = vbcast.lane.b32.xlu0 %v30343_v13, %s156471_s14 (stack36)
        %p119964_p0 = scmp.gt.s32.totalorder %s41499_s22, 1 (stack27)
        %s41504_s14 = sand.u32 127, %s121797_s2 /* smod.u32 w/div 128 */ (stack29)
        %s37776_s26 = sadd.s32 80, %s121600_s10 (stack30)
        %s157886_s22 = smov (%p119964_p0, %s41499_s22), 1 (stack17)
        %s121806_s14 = sand.u32 255, %s41504_s14 (stack31)
        %156695 = sst [smem:[#allocation20_spill]] %s121806_s14 (stack4)
        %s37777_s28 = sshrl.u32 %s37776_s26, 10 (stack25)
        %s156696_s29 = sshll.u32 %s157886_s22, 3 (stack32)
        %s41506_s21 = scalar_lea.vmem %s156438_s3, %s156696_s29 (stack34)
        %p119944_p1 = scmp.gt.s32.totalorder %s37777_s28, 1 (stack27)
        %s156697_s4 = sshrl.u32 %s121797_s2, 7 (stack28)
        %s41508_s29 = scalar_lea.vmem %s41506_s21, %s156697_s4 (stack35)
        %s121817_s26 = sand.u32 1023, %s37776_s26 /* smod.u32 w/div 1024 */ (stack26)
        %156698 = sst [smem:[#allocation21_spill]] %s121817_s26 (stack4)
        %v41509_v14 = vld [vmem:[%s41508_s29] ss:$0 sm:$0xff] (stack22)
        %s157888_s28 = smov (%p119944_p1, %s37777_s28), 1 (stack17)
        %156699 = sst [smem:[#allocation22_spill]] %s157888_s28 (stack4)
        %s156700_s21 = sor.u32 256, %s121806_s14 (stack33)
        %41513 = vbcast.lane.b32.xlu1 %v41509_v14, %s156700_s21 (stack36)
        %s37782_s29 = sand.u32 127, %s121817_s26 /* smod.u32 w/div 128 */ (stack29)
        %s156478_s21 = sshll.u32 %s157888_s28, 3 (stack32)
        %s121826_s29 = sand.u32 255, %s37782_s29 (stack31)
        %156701 = sst [smem:[#allocation23_spill]] %s121826_s29 (stack4)
        %s37784_s14 = scalar_lea.vmem %s156438_s3, %s156478_s21 (stack34)
        %s156479_s4 = sor.u32 256, %s121826_s29 (stack33)
        %s156702_s21 = sshrl.u32 %s121817_s26, 7 (stack28)
        %s37786_s21 = scalar_lea.vmem %s37784_s14, %s156702_s21 (stack35)
        %s48942_s14 = sadd.s32 104, %s121600_s10 (stack30)
        %v37787_v15 = vld [vmem:[%s37786_s21] ss:$0 sm:$0xff] (stack22)
        %s48943_s21 = sshrl.u32 %s48942_s14, 10 (stack25)
        %s121837_s14 = sand.u32 1023, %s48942_s14 /* smod.u32 w/div 1024 */ (stack26)
        %156703 = sst [smem:[#allocation24_spill]] %s121837_s14 (stack4)
        %37791 = vbcast.lane.b32.xlu0 %v37787_v15, %s156479_s4 (stack36)
        %p120004_p2 = scmp.gt.s32.totalorder %s48943_s21, 1 (stack27)
        %s48948_s4 = sand.u32 127, %s121837_s14 /* smod.u32 w/div 128 */ (stack29)
        %s45220_s29 = sadd.s32 96, %s121600_s10 (stack30)
        %s157890_s21 = smov (%p120004_p2, %s48943_s21), 1 (stack17)
        %156704 = sst [smem:[#allocation25_spill]] %s157890_s21 (stack4)
        %s121846_s4 = sand.u32 255, %s48948_s4 (stack31)
        %156705 = sst [smem:[#allocation26_spill]] %s121846_s4 (stack4)
        %s45221_s26 = sshrl.u32 %s45220_s29, 10 (stack25)
        %s156706_s28 = sshll.u32 %s157890_s21, 3 (stack32)
        %s48950_s28 = scalar_lea.vmem %s156438_s3, %s156706_s28 (stack34)
        %p119984_p3 = scmp.gt.s32.totalorder %s45221_s26, 1 (stack27)
        %s156707_s2 = sshrl.u32 %s121837_s14, 7 (stack28)
        %s48952_s21 = scalar_lea.vmem %s48950_s28, %s156707_s2 (stack35)
        %s121857_s29 = sand.u32 1023, %s45220_s29 /* smod.u32 w/div 1024 */ (stack26)
        %156708 = sst [smem:[#allocation27_spill]] %s121857_s29 (stack4)
        %v48953_v16 = vld [vmem:[%s48952_s21] ss:$0 sm:$0xff] (stack22)
        %s157892_s26 = smov (%p119984_p3, %s45221_s26), 1 (stack17)
        %156709 = sst [smem:[#allocation28_spill]] %s157892_s26 (stack4)
        %s156710_s28 = sor.u32 256, %s121846_s4 (stack33)
        %48957 = vbcast.lane.b32.xlu1 %v48953_v16, %s156710_s28 (stack36)
        %s45226_s21 = sand.u32 127, %s121857_s29 /* smod.u32 w/div 128 */ (stack29)
        %s156486_s28 = sshll.u32 %s157892_s26, 3 (stack32)
        %s121866_s21 = sand.u32 255, %s45226_s21 (stack31)
        %156711 = sst [smem:[#allocation29_spill]] %s121866_s21 (stack4)
        %s45228_s4 = scalar_lea.vmem %s156438_s3, %s156486_s28 (stack34)
        %s156487_s2 = sor.u32 256, %s121866_s21 (stack33)
        %s156712_s28 = sshrl.u32 %s121857_s29, 7 (stack28)
        %s45230_s28 = scalar_lea.vmem %s45228_s4, %s156712_s28 (stack35)
        %s56386_s4 = sadd.s32 120, %s121600_s10 (stack30)
        %v45231_v17 = vld [vmem:[%s45230_s28] ss:$0 sm:$0xff] (stack22)
        %s56387_s28 = sshrl.u32 %s56386_s4, 10 (stack25)
        %s121877_s4 = sand.u32 1023, %s56386_s4 /* smod.u32 w/div 1024 */ (stack26)
        %156713 = sst [smem:[#allocation30_spill]] %s121877_s4 (stack4)
        %45235 = vbcast.lane.b32.xlu0 %v45231_v17, %s156487_s2 (stack36)
        %p120044_p4 = scmp.gt.s32.totalorder %s56387_s28, 1 (stack27)
        %s56392_s2 = sand.u32 127, %s121877_s4 /* smod.u32 w/div 128 */ (stack29)
        %s52664_s21 = sadd.s32 112, %s121600_s10 (stack30)
        %s157894_s28 = smov (%p120044_p4, %s56387_s28), 1 (stack17)
        %156714 = sst [smem:[#allocation31_spill]] %s157894_s28 (stack4)
        %s121886_s2 = sand.u32 255, %s56392_s2 (stack31)
        %156715 = sst [smem:[#allocation32_spill]] %s121886_s2 (stack4)
        %s52665_s29 = sshrl.u32 %s52664_s21, 10 (stack25)
        %s156716_s26 = sshll.u32 %s157894_s28, 3 (stack32)
        %s56394_s26 = scalar_lea.vmem %s156438_s3, %s156716_s26 (stack34)
        %p120024_p5 = scmp.gt.s32.totalorder %s52665_s29, 1 (stack27)
        %s156717_s14 = sshrl.u32 %s121877_s4, 7 (stack28)
        %s56396_s28 = scalar_lea.vmem %s56394_s26, %s156717_s14 (stack35)
        %s121897_s21 = sand.u32 1023, %s52664_s21 /* smod.u32 w/div 1024 */ (stack26)
        %156718 = sst [smem:[#allocation33_spill]] %s121897_s21 (stack4)
        %v56397_v18 = vld [vmem:[%s56396_s28] ss:$0 sm:$0xff] (stack22)
        %s157896_s29 = smov (%p120024_p5, %s52665_s29), 1 (stack17)
        %156719 = sst [smem:[#allocation34_spill]] %s157896_s29 (stack4)
        %s156720_s26 = sor.u32 256, %s121886_s2 (stack33)
        %56401 = vbcast.lane.b32.xlu1 %v56397_v18, %s156720_s26 (stack36)
        %s52670_s28 = sand.u32 127, %s121897_s21 /* smod.u32 w/div 128 */ (stack29)
        %s156494_s26 = sshll.u32 %s157896_s29, 3 (stack32)
        %s121906_s28 = sand.u32 255, %s52670_s28 (stack31)
        %156721 = sst [smem:[#allocation35_spill]] %s121906_s28 (stack4)
        %s52672_s2 = scalar_lea.vmem %s156438_s3, %s156494_s26 (stack34)
        %s156495_s14 = sor.u32 256, %s121906_s28 (stack33)
        %s156722_s26 = sshrl.u32 %s121897_s21, 7 (stack28)
        %s52674_s26 = scalar_lea.vmem %s52672_s2, %s156722_s26 (stack35)
        %s63830_s2 = sadd.s32 136, %s121600_s10 (stack30)
        %v52675_v19 = vld [vmem:[%s52674_s26] ss:$0 sm:$0xff] (stack22)
        %s63831_s26 = sshrl.u32 %s63830_s2, 10 (stack25)
        %s121917_s2 = sand.u32 1023, %s63830_s2 /* smod.u32 w/div 1024 */ (stack26)
        %156723 = sst [smem:[#allocation36_spill]] %s121917_s2 (stack4)
        %52679 = vbcast.lane.b32.xlu0 %v52675_v19, %s156495_s14 (stack36)
        %p120084_p6 = scmp.gt.s32.totalorder %s63831_s26, 1 (stack27)
        %s63836_s14 = sand.u32 127, %s121917_s2 /* smod.u32 w/div 128 */ (stack29)
        %s60108_s28 = sadd.s32 128, %s121600_s10 (stack30)
        %s157898_s26 = smov (%p120084_p6, %s63831_s26), 1 (stack17)
        %156724 = sst [smem:[#allocation37_spill]] %s157898_s26 (stack4)
        %s121926_s14 = sand.u32 255, %s63836_s14 (stack31)
        %156725 = sst [smem:[#allocation38_spill]] %s121926_s14 (stack4)
        %s60109_s21 = sshrl.u32 %s60108_s28, 10 (stack25)
        %s156726_s29 = sshll.u32 %s157898_s26, 3 (stack32)
        %s63838_s29 = scalar_lea.vmem %s156438_s3, %s156726_s29 (stack34)
        %p120064_p7 = scmp.gt.s32.totalorder %s60109_s21, 1 (stack27)
        %s156727_s4 = sshrl.u32 %s121917_s2, 7 (stack28)
        %s63840_s26 = scalar_lea.vmem %s63838_s29, %s156727_s4 (stack35)
        %s121937_s28 = sand.u32 1023, %s60108_s28 /* smod.u32 w/div 1024 */ (stack26)
        %156728 = sst [smem:[#allocation39_spill]] %s121937_s28 (stack4)
        %v63841_v20 = vld [vmem:[%s63840_s26] ss:$0 sm:$0xff] (stack22)
        %s157900_s21 = smov (%p120064_p7, %s60109_s21), 1 (stack17)
        %156729 = sst [smem:[#allocation40_spill]] %s157900_s21 (stack4)
        %s156730_s29 = sor.u32 256, %s121926_s14 (stack33)
        %63845 = vbcast.lane.b32.xlu1 %v63841_v20, %s156730_s29 (stack36)
        %s60114_s26 = sand.u32 127, %s121937_s28 /* smod.u32 w/div 128 */ (stack29)
        %s156502_s29 = sshll.u32 %s157900_s21, 3 (stack32)
        %s121946_s26 = sand.u32 255, %s60114_s26 (stack31)
        %156731 = sst [smem:[#allocation41_spill]] %s121946_s26 (stack4)
        %s60116_s14 = scalar_lea.vmem %s156438_s3, %s156502_s29 (stack34)
        %s156503_s4 = sor.u32 256, %s121946_s26 (stack33)
        %s156732_s29 = sshrl.u32 %s121937_s28, 7 (stack28)
        %s60118_s29 = scalar_lea.vmem %s60116_s14, %s156732_s29 (stack35)
        %s71274_s14 = sadd.s32 152, %s121600_s10 (stack30)
        %v60119_v21 = vld [vmem:[%s60118_s29] ss:$0 sm:$0xff] (stack22)
        %s71275_s29 = sshrl.u32 %s71274_s14, 10 (stack25)
        %s121957_s14 = sand.u32 1023, %s71274_s14 /* smod.u32 w/div 1024 */ (stack26)
        %156733 = sst [smem:[#allocation42_spill]] %s121957_s14 (stack4)
        %v121959_v22 = vpop.permute.xlu1 %880 (stack37)
        %156734 = vst [vmem:[#allocation43_spill] sm:$0xff] /*vst_source=*/%v121959_v22 (stack38)
        %v121961_v23 = vpop.permute.xlu0 %379 (stack37)
        %156735 = vst [vmem:[#allocation44_spill] sm:$0xff] /*vst_source=*/%v121961_v23 (stack38)
        %60123 = vbcast.lane.b32.xlu0 %v60119_v21, %s156503_s4 (stack36)
        %p120124_p8 = scmp.gt.s32.totalorder %s71275_s29, 1 (stack27)
        %s71280_s4 = sand.u32 127, %s121957_s14 /* smod.u32 w/div 128 */ (stack29)
        %s67552_s26 = sadd.s32 144, %s121600_s10 (stack30)
        %s157902_s29 = smov (%p120124_p8, %s71275_s29), 1 (stack17)
        %156736 = sst [smem:[#allocation45_spill]] %s157902_s29 (stack4)
        %s121970_s4 = sand.u32 255, %s71280_s4 (stack31)
        %156737 = sst [smem:[#allocation46_spill]] %s121970_s4 (stack4)
        %s67553_s28 = sshrl.u32 %s67552_s26, 10 (stack25)
        %v121972_v24 = vpop.permute.xlu1 %1367 (stack37)
        %156738 = vst [vmem:[#allocation47_spill] sm:$0xff] /*vst_source=*/%v121972_v24 (stack38)
        %v121974_v25 = vpop.permute.xlu0 %1854 (stack37)
        %156739 = vst [vmem:[#allocation48_spill] sm:$0xff] /*vst_source=*/%v121974_v25 (stack38)
        %s156740_s21 = sshll.u32 %s157902_s29, 3 (stack32)
        %s71282_s21 = scalar_lea.vmem %s156438_s3, %s156740_s21 (stack34)
        %p120104_p9 = scmp.gt.s32.totalorder %s67553_s28, 1 (stack27)
        %s156741_s2 = sshrl.u32 %s121957_s14, 7 (stack28)
        %s71284_s29 = scalar_lea.vmem %s71282_s21, %s156741_s2 (stack35)
        %s121985_s26 = sand.u32 1023, %s67552_s26 /* smod.u32 w/div 1024 */ (stack26)
        %156742 = sst [smem:[#allocation49_spill]] %s121985_s26 (stack4)
        %v71285_v26 = vld [vmem:[%s71284_s29] ss:$0 sm:$0xff] (stack22)
        %s157904_s28 = smov (%p120104_p9, %s67553_s28), 1 (stack17)
        %156743 = sst [smem:[#allocation50_spill]] %s157904_s28 (stack4)
        %v121989_v27 = vpop.permute.xlu1 %2341 (stack37)
        %156744 = vst [vmem:[#allocation51_spill] sm:$0xff] /*vst_source=*/%v121989_v27 (stack38)
        %v121991_v28 = vpop.permute.xlu0 %367 (stack39)
        %s156745_s21 = sor.u32 256, %s121970_s4 (stack33)
        %71289 = vbcast.lane.b32.xlu1 %v71285_v26, %s156745_s21 (stack36)
        %s67558_s29 = sand.u32 127, %s121985_s26 /* smod.u32 w/div 128 */ (stack29)
        %s156510_s21 = sshll.u32 %s157904_s28, 3 (stack32)
        %s121998_s29 = sand.u32 255, %s67558_s29 (stack31)
        %156746 = sst [smem:[#allocation52_spill]] %s121998_s29 (stack4)
        %s67560_s4 = scalar_lea.vmem %s156438_s3, %s156510_s21 (stack34)
        %s156511_s2 = sor.u32 256, %s121998_s29 (stack33)
        %v122008_v29 = vadd.s32 %v121961_v23, %v121991_v28 (stack40)
        %s156747_s21 = sshrl.u32 %s121985_s26, 7 (stack28)
        %s67562_s21 = scalar_lea.vmem %s67560_s4, %s156747_s21 (stack35)
        %s78718_s4 = sadd.s32 168, %s121600_s10 (stack30)
        %v122013_v30 = vpop.permute.xlu1 %3315 (stack37)
        %156748 = vst [vmem:[#allocation53_spill] sm:$0xff] /*vst_source=*/%v122013_v30 (stack38)
        %v122015_v31 = vpop.permute.xlu0 %2828 (stack37)
        %156749 = vst [vmem:[#allocation54_spill] sm:$0xff] /*vst_source=*/%v122015_v31 (stack38)
        %v67563_v32 = vld [vmem:[%s67562_s21] ss:$0 sm:$0xff] (stack22)
        %s78719_s21 = sshrl.u32 %s78718_s4, 10 (stack25)
        %s122017_s4 = sand.u32 1023, %s78718_s4 /* smod.u32 w/div 1024 */ (stack26)
        %156750 = sst [smem:[#allocation55_spill]] %s122017_s4 (stack4)
        %67567 = vbcast.lane.b32.xlu0 %v67563_v32, %s156511_s2 (stack36)
        %p120164_p10 = scmp.gt.s32.totalorder %s78719_s21, 1 (stack27)
        %s78724_s2 = sand.u32 127, %s122017_s4 /* smod.u32 w/div 128 */ (stack29)
        %s74996_s29 = sadd.s32 160, %s121600_s10 (stack30)
        %v122026_v33 = vadd.s32 %v121959_v22, %v121991_v28 (stack40)
        %s157906_s21 = smov (%p120164_p10, %s78719_s21), 1 (stack17)
        %156751 = sst [smem:[#allocation56_spill]] %s157906_s21 (stack4)
        %v122030_v34 = vpop.permute.xlu1 %4293 (stack39)
        %156752 = vst [vmem:[#allocation57_spill] sm:$0xff] /*vst_source=*/%v122030_v34 (stack38)
        %v122032_v35 = vpop.permute.xlu0 %3802 (stack37)
        %156753 = vst [vmem:[#allocation58_spill] sm:$0xff] /*vst_source=*/%v122032_v35 (stack38)
        %s122034_s2 = sand.u32 255, %s78724_s2 (stack31)
        %156754 = sst [smem:[#allocation59_spill]] %s122034_s2 (stack4)
        %s74997_s26 = sshrl.u32 %s74996_s29, 10 (stack25)
        %s156755_s28 = sshll.u32 %s157906_s21, 3 (stack32)
        %s78726_s28 = scalar_lea.vmem %s156438_s3, %s156755_s28 (stack34)
        %p120144_p11 = scmp.gt.s32.totalorder %s74997_s26, 1 (stack27)
        %s156756_s14 = sshrl.u32 %s122017_s4, 7 (stack28)
        %s78728_s21 = scalar_lea.vmem %s78726_s28, %s156756_s14 (stack35)
        %s122045_s29 = sand.u32 1023, %s74996_s29 /* smod.u32 w/div 1024 */ (stack26)
        %156757 = sst [smem:[#allocation60_spill]] %s122045_s29 (stack4)
        %v122047_v36 = vpop.permute.xlu1 %11737 (stack39)
        %156758 = vst [vmem:[#allocation61_spill] sm:$0xff] /*vst_source=*/%v122047_v36 (stack38)
        %v122051_v37 = vadd.s32 %v121972_v24, %v121991_v28 (stack40)
        %v78729_v38 = vld [vmem:[%s78728_s21] ss:$0 sm:$0xff] (stack22)
        %s157908_s26 = smov (%p120144_p11, %s74997_s26), 1 (stack17)
        %156759 = sst [smem:[#allocation62_spill]] %s157908_s26 (stack4)
        %s156760_s28 = sor.u32 256, %s122034_s2 (stack33)
        %78733 = vbcast.lane.b32.xlu1 %v78729_v38, %s156760_s28 (stack36)
        %s75002_s21 = sand.u32 127, %s122045_s29 /* smod.u32 w/div 128 */ (stack29)
        %s156518_s28 = sshll.u32 %s157908_s26, 3 (stack32)
        %s122060_s21 = sand.u32 255, %s75002_s21 (stack31)
        %156761 = sst [smem:[#allocation63_spill]] %s122060_s21 (stack4)
        %s75004_s2 = scalar_lea.vmem %s156438_s3, %s156518_s28 (stack34)
        %s156519_s14 = sor.u32 256, %s122060_s21 (stack33)
        %v122068_v39 = vpop.permute.xlu0 %8015 (stack39)
        %156762 = vst [vmem:[#allocation64_spill] sm:$0xff] /*vst_source=*/%v122068_v39 (stack38)
        %s156763_s28 = sshrl.u32 %s122045_s29, 7 (stack28)
        %s75006_s28 = scalar_lea.vmem %s75004_s2, %s156763_s28 (stack35)
        %s86162_s2 = sadd.s32 184, %s121600_s10 (stack30)
        %v75007_v40 = vld [vmem:[%s75006_s28] ss:$0 sm:$0xff] (stack22)
        %s86163_s28 = sshrl.u32 %s86162_s2, 10 (stack25)
        %s122073_s2 = sand.u32 1023, %s86162_s2 /* smod.u32 w/div 1024 */ (stack26)
        %156764 = sst [smem:[#allocation65_spill]] %s122073_s2 (stack4)
        %75011 = vbcast.lane.b32.xlu0 %v75007_v40, %s156519_s14 (stack36)
        %p120204_p12 = scmp.gt.s32.totalorder %s86163_s28, 1 (stack27)
        %v122080_v41 = vadd.s32 %v121974_v25, %v121991_v28 (stack40)
        %s86168_s14 = sand.u32 127, %s122073_s2 /* smod.u32 w/div 128 */ (stack29)
        %s82440_s21 = sadd.s32 176, %s121600_s10 (stack30)
        %s157910_s28 = smov (%p120204_p12, %s86163_s28), 1 (stack17)
        %156765 = sst [smem:[#allocation66_spill]] %s157910_s28 (stack4)
        %s122086_s14 = sand.u32 255, %s86168_s14 (stack31)
        %156766 = sst [smem:[#allocation67_spill]] %s122086_s14 (stack4)
        %s82441_s29 = sshrl.u32 %s82440_s21, 10 (stack25)
        %s156767_s26 = sshll.u32 %s157910_s28, 3 (stack32)
        %s86170_s26 = scalar_lea.vmem %s156438_s3, %s156767_s26 (stack34)
        %p120184_p13 = scmp.gt.s32.totalorder %s82441_s29, 1 (stack27)
        %v122095_v42 = vpop.permute.xlu1 %19181 (stack39)
        %156768 = vst [vmem:[#allocation68_spill] sm:$0xff] /*vst_source=*/%v122095_v42 (stack38)
        %s156769_s4 = sshrl.u32 %s122073_s2, 7 (stack28)
        %s86172_s28 = scalar_lea.vmem %s86170_s26, %s156769_s4 (stack35)
        %s122099_s21 = sand.u32 1023, %s82440_s21 /* smod.u32 w/div 1024 */ (stack26)
        %156770 = sst [smem:[#allocation69_spill]] %s122099_s21 (stack4)
        %v86173_v43 = vld [vmem:[%s86172_s28] ss:$0 sm:$0xff] (stack22)
        %s157912_s29 = smov (%p120184_p13, %s82441_s29), 1 (stack17)
        %156771 = sst [smem:[#allocation70_spill]] %s157912_s29 (stack4)
        %s156772_s26 = sor.u32 256, %s122086_s14 (stack33)
        %86177 = vbcast.lane.b32.xlu1 %v86173_v43, %s156772_s26 (stack36)
        %s82446_s28 = sand.u32 127, %s122099_s21 /* smod.u32 w/div 128 */ (stack29)
        %s156526_s26 = sshll.u32 %s157912_s29, 3 (stack32)
        %s122108_s28 = sand.u32 255, %s82446_s28 (stack31)
        %156773 = sst [smem:[#allocation71_spill]] %s122108_s28 (stack4)
        %s82448_s14 = scalar_lea.vmem %s156438_s3, %s156526_s26 (stack34)
        %s156527_s4 = sor.u32 256, %s122108_s28 (stack33)
        %v122116_v44 = vpop.permute.xlu0 %15459 (stack39)
        %156774 = vst [vmem:[#allocation72_spill] sm:$0xff] /*vst_source=*/%v122116_v44 (stack38)
        %s156775_s26 = sshrl.u32 %s122099_s21, 7 (stack28)
        %s82450_s26 = scalar_lea.vmem %s82448_s14, %s156775_s26 (stack35)
        %s93606_s14 = sadd.s32 200, %s121600_s10 (stack30)
        %v82451_v45 = vld [vmem:[%s82450_s26] ss:$0 sm:$0xff] (stack22)
        %s93607_s26 = sshrl.u32 %s93606_s14, 10 (stack25)
        %s122121_s14 = sand.u32 1023, %s93606_s14 /* smod.u32 w/div 1024 */ (stack26)
        %156776 = sst [smem:[#allocation73_spill]] %s122121_s14 (stack4)
        %82455 = vbcast.lane.b32.xlu0 %v82451_v45, %s156527_s4 (stack36)
        %p120244_p0 = scmp.gt.s32.totalorder %s93607_s26, 1 (stack27)
        %s93612_s4 = sand.u32 127, %s122121_s14 /* smod.u32 w/div 128 */ (stack29)
        %s89884_s28 = sadd.s32 192, %s121600_s10 (stack30)
        %s157914_s26 = smov (%p120244_p0, %s93607_s26), 1 (stack17)
        %156777 = sst [smem:[#allocation74_spill]] %s157914_s26 (stack4)
        %s122130_s4 = sand.u32 255, %s93612_s4 (stack31)
        %156778 = sst [smem:[#allocation75_spill]] %s122130_s4 (stack4)
        %s89885_s21 = sshrl.u32 %s89884_s28, 10 (stack25)
        %s156779_s29 = sshll.u32 %s157914_s26, 3 (stack32)
        %s93614_s29 = scalar_lea.vmem %s156438_s3, %s156779_s29 (stack34)
        %p120224_p1 = scmp.gt.s32.totalorder %s89885_s21, 1 (stack27)
        %v122139_v46 = vpop.permute.xlu1 %26625 (stack39)
        %156780 = vst [vmem:[#allocation76_spill] sm:$0xff] /*vst_source=*/%v122139_v46 (stack38)
        %s156781_s2 = sshrl.u32 %s122121_s14, 7 (stack28)
        %s93616_s26 = scalar_lea.vmem %s93614_s29, %s156781_s2 (stack35)
        %s122143_s28 = sand.u32 1023, %s89884_s28 /* smod.u32 w/div 1024 */ (stack26)
        %156782 = sst [smem:[#allocation77_spill]] %s122143_s28 (stack4)
        %v93617_v47 = vld [vmem:[%s93616_s26] ss:$0 sm:$0xff] (stack22)
        %s157916_s21 = smov (%p120224_p1, %s89885_s21), 1 (stack17)
        %156783 = sst [smem:[#allocation78_spill]] %s157916_s21 (stack4)
        %s156784_s29 = sor.u32 256, %s122130_s4 (stack33)
        %93621 = vbcast.lane.b32.xlu1 %v93617_v47, %s156784_s29 (stack36)
        %s89890_s26 = sand.u32 127, %s122143_s28 /* smod.u32 w/div 128 */ (stack29)
        %s156534_s29 = sshll.u32 %s157916_s21, 3 (stack32)
        %s122152_s26 = sand.u32 255, %s89890_s26 (stack31)
        %156785 = sst [smem:[#allocation79_spill]] %s122152_s26 (stack4)
        %s89892_s4 = scalar_lea.vmem %s156438_s3, %s156534_s29 (stack34)
        %s156535_s2 = sor.u32 256, %s122152_s26 (stack33)
        %v122160_v48 = vpop.permute.xlu0 %22903 (stack39)
        %156786 = vst [vmem:[#allocation80_spill] sm:$0xff] /*vst_source=*/%v122160_v48 (stack38)
        %s156787_s29 = sshrl.u32 %s122143_s28, 7 (stack28)
        %s89894_s29 = scalar_lea.vmem %s89892_s4, %s156787_s29 (stack35)
        %s101050_s4 = sadd.s32 216, %s121600_s10 (stack30)
        %v89895_v49 = vld [vmem:[%s89894_s29] ss:$0 sm:$0xff] (stack22)
        %s101051_s29 = sshrl.u32 %s101050_s4, 10 (stack25)
        %s122165_s4 = sand.u32 1023, %s101050_s4 /* smod.u32 w/div 1024 */ (stack26)
        %156788 = sst [smem:[#allocation81_spill]] %s122165_s4 (stack4)
        %89899 = vbcast.lane.b32.xlu0 %v89895_v49, %s156535_s2 (stack36)
        %p120284_p2 = scmp.gt.s32.totalorder %s101051_s29, 1 (stack27)
        %v122172_v50 = vadd.s32 %v121989_v27, %v121991_v28 (stack40)
        %s101056_s2 = sand.u32 127, %s122165_s4 /* smod.u32 w/div 128 */ (stack29)
        %s97328_s26 = sadd.s32 208, %s121600_s10 (stack30)
        %s157918_s29 = smov (%p120284_p2, %s101051_s29), 1 (stack17)
        %156789 = sst [smem:[#allocation82_spill]] %s157918_s29 (stack4)
        %s122178_s2 = sand.u32 255, %s101056_s2 (stack31)
        %156790 = sst [smem:[#allocation83_spill]] %s122178_s2 (stack4)
        %s97329_s28 = sshrl.u32 %s97328_s26, 10 (stack25)
        %s156791_s21 = sshll.u32 %s157918_s29, 3 (stack32)
        %s101058_s21 = scalar_lea.vmem %s156438_s3, %s156791_s21 (stack34)
        %p120264_p3 = scmp.gt.s32.totalorder %s97329_s28, 1 (stack27)
        %v122187_v51 = vpop.permute.xlu1 %34069 (stack39)
        %156792 = vst [vmem:[#allocation84_spill] sm:$0xff] /*vst_source=*/%v122187_v51 (stack38)
        %s156793_s14 = sshrl.u32 %s122165_s4, 7 (stack28)
        %s101060_s29 = scalar_lea.vmem %s101058_s21, %s156793_s14 (stack35)
        %s122191_s26 = sand.u32 1023, %s97328_s26 /* smod.u32 w/div 1024 */ (stack26)
        %156794 = sst [smem:[#allocation85_spill]] %s122191_s26 (stack4)
        %v101061_v52 = vld [vmem:[%s101060_s29] ss:$0 sm:$0xff] (stack22)
        %s157920_s28 = smov (%p120264_p3, %s97329_s28), 1 (stack17)
        %156795 = sst [smem:[#allocation86_spill]] %s157920_s28 (stack4)
        %s156796_s21 = sor.u32 256, %s122178_s2 (stack33)
        %101065 = vbcast.lane.b32.xlu1 %v101061_v52, %s156796_s21 (stack36)
        %s97334_s29 = sand.u32 127, %s122191_s26 /* smod.u32 w/div 128 */ (stack29)
        %s156542_s21 = sshll.u32 %s157920_s28, 3 (stack32)
        %s122200_s29 = sand.u32 255, %s97334_s29 (stack31)
        %156797 = sst [smem:[#allocation87_spill]] %s122200_s29 (stack4)
        %s97336_s2 = scalar_lea.vmem %s156438_s3, %s156542_s21 (stack34)
        %s156543_s14 = sor.u32 256, %s122200_s29 (stack33)
        %v122208_v53 = vpop.permute.xlu0 %30347 (stack39)
        %156798 = vst [vmem:[#allocation88_spill] sm:$0xff] /*vst_source=*/%v122208_v53 (stack38)
        %s156799_s21 = sshrl.u32 %s122191_s26, 7 (stack28)
        %s97338_s21 = scalar_lea.vmem %s97336_s2, %s156799_s21 (stack35)
        %s108494_s2 = sadd.s32 232, %s121600_s10 (stack30)
        %v97339_v54 = vld [vmem:[%s97338_s21] ss:$0 sm:$0xff] (stack22)
        %s108495_s21 = sshrl.u32 %s108494_s2, 10 (stack25)
        %s122213_s2 = sand.u32 1023, %s108494_s2 /* smod.u32 w/div 1024 */ (stack26)
        %97343 = vbcast.lane.b32.xlu0 %v97339_v54, %s156543_s14 (stack36)
        %p120324_p4 = scmp.gt.s32.totalorder %s108495_s21, 1 (stack27)
        %s108500_s14 = sand.u32 127, %s122213_s2 /* smod.u32 w/div 128 */ (stack29)
        %s104772_s29 = sadd.s32 224, %s121600_s10 (stack30)
        %s157922_s21 = smov (%p120324_p4, %s108495_s21), 1 (stack17)
        %156800 = sst [smem:[#allocation89_spill]] %s157922_s21 (stack4)
        %s122222_s14 = sand.u32 255, %s108500_s14 (stack31)
        %156801 = sst [smem:[#allocation90_spill]] %s122222_s14 (stack4)
        %s104773_s26 = sshrl.u32 %s104772_s29, 10 (stack25)
        %s156802_s21 = sshll.u32 %s157922_s21, 3 (stack32)
        %s108502_s28 = scalar_lea.vmem %s156438_s3, %s156802_s21 (stack34)
        %p120304_p5 = scmp.gt.s32.totalorder %s104773_s26, 1 (stack27)
        %v122231_v55 = vpop.permute.xlu1 %41513 (stack39)
        %156803 = vst [vmem:[#allocation91_spill] sm:$0xff] /*vst_source=*/%v122231_v55 (stack38)
        %s156804_s4 = sshrl.u32 %s122213_s2, 7 (stack28)
        %s108504_s21 = scalar_lea.vmem %s108502_s28, %s156804_s4 (stack35)
        %s122235_s29 = sand.u32 1023, %s104772_s29 /* smod.u32 w/div 1024 */ (stack26)
        %156805 = sst [smem:[#allocation92_spill]] %s122235_s29 (stack4)
        %v108505_v56 = vld [vmem:[%s108504_s21] ss:$0 sm:$0xff] (stack22)
        %s157924_s26 = smov (%p120304_p5, %s104773_s26), 1 (stack17)
        %156806 = sst [smem:[#allocation93_spill]] %s157924_s26 (stack4)
        %s156807_s28 = sor.u32 256, %s122222_s14 (stack33)
        %108509 = vbcast.lane.b32.xlu1 %v108505_v56, %s156807_s28 (stack36)
        %s104778_s21 = sand.u32 127, %s122235_s29 /* smod.u32 w/div 128 */ (stack29)
        %s156550_s28 = sshll.u32 %s157924_s26, 3 (stack32)
        %s122244_s21 = sand.u32 255, %s104778_s21 (stack31)
        %156808 = sst [smem:[#allocation94_spill]] %s122244_s21 (stack4)
        %s104780_s14 = scalar_lea.vmem %s156438_s3, %s156550_s28 (stack34)
        %s156551_s4 = sor.u32 256, %s122244_s21 (stack33)
        %v122252_v57 = vpop.permute.xlu0 %37791 (stack39)
        %156809 = vst [vmem:[#allocation95_spill] sm:$0xff] /*vst_source=*/%v122252_v57 (stack38)
        %s156810_s28 = sshrl.u32 %s122235_s29, 7 (stack28)
        %s104782_s28 = scalar_lea.vmem %s104780_s14, %s156810_s28 (stack35)
        %s115938_s14 = sadd.s32 248, %s121600_s10 (stack30)
        %v104783_v58 = vld [vmem:[%s104782_s28] ss:$0 sm:$0xff] (stack22)
        %s115939_s28 = sshrl.u32 %s115938_s14, 10 (stack25)
        %s122257_s14 = sand.u32 1023, %s115938_s14 /* smod.u32 w/div 1024 */ (stack26)
        %104787 = vbcast.lane.b32.xlu0 %v104783_v58, %s156551_s4 (stack36)
        %p120364_p6 = scmp.gt.s32.totalorder %s115939_s28, 1 (stack27)
        %s115944_s4 = sand.u32 127, %s122257_s14 /* smod.u32 w/div 128 */ (stack29)
        %s112216_s10 = sadd.s32 240, %s121600_s10 (stack30)
        %s157926_s28 = smov (%p120364_p6, %s115939_s28), 1 (stack17)
        %156811 = sst [smem:[#allocation96_spill]] %s157926_s28 (stack4)
        %s122266_s4 = sand.u32 255, %s115944_s4 (stack31)
        %s112217_s21 = sshrl.u32 %s112216_s10, 10 (stack25)
        %s156812_s28 = sshll.u32 %s157926_s28, 3 (stack32)
        %s115946_s26 = scalar_lea.vmem %s156438_s3, %s156812_s28 (stack34)
        %p120344_p7 = scmp.gt.s32.totalorder %s112217_s21, 1 (stack27)
        %v122275_v59 = vpop.permute.xlu1 %48957 (stack39)
        %156813 = vst [vmem:[#allocation97_spill] sm:$0xff] /*vst_source=*/%v122275_v59 (stack38)
        %s156814_s29 = sshrl.u32 %s122257_s14, 7 (stack28)
        %s115948_s28 = scalar_lea.vmem %s115946_s26, %s156814_s29 (stack35)
        %s122279_s10 = sand.u32 1023, %s112216_s10 /* smod.u32 w/div 1024 */ (stack26)
        %v115949_v60 = vld [vmem:[%s115948_s28] ss:$0 sm:$0xff] (stack22)
        %s157928_s21 = smov (%p120344_p7, %s112217_s21), 1 (stack17)
        %s156815_s26 = sor.u32 256, %s122266_s4 (stack33)
        %115953 = vbcast.lane.b32.xlu1 %v115949_v60, %s156815_s26 (stack36)
        %s112222_s28 = sand.u32 127, %s122279_s10 /* smod.u32 w/div 128 */ (stack29)
        %s122288_s28 = sand.u32 255, %s112222_s28 (stack31)
        %s156816_s6 = sld [smem:[#allocation155_spill]] (stack21)
        %v406_v61 = vld [vmem:[%s156816_s6] ss:$0 sm:$0xff] (stack22)
        %s156817_s29 = sshll.u32 %s157928_s21, 3 (stack32)
        %s112224_s6 = scalar_lea.vmem %s156438_s3, %s156817_s29 (stack34)
        %v122299_v62 = vpop.permute.xlu0 %45235 (stack39)
        %156818 = vst [vmem:[#allocation98_spill] sm:$0xff] /*vst_source=*/%v122299_v62 (stack38)
        %s156819_s26 = sshrl.u32 %s122279_s10, 7 (stack28)
        %s112226_s6 = scalar_lea.vmem %s112224_s6, %s156819_s26 (stack35)
        %s156820_s11 = sshll.u32 %s157866_s11, 3 (stack32)
        %s388_s29 = scalar_lea.vmem %s156440_s5, %s156820_s11 (stack34)
        %v112227_v63 = vld [vmem:[%s112226_s6] ss:$0 sm:$0xff] (stack22)
        %407 = vbcast.lane.b32.xlu1 %v406_v61, 0 (stack24)
        %s390_s13 = scalar_lea.vmem %s388_s29, %s121604_s13 (stack35)
        %s156821_s6 = sor.u32 256, %s122288_s28 (stack33)
        %112231 = vbcast.lane.b32.xlu0 %v112227_v63, %s156821_s6 (stack36)
        %v391_v3 = vld [vmem:[%s390_s13] ss:$0 sm:$0xff] (stack22)
        %1380 = vbcast.lane.b32.xlu1 %v406_v61, 2 (stack24)
        %395 = vbcast.lane.b32.xlu0 %v391_v3, %s121610_s19 (stack36)
        %v122312_v4 = vpop.permute.xlu1 %56401 (stack39)
        %156822 = vst [vmem:[#allocation99_spill] sm:$0xff] /*vst_source=*/%v122312_v4 (stack38)
        %s156823_s17 = sshll.u32 %s157868_s17, 3 (stack32)
        %s4303_s26 = scalar_lea.vmem %s156440_s5, %s156823_s17 (stack34)
        %2354 = vbcast.lane.b32.xlu1 %v406_v61, 4 (stack24)
        %893 = vbcast.lane.b32.xlu0 %v406_v61, 1 (stack24)
        %s156824_s24 = sshrl.u32 %s121618_s24, 7 (stack28)
        %s4305_s29 = scalar_lea.vmem %s4303_s26, %s156824_s24 (stack35)
        %s156825_s16 = sshll.u32 %s157870_s16, 3 (stack32)
        %s11747_s17 = scalar_lea.vmem %s156440_s5, %s156825_s16 (stack34)
        %v122326_v5 = vpop.permute.xlu0 %52679 (stack39)
        %156826 = vst [vmem:[#allocation100_spill] sm:$0xff] /*vst_source=*/%v122326_v5 (stack38)
        %3328 = vbcast.lane.b32.xlu1 %v406_v61, 6 (stack24)
        %1867 = vbcast.lane.b32.xlu0 %v406_v61, 3 (stack24)
        %v4306_v6 = vld [vmem:[%s4305_s29] ss:$0 sm:$0xff] (stack22)
        %s156827_s20 = sshrl.u32 %s121637_s20, 7 (stack28)
        %s11749_s19 = scalar_lea.vmem %s11747_s17, %s156827_s20 (stack35)
        %s156828_s12 = sshll.u32 %s157874_s12, 3 (stack32)
        %s19191_s24 = scalar_lea.vmem %s156440_s5, %s156828_s12 (stack34)
        %s156829_s1 = sor.u32 256, %s121626_s1 (stack33)
        %4310 = vbcast.lane.b32.xlu1 %v4306_v6, %s156829_s1 (stack36)
        %s156830_s27 = sshll.u32 %s157872_s27, 3 (stack32)
        %s8025_s13 = scalar_lea.vmem %s156440_s5, %s156830_s27 (stack34)
        %2841 = vbcast.lane.b32.xlu0 %v406_v61, 5 (stack24)
        %s156831_s6 = sld [smem:[#allocation10_spill]] (stack21)
        %v11750_v7 = vld [vmem:[%s11749_s19] ss:$0 sm:$0xff] (stack22)
        %s156832_s15 = sshrl.u32 %s121677_s15, 7 (stack28)
        %s156833_s17 = sld [smem:[#allocation13_spill]] (stack21)
        %s19193_s20 = scalar_lea.vmem %s19191_s24, %s156832_s15 (stack35)
        %s156834_s23 = sshrl.u32 %s121657_s23, 7 (stack28)
        %s156835_s19 = sld [smem:[#allocation9_spill]] (stack21)
        %s8027_s12 = scalar_lea.vmem %s8025_s13, %s156834_s23 (stack35)
        %s156836_s9 = sshll.u32 %s157878_s9, 3 (stack32)
        %s156837_s24 = sld [smem:[#allocation15_spill]] (stack21)
        %s26635_s1 = scalar_lea.vmem %s156440_s5, %s156836_s9 (stack34)
        %s156838_s27 = sld [smem:[#allocation17_spill]] (stack21)
        %v122351_v8 = vpop.permute.xlu1 %63845 (stack39)
        %156839 = vst [vmem:[#allocation101_spill] sm:$0xff] /*vst_source=*/%v122351_v8 (stack38)
        %s156840_s0 = sor.u32 256, %s121646_s0 (stack33)
        %11754 = vbcast.lane.b32.xlu1 %v11750_v7, %s156840_s0 (stack36)
        %s156841_s8 = sshll.u32 %s157876_s8, 3 (stack32)
        %s156842_s13 = sld [smem:[#allocation8_spill]] (stack21)
        %s15469_s15 = scalar_lea.vmem %s156440_s5, %s156841_s8 (stack34)
        %s156843_s30 = sshll.u32 %s157880_s30, 3 (stack32)
        %s22913_s11 = scalar_lea.vmem %s156440_s5, %s156843_s30 (stack34)
        %s156844_s26 = sld [smem:[#allocation19_spill]] (stack21)
        %3815 = vbcast.lane.b32.xlu0 %v406_v61, 7 (stack24)
        %s156845_s0 = sld [smem:[#allocation82_spill]] (stack21)
        %v19194_v9 = vld [vmem:[%s19193_s20] ss:$0 sm:$0xff] (stack22)
        %s156846_s7 = sshll.u32 %s157882_s7, 3 (stack32)
        %s34079_s29 = scalar_lea.vmem %s156440_s5, %s156846_s7 (stack34)
        %s156847_s18 = sshll.u32 %s157884_s18, 3 (stack32)
        %s156848_s23 = sld [smem:[#allocation81_spill]] (stack21)
        %s30357_s9 = scalar_lea.vmem %s156440_s5, %s156847_s18 (stack34)
        %s156849_s7 = sld [smem:[#allocation86_spill]] (stack21)
        %v8028_v10 = vld [vmem:[%s8027_s12] ss:$0 sm:$0xff] (stack22)
        %s156850_s25 = sshrl.u32 %s121717_s25, 7 (stack28)
        %s156851_s12 = sld [smem:[#allocation85_spill]] (stack21)
        %s26637_s1 = scalar_lea.vmem %s26635_s1, %s156850_s25 (stack35)
        %s156852_s22 = sshll.u32 %s157886_s22, 3 (stack32)
        %s156853_s18 = sld [smem:[#allocation89_spill]] (stack21)
        %s41523_s16 = scalar_lea.vmem %s156440_s5, %s156852_s22 (stack34)
        %s156854_s6 = sshrl.u32 %s156831_s6, 7 (stack28)
        %s156855_s30 = sld [smem:[#allocation12_spill]] (stack21)
        %s15471_s15 = scalar_lea.vmem %s15469_s15, %s156854_s6 (stack35)
        %s156856_s17 = sshrl.u32 %s156833_s17, 7 (stack28)
        %s22915_s11 = scalar_lea.vmem %s22913_s11, %s156856_s17 (stack35)
        %s156857_s19 = sor.u32 256, %s156835_s19 (stack33)
        %s156858_s25 = sld [smem:[#allocation93_spill]] (stack21)
        %19198 = vbcast.lane.b32.xlu1 %v19194_v9, %s156857_s19 (stack36)
        %s156859_s24 = sshrl.u32 %s156837_s24, 7 (stack28)
        %s156860_s22 = sld [smem:[#allocation11_spill]] (stack21)
        %s34081_s29 = scalar_lea.vmem %s34079_s29, %s156859_s24 (stack35)
        %s156861_s27 = sshrl.u32 %s156838_s27, 7 (stack28)
        %s30359_s9 = scalar_lea.vmem %s30357_s9, %s156861_s27 (stack35)
        %s156862_s20 = sld [smem:[#allocation92_spill]] (stack21)
        %v122392_v11 = vpop.permute.xlu0 %60123 (stack39)
        %156863 = vst [vmem:[#allocation102_spill] sm:$0xff] /*vst_source=*/%v122392_v11 (stack38)
        %s156864_s13 = sor.u32 256, %s156842_s13 (stack33)
        %s156865_s8 = sld [smem:[#allocation96_spill]] (stack21)
        %8032 = vbcast.lane.b32.xlu0 %v8028_v10, %s156864_s13 (stack36)
        %v26638_v12 = vld [vmem:[%s26637_s1] ss:$0 sm:$0xff] (stack22)
        %s156866_s26 = sshrl.u32 %s156844_s26, 7 (stack28)
        %s41525_s1 = scalar_lea.vmem %s41523_s16, %s156866_s26 (stack35)
        %s156867_s0 = sshll.u32 %s156845_s0, 3 (stack32)
        %s101075_s17 = scalar_lea.vmem %s156440_s5, %s156867_s0 (stack34)
        %s156868_s19 = sld [smem:[#allocation25_spill]] (stack21)
        %v15472_v13 = vld [vmem:[%s15471_s15] ss:$0 sm:$0xff] (stack22)
        %s156869_s23 = sshrl.u32 %s156848_s23, 7 (stack28)
        %s122405_s15 = scalar_lea.vmem %s101075_s17, %s156869_s23 (stack35)
        %s156870_s7 = sshll.u32 %s156849_s7, 3 (stack32)
        %s97353_s13 = scalar_lea.vmem %s156440_s5, %s156870_s7 (stack34)
        %s156871_s12 = sshrl.u32 %s156851_s12, 7 (stack28)
        %s156872_s26 = sld [smem:[#allocation16_spill]] (stack21)
        %s122414_s0 = scalar_lea.vmem %s97353_s13, %s156871_s12 (stack35)
        %s156873_s18 = sshll.u32 %s156853_s18, 3 (stack32)
        %s156874_s17 = sld [smem:[#allocation22_spill]] (stack21)
        %s108519_s23 = scalar_lea.vmem %s156440_s5, %s156873_s18 (stack34)
        %s156875_s30 = sor.u32 256, %s156855_s30 (stack33)
        %26642 = vbcast.lane.b32.xlu1 %v26638_v12, %s156875_s30 (stack36)
        %s156876_s2 = sshrl.u32 %s122213_s2, 7 (stack28)
        %s156877_s7 = sld [smem:[#allocation14_spill]] (stack21)
        %s122425_s24 = scalar_lea.vmem %s108519_s23, %s156876_s2 (stack35)
        %s156878_s25 = sshll.u32 %s156858_s25, 3 (stack32)
        %s104797_s12 = scalar_lea.vmem %s156440_s5, %s156878_s25 (stack34)
        %s156879_s22 = sor.u32 256, %s156860_s22 (stack33)
        %15476 = vbcast.lane.b32.xlu0 %v15472_v13, %s156879_s22 (stack36)
        %s156880_s18 = sld [smem:[#allocation24_spill]] (stack21)
        %v34082_v14 = vld [vmem:[%s34081_s29] ss:$0 sm:$0xff] (stack22)
        %s156881_s29 = sshrl.u32 %s156862_s20, 7 (stack28)
        %s156882_s20 = sld [smem:[#allocation21_spill]] (stack21)
        %s122436_s16 = scalar_lea.vmem %s104797_s12, %s156881_s29 (stack35)
        %s156883_s8 = sshll.u32 %s156865_s8, 3 (stack32)
        %s156884_s30 = sld [smem:[#allocation31_spill]] (stack21)
        %s115963_s2 = scalar_lea.vmem %s156440_s5, %s156883_s8 (stack34)
        %s156885_s25 = sld [smem:[#allocation20_spill]] (stack21)
        %v22916_v15 = vld [vmem:[%s22915_s11] ss:$0 sm:$0xff] (stack22)
        %s156886_s14 = sshrl.u32 %s122257_s14, 7 (stack28)
        %s156887_s11 = sld [smem:[#allocation28_spill]] (stack21)
        %s122445_s27 = scalar_lea.vmem %s115963_s2, %s156886_s14 (stack35)
        %s156888_s21 = sshll.u32 %s157928_s21, 3 (stack32)
        %s156889_s22 = sld [smem:[#allocation18_spill]] (stack21)
        %s112241_s29 = scalar_lea.vmem %s156440_s5, %s156888_s21 (stack34)
        %s156890_s19 = sshll.u32 %s156868_s19, 3 (stack32)
        %s48967_s23 = scalar_lea.vmem %s156440_s5, %s156890_s19 (stack34)
        %s156891_s10 = sshrl.u32 %s122279_s10, 7 (stack28)
        %s122459_s2 = scalar_lea.vmem %s112241_s29, %s156891_s10 (stack35)
        %v122463_v16 = vadd.s32 %v122015_v31, %v121991_v28 (stack40)
        %s156892_s26 = sor.u32 256, %s156872_s26 (stack33)
        %s156893_s14 = sld [smem:[#allocation30_spill]] (stack21)
        %34086 = vbcast.lane.b32.xlu1 %v34082_v14, %s156892_s26 (stack36)
        %s156894_s17 = sshll.u32 %s156874_s17, 3 (stack32)
        %s156895_s12 = sld [smem:[#allocation27_spill]] (stack21)
        %s37801_s29 = scalar_lea.vmem %s156440_s5, %s156894_s17 (stack34)
        %s156896_s19 = sld [smem:[#allocation37_spill]] (stack21)
        %v122472_v17 = vpop.permute.xlu1 %71289 (stack39)
        %156897 = vst [vmem:[#allocation103_spill] sm:$0xff] /*vst_source=*/%v122472_v17 (stack38)
        %s156898_s7 = sor.u32 256, %s156877_s7 (stack33)
        %s156899_s8 = sld [smem:[#allocation26_spill]] (stack21)
        %22920 = vbcast.lane.b32.xlu0 %v22916_v15, %s156898_s7 (stack36)
        %s156900_s6 = sld [smem:[#allocation34_spill]] (stack21)
        %v41526_v18 = vld [vmem:[%s41525_s1] ss:$0 sm:$0xff] (stack22)
        %s156901_s1 = sld [smem:[#allocation23_spill]] (stack21)
        %v30360_v19 = vld [vmem:[%s30359_s9] ss:$0 sm:$0xff] (stack22)
        %s156902_s9 = sshrl.u32 %s156880_s18, 7 (stack28)
        %s48969_s18 = scalar_lea.vmem %s48967_s23, %s156902_s9 (stack35)
        %s156903_s20 = sshrl.u32 %s156882_s20, 7 (stack28)
        %s37803_s23 = scalar_lea.vmem %s37801_s29, %s156903_s20 (stack35)
        %s156904_s30 = sshll.u32 %s156884_s30, 3 (stack32)
        %s156905_s17 = sld [smem:[#allocation36_spill]] (stack21)
        %s56411_s21 = scalar_lea.vmem %s156440_s5, %s156904_s30 (stack34)
        %s156906_s25 = sor.u32 256, %s156885_s25 (stack33)
        %s156907_s13 = sld [smem:[#allocation33_spill]] (stack21)
        %41530 = vbcast.lane.b32.xlu1 %v41526_v18, %s156906_s25 (stack36)
        %s156908_s11 = sshll.u32 %s156887_s11, 3 (stack32)
        %s156909_s9 = sld [smem:[#allocation45_spill]] (stack21)
        %s45245_s20 = scalar_lea.vmem %s156440_s5, %s156908_s11 (stack34)
        %s156910_s22 = sor.u32 256, %s156889_s22 (stack33)
        %s156911_s30 = sld [smem:[#allocation32_spill]] (stack21)
        %30364 = vbcast.lane.b32.xlu0 %v30360_v19, %s156910_s22 (stack36)
        %s156912_s10 = sld [smem:[#allocation40_spill]] (stack21)
        %v48970_v20 = vld [vmem:[%s48969_s18] ss:$0 sm:$0xff] (stack22)
        %s156913_s18 = sld [smem:[#allocation29_spill]] (stack21)
        %v122494_v21 = vpop.permute.xlu0 %67567 (stack39)
        %156914 = vst [vmem:[#allocation104_spill] sm:$0xff] /*vst_source=*/%v122494_v21 (stack38)
        %v37804_v26 = vld [vmem:[%s37803_s23] ss:$0 sm:$0xff] (stack22)
        %s156915_s14 = sshrl.u32 %s156893_s14, 7 (stack28)
        %s56413_s23 = scalar_lea.vmem %s56411_s21, %s156915_s14 (stack35)
        %s156916_s12 = sshrl.u32 %s156895_s12, 7 (stack28)
        %s45247_s26 = scalar_lea.vmem %s45245_s20, %s156916_s12 (stack35)
        %s156917_s19 = sshll.u32 %s156896_s19, 3 (stack32)
        %s156918_s11 = sld [smem:[#allocation42_spill]] (stack21)
        %s63855_s29 = scalar_lea.vmem %s156440_s5, %s156917_s19 (stack34)
        %s156919_s8 = sor.u32 256, %s156899_s8 (stack33)
        %s156920_s7 = sld [smem:[#allocation39_spill]] (stack21)
        %48974 = vbcast.lane.b32.xlu1 %v48970_v20, %s156919_s8 (stack36)
        %s156921_s6 = sshll.u32 %s156900_s6, 3 (stack32)
        %s156922_s14 = sld [smem:[#allocation56_spill]] (stack21)
        %s52689_s12 = scalar_lea.vmem %s156440_s5, %s156921_s6 (stack34)
        %s156923_s1 = sor.u32 256, %s156901_s1 (stack33)
        %s156924_s19 = sld [smem:[#allocation38_spill]] (stack21)
        %37808 = vbcast.lane.b32.xlu0 %v37804_v26, %s156923_s1 (stack36)
        %s156925_s21 = sld [smem:[#allocation50_spill]] (stack21)
        %v56414_v32 = vld [vmem:[%s56413_s23] ss:$0 sm:$0xff] (stack22)
        %s156926_s23 = sld [smem:[#allocation35_spill]] (stack21)
        %v45248_v38 = vld [vmem:[%s45247_s26] ss:$0 sm:$0xff] (stack22)
        %s156927_s17 = sshrl.u32 %s156905_s17, 7 (stack28)
        %s63857_s26 = scalar_lea.vmem %s63855_s29, %s156927_s17 (stack35)
        %s156928_s13 = sshrl.u32 %s156907_s13, 7 (stack28)
        %s52691_s25 = scalar_lea.vmem %s52689_s12, %s156928_s13 (stack35)
        %s156929_s9 = sshll.u32 %s156909_s9, 3 (stack32)
        %s156930_s6 = sld [smem:[#allocation55_spill]] (stack21)
        %s71299_s20 = scalar_lea.vmem %s156440_s5, %s156929_s9 (stack34)
        %s156931_s30 = sor.u32 256, %s156911_s30 (stack33)
        %56418 = vbcast.lane.b32.xlu1 %v56414_v32, %s156931_s30 (stack36)
        %s156932_s10 = sshll.u32 %s156912_s10, 3 (stack32)
        %s156933_s1 = sld [smem:[#allocation49_spill]] (stack21)
        %s60133_s17 = scalar_lea.vmem %s156440_s5, %s156932_s10 (stack34)
        %s156934_s18 = sor.u32 256, %s156913_s18 (stack33)
        %s156935_s13 = sld [smem:[#allocation66_spill]] (stack21)
        %45252 = vbcast.lane.b32.xlu0 %v45248_v38, %s156934_s18 (stack36)
        %s156936_s9 = sld [smem:[#allocation46_spill]] (stack21)
        %v63858_v40 = vld [vmem:[%s63857_s26] ss:$0 sm:$0xff] (stack22)
        %s156937_s26 = sld [smem:[#allocation62_spill]] (stack21)
        %v122532_v43 = vpop.permute.xlu1 %78733 (stack39)
        %156938 = vst [vmem:[#allocation105_spill] sm:$0xff] /*vst_source=*/%v122532_v43 (stack38)
        %s156939_s29 = sld [smem:[#allocation41_spill]] (stack21)
        %v52692_v45 = vld [vmem:[%s52691_s25] ss:$0 sm:$0xff] (stack22)
        %s156940_s11 = sshrl.u32 %s156918_s11, 7 (stack28)
        %s71301_s25 = scalar_lea.vmem %s71299_s20, %s156940_s11 (stack35)
        %s156941_s7 = sshrl.u32 %s156920_s7, 7 (stack28)
        %s60135_s8 = scalar_lea.vmem %s60133_s17, %s156941_s7 (stack35)
        %s156942_s14 = sshll.u32 %s156922_s14, 3 (stack32)
        %s156943_s10 = sld [smem:[#allocation65_spill]] (stack21)
        %s78743_s22 = scalar_lea.vmem %s156440_s5, %s156942_s14 (stack34)
        %s156944_s19 = sor.u32 256, %s156924_s19 (stack33)
        %s156945_s12 = sld [smem:[#allocation60_spill]] (stack21)
        %63862 = vbcast.lane.b32.xlu1 %v63858_v40, %s156944_s19 (stack36)
        %s156946_s21 = sshll.u32 %s156925_s21, 3 (stack32)
        %s156947_s11 = sld [smem:[#allocation74_spill]] (stack21)
        %s67577_s7 = scalar_lea.vmem %s156440_s5, %s156946_s21 (stack34)
        %s156948_s23 = sor.u32 256, %s156926_s23 (stack33)
        %s156949_s14 = sld [smem:[#allocation59_spill]] (stack21)
        %52696 = vbcast.lane.b32.xlu0 %v52692_v45, %s156948_s23 (stack36)
        %s156950_s20 = sld [smem:[#allocation70_spill]] (stack21)
        %v71302_v47 = vld [vmem:[%s71301_s25] ss:$0 sm:$0xff] (stack22)
        %s156951_s25 = sld [smem:[#allocation52_spill]] (stack21)
        %v60136_v49 = vld [vmem:[%s60135_s8] ss:$0 sm:$0xff] (stack22)
        %s156952_s6 = sshrl.u32 %s156930_s6, 7 (stack28)
        %s78745_s8 = scalar_lea.vmem %s78743_s22, %s156952_s6 (stack35)
        %v122554_v52 = vpop.permute.xlu0 %75011 (stack39)
        %156953 = vst [vmem:[#allocation106_spill] sm:$0xff] /*vst_source=*/%v122554_v52 (stack38)
        %s156954_s1 = sshrl.u32 %s156933_s1, 7 (stack28)
        %s156955_s30 = sld [smem:[#allocation73_spill]] (stack21)
        %s67579_s22 = scalar_lea.vmem %s67577_s7, %s156954_s1 (stack35)
        %s156956_s13 = sshll.u32 %s156935_s13, 3 (stack32)
        %s86187_s17 = scalar_lea.vmem %s156440_s5, %s156956_s13 (stack34)
        %s156957_s9 = sor.u32 256, %s156936_s9 (stack33)
        %s156958_s18 = sld [smem:[#allocation69_spill]] (stack21)
        %71306 = vbcast.lane.b32.xlu1 %v71302_v47, %s156957_s9 (stack36)
        %s156959_s26 = sshll.u32 %s156937_s26, 3 (stack32)
        %s156960_s6 = sld [smem:[#allocation67_spill]] (stack21)
        %s75021_s1 = scalar_lea.vmem %s156440_s5, %s156959_s26 (stack34)
        %s156961_s29 = sor.u32 256, %s156939_s29 (stack33)
        %s156962_s13 = sld [smem:[#allocation78_spill]] (stack21)
        %60140 = vbcast.lane.b32.xlu0 %v60136_v49, %s156961_s29 (stack36)
        %s156963_s19 = sld [smem:[#allocation63_spill]] (stack21)
        %v78746_v54 = vld [vmem:[%s78745_s8] ss:$0 sm:$0xff] (stack22)
        %v67580_v56 = vld [vmem:[%s67579_s22] ss:$0 sm:$0xff] (stack22)
        %s156964_s10 = sshrl.u32 %s156943_s10, 7 (stack28)
        %s86189_s8 = scalar_lea.vmem %s86187_s17, %s156964_s10 (stack35)
        %s156965_s12 = sshrl.u32 %s156945_s12, 7 (stack28)
        %s156966_s22 = sld [smem:[#allocation77_spill]] (stack21)
        %s75023_s21 = scalar_lea.vmem %s75021_s1, %s156965_s12 (stack35)
        %s156967_s11 = sshll.u32 %s156947_s11, 3 (stack32)
        %s93631_s26 = scalar_lea.vmem %s156440_s5, %s156967_s11 (stack34)
        %s156968_s14 = sor.u32 256, %s156949_s14 (stack33)
        %s156969_s7 = sld [smem:[#allocation75_spill]] (stack21)
        %78750 = vbcast.lane.b32.xlu1 %v78746_v54, %s156968_s14 (stack36)
        %s156970_s20 = sshll.u32 %s156950_s20, 3 (stack32)
        %s156971_s29 = sld [smem:[#allocation71_spill]] (stack21)
        %s82465_s10 = scalar_lea.vmem %s156440_s5, %s156970_s20 (stack34)
        %s156972_s25 = sor.u32 256, %s156951_s25 (stack33)
        %67584 = vbcast.lane.b32.xlu0 %v67580_v56, %s156972_s25 (stack36)
        %v86190_v58 = vld [vmem:[%s86189_s8] ss:$0 sm:$0xff] (stack22)
        %s156973_s8 = sld [smem:[#allocation83_spill]] (stack21)
        %v75024_v60 = vld [vmem:[%s75023_s21] ss:$0 sm:$0xff] (stack22)
        %s156974_s30 = sshrl.u32 %s156955_s30, 7 (stack28)
        %s156975_s12 = sld [smem:[#allocation79_spill]] (stack21)
        %s93633_s21 = scalar_lea.vmem %s93631_s26, %s156974_s30 (stack35)
        %v122592_v61 = vpop.permute.xlu1 %86177 (stack39)
        %156976 = vst [vmem:[#allocation107_spill] sm:$0xff] /*vst_source=*/%v122592_v61 (stack38)
        %s156977_s18 = sshrl.u32 %s156958_s18, 7 (stack28)
        %s82467_s11 = scalar_lea.vmem %s82465_s10, %s156977_s18 (stack35)
        %s156978_s6 = sor.u32 256, %s156960_s6 (stack33)
        %86194 = vbcast.lane.b32.xlu1 %v86190_v58, %s156978_s6 (stack36)
        %s156979_s13 = sshll.u32 %s156962_s13, 3 (stack32)
        %s156980_s26 = sld [smem:[#allocation90_spill]] (stack21)
        %s89909_s14 = scalar_lea.vmem %s156440_s5, %s156979_s13 (stack34)
        %s156981_s19 = sor.u32 256, %s156963_s19 (stack33)
        %75028 = vbcast.lane.b32.xlu0 %v75024_v60, %s156981_s19 (stack36)
        %s156982_s20 = sld [smem:[#allocation87_spill]] (stack21)
        %v93634_v63 = vld [vmem:[%s93633_s21] ss:$0 sm:$0xff] (stack22)
        %v82468_v3 = vld [vmem:[%s82467_s11] ss:$0 sm:$0xff] (stack22)
        %s156983_s22 = sshrl.u32 %s156966_s22, 7 (stack28)
        %s89911_s23 = scalar_lea.vmem %s89909_s14, %s156983_s22 (stack35)
        %v122607_v6 = vpop.permute.xlu0 %82455 (stack39)
        %156984 = vst [vmem:[#allocation108_spill] sm:$0xff] /*vst_source=*/%v122607_v6 (stack38)
        %s156985_s7 = sor.u32 256, %s156969_s7 (stack33)
        %93638 = vbcast.lane.b32.xlu1 %v93634_v63, %s156985_s7 (stack36)
        %s156986_s1 = sor.u32 256, %s156971_s29 (stack33)
        %s156987_s29 = sld [smem:[#allocation94_spill]] (stack21)
        %82472 = vbcast.lane.b32.xlu0 %v82468_v3, %s156986_s1 (stack36)
        %v101078_v7 = vld [vmem:[%s122405_s15] ss:$0 sm:$0xff] (stack22)
        %v89912_v9 = vld [vmem:[%s89911_s23] ss:$0 sm:$0xff] (stack22)
        %s156988_s15 = sor.u32 256, %s156973_s8 (stack33)
        %101082 = vbcast.lane.b32.xlu1 %v101078_v7, %s156988_s15 (stack36)
        %s156989_s10 = sor.u32 256, %s156975_s12 (stack33)
        %89916 = vbcast.lane.b32.xlu0 %v89912_v9, %s156989_s10 (stack36)
        %v108522_v10 = vld [vmem:[%s122425_s24] ss:$0 sm:$0xff] (stack22)
        %v97356_v12 = vld [vmem:[%s122414_s0] ss:$0 sm:$0xff] (stack22)
        %v122620_v13 = vpop.permute.xlu1 %93621 (stack39)
        %156990 = vst [vmem:[#allocation109_spill] sm:$0xff] /*vst_source=*/%v122620_v13 (stack38)
        %s156991_s0 = sor.u32 256, %s156980_s26 (stack33)
        %108526 = vbcast.lane.b32.xlu1 %v108522_v10, %s156991_s0 (stack36)
        %v122626_v14 = vadd.s32 %v122013_v30, %v121991_v28 (stack40)
        %s156992_s24 = sor.u32 256, %s156982_s20 (stack33)
        %97360 = vbcast.lane.b32.xlu0 %v97356_v12, %s156992_s24 (stack36)
        %v115966_v15 = vld [vmem:[%s122445_s27] ss:$0 sm:$0xff] (stack22)
        %v104800_v18 = vld [vmem:[%s122436_s16] ss:$0 sm:$0xff] (stack22)
        %s156993_s4 = sor.u32 256, %s122266_s4 (stack33)
        %115970 = vbcast.lane.b32.xlu1 %v115966_v15, %s156993_s4 (stack36)
        %v122634_v19 = vpop.permute.xlu0 %89899 (stack39)
        %156994 = vst [vmem:[#allocation110_spill] sm:$0xff] /*vst_source=*/%v122634_v19 (stack38)
        %s156995_s16 = sor.u32 256, %s156987_s29 (stack33)
        %104804 = vbcast.lane.b32.xlu0 %v104800_v18, %s156995_s16 (stack36)
        %v112244_v20 = vld [vmem:[%s122459_s2] ss:$0 sm:$0xff] (stack22)
        %s156996_s28 = sor.u32 256, %s122288_s28 (stack33)
        %112248 = vbcast.lane.b32.xlu0 %v112244_v20, %s156996_s28 (stack36)
        %v122641_v26 = vpop.permute.xlu1 %101065 (stack39)
        %156997 = vst [vmem:[#allocation111_spill] sm:$0xff] /*vst_source=*/%v122641_v26 (stack38)
        %v122643_v32 = vpop.permute.xlu0 %97343 (stack39)
        %156998 = vst [vmem:[#allocation112_spill] sm:$0xff] /*vst_source=*/%v122643_v32 (stack38)
        %v122645_v38 = vpop.permute.xlu1 %108509 (stack39)
        %156999 = vst [vmem:[#allocation113_spill] sm:$0xff] /*vst_source=*/%v122645_v38 (stack38)
        %v122647_v40 = vpop.permute.xlu0 %104787 (stack39)
        %157000 = vst [vmem:[#allocation114_spill] sm:$0xff] /*vst_source=*/%v122647_v40 (stack38)
        %v122649_v45 = vpop.permute.xlu1 %115953 (stack39)
        %157001 = vst [vmem:[#allocation115_spill] sm:$0xff] /*vst_source=*/%v122649_v45 (stack38)
        %v122651_v47 = vpop.permute.xlu1 %407 (stack37)
        %v414_v49 = vlaneseq (stack41)
        %v122653_v54 = vpop.permute.xlu0 %112231 (stack39)
        %157002 = vst [vmem:[#allocation116_spill] sm:$0xff] /*vst_source=*/%v122653_v54 (stack38)
        %v122655_v56 = vpop.permute.xlu1 %1380 (stack37)
        %157003 = vst [vmem:[#allocation117_spill] sm:$0xff] /*vst_source=*/%v122655_v56 (stack38)
        %v122657_v58 = vand.u32 127, %v414_v49 (stack42)
        %v122659_v60 = vpop.permute.xlu0 %395 (stack39)
        %v411_v63 = vadd.s32 %v122651_v47, %v122659_v60 (stack40)
        %v1384_v3 = vadd.s32 %v122655_v56, %v122659_v60 (stack40)
        %v439_v7 = vadd.s32 1, %v122008_v29 (stack40)
        %v925_v9 = vadd.s32 1, %v122026_v33 (stack40)
        %v1412_v10 = vadd.s32 1, %v122051_v37 (stack40)
        %v1899_v12 = vadd.s32 1, %v122080_v41 (stack40)
        %v122669_v15 = vpop.permute.xlu1 %2354 (stack37)
        %157004 = vst [vmem:[#allocation118_spill] sm:$0xff] /*vst_source=*/%v122669_v15 (stack38)
        %v421_v18 = vadd.s32 %v122657_v58, %v411_v63 (stack40)
        %vm430_vm0 = vcmp.lt.u32.totalorder %v411_v63, %v122651_v47 (stack43)
        %v1394_v20 = vadd.s32 %v1384_v3, %v122657_v58 (stack40)
        %vm1403_vm1 = vcmp.lt.u32.totalorder %v1384_v3, %v122655_v56 (stack43)
        %v122675_v49 = vpop.permute.xlu0 %893 (stack37)
        %157005 = vst [vmem:[#allocation119_spill] sm:$0xff] /*vst_source=*/%v122675_v49 (stack38)
        %v443_v29 = vsel /*vm=*/%vm430_vm0, /*on_true_vy=*/%v439_v7, /*on_false_vx=*/%v122008_v29 (stack44)
        %v1416_v37 = vsel /*vm=*/%vm1403_vm1, /*on_true_vy=*/%v1412_v10, /*on_false_vx=*/%v122051_v37 (stack44)
        %v122681_v7 = vadd.s32 %v122669_v15, %v122659_v60 (stack40)
        %v122684_v10 = vadd.s32 1, %v122172_v50 (stack40)
        %vm425_vm2 = vcmp.lt.u32.totalorder %v421_v18, %v411_v63 (stack43)
        %v447_v63 = vadd.s32 1, %v443_v29 (stack40)
        %v460_v18 = vadd.s32 %v421_v18, %v121569_v1 (stack40)
        %v897_v45 = vadd.s32 %v122675_v49, %v122659_v60 (stack40)
        %vm1398_vm3 = vcmp.lt.u32.totalorder %v1394_v20, %v1384_v3 (stack43)
        %v1420_v3 = vadd.s32 1, %v1416_v37 (stack40)
        %v1433_v20 = vadd.s32 %v1394_v20, %v121569_v1 (stack40)
        %v122691_v54 = vadd.s32 1, %v122463_v16 (stack40)
        %v122693_v38 = vpop.permute.xlu1 %3328 (stack37)
        %157006 = vst [vmem:[#allocation120_spill] sm:$0xff] /*vst_source=*/%v122693_v38 (stack38)
        %v451_v29 = vsel /*vm=*/%vm425_vm2, /*on_true_vy=*/%v447_v63, /*on_false_vx=*/%v443_v29 (stack44)
        %v466_v63 = vshll.u32 %v460_v18, 13 (stack45)
        %v467_v40 = vshrl.u32 %v460_v18, 19 (stack46)
        %v907_v26 = vadd.s32 %v897_v45, %v122657_v58 (stack40)
        %v122696_v32 = vpop.permute.xlu0 %1867 (stack37)
        %157007 = vst [vmem:[#allocation121_spill] sm:$0xff] /*vst_source=*/%v122696_v32 (stack38)
        %v456_v29 = vadd.s32 %v451_v29, %v121574_v2 (stack40)
        %vm916_vm4 = vcmp.lt.u32.totalorder %v897_v45, %v122675_v49 (stack43)
        %v1424_v37 = vsel /*vm=*/%vm1398_vm3, /*on_true_vy=*/%v1420_v3, /*on_false_vx=*/%v1416_v37 (stack44)
        %v1439_v3 = vshll.u32 %v1433_v20, 13 (stack45)
        %v468_v40 = vor.u32 %v467_v40, %v466_v63 (stack47)
        %vm911_vm5 = vcmp.lt.u32.totalorder %v907_v26, %v897_v45 (stack43)
        %v929_v33 = vsel /*vm=*/%vm916_vm4, /*on_true_vy=*/%v925_v9, /*on_false_vx=*/%v122026_v33 (stack44)
        %v946_v26 = vadd.s32 %v907_v26, %v121569_v1 (stack40)
        %v464_v45 = vadd.s32 %v460_v18, %v456_v29 (stack40)
        %v933_v9 = vadd.s32 1, %v929_v33 (stack40)
        %v1429_v18 = vadd.s32 %v1424_v37, %v121574_v2 (stack40)
        %v1440_v63 = vshrl.u32 %v1433_v20, 19 (stack46)
        %v122703_v29 = vpop.permute.xlu1 %4310 (stack39)
        %v952_v37 = vshll.u32 %v946_v26, 13 (stack45)
        %v953_v13 = vshrl.u32 %v946_v26, 19 (stack46)
        %v1871_v19 = vadd.s32 %v122696_v32, %v122659_v60 (stack40)
        %v122709_v61 = vadd.s32 %v122681_v7, %v122657_v58 (stack40)
        %v122711_v6 = vpop.permute.xlu0 %2841 (stack37)
        %157008 = vst [vmem:[#allocation122_spill] sm:$0xff] /*vst_source=*/%v122711_v6 (stack38)
        %v469_v40 = vxor.u32 %v468_v40, %v464_v45 (stack48)
        %v937_v33 = vsel /*vm=*/%vm911_vm5, /*on_true_vy=*/%v933_v9, /*on_false_vx=*/%v929_v33 (stack44)
        %v1437_v20 = vadd.s32 %v1433_v20, %v1429_v18 (stack40)
        %v1441_v3 = vor.u32 %v1440_v63, %v1439_v3 (stack47)
        %v942_v9 = vadd.s32 %v937_v33, %v121574_v2 (stack40)
        %v954_v13 = vor.u32 %v953_v13, %v952_v37 (stack47)
        %v1881_v18 = vadd.s32 %v1871_v19, %v122657_v58 (stack40)
        %vm1890_vm6 = vcmp.lt.u32.totalorder %v1871_v19, %v122696_v32 (stack43)
        %v472_v45 = vadd.s32 %v469_v40, %v464_v45 (stack40)
        %v474_v63 = vshll.u32 %v469_v40, 15 (stack45)
        %v475_v37 = vshrl.u32 %v469_v40, 17 (stack46)
        %v1442_v40 = vxor.u32 %v1441_v3, %v1437_v20 (stack48)
        %v122716_v33 = vpop.permute.xlu1 %11754 (stack39)
        %157009 = vst [vmem:[#allocation123_spill] sm:$0xff] /*vst_source=*/%v122716_v33 (stack38)
        %v950_v26 = vadd.s32 %v946_v26, %v942_v9 (stack40)
        %vm1885_vm7 = vcmp.lt.u32.totalorder %v1881_v18, %v1871_v19 (stack43)
        %v1903_v41 = vsel /*vm=*/%vm1890_vm6, /*on_true_vy=*/%v1899_v12, /*on_false_vx=*/%v122080_v41 (stack44)
        %v1920_v12 = vadd.s32 %v1881_v18, %v121569_v1 (stack40)
        %v122720_v3 = vpop.permute.xlu0 %3815 (stack37)
        %157010 = vst [vmem:[#allocation124_spill] sm:$0xff] /*vst_source=*/%v122720_v3 (stack38)
        %v476_v9 = vor.u32 %v475_v37, %v474_v63 (stack47)
        %v1445_v20 = vadd.s32 %v1442_v40, %v1437_v20 (stack40)
        %v1447_v63 = vshll.u32 %v1442_v40, 15 (stack45)
        %v1448_v37 = vshrl.u32 %v1442_v40, 17 (stack46)
        %v955_v13 = vxor.u32 %v954_v13, %v950_v26 (stack48)
        %v1907_v40 = vadd.s32 1, %v1903_v41 (stack40)
        %v1926_v43 = vshll.u32 %v1920_v12, 13 (stack45)
        %v1927_v52 = vshrl.u32 %v1920_v12, 19 (stack46)
        %v477_v9 = vxor.u32 %v476_v9, %v472_v45 (stack48)
        %v1449_v63 = vor.u32 %v1448_v37, %v1447_v63 (stack47)
        %vm2372_vm8 = vcmp.lt.u32.totalorder %v122709_v61, %v122681_v7 (stack43)
        %vm2377_vm9 = vcmp.lt.u32.totalorder %v122681_v7, %v122669_v15 (stack43)
        %v122728_v37 = vadd.s32 %v122709_v61, %v121569_v1 (stack40)
        %v122730_v17 = vpop.permute.xlu1 %19198 (stack39)
        %157011 = vst [vmem:[#allocation125_spill] sm:$0xff] /*vst_source=*/%v122730_v17 (stack38)
        %v958_v26 = vadd.s32 %v955_v13, %v950_v26 (stack40)
        %v960_v21 = vshll.u32 %v955_v13, 15 (stack45)
        %v961_v13 = vshrl.u32 %v955_v13, 17 (stack46)
        %v1911_v19 = vsel /*vm=*/%vm1885_vm7, /*on_true_vy=*/%v1907_v40, /*on_false_vx=*/%v1903_v41 (stack44)
        %v122733_v18 = vpop.permute.xlu0 %8032 (stack39)
        %157012 = vst [vmem:[#allocation126_spill] sm:$0xff] /*vst_source=*/%v122733_v18 (stack38)
        %v480_v45 = vadd.s32 %v477_v9, %v472_v45 (stack40)
        %v482_v41 = vshll.u32 %v477_v9, 26 (stack45)
        %v483_v40 = vshrl.u32 %v477_v9, 6 (stack46)
        %v1450_v9 = vxor.u32 %v1449_v63, %v1445_v20 (stack48)
        %v962_v21 = vor.u32 %v961_v13, %v960_v21 (stack47)
        %v1916_v63 = vadd.s32 %v1911_v19, %v121574_v2 (stack40)
        %v1928_v43 = vor.u32 %v1927_v52, %v1926_v43 (stack47)
        %v2390_v50 = vsel /*vm=*/%vm2377_vm9, /*on_true_vy=*/%v122684_v10, /*on_false_vx=*/%v122172_v50 (stack44)
        %v484_v52 = vor.u32 %v483_v40, %v482_v41 (stack47)
        %v1453_v10 = vadd.s32 %v1450_v9, %v1445_v20 (stack40)
        %v1455_v20 = vshll.u32 %v1450_v9, 26 (stack45)
        %v1456_v13 = vshrl.u32 %v1450_v9, 6 (stack46)
        %v122738_v19 = vpop.permute.xlu1 %26642 (stack39)
        %157013 = vst [vmem:[#allocation127_spill] sm:$0xff] /*vst_source=*/%v122738_v19 (stack38)
        %v963_v41 = vxor.u32 %v962_v21, %v958_v26 (stack48)
        %v1924_v12 = vadd.s32 %v1920_v12, %v1916_v63 (stack40)
        %v2394_v40 = vadd.s32 1, %v2390_v50 (stack40)
        %v2413_v9 = vshll.u32 %v122728_v37, 13 (stack45)
        %v122741_v21 = vpop.permute.xlu0 %15476 (stack39)
        %157014 = vst [vmem:[#allocation128_spill] sm:$0xff] /*vst_source=*/%v122741_v21 (stack38)
        %v485_v63 = vxor.u32 %v484_v52, %v480_v45 (stack48)
        %v1457_v52 = vor.u32 %v1456_v13, %v1455_v20 (stack47)
        %v2414_v20 = vshrl.u32 %v122728_v37, 19 (stack46)
        %v122746_v13 = vadd.s32 %v122711_v6, %v122659_v60 (stack40)
        %v966_v26 = vadd.s32 %v963_v41, %v958_v26 (stack40)
        %v968_v8 = vshll.u32 %v963_v41, 26 (stack45)
        %v969_v41 = vshrl.u32 %v963_v41, 6 (stack46)
        %v1929_v43 = vxor.u32 %v1928_v43, %v1924_v12 (stack48)
        %v488_v45 = vadd.s32 %v485_v63, %v480_v45 (stack40)
        %v494_v11 = vshll.u32 %v485_v63, 6 (stack45)
        %v495_v63 = vshrl.u32 %v485_v63, 26 (stack46)
        %v1458_v52 = vxor.u32 %v1457_v52, %v1453_v10 (stack48)
        %v122748_v4 = vpop.permute.xlu1 %34086 (stack39)
        %157015 = vst [vmem:[#allocation129_spill] sm:$0xff] /*vst_source=*/%v122748_v4 (stack38)
        %v970_v8 = vor.u32 %v969_v41, %v968_v8 (stack47)
        %v1932_v12 = vadd.s32 %v1929_v43, %v1924_v12 (stack40)
        %v1934_v41 = vshll.u32 %v1929_v43, 15 (stack45)
        %v1935_v43 = vshrl.u32 %v1929_v43, 17 (stack46)
        %v122750_v5 = vpop.permute.xlu0 %22920 (stack39)
        %157016 = vst [vmem:[#allocation130_spill] sm:$0xff] /*vst_source=*/%v122750_v5 (stack38)
        %v492_v59 = vadd.s32 %v488_v45, %v121569_v1 (stack40)
        %v496_v11 = vor.u32 %v495_v63, %v494_v11 (stack47)
        %v1461_v10 = vadd.s32 %v1458_v52, %v1453_v10 (stack40)
        %v1467_v63 = vshll.u32 %v1458_v52, 6 (stack45)
        %v971_v8 = vxor.u32 %v970_v8, %v966_v26 (stack48)
        %v1468_v52 = vshrl.u32 %v1458_v52, 26 (stack46)
        %v1936_v41 = vor.u32 %v1935_v43, %v1934_v41 (stack47)
        %v2398_v61 = vsel /*vm=*/%vm2372_vm8, /*on_true_vy=*/%v2394_v40, /*on_false_vx=*/%v2390_v50 (stack44)
        %v497_v7 = vxor.u32 %v496_v11, %v488_v45 (stack48)
        %v1465_v50 = vadd.s32 %v1461_v10, %v121569_v1 (stack40)
        %v2403_v40 = vadd.s32 %v2398_v61, %v121574_v2 (stack40)
        %v2415_v9 = vor.u32 %v2414_v20, %v2413_v9 (stack47)
        %v122758_v20 = vpop.permute.xlu1 %41530 (stack39)
        %157017 = vst [vmem:[#allocation131_spill] sm:$0xff] /*vst_source=*/%v122758_v20 (stack38)
        %v974_v26 = vadd.s32 %v971_v8, %v966_v26 (stack40)
        %v980_v45 = vshll.u32 %v971_v8, 6 (stack45)
        %v981_v43 = vshrl.u32 %v971_v8, 26 (stack46)
        %v1469_v11 = vor.u32 %v1468_v52, %v1467_v63 (stack47)
        %v122760_v63 = vpop.permute.xlu0 %30364 (stack39)
        %157018 = vst [vmem:[#allocation132_spill] sm:$0xff] /*vst_source=*/%v122760_v63 (stack38)
        %v500_v8 = vadd.s32 %v497_v7, %v121564_v0 (stack40)
        %v1937_v52 = vxor.u32 %v1936_v41, %v1932_v12 (stack48)
        %v2411_v37 = vadd.s32 %v122728_v37, %v2403_v40 (stack40)
        %v122766_v41 = vadd.s32 %v122746_v13, %v122657_v58 (stack40)
        %v978_v61 = vadd.s32 %v974_v26, %v121569_v1 (stack40)
        %v982_v7 = vor.u32 %v981_v43, %v980_v45 (stack47)
        %v1470_v10 = vxor.u32 %v1469_v11, %v1461_v10 (stack48)
        %vm2864_vm10 = vcmp.lt.u32.totalorder %v122746_v13, %v122711_v6 (stack43)
        %v504_v40 = vadd.s32 1, %v500_v8 (stack40)
        %v1940_v12 = vadd.s32 %v1937_v52, %v1932_v12 (stack40)
        %v1942_v45 = vshll.u32 %v1937_v52, 26 (stack45)
        %v1943_v43 = vshrl.u32 %v1937_v52, 6 (stack46)
        %v122771_v11 = vpop.permute.xlu1 %48974 (stack39)
        %157019 = vst [vmem:[#allocation133_spill] sm:$0xff] /*vst_source=*/%v122771_v11 (stack38)
        %v983_v26 = vxor.u32 %v982_v7, %v974_v26 (stack48)
        %v1473_v8 = vadd.s32 %v1470_v10, %v121564_v0 (stack40)
        %v2416_v9 = vxor.u32 %v2415_v9, %v2411_v37 (stack48)
        %vm2859_vm11 = vcmp.lt.u32.totalorder %v122766_v41, %v122746_v13 (stack43)
        %v122776_v52 = vpop.permute.xlu0 %37808 (stack39)
        %157020 = vst [vmem:[#allocation134_spill] sm:$0xff] /*vst_source=*/%v122776_v52 (stack38)
        %v508_v59 = vadd.s32 %v504_v40, %v492_v59 (stack40)
        %v510_v7 = vshll.u32 %v504_v40, 17 (stack45)
        %v511_v10 = vshrl.u32 %v504_v40, 15 (stack46)
        %v1944_v40 = vor.u32 %v1943_v43, %v1942_v45 (stack47)
        %v986_v45 = vadd.s32 %v983_v26, %v121564_v0 (stack40)
        %v1477_v43 = vadd.s32 1, %v1473_v8 (stack40)
        %v2419_v37 = vadd.s32 %v2416_v9, %v2411_v37 (stack40)
        %v2421_v26 = vshll.u32 %v2416_v9, 15 (stack45)
        %v512_v8 = vor.u32 %v511_v10, %v510_v7 (stack47)
        %v1945_v7 = vxor.u32 %v1944_v40, %v1940_v12 (stack48)
        %v2422_v9 = vshrl.u32 %v2416_v9, 17 (stack46)
        %v2877_v16 = vsel /*vm=*/%vm2864_vm10, /*on_true_vy=*/%v122691_v54, /*on_false_vx=*/%v122463_v16 (stack44)
        %v122784_v54 = vpop.permute.xlu1 %56418 (stack39)
        %157021 = vst [vmem:[#allocation135_spill] sm:$0xff] /*vst_source=*/%v122784_v54 (stack38)
        %v990_v10 = vadd.s32 1, %v986_v45 (stack40)
        %v1481_v50 = vadd.s32 %v1477_v43, %v1465_v50 (stack40)
        %v1483_v40 = vshll.u32 %v1477_v43, 17 (stack45)
        %v1484_v45 = vshrl.u32 %v1477_v43, 15 (stack46)
        %v122786_v43 = vpop.permute.xlu0 %45252 (stack39)
        %157022 = vst [vmem:[#allocation136_spill] sm:$0xff] /*vst_source=*/%v122786_v43 (stack38)
        %v513_v8 = vxor.u32 %v512_v8, %v508_v59 (stack48)
        %v1948_v12 = vadd.s32 %v1945_v7, %v1940_v12 (stack40)
        %v1954_v54 = vshll.u32 %v1945_v7, 6 (stack45)
        %v1955_v7 = vshrl.u32 %v1945_v7, 26 (stack46)
        %v994_v61 = vadd.s32 %v990_v10, %v978_v61 (stack40)
        %v996_v11 = vshll.u32 %v990_v10, 17 (stack45)
        %v997_v10 = vshrl.u32 %v990_v10, 15 (stack46)
        %v1485_v40 = vor.u32 %v1484_v45, %v1483_v40 (stack47)
        %v516_v59 = vadd.s32 %v513_v8, %v508_v59 (stack40)
        %v518_v45 = vshll.u32 %v513_v8, 29 (stack45)
        %v519_v8 = vshrl.u32 %v513_v8, 3 (stack46)
        %v1952_v62 = vadd.s32 %v1948_v12, %v121569_v1 (stack40)
        %v122789_v43 = vpop.permute.xlu1 %63862 (stack39)
        %157023 = vst [vmem:[#allocation137_spill] sm:$0xff] /*vst_source=*/%v122789_v43 (stack38)
        %v998_v11 = vor.u32 %v997_v10, %v996_v11 (stack47)
        %v1486_v10 = vxor.u32 %v1485_v40, %v1481_v50 (stack48)
        %v1956_v54 = vor.u32 %v1955_v7, %v1954_v54 (stack47)
        %v2423_v26 = vor.u32 %v2422_v9, %v2421_v26 (stack47)
        %v122791_v9 = vpop.permute.xlu0 %52696 (stack39)
        %157024 = vst [vmem:[#allocation138_spill] sm:$0xff] /*vst_source=*/%v122791_v9 (stack38)
        %v520_v7 = vor.u32 %v519_v8, %v518_v45 (stack47)
        %v2881_v40 = vadd.s32 1, %v2877_v16 (stack40)
        %v122795_v45 = vadd.s32 %v122766_v41, %v121569_v1 (stack40)
        %v122799_v8 = vadd.s32 %v122693_v38, %v122659_v60 (stack40)
        %v999_v11 = vxor.u32 %v998_v11, %v994_v61 (stack48)
        %v1489_v50 = vadd.s32 %v1486_v10, %v1481_v50 (stack40)
        %v1491_v43 = vshll.u32 %v1486_v10, 29 (stack45)
        %v1492_v10 = vshrl.u32 %v1486_v10, 3 (stack46)
        %v521_v7 = vxor.u32 %v520_v7, %v516_v59 (stack48)
        %v1957_v12 = vxor.u32 %v1956_v54, %v1948_v12 (stack48)
        %v2424_v54 = vxor.u32 %v2423_v26, %v2419_v37 (stack48)
        %v2885_v13 = vsel /*vm=*/%vm2859_vm11, /*on_true_vy=*/%v2881_v40, /*on_false_vx=*/%v2877_v16 (stack44)
        %v122804_v41 = vpop.permute.xlu1 %71306 (stack39)
        %157025 = vst [vmem:[#allocation139_spill] sm:$0xff] /*vst_source=*/%v122804_v41 (stack38)
        %v1002_v16 = vadd.s32 %v999_v11, %v994_v61 (stack40)
        %v1004_v61 = vshll.u32 %v999_v11, 29 (stack45)
        %v1005_v26 = vshrl.u32 %v999_v11, 3 (stack46)
        %v1493_v43 = vor.u32 %v1492_v10, %v1491_v43 (stack47)
        %v122806_v40 = vpop.permute.xlu0 %60140 (stack39)
        %157026 = vst [vmem:[#allocation140_spill] sm:$0xff] /*vst_source=*/%v122806_v40 (stack38)
        %v524_v59 = vadd.s32 %v521_v7, %v516_v59 (stack40)
        %v526_v11 = vshll.u32 %v521_v7, 16 (stack45)
        %v527_v10 = vshrl.u32 %v521_v7, 16 (stack46)
        %v1960_v7 = vadd.s32 %v1957_v12, %v121564_v0 (stack40)
        %v1006_v12 = vor.u32 %v1005_v26, %v1004_v61 (stack47)
        %v1494_v61 = vxor.u32 %v1493_v43, %v1489_v50 (stack48)
        %v2427_v37 = vadd.s32 %v2424_v54, %v2419_v37 (stack40)
        %v2429_v26 = vshll.u32 %v2424_v54, 26 (stack45)
        %v528_v43 = vor.u32 %v527_v10, %v526_v11 (stack47)
        %v1964_v11 = vadd.s32 1, %v1960_v7 (stack40)
        %v2430_v54 = vshrl.u32 %v2424_v54, 6 (stack46)
        %v2890_v13 = vadd.s32 %v2885_v13, %v121574_v2 (stack40)
        %v122810_v10 = vpop.permute.xlu1 %78750 (stack39)
        %157027 = vst [vmem:[#allocation141_spill] sm:$0xff] /*vst_source=*/%v122810_v10 (stack38)
        %v1007_v7 = vxor.u32 %v1006_v12, %v1002_v16 (stack48)
        %v1497_v50 = vadd.s32 %v1494_v61, %v1489_v50 (stack40)
        %v1499_v12 = vshll.u32 %v1494_v61, 16 (stack45)
        %v1500_v61 = vshrl.u32 %v1494_v61, 16 (stack46)
        %v122812_v10 = vpop.permute.xlu0 %67584 (stack39)
        %157028 = vst [vmem:[#allocation142_spill] sm:$0xff] /*vst_source=*/%v122812_v10 (stack38)
        %v529_v43 = vxor.u32 %v528_v43, %v524_v59 (stack48)
        %v1968_v62 = vadd.s32 %v1964_v11, %v1952_v62 (stack40)
        %v1970_v41 = vshll.u32 %v1964_v11, 17 (stack45)
        %v1971_v11 = vshrl.u32 %v1964_v11, 15 (stack46)
        %v1010_v16 = vadd.s32 %v1007_v7, %v1002_v16 (stack40)
        %v1012_v10 = vshll.u32 %v1007_v7, 16 (stack45)
        %v1013_v7 = vshrl.u32 %v1007_v7, 16 (stack46)
        %v1501_v12 = vor.u32 %v1500_v61, %v1499_v12 (stack47)
        %v532_v59 = vadd.s32 %v529_v43, %v524_v59 (stack40)
        %v538_v61 = vshll.u32 %v529_v43, 24 (stack45)
        %v539_v43 = vshrl.u32 %v529_v43, 8 (stack46)
        %v1972_v41 = vor.u32 %v1971_v11, %v1970_v41 (stack47)
        %v122814_v11 = vpop.permute.xlu1 %86194 (stack39)
        %157029 = vst [vmem:[#allocation143_spill] sm:$0xff] /*vst_source=*/%v122814_v11 (stack38)
        %v1014_v10 = vor.u32 %v1013_v7, %v1012_v10 (stack47)
        %v1502_v7 = vxor.u32 %v1501_v12, %v1497_v50 (stack48)
        %v122817_v13 = vadd.s32 %v122795_v45, %v2890_v13 (stack40)
        %v122819_v12 = vpop.permute.xlu0 %75028 (stack39)
        %157030 = vst [vmem:[#allocation144_spill] sm:$0xff] /*vst_source=*/%v122819_v12 (stack38)
        %v540_v61 = vor.u32 %v539_v43, %v538_v61 (stack47)
        %v1973_v43 = vxor.u32 %v1972_v41, %v1968_v62 (stack48)
        %v2431_v26 = vor.u32 %v2430_v54, %v2429_v26 (stack47)
        %v1015_v54 = vxor.u32 %v1014_v10, %v1010_v16 (stack48)
        %v1505_v50 = vadd.s32 %v1502_v7, %v1497_v50 (stack40)
        %v1511_v41 = vshll.u32 %v1502_v7, 24 (stack45)
        %v1512_v10 = vshrl.u32 %v1502_v7, 8 (stack46)
        %v541_v7 = vxor.u32 %v540_v61, %v532_v59 (stack48)
        %v1976_v62 = vadd.s32 %v1973_v43, %v1968_v62 (stack40)
        %v1978_v61 = vshll.u32 %v1973_v43, 29 (stack45)
        %v1979_v43 = vshrl.u32 %v1973_v43, 3 (stack46)
        %v122821_v11 = vpop.permute.xlu1 %93638 (stack39)
        %157031 = vst [vmem:[#allocation145_spill] sm:$0xff] /*vst_source=*/%v122821_v11 (stack38)
        %v1018_v16 = vadd.s32 %v1015_v54, %v1010_v16 (stack40)
        %v1024_v11 = vshll.u32 %v1015_v54, 24 (stack45)
        %v1025_v54 = vshrl.u32 %v1015_v54, 8 (stack46)
        %v122823_v12 = vpop.permute.xlu0 %82472 (stack39)
        %157032 = vst [vmem:[#allocation146_spill] sm:$0xff] /*vst_source=*/%v122823_v12 (stack38)
        %v544_v7 = vadd.s32 %v541_v7, %v121574_v2 (stack40)
        %v1513_v41 = vor.u32 %v1512_v10, %v1511_v41 (stack47)
        %v1980_v10 = vor.u32 %v1979_v43, %v1978_v61 (stack47)
        %v2432_v26 = vxor.u32 %v2431_v26, %v2427_v37 (stack48)
        %v536_v59 = vadd.s32 %v532_v59, %v121564_v0 (stack40)
        %v1026_v11 = vor.u32 %v1025_v54, %v1024_v11 (stack47)
        %v2900_v61 = vshll.u32 %v122795_v45, 13 (stack45)
        %v2901_v45 = vshrl.u32 %v122795_v45, 19 (stack46)
        %v548_v43 = vadd.s32 2, %v544_v7 (stack40)
        %v1514_v54 = vxor.u32 %v1513_v41, %v1505_v50 (stack48)
        %v1981_v7 = vxor.u32 %v1980_v10, %v1976_v62 (stack48)
        %v122829_v37 = vadd.s32 %v2432_v26, %v2427_v37 (stack40)
        %v122831_v41 = vpop.permute.xlu1 %101082 (stack39)
        %157033 = vst [vmem:[#allocation147_spill] sm:$0xff] /*vst_source=*/%v122831_v41 (stack38)
        %v1027_v10 = vxor.u32 %v1026_v11, %v1018_v16 (stack48)
        %v122833_v11 = vpop.permute.xlu0 %89916 (stack39)
        %157034 = vst [vmem:[#allocation148_spill] sm:$0xff] /*vst_source=*/%v122833_v11 (stack38)
        %v552_v59 = vadd.s32 %v548_v43, %v536_v59 (stack40)
        %v554_v41 = vshll.u32 %v548_v43, 13 (stack45)
        %v555_v43 = vshrl.u32 %v548_v43, 19 (stack46)
        %v1517_v54 = vadd.s32 %v1514_v54, %v121574_v2 (stack40)
        %v1030_v10 = vadd.s32 %v1027_v10, %v121574_v2 (stack40)
        %v2441_v11 = vshll.u32 %v2432_v26, 6 (stack45)
        %v2442_v26 = vshrl.u32 %v2432_v26, 26 (stack46)
        %v2902_v61 = vor.u32 %v2901_v45, %v2900_v61 (stack47)
        %v556_v45 = vor.u32 %v555_v43, %v554_v41 (stack47)
        %v122837_v41 = vpop.permute.xlu1 %108526 (stack39)
        %157035 = vst [vmem:[#allocation149_spill] sm:$0xff] /*vst_source=*/%v122837_v41 (stack38)
        %v1022_v16 = vadd.s32 %v1018_v16, %v121564_v0 (stack40)
        %v1984_v62 = vadd.s32 %v1981_v7, %v1976_v62 (stack40)
        %v3360_v43 = vadd.s32 1, %v122626_v14 (stack40)
        %v122841_v41 = vpop.permute.xlu0 %97360 (stack39)
        %157036 = vst [vmem:[#allocation150_spill] sm:$0xff] /*vst_source=*/%v122841_v41 (stack38)
        %v557_v45 = vxor.u32 %v556_v45, %v552_v59 (stack48)
        %v1034_v10 = vadd.s32 2, %v1030_v10 (stack40)
        %v1521_v54 = vadd.s32 2, %v1517_v54 (stack40)
        %v1986_v41 = vshll.u32 %v1981_v7, 16 (stack45)
        %v1509_v50 = vadd.s32 %v1505_v50, %v121564_v0 (stack40)
        %v1987_v7 = vshrl.u32 %v1981_v7, 16 (stack46)
        %v2443_v11 = vor.u32 %v2442_v26, %v2441_v11 (stack47)
        %v2903_v26 = vxor.u32 %v2902_v61, %v122817_v13 (stack48)
        %v560_v59 = vadd.s32 %v557_v45, %v552_v59 (stack40)
        %v562_v61 = vshll.u32 %v557_v45, 15 (stack45)
        %v563_v45 = vshrl.u32 %v557_v45, 17 (stack46)
        %v1038_v16 = vadd.s32 %v1034_v10, %v1022_v16 (stack40)
        %v122845_v12 = vpop.permute.xlu1 %115970 (stack39)
        %157037 = vst [vmem:[#allocation151_spill] sm:$0xff] /*vst_source=*/%v122845_v12 (stack38)
        %v1040_v12 = vshll.u32 %v1034_v10, 13 (stack45)
        %v1041_v10 = vshrl.u32 %v1034_v10, 19 (stack46)
        %v1525_v50 = vadd.s32 %v1521_v54, %v1509_v50 (stack40)
        %v1527_v40 = vshll.u32 %v1521_v54, 13 (stack45)
        %v122847_v9 = vpop.permute.xlu0 %104804 (stack39)
        %157038 = vst [vmem:[#allocation152_spill] sm:$0xff] /*vst_source=*/%v122847_v9 (stack38)
        %v564_v61 = vor.u32 %v563_v45, %v562_v61 (stack47)
        %v1528_v54 = vshrl.u32 %v1521_v54, 19 (stack46)
        %v1988_v41 = vor.u32 %v1987_v7, %v1986_v41 (stack47)
        %v2444_v7 = vxor.u32 %v2443_v11, %v122829_v37 (stack48)
        %v1042_v12 = vor.u32 %v1041_v10, %v1040_v12 (stack47)
        %v2906_v13 = vadd.s32 %v2903_v26, %v122817_v13 (stack40)
        %v2908_v11 = vshll.u32 %v2903_v26, 15 (stack45)
        %v2909_v26 = vshrl.u32 %v2903_v26, 17 (stack46)
        %v565_v45 = vxor.u32 %v564_v61, %v560_v59 (stack48)
        %v1529_v40 = vor.u32 %v1528_v54, %v1527_v40 (stack47)
        %v1989_v10 = vxor.u32 %v1988_v41, %v1984_v62 (stack48)
        %v122853_v61 = vadd.s32 %v122799_v8, %v122657_v58 (stack40)
        %v1043_v54 = vxor.u32 %v1042_v12, %v1038_v16 (stack48)
        %v2447_v41 = vadd.s32 %v2444_v7, %v121564_v0 (stack40)
        %v2910_v7 = vor.u32 %v2909_v26, %v2908_v11 (stack47)
        %vm3351_vm12 = vcmp.lt.u32.totalorder %v122799_v8, %v122693_v38 (stack43)
        %v122858_v12 = vpop.permute.xlu0 %112248 (stack39)
        %157039 = vst [vmem:[#allocation153_spill] sm:$0xff] /*vst_source=*/%v122858_v12 (stack38)
        %v568_v59 = vadd.s32 %v565_v45, %v560_v59 (stack40)
        %v570_v11 = vshll.u32 %v565_v45, 26 (stack45)
        %v571_v26 = vshrl.u32 %v565_v45, 6 (stack46)
        %v1530_v45 = vxor.u32 %v1529_v40, %v1525_v50 (stack48)
        %v1046_v16 = vadd.s32 %v1043_v54, %v1038_v16 (stack40)
        %v1048_v40 = vshll.u32 %v1043_v54, 15 (stack45)
        %v1049_v54 = vshrl.u32 %v1043_v54, 17 (stack46)
        %v1992_v62 = vadd.s32 %v1989_v10, %v1984_v62 (stack40)
        %v572_v11 = vor.u32 %v571_v26, %v570_v11 (stack47)
        %v1533_v50 = vadd.s32 %v1530_v45, %v1525_v50 (stack40)
        %v1535_v26 = vshll.u32 %v1530_v45, 15 (stack45)
        %v1536_v45 = vshrl.u32 %v1530_v45, 17 (stack46)
        %v1050_v40 = vor.u32 %v1049_v54, %v1048_v40 (stack47)
        %v1998_v54 = vshll.u32 %v1989_v10, 24 (stack45)
        %v1999_v10 = vshrl.u32 %v1989_v10, 8 (stack46)
        %v2439_v37 = vadd.s32 %v122829_v37, %v121569_v1 (stack40)
        %v573_v11 = vxor.u32 %v572_v11, %v568_v59 (stack48)
        %v1537_v26 = vor.u32 %v1536_v45, %v1535_v26 (stack47)
        %v1996_v45 = vadd.s32 %v1992_v62, %v121564_v0 (stack40)
        %v2911_v7 = vxor.u32 %v2910_v7, %v2906_v13 (stack48)
        %v1051_v40 = vxor.u32 %v1050_v40, %v1046_v16 (stack48)
        %v2000_v54 = vor.u32 %v1999_v10, %v1998_v54 (stack47)
        %v2451_v41 = vadd.s32 1, %v2447_v41 (stack40)
        %v3364_v14 = vsel /*vm=*/%vm3351_vm12, /*on_true_vy=*/%v3360_v43, /*on_false_vx=*/%v122626_v14 (stack44)
        %v576_v43 = vadd.s32 %v573_v11, %v568_v59 (stack40)
        %v582_v59 = vshll.u32 %v573_v11, 6 (stack45)
        %v583_v10 = vshrl.u32 %v573_v11, 26 (stack46)
        %v1538_v11 = vxor.u32 %v1537_v26, %v1533_v50 (stack48)
        %v1054_v16 = vadd.s32 %v1051_v40, %v1046_v16 (stack40)
        %v1056_v26 = vshll.u32 %v1051_v40, 26 (stack45)
        %v1057_v40 = vshrl.u32 %v1051_v40, 6 (stack46)
        %v2001_v62 = vxor.u32 %v2000_v54, %v1992_v62 (stack48)
        %v580_v54 = vadd.s32 %v576_v43, %v121574_v2 (stack40)
        %v584_v59 = vor.u32 %v583_v10, %v582_v59 (stack47)
        %v1541_v50 = vadd.s32 %v1538_v11, %v1533_v50 (stack40)
        %v1543_v10 = vshll.u32 %v1538_v11, 26 (stack45)
        %v1058_v26 = vor.u32 %v1057_v40, %v1056_v26 (stack47)
        %v1544_v11 = vshrl.u32 %v1538_v11, 6 (stack46)
        %v2004_v40 = vadd.s32 %v2001_v62, %v121574_v2 (stack40)
        %v2455_v37 = vadd.s32 %v2451_v41, %v2439_v37 (stack40)
        %v585_v43 = vxor.u32 %v584_v59, %v576_v43 (stack48)
        %v2457_v62 = vshll.u32 %v2451_v41, 17 (stack45)
        %v2458_v41 = vshrl.u32 %v2451_v41, 15 (stack46)
        %v2914_v13 = vadd.s32 %v2911_v7, %v2906_v13 (stack40)
        %v1059_v59 = vxor.u32 %v1058_v26, %v1054_v16 (stack48)
        %v1545_v10 = vor.u32 %v1544_v11, %v1543_v10 (stack47)
        %v2008_v26 = vadd.s32 2, %v2004_v40 (stack40)
        %v2916_v11 = vshll.u32 %v2911_v7, 26 (stack45)
        %v588_v40 = vadd.s32 %v585_v43, %v121569_v1 (stack40)
        %v2459_v43 = vor.u32 %v2458_v41, %v2457_v62 (stack47)
        %v2917_v7 = vshrl.u32 %v2911_v7, 6 (stack46)
        %v3368_v62 = vadd.s32 1, %v3364_v14 (stack40)
        %v1062_v16 = vadd.s32 %v1059_v59, %v1054_v16 (stack40)
        %v1068_v41 = vshll.u32 %v1059_v59, 6 (stack45)
        %v1069_v59 = vshrl.u32 %v1059_v59, 26 (stack46)
        %v1546_v10 = vxor.u32 %v1545_v10, %v1541_v50 (stack48)
        %v592_v40 = vadd.s32 3, %v588_v40 (stack40)
        %v2012_v45 = vadd.s32 %v2008_v26, %v1996_v45 (stack40)
        %v2014_v12 = vshll.u32 %v2008_v26, 13 (stack45)
        %v2015_v26 = vshrl.u32 %v2008_v26, 19 (stack46)
        %v1070_v41 = vor.u32 %v1069_v59, %v1068_v41 (stack47)
        %v1549_v50 = vadd.s32 %v1546_v10, %v1541_v50 (stack40)
        %v1555_v59 = vshll.u32 %v1546_v10, 6 (stack45)
        %vm3346_vm13 = vcmp.lt.u32.totalorder %v122853_v61, %v122799_v8 (stack43)
        %v596_v8 = vadd.s32 %v592_v40, %v580_v54 (stack40)
        %v598_v54 = vshll.u32 %v592_v40, 17 (stack45)
        %v599_v40 = vshrl.u32 %v592_v40, 15 (stack46)
        %v1556_v10 = vshrl.u32 %v1546_v10, 26 (stack46)
        %v1066_v9 = vadd.s32 %v1062_v16, %v121574_v2 (stack40)
        %v1071_v16 = vxor.u32 %v1070_v41, %v1062_v16 (stack48)
        %v2016_v12 = vor.u32 %v2015_v26, %v2014_v12 (stack47)
        %v2460_v43 = vxor.u32 %v2459_v43, %v2455_v37 (stack48)
        %v600_v26 = vor.u32 %v599_v40, %v598_v54 (stack47)
        %v1557_v41 = vor.u32 %v1556_v10, %v1555_v59 (stack47)
        %v2918_v11 = vor.u32 %v2917_v7, %v2916_v11 (stack47)
        %v122873_v14 = vsel /*vm=*/%vm3346_vm13, /*on_true_vy=*/%v3368_v62, /*on_false_vx=*/%v3364_v14 (stack44)
        %v1074_v7 = vadd.s32 %v1071_v16, %v121569_v1 (stack40)
        %v2017_v62 = vxor.u32 %v2016_v12, %v2012_v45 (stack48)
        %v122876_v37 = vadd.s32 %v2460_v43, %v2455_v37 (stack40)
        %v2465_v59 = vshll.u32 %v2460_v43, 29 (stack45)
        %v601_v54 = vxor.u32 %v600_v26, %v596_v8 (stack48)
        %v1558_v40 = vxor.u32 %v1557_v41, %v1549_v50 (stack48)
        %v2466_v10 = vshrl.u32 %v2460_v43, 3 (stack46)
        %v2919_v16 = vxor.u32 %v2918_v11, %v2914_v13 (stack48)
        %v1078_v12 = vadd.s32 3, %v1074_v7 (stack40)
        %v2020_v45 = vadd.s32 %v2017_v62, %v2012_v45 (stack40)
        %v2022_v43 = vshll.u32 %v2017_v62, 15 (stack45)
        %v2023_v26 = vshrl.u32 %v2017_v62, 17 (stack46)
        %v604_v8 = vadd.s32 %v601_v54, %v596_v8 (stack40)
        %v606_v41 = vshll.u32 %v601_v54, 29 (stack45)
        %v607_v11 = vshrl.u32 %v601_v54, 3 (stack46)
        %v1561_v7 = vadd.s32 %v1558_v40, %v121569_v1 (stack40)
        %v1082_v9 = vadd.s32 %v1078_v12, %v1066_v9 (stack40)
        %v1084_v62 = vshll.u32 %v1078_v12, 17 (stack45)
        %v1085_v54 = vshrl.u32 %v1078_v12, 15 (stack46)
        %v2024_v40 = vor.u32 %v2023_v26, %v2022_v43 (stack47)
        %v608_v12 = vor.u32 %v607_v11, %v606_v41 (stack47)
        %v1553_v50 = vadd.s32 %v1549_v50, %v121574_v2 (stack40)
        %v1565_v43 = vadd.s32 3, %v1561_v7 (stack40)
        %v122880_v13 = vadd.s32 %v2919_v16, %v2914_v13 (stack40)
        %v1086_v26 = vor.u32 %v1085_v54, %v1084_v62 (stack47)
        %v2025_v41 = vxor.u32 %v2024_v40, %v2020_v45 (stack48)
        %v2467_v59 = vor.u32 %v2466_v10, %v2465_v59 (stack47)
        %v122884_v61 = vadd.s32 %v122853_v61, %v121569_v1 (stack40)
        %v609_v10 = vxor.u32 %v608_v12, %v604_v8 (stack48)
        %v1569_v11 = vadd.s32 %v1565_v43, %v1553_v50 (stack40)
        %v1571_v7 = vshll.u32 %v1565_v43, 17 (stack45)
        %v1572_v62 = vshrl.u32 %v1565_v43, 15 (stack46)
        %v1087_v54 = vxor.u32 %v1086_v26, %v1082_v9 (stack48)
        %v2028_v45 = vadd.s32 %v2025_v41, %v2020_v45 (stack40)
        %v2030_v40 = vshll.u32 %v2025_v41, 26 (stack45)
        %v2031_v12 = vshrl.u32 %v2025_v41, 6 (stack46)
        %v612_v8 = vadd.s32 %v609_v10, %v604_v8 (stack40)
        %v614_v50 = vshll.u32 %v609_v10, 16 (stack45)
        %v615_v43 = vshrl.u32 %v609_v10, 16 (stack46)
        %v1573_v26 = vor.u32 %v1572_v62, %v1571_v7 (stack47)
        %v1090_v9 = vadd.s32 %v1087_v54, %v1082_v9 (stack40)
        %v1092_v41 = vshll.u32 %v1087_v54, 29 (stack45)
        %v1093_v10 = vshrl.u32 %v1087_v54, 3 (stack46)
        %v2032_v7 = vor.u32 %v2031_v12, %v2030_v40 (stack47)
        %v616_v62 = vor.u32 %v615_v43, %v614_v50 (stack47)
        %v1574_v54 = vxor.u32 %v1573_v26, %v1569_v11 (stack48)
        %v2468_v59 = vxor.u32 %v2467_v59, %v122876_v37 (stack48)
        %v2928_v40 = vshll.u32 %v2919_v16, 6 (stack45)
        %v1094_v12 = vor.u32 %v1093_v10, %v1092_v41 (stack47)
        %v2033_v50 = vxor.u32 %v2032_v7, %v2028_v45 (stack48)
        %v122889_v43 = vadd.s32 %v122880_v13, %v121569_v1 (stack40)
        %v2929_v16 = vshrl.u32 %v2919_v16, 26 (stack46)
        %v617_v26 = vxor.u32 %v616_v62, %v612_v8 (stack48)
        %v1577_v11 = vadd.s32 %v1574_v54, %v1569_v11 (stack40)
        %v1579_v41 = vshll.u32 %v1574_v54, 29 (stack45)
        %v1580_v10 = vshrl.u32 %v1574_v54, 3 (stack46)
        %v1095_v7 = vxor.u32 %v1094_v12, %v1090_v9 (stack48)
        %v2036_v45 = vadd.s32 %v2033_v50, %v2028_v45 (stack40)
        %v2042_v62 = vshll.u32 %v2033_v50, 6 (stack45)
        %v2043_v54 = vshrl.u32 %v2033_v50, 26 (stack46)
        %v620_v8 = vadd.s32 %v617_v26, %v612_v8 (stack40)
        %v626_v12 = vshll.u32 %v617_v26, 24 (stack45)
        %v627_v50 = vshrl.u32 %v617_v26, 8 (stack46)
        %v1581_v26 = vor.u32 %v1580_v10, %v1579_v41 (stack47)
        %v1098_v9 = vadd.s32 %v1095_v7, %v1090_v9 (stack40)
        %v1100_v41 = vshll.u32 %v1095_v7, 16 (stack45)
        %v1101_v10 = vshrl.u32 %v1095_v7, 16 (stack46)
        %v2930_v40 = vor.u32 %v2929_v16, %v2928_v40 (stack47)
        %v628_v16 = vor.u32 %v627_v50, %v626_v12 (stack47)
        %v1582_v7 = vxor.u32 %v1581_v26, %v1577_v11 (stack48)
        %v2044_v62 = vor.u32 %v2043_v54, %v2042_v62 (stack47)
        %v3377_v14 = vadd.s32 %v122873_v14, %v121574_v2 (stack40)
        %v1102_v54 = vor.u32 %v1101_v10, %v1100_v41 (stack47)
        %v2471_v37 = vadd.s32 %v2468_v59, %v122876_v37 (stack40)
        %v2473_v12 = vshll.u32 %v2468_v59, 16 (stack45)
        %v2474_v59 = vshrl.u32 %v2468_v59, 16 (stack46)
        %v629_v50 = vxor.u32 %v628_v16, %v620_v8 (stack48)
        %v1585_v11 = vadd.s32 %v1582_v7, %v1577_v11 (stack40)
        %v1587_v26 = vshll.u32 %v1582_v7, 16 (stack45)
        %v1588_v41 = vshrl.u32 %v1582_v7, 16 (stack46)
        %v1103_v10 = vxor.u32 %v1102_v54, %v1098_v9 (stack48)
        %v2045_v16 = vxor.u32 %v2044_v62, %v2036_v45 (stack48)
        %v2475_v7 = vor.u32 %v2474_v59, %v2473_v12 (stack47)
        %v2931_v13 = vxor.u32 %v2930_v40, %v122880_v13 (stack48)
        %v632_v40 = vadd.s32 %v629_v50, %v121564_v0 (stack40)
        %v1589_v62 = vor.u32 %v1588_v41, %v1587_v26 (stack47)
        %v2040_v45 = vadd.s32 %v2036_v45, %v121574_v2 (stack40)
        %v122898_v14 = vadd.s32 %v122884_v61, %v3377_v14 (stack40)
        %v1106_v9 = vadd.s32 %v1103_v10, %v1098_v9 (stack40)
        %v1112_v54 = vshll.u32 %v1103_v10, 24 (stack45)
        %v1113_v12 = vshrl.u32 %v1103_v10, 8 (stack46)
        %v2048_v59 = vadd.s32 %v2045_v16, %v121569_v1 (stack40)
        %v624_v8 = vadd.s32 %v620_v8, %v121569_v1 (stack40)
        %v636_v50 = vadd.s32 4, %v632_v40 (stack40)
        %v1590_v26 = vxor.u32 %v1589_v62, %v1585_v11 (stack48)
        %v2476_v41 = vxor.u32 %v2475_v7, %v2471_v37 (stack48)
        %v1114_v10 = vor.u32 %v1113_v12, %v1112_v54 (stack47)
        %v2052_v16 = vadd.s32 3, %v2048_v59 (stack40)
        %v2934_v7 = vadd.s32 %v2931_v13, %v121564_v0 (stack40)
        %v3387_v13 = vshll.u32 %v122884_v61, 13 (stack45)
        %v640_v40 = vadd.s32 %v636_v50, %v624_v8 (stack40)
        %v642_v62 = vshll.u32 %v636_v50, 13 (stack45)
        %v643_v54 = vshrl.u32 %v636_v50, 19 (stack46)
        %v1593_v11 = vadd.s32 %v1590_v26, %v1585_v11 (stack40)
        %v1110_v12 = vadd.s32 %v1106_v9, %v121569_v1 (stack40)
        %v1115_v9 = vxor.u32 %v1114_v10, %v1106_v9 (stack48)
        %v1599_v59 = vshll.u32 %v1590_v26, 24 (stack45)
        %v1600_v8 = vshrl.u32 %v1590_v26, 8 (stack46)
        %v644_v50 = vor.u32 %v643_v54, %v642_v62 (stack47)
        %v2056_v45 = vadd.s32 %v2052_v16, %v2040_v45 (stack40)
        %v2058_v26 = vshll.u32 %v2052_v16, 17 (stack45)
        %v3388_v10 = vshrl.u32 %v122884_v61, 19 (stack46)
        %v1118_v62 = vadd.s32 %v1115_v9, %v121564_v0 (stack40)
        %v1601_v54 = vor.u32 %v1600_v8, %v1599_v59 (stack47)
        %v2059_v16 = vshrl.u32 %v2052_v16, 15 (stack46)
        %v122907_v37 = vadd.s32 %v2476_v41, %v2471_v37 (stack40)
        %v645_v9 = vxor.u32 %v644_v50, %v640_v40 (stack48)
        %v2485_v59 = vshll.u32 %v2476_v41, 24 (stack45)
        %v2486_v41 = vshrl.u32 %v2476_v41, 8 (stack46)
        %v2938_v7 = vadd.s32 1, %v2934_v7 (stack40)
        %v1122_v8 = vadd.s32 4, %v1118_v62 (stack40)
        %v1597_v50 = vadd.s32 %v1593_v11, %v121569_v1 (stack40)
        %v1602_v11 = vxor.u32 %v1601_v54, %v1593_v11 (stack48)
        %v2060_v26 = vor.u32 %v2059_v16, %v2058_v26 (stack47)
        %v648_v40 = vadd.s32 %v645_v9, %v640_v40 (stack40)
        %v650_v62 = vshll.u32 %v645_v9, 15 (stack45)
        %v651_v54 = vshrl.u32 %v645_v9, 17 (stack46)
        %v2487_v16 = vor.u32 %v2486_v41, %v2485_v59 (stack47)
        %v1126_v12 = vadd.s32 %v1122_v8, %v1110_v12 (stack40)
        %v1128_v9 = vshll.u32 %v1122_v8, 13 (stack45)
        %v1129_v59 = vshrl.u32 %v1122_v8, 19 (stack46)
        %v1605_v41 = vadd.s32 %v1602_v11, %v121564_v0 (stack40)
        %v652_v8 = vor.u32 %v651_v54, %v650_v62 (stack47)
        %v2061_v11 = vxor.u32 %v2060_v26, %v2056_v45 (stack48)
        %v2488_v26 = vxor.u32 %v2487_v16, %v122907_v37 (stack48)
        %v122913_v43 = vadd.s32 %v2938_v7, %v122889_v43 (stack40)
        %v1130_v62 = vor.u32 %v1129_v59, %v1128_v9 (stack47)
        %v1609_v54 = vadd.s32 4, %v1605_v41 (stack40)
        %v2944_v16 = vshll.u32 %v2938_v7, 17 (stack45)
        %v2945_v7 = vshrl.u32 %v2938_v7, 15 (stack46)
        %v653_v9 = vxor.u32 %v652_v8, %v648_v40 (stack48)
        %v2064_v45 = vadd.s32 %v2061_v11, %v2056_v45 (stack40)
        %v2066_v59 = vshll.u32 %v2061_v11, 29 (stack45)
        %v2067_v41 = vshrl.u32 %v2061_v11, 3 (stack46)
        %v1131_v8 = vxor.u32 %v1130_v62, %v1126_v12 (stack48)
        %v1613_v50 = vadd.s32 %v1609_v54, %v1597_v50 (stack40)
        %v1615_v11 = vshll.u32 %v1609_v54, 13 (stack45)
        %v1616_v62 = vshrl.u32 %v1609_v54, 19 (stack46)
        %v656_v40 = vadd.s32 %v653_v9, %v648_v40 (stack40)
        %v658_v54 = vshll.u32 %v653_v9, 26 (stack45)
        %v659_v9 = vshrl.u32 %v653_v9, 6 (stack46)
        %v2068_v59 = vor.u32 %v2067_v41, %v2066_v59 (stack47)
        %v1134_v12 = vadd.s32 %v1131_v8, %v1126_v12 (stack40)
        %v1136_v41 = vshll.u32 %v1131_v8, 15 (stack45)
        %v1137_v8 = vshrl.u32 %v1131_v8, 17 (stack46)
        %v1617_v11 = vor.u32 %v1616_v62, %v1615_v11 (stack47)
        %v660_v62 = vor.u32 %v659_v9, %v658_v54 (stack47)
        %v2069_v54 = vxor.u32 %v2068_v59, %v2064_v45 (stack48)
        %v2491_v26 = vadd.s32 %v2488_v26, %v121574_v2 (stack40)
        %v2946_v16 = vor.u32 %v2945_v7, %v2944_v16 (stack47)
        %v1138_v7 = vor.u32 %v1137_v8, %v1136_v41 (stack47)
        %v1618_v9 = vxor.u32 %v1617_v11, %v1613_v50 (stack48)
        %v3389_v61 = vor.u32 %v3388_v10, %v3387_v13 (stack47)
        %v122920_v60 = vadd.s32 %v122720_v3, %v122659_v60 (stack40)
        %v661_v13 = vxor.u32 %v660_v62, %v656_v40 (stack48)
        %v2072_v10 = vadd.s32 %v2069_v54, %v2064_v45 (stack40)
        %v2074_v45 = vshll.u32 %v2069_v54, 16 (stack45)
        %v2075_v59 = vshrl.u32 %v2069_v54, 16 (stack46)
        %v1139_v41 = vxor.u32 %v1138_v7, %v1134_v12 (stack48)
        %v1621_v50 = vadd.s32 %v1618_v9, %v1613_v50 (stack40)
        %v1623_v8 = vshll.u32 %v1618_v9, 15 (stack45)
        %v1624_v11 = vshrl.u32 %v1618_v9, 17 (stack46)
        %v664_v40 = vadd.s32 %v661_v13, %v656_v40 (stack40)
        %v670_v62 = vshll.u32 %v661_v13, 6 (stack45)
        %v671_v54 = vshrl.u32 %v661_v13, 26 (stack46)
        %v2076_v7 = vor.u32 %v2075_v59, %v2074_v45 (stack47)
        %v1142_v12 = vadd.s32 %v1139_v41, %v1134_v12 (stack40)
        %v1144_v9 = vshll.u32 %v1139_v41, 26 (stack45)
        %v1145_v13 = vshrl.u32 %v1139_v41, 6 (stack46)
        %v1625_v45 = vor.u32 %v1624_v11, %v1623_v8 (stack47)
        %v672_v59 = vor.u32 %v671_v54, %v670_v62 (stack47)
        %v2077_v41 = vxor.u32 %v2076_v7, %v2072_v10 (stack48)
        %v2483_v37 = vadd.s32 %v122907_v37, %v121564_v0 (stack40)
        %v2495_v26 = vadd.s32 2, %v2491_v26 (stack40)
        %v1146_v8 = vor.u32 %v1145_v13, %v1144_v9 (stack47)
        %v1626_v11 = vxor.u32 %v1625_v45, %v1621_v50 (stack48)
        %v2947_v16 = vxor.u32 %v2946_v16, %v122913_v43 (stack48)
        %v122926_v61 = vxor.u32 %v3389_v61, %v122898_v14 (stack48)
        %v673_v62 = vxor.u32 %v672_v59, %v664_v40 (stack48)
        %v2080_v10 = vadd.s32 %v2077_v41, %v2072_v10 (stack40)
        %v2086_v54 = vshll.u32 %v2077_v41, 24 (stack45)
        %v2087_v7 = vshrl.u32 %v2077_v41, 8 (stack46)
        %v1147_v9 = vxor.u32 %v1146_v8, %v1142_v12 (stack48)
        %v1629_v50 = vadd.s32 %v1626_v11, %v1621_v50 (stack40)
        %v1631_v13 = vshll.u32 %v1626_v11, 26 (stack45)
        %v1632_v45 = vshrl.u32 %v1626_v11, 6 (stack46)
        %v668_v40 = vadd.s32 %v664_v40, %v121564_v0 (stack40)
        %v676_v59 = vadd.s32 %v673_v62, %v121574_v2 (stack40)
        %v2088_v41 = vor.u32 %v2087_v7, %v2086_v54 (stack47)
        %v2499_v37 = vadd.s32 %v2495_v26, %v2483_v37 (stack40)
        %v1150_v12 = vadd.s32 %v1147_v9, %v1142_v12 (stack40)
        %v1156_v8 = vshll.u32 %v1147_v9, 6 (stack45)
        %v1157_v11 = vshrl.u32 %v1147_v9, 26 (stack46)
        %v1633_v62 = vor.u32 %v1632_v45, %v1631_v13 (stack47)
        %v680_v54 = vadd.s32 5, %v676_v59 (stack40)
        %v2089_v7 = vxor.u32 %v2088_v41, %v2080_v10 (stack48)
        %v2501_v9 = vshll.u32 %v2495_v26, 13 (stack45)
        %v2502_v26 = vshrl.u32 %v2495_v26, 19 (stack46)
        %v1158_v13 = vor.u32 %v1157_v11, %v1156_v8 (stack47)
        %v1634_v45 = vxor.u32 %v1633_v62, %v1629_v50 (stack48)
        %v2084_v10 = vadd.s32 %v2080_v10, %v121569_v1 (stack40)
        %v2950_v43 = vadd.s32 %v2947_v16, %v122913_v43 (stack40)
        %v682_v40 = vxor.u32 %v680_v54, %v668_v40 (stack48)
        %v2092_v59 = vadd.s32 %v2089_v7, %v121564_v0 (stack40)
        %v2503_v41 = vor.u32 %v2502_v26, %v2501_v9 (stack47)
        %v2952_v8 = vshll.u32 %v2947_v16, 29 (stack45)
        %v1159_v11 = vxor.u32 %v1158_v13, %v1150_v12 (stack48)
        %v1637_v50 = vadd.s32 %v1634_v45, %v1629_v50 (stack40)
        %v1643_v62 = vshll.u32 %v1634_v45, 6 (stack45)
        %v1644_v54 = vshrl.u32 %v1634_v45, 26 (stack46)
        %v683_v7 = vand.u32.u8 255, %v682_v40 (stack49)
        %v2096_v9 = vadd.s32 4, %v2092_v59 (stack40)
        %v2504_v26 = vxor.u32 %v2503_v41, %v2499_v37 (stack48)
        %v2953_v16 = vshrl.u32 %v2947_v16, 3 (stack46)
        %v1154_v12 = vadd.s32 %v1150_v12, %v121564_v0 (stack40)
        %v1162_v13 = vadd.s32 %v1159_v11, %v121574_v2 (stack40)
        %v1645_v45 = vor.u32 %v1644_v54, %v1643_v62 (stack47)
        %v3393_v14 = vadd.s32 %v122926_v61, %v122898_v14 (stack40)
        %v684_v40 = vand.u32 65535, %v683_v7 (stack50)
        %v2100_v10 = vadd.s32 %v2096_v9, %v2084_v10 (stack40)
        %v2102_v59 = vshll.u32 %v2096_v9, 13 (stack45)
        %v2103_v41 = vshrl.u32 %v2096_v9, 19 (stack46)
        %v1166_v11 = vadd.s32 5, %v1162_v13 (stack40)
        %v1646_v62 = vxor.u32 %v1645_v45, %v1637_v50 (stack48)
        %v2507_v37 = vadd.s32 %v2504_v26, %v2499_v37 (stack40)
        %v2509_v54 = vshll.u32 %v2504_v26, 15 (stack45)
        %v685_v7 = vshrl.u32 %v684_v40, 1 (stack51)
        %v2104_v9 = vor.u32 %v2103_v41, %v2102_v59 (stack47)
        %v2510_v26 = vshrl.u32 %v2504_v26, 17 (stack46)
        %v2954_v8 = vor.u32 %v2953_v16, %v2952_v8 (stack47)
        %v1168_v16 = vxor.u32 %v1166_v11, %v1154_v12 (stack48)
        %v1649_v12 = vadd.s32 %v1646_v62, %v121574_v2 (stack40)
        %v3395_v13 = vshll.u32 %v122926_v61, 15 (stack45)
        %v3396_v61 = vshrl.u32 %v122926_v61, 17 (stack46)
        %v686_v45 = vor.u32 16256, %v685_v7 (stack47)
        %v2105_v40 = vxor.u32 %v2104_v9, %v2100_v10 (stack48)
        %v2511_v59 = vor.u32 %v2510_v26, %v2509_v54 (stack47)
        %v2955_v41 = vxor.u32 %v2954_v8, %v2950_v43 (stack48)
        %v1169_v11 = vand.u32.u8 255, %v1168_v16 (stack49)
        %v1641_v50 = vadd.s32 %v1637_v50, %v121564_v0 (stack40)
        %v1653_v62 = vadd.s32 5, %v1649_v12 (stack40)
        %v3397_v54 = vor.u32 %v3396_v61, %v3395_v13 (stack47)
        %v687_v7 = vand.u32.u16 65535, %v686_v45 (stack52)
        %v2108_v10 = vadd.s32 %v2105_v40, %v2100_v10 (stack40)
        %v2110_v9 = vshll.u32 %v2105_v40, 15 (stack45)
        %v2111_v26 = vshrl.u32 %v2105_v40, 17 (stack46)
        %v1170_v8 = vand.u32 65535, %v1169_v11 (stack50)
        %v1655_v16 = vxor.u32 %v1653_v62, %v1641_v50 (stack48)
        %v2512_v12 = vxor.u32 %v2511_v59, %v2507_v37 (stack48)
        %v2958_v43 = vadd.s32 %v2955_v41, %v2950_v43 (stack40)
        %v119749_v13 = vadd.low.f32.bf16 -1.0, %v687_v7 (stack53)
        %v2112_v61 = vor.u32 %v2111_v26, %v2110_v9 (stack47)
        %v2960_v45 = vshll.u32 %v2955_v41, 16 (stack45)
        %v2961_v40 = vshrl.u32 %v2955_v41, 16 (stack46)
        %v1171_v59 = vshrl.u32 %v1170_v8, 1 (stack51)
        %v1656_v41 = vand.u32.u8 255, %v1655_v16 (stack49)
        %v2515_v37 = vadd.s32 %v2512_v12, %v2507_v37 (stack40)
        %v2517_v11 = vshll.u32 %v2512_v12, 26 (stack45)
        %v696_v50 = vmul.f32 2.0, %v119749_v13 (stack54)
        %v2113_v62 = vxor.u32 %v2112_v61, %v2108_v10 (stack48)
        %v2518_v7 = vshrl.u32 %v2512_v12, 6 (stack46)
        %v2962_v9 = vor.u32 %v2961_v40, %v2960_v45 (stack47)
        %v1172_v26 = vor.u32 16256, %v1171_v59 (stack47)
        %v1657_v8 = vand.u32 65535, %v1656_v41 (stack50)
        %v122941_v54 = vxor.u32 %v3397_v54, %v3393_v14 (stack48)
        %v700_v16 = vadd.f32 -0.99609375, %v696_v50 (stack53)
        %v2116_v10 = vadd.s32 %v2113_v62, %v2108_v10 (stack40)
        %v2118_v12 = vshll.u32 %v2113_v62, 26 (stack45)
        %v2119_v13 = vshrl.u32 %v2113_v62, 6 (stack46)
        %v1173_v61 = vand.u32.u16 65535, %v1172_v26 (stack52)
        %v1658_v45 = vshrl.u32 %v1657_v8, 1 (stack51)
        %v2519_v40 = vor.u32 %v2518_v7, %v2517_v11 (stack47)
        %v2963_v59 = vxor.u32 %v2962_v9, %v2958_v43 (stack48)
        %v122943_v41 = vmax.f32 %v700_v16, -0.99609375 (stack55)
        %v2120_v11 = vor.u32 %v2119_v13, %v2118_v12 (stack47)
        %v122946_v14 = vadd.s32 %v122941_v54, %v3393_v14 (stack40)
        %v119750_v50 = vadd.low.f32.bf16 -1.0, %v1173_v61 (stack53)
        %v1659_v62 = vor.u32 16256, %v1658_v45 (stack47)
        %v2520_v7 = vxor.u32 %v2519_v40, %v2515_v37 (stack48)
        %v122948_v43 = vadd.s32 %v2963_v59, %v2958_v43 (stack40)
        %v716_v9 = vxor.u32 2147483648, %v122943_v41 (stack56)
        %v2121_v26 = vxor.u32 %v2120_v11, %v2116_v10 (stack48)
        %v1182_v8 = vmul.f32 2.0, %v119750_v50 (stack54)
        %v1660_v16 = vand.u32.u16 65535, %v1659_v62 (stack52)
        %v2523_v37 = vadd.s32 %v2520_v7, %v2515_v37 (stack40)
        %v719_v12 = vmul.f32 %v716_v9, %v122943_v41 (stack54)
        %v2124_v10 = vadd.s32 %v2121_v26, %v2116_v10 (stack40)
        %v2130_v13 = vshll.u32 %v2121_v26, 6 (stack45)
        %v1186_v61 = vadd.f32 -0.99609375, %v1182_v8 (stack53)
        %v119752_v45 = vadd.low.f32.bf16 -1.0, %v1660_v16 (stack53)
        %v2131_v40 = vshrl.u32 %v2121_v26, 26 (stack46)
        %v721_v11 = vadd.f32 1.0, %v719_v12 (stack57)
        %v2529_v50 = vshll.u32 %v2520_v7, 6 (stack45)
        %v122952_v62 = vmax.f32 %v1186_v61, -0.99609375 (stack55)
        %v1669_v9 = vmul.f32 2.0, %v119752_v45 (stack54)
        %v2132_v26 = vor.u32 %v2131_v40, %v2130_v13 (stack47)
        %v2530_v7 = vshrl.u32 %v2520_v7, 26 (stack46)
        %120433 = vlog2.f32 %v721_v11 (stack58)
        %v1202_v8 = vxor.u32 2147483648, %v122952_v62 (stack56)
        %v1673_v16 = vadd.f32 -0.99609375, %v1669_v9 (stack53)
        %v2133_v13 = vxor.u32 %v2132_v26, %v2124_v10 (stack48)
        %v2531_v61 = vor.u32 %v2530_v7, %v2529_v50 (stack47)
        %v724_v45 = vmul.f32 -0.5, %v719_v12 (stack59)
        %v122956_v40 = vmul.f32 %v1202_v8, %v122952_v62 (stack54)
        %v122958_v11 = vmax.f32 %v1673_v16, -0.99609375 (stack55)
        %v2972_v50 = vshll.u32 %v2963_v59, 24 (stack45)
        %v2136_v9 = vadd.s32 %v2133_v13, %v121574_v2 (stack40)
        %v2532_v26 = vxor.u32 %v2531_v61, %v2523_v37 (stack48)
        %v2973_v59 = vshrl.u32 %v2963_v59, 8 (stack46)
        %vm3838_vm14 = vcmp.lt.u32.totalorder %v122920_v60, %v122720_v3 (stack43)
        %v727_v7 = vand.u32 2147483647, %v719_v12 (stack60)
        %v1207_v8 = vadd.f32 1.0, %v122956_v40 (stack57)
        %v3403_v16 = vshll.u32 %v122941_v54, 26 (stack45)
        %v3404_v54 = vshrl.u32 %v122941_v54, 6 (stack46)
        %v1689_v13 = vxor.u32 2147483648, %v122958_v11 (stack56)
        %v2128_v10 = vadd.s32 %v2124_v10, %v121564_v0 (stack40)
        %v2140_v61 = vadd.s32 5, %v2136_v9 (stack40)
        %v2535_v9 = vadd.s32 %v2532_v26, %v121569_v1 (stack40)
        %v725_v45 = vadd.f32 1.0, %v724_v45 (stack61)
        %120435 = vlog2.f32 %v1207_v8 (stack58)
        %v122972_v8 = vadd.s32 %v122920_v60, %v122657_v58 (stack40)
        %v1692_v13 = vmul.f32 %v1689_v13, %v122958_v11 (stack54)
        %v2142_v10 = vxor.u32 %v2140_v61, %v2128_v10 (stack48)
        %v2539_v61 = vadd.s32 3, %v2535_v9 (stack40)
        %v2974_v50 = vor.u32 %v2973_v59, %v2972_v50 (stack47)
        %v122976_v59 = vmul.f32 inf, %v122943_v41 (stack54)
        %v2527_v37 = vadd.s32 %v2523_v37, %v121574_v2 (stack40)
        %v3405_v16 = vor.u32 %v3404_v54, %v3403_v16 (stack47)
        %v3843_v28 = vadd.s32 %v122032_v35, %v121991_v28 (stack40)
        %vm122981_vm15 = vcmp.lt.f32.partialorder %v727_v7, 0.0004427343 (stack62)
        %v1210_v54 = vmul.f32 -0.5, %v122956_v40 (stack59)
        %v1694_v9 = vadd.f32 1.0, %v1692_v13 (stack57)
        %v2143_v10 = vand.u32.u8 255, %v2142_v10 (stack49)
        %v2543_v37 = vadd.s32 %v2539_v61, %v2527_v37 (stack40)
        %v2545_v26 = vshll.u32 %v2539_v61, 17 (stack45)
        %v2546_v61 = vshrl.u32 %v2539_v61, 15 (stack46)
        %v2975_v50 = vxor.u32 %v2974_v50, %v122948_v43 (stack48)
        %v726_v12 = vmul.f32 %v725_v45, %v719_v12 (stack63)
        %120437 = vlog2.f32 %v1694_v9 (stack58)
        %v2144_v45 = vand.u32 65535, %v2143_v10 (stack50)
        %v2970_v43 = vadd.s32 %v122948_v43, %v121564_v0 (stack40)
        %v120434_v9 = vpop.eup %120433 (stack64)
        %v1213_v10 = vand.u32 2147483647, %v122956_v40 (stack60)
        %v2547_v26 = vor.u32 %v2546_v61, %v2545_v26 (stack47)
        %v2978_v61 = vadd.s32 %v2975_v50, %v121574_v2 (stack40)
        %v3406_v16 = vxor.u32 %v3405_v16, %v122946_v14 (stack48)
        %v723_v50 = vmul.f32 0.6931472, %v120434_v9 (stack65)
        %v1697_v9 = vmul.f32 -0.5, %v1692_v13 (stack59)
        %v2145_v45 = vshrl.u32 %v2144_v45, 1 (stack51)
        %v3847_v55 = vadd.s32 1, %v3843_v28 (stack40)
        %v1211_v54 = vadd.f32 1.0, %v1210_v54 (stack61)
        %v2548_v26 = vxor.u32 %v2547_v26, %v2543_v37 (stack48)
        %v2982_v61 = vadd.s32 2, %v2978_v61 (stack40)
        %v122993_v14 = vadd.s32 %v3406_v16, %v122946_v14 (stack40)
        %v729_v7 = vsel /*vm=*/%vm122981_vm15, /*on_true_vy=*/%v726_v12, /*on_false_vx=*/%v723_v50 (stack66)
        %v1700_v12 = vand.u32 2147483647, %v1692_v13 (stack60)
        %v2146_v50 = vor.u32 16256, %v2145_v45 (stack47)
        %v123000_v55 = vsel /*vm=*/%vm3838_vm14, /*on_true_vy=*/%v3847_v55, /*on_false_vx=*/%v3843_v28 (stack44)
        %v123002_v28 = vxor.u32 2147483648, %v729_v7 (stack56)
        %v2551_v37 = vadd.s32 %v2548_v26, %v2543_v37 (stack40)
        %v2553_v45 = vshll.u32 %v2548_v26, 29 (stack45)
        %v2554_v26 = vshrl.u32 %v2548_v26, 3 (stack46)
        %v1698_v9 = vadd.f32 1.0, %v1697_v9 (stack61)
        %v2986_v43 = vadd.s32 %v2982_v61, %v2970_v43 (stack40)
        %v2988_v7 = vshll.u32 %v2982_v61, 13 (stack45)
        %v2989_v61 = vshrl.u32 %v2982_v61, 19 (stack46)
        %120439 = vrsqrt.f32 %v123002_v28 (stack67)
        %v2147_v50 = vand.u32.u16 65535, %v2146_v50 (stack52)
        %v123008_v20 = vadd.s32 %v122972_v8, %v121569_v1 (stack40)
        %v120436_v57 = vpop.eup %120435 (stack64)
        %v123011_v52 = vmul.f32 inf, %v122952_v62 (stack54)
        %v123015_v51 = vmul.f32 inf, %v122958_v11 (stack54)
        %v2555_v45 = vor.u32 %v2554_v26, %v2553_v45 (stack47)
        %vm123017_vm0 = vcmp.lt.f32.partialorder %v1213_v10, 0.0004427343 (stack62)
        %v2990_v26 = vor.u32 %v2989_v61, %v2988_v7 (stack47)
        %v3415_v7 = vshll.u32 %v3406_v16, 6 (stack45)
        %v3416_v16 = vshrl.u32 %v3406_v16, 26 (stack46)
        %v1212_v40 = vmul.f32 %v1211_v54, %v122956_v40 (stack63)
        %v1699_v13 = vmul.f32 %v1698_v9, %v1692_v13 (stack63)
        %vm123022_vm1 = vcmp.lt.f32.partialorder %v1700_v12, 0.0004427343 (stack62)
        %v2556_v12 = vxor.u32 %v2555_v45, %v2551_v37 (stack48)
        %vm733_vm2 = vcmp.lt.f32.partialorder %v123002_v28, 5.0 (stack68)
        %v1209_v57 = vmul.f32 0.6931472, %v120436_v57 (stack65)
        %v119754_v9 = vadd.low.f32.bf16 -1.0, %v2147_v50 (stack53)
        %v2559_v37 = vadd.s32 %v2556_v12, %v2551_v37 (stack40)
        %v2561_v50 = vshll.u32 %v2556_v12, 16 (stack45)
        %v2562_v45 = vshrl.u32 %v2556_v12, 16 (stack46)
        %v2991_v26 = vxor.u32 %v2990_v26, %v2986_v43 (stack48)
        %v120438_v12 = vpop.eup %120437 (stack64)
        %v123029_v61 = vadd.f32 -2.5, %v123002_v28 (stack53)
        %v1215_v10 = vsel /*vm=*/%vm123017_vm0, /*on_true_vy=*/%v1212_v40, /*on_false_vx=*/%v1209_v57 (stack66)
        %v2156_v40 = vmul.f32 2.0, %v119754_v9 (stack54)
        %v123033_v7 = vor.u32 %v3416_v16, %v3415_v7 (stack47)
        %v123035_v16 = vxor.u32 2147483648, %v1215_v10 (stack56)
        %v1696_v57 = vmul.f32 0.6931472, %v120438_v12 (stack65)
        %v2563_v9 = vor.u32 %v2562_v45, %v2561_v50 (stack47)
        %v123037_v43 = vadd.s32 %v2991_v26, %v2986_v43 (stack40)
        %v156605_v50 = vmov 2.8329768 /* materialized constant */ (stack69)
        %v123042_v45 = vsel /*vm=*/%vm733_vm2, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v156605_v50 (stack44)
        %v156601_v12 = vmov 1.001674 /* materialized constant */ (stack69)
        %v123047_v10 = vsel /*vm=*/%vm733_vm2, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v156601_v12 (stack44)
        %vm778_vm3 = vcmp.eq.f32.partialorder %v123002_v28, inf (stack70)
        %v3418_v7 = vxor.u32 %v123033_v7, %v122993_v14 (stack48)
        %v156603_v12 = vmov 0.0094388705 /* materialized constant */ (stack69)
        %v123055_v12 = vsel /*vm=*/%vm733_vm2, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v156603_v12 (stack44)
        %v156607_v50 = vmov -0.0076224613 /* materialized constant */ (stack69)
        %v123060_v50 = vsel /*vm=*/%vm733_vm2, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v156607_v50 (stack44)
        %v157046_v4 = vmov 0.0057395077 /* materialized constant */ (stack69)
        %v123065_v53 = vsel /*vm=*/%vm733_vm2, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %120441 = vrsqrt.f32 %v123035_v16 (stack67)
        %v157047_v63 = vmov -0.0036734284 /* materialized constant */ (stack69)
        %v123071_v46 = vsel /*vm=*/%vm733_vm2, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v157048_v19 = vmov 0.0013493432 /* materialized constant */ (stack69)
        %v123076_v48 = vsel /*vm=*/%vm733_vm2, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %vm1219_vm4 = vcmp.lt.f32.partialorder %v123035_v16, 5.0 (stack68)
        %v1702_v13 = vsel /*vm=*/%vm123022_vm1, /*on_true_vy=*/%v1699_v13, /*on_false_vx=*/%v1696_v57 (stack66)
        %v156618_v54 = vmov 0.00010095056 /* materialized constant */ (stack69)
        %v766_v57 = vsel /*vm=*/%vm733_vm2, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v156618_v54 (stack44)
        %v156620_v54 = vmov -0.00020021426 /* materialized constant */ (stack69)
        %v770_v54 = vsel /*vm=*/%vm733_vm2, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v156620_v54 (stack44)
        %v2160_v40 = vadd.f32 -0.99609375, %v2156_v40 (stack53)
        %v2564_v9 = vxor.u32 %v2563_v9, %v2559_v37 (stack48)
        %vm780_vm5 = vcmp.eq.f32.partialorder %v123002_v28, 0.0 (stack71)
        %v781_v5 = vand.u32 2147483648, %v123002_v28 (stack72)
        %v2996_v42 = vshll.u32 %v2991_v26, 15 (stack45)
        %v123091_v14 = vadd.s32 %v122993_v14, %v121569_v1 (stack40)
        %v120440_v17 = vpop.eup %120439 (stack73)
        %v157049_v44 = vmov 2.8329768 /* materialized constant */ (stack69)
        %v123096_v21 = vsel /*vm=*/%vm1219_vm4, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157049_v44 (stack44)
        %v123099_v36 = vadd.f32 -2.5, %v123035_v16 (stack53)
        %v123101_v13 = vxor.u32 2147483648, %v1702_v13 (stack56)
        %v2997_v26 = vshrl.u32 %v2991_v26, 17 (stack46)
        %v777_v17 = vmul.f32 %v120440_v17, %v123002_v28 (stack74)
        %v157050_v33 = vmov 1.001674 /* materialized constant */ (stack69)
        %v123107_v39 = vsel /*vm=*/%vm1219_vm4, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v157051_v18 = vmov 0.0094388705 /* materialized constant */ (stack69)
        %v123112_v35 = vsel /*vm=*/%vm1219_vm4, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v2567_v37 = vadd.s32 %v2564_v9, %v2559_v37 (stack40)
        %v157052_v3 = vmov -0.0076224613 /* materialized constant */ (stack69)
        %v123117_v30 = vsel /*vm=*/%vm1219_vm4, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v123122_v38 = vsel /*vm=*/%vm1219_vm4, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %120443 = vrsqrt.f32 %v123101_v13 (stack67)
        %v123125_v40 = vmax.f32 %v2160_v40, -0.99609375 (stack55)
        %v779_v17 = vsel /*vm=*/%vm778_vm3, /*on_true_vy=*/%v123002_v28, /*on_false_vx=*/%v777_v17 (stack75)
        %vm1706_vm6 = vcmp.lt.f32.partialorder %v123101_v13, 5.0 (stack68)
        %v2573_v31 = vshll.u32 %v2564_v9, 24 (stack45)
        %v2574_v9 = vshrl.u32 %v2564_v9, 8 (stack46)
        %v782_v5 = vsel /*vm=*/%vm780_vm5, /*on_true_vy=*/%v781_v5, /*on_false_vx=*/%v779_v17 (stack76)
        %v123136_v17 = vsel /*vm=*/%vm1219_vm4, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v123141_v6 = vsel /*vm=*/%vm1219_vm4, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v2998_v42 = vor.u32 %v2997_v26, %v2996_v42 (stack47)
        %v785_v26 = vadd.f32 -3.0, %v782_v5 (stack53)
        %v157053_v5 = vmov 0.00010095056 /* materialized constant */ (stack69)
        %v1252_v27 = vsel /*vm=*/%vm1219_vm4, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v157054_v15 = vmov -0.00020021426 /* materialized constant */ (stack69)
        %v1256_v25 = vsel /*vm=*/%vm1219_vm4, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %vm1264_vm7 = vcmp.eq.f32.partialorder %v123035_v16, inf (stack70)
        %vm1266_vm8 = vcmp.eq.f32.partialorder %v123035_v16, 0.0 (stack71)
        %v1267_v32 = vand.u32 2147483648, %v123035_v16 (stack72)
        %v123155_v24 = vsel /*vm=*/%vm1706_vm6, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157049_v44 (stack44)
        %v123158_v56 = vadd.f32 -2.5, %v123101_v13 (stack53)
        %v123163_v28 = vsel /*vm=*/%vm733_vm2, /*on_true_vy=*/%v123029_v61, /*on_false_vx=*/%v785_v26 (stack44)
        %v123168_v61 = vsel /*vm=*/%vm1706_vm6, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v2176_v26 = vxor.u32 2147483648, %v123125_v40 (stack56)
        %v2575_v31 = vor.u32 %v2574_v9, %v2573_v31 (stack47)
        %vm3833_vm9 = vcmp.lt.u32.totalorder %v122972_v8, %v122920_v60 (stack43)
        %v793_v54 = vmul.f32 %v123163_v28, %v770_v54 (stack54)
        %v123177_v9 = vsel /*vm=*/%vm1706_vm6, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v2999_v42 = vxor.u32 %v2998_v42, %v123037_v43 (stack48)
        %v3421_v7 = vadd.s32 %v3418_v7, %v121564_v0 (stack40)
        %v120442_v22 = vpop.eup %120441 (stack73)
        %v1743_v44 = vsel /*vm=*/%vm1706_vm6, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %vm1751_vm10 = vcmp.eq.f32.partialorder %v123101_v13, inf (stack70)
        %v1754_v49 = vand.u32 2147483648, %v123101_v13 (stack72)
        %v2179_v26 = vmul.f32 %v2176_v26, %v123125_v40 (stack54)
        %v2576_v31 = vxor.u32 %v2575_v31, %v2567_v37 (stack48)
        %v797_v57 = vadd.f32 %v793_v54, %v766_v57 (stack53)
        %v1263_v22 = vmul.f32 %v120442_v22, %v123035_v16 (stack74)
        %vm1753_vm11 = vcmp.eq.f32.partialorder %v123101_v13, 0.0 (stack71)
        %v3002_v43 = vadd.s32 %v2999_v42, %v123037_v43 (stack40)
        %v3004_v54 = vshll.u32 %v2999_v42, 26 (stack45)
        %v2181_v34 = vadd.f32 1.0, %v2179_v26 (stack57)
        %v2184_v23 = vmul.f32 -0.5, %v2179_v26 (stack59)
        %v2571_v37 = vadd.s32 %v2567_v37, %v121569_v1 (stack40)
        %v2579_v31 = vadd.s32 %v2576_v31, %v121564_v0 (stack40)
        %v801_v57 = vmul.f32 %v797_v57, %v123163_v28 (stack54)
        %v1265_v22 = vsel /*vm=*/%vm1264_vm7, /*on_true_vy=*/%v123035_v16, /*on_false_vx=*/%v1263_v22 (stack75)
        %v3005_v42 = vshrl.u32 %v2999_v42, 6 (stack46)
        %v3425_v7 = vadd.s32 1, %v3421_v7 (stack40)
        %v1268_v32 = vsel /*vm=*/%vm1266_vm8, /*on_true_vy=*/%v1267_v32, /*on_false_vx=*/%v1265_v22 (stack76)
        %120445 = vlog2.f32 %v2181_v34 (stack58)
        %v2187_v34 = vand.u32 2147483647, %v2179_v26 (stack60)
        %v3855_v22 = vadd.s32 1, %v123000_v55 (stack40)
        %v805_v48 = vadd.f32 %v801_v57, %v123076_v48 (stack53)
        %v1271_v57 = vadd.f32 -3.0, %v1268_v32 (stack53)
        %v2583_v31 = vadd.s32 4, %v2579_v31 (stack40)
        %v3006_v54 = vor.u32 %v3005_v42, %v3004_v54 (stack47)
        %v120444_v42 = vpop.eup %120443 (stack73)
        %v2185_v23 = vadd.f32 1.0, %v2184_v23 (stack61)
        %v3429_v14 = vadd.s32 %v3425_v7, %v123091_v14 (stack40)
        %v3431_v32 = vshll.u32 %v3425_v7, 17 (stack45)
        %v3432_v7 = vshrl.u32 %v3425_v7, 15 (stack46)
        %v809_v48 = vmul.f32 %v805_v48, %v123163_v28 (stack54)
        %v123205_v36 = vsel /*vm=*/%vm1219_vm4, /*on_true_vy=*/%v123099_v36, /*on_false_vx=*/%v1271_v57 (stack44)
        %v1750_v16 = vmul.f32 %v120444_v42, %v123101_v13 (stack74)
        %v2587_v37 = vadd.s32 %v2583_v31, %v2571_v37 (stack40)
        %v1279_v25 = vmul.f32 %v123205_v36, %v1256_v25 (stack54)
        %v2589_v57 = vshll.u32 %v2583_v31, 13 (stack45)
        %v2590_v31 = vshrl.u32 %v2583_v31, 19 (stack46)
        %v3007_v54 = vxor.u32 %v3006_v54, %v3002_v43 (stack48)
        %v813_v46 = vadd.f32 %v809_v48, %v123071_v46 (stack53)
        %v1752_v42 = vsel /*vm=*/%vm1751_vm10, /*on_true_vy=*/%v123101_v13, /*on_false_vx=*/%v1750_v16 (stack75)
        %v3433_v32 = vor.u32 %v3432_v7, %v3431_v32 (stack47)
        %v3859_v60 = vsel /*vm=*/%vm3833_vm9, /*on_true_vy=*/%v3855_v22, /*on_false_vx=*/%v123000_v55 (stack44)
        %v1283_v27 = vadd.f32 %v1279_v25, %v1252_v27 (stack53)
        %v1755_v49 = vsel /*vm=*/%vm1753_vm11, /*on_true_vy=*/%v1754_v49, /*on_false_vx=*/%v1752_v42 (stack76)
        %v2591_v8 = vor.u32 %v2590_v31, %v2589_v57 (stack47)
        %v3010_v55 = vadd.s32 %v3007_v54, %v3002_v43 (stack40)
        %v817_v43 = vmul.f32 %v813_v46, %v123163_v28 (stack54)
        %v1758_v22 = vadd.f32 -3.0, %v1755_v49 (stack53)
        %vm123220_vm12 = vcmp.lt.f32.partialorder %v2187_v34, 0.0004427343 (stack62)
        %v3016_v7 = vshll.u32 %v3007_v54, 6 (stack45)
        %v3017_v48 = vshrl.u32 %v3007_v54, 26 (stack46)
        %v1287_v16 = vmul.f32 %v1283_v27, %v123205_v36 (stack54)
        %v2186_v26 = vmul.f32 %v2185_v23, %v2179_v26 (stack63)
        %v2592_v23 = vxor.u32 %v2591_v8, %v2587_v37 (stack48)
        %v3434_v25 = vxor.u32 %v3433_v32, %v3429_v14 (stack48)
        %v821_v53 = vadd.f32 %v817_v43, %v123065_v53 (stack53)
        %v123229_v56 = vsel /*vm=*/%vm1706_vm6, /*on_true_vy=*/%v123158_v56, /*on_false_vx=*/%v1758_v22 (stack44)
        %v3018_v57 = vor.u32 %v3017_v48, %v3016_v7 (stack47)
        %v3864_v31 = vadd.s32 %v3859_v60, %v121574_v2 (stack40)
        %v1291_v6 = vadd.f32 %v1287_v16, %v123141_v6 (stack53)
        %v1766_v44 = vmul.f32 %v123229_v56, %v1743_v44 (stack54)
        %v2595_v37 = vadd.s32 %v2592_v23, %v2587_v37 (stack40)
        %v2597_v54 = vshll.u32 %v2592_v23, 15 (stack45)
        %v825_v46 = vmul.f32 %v821_v53, %v123163_v28 (stack54)
        %v2598_v42 = vshrl.u32 %v2592_v23, 17 (stack46)
        %v3019_v32 = vxor.u32 %v3018_v57, %v3010_v55 (stack48)
        %v123235_v14 = vadd.s32 %v3434_v25, %v3429_v14 (stack40)
        %v1295_v60 = vmul.f32 %v1291_v6, %v123205_v36 (stack54)
        %v1770_v9 = vadd.f32 %v1766_v44, %v123177_v9 (stack53)
        %v3439_v27 = vshll.u32 %v3434_v25, 29 (stack45)
        %v3440_v49 = vshrl.u32 %v3434_v25, 3 (stack46)
        %v120446_v8 = vpop.eup %120445 (stack64)
        %v829_v50 = vadd.f32 %v825_v46, %v123060_v50 (stack53)
        %v2599_v43 = vor.u32 %v2598_v42, %v2597_v54 (stack47)
        %v3022_v22 = vadd.s32 %v3019_v32, %v121569_v1 (stack40)
        %v123242_v7 = vadd.s32 %v123008_v20, %v3864_v31 (stack40)
        %v1299_v17 = vadd.f32 %v1295_v60, %v123136_v17 (stack53)
        %v1774_v48 = vmul.f32 %v1770_v9, %v123229_v56 (stack54)
        %v2183_v16 = vmul.f32 0.6931472, %v120446_v8 (stack65)
        %v3441_v23 = vor.u32 %v3440_v49, %v3439_v27 (stack47)
        %v833_v25 = vmul.f32 %v829_v50, %v123163_v28 (stack54)
        %v2600_v53 = vxor.u32 %v2599_v43, %v2595_v37 (stack48)
        %v3014_v55 = vadd.s32 %v3010_v55, %v121574_v2 (stack40)
        %v3026_v57 = vadd.s32 3, %v3022_v22 (stack40)
        %v1303_v31 = vmul.f32 %v1299_v17, %v123205_v36 (stack54)
        %v1778_v61 = vadd.f32 %v1774_v48, %v123168_v61 (stack53)
        %v2189_v34 = vsel /*vm=*/%vm123220_vm12, /*on_true_vy=*/%v2186_v26, /*on_false_vx=*/%v2183_v16 (stack66)
        %v123253_v26 = vxor.u32 %v3441_v23, %v123235_v14 (stack48)
        %v837_v12 = vadd.f32 %v833_v25, %v123055_v12 (stack53)
        %v123259_v6 = vsel /*vm=*/%vm1706_vm6, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v123261_v44 = vxor.u32 2147483648, %v2189_v34 (stack56)
        %v2603_v37 = vadd.s32 %v2600_v53, %v2595_v37 (stack40)
        %v1307_v38 = vadd.f32 %v1303_v31, %v123122_v38 (stack53)
        %v123267_v54 = vsel /*vm=*/%vm1706_vm6, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %s157057_s27 = sld [smem:[#allocation6_spill]] (stack21)
        %v1782_v46 = vmul.f32 %v1778_v61, %v123229_v56 (stack54)
        %v123270_v42 = vadd.s32 %v3026_v57, %v3014_v55 (stack40)
        %v841_v32 = vmul.f32 %v837_v12, %v123163_v28 (stack54)
        %v1731_v60 = vsel /*vm=*/%vm1706_vm6, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %120447 = vrsqrt.f32 %v123261_v44 (stack67)
        %v3875_v9 = vshrl.u32 %v123008_v20, 19 (stack46)
        %v157058_v27 = vand.u32 2147483647, %v122943_v41 (stack77)
        %vm123280_vm13 = vcmp.eq.f32.partialorder %v157058_v27, 1.0 (stack68)
        %v1311_v8 = vmul.f32 %v1307_v38, %v123205_v36 (stack54)
        %v1723_v50 = vsel /*vm=*/%vm1706_vm6, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v1786_v43 = vadd.f32 %v1782_v46, %v1731_v60 (stack53)
        %vm2193_vm14 = vcmp.lt.f32.partialorder %v123261_v44, 5.0 (stack68)
        %v845_v10 = vadd.f32 %v841_v32, %v123047_v10 (stack53)
        %v1727_v13 = vsel /*vm=*/%vm1706_vm6, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v2605_v22 = vshll.u32 %v2600_v53, 26 (stack45)
        %v2606_v17 = vshrl.u32 %v2600_v53, 6 (stack46)
        %s119739_s2 = sadd.s32 4294967295, %s157057_s27 (stack78)
        %v1315_v30 = vadd.f32 %v1311_v8, %v123117_v30 (stack53)
        %v1790_v48 = vmul.f32 %v1786_v43, %v123229_v56 (stack54)
        %v2166_v16 = vand.u32 2147483647, %v123125_v40 (stack77)
        %v123298_v23 = vmul.f32 inf, %v123125_v40 (stack54)
        %v849_v28 = vmul.f32 %v845_v10, %v123163_v28 (stack54)
        %v123304_v25 = vsel /*vm=*/%vm2193_vm14, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v123307_v53 = vadd.f32 -2.5, %v123261_v44 (stack53)
        %v157061_v20 = vshll.u32 %v123008_v20, 13 (stack45)
        %v3876_v55 = vor.u32 %v3875_v9, %v157061_v20 (stack47)
        %v1319_v31 = vmul.f32 %v1315_v30, %v123205_v36 (stack54)
        %v1794_v61 = vadd.f32 %v1790_v48, %v1727_v13 (stack53)
        %v123315_v34 = vsel /*vm=*/%vm2193_vm14, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v2241_v12 = vand.u32 2147483648, %v123261_v44 (stack72)
        %s123318_s25 = sand.u32 1, %s119739_s2 /* smod.u32 w/div 2 */ (stack79)
        %v853_v45 = vadd.f32 %v849_v28, %v123042_v45 (stack53)
        %v2607_v38 = vor.u32 %v2606_v17, %v2605_v22 (stack47)
        %v3032_v46 = vshll.u32 %v3026_v57, 17 (stack45)
        %v3033_v57 = vshrl.u32 %v3026_v57, 15 (stack46)
        %v1323_v35 = vadd.f32 %v1319_v31, %v123112_v35 (stack53)
        %v1798_v32 = vmul.f32 %v1794_v61, %v123229_v56 (stack54)
        %vm2238_vm15 = vcmp.eq.f32.partialorder %v123261_v44, inf (stack70)
        %v3445_v14 = vadd.s32 %v123253_v26, %v123235_v14 (stack40)
        %v3447_v60 = vshll.u32 %v123253_v26, 16 (stack45)
        %v857_v41 = vmul.f32 %v853_v45, %v122943_v41 (stack54)
        %vm2240_vm0 = vcmp.eq.f32.partialorder %v123261_v44, 0.0 (stack71)
        %v2608_v9 = vxor.u32 %v2607_v38, %v2603_v37 (stack48)
        %v3034_v27 = vor.u32 %v3033_v57, %v3032_v46 (stack47)
        %v3448_v26 = vshrl.u32 %v123253_v26, 16 (stack46)
        %s119740_s8 = sshll.u32 %s123318_s25, 10 (stack80)
        %v1327_v8 = vmul.f32 %v1323_v35, %v123205_v36 (stack54)
        %v1802_v50 = vadd.f32 %v1798_v32, %v1723_v50 (stack53)
        %v3877_v43 = vxor.u32 %v3876_v55, %v123242_v7 (stack48)
        %v123335_v10 = vadd.s32 %v122703_v29, %v122651_v47 (stack40)
        %v861_v59 = vsel /*vm=*/%vm123280_vm13, /*on_true_vy=*/%v122976_v59, /*on_false_vx=*/%v857_v41 (stack44)
        %v157062_v49 = vand.u32 2147483647, %v122952_v62 (stack77)
        %vm123342_vm1 = vcmp.eq.f32.partialorder %v157062_v49, 1.0 (stack68)
        %v2611_v37 = vadd.s32 %v2608_v9, %v2603_v37 (stack40)
        %v2617_v22 = vshll.u32 %v2608_v9, 6 (stack45)
        %v2618_v17 = vshrl.u32 %v2608_v9, 26 (stack46)
        %v865_v30 = vmul.f32 1.4140625, %v861_v59 (stack54)
        %v1331_v39 = vadd.f32 %v1327_v8, %v123107_v39 (stack53)
        %v1806_v48 = vmul.f32 %v1802_v50, %v123229_v56 (stack54)
        %v3035_v28 = vxor.u32 %v3034_v27, %v123270_v42 (stack48)
        %v2615_v20 = vadd.s32 %v2611_v37, %v121564_v0 (stack40)
        %v2619_v55 = vor.u32 %v2618_v17, %v2617_v22 (stack47)
        %v3449_v31 = vor.u32 %v3448_v26, %v3447_v60 (stack47)
        %v3880_v7 = vadd.s32 %v3877_v43, %v123242_v7 (stack40)
        %v120448_v61 = vpop.eup %120447 (stack73)
        %v156663_v45 = vmov 0.0 /* materialized constant */ (stack69)
        %v867_v38 = vpack.c.bf16 %v156663_v45, %v865_v30 (stack81)
        %v1335_v36 = vmul.f32 %v1331_v39, %v123205_v36 (stack54)
        %v1810_v54 = vadd.f32 %v1806_v48, %v123267_v54 (stack53)
        %v3038_v42 = vadd.s32 %v3035_v28, %v123270_v42 (stack40)
        %v2237_v46 = vmul.f32 %v120448_v61, %v123261_v44 (stack74)
        %v2620_v57 = vxor.u32 %v2619_v55, %v2611_v37 (stack48)
        %v3040_v35 = vshll.u32 %v3035_v28, 29 (stack45)
        %v3041_v32 = vshrl.u32 %v3035_v28, 3 (stack46)
        %s123356_s30 = scalar_lea.vmem [#allocation0], %s119740_s8 (stack82)
        %868 = vst [vmem:[%s123356_s30] sm:$0xf] /*vst_source=*/%v867_v38 (stack83)
        %v1339_v21 = vadd.f32 %v1335_v36, %v123096_v21 (stack53)
        %v1814_v60 = vmul.f32 %v1810_v54, %v123229_v56 (stack54)
        %v3450_v41 = vxor.u32 %v3449_v31, %v3445_v14 (stack48)
        %v3882_v9 = vshll.u32 %v3877_v43, 15 (stack45)
        %v157065_v27 = vand.u32 2147483647, %v122958_v11 (stack77)
        %vm123363_vm2 = vcmp.eq.f32.partialorder %v157065_v27, 1.0 (stack68)
        %v2239_v8 = vsel /*vm=*/%vm2238_vm15, /*on_true_vy=*/%v123261_v44, /*on_false_vx=*/%v2237_v46 (stack75)
        %v2623_v50 = vadd.s32 %v2620_v57, %v121574_v2 (stack40)
        %v3042_v59 = vor.u32 %v3041_v32, %v3040_v35 (stack47)
        %v3883_v43 = vshrl.u32 %v3877_v43, 17 (stack46)
        %v1343_v62 = vmul.f32 %v1339_v21, %v122952_v62 (stack54)
        %v1818_v6 = vadd.f32 %v1814_v60, %v123259_v6 (stack53)
        %v2242_v12 = vsel /*vm=*/%vm2240_vm0, /*on_true_vy=*/%v2241_v12, /*on_false_vx=*/%v2239_v8 (stack76)
        %v3453_v14 = vadd.s32 %v3450_v41, %v3445_v14 (stack40)
        %v2245_v49 = vadd.f32 -3.0, %v2242_v12 (stack53)
        %v2627_v37 = vadd.s32 5, %v2623_v50 (stack40)
        %v3043_v22 = vxor.u32 %v3042_v59, %v3038_v42 (stack48)
        %v3459_v17 = vshll.u32 %v3450_v41, 24 (stack45)
        %v1347_v52 = vsel /*vm=*/%vm123342_vm1, /*on_true_vy=*/%v123011_v52, /*on_false_vx=*/%v1343_v62 (stack44)
        %v1822_v56 = vmul.f32 %v1818_v6, %v123229_v56 (stack54)
        %v2230_v13 = vsel /*vm=*/%vm2193_vm14, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v3460_v30 = vshrl.u32 %v3450_v41, 8 (stack46)
        %v1351_v39 = vmul.f32 1.4140625, %v1347_v52 (stack54)
        %v123385_v53 = vsel /*vm=*/%vm2193_vm14, /*on_true_vy=*/%v123307_v53, /*on_false_vx=*/%v2245_v49 (stack44)
        %v2629_v48 = vxor.u32 %v2627_v37, %v2615_v20 (stack48)
        %v3046_v28 = vadd.s32 %v3043_v22, %v3038_v42 (stack40)
        %v1826_v24 = vadd.f32 %v1822_v56, %v123155_v24 (stack53)
        %v2253_v20 = vmul.f32 %v123385_v53, %v2230_v13 (stack54)
        %v3048_v55 = vshll.u32 %v3043_v22, 16 (stack45)
        %v3049_v31 = vshrl.u32 %v3043_v22, 16 (stack46)
        %v1354_v61 = vpack.c.bf16 %v156663_v45, %v1351_v39 (stack81)
        %v2630_v38 = vand.u32.u8 255, %v2629_v48 (stack49)
        %v3461_v36 = vor.u32 %v3460_v30, %v3459_v17 (stack47)
        %v3884_v54 = vor.u32 %v3883_v43, %v3882_v9 (stack47)
        %v1830_v11 = vmul.f32 %v1826_v24, %v122958_v11 (stack54)
        %v2222_v42 = vsel /*vm=*/%vm2193_vm14, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v2257_v34 = vadd.f32 %v2253_v20, %v123315_v34 (stack53)
        %v3050_v46 = vor.u32 %v3049_v31, %v3048_v55 (stack47)
        %119751 = vst [vmem:[%s123356_s30 + $0x80] sm:$0xf] /*vst_source=*/%v1354_v61 (stack83)
        %v2631_v57 = vand.u32 65535, %v2630_v38 (stack50)
        %v3462_v35 = vxor.u32 %v3461_v36, %v3453_v14 (stack48)
        %v3885_v32 = vxor.u32 %v3884_v54, %v3880_v7 (stack48)
        %vm4333_vm3 = vcmp.lt.u32.totalorder %v123335_v10, %v122651_v47 (stack43)
        %v1834_v51 = vsel /*vm=*/%vm123363_vm2, /*on_true_vy=*/%v123015_v51, /*on_false_vx=*/%v1830_v11 (stack44)
        %v2261_v21 = vmul.f32 %v2257_v34, %v123385_v53 (stack54)
        %v3051_v60 = vxor.u32 %v3050_v46, %v3046_v28 (stack48)
        %v3457_v41 = vadd.s32 %v3453_v14, %v121564_v0 (stack40)
        %v1838_v9 = vmul.f32 1.4140625, %v1834_v51 (stack54)
        %v2632_v27 = vshrl.u32 %v2631_v57, 1 (stack51)
        %v3465_v26 = vadd.s32 %v3462_v35, %v121574_v2 (stack40)
        %v3888_v7 = vadd.s32 %v3885_v32, %v3880_v7 (stack40)
        %v2265_v8 = vadd.f32 %v2261_v21, %v2222_v42 (stack53)
        %v3054_v50 = vadd.s32 %v3051_v60, %v3046_v28 (stack40)
        %v3060_v59 = vshll.u32 %v3051_v60, 24 (stack45)
        %v3061_v43 = vshrl.u32 %v3051_v60, 8 (stack46)
        %v1841_v62 = vpack.c.bf16 %v156663_v45, %v1838_v9 (stack81)
        %v2633_v6 = vor.u32 16256, %v2632_v27 (stack47)
        %v3469_v12 = vadd.s32 2, %v3465_v26 (stack40)
        %v3890_v14 = vshll.u32 %v3885_v32, 26 (stack45)
        %v2269_v49 = vmul.f32 %v2265_v8, %v123385_v53 (stack54)
        %v3062_v37 = vor.u32 %v3061_v43, %v3060_v59 (stack47)
        %v3891_v22 = vshrl.u32 %v3885_v32, 6 (stack46)
        %v123408_v17 = vadd.s32 %v123335_v10, %v122657_v58 (stack40)
        %119753 = vst [vmem:[%s123356_s30 + $0x100] sm:$0xf] /*vst_source=*/%v1841_v62 (stack83)
        %v2634_v52 = vand.u32.u16 65535, %v2633_v6 (stack52)
        %v3473_v56 = vadd.s32 %v3469_v12, %v3457_v41 (stack40)
        %v3475_v13 = vshll.u32 %v3469_v12, 13 (stack45)
        %v3476_v30 = vshrl.u32 %v3469_v12, 19 (stack46)
        %v2273_v25 = vadd.f32 %v2269_v49, %v123304_v25 (stack53)
        %v3063_v39 = vxor.u32 %v3062_v37, %v3054_v50 (stack48)
        %v3892_v48 = vor.u32 %v3891_v22, %v3890_v14 (stack47)
        %v157068_v28 = vld [vmem:[#allocation44_spill] sm:$0xff] (stack84)
        %v157069_v24 = vld [vmem:[#allocation57_spill] sm:$0xff] (stack84)
        %v4338_v20 = vadd.s32 %v157069_v24, %v157068_v28 (stack40)
        %v2214_v55 = vsel /*vm=*/%vm2193_vm14, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v119756_v31 = vadd.low.f32.bf16 -1.0, %v2634_v52 (stack53)
        %v3477_v61 = vor.u32 %v3476_v30, %v3475_v13 (stack47)
        %v157070_v38 = vld [vmem:[#allocation119_spill] sm:$0xff] (stack84)
        %v123419_v36 = vadd.s32 %v122703_v29, %v157070_v38 (stack40)
        %v2277_v54 = vmul.f32 %v2273_v25, %v123385_v53 (stack54)
        %v3058_v11 = vadd.s32 %v3054_v50, %v121569_v1 (stack40)
        %v3066_v42 = vadd.s32 %v3063_v39, %v121564_v0 (stack40)
        %v3893_v34 = vxor.u32 %v3892_v48, %v3888_v7 (stack48)
        %v2643_v46 = vmul.f32 2.0, %v119756_v31 (stack54)
        %v3478_v57 = vxor.u32 %v3477_v61, %v3473_v56 (stack48)
        %v4342_v35 = vadd.s32 1, %v4338_v20 (stack40)
        %v123426_v32 = vadd.s32 %v123408_v17, %v121569_v1 (stack40)
        %v2281_v51 = vadd.f32 %v2277_v54, %v2214_v55 (stack53)
        %v3070_v21 = vadd.s32 4, %v3066_v42 (stack40)
        %v3896_v60 = vadd.s32 %v3893_v34, %v3888_v7 (stack40)
        %v3902_v41 = vshll.u32 %v3893_v34, 6 (stack45)
        %v2647_v9 = vadd.f32 -0.99609375, %v2643_v46 (stack53)
        %v3481_v27 = vadd.s32 %v3478_v57, %v3473_v56 (stack40)
        %v3483_v26 = vshll.u32 %v3478_v57, 15 (stack45)
        %v3484_v7 = vshrl.u32 %v3478_v57, 17 (stack46)
        %v2285_v8 = vmul.f32 %v2281_v51, %v123385_v53 (stack54)
        %v3074_v50 = vadd.s32 %v3070_v21, %v3058_v11 (stack40)
        %v3076_v59 = vshll.u32 %v3070_v21, 13 (stack45)
        %v3077_v43 = vshrl.u32 %v3070_v21, 19 (stack46)
        %v2210_v62 = vsel /*vm=*/%vm2193_vm14, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v123432_v6 = vmax.f32 %v2647_v9, -0.99609375 (stack55)
        %v3485_v12 = vor.u32 %v3484_v7, %v3483_v26 (stack47)
        %v3903_v14 = vshrl.u32 %v3893_v34, 26 (stack46)
        %v2206_v49 = vsel /*vm=*/%vm2193_vm14, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v2289_v37 = vadd.f32 %v2285_v8, %v2210_v62 (stack53)
        %v3078_v22 = vor.u32 %v3077_v43, %v3076_v59 (stack47)
        %v4346_v52 = vsel /*vm=*/%vm4333_vm3, /*on_true_vy=*/%v4342_v35, /*on_false_vx=*/%v4338_v20 (stack44)
        %v2663_v56 = vxor.u32 2147483648, %v123432_v6 (stack56)
        %v3486_v13 = vxor.u32 %v3485_v12, %v3481_v27 (stack48)
        %vm4328_vm4 = vcmp.lt.u32.totalorder %v123408_v17, %v123335_v10 (stack43)
        %v4369_v30 = vshll.u32 %v123426_v32, 13 (stack45)
        %v2293_v25 = vmul.f32 %v2289_v37, %v123385_v53 (stack54)
        %v3079_v39 = vxor.u32 %v3078_v22, %v3074_v50 (stack48)
        %v3904_v48 = vor.u32 %v3903_v14, %v3902_v41 (stack47)
        %v4350_v20 = vadd.s32 1, %v4346_v52 (stack40)
        %v2666_v55 = vmul.f32 %v2663_v56, %v123432_v6 (stack54)
        %v3489_v31 = vadd.s32 %v3486_v13, %v3481_v27 (stack40)
        %v3491_v61 = vshll.u32 %v3486_v13, 26 (stack45)
        %v4370_v54 = vshrl.u32 %v123426_v32, 19 (stack46)
        %v2297_v11 = vadd.f32 %v2293_v25, %v2206_v49 (stack53)
        %v3082_v42 = vadd.s32 %v3079_v39, %v3074_v50 (stack40)
        %v3084_v34 = vshll.u32 %v3079_v39, 15 (stack45)
        %v3085_v46 = vshrl.u32 %v3079_v39, 17 (stack46)
        %v157071_v57 = vmov 2.8329768 /* materialized constant */ (stack69)
        %v2198_v35 = vsel /*vm=*/%vm2193_vm14, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v2202_v44 = vsel /*vm=*/%vm2193_vm14, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v2668_v51 = vadd.f32 1.0, %v2666_v55 (stack57)
        %v3492_v21 = vshrl.u32 %v3486_v13, 6 (stack46)
        %v2301_v41 = vmul.f32 %v2297_v11, %v123385_v53 (stack54)
        %v3086_v9 = vor.u32 %v3085_v46, %v3084_v34 (stack47)
        %v3905_v27 = vxor.u32 %v3904_v48, %v3896_v60 (stack48)
        %v4354_v10 = vsel /*vm=*/%vm4328_vm4, /*on_true_vy=*/%v4350_v20, /*on_false_vx=*/%v4346_v52 (stack44)
        %120449 = vlog2.f32 %v2668_v51 (stack58)
        %v3493_v17 = vor.u32 %v3492_v21, %v3491_v61 (stack47)
        %v3900_v60 = vadd.s32 %v3896_v60, %v121569_v1 (stack40)
        %v4371_v26 = vor.u32 %v4370_v54, %v4369_v30 (stack47)
        %v2305_v7 = vadd.f32 %v2301_v41, %v2202_v44 (stack53)
        %v3087_v8 = vxor.u32 %v3086_v9, %v3082_v42 (stack48)
        %v3908_v50 = vadd.s32 %v3905_v27, %v121564_v0 (stack40)
        %v4359_v59 = vadd.s32 %v4354_v10, %v121574_v2 (stack40)
        %v2671_v43 = vmul.f32 -0.5, %v2666_v55 (stack59)
        %v2674_v62 = vand.u32 2147483647, %v2666_v55 (stack60)
        %v3494_v12 = vxor.u32 %v3493_v17, %v3489_v31 (stack48)
        %vm4794_vm5 = vcmp.lt.u32.totalorder %v123419_v36, %v157070_v38 (stack43)
        %v2309_v53 = vmul.f32 %v2305_v7, %v123385_v53 (stack54)
        %v3090_v14 = vadd.s32 %v3087_v8, %v3082_v42 (stack40)
        %v3092_v49 = vshll.u32 %v3087_v8, 26 (stack45)
        %v3093_v37 = vshrl.u32 %v3087_v8, 6 (stack46)
        %v3497_v22 = vadd.s32 %v3494_v12, %v3489_v31 (stack40)
        %v3503_v52 = vshll.u32 %v3494_v12, 6 (stack45)
        %v3504_v56 = vshrl.u32 %v3494_v12, 26 (stack46)
        %v3912_v13 = vadd.s32 1, %v3908_v50 (stack40)
        %vm123465_vm6 = vcmp.eq.f32.partialorder %v2166_v16, 1.0 (stack68)
        %v2313_v30 = vadd.f32 %v2309_v53, %v2198_v35 (stack53)
        %v3094_v25 = vor.u32 %v3093_v37, %v3092_v49 (stack47)
        %v4367_v32 = vadd.s32 %v123426_v32, %v4359_v59 (stack40)
        %v2672_v39 = vadd.f32 1.0, %v2671_v43 (stack61)
        %v3505_v48 = vor.u32 %v3504_v56, %v3503_v52 (stack47)
        %v3916_v20 = vadd.s32 %v3912_v13, %v3900_v60 (stack40)
        %v3918_v31 = vshll.u32 %v3912_v13, 17 (stack45)
        %v2317_v40 = vmul.f32 %v2313_v30, %v123125_v40 (stack54)
        %vm123471_vm7 = vcmp.lt.f32.partialorder %v2674_v62, 0.0004427343 (stack62)
        %v3095_v54 = vxor.u32 %v3094_v25, %v3090_v14 (stack48)
        %v3919_v11 = vshrl.u32 %v3912_v13, 15 (stack46)
        %v4372_v42 = vxor.u32 %v4371_v26, %v4367_v32 (stack48)
        %v3506_v34 = vxor.u32 %v3505_v48, %v3497_v22 (stack48)
        %v123477_v46 = vadd.s32 %v123419_v36, %v122657_v58 (stack40)
        %v157076_v35 = vld [vmem:[#allocation43_spill] sm:$0xff] (stack84)
        %v4799_v44 = vadd.s32 %v157069_v24, %v157076_v35 (stack40)
        %v157077_v51 = vld [vmem:[#allocation117_spill] sm:$0xff] (stack84)
        %v123483_v21 = vadd.s32 %v122703_v29, %v157077_v51 (stack40)
        %v2321_v23 = vsel /*vm=*/%vm123465_vm6, /*on_true_vy=*/%v123298_v23, /*on_false_vx=*/%v2317_v40 (stack44)
        %v3098_v41 = vadd.s32 %v3095_v54, %v3090_v14 (stack40)
        %v3104_v9 = vshll.u32 %v3095_v54, 6 (stack45)
        %v3105_v27 = vshrl.u32 %v3095_v54, 26 (stack46)
        %v2325_v10 = vmul.f32 1.4140625, %v2321_v23 (stack54)
        %v3509_v17 = vadd.s32 %v3506_v34, %v121569_v1 (stack40)
        %v3920_v60 = vor.u32 %v3919_v11, %v3918_v31 (stack47)
        %v4375_v26 = vadd.s32 %v4372_v42, %v4367_v32 (stack40)
        %v2673_v55 = vmul.f32 %v2672_v39, %v2666_v55 (stack63)
        %v3106_v7 = vor.u32 %v3105_v27, %v3104_v9 (stack47)
        %v4377_v8 = vshll.u32 %v4372_v42, 15 (stack45)
        %v4378_v50 = vshrl.u32 %v4372_v42, 17 (stack46)
        %v2328_v59 = vpack.c.bf16 %v156663_v45, %v2325_v10 (stack81)
        %v3501_v43 = vadd.s32 %v3497_v22, %v121574_v2 (stack40)
        %v3513_v62 = vadd.s32 3, %v3509_v17 (stack40)
        %v3921_v12 = vxor.u32 %v3920_v60, %v3916_v20 (stack48)
        %v120450_v53 = vpop.eup %120449 (stack64)
        %v3107_v14 = vxor.u32 %v3106_v7, %v3098_v41 (stack48)
        %v4379_v49 = vor.u32 %v4378_v50, %v4377_v8 (stack47)
        %v4803_v37 = vadd.s32 1, %v4799_v44 (stack40)
        %v4824_v22 = vadd.s32 %v123477_v46, %v121569_v1 (stack40)
        %119755 = vst [vmem:[%s123356_s30 + $0x180] sm:$0xf] /*vst_source=*/%v2328_v59 (stack83)
        %v2670_v52 = vmul.f32 0.6931472, %v120450_v53 (stack65)
        %v3517_v56 = vadd.s32 %v3513_v62, %v3501_v43 (stack40)
        %v3519_v13 = vshll.u32 %v3513_v62, 17 (stack45)
        %v3520_v16 = vshrl.u32 %v3513_v62, 15 (stack46)
        %v3110_v30 = vadd.s32 %v3107_v14, %v121574_v2 (stack40)
        %v3924_v25 = vadd.s32 %v3921_v12, %v3916_v20 (stack40)
        %v3926_v32 = vshll.u32 %v3921_v12, 29 (stack45)
        %v3927_v39 = vshrl.u32 %v3921_v12, 3 (stack46)
        %v2676_v48 = vsel /*vm=*/%vm123471_vm7, /*on_true_vy=*/%v2673_v55, /*on_false_vx=*/%v2670_v52 (stack66)
        %v3521_v20 = vor.u32 %v3520_v16, %v3519_v13 (stack47)
        %v4380_v31 = vxor.u32 %v4379_v49, %v4375_v26 (stack48)
        %v4807_v40 = vsel /*vm=*/%vm4794_vm5, /*on_true_vy=*/%v4803_v37, /*on_false_vx=*/%v4799_v44 (stack44)
        %v123500_v61 = vxor.u32 2147483648, %v2676_v48 (stack56)
        %v3114_v54 = vadd.s32 5, %v3110_v30 (stack40)
        %v3102_v11 = vadd.s32 %v3098_v41, %v121564_v0 (stack40)
        %v3522_v42 = vxor.u32 %v3521_v20, %v3517_v56 (stack48)
        %v3928_v34 = vor.u32 %v3927_v39, %v3926_v32 (stack47)
        %v4383_v44 = vadd.s32 %v4380_v31, %v4375_v26 (stack40)
        %v2653_v23 = vand.u32 2147483647, %v123432_v6 (stack77)
        %vm2680_vm8 = vcmp.lt.f32.partialorder %v123500_v61, 5.0 (stack68)
        %120451 = vrsqrt.f32 %v123500_v61 (stack67)
        %v123507_v41 = vmul.f32 inf, %v123432_v6 (stack54)
        %v3116_v9 = vxor.u32 %v3114_v54, %v3102_v11 (stack48)
        %vm4789_vm9 = vcmp.lt.u32.totalorder %v123477_v46, %v123419_v36 (stack43)
        %v4830_v27 = vshll.u32 %v4824_v22, 13 (stack45)
        %v3525_v10 = vadd.s32 %v3522_v42, %v3517_v56 (stack40)
        %v4385_v17 = vshll.u32 %v4380_v31, 26 (stack45)
        %v4386_v60 = vshrl.u32 %v4380_v31, 6 (stack46)
        %v4811_v26 = vadd.s32 1, %v4807_v40 (stack40)
        %v123514_v55 = vsel /*vm=*/%vm2680_vm8, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v123517_v7 = vadd.f32 -2.5, %v123500_v61 (stack53)
        %v3929_v8 = vxor.u32 %v3928_v34, %v3924_v25 (stack48)
        %v4831_v50 = vshrl.u32 %v4824_v22, 19 (stack46)
        %v123522_v59 = vsel /*vm=*/%vm2680_vm8, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v123527_v43 = vsel /*vm=*/%vm2680_vm8, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v3117_v62 = vand.u32.u8 255, %v3116_v9 (stack49)
        %v3527_v12 = vshll.u32 %v3522_v42, 29 (stack45)
        %v3528_v53 = vshrl.u32 %v3522_v42, 3 (stack46)
        %v3932_v14 = vadd.s32 %v3929_v8, %v3924_v25 (stack40)
        %v3934_v49 = vshll.u32 %v3929_v8, 16 (stack45)
        %v3935_v37 = vshrl.u32 %v3929_v8, 16 (stack46)
        %v123532_v52 = vsel /*vm=*/%vm2680_vm8, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v3118_v56 = vand.u32 65535, %v3117_v62 (stack50)
        %v4387_v13 = vor.u32 %v4386_v60, %v4385_v17 (stack47)
        %v4815_v36 = vsel /*vm=*/%vm4789_vm9, /*on_true_vy=*/%v4811_v26, /*on_false_vx=*/%v4807_v40 (stack44)
        %v2717_v46 = vsel /*vm=*/%vm2680_vm8, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %vm2725_vm10 = vcmp.eq.f32.partialorder %v123500_v61, inf (stack70)
        %v3529_v16 = vor.u32 %v3528_v53, %v3527_v12 (stack47)
        %v3936_v30 = vor.u32 %v3935_v37, %v3934_v49 (stack47)
        %v4820_v25 = vadd.s32 %v4815_v36, %v121574_v2 (stack40)
        %v3119_v32 = vshrl.u32 %v3118_v56, 1 (stack51)
        %v4388_v39 = vxor.u32 %v4387_v13, %v4383_v44 (stack48)
        %vm5255_vm11 = vcmp.lt.u32.totalorder %v123483_v21, %v157077_v51 (stack43)
        %v157078_v48 = vld [vmem:[#allocation47_spill] sm:$0xff] (stack84)
        %v5260_v20 = vadd.s32 %v157069_v24, %v157078_v48 (stack40)
        %v3530_v31 = vxor.u32 %v3529_v16, %v3525_v10 (stack48)
        %v3937_v40 = vxor.u32 %v3936_v30, %v3932_v14 (stack48)
        %v4828_v22 = vadd.s32 %v4824_v22, %v4820_v25 (stack40)
        %v4832_v54 = vor.u32 %v4831_v50, %v4830_v27 (stack47)
        %v3120_v11 = vor.u32 16256, %v3119_v32 (stack47)
        %v4391_v42 = vadd.s32 %v4388_v39, %v4383_v44 (stack40)
        %v4397_v34 = vshll.u32 %v4388_v39, 6 (stack45)
        %v4398_v44 = vshrl.u32 %v4388_v39, 26 (stack46)
        %v3533_v9 = vadd.s32 %v3530_v31, %v3525_v10 (stack40)
        %v3535_v27 = vshll.u32 %v3530_v31, 16 (stack45)
        %v3536_v10 = vshrl.u32 %v3530_v31, 16 (stack46)
        %v3940_v17 = vadd.s32 %v3937_v40, %v3932_v14 (stack40)
        %vm2727_vm12 = vcmp.eq.f32.partialorder %v123500_v61, 0.0 (stack71)
        %v3121_v60 = vand.u32.u16 65535, %v3120_v11 (stack52)
        %v3946_v26 = vshll.u32 %v3937_v40, 24 (stack45)
        %v3947_v8 = vshrl.u32 %v3937_v40, 8 (stack46)
        %v120452_v50 = vpop.eup %120451 (stack73)
        %v2728_v62 = vand.u32 2147483648, %v123500_v61 (stack72)
        %v3537_v12 = vor.u32 %v3536_v10, %v3535_v27 (stack47)
        %v4399_v53 = vor.u32 %v4398_v44, %v4397_v34 (stack47)
        %v4833_v14 = vxor.u32 %v4832_v54, %v4828_v22 (stack48)
        %v2724_v49 = vmul.f32 %v120452_v50, %v123500_v61 (stack74)
        %v119758_v37 = vadd.low.f32.bf16 -1.0, %v3121_v60 (stack53)
        %v3948_v56 = vor.u32 %v3947_v8, %v3946_v26 (stack47)
        %v5264_v13 = vadd.s32 1, %v5260_v20 (stack40)
        %v3538_v36 = vxor.u32 %v3537_v12, %v3533_v9 (stack48)
        %v4400_v16 = vxor.u32 %v4399_v53, %v4391_v42 (stack48)
        %v4836_v30 = vadd.s32 %v4833_v14, %v4828_v22 (stack40)
        %v4838_v25 = vshll.u32 %v4833_v14, 15 (stack45)
        %v2726_v32 = vsel /*vm=*/%vm2725_vm10, /*on_true_vy=*/%v123500_v61, /*on_false_vx=*/%v2724_v49 (stack75)
        %v3130_v39 = vmul.f32 2.0, %v119758_v37 (stack54)
        %v3949_v31 = vxor.u32 %v3948_v56, %v3940_v17 (stack48)
        %v4839_v40 = vshrl.u32 %v4833_v14, 17 (stack46)
        %v2729_v22 = vsel /*vm=*/%vm2727_vm12, /*on_true_vy=*/%v2728_v62, /*on_false_vx=*/%v2726_v32 (stack76)
        %v3541_v54 = vadd.s32 %v3538_v36, %v3533_v9 (stack40)
        %v3547_v11 = vshll.u32 %v3538_v36, 24 (stack45)
        %v3548_v34 = vshrl.u32 %v3538_v36, 8 (stack46)
        %v2732_v44 = vadd.f32 -3.0, %v2729_v22 (stack53)
        %v3134_v9 = vadd.f32 -0.99609375, %v3130_v39 (stack53)
        %v3952_v27 = vadd.s32 %v3949_v31, %v121574_v2 (stack40)
        %v4403_v10 = vadd.s32 %v4400_v16, %v121564_v0 (stack40)
        %v3549_v60 = vor.u32 %v3548_v34, %v3547_v11 (stack47)
        %v3944_v17 = vadd.s32 %v3940_v17, %v121564_v0 (stack40)
        %v4840_v26 = vor.u32 %v4839_v40, %v4838_v25 (stack47)
        %v5268_v20 = vsel /*vm=*/%vm5255_vm11, /*on_true_vy=*/%v5264_v13, /*on_false_vx=*/%v5260_v20 (stack44)
        %v123563_v7 = vsel /*vm=*/%vm2680_vm8, /*on_true_vy=*/%v123517_v7, /*on_false_vx=*/%v2732_v44 (stack44)
        %v123565_v8 = vmax.f32 %v3134_v9, -0.99609375 (stack55)
        %v3956_v50 = vadd.s32 2, %v3952_v27 (stack40)
        %v4407_v62 = vadd.s32 1, %v4403_v10 (stack40)
        %v2713_v12 = vsel /*vm=*/%vm2680_vm8, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v2740_v46 = vmul.f32 %v123563_v7, %v2717_v46 (stack54)
        %v3550_v53 = vxor.u32 %v3549_v60, %v3541_v54 (stack48)
        %v4841_v14 = vxor.u32 %v4840_v26, %v4836_v30 (stack48)
        %v3150_v49 = vxor.u32 2147483648, %v123565_v8 (stack56)
        %v3960_v37 = vadd.s32 %v3956_v50, %v3944_v17 (stack40)
        %v4395_v42 = vadd.s32 %v4391_v42, %v121569_v1 (stack40)
        %v5246_v56 = vadd.s32 %v123483_v21, %v122657_v58 (stack40)
        %v2744_v13 = vadd.f32 %v2740_v46, %v2713_v12 (stack53)
        %v3553_v36 = vadd.s32 %v3550_v53, %v121564_v0 (stack40)
        %v3962_v16 = vshll.u32 %v3956_v50, 13 (stack45)
        %v3963_v25 = vshrl.u32 %v3956_v50, 19 (stack46)
        %v123577_v32 = vmul.f32 %v3150_v49, %v123565_v8 (stack54)
        %v3545_v39 = vadd.s32 %v3541_v54, %v121569_v1 (stack40)
        %v4411_v31 = vadd.s32 %v4407_v62, %v4395_v42 (stack40)
        %v4413_v40 = vshll.u32 %v4407_v62, 17 (stack45)
        %v2748_v22 = vmul.f32 %v2744_v13, %v123563_v7 (stack54)
        %v3557_v54 = vadd.s32 4, %v3553_v36 (stack40)
        %v3964_v11 = vor.u32 %v3963_v25, %v3962_v16 (stack47)
        %v4414_v34 = vshrl.u32 %v4407_v62, 15 (stack46)
        %v2709_v44 = vsel /*vm=*/%vm2680_vm8, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v3155_v9 = vadd.f32 1.0, %v123577_v32 (stack57)
        %v3158_v27 = vmul.f32 -0.5, %v123577_v32 (stack59)
        %v4844_v30 = vadd.s32 %v4841_v14, %v4836_v30 (stack40)
        %v2752_v10 = vadd.f32 %v2748_v22, %v2709_v44 (stack53)
        %v3561_v60 = vadd.s32 %v3557_v54, %v3545_v39 (stack40)
        %v3563_v17 = vshll.u32 %v3557_v54, 13 (stack45)
        %v3564_v26 = vshrl.u32 %v3557_v54, 19 (stack46)
        %120453 = vlog2.f32 %v3155_v9 (stack58)
        %v3965_v50 = vxor.u32 %v3964_v11, %v3960_v37 (stack48)
        %vm5250_vm13 = vcmp.lt.u32.totalorder %v5246_v56, %v123483_v21 (stack43)
        %v5272_v21 = vadd.s32 1, %v5268_v20 (stack40)
        %v2756_v62 = vmul.f32 %v2752_v10, %v123563_v7 (stack54)
        %v3159_v12 = vadd.f32 1.0, %v3158_v27 (stack61)
        %v3565_v46 = vor.u32 %v3564_v26, %v3563_v17 (stack47)
        %v4415_v53 = vor.u32 %v4414_v34, %v4413_v40 (stack47)
        %v3968_v49 = vadd.s32 %v3965_v50, %v3960_v37 (stack40)
        %v3970_v37 = vshll.u32 %v3965_v50, 15 (stack45)
        %v3971_v42 = vshrl.u32 %v3965_v50, 17 (stack46)
        %v4846_v13 = vshll.u32 %v4841_v14, 26 (stack45)
        %v2760_v52 = vadd.f32 %v2756_v62, %v123532_v52 (stack53)
        %v3566_v36 = vxor.u32 %v3565_v46, %v3561_v60 (stack48)
        %v4416_v16 = vxor.u32 %v4415_v53, %v4411_v31 (stack48)
        %v4847_v14 = vshrl.u32 %v4841_v14, 6 (stack46)
        %v3972_v25 = vor.u32 %v3971_v42, %v3970_v37 (stack47)
        %v5276_v20 = vsel /*vm=*/%vm5250_vm13, /*on_true_vy=*/%v5272_v21, /*on_false_vx=*/%v5268_v20 (stack44)
        %v123590_v56 = vadd.s32 %v5246_v56, %v121569_v1 (stack40)
        %v157079_v39 = vld [vmem:[#allocation121_spill] sm:$0xff] (stack84)
        %v123594_v40 = vadd.s32 %v122703_v29, %v157079_v39 (stack40)
        %v2764_v22 = vmul.f32 %v2760_v52, %v123563_v7 (stack54)
        %v3569_v54 = vadd.s32 %v3566_v36, %v3561_v60 (stack40)
        %v3571_v11 = vshll.u32 %v3566_v36, 15 (stack45)
        %v3572_v34 = vshrl.u32 %v3566_v36, 17 (stack46)
        %v3973_v44 = vxor.u32 %v3972_v25, %v3968_v49 (stack48)
        %v4419_v31 = vadd.s32 %v4416_v16, %v4411_v31 (stack40)
        %v4421_v9 = vshll.u32 %v4416_v16, 29 (stack45)
        %v4422_v27 = vshrl.u32 %v4416_v16, 3 (stack46)
        %v2768_v43 = vadd.f32 %v2764_v22, %v123527_v43 (stack53)
        %v3573_v10 = vor.u32 %v3572_v34, %v3571_v11 (stack47)
        %v4848_v60 = vor.u32 %v4847_v14, %v4846_v13 (stack47)
        %v5281_v17 = vadd.s32 %v5276_v20, %v121574_v2 (stack40)
        %v3976_v26 = vadd.s32 %v3973_v44, %v3968_v49 (stack40)
        %v3978_v50 = vshll.u32 %v3973_v44, 26 (stack45)
        %v3979_v21 = vshrl.u32 %v3973_v44, 6 (stack46)
        %v4423_v62 = vor.u32 %v4422_v27, %v4421_v9 (stack47)
        %v2772_v46 = vmul.f32 %v2768_v43, %v123563_v7 (stack54)
        %v3574_v53 = vxor.u32 %v3573_v10, %v3569_v54 (stack48)
        %v4849_v49 = vxor.u32 %v4848_v60, %v4844_v30 (stack48)
        %v123601_v37 = vadd.s32 %v123590_v56, %v5281_v17 (stack40)
        %v2697_v42 = vsel /*vm=*/%vm2680_vm8, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v3161_v13 = vand.u32 2147483647, %v123577_v32 (stack60)
        %v3980_v52 = vor.u32 %v3979_v21, %v3978_v50 (stack47)
        %v4424_v36 = vxor.u32 %v4423_v62, %v4419_v31 (stack48)
        %v2776_v16 = vadd.f32 %v2772_v46, %v2697_v42 (stack53)
        %v3577_v14 = vadd.s32 %v3574_v53, %v3569_v54 (stack40)
        %v3579_v25 = vshll.u32 %v3574_v53, 26 (stack45)
        %v3580_v20 = vshrl.u32 %v3574_v53, 6 (stack46)
        %v3981_v22 = vxor.u32 %v3980_v52, %v3976_v26 (stack48)
        %v4427_v54 = vadd.s32 %v4424_v36, %v4419_v31 (stack40)
        %v4429_v11 = vshll.u32 %v4424_v36, 16 (stack45)
        %v4430_v34 = vshrl.u32 %v4424_v36, 16 (stack46)
        %v120454_v44 = vpop.eup %120453 (stack64)
        %v2780_v31 = vmul.f32 %v2776_v16, %v123563_v7 (stack54)
        %v3160_v32 = vmul.f32 %v3159_v12, %v123577_v32 (stack63)
        %v3581_v12 = vor.u32 %v3580_v20, %v3579_v25 (stack47)
        %v4852_v30 = vadd.s32 %v4849_v49, %v4844_v30 (stack40)
        %v3157_v9 = vmul.f32 0.6931472, %v120454_v44 (stack65)
        %v3984_v27 = vadd.s32 %v3981_v22, %v3976_v26 (stack40)
        %v3990_v43 = vshll.u32 %v3981_v22, 6 (stack45)
        %v3991_v10 = vshrl.u32 %v3981_v22, 26 (stack46)
        %v2784_v59 = vadd.f32 %v2780_v31, %v123522_v59 (stack53)
        %vm3162_vm14 = vcmp.lt.f32.partialorder %v3161_v13, 0.0004427343 (stack62)
        %v3582_v60 = vxor.u32 %v3581_v12, %v3577_v14 (stack48)
        %v4431_v17 = vor.u32 %v4430_v34, %v4429_v11 (stack47)
        %v2689_v61 = vsel /*vm=*/%vm2680_vm8, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v3163_v26 = vsel /*vm=*/%vm3162_vm14, /*on_true_vy=*/%v3160_v32, /*on_false_vx=*/%v3157_v9 (stack66)
        %v3992_v50 = vor.u32 %v3991_v10, %v3990_v43 (stack47)
        %v4858_v21 = vshll.u32 %v4849_v49, 6 (stack45)
        %v2788_v62 = vmul.f32 %v2784_v59, %v123563_v7 (stack54)
        %v123614_v46 = vxor.u32 2147483648, %v3163_v26 (stack56)
        %v3585_v53 = vadd.s32 %v3582_v60, %v3577_v14 (stack40)
        %v4859_v49 = vshrl.u32 %v4849_v49, 26 (stack46)
        %vm123618_vm15 = vcmp.eq.f32.partialorder %v2653_v23, 1.0 (stack68)
        %v3591_v42 = vshll.u32 %v3582_v60, 6 (stack45)
        %v3592_v13 = vshrl.u32 %v3582_v60, 26 (stack46)
        %v3993_v52 = vxor.u32 %v3992_v50, %v3984_v27 (stack48)
        %v4432_v36 = vxor.u32 %v4431_v17, %v4427_v54 (stack48)
        %v2792_v16 = vadd.f32 %v2788_v62, %v2689_v61 (stack53)
        %v3140_v14 = vand.u32 2147483647, %v123565_v8 (stack77)
        %vm3167_vm0 = vcmp.lt.f32.partialorder %v123614_v46, 5.0 (stack68)
        %120455 = vrsqrt.f32 %v123614_v46 (stack67)
        %v123626_v25 = vmul.f32 inf, %v123565_v8 (stack54)
        %v4856_v20 = vadd.s32 %v4852_v30, %v121569_v1 (stack40)
        %v5291_v22 = vshll.u32 %v123590_v56, 13 (stack45)
        %v5292_v56 = vshrl.u32 %v123590_v56, 19 (stack46)
        %v2796_v7 = vmul.f32 %v2792_v16, %v123563_v7 (stack54)
        %v123633_v11 = vadd.f32 -2.5, %v123614_v46 (stack53)
        %v3988_v34 = vadd.s32 %v3984_v27, %v121574_v2 (stack40)
        %v4860_v44 = vor.u32 %v4859_v49, %v4858_v21 (stack47)
        %v123639_v31 = vsel /*vm=*/%vm3167_vm0, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v123644_v32 = vsel /*vm=*/%vm3167_vm0, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v123649_v12 = vsel /*vm=*/%vm3167_vm0, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v3593_v9 = vor.u32 %v3592_v13, %v3591_v42 (stack47)
        %v2800_v55 = vadd.f32 %v2796_v7, %v123514_v55 (stack53)
        %v123655_v27 = vsel /*vm=*/%vm3167_vm0, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v123660_v43 = vsel /*vm=*/%vm3167_vm0, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v3589_v10 = vadd.s32 %v3585_v53, %v121564_v0 (stack40)
        %v3594_v59 = vxor.u32 %v3593_v9, %v3585_v53 (stack48)
        %v3996_v60 = vadd.s32 %v3993_v52, %v121569_v1 (stack40)
        %v4435_v54 = vadd.s32 %v4432_v36, %v4427_v54 (stack40)
        %v4441_v17 = vshll.u32 %v4432_v36, 24 (stack45)
        %v2804_v6 = vmul.f32 %v2800_v55, %v123432_v6 (stack54)
        %v4442_v61 = vshrl.u32 %v4432_v36, 8 (stack46)
        %v4861_v30 = vxor.u32 %v4860_v44, %v4852_v30 (stack48)
        %v5293_v26 = vor.u32 %v5292_v56, %v5291_v22 (stack47)
        %vm3212_vm1 = vcmp.eq.f32.partialorder %v123614_v46, inf (stack70)
        %v3215_v50 = vand.u32 2147483648, %v123614_v46 (stack72)
        %v3597_v21 = vadd.s32 %v3594_v59, %v121574_v2 (stack40)
        %v4000_v62 = vadd.s32 3, %v3996_v60 (stack40)
        %v2808_v41 = vsel /*vm=*/%vm123618_vm15, /*on_true_vy=*/%v123507_v41, /*on_false_vx=*/%v2804_v6 (stack44)
        %vm3214_vm2 = vcmp.eq.f32.partialorder %v123614_v46, 0.0 (stack71)
        %v4443_v53 = vor.u32 %v4442_v61, %v4441_v17 (stack47)
        %v4864_v49 = vadd.s32 %v4861_v30, %v121564_v0 (stack40)
        %v5294_v23 = vxor.u32 %v5293_v26, %v123601_v37 (stack48)
        %v2812_v42 = vmul.f32 1.4140625, %v2808_v41 (stack54)
        %v3601_v13 = vadd.s32 5, %v3597_v21 (stack40)
        %v4004_v52 = vadd.s32 %v4000_v62, %v3988_v34 (stack40)
        %v4006_v36 = vshll.u32 %v4000_v62, 17 (stack45)
        %v4007_v16 = vshrl.u32 %v4000_v62, 15 (stack46)
        %v4444_v22 = vxor.u32 %v4443_v53, %v4435_v54 (stack48)
        %v4868_v56 = vadd.s32 1, %v4864_v49 (stack40)
        %v5297_v37 = vadd.s32 %v5294_v23, %v123601_v37 (stack40)
        %v2815_v7 = vpack.c.bf16 %v156663_v45, %v2812_v42 (stack81)
        %v3603_v34 = vxor.u32 %v3601_v13, %v3589_v10 (stack48)
        %v5299_v44 = vshll.u32 %v5294_v23, 15 (stack45)
        %v5300_v9 = vshrl.u32 %v5294_v23, 17 (stack46)
        %v4008_v55 = vor.u32 %v4007_v16, %v4006_v36 (stack47)
        %v4447_v10 = vadd.s32 %v4444_v22, %v121574_v2 (stack40)
        %v4872_v20 = vadd.s32 %v4868_v56, %v4856_v20 (stack40)
        %v4874_v59 = vshll.u32 %v4868_v56, 17 (stack45)
        %v120456_v60 = vpop.eup %120455 (stack73)
        %119757 = vst [vmem:[%s123356_s30 + $0x200] sm:$0xf] /*vst_source=*/%v2815_v7 (stack83)
        %v3604_v17 = vand.u32.u8 255, %v3603_v34 (stack49)
        %v4439_v54 = vadd.s32 %v4435_v54, %v121564_v0 (stack40)
        %v4875_v6 = vshrl.u32 %v4868_v56, 15 (stack46)
        %v5301_v61 = vor.u32 %v5300_v9, %v5299_v44 (stack47)
        %v3211_v30 = vmul.f32 %v120456_v60, %v123614_v46 (stack74)
        %v4009_v26 = vxor.u32 %v4008_v55, %v4004_v52 (stack48)
        %v4451_v21 = vadd.s32 2, %v4447_v10 (stack40)
        %vm5716_vm3 = vcmp.lt.u32.totalorder %v123594_v40, %v157079_v39 (stack43)
        %v3605_v62 = vand.u32 65535, %v3604_v17 (stack50)
        %v4876_v41 = vor.u32 %v4875_v6, %v4874_v59 (stack47)
        %v5302_v53 = vxor.u32 %v5301_v61, %v5297_v37 (stack48)
        %v157082_v49 = vld [vmem:[#allocation48_spill] sm:$0xff] (stack84)
        %v123684_v23 = vadd.s32 %v157069_v24, %v157082_v49 (stack40)
        %v3213_v42 = vsel /*vm=*/%vm3212_vm1, /*on_true_vy=*/%v123614_v46, /*on_false_vx=*/%v3211_v30 (stack75)
        %v4012_v13 = vadd.s32 %v4009_v26, %v4004_v52 (stack40)
        %v4014_v52 = vshll.u32 %v4009_v26, 29 (stack45)
        %v4015_v36 = vshrl.u32 %v4009_v26, 3 (stack46)
        %v3216_v50 = vsel /*vm=*/%vm3214_vm2, /*on_true_vy=*/%v3215_v50, /*on_false_vx=*/%v3213_v42 (stack76)
        %v3606_v16 = vshrl.u32 %v3605_v62, 1 (stack51)
        %v4455_v22 = vadd.s32 %v4451_v21, %v4439_v54 (stack40)
        %v4457_v56 = vshll.u32 %v4451_v21, 13 (stack45)
        %v3219_v7 = vadd.f32 -3.0, %v3216_v50 (stack53)
        %v4016_v34 = vor.u32 %v4015_v36, %v4014_v52 (stack47)
        %v4458_v44 = vshrl.u32 %v4451_v21, 19 (stack46)
        %v4877_v9 = vxor.u32 %v4876_v41, %v4872_v20 (stack48)
        %v3607_v55 = vor.u32 16256, %v3606_v16 (stack47)
        %v5305_v37 = vadd.s32 %v5302_v53, %v5297_v37 (stack40)
        %v5307_v10 = vshll.u32 %v5302_v53, 26 (stack45)
        %v5308_v59 = vshrl.u32 %v5302_v53, 6 (stack46)
        %v123694_v11 = vsel /*vm=*/%vm3167_vm0, /*on_true_vy=*/%v123633_v11, /*on_false_vx=*/%v3219_v7 (stack44)
        %v4017_v60 = vxor.u32 %v4016_v34, %v4012_v13 (stack48)
        %v4459_v17 = vor.u32 %v4458_v44, %v4457_v56 (stack47)
        %v4880_v20 = vadd.s32 %v4877_v9, %v4872_v20 (stack40)
        %v3227_v43 = vmul.f32 %v123694_v11, %v123660_v43 (stack54)
        %v3608_v54 = vand.u32.u16 65535, %v3607_v55 (stack52)
        %v4882_v6 = vshll.u32 %v4877_v9, 29 (stack45)
        %v4883_v61 = vshrl.u32 %v4877_v9, 3 (stack46)
        %v4020_v30 = vadd.s32 %v4017_v60, %v4012_v13 (stack40)
        %v4022_v26 = vshll.u32 %v4017_v60, 16 (stack45)
        %v4023_v21 = vshrl.u32 %v4017_v60, 16 (stack46)
        %v4460_v62 = vxor.u32 %v4459_v17, %v4455_v22 (stack48)
        %v3231_v27 = vadd.f32 %v3227_v43, %v123655_v27 (stack53)
        %v119760_v41 = vadd.low.f32.bf16 -1.0, %v3608_v54 (stack53)
        %v4884_v53 = vor.u32 %v4883_v61, %v4882_v6 (stack47)
        %v5309_v42 = vor.u32 %v5308_v59, %v5307_v10 (stack47)
        %v4024_v13 = vor.u32 %v4023_v21, %v4022_v26 (stack47)
        %v4463_v52 = vadd.s32 %v4460_v62, %v4455_v22 (stack40)
        %v4465_v36 = vshll.u32 %v4460_v62, 15 (stack45)
        %v4466_v50 = vshrl.u32 %v4460_v62, 17 (stack46)
        %v3235_v16 = vmul.f32 %v3231_v27, %v123694_v11 (stack54)
        %v3617_v22 = vmul.f32 2.0, %v119760_v41 (stack54)
        %v4885_v56 = vxor.u32 %v4884_v53, %v4880_v20 (stack48)
        %v123700_v7 = vxor.u32 %v5309_v42, %v5305_v37 (stack48)
        %v3196_v34 = vsel /*vm=*/%vm3167_vm0, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v4025_v44 = vxor.u32 %v4024_v13, %v4020_v30 (stack48)
        %v4467_v9 = vor.u32 %v4466_v50, %v4465_v36 (stack47)
        %v123707_v55 = vadd.s32 %v123594_v40, %v122657_v58 (stack40)
        %v3239_v10 = vadd.f32 %v3235_v16, %v3196_v34 (stack53)
        %v3621_v59 = vadd.f32 -0.99609375, %v3617_v22 (stack53)
        %v4888_v60 = vadd.s32 %v4885_v56, %v4880_v20 (stack40)
        %v4890_v17 = vshll.u32 %v4885_v56, 16 (stack45)
        %v4028_v20 = vadd.s32 %v4025_v44, %v4020_v30 (stack40)
        %v4034_v43 = vshll.u32 %v4025_v44, 24 (stack45)
        %v4035_v54 = vshrl.u32 %v4025_v44, 8 (stack46)
        %v4468_v6 = vxor.u32 %v4467_v9, %v4463_v52 (stack48)
        %v3243_v61 = vmul.f32 %v3239_v10, %v123694_v11 (stack54)
        %v123710_v30 = vmax.f32 %v3621_v59, -0.99609375 (stack55)
        %v4891_v26 = vshrl.u32 %v4885_v56, 16 (stack46)
        %v123713_v37 = vadd.s32 %v123700_v7, %v5305_v37 (stack40)
        %v3192_v21 = vsel /*vm=*/%vm3167_vm0, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v4036_v62 = vor.u32 %v4035_v54, %v4034_v43 (stack47)
        %v4471_v27 = vadd.s32 %v4468_v6, %v4463_v52 (stack40)
        %v4473_v41 = vshll.u32 %v4468_v6, 26 (stack45)
        %v3184_v53 = vsel /*vm=*/%vm3167_vm0, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v3188_v46 = vsel /*vm=*/%vm3167_vm0, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v3247_v42 = vadd.f32 %v3243_v61, %v3192_v21 (stack53)
        %v3637_v13 = vxor.u32 2147483648, %v123710_v30 (stack56)
        %v4037_v52 = vxor.u32 %v4036_v62, %v4028_v20 (stack48)
        %v4474_v36 = vshrl.u32 %v4468_v6, 6 (stack46)
        %v4892_v50 = vor.u32 %v4891_v26, %v4890_v17 (stack47)
        %v5725_v16 = vadd.s32 1, %v123684_v23 (stack40)
        %v3251_v22 = vmul.f32 %v3247_v42, %v123694_v11 (stack54)
        %v123728_v56 = vmul.f32 %v3637_v13, %v123710_v30 (stack54)
        %v4032_v34 = vadd.s32 %v4028_v20, %v121569_v1 (stack40)
        %v5746_v44 = vadd.s32 %v123707_v55, %v121569_v1 (stack40)
        %v4040_v9 = vadd.s32 %v4037_v52, %v121564_v0 (stack40)
        %v4475_v10 = vor.u32 %v4474_v36, %v4473_v41 (stack47)
        %v4893_v59 = vxor.u32 %v4892_v50, %v4888_v60 (stack48)
        %v123736_v17 = vadd.s32 %v123713_v37, %v121569_v1 (stack40)
        %vm5711_vm4 = vcmp.lt.u32.totalorder %v123707_v55, %v123594_v40 (stack43)
        %v3255_v20 = vadd.f32 %v3251_v22, %v3188_v46 (stack53)
        %v3642_v43 = vadd.f32 1.0, %v123728_v56 (stack57)
        %v3645_v54 = vmul.f32 -0.5, %v123728_v56 (stack59)
        %v5319_v6 = vshll.u32 %v123700_v7, 6 (stack45)
        %v4044_v61 = vadd.s32 4, %v4040_v9 (stack40)
        %v4476_v26 = vxor.u32 %v4475_v10, %v4471_v27 (stack48)
        %v4896_v60 = vadd.s32 %v4893_v59, %v4888_v60 (stack40)
        %v5320_v7 = vshrl.u32 %v123700_v7, 26 (stack46)
        %v3259_v21 = vmul.f32 %v3255_v20, %v123694_v11 (stack54)
        %120457 = vlog2.f32 %v3642_v43 (stack58)
        %v3648_v62 = vand.u32 2147483647, %v123728_v56 (stack60)
        %v4902_v41 = vshll.u32 %v4893_v59, 24 (stack45)
        %v4048_v46 = vadd.s32 %v4044_v61, %v4032_v34 (stack40)
        %v4050_v42 = vshll.u32 %v4044_v61, 13 (stack45)
        %v4051_v13 = vshrl.u32 %v4044_v61, 19 (stack46)
        %v4479_v27 = vadd.s32 %v4476_v26, %v4471_v27 (stack40)
        %v3263_v53 = vadd.f32 %v3259_v21, %v3184_v53 (stack53)
        %v3646_v52 = vadd.f32 1.0, %v3645_v54 (stack61)
        %v4485_v36 = vshll.u32 %v4476_v26, 6 (stack45)
        %v4486_v50 = vshrl.u32 %v4476_v26, 26 (stack46)
        %v4052_v22 = vor.u32 %v4051_v13, %v4050_v42 (stack47)
        %v4483_v34 = vadd.s32 %v4479_v27, %v121574_v2 (stack40)
        %v4900_v9 = vadd.s32 %v4896_v60, %v121564_v0 (stack40)
        %v4903_v10 = vshrl.u32 %v4893_v59, 8 (stack46)
        %v3267_v59 = vmul.f32 %v3263_v53, %v123694_v11 (stack54)
        %v4487_v20 = vor.u32 %v4486_v50, %v4485_v36 (stack47)
        %v5321_v43 = vor.u32 %v5320_v7, %v5319_v6 (stack47)
        %v5729_v23 = vsel /*vm=*/%vm5716_vm3, /*on_true_vy=*/%v5725_v16, /*on_false_vx=*/%v123684_v23 (stack44)
        %v4053_v16 = vxor.u32 %v4052_v22, %v4048_v46 (stack48)
        %v4904_v54 = vor.u32 %v4903_v10, %v4902_v41 (stack47)
        %v5733_v6 = vadd.s32 1, %v5729_v23 (stack40)
        %v5752_v61 = vshll.u32 %v5746_v44, 13 (stack45)
        %v3271_v12 = vadd.f32 %v3267_v59, %v123649_v12 (stack53)
        %v4488_v26 = vxor.u32 %v4487_v20, %v4479_v27 (stack48)
        %v5322_v37 = vxor.u32 %v5321_v43, %v123713_v37 (stack48)
        %v5753_v7 = vshrl.u32 %v5746_v44, 19 (stack46)
        %v4056_v21 = vadd.s32 %v4053_v16, %v4048_v46 (stack40)
        %v4058_v41 = vshll.u32 %v4053_v16, 15 (stack45)
        %v4059_v46 = vshrl.u32 %v4053_v16, 17 (stack46)
        %v4905_v60 = vxor.u32 %v4904_v54, %v4896_v60 (stack48)
        %v3275_v42 = vmul.f32 %v3271_v12, %v123694_v11 (stack54)
        %v4491_v13 = vadd.s32 %v4488_v26, %v121569_v1 (stack40)
        %v5325_v27 = vadd.s32 %v5322_v37, %v121564_v0 (stack40)
        %v5737_v40 = vsel /*vm=*/%vm5711_vm4, /*on_true_vy=*/%v5733_v6, /*on_false_vx=*/%v5729_v23 (stack44)
        %v4060_v55 = vor.u32 %v4059_v46, %v4058_v41 (stack47)
        %v4908_v53 = vadd.s32 %v4905_v60, %v121574_v2 (stack40)
        %v5742_v36 = vadd.s32 %v5737_v40, %v121574_v2 (stack40)
        %v5754_v50 = vor.u32 %v5753_v7, %v5752_v61 (stack47)
        %v3279_v32 = vadd.f32 %v3275_v42, %v123644_v32 (stack53)
        %v4495_v22 = vadd.s32 3, %v4491_v13 (stack40)
        %v5329_v10 = vadd.s32 1, %v5325_v27 (stack40)
        %v157083_v59 = vld [vmem:[#allocation118_spill] sm:$0xff] (stack84)
        %v123766_v20 = vadd.s32 %v122703_v29, %v157083_v59 (stack40)
        %v4061_v43 = vxor.u32 %v4060_v55, %v4056_v21 (stack48)
        %v4912_v23 = vadd.s32 2, %v4908_v53 (stack40)
        %v5750_v44 = vadd.s32 %v5746_v44, %v5742_v36 (stack40)
        %v157084_v16 = vld [vmem:[#allocation51_spill] sm:$0xff] (stack84)
        %v123770_v54 = vadd.s32 %v157069_v24, %v157084_v16 (stack40)
        %v3283_v11 = vmul.f32 %v3279_v32, %v123694_v11 (stack54)
        %v4499_v34 = vadd.s32 %v4495_v22, %v4483_v34 (stack40)
        %v4501_v6 = vshll.u32 %v4495_v22, 17 (stack45)
        %v4502_v61 = vshrl.u32 %v4495_v22, 15 (stack46)
        %v120458_v12 = vpop.eup %120457 (stack64)
        %v4064_v26 = vadd.s32 %v4061_v43, %v4056_v21 (stack40)
        %v4066_v37 = vshll.u32 %v4061_v43, 26 (stack45)
        %v4067_v7 = vshrl.u32 %v4061_v43, 6 (stack46)
        %v4916_v9 = vadd.s32 %v4912_v23, %v4900_v9 (stack40)
        %v3287_v31 = vadd.f32 %v3283_v11, %v123639_v31 (stack53)
        %v3644_v21 = vmul.f32 0.6931472, %v120458_v12 (stack65)
        %v3647_v56 = vmul.f32 %v3646_v52, %v123728_v56 (stack63)
        %v4503_v52 = vor.u32 %v4502_v61, %v4501_v6 (stack47)
        %vm3649_vm5 = vcmp.lt.f32.partialorder %v3648_v62, 0.0004427343 (stack62)
        %v4068_v62 = vor.u32 %v4067_v7, %v4066_v37 (stack47)
        %v4918_v41 = vshll.u32 %v4912_v23, 13 (stack45)
        %v5333_v17 = vadd.s32 %v5329_v10, %v123736_v17 (stack40)
        %v3291_v46 = vmul.f32 %v3287_v31, %v123565_v8 (stack54)
        %v3650_v60 = vsel /*vm=*/%vm3649_vm5, /*on_true_vy=*/%v3647_v56, /*on_false_vx=*/%v3644_v21 (stack66)
        %v4504_v42 = vxor.u32 %v4503_v52, %v4499_v34 (stack48)
        %v4919_v13 = vshrl.u32 %v4912_v23, 19 (stack46)
        %vm3143_vm6 = vcmp.eq.f32.partialorder %v3140_v14, 1.0 (stack68)
        %v123779_v8 = vxor.u32 2147483648, %v3650_v60 (stack56)
        %v4069_v14 = vxor.u32 %v4068_v62, %v4064_v26 (stack48)
        %v5755_v27 = vxor.u32 %v5754_v50, %v5750_v44 (stack48)
        %v3295_v25 = vsel /*vm=*/%vm3143_vm6, /*on_true_vy=*/%v123626_v25, /*on_false_vx=*/%v3291_v46 (stack44)
        %v3627_v40 = vand.u32 2147483647, %v123710_v30 (stack77)
        %v4507_v55 = vadd.s32 %v4504_v42, %v4499_v34 (stack40)
        %v5335_v53 = vshll.u32 %v5329_v10, 17 (stack45)
        %v3299_v36 = vmul.f32 1.4140625, %v3295_v25 (stack54)
        %vm3654_vm7 = vcmp.lt.f32.partialorder %v123779_v8, 5.0 (stack68)
        %120459 = vrsqrt.f32 %v123779_v8 (stack67)
        %v5336_v50 = vshrl.u32 %v5329_v10, 15 (stack46)
        %v4072_v32 = vadd.s32 %v4069_v14, %v4064_v26 (stack40)
        %v4509_v22 = vshll.u32 %v4504_v42, 29 (stack45)
        %v4510_v10 = vshrl.u32 %v4504_v42, 3 (stack46)
        %v4920_v43 = vor.u32 %v4919_v13, %v4918_v41 (stack47)
        %v3302_v23 = vpack.c.bf16 %v156663_v45, %v3299_v36 (stack81)
        %v123787_v11 = vmul.f32 inf, %v123710_v30 (stack54)
        %v123792_v34 = vsel /*vm=*/%vm3654_vm7, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v123797_v6 = vsel /*vm=*/%vm3654_vm7, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v123802_v61 = vsel /*vm=*/%vm3654_vm7, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v123807_v12 = vsel /*vm=*/%vm3654_vm7, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v123812_v26 = vsel /*vm=*/%vm3654_vm7, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %119759 = vst [vmem:[%s123356_s30 + $0x280] sm:$0xf] /*vst_source=*/%v3302_v23 (stack83)
        %v123818_v37 = vsel /*vm=*/%vm3654_vm7, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v123823_v7 = vsel /*vm=*/%vm3654_vm7, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v123826_v31 = vadd.f32 -2.5, %v123779_v8 (stack53)
        %v4078_v21 = vshll.u32 %v4069_v14, 6 (stack45)
        %v4079_v56 = vshrl.u32 %v4069_v14, 26 (stack46)
        %v4511_v52 = vor.u32 %v4510_v10, %v4509_v22 (stack47)
        %v4921_v62 = vxor.u32 %v4920_v43, %v4916_v9 (stack48)
        %v5337_v41 = vor.u32 %v5336_v50, %v5335_v53 (stack47)
        %v4076_v46 = vadd.s32 %v4072_v32, %v121564_v0 (stack40)
        %v5758_v44 = vadd.s32 %v5755_v27, %v5750_v44 (stack40)
        %v5760_v60 = vshll.u32 %v5755_v27, 15 (stack45)
        %v5761_v42 = vshrl.u32 %v5755_v27, 17 (stack46)
        %vm3699_vm8 = vcmp.eq.f32.partialorder %v123779_v8, inf (stack70)
        %v4080_v13 = vor.u32 %v4079_v56, %v4078_v21 (stack47)
        %v4512_v14 = vxor.u32 %v4511_v52, %v4507_v55 (stack48)
        %v4924_v9 = vadd.s32 %v4921_v62, %v4916_v9 (stack40)
        %v4926_v27 = vshll.u32 %v4921_v62, 15 (stack45)
        %vm3701_vm9 = vcmp.eq.f32.partialorder %v123779_v8, 0.0 (stack71)
        %v4927_v25 = vshrl.u32 %v4921_v62, 17 (stack46)
        %v5338_v53 = vxor.u32 %v5337_v41, %v5333_v17 (stack48)
        %v5762_v36 = vor.u32 %v5761_v42, %v5760_v60 (stack47)
        %v4081_v50 = vxor.u32 %v4080_v13, %v4072_v32 (stack48)
        %v4515_v55 = vadd.s32 %v4512_v14, %v4507_v55 (stack40)
        %v4517_v32 = vshll.u32 %v4512_v14, 16 (stack45)
        %v4518_v22 = vshrl.u32 %v4512_v14, 16 (stack46)
        %v4928_v10 = vor.u32 %v4927_v25, %v4926_v27 (stack47)
        %v5341_v17 = vadd.s32 %v5338_v53, %v5333_v17 (stack40)
        %v5343_v43 = vshll.u32 %v5338_v53, 29 (stack45)
        %v5344_v23 = vshrl.u32 %v5338_v53, 3 (stack46)
        %v4084_v21 = vadd.s32 %v4081_v50, %v121574_v2 (stack40)
        %v4519_v56 = vor.u32 %v4518_v22, %v4517_v32 (stack47)
        %v5763_v52 = vxor.u32 %v5762_v36, %v5758_v44 (stack48)
        %vm6177_vm10 = vcmp.lt.u32.totalorder %v123766_v20, %v157083_v59 (stack43)
        %v3702_v62 = vand.u32 2147483648, %v123779_v8 (stack72)
        %v4929_v41 = vxor.u32 %v4928_v10, %v4924_v9 (stack48)
        %v5345_v60 = vor.u32 %v5344_v23, %v5343_v43 (stack47)
        %v123837_v42 = vadd.s32 %v123766_v20, %v122657_v58 (stack40)
        %v120460_v13 = vpop.eup %120459 (stack73)
        %v4088_v14 = vadd.s32 5, %v4084_v21 (stack40)
        %v4520_v27 = vxor.u32 %v4519_v56, %v4515_v55 (stack48)
        %v5766_v44 = vadd.s32 %v5763_v52, %v5758_v44 (stack40)
        %v5768_v25 = vshll.u32 %v5763_v52, 26 (stack45)
        %v3698_v53 = vmul.f32 %v120460_v13, %v123779_v8 (stack74)
        %v4932_v9 = vadd.s32 %v4929_v41, %v4924_v9 (stack40)
        %v4934_v36 = vshll.u32 %v4929_v41, 26 (stack45)
        %v4935_v50 = vshrl.u32 %v4929_v41, 6 (stack46)
        %v4090_v46 = vxor.u32 %v4088_v14, %v4076_v46 (stack48)
        %v4523_v55 = vadd.s32 %v4520_v27, %v4515_v55 (stack40)
        %v4529_v32 = vshll.u32 %v4520_v27, 24 (stack45)
        %v4530_v22 = vshrl.u32 %v4520_v27, 8 (stack46)
        %v3700_v10 = vsel /*vm=*/%vm3699_vm8, /*on_true_vy=*/%v123779_v8, /*on_false_vx=*/%v3698_v53 (stack75)
        %v4936_v43 = vor.u32 %v4935_v50, %v4934_v36 (stack47)
        %v5346_v23 = vxor.u32 %v5345_v60, %v5341_v17 (stack48)
        %v5769_v21 = vshrl.u32 %v5763_v52, 6 (stack46)
        %v3703_v56 = vsel /*vm=*/%vm3701_vm9, /*on_true_vy=*/%v3702_v62, /*on_false_vx=*/%v3700_v10 (stack76)
        %v4091_v52 = vand.u32.u8 255, %v4090_v46 (stack49)
        %v4531_v62 = vor.u32 %v4530_v22, %v4529_v32 (stack47)
        %v6186_v41 = vadd.s32 1, %v123770_v54 (stack40)
        %v3706_v60 = vadd.f32 -3.0, %v3703_v56 (stack53)
        %v4937_v13 = vxor.u32 %v4936_v43, %v4932_v9 (stack48)
        %v5349_v17 = vadd.s32 %v5346_v23, %v5341_v17 (stack40)
        %v5351_v14 = vshll.u32 %v5346_v23, 16 (stack45)
        %v4092_v27 = vand.u32 65535, %v4091_v52 (stack50)
        %v4532_v53 = vxor.u32 %v4531_v62, %v4523_v55 (stack48)
        %v5352_v36 = vshrl.u32 %v5346_v23, 16 (stack46)
        %v5770_v25 = vor.u32 %v5769_v21, %v5768_v25 (stack47)
        %v123849_v31 = vsel /*vm=*/%vm3654_vm7, /*on_true_vy=*/%v123826_v31, /*on_false_vx=*/%v3706_v60 (stack44)
        %v4940_v9 = vadd.s32 %v4937_v13, %v4932_v9 (stack40)
        %v4946_v50 = vshll.u32 %v4937_v13, 6 (stack45)
        %v4947_v46 = vshrl.u32 %v4937_v13, 26 (stack46)
        %v3714_v7 = vmul.f32 %v123849_v31, %v123823_v7 (stack54)
        %v4093_v32 = vshrl.u32 %v4092_v27, 1 (stack51)
        %v4535_v22 = vadd.s32 %v4532_v53, %v121564_v0 (stack40)
        %v5353_v10 = vor.u32 %v5352_v36, %v5351_v14 (stack47)
        %v4527_v55 = vadd.s32 %v4523_v55, %v121569_v1 (stack40)
        %v4948_v43 = vor.u32 %v4947_v46, %v4946_v50 (stack47)
        %v5771_v23 = vxor.u32 %v5770_v25, %v5766_v44 (stack48)
        %v6190_v54 = vsel /*vm=*/%vm6177_vm10, /*on_true_vy=*/%v6186_v41, /*on_false_vx=*/%v123770_v54 (stack44)
        %v3718_v37 = vadd.f32 %v3714_v7, %v123818_v37 (stack53)
        %v4094_v21 = vor.u32 16256, %v4093_v32 (stack47)
        %v4539_v56 = vadd.s32 4, %v4535_v22 (stack40)
        %v5354_v52 = vxor.u32 %v5353_v10, %v5349_v17 (stack48)
        %v4949_v62 = vxor.u32 %v4948_v43, %v4940_v9 (stack48)
        %v123860_v44 = vadd.s32 %v5771_v23, %v5766_v44 (stack40)
        %v5780_v41 = vshll.u32 %v5771_v23, 6 (stack45)
        %v5781_v60 = vshrl.u32 %v5771_v23, 26 (stack46)
        %v3722_v13 = vmul.f32 %v3718_v37, %v123849_v31 (stack54)
        %v4095_v14 = vand.u32.u16 65535, %v4094_v21 (stack52)
        %v4543_v27 = vadd.s32 %v4539_v56, %v4527_v55 (stack40)
        %v4545_v53 = vshll.u32 %v4539_v56, 13 (stack45)
        %v4546_v36 = vshrl.u32 %v4539_v56, 19 (stack46)
        %v4952_v25 = vadd.s32 %v4949_v62, %v121569_v1 (stack40)
        %v5357_v17 = vadd.s32 %v5354_v52, %v5349_v17 (stack40)
        %v5363_v50 = vshll.u32 %v5354_v52, 24 (stack45)
        %v3726_v26 = vadd.f32 %v3722_v13, %v123812_v26 (stack53)
        %v119762_v46 = vadd.low.f32.bf16 -1.0, %v4095_v14 (stack53)
        %v5364_v7 = vshrl.u32 %v5354_v52, 8 (stack46)
        %vm6172_vm11 = vcmp.lt.u32.totalorder %v123837_v42, %v123766_v20 (stack43)
        %v4547_v32 = vor.u32 %v4546_v36, %v4545_v53 (stack47)
        %v4944_v9 = vadd.s32 %v4940_v9, %v121574_v2 (stack40)
        %v4956_v22 = vadd.s32 3, %v4952_v25 (stack40)
        %v5782_v10 = vor.u32 %v5781_v60, %v5780_v41 (stack47)
        %v3730_v55 = vmul.f32 %v3726_v26, %v123849_v31 (stack54)
        %v4104_v43 = vmul.f32 2.0, %v119762_v46 (stack54)
        %v5365_v23 = vor.u32 %v5364_v7, %v5363_v50 (stack47)
        %v6194_v37 = vadd.s32 1, %v6190_v54 (stack40)
        %v4548_v21 = vxor.u32 %v4547_v32, %v4543_v27 (stack48)
        %v4960_v56 = vadd.s32 %v4956_v22, %v4944_v9 (stack40)
        %v4962_v52 = vshll.u32 %v4956_v22, 17 (stack45)
        %v4963_v62 = vshrl.u32 %v4956_v22, 15 (stack46)
        %v3734_v12 = vadd.f32 %v3730_v55, %v123807_v12 (stack53)
        %v4108_v41 = vadd.f32 -0.99609375, %v4104_v43 (stack53)
        %v5366_v60 = vxor.u32 %v5365_v23, %v5357_v17 (stack48)
        %v5783_v13 = vxor.u32 %v5782_v10, %v123860_v44 (stack48)
        %v4551_v14 = vadd.s32 %v4548_v21, %v4543_v27 (stack40)
        %v4553_v27 = vshll.u32 %v4548_v21, 15 (stack45)
        %v4554_v53 = vshrl.u32 %v4548_v21, 17 (stack46)
        %v4964_v36 = vor.u32 %v4963_v62, %v4962_v52 (stack47)
        %v3671_v25 = vsel /*vm=*/%vm3654_vm7, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v3738_v50 = vmul.f32 %v3734_v12, %v123849_v31 (stack54)
        %v123875_v26 = vmax.f32 %v4108_v41, -0.99609375 (stack55)
        %v5369_v46 = vadd.s32 %v5366_v60, %v121574_v2 (stack40)
        %v3675_v8 = vsel /*vm=*/%vm3654_vm7, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v4555_v7 = vor.u32 %v4554_v53, %v4553_v27 (stack47)
        %v4965_v32 = vxor.u32 %v4964_v36, %v4960_v56 (stack48)
        %v6198_v20 = vsel /*vm=*/%vm6172_vm11, /*on_true_vy=*/%v6194_v37, /*on_false_vx=*/%v6190_v54 (stack44)
        %v3742_v54 = vadd.f32 %v3738_v50, %v3675_v8 (stack53)
        %v4124_v9 = vxor.u32 2147483648, %v123875_v26 (stack56)
        %v5778_v44 = vadd.s32 %v123860_v44, %v121569_v1 (stack40)
        %v123889_v42 = vadd.s32 %v123837_v42, %v121569_v1 (stack40)
        %v4556_v22 = vxor.u32 %v4555_v7, %v4551_v14 (stack48)
        %v4968_v10 = vadd.s32 %v4965_v32, %v4960_v56 (stack40)
        %v4970_v55 = vshll.u32 %v4965_v32, 29 (stack45)
        %v4971_v43 = vshrl.u32 %v4965_v32, 3 (stack46)
        %v3746_v23 = vmul.f32 %v3742_v54, %v123849_v31 (stack54)
        %v4127_v37 = vmul.f32 %v4124_v9, %v123875_v26 (stack54)
        %v5361_v17 = vadd.s32 %v5357_v17, %v121564_v0 (stack40)
        %v5373_v21 = vadd.s32 2, %v5369_v46 (stack40)
        %v4559_v56 = vadd.s32 %v4556_v22, %v4551_v14 (stack40)
        %v4561_v52 = vshll.u32 %v4556_v22, 26 (stack45)
        %v4562_v62 = vshrl.u32 %v4556_v22, 6 (stack46)
        %v4972_v12 = vor.u32 %v4971_v43, %v4970_v55 (stack47)
        %v3750_v41 = vadd.f32 %v3746_v23, %v3671_v25 (stack53)
        %v4129_v60 = vadd.f32 1.0, %v4127_v37 (stack57)
        %v4132_v14 = vmul.f32 -0.5, %v4127_v37 (stack59)
        %v5786_v13 = vadd.s32 %v5783_v13, %v121564_v0 (stack40)
        %v4563_v27 = vor.u32 %v4562_v62, %v4561_v52 (stack47)
        %v4973_v53 = vxor.u32 %v4972_v12, %v4968_v10 (stack48)
        %v5377_v36 = vadd.s32 %v5373_v21, %v5361_v17 (stack40)
        %v6213_v25 = vshll.u32 %v123889_v42, 13 (stack45)
        %v3754_v50 = vmul.f32 %v3750_v41, %v123849_v31 (stack54)
        %120461 = vlog2.f32 %v4129_v60 (stack58)
        %v4133_v46 = vadd.f32 1.0, %v4132_v14 (stack61)
        %v5379_v8 = vshll.u32 %v5373_v21, 13 (stack45)
        %v4564_v7 = vxor.u32 %v4563_v27, %v4559_v56 (stack48)
        %v4976_v32 = vadd.s32 %v4973_v53, %v4968_v10 (stack40)
        %v4978_v54 = vshll.u32 %v4973_v53, 16 (stack45)
        %v4979_v9 = vshrl.u32 %v4973_v53, 16 (stack46)
        %v3758_v61 = vadd.f32 %v3754_v50, %v123802_v61 (stack53)
        %v4135_v22 = vand.u32 2147483647, %v4127_v37 (stack60)
        %v5380_v10 = vshrl.u32 %v5373_v21, 19 (stack46)
        %v5790_v55 = vadd.s32 1, %v5786_v13 (stack40)
        %v4567_v43 = vadd.s32 %v4564_v7, %v4559_v56 (stack40)
        %v4573_v23 = vshll.u32 %v4564_v7, 6 (stack45)
        %v4574_v17 = vshrl.u32 %v4564_v7, 26 (stack46)
        %v4980_v21 = vor.u32 %v4979_v9, %v4978_v54 (stack47)
        %v3762_v56 = vmul.f32 %v3758_v61, %v123849_v31 (stack54)
        %v4134_v37 = vmul.f32 %v4133_v46, %v4127_v37 (stack63)
        %v5381_v52 = vor.u32 %v5380_v10, %v5379_v8 (stack47)
        %v5794_v44 = vadd.s32 %v5790_v55, %v5778_v44 (stack40)
        %vm123901_vm12 = vcmp.eq.f32.partialorder %v3627_v40, 1.0 (stack68)
        %v4575_v62 = vor.u32 %v4574_v17, %v4573_v23 (stack47)
        %v4981_v12 = vxor.u32 %v4980_v21, %v4976_v32 (stack48)
        %v5796_v41 = vshll.u32 %v5790_v55, 17 (stack45)
        %v5797_v60 = vshrl.u32 %v5790_v55, 15 (stack46)
        %v3766_v6 = vadd.f32 %v3762_v56, %v123797_v6 (stack53)
        %v5382_v14 = vxor.u32 %v5381_v52, %v5377_v36 (stack48)
        %v6203_v20 = vadd.s32 %v6198_v20, %v121574_v2 (stack40)
        %v6214_v13 = vshrl.u32 %v123889_v42, 19 (stack46)
        %vm123908_vm13 = vcmp.lt.f32.partialorder %v4135_v22, 0.0004427343 (stack62)
        %v4576_v53 = vxor.u32 %v4575_v62, %v4567_v43 (stack48)
        %v4984_v50 = vadd.s32 %v4981_v12, %v4976_v32 (stack40)
        %v4990_v46 = vshll.u32 %v4981_v12, 24 (stack45)
        %v4991_v8 = vshrl.u32 %v4981_v12, 8 (stack46)
        %v3770_v31 = vmul.f32 %v3766_v6, %v123849_v31 (stack54)
        %v5385_v36 = vadd.s32 %v5382_v14, %v5377_v36 (stack40)
        %v5387_v7 = vshll.u32 %v5382_v14, 15 (stack45)
        %v5388_v32 = vshrl.u32 %v5382_v14, 17 (stack46)
        %v4571_v54 = vadd.s32 %v4567_v43, %v121564_v0 (stack40)
        %v4579_v9 = vadd.s32 %v4576_v53, %v121574_v2 (stack40)
        %v4992_v61 = vor.u32 %v4991_v8, %v4990_v46 (stack47)
        %v5798_v22 = vor.u32 %v5797_v60, %v5796_v41 (stack47)
        %v3774_v34 = vadd.f32 %v3770_v31, %v123792_v34 (stack53)
        %v5389_v10 = vor.u32 %v5388_v32, %v5387_v7 (stack47)
        %v6211_v42 = vadd.s32 %v123889_v42, %v6203_v20 (stack40)
        %v6215_v25 = vor.u32 %v6214_v13, %v6213_v25 (stack47)
        %v4583_v55 = vadd.s32 5, %v4579_v9 (stack40)
        %v4993_v43 = vxor.u32 %v4992_v61, %v4984_v50 (stack48)
        %v5799_v23 = vxor.u32 %v5798_v22, %v5794_v44 (stack48)
        %v157089_v17 = vld [vmem:[#allocation122_spill] sm:$0xff] (stack84)
        %v123919_v21 = vadd.s32 %v122703_v29, %v157089_v17 (stack40)
        %v3778_v30 = vmul.f32 %v3774_v34, %v123710_v30 (stack54)
        %v5390_v56 = vxor.u32 %v5389_v10, %v5385_v36 (stack48)
        %v6216_v52 = vxor.u32 %v6215_v25, %v6211_v42 (stack48)
        %v157090_v62 = vld [vmem:[#allocation54_spill] sm:$0xff] (stack84)
        %v123924_v12 = vadd.s32 %v157069_v24, %v157090_v62 (stack40)
        %v120462_v41 = vpop.eup %120461 (stack64)
        %v4585_v60 = vxor.u32 %v4583_v55, %v4571_v54 (stack48)
        %v4988_v6 = vadd.s32 %v4984_v50, %v121569_v1 (stack40)
        %v4996_v14 = vadd.s32 %v4993_v43, %v121564_v0 (stack40)
        %v5802_v44 = vadd.s32 %v5799_v23, %v5794_v44 (stack40)
        %v3782_v11 = vsel /*vm=*/%vm123901_vm12, /*on_true_vy=*/%v123787_v11, /*on_false_vx=*/%v3778_v30 (stack44)
        %v4131_v40 = vmul.f32 0.6931472, %v120462_v41 (stack65)
        %v5393_v20 = vadd.s32 %v5390_v56, %v5385_v36 (stack40)
        %v5395_v13 = vshll.u32 %v5390_v56, 26 (stack45)
        %v3786_v53 = vmul.f32 1.4140625, %v3782_v11 (stack54)
        %v4586_v50 = vand.u32.u8 255, %v4585_v60 (stack49)
        %v5000_v46 = vadd.s32 4, %v4996_v14 (stack40)
        %v5396_v8 = vshrl.u32 %v5390_v56, 6 (stack46)
        %v4137_v37 = vsel /*vm=*/%vm123908_vm13, /*on_true_vy=*/%v4134_v37, /*on_false_vx=*/%v4131_v40 (stack66)
        %v5804_v27 = vshll.u32 %v5799_v23, 29 (stack45)
        %v123933_v31 = vadd.s32 %v6216_v52, %v6211_v42 (stack40)
        %v3789_v36 = vpack.c.bf16 %v156663_v45, %v3786_v53 (stack81)
        %v123936_v7 = vxor.u32 2147483648, %v4137_v37 (stack56)
        %v5004_v32 = vadd.s32 %v5000_v46, %v4988_v6 (stack40)
        %v5805_v54 = vshrl.u32 %v5799_v23, 3 (stack46)
        %v5006_v9 = vshll.u32 %v5000_v46, 13 (stack45)
        %v5007_v61 = vshrl.u32 %v5000_v46, 19 (stack46)
        %v5397_v22 = vor.u32 %v5396_v8, %v5395_v13 (stack47)
        %119761 = vst [vmem:[%s123356_s30 + $0x300] sm:$0xf] /*vst_source=*/%v3789_v36 (stack83)
        %120463 = vrsqrt.f32 %v123936_v7 (stack67)
        %v4587_v34 = vand.u32 65535, %v4586_v50 (stack50)
        %vm4141_vm14 = vcmp.lt.f32.partialorder %v123936_v7, 5.0 (stack68)
        %v5008_v10 = vor.u32 %v5007_v61, %v5006_v9 (stack47)
        %v5398_v42 = vxor.u32 %v5397_v22, %v5393_v20 (stack48)
        %v5806_v25 = vor.u32 %v5805_v54, %v5804_v27 (stack47)
        %v5009_v55 = vxor.u32 %v5008_v10, %v5004_v32 (stack48)
        %v6221_v43 = vshll.u32 %v6216_v52, 15 (stack45)
        %v123944_v23 = vsel /*vm=*/%vm4141_vm14, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v123947_v30 = vadd.f32 -2.5, %v123936_v7 (stack53)
        %v4588_v56 = vshrl.u32 %v4587_v34, 1 (stack51)
        %v5401_v41 = vadd.s32 %v5398_v42, %v5393_v20 (stack40)
        %v5012_v60 = vadd.s32 %v5009_v55, %v5004_v32 (stack40)
        %v5014_v6 = vshll.u32 %v5009_v55, 15 (stack45)
        %v5015_v14 = vshrl.u32 %v5009_v55, 17 (stack46)
        %v5407_v11 = vshll.u32 %v5398_v42, 6 (stack45)
        %v123952_v40 = vsel /*vm=*/%vm4141_vm14, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v4589_v20 = vor.u32 16256, %v4588_v56 (stack47)
        %v5408_v13 = vshrl.u32 %v5398_v42, 26 (stack46)
        %v5807_v53 = vxor.u32 %v5806_v25, %v5802_v44 (stack48)
        %v123957_v50 = vsel /*vm=*/%vm4141_vm14, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %vm4186_vm15 = vcmp.eq.f32.partialorder %v123936_v7, inf (stack70)
        %v5016_v46 = vor.u32 %v5015_v14, %v5014_v6 (stack47)
        %v6222_v52 = vshrl.u32 %v6216_v52, 17 (stack46)
        %vm6638_vm0 = vcmp.lt.u32.totalorder %v123919_v21, %v157089_v17 (stack43)
        %vm4188_vm1 = vcmp.eq.f32.partialorder %v123936_v7, 0.0 (stack71)
        %v4590_v8 = vand.u32.u16 65535, %v4589_v20 (stack52)
        %v5409_v37 = vor.u32 %v5408_v13, %v5407_v11 (stack47)
        %v5810_v44 = vadd.s32 %v5807_v53, %v5802_v44 (stack40)
        %v5812_v27 = vshll.u32 %v5807_v53, 16 (stack45)
        %v5017_v36 = vxor.u32 %v5016_v46, %v5012_v60 (stack48)
        %v5813_v32 = vshrl.u32 %v5807_v53, 16 (stack46)
        %v6223_v54 = vor.u32 %v6222_v52, %v6221_v43 (stack47)
        %v123965_v9 = vadd.s32 %v123919_v21, %v122657_v58 (stack40)
        %v4189_v61 = vand.u32 2147483648, %v123936_v7 (stack72)
        %v119768_v22 = vadd.low.f32.bf16 -1.0, %v4590_v8 (stack53)
        %v5410_v34 = vxor.u32 %v5409_v37, %v5401_v41 (stack48)
        %v6647_v10 = vadd.s32 1, %v123924_v12 (stack40)
        %v5020_v42 = vadd.s32 %v5017_v36, %v5012_v60 (stack40)
        %v5022_v25 = vshll.u32 %v5017_v36, 26 (stack45)
        %v5023_v55 = vshrl.u32 %v5017_v36, 6 (stack46)
        %v5814_v43 = vor.u32 %v5813_v32, %v5812_v27 (stack47)
        %v4599_v56 = vmul.f32 2.0, %v119768_v22 (stack54)
        %v5413_v60 = vadd.s32 %v5410_v34, %v121569_v1 (stack40)
        %v6224_v6 = vxor.u32 %v6223_v54, %v123933_v31 (stack48)
        %v6651_v12 = vsel /*vm=*/%vm6638_vm0, /*on_true_vy=*/%v6647_v10, /*on_false_vx=*/%v123924_v12 (stack44)
        %v120464_v14 = vpop.eup %120463 (stack73)
        %v5024_v11 = vor.u32 %v5023_v55, %v5022_v25 (stack47)
        %v5405_v41 = vadd.s32 %v5401_v41, %v121574_v2 (stack40)
        %v5815_v20 = vxor.u32 %v5814_v43, %v5810_v44 (stack48)
        %v123978_v13 = vadd.s32 %v123965_v9, %v121569_v1 (stack40)
        %v4185_v53 = vmul.f32 %v120464_v14, %v123936_v7 (stack74)
        %v4603_v46 = vadd.f32 -0.99609375, %v4599_v56 (stack53)
        %v5417_v52 = vadd.s32 3, %v5413_v60 (stack40)
        %v123982_v31 = vadd.s32 %v6224_v6, %v123933_v31 (stack40)
        %v5025_v8 = vxor.u32 %v5024_v11, %v5020_v42 (stack48)
        %v5818_v37 = vadd.s32 %v5815_v20, %v5810_v44 (stack40)
        %v5824_v44 = vshll.u32 %v5815_v20, 24 (stack45)
        %v5825_v27 = vshrl.u32 %v5815_v20, 8 (stack46)
        %v4187_v36 = vsel /*vm=*/%vm4186_vm15, /*on_true_vy=*/%v123936_v7, /*on_false_vx=*/%v4185_v53 (stack75)
        %v123987_v32 = vmax.f32 %v4603_v46, -0.99609375 (stack55)
        %v5421_v54 = vadd.s32 %v5417_v52, %v5405_v41 (stack40)
        %v5423_v22 = vshll.u32 %v5417_v52, 17 (stack45)
        %v4190_v61 = vsel /*vm=*/%vm4188_vm1, /*on_true_vy=*/%v4189_v61, /*on_false_vx=*/%v4187_v36 (stack76)
        %v5028_v34 = vadd.s32 %v5025_v8, %v5020_v42 (stack40)
        %v5034_v10 = vshll.u32 %v5025_v8, 6 (stack45)
        %v5035_v42 = vshrl.u32 %v5025_v8, 26 (stack46)
        %v4170_v25 = vsel /*vm=*/%vm4141_vm14, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v4174_v55 = vsel /*vm=*/%vm4141_vm14, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v4193_v43 = vadd.f32 -3.0, %v4190_v61 (stack53)
        %v4619_v56 = vxor.u32 2147483648, %v123987_v32 (stack56)
        %v4178_v60 = vsel /*vm=*/%vm4141_vm14, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v5036_v14 = vor.u32 %v5035_v42, %v5034_v10 (stack47)
        %v5424_v11 = vshrl.u32 %v5417_v52, 15 (stack46)
        %vm6633_vm2 = vcmp.lt.u32.totalorder %v123965_v9, %v123919_v21 (stack43)
        %v124006_v30 = vsel /*vm=*/%vm4141_vm14, /*on_true_vy=*/%v123947_v30, /*on_false_vx=*/%v4193_v43 (stack44)
        %v124009_v41 = vmul.f32 %v4619_v56, %v123987_v32 (stack54)
        %v5826_v20 = vor.u32 %v5825_v27, %v5824_v44 (stack47)
        %v6655_v53 = vadd.s32 1, %v6651_v12 (stack40)
        %v4201_v46 = vmul.f32 %v124006_v30, %v4178_v60 (stack54)
        %v5037_v52 = vxor.u32 %v5036_v14, %v5028_v34 (stack48)
        %v5425_v8 = vor.u32 %v5424_v11, %v5423_v22 (stack47)
        %v6674_v44 = vshll.u32 %v123978_v13, 13 (stack45)
        %v4624_v27 = vadd.f32 1.0, %v124009_v41 (stack57)
        %v4627_v36 = vmul.f32 -0.5, %v124009_v41 (stack59)
        %v5827_v22 = vxor.u32 %v5826_v20, %v5818_v37 (stack48)
        %v6229_v61 = vshll.u32 %v6224_v6, 26 (stack45)
        %v4205_v10 = vadd.f32 %v4201_v46, %v4174_v55 (stack53)
        %v5040_v42 = vadd.s32 %v5037_v52, %v121574_v2 (stack40)
        %v5426_v55 = vxor.u32 %v5425_v8, %v5421_v54 (stack48)
        %v6230_v6 = vshrl.u32 %v6224_v6, 6 (stack46)
        %120465 = vlog2.f32 %v4624_v27 (stack58)
        %v5032_v34 = vadd.s32 %v5028_v34, %v121564_v0 (stack40)
        %v5822_v37 = vadd.s32 %v5818_v37, %v121564_v0 (stack40)
        %v5830_v43 = vadd.s32 %v5827_v22, %v121574_v2 (stack40)
        %v4209_v56 = vmul.f32 %v4205_v10, %v124006_v30 (stack54)
        %v5044_v60 = vadd.s32 5, %v5040_v42 (stack40)
        %v5429_v54 = vadd.s32 %v5426_v55, %v5421_v54 (stack40)
        %v5431_v14 = vshll.u32 %v5426_v55, 29 (stack45)
        %v4630_v11 = vand.u32 2147483647, %v124009_v41 (stack60)
        %v5432_v20 = vshrl.u32 %v5426_v55, 3 (stack46)
        %v5834_v46 = vadd.s32 2, %v5830_v43 (stack40)
        %v6231_v52 = vor.u32 %v6230_v6, %v6229_v61 (stack47)
        %v4213_v25 = vadd.f32 %v4209_v56, %v4170_v25 (stack53)
        %v4628_v8 = vadd.f32 1.0, %v4627_v36 (stack61)
        %v5046_v27 = vxor.u32 %v5044_v60, %v5032_v34 (stack48)
        %v6659_v21 = vsel /*vm=*/%vm6633_vm2, /*on_true_vy=*/%v6655_v53, /*on_false_vx=*/%v6651_v12 (stack44)
        %v5433_v9 = vor.u32 %v5432_v20, %v5431_v14 (stack47)
        %v5838_v12 = vadd.s32 %v5834_v46, %v5822_v37 (stack40)
        %v5840_v53 = vshll.u32 %v5834_v46, 13 (stack45)
        %v5841_v36 = vshrl.u32 %v5834_v46, 19 (stack46)
        %v4217_v22 = vmul.f32 %v4213_v25, %v124006_v30 (stack54)
        %v5047_v61 = vand.u32.u8 255, %v5046_v27 (stack49)
        %v6232_v10 = vxor.u32 %v6231_v52, %v123982_v31 (stack48)
        %v6675_v42 = vshrl.u32 %v123978_v13, 19 (stack46)
        %v5434_v55 = vxor.u32 %v5433_v9, %v5429_v54 (stack48)
        %v5842_v6 = vor.u32 %v5841_v36, %v5840_v53 (stack47)
        %v6664_v34 = vadd.s32 %v6659_v21, %v121574_v2 (stack40)
        %v157091_v37 = vld [vmem:[#allocation120_spill] sm:$0xff] (stack84)
        %v124030_v43 = vadd.s32 %v122703_v29, %v157091_v37 (stack40)
        %v4221_v50 = vadd.f32 %v4217_v22, %v123957_v50 (stack53)
        %v5048_v56 = vand.u32 65535, %v5047_v61 (stack50)
        %v6235_v31 = vadd.s32 %v6232_v10, %v123982_v31 (stack40)
        %v6241_v60 = vshll.u32 %v6232_v10, 6 (stack45)
        %v5437_v54 = vadd.s32 %v5434_v55, %v5429_v54 (stack40)
        %v5439_v14 = vshll.u32 %v5434_v55, 16 (stack45)
        %v5440_v20 = vshrl.u32 %v5434_v55, 16 (stack46)
        %v5843_v46 = vxor.u32 %v5842_v6, %v5838_v12 (stack48)
        %v4225_v52 = vmul.f32 %v4221_v50, %v124006_v30 (stack54)
        %v5049_v25 = vshrl.u32 %v5048_v56, 1 (stack51)
        %v6242_v27 = vshrl.u32 %v6232_v10, 26 (stack46)
        %v6676_v44 = vor.u32 %v6675_v42, %v6674_v44 (stack47)
        %v5441_v21 = vor.u32 %v5440_v20, %v5439_v14 (stack47)
        %v5846_v9 = vadd.s32 %v5843_v46, %v5838_v12 (stack40)
        %v5848_v12 = vshll.u32 %v5843_v46, 15 (stack45)
        %v5849_v53 = vshrl.u32 %v5843_v46, 17 (stack46)
        %v4229_v40 = vadd.f32 %v4225_v52, %v123952_v40 (stack53)
        %v5050_v36 = vor.u32 16256, %v5049_v25 (stack47)
        %v6243_v22 = vor.u32 %v6242_v27, %v6241_v60 (stack47)
        %v6672_v13 = vadd.s32 %v123978_v13, %v6664_v34 (stack40)
        %v4629_v41 = vmul.f32 %v4628_v8, %v124009_v41 (stack63)
        %v5442_v8 = vxor.u32 %v5441_v21, %v5437_v54 (stack48)
        %v5850_v61 = vor.u32 %v5849_v53, %v5848_v12 (stack47)
        %vm7099_vm3 = vcmp.lt.u32.totalorder %v124030_v43, %v157091_v37 (stack43)
        %v120466_v10 = vpop.eup %120465 (stack64)
        %v4233_v42 = vmul.f32 %v4229_v40, %v124006_v30 (stack54)
        %v5051_v55 = vand.u32.u16 65535, %v5050_v36 (stack52)
        %v6244_v6 = vxor.u32 %v6243_v22, %v6235_v31 (stack48)
        %v124041_v34 = vxor.u32 %v6676_v44, %v6672_v13 (stack48)
        %v4626_v50 = vmul.f32 0.6931472, %v120466_v10 (stack65)
        %v5445_v56 = vadd.s32 %v5442_v8, %v5437_v54 (stack40)
        %v5451_v60 = vshll.u32 %v5442_v8, 24 (stack45)
        %v5452_v54 = vshrl.u32 %v5442_v8, 8 (stack46)
        %v4237_v23 = vadd.f32 %v4233_v42, %v123944_v23 (stack53)
        %vm4631_vm4 = vcmp.lt.f32.partialorder %v4630_v11, 0.0004427343 (stack62)
        %v119770_v11 = vadd.low.f32.bf16 -1.0, %v5051_v55 (stack53)
        %v5851_v14 = vxor.u32 %v5850_v61, %v5846_v9 (stack48)
        %v4632_v20 = vsel /*vm=*/%vm4631_vm4, /*on_true_vy=*/%v4629_v41, /*on_false_vx=*/%v4626_v50 (stack66)
        %v5453_v46 = vor.u32 %v5452_v54, %v5451_v60 (stack47)
        %v6247_v52 = vadd.s32 %v6244_v6, %v121564_v0 (stack40)
        %v124046_v25 = vadd.s32 %v124041_v34, %v6672_v13 (stack40)
        %v4114_v27 = vand.u32 2147483647, %v123875_v26 (stack77)
        %v4241_v44 = vmul.f32 %v4237_v23, %v124006_v30 (stack54)
        %v124050_v21 = vxor.u32 2147483648, %v4632_v20 (stack56)
        %v5854_v9 = vadd.s32 %v5851_v14, %v5846_v9 (stack40)
        %v4154_v12 = vsel /*vm=*/%vm4141_vm14, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v5454_v53 = vxor.u32 %v5453_v46, %v5445_v56 (stack48)
        %v5856_v40 = vshll.u32 %v5851_v14, 26 (stack45)
        %v5857_v36 = vshrl.u32 %v5851_v14, 6 (stack46)
        %v4245_v22 = vadd.f32 %v4241_v44, %v4154_v12 (stack53)
        %120467 = vrsqrt.f32 %v124050_v21 (stack67)
        %v5060_v13 = vmul.f32 2.0, %v119770_v11 (stack54)
        %v5457_v41 = vadd.s32 %v5454_v53, %v121564_v0 (stack40)
        %v6251_v8 = vadd.s32 1, %v6247_v52 (stack40)
        %v4122_v61 = vmul.f32 inf, %v123875_v26 (stack54)
        %v4146_v10 = vsel /*vm=*/%vm4141_vm14, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v4150_v7 = vsel /*vm=*/%vm4141_vm14, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v4249_v42 = vmul.f32 %v4245_v22, %v124006_v30 (stack54)
        %vm124065_vm5 = vcmp.eq.f32.partialorder %v4114_v27, 1.0 (stack68)
        %v4609_v6 = vand.u32 2147483647, %v123987_v32 (stack77)
        %v124071_v50 = vmul.f32 inf, %v123987_v32 (stack54)
        %v5858_v60 = vor.u32 %v5857_v36, %v5856_v40 (stack47)
        %v6239_v31 = vadd.s32 %v6235_v31, %v121569_v1 (stack40)
        %v4253_v54 = vadd.f32 %v4249_v42, %v4150_v7 (stack53)
        %vm4636_vm6 = vcmp.lt.f32.partialorder %v124050_v21, 5.0 (stack68)
        %v5449_v56 = vadd.s32 %v5445_v56, %v121569_v1 (stack40)
        %v124078_v23 = vadd.s32 %v124030_v43, %v122657_v58 (stack40)
        %v5064_v11 = vadd.f32 -0.99609375, %v5060_v13 (stack53)
        %v5461_v14 = vadd.s32 4, %v5457_v41 (stack40)
        %v5859_v20 = vxor.u32 %v5858_v60, %v5854_v9 (stack48)
        %v6255_v46 = vadd.s32 %v6251_v8, %v6239_v31 (stack40)
        %v4257_v30 = vmul.f32 %v4253_v54, %v124006_v30 (stack54)
        %v4677_v52 = vadd.f32 -2.5, %v124050_v21 (stack53)
        %v6257_v27 = vshll.u32 %v6251_v8, 17 (stack45)
        %v6258_v44 = vshrl.u32 %v6251_v8, 15 (stack46)
        %v124082_v12 = vmax.f32 %v5064_v11, -0.99609375 (stack55)
        %v5465_v53 = vadd.s32 %v5461_v14, %v5449_v56 (stack40)
        %v5467_v40 = vshll.u32 %v5461_v14, 13 (stack45)
        %v5468_v36 = vshrl.u32 %v5461_v14, 19 (stack46)
        %v4261_v22 = vadd.f32 %v4257_v30, %v4146_v10 (stack53)
        %v5862_v9 = vadd.s32 %v5859_v20, %v5854_v9 (stack40)
        %v5868_v13 = vshll.u32 %v5859_v20, 6 (stack45)
        %v5869_v41 = vshrl.u32 %v5859_v20, 26 (stack46)
        %v124087_v8 = vsel /*vm=*/%vm4636_vm6, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v124092_v10 = vsel /*vm=*/%vm4636_vm6, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v5080_v7 = vxor.u32 2147483648, %v124082_v12 (stack56)
        %v5469_v42 = vor.u32 %v5468_v36, %v5467_v40 (stack47)
        %v4265_v26 = vmul.f32 %v4261_v22, %v123875_v26 (stack54)
        %v124099_v60 = vsel /*vm=*/%vm4636_vm6, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v5870_v31 = vor.u32 %v5869_v41, %v5868_v13 (stack47)
        %v6259_v54 = vor.u32 %v6258_v44, %v6257_v27 (stack47)
        %v4673_v56 = vsel /*vm=*/%vm4636_vm6, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %vm4681_vm7 = vcmp.eq.f32.partialorder %v124050_v21, inf (stack70)
        %v124106_v11 = vmul.f32 %v5080_v7, %v124082_v12 (stack54)
        %v5470_v14 = vxor.u32 %v5469_v42, %v5465_v53 (stack48)
        %v4269_v61 = vsel /*vm=*/%vm124065_vm5, /*on_true_vy=*/%v4122_v61, /*on_false_vx=*/%v4265_v26 (stack44)
        %vm4683_vm8 = vcmp.eq.f32.partialorder %v124050_v21, 0.0 (stack71)
        %v5871_v55 = vxor.u32 %v5870_v31, %v5862_v9 (stack48)
        %v6260_v20 = vxor.u32 %v6259_v54, %v6255_v46 (stack48)
        %v120468_v30 = vpop.eup %120467 (stack73)
        %v4273_v27 = vmul.f32 1.4140625, %v4269_v61 (stack54)
        %v5085_v44 = vadd.f32 1.0, %v124106_v11 (stack57)
        %v6682_v40 = vshll.u32 %v124041_v34, 15 (stack45)
        %v6683_v34 = vshrl.u32 %v124041_v34, 17 (stack46)
        %v4680_v36 = vmul.f32 %v120468_v30, %v124050_v21 (stack74)
        %v5473_v53 = vadd.s32 %v5470_v14, %v5465_v53 (stack40)
        %v5475_v22 = vshll.u32 %v5470_v14, 15 (stack45)
        %v5476_v13 = vshrl.u32 %v5470_v14, 17 (stack46)
        %v4276_v41 = vpack.c.bf16 %v156663_v45, %v4273_v27 (stack81)
        %v4684_v7 = vand.u32 2147483648, %v124050_v21 (stack72)
        %120469 = vlog2.f32 %v5085_v44 (stack58)
        %v5866_v9 = vadd.s32 %v5862_v9, %v121574_v2 (stack40)
        %v4682_v42 = vsel /*vm=*/%vm4681_vm7, /*on_true_vy=*/%v124050_v21, /*on_false_vx=*/%v4680_v36 (stack75)
        %v5477_v26 = vor.u32 %v5476_v13, %v5475_v22 (stack47)
        %v5874_v31 = vadd.s32 %v5871_v55, %v121569_v1 (stack40)
        %v6263_v46 = vadd.s32 %v6260_v20, %v6255_v46 (stack40)
        %119763 = vst [vmem:[%s123356_s30 + $0x380] sm:$0xf] /*vst_source=*/%v4276_v41 (stack83)
        %v4685_v54 = vsel /*vm=*/%vm4683_vm8, /*on_true_vy=*/%v4684_v7, /*on_false_vx=*/%v4682_v42 (stack76)
        %v5088_v14 = vmul.f32 -0.5, %v124106_v11 (stack59)
        %v6265_v61 = vshll.u32 %v6260_v20, 29 (stack45)
        %v6266_v55 = vshrl.u32 %v6260_v20, 3 (stack46)
        %v4688_v20 = vadd.f32 -3.0, %v4685_v54 (stack53)
        %v5478_v30 = vxor.u32 %v5477_v26, %v5473_v53 (stack48)
        %v5878_v27 = vadd.s32 3, %v5874_v31 (stack40)
        %v6684_v44 = vor.u32 %v6683_v34, %v6682_v40 (stack47)
        %v5091_v40 = vand.u32 2147483647, %v124106_v11 (stack60)
        %v6267_v34 = vor.u32 %v6266_v55, %v6265_v61 (stack47)
        %v157094_v36 = vld [vmem:[#allocation53_spill] sm:$0xff] (stack84)
        %v7104_v22 = vadd.s32 %v157069_v24, %v157094_v36 (stack40)
        %v157095_v13 = vld [vmem:[#allocation124_spill] sm:$0xff] (stack84)
        %v124131_v29 = vadd.s32 %v122703_v29, %v157095_v13 (stack40)
        %v124135_v52 = vsel /*vm=*/%vm4636_vm6, /*on_true_vy=*/%v4677_v52, /*on_false_vx=*/%v4688_v20 (stack44)
        %v5481_v53 = vadd.s32 %v5478_v30, %v5473_v53 (stack40)
        %v5483_v41 = vshll.u32 %v5478_v30, 26 (stack45)
        %v5484_v7 = vshrl.u32 %v5478_v30, 6 (stack46)
        %v4696_v56 = vmul.f32 %v124135_v52, %v4673_v56 (stack54)
        %v5882_v9 = vadd.s32 %v5878_v27, %v5866_v9 (stack40)
        %v5884_v42 = vshll.u32 %v5878_v27, 17 (stack45)
        %v5885_v26 = vshrl.u32 %v5878_v27, 15 (stack46)
        %v4669_v31 = vsel /*vm=*/%vm4636_vm6, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v5485_v54 = vor.u32 %v5484_v7, %v5483_v41 (stack47)
        %v6268_v61 = vxor.u32 %v6267_v34, %v6263_v46 (stack48)
        %v6685_v55 = vxor.u32 %v6684_v44, %v124046_v25 (stack48)
        %v4700_v20 = vadd.f32 %v4696_v56, %v4669_v31 (stack53)
        %v5089_v14 = vadd.f32 1.0, %v5088_v14 (stack61)
        %vm124142_vm9 = vcmp.lt.f32.partialorder %v5091_v40, 0.0004427343 (stack62)
        %v5886_v27 = vor.u32 %v5885_v26, %v5884_v42 (stack47)
        %v5486_v44 = vxor.u32 %v5485_v54, %v5481_v53 (stack48)
        %v6271_v46 = vadd.s32 %v6268_v61, %v6263_v46 (stack40)
        %v6273_v40 = vshll.u32 %v6268_v61, 16 (stack45)
        %v6274_v34 = vshrl.u32 %v6268_v61, 16 (stack46)
        %v4704_v41 = vmul.f32 %v4700_v20, %v124135_v52 (stack54)
        %v5887_v7 = vxor.u32 %v5886_v27, %v5882_v9 (stack48)
        %v124148_v25 = vadd.s32 %v6685_v55, %v124046_v25 (stack40)
        %v7108_v56 = vadd.s32 1, %v7104_v22 (stack40)
        %v5489_v53 = vadd.s32 %v5486_v44, %v5481_v53 (stack40)
        %v5495_v42 = vshll.u32 %v5486_v44, 6 (stack45)
        %v5496_v26 = vshrl.u32 %v5486_v44, 26 (stack46)
        %v6275_v31 = vor.u32 %v6274_v34, %v6273_v40 (stack47)
        %v4708_v60 = vadd.f32 %v4704_v41, %v124099_v60 (stack53)
        %v5890_v9 = vadd.s32 %v5887_v7, %v5882_v9 (stack40)
        %v5892_v54 = vshll.u32 %v5887_v7, 29 (stack45)
        %v5893_v61 = vshrl.u32 %v5887_v7, 3 (stack46)
        %v120470_v20 = vpop.eup %120469 (stack64)
        %v5090_v11 = vmul.f32 %v5089_v14, %v124106_v11 (stack63)
        %v5497_v14 = vor.u32 %v5496_v26, %v5495_v42 (stack47)
        %v6276_v27 = vxor.u32 %v6275_v31, %v6271_v46 (stack48)
        %v6690_v44 = vshll.u32 %v6685_v55, 26 (stack45)
        %v4712_v40 = vmul.f32 %v4708_v60, %v124135_v52 (stack54)
        %v5087_v34 = vmul.f32 0.6931472, %v120470_v20 (stack65)
        %v5894_v41 = vor.u32 %v5893_v61, %v5892_v54 (stack47)
        %v7112_v22 = vsel /*vm=*/%vm7099_vm3, /*on_true_vy=*/%v7108_v56, /*on_false_vx=*/%v7104_v22 (stack44)
        %v5498_v7 = vxor.u32 %v5497_v14, %v5489_v53 (stack48)
        %v6279_v46 = vadd.s32 %v6276_v27, %v6271_v46 (stack40)
        %v6285_v56 = vshll.u32 %v6276_v27, 24 (stack45)
        %v6691_v55 = vshrl.u32 %v6685_v55, 6 (stack46)
        %v4716_v10 = vadd.f32 %v4712_v40, %v124092_v10 (stack53)
        %v5093_v30 = vsel /*vm=*/%vm124142_vm9, /*on_true_vy=*/%v5090_v11, /*on_false_vx=*/%v5087_v34 (stack66)
        %v5895_v42 = vxor.u32 %v5894_v41, %v5890_v9 (stack48)
        %v6286_v26 = vshrl.u32 %v6276_v27, 8 (stack46)
        %v124162_v31 = vsel /*vm=*/%vm4636_vm6, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v4649_v60 = vsel /*vm=*/%vm4636_vm6, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v124167_v54 = vxor.u32 2147483648, %v5093_v30 (stack56)
        %v124171_v61 = vadd.s32 %v124078_v23, %v121569_v1 (stack40)
        %v4720_v20 = vmul.f32 %v4716_v10, %v124135_v52 (stack54)
        %v5898_v9 = vadd.s32 %v5895_v42, %v5890_v9 (stack40)
        %v5900_v11 = vshll.u32 %v5895_v42, 16 (stack45)
        %v5901_v14 = vshrl.u32 %v5895_v42, 16 (stack46)
        %v4653_v27 = vsel /*vm=*/%vm4636_vm6, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v4657_v21 = vsel /*vm=*/%vm4636_vm6, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %120471 = vrsqrt.f32 %v124167_v54 (stack67)
        %v5501_v40 = vadd.s32 %v5498_v7, %v121574_v2 (stack40)
        %v4724_v34 = vadd.f32 %v4720_v20, %v4657_v21 (stack53)
        %vm5097_vm10 = vcmp.lt.f32.partialorder %v124167_v54, 5.0 (stack68)
        %v6287_v41 = vor.u32 %v6286_v26, %v6285_v56 (stack47)
        %v6692_v44 = vor.u32 %v6691_v55, %v6690_v44 (stack47)
        %v5902_v7 = vor.u32 %v5901_v14, %v5900_v11 (stack47)
        %vm7094_vm11 = vcmp.lt.u32.totalorder %v124078_v23, %v124030_v43 (stack43)
        %v7135_v56 = vshll.u32 %v124171_v61, 13 (stack45)
        %v7136_v55 = vshrl.u32 %v124171_v61, 19 (stack46)
        %v4728_v10 = vmul.f32 %v4724_v34, %v124135_v52 (stack54)
        %v124189_v30 = vadd.f32 -2.5, %v124167_v54 (stack53)
        %v5493_v53 = vadd.s32 %v5489_v53, %v121564_v0 (stack40)
        %v6283_v42 = vadd.s32 %v6279_v46, %v121564_v0 (stack40)
        %v124196_v26 = vsel /*vm=*/%vm5097_vm10, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v124201_v20 = vsel /*vm=*/%vm5097_vm10, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v5505_v11 = vadd.s32 5, %v5501_v40 (stack40)
        %v5903_v14 = vxor.u32 %v5902_v7, %v5898_v9 (stack48)
        %v4732_v27 = vadd.f32 %v4728_v10, %v4653_v27 (stack53)
        %v6288_v46 = vxor.u32 %v6287_v41, %v6279_v46 (stack48)
        %v6693_v21 = vxor.u32 %v6692_v44, %v124148_v25 (stack48)
        %v7116_v40 = vadd.s32 1, %v7112_v22 (stack40)
        %v5507_v34 = vxor.u32 %v5505_v11, %v5493_v53 (stack48)
        %v5906_v9 = vadd.s32 %v5903_v14, %v5898_v9 (stack40)
        %v5912_v41 = vshll.u32 %v5903_v14, 24 (stack45)
        %v5913_v44 = vshrl.u32 %v5903_v14, 8 (stack46)
        %v4736_v7 = vmul.f32 %v4732_v27, %v124135_v52 (stack54)
        %vm5142_vm12 = vcmp.eq.f32.partialorder %v124167_v54, inf (stack70)
        %v6291_v10 = vadd.s32 %v6288_v46, %v121574_v2 (stack40)
        %v6696_v25 = vadd.s32 %v6693_v21, %v124148_v25 (stack40)
        %v6702_v53 = vshll.u32 %v6693_v21, 6 (stack45)
        %vm5144_vm13 = vcmp.eq.f32.partialorder %v124167_v54, 0.0 (stack71)
        %v5508_v11 = vand.u32.u8 255, %v5507_v34 (stack49)
        %v5914_v14 = vor.u32 %v5913_v44, %v5912_v41 (stack47)
        %v6703_v27 = vshrl.u32 %v6693_v21, 26 (stack46)
        %v4740_v60 = vadd.f32 %v4736_v7, %v4649_v60 (stack53)
        %v5145_v46 = vand.u32 2147483648, %v124167_v54 (stack72)
        %v6295_v21 = vadd.s32 2, %v6291_v10 (stack40)
        %v7120_v43 = vsel /*vm=*/%vm7094_vm11, /*on_true_vy=*/%v7116_v40, /*on_false_vx=*/%v7112_v22 (stack44)
        %v5509_v23 = vand.u32 65535, %v5508_v11 (stack50)
        %v5915_v22 = vxor.u32 %v5914_v14, %v5906_v9 (stack48)
        %v6704_v40 = vor.u32 %v6703_v27, %v6702_v53 (stack47)
        %v7125_v34 = vadd.s32 %v7120_v43, %v121574_v2 (stack40)
        %v4744_v41 = vmul.f32 %v4740_v60, %v124135_v52 (stack54)
        %v6299_v42 = vadd.s32 %v6295_v21, %v6283_v42 (stack40)
        %v6301_v44 = vshll.u32 %v6295_v21, 13 (stack45)
        %v6302_v7 = vshrl.u32 %v6295_v21, 19 (stack46)
        %vm124217_vm14 = vcmp.eq.f32.partialorder %v4609_v6, 1.0 (stack68)
        %v5510_v10 = vshrl.u32 %v5509_v23, 1 (stack51)
        %v5918_v53 = vadd.s32 %v5915_v22, %v121564_v0 (stack40)
        %v6705_v11 = vxor.u32 %v6704_v40, %v6696_v25 (stack48)
        %v7133_v61 = vadd.s32 %v124171_v61, %v7125_v34 (stack40)
        %v120472_v14 = vpop.eup %120471 (stack73)
        %v4748_v31 = vadd.f32 %v4744_v41, %v124162_v31 (stack53)
        %v5910_v9 = vadd.s32 %v5906_v9, %v121569_v1 (stack40)
        %v6303_v27 = vor.u32 %v6302_v7, %v6301_v44 (stack47)
        %v7137_v56 = vor.u32 %v7136_v55, %v7135_v56 (stack47)
        %v5141_v55 = vmul.f32 %v120472_v14, %v124167_v54 (stack74)
        %v5511_v60 = vor.u32 16256, %v5510_v10 (stack47)
        %v5922_v21 = vadd.s32 4, %v5918_v53 (stack40)
        %v6700_v25 = vadd.s32 %v6696_v25, %v121569_v1 (stack40)
        %v4752_v52 = vmul.f32 %v4748_v31, %v124135_v52 (stack54)
        %v6304_v43 = vxor.u32 %v6303_v27, %v6299_v42 (stack48)
        %v6708_v23 = vadd.s32 %v6705_v11, %v121564_v0 (stack40)
        %v7138_v22 = vxor.u32 %v7137_v56, %v7133_v61 (stack48)
        %v5143_v40 = vsel /*vm=*/%vm5142_vm12, /*on_true_vy=*/%v124167_v54, /*on_false_vx=*/%v5141_v55 (stack75)
        %v5512_v34 = vand.u32.u16 65535, %v5511_v60 (stack52)
        %v5926_v41 = vadd.s32 %v5922_v21, %v5910_v9 (stack40)
        %v5928_v44 = vshll.u32 %v5922_v21, 13 (stack45)
        %v4756_v8 = vadd.f32 %v4752_v52, %v124087_v8 (stack53)
        %v5146_v46 = vsel /*vm=*/%vm5144_vm13, /*on_true_vy=*/%v5145_v46, /*on_false_vx=*/%v5143_v40 (stack76)
        %v5929_v7 = vshrl.u32 %v5922_v21, 19 (stack46)
        %v6307_v42 = vadd.s32 %v6304_v43, %v6299_v42 (stack40)
        %v5149_v10 = vadd.f32 -3.0, %v5146_v46 (stack53)
        %v119772_v53 = vadd.low.f32.bf16 -1.0, %v5512_v34 (stack53)
        %v6309_v11 = vshll.u32 %v6304_v43, 15 (stack45)
        %v6310_v14 = vshrl.u32 %v6304_v43, 17 (stack46)
        %v4760_v32 = vmul.f32 %v4756_v8, %v123987_v32 (stack54)
        %v5930_v31 = vor.u32 %v5929_v7, %v5928_v44 (stack47)
        %v6712_v9 = vadd.s32 1, %v6708_v23 (stack40)
        %v124236_v61 = vadd.s32 %v7138_v22, %v7133_v61 (stack40)
        %v124241_v30 = vsel /*vm=*/%vm5097_vm10, /*on_true_vy=*/%v124189_v30, /*on_false_vx=*/%v5149_v10 (stack44)
        %v5521_v27 = vmul.f32 2.0, %v119772_v53 (stack54)
        %v6311_v56 = vor.u32 %v6310_v14, %v6309_v11 (stack47)
        %v7143_v55 = vshll.u32 %v7138_v22, 15 (stack45)
        %v4764_v50 = vsel /*vm=*/%vm124217_vm14, /*on_true_vy=*/%v124071_v50, /*on_false_vx=*/%v4760_v32 (stack44)
        %v5157_v20 = vmul.f32 %v124241_v30, %v124201_v20 (stack54)
        %v5931_v6 = vxor.u32 %v5930_v31, %v5926_v41 (stack48)
        %v6716_v60 = vadd.s32 %v6712_v9, %v6700_v25 (stack40)
        %v4768_v21 = vmul.f32 1.4140625, %v4764_v50 (stack54)
        %v5525_v25 = vadd.f32 -0.99609375, %v5521_v27 (stack53)
        %v6312_v52 = vxor.u32 %v6311_v56, %v6307_v42 (stack48)
        %v6718_v43 = vshll.u32 %v6712_v9, 17 (stack45)
        %v5161_v26 = vadd.f32 %v5157_v20, %v124196_v26 (stack53)
        %v5934_v23 = vadd.s32 %v5931_v6, %v5926_v41 (stack40)
        %v5936_v40 = vshll.u32 %v5931_v6, 15 (stack45)
        %v5937_v34 = vshrl.u32 %v5931_v6, 17 (stack46)
        %v4771_v41 = vpack.c.bf16 %v156663_v45, %v4768_v21 (stack81)
        %v124250_v44 = vmax.f32 %v5525_v25, -0.99609375 (stack55)
        %v6315_v8 = vadd.s32 %v6312_v52, %v6307_v42 (stack40)
        %v6317_v46 = vshll.u32 %v6312_v52, 26 (stack45)
        %v5165_v7 = vmul.f32 %v5161_v26, %v124241_v30 (stack54)
        %v5938_v42 = vor.u32 %v5937_v34, %v5936_v40 (stack47)
        %v6318_v10 = vshrl.u32 %v6312_v52, 6 (stack46)
        %v6719_v53 = vshrl.u32 %v6712_v9, 15 (stack46)
        %119769 = vst [vmem:[%s123356_s30 + $0x4] sm:$0xf] /*vst_source=*/%v4771_v41 (stack83)
        %v5070_v11 = vand.u32 2147483647, %v124082_v12 (stack77)
        %v5126_v14 = vsel /*vm=*/%vm5097_vm10, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v5541_v32 = vxor.u32 2147483648, %v124250_v44 (stack56)
        %v7144_v22 = vshrl.u32 %v7138_v22, 17 (stack46)
        %v5169_v31 = vadd.f32 %v5165_v7, %v5126_v14 (stack53)
        %v5939_v9 = vxor.u32 %v5938_v42, %v5934_v23 (stack48)
        %v6319_v27 = vor.u32 %v6318_v10, %v6317_v46 (stack47)
        %v6720_v56 = vor.u32 %v6719_v53, %v6718_v43 (stack47)
        %v124260_v50 = vmul.f32 inf, %v124082_v12 (stack54)
        %v124263_v20 = vmul.f32 %v5541_v32, %v124250_v44 (stack54)
        %v7145_v55 = vor.u32 %v7144_v22, %v7143_v55 (stack47)
        %vm7560_vm15 = vcmp.lt.u32.totalorder %v124131_v29, %v157095_v13 (stack43)
        %v5173_v6 = vmul.f32 %v5169_v31, %v124241_v30 (stack54)
        %v5942_v21 = vadd.s32 %v5939_v9, %v5934_v23 (stack40)
        %v5944_v25 = vshll.u32 %v5939_v9, 26 (stack45)
        %v5945_v52 = vshrl.u32 %v5939_v9, 6 (stack46)
        %v124271_v43 = vsel /*vm=*/%vm5097_vm10, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v5122_v26 = vsel /*vm=*/%vm5097_vm10, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v5546_v23 = vadd.f32 1.0, %v124263_v20 (stack57)
        %v6320_v40 = vxor.u32 %v6319_v27, %v6315_v8 (stack48)
        %v5177_v34 = vadd.f32 %v5173_v6, %v5122_v26 (stack53)
        %v5946_v41 = vor.u32 %v5945_v52, %v5944_v25 (stack47)
        %v6721_v46 = vxor.u32 %v6720_v56, %v6716_v60 (stack48)
        %v7146_v7 = vxor.u32 %v7145_v55, %v124236_v61 (stack48)
        %v5110_v42 = vsel /*vm=*/%vm5097_vm10, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v5114_v10 = vsel /*vm=*/%vm5097_vm10, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %120473 = vlog2.f32 %v5546_v23 (stack58)
        %v6323_v8 = vadd.s32 %v6320_v40, %v6315_v8 (stack40)
        %v5181_v53 = vmul.f32 %v5177_v34, %v124241_v30 (stack54)
        %v5947_v14 = vxor.u32 %v5946_v41, %v5942_v21 (stack48)
        %v6329_v32 = vshll.u32 %v6320_v40, 6 (stack45)
        %v6330_v22 = vshrl.u32 %v6320_v40, 26 (stack46)
        %v5118_v31 = vsel /*vm=*/%vm5097_vm10, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v5549_v9 = vmul.f32 -0.5, %v124263_v20 (stack59)
        %v6724_v60 = vadd.s32 %v6721_v46, %v6716_v60 (stack40)
        %v6726_v27 = vshll.u32 %v6721_v46, 29 (stack45)
        %v5185_v56 = vadd.f32 %v5181_v53, %v5118_v31 (stack53)
        %v5950_v55 = vadd.s32 %v5947_v14, %v5942_v21 (stack40)
        %v5956_v6 = vshll.u32 %v5947_v14, 6 (stack45)
        %v5957_v21 = vshrl.u32 %v5947_v14, 26 (stack46)
        %v6331_v25 = vor.u32 %v6330_v22, %v6329_v32 (stack47)
        %v6727_v52 = vshrl.u32 %v6721_v46, 3 (stack46)
        %v7149_v61 = vadd.s32 %v7146_v7, %v124236_v61 (stack40)
        %v7151_v26 = vshll.u32 %v7146_v7, 26 (stack45)
        %v5189_v23 = vmul.f32 %v5185_v56, %v124241_v30 (stack54)
        %v5958_v40 = vor.u32 %v5957_v21, %v5956_v6 (stack47)
        %v7152_v34 = vshrl.u32 %v7146_v7, 6 (stack46)
        %v124293_v41 = vadd.s32 %v124131_v29, %v122657_v58 (stack40)
        %v5552_v46 = vand.u32 2147483647, %v124263_v20 (stack60)
        %v6332_v7 = vxor.u32 %v6331_v25, %v6323_v8 (stack48)
        %v6728_v53 = vor.u32 %v6727_v52, %v6726_v27 (stack47)
        %v157100_v14 = vld [vmem:[#allocation58_spill] sm:$0xff] (stack84)
        %v7565_v24 = vadd.s32 %v157069_v24, %v157100_v14 (stack40)
        %v5193_v10 = vadd.f32 %v5189_v23, %v5114_v10 (stack53)
        %v5959_v32 = vxor.u32 %v5958_v40, %v5950_v55 (stack48)
        %v7153_v22 = vor.u32 %v7152_v34, %v7151_v26 (stack47)
        %v157101_v31 = vld [vmem:[#allocation126_spill] sm:$0xff] (stack84)
        %v124300_v27 = vadd.s32 %v157101_v31, %v122651_v47 (stack40)
        %v5550_v9 = vadd.f32 1.0, %v5549_v9 (stack61)
        %v6327_v8 = vadd.s32 %v6323_v8, %v121574_v2 (stack40)
        %v6335_v56 = vadd.s32 %v6332_v7, %v121569_v1 (stack40)
        %v6729_v6 = vxor.u32 %v6728_v53, %v6724_v60 (stack48)
        %v5197_v21 = vmul.f32 %v5193_v10, %v124241_v30 (stack54)
        %v5954_v55 = vadd.s32 %v5950_v55, %v121564_v0 (stack40)
        %v5962_v25 = vadd.s32 %v5959_v32, %v121574_v2 (stack40)
        %v7154_v52 = vxor.u32 %v7153_v22, %v7149_v61 (stack48)
        %v6339_v26 = vadd.s32 3, %v6335_v56 (stack40)
        %v6732_v60 = vadd.s32 %v6729_v6, %v6724_v60 (stack40)
        %v6734_v23 = vshll.u32 %v6729_v6, 16 (stack45)
        %v6735_v40 = vshrl.u32 %v6729_v6, 16 (stack46)
        %v5201_v42 = vadd.f32 %v5197_v21, %v5110_v42 (stack53)
        %v5966_v34 = vadd.s32 5, %v5962_v25 (stack40)
        %v124307_v61 = vadd.s32 %v7154_v52, %v7149_v61 (stack40)
        %v7569_v7 = vadd.s32 1, %v7565_v24 (stack40)
        %v6343_v53 = vadd.s32 %v6339_v26, %v6327_v8 (stack40)
        %v6345_v10 = vshll.u32 %v6339_v26, 17 (stack45)
        %v6346_v32 = vshrl.u32 %v6339_v26, 15 (stack46)
        %v6736_v22 = vor.u32 %v6735_v40, %v6734_v23 (stack47)
        %v120474_v8 = vpop.eup %120473 (stack64)
        %v5205_v56 = vmul.f32 %v5201_v42, %v124241_v30 (stack54)
        %v5551_v20 = vmul.f32 %v5550_v9, %v124263_v20 (stack63)
        %vm124311_vm0 = vcmp.lt.f32.partialorder %v5552_v46, 0.0004427343 (stack62)
        %v5968_v9 = vxor.u32 %v5966_v34, %v5954_v55 (stack48)
        %v5548_v6 = vmul.f32 0.6931472, %v120474_v8 (stack65)
        %v6347_v21 = vor.u32 %v6346_v32, %v6345_v10 (stack47)
        %v6737_v55 = vxor.u32 %v6736_v22, %v6732_v60 (stack48)
        %v7573_v24 = vsel /*vm=*/%vm7560_vm15, /*on_true_vy=*/%v7569_v7, /*on_false_vx=*/%v7565_v24 (stack44)
        %v5209_v43 = vadd.f32 %v5205_v56, %v124271_v43 (stack53)
        %v7163_v25 = vshll.u32 %v7154_v52, 6 (stack45)
        %v7164_v52 = vshrl.u32 %v7154_v52, 26 (stack46)
        %v7590_v26 = vadd.s32 %v124293_v41, %v121569_v1 (stack40)
        %v5554_v23 = vsel /*vm=*/%vm124311_vm0, /*on_true_vy=*/%v5551_v20, /*on_false_vx=*/%v5548_v6 (stack66)
        %v5969_v40 = vand.u32.u8 255, %v5968_v9 (stack49)
        %v6348_v42 = vxor.u32 %v6347_v21, %v6343_v53 (stack48)
        %v6740_v60 = vadd.s32 %v6737_v55, %v6732_v60 (stack40)
        %vm124325_vm1 = vcmp.eq.f32.partialorder %v5070_v11, 1.0 (stack68)
        %v5102_v54 = vsel /*vm=*/%vm5097_vm10, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v5213_v30 = vmul.f32 %v5209_v43, %v124241_v30 (stack54)
        %v124333_v34 = vxor.u32 2147483648, %v5554_v23 (stack56)
        %v6351_v7 = vadd.s32 %v6348_v42, %v6343_v53 (stack40)
        %v6353_v53 = vshll.u32 %v6348_v42, 29 (stack45)
        %v6354_v10 = vshrl.u32 %v6348_v42, 3 (stack46)
        %vm7555_vm2 = vcmp.lt.u32.totalorder %v124293_v41, %v124131_v29 (stack43)
        %v5217_v32 = vadd.f32 %v5213_v30, %v5102_v54 (stack53)
        %v5531_v22 = vand.u32 2147483647, %v124250_v44 (stack77)
        %120475 = vrsqrt.f32 %v124333_v34 (stack67)
        %v7596_v8 = vshll.u32 %v7590_v26, 13 (stack45)
        %vm5558_vm3 = vcmp.lt.f32.partialorder %v124333_v34, 5.0 (stack68)
        %v5970_v56 = vand.u32 65535, %v5969_v40 (stack50)
        %v6355_v20 = vor.u32 %v6354_v10, %v6353_v53 (stack47)
        %v7165_v46 = vor.u32 %v7164_v52, %v7163_v25 (stack47)
        %v5221_v12 = vmul.f32 %v5217_v32, %v124082_v12 (stack54)
        %v6746_v9 = vshll.u32 %v6737_v55, 24 (stack45)
        %v6747_v6 = vshrl.u32 %v6737_v55, 8 (stack46)
        %v7577_v21 = vadd.s32 1, %v7573_v24 (stack40)
        %v6356_v55 = vxor.u32 %v6355_v20, %v6351_v7 (stack48)
        %v6744_v43 = vadd.s32 %v6740_v60, %v121564_v0 (stack40)
        %v7161_v25 = vadd.s32 %v124307_v61, %v121569_v1 (stack40)
        %v7597_v52 = vshrl.u32 %v7590_v26, 19 (stack46)
        %v5225_v50 = vsel /*vm=*/%vm124325_vm1, /*on_true_vy=*/%v124260_v50, /*on_false_vx=*/%v5221_v12 (stack44)
        %v124350_v23 = vsel /*vm=*/%vm5558_vm3, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v124355_v40 = vsel /*vm=*/%vm5558_vm3, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v124358_v42 = vadd.f32 -2.5, %v124333_v34 (stack53)
        %v5229_v11 = vmul.f32 1.4140625, %v5225_v50 (stack54)
        %v5971_v54 = vshrl.u32 %v5970_v56, 1 (stack51)
        %v6359_v30 = vadd.s32 %v6356_v55, %v6351_v7 (stack40)
        %v6361_v7 = vshll.u32 %v6356_v55, 16 (stack45)
        %v6362_v53 = vshrl.u32 %v6356_v55, 16 (stack46)
        %v6748_v10 = vor.u32 %v6747_v6, %v6746_v9 (stack47)
        %v7166_v61 = vxor.u32 %v7165_v46, %v124307_v61 (stack48)
        %v7581_v29 = vsel /*vm=*/%vm7555_vm2, /*on_true_vy=*/%v7577_v21, /*on_false_vx=*/%v7573_v24 (stack44)
        %v5232_v41 = vpack.c.bf16 %v156663_v45, %v5229_v11 (stack81)
        %v5972_v24 = vor.u32 16256, %v5971_v54 (stack47)
        %v7586_v32 = vadd.s32 %v7581_v29, %v121574_v2 (stack40)
        %v7598_v8 = vor.u32 %v7597_v52, %v7596_v8 (stack47)
        %v124369_v56 = vsel /*vm=*/%vm5558_vm3, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v6363_v20 = vor.u32 %v6362_v53, %v6361_v7 (stack47)
        %v6749_v60 = vxor.u32 %v6748_v10, %v6740_v60 (stack48)
        %v7169_v46 = vadd.s32 %v7166_v61, %v121564_v0 (stack40)
        %119771 = vst [vmem:[%s123356_s30 + $0x84] sm:$0xf] /*vst_source=*/%v5232_v41 (stack83)
        %v5973_v12 = vand.u32.u16 65535, %v5972_v24 (stack52)
        %v7594_v26 = vadd.s32 %v7590_v26, %v7586_v32 (stack40)
        %vm8055_vm4 = vcmp.lt.u32.totalorder %v124300_v27, %v122651_v47 (stack43)
        %v157106_v9 = vld [vmem:[#allocation64_spill] sm:$0xff] (stack84)
        %v8060_v6 = vadd.s32 %v157106_v9, %v157068_v28 (stack40)
        %v5595_v21 = vsel /*vm=*/%vm5558_vm3, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v6364_v55 = vxor.u32 %v6363_v20, %v6359_v30 (stack48)
        %v6752_v52 = vadd.s32 %v6749_v60, %v121574_v2 (stack40)
        %v7173_v50 = vadd.s32 1, %v7169_v46 (stack40)
        %vm5603_vm5 = vcmp.eq.f32.partialorder %v124333_v34, inf (stack70)
        %vm5605_vm6 = vcmp.eq.f32.partialorder %v124333_v34, 0.0 (stack71)
        %v119774_v11 = vadd.low.f32.bf16 -1.0, %v5973_v12 (stack53)
        %v7599_v54 = vxor.u32 %v7598_v8, %v7594_v26 (stack48)
        %v6367_v30 = vadd.s32 %v6364_v55, %v6359_v30 (stack40)
        %v6373_v7 = vshll.u32 %v6364_v55, 24 (stack45)
        %v6374_v53 = vshrl.u32 %v6364_v55, 8 (stack46)
        %v6756_v10 = vadd.s32 2, %v6752_v52 (stack40)
        %v120476_v61 = vpop.eup %120475 (stack73)
        %v5982_v29 = vmul.f32 2.0, %v119774_v11 (stack54)
        %v7177_v25 = vadd.s32 %v7173_v50, %v7161_v25 (stack40)
        %v7179_v41 = vshll.u32 %v7173_v50, 17 (stack45)
        %v7180_v24 = vshrl.u32 %v7173_v50, 15 (stack46)
        %v5602_v32 = vmul.f32 %v120476_v61, %v124333_v34 (stack74)
        %v5606_v8 = vand.u32 2147483648, %v124333_v34 (stack72)
        %v6375_v20 = vor.u32 %v6374_v53, %v6373_v7 (stack47)
        %v6760_v43 = vadd.s32 %v6756_v10, %v6744_v43 (stack40)
        %v5986_v60 = vadd.f32 -0.99609375, %v5982_v29 (stack53)
        %v6762_v46 = vshll.u32 %v6756_v10, 13 (stack45)
        %v6763_v12 = vshrl.u32 %v6756_v10, 19 (stack46)
        %v7181_v55 = vor.u32 %v7180_v24, %v7179_v41 (stack47)
        %v5604_v52 = vsel /*vm=*/%vm5603_vm5, /*on_true_vy=*/%v124333_v34, /*on_false_vx=*/%v5602_v32 (stack75)
        %v6376_v50 = vxor.u32 %v6375_v20, %v6367_v30 (stack48)
        %v7602_v26 = vadd.s32 %v7599_v54, %v7594_v26 (stack40)
        %v8064_v11 = vadd.s32 1, %v8060_v6 (stack40)
        %v5607_v7 = vsel /*vm=*/%vm5605_vm6, /*on_true_vy=*/%v5606_v8, /*on_false_vx=*/%v5604_v52 (stack76)
        %v124390_v53 = vmax.f32 %v5986_v60, -0.99609375 (stack55)
        %v6764_v10 = vor.u32 %v6763_v12, %v6762_v46 (stack47)
        %v7182_v61 = vxor.u32 %v7181_v55, %v7177_v25 (stack48)
        %v5610_v29 = vadd.f32 -3.0, %v5607_v7 (stack53)
        %v6379_v41 = vadd.s32 %v6376_v50, %v121564_v0 (stack40)
        %v8046_v24 = vadd.s32 %v124300_v27, %v122657_v58 (stack40)
        %v8068_v6 = vsel /*vm=*/%vm8055_vm4, /*on_true_vy=*/%v8064_v11, /*on_false_vx=*/%v8060_v6 (stack44)
        %v6002_v32 = vxor.u32 2147483648, %v124390_v53 (stack56)
        %v6371_v30 = vadd.s32 %v6367_v30, %v121569_v1 (stack40)
        %v6765_v8 = vxor.u32 %v6764_v10, %v6760_v43 (stack48)
        %v7604_v20 = vshll.u32 %v7599_v54, 15 (stack45)
        %v124403_v42 = vsel /*vm=*/%vm5558_vm3, /*on_true_vy=*/%v124358_v42, /*on_false_vx=*/%v5610_v29 (stack44)
        %v6383_v60 = vadd.s32 4, %v6379_v41 (stack40)
        %v7185_v25 = vadd.s32 %v7182_v61, %v7177_v25 (stack40)
        %v7605_v54 = vshrl.u32 %v7599_v54, 17 (stack46)
        %v5618_v21 = vmul.f32 %v124403_v42, %v5595_v21 (stack54)
        %v124407_v46 = vmul.f32 %v6002_v32, %v124390_v53 (stack54)
        %v6768_v43 = vadd.s32 %v6765_v8, %v6760_v43 (stack40)
        %v7187_v12 = vshll.u32 %v7182_v61, 29 (stack45)
        %v6387_v55 = vadd.s32 %v6383_v60, %v6371_v30 (stack40)
        %v6389_v52 = vshll.u32 %v6383_v60, 13 (stack45)
        %v6390_v50 = vshrl.u32 %v6383_v60, 19 (stack46)
        %v6770_v11 = vshll.u32 %v6765_v8, 15 (stack45)
        %v5583_v7 = vsel /*vm=*/%vm5558_vm3, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v5587_v10 = vsel /*vm=*/%vm5558_vm3, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v5622_v56 = vadd.f32 %v5618_v21, %v124369_v56 (stack53)
        %v6007_v29 = vadd.f32 1.0, %v124407_v46 (stack57)
        %v6391_v41 = vor.u32 %v6390_v50, %v6389_v52 (stack47)
        %v6771_v32 = vshrl.u32 %v6765_v8, 17 (stack46)
        %v7188_v61 = vshrl.u32 %v7182_v61, 3 (stack46)
        %v7606_v30 = vor.u32 %v7605_v54, %v7604_v20 (stack47)
        %v5626_v8 = vmul.f32 %v5622_v56, %v124403_v42 (stack54)
        %120477 = vlog2.f32 %v6007_v29 (stack58)
        %vm8050_vm7 = vcmp.lt.u32.totalorder %v8046_v24, %v124300_v27 (stack43)
        %v124420_v20 = vadd.s32 %v8046_v24, %v121569_v1 (stack40)
        %v6392_v60 = vxor.u32 %v6391_v41, %v6387_v55 (stack48)
        %v6772_v54 = vor.u32 %v6771_v32, %v6770_v11 (stack47)
        %v7189_v21 = vor.u32 %v7188_v61, %v7187_v12 (stack47)
        %v7607_v12 = vxor.u32 %v7606_v30, %v7602_v26 (stack48)
        %v5630_v52 = vadd.f32 %v5626_v8, %v5587_v10 (stack53)
        %v6010_v50 = vmul.f32 -0.5, %v124407_v46 (stack59)
        %v6013_v11 = vand.u32 2147483647, %v124407_v46 (stack60)
        %v8072_v10 = vadd.s32 1, %v8068_v6 (stack40)
        %v6395_v55 = vadd.s32 %v6392_v60, %v6387_v55 (stack40)
        %v6397_v56 = vshll.u32 %v6392_v60, 15 (stack45)
        %v6398_v29 = vshrl.u32 %v6392_v60, 17 (stack46)
        %v6773_v41 = vxor.u32 %v6772_v54, %v6768_v43 (stack48)
        %v5634_v32 = vmul.f32 %v5630_v52, %v124403_v42 (stack54)
        %v7190_v61 = vxor.u32 %v7189_v21, %v7185_v25 (stack48)
        %v7610_v26 = vadd.s32 %v7607_v12, %v7602_v26 (stack40)
        %v7612_v30 = vshll.u32 %v7607_v12, 26 (stack45)
        %v6399_v8 = vor.u32 %v6398_v29, %v6397_v56 (stack47)
        %v6776_v43 = vadd.s32 %v6773_v41, %v6768_v43 (stack40)
        %v6778_v60 = vshll.u32 %v6773_v41, 26 (stack45)
        %v6779_v54 = vshrl.u32 %v6773_v41, 6 (stack46)
        %v5638_v7 = vadd.f32 %v5634_v32, %v5583_v7 (stack53)
        %v7193_v25 = vadd.s32 %v7190_v61, %v7185_v25 (stack40)
        %v7195_v21 = vshll.u32 %v7190_v61, 16 (stack45)
        %v7196_v52 = vshrl.u32 %v7190_v61, 16 (stack46)
        %v6400_v56 = vxor.u32 %v6399_v8, %v6395_v55 (stack48)
        %v6780_v29 = vor.u32 %v6779_v54, %v6778_v60 (stack47)
        %v7613_v12 = vshrl.u32 %v7607_v12, 6 (stack46)
        %v8076_v27 = vsel /*vm=*/%vm8050_vm7, /*on_true_vy=*/%v8072_v10, /*on_false_vx=*/%v8068_v6 (stack44)
        %v5642_v24 = vmul.f32 %v5638_v7, %v124403_v42 (stack54)
        %v6011_v6 = vadd.f32 1.0, %v6010_v50 (stack61)
        %v7197_v50 = vor.u32 %v7196_v52, %v7195_v21 (stack47)
        %v8081_v10 = vadd.s32 %v8076_v27, %v121574_v2 (stack40)
        %v6403_v55 = vadd.s32 %v6400_v56, %v6395_v55 (stack40)
        %v6405_v41 = vshll.u32 %v6400_v56, 26 (stack45)
        %v6406_v32 = vshrl.u32 %v6400_v56, 6 (stack46)
        %v6781_v61 = vxor.u32 %v6780_v29, %v6776_v43 (stack48)
        %v5646_v40 = vadd.f32 %v5642_v24, %v124355_v40 (stack53)
        %v7198_v8 = vxor.u32 %v7197_v50, %v7193_v25 (stack48)
        %v7614_v30 = vor.u32 %v7613_v12, %v7612_v30 (stack47)
        %v124431_v60 = vadd.s32 %v124420_v20, %v8081_v10 (stack40)
        %v6407_v54 = vor.u32 %v6406_v32, %v6405_v41 (stack47)
        %v6784_v43 = vadd.s32 %v6781_v61, %v6776_v43 (stack40)
        %v6790_v7 = vshll.u32 %v6781_v61, 6 (stack45)
        %v6791_v21 = vshrl.u32 %v6781_v61, 26 (stack46)
        %v5650_v52 = vmul.f32 %v5646_v40, %v124403_v42 (stack54)
        %v7201_v25 = vadd.s32 %v7198_v8, %v7193_v25 (stack40)
        %v7207_v56 = vshll.u32 %v7198_v8, 24 (stack45)
        %v7208_v29 = vshrl.u32 %v7198_v8, 8 (stack46)
        %v120478_v12 = vpop.eup %120477 (stack64)
        %vm124434_vm8 = vcmp.lt.f32.partialorder %v6013_v11, 0.0004427343 (stack62)
        %v6408_v27 = vxor.u32 %v6407_v54, %v6403_v55 (stack48)
        %v6792_v24 = vor.u32 %v6791_v21, %v6790_v7 (stack47)
        %v7615_v50 = vxor.u32 %v7614_v30, %v7610_v26 (stack48)
        %v5654_v23 = vadd.f32 %v5650_v52, %v124350_v23 (stack53)
        %v6009_v10 = vmul.f32 0.6931472, %v120478_v12 (stack65)
        %v6012_v46 = vmul.f32 %v6011_v6, %v124407_v46 (stack63)
        %v7209_v6 = vor.u32 %v7208_v29, %v7207_v56 (stack47)
        %v6411_v55 = vadd.s32 %v6408_v27, %v6403_v55 (stack40)
        %v6417_v41 = vshll.u32 %v6408_v27, 6 (stack45)
        %v6418_v32 = vshrl.u32 %v6408_v27, 26 (stack46)
        %v6793_v61 = vxor.u32 %v6792_v24, %v6784_v43 (stack48)
        %v5658_v40 = vmul.f32 %v5654_v23, %v124403_v42 (stack54)
        %v6015_v8 = vsel /*vm=*/%vm124434_vm8, /*on_true_vy=*/%v6012_v46, /*on_false_vx=*/%v6009_v10 (stack66)
        %v7210_v30 = vxor.u32 %v7209_v6, %v7201_v25 (stack48)
        %v124443_v26 = vadd.s32 %v7615_v50, %v7610_v26 (stack40)
        %v5539_v54 = vmul.f32 inf, %v124250_v44 (stack54)
        %v5571_v7 = vsel /*vm=*/%vm5558_vm3, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v124449_v21 = vxor.u32 2147483648, %v6015_v8 (stack56)
        %v6419_v52 = vor.u32 %v6418_v32, %v6417_v41 (stack47)
        %v5563_v56 = vsel /*vm=*/%vm5558_vm3, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v5567_v34 = vsel /*vm=*/%vm5558_vm3, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v5662_v29 = vadd.f32 %v5658_v40, %v5571_v7 (stack53)
        %v5992_v12 = vand.u32 2147483647, %v124390_v53 (stack77)
        %vm6019_vm9 = vcmp.lt.f32.partialorder %v124449_v21, 5.0 (stack68)
        %120479 = vrsqrt.f32 %v124449_v21 (stack67)
        %v6796_v11 = vadd.s32 %v6793_v61, %v121569_v1 (stack40)
        %v8091_v27 = vshll.u32 %v124420_v20, 13 (stack45)
        %v5666_v24 = vmul.f32 %v5662_v29, %v124403_v42 (stack54)
        %v6788_v43 = vadd.s32 %v6784_v43, %v121574_v2 (stack40)
        %v7213_v23 = vadd.s32 %v7210_v30, %v121574_v2 (stack40)
        %v8092_v20 = vshrl.u32 %v124420_v20, 19 (stack46)
        %vm124468_vm10 = vcmp.eq.f32.partialorder %v5531_v22, 1.0 (stack68)
        %v6415_v10 = vadd.s32 %v6411_v55, %v121564_v0 (stack40)
        %v6420_v46 = vxor.u32 %v6419_v52, %v6411_v55 (stack48)
        %v7205_v25 = vadd.s32 %v7201_v25, %v121564_v0 (stack40)
        %v124476_v6 = vadd.s32 %v124443_v26, %v121569_v1 (stack40)
        %v5670_v55 = vadd.f32 %v5666_v24, %v5567_v34 (stack53)
        %v124481_v41 = vsel /*vm=*/%vm6019_vm9, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v124484_v32 = vadd.f32 -2.5, %v124449_v21 (stack53)
        %v7624_v61 = vshll.u32 %v7615_v50, 6 (stack45)
        %v124489_v40 = vsel /*vm=*/%vm6019_vm9, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v124494_v8 = vsel /*vm=*/%vm6019_vm9, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v6423_v30 = vadd.s32 %v6420_v46, %v121574_v2 (stack40)
        %v6800_v7 = vadd.s32 3, %v6796_v11 (stack40)
        %v5674_v42 = vmul.f32 %v5670_v55, %v124403_v42 (stack54)
        %v7217_v52 = vadd.s32 2, %v7213_v23 (stack40)
        %v7625_v50 = vshrl.u32 %v7615_v50, 26 (stack46)
        %v8093_v34 = vor.u32 %v8092_v20, %v8091_v27 (stack47)
        %v6427_v29 = vadd.s32 5, %v6423_v30 (stack40)
        %v6804_v11 = vadd.s32 %v6800_v7, %v6788_v43 (stack40)
        %v6806_v27 = vshll.u32 %v6800_v7, 17 (stack45)
        %v6807_v24 = vshrl.u32 %v6800_v7, 15 (stack46)
        %v5678_v56 = vadd.f32 %v5674_v42, %v5563_v56 (stack53)
        %vm6064_vm11 = vcmp.eq.f32.partialorder %v124449_v21, inf (stack70)
        %v7221_v43 = vadd.s32 %v7217_v52, %v7205_v25 (stack40)
        %v7223_v23 = vshll.u32 %v7217_v52, 13 (stack45)
        %v7224_v20 = vshrl.u32 %v7217_v52, 19 (stack46)
        %vm6066_vm12 = vcmp.eq.f32.partialorder %v124449_v21, 0.0 (stack71)
        %v6429_v10 = vxor.u32 %v6427_v29, %v6415_v10 (stack48)
        %v6808_v46 = vor.u32 %v6807_v24, %v6806_v27 (stack47)
        %v7626_v25 = vor.u32 %v7625_v50, %v7624_v61 (stack47)
        %v8094_v55 = vxor.u32 %v8093_v34, %v124431_v60 (stack48)
        %v5682_v44 = vmul.f32 %v5678_v56, %v124250_v44 (stack54)
        %v7225_v61 = vor.u32 %v7224_v20, %v7223_v23 (stack47)
        %v124504_v30 = vadd.s32 %v157101_v31, %v157070_v38 (stack40)
        %v124508_v7 = vadd.s32 %v157106_v9, %v157076_v35 (stack40)
        %v6430_v42 = vand.u32.u8 255, %v6429_v10 (stack49)
        %v6809_v52 = vxor.u32 %v6808_v46, %v6804_v11 (stack48)
        %v7627_v26 = vxor.u32 %v7626_v25, %v124443_v26 (stack48)
        %v8097_v60 = vadd.s32 %v8094_v55, %v124431_v60 (stack40)
        %v5686_v54 = vsel /*vm=*/%vm124468_vm10, /*on_true_vy=*/%v5539_v54, /*on_false_vx=*/%v5682_v44 (stack44)
        %v7226_v22 = vxor.u32 %v7225_v61, %v7221_v43 (stack48)
        %v8099_v50 = vshll.u32 %v8094_v55, 15 (stack45)
        %v8100_v34 = vshrl.u32 %v8094_v55, 17 (stack46)
        %v5690_v29 = vmul.f32 1.4140625, %v5686_v54 (stack54)
        %v6431_v27 = vand.u32 65535, %v6430_v42 (stack50)
        %v6812_v11 = vadd.s32 %v6809_v52, %v6804_v11 (stack40)
        %v6814_v24 = vshll.u32 %v6809_v52, 29 (stack45)
        %v120480_v56 = vpop.eup %120479 (stack73)
        %v6815_v23 = vshrl.u32 %v6809_v52, 3 (stack46)
        %v7229_v43 = vadd.s32 %v7226_v22, %v7221_v43 (stack40)
        %v7231_v20 = vshll.u32 %v7226_v22, 15 (stack45)
        %v7232_v10 = vshrl.u32 %v7226_v22, 17 (stack46)
        %v5693_v46 = vpack.c.bf16 %v156663_v45, %v5690_v29 (stack81)
        %v6063_v25 = vmul.f32 %v120480_v56, %v124449_v21 (stack74)
        %v6432_v55 = vshrl.u32 %v6431_v27, 1 (stack51)
        %v7630_v44 = vadd.s32 %v7627_v26, %v121564_v0 (stack40)
        %v6067_v61 = vand.u32 2147483648, %v124449_v21 (stack72)
        %v6816_v42 = vor.u32 %v6815_v23, %v6814_v24 (stack47)
        %v7233_v52 = vor.u32 %v7232_v10, %v7231_v20 (stack47)
        %v8101_v26 = vor.u32 %v8100_v34, %v8099_v50 (stack47)
        %119773 = vst [vmem:[%s123356_s30 + $0x104] sm:$0xf] /*vst_source=*/%v5693_v46 (stack83)
        %v6065_v54 = vsel /*vm=*/%vm6064_vm11, /*on_true_vy=*/%v124449_v21, /*on_false_vx=*/%v6063_v25 (stack75)
        %v6433_v22 = vor.u32 16256, %v6432_v55 (stack47)
        %v7634_v50 = vadd.s32 1, %v7630_v44 (stack40)
        %vm8516_vm13 = vcmp.lt.u32.totalorder %v124504_v30, %v157070_v38 (stack43)
        %v6068_v34 = vsel /*vm=*/%vm6066_vm12, /*on_true_vy=*/%v6067_v61, /*on_false_vx=*/%v6065_v54 (stack76)
        %v6817_v29 = vxor.u32 %v6816_v42, %v6812_v11 (stack48)
        %v7234_v27 = vxor.u32 %v7233_v52, %v7229_v43 (stack48)
        %v8102_v24 = vxor.u32 %v8101_v26, %v8097_v60 (stack48)
        %v6071_v56 = vadd.f32 -3.0, %v6068_v34 (stack53)
        %v6434_v23 = vand.u32.u16 65535, %v6433_v22 (stack52)
        %v7638_v6 = vadd.s32 %v7634_v50, %v124476_v6 (stack40)
        %v7640_v20 = vshll.u32 %v7634_v50, 17 (stack45)
        %v6820_v11 = vadd.s32 %v6817_v29, %v6812_v11 (stack40)
        %v6822_v10 = vshll.u32 %v6817_v29, 16 (stack45)
        %v6823_v46 = vshrl.u32 %v6817_v29, 16 (stack46)
        %v7237_v43 = vadd.s32 %v7234_v27, %v7229_v43 (stack40)
        %v124530_v32 = vsel /*vm=*/%vm6019_vm9, /*on_true_vy=*/%v124484_v32, /*on_false_vx=*/%v6071_v56 (stack44)
        %v119776_v25 = vadd.low.f32.bf16 -1.0, %v6434_v23 (stack53)
        %v7239_v55 = vshll.u32 %v7234_v27, 26 (stack45)
        %v7240_v44 = vshrl.u32 %v7234_v27, 6 (stack46)
        %v6079_v8 = vmul.f32 %v124530_v32, %v124494_v8 (stack54)
        %v6824_v61 = vor.u32 %v6823_v46, %v6822_v10 (stack47)
        %v7641_v42 = vshrl.u32 %v7634_v50, 15 (stack46)
        %v8105_v60 = vadd.s32 %v8102_v24, %v8097_v60 (stack40)
        %v6052_v52 = vsel /*vm=*/%vm6019_vm9, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v6443_v26 = vmul.f32 2.0, %v119776_v25 (stack54)
        %v7241_v54 = vor.u32 %v7240_v44, %v7239_v55 (stack47)
        %v8107_v22 = vshll.u32 %v8102_v24, 26 (stack45)
        %v6083_v50 = vadd.f32 %v6079_v8, %v6052_v52 (stack53)
        %v6825_v34 = vxor.u32 %v6824_v61, %v6820_v11 (stack48)
        %v7642_v29 = vor.u32 %v7641_v42, %v7640_v20 (stack47)
        %v8108_v27 = vshrl.u32 %v8102_v24, 6 (stack46)
        %v124540_v24 = vsel /*vm=*/%vm6019_vm9, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v6048_v56 = vsel /*vm=*/%vm6019_vm9, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v6447_v23 = vadd.f32 -0.99609375, %v6443_v26 (stack53)
        %v7242_v20 = vxor.u32 %v7241_v54, %v7237_v43 (stack48)
        %v6087_v10 = vmul.f32 %v6083_v50, %v124530_v32 (stack54)
        %v6828_v11 = vadd.s32 %v6825_v34, %v6820_v11 (stack40)
        %v6834_v46 = vshll.u32 %v6825_v34, 24 (stack45)
        %v6835_v25 = vshrl.u32 %v6825_v34, 8 (stack46)
        %v124546_v55 = vmax.f32 %v6447_v23, -0.99609375 (stack55)
        %v7245_v43 = vadd.s32 %v7242_v20, %v7237_v43 (stack40)
        %v7251_v44 = vshll.u32 %v7242_v20, 6 (stack45)
        %v7252_v8 = vshrl.u32 %v7242_v20, 26 (stack46)
        %v6091_v61 = vadd.f32 %v6087_v10, %v6048_v56 (stack53)
        %v6836_v42 = vor.u32 %v6835_v25, %v6834_v46 (stack47)
        %v7643_v52 = vxor.u32 %v7642_v29, %v7638_v6 (stack48)
        %v8109_v26 = vor.u32 %v8108_v27, %v8107_v22 (stack47)
        %v6036_v54 = vsel /*vm=*/%vm6019_vm9, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v6040_v22 = vsel /*vm=*/%vm6019_vm9, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v6463_v50 = vxor.u32 2147483648, %v124546_v55 (stack56)
        %v6095_v34 = vmul.f32 %v6091_v61, %v124530_v32 (stack54)
        %v6837_v29 = vxor.u32 %v6836_v42, %v6828_v11 (stack48)
        %v7253_v27 = vor.u32 %v7252_v8, %v7251_v44 (stack47)
        %v7646_v6 = vadd.s32 %v7643_v52, %v7638_v6 (stack40)
        %v6044_v21 = vsel /*vm=*/%vm6019_vm9, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v124560_v56 = vmul.f32 %v6463_v50, %v124546_v55 (stack54)
        %v7648_v23 = vshll.u32 %v7643_v52, 29 (stack45)
        %v7649_v20 = vshrl.u32 %v7643_v52, 3 (stack46)
        %v6099_v10 = vadd.f32 %v6095_v34, %v6044_v21 (stack53)
        %v6840_v46 = vadd.s32 %v6837_v29, %v121564_v0 (stack40)
        %v7254_v25 = vxor.u32 %v7253_v27, %v7245_v43 (stack48)
        %v8110_v44 = vxor.u32 %v8109_v26, %v8105_v60 (stack48)
        %v6468_v8 = vadd.f32 1.0, %v124560_v56 (stack57)
        %v6832_v11 = vadd.s32 %v6828_v11, %v121569_v1 (stack40)
        %v7650_v61 = vor.u32 %v7649_v20, %v7648_v23 (stack47)
        %v124567_v42 = vadd.s32 %v124504_v30, %v122657_v58 (stack40)
        %v6103_v52 = vmul.f32 %v6099_v10, %v124530_v32 (stack54)
        %v6844_v26 = vadd.s32 4, %v6840_v46 (stack40)
        %v7257_v50 = vadd.s32 %v7254_v25, %v121569_v1 (stack40)
        %v124571_v60 = vadd.s32 %v8110_v44, %v8105_v60 (stack40)
        %120481 = vlog2.f32 %v6468_v8 (stack58)
        %v7249_v43 = vadd.s32 %v7245_v43, %v121574_v2 (stack40)
        %v7651_v34 = vxor.u32 %v7650_v61, %v7646_v6 (stack48)
        %v8525_v29 = vadd.s32 1, %v124508_v7 (stack40)
        %v6107_v22 = vadd.f32 %v6103_v52, %v6040_v22 (stack53)
        %v6848_v27 = vadd.s32 %v6844_v26, %v6832_v11 (stack40)
        %v6850_v21 = vshll.u32 %v6844_v26, 13 (stack45)
        %v6851_v23 = vshrl.u32 %v6844_v26, 19 (stack46)
        %v6471_v20 = vmul.f32 -0.5, %v124560_v56 (stack59)
        %v7261_v10 = vadd.s32 3, %v7257_v50 (stack40)
        %v7654_v6 = vadd.s32 %v7651_v34, %v7646_v6 (stack40)
        %v7656_v46 = vshll.u32 %v7651_v34, 16 (stack45)
        %v6111_v25 = vmul.f32 %v6107_v22, %v124530_v32 (stack54)
        %v6474_v8 = vand.u32 2147483647, %v124560_v56 (stack60)
        %v6852_v11 = vor.u32 %v6851_v23, %v6850_v21 (stack47)
        %v7657_v61 = vshrl.u32 %v7651_v34, 16 (stack46)
        %v7265_v52 = vadd.s32 %v7261_v10, %v7249_v43 (stack40)
        %v7267_v26 = vshll.u32 %v7261_v10, 17 (stack45)
        %v7268_v50 = vshrl.u32 %v7261_v10, 15 (stack46)
        %v8119_v43 = vshll.u32 %v8110_v44, 6 (stack45)
        %v6115_v54 = vadd.f32 %v6111_v25, %v6036_v54 (stack53)
        %v6853_v34 = vxor.u32 %v6852_v11, %v6848_v27 (stack48)
        %v7658_v22 = vor.u32 %v7657_v61, %v7656_v46 (stack47)
        %v8120_v44 = vshrl.u32 %v8110_v44, 26 (stack46)
        %v6472_v21 = vadd.f32 1.0, %v6471_v20 (stack61)
        %v7269_v23 = vor.u32 %v7268_v50, %v7267_v26 (stack47)
        %v8529_v7 = vsel /*vm=*/%vm8516_vm13, /*on_true_vy=*/%v8525_v29, /*on_false_vx=*/%v124508_v7 (stack44)
        %v124584_v29 = vadd.s32 %v157101_v31, %v157077_v51 (stack40)
        %v6119_v20 = vmul.f32 %v6115_v54, %v124530_v32 (stack54)
        %v6856_v27 = vadd.s32 %v6853_v34, %v6848_v27 (stack40)
        %v6858_v10 = vshll.u32 %v6853_v34, 15 (stack45)
        %v6859_v46 = vshrl.u32 %v6853_v34, 17 (stack46)
        %v7270_v25 = vxor.u32 %v7269_v23, %v7265_v52 (stack48)
        %v7659_v11 = vxor.u32 %v7658_v22, %v7654_v6 (stack48)
        %v8121_v61 = vor.u32 %v8120_v44, %v8119_v43 (stack47)
        %v8533_v26 = vadd.s32 1, %v8529_v7 (stack40)
        %v6123_v24 = vadd.f32 %v6119_v20, %v124540_v24 (stack53)
        %vm124588_vm14 = vcmp.lt.f32.partialorder %v6474_v8, 0.0004427343 (stack62)
        %v6860_v50 = vor.u32 %v6859_v46, %v6858_v10 (stack47)
        %vm8511_vm15 = vcmp.lt.u32.totalorder %v124567_v42, %v124504_v30 (stack43)
        %v7273_v30 = vadd.s32 %v7270_v25, %v7265_v52 (stack40)
        %v7275_v52 = vshll.u32 %v7270_v25, 29 (stack45)
        %v7276_v43 = vshrl.u32 %v7270_v25, 3 (stack46)
        %v7662_v6 = vadd.s32 %v7659_v11, %v7654_v6 (stack40)
        %v6127_v54 = vmul.f32 %v6123_v24, %v124530_v32 (stack54)
        %v6861_v34 = vxor.u32 %v6860_v50, %v6856_v27 (stack48)
        %v7668_v22 = vshll.u32 %v7659_v11, 24 (stack45)
        %v7669_v44 = vshrl.u32 %v7659_v11, 8 (stack46)
        %v6473_v56 = vmul.f32 %v6472_v21, %v124560_v56 (stack63)
        %v7277_v21 = vor.u32 %v7276_v43, %v7275_v52 (stack47)
        %v8122_v23 = vxor.u32 %v8121_v61, %v124571_v60 (stack48)
        %v8537_v7 = vsel /*vm=*/%vm8511_vm15, /*on_true_vy=*/%v8533_v26, /*on_false_vx=*/%v8529_v7 (stack44)
        %v120482_v20 = vpop.eup %120481 (stack64)
        %v6131_v40 = vadd.f32 %v6127_v54, %v124489_v40 (stack53)
        %v6864_v27 = vadd.s32 %v6861_v34, %v6856_v27 (stack40)
        %v6866_v10 = vshll.u32 %v6861_v34, 26 (stack45)
        %v6867_v46 = vshrl.u32 %v6861_v34, 6 (stack46)
        %v6470_v25 = vmul.f32 0.6931472, %v120482_v20 (stack65)
        %v7278_v11 = vxor.u32 %v7277_v21, %v7273_v30 (stack48)
        %v7670_v61 = vor.u32 %v7669_v44, %v7668_v22 (stack47)
        %v8546_v42 = vadd.s32 %v124567_v42, %v121569_v1 (stack40)
        %v6135_v32 = vmul.f32 %v6131_v40, %v124530_v32 (stack54)
        %v6868_v26 = vor.u32 %v6867_v46, %v6866_v10 (stack47)
        %v8125_v24 = vadd.s32 %v8122_v23, %v121564_v0 (stack40)
        %v8542_v50 = vadd.s32 %v8537_v7, %v121574_v2 (stack40)
        %v6476_v8 = vsel /*vm=*/%vm124588_vm14, /*on_true_vy=*/%v6473_v56, /*on_false_vx=*/%v6470_v25 (stack66)
        %v7281_v30 = vadd.s32 %v7278_v11, %v7273_v30 (stack40)
        %v7283_v52 = vshll.u32 %v7278_v11, 16 (stack45)
        %v7284_v43 = vshrl.u32 %v7278_v11, 16 (stack46)
        %v6139_v41 = vadd.f32 %v6135_v32, %v124481_v41 (stack53)
        %v124606_v54 = vxor.u32 2147483648, %v6476_v8 (stack56)
        %v6869_v34 = vxor.u32 %v6868_v26, %v6864_v27 (stack48)
        %v7671_v22 = vxor.u32 %v7670_v61, %v7662_v6 (stack48)
        %v6000_v44 = vmul.f32 inf, %v124390_v53 (stack54)
        %v8550_v56 = vadd.s32 %v8546_v42, %v8542_v50 (stack40)
        %v8552_v21 = vshll.u32 %v8546_v42, 13 (stack45)
        %v8553_v23 = vshrl.u32 %v8546_v42, 19 (stack46)
        %vm5995_vm0 = vcmp.eq.f32.partialorder %v5992_v12, 1.0 (stack68)
        %v6143_v53 = vmul.f32 %v6139_v41, %v124390_v53 (stack54)
        %vm6480_vm1 = vcmp.lt.f32.partialorder %v124606_v54, 5.0 (stack68)
        %120483 = vrsqrt.f32 %v124606_v54 (stack67)
        %v6453_v12 = vand.u32 2147483647, %v124546_v55 (stack77)
        %v124616_v7 = vmul.f32 inf, %v124546_v55 (stack54)
        %v6872_v20 = vadd.s32 %v6869_v34, %v6864_v27 (stack40)
        %v7285_v40 = vor.u32 %v7284_v43, %v7283_v52 (stack47)
        %v6147_v27 = vsel /*vm=*/%vm5995_vm0, /*on_true_vy=*/%v6000_v44, /*on_false_vx=*/%v6143_v53 (stack44)
        %v7666_v6 = vadd.s32 %v7662_v6, %v121564_v0 (stack40)
        %v8117_v60 = vadd.s32 %v124571_v60, %v121569_v1 (stack40)
        %v8129_v10 = vadd.s32 1, %v8125_v24 (stack40)
        %v6151_v46 = vmul.f32 1.4140625, %v6147_v27 (stack54)
        %v124624_v25 = vsel /*vm=*/%vm6480_vm1, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v124627_v11 = vadd.f32 -2.5, %v124606_v54 (stack53)
        %v8554_v61 = vor.u32 %v8553_v23, %v8552_v21 (stack47)
        %v124632_v42 = vsel /*vm=*/%vm6480_vm1, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v124637_v32 = vsel /*vm=*/%vm6480_vm1, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v124642_v26 = vsel /*vm=*/%vm6480_vm1, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v124646_v24 = vadd.s32 %v124584_v29, %v122657_v58 (stack40)
        %v6154_v50 = vpack.c.bf16 %v156663_v45, %v6151_v46 (stack81)
        %v6878_v8 = vshll.u32 %v6869_v34, 6 (stack45)
        %v6879_v52 = vshrl.u32 %v6869_v34, 26 (stack46)
        %v7286_v43 = vxor.u32 %v7285_v40, %v7281_v30 (stack48)
        %v7674_v41 = vadd.s32 %v7671_v22, %v121574_v2 (stack40)
        %v8133_v34 = vadd.s32 %v8129_v10, %v8117_v60 (stack40)
        %v8135_v22 = vshll.u32 %v8129_v10, 17 (stack45)
        %v8136_v44 = vshrl.u32 %v8129_v10, 15 (stack46)
        %119775 = vst [vmem:[%s123356_s30 + $0x184] sm:$0xf] /*vst_source=*/%v6154_v50 (stack83)
        %vm6525_vm2 = vcmp.eq.f32.partialorder %v124606_v54, inf (stack70)
        %v6880_v21 = vor.u32 %v6879_v52, %v6878_v8 (stack47)
        %v7289_v30 = vadd.s32 %v7286_v43, %v7281_v30 (stack40)
        %v7295_v23 = vshll.u32 %v7286_v43, 24 (stack45)
        %v7296_v53 = vshrl.u32 %v7286_v43, 8 (stack46)
        %vm6527_vm3 = vcmp.eq.f32.partialorder %v124606_v54, 0.0 (stack71)
        %v6528_v40 = vand.u32 2147483648, %v124606_v54 (stack72)
        %v7678_v27 = vadd.s32 2, %v7674_v41 (stack40)
        %v8137_v60 = vor.u32 %v8136_v44, %v8135_v22 (stack47)
        %v8555_v10 = vxor.u32 %v8554_v61, %v8550_v56 (stack48)
        %v6876_v46 = vadd.s32 %v6872_v20, %v121564_v0 (stack40)
        %v6881_v20 = vxor.u32 %v6880_v21, %v6872_v20 (stack48)
        %v7297_v61 = vor.u32 %v7296_v53, %v7295_v23 (stack47)
        %vm8977_vm4 = vcmp.lt.u32.totalorder %v124584_v29, %v157077_v51 (stack43)
        %v7682_v6 = vadd.s32 %v7678_v27, %v7666_v6 (stack40)
        %v7684_v50 = vshll.u32 %v7678_v27, 13 (stack45)
        %v7685_v8 = vshrl.u32 %v7678_v27, 19 (stack46)
        %v8138_v52 = vxor.u32 %v8137_v60, %v8133_v34 (stack48)
        %v6884_v43 = vadd.s32 %v6881_v20, %v121574_v2 (stack40)
        %v7298_v41 = vxor.u32 %v7297_v61, %v7289_v30 (stack48)
        %v8558_v56 = vadd.s32 %v8555_v10, %v8550_v56 (stack40)
        %v8560_v22 = vshll.u32 %v8555_v10, 15 (stack45)
        %v7686_v44 = vor.u32 %v7685_v8, %v7684_v50 (stack47)
        %v8141_v34 = vadd.s32 %v8138_v52, %v8133_v34 (stack40)
        %v8143_v21 = vshll.u32 %v8138_v52, 29 (stack45)
        %v8144_v23 = vshrl.u32 %v8138_v52, 3 (stack46)
        %v120484_v53 = vpop.eup %120483 (stack73)
        %v6888_v27 = vadd.s32 5, %v6884_v43 (stack40)
        %v7301_v60 = vadd.s32 %v7298_v41, %v121564_v0 (stack40)
        %v8561_v10 = vshrl.u32 %v8555_v10, 17 (stack46)
        %v8982_v20 = vadd.s32 %v157106_v9, %v157078_v48 (stack40)
        %v6524_v61 = vmul.f32 %v120484_v53, %v124606_v54 (stack74)
        %v7293_v30 = vadd.s32 %v7289_v30, %v121569_v1 (stack40)
        %v7687_v50 = vxor.u32 %v7686_v44, %v7682_v6 (stack48)
        %v8145_v8 = vor.u32 %v8144_v23, %v8143_v21 (stack47)
        %v6890_v46 = vxor.u32 %v6888_v27, %v6876_v46 (stack48)
        %v7305_v52 = vadd.s32 4, %v7301_v60 (stack40)
        %v8562_v43 = vor.u32 %v8561_v10, %v8560_v22 (stack47)
        %v8986_v41 = vadd.s32 1, %v8982_v20 (stack40)
        %v6526_v22 = vsel /*vm=*/%vm6525_vm2, /*on_true_vy=*/%v124606_v54, /*on_false_vx=*/%v6524_v61 (stack75)
        %v7690_v6 = vadd.s32 %v7687_v50, %v7682_v6 (stack40)
        %v7692_v44 = vshll.u32 %v7687_v50, 15 (stack45)
        %v7693_v21 = vshrl.u32 %v7687_v50, 17 (stack46)
        %v6529_v40 = vsel /*vm=*/%vm6527_vm3, /*on_true_vy=*/%v6528_v40, /*on_false_vx=*/%v6526_v22 (stack76)
        %v6891_v23 = vand.u32.u8 255, %v6890_v46 (stack49)
        %v7309_v53 = vadd.s32 %v7305_v52, %v7293_v30 (stack40)
        %v7311_v27 = vshll.u32 %v7305_v52, 13 (stack45)
        %v6532_v60 = vadd.f32 -3.0, %v6529_v40 (stack53)
        %v7312_v10 = vshrl.u32 %v7305_v52, 19 (stack46)
        %v7694_v61 = vor.u32 %v7693_v21, %v7692_v44 (stack47)
        %v8146_v30 = vxor.u32 %v8145_v8, %v8141_v34 (stack48)
        %v6517_v50 = vsel /*vm=*/%vm6480_vm1, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v6892_v8 = vand.u32 65535, %v6891_v23 (stack50)
        %v8563_v46 = vxor.u32 %v8562_v43, %v8558_v56 (stack48)
        %v8990_v20 = vsel /*vm=*/%vm8977_vm4, /*on_true_vy=*/%v8986_v41, /*on_false_vx=*/%v8982_v20 (stack44)
        %v124677_v11 = vsel /*vm=*/%vm6480_vm1, /*on_true_vy=*/%v124627_v11, /*on_false_vx=*/%v6532_v60 (stack44)
        %v7313_v52 = vor.u32 %v7312_v10, %v7311_v27 (stack47)
        %v7695_v43 = vxor.u32 %v7694_v61, %v7690_v6 (stack48)
        %v8149_v34 = vadd.s32 %v8146_v30, %v8141_v34 (stack40)
        %v6540_v41 = vmul.f32 %v124677_v11, %v6517_v50 (stack54)
        %v6893_v22 = vshrl.u32 %v6892_v8, 1 (stack51)
        %v8151_v44 = vshll.u32 %v8146_v30, 16 (stack45)
        %v8152_v21 = vshrl.u32 %v8146_v30, 16 (stack46)
        %v7314_v40 = vxor.u32 %v7313_v52, %v7309_v53 (stack48)
        %v7698_v6 = vadd.s32 %v7695_v43, %v7690_v6 (stack40)
        %v7700_v23 = vshll.u32 %v7695_v43, 26 (stack45)
        %v7701_v27 = vshrl.u32 %v7695_v43, 6 (stack46)
        %v6544_v26 = vadd.f32 %v6540_v41, %v124642_v26 (stack53)
        %v6894_v60 = vor.u32 16256, %v6893_v22 (stack47)
        %v8153_v10 = vor.u32 %v8152_v21, %v8151_v44 (stack47)
        %v8566_v56 = vadd.s32 %v8563_v46, %v8558_v56 (stack40)
        %v7317_v53 = vadd.s32 %v7314_v40, %v7309_v53 (stack40)
        %v7319_v61 = vshll.u32 %v7314_v40, 15 (stack45)
        %v7320_v30 = vshrl.u32 %v7314_v40, 17 (stack46)
        %v7702_v50 = vor.u32 %v7701_v27, %v7700_v23 (stack47)
        %v6548_v8 = vmul.f32 %v6544_v26, %v124677_v11 (stack54)
        %v6895_v52 = vand.u32.u16 65535, %v6894_v60 (stack52)
        %v8154_v43 = vxor.u32 %v8153_v10, %v8149_v34 (stack48)
        %v8568_v41 = vshll.u32 %v8563_v46, 26 (stack45)
        %v7321_v22 = vor.u32 %v7320_v30, %v7319_v61 (stack47)
        %v7703_v44 = vxor.u32 %v7702_v50, %v7698_v6 (stack48)
        %v8569_v46 = vshrl.u32 %v8563_v46, 6 (stack46)
        %v8994_v21 = vadd.s32 1, %v8990_v20 (stack40)
        %v6552_v32 = vadd.f32 %v6548_v8, %v124637_v32 (stack53)
        %v119778_v40 = vadd.low.f32.bf16 -1.0, %v6895_v52 (stack53)
        %v8157_v34 = vadd.s32 %v8154_v43, %v8149_v34 (stack40)
        %v8163_v23 = vshll.u32 %v8154_v43, 24 (stack45)
        %v7322_v27 = vxor.u32 %v7321_v22, %v7317_v53 (stack48)
        %v7706_v6 = vadd.s32 %v7703_v44, %v7698_v6 (stack40)
        %v7712_v26 = vshll.u32 %v7703_v44, 6 (stack45)
        %v7713_v60 = vshrl.u32 %v7703_v44, 26 (stack46)
        %v6556_v10 = vmul.f32 %v6552_v32, %v124677_v11 (stack54)
        %v6904_v61 = vmul.f32 2.0, %v119778_v40 (stack54)
        %v8164_v30 = vshrl.u32 %v8154_v43, 8 (stack46)
        %vm8972_vm5 = vcmp.lt.u32.totalorder %v124646_v24, %v124584_v29 (stack43)
        %v7325_v29 = vadd.s32 %v7322_v27, %v7317_v53 (stack40)
        %v7327_v53 = vshll.u32 %v7322_v27, 26 (stack45)
        %v7328_v50 = vshrl.u32 %v7322_v27, 6 (stack46)
        %v9007_v24 = vadd.s32 %v124646_v24, %v121569_v1 (stack40)
        %v6560_v42 = vadd.f32 %v6556_v10, %v124632_v42 (stack53)
        %v6908_v8 = vadd.f32 -0.99609375, %v6904_v61 (stack53)
        %v7714_v52 = vor.u32 %v7713_v60, %v7712_v26 (stack47)
        %v8165_v43 = vor.u32 %v8164_v30, %v8163_v23 (stack47)
        %v6489_v22 = vsel /*vm=*/%vm6480_vm1, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v7329_v44 = vor.u32 %v7328_v50, %v7327_v53 (stack47)
        %v8570_v41 = vor.u32 %v8569_v46, %v8568_v41 (stack47)
        %v8998_v20 = vsel /*vm=*/%vm8972_vm5, /*on_true_vy=*/%v8994_v21, /*on_false_vx=*/%v8990_v20 (stack44)
        %v6564_v46 = vmul.f32 %v6560_v42, %v124677_v11 (stack54)
        %v124693_v21 = vmax.f32 %v6908_v8, -0.99609375 (stack55)
        %v7715_v32 = vxor.u32 %v7714_v52, %v7706_v6 (stack48)
        %v8166_v40 = vxor.u32 %v8165_v43, %v8157_v34 (stack48)
        %v6493_v23 = vsel /*vm=*/%vm6480_vm1, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v6501_v27 = vsel /*vm=*/%vm6480_vm1, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v7330_v26 = vxor.u32 %v7329_v44, %v7325_v29 (stack48)
        %v8571_v60 = vxor.u32 %v8570_v41, %v8566_v56 (stack48)
        %v6497_v54 = vsel /*vm=*/%vm6480_vm1, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v6568_v10 = vadd.f32 %v6564_v46, %v6501_v27 (stack53)
        %v6924_v61 = vxor.u32 2147483648, %v124693_v21 (stack56)
        %v9013_v30 = vshll.u32 %v9007_v24, 13 (stack45)
        %v7333_v29 = vadd.s32 %v7330_v26, %v7325_v29 (stack40)
        %v7339_v53 = vshll.u32 %v7330_v26, 6 (stack45)
        %v7340_v50 = vshrl.u32 %v7330_v26, 26 (stack46)
        %v7718_v42 = vadd.s32 %v7715_v32, %v121569_v1 (stack40)
        %v6572_v8 = vmul.f32 %v6568_v10, %v124677_v11 (stack54)
        %v124708_v52 = vmul.f32 %v6924_v61, %v124693_v21 (stack54)
        %v7710_v6 = vadd.s32 %v7706_v6, %v121574_v2 (stack40)
        %v9014_v43 = vshrl.u32 %v9007_v24, 19 (stack46)
        %v7341_v44 = vor.u32 %v7340_v50, %v7339_v53 (stack47)
        %v7722_v41 = vadd.s32 3, %v7718_v42 (stack40)
        %v8169_v46 = vadd.s32 %v8166_v40, %v121574_v2 (stack40)
        %v8574_v56 = vadd.s32 %v8571_v60, %v8566_v56 (stack40)
        %v6576_v32 = vadd.f32 %v6572_v8, %v6497_v54 (stack53)
        %v6929_v40 = vadd.f32 1.0, %v124708_v52 (stack57)
        %v8161_v34 = vadd.s32 %v8157_v34, %v121564_v0 (stack40)
        %v9003_v20 = vadd.s32 %v8998_v20, %v121574_v2 (stack40)
        %v7342_v27 = vxor.u32 %v7341_v44, %v7333_v29 (stack48)
        %v7726_v26 = vadd.s32 %v7722_v41, %v7710_v6 (stack40)
        %v7728_v54 = vshll.u32 %v7722_v41, 17 (stack45)
        %v7729_v10 = vshrl.u32 %v7722_v41, 15 (stack46)
        %v6580_v61 = vmul.f32 %v6576_v32, %v124677_v11 (stack54)
        %120485 = vlog2.f32 %v6929_v40 (stack58)
        %v7337_v29 = vadd.s32 %v7333_v29, %v121564_v0 (stack40)
        %v9015_v30 = vor.u32 %v9014_v43, %v9013_v30 (stack47)
        %v6932_v53 = vmul.f32 -0.5, %v124708_v52 (stack59)
        %v7345_v50 = vadd.s32 %v7342_v27, %v121574_v2 (stack40)
        %v7730_v42 = vor.u32 %v7729_v10, %v7728_v54 (stack47)
        %v8173_v8 = vadd.s32 2, %v8169_v46 (stack40)
        %v6584_v23 = vadd.f32 %v6580_v61, %v6493_v23 (stack53)
        %v6935_v6 = vand.u32 2147483647, %v124708_v52 (stack60)
        %v8580_v43 = vshll.u32 %v8571_v60, 6 (stack45)
        %v8581_v60 = vshrl.u32 %v8571_v60, 26 (stack46)
        %v7349_v44 = vadd.s32 5, %v7345_v50 (stack40)
        %v7731_v41 = vxor.u32 %v7730_v42, %v7726_v26 (stack48)
        %v8177_v46 = vadd.s32 %v8173_v8, %v8161_v34 (stack40)
        %v8179_v32 = vshll.u32 %v8173_v8, 13 (stack45)
        %v6588_v40 = vmul.f32 %v6584_v23, %v124677_v11 (stack54)
        %v8180_v34 = vshrl.u32 %v8173_v8, 19 (stack46)
        %v8582_v27 = vor.u32 %v8581_v60, %v8580_v43 (stack47)
        %v9011_v24 = vadd.s32 %v9007_v24, %v9003_v20 (stack40)
        %vm124723_vm6 = vcmp.eq.f32.partialorder %v6453_v12, 1.0 (stack68)
        %v7351_v20 = vxor.u32 %v7349_v44, %v7337_v29 (stack48)
        %v7734_v26 = vadd.s32 %v7731_v41, %v7726_v26 (stack40)
        %v7736_v54 = vshll.u32 %v7731_v41, 29 (stack45)
        %v7737_v10 = vshrl.u32 %v7731_v41, 3 (stack46)
        %v6592_v22 = vadd.f32 %v6588_v40, %v6489_v22 (stack53)
        %v8181_v61 = vor.u32 %v8180_v34, %v8179_v32 (stack47)
        %v8583_v29 = vxor.u32 %v8582_v27, %v8574_v56 (stack48)
        %v9016_v30 = vxor.u32 %v9015_v30, %v9011_v24 (stack48)
        %v7352_v50 = vand.u32.u8 255, %v7351_v20 (stack49)
        %v7738_v42 = vor.u32 %v7737_v10, %v7736_v54 (stack47)
        %v124729_v8 = vadd.s32 %v157101_v31, %v157079_v39 (stack40)
        %v124733_v23 = vadd.s32 %v157106_v9, %v157082_v49 (stack40)
        %v6596_v11 = vmul.f32 %v6592_v22, %v124677_v11 (stack54)
        %v8182_v43 = vxor.u32 %v8181_v61, %v8177_v46 (stack48)
        %v8586_v60 = vadd.s32 %v8583_v29, %v121564_v0 (stack40)
        %v124737_v44 = vadd.s32 %v9016_v30, %v9011_v24 (stack40)
        %v6933_v53 = vadd.f32 1.0, %v6932_v53 (stack61)
        %vm124739_vm7 = vcmp.lt.f32.partialorder %v6935_v6, 0.0004427343 (stack62)
        %v7353_v41 = vand.u32 65535, %v7352_v50 (stack50)
        %v7739_v32 = vxor.u32 %v7738_v42, %v7734_v26 (stack48)
        %v6600_v25 = vadd.f32 %v6596_v11, %v124624_v25 (stack53)
        %v8185_v46 = vadd.s32 %v8182_v43, %v8177_v46 (stack40)
        %v8187_v40 = vshll.u32 %v8182_v43, 15 (stack45)
        %v8188_v34 = vshrl.u32 %v8182_v43, 17 (stack46)
        %v7354_v27 = vshrl.u32 %v7353_v41, 1 (stack51)
        %v7742_v24 = vadd.s32 %v7739_v32, %v7734_v26 (stack40)
        %v7744_v20 = vshll.u32 %v7739_v32, 16 (stack45)
        %v7745_v26 = vshrl.u32 %v7739_v32, 16 (stack46)
        %v6604_v55 = vmul.f32 %v6600_v25, %v124546_v55 (stack54)
        %v8189_v54 = vor.u32 %v8188_v34, %v8187_v40 (stack47)
        %v8578_v56 = vadd.s32 %v8574_v56, %v121569_v1 (stack40)
        %v8590_v10 = vadd.s32 1, %v8586_v60 (stack40)
        %v120486_v22 = vpop.eup %120485 (stack64)
        %v6934_v52 = vmul.f32 %v6933_v53, %v124708_v52 (stack63)
        %v7355_v61 = vor.u32 16256, %v7354_v27 (stack47)
        %v7746_v29 = vor.u32 %v7745_v26, %v7744_v20 (stack47)
        %vm9438_vm8 = vcmp.lt.u32.totalorder %v124729_v8, %v157079_v39 (stack43)
        %v6608_v7 = vsel /*vm=*/%vm124723_vm6, /*on_true_vy=*/%v124616_v7, /*on_false_vx=*/%v6604_v55 (stack44)
        %v6931_v12 = vmul.f32 0.6931472, %v120486_v22 (stack65)
        %v8190_v50 = vxor.u32 %v8189_v54, %v8185_v46 (stack48)
        %v8594_v42 = vadd.s32 %v8590_v10, %v8578_v56 (stack40)
        %v6612_v11 = vmul.f32 1.4140625, %v6608_v7 (stack54)
        %v7356_v43 = vand.u32.u16 65535, %v7355_v61 (stack52)
        %v7747_v60 = vxor.u32 %v7746_v29, %v7742_v24 (stack48)
        %v9021_v53 = vshll.u32 %v9016_v30, 15 (stack45)
        %v6937_v6 = vsel /*vm=*/%vm124739_vm7, /*on_true_vy=*/%v6934_v52, /*on_false_vx=*/%v6931_v12 (stack66)
        %v8193_v41 = vadd.s32 %v8190_v50, %v8185_v46 (stack40)
        %v8195_v32 = vshll.u32 %v8190_v50, 26 (stack45)
        %v8196_v25 = vshrl.u32 %v8190_v50, 6 (stack46)
        %v6615_v46 = vpack.c.bf16 %v156663_v45, %v6612_v11 (stack81)
        %v124755_v40 = vxor.u32 2147483648, %v6937_v6 (stack56)
        %v7750_v34 = vadd.s32 %v7747_v60, %v7742_v24 (stack40)
        %v9022_v30 = vshrl.u32 %v9016_v30, 17 (stack46)
        %v7756_v27 = vshll.u32 %v7747_v60, 24 (stack45)
        %v7757_v24 = vshrl.u32 %v7747_v60, 8 (stack46)
        %v8197_v20 = vor.u32 %v8196_v25, %v8195_v32 (stack47)
        %119777 = vst [vmem:[%s123356_s30 + $0x204] sm:$0xf] /*vst_source=*/%v6615_v46 (stack83)
        %120487 = vrsqrt.f32 %v124755_v40 (stack67)
        %v119780_v26 = vadd.low.f32.bf16 -1.0, %v7356_v43 (stack53)
        %v8596_v55 = vshll.u32 %v8590_v10, 17 (stack45)
        %v8597_v54 = vshrl.u32 %v8590_v10, 15 (stack46)
        %v6914_v56 = vand.u32 2147483647, %v124693_v21 (stack77)
        %v7758_v10 = vor.u32 %v7757_v24, %v7756_v27 (stack47)
        %v9023_v22 = vor.u32 %v9022_v30, %v9021_v53 (stack47)
        %v124761_v52 = vmul.f32 inf, %v124693_v21 (stack54)
        %vm6941_vm9 = vcmp.lt.f32.partialorder %v124755_v40, 5.0 (stack68)
        %v8198_v61 = vxor.u32 %v8197_v20, %v8193_v41 (stack48)
        %v124766_v29 = vadd.s32 %v124729_v8, %v122657_v58 (stack40)
        %v124769_v7 = vadd.f32 -2.5, %v124755_v40 (stack53)
        %v7365_v12 = vmul.f32 2.0, %v119780_v26 (stack54)
        %v7754_v50 = vadd.s32 %v7750_v34, %v121569_v1 (stack40)
        %v7759_v11 = vxor.u32 %v7758_v10, %v7750_v34 (stack48)
        %v8201_v43 = vadd.s32 %v8198_v61, %v8193_v41 (stack40)
        %v8207_v60 = vshll.u32 %v8198_v61, 6 (stack45)
        %v8208_v53 = vshrl.u32 %v8198_v61, 26 (stack46)
        %v8598_v6 = vor.u32 %v8597_v54, %v8596_v55 (stack47)
        %v124775_v41 = vsel /*vm=*/%vm6941_vm9, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v7369_v32 = vadd.f32 -0.99609375, %v7365_v12 (stack53)
        %v7762_v25 = vadd.s32 %v7759_v11, %v121564_v0 (stack40)
        %v9024_v46 = vxor.u32 %v9023_v22, %v124737_v44 (stack48)
        %v124782_v34 = vsel /*vm=*/%vm6941_vm9, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v124787_v30 = vsel /*vm=*/%vm6941_vm9, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %vm6986_vm10 = vcmp.eq.f32.partialorder %v124755_v40, inf (stack70)
        %v8209_v27 = vor.u32 %v8208_v53, %v8207_v60 (stack47)
        %v8599_v24 = vxor.u32 %v8598_v6, %v8594_v42 (stack48)
        %v6978_v20 = vsel /*vm=*/%vm6941_vm9, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v124793_v26 = vmax.f32 %v7369_v32, -0.99609375 (stack55)
        %v7766_v55 = vadd.s32 4, %v7762_v25 (stack40)
        %v124796_v44 = vadd.s32 %v9024_v46, %v124737_v44 (stack40)
        %v8210_v54 = vxor.u32 %v8209_v27, %v8201_v43 (stack48)
        %v8602_v42 = vadd.s32 %v8599_v24, %v8594_v42 (stack40)
        %v8604_v10 = vshll.u32 %v8599_v24, 29 (stack45)
        %v8605_v22 = vshrl.u32 %v8599_v24, 3 (stack46)
        %vm6988_vm11 = vcmp.eq.f32.partialorder %v124755_v40, 0.0 (stack71)
        %v7385_v61 = vxor.u32 2147483648, %v124793_v26 (stack56)
        %v7770_v12 = vadd.s32 %v7766_v55, %v7754_v50 (stack40)
        %v9447_v50 = vadd.s32 1, %v124733_v23 (stack40)
        %v7772_v11 = vshll.u32 %v7766_v55, 13 (stack45)
        %v7773_v60 = vshrl.u32 %v7766_v55, 19 (stack46)
        %v8213_v53 = vadd.s32 %v8210_v54, %v121569_v1 (stack40)
        %v8606_v6 = vor.u32 %v8605_v22, %v8604_v10 (stack47)
        %v6989_v32 = vand.u32 2147483648, %v124755_v40 (stack72)
        %v124804_v25 = vmul.f32 %v7385_v61, %v124793_v26 (stack54)
        %v8205_v43 = vadd.s32 %v8201_v43, %v121574_v2 (stack40)
        %v9451_v23 = vsel /*vm=*/%vm9438_vm8, /*on_true_vy=*/%v9447_v50, /*on_false_vx=*/%v124733_v23 (stack44)
        %v120488_v27 = vpop.eup %120487 (stack73)
        %v7774_v24 = vor.u32 %v7773_v60, %v7772_v11 (stack47)
        %v8217_v55 = vadd.s32 3, %v8213_v53 (stack40)
        %v8607_v54 = vxor.u32 %v8606_v6, %v8602_v42 (stack48)
        %v9029_v10 = vshll.u32 %v9024_v46, 26 (stack45)
        %v6985_v22 = vmul.f32 %v120488_v27, %v124755_v40 (stack74)
        %v7390_v61 = vadd.f32 1.0, %v124804_v25 (stack57)
        %v7393_v50 = vmul.f32 -0.5, %v124804_v25 (stack59)
        %v9030_v46 = vshrl.u32 %v9024_v46, 6 (stack46)
        %v7775_v11 = vxor.u32 %v7774_v24, %v7770_v12 (stack48)
        %v8221_v60 = vadd.s32 %v8217_v55, %v8205_v43 (stack40)
        %v8223_v53 = vshll.u32 %v8217_v55, 17 (stack45)
        %v8224_v6 = vshrl.u32 %v8217_v55, 15 (stack46)
        %v6987_v43 = vsel /*vm=*/%vm6986_vm10, /*on_true_vy=*/%v124755_v40, /*on_false_vx=*/%v6985_v22 (stack75)
        %120489 = vlog2.f32 %v7390_v61 (stack58)
        %vm9433_vm12 = vcmp.lt.u32.totalorder %v124766_v29, %v124729_v8 (stack43)
        %v9455_v27 = vadd.s32 1, %v9451_v23 (stack40)
        %v6990_v32 = vsel /*vm=*/%vm6988_vm11, /*on_true_vy=*/%v6989_v32, /*on_false_vx=*/%v6987_v43 (stack76)
        %v7778_v12 = vadd.s32 %v7775_v11, %v7770_v12 (stack40)
        %v7780_v24 = vshll.u32 %v7775_v11, 15 (stack45)
        %v7781_v55 = vshrl.u32 %v7775_v11, 17 (stack46)
        %v6993_v22 = vadd.f32 -3.0, %v6990_v32 (stack53)
        %v7394_v61 = vadd.f32 1.0, %v7393_v50 (stack61)
        %v8225_v50 = vor.u32 %v8224_v6, %v8223_v53 (stack47)
        %v8610_v42 = vadd.s32 %v8607_v54, %v8602_v42 (stack40)
        %v7782_v11 = vor.u32 %v7781_v55, %v7780_v24 (stack47)
        %v8612_v53 = vshll.u32 %v8607_v54, 16 (stack45)
        %v8613_v54 = vshrl.u32 %v8607_v54, 16 (stack46)
        %v9031_v10 = vor.u32 %v9030_v46, %v9029_v10 (stack47)
        %v124824_v7 = vsel /*vm=*/%vm6941_vm9, /*on_true_vy=*/%v124769_v7, /*on_false_vx=*/%v6993_v22 (stack44)
        %v8226_v46 = vxor.u32 %v8225_v50, %v8221_v60 (stack48)
        %v9459_v8 = vsel /*vm=*/%vm9433_vm12, /*on_true_vy=*/%v9455_v27, /*on_false_vx=*/%v9451_v23 (stack44)
        %v124831_v29 = vadd.s32 %v124766_v29, %v121569_v1 (stack40)
        %v7001_v20 = vmul.f32 %v124824_v7, %v6978_v20 (stack54)
        %v7783_v23 = vxor.u32 %v7782_v11, %v7778_v12 (stack48)
        %v8614_v6 = vor.u32 %v8613_v54, %v8612_v53 (stack47)
        %v9032_v43 = vxor.u32 %v9031_v10, %v124796_v44 (stack48)
        %v8229_v60 = vadd.s32 %v8226_v46, %v8221_v60 (stack40)
        %v8231_v27 = vshll.u32 %v8226_v46, 29 (stack45)
        %v8232_v32 = vshrl.u32 %v8226_v46, 3 (stack46)
        %v9464_v24 = vadd.s32 %v9459_v8, %v121574_v2 (stack40)
        %v7005_v30 = vadd.f32 %v7001_v20, %v124787_v30 (stack53)
        %v7786_v12 = vadd.s32 %v7783_v23, %v7778_v12 (stack40)
        %v7788_v55 = vshll.u32 %v7783_v23, 26 (stack45)
        %v7789_v22 = vshrl.u32 %v7783_v23, 6 (stack46)
        %v8233_v50 = vor.u32 %v8232_v32, %v8231_v27 (stack47)
        %v8615_v11 = vxor.u32 %v8614_v6, %v8610_v42 (stack48)
        %v9035_v44 = vadd.s32 %v9032_v43, %v124796_v44 (stack40)
        %v9041_v53 = vshll.u32 %v9032_v43, 6 (stack45)
        %v7009_v54 = vmul.f32 %v7005_v30, %v124824_v7 (stack54)
        %v7790_v10 = vor.u32 %v7789_v22, %v7788_v55 (stack47)
        %v9042_v46 = vshrl.u32 %v9032_v43, 26 (stack46)
        %v124840_v8 = vadd.s32 %v124831_v29, %v9464_v24 (stack40)
        %v8234_v20 = vxor.u32 %v8233_v50, %v8229_v60 (stack48)
        %v8618_v42 = vadd.s32 %v8615_v11, %v8610_v42 (stack40)
        %v8624_v23 = vshll.u32 %v8615_v11, 24 (stack45)
        %v8625_v6 = vshrl.u32 %v8615_v11, 8 (stack46)
        %v7013_v34 = vadd.f32 %v7009_v54, %v124782_v34 (stack53)
        %v7396_v43 = vand.u32 2147483647, %v124804_v25 (stack60)
        %v7791_v27 = vxor.u32 %v7790_v10, %v7786_v12 (stack48)
        %v9043_v32 = vor.u32 %v9042_v46, %v9041_v53 (stack47)
        %v7395_v25 = vmul.f32 %v7394_v61, %v124804_v25 (stack63)
        %v8237_v61 = vadd.s32 %v8234_v20, %v8229_v60 (stack40)
        %v8239_v60 = vshll.u32 %v8234_v20, 16 (stack45)
        %v8240_v24 = vshrl.u32 %v8234_v20, 16 (stack46)
        %v120490_v30 = vpop.eup %120489 (stack64)
        %v7017_v55 = vmul.f32 %v7013_v34, %v124824_v7 (stack54)
        %v7794_v12 = vadd.s32 %v7791_v27, %v7786_v12 (stack40)
        %v7800_v22 = vshll.u32 %v7791_v27, 6 (stack45)
        %v7801_v50 = vshrl.u32 %v7791_v27, 26 (stack46)
        %v7392_v11 = vmul.f32 0.6931472, %v120490_v30 (stack65)
        %v8241_v53 = vor.u32 %v8240_v24, %v8239_v60 (stack47)
        %v8626_v54 = vor.u32 %v8625_v6, %v8624_v23 (stack47)
        %v9044_v10 = vxor.u32 %v9043_v32, %v9035_v44 (stack48)
        %v124849_v46 = vsel /*vm=*/%vm6941_vm9, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v7021_v41 = vadd.f32 %v7017_v55, %v124775_v41 (stack53)
        %vm7397_vm13 = vcmp.lt.f32.partialorder %v7396_v43, 0.0004427343 (stack62)
        %v7802_v20 = vor.u32 %v7801_v50, %v7800_v22 (stack47)
        %v6950_v23 = vsel /*vm=*/%vm6941_vm9, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v7398_v6 = vsel /*vm=*/%vm7397_vm13, /*on_true_vy=*/%v7395_v25, /*on_false_vx=*/%v7392_v11 (stack66)
        %v8242_v34 = vxor.u32 %v8241_v53, %v8237_v61 (stack48)
        %v8627_v43 = vxor.u32 %v8626_v54, %v8618_v42 (stack48)
        %v6954_v27 = vsel /*vm=*/%vm6941_vm9, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v7025_v32 = vmul.f32 %v7021_v41, %v124824_v7 (stack54)
        %v124859_v25 = vxor.u32 2147483648, %v7398_v6 (stack56)
        %v7803_v60 = vxor.u32 %v7802_v20, %v7794_v12 (stack48)
        %v6958_v24 = vsel /*vm=*/%vm6941_vm9, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v6962_v40 = vsel /*vm=*/%vm6941_vm9, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v8245_v61 = vadd.s32 %v8242_v34, %v8237_v61 (stack40)
        %v9039_v44 = vadd.s32 %v9035_v44, %v121569_v1 (stack40)
        %v7029_v30 = vadd.f32 %v7025_v32, %v6962_v40 (stack53)
        %vm7402_vm14 = vcmp.lt.f32.partialorder %v124859_v25, 5.0 (stack68)
        %120491 = vrsqrt.f32 %v124859_v25 (stack67)
        %v9047_v55 = vadd.s32 %v9044_v10, %v121564_v0 (stack40)
        %v7806_v22 = vadd.s32 %v7803_v60, %v121574_v2 (stack40)
        %v8251_v50 = vshll.u32 %v8242_v34, 24 (stack45)
        %v8252_v11 = vshrl.u32 %v8242_v34, 8 (stack46)
        %v8630_v53 = vadd.s32 %v8627_v43, %v121574_v2 (stack40)
        %v7033_v54 = vmul.f32 %v7029_v30, %v124824_v7 (stack54)
        %v8622_v42 = vadd.s32 %v8618_v42, %v121564_v0 (stack40)
        %v9474_v10 = vshll.u32 %v124831_v29, 13 (stack45)
        %v9475_v29 = vshrl.u32 %v124831_v29, 19 (stack46)
        %v124880_v41 = vsel /*vm=*/%vm7402_vm14, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v124885_v20 = vsel /*vm=*/%vm7402_vm14, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v124888_v6 = vadd.f32 -2.5, %v124859_v25 (stack53)
        %v7798_v12 = vadd.s32 %v7794_v12, %v121564_v0 (stack40)
        %v7037_v34 = vadd.f32 %v7033_v54, %v6958_v24 (stack53)
        %v124894_v43 = vsel /*vm=*/%vm7402_vm14, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v124899_v32 = vsel /*vm=*/%vm7402_vm14, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v8249_v60 = vadd.s32 %v8245_v61, %v121569_v1 (stack40)
        %v7810_v24 = vadd.s32 5, %v7806_v22 (stack40)
        %v8253_v40 = vor.u32 %v8252_v11, %v8251_v50 (stack47)
        %v8634_v30 = vadd.s32 2, %v8630_v53 (stack40)
        %v9051_v55 = vadd.s32 1, %v9047_v55 (stack40)
        %v7041_v22 = vmul.f32 %v7037_v34, %v124824_v7 (stack54)
        %v9476_v50 = vor.u32 %v9475_v29, %v9474_v10 (stack47)
        %v124905_v11 = vadd.s32 %v157101_v31, %v157083_v59 (stack40)
        %v124909_v53 = vadd.s32 %v157106_v9, %v157084_v16 (stack40)
        %vm7447_vm15 = vcmp.eq.f32.partialorder %v124859_v25, inf (stack70)
        %v7812_v54 = vxor.u32 %v7810_v24, %v7798_v12 (stack48)
        %v8254_v61 = vxor.u32 %v8253_v40, %v8245_v61 (stack48)
        %v8638_v42 = vadd.s32 %v8634_v30, %v8622_v42 (stack40)
        %v8640_v10 = vshll.u32 %v8634_v30, 13 (stack45)
        %v7045_v27 = vadd.f32 %v7041_v22, %v6954_v27 (stack53)
        %v8641_v29 = vshrl.u32 %v8634_v30, 19 (stack46)
        %v9055_v44 = vadd.s32 %v9051_v55, %v9039_v44 (stack40)
        %v9057_v12 = vshll.u32 %v9051_v55, 17 (stack45)
        %v7813_v34 = vand.u32.u8 255, %v7812_v54 (stack49)
        %v8257_v24 = vadd.s32 %v8254_v61, %v121564_v0 (stack40)
        %v9058_v40 = vshrl.u32 %v9051_v55, 15 (stack46)
        %v9477_v30 = vxor.u32 %v9476_v50, %v124840_v8 (stack48)
        %v7049_v55 = vmul.f32 %v7045_v27, %v124824_v7 (stack54)
        %v7450_v22 = vand.u32 2147483648, %v124859_v25 (stack72)
        %v8642_v50 = vor.u32 %v8641_v29, %v8640_v10 (stack47)
        %vm9899_vm0 = vcmp.lt.u32.totalorder %v124905_v11, %v157083_v59 (stack43)
        %vm124920_vm1 = vcmp.eq.f32.partialorder %v6914_v56, 1.0 (stack68)
        %v7814_v54 = vand.u32 65535, %v7813_v34 (stack50)
        %v8261_v61 = vadd.s32 4, %v8257_v24 (stack40)
        %v9059_v10 = vor.u32 %v9058_v40, %v9057_v12 (stack47)
        %v124925_v8 = vadd.s32 %v9477_v30, %v124840_v8 (stack40)
        %v7053_v23 = vadd.f32 %v7049_v55, %v6950_v23 (stack53)
        %v8643_v27 = vxor.u32 %v8642_v50, %v8638_v42 (stack48)
        %v9482_v29 = vshll.u32 %v9477_v30, 15 (stack45)
        %v9483_v12 = vshrl.u32 %v9477_v30, 17 (stack46)
        %v120492_v34 = vpop.eup %120491 (stack73)
        %v7815_v24 = vshrl.u32 %v7814_v54, 1 (stack51)
        %v8265_v60 = vadd.s32 %v8261_v61, %v8249_v60 (stack40)
        %v8267_v40 = vshll.u32 %v8261_v61, 13 (stack45)
        %v8268_v30 = vshrl.u32 %v8261_v61, 19 (stack46)
        %v7057_v7 = vmul.f32 %v7053_v23, %v124824_v7 (stack54)
        %v7446_v55 = vmul.f32 %v120492_v34, %v124859_v25 (stack74)
        %v8646_v42 = vadd.s32 %v8643_v27, %v8638_v42 (stack40)
        %v8648_v50 = vshll.u32 %v8643_v27, 15 (stack45)
        %v7816_v54 = vor.u32 16256, %v7815_v24 (stack47)
        %v8269_v61 = vor.u32 %v8268_v30, %v8267_v40 (stack47)
        %v8649_v23 = vshrl.u32 %v8643_v27, 17 (stack46)
        %v9060_v10 = vxor.u32 %v9059_v10, %v9055_v44 (stack48)
        %v7061_v46 = vadd.f32 %v7057_v7, %v124849_v46 (stack53)
        %v7448_v27 = vsel /*vm=*/%vm7447_vm15, /*on_true_vy=*/%v124859_v25, /*on_false_vx=*/%v7446_v55 (stack75)
        %vm7449_vm2 = vcmp.eq.f32.partialorder %v124859_v25, 0.0 (stack71)
        %v9484_v29 = vor.u32 %v9483_v12, %v9482_v29 (stack47)
        %v7451_v22 = vsel /*vm=*/%vm7449_vm2, /*on_true_vy=*/%v7450_v22, /*on_false_vx=*/%v7448_v27 (stack76)
        %v7817_v12 = vand.u32.u16 65535, %v7816_v54 (stack52)
        %v8270_v34 = vxor.u32 %v8269_v61, %v8265_v60 (stack48)
        %v8650_v24 = vor.u32 %v8649_v23, %v8648_v50 (stack47)
        %v7065_v21 = vmul.f32 %v7061_v46, %v124693_v21 (stack54)
        %v7454_v40 = vadd.f32 -3.0, %v7451_v22 (stack53)
        %v9063_v44 = vadd.s32 %v9060_v10, %v9055_v44 (stack40)
        %v9065_v30 = vshll.u32 %v9060_v10, 29 (stack45)
        %v119782_v7 = vadd.low.f32.bf16 -1.0, %v7817_v12 (stack53)
        %v8273_v60 = vadd.s32 %v8270_v34, %v8265_v60 (stack40)
        %v8275_v55 = vshll.u32 %v8270_v34, 15 (stack45)
        %v8276_v50 = vshrl.u32 %v8270_v34, 17 (stack46)
        %v7069_v52 = vsel /*vm=*/%vm124920_vm1, /*on_true_vy=*/%v124761_v52, /*on_false_vx=*/%v7065_v21 (stack44)
        %v124941_v6 = vsel /*vm=*/%vm7402_vm14, /*on_true_vy=*/%v124888_v6, /*on_false_vx=*/%v7454_v40 (stack44)
        %v8651_v56 = vxor.u32 %v8650_v24, %v8646_v42 (stack48)
        %v9066_v54 = vshrl.u32 %v9060_v10, 3 (stack46)
        %v7073_v61 = vmul.f32 1.4140625, %v7069_v52 (stack54)
        %v7462_v32 = vmul.f32 %v124941_v6, %v124899_v32 (stack54)
        %v7826_v23 = vmul.f32 2.0, %v119782_v7 (stack54)
        %v8277_v10 = vor.u32 %v8276_v50, %v8275_v55 (stack47)
        %v8654_v42 = vadd.s32 %v8651_v56, %v8646_v42 (stack40)
        %v8656_v46 = vshll.u32 %v8651_v56, 26 (stack45)
        %v8657_v27 = vshrl.u32 %v8651_v56, 6 (stack46)
        %v9067_v22 = vor.u32 %v9066_v54, %v9065_v30 (stack47)
        %v7076_v12 = vpack.c.bf16 %v156663_v45, %v7073_v61 (stack81)
        %v7466_v43 = vadd.f32 %v7462_v32, %v124894_v43 (stack53)
        %v7830_v34 = vadd.f32 -0.99609375, %v7826_v23 (stack53)
        %v8278_v24 = vxor.u32 %v8277_v10, %v8273_v60 (stack48)
        %v7419_v21 = vsel /*vm=*/%vm7402_vm14, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v8658_v40 = vor.u32 %v8657_v27, %v8656_v46 (stack47)
        %v9068_v30 = vxor.u32 %v9067_v22, %v9063_v44 (stack48)
        %v9485_v29 = vxor.u32 %v9484_v29, %v124925_v8 (stack48)
        %119779 = vst [vmem:[%s123356_s30 + $0x284] sm:$0xf] /*vst_source=*/%v7076_v12 (stack83)
        %v7470_v7 = vmul.f32 %v7466_v43, %v124941_v6 (stack54)
        %v124953_v55 = vmax.f32 %v7830_v34, -0.99609375 (stack55)
        %v8281_v60 = vadd.s32 %v8278_v24, %v8273_v60 (stack40)
        %v8283_v50 = vshll.u32 %v8278_v24, 26 (stack45)
        %v7431_v52 = vsel /*vm=*/%vm7402_vm14, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v8284_v56 = vshrl.u32 %v8278_v24, 6 (stack46)
        %v8659_v54 = vxor.u32 %v8658_v40, %v8654_v42 (stack48)
        %v9071_v44 = vadd.s32 %v9068_v30, %v9063_v44 (stack40)
        %v7423_v61 = vsel /*vm=*/%vm7402_vm14, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v7474_v32 = vadd.f32 %v7470_v7, %v7431_v52 (stack53)
        %v7846_v23 = vxor.u32 2147483648, %v124953_v55 (stack56)
        %v9890_v10 = vadd.s32 %v124905_v11, %v122657_v58 (stack40)
        %v8285_v46 = vor.u32 %v8284_v56, %v8283_v50 (stack47)
        %v8662_v42 = vadd.s32 %v8659_v54, %v8654_v42 (stack40)
        %v8668_v27 = vshll.u32 %v8659_v54, 6 (stack45)
        %v8669_v22 = vshrl.u32 %v8659_v54, 26 (stack46)
        %v7427_v12 = vsel /*vm=*/%vm7402_vm14, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v7478_v43 = vmul.f32 %v7474_v32, %v124941_v6 (stack54)
        %v124969_v34 = vmul.f32 %v7846_v23, %v124953_v55 (stack54)
        %v9073_v24 = vshll.u32 %v9068_v30, 16 (stack45)
        %v8286_v40 = vxor.u32 %v8285_v46, %v8281_v60 (stack48)
        %v8670_v7 = vor.u32 %v8669_v22, %v8668_v27 (stack47)
        %v9074_v30 = vshrl.u32 %v9068_v30, 16 (stack46)
        %v9488_v8 = vadd.s32 %v9485_v29, %v124925_v8 (stack40)
        %v7482_v50 = vadd.f32 %v7478_v43, %v7427_v12 (stack53)
        %v7851_v52 = vadd.f32 1.0, %v124969_v34 (stack57)
        %v7854_v56 = vmul.f32 -0.5, %v124969_v34 (stack59)
        %vm9894_vm3 = vcmp.lt.u32.totalorder %v9890_v10, %v124905_v11 (stack43)
        %v8289_v60 = vadd.s32 %v8286_v40, %v8281_v60 (stack40)
        %v8295_v54 = vshll.u32 %v8286_v40, 6 (stack45)
        %v8296_v32 = vshrl.u32 %v8286_v40, 26 (stack46)
        %v8671_v23 = vxor.u32 %v8670_v7, %v8662_v42 (stack48)
        %v7486_v46 = vmul.f32 %v7482_v50, %v124941_v6 (stack54)
        %120493 = vlog2.f32 %v7851_v52 (stack58)
        %v8666_v42 = vadd.s32 %v8662_v42, %v121574_v2 (stack40)
        %v9908_v27 = vadd.s32 1, %v124909_v53 (stack40)
        %v7857_v22 = vand.u32 2147483647, %v124969_v34 (stack60)
        %v8297_v12 = vor.u32 %v8296_v32, %v8295_v54 (stack47)
        %v8674_v43 = vadd.s32 %v8671_v23, %v121569_v1 (stack40)
        %v9075_v24 = vor.u32 %v9074_v30, %v9073_v24 (stack47)
        %v7490_v61 = vadd.f32 %v7486_v46, %v7423_v61 (stack53)
        %v7855_v40 = vadd.f32 1.0, %v7854_v56 (stack61)
        %v9490_v7 = vshll.u32 %v9485_v29, 26 (stack45)
        %v9491_v29 = vshrl.u32 %v9485_v29, 6 (stack46)
        %v8298_v30 = vxor.u32 %v8297_v12, %v8289_v60 (stack48)
        %v8678_v50 = vadd.s32 3, %v8674_v43 (stack40)
        %v9076_v52 = vxor.u32 %v9075_v24, %v9071_v44 (stack48)
        %v9912_v53 = vsel /*vm=*/%vm9899_vm0, /*on_true_vy=*/%v9908_v27, /*on_false_vx=*/%v124909_v53 (stack44)
        %v7494_v56 = vmul.f32 %v7490_v61, %v124941_v6 (stack54)
        %v8293_v60 = vadd.s32 %v8289_v60, %v121564_v0 (stack40)
        %v9492_v54 = vor.u32 %v9491_v29, %v9490_v7 (stack47)
        %v9916_v32 = vadd.s32 1, %v9912_v53 (stack40)
        %v8301_v23 = vadd.s32 %v8298_v30, %v121574_v2 (stack40)
        %v8682_v46 = vadd.s32 %v8678_v50, %v8666_v42 (stack40)
        %v8684_v42 = vshll.u32 %v8678_v50, 17 (stack45)
        %v8685_v27 = vshrl.u32 %v8678_v50, 15 (stack46)
        %v7498_v21 = vadd.f32 %v7494_v56, %v7419_v21 (stack53)
        %v9079_v44 = vadd.s32 %v9076_v52, %v9071_v44 (stack40)
        %v9085_v12 = vshll.u32 %v9076_v52, 24 (stack45)
        %v9086_v43 = vshrl.u32 %v9076_v52, 8 (stack46)
        %vm124987_vm4 = vcmp.lt.f32.partialorder %v7857_v22, 0.0004427343 (stack62)
        %v8305_v24 = vadd.s32 5, %v8301_v23 (stack40)
        %v8686_v61 = vor.u32 %v8685_v27, %v8684_v42 (stack47)
        %v9493_v7 = vxor.u32 %v9492_v54, %v9488_v8 (stack48)
        %v9920_v11 = vsel /*vm=*/%vm9894_vm3, /*on_true_vy=*/%v9916_v32, /*on_false_vx=*/%v9912_v53 (stack44)
        %v7502_v29 = vmul.f32 %v7498_v21, %v124941_v6 (stack54)
        %v9087_v30 = vor.u32 %v9086_v43, %v9085_v12 (stack47)
        %v9925_v50 = vadd.s32 %v9920_v11, %v121574_v2 (stack40)
        %v9929_v10 = vadd.s32 %v9890_v10, %v121569_v1 (stack40)
        %v8307_v52 = vxor.u32 %v8305_v24, %v8293_v60 (stack48)
        %v8687_v53 = vxor.u32 %v8686_v61, %v8682_v46 (stack48)
        %v9496_v8 = vadd.s32 %v9493_v7, %v9488_v8 (stack40)
        %v9502_v56 = vshll.u32 %v9493_v7, 6 (stack45)
        %v7506_v20 = vadd.f32 %v7502_v29, %v124885_v20 (stack53)
        %v9088_v60 = vxor.u32 %v9087_v30, %v9079_v44 (stack48)
        %v9503_v54 = vshrl.u32 %v9493_v7, 26 (stack46)
        %v124997_v32 = vadd.s32 %v9929_v10, %v9925_v50 (stack40)
        %v8308_v23 = vand.u32.u8 255, %v8307_v52 (stack49)
        %v8690_v46 = vadd.s32 %v8687_v53, %v8682_v46 (stack40)
        %v8692_v42 = vshll.u32 %v8687_v53, 29 (stack45)
        %v8693_v27 = vshrl.u32 %v8687_v53, 3 (stack46)
        %v7510_v21 = vmul.f32 %v7506_v20, %v124941_v6 (stack54)
        %v7856_v34 = vmul.f32 %v7855_v40, %v124969_v34 (stack63)
        %v9091_v40 = vadd.s32 %v9088_v60, %v121574_v2 (stack40)
        %v9504_v12 = vor.u32 %v9503_v54, %v9502_v56 (stack47)
        %v120494_v43 = vpop.eup %120493 (stack64)
        %v8309_v24 = vand.u32 65535, %v8308_v23 (stack50)
        %v8694_v61 = vor.u32 %v8693_v27, %v8692_v42 (stack47)
        %v9083_v44 = vadd.s32 %v9079_v44, %v121564_v0 (stack40)
        %v9935_v7 = vshll.u32 %v9929_v10, 13 (stack45)
        %v7514_v41 = vadd.f32 %v7510_v21, %v124880_v41 (stack53)
        %v7853_v11 = vmul.f32 0.6931472, %v120494_v43 (stack65)
        %v9095_v29 = vadd.s32 2, %v9091_v40 (stack40)
        %v9505_v30 = vxor.u32 %v9504_v12, %v9496_v8 (stack48)
        %v8310_v50 = vshrl.u32 %v8309_v24, 1 (stack51)
        %v8695_v52 = vxor.u32 %v8694_v61, %v8690_v46 (stack48)
        %v9936_v10 = vshrl.u32 %v9929_v10, 19 (stack46)
        %v125006_v53 = vadd.s32 %v157101_v31, %v157089_v17 (stack40)
        %v7375_v56 = vand.u32 2147483647, %v124793_v26 (stack77)
        %v7518_v6 = vmul.f32 %v7514_v41, %v124941_v6 (stack54)
        %v7859_v22 = vsel /*vm=*/%vm124987_vm4, /*on_true_vy=*/%v7856_v34, /*on_false_vx=*/%v7853_v11 (stack66)
        %v9099_v20 = vadd.s32 %v9095_v29, %v9083_v44 (stack40)
        %v7407_v25 = vsel /*vm=*/%vm7402_vm14, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v125015_v60 = vxor.u32 2147483648, %v7859_v22 (stack56)
        %v8698_v54 = vadd.s32 %v8695_v52, %v8690_v46 (stack40)
        %v8700_v23 = vshll.u32 %v8695_v52, 16 (stack45)
        %v7383_v46 = vmul.f32 inf, %v124793_v26 (stack54)
        %v7522_v42 = vadd.f32 %v7518_v6, %v7407_v25 (stack53)
        %v8701_v27 = vshrl.u32 %v8695_v52, 16 (stack46)
        %120495 = vrsqrt.f32 %v125015_v60 (stack67)
        %v8311_v21 = vor.u32 16256, %v8310_v50 (stack47)
        %v9101_v34 = vshll.u32 %v9095_v29, 13 (stack45)
        %v9937_v40 = vor.u32 %v9936_v10, %v9935_v7 (stack47)
        %v7526_v26 = vmul.f32 %v7522_v42, %v124793_v26 (stack54)
        %vm7863_vm5 = vcmp.lt.f32.partialorder %v125015_v60, 5.0 (stack68)
        %v9102_v12 = vshrl.u32 %v9095_v29, 19 (stack46)
        %v9508_v43 = vadd.s32 %v9505_v30, %v121564_v0 (stack40)
        %vm7378_vm6 = vcmp.eq.f32.partialorder %v7375_v56, 1.0 (stack68)
        %v8702_v24 = vor.u32 %v8701_v27, %v8700_v23 (stack47)
        %v7530_v61 = vsel /*vm=*/%vm7378_vm6, /*on_true_vy=*/%v7383_v46, /*on_false_vx=*/%v7526_v26 (stack44)
        %v7836_v44 = vand.u32 2147483647, %v124953_v55 (stack77)
        %v9500_v8 = vadd.s32 %v9496_v8, %v121569_v1 (stack40)
        %v7534_v7 = vmul.f32 1.4140625, %v7530_v61 (stack54)
        %v125027_v41 = vsel /*vm=*/%vm7863_vm5, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v125030_v11 = vadd.f32 -2.5, %v125015_v60 (stack53)
        %v8312_v29 = vand.u32.u16 65535, %v8311_v21 (stack52)
        %v8703_v30 = vxor.u32 %v8702_v24, %v8698_v54 (stack48)
        %v9103_v50 = vor.u32 %v9102_v12, %v9101_v34 (stack47)
        %v9512_v52 = vadd.s32 1, %v9508_v43 (stack40)
        %v9938_v10 = vxor.u32 %v9937_v40, %v124997_v32 (stack48)
        %v7537_v56 = vpack.c.bf16 %v156663_v45, %v7534_v7 (stack81)
        %v125037_v6 = vsel /*vm=*/%vm7863_vm5, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v119788_v22 = vadd.low.f32.bf16 -1.0, %v8312_v29 (stack53)
        %vm10360_vm7 = vcmp.lt.u32.totalorder %v125006_v53, %v157089_v17 (stack43)
        %vm7908_vm8 = vcmp.eq.f32.partialorder %v125015_v60, inf (stack70)
        %v8706_v25 = vadd.s32 %v8703_v30, %v8698_v54 (stack40)
        %v8712_v54 = vshll.u32 %v8703_v30, 24 (stack45)
        %v8713_v23 = vshrl.u32 %v8703_v30, 8 (stack46)
        %v9104_v46 = vxor.u32 %v9103_v50, %v9099_v20 (stack48)
        %119781 = vst [vmem:[%s123356_s30 + $0x304] sm:$0xf] /*vst_source=*/%v7537_v56 (stack83)
        %v8321_v42 = vmul.f32 2.0, %v119788_v22 (stack54)
        %v9516_v27 = vadd.s32 %v9512_v52, %v9500_v8 (stack40)
        %v9518_v21 = vshll.u32 %v9512_v52, 17 (stack45)
        %v9519_v34 = vshrl.u32 %v9512_v52, 15 (stack46)
        %v125046_v40 = vsel /*vm=*/%vm7863_vm5, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v8714_v26 = vor.u32 %v8713_v23, %v8712_v54 (stack47)
        %v9107_v20 = vadd.s32 %v9104_v46, %v9099_v20 (stack40)
        %v9109_v12 = vshll.u32 %v9104_v46, 15 (stack45)
        %v8325_v43 = vadd.f32 -0.99609375, %v8321_v42 (stack53)
        %v9110_v24 = vshrl.u32 %v9104_v46, 17 (stack46)
        %v9520_v61 = vor.u32 %v9519_v34, %v9518_v21 (stack47)
        %v9941_v32 = vadd.s32 %v9938_v10, %v124997_v32 (stack40)
        %v125052_v8 = vsel /*vm=*/%vm7863_vm5, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v125057_v7 = vsel /*vm=*/%vm7863_vm5, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %vm7910_vm9 = vcmp.eq.f32.partialorder %v125015_v60, 0.0 (stack71)
        %v8715_v29 = vxor.u32 %v8714_v26, %v8706_v25 (stack48)
        %v125060_v30 = vmax.f32 %v8325_v43, -0.99609375 (stack55)
        %v9111_v50 = vor.u32 %v9110_v24, %v9109_v12 (stack47)
        %v9521_v52 = vxor.u32 %v9520_v61, %v9516_v27 (stack48)
        %v10365_v56 = vadd.s32 %v157106_v9, %v157090_v62 (stack40)
        %v120496_v22 = vpop.eup %120495 (stack73)
        %v7911_v54 = vand.u32 2147483648, %v125015_v60 (stack72)
        %v8718_v23 = vadd.s32 %v8715_v29, %v121564_v0 (stack40)
        %v125068_v46 = vadd.s32 %v125006_v53, %v122657_v58 (stack40)
        %v125072_v42 = vadd.s32 %v157101_v31, %v157091_v37 (stack40)
        %v7907_v21 = vmul.f32 %v120496_v22, %v125015_v60 (stack74)
        %v8341_v34 = vxor.u32 2147483648, %v125060_v30 (stack56)
        %v9943_v26 = vshll.u32 %v9938_v10, 15 (stack45)
        %v9944_v10 = vshrl.u32 %v9938_v10, 17 (stack46)
        %v8710_v25 = vadd.s32 %v8706_v25, %v121569_v1 (stack40)
        %v8722_v12 = vadd.s32 4, %v8718_v23 (stack40)
        %v9112_v43 = vxor.u32 %v9111_v50, %v9107_v20 (stack48)
        %v9524_v27 = vadd.s32 %v9521_v52, %v9516_v27 (stack40)
        %v7909_v24 = vsel /*vm=*/%vm7908_vm8, /*on_true_vy=*/%v125015_v60, /*on_false_vx=*/%v7907_v21 (stack75)
        %v125081_v61 = vmul.f32 %v8341_v34, %v125060_v30 (stack54)
        %v9526_v29 = vshll.u32 %v9521_v52, 29 (stack45)
        %v9527_v50 = vshrl.u32 %v9521_v52, 3 (stack46)
        %v7912_v52 = vsel /*vm=*/%vm7910_vm9, /*on_true_vy=*/%v7911_v54, /*on_false_vx=*/%v7909_v24 (stack76)
        %v8726_v22 = vadd.s32 %v8722_v12, %v8710_v25 (stack40)
        %v8728_v54 = vshll.u32 %v8722_v12, 13 (stack45)
        %v8729_v23 = vshrl.u32 %v8722_v12, 19 (stack46)
        %v7896_v21 = vsel /*vm=*/%vm7863_vm5, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v7915_v34 = vadd.f32 -3.0, %v7912_v52 (stack53)
        %v8346_v25 = vadd.f32 1.0, %v125081_v61 (stack57)
        %v9945_v26 = vor.u32 %v9944_v10, %v9943_v26 (stack47)
        %v8730_v10 = vor.u32 %v8729_v23, %v8728_v54 (stack47)
        %v9115_v20 = vadd.s32 %v9112_v43, %v9107_v20 (stack40)
        %v9117_v12 = vshll.u32 %v9112_v43, 26 (stack45)
        %v9118_v43 = vshrl.u32 %v9112_v43, 6 (stack46)
        %v7900_v24 = vsel /*vm=*/%vm7863_vm5, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v125095_v11 = vsel /*vm=*/%vm7863_vm5, /*on_true_vy=*/%v125030_v11, /*on_false_vx=*/%v7915_v34 (stack44)
        %120497 = vlog2.f32 %v8346_v25 (stack58)
        %vm10355_vm10 = vcmp.lt.u32.totalorder %v125068_v46, %v125006_v53 (stack43)
        %v7923_v52 = vmul.f32 %v125095_v11, %v7900_v24 (stack54)
        %v8731_v54 = vxor.u32 %v8730_v10, %v8726_v22 (stack48)
        %v9119_v23 = vor.u32 %v9118_v43, %v9117_v12 (stack47)
        %v9528_v29 = vor.u32 %v9527_v50, %v9526_v29 (stack47)
        %v8349_v50 = vmul.f32 -0.5, %v125081_v61 (stack59)
        %v8352_v34 = vand.u32 2147483647, %v125081_v61 (stack60)
        %v9946_v25 = vxor.u32 %v9945_v26, %v9941_v32 (stack48)
        %v10369_v26 = vadd.s32 1, %v10365_v56 (stack40)
        %v7927_v21 = vadd.f32 %v7923_v52, %v7896_v21 (stack53)
        %v8734_v22 = vadd.s32 %v8731_v54, %v8726_v22 (stack40)
        %v8736_v10 = vshll.u32 %v8731_v54, 15 (stack45)
        %v8737_v12 = vshrl.u32 %v8731_v54, 17 (stack46)
        %v9120_v43 = vxor.u32 %v9119_v23, %v9115_v20 (stack48)
        %v9529_v24 = vxor.u32 %v9528_v29, %v9524_v27 (stack48)
        %v9949_v32 = vadd.s32 %v9946_v25, %v9941_v32 (stack40)
        %v9951_v52 = vshll.u32 %v9946_v25, 26 (stack45)
        %v7931_v54 = vmul.f32 %v7927_v21, %v125095_v11 (stack54)
        %v8738_v23 = vor.u32 %v8737_v12, %v8736_v10 (stack47)
        %v9952_v29 = vshrl.u32 %v9946_v25, 6 (stack46)
        %v10373_v56 = vsel /*vm=*/%vm10360_vm7, /*on_true_vy=*/%v10369_v26, /*on_false_vx=*/%v10365_v56 (stack44)
        %v9123_v20 = vadd.s32 %v9120_v43, %v9115_v20 (stack40)
        %v9129_v25 = vshll.u32 %v9120_v43, 6 (stack45)
        %v9130_v26 = vshrl.u32 %v9120_v43, 26 (stack46)
        %v9532_v27 = vadd.s32 %v9529_v24, %v9524_v27 (stack40)
        %v7935_v7 = vadd.f32 %v7931_v54, %v125057_v7 (stack53)
        %v8739_v21 = vxor.u32 %v8738_v23, %v8734_v22 (stack48)
        %v9534_v10 = vshll.u32 %v9529_v24, 16 (stack45)
        %v9535_v12 = vshrl.u32 %v9529_v24, 16 (stack46)
        %v8350_v50 = vadd.f32 1.0, %v8349_v50 (stack61)
        %v9131_v43 = vor.u32 %v9130_v26, %v9129_v25 (stack47)
        %v9953_v24 = vor.u32 %v9952_v29, %v9951_v52 (stack47)
        %v10377_v52 = vadd.s32 1, %v10373_v56 (stack40)
        %v7939_v54 = vmul.f32 %v7935_v7, %v125095_v11 (stack54)
        %v8742_v22 = vadd.s32 %v8739_v21, %v8734_v22 (stack40)
        %v8744_v23 = vshll.u32 %v8739_v21, 26 (stack45)
        %v8745_v29 = vshrl.u32 %v8739_v21, 6 (stack46)
        %v9132_v25 = vxor.u32 %v9131_v43, %v9123_v20 (stack48)
        %v9536_v26 = vor.u32 %v9535_v12, %v9534_v10 (stack47)
        %v9954_v7 = vxor.u32 %v9953_v24, %v9949_v32 (stack48)
        %v10381_v53 = vsel /*vm=*/%vm10355_vm10, /*on_true_vy=*/%v10377_v52, /*on_false_vx=*/%v10373_v56 (stack44)
        %v7943_v8 = vadd.f32 %v7939_v54, %v125052_v8 (stack53)
        %v8746_v56 = vor.u32 %v8745_v29, %v8744_v23 (stack47)
        %v10386_v21 = vadd.s32 %v10381_v53, %v121574_v2 (stack40)
        %v10390_v46 = vadd.s32 %v125068_v46, %v121569_v1 (stack40)
        %vm125115_vm11 = vcmp.lt.f32.partialorder %v8352_v34, 0.0004427343 (stack62)
        %v9135_v10 = vadd.s32 %v9132_v25, %v121569_v1 (stack40)
        %v9537_v12 = vxor.u32 %v9536_v26, %v9532_v27 (stack48)
        %v125120_v32 = vadd.s32 %v9954_v7, %v9949_v32 (stack40)
        %v120498_v43 = vpop.eup %120497 (stack64)
        %v7947_v24 = vmul.f32 %v7943_v8, %v125095_v11 (stack54)
        %v8351_v61 = vmul.f32 %v8350_v50, %v125081_v61 (stack63)
        %v8747_v50 = vxor.u32 %v8746_v56, %v8742_v22 (stack48)
        %v125124_v52 = vadd.s32 %v10390_v46, %v10386_v21 (stack40)
        %v8348_v54 = vmul.f32 0.6931472, %v120498_v43 (stack65)
        %v9127_v20 = vadd.s32 %v9123_v20, %v121574_v2 (stack40)
        %v9139_v23 = vadd.s32 3, %v9135_v10 (stack40)
        %v9540_v27 = vadd.s32 %v9537_v12, %v9532_v27 (stack40)
        %v7951_v40 = vadd.f32 %v7947_v24, %v125046_v40 (stack53)
        %v8750_v22 = vadd.s32 %v8747_v50, %v8742_v22 (stack40)
        %v8756_v29 = vshll.u32 %v8747_v50, 6 (stack45)
        %v8757_v25 = vshrl.u32 %v8747_v50, 26 (stack46)
        %v8354_v26 = vsel /*vm=*/%vm125115_vm11, /*on_true_vy=*/%v8351_v61, /*on_false_vx=*/%v8348_v54 (stack66)
        %v9143_v53 = vadd.s32 %v9139_v23, %v9127_v20 (stack40)
        %v9145_v8 = vshll.u32 %v9139_v23, 17 (stack45)
        %v9146_v56 = vshrl.u32 %v9139_v23, 15 (stack46)
        %v7876_v21 = vsel /*vm=*/%vm7863_vm5, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v7955_v34 = vmul.f32 %v7951_v40, %v125095_v11 (stack54)
        %v125134_v10 = vxor.u32 2147483648, %v8354_v26 (stack56)
        %v8758_v43 = vor.u32 %v8757_v25, %v8756_v29 (stack47)
        %v125137_v24 = vmul.f32 inf, %v124953_v55 (stack54)
        %v7880_v60 = vsel /*vm=*/%vm7863_vm5, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v8331_v61 = vand.u32 2147483647, %v125060_v30 (stack77)
        %v9963_v50 = vshll.u32 %v9954_v7, 6 (stack45)
        %v7959_v54 = vadd.f32 %v7955_v34, %v7880_v60 (stack53)
        %120499 = vrsqrt.f32 %v125134_v10 (stack67)
        %v9546_v20 = vshll.u32 %v9537_v12, 24 (stack45)
        %v9964_v7 = vshrl.u32 %v9954_v7, 26 (stack46)
        %vm8358_vm12 = vcmp.lt.f32.partialorder %v125134_v10, 5.0 (stack68)
        %v8759_v23 = vxor.u32 %v8758_v43, %v8750_v22 (stack48)
        %v9147_v40 = vor.u32 %v9146_v56, %v9145_v8 (stack47)
        %v9547_v12 = vshrl.u32 %v9537_v12, 8 (stack46)
        %v7963_v29 = vmul.f32 %v7959_v54, %v125095_v11 (stack54)
        %v8754_v22 = vadd.s32 %v8750_v22, %v121564_v0 (stack40)
        %v10396_v25 = vshll.u32 %v10390_v46, 13 (stack45)
        %v10397_v46 = vshrl.u32 %v10390_v46, 19 (stack46)
        %v125148_v26 = vadd.f32 -2.5, %v125134_v10 (stack53)
        %v8762_v8 = vadd.s32 %v8759_v23, %v121574_v2 (stack40)
        %v9544_v56 = vadd.s32 %v9540_v27, %v121564_v0 (stack40)
        %v9961_v34 = vadd.s32 %v125120_v32, %v121569_v1 (stack40)
        %v7967_v21 = vadd.f32 %v7963_v29, %v7876_v21 (stack53)
        %v125157_v43 = vsel /*vm=*/%vm8358_vm12, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v125162_v60 = vsel /*vm=*/%vm8358_vm12, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v125167_v54 = vsel /*vm=*/%vm8358_vm12, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v8766_v23 = vadd.s32 5, %v8762_v8 (stack40)
        %v9148_v40 = vxor.u32 %v9147_v40, %v9143_v53 (stack48)
        %v9548_v20 = vor.u32 %v9547_v12, %v9546_v20 (stack47)
        %v9965_v50 = vor.u32 %v9964_v7, %v9963_v50 (stack47)
        %v7971_v7 = vmul.f32 %v7967_v21, %v125095_v11 (stack54)
        %v125173_v12 = vsel /*vm=*/%vm8358_vm12, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v10398_v29 = vor.u32 %v10397_v46, %v10396_v25 (stack47)
        %vm10821_vm13 = vcmp.lt.u32.totalorder %v125072_v42, %v157091_v37 (stack43)
        %vm125179_vm14 = vcmp.eq.f32.partialorder %v7836_v44, 1.0 (stack68)
        %vm8403_vm15 = vcmp.eq.f32.partialorder %v125134_v10, inf (stack70)
        %v8768_v22 = vxor.u32 %v8766_v23, %v8754_v22 (stack48)
        %v9151_v53 = vadd.s32 %v9148_v40, %v9143_v53 (stack40)
        %v9153_v25 = vshll.u32 %v9148_v40, 29 (stack45)
        %v9154_v46 = vshrl.u32 %v9148_v40, 3 (stack46)
        %v7975_v6 = vadd.f32 %v7971_v7, %v125037_v6 (stack53)
        %v9549_v27 = vxor.u32 %v9548_v20, %v9540_v27 (stack48)
        %v9966_v32 = vxor.u32 %v9965_v50, %v125120_v32 (stack48)
        %v10399_v8 = vxor.u32 %v10398_v29, %v125124_v52 (stack48)
        %vm8405_vm0 = vcmp.eq.f32.partialorder %v125134_v10, 0.0 (stack71)
        %v8769_v21 = vand.u32.u8 255, %v8768_v22 (stack49)
        %v9155_v23 = vor.u32 %v9154_v46, %v9153_v25 (stack47)
        %v125190_v40 = vadd.s32 %v157106_v9, %v157094_v36 (stack40)
        %v7979_v11 = vmul.f32 %v7975_v6, %v125095_v11 (stack54)
        %v9552_v20 = vadd.s32 %v9549_v27, %v121574_v2 (stack40)
        %v9969_v50 = vadd.s32 %v9966_v32, %v121564_v0 (stack40)
        %v10402_v52 = vadd.s32 %v10399_v8, %v125124_v52 (stack40)
        %v8406_v7 = vand.u32 2147483648, %v125134_v10 (stack72)
        %v8770_v29 = vand.u32 65535, %v8769_v21 (stack50)
        %v9156_v22 = vxor.u32 %v9155_v23, %v9151_v53 (stack48)
        %v10404_v25 = vshll.u32 %v10399_v8, 15 (stack45)
        %v7983_v41 = vadd.f32 %v7979_v11, %v125027_v41 (stack53)
        %v9556_v46 = vadd.s32 2, %v9552_v20 (stack40)
        %v9973_v6 = vadd.s32 1, %v9969_v50 (stack40)
        %v10405_v27 = vshrl.u32 %v10399_v8, 17 (stack46)
        %v120500_v32 = vpop.eup %120499 (stack73)
        %v8771_v8 = vshrl.u32 %v8770_v29, 1 (stack51)
        %v9159_v53 = vadd.s32 %v9156_v22, %v9151_v53 (stack40)
        %v9161_v21 = vshll.u32 %v9156_v22, 16 (stack45)
        %v9162_v23 = vshrl.u32 %v9156_v22, 16 (stack46)
        %v7987_v55 = vmul.f32 %v7983_v41, %v124953_v55 (stack54)
        %v8402_v11 = vmul.f32 %v120500_v32, %v125134_v10 (stack74)
        %v9560_v56 = vadd.s32 %v9556_v46, %v9544_v56 (stack40)
        %v9562_v20 = vshll.u32 %v9556_v46, 13 (stack45)
        %v8772_v50 = vor.u32 16256, %v8771_v8 (stack47)
        %v9163_v29 = vor.u32 %v9162_v23, %v9161_v21 (stack47)
        %v9563_v22 = vshrl.u32 %v9556_v46, 19 (stack46)
        %v9977_v34 = vadd.s32 %v9973_v6, %v9961_v34 (stack40)
        %v7991_v24 = vsel /*vm=*/%vm125179_vm14, /*on_true_vy=*/%v125137_v24, /*on_false_vx=*/%v7987_v55 (stack44)
        %v8404_v44 = vsel /*vm=*/%vm8403_vm15, /*on_true_vy=*/%v125134_v10, /*on_false_vx=*/%v8402_v11 (stack75)
        %v9979_v41 = vshll.u32 %v9973_v6, 17 (stack45)
        %v9980_v46 = vshrl.u32 %v9973_v6, 15 (stack46)
        %v7995_v6 = vmul.f32 1.4140625, %v7991_v24 (stack54)
        %v8407_v7 = vsel /*vm=*/%vm8405_vm0, /*on_true_vy=*/%v8406_v7, /*on_false_vx=*/%v8404_v44 (stack76)
        %v8773_v32 = vand.u32.u16 65535, %v8772_v50 (stack52)
        %v9164_v8 = vxor.u32 %v9163_v29, %v9159_v53 (stack48)
        %v8410_v21 = vadd.f32 -3.0, %v8407_v7 (stack53)
        %v9564_v23 = vor.u32 %v9563_v22, %v9562_v20 (stack47)
        %v9981_v55 = vor.u32 %v9980_v46, %v9979_v41 (stack47)
        %v10406_v25 = vor.u32 %v10405_v27, %v10404_v25 (stack47)
        %v7998_v27 = vpack.c.bf16 %v156663_v45, %v7995_v6 (stack81)
        %v119790_v11 = vadd.low.f32.bf16 -1.0, %v8773_v32 (stack53)
        %v9167_v53 = vadd.s32 %v9164_v8, %v9159_v53 (stack40)
        %v9173_v20 = vshll.u32 %v9164_v8, 24 (stack45)
        %v125212_v26 = vsel /*vm=*/%vm8358_vm12, /*on_true_vy=*/%v125148_v26, /*on_false_vx=*/%v8410_v21 (stack44)
        %v9174_v50 = vshrl.u32 %v9164_v8, 8 (stack46)
        %v9565_v29 = vxor.u32 %v9564_v23, %v9560_v56 (stack48)
        %v9982_v22 = vxor.u32 %v9981_v55, %v9977_v34 (stack48)
        %119783 = vst [vmem:[%s123356_s30 + $0x384] sm:$0xf] /*vst_source=*/%v7998_v27 (stack83)
        %v8418_v12 = vmul.f32 %v125212_v26, %v125173_v12 (stack54)
        %v8782_v24 = vmul.f32 2.0, %v119790_v11 (stack54)
        %v10407_v44 = vxor.u32 %v10406_v25, %v10402_v52 (stack48)
        %v10830_v41 = vadd.s32 1, %v125190_v40 (stack40)
        %v9175_v46 = vor.u32 %v9174_v50, %v9173_v20 (stack47)
        %v9568_v56 = vadd.s32 %v9565_v29, %v9560_v56 (stack40)
        %v9570_v6 = vshll.u32 %v9565_v29, 15 (stack45)
        %v9571_v7 = vshrl.u32 %v9565_v29, 17 (stack46)
        %v8422_v54 = vadd.f32 %v8418_v12, %v125167_v54 (stack53)
        %v8786_v32 = vadd.f32 -0.99609375, %v8782_v24 (stack53)
        %v9985_v34 = vadd.s32 %v9982_v22, %v9977_v34 (stack40)
        %v9987_v8 = vshll.u32 %v9982_v22, 29 (stack45)
        %v9176_v21 = vxor.u32 %v9175_v46, %v9167_v53 (stack48)
        %v9572_v23 = vor.u32 %v9571_v7, %v9570_v6 (stack47)
        %v9988_v55 = vshrl.u32 %v9982_v22, 3 (stack46)
        %v10410_v52 = vadd.s32 %v10407_v44, %v10402_v52 (stack40)
        %v8375_v25 = vsel /*vm=*/%vm8358_vm12, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v8387_v27 = vsel /*vm=*/%vm8358_vm12, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v8426_v11 = vmul.f32 %v8422_v54, %v125212_v26 (stack54)
        %v125226_v20 = vmax.f32 %v8786_v32, -0.99609375 (stack55)
        %v9179_v50 = vadd.s32 %v9176_v21, %v121564_v0 (stack40)
        %v9573_v29 = vxor.u32 %v9572_v23, %v9568_v56 (stack48)
        %v9989_v22 = vor.u32 %v9988_v55, %v9987_v8 (stack47)
        %v10834_v40 = vsel /*vm=*/%vm10821_vm13, /*on_true_vy=*/%v10830_v41, /*on_false_vx=*/%v125190_v40 (stack44)
        %v8383_v12 = vsel /*vm=*/%vm8358_vm12, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v8430_v24 = vadd.f32 %v8426_v11, %v8387_v27 (stack53)
        %v8802_v41 = vxor.u32 2147483648, %v125226_v20 (stack56)
        %v9171_v53 = vadd.s32 %v9167_v53, %v121569_v1 (stack40)
        %v9183_v46 = vadd.s32 4, %v9179_v50 (stack40)
        %v9576_v56 = vadd.s32 %v9573_v29, %v9568_v56 (stack40)
        %v9578_v6 = vshll.u32 %v9573_v29, 26 (stack45)
        %v9579_v7 = vshrl.u32 %v9573_v29, 6 (stack46)
        %v8434_v54 = vmul.f32 %v8430_v24, %v125212_v26 (stack54)
        %v125240_v32 = vmul.f32 %v8802_v41, %v125226_v20 (stack54)
        %v9990_v8 = vxor.u32 %v9989_v22, %v9985_v34 (stack48)
        %v10812_v21 = vadd.s32 %v125072_v42, %v122657_v58 (stack40)
        %v9187_v23 = vadd.s32 %v9183_v46, %v9171_v53 (stack40)
        %v9189_v55 = vshll.u32 %v9183_v46, 13 (stack45)
        %v9190_v27 = vshrl.u32 %v9183_v46, 19 (stack46)
        %v9580_v11 = vor.u32 %v9579_v7, %v9578_v6 (stack47)
        %v8438_v50 = vadd.f32 %v8434_v54, %v8383_v12 (stack53)
        %v8807_v29 = vadd.f32 1.0, %v125240_v32 (stack57)
        %v10412_v22 = vshll.u32 %v10407_v44, 26 (stack45)
        %v10413_v44 = vshrl.u32 %v10407_v44, 6 (stack46)
        %v8379_v12 = vsel /*vm=*/%vm8358_vm12, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v9191_v24 = vor.u32 %v9190_v27, %v9189_v55 (stack47)
        %v9581_v41 = vxor.u32 %v9580_v11, %v9576_v56 (stack48)
        %v9993_v34 = vadd.s32 %v9990_v8, %v9985_v34 (stack40)
        %v8442_v53 = vmul.f32 %v8438_v50, %v125212_v26 (stack54)
        %120501 = vlog2.f32 %v8807_v29 (stack58)
        %v8810_v46 = vmul.f32 -0.5, %v125240_v32 (stack59)
        %v9995_v6 = vshll.u32 %v9990_v8, 16 (stack45)
        %v9192_v7 = vxor.u32 %v9191_v24, %v9187_v23 (stack48)
        %v9584_v56 = vadd.s32 %v9581_v41, %v9576_v56 (stack40)
        %v9590_v54 = vshll.u32 %v9581_v41, 6 (stack45)
        %v9591_v55 = vshrl.u32 %v9581_v41, 26 (stack46)
        %v8446_v27 = vadd.f32 %v8442_v53, %v8379_v12 (stack53)
        %v9996_v8 = vshrl.u32 %v9990_v8, 16 (stack46)
        %v10414_v11 = vor.u32 %v10413_v44, %v10412_v22 (stack47)
        %vm10816_vm1 = vcmp.lt.u32.totalorder %v10812_v21, %v125072_v42 (stack43)
        %v8813_v50 = vand.u32 2147483647, %v125240_v32 (stack60)
        %v9195_v23 = vadd.s32 %v9192_v7, %v9187_v23 (stack40)
        %v9197_v29 = vshll.u32 %v9192_v7, 15 (stack45)
        %v9198_v22 = vshrl.u32 %v9192_v7, 17 (stack46)
        %v8450_v44 = vmul.f32 %v8446_v27, %v125212_v26 (stack54)
        %v9592_v12 = vor.u32 %v9591_v55, %v9590_v54 (stack47)
        %v9997_v24 = vor.u32 %v9996_v8, %v9995_v6 (stack47)
        %v10415_v41 = vxor.u32 %v10414_v11, %v10410_v52 (stack48)
        %v8811_v53 = vadd.f32 1.0, %v8810_v46 (stack61)
        %v9199_v46 = vor.u32 %v9198_v22, %v9197_v29 (stack47)
        %v10838_v6 = vadd.s32 1, %v10834_v40 (stack40)
        %v125255_v31 = vadd.s32 %v157101_v31, %v157095_v13 (stack40)
        %v8454_v25 = vadd.f32 %v8450_v44, %v8375_v25 (stack53)
        %v9593_v7 = vxor.u32 %v9592_v12, %v9584_v56 (stack48)
        %v9998_v54 = vxor.u32 %v9997_v24, %v9993_v34 (stack48)
        %v10418_v52 = vadd.s32 %v10415_v41, %v10410_v52 (stack40)
        %v9200_v55 = vxor.u32 %v9199_v46, %v9195_v23 (stack48)
        %v10424_v27 = vshll.u32 %v10415_v41, 6 (stack45)
        %v10425_v8 = vshrl.u32 %v10415_v41, 26 (stack46)
        %v10842_v42 = vsel /*vm=*/%vm10816_vm1, /*on_true_vy=*/%v10838_v6, /*on_false_vx=*/%v10834_v40 (stack44)
        %v8458_v40 = vmul.f32 %v8454_v25, %v125212_v26 (stack54)
        %v9596_v11 = vadd.s32 %v9593_v7, %v121569_v1 (stack40)
        %v10001_v34 = vadd.s32 %v9998_v54, %v9993_v34 (stack40)
        %v10007_v29 = vshll.u32 %v9998_v54, 24 (stack45)
        %v9203_v23 = vadd.s32 %v9200_v55, %v9195_v23 (stack40)
        %v9205_v22 = vshll.u32 %v9200_v55, 26 (stack45)
        %v9206_v44 = vshrl.u32 %v9200_v55, 6 (stack46)
        %v10008_v12 = vshrl.u32 %v9998_v54, 8 (stack46)
        %v8462_v60 = vadd.f32 %v8458_v40, %v125162_v60 (stack53)
        %v9588_v56 = vadd.s32 %v9584_v56, %v121574_v2 (stack40)
        %v9600_v24 = vadd.s32 3, %v9596_v11 (stack40)
        %v125264_v21 = vadd.s32 %v10812_v21, %v121569_v1 (stack40)
        %v9207_v41 = vor.u32 %v9206_v44, %v9205_v22 (stack47)
        %v10009_v46 = vor.u32 %v10008_v12, %v10007_v29 (stack47)
        %v10426_v6 = vor.u32 %v10425_v8, %v10424_v27 (stack47)
        %v10847_v25 = vadd.s32 %v10842_v42, %v121574_v2 (stack40)
        %v8466_v7 = vmul.f32 %v8462_v60, %v125212_v26 (stack54)
        %v9604_v54 = vadd.s32 %v9600_v24, %v9588_v56 (stack40)
        %v9606_v55 = vshll.u32 %v9600_v24, 17 (stack45)
        %v9607_v27 = vshrl.u32 %v9600_v24, 15 (stack46)
        %v120502_v8 = vpop.eup %120501 (stack64)
        %v9208_v42 = vxor.u32 %v9207_v41, %v9203_v23 (stack48)
        %v10010_v40 = vxor.u32 %v10009_v46, %v10001_v34 (stack48)
        %v10427_v11 = vxor.u32 %v10426_v6, %v10418_v52 (stack48)
        %v125269_v29 = vadd.s32 %v125264_v21, %v10847_v25 (stack40)
        %v8470_v43 = vadd.f32 %v8466_v7, %v125157_v43 (stack53)
        %v8809_v22 = vmul.f32 0.6931472, %v120502_v8 (stack65)
        %v8812_v32 = vmul.f32 %v8811_v53, %v125240_v32 (stack63)
        %v9608_v53 = vor.u32 %v9607_v27, %v9606_v55 (stack47)
        %vm8814_vm2 = vcmp.lt.f32.partialorder %v8813_v50, 0.0004427343 (stack62)
        %v9211_v50 = vadd.s32 %v9208_v42, %v9203_v23 (stack40)
        %v9217_v23 = vshll.u32 %v9208_v42, 6 (stack45)
        %v9218_v44 = vshrl.u32 %v9208_v42, 26 (stack46)
        %v8474_v26 = vmul.f32 %v8470_v43, %v125212_v26 (stack54)
        %v8815_v12 = vsel /*vm=*/%vm8814_vm2, /*on_true_vy=*/%v8812_v32, /*on_false_vx=*/%v8809_v22 (stack66)
        %v9609_v60 = vxor.u32 %v9608_v53, %v9604_v54 (stack48)
        %v10013_v56 = vadd.s32 %v10010_v40, %v121574_v2 (stack40)
        %v8363_v10 = vsel /*vm=*/%vm8358_vm12, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v125278_v24 = vxor.u32 2147483648, %v8815_v12 (stack56)
        %v9219_v41 = vor.u32 %v9218_v44, %v9217_v23 (stack47)
        %vm125282_vm3 = vcmp.eq.f32.partialorder %v8331_v61, 1.0 (stack68)
        %v8339_v46 = vmul.f32 inf, %v125060_v30 (stack54)
        %v8478_v6 = vadd.f32 %v8474_v26, %v8363_v10 (stack53)
        %v9612_v25 = vadd.s32 %v9609_v60, %v9604_v54 (stack40)
        %v8792_v7 = vand.u32 2147483647, %v125226_v20 (stack77)
        %vm8819_vm4 = vcmp.lt.f32.partialorder %v125278_v24, 5.0 (stack68)
        %120503 = vrsqrt.f32 %v125278_v24 (stack67)
        %v10005_v34 = vadd.s32 %v10001_v34, %v121564_v0 (stack40)
        %v8482_v30 = vmul.f32 %v8478_v6, %v125060_v30 (stack54)
        %v9614_v54 = vshll.u32 %v9609_v60, 29 (stack45)
        %v9615_v55 = vshrl.u32 %v9609_v60, 3 (stack46)
        %v10017_v27 = vadd.s32 2, %v10013_v56 (stack40)
        %v9220_v8 = vxor.u32 %v9219_v41, %v9211_v50 (stack48)
        %v10422_v52 = vadd.s32 %v10418_v52, %v121569_v1 (stack40)
        %v10430_v42 = vadd.s32 %v10427_v11, %v121564_v0 (stack40)
        %v10857_v40 = vshll.u32 %v125264_v21, 13 (stack45)
        %v8486_v11 = vsel /*vm=*/%vm125282_vm3, /*on_true_vy=*/%v8339_v46, /*on_false_vx=*/%v8482_v30 (stack44)
        %v125300_v43 = vsel /*vm=*/%vm8819_vm4, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v125303_v22 = vadd.f32 -2.5, %v125278_v24 (stack53)
        %v9215_v32 = vadd.s32 %v9211_v50, %v121564_v0 (stack40)
        %v8490_v53 = vmul.f32 1.4140625, %v8486_v11 (stack54)
        %v125309_v50 = vsel /*vm=*/%vm8819_vm4, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v125314_v23 = vsel /*vm=*/%vm8819_vm4, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v9223_v44 = vadd.s32 %v9220_v8, %v121574_v2 (stack40)
        %v9616_v26 = vor.u32 %v9615_v55, %v9614_v54 (stack47)
        %v10021_v12 = vadd.s32 %v10017_v27, %v10005_v34 (stack40)
        %v10023_v60 = vshll.u32 %v10017_v27, 13 (stack45)
        %v10024_v56 = vshrl.u32 %v10017_v27, 19 (stack46)
        %v8493_v10 = vpack.c.bf16 %v156663_v45, %v8490_v53 (stack81)
        %v9227_v41 = vadd.s32 5, %v9223_v44 (stack40)
        %v10434_v61 = vadd.s32 1, %v10430_v42 (stack40)
        %v10858_v21 = vshrl.u32 %v125264_v21, 19 (stack46)
        %v8856_v46 = vsel /*vm=*/%vm8819_vm4, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %vm8864_vm5 = vcmp.eq.f32.partialorder %v125278_v24, inf (stack70)
        %v9617_v6 = vxor.u32 %v9616_v26, %v9612_v25 (stack48)
        %v10025_v34 = vor.u32 %v10024_v56, %v10023_v60 (stack47)
        %vm11282_vm6 = vcmp.lt.u32.totalorder %v125255_v31, %v157095_v13 (stack43)
        %119789 = vst [vmem:[%s123356_s30 + $0x8] sm:$0xf] /*vst_source=*/%v8493_v10 (stack83)
        %v9229_v30 = vxor.u32 %v9227_v41, %v9215_v32 (stack48)
        %v10438_v54 = vadd.s32 %v10434_v61, %v10422_v52 (stack40)
        %v10440_v55 = vshll.u32 %v10434_v61, 17 (stack45)
        %v10441_v27 = vshrl.u32 %v10434_v61, 15 (stack46)
        %v9620_v25 = vadd.s32 %v9617_v6, %v9612_v25 (stack40)
        %v9622_v8 = vshll.u32 %v9617_v6, 16 (stack45)
        %v9623_v52 = vshrl.u32 %v9617_v6, 16 (stack46)
        %v10026_v42 = vxor.u32 %v10025_v34, %v10021_v12 (stack48)
        %vm8866_vm7 = vcmp.eq.f32.partialorder %v125278_v24, 0.0 (stack71)
        %v9230_v11 = vand.u32.u8 255, %v9229_v30 (stack49)
        %v10442_v32 = vor.u32 %v10441_v27, %v10440_v55 (stack47)
        %v10859_v40 = vor.u32 %v10858_v21, %v10857_v40 (stack47)
        %v9624_v53 = vor.u32 %v9623_v52, %v9622_v8 (stack47)
        %v10029_v44 = vadd.s32 %v10026_v42, %v10021_v12 (stack40)
        %v10031_v26 = vshll.u32 %v10026_v42, 15 (stack45)
        %v10032_v12 = vshrl.u32 %v10026_v42, 17 (stack46)
        %v9231_v60 = vand.u32 65535, %v9230_v11 (stack50)
        %v10443_v56 = vxor.u32 %v10442_v32, %v10438_v54 (stack48)
        %v10860_v10 = vxor.u32 %v10859_v40, %v125269_v29 (stack48)
        %v11287_v9 = vadd.s32 %v157106_v9, %v157100_v14 (stack40)
        %v120504_v41 = vpop.eup %120503 (stack73)
        %v8867_v61 = vand.u32 2147483648, %v125278_v24 (stack72)
        %v9625_v21 = vxor.u32 %v9624_v53, %v9620_v25 (stack48)
        %v10033_v6 = vor.u32 %v10032_v12, %v10031_v26 (stack47)
        %v157127_v34 = vld [vmem:[#allocation123_spill] sm:$0xff] (stack84)
        %v125333_v30 = vadd.s32 %v157127_v34, %v122651_v47 (stack40)
        %v8863_v55 = vmul.f32 %v120504_v41, %v125278_v24 (stack74)
        %v9232_v27 = vshrl.u32 %v9231_v60, 1 (stack51)
        %v10446_v54 = vadd.s32 %v10443_v56, %v10438_v54 (stack40)
        %v10448_v8 = vshll.u32 %v10443_v56, 29 (stack45)
        %v9628_v25 = vadd.s32 %v9625_v21, %v9620_v25 (stack40)
        %v9634_v52 = vshll.u32 %v9625_v21, 24 (stack45)
        %v9635_v42 = vshrl.u32 %v9625_v21, 8 (stack46)
        %v10034_v11 = vxor.u32 %v10033_v6, %v10029_v44 (stack48)
        %v8865_v32 = vsel /*vm=*/%vm8864_vm5, /*on_true_vy=*/%v125278_v24, /*on_false_vx=*/%v8863_v55 (stack75)
        %v9233_v40 = vor.u32 16256, %v9232_v27 (stack47)
        %v10449_v53 = vshrl.u32 %v10443_v56, 3 (stack46)
        %v10863_v29 = vadd.s32 %v10860_v10, %v125269_v29 (stack40)
        %v8868_v26 = vsel /*vm=*/%vm8866_vm7, /*on_true_vy=*/%v8867_v61, /*on_false_vx=*/%v8865_v32 (stack76)
        %v9636_v12 = vor.u32 %v9635_v42, %v9634_v52 (stack47)
        %v10037_v44 = vadd.s32 %v10034_v11, %v10029_v44 (stack40)
        %v125344_v60 = vadd.s32 %v125255_v31, %v122657_v58 (stack40)
        %v8871_v56 = vadd.f32 -3.0, %v8868_v26 (stack53)
        %v9234_v41 = vand.u32.u16 65535, %v9233_v40 (stack52)
        %v10039_v61 = vshll.u32 %v10034_v11, 26 (stack45)
        %v10040_v21 = vshrl.u32 %v10034_v11, 6 (stack46)
        %v9637_v6 = vxor.u32 %v9636_v12, %v9628_v25 (stack48)
        %v10450_v55 = vor.u32 %v10449_v53, %v10448_v8 (stack47)
        %v10865_v27 = vshll.u32 %v10860_v10, 15 (stack45)
        %v10866_v10 = vshrl.u32 %v10860_v10, 17 (stack46)
        %v125349_v22 = vsel /*vm=*/%vm8819_vm4, /*on_true_vy=*/%v125303_v22, /*on_false_vx=*/%v8871_v56 (stack44)
        %v119792_v8 = vadd.low.f32.bf16 -1.0, %v9234_v41 (stack53)
        %v10041_v52 = vor.u32 %v10040_v21, %v10039_v61 (stack47)
        %v11291_v42 = vadd.s32 1, %v11287_v9 (stack40)
        %v8879_v46 = vmul.f32 %v125349_v22, %v8856_v46 (stack54)
        %v9632_v25 = vadd.s32 %v9628_v25, %v121569_v1 (stack40)
        %v9640_v11 = vadd.s32 %v9637_v6, %v121564_v0 (stack40)
        %v10451_v32 = vxor.u32 %v10450_v55, %v10446_v54 (stack48)
        %v9243_v40 = vmul.f32 2.0, %v119792_v8 (stack54)
        %v10042_v53 = vxor.u32 %v10041_v52, %v10037_v44 (stack48)
        %v10867_v26 = vor.u32 %v10866_v10, %v10865_v27 (stack47)
        %v125357_v9 = vsel /*vm=*/%vm11282_vm6, /*on_true_vy=*/%v11291_v42, /*on_false_vx=*/%v11287_v9 (stack44)
        %v8883_v23 = vadd.f32 %v8879_v46, %v125314_v23 (stack53)
        %v9644_v12 = vadd.s32 4, %v9640_v11 (stack40)
        %v10454_v54 = vadd.s32 %v10451_v32, %v10446_v54 (stack40)
        %v10456_v56 = vshll.u32 %v10451_v32, 16 (stack45)
        %v9247_v41 = vadd.f32 -0.99609375, %v9243_v40 (stack53)
        %v10045_v44 = vadd.s32 %v10042_v53, %v10037_v44 (stack40)
        %v10051_v61 = vshll.u32 %v10042_v53, 6 (stack45)
        %v10052_v21 = vshrl.u32 %v10042_v53, 26 (stack46)
        %v8887_v6 = vmul.f32 %v8883_v23, %v125349_v22 (stack54)
        %v9648_v55 = vadd.s32 %v9644_v12, %v9632_v25 (stack40)
        %v9650_v27 = vshll.u32 %v9644_v12, 13 (stack45)
        %v9651_v10 = vshrl.u32 %v9644_v12, 19 (stack46)
        %v8848_v8 = vsel /*vm=*/%vm8819_vm4, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v125364_v52 = vmax.f32 %v9247_v41, -0.99609375 (stack55)
        %v10053_v42 = vor.u32 %v10052_v21, %v10051_v61 (stack47)
        %v10457_v46 = vshrl.u32 %v10451_v32, 16 (stack46)
        %v8840_v25 = vsel /*vm=*/%vm8819_vm4, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v8891_v11 = vadd.f32 %v8887_v6, %v8848_v8 (stack53)
        %v9652_v32 = vor.u32 %v9651_v10, %v9650_v27 (stack47)
        %v10868_v40 = vxor.u32 %v10867_v26, %v10863_v29 (stack48)
        %v8844_v53 = vsel /*vm=*/%vm8819_vm4, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v9263_v26 = vxor.u32 2147483648, %v125364_v52 (stack56)
        %v10054_v23 = vxor.u32 %v10053_v42, %v10045_v44 (stack48)
        %vm11277_vm8 = vcmp.lt.u32.totalorder %v125344_v60, %v125255_v31 (stack43)
        %v8895_v12 = vmul.f32 %v8891_v11, %v125349_v22 (stack54)
        %v9653_v41 = vxor.u32 %v9652_v32, %v9648_v55 (stack48)
        %v10458_v56 = vor.u32 %v10457_v46, %v10456_v56 (stack47)
        %v10871_v29 = vadd.s32 %v10868_v40, %v10863_v29 (stack40)
        %v9266_v61 = vmul.f32 %v9263_v26, %v125364_v52 (stack54)
        %v10049_v44 = vadd.s32 %v10045_v44, %v121574_v2 (stack40)
        %v10057_v21 = vadd.s32 %v10054_v23, %v121569_v1 (stack40)
        %v125381_v6 = vadd.s32 %v125344_v60, %v121569_v1 (stack40)
        %v8899_v27 = vadd.f32 %v8895_v12, %v8844_v53 (stack53)
        %v9656_v55 = vadd.s32 %v9653_v41, %v9648_v55 (stack40)
        %v9658_v10 = vshll.u32 %v9653_v41, 15 (stack45)
        %v9659_v8 = vshrl.u32 %v9653_v41, 17 (stack46)
        %v9268_v42 = vadd.f32 1.0, %v9266_v61 (stack57)
        %v9271_v46 = vmul.f32 -0.5, %v9266_v61 (stack59)
        %v10061_v11 = vadd.s32 3, %v10057_v21 (stack40)
        %v11299_v32 = vadd.s32 1, %v125357_v9 (stack40)
        %v8903_v53 = vmul.f32 %v8899_v27, %v125349_v22 (stack54)
        %v9660_v26 = vor.u32 %v9659_v8, %v9658_v10 (stack47)
        %v10459_v23 = vxor.u32 %v10458_v56, %v10454_v54 (stack48)
        %v10873_v12 = vshll.u32 %v10868_v40, 26 (stack45)
        %120505 = vlog2.f32 %v9268_v42 (stack58)
        %v9274_v41 = vand.u32 2147483647, %v9266_v61 (stack60)
        %v10065_v56 = vadd.s32 %v10061_v11, %v10049_v44 (stack40)
        %v10874_v40 = vshrl.u32 %v10868_v40, 6 (stack46)
        %v8907_v25 = vadd.f32 %v8903_v53, %v8840_v25 (stack53)
        %v9661_v44 = vxor.u32 %v9660_v26, %v9656_v55 (stack48)
        %v10067_v21 = vshll.u32 %v10061_v11, 17 (stack45)
        %v10068_v27 = vshrl.u32 %v10061_v11, 15 (stack46)
        %v9272_v10 = vadd.f32 1.0, %v9271_v46 (stack61)
        %v10462_v54 = vadd.s32 %v10459_v23, %v10454_v54 (stack40)
        %v10468_v8 = vshll.u32 %v10459_v23, 24 (stack45)
        %v10469_v42 = vshrl.u32 %v10459_v23, 8 (stack46)
        %v8911_v46 = vmul.f32 %v8907_v25, %v125349_v22 (stack54)
        %v9664_v55 = vadd.s32 %v9661_v44, %v9656_v55 (stack40)
        %v9666_v11 = vshll.u32 %v9661_v44, 26 (stack45)
        %v9667_v53 = vshrl.u32 %v9661_v44, 6 (stack46)
        %v8836_v26 = vsel /*vm=*/%vm8819_vm4, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v10069_v23 = vor.u32 %v10068_v27, %v10067_v21 (stack47)
        %v10470_v25 = vor.u32 %v10469_v42, %v10468_v8 (stack47)
        %v10875_v12 = vor.u32 %v10874_v40, %v10873_v12 (stack47)
        %v8915_v40 = vadd.f32 %v8911_v46, %v8836_v26 (stack53)
        %v9668_v44 = vor.u32 %v9667_v53, %v9666_v11 (stack47)
        %v11303_v31 = vsel /*vm=*/%vm11277_vm8, /*on_true_vy=*/%v11299_v32, /*on_false_vx=*/%v125357_v9 (stack44)
        %v11318_v60 = vshll.u32 %v125381_v6, 13 (stack45)
        %v9273_v9 = vmul.f32 %v9272_v10, %v9266_v61 (stack63)
        %v10070_v61 = vxor.u32 %v10069_v23, %v10065_v56 (stack48)
        %v10471_v32 = vxor.u32 %v10470_v25, %v10462_v54 (stack48)
        %v10876_v21 = vxor.u32 %v10875_v12, %v10871_v29 (stack48)
        %v8919_v27 = vmul.f32 %v8915_v40, %v125349_v22 (stack54)
        %vm125395_vm9 = vcmp.lt.f32.partialorder %v9274_v41, 0.0004427343 (stack62)
        %v9669_v10 = vxor.u32 %v9668_v44, %v9664_v55 (stack48)
        %v10466_v54 = vadd.s32 %v10462_v54, %v121564_v0 (stack40)
        %v11319_v8 = vshrl.u32 %v125381_v6, 19 (stack46)
        %v10073_v56 = vadd.s32 %v10070_v61, %v10065_v56 (stack40)
        %v10075_v42 = vshll.u32 %v10070_v61, 29 (stack45)
        %v10076_v46 = vshrl.u32 %v10070_v61, 3 (stack46)
        %v10474_v11 = vadd.s32 %v10471_v32, %v121574_v2 (stack40)
        %v8923_v50 = vadd.f32 %v8919_v27, %v125309_v50 (stack53)
        %v9672_v55 = vadd.s32 %v9669_v10, %v9664_v55 (stack40)
        %v9678_v53 = vshll.u32 %v9669_v10, 6 (stack45)
        %v9679_v26 = vshrl.u32 %v9669_v10, 26 (stack46)
        %v10077_v23 = vor.u32 %v10076_v46, %v10075_v42 (stack47)
        %v10478_v25 = vadd.s32 2, %v10474_v11 (stack40)
        %v10879_v29 = vadd.s32 %v10876_v21, %v10871_v29 (stack40)
        %v10885_v12 = vshll.u32 %v10876_v21, 6 (stack45)
        %v8927_v40 = vmul.f32 %v8923_v50, %v125349_v22 (stack54)
        %v9680_v44 = vor.u32 %v9679_v26, %v9678_v53 (stack47)
        %v10886_v61 = vshrl.u32 %v10876_v21, 26 (stack46)
        %v11308_v31 = vadd.s32 %v11303_v31, %v121574_v2 (stack40)
        %v10078_v32 = vxor.u32 %v10077_v23, %v10073_v56 (stack48)
        %v10482_v21 = vadd.s32 %v10478_v25, %v10466_v54 (stack40)
        %v10484_v27 = vshll.u32 %v10478_v25, 13 (stack45)
        %v10485_v10 = vshrl.u32 %v10478_v25, 19 (stack46)
        %v120506_v54 = vpop.eup %120505 (stack64)
        %v8931_v43 = vadd.f32 %v8927_v40, %v125300_v43 (stack53)
        %v9681_v42 = vxor.u32 %v9680_v44, %v9672_v55 (stack48)
        %v10887_v46 = vor.u32 %v10886_v61, %v10885_v12 (stack47)
        %v11320_v60 = vor.u32 %v11319_v8, %v11318_v60 (stack47)
        %v9270_v8 = vmul.f32 0.6931472, %v120506_v54 (stack65)
        %v10081_v56 = vadd.s32 %v10078_v32, %v10073_v56 (stack40)
        %v10083_v11 = vshll.u32 %v10078_v32, 16 (stack45)
        %v10084_v50 = vshrl.u32 %v10078_v32, 16 (stack46)
        %v8935_v22 = vmul.f32 %v8931_v43, %v125349_v22 (stack54)
        %v9684_v53 = vadd.s32 %v9681_v42, %v121574_v2 (stack40)
        %v10486_v26 = vor.u32 %v10485_v10, %v10484_v27 (stack47)
        %v10888_v23 = vxor.u32 %v10887_v46, %v10879_v29 (stack48)
        %v8824_v24 = vsel /*vm=*/%vm8819_vm4, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v9276_v9 = vsel /*vm=*/%vm125395_vm9, /*on_true_vy=*/%v9273_v9, /*on_false_vx=*/%v9270_v8 (stack66)
        %v10085_v41 = vor.u32 %v10084_v50, %v10083_v11 (stack47)
        %v11316_v6 = vadd.s32 %v125381_v6, %v11308_v31 (stack40)
        %v8939_v25 = vadd.f32 %v8935_v22, %v8824_v24 (stack53)
        %v125414_v12 = vxor.u32 2147483648, %v9276_v9 (stack56)
        %v9688_v40 = vadd.s32 5, %v9684_v53 (stack40)
        %v10487_v44 = vxor.u32 %v10486_v26, %v10482_v21 (stack48)
        %v9676_v55 = vadd.s32 %v9672_v55, %v121564_v0 (stack40)
        %v10086_v61 = vxor.u32 %v10085_v41, %v10081_v56 (stack48)
        %v11321_v31 = vxor.u32 %v11320_v60, %v11316_v6 (stack48)
        %vm11777_vm10 = vcmp.lt.u32.totalorder %v125333_v30, %v122651_v47 (stack43)
        %v8800_v32 = vmul.f32 inf, %v125226_v20 (stack54)
        %v8943_v27 = vmul.f32 %v8939_v25, %v125226_v20 (stack54)
        %vm9280_vm11 = vcmp.lt.f32.partialorder %v125414_v12, 5.0 (stack68)
        %120507 = vrsqrt.f32 %v125414_v12 (stack67)
        %vm8795_vm12 = vcmp.eq.f32.partialorder %v8792_v7, 1.0 (stack68)
        %v9690_v20 = vxor.u32 %v9688_v40, %v9676_v55 (stack48)
        %v8947_v7 = vsel /*vm=*/%vm8795_vm12, /*on_true_vy=*/%v8800_v32, /*on_false_vx=*/%v8943_v27 (stack44)
        %v10883_v29 = vadd.s32 %v10879_v29, %v121569_v1 (stack40)
        %v125428_v10 = vadd.s32 %v125333_v30, %v122657_v58 (stack40)
        %v8951_v54 = vmul.f32 1.4140625, %v8947_v7 (stack54)
        %v125433_v43 = vsel /*vm=*/%vm9280_vm11, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v125438_v42 = vsel /*vm=*/%vm9280_vm11, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v10891_v46 = vadd.s32 %v10888_v23, %v121564_v0 (stack40)
        %v125444_v60 = vsel /*vm=*/%vm9280_vm11, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v125449_v8 = vsel /*vm=*/%vm9280_vm11, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v125452_v11 = vadd.f32 -2.5, %v125414_v12 (stack53)
        %v9691_v50 = vand.u32.u8 255, %v9690_v20 (stack49)
        %v8954_v22 = vpack.c.bf16 %v156663_v45, %v8951_v54 (stack81)
        %v10089_v56 = vadd.s32 %v10086_v61, %v10081_v56 (stack40)
        %v10095_v53 = vshll.u32 %v10086_v61, 24 (stack45)
        %v10096_v26 = vshrl.u32 %v10086_v61, 8 (stack46)
        %v9692_v23 = vand.u32 65535, %v9691_v50 (stack50)
        %v10490_v21 = vadd.s32 %v10487_v44, %v10482_v21 (stack40)
        %v10492_v24 = vshll.u32 %v10487_v44, 15 (stack45)
        %v10493_v9 = vshrl.u32 %v10487_v44, 17 (stack46)
        %119791 = vst [vmem:[%s123356_s30 + $0x88] sm:$0xf] /*vst_source=*/%v8954_v22 (stack83)
        %vm9325_vm13 = vcmp.eq.f32.partialorder %v125414_v12, inf (stack70)
        %v10097_v41 = vor.u32 %v10096_v26, %v10095_v53 (stack47)
        %v10895_v25 = vadd.s32 1, %v10891_v46 (stack40)
        %v11324_v6 = vadd.s32 %v11321_v31, %v11316_v6 (stack40)
        %v9693_v40 = vshrl.u32 %v9692_v23, 1 (stack51)
        %v10494_v44 = vor.u32 %v10493_v9, %v10492_v24 (stack47)
        %v11326_v55 = vshll.u32 %v11321_v31, 15 (stack45)
        %v11327_v61 = vshrl.u32 %v11321_v31, 17 (stack46)
        %v10098_v31 = vxor.u32 %v10097_v41, %v10089_v56 (stack48)
        %v10899_v32 = vadd.s32 %v10895_v25, %v10883_v29 (stack40)
        %v10901_v27 = vshll.u32 %v10895_v25, 17 (stack45)
        %v10902_v20 = vshrl.u32 %v10895_v25, 15 (stack46)
        %v9694_v7 = vor.u32 16256, %v9693_v40 (stack47)
        %v10495_v29 = vxor.u32 %v10494_v44, %v10490_v21 (stack48)
        %v11328_v54 = vor.u32 %v11327_v61, %v11326_v55 (stack47)
        %v157130_v46 = vld [vmem:[#allocation61_spill] sm:$0xff] (stack84)
        %v11782_v50 = vadd.s32 %v157130_v46, %v157068_v28 (stack40)
        %vm9327_vm14 = vcmp.eq.f32.partialorder %v125414_v12, 0.0 (stack71)
        %v10101_v22 = vadd.s32 %v10098_v31, %v121564_v0 (stack40)
        %v10903_v53 = vor.u32 %v10902_v20, %v10901_v27 (stack47)
        %v125463_v26 = vadd.s32 %v157127_v34, %v157070_v38 (stack40)
        %v9695_v23 = vand.u32.u16 65535, %v9694_v7 (stack52)
        %v10498_v21 = vadd.s32 %v10495_v29, %v10490_v21 (stack40)
        %v10500_v24 = vshll.u32 %v10495_v29, 26 (stack45)
        %v10501_v9 = vshrl.u32 %v10495_v29, 6 (stack46)
        %v120508_v41 = vpop.eup %120507 (stack73)
        %v10093_v56 = vadd.s32 %v10089_v56, %v121569_v1 (stack40)
        %v10105_v25 = vadd.s32 4, %v10101_v22 (stack40)
        %v10904_v40 = vxor.u32 %v10903_v53, %v10899_v32 (stack48)
        %v11329_v44 = vxor.u32 %v11328_v54, %v11324_v6 (stack48)
        %v9324_v55 = vmul.f32 %v120508_v41, %v125414_v12 (stack74)
        %v9328_v61 = vand.u32 2147483648, %v125414_v12 (stack72)
        %v119794_v31 = vadd.low.f32.bf16 -1.0, %v9695_v23 (stack53)
        %v10502_v27 = vor.u32 %v10501_v9, %v10500_v24 (stack47)
        %v10109_v20 = vadd.s32 %v10105_v25, %v10093_v56 (stack40)
        %v10111_v7 = vshll.u32 %v10105_v25, 13 (stack45)
        %v10112_v29 = vshrl.u32 %v10105_v25, 19 (stack46)
        %v10907_v32 = vadd.s32 %v10904_v40, %v10899_v32 (stack40)
        %v9326_v54 = vsel /*vm=*/%vm9325_vm13, /*on_true_vy=*/%v125414_v12, /*on_false_vx=*/%v9324_v55 (stack75)
        %v9704_v22 = vmul.f32 2.0, %v119794_v31 (stack54)
        %v10503_v53 = vxor.u32 %v10502_v27, %v10498_v21 (stack48)
        %v10909_v23 = vshll.u32 %v10904_v40, 29 (stack45)
        %v9329_v24 = vsel /*vm=*/%vm9327_vm14, /*on_true_vy=*/%v9328_v61, /*on_false_vx=*/%v9326_v54 (stack76)
        %v10113_v9 = vor.u32 %v10112_v29, %v10111_v7 (stack47)
        %v10910_v41 = vshrl.u32 %v10904_v40, 3 (stack46)
        %v11332_v6 = vadd.s32 %v11329_v44, %v11324_v6 (stack40)
        %v9332_v56 = vadd.f32 -3.0, %v9329_v24 (stack53)
        %v9708_v25 = vadd.f32 -0.99609375, %v9704_v22 (stack53)
        %v10506_v21 = vadd.s32 %v10503_v53, %v10498_v21 (stack40)
        %v10512_v40 = vshll.u32 %v10503_v53, 6 (stack45)
        %v9317_v55 = vsel /*vm=*/%vm9280_vm11, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v10114_v61 = vxor.u32 %v10113_v9, %v10109_v20 (stack48)
        %v10513_v31 = vshrl.u32 %v10503_v53, 26 (stack46)
        %v10911_v27 = vor.u32 %v10910_v41, %v10909_v23 (stack47)
        %v125479_v11 = vsel /*vm=*/%vm9280_vm11, /*on_true_vy=*/%v125452_v11, /*on_false_vx=*/%v9332_v56 (stack44)
        %v125481_v7 = vmax.f32 %v9708_v25, -0.99609375 (stack55)
        %v11334_v29 = vshll.u32 %v11329_v44, 26 (stack45)
        %v11335_v44 = vshrl.u32 %v11329_v44, 6 (stack46)
        %v9340_v54 = vmul.f32 %v125479_v11, %v9317_v55 (stack54)
        %v10117_v20 = vadd.s32 %v10114_v61, %v10109_v20 (stack40)
        %v10119_v22 = vshll.u32 %v10114_v61, 15 (stack45)
        %v10120_v53 = vshrl.u32 %v10114_v61, 17 (stack46)
        %v9724_v23 = vxor.u32 2147483648, %v125481_v7 (stack56)
        %v10514_v24 = vor.u32 %v10513_v31, %v10512_v40 (stack47)
        %v11786_v9 = vadd.s32 1, %v11782_v50 (stack40)
        %v125487_v41 = vadd.s32 %v125428_v10, %v121569_v1 (stack40)
        %v9305_v56 = vsel /*vm=*/%vm9280_vm11, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v9344_v8 = vadd.f32 %v9340_v54, %v125449_v8 (stack53)
        %v10121_v25 = vor.u32 %v10120_v53, %v10119_v22 (stack47)
        %v10912_v40 = vxor.u32 %v10911_v27, %v10907_v32 (stack48)
        %v9309_v55 = vsel /*vm=*/%vm9280_vm11, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v9727_v61 = vmul.f32 %v9724_v23, %v125481_v7 (stack54)
        %v10515_v31 = vxor.u32 %v10514_v24, %v10506_v21 (stack48)
        %vm11772_vm15 = vcmp.lt.u32.totalorder %v125428_v10, %v125333_v30 (stack43)
        %v11790_v50 = vsel /*vm=*/%vm11777_vm10, /*on_true_vy=*/%v11786_v9, /*on_false_vx=*/%v11782_v50 (stack44)
        %v9348_v27 = vmul.f32 %v9344_v8, %v125479_v11 (stack54)
        %v10122_v54 = vxor.u32 %v10121_v25, %v10117_v20 (stack48)
        %v10915_v32 = vadd.s32 %v10912_v40, %v10907_v32 (stack40)
        %v11336_v29 = vor.u32 %v11335_v44, %v11334_v29 (stack47)
        %v9729_v44 = vadd.f32 1.0, %v9727_v61 (stack57)
        %v10518_v22 = vadd.s32 %v10515_v31, %v121569_v1 (stack40)
        %v10917_v53 = vshll.u32 %v10912_v40, 16 (stack45)
        %v11813_v23 = vshll.u32 %v125487_v41, 13 (stack45)
        %v9352_v24 = vadd.f32 %v9348_v27, %v9309_v55 (stack53)
        %v10125_v20 = vadd.s32 %v10122_v54, %v10117_v20 (stack40)
        %v10127_v9 = vshll.u32 %v10122_v54, 26 (stack45)
        %v10128_v8 = vshrl.u32 %v10122_v54, 6 (stack46)
        %120509 = vlog2.f32 %v9729_v44 (stack58)
        %v9732_v25 = vmul.f32 -0.5, %v9727_v61 (stack59)
        %v10510_v21 = vadd.s32 %v10506_v21, %v121574_v2 (stack40)
        %v10522_v55 = vadd.s32 3, %v10518_v22 (stack40)
        %v9356_v31 = vmul.f32 %v9352_v24, %v125479_v11 (stack54)
        %v10129_v27 = vor.u32 %v10128_v8, %v10127_v9 (stack47)
        %v10918_v40 = vshrl.u32 %v10912_v40, 16 (stack46)
        %v11337_v54 = vxor.u32 %v11336_v29, %v11332_v6 (stack48)
        %v9735_v29 = vand.u32 2147483647, %v9727_v61 (stack60)
        %v10526_v44 = vadd.s32 %v10522_v55, %v10510_v21 (stack40)
        %v10528_v22 = vshll.u32 %v10522_v55, 17 (stack45)
        %v10529_v24 = vshrl.u32 %v10522_v55, 15 (stack46)
        %v9360_v56 = vadd.f32 %v9356_v31, %v9305_v56 (stack53)
        %v10130_v9 = vxor.u32 %v10129_v27, %v10125_v20 (stack48)
        %v10919_v53 = vor.u32 %v10918_v40, %v10917_v53 (stack47)
        %v11340_v6 = vadd.s32 %v11337_v54, %v11332_v6 (stack40)
        %v10530_v8 = vor.u32 %v10529_v24, %v10528_v22 (stack47)
        %v11346_v21 = vshll.u32 %v11337_v54, 6 (stack45)
        %v11347_v55 = vshrl.u32 %v11337_v54, 26 (stack46)
        %v11794_v31 = vadd.s32 1, %v11790_v50 (stack40)
        %v9364_v27 = vmul.f32 %v9360_v56, %v125479_v11 (stack54)
        %v10133_v20 = vadd.s32 %v10130_v9, %v10125_v20 (stack40)
        %v10139_v40 = vshll.u32 %v10130_v9, 6 (stack45)
        %v10140_v54 = vshrl.u32 %v10130_v9, 26 (stack46)
        %v9733_v25 = vadd.f32 1.0, %v9732_v25 (stack61)
        %v10531_v22 = vxor.u32 %v10530_v8, %v10526_v44 (stack48)
        %v10920_v24 = vxor.u32 %v10919_v53, %v10915_v32 (stack48)
        %v11348_v56 = vor.u32 %v11347_v55, %v11346_v21 (stack47)
        %v9368_v60 = vadd.f32 %v9364_v27, %v125444_v60 (stack53)
        %vm125509_vm0 = vcmp.lt.f32.partialorder %v9735_v29, 0.0004427343 (stack62)
        %v10141_v9 = vor.u32 %v10140_v54, %v10139_v40 (stack47)
        %v11798_v30 = vsel /*vm=*/%vm11772_vm15, /*on_true_vy=*/%v11794_v31, /*on_false_vx=*/%v11790_v50 (stack44)
        %v10534_v10 = vadd.s32 %v10531_v22, %v10526_v44 (stack40)
        %v10536_v50 = vshll.u32 %v10531_v22, 29 (stack45)
        %v10537_v44 = vshrl.u32 %v10531_v22, 3 (stack46)
        %v10923_v32 = vadd.s32 %v10920_v24, %v10915_v32 (stack40)
        %v9372_v53 = vmul.f32 %v9368_v60, %v125479_v11 (stack54)
        %v10142_v8 = vxor.u32 %v10141_v9, %v10133_v20 (stack48)
        %v10929_v21 = vshll.u32 %v10920_v24, 24 (stack45)
        %v10930_v55 = vshrl.u32 %v10920_v24, 8 (stack46)
        %v9734_v61 = vmul.f32 %v9733_v25, %v9727_v61 (stack63)
        %v10538_v31 = vor.u32 %v10537_v44, %v10536_v50 (stack47)
        %v11349_v27 = vxor.u32 %v11348_v56, %v11340_v6 (stack48)
        %v11803_v40 = vadd.s32 %v11798_v30, %v121574_v2 (stack40)
        %v9376_v42 = vadd.f32 %v9372_v53, %v125438_v42 (stack53)
        %v10145_v54 = vadd.s32 %v10142_v8, %v121574_v2 (stack40)
        %v10931_v25 = vor.u32 %v10930_v55, %v10929_v21 (stack47)
        %v11814_v22 = vshrl.u32 %v125487_v41, 19 (stack46)
        %v10137_v20 = vadd.s32 %v10133_v20, %v121564_v0 (stack40)
        %v10539_v24 = vxor.u32 %v10538_v31, %v10534_v10 (stack48)
        %v11352_v56 = vadd.s32 %v11349_v27, %v121564_v0 (stack40)
        %v11811_v41 = vadd.s32 %v125487_v41, %v11803_v40 (stack40)
        %v120510_v60 = vpop.eup %120509 (stack64)
        %v9380_v9 = vmul.f32 %v9376_v42, %v125479_v11 (stack54)
        %v10149_v30 = vadd.s32 5, %v10145_v54 (stack40)
        %v10932_v50 = vxor.u32 %v10931_v25, %v10923_v32 (stack48)
        %v11815_v23 = vor.u32 %v11814_v22, %v11813_v23 (stack47)
        %v9731_v44 = vmul.f32 0.6931472, %v120510_v60 (stack65)
        %v10542_v10 = vadd.s32 %v10539_v24, %v10534_v10 (stack40)
        %v10544_v53 = vshll.u32 %v10539_v24, 16 (stack45)
        %v10545_v8 = vshrl.u32 %v10539_v24, 16 (stack46)
        %v9384_v43 = vadd.f32 %v9380_v9, %v125433_v43 (stack53)
        %v10151_v21 = vxor.u32 %v10149_v30, %v10137_v20 (stack48)
        %v11344_v6 = vadd.s32 %v11340_v6, %v121569_v1 (stack40)
        %v11356_v55 = vadd.s32 1, %v11352_v56 (stack40)
        %v9737_v29 = vsel /*vm=*/%vm125509_vm0, /*on_true_vy=*/%v9734_v61, /*on_false_vx=*/%v9731_v44 (stack66)
        %v10546_v61 = vor.u32 %v10545_v8, %v10544_v53 (stack47)
        %v10935_v31 = vadd.s32 %v10932_v50, %v121574_v2 (stack40)
        %v11816_v27 = vxor.u32 %v11815_v23, %v11811_v41 (stack48)
        %v9388_v40 = vmul.f32 %v9384_v43, %v125479_v11 (stack54)
        %v125531_v42 = vxor.u32 2147483648, %v9737_v29 (stack56)
        %v9253_v54 = vand.u32 2147483647, %v125364_v52 (stack77)
        %v9289_v25 = vsel /*vm=*/%vm9280_vm11, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v10547_v22 = vxor.u32 %v10546_v61, %v10542_v10 (stack48)
        %v11360_v20 = vadd.s32 %v11356_v55, %v11344_v6 (stack40)
        %v9392_v24 = vadd.f32 %v9388_v40, %v9289_v25 (stack53)
        %120511 = vrsqrt.f32 %v125531_v42 (stack67)
        %v10152_v56 = vand.u32.u8 255, %v10151_v21 (stack49)
        %v10550_v60 = vadd.s32 %v10547_v22, %v10542_v10 (stack40)
        %v10939_v9 = vadd.s32 2, %v10935_v31 (stack40)
        %v9261_v30 = vmul.f32 inf, %v125364_v52 (stack54)
        %v9396_v11 = vmul.f32 %v9392_v24, %v125479_v11 (stack54)
        %v11362_v50 = vshll.u32 %v11356_v55, 17 (stack45)
        %v11363_v23 = vshrl.u32 %v11356_v55, 15 (stack46)
        %vm125540_vm1 = vcmp.eq.f32.partialorder %v9253_v54, 1.0 (stack68)
        %v9285_v12 = vsel /*vm=*/%vm9280_vm11, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v9714_v10 = vand.u32 2147483647, %v125481_v7 (stack77)
        %v10927_v32 = vadd.s32 %v10923_v32, %v121564_v0 (stack40)
        %v9400_v53 = vadd.f32 %v9396_v11, %v9285_v12 (stack53)
        %v125550_v8 = vadd.f32 -2.5, %v125531_v42 (stack53)
        %v10554_v43 = vadd.s32 %v10550_v60, %v121569_v1 (stack40)
        %v125555_v21 = vadd.s32 %v125463_v26, %v122657_v58 (stack40)
        %v10153_v6 = vand.u32 65535, %v10152_v56 (stack50)
        %v10556_v55 = vshll.u32 %v10547_v22, 24 (stack45)
        %v10557_v29 = vshrl.u32 %v10547_v22, 8 (stack46)
        %v10943_v61 = vadd.s32 %v10939_v9, %v10927_v32 (stack40)
        %v9404_v52 = vmul.f32 %v9400_v53, %v125364_v52 (stack54)
        %v10945_v31 = vshll.u32 %v10939_v9, 13 (stack45)
        %v10946_v40 = vshrl.u32 %v10939_v9, 19 (stack46)
        %v11364_v54 = vor.u32 %v11363_v23, %v11362_v50 (stack47)
        %vm9786_vm2 = vcmp.eq.f32.partialorder %v125531_v42, inf (stack70)
        %v10154_v25 = vshrl.u32 %v10153_v6, 1 (stack51)
        %v10558_v22 = vor.u32 %v10557_v29, %v10556_v55 (stack47)
        %v11819_v41 = vadd.s32 %v11816_v27, %v11811_v41 (stack40)
        %v11821_v24 = vshll.u32 %v11816_v27, 15 (stack45)
        %v9408_v56 = vsel /*vm=*/%vm125540_vm1, /*on_true_vy=*/%v9261_v30, /*on_false_vx=*/%v9404_v52 (stack44)
        %vm9788_vm3 = vcmp.eq.f32.partialorder %v125531_v42, 0.0 (stack71)
        %v10947_v9 = vor.u32 %v10946_v40, %v10945_v31 (stack47)
        %v11365_v30 = vxor.u32 %v11364_v54, %v11360_v20 (stack48)
        %v11822_v27 = vshrl.u32 %v11816_v27, 17 (stack46)
        %v9412_v11 = vmul.f32 1.4140625, %v9408_v56 (stack54)
        %vm9741_vm4 = vcmp.lt.f32.partialorder %v125531_v42, 5.0 (stack68)
        %v10155_v50 = vor.u32 16256, %v10154_v25 (stack47)
        %v10559_v60 = vxor.u32 %v10558_v22, %v10550_v60 (stack48)
        %vm12238_vm5 = vcmp.lt.u32.totalorder %v125463_v26, %v157070_v38 (stack43)
        %v10948_v23 = vxor.u32 %v10947_v9, %v10943_v61 (stack48)
        %v11368_v20 = vadd.s32 %v11365_v30, %v11360_v20 (stack40)
        %v11370_v44 = vshll.u32 %v11365_v30, 29 (stack45)
        %v11371_v12 = vshrl.u32 %v11365_v30, 3 (stack46)
        %v9415_v32 = vpack.c.bf16 %v156663_v45, %v9412_v11 (stack81)
        %v10156_v53 = vand.u32.u16 65535, %v10155_v50 (stack52)
        %v10562_v6 = vadd.s32 %v10559_v60, %v121564_v0 (stack40)
        %v11823_v55 = vor.u32 %v11822_v27, %v11821_v24 (stack47)
        %v10951_v29 = vadd.s32 %v10948_v23, %v10943_v61 (stack40)
        %v10953_v61 = vshll.u32 %v10948_v23, 15 (stack45)
        %v10954_v52 = vshrl.u32 %v10948_v23, 17 (stack46)
        %v11372_v31 = vor.u32 %v11371_v12, %v11370_v44 (stack47)
        %v120512_v40 = vpop.eup %120511 (stack73)
        %119793 = vst [vmem:[%s123356_s30 + $0x108] sm:$0xf] /*vst_source=*/%v9415_v32 (stack83)
        %v119796_v54 = vadd.low.f32.bf16 -1.0, %v10156_v53 (stack53)
        %v10566_v25 = vadd.s32 4, %v10562_v6 (stack40)
        %v125568_v22 = vxor.u32 %v11823_v55, %v11819_v41 (stack48)
        %v125572_v24 = vadd.s32 %v157130_v46, %v157076_v35 (stack40)
        %v9785_v56 = vmul.f32 %v120512_v40, %v125531_v42 (stack74)
        %v9789_v9 = vand.u32 2147483648, %v125531_v42 (stack72)
        %v10955_v30 = vor.u32 %v10954_v52, %v10953_v61 (stack47)
        %v11373_v27 = vxor.u32 %v11372_v31, %v11368_v20 (stack48)
        %v10165_v11 = vmul.f32 2.0, %v119796_v54 (stack54)
        %v10570_v43 = vadd.s32 %v10566_v25, %v10554_v43 (stack40)
        %v10572_v50 = vshll.u32 %v10566_v25, 13 (stack45)
        %v10573_v60 = vshrl.u32 %v10566_v25, 19 (stack46)
        %v9787_v23 = vsel /*vm=*/%vm9786_vm2, /*on_true_vy=*/%v125531_v42, /*on_false_vx=*/%v9785_v56 (stack75)
        %v10956_v44 = vxor.u32 %v10955_v30, %v10951_v29 (stack48)
        %v11376_v20 = vadd.s32 %v11373_v27, %v11368_v20 (stack40)
        %v11378_v12 = vshll.u32 %v11373_v27, 16 (stack45)
        %v9790_v32 = vsel /*vm=*/%vm9788_vm3, /*on_true_vy=*/%v9789_v9, /*on_false_vx=*/%v9787_v23 (stack76)
        %v10169_v53 = vadd.f32 -0.99609375, %v10165_v11 (stack53)
        %v10574_v6 = vor.u32 %v10573_v60, %v10572_v50 (stack47)
        %v11379_v55 = vshrl.u32 %v11373_v27, 16 (stack46)
        %v9793_v61 = vadd.f32 -3.0, %v9790_v32 (stack53)
        %v10959_v29 = vadd.s32 %v10956_v44, %v10951_v29 (stack40)
        %v10961_v52 = vshll.u32 %v10956_v44, 26 (stack45)
        %v10962_v31 = vshrl.u32 %v10956_v44, 6 (stack46)
        %v125581_v40 = vmax.f32 %v10169_v53, -0.99609375 (stack55)
        %v10575_v54 = vxor.u32 %v10574_v6, %v10570_v43 (stack48)
        %v11380_v25 = vor.u32 %v11379_v55, %v11378_v12 (stack47)
        %v125584_v41 = vadd.s32 %v125568_v22, %v11819_v41 (stack40)
        %v125589_v56 = vsel /*vm=*/%vm9741_vm4, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v9778_v9 = vsel /*vm=*/%vm9741_vm4, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v125597_v8 = vsel /*vm=*/%vm9741_vm4, /*on_true_vy=*/%v125550_v8, /*on_false_vx=*/%v9793_v61 (stack44)
        %v10963_v30 = vor.u32 %v10962_v31, %v10961_v52 (stack47)
        %v125602_v27 = vsel /*vm=*/%vm9741_vm4, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v9774_v11 = vsel /*vm=*/%vm9741_vm4, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v9801_v50 = vmul.f32 %v125597_v8, %v9778_v9 (stack54)
        %v10185_v60 = vxor.u32 2147483648, %v125581_v40 (stack56)
        %v10578_v43 = vadd.s32 %v10575_v54, %v10570_v43 (stack40)
        %v10580_v23 = vshll.u32 %v10575_v54, 15 (stack45)
        %v10581_v44 = vshrl.u32 %v10575_v54, 17 (stack46)
        %v10964_v12 = vxor.u32 %v10963_v30, %v10959_v29 (stack48)
        %v9770_v32 = vsel /*vm=*/%vm9741_vm4, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v9805_v53 = vadd.f32 %v9801_v50, %v9774_v11 (stack53)
        %v10188_v6 = vmul.f32 %v10185_v60, %v125581_v40 (stack54)
        %v11381_v55 = vxor.u32 %v11380_v25, %v11376_v20 (stack48)
        %v10582_v61 = vor.u32 %v10581_v44, %v10580_v23 (stack47)
        %v10967_v29 = vadd.s32 %v10964_v12, %v10959_v29 (stack40)
        %v10973_v52 = vshll.u32 %v10964_v12, 6 (stack45)
        %v10974_v31 = vshrl.u32 %v10964_v12, 26 (stack46)
        %v9809_v54 = vmul.f32 %v9805_v53, %v125597_v8 (stack54)
        %v10190_v25 = vadd.f32 1.0, %v10188_v6 (stack57)
        %v10193_v9 = vmul.f32 -0.5, %v10188_v6 (stack59)
        %v11829_v30 = vshll.u32 %v125568_v22, 26 (stack45)
        %v10583_v11 = vxor.u32 %v10582_v61, %v10578_v43 (stack48)
        %v10975_v50 = vor.u32 %v10974_v31, %v10973_v52 (stack47)
        %v11384_v20 = vadd.s32 %v11381_v55, %v11376_v20 (stack40)
        %v11830_v22 = vshrl.u32 %v125568_v22, 6 (stack46)
        %v9762_v60 = vsel /*vm=*/%vm9741_vm4, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v9766_v23 = vsel /*vm=*/%vm9741_vm4, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v9813_v44 = vadd.f32 %v9809_v54, %v9770_v32 (stack53)
        %120513 = vlog2.f32 %v10190_v25 (stack58)
        %v10586_v43 = vadd.s32 %v10583_v11, %v10578_v43 (stack40)
        %v10588_v12 = vshll.u32 %v10583_v11, 26 (stack45)
        %v10589_v32 = vshrl.u32 %v10583_v11, 6 (stack46)
        %v10976_v53 = vxor.u32 %v10975_v50, %v10967_v29 (stack48)
        %v9817_v61 = vmul.f32 %v9813_v44, %v125597_v8 (stack54)
        %v10194_v52 = vadd.f32 1.0, %v10193_v9 (stack61)
        %v10196_v31 = vand.u32 2147483647, %v10188_v6 (stack60)
        %v11390_v54 = vshll.u32 %v11381_v55, 24 (stack45)
        %vm12233_vm6 = vcmp.lt.u32.totalorder %v125555_v21, %v125463_v26 (stack43)
        %v10590_v25 = vor.u32 %v10589_v32, %v10588_v12 (stack47)
        %v10979_v9 = vadd.s32 %v10976_v53, %v121569_v1 (stack40)
        %v11391_v55 = vshrl.u32 %v11381_v55, 8 (stack46)
        %v11831_v30 = vor.u32 %v11830_v22, %v11829_v30 (stack47)
        %v9821_v11 = vadd.f32 %v9817_v61, %v9766_v23 (stack53)
        %v10971_v29 = vadd.s32 %v10967_v29, %v121574_v2 (stack40)
        %v12247_v50 = vadd.s32 1, %v125572_v24 (stack40)
        %v125630_v22 = vadd.s32 %v125555_v21, %v121569_v1 (stack40)
        %v10591_v23 = vxor.u32 %v10590_v25, %v10586_v43 (stack48)
        %v10983_v44 = vadd.s32 3, %v10979_v9 (stack40)
        %v11392_v12 = vor.u32 %v11391_v55, %v11390_v54 (stack47)
        %v11832_v32 = vxor.u32 %v11831_v30, %v125584_v41 (stack48)
        %v9825_v53 = vmul.f32 %v9821_v11, %v125597_v8 (stack54)
        %v10195_v6 = vmul.f32 %v10194_v52, %v10188_v6 (stack63)
        %v12251_v24 = vsel /*vm=*/%vm12238_vm5, /*on_true_vy=*/%v12247_v50, /*on_false_vx=*/%v125572_v24 (stack44)
        %v125640_v61 = vadd.s32 %v157127_v34, %v157077_v51 (stack40)
        %vm125642_vm7 = vcmp.lt.f32.partialorder %v10196_v31, 0.0004427343 (stack62)
        %v10594_v43 = vadd.s32 %v10591_v23, %v10586_v43 (stack40)
        %v10600_v31 = vshll.u32 %v10591_v23, 6 (stack45)
        %v10601_v54 = vshrl.u32 %v10591_v23, 26 (stack46)
        %v10987_v25 = vadd.s32 %v10983_v44, %v10971_v29 (stack40)
        %v9829_v60 = vadd.f32 %v9825_v53, %v9762_v60 (stack53)
        %v10989_v9 = vshll.u32 %v10983_v44, 17 (stack45)
        %v10990_v55 = vshrl.u32 %v10983_v44, 15 (stack46)
        %v11393_v30 = vxor.u32 %v11392_v12, %v11384_v20 (stack48)
        %v10602_v11 = vor.u32 %v10601_v54, %v10600_v31 (stack47)
        %v11388_v20 = vadd.s32 %v11384_v20, %v121564_v0 (stack40)
        %v11835_v41 = vadd.s32 %v11832_v32, %v125584_v41 (stack40)
        %v11841_v29 = vshll.u32 %v11832_v32, 6 (stack45)
        %v9833_v50 = vmul.f32 %v9829_v60, %v125597_v8 (stack54)
        %v10991_v23 = vor.u32 %v10990_v55, %v10989_v9 (stack47)
        %v11396_v44 = vadd.s32 %v11393_v30, %v121574_v2 (stack40)
        %v11842_v12 = vshrl.u32 %v11832_v32, 26 (stack46)
        %v10603_v32 = vxor.u32 %v10602_v11, %v10594_v43 (stack48)
        %v12255_v53 = vadd.s32 1, %v12251_v24 (stack40)
        %v12274_v31 = vshll.u32 %v125630_v22, 13 (stack45)
        %v12275_v54 = vshrl.u32 %v125630_v22, 19 (stack46)
        %v9837_v27 = vadd.f32 %v9833_v50, %v125602_v27 (stack53)
        %v10992_v60 = vxor.u32 %v10991_v23, %v10987_v25 (stack48)
        %v11400_v9 = vadd.s32 2, %v11396_v44 (stack40)
        %v11843_v55 = vor.u32 %v11842_v12, %v11841_v29 (stack47)
        %v120514_v30 = vpop.eup %120513 (stack64)
        %v10598_v43 = vadd.s32 %v10594_v43, %v121564_v0 (stack40)
        %v10606_v11 = vadd.s32 %v10603_v32, %v121574_v2 (stack40)
        %v12259_v26 = vsel /*vm=*/%vm12233_vm6, /*on_true_vy=*/%v12255_v53, /*on_false_vx=*/%v12251_v24 (stack44)
        %vm12699_vm8 = vcmp.lt.u32.totalorder %v125640_v61, %v157077_v51 (stack43)
        %v9841_v21 = vmul.f32 %v9837_v27, %v125597_v8 (stack54)
        %v10192_v24 = vmul.f32 0.6931472, %v120514_v30 (stack65)
        %v10995_v25 = vadd.s32 %v10992_v60, %v10987_v25 (stack40)
        %v10997_v29 = vshll.u32 %v10992_v60, 29 (stack45)
        %v10610_v50 = vadd.s32 5, %v10606_v11 (stack40)
        %v10998_v23 = vshrl.u32 %v10992_v60, 3 (stack46)
        %v11404_v20 = vadd.s32 %v11400_v9, %v11388_v20 (stack40)
        %v11406_v44 = vshll.u32 %v11400_v9, 13 (stack45)
        %v9845_v56 = vadd.f32 %v9841_v21, %v125589_v56 (stack53)
        %v10198_v6 = vsel /*vm=*/%vm125642_vm7, /*on_true_vy=*/%v10195_v6, /*on_false_vx=*/%v10192_v24 (stack66)
        %v11407_v52 = vshrl.u32 %v11400_v9, 19 (stack46)
        %v11844_v12 = vxor.u32 %v11843_v55, %v11835_v41 (stack48)
        %v125664_v32 = vxor.u32 2147483648, %v10198_v6 (stack56)
        %v10612_v53 = vxor.u32 %v10610_v50, %v10598_v43 (stack48)
        %v10999_v27 = vor.u32 %v10998_v23, %v10997_v29 (stack47)
        %v9722_v60 = vmul.f32 inf, %v125481_v7 (stack54)
        %v9849_v9 = vmul.f32 %v9845_v56, %v125597_v8 (stack54)
        %v12704_v55 = vadd.s32 %v157130_v46, %v157078_v48 (stack40)
        %vm125672_vm9 = vcmp.eq.f32.partialorder %v9714_v10, 1.0 (stack68)
        %v9746_v30 = vsel /*vm=*/%vm9741_vm4, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v9750_v42 = vsel /*vm=*/%vm9741_vm4, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %vm10202_vm10 = vcmp.lt.f32.partialorder %v125664_v32, 5.0 (stack68)
        %120515 = vrsqrt.f32 %v125664_v32 (stack67)
        %v9853_v43 = vadd.f32 %v9849_v9, %v9750_v42 (stack53)
        %v10175_v11 = vand.u32 2147483647, %v125581_v40 (stack77)
        %v11408_v21 = vor.u32 %v11407_v52, %v11406_v44 (stack47)
        %v12276_v31 = vor.u32 %v12275_v54, %v12274_v31 (stack47)
        %v11000_v54 = vxor.u32 %v10999_v27, %v10995_v25 (stack48)
        %v11839_v41 = vadd.s32 %v11835_v41, %v121569_v1 (stack40)
        %v11847_v24 = vadd.s32 %v11844_v12, %v121564_v0 (stack40)
        %v12264_v26 = vadd.s32 %v12259_v26, %v121574_v2 (stack40)
        %v9857_v8 = vmul.f32 %v9853_v43, %v125597_v8 (stack54)
        %v125692_v29 = vsel /*vm=*/%vm10202_vm10, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v125695_v50 = vadd.f32 -2.5, %v125664_v32 (stack53)
        %v125699_v23 = vadd.s32 %v125640_v61, %v122657_v58 (stack40)
        %v125704_v44 = vsel /*vm=*/%vm10202_vm10, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v125709_v56 = vsel /*vm=*/%vm10202_vm10, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v10613_v6 = vand.u32.u8 255, %v10612_v53 (stack49)
        %v11003_v25 = vadd.s32 %v11000_v54, %v10995_v25 (stack40)
        %v9861_v52 = vadd.f32 %v9857_v8, %v9746_v30 (stack53)
        %v11005_v12 = vshll.u32 %v11000_v54, 16 (stack45)
        %v11006_v53 = vshrl.u32 %v11000_v54, 16 (stack46)
        %v11409_v27 = vxor.u32 %v11408_v21, %v11404_v20 (stack48)
        %v10614_v9 = vand.u32 65535, %v10613_v6 (stack50)
        %v11851_v30 = vadd.s32 1, %v11847_v24 (stack40)
        %v12272_v22 = vadd.s32 %v125630_v22, %v12264_v26 (stack40)
        %v12708_v42 = vadd.s32 1, %v12704_v55 (stack40)
        %v9865_v7 = vmul.f32 %v9861_v52, %v125481_v7 (stack54)
        %vm10247_vm11 = vcmp.eq.f32.partialorder %v125664_v32, inf (stack70)
        %v11007_v43 = vor.u32 %v11006_v53, %v11005_v12 (stack47)
        %v11412_v20 = vadd.s32 %v11409_v27, %v11404_v20 (stack40)
        %v11414_v21 = vshll.u32 %v11409_v27, 15 (stack45)
        %vm10249_vm12 = vcmp.eq.f32.partialorder %v125664_v32, 0.0 (stack71)
        %v10615_v54 = vshrl.u32 %v10614_v9, 1 (stack51)
        %v11415_v24 = vshrl.u32 %v11409_v27, 17 (stack46)
        %v11855_v41 = vadd.s32 %v11851_v30, %v11839_v41 (stack40)
        %v11857_v26 = vshll.u32 %v11851_v30, 17 (stack45)
        %vm12694_vm13 = vcmp.lt.u32.totalorder %v125699_v23, %v125640_v61 (stack43)
        %v9869_v60 = vsel /*vm=*/%vm125672_vm9, /*on_true_vy=*/%v9722_v60, /*on_false_vx=*/%v9865_v7 (stack44)
        %v11008_v10 = vxor.u32 %v11007_v43, %v11003_v25 (stack48)
        %v11858_v8 = vshrl.u32 %v11851_v30, 15 (stack46)
        %v12277_v31 = vxor.u32 %v12276_v31, %v12272_v22 (stack48)
        %v9873_v6 = vmul.f32 1.4140625, %v9869_v60 (stack54)
        %v10616_v52 = vor.u32 16256, %v10615_v54 (stack47)
        %v11416_v12 = vor.u32 %v11415_v24, %v11414_v21 (stack47)
        %v12712_v55 = vsel /*vm=*/%vm12699_vm8, /*on_true_vy=*/%v12708_v42, /*on_false_vx=*/%v12704_v55 (stack44)
        %v11011_v25 = vadd.s32 %v11008_v10, %v11003_v25 (stack40)
        %v11017_v53 = vshll.u32 %v11008_v10, 24 (stack45)
        %v11018_v27 = vshrl.u32 %v11008_v10, 8 (stack46)
        %v11859_v9 = vor.u32 %v11858_v8, %v11857_v26 (stack47)
        %v9876_v30 = vpack.c.bf16 %v156663_v45, %v9873_v6 (stack81)
        %v10617_v42 = vand.u32.u16 65535, %v10616_v52 (stack52)
        %v11417_v7 = vxor.u32 %v11416_v12, %v11412_v20 (stack48)
        %v125723_v22 = vadd.s32 %v12277_v31, %v12272_v22 (stack40)
        %v120516_v43 = vpop.eup %120515 (stack73)
        %v10250_v21 = vand.u32 2147483648, %v125664_v32 (stack72)
        %v11019_v54 = vor.u32 %v11018_v27, %v11017_v53 (stack47)
        %v11860_v24 = vxor.u32 %v11859_v9, %v11855_v41 (stack48)
        %v12282_v26 = vshll.u32 %v12277_v31, 15 (stack45)
        %119795 = vst [vmem:[%s123356_s30 + $0x188] sm:$0xf] /*vst_source=*/%v9876_v30 (stack83)
        %v10246_v60 = vmul.f32 %v120516_v43, %v125664_v32 (stack74)
        %v119798_v10 = vadd.low.f32.bf16 -1.0, %v10617_v42 (stack53)
        %v11420_v20 = vadd.s32 %v11417_v7, %v11412_v20 (stack40)
        %v11422_v8 = vshll.u32 %v11417_v7, 26 (stack45)
        %v11020_v6 = vxor.u32 %v11019_v54, %v11011_v25 (stack48)
        %v11423_v52 = vshrl.u32 %v11417_v7, 6 (stack46)
        %v11863_v41 = vadd.s32 %v11860_v24, %v11855_v41 (stack40)
        %v11865_v12 = vshll.u32 %v11860_v24, 29 (stack45)
        %v10248_v53 = vsel /*vm=*/%vm10247_vm11, /*on_true_vy=*/%v125664_v32, /*on_false_vx=*/%v10246_v60 (stack75)
        %v10626_v27 = vmul.f32 2.0, %v119798_v10 (stack54)
        %v11866_v9 = vshrl.u32 %v11860_v24, 3 (stack46)
        %v12283_v31 = vshrl.u32 %v12277_v31, 17 (stack46)
        %v10251_v30 = vsel /*vm=*/%vm10249_vm12, /*on_true_vy=*/%v10250_v21, /*on_false_vx=*/%v10248_v53 (stack76)
        %v11023_v42 = vadd.s32 %v11020_v6, %v121564_v0 (stack40)
        %v11424_v7 = vor.u32 %v11423_v52, %v11422_v8 (stack47)
        %v12716_v43 = vadd.s32 1, %v12712_v55 (stack40)
        %v10254_v21 = vadd.f32 -3.0, %v10251_v30 (stack53)
        %v10630_v54 = vadd.f32 -0.99609375, %v10626_v27 (stack53)
        %v11867_v24 = vor.u32 %v11866_v9, %v11865_v12 (stack47)
        %v12284_v26 = vor.u32 %v12283_v31, %v12282_v26 (stack47)
        %v11015_v25 = vadd.s32 %v11011_v25, %v121569_v1 (stack40)
        %v11027_v60 = vadd.s32 4, %v11023_v42 (stack40)
        %v11425_v10 = vxor.u32 %v11424_v7, %v11420_v20 (stack48)
        %v12720_v61 = vsel /*vm=*/%vm12694_vm13, /*on_true_vy=*/%v12716_v43, /*on_false_vx=*/%v12712_v55 (stack44)
        %v125741_v50 = vsel /*vm=*/%vm10202_vm10, /*on_true_vy=*/%v125695_v50, /*on_false_vx=*/%v10254_v21 (stack44)
        %v125743_v55 = vmax.f32 %v10630_v54, -0.99609375 (stack55)
        %v11868_v8 = vxor.u32 %v11867_v24, %v11863_v41 (stack48)
        %v12285_v6 = vxor.u32 %v12284_v26, %v125723_v22 (stack48)
        %v10262_v56 = vmul.f32 %v125741_v50, %v125709_v56 (stack54)
        %v11031_v52 = vadd.s32 %v11027_v60, %v11015_v25 (stack40)
        %v11033_v12 = vshll.u32 %v11027_v60, 13 (stack45)
        %v11034_v53 = vshrl.u32 %v11027_v60, 19 (stack46)
        %v10223_v27 = vsel /*vm=*/%vm10202_vm10, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v10235_v9 = vsel /*vm=*/%vm10202_vm10, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v10646_v31 = vxor.u32 2147483648, %v125743_v55 (stack56)
        %v11428_v20 = vadd.s32 %v11425_v10, %v11420_v20 (stack40)
        %v10266_v30 = vadd.f32 %v10262_v56, %v10235_v9 (stack53)
        %v11035_v42 = vor.u32 %v11034_v53, %v11033_v12 (stack47)
        %v11434_v7 = vshll.u32 %v11425_v10, 6 (stack45)
        %v11435_v43 = vshrl.u32 %v11425_v10, 26 (stack46)
        %v10227_v21 = vsel /*vm=*/%vm10202_vm10, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v10231_v54 = vsel /*vm=*/%vm10202_vm10, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v125762_v24 = vmul.f32 %v10646_v31, %v125743_v55 (stack54)
        %v11871_v41 = vadd.s32 %v11868_v8, %v11863_v41 (stack40)
        %v10270_v26 = vmul.f32 %v10266_v30, %v125741_v50 (stack54)
        %v11036_v25 = vxor.u32 %v11035_v42, %v11031_v52 (stack48)
        %v11436_v60 = vor.u32 %v11435_v43, %v11434_v7 (stack47)
        %v11873_v10 = vshll.u32 %v11868_v8, 16 (stack45)
        %v10651_v56 = vadd.f32 1.0, %v125762_v24 (stack57)
        %v10654_v12 = vmul.f32 -0.5, %v125762_v24 (stack59)
        %v11874_v8 = vshrl.u32 %v11868_v8, 16 (stack46)
        %v12729_v23 = vadd.s32 %v125699_v23, %v121569_v1 (stack40)
        %v10274_v53 = vadd.f32 %v10270_v26, %v10231_v54 (stack53)
        %v11039_v52 = vadd.s32 %v11036_v25, %v11031_v52 (stack40)
        %v11041_v9 = vshll.u32 %v11036_v25, 15 (stack45)
        %v11042_v31 = vshrl.u32 %v11036_v25, 17 (stack46)
        %120517 = vlog2.f32 %v10651_v56 (stack58)
        %v10657_v30 = vand.u32 2147483647, %v125762_v24 (stack60)
        %v11432_v42 = vadd.s32 %v11428_v20, %v121574_v2 (stack40)
        %v11437_v20 = vxor.u32 %v11436_v60, %v11428_v20 (stack48)
        %v10278_v7 = vmul.f32 %v10274_v53, %v125741_v50 (stack54)
        %v11043_v43 = vor.u32 %v11042_v31, %v11041_v9 (stack47)
        %v11875_v54 = vor.u32 %v11874_v8, %v11873_v10 (stack47)
        %v12288_v22 = vadd.s32 %v12285_v6, %v125723_v22 (stack40)
        %v10655_v26 = vadd.f32 1.0, %v10654_v12 (stack61)
        %v11440_v25 = vadd.s32 %v11437_v20, %v121569_v1 (stack40)
        %v12290_v60 = vshll.u32 %v12285_v6, 26 (stack45)
        %v12291_v6 = vshrl.u32 %v12285_v6, 6 (stack46)
        %v10282_v21 = vadd.f32 %v10278_v7, %v10227_v21 (stack53)
        %v11044_v10 = vxor.u32 %v11043_v43, %v11039_v52 (stack48)
        %v11876_v56 = vxor.u32 %v11875_v54, %v11871_v41 (stack48)
        %v12725_v61 = vadd.s32 %v12720_v61, %v121574_v2 (stack40)
        %v11444_v12 = vadd.s32 3, %v11440_v25 (stack40)
        %v12292_v8 = vor.u32 %v12291_v6, %v12290_v60 (stack47)
        %v12735_v53 = vshll.u32 %v12729_v23, 13 (stack45)
        %v12736_v9 = vshrl.u32 %v12729_v23, 19 (stack46)
        %v10286_v31 = vmul.f32 %v10282_v21, %v125741_v50 (stack54)
        %v11047_v52 = vadd.s32 %v11044_v10, %v11039_v52 (stack40)
        %v11049_v20 = vshll.u32 %v11044_v10, 26 (stack45)
        %v11050_v7 = vshrl.u32 %v11044_v10, 6 (stack46)
        %v11448_v42 = vadd.s32 %v11444_v12, %v11432_v42 (stack40)
        %v11450_v43 = vshll.u32 %v11444_v12, 17 (stack45)
        %v11451_v54 = vshrl.u32 %v11444_v12, 15 (stack46)
        %v11879_v41 = vadd.s32 %v11876_v56, %v11871_v41 (stack40)
        %v10290_v27 = vadd.f32 %v10286_v31, %v10223_v27 (stack53)
        %v11051_v25 = vor.u32 %v11050_v7, %v11049_v20 (stack47)
        %v11885_v60 = vshll.u32 %v11876_v56, 24 (stack45)
        %v11886_v6 = vshrl.u32 %v11876_v56, 8 (stack46)
        %vm125776_vm14 = vcmp.lt.f32.partialorder %v10657_v30, 0.0004427343 (stack62)
        %v11452_v21 = vor.u32 %v11451_v54, %v11450_v43 (stack47)
        %v12293_v10 = vxor.u32 %v12292_v8, %v12288_v22 (stack48)
        %v12733_v23 = vadd.s32 %v12729_v23, %v12725_v61 (stack40)
        %v10294_v56 = vmul.f32 %v10290_v27, %v125741_v50 (stack54)
        %v11052_v61 = vxor.u32 %v11051_v25, %v11047_v52 (stack48)
        %v11887_v12 = vor.u32 %v11886_v6, %v11885_v60 (stack47)
        %v12737_v8 = vor.u32 %v12736_v9, %v12735_v53 (stack47)
        %v11453_v53 = vxor.u32 %v11452_v21, %v11448_v42 (stack48)
        %v12296_v22 = vadd.s32 %v12293_v10, %v12288_v22 (stack40)
        %v12302_v9 = vshll.u32 %v12293_v10, 6 (stack45)
        %v12303_v31 = vshrl.u32 %v12293_v10, 26 (stack46)
        %v10298_v44 = vadd.f32 %v10294_v56, %v125704_v44 (stack53)
        %v11055_v52 = vadd.s32 %v11052_v61, %v11047_v52 (stack40)
        %v11061_v20 = vshll.u32 %v11052_v61, 6 (stack45)
        %v11062_v7 = vshrl.u32 %v11052_v61, 26 (stack46)
        %v11456_v42 = vadd.s32 %v11453_v53, %v11448_v42 (stack40)
        %v11458_v43 = vshll.u32 %v11453_v53, 29 (stack45)
        %v11459_v54 = vshrl.u32 %v11453_v53, 3 (stack46)
        %v11888_v27 = vxor.u32 %v11887_v12, %v11879_v41 (stack48)
        %v120518_v25 = vpop.eup %120517 (stack64)
        %v10302_v60 = vmul.f32 %v10298_v44, %v125741_v50 (stack54)
        %v10656_v24 = vmul.f32 %v10655_v26, %v125762_v24 (stack63)
        %v11063_v26 = vor.u32 %v11062_v7, %v11061_v20 (stack47)
        %v11883_v41 = vadd.s32 %v11879_v41, %v121564_v0 (stack40)
        %v10653_v6 = vmul.f32 0.6931472, %v120518_v25 (stack65)
        %v11460_v21 = vor.u32 %v11459_v54, %v11458_v43 (stack47)
        %v11891_v10 = vadd.s32 %v11888_v27, %v121574_v2 (stack40)
        %v12304_v56 = vor.u32 %v12303_v31, %v12302_v9 (stack47)
        %v10306_v29 = vadd.f32 %v10302_v60, %v125692_v29 (stack53)
        %v11064_v61 = vxor.u32 %v11063_v26, %v11055_v52 (stack48)
        %v12738_v12 = vxor.u32 %v12737_v8, %v12733_v23 (stack48)
        %v125789_v8 = vadd.s32 %v157127_v34, %v157079_v39 (stack40)
        %v10659_v30 = vsel /*vm=*/%vm125776_vm14, /*on_true_vy=*/%v10656_v24, /*on_false_vx=*/%v10653_v6 (stack66)
        %v11461_v53 = vxor.u32 %v11460_v21, %v11456_v42 (stack48)
        %v11895_v9 = vadd.s32 2, %v11891_v10 (stack40)
        %v12305_v31 = vxor.u32 %v12304_v56, %v12296_v22 (stack48)
        %v10211_v44 = vsel /*vm=*/%vm10202_vm10, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v10310_v20 = vmul.f32 %v10306_v29, %v125741_v50 (stack54)
        %v125797_v7 = vxor.u32 2147483648, %v10659_v30 (stack56)
        %v125799_v23 = vadd.s32 %v12738_v12, %v12733_v23 (stack40)
        %v11464_v42 = vadd.s32 %v11461_v53, %v11456_v42 (stack40)
        %v11466_v43 = vshll.u32 %v11461_v53, 16 (stack45)
        %v11467_v54 = vshrl.u32 %v11461_v53, 16 (stack46)
        %v11899_v27 = vadd.s32 %v11895_v9, %v11883_v41 (stack40)
        %v10314_v25 = vadd.f32 %v10310_v20, %v10211_v44 (stack53)
        %vm10663_vm15 = vcmp.lt.f32.partialorder %v125797_v7, 5.0 (stack68)
        %120519 = vrsqrt.f32 %v125797_v7 (stack67)
        %v10183_v60 = vmul.f32 inf, %v125581_v40 (stack54)
        %v11067_v24 = vadd.s32 %v11064_v61, %v121574_v2 (stack40)
        %v11468_v26 = vor.u32 %v11467_v54, %v11466_v43 (stack47)
        %vm125807_vm0 = vcmp.eq.f32.partialorder %v10175_v11, 1.0 (stack68)
        %v10207_v32 = vsel /*vm=*/%vm10202_vm10, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v10318_v50 = vmul.f32 %v10314_v25, %v125741_v50 (stack54)
        %v11059_v52 = vadd.s32 %v11055_v52, %v121564_v0 (stack40)
        %v125819_v41 = vsel /*vm=*/%vm10663_vm15, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v125822_v6 = vadd.f32 -2.5, %v125797_v7 (stack53)
        %v11469_v21 = vxor.u32 %v11468_v26, %v11464_v42 (stack48)
        %v12300_v22 = vadd.s32 %v12296_v22, %v121569_v1 (stack40)
        %v10322_v10 = vadd.f32 %v10318_v50, %v10207_v32 (stack53)
        %v125828_v56 = vsel /*vm=*/%vm10663_vm15, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v125833_v29 = vsel /*vm=*/%vm10663_vm15, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v125838_v61 = vsel /*vm=*/%vm10663_vm15, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v11071_v30 = vadd.s32 5, %v11067_v24 (stack40)
        %v11472_v53 = vadd.s32 %v11469_v21, %v11464_v42 (stack40)
        %v11478_v44 = vshll.u32 %v11469_v21, 24 (stack45)
        %v11479_v20 = vshrl.u32 %v11469_v21, 8 (stack46)
        %v10326_v40 = vmul.f32 %v10322_v10, %v125581_v40 (stack54)
        %v11901_v42 = vshll.u32 %v11895_v9, 13 (stack45)
        %v11902_v9 = vshrl.u32 %v11895_v9, 19 (stack46)
        %v12308_v31 = vadd.s32 %v12305_v31, %v121564_v0 (stack40)
        %vm10708_vm1 = vcmp.eq.f32.partialorder %v125797_v7, inf (stack70)
        %v11073_v43 = vxor.u32 %v11071_v30, %v11059_v52 (stack48)
        %v11480_v54 = vor.u32 %v11479_v20, %v11478_v44 (stack47)
        %v12743_v25 = vshll.u32 %v12738_v12, 15 (stack45)
        %v10330_v60 = vsel /*vm=*/%vm125807_vm0, /*on_true_vy=*/%v10183_v60, /*on_false_vx=*/%v10326_v40 (stack44)
        %vm10710_vm2 = vcmp.eq.f32.partialorder %v125797_v7, 0.0 (stack71)
        %v11903_v24 = vor.u32 %v11902_v9, %v11901_v42 (stack47)
        %v12312_v26 = vadd.s32 1, %v12308_v31 (stack40)
        %v12744_v12 = vshrl.u32 %v12738_v12, 17 (stack46)
        %v10334_v11 = vmul.f32 1.4140625, %v10330_v60 (stack54)
        %v10711_v32 = vand.u32 2147483648, %v125797_v7 (stack72)
        %v11074_v50 = vand.u32.u8 255, %v11073_v43 (stack49)
        %v11481_v52 = vxor.u32 %v11480_v54, %v11472_v53 (stack48)
        %v11904_v21 = vxor.u32 %v11903_v24, %v11899_v27 (stack48)
        %v12316_v22 = vadd.s32 %v12312_v26, %v12300_v22 (stack40)
        %v12318_v10 = vshll.u32 %v12312_v26, 17 (stack45)
        %v12319_v30 = vshrl.u32 %v12312_v26, 15 (stack46)
        %v10337_v44 = vpack.c.bf16 %v156663_v45, %v10334_v11 (stack81)
        %v11075_v20 = vand.u32 65535, %v11074_v50 (stack50)
        %v11484_v40 = vadd.s32 %v11481_v52, %v121564_v0 (stack40)
        %v12745_v42 = vor.u32 %v12744_v12, %v12743_v25 (stack47)
        %v11907_v27 = vadd.s32 %v11904_v21, %v11899_v27 (stack40)
        %v11909_v9 = vshll.u32 %v11904_v21, 15 (stack45)
        %v11910_v31 = vshrl.u32 %v11904_v21, 17 (stack46)
        %v12320_v43 = vor.u32 %v12319_v30, %v12318_v10 (stack47)
        %v120520_v54 = vpop.eup %120519 (stack73)
        %119797 = vst [vmem:[%s123356_s30 + $0x208] sm:$0xf] /*vst_source=*/%v10337_v44 (stack83)
        %v11076_v25 = vshrl.u32 %v11075_v20, 1 (stack51)
        %v11476_v53 = vadd.s32 %v11472_v53, %v121569_v1 (stack40)
        %v11488_v60 = vadd.s32 4, %v11484_v40 (stack40)
        %v12746_v24 = vxor.u32 %v12745_v42, %v125799_v23 (stack48)
        %v10707_v26 = vmul.f32 %v120520_v54, %v125797_v7 (stack74)
        %v11911_v12 = vor.u32 %v11910_v31, %v11909_v9 (stack47)
        %v12321_v11 = vxor.u32 %v12320_v43, %v12316_v22 (stack48)
        %vm13160_vm3 = vcmp.lt.u32.totalorder %v125789_v8, %v157079_v39 (stack43)
        %v11077_v50 = vor.u32 16256, %v11076_v25 (stack47)
        %v11492_v52 = vadd.s32 %v11488_v60, %v11476_v53 (stack40)
        %v11494_v21 = vshll.u32 %v11488_v60, 13 (stack45)
        %v11495_v10 = vshrl.u32 %v11488_v60, 19 (stack46)
        %v10709_v30 = vsel /*vm=*/%vm10708_vm1, /*on_true_vy=*/%v125797_v7, /*on_false_vx=*/%v10707_v26 (stack75)
        %v11912_v44 = vxor.u32 %v11911_v12, %v11907_v27 (stack48)
        %v12324_v22 = vadd.s32 %v12321_v11, %v12316_v22 (stack40)
        %v12326_v20 = vshll.u32 %v12321_v11, 29 (stack45)
        %v10712_v32 = vsel /*vm=*/%vm10710_vm2, /*on_true_vy=*/%v10711_v32, /*on_false_vx=*/%v10709_v30 (stack76)
        %v11078_v40 = vand.u32.u16 65535, %v11077_v50 (stack52)
        %v11496_v42 = vor.u32 %v11495_v10, %v11494_v21 (stack47)
        %v12327_v9 = vshrl.u32 %v12321_v11, 3 (stack46)
        %v10715_v31 = vadd.f32 -3.0, %v10712_v32 (stack53)
        %v11915_v27 = vadd.s32 %v11912_v44, %v11907_v27 (stack40)
        %v11917_v43 = vshll.u32 %v11912_v44, 26 (stack45)
        %v11918_v54 = vshrl.u32 %v11912_v44, 6 (stack46)
        %v119800_v25 = vadd.low.f32.bf16 -1.0, %v11078_v40 (stack53)
        %v11497_v53 = vxor.u32 %v11496_v42, %v11492_v52 (stack48)
        %v12328_v60 = vor.u32 %v12327_v9, %v12326_v20 (stack47)
        %v12749_v23 = vadd.s32 %v12746_v24, %v125799_v23 (stack40)
        %v10700_v26 = vsel /*vm=*/%vm10663_vm15, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v125867_v6 = vsel /*vm=*/%vm10663_vm15, /*on_true_vy=*/%v125822_v6, /*on_false_vx=*/%v10715_v31 (stack44)
        %v11919_v12 = vor.u32 %v11918_v54, %v11917_v43 (stack47)
        %v12751_v11 = vshll.u32 %v12746_v24, 26 (stack45)
        %v10723_v50 = vmul.f32 %v125867_v6, %v10700_v26 (stack54)
        %v11087_v21 = vmul.f32 2.0, %v119800_v25 (stack54)
        %v11500_v52 = vadd.s32 %v11497_v53, %v11492_v52 (stack40)
        %v11502_v10 = vshll.u32 %v11497_v53, 15 (stack45)
        %v11503_v30 = vshrl.u32 %v11497_v53, 17 (stack46)
        %v11920_v44 = vxor.u32 %v11919_v12, %v11915_v27 (stack48)
        %v12329_v20 = vxor.u32 %v12328_v60, %v12324_v22 (stack48)
        %v12752_v24 = vshrl.u32 %v12746_v24, 6 (stack46)
        %v10727_v61 = vadd.f32 %v10723_v50, %v125838_v61 (stack53)
        %v11091_v32 = vadd.f32 -0.99609375, %v11087_v21 (stack53)
        %v125873_v40 = vadd.s32 %v125789_v8, %v122657_v58 (stack40)
        %v125877_v42 = vadd.s32 %v157130_v46, %v157082_v49 (stack40)
        %v11504_v9 = vor.u32 %v11503_v30, %v11502_v10 (stack47)
        %v11923_v31 = vadd.s32 %v11920_v44, %v11915_v27 (stack40)
        %v11929_v27 = vshll.u32 %v11920_v44, 6 (stack45)
        %v11930_v43 = vshrl.u32 %v11920_v44, 26 (stack46)
        %v10731_v54 = vmul.f32 %v10727_v61, %v125867_v6 (stack54)
        %v125880_v25 = vmax.f32 %v11091_v32, -0.99609375 (stack55)
        %v12332_v22 = vadd.s32 %v12329_v20, %v12324_v22 (stack40)
        %v12334_v53 = vshll.u32 %v12329_v20, 16 (stack45)
        %v11505_v60 = vxor.u32 %v11504_v9, %v11500_v52 (stack48)
        %v11931_v26 = vor.u32 %v11930_v43, %v11929_v27 (stack47)
        %v12335_v12 = vshrl.u32 %v12329_v20, 16 (stack46)
        %v12753_v11 = vor.u32 %v12752_v24, %v12751_v11 (stack47)
        %v10680_v50 = vsel /*vm=*/%vm10663_vm15, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v10684_v21 = vsel /*vm=*/%vm10663_vm15, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v10735_v29 = vadd.f32 %v10731_v54, %v125833_v29 (stack53)
        %v11107_v10 = vxor.u32 2147483648, %v125880_v25 (stack56)
        %v11508_v52 = vadd.s32 %v11505_v60, %v11500_v52 (stack40)
        %v11510_v30 = vshll.u32 %v11505_v60, 26 (stack45)
        %v11511_v44 = vshrl.u32 %v11505_v60, 6 (stack46)
        %v11932_v20 = vxor.u32 %v11931_v26, %v11923_v31 (stack48)
        %v10688_v24 = vsel /*vm=*/%vm10663_vm15, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v10739_v61 = vmul.f32 %v10735_v29, %v125867_v6 (stack54)
        %v11110_v32 = vmul.f32 %v11107_v10, %v125880_v25 (stack54)
        %v12336_v9 = vor.u32 %v12335_v12, %v12334_v53 (stack47)
        %v11512_v27 = vor.u32 %v11511_v44, %v11510_v30 (stack47)
        %v11935_v43 = vadd.s32 %v11932_v20, %v121569_v1 (stack40)
        %v12754_v54 = vxor.u32 %v12753_v11, %v12749_v23 (stack48)
        %v125898_v53 = vadd.s32 %v125873_v40, %v121569_v1 (stack40)
        %v10743_v60 = vadd.f32 %v10739_v61, %v10688_v24 (stack53)
        %v11112_v26 = vadd.f32 1.0, %v11110_v32 (stack57)
        %v11115_v12 = vmul.f32 -0.5, %v11110_v32 (stack59)
        %v11927_v31 = vadd.s32 %v11923_v31, %v121574_v2 (stack40)
        %vm13155_vm4 = vcmp.lt.u32.totalorder %v125873_v40, %v125789_v8 (stack43)
        %v11513_v11 = vxor.u32 %v11512_v27, %v11508_v52 (stack48)
        %v11939_v29 = vadd.s32 3, %v11935_v43 (stack40)
        %v12337_v10 = vxor.u32 %v12336_v9, %v12332_v22 (stack48)
        %v12757_v23 = vadd.s32 %v12754_v54, %v12749_v23 (stack40)
        %v10747_v30 = vmul.f32 %v10743_v60, %v125867_v6 (stack54)
        %120521 = vlog2.f32 %v11112_v26 (stack58)
        %v11116_v44 = vadd.f32 1.0, %v11115_v12 (stack61)
        %v13169_v20 = vadd.s32 1, %v125877_v42 (stack40)
        %v11516_v52 = vadd.s32 %v11513_v11, %v11508_v52 (stack40)
        %v11522_v24 = vshll.u32 %v11513_v11, 6 (stack45)
        %v11523_v61 = vshrl.u32 %v11513_v11, 26 (stack46)
        %v11943_v9 = vadd.s32 %v11939_v29, %v11927_v31 (stack40)
        %v10751_v21 = vadd.f32 %v10747_v30, %v10684_v21 (stack53)
        %v11118_v27 = vand.u32 2147483647, %v11110_v32 (stack60)
        %v11945_v43 = vshll.u32 %v11939_v29, 17 (stack45)
        %v11946_v60 = vshrl.u32 %v11939_v29, 15 (stack46)
        %v11117_v32 = vmul.f32 %v11116_v44, %v11110_v32 (stack63)
        %v11524_v26 = vor.u32 %v11523_v61, %v11522_v24 (stack47)
        %v12340_v22 = vadd.s32 %v12337_v10, %v12332_v22 (stack40)
        %v12346_v12 = vshll.u32 %v12337_v10, 24 (stack45)
        %v10755_v31 = vmul.f32 %v10751_v21, %v125867_v6 (stack54)
        %v11520_v11 = vadd.s32 %v11516_v52, %v121564_v0 (stack40)
        %v11947_v29 = vor.u32 %v11946_v60, %v11945_v43 (stack47)
        %v12347_v10 = vshrl.u32 %v12337_v10, 8 (stack46)
        %v11525_v30 = vxor.u32 %v11524_v26, %v11516_v52 (stack48)
        %v12761_v44 = vadd.s32 %v12757_v23, %v121569_v1 (stack40)
        %v12763_v52 = vshll.u32 %v12754_v54, 6 (stack45)
        %v12764_v54 = vshrl.u32 %v12754_v54, 26 (stack46)
        %v10759_v50 = vadd.f32 %v10755_v31, %v10680_v50 (stack53)
        %v11948_v24 = vxor.u32 %v11947_v29, %v11943_v9 (stack48)
        %v12348_v61 = vor.u32 %v12347_v10, %v12346_v12 (stack47)
        %v13173_v42 = vsel /*vm=*/%vm13160_vm3, /*on_true_vy=*/%v13169_v20, /*on_false_vx=*/%v125877_v42 (stack44)
        %vm125912_vm5 = vcmp.lt.f32.partialorder %v11118_v27, 0.0004427343 (stack62)
        %v11528_v21 = vadd.s32 %v11525_v30, %v121574_v2 (stack40)
        %v12765_v27 = vor.u32 %v12764_v54, %v12763_v52 (stack47)
        %v13177_v43 = vadd.s32 1, %v13173_v42 (stack40)
        %v13196_v60 = vshll.u32 %v125898_v53, 13 (stack45)
        %v10763_v26 = vmul.f32 %v10759_v50, %v125867_v6 (stack54)
        %v11951_v9 = vadd.s32 %v11948_v24, %v11943_v9 (stack40)
        %v11953_v12 = vshll.u32 %v11948_v24, 29 (stack45)
        %v11954_v31 = vshrl.u32 %v11948_v24, 3 (stack46)
        %v11532_v29 = vadd.s32 5, %v11528_v21 (stack40)
        %v12349_v10 = vxor.u32 %v12348_v61, %v12340_v22 (stack48)
        %v12766_v23 = vxor.u32 %v12765_v27, %v12757_v23 (stack48)
        %v13181_v8 = vsel /*vm=*/%vm13155_vm4, /*on_true_vy=*/%v13177_v43, /*on_false_vx=*/%v13173_v42 (stack44)
        %v10767_v56 = vadd.f32 %v10763_v26, %v125828_v56 (stack53)
        %v11955_v40 = vor.u32 %v11954_v31, %v11953_v12 (stack47)
        %v13186_v30 = vadd.s32 %v13181_v8, %v121574_v2 (stack40)
        %v13197_v52 = vshrl.u32 %v125898_v53, 19 (stack46)
        %v11534_v11 = vxor.u32 %v11532_v29, %v11520_v11 (stack48)
        %v12352_v54 = vadd.s32 %v12349_v10, %v121574_v2 (stack40)
        %v12769_v50 = vadd.s32 %v12766_v23, %v121564_v0 (stack40)
        %v125929_v24 = vadd.s32 %v157127_v34, %v157083_v59 (stack40)
        %v10771_v61 = vmul.f32 %v10767_v56, %v125867_v6 (stack54)
        %v11956_v42 = vxor.u32 %v11955_v40, %v11951_v9 (stack48)
        %v12344_v22 = vadd.s32 %v12340_v22, %v121564_v0 (stack40)
        %v13194_v53 = vadd.s32 %v125898_v53, %v13186_v30 (stack40)
        %v120522_v21 = vpop.eup %120521 (stack64)
        %v11535_v27 = vand.u32.u8 255, %v11534_v11 (stack49)
        %v12356_v43 = vadd.s32 2, %v12352_v54 (stack40)
        %v12773_v26 = vadd.s32 1, %v12769_v50 (stack40)
        %v13198_v60 = vor.u32 %v13197_v52, %v13196_v60 (stack47)
        %v10775_v41 = vadd.f32 %v10771_v61, %v125819_v41 (stack53)
        %v11114_v12 = vmul.f32 0.6931472, %v120522_v21 (stack65)
        %v11959_v9 = vadd.s32 %v11956_v42, %v11951_v9 (stack40)
        %v11961_v31 = vshll.u32 %v11956_v42, 16 (stack45)
        %v11536_v29 = vand.u32 65535, %v11535_v27 (stack50)
        %v11962_v10 = vshrl.u32 %v11956_v42, 16 (stack46)
        %v12360_v23 = vadd.s32 %v12356_v43, %v12344_v22 (stack40)
        %v12362_v8 = vshll.u32 %v12356_v43, 13 (stack45)
        %v10779_v6 = vmul.f32 %v10775_v41, %v125867_v6 (stack54)
        %v11120_v32 = vsel /*vm=*/%vm125912_vm5, /*on_true_vy=*/%v11117_v32, /*on_false_vx=*/%v11114_v12 (stack66)
        %v12363_v20 = vshrl.u32 %v12356_v43, 19 (stack46)
        %v12777_v44 = vadd.s32 %v12773_v26, %v12761_v44 (stack40)
        %v10636_v56 = vand.u32 2147483647, %v125743_v55 (stack77)
        %v10668_v7 = vsel /*vm=*/%vm10663_vm15, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v125942_v40 = vxor.u32 2147483648, %v11120_v32 (stack56)
        %v11963_v30 = vor.u32 %v11962_v10, %v11961_v31 (stack47)
        %v10783_v52 = vadd.f32 %v10779_v6, %v10668_v7 (stack53)
        %v13199_v11 = vxor.u32 %v13198_v60, %v13194_v53 (stack48)
        %120523 = vrsqrt.f32 %v125942_v40 (stack67)
        %v11537_v54 = vshrl.u32 %v11536_v29, 1 (stack51)
        %v10644_v50 = vmul.f32 inf, %v125743_v55 (stack54)
        %v10787_v55 = vmul.f32 %v10783_v52, %v125743_v55 (stack54)
        %v12364_v61 = vor.u32 %v12363_v20, %v12362_v8 (stack47)
        %vm10639_vm6 = vcmp.eq.f32.partialorder %v10636_v56, 1.0 (stack68)
        %v11964_v42 = vxor.u32 %v11963_v30, %v11959_v9 (stack48)
        %v12779_v22 = vshll.u32 %v12773_v26, 17 (stack45)
        %v12780_v21 = vshrl.u32 %v12773_v26, 15 (stack46)
        %v10791_v27 = vsel /*vm=*/%vm10639_vm6, /*on_true_vy=*/%v10644_v50, /*on_false_vx=*/%v10787_v55 (stack44)
        %v11097_v43 = vand.u32 2147483647, %v125880_v25 (stack77)
        %v125949_v26 = vmul.f32 inf, %v125880_v25 (stack54)
        %v125953_v60 = vadd.s32 %v125929_v24, %v122657_v58 (stack40)
        %v10795_v41 = vmul.f32 1.4140625, %v10791_v27 (stack54)
        %vm11124_vm7 = vcmp.lt.f32.partialorder %v125942_v40, 5.0 (stack68)
        %v125957_v12 = vadd.f32 -2.5, %v125942_v40 (stack53)
        %v11538_v31 = vor.u32 16256, %v11537_v54 (stack47)
        %v11967_v9 = vadd.s32 %v11964_v42, %v11959_v9 (stack40)
        %v11973_v29 = vshll.u32 %v11964_v42, 24 (stack45)
        %v11974_v10 = vshrl.u32 %v11964_v42, 8 (stack46)
        %v12365_v8 = vxor.u32 %v12364_v61, %v12360_v23 (stack48)
        %v10798_v6 = vpack.c.bf16 %v156663_v45, %v10795_v41 (stack81)
        %v11539_v32 = vand.u32.u16 65535, %v11538_v31 (stack52)
        %v12781_v20 = vor.u32 %v12780_v21, %v12779_v22 (stack47)
        %v13202_v53 = vadd.s32 %v13199_v11, %v13194_v53 (stack40)
        %vm11169_vm8 = vcmp.eq.f32.partialorder %v125942_v40, inf (stack70)
        %v11975_v56 = vor.u32 %v11974_v10, %v11973_v29 (stack47)
        %v12368_v23 = vadd.s32 %v12365_v8, %v12360_v23 (stack40)
        %v12370_v7 = vshll.u32 %v12365_v8, 15 (stack45)
        %119799 = vst [vmem:[%s123356_s30 + $0x288] sm:$0xf] /*vst_source=*/%v10798_v6 (stack83)
        %v119802_v30 = vadd.low.f32.bf16 -1.0, %v11539_v32 (stack53)
        %v12371_v52 = vshrl.u32 %v12365_v8, 17 (stack46)
        %v12782_v54 = vxor.u32 %v12781_v20, %v12777_v44 (stack48)
        %v13204_v50 = vshll.u32 %v13199_v11, 15 (stack45)
        %v125965_v55 = vsel /*vm=*/%vm11124_vm7, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v11976_v61 = vxor.u32 %v11975_v56, %v11967_v9 (stack48)
        %v13205_v11 = vshrl.u32 %v13199_v11, 17 (stack46)
        %vm13621_vm9 = vcmp.lt.u32.totalorder %v125929_v24, %v157083_v59 (stack43)
        %v11548_v42 = vmul.f32 2.0, %v119802_v30 (stack54)
        %v12372_v22 = vor.u32 %v12371_v52, %v12370_v7 (stack47)
        %v12785_v44 = vadd.s32 %v12782_v54, %v12777_v44 (stack40)
        %v12787_v21 = vshll.u32 %v12782_v54, 29 (stack45)
        %v11979_v27 = vadd.s32 %v11976_v61, %v121564_v0 (stack40)
        %v12788_v41 = vshrl.u32 %v12782_v54, 3 (stack46)
        %v13206_v31 = vor.u32 %v13205_v11, %v13204_v50 (stack47)
        %v13626_v29 = vadd.s32 %v157130_v46, %v157084_v16 (stack40)
        %v11172_v10 = vand.u32 2147483648, %v125942_v40 (stack72)
        %v11552_v8 = vadd.f32 -0.99609375, %v11548_v42 (stack53)
        %v12373_v6 = vxor.u32 %v12372_v22, %v12368_v23 (stack48)
        %v125975_v32 = vadd.s32 %v157127_v34, %v157089_v17 (stack40)
        %v120524_v20 = vpop.eup %120523 (stack73)
        %v11971_v9 = vadd.s32 %v11967_v9, %v121569_v1 (stack40)
        %v11983_v56 = vadd.s32 4, %v11979_v27 (stack40)
        %v12789_v7 = vor.u32 %v12788_v41, %v12787_v21 (stack47)
        %v13207_v30 = vxor.u32 %v13206_v31, %v13202_v53 (stack48)
        %v11168_v52 = vmul.f32 %v120524_v20, %v125942_v40 (stack74)
        %v125979_v54 = vmax.f32 %v11552_v8, -0.99609375 (stack55)
        %v12376_v23 = vadd.s32 %v12373_v6, %v12368_v23 (stack40)
        %v12378_v50 = vshll.u32 %v12373_v6, 26 (stack45)
        %v11987_v61 = vadd.s32 %v11983_v56, %v11971_v9 (stack40)
        %v11989_v11 = vshll.u32 %v11983_v56, 13 (stack45)
        %v11990_v42 = vshrl.u32 %v11983_v56, 19 (stack46)
        %v12379_v22 = vshrl.u32 %v12373_v6, 6 (stack46)
        %v125984_v21 = vsel /*vm=*/%vm11124_vm7, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v11170_v27 = vsel /*vm=*/%vm11169_vm8, /*on_true_vy=*/%v125942_v40, /*on_false_vx=*/%v11168_v52 (stack75)
        %vm11171_vm10 = vcmp.eq.f32.partialorder %v125942_v40, 0.0 (stack71)
        %v11568_v41 = vxor.u32 2147483648, %v125979_v54 (stack56)
        %v11173_v31 = vsel /*vm=*/%vm11171_vm10, /*on_true_vy=*/%v11172_v10, /*on_false_vx=*/%v11170_v27 (stack76)
        %v11991_v10 = vor.u32 %v11990_v42, %v11989_v11 (stack47)
        %v12380_v8 = vor.u32 %v12379_v22, %v12378_v50 (stack47)
        %v12790_v6 = vxor.u32 %v12789_v7, %v12785_v44 (stack48)
        %v11149_v20 = vsel /*vm=*/%vm11124_vm7, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v11176_v9 = vadd.f32 -3.0, %v11173_v31 (stack53)
        %v125995_v56 = vmul.f32 %v11568_v41, %v125979_v54 (stack54)
        %v125997_v53 = vadd.s32 %v13207_v30, %v13202_v53 (stack40)
        %v11153_v7 = vsel /*vm=*/%vm11124_vm7, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v11992_v52 = vxor.u32 %v11991_v10, %v11987_v61 (stack48)
        %v12381_v50 = vxor.u32 %v12380_v8, %v12376_v23 (stack48)
        %v12793_v44 = vadd.s32 %v12790_v6, %v12785_v44 (stack40)
        %v11157_v11 = vsel /*vm=*/%vm11124_vm7, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v11161_v42 = vsel /*vm=*/%vm11124_vm7, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v126011_v12 = vsel /*vm=*/%vm11124_vm7, /*on_true_vy=*/%v125957_v12, /*on_false_vx=*/%v11176_v9 (stack44)
        %v11573_v22 = vadd.f32 1.0, %v125995_v56 (stack57)
        %v11184_v27 = vmul.f32 %v126011_v12, %v11161_v42 (stack54)
        %v11995_v61 = vadd.s32 %v11992_v52, %v11987_v61 (stack40)
        %v11997_v41 = vshll.u32 %v11992_v52, 15 (stack45)
        %v11998_v31 = vshrl.u32 %v11992_v52, 17 (stack46)
        %120525 = vlog2.f32 %v11573_v22 (stack58)
        %v12384_v23 = vadd.s32 %v12381_v50, %v12376_v23 (stack40)
        %v12795_v10 = vshll.u32 %v12790_v6, 16 (stack45)
        %v13630_v8 = vadd.s32 1, %v13626_v29 (stack40)
        %v11188_v9 = vadd.f32 %v11184_v27, %v11157_v11 (stack53)
        %v11999_v52 = vor.u32 %v11998_v31, %v11997_v41 (stack47)
        %v12390_v11 = vshll.u32 %v12381_v50, 6 (stack45)
        %v12391_v50 = vshrl.u32 %v12381_v50, 26 (stack46)
        %v11576_v42 = vmul.f32 -0.5, %v125995_v56 (stack59)
        %v11579_v22 = vand.u32 2147483647, %v125995_v56 (stack60)
        %v12796_v6 = vshrl.u32 %v12790_v6, 16 (stack46)
        %v13212_v27 = vshll.u32 %v13207_v30, 26 (stack45)
        %v11192_v41 = vmul.f32 %v11188_v9, %v126011_v12 (stack54)
        %v12000_v31 = vxor.u32 %v11999_v52, %v11995_v61 (stack48)
        %v12392_v9 = vor.u32 %v12391_v50, %v12390_v11 (stack47)
        %v13213_v30 = vshrl.u32 %v13207_v30, 6 (stack46)
        %v12797_v10 = vor.u32 %v12796_v6, %v12795_v10 (stack47)
        %vm13616_vm11 = vcmp.lt.u32.totalorder %v125953_v60, %v125929_v24 (stack43)
        %v13634_v29 = vsel /*vm=*/%vm13621_vm9, /*on_true_vy=*/%v13630_v8, /*on_false_vx=*/%v13626_v29 (stack44)
        %v126025_v8 = vadd.s32 %v125953_v60, %v121569_v1 (stack40)
        %v11196_v7 = vadd.f32 %v11192_v41, %v11153_v7 (stack53)
        %v12003_v61 = vadd.s32 %v12000_v31, %v11995_v61 (stack40)
        %v12005_v52 = vshll.u32 %v12000_v31, 26 (stack45)
        %v12006_v11 = vshrl.u32 %v12000_v31, 6 (stack46)
        %v12393_v50 = vxor.u32 %v12392_v9, %v12384_v23 (stack48)
        %v12798_v6 = vxor.u32 %v12797_v10, %v12793_v44 (stack48)
        %v13214_v27 = vor.u32 %v13213_v30, %v13212_v27 (stack47)
        %v13638_v41 = vadd.s32 1, %v13634_v29 (stack40)
        %v11200_v31 = vmul.f32 %v11196_v7, %v126011_v12 (stack54)
        %v11577_v42 = vadd.f32 1.0, %v11576_v42 (stack61)
        %vm126028_vm12 = vcmp.lt.f32.partialorder %v11579_v22, 0.0004427343 (stack62)
        %v12007_v9 = vor.u32 %v12006_v11, %v12005_v52 (stack47)
        %v12396_v30 = vadd.s32 %v12393_v50, %v121569_v1 (stack40)
        %v12801_v44 = vadd.s32 %v12798_v6, %v12793_v44 (stack40)
        %v12807_v10 = vshll.u32 %v12798_v6, 24 (stack45)
        %v12808_v7 = vshrl.u32 %v12798_v6, 8 (stack46)
        %v11204_v20 = vadd.f32 %v11200_v31, %v11149_v20 (stack53)
        %v12008_v52 = vxor.u32 %v12007_v9, %v12003_v61 (stack48)
        %v13215_v11 = vxor.u32 %v13214_v27, %v125997_v53 (stack48)
        %v13642_v24 = vsel /*vm=*/%vm13616_vm11, /*on_true_vy=*/%v13638_v41, /*on_false_vx=*/%v13634_v29 (stack44)
        %v12388_v60 = vadd.s32 %v12384_v23, %v121574_v2 (stack40)
        %v12400_v23 = vadd.s32 3, %v12396_v30 (stack40)
        %v12809_v29 = vor.u32 %v12808_v7, %v12807_v10 (stack47)
        %v13647_v50 = vadd.s32 %v13642_v24, %v121574_v2 (stack40)
        %v11208_v6 = vmul.f32 %v11204_v20, %v126011_v12 (stack54)
        %v12011_v61 = vadd.s32 %v12008_v52, %v12003_v61 (stack40)
        %v12017_v27 = vshll.u32 %v12008_v52, 6 (stack45)
        %v12018_v41 = vshrl.u32 %v12008_v52, 26 (stack46)
        %v12404_v31 = vadd.s32 %v12400_v23, %v12388_v60 (stack40)
        %v12406_v9 = vshll.u32 %v12400_v23, 17 (stack45)
        %v12407_v30 = vshrl.u32 %v12400_v23, 15 (stack46)
        %v12810_v10 = vxor.u32 %v12809_v29, %v12801_v44 (stack48)
        %v120526_v7 = vpop.eup %120525 (stack64)
        %v11212_v21 = vadd.f32 %v11208_v6, %v125984_v21 (stack53)
        %v11578_v56 = vmul.f32 %v11577_v42, %v125995_v56 (stack63)
        %v12019_v42 = vor.u32 %v12018_v41, %v12017_v27 (stack47)
        %v13218_v53 = vadd.s32 %v13215_v11, %v125997_v53 (stack40)
        %v11575_v20 = vmul.f32 0.6931472, %v120526_v7 (stack65)
        %v12408_v52 = vor.u32 %v12407_v30, %v12406_v9 (stack47)
        %v12813_v24 = vadd.s32 %v12810_v10, %v121574_v2 (stack40)
        %v13657_v60 = vshll.u32 %v126025_v8, 13 (stack45)
        %v11216_v23 = vmul.f32 %v11212_v21, %v126011_v12 (stack54)
        %v12020_v29 = vxor.u32 %v12019_v42, %v12011_v61 (stack48)
        %v12805_v44 = vadd.s32 %v12801_v44, %v121564_v0 (stack40)
        %v13658_v6 = vshrl.u32 %v126025_v8, 19 (stack46)
        %v11581_v22 = vsel /*vm=*/%vm126028_vm12, /*on_true_vy=*/%v11578_v56, /*on_false_vx=*/%v11575_v20 (stack66)
        %v12409_v27 = vxor.u32 %v12408_v52, %v12404_v31 (stack48)
        %v12817_v41 = vadd.s32 2, %v12813_v24 (stack40)
        %v13655_v8 = vadd.s32 %v126025_v8, %v13647_v50 (stack40)
        %v11220_v55 = vadd.f32 %v11216_v23, %v125965_v55 (stack53)
        %v126052_v50 = vxor.u32 2147483648, %v11581_v22 (stack56)
        %v13224_v9 = vshll.u32 %v13215_v11, 6 (stack45)
        %v13225_v11 = vshrl.u32 %v13215_v11, 26 (stack46)
        %v12412_v31 = vadd.s32 %v12409_v27, %v12404_v31 (stack40)
        %v12414_v30 = vshll.u32 %v12409_v27, 29 (stack45)
        %v12415_v10 = vshrl.u32 %v12409_v27, 3 (stack46)
        %v12821_v7 = vadd.s32 %v12817_v41, %v12805_v44 (stack40)
        %v11129_v21 = vsel /*vm=*/%vm11124_vm7, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v11133_v56 = vsel /*vm=*/%vm11124_vm7, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v11224_v42 = vmul.f32 %v11220_v55, %v126011_v12 (stack54)
        %120527 = vrsqrt.f32 %v126052_v50 (stack67)
        %v11137_v40 = vsel /*vm=*/%vm11124_vm7, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %vm11585_vm13 = vcmp.lt.f32.partialorder %v126052_v50, 5.0 (stack68)
        %v12023_v20 = vadd.s32 %v12020_v29, %v121574_v2 (stack40)
        %v12416_v52 = vor.u32 %v12415_v10, %v12414_v30 (stack47)
        %v11228_v24 = vadd.f32 %v11224_v42, %v11137_v40 (stack53)
        %v11558_v23 = vand.u32 2147483647, %v125979_v54 (stack77)
        %v13226_v29 = vor.u32 %v13225_v11, %v13224_v9 (stack47)
        %v13659_v60 = vor.u32 %v13658_v6, %v13657_v60 (stack47)
        %v12015_v61 = vadd.s32 %v12011_v61, %v121564_v0 (stack40)
        %v12417_v44 = vxor.u32 %v12416_v52, %v12412_v31 (stack48)
        %v13222_v6 = vadd.s32 %v13218_v53, %v121569_v1 (stack40)
        %v126072_v22 = vadd.s32 %v125975_v32, %v122657_v58 (stack40)
        %v11232_v27 = vmul.f32 %v11228_v24, %v126011_v12 (stack54)
        %v126078_v55 = vsel /*vm=*/%vm11585_vm13, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v126083_v9 = vsel /*vm=*/%vm11585_vm13, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v126086_v11 = vadd.f32 -2.5, %v126052_v50 (stack53)
        %vm126090_vm14 = vcmp.eq.f32.partialorder %v11097_v43, 1.0 (stack68)
        %v12027_v30 = vadd.s32 5, %v12023_v20 (stack40)
        %v12420_v31 = vadd.s32 %v12417_v44, %v12412_v31 (stack40)
        %v12422_v10 = vshll.u32 %v12417_v44, 16 (stack45)
        %v12423_v42 = vshrl.u32 %v12417_v44, 16 (stack46)
        %v11236_v56 = vadd.f32 %v11232_v27, %v11133_v56 (stack53)
        %v12823_v40 = vshll.u32 %v12817_v41, 13 (stack45)
        %v12824_v41 = vshrl.u32 %v12817_v41, 19 (stack46)
        %v13227_v53 = vxor.u32 %v13226_v29, %v13218_v53 (stack48)
        %vm11630_vm15 = vcmp.eq.f32.partialorder %v126052_v50, inf (stack70)
        %v11633_v20 = vand.u32 2147483648, %v126052_v50 (stack72)
        %v12029_v52 = vxor.u32 %v12027_v30, %v12015_v61 (stack48)
        %v12424_v24 = vor.u32 %v12423_v42, %v12422_v10 (stack47)
        %v13660_v29 = vxor.u32 %v13659_v60, %v13655_v8 (stack48)
        %v11240_v12 = vmul.f32 %v11236_v56, %v126011_v12 (stack54)
        %vm11632_vm0 = vcmp.eq.f32.partialorder %v126052_v50, 0.0 (stack71)
        %v12825_v60 = vor.u32 %v12824_v41, %v12823_v40 (stack47)
        %v13230_v61 = vadd.s32 %v13227_v53, %v121564_v0 (stack40)
        %vm14082_vm1 = vcmp.lt.u32.totalorder %v125975_v32, %v157089_v17 (stack43)
        %v12030_v44 = vand.u32.u8 255, %v12029_v52 (stack49)
        %v12425_v27 = vxor.u32 %v12424_v24, %v12420_v31 (stack48)
        %v13663_v8 = vadd.s32 %v13660_v29, %v13655_v8 (stack40)
        %v13665_v30 = vshll.u32 %v13660_v29, 15 (stack45)
        %v11244_v21 = vadd.f32 %v11240_v12, %v11129_v21 (stack53)
        %v12826_v10 = vxor.u32 %v12825_v60, %v12821_v7 (stack48)
        %v13234_v42 = vadd.s32 1, %v13230_v61 (stack40)
        %v13666_v56 = vshrl.u32 %v13660_v29, 17 (stack46)
        %v12031_v40 = vand.u32 65535, %v12030_v44 (stack50)
        %v12428_v31 = vadd.s32 %v12425_v27, %v12420_v31 (stack40)
        %v12434_v41 = vshll.u32 %v12425_v27, 24 (stack45)
        %v12435_v53 = vshrl.u32 %v12425_v27, 8 (stack46)
        %v11248_v25 = vmul.f32 %v11244_v21, %v125880_v25 (stack54)
        %v12829_v7 = vadd.s32 %v12826_v10, %v12821_v7 (stack40)
        %v12831_v52 = vshll.u32 %v12826_v10, 15 (stack45)
        %v12832_v24 = vshrl.u32 %v12826_v10, 17 (stack46)
        %v120528_v29 = vpop.eup %120527 (stack73)
        %v12032_v12 = vshrl.u32 %v12031_v40, 1 (stack51)
        %v12432_v60 = vadd.s32 %v12428_v31, %v121569_v1 (stack40)
        %v12436_v61 = vor.u32 %v12435_v53, %v12434_v41 (stack47)
        %v13238_v6 = vadd.s32 %v13234_v42, %v13222_v6 (stack40)
        %v11252_v26 = vsel /*vm=*/%vm126090_vm14, /*on_true_vy=*/%v125949_v26, /*on_false_vx=*/%v11248_v25 (stack44)
        %v11629_v43 = vmul.f32 %v120528_v29, %v126052_v50 (stack74)
        %v12833_v44 = vor.u32 %v12832_v24, %v12831_v52 (stack47)
        %v13240_v27 = vshll.u32 %v13234_v42, 17 (stack45)
        %v11256_v21 = vmul.f32 1.4140625, %v11252_v26 (stack54)
        %v12033_v10 = vor.u32 16256, %v12032_v12 (stack47)
        %v12437_v40 = vxor.u32 %v12436_v61, %v12428_v31 (stack48)
        %v13241_v42 = vshrl.u32 %v13234_v42, 15 (stack46)
        %v11631_v31 = vsel /*vm=*/%vm11630_vm15, /*on_true_vy=*/%v126052_v50, /*on_false_vx=*/%v11629_v43 (stack75)
        %v12834_v41 = vxor.u32 %v12833_v44, %v12829_v7 (stack48)
        %v13667_v30 = vor.u32 %v13666_v56, %v13665_v30 (stack47)
        %v14087_v56 = vadd.s32 %v157130_v46, %v157090_v62 (stack40)
        %v11259_v53 = vpack.c.bf16 %v156663_v45, %v11256_v21 (stack81)
        %v11634_v20 = vsel /*vm=*/%vm11632_vm0, /*on_true_vy=*/%v11633_v20, /*on_false_vx=*/%v11631_v31 (stack76)
        %v12034_v25 = vand.u32.u16 65535, %v12033_v10 (stack52)
        %v12440_v52 = vadd.s32 %v12437_v40, %v121564_v0 (stack40)
        %v11637_v24 = vadd.f32 -3.0, %v11634_v20 (stack53)
        %v12837_v7 = vadd.s32 %v12834_v41, %v12829_v7 (stack40)
        %v12839_v29 = vshll.u32 %v12834_v41, 26 (stack45)
        %v12840_v12 = vshrl.u32 %v12834_v41, 6 (stack46)
        %119801 = vst [vmem:[%s123356_s30 + $0x308] sm:$0xf] /*vst_source=*/%v11259_v53 (stack83)
        %v119808_v61 = vadd.low.f32.bf16 -1.0, %v12034_v25 (stack53)
        %v12444_v26 = vadd.s32 4, %v12440_v52 (stack40)
        %v13242_v43 = vor.u32 %v13241_v42, %v13240_v27 (stack47)
        %v13668_v44 = vxor.u32 %v13667_v30, %v13663_v8 (stack48)
        %v11618_v27 = vsel /*vm=*/%vm11585_vm13, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v11622_v21 = vsel /*vm=*/%vm11585_vm13, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v126126_v11 = vsel /*vm=*/%vm11585_vm13, /*on_true_vy=*/%v126086_v11, /*on_false_vx=*/%v11637_v24 (stack44)
        %v12841_v10 = vor.u32 %v12840_v12, %v12839_v29 (stack47)
        %v11645_v40 = vmul.f32 %v126126_v11, %v11622_v21 (stack54)
        %v12043_v42 = vmul.f32 2.0, %v119808_v61 (stack54)
        %v12448_v60 = vadd.s32 %v12444_v26, %v12432_v60 (stack40)
        %v12450_v31 = vshll.u32 %v12444_v26, 13 (stack45)
        %v12451_v41 = vshrl.u32 %v12444_v26, 19 (stack46)
        %v12842_v30 = vxor.u32 %v12841_v10, %v12837_v7 (stack48)
        %v13243_v53 = vxor.u32 %v13242_v43, %v13238_v6 (stack48)
        %v13671_v8 = vadd.s32 %v13668_v44, %v13663_v8 (stack40)
        %v11614_v20 = vsel /*vm=*/%vm11585_vm13, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v11649_v25 = vadd.f32 %v11645_v40, %v11618_v27 (stack53)
        %v12047_v52 = vadd.f32 -0.99609375, %v12043_v42 (stack53)
        %v13673_v24 = vshll.u32 %v13668_v44, 26 (stack45)
        %v12452_v29 = vor.u32 %v12451_v41, %v12450_v31 (stack47)
        %v12845_v7 = vadd.s32 %v12842_v30, %v12837_v7 (stack40)
        %v12851_v12 = vshll.u32 %v12842_v30, 6 (stack45)
        %v12852_v61 = vshrl.u32 %v12842_v30, 26 (stack46)
        %v11653_v26 = vmul.f32 %v11649_v25, %v126126_v11 (stack54)
        %v126133_v43 = vmax.f32 %v12047_v52, -0.99609375 (stack55)
        %v13246_v6 = vadd.s32 %v13243_v53, %v13238_v6 (stack40)
        %v13248_v27 = vshll.u32 %v13243_v53, 29 (stack45)
        %v12453_v21 = vxor.u32 %v12452_v29, %v12448_v60 (stack48)
        %v12853_v10 = vor.u32 %v12852_v61, %v12851_v12 (stack47)
        %v13249_v40 = vshrl.u32 %v13243_v53, 3 (stack46)
        %v13674_v44 = vshrl.u32 %v13668_v44, 6 (stack46)
        %v11602_v42 = vsel /*vm=*/%vm11585_vm13, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v11657_v31 = vadd.f32 %v11653_v26, %v11614_v20 (stack53)
        %v12063_v41 = vxor.u32 2147483648, %v126133_v43 (stack56)
        %v14091_v30 = vadd.s32 1, %v14087_v56 (stack40)
        %v12456_v60 = vadd.s32 %v12453_v21, %v12448_v60 (stack40)
        %v12458_v53 = vshll.u32 %v12453_v21, 15 (stack45)
        %v12459_v20 = vshrl.u32 %v12453_v21, 17 (stack46)
        %v12854_v25 = vxor.u32 %v12853_v10, %v12845_v7 (stack48)
        %v11610_v52 = vsel /*vm=*/%vm11585_vm13, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v11661_v29 = vmul.f32 %v11657_v31, %v126126_v11 (stack54)
        %v12066_v12 = vmul.f32 %v12063_v41, %v126133_v43 (stack54)
        %v13250_v61 = vor.u32 %v13249_v40, %v13248_v27 (stack47)
        %v12460_v26 = vor.u32 %v12459_v20, %v12458_v53 (stack47)
        %v12857_v27 = vadd.s32 %v12854_v25, %v121569_v1 (stack40)
        %v13675_v24 = vor.u32 %v13674_v44, %v13673_v24 (stack47)
        %v14095_v56 = vsel /*vm=*/%vm14082_vm1, /*on_true_vy=*/%v14091_v30, /*on_false_vx=*/%v14087_v56 (stack44)
        %v11606_v21 = vsel /*vm=*/%vm11585_vm13, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v11665_v10 = vadd.f32 %v11661_v29, %v11610_v52 (stack53)
        %v12068_v40 = vadd.f32 1.0, %v12066_v12 (stack57)
        %v12849_v7 = vadd.s32 %v12845_v7, %v121574_v2 (stack40)
        %v12461_v44 = vxor.u32 %v12460_v26, %v12456_v60 (stack48)
        %v12861_v31 = vadd.s32 3, %v12857_v27 (stack40)
        %v13251_v41 = vxor.u32 %v13250_v61, %v13246_v6 (stack48)
        %v13676_v30 = vxor.u32 %v13675_v24, %v13671_v8 (stack48)
        %v11669_v53 = vmul.f32 %v11665_v10, %v126126_v11 (stack54)
        %120529 = vlog2.f32 %v12068_v40 (stack58)
        %v12071_v20 = vmul.f32 -0.5, %v12066_v12 (stack59)
        %vm14077_vm2 = vcmp.lt.u32.totalorder %v126072_v22, %v125975_v32 (stack43)
        %v12464_v60 = vadd.s32 %v12461_v44, %v12456_v60 (stack40)
        %v12466_v25 = vshll.u32 %v12461_v44, 26 (stack45)
        %v12467_v52 = vshrl.u32 %v12461_v44, 6 (stack46)
        %v12865_v29 = vadd.s32 %v12861_v31, %v12849_v7 (stack40)
        %v11673_v61 = vadd.f32 %v11669_v53, %v11606_v21 (stack53)
        %v12074_v26 = vand.u32 2147483647, %v12066_v12 (stack60)
        %v12867_v27 = vshll.u32 %v12861_v31, 17 (stack45)
        %v12868_v24 = vshrl.u32 %v12861_v31, 15 (stack46)
        %v12468_v21 = vor.u32 %v12467_v52, %v12466_v25 (stack47)
        %v13254_v6 = vadd.s32 %v13251_v41, %v13246_v6 (stack40)
        %v13256_v10 = vshll.u32 %v13251_v41, 16 (stack45)
        %v13257_v40 = vshrl.u32 %v13251_v41, 16 (stack46)
        %v11677_v7 = vmul.f32 %v11673_v61, %v126126_v11 (stack54)
        %v12869_v44 = vor.u32 %v12868_v24, %v12867_v27 (stack47)
        %v126156_v8 = vadd.s32 %v13676_v30, %v13671_v8 (stack40)
        %v14112_v31 = vadd.s32 %v126072_v22, %v121569_v1 (stack40)
        %v12072_v41 = vadd.f32 1.0, %v12071_v20 (stack61)
        %v12469_v53 = vxor.u32 %v12468_v21, %v12464_v60 (stack48)
        %v13258_v20 = vor.u32 %v13257_v40, %v13256_v10 (stack47)
        %v13685_v25 = vshll.u32 %v13676_v30, 6 (stack45)
        %v11681_v42 = vadd.f32 %v11677_v7, %v11602_v42 (stack53)
        %v12870_v52 = vxor.u32 %v12869_v44, %v12865_v29 (stack48)
        %v13686_v30 = vshrl.u32 %v13676_v30, 26 (stack46)
        %v14099_v61 = vadd.s32 1, %v14095_v56 (stack40)
        %vm126160_vm3 = vcmp.lt.f32.partialorder %v12074_v26, 0.0004427343 (stack62)
        %v12472_v60 = vadd.s32 %v12469_v53, %v12464_v60 (stack40)
        %v12478_v27 = vshll.u32 %v12469_v53, 6 (stack45)
        %v12479_v24 = vshrl.u32 %v12469_v53, 26 (stack46)
        %v13259_v21 = vxor.u32 %v13258_v20, %v13254_v6 (stack48)
        %v11685_v10 = vmul.f32 %v11681_v42, %v126126_v11 (stack54)
        %v12873_v29 = vadd.s32 %v12870_v52, %v12865_v29 (stack40)
        %v12875_v40 = vshll.u32 %v12870_v52, 29 (stack45)
        %v12876_v7 = vshrl.u32 %v12870_v52, 3 (stack46)
        %v12480_v44 = vor.u32 %v12479_v24, %v12478_v27 (stack47)
        %v13262_v6 = vadd.s32 %v13259_v21, %v13254_v6 (stack40)
        %v13268_v53 = vshll.u32 %v13259_v21, 24 (stack45)
        %v14118_v20 = vshll.u32 %v14112_v31, 13 (stack45)
        %v11689_v9 = vadd.f32 %v11685_v10, %v126083_v9 (stack53)
        %v12877_v42 = vor.u32 %v12876_v7, %v12875_v40 (stack47)
        %v13269_v52 = vshrl.u32 %v13259_v21, 8 (stack46)
        %v13687_v25 = vor.u32 %v13686_v30, %v13685_v25 (stack47)
        %v12073_v12 = vmul.f32 %v12072_v41, %v12066_v12 (stack63)
        %v12481_v41 = vxor.u32 %v12480_v44, %v12472_v60 (stack48)
        %v14103_v32 = vsel /*vm=*/%vm14077_vm2, /*on_true_vy=*/%v14099_v61, /*on_false_vx=*/%v14095_v56 (stack44)
        %v14119_v22 = vshrl.u32 %v14112_v31, 19 (stack46)
        %v11693_v56 = vmul.f32 %v11689_v9, %v126126_v11 (stack54)
        %v12878_v30 = vxor.u32 %v12877_v42, %v12873_v29 (stack48)
        %v13270_v61 = vor.u32 %v13269_v52, %v13268_v53 (stack47)
        %v13688_v27 = vxor.u32 %v13687_v25, %v126156_v8 (stack48)
        %v120530_v24 = vpop.eup %120529 (stack64)
        %v12484_v21 = vadd.s32 %v12481_v41, %v121574_v2 (stack40)
        %v14108_v10 = vadd.s32 %v14103_v32, %v121574_v2 (stack40)
        %v14120_v40 = vor.u32 %v14119_v22, %v14118_v20 (stack47)
        %v126175_v7 = vadd.s32 %v157127_v34, %v157091_v37 (stack40)
        %v11697_v55 = vadd.f32 %v11693_v56, %v126078_v55 (stack53)
        %v12070_v44 = vmul.f32 0.6931472, %v120530_v24 (stack65)
        %v12881_v29 = vadd.s32 %v12878_v30, %v12873_v29 (stack40)
        %v12883_v53 = vshll.u32 %v12878_v30, 16 (stack45)
        %v12476_v60 = vadd.s32 %v12472_v60, %v121564_v0 (stack40)
        %v12488_v20 = vadd.s32 5, %v12484_v21 (stack40)
        %v12884_v9 = vshrl.u32 %v12878_v30, 16 (stack46)
        %v13271_v42 = vxor.u32 %v13270_v61, %v13262_v6 (stack48)
        %v11590_v50 = vsel /*vm=*/%vm11585_vm13, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v11701_v11 = vmul.f32 %v11697_v55, %v126126_v11 (stack54)
        %v12076_v26 = vsel /*vm=*/%vm126160_vm3, /*on_true_vy=*/%v12073_v12, /*on_false_vx=*/%v12070_v44 (stack66)
        %v14116_v31 = vadd.s32 %v14112_v31, %v14108_v10 (stack40)
        %v126185_v52 = vxor.u32 2147483648, %v12076_v26 (stack56)
        %v12490_v25 = vxor.u32 %v12488_v20, %v12476_v60 (stack48)
        %v12885_v12 = vor.u32 %v12884_v9, %v12883_v53 (stack47)
        %v13691_v41 = vadd.s32 %v13688_v27, %v121564_v0 (stack40)
        %v11705_v32 = vadd.f32 %v11701_v11, %v11590_v50 (stack53)
        %v14121_v22 = vxor.u32 %v14120_v40, %v14116_v31 (stack48)
        %v11566_v56 = vmul.f32 inf, %v125979_v54 (stack54)
        %vm12080_vm4 = vcmp.lt.f32.partialorder %v126185_v52, 5.0 (stack68)
        %120531 = vrsqrt.f32 %v126185_v52 (stack67)
        %vm11561_vm5 = vcmp.eq.f32.partialorder %v11558_v23, 1.0 (stack68)
        %v11709_v54 = vmul.f32 %v11705_v32, %v125979_v54 (stack54)
        %v12053_v23 = vand.u32 2147483647, %v126133_v43 (stack77)
        %v13274_v30 = vadd.s32 %v13271_v42, %v121574_v2 (stack40)
        %v12886_v61 = vxor.u32 %v12885_v12, %v12881_v29 (stack48)
        %v13266_v6 = vadd.s32 %v13262_v6, %v121564_v0 (stack40)
        %v13683_v8 = vadd.s32 %v126156_v8, %v121569_v1 (stack40)
        %v13695_v27 = vadd.s32 1, %v13691_v41 (stack40)
        %v11713_v24 = vsel /*vm=*/%vm11561_vm5, /*on_true_vy=*/%v11566_v56, /*on_false_vx=*/%v11709_v54 (stack44)
        %v126202_v21 = vsel /*vm=*/%vm12080_vm4, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v126205_v10 = vadd.f32 -2.5, %v126185_v52 (stack53)
        %v126209_v40 = vadd.s32 %v126175_v7, %v122657_v58 (stack40)
        %v11717_v55 = vmul.f32 1.4140625, %v11713_v24 (stack54)
        %v126214_v44 = vsel /*vm=*/%vm12080_vm4, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v126219_v53 = vsel /*vm=*/%vm12080_vm4, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v12491_v60 = vand.u32.u8 255, %v12490_v25 (stack49)
        %v12889_v29 = vadd.s32 %v12886_v61, %v12881_v29 (stack40)
        %v12895_v20 = vshll.u32 %v12886_v61, 24 (stack45)
        %v12896_v9 = vshrl.u32 %v12886_v61, 8 (stack46)
        %v13278_v42 = vadd.s32 2, %v13274_v30 (stack40)
        %v11720_v50 = vpack.c.bf16 %v156663_v45, %v11717_v55 (stack81)
        %v12492_v11 = vand.u32 65535, %v12491_v60 (stack50)
        %v13699_v26 = vadd.s32 %v13695_v27, %v13683_v8 (stack40)
        %v13701_v25 = vshll.u32 %v13695_v27, 17 (stack45)
        %v126225_v12 = vsel /*vm=*/%vm12080_vm4, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %vm12125_vm6 = vcmp.eq.f32.partialorder %v126185_v52, inf (stack70)
        %v12897_v41 = vor.u32 %v12896_v9, %v12895_v20 (stack47)
        %v13282_v32 = vadd.s32 %v13278_v42, %v13266_v6 (stack40)
        %v13284_v56 = vshll.u32 %v13278_v42, 13 (stack45)
        %119803 = vst [vmem:[%s123356_s30 + $0x388] sm:$0xf] /*vst_source=*/%v11720_v50 (stack83)
        %v12493_v54 = vshrl.u32 %v12492_v11, 1 (stack51)
        %v13285_v30 = vshrl.u32 %v13278_v42, 19 (stack46)
        %v13702_v61 = vshrl.u32 %v13695_v27, 15 (stack46)
        %v14124_v31 = vadd.s32 %v14121_v22, %v14116_v31 (stack40)
        %v12898_v6 = vxor.u32 %v12897_v41, %v12889_v29 (stack48)
        %v14126_v8 = vshll.u32 %v14121_v22, 15 (stack45)
        %v14127_v22 = vshrl.u32 %v14121_v22, 17 (stack46)
        %vm14543_vm7 = vcmp.lt.u32.totalorder %v126175_v7, %v157091_v37 (stack43)
        %v12494_v27 = vor.u32 16256, %v12493_v54 (stack47)
        %v13286_v24 = vor.u32 %v13285_v30, %v13284_v56 (stack47)
        %v13703_v55 = vor.u32 %v13702_v61, %v13701_v25 (stack47)
        %v14548_v60 = vadd.s32 %v157130_v46, %v157094_v36 (stack40)
        %v12113_v20 = vsel /*vm=*/%vm12080_vm4, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v12901_v9 = vadd.s32 %v12898_v6, %v121564_v0 (stack40)
        %v14128_v42 = vor.u32 %v14127_v22, %v14126_v8 (stack47)
        %v126239_v34 = vadd.s32 %v157127_v34, %v157095_v13 (stack40)
        %vm12127_vm8 = vcmp.eq.f32.partialorder %v126185_v52, 0.0 (stack71)
        %v12495_v50 = vand.u32.u16 65535, %v12494_v27 (stack52)
        %v13287_v11 = vxor.u32 %v13286_v24, %v13282_v32 (stack48)
        %v13704_v25 = vxor.u32 %v13703_v55, %v13699_v26 (stack48)
        %v120532_v41 = vpop.eup %120531 (stack73)
        %v12128_v56 = vand.u32 2147483648, %v126185_v52 (stack72)
        %v12893_v29 = vadd.s32 %v12889_v29, %v121569_v1 (stack40)
        %v12905_v54 = vadd.s32 4, %v12901_v9 (stack40)
        %v14129_v30 = vxor.u32 %v14128_v42, %v14124_v31 (stack48)
        %v12124_v61 = vmul.f32 %v120532_v41, %v126185_v52 (stack74)
        %v119810_v6 = vadd.low.f32.bf16 -1.0, %v12495_v50 (stack53)
        %v13290_v32 = vadd.s32 %v13287_v11, %v13282_v32 (stack40)
        %v13292_v8 = vshll.u32 %v13287_v11, 15 (stack45)
        %v12909_v22 = vadd.s32 %v12905_v54, %v12893_v29 (stack40)
        %v12911_v27 = vshll.u32 %v12905_v54, 13 (stack45)
        %v12912_v24 = vshrl.u32 %v12905_v54, 19 (stack46)
        %v13293_v55 = vshrl.u32 %v13287_v11, 17 (stack46)
        %v12126_v9 = vsel /*vm=*/%vm12125_vm6, /*on_true_vy=*/%v126185_v52, /*on_false_vx=*/%v12124_v61 (stack75)
        %v12504_v42 = vmul.f32 2.0, %v119810_v6 (stack54)
        %v13707_v26 = vadd.s32 %v13704_v25, %v13699_v26 (stack40)
        %v13709_v50 = vshll.u32 %v13704_v25, 29 (stack45)
        %v12129_v11 = vsel /*vm=*/%vm12127_vm8, /*on_true_vy=*/%v12128_v56, /*on_false_vx=*/%v12126_v9 (stack76)
        %v12913_v41 = vor.u32 %v12912_v24, %v12911_v27 (stack47)
        %v13294_v56 = vor.u32 %v13293_v55, %v13292_v8 (stack47)
        %v13710_v25 = vshrl.u32 %v13704_v25, 3 (stack46)
        %v12132_v29 = vadd.f32 -3.0, %v12129_v11 (stack53)
        %v12508_v54 = vadd.f32 -0.99609375, %v12504_v42 (stack53)
        %v126250_v31 = vadd.s32 %v14129_v30, %v14124_v31 (stack40)
        %v14552_v61 = vadd.s32 1, %v14548_v60 (stack40)
        %v12117_v6 = vsel /*vm=*/%vm12080_vm4, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v12914_v8 = vxor.u32 %v12913_v41, %v12909_v22 (stack48)
        %v13295_v27 = vxor.u32 %v13294_v56, %v13290_v32 (stack48)
        %v126257_v24 = vadd.s32 %v126209_v40, %v121569_v1 (stack40)
        %v126262_v10 = vsel /*vm=*/%vm12080_vm4, /*on_true_vy=*/%v126205_v10, /*on_false_vx=*/%v12132_v29 (stack44)
        %v126264_v55 = vmax.f32 %v12508_v54, -0.99609375 (stack55)
        %v13711_v9 = vor.u32 %v13710_v25, %v13709_v50 (stack47)
        %v14556_v60 = vsel /*vm=*/%vm14543_vm7, /*on_true_vy=*/%v14552_v61, /*on_false_vx=*/%v14548_v60 (stack44)
        %v12140_v42 = vmul.f32 %v126262_v10, %v12117_v6 (stack54)
        %v12917_v22 = vadd.s32 %v12914_v8, %v12909_v22 (stack40)
        %v12919_v50 = vshll.u32 %v12914_v8, 15 (stack45)
        %v12920_v11 = vshrl.u32 %v12914_v8, 17 (stack46)
        %vm14538_vm9 = vcmp.lt.u32.totalorder %v126209_v40, %v126175_v7 (stack43)
        %v12524_v41 = vxor.u32 2147483648, %v126264_v55 (stack56)
        %v13298_v32 = vadd.s32 %v13295_v27, %v13290_v32 (stack40)
        %v14134_v56 = vshll.u32 %v14129_v30, 26 (stack45)
        %v14135_v30 = vshrl.u32 %v14129_v30, 6 (stack46)
        %v12144_v20 = vadd.f32 %v12140_v42, %v12113_v20 (stack53)
        %v12921_v25 = vor.u32 %v12920_v11, %v12919_v50 (stack47)
        %v13300_v29 = vshll.u32 %v13295_v27, 26 (stack45)
        %v13301_v54 = vshrl.u32 %v13295_v27, 6 (stack46)
        %v12109_v61 = vsel /*vm=*/%vm12080_vm4, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v12527_v6 = vmul.f32 %v12524_v41, %v126264_v55 (stack54)
        %v13712_v8 = vxor.u32 %v13711_v9, %v13707_v26 (stack48)
        %v14579_v27 = vshll.u32 %v126257_v24, 13 (stack45)
        %v12148_v9 = vmul.f32 %v12144_v20, %v126262_v10 (stack54)
        %v12922_v42 = vxor.u32 %v12921_v25, %v12917_v22 (stack48)
        %v13302_v50 = vor.u32 %v13301_v54, %v13300_v29 (stack47)
        %v14580_v11 = vshrl.u32 %v126257_v24, 19 (stack46)
        %v12529_v41 = vadd.f32 1.0, %v12527_v6 (stack57)
        %v12532_v20 = vmul.f32 -0.5, %v12527_v6 (stack59)
        %v13715_v26 = vadd.s32 %v13712_v8, %v13707_v26 (stack40)
        %v14136_v56 = vor.u32 %v14135_v30, %v14134_v56 (stack47)
        %v12152_v30 = vadd.f32 %v12148_v9, %v12109_v61 (stack53)
        %v12925_v22 = vadd.s32 %v12922_v42, %v12917_v22 (stack40)
        %v12927_v25 = vshll.u32 %v12922_v42, 26 (stack45)
        %v12928_v29 = vshrl.u32 %v12922_v42, 6 (stack46)
        %120533 = vlog2.f32 %v12529_v41 (stack58)
        %v12533_v54 = vadd.f32 1.0, %v12532_v20 (stack61)
        %v13303_v61 = vxor.u32 %v13302_v50, %v13298_v32 (stack48)
        %v14560_v9 = vadd.s32 1, %v14556_v60 (stack40)
        %v12156_v42 = vmul.f32 %v12152_v30, %v126262_v10 (stack54)
        %v12929_v50 = vor.u32 %v12928_v29, %v12927_v25 (stack47)
        %v13717_v41 = vshll.u32 %v13712_v8, 16 (stack45)
        %v13718_v8 = vshrl.u32 %v13712_v8, 16 (stack46)
        %v12535_v20 = vand.u32 2147483647, %v12527_v6 (stack60)
        %v13306_v32 = vadd.s32 %v13303_v61, %v13298_v32 (stack40)
        %v13312_v30 = vshll.u32 %v13303_v61, 6 (stack45)
        %v13313_v25 = vshrl.u32 %v13303_v61, 26 (stack46)
        %v12160_v12 = vadd.f32 %v12156_v42, %v126225_v12 (stack53)
        %v12930_v29 = vxor.u32 %v12929_v50, %v12925_v22 (stack48)
        %v13719_v61 = vor.u32 %v13718_v8, %v13717_v41 (stack47)
        %v14137_v56 = vxor.u32 %v14136_v56, %v126250_v31 (stack48)
        %v12534_v6 = vmul.f32 %v12533_v54, %v12527_v6 (stack63)
        %v13314_v54 = vor.u32 %v13313_v25, %v13312_v30 (stack47)
        %v14564_v7 = vsel /*vm=*/%vm14538_vm9, /*on_true_vy=*/%v14560_v9, /*on_false_vx=*/%v14556_v60 (stack44)
        %v14581_v40 = vor.u32 %v14580_v11, %v14579_v27 (stack47)
        %v12164_v60 = vmul.f32 %v12160_v12, %v126262_v10 (stack54)
        %v12933_v27 = vadd.s32 %v12930_v29, %v12925_v22 (stack40)
        %v12939_v11 = vshll.u32 %v12930_v29, 6 (stack45)
        %v12940_v22 = vshrl.u32 %v12930_v29, 26 (stack46)
        %v13315_v9 = vxor.u32 %v13314_v54, %v13306_v32 (stack48)
        %v13720_v42 = vxor.u32 %v13719_v61, %v13715_v26 (stack48)
        %v14140_v31 = vadd.s32 %v14137_v56, %v126250_v31 (stack40)
        %v14146_v50 = vshll.u32 %v14137_v56, 6 (stack45)
        %v12168_v53 = vadd.f32 %v12164_v60, %v126219_v53 (stack53)
        %vm126289_vm10 = vcmp.lt.f32.partialorder %v12535_v20, 0.0004427343 (stack62)
        %v12941_v8 = vor.u32 %v12940_v22, %v12939_v11 (stack47)
        %v13310_v20 = vadd.s32 %v13306_v32, %v121574_v2 (stack40)
        %v14147_v32 = vshrl.u32 %v14137_v56, 26 (stack46)
        %v13318_v30 = vadd.s32 %v13315_v9, %v121569_v1 (stack40)
        %v13723_v26 = vadd.s32 %v13720_v42, %v13715_v26 (stack40)
        %v13729_v25 = vshll.u32 %v13720_v42, 24 (stack45)
        %v13730_v12 = vshrl.u32 %v13720_v42, 8 (stack46)
        %v12172_v29 = vmul.f32 %v12168_v53, %v126262_v10 (stack54)
        %v12937_v61 = vadd.s32 %v12933_v27, %v121564_v0 (stack40)
        %v12942_v56 = vxor.u32 %v12941_v8, %v12933_v27 (stack48)
        %v14148_v54 = vor.u32 %v14147_v32, %v14146_v50 (stack47)
        %v13322_v60 = vadd.s32 3, %v13318_v30 (stack40)
        %v13731_v27 = vor.u32 %v13730_v12, %v13729_v25 (stack47)
        %v14144_v11 = vadd.s32 %v14140_v31, %v121569_v1 (stack40)
        %v14569_v7 = vadd.s32 %v14564_v7, %v121574_v2 (stack40)
        %v12176_v44 = vadd.f32 %v12172_v29, %v126214_v44 (stack53)
        %v12945_v22 = vadd.s32 %v12942_v56, %v121574_v2 (stack40)
        %v13727_v9 = vadd.s32 %v13723_v26, %v121564_v0 (stack40)
        %v14149_v42 = vxor.u32 %v14148_v54, %v14140_v31 (stack48)
        %v13326_v31 = vadd.s32 %v13322_v60, %v13310_v20 (stack40)
        %v13328_v50 = vshll.u32 %v13322_v60, 17 (stack45)
        %v13329_v53 = vshrl.u32 %v13322_v60, 15 (stack46)
        %v13732_v8 = vxor.u32 %v13731_v27, %v13723_v26 (stack48)
        %v120534_v20 = vpop.eup %120533 (stack64)
        %v12180_v32 = vmul.f32 %v12176_v44, %v126262_v10 (stack54)
        %v12949_v30 = vadd.s32 5, %v12945_v22 (stack40)
        %v14152_v26 = vadd.s32 %v14149_v42, %v121564_v0 (stack40)
        %v14577_v24 = vadd.s32 %v126257_v24, %v14569_v7 (stack40)
        %v12531_v25 = vmul.f32 0.6931472, %v120534_v20 (stack65)
        %v13330_v12 = vor.u32 %v13329_v53, %v13328_v50 (stack47)
        %v13735_v29 = vadd.s32 %v13732_v8, %v121574_v2 (stack40)
        %vm15004_vm11 = vcmp.lt.u32.totalorder %v126239_v34, %v157095_v13 (stack43)
        %v12184_v21 = vadd.f32 %v12180_v32, %v126202_v21 (stack53)
        %v12951_v61 = vxor.u32 %v12949_v30, %v12937_v61 (stack48)
        %v14156_v56 = vadd.s32 1, %v14152_v26 (stack40)
        %v14582_v40 = vxor.u32 %v14581_v40, %v14577_v24 (stack48)
        %v12537_v6 = vsel /*vm=*/%vm126289_vm10, /*on_true_vy=*/%v12534_v6, /*on_false_vx=*/%v12531_v25 (stack66)
        %v13331_v41 = vxor.u32 %v13330_v12, %v13326_v31 (stack48)
        %v13739_v54 = vadd.s32 2, %v13735_v29 (stack40)
        %v126313_v46 = vadd.s32 %v157130_v46, %v157100_v14 (stack40)
        %v12089_v60 = vsel /*vm=*/%vm12080_vm4, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v12188_v27 = vmul.f32 %v12184_v21, %v126262_v10 (stack54)
        %v126319_v7 = vxor.u32 2147483648, %v12537_v6 (stack56)
        %v126321_v11 = vadd.s32 %v14156_v56, %v14144_v11 (stack40)
        %v13334_v44 = vadd.s32 %v13331_v41, %v13326_v31 (stack40)
        %v13336_v22 = vshll.u32 %v13331_v41, 29 (stack45)
        %v13337_v42 = vshrl.u32 %v13331_v41, 3 (stack46)
        %v13743_v9 = vadd.s32 %v13739_v54, %v13727_v9 (stack40)
        %v12192_v31 = vadd.f32 %v12188_v27, %v12089_v60 (stack53)
        %120535 = vrsqrt.f32 %v126319_v7 (stack67)
        %vm12541_vm12 = vcmp.lt.f32.partialorder %v126319_v7, 5.0 (stack68)
        %v12952_v50 = vand.u32.u8 255, %v12951_v61 (stack49)
        %v13338_v53 = vor.u32 %v13337_v42, %v13336_v22 (stack47)
        %vm126327_vm13 = vcmp.eq.f32.partialorder %v12053_v23, 1.0 (stack68)
        %v12061_v8 = vmul.f32 inf, %v126133_v43 (stack54)
        %v12196_v10 = vmul.f32 %v12192_v31, %v126262_v10 (stack54)
        %v12085_v52 = vsel /*vm=*/%vm12080_vm4, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v12514_v20 = vand.u32 2147483647, %v126264_v55 (stack77)
        %v13339_v32 = vxor.u32 %v13338_v53, %v13334_v44 (stack48)
        %v126339_v30 = vadd.s32 %v126239_v34, %v122657_v58 (stack40)
        %v12200_v26 = vadd.f32 %v12196_v10, %v12085_v52 (stack53)
        %v126344_v25 = vsel /*vm=*/%vm12541_vm12, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v126349_v12 = vsel /*vm=*/%vm12541_vm12, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v126352_v29 = vadd.f32 -2.5, %v126319_v7 (stack53)
        %v12953_v21 = vand.u32 65535, %v12952_v50 (stack50)
        %v13342_v61 = vadd.s32 %v13339_v32, %v13334_v44 (stack40)
        %v13344_v6 = vshll.u32 %v13339_v32, 16 (stack45)
        %v13345_v41 = vshrl.u32 %v13339_v32, 16 (stack46)
        %v12204_v43 = vmul.f32 %v12200_v26, %v126133_v43 (stack54)
        %v13745_v60 = vshll.u32 %v13739_v54, 13 (stack45)
        %v13746_v54 = vshrl.u32 %v13739_v54, 19 (stack46)
        %v14162_v27 = vshll.u32 %v14156_v56, 17 (stack45)
        %vm12586_vm14 = vcmp.eq.f32.partialorder %v126319_v7, inf (stack70)
        %v12954_v44 = vshrl.u32 %v12953_v21, 1 (stack51)
        %v13346_v22 = vor.u32 %v13345_v41, %v13344_v6 (stack47)
        %v14163_v56 = vshrl.u32 %v14156_v56, 15 (stack46)
        %v14585_v24 = vadd.s32 %v14582_v40, %v14577_v24 (stack40)
        %v12208_v42 = vsel /*vm=*/%vm126327_vm13, /*on_true_vy=*/%v12061_v8, /*on_false_vx=*/%v12204_v43 (stack44)
        %v13747_v31 = vor.u32 %v13746_v54, %v13745_v60 (stack47)
        %v14587_v50 = vshll.u32 %v14582_v40, 15 (stack45)
        %v14588_v40 = vshrl.u32 %v14582_v40, 17 (stack46)
        %v12212_v53 = vmul.f32 1.4140625, %v12208_v42 (stack54)
        %v12955_v23 = vor.u32 16256, %v12954_v44 (stack47)
        %v13347_v8 = vxor.u32 %v13346_v22, %v13342_v61 (stack48)
        %v14164_v10 = vor.u32 %v14163_v56, %v14162_v27 (stack47)
        %vm12588_vm15 = vcmp.eq.f32.partialorder %v126319_v7, 0.0 (stack71)
        %v13748_v52 = vxor.u32 %v13747_v31, %v13743_v9 (stack48)
        %v14589_v32 = vor.u32 %v14588_v40, %v14587_v50 (stack47)
        %v15013_v26 = vadd.s32 1, %v126313_v46 (stack40)
        %v12215_v21 = vpack.c.bf16 %v156663_v45, %v12212_v53 (stack81)
        %v12956_v6 = vand.u32.u16 65535, %v12955_v23 (stack52)
        %v13350_v61 = vadd.s32 %v13347_v8, %v13342_v61 (stack40)
        %v13356_v41 = vshll.u32 %v13347_v8, 24 (stack45)
        %v13357_v43 = vshrl.u32 %v13347_v8, 8 (stack46)
        %v13751_v9 = vadd.s32 %v13748_v52, %v13743_v9 (stack40)
        %v13753_v60 = vshll.u32 %v13748_v52, 15 (stack45)
        %v13754_v54 = vshrl.u32 %v13748_v52, 17 (stack46)
        %v120536_v27 = vpop.eup %120535 (stack73)
        %119809 = vst [vmem:[%s123356_s30 + $0xc] sm:$0xf] /*vst_source=*/%v12215_v21 (stack83)
        %v12589_v44 = vand.u32 2147483648, %v126319_v7 (stack72)
        %v119812_v22 = vadd.low.f32.bf16 -1.0, %v12956_v6 (stack53)
        %v14165_v56 = vxor.u32 %v14164_v10, %v126321_v11 (stack48)
        %v126364_v42 = vxor.u32 %v14589_v32, %v14585_v24 (stack48)
        %v12585_v31 = vmul.f32 %v120536_v27, %v126319_v7 (stack74)
        %v13358_v50 = vor.u32 %v13357_v43, %v13356_v41 (stack47)
        %v13755_v40 = vor.u32 %v13754_v54, %v13753_v60 (stack47)
        %v126371_v46 = vsel /*vm=*/%vm15004_vm11, /*on_true_vy=*/%v15013_v26, /*on_false_vx=*/%v126313_v46 (stack44)
        %v12965_v53 = vmul.f32 2.0, %v119812_v22 (stack54)
        %v14168_v11 = vadd.s32 %v14165_v56, %v126321_v11 (stack40)
        %v14170_v23 = vshll.u32 %v14165_v56, 29 (stack45)
        %v14171_v8 = vshrl.u32 %v14165_v56, 3 (stack46)
        %v12587_v10 = vsel /*vm=*/%vm12586_vm14, /*on_true_vy=*/%v126319_v7, /*on_false_vx=*/%v12585_v31 (stack75)
        %v13359_v52 = vxor.u32 %v13358_v50, %v13350_v61 (stack48)
        %v13756_v32 = vxor.u32 %v13755_v40, %v13751_v9 (stack48)
        %v126378_v24 = vadd.s32 %v126364_v42, %v14585_v24 (stack40)
        %v12570_v26 = vsel /*vm=*/%vm12541_vm12, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v12590_v21 = vsel /*vm=*/%vm12588_vm15, /*on_true_vy=*/%v12589_v44, /*on_false_vx=*/%v12587_v10 (stack76)
        %v12969_v6 = vadd.f32 -0.99609375, %v12965_v53 (stack53)
        %v14172_v41 = vor.u32 %v14171_v8, %v14170_v23 (stack47)
        %v12593_v43 = vadd.f32 -3.0, %v12590_v21 (stack53)
        %v13362_v60 = vadd.s32 %v13359_v52, %v121564_v0 (stack40)
        %v13759_v9 = vadd.s32 %v13756_v32, %v13751_v9 (stack40)
        %v13761_v54 = vshll.u32 %v13756_v32, 26 (stack45)
        %v12574_v27 = vsel /*vm=*/%vm12541_vm12, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v126389_v44 = vmax.f32 %v12969_v6, -0.99609375 (stack55)
        %v13762_v22 = vshrl.u32 %v13756_v32, 6 (stack46)
        %v14173_v56 = vxor.u32 %v14172_v41, %v14168_v11 (stack48)
        %vm14999_vm0 = vcmp.lt.u32.totalorder %v126339_v30, %v126239_v34 (stack43)
        %v12578_v31 = vsel /*vm=*/%vm12541_vm12, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v126399_v29 = vsel /*vm=*/%vm12541_vm12, /*on_true_vy=*/%v126352_v29, /*on_false_vx=*/%v12593_v43 (stack44)
        %v13354_v61 = vadd.s32 %v13350_v61, %v121569_v1 (stack40)
        %v13366_v50 = vadd.s32 4, %v13362_v60 (stack40)
        %v12601_v40 = vmul.f32 %v126399_v29, %v12578_v31 (stack54)
        %v12985_v53 = vxor.u32 2147483648, %v126389_v44 (stack56)
        %v14595_v23 = vshll.u32 %v126364_v42, 26 (stack45)
        %v126407_v8 = vadd.s32 %v126339_v30, %v121569_v1 (stack40)
        %v13370_v10 = vadd.s32 %v13366_v50, %v13354_v61 (stack40)
        %v13372_v52 = vshll.u32 %v13366_v50, 13 (stack45)
        %v13373_v32 = vshrl.u32 %v13366_v50, 19 (stack46)
        %v13763_v21 = vor.u32 %v13762_v22, %v13761_v54 (stack47)
        %v12605_v6 = vadd.f32 %v12601_v40, %v12574_v27 (stack53)
        %v126410_v41 = vmul.f32 %v12985_v53, %v126389_v44 (stack54)
        %v14176_v11 = vadd.s32 %v14173_v56, %v14168_v11 (stack40)
        %v14596_v42 = vshrl.u32 %v126364_v42, 6 (stack46)
        %v13374_v43 = vor.u32 %v13373_v32, %v13372_v52 (stack47)
        %v13764_v60 = vxor.u32 %v13763_v21, %v13759_v9 (stack48)
        %v14178_v54 = vshll.u32 %v14173_v56, 16 (stack45)
        %v15021_v27 = vadd.s32 1, %v126371_v46 (stack40)
        %v12609_v22 = vmul.f32 %v12605_v6, %v126399_v29 (stack54)
        %v12990_v31 = vadd.f32 1.0, %v126410_v41 (stack57)
        %v12993_v61 = vmul.f32 -0.5, %v126410_v41 (stack59)
        %v14179_v56 = vshrl.u32 %v14173_v56, 16 (stack46)
        %v13375_v50 = vxor.u32 %v13374_v43, %v13370_v10 (stack48)
        %v13767_v9 = vadd.s32 %v13764_v60, %v13759_v9 (stack40)
        %v13773_v40 = vshll.u32 %v13764_v60, 6 (stack45)
        %v13774_v53 = vshrl.u32 %v13764_v60, 26 (stack46)
        %v12562_v52 = vsel /*vm=*/%vm12541_vm12, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v12566_v32 = vsel /*vm=*/%vm12541_vm12, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v12613_v26 = vadd.f32 %v12609_v22, %v12570_v26 (stack53)
        %120537 = vlog2.f32 %v12990_v31 (stack58)
        %v13378_v10 = vadd.s32 %v13375_v50, %v13370_v10 (stack40)
        %v13380_v21 = vshll.u32 %v13375_v50, 15 (stack45)
        %v13381_v6 = vshrl.u32 %v13375_v50, 17 (stack46)
        %v15040_v43 = vshll.u32 %v126407_v8, 13 (stack45)
        %v12617_v60 = vmul.f32 %v12613_v26, %v126399_v29 (stack54)
        %v12996_v22 = vand.u32 2147483647, %v126410_v41 (stack60)
        %v13775_v31 = vor.u32 %v13774_v53, %v13773_v40 (stack47)
        %v14180_v54 = vor.u32 %v14179_v56, %v14178_v54 (stack47)
        %v12994_v61 = vadd.f32 1.0, %v12993_v61 (stack61)
        %v13382_v56 = vor.u32 %v13381_v6, %v13380_v21 (stack47)
        %v14597_v23 = vor.u32 %v14596_v42, %v14595_v23 (stack47)
        %v15025_v34 = vsel /*vm=*/%vm14999_vm0, /*on_true_vy=*/%v15021_v27, /*on_false_vx=*/%v126371_v46 (stack44)
        %v12621_v30 = vadd.f32 %v12617_v60, %v12566_v32 (stack53)
        %v13771_v46 = vadd.s32 %v13767_v9, %v121574_v2 (stack40)
        %v13776_v42 = vxor.u32 %v13775_v31, %v13767_v9 (stack48)
        %v14181_v27 = vxor.u32 %v14180_v54, %v14176_v11 (stack48)
        %v13383_v50 = vxor.u32 %v13382_v56, %v13378_v10 (stack48)
        %v14598_v9 = vxor.u32 %v14597_v23, %v126378_v24 (stack48)
        %v15041_v40 = vshrl.u32 %v126407_v8, 19 (stack46)
        %v157155_v53 = vld [vmem:[#allocation128_spill] sm:$0xff] (stack84)
        %v126435_v32 = vadd.s32 %v157155_v53, %v122651_v47 (stack40)
        %v12625_v26 = vmul.f32 %v12621_v30, %v126399_v29 (stack54)
        %v13779_v21 = vadd.s32 %v13776_v42, %v121569_v1 (stack40)
        %v14184_v11 = vadd.s32 %v14181_v27, %v14176_v11 (stack40)
        %v14190_v6 = vshll.u32 %v14181_v27, 24 (stack45)
        %vm126439_vm1 = vcmp.lt.f32.partialorder %v12996_v22, 0.0004427343 (stack62)
        %v13386_v10 = vadd.s32 %v13383_v50, %v13378_v10 (stack40)
        %v13388_v22 = vshll.u32 %v13383_v50, 26 (stack45)
        %v13389_v31 = vshrl.u32 %v13383_v50, 6 (stack46)
        %v14191_v54 = vshrl.u32 %v14181_v27, 8 (stack46)
        %v12629_v52 = vadd.f32 %v12625_v26, %v12562_v52 (stack53)
        %v13783_v56 = vadd.s32 3, %v13779_v21 (stack40)
        %v14601_v24 = vadd.s32 %v14598_v9, %v126378_v24 (stack40)
        %v15030_v23 = vadd.s32 %v15025_v34, %v121574_v2 (stack40)
        %v13390_v34 = vor.u32 %v13389_v31, %v13388_v22 (stack47)
        %v14192_v30 = vor.u32 %v14191_v54, %v14190_v6 (stack47)
        %v14607_v42 = vshll.u32 %v14598_v9, 6 (stack45)
        %v14608_v27 = vshrl.u32 %v14598_v9, 26 (stack46)
        %v12633_v50 = vmul.f32 %v12629_v52, %v126399_v29 (stack54)
        %v13787_v46 = vadd.s32 %v13783_v56, %v13771_v46 (stack40)
        %v13789_v9 = vshll.u32 %v13783_v56, 17 (stack45)
        %v13790_v26 = vshrl.u32 %v13783_v56, 15 (stack46)
        %v13391_v21 = vxor.u32 %v13390_v34, %v13386_v10 (stack48)
        %v14193_v6 = vxor.u32 %v14192_v30, %v14184_v11 (stack48)
        %v14609_v22 = vor.u32 %v14608_v27, %v14607_v42 (stack47)
        %v15042_v43 = vor.u32 %v15041_v40, %v15040_v43 (stack47)
        %v12637_v12 = vadd.f32 %v12633_v50, %v126349_v12 (stack53)
        %v12995_v41 = vmul.f32 %v12994_v61, %v126410_v41 (stack63)
        %v13791_v61 = vor.u32 %v13790_v26, %v13789_v9 (stack47)
        %v15038_v8 = vadd.s32 %v126407_v8, %v15030_v23 (stack40)
        %v120538_v40 = vpop.eup %120537 (stack64)
        %v13394_v10 = vadd.s32 %v13391_v21, %v13386_v10 (stack40)
        %v13400_v31 = vshll.u32 %v13391_v21, 6 (stack45)
        %v13401_v54 = vshrl.u32 %v13391_v21, 26 (stack46)
        %v14196_v52 = vadd.s32 %v14193_v6, %v121574_v2 (stack40)
        %v12641_v56 = vmul.f32 %v12637_v12, %v126399_v29 (stack54)
        %v12992_v23 = vmul.f32 0.6931472, %v120538_v40 (stack65)
        %v13792_v34 = vxor.u32 %v13791_v61, %v13787_v46 (stack48)
        %v14610_v30 = vxor.u32 %v14609_v22, %v14601_v24 (stack48)
        %v13402_v42 = vor.u32 %v13401_v54, %v13400_v31 (stack47)
        %v14188_v11 = vadd.s32 %v14184_v11, %v121564_v0 (stack40)
        %v14200_v27 = vadd.s32 2, %v14196_v52 (stack40)
        %v15043_v50 = vxor.u32 %v15042_v43, %v15038_v8 (stack48)
        %v12645_v25 = vadd.f32 %v12641_v56, %v126344_v25 (stack53)
        %v12998_v60 = vsel /*vm=*/%vm126439_vm1, /*on_true_vy=*/%v12995_v41, /*on_false_vx=*/%v12992_v23 (stack66)
        %v13795_v46 = vadd.s32 %v13792_v34, %v13787_v46 (stack40)
        %v126455_v9 = vxor.u32 2147483648, %v12998_v60 (stack56)
        %v13403_v26 = vxor.u32 %v13402_v42, %v13394_v10 (stack48)
        %v14204_v21 = vadd.s32 %v14200_v27, %v14188_v11 (stack40)
        %v12522_v6 = vmul.f32 inf, %v126264_v55 (stack54)
        %v12546_v22 = vsel /*vm=*/%vm12541_vm12, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v12550_v7 = vsel /*vm=*/%vm12541_vm12, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v12649_v43 = vmul.f32 %v12645_v25, %v126399_v29 (stack54)
        %vm126467_vm2 = vcmp.eq.f32.partialorder %v12514_v20, 1.0 (stack68)
        %vm13002_vm3 = vcmp.lt.f32.partialorder %v126455_v9, 5.0 (stack68)
        %120539 = vrsqrt.f32 %v126455_v9 (stack67)
        %v13797_v12 = vshll.u32 %v13792_v34, 29 (stack45)
        %v13798_v41 = vshrl.u32 %v13792_v34, 3 (stack46)
        %v12653_v61 = vadd.f32 %v12649_v43, %v12550_v7 (stack53)
        %v14206_v40 = vshll.u32 %v14200_v27, 13 (stack45)
        %v14207_v31 = vshrl.u32 %v14200_v27, 19 (stack46)
        %v14613_v54 = vadd.s32 %v14610_v30, %v121564_v0 (stack40)
        %v12975_v52 = vand.u32 2147483647, %v126389_v44 (stack77)
        %v13406_v56 = vadd.s32 %v13403_v26, %v121574_v2 (stack40)
        %v14605_v24 = vadd.s32 %v14601_v24, %v121569_v1 (stack40)
        %v126479_v23 = vadd.s32 %v126435_v32, %v122657_v58 (stack40)
        %v12657_v29 = vmul.f32 %v12653_v61, %v126399_v29 (stack54)
        %v126485_v34 = vsel /*vm=*/%vm13002_vm3, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v126488_v30 = vadd.f32 -2.5, %v126455_v9 (stack53)
        %v13398_v10 = vadd.s32 %v13394_v10, %v121564_v0 (stack40)
        %v126494_v42 = vsel /*vm=*/%vm13002_vm3, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v126499_v11 = vsel /*vm=*/%vm13002_vm3, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v13410_v27 = vadd.s32 5, %v13406_v56 (stack40)
        %v13799_v25 = vor.u32 %v13798_v41, %v13797_v12 (stack47)
        %v12661_v60 = vadd.f32 %v12657_v29, %v12546_v22 (stack53)
        %v14208_v26 = vor.u32 %v14207_v31, %v14206_v40 (stack47)
        %v14617_v22 = vadd.s32 1, %v14613_v54 (stack40)
        %v15046_v8 = vadd.s32 %v15043_v50, %v15038_v8 (stack40)
        %v13412_v7 = vxor.u32 %v13410_v27, %v13398_v10 (stack48)
        %v13800_v43 = vxor.u32 %v13799_v25, %v13795_v46 (stack48)
        %v15048_v12 = vshll.u32 %v15043_v50, 15 (stack45)
        %v15049_v50 = vshrl.u32 %v15043_v50, 17 (stack46)
        %v12665_v55 = vmul.f32 %v12661_v60, %v126264_v55 (stack54)
        %vm13047_vm4 = vcmp.eq.f32.partialorder %v126455_v9, inf (stack70)
        %v14209_v41 = vxor.u32 %v14208_v26, %v14204_v21 (stack48)
        %v14621_v61 = vadd.s32 %v14617_v22, %v14605_v24 (stack40)
        %v14623_v40 = vshll.u32 %v14617_v22, 17 (stack45)
        %v13413_v31 = vand.u32.u8 255, %v13412_v7 (stack49)
        %v13803_v46 = vadd.s32 %v13800_v43, %v13795_v46 (stack40)
        %v13805_v54 = vshll.u32 %v13800_v43, 16 (stack45)
        %v13806_v56 = vshrl.u32 %v13800_v43, 16 (stack46)
        %v12669_v6 = vsel /*vm=*/%vm126467_vm2, /*on_true_vy=*/%v12522_v6, /*on_false_vx=*/%v12665_v55 (stack44)
        %v14212_v21 = vadd.s32 %v14209_v41, %v14204_v21 (stack40)
        %v14214_v20 = vshll.u32 %v14209_v41, 15 (stack45)
        %v14215_v24 = vshrl.u32 %v14209_v41, 17 (stack46)
        %v12673_v29 = vmul.f32 1.4140625, %v12669_v6 (stack54)
        %v13414_v10 = vand.u32 65535, %v13413_v31 (stack50)
        %v13807_v27 = vor.u32 %v13806_v56, %v13805_v54 (stack47)
        %v14624_v25 = vshrl.u32 %v14617_v22, 15 (stack46)
        %v13039_v60 = vsel /*vm=*/%vm13002_vm3, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v14216_v26 = vor.u32 %v14215_v24, %v14214_v20 (stack47)
        %v15050_v22 = vor.u32 %v15049_v50, %v15048_v12 (stack47)
        %vm15499_vm5 = vcmp.lt.u32.totalorder %v126435_v32, %v122651_v47 (stack43)
        %v12676_v7 = vpack.c.bf16 %v156663_v45, %v12673_v29 (stack81)
        %v13415_v43 = vshrl.u32 %v13414_v10, 1 (stack51)
        %v13808_v12 = vxor.u32 %v13807_v27, %v13803_v46 (stack48)
        %v14625_v50 = vor.u32 %v14624_v25, %v14623_v40 (stack47)
        %v120540_v55 = vpop.eup %120539 (stack73)
        %v13050_v41 = vand.u32 2147483648, %v126455_v9 (stack72)
        %v14217_v40 = vxor.u32 %v14216_v26, %v14212_v21 (stack48)
        %v15051_v31 = vxor.u32 %v15050_v22, %v15046_v8 (stack48)
        %v157160_v54 = vld [vmem:[#allocation72_spill] sm:$0xff] (stack84)
        %v15504_v56 = vadd.s32 %v157160_v54, %v157068_v28 (stack40)
        %119811 = vst [vmem:[%s123356_s30 + $0x8c] sm:$0xf] /*vst_source=*/%v12676_v7 (stack83)
        %v13046_v6 = vmul.f32 %v120540_v55, %v126455_v9 (stack74)
        %v13416_v20 = vor.u32 16256, %v13415_v43 (stack47)
        %v13811_v46 = vadd.s32 %v13808_v12, %v13803_v46 (stack40)
        %v13817_v24 = vshll.u32 %v13808_v12, 24 (stack45)
        %v13818_v29 = vshrl.u32 %v13808_v12, 8 (stack46)
        %v14220_v21 = vadd.s32 %v14217_v40, %v14212_v21 (stack40)
        %v14222_v10 = vshll.u32 %v14217_v40, 26 (stack45)
        %v14223_v27 = vshrl.u32 %v14217_v40, 6 (stack46)
        %v13048_v25 = vsel /*vm=*/%vm13047_vm4, /*on_true_vy=*/%v126455_v9, /*on_false_vx=*/%v13046_v6 (stack75)
        %vm13049_vm6 = vcmp.eq.f32.partialorder %v126455_v9, 0.0 (stack71)
        %v13417_v26 = vand.u32.u16 65535, %v13416_v20 (stack52)
        %v14626_v22 = vxor.u32 %v14625_v50, %v14621_v61 (stack48)
        %v13051_v7 = vsel /*vm=*/%vm13049_vm6, /*on_true_vy=*/%v13050_v41, /*on_false_vx=*/%v13048_v25 (stack76)
        %v13819_v43 = vor.u32 %v13818_v29, %v13817_v24 (stack47)
        %v14224_v12 = vor.u32 %v14223_v27, %v14222_v10 (stack47)
        %v15054_v8 = vadd.s32 %v15051_v31, %v15046_v8 (stack40)
        %v13054_v50 = vadd.f32 -3.0, %v13051_v7 (stack53)
        %v119814_v55 = vadd.low.f32.bf16 -1.0, %v13417_v26 (stack53)
        %v14629_v61 = vadd.s32 %v14626_v22, %v14621_v61 (stack40)
        %v14631_v41 = vshll.u32 %v14626_v22, 29 (stack45)
        %v13820_v40 = vxor.u32 %v13819_v43, %v13811_v46 (stack48)
        %v14225_v6 = vxor.u32 %v14224_v12, %v14220_v21 (stack48)
        %v14632_v20 = vshrl.u32 %v14626_v22, 3 (stack46)
        %v15056_v24 = vshll.u32 %v15051_v31, 26 (stack45)
        %v126523_v30 = vsel /*vm=*/%vm13002_vm3, /*on_true_vy=*/%v126488_v30, /*on_false_vx=*/%v13054_v50 (stack44)
        %v13426_v29 = vmul.f32 2.0, %v119814_v55 (stack54)
        %v15057_v31 = vshrl.u32 %v15051_v31, 6 (stack46)
        %v15508_v10 = vadd.s32 1, %v15504_v56 (stack40)
        %v13062_v60 = vmul.f32 %v126523_v30, %v13039_v60 (stack54)
        %v13823_v27 = vadd.s32 %v13820_v40, %v121564_v0 (stack40)
        %v14228_v21 = vadd.s32 %v14225_v6, %v14220_v21 (stack40)
        %v14234_v25 = vshll.u32 %v14225_v6, 6 (stack45)
        %v13430_v26 = vadd.f32 -0.99609375, %v13426_v29 (stack53)
        %v14235_v22 = vshrl.u32 %v14225_v6, 26 (stack46)
        %v14633_v7 = vor.u32 %v14632_v20, %v14631_v41 (stack47)
        %v15058_v43 = vor.u32 %v15057_v31, %v15056_v24 (stack47)
        %v13066_v11 = vadd.f32 %v13062_v60, %v126499_v11 (stack53)
        %v13815_v46 = vadd.s32 %v13811_v46, %v121569_v1 (stack40)
        %v13827_v12 = vadd.s32 4, %v13823_v27 (stack40)
        %v126532_v56 = vsel /*vm=*/%vm15499_vm5, /*on_true_vy=*/%v15508_v10, /*on_false_vx=*/%v15504_v56 (stack44)
        %v126534_v50 = vmax.f32 %v13430_v26, -0.99609375 (stack55)
        %v14236_v55 = vor.u32 %v14235_v22, %v14234_v25 (stack47)
        %v14634_v41 = vxor.u32 %v14633_v7, %v14629_v61 (stack48)
        %v15059_v40 = vxor.u32 %v15058_v43, %v15054_v8 (stack48)
        %v13070_v6 = vmul.f32 %v13066_v11, %v126523_v30 (stack54)
        %v13831_v20 = vadd.s32 %v13827_v12, %v13815_v46 (stack40)
        %v13833_v24 = vshll.u32 %v13827_v12, 13 (stack45)
        %v13834_v29 = vshrl.u32 %v13827_v12, 19 (stack46)
        %v13019_v31 = vsel /*vm=*/%vm13002_vm3, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v13031_v10 = vsel /*vm=*/%vm13002_vm3, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v13446_v60 = vxor.u32 2147483648, %v126534_v50 (stack56)
        %v14237_v27 = vxor.u32 %v14236_v55, %v14228_v21 (stack48)
        %v13023_v25 = vsel /*vm=*/%vm13002_vm3, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v13074_v26 = vadd.f32 %v13070_v6, %v13031_v10 (stack53)
        %v13835_v22 = vor.u32 %v13834_v29, %v13833_v24 (stack47)
        %v14637_v61 = vadd.s32 %v14634_v41, %v14629_v61 (stack40)
        %v13027_v7 = vsel /*vm=*/%vm13002_vm3, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v126551_v43 = vmul.f32 %v13446_v60, %v126534_v50 (stack54)
        %v14240_v11 = vadd.s32 %v14237_v27, %v121569_v1 (stack40)
        %v126556_v46 = vadd.s32 %v126479_v23, %v121569_v1 (stack40)
        %v13078_v12 = vmul.f32 %v13074_v26, %v126523_v30 (stack54)
        %v13836_v55 = vxor.u32 %v13835_v22, %v13831_v20 (stack48)
        %v14232_v21 = vadd.s32 %v14228_v21, %v121574_v2 (stack40)
        %v126560_v8 = vadd.s32 %v15059_v40, %v15054_v8 (stack40)
        %v13451_v6 = vadd.f32 1.0, %v126551_v43 (stack57)
        %v14244_v24 = vadd.s32 3, %v14240_v11 (stack40)
        %v14639_v29 = vshll.u32 %v14634_v41, 16 (stack45)
        %v14640_v41 = vshrl.u32 %v14634_v41, 16 (stack46)
        %v13082_v10 = vadd.f32 %v13078_v12, %v13027_v7 (stack53)
        %v13839_v20 = vadd.s32 %v13836_v55, %v13831_v20 (stack40)
        %v13841_v60 = vshll.u32 %v13836_v55, 15 (stack45)
        %v13842_v27 = vshrl.u32 %v13836_v55, 17 (stack46)
        %120541 = vlog2.f32 %v13451_v6 (stack58)
        %v13454_v26 = vmul.f32 -0.5, %v126551_v43 (stack59)
        %v14248_v22 = vadd.s32 %v14244_v24, %v14232_v21 (stack40)
        %v15068_v7 = vshll.u32 %v15059_v40, 6 (stack45)
        %v13086_v11 = vmul.f32 %v13082_v10, %v126523_v30 (stack54)
        %v13843_v12 = vor.u32 %v13842_v27, %v13841_v60 (stack47)
        %v14250_v55 = vshll.u32 %v14244_v24, 17 (stack45)
        %v14251_v21 = vshrl.u32 %v14244_v24, 15 (stack46)
        %v13457_v6 = vand.u32 2147483647, %v126551_v43 (stack60)
        %v14641_v24 = vor.u32 %v14640_v41, %v14639_v29 (stack47)
        %v15069_v40 = vshrl.u32 %v15059_v40, 26 (stack46)
        %vm15494_vm7 = vcmp.lt.u32.totalorder %v126479_v23, %v126435_v32 (stack43)
        %v13090_v25 = vadd.f32 %v13086_v11, %v13023_v25 (stack53)
        %v13844_v29 = vxor.u32 %v13843_v12, %v13839_v20 (stack48)
        %v14252_v41 = vor.u32 %v14251_v21, %v14250_v55 (stack47)
        %v15516_v10 = vadd.s32 1, %v126532_v56 (stack40)
        %v13455_v60 = vadd.f32 1.0, %v13454_v26 (stack61)
        %v14642_v27 = vxor.u32 %v14641_v24, %v14637_v61 (stack48)
        %v15070_v26 = vor.u32 %v15069_v40, %v15068_v7 (stack47)
        %v15535_v7 = vshll.u32 %v126556_v46, 13 (stack45)
        %v13094_v11 = vmul.f32 %v13090_v25, %v126523_v30 (stack54)
        %v13847_v20 = vadd.s32 %v13844_v29, %v13839_v20 (stack40)
        %v13849_v12 = vshll.u32 %v13844_v29, 26 (stack45)
        %v13850_v55 = vshrl.u32 %v13844_v29, 6 (stack46)
        %v14253_v21 = vxor.u32 %v14252_v41, %v14248_v22 (stack48)
        %v14645_v61 = vadd.s32 %v14642_v27, %v14637_v61 (stack40)
        %v14651_v24 = vshll.u32 %v14642_v27, 24 (stack45)
        %v14652_v40 = vshrl.u32 %v14642_v27, 8 (stack46)
        %v13098_v31 = vadd.f32 %v13094_v11, %v13019_v31 (stack53)
        %v13851_v25 = vor.u32 %v13850_v55, %v13849_v12 (stack47)
        %v15071_v29 = vxor.u32 %v15070_v26, %v126560_v8 (stack48)
        %v15520_v32 = vsel /*vm=*/%vm15494_vm7, /*on_true_vy=*/%v15516_v10, /*on_false_vx=*/%v126532_v56 (stack44)
        %v14256_v23 = vadd.s32 %v14253_v21, %v14248_v22 (stack40)
        %v14258_v56 = vshll.u32 %v14253_v21, 29 (stack45)
        %v14259_v22 = vshrl.u32 %v14253_v21, 3 (stack46)
        %v15536_v41 = vshrl.u32 %v126556_v46, 19 (stack46)
        %v13102_v10 = vmul.f32 %v13098_v31, %v126523_v30 (stack54)
        %v13852_v27 = vxor.u32 %v13851_v25, %v13847_v20 (stack48)
        %v14653_v26 = vor.u32 %v14652_v40, %v14651_v24 (stack47)
        %v15074_v11 = vadd.s32 %v15071_v29, %v121564_v0 (stack40)
        %v13456_v43 = vmul.f32 %v13455_v60, %v126551_v43 (stack63)
        %v14260_v60 = vor.u32 %v14259_v22, %v14258_v56 (stack47)
        %v15525_v12 = vadd.s32 %v15520_v32, %v121574_v2 (stack40)
        %v126583_v55 = vadd.s32 %v157155_v53, %v157070_v38 (stack40)
        %v13106_v42 = vadd.f32 %v13102_v10, %v126494_v42 (stack53)
        %v13855_v20 = vadd.s32 %v13852_v27, %v13847_v20 (stack40)
        %v13861_v21 = vshll.u32 %v13852_v27, 6 (stack45)
        %v13862_v24 = vshrl.u32 %v13852_v27, 26 (stack46)
        %v14261_v40 = vxor.u32 %v14260_v60, %v14256_v23 (stack48)
        %v14654_v31 = vxor.u32 %v14653_v26, %v14645_v61 (stack48)
        %v15078_v25 = vadd.s32 1, %v15074_v11 (stack40)
        %v15533_v46 = vadd.s32 %v126556_v46, %v15525_v12 (stack40)
        %v120542_v29 = vpop.eup %120541 (stack64)
        %v13110_v32 = vmul.f32 %v13106_v42, %v126523_v30 (stack54)
        %v13863_v56 = vor.u32 %v13862_v24, %v13861_v21 (stack47)
        %v15066_v8 = vadd.s32 %v126560_v8, %v121569_v1 (stack40)
        %v15537_v7 = vor.u32 %v15536_v41, %v15535_v7 (stack47)
        %v13453_v22 = vmul.f32 0.6931472, %v120542_v29 (stack65)
        %v14264_v23 = vadd.s32 %v14261_v40, %v14256_v23 (stack40)
        %v14266_v41 = vshll.u32 %v14261_v40, 16 (stack45)
        %v14267_v10 = vshrl.u32 %v14261_v40, 16 (stack46)
        %v13114_v34 = vadd.f32 %v13110_v32, %v126485_v34 (stack53)
        %vm13458_vm8 = vcmp.lt.f32.partialorder %v13457_v6, 0.0004427343 (stack62)
        %v13864_v6 = vxor.u32 %v13863_v56, %v13855_v20 (stack48)
        %v15082_v27 = vadd.s32 %v15078_v25, %v15066_v8 (stack40)
        %v13459_v26 = vsel /*vm=*/%vm13458_vm8, /*on_true_vy=*/%v13456_v43, /*on_false_vx=*/%v13453_v22 (stack66)
        %v14268_v11 = vor.u32 %v14267_v10, %v14266_v41 (stack47)
        %v14657_v43 = vadd.s32 %v14654_v31, %v121574_v2 (stack40)
        %v13118_v30 = vmul.f32 %v13114_v34, %v126523_v30 (stack54)
        %v126593_v60 = vxor.u32 2147483648, %v13459_v26 (stack56)
        %v15084_v12 = vshll.u32 %v15078_v25, 17 (stack45)
        %v15085_v42 = vshrl.u32 %v15078_v25, 15 (stack46)
        %v12983_v21 = vmul.f32 inf, %v126389_v44 (stack54)
        %v13007_v9 = vsel /*vm=*/%vm13002_vm3, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v14269_v24 = vxor.u32 %v14268_v11, %v14264_v23 (stack48)
        %v15538_v40 = vxor.u32 %v15537_v7, %v15533_v46 (stack48)
        %vm126601_vm9 = vcmp.eq.f32.partialorder %v12975_v52, 1.0 (stack68)
        %v13122_v31 = vadd.f32 %v13118_v30, %v13007_v9 (stack53)
        %vm13463_vm10 = vcmp.lt.f32.partialorder %v126593_v60, 5.0 (stack68)
        %120543 = vrsqrt.f32 %v126593_v60 (stack67)
        %v13436_v25 = vand.u32 2147483647, %v126534_v50 (stack77)
        %v13867_v29 = vadd.s32 %v13864_v6, %v121574_v2 (stack40)
        %v14272_v32 = vadd.s32 %v14269_v24, %v14264_v23 (stack40)
        %v14649_v61 = vadd.s32 %v14645_v61, %v121564_v0 (stack40)
        %v13126_v44 = vmul.f32 %v13122_v31, %v126389_v44 (stack54)
        %v13859_v20 = vadd.s32 %v13855_v20, %v121564_v0 (stack40)
        %v14661_v56 = vadd.s32 2, %v14657_v43 (stack40)
        %v15086_v8 = vor.u32 %v15085_v42, %v15084_v12 (stack47)
        %v126615_v7 = vsel /*vm=*/%vm13463_vm10, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v126620_v22 = vsel /*vm=*/%vm13463_vm10, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v126623_v23 = vadd.f32 -2.5, %v126593_v60 (stack53)
        %v126627_v41 = vadd.s32 %v126583_v55, %v122657_v58 (stack40)
        %v13130_v10 = vsel /*vm=*/%vm126601_vm9, /*on_true_vy=*/%v12983_v21, /*on_false_vx=*/%v13126_v44 (stack44)
        %v126634_v34 = vsel /*vm=*/%vm13463_vm10, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v126639_v6 = vsel /*vm=*/%vm13463_vm10, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v14276_v26 = vadd.s32 %v14272_v32, %v121569_v1 (stack40)
        %v13134_v11 = vmul.f32 1.4140625, %v13130_v10 (stack54)
        %v13871_v43 = vadd.s32 5, %v13867_v29 (stack40)
        %v14278_v30 = vshll.u32 %v14269_v24, 24 (stack45)
        %v14279_v12 = vshrl.u32 %v14269_v24, 8 (stack46)
        %v14665_v42 = vadd.s32 %v14661_v56, %v14649_v61 (stack40)
        %v14667_v21 = vshll.u32 %v14661_v56, 13 (stack45)
        %v14668_v9 = vshrl.u32 %v14661_v56, 19 (stack46)
        %v15087_v24 = vxor.u32 %v15086_v8, %v15082_v27 (stack48)
        %v13137_v52 = vpack.c.bf16 %v156663_v45, %v13134_v11 (stack81)
        %vm13508_vm11 = vcmp.eq.f32.partialorder %v126593_v60, inf (stack70)
        %v13873_v31 = vxor.u32 %v13871_v43, %v13859_v20 (stack48)
        %v14280_v29 = vor.u32 %v14279_v12, %v14278_v30 (stack47)
        %v15541_v46 = vadd.s32 %v15538_v40, %v15533_v46 (stack40)
        %v14669_v61 = vor.u32 %v14668_v9, %v14667_v21 (stack47)
        %v15090_v27 = vadd.s32 %v15087_v24, %v15082_v27 (stack40)
        %v15092_v44 = vshll.u32 %v15087_v24, 29 (stack45)
        %v15093_v20 = vshrl.u32 %v15087_v24, 3 (stack46)
        %119813 = vst [vmem:[%s123356_s30 + $0x10c] sm:$0xf] /*vst_source=*/%v13137_v52 (stack83)
        %v13874_v56 = vand.u32.u8 255, %v13873_v31 (stack49)
        %v14281_v32 = vxor.u32 %v14280_v29, %v14272_v32 (stack48)
        %v15543_v8 = vshll.u32 %v15538_v40, 15 (stack45)
        %v15544_v40 = vshrl.u32 %v15538_v40, 17 (stack46)
        %v14670_v10 = vxor.u32 %v14669_v61, %v14665_v42 (stack48)
        %v15094_v11 = vor.u32 %v15093_v20, %v15092_v44 (stack47)
        %vm15960_vm12 = vcmp.lt.u32.totalorder %v126583_v55, %v157070_v38 (stack43)
        %v15965_v43 = vadd.s32 %v157160_v54, %v157076_v35 (stack40)
        %vm13510_vm13 = vcmp.eq.f32.partialorder %v126593_v60, 0.0 (stack71)
        %v13875_v30 = vand.u32 65535, %v13874_v56 (stack50)
        %v14284_v12 = vadd.s32 %v14281_v32, %v121564_v0 (stack40)
        %v15545_v21 = vor.u32 %v15544_v40, %v15543_v8 (stack47)
        %v14673_v42 = vadd.s32 %v14670_v10, %v14665_v42 (stack40)
        %v14675_v9 = vshll.u32 %v14670_v10, 15 (stack45)
        %v14676_v24 = vshrl.u32 %v14670_v10, 17 (stack46)
        %v15095_v52 = vxor.u32 %v15094_v11, %v15090_v27 (stack48)
        %v120544_v31 = vpop.eup %120543 (stack73)
        %v13511_v29 = vand.u32 2147483648, %v126593_v60 (stack72)
        %v13876_v61 = vshrl.u32 %v13875_v30, 1 (stack51)
        %v14288_v44 = vadd.s32 4, %v14284_v12 (stack40)
        %v15546_v20 = vxor.u32 %v15545_v21, %v15541_v46 (stack48)
        %v13507_v56 = vmul.f32 %v120544_v31, %v126593_v60 (stack74)
        %v14677_v32 = vor.u32 %v14676_v24, %v14675_v9 (stack47)
        %v15098_v27 = vadd.s32 %v15095_v52, %v15090_v27 (stack40)
        %v15100_v8 = vshll.u32 %v15095_v52, 16 (stack45)
        %v13877_v40 = vor.u32 16256, %v13876_v61 (stack47)
        %v14292_v26 = vadd.s32 %v14288_v44, %v14276_v26 (stack40)
        %v14294_v10 = vshll.u32 %v14288_v44, 13 (stack45)
        %v14295_v11 = vshrl.u32 %v14288_v44, 19 (stack46)
        %v13509_v30 = vsel /*vm=*/%vm13508_vm11, /*on_true_vy=*/%v126593_v60, /*on_false_vx=*/%v13507_v56 (stack75)
        %v14678_v12 = vxor.u32 %v14677_v32, %v14673_v42 (stack48)
        %v15101_v21 = vshrl.u32 %v15095_v52, 16 (stack46)
        %v126656_v46 = vadd.s32 %v15546_v20, %v15541_v46 (stack40)
        %v13512_v9 = vsel /*vm=*/%vm13510_vm13, /*on_true_vy=*/%v13511_v29, /*on_false_vx=*/%v13509_v30 (stack76)
        %v13878_v24 = vand.u32.u16 65535, %v13877_v40 (stack52)
        %v14296_v52 = vor.u32 %v14295_v11, %v14294_v10 (stack47)
        %v15969_v31 = vadd.s32 1, %v15965_v43 (stack40)
        %v13515_v29 = vadd.f32 -3.0, %v13512_v9 (stack53)
        %v14681_v42 = vadd.s32 %v14678_v12, %v14673_v42 (stack40)
        %v14683_v61 = vshll.u32 %v14678_v12, 26 (stack45)
        %v14684_v44 = vshrl.u32 %v14678_v12, 6 (stack46)
        %v119816_v56 = vadd.low.f32.bf16 -1.0, %v13878_v24 (stack53)
        %v14297_v32 = vxor.u32 %v14296_v52, %v14292_v26 (stack48)
        %v15102_v8 = vor.u32 %v15101_v21, %v15100_v8 (stack47)
        %v15551_v40 = vshll.u32 %v15546_v20, 26 (stack45)
        %v126663_v23 = vsel /*vm=*/%vm13463_vm10, /*on_true_vy=*/%v126623_v23, /*on_false_vx=*/%v13515_v29 (stack44)
        %v14685_v10 = vor.u32 %v14684_v44, %v14683_v61 (stack47)
        %v15552_v20 = vshrl.u32 %v15546_v20, 6 (stack46)
        %v126668_v43 = vsel /*vm=*/%vm15960_vm12, /*on_true_vy=*/%v15969_v31, /*on_false_vx=*/%v15965_v43 (stack44)
        %v13523_v6 = vmul.f32 %v126663_v23, %v126639_v6 (stack54)
        %v13887_v11 = vmul.f32 2.0, %v119816_v56 (stack54)
        %v14300_v26 = vadd.s32 %v14297_v32, %v14292_v26 (stack40)
        %v14302_v30 = vshll.u32 %v14297_v32, 15 (stack45)
        %v13496_v12 = vsel /*vm=*/%vm13463_vm10, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v14303_v21 = vshrl.u32 %v14297_v32, 17 (stack46)
        %v14686_v9 = vxor.u32 %v14685_v10, %v14681_v42 (stack48)
        %v15103_v24 = vxor.u32 %v15102_v8, %v15098_v27 (stack48)
        %v13492_v52 = vsel /*vm=*/%vm13463_vm10, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v13527_v31 = vadd.f32 %v13523_v6, %v13496_v12 (stack53)
        %v13891_v29 = vadd.f32 -0.99609375, %v13887_v11 (stack53)
        %v126680_v61 = vadd.s32 %v126627_v41, %v121569_v1 (stack40)
        %v14304_v44 = vor.u32 %v14303_v21, %v14302_v30 (stack47)
        %v14689_v42 = vadd.s32 %v14686_v9, %v14681_v42 (stack40)
        %v14695_v56 = vshll.u32 %v14686_v9, 6 (stack45)
        %v14696_v32 = vshrl.u32 %v14686_v9, 26 (stack46)
        %v13531_v8 = vmul.f32 %v13527_v31, %v126663_v23 (stack54)
        %v126683_v10 = vmax.f32 %v13891_v29, -0.99609375 (stack55)
        %v15106_v27 = vadd.s32 %v15103_v24, %v15098_v27 (stack40)
        %v15553_v40 = vor.u32 %v15552_v20, %v15551_v40 (stack47)
        %v14305_v20 = vxor.u32 %v14304_v44, %v14300_v26 (stack48)
        %v14697_v6 = vor.u32 %v14696_v32, %v14695_v56 (stack47)
        %v15112_v11 = vshll.u32 %v15103_v24, 24 (stack45)
        %v15113_v30 = vshrl.u32 %v15103_v24, 8 (stack46)
        %v13484_v12 = vsel /*vm=*/%vm13463_vm10, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v13488_v21 = vsel /*vm=*/%vm13463_vm10, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v13535_v9 = vadd.f32 %v13531_v8, %v13492_v52 (stack53)
        %v13907_v24 = vxor.u32 2147483648, %v126683_v10 (stack56)
        %vm15955_vm14 = vcmp.lt.u32.totalorder %v126627_v41, %v126583_v55 (stack43)
        %v14308_v26 = vadd.s32 %v14305_v20, %v14300_v26 (stack40)
        %v14310_v52 = vshll.u32 %v14305_v20, 26 (stack45)
        %v14311_v31 = vshrl.u32 %v14305_v20, 6 (stack46)
        %v14698_v29 = vxor.u32 %v14697_v6, %v14689_v42 (stack48)
        %v13539_v44 = vmul.f32 %v13535_v9, %v126663_v23 (stack54)
        %v126696_v56 = vmul.f32 %v13907_v24, %v126683_v10 (stack54)
        %v15977_v32 = vadd.s32 1, %v126668_v43 (stack40)
        %v15996_v8 = vshll.u32 %v126680_v61, 13 (stack45)
        %v14312_v20 = vor.u32 %v14311_v31, %v14310_v52 (stack47)
        %v14701_v6 = vadd.s32 %v14698_v29, %v121569_v1 (stack40)
        %v15114_v11 = vor.u32 %v15113_v30, %v15112_v11 (stack47)
        %v15554_v40 = vxor.u32 %v15553_v40, %v126656_v46 (stack48)
        %v13543_v30 = vadd.f32 %v13539_v44, %v13488_v21 (stack53)
        %v13912_v21 = vadd.f32 1.0, %v126696_v56 (stack57)
        %v13915_v9 = vmul.f32 -0.5, %v126696_v56 (stack59)
        %v14693_v42 = vadd.s32 %v14689_v42, %v121574_v2 (stack40)
        %v14313_v24 = vxor.u32 %v14312_v20, %v14308_v26 (stack48)
        %v14705_v52 = vadd.s32 3, %v14701_v6 (stack40)
        %v15115_v31 = vxor.u32 %v15114_v11, %v15106_v27 (stack48)
        %v126706_v46 = vadd.s32 %v15554_v40, %v126656_v46 (stack40)
        %v13547_v29 = vmul.f32 %v13543_v30, %v126663_v23 (stack54)
        %120545 = vlog2.f32 %v13912_v21 (stack58)
        %v15110_v27 = vadd.s32 %v15106_v27, %v121564_v0 (stack40)
        %v15997_v44 = vshrl.u32 %v126680_v61, 19 (stack46)
        %v14316_v26 = vadd.s32 %v14313_v24, %v14308_v26 (stack40)
        %v14322_v20 = vshll.u32 %v14313_v24, 6 (stack45)
        %v14323_v6 = vshrl.u32 %v14313_v24, 26 (stack46)
        %v14709_v11 = vadd.s32 %v14705_v52, %v14693_v42 (stack40)
        %v13551_v12 = vadd.f32 %v13547_v29, %v13484_v12 (stack53)
        %v13918_v30 = vand.u32 2147483647, %v126696_v56 (stack60)
        %v14711_v21 = vshll.u32 %v14705_v52, 17 (stack45)
        %v14712_v42 = vshrl.u32 %v14705_v52, 15 (stack46)
        %v13916_v9 = vadd.f32 1.0, %v13915_v9 (stack61)
        %v14320_v24 = vadd.s32 %v14316_v26, %v121564_v0 (stack40)
        %v14324_v52 = vor.u32 %v14323_v6, %v14322_v20 (stack47)
        %v15118_v31 = vadd.s32 %v15115_v31, %v121574_v2 (stack40)
        %v13555_v29 = vmul.f32 %v13551_v12, %v126663_v23 (stack54)
        %v14713_v20 = vor.u32 %v14712_v42, %v14711_v21 (stack47)
        %v15563_v6 = vshll.u32 %v15554_v40, 6 (stack45)
        %v15564_v40 = vshrl.u32 %v15554_v40, 26 (stack46)
        %v14325_v26 = vxor.u32 %v14324_v52, %v14316_v26 (stack48)
        %v15122_v12 = vadd.s32 2, %v15118_v31 (stack40)
        %v15981_v55 = vsel /*vm=*/%vm15955_vm14, /*on_true_vy=*/%v15977_v32, /*on_false_vx=*/%v126668_v43 (stack44)
        %v15998_v41 = vor.u32 %v15997_v44, %v15996_v8 (stack47)
        %v13559_v34 = vadd.f32 %v13555_v29, %v126634_v34 (stack53)
        %v14714_v43 = vxor.u32 %v14713_v20, %v14709_v11 (stack48)
        %v15565_v32 = vor.u32 %v15564_v40, %v15563_v6 (stack47)
        %v15986_v8 = vadd.s32 %v15981_v55, %v121574_v2 (stack40)
        %vm126721_vm15 = vcmp.lt.f32.partialorder %v13918_v30, 0.0004427343 (stack62)
        %v14328_v30 = vadd.s32 %v14325_v26, %v121574_v2 (stack40)
        %v15126_v27 = vadd.s32 %v15122_v12, %v15110_v27 (stack40)
        %v15128_v21 = vshll.u32 %v15122_v12, 13 (stack45)
        %v15129_v42 = vshrl.u32 %v15122_v12, 19 (stack46)
        %v13563_v52 = vmul.f32 %v13559_v34, %v126663_v23 (stack54)
        %v14717_v11 = vadd.s32 %v14714_v43, %v14709_v11 (stack40)
        %v14719_v31 = vshll.u32 %v14714_v43, 29 (stack45)
        %v14720_v29 = vshrl.u32 %v14714_v43, 3 (stack46)
        %v14332_v20 = vadd.s32 5, %v14328_v30 (stack40)
        %v15130_v6 = vor.u32 %v15129_v42, %v15128_v21 (stack47)
        %v15566_v40 = vxor.u32 %v15565_v32, %v126706_v46 (stack48)
        %v15994_v61 = vadd.s32 %v126680_v61, %v15986_v8 (stack40)
        %v13567_v22 = vadd.f32 %v13563_v52, %v126620_v22 (stack53)
        %v14721_v26 = vor.u32 %v14720_v29, %v14719_v31 (stack47)
        %v126732_v12 = vadd.s32 %v157155_v53, %v157077_v51 (stack40)
        %v126736_v55 = vadd.s32 %v157160_v54, %v157078_v48 (stack40)
        %v14334_v24 = vxor.u32 %v14332_v20, %v14320_v24 (stack48)
        %v15131_v34 = vxor.u32 %v15130_v6, %v15126_v27 (stack48)
        %v15569_v43 = vadd.s32 %v15566_v40, %v121564_v0 (stack40)
        %v126739_v41 = vxor.u32 %v15998_v41, %v15994_v61 (stack48)
        %v13571_v32 = vmul.f32 %v13567_v22, %v126663_v23 (stack54)
        %v13917_v56 = vmul.f32 %v13916_v9, %v126696_v56 (stack63)
        %v14722_v9 = vxor.u32 %v14721_v26, %v14717_v11 (stack48)
        %vm16421_vm0 = vcmp.lt.u32.totalorder %v126732_v12, %v157077_v51 (stack43)
        %v120546_v8 = vpop.eup %120545 (stack64)
        %v14335_v30 = vand.u32.u8 255, %v14334_v24 (stack49)
        %v15134_v27 = vadd.s32 %v15131_v34, %v15126_v27 (stack40)
        %v15136_v21 = vshll.u32 %v15131_v34, 15 (stack45)
        %v15137_v42 = vshrl.u32 %v15131_v34, 17 (stack46)
        %v13575_v7 = vadd.f32 %v13571_v32, %v126615_v7 (stack53)
        %v13914_v52 = vmul.f32 0.6931472, %v120546_v8 (stack65)
        %v14725_v11 = vadd.s32 %v14722_v9, %v14717_v11 (stack40)
        %v14727_v31 = vshll.u32 %v14722_v9, 16 (stack45)
        %v14336_v29 = vand.u32 65535, %v14335_v30 (stack50)
        %v14728_v20 = vshrl.u32 %v14722_v9, 16 (stack46)
        %v15138_v6 = vor.u32 %v15137_v42, %v15136_v21 (stack47)
        %v15573_v40 = vadd.s32 1, %v15569_v43 (stack40)
        %v13579_v23 = vmul.f32 %v13575_v7, %v126663_v23 (stack54)
        %v13920_v44 = vsel /*vm=*/%vm126721_vm15, /*on_true_vy=*/%v13917_v56, /*on_false_vx=*/%v13914_v52 (stack66)
        %v15561_v46 = vadd.s32 %v126706_v46, %v121569_v1 (stack40)
        %v126752_v61 = vadd.s32 %v126739_v41, %v15994_v61 (stack40)
        %v13468_v60 = vsel /*vm=*/%vm13463_vm10, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v126757_v22 = vxor.u32 2147483648, %v13920_v44 (stack56)
        %v14729_v26 = vor.u32 %v14728_v20, %v14727_v31 (stack47)
        %v15139_v24 = vxor.u32 %v15138_v6, %v15134_v27 (stack48)
        %v13583_v34 = vadd.f32 %v13579_v23, %v13468_v60 (stack53)
        %v15577_v43 = vadd.s32 %v15573_v40, %v15561_v46 (stack40)
        %120547 = vrsqrt.f32 %v126757_v22 (stack67)
        %v14337_v32 = vshrl.u32 %v14336_v29, 1 (stack51)
        %v13444_v56 = vmul.f32 inf, %v126534_v50 (stack54)
        %v13587_v9 = vmul.f32 %v13583_v34, %v126534_v50 (stack54)
        %vm13924_vm1 = vcmp.lt.f32.partialorder %v126757_v22, 5.0 (stack68)
        %vm13439_vm2 = vcmp.eq.f32.partialorder %v13436_v25, 1.0 (stack68)
        %v13897_v50 = vand.u32 2147483647, %v126683_v10 (stack77)
        %v14730_v25 = vxor.u32 %v14729_v26, %v14725_v11 (stack48)
        %v126768_v8 = vadd.s32 %v126732_v12, %v122657_v58 (stack40)
        %v13591_v30 = vsel /*vm=*/%vm13439_vm2, /*on_true_vy=*/%v13444_v56, /*on_false_vx=*/%v13587_v9 (stack44)
        %v15579_v21 = vshll.u32 %v15573_v40, 17 (stack45)
        %v15580_v42 = vshrl.u32 %v15573_v40, 15 (stack46)
        %v16004_v7 = vshll.u32 %v126739_v41, 15 (stack45)
        %v13595_v52 = vmul.f32 1.4140625, %v13591_v30 (stack54)
        %v126774_v31 = vsel /*vm=*/%vm13924_vm1, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v126777_v29 = vadd.f32 -2.5, %v126757_v22 (stack53)
        %v14338_v20 = vor.u32 16256, %v14337_v32 (stack47)
        %v14733_v11 = vadd.s32 %v14730_v25, %v14725_v11 (stack40)
        %v14739_v6 = vshll.u32 %v14730_v25, 24 (stack45)
        %v14740_v40 = vshrl.u32 %v14730_v25, 8 (stack46)
        %v15142_v27 = vadd.s32 %v15139_v24, %v15134_v27 (stack40)
        %v13598_v23 = vpack.c.bf16 %v156663_v45, %v13595_v52 (stack81)
        %v14339_v44 = vand.u32.u16 65535, %v14338_v20 (stack52)
        %v15144_v46 = vshll.u32 %v15139_v24, 26 (stack45)
        %v15145_v60 = vshrl.u32 %v15139_v24, 6 (stack46)
        %v126783_v26 = vsel /*vm=*/%vm13924_vm1, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %vm13969_vm3 = vcmp.eq.f32.partialorder %v126757_v22, inf (stack70)
        %v14741_v24 = vor.u32 %v14740_v40, %v14739_v6 (stack47)
        %v15581_v34 = vor.u32 %v15580_v42, %v15579_v21 (stack47)
        %v16005_v41 = vshrl.u32 %v126739_v41, 17 (stack46)
        %119815 = vst [vmem:[%s123356_s30 + $0x18c] sm:$0xf] /*vst_source=*/%v13598_v23 (stack83)
        %v126791_v32 = vsel /*vm=*/%vm13924_vm1, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v119818_v56 = vadd.low.f32.bf16 -1.0, %v14339_v44 (stack53)
        %v15146_v9 = vor.u32 %v15145_v60, %v15144_v46 (stack47)
        %v16430_v25 = vadd.s32 1, %v126736_v55 (stack40)
        %v126797_v30 = vsel /*vm=*/%vm13924_vm1, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v14742_v21 = vxor.u32 %v14741_v24, %v14733_v11 (stack48)
        %v15582_v42 = vxor.u32 %v15581_v34, %v15577_v43 (stack48)
        %v16006_v7 = vor.u32 %v16005_v41, %v16004_v7 (stack47)
        %v14348_v52 = vmul.f32 2.0, %v119818_v56 (stack54)
        %v15147_v20 = vxor.u32 %v15146_v9, %v15142_v27 (stack48)
        %v126803_v55 = vsel /*vm=*/%vm16421_vm0, /*on_true_vy=*/%v16430_v25, /*on_false_vx=*/%v126736_v55 (stack44)
        %v126807_v6 = vadd.s32 %v157155_v53, %v157079_v39 (stack40)
        %v14745_v40 = vadd.s32 %v14742_v21, %v121564_v0 (stack40)
        %v15585_v43 = vadd.s32 %v15582_v42, %v15577_v43 (stack40)
        %v15587_v23 = vshll.u32 %v15582_v42, 29 (stack45)
        %v15588_v44 = vshrl.u32 %v15582_v42, 3 (stack46)
        %v14352_v46 = vadd.f32 -0.99609375, %v14348_v52 (stack53)
        %v15150_v27 = vadd.s32 %v15147_v20, %v15142_v27 (stack40)
        %v15156_v60 = vshll.u32 %v15147_v20, 6 (stack45)
        %v15157_v24 = vshrl.u32 %v15147_v20, 26 (stack46)
        %v120548_v34 = vpop.eup %120547 (stack73)
        %v14737_v11 = vadd.s32 %v14733_v11, %v121569_v1 (stack40)
        %v14749_v41 = vadd.s32 4, %v14745_v40 (stack40)
        %v15589_v56 = vor.u32 %v15588_v44, %v15587_v23 (stack47)
        %v126812_v9 = vxor.u32 %v16006_v7, %v126752_v61 (stack48)
        %v13968_v25 = vmul.f32 %v120548_v34, %v126757_v22 (stack74)
        %v13972_v21 = vand.u32 2147483648, %v126757_v22 (stack72)
        %v126816_v42 = vmax.f32 %v14352_v46, -0.99609375 (stack55)
        %v15158_v7 = vor.u32 %v15157_v24, %v15156_v60 (stack47)
        %v14753_v52 = vadd.s32 %v14749_v41, %v14737_v11 (stack40)
        %v14755_v20 = vshll.u32 %v14749_v41, 13 (stack45)
        %v14756_v40 = vshrl.u32 %v14749_v41, 19 (stack46)
        %v15590_v23 = vxor.u32 %v15589_v56, %v15585_v43 (stack48)
        %v13957_v44 = vsel /*vm=*/%vm13924_vm1, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v13970_v46 = vsel /*vm=*/%vm13969_vm3, /*on_true_vy=*/%v126757_v22, /*on_false_vx=*/%v13968_v25 (stack75)
        %vm13971_vm4 = vcmp.eq.f32.partialorder %v126757_v22, 0.0 (stack71)
        %v14368_v60 = vxor.u32 2147483648, %v126816_v42 (stack56)
        %v13973_v24 = vsel /*vm=*/%vm13971_vm4, /*on_true_vy=*/%v13972_v21, /*on_false_vx=*/%v13970_v46 (stack76)
        %v14757_v34 = vor.u32 %v14756_v40, %v14755_v20 (stack47)
        %v15159_v11 = vxor.u32 %v15158_v7, %v15150_v27 (stack48)
        %v15593_v43 = vadd.s32 %v15590_v23, %v15585_v43 (stack40)
        %v13961_v41 = vsel /*vm=*/%vm13924_vm1, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v13976_v56 = vadd.f32 -3.0, %v13973_v24 (stack53)
        %v126830_v25 = vmul.f32 %v14368_v60, %v126816_v42 (stack54)
        %v15595_v21 = vshll.u32 %v15590_v23, 16 (stack45)
        %v14758_v7 = vxor.u32 %v14757_v34, %v14753_v52 (stack48)
        %v15162_v20 = vadd.s32 %v15159_v11, %v121569_v1 (stack40)
        %v15596_v40 = vshrl.u32 %v15590_v23, 16 (stack46)
        %v16010_v61 = vadd.s32 %v126812_v9, %v126752_v61 (stack40)
        %v126838_v29 = vsel /*vm=*/%vm13924_vm1, /*on_true_vy=*/%v126777_v29, /*on_false_vx=*/%v13976_v56 (stack44)
        %v14373_v23 = vadd.f32 1.0, %v126830_v25 (stack57)
        %vm16416_vm5 = vcmp.lt.u32.totalorder %v126768_v8, %v126732_v12 (stack43)
        %v16451_v46 = vadd.s32 %v126768_v8, %v121569_v1 (stack40)
        %v13984_v60 = vmul.f32 %v126838_v29, %v13961_v41 (stack54)
        %v14761_v52 = vadd.s32 %v14758_v7, %v14753_v52 (stack40)
        %v14763_v24 = vshll.u32 %v14758_v7, 15 (stack45)
        %v14764_v34 = vshrl.u32 %v14758_v7, 17 (stack46)
        %120549 = vlog2.f32 %v14373_v23 (stack58)
        %v15154_v27 = vadd.s32 %v15150_v27, %v121574_v2 (stack40)
        %v15166_v11 = vadd.s32 3, %v15162_v20 (stack40)
        %v16438_v41 = vadd.s32 1, %v126803_v55 (stack40)
        %v13988_v44 = vadd.f32 %v13984_v60, %v13957_v44 (stack53)
        %v14376_v56 = vmul.f32 -0.5, %v126830_v25 (stack59)
        %v14765_v7 = vor.u32 %v14764_v34, %v14763_v24 (stack47)
        %v15597_v21 = vor.u32 %v15596_v40, %v15595_v21 (stack47)
        %v15170_v20 = vadd.s32 %v15166_v11, %v15154_v27 (stack40)
        %v15172_v40 = vshll.u32 %v15166_v11, 17 (stack45)
        %v15173_v23 = vshrl.u32 %v15166_v11, 15 (stack46)
        %v16012_v60 = vshll.u32 %v126812_v9, 26 (stack45)
        %v13992_v24 = vmul.f32 %v13988_v44, %v126838_v29 (stack54)
        %v14766_v34 = vxor.u32 %v14765_v7, %v14761_v52 (stack48)
        %v15598_v27 = vxor.u32 %v15597_v21, %v15593_v43 (stack48)
        %v16013_v9 = vshrl.u32 %v126812_v9, 6 (stack46)
        %v15174_v11 = vor.u32 %v15173_v23, %v15172_v40 (stack47)
        %v16442_v12 = vsel /*vm=*/%vm16416_vm5, /*on_true_vy=*/%v16438_v41, /*on_false_vx=*/%v126803_v55 (stack44)
        %v16457_v8 = vshll.u32 %v16451_v46, 13 (stack45)
        %v16458_v55 = vshrl.u32 %v16451_v46, 19 (stack46)
        %v13996_v30 = vadd.f32 %v13992_v24, %v126797_v30 (stack53)
        %v14769_v52 = vadd.s32 %v14766_v34, %v14761_v52 (stack40)
        %v14771_v41 = vshll.u32 %v14766_v34, 26 (stack45)
        %v14772_v44 = vshrl.u32 %v14766_v34, 6 (stack46)
        %v15175_v7 = vxor.u32 %v15174_v11, %v15170_v20 (stack48)
        %v15601_v43 = vadd.s32 %v15598_v27, %v15593_v43 (stack40)
        %v15607_v21 = vshll.u32 %v15598_v27, 24 (stack45)
        %v15608_v40 = vshrl.u32 %v15598_v27, 8 (stack46)
        %v14000_v23 = vmul.f32 %v13996_v30, %v126838_v29 (stack54)
        %v14773_v24 = vor.u32 %v14772_v44, %v14771_v41 (stack47)
        %v16014_v60 = vor.u32 %v16013_v9, %v16012_v60 (stack47)
        %v16447_v34 = vadd.s32 %v16442_v12, %v121574_v2 (stack40)
        %v14377_v56 = vadd.f32 1.0, %v14376_v56 (stack61)
        %v15178_v20 = vadd.s32 %v15175_v7, %v15170_v20 (stack40)
        %v15180_v27 = vshll.u32 %v15175_v7, 29 (stack45)
        %v15181_v9 = vshrl.u32 %v15175_v7, 3 (stack46)
        %v14004_v32 = vadd.f32 %v14000_v23, %v126791_v32 (stack53)
        %v14774_v11 = vxor.u32 %v14773_v24, %v14769_v52 (stack48)
        %v15609_v12 = vor.u32 %v15608_v40, %v15607_v21 (stack47)
        %v16015_v30 = vxor.u32 %v16014_v60, %v16010_v61 (stack48)
        %v14379_v41 = vand.u32 2147483647, %v126830_v25 (stack60)
        %v15182_v44 = vor.u32 %v15181_v9, %v15180_v27 (stack47)
        %v16455_v46 = vadd.s32 %v16451_v46, %v16447_v34 (stack40)
        %v16459_v8 = vor.u32 %v16458_v55, %v16457_v8 (stack47)
        %v14008_v55 = vmul.f32 %v14004_v32, %v126838_v29 (stack54)
        %v14777_v52 = vadd.s32 %v14774_v11, %v14769_v52 (stack40)
        %v14783_v7 = vshll.u32 %v14774_v11, 6 (stack45)
        %v14784_v21 = vshrl.u32 %v14774_v11, 26 (stack46)
        %v15183_v40 = vxor.u32 %v15182_v44, %v15178_v20 (stack48)
        %v15610_v23 = vxor.u32 %v15609_v12, %v15601_v43 (stack48)
        %v16018_v61 = vadd.s32 %v16015_v30, %v16010_v61 (stack40)
        %v16024_v24 = vshll.u32 %v16015_v30, 6 (stack45)
        %v120550_v60 = vpop.eup %120549 (stack64)
        %v14012_v26 = vadd.f32 %v14008_v55, %v126783_v26 (stack53)
        %v14378_v25 = vmul.f32 %v14377_v56, %v126830_v25 (stack63)
        %v14785_v34 = vor.u32 %v14784_v21, %v14783_v7 (stack47)
        %v16025_v56 = vshrl.u32 %v16015_v30, 26 (stack46)
        %v14375_v27 = vmul.f32 0.6931472, %v120550_v60 (stack65)
        %v15186_v20 = vadd.s32 %v15183_v40, %v15178_v20 (stack40)
        %v15188_v9 = vshll.u32 %v15183_v40, 16 (stack45)
        %v15189_v32 = vshrl.u32 %v15183_v40, 16 (stack46)
        %v14016_v11 = vmul.f32 %v14012_v26, %v126838_v29 (stack54)
        %vm14380_vm6 = vcmp.lt.f32.partialorder %v14379_v41, 0.0004427343 (stack62)
        %v14786_v12 = vxor.u32 %v14785_v34, %v14777_v52 (stack48)
        %v15613_v30 = vadd.s32 %v15610_v23, %v121574_v2 (stack40)
        %v14381_v41 = vsel /*vm=*/%vm14380_vm6, /*on_true_vy=*/%v14378_v25, /*on_false_vx=*/%v14375_v27 (stack66)
        %v15190_v44 = vor.u32 %v15189_v32, %v15188_v9 (stack47)
        %v16026_v55 = vor.u32 %v16025_v56, %v16024_v24 (stack47)
        %v16460_v8 = vxor.u32 %v16459_v8, %v16455_v46 (stack48)
        %v126867_v7 = vmul.f32 inf, %v126683_v10 (stack54)
        %v13929_v21 = vsel /*vm=*/%vm13924_vm1, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v14020_v31 = vadd.f32 %v14016_v11, %v126774_v31 (stack53)
        %v126873_v40 = vxor.u32 2147483648, %v14381_v41 (stack56)
        %v13933_v23 = vsel /*vm=*/%vm13924_vm1, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v15191_v24 = vxor.u32 %v15190_v44, %v15186_v20 (stack48)
        %v16027_v60 = vxor.u32 %v16026_v55, %v16018_v61 (stack48)
        %v16463_v46 = vadd.s32 %v16460_v8, %v16455_v46 (stack40)
        %v13937_v22 = vsel /*vm=*/%vm13924_vm1, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v14024_v26 = vmul.f32 %v14020_v31, %v126838_v29 (stack54)
        %vm14385_vm7 = vcmp.lt.f32.partialorder %v126873_v40, 5.0 (stack68)
        %120551 = vrsqrt.f32 %v126873_v40 (stack67)
        %v14358_v25 = vand.u32 2147483647, %v126816_v42 (stack77)
        %v14789_v34 = vadd.s32 %v14786_v12, %v121574_v2 (stack40)
        %v15194_v56 = vadd.s32 %v15191_v24, %v15186_v20 (stack40)
        %v15617_v27 = vadd.s32 2, %v15613_v30 (stack40)
        %v14028_v20 = vadd.f32 %v14024_v26, %v13937_v22 (stack53)
        %v14781_v52 = vadd.s32 %v14777_v52, %v121564_v0 (stack40)
        %v15605_v43 = vadd.s32 %v15601_v43, %v121564_v0 (stack40)
        %v126890_v9 = vadd.s32 %v126807_v6, %v122657_v58 (stack40)
        %v126895_v32 = vsel /*vm=*/%vm14385_vm7, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v126898_v11 = vadd.f32 -2.5, %v126873_v40 (stack53)
        %v16022_v61 = vadd.s32 %v16018_v61, %v121569_v1 (stack40)
        %v16465_v12 = vshll.u32 %v16460_v8, 15 (stack45)
        %v14032_v30 = vmul.f32 %v14028_v20, %v126838_v29 (stack54)
        %v126905_v41 = vsel /*vm=*/%vm14385_vm7, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v126910_v44 = vsel /*vm=*/%vm14385_vm7, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v15198_v55 = vadd.s32 %v15194_v56, %v121569_v1 (stack40)
        %vm126915_vm8 = vcmp.eq.f32.partialorder %v13897_v50, 1.0 (stack68)
        %v14793_v31 = vadd.s32 5, %v14789_v34 (stack40)
        %v15200_v22 = vshll.u32 %v15191_v24, 24 (stack45)
        %v15201_v24 = vshrl.u32 %v15191_v24, 8 (stack46)
        %v15621_v26 = vadd.s32 %v15617_v27, %v15605_v43 (stack40)
        %v14036_v23 = vadd.f32 %v14032_v30, %v13933_v23 (stack53)
        %v15623_v34 = vshll.u32 %v15617_v27, 13 (stack45)
        %v15624_v27 = vshrl.u32 %v15617_v27, 19 (stack46)
        %v16030_v60 = vadd.s32 %v16027_v60, %v121564_v0 (stack40)
        %vm14430_vm9 = vcmp.eq.f32.partialorder %v126873_v40, inf (stack70)
        %v14433_v20 = vand.u32 2147483648, %v126873_v40 (stack72)
        %v14795_v52 = vxor.u32 %v14793_v31, %v14781_v52 (stack48)
        %v15202_v43 = vor.u32 %v15201_v24, %v15200_v22 (stack47)
        %v16466_v8 = vshrl.u32 %v16460_v8, 17 (stack46)
        %v14040_v29 = vmul.f32 %v14036_v23, %v126838_v29 (stack54)
        %vm14432_vm10 = vcmp.eq.f32.partialorder %v126873_v40, 0.0 (stack71)
        %v15625_v30 = vor.u32 %v15624_v27, %v15623_v34 (stack47)
        %v16034_v31 = vadd.s32 1, %v16030_v60 (stack40)
        %vm16882_vm11 = vcmp.lt.u32.totalorder %v126807_v6, %v157079_v39 (stack43)
        %v14796_v22 = vand.u32.u8 255, %v14795_v52 (stack49)
        %v15203_v56 = vxor.u32 %v15202_v43, %v15194_v56 (stack48)
        %v16467_v12 = vor.u32 %v16466_v8, %v16465_v12 (stack47)
        %v126928_v24 = vadd.s32 %v157160_v54, %v157082_v49 (stack40)
        %v14044_v21 = vadd.f32 %v14040_v29, %v13929_v21 (stack53)
        %v15626_v23 = vxor.u32 %v15625_v30, %v15621_v26 (stack48)
        %v16038_v61 = vadd.s32 %v16034_v31, %v16022_v61 (stack40)
        %v16040_v34 = vshll.u32 %v16034_v31, 17 (stack45)
        %v14797_v27 = vand.u32 65535, %v14796_v22 (stack50)
        %v15206_v60 = vadd.s32 %v15203_v56, %v121564_v0 (stack40)
        %v16041_v52 = vshrl.u32 %v16034_v31, 15 (stack46)
        %v16468_v43 = vxor.u32 %v16467_v12, %v16463_v46 (stack48)
        %v14048_v10 = vmul.f32 %v14044_v21, %v126683_v10 (stack54)
        %v15629_v26 = vadd.s32 %v15626_v23, %v15621_v26 (stack40)
        %v15631_v8 = vshll.u32 %v15626_v23, 15 (stack45)
        %v15632_v29 = vshrl.u32 %v15626_v23, 17 (stack46)
        %v120552_v30 = vpop.eup %120551 (stack73)
        %v14798_v31 = vshrl.u32 %v14797_v27, 1 (stack51)
        %v15210_v22 = vadd.s32 4, %v15206_v60 (stack40)
        %v16042_v56 = vor.u32 %v16041_v52, %v16040_v34 (stack47)
        %v126932_v46 = vadd.s32 %v16468_v43, %v16463_v46 (stack40)
        %v14052_v7 = vsel /*vm=*/%vm126915_vm8, /*on_true_vy=*/%v126867_v7, /*on_false_vx=*/%v14048_v10 (stack44)
        %v14429_v50 = vmul.f32 %v120552_v30, %v126873_v40 (stack74)
        %v15633_v12 = vor.u32 %v15632_v29, %v15631_v8 (stack47)
        %v16473_v21 = vshll.u32 %v16468_v43, 26 (stack45)
        %v14056_v23 = vmul.f32 1.4140625, %v14052_v7 (stack54)
        %v14799_v34 = vor.u32 16256, %v14798_v31 (stack47)
        %v15214_v55 = vadd.s32 %v15210_v22, %v15198_v55 (stack40)
        %v15216_v27 = vshll.u32 %v15210_v22, 13 (stack45)
        %v14431_v60 = vsel /*vm=*/%vm14430_vm9, /*on_true_vy=*/%v126873_v40, /*on_false_vx=*/%v14429_v50 (stack75)
        %v15217_v52 = vshrl.u32 %v15210_v22, 19 (stack46)
        %v15634_v10 = vxor.u32 %v15633_v12, %v15629_v26 (stack48)
        %v16043_v8 = vxor.u32 %v16042_v56, %v16038_v61 (stack48)
        %v14059_v29 = vpack.c.bf16 %v156663_v45, %v14056_v23 (stack81)
        %v14434_v20 = vsel /*vm=*/%vm14432_vm10, /*on_true_vy=*/%v14433_v20, /*on_false_vx=*/%v14431_v60 (stack76)
        %v14800_v30 = vand.u32.u16 65535, %v14799_v34 (stack52)
        %v16474_v43 = vshrl.u32 %v16468_v43, 6 (stack46)
        %v14437_v31 = vadd.f32 -3.0, %v14434_v20 (stack53)
        %v15218_v22 = vor.u32 %v15217_v52, %v15216_v27 (stack47)
        %v15637_v26 = vadd.s32 %v15634_v10, %v15629_v26 (stack40)
        %v15639_v56 = vshll.u32 %v15634_v10, 26 (stack45)
        %119817 = vst [vmem:[%s123356_s30 + $0x20c] sm:$0xf] /*vst_source=*/%v14059_v29 (stack83)
        %v119820_v7 = vadd.low.f32.bf16 -1.0, %v14800_v30 (stack53)
        %v15640_v50 = vshrl.u32 %v15634_v10, 6 (stack46)
        %v16046_v61 = vadd.s32 %v16043_v8, %v16038_v61 (stack40)
        %v16048_v12 = vshll.u32 %v16043_v8, 29 (stack45)
        %v126948_v11 = vsel /*vm=*/%vm14385_vm7, /*on_true_vy=*/%v126898_v11, /*on_false_vx=*/%v14437_v31 (stack44)
        %v15219_v23 = vxor.u32 %v15218_v22, %v15214_v55 (stack48)
        %v16049_v34 = vshrl.u32 %v16043_v8, 3 (stack46)
        %v16475_v21 = vor.u32 %v16474_v43, %v16473_v21 (stack47)
        %v14445_v44 = vmul.f32 %v126948_v11, %v126910_v44 (stack54)
        %v14809_v27 = vmul.f32 2.0, %v119820_v7 (stack54)
        %v15641_v60 = vor.u32 %v15640_v50, %v15639_v56 (stack47)
        %v16891_v52 = vadd.s32 1, %v126928_v24 (stack40)
        %v15222_v55 = vadd.s32 %v15219_v23, %v15214_v55 (stack40)
        %v15224_v10 = vshll.u32 %v15219_v23, 15 (stack45)
        %v15225_v8 = vshrl.u32 %v15219_v23, 17 (stack46)
        %v16050_v29 = vor.u32 %v16049_v34, %v16048_v12 (stack47)
        %v14449_v41 = vadd.f32 %v14445_v44, %v126905_v41 (stack53)
        %v14813_v20 = vadd.f32 -0.99609375, %v14809_v27 (stack53)
        %v15642_v30 = vxor.u32 %v15641_v60, %v15637_v26 (stack48)
        %v126955_v43 = vxor.u32 %v16475_v21, %v126932_v46 (stack48)
        %v126960_v31 = vsel /*vm=*/%vm14385_vm7, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v15226_v22 = vor.u32 %v15225_v8, %v15224_v10 (stack47)
        %v16051_v56 = vxor.u32 %v16050_v29, %v16046_v61 (stack48)
        %v126966_v24 = vsel /*vm=*/%vm16882_vm11, /*on_true_vy=*/%v16891_v52, /*on_false_vx=*/%v126928_v24 (stack44)
        %v14453_v7 = vmul.f32 %v14449_v41, %v126948_v11 (stack54)
        %v126969_v50 = vmax.f32 %v14813_v20, -0.99609375 (stack55)
        %v15645_v26 = vadd.s32 %v15642_v30, %v15637_v26 (stack40)
        %v15651_v12 = vshll.u32 %v15642_v30, 6 (stack45)
        %v14414_v23 = vsel /*vm=*/%vm14385_vm7, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v15227_v34 = vxor.u32 %v15226_v22, %v15222_v55 (stack48)
        %v15652_v21 = vshrl.u32 %v15642_v30, 26 (stack46)
        %v16054_v61 = vadd.s32 %v16051_v56, %v16046_v61 (stack40)
        %v14402_v44 = vsel /*vm=*/%vm14385_vm7, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v14406_v27 = vsel /*vm=*/%vm14385_vm7, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v14457_v60 = vadd.f32 %v14453_v7, %v14414_v23 (stack53)
        %v14829_v52 = vxor.u32 2147483648, %v126969_v50 (stack56)
        %v15230_v55 = vadd.s32 %v15227_v34, %v15222_v55 (stack40)
        %v15232_v10 = vshll.u32 %v15227_v34, 26 (stack45)
        %v15233_v8 = vshrl.u32 %v15227_v34, 6 (stack46)
        %v16056_v29 = vshll.u32 %v16051_v56, 16 (stack45)
        %v14410_v41 = vsel /*vm=*/%vm14385_vm7, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v14461_v20 = vmul.f32 %v14457_v60, %v126948_v11 (stack54)
        %v14832_v30 = vmul.f32 %v14829_v52, %v126969_v50 (stack54)
        %v15653_v22 = vor.u32 %v15652_v21, %v15651_v12 (stack47)
        %v15234_v7 = vor.u32 %v15233_v8, %v15232_v10 (stack47)
        %v16057_v56 = vshrl.u32 %v16051_v56, 16 (stack46)
        %v16479_v46 = vadd.s32 %v126955_v43, %v126932_v46 (stack40)
        %vm16877_vm12 = vcmp.lt.u32.totalorder %v126890_v9, %v126807_v6 (stack43)
        %v14465_v12 = vadd.f32 %v14461_v20, %v14410_v41 (stack53)
        %v14834_v23 = vadd.f32 1.0, %v14832_v30 (stack57)
        %v14837_v34 = vmul.f32 -0.5, %v14832_v30 (stack59)
        %v126992_v21 = vadd.s32 %v126890_v9, %v121569_v1 (stack40)
        %v15235_v60 = vxor.u32 %v15234_v7, %v15230_v55 (stack48)
        %v15649_v52 = vadd.s32 %v15645_v26, %v121574_v2 (stack40)
        %v15654_v26 = vxor.u32 %v15653_v22, %v15645_v26 (stack48)
        %v16058_v10 = vor.u32 %v16057_v56, %v16056_v29 (stack47)
        %v14469_v8 = vmul.f32 %v14465_v12, %v126948_v11 (stack54)
        %120553 = vlog2.f32 %v14834_v23 (stack58)
        %v14840_v29 = vand.u32 2147483647, %v14832_v30 (stack60)
        %v16485_v41 = vshll.u32 %v126955_v43, 6 (stack45)
        %v15238_v55 = vadd.s32 %v15235_v60, %v15230_v55 (stack40)
        %v15244_v20 = vshll.u32 %v15235_v60, 6 (stack45)
        %v15245_v22 = vshrl.u32 %v15235_v60, 26 (stack46)
        %v15657_v7 = vadd.s32 %v15654_v26, %v121569_v1 (stack40)
        %v14473_v27 = vadd.f32 %v14469_v8, %v14406_v27 (stack53)
        %v14838_v56 = vadd.f32 1.0, %v14837_v34 (stack61)
        %v16059_v12 = vxor.u32 %v16058_v10, %v16054_v61 (stack48)
        %v16486_v43 = vshrl.u32 %v126955_v43, 26 (stack46)
        %v15246_v23 = vor.u32 %v15245_v22, %v15244_v20 (stack47)
        %v15661_v34 = vadd.s32 3, %v15657_v7 (stack40)
        %v16483_v60 = vadd.s32 %v16479_v46, %v121569_v1 (stack40)
        %v16899_v26 = vadd.s32 1, %v126966_v24 (stack40)
        %v14477_v10 = vmul.f32 %v14473_v27, %v126948_v11 (stack54)
        %v16062_v61 = vadd.s32 %v16059_v12, %v16054_v61 (stack40)
        %v16068_v8 = vshll.u32 %v16059_v12, 24 (stack45)
        %v16069_v20 = vshrl.u32 %v16059_v12, 8 (stack46)
        %v15247_v22 = vxor.u32 %v15246_v23, %v15238_v55 (stack48)
        %v15665_v52 = vadd.s32 %v15661_v34, %v15649_v52 (stack40)
        %v15667_v7 = vshll.u32 %v15661_v34, 17 (stack45)
        %v15668_v27 = vshrl.u32 %v15661_v34, 15 (stack46)
        %v14481_v44 = vadd.f32 %v14477_v10, %v14402_v44 (stack53)
        %v14839_v30 = vmul.f32 %v14838_v56, %v14832_v30 (stack63)
        %v16070_v56 = vor.u32 %v16069_v20, %v16068_v8 (stack47)
        %v16487_v41 = vor.u32 %v16486_v43, %v16485_v41 (stack47)
        %vm127002_vm13 = vcmp.lt.f32.partialorder %v14840_v29, 0.0004427343 (stack62)
        %v15242_v55 = vadd.s32 %v15238_v55, %v121564_v0 (stack40)
        %v15250_v12 = vadd.s32 %v15247_v22, %v121574_v2 (stack40)
        %v15669_v43 = vor.u32 %v15668_v27, %v15667_v7 (stack47)
        %v16903_v6 = vsel /*vm=*/%vm16877_vm12, /*on_true_vy=*/%v16899_v26, /*on_false_vx=*/%v126966_v24 (stack44)
        %v14485_v9 = vmul.f32 %v14481_v44, %v126948_v11 (stack54)
        %v16071_v24 = vxor.u32 %v16070_v56, %v16062_v61 (stack48)
        %v16488_v46 = vxor.u32 %v16487_v41, %v16479_v46 (stack48)
        %v16908_v23 = vadd.s32 %v16903_v6, %v121574_v2 (stack40)
        %v15254_v34 = vadd.s32 5, %v15250_v12 (stack40)
        %v15670_v26 = vxor.u32 %v15669_v43, %v15665_v52 (stack48)
        %v16066_v10 = vadd.s32 %v16062_v61, %v121564_v0 (stack40)
        %v127017_v61 = vadd.s32 %v157155_v53, %v157083_v59 (stack40)
        %v14489_v31 = vadd.f32 %v14485_v9, %v126960_v31 (stack53)
        %v16074_v8 = vadd.s32 %v16071_v24, %v121574_v2 (stack40)
        %v16491_v20 = vadd.s32 %v16488_v46, %v121564_v0 (stack40)
        %v127023_v22 = vadd.s32 %v126992_v21, %v16908_v23 (stack40)
        %v15256_v7 = vxor.u32 %v15254_v34, %v15242_v55 (stack48)
        %v15673_v52 = vadd.s32 %v15670_v26, %v15665_v52 (stack40)
        %v15675_v27 = vshll.u32 %v15670_v26, 29 (stack45)
        %v15676_v44 = vshrl.u32 %v15670_v26, 3 (stack46)
        %v14493_v56 = vmul.f32 %v14489_v31, %v126948_v11 (stack54)
        %v16078_v41 = vadd.s32 2, %v16074_v8 (stack40)
        %v16495_v55 = vadd.s32 1, %v16491_v20 (stack40)
        %v16918_v12 = vshll.u32 %v126992_v21, 13 (stack45)
        %v120554_v43 = vpop.eup %120553 (stack64)
        %v15257_v6 = vand.u32.u8 255, %v15256_v7 (stack49)
        %v15677_v9 = vor.u32 %v15676_v44, %v15675_v27 (stack47)
        %v16919_v21 = vshrl.u32 %v126992_v21, 19 (stack46)
        %vm17343_vm14 = vcmp.lt.u32.totalorder %v127017_v61, %v157083_v59 (stack43)
        %v14497_v32 = vadd.f32 %v14493_v56, %v126895_v32 (stack53)
        %v14836_v24 = vmul.f32 0.6931472, %v120554_v43 (stack65)
        %v16082_v46 = vadd.s32 %v16078_v41, %v16066_v10 (stack40)
        %v16084_v23 = vshll.u32 %v16078_v41, 13 (stack45)
        %v15258_v34 = vand.u32 65535, %v15257_v6 (stack50)
        %v15678_v26 = vxor.u32 %v15677_v9, %v15673_v52 (stack48)
        %v16085_v10 = vshrl.u32 %v16078_v41, 19 (stack46)
        %v16499_v60 = vadd.s32 %v16495_v55, %v16483_v60 (stack40)
        %v14501_v11 = vmul.f32 %v14497_v32, %v126948_v11 (stack54)
        %v14842_v30 = vsel /*vm=*/%vm127002_vm13, /*on_true_vy=*/%v14839_v30, /*on_false_vx=*/%v14836_v24 (stack66)
        %v16501_v29 = vshll.u32 %v16495_v55, 17 (stack45)
        %v16502_v31 = vshrl.u32 %v16495_v55, 15 (stack46)
        %v14390_v40 = vsel /*vm=*/%vm14385_vm7, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v127037_v8 = vxor.u32 2147483648, %v14842_v30 (stack56)
        %v15681_v20 = vadd.s32 %v15678_v26, %v15673_v52 (stack40)
        %v15683_v7 = vshll.u32 %v15678_v26, 16 (stack45)
        %v14505_v52 = vadd.f32 %v14501_v11, %v14390_v40 (stack53)
        %v15684_v27 = vshrl.u32 %v15678_v26, 16 (stack46)
        %v14366_v44 = vmul.f32 inf, %v126816_v42 (stack54)
        %120555 = vrsqrt.f32 %v127037_v8 (stack67)
        %v15259_v56 = vshrl.u32 %v15258_v34, 1 (stack51)
        %v14509_v41 = vmul.f32 %v14505_v52, %v126816_v42 (stack54)
        %v16086_v55 = vor.u32 %v16085_v10, %v16084_v23 (stack47)
        %v16503_v43 = vor.u32 %v16502_v31, %v16501_v29 (stack47)
        %v16920_v12 = vor.u32 %v16919_v21, %v16918_v12 (stack47)
        %vm14361_vm15 = vcmp.eq.f32.partialorder %v14358_v25, 1.0 (stack68)
        %v15685_v42 = vor.u32 %v15684_v27, %v15683_v7 (stack47)
        %v14513_v25 = vsel /*vm=*/%vm14361_vm15, /*on_true_vy=*/%v14366_v44, /*on_false_vx=*/%v14509_v41 (stack44)
        %vm14846_vm0 = vcmp.lt.f32.partialorder %v127037_v8, 5.0 (stack68)
        %v14517_v6 = vmul.f32 1.4140625, %v14513_v25 (stack54)
        %v127046_v9 = vadd.f32 -2.5, %v127037_v8 (stack53)
        %v15260_v21 = vor.u32 16256, %v15259_v56 (stack47)
        %v127050_v32 = vadd.s32 %v127017_v61, %v122657_v58 (stack40)
        %v15686_v24 = vxor.u32 %v15685_v42, %v15681_v20 (stack48)
        %v16087_v23 = vxor.u32 %v16086_v55, %v16082_v46 (stack48)
        %v16504_v34 = vxor.u32 %v16503_v43, %v16499_v60 (stack48)
        %v16921_v26 = vxor.u32 %v16920_v12, %v127023_v22 (stack48)
        %v14520_v10 = vpack.c.bf16 %v156663_v45, %v14517_v6 (stack81)
        %v127057_v11 = vsel /*vm=*/%vm14846_vm0, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v15261_v30 = vand.u32.u16 65535, %v15260_v21 (stack52)
        %v17348_v29 = vadd.s32 %v157160_v54, %v157084_v16 (stack40)
        %vm14891_vm1 = vcmp.eq.f32.partialorder %v127037_v8, inf (stack70)
        %v15689_v31 = vadd.s32 %v15686_v24, %v15681_v20 (stack40)
        %v15695_v40 = vshll.u32 %v15686_v24, 24 (stack45)
        %v15696_v20 = vshrl.u32 %v15686_v24, 8 (stack46)
        %v16090_v46 = vadd.s32 %v16087_v23, %v16082_v46 (stack40)
        %119819 = vst [vmem:[%s123356_s30 + $0x28c] sm:$0xf] /*vst_source=*/%v14520_v10 (stack83)
        %v119822_v7 = vadd.low.f32.bf16 -1.0, %v15261_v30 (stack53)
        %v16092_v52 = vshll.u32 %v16087_v23, 15 (stack45)
        %v16093_v27 = vshrl.u32 %v16087_v23, 17 (stack46)
        %v16507_v60 = vadd.s32 %v16504_v34, %v16499_v60 (stack40)
        %v127066_v44 = vsel /*vm=*/%vm14846_vm0, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v15697_v56 = vor.u32 %v15696_v20, %v15695_v40 (stack47)
        %v16509_v41 = vshll.u32 %v16504_v34, 29 (stack45)
        %v16510_v55 = vshrl.u32 %v16504_v34, 3 (stack46)
        %v15270_v43 = vmul.f32 2.0, %v119822_v7 (stack54)
        %v16094_v12 = vor.u32 %v16093_v27, %v16092_v52 (stack47)
        %v16924_v22 = vadd.s32 %v16921_v26, %v127023_v22 (stack40)
        %v16926_v42 = vshll.u32 %v16921_v26, 15 (stack45)
        %v15698_v25 = vxor.u32 %v15697_v56, %v15689_v31 (stack48)
        %v16511_v6 = vor.u32 %v16510_v55, %v16509_v41 (stack47)
        %v16927_v21 = vshrl.u32 %v16921_v26, 17 (stack46)
        %v17352_v24 = vadd.s32 1, %v17348_v29 (stack40)
        %v14894_v23 = vand.u32 2147483648, %v127037_v8 (stack72)
        %v15274_v34 = vadd.f32 -0.99609375, %v15270_v43 (stack53)
        %v16095_v26 = vxor.u32 %v16094_v12, %v16090_v46 (stack48)
        %v127072_v10 = vadd.s32 %v157155_v53, %v157089_v17 (stack40)
        %v120556_v30 = vpop.eup %120555 (stack73)
        %v15693_v31 = vadd.s32 %v15689_v31, %v121569_v1 (stack40)
        %v15701_v40 = vadd.s32 %v15698_v25, %v121564_v0 (stack40)
        %v16512_v20 = vxor.u32 %v16511_v6, %v16507_v60 (stack48)
        %v17356_v29 = vsel /*vm=*/%vm17343_vm14, /*on_true_vy=*/%v17352_v24, /*on_false_vx=*/%v17348_v29 (stack44)
        %v14890_v7 = vmul.f32 %v120556_v30, %v127037_v8 (stack74)
        %v127080_v52 = vmax.f32 %v15274_v34, -0.99609375 (stack55)
        %v16098_v46 = vadd.s32 %v16095_v26, %v16090_v46 (stack40)
        %v16100_v27 = vshll.u32 %v16095_v26, 26 (stack45)
        %v15705_v56 = vadd.s32 4, %v15701_v40 (stack40)
        %v16101_v41 = vshrl.u32 %v16095_v26, 6 (stack46)
        %v16515_v60 = vadd.s32 %v16512_v20, %v16507_v60 (stack40)
        %v16928_v55 = vor.u32 %v16927_v21, %v16926_v42 (stack47)
        %v14892_v43 = vsel /*vm=*/%vm14891_vm1, /*on_true_vy=*/%v127037_v8, /*on_false_vx=*/%v14890_v7 (stack75)
        %vm14893_vm2 = vcmp.eq.f32.partialorder %v127037_v8, 0.0 (stack71)
        %v15290_v12 = vxor.u32 2147483648, %v127080_v52 (stack56)
        %v16517_v42 = vshll.u32 %v16512_v20, 16 (stack45)
        %v14895_v25 = vsel /*vm=*/%vm14893_vm2, /*on_true_vy=*/%v14894_v23, /*on_false_vx=*/%v14892_v43 (stack76)
        %v15709_v6 = vadd.s32 %v15705_v56, %v15693_v31 (stack40)
        %v15711_v21 = vshll.u32 %v15705_v56, 13 (stack45)
        %v15712_v24 = vshrl.u32 %v15705_v56, 19 (stack46)
        %v14875_v23 = vsel /*vm=*/%vm14846_vm0, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v14898_v34 = vadd.f32 -3.0, %v14895_v25 (stack53)
        %v127091_v26 = vmul.f32 %v15290_v12, %v127080_v52 (stack54)
        %v16102_v30 = vor.u32 %v16101_v41, %v16100_v27 (stack47)
        %v14879_v31 = vsel /*vm=*/%vm14846_vm0, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v15713_v40 = vor.u32 %v15712_v24, %v15711_v21 (stack47)
        %v16518_v20 = vshrl.u32 %v16512_v20, 16 (stack46)
        %v16929_v7 = vxor.u32 %v16928_v55, %v16924_v22 (stack48)
        %v14883_v27 = vsel /*vm=*/%vm14846_vm0, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v127102_v9 = vsel /*vm=*/%vm14846_vm0, /*on_true_vy=*/%v127046_v9, /*on_false_vx=*/%v14898_v34 (stack44)
        %v15295_v56 = vadd.f32 1.0, %v127091_v26 (stack57)
        %vm17338_vm3 = vcmp.lt.u32.totalorder %v127050_v32, %v127017_v61 (stack43)
        %v14906_v41 = vmul.f32 %v127102_v9, %v14883_v27 (stack54)
        %v15714_v55 = vxor.u32 %v15713_v40, %v15709_v6 (stack48)
        %v16103_v43 = vxor.u32 %v16102_v30, %v16098_v46 (stack48)
        %v16519_v12 = vor.u32 %v16518_v20, %v16517_v42 (stack47)
        %120557 = vlog2.f32 %v15295_v56 (stack58)
        %v15298_v42 = vmul.f32 -0.5, %v127091_v26 (stack59)
        %v16932_v22 = vadd.s32 %v16929_v7, %v16924_v22 (stack40)
        %v17360_v25 = vadd.s32 1, %v17356_v29 (stack40)
        %v14910_v21 = vadd.f32 %v14906_v41, %v14879_v31 (stack53)
        %v15717_v6 = vadd.s32 %v15714_v55, %v15709_v6 (stack40)
        %v15719_v24 = vshll.u32 %v15714_v55, 15 (stack45)
        %v15720_v34 = vshrl.u32 %v15714_v55, 17 (stack46)
        %v16106_v46 = vadd.s32 %v16103_v43, %v16098_v46 (stack40)
        %v16112_v30 = vshll.u32 %v16103_v43, 6 (stack45)
        %v16113_v31 = vshrl.u32 %v16103_v43, 26 (stack46)
        %v127111_v40 = vadd.s32 %v127050_v32, %v121569_v1 (stack40)
        %v14914_v20 = vmul.f32 %v14910_v21, %v127102_v9 (stack54)
        %v15721_v27 = vor.u32 %v15720_v34, %v15719_v24 (stack47)
        %v16520_v56 = vxor.u32 %v16519_v12, %v16515_v60 (stack48)
        %v16934_v41 = vshll.u32 %v16929_v7, 26 (stack45)
        %v15299_v55 = vadd.f32 1.0, %v15298_v42 (stack61)
        %v16114_v43 = vor.u32 %v16113_v31, %v16112_v30 (stack47)
        %v16935_v7 = vshrl.u32 %v16929_v7, 6 (stack46)
        %v17364_v61 = vsel /*vm=*/%vm17338_vm3, /*on_true_vy=*/%v17360_v25, /*on_false_vx=*/%v17356_v29 (stack44)
        %v14918_v32 = vadd.f32 %v14914_v20, %v14875_v23 (stack53)
        %v15722_v29 = vxor.u32 %v15721_v27, %v15717_v6 (stack48)
        %v16523_v60 = vadd.s32 %v16520_v56, %v16515_v60 (stack40)
        %v16529_v23 = vshll.u32 %v16520_v56, 24 (stack45)
        %v16115_v12 = vxor.u32 %v16114_v43, %v16106_v46 (stack48)
        %v16530_v42 = vshrl.u32 %v16520_v56, 8 (stack46)
        %v16936_v25 = vor.u32 %v16935_v7, %v16934_v41 (stack47)
        %v17369_v21 = vadd.s32 %v17364_v61, %v121574_v2 (stack40)
        %v14922_v24 = vmul.f32 %v14918_v32, %v127102_v9 (stack54)
        %v15725_v6 = vadd.s32 %v15722_v29, %v15717_v6 (stack40)
        %v15727_v34 = vshll.u32 %v15722_v29, 26 (stack45)
        %v15728_v30 = vshrl.u32 %v15722_v29, 6 (stack46)
        %v15301_v31 = vand.u32 2147483647, %v127091_v26 (stack60)
        %v16118_v20 = vadd.s32 %v16115_v12, %v121569_v1 (stack40)
        %v16531_v27 = vor.u32 %v16530_v42, %v16529_v23 (stack47)
        %v16937_v56 = vxor.u32 %v16936_v25, %v16932_v22 (stack48)
        %v14926_v44 = vadd.f32 %v14922_v24, %v127066_v44 (stack53)
        %v15300_v26 = vmul.f32 %v15299_v55, %v127091_v26 (stack63)
        %v15729_v41 = vor.u32 %v15728_v30, %v15727_v34 (stack47)
        %v127124_v55 = vadd.s32 %v127111_v40, %v17369_v21 (stack40)
        %v16110_v46 = vadd.s32 %v16106_v46, %v121574_v2 (stack40)
        %v16122_v43 = vadd.s32 3, %v16118_v20 (stack40)
        %v16532_v7 = vxor.u32 %v16531_v27, %v16523_v60 (stack48)
        %v16940_v22 = vadd.s32 %v16937_v56, %v16932_v22 (stack40)
        %v14930_v61 = vmul.f32 %v14926_v44, %v127102_v9 (stack54)
        %v15730_v32 = vxor.u32 %v15729_v41, %v15725_v6 (stack48)
        %v16946_v29 = vshll.u32 %v16937_v56, 6 (stack45)
        %v16947_v23 = vshrl.u32 %v16937_v56, 26 (stack46)
        %v16126_v12 = vadd.s32 %v16122_v43, %v16110_v46 (stack40)
        %v16128_v42 = vshll.u32 %v16122_v43, 17 (stack45)
        %v16129_v25 = vshrl.u32 %v16122_v43, 15 (stack46)
        %v16535_v21 = vadd.s32 %v16532_v7, %v121574_v2 (stack40)
        %v120558_v24 = vpop.eup %120557 (stack64)
        %v14934_v11 = vadd.f32 %v14930_v61, %v127057_v11 (stack53)
        %v15733_v6 = vadd.s32 %v15730_v32, %v15725_v6 (stack40)
        %v15739_v34 = vshll.u32 %v15730_v32, 6 (stack45)
        %v15740_v30 = vshrl.u32 %v15730_v32, 26 (stack46)
        %v15297_v20 = vmul.f32 0.6931472, %v120558_v24 (stack65)
        %v16130_v27 = vor.u32 %v16129_v25, %v16128_v42 (stack47)
        %v16527_v60 = vadd.s32 %v16523_v60, %v121564_v0 (stack40)
        %v16539_v56 = vadd.s32 2, %v16535_v21 (stack40)
        %v14938_v44 = vmul.f32 %v14934_v11, %v127102_v9 (stack54)
        %vm15302_vm4 = vcmp.lt.f32.partialorder %v15301_v31, 0.0004427343 (stack62)
        %v15741_v31 = vor.u32 %v15740_v30, %v15739_v34 (stack47)
        %v16948_v41 = vor.u32 %v16947_v23, %v16946_v29 (stack47)
        %v14863_v46 = vsel /*vm=*/%vm14846_vm0, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v15303_v26 = vsel /*vm=*/%vm15302_vm4, /*on_true_vy=*/%v15300_v26, /*on_false_vx=*/%v15297_v20 (stack66)
        %v16131_v43 = vxor.u32 %v16130_v27, %v16126_v12 (stack48)
        %v16543_v7 = vadd.s32 %v16539_v56, %v16527_v60 (stack40)
        %v14819_v61 = vand.u32 2147483647, %v126969_v50 (stack77)
        %v14942_v32 = vadd.f32 %v14938_v44, %v14863_v46 (stack53)
        %v127136_v29 = vxor.u32 2147483648, %v15303_v26 (stack56)
        %v15742_v23 = vxor.u32 %v15741_v31, %v15733_v6 (stack48)
        %v16134_v12 = vadd.s32 %v16131_v43, %v16126_v12 (stack40)
        %v16136_v42 = vshll.u32 %v16131_v43, 29 (stack45)
        %v16137_v25 = vshrl.u32 %v16131_v43, 3 (stack46)
        %v16949_v21 = vxor.u32 %v16948_v41, %v16940_v22 (stack48)
        %v127139_v24 = vmul.f32 inf, %v126969_v50 (stack54)
        %v14859_v11 = vsel /*vm=*/%vm14846_vm0, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v14946_v34 = vmul.f32 %v14942_v32, %v127102_v9 (stack54)
        %120559 = vrsqrt.f32 %v127136_v29 (stack67)
        %vm15307_vm5 = vcmp.lt.f32.partialorder %v127136_v29, 5.0 (stack68)
        %v15745_v30 = vadd.s32 %v15742_v23, %v121574_v2 (stack40)
        %v16545_v20 = vshll.u32 %v16539_v56, 13 (stack45)
        %v16546_v27 = vshrl.u32 %v16539_v56, 19 (stack46)
        %v14851_v60 = vsel /*vm=*/%vm14846_vm0, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v14950_v56 = vadd.f32 %v14946_v34, %v14859_v11 (stack53)
        %v17379_v44 = vshll.u32 %v127111_v40, 13 (stack45)
        %v17380_v40 = vshrl.u32 %v127111_v40, 19 (stack46)
        %v14855_v8 = vsel /*vm=*/%vm14846_vm0, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v15280_v31 = vand.u32 2147483647, %v127080_v52 (stack77)
        %v16138_v41 = vor.u32 %v16137_v25, %v16136_v42 (stack47)
        %v16944_v22 = vadd.s32 %v16940_v22, %v121569_v1 (stack40)
        %v14954_v46 = vmul.f32 %v14950_v56, %v127102_v9 (stack54)
        %v127162_v26 = vsel /*vm=*/%vm15307_vm5, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v127165_v43 = vadd.f32 -2.5, %v127136_v29 (stack53)
        %v15737_v6 = vadd.s32 %v15733_v6, %v121564_v0 (stack40)
        %vm127168_vm6 = vcmp.eq.f32.partialorder %v14819_v61, 1.0 (stack68)
        %v15749_v32 = vadd.s32 5, %v15745_v30 (stack40)
        %v16139_v23 = vxor.u32 %v16138_v41, %v16134_v12 (stack48)
        %v16547_v42 = vor.u32 %v16546_v27, %v16545_v20 (stack47)
        %v16952_v25 = vadd.s32 %v16949_v21, %v121564_v0 (stack40)
        %v14958_v21 = vadd.f32 %v14954_v46, %v14855_v8 (stack53)
        %v127176_v11 = vsel /*vm=*/%vm15307_vm5, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v17381_v34 = vor.u32 %v17380_v40, %v17379_v44 (stack47)
        %vm17804_vm7 = vcmp.lt.u32.totalorder %v127072_v10, %v157089_v17 (stack43)
        %vm15352_vm8 = vcmp.eq.f32.partialorder %v127136_v29, inf (stack70)
        %v15751_v30 = vxor.u32 %v15749_v32, %v15737_v6 (stack48)
        %v16142_v12 = vadd.s32 %v16139_v23, %v16134_v12 (stack40)
        %v16144_v20 = vshll.u32 %v16139_v23, 16 (stack45)
        %v16145_v27 = vshrl.u32 %v16139_v23, 16 (stack46)
        %v14962_v9 = vmul.f32 %v14958_v21, %v127102_v9 (stack54)
        %vm15354_vm9 = vcmp.eq.f32.partialorder %v127136_v29, 0.0 (stack71)
        %v16548_v56 = vxor.u32 %v16547_v42, %v16543_v7 (stack48)
        %v16956_v44 = vadd.s32 1, %v16952_v25 (stack40)
        %v17382_v40 = vxor.u32 %v17381_v34, %v127124_v55 (stack48)
        %v15355_v8 = vand.u32 2147483648, %v127136_v29 (stack72)
        %v15752_v41 = vand.u32.u8 255, %v15751_v30 (stack49)
        %v16146_v46 = vor.u32 %v16145_v27, %v16144_v20 (stack47)
        %v127187_v6 = vadd.s32 %v157160_v54, %v157090_v62 (stack40)
        %v14966_v60 = vadd.f32 %v14962_v9, %v14851_v60 (stack53)
        %v16551_v7 = vadd.s32 %v16548_v56, %v16543_v7 (stack40)
        %v16553_v32 = vshll.u32 %v16548_v56, 15 (stack45)
        %v16554_v23 = vshrl.u32 %v16548_v56, 17 (stack46)
        %v15753_v42 = vand.u32 65535, %v15752_v41 (stack50)
        %v16147_v25 = vxor.u32 %v16146_v46, %v16142_v12 (stack48)
        %v16960_v22 = vadd.s32 %v16956_v44, %v16944_v22 (stack40)
        %v16962_v21 = vshll.u32 %v16956_v44, 17 (stack45)
        %v14970_v50 = vmul.f32 %v14966_v60, %v126969_v50 (stack54)
        %v16555_v34 = vor.u32 %v16554_v23, %v16553_v32 (stack47)
        %v16963_v30 = vshrl.u32 %v16956_v44, 15 (stack46)
        %v127191_v55 = vadd.s32 %v17382_v40, %v127124_v55 (stack40)
        %v120560_v20 = vpop.eup %120559 (stack73)
        %v15754_v27 = vshrl.u32 %v15753_v42, 1 (stack51)
        %v16150_v12 = vadd.s32 %v16147_v25, %v16142_v12 (stack40)
        %v16156_v9 = vshll.u32 %v16147_v25, 24 (stack45)
        %v16157_v56 = vshrl.u32 %v16147_v25, 8 (stack46)
        %v14974_v24 = vsel /*vm=*/%vm127168_vm6, /*on_true_vy=*/%v127139_v24, /*on_false_vx=*/%v14970_v50 (stack44)
        %v15351_v61 = vmul.f32 %v120560_v20, %v127136_v29 (stack74)
        %v16556_v44 = vxor.u32 %v16555_v34, %v16551_v7 (stack48)
        %v16964_v41 = vor.u32 %v16963_v30, %v16962_v21 (stack47)
        %v14978_v46 = vmul.f32 1.4140625, %v14974_v24 (stack54)
        %v15755_v60 = vor.u32 16256, %v15754_v27 (stack47)
        %v16154_v32 = vadd.s32 %v16150_v12, %v121569_v1 (stack40)
        %v16158_v23 = vor.u32 %v16157_v56, %v16156_v9 (stack47)
        %v15353_v42 = vsel /*vm=*/%vm15352_vm8, /*on_true_vy=*/%v127136_v29, /*on_false_vx=*/%v15351_v61 (stack75)
        %v16559_v7 = vadd.s32 %v16556_v44, %v16551_v7 (stack40)
        %v16561_v25 = vshll.u32 %v16556_v44, 26 (stack45)
        %v16562_v21 = vshrl.u32 %v16556_v44, 6 (stack46)
        %v14981_v50 = vpack.c.bf16 %v156663_v45, %v14978_v46 (stack81)
        %v15356_v8 = vsel /*vm=*/%vm15354_vm9, /*on_true_vy=*/%v15355_v8, /*on_false_vx=*/%v15353_v42 (stack76)
        %v15756_v34 = vand.u32.u16 65535, %v15755_v60 (stack52)
        %v16159_v30 = vxor.u32 %v16158_v23, %v16150_v12 (stack48)
        %v15359_v20 = vadd.f32 -3.0, %v15356_v8 (stack53)
        %v16563_v27 = vor.u32 %v16562_v21, %v16561_v25 (stack47)
        %v16965_v12 = vxor.u32 %v16964_v41, %v16960_v22 (stack48)
        %v17387_v9 = vshll.u32 %v17382_v40, 15 (stack45)
        %119821 = vst [vmem:[%s123356_s30 + $0x30c] sm:$0xf] /*vst_source=*/%v14981_v50 (stack83)
        %v119828_v56 = vadd.low.f32.bf16 -1.0, %v15756_v34 (stack53)
        %v16162_v24 = vadd.s32 %v16159_v30, %v121564_v0 (stack40)
        %v17388_v40 = vshrl.u32 %v17382_v40, 17 (stack46)
        %v17813_v61 = vadd.s32 1, %v127187_v6 (stack40)
        %v127210_v43 = vsel /*vm=*/%vm15307_vm5, /*on_true_vy=*/%v127165_v43, /*on_false_vx=*/%v15359_v20 (stack44)
        %v16564_v44 = vxor.u32 %v16563_v27, %v16559_v7 (stack48)
        %v16968_v22 = vadd.s32 %v16965_v12, %v16960_v22 (stack40)
        %v16970_v41 = vshll.u32 %v16965_v12, 29 (stack45)
        %v15367_v11 = vmul.f32 %v127210_v43, %v127176_v11 (stack54)
        %v15765_v46 = vmul.f32 2.0, %v119828_v56 (stack54)
        %v16166_v60 = vadd.s32 4, %v16162_v24 (stack40)
        %v16971_v23 = vshrl.u32 %v16965_v12, 3 (stack46)
        %v16567_v42 = vadd.s32 %v16564_v44, %v16559_v7 (stack40)
        %v16573_v7 = vshll.u32 %v16564_v44, 6 (stack45)
        %v16574_v25 = vshrl.u32 %v16564_v44, 26 (stack46)
        %v17389_v21 = vor.u32 %v17388_v40, %v17387_v9 (stack47)
        %v15371_v26 = vadd.f32 %v15367_v11, %v127162_v26 (stack53)
        %v15769_v50 = vadd.f32 -0.99609375, %v15765_v46 (stack53)
        %v16170_v32 = vadd.s32 %v16166_v60, %v16154_v32 (stack40)
        %v16172_v8 = vshll.u32 %v16166_v60, 13 (stack45)
        %v127218_v34 = vsel /*vm=*/%vm15307_vm5, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v16173_v30 = vshrl.u32 %v16166_v60, 19 (stack46)
        %v16575_v20 = vor.u32 %v16574_v25, %v16573_v7 (stack47)
        %v16972_v27 = vor.u32 %v16971_v23, %v16970_v41 (stack47)
        %v15375_v12 = vmul.f32 %v15371_v26, %v127210_v43 (stack54)
        %v127221_v9 = vmax.f32 %v15769_v50, -0.99609375 (stack55)
        %v17390_v56 = vxor.u32 %v17389_v21, %v127191_v55 (stack48)
        %v17817_v6 = vsel /*vm=*/%vm17804_vm7, /*on_true_vy=*/%v17813_v61, /*on_false_vx=*/%v127187_v6 (stack44)
        %v15336_v24 = vsel /*vm=*/%vm15307_vm5, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v16174_v40 = vor.u32 %v16173_v30, %v16172_v8 (stack47)
        %v16576_v61 = vxor.u32 %v16575_v20, %v16567_v42 (stack48)
        %v16973_v44 = vxor.u32 %v16972_v27, %v16968_v22 (stack48)
        %v15332_v41 = vsel /*vm=*/%vm15307_vm5, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v15379_v11 = vadd.f32 %v15375_v12, %v15336_v24 (stack53)
        %v15785_v46 = vxor.u32 2147483648, %v127221_v9 (stack56)
        %v127237_v60 = vadd.s32 %v127072_v10, %v122657_v58 (stack40)
        %v16175_v23 = vxor.u32 %v16174_v40, %v16170_v32 (stack48)
        %v16571_v42 = vadd.s32 %v16567_v42, %v121574_v2 (stack40)
        %v16579_v7 = vadd.s32 %v16576_v61, %v121569_v1 (stack40)
        %v16976_v22 = vadd.s32 %v16973_v44, %v16968_v22 (stack40)
        %v15383_v25 = vmul.f32 %v15379_v11, %v127210_v43 (stack54)
        %v127243_v21 = vmul.f32 %v15785_v46, %v127221_v9 (stack54)
        %v16978_v26 = vshll.u32 %v16973_v44, 16 (stack45)
        %v16979_v50 = vshrl.u32 %v16973_v44, 16 (stack46)
        %v16178_v32 = vadd.s32 %v16175_v23, %v16170_v32 (stack40)
        %v16180_v8 = vshll.u32 %v16175_v23, 15 (stack45)
        %v16181_v30 = vshrl.u32 %v16175_v23, 17 (stack46)
        %v16583_v20 = vadd.s32 3, %v16579_v7 (stack40)
        %v15324_v27 = vsel /*vm=*/%vm15307_vm5, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v15328_v12 = vsel /*vm=*/%vm15307_vm5, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v15387_v24 = vadd.f32 %v15383_v25, %v15332_v41 (stack53)
        %v15790_v40 = vadd.f32 1.0, %v127243_v21 (stack57)
        %v16182_v61 = vor.u32 %v16181_v30, %v16180_v8 (stack47)
        %v16587_v44 = vadd.s32 %v16583_v20, %v16571_v42 (stack40)
        %v16589_v41 = vshll.u32 %v16583_v20, 17 (stack45)
        %v16590_v11 = vshrl.u32 %v16583_v20, 15 (stack46)
        %v15391_v46 = vmul.f32 %v15387_v24, %v127210_v43 (stack54)
        %120561 = vlog2.f32 %v15790_v40 (stack58)
        %vm17799_vm10 = vcmp.lt.u32.totalorder %v127237_v60, %v127072_v10 (stack43)
        %v17821_v23 = vadd.s32 1, %v17817_v6 (stack40)
        %v16183_v42 = vxor.u32 %v16182_v61, %v16178_v32 (stack48)
        %v16591_v7 = vor.u32 %v16590_v11, %v16589_v41 (stack47)
        %v16980_v25 = vor.u32 %v16979_v50, %v16978_v26 (stack47)
        %v17393_v55 = vadd.s32 %v17390_v56, %v127191_v55 (stack40)
        %v15395_v26 = vadd.f32 %v15391_v46, %v15328_v12 (stack53)
        %v15793_v50 = vmul.f32 -0.5, %v127243_v21 (stack59)
        %v17395_v8 = vshll.u32 %v17390_v56, 26 (stack45)
        %v17396_v56 = vshrl.u32 %v17390_v56, 6 (stack46)
        %v16186_v32 = vadd.s32 %v16183_v42, %v16178_v32 (stack40)
        %v16188_v30 = vshll.u32 %v16183_v42, 26 (stack45)
        %v16189_v20 = vshrl.u32 %v16183_v42, 6 (stack46)
        %v16592_v12 = vxor.u32 %v16591_v7, %v16587_v44 (stack48)
        %v15399_v24 = vmul.f32 %v15395_v26, %v127210_v43 (stack54)
        %v16981_v40 = vxor.u32 %v16980_v25, %v16976_v22 (stack48)
        %v17397_v61 = vor.u32 %v17396_v56, %v17395_v8 (stack47)
        %v17825_v10 = vsel /*vm=*/%vm17799_vm10, /*on_true_vy=*/%v17821_v23, /*on_false_vx=*/%v17817_v6 (stack44)
        %v16190_v6 = vor.u32 %v16189_v20, %v16188_v30 (stack47)
        %v16595_v44 = vadd.s32 %v16592_v12, %v16587_v44 (stack40)
        %v16597_v41 = vshll.u32 %v16592_v12, 29 (stack45)
        %v16598_v11 = vshrl.u32 %v16592_v12, 3 (stack46)
        %v15403_v27 = vadd.f32 %v15399_v24, %v15324_v27 (stack53)
        %v16984_v22 = vadd.s32 %v16981_v40, %v16976_v22 (stack40)
        %v16990_v46 = vshll.u32 %v16981_v40, 24 (stack45)
        %v16991_v23 = vshrl.u32 %v16981_v40, 8 (stack46)
        %v15796_v42 = vand.u32 2147483647, %v127243_v21 (stack60)
        %v16191_v7 = vxor.u32 %v16190_v6, %v16186_v32 (stack48)
        %v16599_v25 = vor.u32 %v16598_v11, %v16597_v41 (stack47)
        %v17398_v26 = vxor.u32 %v17397_v61, %v17393_v55 (stack48)
        %v15407_v8 = vmul.f32 %v15403_v27, %v127210_v43 (stack54)
        %v15794_v50 = vadd.f32 1.0, %v15793_v50 (stack61)
        %v16992_v56 = vor.u32 %v16991_v23, %v16990_v46 (stack47)
        %v17830_v30 = vadd.s32 %v17825_v10, %v121574_v2 (stack40)
        %v16194_v32 = vadd.s32 %v16191_v7, %v16186_v32 (stack40)
        %v16200_v20 = vshll.u32 %v16191_v7, 6 (stack45)
        %v16201_v12 = vshrl.u32 %v16191_v7, 26 (stack46)
        %v16600_v24 = vxor.u32 %v16599_v25, %v16595_v44 (stack48)
        %v15316_v40 = vsel /*vm=*/%vm15307_vm5, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v15411_v34 = vadd.f32 %v15407_v8, %v127218_v34 (stack53)
        %v16993_v61 = vxor.u32 %v16992_v56, %v16984_v22 (stack48)
        %v17401_v55 = vadd.s32 %v17398_v26, %v17393_v55 (stack40)
        %v16202_v10 = vor.u32 %v16201_v12, %v16200_v20 (stack47)
        %v16603_v6 = vadd.s32 %v16600_v24, %v16595_v44 (stack40)
        %v16605_v44 = vshll.u32 %v16600_v24, 16 (stack45)
        %v17834_v60 = vadd.s32 %v127237_v60, %v121569_v1 (stack40)
        %v15415_v41 = vmul.f32 %v15411_v34, %v127210_v43 (stack54)
        %vm127271_vm11 = vcmp.lt.f32.partialorder %v15796_v42, 0.0004427343 (stack62)
        %v16606_v27 = vshrl.u32 %v16600_v24, 16 (stack46)
        %v16996_v46 = vadd.s32 %v16993_v61, %v121574_v2 (stack40)
        %v120562_v23 = vpop.eup %120561 (stack64)
        %v15795_v21 = vmul.f32 %v15794_v50, %v127243_v21 (stack63)
        %v16203_v42 = vxor.u32 %v16202_v10, %v16194_v32 (stack48)
        %v16988_v22 = vadd.s32 %v16984_v22, %v121564_v0 (stack40)
        %v17838_v7 = vadd.s32 %v17834_v60, %v17830_v30 (stack40)
        %v15419_v25 = vadd.f32 %v15415_v41, %v15316_v40 (stack53)
        %v15792_v8 = vmul.f32 0.6931472, %v120562_v23 (stack65)
        %v16607_v50 = vor.u32 %v16606_v27, %v16605_v44 (stack47)
        %v17000_v56 = vadd.s32 2, %v16996_v46 (stack40)
        %v16206_v30 = vadd.s32 %v16203_v42, %v121574_v2 (stack40)
        %v17407_v20 = vshll.u32 %v17398_v26, 6 (stack45)
        %v17408_v26 = vshrl.u32 %v17398_v26, 26 (stack46)
        %v127281_v12 = vadd.s32 %v157155_v53, %v157091_v37 (stack40)
        %v15423_v43 = vmul.f32 %v15419_v25, %v127210_v43 (stack54)
        %v15798_v24 = vsel /*vm=*/%vm127271_vm11, /*on_true_vy=*/%v15795_v21, /*on_false_vx=*/%v15792_v8 (stack66)
        %v16608_v40 = vxor.u32 %v16607_v50, %v16603_v6 (stack48)
        %v17004_v34 = vadd.s32 %v17000_v56, %v16988_v22 (stack40)
        %v15312_v29 = vsel /*vm=*/%vm15307_vm5, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v127289_v61 = vxor.u32 2147483648, %v15798_v24 (stack56)
        %v16210_v10 = vadd.s32 5, %v16206_v30 (stack40)
        %vm127293_vm12 = vcmp.eq.f32.partialorder %v15280_v31, 1.0 (stack68)
        %v15288_v44 = vmul.f32 inf, %v127080_v52 (stack54)
        %v15427_v41 = vadd.f32 %v15423_v43, %v15312_v29 (stack53)
        %v16611_v6 = vadd.s32 %v16608_v40, %v16603_v6 (stack40)
        %120563 = vrsqrt.f32 %v127289_v61 (stack67)
        %v16198_v32 = vadd.s32 %v16194_v32, %v121564_v0 (stack40)
        %v17006_v11 = vshll.u32 %v17000_v56, 13 (stack45)
        %v17409_v27 = vor.u32 %v17408_v26, %v17407_v20 (stack47)
        %v15431_v52 = vmul.f32 %v15427_v41, %v127080_v52 (stack54)
        %v16617_v46 = vshll.u32 %v16608_v40, 24 (stack45)
        %v16618_v23 = vshrl.u32 %v16608_v40, 8 (stack46)
        %v17007_v21 = vshrl.u32 %v17000_v56, 19 (stack46)
        %vm15802_vm13 = vcmp.lt.f32.partialorder %v127289_v61, 5.0 (stack68)
        %v16212_v42 = vxor.u32 %v16210_v10, %v16198_v32 (stack48)
        %v17840_v22 = vshll.u32 %v17834_v60, 13 (stack45)
        %v17841_v60 = vshrl.u32 %v17834_v60, 19 (stack46)
        %v15435_v25 = vsel /*vm=*/%vm127293_vm12, /*on_true_vy=*/%v15288_v44, /*on_false_vx=*/%v15431_v52 (stack44)
        %v15439_v8 = vmul.f32 1.4140625, %v15435_v25 (stack54)
        %v127305_v50 = vadd.f32 -2.5, %v127289_v61 (stack53)
        %v16213_v56 = vand.u32.u8 255, %v16212_v42 (stack49)
        %v17405_v30 = vadd.s32 %v17401_v55, %v121569_v1 (stack40)
        %v127311_v20 = vsel /*vm=*/%vm15802_vm13, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v16619_v26 = vor.u32 %v16618_v23, %v16617_v46 (stack47)
        %v17008_v43 = vor.u32 %v17007_v21, %v17006_v11 (stack47)
        %v17410_v55 = vxor.u32 %v17409_v27, %v17401_v55 (stack48)
        %v15442_v24 = vpack.c.bf16 %v156663_v45, %v15439_v8 (stack81)
        %v15850_v40 = vand.u32 2147483648, %v127289_v61 (stack72)
        %v16214_v29 = vand.u32 65535, %v16213_v56 (stack50)
        %v17842_v10 = vor.u32 %v17841_v60, %v17840_v22 (stack47)
        %vm15847_vm14 = vcmp.eq.f32.partialorder %v127289_v61, inf (stack70)
        %v16620_v31 = vxor.u32 %v16619_v26, %v16611_v6 (stack48)
        %v17009_v44 = vxor.u32 %v17008_v43, %v17004_v34 (stack48)
        %v17413_v41 = vadd.s32 %v17410_v55, %v121564_v0 (stack40)
        %vm18265_vm15 = vcmp.lt.u32.totalorder %v127281_v12, %v157091_v37 (stack43)
        %119823 = vst [vmem:[%s123356_s30 + $0x38c] sm:$0xf] /*vst_source=*/%v15442_v24 (stack83)
        %vm15849_vm0 = vcmp.eq.f32.partialorder %v127289_v61, 0.0 (stack71)
        %v16215_v32 = vshrl.u32 %v16214_v29, 1 (stack51)
        %v16615_v6 = vadd.s32 %v16611_v6, %v121569_v1 (stack40)
        %v17843_v11 = vxor.u32 %v17842_v10, %v17838_v7 (stack48)
        %v18270_v27 = vadd.s32 %v157160_v54, %v157094_v36 (stack40)
        %v16623_v52 = vadd.s32 %v16620_v31, %v121564_v0 (stack40)
        %v17012_v34 = vadd.s32 %v17009_v44, %v17004_v34 (stack40)
        %v17014_v46 = vshll.u32 %v17009_v44, 15 (stack45)
        %v17015_v23 = vshrl.u32 %v17009_v44, 17 (stack46)
        %v16216_v21 = vor.u32 16256, %v16215_v32 (stack47)
        %v17417_v42 = vadd.s32 1, %v17413_v41 (stack40)
        %v17846_v7 = vadd.s32 %v17843_v11, %v17838_v7 (stack40)
        %v17848_v22 = vshll.u32 %v17843_v11, 15 (stack45)
        %v16627_v60 = vadd.s32 4, %v16623_v52 (stack40)
        %v17016_v25 = vor.u32 %v17015_v23, %v17014_v46 (stack47)
        %v17849_v8 = vshrl.u32 %v17843_v11, 17 (stack46)
        %v18274_v56 = vadd.s32 1, %v18270_v27 (stack40)
        %v16217_v26 = vand.u32.u16 65535, %v16216_v21 (stack52)
        %v17421_v30 = vadd.s32 %v17417_v42, %v17405_v30 (stack40)
        %v17423_v43 = vshll.u32 %v17417_v42, 17 (stack45)
        %v17424_v55 = vshrl.u32 %v17417_v42, 15 (stack46)
        %v120564_v24 = vpop.eup %120563 (stack73)
        %v16631_v29 = vadd.s32 %v16627_v60, %v16615_v6 (stack40)
        %v16633_v10 = vshll.u32 %v16627_v60, 13 (stack45)
        %v16634_v31 = vshrl.u32 %v16627_v60, 19 (stack46)
        %v17017_v44 = vxor.u32 %v17016_v25, %v17012_v34 (stack48)
        %v15846_v41 = vmul.f32 %v120564_v24, %v127289_v61 (stack74)
        %v119830_v32 = vadd.low.f32.bf16 -1.0, %v16217_v26 (stack53)
        %v17425_v6 = vor.u32 %v17424_v55, %v17423_v43 (stack47)
        %v17850_v11 = vor.u32 %v17849_v8, %v17848_v22 (stack47)
        %v16635_v52 = vor.u32 %v16634_v31, %v16633_v10 (stack47)
        %v17020_v34 = vadd.s32 %v17017_v44, %v17012_v34 (stack40)
        %v17022_v46 = vshll.u32 %v17017_v44, 26 (stack45)
        %v17023_v23 = vshrl.u32 %v17017_v44, 6 (stack46)
        %v15848_v21 = vsel /*vm=*/%vm15847_vm14, /*on_true_vy=*/%v127289_v61, /*on_false_vx=*/%v15846_v41 (stack75)
        %v16226_v42 = vmul.f32 2.0, %v119830_v32 (stack54)
        %v17426_v22 = vxor.u32 %v17425_v6, %v17421_v30 (stack48)
        %v17851_v60 = vxor.u32 %v17850_v11, %v17846_v7 (stack48)
        %v15851_v40 = vsel /*vm=*/%vm15849_vm0, /*on_true_vy=*/%v15850_v40, /*on_false_vx=*/%v15848_v21 (stack76)
        %v16636_v25 = vxor.u32 %v16635_v52, %v16631_v29 (stack48)
        %v17024_v8 = vor.u32 %v17023_v23, %v17022_v46 (stack47)
        %v127334_v27 = vsel /*vm=*/%vm18265_vm15, /*on_true_vy=*/%v18274_v56, /*on_false_vx=*/%v18270_v27 (stack44)
        %v15854_v56 = vadd.f32 -3.0, %v15851_v40 (stack53)
        %v16230_v26 = vadd.f32 -0.99609375, %v16226_v42 (stack53)
        %v17429_v30 = vadd.s32 %v17426_v22, %v17421_v30 (stack40)
        %v17431_v43 = vshll.u32 %v17426_v22, 29 (stack45)
        %v16639_v55 = vadd.s32 %v16636_v25, %v16631_v29 (stack40)
        %v16641_v24 = vshll.u32 %v16636_v25, 15 (stack45)
        %v16642_v29 = vshrl.u32 %v16636_v25, 17 (stack46)
        %v17025_v10 = vxor.u32 %v17024_v8, %v17020_v34 (stack48)
        %v127339_v50 = vsel /*vm=*/%vm15802_vm13, /*on_true_vy=*/%v127305_v50, /*on_false_vx=*/%v15854_v56 (stack44)
        %v127341_v31 = vmax.f32 %v16230_v26, -0.99609375 (stack55)
        %v17432_v44 = vshrl.u32 %v17426_v22, 3 (stack46)
        %v17854_v7 = vadd.s32 %v17851_v60, %v17846_v7 (stack40)
        %v15862_v20 = vmul.f32 %v127339_v50, %v127311_v20 (stack54)
        %v16643_v41 = vor.u32 %v16642_v29, %v16641_v24 (stack47)
        %v17028_v32 = vadd.s32 %v17025_v10, %v17020_v34 (stack40)
        %v17034_v6 = vshll.u32 %v17025_v10, 6 (stack45)
        %v15835_v11 = vsel /*vm=*/%vm15802_vm13, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v16246_v52 = vxor.u32 2147483648, %v127341_v31 (stack56)
        %v17035_v34 = vshrl.u32 %v17025_v10, 26 (stack46)
        %v15866_v46 = vadd.f32 %v15862_v20, %v15835_v11 (stack53)
        %v16644_v23 = vxor.u32 %v16643_v41, %v16639_v55 (stack48)
        %v17433_v21 = vor.u32 %v17432_v44, %v17431_v43 (stack47)
        %v15819_v42 = vsel /*vm=*/%vm15802_vm13, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v127353_v22 = vmul.f32 %v16246_v52, %v127341_v31 (stack54)
        %v17036_v40 = vor.u32 %v17035_v34, %v17034_v6 (stack47)
        %v127357_v25 = vadd.s32 %v127281_v12, %v122657_v58 (stack40)
        %v15870_v8 = vmul.f32 %v15866_v46, %v127339_v50 (stack54)
        %v16647_v56 = vadd.s32 %v16644_v23, %v16639_v55 (stack40)
        %v16649_v26 = vshll.u32 %v16644_v23, 26 (stack45)
        %v16650_v43 = vshrl.u32 %v16644_v23, 6 (stack46)
        %v15831_v55 = vsel /*vm=*/%vm15802_vm13, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v16251_v24 = vadd.f32 1.0, %v127353_v22 (stack57)
        %v17037_v29 = vxor.u32 %v17036_v40, %v17028_v32 (stack48)
        %v17856_v10 = vshll.u32 %v17851_v60, 26 (stack45)
        %v15874_v44 = vadd.f32 %v15870_v8, %v15831_v55 (stack53)
        %v16651_v20 = vor.u32 %v16650_v43, %v16649_v26 (stack47)
        %v17434_v41 = vxor.u32 %v17433_v21, %v17429_v30 (stack48)
        %v17857_v60 = vshrl.u32 %v17851_v60, 6 (stack46)
        %v15823_v6 = vsel /*vm=*/%vm15802_vm13, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v15827_v11 = vsel /*vm=*/%vm15802_vm13, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %120565 = vlog2.f32 %v16251_v24 (stack58)
        %v17040_v52 = vadd.s32 %v17037_v29, %v121569_v1 (stack40)
        %v15878_v34 = vmul.f32 %v15874_v44, %v127339_v50 (stack54)
        %v16652_v46 = vxor.u32 %v16651_v20, %v16647_v56 (stack48)
        %v17437_v30 = vadd.s32 %v17434_v41, %v17429_v30 (stack40)
        %v17439_v23 = vshll.u32 %v17434_v41, 16 (stack45)
        %vm18260_vm1 = vcmp.lt.u32.totalorder %v127357_v25, %v127281_v12 (stack43)
        %v17032_v32 = vadd.s32 %v17028_v32, %v121574_v2 (stack40)
        %v17044_v21 = vadd.s32 3, %v17040_v52 (stack40)
        %v17440_v40 = vshrl.u32 %v17434_v41, 16 (stack46)
        %v17858_v8 = vor.u32 %v17857_v60, %v17856_v10 (stack47)
        %v15882_v26 = vadd.f32 %v15878_v34, %v15827_v11 (stack53)
        %v16655_v56 = vadd.s32 %v16652_v46, %v16647_v56 (stack40)
        %v16661_v43 = vshll.u32 %v16652_v46, 6 (stack45)
        %v16662_v55 = vshrl.u32 %v16652_v46, 26 (stack46)
        %v17048_v24 = vadd.s32 %v17044_v21, %v17032_v32 (stack40)
        %v17050_v29 = vshll.u32 %v17044_v21, 17 (stack45)
        %v17051_v10 = vshrl.u32 %v17044_v21, 15 (stack46)
        %v17441_v44 = vor.u32 %v17440_v40, %v17439_v23 (stack47)
        %v15886_v20 = vmul.f32 %v15882_v26, %v127339_v50 (stack54)
        %v16254_v41 = vmul.f32 -0.5, %v127353_v22 (stack59)
        %v16663_v60 = vor.u32 %v16662_v55, %v16661_v43 (stack47)
        %v17859_v11 = vxor.u32 %v17858_v8, %v17854_v7 (stack48)
        %v16257_v52 = vand.u32 2147483647, %v127353_v22 (stack60)
        %v17052_v34 = vor.u32 %v17051_v10, %v17050_v29 (stack47)
        %v17442_v46 = vxor.u32 %v17441_v44, %v17437_v30 (stack48)
        %v18282_v23 = vadd.s32 1, %v127334_v27 (stack40)
        %v15890_v6 = vadd.f32 %v15886_v20, %v15823_v6 (stack53)
        %v16664_v32 = vxor.u32 %v16663_v60, %v16655_v56 (stack48)
        %v127379_v7 = vadd.s32 %v17859_v11, %v17854_v7 (stack40)
        %v17868_v21 = vshll.u32 %v17859_v11, 6 (stack45)
        %v17053_v40 = vxor.u32 %v17052_v34, %v17048_v24 (stack48)
        %v17445_v30 = vadd.s32 %v17442_v46, %v17437_v30 (stack40)
        %v17451_v8 = vshll.u32 %v17442_v46, 24 (stack45)
        %v17452_v26 = vshrl.u32 %v17442_v46, 8 (stack46)
        %v15894_v43 = vmul.f32 %v15890_v6, %v127339_v50 (stack54)
        %v16255_v55 = vadd.f32 1.0, %v16254_v41 (stack61)
        %v16667_v29 = vadd.s32 %v16664_v32, %v121574_v2 (stack40)
        %v17869_v10 = vshrl.u32 %v17859_v11, 26 (stack46)
        %v16659_v56 = vadd.s32 %v16655_v56, %v121564_v0 (stack40)
        %v17056_v24 = vadd.s32 %v17053_v40, %v17048_v24 (stack40)
        %v17058_v44 = vshll.u32 %v17053_v40, 29 (stack45)
        %v17059_v20 = vshrl.u32 %v17053_v40, 3 (stack46)
        %v15898_v42 = vadd.f32 %v15894_v43, %v15819_v42 (stack53)
        %v16671_v41 = vadd.s32 5, %v16667_v29 (stack40)
        %v17453_v60 = vor.u32 %v17452_v26, %v17451_v8 (stack47)
        %v17870_v11 = vor.u32 %v17869_v10, %v17868_v21 (stack47)
        %v15775_v34 = vand.u32 2147483647, %v127221_v9 (stack77)
        %v15815_v46 = vsel /*vm=*/%vm15802_vm13, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v17060_v6 = vor.u32 %v17059_v20, %v17058_v44 (stack47)
        %v18286_v12 = vsel /*vm=*/%vm18260_vm1, /*on_true_vy=*/%v18282_v23, /*on_false_vx=*/%v127334_v27 (stack44)
        %v120566_v27 = vpop.eup %120565 (stack64)
        %v15902_v23 = vmul.f32 %v15898_v42, %v127339_v50 (stack54)
        %v16673_v32 = vxor.u32 %v16671_v41, %v16659_v56 (stack48)
        %v17454_v21 = vxor.u32 %v17453_v60, %v17445_v30 (stack48)
        %v17871_v40 = vxor.u32 %v17870_v11, %v127379_v7 (stack48)
        %v16253_v8 = vmul.f32 0.6931472, %v120566_v27 (stack65)
        %v16256_v22 = vmul.f32 %v16255_v55, %v127353_v22 (stack63)
        %v17061_v26 = vxor.u32 %v17060_v6, %v17056_v24 (stack48)
        %v18291_v43 = vadd.s32 %v18286_v12, %v121574_v2 (stack40)
        %v15906_v55 = vadd.f32 %v15902_v23, %v15815_v46 (stack53)
        %vm16258_vm2 = vcmp.lt.f32.partialorder %v16257_v52, 0.0004427343 (stack62)
        %v16674_v52 = vand.u32.u8 255, %v16673_v32 (stack49)
        %v18295_v25 = vadd.s32 %v127357_v25, %v121569_v1 (stack40)
        %v16259_v29 = vsel /*vm=*/%vm16258_vm2, /*on_true_vy=*/%v16256_v22, /*on_false_vx=*/%v16253_v8 (stack66)
        %v17064_v10 = vadd.s32 %v17061_v26, %v17056_v24 (stack40)
        %v17066_v56 = vshll.u32 %v17061_v26, 16 (stack45)
        %v17067_v24 = vshrl.u32 %v17061_v26, 16 (stack46)
        %v15811_v44 = vsel /*vm=*/%vm15802_vm13, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v15910_v20 = vmul.f32 %v15906_v55, %v127339_v50 (stack54)
        %v127402_v42 = vxor.u32 2147483648, %v16259_v29 (stack56)
        %v17457_v41 = vadd.s32 %v17454_v21, %v121574_v2 (stack40)
        %v17068_v60 = vor.u32 %v17067_v24, %v17066_v56 (stack47)
        %v17874_v11 = vadd.s32 %v17871_v40, %v121564_v0 (stack40)
        %v18299_v46 = vadd.s32 %v18295_v25, %v18291_v43 (stack40)
        %v127408_v53 = vadd.s32 %v157155_v53, %v157095_v13 (stack40)
        %v15914_v6 = vadd.f32 %v15910_v20, %v15811_v44 (stack53)
        %120567 = vrsqrt.f32 %v127402_v42 (stack67)
        %v18301_v12 = vshll.u32 %v18295_v25, 13 (stack45)
        %v18302_v27 = vshrl.u32 %v18295_v25, 19 (stack46)
        %v16675_v23 = vand.u32 65535, %v16674_v52 (stack50)
        %v17069_v32 = vxor.u32 %v17068_v60, %v17064_v10 (stack48)
        %vm127411_vm3 = vcmp.eq.f32.partialorder %v15775_v34, 1.0 (stack68)
        %v15783_v21 = vmul.f32 inf, %v127221_v9 (stack54)
        %v15918_v50 = vmul.f32 %v15914_v6, %v127339_v50 (stack54)
        %v17461_v40 = vadd.s32 2, %v17457_v41 (stack40)
        %v15807_v61 = vsel /*vm=*/%vm15802_vm13, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v16236_v8 = vand.u32 2147483647, %v127341_v31 (stack77)
        %v17072_v22 = vadd.s32 %v17069_v32, %v17064_v10 (stack40)
        %v17878_v26 = vadd.s32 1, %v17874_v11 (stack40)
        %v15922_v43 = vadd.f32 %v15918_v50, %v15807_v61 (stack53)
        %v17449_v30 = vadd.s32 %v17445_v30, %v121564_v0 (stack40)
        %v17866_v7 = vadd.s32 %v127379_v7, %v121569_v1 (stack40)
        %v18303_v55 = vor.u32 %v18302_v27, %v18301_v12 (stack47)
        %v127425_v52 = vadd.f32 -2.5, %v127402_v42 (stack53)
        %v16676_v25 = vshrl.u32 %v16675_v23, 1 (stack51)
        %v17078_v29 = vshll.u32 %v17069_v32, 24 (stack45)
        %v17079_v10 = vshrl.u32 %v17069_v32, 8 (stack46)
        %v15926_v9 = vmul.f32 %v15922_v43, %v127221_v9 (stack54)
        %v17465_v56 = vadd.s32 %v17461_v40, %v17449_v30 (stack40)
        %v17467_v24 = vshll.u32 %v17461_v40, 13 (stack45)
        %v17468_v44 = vshrl.u32 %v17461_v40, 19 (stack46)
        %vm16308_vm4 = vcmp.eq.f32.partialorder %v127402_v42, inf (stack70)
        %v16677_v20 = vor.u32 16256, %v16676_v25 (stack47)
        %v17080_v41 = vor.u32 %v17079_v10, %v17078_v29 (stack47)
        %v17882_v60 = vadd.s32 %v17878_v26, %v17866_v7 (stack40)
        %v17884_v11 = vshll.u32 %v17878_v26, 17 (stack45)
        %v15930_v6 = vsel /*vm=*/%vm127411_vm3, /*on_true_vy=*/%v15783_v21, /*on_false_vx=*/%v15926_v9 (stack44)
        %vm16263_vm5 = vcmp.lt.f32.partialorder %v127402_v42, 5.0 (stack68)
        %vm16310_vm6 = vcmp.eq.f32.partialorder %v127402_v42, 0.0 (stack71)
        %v17469_v12 = vor.u32 %v17468_v44, %v17467_v24 (stack47)
        %v17885_v27 = vshrl.u32 %v17878_v26, 15 (stack46)
        %v18304_v23 = vxor.u32 %v18303_v55, %v18299_v46 (stack48)
        %v15934_v32 = vmul.f32 1.4140625, %v15930_v6 (stack54)
        %v16311_v34 = vand.u32 2147483648, %v127402_v42 (stack72)
        %v16678_v21 = vand.u32.u16 65535, %v16677_v20 (stack52)
        %v17081_v50 = vxor.u32 %v17080_v41, %v17072_v22 (stack48)
        %v17470_v40 = vxor.u32 %v17469_v12, %v17465_v56 (stack48)
        %v17886_v61 = vor.u32 %v17885_v27, %v17884_v11 (stack47)
        %v18307_v46 = vadd.s32 %v18304_v23, %v18299_v46 (stack40)
        %v18309_v26 = vshll.u32 %v18304_v23, 15 (stack45)
        %v15937_v43 = vpack.c.bf16 %v156663_v45, %v15934_v32 (stack81)
        %v119832_v30 = vadd.low.f32.bf16 -1.0, %v16678_v21 (stack53)
        %v17084_v7 = vadd.s32 %v17081_v50, %v121564_v0 (stack40)
        %v18310_v55 = vshrl.u32 %v18304_v23, 17 (stack46)
        %v17473_v25 = vadd.s32 %v17470_v40, %v17465_v56 (stack40)
        %v17475_v29 = vshll.u32 %v17470_v40, 15 (stack45)
        %v17476_v10 = vshrl.u32 %v17470_v40, 17 (stack46)
        %v17887_v9 = vxor.u32 %v17886_v61, %v17882_v60 (stack48)
        %v120568_v56 = vpop.eup %120567 (stack73)
        %119829 = vst [vmem:[%s123356_s30 + $0x10] sm:$0xf] /*vst_source=*/%v15937_v43 (stack83)
        %v16687_v24 = vmul.f32 2.0, %v119832_v30 (stack54)
        %v17076_v22 = vadd.s32 %v17072_v22, %v121569_v1 (stack40)
        %v17088_v44 = vadd.s32 4, %v17084_v7 (stack40)
        %v18311_v20 = vor.u32 %v18310_v55, %v18309_v26 (stack47)
        %v16307_v41 = vmul.f32 %v120568_v56, %v127402_v42 (stack74)
        %v17477_v11 = vor.u32 %v17476_v10, %v17475_v29 (stack47)
        %v17890_v60 = vadd.s32 %v17887_v9, %v17882_v60 (stack40)
        %v17892_v6 = vshll.u32 %v17887_v9, 29 (stack45)
        %v16691_v12 = vadd.f32 -0.99609375, %v16687_v24 (stack53)
        %v17092_v27 = vadd.s32 %v17088_v44, %v17076_v22 (stack40)
        %v17094_v23 = vshll.u32 %v17088_v44, 13 (stack45)
        %v17095_v32 = vshrl.u32 %v17088_v44, 19 (stack46)
        %v16309_v21 = vsel /*vm=*/%vm16308_vm4, /*on_true_vy=*/%v127402_v42, /*on_false_vx=*/%v16307_v41 (stack75)
        %v17478_v50 = vxor.u32 %v17477_v11, %v17473_v25 (stack48)
        %v17893_v40 = vshrl.u32 %v17887_v9, 3 (stack46)
        %v127442_v61 = vxor.u32 %v18311_v20, %v18307_v46 (stack48)
        %v16312_v34 = vsel /*vm=*/%vm16310_vm6, /*on_true_vy=*/%v16311_v34, /*on_false_vx=*/%v16309_v21 (stack76)
        %v127446_v26 = vmax.f32 %v16691_v12, -0.99609375 (stack55)
        %v17096_v43 = vor.u32 %v17095_v32, %v17094_v23 (stack47)
        %vm18726_vm7 = vcmp.lt.u32.totalorder %v127408_v53, %v157095_v13 (stack43)
        %v16315_v30 = vadd.f32 -3.0, %v16312_v34 (stack53)
        %v17481_v7 = vadd.s32 %v17478_v50, %v17473_v25 (stack40)
        %v17483_v55 = vshll.u32 %v17478_v50, 26 (stack45)
        %v17484_v25 = vshrl.u32 %v17478_v50, 6 (stack46)
        %v127451_v29 = vmul.f32 inf, %v127341_v31 (stack54)
        %v16300_v10 = vsel /*vm=*/%vm16263_vm5, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v16707_v9 = vxor.u32 2147483648, %v127446_v26 (stack56)
        %v17097_v56 = vxor.u32 %v17096_v43, %v17092_v27 (stack48)
        %v127460_v52 = vsel /*vm=*/%vm16263_vm5, /*on_true_vy=*/%v127425_v52, /*on_false_vx=*/%v16315_v30 (stack44)
        %v17485_v24 = vor.u32 %v17484_v25, %v17483_v55 (stack47)
        %v17894_v22 = vor.u32 %v17893_v40, %v17892_v6 (stack47)
        %v127463_v46 = vadd.s32 %v127442_v61, %v18307_v46 (stack40)
        %v16296_v44 = vsel /*vm=*/%vm16263_vm5, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v16323_v20 = vmul.f32 %v127460_v52, %v16300_v10 (stack54)
        %v127470_v41 = vmul.f32 %v16707_v9, %v127446_v26 (stack54)
        %v17100_v11 = vadd.s32 %v17097_v56, %v17092_v27 (stack40)
        %v17102_v6 = vshll.u32 %v17097_v56, 15 (stack45)
        %v17103_v12 = vshrl.u32 %v17097_v56, 17 (stack46)
        %v17486_v27 = vxor.u32 %v17485_v24, %v17481_v7 (stack48)
        %v17895_v23 = vxor.u32 %v17894_v22, %v17890_v60 (stack48)
        %v127475_v32 = vsel /*vm=*/%vm16263_vm5, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v127480_v21 = vsel /*vm=*/%vm16263_vm5, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v16327_v50 = vadd.f32 %v16323_v20, %v16296_v44 (stack53)
        %v16712_v40 = vadd.f32 1.0, %v127470_v41 (stack57)
        %v17104_v34 = vor.u32 %v17103_v12, %v17102_v6 (stack47)
        %v17489_v43 = vadd.s32 %v17486_v27, %v17481_v7 (stack40)
        %v17495_v30 = vshll.u32 %v17486_v27, 6 (stack45)
        %v17496_v7 = vshrl.u32 %v17486_v27, 26 (stack46)
        %v16284_v55 = vsel /*vm=*/%vm16263_vm5, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v16288_v25 = vsel /*vm=*/%vm16263_vm5, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v16331_v10 = vmul.f32 %v16327_v50, %v127460_v52 (stack54)
        %120569 = vlog2.f32 %v16712_v40 (stack58)
        %v16292_v9 = vsel /*vm=*/%vm16263_vm5, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v17105_v56 = vxor.u32 %v17104_v34, %v17100_v11 (stack48)
        %v17497_v24 = vor.u32 %v17496_v7, %v17495_v30 (stack47)
        %v17898_v60 = vadd.s32 %v17895_v23, %v17890_v60 (stack40)
        %v16335_v22 = vadd.f32 %v16331_v10, %v16292_v9 (stack53)
        %v16715_v44 = vmul.f32 -0.5, %v127470_v41 (stack59)
        %v17900_v20 = vshll.u32 %v17895_v23, 16 (stack45)
        %v17901_v6 = vshrl.u32 %v17895_v23, 16 (stack46)
        %v17108_v11 = vadd.s32 %v17105_v56, %v17100_v11 (stack40)
        %v17110_v12 = vshll.u32 %v17105_v56, 26 (stack45)
        %v17111_v27 = vshrl.u32 %v17105_v56, 6 (stack46)
        %v17498_v23 = vxor.u32 %v17497_v24, %v17489_v43 (stack48)
        %v16339_v50 = vmul.f32 %v16335_v22, %v127460_v52 (stack54)
        %v17902_v40 = vor.u32 %v17901_v6, %v17900_v20 (stack47)
        %v18317_v34 = vshll.u32 %v127442_v61, 26 (stack45)
        %v18318_v61 = vshrl.u32 %v127442_v61, 6 (stack46)
        %v17112_v30 = vor.u32 %v17111_v27, %v17110_v12 (stack47)
        %v17501_v7 = vadd.s32 %v17498_v23, %v121569_v1 (stack40)
        %v18717_v10 = vadd.s32 %v127408_v53, %v122657_v58 (stack40)
        %v18731_v54 = vadd.s32 %v157160_v54, %v157100_v14 (stack40)
        %v16343_v25 = vadd.f32 %v16339_v50, %v16288_v25 (stack53)
        %v16716_v9 = vadd.f32 1.0, %v16715_v44 (stack61)
        %v17903_v56 = vxor.u32 %v17902_v40, %v17898_v60 (stack48)
        %v157177_v24 = vld [vmem:[#allocation125_spill] sm:$0xff] (stack84)
        %v127504_v22 = vadd.s32 %v157177_v24, %v122651_v47 (stack40)
        %v17113_v44 = vxor.u32 %v17112_v30, %v17108_v11 (stack48)
        %v17493_v43 = vadd.s32 %v17489_v43, %v121574_v2 (stack40)
        %v17505_v20 = vadd.s32 3, %v17501_v7 (stack40)
        %v18319_v6 = vor.u32 %v18318_v61, %v18317_v34 (stack47)
        %v16347_v12 = vmul.f32 %v16343_v25, %v127460_v52 (stack54)
        %v17906_v60 = vadd.s32 %v17903_v56, %v17898_v60 (stack40)
        %v17912_v27 = vshll.u32 %v17903_v56, 24 (stack45)
        %v17913_v23 = vshrl.u32 %v17903_v56, 8 (stack46)
        %v17116_v11 = vadd.s32 %v17113_v44, %v17108_v11 (stack40)
        %v17122_v50 = vshll.u32 %v17113_v44, 6 (stack45)
        %v17123_v40 = vshrl.u32 %v17113_v44, 26 (stack46)
        %v17509_v34 = vadd.s32 %v17505_v20, %v17493_v43 (stack40)
        %v16351_v55 = vadd.f32 %v16347_v12, %v16284_v55 (stack53)
        %v17511_v61 = vshll.u32 %v17505_v20, 17 (stack45)
        %v17512_v30 = vshrl.u32 %v17505_v20, 15 (stack46)
        %v18735_v7 = vadd.s32 1, %v18731_v54 (stack40)
        %v16718_v25 = vand.u32 2147483647, %v127470_v41 (stack60)
        %v17124_v56 = vor.u32 %v17123_v40, %v17122_v50 (stack47)
        %v17914_v44 = vor.u32 %v17913_v23, %v17912_v27 (stack47)
        %v18320_v43 = vxor.u32 %v18319_v6, %v127463_v46 (stack48)
        %v16280_v20 = vsel /*vm=*/%vm16263_vm5, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v16355_v6 = vmul.f32 %v16351_v55, %v127460_v52 (stack54)
        %v17513_v12 = vor.u32 %v17512_v30, %v17511_v61 (stack47)
        %v18739_v54 = vsel /*vm=*/%vm18726_vm7, /*on_true_vy=*/%v18735_v7, /*on_false_vx=*/%v18731_v54 (stack44)
        %v120570_v27 = vpop.eup %120569 (stack64)
        %v16717_v41 = vmul.f32 %v16716_v9, %v127470_v41 (stack63)
        %v17125_v9 = vxor.u32 %v17124_v56, %v17116_v11 (stack48)
        %v17915_v23 = vxor.u32 %v17914_v44, %v17906_v60 (stack48)
        %v18323_v46 = vadd.s32 %v18320_v43, %v127463_v46 (stack40)
        %v16359_v50 = vadd.f32 %v16355_v6, %v16280_v20 (stack53)
        %v16714_v40 = vmul.f32 0.6931472, %v120570_v27 (stack65)
        %v17514_v55 = vxor.u32 %v17513_v12, %v17509_v34 (stack48)
        %v18756_v61 = vadd.s32 %v18717_v10, %v121569_v1 (stack40)
        %vm16719_vm8 = vcmp.lt.f32.partialorder %v16718_v25, 0.0004427343 (stack62)
        %v17128_v30 = vadd.s32 %v17125_v9, %v121574_v2 (stack40)
        %vm18721_vm9 = vcmp.lt.u32.totalorder %v18717_v10, %v127408_v53 (stack43)
        %v18743_v53 = vadd.s32 1, %v18739_v54 (stack40)
        %v16363_v10 = vmul.f32 %v16359_v50, %v127460_v52 (stack54)
        %v16720_v7 = vsel /*vm=*/%vm16719_vm8, /*on_true_vy=*/%v16717_v41, /*on_false_vx=*/%v16714_v40 (stack66)
        %v17517_v34 = vadd.s32 %v17514_v55, %v17509_v34 (stack40)
        %v17918_v25 = vadd.s32 %v17915_v23, %v121574_v2 (stack40)
        %v127524_v56 = vxor.u32 2147483648, %v16720_v7 (stack56)
        %v17132_v44 = vadd.s32 5, %v17128_v30 (stack40)
        %v18329_v20 = vshll.u32 %v18320_v43, 6 (stack45)
        %v18330_v43 = vshrl.u32 %v18320_v43, 26 (stack46)
        %v16367_v21 = vadd.f32 %v16363_v10, %v127480_v21 (stack53)
        %v18747_v6 = vsel /*vm=*/%vm18721_vm9, /*on_true_vy=*/%v18743_v53, /*on_false_vx=*/%v18739_v54 (stack44)
        %v18762_v12 = vshll.u32 %v18756_v61, 13 (stack45)
        %v18763_v54 = vshrl.u32 %v18756_v61, 19 (stack46)
        %120571 = vrsqrt.f32 %v127524_v56 (stack67)
        %v17120_v11 = vadd.s32 %v17116_v11, %v121564_v0 (stack40)
        %v17519_v27 = vshll.u32 %v17514_v55, 29 (stack45)
        %v17520_v41 = vshrl.u32 %v17514_v55, 3 (stack46)
        %v16272_v42 = vsel /*vm=*/%vm16263_vm5, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v16371_v9 = vmul.f32 %v16367_v21, %v127460_v52 (stack54)
        %vm16724_vm10 = vcmp.lt.f32.partialorder %v127524_v56, 5.0 (stack68)
        %v17922_v23 = vadd.s32 2, %v17918_v25 (stack40)
        %vm127536_vm11 = vcmp.eq.f32.partialorder %v16236_v8, 1.0 (stack68)
        %v16697_v50 = vand.u32 2147483647, %v127446_v26 (stack77)
        %v17134_v40 = vxor.u32 %v17132_v44, %v17120_v11 (stack48)
        %v17910_v60 = vadd.s32 %v17906_v60, %v121564_v0 (stack40)
        %v18331_v55 = vor.u32 %v18330_v43, %v18329_v20 (stack47)
        %v16375_v30 = vadd.f32 %v16371_v9, %v16272_v42 (stack53)
        %v127543_v53 = vadd.f32 -2.5, %v127524_v56 (stack53)
        %v18327_v10 = vadd.s32 %v18323_v46, %v121569_v1 (stack40)
        %v18764_v7 = vor.u32 %v18763_v54, %v18762_v12 (stack47)
        %v127549_v25 = vsel /*vm=*/%vm16724_vm10, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v127554_v44 = vsel /*vm=*/%vm16724_vm10, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v17135_v20 = vand.u32.u8 255, %v17134_v40 (stack49)
        %v17521_v43 = vor.u32 %v17520_v41, %v17519_v27 (stack47)
        %v16379_v52 = vmul.f32 %v16375_v30, %v127460_v52 (stack54)
        %v17926_v21 = vadd.s32 %v17922_v23, %v17910_v60 (stack40)
        %v17928_v12 = vshll.u32 %v17922_v23, 13 (stack45)
        %v17929_v54 = vshrl.u32 %v17922_v23, 19 (stack46)
        %v17136_v11 = vand.u32 65535, %v17135_v20 (stack50)
        %v17522_v27 = vxor.u32 %v17521_v43, %v17517_v34 (stack48)
        %v18332_v46 = vxor.u32 %v18331_v55, %v18323_v46 (stack48)
        %v18752_v6 = vadd.s32 %v18747_v6, %v121574_v2 (stack40)
        %v16383_v32 = vadd.f32 %v16379_v52, %v127475_v32 (stack53)
        %v127562_v41 = vsel /*vm=*/%vm16724_vm10, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %vm16769_vm12 = vcmp.eq.f32.partialorder %v127524_v56, inf (stack70)
        %v17930_v42 = vor.u32 %v17929_v54, %v17928_v12 (stack47)
        %vm19221_vm13 = vcmp.lt.u32.totalorder %v127504_v22, %v122651_v47 (stack43)
        %v17137_v9 = vshrl.u32 %v17136_v11, 1 (stack51)
        %v17525_v34 = vadd.s32 %v17522_v27, %v17517_v34 (stack40)
        %v17527_v23 = vshll.u32 %v17522_v27, 16 (stack45)
        %v17528_v40 = vshrl.u32 %v17522_v27, 16 (stack46)
        %v16387_v31 = vmul.f32 %v16383_v32, %v127341_v31 (stack54)
        %v17931_v60 = vxor.u32 %v17930_v42, %v17926_v21 (stack48)
        %v18335_v55 = vadd.s32 %v18332_v46, %v121564_v0 (stack40)
        %v18760_v61 = vadd.s32 %v18756_v61, %v18752_v6 (stack40)
        %v16761_v30 = vsel /*vm=*/%vm16724_vm10, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v17138_v20 = vor.u32 16256, %v17137_v9 (stack47)
        %v17529_v43 = vor.u32 %v17528_v40, %v17527_v23 (stack47)
        %v157180_v52 = vld [vmem:[#allocation68_spill] sm:$0xff] (stack84)
        %v19226_v12 = vadd.s32 %v157180_v52, %v157068_v28 (stack40)
        %v16391_v29 = vsel /*vm=*/%vm127536_vm11, /*on_true_vy=*/%v127451_v29, /*on_false_vx=*/%v16387_v31 (stack44)
        %v17934_v8 = vadd.s32 %v17931_v60, %v17926_v21 (stack40)
        %v17936_v21 = vshll.u32 %v17931_v60, 15 (stack45)
        %v17937_v54 = vshrl.u32 %v17931_v60, 17 (stack46)
        %v16395_v11 = vmul.f32 1.4140625, %v16391_v29 (stack54)
        %v17139_v27 = vand.u32.u16 65535, %v17138_v20 (stack52)
        %v17530_v46 = vxor.u32 %v17529_v43, %v17525_v34 (stack48)
        %v18339_v6 = vadd.s32 1, %v18335_v55 (stack40)
        %v120572_v32 = vpop.eup %120571 (stack73)
        %vm16771_vm14 = vcmp.eq.f32.partialorder %v127524_v56, 0.0 (stack71)
        %v16772_v42 = vand.u32 2147483648, %v127524_v56 (stack72)
        %v17938_v9 = vor.u32 %v17937_v54, %v17936_v21 (stack47)
        %v18765_v7 = vxor.u32 %v18764_v7, %v18760_v61 (stack48)
        %v16398_v23 = vpack.c.bf16 %v156663_v45, %v16395_v11 (stack81)
        %v16768_v40 = vmul.f32 %v120572_v32, %v127524_v56 (stack74)
        %v119834_v31 = vadd.low.f32.bf16 -1.0, %v17139_v27 (stack53)
        %v17533_v34 = vadd.s32 %v17530_v46, %v17525_v34 (stack40)
        %v17539_v60 = vshll.u32 %v17530_v46, 24 (stack45)
        %v17540_v55 = vshrl.u32 %v17530_v46, 8 (stack46)
        %v17939_v20 = vxor.u32 %v17938_v9, %v17934_v8 (stack48)
        %v18343_v10 = vadd.s32 %v18339_v6, %v18327_v10 (stack40)
        %119831 = vst [vmem:[%s123356_s30 + $0x90] sm:$0xf] /*vst_source=*/%v16398_v23 (stack83)
        %v16770_v43 = vsel /*vm=*/%vm16769_vm12, /*on_true_vy=*/%v127524_v56, /*on_false_vx=*/%v16768_v40 (stack75)
        %v17148_v29 = vmul.f32 2.0, %v119834_v31 (stack54)
        %v18345_v21 = vshll.u32 %v18339_v6, 17 (stack45)
        %v19230_v54 = vadd.s32 1, %v19226_v12 (stack40)
        %v16773_v11 = vsel /*vm=*/%vm16771_vm14, /*on_true_vy=*/%v16772_v42, /*on_false_vx=*/%v16770_v43 (stack76)
        %v17541_v27 = vor.u32 %v17540_v55, %v17539_v60 (stack47)
        %v17942_v8 = vadd.s32 %v17939_v20, %v17934_v8 (stack40)
        %v17944_v46 = vshll.u32 %v17939_v20, 26 (stack45)
        %v16776_v32 = vadd.f32 -3.0, %v16773_v11 (stack53)
        %v17152_v42 = vadd.f32 -0.99609375, %v17148_v29 (stack53)
        %v17945_v9 = vshrl.u32 %v17939_v20, 6 (stack46)
        %v18346_v6 = vshrl.u32 %v18339_v6, 15 (stack46)
        %v17542_v23 = vxor.u32 %v17541_v27, %v17533_v34 (stack48)
        %v18768_v61 = vadd.s32 %v18765_v7, %v18760_v61 (stack40)
        %v18770_v40 = vshll.u32 %v18765_v7, 15 (stack45)
        %v18771_v7 = vshrl.u32 %v18765_v7, 17 (stack46)
        %v127590_v53 = vsel /*vm=*/%vm16724_vm10, /*on_true_vy=*/%v127543_v53, /*on_false_vx=*/%v16776_v32 (stack44)
        %v127592_v31 = vmax.f32 %v17152_v42, -0.99609375 (stack55)
        %v17946_v60 = vor.u32 %v17945_v9, %v17944_v46 (stack47)
        %v18347_v55 = vor.u32 %v18346_v6, %v18345_v21 (stack47)
        %v16784_v30 = vmul.f32 %v127590_v53, %v16761_v30 (stack54)
        %v17545_v20 = vadd.s32 %v17542_v23, %v121564_v0 (stack40)
        %v18772_v43 = vor.u32 %v18771_v7, %v18770_v40 (stack47)
        %v19234_v12 = vsel /*vm=*/%vm19221_vm13, /*on_true_vy=*/%v19230_v54, /*on_false_vx=*/%v19226_v12 (stack44)
        %v17168_v29 = vxor.u32 2147483648, %v127592_v31 (stack56)
        %v17537_v34 = vadd.s32 %v17533_v34, %v121569_v1 (stack40)
        %v17947_v21 = vxor.u32 %v17946_v60, %v17942_v8 (stack48)
        %v19212_v54 = vadd.s32 %v127504_v22, %v122657_v58 (stack40)
        %v16788_v41 = vadd.f32 %v16784_v30, %v127562_v41 (stack53)
        %v17549_v11 = vadd.s32 4, %v17545_v20 (stack40)
        %v18348_v27 = vxor.u32 %v18347_v55, %v18343_v10 (stack48)
        %v18773_v46 = vxor.u32 %v18772_v43, %v18768_v61 (stack48)
        %v16745_v32 = vsel /*vm=*/%vm16724_vm10, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v17171_v42 = vmul.f32 %v17168_v29, %v127592_v31 (stack54)
        %v17950_v8 = vadd.s32 %v17947_v21, %v17942_v8 (stack40)
        %v17956_v9 = vshll.u32 %v17947_v21, 6 (stack45)
        %v16792_v6 = vmul.f32 %v16788_v41, %v127590_v53 (stack54)
        %v17553_v23 = vadd.s32 %v17549_v11, %v17537_v34 (stack40)
        %v17555_v40 = vshll.u32 %v17549_v11, 13 (stack45)
        %v17556_v7 = vshrl.u32 %v17549_v11, 19 (stack46)
        %v16749_v60 = vsel /*vm=*/%vm16724_vm10, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v16753_v55 = vsel /*vm=*/%vm16724_vm10, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v17173_v30 = vadd.f32 1.0, %v17171_v42 (stack57)
        %vm19216_vm15 = vcmp.lt.u32.totalorder %v19212_v54, %v127504_v22 (stack43)
        %v16796_v20 = vadd.f32 %v16792_v6, %v16753_v55 (stack53)
        %v17557_v43 = vor.u32 %v17556_v7, %v17555_v40 (stack47)
        %v17957_v29 = vshrl.u32 %v17947_v21, 26 (stack46)
        %v18351_v10 = vadd.s32 %v18348_v27, %v18343_v10 (stack40)
        %120573 = vlog2.f32 %v17173_v30 (stack58)
        %v17176_v34 = vmul.f32 -0.5, %v17171_v42 (stack59)
        %v18353_v21 = vshll.u32 %v18348_v27, 29 (stack45)
        %v127617_v41 = vadd.s32 %v19212_v54, %v121569_v1 (stack40)
        %v16800_v11 = vmul.f32 %v16796_v20, %v127590_v53 (stack54)
        %v17558_v6 = vxor.u32 %v17557_v43, %v17553_v23 (stack48)
        %v17958_v9 = vor.u32 %v17957_v29, %v17956_v9 (stack47)
        %v18354_v27 = vshrl.u32 %v18348_v27, 3 (stack46)
        %v17179_v40 = vand.u32 2147483647, %v17171_v42 (stack60)
        %v18776_v61 = vadd.s32 %v18773_v46, %v18768_v61 (stack40)
        %v18778_v7 = vshll.u32 %v18773_v46, 26 (stack45)
        %v18779_v46 = vshrl.u32 %v18773_v46, 6 (stack46)
        %v16804_v60 = vadd.f32 %v16800_v11, %v16749_v60 (stack53)
        %v17561_v23 = vadd.s32 %v17558_v6, %v17553_v23 (stack40)
        %v17563_v55 = vshll.u32 %v17558_v6, 15 (stack45)
        %v17564_v30 = vshrl.u32 %v17558_v6, 17 (stack46)
        %v17959_v20 = vxor.u32 %v17958_v9, %v17950_v8 (stack48)
        %v18355_v43 = vor.u32 %v18354_v27, %v18353_v21 (stack47)
        %v18780_v29 = vor.u32 %v18779_v46, %v18778_v7 (stack47)
        %v19238_v21 = vadd.s32 1, %v19234_v12 (stack40)
        %v16808_v11 = vmul.f32 %v16804_v60, %v127590_v53 (stack54)
        %v17177_v34 = vadd.f32 1.0, %v17176_v34 (stack61)
        %v17565_v6 = vor.u32 %v17564_v30, %v17563_v55 (stack47)
        %v17954_v8 = vadd.s32 %v17950_v8, %v121574_v2 (stack40)
        %v17962_v9 = vadd.s32 %v17959_v20, %v121569_v1 (stack40)
        %v18356_v27 = vxor.u32 %v18355_v43, %v18351_v10 (stack48)
        %v18781_v7 = vxor.u32 %v18780_v29, %v18776_v61 (stack48)
        %v19242_v22 = vsel /*vm=*/%vm19216_vm15, /*on_true_vy=*/%v19238_v21, /*on_false_vx=*/%v19234_v12 (stack44)
        %v16812_v12 = vadd.f32 %v16808_v11, %v16745_v32 (stack53)
        %vm127625_vm0 = vcmp.lt.f32.partialorder %v17179_v40, 0.0004427343 (stack62)
        %v17566_v32 = vxor.u32 %v17565_v6, %v17561_v23 (stack48)
        %v19247_v40 = vadd.s32 %v19242_v22, %v121574_v2 (stack40)
        %v17966_v46 = vadd.s32 3, %v17962_v9 (stack40)
        %v18359_v10 = vadd.s32 %v18356_v27, %v18351_v10 (stack40)
        %v18361_v60 = vshll.u32 %v18356_v27, 16 (stack45)
        %v18362_v55 = vshrl.u32 %v18356_v27, 16 (stack46)
        %v16816_v30 = vmul.f32 %v16812_v12, %v127590_v53 (stack54)
        %v17569_v23 = vadd.s32 %v17566_v32, %v17561_v23 (stack40)
        %v17571_v20 = vshll.u32 %v17566_v32, 26 (stack45)
        %v17572_v43 = vshrl.u32 %v17566_v32, 6 (stack46)
        %v17970_v29 = vadd.s32 %v17966_v46, %v17954_v8 (stack40)
        %v17972_v21 = vshll.u32 %v17966_v46, 17 (stack45)
        %v17973_v11 = vshrl.u32 %v17966_v46, 15 (stack46)
        %v18363_v6 = vor.u32 %v18362_v55, %v18361_v60 (stack47)
        %v16820_v44 = vadd.f32 %v16816_v30, %v127554_v44 (stack53)
        %v17178_v42 = vmul.f32 %v17177_v34, %v17171_v42 (stack63)
        %v17573_v34 = vor.u32 %v17572_v43, %v17571_v20 (stack47)
        %v127632_v61 = vadd.s32 %v18781_v7, %v18776_v61 (stack40)
        %v17974_v8 = vor.u32 %v17973_v11, %v17972_v21 (stack47)
        %v18364_v9 = vxor.u32 %v18363_v6, %v18359_v10 (stack48)
        %v127635_v27 = vadd.s32 %v127617_v41, %v19247_v40 (stack40)
        %v19257_v22 = vshll.u32 %v127617_v41, 13 (stack45)
        %v120574_v12 = vpop.eup %120573 (stack64)
        %v16824_v32 = vmul.f32 %v16820_v44, %v127590_v53 (stack54)
        %v17574_v40 = vxor.u32 %v17573_v34, %v17569_v23 (stack48)
        %v18790_v46 = vshll.u32 %v18781_v7, 6 (stack45)
        %v127641_v60 = vadd.s32 %v157177_v24, %v157070_v38 (stack40)
        %v17175_v55 = vmul.f32 0.6931472, %v120574_v12 (stack65)
        %v17975_v30 = vxor.u32 %v17974_v8, %v17970_v29 (stack48)
        %v18367_v10 = vadd.s32 %v18364_v9, %v18359_v10 (stack40)
        %v18791_v7 = vshrl.u32 %v18781_v7, 26 (stack46)
        %v16828_v25 = vadd.f32 %v16824_v32, %v127549_v25 (stack53)
        %v17577_v23 = vadd.s32 %v17574_v40, %v17569_v23 (stack40)
        %v17583_v20 = vshll.u32 %v17574_v40, 6 (stack45)
        %v17584_v43 = vshrl.u32 %v17574_v40, 26 (stack46)
        %v17181_v54 = vsel /*vm=*/%vm127625_vm0, /*on_true_vy=*/%v17178_v42, /*on_false_vx=*/%v17175_v55 (stack66)
        %v17978_v29 = vadd.s32 %v17975_v30, %v17970_v29 (stack40)
        %v17980_v21 = vshll.u32 %v17975_v30, 29 (stack45)
        %v17981_v11 = vshrl.u32 %v17975_v30, 3 (stack46)
        %v16832_v6 = vmul.f32 %v16828_v25, %v127590_v53 (stack54)
        %v127647_v44 = vxor.u32 2147483648, %v17181_v54 (stack56)
        %v17585_v42 = vor.u32 %v17584_v43, %v17583_v20 (stack47)
        %v19258_v41 = vshrl.u32 %v127617_v41, 19 (stack46)
        %vm127652_vm1 = vcmp.eq.f32.partialorder %v16697_v50, 1.0 (stack68)
        %v16705_v34 = vmul.f32 inf, %v127446_v26 (stack54)
        %v16733_v8 = vsel /*vm=*/%vm16724_vm10, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v16836_v12 = vadd.f32 %v16832_v6, %v16733_v8 (stack53)
        %120575 = vrsqrt.f32 %v127647_v44 (stack67)
        %v17982_v32 = vor.u32 %v17981_v11, %v17980_v21 (stack47)
        %v18373_v40 = vshll.u32 %v18364_v9, 24 (stack45)
        %vm17185_vm2 = vcmp.lt.f32.partialorder %v127647_v44, 5.0 (stack68)
        %v17586_v55 = vxor.u32 %v17585_v42, %v17577_v23 (stack48)
        %v18374_v9 = vshrl.u32 %v18364_v9, 8 (stack46)
        %v18792_v46 = vor.u32 %v18791_v7, %v18790_v46 (stack47)
        %v16729_v56 = vsel /*vm=*/%vm16724_vm10, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v16840_v53 = vmul.f32 %v16836_v12, %v127590_v53 (stack54)
        %v18788_v30 = vadd.s32 %v127632_v61, %v121569_v1 (stack40)
        %v19259_v22 = vor.u32 %v19258_v41, %v19257_v22 (stack47)
        %v127669_v7 = vadd.f32 -2.5, %v127647_v44 (stack53)
        %v17581_v25 = vadd.s32 %v17577_v23, %v121564_v0 (stack40)
        %v17589_v23 = vadd.s32 %v17586_v55, %v121574_v2 (stack40)
        %v18371_v20 = vadd.s32 %v18367_v10, %v121564_v0 (stack40)
        %v16844_v43 = vadd.f32 %v16840_v53, %v16729_v56 (stack53)
        %v127677_v54 = vsel /*vm=*/%vm17185_vm2, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v127682_v21 = vsel /*vm=*/%vm17185_vm2, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v127687_v11 = vsel /*vm=*/%vm17185_vm2, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v17593_v6 = vadd.s32 5, %v17589_v23 (stack40)
        %v17983_v42 = vxor.u32 %v17982_v32, %v17978_v29 (stack48)
        %v18375_v41 = vor.u32 %v18374_v9, %v18373_v40 (stack47)
        %v18793_v61 = vxor.u32 %v18792_v46, %v127632_v61 (stack48)
        %v16848_v26 = vmul.f32 %v16844_v43, %v127446_v26 (stack54)
        %v17233_v8 = vand.u32 2147483648, %v127647_v44 (stack72)
        %v19260_v12 = vxor.u32 %v19259_v22, %v127635_v27 (stack48)
        %vm19682_vm3 = vcmp.lt.u32.totalorder %v127641_v60, %v157070_v38 (stack43)
        %vm17230_vm4 = vcmp.eq.f32.partialorder %v127647_v44, inf (stack70)
        %v17595_v32 = vxor.u32 %v17593_v6, %v17581_v25 (stack48)
        %v17986_v29 = vadd.s32 %v17983_v42, %v17978_v29 (stack40)
        %v17988_v40 = vshll.u32 %v17983_v42, 16 (stack45)
        %v17989_v55 = vshrl.u32 %v17983_v42, 16 (stack46)
        %v16852_v50 = vsel /*vm=*/%vm127652_vm1, /*on_true_vy=*/%v16705_v34, /*on_false_vx=*/%v16848_v26 (stack44)
        %vm17232_vm5 = vcmp.eq.f32.partialorder %v127647_v44, 0.0 (stack71)
        %v18376_v10 = vxor.u32 %v18375_v41, %v18367_v10 (stack48)
        %v18796_v34 = vadd.s32 %v18793_v61, %v121564_v0 (stack40)
        %v19263_v27 = vadd.s32 %v19260_v12, %v127635_v27 (stack40)
        %v16856_v9 = vmul.f32 1.4140625, %v16852_v50 (stack54)
        %v17596_v46 = vand.u32.u8 255, %v17595_v32 (stack49)
        %v17990_v56 = vor.u32 %v17989_v55, %v17988_v40 (stack47)
        %v127703_v53 = vadd.s32 %v127641_v60, %v122657_v58 (stack40)
        %v18379_v22 = vadd.s32 %v18376_v10, %v121574_v2 (stack40)
        %v18800_v25 = vadd.s32 1, %v18796_v34 (stack40)
        %v19265_v23 = vshll.u32 %v19260_v12, 15 (stack45)
        %v19266_v43 = vshrl.u32 %v19260_v12, 17 (stack46)
        %v16859_v6 = vpack.c.bf16 %v156663_v45, %v16856_v9 (stack81)
        %v17597_v42 = vand.u32 65535, %v17596_v46 (stack50)
        %v17991_v41 = vxor.u32 %v17990_v56, %v17986_v29 (stack48)
        %v19687_v61 = vadd.s32 %v157180_v52, %v157076_v35 (stack40)
        %v18383_v26 = vadd.s32 2, %v18379_v22 (stack40)
        %v18804_v30 = vadd.s32 %v18800_v25, %v18788_v30 (stack40)
        %v18806_v12 = vshll.u32 %v18800_v25, 17 (stack45)
        %v18807_v32 = vshrl.u32 %v18800_v25, 15 (stack46)
        %v120576_v40 = vpop.eup %120575 (stack73)
        %119833 = vst [vmem:[%s123356_s30 + $0x110] sm:$0xf] /*vst_source=*/%v16859_v6 (stack83)
        %v17598_v55 = vshrl.u32 %v17597_v42, 1 (stack51)
        %v17994_v29 = vadd.s32 %v17991_v41, %v17986_v29 (stack40)
        %v18000_v50 = vshll.u32 %v17991_v41, 24 (stack45)
        %v18001_v10 = vshrl.u32 %v17991_v41, 8 (stack46)
        %v17229_v34 = vmul.f32 %v120576_v40, %v127647_v44 (stack74)
        %v18387_v20 = vadd.s32 %v18383_v26, %v18371_v20 (stack40)
        %v18389_v9 = vshll.u32 %v18383_v26, 13 (stack45)
        %v18390_v46 = vshrl.u32 %v18383_v26, 19 (stack46)
        %v17599_v56 = vor.u32 16256, %v17598_v55 (stack47)
        %v17998_v22 = vadd.s32 %v17994_v29, %v121569_v1 (stack40)
        %v18002_v25 = vor.u32 %v18001_v10, %v18000_v50 (stack47)
        %v18808_v6 = vor.u32 %v18807_v32, %v18806_v12 (stack47)
        %v17231_v42 = vsel /*vm=*/%vm17230_vm4, /*on_true_vy=*/%v127647_v44, /*on_false_vx=*/%v17229_v34 (stack75)
        %v18391_v41 = vor.u32 %v18390_v46, %v18389_v9 (stack47)
        %v19267_v23 = vor.u32 %v19266_v43, %v19265_v23 (stack47)
        %v19691_v43 = vadd.s32 1, %v19687_v61 (stack40)
        %v17234_v8 = vsel /*vm=*/%vm17232_vm5, /*on_true_vy=*/%v17233_v8, /*on_false_vx=*/%v17231_v42 (stack76)
        %v17600_v26 = vand.u32.u16 65535, %v17599_v56 (stack52)
        %v18003_v12 = vxor.u32 %v18002_v25, %v17994_v29 (stack48)
        %v18809_v32 = vxor.u32 %v18808_v6, %v18804_v30 (stack48)
        %v17237_v40 = vadd.f32 -3.0, %v17234_v8 (stack53)
        %v18392_v55 = vxor.u32 %v18391_v41, %v18387_v20 (stack48)
        %v19268_v29 = vxor.u32 %v19267_v23, %v19263_v27 (stack48)
        %v19695_v61 = vsel /*vm=*/%vm19682_vm3, /*on_true_vy=*/%v19691_v43, /*on_false_vx=*/%v19687_v61 (stack44)
        %v119836_v50 = vadd.low.f32.bf16 -1.0, %v17600_v26 (stack53)
        %v18006_v10 = vadd.s32 %v18003_v12, %v121564_v0 (stack40)
        %v18812_v30 = vadd.s32 %v18809_v32, %v18804_v30 (stack40)
        %v18814_v34 = vshll.u32 %v18809_v32, 29 (stack45)
        %v127724_v7 = vsel /*vm=*/%vm17185_vm2, /*on_true_vy=*/%v127669_v7, /*on_false_vx=*/%v17237_v40 (stack44)
        %v18395_v20 = vadd.s32 %v18392_v55, %v18387_v20 (stack40)
        %v18397_v9 = vshll.u32 %v18392_v55, 15 (stack45)
        %v18398_v46 = vshrl.u32 %v18392_v55, 17 (stack46)
        %v17245_v11 = vmul.f32 %v127724_v7, %v127687_v11 (stack54)
        %v17609_v56 = vmul.f32 2.0, %v119836_v50 (stack54)
        %v18010_v25 = vadd.s32 4, %v18006_v10 (stack40)
        %v18815_v6 = vshrl.u32 %v18809_v32, 3 (stack46)
        %v18399_v42 = vor.u32 %v18398_v46, %v18397_v9 (stack47)
        %v19271_v27 = vadd.s32 %v19268_v29, %v19263_v27 (stack40)
        %v19273_v41 = vshll.u32 %v19268_v29, 26 (stack45)
        %v19274_v23 = vshrl.u32 %v19268_v29, 6 (stack46)
        %v17249_v21 = vadd.f32 %v17245_v11, %v127682_v21 (stack53)
        %v17613_v43 = vadd.f32 -0.99609375, %v17609_v56 (stack53)
        %v18014_v22 = vadd.s32 %v18010_v25, %v17998_v22 (stack40)
        %v18016_v8 = vshll.u32 %v18010_v25, 13 (stack45)
        %v18017_v26 = vshrl.u32 %v18010_v25, 19 (stack46)
        %v18400_v12 = vxor.u32 %v18399_v42, %v18395_v20 (stack48)
        %v18816_v32 = vor.u32 %v18815_v6, %v18814_v34 (stack47)
        %v19275_v40 = vor.u32 %v19274_v23, %v19273_v41 (stack47)
        %v17253_v55 = vmul.f32 %v17249_v21, %v127724_v7 (stack54)
        %v127730_v29 = vmax.f32 %v17613_v43, -0.99609375 (stack55)
        %vm19677_vm6 = vcmp.lt.u32.totalorder %v127703_v53, %v127641_v60 (stack43)
        %v19699_v60 = vadd.s32 1, %v19695_v61 (stack40)
        %v18018_v50 = vor.u32 %v18017_v26, %v18016_v8 (stack47)
        %v18403_v10 = vadd.s32 %v18400_v12, %v18395_v20 (stack40)
        %v18405_v34 = vshll.u32 %v18400_v12, 26 (stack45)
        %v18406_v20 = vshrl.u32 %v18400_v12, 6 (stack46)
        %v17257_v54 = vadd.f32 %v17253_v55, %v127677_v54 (stack53)
        %v17629_v9 = vxor.u32 2147483648, %v127730_v29 (stack56)
        %v18019_v46 = vxor.u32 %v18018_v50, %v18014_v22 (stack48)
        %v18407_v11 = vor.u32 %v18406_v20, %v18405_v34 (stack47)
        %v18817_v56 = vxor.u32 %v18816_v32, %v18812_v30 (stack48)
        %v19276_v25 = vxor.u32 %v19275_v40, %v19271_v27 (stack48)
        %v17210_v6 = vsel /*vm=*/%vm17185_vm2, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v17261_v42 = vmul.f32 %v17257_v54, %v127724_v7 (stack54)
        %v127741_v41 = vmul.f32 %v17629_v9, %v127730_v29 (stack54)
        %v19703_v61 = vsel /*vm=*/%vm19677_vm6, /*on_true_vy=*/%v19699_v60, /*on_false_vx=*/%v19695_v61 (stack44)
        %v18022_v23 = vadd.s32 %v18019_v46, %v18014_v22 (stack40)
        %v18024_v21 = vshll.u32 %v18019_v46, 15 (stack45)
        %v18025_v43 = vshrl.u32 %v18019_v46, 17 (stack46)
        %v18408_v22 = vxor.u32 %v18407_v11, %v18403_v10 (stack48)
        %v17158_v8 = vand.u32 2147483647, %v127592_v31 (stack77)
        %v127747_v26 = vsel /*vm=*/%vm17185_vm2, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v17265_v12 = vadd.f32 %v17261_v42, %v17210_v6 (stack53)
        %v17634_v32 = vadd.f32 1.0, %v127741_v41 (stack57)
        %v18026_v40 = vor.u32 %v18025_v43, %v18024_v21 (stack47)
        %v18411_v55 = vadd.s32 %v18408_v22, %v18403_v10 (stack40)
        %v18417_v60 = vshll.u32 %v18408_v22, 6 (stack45)
        %v18418_v50 = vshrl.u32 %v18408_v22, 26 (stack46)
        %v17198_v10 = vsel /*vm=*/%vm17185_vm2, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v17202_v34 = vsel /*vm=*/%vm17185_vm2, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v17269_v20 = vmul.f32 %v17265_v12, %v127724_v7 (stack54)
        %120577 = vlog2.f32 %v17634_v32 (stack58)
        %v17206_v54 = vsel /*vm=*/%vm17185_vm2, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v18027_v9 = vxor.u32 %v18026_v40, %v18022_v23 (stack48)
        %v18419_v46 = vor.u32 %v18418_v50, %v18417_v60 (stack47)
        %v18820_v30 = vadd.s32 %v18817_v56, %v18812_v30 (stack40)
        %v17273_v11 = vadd.f32 %v17269_v20, %v17206_v54 (stack53)
        %v18822_v6 = vshll.u32 %v18817_v56, 16 (stack45)
        %v18823_v56 = vshrl.u32 %v18817_v56, 16 (stack46)
        %v127762_v53 = vadd.s32 %v127703_v53, %v121569_v1 (stack40)
        %v18030_v42 = vadd.s32 %v18027_v9, %v18022_v23 (stack40)
        %v18032_v23 = vshll.u32 %v18027_v9, 26 (stack45)
        %v18033_v21 = vshrl.u32 %v18027_v9, 6 (stack46)
        %v18420_v43 = vxor.u32 %v18419_v46, %v18411_v55 (stack48)
        %v17277_v22 = vmul.f32 %v17273_v11, %v127724_v7 (stack54)
        %v18824_v12 = vor.u32 %v18823_v56, %v18822_v6 (stack47)
        %v19279_v27 = vadd.s32 %v19276_v25, %v19271_v27 (stack40)
        %v19285_v32 = vshll.u32 %v19276_v25, 6 (stack45)
        %v18034_v40 = vor.u32 %v18033_v21, %v18032_v23 (stack47)
        %v18423_v60 = vadd.s32 %v18420_v43, %v121569_v1 (stack40)
        %v19286_v25 = vshrl.u32 %v19276_v25, 26 (stack46)
        %v19708_v61 = vadd.s32 %v19703_v61, %v121574_v2 (stack40)
        %v17281_v50 = vadd.f32 %v17277_v22, %v17202_v34 (stack53)
        %v17637_v34 = vmul.f32 -0.5, %v127741_v41 (stack59)
        %v18415_v55 = vadd.s32 %v18411_v55, %v121574_v2 (stack40)
        %v18825_v20 = vxor.u32 %v18824_v12, %v18820_v30 (stack48)
        %v18035_v54 = vxor.u32 %v18034_v40, %v18030_v42 (stack48)
        %v18427_v9 = vadd.s32 3, %v18423_v60 (stack40)
        %v19287_v46 = vor.u32 %v19286_v25, %v19285_v32 (stack47)
        %v127770_v11 = vadd.s32 %v127762_v53, %v19708_v61 (stack40)
        %v17285_v6 = vmul.f32 %v17281_v50, %v127724_v7 (stack54)
        %v18828_v30 = vadd.s32 %v18825_v20, %v18820_v30 (stack40)
        %v18834_v56 = vshll.u32 %v18825_v20, 24 (stack45)
        %v18835_v23 = vshrl.u32 %v18825_v20, 8 (stack46)
        %v18038_v42 = vadd.s32 %v18035_v54, %v18030_v42 (stack40)
        %v18044_v21 = vshll.u32 %v18035_v54, 6 (stack45)
        %v18045_v43 = vshrl.u32 %v18035_v54, 26 (stack46)
        %v18431_v22 = vadd.s32 %v18427_v9, %v18415_v55 (stack40)
        %v17289_v10 = vadd.f32 %v17285_v6, %v17198_v10 (stack53)
        %v17638_v12 = vadd.f32 1.0, %v17637_v34 (stack61)
        %v18433_v32 = vshll.u32 %v18427_v9, 17 (stack45)
        %v18434_v40 = vshrl.u32 %v18427_v9, 15 (stack46)
        %v17640_v60 = vand.u32 2147483647, %v127741_v41 (stack60)
        %v18046_v25 = vor.u32 %v18045_v43, %v18044_v21 (stack47)
        %v18836_v61 = vor.u32 %v18835_v23, %v18834_v56 (stack47)
        %v19288_v50 = vxor.u32 %v19287_v46, %v19279_v27 (stack48)
        %v17194_v44 = vsel /*vm=*/%vm17185_vm2, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v17293_v34 = vmul.f32 %v17289_v10, %v127724_v7 (stack54)
        %v18435_v55 = vor.u32 %v18434_v40, %v18433_v32 (stack47)
        %v127780_v20 = vadd.s32 %v157177_v24, %v157077_v51 (stack40)
        %v120578_v54 = vpop.eup %120577 (stack64)
        %v18047_v9 = vxor.u32 %v18046_v25, %v18038_v42 (stack48)
        %v18837_v46 = vxor.u32 %v18836_v61, %v18828_v30 (stack48)
        %v19291_v6 = vadd.s32 %v19288_v50, %v121564_v0 (stack40)
        %v127785_v56 = vadd.s32 %v157180_v52, %v157078_v48 (stack40)
        %v17297_v23 = vadd.f32 %v17293_v34, %v17194_v44 (stack53)
        %v17636_v21 = vmul.f32 0.6931472, %v120578_v54 (stack65)
        %v17639_v41 = vmul.f32 %v17638_v12, %v127741_v41 (stack63)
        %v18436_v43 = vxor.u32 %v18435_v55, %v18431_v22 (stack48)
        %vm17641_vm7 = vcmp.lt.f32.partialorder %v17640_v60, 0.0004427343 (stack62)
        %v18050_v10 = vadd.s32 %v18047_v9, %v121574_v2 (stack40)
        %v19283_v27 = vadd.s32 %v19279_v27, %v121569_v1 (stack40)
        %v19295_v12 = vadd.s32 1, %v19291_v6 (stack40)
        %v17301_v7 = vmul.f32 %v17297_v23, %v127724_v7 (stack54)
        %v17642_v32 = vsel /*vm=*/%vm17641_vm7, /*on_true_vy=*/%v17639_v41, /*on_false_vx=*/%v17636_v21 (stack66)
        %v18439_v22 = vadd.s32 %v18436_v43, %v18431_v22 (stack40)
        %v18840_v40 = vadd.s32 %v18837_v46, %v121574_v2 (stack40)
        %v127792_v60 = vxor.u32 2147483648, %v17642_v32 (stack56)
        %v18054_v25 = vadd.s32 5, %v18050_v10 (stack40)
        %v19718_v61 = vshll.u32 %v127762_v53, 13 (stack45)
        %v19719_v53 = vshrl.u32 %v127762_v53, 19 (stack46)
        %vm127798_vm8 = vcmp.eq.f32.partialorder %v17158_v8, 1.0 (stack68)
        %v17166_v50 = vmul.f32 inf, %v127592_v31 (stack54)
        %v17305_v26 = vadd.f32 %v17301_v7, %v127747_v26 (stack53)
        %v19299_v44 = vadd.s32 %v19295_v12, %v19283_v27 (stack40)
        %vm17646_vm9 = vcmp.lt.f32.partialorder %v127792_v60, 5.0 (stack68)
        %120579 = vrsqrt.f32 %v127792_v60 (stack67)
        %v18042_v42 = vadd.s32 %v18038_v42, %v121564_v0 (stack40)
        %v18832_v30 = vadd.s32 %v18828_v30, %v121564_v0 (stack40)
        %v17309_v31 = vmul.f32 %v17305_v26, %v127592_v31 (stack54)
        %v18441_v34 = vshll.u32 %v18436_v43, 29 (stack45)
        %v18442_v55 = vshrl.u32 %v18436_v43, 3 (stack46)
        %v18844_v54 = vadd.s32 2, %v18840_v40 (stack40)
        %v18056_v9 = vxor.u32 %v18054_v25, %v18042_v42 (stack48)
        %v19301_v46 = vshll.u32 %v19295_v12, 17 (stack45)
        %v19302_v6 = vshrl.u32 %v19295_v12, 15 (stack46)
        %v19720_v23 = vor.u32 %v19719_v53, %v19718_v61 (stack47)
        %v17313_v21 = vsel /*vm=*/%vm127798_vm8, /*on_true_vy=*/%v17166_v50, /*on_false_vx=*/%v17309_v31 (stack44)
        %v127814_v41 = vsel /*vm=*/%vm17646_vm9, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v127817_v43 = vadd.f32 -2.5, %v127792_v60 (stack53)
        %v127821_v10 = vadd.s32 %v127780_v20, %v122657_v58 (stack40)
        %v17317_v27 = vmul.f32 1.4140625, %v17313_v21 (stack54)
        %v127826_v12 = vsel /*vm=*/%vm17646_vm9, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v127831_v7 = vsel /*vm=*/%vm17646_vm9, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v18057_v32 = vand.u32.u8 255, %v18056_v9 (stack49)
        %v18443_v40 = vor.u32 %v18442_v55, %v18441_v34 (stack47)
        %v18848_v25 = vadd.s32 %v18844_v54, %v18832_v30 (stack40)
        %v18850_v61 = vshll.u32 %v18844_v54, 13 (stack45)
        %v18851_v53 = vshrl.u32 %v18844_v54, 19 (stack46)
        %v17320_v8 = vpack.c.bf16 %v156663_v45, %v17317_v27 (stack81)
        %v18058_v50 = vand.u32 65535, %v18057_v32 (stack50)
        %v19303_v26 = vor.u32 %v19302_v6, %v19301_v46 (stack47)
        %v19721_v42 = vxor.u32 %v19720_v23, %v127770_v11 (stack48)
        %v127838_v30 = vsel /*vm=*/%vm17646_vm9, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %vm17691_vm10 = vcmp.eq.f32.partialorder %v127792_v60, inf (stack70)
        %v18444_v31 = vxor.u32 %v18443_v40, %v18439_v22 (stack48)
        %v18852_v34 = vor.u32 %v18851_v53, %v18850_v61 (stack47)
        %vm20143_vm11 = vcmp.lt.u32.totalorder %v127780_v20, %v157077_v51 (stack43)
        %119835 = vst [vmem:[%s123356_s30 + $0x190] sm:$0xf] /*vst_source=*/%v17320_v8 (stack83)
        %v18059_v55 = vshrl.u32 %v18058_v50, 1 (stack51)
        %v19304_v54 = vxor.u32 %v19303_v26, %v19299_v44 (stack48)
        %v19724_v11 = vadd.s32 %v19721_v42, %v127770_v11 (stack40)
        %v19726_v9 = vshll.u32 %v19721_v42, 15 (stack45)
        %v18447_v22 = vadd.s32 %v18444_v31, %v18439_v22 (stack40)
        %v18449_v46 = vshll.u32 %v18444_v31, 16 (stack45)
        %v18450_v6 = vshrl.u32 %v18444_v31, 16 (stack46)
        %v18853_v23 = vxor.u32 %v18852_v34, %v18848_v25 (stack48)
        %v18060_v21 = vor.u32 16256, %v18059_v55 (stack47)
        %v19307_v44 = vadd.s32 %v19304_v54, %v19299_v44 (stack40)
        %v19309_v27 = vshll.u32 %v19304_v54, 29 (stack45)
        %v19310_v32 = vshrl.u32 %v19304_v54, 3 (stack46)
        %v18451_v40 = vor.u32 %v18450_v6, %v18449_v46 (stack47)
        %v18856_v25 = vadd.s32 %v18853_v23, %v18848_v25 (stack40)
        %v18858_v61 = vshll.u32 %v18853_v23, 15 (stack45)
        %v18859_v53 = vshrl.u32 %v18853_v23, 17 (stack46)
        %vm17693_vm12 = vcmp.eq.f32.partialorder %v127792_v60, 0.0 (stack71)
        %v18061_v8 = vand.u32.u16 65535, %v18060_v21 (stack52)
        %v19311_v50 = vor.u32 %v19310_v32, %v19309_v27 (stack47)
        %v19727_v26 = vshrl.u32 %v19721_v42, 17 (stack46)
        %v120580_v42 = vpop.eup %120579 (stack73)
        %v17694_v31 = vand.u32 2147483648, %v127792_v60 (stack72)
        %v18452_v34 = vxor.u32 %v18451_v40, %v18447_v22 (stack48)
        %v18860_v55 = vor.u32 %v18859_v53, %v18858_v61 (stack47)
        %v127849_v54 = vadd.s32 %v157177_v24, %v157079_v39 (stack40)
        %v17690_v46 = vmul.f32 %v120580_v42, %v127792_v60 (stack74)
        %v119838_v6 = vadd.low.f32.bf16 -1.0, %v18061_v8 (stack53)
        %v19312_v23 = vxor.u32 %v19311_v50, %v19307_v44 (stack48)
        %v19728_v9 = vor.u32 %v19727_v26, %v19726_v9 (stack47)
        %v18455_v22 = vadd.s32 %v18452_v34, %v18447_v22 (stack40)
        %v18461_v21 = vshll.u32 %v18452_v34, 24 (stack45)
        %v18462_v27 = vshrl.u32 %v18452_v34, 8 (stack46)
        %v18861_v32 = vxor.u32 %v18860_v55, %v18856_v25 (stack48)
        %v17692_v40 = vsel /*vm=*/%vm17691_vm10, /*on_true_vy=*/%v127792_v60, /*on_false_vx=*/%v17690_v46 (stack75)
        %v18070_v61 = vmul.f32 2.0, %v119838_v6 (stack54)
        %v19315_v44 = vadd.s32 %v19312_v23, %v19307_v44 (stack40)
        %v20152_v53 = vadd.s32 1, %v127785_v56 (stack40)
        %v17695_v8 = vsel /*vm=*/%vm17693_vm12, /*on_true_vy=*/%v17694_v31, /*on_false_vx=*/%v17692_v40 (stack76)
        %v18463_v50 = vor.u32 %v18462_v27, %v18461_v21 (stack47)
        %v18864_v25 = vadd.s32 %v18861_v32, %v18856_v25 (stack40)
        %v19317_v26 = vshll.u32 %v19312_v23, 16 (stack45)
        %v17698_v42 = vadd.f32 -3.0, %v17695_v8 (stack53)
        %v18074_v31 = vadd.f32 -0.99609375, %v18070_v61 (stack53)
        %v18866_v34 = vshll.u32 %v18861_v32, 26 (stack45)
        %v18867_v55 = vshrl.u32 %v18861_v32, 6 (stack46)
        %v18464_v46 = vxor.u32 %v18463_v50, %v18455_v22 (stack48)
        %v19318_v6 = vshrl.u32 %v19312_v23, 16 (stack46)
        %v19729_v23 = vxor.u32 %v19728_v9, %v19724_v11 (stack48)
        %v20156_v56 = vsel /*vm=*/%vm20143_vm11, /*on_true_vy=*/%v20152_v53, /*on_false_vx=*/%v127785_v56 (stack44)
        %v17683_v9 = vsel /*vm=*/%vm17646_vm9, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v127868_v43 = vsel /*vm=*/%vm17646_vm9, /*on_true_vy=*/%v127817_v43, /*on_false_vx=*/%v17698_v42 (stack44)
        %v127870_v21 = vmax.f32 %v18074_v31, -0.99609375 (stack55)
        %v18868_v27 = vor.u32 %v18867_v55, %v18866_v34 (stack47)
        %v17706_v32 = vmul.f32 %v127868_v43, %v17683_v9 (stack54)
        %v18467_v40 = vadd.s32 %v18464_v46, %v121564_v0 (stack40)
        %v19319_v61 = vor.u32 %v19318_v6, %v19317_v26 (stack47)
        %v19732_v11 = vadd.s32 %v19729_v23, %v19724_v11 (stack40)
        %v17675_v53 = vsel /*vm=*/%vm17646_vm9, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v17679_v8 = vsel /*vm=*/%vm17646_vm9, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v18090_v50 = vxor.u32 2147483648, %v127870_v21 (stack56)
        %v18869_v26 = vxor.u32 %v18868_v27, %v18864_v25 (stack48)
        %v17710_v42 = vadd.f32 %v17706_v32, %v17679_v8 (stack53)
        %v18459_v22 = vadd.s32 %v18455_v22, %v121569_v1 (stack40)
        %v18471_v31 = vadd.s32 4, %v18467_v40 (stack40)
        %v19320_v34 = vxor.u32 %v19319_v61, %v19315_v44 (stack48)
        %v127883_v55 = vmul.f32 %v18090_v50, %v127870_v21 (stack54)
        %v18872_v25 = vadd.s32 %v18869_v26, %v18864_v25 (stack40)
        %v18878_v46 = vshll.u32 %v18869_v26, 6 (stack45)
        %vm20138_vm13 = vcmp.lt.u32.totalorder %v127821_v10, %v127780_v20 (stack43)
        %v17714_v6 = vmul.f32 %v17710_v42, %v127868_v43 (stack54)
        %v18475_v9 = vadd.s32 %v18471_v31, %v18459_v22 (stack40)
        %v18477_v27 = vshll.u32 %v18471_v31, 13 (stack45)
        %v18478_v32 = vshrl.u32 %v18471_v31, 19 (stack46)
        %v18095_v40 = vadd.f32 1.0, %v127883_v55 (stack57)
        %v18098_v61 = vmul.f32 -0.5, %v127883_v55 (stack59)
        %v20160_v8 = vadd.s32 1, %v20156_v56 (stack40)
        %v20173_v50 = vadd.s32 %v127821_v10, %v121569_v1 (stack40)
        %v17718_v53 = vadd.f32 %v17714_v6, %v17675_v53 (stack53)
        %v18479_v42 = vor.u32 %v18478_v32, %v18477_v27 (stack47)
        %v18879_v26 = vshrl.u32 %v18869_v26, 26 (stack46)
        %v19323_v44 = vadd.s32 %v19320_v34, %v19315_v44 (stack40)
        %120581 = vlog2.f32 %v18095_v40 (stack58)
        %v18101_v22 = vand.u32 2147483647, %v127883_v55 (stack60)
        %v19329_v31 = vshll.u32 %v19320_v34, 24 (stack45)
        %v19734_v6 = vshll.u32 %v19729_v23, 26 (stack45)
        %v17722_v27 = vmul.f32 %v17718_v53, %v127868_v43 (stack54)
        %v18480_v32 = vxor.u32 %v18479_v42, %v18475_v9 (stack48)
        %v18876_v40 = vadd.s32 %v18872_v25, %v121574_v2 (stack40)
        %v18880_v46 = vor.u32 %v18879_v26, %v18878_v46 (stack47)
        %v18099_v61 = vadd.f32 1.0, %v18098_v61 (stack61)
        %v19330_v34 = vshrl.u32 %v19320_v34, 8 (stack46)
        %v19735_v23 = vshrl.u32 %v19729_v23, 6 (stack46)
        %v20164_v20 = vsel /*vm=*/%vm20138_vm13, /*on_true_vy=*/%v20160_v8, /*on_false_vx=*/%v20156_v56 (stack44)
        %v17726_v10 = vadd.f32 %v17722_v27, %v127838_v30 (stack53)
        %v18483_v30 = vadd.s32 %v18480_v32, %v18475_v9 (stack40)
        %v18485_v56 = vshll.u32 %v18480_v32, 15 (stack45)
        %v18486_v9 = vshrl.u32 %v18480_v32, 17 (stack46)
        %v18881_v25 = vxor.u32 %v18880_v46, %v18872_v25 (stack48)
        %v19331_v8 = vor.u32 %v19330_v34, %v19329_v31 (stack47)
        %v19736_v53 = vor.u32 %v19735_v23, %v19734_v6 (stack47)
        %v20169_v42 = vadd.s32 %v20164_v20, %v121574_v2 (stack40)
        %v17730_v26 = vmul.f32 %v17726_v10, %v127868_v43 (stack54)
        %v18487_v31 = vor.u32 %v18486_v9, %v18485_v56 (stack47)
        %v20179_v6 = vshll.u32 %v20173_v50, 13 (stack45)
        %v20180_v27 = vshrl.u32 %v20173_v50, 19 (stack46)
        %v18884_v32 = vadd.s32 %v18881_v25, %v121569_v1 (stack40)
        %v19332_v46 = vxor.u32 %v19331_v8, %v19323_v44 (stack48)
        %v19737_v34 = vxor.u32 %v19736_v53, %v19732_v11 (stack48)
        %v20177_v50 = vadd.s32 %v20173_v50, %v20169_v42 (stack40)
        %v17734_v7 = vadd.f32 %v17730_v26, %v127831_v7 (stack53)
        %v18488_v23 = vxor.u32 %v18487_v31, %v18483_v30 (stack48)
        %v19327_v44 = vadd.s32 %v19323_v44, %v121564_v0 (stack40)
        %v20181_v20 = vor.u32 %v20180_v27, %v20179_v6 (stack47)
        %v18888_v10 = vadd.s32 3, %v18884_v32 (stack40)
        %v19335_v56 = vadd.s32 %v19332_v46, %v121574_v2 (stack40)
        %v127905_v11 = vadd.s32 %v19737_v34, %v19732_v11 (stack40)
        %v19746_v9 = vshll.u32 %v19737_v34, 6 (stack45)
        %v17738_v25 = vmul.f32 %v17734_v7, %v127868_v43 (stack54)
        %v18491_v30 = vadd.s32 %v18488_v23, %v18483_v30 (stack40)
        %v18493_v8 = vshll.u32 %v18488_v23, 26 (stack45)
        %v18494_v53 = vshrl.u32 %v18488_v23, 6 (stack46)
        %v18892_v40 = vadd.s32 %v18888_v10, %v18876_v40 (stack40)
        %v18894_v42 = vshll.u32 %v18888_v10, 17 (stack45)
        %v18895_v26 = vshrl.u32 %v18888_v10, 15 (stack46)
        %v19339_v31 = vadd.s32 2, %v19335_v56 (stack40)
        %v17742_v12 = vadd.f32 %v17738_v25, %v127826_v12 (stack53)
        %vm127909_vm14 = vcmp.lt.f32.partialorder %v18101_v22, 0.0004427343 (stack62)
        %v18495_v6 = vor.u32 %v18494_v53, %v18493_v8 (stack47)
        %v19747_v27 = vshrl.u32 %v19737_v34, 26 (stack46)
        %v18896_v32 = vor.u32 %v18895_v26, %v18894_v42 (stack47)
        %v19343_v46 = vadd.s32 %v19339_v31, %v19327_v44 (stack40)
        %v19345_v34 = vshll.u32 %v19339_v31, 13 (stack45)
        %v19346_v7 = vshrl.u32 %v19339_v31, 19 (stack46)
        %v120582_v23 = vpop.eup %120581 (stack64)
        %v17746_v44 = vmul.f32 %v17742_v12, %v127868_v43 (stack54)
        %v18100_v55 = vmul.f32 %v18099_v61, %v127883_v55 (stack63)
        %v18496_v61 = vxor.u32 %v18495_v6, %v18491_v30 (stack48)
        %v127915_v20 = vxor.u32 %v20181_v20, %v20177_v50 (stack48)
        %v18097_v10 = vmul.f32 0.6931472, %v120582_v23 (stack65)
        %v18897_v56 = vxor.u32 %v18896_v32, %v18892_v40 (stack48)
        %v19347_v25 = vor.u32 %v19346_v7, %v19345_v34 (stack47)
        %v19748_v9 = vor.u32 %v19747_v27, %v19746_v9 (stack47)
        %v17750_v41 = vadd.f32 %v17746_v44, %v127814_v41 (stack53)
        %v18499_v30 = vadd.s32 %v18496_v61, %v18491_v30 (stack40)
        %v18505_v8 = vshll.u32 %v18496_v61, 6 (stack45)
        %v18506_v53 = vshrl.u32 %v18496_v61, 26 (stack46)
        %v18103_v42 = vsel /*vm=*/%vm127909_vm14, /*on_true_vy=*/%v18100_v55, /*on_false_vx=*/%v18097_v10 (stack66)
        %v18900_v40 = vadd.s32 %v18897_v56, %v18892_v40 (stack40)
        %v18902_v26 = vshll.u32 %v18897_v56, 29 (stack45)
        %v18903_v31 = vshrl.u32 %v18897_v56, 3 (stack46)
        %v17619_v12 = vand.u32 2147483647, %v127730_v29 (stack77)
        %v17754_v22 = vmul.f32 %v17750_v41, %v127868_v43 (stack54)
        %v127922_v6 = vxor.u32 2147483648, %v18103_v42 (stack56)
        %v18507_v27 = vor.u32 %v18506_v53, %v18505_v8 (stack47)
        %v17655_v32 = vsel /*vm=*/%vm17646_vm9, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v19348_v34 = vxor.u32 %v19347_v25, %v19343_v46 (stack48)
        %v19749_v7 = vxor.u32 %v19748_v9, %v127905_v11 (stack48)
        %v127929_v50 = vadd.s32 %v127915_v20, %v20177_v50 (stack40)
        %v17758_v23 = vadd.f32 %v17754_v22, %v17655_v32 (stack53)
        %120583 = vrsqrt.f32 %v127922_v6 (stack67)
        %v17627_v44 = vmul.f32 inf, %v127730_v29 (stack54)
        %vm18107_vm15 = vcmp.lt.f32.partialorder %v127922_v6, 5.0 (stack68)
        %v18508_v55 = vxor.u32 %v18507_v27, %v18499_v30 (stack48)
        %v18904_v61 = vor.u32 %v18903_v31, %v18902_v26 (stack47)
        %vm127934_vm0 = vcmp.eq.f32.partialorder %v17619_v12, 1.0 (stack68)
        %v17651_v60 = vsel /*vm=*/%vm17646_vm9, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v17762_v43 = vmul.f32 %v17758_v23, %v127868_v43 (stack54)
        %v18080_v56 = vand.u32 2147483647, %v127870_v21 (stack77)
        %v18503_v25 = vadd.s32 %v18499_v30, %v121564_v0 (stack40)
        %v18511_v9 = vadd.s32 %v18508_v55, %v121574_v2 (stack40)
        %v19744_v11 = vadd.s32 %v127905_v11, %v121569_v1 (stack40)
        %v127949_v41 = vadd.s32 %v127849_v54, %v122657_v58 (stack40)
        %v17766_v30 = vadd.f32 %v17762_v43, %v17651_v60 (stack53)
        %v127954_v8 = vsel /*vm=*/%vm18107_vm15, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v127959_v53 = vsel /*vm=*/%vm18107_vm15, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v127962_v42 = vadd.f32 -2.5, %v127922_v6 (stack53)
        %v18515_v26 = vadd.s32 5, %v18511_v9 (stack40)
        %v18905_v31 = vxor.u32 %v18904_v61, %v18900_v40 (stack48)
        %v19351_v46 = vadd.s32 %v19348_v34, %v19343_v46 (stack40)
        %v19353_v12 = vshll.u32 %v19348_v34, 15 (stack45)
        %v17770_v29 = vmul.f32 %v17766_v30, %v127730_v29 (stack54)
        %v19354_v22 = vshrl.u32 %v19348_v34, 17 (stack46)
        %v19752_v27 = vadd.s32 %v19749_v7, %v121564_v0 (stack40)
        %v20187_v32 = vshll.u32 %v127915_v20, 15 (stack45)
        %vm18152_vm1 = vcmp.eq.f32.partialorder %v127922_v6, inf (stack70)
        %v18517_v34 = vxor.u32 %v18515_v26, %v18503_v25 (stack48)
        %v18908_v40 = vadd.s32 %v18905_v31, %v18900_v40 (stack40)
        %v18910_v7 = vshll.u32 %v18905_v31, 16 (stack45)
        %v18911_v23 = vshrl.u32 %v18905_v31, 16 (stack46)
        %v17774_v44 = vsel /*vm=*/%vm127934_vm0, /*on_true_vy=*/%v17627_v44, /*on_false_vx=*/%v17770_v29 (stack44)
        %vm18154_vm2 = vcmp.eq.f32.partialorder %v127922_v6, 0.0 (stack71)
        %v19355_v55 = vor.u32 %v19354_v22, %v19353_v12 (stack47)
        %v19756_v61 = vadd.s32 1, %v19752_v27 (stack40)
        %v20188_v20 = vshrl.u32 %v127915_v20, 17 (stack46)
        %v17778_v10 = vmul.f32 1.4140625, %v17774_v44 (stack54)
        %v18518_v60 = vand.u32.u8 255, %v18517_v34 (stack49)
        %v18912_v43 = vor.u32 %v18911_v23, %v18910_v7 (stack47)
        %vm20604_vm3 = vcmp.lt.u32.totalorder %v127849_v54, %v157079_v39 (stack43)
        %v19356_v25 = vxor.u32 %v19355_v55, %v19351_v46 (stack48)
        %v19760_v9 = vadd.s32 %v19756_v61, %v19744_v11 (stack40)
        %v19762_v11 = vshll.u32 %v19756_v61, 17 (stack45)
        %v19763_v30 = vshrl.u32 %v19756_v61, 15 (stack46)
        %v17781_v26 = vpack.c.bf16 %v156663_v45, %v17778_v10 (stack81)
        %v18519_v31 = vand.u32 65535, %v18518_v60 (stack50)
        %v18913_v12 = vxor.u32 %v18912_v43, %v18908_v40 (stack48)
        %v20189_v29 = vor.u32 %v20188_v20, %v20187_v32 (stack47)
        %v19359_v46 = vadd.s32 %v19356_v25, %v19351_v46 (stack40)
        %v19361_v22 = vshll.u32 %v19356_v25, 26 (stack45)
        %v19362_v27 = vshrl.u32 %v19356_v25, 6 (stack46)
        %v19764_v32 = vor.u32 %v19763_v30, %v19762_v11 (stack47)
        %v120584_v34 = vpop.eup %120583 (stack73)
        %119837 = vst [vmem:[%s123356_s30 + $0x210] sm:$0xf] /*vst_source=*/%v17781_v26 (stack83)
        %v18520_v7 = vshrl.u32 %v18519_v31, 1 (stack51)
        %v18916_v40 = vadd.s32 %v18913_v12, %v18908_v40 (stack40)
        %v18922_v23 = vshll.u32 %v18913_v12, 24 (stack45)
        %v18923_v44 = vshrl.u32 %v18913_v12, 8 (stack46)
        %v18151_v55 = vmul.f32 %v120584_v34, %v127922_v6 (stack74)
        %v19363_v61 = vor.u32 %v19362_v27, %v19361_v22 (stack47)
        %v19765_v20 = vxor.u32 %v19764_v32, %v19760_v9 (stack48)
        %v20190_v10 = vxor.u32 %v20189_v29, %v127929_v50 (stack48)
        %v18155_v60 = vand.u32 2147483648, %v127922_v6 (stack72)
        %v18521_v43 = vor.u32 16256, %v18520_v7 (stack47)
        %v18924_v25 = vor.u32 %v18923_v44, %v18922_v23 (stack47)
        %v20609_v11 = vadd.s32 %v157180_v52, %v157082_v49 (stack40)
        %v18153_v30 = vsel /*vm=*/%vm18152_vm1, /*on_true_vy=*/%v127922_v6, /*on_false_vx=*/%v18151_v55 (stack75)
        %v19364_v26 = vxor.u32 %v19363_v61, %v19359_v46 (stack48)
        %v19768_v9 = vadd.s32 %v19765_v20, %v19760_v9 (stack40)
        %v19770_v31 = vshll.u32 %v19765_v20, 29 (stack45)
        %v18156_v12 = vsel /*vm=*/%vm18154_vm2, /*on_true_vy=*/%v18155_v60, /*on_false_vx=*/%v18153_v30 (stack76)
        %v18522_v29 = vand.u32.u16 65535, %v18521_v43 (stack52)
        %v18925_v22 = vxor.u32 %v18924_v25, %v18916_v40 (stack48)
        %v19771_v27 = vshrl.u32 %v19765_v20, 3 (stack46)
        %v18159_v32 = vadd.f32 -3.0, %v18156_v12 (stack53)
        %v19367_v46 = vadd.s32 %v19364_v26, %v19359_v46 (stack40)
        %v19373_v34 = vshll.u32 %v19364_v26, 6 (stack45)
        %v19374_v7 = vshrl.u32 %v19364_v26, 26 (stack46)
        %v119840_v23 = vadd.low.f32.bf16 -1.0, %v18522_v29 (stack53)
        %v18928_v44 = vadd.s32 %v18925_v22, %v121564_v0 (stack40)
        %v19772_v55 = vor.u32 %v19771_v27, %v19770_v31 (stack47)
        %v127988_v50 = vadd.s32 %v20190_v10, %v127929_v50 (stack40)
        %v18144_v61 = vsel /*vm=*/%vm18107_vm15, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v127996_v42 = vsel /*vm=*/%vm18107_vm15, /*on_true_vy=*/%v127962_v42, /*on_false_vx=*/%v18159_v32 (stack44)
        %v18920_v40 = vadd.s32 %v18916_v40, %v121569_v1 (stack40)
        %v19375_v20 = vor.u32 %v19374_v7, %v19373_v34 (stack47)
        %v18167_v60 = vmul.f32 %v127996_v42, %v18144_v61 (stack54)
        %v18531_v43 = vmul.f32 2.0, %v119840_v23 (stack54)
        %v18932_v25 = vadd.s32 4, %v18928_v44 (stack40)
        %v19773_v30 = vxor.u32 %v19772_v55, %v19768_v9 (stack48)
        %v18140_v26 = vsel /*vm=*/%vm18107_vm15, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v19376_v31 = vxor.u32 %v19375_v20, %v19367_v46 (stack48)
        %v20195_v12 = vshll.u32 %v20190_v10, 26 (stack45)
        %v20196_v10 = vshrl.u32 %v20190_v10, 6 (stack46)
        %v18171_v29 = vadd.f32 %v18167_v60, %v18140_v26 (stack53)
        %v18535_v22 = vadd.f32 -0.99609375, %v18531_v43 (stack53)
        %v18936_v27 = vadd.s32 %v18932_v25, %v18920_v40 (stack40)
        %v18938_v32 = vshll.u32 %v18932_v25, 13 (stack45)
        %v18939_v34 = vshrl.u32 %v18932_v25, 19 (stack46)
        %v19379_v7 = vadd.s32 %v19376_v31, %v121569_v1 (stack40)
        %v19776_v9 = vadd.s32 %v19773_v30, %v19768_v9 (stack40)
        %v20613_v23 = vadd.s32 1, %v20609_v11 (stack40)
        %v18175_v44 = vmul.f32 %v18171_v29, %v127996_v42 (stack54)
        %v128005_v55 = vmax.f32 %v18535_v22, -0.99609375 (stack55)
        %v19778_v61 = vshll.u32 %v19773_v30, 16 (stack45)
        %v19779_v40 = vshrl.u32 %v19773_v30, 16 (stack46)
        %v18940_v20 = vor.u32 %v18939_v34, %v18938_v32 (stack47)
        %v19371_v46 = vadd.s32 %v19367_v46, %v121574_v2 (stack40)
        %v19383_v60 = vadd.s32 3, %v19379_v7 (stack40)
        %v128011_v11 = vsel /*vm=*/%vm20604_vm3, /*on_true_vy=*/%v20613_v23, /*on_false_vx=*/%v20609_v11 (stack44)
        %v128016_v43 = vsel /*vm=*/%vm18107_vm15, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v18179_v53 = vadd.f32 %v18175_v44, %v127959_v53 (stack53)
        %v18551_v25 = vxor.u32 2147483648, %v128005_v55 (stack56)
        %v20197_v30 = vor.u32 %v20196_v10, %v20195_v12 (stack47)
        %v18941_v26 = vxor.u32 %v18940_v20, %v18936_v27 (stack48)
        %v19387_v31 = vadd.s32 %v19383_v60, %v19371_v46 (stack40)
        %v19389_v12 = vshll.u32 %v19383_v60, 17 (stack45)
        %v19390_v10 = vshrl.u32 %v19383_v60, 15 (stack46)
        %v18132_v29 = vsel /*vm=*/%vm18107_vm15, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v18183_v22 = vmul.f32 %v18179_v53, %v127996_v42 (stack54)
        %v18554_v32 = vmul.f32 %v18551_v25, %v128005_v55 (stack54)
        %v19780_v34 = vor.u32 %v19779_v40, %v19778_v61 (stack47)
        %v18944_v27 = vadd.s32 %v18941_v26, %v18936_v27 (stack40)
        %v18946_v7 = vshll.u32 %v18941_v26, 15 (stack45)
        %v18947_v23 = vshrl.u32 %v18941_v26, 17 (stack46)
        %v19391_v44 = vor.u32 %v19390_v10, %v19389_v12 (stack47)
        %vm20599_vm4 = vcmp.lt.u32.totalorder %v127949_v41, %v127849_v54 (stack43)
        %v18124_v61 = vsel /*vm=*/%vm18107_vm15, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v18128_v40 = vsel /*vm=*/%vm18107_vm15, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v18187_v20 = vadd.f32 %v18183_v22, %v18132_v29 (stack53)
        %v18556_v46 = vadd.f32 1.0, %v18554_v32 (stack57)
        %v18948_v60 = vor.u32 %v18947_v23, %v18946_v7 (stack47)
        %v19392_v53 = vxor.u32 %v19391_v44, %v19387_v31 (stack48)
        %v19781_v25 = vxor.u32 %v19780_v34, %v19776_v9 (stack48)
        %v20198_v30 = vxor.u32 %v20197_v30, %v127988_v50 (stack48)
        %v18191_v26 = vmul.f32 %v18187_v20, %v127996_v42 (stack54)
        %120585 = vlog2.f32 %v18556_v46 (stack58)
        %v18559_v12 = vmul.f32 -0.5, %v18554_v32 (stack59)
        %v128037_v10 = vadd.s32 %v127949_v41, %v121569_v1 (stack40)
        %v18949_v29 = vxor.u32 %v18948_v60, %v18944_v27 (stack48)
        %v19395_v31 = vadd.s32 %v19392_v53, %v19387_v31 (stack40)
        %v19397_v22 = vshll.u32 %v19392_v53, 29 (stack45)
        %v19398_v34 = vshrl.u32 %v19392_v53, 3 (stack46)
        %v18195_v7 = vadd.f32 %v18191_v26, %v18128_v40 (stack53)
        %v18562_v23 = vand.u32 2147483647, %v18554_v32 (stack60)
        %v19784_v9 = vadd.s32 %v19781_v25, %v19776_v9 (stack40)
        %v19790_v44 = vshll.u32 %v19781_v25, 24 (stack45)
        %v18952_v27 = vadd.s32 %v18949_v29, %v18944_v27 (stack40)
        %v18954_v40 = vshll.u32 %v18949_v29, 26 (stack45)
        %v18955_v20 = vshrl.u32 %v18949_v29, 6 (stack46)
        %v19399_v46 = vor.u32 %v19398_v34, %v19397_v22 (stack47)
        %v18199_v60 = vmul.f32 %v18195_v7, %v127996_v42 (stack54)
        %v19791_v53 = vshrl.u32 %v19781_v25, 8 (stack46)
        %v20201_v50 = vadd.s32 %v20198_v30, %v127988_v50 (stack40)
        %v20640_v25 = vshll.u32 %v128037_v10, 13 (stack45)
        %v18956_v26 = vor.u32 %v18955_v20, %v18954_v40 (stack47)
        %v19400_v29 = vxor.u32 %v19399_v46, %v19395_v31 (stack48)
        %v20207_v22 = vshll.u32 %v20198_v30, 6 (stack45)
        %v20208_v30 = vshrl.u32 %v20198_v30, 26 (stack46)
        %v18203_v61 = vadd.f32 %v18199_v60, %v18124_v61 (stack53)
        %v18560_v12 = vadd.f32 1.0, %v18559_v12 (stack61)
        %v19792_v34 = vor.u32 %v19791_v53, %v19790_v44 (stack47)
        %v20621_v7 = vadd.s32 1, %v128011_v11 (stack40)
        %vm128043_vm5 = vcmp.lt.f32.partialorder %v18562_v23, 0.0004427343 (stack62)
        %v18957_v44 = vxor.u32 %v18956_v26, %v18952_v27 (stack48)
        %v19403_v31 = vadd.s32 %v19400_v29, %v19395_v31 (stack40)
        %v19405_v40 = vshll.u32 %v19400_v29, 16 (stack45)
        %v19406_v20 = vshrl.u32 %v19400_v29, 16 (stack46)
        %v18207_v46 = vmul.f32 %v18203_v61, %v127996_v42 (stack54)
        %v19793_v60 = vxor.u32 %v19792_v34, %v19784_v9 (stack48)
        %v20209_v53 = vor.u32 %v20208_v30, %v20207_v22 (stack47)
        %v20625_v54 = vsel /*vm=*/%vm20599_vm4, /*on_true_vy=*/%v20621_v7, /*on_false_vx=*/%v128011_v11 (stack44)
        %v18960_v41 = vadd.s32 %v18957_v44, %v18952_v27 (stack40)
        %v18966_v11 = vshll.u32 %v18957_v44, 6 (stack45)
        %v18967_v27 = vshrl.u32 %v18957_v44, 26 (stack46)
        %v19407_v26 = vor.u32 %v19406_v20, %v19405_v40 (stack47)
        %v18211_v43 = vadd.f32 %v18207_v46, %v128016_v43 (stack53)
        %v19796_v29 = vadd.s32 %v19793_v60, %v121574_v2 (stack40)
        %v20210_v22 = vxor.u32 %v20209_v53, %v20201_v50 (stack48)
        %v20630_v30 = vadd.s32 %v20625_v54, %v121574_v2 (stack40)
        %v18561_v32 = vmul.f32 %v18560_v12, %v18554_v32 (stack63)
        %v18968_v61 = vor.u32 %v18967_v27, %v18966_v11 (stack47)
        %v19408_v12 = vxor.u32 %v19407_v26, %v19403_v31 (stack48)
        %v19788_v9 = vadd.s32 %v19784_v9, %v121564_v0 (stack40)
        %v18215_v34 = vmul.f32 %v18211_v43, %v127996_v42 (stack54)
        %v19800_v7 = vadd.s32 2, %v19796_v29 (stack40)
        %v20213_v44 = vadd.s32 %v20210_v22, %v121564_v0 (stack40)
        %v20638_v40 = vadd.s32 %v128037_v10, %v20630_v30 (stack40)
        %v120586_v20 = vpop.eup %120585 (stack64)
        %v18969_v46 = vxor.u32 %v18968_v61, %v18960_v41 (stack48)
        %v19411_v31 = vadd.s32 %v19408_v12, %v19403_v31 (stack40)
        %v19417_v60 = vshll.u32 %v19408_v12, 24 (stack45)
        %v19418_v53 = vshrl.u32 %v19408_v12, 8 (stack46)
        %v18219_v8 = vadd.f32 %v18215_v34, %v127954_v8 (stack53)
        %v18558_v54 = vmul.f32 0.6931472, %v120586_v20 (stack65)
        %v19804_v11 = vadd.s32 %v19800_v7, %v19788_v9 (stack40)
        %v20205_v50 = vadd.s32 %v20201_v50, %v121569_v1 (stack40)
        %v18972_v27 = vadd.s32 %v18969_v46, %v121574_v2 (stack40)
        %v19419_v26 = vor.u32 %v19418_v53, %v19417_v60 (stack47)
        %v19806_v43 = vshll.u32 %v19800_v7, 13 (stack45)
        %v20641_v10 = vshrl.u32 %v128037_v10, 19 (stack46)
        %v18223_v42 = vmul.f32 %v18219_v8, %v127996_v42 (stack54)
        %v18564_v23 = vsel /*vm=*/%vm128043_vm5, /*on_true_vy=*/%v18561_v32, /*on_false_vx=*/%v18558_v54 (stack66)
        %v19807_v29 = vshrl.u32 %v19800_v7, 19 (stack46)
        %v20217_v22 = vadd.s32 1, %v20213_v44 (stack40)
        %v18112_v6 = vsel /*vm=*/%vm18107_vm15, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v128069_v30 = vxor.u32 2147483648, %v18564_v23 (stack56)
        %v18976_v32 = vadd.s32 5, %v18972_v27 (stack40)
        %v19420_v61 = vxor.u32 %v19419_v26, %v19411_v31 (stack48)
        %v18088_v12 = vmul.f32 inf, %v127870_v21 (stack54)
        %v18227_v9 = vadd.f32 %v18223_v42, %v18112_v6 (stack53)
        %v20221_v34 = vadd.s32 %v20217_v22, %v20205_v50 (stack40)
        %vm18568_vm6 = vcmp.lt.f32.partialorder %v128069_v30, 5.0 (stack68)
        %120587 = vrsqrt.f32 %v128069_v30 (stack67)
        %v18964_v41 = vadd.s32 %v18960_v41, %v121564_v0 (stack40)
        %v20642_v25 = vor.u32 %v20641_v10, %v20640_v25 (stack47)
        %v18231_v7 = vmul.f32 %v18227_v9, %v127870_v21 (stack54)
        %v19808_v44 = vor.u32 %v19807_v29, %v19806_v43 (stack47)
        %v20223_v20 = vshll.u32 %v20217_v22, 17 (stack45)
        %v20224_v46 = vshrl.u32 %v20217_v22, 15 (stack46)
        %vm18083_vm7 = vcmp.eq.f32.partialorder %v18080_v56, 1.0 (stack68)
        %v18978_v21 = vxor.u32 %v18976_v32, %v18964_v41 (stack48)
        %v19415_v56 = vadd.s32 %v19411_v31, %v121569_v1 (stack40)
        %v18235_v31 = vsel /*vm=*/%vm18083_vm7, /*on_true_vy=*/%v18088_v12, /*on_false_vx=*/%v18231_v7 (stack44)
        %v128082_v60 = vsel /*vm=*/%vm18568_vm6, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v128087_v53 = vsel /*vm=*/%vm18568_vm6, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v128090_v8 = vadd.f32 -2.5, %v128069_v30 (stack53)
        %v18239_v54 = vmul.f32 1.4140625, %v18235_v31 (stack54)
        %v128095_v50 = vsel /*vm=*/%vm18568_vm6, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v128100_v27 = vsel /*vm=*/%vm18568_vm6, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v18979_v26 = vand.u32.u8 255, %v18978_v21 (stack49)
        %v19423_v43 = vadd.s32 %v19420_v61, %v121564_v0 (stack40)
        %v19809_v10 = vxor.u32 %v19808_v44, %v19804_v11 (stack48)
        %v20225_v42 = vor.u32 %v20224_v46, %v20223_v20 (stack47)
        %v20643_v23 = vxor.u32 %v20642_v25, %v20638_v40 (stack48)
        %v18242_v29 = vpack.c.bf16 %v156663_v45, %v18239_v54 (stack81)
        %v18980_v22 = vand.u32 65535, %v18979_v26 (stack50)
        %v128106_v6 = vadd.s32 %v157177_v24, %v157083_v59 (stack40)
        %v128110_v32 = vadd.s32 %v157180_v52, %v157084_v16 (stack40)
        %vm18613_vm8 = vcmp.eq.f32.partialorder %v128069_v30, inf (stack70)
        %v19427_v61 = vadd.s32 4, %v19423_v43 (stack40)
        %v19812_v11 = vadd.s32 %v19809_v10, %v19804_v11 (stack40)
        %v19814_v12 = vshll.u32 %v19809_v10, 15 (stack45)
        %v19815_v9 = vshrl.u32 %v19809_v10, 17 (stack46)
        %119839 = vst [vmem:[%s123356_s30 + $0x290] sm:$0xf] /*vst_source=*/%v18242_v29 (stack83)
        %v18981_v41 = vshrl.u32 %v18980_v22, 1 (stack51)
        %v20226_v25 = vxor.u32 %v20225_v42, %v20221_v34 (stack48)
        %v20646_v40 = vadd.s32 %v20643_v23, %v20638_v40 (stack40)
        %v20648_v7 = vshll.u32 %v20643_v23, 15 (stack45)
        %v19431_v44 = vadd.s32 %v19427_v61, %v19415_v56 (stack40)
        %v19433_v20 = vshll.u32 %v19427_v61, 13 (stack45)
        %v19434_v46 = vshrl.u32 %v19427_v61, 19 (stack46)
        %v19816_v21 = vor.u32 %v19815_v9, %v19814_v12 (stack47)
        %v18982_v56 = vor.u32 16256, %v18981_v41 (stack47)
        %v20229_v34 = vadd.s32 %v20226_v25, %v20221_v34 (stack40)
        %v20231_v31 = vshll.u32 %v20226_v25, 29 (stack45)
        %v20232_v54 = vshrl.u32 %v20226_v25, 3 (stack46)
        %vm18615_vm9 = vcmp.eq.f32.partialorder %v128069_v30, 0.0 (stack71)
        %v19435_v26 = vor.u32 %v19434_v46, %v19433_v20 (stack47)
        %v19817_v43 = vxor.u32 %v19816_v21, %v19812_v11 (stack48)
        %v20649_v10 = vshrl.u32 %v20643_v23, 17 (stack46)
        %v18616_v42 = vand.u32 2147483648, %v128069_v30 (stack72)
        %v18983_v23 = vand.u32.u16 65535, %v18982_v56 (stack52)
        %v20233_v29 = vor.u32 %v20232_v54, %v20231_v31 (stack47)
        %vm21065_vm10 = vcmp.lt.u32.totalorder %v128106_v6, %v157083_v59 (stack43)
        %v120588_v22 = vpop.eup %120587 (stack73)
        %v19436_v61 = vxor.u32 %v19435_v26, %v19431_v44 (stack48)
        %v19820_v11 = vadd.s32 %v19817_v43, %v19812_v11 (stack40)
        %v19822_v12 = vshll.u32 %v19817_v43, 26 (stack45)
        %v19823_v9 = vshrl.u32 %v19817_v43, 6 (stack46)
        %v18612_v41 = vmul.f32 %v120588_v22, %v128069_v30 (stack74)
        %v119842_v25 = vadd.low.f32.bf16 -1.0, %v18983_v23 (stack53)
        %v20234_v20 = vxor.u32 %v20233_v29, %v20229_v34 (stack48)
        %v20650_v7 = vor.u32 %v20649_v10, %v20648_v7 (stack47)
        %v19439_v44 = vadd.s32 %v19436_v61, %v19431_v44 (stack40)
        %v19441_v46 = vshll.u32 %v19436_v61, 15 (stack45)
        %v19442_v21 = vshrl.u32 %v19436_v61, 17 (stack46)
        %v19824_v56 = vor.u32 %v19823_v9, %v19822_v12 (stack47)
        %v18614_v31 = vsel /*vm=*/%vm18613_vm8, /*on_true_vy=*/%v128069_v30, /*on_false_vx=*/%v18612_v41 (stack75)
        %v18992_v54 = vmul.f32 2.0, %v119842_v25 (stack54)
        %v20237_v34 = vadd.s32 %v20234_v20, %v20229_v34 (stack40)
        %v20239_v26 = vshll.u32 %v20234_v20, 16 (stack45)
        %v18617_v43 = vsel /*vm=*/%vm18615_vm9, /*on_true_vy=*/%v18616_v42, /*on_false_vx=*/%v18614_v31 (stack76)
        %v19443_v10 = vor.u32 %v19442_v21, %v19441_v46 (stack47)
        %v19825_v42 = vxor.u32 %v19824_v56, %v19820_v11 (stack48)
        %v20240_v23 = vshrl.u32 %v20234_v20, 16 (stack46)
        %v18620_v29 = vadd.f32 -3.0, %v18617_v43 (stack53)
        %v18996_v22 = vadd.f32 -0.99609375, %v18992_v54 (stack53)
        %v20651_v61 = vxor.u32 %v20650_v7, %v20646_v40 (stack48)
        %v128126_v12 = vadd.s32 %v128106_v6, %v122657_v58 (stack40)
        %v19444_v9 = vxor.u32 %v19443_v10, %v19439_v44 (stack48)
        %v19828_v11 = vadd.s32 %v19825_v42, %v19820_v11 (stack40)
        %v19834_v41 = vshll.u32 %v19825_v42, 6 (stack45)
        %v19835_v25 = vshrl.u32 %v19825_v42, 26 (stack46)
        %v128131_v8 = vsel /*vm=*/%vm18568_vm6, /*on_true_vy=*/%v128090_v8, /*on_false_vx=*/%v18620_v29 (stack44)
        %v128133_v20 = vmax.f32 %v18996_v22, -0.99609375 (stack55)
        %v20241_v7 = vor.u32 %v20240_v23, %v20239_v26 (stack47)
        %v20654_v40 = vadd.s32 %v20651_v61, %v20646_v40 (stack40)
        %v18628_v27 = vmul.f32 %v128131_v8, %v128100_v27 (stack54)
        %v19447_v44 = vadd.s32 %v19444_v9, %v19439_v44 (stack40)
        %v19449_v46 = vshll.u32 %v19444_v9, 26 (stack45)
        %v19450_v21 = vshrl.u32 %v19444_v9, 6 (stack46)
        %v18593_v56 = vsel /*vm=*/%vm18568_vm6, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v18601_v31 = vsel /*vm=*/%vm18568_vm6, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v19012_v54 = vxor.u32 2147483648, %v128133_v20 (stack56)
        %v18632_v26 = vadd.f32 %v18628_v27, %v18601_v31 (stack53)
        %v19451_v43 = vor.u32 %v19450_v21, %v19449_v46 (stack47)
        %v19836_v10 = vor.u32 %v19835_v25, %v19834_v41 (stack47)
        %v20242_v42 = vxor.u32 %v20241_v7, %v20237_v34 (stack48)
        %v18597_v23 = vsel /*vm=*/%vm18568_vm6, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v128148_v29 = vmul.f32 %v19012_v54, %v128133_v20 (stack54)
        %v19832_v22 = vadd.s32 %v19828_v11, %v121574_v2 (stack40)
        %v21074_v9 = vadd.s32 1, %v128110_v32 (stack40)
        %v18636_v41 = vmul.f32 %v18632_v26, %v128131_v8 (stack54)
        %v19452_v25 = vxor.u32 %v19451_v43, %v19447_v44 (stack48)
        %v19837_v11 = vxor.u32 %v19836_v10, %v19828_v11 (stack48)
        %v20245_v34 = vadd.s32 %v20242_v42, %v20237_v34 (stack40)
        %vm21060_vm11 = vcmp.lt.u32.totalorder %v128126_v12, %v128106_v6 (stack43)
        %v19017_v7 = vadd.f32 1.0, %v128148_v29 (stack57)
        %v19020_v27 = vmul.f32 -0.5, %v128148_v29 (stack59)
        %v20656_v46 = vshll.u32 %v20651_v61, 26 (stack45)
        %v20657_v61 = vshrl.u32 %v20651_v61, 6 (stack46)
        %v18640_v21 = vadd.f32 %v18636_v41, %v18597_v23 (stack53)
        %v19455_v44 = vadd.s32 %v19452_v25, %v19447_v44 (stack40)
        %v19461_v31 = vshll.u32 %v19452_v25, 6 (stack45)
        %v19462_v54 = vshrl.u32 %v19452_v25, 26 (stack46)
        %120589 = vlog2.f32 %v19017_v7 (stack58)
        %v19023_v26 = vand.u32 2147483647, %v128148_v29 (stack60)
        %v19840_v43 = vadd.s32 %v19837_v11, %v121569_v1 (stack40)
        %v20251_v10 = vshll.u32 %v20242_v42, 24 (stack45)
        %v18644_v23 = vmul.f32 %v18640_v21, %v128131_v8 (stack54)
        %v19021_v41 = vadd.f32 1.0, %v19020_v27 (stack61)
        %v19459_v25 = vadd.s32 %v19455_v44, %v121564_v0 (stack40)
        %v19463_v11 = vor.u32 %v19462_v54, %v19461_v31 (stack47)
        %v19844_v7 = vadd.s32 3, %v19840_v43 (stack40)
        %v20249_v27 = vadd.s32 %v20245_v34, %v121564_v0 (stack40)
        %v20252_v42 = vshrl.u32 %v20242_v42, 8 (stack46)
        %v20658_v46 = vor.u32 %v20657_v61, %v20656_v46 (stack47)
        %v18648_v56 = vadd.f32 %v18644_v23, %v18593_v56 (stack53)
        %v19464_v61 = vxor.u32 %v19463_v11, %v19455_v44 (stack48)
        %v21078_v32 = vsel /*vm=*/%vm21065_vm10, /*on_true_vy=*/%v21074_v9, /*on_false_vx=*/%v128110_v32 (stack44)
        %v21095_v9 = vadd.s32 %v128126_v12, %v121569_v1 (stack40)
        %v19848_v22 = vadd.s32 %v19844_v7, %v19832_v22 (stack40)
        %v19850_v21 = vshll.u32 %v19844_v7, 17 (stack45)
        %v19851_v44 = vshrl.u32 %v19844_v7, 15 (stack46)
        %v20253_v31 = vor.u32 %v20252_v42, %v20251_v10 (stack47)
        %v18652_v54 = vmul.f32 %v18648_v56, %v128131_v8 (stack54)
        %v19467_v43 = vadd.s32 %v19464_v61, %v121574_v2 (stack40)
        %v20659_v10 = vxor.u32 %v20658_v46, %v20654_v40 (stack48)
        %v21082_v23 = vadd.s32 1, %v21078_v32 (stack40)
        %v19022_v29 = vmul.f32 %v19021_v41, %v128148_v29 (stack63)
        %v19852_v41 = vor.u32 %v19851_v44, %v19850_v21 (stack47)
        %v20254_v34 = vxor.u32 %v20253_v31, %v20245_v34 (stack48)
        %v21101_v11 = vshll.u32 %v21095_v9, 13 (stack45)
        %v18656_v50 = vadd.f32 %v18652_v54, %v128095_v50 (stack53)
        %v19471_v7 = vadd.s32 5, %v19467_v43 (stack40)
        %v20662_v40 = vadd.s32 %v20659_v10, %v20654_v40 (stack40)
        %v20668_v42 = vshll.u32 %v20659_v10, 6 (stack45)
        %v19853_v46 = vxor.u32 %v19852_v41, %v19848_v22 (stack48)
        %v20257_v56 = vadd.s32 %v20254_v34, %v121574_v2 (stack40)
        %v20669_v61 = vshrl.u32 %v20659_v10, 26 (stack46)
        %v21086_v6 = vsel /*vm=*/%vm21060_vm11, /*on_true_vy=*/%v21082_v23, /*on_false_vx=*/%v21078_v32 (stack44)
        %v18660_v12 = vmul.f32 %v18656_v50, %v128131_v8 (stack54)
        %v19473_v25 = vxor.u32 %v19471_v7, %v19459_v25 (stack48)
        %v21091_v32 = vadd.s32 %v21086_v6, %v121574_v2 (stack40)
        %v21102_v21 = vshrl.u32 %v21095_v9, 19 (stack46)
        %v19856_v22 = vadd.s32 %v19853_v46, %v19848_v22 (stack40)
        %v19858_v44 = vshll.u32 %v19853_v46, 29 (stack45)
        %v19859_v31 = vshrl.u32 %v19853_v46, 3 (stack46)
        %v20261_v54 = vadd.s32 2, %v20257_v56 (stack40)
        %v18664_v53 = vadd.f32 %v18660_v12, %v128087_v53 (stack53)
        %v19474_v43 = vand.u32.u8 255, %v19473_v25 (stack49)
        %v20670_v10 = vor.u32 %v20669_v61, %v20668_v42 (stack47)
        %v21099_v9 = vadd.s32 %v21095_v9, %v21091_v32 (stack40)
        %v19860_v23 = vor.u32 %v19859_v31, %v19858_v44 (stack47)
        %v20265_v27 = vadd.s32 %v20261_v54, %v20249_v27 (stack40)
        %v20267_v41 = vshll.u32 %v20261_v54, 13 (stack45)
        %v20268_v34 = vshrl.u32 %v20261_v54, 19 (stack46)
        %v120590_v50 = vpop.eup %120589 (stack64)
        %v18668_v7 = vmul.f32 %v18664_v53, %v128131_v8 (stack54)
        %v19475_v42 = vand.u32 65535, %v19474_v43 (stack50)
        %v20671_v46 = vxor.u32 %v20670_v10, %v20662_v40 (stack48)
        %v21103_v11 = vor.u32 %v21102_v21, %v21101_v11 (stack47)
        %v19019_v56 = vmul.f32 0.6931472, %v120590_v50 (stack65)
        %v19861_v61 = vxor.u32 %v19860_v23, %v19856_v22 (stack48)
        %v20269_v6 = vor.u32 %v20268_v34, %v20267_v41 (stack47)
        %v128182_v12 = vadd.s32 %v157177_v24, %v157089_v17 (stack40)
        %v18672_v60 = vadd.f32 %v18668_v7, %v128082_v60 (stack53)
        %vm19024_vm12 = vcmp.lt.f32.partialorder %v19023_v26, 0.0004427343 (stack62)
        %v19476_v26 = vshrl.u32 %v19475_v42, 1 (stack51)
        %v21104_v25 = vxor.u32 %v21103_v11, %v21099_v9 (stack48)
        %v19025_v29 = vsel /*vm=*/%vm19024_vm12, /*on_true_vy=*/%v19022_v29, /*on_false_vx=*/%v19019_v56 (stack66)
        %v19864_v32 = vadd.s32 %v19861_v61, %v19856_v22 (stack40)
        %v19866_v21 = vshll.u32 %v19861_v61, 16 (stack45)
        %v19867_v22 = vshrl.u32 %v19861_v61, 16 (stack46)
        %v18541_v44 = vand.u32 2147483647, %v128005_v55 (stack77)
        %v18676_v31 = vmul.f32 %v18672_v60, %v128131_v8 (stack54)
        %v128187_v54 = vxor.u32 2147483648, %v19025_v29 (stack56)
        %v20270_v53 = vxor.u32 %v20269_v6, %v20265_v27 (stack48)
        %v18577_v43 = vsel /*vm=*/%vm18568_vm6, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v19868_v10 = vor.u32 %v19867_v22, %v19866_v21 (stack47)
        %v20674_v23 = vadd.s32 %v20671_v46, %v121564_v0 (stack40)
        %v128193_v9 = vadd.s32 %v21104_v25, %v21099_v9 (stack40)
        %v18680_v41 = vadd.f32 %v18676_v31, %v18577_v43 (stack53)
        %120591 = vrsqrt.f32 %v128187_v54 (stack67)
        %v18549_v34 = vmul.f32 inf, %v128005_v55 (stack54)
        %vm19029_vm13 = vcmp.lt.f32.partialorder %v128187_v54, 5.0 (stack68)
        %v19477_v50 = vor.u32 16256, %v19476_v26 (stack47)
        %v19869_v7 = vxor.u32 %v19868_v10, %v19864_v32 (stack48)
        %vm128198_vm14 = vcmp.eq.f32.partialorder %v18541_v44, 1.0 (stack68)
        %v18573_v30 = vsel /*vm=*/%vm18568_vm6, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v18684_v8 = vmul.f32 %v18680_v41, %v128131_v8 (stack54)
        %v19002_v46 = vand.u32 2147483647, %v128133_v20 (stack77)
        %v128208_v11 = vmul.f32 inf, %v128133_v20 (stack54)
        %v19872_v56 = vadd.s32 %v19869_v7, %v19864_v32 (stack40)
        %v20666_v40 = vadd.s32 %v20662_v40, %v121569_v1 (stack40)
        %v20678_v61 = vadd.s32 1, %v20674_v23 (stack40)
        %v18688_v6 = vadd.f32 %v18684_v8, %v18573_v30 (stack53)
        %v128214_v60 = vsel /*vm=*/%vm19029_vm13, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v128217_v26 = vadd.f32 -2.5, %v128187_v54 (stack53)
        %v21109_v29 = vshll.u32 %v21104_v25, 15 (stack45)
        %v128222_v32 = vsel /*vm=*/%vm19029_vm13, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v19478_v21 = vand.u32.u16 65535, %v19477_v50 (stack52)
        %v19878_v22 = vshll.u32 %v19869_v7, 24 (stack45)
        %v19879_v44 = vshrl.u32 %v19869_v7, 8 (stack46)
        %v18692_v55 = vmul.f32 %v18688_v6, %v128005_v55 (stack54)
        %v20273_v27 = vadd.s32 %v20270_v53, %v20265_v27 (stack40)
        %v20275_v31 = vshll.u32 %v20270_v53, 15 (stack45)
        %v20276_v53 = vshrl.u32 %v20270_v53, 17 (stack46)
        %v119848_v43 = vadd.low.f32.bf16 -1.0, %v19478_v21 (stack53)
        %v19880_v10 = vor.u32 %v19879_v44, %v19878_v22 (stack47)
        %v20682_v23 = vadd.s32 %v20678_v61, %v20666_v40 (stack40)
        %v20684_v41 = vshll.u32 %v20678_v61, 17 (stack45)
        %v18696_v34 = vsel /*vm=*/%vm128198_vm14, /*on_true_vy=*/%v18549_v34, /*on_false_vx=*/%v18692_v55 (stack44)
        %v20277_v50 = vor.u32 %v20276_v53, %v20275_v31 (stack47)
        %v20685_v7 = vshrl.u32 %v20678_v61, 15 (stack46)
        %v21110_v25 = vshrl.u32 %v21104_v25, 17 (stack46)
        %v18700_v42 = vmul.f32 1.4140625, %v18696_v34 (stack54)
        %vm19074_vm15 = vcmp.eq.f32.partialorder %v128187_v54, inf (stack70)
        %v19487_v30 = vmul.f32 2.0, %v119848_v43 (stack54)
        %v19881_v8 = vxor.u32 %v19880_v10, %v19872_v56 (stack48)
        %v20278_v40 = vxor.u32 %v20277_v50, %v20273_v27 (stack48)
        %v20686_v61 = vor.u32 %v20685_v7, %v20684_v41 (stack47)
        %v21111_v6 = vor.u32 %v21110_v25, %v21109_v29 (stack47)
        %vm21526_vm0 = vcmp.lt.u32.totalorder %v128182_v12, %v157089_v17 (stack43)
        %v18703_v29 = vpack.c.bf16 %v156663_v45, %v18700_v42 (stack81)
        %v19491_v21 = vadd.f32 -0.99609375, %v19487_v30 (stack53)
        %v19876_v56 = vadd.s32 %v19872_v56, %v121569_v1 (stack40)
        %v19884_v22 = vadd.s32 %v19881_v8, %v121564_v0 (stack40)
        %v20281_v44 = vadd.s32 %v20278_v40, %v20273_v27 (stack40)
        %v20283_v55 = vshll.u32 %v20278_v40, 26 (stack45)
        %v20284_v27 = vshrl.u32 %v20278_v40, 6 (stack46)
        %v20687_v31 = vxor.u32 %v20686_v61, %v20682_v23 (stack48)
        %v120592_v53 = vpop.eup %120591 (stack73)
        %119841 = vst [vmem:[%s123356_s30 + $0x310] sm:$0xf] /*vst_source=*/%v18703_v29 (stack83)
        %v128234_v43 = vmax.f32 %v19491_v21, -0.99609375 (stack55)
        %v19888_v10 = vadd.s32 4, %v19884_v22 (stack40)
        %v21112_v41 = vxor.u32 %v21111_v6, %v128193_v9 (stack48)
        %v128239_v34 = vadd.s32 %v157180_v52, %v157090_v62 (stack40)
        %v19073_v50 = vmul.f32 %v120592_v53, %v128187_v54 (stack74)
        %vm19076_vm1 = vcmp.eq.f32.partialorder %v128187_v54, 0.0 (stack71)
        %v20285_v7 = vor.u32 %v20284_v27, %v20283_v55 (stack47)
        %v20690_v23 = vadd.s32 %v20687_v31, %v20682_v23 (stack40)
        %v19077_v25 = vand.u32 2147483648, %v128187_v54 (stack72)
        %v19507_v42 = vxor.u32 2147483648, %v128234_v43 (stack56)
        %v19892_v30 = vadd.s32 %v19888_v10, %v19876_v56 (stack40)
        %v20692_v8 = vshll.u32 %v20687_v31, 29 (stack45)
        %v19075_v40 = vsel /*vm=*/%vm19074_vm15, /*on_true_vy=*/%v128187_v54, /*on_false_vx=*/%v19073_v50 (stack75)
        %v19894_v61 = vshll.u32 %v19888_v10, 13 (stack45)
        %v19895_v6 = vshrl.u32 %v19888_v10, 19 (stack46)
        %v20286_v29 = vxor.u32 %v20285_v7, %v20281_v44 (stack48)
        %v128251_v21 = vsel /*vm=*/%vm19029_vm13, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v19078_v56 = vsel /*vm=*/%vm19076_vm1, /*on_true_vy=*/%v19077_v25, /*on_false_vx=*/%v19075_v40 (stack76)
        %v128254_v22 = vmul.f32 %v19507_v42, %v128234_v43 (stack54)
        %v20693_v55 = vshrl.u32 %v20687_v31, 3 (stack46)
        %v19081_v27 = vadd.f32 -3.0, %v19078_v56 (stack53)
        %v19896_v31 = vor.u32 %v19895_v6, %v19894_v61 (stack47)
        %v20289_v44 = vadd.s32 %v20286_v29, %v20281_v44 (stack40)
        %v20295_v53 = vshll.u32 %v20286_v29, 6 (stack45)
        %v19054_v10 = vsel /*vm=*/%vm19029_vm13, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v19058_v50 = vsel /*vm=*/%vm19029_vm13, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v19512_v7 = vadd.f32 1.0, %v128254_v22 (stack57)
        %v20296_v25 = vshrl.u32 %v20286_v29, 26 (stack46)
        %v19066_v42 = vsel /*vm=*/%vm19029_vm13, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v128269_v26 = vsel /*vm=*/%vm19029_vm13, /*on_true_vy=*/%v128217_v26, /*on_false_vx=*/%v19081_v27 (stack44)
        %v19897_v40 = vxor.u32 %v19896_v31, %v19892_v30 (stack48)
        %v20694_v8 = vor.u32 %v20693_v55, %v20692_v8 (stack47)
        %v19062_v61 = vsel /*vm=*/%vm19029_vm13, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v19089_v6 = vmul.f32 %v128269_v26, %v19066_v42 (stack54)
        %120593 = vlog2.f32 %v19512_v7 (stack58)
        %v19515_v29 = vmul.f32 -0.5, %v128254_v22 (stack59)
        %v19900_v30 = vadd.s32 %v19897_v40, %v19892_v30 (stack40)
        %v19902_v56 = vshll.u32 %v19897_v40, 15 (stack45)
        %v19903_v55 = vshrl.u32 %v19897_v40, 17 (stack46)
        %v20297_v27 = vor.u32 %v20296_v25, %v20295_v53 (stack47)
        %v19093_v31 = vadd.f32 %v19089_v6, %v19062_v61 (stack53)
        %v20293_v53 = vadd.s32 %v20289_v44, %v121574_v2 (stack40)
        %v20695_v7 = vxor.u32 %v20694_v8, %v20690_v23 (stack48)
        %v21115_v9 = vadd.s32 %v21112_v41, %v128193_v9 (stack40)
        %v19904_v25 = vor.u32 %v19903_v55, %v19902_v56 (stack47)
        %v20298_v44 = vxor.u32 %v20297_v27, %v20289_v44 (stack48)
        %v21117_v42 = vshll.u32 %v21112_v41, 26 (stack45)
        %v21118_v41 = vshrl.u32 %v21112_v41, 6 (stack46)
        %v19097_v40 = vmul.f32 %v19093_v31, %v128269_v26 (stack54)
        %v20698_v23 = vadd.s32 %v20695_v7, %v20690_v23 (stack40)
        %v20700_v8 = vshll.u32 %v20695_v7, 16 (stack45)
        %v20701_v61 = vshrl.u32 %v20695_v7, 16 (stack46)
        %v19516_v6 = vadd.f32 1.0, %v19515_v29 (stack61)
        %v19905_v29 = vxor.u32 %v19904_v25, %v19900_v30 (stack48)
        %v20301_v56 = vadd.s32 %v20298_v44, %v121569_v1 (stack40)
        %v21119_v55 = vor.u32 %v21118_v41, %v21117_v42 (stack47)
        %v19101_v50 = vadd.f32 %v19097_v40, %v19058_v50 (stack53)
        %v20702_v27 = vor.u32 %v20701_v61, %v20700_v8 (stack47)
        %v21535_v31 = vadd.s32 1, %v128239_v34 (stack40)
        %v128283_v7 = vadd.s32 %v157177_v24, %v157091_v37 (stack40)
        %v19908_v30 = vadd.s32 %v19905_v29, %v19900_v30 (stack40)
        %v19910_v25 = vshll.u32 %v19905_v29, 26 (stack45)
        %v19911_v44 = vshrl.u32 %v19905_v29, 6 (stack46)
        %v20305_v42 = vadd.s32 3, %v20301_v56 (stack40)
        %v19105_v41 = vmul.f32 %v19101_v50, %v128269_v26 (stack54)
        %v20703_v40 = vxor.u32 %v20702_v27, %v20698_v23 (stack48)
        %v21120_v8 = vxor.u32 %v21119_v55, %v21115_v9 (stack48)
        %v128290_v34 = vsel /*vm=*/%vm21526_vm0, /*on_true_vy=*/%v21535_v31, /*on_false_vx=*/%v128239_v34 (stack44)
        %v19912_v61 = vor.u32 %v19911_v44, %v19910_v25 (stack47)
        %v20309_v53 = vadd.s32 %v20305_v42, %v20293_v53 (stack40)
        %v20311_v29 = vshll.u32 %v20305_v42, 17 (stack45)
        %v20312_v56 = vshrl.u32 %v20305_v42, 15 (stack46)
        %v19109_v10 = vadd.f32 %v19105_v41, %v19054_v10 (stack53)
        %v20706_v23 = vadd.s32 %v20703_v40, %v20698_v23 (stack40)
        %v20712_v55 = vshll.u32 %v20703_v40, 24 (stack45)
        %v20713_v50 = vshrl.u32 %v20703_v40, 8 (stack46)
        %v19518_v27 = vand.u32 2147483647, %v128254_v22 (stack60)
        %v19913_v31 = vxor.u32 %v19912_v61, %v19908_v30 (stack48)
        %v20313_v25 = vor.u32 %v20312_v56, %v20311_v29 (stack47)
        %v128293_v9 = vadd.s32 %v21120_v8, %v21115_v9 (stack40)
        %v19050_v44 = vsel /*vm=*/%vm19029_vm13, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v19113_v42 = vmul.f32 %v19109_v10, %v128269_v26 (stack54)
        %v20714_v41 = vor.u32 %v20713_v50, %v20712_v55 (stack47)
        %v21517_v40 = vadd.s32 %v128182_v12, %v122657_v58 (stack40)
        %v120594_v61 = vpop.eup %120593 (stack64)
        %v19916_v30 = vadd.s32 %v19913_v31, %v19908_v30 (stack40)
        %v19922_v29 = vshll.u32 %v19913_v31, 6 (stack45)
        %v19923_v56 = vshrl.u32 %v19913_v31, 26 (stack46)
        %v20314_v10 = vxor.u32 %v20313_v25, %v20309_v53 (stack48)
        %v19117_v55 = vadd.f32 %v19113_v42, %v19050_v44 (stack53)
        %v19514_v50 = vmul.f32 0.6931472, %v120594_v61 (stack65)
        %v19517_v22 = vmul.f32 %v19516_v6, %v128254_v22 (stack63)
        %v20715_v6 = vxor.u32 %v20714_v41, %v20706_v23 (stack48)
        %vm19519_vm2 = vcmp.lt.f32.partialorder %v19518_v27, 0.0004427343 (stack62)
        %v19924_v27 = vor.u32 %v19923_v56, %v19922_v29 (stack47)
        %v20317_v53 = vadd.s32 %v20314_v10, %v20309_v53 (stack40)
        %v20319_v31 = vshll.u32 %v20314_v10, 29 (stack45)
        %v19121_v25 = vmul.f32 %v19117_v55, %v128269_v26 (stack54)
        %v19520_v44 = vsel /*vm=*/%vm19519_vm2, /*on_true_vy=*/%v19517_v22, /*on_false_vx=*/%v19514_v50 (stack66)
        %v20320_v42 = vshrl.u32 %v20314_v10, 3 (stack46)
        %v20718_v41 = vadd.s32 %v20715_v6, %v121574_v2 (stack40)
        %v128304_v61 = vxor.u32 2147483648, %v19520_v44 (stack56)
        %v19925_v29 = vxor.u32 %v19924_v27, %v19916_v30 (stack48)
        %v21129_v56 = vshll.u32 %v21120_v8, 6 (stack45)
        %v21130_v8 = vshrl.u32 %v21120_v8, 26 (stack46)
        %v19042_v54 = vsel /*vm=*/%vm19029_vm13, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v19125_v21 = vadd.f32 %v19121_v25, %v128251_v21 (stack53)
        %vm21521_vm3 = vcmp.lt.u32.totalorder %v21517_v40, %v128182_v12 (stack43)
        %v21556_v10 = vadd.s32 %v21517_v40, %v121569_v1 (stack40)
        %v19497_v55 = vand.u32 2147483647, %v128234_v43 (stack77)
        %vm19524_vm4 = vcmp.lt.f32.partialorder %v128304_v61, 5.0 (stack68)
        %120595 = vrsqrt.f32 %v128304_v61 (stack67)
        %v20321_v50 = vor.u32 %v20320_v42, %v20319_v31 (stack47)
        %v19129_v22 = vmul.f32 %v19125_v21, %v128269_v26 (stack54)
        %v20710_v23 = vadd.s32 %v20706_v23, %v121564_v0 (stack40)
        %v20722_v6 = vadd.s32 2, %v20718_v41 (stack40)
        %v21127_v27 = vadd.s32 %v128293_v9, %v121569_v1 (stack40)
        %v19920_v30 = vadd.s32 %v19916_v30, %v121564_v0 (stack40)
        %v19928_v31 = vadd.s32 %v19925_v29, %v121574_v2 (stack40)
        %v21131_v25 = vor.u32 %v21130_v8, %v21129_v56 (stack47)
        %v21543_v44 = vadd.s32 1, %v128290_v34 (stack40)
        %v19133_v42 = vadd.f32 %v19129_v22, %v19042_v54 (stack53)
        %v128325_v41 = vsel /*vm=*/%vm19524_vm4, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v128328_v29 = vadd.f32 -2.5, %v128304_v61 (stack53)
        %v21562_v56 = vshll.u32 %v21556_v10, 13 (stack45)
        %v128333_v8 = vsel /*vm=*/%vm19524_vm4, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v128338_v54 = vsel /*vm=*/%vm19524_vm4, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v19932_v21 = vadd.s32 5, %v19928_v31 (stack40)
        %v20322_v50 = vxor.u32 %v20321_v50, %v20317_v53 (stack48)
        %v19137_v22 = vmul.f32 %v19133_v42, %v128269_v26 (stack54)
        %v20726_v23 = vadd.s32 %v20722_v6, %v20710_v23 (stack40)
        %v20728_v31 = vshll.u32 %v20722_v6, 13 (stack45)
        %v20729_v6 = vshrl.u32 %v20722_v6, 19 (stack46)
        %vm128343_vm5 = vcmp.eq.f32.partialorder %v19002_v46, 1.0 (stack68)
        %v19934_v30 = vxor.u32 %v19932_v21, %v19920_v30 (stack48)
        %v20325_v53 = vadd.s32 %v20322_v50, %v20317_v53 (stack40)
        %v20327_v42 = vshll.u32 %v20322_v50, 16 (stack45)
        %v20328_v21 = vshrl.u32 %v20322_v50, 16 (stack46)
        %v19141_v32 = vadd.f32 %v19137_v22, %v128222_v32 (stack53)
        %vm19569_vm6 = vcmp.eq.f32.partialorder %v128304_v61, inf (stack70)
        %v20730_v50 = vor.u32 %v20729_v6, %v20728_v31 (stack47)
        %v21132_v9 = vxor.u32 %v21131_v25, %v128293_v9 (stack48)
        %v21547_v12 = vsel /*vm=*/%vm21521_vm3, /*on_true_vy=*/%v21543_v44, /*on_false_vx=*/%v128290_v34 (stack44)
        %v19935_v34 = vand.u32.u8 255, %v19934_v30 (stack49)
        %v20329_v40 = vor.u32 %v20328_v21, %v20327_v42 (stack47)
        %v21552_v25 = vadd.s32 %v21547_v12, %v121574_v2 (stack40)
        %v21563_v44 = vshrl.u32 %v21556_v10, 19 (stack46)
        %v19145_v26 = vmul.f32 %v19141_v32, %v128269_v26 (stack54)
        %vm19571_vm7 = vcmp.eq.f32.partialorder %v128304_v61, 0.0 (stack71)
        %v20731_v22 = vxor.u32 %v20730_v50, %v20726_v23 (stack48)
        %v21135_v31 = vadd.s32 %v21132_v9, %v121564_v0 (stack40)
        %v19936_v6 = vand.u32 65535, %v19935_v34 (stack50)
        %v20330_v30 = vxor.u32 %v20329_v40, %v20325_v53 (stack48)
        %v21560_v10 = vadd.s32 %v21556_v10, %v21552_v25 (stack40)
        %v21564_v56 = vor.u32 %v21563_v44, %v21562_v56 (stack47)
        %v19149_v60 = vadd.f32 %v19145_v26, %v128214_v60 (stack53)
        %v20734_v23 = vadd.s32 %v20731_v22, %v20726_v23 (stack40)
        %v20736_v42 = vshll.u32 %v20731_v22, 15 (stack45)
        %v20737_v21 = vshrl.u32 %v20731_v22, 17 (stack46)
        %v19937_v32 = vshrl.u32 %v19936_v6, 1 (stack51)
        %v20333_v53 = vadd.s32 %v20330_v30, %v20325_v53 (stack40)
        %v20339_v50 = vshll.u32 %v20330_v30, 24 (stack45)
        %v20340_v9 = vshrl.u32 %v20330_v30, 8 (stack46)
        %v120596_v12 = vpop.eup %120595 (stack73)
        %v19153_v20 = vmul.f32 %v19149_v60, %v128133_v20 (stack54)
        %v20738_v34 = vor.u32 %v20737_v21, %v20736_v42 (stack47)
        %v21139_v40 = vadd.s32 1, %v21135_v31 (stack40)
        %v21565_v25 = vxor.u32 %v21564_v56, %v21560_v10 (stack48)
        %v19568_v44 = vmul.f32 %v120596_v12, %v128304_v61 (stack74)
        %v19572_v26 = vand.u32 2147483648, %v128304_v61 (stack72)
        %v19938_v22 = vor.u32 16256, %v19937_v32 (stack47)
        %v20341_v31 = vor.u32 %v20340_v9, %v20339_v50 (stack47)
        %v19157_v11 = vsel /*vm=*/%vm128343_vm5, /*on_true_vy=*/%v128208_v11, /*on_false_vx=*/%v19153_v20 (stack44)
        %v20739_v46 = vxor.u32 %v20738_v34, %v20734_v23 (stack48)
        %v21143_v27 = vadd.s32 %v21139_v40, %v21127_v27 (stack40)
        %v21145_v6 = vshll.u32 %v21139_v40, 17 (stack45)
        %v19161_v30 = vmul.f32 1.4140625, %v19157_v11 (stack54)
        %v19570_v56 = vsel /*vm=*/%vm19569_vm6, /*on_true_vy=*/%v128304_v61, /*on_false_vx=*/%v19568_v44 (stack75)
        %v19939_v60 = vand.u32.u16 65535, %v19938_v22 (stack52)
        %v20342_v42 = vxor.u32 %v20341_v31, %v20333_v53 (stack48)
        %v19573_v21 = vsel /*vm=*/%vm19571_vm7, /*on_true_vy=*/%v19572_v26, /*on_false_vx=*/%v19570_v56 (stack76)
        %v20742_v23 = vadd.s32 %v20739_v46, %v20734_v23 (stack40)
        %v20744_v32 = vshll.u32 %v20739_v46, 26 (stack45)
        %v20745_v50 = vshrl.u32 %v20739_v46, 6 (stack46)
        %v19164_v9 = vpack.c.bf16 %v156663_v45, %v19161_v30 (stack81)
        %v19576_v12 = vadd.f32 -3.0, %v19573_v21 (stack53)
        %v119850_v20 = vadd.low.f32.bf16 -1.0, %v19939_v60 (stack53)
        %v20345_v34 = vadd.s32 %v20342_v42, %v121564_v0 (stack40)
        %v20337_v53 = vadd.s32 %v20333_v53, %v121569_v1 (stack40)
        %v20746_v44 = vor.u32 %v20745_v50, %v20744_v32 (stack47)
        %v21146_v40 = vshrl.u32 %v21139_v40, 15 (stack46)
        %v21568_v10 = vadd.s32 %v21565_v25, %v21560_v10 (stack40)
        %119843 = vst [vmem:[%s123356_s30 + $0x390] sm:$0xf] /*vst_source=*/%v19164_v9 (stack83)
        %v128376_v29 = vsel /*vm=*/%vm19524_vm4, /*on_true_vy=*/%v128328_v29, /*on_false_vx=*/%v19576_v12 (stack44)
        %v19948_v26 = vmul.f32 2.0, %v119850_v20 (stack54)
        %v20349_v22 = vadd.s32 4, %v20345_v34 (stack40)
        %v21570_v31 = vshll.u32 %v21565_v25, 15 (stack45)
        %v19584_v54 = vmul.f32 %v128376_v29, %v128338_v54 (stack54)
        %v20747_v11 = vxor.u32 %v20746_v44, %v20742_v23 (stack48)
        %v21147_v46 = vor.u32 %v21146_v40, %v21145_v6 (stack47)
        %v21571_v25 = vshrl.u32 %v21565_v25, 17 (stack46)
        %v19952_v6 = vadd.f32 -0.99609375, %v19948_v26 (stack53)
        %v20353_v30 = vadd.s32 %v20349_v22, %v20337_v53 (stack40)
        %v20355_v56 = vshll.u32 %v20349_v22, 13 (stack45)
        %v20356_v60 = vshrl.u32 %v20349_v22, 19 (stack46)
        %v19588_v8 = vadd.f32 %v19584_v54, %v128333_v8 (stack53)
        %v20750_v42 = vadd.s32 %v20747_v11, %v20742_v23 (stack40)
        %v20756_v21 = vshll.u32 %v20747_v11, 6 (stack45)
        %v20757_v23 = vshrl.u32 %v20747_v11, 26 (stack46)
        %v128384_v32 = vsel /*vm=*/%vm19524_vm4, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v128386_v50 = vmax.f32 %v19952_v6, -0.99609375 (stack55)
        %v20357_v9 = vor.u32 %v20356_v60, %v20355_v56 (stack47)
        %v21148_v12 = vxor.u32 %v21147_v46, %v21143_v27 (stack48)
        %v128391_v20 = vsel /*vm=*/%vm19524_vm4, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v19592_v34 = vmul.f32 %v19588_v8, %v128376_v29 (stack54)
        %v20758_v53 = vor.u32 %v20757_v23, %v20756_v21 (stack47)
        %vm21987_vm8 = vcmp.lt.u32.totalorder %v128283_v7, %v157091_v37 (stack43)
        %v19553_v44 = vsel /*vm=*/%vm19524_vm4, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v19968_v40 = vxor.u32 2147483648, %v128386_v50 (stack56)
        %v20358_v26 = vxor.u32 %v20357_v9, %v20353_v30 (stack48)
        %v21572_v22 = vor.u32 %v21571_v25, %v21570_v31 (stack47)
        %v19596_v31 = vadd.f32 %v19592_v34, %v19553_v44 (stack53)
        %v20759_v54 = vxor.u32 %v20758_v53, %v20750_v42 (stack48)
        %v21151_v27 = vadd.s32 %v21148_v12, %v21143_v27 (stack40)
        %v21153_v11 = vshll.u32 %v21148_v12, 29 (stack45)
        %v19541_v46 = vsel /*vm=*/%vm19524_vm4, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v128404_v25 = vmul.f32 %v19968_v40, %v128386_v50 (stack54)
        %v20361_v6 = vadd.s32 %v20358_v26, %v20353_v30 (stack40)
        %v20363_v30 = vshll.u32 %v20358_v26, 15 (stack45)
        %v19600_v56 = vmul.f32 %v19596_v31, %v128376_v29 (stack54)
        %v20364_v60 = vshrl.u32 %v20358_v26, 17 (stack46)
        %v20762_v8 = vadd.s32 %v20759_v54, %v121569_v1 (stack40)
        %v21154_v21 = vshrl.u32 %v21148_v12, 3 (stack46)
        %v19549_v23 = vsel /*vm=*/%vm19524_vm4, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v19973_v9 = vadd.f32 1.0, %v128404_v25 (stack57)
        %v20754_v42 = vadd.s32 %v20750_v42, %v121574_v2 (stack40)
        %v21573_v12 = vxor.u32 %v21572_v22, %v21568_v10 (stack48)
        %v19604_v34 = vadd.f32 %v19600_v56, %v19549_v23 (stack53)
        %v20365_v53 = vor.u32 %v20364_v60, %v20363_v30 (stack47)
        %v20766_v44 = vadd.s32 3, %v20762_v8 (stack40)
        %v21155_v40 = vor.u32 %v21154_v21, %v21153_v11 (stack47)
        %v19545_v61 = vsel /*vm=*/%vm19524_vm4, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %120597 = vlog2.f32 %v19973_v9 (stack58)
        %v21576_v10 = vadd.s32 %v21573_v12, %v21568_v10 (stack40)
        %v128418_v26 = vadd.s32 %v128283_v7, %v122657_v58 (stack40)
        %v19608_v22 = vmul.f32 %v19604_v34, %v128376_v29 (stack54)
        %v20366_v31 = vxor.u32 %v20365_v53, %v20361_v6 (stack48)
        %v20770_v54 = vadd.s32 %v20766_v44, %v20754_v42 (stack40)
        %v20772_v11 = vshll.u32 %v20766_v44, 17 (stack45)
        %v19976_v30 = vmul.f32 -0.5, %v128404_v25 (stack59)
        %v20773_v56 = vshrl.u32 %v20766_v44, 15 (stack46)
        %v21156_v60 = vxor.u32 %v21155_v40, %v21151_v27 (stack48)
        %v21578_v8 = vshll.u32 %v21573_v12, 26 (stack45)
        %v19612_v21 = vadd.f32 %v19608_v22, %v19545_v61 (stack53)
        %v20369_v6 = vadd.s32 %v20366_v31, %v20361_v6 (stack40)
        %v20371_v23 = vshll.u32 %v20366_v31, 26 (stack45)
        %v20372_v9 = vshrl.u32 %v20366_v31, 6 (stack46)
        %v20774_v42 = vor.u32 %v20773_v56, %v20772_v11 (stack47)
        %v21159_v27 = vadd.s32 %v21156_v60, %v21151_v27 (stack40)
        %v21161_v34 = vshll.u32 %v21156_v60, 16 (stack45)
        %v21162_v53 = vshrl.u32 %v21156_v60, 16 (stack46)
        %v19616_v44 = vmul.f32 %v19612_v21, %v128376_v29 (stack54)
        %v20373_v40 = vor.u32 %v20372_v9, %v20371_v23 (stack47)
        %v21579_v12 = vshrl.u32 %v21573_v12, 6 (stack46)
        %v21992_v61 = vadd.s32 %v157180_v52, %v157094_v36 (stack40)
        %v19977_v22 = vadd.f32 1.0, %v19976_v30 (stack61)
        %v20775_v31 = vxor.u32 %v20774_v42, %v20770_v54 (stack48)
        %v21163_v11 = vor.u32 %v21162_v53, %v21161_v34 (stack47)
        %v128427_v24 = vadd.s32 %v157177_v24, %v157095_v13 (stack40)
        %v19620_v46 = vadd.f32 %v19616_v44, %v19541_v46 (stack53)
        %v20374_v30 = vxor.u32 %v20373_v40, %v20369_v6 (stack48)
        %v21580_v56 = vor.u32 %v21579_v12, %v21578_v8 (stack47)
        %v21996_v60 = vadd.s32 1, %v21992_v61 (stack40)
        %v20778_v54 = vadd.s32 %v20775_v31, %v20770_v54 (stack40)
        %v20780_v8 = vshll.u32 %v20775_v31, 29 (stack45)
        %v20781_v21 = vshrl.u32 %v20775_v31, 3 (stack46)
        %v21164_v23 = vxor.u32 %v21163_v11, %v21159_v27 (stack48)
        %v19624_v9 = vmul.f32 %v19620_v46, %v128376_v29 (stack54)
        %v20377_v6 = vadd.s32 %v20374_v30, %v20369_v6 (stack40)
        %v20383_v42 = vshll.u32 %v20374_v30, 6 (stack45)
        %v20384_v34 = vshrl.u32 %v20374_v30, 26 (stack46)
        %v20782_v53 = vor.u32 %v20781_v21, %v20780_v8 (stack47)
        %v21167_v27 = vadd.s32 %v21164_v23, %v21159_v27 (stack40)
        %v21173_v44 = vshll.u32 %v21164_v23, 24 (stack45)
        %v21174_v40 = vshrl.u32 %v21164_v23, 8 (stack46)
        %v19628_v20 = vadd.f32 %v19624_v9, %v128391_v20 (stack53)
        %v19979_v12 = vand.u32 2147483647, %v128404_v25 (stack60)
        %v20385_v31 = vor.u32 %v20384_v34, %v20383_v42 (stack47)
        %v21581_v11 = vxor.u32 %v21580_v56, %v21576_v10 (stack48)
        %v20783_v46 = vxor.u32 %v20782_v53, %v20778_v54 (stack48)
        %v21175_v30 = vor.u32 %v21174_v40, %v21173_v44 (stack47)
        %vm21982_vm9 = vcmp.lt.u32.totalorder %v128418_v26, %v128283_v7 (stack43)
        %v22000_v61 = vsel /*vm=*/%vm21987_vm8, /*on_true_vy=*/%v21996_v60, /*on_false_vx=*/%v21992_v61 (stack44)
        %v120598_v56 = vpop.eup %120597 (stack64)
        %v19632_v60 = vmul.f32 %v19628_v20, %v128376_v29 (stack54)
        %v19978_v25 = vmul.f32 %v19977_v22, %v128404_v25 (stack63)
        %v20386_v22 = vxor.u32 %v20385_v31, %v20377_v6 (stack48)
        %v21584_v10 = vadd.s32 %v21581_v11, %v21576_v10 (stack40)
        %v19975_v8 = vmul.f32 0.6931472, %v120598_v56 (stack65)
        %v20786_v54 = vadd.s32 %v20783_v46, %v20778_v54 (stack40)
        %v20788_v21 = vshll.u32 %v20783_v46, 16 (stack45)
        %v20789_v23 = vshrl.u32 %v20783_v46, 16 (stack46)
        %v19636_v32 = vadd.f32 %v19632_v60, %v128384_v32 (stack53)
        %vm19980_vm10 = vcmp.lt.f32.partialorder %v19979_v12, 0.0004427343 (stack62)
        %v20389_v9 = vadd.s32 %v20386_v22, %v121574_v2 (stack40)
        %v21176_v42 = vxor.u32 %v21175_v30, %v21167_v27 (stack48)
        %v19981_v34 = vsel /*vm=*/%vm19980_vm10, /*on_true_vy=*/%v19978_v25, /*on_false_vx=*/%v19975_v8 (stack66)
        %v20790_v53 = vor.u32 %v20789_v23, %v20788_v21 (stack47)
        %v21590_v44 = vshll.u32 %v21581_v11, 6 (stack45)
        %v22004_v40 = vadd.s32 1, %v22000_v61 (stack40)
        %v19640_v29 = vmul.f32 %v19636_v32, %v128376_v29 (stack54)
        %v128442_v20 = vxor.u32 2147483648, %v19981_v34 (stack56)
        %v20393_v12 = vadd.s32 5, %v20389_v9 (stack40)
        %v21591_v31 = vshrl.u32 %v21581_v11, 26 (stack46)
        %v20381_v6 = vadd.s32 %v20377_v6, %v121564_v0 (stack40)
        %v20791_v11 = vxor.u32 %v20790_v53, %v20786_v54 (stack48)
        %v22008_v7 = vsel /*vm=*/%vm21982_vm9, /*on_true_vy=*/%v22004_v40, /*on_false_vx=*/%v22000_v61 (stack44)
        %v22017_v26 = vadd.s32 %v128418_v26, %v121569_v1 (stack40)
        %v19644_v41 = vadd.f32 %v19640_v29, %v128325_v41 (stack53)
        %120599 = vrsqrt.f32 %v128442_v20 (stack67)
        %vm128454_vm11 = vcmp.eq.f32.partialorder %v19497_v55, 1.0 (stack68)
        %v19505_v46 = vmul.f32 inf, %v128234_v43 (stack54)
        %vm19985_vm12 = vcmp.lt.f32.partialorder %v128442_v20, 5.0 (stack68)
        %v20395_v30 = vxor.u32 %v20393_v12, %v20381_v6 (stack48)
        %v19648_v43 = vmul.f32 %v19644_v41, %v128234_v43 (stack54)
        %v19958_v61 = vand.u32 2147483647, %v128386_v50 (stack77)
        %v21179_v56 = vadd.s32 %v21176_v42, %v121574_v2 (stack40)
        %v21592_v60 = vor.u32 %v21591_v31, %v21590_v44 (stack47)
        %v20794_v25 = vadd.s32 %v20791_v11, %v20786_v54 (stack40)
        %v21171_v27 = vadd.s32 %v21167_v27, %v121564_v0 (stack40)
        %v21588_v22 = vadd.s32 %v21584_v10, %v121569_v1 (stack40)
        %v22023_v8 = vshll.u32 %v22017_v26, 13 (stack45)
        %v19652_v54 = vsel /*vm=*/%vm128454_vm11, /*on_true_vy=*/%v19505_v46, /*on_false_vx=*/%v19648_v43 (stack44)
        %v128470_v21 = vsel /*vm=*/%vm19985_vm12, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v128475_v23 = vsel /*vm=*/%vm19985_vm12, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v128478_v32 = vadd.f32 -2.5, %v128442_v20 (stack53)
        %v19656_v9 = vmul.f32 1.4140625, %v19652_v54 (stack54)
        %v128483_v42 = vsel /*vm=*/%vm19985_vm12, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v20396_v34 = vand.u32.u8 255, %v20395_v30 (stack49)
        %v20800_v53 = vshll.u32 %v20791_v11, 24 (stack45)
        %v20801_v44 = vshrl.u32 %v20791_v11, 8 (stack46)
        %v21183_v40 = vadd.s32 2, %v21179_v56 (stack40)
        %v21593_v10 = vxor.u32 %v21592_v60, %v21584_v10 (stack48)
        %v22013_v29 = vadd.s32 %v22008_v7, %v121574_v2 (stack40)
        %v19659_v12 = vpack.c.bf16 %v156663_v45, %v19656_v9 (stack81)
        %vm20030_vm13 = vcmp.eq.f32.partialorder %v128442_v20, inf (stack70)
        %v20397_v31 = vand.u32 65535, %v20396_v34 (stack50)
        %v22024_v6 = vshrl.u32 %v22017_v26, 19 (stack46)
        %vm20032_vm14 = vcmp.eq.f32.partialorder %v128442_v20, 0.0 (stack71)
        %v20802_v11 = vor.u32 %v20801_v44, %v20800_v53 (stack47)
        %v21187_v7 = vadd.s32 %v21183_v40, %v21171_v27 (stack40)
        %v21189_v41 = vshll.u32 %v21183_v40, 13 (stack45)
        %v21190_v55 = vshrl.u32 %v21183_v40, 19 (stack46)
        %119849 = vst [vmem:[%s123356_s30 + $0x14] sm:$0xf] /*vst_source=*/%v19659_v12 (stack83)
        %v20398_v46 = vshrl.u32 %v20397_v31, 1 (stack51)
        %v21596_v30 = vadd.s32 %v21593_v10, %v121564_v0 (stack40)
        %v22021_v26 = vadd.s32 %v22017_v26, %v22013_v29 (stack40)
        %v22025_v43 = vor.u32 %v22024_v6, %v22023_v8 (stack47)
        %v20033_v56 = vand.u32 2147483648, %v128442_v20 (stack72)
        %v20803_v60 = vxor.u32 %v20802_v11, %v20794_v25 (stack48)
        %v21191_v27 = vor.u32 %v21190_v55, %v21189_v41 (stack47)
        %vm22448_vm15 = vcmp.lt.u32.totalorder %v128427_v24, %v157095_v13 (stack43)
        %v20399_v8 = vor.u32 16256, %v20398_v46 (stack47)
        %v21600_v54 = vadd.s32 1, %v21596_v30 (stack40)
        %v22026_v9 = vxor.u32 %v22025_v43, %v22021_v26 (stack48)
        %v128496_v52 = vadd.s32 %v157180_v52, %v157100_v14 (stack40)
        %v20798_v25 = vadd.s32 %v20794_v25, %v121569_v1 (stack40)
        %v20806_v34 = vadd.s32 %v20803_v60, %v121564_v0 (stack40)
        %v21192_v53 = vxor.u32 %v21191_v27, %v21187_v7 (stack48)
        %v157199_v44 = vld [vmem:[#allocation130_spill] sm:$0xff] (stack84)
        %v128502_v40 = vadd.s32 %v157199_v44, %v122651_v47 (stack40)
        %v120600_v10 = vpop.eup %120599 (stack73)
        %v20400_v29 = vand.u32.u16 65535, %v20399_v8 (stack52)
        %v21604_v22 = vadd.s32 %v21600_v54, %v21588_v22 (stack40)
        %v21606_v12 = vshll.u32 %v21600_v54, 17 (stack45)
        %v21607_v31 = vshrl.u32 %v21600_v54, 15 (stack46)
        %v20029_v6 = vmul.f32 %v120600_v10, %v128442_v20 (stack74)
        %v20810_v11 = vadd.s32 4, %v20806_v34 (stack40)
        %v21195_v7 = vadd.s32 %v21192_v53, %v21187_v7 (stack40)
        %v21197_v41 = vshll.u32 %v21192_v53, 15 (stack45)
        %v119852_v55 = vadd.low.f32.bf16 -1.0, %v20400_v29 (stack53)
        %v21198_v46 = vshrl.u32 %v21192_v53, 17 (stack46)
        %v21608_v30 = vor.u32 %v21607_v31, %v21606_v12 (stack47)
        %v22029_v26 = vadd.s32 %v22026_v9, %v22021_v26 (stack40)
        %v20031_v43 = vsel /*vm=*/%vm20030_vm13, /*on_true_vy=*/%v128442_v20, /*on_false_vx=*/%v20029_v6 (stack75)
        %v20814_v60 = vadd.s32 %v20810_v11, %v20798_v25 (stack40)
        %v20816_v27 = vshll.u32 %v20810_v11, 13 (stack45)
        %v20817_v8 = vshrl.u32 %v20810_v11, 19 (stack46)
        %v20034_v56 = vsel /*vm=*/%vm20032_vm14, /*on_true_vy=*/%v20033_v56, /*on_false_vx=*/%v20031_v43 (stack76)
        %v20409_v54 = vmul.f32 2.0, %v119852_v55 (stack54)
        %v21199_v25 = vor.u32 %v21198_v46, %v21197_v41 (stack47)
        %v21609_v34 = vxor.u32 %v21608_v30, %v21604_v22 (stack48)
        %v20037_v53 = vadd.f32 -3.0, %v20034_v56 (stack53)
        %v20818_v10 = vor.u32 %v20817_v8, %v20816_v27 (stack47)
        %v22031_v29 = vshll.u32 %v22026_v9, 15 (stack45)
        %v22032_v9 = vshrl.u32 %v22026_v9, 17 (stack46)
        %v20413_v12 = vadd.f32 -0.99609375, %v20409_v54 (stack53)
        %v21200_v31 = vxor.u32 %v21199_v25, %v21195_v7 (stack48)
        %v21612_v22 = vadd.s32 %v21609_v34, %v21604_v22 (stack40)
        %v21614_v6 = vshll.u32 %v21609_v34, 29 (stack45)
        %v128513_v32 = vsel /*vm=*/%vm19985_vm12, /*on_true_vy=*/%v128478_v32, /*on_false_vx=*/%v20037_v53 (stack44)
        %v20819_v11 = vxor.u32 %v20818_v10, %v20814_v60 (stack48)
        %v21615_v41 = vshrl.u32 %v21609_v34, 3 (stack46)
        %v22033_v55 = vor.u32 %v22032_v9, %v22031_v29 (stack47)
        %v20045_v42 = vmul.f32 %v128513_v32, %v128483_v42 (stack54)
        %v128517_v46 = vmax.f32 %v20413_v12, -0.99609375 (stack55)
        %v21203_v7 = vadd.s32 %v21200_v31, %v21195_v7 (stack40)
        %v21205_v30 = vshll.u32 %v21200_v31, 26 (stack45)
        %v20822_v43 = vadd.s32 %v20819_v11, %v20814_v60 (stack40)
        %v20824_v60 = vshll.u32 %v20819_v11, 15 (stack45)
        %v20825_v27 = vshrl.u32 %v20819_v11, 17 (stack46)
        %v21206_v8 = vshrl.u32 %v21200_v31, 6 (stack46)
        %v128522_v56 = vsel /*vm=*/%vm19985_vm12, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v128527_v54 = vsel /*vm=*/%vm19985_vm12, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v20049_v23 = vadd.f32 %v20045_v42, %v128475_v23 (stack53)
        %v20429_v25 = vxor.u32 2147483648, %v128517_v46 (stack56)
        %v20826_v34 = vor.u32 %v20825_v27, %v20824_v60 (stack47)
        %v21207_v53 = vor.u32 %v21206_v8, %v21205_v30 (stack47)
        %v21616_v10 = vor.u32 %v21615_v41, %v21614_v6 (stack47)
        %v22034_v29 = vxor.u32 %v22033_v55, %v22029_v26 (stack48)
        %v20014_v9 = vsel /*vm=*/%vm19985_vm12, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v20053_v12 = vmul.f32 %v20049_v23, %v128513_v32 (stack54)
        %v128536_v31 = vmul.f32 %v20429_v25, %v128517_v46 (stack54)
        %v22439_v6 = vadd.s32 %v128427_v24, %v122657_v58 (stack40)
        %v20827_v11 = vxor.u32 %v20826_v34, %v20822_v43 (stack48)
        %v21208_v41 = vxor.u32 %v21207_v53, %v21203_v7 (stack48)
        %v21617_v55 = vxor.u32 %v21616_v10, %v21612_v22 (stack48)
        %v22037_v26 = vadd.s32 %v22034_v29, %v22029_v26 (stack40)
        %v20006_v42 = vsel /*vm=*/%vm19985_vm12, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v20010_v30 = vsel /*vm=*/%vm19985_vm12, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v20057_v60 = vadd.f32 %v20053_v12, %v20014_v9 (stack53)
        %v20434_v27 = vadd.f32 1.0, %v128536_v31 (stack57)
        %v20830_v43 = vadd.s32 %v20827_v11, %v20822_v43 (stack40)
        %v20832_v8 = vshll.u32 %v20827_v11, 26 (stack45)
        %v20833_v23 = vshrl.u32 %v20827_v11, 6 (stack46)
        %v21211_v7 = vadd.s32 %v21208_v41, %v21203_v7 (stack40)
        %v20061_v25 = vmul.f32 %v20057_v60, %v128513_v32 (stack54)
        %120601 = vlog2.f32 %v20434_v27 (stack58)
        %vm22443_vm0 = vcmp.lt.u32.totalorder %v22439_v6, %v128427_v24 (stack43)
        %v22457_v34 = vadd.s32 1, %v128496_v52 (stack40)
        %v20437_v53 = vmul.f32 -0.5, %v128536_v31 (stack59)
        %v20834_v10 = vor.u32 %v20833_v23, %v20832_v8 (stack47)
        %v21217_v9 = vshll.u32 %v21208_v41, 6 (stack45)
        %v21218_v12 = vshrl.u32 %v21208_v41, 26 (stack46)
        %v20065_v11 = vadd.f32 %v20061_v25, %v20010_v30 (stack53)
        %v20440_v41 = vand.u32 2147483647, %v128536_v31 (stack60)
        %v21620_v22 = vadd.s32 %v21617_v55, %v21612_v22 (stack40)
        %v21622_v30 = vshll.u32 %v21617_v55, 16 (stack45)
        %v20835_v60 = vxor.u32 %v20834_v10, %v20830_v43 (stack48)
        %v21219_v27 = vor.u32 %v21218_v12, %v21217_v9 (stack47)
        %v21623_v55 = vshrl.u32 %v21617_v55, 16 (stack46)
        %v22039_v8 = vshll.u32 %v22034_v29, 26 (stack45)
        %v20069_v23 = vmul.f32 %v20065_v11, %v128513_v32 (stack54)
        %v22040_v29 = vshrl.u32 %v22034_v29, 6 (stack46)
        %v22461_v52 = vsel /*vm=*/%vm22448_vm15, /*on_true_vy=*/%v22457_v34, /*on_false_vx=*/%v128496_v52 (stack44)
        %v128558_v25 = vadd.s32 %v22439_v6, %v121569_v1 (stack40)
        %v20838_v43 = vadd.s32 %v20835_v60, %v20830_v43 (stack40)
        %v20844_v34 = vshll.u32 %v20835_v60, 6 (stack45)
        %v20845_v10 = vshrl.u32 %v20835_v60, 26 (stack46)
        %v21220_v9 = vxor.u32 %v21219_v27, %v21211_v7 (stack48)
        %v20073_v42 = vadd.f32 %v20069_v23, %v20006_v42 (stack53)
        %v21624_v12 = vor.u32 %v21623_v55, %v21622_v30 (stack47)
        %v22041_v11 = vor.u32 %v22040_v29, %v22039_v8 (stack47)
        %v22465_v30 = vadd.s32 1, %v22461_v52 (stack40)
        %v20438_v53 = vadd.f32 1.0, %v20437_v53 (stack61)
        %vm128560_vm1 = vcmp.lt.f32.partialorder %v20440_v41, 0.0004427343 (stack62)
        %v20846_v60 = vor.u32 %v20845_v10, %v20844_v34 (stack47)
        %v21223_v27 = vadd.s32 %v21220_v9, %v121569_v1 (stack40)
        %v20077_v55 = vmul.f32 %v20073_v42, %v128513_v32 (stack54)
        %v21625_v8 = vxor.u32 %v21624_v12, %v21620_v22 (stack48)
        %v22042_v23 = vxor.u32 %v22041_v11, %v22037_v26 (stack48)
        %v22469_v24 = vsel /*vm=*/%vm22443_vm0, /*on_true_vy=*/%v22465_v30, /*on_false_vx=*/%v22461_v52 (stack44)
        %v20847_v6 = vxor.u32 %v20846_v60, %v20838_v43 (stack48)
        %v21215_v7 = vadd.s32 %v21211_v7, %v121574_v2 (stack40)
        %v21227_v29 = vadd.s32 3, %v21223_v27 (stack40)
        %v22474_v52 = vadd.s32 %v22469_v24, %v121574_v2 (stack40)
        %v20081_v54 = vadd.f32 %v20077_v55, %v128527_v54 (stack53)
        %v21628_v22 = vadd.s32 %v21625_v8, %v21620_v22 (stack40)
        %v21634_v34 = vshll.u32 %v21625_v8, 24 (stack45)
        %v21635_v10 = vshrl.u32 %v21625_v8, 8 (stack46)
        %v20850_v9 = vadd.s32 %v20847_v6, %v121574_v2 (stack40)
        %v21231_v42 = vadd.s32 %v21227_v29, %v21215_v7 (stack40)
        %v21233_v12 = vshll.u32 %v21227_v29, 17 (stack45)
        %v21234_v11 = vshrl.u32 %v21227_v29, 15 (stack46)
        %v20085_v30 = vmul.f32 %v20081_v54, %v128513_v32 (stack54)
        %v20842_v43 = vadd.s32 %v20838_v43, %v121564_v0 (stack40)
        %v21636_v60 = vor.u32 %v21635_v10, %v21634_v34 (stack47)
        %v22045_v26 = vadd.s32 %v22042_v23, %v22037_v26 (stack40)
        %v120602_v27 = vpop.eup %120601 (stack64)
        %v20854_v55 = vadd.s32 5, %v20850_v9 (stack40)
        %v21235_v8 = vor.u32 %v21234_v11, %v21233_v12 (stack47)
        %v22051_v24 = vshll.u32 %v22042_v23, 6 (stack45)
        %v22052_v23 = vshrl.u32 %v22042_v23, 26 (stack46)
        %v20089_v56 = vadd.f32 %v20085_v30, %v128522_v56 (stack53)
        %v20436_v6 = vmul.f32 0.6931472, %v120602_v27 (stack65)
        %v20439_v31 = vmul.f32 %v20438_v53, %v128536_v31 (stack63)
        %v21637_v53 = vxor.u32 %v21636_v60, %v21628_v22 (stack48)
        %v20856_v7 = vxor.u32 %v20854_v55, %v20842_v43 (stack48)
        %v21236_v29 = vxor.u32 %v21235_v8, %v21231_v42 (stack48)
        %v22053_v54 = vor.u32 %v22052_v23, %v22051_v24 (stack47)
        %v22482_v52 = vadd.s32 %v128558_v25, %v22474_v52 (stack40)
        %v20093_v34 = vmul.f32 %v20089_v56, %v128513_v32 (stack54)
        %v20442_v41 = vsel /*vm=*/%vm128560_vm1, /*on_true_vy=*/%v20439_v31, /*on_false_vx=*/%v20436_v6 (stack66)
        %v21640_v10 = vadd.s32 %v21637_v53, %v121574_v2 (stack40)
        %v22484_v9 = vshll.u32 %v128558_v25, 13 (stack45)
        %v128582_v12 = vxor.u32 2147483648, %v20442_v41 (stack56)
        %v21239_v42 = vadd.s32 %v21236_v29, %v21231_v42 (stack40)
        %v21241_v11 = vshll.u32 %v21236_v29, 29 (stack45)
        %v22485_v25 = vshrl.u32 %v128558_v25, 19 (stack46)
        %v20097_v21 = vadd.f32 %v20093_v34, %v128470_v21 (stack53)
        %v21242_v30 = vshrl.u32 %v21236_v29, 3 (stack46)
        %v22054_v43 = vxor.u32 %v22053_v54, %v22045_v26 (stack48)
        %vm128588_vm2 = vcmp.eq.f32.partialorder %v19958_v61, 1.0 (stack68)
        %v19966_v60 = vmul.f32 inf, %v128386_v50 (stack54)
        %120603 = vrsqrt.f32 %v128582_v12 (stack67)
        %v20857_v27 = vand.u32.u8 255, %v20856_v7 (stack49)
        %v19990_v20 = vsel /*vm=*/%vm19985_vm12, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v20101_v32 = vmul.f32 %v20097_v21, %v128513_v32 (stack54)
        %vm20446_vm3 = vcmp.lt.f32.partialorder %v128582_v12, 5.0 (stack68)
        %v21644_v55 = vadd.s32 2, %v21640_v10 (stack40)
        %v20419_v8 = vand.u32 2147483647, %v128517_v46 (stack77)
        %v21243_v24 = vor.u32 %v21242_v30, %v21241_v11 (stack47)
        %v21632_v22 = vadd.s32 %v21628_v22, %v121564_v0 (stack40)
        %v22486_v23 = vor.u32 %v22485_v25, %v22484_v9 (stack47)
        %v20105_v56 = vadd.f32 %v20101_v32, %v19990_v20 (stack53)
        %v128602_v6 = vadd.f32 -2.5, %v128582_v12 (stack53)
        %v22049_v26 = vadd.s32 %v22045_v26, %v121569_v1 (stack40)
        %v128607_v31 = vadd.s32 %v128502_v40, %v122657_v58 (stack40)
        %v128612_v53 = vsel /*vm=*/%vm20446_vm3, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v128617_v7 = vsel /*vm=*/%vm20446_vm3, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v20858_v29 = vand.u32 65535, %v20857_v27 (stack50)
        %v21244_v54 = vxor.u32 %v21243_v24, %v21239_v42 (stack48)
        %v20109_v50 = vmul.f32 %v20105_v56, %v128386_v50 (stack54)
        %v21648_v34 = vadd.s32 %v21644_v55, %v21632_v22 (stack40)
        %v21650_v41 = vshll.u32 %v21644_v55, 13 (stack45)
        %v21651_v10 = vshrl.u32 %v21644_v55, 19 (stack46)
        %v20859_v9 = vshrl.u32 %v20858_v29, 1 (stack51)
        %v21247_v42 = vadd.s32 %v21244_v54, %v21239_v42 (stack40)
        %v21249_v11 = vshll.u32 %v21244_v54, 16 (stack45)
        %v21250_v25 = vshrl.u32 %v21244_v54, 16 (stack46)
        %v20113_v21 = vsel /*vm=*/%vm128588_vm2, /*on_true_vy=*/%v19966_v60, /*on_false_vx=*/%v20109_v50 (stack44)
        %vm20491_vm4 = vcmp.eq.f32.partialorder %v128582_v12, inf (stack70)
        %v21652_v30 = vor.u32 %v21651_v10, %v21650_v41 (stack47)
        %v22057_v43 = vadd.s32 %v22054_v43, %v121564_v0 (stack40)
        %v22487_v61 = vxor.u32 %v22486_v23, %v22482_v52 (stack48)
        %v20117_v60 = vmul.f32 1.4140625, %v20113_v21 (stack54)
        %vm20493_vm5 = vcmp.eq.f32.partialorder %v128582_v12, 0.0 (stack71)
        %v20860_v27 = vor.u32 16256, %v20859_v9 (stack47)
        %v21251_v20 = vor.u32 %v21250_v25, %v21249_v11 (stack47)
        %v21653_v32 = vxor.u32 %v21652_v30, %v21648_v34 (stack48)
        %v22061_v55 = vadd.s32 1, %v22057_v43 (stack40)
        %v22490_v52 = vadd.s32 %v22487_v61, %v22482_v52 (stack40)
        %v22492_v24 = vshll.u32 %v22487_v61, 15 (stack45)
        %v20120_v22 = vpack.c.bf16 %v156663_v45, %v20117_v60 (stack81)
        %v20861_v23 = vand.u32.u16 65535, %v20860_v27 (stack52)
        %v21252_v56 = vxor.u32 %v21251_v20, %v21247_v42 (stack48)
        %v22493_v29 = vshrl.u32 %v22487_v61, 17 (stack46)
        %v21656_v54 = vadd.s32 %v21653_v32, %v21648_v34 (stack40)
        %v21658_v50 = vshll.u32 %v21653_v32, 15 (stack45)
        %v21659_v34 = vshrl.u32 %v21653_v32, 17 (stack46)
        %v22065_v26 = vadd.s32 %v22061_v55, %v22049_v26 (stack40)
        %119851 = vst [vmem:[%s123356_s30 + $0x94] sm:$0xf] /*vst_source=*/%v20120_v22 (stack83)
        %v119854_v41 = vadd.low.f32.bf16 -1.0, %v20861_v23 (stack53)
        %v21255_v10 = vadd.s32 %v21252_v56, %v21247_v42 (stack40)
        %v21261_v9 = vshll.u32 %v21252_v56, 24 (stack45)
        %v21262_v42 = vshrl.u32 %v21252_v56, 8 (stack46)
        %v120604_v11 = vpop.eup %120603 (stack73)
        %v21660_v25 = vor.u32 %v21659_v34, %v21658_v50 (stack47)
        %v22067_v21 = vshll.u32 %v22061_v55, 17 (stack45)
        %v22068_v30 = vshrl.u32 %v22061_v55, 15 (stack46)
        %v22494_v43 = vor.u32 %v22493_v29, %v22492_v24 (stack47)
        %v20490_v61 = vmul.f32 %v120604_v11, %v128582_v12 (stack74)
        %v20494_v60 = vand.u32 2147483648, %v128582_v12 (stack72)
        %v20870_v27 = vmul.f32 2.0, %v119854_v41 (stack54)
        %v21263_v20 = vor.u32 %v21262_v42, %v21261_v9 (stack47)
        %v21661_v32 = vxor.u32 %v21660_v25, %v21656_v54 (stack48)
        %v22069_v55 = vor.u32 %v22068_v30, %v22067_v21 (stack47)
        %v22495_v24 = vxor.u32 %v22494_v43, %v22490_v52 (stack48)
        %vm22943_vm6 = vcmp.lt.u32.totalorder %v128502_v40, %v122651_v47 (stack43)
        %v20492_v22 = vsel /*vm=*/%vm20491_vm4, /*on_true_vy=*/%v128582_v12, /*on_false_vx=*/%v20490_v61 (stack75)
        %v20874_v23 = vadd.f32 -0.99609375, %v20870_v27 (stack53)
        %v21264_v56 = vxor.u32 %v21263_v20, %v21255_v10 (stack48)
        %v157204_v29 = vld [vmem:[#allocation80_spill] sm:$0xff] (stack84)
        %v22948_v50 = vadd.s32 %v157204_v29, %v157068_v28 (stack40)
        %v20495_v34 = vsel /*vm=*/%vm20493_vm5, /*on_true_vy=*/%v20494_v60, /*on_false_vx=*/%v20492_v22 (stack76)
        %v21664_v54 = vadd.s32 %v21661_v32, %v21656_v54 (stack40)
        %v21666_v41 = vshll.u32 %v21661_v32, 26 (stack45)
        %v21667_v9 = vshrl.u32 %v21661_v32, 6 (stack46)
        %v20498_v42 = vadd.f32 -3.0, %v20495_v34 (stack53)
        %v128638_v11 = vmax.f32 %v20874_v23, -0.99609375 (stack55)
        %v21267_v25 = vadd.s32 %v21264_v56, %v121564_v0 (stack40)
        %v22070_v21 = vxor.u32 %v22069_v55, %v22065_v26 (stack48)
        %v128644_v30 = vsel /*vm=*/%vm20446_vm3, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v20479_v43 = vsel /*vm=*/%vm20446_vm3, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v21668_v61 = vor.u32 %v21667_v9, %v21666_v41 (stack47)
        %v22498_v52 = vadd.s32 %v22495_v24, %v22490_v52 (stack40)
        %v20483_v60 = vsel /*vm=*/%vm20446_vm3, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v128655_v6 = vsel /*vm=*/%vm20446_vm3, /*on_true_vy=*/%v128602_v6, /*on_false_vx=*/%v20498_v42 (stack44)
        %v20890_v27 = vxor.u32 2147483648, %v128638_v11 (stack56)
        %v21259_v10 = vadd.s32 %v21255_v10, %v121569_v1 (stack40)
        %v20506_v20 = vmul.f32 %v128655_v6, %v20483_v60 (stack54)
        %v21271_v32 = vadd.s32 4, %v21267_v25 (stack40)
        %v21669_v55 = vxor.u32 %v21668_v61, %v21664_v54 (stack48)
        %v22073_v26 = vadd.s32 %v22070_v21, %v22065_v26 (stack40)
        %v20893_v22 = vmul.f32 %v20890_v27, %v128638_v11 (stack54)
        %v22075_v23 = vshll.u32 %v22070_v21, 29 (stack45)
        %v22076_v56 = vshrl.u32 %v22070_v21, 3 (stack46)
        %v22500_v34 = vshll.u32 %v22495_v24, 26 (stack45)
        %v20510_v41 = vadd.f32 %v20506_v20, %v20479_v43 (stack53)
        %v21275_v9 = vadd.s32 %v21271_v32, %v21259_v10 (stack40)
        %v21277_v42 = vshll.u32 %v21271_v32, 13 (stack45)
        %v21278_v25 = vshrl.u32 %v21271_v32, 19 (stack46)
        %v20895_v21 = vadd.f32 1.0, %v20893_v22 (stack57)
        %v20898_v43 = vmul.f32 -0.5, %v20893_v22 (stack59)
        %v21672_v54 = vadd.s32 %v21669_v55, %v21664_v54 (stack40)
        %v22501_v24 = vshrl.u32 %v22495_v24, 6 (stack46)
        %v20514_v61 = vmul.f32 %v20510_v41, %v128655_v6 (stack54)
        %v21279_v60 = vor.u32 %v21278_v25, %v21277_v42 (stack47)
        %v21678_v27 = vshll.u32 %v21669_v55, 6 (stack45)
        %v21679_v10 = vshrl.u32 %v21669_v55, 26 (stack46)
        %v20471_v20 = vsel /*vm=*/%vm20446_vm3, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v20475_v32 = vsel /*vm=*/%vm20446_vm3, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %120605 = vlog2.f32 %v20895_v21 (stack58)
        %vm22938_vm7 = vcmp.lt.u32.totalorder %v128607_v31, %v128502_v40 (stack43)
        %v20518_v55 = vadd.f32 %v20514_v61, %v20475_v32 (stack53)
        %v21280_v41 = vxor.u32 %v21279_v60, %v21275_v9 (stack48)
        %v21680_v42 = vor.u32 %v21679_v10, %v21678_v27 (stack47)
        %v22077_v23 = vor.u32 %v22076_v56, %v22075_v23 (stack47)
        %v20899_v56 = vadd.f32 1.0, %v20898_v43 (stack61)
        %v20901_v25 = vand.u32 2147483647, %v20893_v22 (stack60)
        %v22502_v34 = vor.u32 %v22501_v24, %v22500_v34 (stack47)
        %v22952_v21 = vadd.s32 1, %v22948_v50 (stack40)
        %v20522_v43 = vmul.f32 %v20518_v55, %v128655_v6 (stack54)
        %v21283_v9 = vadd.s32 %v21280_v41, %v21275_v9 (stack40)
        %v21285_v24 = vshll.u32 %v21280_v41, 15 (stack45)
        %v21286_v61 = vshrl.u32 %v21280_v41, 17 (stack46)
        %v21681_v60 = vxor.u32 %v21680_v42, %v21672_v54 (stack48)
        %v22078_v27 = vxor.u32 %v22077_v23, %v22073_v26 (stack48)
        %v22503_v10 = vxor.u32 %v22502_v34, %v22498_v52 (stack48)
        %v22956_v50 = vsel /*vm=*/%vm22943_vm6, /*on_true_vy=*/%v22952_v21, /*on_false_vx=*/%v22948_v50 (stack44)
        %v20526_v20 = vadd.f32 %v20522_v43, %v20471_v20 (stack53)
        %v21287_v32 = vor.u32 %v21286_v61, %v21285_v24 (stack47)
        %v21676_v54 = vadd.s32 %v21672_v54, %v121574_v2 (stack40)
        %v22960_v55 = vadd.s32 1, %v22956_v50 (stack40)
        %v21684_v41 = vadd.s32 %v21681_v60, %v121569_v1 (stack40)
        %v22081_v26 = vadd.s32 %v22078_v27, %v22073_v26 (stack40)
        %v22083_v42 = vshll.u32 %v22078_v27, 16 (stack45)
        %v22084_v23 = vshrl.u32 %v22078_v27, 16 (stack46)
        %v20530_v34 = vmul.f32 %v20526_v20, %v128655_v6 (stack54)
        %vm128677_vm8 = vcmp.lt.f32.partialorder %v20901_v25, 0.0004427343 (stack62)
        %v21288_v21 = vxor.u32 %v21287_v32, %v21283_v9 (stack48)
        %v22506_v52 = vadd.s32 %v22503_v10, %v22498_v52 (stack40)
        %v22512_v43 = vshll.u32 %v22503_v10, 6 (stack45)
        %v21688_v24 = vadd.s32 3, %v21684_v41 (stack40)
        %v22085_v61 = vor.u32 %v22084_v23, %v22083_v42 (stack47)
        %v22513_v60 = vshrl.u32 %v22503_v10, 26 (stack46)
        %v22964_v40 = vsel /*vm=*/%vm22938_vm7, /*on_true_vy=*/%v22960_v55, /*on_false_vx=*/%v22956_v50 (stack44)
        %v20534_v30 = vadd.f32 %v20530_v34, %v128644_v30 (stack53)
        %v21291_v9 = vadd.s32 %v21288_v21, %v21283_v9 (stack40)
        %v21293_v27 = vshll.u32 %v21288_v21, 26 (stack45)
        %v21294_v10 = vshrl.u32 %v21288_v21, 6 (stack46)
        %v21692_v50 = vadd.s32 %v21688_v24, %v21676_v54 (stack40)
        %v21694_v20 = vshll.u32 %v21688_v24, 17 (stack45)
        %v21695_v32 = vshrl.u32 %v21688_v24, 15 (stack46)
        %v22086_v54 = vxor.u32 %v22085_v61, %v22081_v26 (stack48)
        %v20538_v55 = vmul.f32 %v20534_v30, %v128655_v6 (stack54)
        %v20900_v22 = vmul.f32 %v20899_v56, %v20893_v22 (stack63)
        %v21295_v56 = vor.u32 %v21294_v10, %v21293_v27 (stack47)
        %v22514_v41 = vor.u32 %v22513_v60, %v22512_v43 (stack47)
        %v21696_v42 = vor.u32 %v21695_v32, %v21694_v20 (stack47)
        %v22089_v26 = vadd.s32 %v22086_v54, %v22081_v26 (stack40)
        %v22095_v23 = vshll.u32 %v22086_v54, 24 (stack45)
        %v22096_v34 = vshrl.u32 %v22086_v54, 8 (stack46)
        %v120606_v21 = vpop.eup %120605 (stack64)
        %v20542_v7 = vadd.f32 %v20538_v55, %v128617_v7 (stack53)
        %v21296_v43 = vxor.u32 %v21295_v56, %v21291_v9 (stack48)
        %v22515_v24 = vxor.u32 %v22514_v41, %v22506_v52 (stack48)
        %v22973_v31 = vadd.s32 %v128607_v31, %v121569_v1 (stack40)
        %v20897_v61 = vmul.f32 0.6931472, %v120606_v21 (stack65)
        %v21697_v60 = vxor.u32 %v21696_v42, %v21692_v50 (stack48)
        %v22097_v30 = vor.u32 %v22096_v34, %v22095_v23 (stack47)
        %v22969_v40 = vadd.s32 %v22964_v40, %v121574_v2 (stack40)
        %v20546_v27 = vmul.f32 %v20542_v7, %v128655_v6 (stack54)
        %v21299_v9 = vadd.s32 %v21296_v43, %v21291_v9 (stack40)
        %v21305_v10 = vshll.u32 %v21296_v43, 6 (stack45)
        %v21306_v20 = vshrl.u32 %v21296_v43, 26 (stack46)
        %v20903_v25 = vsel /*vm=*/%vm128677_vm8, /*on_true_vy=*/%v20900_v22, /*on_false_vx=*/%v20897_v61 (stack66)
        %v21700_v50 = vadd.s32 %v21697_v60, %v21692_v50 (stack40)
        %v21702_v32 = vshll.u32 %v21697_v60, 29 (stack45)
        %v21703_v54 = vshrl.u32 %v21697_v60, 3 (stack46)
        %v20550_v53 = vadd.f32 %v20546_v27, %v128612_v53 (stack53)
        %v128694_v55 = vxor.u32 2147483648, %v20903_v25 (stack56)
        %v21307_v22 = vor.u32 %v21306_v20, %v21305_v10 (stack47)
        %v22098_v56 = vxor.u32 %v22097_v30, %v22089_v26 (stack48)
        %v128696_v41 = vadd.s32 %v22973_v31, %v22969_v40 (stack40)
        %v20427_v42 = vmul.f32 inf, %v128517_v46 (stack54)
        %v20455_v23 = vsel /*vm=*/%vm20446_vm3, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v20554_v34 = vmul.f32 %v20550_v53, %v128655_v6 (stack54)
        %120607 = vrsqrt.f32 %v128694_v55 (stack67)
        %vm128706_vm9 = vcmp.eq.f32.partialorder %v20419_v8, 1.0 (stack68)
        %vm20907_vm10 = vcmp.lt.f32.partialorder %v128694_v55, 5.0 (stack68)
        %v21308_v21 = vxor.u32 %v21307_v22, %v21299_v9 (stack48)
        %v21704_v7 = vor.u32 %v21703_v54, %v21702_v32 (stack47)
        %v22518_v43 = vadd.s32 %v22515_v24, %v121564_v0 (stack40)
        %v20451_v12 = vsel /*vm=*/%vm20446_vm3, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v20558_v24 = vadd.f32 %v20554_v34, %v20455_v23 (stack53)
        %v22510_v52 = vadd.s32 %v22506_v52, %v121569_v1 (stack40)
        %v22979_v61 = vshll.u32 %v22973_v31, 13 (stack45)
        %v128717_v60 = vadd.f32 -2.5, %v128694_v55 (stack53)
        %v21303_v30 = vadd.s32 %v21299_v9, %v121564_v0 (stack40)
        %v21311_v40 = vadd.s32 %v21308_v21, %v121574_v2 (stack40)
        %v22093_v26 = vadd.s32 %v22089_v26, %v121564_v0 (stack40)
        %v20562_v6 = vmul.f32 %v20558_v24, %v128655_v6 (stack54)
        %v128726_v27 = vsel /*vm=*/%vm20907_vm10, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v128731_v9 = vsel /*vm=*/%vm20907_vm10, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v128736_v10 = vsel /*vm=*/%vm20907_vm10, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v21315_v20 = vadd.s32 5, %v21311_v40 (stack40)
        %v21705_v25 = vxor.u32 %v21704_v7, %v21700_v50 (stack48)
        %v22101_v32 = vadd.s32 %v22098_v56, %v121574_v2 (stack40)
        %v22522_v54 = vadd.s32 1, %v22518_v43 (stack40)
        %v20566_v53 = vadd.f32 %v20562_v6, %v20451_v12 (stack53)
        %v22980_v31 = vshrl.u32 %v22973_v31, 19 (stack46)
        %v128741_v22 = vadd.s32 %v157199_v44, %v157070_v38 (stack40)
        %v128745_v56 = vadd.s32 %v157204_v29, %v157076_v35 (stack40)
        %vm20952_vm11 = vcmp.eq.f32.partialorder %v128694_v55, inf (stack70)
        %v21317_v23 = vxor.u32 %v21315_v20, %v21303_v30 (stack48)
        %v21708_v50 = vadd.s32 %v21705_v25, %v21700_v50 (stack40)
        %v21710_v34 = vshll.u32 %v21705_v25, 16 (stack45)
        %v21711_v21 = vshrl.u32 %v21705_v25, 16 (stack46)
        %v20570_v46 = vmul.f32 %v20566_v53, %v128517_v46 (stack54)
        %v22105_v7 = vadd.s32 2, %v22101_v32 (stack40)
        %v22526_v43 = vadd.s32 %v22522_v54, %v22510_v52 (stack40)
        %v22528_v12 = vshll.u32 %v22522_v54, 17 (stack45)
        %v21318_v24 = vand.u32.u8 255, %v21317_v23 (stack49)
        %v21712_v52 = vor.u32 %v21711_v21, %v21710_v34 (stack47)
        %v22529_v30 = vshrl.u32 %v22522_v54, 15 (stack46)
        %v22981_v61 = vor.u32 %v22980_v31, %v22979_v61 (stack47)
        %v20574_v42 = vsel /*vm=*/%vm128706_vm9, /*on_true_vy=*/%v20427_v42, /*on_false_vx=*/%v20570_v46 (stack44)
        %v22109_v8 = vadd.s32 %v22105_v7, %v22093_v26 (stack40)
        %v22111_v40 = vshll.u32 %v22105_v7, 13 (stack45)
        %v22112_v26 = vshrl.u32 %v22105_v7, 19 (stack46)
        %v20578_v6 = vmul.f32 1.4140625, %v20574_v42 (stack54)
        %v21319_v20 = vand.u32 65535, %v21318_v24 (stack50)
        %v21713_v25 = vxor.u32 %v21712_v52, %v21708_v50 (stack48)
        %v22530_v32 = vor.u32 %v22529_v30, %v22528_v12 (stack47)
        %vm20954_vm12 = vcmp.eq.f32.partialorder %v128694_v55, 0.0 (stack71)
        %v22113_v54 = vor.u32 %v22112_v26, %v22111_v40 (stack47)
        %v22982_v53 = vxor.u32 %v22981_v61, %v128696_v41 (stack48)
        %vm23404_vm13 = vcmp.lt.u32.totalorder %v128741_v22, %v157070_v38 (stack43)
        %v120608_v31 = vpop.eup %120607 (stack73)
        %v20581_v23 = vpack.c.bf16 %v156663_v45, %v20578_v6 (stack81)
        %v21320_v34 = vshrl.u32 %v21319_v20, 1 (stack51)
        %v21716_v50 = vadd.s32 %v21713_v25, %v21708_v50 (stack40)
        %v21722_v21 = vshll.u32 %v21713_v25, 24 (stack45)
        %v20951_v46 = vmul.f32 %v120608_v31, %v128694_v55 (stack74)
        %v21723_v7 = vshrl.u32 %v21713_v25, 8 (stack46)
        %v22114_v12 = vxor.u32 %v22113_v54, %v22109_v8 (stack48)
        %v22531_v24 = vxor.u32 %v22530_v32, %v22526_v43 (stack48)
        %119853 = vst [vmem:[%s123356_s30 + $0x114] sm:$0xf] /*vst_source=*/%v20581_v23 (stack83)
        %v20955_v52 = vand.u32 2147483648, %v128694_v55 (stack72)
        %v21321_v30 = vor.u32 16256, %v21320_v34 (stack47)
        %v22985_v41 = vadd.s32 %v22982_v53, %v128696_v41 (stack40)
        %v22987_v61 = vshll.u32 %v22982_v53, 15 (stack45)
        %v20953_v42 = vsel /*vm=*/%vm20952_vm11, /*on_true_vy=*/%v128694_v55, /*on_false_vx=*/%v20951_v46 (stack75)
        %v21724_v40 = vor.u32 %v21723_v7, %v21722_v21 (stack47)
        %v22117_v8 = vadd.s32 %v22114_v12, %v22109_v8 (stack40)
        %v22119_v26 = vshll.u32 %v22114_v12, 15 (stack45)
        %v20956_v6 = vsel /*vm=*/%vm20954_vm12, /*on_true_vy=*/%v20955_v52, /*on_false_vx=*/%v20953_v42 (stack76)
        %v21322_v20 = vand.u32.u16 65535, %v21321_v30 (stack52)
        %v22120_v25 = vshrl.u32 %v22114_v12, 17 (stack46)
        %v22534_v43 = vadd.s32 %v22531_v24, %v22526_v43 (stack40)
        %v20959_v32 = vadd.f32 -3.0, %v20956_v6 (stack53)
        %v21725_v54 = vxor.u32 %v21724_v40, %v21716_v50 (stack48)
        %v22536_v31 = vshll.u32 %v22531_v24, 29 (stack45)
        %v22537_v23 = vshrl.u32 %v22531_v24, 3 (stack46)
        %v20944_v34 = vsel /*vm=*/%vm20907_vm10, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v119856_v21 = vadd.low.f32.bf16 -1.0, %v21322_v20 (stack53)
        %v22121_v46 = vor.u32 %v22120_v25, %v22119_v26 (stack47)
        %v22988_v53 = vshrl.u32 %v22982_v53, 17 (stack46)
        %v128771_v60 = vsel /*vm=*/%vm20907_vm10, /*on_true_vy=*/%v128717_v60, /*on_false_vx=*/%v20959_v32 (stack44)
        %v21728_v7 = vadd.s32 %v21725_v54, %v121564_v0 (stack40)
        %v22538_v12 = vor.u32 %v22537_v23, %v22536_v31 (stack47)
        %v23413_v24 = vadd.s32 1, %v128745_v56 (stack40)
        %v20967_v52 = vmul.f32 %v128771_v60, %v20944_v34 (stack54)
        %v21331_v30 = vmul.f32 2.0, %v119856_v21 (stack54)
        %v21720_v50 = vadd.s32 %v21716_v50, %v121569_v1 (stack40)
        %v22122_v42 = vxor.u32 %v22121_v46, %v22117_v8 (stack48)
        %v21732_v40 = vadd.s32 4, %v21728_v7 (stack40)
        %v22539_v26 = vxor.u32 %v22538_v12, %v22534_v43 (stack48)
        %v22989_v61 = vor.u32 %v22988_v53, %v22987_v61 (stack47)
        %v128781_v56 = vsel /*vm=*/%vm23404_vm13, /*on_true_vy=*/%v23413_v24, /*on_false_vx=*/%v128745_v56 (stack44)
        %v20971_v10 = vadd.f32 %v20967_v52, %v128736_v10 (stack53)
        %v21335_v6 = vadd.f32 -0.99609375, %v21331_v30 (stack53)
        %v22125_v8 = vadd.s32 %v22122_v42, %v22117_v8 (stack40)
        %v22127_v20 = vshll.u32 %v22122_v42, 26 (stack45)
        %v21736_v25 = vadd.s32 %v21732_v40, %v21720_v50 (stack40)
        %v21738_v32 = vshll.u32 %v21732_v40, 13 (stack45)
        %v21739_v54 = vshrl.u32 %v21732_v40, 19 (stack46)
        %v22128_v31 = vshrl.u32 %v22122_v42, 6 (stack46)
        %v20975_v23 = vmul.f32 %v20971_v10, %v128771_v60 (stack54)
        %v128785_v34 = vmax.f32 %v21335_v6, -0.99609375 (stack55)
        %v22542_v43 = vadd.s32 %v22539_v26, %v22534_v43 (stack40)
        %v22544_v21 = vshll.u32 %v22539_v26, 16 (stack45)
        %v21740_v46 = vor.u32 %v21739_v54, %v21738_v32 (stack47)
        %v22129_v53 = vor.u32 %v22128_v31, %v22127_v20 (stack47)
        %v22545_v7 = vshrl.u32 %v22539_v26, 16 (stack46)
        %v22990_v12 = vxor.u32 %v22989_v61, %v22985_v41 (stack48)
        %v20924_v24 = vsel /*vm=*/%vm20907_vm10, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v20979_v9 = vadd.f32 %v20975_v23, %v128731_v9 (stack53)
        %v21351_v52 = vxor.u32 2147483648, %v128785_v34 (stack56)
        %v23395_v30 = vadd.s32 %v128741_v22, %v122657_v58 (stack40)
        %v20928_v50 = vsel /*vm=*/%vm20907_vm10, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v21741_v42 = vxor.u32 %v21740_v46, %v21736_v25 (stack48)
        %v22130_v40 = vxor.u32 %v22129_v53, %v22125_v8 (stack48)
        %v128797_v41 = vadd.s32 %v22990_v12, %v22985_v41 (stack40)
        %v20932_v26 = vsel /*vm=*/%vm20907_vm10, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v20983_v61 = vmul.f32 %v20979_v9, %v128771_v60 (stack54)
        %v128804_v10 = vmul.f32 %v21351_v52, %v128785_v34 (stack54)
        %v22546_v6 = vor.u32 %v22545_v7, %v22544_v21 (stack47)
        %v21744_v20 = vadd.s32 %v21741_v42, %v21736_v25 (stack40)
        %v21746_v25 = vshll.u32 %v21741_v42, 15 (stack45)
        %v21747_v32 = vshrl.u32 %v21741_v42, 17 (stack46)
        %v22133_v8 = vadd.s32 %v22130_v40, %v22125_v8 (stack40)
        %v20987_v54 = vadd.f32 %v20983_v61, %v20932_v26 (stack53)
        %v21356_v31 = vadd.f32 1.0, %v128804_v10 (stack57)
        %v21359_v23 = vmul.f32 -0.5, %v128804_v10 (stack59)
        %vm23399_vm14 = vcmp.lt.u32.totalorder %v23395_v30, %v128741_v22 (stack43)
        %v21748_v21 = vor.u32 %v21747_v32, %v21746_v25 (stack47)
        %v22139_v46 = vshll.u32 %v22130_v40, 6 (stack45)
        %v22140_v53 = vshrl.u32 %v22130_v40, 26 (stack46)
        %v23434_v7 = vadd.s32 %v23395_v30, %v121569_v1 (stack40)
        %v20991_v9 = vmul.f32 %v20987_v54, %v128771_v60 (stack54)
        %120609 = vlog2.f32 %v21356_v31 (stack58)
        %v21362_v52 = vand.u32 2147483647, %v128804_v10 (stack60)
        %v22995_v42 = vshll.u32 %v22990_v12, 26 (stack45)
        %v21749_v40 = vxor.u32 %v21748_v21, %v21744_v20 (stack48)
        %v22141_v26 = vor.u32 %v22140_v53, %v22139_v46 (stack47)
        %v22547_v61 = vxor.u32 %v22546_v6, %v22542_v43 (stack48)
        %v22996_v12 = vshrl.u32 %v22990_v12, 6 (stack46)
        %v20995_v50 = vadd.f32 %v20991_v9, %v20928_v50 (stack53)
        %v21360_v6 = vadd.f32 1.0, %v21359_v23 (stack61)
        %v22137_v25 = vadd.s32 %v22133_v8, %v121574_v2 (stack40)
        %v23421_v32 = vadd.s32 1, %v128781_v56 (stack40)
        %v21752_v20 = vadd.s32 %v21749_v40, %v21744_v20 (stack40)
        %v21754_v54 = vshll.u32 %v21749_v40, 26 (stack45)
        %v21755_v31 = vshrl.u32 %v21749_v40, 6 (stack46)
        %v22142_v8 = vxor.u32 %v22141_v26, %v22133_v8 (stack48)
        %v20999_v23 = vmul.f32 %v20995_v50, %v128771_v60 (stack54)
        %v22550_v43 = vadd.s32 %v22547_v61, %v22542_v43 (stack40)
        %v22556_v21 = vshll.u32 %v22547_v61, 24 (stack45)
        %v22557_v46 = vshrl.u32 %v22547_v61, 8 (stack46)
        %v21756_v53 = vor.u32 %v21755_v31, %v21754_v54 (stack47)
        %v22145_v9 = vadd.s32 %v22142_v8, %v121569_v1 (stack40)
        %v22997_v42 = vor.u32 %v22996_v12, %v22995_v42 (stack47)
        %v23425_v22 = vsel /*vm=*/%vm23399_vm14, /*on_true_vy=*/%v23421_v32, /*on_false_vx=*/%v128781_v56 (stack44)
        %v21003_v56 = vadd.f32 %v20999_v23, %v20924_v24 (stack53)
        %v22558_v24 = vor.u32 %v22557_v46, %v22556_v21 (stack47)
        %v23430_v30 = vadd.s32 %v23425_v22, %v121574_v2 (stack40)
        %v23440_v40 = vshll.u32 %v23434_v7, 13 (stack45)
        %v21757_v26 = vxor.u32 %v21756_v53, %v21752_v20 (stack48)
        %v22149_v61 = vadd.s32 3, %v22145_v9 (stack40)
        %v22998_v12 = vxor.u32 %v22997_v42, %v128797_v41 (stack48)
        %v23441_v50 = vshrl.u32 %v23434_v7, 19 (stack46)
        %v21007_v32 = vmul.f32 %v21003_v56, %v128771_v60 (stack54)
        %v22559_v54 = vxor.u32 %v22558_v24, %v22550_v43 (stack48)
        %v128822_v7 = vadd.s32 %v23434_v7, %v23430_v30 (stack40)
        %v128826_v31 = vadd.s32 %v157199_v44, %v157077_v51 (stack40)
        %v21760_v20 = vadd.s32 %v21757_v26, %v21752_v20 (stack40)
        %v21766_v8 = vshll.u32 %v21757_v26, 6 (stack45)
        %v21767_v23 = vshrl.u32 %v21757_v26, 26 (stack46)
        %v22153_v25 = vadd.s32 %v22149_v61, %v22137_v25 (stack40)
        %v21011_v27 = vadd.f32 %v21007_v32, %v128726_v27 (stack53)
        %v22155_v21 = vshll.u32 %v22149_v61, 17 (stack45)
        %v22156_v46 = vshrl.u32 %v22149_v61, 15 (stack46)
        %v22562_v53 = vadd.s32 %v22559_v54, %v121574_v2 (stack40)
        %v21768_v9 = vor.u32 %v21767_v23, %v21766_v8 (stack47)
        %v22554_v43 = vadd.s32 %v22550_v43, %v121564_v0 (stack40)
        %v23001_v41 = vadd.s32 %v22998_v12, %v128797_v41 (stack40)
        %v23007_v42 = vshll.u32 %v22998_v12, 6 (stack45)
        %v21015_v22 = vmul.f32 %v21011_v27, %v128771_v60 (stack54)
        %v22157_v56 = vor.u32 %v22156_v46, %v22155_v21 (stack47)
        %v22566_v24 = vadd.s32 2, %v22562_v53 (stack40)
        %v23008_v30 = vshrl.u32 %v22998_v12, 26 (stack46)
        %v120610_v26 = vpop.eup %120609 (stack64)
        %v20916_v61 = vsel /*vm=*/%vm20907_vm10, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v21361_v10 = vmul.f32 %v21360_v6, %v128804_v10 (stack63)
        %v21769_v6 = vxor.u32 %v21768_v9, %v21760_v20 (stack48)
        %v23442_v40 = vor.u32 %v23441_v50, %v23440_v40 (stack47)
        %v21019_v12 = vadd.f32 %v21015_v22, %v20916_v61 (stack53)
        %v21358_v50 = vmul.f32 0.6931472, %v120610_v26 (stack65)
        %v22158_v32 = vxor.u32 %v22157_v56, %v22153_v25 (stack48)
        %v22570_v54 = vadd.s32 %v22566_v24, %v22554_v43 (stack40)
        %vm21363_vm15 = vcmp.lt.f32.partialorder %v21362_v52, 0.0004427343 (stack62)
        %v21772_v52 = vadd.s32 %v21769_v6, %v121574_v2 (stack40)
        %v22572_v8 = vshll.u32 %v22566_v24, 13 (stack45)
        %v23009_v23 = vor.u32 %v23008_v30, %v23007_v42 (stack47)
        %v21023_v60 = vmul.f32 %v21019_v12, %v128771_v60 (stack54)
        %v21364_v27 = vsel /*vm=*/%vm21363_vm15, /*on_true_vy=*/%v21361_v10, /*on_false_vx=*/%v21358_v50 (stack66)
        %v22161_v25 = vadd.s32 %v22158_v32, %v22153_v25 (stack40)
        %v22573_v21 = vshrl.u32 %v22566_v24, 19 (stack46)
        %v20880_v46 = vand.u32 2147483647, %v128638_v11 (stack77)
        %v20912_v55 = vsel /*vm=*/%vm20907_vm10, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v128843_v53 = vxor.u32 2147483648, %v21364_v27 (stack56)
        %v21776_v9 = vadd.s32 5, %v21772_v52 (stack40)
        %v21027_v43 = vadd.f32 %v21023_v60, %v20912_v55 (stack53)
        %v23010_v42 = vxor.u32 %v23009_v23, %v23001_v41 (stack48)
        %v23443_v22 = vxor.u32 %v23442_v40, %v128822_v7 (stack48)
        %v20888_v56 = vmul.f32 inf, %v128638_v11 (stack54)
        %120611 = vrsqrt.f32 %v128843_v53 (stack67)
        %v21764_v20 = vadd.s32 %v21760_v20, %v121564_v0 (stack40)
        %v22163_v24 = vshll.u32 %v22158_v32, 29 (stack45)
        %v21031_v11 = vmul.f32 %v21027_v43, %v128638_v11 (stack54)
        %vm21368_vm0 = vcmp.lt.f32.partialorder %v128843_v53, 5.0 (stack68)
        %v22164_v30 = vshrl.u32 %v22158_v32, 3 (stack46)
        %v22574_v26 = vor.u32 %v22573_v21, %v22572_v8 (stack47)
        %vm20883_vm1 = vcmp.eq.f32.partialorder %v20880_v46, 1.0 (stack68)
        %v21778_v61 = vxor.u32 %v21776_v9, %v21764_v20 (stack48)
        %v21035_v10 = vsel /*vm=*/%vm20883_vm1, /*on_true_vy=*/%v20888_v56, /*on_false_vx=*/%v21031_v11 (stack44)
        %v21341_v6 = vand.u32 2147483647, %v128785_v34 (stack77)
        %v23005_v41 = vadd.s32 %v23001_v41, %v121569_v1 (stack40)
        %v128855_v40 = vadd.s32 %v128826_v31, %v122657_v58 (stack40)
        %v21039_v12 = vmul.f32 1.4140625, %v21035_v10 (stack54)
        %v128860_v50 = vsel /*vm=*/%vm21368_vm0, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v128863_v32 = vadd.f32 -2.5, %v128843_v53 (stack53)
        %v21779_v52 = vand.u32.u8 255, %v21778_v61 (stack49)
        %v22165_v8 = vor.u32 %v22164_v30, %v22163_v24 (stack47)
        %v22575_v23 = vxor.u32 %v22574_v26, %v22570_v54 (stack48)
        %v23013_v60 = vadd.s32 %v23010_v42, %v121564_v0 (stack40)
        %v23446_v7 = vadd.s32 %v23443_v22, %v128822_v7 (stack40)
        %v21042_v27 = vpack.c.bf16 %v156663_v45, %v21039_v12 (stack81)
        %v21780_v21 = vand.u32 65535, %v21779_v52 (stack50)
        %v23448_v46 = vshll.u32 %v23443_v22, 15 (stack45)
        %v23449_v55 = vshrl.u32 %v23443_v22, 17 (stack46)
        %vm21413_vm2 = vcmp.eq.f32.partialorder %v128843_v53, inf (stack70)
        %v22166_v9 = vxor.u32 %v22165_v8, %v22161_v25 (stack48)
        %v22578_v54 = vadd.s32 %v22575_v23, %v22570_v54 (stack40)
        %v22580_v43 = vshll.u32 %v22575_v23, 15 (stack45)
        %v22581_v42 = vshrl.u32 %v22575_v23, 17 (stack46)
        %119855 = vst [vmem:[%s123356_s30 + $0x194] sm:$0xf] /*vst_source=*/%v21042_v27 (stack83)
        %vm21415_vm3 = vcmp.eq.f32.partialorder %v128843_v53, 0.0 (stack71)
        %v21781_v22 = vshrl.u32 %v21780_v21, 1 (stack51)
        %v23017_v56 = vadd.s32 1, %v23013_v60 (stack40)
        %v23450_v20 = vor.u32 %v23449_v55, %v23448_v46 (stack47)
        %vm23865_vm4 = vcmp.lt.u32.totalorder %v128826_v31, %v157077_v51 (stack43)
        %v22169_v25 = vadd.s32 %v22166_v9, %v22161_v25 (stack40)
        %v22171_v24 = vshll.u32 %v22166_v9, 16 (stack45)
        %v22172_v11 = vshrl.u32 %v22166_v9, 16 (stack46)
        %v22582_v30 = vor.u32 %v22581_v42, %v22580_v43 (stack47)
        %v21782_v26 = vor.u32 16256, %v21781_v22 (stack47)
        %v23021_v61 = vadd.s32 %v23017_v56, %v23005_v41 (stack40)
        %v23023_v10 = vshll.u32 %v23017_v56, 17 (stack45)
        %v23024_v41 = vshrl.u32 %v23017_v56, 15 (stack46)
        %v22173_v12 = vor.u32 %v22172_v11, %v22171_v24 (stack47)
        %v22583_v52 = vxor.u32 %v22582_v30, %v22578_v54 (stack48)
        %v23451_v8 = vxor.u32 %v23450_v20, %v23446_v7 (stack48)
        %v128875_v23 = vadd.s32 %v157204_v29, %v157078_v48 (stack40)
        %v21416_v60 = vand.u32 2147483648, %v128843_v53 (stack72)
        %v21783_v27 = vand.u32.u16 65535, %v21782_v26 (stack52)
        %v23025_v21 = vor.u32 %v23024_v41, %v23023_v10 (stack47)
        %v128880_v46 = vadd.s32 %v157199_v44, %v157079_v39 (stack40)
        %v120612_v55 = vpop.eup %120611 (stack73)
        %v22174_v9 = vxor.u32 %v22173_v12, %v22169_v25 (stack48)
        %v22586_v54 = vadd.s32 %v22583_v52, %v22578_v54 (stack40)
        %v22588_v43 = vshll.u32 %v22583_v52, 26 (stack45)
        %v22589_v42 = vshrl.u32 %v22583_v52, 6 (stack46)
        %v21412_v22 = vmul.f32 %v120612_v55, %v128843_v53 (stack74)
        %v119858_v56 = vadd.low.f32.bf16 -1.0, %v21783_v27 (stack53)
        %v23026_v20 = vxor.u32 %v23025_v21, %v23021_v61 (stack48)
        %v23454_v7 = vadd.s32 %v23451_v8, %v23446_v7 (stack40)
        %v22177_v25 = vadd.s32 %v22174_v9, %v22169_v25 (stack40)
        %v22183_v24 = vshll.u32 %v22174_v9, 24 (stack45)
        %v22184_v11 = vshrl.u32 %v22174_v9, 8 (stack46)
        %v22590_v30 = vor.u32 %v22589_v42, %v22588_v43 (stack47)
        %v21414_v26 = vsel /*vm=*/%vm21413_vm2, /*on_true_vy=*/%v128843_v53, /*on_false_vx=*/%v21412_v22 (stack75)
        %v21792_v10 = vmul.f32 2.0, %v119858_v56 (stack54)
        %v23029_v61 = vadd.s32 %v23026_v20, %v23021_v61 (stack40)
        %v23031_v41 = vshll.u32 %v23026_v20, 29 (stack45)
        %v21405_v12 = vsel /*vm=*/%vm21368_vm0, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v21417_v52 = vsel /*vm=*/%vm21415_vm3, /*on_true_vy=*/%v21416_v60, /*on_false_vx=*/%v21414_v26 (stack76)
        %v22185_v60 = vor.u32 %v22184_v11, %v22183_v24 (stack47)
        %v22591_v27 = vxor.u32 %v22590_v30, %v22586_v54 (stack48)
        %v21420_v21 = vadd.f32 -3.0, %v21417_v52 (stack53)
        %v21796_v55 = vadd.f32 -0.99609375, %v21792_v10 (stack53)
        %v23032_v9 = vshrl.u32 %v23026_v20, 3 (stack46)
        %v23456_v43 = vshll.u32 %v23451_v8, 26 (stack45)
        %v22186_v42 = vxor.u32 %v22185_v60, %v22177_v25 (stack48)
        %v22594_v54 = vadd.s32 %v22591_v27, %v22586_v54 (stack40)
        %v22600_v22 = vshll.u32 %v22591_v27, 6 (stack45)
        %v22601_v56 = vshrl.u32 %v22591_v27, 26 (stack46)
        %v128894_v32 = vsel /*vm=*/%vm21368_vm0, /*on_true_vy=*/%v128863_v32, /*on_false_vx=*/%v21420_v21 (stack44)
        %v128896_v20 = vmax.f32 %v21796_v55, -0.99609375 (stack55)
        %v23033_v24 = vor.u32 %v23032_v9, %v23031_v41 (stack47)
        %v23457_v8 = vshrl.u32 %v23451_v8, 6 (stack46)
        %v128901_v11 = vsel /*vm=*/%vm21368_vm0, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v21428_v30 = vmul.f32 %v128894_v32, %v21405_v12 (stack54)
        %v22189_v26 = vadd.s32 %v22186_v42, %v121564_v0 (stack40)
        %v22602_v10 = vor.u32 %v22601_v56, %v22600_v22 (stack47)
        %v21401_v41 = vsel /*vm=*/%vm21368_vm0, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v21812_v12 = vxor.u32 2147483648, %v128896_v20 (stack56)
        %v22181_v25 = vadd.s32 %v22177_v25, %v121569_v1 (stack40)
        %v23034_v52 = vxor.u32 %v23033_v24, %v23029_v61 (stack48)
        %v21432_v60 = vadd.f32 %v21428_v30, %v21401_v41 (stack53)
        %v22193_v27 = vadd.s32 4, %v22189_v26 (stack40)
        %v22603_v21 = vxor.u32 %v22602_v10, %v22594_v54 (stack48)
        %v23458_v55 = vor.u32 %v23457_v8, %v23456_v43 (stack47)
        %v21389_v9 = vsel /*vm=*/%vm21368_vm0, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v21815_v43 = vmul.f32 %v21812_v12, %v128896_v20 (stack54)
        %v23037_v61 = vadd.s32 %v23034_v52, %v23029_v61 (stack40)
        %v23039_v42 = vshll.u32 %v23034_v52, 16 (stack45)
        %v21436_v22 = vmul.f32 %v21432_v60, %v128894_v32 (stack54)
        %v22197_v56 = vadd.s32 %v22193_v27, %v22181_v25 (stack40)
        %v22199_v24 = vshll.u32 %v22193_v27, 13 (stack45)
        %v22200_v8 = vshrl.u32 %v22193_v27, 19 (stack46)
        %v21393_v30 = vsel /*vm=*/%vm21368_vm0, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v21397_v26 = vsel /*vm=*/%vm21368_vm0, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v21817_v10 = vadd.f32 1.0, %v21815_v43 (stack57)
        %v22606_v41 = vadd.s32 %v22603_v21, %v121569_v1 (stack40)
        %v21440_v12 = vadd.f32 %v21436_v22, %v21397_v26 (stack53)
        %v22201_v25 = vor.u32 %v22200_v8, %v22199_v24 (stack47)
        %v23040_v52 = vshrl.u32 %v23034_v52, 16 (stack46)
        %v23459_v60 = vxor.u32 %v23458_v55, %v23454_v7 (stack48)
        %120613 = vlog2.f32 %v21817_v10 (stack58)
        %v21820_v27 = vmul.f32 -0.5, %v21815_v43 (stack59)
        %v22598_v54 = vadd.s32 %v22594_v54, %v121574_v2 (stack40)
        %v22610_v21 = vadd.s32 3, %v22606_v41 (stack40)
        %v21444_v55 = vmul.f32 %v21440_v12, %v128894_v32 (stack54)
        %v22202_v22 = vxor.u32 %v22201_v25, %v22197_v56 (stack48)
        %v23041_v42 = vor.u32 %v23040_v52, %v23039_v42 (stack47)
        %v23462_v7 = vadd.s32 %v23459_v60, %v23454_v7 (stack40)
        %vm23860_vm5 = vcmp.lt.u32.totalorder %v128855_v40, %v128826_v31 (stack43)
        %v21823_v24 = vand.u32 2147483647, %v21815_v43 (stack60)
        %v22614_v8 = vadd.s32 %v22610_v21, %v22598_v54 (stack40)
        %v22616_v26 = vshll.u32 %v22610_v21, 17 (stack45)
        %v22617_v10 = vshrl.u32 %v22610_v21, 15 (stack46)
        %v21448_v30 = vadd.f32 %v21444_v55, %v21393_v30 (stack53)
        %v22205_v56 = vadd.s32 %v22202_v22, %v22197_v56 (stack40)
        %v22207_v41 = vshll.u32 %v22202_v22, 15 (stack45)
        %v22208_v12 = vshrl.u32 %v22202_v22, 17 (stack46)
        %v21821_v25 = vadd.f32 1.0, %v21820_v27 (stack61)
        %v22618_v52 = vor.u32 %v22617_v10, %v22616_v26 (stack47)
        %v23042_v27 = vxor.u32 %v23041_v42, %v23037_v61 (stack48)
        %v23468_v54 = vshll.u32 %v23459_v60, 6 (stack45)
        %v21452_v21 = vmul.f32 %v21448_v30, %v128894_v32 (stack54)
        %v22209_v55 = vor.u32 %v22208_v12, %v22207_v41 (stack47)
        %v23469_v60 = vshrl.u32 %v23459_v60, 26 (stack46)
        %v23874_v22 = vadd.s32 1, %v128875_v23 (stack40)
        %v22619_v42 = vxor.u32 %v22618_v52, %v22614_v8 (stack48)
        %v23045_v61 = vadd.s32 %v23042_v27, %v23037_v61 (stack40)
        %v23051_v26 = vshll.u32 %v23042_v27, 24 (stack45)
        %v23052_v10 = vshrl.u32 %v23042_v27, 8 (stack46)
        %v21456_v9 = vadd.f32 %v21452_v21, %v21389_v9 (stack53)
        %v22210_v30 = vxor.u32 %v22209_v55, %v22205_v56 (stack48)
        %v23470_v41 = vor.u32 %v23469_v60, %v23468_v54 (stack47)
        %v23878_v23 = vsel /*vm=*/%vm23865_vm4, /*on_true_vy=*/%v23874_v22, /*on_false_vx=*/%v128875_v23 (stack44)
        %v22622_v8 = vadd.s32 %v22619_v42, %v22614_v8 (stack40)
        %v22624_v12 = vshll.u32 %v22619_v42, 29 (stack45)
        %v22625_v52 = vshrl.u32 %v22619_v42, 3 (stack46)
        %v128934_v27 = vadd.s32 %v128855_v40, %v121569_v1 (stack40)
        %v21460_v54 = vmul.f32 %v21456_v9, %v128894_v32 (stack54)
        %v22213_v56 = vadd.s32 %v22210_v30, %v22205_v56 (stack40)
        %v22215_v21 = vshll.u32 %v22210_v30, 26 (stack45)
        %v22216_v55 = vshrl.u32 %v22210_v30, 6 (stack46)
        %v22626_v60 = vor.u32 %v22625_v52, %v22624_v12 (stack47)
        %v23053_v22 = vor.u32 %v23052_v10, %v23051_v26 (stack47)
        %v23471_v42 = vxor.u32 %v23470_v41, %v23462_v7 (stack48)
        %v23882_v26 = vadd.s32 1, %v23878_v23 (stack40)
        %v21464_v11 = vadd.f32 %v21460_v54, %v128901_v11 (stack53)
        %v21822_v43 = vmul.f32 %v21821_v25, %v21815_v43 (stack63)
        %vm128938_vm6 = vcmp.lt.f32.partialorder %v21823_v24, 0.0004427343 (stack62)
        %v22217_v25 = vor.u32 %v22216_v55, %v22215_v21 (stack47)
        %v22627_v10 = vxor.u32 %v22626_v60, %v22622_v8 (stack48)
        %v23054_v9 = vxor.u32 %v23053_v22, %v23045_v61 (stack48)
        %v23474_v30 = vadd.s32 %v23471_v42, %v121564_v0 (stack40)
        %v23886_v31 = vsel /*vm=*/%vm23860_vm5, /*on_true_vy=*/%v23882_v26, /*on_false_vx=*/%v23878_v23 (stack44)
        %v120614_v40 = vpop.eup %120613 (stack64)
        %v21468_v41 = vmul.f32 %v21464_v11, %v128894_v32 (stack54)
        %v22218_v23 = vxor.u32 %v22217_v25, %v22213_v56 (stack48)
        %v23466_v7 = vadd.s32 %v23462_v7, %v121569_v1 (stack40)
        %v23901_v12 = vshll.u32 %v128934_v27, 13 (stack45)
        %v21819_v52 = vmul.f32 0.6931472, %v120614_v40 (stack65)
        %v22630_v8 = vadd.s32 %v22627_v10, %v22622_v8 (stack40)
        %v22632_v54 = vshll.u32 %v22627_v10, 16 (stack45)
        %v22633_v21 = vshrl.u32 %v22627_v10, 16 (stack46)
        %v21472_v50 = vadd.f32 %v21468_v41, %v128860_v50 (stack53)
        %v22221_v56 = vadd.s32 %v22218_v23, %v22213_v56 (stack40)
        %v22227_v55 = vshll.u32 %v22218_v23, 6 (stack45)
        %v22228_v60 = vshrl.u32 %v22218_v23, 26 (stack46)
        %v21825_v22 = vsel /*vm=*/%vm128938_vm6, /*on_true_vy=*/%v21822_v43, /*on_false_vx=*/%v21819_v52 (stack66)
        %v22634_v42 = vor.u32 %v22633_v21, %v22632_v54 (stack47)
        %v23478_v26 = vadd.s32 1, %v23474_v30 (stack40)
        %v23902_v11 = vshrl.u32 %v128934_v27, 19 (stack46)
        %v21476_v43 = vmul.f32 %v21472_v50, %v128894_v32 (stack54)
        %v128954_v24 = vxor.u32 2147483648, %v21825_v22 (stack56)
        %v22229_v25 = vor.u32 %v22228_v60, %v22227_v55 (stack47)
        %v23057_v10 = vadd.s32 %v23054_v9, %v121574_v2 (stack40)
        %v21349_v9 = vmul.f32 inf, %v128785_v34 (stack54)
        %v21377_v30 = vsel /*vm=*/%vm21368_vm0, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v22635_v40 = vxor.u32 %v22634_v42, %v22630_v8 (stack48)
        %v23482_v41 = vadd.s32 %v23478_v26, %v23466_v7 (stack40)
        %vm128963_vm7 = vcmp.eq.f32.partialorder %v21341_v6, 1.0 (stack68)
        %v21480_v23 = vadd.f32 %v21476_v43, %v21377_v30 (stack53)
        %vm21829_vm8 = vcmp.lt.f32.partialorder %v128954_v24, 5.0 (stack68)
        %120615 = vrsqrt.f32 %v128954_v24 (stack67)
        %v21373_v53 = vsel /*vm=*/%vm21368_vm0, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v22230_v7 = vxor.u32 %v22229_v25, %v22221_v56 (stack48)
        %v23049_v61 = vadd.s32 %v23045_v61, %v121564_v0 (stack40)
        %v23891_v31 = vadd.s32 %v23886_v31, %v121574_v2 (stack40)
        %v21484_v32 = vmul.f32 %v21480_v23, %v128894_v32 (stack54)
        %v22225_v52 = vadd.s32 %v22221_v56, %v121564_v0 (stack40)
        %v23061_v54 = vadd.s32 2, %v23057_v10 (stack40)
        %v23903_v12 = vor.u32 %v23902_v11, %v23901_v12 (stack47)
        %v128979_v21 = vsel /*vm=*/%vm21829_vm8, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v128982_v50 = vadd.f32 -2.5, %v128954_v24 (stack53)
        %v22233_v56 = vadd.s32 %v22230_v7, %v121574_v2 (stack40)
        %v23484_v55 = vshll.u32 %v23478_v26, 17 (stack45)
        %v21488_v60 = vadd.f32 %v21484_v32, %v21373_v53 (stack53)
        %v128988_v22 = vsel /*vm=*/%vm21829_vm8, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v128993_v42 = vsel /*vm=*/%vm21829_vm8, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v128998_v11 = vsel /*vm=*/%vm21829_vm8, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v22237_v43 = vadd.s32 5, %v22233_v56 (stack40)
        %v22638_v8 = vadd.s32 %v22635_v40, %v22630_v8 (stack40)
        %v22644_v25 = vshll.u32 %v22635_v40, 24 (stack45)
        %v22645_v10 = vshrl.u32 %v22635_v40, 8 (stack46)
        %v21492_v34 = vmul.f32 %v21488_v60, %v128785_v34 (stack54)
        %v23065_v30 = vadd.s32 %v23061_v54, %v23049_v61 (stack40)
        %v23067_v40 = vshll.u32 %v23061_v54, 13 (stack45)
        %v23068_v23 = vshrl.u32 %v23061_v54, 19 (stack46)
        %vm21874_vm9 = vcmp.eq.f32.partialorder %v128954_v24, inf (stack70)
        %v22239_v53 = vxor.u32 %v22237_v43, %v22225_v52 (stack48)
        %v22646_v7 = vor.u32 %v22645_v10, %v22644_v25 (stack47)
        %v23485_v26 = vshrl.u32 %v23478_v26, 15 (stack46)
        %v21496_v9 = vsel /*vm=*/%vm128963_vm7, /*on_true_vy=*/%v21349_v9, /*on_false_vx=*/%v21492_v34 (stack44)
        %vm21876_vm10 = vcmp.eq.f32.partialorder %v128954_v24, 0.0 (stack71)
        %v21877_v6 = vand.u32 2147483648, %v128954_v24 (stack72)
        %v23069_v61 = vor.u32 %v23068_v23, %v23067_v40 (stack47)
        %v23899_v27 = vadd.s32 %v128934_v27, %v23891_v31 (stack40)
        %v21500_v31 = vmul.f32 1.4140625, %v21496_v9 (stack54)
        %v22240_v32 = vand.u32.u8 255, %v22239_v53 (stack49)
        %v22647_v52 = vxor.u32 %v22646_v7, %v22638_v8 (stack48)
        %v23486_v54 = vor.u32 %v23485_v26, %v23484_v55 (stack47)
        %v22642_v56 = vadd.s32 %v22638_v8, %v121569_v1 (stack40)
        %v23070_v55 = vxor.u32 %v23069_v61, %v23065_v30 (stack48)
        %v23904_v12 = vxor.u32 %v23903_v12, %v23899_v27 (stack48)
        %vm24326_vm11 = vcmp.lt.u32.totalorder %v128880_v46, %v157079_v39 (stack43)
        %v21503_v60 = vpack.c.bf16 %v156663_v45, %v21500_v31 (stack81)
        %v22241_v43 = vand.u32 65535, %v22240_v32 (stack50)
        %v22650_v8 = vadd.s32 %v22647_v52, %v121564_v0 (stack40)
        %v23487_v25 = vxor.u32 %v23486_v54, %v23482_v41 (stack48)
        %v23073_v10 = vadd.s32 %v23070_v55, %v23065_v30 (stack40)
        %v23075_v34 = vshll.u32 %v23070_v55, 15 (stack45)
        %v23076_v30 = vshrl.u32 %v23070_v55, 17 (stack46)
        %v23907_v40 = vadd.s32 %v23904_v12, %v23899_v27 (stack40)
        %v120616_v23 = vpop.eup %120615 (stack73)
        %119857 = vst [vmem:[%s123356_s30 + $0x214] sm:$0xf] /*vst_source=*/%v21503_v60 (stack83)
        %v22242_v53 = vshrl.u32 %v22241_v43, 1 (stack51)
        %v22654_v7 = vadd.s32 4, %v22650_v8 (stack40)
        %v23490_v41 = vadd.s32 %v23487_v25, %v23482_v41 (stack40)
        %v23492_v26 = vshll.u32 %v23487_v25, 29 (stack45)
        %v21873_v9 = vmul.f32 %v120616_v23, %v128954_v24 (stack74)
        %v23077_v61 = vor.u32 %v23076_v30, %v23075_v34 (stack47)
        %v23493_v27 = vshrl.u32 %v23487_v25, 3 (stack46)
        %v23909_v31 = vshll.u32 %v23904_v12, 15 (stack45)
        %v22243_v32 = vor.u32 16256, %v22242_v53 (stack47)
        %v22658_v52 = vadd.s32 %v22654_v7, %v22642_v56 (stack40)
        %v22660_v54 = vshll.u32 %v22654_v7, 13 (stack45)
        %v22661_v56 = vshrl.u32 %v22654_v7, 19 (stack46)
        %v21875_v55 = vsel /*vm=*/%vm21874_vm9, /*on_true_vy=*/%v128954_v24, /*on_false_vx=*/%v21873_v9 (stack75)
        %v23078_v60 = vxor.u32 %v23077_v61, %v23073_v10 (stack48)
        %v23494_v43 = vor.u32 %v23493_v27, %v23492_v26 (stack47)
        %v23910_v12 = vshrl.u32 %v23904_v12, 17 (stack46)
        %v21878_v6 = vsel /*vm=*/%vm21876_vm10, /*on_true_vy=*/%v21877_v6, /*on_false_vx=*/%v21875_v55 (stack76)
        %v22244_v8 = vand.u32.u16 65535, %v22243_v32 (stack52)
        %v22662_v25 = vor.u32 %v22661_v56, %v22660_v54 (stack47)
        %v24331_v34 = vadd.s32 %v157204_v29, %v157082_v49 (stack40)
        %v21881_v30 = vadd.f32 -3.0, %v21878_v6 (stack53)
        %v23081_v10 = vadd.s32 %v23078_v60, %v23073_v10 (stack40)
        %v23083_v23 = vshll.u32 %v23078_v60, 26 (stack45)
        %v23084_v53 = vshrl.u32 %v23078_v60, 6 (stack46)
        %v119860_v7 = vadd.low.f32.bf16 -1.0, %v22244_v8 (stack53)
        %v22663_v26 = vxor.u32 %v22662_v25, %v22658_v52 (stack48)
        %v23495_v9 = vxor.u32 %v23494_v43, %v23490_v41 (stack48)
        %v23911_v61 = vor.u32 %v23910_v12, %v23909_v31 (stack47)
        %v21866_v27 = vsel /*vm=*/%vm21829_vm8, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v129027_v50 = vsel /*vm=*/%vm21829_vm8, /*on_true_vy=*/%v128982_v50, /*on_false_vx=*/%v21881_v30 (stack44)
        %v23085_v31 = vor.u32 %v23084_v53, %v23083_v23 (stack47)
        %v129031_v32 = vadd.s32 %v128880_v46, %v122657_v58 (stack40)
        %v21889_v54 = vmul.f32 %v129027_v50, %v21866_v27 (stack54)
        %v22253_v56 = vmul.f32 2.0, %v119860_v7 (stack54)
        %v22666_v52 = vadd.s32 %v22663_v26, %v22658_v52 (stack40)
        %v22668_v55 = vshll.u32 %v22663_v26, 15 (stack45)
        %v22669_v60 = vshrl.u32 %v22663_v26, 17 (stack46)
        %v23086_v43 = vxor.u32 %v23085_v31, %v23081_v10 (stack48)
        %v23498_v41 = vadd.s32 %v23495_v9, %v23490_v41 (stack40)
        %v23500_v12 = vshll.u32 %v23495_v9, 16 (stack45)
        %v21893_v11 = vadd.f32 %v21889_v54, %v128998_v11 (stack53)
        %v22257_v6 = vadd.f32 -0.99609375, %v22253_v56 (stack53)
        %v23501_v8 = vshrl.u32 %v23495_v9, 16 (stack46)
        %v23912_v25 = vxor.u32 %v23911_v61, %v23907_v40 (stack48)
        %v22670_v30 = vor.u32 %v22669_v60, %v22668_v55 (stack47)
        %v23089_v10 = vadd.s32 %v23086_v43, %v23081_v10 (stack40)
        %v23095_v23 = vshll.u32 %v23086_v43, 6 (stack45)
        %v23096_v53 = vshrl.u32 %v23086_v43, 26 (stack46)
        %v21897_v7 = vmul.f32 %v21893_v11, %v129027_v50 (stack54)
        %v129036_v26 = vmax.f32 %v22257_v6, -0.99609375 (stack55)
        %v23502_v9 = vor.u32 %v23501_v8, %v23500_v12 (stack47)
        %v129038_v40 = vadd.s32 %v23912_v25, %v23907_v40 (stack40)
        %v21850_v61 = vsel /*vm=*/%vm21829_vm8, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v21858_v27 = vsel /*vm=*/%vm21829_vm8, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v22671_v31 = vxor.u32 %v22670_v30, %v22666_v52 (stack48)
        %v23097_v54 = vor.u32 %v23096_v53, %v23095_v23 (stack47)
        %v21854_v56 = vsel /*vm=*/%vm21829_vm8, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v21901_v55 = vadd.f32 %v21897_v7, %v21858_v27 (stack53)
        %v22273_v60 = vxor.u32 2147483648, %v129036_v26 (stack56)
        %v24335_v43 = vadd.s32 1, %v24331_v34 (stack40)
        %v22674_v52 = vadd.s32 %v22671_v31, %v22666_v52 (stack40)
        %v22676_v12 = vshll.u32 %v22671_v31, 26 (stack45)
        %v22677_v11 = vshrl.u32 %v22671_v31, 6 (stack46)
        %v23098_v6 = vxor.u32 %v23097_v54, %v23089_v10 (stack48)
        %vm24321_vm12 = vcmp.lt.u32.totalorder %v129031_v32, %v128880_v46 (stack43)
        %v21905_v8 = vmul.f32 %v21901_v55, %v129027_v50 (stack54)
        %v22276_v30 = vmul.f32 %v22273_v60, %v129036_v26 (stack54)
        %v23503_v23 = vxor.u32 %v23502_v9, %v23498_v41 (stack48)
        %v24356_v53 = vadd.s32 %v129031_v32, %v121569_v1 (stack40)
        %v22678_v7 = vor.u32 %v22677_v11, %v22676_v12 (stack47)
        %v23093_v10 = vadd.s32 %v23089_v10, %v121574_v2 (stack40)
        %v23101_v9 = vadd.s32 %v23098_v6, %v121569_v1 (stack40)
        %v24339_v34 = vsel /*vm=*/%vm24326_vm11, /*on_true_vy=*/%v24335_v43, /*on_false_vx=*/%v24331_v34 (stack44)
        %v21909_v27 = vadd.f32 %v21905_v8, %v21854_v56 (stack53)
        %v22278_v31 = vadd.f32 1.0, %v22276_v30 (stack57)
        %v22281_v54 = vmul.f32 -0.5, %v22276_v30 (stack59)
        %v23917_v56 = vshll.u32 %v23912_v25, 26 (stack45)
        %v22679_v55 = vxor.u32 %v22678_v7, %v22674_v52 (stack48)
        %v23105_v60 = vadd.s32 3, %v23101_v9 (stack40)
        %v23506_v41 = vadd.s32 %v23503_v23, %v23498_v41 (stack40)
        %v23918_v25 = vshrl.u32 %v23912_v25, 6 (stack46)
        %v21913_v43 = vmul.f32 %v21909_v27, %v129027_v50 (stack54)
        %120617 = vlog2.f32 %v22278_v31 (stack58)
        %v22282_v12 = vadd.f32 1.0, %v22281_v54 (stack61)
        %v23512_v11 = vshll.u32 %v23503_v23, 24 (stack45)
        %v22682_v52 = vadd.s32 %v22679_v55, %v22674_v52 (stack40)
        %v22688_v6 = vshll.u32 %v22679_v55, 6 (stack45)
        %v22689_v8 = vshrl.u32 %v22679_v55, 26 (stack46)
        %v23109_v7 = vadd.s32 %v23105_v60, %v23093_v10 (stack40)
        %v21917_v61 = vadd.f32 %v21913_v43, %v21850_v61 (stack53)
        %v22284_v10 = vand.u32 2147483647, %v22276_v30 (stack60)
        %v23111_v9 = vshll.u32 %v23105_v60, 17 (stack45)
        %v23112_v27 = vshrl.u32 %v23105_v60, 15 (stack46)
        %v22283_v30 = vmul.f32 %v22282_v12, %v22276_v30 (stack63)
        %v22686_v31 = vadd.s32 %v22682_v52, %v121564_v0 (stack40)
        %v22690_v54 = vor.u32 %v22689_v8, %v22688_v6 (stack47)
        %v23513_v23 = vshrl.u32 %v23503_v23, 8 (stack46)
        %v21921_v55 = vmul.f32 %v21917_v61, %v129027_v50 (stack54)
        %v23113_v60 = vor.u32 %v23112_v27, %v23111_v9 (stack47)
        %v23919_v56 = vor.u32 %v23918_v25, %v23917_v56 (stack47)
        %v24343_v25 = vadd.s32 1, %v24339_v34 (stack40)
        %v22691_v43 = vxor.u32 %v22690_v54, %v22682_v52 (stack48)
        %v23514_v12 = vor.u32 %v23513_v23, %v23512_v11 (stack47)
        %v24362_v11 = vshll.u32 %v24356_v53, 13 (stack45)
        %v24363_v52 = vshrl.u32 %v24356_v53, 19 (stack46)
        %v21925_v42 = vadd.f32 %v21921_v55, %v128993_v42 (stack53)
        %v23114_v6 = vxor.u32 %v23113_v60, %v23109_v7 (stack48)
        %v23920_v8 = vxor.u32 %v23919_v56, %v129038_v40 (stack48)
        %v24347_v46 = vsel /*vm=*/%vm24321_vm12, /*on_true_vy=*/%v24343_v25, /*on_false_vx=*/%v24339_v34 (stack44)
        %vm129069_vm13 = vcmp.lt.f32.partialorder %v22284_v10, 0.0004427343 (stack62)
        %v22694_v34 = vadd.s32 %v22691_v43, %v121574_v2 (stack40)
        %v23515_v61 = vxor.u32 %v23514_v12, %v23506_v41 (stack48)
        %v24352_v10 = vadd.s32 %v24347_v46, %v121574_v2 (stack40)
        %v24364_v9 = vor.u32 %v24363_v52, %v24362_v11 (stack47)
        %v21929_v27 = vmul.f32 %v21925_v42, %v129027_v50 (stack54)
        %v23117_v7 = vadd.s32 %v23114_v6, %v23109_v7 (stack40)
        %v23119_v54 = vshll.u32 %v23114_v6, 29 (stack45)
        %v23120_v23 = vshrl.u32 %v23114_v6, 3 (stack46)
        %v22698_v55 = vadd.s32 5, %v22694_v34 (stack40)
        %v23518_v60 = vadd.s32 %v23515_v61, %v121574_v2 (stack40)
        %v23923_v40 = vadd.s32 %v23920_v8, %v129038_v40 (stack40)
        %v23929_v56 = vshll.u32 %v23920_v8, 6 (stack45)
        %v21933_v22 = vadd.f32 %v21929_v27, %v128988_v22 (stack53)
        %v23121_v25 = vor.u32 %v23120_v23, %v23119_v54 (stack47)
        %v23930_v43 = vshrl.u32 %v23920_v8, 26 (stack46)
        %v24360_v53 = vadd.s32 %v24356_v53, %v24352_v10 (stack40)
        %v22700_v31 = vxor.u32 %v22698_v55, %v22686_v31 (stack48)
        %v23510_v41 = vadd.s32 %v23506_v41, %v121564_v0 (stack40)
        %v23522_v12 = vadd.s32 2, %v23518_v60 (stack40)
        %v129082_v11 = vadd.s32 %v157199_v44, %v157083_v59 (stack40)
        %v21937_v52 = vmul.f32 %v21933_v22, %v129027_v50 (stack54)
        %v23122_v42 = vxor.u32 %v23121_v25, %v23117_v7 (stack48)
        %v23931_v6 = vor.u32 %v23930_v43, %v23929_v56 (stack47)
        %v24365_v8 = vxor.u32 %v24364_v9, %v24360_v53 (stack48)
        %v120618_v46 = vpop.eup %120617 (stack64)
        %v22701_v34 = vand.u32.u8 255, %v22700_v31 (stack49)
        %v23526_v61 = vadd.s32 %v23522_v12, %v23510_v41 (stack40)
        %v23528_v10 = vshll.u32 %v23522_v12, 13 (stack45)
        %v23529_v9 = vshrl.u32 %v23522_v12, 19 (stack46)
        %v21941_v21 = vadd.f32 %v21937_v52, %v128979_v21 (stack53)
        %v22280_v27 = vmul.f32 0.6931472, %v120618_v46 (stack65)
        %v23125_v7 = vadd.s32 %v23122_v42, %v23117_v7 (stack40)
        %v23127_v54 = vshll.u32 %v23122_v42, 16 (stack45)
        %v22702_v23 = vand.u32 65535, %v22701_v34 (stack50)
        %v23128_v55 = vshrl.u32 %v23122_v42, 16 (stack46)
        %v23530_v60 = vor.u32 %v23529_v9, %v23528_v10 (stack47)
        %v23932_v56 = vxor.u32 %v23931_v6, %v23923_v40 (stack48)
        %v21802_v22 = vand.u32 2147483647, %v128896_v20 (stack77)
        %v21945_v50 = vmul.f32 %v21941_v21, %v129027_v50 (stack54)
        %v22286_v30 = vsel /*vm=*/%vm129069_vm13, /*on_true_vy=*/%v22283_v30, /*on_false_vx=*/%v22280_v27 (stack66)
        %v24368_v32 = vadd.s32 %v24365_v8, %v24360_v53 (stack40)
        %v21834_v24 = vsel /*vm=*/%vm21829_vm8, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v129093_v25 = vxor.u32 2147483648, %v22286_v30 (stack56)
        %v23129_v43 = vor.u32 %v23128_v55, %v23127_v54 (stack47)
        %v23531_v53 = vxor.u32 %v23530_v60, %v23526_v61 (stack48)
        %v21949_v31 = vadd.f32 %v21945_v50, %v21834_v24 (stack53)
        %120619 = vrsqrt.f32 %v129093_v25 (stack67)
        %v22703_v41 = vshrl.u32 %v22702_v23, 1 (stack51)
        %vm21805_vm14 = vcmp.eq.f32.partialorder %v21802_v22, 1.0 (stack68)
        %v21810_v12 = vmul.f32 inf, %v128896_v20 (stack54)
        %v21953_v20 = vmul.f32 %v21949_v31, %v128896_v20 (stack54)
        %v22263_v52 = vand.u32 2147483647, %v129036_v26 (stack77)
        %v129100_v42 = vmul.f32 inf, %v129036_v26 (stack54)
        %v23130_v6 = vxor.u32 %v23129_v43, %v23125_v7 (stack48)
        %v23927_v40 = vadd.s32 %v23923_v40, %v121569_v1 (stack40)
        %v21957_v46 = vsel /*vm=*/%vm21805_vm14, /*on_true_vy=*/%v21810_v12, /*on_false_vx=*/%v21953_v20 (stack44)
        %v23935_v34 = vadd.s32 %v23932_v56, %v121564_v0 (stack40)
        %v24370_v10 = vshll.u32 %v24365_v8, 15 (stack45)
        %v24371_v8 = vshrl.u32 %v24365_v8, 17 (stack46)
        %v21961_v9 = vmul.f32 1.4140625, %v21957_v46 (stack54)
        %vm22290_vm15 = vcmp.lt.f32.partialorder %v129093_v25, 5.0 (stack68)
        %v22704_v21 = vor.u32 16256, %v22703_v41 (stack47)
        %v129107_v27 = vadd.s32 %v129082_v11, %v122657_v58 (stack40)
        %v23133_v7 = vadd.s32 %v23130_v6, %v23125_v7 (stack40)
        %v23139_v54 = vshll.u32 %v23130_v6, 24 (stack45)
        %v23140_v23 = vshrl.u32 %v23130_v6, 8 (stack46)
        %v23534_v61 = vadd.s32 %v23531_v53, %v23526_v61 (stack40)
        %v21964_v55 = vpack.c.bf16 %v156663_v45, %v21961_v9 (stack81)
        %v22705_v60 = vand.u32.u16 65535, %v22704_v21 (stack52)
        %v23536_v56 = vshll.u32 %v23531_v53, 15 (stack45)
        %v23537_v22 = vshrl.u32 %v23531_v53, 17 (stack46)
        %v22331_v50 = vadd.f32 -2.5, %v129093_v25 (stack53)
        %v23141_v30 = vor.u32 %v23140_v23, %v23139_v54 (stack47)
        %v23939_v24 = vadd.s32 1, %v23935_v34 (stack40)
        %v24372_v43 = vor.u32 %v24371_v8, %v24370_v10 (stack47)
        %119859 = vst [vmem:[%s123356_s30 + $0x294] sm:$0xf] /*vst_source=*/%v21964_v55 (stack83)
        %vm22335_vm0 = vcmp.eq.f32.partialorder %v129093_v25, inf (stack70)
        %v119862_v53 = vadd.low.f32.bf16 -1.0, %v22705_v60 (stack53)
        %v23538_v31 = vor.u32 %v23537_v22, %v23536_v56 (stack47)
        %vm24787_vm1 = vcmp.lt.u32.totalorder %v129082_v11, %v157083_v59 (stack43)
        %v23142_v41 = vxor.u32 %v23141_v30, %v23133_v7 (stack48)
        %v23943_v12 = vadd.s32 %v23939_v24, %v23927_v40 (stack40)
        %v23945_v20 = vshll.u32 %v23939_v24, 17 (stack45)
        %v23946_v6 = vshrl.u32 %v23939_v24, 15 (stack46)
        %v22714_v40 = vmul.f32 2.0, %v119862_v53 (stack54)
        %v23539_v46 = vxor.u32 %v23538_v31, %v23534_v61 (stack48)
        %v24373_v34 = vxor.u32 %v24372_v43, %v24368_v32 (stack48)
        %v129117_v10 = vadd.s32 %v157204_v29, %v157084_v16 (stack40)
        %v129122_v8 = vsel /*vm=*/%vm22290_vm15, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v23145_v9 = vadd.s32 %v23142_v41, %v121564_v0 (stack40)
        %v23947_v21 = vor.u32 %v23946_v6, %v23945_v20 (stack47)
        %v129127_v54 = vadd.s32 %v157199_v44, %v157089_v17 (stack40)
        %v22718_v23 = vadd.f32 -0.99609375, %v22714_v40 (stack53)
        %v23542_v61 = vadd.s32 %v23539_v46, %v23534_v61 (stack40)
        %v23544_v55 = vshll.u32 %v23539_v46, 26 (stack45)
        %v23545_v60 = vshrl.u32 %v23539_v46, 6 (stack46)
        %v120620_v56 = vpop.eup %120619 (stack73)
        %v23137_v7 = vadd.s32 %v23133_v7, %v121569_v1 (stack40)
        %v23149_v22 = vadd.s32 4, %v23145_v9 (stack40)
        %v23948_v30 = vxor.u32 %v23947_v21, %v23943_v12 (stack48)
        %v129130_v32 = vadd.s32 %v24373_v34, %v24368_v32 (stack40)
        %v22334_v24 = vmul.f32 %v120620_v56, %v129093_v25 (stack74)
        %v22338_v43 = vand.u32 2147483648, %v129093_v25 (stack72)
        %v129134_v53 = vmax.f32 %v22718_v23, -0.99609375 (stack55)
        %v23546_v31 = vor.u32 %v23545_v60, %v23544_v55 (stack47)
        %v23153_v41 = vadd.s32 %v23149_v22, %v23137_v7 (stack40)
        %v23155_v20 = vshll.u32 %v23149_v22, 13 (stack45)
        %v23156_v6 = vshrl.u32 %v23149_v22, 19 (stack46)
        %v23951_v12 = vadd.s32 %v23948_v30, %v23943_v12 (stack40)
        %v129139_v40 = vsel /*vm=*/%vm22290_vm15, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v22336_v46 = vsel /*vm=*/%vm22335_vm0, /*on_true_vy=*/%v129093_v25, /*on_false_vx=*/%v22334_v24 (stack75)
        %vm22337_vm2 = vcmp.eq.f32.partialorder %v129093_v25, 0.0 (stack71)
        %v22734_v9 = vxor.u32 2147483648, %v129134_v53 (stack56)
        %v22327_v21 = vsel /*vm=*/%vm22290_vm15, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v22339_v23 = vsel /*vm=*/%vm22337_vm2, /*on_true_vy=*/%v22338_v43, /*on_false_vx=*/%v22336_v46 (stack76)
        %v23157_v55 = vor.u32 %v23156_v6, %v23155_v20 (stack47)
        %v23547_v60 = vxor.u32 %v23546_v31, %v23542_v61 (stack48)
        %v22342_v56 = vadd.f32 -3.0, %v22339_v23 (stack53)
        %v129150_v7 = vmul.f32 %v22734_v9, %v129134_v53 (stack54)
        %v23953_v22 = vshll.u32 %v23948_v30, 29 (stack45)
        %v23954_v30 = vshrl.u32 %v23948_v30, 3 (stack46)
        %v23158_v24 = vxor.u32 %v23157_v55, %v23153_v41 (stack48)
        %v23550_v61 = vadd.s32 %v23547_v60, %v23542_v61 (stack40)
        %v23556_v43 = vshll.u32 %v23547_v60, 6 (stack45)
        %v23557_v31 = vshrl.u32 %v23547_v60, 26 (stack46)
        %v129154_v50 = vsel /*vm=*/%vm22290_vm15, /*on_true_vy=*/%v22331_v50, /*on_false_vx=*/%v22342_v56 (stack44)
        %v22739_v20 = vadd.f32 1.0, %v129150_v7 (stack57)
        %v24378_v6 = vshll.u32 %v24373_v34, 26 (stack45)
        %v24379_v34 = vshrl.u32 %v24373_v34, 6 (stack46)
        %v22350_v46 = vmul.f32 %v129154_v50, %v22327_v21 (stack54)
        %v23161_v41 = vadd.s32 %v23158_v24, %v23153_v41 (stack40)
        %v23163_v9 = vshll.u32 %v23158_v24, 15 (stack45)
        %v23164_v21 = vshrl.u32 %v23158_v24, 17 (stack46)
        %v22315_v23 = vsel /*vm=*/%vm22290_vm15, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v22323_v55 = vsel /*vm=*/%vm22290_vm15, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %120621 = vlog2.f32 %v22739_v20 (stack58)
        %v22742_v60 = vmul.f32 -0.5, %v129150_v7 (stack59)
        %v22354_v56 = vadd.f32 %v22350_v46, %v22323_v55 (stack53)
        %v23165_v24 = vor.u32 %v23164_v21, %v23163_v9 (stack47)
        %v23558_v43 = vor.u32 %v23557_v31, %v23556_v43 (stack47)
        %v23955_v22 = vor.u32 %v23954_v30, %v23953_v22 (stack47)
        %v22319_v30 = vsel /*vm=*/%vm22290_vm15, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v22745_v31 = vand.u32 2147483647, %v129150_v7 (stack60)
        %v24380_v20 = vor.u32 %v24379_v34, %v24378_v6 (stack47)
        %v24796_v6 = vadd.s32 1, %v129117_v10 (stack40)
        %v22358_v34 = vmul.f32 %v22354_v56, %v129154_v50 (stack54)
        %v23166_v46 = vxor.u32 %v23165_v24, %v23161_v41 (stack48)
        %v23559_v9 = vxor.u32 %v23558_v43, %v23550_v61 (stack48)
        %v23956_v21 = vxor.u32 %v23955_v22, %v23951_v12 (stack48)
        %v22743_v55 = vadd.f32 1.0, %v22742_v60 (stack61)
        %v24381_v60 = vxor.u32 %v24380_v20, %v129130_v32 (stack48)
        %vm24782_vm3 = vcmp.lt.u32.totalorder %v129107_v27, %v129082_v11 (stack43)
        %v24800_v10 = vsel /*vm=*/%vm24787_vm1, /*on_true_vy=*/%v24796_v6, /*on_false_vx=*/%v129117_v10 (stack44)
        %v129180_v56 = vadd.s32 %v129107_v27, %v121569_v1 (stack40)
        %v22362_v24 = vadd.f32 %v22358_v34, %v22319_v30 (stack53)
        %v23169_v41 = vadd.s32 %v23166_v46, %v23161_v41 (stack40)
        %v23171_v43 = vshll.u32 %v23166_v46, 26 (stack45)
        %v23172_v22 = vshrl.u32 %v23166_v46, 6 (stack46)
        %v23562_v30 = vadd.s32 %v23559_v9, %v121569_v1 (stack40)
        %v23959_v12 = vadd.s32 %v23956_v21, %v23951_v12 (stack40)
        %v23961_v20 = vshll.u32 %v23956_v21, 16 (stack45)
        %v23962_v6 = vshrl.u32 %v23956_v21, 16 (stack46)
        %v22366_v34 = vmul.f32 %v22362_v24, %v129154_v50 (stack54)
        %vm129184_vm4 = vcmp.lt.f32.partialorder %v22745_v31, 0.0004427343 (stack62)
        %v23173_v46 = vor.u32 %v23172_v22, %v23171_v43 (stack47)
        %v24384_v32 = vadd.s32 %v24381_v60, %v129130_v32 (stack40)
        %v23554_v61 = vadd.s32 %v23550_v61, %v121574_v2 (stack40)
        %v23566_v9 = vadd.s32 3, %v23562_v30 (stack40)
        %v23963_v21 = vor.u32 %v23962_v6, %v23961_v20 (stack47)
        %v24390_v24 = vshll.u32 %v24381_v60, 6 (stack45)
        %v22370_v23 = vadd.f32 %v22366_v34, %v22315_v23 (stack53)
        %v23174_v43 = vxor.u32 %v23173_v46, %v23169_v41 (stack48)
        %v24391_v60 = vshrl.u32 %v24381_v60, 26 (stack46)
        %v24804_v22 = vadd.s32 1, %v24800_v10 (stack40)
        %v23570_v30 = vadd.s32 %v23566_v9, %v23554_v61 (stack40)
        %v23572_v20 = vshll.u32 %v23566_v9, 17 (stack45)
        %v23573_v6 = vshrl.u32 %v23566_v9, 15 (stack46)
        %v23964_v34 = vxor.u32 %v23963_v21, %v23959_v12 (stack48)
        %v22374_v46 = vmul.f32 %v22370_v23, %v129154_v50 (stack54)
        %v23177_v41 = vadd.s32 %v23174_v43, %v23169_v41 (stack40)
        %v23183_v61 = vshll.u32 %v23174_v43, 6 (stack45)
        %v23184_v9 = vshrl.u32 %v23174_v43, 26 (stack46)
        %v23574_v21 = vor.u32 %v23573_v6, %v23572_v20 (stack47)
        %v23967_v12 = vadd.s32 %v23964_v34, %v23959_v12 (stack40)
        %v23973_v23 = vshll.u32 %v23964_v34, 24 (stack45)
        %v23974_v43 = vshrl.u32 %v23964_v34, 8 (stack46)
        %v120622_v20 = vpop.eup %120621 (stack64)
        %v22378_v40 = vadd.f32 %v22374_v46, %v129139_v40 (stack53)
        %v22744_v7 = vmul.f32 %v22743_v55, %v129150_v7 (stack63)
        %v23185_v55 = vor.u32 %v23184_v9, %v23183_v61 (stack47)
        %v24392_v24 = vor.u32 %v24391_v60, %v24390_v24 (stack47)
        %v22741_v60 = vmul.f32 0.6931472, %v120622_v20 (stack65)
        %v23575_v6 = vxor.u32 %v23574_v21, %v23570_v30 (stack48)
        %v23975_v34 = vor.u32 %v23974_v43, %v23973_v23 (stack47)
        %v24823_v46 = vshll.u32 %v129180_v56, 13 (stack45)
        %v22382_v61 = vmul.f32 %v22378_v40, %v129154_v50 (stack54)
        %v23186_v9 = vxor.u32 %v23185_v55, %v23177_v41 (stack48)
        %v24393_v21 = vxor.u32 %v24392_v24, %v24384_v32 (stack48)
        %v24808_v11 = vsel /*vm=*/%vm24782_vm3, /*on_true_vy=*/%v24804_v22, /*on_false_vx=*/%v24800_v10 (stack44)
        %v22747_v27 = vsel /*vm=*/%vm129184_vm4, /*on_true_vy=*/%v22744_v7, /*on_false_vx=*/%v22741_v60 (stack66)
        %v23578_v10 = vadd.s32 %v23575_v6, %v23570_v30 (stack40)
        %v23580_v31 = vshll.u32 %v23575_v6, 29 (stack45)
        %v23581_v22 = vshrl.u32 %v23575_v6, 3 (stack46)
        %v22386_v8 = vadd.f32 %v22382_v61, %v129122_v8 (stack53)
        %v129201_v30 = vxor.u32 2147483648, %v22747_v27 (stack56)
        %v23976_v23 = vxor.u32 %v23975_v34, %v23967_v12 (stack48)
        %v24824_v43 = vshrl.u32 %v129180_v56, 19 (stack46)
        %v22295_v20 = vsel /*vm=*/%vm22290_vm15, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v22299_v40 = vsel /*vm=*/%vm22290_vm15, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v22303_v25 = vsel /*vm=*/%vm22290_vm15, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v23582_v7 = vor.u32 %v23581_v22, %v23580_v31 (stack47)
        %v22390_v55 = vmul.f32 %v22386_v8, %v129154_v50 (stack54)
        %v22724_v24 = vand.u32 2147483647, %v129134_v53 (stack77)
        %120623 = vrsqrt.f32 %v129201_v30 (stack67)
        %v129218_v60 = vadd.s32 %v129127_v54, %v122657_v58 (stack40)
        %vm22751_vm5 = vcmp.lt.f32.partialorder %v129201_v30, 5.0 (stack68)
        %v23189_v6 = vadd.s32 %v23186_v9, %v121574_v2 (stack40)
        %v23583_v34 = vxor.u32 %v23582_v7, %v23578_v10 (stack48)
        %v24388_v32 = vadd.s32 %v24384_v32, %v121569_v1 (stack40)
        %v22394_v61 = vadd.f32 %v22390_v55, %v22303_v25 (stack53)
        %v24396_v9 = vadd.s32 %v24393_v21, %v121564_v0 (stack40)
        %v24813_v21 = vadd.s32 %v24808_v11, %v121574_v2 (stack40)
        %v24825_v46 = vor.u32 %v24824_v43, %v24823_v46 (stack47)
        %v129226_v11 = vadd.f32 -2.5, %v129201_v30 (stack53)
        %v23181_v41 = vadd.s32 %v23177_v41, %v121564_v0 (stack40)
        %v23586_v27 = vadd.s32 %v23583_v34, %v23578_v10 (stack40)
        %v23971_v12 = vadd.s32 %v23967_v12, %v121564_v0 (stack40)
        %v22398_v10 = vmul.f32 %v22394_v61, %v129154_v50 (stack54)
        %v129234_v31 = vsel /*vm=*/%vm22751_vm5, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v129239_v22 = vsel /*vm=*/%vm22751_vm5, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v129244_v8 = vsel /*vm=*/%vm22751_vm5, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %vm129248_vm6 = vcmp.eq.f32.partialorder %v22263_v52, 1.0 (stack68)
        %v23193_v43 = vadd.s32 5, %v23189_v6 (stack40)
        %v23588_v25 = vshll.u32 %v23583_v34, 16 (stack45)
        %v23589_v7 = vshrl.u32 %v23583_v34, 16 (stack46)
        %v23979_v23 = vadd.s32 %v23976_v23, %v121574_v2 (stack40)
        %v22402_v40 = vadd.f32 %v22398_v10, %v22299_v40 (stack53)
        %v24400_v55 = vadd.s32 1, %v24396_v9 (stack40)
        %v24821_v56 = vadd.s32 %v129180_v56, %v24813_v21 (stack40)
        %vm25248_vm7 = vcmp.lt.u32.totalorder %v129127_v54, %v157089_v17 (stack43)
        %vm22796_vm8 = vcmp.eq.f32.partialorder %v129201_v30, inf (stack70)
        %v23195_v6 = vxor.u32 %v23193_v43, %v23181_v41 (stack48)
        %v23590_v34 = vor.u32 %v23589_v7, %v23588_v25 (stack47)
        %v23983_v61 = vadd.s32 2, %v23979_v23 (stack40)
        %v129259_v9 = vadd.s32 %v157204_v29, %v157090_v62 (stack40)
        %v22406_v50 = vmul.f32 %v22402_v40, %v129154_v50 (stack54)
        %vm22798_vm9 = vcmp.eq.f32.partialorder %v129201_v30, 0.0 (stack71)
        %v24404_v32 = vadd.s32 %v24400_v55, %v24388_v32 (stack40)
        %v24406_v21 = vshll.u32 %v24400_v55, 17 (stack45)
        %v24407_v41 = vshrl.u32 %v24400_v55, 15 (stack46)
        %v23196_v10 = vand.u32.u8 255, %v23195_v6 (stack49)
        %v23591_v43 = vxor.u32 %v23590_v34, %v23586_v27 (stack48)
        %v23987_v12 = vadd.s32 %v23983_v61, %v23971_v12 (stack40)
        %v23989_v25 = vshll.u32 %v23983_v61, 13 (stack45)
        %v22410_v20 = vadd.f32 %v22406_v50, %v22295_v20 (stack53)
        %v23990_v7 = vshrl.u32 %v23983_v61, 19 (stack46)
        %v24408_v23 = vor.u32 %v24407_v41, %v24406_v21 (stack47)
        %v24826_v46 = vxor.u32 %v24825_v46, %v24821_v56 (stack48)
        %v23197_v40 = vand.u32 65535, %v23196_v10 (stack50)
        %v23594_v27 = vadd.s32 %v23591_v43, %v23586_v27 (stack40)
        %v23600_v55 = vshll.u32 %v23591_v43, 24 (stack45)
        %v23601_v6 = vshrl.u32 %v23591_v43, 8 (stack46)
        %v22414_v26 = vmul.f32 %v22410_v20, %v129036_v26 (stack54)
        %v23991_v34 = vor.u32 %v23990_v7, %v23989_v25 (stack47)
        %v24409_v61 = vxor.u32 %v24408_v23, %v24404_v32 (stack48)
        %v24829_v56 = vadd.s32 %v24826_v46, %v24821_v56 (stack40)
        %v120624_v50 = vpop.eup %120623 (stack73)
        %v22799_v21 = vand.u32 2147483648, %v129201_v30 (stack72)
        %v23198_v41 = vshrl.u32 %v23197_v40, 1 (stack51)
        %v23602_v10 = vor.u32 %v23601_v6, %v23600_v55 (stack47)
        %v24831_v43 = vshll.u32 %v24826_v46, 15 (stack45)
        %v22418_v42 = vsel /*vm=*/%vm129248_vm6, /*on_true_vy=*/%v129100_v42, /*on_false_vx=*/%v22414_v26 (stack44)
        %v22795_v52 = vmul.f32 %v120624_v50, %v129201_v30 (stack74)
        %v23992_v25 = vxor.u32 %v23991_v34, %v23987_v12 (stack48)
        %v24412_v32 = vadd.s32 %v24409_v61, %v24404_v32 (stack40)
        %v22422_v20 = vmul.f32 1.4140625, %v22418_v42 (stack54)
        %v23199_v7 = vor.u32 16256, %v23198_v41 (stack47)
        %v23603_v23 = vxor.u32 %v23602_v10, %v23594_v27 (stack48)
        %v24414_v40 = vshll.u32 %v24409_v61, 29 (stack45)
        %v22797_v55 = vsel /*vm=*/%vm22796_vm8, /*on_true_vy=*/%v129201_v30, /*on_false_vx=*/%v22795_v52 (stack75)
        %v23995_v12 = vadd.s32 %v23992_v25, %v23987_v12 (stack40)
        %v23997_v6 = vshll.u32 %v23992_v25, 15 (stack45)
        %v23998_v26 = vshrl.u32 %v23992_v25, 17 (stack46)
        %v22425_v34 = vpack.c.bf16 %v156663_v45, %v22422_v20 (stack81)
        %v22800_v50 = vsel /*vm=*/%vm22798_vm9, /*on_true_vy=*/%v22799_v21, /*on_false_vx=*/%v22797_v55 (stack76)
        %v23200_v21 = vand.u32.u16 65535, %v23199_v7 (stack52)
        %v23606_v41 = vadd.s32 %v23603_v23, %v121564_v0 (stack40)
        %v22803_v10 = vadd.f32 -3.0, %v22800_v50 (stack53)
        %v23999_v42 = vor.u32 %v23998_v26, %v23997_v6 (stack47)
        %v24415_v61 = vshrl.u32 %v24409_v61, 3 (stack46)
        %v24832_v46 = vshrl.u32 %v24826_v46, 17 (stack46)
        %119861 = vst [vmem:[%s123356_s30 + $0x314] sm:$0xf] /*vst_source=*/%v22425_v34 (stack83)
        %v119868_v52 = vadd.low.f32.bf16 -1.0, %v23200_v21 (stack53)
        %v23598_v27 = vadd.s32 %v23594_v27, %v121569_v1 (stack40)
        %v23610_v25 = vadd.s32 4, %v23606_v41 (stack40)
        %v25257_v20 = vadd.s32 1, %v129259_v9 (stack40)
        %v129282_v11 = vsel /*vm=*/%vm22751_vm5, /*on_true_vy=*/%v129226_v11, /*on_false_vx=*/%v22803_v10 (stack44)
        %v24000_v7 = vxor.u32 %v23999_v42, %v23995_v12 (stack48)
        %v24416_v23 = vor.u32 %v24415_v61, %v24414_v40 (stack47)
        %v24833_v43 = vor.u32 %v24832_v46, %v24831_v43 (stack47)
        %v22811_v8 = vmul.f32 %v129282_v11, %v129244_v8 (stack54)
        %v23209_v40 = vmul.f32 2.0, %v119868_v52 (stack54)
        %v23614_v55 = vadd.s32 %v23610_v25, %v23598_v27 (stack40)
        %v23616_v6 = vshll.u32 %v23610_v25, 13 (stack45)
        %v23617_v26 = vshrl.u32 %v23610_v25, 19 (stack46)
        %v24003_v12 = vadd.s32 %v24000_v7, %v23995_v12 (stack40)
        %v24005_v34 = vshll.u32 %v24000_v7, 26 (stack45)
        %v24006_v50 = vshrl.u32 %v24000_v7, 6 (stack46)
        %v22815_v22 = vadd.f32 %v22811_v8, %v129239_v22 (stack53)
        %v23213_v21 = vadd.f32 -0.99609375, %v23209_v40 (stack53)
        %v24417_v41 = vxor.u32 %v24416_v23, %v24412_v32 (stack48)
        %v24834_v10 = vxor.u32 %v24833_v43, %v24829_v56 (stack48)
        %v22780_v42 = vsel /*vm=*/%vm22751_vm5, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v23618_v61 = vor.u32 %v23617_v26, %v23616_v6 (stack47)
        %v24007_v46 = vor.u32 %v24006_v50, %v24005_v34 (stack47)
        %v25261_v9 = vsel /*vm=*/%vm25248_vm7, /*on_true_vy=*/%v25257_v20, /*on_false_vx=*/%v129259_v9 (stack44)
        %v22819_v52 = vmul.f32 %v22815_v22, %v129282_v11 (stack54)
        %v129295_v27 = vmax.f32 %v23213_v21, -0.99609375 (stack55)
        %v24420_v32 = vadd.s32 %v24417_v41, %v24412_v32 (stack40)
        %v24422_v25 = vshll.u32 %v24417_v41, 16 (stack45)
        %v23619_v20 = vxor.u32 %v23618_v61, %v23614_v55 (stack48)
        %v24008_v7 = vxor.u32 %v24007_v46, %v24003_v12 (stack48)
        %v24423_v23 = vshrl.u32 %v24417_v41, 16 (stack46)
        %v129297_v56 = vadd.s32 %v24834_v10, %v24829_v56 (stack40)
        %v129302_v43 = vsel /*vm=*/%vm22751_vm5, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v129307_v8 = vsel /*vm=*/%vm22751_vm5, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v22823_v40 = vadd.f32 %v22819_v52, %v22780_v42 (stack53)
        %v23229_v6 = vxor.u32 2147483648, %v129295_v27 (stack56)
        %v23622_v55 = vadd.s32 %v23619_v20, %v23614_v55 (stack40)
        %v23624_v26 = vshll.u32 %v23619_v20, 15 (stack45)
        %v23625_v34 = vshrl.u32 %v23619_v20, 17 (stack46)
        %v24011_v12 = vadd.s32 %v24008_v7, %v24003_v12 (stack40)
        %vm25243_vm10 = vcmp.lt.u32.totalorder %v129218_v60, %v129127_v54 (stack43)
        %v22768_v50 = vsel /*vm=*/%vm22751_vm5, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v22827_v22 = vmul.f32 %v22823_v40, %v129282_v11 (stack54)
        %v23232_v21 = vmul.f32 %v23229_v6, %v129295_v27 (stack54)
        %v24017_v41 = vshll.u32 %v24008_v7, 6 (stack45)
        %v22776_v42 = vsel /*vm=*/%vm22751_vm5, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v23626_v61 = vor.u32 %v23625_v34, %v23624_v26 (stack47)
        %v24018_v46 = vshrl.u32 %v24008_v7, 26 (stack46)
        %v24424_v52 = vor.u32 %v24423_v23, %v24422_v25 (stack47)
        %v22772_v30 = vsel /*vm=*/%vm22751_vm5, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v22831_v25 = vadd.f32 %v22827_v22, %v22776_v42 (stack53)
        %v23234_v20 = vadd.f32 1.0, %v23232_v21 (stack57)
        %v23237_v7 = vmul.f32 -0.5, %v23232_v21 (stack59)
        %v23627_v23 = vxor.u32 %v23626_v61, %v23622_v55 (stack48)
        %v24019_v40 = vor.u32 %v24018_v46, %v24017_v41 (stack47)
        %v24425_v6 = vxor.u32 %v24424_v52, %v24420_v32 (stack48)
        %v25278_v26 = vadd.s32 %v129218_v60, %v121569_v1 (stack40)
        %v22835_v34 = vmul.f32 %v22831_v25, %v129282_v11 (stack54)
        %120625 = vlog2.f32 %v23234_v20 (stack58)
        %v23240_v22 = vand.u32 2147483647, %v23232_v21 (stack60)
        %v24839_v41 = vshll.u32 %v24834_v10, 26 (stack45)
        %v23630_v55 = vadd.s32 %v23627_v23, %v23622_v55 (stack40)
        %v23632_v42 = vshll.u32 %v23627_v23, 26 (stack45)
        %v23633_v61 = vshrl.u32 %v23627_v23, 6 (stack46)
        %v24020_v46 = vxor.u32 %v24019_v40, %v24011_v12 (stack48)
        %v22839_v52 = vadd.f32 %v22835_v34, %v22772_v30 (stack53)
        %v23238_v30 = vadd.f32 1.0, %v23237_v7 (stack61)
        %v24428_v32 = vadd.s32 %v24425_v6, %v24420_v32 (stack40)
        %v24434_v25 = vshll.u32 %v24425_v6, 24 (stack45)
        %v23634_v20 = vor.u32 %v23633_v61, %v23632_v42 (stack47)
        %v24023_v7 = vadd.s32 %v24020_v46, %v121569_v1 (stack40)
        %v24435_v23 = vshrl.u32 %v24425_v6, 8 (stack46)
        %v24840_v10 = vshrl.u32 %v24834_v10, 6 (stack46)
        %v22843_v40 = vmul.f32 %v22839_v52, %v129282_v11 (stack54)
        %v24015_v12 = vadd.s32 %v24011_v12, %v121574_v2 (stack40)
        %v25265_v6 = vadd.s32 1, %v25261_v9 (stack40)
        %v25284_v34 = vshll.u32 %v25278_v26, 13 (stack45)
        %v23635_v42 = vxor.u32 %v23634_v20, %v23630_v55 (stack48)
        %v24027_v61 = vadd.s32 3, %v24023_v7 (stack40)
        %v24436_v46 = vor.u32 %v24435_v23, %v24434_v25 (stack47)
        %v24841_v41 = vor.u32 %v24840_v10, %v24839_v41 (stack47)
        %v22847_v50 = vadd.f32 %v22843_v40, %v22768_v50 (stack53)
        %v23239_v21 = vmul.f32 %v23238_v30, %v23232_v21 (stack63)
        %v25269_v54 = vsel /*vm=*/%vm25243_vm10, /*on_true_vy=*/%v25265_v6, /*on_false_vx=*/%v25261_v9 (stack44)
        %v129334_v60 = vadd.s32 %v157199_v44, %v157091_v37 (stack40)
        %vm129336_vm11 = vcmp.lt.f32.partialorder %v23240_v22, 0.0004427343 (stack62)
        %v23638_v22 = vadd.s32 %v23635_v42, %v23630_v55 (stack40)
        %v23644_v55 = vshll.u32 %v23635_v42, 6 (stack45)
        %v23645_v52 = vshrl.u32 %v23635_v42, 26 (stack46)
        %v24031_v30 = vadd.s32 %v24027_v61, %v24015_v12 (stack40)
        %v22851_v25 = vmul.f32 %v22847_v50, %v129282_v11 (stack54)
        %v24033_v20 = vshll.u32 %v24027_v61, 17 (stack45)
        %v24034_v7 = vshrl.u32 %v24027_v61, 15 (stack46)
        %v24437_v23 = vxor.u32 %v24436_v46, %v24428_v32 (stack48)
        %v23646_v10 = vor.u32 %v23645_v52, %v23644_v55 (stack47)
        %v24842_v40 = vxor.u32 %v24841_v41, %v129297_v56 (stack48)
        %v25274_v12 = vadd.s32 %v25269_v54, %v121574_v2 (stack40)
        %v25285_v6 = vshrl.u32 %v25278_v26, 19 (stack46)
        %v22855_v8 = vadd.f32 %v22851_v25, %v129307_v8 (stack53)
        %v24035_v42 = vor.u32 %v24034_v7, %v24033_v20 (stack47)
        %v24432_v32 = vadd.s32 %v24428_v32, %v121564_v0 (stack40)
        %v24440_v61 = vadd.s32 %v24437_v23, %v121574_v2 (stack40)
        %v23647_v46 = vxor.u32 %v23646_v10, %v23638_v22 (stack48)
        %v24845_v56 = vadd.s32 %v24842_v40, %v129297_v56 (stack40)
        %v24851_v41 = vshll.u32 %v24842_v40, 6 (stack45)
        %v24852_v50 = vshrl.u32 %v24842_v40, 26 (stack46)
        %v22859_v54 = vmul.f32 %v22855_v8, %v129282_v11 (stack54)
        %v24036_v55 = vxor.u32 %v24035_v42, %v24031_v30 (stack48)
        %v24444_v52 = vadd.s32 2, %v24440_v61 (stack40)
        %v25282_v26 = vadd.s32 %v25278_v26, %v25274_v12 (stack40)
        %v120626_v25 = vpop.eup %120625 (stack64)
        %v23642_v22 = vadd.s32 %v23638_v22, %v121564_v0 (stack40)
        %v23650_v20 = vadd.s32 %v23647_v46, %v121574_v2 (stack40)
        %v24853_v7 = vor.u32 %v24852_v50, %v24851_v41 (stack47)
        %v25286_v34 = vor.u32 %v25285_v6, %v25284_v34 (stack47)
        %v22863_v43 = vadd.f32 %v22859_v54, %v129302_v43 (stack53)
        %v23236_v23 = vmul.f32 0.6931472, %v120626_v25 (stack65)
        %v24039_v30 = vadd.s32 %v24036_v55, %v24031_v30 (stack40)
        %v24041_v10 = vshll.u32 %v24036_v55, 29 (stack45)
        %v23654_v40 = vadd.s32 5, %v23650_v20 (stack40)
        %v24042_v12 = vshrl.u32 %v24036_v55, 3 (stack46)
        %v24448_v6 = vadd.s32 %v24444_v52, %v24432_v32 (stack40)
        %v24450_v8 = vshll.u32 %v24444_v52, 13 (stack45)
        %v22867_v11 = vmul.f32 %v22863_v43, %v129282_v11 (stack54)
        %v23242_v21 = vsel /*vm=*/%vm129336_vm11, /*on_true_vy=*/%v23239_v21, /*on_false_vx=*/%v23236_v23 (stack66)
        %v24451_v9 = vshrl.u32 %v24444_v52, 19 (stack46)
        %v24854_v42 = vxor.u32 %v24853_v7, %v24845_v56 (stack48)
        %v129354_v32 = vxor.u32 2147483648, %v23242_v21 (stack56)
        %v23656_v61 = vxor.u32 %v23654_v40, %v23642_v22 (stack48)
        %v24043_v46 = vor.u32 %v24042_v12, %v24041_v10 (stack47)
        %v25287_v41 = vxor.u32 %v25286_v34, %v25282_v26 (stack48)
        %v22871_v31 = vadd.f32 %v22867_v11, %v129234_v31 (stack53)
        %vm25709_vm12 = vcmp.lt.u32.totalorder %v129334_v60, %v157091_v37 (stack43)
        %vm23246_vm13 = vcmp.lt.f32.partialorder %v129354_v32, 5.0 (stack68)
        %120627 = vrsqrt.f32 %v129354_v32 (stack67)
        %vm22727_vm14 = vcmp.eq.f32.partialorder %v22724_v24, 1.0 (stack68)
        %v22732_v24 = vmul.f32 inf, %v129134_v53 (stack54)
        %v22875_v53 = vmul.f32 %v22871_v31, %v129134_v53 (stack54)
        %v24452_v50 = vor.u32 %v24451_v9, %v24450_v8 (stack47)
        %v24044_v54 = vxor.u32 %v24043_v46, %v24039_v30 (stack48)
        %v24849_v56 = vadd.s32 %v24845_v56, %v121569_v1 (stack40)
        %v24857_v55 = vadd.s32 %v24854_v42, %v121564_v0 (stack40)
        %v129369_v52 = vadd.s32 %v129334_v60, %v122657_v58 (stack40)
        %v22879_v25 = vsel /*vm=*/%vm22727_vm14, /*on_true_vy=*/%v22732_v24, /*on_false_vx=*/%v22875_v53 (stack44)
        %v129374_v22 = vsel /*vm=*/%vm23246_vm13, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v129379_v20 = vsel /*vm=*/%vm23246_vm13, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v129382_v7 = vadd.f32 -2.5, %v129354_v32 (stack53)
        %v22883_v34 = vmul.f32 1.4140625, %v22879_v25 (stack54)
        %v129387_v43 = vsel /*vm=*/%vm23246_vm13, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v129392_v23 = vsel /*vm=*/%vm23246_vm13, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v23657_v10 = vand.u32.u8 255, %v23656_v61 (stack49)
        %v24047_v30 = vadd.s32 %v24044_v54, %v24039_v30 (stack40)
        %v24049_v40 = vshll.u32 %v24044_v54, 16 (stack45)
        %v24050_v12 = vshrl.u32 %v24044_v54, 16 (stack46)
        %v24453_v8 = vxor.u32 %v24452_v50, %v24448_v6 (stack48)
        %v22886_v11 = vpack.c.bf16 %v156663_v45, %v22883_v34 (stack81)
        %v23658_v21 = vand.u32 65535, %v23657_v10 (stack50)
        %v24861_v9 = vadd.s32 1, %v24857_v55 (stack40)
        %v25290_v26 = vadd.s32 %v25287_v41, %v25282_v26 (stack40)
        %vm23291_vm15 = vcmp.eq.f32.partialorder %v129354_v32, inf (stack70)
        %v24051_v42 = vor.u32 %v24050_v12, %v24049_v40 (stack47)
        %v24456_v6 = vadd.s32 %v24453_v8, %v24448_v6 (stack40)
        %v24458_v61 = vshll.u32 %v24453_v8, 15 (stack45)
        %v24459_v46 = vshrl.u32 %v24453_v8, 17 (stack46)
        %119863 = vst [vmem:[%s123356_s30 + $0x394] sm:$0xf] /*vst_source=*/%v22886_v11 (stack83)
        %v23659_v31 = vshrl.u32 %v23658_v21, 1 (stack51)
        %v24865_v24 = vadd.s32 %v24861_v9, %v24849_v56 (stack40)
        %v24867_v53 = vshll.u32 %v24861_v9, 17 (stack45)
        %v24868_v50 = vshrl.u32 %v24861_v9, 15 (stack46)
        %v24052_v54 = vxor.u32 %v24051_v42, %v24047_v30 (stack48)
        %v24460_v56 = vor.u32 %v24459_v46, %v24458_v61 (stack47)
        %v25292_v55 = vshll.u32 %v25287_v41, 15 (stack45)
        %v25293_v41 = vshrl.u32 %v25287_v41, 17 (stack46)
        %vm23293_vm0 = vcmp.eq.f32.partialorder %v129354_v32, 0.0 (stack71)
        %v23660_v25 = vor.u32 16256, %v23659_v31 (stack47)
        %v24869_v34 = vor.u32 %v24868_v50, %v24867_v53 (stack47)
        %v25714_v10 = vadd.s32 %v157204_v29, %v157094_v36 (stack40)
        %v24055_v30 = vadd.s32 %v24052_v54, %v24047_v30 (stack40)
        %v24061_v40 = vshll.u32 %v24052_v54, 24 (stack45)
        %v24062_v12 = vshrl.u32 %v24052_v54, 8 (stack46)
        %v24461_v8 = vxor.u32 %v24460_v56, %v24456_v6 (stack48)
        %v23294_v11 = vand.u32 2147483648, %v129354_v32 (stack72)
        %v23661_v21 = vand.u32.u16 65535, %v23660_v25 (stack52)
        %v24870_v9 = vxor.u32 %v24869_v34, %v24865_v24 (stack48)
        %v25294_v42 = vor.u32 %v25293_v41, %v25292_v55 (stack47)
        %v120628_v61 = vpop.eup %120627 (stack73)
        %v24063_v46 = vor.u32 %v24062_v12, %v24061_v40 (stack47)
        %v24464_v6 = vadd.s32 %v24461_v8, %v24456_v6 (stack40)
        %v24466_v31 = vshll.u32 %v24461_v8, 26 (stack45)
        %v25718_v53 = vadd.s32 1, %v25714_v10 (stack40)
        %v23290_v50 = vmul.f32 %v120628_v61, %v129354_v32 (stack74)
        %v119870_v54 = vadd.low.f32.bf16 -1.0, %v23661_v21 (stack53)
        %v24467_v56 = vshrl.u32 %v24461_v8, 6 (stack46)
        %v24873_v24 = vadd.s32 %v24870_v9, %v24865_v24 (stack40)
        %v24064_v55 = vxor.u32 %v24063_v46, %v24055_v30 (stack48)
        %v24875_v41 = vshll.u32 %v24870_v9, 29 (stack45)
        %v24876_v25 = vshrl.u32 %v24870_v9, 3 (stack46)
        %v25295_v34 = vxor.u32 %v25294_v42, %v25290_v26 (stack48)
        %v23292_v40 = vsel /*vm=*/%vm23291_vm15, /*on_true_vy=*/%v129354_v32, /*on_false_vx=*/%v23290_v50 (stack75)
        %v23670_v12 = vmul.f32 2.0, %v119870_v54 (stack54)
        %v24468_v8 = vor.u32 %v24467_v56, %v24466_v31 (stack47)
        %v25722_v10 = vsel /*vm=*/%vm25709_vm12, /*on_true_vy=*/%v25718_v53, /*on_false_vx=*/%v25714_v10 (stack44)
        %v23295_v11 = vsel /*vm=*/%vm23293_vm0, /*on_true_vy=*/%v23294_v11, /*on_false_vx=*/%v23292_v40 (stack76)
        %v24067_v21 = vadd.s32 %v24064_v55, %v121564_v0 (stack40)
        %v24877_v9 = vor.u32 %v24876_v25, %v24875_v41 (stack47)
        %v25298_v26 = vadd.s32 %v25295_v34, %v25290_v26 (stack40)
        %v23298_v42 = vadd.f32 -3.0, %v23295_v11 (stack53)
        %v23674_v61 = vadd.f32 -0.99609375, %v23670_v12 (stack53)
        %v24059_v30 = vadd.s32 %v24055_v30, %v121569_v1 (stack40)
        %v24469_v46 = vxor.u32 %v24468_v8, %v24464_v6 (stack48)
        %v24071_v31 = vadd.s32 4, %v24067_v21 (stack40)
        %v24878_v53 = vxor.u32 %v24877_v9, %v24873_v24 (stack48)
        %v25300_v50 = vshll.u32 %v25295_v34, 26 (stack45)
        %v25301_v54 = vshrl.u32 %v25295_v34, 6 (stack46)
        %v129415_v7 = vsel /*vm=*/%vm23246_vm13, /*on_true_vy=*/%v129382_v7, /*on_false_vx=*/%v23298_v42 (stack44)
        %v129417_v56 = vmax.f32 %v23674_v61, -0.99609375 (stack55)
        %v24472_v6 = vadd.s32 %v24469_v46, %v24464_v6 (stack40)
        %v24478_v55 = vshll.u32 %v24469_v46, 6 (stack45)
        %v23306_v23 = vmul.f32 %v129415_v7, %v129392_v23 (stack54)
        %v24075_v41 = vadd.s32 %v24071_v31, %v24059_v30 (stack40)
        %v24077_v25 = vshll.u32 %v24071_v31, 13 (stack45)
        %v24078_v34 = vshrl.u32 %v24071_v31, 19 (stack46)
        %v23271_v40 = vsel /*vm=*/%vm23246_vm13, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v23279_v12 = vsel /*vm=*/%vm23246_vm13, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v23690_v8 = vxor.u32 2147483648, %v129417_v56 (stack56)
        %vm25704_vm1 = vcmp.lt.u32.totalorder %v129369_v52, %v129334_v60 (stack43)
        %v23310_v11 = vadd.f32 %v23306_v23, %v23279_v12 (stack53)
        %v24079_v21 = vor.u32 %v24078_v34, %v24077_v25 (stack47)
        %v24479_v9 = vshrl.u32 %v24469_v46, 26 (stack46)
        %v24881_v24 = vadd.s32 %v24878_v53, %v24873_v24 (stack40)
        %v23275_v42 = vsel /*vm=*/%vm23246_vm13, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v129434_v61 = vmul.f32 %v23690_v8, %v129417_v56 (stack54)
        %v24883_v30 = vshll.u32 %v24878_v53, 16 (stack45)
        %v24884_v46 = vshrl.u32 %v24878_v53, 16 (stack46)
        %v23314_v31 = vmul.f32 %v23310_v11, %v129415_v7 (stack54)
        %v24080_v53 = vxor.u32 %v24079_v21, %v24075_v41 (stack48)
        %v24480_v55 = vor.u32 %v24479_v9, %v24478_v55 (stack47)
        %v25302_v50 = vor.u32 %v25301_v54, %v25300_v50 (stack47)
        %v23695_v54 = vadd.f32 1.0, %v129434_v61 (stack57)
        %v23698_v23 = vmul.f32 -0.5, %v129434_v61 (stack59)
        %v24885_v25 = vor.u32 %v24884_v46, %v24883_v30 (stack47)
        %v25726_v34 = vadd.s32 1, %v25722_v10 (stack40)
        %v23318_v12 = vadd.f32 %v23314_v31, %v23275_v42 (stack53)
        %v24083_v41 = vadd.s32 %v24080_v53, %v24075_v41 (stack40)
        %v24085_v8 = vshll.u32 %v24080_v53, 15 (stack45)
        %v24086_v11 = vshrl.u32 %v24080_v53, 17 (stack46)
        %120629 = vlog2.f32 %v23695_v54 (stack58)
        %v24476_v21 = vadd.s32 %v24472_v6, %v121574_v2 (stack40)
        %v24481_v6 = vxor.u32 %v24480_v55, %v24472_v6 (stack48)
        %v25739_v9 = vadd.s32 %v129369_v52, %v121569_v1 (stack40)
        %v23322_v42 = vmul.f32 %v23318_v12, %v129415_v7 (stack54)
        %v24087_v30 = vor.u32 %v24086_v11, %v24085_v8 (stack47)
        %v24886_v46 = vxor.u32 %v24885_v25, %v24881_v24 (stack48)
        %v25303_v31 = vxor.u32 %v25302_v50, %v25298_v26 (stack48)
        %v23699_v53 = vadd.f32 1.0, %v23698_v23 (stack61)
        %v23701_v55 = vand.u32 2147483647, %v129434_v61 (stack60)
        %v24484_v50 = vadd.s32 %v24481_v6, %v121569_v1 (stack40)
        %v25730_v60 = vsel /*vm=*/%vm25704_vm1, /*on_true_vy=*/%v25726_v34, /*on_false_vx=*/%v25722_v10 (stack44)
        %v23326_v52 = vadd.f32 %v23322_v42, %v23271_v40 (stack53)
        %v24088_v10 = vxor.u32 %v24087_v30, %v24083_v41 (stack48)
        %v24889_v40 = vadd.s32 %v24886_v46, %v24881_v24 (stack40)
        %v24895_v24 = vshll.u32 %v24886_v46, 24 (stack45)
        %v24488_v54 = vadd.s32 3, %v24484_v50 (stack40)
        %v24896_v23 = vshrl.u32 %v24886_v46, 8 (stack46)
        %v129448_v26 = vadd.s32 %v25303_v31, %v25298_v26 (stack40)
        %v25745_v25 = vshll.u32 %v25739_v9, 13 (stack45)
        %v23330_v34 = vmul.f32 %v23326_v52, %v129415_v7 (stack54)
        %v24091_v12 = vadd.s32 %v24088_v10, %v24083_v41 (stack40)
        %v24093_v41 = vshll.u32 %v24088_v10, 26 (stack45)
        %v24094_v8 = vshrl.u32 %v24088_v10, 6 (stack46)
        %v24492_v11 = vadd.s32 %v24488_v54, %v24476_v21 (stack40)
        %v24494_v21 = vshll.u32 %v24488_v54, 17 (stack45)
        %v24495_v6 = vshrl.u32 %v24488_v54, 15 (stack46)
        %v25312_v42 = vshll.u32 %v25303_v31, 6 (stack45)
        %v23334_v43 = vadd.f32 %v23330_v34, %v129387_v43 (stack53)
        %v23700_v61 = vmul.f32 %v23699_v53, %v129434_v61 (stack63)
        %v24095_v30 = vor.u32 %v24094_v8, %v24093_v41 (stack47)
        %v24897_v46 = vor.u32 %v24896_v23, %v24895_v24 (stack47)
        %v24496_v53 = vor.u32 %v24495_v6, %v24494_v21 (stack47)
        %v25313_v31 = vshrl.u32 %v25303_v31, 26 (stack46)
        %v25735_v50 = vadd.s32 %v25730_v60, %v121574_v2 (stack40)
        %v25746_v60 = vshrl.u32 %v25739_v9, 19 (stack46)
        %v23338_v52 = vmul.f32 %v23334_v43, %v129415_v7 (stack54)
        %v24096_v10 = vxor.u32 %v24095_v30, %v24091_v12 (stack48)
        %v24898_v24 = vxor.u32 %v24897_v46, %v24889_v40 (stack48)
        %v129457_v44 = vadd.s32 %v157199_v44, %v157095_v13 (stack40)
        %v24497_v54 = vxor.u32 %v24496_v53, %v24492_v11 (stack48)
        %v25314_v23 = vor.u32 %v25313_v31, %v25312_v42 (stack47)
        %v129459_v9 = vadd.s32 %v25739_v9, %v25735_v50 (stack40)
        %v25747_v25 = vor.u32 %v25746_v60, %v25745_v25 (stack47)
        %v23342_v20 = vadd.f32 %v23338_v52, %v129379_v20 (stack53)
        %v24099_v34 = vadd.s32 %v24096_v10, %v24091_v12 (stack40)
        %v24105_v12 = vshll.u32 %v24096_v10, 6 (stack45)
        %v24106_v41 = vshrl.u32 %v24096_v10, 26 (stack46)
        %v24500_v8 = vadd.s32 %v24497_v54, %v24492_v11 (stack40)
        %v24502_v11 = vshll.u32 %v24497_v54, 29 (stack45)
        %v24503_v21 = vshrl.u32 %v24497_v54, 3 (stack46)
        %v24901_v6 = vadd.s32 %v24898_v24, %v121574_v2 (stack40)
        %v120630_v42 = vpop.eup %120629 (stack64)
        %v23346_v43 = vmul.f32 %v23342_v20, %v129415_v7 (stack54)
        %v24107_v30 = vor.u32 %v24106_v41, %v24105_v12 (stack47)
        %v24893_v40 = vadd.s32 %v24889_v40, %v121564_v0 (stack40)
        %v25315_v46 = vxor.u32 %v25314_v23, %v129448_v26 (stack48)
        %v23697_v53 = vmul.f32 0.6931472, %v120630_v42 (stack65)
        %v24504_v31 = vor.u32 %v24503_v21, %v24502_v11 (stack47)
        %v24905_v50 = vadd.s32 2, %v24901_v6 (stack40)
        %v129467_v60 = vxor.u32 %v25747_v25, %v129459_v9 (stack48)
        %v23219_v52 = vand.u32 2147483647, %v129295_v27 (stack77)
        %v23350_v22 = vadd.f32 %v23346_v43, %v129374_v22 (stack53)
        %vm23702_vm2 = vcmp.lt.f32.partialorder %v23701_v55, 0.0004427343 (stack62)
        %v24108_v55 = vxor.u32 %v24107_v30, %v24099_v34 (stack48)
        %v23703_v61 = vsel /*vm=*/%vm23702_vm2, /*on_true_vy=*/%v23700_v61, /*on_false_vx=*/%v23697_v53 (stack66)
        %v24505_v10 = vxor.u32 %v24504_v31, %v24500_v8 (stack48)
        %v24909_v24 = vadd.s32 %v24905_v50, %v24893_v40 (stack40)
        %v23227_v54 = vmul.f32 inf, %v129295_v27 (stack54)
        %v23354_v23 = vmul.f32 %v23350_v22, %v129415_v7 (stack54)
        %v129473_v25 = vxor.u32 2147483648, %v23703_v61 (stack56)
        %v25318_v20 = vadd.s32 %v25315_v46, %v121564_v0 (stack40)
        %v23255_v12 = vsel /*vm=*/%vm23246_vm13, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v24508_v41 = vadd.s32 %v24505_v10, %v24500_v8 (stack40)
        %v24510_v8 = vshll.u32 %v24505_v10, 16 (stack45)
        %v24511_v11 = vshrl.u32 %v24505_v10, 16 (stack46)
        %vm129479_vm3 = vcmp.eq.f32.partialorder %v23219_v52, 1.0 (stack68)
        %v23251_v32 = vsel /*vm=*/%vm23246_vm13, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v23358_v6 = vadd.f32 %v23354_v23, %v23255_v12 (stack53)
        %120631 = vrsqrt.f32 %v129473_v25 (stack67)
        %vm23707_vm4 = vcmp.lt.f32.partialorder %v129473_v25, 5.0 (stack68)
        %v24111_v42 = vadd.s32 %v24108_v55, %v121574_v2 (stack40)
        %v24512_v43 = vor.u32 %v24511_v11, %v24510_v8 (stack47)
        %v25310_v26 = vadd.s32 %v129448_v26, %v121569_v1 (stack40)
        %v23362_v7 = vmul.f32 %v23358_v6, %v129415_v7 (stack54)
        %v24911_v30 = vshll.u32 %v24905_v50, 13 (stack45)
        %v24912_v40 = vshrl.u32 %v24905_v50, 19 (stack46)
        %v25322_v46 = vadd.s32 1, %v25318_v20 (stack40)
        %v129493_v53 = vadd.f32 -2.5, %v129473_v25 (stack53)
        %v24103_v34 = vadd.s32 %v24099_v34, %v121564_v0 (stack40)
        %v24513_v31 = vxor.u32 %v24512_v43, %v24508_v41 (stack48)
        %v129498_v50 = vadd.s32 %v129457_v44, %v122657_v58 (stack40)
        %v23366_v52 = vadd.f32 %v23362_v7, %v23251_v32 (stack53)
        %v129503_v22 = vsel /*vm=*/%vm23707_vm4, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v129508_v55 = vsel /*vm=*/%vm23707_vm4, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v129513_v61 = vsel /*vm=*/%vm23707_vm4, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v24115_v10 = vadd.s32 5, %v24111_v42 (stack40)
        %v24516_v23 = vadd.s32 %v24513_v31, %v24508_v41 (stack40)
        %v24522_v20 = vshll.u32 %v24513_v31, 24 (stack45)
        %v24523_v12 = vshrl.u32 %v24513_v31, 8 (stack46)
        %v23370_v27 = vmul.f32 %v23366_v52, %v129295_v27 (stack54)
        %v24913_v41 = vor.u32 %v24912_v40, %v24911_v30 (stack47)
        %v25326_v8 = vadd.s32 %v25322_v46, %v25310_v26 (stack40)
        %v25328_v11 = vshll.u32 %v25322_v46, 17 (stack45)
        %vm23752_vm5 = vcmp.eq.f32.partialorder %v129473_v25, inf (stack70)
        %v23755_v32 = vand.u32 2147483648, %v129473_v25 (stack72)
        %v24117_v6 = vxor.u32 %v24115_v10, %v24103_v34 (stack48)
        %v24524_v42 = vor.u32 %v24523_v12, %v24522_v20 (stack47)
        %v25329_v43 = vshrl.u32 %v25322_v46, 15 (stack46)
        %v23374_v54 = vsel /*vm=*/%vm129479_vm3, /*on_true_vy=*/%v23227_v54, /*on_false_vx=*/%v23370_v27 (stack44)
        %vm23754_vm6 = vcmp.eq.f32.partialorder %v129473_v25, 0.0 (stack71)
        %v24914_v21 = vxor.u32 %v24913_v41, %v24909_v24 (stack48)
        %v25751_v9 = vadd.s32 %v129467_v60, %v129459_v9 (stack40)
        %v25753_v26 = vshll.u32 %v129467_v60, 15 (stack45)
        %v23378_v7 = vmul.f32 1.4140625, %v23374_v54 (stack54)
        %v24118_v30 = vand.u32.u8 255, %v24117_v6 (stack49)
        %v24525_v40 = vxor.u32 %v24524_v42, %v24516_v23 (stack48)
        %v25330_v46 = vor.u32 %v25329_v43, %v25328_v11 (stack47)
        %v24917_v24 = vadd.s32 %v24914_v21, %v24909_v24 (stack40)
        %v24919_v34 = vshll.u32 %v24914_v21, 15 (stack45)
        %v24920_v31 = vshrl.u32 %v24914_v21, 17 (stack46)
        %v25754_v60 = vshrl.u32 %v129467_v60, 17 (stack46)
        %v23381_v52 = vpack.c.bf16 %v156663_v45, %v23378_v7 (stack81)
        %v24119_v10 = vand.u32 65535, %v24118_v30 (stack50)
        %v24528_v20 = vadd.s32 %v24525_v40, %v121564_v0 (stack40)
        %v25331_v12 = vxor.u32 %v25330_v46, %v25326_v8 (stack48)
        %v24520_v23 = vadd.s32 %v24516_v23, %v121569_v1 (stack40)
        %v24921_v27 = vor.u32 %v24920_v31, %v24919_v34 (stack47)
        %v25755_v41 = vor.u32 %v25754_v60, %v25753_v26 (stack47)
        %vm26170_vm7 = vcmp.lt.u32.totalorder %v129457_v44, %v157095_v13 (stack43)
        %v120632_v11 = vpop.eup %120631 (stack73)
        %119869 = vst [vmem:[%s123356_s30 + $0x18] sm:$0xf] /*vst_source=*/%v23381_v52 (stack83)
        %v24120_v6 = vshrl.u32 %v24119_v10, 1 (stack51)
        %v24532_v42 = vadd.s32 4, %v24528_v20 (stack40)
        %v25334_v8 = vadd.s32 %v25331_v12, %v25326_v8 (stack40)
        %v25336_v43 = vshll.u32 %v25331_v12, 29 (stack45)
        %v23751_v54 = vmul.f32 %v120632_v11, %v129473_v25 (stack74)
        %v24922_v21 = vxor.u32 %v24921_v27, %v24917_v24 (stack48)
        %v25337_v26 = vshrl.u32 %v25331_v12, 3 (stack46)
        %v25756_v7 = vxor.u32 %v25755_v41, %v25751_v9 (stack48)
        %v24121_v30 = vor.u32 16256, %v24120_v6 (stack47)
        %v24536_v40 = vadd.s32 %v24532_v42, %v24520_v23 (stack40)
        %v24538_v46 = vshll.u32 %v24532_v42, 13 (stack45)
        %v24539_v34 = vshrl.u32 %v24532_v42, 19 (stack46)
        %v23753_v31 = vsel /*vm=*/%vm23752_vm5, /*on_true_vy=*/%v129473_v25, /*on_false_vx=*/%v23751_v54 (stack75)
        %v24925_v24 = vadd.s32 %v24922_v21, %v24917_v24 (stack40)
        %v24927_v60 = vshll.u32 %v24922_v21, 26 (stack45)
        %v24928_v52 = vshrl.u32 %v24922_v21, 6 (stack46)
        %v23756_v32 = vsel /*vm=*/%vm23754_vm6, /*on_true_vy=*/%v23755_v32, /*on_false_vx=*/%v23753_v31 (stack76)
        %v24122_v10 = vand.u32.u16 65535, %v24121_v30 (stack52)
        %v24540_v20 = vor.u32 %v24539_v34, %v24538_v46 (stack47)
        %v25338_v12 = vor.u32 %v25337_v26, %v25336_v43 (stack47)
        %v23744_v23 = vsel /*vm=*/%vm23707_vm4, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v23759_v27 = vadd.f32 -3.0, %v23756_v32 (stack53)
        %v24929_v41 = vor.u32 %v24928_v52, %v24927_v60 (stack47)
        %v129540_v9 = vadd.s32 %v25756_v7, %v25751_v9 (stack40)
        %v119872_v11 = vadd.low.f32.bf16 -1.0, %v24122_v10 (stack53)
        %v24541_v6 = vxor.u32 %v24540_v20, %v24536_v40 (stack48)
        %v25339_v42 = vxor.u32 %v25338_v12, %v25334_v8 (stack48)
        %v25761_v43 = vshll.u32 %v25756_v7, 26 (stack45)
        %v129545_v53 = vsel /*vm=*/%vm23707_vm4, /*on_true_vy=*/%v129493_v53, /*on_false_vx=*/%v23759_v27 (stack44)
        %v24930_v54 = vxor.u32 %v24929_v41, %v24925_v24 (stack48)
        %v25762_v21 = vshrl.u32 %v25756_v7, 6 (stack46)
        %v26175_v29 = vadd.s32 %v157204_v29, %v157100_v14 (stack40)
        %v23767_v26 = vmul.f32 %v129545_v53, %v23744_v23 (stack54)
        %v24131_v7 = vmul.f32 2.0, %v119872_v11 (stack54)
        %v24544_v30 = vadd.s32 %v24541_v6, %v24536_v40 (stack40)
        %v24546_v40 = vshll.u32 %v24541_v6, 15 (stack45)
        %v24547_v46 = vshrl.u32 %v24541_v6, 17 (stack46)
        %v24933_v34 = vadd.s32 %v24930_v54, %v24925_v24 (stack40)
        %v24939_v31 = vshll.u32 %v24930_v54, 6 (stack45)
        %v24940_v24 = vshrl.u32 %v24930_v54, 26 (stack46)
        %v23771_v61 = vadd.f32 %v23767_v26, %v129513_v61 (stack53)
        %v24135_v60 = vadd.f32 -0.99609375, %v24131_v7 (stack53)
        %v25342_v8 = vadd.s32 %v25339_v42, %v25334_v8 (stack40)
        %v25344_v52 = vshll.u32 %v25339_v42, 16 (stack45)
        %v23724_v32 = vsel /*vm=*/%vm23707_vm4, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v24548_v10 = vor.u32 %v24547_v46, %v24546_v40 (stack47)
        %v24941_v20 = vor.u32 %v24940_v24, %v24939_v31 (stack47)
        %v25345_v12 = vshrl.u32 %v25339_v42, 16 (stack46)
        %v23732_v23 = vsel /*vm=*/%vm23707_vm4, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v23736_v27 = vsel /*vm=*/%vm23707_vm4, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v23775_v41 = vmul.f32 %v23771_v61, %v129545_v53 (stack54)
        %v129561_v11 = vmax.f32 %v24135_v60, -0.99609375 (stack55)
        %v24549_v6 = vxor.u32 %v24548_v10, %v24544_v30 (stack48)
        %v24942_v42 = vxor.u32 %v24941_v20, %v24933_v34 (stack48)
        %v25346_v54 = vor.u32 %v25345_v12, %v25344_v52 (stack47)
        %v25763_v43 = vor.u32 %v25762_v21, %v25761_v43 (stack47)
        %v23779_v21 = vadd.f32 %v23775_v41, %v23736_v27 (stack53)
        %v24151_v26 = vxor.u32 2147483648, %v129561_v11 (stack56)
        %v26179_v7 = vadd.s32 1, %v26175_v29 (stack40)
        %v129566_v40 = vadd.s32 %v129498_v50, %v121569_v1 (stack40)
        %v24552_v30 = vadd.s32 %v24549_v6, %v24544_v30 (stack40)
        %v24554_v46 = vshll.u32 %v24549_v6, 26 (stack45)
        %v24555_v31 = vshrl.u32 %v24549_v6, 6 (stack46)
        %v24945_v24 = vadd.s32 %v24942_v42, %v121569_v1 (stack40)
        %v23783_v61 = vmul.f32 %v23779_v21, %v129545_v53 (stack54)
        %v129571_v60 = vmul.f32 %v24151_v26, %v129561_v11 (stack54)
        %v24937_v34 = vadd.s32 %v24933_v34, %v121574_v2 (stack40)
        %v25347_v52 = vxor.u32 %v25346_v54, %v25342_v8 (stack48)
        %v24556_v10 = vor.u32 %v24555_v31, %v24554_v46 (stack47)
        %v24949_v20 = vadd.s32 3, %v24945_v24 (stack40)
        %v25764_v12 = vxor.u32 %v25763_v43, %v129540_v9 (stack48)
        %v26183_v29 = vsel /*vm=*/%vm26170_vm7, /*on_true_vy=*/%v26179_v7, /*on_false_vx=*/%v26175_v29 (stack44)
        %v23728_v27 = vsel /*vm=*/%vm23707_vm4, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v23787_v23 = vadd.f32 %v23783_v61, %v23732_v23 (stack53)
        %v24156_v41 = vadd.f32 1.0, %v129571_v60 (stack57)
        %v24159_v6 = vmul.f32 -0.5, %v129571_v60 (stack59)
        %v24557_v42 = vxor.u32 %v24556_v10, %v24552_v30 (stack48)
        %v24953_v54 = vadd.s32 %v24949_v20, %v24937_v34 (stack40)
        %v24955_v43 = vshll.u32 %v24949_v20, 17 (stack45)
        %v24956_v21 = vshrl.u32 %v24949_v20, 15 (stack46)
        %v23791_v26 = vmul.f32 %v23787_v23, %v129545_v53 (stack54)
        %120633 = vlog2.f32 %v24156_v41 (stack58)
        %vm26165_vm8 = vcmp.lt.u32.totalorder %v129498_v50, %v129457_v44 (stack43)
        %v26206_v7 = vshll.u32 %v129566_v40, 13 (stack45)
        %v24560_v30 = vadd.s32 %v24557_v42, %v24552_v30 (stack40)
        %v24566_v46 = vshll.u32 %v24557_v42, 6 (stack45)
        %v24567_v31 = vshrl.u32 %v24557_v42, 26 (stack46)
        %v24957_v24 = vor.u32 %v24956_v21, %v24955_v43 (stack47)
        %v23795_v61 = vadd.f32 %v23791_v26, %v23728_v27 (stack53)
        %v24162_v34 = vand.u32 2147483647, %v129571_v60 (stack60)
        %v25350_v8 = vadd.s32 %v25347_v52, %v25342_v8 (stack40)
        %v25356_v10 = vshll.u32 %v25347_v52, 24 (stack45)
        %v24160_v20 = vadd.f32 1.0, %v24159_v6 (stack61)
        %v24568_v27 = vor.u32 %v24567_v31, %v24566_v46 (stack47)
        %v24958_v23 = vxor.u32 %v24957_v24, %v24953_v54 (stack48)
        %v25357_v52 = vshrl.u32 %v25347_v52, 8 (stack46)
        %v23799_v41 = vmul.f32 %v23795_v61, %v129545_v53 (stack54)
        %v24564_v6 = vadd.s32 %v24560_v30, %v121564_v0 (stack40)
        %v25767_v9 = vadd.s32 %v25764_v12, %v129540_v9 (stack40)
        %v25773_v42 = vshll.u32 %v25764_v12, 6 (stack45)
        %v24569_v43 = vxor.u32 %v24568_v27, %v24560_v30 (stack48)
        %v24961_v54 = vadd.s32 %v24958_v23, %v24953_v54 (stack40)
        %v24963_v21 = vshll.u32 %v24958_v23, 29 (stack45)
        %v24964_v26 = vshrl.u32 %v24958_v23, 3 (stack46)
        %v23803_v32 = vadd.f32 %v23799_v41, %v23724_v32 (stack53)
        %v25354_v30 = vadd.s32 %v25350_v8, %v121564_v0 (stack40)
        %v25358_v46 = vor.u32 %v25357_v52, %v25356_v10 (stack47)
        %v25774_v12 = vshrl.u32 %v25764_v12, 26 (stack46)
        %vm129592_vm9 = vcmp.lt.f32.partialorder %v24162_v34, 0.0004427343 (stack62)
        %v24572_v24 = vadd.s32 %v24569_v43, %v121574_v2 (stack40)
        %v24965_v61 = vor.u32 %v24964_v26, %v24963_v21 (stack47)
        %v26187_v34 = vadd.s32 1, %v26183_v29 (stack40)
        %v26207_v10 = vshrl.u32 %v129566_v40, 19 (stack46)
        %v23807_v27 = vmul.f32 %v23803_v32, %v129545_v53 (stack54)
        %v25359_v8 = vxor.u32 %v25358_v46, %v25350_v8 (stack48)
        %v25775_v23 = vor.u32 %v25774_v12, %v25773_v42 (stack47)
        %v157225_v52 = vld [vmem:[#allocation127_spill] sm:$0xff] (stack84)
        %v129601_v41 = vadd.s32 %v157225_v52, %v122651_v47 (stack40)
        %v24576_v42 = vadd.s32 5, %v24572_v24 (stack40)
        %v24966_v43 = vxor.u32 %v24965_v61, %v24961_v54 (stack48)
        %v26191_v44 = vsel /*vm=*/%vm26165_vm8, /*on_true_vy=*/%v26187_v34, /*on_false_vx=*/%v26183_v29 (stack44)
        %v26208_v50 = vor.u32 %v26207_v10, %v26206_v7 (stack47)
        %v23811_v55 = vadd.f32 %v23807_v27, %v129508_v55 (stack53)
        %v25362_v29 = vadd.s32 %v25359_v8, %v121574_v2 (stack40)
        %v25776_v7 = vxor.u32 %v25775_v23, %v25767_v9 (stack48)
        %v26196_v21 = vadd.s32 %v26191_v44, %v121574_v2 (stack40)
        %v24578_v6 = vxor.u32 %v24576_v42, %v24564_v6 (stack48)
        %v24969_v54 = vadd.s32 %v24966_v43, %v24961_v54 (stack40)
        %v24971_v26 = vshll.u32 %v24966_v43, 16 (stack45)
        %v24972_v32 = vshrl.u32 %v24966_v43, 16 (stack46)
        %v23815_v46 = vmul.f32 %v23811_v55, %v129545_v53 (stack54)
        %v25366_v12 = vadd.s32 2, %v25362_v29 (stack40)
        %v25779_v24 = vadd.s32 %v25776_v7, %v121564_v0 (stack40)
        %v26204_v40 = vadd.s32 %v129566_v40, %v26196_v21 (stack40)
        %v120634_v61 = vpop.eup %120633 (stack64)
        %v24161_v60 = vmul.f32 %v24160_v20, %v129571_v60 (stack63)
        %v24579_v20 = vand.u32.u8 255, %v24578_v6 (stack49)
        %v24973_v34 = vor.u32 %v24972_v32, %v24971_v26 (stack47)
        %vm26665_vm10 = vcmp.lt.u32.totalorder %v129601_v41, %v122651_v47 (stack43)
        %v23819_v22 = vadd.f32 %v23815_v46, %v129503_v22 (stack53)
        %v24158_v10 = vmul.f32 0.6931472, %v120634_v61 (stack65)
        %v25370_v30 = vadd.s32 %v25366_v12, %v25354_v30 (stack40)
        %v25771_v9 = vadd.s32 %v25767_v9, %v121569_v1 (stack40)
        %v24580_v27 = vand.u32 65535, %v24579_v20 (stack50)
        %v24974_v8 = vxor.u32 %v24973_v34, %v24969_v54 (stack48)
        %v25372_v23 = vshll.u32 %v25366_v12, 13 (stack45)
        %v25783_v42 = vadd.s32 1, %v25779_v24 (stack40)
        %v23823_v53 = vmul.f32 %v23819_v22, %v129545_v53 (stack54)
        %v24164_v31 = vsel /*vm=*/%vm129592_vm9, /*on_true_vy=*/%v24161_v60, /*on_false_vx=*/%v24158_v10 (stack66)
        %v25373_v43 = vshrl.u32 %v25366_v12, 19 (stack46)
        %v26209_v44 = vxor.u32 %v26208_v50, %v26204_v40 (stack48)
        %v23680_v50 = vand.u32 2147483647, %v129417_v56 (stack77)
        %v23712_v25 = vsel /*vm=*/%vm23707_vm4, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v129624_v55 = vxor.u32 2147483648, %v24164_v31 (stack56)
        %v24977_v29 = vadd.s32 %v24974_v8, %v24969_v54 (stack40)
        %v23827_v7 = vadd.f32 %v23823_v53, %v23712_v25 (stack53)
        %v25787_v21 = vadd.s32 %v25783_v42, %v25771_v9 (stack40)
        %v23688_v6 = vmul.f32 inf, %v129417_v56 (stack54)
        %120635 = vrsqrt.f32 %v129624_v55 (stack67)
        %v24581_v54 = vshrl.u32 %v24580_v27, 1 (stack51)
        %v23831_v56 = vmul.f32 %v23827_v7, %v129417_v56 (stack54)
        %v24983_v26 = vshll.u32 %v24974_v8, 24 (stack45)
        %v24984_v32 = vshrl.u32 %v24974_v8, 8 (stack46)
        %v25374_v46 = vor.u32 %v25373_v43, %v25372_v23 (stack47)
        %vm23683_vm11 = vcmp.eq.f32.partialorder %v23680_v50, 1.0 (stack68)
        %v23835_v12 = vsel /*vm=*/%vm23683_vm11, /*on_true_vy=*/%v23688_v6, /*on_false_vx=*/%v23831_v56 (stack44)
        %v24141_v24 = vand.u32 2147483647, %v129561_v11 (stack77)
        %v23839_v61 = vmul.f32 1.4140625, %v23835_v12 (stack54)
        %v129631_v60 = vadd.f32 -2.5, %v129624_v55 (stack53)
        %v24582_v20 = vor.u32 16256, %v24581_v54 (stack47)
        %v129635_v34 = vadd.s32 %v129601_v41, %v122657_v58 (stack40)
        %vm24168_vm12 = vcmp.lt.f32.partialorder %v129624_v55, 5.0 (stack68)
        %v24985_v22 = vor.u32 %v24984_v32, %v24983_v26 (stack47)
        %v25375_v10 = vxor.u32 %v25374_v46, %v25370_v30 (stack48)
        %v25789_v9 = vshll.u32 %v25783_v42, 17 (stack45)
        %v25790_v27 = vshrl.u32 %v25783_v42, 15 (stack46)
        %v23842_v8 = vpack.c.bf16 %v156663_v45, %v23839_v61 (stack81)
        %v24583_v23 = vand.u32.u16 65535, %v24582_v20 (stack52)
        %v26212_v40 = vadd.s32 %v26209_v44, %v26204_v40 (stack40)
        %v26214_v42 = vshll.u32 %v26209_v44, 15 (stack45)
        %v24986_v53 = vxor.u32 %v24985_v22, %v24977_v29 (stack48)
        %v25378_v30 = vadd.s32 %v25375_v10, %v25370_v30 (stack40)
        %v25380_v31 = vshll.u32 %v25375_v10, 15 (stack45)
        %v25381_v43 = vshrl.u32 %v25375_v10, 17 (stack46)
        %119871 = vst [vmem:[%s123356_s30 + $0x98] sm:$0xf] /*vst_source=*/%v23842_v8 (stack83)
        %v119874_v50 = vadd.low.f32.bf16 -1.0, %v24583_v23 (stack53)
        %v25791_v25 = vor.u32 %v25790_v27, %v25789_v9 (stack47)
        %v26215_v44 = vshrl.u32 %v26209_v44, 17 (stack46)
        %v157226_v7 = vld [vmem:[#allocation76_spill] sm:$0xff] (stack84)
        %v26670_v6 = vadd.s32 %v157226_v7, %v157068_v28 (stack40)
        %vm24213_vm13 = vcmp.eq.f32.partialorder %v129624_v55, inf (stack70)
        %v24989_v54 = vadd.s32 %v24986_v53, %v121564_v0 (stack40)
        %v25382_v56 = vor.u32 %v25381_v43, %v25380_v31 (stack47)
        %v129646_v26 = vadd.s32 %v157225_v52, %v157070_v38 (stack40)
        %v24216_v32 = vand.u32 2147483648, %v129624_v55 (stack72)
        %v24592_v46 = vmul.f32 2.0, %v119874_v50 (stack54)
        %v24981_v29 = vadd.s32 %v24977_v29, %v121569_v1 (stack40)
        %v25792_v12 = vxor.u32 %v25791_v25, %v25787_v21 (stack48)
        %v24993_v61 = vadd.s32 4, %v24989_v54 (stack40)
        %v25383_v20 = vxor.u32 %v25382_v56, %v25378_v30 (stack48)
        %v26216_v22 = vor.u32 %v26215_v44, %v26214_v42 (stack47)
        %v26674_v10 = vadd.s32 1, %v26670_v6 (stack40)
        %v24596_v9 = vadd.f32 -0.99609375, %v24592_v46 (stack53)
        %v25795_v21 = vadd.s32 %v25792_v12, %v25787_v21 (stack40)
        %v25797_v27 = vshll.u32 %v25792_v12, 29 (stack45)
        %v25798_v8 = vshrl.u32 %v25792_v12, 3 (stack46)
        %v120636_v23 = vpop.eup %120635 (stack73)
        %v24997_v42 = vadd.s32 %v24993_v61, %v24981_v29 (stack40)
        %v24999_v53 = vshll.u32 %v24993_v61, 13 (stack45)
        %v25000_v31 = vshrl.u32 %v24993_v61, 19 (stack46)
        %v25386_v30 = vadd.s32 %v25383_v20, %v25378_v30 (stack40)
        %v24212_v43 = vmul.f32 %v120636_v23, %v129624_v55 (stack74)
        %v129651_v50 = vmax.f32 %v24596_v9, -0.99609375 (stack55)
        %v25388_v25 = vshll.u32 %v25383_v20, 26 (stack45)
        %v25389_v44 = vshrl.u32 %v25383_v20, 6 (stack46)
        %v25001_v54 = vor.u32 %v25000_v31, %v24999_v53 (stack47)
        %v25799_v56 = vor.u32 %v25798_v8, %v25797_v27 (stack47)
        %v26217_v46 = vxor.u32 %v26216_v22, %v26212_v40 (stack48)
        %v26678_v6 = vsel /*vm=*/%vm26665_vm10, /*on_true_vy=*/%v26674_v10, /*on_false_vx=*/%v26670_v6 (stack44)
        %v129659_v29 = vsel /*vm=*/%vm24168_vm12, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v24214_v12 = vsel /*vm=*/%vm24213_vm13, /*on_true_vy=*/%v129624_v55, /*on_false_vx=*/%v24212_v43 (stack75)
        %vm24215_vm14 = vcmp.eq.f32.partialorder %v129624_v55, 0.0 (stack71)
        %v24612_v61 = vxor.u32 2147483648, %v129651_v50 (stack56)
        %v24217_v32 = vsel /*vm=*/%vm24215_vm14, /*on_true_vy=*/%v24216_v32, /*on_false_vx=*/%v24214_v12 (stack76)
        %v25002_v20 = vxor.u32 %v25001_v54, %v24997_v42 (stack48)
        %v25390_v22 = vor.u32 %v25389_v44, %v25388_v25 (stack47)
        %v25800_v10 = vxor.u32 %v25799_v56, %v25795_v21 (stack48)
        %v129669_v9 = vsel /*vm=*/%vm24168_vm12, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v24220_v27 = vadd.f32 -3.0, %v24217_v32 (stack53)
        %v129672_v8 = vmul.f32 %v24612_v61, %v129651_v50 (stack54)
        %v129674_v40 = vadd.s32 %v26217_v46, %v26212_v40 (stack40)
        %vm26660_vm15 = vcmp.lt.u32.totalorder %v129635_v34, %v129601_v41 (stack43)
        %v25005_v23 = vadd.s32 %v25002_v20, %v24997_v42 (stack40)
        %v25007_v42 = vshll.u32 %v25002_v20, 15 (stack45)
        %v25008_v53 = vshrl.u32 %v25002_v20, 17 (stack46)
        %v25391_v31 = vxor.u32 %v25390_v22, %v25386_v30 (stack48)
        %v24193_v43 = vsel /*vm=*/%vm24168_vm12, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v24205_v25 = vsel /*vm=*/%vm24168_vm12, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v129687_v60 = vsel /*vm=*/%vm24168_vm12, /*on_true_vy=*/%v129631_v60, /*on_false_vx=*/%v24220_v27 (stack44)
        %v24617_v44 = vadd.f32 1.0, %v129672_v8 (stack57)
        %v24228_v54 = vmul.f32 %v129687_v60, %v24205_v25 (stack54)
        %v25009_v56 = vor.u32 %v25008_v53, %v25007_v42 (stack47)
        %v25394_v30 = vadd.s32 %v25391_v31, %v25386_v30 (stack40)
        %v25400_v12 = vshll.u32 %v25391_v31, 6 (stack45)
        %v24197_v61 = vsel /*vm=*/%vm24168_vm12, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v24201_v32 = vsel /*vm=*/%vm24168_vm12, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %120637 = vlog2.f32 %v24617_v44 (stack58)
        %v25401_v20 = vshrl.u32 %v25391_v31, 26 (stack46)
        %v24232_v22 = vadd.f32 %v24228_v54, %v24201_v32 (stack53)
        %v24620_v27 = vmul.f32 -0.5, %v129672_v8 (stack59)
        %v25010_v42 = vxor.u32 %v25009_v56, %v25005_v23 (stack48)
        %v25803_v21 = vadd.s32 %v25800_v10, %v25795_v21 (stack40)
        %v25402_v53 = vor.u32 %v25401_v20, %v25400_v12 (stack47)
        %v25805_v31 = vshll.u32 %v25800_v10, 16 (stack45)
        %v25806_v10 = vshrl.u32 %v25800_v10, 16 (stack46)
        %v129700_v25 = vadd.s32 %v129635_v34, %v121569_v1 (stack40)
        %v24236_v44 = vmul.f32 %v24232_v22, %v129687_v60 (stack54)
        %v25013_v23 = vadd.s32 %v25010_v42, %v25005_v23 (stack40)
        %v25015_v54 = vshll.u32 %v25010_v42, 26 (stack45)
        %v25016_v56 = vshrl.u32 %v25010_v42, 6 (stack46)
        %v25403_v12 = vxor.u32 %v25402_v53, %v25394_v30 (stack48)
        %v25807_v32 = vor.u32 %v25806_v10, %v25805_v31 (stack47)
        %v26222_v20 = vshll.u32 %v26217_v46, 26 (stack45)
        %v26223_v46 = vshrl.u32 %v26217_v46, 6 (stack46)
        %v24240_v61 = vadd.f32 %v24236_v44, %v24197_v61 (stack53)
        %v24621_v22 = vadd.f32 1.0, %v24620_v27 (stack61)
        %v25017_v27 = vor.u32 %v25016_v56, %v25015_v54 (stack47)
        %v26682_v42 = vadd.s32 1, %v26678_v6 (stack40)
        %v25398_v30 = vadd.s32 %v25394_v30, %v121574_v2 (stack40)
        %v25406_v53 = vadd.s32 %v25403_v12, %v121569_v1 (stack40)
        %v25808_v31 = vxor.u32 %v25807_v32, %v25803_v21 (stack48)
        %v26224_v10 = vor.u32 %v26223_v46, %v26222_v20 (stack47)
        %v24244_v44 = vmul.f32 %v24240_v61, %v129687_v60 (stack54)
        %v25018_v54 = vxor.u32 %v25017_v27, %v25013_v23 (stack48)
        %v26686_v41 = vsel /*vm=*/%vm26660_vm15, /*on_true_vy=*/%v26682_v42, /*on_false_vx=*/%v26678_v6 (stack44)
        %vm27126_vm0 = vcmp.lt.u32.totalorder %v129646_v26, %v157070_v38 (stack43)
        %v25410_v34 = vadd.s32 3, %v25406_v53 (stack40)
        %v25811_v6 = vadd.s32 %v25808_v31, %v25803_v21 (stack40)
        %v25817_v21 = vshll.u32 %v25808_v31, 24 (stack45)
        %v25818_v56 = vshrl.u32 %v25808_v31, 8 (stack46)
        %v24248_v43 = vadd.f32 %v24244_v44, %v24193_v43 (stack53)
        %v25021_v23 = vadd.s32 %v25018_v54, %v25013_v23 (stack40)
        %v25027_v12 = vshll.u32 %v25018_v54, 6 (stack45)
        %v25028_v32 = vshrl.u32 %v25018_v54, 26 (stack46)
        %v25414_v20 = vadd.s32 %v25410_v34, %v25398_v30 (stack40)
        %v25416_v46 = vshll.u32 %v25410_v34, 17 (stack45)
        %v25417_v61 = vshrl.u32 %v25410_v34, 15 (stack46)
        %v26701_v27 = vshll.u32 %v129700_v25, 13 (stack45)
        %v24252_v42 = vmul.f32 %v24248_v43, %v129687_v60 (stack54)
        %v24623_v30 = vand.u32 2147483647, %v129672_v8 (stack60)
        %v25029_v53 = vor.u32 %v25028_v32, %v25027_v12 (stack47)
        %v25819_v31 = vor.u32 %v25818_v56, %v25817_v21 (stack47)
        %v24622_v8 = vmul.f32 %v24621_v22, %v129672_v8 (stack63)
        %v25418_v22 = vor.u32 %v25417_v61, %v25416_v46 (stack47)
        %v26225_v10 = vxor.u32 %v26224_v10, %v129674_v40 (stack48)
        %v26702_v44 = vshrl.u32 %v129700_v25, 19 (stack46)
        %v120638_v54 = vpop.eup %120637 (stack64)
        %v24256_v9 = vadd.f32 %v24252_v42, %v129669_v9 (stack53)
        %v25030_v34 = vxor.u32 %v25029_v53, %v25021_v23 (stack48)
        %v25820_v21 = vxor.u32 %v25819_v31, %v25811_v6 (stack48)
        %v129720_v56 = vadd.s32 %v157226_v7, %v157076_v35 (stack40)
        %v24619_v43 = vmul.f32 0.6931472, %v120638_v54 (stack65)
        %v25419_v12 = vxor.u32 %v25418_v22, %v25414_v20 (stack48)
        %v26228_v40 = vadd.s32 %v26225_v10, %v129674_v40 (stack40)
        %v26691_v41 = vadd.s32 %v26686_v41, %v121574_v2 (stack40)
        %v24260_v32 = vmul.f32 %v24256_v9, %v129687_v60 (stack54)
        %vm24624_vm1 = vcmp.lt.f32.partialorder %v24623_v30, 0.0004427343 (stack62)
        %v25025_v23 = vadd.s32 %v25021_v23, %v121564_v0 (stack40)
        %v25033_v46 = vadd.s32 %v25030_v34, %v121574_v2 (stack40)
        %v24625_v61 = vsel /*vm=*/%vm24624_vm1, /*on_true_vy=*/%v24622_v8, /*on_false_vx=*/%v24619_v43 (stack66)
        %v25422_v20 = vadd.s32 %v25419_v12, %v25414_v20 (stack40)
        %v25424_v42 = vshll.u32 %v25419_v12, 29 (stack45)
        %v25425_v30 = vshrl.u32 %v25419_v12, 3 (stack46)
        %v24264_v29 = vadd.f32 %v24260_v32, %v129659_v29 (stack53)
        %v129728_v53 = vxor.u32 2147483648, %v24625_v61 (stack56)
        %v25037_v31 = vadd.s32 5, %v25033_v46 (stack40)
        %v25823_v8 = vadd.s32 %v25820_v21, %v121574_v2 (stack40)
        %v25426_v22 = vor.u32 %v25425_v30, %v25424_v42 (stack47)
        %v26234_v54 = vshll.u32 %v26225_v10, 6 (stack45)
        %v26235_v10 = vshrl.u32 %v26225_v10, 26 (stack46)
        %v26699_v25 = vadd.s32 %v129700_v25, %v26691_v41 (stack40)
        %v129733_v9 = vmul.f32 inf, %v129561_v11 (stack54)
        %v24173_v34 = vsel /*vm=*/%vm24168_vm12, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v24268_v21 = vmul.f32 %v24264_v29, %v129687_v60 (stack54)
        %120639 = vrsqrt.f32 %v129728_v53 (stack67)
        %v24177_v43 = vsel /*vm=*/%vm24168_vm12, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v24181_v55 = vsel /*vm=*/%vm24168_vm12, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %vm24629_vm2 = vcmp.lt.f32.partialorder %v129728_v53, 5.0 (stack68)
        %v25039_v12 = vxor.u32 %v25037_v31, %v25025_v23 (stack48)
        %v24272_v41 = vadd.f32 %v24268_v21, %v24181_v55 (stack53)
        %v25827_v32 = vadd.s32 2, %v25823_v8 (stack40)
        %v26703_v27 = vor.u32 %v26702_v44, %v26701_v27 (stack47)
        %v129749_v44 = vadd.s32 %v129646_v26, %v122657_v58 (stack40)
        %v25427_v23 = vxor.u32 %v25426_v22, %v25422_v20 (stack48)
        %v25815_v6 = vadd.s32 %v25811_v6, %v121564_v0 (stack40)
        %v26232_v46 = vadd.s32 %v26228_v40, %v121569_v1 (stack40)
        %v26236_v61 = vor.u32 %v26235_v10, %v26234_v54 (stack47)
        %v24276_v42 = vmul.f32 %v24272_v41, %v129687_v60 (stack54)
        %v129757_v30 = vsel /*vm=*/%vm24629_vm2, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v129762_v29 = vsel /*vm=*/%vm24629_vm2, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v129765_v31 = vadd.f32 -2.5, %v129728_v53 (stack53)
        %vm129769_vm3 = vcmp.eq.f32.partialorder %v24141_v24, 1.0 (stack68)
        %v25040_v8 = vand.u32.u8 255, %v25039_v12 (stack49)
        %v25430_v20 = vadd.s32 %v25427_v23, %v25422_v20 (stack40)
        %v25432_v22 = vshll.u32 %v25427_v23, 16 (stack45)
        %v25433_v54 = vshrl.u32 %v25427_v23, 16 (stack46)
        %v24280_v10 = vadd.f32 %v24276_v42, %v24177_v43 (stack53)
        %v25831_v21 = vadd.s32 %v25827_v32, %v25815_v6 (stack40)
        %v25833_v43 = vshll.u32 %v25827_v32, 13 (stack45)
        %v25834_v55 = vshrl.u32 %v25827_v32, 19 (stack46)
        %vm24674_vm4 = vcmp.eq.f32.partialorder %v129728_v53, inf (stack70)
        %v25041_v12 = vand.u32 65535, %v25040_v8 (stack50)
        %v25434_v41 = vor.u32 %v25433_v54, %v25432_v22 (stack47)
        %v26237_v40 = vxor.u32 %v26236_v61, %v26228_v40 (stack48)
        %v26704_v32 = vxor.u32 %v26703_v27, %v26699_v25 (stack48)
        %v24284_v60 = vmul.f32 %v24280_v10, %v129687_v60 (stack54)
        %vm24676_vm5 = vcmp.eq.f32.partialorder %v129728_v53, 0.0 (stack71)
        %v24677_v27 = vand.u32 2147483648, %v129728_v53 (stack72)
        %v25835_v23 = vor.u32 %v25834_v55, %v25833_v43 (stack47)
        %v27135_v6 = vadd.s32 1, %v129720_v56 (stack40)
        %v25042_v61 = vshrl.u32 %v25041_v12, 1 (stack51)
        %v25435_v42 = vxor.u32 %v25434_v41, %v25430_v20 (stack48)
        %v26240_v8 = vadd.s32 %v26237_v40, %v121564_v0 (stack40)
        %v26707_v25 = vadd.s32 %v26704_v32, %v26699_v25 (stack40)
        %v24288_v34 = vadd.f32 %v24284_v60, %v24173_v34 (stack53)
        %v25836_v22 = vxor.u32 %v25835_v23, %v25831_v21 (stack48)
        %v26709_v54 = vshll.u32 %v26704_v32, 15 (stack45)
        %v26710_v10 = vshrl.u32 %v26704_v32, 17 (stack46)
        %v25043_v43 = vor.u32 16256, %v25042_v61 (stack47)
        %v25438_v20 = vadd.s32 %v25435_v42, %v25430_v20 (stack40)
        %v25444_v55 = vshll.u32 %v25435_v42, 24 (stack45)
        %v25445_v12 = vshrl.u32 %v25435_v42, 8 (stack46)
        %v24292_v11 = vmul.f32 %v24288_v34, %v129561_v11 (stack54)
        %v25839_v21 = vadd.s32 %v25836_v22, %v25831_v21 (stack40)
        %v25841_v41 = vshll.u32 %v25836_v22, 15 (stack45)
        %v25842_v40 = vshrl.u32 %v25836_v22, 17 (stack46)
        %v120640_v32 = vpop.eup %120639 (stack73)
        %v25044_v60 = vand.u32.u16 65535, %v25043_v43 (stack52)
        %v25442_v23 = vadd.s32 %v25438_v20, %v121569_v1 (stack40)
        %v25446_v61 = vor.u32 %v25445_v12, %v25444_v55 (stack47)
        %v26244_v42 = vadd.s32 1, %v26240_v8 (stack40)
        %v24296_v9 = vsel /*vm=*/%vm129769_vm3, /*on_true_vy=*/%v129733_v9, /*on_false_vx=*/%v24292_v11 (stack44)
        %v24673_v24 = vmul.f32 %v120640_v32, %v129728_v53 (stack74)
        %v25843_v8 = vor.u32 %v25842_v40, %v25841_v41 (stack47)
        %v26711_v34 = vor.u32 %v26710_v10, %v26709_v54 (stack47)
        %v24300_v22 = vmul.f32 1.4140625, %v24296_v9 (stack54)
        %v119876_v54 = vadd.low.f32.bf16 -1.0, %v25044_v60 (stack53)
        %v25447_v10 = vxor.u32 %v25446_v61, %v25438_v20 (stack48)
        %v26248_v46 = vadd.s32 %v26244_v42, %v26232_v46 (stack40)
        %v24675_v43 = vsel /*vm=*/%vm24674_vm4, /*on_true_vy=*/%v129728_v53, /*on_false_vx=*/%v24673_v24 (stack75)
        %v25844_v20 = vxor.u32 %v25843_v8, %v25839_v21 (stack48)
        %v26250_v55 = vshll.u32 %v26244_v42, 17 (stack45)
        %v26251_v12 = vshrl.u32 %v26244_v42, 15 (stack46)
        %v24303_v11 = vpack.c.bf16 %v156663_v45, %v24300_v22 (stack81)
        %v24678_v27 = vsel /*vm=*/%vm24676_vm5, /*on_true_vy=*/%v24677_v27, /*on_false_vx=*/%v24675_v43 (stack76)
        %v25053_v41 = vmul.f32 2.0, %v119876_v54 (stack54)
        %v25450_v40 = vadd.s32 %v25447_v10, %v121564_v0 (stack40)
        %v24681_v32 = vadd.f32 -3.0, %v24678_v27 (stack53)
        %v25847_v21 = vadd.s32 %v25844_v20, %v25839_v21 (stack40)
        %v25849_v60 = vshll.u32 %v25844_v20, 26 (stack45)
        %v25850_v61 = vshrl.u32 %v25844_v20, 6 (stack46)
        %119873 = vst [vmem:[%s123356_s30 + $0x118] sm:$0xf] /*vst_source=*/%v24303_v11 (stack83)
        %v25057_v42 = vadd.f32 -0.99609375, %v25053_v41 (stack53)
        %v25454_v9 = vadd.s32 4, %v25450_v40 (stack40)
        %v26252_v24 = vor.u32 %v26251_v12, %v26250_v55 (stack47)
        %v26712_v8 = vxor.u32 %v26711_v34, %v26707_v25 (stack48)
        %v24666_v34 = vsel /*vm=*/%vm24629_vm2, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v129799_v31 = vsel /*vm=*/%vm24629_vm2, /*on_true_vy=*/%v129765_v31, /*on_false_vx=*/%v24681_v32 (stack44)
        %v25851_v22 = vor.u32 %v25850_v61, %v25849_v60 (stack47)
        %v27139_v56 = vsel /*vm=*/%vm27126_vm0, /*on_true_vy=*/%v27135_v6, /*on_false_vx=*/%v129720_v56 (stack44)
        %v24689_v6 = vmul.f32 %v129799_v31, %v24666_v34 (stack54)
        %v129806_v54 = vmax.f32 %v25057_v42, -0.99609375 (stack55)
        %v25458_v23 = vadd.s32 %v25454_v9, %v25442_v23 (stack40)
        %v25460_v10 = vshll.u32 %v25454_v9, 13 (stack45)
        %v25461_v43 = vshrl.u32 %v25454_v9, 19 (stack46)
        %v25852_v20 = vxor.u32 %v25851_v22, %v25847_v21 (stack48)
        %v26253_v55 = vxor.u32 %v26252_v24, %v26248_v46 (stack48)
        %v129808_v25 = vadd.s32 %v26712_v8, %v26707_v25 (stack40)
        %vm27121_vm6 = vcmp.lt.u32.totalorder %v129749_v44, %v129646_v26 (stack43)
        %v129815_v12 = vsel /*vm=*/%vm24629_vm2, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v24650_v11 = vsel /*vm=*/%vm24629_vm2, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v24693_v29 = vadd.f32 %v24689_v6, %v129762_v29 (stack53)
        %v25073_v27 = vxor.u32 2147483648, %v129806_v54 (stack56)
        %v25462_v41 = vor.u32 %v25461_v43, %v25460_v10 (stack47)
        %v25855_v40 = vadd.s32 %v25852_v20, %v25847_v21 (stack40)
        %v25861_v32 = vshll.u32 %v25852_v20, 6 (stack45)
        %v25862_v21 = vshrl.u32 %v25852_v20, 26 (stack46)
        %v24697_v60 = vmul.f32 %v24693_v29, %v129799_v31 (stack54)
        %v129824_v61 = vmul.f32 %v25073_v27, %v129806_v54 (stack54)
        %v26256_v46 = vadd.s32 %v26253_v55, %v26248_v46 (stack40)
        %v129828_v42 = vadd.s32 %v129749_v44, %v121569_v1 (stack40)
        %v24654_v9 = vsel /*vm=*/%vm24629_vm2, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v24658_v24 = vsel /*vm=*/%vm24629_vm2, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v25463_v34 = vxor.u32 %v25462_v41, %v25458_v23 (stack48)
        %v25863_v22 = vor.u32 %v25862_v21, %v25861_v32 (stack47)
        %v24701_v6 = vadd.f32 %v24697_v60, %v24658_v24 (stack53)
        %v25078_v10 = vadd.f32 1.0, %v129824_v61 (stack57)
        %v25081_v43 = vmul.f32 -0.5, %v129824_v61 (stack59)
        %v26258_v20 = vshll.u32 %v26253_v55, 29 (stack45)
        %v25466_v23 = vadd.s32 %v25463_v34, %v25458_v23 (stack40)
        %v25468_v29 = vshll.u32 %v25463_v34, 15 (stack45)
        %v25469_v27 = vshrl.u32 %v25463_v34, 17 (stack46)
        %v25864_v41 = vxor.u32 %v25863_v22, %v25855_v40 (stack48)
        %v24705_v32 = vmul.f32 %v24701_v6, %v129799_v31 (stack54)
        %120641 = vlog2.f32 %v25078_v10 (stack58)
        %v25859_v40 = vadd.s32 %v25855_v40, %v121574_v2 (stack40)
        %v27162_v21 = vshll.u32 %v129828_v42, 13 (stack45)
        %v25470_v60 = vor.u32 %v25469_v27, %v25468_v29 (stack47)
        %v25867_v24 = vadd.s32 %v25864_v41, %v121569_v1 (stack40)
        %v26259_v55 = vshrl.u32 %v26253_v55, 3 (stack46)
        %v26717_v34 = vshll.u32 %v26712_v8, 26 (stack45)
        %v24709_v9 = vadd.f32 %v24705_v32, %v24654_v9 (stack53)
        %v25084_v22 = vand.u32 2147483647, %v129824_v61 (stack60)
        %v26718_v8 = vshrl.u32 %v26712_v8, 6 (stack46)
        %v27143_v6 = vadd.s32 1, %v27139_v56 (stack40)
        %v25082_v10 = vadd.f32 1.0, %v25081_v43 (stack61)
        %v25471_v43 = vxor.u32 %v25470_v60, %v25466_v23 (stack48)
        %v25871_v29 = vadd.s32 3, %v25867_v24 (stack40)
        %v26260_v20 = vor.u32 %v26259_v55, %v26258_v20 (stack47)
        %v24713_v27 = vmul.f32 %v24709_v9, %v129799_v31 (stack54)
        %v26719_v41 = vor.u32 %v26718_v8, %v26717_v34 (stack47)
        %v27147_v26 = vsel /*vm=*/%vm27121_vm6, /*on_true_vy=*/%v27143_v6, /*on_false_vx=*/%v27139_v56 (stack44)
        %v129849_v44 = vadd.s32 %v157225_v52, %v157077_v51 (stack40)
        %v25474_v56 = vadd.s32 %v25471_v43, %v25466_v23 (stack40)
        %v25476_v23 = vshll.u32 %v25471_v43, 26 (stack45)
        %v25477_v32 = vshrl.u32 %v25471_v43, 6 (stack46)
        %v25875_v40 = vadd.s32 %v25871_v29, %v25859_v40 (stack40)
        %v24717_v11 = vadd.f32 %v24713_v27, %v24650_v11 (stack53)
        %v25877_v60 = vshll.u32 %v25871_v29, 17 (stack45)
        %v25878_v24 = vshrl.u32 %v25871_v29, 15 (stack46)
        %v26261_v55 = vxor.u32 %v26260_v20, %v26256_v46 (stack48)
        %vm129851_vm7 = vcmp.lt.f32.partialorder %v25084_v22, 0.0004427343 (stack62)
        %v25478_v9 = vor.u32 %v25477_v32, %v25476_v23 (stack47)
        %v26720_v22 = vxor.u32 %v26719_v41, %v129808_v25 (stack48)
        %v27152_v8 = vadd.s32 %v27147_v26, %v121574_v2 (stack40)
        %v24721_v6 = vmul.f32 %v24717_v11, %v129799_v31 (stack54)
        %v25879_v43 = vor.u32 %v25878_v24, %v25877_v60 (stack47)
        %v26264_v46 = vadd.s32 %v26261_v55, %v26256_v46 (stack40)
        %v26266_v29 = vshll.u32 %v26261_v55, 16 (stack45)
        %v25479_v20 = vxor.u32 %v25478_v9, %v25474_v56 (stack48)
        %v26267_v27 = vshrl.u32 %v26261_v55, 16 (stack46)
        %v26723_v25 = vadd.s32 %v26720_v22, %v129808_v25 (stack40)
        %v26729_v41 = vshll.u32 %v26720_v22, 6 (stack45)
        %v24725_v12 = vadd.f32 %v24721_v6, %v129815_v12 (stack53)
        %v25880_v26 = vxor.u32 %v25879_v43, %v25875_v40 (stack48)
        %v26730_v23 = vshrl.u32 %v26720_v22, 26 (stack46)
        %v129861_v32 = vadd.s32 %v129828_v42, %v27152_v8 (stack40)
        %v25482_v56 = vadd.s32 %v25479_v20, %v25474_v56 (stack40)
        %v25488_v11 = vshll.u32 %v25479_v20, 6 (stack45)
        %v25489_v60 = vshrl.u32 %v25479_v20, 26 (stack46)
        %v26268_v24 = vor.u32 %v26267_v27, %v26266_v29 (stack47)
        %v24729_v55 = vmul.f32 %v24725_v12, %v129799_v31 (stack54)
        %v25883_v40 = vadd.s32 %v25880_v26, %v25875_v40 (stack40)
        %v25885_v9 = vshll.u32 %v25880_v26, 29 (stack45)
        %v25886_v22 = vshrl.u32 %v25880_v26, 3 (stack46)
        %v120642_v8 = vpop.eup %120641 (stack64)
        %v25083_v61 = vmul.f32 %v25082_v10, %v129824_v61 (stack63)
        %v25490_v10 = vor.u32 %v25489_v60, %v25488_v11 (stack47)
        %v26269_v6 = vxor.u32 %v26268_v24, %v26264_v46 (stack48)
        %v27163_v43 = vshrl.u32 %v129828_v42, 19 (stack46)
        %v24733_v30 = vadd.f32 %v24729_v55, %v129757_v30 (stack53)
        %v25080_v29 = vmul.f32 0.6931472, %v120642_v8 (stack65)
        %v25887_v20 = vor.u32 %v25886_v22, %v25885_v9 (stack47)
        %v26731_v27 = vor.u32 %v26730_v23, %v26729_v41 (stack47)
        %v25491_v41 = vxor.u32 %v25490_v10, %v25482_v56 (stack48)
        %v26272_v46 = vadd.s32 %v26269_v6, %v26264_v46 (stack40)
        %v26278_v12 = vshll.u32 %v26269_v6, 24 (stack45)
        %v26279_v26 = vshrl.u32 %v26269_v6, 8 (stack46)
        %v24737_v23 = vmul.f32 %v24733_v30, %v129799_v31 (stack54)
        %v25086_v34 = vsel /*vm=*/%vm129851_vm7, /*on_true_vy=*/%v25083_v61, /*on_false_vx=*/%v25080_v29 (stack66)
        %v25888_v11 = vxor.u32 %v25887_v20, %v25883_v40 (stack48)
        %v26732_v60 = vxor.u32 %v26731_v27, %v26723_v25 (stack48)
        %v24602_v24 = vand.u32 2147483647, %v129651_v50 (stack77)
        %v24638_v55 = vsel /*vm=*/%vm24629_vm2, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v129874_v9 = vxor.u32 2147483648, %v25086_v34 (stack56)
        %v24741_v22 = vadd.f32 %v24737_v23, %v24638_v55 (stack53)
        %v25891_v40 = vadd.s32 %v25888_v11, %v25883_v40 (stack40)
        %v25893_v8 = vshll.u32 %v25888_v11, 16 (stack45)
        %v25894_v61 = vshrl.u32 %v25888_v11, 16 (stack46)
        %120643 = vrsqrt.f32 %v129874_v9 (stack67)
        %v25494_v10 = vadd.s32 %v25491_v41, %v121574_v2 (stack40)
        %v24745_v31 = vmul.f32 %v24741_v22, %v129799_v31 (stack54)
        %vm25090_vm8 = vcmp.lt.f32.partialorder %v129874_v9, 5.0 (stack68)
        %v26280_v6 = vor.u32 %v26279_v26, %v26278_v12 (stack47)
        %v27164_v42 = vor.u32 %v27163_v43, %v27162_v21 (stack47)
        %vm129882_vm9 = vcmp.eq.f32.partialorder %v24602_v24, 1.0 (stack68)
        %v24610_v43 = vmul.f32 inf, %v129651_v50 (stack54)
        %v24634_v53 = vsel /*vm=*/%vm24629_vm2, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v25895_v30 = vor.u32 %v25894_v61, %v25893_v8 (stack47)
        %v24749_v29 = vadd.f32 %v24745_v31, %v24634_v53 (stack53)
        %v25486_v56 = vadd.s32 %v25482_v56, %v121564_v0 (stack40)
        %v26276_v20 = vadd.s32 %v26272_v46, %v121564_v0 (stack40)
        %v26727_v25 = vadd.s32 %v26723_v25, %v121569_v1 (stack40)
        %v129896_v27 = vsel /*vm=*/%vm25090_vm8, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v129899_v41 = vadd.f32 -2.5, %v129874_v9 (stack53)
        %v25498_v12 = vadd.s32 5, %v25494_v10 (stack40)
        %v25896_v26 = vxor.u32 %v25895_v30, %v25891_v40 (stack48)
        %v24753_v50 = vmul.f32 %v24749_v29, %v129651_v50 (stack54)
        %v26281_v46 = vxor.u32 %v26280_v6, %v26272_v46 (stack48)
        %v26735_v23 = vadd.s32 %v26732_v60, %v121564_v0 (stack40)
        %v27165_v34 = vxor.u32 %v27164_v42, %v129861_v32 (stack48)
        %v25500_v11 = vxor.u32 %v25498_v12, %v25486_v56 (stack48)
        %v25899_v60 = vadd.s32 %v25896_v26, %v25891_v40 (stack40)
        %v25905_v24 = vshll.u32 %v25896_v26, 24 (stack45)
        %v25906_v55 = vshrl.u32 %v25896_v26, 8 (stack46)
        %v24757_v22 = vsel /*vm=*/%vm129882_vm9, /*on_true_vy=*/%v24610_v43, /*on_false_vx=*/%v24753_v50 (stack44)
        %vm25135_vm10 = vcmp.eq.f32.partialorder %v129874_v9, inf (stack70)
        %v26284_v40 = vadd.s32 %v26281_v46, %v121574_v2 (stack40)
        %v26739_v8 = vadd.s32 1, %v26735_v23 (stack40)
        %v27168_v32 = vadd.s32 %v27165_v34, %v129861_v32 (stack40)
        %v24761_v61 = vmul.f32 1.4140625, %v24757_v22 (stack54)
        %vm25137_vm11 = vcmp.eq.f32.partialorder %v129874_v9, 0.0 (stack71)
        %v25138_v10 = vand.u32 2147483648, %v129874_v9 (stack72)
        %v25501_v31 = vand.u32.u8 255, %v25500_v11 (stack49)
        %v25907_v6 = vor.u32 %v25906_v55, %v25905_v24 (stack47)
        %v26288_v42 = vadd.s32 2, %v26284_v40 (stack40)
        %v26743_v21 = vadd.s32 %v26739_v8, %v26727_v25 (stack40)
        %v26745_v43 = vshll.u32 %v26739_v8, 17 (stack45)
        %v26746_v53 = vshrl.u32 %v26739_v8, 15 (stack46)
        %v24764_v30 = vpack.c.bf16 %v156663_v45, %v24761_v61 (stack81)
        %v25502_v29 = vand.u32 65535, %v25501_v31 (stack50)
        %v25908_v56 = vxor.u32 %v25907_v6, %v25899_v60 (stack48)
        %v27170_v25 = vshll.u32 %v27165_v34, 15 (stack45)
        %v26292_v20 = vadd.s32 %v26288_v42, %v26276_v20 (stack40)
        %v26294_v12 = vshll.u32 %v26288_v42, 13 (stack45)
        %v26295_v26 = vshrl.u32 %v26288_v42, 19 (stack46)
        %v26747_v50 = vor.u32 %v26746_v53, %v26745_v43 (stack47)
        %119875 = vst [vmem:[%s123356_s30 + $0x198] sm:$0xf] /*vst_source=*/%v24764_v30 (stack83)
        %v25503_v46 = vshrl.u32 %v25502_v29, 1 (stack51)
        %v25903_v23 = vadd.s32 %v25899_v60, %v121569_v1 (stack40)
        %v25911_v11 = vadd.s32 %v25908_v56, %v121564_v0 (stack40)
        %v27171_v34 = vshrl.u32 %v27165_v34, 17 (stack46)
        %v120644_v60 = vpop.eup %120643 (stack73)
        %v26296_v24 = vor.u32 %v26295_v26, %v26294_v12 (stack47)
        %v26748_v55 = vxor.u32 %v26747_v50, %v26743_v21 (stack48)
        %vm27587_vm12 = vcmp.lt.u32.totalorder %v129849_v44, %v157077_v51 (stack43)
        %v27592_v22 = vadd.s32 %v157226_v7, %v157078_v48 (stack40)
        %v25134_v40 = vmul.f32 %v120644_v60, %v129874_v9 (stack74)
        %v25504_v8 = vor.u32 16256, %v25503_v46 (stack47)
        %v25915_v61 = vadd.s32 4, %v25911_v11 (stack40)
        %v27172_v31 = vor.u32 %v27171_v34, %v27170_v25 (stack47)
        %v26297_v6 = vxor.u32 %v26296_v24, %v26292_v20 (stack48)
        %v26751_v42 = vadd.s32 %v26748_v55, %v26743_v21 (stack40)
        %v26753_v21 = vshll.u32 %v26748_v55, 29 (stack45)
        %v26754_v43 = vshrl.u32 %v26748_v55, 3 (stack46)
        %v25136_v53 = vsel /*vm=*/%vm25135_vm10, /*on_true_vy=*/%v129874_v9, /*on_false_vx=*/%v25134_v40 (stack75)
        %v25505_v30 = vand.u32.u16 65535, %v25504_v8 (stack52)
        %v25919_v29 = vadd.s32 %v25915_v61, %v25903_v23 (stack40)
        %v25921_v56 = vshll.u32 %v25915_v61, 13 (stack45)
        %v25139_v10 = vsel /*vm=*/%vm25137_vm11, /*on_true_vy=*/%v25138_v10, /*on_false_vx=*/%v25136_v53 (stack76)
        %v25922_v25 = vshrl.u32 %v25915_v61, 19 (stack46)
        %v26300_v20 = vadd.s32 %v26297_v6, %v26292_v20 (stack40)
        %v26302_v12 = vshll.u32 %v26297_v6, 15 (stack45)
        %v25142_v26 = vadd.f32 -3.0, %v25139_v10 (stack53)
        %v119878_v50 = vadd.low.f32.bf16 -1.0, %v25505_v30 (stack53)
        %v26303_v46 = vshrl.u32 %v26297_v6, 17 (stack46)
        %v26755_v23 = vor.u32 %v26754_v43, %v26753_v21 (stack47)
        %v25119_v11 = vsel /*vm=*/%vm25090_vm8, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v25127_v34 = vsel /*vm=*/%vm25090_vm8, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v25923_v60 = vor.u32 %v25922_v25, %v25921_v56 (stack47)
        %v27173_v24 = vxor.u32 %v27172_v31, %v27168_v32 (stack48)
        %v129934_v41 = vsel /*vm=*/%vm25090_vm8, /*on_true_vy=*/%v129899_v41, /*on_false_vx=*/%v25142_v26 (stack44)
        %v25514_v55 = vmul.f32 2.0, %v119878_v50 (stack54)
        %v26304_v40 = vor.u32 %v26303_v46, %v26302_v12 (stack47)
        %v26756_v8 = vxor.u32 %v26755_v23, %v26751_v42 (stack48)
        %v25123_v61 = vsel /*vm=*/%vm25090_vm8, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v25150_v31 = vmul.f32 %v129934_v41, %v25127_v34 (stack54)
        %v25924_v6 = vxor.u32 %v25923_v60, %v25919_v29 (stack48)
        %v129940_v32 = vadd.s32 %v27173_v24, %v27168_v32 (stack40)
        %v25518_v21 = vadd.f32 -0.99609375, %v25514_v55 (stack53)
        %v26305_v43 = vxor.u32 %v26304_v40, %v26300_v20 (stack48)
        %v26759_v42 = vadd.s32 %v26756_v8, %v26751_v42 (stack40)
        %v26761_v53 = vshll.u32 %v26756_v8, 16 (stack45)
        %v25154_v30 = vadd.f32 %v25150_v31, %v25123_v61 (stack53)
        %v25927_v29 = vadd.s32 %v25924_v6, %v25919_v29 (stack40)
        %v25929_v56 = vshll.u32 %v25924_v6, 15 (stack45)
        %v25930_v10 = vshrl.u32 %v25924_v6, 17 (stack46)
        %v129942_v25 = vmax.f32 %v25518_v21, -0.99609375 (stack55)
        %v26308_v20 = vadd.s32 %v26305_v43, %v26300_v20 (stack40)
        %v26310_v12 = vshll.u32 %v26305_v43, 26 (stack45)
        %v26311_v26 = vshrl.u32 %v26305_v43, 6 (stack46)
        %v25158_v50 = vmul.f32 %v25154_v30, %v129934_v41 (stack54)
        %v25931_v46 = vor.u32 %v25930_v10, %v25929_v56 (stack47)
        %v26762_v23 = vshrl.u32 %v26756_v8, 16 (stack46)
        %v27596_v34 = vadd.s32 1, %v27592_v22 (stack40)
        %v25534_v60 = vxor.u32 2147483648, %v129942_v25 (stack56)
        %v26312_v55 = vor.u32 %v26311_v26, %v26310_v12 (stack47)
        %v27178_v40 = vshll.u32 %v27173_v24, 26 (stack45)
        %v27179_v24 = vshrl.u32 %v27173_v24, 6 (stack46)
        %v129949_v8 = vsel /*vm=*/%vm25090_vm8, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v25115_v61 = vsel /*vm=*/%vm25090_vm8, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v25162_v11 = vadd.f32 %v25158_v50, %v25119_v11 (stack53)
        %v25932_v31 = vxor.u32 %v25931_v46, %v25927_v29 (stack48)
        %v129955_v6 = vmul.f32 %v25534_v60, %v129942_v25 (stack54)
        %v26313_v21 = vxor.u32 %v26312_v55, %v26308_v20 (stack48)
        %v26763_v43 = vor.u32 %v26762_v23, %v26761_v53 (stack47)
        %v27600_v22 = vsel /*vm=*/%vm27587_vm12, /*on_true_vy=*/%v27596_v34, /*on_false_vx=*/%v27592_v22 (stack44)
        %v25166_v53 = vmul.f32 %v25162_v11, %v129934_v41 (stack54)
        %v25935_v30 = vadd.s32 %v25932_v31, %v25927_v29 (stack40)
        %v25937_v29 = vshll.u32 %v25932_v31, 26 (stack45)
        %v25938_v56 = vshrl.u32 %v25932_v31, 6 (stack46)
        %v25539_v10 = vadd.f32 1.0, %v129955_v6 (stack57)
        %v26316_v20 = vadd.s32 %v26313_v21, %v26308_v20 (stack40)
        %v27180_v12 = vor.u32 %v27179_v24, %v27178_v40 (stack47)
        %v27578_v26 = vadd.s32 %v129849_v44, %v122657_v58 (stack40)
        %v25170_v50 = vadd.f32 %v25166_v53, %v25115_v61 (stack53)
        %v25939_v46 = vor.u32 %v25938_v56, %v25937_v29 (stack47)
        %v26322_v23 = vshll.u32 %v26313_v21, 6 (stack45)
        %v26323_v34 = vshrl.u32 %v26313_v21, 26 (stack46)
        %v25107_v60 = vsel /*vm=*/%vm25090_vm8, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v25111_v55 = vsel /*vm=*/%vm25090_vm8, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %120645 = vlog2.f32 %v25539_v10 (stack58)
        %v25542_v40 = vmul.f32 -0.5, %v129955_v6 (stack59)
        %v25174_v24 = vmul.f32 %v25170_v50, %v129934_v41 (stack54)
        %v25940_v61 = vxor.u32 %v25939_v46, %v25935_v30 (stack48)
        %v26324_v11 = vor.u32 %v26323_v34, %v26322_v23 (stack47)
        %v26764_v31 = vxor.u32 %v26763_v43, %v26759_v42 (stack48)
        %v25545_v21 = vand.u32 2147483647, %v129955_v6 (stack60)
        %v27181_v43 = vxor.u32 %v27180_v12, %v129940_v32 (stack48)
        %vm27582_vm13 = vcmp.lt.u32.totalorder %v27578_v26, %v129849_v44 (stack43)
        %v27604_v53 = vadd.s32 1, %v27600_v22 (stack40)
        %v25178_v29 = vadd.f32 %v25174_v24, %v25111_v55 (stack53)
        %v25943_v30 = vadd.s32 %v25940_v61, %v25935_v30 (stack40)
        %v25949_v56 = vshll.u32 %v25940_v61, 6 (stack45)
        %v25950_v10 = vshrl.u32 %v25940_v61, 26 (stack46)
        %v26325_v12 = vxor.u32 %v26324_v11, %v26316_v20 (stack48)
        %v26767_v42 = vadd.s32 %v26764_v31, %v26759_v42 (stack40)
        %v26773_v50 = vshll.u32 %v26764_v31, 24 (stack45)
        %v26774_v46 = vshrl.u32 %v26764_v31, 8 (stack46)
        %v25182_v23 = vmul.f32 %v25178_v29, %v129934_v41 (stack54)
        %v25543_v34 = vadd.f32 1.0, %v25542_v40 (stack61)
        %v25951_v55 = vor.u32 %v25950_v10, %v25949_v56 (stack47)
        %v27184_v32 = vadd.s32 %v27181_v43, %v129940_v32 (stack40)
        %v26320_v20 = vadd.s32 %v26316_v20, %v121574_v2 (stack40)
        %v26328_v40 = vadd.s32 %v26325_v12, %v121569_v1 (stack40)
        %v26775_v24 = vor.u32 %v26774_v46, %v26773_v50 (stack47)
        %v27190_v61 = vshll.u32 %v27181_v43, 6 (stack45)
        %v25186_v60 = vadd.f32 %v25182_v23, %v25107_v60 (stack53)
        %vm129979_vm14 = vcmp.lt.f32.partialorder %v25545_v21, 0.0004427343 (stack62)
        %v25952_v31 = vxor.u32 %v25951_v55, %v25943_v30 (stack48)
        %v27191_v21 = vshrl.u32 %v27181_v43, 26 (stack46)
        %v129984_v43 = vadd.s32 %v27578_v26, %v121569_v1 (stack40)
        %v25947_v29 = vadd.s32 %v25943_v30, %v121564_v0 (stack40)
        %v26332_v30 = vadd.s32 3, %v26328_v40 (stack40)
        %v26776_v56 = vxor.u32 %v26775_v24, %v26767_v42 (stack48)
        %v27608_v44 = vsel /*vm=*/%vm27582_vm13, /*on_true_vy=*/%v27604_v53, /*on_false_vx=*/%v27600_v22 (stack44)
        %v25190_v22 = vmul.f32 %v25186_v60, %v129934_v41 (stack54)
        %v25955_v26 = vadd.s32 %v25952_v31, %v121574_v2 (stack40)
        %v27192_v53 = vor.u32 %v27191_v21, %v27190_v61 (stack47)
        %v27613_v10 = vadd.s32 %v27608_v44, %v121574_v2 (stack40)
        %v26336_v12 = vadd.s32 %v26332_v30, %v26320_v20 (stack40)
        %v26338_v50 = vshll.u32 %v26332_v30, 17 (stack45)
        %v26339_v46 = vshrl.u32 %v26332_v30, 15 (stack46)
        %v26779_v23 = vadd.s32 %v26776_v56, %v121574_v2 (stack40)
        %v25194_v8 = vadd.f32 %v25190_v22, %v129949_v8 (stack53)
        %v25959_v55 = vadd.s32 5, %v25955_v26 (stack40)
        %v27193_v20 = vxor.u32 %v27192_v53, %v27184_v32 (stack48)
        %v129995_v40 = vadd.s32 %v129984_v43, %v27613_v10 (stack40)
        %v26340_v24 = vor.u32 %v26339_v46, %v26338_v50 (stack47)
        %v26771_v42 = vadd.s32 %v26767_v42, %v121564_v0 (stack40)
        %v26783_v61 = vadd.s32 2, %v26779_v23 (stack40)
        %v130000_v60 = vadd.s32 %v157225_v52, %v157079_v39 (stack40)
        %v120646_v31 = vpop.eup %120645 (stack64)
        %v25198_v21 = vmul.f32 %v25194_v8, %v129934_v41 (stack54)
        %v25961_v29 = vxor.u32 %v25959_v55, %v25947_v29 (stack48)
        %v27196_v30 = vadd.s32 %v27193_v20, %v121564_v0 (stack40)
        %v130006_v56 = vadd.s32 %v157226_v7, %v157082_v49 (stack40)
        %v25541_v44 = vmul.f32 0.6931472, %v120646_v31 (stack65)
        %v25544_v6 = vmul.f32 %v25543_v34, %v129955_v6 (stack63)
        %v26341_v34 = vxor.u32 %v26340_v24, %v26336_v12 (stack48)
        %v26787_v22 = vadd.s32 %v26783_v61, %v26771_v42 (stack40)
        %v25202_v27 = vadd.f32 %v25198_v21, %v129896_v27 (stack53)
        %v25962_v26 = vand.u32.u8 255, %v25961_v29 (stack49)
        %v27188_v32 = vadd.s32 %v27184_v32, %v121569_v1 (stack40)
        %v27200_v53 = vadd.s32 1, %v27196_v30 (stack40)
        %v25547_v11 = vsel /*vm=*/%vm129979_vm14, /*on_true_vy=*/%v25544_v6, /*on_false_vx=*/%v25541_v44 (stack66)
        %v26344_v10 = vadd.s32 %v26341_v34, %v26336_v12 (stack40)
        %v26346_v12 = vshll.u32 %v26341_v34, 29 (stack45)
        %v26347_v50 = vshrl.u32 %v26341_v34, 3 (stack46)
        %v25206_v41 = vmul.f32 %v25202_v27, %v129934_v41 (stack54)
        %v130014_v46 = vxor.u32 2147483648, %v25547_v11 (stack56)
        %v26789_v23 = vshll.u32 %v26783_v61, 13 (stack45)
        %v26790_v8 = vshrl.u32 %v26783_v61, 19 (stack46)
        %v25063_v55 = vand.u32 2147483647, %v129806_v54 (stack77)
        %v25095_v9 = vsel /*vm=*/%vm25090_vm8, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v26348_v20 = vor.u32 %v26347_v50, %v26346_v12 (stack47)
        %v27204_v24 = vadd.s32 %v27200_v53, %v27188_v32 (stack40)
        %v25071_v42 = vmul.f32 inf, %v129806_v54 (stack54)
        %v25210_v61 = vadd.f32 %v25206_v41, %v25095_v9 (stack53)
        %120647 = vrsqrt.f32 %v130014_v46 (stack67)
        %v27623_v31 = vshll.u32 %v129984_v43, 13 (stack45)
        %vm25551_vm15 = vcmp.lt.f32.partialorder %v130014_v46, 5.0 (stack68)
        %v25963_v21 = vand.u32 65535, %v25962_v26 (stack50)
        %v26349_v29 = vxor.u32 %v26348_v20, %v26344_v10 (stack48)
        %v27624_v43 = vshrl.u32 %v129984_v43, 19 (stack46)
        %v25214_v54 = vmul.f32 %v25210_v61, %v129806_v54 (stack54)
        %v26791_v30 = vor.u32 %v26790_v8, %v26789_v23 (stack47)
        %v27206_v44 = vshll.u32 %v27200_v53, 17 (stack45)
        %v27207_v6 = vshrl.u32 %v27200_v53, 15 (stack46)
        %vm25066_vm0 = vcmp.eq.f32.partialorder %v25063_v55, 1.0 (stack68)
        %v26352_v34 = vadd.s32 %v26349_v29, %v26344_v10 (stack40)
        %v25218_v27 = vsel /*vm=*/%vm25066_vm0, /*on_true_vy=*/%v25071_v42, /*on_false_vx=*/%v25214_v54 (stack44)
        %v25524_v26 = vand.u32 2147483647, %v129942_v25 (stack77)
        %v130030_v32 = vsel /*vm=*/%vm25551_vm15, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v130033_v53 = vadd.f32 -2.5, %v130014_v46 (stack53)
        %v25222_v11 = vmul.f32 1.4140625, %v25218_v27 (stack54)
        %v25964_v10 = vshrl.u32 %v25963_v21, 1 (stack51)
        %v26354_v12 = vshll.u32 %v26349_v29, 16 (stack45)
        %v26355_v50 = vshrl.u32 %v26349_v29, 16 (stack46)
        %v130038_v41 = vsel /*vm=*/%vm25551_vm15, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v26792_v23 = vxor.u32 %v26791_v30, %v26787_v22 (stack48)
        %v27208_v8 = vor.u32 %v27207_v6, %v27206_v44 (stack47)
        %v27625_v55 = vor.u32 %v27624_v43, %v27623_v31 (stack47)
        %v25225_v9 = vpack.c.bf16 %v156663_v45, %v25222_v11 (stack81)
        %v25965_v20 = vor.u32 16256, %v25964_v10 (stack47)
        %v26356_v42 = vor.u32 %v26355_v50, %v26354_v12 (stack47)
        %vm28048_vm1 = vcmp.lt.u32.totalorder %v130000_v60, %v157079_v39 (stack43)
        %v26795_v22 = vadd.s32 %v26792_v23, %v26787_v22 (stack40)
        %v26797_v61 = vshll.u32 %v26792_v23, 15 (stack45)
        %v26798_v31 = vshrl.u32 %v26792_v23, 17 (stack46)
        %v27209_v21 = vxor.u32 %v27208_v8, %v27204_v24 (stack48)
        %119877 = vst [vmem:[%s123356_s30 + $0x218] sm:$0xf] /*vst_source=*/%v25225_v9 (stack83)
        %v130047_v29 = vsel /*vm=*/%vm25551_vm15, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v25966_v43 = vand.u32.u16 65535, %v25965_v20 (stack52)
        %v26357_v54 = vxor.u32 %v26356_v42, %v26352_v34 (stack48)
        %v27626_v30 = vxor.u32 %v27625_v55, %v129995_v40 (stack48)
        %v26799_v44 = vor.u32 %v26798_v31, %v26797_v61 (stack47)
        %v27212_v24 = vadd.s32 %v27209_v21, %v27204_v24 (stack40)
        %v27214_v6 = vshll.u32 %v27209_v21, 29 (stack45)
        %v27215_v27 = vshrl.u32 %v27209_v21, 3 (stack46)
        %v119880_v11 = vadd.low.f32.bf16 -1.0, %v25966_v43 (stack53)
        %v26360_v34 = vadd.s32 %v26357_v54, %v26352_v34 (stack40)
        %v26366_v10 = vshll.u32 %v26357_v54, 24 (stack45)
        %v26367_v12 = vshrl.u32 %v26357_v54, 8 (stack46)
        %vm25596_vm2 = vcmp.eq.f32.partialorder %v130014_v46, inf (stack70)
        %v26800_v50 = vxor.u32 %v26799_v44, %v26795_v22 (stack48)
        %v27216_v23 = vor.u32 %v27215_v27, %v27214_v6 (stack47)
        %v27629_v40 = vadd.s32 %v27626_v30, %v129995_v40 (stack40)
        %v120648_v8 = vpop.eup %120647 (stack73)
        %v25975_v55 = vmul.f32 2.0, %v119880_v11 (stack54)
        %v26368_v9 = vor.u32 %v26367_v12, %v26366_v10 (stack47)
        %v27631_v20 = vshll.u32 %v27626_v30, 15 (stack45)
        %v27632_v42 = vshrl.u32 %v27626_v30, 17 (stack46)
        %v25595_v61 = vmul.f32 %v120648_v8, %v130014_v46 (stack74)
        %v26803_v22 = vadd.s32 %v26800_v50, %v26795_v22 (stack40)
        %v26805_v31 = vshll.u32 %v26800_v50, 26 (stack45)
        %v26806_v21 = vshrl.u32 %v26800_v50, 6 (stack46)
        %v25599_v43 = vand.u32 2147483648, %v130014_v46 (stack72)
        %v25979_v54 = vadd.f32 -0.99609375, %v25975_v55 (stack53)
        %v26369_v30 = vxor.u32 %v26368_v9, %v26360_v34 (stack48)
        %v27217_v44 = vxor.u32 %v27216_v23, %v27212_v24 (stack48)
        %v25588_v6 = vsel /*vm=*/%vm25551_vm15, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v25597_v27 = vsel /*vm=*/%vm25596_vm2, /*on_true_vy=*/%v130014_v46, /*on_false_vx=*/%v25595_v61 (stack75)
        %vm25598_vm3 = vcmp.eq.f32.partialorder %v130014_v46, 0.0 (stack71)
        %v26807_v11 = vor.u32 %v26806_v21, %v26805_v31 (stack47)
        %v25600_v10 = vsel /*vm=*/%vm25598_vm3, /*on_true_vy=*/%v25599_v43, /*on_false_vx=*/%v25597_v27 (stack76)
        %v130061_v12 = vmax.f32 %v25979_v54, -0.99609375 (stack55)
        %v26372_v50 = vadd.s32 %v26369_v30, %v121564_v0 (stack40)
        %v27220_v24 = vadd.s32 %v27217_v44, %v27212_v24 (stack40)
        %v25603_v23 = vadd.f32 -3.0, %v25600_v10 (stack53)
        %v26364_v34 = vadd.s32 %v26360_v34, %v121569_v1 (stack40)
        %v26808_v8 = vxor.u32 %v26807_v11, %v26803_v22 (stack48)
        %v27633_v55 = vor.u32 %v27632_v42, %v27631_v20 (stack47)
        %v25995_v9 = vxor.u32 2147483648, %v130061_v12 (stack56)
        %v26376_v20 = vadd.s32 4, %v26372_v50 (stack40)
        %v27222_v42 = vshll.u32 %v27217_v44, 16 (stack45)
        %v27223_v61 = vshrl.u32 %v27217_v44, 16 (stack46)
        %v130069_v53 = vsel /*vm=*/%vm25551_vm15, /*on_true_vy=*/%v130033_v53, /*on_false_vx=*/%v25603_v23 (stack44)
        %v26811_v22 = vadd.s32 %v26808_v8, %v26803_v22 (stack40)
        %v26817_v31 = vshll.u32 %v26808_v8, 6 (stack45)
        %v26818_v21 = vshrl.u32 %v26808_v8, 26 (stack46)
        %v25576_v43 = vsel /*vm=*/%vm25551_vm15, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v25611_v54 = vmul.f32 %v130069_v53, %v25588_v6 (stack54)
        %v130076_v30 = vmul.f32 %v25995_v9, %v130061_v12 (stack54)
        %v26380_v44 = vadd.s32 %v26376_v20, %v26364_v34 (stack40)
        %v25584_v6 = vsel /*vm=*/%vm25551_vm15, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v26382_v27 = vshll.u32 %v26376_v20, 13 (stack45)
        %v26383_v11 = vshrl.u32 %v26376_v20, 19 (stack46)
        %v26819_v10 = vor.u32 %v26818_v21, %v26817_v31 (stack47)
        %v25580_v50 = vsel /*vm=*/%vm25551_vm15, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v25615_v23 = vadd.f32 %v25611_v54, %v25584_v6 (stack53)
        %v26000_v34 = vadd.f32 1.0, %v130076_v30 (stack57)
        %v130087_v8 = vadd.s32 %v130000_v60, %v122657_v58 (stack40)
        %v26384_v9 = vor.u32 %v26383_v11, %v26382_v27 (stack47)
        %v26820_v20 = vxor.u32 %v26819_v10, %v26811_v22 (stack48)
        %v27224_v42 = vor.u32 %v27223_v61, %v27222_v42 (stack47)
        %v27634_v55 = vxor.u32 %v27633_v55, %v27629_v40 (stack48)
        %v25619_v61 = vmul.f32 %v25615_v23, %v130069_v53 (stack54)
        %120649 = vlog2.f32 %v26000_v34 (stack58)
        %v26815_v22 = vadd.s32 %v26811_v22, %v121574_v2 (stack40)
        %v28057_v31 = vadd.s32 1, %v130006_v56 (stack40)
        %v26385_v21 = vxor.u32 %v26384_v9, %v26380_v44 (stack48)
        %v26823_v54 = vadd.s32 %v26820_v20, %v121569_v1 (stack40)
        %v27225_v6 = vxor.u32 %v27224_v42, %v27220_v24 (stack48)
        %v27637_v40 = vadd.s32 %v27634_v55, %v27629_v40 (stack40)
        %v25623_v27 = vadd.f32 %v25619_v61, %v25580_v50 (stack53)
        %v26003_v11 = vmul.f32 -0.5, %v130076_v30 (stack59)
        %v27639_v10 = vshll.u32 %v27634_v55, 26 (stack45)
        %v27640_v50 = vshrl.u32 %v27634_v55, 6 (stack46)
        %vm28043_vm4 = vcmp.lt.u32.totalorder %v130087_v8, %v130000_v60 (stack43)
        %v26388_v44 = vadd.s32 %v26385_v21, %v26380_v44 (stack40)
        %v26390_v23 = vshll.u32 %v26385_v21, 15 (stack45)
        %v26391_v34 = vshrl.u32 %v26385_v21, 17 (stack46)
        %v26827_v9 = vadd.s32 3, %v26823_v54 (stack40)
        %v25627_v20 = vmul.f32 %v25623_v27, %v130069_v53 (stack54)
        %v27228_v24 = vadd.s32 %v27225_v6, %v27220_v24 (stack40)
        %v27234_v42 = vshll.u32 %v27225_v6, 24 (stack45)
        %v27235_v55 = vshrl.u32 %v27225_v6, 8 (stack46)
        %v26392_v61 = vor.u32 %v26391_v34, %v26390_v23 (stack47)
        %v26831_v22 = vadd.s32 %v26827_v9, %v26815_v22 (stack40)
        %v26833_v21 = vshll.u32 %v26827_v9, 17 (stack45)
        %v26834_v54 = vshrl.u32 %v26827_v9, 15 (stack46)
        %v25631_v43 = vadd.f32 %v25627_v20, %v25576_v43 (stack53)
        %v26006_v6 = vand.u32 2147483647, %v130076_v30 (stack60)
        %v27236_v27 = vor.u32 %v27235_v55, %v27234_v42 (stack47)
        %v27641_v10 = vor.u32 %v27640_v50, %v27639_v10 (stack47)
        %v26004_v11 = vadd.f32 1.0, %v26003_v11 (stack61)
        %v26393_v50 = vxor.u32 %v26392_v61, %v26388_v44 (stack48)
        %v26835_v23 = vor.u32 %v26834_v54, %v26833_v21 (stack47)
        %v28061_v56 = vsel /*vm=*/%vm28048_vm1, /*on_true_vy=*/%v28057_v31, /*on_false_vx=*/%v130006_v56 (stack44)
        %v25635_v31 = vmul.f32 %v25631_v43, %v130069_v53 (stack54)
        %v27237_v34 = vxor.u32 %v27236_v27, %v27228_v24 (stack48)
        %v27642_v9 = vxor.u32 %v27641_v10, %v27637_v40 (stack48)
        %v28065_v20 = vadd.s32 1, %v28061_v56 (stack40)
        %v26396_v44 = vadd.s32 %v26393_v50, %v26388_v44 (stack40)
        %v26398_v42 = vshll.u32 %v26393_v50, 26 (stack45)
        %v26399_v55 = vshrl.u32 %v26393_v50, 6 (stack46)
        %v26836_v61 = vxor.u32 %v26835_v23, %v26831_v22 (stack48)
        %v25639_v29 = vadd.f32 %v25635_v31, %v130047_v29 (stack53)
        %vm130104_vm5 = vcmp.lt.f32.partialorder %v26006_v6, 0.0004427343 (stack62)
        %v27240_v54 = vadd.s32 %v27237_v34, %v121574_v2 (stack40)
        %v130109_v40 = vadd.s32 %v27642_v9, %v27637_v40 (stack40)
        %v26400_v43 = vor.u32 %v26399_v55, %v26398_v42 (stack47)
        %v26839_v22 = vadd.s32 %v26836_v61, %v26831_v22 (stack40)
        %v26841_v6 = vshll.u32 %v26836_v61, 29 (stack45)
        %v26842_v27 = vshrl.u32 %v26836_v61, 3 (stack46)
        %v25643_v10 = vmul.f32 %v25639_v29, %v130069_v53 (stack54)
        %v26005_v30 = vmul.f32 %v26004_v11, %v130076_v30 (stack63)
        %v27232_v24 = vadd.s32 %v27228_v24, %v121564_v0 (stack40)
        %v27244_v11 = vadd.s32 2, %v27240_v54 (stack40)
        %v120650_v50 = vpop.eup %120649 (stack64)
        %v26401_v23 = vxor.u32 %v26400_v43, %v26396_v44 (stack48)
        %v26843_v31 = vor.u32 %v26842_v27, %v26841_v6 (stack47)
        %v27651_v34 = vshll.u32 %v27642_v9, 6 (stack45)
        %v28069_v60 = vsel /*vm=*/%vm28043_vm4, /*on_true_vy=*/%v28065_v20, /*on_false_vx=*/%v28061_v56 (stack44)
        %v25647_v41 = vadd.f32 %v25643_v10, %v130038_v41 (stack53)
        %v26002_v56 = vmul.f32 0.6931472, %v120650_v50 (stack65)
        %v27248_v20 = vadd.s32 %v27244_v11, %v27232_v24 (stack40)
        %v27652_v9 = vshrl.u32 %v27642_v9, 26 (stack46)
        %v26404_v44 = vadd.s32 %v26401_v23, %v26396_v44 (stack40)
        %v26410_v42 = vshll.u32 %v26401_v23, 6 (stack45)
        %v26411_v55 = vshrl.u32 %v26401_v23, 26 (stack46)
        %v26844_v61 = vxor.u32 %v26843_v31, %v26839_v22 (stack48)
        %v25651_v29 = vmul.f32 %v25647_v41, %v130069_v53 (stack54)
        %v26008_v21 = vsel /*vm=*/%vm130104_vm5, /*on_true_vy=*/%v26005_v30, /*on_false_vx=*/%v26002_v56 (stack66)
        %v27250_v54 = vshll.u32 %v27244_v11, 13 (stack45)
        %v27251_v43 = vshrl.u32 %v27244_v11, 19 (stack46)
        %v130121_v6 = vxor.u32 2147483648, %v26008_v21 (stack56)
        %v26412_v27 = vor.u32 %v26411_v55, %v26410_v42 (stack47)
        %v26847_v22 = vadd.s32 %v26844_v61, %v26839_v22 (stack40)
        %v28078_v8 = vadd.s32 %v130087_v8, %v121569_v1 (stack40)
        %v25532_v10 = vmul.f32 inf, %v129942_v25 (stack54)
        %v25556_v30 = vsel /*vm=*/%vm25551_vm15, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v25655_v32 = vadd.f32 %v25651_v29, %v130030_v32 (stack53)
        %v25560_v46 = vsel /*vm=*/%vm25551_vm15, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %120651 = vrsqrt.f32 %v130121_v6 (stack67)
        %v26849_v24 = vshll.u32 %v26844_v61, 16 (stack45)
        %v26850_v11 = vshrl.u32 %v26844_v61, 16 (stack46)
        %v25659_v50 = vmul.f32 %v25655_v32, %v130069_v53 (stack54)
        %vm26012_vm6 = vcmp.lt.f32.partialorder %v130121_v6, 5.0 (stack68)
        %v27252_v23 = vor.u32 %v27251_v43, %v27250_v54 (stack47)
        %v27653_v31 = vor.u32 %v27652_v9, %v27651_v34 (stack47)
        %vm130138_vm7 = vcmp.eq.f32.partialorder %v25524_v26, 1.0 (stack68)
        %v25985_v34 = vand.u32 2147483647, %v130061_v12 (stack77)
        %v26413_v41 = vxor.u32 %v26412_v27, %v26404_v44 (stack48)
        %v28084_v56 = vshll.u32 %v28078_v8, 13 (stack45)
        %v28085_v9 = vshrl.u32 %v28078_v8, 19 (stack46)
        %v25663_v42 = vadd.f32 %v25659_v50, %v25560_v46 (stack53)
        %v130144_v55 = vadd.f32 -2.5, %v130121_v6 (stack53)
        %v26408_v44 = vadd.s32 %v26404_v44, %v121564_v0 (stack40)
        %v27649_v61 = vadd.s32 %v130109_v40, %v121569_v1 (stack40)
        %v130152_v29 = vsel /*vm=*/%vm26012_vm6, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v130157_v21 = vsel /*vm=*/%vm26012_vm6, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v26416_v54 = vadd.s32 %v26413_v41, %v121574_v2 (stack40)
        %v26851_v43 = vor.u32 %v26850_v11, %v26849_v24 (stack47)
        %v25667_v53 = vmul.f32 %v25663_v42, %v130069_v53 (stack54)
        %v27253_v27 = vxor.u32 %v27252_v23, %v27248_v20 (stack48)
        %v27654_v40 = vxor.u32 %v27653_v31, %v130109_v40 (stack48)
        %v28074_v60 = vadd.s32 %v28069_v60, %v121574_v2 (stack40)
        %v26420_v32 = vadd.s32 5, %v26416_v54 (stack40)
        %v26852_v46 = vxor.u32 %v26851_v43, %v26847_v22 (stack48)
        %v28086_v24 = vor.u32 %v28085_v9, %v28084_v56 (stack47)
        %v130165_v11 = vadd.s32 %v157225_v52, %v157083_v59 (stack40)
        %v25671_v30 = vadd.f32 %v25667_v53, %v25556_v30 (stack53)
        %vm26057_vm8 = vcmp.eq.f32.partialorder %v130121_v6, inf (stack70)
        %v27256_v20 = vadd.s32 %v27253_v27, %v27248_v20 (stack40)
        %v27258_v50 = vshll.u32 %v27253_v27, 15 (stack45)
        %v27259_v23 = vshrl.u32 %v27253_v27, 17 (stack46)
        %v26422_v31 = vxor.u32 %v26420_v32, %v26408_v44 (stack48)
        %v26855_v22 = vadd.s32 %v26852_v46, %v26847_v22 (stack40)
        %v26861_v41 = vshll.u32 %v26852_v46, 24 (stack45)
        %v26862_v56 = vshrl.u32 %v26852_v46, 8 (stack46)
        %v25675_v25 = vmul.f32 %v25671_v30, %v129942_v25 (stack54)
        %v27260_v9 = vor.u32 %v27259_v23, %v27258_v50 (stack47)
        %v27657_v42 = vadd.s32 %v27654_v40, %v121564_v0 (stack40)
        %v28082_v8 = vadd.s32 %v28078_v8, %v28074_v60 (stack40)
        %vm26059_vm9 = vcmp.eq.f32.partialorder %v130121_v6, 0.0 (stack71)
        %v26060_v44 = vand.u32 2147483648, %v130121_v6 (stack72)
        %v26423_v54 = vand.u32.u8 255, %v26422_v31 (stack49)
        %v26863_v43 = vor.u32 %v26862_v56, %v26861_v41 (stack47)
        %v25679_v10 = vsel /*vm=*/%vm130138_vm7, /*on_true_vy=*/%v25532_v10, /*on_false_vx=*/%v25675_v25 (stack44)
        %v27261_v26 = vxor.u32 %v27260_v9, %v27256_v20 (stack48)
        %v27661_v53 = vadd.s32 1, %v27657_v42 (stack40)
        %v28087_v27 = vxor.u32 %v28086_v24, %v28082_v8 (stack48)
        %v25683_v40 = vmul.f32 1.4140625, %v25679_v10 (stack54)
        %v26424_v60 = vand.u32 65535, %v26423_v54 (stack50)
        %v26859_v32 = vadd.s32 %v26855_v22, %v121569_v1 (stack40)
        %v26864_v46 = vxor.u32 %v26863_v43, %v26855_v22 (stack48)
        %v120652_v24 = vpop.eup %120651 (stack73)
        %v27264_v30 = vadd.s32 %v27261_v26, %v27256_v20 (stack40)
        %v27266_v20 = vshll.u32 %v27261_v26, 26 (stack45)
        %v27267_v50 = vshrl.u32 %v27261_v26, 6 (stack46)
        %v27665_v61 = vadd.s32 %v27661_v53, %v27649_v61 (stack40)
        %v25686_v23 = vpack.c.bf16 %v156663_v45, %v25683_v40 (stack81)
        %v26056_v31 = vmul.f32 %v120652_v24, %v130121_v6 (stack74)
        %v26425_v22 = vshrl.u32 %v26424_v60, 1 (stack51)
        %v26867_v41 = vadd.s32 %v26864_v46, %v121564_v0 (stack40)
        %v27268_v56 = vor.u32 %v27267_v50, %v27266_v20 (stack47)
        %v27667_v25 = vshll.u32 %v27661_v53, 17 (stack45)
        %v27668_v9 = vshrl.u32 %v27661_v53, 15 (stack46)
        %v28090_v42 = vadd.s32 %v28087_v27, %v28082_v8 (stack40)
        %119879 = vst [vmem:[%s123356_s30 + $0x298] sm:$0xf] /*vst_source=*/%v25686_v23 (stack83)
        %v26058_v8 = vsel /*vm=*/%vm26057_vm8, /*on_true_vy=*/%v130121_v6, /*on_false_vx=*/%v26056_v31 (stack75)
        %v26426_v54 = vor.u32 16256, %v26425_v22 (stack47)
        %v26871_v43 = vadd.s32 4, %v26867_v41 (stack40)
        %v28092_v10 = vshll.u32 %v28087_v27, 15 (stack45)
        %v26061_v44 = vsel /*vm=*/%vm26059_vm9, /*on_true_vy=*/%v26060_v44, /*on_false_vx=*/%v26058_v8 (stack76)
        %v27269_v26 = vxor.u32 %v27268_v56, %v27264_v30 (stack48)
        %v27669_v53 = vor.u32 %v27668_v9, %v27667_v25 (stack47)
        %v28093_v27 = vshrl.u32 %v28087_v27, 17 (stack46)
        %v26064_v40 = vadd.f32 -3.0, %v26061_v44 (stack53)
        %v26427_v60 = vand.u32.u16 65535, %v26426_v54 (stack52)
        %v26875_v32 = vadd.s32 %v26871_v43, %v26859_v32 (stack40)
        %v26877_v46 = vshll.u32 %v26871_v43, 13 (stack45)
        %v26878_v24 = vshrl.u32 %v26871_v43, 19 (stack46)
        %v27272_v30 = vadd.s32 %v27269_v26, %v27264_v30 (stack40)
        %v27278_v20 = vshll.u32 %v27269_v26, 6 (stack45)
        %v27279_v50 = vshrl.u32 %v27269_v26, 26 (stack46)
        %v130187_v55 = vsel /*vm=*/%vm26012_vm6, /*on_true_vy=*/%v130144_v55, /*on_false_vx=*/%v26064_v40 (stack44)
        %v119882_v23 = vadd.low.f32.bf16 -1.0, %v26427_v60 (stack53)
        %v27670_v31 = vxor.u32 %v27669_v53, %v27665_v61 (stack48)
        %v28094_v22 = vor.u32 %v28093_v27, %v28092_v10 (stack47)
        %v26045_v41 = vsel /*vm=*/%vm26012_vm6, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v26072_v21 = vmul.f32 %v130187_v55, %v130157_v21 (stack54)
        %v26879_v56 = vor.u32 %v26878_v24, %v26877_v46 (stack47)
        %v27280_v25 = vor.u32 %v27279_v50, %v27278_v20 (stack47)
        %v26436_v9 = vmul.f32 2.0, %v119882_v23 (stack54)
        %v27673_v61 = vadd.s32 %v27670_v31, %v27665_v61 (stack40)
        %v27675_v8 = vshll.u32 %v27670_v31, 29 (stack45)
        %v27676_v54 = vshrl.u32 %v27670_v31, 3 (stack46)
        %v26076_v43 = vadd.f32 %v26072_v21, %v26045_v41 (stack53)
        %v26880_v10 = vxor.u32 %v26879_v56, %v26875_v32 (stack48)
        %v27281_v44 = vxor.u32 %v27280_v25, %v27272_v30 (stack48)
        %v28095_v26 = vxor.u32 %v28094_v22, %v28090_v42 (stack48)
        %v26440_v53 = vadd.f32 -0.99609375, %v26436_v9 (stack53)
        %v27677_v27 = vor.u32 %v27676_v54, %v27675_v8 (stack47)
        %vm28509_vm10 = vcmp.lt.u32.totalorder %v130165_v11, %v157083_v59 (stack43)
        %v130198_v40 = vadd.s32 %v157226_v7, %v157084_v16 (stack40)
        %v26080_v60 = vmul.f32 %v26076_v43, %v130187_v55 (stack54)
        %v26883_v32 = vadd.s32 %v26880_v10, %v26875_v32 (stack40)
        %v26885_v46 = vshll.u32 %v26880_v10, 15 (stack45)
        %v26886_v24 = vshrl.u32 %v26880_v10, 17 (stack46)
        %v130201_v20 = vmax.f32 %v26440_v53, -0.99609375 (stack55)
        %v27284_v50 = vadd.s32 %v27281_v44, %v121569_v1 (stack40)
        %v27678_v23 = vxor.u32 %v27677_v27, %v27673_v61 (stack48)
        %v28098_v42 = vadd.s32 %v28095_v26, %v28090_v42 (stack40)
        %v130207_v31 = vsel /*vm=*/%vm26012_vm6, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v26037_v22 = vsel /*vm=*/%vm26012_vm6, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v26084_v29 = vadd.f32 %v26080_v60, %v130152_v29 (stack53)
        %v26887_v41 = vor.u32 %v26886_v24, %v26885_v46 (stack47)
        %v26456_v21 = vxor.u32 2147483648, %v130201_v20 (stack56)
        %v27276_v30 = vadd.s32 %v27272_v30, %v121574_v2 (stack40)
        %v27288_v56 = vadd.s32 3, %v27284_v50 (stack40)
        %v28100_v25 = vshll.u32 %v28095_v26, 26 (stack45)
        %v26088_v9 = vmul.f32 %v26084_v29, %v130187_v55 (stack54)
        %v26888_v8 = vxor.u32 %v26887_v41, %v26883_v32 (stack48)
        %v27681_v61 = vadd.s32 %v27678_v23, %v27673_v61 (stack40)
        %v28101_v54 = vshrl.u32 %v28095_v26, 6 (stack46)
        %v130217_v43 = vmul.f32 %v26456_v21, %v130201_v20 (stack54)
        %v27292_v10 = vadd.s32 %v27288_v56, %v27276_v30 (stack40)
        %v27294_v44 = vshll.u32 %v27288_v56, 17 (stack45)
        %v27683_v26 = vshll.u32 %v27678_v23, 16 (stack45)
        %v26092_v53 = vadd.f32 %v26088_v9, %v26037_v22 (stack53)
        %v26891_v27 = vadd.s32 %v26888_v8, %v26883_v32 (stack40)
        %v26893_v60 = vshll.u32 %v26888_v8, 26 (stack45)
        %v26894_v32 = vshrl.u32 %v26888_v8, 6 (stack46)
        %v26021_v46 = vsel /*vm=*/%vm26012_vm6, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v26461_v24 = vadd.f32 1.0, %v130217_v43 (stack57)
        %v27295_v50 = vshrl.u32 %v27288_v56, 15 (stack46)
        %v130225_v22 = vadd.s32 %v130165_v11, %v122657_v58 (stack40)
        %v26096_v29 = vmul.f32 %v26092_v53, %v130187_v55 (stack54)
        %v26895_v41 = vor.u32 %v26894_v32, %v26893_v60 (stack47)
        %v27684_v23 = vshrl.u32 %v27678_v23, 16 (stack46)
        %v28102_v21 = vor.u32 %v28101_v54, %v28100_v25 (stack47)
        %v26025_v30 = vsel /*vm=*/%vm26012_vm6, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v26033_v56 = vsel /*vm=*/%vm26012_vm6, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %120653 = vlog2.f32 %v26461_v24 (stack58)
        %v27296_v25 = vor.u32 %v27295_v50, %v27294_v44 (stack47)
        %v26100_v9 = vadd.f32 %v26096_v29, %v26033_v56 (stack53)
        %v26896_v8 = vxor.u32 %v26895_v41, %v26891_v27 (stack48)
        %v27685_v54 = vor.u32 %v27684_v23, %v27683_v26 (stack47)
        %v28103_v44 = vxor.u32 %v28102_v21, %v28098_v42 (stack48)
        %v26029_v6 = vsel /*vm=*/%vm26012_vm6, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v26464_v26 = vmul.f32 -0.5, %v130217_v43 (stack59)
        %v27297_v53 = vxor.u32 %v27296_v25, %v27292_v10 (stack48)
        %vm28504_vm11 = vcmp.lt.u32.totalorder %v130225_v22, %v130165_v11 (stack43)
        %v26104_v60 = vmul.f32 %v26100_v9, %v130187_v55 (stack54)
        %v26899_v27 = vadd.s32 %v26896_v8, %v26891_v27 (stack40)
        %v26905_v32 = vshll.u32 %v26896_v8, 6 (stack45)
        %v26906_v24 = vshrl.u32 %v26896_v8, 26 (stack46)
        %v27300_v10 = vadd.s32 %v27297_v53, %v27292_v10 (stack40)
        %v27302_v50 = vshll.u32 %v27297_v53, 29 (stack45)
        %v27303_v29 = vshrl.u32 %v27297_v53, 3 (stack46)
        %v27686_v41 = vxor.u32 %v27685_v54, %v27681_v61 (stack48)
        %v26108_v23 = vadd.f32 %v26104_v60, %v26029_v6 (stack53)
        %v26467_v21 = vand.u32 2147483647, %v130217_v43 (stack60)
        %v26907_v56 = vor.u32 %v26906_v24, %v26905_v32 (stack47)
        %v130242_v42 = vadd.s32 %v28103_v44, %v28098_v42 (stack40)
        %v27304_v25 = vor.u32 %v27303_v29, %v27302_v50 (stack47)
        %v27689_v61 = vadd.s32 %v27686_v41, %v27681_v61 (stack40)
        %v27695_v9 = vshll.u32 %v27686_v41, 24 (stack45)
        %v27696_v8 = vshrl.u32 %v27686_v41, 8 (stack46)
        %v26112_v54 = vmul.f32 %v26108_v23, %v130187_v55 (stack54)
        %v26908_v6 = vxor.u32 %v26907_v56, %v26899_v27 (stack48)
        %v28112_v53 = vshll.u32 %v28103_v44, 6 (stack45)
        %v28518_v60 = vadd.s32 1, %v130198_v40 (stack40)
        %v26465_v26 = vadd.f32 1.0, %v26464_v26 (stack61)
        %v27305_v32 = vxor.u32 %v27304_v25, %v27300_v10 (stack48)
        %v27697_v24 = vor.u32 %v27696_v8, %v27695_v9 (stack47)
        %v28113_v44 = vshrl.u32 %v28103_v44, 26 (stack46)
        %v26116_v30 = vadd.f32 %v26112_v54, %v26025_v30 (stack53)
        %v26903_v27 = vadd.s32 %v26899_v27, %v121564_v0 (stack40)
        %v26911_v50 = vadd.s32 %v26908_v6, %v121574_v2 (stack40)
        %v28522_v40 = vsel /*vm=*/%vm28509_vm10, /*on_true_vy=*/%v28518_v60, /*on_false_vx=*/%v130198_v40 (stack44)
        %v27308_v10 = vadd.s32 %v27305_v32, %v27300_v10 (stack40)
        %v27310_v29 = vshll.u32 %v27305_v32, 16 (stack45)
        %v27311_v41 = vshrl.u32 %v27305_v32, 16 (stack46)
        %v27698_v23 = vxor.u32 %v27697_v24, %v27689_v61 (stack48)
        %v26120_v56 = vmul.f32 %v26116_v30, %v130187_v55 (stack54)
        %v26915_v25 = vadd.s32 5, %v26911_v50 (stack40)
        %v28114_v9 = vor.u32 %v28113_v44, %v28112_v53 (stack47)
        %v28526_v8 = vadd.s32 1, %v28522_v40 (stack40)
        %v26466_v43 = vmul.f32 %v26465_v26, %v130217_v43 (stack63)
        %v27312_v54 = vor.u32 %v27311_v41, %v27310_v29 (stack47)
        %v27701_v6 = vadd.s32 %v27698_v23, %v121574_v2 (stack40)
        %v130257_v53 = vadd.s32 %v157225_v52, %v157089_v17 (stack40)
        %v120654_v60 = vpop.eup %120653 (stack64)
        %v26124_v46 = vadd.f32 %v26120_v56, %v26021_v46 (stack53)
        %v26917_v26 = vxor.u32 %v26915_v25, %v26903_v27 (stack48)
        %v28115_v32 = vxor.u32 %v28114_v9, %v130242_v42 (stack48)
        %v28530_v11 = vsel /*vm=*/%vm28504_vm11, /*on_true_vy=*/%v28526_v8, /*on_false_vx=*/%v28522_v40 (stack44)
        %v26463_v24 = vmul.f32 0.6931472, %v120654_v60 (stack65)
        %v27313_v44 = vxor.u32 %v27312_v54, %v27308_v10 (stack48)
        %v27705_v30 = vadd.s32 2, %v27701_v6 (stack40)
        %v28539_v22 = vadd.s32 %v130225_v22, %v121569_v1 (stack40)
        %v26128_v55 = vmul.f32 %v26124_v46, %v130187_v55 (stack54)
        %vm26468_vm12 = vcmp.lt.f32.partialorder %v26467_v21, 0.0004427343 (stack62)
        %v26918_v21 = vand.u32.u8 255, %v26917_v26 (stack49)
        %v27693_v61 = vadd.s32 %v27689_v61, %v121564_v0 (stack40)
        %v26469_v27 = vsel /*vm=*/%vm26468_vm12, /*on_true_vy=*/%v26466_v43, /*on_false_vx=*/%v26463_v24 (stack66)
        %v27316_v50 = vadd.s32 %v27313_v44, %v27308_v10 (stack40)
        %v27322_v40 = vshll.u32 %v27313_v44, 24 (stack45)
        %v27323_v10 = vshrl.u32 %v27313_v44, 8 (stack46)
        %v25993_v29 = vmul.f32 inf, %v130061_v12 (stack54)
        %v26132_v31 = vadd.f32 %v26128_v55, %v130207_v31 (stack53)
        %v130269_v41 = vxor.u32 2147483648, %v26469_v27 (stack56)
        %v27709_v23 = vadd.s32 %v27705_v30, %v27693_v61 (stack40)
        %vm25988_vm13 = vcmp.eq.f32.partialorder %v25985_v34, 1.0 (stack68)
        %v27324_v34 = vor.u32 %v27323_v10, %v27322_v40 (stack47)
        %v28545_v56 = vshll.u32 %v28539_v22, 13 (stack45)
        %v28546_v25 = vshrl.u32 %v28539_v22, 19 (stack46)
        %v26136_v12 = vmul.f32 %v26132_v31, %v130061_v12 (stack54)
        %120655 = vrsqrt.f32 %v130269_v41 (stack67)
        %v26919_v9 = vand.u32 65535, %v26918_v21 (stack50)
        %v28118_v8 = vadd.s32 %v28115_v32, %v121564_v0 (stack40)
        %vm26473_vm14 = vcmp.lt.f32.partialorder %v130269_v41, 5.0 (stack68)
        %v27325_v43 = vxor.u32 %v27324_v34, %v27316_v50 (stack48)
        %v27711_v54 = vshll.u32 %v27705_v30, 13 (stack45)
        %v27712_v6 = vshrl.u32 %v27705_v30, 19 (stack46)
        %v26140_v60 = vsel /*vm=*/%vm25988_vm13, /*on_true_vy=*/%v25993_v29, /*on_false_vx=*/%v26136_v12 (stack44)
        %v28535_v46 = vadd.s32 %v28530_v11, %v121574_v2 (stack40)
        %v26144_v26 = vmul.f32 1.4140625, %v26140_v60 (stack54)
        %v27320_v32 = vadd.s32 %v27316_v50, %v121569_v1 (stack40)
        %v28110_v42 = vadd.s32 %v130242_v42, %v121569_v1 (stack40)
        %v28547_v11 = vor.u32 %v28546_v25, %v28545_v56 (stack47)
        %v130284_v24 = vsel /*vm=*/%vm26473_vm14, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v130289_v44 = vsel /*vm=*/%vm26473_vm14, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v130292_v30 = vadd.f32 -2.5, %v130269_v41 (stack53)
        %v26920_v55 = vshrl.u32 %v26919_v9, 1 (stack51)
        %v26147_v21 = vpack.c.bf16 %v156663_v45, %v26144_v26 (stack81)
        %v27328_v61 = vadd.s32 %v27325_v43, %v121564_v0 (stack40)
        %v27713_v27 = vor.u32 %v27712_v6, %v27711_v54 (stack47)
        %v28122_v50 = vadd.s32 1, %v28118_v8 (stack40)
        %v130299_v40 = vsel /*vm=*/%vm26473_vm14, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v26921_v10 = vor.u32 16256, %v26920_v55 (stack47)
        %v28543_v22 = vadd.s32 %v28539_v22, %v28535_v46 (stack40)
        %vm28970_vm15 = vcmp.lt.u32.totalorder %v130257_v53, %v157089_v17 (stack43)
        %119881 = vst [vmem:[%s123356_s30 + $0x318] sm:$0xf] /*vst_source=*/%v26147_v21 (stack83)
        %vm26518_vm0 = vcmp.eq.f32.partialorder %v130269_v41, inf (stack70)
        %v27332_v29 = vadd.s32 4, %v27328_v61 (stack40)
        %v27714_v31 = vxor.u32 %v27713_v27, %v27709_v23 (stack48)
        %v28126_v34 = vadd.s32 %v28122_v50, %v28110_v42 (stack40)
        %v28128_v56 = vshll.u32 %v28122_v50, 17 (stack45)
        %vm26520_vm1 = vcmp.eq.f32.partialorder %v130269_v41, 0.0 (stack71)
        %v26922_v25 = vand.u32.u16 65535, %v26921_v10 (stack52)
        %v28129_v12 = vshrl.u32 %v28122_v50, 15 (stack46)
        %v28548_v9 = vxor.u32 %v28547_v11, %v28543_v22 (stack48)
        %v27336_v8 = vadd.s32 %v27332_v29, %v27320_v32 (stack40)
        %v27338_v43 = vshll.u32 %v27332_v29, 13 (stack45)
        %v27339_v54 = vshrl.u32 %v27332_v29, 19 (stack46)
        %v27717_v23 = vadd.s32 %v27714_v31, %v27709_v23 (stack40)
        %v119888_v6 = vadd.low.f32.bf16 -1.0, %v26922_v25 (stack53)
        %v27719_v60 = vshll.u32 %v27714_v31, 15 (stack45)
        %v27720_v46 = vshrl.u32 %v27714_v31, 17 (stack46)
        %v28130_v26 = vor.u32 %v28129_v12, %v28128_v56 (stack47)
        %v27340_v32 = vor.u32 %v27339_v54, %v27338_v43 (stack47)
        %v28551_v42 = vadd.s32 %v28548_v9, %v28543_v22 (stack40)
        %v28553_v11 = vshll.u32 %v28548_v9, 15 (stack45)
        %v28554_v55 = vshrl.u32 %v28548_v9, 17 (stack46)
        %v26931_v21 = vmul.f32 2.0, %v119888_v6 (stack54)
        %v27721_v61 = vor.u32 %v27720_v46, %v27719_v60 (stack47)
        %v28131_v27 = vxor.u32 %v28130_v26, %v28126_v34 (stack48)
        %v130308_v50 = vadd.s32 %v157226_v7, %v157090_v62 (stack40)
        %v120656_v10 = vpop.eup %120655 (stack73)
        %v26521_v22 = vand.u32 2147483648, %v130269_v41 (stack72)
        %v27341_v29 = vxor.u32 %v27340_v32, %v27336_v8 (stack48)
        %v28555_v31 = vor.u32 %v28554_v55, %v28553_v11 (stack47)
        %v130313_v56 = vadd.s32 %v157225_v52, %v157091_v37 (stack40)
        %v26517_v25 = vmul.f32 %v120656_v10, %v130269_v41 (stack74)
        %v26935_v12 = vadd.f32 -0.99609375, %v26931_v21 (stack53)
        %v27722_v9 = vxor.u32 %v27721_v61, %v27717_v23 (stack48)
        %v28134_v34 = vadd.s32 %v28131_v27, %v28126_v34 (stack40)
        %v27344_v8 = vadd.s32 %v27341_v29, %v27336_v8 (stack40)
        %v27346_v43 = vshll.u32 %v27341_v29, 15 (stack45)
        %v27347_v54 = vshrl.u32 %v27341_v29, 17 (stack46)
        %v28136_v6 = vshll.u32 %v28131_v27, 29 (stack45)
        %v26519_v60 = vsel /*vm=*/%vm26518_vm0, /*on_true_vy=*/%v130269_v41, /*on_false_vx=*/%v26517_v25 (stack75)
        %v130319_v46 = vmax.f32 %v26935_v12, -0.99609375 (stack55)
        %v27725_v23 = vadd.s32 %v27722_v9, %v27717_v23 (stack40)
        %v27727_v26 = vshll.u32 %v27722_v9, 26 (stack45)
        %v26522_v32 = vsel /*vm=*/%vm26520_vm1, /*on_true_vy=*/%v26521_v22, /*on_false_vx=*/%v26519_v60 (stack76)
        %v27348_v11 = vor.u32 %v27347_v54, %v27346_v43 (stack47)
        %v27728_v55 = vshrl.u32 %v27722_v9, 6 (stack46)
        %v28137_v21 = vshrl.u32 %v28131_v27, 3 (stack46)
        %v26502_v61 = vsel /*vm=*/%vm26473_vm14, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v26525_v27 = vadd.f32 -3.0, %v26522_v32 (stack53)
        %v26951_v10 = vxor.u32 2147483648, %v130319_v46 (stack56)
        %v28961_v22 = vadd.s32 %v130257_v53, %v122657_v58 (stack40)
        %v27349_v29 = vxor.u32 %v27348_v11, %v27344_v8 (stack48)
        %v27729_v25 = vor.u32 %v27728_v55, %v27727_v26 (stack47)
        %v28138_v12 = vor.u32 %v28137_v21, %v28136_v6 (stack47)
        %v28556_v31 = vxor.u32 %v28555_v31, %v28551_v42 (stack48)
        %v26506_v9 = vsel /*vm=*/%vm26473_vm14, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v26510_v43 = vsel /*vm=*/%vm26473_vm14, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v130338_v30 = vsel /*vm=*/%vm26473_vm14, /*on_true_vy=*/%v130292_v30, /*on_false_vx=*/%v26525_v27 (stack44)
        %v130341_v54 = vmul.f32 %v26951_v10, %v130319_v46 (stack54)
        %v26533_v6 = vmul.f32 %v130338_v30, %v26510_v43 (stack54)
        %v27352_v8 = vadd.s32 %v27349_v29, %v27344_v8 (stack40)
        %v27354_v60 = vshll.u32 %v27349_v29, 26 (stack45)
        %v27355_v26 = vshrl.u32 %v27349_v29, 6 (stack46)
        %v26956_v32 = vadd.f32 1.0, %v130341_v54 (stack57)
        %v26959_v11 = vmul.f32 -0.5, %v130341_v54 (stack59)
        %v27730_v55 = vxor.u32 %v27729_v25, %v27725_v23 (stack48)
        %vm28965_vm2 = vcmp.lt.u32.totalorder %v28961_v22, %v130257_v53 (stack43)
        %v26537_v21 = vadd.f32 %v26533_v6, %v26506_v9 (stack53)
        %v27356_v27 = vor.u32 %v27355_v26, %v27354_v60 (stack47)
        %v28139_v10 = vxor.u32 %v28138_v12, %v28134_v34 (stack48)
        %v28559_v42 = vadd.s32 %v28556_v31, %v28551_v42 (stack40)
        %120657 = vlog2.f32 %v26956_v32 (stack58)
        %v27733_v23 = vadd.s32 %v27730_v55, %v27725_v23 (stack40)
        %v28979_v29 = vadd.s32 1, %v130308_v50 (stack40)
        %v29000_v25 = vadd.s32 %v28961_v22, %v121569_v1 (stack40)
        %v26541_v12 = vmul.f32 %v26537_v21, %v130338_v30 (stack54)
        %v27357_v9 = vxor.u32 %v27356_v27, %v27352_v8 (stack48)
        %v27739_v43 = vshll.u32 %v27730_v55, 6 (stack45)
        %v27740_v6 = vshrl.u32 %v27730_v55, 26 (stack46)
        %v26960_v60 = vadd.f32 1.0, %v26959_v11 (stack61)
        %v26962_v26 = vand.u32 2147483647, %v130341_v54 (stack60)
        %v28142_v34 = vadd.s32 %v28139_v10, %v28134_v34 (stack40)
        %v28144_v32 = vshll.u32 %v28139_v10, 16 (stack45)
        %v26545_v61 = vadd.f32 %v26541_v12, %v26502_v61 (stack53)
        %v27360_v8 = vadd.s32 %v27357_v9, %v27352_v8 (stack40)
        %v27366_v11 = vshll.u32 %v27357_v9, 6 (stack45)
        %v27367_v55 = vshrl.u32 %v27357_v9, 26 (stack46)
        %v27741_v21 = vor.u32 %v27740_v6, %v27739_v43 (stack47)
        %v28145_v27 = vshrl.u32 %v28139_v10, 16 (stack46)
        %v28561_v10 = vshll.u32 %v28556_v31, 26 (stack45)
        %v28562_v31 = vshrl.u32 %v28556_v31, 6 (stack46)
        %v26549_v12 = vmul.f32 %v26545_v61, %v130338_v30 (stack54)
        %v27368_v9 = vor.u32 %v27367_v55, %v27366_v11 (stack47)
        %v27737_v43 = vadd.s32 %v27733_v23, %v121574_v2 (stack40)
        %v28983_v50 = vsel /*vm=*/%vm28970_vm15, /*on_true_vy=*/%v28979_v29, /*on_false_vx=*/%v130308_v50 (stack44)
        %v27742_v23 = vxor.u32 %v27741_v21, %v27733_v23 (stack48)
        %v28146_v29 = vor.u32 %v28145_v27, %v28144_v32 (stack47)
        %v28563_v6 = vor.u32 %v28562_v31, %v28561_v10 (stack47)
        %v28987_v32 = vadd.s32 1, %v28983_v50 (stack40)
        %v26553_v40 = vadd.f32 %v26549_v12, %v130299_v40 (stack53)
        %v27369_v61 = vxor.u32 %v27368_v9, %v27360_v8 (stack48)
        %v29006_v11 = vshll.u32 %v29000_v25, 13 (stack45)
        %v29007_v55 = vshrl.u32 %v29000_v25, 19 (stack46)
        %v27745_v21 = vadd.s32 %v27742_v23, %v121569_v1 (stack40)
        %v28147_v27 = vxor.u32 %v28146_v29, %v28142_v34 (stack48)
        %v28564_v10 = vxor.u32 %v28563_v6, %v28559_v42 (stack48)
        %v28991_v53 = vsel /*vm=*/%vm28965_vm2, /*on_true_vy=*/%v28987_v32, /*on_false_vx=*/%v28983_v50 (stack44)
        %v26557_v22 = vmul.f32 %v26553_v40, %v130338_v30 (stack54)
        %v27364_v8 = vadd.s32 %v27360_v8, %v121564_v0 (stack40)
        %v27372_v31 = vadd.s32 %v27369_v61, %v121574_v2 (stack40)
        %v28996_v12 = vadd.s32 %v28991_v53, %v121574_v2 (stack40)
        %v27749_v9 = vadd.s32 3, %v27745_v21 (stack40)
        %v28150_v34 = vadd.s32 %v28147_v27, %v28142_v34 (stack40)
        %v28156_v50 = vshll.u32 %v28147_v27, 24 (stack45)
        %v28157_v23 = vshrl.u32 %v28147_v27, 8 (stack46)
        %v26561_v44 = vadd.f32 %v26557_v22, %v130289_v44 (stack53)
        %v27376_v29 = vadd.s32 5, %v27372_v31 (stack40)
        %v28567_v42 = vadd.s32 %v28564_v10, %v28559_v42 (stack40)
        %v29008_v6 = vor.u32 %v29007_v55, %v29006_v11 (stack47)
        %v27753_v43 = vadd.s32 %v27749_v9, %v27737_v43 (stack40)
        %v27755_v32 = vshll.u32 %v27749_v9, 17 (stack45)
        %v27756_v40 = vshrl.u32 %v27749_v9, 15 (stack46)
        %v28573_v61 = vshll.u32 %v28564_v10, 6 (stack45)
        %v120658_v11 = vpop.eup %120657 (stack64)
        %v26565_v55 = vmul.f32 %v26561_v44, %v130338_v30 (stack54)
        %v26961_v54 = vmul.f32 %v26960_v60, %v130341_v54 (stack63)
        %v27378_v60 = vxor.u32 %v27376_v29, %v27364_v8 (stack48)
        %v28158_v21 = vor.u32 %v28157_v23, %v28156_v50 (stack47)
        %v26958_v27 = vmul.f32 0.6931472, %v120658_v11 (stack65)
        %v27757_v53 = vor.u32 %v27756_v40, %v27755_v32 (stack47)
        %v28574_v10 = vshrl.u32 %v28564_v10, 26 (stack46)
        %v29004_v25 = vadd.s32 %v29000_v25, %v28996_v12 (stack40)
        %v26569_v24 = vadd.f32 %v26565_v55, %v130284_v24 (stack53)
        %vm26963_vm3 = vcmp.lt.f32.partialorder %v26962_v26, 0.0004427343 (stack62)
        %v27379_v26 = vand.u32.u8 255, %v27378_v60 (stack49)
        %v28159_v22 = vxor.u32 %v28158_v21, %v28150_v34 (stack48)
        %v26964_v8 = vsel /*vm=*/%vm26963_vm3, /*on_true_vy=*/%v26961_v54, /*on_false_vx=*/%v26958_v27 (stack66)
        %v27758_v31 = vxor.u32 %v27757_v53, %v27753_v43 (stack48)
        %v28575_v12 = vor.u32 %v28574_v10, %v28573_v61 (stack47)
        %v29009_v9 = vxor.u32 %v29008_v6, %v29004_v25 (stack48)
        %v26446_v50 = vand.u32 2147483647, %v130201_v20 (stack77)
        %v26486_v23 = vsel /*vm=*/%vm26473_vm14, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v26573_v44 = vmul.f32 %v26569_v24, %v130338_v30 (stack54)
        %v130374_v29 = vxor.u32 2147483648, %v26964_v8 (stack56)
        %v27761_v6 = vadd.s32 %v27758_v31, %v27753_v43 (stack40)
        %v27763_v43 = vshll.u32 %v27758_v31, 29 (stack45)
        %v27764_v32 = vshrl.u32 %v27758_v31, 3 (stack46)
        %v28576_v40 = vxor.u32 %v28575_v12, %v28567_v42 (stack48)
        %v26454_v61 = vmul.f32 inf, %v130201_v20 (stack54)
        %v26577_v11 = vadd.f32 %v26573_v44, %v26486_v23 (stack53)
        %120659 = vrsqrt.f32 %v130374_v29 (stack67)
        %v26478_v55 = vsel /*vm=*/%vm26473_vm14, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %vm26968_vm4 = vcmp.lt.f32.partialorder %v130374_v29, 5.0 (stack68)
        %v27380_v54 = vand.u32 65535, %v27379_v26 (stack50)
        %v27765_v60 = vor.u32 %v27764_v32, %v27763_v43 (stack47)
        %v26482_v41 = vsel /*vm=*/%vm26473_vm14, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v26581_v21 = vmul.f32 %v26577_v11, %v130338_v30 (stack54)
        %v26941_v27 = vand.u32 2147483647, %v130319_v46 (stack77)
        %v28162_v53 = vadd.s32 %v28159_v22, %v121574_v2 (stack40)
        %vm130388_vm5 = vcmp.eq.f32.partialorder %v26446_v50, 1.0 (stack68)
        %v130393_v24 = vmul.f32 inf, %v130319_v46 (stack54)
        %v27766_v26 = vxor.u32 %v27765_v60, %v27761_v6 (stack48)
        %v28154_v34 = vadd.s32 %v28150_v34, %v121564_v0 (stack40)
        %v28571_v42 = vadd.s32 %v28567_v42, %v121569_v1 (stack40)
        %v26585_v22 = vadd.f32 %v26581_v21, %v26482_v41 (stack53)
        %v130400_v8 = vsel /*vm=*/%vm26968_vm4, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v130403_v31 = vadd.f32 -2.5, %v130374_v29 (stack53)
        %v130407_v12 = vadd.s32 %v130313_v56, %v122657_v58 (stack40)
        %v27381_v50 = vshrl.u32 %v27380_v54, 1 (stack51)
        %v27769_v23 = vadd.s32 %v27766_v26, %v27761_v6 (stack40)
        %v27771_v44 = vshll.u32 %v27766_v26, 16 (stack45)
        %v27772_v6 = vshrl.u32 %v27766_v26, 16 (stack46)
        %v26589_v30 = vmul.f32 %v26585_v22, %v130338_v30 (stack54)
        %v28166_v43 = vadd.s32 2, %v28162_v53 (stack40)
        %v28579_v32 = vadd.s32 %v28576_v40, %v121564_v0 (stack40)
        %v29012_v25 = vadd.s32 %v29009_v9, %v29004_v25 (stack40)
        %vm27013_vm6 = vcmp.eq.f32.partialorder %v130374_v29, inf (stack70)
        %v27382_v40 = vor.u32 16256, %v27381_v50 (stack47)
        %v27773_v11 = vor.u32 %v27772_v6, %v27771_v44 (stack47)
        %v29014_v54 = vshll.u32 %v29009_v9, 15 (stack45)
        %v29015_v9 = vshrl.u32 %v29009_v9, 17 (stack46)
        %v26593_v55 = vadd.f32 %v26589_v30, %v26478_v55 (stack53)
        %v28170_v60 = vadd.s32 %v28166_v43, %v28154_v34 (stack40)
        %v28172_v41 = vshll.u32 %v28166_v43, 13 (stack45)
        %v28173_v21 = vshrl.u32 %v28166_v43, 19 (stack46)
        %vm27015_vm7 = vcmp.eq.f32.partialorder %v130374_v29, 0.0 (stack71)
        %v27383_v53 = vand.u32.u16 65535, %v27382_v40 (stack52)
        %v27774_v26 = vxor.u32 %v27773_v11, %v27769_v23 (stack48)
        %v28583_v34 = vadd.s32 1, %v28579_v32 (stack40)
        %v26597_v20 = vmul.f32 %v26593_v55, %v130201_v20 (stack54)
        %v27016_v22 = vand.u32 2147483648, %v130374_v29 (stack72)
        %v28174_v50 = vor.u32 %v28173_v21, %v28172_v41 (stack47)
        %vm29431_vm8 = vcmp.lt.u32.totalorder %v130313_v56, %v157091_v37 (stack43)
        %v119890_v44 = vadd.low.f32.bf16 -1.0, %v27383_v53 (stack53)
        %v27777_v23 = vadd.s32 %v27774_v26, %v27769_v23 (stack40)
        %v27783_v6 = vshll.u32 %v27774_v26, 24 (stack45)
        %v27784_v30 = vshrl.u32 %v27774_v26, 8 (stack46)
        %v26601_v61 = vsel /*vm=*/%vm130388_vm5, /*on_true_vy=*/%v26454_v61, /*on_false_vx=*/%v26597_v20 (stack44)
        %v28175_v10 = vxor.u32 %v28174_v50, %v28170_v60 (stack48)
        %v28587_v42 = vadd.s32 %v28583_v34, %v28571_v42 (stack40)
        %v29016_v43 = vor.u32 %v29015_v9, %v29014_v54 (stack47)
        %v120660_v32 = vpop.eup %120659 (stack73)
        %v26605_v40 = vmul.f32 1.4140625, %v26601_v61 (stack54)
        %v27392_v11 = vmul.f32 2.0, %v119890_v44 (stack54)
        %v27785_v54 = vor.u32 %v27784_v30, %v27783_v6 (stack47)
        %v28589_v9 = vshll.u32 %v28583_v34, 17 (stack45)
        %v27012_v55 = vmul.f32 %v120660_v32, %v130374_v29 (stack74)
        %v28178_v60 = vadd.s32 %v28175_v10, %v28170_v60 (stack40)
        %v28180_v41 = vshll.u32 %v28175_v10, 15 (stack45)
        %v28181_v21 = vshrl.u32 %v28175_v10, 17 (stack46)
        %v26608_v53 = vpack.c.bf16 %v156663_v45, %v26605_v40 (stack81)
        %v27396_v26 = vadd.f32 -0.99609375, %v27392_v11 (stack53)
        %v27786_v20 = vxor.u32 %v27785_v54, %v27777_v23 (stack48)
        %v28590_v34 = vshrl.u32 %v28583_v34, 15 (stack46)
        %v27014_v50 = vsel /*vm=*/%vm27013_vm6, /*on_true_vy=*/%v130374_v29, /*on_false_vx=*/%v27012_v55 (stack75)
        %v28182_v44 = vor.u32 %v28181_v21, %v28180_v41 (stack47)
        %v29017_v6 = vxor.u32 %v29016_v43, %v29012_v25 (stack48)
        %v130426_v30 = vadd.s32 %v157226_v7, %v157094_v36 (stack40)
        %119883 = vst [vmem:[%s123356_s30 + $0x398] sm:$0xf] /*vst_source=*/%v26608_v53 (stack83)
        %v130432_v61 = vsel /*vm=*/%vm26968_vm4, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v27017_v22 = vsel /*vm=*/%vm27015_vm7, /*on_true_vy=*/%v27016_v22, /*on_false_vx=*/%v27014_v50 (stack76)
        %v130436_v10 = vmax.f32 %v27396_v26, -0.99609375 (stack55)
        %v27789_v43 = vadd.s32 %v27786_v20, %v121564_v0 (stack40)
        %v27020_v32 = vadd.f32 -3.0, %v27017_v22 (stack53)
        %v28183_v40 = vxor.u32 %v28182_v44, %v28178_v60 (stack48)
        %v28591_v11 = vor.u32 %v28590_v34, %v28589_v9 (stack47)
        %v130439_v25 = vadd.s32 %v29017_v6, %v29012_v25 (stack40)
        %v27005_v54 = vsel /*vm=*/%vm26968_vm4, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v27412_v9 = vxor.u32 2147483648, %v130436_v10 (stack56)
        %v27781_v23 = vadd.s32 %v27777_v23, %v121569_v1 (stack40)
        %v27793_v55 = vadd.s32 4, %v27789_v43 (stack40)
        %v130449_v31 = vsel /*vm=*/%vm26968_vm4, /*on_true_vy=*/%v130403_v31, /*on_false_vx=*/%v27020_v32 (stack44)
        %v28186_v60 = vadd.s32 %v28183_v40, %v28178_v60 (stack40)
        %v28188_v41 = vshll.u32 %v28183_v40, 26 (stack45)
        %v28189_v21 = vshrl.u32 %v28183_v40, 6 (stack46)
        %v27001_v53 = vsel /*vm=*/%vm26968_vm4, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v27028_v26 = vmul.f32 %v130449_v31, %v27005_v54 (stack54)
        %v27415_v20 = vmul.f32 %v27412_v9, %v130436_v10 (stack54)
        %v27797_v34 = vadd.s32 %v27793_v55, %v27781_v23 (stack40)
        %v27799_v50 = vshll.u32 %v27793_v55, 13 (stack45)
        %v27800_v44 = vshrl.u32 %v27793_v55, 19 (stack46)
        %v28190_v22 = vor.u32 %v28189_v21, %v28188_v41 (stack47)
        %v28592_v43 = vxor.u32 %v28591_v11, %v28587_v42 (stack48)
        %v26989_v32 = vsel /*vm=*/%vm26968_vm4, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v26993_v40 = vsel /*vm=*/%vm26968_vm4, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v27032_v11 = vadd.f32 %v27028_v26, %v27001_v53 (stack53)
        %v27417_v54 = vadd.f32 1.0, %v27415_v20 (stack57)
        %v26997_v9 = vsel /*vm=*/%vm26968_vm4, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v27801_v23 = vor.u32 %v27800_v44, %v27799_v50 (stack47)
        %v28191_v55 = vxor.u32 %v28190_v22, %v28186_v60 (stack48)
        %v28595_v42 = vadd.s32 %v28592_v43, %v28587_v42 (stack40)
        %v27036_v41 = vmul.f32 %v27032_v11, %v130449_v31 (stack54)
        %120661 = vlog2.f32 %v27417_v54 (stack58)
        %v28597_v21 = vshll.u32 %v28592_v43, 29 (stack45)
        %v29022_v53 = vshll.u32 %v29017_v6, 26 (stack45)
        %v27802_v26 = vxor.u32 %v27801_v23, %v27797_v34 (stack48)
        %v28194_v60 = vadd.s32 %v28191_v55, %v28186_v60 (stack40)
        %v28200_v50 = vshll.u32 %v28191_v55, 6 (stack45)
        %v28201_v44 = vshrl.u32 %v28191_v55, 26 (stack46)
        %v27040_v22 = vadd.f32 %v27036_v41, %v26997_v9 (stack53)
        %v27420_v11 = vmul.f32 -0.5, %v27415_v20 (stack59)
        %v28598_v43 = vshrl.u32 %v28592_v43, 3 (stack46)
        %v29023_v6 = vshrl.u32 %v29017_v6, 6 (stack46)
        %v27423_v54 = vand.u32 2147483647, %v27415_v20 (stack60)
        %v27805_v34 = vadd.s32 %v27802_v26, %v27797_v34 (stack40)
        %v27807_v9 = vshll.u32 %v27802_v26, 15 (stack45)
        %v27808_v23 = vshrl.u32 %v27802_v26, 17 (stack46)
        %v27044_v55 = vmul.f32 %v27040_v22, %v130449_v31 (stack54)
        %v28202_v41 = vor.u32 %v28201_v44, %v28200_v50 (stack47)
        %v28599_v21 = vor.u32 %v28598_v43, %v28597_v21 (stack47)
        %v29024_v53 = vor.u32 %v29023_v6, %v29022_v53 (stack47)
        %v27809_v26 = vor.u32 %v27808_v23, %v27807_v9 (stack47)
        %vm29426_vm9 = vcmp.lt.u32.totalorder %v130407_v12, %v130313_v56 (stack43)
        %v29440_v50 = vadd.s32 1, %v130426_v30 (stack40)
        %v130472_v52 = vadd.s32 %v157225_v52, %v157095_v13 (stack40)
        %v27048_v40 = vadd.f32 %v27044_v55, %v26993_v40 (stack53)
        %v28203_v44 = vxor.u32 %v28202_v41, %v28194_v60 (stack48)
        %v28600_v22 = vxor.u32 %v28599_v21, %v28595_v42 (stack48)
        %v29025_v43 = vxor.u32 %v29024_v53, %v130439_v25 (stack48)
        %v27421_v11 = vadd.f32 1.0, %v27420_v11 (stack61)
        %vm130475_vm10 = vcmp.lt.f32.partialorder %v27423_v54, 0.0004427343 (stack62)
        %v27810_v54 = vxor.u32 %v27809_v26, %v27805_v34 (stack48)
        %v29444_v30 = vsel /*vm=*/%vm29431_vm8, /*on_true_vy=*/%v29440_v50, /*on_false_vx=*/%v130426_v30 (stack44)
        %v27052_v9 = vmul.f32 %v27048_v40, %v130449_v31 (stack54)
        %v28206_v23 = vadd.s32 %v28203_v44, %v121569_v1 (stack40)
        %v28603_v42 = vadd.s32 %v28600_v22, %v28595_v42 (stack40)
        %v28605_v55 = vshll.u32 %v28600_v22, 16 (stack45)
        %v27813_v34 = vadd.s32 %v27810_v54, %v27805_v34 (stack40)
        %v27815_v41 = vshll.u32 %v27810_v54, 26 (stack45)
        %v27816_v21 = vshrl.u32 %v27810_v54, 6 (stack46)
        %v28606_v53 = vshrl.u32 %v28600_v22, 16 (stack46)
        %v27056_v32 = vadd.f32 %v27052_v9, %v26989_v32 (stack53)
        %v28198_v60 = vadd.s32 %v28194_v60, %v121574_v2 (stack40)
        %v28210_v26 = vadd.s32 3, %v28206_v23 (stack40)
        %v130487_v25 = vadd.s32 %v29025_v43, %v130439_v25 (stack40)
        %v27422_v20 = vmul.f32 %v27421_v11, %v27415_v20 (stack63)
        %v27817_v50 = vor.u32 %v27816_v21, %v27815_v41 (stack47)
        %v28607_v40 = vor.u32 %v28606_v53, %v28605_v55 (stack47)
        %v29448_v44 = vadd.s32 1, %v29444_v30 (stack40)
        %v27060_v22 = vmul.f32 %v27056_v32, %v130449_v31 (stack54)
        %v28214_v11 = vadd.s32 %v28210_v26, %v28198_v60 (stack40)
        %v28216_v54 = vshll.u32 %v28210_v26, 17 (stack45)
        %v28217_v9 = vshrl.u32 %v28210_v26, 15 (stack46)
        %v120662_v23 = vpop.eup %120661 (stack64)
        %v27818_v55 = vxor.u32 %v27817_v50, %v27813_v34 (stack48)
        %v28608_v41 = vxor.u32 %v28607_v40, %v28603_v42 (stack48)
        %v29034_v21 = vshll.u32 %v29025_v43, 6 (stack45)
        %v29461_v53 = vadd.s32 %v130407_v12, %v121569_v1 (stack40)
        %v27064_v61 = vadd.f32 %v27060_v22, %v130432_v61 (stack53)
        %v27419_v32 = vmul.f32 0.6931472, %v120662_v23 (stack65)
        %v28218_v60 = vor.u32 %v28217_v9, %v28216_v54 (stack47)
        %v29452_v56 = vsel /*vm=*/%vm29426_vm9, /*on_true_vy=*/%v29448_v44, /*on_false_vx=*/%v29444_v30 (stack44)
        %v27821_v12 = vadd.s32 %v27818_v55, %v27813_v34 (stack40)
        %v27827_v30 = vshll.u32 %v27818_v55, 6 (stack45)
        %v27828_v34 = vshrl.u32 %v27818_v55, 26 (stack46)
        %v28611_v42 = vadd.s32 %v28608_v41, %v28603_v42 (stack40)
        %v27068_v26 = vmul.f32 %v27064_v61, %v130449_v31 (stack54)
        %v27425_v6 = vsel /*vm=*/%vm130475_vm10, /*on_true_vy=*/%v27422_v20, /*on_false_vx=*/%v27419_v32 (stack66)
        %v28219_v20 = vxor.u32 %v28218_v60, %v28214_v11 (stack48)
        %v29035_v43 = vshrl.u32 %v29025_v43, 26 (stack46)
        %v26977_v50 = vsel /*vm=*/%vm26968_vm4, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v26981_v29 = vsel /*vm=*/%vm26968_vm4, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v130505_v40 = vxor.u32 2147483648, %v27425_v6 (stack56)
        %v27829_v44 = vor.u32 %v27828_v34, %v27827_v30 (stack47)
        %v27072_v22 = vadd.f32 %v27068_v26, %v26981_v29 (stack53)
        %v27402_v54 = vand.u32 2147483647, %v130436_v10 (stack77)
        %v28222_v11 = vadd.s32 %v28219_v20, %v28214_v11 (stack40)
        %v29467_v9 = vshll.u32 %v29461_v53, 13 (stack45)
        %vm27429_vm11 = vcmp.lt.f32.partialorder %v130505_v40, 5.0 (stack68)
        %120663 = vrsqrt.f32 %v130505_v40 (stack67)
        %v28224_v23 = vshll.u32 %v28219_v20, 29 (stack45)
        %v28225_v55 = vshrl.u32 %v28219_v20, 3 (stack46)
        %v27076_v61 = vmul.f32 %v27072_v22, %v130449_v31 (stack54)
        %v29032_v32 = vadd.s32 %v130487_v25, %v121569_v1 (stack40)
        %v29036_v21 = vor.u32 %v29035_v43, %v29034_v21 (stack47)
        %v29468_v60 = vshrl.u32 %v29461_v53, 19 (stack46)
        %vm130515_vm12 = vcmp.eq.f32.partialorder %v26941_v27, 1.0 (stack68)
        %v27825_v30 = vadd.s32 %v27821_v12, %v121564_v0 (stack40)
        %v27830_v12 = vxor.u32 %v27829_v44, %v27821_v12 (stack48)
        %v28615_v34 = vadd.s32 %v28611_v42, %v121564_v0 (stack40)
        %v28617_v26 = vshll.u32 %v28608_v41, 24 (stack45)
        %v27080_v6 = vadd.f32 %v27076_v61, %v26977_v50 (stack53)
        %v130524_v20 = vsel /*vm=*/%vm27429_vm11, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v130529_v43 = vsel /*vm=*/%vm27429_vm11, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v130532_v50 = vadd.f32 -2.5, %v130505_v40 (stack53)
        %v130537_v29 = vsel /*vm=*/%vm27429_vm11, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v130542_v44 = vsel /*vm=*/%vm27429_vm11, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v27833_v22 = vadd.s32 %v27830_v12, %v121574_v2 (stack40)
        %v28226_v23 = vor.u32 %v28225_v55, %v28224_v23 (stack47)
        %v27084_v31 = vmul.f32 %v27080_v6, %v130449_v31 (stack54)
        %v28618_v41 = vshrl.u32 %v28608_v41, 8 (stack46)
        %v29037_v25 = vxor.u32 %v29036_v21, %v130487_v25 (stack48)
        %v29457_v56 = vadd.s32 %v29452_v56, %v121574_v2 (stack40)
        %v130551_v55 = vsel /*vm=*/%vm27429_vm11, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v27837_v61 = vadd.s32 5, %v27833_v22 (stack40)
        %v28227_v21 = vxor.u32 %v28226_v23, %v28222_v11 (stack48)
        %v29469_v9 = vor.u32 %v29468_v60, %v29467_v9 (stack47)
        %v27088_v8 = vadd.f32 %v27084_v31, %v130400_v8 (stack53)
        %vm27474_vm13 = vcmp.eq.f32.partialorder %v130505_v40, inf (stack70)
        %v28619_v60 = vor.u32 %v28618_v41, %v28617_v26 (stack47)
        %v29040_v12 = vadd.s32 %v29037_v25, %v121564_v0 (stack40)
        %v29465_v53 = vadd.s32 %v29461_v53, %v29457_v56 (stack40)
        %v27839_v30 = vxor.u32 %v27837_v61, %v27825_v30 (stack48)
        %v28230_v11 = vadd.s32 %v28227_v21, %v28222_v11 (stack40)
        %v28232_v26 = vshll.u32 %v28227_v21, 16 (stack45)
        %v28233_v6 = vshrl.u32 %v28227_v21, 16 (stack46)
        %v27092_v46 = vmul.f32 %v27088_v8, %v130319_v46 (stack54)
        %v28620_v42 = vxor.u32 %v28619_v60, %v28611_v42 (stack48)
        %v29044_v22 = vadd.s32 1, %v29040_v12 (stack40)
        %v29470_v23 = vxor.u32 %v29469_v9, %v29465_v53 (stack48)
        %v27477_v31 = vand.u32 2147483648, %v130505_v40 (stack72)
        %v27840_v41 = vand.u32.u8 255, %v27839_v30 (stack49)
        %v28234_v25 = vor.u32 %v28233_v6, %v28232_v26 (stack47)
        %vm29892_vm14 = vcmp.lt.u32.totalorder %v130472_v52, %v157095_v13 (stack43)
        %v27096_v24 = vsel /*vm=*/%vm130515_vm12, /*on_true_vy=*/%v130393_v24, /*on_false_vx=*/%v27092_v46 (stack44)
        %v28623_v27 = vadd.s32 %v28620_v42, %v121574_v2 (stack40)
        %v29048_v32 = vadd.s32 %v29044_v22, %v29032_v32 (stack40)
        %v29050_v56 = vshll.u32 %v29044_v22, 17 (stack45)
        %v27100_v61 = vmul.f32 1.4140625, %v27096_v24 (stack54)
        %v27841_v21 = vand.u32 65535, %v27840_v41 (stack50)
        %v28235_v9 = vxor.u32 %v28234_v25, %v28230_v11 (stack48)
        %v29051_v8 = vshrl.u32 %v29044_v22, 15 (stack46)
        %v120664_v60 = vpop.eup %120663 (stack73)
        %v28627_v12 = vadd.s32 2, %v28623_v27 (stack40)
        %v29473_v53 = vadd.s32 %v29470_v23, %v29465_v53 (stack40)
        %v29475_v30 = vshll.u32 %v29470_v23, 15 (stack45)
        %v29476_v26 = vshrl.u32 %v29470_v23, 17 (stack46)
        %v27103_v6 = vpack.c.bf16 %v156663_v45, %v27100_v61 (stack81)
        %v27473_v46 = vmul.f32 %v120664_v60, %v130505_v40 (stack74)
        %v27842_v42 = vshrl.u32 %v27841_v21, 1 (stack51)
        %v28238_v11 = vadd.s32 %v28235_v9, %v28230_v11 (stack40)
        %v28244_v22 = vshll.u32 %v28235_v9, 24 (stack45)
        %v28245_v23 = vshrl.u32 %v28235_v9, 8 (stack46)
        %v28631_v34 = vadd.s32 %v28627_v12, %v28615_v34 (stack40)
        %v28633_v41 = vshll.u32 %v28627_v12, 13 (stack45)
        %119889 = vst [vmem:[%s123356_s30 + $0x1c] sm:$0xf] /*vst_source=*/%v27103_v6 (stack83)
        %v27475_v25 = vsel /*vm=*/%vm27474_vm13, /*on_true_vy=*/%v130505_v40, /*on_false_vx=*/%v27473_v46 (stack75)
        %vm27476_vm15 = vcmp.eq.f32.partialorder %v130505_v40, 0.0 (stack71)
        %v27843_v24 = vor.u32 16256, %v27842_v42 (stack47)
        %v28634_v27 = vshrl.u32 %v28627_v12, 19 (stack46)
        %v27478_v31 = vsel /*vm=*/%vm27476_vm15, /*on_true_vy=*/%v27477_v31, /*on_false_vx=*/%v27475_v25 (stack76)
        %v28246_v61 = vor.u32 %v28245_v23, %v28244_v22 (stack47)
        %v29052_v56 = vor.u32 %v29051_v8, %v29050_v56 (stack47)
        %v29477_v21 = vor.u32 %v29476_v26, %v29475_v30 (stack47)
        %v27481_v9 = vadd.f32 -3.0, %v27478_v31 (stack53)
        %v27844_v8 = vand.u32.u16 65535, %v27843_v24 (stack52)
        %v28635_v60 = vor.u32 %v28634_v27, %v28633_v41 (stack47)
        %v29897_v7 = vadd.s32 %v157226_v7, %v157100_v14 (stack40)
        %v28242_v12 = vadd.s32 %v28238_v11, %v121569_v1 (stack40)
        %v28247_v30 = vxor.u32 %v28246_v61, %v28238_v11 (stack48)
        %v29053_v26 = vxor.u32 %v29052_v56, %v29048_v32 (stack48)
        %v29478_v6 = vxor.u32 %v29477_v21, %v29473_v53 (stack48)
        %v130577_v50 = vsel /*vm=*/%vm27429_vm11, /*on_true_vy=*/%v130532_v50, /*on_false_vx=*/%v27481_v9 (stack44)
        %v119892_v46 = vadd.low.f32.bf16 -1.0, %v27844_v8 (stack53)
        %v28636_v42 = vxor.u32 %v28635_v60, %v28631_v34 (stack48)
        %v29901_v11 = vadd.s32 1, %v29897_v7 (stack40)
        %v27489_v55 = vmul.f32 %v130577_v50, %v130551_v55 (stack54)
        %v28250_v22 = vadd.s32 %v28247_v30, %v121564_v0 (stack40)
        %v29056_v32 = vadd.s32 %v29053_v26, %v29048_v32 (stack40)
        %v29058_v23 = vshll.u32 %v29053_v26, 29 (stack45)
        %v27853_v41 = vmul.f32 2.0, %v119892_v46 (stack54)
        %v28639_v34 = vadd.s32 %v28636_v42, %v28631_v34 (stack40)
        %v28641_v25 = vshll.u32 %v28636_v42, 15 (stack45)
        %v28642_v24 = vshrl.u32 %v28636_v42, 17 (stack46)
        %v27493_v44 = vadd.f32 %v27489_v55, %v130542_v44 (stack53)
        %v28254_v27 = vadd.s32 4, %v28250_v22 (stack40)
        %v29059_v31 = vshrl.u32 %v29053_v26, 3 (stack46)
        %v29481_v53 = vadd.s32 %v29478_v6, %v29473_v53 (stack40)
        %v27857_v61 = vadd.f32 -0.99609375, %v27853_v41 (stack53)
        %v28643_v56 = vor.u32 %v28642_v24, %v28641_v25 (stack47)
        %v29483_v21 = vshll.u32 %v29478_v6, 26 (stack45)
        %v29484_v9 = vshrl.u32 %v29478_v6, 6 (stack46)
        %v27497_v8 = vmul.f32 %v27493_v44, %v130577_v50 (stack54)
        %v28258_v60 = vadd.s32 %v28254_v27, %v28242_v12 (stack40)
        %v28260_v12 = vshll.u32 %v28254_v27, 13 (stack45)
        %v28261_v30 = vshrl.u32 %v28254_v27, 19 (stack46)
        %v130584_v26 = vmax.f32 %v27857_v61, -0.99609375 (stack55)
        %v28644_v6 = vxor.u32 %v28643_v56, %v28639_v34 (stack48)
        %v29060_v46 = vor.u32 %v29059_v31, %v29058_v23 (stack47)
        %v29485_v42 = vor.u32 %v29484_v9, %v29483_v21 (stack47)
        %v130589_v55 = vsel /*vm=*/%vm27429_vm11, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v27501_v29 = vadd.f32 %v27497_v8, %v130537_v29 (stack53)
        %v28262_v22 = vor.u32 %v28261_v30, %v28260_v12 (stack47)
        %v130595_v7 = vsel /*vm=*/%vm29892_vm14, /*on_true_vy=*/%v29901_v11, /*on_false_vx=*/%v29897_v7 (stack44)
        %v27446_v11 = vsel /*vm=*/%vm27429_vm11, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v27873_v23 = vxor.u32 2147483648, %v130584_v26 (stack56)
        %v28647_v41 = vadd.s32 %v28644_v6, %v28639_v34 (stack40)
        %v130603_v34 = vadd.s32 %v130472_v52, %v122657_v58 (stack40)
        %v27505_v25 = vmul.f32 %v27501_v29, %v130577_v50 (stack54)
        %v28263_v24 = vxor.u32 %v28262_v22, %v28258_v60 (stack48)
        %v28649_v44 = vshll.u32 %v28644_v6, 26 (stack45)
        %v28650_v27 = vshrl.u32 %v28644_v6, 6 (stack46)
        %v27454_v31 = vsel /*vm=*/%vm27429_vm11, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v27876_v61 = vmul.f32 %v27873_v23, %v130584_v26 (stack54)
        %v29061_v56 = vxor.u32 %v29060_v46, %v29056_v32 (stack48)
        %v29486_v21 = vxor.u32 %v29485_v42, %v29481_v53 (stack48)
        %v27509_v9 = vadd.f32 %v27505_v25, %v27454_v31 (stack53)
        %v28266_v8 = vadd.s32 %v28263_v24, %v28258_v60 (stack40)
        %v28268_v60 = vshll.u32 %v28263_v24, 15 (stack45)
        %v28269_v12 = vshrl.u32 %v28263_v24, 17 (stack46)
        %v27450_v40 = vsel /*vm=*/%vm27429_vm11, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v27878_v30 = vadd.f32 1.0, %v27876_v61 (stack57)
        %v27881_v6 = vmul.f32 -0.5, %v27876_v61 (stack59)
        %v28651_v46 = vor.u32 %v28650_v27, %v28649_v44 (stack47)
        %v27513_v42 = vmul.f32 %v27509_v9, %v130577_v50 (stack54)
        %v28270_v29 = vor.u32 %v28269_v12, %v28268_v60 (stack47)
        %v29064_v32 = vadd.s32 %v29061_v56, %v29056_v32 (stack40)
        %v130616_v22 = vadd.s32 %v130603_v34, %v121569_v1 (stack40)
        %120665 = vlog2.f32 %v27878_v30 (stack58)
        %v27884_v23 = vand.u32 2147483647, %v27876_v61 (stack60)
        %v28652_v25 = vxor.u32 %v28651_v46, %v28647_v41 (stack48)
        %v29066_v24 = vshll.u32 %v29061_v56, 16 (stack45)
        %v27517_v44 = vadd.f32 %v27513_v42, %v27450_v40 (stack53)
        %v28271_v27 = vxor.u32 %v28270_v29, %v28266_v8 (stack48)
        %v29067_v31 = vshrl.u32 %v29061_v56, 16 (stack46)
        %v29489_v53 = vadd.s32 %v29486_v21, %v29481_v53 (stack40)
        %v27882_v56 = vadd.f32 1.0, %v27881_v6 (stack61)
        %v28655_v41 = vadd.s32 %v28652_v25, %v28647_v41 (stack40)
        %v28661_v9 = vshll.u32 %v28652_v25, 6 (stack45)
        %v28662_v60 = vshrl.u32 %v28652_v25, 26 (stack46)
        %v27521_v12 = vmul.f32 %v27517_v44, %v130577_v50 (stack54)
        %v28274_v8 = vadd.s32 %v28271_v27, %v28266_v8 (stack40)
        %v28276_v40 = vshll.u32 %v28271_v27, 26 (stack45)
        %v28277_v30 = vshrl.u32 %v28271_v27, 6 (stack46)
        %v28663_v6 = vor.u32 %v28662_v60, %v28661_v9 (stack47)
        %v29068_v46 = vor.u32 %v29067_v31, %v29066_v24 (stack47)
        %vm29887_vm0 = vcmp.lt.u32.totalorder %v130603_v34, %v130472_v52 (stack43)
        %v29928_v42 = vshll.u32 %v130616_v22, 13 (stack45)
        %v27525_v11 = vadd.f32 %v27521_v12, %v27446_v11 (stack53)
        %v28278_v29 = vor.u32 %v28277_v30, %v28276_v40 (stack47)
        %v29495_v25 = vshll.u32 %v29486_v21, 6 (stack45)
        %v29496_v21 = vshrl.u32 %v29486_v21, 26 (stack46)
        %v27883_v61 = vmul.f32 %v27882_v56, %v27876_v61 (stack63)
        %v28664_v24 = vxor.u32 %v28663_v6, %v28655_v41 (stack48)
        %v29069_v44 = vxor.u32 %v29068_v46, %v29064_v32 (stack48)
        %v29909_v27 = vadd.s32 1, %v130595_v7 (stack40)
        %v27529_v31 = vmul.f32 %v27525_v11, %v130577_v50 (stack54)
        %vm130624_vm1 = vcmp.lt.f32.partialorder %v27884_v23, 0.0004427343 (stack62)
        %v28279_v56 = vxor.u32 %v28278_v29, %v28274_v8 (stack48)
        %v29497_v9 = vor.u32 %v29496_v21, %v29495_v25 (stack47)
        %v157247_v60 = vld [vmem:[#allocation132_spill] sm:$0xff] (stack84)
        %v130630_v12 = vadd.s32 %v157247_v60, %v122651_v47 (stack40)
        %v28667_v40 = vadd.s32 %v28664_v24, %v121569_v1 (stack40)
        %v29072_v32 = vadd.s32 %v29069_v44, %v29064_v32 (stack40)
        %v29078_v30 = vshll.u32 %v29069_v44, 24 (stack45)
        %v29079_v6 = vshrl.u32 %v29069_v44, 8 (stack46)
        %v27533_v55 = vadd.f32 %v27529_v31, %v130589_v55 (stack53)
        %v28282_v8 = vadd.s32 %v28279_v56, %v28274_v8 (stack40)
        %v28288_v46 = vshll.u32 %v28279_v56, 6 (stack45)
        %v28289_v11 = vshrl.u32 %v28279_v56, 26 (stack46)
        %v28659_v41 = vadd.s32 %v28655_v41, %v121574_v2 (stack40)
        %v28671_v29 = vadd.s32 3, %v28667_v40 (stack40)
        %v29080_v25 = vor.u32 %v29079_v6, %v29078_v30 (stack47)
        %v29498_v21 = vxor.u32 %v29497_v9, %v29489_v53 (stack48)
        %v27537_v24 = vmul.f32 %v27533_v55, %v130577_v50 (stack54)
        %v28290_v44 = vor.u32 %v28289_v11, %v28288_v46 (stack47)
        %v29493_v53 = vadd.s32 %v29489_v53, %v121569_v1 (stack40)
        %v29913_v52 = vsel /*vm=*/%vm29887_vm0, /*on_true_vy=*/%v29909_v27, /*on_false_vx=*/%v130595_v7 (stack44)
        %v28675_v7 = vadd.s32 %v28671_v29, %v28659_v41 (stack40)
        %v28677_v34 = vshll.u32 %v28671_v29, 17 (stack45)
        %v28678_v27 = vshrl.u32 %v28671_v29, 15 (stack46)
        %v29081_v31 = vxor.u32 %v29080_v25, %v29072_v32 (stack48)
        %v120666_v56 = vpop.eup %120665 (stack64)
        %v27541_v43 = vadd.f32 %v27537_v24, %v130529_v43 (stack53)
        %v28291_v9 = vxor.u32 %v28290_v44, %v28282_v8 (stack48)
        %v29501_v40 = vadd.s32 %v29498_v21, %v121564_v0 (stack40)
        %v29918_v30 = vadd.s32 %v29913_v52, %v121574_v2 (stack40)
        %v27880_v6 = vmul.f32 0.6931472, %v120666_v56 (stack65)
        %v28679_v55 = vor.u32 %v28678_v27, %v28677_v34 (stack47)
        %v29084_v46 = vadd.s32 %v29081_v31, %v121574_v2 (stack40)
        %v29929_v11 = vshrl.u32 %v130616_v22, 19 (stack46)
        %v27545_v50 = vmul.f32 %v27541_v43, %v130577_v50 (stack54)
        %v28294_v41 = vadd.s32 %v28291_v9, %v121574_v2 (stack40)
        %v29505_v29 = vadd.s32 1, %v29501_v40 (stack40)
        %v29926_v25 = vadd.s32 %v130616_v22, %v29918_v30 (stack40)
        %v27886_v61 = vsel /*vm=*/%vm130624_vm1, /*on_true_vy=*/%v27883_v61, /*on_false_vx=*/%v27880_v6 (stack66)
        %v28680_v23 = vxor.u32 %v28679_v55, %v28675_v7 (stack48)
        %v29076_v32 = vadd.s32 %v29072_v32, %v121564_v0 (stack40)
        %v29088_v21 = vadd.s32 2, %v29084_v46 (stack40)
        %v27549_v20 = vadd.f32 %v27545_v50, %v130524_v20 (stack53)
        %v130653_v24 = vxor.u32 2147483648, %v27886_v61 (stack56)
        %v28298_v44 = vadd.s32 5, %v28294_v41 (stack40)
        %v29509_v53 = vadd.s32 %v29505_v29, %v29493_v53 (stack40)
        %v28286_v8 = vadd.s32 %v28282_v8, %v121564_v0 (stack40)
        %v28683_v52 = vadd.s32 %v28680_v23, %v28675_v7 (stack40)
        %v29092_v7 = vadd.s32 %v29088_v21, %v29076_v32 (stack40)
        %v27410_v34 = vmul.f32 inf, %v130436_v10 (stack54)
        %v27553_v27 = vmul.f32 %v27549_v20, %v130436_v10 (stack54)
        %vm27890_vm2 = vcmp.lt.f32.partialorder %v130653_v24, 5.0 (stack68)
        %120667 = vrsqrt.f32 %v130653_v24 (stack67)
        %vm27405_vm3 = vcmp.eq.f32.partialorder %v27402_v54, 1.0 (stack68)
        %v28300_v10 = vxor.u32 %v28298_v44, %v28286_v8 (stack48)
        %v28685_v54 = vshll.u32 %v28680_v23, 29 (stack45)
        %v28686_v31 = vshrl.u32 %v28680_v23, 3 (stack46)
        %v27557_v56 = vsel /*vm=*/%vm27405_vm3, /*on_true_vy=*/%v27410_v34, /*on_false_vx=*/%v27553_v27 (stack44)
        %v27863_v43 = vand.u32 2147483647, %v130584_v26 (stack77)
        %v29930_v22 = vor.u32 %v29929_v11, %v29928_v42 (stack47)
        %v27561_v42 = vmul.f32 1.4140625, %v27557_v56 (stack54)
        %v130668_v9 = vsel /*vm=*/%vm27890_vm2, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v130673_v40 = vsel /*vm=*/%vm27890_vm2, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v130677_v30 = vadd.s32 %v130630_v12, %v122657_v58 (stack40)
        %v130682_v6 = vsel /*vm=*/%vm27890_vm2, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v130687_v55 = vsel /*vm=*/%vm27890_vm2, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v130690_v46 = vadd.f32 -2.5, %v130653_v24 (stack53)
        %v28301_v11 = vand.u32.u8 255, %v28300_v10 (stack49)
        %v27564_v50 = vpack.c.bf16 %v156663_v45, %v27561_v42 (stack81)
        %v28687_v41 = vor.u32 %v28686_v31, %v28685_v54 (stack47)
        %v29094_v61 = vshll.u32 %v29088_v21, 13 (stack45)
        %v29095_v23 = vshrl.u32 %v29088_v21, 19 (stack46)
        %v28302_v32 = vand.u32 65535, %v28301_v11 (stack50)
        %v29511_v21 = vshll.u32 %v29505_v29, 17 (stack45)
        %v29512_v29 = vshrl.u32 %v29505_v29, 15 (stack46)
        %v29931_v20 = vxor.u32 %v29930_v22, %v29926_v25 (stack48)
        %119891 = vst [vmem:[%s123356_s30 + $0x9c] sm:$0xf] /*vst_source=*/%v27564_v50 (stack83)
        %vm27935_vm4 = vcmp.eq.f32.partialorder %v130653_v24, inf (stack70)
        %v28688_v44 = vxor.u32 %v28687_v41, %v28683_v52 (stack48)
        %v29096_v8 = vor.u32 %v29095_v23, %v29094_v61 (stack47)
        %vm30387_vm5 = vcmp.lt.u32.totalorder %v130630_v12, %v122651_v47 (stack43)
        %v28303_v34 = vshrl.u32 %v28302_v32, 1 (stack51)
        %v29513_v27 = vor.u32 %v29512_v29, %v29511_v21 (stack47)
        %v29934_v25 = vadd.s32 %v29931_v20, %v29926_v25 (stack40)
        %v29936_v10 = vshll.u32 %v29931_v20, 15 (stack45)
        %v28691_v52 = vadd.s32 %v28688_v44, %v28683_v52 (stack40)
        %v28693_v54 = vshll.u32 %v28688_v44, 16 (stack45)
        %v28694_v31 = vshrl.u32 %v28688_v44, 16 (stack46)
        %v29097_v56 = vxor.u32 %v29096_v8, %v29092_v7 (stack48)
        %v28304_v22 = vor.u32 16256, %v28303_v34 (stack47)
        %v29514_v42 = vxor.u32 %v29513_v27, %v29509_v53 (stack48)
        %v29937_v11 = vshrl.u32 %v29931_v20, 17 (stack46)
        %v157248_v50 = vld [vmem:[#allocation88_spill] sm:$0xff] (stack84)
        %v130699_v41 = vadd.s32 %v157248_v50, %v157068_v28 (stack40)
        %v28695_v61 = vor.u32 %v28694_v31, %v28693_v54 (stack47)
        %v29100_v7 = vadd.s32 %v29097_v56, %v29092_v7 (stack40)
        %v29102_v23 = vshll.u32 %v29097_v56, 15 (stack45)
        %v29103_v32 = vshrl.u32 %v29097_v56, 17 (stack46)
        %v28305_v21 = vand.u32.u16 65535, %v28304_v22 (stack52)
        %v29517_v53 = vadd.s32 %v29514_v42, %v29509_v53 (stack40)
        %v29519_v29 = vshll.u32 %v29514_v42, 29 (stack45)
        %v29520_v20 = vshrl.u32 %v29514_v42, 3 (stack46)
        %v120668_v44 = vpop.eup %120667 (stack73)
        %vm27937_vm6 = vcmp.eq.f32.partialorder %v130653_v24, 0.0 (stack71)
        %v28696_v8 = vxor.u32 %v28695_v61, %v28691_v52 (stack48)
        %v29104_v34 = vor.u32 %v29103_v32, %v29102_v23 (stack47)
        %v29938_v27 = vor.u32 %v29937_v11, %v29936_v10 (stack47)
        %v27934_v10 = vmul.f32 %v120668_v44, %v130653_v24 (stack74)
        %v27938_v54 = vand.u32 2147483648, %v130653_v24 (stack72)
        %v119894_v31 = vadd.low.f32.bf16 -1.0, %v28305_v21 (stack53)
        %v29521_v56 = vor.u32 %v29520_v20, %v29519_v29 (stack47)
        %v28699_v52 = vadd.s32 %v28696_v8, %v28691_v52 (stack40)
        %v28705_v22 = vshll.u32 %v28696_v8, 24 (stack45)
        %v28706_v42 = vshrl.u32 %v28696_v8, 8 (stack46)
        %v29105_v11 = vxor.u32 %v29104_v34, %v29100_v7 (stack48)
        %v27936_v61 = vsel /*vm=*/%vm27935_vm4, /*on_true_vy=*/%v130653_v24, /*on_false_vx=*/%v27934_v10 (stack75)
        %v28314_v23 = vmul.f32 2.0, %v119894_v31 (stack54)
        %v29522_v32 = vxor.u32 %v29521_v56, %v29517_v53 (stack48)
        %v29939_v21 = vxor.u32 %v29938_v27, %v29934_v25 (stack48)
        %v27927_v29 = vsel /*vm=*/%vm27890_vm2, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v27939_v20 = vsel /*vm=*/%vm27937_vm6, /*on_true_vy=*/%v27938_v54, /*on_false_vx=*/%v27936_v61 (stack76)
        %v28707_v44 = vor.u32 %v28706_v42, %v28705_v22 (stack47)
        %v29108_v7 = vadd.s32 %v29105_v11, %v29100_v7 (stack40)
        %v27942_v8 = vadd.f32 -3.0, %v27939_v20 (stack53)
        %v28318_v34 = vadd.f32 -0.99609375, %v28314_v23 (stack53)
        %v29110_v27 = vshll.u32 %v29105_v11, 26 (stack45)
        %v29111_v10 = vshrl.u32 %v29105_v11, 6 (stack46)
        %v28708_v54 = vxor.u32 %v28707_v44, %v28699_v52 (stack48)
        %v29525_v53 = vadd.s32 %v29522_v32, %v29517_v53 (stack40)
        %v29527_v31 = vshll.u32 %v29522_v32, 16 (stack45)
        %v29528_v56 = vshrl.u32 %v29522_v32, 16 (stack46)
        %v130715_v46 = vsel /*vm=*/%vm27890_vm2, /*on_true_vy=*/%v130690_v46, /*on_false_vx=*/%v27942_v8 (stack44)
        %v130717_v22 = vmax.f32 %v28318_v34, -0.99609375 (stack55)
        %v29112_v42 = vor.u32 %v29111_v10, %v29110_v27 (stack47)
        %v29942_v25 = vadd.s32 %v29939_v21, %v29934_v25 (stack40)
        %v27919_v11 = vsel /*vm=*/%vm27890_vm2, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v27950_v61 = vmul.f32 %v130715_v46, %v27927_v29 (stack54)
        %v28711_v23 = vadd.s32 %v28708_v54, %v121564_v0 (stack40)
        %v29529_v32 = vor.u32 %v29528_v56, %v29527_v31 (stack47)
        %v27923_v29 = vsel /*vm=*/%vm27890_vm2, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v28334_v20 = vxor.u32 2147483648, %v130717_v22 (stack56)
        %v29113_v44 = vxor.u32 %v29112_v42, %v29108_v7 (stack48)
        %v30396_v8 = vadd.s32 1, %v130699_v41 (stack40)
        %v27954_v34 = vadd.f32 %v27950_v61, %v27923_v29 (stack53)
        %v28703_v52 = vadd.s32 %v28699_v52, %v121569_v1 (stack40)
        %v28715_v27 = vadd.s32 4, %v28711_v23 (stack40)
        %v29530_v10 = vxor.u32 %v29529_v32, %v29525_v53 (stack48)
        %v28337_v54 = vmul.f32 %v28334_v20, %v130717_v22 (stack54)
        %v29116_v7 = vadd.s32 %v29113_v44, %v29108_v7 (stack40)
        %v29122_v31 = vshll.u32 %v29113_v44, 6 (stack45)
        %vm30382_vm7 = vcmp.lt.u32.totalorder %v130677_v30, %v130630_v12 (stack43)
        %v130735_v56 = vadd.s32 %v130677_v30, %v121569_v1 (stack40)
        %v27958_v42 = vmul.f32 %v27954_v34, %v130715_v46 (stack54)
        %v28719_v61 = vadd.s32 %v28715_v27, %v28703_v52 (stack40)
        %v28721_v23 = vshll.u32 %v28715_v27, 13 (stack45)
        %v28722_v32 = vshrl.u32 %v28715_v27, 19 (stack46)
        %v28339_v29 = vadd.f32 1.0, %v28337_v54 (stack57)
        %v28342_v20 = vmul.f32 -0.5, %v28337_v54 (stack59)
        %v29944_v34 = vshll.u32 %v29939_v21, 26 (stack45)
        %v29945_v21 = vshrl.u32 %v29939_v21, 6 (stack46)
        %v27962_v11 = vadd.f32 %v27958_v42, %v27919_v11 (stack53)
        %v28723_v52 = vor.u32 %v28722_v32, %v28721_v23 (stack47)
        %v29123_v44 = vshrl.u32 %v29113_v44, 26 (stack46)
        %v29533_v53 = vadd.s32 %v29530_v10, %v29525_v53 (stack40)
        %120669 = vlog2.f32 %v28339_v29 (stack58)
        %v28345_v27 = vand.u32 2147483647, %v28337_v54 (stack60)
        %v29120_v42 = vadd.s32 %v29116_v7, %v121574_v2 (stack40)
        %v29539_v23 = vshll.u32 %v29530_v10, 24 (stack45)
        %v27966_v32 = vmul.f32 %v27962_v11, %v130715_v46 (stack54)
        %v28343_v29 = vadd.f32 1.0, %v28342_v20 (stack61)
        %v28724_v20 = vxor.u32 %v28723_v52, %v28719_v61 (stack48)
        %v29124_v31 = vor.u32 %v29123_v44, %v29122_v31 (stack47)
        %v29537_v11 = vadd.s32 %v29533_v53, %v121564_v0 (stack40)
        %v29540_v10 = vshrl.u32 %v29530_v10, 8 (stack46)
        %v29946_v34 = vor.u32 %v29945_v21, %v29944_v34 (stack47)
        %v30400_v41 = vsel /*vm=*/%vm30387_vm5, /*on_true_vy=*/%v30396_v8, /*on_false_vx=*/%v130699_v41 (stack44)
        %v27970_v55 = vadd.f32 %v27966_v32, %v130687_v55 (stack53)
        %v28727_v8 = vadd.s32 %v28724_v20, %v28719_v61 (stack40)
        %v28729_v61 = vshll.u32 %v28724_v20, 15 (stack45)
        %v28730_v21 = vshrl.u32 %v28724_v20, 17 (stack46)
        %v29125_v7 = vxor.u32 %v29124_v31, %v29116_v7 (stack48)
        %v29541_v52 = vor.u32 %v29540_v10, %v29539_v23 (stack47)
        %v29947_v44 = vxor.u32 %v29946_v34, %v29942_v25 (stack48)
        %v30404_v23 = vadd.s32 1, %v30400_v41 (stack40)
        %v27974_v32 = vmul.f32 %v27970_v55, %v130715_v46 (stack54)
        %v28344_v54 = vmul.f32 %v28343_v29, %v28337_v54 (stack63)
        %v28731_v29 = vor.u32 %v28730_v21, %v28729_v61 (stack47)
        %v30423_v20 = vshll.u32 %v130735_v56, 13 (stack45)
        %v29128_v31 = vadd.s32 %v29125_v7, %v121569_v1 (stack40)
        %v29542_v53 = vxor.u32 %v29541_v52, %v29533_v53 (stack48)
        %v130749_v25 = vadd.s32 %v29947_v44, %v29942_v25 (stack40)
        %v29956_v10 = vshll.u32 %v29947_v44, 6 (stack45)
        %v27978_v6 = vadd.f32 %v27974_v32, %v130682_v6 (stack53)
        %vm130752_vm8 = vcmp.lt.f32.partialorder %v28345_v27, 0.0004427343 (stack62)
        %v28732_v34 = vxor.u32 %v28731_v29, %v28727_v8 (stack48)
        %v29957_v55 = vshrl.u32 %v29947_v44, 26 (stack46)
        %v30408_v12 = vsel /*vm=*/%vm30382_vm7, /*on_true_vy=*/%v30404_v23, /*on_false_vx=*/%v30400_v41 (stack44)
        %v29132_v30 = vadd.s32 3, %v29128_v31 (stack40)
        %v29545_v41 = vadd.s32 %v29542_v53, %v121574_v2 (stack40)
        %v30413_v61 = vadd.s32 %v30408_v12, %v121574_v2 (stack40)
        %v30424_v21 = vshrl.u32 %v130735_v56, 19 (stack46)
        %v27982_v7 = vmul.f32 %v27978_v6, %v130715_v46 (stack54)
        %v28735_v8 = vadd.s32 %v28732_v34, %v28727_v8 (stack40)
        %v28737_v52 = vshll.u32 %v28732_v34, 26 (stack45)
        %v28738_v44 = vshrl.u32 %v28732_v34, 6 (stack46)
        %v29136_v42 = vadd.s32 %v29132_v30, %v29120_v42 (stack40)
        %v29138_v23 = vshll.u32 %v29132_v30, 17 (stack45)
        %v29139_v32 = vshrl.u32 %v29132_v30, 15 (stack46)
        %v29549_v29 = vadd.s32 2, %v29545_v41 (stack40)
        %v27986_v40 = vadd.f32 %v27982_v7, %v130673_v40 (stack53)
        %v28739_v31 = vor.u32 %v28738_v44, %v28737_v52 (stack47)
        %v29958_v53 = vor.u32 %v29957_v55, %v29956_v10 (stack47)
        %v30421_v56 = vadd.s32 %v130735_v56, %v30413_v61 (stack40)
        %v29140_v10 = vor.u32 %v29139_v32, %v29138_v23 (stack47)
        %v29553_v11 = vadd.s32 %v29549_v29, %v29537_v11 (stack40)
        %v29555_v6 = vshll.u32 %v29549_v29, 13 (stack45)
        %v29556_v34 = vshrl.u32 %v29549_v29, 19 (stack46)
        %v120670_v55 = vpop.eup %120669 (stack64)
        %v27990_v12 = vmul.f32 %v27986_v40, %v130715_v46 (stack54)
        %v28740_v30 = vxor.u32 %v28739_v31, %v28735_v8 (stack48)
        %v29959_v41 = vxor.u32 %v29958_v53, %v130749_v25 (stack48)
        %v30425_v20 = vor.u32 %v30424_v21, %v30423_v20 (stack47)
        %v28341_v61 = vmul.f32 0.6931472, %v120670_v55 (stack65)
        %v29141_v21 = vxor.u32 %v29140_v10, %v29136_v42 (stack48)
        %v29557_v7 = vor.u32 %v29556_v34, %v29555_v6 (stack47)
        %v130769_v52 = vadd.s32 %v157247_v60, %v157070_v38 (stack40)
        %v27994_v9 = vadd.f32 %v27990_v12, %v130668_v9 (stack53)
        %v28743_v8 = vadd.s32 %v28740_v30, %v28735_v8 (stack40)
        %v28749_v44 = vshll.u32 %v28740_v30, 6 (stack45)
        %v28750_v23 = vshrl.u32 %v28740_v30, 26 (stack46)
        %v28347_v54 = vsel /*vm=*/%vm130752_vm8, /*on_true_vy=*/%v28344_v54, /*on_false_vx=*/%v28341_v61 (stack66)
        %v29144_v27 = vadd.s32 %v29141_v21, %v29136_v42 (stack40)
        %v29146_v42 = vshll.u32 %v29141_v21, 29 (stack45)
        %v29147_v32 = vshrl.u32 %v29141_v21, 3 (stack46)
        %v27998_v29 = vmul.f32 %v27994_v9, %v130715_v46 (stack54)
        %v130775_v40 = vxor.u32 2147483648, %v28347_v54 (stack56)
        %v28751_v31 = vor.u32 %v28750_v23, %v28749_v44 (stack47)
        %v27899_v53 = vsel /*vm=*/%vm27890_vm2, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v29558_v10 = vxor.u32 %v29557_v7, %v29553_v11 (stack48)
        %v30426_v6 = vxor.u32 %v30425_v20, %v30421_v56 (stack48)
        %v27871_v34 = vmul.f32 inf, %v130584_v26 (stack54)
        %v28002_v55 = vadd.f32 %v27998_v29, %v27899_v53 (stack53)
        %120671 = vrsqrt.f32 %v130775_v40 (stack67)
        %vm130784_vm9 = vcmp.eq.f32.partialorder %v27863_v43, 1.0 (stack68)
        %vm28351_vm10 = vcmp.lt.f32.partialorder %v130775_v40, 5.0 (stack68)
        %v28752_v12 = vxor.u32 %v28751_v31, %v28743_v8 (stack48)
        %v29148_v30 = vor.u32 %v29147_v32, %v29146_v42 (stack47)
        %v27895_v24 = vsel /*vm=*/%vm27890_vm2, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v28006_v46 = vmul.f32 %v28002_v55, %v130715_v46 (stack54)
        %v28324_v20 = vand.u32 2147483647, %v130717_v22 (stack77)
        %v29962_v41 = vadd.s32 %v29959_v41, %v121564_v0 (stack40)
        %v130796_v61 = vadd.f32 -2.5, %v130775_v40 (stack53)
        %v28747_v21 = vadd.s32 %v28743_v8, %v121564_v0 (stack40)
        %v28755_v7 = vadd.s32 %v28752_v12, %v121574_v2 (stack40)
        %v29954_v25 = vadd.s32 %v130749_v25, %v121569_v1 (stack40)
        %v28010_v9 = vadd.f32 %v28006_v46, %v27895_v24 (stack53)
        %v130805_v8 = vsel /*vm=*/%vm28351_vm10, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v130810_v44 = vsel /*vm=*/%vm28351_vm10, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v130815_v23 = vsel /*vm=*/%vm28351_vm10, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v28759_v54 = vadd.s32 5, %v28755_v7 (stack40)
        %v29149_v42 = vxor.u32 %v29148_v30, %v29144_v27 (stack48)
        %v29561_v11 = vadd.s32 %v29558_v10, %v29553_v11 (stack40)
        %v29563_v32 = vshll.u32 %v29558_v10, 15 (stack45)
        %v28014_v26 = vmul.f32 %v28010_v9, %v130584_v26 (stack54)
        %v29564_v29 = vshrl.u32 %v29558_v10, 17 (stack46)
        %v29966_v31 = vadd.s32 1, %v29962_v41 (stack40)
        %v30429_v56 = vadd.s32 %v30426_v6, %v30421_v56 (stack40)
        %v28761_v53 = vxor.u32 %v28759_v54, %v28747_v21 (stack48)
        %v29152_v27 = vadd.s32 %v29149_v42, %v29144_v27 (stack40)
        %v29154_v10 = vshll.u32 %v29149_v42, 16 (stack45)
        %v29155_v55 = vshrl.u32 %v29149_v42, 16 (stack46)
        %v28018_v34 = vsel /*vm=*/%vm130784_vm9, /*on_true_vy=*/%v27871_v34, /*on_false_vx=*/%v28014_v26 (stack44)
        %v29565_v43 = vor.u32 %v29564_v29, %v29563_v32 (stack47)
        %v29970_v12 = vadd.s32 %v29966_v31, %v29954_v25 (stack40)
        %v29972_v30 = vshll.u32 %v29966_v31, 17 (stack45)
        %v28022_v24 = vmul.f32 1.4140625, %v28018_v34 (stack54)
        %v28762_v46 = vand.u32.u8 255, %v28761_v53 (stack49)
        %v29156_v41 = vor.u32 %v29155_v55, %v29154_v10 (stack47)
        %v29973_v21 = vshrl.u32 %v29966_v31, 15 (stack46)
        %vm28396_vm11 = vcmp.eq.f32.partialorder %v130775_v40, inf (stack70)
        %v29566_v7 = vxor.u32 %v29565_v43, %v29561_v11 (stack48)
        %v30431_v25 = vshll.u32 %v30426_v6, 15 (stack45)
        %v30432_v6 = vshrl.u32 %v30426_v6, 17 (stack46)
        %v28025_v9 = vpack.c.bf16 %v156663_v45, %v28022_v24 (stack81)
        %v28763_v54 = vand.u32 65535, %v28762_v46 (stack50)
        %v29157_v42 = vxor.u32 %v29156_v41, %v29152_v27 (stack48)
        %v29974_v32 = vor.u32 %v29973_v21, %v29972_v30 (stack47)
        %v29569_v11 = vadd.s32 %v29566_v7, %v29561_v11 (stack40)
        %v29571_v26 = vshll.u32 %v29566_v7, 26 (stack45)
        %v29572_v29 = vshrl.u32 %v29566_v7, 6 (stack46)
        %v30433_v31 = vor.u32 %v30432_v6, %v30431_v25 (stack47)
        %v120672_v53 = vpop.eup %120671 (stack73)
        %119893 = vst [vmem:[%s123356_s30 + $0x11c] sm:$0xf] /*vst_source=*/%v28025_v9 (stack83)
        %v28764_v10 = vshrl.u32 %v28763_v54, 1 (stack51)
        %v29160_v27 = vadd.s32 %v29157_v42, %v29152_v27 (stack40)
        %v29166_v55 = vshll.u32 %v29157_v42, 24 (stack45)
        %v29167_v34 = vshrl.u32 %v29157_v42, 8 (stack46)
        %v28395_v43 = vmul.f32 %v120672_v53, %v130775_v40 (stack74)
        %v29573_v30 = vor.u32 %v29572_v29, %v29571_v26 (stack47)
        %v29975_v24 = vxor.u32 %v29974_v32, %v29970_v12 (stack48)
        %v30434_v46 = vxor.u32 %v30433_v31, %v30429_v56 (stack48)
        %vm28398_vm12 = vcmp.eq.f32.partialorder %v130775_v40, 0.0 (stack71)
        %v28399_v41 = vand.u32 2147483648, %v130775_v40 (stack72)
        %v28765_v21 = vor.u32 16256, %v28764_v10 (stack47)
        %v29168_v7 = vor.u32 %v29167_v34, %v29166_v55 (stack47)
        %v28397_v25 = vsel /*vm=*/%vm28396_vm11, /*on_true_vy=*/%v130775_v40, /*on_false_vx=*/%v28395_v43 (stack75)
        %v29574_v6 = vxor.u32 %v29573_v30, %v29569_v11 (stack48)
        %v29978_v12 = vadd.s32 %v29975_v24, %v29970_v12 (stack40)
        %v29980_v9 = vshll.u32 %v29975_v24, 29 (stack45)
        %v28400_v54 = vsel /*vm=*/%vm28398_vm12, /*on_true_vy=*/%v28399_v41, /*on_false_vx=*/%v28397_v25 (stack76)
        %v28766_v42 = vand.u32.u16 65535, %v28765_v21 (stack52)
        %v29169_v32 = vxor.u32 %v29168_v7, %v29160_v27 (stack48)
        %v29981_v26 = vshrl.u32 %v29975_v24, 3 (stack46)
        %v28403_v29 = vadd.f32 -3.0, %v28400_v54 (stack53)
        %v29577_v11 = vadd.s32 %v29574_v6, %v29569_v11 (stack40)
        %v29583_v31 = vshll.u32 %v29574_v6, 6 (stack45)
        %v29584_v53 = vshrl.u32 %v29574_v6, 26 (stack46)
        %v119896_v10 = vadd.low.f32.bf16 -1.0, %v28766_v42 (stack53)
        %v29172_v55 = vadd.s32 %v29169_v32, %v121564_v0 (stack40)
        %v29982_v34 = vor.u32 %v29981_v26, %v29980_v9 (stack47)
        %v130830_v56 = vadd.s32 %v30434_v46, %v30429_v56 (stack40)
        %v130835_v61 = vsel /*vm=*/%vm28351_vm10, /*on_true_vy=*/%v130796_v61, /*on_false_vx=*/%v28403_v29 (stack44)
        %v29164_v27 = vadd.s32 %v29160_v27, %v121569_v1 (stack40)
        %v29585_v43 = vor.u32 %v29584_v53, %v29583_v31 (stack47)
        %v30439_v30 = vshll.u32 %v30434_v46, 26 (stack45)
        %v28411_v23 = vmul.f32 %v130835_v61, %v130815_v23 (stack54)
        %v28775_v24 = vmul.f32 2.0, %v119896_v10 (stack54)
        %v29176_v41 = vadd.s32 4, %v29172_v55 (stack40)
        %v29983_v21 = vxor.u32 %v29982_v34, %v29978_v12 (stack48)
        %v29586_v7 = vxor.u32 %v29585_v43, %v29577_v11 (stack48)
        %v30440_v46 = vshrl.u32 %v30434_v46, 6 (stack46)
        %vm30848_vm13 = vcmp.lt.u32.totalorder %v130769_v52, %v157070_v38 (stack43)
        %v130844_v25 = vadd.s32 %v157248_v50, %v157076_v35 (stack40)
        %v28415_v44 = vadd.f32 %v28411_v23, %v130810_v44 (stack53)
        %v28779_v6 = vadd.f32 -0.99609375, %v28775_v24 (stack53)
        %v29180_v9 = vadd.s32 %v29176_v41, %v29164_v27 (stack40)
        %v29182_v54 = vshll.u32 %v29176_v41, 13 (stack45)
        %v130850_v42 = vsel /*vm=*/%vm28351_vm10, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v29183_v32 = vshrl.u32 %v29176_v41, 19 (stack46)
        %v29589_v26 = vadd.s32 %v29586_v7, %v121569_v1 (stack40)
        %v29986_v12 = vadd.s32 %v29983_v21, %v29978_v12 (stack40)
        %v28419_v29 = vmul.f32 %v28415_v44, %v130835_v61 (stack54)
        %v130854_v31 = vmax.f32 %v28779_v6, -0.99609375 (stack55)
        %v29988_v53 = vshll.u32 %v29983_v21, 16 (stack45)
        %v29989_v10 = vshrl.u32 %v29983_v21, 16 (stack46)
        %v28380_v55 = vsel /*vm=*/%vm28351_vm10, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v29184_v34 = vor.u32 %v29183_v32, %v29182_v54 (stack47)
        %v29581_v11 = vadd.s32 %v29577_v11, %v121574_v2 (stack40)
        %v29593_v27 = vadd.s32 3, %v29589_v26 (stack40)
        %v28423_v43 = vadd.f32 %v28419_v29, %v28380_v55 (stack53)
        %v28795_v23 = vxor.u32 2147483648, %v130854_v31 (stack56)
        %v30441_v30 = vor.u32 %v30440_v46, %v30439_v30 (stack47)
        %v130863_v24 = vadd.s32 %v130769_v52, %v122657_v58 (stack40)
        %v29185_v41 = vxor.u32 %v29184_v34, %v29180_v9 (stack48)
        %v29597_v21 = vadd.s32 %v29593_v27, %v29581_v11 (stack40)
        %v29599_v7 = vshll.u32 %v29593_v27, 17 (stack45)
        %v29600_v46 = vshrl.u32 %v29593_v27, 15 (stack46)
        %v28376_v44 = vsel /*vm=*/%vm28351_vm10, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v28427_v6 = vmul.f32 %v28423_v43, %v130835_v61 (stack54)
        %v28798_v54 = vmul.f32 %v28795_v23, %v130854_v31 (stack54)
        %v29990_v32 = vor.u32 %v29989_v10, %v29988_v53 (stack47)
        %v29188_v9 = vadd.s32 %v29185_v41, %v29180_v9 (stack40)
        %v29190_v26 = vshll.u32 %v29185_v41, 15 (stack45)
        %v29191_v29 = vshrl.u32 %v29185_v41, 17 (stack46)
        %v29601_v53 = vor.u32 %v29600_v46, %v29599_v7 (stack47)
        %v28368_v10 = vsel /*vm=*/%vm28351_vm10, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v28372_v55 = vsel /*vm=*/%vm28351_vm10, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v28431_v34 = vadd.f32 %v28427_v6, %v28376_v44 (stack53)
        %v28800_v11 = vadd.f32 1.0, %v28798_v54 (stack57)
        %v29192_v27 = vor.u32 %v29191_v29, %v29190_v26 (stack47)
        %v29602_v43 = vxor.u32 %v29601_v53, %v29597_v21 (stack48)
        %v29991_v23 = vxor.u32 %v29990_v32, %v29986_v12 (stack48)
        %v30442_v30 = vxor.u32 %v30441_v30, %v130830_v56 (stack48)
        %vm30843_vm14 = vcmp.lt.u32.totalorder %v130863_v24, %v130769_v52 (stack43)
        %v28435_v41 = vmul.f32 %v28431_v34, %v130835_v61 (stack54)
        %120673 = vlog2.f32 %v28800_v11 (stack58)
        %v28803_v7 = vmul.f32 -0.5, %v28798_v54 (stack59)
        %v30857_v46 = vadd.s32 1, %v130844_v25 (stack40)
        %v29193_v44 = vxor.u32 %v29192_v27, %v29188_v9 (stack48)
        %v29605_v21 = vadd.s32 %v29602_v43, %v29597_v21 (stack40)
        %v29607_v6 = vshll.u32 %v29602_v43, 29 (stack45)
        %v29608_v32 = vshrl.u32 %v29602_v43, 3 (stack46)
        %v28439_v26 = vadd.f32 %v28435_v41, %v28372_v55 (stack53)
        %v28806_v29 = vand.u32 2147483647, %v28798_v54 (stack60)
        %v29994_v12 = vadd.s32 %v29991_v23, %v29986_v12 (stack40)
        %v30000_v53 = vshll.u32 %v29991_v23, 24 (stack45)
        %v29196_v9 = vadd.s32 %v29193_v44, %v29188_v9 (stack40)
        %v29198_v55 = vshll.u32 %v29193_v44, 26 (stack45)
        %v29199_v34 = vshrl.u32 %v29193_v44, 6 (stack46)
        %v29609_v11 = vor.u32 %v29608_v32, %v29607_v6 (stack47)
        %v28443_v27 = vmul.f32 %v28439_v26, %v130835_v61 (stack54)
        %v30001_v43 = vshrl.u32 %v29991_v23, 8 (stack46)
        %v30445_v56 = vadd.s32 %v30442_v30, %v130830_v56 (stack40)
        %v130885_v23 = vadd.s32 %v130863_v24, %v121569_v1 (stack40)
        %v29200_v41 = vor.u32 %v29199_v34, %v29198_v55 (stack47)
        %v29610_v44 = vxor.u32 %v29609_v11, %v29605_v21 (stack48)
        %v30451_v6 = vshll.u32 %v30442_v30, 6 (stack45)
        %v30452_v30 = vshrl.u32 %v30442_v30, 26 (stack46)
        %v28447_v10 = vadd.f32 %v28443_v27, %v28368_v10 (stack53)
        %v28804_v7 = vadd.f32 1.0, %v28803_v7 (stack61)
        %v30002_v32 = vor.u32 %v30001_v43, %v30000_v53 (stack47)
        %v30861_v25 = vsel /*vm=*/%vm30848_vm13, /*on_true_vy=*/%v30857_v46, /*on_false_vx=*/%v130844_v25 (stack44)
        %vm130891_vm15 = vcmp.lt.f32.partialorder %v28806_v29, 0.0004427343 (stack62)
        %v29201_v26 = vxor.u32 %v29200_v41, %v29196_v9 (stack48)
        %v29613_v21 = vadd.s32 %v29610_v44, %v29605_v21 (stack40)
        %v29615_v29 = vshll.u32 %v29610_v44, 16 (stack45)
        %v29616_v53 = vshrl.u32 %v29610_v44, 16 (stack46)
        %v28451_v55 = vmul.f32 %v28447_v10, %v130835_v61 (stack54)
        %v30003_v34 = vxor.u32 %v30002_v32, %v29994_v12 (stack48)
        %v30453_v11 = vor.u32 %v30452_v30, %v30451_v6 (stack47)
        %v30865_v27 = vadd.s32 1, %v30861_v25 (stack40)
        %v29204_v9 = vadd.s32 %v29201_v26, %v29196_v9 (stack40)
        %v29210_v43 = vshll.u32 %v29201_v26, 6 (stack45)
        %v29211_v41 = vshrl.u32 %v29201_v26, 26 (stack46)
        %v29617_v44 = vor.u32 %v29616_v53, %v29615_v29 (stack47)
        %v28455_v42 = vadd.f32 %v28451_v55, %v130850_v42 (stack53)
        %v30006_v6 = vadd.s32 %v30003_v34, %v121574_v2 (stack40)
        %v30454_v30 = vxor.u32 %v30453_v11, %v30445_v56 (stack48)
        %v30869_v52 = vsel /*vm=*/%vm30843_vm14, /*on_true_vy=*/%v30865_v27, /*on_false_vx=*/%v30861_v25 (stack44)
        %v28805_v24 = vmul.f32 %v28804_v7, %v28798_v54 (stack63)
        %v29212_v54 = vor.u32 %v29211_v41, %v29210_v43 (stack47)
        %v29618_v10 = vxor.u32 %v29617_v44, %v29613_v21 (stack48)
        %v29998_v12 = vadd.s32 %v29994_v12, %v121564_v0 (stack40)
        %v28459_v7 = vmul.f32 %v28455_v42, %v130835_v61 (stack54)
        %v30010_v32 = vadd.s32 2, %v30006_v6 (stack40)
        %v30457_v25 = vadd.s32 %v30454_v30, %v121564_v0 (stack40)
        %v30874_v26 = vadd.s32 %v30869_v52, %v121574_v2 (stack40)
        %v120674_v29 = vpop.eup %120673 (stack64)
        %v29213_v53 = vxor.u32 %v29212_v54, %v29204_v9 (stack48)
        %v29621_v21 = vadd.s32 %v29618_v10, %v29613_v21 (stack40)
        %v29627_v55 = vshll.u32 %v29618_v10, 24 (stack45)
        %v29628_v34 = vshrl.u32 %v29618_v10, 8 (stack46)
        %v28463_v8 = vadd.f32 %v28459_v7, %v130805_v8 (stack53)
        %v28802_v11 = vmul.f32 0.6931472, %v120674_v29 (stack65)
        %v30014_v27 = vadd.s32 %v30010_v32, %v29998_v12 (stack40)
        %v30449_v56 = vadd.s32 %v30445_v56, %v121569_v1 (stack40)
        %v29216_v43 = vadd.s32 %v29213_v53, %v121574_v2 (stack40)
        %v29629_v41 = vor.u32 %v29628_v34, %v29627_v55 (stack47)
        %v30016_v44 = vshll.u32 %v30010_v32, 13 (stack45)
        %v30017_v42 = vshrl.u32 %v30010_v32, 19 (stack46)
        %v28467_v61 = vmul.f32 %v28463_v8, %v130835_v61 (stack54)
        %v28808_v46 = vsel /*vm=*/%vm130891_vm15, /*on_true_vy=*/%v28805_v24, /*on_false_vx=*/%v28802_v11 (stack66)
        %v30461_v6 = vadd.s32 1, %v30457_v25 (stack40)
        %v130912_v30 = vadd.s32 %v130885_v23, %v30874_v26 (stack40)
        %v28356_v40 = vsel /*vm=*/%vm28351_vm10, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v130917_v52 = vxor.u32 2147483648, %v28808_v46 (stack56)
        %v29220_v24 = vadd.s32 5, %v29216_v43 (stack40)
        %v29630_v54 = vxor.u32 %v29629_v41, %v29621_v21 (stack48)
        %v28471_v10 = vadd.f32 %v28467_v61, %v28356_v40 (stack53)
        %v30465_v12 = vadd.s32 %v30461_v6, %v30449_v56 (stack40)
        %v28332_v7 = vmul.f32 inf, %v130717_v22 (stack54)
        %120675 = vrsqrt.f32 %v130917_v52 (stack67)
        %v29208_v9 = vadd.s32 %v29204_v9, %v121564_v0 (stack40)
        %v30018_v32 = vor.u32 %v30017_v42, %v30016_v44 (stack47)
        %v28475_v25 = vmul.f32 %v28471_v10, %v130717_v22 (stack54)
        %vm28812_vm0 = vcmp.lt.f32.partialorder %v130917_v52, 5.0 (stack68)
        %v30467_v26 = vshll.u32 %v30461_v6, 17 (stack45)
        %v30468_v29 = vshrl.u32 %v30461_v6, 15 (stack46)
        %vm28327_vm1 = vcmp.eq.f32.partialorder %v28324_v20, 1.0 (stack68)
        %v29222_v22 = vxor.u32 %v29220_v24, %v29208_v9 (stack48)
        %v28479_v20 = vsel /*vm=*/%vm28327_vm1, /*on_true_vy=*/%v28332_v7, /*on_false_vx=*/%v28475_v25 (stack44)
        %v130927_v53 = vadd.f32 -2.5, %v130917_v52 (stack53)
        %v29625_v21 = vadd.s32 %v29621_v21, %v121569_v1 (stack40)
        %v30884_v55 = vshll.u32 %v130885_v23, 13 (stack45)
        %v28483_v34 = vmul.f32 1.4140625, %v28479_v20 (stack54)
        %v130934_v8 = vsel /*vm=*/%vm28812_vm0, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v130939_v11 = vsel /*vm=*/%vm28812_vm0, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v29223_v56 = vand.u32.u8 255, %v29222_v22 (stack49)
        %v29633_v43 = vadd.s32 %v29630_v54, %v121564_v0 (stack40)
        %v30019_v41 = vxor.u32 %v30018_v32, %v30014_v27 (stack48)
        %v30469_v44 = vor.u32 %v30468_v29, %v30467_v26 (stack47)
        %v30885_v23 = vshrl.u32 %v130885_v23, 19 (stack46)
        %v28486_v42 = vpack.c.bf16 %v156663_v45, %v28483_v34 (stack81)
        %v29224_v61 = vand.u32 65535, %v29223_v56 (stack50)
        %v130946_v46 = vadd.s32 %v157247_v60, %v157077_v51 (stack40)
        %v130950_v6 = vadd.s32 %v157248_v50, %v157078_v48 (stack40)
        %vm28857_vm2 = vcmp.eq.f32.partialorder %v130917_v52, inf (stack70)
        %v29637_v40 = vadd.s32 4, %v29633_v43 (stack40)
        %v30022_v27 = vadd.s32 %v30019_v41, %v30014_v27 (stack40)
        %v30024_v24 = vshll.u32 %v30019_v41, 15 (stack45)
        %v30025_v54 = vshrl.u32 %v30019_v41, 17 (stack46)
        %119895 = vst [vmem:[%s123356_s30 + $0x19c] sm:$0xf] /*vst_source=*/%v28486_v42 (stack83)
        %v28849_v10 = vsel /*vm=*/%vm28812_vm0, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v29225_v7 = vshrl.u32 %v29224_v61, 1 (stack51)
        %v30470_v9 = vxor.u32 %v30469_v44, %v30465_v12 (stack48)
        %v30886_v32 = vor.u32 %v30885_v23, %v30884_v55 (stack47)
        %v29641_v25 = vadd.s32 %v29637_v40, %v29625_v21 (stack40)
        %v29643_v26 = vshll.u32 %v29637_v40, 13 (stack45)
        %v29644_v29 = vshrl.u32 %v29637_v40, 19 (stack46)
        %v30026_v22 = vor.u32 %v30025_v54, %v30024_v24 (stack47)
        %v29226_v20 = vor.u32 16256, %v29225_v7 (stack47)
        %v30473_v12 = vadd.s32 %v30470_v9, %v30465_v12 (stack40)
        %v30475_v21 = vshll.u32 %v30470_v9, 29 (stack45)
        %v30476_v55 = vshrl.u32 %v30470_v9, 3 (stack46)
        %vm28859_vm3 = vcmp.eq.f32.partialorder %v130917_v52, 0.0 (stack71)
        %v29645_v34 = vor.u32 %v29644_v29, %v29643_v26 (stack47)
        %v30027_v56 = vxor.u32 %v30026_v22, %v30022_v27 (stack48)
        %v30887_v43 = vxor.u32 %v30886_v32, %v130912_v30 (stack48)
        %v28860_v41 = vand.u32 2147483648, %v130917_v52 (stack72)
        %v29227_v44 = vand.u32.u16 65535, %v29226_v20 (stack52)
        %v30477_v23 = vor.u32 %v30476_v55, %v30475_v21 (stack47)
        %vm31309_vm4 = vcmp.lt.u32.totalorder %v130946_v46, %v157077_v51 (stack43)
        %v120676_v42 = vpop.eup %120675 (stack73)
        %v29646_v61 = vxor.u32 %v29645_v34, %v29641_v25 (stack48)
        %v30030_v40 = vadd.s32 %v30027_v56, %v30022_v27 (stack40)
        %v30032_v27 = vshll.u32 %v30027_v56, 26 (stack45)
        %v30033_v24 = vshrl.u32 %v30027_v56, 6 (stack46)
        %v28856_v54 = vmul.f32 %v120676_v42, %v130917_v52 (stack74)
        %v119898_v7 = vadd.low.f32.bf16 -1.0, %v29227_v44 (stack53)
        %v30478_v9 = vxor.u32 %v30477_v23, %v30473_v12 (stack48)
        %v130964_v30 = vadd.s32 %v30887_v43, %v130912_v30 (stack40)
        %v29649_v32 = vadd.s32 %v29646_v61, %v29641_v25 (stack40)
        %v29651_v25 = vshll.u32 %v29646_v61, 15 (stack45)
        %v29652_v26 = vshrl.u32 %v29646_v61, 17 (stack46)
        %v30034_v29 = vor.u32 %v30033_v24, %v30032_v27 (stack47)
        %v28858_v22 = vsel /*vm=*/%vm28857_vm2, /*on_true_vy=*/%v130917_v52, /*on_false_vx=*/%v28856_v54 (stack75)
        %v29236_v20 = vmul.f32 2.0, %v119898_v7 (stack54)
        %v30481_v12 = vadd.s32 %v30478_v9, %v30473_v12 (stack40)
        %v30483_v21 = vshll.u32 %v30478_v9, 16 (stack45)
        %v28861_v55 = vsel /*vm=*/%vm28859_vm3, /*on_true_vy=*/%v28860_v41, /*on_false_vx=*/%v28858_v22 (stack76)
        %v29653_v34 = vor.u32 %v29652_v26, %v29651_v25 (stack47)
        %v30035_v56 = vxor.u32 %v30034_v29, %v30030_v40 (stack48)
        %v30484_v41 = vshrl.u32 %v30478_v9, 16 (stack46)
        %v28864_v44 = vadd.f32 -3.0, %v28861_v55 (stack53)
        %v29240_v23 = vadd.f32 -0.99609375, %v29236_v20 (stack53)
        %v30892_v42 = vshll.u32 %v30887_v43, 15 (stack45)
        %v30893_v43 = vshrl.u32 %v30887_v43, 17 (stack46)
        %v29654_v61 = vxor.u32 %v29653_v34, %v29649_v32 (stack48)
        %v30038_v40 = vadd.s32 %v30035_v56, %v30030_v40 (stack40)
        %v30044_v27 = vshll.u32 %v30035_v56, 6 (stack45)
        %v30045_v24 = vshrl.u32 %v30035_v56, 26 (stack46)
        %v130974_v53 = vsel /*vm=*/%vm28812_vm0, /*on_true_vy=*/%v130927_v53, /*on_false_vx=*/%v28864_v44 (stack44)
        %v130976_v54 = vmax.f32 %v29240_v23, -0.99609375 (stack55)
        %v30485_v7 = vor.u32 %v30484_v41, %v30483_v21 (stack47)
        %v30894_v9 = vor.u32 %v30893_v43, %v30892_v42 (stack47)
        %v28872_v10 = vmul.f32 %v130974_v53, %v28849_v10 (stack54)
        %v29657_v32 = vadd.s32 %v29654_v61, %v29649_v32 (stack40)
        %v29659_v25 = vshll.u32 %v29654_v61, 26 (stack45)
        %v29660_v26 = vshrl.u32 %v29654_v61, 6 (stack46)
        %v28833_v29 = vsel /*vm=*/%vm28812_vm0, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v28845_v22 = vsel /*vm=*/%vm28812_vm0, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v29256_v20 = vxor.u32 2147483648, %v130976_v54 (stack56)
        %v31318_v21 = vadd.s32 1, %v130950_v6 (stack40)
        %v28876_v55 = vadd.f32 %v28872_v10, %v28845_v22 (stack53)
        %v29661_v34 = vor.u32 %v29660_v26, %v29659_v25 (stack47)
        %v30046_v56 = vor.u32 %v30045_v24, %v30044_v27 (stack47)
        %v30486_v41 = vxor.u32 %v30485_v7, %v30481_v12 (stack48)
        %v130988_v44 = vmul.f32 %v29256_v20, %v130976_v54 (stack54)
        %v30895_v23 = vxor.u32 %v30894_v9, %v130964_v30 (stack48)
        %v31300_v42 = vadd.s32 %v130946_v46, %v122657_v58 (stack40)
        %v31322_v6 = vsel /*vm=*/%vm31309_vm4, /*on_true_vy=*/%v31318_v21, /*on_false_vx=*/%v130950_v6 (stack44)
        %v28880_v43 = vmul.f32 %v28876_v55, %v130974_v53 (stack54)
        %v29662_v61 = vxor.u32 %v29661_v34, %v29657_v32 (stack48)
        %v30047_v27 = vxor.u32 %v30046_v56, %v30038_v40 (stack48)
        %v30489_v12 = vadd.s32 %v30486_v41, %v30481_v12 (stack40)
        %v28837_v24 = vsel /*vm=*/%vm28812_vm0, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v28841_v7 = vsel /*vm=*/%vm28812_vm0, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v29261_v9 = vadd.f32 1.0, %v130988_v44 (stack57)
        %v29264_v10 = vmul.f32 -0.5, %v130988_v44 (stack59)
        %v28884_v25 = vadd.f32 %v28880_v43, %v28841_v7 (stack53)
        %v29665_v32 = vadd.s32 %v29662_v61, %v29657_v32 (stack40)
        %v29671_v26 = vshll.u32 %v29662_v61, 6 (stack45)
        %v29672_v22 = vshrl.u32 %v29662_v61, 26 (stack46)
        %120677 = vlog2.f32 %v29261_v9 (stack58)
        %v30050_v20 = vadd.s32 %v30047_v27, %v121569_v1 (stack40)
        %v30495_v21 = vshll.u32 %v30486_v41, 24 (stack45)
        %vm31304_vm5 = vcmp.lt.u32.totalorder %v31300_v42, %v130946_v46 (stack43)
        %v28888_v55 = vmul.f32 %v28884_v25, %v130974_v53 (stack54)
        %v29267_v34 = vand.u32 2147483647, %v130988_v44 (stack60)
        %v29673_v56 = vor.u32 %v29672_v22, %v29671_v26 (stack47)
        %v30042_v40 = vadd.s32 %v30038_v40, %v121574_v2 (stack40)
        %v29265_v43 = vadd.f32 1.0, %v29264_v10 (stack61)
        %v30054_v61 = vadd.s32 3, %v30050_v20 (stack40)
        %v30496_v41 = vshrl.u32 %v30486_v41, 8 (stack46)
        %v30898_v30 = vadd.s32 %v30895_v23, %v130964_v30 (stack40)
        %v28892_v27 = vadd.f32 %v28888_v55, %v28837_v24 (stack53)
        %v29674_v24 = vxor.u32 %v29673_v56, %v29665_v32 (stack48)
        %v30900_v7 = vshll.u32 %v30895_v23, 26 (stack45)
        %v30901_v23 = vshrl.u32 %v30895_v23, 6 (stack46)
        %v30058_v9 = vadd.s32 %v30054_v61, %v30042_v40 (stack40)
        %v30060_v10 = vshll.u32 %v30054_v61, 17 (stack45)
        %v30061_v25 = vshrl.u32 %v30054_v61, 15 (stack46)
        %v30497_v26 = vor.u32 %v30496_v41, %v30495_v21 (stack47)
        %v28896_v22 = vmul.f32 %v28892_v27, %v130974_v53 (stack54)
        %v29677_v20 = vadd.s32 %v29674_v24, %v121574_v2 (stack40)
        %v30902_v21 = vor.u32 %v30901_v23, %v30900_v7 (stack47)
        %v31326_v55 = vadd.s32 1, %v31322_v6 (stack40)
        %v29669_v32 = vadd.s32 %v29665_v32, %v121564_v0 (stack40)
        %v30062_v56 = vor.u32 %v30061_v25, %v30060_v10 (stack47)
        %v30498_v40 = vxor.u32 %v30497_v26, %v30489_v12 (stack48)
        %v131017_v61 = vadd.s32 %v157247_v60, %v157079_v39 (stack40)
        %v28900_v29 = vadd.f32 %v28896_v22, %v28833_v29 (stack53)
        %v29681_v41 = vadd.s32 5, %v29677_v20 (stack40)
        %v30903_v27 = vxor.u32 %v30902_v21, %v30898_v30 (stack48)
        %v31330_v46 = vsel /*vm=*/%vm31304_vm5, /*on_true_vy=*/%v31326_v55, /*on_false_vx=*/%v31322_v6 (stack44)
        %v30063_v6 = vxor.u32 %v30062_v56, %v30058_v9 (stack48)
        %v30493_v12 = vadd.s32 %v30489_v12, %v121564_v0 (stack40)
        %v30501_v24 = vadd.s32 %v30498_v40, %v121574_v2 (stack40)
        %v31335_v7 = vadd.s32 %v31330_v46, %v121574_v2 (stack40)
        %v28904_v23 = vmul.f32 %v28900_v29, %v130974_v53 (stack54)
        %v29683_v10 = vxor.u32 %v29681_v41, %v29669_v32 (stack48)
        %v30906_v30 = vadd.s32 %v30903_v27, %v30898_v30 (stack40)
        %v30912_v25 = vshll.u32 %v30903_v27, 6 (stack45)
        %v30066_v9 = vadd.s32 %v30063_v6, %v30058_v9 (stack40)
        %v30068_v26 = vshll.u32 %v30063_v6, 29 (stack45)
        %v30069_v22 = vshrl.u32 %v30063_v6, 3 (stack46)
        %v30505_v20 = vadd.s32 2, %v30501_v24 (stack40)
        %v28908_v11 = vadd.f32 %v28904_v23, %v130939_v11 (stack53)
        %v29684_v21 = vand.u32.u8 255, %v29683_v10 (stack49)
        %v30913_v55 = vshrl.u32 %v30903_v27, 26 (stack46)
        %v31339_v42 = vadd.s32 %v31300_v42, %v121569_v1 (stack40)
        %v30070_v32 = vor.u32 %v30069_v22, %v30068_v26 (stack47)
        %v30509_v56 = vadd.s32 %v30505_v20, %v30493_v12 (stack40)
        %v30511_v40 = vshll.u32 %v30505_v20, 13 (stack45)
        %v30512_v29 = vshrl.u32 %v30505_v20, 19 (stack46)
        %v120678_v41 = vpop.eup %120677 (stack64)
        %v28912_v27 = vmul.f32 %v28908_v11, %v130974_v53 (stack54)
        %v29685_v46 = vand.u32 65535, %v29684_v21 (stack50)
        %v30914_v6 = vor.u32 %v30913_v55, %v30912_v25 (stack47)
        %v31343_v12 = vadd.s32 %v31339_v42, %v31335_v7 (stack40)
        %v29263_v24 = vmul.f32 0.6931472, %v120678_v41 (stack65)
        %v29266_v44 = vmul.f32 %v29265_v43, %v130988_v44 (stack63)
        %v30071_v43 = vxor.u32 %v30070_v32, %v30066_v9 (stack48)
        %v30513_v7 = vor.u32 %v30512_v29, %v30511_v40 (stack47)
        %v28916_v8 = vadd.f32 %v28912_v27, %v130934_v8 (stack53)
        %vm29268_vm6 = vcmp.lt.f32.partialorder %v29267_v34, 0.0004427343 (stack62)
        %v29686_v34 = vshrl.u32 %v29685_v46, 1 (stack51)
        %v30915_v23 = vxor.u32 %v30914_v6, %v30906_v30 (stack48)
        %v29269_v10 = vsel /*vm=*/%vm29268_vm6, /*on_true_vy=*/%v29266_v44, /*on_false_vx=*/%v29263_v24 (stack66)
        %v30074_v25 = vadd.s32 %v30071_v43, %v30066_v9 (stack40)
        %v30076_v9 = vshll.u32 %v30071_v43, 16 (stack45)
        %v30077_v26 = vshrl.u32 %v30071_v43, 16 (stack46)
        %v28785_v22 = vand.u32 2147483647, %v130854_v31 (stack77)
        %v28920_v20 = vmul.f32 %v28916_v8, %v130974_v53 (stack54)
        %v131032_v11 = vxor.u32 2147483648, %v29269_v10 (stack56)
        %v30514_v21 = vxor.u32 %v30513_v7, %v30509_v56 (stack48)
        %v28821_v55 = vsel /*vm=*/%vm28812_vm0, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v30078_v32 = vor.u32 %v30077_v26, %v30076_v9 (stack47)
        %v31345_v40 = vshll.u32 %v31339_v42, 13 (stack45)
        %v31346_v42 = vshrl.u32 %v31339_v42, 19 (stack46)
        %v28924_v29 = vadd.f32 %v28920_v20, %v28821_v55 (stack53)
        %120679 = vrsqrt.f32 %v131032_v11 (stack67)
        %v29687_v41 = vor.u32 16256, %v29686_v34 (stack47)
        %v30079_v27 = vxor.u32 %v30078_v32, %v30074_v25 (stack48)
        %vm131038_vm7 = vcmp.eq.f32.partialorder %v28785_v22, 1.0 (stack68)
        %v28793_v6 = vmul.f32 inf, %v130854_v31 (stack54)
        %v28928_v53 = vmul.f32 %v28924_v29, %v130974_v53 (stack54)
        %vm29273_vm8 = vcmp.lt.f32.partialorder %v131032_v11, 5.0 (stack68)
        %v28817_v52 = vsel /*vm=*/%vm28812_vm0, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v30082_v24 = vadd.s32 %v30079_v27, %v30074_v25 (stack40)
        %v30918_v44 = vadd.s32 %v30915_v23, %v121564_v0 (stack40)
        %v31347_v43 = vor.u32 %v31346_v42, %v31345_v40 (stack47)
        %v28932_v7 = vadd.f32 %v28928_v53, %v28817_v52 (stack53)
        %v131050_v8 = vadd.f32 -2.5, %v131032_v11 (stack53)
        %v30910_v30 = vadd.s32 %v30906_v30, %v121569_v1 (stack40)
        %v131055_v34 = vadd.s32 %v131017_v61, %v122657_v58 (stack40)
        %v131060_v23 = vsel /*vm=*/%vm29273_vm8, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v29688_v10 = vand.u32.u16 65535, %v29687_v41 (stack52)
        %v30088_v25 = vshll.u32 %v30079_v27, 24 (stack45)
        %v30089_v9 = vshrl.u32 %v30079_v27, 8 (stack46)
        %v28936_v31 = vmul.f32 %v28932_v7, %v130854_v31 (stack54)
        %v30517_v56 = vadd.s32 %v30514_v21, %v30509_v56 (stack40)
        %v30519_v26 = vshll.u32 %v30514_v21, 15 (stack45)
        %v30520_v22 = vshrl.u32 %v30514_v21, 17 (stack46)
        %v119900_v20 = vadd.low.f32.bf16 -1.0, %v29688_v10 (stack53)
        %v30090_v21 = vor.u32 %v30089_v9, %v30088_v25 (stack47)
        %v30922_v55 = vadd.s32 1, %v30918_v44 (stack40)
        %v131063_v32 = vxor.u32 %v31347_v43, %v31343_v12 (stack48)
        %v28940_v40 = vsel /*vm=*/%vm131038_vm7, /*on_true_vy=*/%v28793_v6, /*on_false_vx=*/%v28936_v31 (stack44)
        %v30521_v42 = vor.u32 %v30520_v22, %v30519_v26 (stack47)
        %vm31770_vm9 = vcmp.lt.u32.totalorder %v131017_v61, %v157079_v39 (stack43)
        %v131071_v29 = vadd.s32 %v157248_v50, %v157082_v49 (stack40)
        %v28944_v41 = vmul.f32 1.4140625, %v28940_v40 (stack54)
        %v29697_v27 = vmul.f32 2.0, %v119900_v20 (stack54)
        %v30091_v46 = vxor.u32 %v30090_v21, %v30082_v24 (stack48)
        %v30926_v6 = vadd.s32 %v30922_v55, %v30910_v30 (stack40)
        %v30522_v53 = vxor.u32 %v30521_v42, %v30517_v56 (stack48)
        %v30928_v52 = vshll.u32 %v30922_v55, 17 (stack45)
        %v30929_v44 = vshrl.u32 %v30922_v55, 15 (stack46)
        %v131074_v12 = vadd.s32 %v131063_v32, %v31343_v12 (stack40)
        %v28947_v43 = vpack.c.bf16 %v156663_v45, %v28944_v41 (stack81)
        %v131080_v7 = vsel /*vm=*/%vm29273_vm8, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v29701_v30 = vadd.f32 -0.99609375, %v29697_v27 (stack53)
        %v30094_v10 = vadd.s32 %v30091_v46, %v121564_v0 (stack40)
        %v30525_v25 = vadd.s32 %v30522_v53, %v30517_v56 (stack40)
        %v30527_v9 = vshll.u32 %v30522_v53, 26 (stack45)
        %v30528_v31 = vshrl.u32 %v30522_v53, 6 (stack46)
        %v30930_v56 = vor.u32 %v30929_v44, %v30928_v52 (stack47)
        %v120680_v26 = vpop.eup %120679 (stack73)
        %119897 = vst [vmem:[%s123356_s30 + $0x21c] sm:$0xf] /*vst_source=*/%v28947_v43 (stack83)
        %v131087_v22 = vsel /*vm=*/%vm29273_vm8, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v131089_v20 = vmax.f32 %v29701_v30, -0.99609375 (stack55)
        %v30086_v24 = vadd.s32 %v30082_v24, %v121569_v1 (stack40)
        %v30098_v21 = vadd.s32 4, %v30094_v10 (stack40)
        %v29317_v55 = vmul.f32 %v120680_v26, %v131032_v11 (stack74)
        %vm29318_vm10 = vcmp.eq.f32.partialorder %v131032_v11, inf (stack70)
        %v30529_v40 = vor.u32 %v30528_v31, %v30527_v9 (stack47)
        %v30931_v42 = vxor.u32 %v30930_v56, %v30926_v6 (stack48)
        %vm29320_vm11 = vcmp.eq.f32.partialorder %v131032_v11, 0.0 (stack71)
        %v29321_v41 = vand.u32 2147483648, %v131032_v11 (stack72)
        %v29717_v27 = vxor.u32 2147483648, %v131089_v20 (stack56)
        %v30102_v46 = vadd.s32 %v30098_v21, %v30086_v24 (stack40)
        %v29319_v53 = vsel /*vm=*/%vm29318_vm10, /*on_true_vy=*/%v131032_v11, /*on_false_vx=*/%v29317_v55 (stack75)
        %v30104_v52 = vshll.u32 %v30098_v21, 13 (stack45)
        %v30105_v44 = vshrl.u32 %v30098_v21, 19 (stack46)
        %v30530_v43 = vxor.u32 %v30529_v40, %v30525_v25 (stack48)
        %v29306_v30 = vsel /*vm=*/%vm29273_vm8, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v29322_v10 = vsel /*vm=*/%vm29320_vm11, /*on_true_vy=*/%v29321_v41, /*on_false_vx=*/%v29319_v53 (stack76)
        %v131102_v9 = vmul.f32 %v29717_v27, %v131089_v20 (stack54)
        %v30934_v6 = vadd.s32 %v30931_v42, %v30926_v6 (stack40)
        %v29325_v31 = vadd.f32 -3.0, %v29322_v10 (stack53)
        %v30106_v56 = vor.u32 %v30105_v44, %v30104_v52 (stack47)
        %v30533_v25 = vadd.s32 %v30530_v43, %v30525_v25 (stack40)
        %v30539_v26 = vshll.u32 %v30530_v43, 6 (stack45)
        %v29722_v24 = vadd.f32 1.0, %v131102_v9 (stack57)
        %v30540_v21 = vshrl.u32 %v30530_v43, 26 (stack46)
        %v31353_v55 = vshll.u32 %v131063_v32, 15 (stack45)
        %v31354_v32 = vshrl.u32 %v131063_v32, 17 (stack46)
        %v29310_v40 = vsel /*vm=*/%vm29273_vm8, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v131113_v8 = vsel /*vm=*/%vm29273_vm8, /*on_true_vy=*/%v131050_v8, /*on_false_vx=*/%v29325_v31 (stack44)
        %v30107_v41 = vxor.u32 %v30106_v56, %v30102_v46 (stack48)
        %vm31765_vm12 = vcmp.lt.u32.totalorder %v131055_v34, %v131017_v61 (stack43)
        %v31779_v27 = vadd.s32 1, %v131071_v29 (stack40)
        %v29333_v53 = vmul.f32 %v131113_v8, %v29310_v40 (stack54)
        %120681 = vlog2.f32 %v29722_v24 (stack58)
        %v29725_v52 = vmul.f32 -0.5, %v131102_v9 (stack59)
        %v30936_v44 = vshll.u32 %v30931_v42, 29 (stack45)
        %v30110_v46 = vadd.s32 %v30107_v41, %v30102_v46 (stack40)
        %v30112_v43 = vshll.u32 %v30107_v41, 15 (stack45)
        %v30113_v10 = vshrl.u32 %v30107_v41, 17 (stack46)
        %v30541_v31 = vor.u32 %v30540_v21, %v30539_v26 (stack47)
        %v29302_v56 = vsel /*vm=*/%vm29273_vm8, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v29337_v30 = vadd.f32 %v29333_v53, %v29306_v30 (stack53)
        %v30937_v42 = vshrl.u32 %v30931_v42, 3 (stack46)
        %v31355_v26 = vor.u32 %v31354_v32, %v31353_v55 (stack47)
        %v30114_v24 = vor.u32 %v30113_v10, %v30112_v43 (stack47)
        %v30537_v21 = vadd.s32 %v30533_v25, %v121574_v2 (stack40)
        %v30542_v25 = vxor.u32 %v30541_v31, %v30533_v25 (stack48)
        %v31783_v29 = vsel /*vm=*/%vm31770_vm9, /*on_true_vy=*/%v31779_v27, /*on_false_vx=*/%v131071_v29 (stack44)
        %v29341_v55 = vmul.f32 %v29337_v30, %v131113_v8 (stack54)
        %v29726_v32 = vadd.f32 1.0, %v29725_v52 (stack61)
        %v30938_v40 = vor.u32 %v30937_v42, %v30936_v44 (stack47)
        %v31356_v41 = vxor.u32 %v31355_v26, %v131074_v12 (stack48)
        %v30115_v27 = vxor.u32 %v30114_v24, %v30110_v46 (stack48)
        %v30545_v53 = vadd.s32 %v30542_v25, %v121569_v1 (stack40)
        %v31787_v52 = vadd.s32 1, %v31783_v29 (stack40)
        %v131133_v44 = vadd.s32 %v157247_v60, %v157083_v59 (stack40)
        %v29345_v43 = vadd.f32 %v29341_v55, %v29302_v56 (stack53)
        %v30939_v10 = vxor.u32 %v30938_v40, %v30934_v6 (stack48)
        %v131136_v12 = vadd.s32 %v31356_v41, %v131074_v12 (stack40)
        %v31361_v31 = vshll.u32 %v31356_v41, 26 (stack45)
        %v30118_v46 = vadd.s32 %v30115_v27, %v30110_v46 (stack40)
        %v30120_v56 = vshll.u32 %v30115_v27, 26 (stack45)
        %v30121_v30 = vshrl.u32 %v30115_v27, 6 (stack46)
        %v30549_v42 = vadd.s32 3, %v30545_v53 (stack40)
        %v29349_v26 = vmul.f32 %v29345_v43, %v131113_v8 (stack54)
        %v30942_v6 = vadd.s32 %v30939_v10, %v30934_v6 (stack40)
        %v30944_v24 = vshll.u32 %v30939_v10, 16 (stack45)
        %v30945_v25 = vshrl.u32 %v30939_v10, 16 (stack46)
        %v30122_v55 = vor.u32 %v30121_v30, %v30120_v56 (stack47)
        %v30553_v21 = vadd.s32 %v30549_v42, %v30537_v21 (stack40)
        %v30555_v40 = vshll.u32 %v30549_v42, 17 (stack45)
        %v30556_v27 = vshrl.u32 %v30549_v42, 15 (stack46)
        %v29353_v22 = vadd.f32 %v29349_v26, %v131087_v22 (stack53)
        %v30946_v53 = vor.u32 %v30945_v25, %v30944_v24 (stack47)
        %v31362_v41 = vshrl.u32 %v31356_v41, 6 (stack46)
        %v31791_v61 = vsel /*vm=*/%vm31765_vm12, /*on_true_vy=*/%v31787_v52, /*on_false_vx=*/%v31783_v29 (stack44)
        %v29728_v29 = vand.u32 2147483647, %v131102_v9 (stack60)
        %v30123_v52 = vxor.u32 %v30122_v55, %v30118_v46 (stack48)
        %v30557_v43 = vor.u32 %v30556_v27, %v30555_v40 (stack47)
        %v31800_v34 = vadd.s32 %v131055_v34, %v121569_v1 (stack40)
        %v29357_v10 = vmul.f32 %v29353_v22, %v131113_v8 (stack54)
        %v29727_v9 = vmul.f32 %v29726_v32, %v131102_v9 (stack63)
        %v30947_v32 = vxor.u32 %v30946_v53, %v30942_v6 (stack48)
        %v31363_v31 = vor.u32 %v31362_v41, %v31361_v31 (stack47)
        %v120682_v56 = vpop.eup %120681 (stack64)
        %v30126_v46 = vadd.s32 %v30123_v52, %v30118_v46 (stack40)
        %v30132_v30 = vshll.u32 %v30123_v52, 6 (stack45)
        %v30133_v42 = vshrl.u32 %v30123_v52, 26 (stack46)
        %v30558_v26 = vxor.u32 %v30557_v43, %v30553_v21 (stack48)
        %v29361_v7 = vadd.f32 %v29357_v10, %v131080_v7 (stack53)
        %v29724_v24 = vmul.f32 0.6931472, %v120682_v56 (stack65)
        %v30950_v6 = vadd.s32 %v30947_v32, %v30942_v6 (stack40)
        %v31796_v25 = vadd.s32 %v31791_v61, %v121574_v2 (stack40)
        %vm29729_vm13 = vcmp.lt.f32.partialorder %v29728_v29, 0.0004427343 (stack62)
        %v30134_v55 = vor.u32 %v30133_v42, %v30132_v30 (stack47)
        %v30561_v21 = vadd.s32 %v30558_v26, %v30553_v21 (stack40)
        %v30563_v40 = vshll.u32 %v30558_v26, 29 (stack45)
        %v29365_v27 = vmul.f32 %v29361_v7, %v131113_v8 (stack54)
        %v29730_v22 = vsel /*vm=*/%vm29729_vm13, /*on_true_vy=*/%v29727_v9, /*on_false_vx=*/%v29724_v24 (stack66)
        %v30564_v53 = vshrl.u32 %v30558_v26, 3 (stack46)
        %v31806_v41 = vshll.u32 %v31800_v34, 13 (stack45)
        %v131151_v61 = vxor.u32 2147483648, %v29730_v22 (stack56)
        %v30135_v29 = vxor.u32 %v30134_v55, %v30126_v46 (stack48)
        %v31364_v52 = vxor.u32 %v31363_v31, %v131136_v12 (stack48)
        %v31807_v43 = vshrl.u32 %v31800_v34, 19 (stack46)
        %v29246_v10 = vand.u32 2147483647, %v130976_v54 (stack77)
        %v131156_v9 = vmul.f32 inf, %v130976_v54 (stack54)
        %v29369_v23 = vadd.f32 %v29365_v27, %v131060_v23 (stack53)
        %v31804_v34 = vadd.s32 %v31800_v34, %v31796_v25 (stack40)
        %v29278_v31 = vsel /*vm=*/%vm29273_vm8, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %vm29734_vm14 = vcmp.lt.f32.partialorder %v131151_v61, 5.0 (stack68)
        %120683 = vrsqrt.f32 %v131151_v61 (stack67)
        %v30565_v56 = vor.u32 %v30564_v53, %v30563_v40 (stack47)
        %v29282_v30 = vsel /*vm=*/%vm29273_vm8, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v29373_v42 = vmul.f32 %v29369_v23, %v131113_v8 (stack54)
        %v30956_v26 = vshll.u32 %v30947_v32, 24 (stack45)
        %v30957_v32 = vshrl.u32 %v30947_v32, 8 (stack46)
        %v29286_v11 = vsel /*vm=*/%vm29273_vm8, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v30130_v46 = vadd.s32 %v30126_v46, %v121564_v0 (stack40)
        %v30138_v7 = vadd.s32 %v30135_v29, %v121574_v2 (stack40)
        %v31808_v24 = vor.u32 %v31807_v43, %v31806_v41 (stack47)
        %v29377_v25 = vadd.f32 %v29373_v42, %v29286_v11 (stack53)
        %v131176_v55 = vsel /*vm=*/%vm29734_vm14, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v131179_v40 = vadd.f32 -2.5, %v131151_v61 (stack53)
        %v30954_v27 = vadd.s32 %v30950_v6, %v121564_v0 (stack40)
        %v131185_v22 = vsel /*vm=*/%vm29734_vm14, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v29782_v53 = vand.u32 2147483648, %v131151_v61 (stack72)
        %v30142_v41 = vadd.s32 5, %v30138_v7 (stack40)
        %v30566_v29 = vxor.u32 %v30565_v56, %v30561_v21 (stack48)
        %v29381_v43 = vmul.f32 %v29377_v25, %v131113_v8 (stack54)
        %v30958_v23 = vor.u32 %v30957_v32, %v30956_v26 (stack47)
        %v31367_v12 = vadd.s32 %v31364_v52, %v131136_v12 (stack40)
        %v31373_v56 = vshll.u32 %v31364_v52, 6 (stack45)
        %vm131190_vm15 = vcmp.eq.f32.partialorder %v29246_v10, 1.0 (stack68)
        %v30144_v42 = vxor.u32 %v30142_v41, %v30130_v46 (stack48)
        %v30569_v21 = vadd.s32 %v30566_v29, %v30561_v21 (stack40)
        %v30571_v26 = vshll.u32 %v30566_v29, 16 (stack45)
        %v30572_v32 = vshrl.u32 %v30566_v29, 16 (stack46)
        %v29385_v30 = vadd.f32 %v29381_v43, %v29282_v30 (stack53)
        %vm29779_vm0 = vcmp.eq.f32.partialorder %v131151_v61, inf (stack70)
        %v30959_v6 = vxor.u32 %v30958_v23, %v30950_v6 (stack48)
        %v31371_v11 = vadd.s32 %v31367_v12, %v121569_v1 (stack40)
        %v31374_v52 = vshrl.u32 %v31364_v52, 26 (stack46)
        %vm29781_vm1 = vcmp.eq.f32.partialorder %v131151_v61, 0.0 (stack71)
        %v30145_v46 = vand.u32.u8 255, %v30144_v42 (stack49)
        %v30573_v7 = vor.u32 %v30572_v32, %v30571_v26 (stack47)
        %v31809_v24 = vxor.u32 %v31808_v24, %v31804_v34 (stack48)
        %vm32231_vm2 = vcmp.lt.u32.totalorder %v131133_v44, %v157083_v59 (stack43)
        %v29389_v8 = vmul.f32 %v29385_v30, %v131113_v8 (stack54)
        %v30962_v25 = vadd.s32 %v30959_v6, %v121574_v2 (stack40)
        %v31375_v41 = vor.u32 %v31374_v52, %v31373_v56 (stack47)
        %v131203_v29 = vadd.s32 %v157248_v50, %v157084_v16 (stack40)
        %v30146_v43 = vand.u32 65535, %v30145_v46 (stack50)
        %v30574_v23 = vxor.u32 %v30573_v7, %v30569_v21 (stack48)
        %v31812_v34 = vadd.s32 %v31809_v24, %v31804_v34 (stack40)
        %v31814_v56 = vshll.u32 %v31809_v24, 15 (stack45)
        %v29393_v31 = vadd.f32 %v29389_v8, %v29278_v31 (stack53)
        %v30966_v42 = vadd.s32 2, %v30962_v25 (stack40)
        %v31376_v12 = vxor.u32 %v31375_v41, %v31367_v12 (stack48)
        %v31815_v26 = vshrl.u32 %v31809_v24, 17 (stack46)
        %v30147_v32 = vshrl.u32 %v30146_v43, 1 (stack51)
        %v30577_v21 = vadd.s32 %v30574_v23, %v30569_v21 (stack40)
        %v30583_v30 = vshll.u32 %v30574_v23, 24 (stack45)
        %v30584_v6 = vshrl.u32 %v30574_v23, 8 (stack46)
        %v120684_v52 = vpop.eup %120683 (stack73)
        %v29397_v54 = vmul.f32 %v29393_v31, %v130976_v54 (stack54)
        %v30970_v27 = vadd.s32 %v30966_v42, %v30954_v27 (stack40)
        %v30972_v46 = vshll.u32 %v30966_v42, 13 (stack45)
        %v30973_v7 = vshrl.u32 %v30966_v42, 19 (stack46)
        %v29778_v24 = vmul.f32 %v120684_v52, %v131151_v61 (stack74)
        %v30148_v8 = vor.u32 16256, %v30147_v32 (stack47)
        %v30581_v25 = vadd.s32 %v30577_v21, %v121569_v1 (stack40)
        %v30585_v41 = vor.u32 %v30584_v6, %v30583_v30 (stack47)
        %v29401_v9 = vsel /*vm=*/%vm131190_vm15, /*on_true_vy=*/%v131156_v9, /*on_false_vx=*/%v29397_v54 (stack44)
        %v30974_v10 = vor.u32 %v30973_v7, %v30972_v46 (stack47)
        %v31379_v43 = vadd.s32 %v31376_v12, %v121564_v0 (stack40)
        %v31816_v23 = vor.u32 %v31815_v26, %v31814_v56 (stack47)
        %v29405_v56 = vmul.f32 1.4140625, %v29401_v9 (stack54)
        %v29780_v31 = vsel /*vm=*/%vm29779_vm0, /*on_true_vy=*/%v131151_v61, /*on_false_vx=*/%v29778_v24 (stack75)
        %v30149_v42 = vand.u32.u16 65535, %v30148_v8 (stack52)
        %v30586_v12 = vxor.u32 %v30585_v41, %v30577_v21 (stack48)
        %v29783_v53 = vsel /*vm=*/%vm29781_vm1, /*on_true_vy=*/%v29782_v53, /*on_false_vx=*/%v29780_v31 (stack76)
        %v30975_v26 = vxor.u32 %v30974_v10, %v30970_v27 (stack48)
        %v31383_v32 = vadd.s32 1, %v31379_v43 (stack40)
        %v31817_v21 = vxor.u32 %v31816_v23, %v31812_v34 (stack48)
        %v29408_v30 = vpack.c.bf16 %v156663_v45, %v29405_v56 (stack81)
        %v29786_v6 = vadd.f32 -3.0, %v29783_v53 (stack53)
        %v119902_v52 = vadd.low.f32.bf16 -1.0, %v30149_v42 (stack53)
        %v30589_v54 = vadd.s32 %v30586_v12, %v121564_v0 (stack40)
        %v30978_v27 = vadd.s32 %v30975_v26, %v30970_v27 (stack40)
        %v30980_v46 = vshll.u32 %v30975_v26, 15 (stack45)
        %v30981_v7 = vshrl.u32 %v30975_v26, 17 (stack46)
        %v31387_v11 = vadd.s32 %v31383_v32, %v31371_v11 (stack40)
        %119899 = vst [vmem:[%s123356_s30 + $0x29c] sm:$0xf] /*vst_source=*/%v29408_v30 (stack83)
        %v131223_v40 = vsel /*vm=*/%vm29734_vm14, /*on_true_vy=*/%v131179_v40, /*on_false_vx=*/%v29786_v6 (stack44)
        %v30158_v24 = vmul.f32 2.0, %v119902_v52 (stack54)
        %v30593_v8 = vadd.s32 4, %v30589_v54 (stack40)
        %v31389_v41 = vshll.u32 %v31383_v32, 17 (stack45)
        %v29794_v22 = vmul.f32 %v131223_v40, %v131185_v22 (stack54)
        %v30982_v9 = vor.u32 %v30981_v7, %v30980_v46 (stack47)
        %v31390_v10 = vshrl.u32 %v31383_v32, 15 (stack46)
        %v31820_v34 = vadd.s32 %v31817_v21, %v31812_v34 (stack40)
        %v30162_v43 = vadd.f32 -0.99609375, %v30158_v24 (stack53)
        %v30597_v25 = vadd.s32 %v30593_v8, %v30581_v25 (stack40)
        %v30599_v23 = vshll.u32 %v30593_v8, 13 (stack45)
        %v30600_v56 = vshrl.u32 %v30593_v8, 19 (stack46)
        %v29707_v31 = vand.u32 2147483647, %v131089_v20 (stack77)
        %v29798_v55 = vadd.f32 %v29794_v22, %v131176_v55 (stack53)
        %v30983_v42 = vxor.u32 %v30982_v9, %v30978_v27 (stack48)
        %v31391_v12 = vor.u32 %v31390_v10, %v31389_v41 (stack47)
        %v29763_v53 = vsel /*vm=*/%vm29734_vm14, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v131232_v26 = vmax.f32 %v30162_v43, -0.99609375 (stack55)
        %v30601_v32 = vor.u32 %v30600_v56, %v30599_v23 (stack47)
        %v131236_v30 = vadd.s32 %v131133_v44, %v122657_v58 (stack40)
        %v29802_v6 = vmul.f32 %v29798_v55, %v131223_v40 (stack54)
        %v30986_v52 = vadd.s32 %v30983_v42, %v30978_v27 (stack40)
        %v30988_v54 = vshll.u32 %v30983_v42, 26 (stack45)
        %v30989_v27 = vshrl.u32 %v30983_v42, 6 (stack46)
        %v30178_v46 = vxor.u32 2147483648, %v131232_v26 (stack56)
        %v30602_v7 = vxor.u32 %v30601_v32, %v30597_v25 (stack48)
        %v31822_v24 = vshll.u32 %v31817_v21, 26 (stack45)
        %v31823_v21 = vshrl.u32 %v31817_v21, 6 (stack46)
        %v131243_v8 = vsel /*vm=*/%vm29734_vm14, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v29806_v41 = vadd.f32 %v29802_v6, %v29763_v53 (stack53)
        %v30990_v22 = vor.u32 %v30989_v27, %v30988_v54 (stack47)
        %v31392_v9 = vxor.u32 %v31391_v12, %v31387_v11 (stack48)
        %v29751_v10 = vsel /*vm=*/%vm29734_vm14, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v131249_v43 = vmul.f32 %v30178_v46, %v131232_v26 (stack54)
        %v30605_v25 = vadd.s32 %v30602_v7, %v30597_v25 (stack40)
        %v30607_v23 = vshll.u32 %v30602_v7, 15 (stack45)
        %vm32226_vm3 = vcmp.lt.u32.totalorder %v131236_v30, %v131133_v44 (stack43)
        %v29810_v56 = vmul.f32 %v29806_v41, %v131223_v40 (stack54)
        %v30608_v55 = vshrl.u32 %v30602_v7, 17 (stack46)
        %v30991_v42 = vxor.u32 %v30990_v22, %v30986_v52 (stack48)
        %v31395_v11 = vadd.s32 %v31392_v9, %v31387_v11 (stack40)
        %v29755_v12 = vsel /*vm=*/%vm29734_vm14, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v29759_v53 = vsel /*vm=*/%vm29734_vm14, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v30183_v32 = vadd.f32 1.0, %v131249_v43 (stack57)
        %v31824_v6 = vor.u32 %v31823_v21, %v31822_v24 (stack47)
        %v29814_v54 = vadd.f32 %v29810_v56, %v29759_v53 (stack53)
        %v30609_v27 = vor.u32 %v30608_v55, %v30607_v23 (stack47)
        %v30994_v52 = vadd.s32 %v30991_v42, %v30986_v52 (stack40)
        %v31000_v46 = vshll.u32 %v30991_v42, 6 (stack45)
        %120685 = vlog2.f32 %v30183_v32 (stack58)
        %v31001_v7 = vshrl.u32 %v30991_v42, 26 (stack46)
        %v31397_v24 = vshll.u32 %v31392_v9, 29 (stack45)
        %v32240_v21 = vadd.s32 1, %v131203_v29 (stack40)
        %v29818_v41 = vmul.f32 %v29814_v54, %v131223_v40 (stack54)
        %v30186_v22 = vmul.f32 -0.5, %v131249_v43 (stack59)
        %v30610_v23 = vxor.u32 %v30609_v27, %v30605_v25 (stack48)
        %v31398_v9 = vshrl.u32 %v31392_v9, 3 (stack46)
        %v30189_v56 = vand.u32 2147483647, %v131249_v43 (stack60)
        %v31002_v55 = vor.u32 %v31001_v7, %v31000_v46 (stack47)
        %v31825_v42 = vxor.u32 %v31824_v6, %v31820_v34 (stack48)
        %v32244_v29 = vsel /*vm=*/%vm32231_vm2, /*on_true_vy=*/%v32240_v21, /*on_false_vx=*/%v131203_v29 (stack44)
        %v29822_v12 = vadd.f32 %v29818_v41, %v29755_v12 (stack53)
        %v30613_v25 = vadd.s32 %v30610_v23, %v30605_v25 (stack40)
        %v30615_v53 = vshll.u32 %v30610_v23, 26 (stack45)
        %v30616_v32 = vshrl.u32 %v30610_v23, 6 (stack46)
        %v31003_v6 = vxor.u32 %v31002_v55, %v30994_v52 (stack48)
        %v31399_v54 = vor.u32 %v31398_v9, %v31397_v24 (stack47)
        %v31828_v34 = vadd.s32 %v31825_v42, %v31820_v34 (stack40)
        %v31834_v27 = vshll.u32 %v31825_v42, 6 (stack45)
        %v29826_v46 = vmul.f32 %v29822_v12, %v131223_v40 (stack54)
        %v30617_v7 = vor.u32 %v30616_v32, %v30615_v53 (stack47)
        %v31835_v24 = vshrl.u32 %v31825_v42, 26 (stack46)
        %v32248_v21 = vadd.s32 1, %v32244_v29 (stack40)
        %v30187_v41 = vadd.f32 1.0, %v30186_v22 (stack61)
        %v30998_v52 = vadd.s32 %v30994_v52, %v121574_v2 (stack40)
        %v31006_v22 = vadd.s32 %v31003_v6, %v121569_v1 (stack40)
        %v31400_v23 = vxor.u32 %v31399_v54, %v31395_v11 (stack48)
        %v29830_v10 = vadd.f32 %v29826_v46, %v29751_v10 (stack53)
        %v30618_v9 = vxor.u32 %v30617_v7, %v30613_v25 (stack48)
        %v31836_v55 = vor.u32 %v31835_v24, %v31834_v27 (stack47)
        %v32252_v44 = vsel /*vm=*/%vm32226_vm3, /*on_true_vy=*/%v32248_v21, /*on_false_vx=*/%v32244_v29 (stack44)
        %v31010_v42 = vadd.s32 3, %v31006_v22 (stack40)
        %v31403_v11 = vadd.s32 %v31400_v23, %v31395_v11 (stack40)
        %v31405_v29 = vshll.u32 %v31400_v23, 16 (stack45)
        %v31406_v12 = vshrl.u32 %v31400_v23, 16 (stack46)
        %v29834_v53 = vmul.f32 %v29830_v10, %v131223_v40 (stack54)
        %v30621_v25 = vadd.s32 %v30618_v9, %v30613_v25 (stack40)
        %v30627_v32 = vshll.u32 %v30618_v9, 6 (stack45)
        %v30628_v6 = vshrl.u32 %v30618_v9, 26 (stack46)
        %v31014_v54 = vadd.s32 %v31010_v42, %v30998_v52 (stack40)
        %v31016_v27 = vshll.u32 %v31010_v42, 17 (stack45)
        %v31017_v46 = vshrl.u32 %v31010_v42, 15 (stack46)
        %v31407_v7 = vor.u32 %v31406_v12, %v31405_v29 (stack47)
        %v29743_v24 = vsel /*vm=*/%vm29734_vm14, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v29838_v8 = vadd.f32 %v29834_v53, %v131243_v8 (stack53)
        %v30629_v21 = vor.u32 %v30628_v6, %v30627_v32 (stack47)
        %v31837_v52 = vxor.u32 %v31836_v55, %v31828_v34 (stack48)
        %v30188_v43 = vmul.f32 %v30187_v41, %v131249_v43 (stack63)
        %vm131281_vm4 = vcmp.lt.f32.partialorder %v30189_v56, 0.0004427343 (stack62)
        %v31018_v41 = vor.u32 %v31017_v46, %v31016_v27 (stack47)
        %v31408_v22 = vxor.u32 %v31407_v7, %v31403_v11 (stack48)
        %v120686_v23 = vpop.eup %120685 (stack64)
        %v29842_v10 = vmul.f32 %v29838_v8, %v131223_v40 (stack54)
        %v30630_v9 = vxor.u32 %v30629_v21, %v30621_v25 (stack48)
        %v31832_v34 = vadd.s32 %v31828_v34, %v121569_v1 (stack40)
        %v31840_v55 = vadd.s32 %v31837_v52, %v121564_v0 (stack40)
        %v30185_v42 = vmul.f32 0.6931472, %v120686_v23 (stack65)
        %v31019_v29 = vxor.u32 %v31018_v41, %v31014_v54 (stack48)
        %v31411_v11 = vadd.s32 %v31408_v22, %v31403_v11 (stack40)
        %v32261_v30 = vadd.s32 %v131236_v30, %v121569_v1 (stack40)
        %v29846_v12 = vadd.f32 %v29842_v10, %v29743_v24 (stack53)
        %v30633_v53 = vadd.s32 %v30630_v9, %v121574_v2 (stack40)
        %v31417_v32 = vshll.u32 %v31408_v22, 24 (stack45)
        %v31844_v6 = vadd.s32 1, %v31840_v55 (stack40)
        %v30191_v27 = vsel /*vm=*/%vm131281_vm4, /*on_true_vy=*/%v30188_v43, /*on_false_vx=*/%v30185_v42 (stack66)
        %v31022_v54 = vadd.s32 %v31019_v29, %v31014_v54 (stack40)
        %v31024_v46 = vshll.u32 %v31019_v29, 29 (stack45)
        %v31025_v7 = vshrl.u32 %v31019_v29, 3 (stack46)
        %v29850_v40 = vmul.f32 %v29846_v12, %v131223_v40 (stack54)
        %v131294_v24 = vxor.u32 2147483648, %v30191_v27 (stack56)
        %v30637_v8 = vadd.s32 5, %v30633_v53 (stack40)
        %v31418_v21 = vshrl.u32 %v31408_v22, 8 (stack46)
        %v29739_v61 = vsel /*vm=*/%vm29734_vm14, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v30625_v25 = vadd.s32 %v30621_v25, %v121564_v0 (stack40)
        %v31026_v52 = vor.u32 %v31025_v7, %v31024_v46 (stack47)
        %v31848_v43 = vadd.s32 %v31844_v6, %v31832_v34 (stack40)
        %v29715_v56 = vmul.f32 inf, %v131089_v20 (stack54)
        %v29854_v41 = vadd.f32 %v29850_v40, %v29739_v61 (stack53)
        %120687 = vrsqrt.f32 %v131294_v24 (stack67)
        %vm131304_vm5 = vcmp.eq.f32.partialorder %v29707_v31, 1.0 (stack68)
        %v30168_v22 = vand.u32 2147483647, %v131232_v26 (stack77)
        %vm30195_vm6 = vcmp.lt.f32.partialorder %v131294_v24, 5.0 (stack68)
        %v30639_v23 = vxor.u32 %v30637_v8, %v30625_v25 (stack48)
        %v29858_v20 = vmul.f32 %v29854_v41, %v131089_v20 (stack54)
        %v31419_v10 = vor.u32 %v31418_v21, %v31417_v32 (stack47)
        %v32257_v44 = vadd.s32 %v32252_v44, %v121574_v2 (stack40)
        %v32267_v9 = vshll.u32 %v32261_v30, 13 (stack45)
        %v31027_v34 = vxor.u32 %v31026_v52, %v31022_v54 (stack48)
        %v31415_v55 = vadd.s32 %v31411_v11, %v121564_v0 (stack40)
        %v31850_v42 = vshll.u32 %v31844_v6, 17 (stack45)
        %v32268_v29 = vshrl.u32 %v32261_v30, 19 (stack46)
        %v29862_v12 = vsel /*vm=*/%vm131304_vm5, /*on_true_vy=*/%v29715_v56, /*on_false_vx=*/%v29858_v20 (stack44)
        %v131318_v53 = vsel /*vm=*/%vm30195_vm6, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v131323_v32 = vsel /*vm=*/%vm30195_vm6, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v131326_v27 = vadd.f32 -2.5, %v131294_v24 (stack53)
        %v29866_v46 = vmul.f32 1.4140625, %v29862_v12 (stack54)
        %v30640_v7 = vand.u32.u8 255, %v30639_v23 (stack49)
        %v31030_v54 = vadd.s32 %v31027_v34, %v31022_v54 (stack40)
        %v31032_v40 = vshll.u32 %v31027_v34, 16 (stack45)
        %v31033_v8 = vshrl.u32 %v31027_v34, 16 (stack46)
        %v31420_v11 = vxor.u32 %v31419_v10, %v31411_v11 (stack48)
        %v31851_v6 = vshrl.u32 %v31844_v6, 15 (stack46)
        %v32265_v30 = vadd.s32 %v32261_v30, %v32257_v44 (stack40)
        %v29869_v21 = vpack.c.bf16 %v156663_v45, %v29866_v46 (stack81)
        %v30641_v61 = vand.u32 65535, %v30640_v7 (stack50)
        %v32269_v25 = vor.u32 %v32268_v29, %v32267_v9 (stack47)
        %v131331_v52 = vadd.s32 %v157247_v60, %v157089_v17 (stack40)
        %v31034_v56 = vor.u32 %v31033_v8, %v31032_v40 (stack47)
        %v31423_v41 = vadd.s32 %v31420_v11, %v121574_v2 (stack40)
        %v31852_v31 = vor.u32 %v31851_v6, %v31850_v42 (stack47)
        %v32697_v23 = vadd.s32 %v157248_v50, %v157090_v62 (stack40)
        %119901 = vst [vmem:[%s123356_s30 + $0x31c] sm:$0xf] /*vst_source=*/%v29869_v21 (stack83)
        %vm30240_vm7 = vcmp.eq.f32.partialorder %v131294_v24, inf (stack70)
        %v30642_v20 = vshrl.u32 %v30641_v61, 1 (stack51)
        %v32270_v10 = vxor.u32 %v32269_v25, %v32265_v30 (stack48)
        %vm32692_vm8 = vcmp.lt.u32.totalorder %v131331_v52, %v157089_v17 (stack43)
        %v30243_v44 = vand.u32 2147483648, %v131294_v24 (stack72)
        %v31035_v9 = vxor.u32 %v31034_v56, %v31030_v54 (stack48)
        %v31427_v34 = vadd.s32 2, %v31423_v41 (stack40)
        %v31853_v42 = vxor.u32 %v31852_v31, %v31848_v43 (stack48)
        %v30643_v29 = vor.u32 16256, %v30642_v20 (stack47)
        %v32273_v12 = vadd.s32 %v32270_v10, %v32265_v30 (stack40)
        %v32275_v46 = vshll.u32 %v32270_v10, 15 (stack45)
        %v32276_v7 = vshrl.u32 %v32270_v10, 17 (stack46)
        %v31038_v54 = vadd.s32 %v31035_v9, %v31030_v54 (stack40)
        %v31044_v40 = vshll.u32 %v31035_v9, 24 (stack45)
        %v31045_v8 = vshrl.u32 %v31035_v9, 8 (stack46)
        %v31431_v55 = vadd.s32 %v31427_v34, %v31415_v55 (stack40)
        %v120688_v11 = vpop.eup %120687 (stack73)
        %v30644_v6 = vand.u32.u16 65535, %v30643_v29 (stack52)
        %v31433_v30 = vshll.u32 %v31427_v34, 13 (stack45)
        %v31434_v21 = vshrl.u32 %v31427_v34, 19 (stack46)
        %v31856_v43 = vadd.s32 %v31853_v42, %v31848_v43 (stack40)
        %v30239_v61 = vmul.f32 %v120688_v11, %v131294_v24 (stack74)
        %v31046_v25 = vor.u32 %v31045_v8, %v31044_v40 (stack47)
        %v31858_v56 = vshll.u32 %v31853_v42, 29 (stack45)
        %v32701_v41 = vadd.s32 1, %v32697_v23 (stack40)
        %v119908_v31 = vadd.low.f32.bf16 -1.0, %v30644_v6 (stack53)
        %v31435_v20 = vor.u32 %v31434_v21, %v31433_v30 (stack47)
        %v31859_v10 = vshrl.u32 %v31853_v42, 3 (stack46)
        %v32277_v9 = vor.u32 %v32276_v7, %v32275_v46 (stack47)
        %v30241_v34 = vsel /*vm=*/%vm30240_vm7, /*on_true_vy=*/%v131294_v24, /*on_false_vx=*/%v30239_v61 (stack75)
        %vm30242_vm9 = vcmp.eq.f32.partialorder %v131294_v24, 0.0 (stack71)
        %v31047_v42 = vxor.u32 %v31046_v25, %v31038_v54 (stack48)
        %v32705_v23 = vsel /*vm=*/%vm32692_vm8, /*on_true_vy=*/%v32701_v41, /*on_false_vx=*/%v32697_v23 (stack44)
        %v30244_v44 = vsel /*vm=*/%vm30242_vm9, /*on_true_vy=*/%v30243_v44, /*on_false_vx=*/%v30241_v34 (stack76)
        %v30653_v29 = vmul.f32 2.0, %v119908_v31 (stack54)
        %v31436_v46 = vxor.u32 %v31435_v20, %v31431_v55 (stack48)
        %v31860_v7 = vor.u32 %v31859_v10, %v31858_v56 (stack47)
        %v30247_v40 = vadd.f32 -3.0, %v30244_v44 (stack53)
        %v31042_v54 = vadd.s32 %v31038_v54, %v121569_v1 (stack40)
        %v31050_v8 = vadd.s32 %v31047_v42, %v121564_v0 (stack40)
        %v32278_v11 = vxor.u32 %v32277_v9, %v32273_v12 (stack48)
        %v30657_v6 = vadd.f32 -0.99609375, %v30653_v29 (stack53)
        %v31439_v55 = vadd.s32 %v31436_v46, %v31431_v55 (stack40)
        %v31441_v30 = vshll.u32 %v31436_v46, 15 (stack45)
        %v31442_v21 = vshrl.u32 %v31436_v46, 17 (stack46)
        %v131354_v27 = vsel /*vm=*/%vm30195_vm6, /*on_true_vy=*/%v131326_v27, /*on_false_vx=*/%v30247_v40 (stack44)
        %v31054_v61 = vadd.s32 4, %v31050_v8 (stack40)
        %v31861_v25 = vxor.u32 %v31860_v7, %v31856_v43 (stack48)
        %v131356_v12 = vadd.s32 %v32278_v11, %v32273_v12 (stack40)
        %v30228_v56 = vsel /*vm=*/%vm30195_vm6, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v30255_v32 = vmul.f32 %v131354_v27, %v131323_v32 (stack54)
        %v131363_v41 = vmax.f32 %v30657_v6, -0.99609375 (stack55)
        %v31443_v31 = vor.u32 %v31442_v21, %v31441_v30 (stack47)
        %v31058_v20 = vadd.s32 %v31054_v61, %v31042_v54 (stack40)
        %v31060_v10 = vshll.u32 %v31054_v61, 13 (stack45)
        %v31061_v9 = vshrl.u32 %v31054_v61, 19 (stack46)
        %v31864_v43 = vadd.s32 %v31861_v25, %v31856_v43 (stack40)
        %v30224_v34 = vsel /*vm=*/%vm30195_vm6, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v30259_v42 = vadd.f32 %v30255_v32, %v30228_v56 (stack53)
        %v30673_v44 = vxor.u32 2147483648, %v131363_v41 (stack56)
        %v32683_v29 = vadd.s32 %v131331_v52, %v122657_v58 (stack40)
        %v31062_v46 = vor.u32 %v31061_v9, %v31060_v10 (stack47)
        %v31444_v7 = vxor.u32 %v31443_v31, %v31439_v55 (stack48)
        %v31866_v40 = vshll.u32 %v31861_v25, 16 (stack45)
        %v32283_v54 = vshll.u32 %v32278_v11, 26 (stack45)
        %v30263_v8 = vmul.f32 %v30259_v42, %v131354_v27 (stack54)
        %v131373_v6 = vmul.f32 %v30673_v44, %v131363_v41 (stack54)
        %v31867_v30 = vshrl.u32 %v31861_v25, 16 (stack46)
        %v32284_v11 = vshrl.u32 %v32278_v11, 6 (stack46)
        %v31063_v21 = vxor.u32 %v31062_v46, %v31058_v20 (stack48)
        %v31447_v55 = vadd.s32 %v31444_v7, %v31439_v55 (stack40)
        %v31449_v61 = vshll.u32 %v31444_v7, 26 (stack45)
        %v31450_v25 = vshrl.u32 %v31444_v7, 6 (stack46)
        %v30267_v56 = vadd.f32 %v30263_v8, %v30224_v34 (stack53)
        %v30678_v32 = vadd.f32 1.0, %v131373_v6 (stack57)
        %vm32687_vm10 = vcmp.lt.u32.totalorder %v32683_v29, %v131331_v52 (stack43)
        %v32709_v31 = vadd.s32 1, %v32705_v23 (stack40)
        %v31066_v20 = vadd.s32 %v31063_v21, %v31058_v20 (stack40)
        %v31068_v10 = vshll.u32 %v31063_v21, 15 (stack45)
        %v31069_v9 = vshrl.u32 %v31063_v21, 17 (stack46)
        %v31451_v34 = vor.u32 %v31450_v25, %v31449_v61 (stack47)
        %v30216_v42 = vsel /*vm=*/%vm30195_vm6, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v30220_v44 = vsel /*vm=*/%vm30195_vm6, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v30271_v46 = vmul.f32 %v30267_v56, %v131354_v27 (stack54)
        %120689 = vlog2.f32 %v30678_v32 (stack58)
        %v31070_v7 = vor.u32 %v31069_v9, %v31068_v10 (stack47)
        %v31452_v8 = vxor.u32 %v31451_v34, %v31447_v55 (stack48)
        %v31868_v40 = vor.u32 %v31867_v30, %v31866_v40 (stack47)
        %v32285_v54 = vor.u32 %v32284_v11, %v32283_v54 (stack47)
        %v30275_v30 = vadd.f32 %v30271_v46, %v30220_v44 (stack53)
        %v30681_v11 = vmul.f32 -0.5, %v131373_v6 (stack59)
        %v30684_v21 = vand.u32 2147483647, %v131373_v6 (stack60)
        %v32713_v52 = vsel /*vm=*/%vm32687_vm10, /*on_true_vy=*/%v32709_v31, /*on_false_vx=*/%v32705_v23 (stack44)
        %v31071_v23 = vxor.u32 %v31070_v7, %v31066_v20 (stack48)
        %v31455_v55 = vadd.s32 %v31452_v8, %v31447_v55 (stack40)
        %v31461_v61 = vshll.u32 %v31452_v8, 6 (stack45)
        %v31462_v25 = vshrl.u32 %v31452_v8, 26 (stack46)
        %v30279_v56 = vmul.f32 %v30275_v30, %v131354_v27 (stack54)
        %v31869_v32 = vxor.u32 %v31868_v40, %v31864_v43 (stack48)
        %v32286_v31 = vxor.u32 %v32285_v54, %v131356_v12 (stack48)
        %v131391_v29 = vadd.s32 %v32683_v29, %v121569_v1 (stack40)
        %v31074_v20 = vadd.s32 %v31071_v23, %v31066_v20 (stack40)
        %v31076_v10 = vshll.u32 %v31071_v23, 26 (stack45)
        %v31077_v9 = vshrl.u32 %v31071_v23, 6 (stack46)
        %v32718_v34 = vadd.s32 %v32713_v52, %v121574_v2 (stack40)
        %v30283_v42 = vadd.f32 %v30279_v56, %v30216_v42 (stack53)
        %v31463_v44 = vor.u32 %v31462_v25, %v31461_v61 (stack47)
        %v31872_v43 = vadd.s32 %v31869_v32, %v31864_v43 (stack40)
        %v31878_v46 = vshll.u32 %v31869_v32, 24 (stack45)
        %v31078_v7 = vor.u32 %v31077_v9, %v31076_v10 (stack47)
        %v31879_v8 = vshrl.u32 %v31869_v32, 8 (stack46)
        %v32289_v12 = vadd.s32 %v32286_v31, %v131356_v12 (stack40)
        %v32295_v40 = vshll.u32 %v32286_v31, 6 (stack45)
        %v30212_v54 = vsel /*vm=*/%vm30195_vm6, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v30287_v30 = vmul.f32 %v30283_v42, %v131354_v27 (stack54)
        %v31464_v52 = vxor.u32 %v31463_v44, %v31455_v55 (stack48)
        %v32296_v23 = vshrl.u32 %v32286_v31, 26 (stack46)
        %v30682_v11 = vadd.f32 1.0, %v30681_v11 (stack61)
        %v31079_v61 = vxor.u32 %v31078_v7, %v31074_v20 (stack48)
        %v31880_v25 = vor.u32 %v31879_v8, %v31878_v46 (stack47)
        %v131400_v56 = vadd.s32 %v131391_v29, %v32718_v34 (stack40)
        %v30291_v32 = vadd.f32 %v30287_v30, %v30212_v54 (stack53)
        %vm131402_vm11 = vcmp.lt.f32.partialorder %v30684_v21, 0.0004427343 (stack62)
        %v31467_v31 = vadd.s32 %v31464_v52, %v121569_v1 (stack40)
        %v32297_v10 = vor.u32 %v32296_v23, %v32295_v40 (stack47)
        %v31082_v20 = vadd.s32 %v31079_v61, %v31074_v20 (stack40)
        %v31088_v9 = vshll.u32 %v31079_v61, 6 (stack45)
        %v31089_v34 = vshrl.u32 %v31079_v61, 26 (stack46)
        %v31881_v42 = vxor.u32 %v31880_v25, %v31872_v43 (stack48)
        %v30295_v44 = vmul.f32 %v30291_v32, %v131354_v27 (stack54)
        %v31459_v55 = vadd.s32 %v31455_v55, %v121574_v2 (stack40)
        %v31471_v46 = vadd.s32 3, %v31467_v31 (stack40)
        %v32298_v7 = vxor.u32 %v32297_v10, %v32289_v12 (stack48)
        %v120690_v8 = vpop.eup %120689 (stack64)
        %v30683_v6 = vmul.f32 %v30682_v11, %v131373_v6 (stack63)
        %v31090_v40 = vor.u32 %v31089_v34, %v31088_v9 (stack47)
        %v31884_v54 = vadd.s32 %v31881_v42, %v121574_v2 (stack40)
        %v131413_v30 = vadd.s32 %v157247_v60, %v157091_v37 (stack40)
        %v30299_v53 = vadd.f32 %v30295_v44, %v131318_v53 (stack53)
        %v30680_v52 = vmul.f32 0.6931472, %v120690_v8 (stack65)
        %v31475_v23 = vadd.s32 %v31471_v46, %v31459_v55 (stack40)
        %v31477_v11 = vshll.u32 %v31471_v46, 17 (stack45)
        %v31091_v61 = vxor.u32 %v31090_v40, %v31082_v20 (stack48)
        %v31478_v25 = vshrl.u32 %v31471_v46, 15 (stack46)
        %v31876_v43 = vadd.s32 %v31872_v43, %v121564_v0 (stack40)
        %v31888_v32 = vadd.s32 2, %v31884_v54 (stack40)
        %v30204_v31 = vsel /*vm=*/%vm30195_vm6, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v30303_v10 = vmul.f32 %v30299_v53, %v131354_v27 (stack54)
        %v30686_v21 = vsel /*vm=*/%vm131402_vm11, /*on_true_vy=*/%v30683_v6, /*on_false_vx=*/%v30680_v52 (stack66)
        %v131423_v9 = vxor.u32 2147483648, %v30686_v21 (stack56)
        %v31479_v34 = vor.u32 %v31478_v25, %v31477_v11 (stack47)
        %v31892_v42 = vadd.s32 %v31888_v32, %v31876_v43 (stack40)
        %v32301_v44 = vadd.s32 %v32298_v7, %v121564_v0 (stack40)
        %v30307_v55 = vadd.f32 %v30303_v10, %v30204_v31 (stack53)
        %v32728_v46 = vshll.u32 %v131391_v29, 13 (stack45)
        %v32729_v29 = vshrl.u32 %v131391_v29, 19 (stack46)
        %vm131430_vm12 = vcmp.eq.f32.partialorder %v30168_v22, 1.0 (stack68)
        %v30176_v7 = vmul.f32 inf, %v131232_v26 (stack54)
        %120691 = vrsqrt.f32 %v131423_v9 (stack67)
        %v31094_v8 = vadd.s32 %v31091_v61, %v121574_v2 (stack40)
        %v30311_v27 = vmul.f32 %v30307_v55, %v131354_v27 (stack54)
        %vm30690_vm13 = vcmp.lt.f32.partialorder %v131423_v9, 5.0 (stack68)
        %v31894_v6 = vshll.u32 %v31888_v32, 13 (stack45)
        %v31895_v40 = vshrl.u32 %v31888_v32, 19 (stack46)
        %v30200_v24 = vsel /*vm=*/%vm30195_vm6, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v30663_v54 = vand.u32 2147483647, %v131363_v41 (stack77)
        %v31480_v53 = vxor.u32 %v31479_v34, %v31475_v23 (stack48)
        %v32305_v52 = vadd.s32 1, %v32301_v44 (stack40)
        %v30315_v11 = vadd.f32 %v30311_v27, %v30200_v24 (stack53)
        %v31086_v20 = vadd.s32 %v31082_v20, %v121564_v0 (stack40)
        %v32293_v12 = vadd.s32 %v32289_v12, %v121569_v1 (stack40)
        %v32730_v61 = vor.u32 %v32729_v29, %v32728_v46 (stack47)
        %v131448_v25 = vsel /*vm=*/%vm30690_vm13, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v131451_v43 = vadd.f32 -2.5, %v131423_v9 (stack53)
        %v31098_v32 = vadd.s32 5, %v31094_v8 (stack40)
        %v31483_v23 = vadd.s32 %v31480_v53, %v31475_v23 (stack40)
        %v30319_v26 = vmul.f32 %v30315_v11, %v131232_v26 (stack54)
        %v31485_v31 = vshll.u32 %v31480_v53, 29 (stack45)
        %v31486_v10 = vshrl.u32 %v31480_v53, 3 (stack46)
        %v31896_v21 = vor.u32 %v31895_v40, %v31894_v6 (stack47)
        %v31100_v34 = vxor.u32 %v31098_v32, %v31086_v20 (stack48)
        %v32309_v44 = vadd.s32 %v32305_v52, %v32293_v12 (stack40)
        %v32311_v55 = vshll.u32 %v32305_v52, 17 (stack45)
        %v32312_v46 = vshrl.u32 %v32305_v52, 15 (stack46)
        %v30323_v29 = vsel /*vm=*/%vm131430_vm12, /*on_true_vy=*/%v30176_v7, /*on_false_vx=*/%v30319_v26 (stack44)
        %vm30735_vm14 = vcmp.eq.f32.partialorder %v131423_v9, inf (stack70)
        %v31487_v22 = vor.u32 %v31486_v10, %v31485_v31 (stack47)
        %v31897_v7 = vxor.u32 %v31896_v21, %v31892_v42 (stack48)
        %v32731_v8 = vxor.u32 %v32730_v61, %v131400_v56 (stack48)
        %v30327_v27 = vmul.f32 1.4140625, %v30323_v29 (stack54)
        %vm30737_vm15 = vcmp.eq.f32.partialorder %v131423_v9, 0.0 (stack71)
        %v30738_v6 = vand.u32 2147483648, %v131423_v9 (stack72)
        %v31101_v40 = vand.u32.u8 255, %v31100_v34 (stack49)
        %v32313_v24 = vor.u32 %v32312_v46, %v32311_v55 (stack47)
        %v31488_v53 = vxor.u32 %v31487_v22, %v31483_v23 (stack48)
        %v31900_v42 = vadd.s32 %v31897_v7, %v31892_v42 (stack40)
        %v31902_v52 = vshll.u32 %v31897_v7, 15 (stack45)
        %v31903_v11 = vshrl.u32 %v31897_v7, 17 (stack46)
        %v30330_v20 = vpack.c.bf16 %v156663_v45, %v30327_v27 (stack81)
        %v31102_v12 = vand.u32 65535, %v31101_v40 (stack50)
        %v32314_v61 = vxor.u32 %v32313_v24, %v32309_v44 (stack48)
        %v32734_v56 = vadd.s32 %v32731_v8, %v131400_v56 (stack40)
        %v31491_v32 = vadd.s32 %v31488_v53, %v31483_v23 (stack40)
        %v31493_v23 = vshll.u32 %v31488_v53, 16 (stack45)
        %v31494_v26 = vshrl.u32 %v31488_v53, 16 (stack46)
        %v31904_v31 = vor.u32 %v31903_v11, %v31902_v52 (stack47)
        %119903 = vst [vmem:[%s123356_s30 + $0x39c] sm:$0xf] /*vst_source=*/%v30330_v20 (stack83)
        %v31103_v10 = vshrl.u32 %v31102_v12, 1 (stack51)
        %v32317_v21 = vadd.s32 %v32314_v61, %v32309_v44 (stack40)
        %v32319_v34 = vshll.u32 %v32314_v61, 29 (stack45)
        %v32320_v44 = vshrl.u32 %v32314_v61, 3 (stack46)
        %v120692_v55 = vpop.eup %120691 (stack73)
        %v31495_v46 = vor.u32 %v31494_v26, %v31493_v23 (stack47)
        %v31905_v29 = vxor.u32 %v31904_v31, %v31900_v42 (stack48)
        %v32736_v22 = vshll.u32 %v32731_v8, 15 (stack45)
        %v32737_v7 = vshrl.u32 %v32731_v8, 17 (stack46)
        %v30734_v8 = vmul.f32 %v120692_v55, %v131423_v9 (stack74)
        %v31104_v27 = vor.u32 16256, %v31103_v10 (stack47)
        %v32321_v40 = vor.u32 %v32320_v44, %v32319_v34 (stack47)
        %vm33153_vm0 = vcmp.lt.u32.totalorder %v131413_v30, %v157091_v37 (stack43)
        %v31496_v24 = vxor.u32 %v31495_v46, %v31491_v32 (stack48)
        %v31908_v53 = vadd.s32 %v31905_v29, %v31900_v42 (stack40)
        %v31910_v42 = vshll.u32 %v31905_v29, 26 (stack45)
        %v31911_v52 = vshrl.u32 %v31905_v29, 6 (stack46)
        %v30736_v11 = vsel /*vm=*/%vm30735_vm14, /*on_true_vy=*/%v131423_v9, /*on_false_vx=*/%v30734_v8 (stack75)
        %v31105_v20 = vand.u32.u16 65535, %v31104_v27 (stack52)
        %v32322_v12 = vxor.u32 %v32321_v40, %v32317_v21 (stack48)
        %v32738_v61 = vor.u32 %v32737_v7, %v32736_v22 (stack47)
        %v30739_v6 = vsel /*vm=*/%vm30737_vm15, /*on_true_vy=*/%v30738_v6, /*on_false_vx=*/%v30736_v11 (stack76)
        %v31499_v32 = vadd.s32 %v31496_v24, %v31491_v32 (stack40)
        %v31505_v23 = vshll.u32 %v31496_v24, 24 (stack45)
        %v31506_v26 = vshrl.u32 %v31496_v24, 8 (stack46)
        %v30742_v31 = vadd.f32 -3.0, %v30739_v6 (stack53)
        %v119910_v10 = vadd.low.f32.bf16 -1.0, %v31105_v20 (stack53)
        %v31912_v34 = vor.u32 %v31911_v52, %v31910_v42 (stack47)
        %v32325_v21 = vadd.s32 %v32322_v12, %v32317_v21 (stack40)
        %v30727_v44 = vsel /*vm=*/%vm30690_vm13, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v31507_v55 = vor.u32 %v31506_v26, %v31505_v23 (stack47)
        %v32327_v46 = vshll.u32 %v32322_v12, 16 (stack45)
        %v32328_v29 = vshrl.u32 %v32322_v12, 16 (stack46)
        %v131477_v43 = vsel /*vm=*/%vm30690_vm13, /*on_true_vy=*/%v131451_v43, /*on_false_vx=*/%v30742_v31 (stack44)
        %v31114_v22 = vmul.f32 2.0, %v119910_v10 (stack54)
        %v31913_v7 = vxor.u32 %v31912_v34, %v31908_v53 (stack48)
        %v32739_v8 = vxor.u32 %v32738_v61, %v32734_v56 (stack48)
        %v30750_v27 = vmul.f32 %v131477_v43, %v30727_v44 (stack54)
        %v31508_v40 = vxor.u32 %v31507_v55, %v31499_v32 (stack48)
        %v32329_v24 = vor.u32 %v32328_v29, %v32327_v46 (stack47)
        %v131482_v42 = vadd.s32 %v157248_v50, %v157094_v36 (stack40)
        %v31118_v52 = vadd.f32 -0.99609375, %v31114_v22 (stack53)
        %v31916_v53 = vadd.s32 %v31913_v7, %v31908_v53 (stack40)
        %v31922_v11 = vshll.u32 %v31913_v7, 6 (stack45)
        %v31923_v20 = vshrl.u32 %v31913_v7, 26 (stack46)
        %v30754_v25 = vadd.f32 %v30750_v27, %v131448_v25 (stack53)
        %v31511_v12 = vadd.s32 %v31508_v40, %v121564_v0 (stack40)
        %v32330_v61 = vxor.u32 %v32329_v24, %v32325_v21 (stack48)
        %v32742_v56 = vadd.s32 %v32739_v8, %v32734_v56 (stack40)
        %v30719_v6 = vsel /*vm=*/%vm30690_vm13, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v131489_v23 = vmax.f32 %v31118_v52, -0.99609375 (stack55)
        %v31924_v26 = vor.u32 %v31923_v20, %v31922_v11 (stack47)
        %v131493_v31 = vadd.s32 %v131413_v30, %v122657_v58 (stack40)
        %v30758_v10 = vmul.f32 %v30754_v25, %v131477_v43 (stack54)
        %v31503_v32 = vadd.s32 %v31499_v32, %v121569_v1 (stack40)
        %v31515_v34 = vadd.s32 4, %v31511_v12 (stack40)
        %v32333_v21 = vadd.s32 %v32330_v61, %v32325_v21 (stack40)
        %v31134_v44 = vxor.u32 2147483648, %v131489_v23 (stack56)
        %v31925_v55 = vxor.u32 %v31924_v26, %v31916_v53 (stack48)
        %v32339_v46 = vshll.u32 %v32330_v61, 24 (stack45)
        %v32744_v29 = vshll.u32 %v32739_v8, 26 (stack45)
        %v30762_v22 = vadd.f32 %v30758_v10, %v30719_v6 (stack53)
        %v31519_v7 = vadd.s32 %v31515_v34, %v31503_v32 (stack40)
        %v31521_v27 = vshll.u32 %v31515_v34, 13 (stack45)
        %v31522_v40 = vshrl.u32 %v31515_v34, 19 (stack46)
        %v131501_v24 = vsel /*vm=*/%vm30690_vm13, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v30715_v52 = vsel /*vm=*/%vm30690_vm13, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v131507_v11 = vmul.f32 %v31134_v44, %v131489_v23 (stack54)
        %v31928_v20 = vadd.s32 %v31925_v55, %v121569_v1 (stack40)
        %v30766_v25 = vmul.f32 %v30762_v22, %v131477_v43 (stack54)
        %v31523_v12 = vor.u32 %v31522_v40, %v31521_v27 (stack47)
        %v32340_v61 = vshrl.u32 %v32330_v61, 8 (stack46)
        %v32745_v8 = vshrl.u32 %v32739_v8, 6 (stack46)
        %v31139_v6 = vadd.f32 1.0, %v131507_v11 (stack57)
        %v31142_v26 = vmul.f32 -0.5, %v131507_v11 (stack59)
        %v31920_v53 = vadd.s32 %v31916_v53, %v121574_v2 (stack40)
        %v31932_v10 = vadd.s32 3, %v31928_v20 (stack40)
        %v30770_v32 = vadd.f32 %v30766_v25, %v30715_v52 (stack53)
        %v31524_v34 = vxor.u32 %v31523_v12, %v31519_v7 (stack48)
        %v32341_v44 = vor.u32 %v32340_v61, %v32339_v46 (stack47)
        %v32746_v55 = vor.u32 %v32745_v8, %v32744_v29 (stack47)
        %v30707_v46 = vsel /*vm=*/%vm30690_vm13, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v30711_v29 = vsel /*vm=*/%vm30690_vm13, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %120693 = vlog2.f32 %v31139_v6 (stack58)
        %v31936_v22 = vadd.s32 %v31932_v10, %v31920_v53 (stack40)
        %v30774_v27 = vmul.f32 %v30770_v32, %v131477_v43 (stack54)
        %v31527_v7 = vadd.s32 %v31524_v34, %v31519_v7 (stack40)
        %v31529_v40 = vshll.u32 %v31524_v34, 15 (stack45)
        %v31530_v52 = vshrl.u32 %v31524_v34, 17 (stack46)
        %vm33148_vm1 = vcmp.lt.u32.totalorder %v131493_v31, %v131413_v30 (stack43)
        %v31938_v20 = vshll.u32 %v31932_v10, 17 (stack45)
        %v31939_v25 = vshrl.u32 %v31932_v10, 15 (stack46)
        %v32337_v12 = vadd.s32 %v32333_v21, %v121564_v0 (stack40)
        %v32342_v21 = vxor.u32 %v32341_v44, %v32333_v21 (stack48)
        %v30778_v61 = vadd.f32 %v30774_v27, %v30711_v29 (stack53)
        %v31143_v8 = vadd.f32 1.0, %v31142_v26 (stack61)
        %v31531_v6 = vor.u32 %v31530_v52, %v31529_v40 (stack47)
        %v32747_v26 = vxor.u32 %v32746_v55, %v32742_v56 (stack48)
        %v31940_v53 = vor.u32 %v31939_v25, %v31938_v20 (stack47)
        %v32345_v10 = vadd.s32 %v32342_v21, %v121574_v2 (stack40)
        %v33162_v32 = vadd.s32 1, %v131482_v42 (stack40)
        %v131528_v60 = vadd.s32 %v157247_v60, %v157095_v13 (stack40)
        %v30782_v34 = vmul.f32 %v30778_v61, %v131477_v43 (stack54)
        %v31532_v44 = vxor.u32 %v31531_v6, %v31527_v7 (stack48)
        %v32750_v56 = vadd.s32 %v32747_v26, %v32742_v56 (stack40)
        %v32756_v55 = vshll.u32 %v32747_v26, 6 (stack45)
        %v31941_v29 = vxor.u32 %v31940_v53, %v31936_v22 (stack48)
        %v32349_v27 = vadd.s32 2, %v32345_v10 (stack40)
        %v32757_v40 = vshrl.u32 %v32747_v26, 26 (stack46)
        %v33166_v42 = vsel /*vm=*/%vm33153_vm0, /*on_true_vy=*/%v33162_v32, /*on_false_vx=*/%v131482_v42 (stack44)
        %v30786_v46 = vadd.f32 %v30782_v34, %v30707_v46 (stack53)
        %v31535_v7 = vadd.s32 %v31532_v44, %v31527_v7 (stack40)
        %v31537_v52 = vshll.u32 %v31532_v44, 26 (stack45)
        %v31538_v20 = vshrl.u32 %v31532_v44, 6 (stack46)
        %v31944_v22 = vadd.s32 %v31941_v29, %v31936_v22 (stack40)
        %v31946_v25 = vshll.u32 %v31941_v29, 29 (stack45)
        %v31947_v21 = vshrl.u32 %v31941_v29, 3 (stack46)
        %v32353_v12 = vadd.s32 %v32349_v27, %v32337_v12 (stack40)
        %v30790_v61 = vmul.f32 %v30786_v46, %v131477_v43 (stack54)
        %v31539_v6 = vor.u32 %v31538_v20, %v31537_v52 (stack47)
        %v32355_v26 = vshll.u32 %v32349_v27, 13 (stack45)
        %v32356_v53 = vshrl.u32 %v32349_v27, 19 (stack46)
        %v30703_v10 = vsel /*vm=*/%vm30690_vm13, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v31948_v32 = vor.u32 %v31947_v21, %v31946_v25 (stack47)
        %v32758_v34 = vor.u32 %v32757_v40, %v32756_v55 (stack47)
        %v33170_v44 = vadd.s32 1, %v33166_v42 (stack40)
        %v30794_v55 = vadd.f32 %v30790_v61, %v30703_v10 (stack53)
        %v31145_v29 = vand.u32 2147483647, %v131507_v11 (stack60)
        %v31540_v27 = vxor.u32 %v31539_v6, %v31535_v7 (stack48)
        %v32357_v40 = vor.u32 %v32356_v53, %v32355_v26 (stack47)
        %v31144_v11 = vmul.f32 %v31143_v8, %v131507_v11 (stack63)
        %v31949_v8 = vxor.u32 %v31948_v32, %v31944_v22 (stack48)
        %v32759_v46 = vxor.u32 %v32758_v34, %v32750_v56 (stack48)
        %v33174_v30 = vsel /*vm=*/%vm33148_vm1, /*on_true_vy=*/%v33170_v44, /*on_false_vx=*/%v33166_v42 (stack44)
        %v120694_v42 = vpop.eup %120693 (stack64)
        %v30798_v52 = vmul.f32 %v30794_v55, %v131477_v43 (stack54)
        %v31543_v7 = vadd.s32 %v31540_v27, %v31535_v7 (stack40)
        %v31549_v20 = vshll.u32 %v31540_v27, 6 (stack45)
        %v31550_v25 = vshrl.u32 %v31540_v27, 26 (stack46)
        %v31141_v21 = vmul.f32 0.6931472, %v120694_v42 (stack65)
        %v31952_v22 = vadd.s32 %v31949_v8, %v31944_v22 (stack40)
        %v31954_v61 = vshll.u32 %v31949_v8, 16 (stack45)
        %v31955_v6 = vshrl.u32 %v31949_v8, 16 (stack46)
        %v30802_v24 = vadd.f32 %v30798_v52, %v131501_v24 (stack53)
        %vm31146_vm2 = vcmp.lt.f32.partialorder %v31145_v29, 0.0004427343 (stack62)
        %v31551_v26 = vor.u32 %v31550_v25, %v31549_v20 (stack47)
        %v32358_v53 = vxor.u32 %v32357_v40, %v32353_v12 (stack48)
        %v31147_v10 = vsel /*vm=*/%vm31146_vm2, /*on_true_vy=*/%v31144_v11, /*on_false_vx=*/%v31141_v21 (stack66)
        %v31956_v32 = vor.u32 %v31955_v6, %v31954_v61 (stack47)
        %v32762_v34 = vadd.s32 %v32759_v46, %v121564_v0 (stack40)
        %v33183_v31 = vadd.s32 %v131493_v31, %v121569_v1 (stack40)
        %v30806_v43 = vmul.f32 %v30802_v24, %v131477_v43 (stack54)
        %v131550_v44 = vxor.u32 2147483648, %v31147_v10 (stack56)
        %v31552_v55 = vxor.u32 %v31551_v26, %v31543_v7 (stack48)
        %v32361_v12 = vadd.s32 %v32358_v53, %v32353_v12 (stack40)
        %vm131554_vm3 = vcmp.eq.f32.partialorder %v30663_v54, 1.0 (stack68)
        %v30671_v29 = vmul.f32 inf, %v131363_v41 (stack54)
        %v30695_v9 = vsel /*vm=*/%vm30690_vm13, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v31957_v27 = vxor.u32 %v31956_v32, %v31952_v22 (stack48)
        %v30810_v40 = vadd.f32 %v30806_v43, %v30695_v9 (stack53)
        %v31124_v11 = vand.u32 2147483647, %v131489_v23 (stack77)
        %120695 = vrsqrt.f32 %v131550_v44 (stack67)
        %v32754_v56 = vadd.s32 %v32750_v56, %v121569_v1 (stack40)
        %vm31151_vm4 = vcmp.lt.f32.partialorder %v131550_v44, 5.0 (stack68)
        %v31555_v8 = vadd.s32 %v31552_v55, %v121574_v2 (stack40)
        %v33189_v46 = vshll.u32 %v33183_v31, 13 (stack45)
        %v33190_v42 = vshrl.u32 %v33183_v31, 19 (stack46)
        %v30814_v41 = vmul.f32 %v30810_v40, %v131363_v41 (stack54)
        %v32363_v52 = vshll.u32 %v32358_v53, 15 (stack45)
        %v32364_v20 = vshrl.u32 %v32358_v53, 17 (stack46)
        %v32766_v25 = vadd.s32 1, %v32762_v34 (stack40)
        %v131569_v21 = vadd.f32 -2.5, %v131550_v44 (stack53)
        %v31547_v7 = vadd.s32 %v31543_v7, %v121564_v0 (stack40)
        %v31960_v22 = vadd.s32 %v31957_v27, %v31952_v22 (stack40)
        %v33179_v30 = vadd.s32 %v33174_v30, %v121574_v2 (stack40)
        %v30818_v61 = vsel /*vm=*/%vm131554_vm3, /*on_true_vy=*/%v30671_v29, /*on_false_vx=*/%v30814_v41 (stack44)
        %v131578_v6 = vsel /*vm=*/%vm31151_vm4, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v131583_v24 = vsel /*vm=*/%vm31151_vm4, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v131588_v26 = vsel /*vm=*/%vm31151_vm4, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v30822_v53 = vmul.f32 1.4140625, %v30818_v61 (stack54)
        %v131593_v10 = vsel /*vm=*/%vm31151_vm4, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v31559_v32 = vadd.s32 5, %v31555_v8 (stack40)
        %v31966_v34 = vshll.u32 %v31957_v27, 24 (stack45)
        %v31967_v43 = vshrl.u32 %v31957_v27, 8 (stack46)
        %v32365_v55 = vor.u32 %v32364_v20, %v32363_v52 (stack47)
        %v32770_v54 = vadd.s32 %v32766_v25, %v32754_v56 (stack40)
        %v32772_v29 = vshll.u32 %v32766_v25, 17 (stack45)
        %v30825_v9 = vpack.c.bf16 %v156663_v45, %v30822_v53 (stack81)
        %vm31196_vm5 = vcmp.eq.f32.partialorder %v131550_v44, inf (stack70)
        %v31561_v27 = vxor.u32 %v31559_v32, %v31547_v7 (stack48)
        %v32773_v40 = vshrl.u32 %v32766_v25, 15 (stack46)
        %v33187_v31 = vadd.s32 %v33183_v31, %v33179_v30 (stack40)
        %vm31198_vm6 = vcmp.eq.f32.partialorder %v131550_v44, 0.0 (stack71)
        %v31968_v56 = vor.u32 %v31967_v43, %v31966_v34 (stack47)
        %v32366_v8 = vxor.u32 %v32365_v55, %v32361_v12 (stack48)
        %v33191_v46 = vor.u32 %v33190_v42, %v33189_v46 (stack47)
        %119909 = vst [vmem:[%s123356_s30 + $0x20] sm:$0xf] /*vst_source=*/%v30825_v9 (stack83)
        %v31562_v42 = vand.u32.u8 255, %v31561_v27 (stack49)
        %v32774_v41 = vor.u32 %v32773_v40, %v32772_v29 (stack47)
        %vm33614_vm7 = vcmp.lt.u32.totalorder %v131528_v60, %v157095_v13 (stack43)
        %v33619_v50 = vadd.s32 %v157248_v50, %v157100_v14 (stack40)
        %v31969_v52 = vxor.u32 %v31968_v56, %v31960_v22 (stack48)
        %v32369_v12 = vadd.s32 %v32366_v8, %v32361_v12 (stack40)
        %v32371_v20 = vshll.u32 %v32366_v8, 26 (stack45)
        %v32372_v25 = vshrl.u32 %v32366_v8, 6 (stack46)
        %v31199_v7 = vand.u32 2147483648, %v131550_v44 (stack72)
        %v31563_v30 = vand.u32 65535, %v31562_v42 (stack50)
        %v32775_v61 = vxor.u32 %v32774_v41, %v32770_v54 (stack48)
        %v33192_v53 = vxor.u32 %v33191_v46, %v33187_v31 (stack48)
        %v31964_v22 = vadd.s32 %v31960_v22, %v121569_v1 (stack40)
        %v31972_v32 = vadd.s32 %v31969_v52, %v121564_v0 (stack40)
        %v32373_v34 = vor.u32 %v32372_v25, %v32371_v20 (stack47)
        %v33623_v43 = vadd.s32 1, %v33619_v50 (stack40)
        %v120696_v55 = vpop.eup %120695 (stack73)
        %v31564_v29 = vshrl.u32 %v31563_v30, 1 (stack51)
        %v32778_v54 = vadd.s32 %v32775_v61, %v32770_v54 (stack40)
        %v32780_v9 = vshll.u32 %v32775_v61, 29 (stack45)
        %v32781_v27 = vshrl.u32 %v32775_v61, 3 (stack46)
        %v31195_v40 = vmul.f32 %v120696_v55, %v131550_v44 (stack74)
        %v31976_v56 = vadd.s32 4, %v31972_v32 (stack40)
        %v32374_v8 = vxor.u32 %v32373_v34, %v32369_v12 (stack48)
        %v33195_v31 = vadd.s32 %v33192_v53, %v33187_v31 (stack40)
        %v31565_v46 = vor.u32 16256, %v31564_v29 (stack47)
        %v32782_v42 = vor.u32 %v32781_v27, %v32780_v9 (stack47)
        %v33197_v41 = vshll.u32 %v33192_v53, 15 (stack45)
        %v33198_v52 = vshrl.u32 %v33192_v53, 17 (stack46)
        %v31197_v20 = vsel /*vm=*/%vm31196_vm5, /*on_true_vy=*/%v131550_v44, /*on_false_vx=*/%v31195_v40 (stack75)
        %v31980_v25 = vadd.s32 %v31976_v56, %v31964_v22 (stack40)
        %v31982_v30 = vshll.u32 %v31976_v56, 13 (stack45)
        %v31983_v61 = vshrl.u32 %v31976_v56, 19 (stack46)
        %v31200_v7 = vsel /*vm=*/%vm31198_vm6, /*on_true_vy=*/%v31199_v7, /*on_false_vx=*/%v31197_v20 (stack76)
        %v31566_v53 = vand.u32.u16 65535, %v31565_v46 (stack52)
        %v32377_v12 = vadd.s32 %v32374_v8, %v32369_v12 (stack40)
        %v32383_v22 = vshll.u32 %v32374_v8, 6 (stack45)
        %v31203_v32 = vadd.f32 -3.0, %v31200_v7 (stack53)
        %v31984_v34 = vor.u32 %v31983_v61, %v31982_v30 (stack47)
        %v32384_v55 = vshrl.u32 %v32374_v8, 26 (stack46)
        %v32783_v29 = vxor.u32 %v32782_v42, %v32778_v54 (stack48)
        %v119912_v9 = vadd.low.f32.bf16 -1.0, %v31566_v53 (stack53)
        %v33199_v27 = vor.u32 %v33198_v52, %v33197_v41 (stack47)
        %v131614_v40 = vadd.s32 %v131528_v60, %v122657_v58 (stack40)
        %v131619_v50 = vsel /*vm=*/%vm33614_vm7, /*on_true_vy=*/%v33623_v43, /*on_false_vx=*/%v33619_v50 (stack44)
        %v131624_v21 = vsel /*vm=*/%vm31151_vm4, /*on_true_vy=*/%v131569_v21, /*on_false_vx=*/%v31203_v32 (stack44)
        %v31985_v43 = vxor.u32 %v31984_v34, %v31980_v25 (stack48)
        %v32385_v56 = vor.u32 %v32384_v55, %v32383_v22 (stack47)
        %v32786_v54 = vadd.s32 %v32783_v29, %v32778_v54 (stack40)
        %v31211_v10 = vmul.f32 %v131624_v21, %v131593_v10 (stack54)
        %v31575_v8 = vmul.f32 2.0, %v119912_v9 (stack54)
        %v32788_v46 = vshll.u32 %v32783_v29, 16 (stack45)
        %v32789_v42 = vshrl.u32 %v32783_v29, 16 (stack46)
        %v31988_v41 = vadd.s32 %v31985_v43, %v31980_v25 (stack40)
        %v31990_v52 = vshll.u32 %v31985_v43, 15 (stack45)
        %v31991_v20 = vshrl.u32 %v31985_v43, 17 (stack46)
        %v32386_v25 = vxor.u32 %v32385_v56, %v32377_v12 (stack48)
        %v31215_v26 = vadd.f32 %v31211_v10, %v131588_v26 (stack53)
        %v31579_v30 = vadd.f32 -0.99609375, %v31575_v8 (stack53)
        %v32790_v61 = vor.u32 %v32789_v42, %v32788_v46 (stack47)
        %v33200_v7 = vxor.u32 %v33199_v27, %v33195_v31 (stack48)
        %v31172_v53 = vsel /*vm=*/%vm31151_vm4, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v31176_v22 = vsel /*vm=*/%vm31151_vm4, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v31992_v32 = vor.u32 %v31991_v20, %v31990_v52 (stack47)
        %v32389_v34 = vadd.s32 %v32386_v25, %v121569_v1 (stack40)
        %v31219_v55 = vmul.f32 %v31215_v26, %v131624_v21 (stack54)
        %v131637_v29 = vmax.f32 %v31579_v30, -0.99609375 (stack55)
        %v32791_v9 = vxor.u32 %v32790_v61, %v32786_v54 (stack48)
        %v33203_v31 = vadd.s32 %v33200_v7, %v33195_v31 (stack40)
        %v31180_v27 = vsel /*vm=*/%vm31151_vm4, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v31993_v43 = vxor.u32 %v31992_v32, %v31988_v41 (stack48)
        %v32381_v12 = vadd.s32 %v32377_v12, %v121574_v2 (stack40)
        %v32393_v56 = vadd.s32 3, %v32389_v34 (stack40)
        %v31223_v10 = vadd.f32 %v31219_v55, %v31180_v27 (stack53)
        %v31595_v8 = vxor.u32 2147483648, %v131637_v29 (stack56)
        %vm33609_vm8 = vcmp.lt.u32.totalorder %v131614_v40, %v131528_v60 (stack43)
        %v33644_v46 = vadd.s32 %v131614_v40, %v121569_v1 (stack40)
        %v31996_v42 = vadd.s32 %v31993_v43, %v31988_v41 (stack40)
        %v31998_v41 = vshll.u32 %v31993_v43, 26 (stack45)
        %v31999_v52 = vshrl.u32 %v31993_v43, 6 (stack46)
        %v32397_v20 = vadd.s32 %v32393_v56, %v32381_v12 (stack40)
        %v31227_v25 = vmul.f32 %v31223_v10, %v131624_v21 (stack54)
        %v131650_v26 = vmul.f32 %v31595_v8, %v131637_v29 (stack54)
        %v32399_v30 = vshll.u32 %v32393_v56, 17 (stack45)
        %v33631_v61 = vadd.s32 1, %v131619_v50 (stack40)
        %v32000_v32 = vor.u32 %v31999_v52, %v31998_v41 (stack47)
        %v32400_v34 = vshrl.u32 %v32393_v56, 15 (stack46)
        %v32794_v54 = vadd.s32 %v32791_v9, %v32786_v54 (stack40)
        %v33205_v55 = vshll.u32 %v33200_v7, 26 (stack45)
        %v31231_v22 = vadd.f32 %v31227_v25, %v31176_v22 (stack53)
        %v31600_v27 = vadd.f32 1.0, %v131650_v26 (stack57)
        %v32800_v43 = vshll.u32 %v32791_v9, 24 (stack45)
        %v33206_v7 = vshrl.u32 %v33200_v7, 6 (stack46)
        %v31603_v12 = vmul.f32 -0.5, %v131650_v26 (stack59)
        %v32001_v56 = vxor.u32 %v32000_v32, %v31996_v42 (stack48)
        %v32401_v10 = vor.u32 %v32400_v34, %v32399_v30 (stack47)
        %v32801_v9 = vshrl.u32 %v32791_v9, 8 (stack46)
        %v31235_v8 = vmul.f32 %v31231_v22, %v131624_v21 (stack54)
        %120697 = vlog2.f32 %v31600_v27 (stack58)
        %v31606_v41 = vand.u32 2147483647, %v131650_v26 (stack60)
        %v33650_v52 = vshll.u32 %v33644_v46, 13 (stack45)
        %v32004_v42 = vadd.s32 %v32001_v56, %v31996_v42 (stack40)
        %v32010_v25 = vshll.u32 %v32001_v56, 6 (stack45)
        %v32011_v30 = vshrl.u32 %v32001_v56, 26 (stack46)
        %v32402_v32 = vxor.u32 %v32401_v10, %v32397_v20 (stack48)
        %v31239_v53 = vadd.f32 %v31235_v8, %v31172_v53 (stack53)
        %v32798_v34 = vadd.s32 %v32794_v54, %v121564_v0 (stack40)
        %v32802_v22 = vor.u32 %v32801_v9, %v32800_v43 (stack47)
        %v33207_v55 = vor.u32 %v33206_v7, %v33205_v55 (stack47)
        %v31604_v27 = vadd.f32 1.0, %v31603_v12 (stack61)
        %v32012_v43 = vor.u32 %v32011_v30, %v32010_v25 (stack47)
        %v32405_v20 = vadd.s32 %v32402_v32, %v32397_v20 (stack40)
        %v32407_v7 = vshll.u32 %v32402_v32, 29 (stack45)
        %v31243_v12 = vmul.f32 %v31239_v53, %v131624_v21 (stack54)
        %v32408_v56 = vshrl.u32 %v32402_v32, 3 (stack46)
        %v32803_v54 = vxor.u32 %v32802_v22, %v32794_v54 (stack48)
        %v33208_v10 = vxor.u32 %v33207_v55, %v33203_v31 (stack48)
        %v32013_v9 = vxor.u32 %v32012_v43, %v32004_v42 (stack48)
        %v33635_v60 = vsel /*vm=*/%vm33609_vm8, /*on_true_vy=*/%v33631_v61, /*on_false_vx=*/%v131619_v50 (stack44)
        %v33651_v40 = vshrl.u32 %v33644_v46, 19 (stack46)
        %v157269_v50 = vld [vmem:[#allocation129_spill] sm:$0xff] (stack84)
        %v131665_v61 = vadd.s32 %v157269_v50, %v122651_v47 (stack40)
        %v31247_v24 = vadd.f32 %v31243_v12, %v131583_v24 (stack53)
        %v32409_v8 = vor.u32 %v32408_v56, %v32407_v7 (stack47)
        %v32806_v25 = vadd.s32 %v32803_v54, %v121574_v2 (stack40)
        %v33211_v31 = vadd.s32 %v33208_v10, %v33203_v31 (stack40)
        %v32016_v30 = vadd.s32 %v32013_v9, %v121574_v2 (stack40)
        %v33217_v32 = vshll.u32 %v33208_v10, 6 (stack45)
        %v33218_v53 = vshrl.u32 %v33208_v10, 26 (stack46)
        %v33640_v22 = vadd.s32 %v33635_v60, %v121574_v2 (stack40)
        %v31251_v55 = vmul.f32 %v31247_v24, %v131624_v21 (stack54)
        %v32008_v42 = vadd.s32 %v32004_v42, %v121564_v0 (stack40)
        %v32410_v43 = vxor.u32 %v32409_v8, %v32405_v20 (stack48)
        %v32810_v7 = vadd.s32 2, %v32806_v25 (stack40)
        %v32020_v12 = vadd.s32 5, %v32016_v30 (stack40)
        %v33219_v56 = vor.u32 %v33218_v53, %v33217_v32 (stack47)
        %v33648_v46 = vadd.s32 %v33644_v46, %v33640_v22 (stack40)
        %v33652_v52 = vor.u32 %v33651_v40, %v33650_v52 (stack47)
        %v31255_v6 = vadd.f32 %v31251_v55, %v131578_v6 (stack53)
        %v32413_v20 = vadd.s32 %v32410_v43, %v32405_v20 (stack40)
        %v32415_v54 = vshll.u32 %v32410_v43, 16 (stack45)
        %v32416_v10 = vshrl.u32 %v32410_v43, 16 (stack46)
        %v32022_v9 = vxor.u32 %v32020_v12, %v32008_v42 (stack48)
        %v32814_v34 = vadd.s32 %v32810_v7, %v32798_v34 (stack40)
        %v32816_v60 = vshll.u32 %v32810_v7, 13 (stack45)
        %v32817_v40 = vshrl.u32 %v32810_v7, 19 (stack46)
        %v31259_v24 = vmul.f32 %v31255_v6, %v131624_v21 (stack54)
        %v32417_v8 = vor.u32 %v32416_v10, %v32415_v54 (stack47)
        %v33220_v25 = vxor.u32 %v33219_v56, %v33211_v31 (stack48)
        %v33653_v30 = vxor.u32 %v33652_v52, %v33648_v46 (stack48)
        %v120698_v32 = vpop.eup %120697 (stack64)
        %v31160_v53 = vsel /*vm=*/%vm31151_vm4, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v32023_v22 = vand.u32.u8 255, %v32022_v9 (stack49)
        %v32818_v55 = vor.u32 %v32817_v40, %v32816_v60 (stack47)
        %vm34109_vm9 = vcmp.lt.u32.totalorder %v131665_v61, %v122651_v47 (stack43)
        %v31263_v42 = vadd.f32 %v31259_v24, %v31160_v53 (stack53)
        %v31602_v43 = vmul.f32 0.6931472, %v120698_v32 (stack65)
        %v31605_v26 = vmul.f32 %v31604_v27, %v131650_v26 (stack63)
        %v32418_v27 = vxor.u32 %v32417_v8, %v32413_v20 (stack48)
        %vm31607_vm10 = vcmp.lt.f32.partialorder %v31606_v41, 0.0004427343 (stack62)
        %v32024_v41 = vand.u32 65535, %v32023_v22 (stack50)
        %v32819_v7 = vxor.u32 %v32818_v55, %v32814_v34 (stack48)
        %v33656_v12 = vadd.s32 %v33653_v30, %v33648_v46 (stack40)
        %v31156_v44 = vsel /*vm=*/%vm31151_vm4, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v31267_v21 = vmul.f32 %v31263_v42, %v131624_v21 (stack54)
        %v31608_v56 = vsel /*vm=*/%vm31607_vm10, /*on_true_vy=*/%v31605_v26, /*on_false_vx=*/%v31602_v43 (stack66)
        %v32421_v46 = vadd.s32 %v32418_v27, %v32413_v20 (stack40)
        %v131685_v52 = vxor.u32 2147483648, %v31608_v56 (stack56)
        %v32427_v6 = vshll.u32 %v32418_v27, 24 (stack45)
        %v32428_v20 = vshrl.u32 %v32418_v27, 8 (stack46)
        %v32822_v54 = vadd.s32 %v32819_v7, %v32814_v34 (stack40)
        %v31271_v10 = vadd.f32 %v31267_v21, %v31156_v44 (stack53)
        %v31132_v9 = vmul.f32 inf, %v131489_v23 (stack54)
        %120699 = vrsqrt.f32 %v131685_v52 (stack67)
        %v32025_v34 = vshrl.u32 %v32024_v41, 1 (stack51)
        %v33223_v60 = vadd.s32 %v33220_v25, %v121564_v0 (stack40)
        %v31275_v40 = vmul.f32 %v31271_v10, %v131489_v23 (stack54)
        %vm31612_vm11 = vcmp.lt.f32.partialorder %v131685_v52, 5.0 (stack68)
        %v32824_v24 = vshll.u32 %v32819_v7, 15 (stack45)
        %v32825_v8 = vshrl.u32 %v32819_v7, 17 (stack46)
        %vm31127_vm12 = vcmp.eq.f32.partialorder %v31124_v11, 1.0 (stack68)
        %v32429_v23 = vor.u32 %v32428_v20, %v32427_v6 (stack47)
        %v33215_v11 = vadd.s32 %v33211_v31, %v121569_v1 (stack40)
        %v31279_v31 = vsel /*vm=*/%vm31127_vm12, /*on_true_vy=*/%v31132_v9, /*on_false_vx=*/%v31275_v40 (stack44)
        %v32425_v25 = vadd.s32 %v32421_v46, %v121569_v1 (stack40)
        %v33658_v32 = vshll.u32 %v33653_v30, 15 (stack45)
        %v131698_v53 = vadd.s32 %v131665_v61, %v122657_v58 (stack40)
        %v31283_v22 = vmul.f32 1.4140625, %v31279_v31 (stack54)
        %v131703_v55 = vsel /*vm=*/%vm31612_vm11, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v131706_v42 = vadd.f32 -2.5, %v131685_v52 (stack53)
        %v32026_v43 = vor.u32 16256, %v32025_v34 (stack47)
        %v32430_v26 = vxor.u32 %v32429_v23, %v32421_v46 (stack48)
        %v32826_v27 = vor.u32 %v32825_v8, %v32824_v24 (stack47)
        %v33227_v41 = vadd.s32 1, %v33223_v60 (stack40)
        %v33659_v30 = vshrl.u32 %v33653_v30, 17 (stack46)
        %v31286_v7 = vpack.c.bf16 %v156663_v45, %v31283_v22 (stack81)
        %v131712_v44 = vsel /*vm=*/%vm31612_vm11, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v32027_v21 = vand.u32.u16 65535, %v32026_v43 (stack52)
        %v157270_v56 = vld [vmem:[#allocation84_spill] sm:$0xff] (stack84)
        %v34114_v46 = vadd.s32 %v157270_v56, %v157068_v28 (stack40)
        %vm31657_vm13 = vcmp.eq.f32.partialorder %v131685_v52, inf (stack70)
        %v32433_v6 = vadd.s32 %v32430_v26, %v121564_v0 (stack40)
        %v32827_v20 = vxor.u32 %v32826_v27, %v32822_v54 (stack48)
        %v33231_v10 = vadd.s32 %v33227_v41, %v33215_v11 (stack40)
        %v33233_v9 = vshll.u32 %v33227_v41, 17 (stack45)
        %119911 = vst [vmem:[%s123356_s30 + $0xa0] sm:$0xf] /*vst_source=*/%v31286_v7 (stack83)
        %v119914_v34 = vadd.low.f32.bf16 -1.0, %v32027_v21 (stack53)
        %v33234_v60 = vshrl.u32 %v33227_v41, 15 (stack46)
        %v33660_v40 = vor.u32 %v33659_v30, %v33658_v32 (stack47)
        %v34118_v24 = vadd.s32 1, %v34114_v46 (stack40)
        %v32437_v8 = vadd.s32 4, %v32433_v6 (stack40)
        %v32830_v54 = vadd.s32 %v32827_v20, %v32822_v54 (stack40)
        %v32832_v23 = vshll.u32 %v32827_v20, 26 (stack45)
        %v32833_v11 = vshrl.u32 %v32827_v20, 6 (stack46)
        %v32036_v31 = vmul.f32 2.0, %v119914_v34 (stack54)
        %v33235_v32 = vor.u32 %v33234_v60, %v33233_v9 (stack47)
        %v33661_v22 = vxor.u32 %v33660_v40, %v33656_v12 (stack48)
        %v131722_v43 = vsel /*vm=*/%vm34109_vm9, /*on_true_vy=*/%v34118_v24, /*on_false_vx=*/%v34114_v46 (stack44)
        %v32441_v25 = vadd.s32 %v32437_v8, %v32425_v25 (stack40)
        %v32443_v26 = vshll.u32 %v32437_v8, 13 (stack45)
        %v32444_v27 = vshrl.u32 %v32437_v8, 19 (stack46)
        %v32834_v41 = vor.u32 %v32833_v11, %v32832_v23 (stack47)
        %v31641_v30 = vsel /*vm=*/%vm31612_vm11, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v32040_v7 = vadd.f32 -0.99609375, %v32036_v31 (stack53)
        %v33236_v21 = vxor.u32 %v33235_v32, %v33231_v10 (stack48)
        %v33664_v12 = vadd.s32 %v33661_v22, %v33656_v12 (stack40)
        %v120700_v46 = vpop.eup %120699 (stack73)
        %v31660_v6 = vand.u32 2147483648, %v131685_v52 (stack72)
        %v32445_v20 = vor.u32 %v32444_v27, %v32443_v26 (stack47)
        %v32835_v9 = vxor.u32 %v32834_v41, %v32830_v54 (stack48)
        %v33666_v34 = vshll.u32 %v33661_v22, 26 (stack45)
        %v31656_v60 = vmul.f32 %v120700_v46, %v131685_v52 (stack74)
        %v131729_v40 = vmax.f32 %v32040_v7, -0.99609375 (stack55)
        %v33239_v10 = vadd.s32 %v33236_v21, %v33231_v10 (stack40)
        %v33667_v24 = vshrl.u32 %v33661_v22, 6 (stack46)
        %v32446_v8 = vxor.u32 %v32445_v20, %v32441_v25 (stack48)
        %v32838_v54 = vadd.s32 %v32835_v9, %v32830_v54 (stack40)
        %v32844_v23 = vshll.u32 %v32835_v9, 6 (stack45)
        %v32845_v11 = vshrl.u32 %v32835_v9, 26 (stack46)
        %v31658_v31 = vsel /*vm=*/%vm31657_vm13, /*on_true_vy=*/%v131685_v52, /*on_false_vx=*/%v31656_v60 (stack75)
        %vm31659_vm14 = vcmp.eq.f32.partialorder %v131685_v52, 0.0 (stack71)
        %v32056_v32 = vxor.u32 2147483648, %v131729_v40 (stack56)
        %v33241_v22 = vshll.u32 %v33236_v21, 29 (stack45)
        %v31661_v26 = vsel /*vm=*/%vm31659_vm14, /*on_true_vy=*/%v31660_v6, /*on_false_vx=*/%v31658_v31 (stack76)
        %v32449_v25 = vadd.s32 %v32446_v8, %v32441_v25 (stack40)
        %v32451_v27 = vshll.u32 %v32446_v8, 15 (stack45)
        %v32452_v41 = vshrl.u32 %v32446_v8, 17 (stack46)
        %v31645_v7 = vsel /*vm=*/%vm31612_vm11, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v31649_v46 = vsel /*vm=*/%vm31612_vm11, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v31664_v6 = vadd.f32 -3.0, %v31661_v26 (stack53)
        %v32059_v20 = vmul.f32 %v32056_v32, %v131729_v40 (stack54)
        %v32453_v9 = vor.u32 %v32452_v41, %v32451_v27 (stack47)
        %v32846_v60 = vor.u32 %v32845_v11, %v32844_v23 (stack47)
        %v33242_v21 = vshrl.u32 %v33236_v21, 3 (stack46)
        %v33668_v34 = vor.u32 %v33667_v24, %v33666_v34 (stack47)
        %v131746_v42 = vsel /*vm=*/%vm31612_vm11, /*on_true_vy=*/%v131706_v42, /*on_false_vx=*/%v31664_v6 (stack44)
        %v32061_v24 = vadd.f32 1.0, %v32059_v20 (stack57)
        %vm34104_vm15 = vcmp.lt.u32.totalorder %v131698_v53, %v131665_v61 (stack43)
        %v34126_v8 = vadd.s32 1, %v131722_v43 (stack40)
        %v31672_v23 = vmul.f32 %v131746_v42, %v31649_v46 (stack54)
        %v32454_v11 = vxor.u32 %v32453_v9, %v32449_v25 (stack48)
        %v32847_v31 = vxor.u32 %v32846_v60, %v32838_v54 (stack48)
        %v33243_v32 = vor.u32 %v33242_v21, %v33241_v22 (stack47)
        %120701 = vlog2.f32 %v32061_v24 (stack58)
        %v32064_v22 = vmul.f32 -0.5, %v32059_v20 (stack59)
        %v32842_v54 = vadd.s32 %v32838_v54, %v121574_v2 (stack40)
        %v33669_v26 = vxor.u32 %v33668_v34, %v33664_v12 (stack48)
        %v31676_v27 = vadd.f32 %v31672_v23, %v31645_v7 (stack53)
        %v32457_v25 = vadd.s32 %v32454_v11, %v32449_v25 (stack40)
        %v32459_v41 = vshll.u32 %v32454_v11, 26 (stack45)
        %v32460_v7 = vshrl.u32 %v32454_v11, 6 (stack46)
        %v32067_v46 = vand.u32 2147483647, %v32059_v20 (stack60)
        %v32850_v6 = vadd.s32 %v32847_v31, %v121569_v1 (stack40)
        %v33244_v9 = vxor.u32 %v33243_v32, %v33239_v10 (stack48)
        %v33672_v12 = vadd.s32 %v33669_v26, %v33664_v12 (stack40)
        %v31680_v60 = vmul.f32 %v31676_v27, %v131746_v42 (stack54)
        %v32461_v21 = vor.u32 %v32460_v7, %v32459_v41 (stack47)
        %v33678_v34 = vshll.u32 %v33669_v26, 6 (stack45)
        %v33679_v24 = vshrl.u32 %v33669_v26, 26 (stack46)
        %v32854_v23 = vadd.s32 3, %v32850_v6 (stack40)
        %v33247_v10 = vadd.s32 %v33244_v9, %v33239_v10 (stack40)
        %v33249_v11 = vshll.u32 %v33244_v9, 16 (stack45)
        %v33250_v31 = vshrl.u32 %v33244_v9, 16 (stack46)
        %v31684_v30 = vadd.f32 %v31680_v60, %v31641_v30 (stack53)
        %v32065_v32 = vadd.f32 1.0, %v32064_v22 (stack61)
        %v32462_v22 = vxor.u32 %v32461_v21, %v32457_v25 (stack48)
        %v33680_v26 = vor.u32 %v33679_v24, %v33678_v34 (stack47)
        %v32858_v54 = vadd.s32 %v32854_v23, %v32842_v54 (stack40)
        %v32860_v27 = vshll.u32 %v32854_v23, 17 (stack45)
        %v32861_v41 = vshrl.u32 %v32854_v23, 15 (stack46)
        %v33251_v7 = vor.u32 %v33250_v31, %v33249_v11 (stack47)
        %v31688_v6 = vmul.f32 %v31684_v30, %v131746_v42 (stack54)
        %vm131756_vm0 = vcmp.lt.f32.partialorder %v32067_v46, 0.0004427343 (stack62)
        %v32465_v25 = vadd.s32 %v32462_v22, %v32457_v25 (stack40)
        %v32471_v9 = vshll.u32 %v32462_v22, 6 (stack45)
        %v32472_v60 = vshrl.u32 %v32462_v22, 26 (stack46)
        %v32862_v21 = vor.u32 %v32861_v41, %v32860_v27 (stack47)
        %v33252_v34 = vxor.u32 %v33251_v7, %v33247_v10 (stack48)
        %v33681_v24 = vxor.u32 %v33680_v26, %v33672_v12 (stack48)
        %v34130_v61 = vsel /*vm=*/%vm34104_vm15, /*on_true_vy=*/%v34126_v8, /*on_false_vx=*/%v131722_v43 (stack44)
        %v31692_v44 = vadd.f32 %v31688_v6, %v131712_v44 (stack53)
        %v32066_v43 = vmul.f32 %v32065_v32, %v32059_v20 (stack63)
        %v32473_v20 = vor.u32 %v32472_v60, %v32471_v9 (stack47)
        %v34135_v8 = vadd.s32 %v34130_v61, %v121574_v2 (stack40)
        %v32863_v23 = vxor.u32 %v32862_v21, %v32858_v54 (stack48)
        %v33255_v10 = vadd.s32 %v33252_v34, %v33247_v10 (stack40)
        %v33261_v11 = vshll.u32 %v33252_v34, 24 (stack45)
        %v33262_v31 = vshrl.u32 %v33252_v34, 8 (stack46)
        %v31696_v30 = vmul.f32 %v31692_v44, %v131746_v42 (stack54)
        %v32474_v32 = vxor.u32 %v32473_v20, %v32465_v25 (stack48)
        %v33676_v12 = vadd.s32 %v33672_v12, %v121569_v1 (stack40)
        %v33684_v22 = vadd.s32 %v33681_v24, %v121564_v0 (stack40)
        %v32866_v26 = vadd.s32 %v32863_v23, %v32858_v54 (stack40)
        %v32868_v54 = vshll.u32 %v32863_v23, 29 (stack45)
        %v32869_v27 = vshrl.u32 %v32863_v23, 3 (stack46)
        %v131771_v53 = vadd.s32 %v131698_v53, %v121569_v1 (stack40)
        %v120702_v41 = vpop.eup %120701 (stack64)
        %v31700_v55 = vadd.f32 %v31696_v30, %v131703_v55 (stack53)
        %v32477_v7 = vadd.s32 %v32474_v32, %v121574_v2 (stack40)
        %v33263_v6 = vor.u32 %v33262_v31, %v33261_v11 (stack47)
        %v33688_v9 = vadd.s32 1, %v33684_v22 (stack40)
        %v32063_v60 = vmul.f32 0.6931472, %v120702_v41 (stack65)
        %v32469_v25 = vadd.s32 %v32465_v25, %v121564_v0 (stack40)
        %v32870_v21 = vor.u32 %v32869_v27, %v32868_v54 (stack47)
        %v131777_v34 = vadd.s32 %v131771_v53, %v34135_v8 (stack40)
        %v31704_v24 = vmul.f32 %v31700_v55, %v131746_v42 (stack54)
        %v32481_v61 = vadd.s32 5, %v32477_v7 (stack40)
        %v33264_v44 = vxor.u32 %v33263_v6, %v33255_v10 (stack48)
        %v33692_v20 = vadd.s32 %v33688_v9, %v33676_v12 (stack40)
        %v31629_v8 = vsel /*vm=*/%vm31612_vm11, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v32069_v46 = vsel /*vm=*/%vm131756_vm0, /*on_true_vy=*/%v32066_v43, /*on_false_vx=*/%v32063_v60 (stack66)
        %v32871_v43 = vxor.u32 %v32870_v21, %v32866_v26 (stack48)
        %v33694_v23 = vshll.u32 %v33688_v9, 17 (stack45)
        %v31708_v11 = vadd.f32 %v31704_v24, %v31629_v8 (stack53)
        %v131785_v31 = vxor.u32 2147483648, %v32069_v46 (stack56)
        %v32483_v30 = vxor.u32 %v32481_v61, %v32469_v25 (stack48)
        %v33695_v32 = vshrl.u32 %v33688_v9, 15 (stack46)
        %v32874_v12 = vadd.s32 %v32871_v43, %v32866_v26 (stack40)
        %v32876_v22 = vshll.u32 %v32871_v43, 16 (stack45)
        %v32877_v26 = vshrl.u32 %v32871_v43, 16 (stack46)
        %v31585_v54 = vand.u32 2147483647, %v131637_v29 (stack77)
        %v31712_v27 = vmul.f32 %v31708_v11, %v131746_v42 (stack54)
        %120703 = vrsqrt.f32 %v131785_v31 (stack67)
        %v31593_v41 = vmul.f32 inf, %v131637_v29 (stack54)
        %v31625_v55 = vsel /*vm=*/%vm31612_vm11, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %vm32073_vm1 = vcmp.lt.f32.partialorder %v131785_v31, 5.0 (stack68)
        %v32878_v7 = vor.u32 %v32877_v26, %v32876_v22 (stack47)
        %v31617_v6 = vsel /*vm=*/%vm31612_vm11, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v31716_v9 = vadd.f32 %v31712_v27, %v31625_v55 (stack53)
        %v33267_v60 = vadd.s32 %v33264_v44, %v121574_v2 (stack40)
        %v33696_v25 = vor.u32 %v33695_v32, %v33694_v23 (stack47)
        %v31621_v52 = vsel /*vm=*/%vm31612_vm11, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v32046_v21 = vand.u32 2147483647, %v131729_v40 (stack77)
        %v32879_v24 = vxor.u32 %v32878_v7, %v32874_v12 (stack48)
        %v33259_v10 = vadd.s32 %v33255_v10, %v121564_v0 (stack40)
        %v31720_v61 = vmul.f32 %v31716_v9, %v131746_v42 (stack54)
        %v131808_v44 = vsel /*vm=*/%vm32073_vm1, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v131811_v8 = vadd.f32 -2.5, %v131785_v31 (stack53)
        %v34145_v46 = vshll.u32 %v131771_v53, 13 (stack45)
        %vm131814_vm2 = vcmp.eq.f32.partialorder %v31585_v54, 1.0 (stack68)
        %v32484_v23 = vand.u32.u8 255, %v32483_v30 (stack49)
        %v32882_v11 = vadd.s32 %v32879_v24, %v32874_v12 (stack40)
        %v32888_v30 = vshll.u32 %v32879_v24, 24 (stack45)
        %v32889_v32 = vshrl.u32 %v32879_v24, 8 (stack46)
        %v31724_v12 = vadd.f32 %v31720_v61, %v31621_v52 (stack53)
        %v33271_v22 = vadd.s32 2, %v33267_v60 (stack40)
        %v33697_v26 = vxor.u32 %v33696_v25, %v33692_v20 (stack48)
        %v34146_v53 = vshrl.u32 %v131771_v53, 19 (stack46)
        %vm32118_vm3 = vcmp.eq.f32.partialorder %v131785_v31, inf (stack70)
        %v32485_v54 = vand.u32 65535, %v32484_v23 (stack50)
        %v32890_v27 = vor.u32 %v32889_v32, %v32888_v30 (stack47)
        %v131822_v55 = vadd.s32 %v157269_v50, %v157070_v38 (stack40)
        %v31728_v42 = vmul.f32 %v31724_v12, %v131746_v42 (stack54)
        %vm32120_vm4 = vcmp.eq.f32.partialorder %v131785_v31, 0.0 (stack71)
        %v33275_v7 = vadd.s32 %v33271_v22, %v33259_v10 (stack40)
        %v33277_v9 = vshll.u32 %v33271_v22, 13 (stack45)
        %v33278_v60 = vshrl.u32 %v33271_v22, 19 (stack46)
        %v32486_v25 = vshrl.u32 %v32485_v54, 1 (stack51)
        %v32891_v52 = vxor.u32 %v32890_v27, %v32882_v11 (stack48)
        %v33700_v20 = vadd.s32 %v33697_v26, %v33692_v20 (stack40)
        %v33702_v24 = vshll.u32 %v33697_v26, 29 (stack45)
        %v31732_v6 = vadd.f32 %v31728_v42, %v31617_v6 (stack53)
        %v33279_v10 = vor.u32 %v33278_v60, %v33277_v9 (stack47)
        %v33703_v61 = vshrl.u32 %v33697_v26, 3 (stack46)
        %v34147_v46 = vor.u32 %v34146_v53, %v34145_v46 (stack47)
        %v32121_v23 = vand.u32 2147483648, %v131785_v31 (stack72)
        %v32487_v30 = vor.u32 16256, %v32486_v25 (stack47)
        %v32894_v32 = vadd.s32 %v32891_v52, %v121564_v0 (stack40)
        %vm34570_vm5 = vcmp.lt.u32.totalorder %v131822_v55, %v157070_v38 (stack43)
        %v31736_v29 = vmul.f32 %v31732_v6, %v131637_v29 (stack54)
        %v33280_v12 = vxor.u32 %v33279_v10, %v33275_v7 (stack48)
        %v33704_v22 = vor.u32 %v33703_v61, %v33702_v24 (stack47)
        %v34148_v26 = vxor.u32 %v34147_v46, %v131777_v34 (stack48)
        %v120704_v53 = vpop.eup %120703 (stack73)
        %v32488_v54 = vand.u32.u16 65535, %v32487_v30 (stack52)
        %v32886_v11 = vadd.s32 %v32882_v11, %v121569_v1 (stack40)
        %v32898_v27 = vadd.s32 4, %v32894_v32 (stack40)
        %v131835_v42 = vadd.s32 %v157270_v56, %v157076_v35 (stack40)
        %v31740_v41 = vsel /*vm=*/%vm131814_vm2, /*on_true_vy=*/%v31593_v41, /*on_false_vx=*/%v31736_v29 (stack44)
        %v32117_v43 = vmul.f32 %v120704_v53, %v131785_v31 (stack74)
        %v33283_v7 = vadd.s32 %v33280_v12, %v33275_v7 (stack40)
        %v33285_v9 = vshll.u32 %v33280_v12, 15 (stack45)
        %v31744_v60 = vmul.f32 1.4140625, %v31740_v41 (stack54)
        %v119916_v25 = vadd.low.f32.bf16 -1.0, %v32488_v54 (stack53)
        %v32902_v52 = vadd.s32 %v32898_v27, %v32886_v11 (stack40)
        %v32904_v24 = vshll.u32 %v32898_v27, 13 (stack45)
        %v32119_v6 = vsel /*vm=*/%vm32118_vm3, /*on_true_vy=*/%v131785_v31, /*on_false_vx=*/%v32117_v43 (stack75)
        %v32905_v10 = vshrl.u32 %v32898_v27, 19 (stack46)
        %v33286_v61 = vshrl.u32 %v33280_v12, 17 (stack46)
        %v33705_v46 = vxor.u32 %v33704_v22, %v33700_v20 (stack48)
        %v31747_v30 = vpack.c.bf16 %v156663_v45, %v31744_v60 (stack81)
        %v32122_v23 = vsel /*vm=*/%vm32120_vm4, /*on_true_vy=*/%v32121_v23, /*on_false_vx=*/%v32119_v6 (stack76)
        %v32497_v32 = vmul.f32 2.0, %v119916_v25 (stack54)
        %v131847_v34 = vadd.s32 %v34148_v26, %v131777_v34 (stack40)
        %v32125_v29 = vadd.f32 -3.0, %v32122_v23 (stack53)
        %v32906_v12 = vor.u32 %v32905_v10, %v32904_v24 (stack47)
        %v33287_v22 = vor.u32 %v33286_v61, %v33285_v9 (stack47)
        %v33708_v20 = vadd.s32 %v33705_v46, %v33700_v20 (stack40)
        %119913 = vst [vmem:[%s123356_s30 + $0x120] sm:$0xf] /*vst_source=*/%v31747_v30 (stack83)
        %v131853_v53 = vsel /*vm=*/%vm32073_vm1, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v32501_v54 = vadd.f32 -0.99609375, %v32497_v32 (stack53)
        %v33710_v11 = vshll.u32 %v33705_v46, 16 (stack45)
        %v33711_v27 = vshrl.u32 %v33705_v46, 16 (stack46)
        %v32110_v41 = vsel /*vm=*/%vm32073_vm1, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v131861_v8 = vsel /*vm=*/%vm32073_vm1, /*on_true_vy=*/%v131811_v8, /*on_false_vx=*/%v32125_v29 (stack44)
        %v32907_v43 = vxor.u32 %v32906_v12, %v32902_v52 (stack48)
        %v33288_v9 = vxor.u32 %v33287_v22, %v33283_v7 (stack48)
        %v32106_v60 = vsel /*vm=*/%vm32073_vm1, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v32133_v25 = vmul.f32 %v131861_v8, %v32110_v41 (stack54)
        %v131867_v24 = vmax.f32 %v32501_v54, -0.99609375 (stack55)
        %v33712_v6 = vor.u32 %v33711_v27, %v33710_v11 (stack47)
        %v32910_v52 = vadd.s32 %v32907_v43, %v32902_v52 (stack40)
        %v32912_v10 = vshll.u32 %v32907_v43, 15 (stack45)
        %v32913_v61 = vshrl.u32 %v32907_v43, 17 (stack46)
        %v33291_v7 = vadd.s32 %v33288_v9, %v33283_v7 (stack40)
        %v32137_v46 = vadd.f32 %v32133_v25, %v32106_v60 (stack53)
        %v32517_v30 = vxor.u32 2147483648, %v131867_v24 (stack56)
        %v34153_v23 = vshll.u32 %v34148_v26, 15 (stack45)
        %v34154_v26 = vshrl.u32 %v34148_v26, 17 (stack46)
        %v32914_v32 = vor.u32 %v32913_v61, %v32912_v10 (stack47)
        %v33293_v29 = vshll.u32 %v33288_v9, 26 (stack45)
        %v33294_v12 = vshrl.u32 %v33288_v9, 6 (stack46)
        %v33713_v22 = vxor.u32 %v33712_v6, %v33708_v20 (stack48)
        %v32094_v54 = vsel /*vm=*/%vm32073_vm1, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v32098_v11 = vsel /*vm=*/%vm32073_vm1, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v32141_v27 = vmul.f32 %v32137_v46, %v131861_v8 (stack54)
        %v131878_v41 = vmul.f32 %v32517_v30, %v131867_v24 (stack54)
        %v32102_v43 = vsel /*vm=*/%vm32073_vm1, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v32915_v9 = vxor.u32 %v32914_v32, %v32910_v52 (stack48)
        %v33295_v60 = vor.u32 %v33294_v12, %v33293_v29 (stack47)
        %v33716_v20 = vadd.s32 %v33713_v22, %v33708_v20 (stack40)
        %v32145_v25 = vadd.f32 %v32141_v27, %v32102_v43 (stack53)
        %v32522_v6 = vadd.f32 1.0, %v131878_v41 (stack57)
        %v34155_v10 = vor.u32 %v34154_v26, %v34153_v23 (stack47)
        %v34561_v61 = vadd.s32 %v131822_v55, %v122657_v58 (stack40)
        %v32918_v52 = vadd.s32 %v32915_v9, %v32910_v52 (stack40)
        %v32920_v46 = vshll.u32 %v32915_v9, 26 (stack45)
        %v32921_v30 = vshrl.u32 %v32915_v9, 6 (stack46)
        %v33296_v23 = vxor.u32 %v33295_v60, %v33291_v7 (stack48)
        %v32149_v26 = vmul.f32 %v32145_v25, %v131861_v8 (stack54)
        %120705 = vlog2.f32 %v32522_v6 (stack58)
        %v32525_v32 = vmul.f32 -0.5, %v131878_v41 (stack59)
        %v33722_v29 = vshll.u32 %v33713_v22, 24 (stack45)
        %v32922_v12 = vor.u32 %v32921_v30, %v32920_v46 (stack47)
        %v33299_v7 = vadd.s32 %v33296_v23, %v33291_v7 (stack40)
        %v33305_v27 = vshll.u32 %v33296_v23, 6 (stack45)
        %v33306_v43 = vshrl.u32 %v33296_v23, 26 (stack46)
        %v32153_v11 = vadd.f32 %v32149_v26, %v32098_v11 (stack53)
        %v33723_v22 = vshrl.u32 %v33713_v22, 8 (stack46)
        %vm34565_vm6 = vcmp.lt.u32.totalorder %v34561_v61, %v131822_v55 (stack43)
        %v34579_v9 = vadd.s32 1, %v131835_v42 (stack40)
        %v32528_v60 = vand.u32 2147483647, %v131878_v41 (stack60)
        %v32923_v25 = vxor.u32 %v32922_v12, %v32918_v52 (stack48)
        %v33307_v6 = vor.u32 %v33306_v43, %v33305_v27 (stack47)
        %v34156_v10 = vxor.u32 %v34155_v10, %v131847_v34 (stack48)
        %v32157_v46 = vmul.f32 %v32153_v11, %v131861_v8 (stack54)
        %v32526_v30 = vadd.f32 1.0, %v32525_v32 (stack61)
        %v33724_v23 = vor.u32 %v33723_v22, %v33722_v29 (stack47)
        %v34583_v42 = vsel /*vm=*/%vm34570_vm5, /*on_true_vy=*/%v34579_v9, /*on_false_vx=*/%v131835_v42 (stack44)
        %v32926_v52 = vadd.s32 %v32923_v25, %v32918_v52 (stack40)
        %v32932_v26 = vshll.u32 %v32923_v25, 6 (stack45)
        %v32933_v32 = vshrl.u32 %v32923_v25, 26 (stack46)
        %v33308_v29 = vxor.u32 %v33307_v6, %v33299_v7 (stack48)
        %v32161_v54 = vadd.f32 %v32157_v46, %v32094_v54 (stack53)
        %v33725_v12 = vxor.u32 %v33724_v23, %v33716_v20 (stack48)
        %v34159_v34 = vadd.s32 %v34156_v10, %v131847_v34 (stack40)
        %v34161_v27 = vshll.u32 %v34156_v10, 26 (stack45)
        %v32934_v43 = vor.u32 %v32933_v32, %v32932_v26 (stack47)
        %v33311_v11 = vadd.s32 %v33308_v29, %v121569_v1 (stack40)
        %v33720_v20 = vadd.s32 %v33716_v20, %v121564_v0 (stack40)
        %v34162_v22 = vshrl.u32 %v34156_v10, 6 (stack46)
        %v32165_v9 = vmul.f32 %v32161_v54, %v131861_v8 (stack54)
        %v33303_v7 = vadd.s32 %v33299_v7, %v121574_v2 (stack40)
        %v33728_v25 = vadd.s32 %v33725_v12, %v121574_v2 (stack40)
        %v34587_v6 = vadd.s32 1, %v34583_v42 (stack40)
        %v32935_v10 = vxor.u32 %v32934_v43, %v32926_v52 (stack48)
        %v33315_v46 = vadd.s32 3, %v33311_v11 (stack40)
        %v34163_v23 = vor.u32 %v34162_v22, %v34161_v27 (stack47)
        %v131904_v26 = vadd.s32 %v34561_v61, %v121569_v1 (stack40)
        %v32169_v53 = vadd.f32 %v32165_v9, %v131853_v53 (stack53)
        %v33732_v32 = vadd.s32 2, %v33728_v25 (stack40)
        %v34591_v55 = vsel /*vm=*/%vm34565_vm6, /*on_true_vy=*/%v34587_v6, /*on_false_vx=*/%v34583_v42 (stack44)
        %v131911_v61 = vadd.s32 %v157269_v50, %v157077_v51 (stack40)
        %v32938_v42 = vadd.s32 %v32935_v10, %v121574_v2 (stack40)
        %v33319_v29 = vadd.s32 %v33315_v46, %v33303_v7 (stack40)
        %v33321_v54 = vshll.u32 %v33315_v46, 17 (stack45)
        %v33322_v12 = vshrl.u32 %v33315_v46, 15 (stack46)
        %v32173_v27 = vmul.f32 %v32169_v53, %v131861_v8 (stack54)
        %v33736_v43 = vadd.s32 %v33732_v32, %v33720_v20 (stack40)
        %v33738_v11 = vshll.u32 %v33732_v32, 13 (stack45)
        %v33739_v20 = vshrl.u32 %v33732_v32, 19 (stack46)
        %v120706_v22 = vpop.eup %120705 (stack64)
        %v32930_v52 = vadd.s32 %v32926_v52, %v121564_v0 (stack40)
        %v32942_v9 = vadd.s32 5, %v32938_v42 (stack40)
        %v33323_v7 = vor.u32 %v33322_v12, %v33321_v54 (stack47)
        %v34164_v25 = vxor.u32 %v34163_v23, %v34159_v34 (stack48)
        %v32177_v44 = vadd.f32 %v32173_v27, %v131808_v44 (stack53)
        %v32524_v6 = vmul.f32 0.6931472, %v120706_v22 (stack65)
        %v32527_v41 = vmul.f32 %v32526_v30, %v131878_v41 (stack63)
        %v33740_v30 = vor.u32 %v33739_v20, %v33738_v11 (stack47)
        %vm32529_vm7 = vcmp.lt.f32.partialorder %v32528_v60, 0.0004427343 (stack62)
        %v32944_v60 = vxor.u32 %v32942_v9, %v32930_v52 (stack48)
        %v33324_v10 = vxor.u32 %v33323_v7, %v33319_v29 (stack48)
        %v34167_v34 = vadd.s32 %v34164_v25, %v34159_v34 (stack40)
        %v32082_v46 = vsel /*vm=*/%vm32073_vm1, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v32181_v23 = vmul.f32 %v32177_v44, %v131861_v8 (stack54)
        %v32530_v53 = vsel /*vm=*/%vm32529_vm7, /*on_true_vy=*/%v32527_v41, /*on_false_vx=*/%v32524_v6 (stack66)
        %v33741_v32 = vxor.u32 %v33740_v30, %v33736_v43 (stack48)
        %v131922_v42 = vxor.u32 2147483648, %v32530_v53 (stack56)
        %v33327_v29 = vadd.s32 %v33324_v10, %v33319_v29 (stack40)
        %v33329_v54 = vshll.u32 %v33324_v10, 29 (stack45)
        %v34606_v12 = vshll.u32 %v131904_v26, 13 (stack45)
        %v32185_v27 = vadd.f32 %v32181_v23, %v32082_v46 (stack53)
        %v33330_v11 = vshrl.u32 %v33324_v10, 3 (stack46)
        %v33744_v43 = vadd.s32 %v33741_v32, %v33736_v43 (stack40)
        %v34607_v20 = vshrl.u32 %v131904_v26, 19 (stack46)
        %v32054_v22 = vmul.f32 inf, %v131729_v40 (stack54)
        %120707 = vrsqrt.f32 %v131922_v42 (stack67)
        %v32945_v52 = vand.u32.u8 255, %v32944_v60 (stack49)
        %v32189_v8 = vmul.f32 %v32185_v27, %v131861_v8 (stack54)
        %vm32534_vm8 = vcmp.lt.f32.partialorder %v131922_v42, 5.0 (stack68)
        %v34173_v9 = vshll.u32 %v34164_v25, 6 (stack45)
        %v34174_v7 = vshrl.u32 %v34164_v25, 26 (stack46)
        %vm131932_vm9 = vcmp.eq.f32.partialorder %v32046_v21, 1.0 (stack68)
        %v32078_v31 = vsel /*vm=*/%vm32073_vm1, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v32507_v25 = vand.u32 2147483647, %v131867_v24 (stack77)
        %v33331_v44 = vor.u32 %v33330_v11, %v33329_v54 (stack47)
        %v32193_v6 = vadd.f32 %v32189_v8, %v32078_v31 (stack53)
        %v33746_v41 = vshll.u32 %v33741_v32, 15 (stack45)
        %v34596_v55 = vadd.s32 %v34591_v55, %v121574_v2 (stack40)
        %v34608_v30 = vor.u32 %v34607_v20, %v34606_v12 (stack47)
        %v131944_v60 = vsel /*vm=*/%vm32534_vm8, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v131947_v10 = vadd.f32 -2.5, %v131922_v42 (stack53)
        %v32946_v46 = vand.u32 65535, %v32945_v52 (stack50)
        %v33332_v23 = vxor.u32 %v33331_v44, %v33327_v29 (stack48)
        %v32197_v40 = vmul.f32 %v32193_v6, %v131729_v40 (stack54)
        %v131953_v53 = vsel /*vm=*/%vm32534_vm8, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v33747_v32 = vshrl.u32 %v33741_v32, 17 (stack46)
        %v34175_v54 = vor.u32 %v34174_v7, %v34173_v9 (stack47)
        %v32947_v12 = vshrl.u32 %v32946_v46, 1 (stack51)
        %v33335_v29 = vadd.s32 %v33332_v23, %v33327_v29 (stack40)
        %v33337_v27 = vshll.u32 %v33332_v23, 16 (stack45)
        %v33338_v11 = vshrl.u32 %v33332_v23, 16 (stack46)
        %v32201_v20 = vsel /*vm=*/%vm131932_vm9, /*on_true_vy=*/%v32054_v22, /*on_false_vx=*/%v32197_v40 (stack44)
        %vm32579_vm10 = vcmp.eq.f32.partialorder %v131922_v42, inf (stack70)
        %v33748_v22 = vor.u32 %v33747_v32, %v33746_v41 (stack47)
        %v34176_v52 = vxor.u32 %v34175_v54, %v34167_v34 (stack48)
        %v34604_v26 = vadd.s32 %v131904_v26, %v34596_v55 (stack40)
        %v32205_v8 = vmul.f32 1.4140625, %v32201_v20 (stack54)
        %vm32581_vm11 = vcmp.eq.f32.partialorder %v131922_v42, 0.0 (stack71)
        %v32948_v9 = vor.u32 16256, %v32947_v12 (stack47)
        %v33339_v7 = vor.u32 %v33338_v11, %v33337_v27 (stack47)
        %v33749_v21 = vxor.u32 %v33748_v22, %v33744_v43 (stack48)
        %v34179_v31 = vadd.s32 %v34176_v52, %v121564_v0 (stack40)
        %v34609_v44 = vxor.u32 %v34608_v30, %v34604_v26 (stack48)
        %vm35031_vm12 = vcmp.lt.u32.totalorder %v131911_v61, %v157077_v51 (stack43)
        %v32208_v6 = vpack.c.bf16 %v156663_v45, %v32205_v8 (stack81)
        %v32949_v41 = vand.u32.u16 65535, %v32948_v9 (stack52)
        %v33340_v55 = vxor.u32 %v33339_v7, %v33335_v29 (stack48)
        %v34171_v34 = vadd.s32 %v34167_v34, %v121569_v1 (stack40)
        %v33752_v43 = vadd.s32 %v33749_v21, %v33744_v43 (stack40)
        %v33754_v30 = vshll.u32 %v33749_v21, 26 (stack45)
        %v33755_v46 = vshrl.u32 %v33749_v21, 6 (stack46)
        %v34183_v23 = vadd.s32 1, %v34179_v31 (stack40)
        %119915 = vst [vmem:[%s123356_s30 + $0x1a0] sm:$0xf] /*vst_source=*/%v32208_v6 (stack83)
        %v119918_v40 = vadd.low.f32.bf16 -1.0, %v32949_v41 (stack53)
        %v33343_v32 = vadd.s32 %v33340_v55, %v33335_v29 (stack40)
        %v33349_v54 = vshll.u32 %v33340_v55, 24 (stack45)
        %v33350_v12 = vshrl.u32 %v33340_v55, 8 (stack46)
        %v120708_v29 = vpop.eup %120707 (stack73)
        %v33756_v27 = vor.u32 %v33755_v46, %v33754_v30 (stack47)
        %v34187_v11 = vadd.s32 %v34183_v23, %v34171_v34 (stack40)
        %v34189_v20 = vshll.u32 %v34183_v23, 17 (stack45)
        %v34190_v22 = vshrl.u32 %v34183_v23, 15 (stack46)
        %v32578_v52 = vmul.f32 %v120708_v29, %v131922_v42 (stack74)
        %v32582_v8 = vand.u32 2147483648, %v131922_v42 (stack72)
        %v32958_v9 = vmul.f32 2.0, %v119918_v40 (stack54)
        %v33351_v7 = vor.u32 %v33350_v12, %v33349_v54 (stack47)
        %v33757_v21 = vxor.u32 %v33756_v27, %v33752_v43 (stack48)
        %v34191_v31 = vor.u32 %v34190_v22, %v34189_v20 (stack47)
        %v34612_v26 = vadd.s32 %v34609_v44, %v34604_v26 (stack40)
        %v34614_v6 = vshll.u32 %v34609_v44, 15 (stack45)
        %v32580_v41 = vsel /*vm=*/%vm32579_vm10, /*on_true_vy=*/%v131922_v42, /*on_false_vx=*/%v32578_v52 (stack75)
        %v32962_v55 = vadd.f32 -0.99609375, %v32958_v9 (stack53)
        %v33352_v34 = vxor.u32 %v33351_v7, %v33343_v32 (stack48)
        %v34615_v44 = vshrl.u32 %v34609_v44, 17 (stack46)
        %v32583_v30 = vsel /*vm=*/%vm32581_vm11, /*on_true_vy=*/%v32582_v8, /*on_false_vx=*/%v32580_v41 (stack76)
        %v33760_v43 = vadd.s32 %v33757_v21, %v33752_v43 (stack40)
        %v33766_v46 = vshll.u32 %v33757_v21, 6 (stack45)
        %v33767_v23 = vshrl.u32 %v33757_v21, 26 (stack46)
        %v32586_v40 = vadd.f32 -3.0, %v32583_v30 (stack53)
        %v131973_v54 = vmax.f32 %v32962_v55, -0.99609375 (stack55)
        %v33355_v12 = vadd.s32 %v33352_v34, %v121564_v0 (stack40)
        %v34192_v29 = vxor.u32 %v34191_v31, %v34187_v11 (stack48)
        %v32559_v27 = vsel /*vm=*/%vm32534_vm8, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v32571_v20 = vsel /*vm=*/%vm32534_vm8, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v33768_v22 = vor.u32 %v33767_v23, %v33766_v46 (stack47)
        %v131984_v52 = vadd.s32 %v157270_v56, %v157078_v48 (stack40)
        %v131989_v10 = vsel /*vm=*/%vm32534_vm8, /*on_true_vy=*/%v131947_v10, /*on_false_vx=*/%v32586_v40 (stack44)
        %v32978_v8 = vxor.u32 2147483648, %v131973_v54 (stack56)
        %v33347_v32 = vadd.s32 %v33343_v32, %v121569_v1 (stack40)
        %v34616_v9 = vor.u32 %v34615_v44, %v34614_v6 (stack47)
        %v32594_v7 = vmul.f32 %v131989_v10, %v32571_v20 (stack54)
        %v33359_v21 = vadd.s32 4, %v33355_v12 (stack40)
        %v33769_v31 = vxor.u32 %v33768_v22, %v33760_v43 (stack48)
        %v34195_v11 = vadd.s32 %v34192_v29, %v34187_v11 (stack40)
        %v32567_v6 = vsel /*vm=*/%vm32534_vm8, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v131998_v41 = vmul.f32 %v32978_v8, %v131973_v54 (stack54)
        %v34197_v55 = vshll.u32 %v34192_v29, 29 (stack45)
        %v34198_v34 = vshrl.u32 %v34192_v29, 3 (stack46)
        %v32598_v44 = vadd.f32 %v32594_v7, %v32567_v6 (stack53)
        %v33363_v30 = vadd.s32 %v33359_v21, %v33347_v32 (stack40)
        %v33365_v46 = vshll.u32 %v33359_v21, 13 (stack45)
        %v33366_v23 = vshrl.u32 %v33359_v21, 19 (stack46)
        %v32563_v40 = vsel /*vm=*/%vm32534_vm8, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v32983_v12 = vadd.f32 1.0, %v131998_v41 (stack57)
        %v33772_v29 = vadd.s32 %v33769_v31, %v121569_v1 (stack40)
        %v132007_v20 = vadd.s32 %v131911_v61, %v122657_v58 (stack40)
        %v32602_v22 = vmul.f32 %v32598_v44, %v131989_v10 (stack54)
        %v33367_v8 = vor.u32 %v33366_v23, %v33365_v46 (stack47)
        %v34199_v32 = vor.u32 %v34198_v34, %v34197_v55 (stack47)
        %v34617_v9 = vxor.u32 %v34616_v9, %v34612_v26 (stack48)
        %120709 = vlog2.f32 %v32983_v12 (stack58)
        %v32986_v7 = vmul.f32 -0.5, %v131998_v41 (stack59)
        %v33764_v43 = vadd.s32 %v33760_v43, %v121574_v2 (stack40)
        %v33776_v21 = vadd.s32 3, %v33772_v29 (stack40)
        %v32606_v31 = vadd.f32 %v32602_v22, %v32563_v40 (stack53)
        %v33368_v6 = vxor.u32 %v33367_v8, %v33363_v30 (stack48)
        %v34200_v55 = vxor.u32 %v34199_v32, %v34195_v11 (stack48)
        %v34620_v26 = vadd.s32 %v34617_v9, %v34612_v26 (stack40)
        %v32989_v34 = vand.u32 2147483647, %v131998_v41 (stack60)
        %v33780_v44 = vadd.s32 %v33776_v21, %v33764_v43 (stack40)
        %v33782_v46 = vshll.u32 %v33776_v21, 17 (stack45)
        %v33783_v23 = vshrl.u32 %v33776_v21, 15 (stack46)
        %v32610_v40 = vmul.f32 %v32606_v31, %v131989_v10 (stack54)
        %v33371_v30 = vadd.s32 %v33368_v6, %v33363_v30 (stack40)
        %v33373_v12 = vshll.u32 %v33368_v6, 15 (stack45)
        %v33374_v29 = vshrl.u32 %v33368_v6, 17 (stack46)
        %v33784_v22 = vor.u32 %v33783_v23, %v33782_v46 (stack47)
        %v34203_v11 = vadd.s32 %v34200_v55, %v34195_v11 (stack40)
        %v34205_v8 = vshll.u32 %v34200_v55, 16 (stack45)
        %v34206_v32 = vshrl.u32 %v34200_v55, 16 (stack46)
        %v32614_v27 = vadd.f32 %v32610_v40, %v32559_v27 (stack53)
        %v33375_v43 = vor.u32 %v33374_v29, %v33373_v12 (stack47)
        %v34622_v21 = vshll.u32 %v34617_v9, 26 (stack45)
        %v34623_v9 = vshrl.u32 %v34617_v9, 6 (stack46)
        %v32987_v7 = vadd.f32 1.0, %v32986_v7 (stack61)
        %v33785_v31 = vxor.u32 %v33784_v22, %v33780_v44 (stack48)
        %v34207_v6 = vor.u32 %v34206_v32, %v34205_v8 (stack47)
        %v35040_v55 = vadd.s32 1, %v131984_v52 (stack40)
        %v32618_v46 = vmul.f32 %v32614_v27, %v131989_v10 (stack54)
        %v33376_v23 = vxor.u32 %v33375_v43, %v33371_v30 (stack48)
        %v34624_v40 = vor.u32 %v34623_v9, %v34622_v21 (stack47)
        %vm35026_vm13 = vcmp.lt.u32.totalorder %v132007_v20, %v131911_v61 (stack43)
        %v132020_v12 = vadd.s32 %v157269_v50, %v157079_v39 (stack40)
        %v33788_v44 = vadd.s32 %v33785_v31, %v33780_v44 (stack40)
        %v33790_v29 = vshll.u32 %v33785_v31, 29 (stack45)
        %v33791_v22 = vshrl.u32 %v33785_v31, 3 (stack46)
        %v34208_v8 = vxor.u32 %v34207_v6, %v34203_v11 (stack48)
        %v32622_v53 = vadd.f32 %v32618_v46, %v131953_v53 (stack53)
        %v33379_v30 = vadd.s32 %v33376_v23, %v33371_v30 (stack40)
        %v33381_v32 = vshll.u32 %v33376_v23, 26 (stack45)
        %v33382_v27 = vshrl.u32 %v33376_v23, 6 (stack46)
        %v33792_v43 = vor.u32 %v33791_v22, %v33790_v29 (stack47)
        %v34211_v11 = vadd.s32 %v34208_v8, %v34203_v11 (stack40)
        %v34217_v21 = vshll.u32 %v34208_v8, 24 (stack45)
        %v34218_v9 = vshrl.u32 %v34208_v8, 8 (stack46)
        %v32626_v31 = vmul.f32 %v32622_v53, %v131989_v10 (stack54)
        %v33383_v6 = vor.u32 %v33382_v27, %v33381_v32 (stack47)
        %v34625_v46 = vxor.u32 %v34624_v40, %v34620_v26 (stack48)
        %v35044_v52 = vsel /*vm=*/%vm35031_vm12, /*on_true_vy=*/%v35040_v55, /*on_false_vx=*/%v131984_v52 (stack44)
        %v32988_v41 = vmul.f32 %v32987_v7, %v131998_v41 (stack63)
        %vm132029_vm14 = vcmp.lt.f32.partialorder %v32989_v34, 0.0004427343 (stack62)
        %v33793_v7 = vxor.u32 %v33792_v43, %v33788_v44 (stack48)
        %v34219_v55 = vor.u32 %v34218_v9, %v34217_v21 (stack47)
        %v120710_v23 = vpop.eup %120709 (stack64)
        %v32630_v60 = vadd.f32 %v32626_v31, %v131944_v60 (stack53)
        %v33384_v40 = vxor.u32 %v33383_v6, %v33379_v30 (stack48)
        %v132034_v26 = vadd.s32 %v34625_v46, %v34620_v26 (stack40)
        %v35048_v29 = vadd.s32 1, %v35044_v52 (stack40)
        %v32985_v22 = vmul.f32 0.6931472, %v120710_v23 (stack65)
        %v33796_v44 = vadd.s32 %v33793_v7, %v33788_v44 (stack40)
        %v33798_v8 = vshll.u32 %v33793_v7, 16 (stack45)
        %v33799_v53 = vshrl.u32 %v33793_v7, 16 (stack46)
        %v32634_v32 = vmul.f32 %v32630_v60, %v131989_v10 (stack54)
        %v33387_v30 = vadd.s32 %v33384_v40, %v33379_v30 (stack40)
        %v33393_v27 = vshll.u32 %v33384_v40, 6 (stack45)
        %v33394_v43 = vshrl.u32 %v33384_v40, 26 (stack46)
        %v32547_v21 = vsel /*vm=*/%vm32534_vm8, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v32991_v9 = vsel /*vm=*/%vm132029_vm14, /*on_true_vy=*/%v32988_v41, /*on_false_vx=*/%v32985_v22 (stack66)
        %v33800_v31 = vor.u32 %v33799_v53, %v33798_v8 (stack47)
        %v34220_v6 = vxor.u32 %v34219_v55, %v34211_v11 (stack48)
        %v32515_v41 = vmul.f32 inf, %v131867_v24 (stack54)
        %v32638_v34 = vadd.f32 %v32634_v32, %v32547_v21 (stack53)
        %v132043_v7 = vxor.u32 2147483648, %v32991_v9 (stack56)
        %v33395_v55 = vor.u32 %v33394_v43, %v33393_v27 (stack47)
        %v32539_v23 = vsel /*vm=*/%vm32534_vm8, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v32543_v42 = vsel /*vm=*/%vm32534_vm8, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v33801_v60 = vxor.u32 %v33800_v31, %v33796_v44 (stack48)
        %v35052_v61 = vsel /*vm=*/%vm35026_vm13, /*on_true_vy=*/%v35048_v29, /*on_false_vx=*/%v35044_v52 (stack44)
        %v32642_v52 = vmul.f32 %v32638_v34, %v131989_v10 (stack54)
        %v32968_v40 = vand.u32 2147483647, %v131973_v54 (stack77)
        %vm32995_vm15 = vcmp.lt.f32.partialorder %v132043_v7, 5.0 (stack68)
        %120711 = vrsqrt.f32 %v132043_v7 (stack67)
        %vm132060_vm0 = vcmp.eq.f32.partialorder %v32507_v25, 1.0 (stack68)
        %v33396_v29 = vxor.u32 %v33395_v55, %v33387_v30 (stack48)
        %v34215_v11 = vadd.s32 %v34211_v11, %v121564_v0 (stack40)
        %v34634_v22 = vshll.u32 %v34625_v46, 6 (stack45)
        %v35061_v20 = vadd.s32 %v132007_v20, %v121569_v1 (stack40)
        %v32646_v8 = vadd.f32 %v32642_v52, %v32543_v42 (stack53)
        %v34223_v53 = vadd.s32 %v34220_v6, %v121574_v2 (stack40)
        %v34632_v32 = vadd.s32 %v132034_v26, %v121569_v1 (stack40)
        %v34635_v46 = vshrl.u32 %v34625_v46, 26 (stack46)
        %v132073_v27 = vsel /*vm=*/%vm32995_vm15, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v132076_v43 = vadd.f32 -2.5, %v132043_v7 (stack53)
        %v33391_v30 = vadd.s32 %v33387_v30, %v121564_v0 (stack40)
        %v33399_v21 = vadd.s32 %v33396_v29, %v121574_v2 (stack40)
        %v32650_v10 = vmul.f32 %v32646_v8, %v131989_v10 (stack54)
        %v132084_v9 = vsel /*vm=*/%vm32995_vm15, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v132089_v31 = vsel /*vm=*/%vm32995_vm15, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v132094_v6 = vsel /*vm=*/%vm32995_vm15, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v33403_v34 = vadd.s32 5, %v33399_v21 (stack40)
        %v33804_v44 = vadd.s32 %v33801_v60, %v33796_v44 (stack40)
        %v33810_v55 = vshll.u32 %v33801_v60, 24 (stack45)
        %v33811_v42 = vshrl.u32 %v33801_v60, 8 (stack46)
        %v32654_v23 = vadd.f32 %v32650_v10, %v32539_v23 (stack53)
        %v34227_v60 = vadd.s32 2, %v34223_v53 (stack40)
        %v34636_v52 = vor.u32 %v34635_v46, %v34634_v22 (stack47)
        %v35057_v61 = vadd.s32 %v35052_v61, %v121574_v2 (stack40)
        %vm33040_vm1 = vcmp.eq.f32.partialorder %v132043_v7, inf (stack70)
        %v33405_v29 = vxor.u32 %v33403_v34, %v33391_v30 (stack48)
        %v33812_v22 = vor.u32 %v33811_v42, %v33810_v55 (stack47)
        %v35067_v8 = vshll.u32 %v35061_v20, 13 (stack45)
        %v32658_v24 = vmul.f32 %v32654_v23, %v131867_v24 (stack54)
        %vm33042_vm2 = vcmp.eq.f32.partialorder %v132043_v7, 0.0 (stack71)
        %v34231_v11 = vadd.s32 %v34227_v60, %v34215_v11 (stack40)
        %v34233_v53 = vshll.u32 %v34227_v60, 13 (stack45)
        %v34234_v46 = vshrl.u32 %v34227_v60, 19 (stack46)
        %v33406_v30 = vand.u32.u8 255, %v33405_v29 (stack49)
        %v33813_v21 = vxor.u32 %v33812_v22, %v33804_v44 (stack48)
        %v34637_v26 = vxor.u32 %v34636_v52, %v132034_v26 (stack48)
        %v35065_v10 = vadd.s32 %v35061_v20, %v35057_v61 (stack40)
        %v32662_v41 = vsel /*vm=*/%vm132060_vm0, /*on_true_vy=*/%v32515_v41, /*on_false_vx=*/%v32658_v24 (stack44)
        %v33043_v25 = vand.u32 2147483648, %v132043_v7 (stack72)
        %v34235_v34 = vor.u32 %v34234_v46, %v34233_v53 (stack47)
        %v35068_v20 = vshrl.u32 %v35061_v20, 19 (stack46)
        %v32666_v55 = vmul.f32 1.4140625, %v32662_v41 (stack54)
        %v33407_v42 = vand.u32 65535, %v33406_v30 (stack50)
        %v33816_v23 = vadd.s32 %v33813_v21, %v121564_v0 (stack40)
        %v34640_v60 = vadd.s32 %v34637_v26, %v121564_v0 (stack40)
        %v33808_v44 = vadd.s32 %v33804_v44, %v121569_v1 (stack40)
        %v34236_v52 = vxor.u32 %v34235_v34, %v34231_v11 (stack48)
        %v35069_v61 = vor.u32 %v35068_v20, %v35067_v8 (stack47)
        %vm35492_vm3 = vcmp.lt.u32.totalorder %v132020_v12, %v157079_v39 (stack43)
        %v120712_v29 = vpop.eup %120711 (stack73)
        %v32669_v22 = vpack.c.bf16 %v156663_v45, %v32666_v55 (stack81)
        %v33408_v8 = vshrl.u32 %v33407_v42, 1 (stack51)
        %v33820_v24 = vadd.s32 4, %v33816_v23 (stack40)
        %v34644_v53 = vadd.s32 1, %v34640_v60 (stack40)
        %v33039_v46 = vmul.f32 %v120712_v29, %v132043_v7 (stack74)
        %v34239_v11 = vadd.s32 %v34236_v52, %v34231_v11 (stack40)
        %v34241_v30 = vshll.u32 %v34236_v52, 15 (stack45)
        %v34242_v21 = vshrl.u32 %v34236_v52, 17 (stack46)
        %119917 = vst [vmem:[%s123356_s30 + $0x220] sm:$0xf] /*vst_source=*/%v32669_v22 (stack83)
        %v33409_v26 = vor.u32 16256, %v33408_v8 (stack47)
        %v33824_v41 = vadd.s32 %v33820_v24, %v33808_v44 (stack40)
        %v33826_v34 = vshll.u32 %v33820_v24, 13 (stack45)
        %v33827_v20 = vshrl.u32 %v33820_v24, 19 (stack46)
        %v33041_v55 = vsel /*vm=*/%vm33040_vm1, /*on_true_vy=*/%v132043_v7, /*on_false_vx=*/%v33039_v46 (stack75)
        %v34243_v42 = vor.u32 %v34242_v21, %v34241_v30 (stack47)
        %v34648_v32 = vadd.s32 %v34644_v53, %v34632_v32 (stack40)
        %v34650_v23 = vshll.u32 %v34644_v53, 17 (stack45)
        %v33044_v25 = vsel /*vm=*/%vm33042_vm2, /*on_true_vy=*/%v33043_v25, /*on_false_vx=*/%v33041_v55 (stack76)
        %v33410_v60 = vand.u32.u16 65535, %v33409_v26 (stack52)
        %v33828_v44 = vor.u32 %v33827_v20, %v33826_v34 (stack47)
        %v34651_v52 = vshrl.u32 %v34644_v53, 15 (stack46)
        %v33047_v29 = vadd.f32 -3.0, %v33044_v25 (stack53)
        %v34244_v22 = vxor.u32 %v34243_v42, %v34239_v11 (stack48)
        %v35070_v61 = vxor.u32 %v35069_v61, %v35065_v10 (stack48)
        %v132119_v8 = vadd.s32 %v157270_v56, %v157082_v49 (stack40)
        %v33032_v24 = vsel /*vm=*/%vm32995_vm15, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v119920_v53 = vadd.low.f32.bf16 -1.0, %v33410_v60 (stack53)
        %v33829_v46 = vxor.u32 %v33828_v44, %v33824_v41 (stack48)
        %v34652_v30 = vor.u32 %v34651_v52, %v34650_v23 (stack47)
        %v132127_v43 = vsel /*vm=*/%vm32995_vm15, /*on_true_vy=*/%v132076_v43, /*on_false_vx=*/%v33047_v29 (stack44)
        %v34247_v11 = vadd.s32 %v34244_v22, %v34239_v11 (stack40)
        %v34249_v21 = vshll.u32 %v34244_v22, 26 (stack45)
        %v34250_v26 = vshrl.u32 %v34244_v22, 6 (stack46)
        %v33055_v34 = vmul.f32 %v132127_v43, %v33032_v24 (stack54)
        %v33419_v20 = vmul.f32 2.0, %v119920_v53 (stack54)
        %v33832_v41 = vadd.s32 %v33829_v46, %v33824_v41 (stack40)
        %v33834_v55 = vshll.u32 %v33829_v46, 15 (stack45)
        %v33835_v42 = vshrl.u32 %v33829_v46, 17 (stack46)
        %v34251_v23 = vor.u32 %v34250_v26, %v34249_v21 (stack47)
        %v34653_v25 = vxor.u32 %v34652_v30, %v34648_v32 (stack48)
        %v35073_v10 = vadd.s32 %v35070_v61, %v35065_v10 (stack40)
        %v33059_v6 = vadd.f32 %v33055_v34, %v132094_v6 (stack53)
        %v33423_v60 = vadd.f32 -0.99609375, %v33419_v20 (stack53)
        %v35075_v44 = vshll.u32 %v35070_v61, 15 (stack45)
        %v35076_v52 = vshrl.u32 %v35070_v61, 17 (stack46)
        %v33836_v29 = vor.u32 %v33835_v42, %v33834_v55 (stack47)
        %v34252_v22 = vxor.u32 %v34251_v23, %v34247_v11 (stack48)
        %v34656_v32 = vadd.s32 %v34653_v25, %v34648_v32 (stack40)
        %v34658_v61 = vshll.u32 %v34653_v25, 29 (stack45)
        %v33063_v24 = vmul.f32 %v33059_v6, %v132127_v43 (stack54)
        %v132132_v53 = vmax.f32 %v33423_v60, -0.99609375 (stack55)
        %v34659_v46 = vshrl.u32 %v34653_v25, 3 (stack46)
        %v35077_v30 = vor.u32 %v35076_v52, %v35075_v44 (stack47)
        %v33837_v21 = vxor.u32 %v33836_v29, %v33832_v41 (stack48)
        %v34255_v11 = vadd.s32 %v34252_v22, %v34247_v11 (stack40)
        %v34261_v26 = vshll.u32 %v34252_v22, 6 (stack45)
        %v34262_v34 = vshrl.u32 %v34252_v22, 26 (stack46)
        %v132137_v20 = vsel /*vm=*/%vm32995_vm15, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v33067_v31 = vadd.f32 %v33063_v24, %v132089_v31 (stack53)
        %v33439_v55 = vxor.u32 2147483648, %v132132_v53 (stack56)
        %v35483_v42 = vadd.s32 %v132020_v12, %v122657_v58 (stack40)
        %v33012_v23 = vsel /*vm=*/%vm32995_vm15, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v33840_v41 = vadd.s32 %v33837_v21, %v33832_v41 (stack40)
        %v33842_v25 = vshll.u32 %v33837_v21, 26 (stack45)
        %v33843_v6 = vshrl.u32 %v33837_v21, 6 (stack46)
        %v33016_v60 = vsel /*vm=*/%vm32995_vm15, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v33071_v44 = vmul.f32 %v33067_v31, %v132127_v43 (stack54)
        %v132151_v52 = vmul.f32 %v33439_v55, %v132132_v53 (stack54)
        %v34263_v29 = vor.u32 %v34262_v34, %v34261_v26 (stack47)
        %v33020_v7 = vsel /*vm=*/%vm32995_vm15, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v33844_v22 = vor.u32 %v33843_v6, %v33842_v25 (stack47)
        %v34660_v61 = vor.u32 %v34659_v46, %v34658_v61 (stack47)
        %v35078_v24 = vxor.u32 %v35077_v30, %v35073_v10 (stack48)
        %v33075_v46 = vadd.f32 %v33071_v44, %v33020_v7 (stack53)
        %v33444_v30 = vadd.f32 1.0, %v132151_v52 (stack57)
        %vm35487_vm4 = vcmp.lt.u32.totalorder %v35483_v42, %v132020_v12 (stack43)
        %v132159_v21 = vadd.s32 %v35483_v42, %v121569_v1 (stack40)
        %v33845_v26 = vxor.u32 %v33844_v22, %v33840_v41 (stack48)
        %v34264_v34 = vxor.u32 %v34263_v29, %v34255_v11 (stack48)
        %v34661_v31 = vxor.u32 %v34660_v61, %v34656_v32 (stack48)
        %v35081_v10 = vadd.s32 %v35078_v24, %v35073_v10 (stack40)
        %v33079_v55 = vmul.f32 %v33075_v46, %v132127_v43 (stack54)
        %120713 = vlog2.f32 %v33444_v30 (stack58)
        %v34259_v11 = vadd.s32 %v34255_v11, %v121574_v2 (stack40)
        %v35501_v25 = vadd.s32 1, %v132119_v8 (stack40)
        %v33848_v41 = vadd.s32 %v33845_v26, %v33840_v41 (stack40)
        %v33854_v6 = vshll.u32 %v33845_v26, 6 (stack45)
        %v33855_v44 = vshrl.u32 %v33845_v26, 26 (stack46)
        %v34267_v29 = vadd.s32 %v34264_v34, %v121569_v1 (stack40)
        %v33083_v60 = vadd.f32 %v33079_v55, %v33016_v60 (stack53)
        %v33447_v7 = vmul.f32 -0.5, %v132151_v52 (stack59)
        %v34664_v32 = vadd.s32 %v34661_v31, %v34656_v32 (stack40)
        %v34666_v22 = vshll.u32 %v34661_v31, 16 (stack45)
        %v33450_v61 = vand.u32 2147483647, %v132151_v52 (stack60)
        %v33856_v46 = vor.u32 %v33855_v44, %v33854_v6 (stack47)
        %v34271_v30 = vadd.s32 3, %v34267_v29 (stack40)
        %v34667_v26 = vshrl.u32 %v34661_v31, 16 (stack46)
        %v33087_v34 = vmul.f32 %v33083_v60, %v132127_v43 (stack54)
        %v35083_v31 = vshll.u32 %v35078_v24, 26 (stack45)
        %v35084_v24 = vshrl.u32 %v35078_v24, 6 (stack46)
        %v35505_v8 = vsel /*vm=*/%vm35492_vm3, /*on_true_vy=*/%v35501_v25, /*on_false_vx=*/%v132119_v8 (stack44)
        %v33857_v55 = vxor.u32 %v33856_v46, %v33848_v41 (stack48)
        %v34275_v11 = vadd.s32 %v34271_v30, %v34259_v11 (stack40)
        %v34277_v25 = vshll.u32 %v34271_v30, 17 (stack45)
        %v34278_v6 = vshrl.u32 %v34271_v30, 15 (stack46)
        %v33091_v23 = vadd.f32 %v33087_v34, %v33012_v23 (stack53)
        %v34668_v44 = vor.u32 %v34667_v26, %v34666_v22 (stack47)
        %v35085_v29 = vor.u32 %v35084_v24, %v35083_v31 (stack47)
        %v35509_v60 = vadd.s32 1, %v35505_v8 (stack40)
        %v33448_v7 = vadd.f32 1.0, %v33447_v7 (stack61)
        %vm132172_vm5 = vcmp.lt.f32.partialorder %v33450_v61, 0.0004427343 (stack62)
        %v33860_v61 = vadd.s32 %v33857_v55, %v121574_v2 (stack40)
        %v34279_v46 = vor.u32 %v34278_v6, %v34277_v25 (stack47)
        %v33095_v30 = vmul.f32 %v33091_v23, %v132127_v43 (stack54)
        %v34669_v26 = vxor.u32 %v34668_v44, %v34664_v32 (stack48)
        %v35086_v34 = vxor.u32 %v35085_v29, %v35081_v10 (stack48)
        %v35513_v12 = vsel /*vm=*/%vm35487_vm4, /*on_true_vy=*/%v35509_v60, /*on_false_vx=*/%v35505_v8 (stack44)
        %v33852_v42 = vadd.s32 %v33848_v41, %v121564_v0 (stack40)
        %v33864_v41 = vadd.s32 5, %v33860_v61 (stack40)
        %v34280_v31 = vxor.u32 %v34279_v46, %v34275_v11 (stack48)
        %v35518_v24 = vadd.s32 %v35513_v12, %v121574_v2 (stack40)
        %v33099_v20 = vadd.f32 %v33095_v30, %v132137_v20 (stack53)
        %v34672_v32 = vadd.s32 %v34669_v26, %v34664_v32 (stack40)
        %v34678_v8 = vshll.u32 %v34669_v26, 24 (stack45)
        %v34679_v55 = vshrl.u32 %v34669_v26, 8 (stack46)
        %v33866_v25 = vxor.u32 %v33864_v41, %v33852_v42 (stack48)
        %v34283_v11 = vadd.s32 %v34280_v31, %v34275_v11 (stack40)
        %v34285_v6 = vshll.u32 %v34280_v31, 29 (stack45)
        %v34286_v23 = vshrl.u32 %v34280_v31, 3 (stack46)
        %v33103_v44 = vmul.f32 %v33099_v20, %v132127_v43 (stack54)
        %v33449_v52 = vmul.f32 %v33448_v7, %v132151_v52 (stack63)
        %v34680_v29 = vor.u32 %v34679_v55, %v34678_v8 (stack47)
        %v35089_v10 = vadd.s32 %v35086_v34, %v35081_v10 (stack40)
        %v120714_v60 = vpop.eup %120713 (stack64)
        %v33867_v7 = vand.u32.u8 255, %v33866_v25 (stack49)
        %v34287_v61 = vor.u32 %v34286_v23, %v34285_v6 (stack47)
        %v35095_v46 = vshll.u32 %v35086_v34, 6 (stack45)
        %v35096_v30 = vshrl.u32 %v35086_v34, 26 (stack46)
        %v33107_v9 = vadd.f32 %v33103_v44, %v132084_v9 (stack53)
        %v33446_v26 = vmul.f32 0.6931472, %v120714_v60 (stack65)
        %v34681_v34 = vxor.u32 %v34680_v29, %v34672_v32 (stack48)
        %v35528_v12 = vshll.u32 %v132159_v21, 13 (stack45)
        %v33868_v42 = vand.u32 65535, %v33867_v7 (stack50)
        %v34288_v41 = vxor.u32 %v34287_v61, %v34283_v11 (stack48)
        %v35097_v31 = vor.u32 %v35096_v30, %v35095_v46 (stack47)
        %v35526_v24 = vadd.s32 %v132159_v21, %v35518_v24 (stack40)
        %v33111_v43 = vmul.f32 %v33107_v9, %v132127_v43 (stack54)
        %v33452_v22 = vsel /*vm=*/%vm132172_vm5, /*on_true_vy=*/%v33449_v52, /*on_false_vx=*/%v33446_v26 (stack66)
        %v34684_v20 = vadd.s32 %v34681_v34, %v121574_v2 (stack40)
        %v132194_v8 = vadd.s32 %v157269_v50, %v157083_v59 (stack40)
        %v132196_v55 = vxor.u32 2147483648, %v33452_v22 (stack56)
        %v34291_v25 = vadd.s32 %v34288_v41, %v34283_v11 (stack40)
        %v34293_v11 = vshll.u32 %v34288_v41, 16 (stack45)
        %v35529_v21 = vshrl.u32 %v132159_v21, 19 (stack46)
        %v33115_v27 = vadd.f32 %v33111_v43, %v132073_v27 (stack53)
        %v34294_v6 = vshrl.u32 %v34288_v41, 16 (stack46)
        %v35098_v23 = vxor.u32 %v35097_v31, %v35089_v10 (stack48)
        %120715 = vrsqrt.f32 %v132196_v55 (stack67)
        %v33869_v44 = vshrl.u32 %v33868_v42, 1 (stack51)
        %v32976_v52 = vmul.f32 inf, %v131973_v54 (stack54)
        %v33119_v29 = vmul.f32 %v33115_v27, %v131973_v54 (stack54)
        %vm33456_vm6 = vcmp.lt.f32.partialorder %v132196_v55, 5.0 (stack68)
        %v34688_v60 = vadd.s32 2, %v34684_v20 (stack40)
        %vm32971_vm7 = vcmp.eq.f32.partialorder %v32968_v40, 1.0 (stack68)
        %v34295_v54 = vor.u32 %v34294_v6, %v34293_v11 (stack47)
        %v35530_v40 = vor.u32 %v35529_v21, %v35528_v12 (stack47)
        %v33123_v7 = vsel /*vm=*/%vm32971_vm7, /*on_true_vy=*/%v32976_v52, /*on_false_vx=*/%v33119_v29 (stack44)
        %v34676_v32 = vadd.s32 %v34672_v32, %v121564_v0 (stack40)
        %v35093_v10 = vadd.s32 %v35089_v10, %v121569_v1 (stack40)
        %v33127_v61 = vmul.f32 1.4140625, %v33123_v7 (stack54)
        %v132211_v46 = vsel /*vm=*/%vm33456_vm6, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v132214_v30 = vadd.f32 -2.5, %v132196_v55 (stack53)
        %v33870_v9 = vor.u32 16256, %v33869_v44 (stack47)
        %v34296_v26 = vxor.u32 %v34295_v54, %v34291_v25 (stack48)
        %v34692_v34 = vadd.s32 %v34688_v60, %v34676_v32 (stack40)
        %v34694_v12 = vshll.u32 %v34688_v60, 13 (stack45)
        %v34695_v42 = vshrl.u32 %v34688_v60, 19 (stack46)
        %v33130_v41 = vpack.c.bf16 %v156663_v45, %v33127_v61 (stack81)
        %v33871_v31 = vand.u32.u16 65535, %v33870_v9 (stack52)
        %v35101_v43 = vadd.s32 %v35098_v23, %v121564_v0 (stack40)
        %v35531_v22 = vxor.u32 %v35530_v40, %v35526_v24 (stack48)
        %vm33501_vm8 = vcmp.eq.f32.partialorder %v132196_v55, inf (stack70)
        %v34299_v20 = vadd.s32 %v34296_v26, %v34291_v25 (stack40)
        %v34305_v25 = vshll.u32 %v34296_v26, 24 (stack45)
        %v34306_v11 = vshrl.u32 %v34296_v26, 8 (stack46)
        %v34696_v21 = vor.u32 %v34695_v42, %v34694_v12 (stack47)
        %119919 = vst [vmem:[%s123356_s30 + $0x2a0] sm:$0xf] /*vst_source=*/%v33130_v41 (stack83)
        %v119922_v27 = vadd.low.f32.bf16 -1.0, %v33871_v31 (stack53)
        %v35105_v6 = vadd.s32 1, %v35101_v43 (stack40)
        %v132220_v24 = vadd.s32 %v35531_v22, %v35526_v24 (stack40)
        %v35536_v23 = vshll.u32 %v35531_v22, 15 (stack45)
        %v132225_v44 = vsel /*vm=*/%vm33456_vm6, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v34307_v52 = vor.u32 %v34306_v11, %v34305_v25 (stack47)
        %v34697_v29 = vxor.u32 %v34696_v21, %v34692_v34 (stack48)
        %v35537_v60 = vshrl.u32 %v35531_v22, 17 (stack46)
        %v33880_v54 = vmul.f32 2.0, %v119922_v27 (stack54)
        %v35109_v40 = vadd.s32 %v35105_v6, %v35093_v10 (stack40)
        %v35111_v7 = vshll.u32 %v35105_v6, 17 (stack45)
        %v35112_v32 = vshrl.u32 %v35105_v6, 15 (stack46)
        %v34308_v10 = vxor.u32 %v34307_v52, %v34299_v20 (stack48)
        %v34700_v61 = vadd.s32 %v34697_v29, %v34692_v34 (stack40)
        %v34702_v9 = vshll.u32 %v34697_v29, 15 (stack45)
        %v34703_v26 = vshrl.u32 %v34697_v29, 17 (stack46)
        %v132230_v34 = vsel /*vm=*/%vm33456_vm6, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v33884_v12 = vadd.f32 -0.99609375, %v33880_v54 (stack53)
        %v35113_v42 = vor.u32 %v35112_v32, %v35111_v7 (stack47)
        %v35538_v41 = vor.u32 %v35537_v60, %v35536_v23 (stack47)
        %v120716_v31 = vpop.eup %120715 (stack73)
        %v34311_v43 = vadd.s32 %v34308_v10, %v121564_v0 (stack40)
        %v34704_v22 = vor.u32 %v34703_v26, %v34702_v9 (stack47)
        %vm35953_vm9 = vcmp.lt.u32.totalorder %v132194_v8, %v157083_v59 (stack43)
        %v35958_v25 = vadd.s32 %v157270_v56, %v157084_v16 (stack40)
        %v33500_v11 = vmul.f32 %v120716_v31, %v132196_v55 (stack74)
        %v132238_v21 = vmax.f32 %v33884_v12, -0.99609375 (stack55)
        %v35114_v27 = vxor.u32 %v35113_v42, %v35109_v40 (stack48)
        %v35539_v6 = vxor.u32 %v35538_v41, %v132220_v24 (stack48)
        %v33504_v23 = vand.u32 2147483648, %v132196_v55 (stack72)
        %v34303_v20 = vadd.s32 %v34299_v20, %v121569_v1 (stack40)
        %v34315_v52 = vadd.s32 4, %v34311_v43 (stack40)
        %v34705_v29 = vxor.u32 %v34704_v22, %v34700_v61 (stack48)
        %v33485_v60 = vsel /*vm=*/%vm33456_vm6, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v33502_v54 = vsel /*vm=*/%vm33501_vm8, /*on_true_vy=*/%v132196_v55, /*on_false_vx=*/%v33500_v11 (stack75)
        %vm33503_vm10 = vcmp.eq.f32.partialorder %v132196_v55, 0.0 (stack71)
        %v33900_v7 = vxor.u32 2147483648, %v132238_v21 (stack56)
        %v33505_v32 = vsel /*vm=*/%vm33503_vm10, /*on_true_vy=*/%v33504_v23, /*on_false_vx=*/%v33502_v54 (stack76)
        %v34319_v10 = vadd.s32 %v34315_v52, %v34303_v20 (stack40)
        %v34321_v9 = vshll.u32 %v34315_v52, 13 (stack45)
        %v34322_v26 = vshrl.u32 %v34315_v52, 19 (stack46)
        %v33508_v12 = vadd.f32 -3.0, %v33505_v32 (stack53)
        %v33903_v42 = vmul.f32 %v33900_v7, %v132238_v21 (stack54)
        %v34708_v61 = vadd.s32 %v34705_v29, %v34700_v61 (stack40)
        %v132254_v41 = vadd.s32 %v132194_v8, %v122657_v58 (stack40)
        %v34323_v31 = vor.u32 %v34322_v26, %v34321_v9 (stack47)
        %v34710_v43 = vshll.u32 %v34705_v29, 26 (stack45)
        %v34711_v22 = vshrl.u32 %v34705_v29, 6 (stack46)
        %v35117_v40 = vadd.s32 %v35114_v27, %v35109_v40 (stack40)
        %v33489_v11 = vsel /*vm=*/%vm33456_vm6, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v33493_v23 = vsel /*vm=*/%vm33456_vm6, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v132265_v30 = vsel /*vm=*/%vm33456_vm6, /*on_true_vy=*/%v132214_v30, /*on_false_vx=*/%v33508_v12 (stack44)
        %v33905_v20 = vadd.f32 1.0, %v33903_v42 (stack57)
        %v33516_v52 = vmul.f32 %v132265_v30, %v33493_v23 (stack54)
        %v34324_v29 = vxor.u32 %v34323_v31, %v34319_v10 (stack48)
        %v34712_v54 = vor.u32 %v34711_v22, %v34710_v43 (stack47)
        %v35119_v7 = vshll.u32 %v35114_v27, 29 (stack45)
        %120717 = vlog2.f32 %v33905_v20 (stack58)
        %v33908_v32 = vmul.f32 -0.5, %v33903_v42 (stack59)
        %v35120_v27 = vshrl.u32 %v35114_v27, 3 (stack46)
        %vm35948_vm11 = vcmp.lt.u32.totalorder %v132254_v41, %v132194_v8 (stack43)
        %v35962_v9 = vadd.s32 1, %v35958_v25 (stack40)
        %v33520_v26 = vadd.f32 %v33516_v52, %v33489_v11 (stack53)
        %v34327_v10 = vadd.s32 %v34324_v29, %v34319_v10 (stack40)
        %v34329_v12 = vshll.u32 %v34324_v29, 15 (stack45)
        %v34330_v31 = vshrl.u32 %v34324_v29, 17 (stack46)
        %v33911_v43 = vand.u32 2147483647, %v33903_v42 (stack60)
        %v34713_v22 = vxor.u32 %v34712_v54, %v34708_v61 (stack48)
        %v35121_v11 = vor.u32 %v35120_v27, %v35119_v7 (stack47)
        %v35542_v24 = vadd.s32 %v35539_v6, %v132220_v24 (stack40)
        %v33524_v23 = vmul.f32 %v33520_v26, %v132265_v30 (stack54)
        %v34331_v20 = vor.u32 %v34330_v31, %v34329_v12 (stack47)
        %v35544_v52 = vshll.u32 %v35539_v6, 26 (stack45)
        %v35545_v6 = vshrl.u32 %v35539_v6, 6 (stack46)
        %v34716_v61 = vadd.s32 %v34713_v22, %v34708_v61 (stack40)
        %v34722_v29 = vshll.u32 %v34713_v22, 6 (stack45)
        %v34723_v54 = vshrl.u32 %v34713_v22, 26 (stack46)
        %v35122_v7 = vxor.u32 %v35121_v11, %v35117_v40 (stack48)
        %v33528_v60 = vadd.f32 %v33524_v23, %v33485_v60 (stack53)
        %v34332_v27 = vxor.u32 %v34331_v20, %v34327_v10 (stack48)
        %v35546_v26 = vor.u32 %v35545_v6, %v35544_v52 (stack47)
        %v35966_v25 = vsel /*vm=*/%vm35953_vm9, /*on_true_vy=*/%v35962_v9, /*on_false_vx=*/%v35958_v25 (stack44)
        %v33909_v32 = vadd.f32 1.0, %v33908_v32 (stack61)
        %v34724_v9 = vor.u32 %v34723_v54, %v34722_v29 (stack47)
        %v35125_v40 = vadd.s32 %v35122_v7, %v35117_v40 (stack40)
        %v35127_v12 = vshll.u32 %v35122_v7, 16 (stack45)
        %v33532_v31 = vmul.f32 %v33528_v60, %v132265_v30 (stack54)
        %v34335_v10 = vadd.s32 %v34332_v27, %v34327_v10 (stack40)
        %v34337_v22 = vshll.u32 %v34332_v27, 26 (stack45)
        %v34338_v11 = vshrl.u32 %v34332_v27, 6 (stack46)
        %v34725_v23 = vxor.u32 %v34724_v9, %v34716_v61 (stack48)
        %v35128_v20 = vshrl.u32 %v35122_v7, 16 (stack46)
        %v35547_v52 = vxor.u32 %v35546_v26, %v35542_v24 (stack48)
        %v35970_v6 = vadd.s32 1, %v35966_v25 (stack40)
        %v33536_v34 = vadd.f32 %v33532_v31, %v132230_v34 (stack53)
        %vm132277_vm12 = vcmp.lt.f32.partialorder %v33911_v43, 0.0004427343 (stack62)
        %v34339_v29 = vor.u32 %v34338_v11, %v34337_v22 (stack47)
        %v132283_v54 = vadd.s32 %v157269_v50, %v157089_v17 (stack40)
        %v33910_v42 = vmul.f32 %v33909_v32, %v33903_v42 (stack63)
        %v34728_v7 = vadd.s32 %v34725_v23, %v121569_v1 (stack40)
        %v35129_v60 = vor.u32 %v35128_v20, %v35127_v12 (stack47)
        %v132286_v24 = vadd.s32 %v35547_v52, %v35542_v24 (stack40)
        %v33540_v27 = vmul.f32 %v33536_v34, %v132265_v30 (stack54)
        %v34340_v26 = vxor.u32 %v34339_v29, %v34335_v10 (stack48)
        %v34720_v61 = vadd.s32 %v34716_v61, %v121574_v2 (stack40)
        %v35974_v8 = vsel /*vm=*/%vm35948_vm11, /*on_true_vy=*/%v35970_v6, /*on_false_vx=*/%v35966_v25 (stack44)
        %v34732_v25 = vadd.s32 3, %v34728_v7 (stack40)
        %v35130_v32 = vxor.u32 %v35129_v60, %v35125_v40 (stack48)
        %v35979_v9 = vadd.s32 %v35974_v8, %v121574_v2 (stack40)
        %v35983_v41 = vadd.s32 %v132254_v41, %v121569_v1 (stack40)
        %v120718_v12 = vpop.eup %120717 (stack64)
        %v33544_v44 = vadd.f32 %v33540_v27, %v132225_v44 (stack53)
        %v34343_v31 = vadd.s32 %v34340_v26, %v34335_v10 (stack40)
        %v34349_v10 = vshll.u32 %v34340_v26, 6 (stack45)
        %v34350_v22 = vshrl.u32 %v34340_v26, 26 (stack46)
        %v33907_v11 = vmul.f32 0.6931472, %v120718_v12 (stack65)
        %v34736_v23 = vadd.s32 %v34732_v25, %v34720_v61 (stack40)
        %v34738_v20 = vshll.u32 %v34732_v25, 17 (stack45)
        %v34739_v6 = vshrl.u32 %v34732_v25, 15 (stack46)
        %v33548_v34 = vmul.f32 %v33544_v44, %v132265_v30 (stack54)
        %v34351_v29 = vor.u32 %v34350_v22, %v34349_v10 (stack47)
        %v35133_v40 = vadd.s32 %v35130_v32, %v35125_v40 (stack40)
        %v35556_v7 = vshll.u32 %v35547_v52, 6 (stack45)
        %v33913_v43 = vsel /*vm=*/%vm132277_vm12, /*on_true_vy=*/%v33910_v42, /*on_false_vx=*/%v33907_v11 (stack66)
        %v34740_v42 = vor.u32 %v34739_v6, %v34738_v20 (stack47)
        %v35139_v60 = vshll.u32 %v35130_v32, 24 (stack45)
        %v35140_v27 = vshrl.u32 %v35130_v32, 8 (stack46)
        %v33552_v46 = vadd.f32 %v33548_v34, %v132211_v46 (stack53)
        %v132301_v26 = vxor.u32 2147483648, %v33913_v43 (stack56)
        %v34352_v61 = vxor.u32 %v34351_v29, %v34343_v31 (stack48)
        %v35557_v52 = vshrl.u32 %v35547_v52, 26 (stack46)
        %v33429_v8 = vand.u32 2147483647, %v132132_v53 (stack77)
        %v132305_v25 = vmul.f32 inf, %v132132_v53 (stack54)
        %v34741_v32 = vxor.u32 %v34740_v42, %v34736_v23 (stack48)
        %v132307_v9 = vadd.s32 %v35983_v41, %v35979_v9 (stack40)
        %v33461_v12 = vsel /*vm=*/%vm33456_vm6, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v33465_v44 = vsel /*vm=*/%vm33456_vm6, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v33556_v10 = vmul.f32 %v33552_v46, %v132265_v30 (stack54)
        %120719 = vrsqrt.f32 %v132301_v26 (stack67)
        %v33469_v55 = vsel /*vm=*/%vm33456_vm6, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %vm33917_vm13 = vcmp.lt.f32.partialorder %v132301_v26, 5.0 (stack68)
        %v34355_v22 = vadd.s32 %v34352_v61, %v121574_v2 (stack40)
        %v35141_v11 = vor.u32 %v35140_v27, %v35139_v60 (stack47)
        %v33560_v20 = vadd.f32 %v33556_v10, %v33469_v55 (stack53)
        %v33890_v6 = vand.u32 2147483647, %v132238_v21 (stack77)
        %v35554_v34 = vadd.s32 %v132286_v24, %v121569_v1 (stack40)
        %v35558_v29 = vor.u32 %v35557_v52, %v35556_v7 (stack47)
        %v132326_v7 = vadd.f32 -2.5, %v132301_v26 (stack53)
        %v34347_v31 = vadd.s32 %v34343_v31, %v121564_v0 (stack40)
        %v34744_v23 = vadd.s32 %v34741_v32, %v34736_v23 (stack40)
        %v35137_v43 = vadd.s32 %v35133_v40, %v121564_v0 (stack40)
        %v33564_v42 = vmul.f32 %v33560_v20, %v132265_v30 (stack54)
        %v132334_v60 = vsel /*vm=*/%vm33917_vm13, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v132339_v27 = vsel /*vm=*/%vm33917_vm13, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v132344_v46 = vsel /*vm=*/%vm33917_vm13, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %vm132346_vm14 = vcmp.eq.f32.partialorder %v33429_v8, 1.0 (stack68)
        %v34359_v52 = vadd.s32 5, %v34355_v22 (stack40)
        %v34746_v8 = vshll.u32 %v34741_v32, 29 (stack45)
        %v34747_v32 = vshrl.u32 %v34741_v32, 3 (stack46)
        %v35142_v40 = vxor.u32 %v35141_v11, %v35133_v40 (stack48)
        %v33568_v44 = vadd.f32 %v33564_v42, %v33465_v44 (stack53)
        %v35559_v24 = vxor.u32 %v35558_v29, %v132286_v24 (stack48)
        %v35989_v10 = vshll.u32 %v35983_v41, 13 (stack45)
        %v35990_v41 = vshrl.u32 %v35983_v41, 19 (stack46)
        %vm33962_vm15 = vcmp.eq.f32.partialorder %v132301_v26, inf (stack70)
        %v34361_v55 = vxor.u32 %v34359_v52, %v34347_v31 (stack48)
        %v34748_v22 = vor.u32 %v34747_v32, %v34746_v8 (stack47)
        %v35145_v11 = vadd.s32 %v35142_v40, %v121574_v2 (stack40)
        %v33572_v30 = vmul.f32 %v33568_v44, %v132265_v30 (stack54)
        %v35562_v20 = vadd.s32 %v35559_v24, %v121564_v0 (stack40)
        %v35991_v29 = vor.u32 %v35990_v41, %v35989_v10 (stack47)
        %vm36414_vm0 = vcmp.lt.u32.totalorder %v132283_v54, %v157089_v17 (stack43)
        %v33965_v31 = vand.u32 2147483648, %v132301_v26 (stack72)
        %v34362_v42 = vand.u32.u8 255, %v34361_v55 (stack49)
        %v34749_v52 = vxor.u32 %v34748_v22, %v34744_v23 (stack48)
        %v35149_v8 = vadd.s32 2, %v35145_v11 (stack40)
        %v33576_v12 = vadd.f32 %v33572_v30, %v33461_v12 (stack53)
        %v35566_v32 = vadd.s32 1, %v35562_v20 (stack40)
        %v35992_v40 = vxor.u32 %v35991_v29, %v132307_v9 (stack48)
        %v36419_v44 = vadd.s32 %v157270_v56, %v157090_v62 (stack40)
        %v34363_v24 = vand.u32 65535, %v34362_v42 (stack50)
        %v34752_v23 = vadd.s32 %v34749_v52, %v34744_v23 (stack40)
        %v34754_v10 = vshll.u32 %v34749_v52, 16 (stack45)
        %v34755_v41 = vshrl.u32 %v34749_v52, 16 (stack46)
        %v33580_v53 = vmul.f32 %v33576_v12, %v132132_v53 (stack54)
        %v35153_v43 = vadd.s32 %v35149_v8, %v35137_v43 (stack40)
        %v35155_v55 = vshll.u32 %v35149_v8, 13 (stack45)
        %v35156_v22 = vshrl.u32 %v35149_v8, 19 (stack46)
        %v120720_v11 = vpop.eup %120719 (stack73)
        %v34364_v30 = vshrl.u32 %v34363_v24, 1 (stack51)
        %v34756_v20 = vor.u32 %v34755_v41, %v34754_v10 (stack47)
        %v35570_v34 = vadd.s32 %v35566_v32, %v35554_v34 (stack40)
        %v35572_v29 = vshll.u32 %v35566_v32, 17 (stack45)
        %v33584_v25 = vsel /*vm=*/%vm132346_vm14, /*on_true_vy=*/%v132305_v25, /*on_false_vx=*/%v33580_v53 (stack44)
        %v33961_v61 = vmul.f32 %v120720_v11, %v132301_v26 (stack74)
        %v35157_v42 = vor.u32 %v35156_v22, %v35155_v55 (stack47)
        %v35573_v52 = vshrl.u32 %v35566_v32, 15 (stack46)
        %v33588_v8 = vmul.f32 1.4140625, %v33584_v25 (stack54)
        %v34365_v12 = vor.u32 16256, %v34364_v30 (stack47)
        %v34757_v32 = vxor.u32 %v34756_v20, %v34752_v23 (stack48)
        %v132367_v9 = vadd.s32 %v35992_v40, %v132307_v9 (stack40)
        %v33963_v24 = vsel /*vm=*/%vm33962_vm15, /*on_true_vy=*/%v132301_v26, /*on_false_vx=*/%v33961_v61 (stack75)
        %vm33964_vm1 = vcmp.eq.f32.partialorder %v132301_v26, 0.0 (stack71)
        %v35158_v10 = vxor.u32 %v35157_v42, %v35153_v43 (stack48)
        %v35574_v41 = vor.u32 %v35573_v52, %v35572_v29 (stack47)
        %v33591_v53 = vpack.c.bf16 %v156663_v45, %v33588_v8 (stack81)
        %v33966_v31 = vsel /*vm=*/%vm33964_vm1, /*on_true_vy=*/%v33965_v31, /*on_false_vx=*/%v33963_v24 (stack76)
        %v34366_v55 = vand.u32.u16 65535, %v34365_v12 (stack52)
        %v34760_v23 = vadd.s32 %v34757_v32, %v34752_v23 (stack40)
        %v33969_v22 = vadd.f32 -3.0, %v33966_v31 (stack53)
        %v34766_v11 = vshll.u32 %v34757_v32, 24 (stack45)
        %v34767_v30 = vshrl.u32 %v34757_v32, 8 (stack46)
        %v35161_v43 = vadd.s32 %v35158_v10, %v35153_v43 (stack40)
        %119921 = vst [vmem:[%s123356_s30 + $0x320] sm:$0xf] /*vst_source=*/%v33591_v53 (stack83)
        %v119928_v20 = vadd.low.f32.bf16 -1.0, %v34366_v55 (stack53)
        %v35163_v29 = vshll.u32 %v35158_v10, 15 (stack45)
        %v35164_v25 = vshrl.u32 %v35158_v10, 17 (stack46)
        %v35997_v61 = vshll.u32 %v35992_v40, 15 (stack45)
        %v132378_v7 = vsel /*vm=*/%vm33917_vm13, /*on_true_vy=*/%v132326_v7, /*on_false_vx=*/%v33969_v22 (stack44)
        %v34768_v42 = vor.u32 %v34767_v30, %v34766_v11 (stack47)
        %v35575_v52 = vxor.u32 %v35574_v41, %v35570_v34 (stack48)
        %v35998_v40 = vshrl.u32 %v35992_v40, 17 (stack46)
        %v33977_v46 = vmul.f32 %v132378_v7, %v132344_v46 (stack54)
        %v34375_v8 = vmul.f32 2.0, %v119928_v20 (stack54)
        %v35165_v12 = vor.u32 %v35164_v25, %v35163_v29 (stack47)
        %v36423_v32 = vadd.s32 1, %v36419_v44 (stack40)
        %v34769_v24 = vxor.u32 %v34768_v42, %v34760_v23 (stack48)
        %v35578_v34 = vadd.s32 %v35575_v52, %v35570_v34 (stack40)
        %v35580_v10 = vshll.u32 %v35575_v52, 29 (stack45)
        %v35581_v41 = vshrl.u32 %v35575_v52, 3 (stack46)
        %v33981_v27 = vadd.f32 %v33977_v46, %v132339_v27 (stack53)
        %v34379_v53 = vadd.f32 -0.99609375, %v34375_v8 (stack53)
        %v35166_v31 = vxor.u32 %v35165_v12, %v35161_v43 (stack48)
        %v35999_v55 = vor.u32 %v35998_v40, %v35997_v61 (stack47)
        %v34764_v23 = vadd.s32 %v34760_v23, %v121569_v1 (stack40)
        %v34772_v22 = vadd.s32 %v34769_v24, %v121564_v0 (stack40)
        %v35582_v11 = vor.u32 %v35581_v41, %v35580_v10 (stack47)
        %v132388_v44 = vsel /*vm=*/%vm36414_vm0, /*on_true_vy=*/%v36423_v32, /*on_false_vx=*/%v36419_v44 (stack44)
        %v33985_v30 = vmul.f32 %v33981_v27, %v132378_v7 (stack54)
        %v132391_v20 = vmax.f32 %v34379_v53, -0.99609375 (stack55)
        %v35169_v43 = vadd.s32 %v35166_v31, %v35161_v43 (stack40)
        %v35171_v29 = vshll.u32 %v35166_v31, 26 (stack45)
        %v34776_v25 = vadd.s32 4, %v34772_v22 (stack40)
        %v35172_v61 = vshrl.u32 %v35166_v31, 6 (stack46)
        %v35583_v42 = vxor.u32 %v35582_v11, %v35578_v34 (stack48)
        %v36000_v52 = vxor.u32 %v35999_v55, %v132367_v9 (stack48)
        %v132397_v40 = vsel /*vm=*/%vm33917_vm13, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v132402_v46 = vsel /*vm=*/%vm33917_vm13, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v33989_v60 = vadd.f32 %v33985_v30, %v132334_v60 (stack53)
        %v34395_v8 = vxor.u32 2147483648, %v132391_v20 (stack56)
        %v34780_v12 = vadd.s32 %v34776_v25, %v34764_v23 (stack40)
        %v34782_v32 = vshll.u32 %v34776_v25, 13 (stack45)
        %v34783_v24 = vshrl.u32 %v34776_v25, 19 (stack46)
        %v35173_v10 = vor.u32 %v35172_v61, %v35171_v29 (stack47)
        %v33930_v41 = vsel /*vm=*/%vm33917_vm13, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v33993_v27 = vmul.f32 %v33989_v60, %v132378_v7 (stack54)
        %v132411_v53 = vmul.f32 %v34395_v8, %v132391_v20 (stack54)
        %v35586_v34 = vadd.s32 %v35583_v42, %v35578_v34 (stack40)
        %v33942_v31 = vsel /*vm=*/%vm33917_vm13, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v34784_v55 = vor.u32 %v34783_v24, %v34782_v32 (stack47)
        %v35174_v23 = vxor.u32 %v35173_v10, %v35169_v43 (stack48)
        %v36405_v22 = vadd.s32 %v132283_v54, %v122657_v58 (stack40)
        %v33997_v11 = vadd.f32 %v33993_v27, %v33942_v31 (stack53)
        %v34400_v30 = vadd.f32 1.0, %v132411_v53 (stack57)
        %v35588_v29 = vshll.u32 %v35583_v42, 16 (stack45)
        %v35589_v25 = vshrl.u32 %v35583_v42, 16 (stack46)
        %v34785_v61 = vxor.u32 %v34784_v55, %v34780_v12 (stack48)
        %v35177_v43 = vadd.s32 %v35174_v23, %v35169_v43 (stack40)
        %v35183_v42 = vshll.u32 %v35174_v23, 6 (stack45)
        %v35184_v60 = vshrl.u32 %v35174_v23, 26 (stack46)
        %v33934_v8 = vsel /*vm=*/%vm33917_vm13, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v33938_v26 = vsel /*vm=*/%vm33917_vm13, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v34001_v32 = vmul.f32 %v33997_v11, %v132378_v7 (stack54)
        %120721 = vlog2.f32 %v34400_v30 (stack58)
        %v34788_v12 = vadd.s32 %v34785_v61, %v34780_v12 (stack40)
        %v34790_v24 = vshll.u32 %v34785_v61, 15 (stack45)
        %v34791_v10 = vshrl.u32 %v34785_v61, 17 (stack46)
        %vm36409_vm2 = vcmp.lt.u32.totalorder %v36405_v22, %v132283_v54 (stack43)
        %v34005_v27 = vadd.f32 %v34001_v32, %v33938_v26 (stack53)
        %v35185_v31 = vor.u32 %v35184_v60, %v35183_v42 (stack47)
        %v35590_v55 = vor.u32 %v35589_v25, %v35588_v29 (stack47)
        %v132428_v23 = vadd.s32 %v36405_v22, %v121569_v1 (stack40)
        %v34792_v11 = vor.u32 %v34791_v10, %v34790_v24 (stack47)
        %v36003_v9 = vadd.s32 %v36000_v52, %v132367_v9 (stack40)
        %v36005_v30 = vshll.u32 %v36000_v52, 26 (stack45)
        %v36006_v52 = vshrl.u32 %v36000_v52, 6 (stack46)
        %v34009_v29 = vmul.f32 %v34005_v27, %v132378_v7 (stack54)
        %v34403_v25 = vmul.f32 -0.5, %v132411_v53 (stack59)
        %v35186_v61 = vxor.u32 %v35185_v31, %v35177_v43 (stack48)
        %v35591_v42 = vxor.u32 %v35590_v55, %v35586_v34 (stack48)
        %v34406_v60 = vand.u32 2147483647, %v132411_v53 (stack60)
        %v34793_v26 = vxor.u32 %v34792_v11, %v34788_v12 (stack48)
        %v36007_v32 = vor.u32 %v36006_v52, %v36005_v30 (stack47)
        %v36431_v24 = vadd.s32 1, %v132388_v44 (stack40)
        %v34013_v8 = vadd.f32 %v34009_v29, %v33934_v8 (stack53)
        %v35189_v10 = vadd.s32 %v35186_v61, %v121569_v1 (stack40)
        %v35594_v34 = vadd.s32 %v35591_v42, %v35586_v34 (stack40)
        %v35600_v27 = vshll.u32 %v35591_v42, 24 (stack45)
        %v34796_v12 = vadd.s32 %v34793_v26, %v34788_v12 (stack40)
        %v34798_v31 = vshll.u32 %v34793_v26, 26 (stack45)
        %v34799_v55 = vshrl.u32 %v34793_v26, 6 (stack46)
        %v35601_v11 = vshrl.u32 %v35591_v42, 8 (stack46)
        %v34017_v30 = vmul.f32 %v34013_v8, %v132378_v7 (stack54)
        %v35181_v43 = vadd.s32 %v35177_v43, %v121574_v2 (stack40)
        %v35193_v52 = vadd.s32 3, %v35189_v10 (stack40)
        %v36008_v29 = vxor.u32 %v36007_v32, %v36003_v9 (stack48)
        %v34404_v25 = vadd.f32 1.0, %v34403_v25 (stack61)
        %v34800_v61 = vor.u32 %v34799_v55, %v34798_v31 (stack47)
        %v35602_v42 = vor.u32 %v35601_v11, %v35600_v27 (stack47)
        %v36435_v54 = vsel /*vm=*/%vm36409_vm2, /*on_true_vy=*/%v36431_v24, /*on_false_vx=*/%v132388_v44 (stack44)
        %v34021_v44 = vadd.f32 %v34017_v30, %v33930_v41 (stack53)
        %v35197_v41 = vadd.s32 %v35193_v52, %v35181_v43 (stack40)
        %v35199_v22 = vshll.u32 %v35193_v52, 17 (stack45)
        %v35200_v26 = vshrl.u32 %v35193_v52, 15 (stack46)
        %v34801_v32 = vxor.u32 %v34800_v61, %v34796_v12 (stack48)
        %v35603_v24 = vxor.u32 %v35602_v42, %v35594_v34 (stack48)
        %v36011_v9 = vadd.s32 %v36008_v29, %v36003_v9 (stack40)
        %v36017_v8 = vshll.u32 %v36008_v29, 6 (stack45)
        %v34025_v10 = vmul.f32 %v34021_v44, %v132378_v7 (stack54)
        %vm132442_vm3 = vcmp.lt.f32.partialorder %v34406_v60, 0.0004427343 (stack62)
        %v35201_v27 = vor.u32 %v35200_v26, %v35199_v22 (stack47)
        %v36018_v31 = vshrl.u32 %v36008_v29, 26 (stack46)
        %v120722_v55 = vpop.eup %120721 (stack64)
        %v34804_v12 = vadd.s32 %v34801_v32, %v34796_v12 (stack40)
        %v34810_v11 = vshll.u32 %v34801_v32, 6 (stack45)
        %v34811_v30 = vshrl.u32 %v34801_v32, 26 (stack46)
        %v35606_v43 = vadd.s32 %v35603_v24, %v121574_v2 (stack40)
        %v34029_v46 = vadd.f32 %v34025_v10, %v132402_v46 (stack53)
        %v34402_v52 = vmul.f32 0.6931472, %v120722_v55 (stack65)
        %v34405_v53 = vmul.f32 %v34404_v25, %v132411_v53 (stack63)
        %v35202_v29 = vxor.u32 %v35201_v27, %v35197_v41 (stack48)
        %v34812_v25 = vor.u32 %v34811_v30, %v34810_v11 (stack47)
        %v35598_v34 = vadd.s32 %v35594_v34, %v121564_v0 (stack40)
        %v35610_v61 = vadd.s32 2, %v35606_v43 (stack40)
        %v36019_v42 = vor.u32 %v36018_v31, %v36017_v8 (stack47)
        %v34033_v7 = vmul.f32 %v34029_v46, %v132378_v7 (stack54)
        %v34408_v44 = vsel /*vm=*/%vm132442_vm3, /*on_true_vy=*/%v34405_v53, /*on_false_vx=*/%v34402_v52 (stack66)
        %v35205_v41 = vadd.s32 %v35202_v29, %v35197_v41 (stack40)
        %v36450_v22 = vshll.u32 %v132428_v23, 13 (stack45)
        %v132454_v26 = vxor.u32 2147483648, %v34408_v44 (stack56)
        %v34813_v32 = vxor.u32 %v34812_v25, %v34804_v12 (stack48)
        %v35614_v24 = vadd.s32 %v35610_v61, %v35598_v34 (stack40)
        %v36451_v8 = vshrl.u32 %v132428_v23, 19 (stack46)
        %vm132459_vm4 = vcmp.eq.f32.partialorder %v33890_v6, 1.0 (stack68)
        %v33898_v10 = vmul.f32 inf, %v132238_v21 (stack54)
        %v34037_v40 = vadd.f32 %v34033_v7, %v132397_v40 (stack53)
        %v36020_v60 = vxor.u32 %v36019_v42, %v36011_v9 (stack48)
        %vm34412_vm5 = vcmp.lt.f32.partialorder %v132454_v26, 5.0 (stack68)
        %120723 = vrsqrt.f32 %v132454_v26 (stack67)
        %v35207_v27 = vshll.u32 %v35202_v29, 29 (stack45)
        %v36440_v54 = vadd.s32 %v36435_v54, %v121574_v2 (stack40)
        %v34041_v21 = vmul.f32 %v34037_v40, %v132238_v21 (stack54)
        %v35208_v31 = vshrl.u32 %v35202_v29, 3 (stack46)
        %v35616_v55 = vshll.u32 %v35610_v61, 13 (stack45)
        %v35617_v11 = vshrl.u32 %v35610_v61, 19 (stack46)
        %v34385_v30 = vand.u32 2147483647, %v132391_v20 (stack77)
        %v34816_v43 = vadd.s32 %v34813_v32, %v121574_v2 (stack40)
        %v36015_v9 = vadd.s32 %v36011_v9, %v121569_v1 (stack40)
        %v36452_v46 = vor.u32 %v36451_v8, %v36450_v22 (stack47)
        %v34045_v52 = vsel /*vm=*/%vm132459_vm4, /*on_true_vy=*/%v33898_v10, /*on_false_vx=*/%v34041_v21 (stack44)
        %v132477_v53 = vsel /*vm=*/%vm34412_vm5, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v132480_v29 = vadd.f32 -2.5, %v132454_v26 (stack53)
        %v34808_v12 = vadd.s32 %v34804_v12, %v121564_v0 (stack40)
        %v34049_v25 = vmul.f32 1.4140625, %v34045_v52 (stack54)
        %v132486_v34 = vsel /*vm=*/%vm34412_vm5, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v132491_v61 = vsel /*vm=*/%vm34412_vm5, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v34820_v42 = vadd.s32 5, %v34816_v43 (stack40)
        %v35209_v7 = vor.u32 %v35208_v31, %v35207_v27 (stack47)
        %v35618_v44 = vor.u32 %v35617_v11, %v35616_v55 (stack47)
        %v36023_v22 = vadd.s32 %v36020_v60, %v121564_v0 (stack40)
        %v36448_v23 = vadd.s32 %v132428_v23, %v36440_v54 (stack40)
        %v34052_v32 = vpack.c.bf16 %v156663_v45, %v34049_v25 (stack81)
        %v34822_v8 = vxor.u32 %v34820_v42, %v34808_v12 (stack48)
        %v132498_v6 = vadd.s32 %v157269_v50, %v157091_v37 (stack40)
        %v36880_v10 = vadd.s32 %v157270_v56, %v157094_v36 (stack40)
        %vm34457_vm6 = vcmp.eq.f32.partialorder %v132454_v26, inf (stack70)
        %v35210_v40 = vxor.u32 %v35209_v7, %v35205_v41 (stack48)
        %v35619_v60 = vxor.u32 %v35618_v44, %v35614_v24 (stack48)
        %v36027_v27 = vadd.s32 1, %v36023_v22 (stack40)
        %v36453_v54 = vxor.u32 %v36452_v46, %v36448_v23 (stack48)
        %119923 = vst [vmem:[%s123356_s30 + $0x3a0] sm:$0xf] /*vst_source=*/%v34052_v32 (stack83)
        %vm34459_vm7 = vcmp.eq.f32.partialorder %v132454_v26, 0.0 (stack71)
        %v34823_v21 = vand.u32.u8 255, %v34822_v8 (stack49)
        %vm36875_vm8 = vcmp.lt.u32.totalorder %v132498_v6, %v157091_v37 (stack43)
        %v36884_v31 = vadd.s32 1, %v36880_v10 (stack40)
        %v35213_v41 = vadd.s32 %v35210_v40, %v35205_v41 (stack40)
        %v35215_v55 = vshll.u32 %v35210_v40, 16 (stack45)
        %v35216_v11 = vshrl.u32 %v35210_v40, 16 (stack46)
        %v35622_v24 = vadd.s32 %v35619_v60, %v35614_v24 (stack40)
        %v34824_v43 = vand.u32 65535, %v34823_v21 (stack50)
        %v35624_v46 = vshll.u32 %v35619_v60, 15 (stack45)
        %v35625_v52 = vshrl.u32 %v35619_v60, 17 (stack46)
        %v36031_v9 = vadd.s32 %v36027_v27, %v36015_v9 (stack40)
        %v35217_v12 = vor.u32 %v35216_v11, %v35215_v55 (stack47)
        %v36033_v25 = vshll.u32 %v36027_v27, 17 (stack45)
        %v36034_v42 = vshrl.u32 %v36027_v27, 15 (stack46)
        %v36456_v7 = vadd.s32 %v36453_v54, %v36448_v23 (stack40)
        %v34825_v44 = vshrl.u32 %v34824_v43, 1 (stack51)
        %v35626_v22 = vor.u32 %v35625_v52, %v35624_v46 (stack47)
        %v36458_v23 = vshll.u32 %v36453_v54, 15 (stack45)
        %v36459_v32 = vshrl.u32 %v36453_v54, 17 (stack46)
        %v120724_v8 = vpop.eup %120723 (stack73)
        %v34460_v40 = vand.u32 2147483648, %v132454_v26 (stack72)
        %v35218_v60 = vxor.u32 %v35217_v12, %v35213_v41 (stack48)
        %v36035_v27 = vor.u32 %v36034_v42, %v36033_v25 (stack47)
        %v132511_v10 = vsel /*vm=*/%vm36875_vm8, /*on_true_vy=*/%v36884_v31, /*on_false_vx=*/%v36880_v10 (stack44)
        %v34456_v54 = vmul.f32 %v120724_v8, %v132454_v26 (stack74)
        %v34826_v21 = vor.u32 16256, %v34825_v44 (stack47)
        %v35627_v31 = vxor.u32 %v35626_v22, %v35622_v24 (stack48)
        %v36460_v55 = vor.u32 %v36459_v32, %v36458_v23 (stack47)
        %v35221_v41 = vadd.s32 %v35218_v60, %v35213_v41 (stack40)
        %v35227_v11 = vshll.u32 %v35218_v60, 24 (stack45)
        %v35228_v43 = vshrl.u32 %v35218_v60, 8 (stack46)
        %v36036_v46 = vxor.u32 %v36035_v27, %v36031_v9 (stack48)
        %v34458_v52 = vsel /*vm=*/%vm34457_vm6, /*on_true_vy=*/%v132454_v26, /*on_false_vx=*/%v34456_v54 (stack75)
        %v34827_v12 = vand.u32.u16 65535, %v34826_v21 (stack52)
        %v35630_v24 = vadd.s32 %v35627_v31, %v35622_v24 (stack40)
        %v35632_v25 = vshll.u32 %v35627_v31, 26 (stack45)
        %v34445_v42 = vsel /*vm=*/%vm34412_vm5, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v34461_v44 = vsel /*vm=*/%vm34459_vm7, /*on_true_vy=*/%v34460_v40, /*on_false_vx=*/%v34458_v52 (stack76)
        %v35229_v22 = vor.u32 %v35228_v43, %v35227_v11 (stack47)
        %v35633_v23 = vshrl.u32 %v35627_v31, 6 (stack46)
        %v34464_v32 = vadd.f32 -3.0, %v34461_v44 (stack53)
        %v119930_v8 = vadd.low.f32.bf16 -1.0, %v34827_v12 (stack53)
        %v36039_v9 = vadd.s32 %v36036_v46, %v36031_v9 (stack40)
        %v36041_v40 = vshll.u32 %v36036_v46, 29 (stack45)
        %v35230_v60 = vxor.u32 %v35229_v22, %v35221_v41 (stack48)
        %v35634_v27 = vor.u32 %v35633_v23, %v35632_v25 (stack47)
        %v36042_v54 = vshrl.u32 %v36036_v46, 3 (stack46)
        %v36461_v21 = vxor.u32 %v36460_v55, %v36456_v7 (stack48)
        %v34449_v31 = vsel /*vm=*/%vm34412_vm5, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v132528_v29 = vsel /*vm=*/%vm34412_vm5, /*on_true_vy=*/%v132480_v29, /*on_false_vx=*/%v34464_v32 (stack44)
        %v34836_v55 = vmul.f32 2.0, %v119930_v8 (stack54)
        %v35225_v41 = vadd.s32 %v35221_v41, %v121569_v1 (stack40)
        %v34472_v11 = vmul.f32 %v132528_v29, %v34449_v31 (stack54)
        %v35233_v43 = vadd.s32 %v35230_v60, %v121564_v0 (stack40)
        %v35635_v46 = vxor.u32 %v35634_v27, %v35630_v24 (stack48)
        %v36043_v52 = vor.u32 %v36042_v54, %v36041_v40 (stack47)
        %v34840_v12 = vadd.f32 -0.99609375, %v34836_v55 (stack53)
        %v36464_v7 = vadd.s32 %v36461_v21, %v36456_v7 (stack40)
        %v36466_v25 = vshll.u32 %v36461_v21, 26 (stack45)
        %v36467_v44 = vshrl.u32 %v36461_v21, 6 (stack46)
        %v34476_v42 = vadd.f32 %v34472_v11, %v34445_v42 (stack53)
        %v35237_v22 = vadd.s32 4, %v35233_v43 (stack40)
        %v35638_v24 = vadd.s32 %v35635_v46, %v35630_v24 (stack40)
        %v35644_v23 = vshll.u32 %v35635_v46, 6 (stack45)
        %v132533_v32 = vmax.f32 %v34840_v12, -0.99609375 (stack55)
        %v35645_v8 = vshrl.u32 %v35635_v46, 26 (stack46)
        %v36044_v40 = vxor.u32 %v36043_v52, %v36039_v9 (stack48)
        %v36468_v60 = vor.u32 %v36467_v44, %v36466_v25 (stack47)
        %v34480_v27 = vmul.f32 %v34476_v42, %v132528_v29 (stack54)
        %v35241_v54 = vadd.s32 %v35237_v22, %v35225_v41 (stack40)
        %v35243_v21 = vshll.u32 %v35237_v22, 13 (stack45)
        %v35244_v31 = vshrl.u32 %v35237_v22, 19 (stack46)
        %v34433_v55 = vsel /*vm=*/%vm34412_vm5, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v34441_v41 = vsel /*vm=*/%vm34412_vm5, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v34856_v11 = vxor.u32 2147483648, %v132533_v32 (stack56)
        %v36866_v43 = vadd.s32 %v132498_v6, %v122657_v58 (stack40)
        %v34484_v46 = vadd.f32 %v34480_v27, %v34441_v41 (stack53)
        %v35245_v52 = vor.u32 %v35244_v31, %v35243_v21 (stack47)
        %v35646_v12 = vor.u32 %v35645_v8, %v35644_v23 (stack47)
        %v36047_v9 = vadd.s32 %v36044_v40, %v36039_v9 (stack40)
        %v34437_v25 = vsel /*vm=*/%vm34412_vm5, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v132549_v44 = vmul.f32 %v34856_v11, %v132533_v32 (stack54)
        %v36049_v42 = vshll.u32 %v36044_v40, 16 (stack45)
        %v36050_v22 = vshrl.u32 %v36044_v40, 16 (stack46)
        %v34488_v23 = vmul.f32 %v34484_v46, %v132528_v29 (stack54)
        %v35246_v8 = vxor.u32 %v35245_v52, %v35241_v54 (stack48)
        %v35647_v40 = vxor.u32 %v35646_v12, %v35638_v24 (stack48)
        %v36469_v60 = vxor.u32 %v36468_v60, %v36464_v7 (stack48)
        %v34861_v27 = vadd.f32 1.0, %v132549_v44 (stack57)
        %v36051_v21 = vor.u32 %v36050_v22, %v36049_v42 (stack47)
        %vm36870_vm9 = vcmp.lt.u32.totalorder %v36866_v43, %v132498_v6 (stack43)
        %v36892_v31 = vadd.s32 1, %v132511_v10 (stack40)
        %v34492_v41 = vadd.f32 %v34488_v23, %v34437_v25 (stack53)
        %v35249_v54 = vadd.s32 %v35246_v8, %v35241_v54 (stack40)
        %v35251_v11 = vshll.u32 %v35246_v8, 15 (stack45)
        %v35252_v46 = vshrl.u32 %v35246_v8, 17 (stack46)
        %120725 = vlog2.f32 %v34861_v27 (stack58)
        %v34864_v52 = vmul.f32 -0.5, %v132549_v44 (stack59)
        %v35642_v24 = vadd.s32 %v35638_v24, %v121574_v2 (stack40)
        %v35650_v12 = vadd.s32 %v35647_v40, %v121569_v1 (stack40)
        %v34496_v25 = vmul.f32 %v34492_v41, %v132528_v29 (stack54)
        %v35253_v42 = vor.u32 %v35252_v46, %v35251_v11 (stack47)
        %v36052_v22 = vxor.u32 %v36051_v21, %v36047_v9 (stack48)
        %v36472_v7 = vadd.s32 %v36469_v60, %v36464_v7 (stack40)
        %v34867_v23 = vand.u32 2147483647, %v132549_v44 (stack60)
        %v35654_v8 = vadd.s32 3, %v35650_v12 (stack40)
        %v36478_v40 = vshll.u32 %v36469_v60, 6 (stack45)
        %v36479_v60 = vshrl.u32 %v36469_v60, 26 (stack46)
        %v34500_v55 = vadd.f32 %v34496_v25, %v34433_v55 (stack53)
        %v35254_v27 = vxor.u32 %v35253_v42, %v35249_v54 (stack48)
        %v36055_v9 = vadd.s32 %v36052_v22, %v36047_v9 (stack40)
        %v36061_v21 = vshll.u32 %v36052_v22, 24 (stack45)
        %v35658_v41 = vadd.s32 %v35654_v8, %v35642_v24 (stack40)
        %v35660_v11 = vshll.u32 %v35654_v8, 17 (stack45)
        %v35661_v46 = vshrl.u32 %v35654_v8, 15 (stack46)
        %v36062_v24 = vshrl.u32 %v36052_v22, 8 (stack46)
        %v34504_v12 = vmul.f32 %v34500_v55, %v132528_v29 (stack54)
        %v35257_v54 = vadd.s32 %v35254_v27, %v35249_v54 (stack40)
        %v35259_v25 = vshll.u32 %v35254_v27, 26 (stack45)
        %v35260_v42 = vshrl.u32 %v35254_v27, 6 (stack46)
        %v34865_v52 = vadd.f32 1.0, %v34864_v52 (stack61)
        %v35662_v22 = vor.u32 %v35661_v46, %v35660_v11 (stack47)
        %v36063_v8 = vor.u32 %v36062_v24, %v36061_v21 (stack47)
        %v36905_v55 = vadd.s32 %v36866_v43, %v121569_v1 (stack40)
        %v34508_v61 = vadd.f32 %v34504_v12, %v132491_v61 (stack53)
        %v35261_v27 = vor.u32 %v35260_v42, %v35259_v25 (stack47)
        %v36480_v40 = vor.u32 %v36479_v60, %v36478_v40 (stack47)
        %v36896_v6 = vsel /*vm=*/%vm36870_vm9, /*on_true_vy=*/%v36892_v31, /*on_false_vx=*/%v132511_v10 (stack44)
        %vm132566_vm10 = vcmp.lt.f32.partialorder %v34867_v23, 0.0004427343 (stack62)
        %v35663_v43 = vxor.u32 %v35662_v22, %v35658_v41 (stack48)
        %v36064_v31 = vxor.u32 %v36063_v8, %v36055_v9 (stack48)
        %v36901_v23 = vadd.s32 %v36896_v6, %v121574_v2 (stack40)
        %v34512_v60 = vmul.f32 %v34508_v61, %v132528_v29 (stack54)
        %v35262_v21 = vxor.u32 %v35261_v27, %v35257_v54 (stack48)
        %v36059_v9 = vadd.s32 %v36055_v9, %v121564_v0 (stack40)
        %v36481_v11 = vxor.u32 %v36480_v40, %v36472_v7 (stack48)
        %v35666_v41 = vadd.s32 %v35663_v43, %v35658_v41 (stack40)
        %v35668_v46 = vshll.u32 %v35663_v43, 29 (stack45)
        %v35669_v24 = vshrl.u32 %v35663_v43, 3 (stack46)
        %v36067_v12 = vadd.s32 %v36064_v31, %v121574_v2 (stack40)
        %v34516_v34 = vadd.f32 %v34512_v60, %v132486_v34 (stack53)
        %v35265_v54 = vadd.s32 %v35262_v21, %v35257_v54 (stack40)
        %v35271_v25 = vshll.u32 %v35262_v21, 6 (stack45)
        %v35272_v42 = vshrl.u32 %v35262_v21, 26 (stack46)
        %v35670_v22 = vor.u32 %v35669_v24, %v35668_v46 (stack47)
        %v36071_v8 = vadd.s32 2, %v36067_v12 (stack40)
        %v36484_v61 = vadd.s32 %v36481_v11, %v121564_v0 (stack40)
        %v132576_v27 = vadd.s32 %v36905_v55, %v36901_v23 (stack40)
        %v120726_v40 = vpop.eup %120725 (stack64)
        %v34520_v6 = vmul.f32 %v34516_v34, %v132528_v29 (stack54)
        %v34866_v44 = vmul.f32 %v34865_v52, %v132549_v44 (stack63)
        %v35273_v52 = vor.u32 %v35272_v42, %v35271_v25 (stack47)
        %v36476_v7 = vadd.s32 %v36472_v7, %v121569_v1 (stack40)
        %v34863_v43 = vmul.f32 0.6931472, %v120726_v40 (stack65)
        %v35671_v31 = vxor.u32 %v35670_v22, %v35666_v41 (stack48)
        %v36075_v23 = vadd.s32 %v36071_v8, %v36059_v9 (stack40)
        %v36911_v60 = vshll.u32 %v36905_v55, 13 (stack45)
        %v34524_v53 = vadd.f32 %v34520_v6, %v132477_v53 (stack53)
        %v35274_v21 = vxor.u32 %v35273_v52, %v35265_v54 (stack48)
        %v36488_v9 = vadd.s32 1, %v36484_v61 (stack40)
        %v36912_v55 = vshrl.u32 %v36905_v55, 19 (stack46)
        %v34869_v10 = vsel /*vm=*/%vm132566_vm10, /*on_true_vy=*/%v34866_v44, /*on_false_vx=*/%v34863_v43 (stack66)
        %v35674_v11 = vadd.s32 %v35671_v31, %v35666_v41 (stack40)
        %v35676_v41 = vshll.u32 %v35671_v31, 16 (stack45)
        %v35677_v46 = vshrl.u32 %v35671_v31, 16 (stack46)
        %v34528_v29 = vmul.f32 %v34524_v53, %v132528_v29 (stack54)
        %v132585_v24 = vxor.u32 2147483648, %v34869_v10 (stack56)
        %v36077_v12 = vshll.u32 %v36071_v8, 13 (stack45)
        %v36078_v34 = vshrl.u32 %v36071_v8, 19 (stack46)
        %v34417_v26 = vsel /*vm=*/%vm34412_vm5, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v35678_v25 = vor.u32 %v35677_v46, %v35676_v41 (stack47)
        %v36492_v42 = vadd.s32 %v36488_v9, %v36476_v7 (stack40)
        %v34393_v22 = vmul.f32 inf, %v132391_v20 (stack54)
        %v34532_v8 = vadd.f32 %v34528_v29, %v34417_v26 (stack53)
        %vm34873_vm11 = vcmp.lt.f32.partialorder %v132585_v24, 5.0 (stack68)
        %120727 = vrsqrt.f32 %v132585_v24 (stack67)
        %vm132595_vm12 = vcmp.eq.f32.partialorder %v34385_v30, 1.0 (stack68)
        %v35277_v61 = vadd.s32 %v35274_v21, %v121574_v2 (stack40)
        %v35679_v40 = vxor.u32 %v35678_v25, %v35674_v11 (stack48)
        %v36913_v6 = vor.u32 %v36912_v55, %v36911_v60 (stack47)
        %v34536_v20 = vmul.f32 %v34532_v8, %v132391_v20 (stack54)
        %v36079_v44 = vor.u32 %v36078_v34, %v36077_v12 (stack47)
        %v36494_v52 = vshll.u32 %v36488_v9, 17 (stack45)
        %v36495_v7 = vshrl.u32 %v36488_v9, 15 (stack46)
        %v132604_v43 = vsel /*vm=*/%vm34873_vm11, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v132607_v31 = vadd.f32 -2.5, %v132585_v24 (stack53)
        %v35269_v54 = vadd.s32 %v35265_v54, %v121564_v0 (stack40)
        %v35682_v60 = vadd.s32 %v35679_v40, %v35674_v11 (stack40)
        %v34540_v53 = vsel /*vm=*/%vm132595_vm12, /*on_true_vy=*/%v34393_v22, /*on_false_vx=*/%v34536_v20 (stack44)
        %v132615_v21 = vsel /*vm=*/%vm34873_vm11, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v132620_v9 = vsel /*vm=*/%vm34873_vm11, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v132625_v55 = vsel /*vm=*/%vm34873_vm11, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v34544_v10 = vmul.f32 1.4140625, %v34540_v53 (stack54)
        %v132630_v11 = vsel /*vm=*/%vm34873_vm11, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v35281_v41 = vadd.s32 5, %v35277_v61 (stack40)
        %v35688_v46 = vshll.u32 %v35679_v40, 24 (stack45)
        %v35689_v29 = vshrl.u32 %v35679_v40, 8 (stack46)
        %v36080_v12 = vxor.u32 %v36079_v44, %v36075_v23 (stack48)
        %v36496_v34 = vor.u32 %v36495_v7, %v36494_v52 (stack47)
        %v36914_v26 = vxor.u32 %v36913_v6, %v132576_v27 (stack48)
        %v34547_v25 = vpack.c.bf16 %v156663_v45, %v34544_v10 (stack81)
        %vm34918_vm13 = vcmp.eq.f32.partialorder %v132585_v24, inf (stack70)
        %v35283_v22 = vxor.u32 %v35281_v41, %v35269_v54 (stack48)
        %v132637_v50 = vadd.s32 %v157269_v50, %v157095_v13 (stack40)
        %v132641_v56 = vadd.s32 %v157270_v56, %v157100_v14 (stack40)
        %vm34920_vm14 = vcmp.eq.f32.partialorder %v132585_v24, 0.0 (stack71)
        %v35690_v8 = vor.u32 %v35689_v29, %v35688_v46 (stack47)
        %v36083_v23 = vadd.s32 %v36080_v12, %v36075_v23 (stack40)
        %v36085_v30 = vshll.u32 %v36080_v12, 15 (stack45)
        %v36086_v61 = vshrl.u32 %v36080_v12, 17 (stack46)
        %119929 = vst [vmem:[%s123356_s30 + $0x24] sm:$0xf] /*vst_source=*/%v34547_v25 (stack83)
        %v35284_v40 = vand.u32.u8 255, %v35283_v22 (stack49)
        %v36497_v6 = vxor.u32 %v36496_v34, %v36492_v42 (stack48)
        %v36917_v27 = vadd.s32 %v36914_v26, %v132576_v27 (stack40)
        %v36919_v20 = vshll.u32 %v36914_v26, 15 (stack45)
        %v34921_v44 = vand.u32 2147483648, %v132585_v24 (stack72)
        %v35691_v52 = vxor.u32 %v35690_v8, %v35682_v60 (stack48)
        %v36087_v7 = vor.u32 %v36086_v61, %v36085_v30 (stack47)
        %v36920_v54 = vshrl.u32 %v36914_v26, 17 (stack46)
        %v35285_v53 = vand.u32 65535, %v35284_v40 (stack50)
        %v36500_v42 = vadd.s32 %v36497_v6, %v36492_v42 (stack40)
        %v36502_v10 = vshll.u32 %v36497_v6, 29 (stack45)
        %v36503_v41 = vshrl.u32 %v36497_v6, 3 (stack46)
        %v35686_v60 = vadd.s32 %v35682_v60, %v121569_v1 (stack40)
        %v35694_v46 = vadd.s32 %v35691_v52, %v121564_v0 (stack40)
        %v36088_v29 = vxor.u32 %v36087_v7, %v36083_v23 (stack48)
        %v36921_v12 = vor.u32 %v36920_v54, %v36919_v20 (stack47)
        %v120728_v34 = vpop.eup %120727 (stack73)
        %v35286_v26 = vshrl.u32 %v35285_v53, 1 (stack51)
        %v36504_v25 = vor.u32 %v36503_v41, %v36502_v10 (stack47)
        %vm37336_vm15 = vcmp.lt.u32.totalorder %v132637_v50, %v157095_v13 (stack43)
        %v37345_v22 = vadd.s32 1, %v132641_v56 (stack40)
        %v34917_v8 = vmul.f32 %v120728_v34, %v132585_v24 (stack74)
        %v35698_v30 = vadd.s32 4, %v35694_v46 (stack40)
        %v36091_v23 = vadd.s32 %v36088_v29, %v36083_v23 (stack40)
        %v36093_v61 = vshll.u32 %v36088_v29, 26 (stack45)
        %v35287_v40 = vor.u32 16256, %v35286_v26 (stack47)
        %v36094_v6 = vshrl.u32 %v36088_v29, 6 (stack46)
        %v36505_v20 = vxor.u32 %v36504_v25, %v36500_v42 (stack48)
        %v36922_v52 = vxor.u32 %v36921_v12, %v36917_v27 (stack48)
        %v34919_v7 = vsel /*vm=*/%vm34918_vm13, /*on_true_vy=*/%v132585_v24, /*on_false_vx=*/%v34917_v8 (stack75)
        %v35702_v54 = vadd.s32 %v35698_v30, %v35686_v60 (stack40)
        %v35704_v53 = vshll.u32 %v35698_v30, 13 (stack45)
        %v35705_v10 = vshrl.u32 %v35698_v30, 19 (stack46)
        %v34922_v44 = vsel /*vm=*/%vm34920_vm14, /*on_true_vy=*/%v34921_v44, /*on_false_vx=*/%v34919_v7 (stack76)
        %v35288_v41 = vand.u32.u16 65535, %v35287_v40 (stack52)
        %v36095_v60 = vor.u32 %v36094_v6, %v36093_v61 (stack47)
        %v36508_v42 = vadd.s32 %v36505_v20, %v36500_v42 (stack40)
        %v34925_v46 = vadd.f32 -3.0, %v34922_v44 (stack53)
        %v35706_v29 = vor.u32 %v35705_v10, %v35704_v53 (stack47)
        %v36510_v12 = vshll.u32 %v36505_v20, 16 (stack45)
        %v36511_v34 = vshrl.u32 %v36505_v20, 16 (stack46)
        %v119932_v26 = vadd.low.f32.bf16 -1.0, %v35288_v41 (stack53)
        %v36096_v25 = vxor.u32 %v36095_v60, %v36091_v23 (stack48)
        %v36925_v27 = vadd.s32 %v36922_v52, %v36917_v27 (stack40)
        %v36927_v8 = vshll.u32 %v36922_v52, 26 (stack45)
        %v132661_v31 = vsel /*vm=*/%vm34873_vm11, /*on_true_vy=*/%v132607_v31, /*on_false_vx=*/%v34925_v46 (stack44)
        %v35707_v30 = vxor.u32 %v35706_v29, %v35702_v54 (stack48)
        %v36512_v61 = vor.u32 %v36511_v34, %v36510_v12 (stack47)
        %v36928_v40 = vshrl.u32 %v36922_v52, 6 (stack46)
        %v34933_v11 = vmul.f32 %v132661_v31, %v132630_v11 (stack54)
        %v35297_v6 = vmul.f32 2.0, %v119932_v26 (stack54)
        %v36099_v23 = vadd.s32 %v36096_v25, %v36091_v23 (stack40)
        %v36105_v20 = vshll.u32 %v36096_v25, 6 (stack45)
        %v35710_v52 = vadd.s32 %v35707_v30, %v35702_v54 (stack40)
        %v35712_v7 = vshll.u32 %v35707_v30, 15 (stack45)
        %v35713_v54 = vshrl.u32 %v35707_v30, 17 (stack46)
        %v36106_v53 = vshrl.u32 %v36096_v25, 26 (stack46)
        %v34894_v10 = vsel /*vm=*/%vm34873_vm11, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v34937_v55 = vadd.f32 %v34933_v11, %v132625_v55 (stack53)
        %v35301_v44 = vadd.f32 -0.99609375, %v35297_v6 (stack53)
        %v36513_v41 = vxor.u32 %v36512_v61, %v36508_v42 (stack48)
        %v35714_v60 = vor.u32 %v35713_v54, %v35712_v7 (stack47)
        %v36107_v46 = vor.u32 %v36106_v53, %v36105_v20 (stack47)
        %v36929_v29 = vor.u32 %v36928_v40, %v36927_v8 (stack47)
        %v37349_v56 = vsel /*vm=*/%vm37336_vm15, /*on_true_vy=*/%v37345_v22, /*on_false_vx=*/%v132641_v56 (stack44)
        %v34941_v22 = vmul.f32 %v34937_v55, %v132661_v31 (stack54)
        %v132674_v12 = vmax.f32 %v35301_v44, -0.99609375 (stack55)
        %v36516_v42 = vadd.s32 %v36513_v41, %v36508_v42 (stack40)
        %v37327_v34 = vadd.s32 %v132637_v50, %v122657_v58 (stack40)
        %v34902_v26 = vsel /*vm=*/%vm34873_vm11, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v35715_v25 = vxor.u32 %v35714_v60, %v35710_v52 (stack48)
        %v36108_v8 = vxor.u32 %v36107_v46, %v36099_v23 (stack48)
        %v36930_v30 = vxor.u32 %v36929_v29, %v36925_v27 (stack48)
        %v34945_v61 = vadd.f32 %v34941_v22, %v34902_v26 (stack53)
        %v35317_v40 = vxor.u32 2147483648, %v132674_v12 (stack56)
        %v36522_v11 = vshll.u32 %v36513_v41, 24 (stack45)
        %v36523_v6 = vshrl.u32 %v36513_v41, 8 (stack46)
        %v35718_v20 = vadd.s32 %v35715_v25, %v35710_v52 (stack40)
        %v35720_v52 = vshll.u32 %v35715_v25, 26 (stack45)
        %v35721_v7 = vshrl.u32 %v35715_v25, 6 (stack46)
        %v36111_v54 = vadd.s32 %v36108_v8, %v121569_v1 (stack40)
        %v34898_v53 = vsel /*vm=*/%vm34873_vm11, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v34949_v55 = vmul.f32 %v34945_v61, %v132661_v31 (stack54)
        %v35320_v44 = vmul.f32 %v35317_v40, %v132674_v12 (stack54)
        %vm37331_vm0 = vcmp.lt.u32.totalorder %v37327_v34, %v132637_v50 (stack43)
        %v35722_v41 = vor.u32 %v35721_v7, %v35720_v52 (stack47)
        %v36103_v23 = vadd.s32 %v36099_v23, %v121574_v2 (stack40)
        %v36115_v60 = vadd.s32 3, %v36111_v54 (stack40)
        %v132690_v27 = vadd.s32 %v36930_v30, %v36925_v27 (stack40)
        %v34953_v46 = vadd.f32 %v34949_v55, %v34898_v53 (stack53)
        %v35322_v29 = vadd.f32 1.0, %v35320_v44 (stack57)
        %v35325_v22 = vmul.f32 -0.5, %v35320_v44 (stack59)
        %v36524_v26 = vor.u32 %v36523_v6, %v36522_v11 (stack47)
        %v35723_v25 = vxor.u32 %v35722_v41, %v35718_v20 (stack48)
        %v36119_v8 = vadd.s32 %v36115_v60, %v36103_v23 (stack40)
        %v36121_v61 = vshll.u32 %v36115_v60, 17 (stack45)
        %v36122_v40 = vshrl.u32 %v36115_v60, 15 (stack46)
        %v34957_v11 = vmul.f32 %v34953_v46, %v132661_v31 (stack54)
        %120729 = vlog2.f32 %v35322_v29 (stack58)
        %v35326_v6 = vadd.f32 1.0, %v35325_v22 (stack61)
        %v36520_v52 = vadd.s32 %v36516_v42, %v121564_v0 (stack40)
        %v35726_v20 = vadd.s32 %v35723_v25, %v35718_v20 (stack40)
        %v35732_v7 = vshll.u32 %v35723_v25, 6 (stack45)
        %v35733_v54 = vshrl.u32 %v35723_v25, 26 (stack46)
        %v36123_v53 = vor.u32 %v36122_v40, %v36121_v61 (stack47)
        %v34961_v10 = vadd.f32 %v34957_v11, %v34894_v10 (stack53)
        %v132694_v55 = vmul.f32 %v35326_v6, %v35320_v44 (stack63)
        %v35328_v44 = vand.u32 2147483647, %v35320_v44 (stack60)
        %v36525_v42 = vxor.u32 %v36524_v26, %v36516_v42 (stack48)
        %v35730_v41 = vadd.s32 %v35726_v20, %v121564_v0 (stack40)
        %v35734_v23 = vor.u32 %v35733_v54, %v35732_v7 (stack47)
        %v36124_v60 = vxor.u32 %v36123_v53, %v36119_v8 (stack48)
        %v36939_v46 = vshll.u32 %v36930_v30, 6 (stack45)
        %v34965_v29 = vmul.f32 %v34961_v10, %v132661_v31 (stack54)
        %v36528_v22 = vadd.s32 %v36525_v42, %v121574_v2 (stack40)
        %v36940_v30 = vshrl.u32 %v36930_v30, 26 (stack46)
        %v37353_v26 = vadd.s32 1, %v37349_v56 (stack40)
        %v35735_v25 = vxor.u32 %v35734_v23, %v35726_v20 (stack48)
        %v36127_v8 = vadd.s32 %v36124_v60, %v36119_v8 (stack40)
        %v36129_v61 = vshll.u32 %v36124_v60, 29 (stack45)
        %v36130_v40 = vshrl.u32 %v36124_v60, 3 (stack46)
        %v34969_v9 = vadd.f32 %v34965_v29, %v132620_v9 (stack53)
        %v36532_v11 = vadd.s32 2, %v36528_v22 (stack40)
        %v36941_v6 = vor.u32 %v36940_v30, %v36939_v46 (stack47)
        %v37357_v50 = vsel /*vm=*/%vm37331_vm0, /*on_true_vy=*/%v37353_v26, /*on_false_vx=*/%v37349_v56 (stack44)
        %vm132702_vm1 = vcmp.lt.f32.partialorder %v35328_v44, 0.0004427343 (stack62)
        %v35738_v20 = vadd.s32 %v35735_v25, %v121574_v2 (stack40)
        %v36131_v7 = vor.u32 %v36130_v40, %v36129_v61 (stack47)
        %v37362_v54 = vadd.s32 %v37357_v50, %v121574_v2 (stack40)
        %v37366_v34 = vadd.s32 %v37327_v34, %v121569_v1 (stack40)
        %v34973_v53 = vmul.f32 %v34969_v9, %v132661_v31 (stack54)
        %v36536_v52 = vadd.s32 %v36532_v11, %v36520_v52 (stack40)
        %v36538_v10 = vshll.u32 %v36532_v11, 13 (stack45)
        %v36539_v44 = vshrl.u32 %v36532_v11, 19 (stack46)
        %v35742_v42 = vadd.s32 5, %v35738_v20 (stack40)
        %v36132_v23 = vxor.u32 %v36131_v7, %v36127_v8 (stack48)
        %v36942_v60 = vxor.u32 %v36941_v6, %v132690_v27 (stack48)
        %v37370_v46 = vadd.s32 %v37366_v34, %v37362_v54 (stack40)
        %v34977_v21 = vadd.f32 %v34973_v53, %v132615_v21 (stack53)
        %v36540_v29 = vor.u32 %v36539_v44, %v36538_v10 (stack47)
        %v37372_v22 = vshll.u32 %v37366_v34, 13 (stack45)
        %v37373_v30 = vshrl.u32 %v37366_v34, 19 (stack46)
        %v35744_v41 = vxor.u32 %v35742_v42, %v35730_v41 (stack48)
        %v36135_v26 = vadd.s32 %v36132_v23, %v36127_v8 (stack40)
        %v36137_v25 = vshll.u32 %v36132_v23, 16 (stack45)
        %v36138_v8 = vshrl.u32 %v36132_v23, 16 (stack46)
        %v34981_v61 = vmul.f32 %v34977_v21, %v132661_v31 (stack54)
        %v36541_v40 = vxor.u32 %v36540_v29, %v36536_v52 (stack48)
        %v36945_v9 = vadd.s32 %v36942_v60, %v121564_v0 (stack40)
        %v37374_v11 = vor.u32 %v37373_v30, %v37372_v22 (stack47)
        %v120730_v6 = vpop.eup %120729 (stack64)
        %v35745_v50 = vand.u32.u8 255, %v35744_v41 (stack49)
        %v36139_v20 = vor.u32 %v36138_v8, %v36137_v25 (stack47)
        %v157297_v7 = vld [vmem:[#allocation134_spill] sm:$0xff] (stack84)
        %v132716_v54 = vadd.s32 %v157297_v7, %v122651_v47 (stack40)
        %v157298_v34 = vld [vmem:[#allocation95_spill] sm:$0xff] (stack84)
        %v132720_v53 = vadd.s32 %v157298_v34, %v157068_v28 (stack40)
        %v34985_v43 = vadd.f32 %v34981_v61, %v132604_v43 (stack53)
        %v35324_v10 = vmul.f32 0.6931472, %v120730_v6 (stack65)
        %v36544_v52 = vadd.s32 %v36541_v40, %v36536_v52 (stack40)
        %v36937_v27 = vadd.s32 %v132690_v27, %v121569_v1 (stack40)
        %v35746_v44 = vand.u32 65535, %v35745_v50 (stack50)
        %v36140_v42 = vxor.u32 %v36139_v20, %v36135_v26 (stack48)
        %v36546_v23 = vshll.u32 %v36541_v40, 15 (stack45)
        %v36949_v60 = vadd.s32 1, %v36945_v9 (stack40)
        %v34989_v31 = vmul.f32 %v34985_v43, %v132661_v31 (stack54)
        %v35330_v55 = vsel /*vm=*/%vm132702_vm1, /*on_true_vy=*/%v132694_v55, /*on_false_vx=*/%v35324_v10 (stack66)
        %v36547_v56 = vshrl.u32 %v36541_v40, 17 (stack46)
        %v37375_v21 = vxor.u32 %v37374_v11, %v37370_v46 (stack48)
        %v34846_v29 = vand.u32 2147483647, %v132533_v32 (stack77)
        %v34878_v24 = vsel /*vm=*/%vm34873_vm11, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v132733_v22 = vxor.u32 2147483648, %v35330_v55 (stack56)
        %v36143_v30 = vadd.s32 %v36140_v42, %v36135_v26 (stack40)
        %v34993_v41 = vadd.f32 %v34989_v31, %v34878_v24 (stack53)
        %v36953_v26 = vadd.s32 %v36949_v60, %v36937_v27 (stack40)
        %v34854_v25 = vmul.f32 inf, %v132533_v32 (stack54)
        %120731 = vrsqrt.f32 %v132733_v22 (stack67)
        %v35747_v8 = vshrl.u32 %v35746_v44, 1 (stack51)
        %v36149_v61 = vshll.u32 %v36140_v42, 24 (stack45)
        %v34997_v32 = vmul.f32 %v34993_v41, %v132533_v32 (stack54)
        %vm35334_vm2 = vcmp.lt.f32.partialorder %v132733_v22, 5.0 (stack68)
        %v36150_v40 = vshrl.u32 %v36140_v42, 8 (stack46)
        %v36548_v9 = vor.u32 %v36547_v56, %v36546_v23 (stack47)
        %vm34849_vm3 = vcmp.eq.f32.partialorder %v34846_v29, 1.0 (stack68)
        %v35001_v11 = vsel /*vm=*/%vm34849_vm3, /*on_true_vy=*/%v34854_v25, /*on_false_vx=*/%v34997_v32 (stack44)
        %v132740_v6 = vadd.f32 -2.5, %v132733_v22 (stack53)
        %v132744_v50 = vadd.s32 %v132716_v54, %v122657_v58 (stack40)
        %v35005_v20 = vmul.f32 1.4140625, %v35001_v11 (stack54)
        %v132749_v43 = vsel /*vm=*/%vm35334_vm2, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v132754_v10 = vsel /*vm=*/%vm35334_vm2, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v35748_v27 = vor.u32 16256, %v35747_v8 (stack47)
        %v36151_v44 = vor.u32 %v36150_v40, %v36149_v61 (stack47)
        %v36549_v42 = vxor.u32 %v36548_v9, %v36544_v52 (stack48)
        %v36955_v23 = vshll.u32 %v36949_v60, 17 (stack45)
        %v36956_v60 = vshrl.u32 %v36949_v60, 15 (stack46)
        %v35008_v31 = vpack.c.bf16 %v156663_v45, %v35005_v20 (stack81)
        %v35749_v55 = vand.u32.u16 65535, %v35748_v27 (stack52)
        %v37378_v46 = vadd.s32 %v37375_v21, %v37370_v46 (stack40)
        %v37380_v56 = vshll.u32 %v37375_v21, 15 (stack45)
        %vm35379_vm4 = vcmp.eq.f32.partialorder %v132733_v22, inf (stack70)
        %v36152_v29 = vxor.u32 %v36151_v44, %v36143_v30 (stack48)
        %v36552_v52 = vadd.s32 %v36549_v42, %v36544_v52 (stack40)
        %v36554_v24 = vshll.u32 %v36549_v42, 26 (stack45)
        %v36555_v41 = vshrl.u32 %v36549_v42, 6 (stack46)
        %119931 = vst [vmem:[%s123356_s30 + $0xa4] sm:$0xf] /*vst_source=*/%v35008_v31 (stack83)
        %v132762_v25 = vsel /*vm=*/%vm35334_vm2, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v119934_v8 = vadd.low.f32.bf16 -1.0, %v35749_v55 (stack53)
        %v36957_v61 = vor.u32 %v36956_v60, %v36955_v23 (stack47)
        %v37381_v21 = vshrl.u32 %v37375_v21, 17 (stack46)
        %v36155_v32 = vadd.s32 %v36152_v29, %v121564_v0 (stack40)
        %v36556_v40 = vor.u32 %v36555_v41, %v36554_v24 (stack47)
        %vm37831_vm5 = vcmp.lt.u32.totalorder %v132716_v54, %v122651_v47 (stack43)
        %v37840_v9 = vadd.s32 1, %v132720_v53 (stack40)
        %v35758_v11 = vmul.f32 2.0, %v119934_v8 (stack54)
        %v36147_v30 = vadd.s32 %v36143_v30, %v121569_v1 (stack40)
        %v36958_v20 = vxor.u32 %v36957_v61, %v36953_v26 (stack48)
        %v37382_v27 = vor.u32 %v37381_v21, %v37380_v56 (stack47)
        %v36159_v44 = vadd.s32 4, %v36155_v32 (stack40)
        %v36557_v42 = vxor.u32 %v36556_v40, %v36552_v52 (stack48)
        %v132770_v53 = vsel /*vm=*/%vm37831_vm5, /*on_true_vy=*/%v37840_v9, /*on_false_vx=*/%v132720_v53 (stack44)
        %v132774_v23 = vadd.s32 %v157297_v7, %v157070_v38 (stack40)
        %v35762_v60 = vadd.f32 -0.99609375, %v35758_v11 (stack53)
        %v36961_v26 = vadd.s32 %v36958_v20, %v36953_v26 (stack40)
        %v36963_v31 = vshll.u32 %v36958_v20, 29 (stack45)
        %v36964_v55 = vshrl.u32 %v36958_v20, 3 (stack46)
        %v120732_v56 = vpop.eup %120731 (stack73)
        %v36163_v29 = vadd.s32 %v36159_v44, %v36147_v30 (stack40)
        %v36165_v24 = vshll.u32 %v36159_v44, 13 (stack45)
        %v36166_v41 = vshrl.u32 %v36159_v44, 19 (stack46)
        %v36560_v52 = vadd.s32 %v36557_v42, %v36552_v52 (stack40)
        %v35378_v8 = vmul.f32 %v120732_v56, %v132733_v22 (stack74)
        %v132777_v61 = vmax.f32 %v35762_v60, -0.99609375 (stack55)
        %v36566_v21 = vshll.u32 %v36557_v42, 6 (stack45)
        %v36567_v32 = vshrl.u32 %v36557_v42, 26 (stack46)
        %v35382_v40 = vand.u32 2147483648, %v132733_v22 (stack72)
        %v36167_v9 = vor.u32 %v36166_v41, %v36165_v24 (stack47)
        %v36965_v11 = vor.u32 %v36964_v55, %v36963_v31 (stack47)
        %v37383_v30 = vxor.u32 %v37382_v27, %v37378_v46 (stack48)
        %v35363_v20 = vsel /*vm=*/%vm35334_vm2, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v35380_v27 = vsel /*vm=*/%vm35379_vm4, /*on_true_vy=*/%v132733_v22, /*on_false_vx=*/%v35378_v8 (stack75)
        %vm35381_vm6 = vcmp.eq.f32.partialorder %v132733_v22, 0.0 (stack71)
        %v35778_v44 = vxor.u32 2147483648, %v132777_v61 (stack56)
        %v35383_v42 = vsel /*vm=*/%vm35381_vm6, /*on_true_vy=*/%v35382_v40, /*on_false_vx=*/%v35380_v27 (stack76)
        %v36168_v60 = vxor.u32 %v36167_v9, %v36163_v29 (stack48)
        %v36568_v31 = vor.u32 %v36567_v32, %v36566_v21 (stack47)
        %v36966_v55 = vxor.u32 %v36965_v11, %v36961_v26 (stack48)
        %v35367_v56 = vsel /*vm=*/%vm35334_vm2, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v35386_v24 = vadd.f32 -3.0, %v35383_v42 (stack53)
        %v132792_v41 = vmul.f32 %v35778_v44, %v132777_v61 (stack54)
        %v37386_v46 = vadd.s32 %v37383_v30, %v37378_v46 (stack40)
        %v36171_v29 = vadd.s32 %v36168_v60, %v36163_v29 (stack40)
        %v36173_v8 = vshll.u32 %v36168_v60, 15 (stack45)
        %v36174_v21 = vshrl.u32 %v36168_v60, 17 (stack46)
        %v36569_v32 = vxor.u32 %v36568_v31, %v36560_v52 (stack48)
        %v35371_v40 = vsel /*vm=*/%vm35334_vm2, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v132800_v6 = vsel /*vm=*/%vm35334_vm2, /*on_true_vy=*/%v132740_v6, /*on_false_vx=*/%v35386_v24 (stack44)
        %v35783_v9 = vadd.f32 1.0, %v132792_v41 (stack57)
        %vm37826_vm7 = vcmp.lt.u32.totalorder %v132744_v50, %v132716_v54 (stack43)
        %v35394_v11 = vmul.f32 %v132800_v6, %v35371_v40 (stack54)
        %v36175_v27 = vor.u32 %v36174_v21, %v36173_v8 (stack47)
        %v36572_v44 = vadd.s32 %v36569_v32, %v121569_v1 (stack40)
        %v36969_v26 = vadd.s32 %v36966_v55, %v36961_v26 (stack40)
        %120733 = vlog2.f32 %v35783_v9 (stack58)
        %v36564_v52 = vadd.s32 %v36560_v52, %v121574_v2 (stack40)
        %v36971_v42 = vshll.u32 %v36966_v55, 16 (stack45)
        %v37861_v60 = vadd.s32 %v132744_v50, %v121569_v1 (stack40)
        %v35398_v31 = vadd.f32 %v35394_v11, %v35367_v56 (stack53)
        %v36176_v56 = vxor.u32 %v36175_v27, %v36171_v29 (stack48)
        %v36576_v24 = vadd.s32 3, %v36572_v44 (stack40)
        %v36972_v55 = vshrl.u32 %v36966_v55, 16 (stack46)
        %v35786_v8 = vmul.f32 -0.5, %v132792_v41 (stack59)
        %v37388_v21 = vshll.u32 %v37383_v30, 26 (stack45)
        %v37389_v30 = vshrl.u32 %v37383_v30, 6 (stack46)
        %v37848_v32 = vadd.s32 1, %v132770_v53 (stack40)
        %v35402_v40 = vmul.f32 %v35398_v31, %v132800_v6 (stack54)
        %v36179_v29 = vadd.s32 %v36176_v56, %v36171_v29 (stack40)
        %v36181_v9 = vshll.u32 %v36176_v56, 26 (stack45)
        %v36182_v11 = vshrl.u32 %v36176_v56, 6 (stack46)
        %v36580_v27 = vadd.s32 %v36576_v24, %v36564_v52 (stack40)
        %v36582_v44 = vshll.u32 %v36576_v24, 17 (stack45)
        %v36583_v52 = vshrl.u32 %v36576_v24, 15 (stack46)
        %v36973_v42 = vor.u32 %v36972_v55, %v36971_v42 (stack47)
        %v35406_v20 = vadd.f32 %v35402_v40, %v35363_v20 (stack53)
        %v36183_v31 = vor.u32 %v36182_v11, %v36181_v9 (stack47)
        %v37390_v56 = vor.u32 %v37389_v30, %v37388_v21 (stack47)
        %v37852_v54 = vsel /*vm=*/%vm37826_vm7, /*on_true_vy=*/%v37848_v32, /*on_false_vx=*/%v132770_v53 (stack44)
        %v35787_v50 = vadd.f32 1.0, %v35786_v8 (stack61)
        %v35789_v53 = vand.u32 2147483647, %v132792_v41 (stack60)
        %v36584_v24 = vor.u32 %v36583_v52, %v36582_v44 (stack47)
        %v36974_v55 = vxor.u32 %v36973_v42, %v36969_v26 (stack48)
        %v35410_v8 = vmul.f32 %v35406_v20, %v132800_v6 (stack54)
        %v36184_v21 = vxor.u32 %v36183_v31, %v36179_v29 (stack48)
        %v37391_v30 = vxor.u32 %v37390_v56, %v37386_v46 (stack48)
        %v37857_v32 = vadd.s32 %v37852_v54, %v121574_v2 (stack40)
        %v36585_v40 = vxor.u32 %v36584_v24, %v36580_v27 (stack48)
        %v36977_v26 = vadd.s32 %v36974_v55, %v36969_v26 (stack40)
        %v36983_v9 = vshll.u32 %v36974_v55, 24 (stack45)
        %v36984_v11 = vshrl.u32 %v36974_v55, 8 (stack46)
        %v35414_v25 = vadd.f32 %v35410_v8, %v132762_v25 (stack53)
        %v36187_v29 = vadd.s32 %v36184_v21, %v36179_v29 (stack40)
        %v36193_v44 = vshll.u32 %v36184_v21, 6 (stack45)
        %v36194_v52 = vshrl.u32 %v36184_v21, 26 (stack46)
        %v36588_v27 = vadd.s32 %v36585_v40, %v36580_v27 (stack40)
        %v36590_v42 = vshll.u32 %v36585_v40, 29 (stack45)
        %v36591_v20 = vshrl.u32 %v36585_v40, 3 (stack46)
        %v37867_v31 = vshll.u32 %v37861_v60, 13 (stack45)
        %v35418_v56 = vmul.f32 %v35414_v25, %v132800_v6 (stack54)
        %v36195_v54 = vor.u32 %v36194_v52, %v36193_v44 (stack47)
        %v36985_v24 = vor.u32 %v36984_v11, %v36983_v9 (stack47)
        %v37868_v55 = vshrl.u32 %v37861_v60, 19 (stack46)
        %v36592_v8 = vor.u32 %v36591_v20, %v36590_v42 (stack47)
        %v37394_v46 = vadd.s32 %v37391_v30, %v37386_v46 (stack40)
        %v37400_v21 = vshll.u32 %v37391_v30, 6 (stack45)
        %v37401_v30 = vshrl.u32 %v37391_v30, 26 (stack46)
        %v120734_v40 = vpop.eup %120733 (stack64)
        %v35422_v10 = vadd.f32 %v35418_v56, %v132754_v10 (stack53)
        %v36196_v9 = vxor.u32 %v36195_v54, %v36187_v29 (stack48)
        %v36986_v11 = vxor.u32 %v36985_v24, %v36977_v26 (stack48)
        %v37865_v60 = vadd.s32 %v37861_v60, %v37857_v32 (stack40)
        %v35785_v32 = vmul.f32 0.6931472, %v120734_v40 (stack65)
        %v35788_v41 = vmul.f32 %v35787_v50, %v132792_v41 (stack63)
        %v36593_v50 = vxor.u32 %v36592_v8, %v36588_v27 (stack48)
        %v37402_v25 = vor.u32 %v37401_v30, %v37400_v21 (stack47)
        %v35426_v44 = vmul.f32 %v35422_v10, %v132800_v6 (stack54)
        %vm35790_vm8 = vcmp.lt.f32.partialorder %v35789_v53, 0.0004427343 (stack62)
        %v36199_v53 = vadd.s32 %v36196_v9, %v121574_v2 (stack40)
        %v37869_v52 = vor.u32 %v37868_v55, %v37867_v31 (stack47)
        %v35791_v42 = vsel /*vm=*/%vm35790_vm8, /*on_true_vy=*/%v35788_v41, /*on_false_vx=*/%v35785_v32 (stack66)
        %v36596_v27 = vadd.s32 %v36593_v50, %v36588_v27 (stack40)
        %v36598_v20 = vshll.u32 %v36593_v50, 16 (stack45)
        %v36599_v31 = vshrl.u32 %v36593_v50, 16 (stack46)
        %v35430_v43 = vadd.f32 %v35426_v44, %v132749_v43 (stack53)
        %v132827_v56 = vxor.u32 2147483648, %v35791_v42 (stack56)
        %v36203_v54 = vadd.s32 5, %v36199_v53 (stack40)
        %v36989_v24 = vadd.s32 %v36986_v11, %v121574_v2 (stack40)
        %v36191_v29 = vadd.s32 %v36187_v29, %v121564_v0 (stack40)
        %v36600_v55 = vor.u32 %v36599_v31, %v36598_v20 (stack47)
        %v37403_v8 = vxor.u32 %v37402_v25, %v37394_v46 (stack48)
        %v37870_v21 = vxor.u32 %v37869_v52, %v37865_v60 (stack48)
        %v35307_v30 = vand.u32 2147483647, %v132674_v12 (stack77)
        %v132833_v40 = vmul.f32 inf, %v132674_v12 (stack54)
        %v35434_v10 = vmul.f32 %v35430_v43, %v132800_v6 (stack54)
        %120735 = vrsqrt.f32 %v132827_v56 (stack67)
        %v35339_v9 = vsel /*vm=*/%vm35334_vm2, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v35347_v11 = vsel /*vm=*/%vm35334_vm2, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %vm35795_vm9 = vcmp.lt.f32.partialorder %v132827_v56, 5.0 (stack68)
        %v36205_v32 = vxor.u32 %v36203_v54, %v36191_v29 (stack48)
        %v35343_v22 = vsel /*vm=*/%vm35334_vm2, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v35438_v41 = vadd.f32 %v35434_v10, %v35347_v11 (stack53)
        %v36981_v26 = vadd.s32 %v36977_v26, %v121564_v0 (stack40)
        %v36993_v50 = vadd.s32 2, %v36989_v24 (stack40)
        %v132849_v25 = vadd.f32 -2.5, %v132827_v56 (stack53)
        %v36601_v44 = vxor.u32 %v36600_v55, %v36596_v27 (stack48)
        %v37398_v46 = vadd.s32 %v37394_v46, %v121569_v1 (stack40)
        %v132854_v53 = vadd.s32 %v132774_v23, %v122657_v58 (stack40)
        %v35442_v52 = vmul.f32 %v35438_v41, %v132800_v6 (stack54)
        %v132860_v42 = vsel /*vm=*/%vm35795_vm9, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v132865_v20 = vsel /*vm=*/%vm35795_vm9, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v132870_v31 = vsel /*vm=*/%vm35795_vm9, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %vm132872_vm10 = vcmp.eq.f32.partialorder %v35307_v30, 1.0 (stack68)
        %v36206_v54 = vand.u32.u8 255, %v36205_v32 (stack49)
        %v36604_v27 = vadd.s32 %v36601_v44, %v36596_v27 (stack40)
        %v36610_v24 = vshll.u32 %v36601_v44, 24 (stack45)
        %v36611_v29 = vshrl.u32 %v36601_v44, 8 (stack46)
        %v35446_v55 = vadd.f32 %v35442_v52, %v35343_v22 (stack53)
        %v36997_v30 = vadd.s32 %v36993_v50, %v36981_v26 (stack40)
        %v36999_v10 = vshll.u32 %v36993_v50, 13 (stack45)
        %v37000_v11 = vshrl.u32 %v36993_v50, 19 (stack46)
        %vm35840_vm11 = vcmp.eq.f32.partialorder %v132827_v56, inf (stack70)
        %v35843_v32 = vand.u32 2147483648, %v132827_v56 (stack72)
        %v36207_v22 = vand.u32 65535, %v36206_v54 (stack50)
        %v36612_v41 = vor.u32 %v36611_v29, %v36610_v24 (stack47)
        %v37406_v8 = vadd.s32 %v37403_v8, %v121564_v0 (stack40)
        %v35450_v6 = vmul.f32 %v35446_v55, %v132800_v6 (stack54)
        %vm35842_vm12 = vcmp.eq.f32.partialorder %v132827_v56, 0.0 (stack71)
        %v37001_v26 = vor.u32 %v37000_v11, %v36999_v10 (stack47)
        %v37873_v60 = vadd.s32 %v37870_v21, %v37865_v60 (stack40)
        %v37875_v50 = vshll.u32 %v37870_v21, 15 (stack45)
        %v36208_v44 = vshrl.u32 %v36207_v22, 1 (stack51)
        %v36613_v52 = vxor.u32 %v36612_v41, %v36604_v27 (stack48)
        %v37410_v54 = vadd.s32 1, %v37406_v8 (stack40)
        %v37876_v21 = vshrl.u32 %v37870_v21, 17 (stack46)
        %v35454_v9 = vadd.f32 %v35450_v6, %v35339_v9 (stack53)
        %v36608_v27 = vadd.s32 %v36604_v27, %v121569_v1 (stack40)
        %v37002_v24 = vxor.u32 %v37001_v26, %v36997_v30 (stack48)
        %vm38292_vm13 = vcmp.lt.u32.totalorder %v132774_v23, %v157070_v38 (stack43)
        %v36209_v29 = vor.u32 16256, %v36208_v44 (stack47)
        %v36616_v55 = vadd.s32 %v36613_v52, %v121564_v0 (stack40)
        %v37414_v46 = vadd.s32 %v37410_v54, %v37398_v46 (stack40)
        %v37416_v10 = vshll.u32 %v37410_v54, 17 (stack45)
        %v35458_v12 = vmul.f32 %v35454_v9, %v132674_v12 (stack54)
        %v37005_v30 = vadd.s32 %v37002_v24, %v36997_v30 (stack40)
        %v37007_v11 = vshll.u32 %v37002_v24, 15 (stack45)
        %v37008_v22 = vshrl.u32 %v37002_v24, 17 (stack46)
        %v120736_v41 = vpop.eup %120735 (stack73)
        %v36210_v8 = vand.u32.u16 65535, %v36209_v29 (stack52)
        %v36620_v6 = vadd.s32 4, %v36616_v55 (stack40)
        %v37417_v26 = vshrl.u32 %v37410_v54, 15 (stack46)
        %v37877_v50 = vor.u32 %v37876_v21, %v37875_v50 (stack47)
        %v35462_v40 = vsel /*vm=*/%vm132872_vm10, /*on_true_vy=*/%v132833_v40, /*on_false_vx=*/%v35458_v12 (stack44)
        %v35839_v43 = vmul.f32 %v120736_v41, %v132827_v56 (stack74)
        %v37009_v44 = vor.u32 %v37008_v22, %v37007_v11 (stack47)
        %v132892_v52 = vadd.s32 %v157298_v34, %v157076_v35 (stack40)
        %v35466_v54 = vmul.f32 1.4140625, %v35462_v40 (stack54)
        %v119936_v21 = vadd.low.f32.bf16 -1.0, %v36210_v8 (stack53)
        %v36624_v9 = vadd.s32 %v36620_v6, %v36608_v27 (stack40)
        %v36626_v27 = vshll.u32 %v36620_v6, 13 (stack45)
        %v35841_v24 = vsel /*vm=*/%vm35840_vm11, /*on_true_vy=*/%v132827_v56, /*on_false_vx=*/%v35839_v43 (stack75)
        %v36627_v29 = vshrl.u32 %v36620_v6, 19 (stack46)
        %v37010_v55 = vxor.u32 %v37009_v44, %v37005_v30 (stack48)
        %v37418_v10 = vor.u32 %v37417_v26, %v37416_v10 (stack47)
        %v35469_v12 = vpack.c.bf16 %v156663_v45, %v35466_v54 (stack81)
        %v35844_v32 = vsel /*vm=*/%vm35842_vm12, /*on_true_vy=*/%v35843_v32, /*on_false_vx=*/%v35841_v24 (stack76)
        %v36219_v11 = vmul.f32 2.0, %v119936_v21 (stack54)
        %v37878_v22 = vxor.u32 %v37877_v50, %v37873_v60 (stack48)
        %v35847_v41 = vadd.f32 -3.0, %v35844_v32 (stack53)
        %v36628_v8 = vor.u32 %v36627_v29, %v36626_v27 (stack47)
        %v37013_v30 = vadd.s32 %v37010_v55, %v37005_v30 (stack40)
        %v37015_v6 = vshll.u32 %v37010_v55, 26 (stack45)
        %119933 = vst [vmem:[%s123356_s30 + $0x124] sm:$0xf] /*vst_source=*/%v35469_v12 (stack83)
        %v36223_v26 = vadd.f32 -0.99609375, %v36219_v11 (stack53)
        %v37016_v50 = vshrl.u32 %v37010_v55, 6 (stack46)
        %v37419_v40 = vxor.u32 %v37418_v10, %v37414_v46 (stack48)
        %v37881_v60 = vadd.s32 %v37878_v22, %v37873_v60 (stack40)
        %v132904_v25 = vsel /*vm=*/%vm35795_vm9, /*on_true_vy=*/%v132849_v25, /*on_false_vx=*/%v35847_v41 (stack44)
        %v36629_v43 = vxor.u32 %v36628_v8, %v36624_v9 (stack48)
        %v37883_v44 = vshll.u32 %v37878_v22, 26 (stack45)
        %v37884_v54 = vshrl.u32 %v37878_v22, 6 (stack46)
        %v35855_v31 = vmul.f32 %v132904_v25, %v132870_v31 (stack54)
        %v132908_v21 = vmax.f32 %v36223_v26, -0.99609375 (stack55)
        %v37017_v27 = vor.u32 %v37016_v50, %v37015_v6 (stack47)
        %v37422_v46 = vadd.s32 %v37419_v40, %v37414_v46 (stack40)
        %v35828_v24 = vsel /*vm=*/%vm35795_vm9, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v36632_v9 = vadd.s32 %v36629_v43, %v36624_v9 (stack40)
        %v36634_v29 = vshll.u32 %v36629_v43, 15 (stack45)
        %v36635_v55 = vshrl.u32 %v36629_v43, 17 (stack46)
        %v132916_v10 = vsel /*vm=*/%vm35795_vm9, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v35816_v12 = vsel /*vm=*/%vm35795_vm9, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v35859_v32 = vadd.f32 %v35855_v31, %v35828_v24 (stack53)
        %v36239_v11 = vxor.u32 2147483648, %v132908_v21 (stack56)
        %v35824_v22 = vsel /*vm=*/%vm35795_vm9, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v36636_v41 = vor.u32 %v36635_v55, %v36634_v29 (stack47)
        %v37018_v8 = vxor.u32 %v37017_v27, %v37013_v30 (stack48)
        %v37424_v6 = vshll.u32 %v37419_v40, 29 (stack45)
        %v35863_v26 = vmul.f32 %v35859_v32, %v132904_v25 (stack54)
        %v36242_v50 = vmul.f32 %v36239_v11, %v132908_v21 (stack54)
        %v37425_v40 = vshrl.u32 %v37419_v40, 3 (stack46)
        %v37885_v43 = vor.u32 %v37884_v54, %v37883_v44 (stack47)
        %v36637_v44 = vxor.u32 %v36636_v41, %v36632_v9 (stack48)
        %v37021_v30 = vadd.s32 %v37018_v8, %v37013_v30 (stack40)
        %v37027_v54 = vshll.u32 %v37018_v8, 6 (stack45)
        %v37028_v31 = vshrl.u32 %v37018_v8, 26 (stack46)
        %v35820_v27 = vsel /*vm=*/%vm35795_vm9, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v35867_v24 = vadd.f32 %v35863_v26, %v35824_v22 (stack53)
        %v36244_v29 = vadd.f32 1.0, %v36242_v50 (stack57)
        %v36247_v55 = vmul.f32 -0.5, %v36242_v50 (stack59)
        %v36640_v9 = vadd.s32 %v36637_v44, %v36632_v9 (stack40)
        %v36642_v32 = vshll.u32 %v36637_v44, 26 (stack45)
        %v36643_v11 = vshrl.u32 %v36637_v44, 6 (stack46)
        %vm38287_vm14 = vcmp.lt.u32.totalorder %v132854_v53, %v132774_v23 (stack43)
        %v35871_v22 = vmul.f32 %v35867_v24, %v132904_v25 (stack54)
        %120737 = vlog2.f32 %v36244_v29 (stack58)
        %v36250_v41 = vand.u32 2147483647, %v36242_v50 (stack60)
        %v38301_v8 = vadd.s32 1, %v132892_v52 (stack40)
        %v36644_v26 = vor.u32 %v36643_v11, %v36642_v32 (stack47)
        %v37029_v44 = vor.u32 %v37028_v31, %v37027_v54 (stack47)
        %v37426_v6 = vor.u32 %v37425_v40, %v37424_v6 (stack47)
        %v37886_v40 = vxor.u32 %v37885_v43, %v37881_v60 (stack48)
        %v35875_v43 = vadd.f32 %v35871_v22, %v35820_v27 (stack53)
        %v36248_v54 = vadd.f32 1.0, %v36247_v55 (stack61)
        %v37025_v31 = vadd.s32 %v37021_v30, %v121574_v2 (stack40)
        %v38305_v52 = vsel /*vm=*/%vm38292_vm13, /*on_true_vy=*/%v38301_v8, /*on_false_vx=*/%v132892_v52 (stack44)
        %v36645_v27 = vxor.u32 %v36644_v26, %v36640_v9 (stack48)
        %v37030_v30 = vxor.u32 %v37029_v44, %v37021_v30 (stack48)
        %v37427_v24 = vxor.u32 %v37426_v6, %v37422_v46 (stack48)
        %v37889_v60 = vadd.s32 %v37886_v40, %v37881_v60 (stack40)
        %v35879_v29 = vmul.f32 %v35875_v43, %v132904_v25 (stack54)
        %v37895_v55 = vshll.u32 %v37886_v40, 6 (stack45)
        %v37896_v32 = vshrl.u32 %v37886_v40, 26 (stack46)
        %v38309_v11 = vadd.s32 1, %v38305_v52 (stack40)
        %v36648_v9 = vadd.s32 %v36645_v27, %v36640_v9 (stack40)
        %v36654_v22 = vshll.u32 %v36645_v27, 6 (stack45)
        %v36655_v8 = vshrl.u32 %v36645_v27, 26 (stack46)
        %v37033_v26 = vadd.s32 %v37030_v30, %v121569_v1 (stack40)
        %v35883_v12 = vadd.f32 %v35879_v29, %v35816_v12 (stack53)
        %v37430_v46 = vadd.s32 %v37427_v24, %v37422_v46 (stack40)
        %v37432_v44 = vshll.u32 %v37427_v24, 16 (stack45)
        %v37433_v6 = vshrl.u32 %v37427_v24, 16 (stack46)
        %v36249_v50 = vmul.f32 %v36248_v54, %v36242_v50 (stack63)
        %vm132941_vm15 = vcmp.lt.f32.partialorder %v36250_v41, 0.0004427343 (stack62)
        %v36656_v40 = vor.u32 %v36655_v8, %v36654_v22 (stack47)
        %v37037_v43 = vadd.s32 3, %v37033_v26 (stack40)
        %v35887_v54 = vmul.f32 %v35883_v12, %v132904_v25 (stack54)
        %v37434_v27 = vor.u32 %v37433_v6, %v37432_v44 (stack47)
        %v37897_v30 = vor.u32 %v37896_v32, %v37895_v55 (stack47)
        %v38313_v23 = vsel /*vm=*/%vm38287_vm14, /*on_true_vy=*/%v38309_v11, /*on_false_vx=*/%v38305_v52 (stack44)
        %v36657_v52 = vxor.u32 %v36656_v40, %v36648_v9 (stack48)
        %v37041_v31 = vadd.s32 %v37037_v43, %v37025_v31 (stack40)
        %v37043_v24 = vshll.u32 %v37037_v43, 17 (stack45)
        %v37044_v29 = vshrl.u32 %v37037_v43, 15 (stack46)
        %v35891_v10 = vadd.f32 %v35887_v54, %v132916_v10 (stack53)
        %v37435_v55 = vxor.u32 %v37434_v27, %v37430_v46 (stack48)
        %v37898_v32 = vxor.u32 %v37897_v30, %v37889_v60 (stack48)
        %v38318_v11 = vadd.s32 %v38313_v23, %v121574_v2 (stack40)
        %v36652_v9 = vadd.s32 %v36648_v9, %v121564_v0 (stack40)
        %v36660_v22 = vadd.s32 %v36657_v52, %v121574_v2 (stack40)
        %v37045_v8 = vor.u32 %v37044_v29, %v37043_v24 (stack47)
        %v38322_v53 = vadd.s32 %v132854_v53, %v121569_v1 (stack40)
        %v35895_v26 = vmul.f32 %v35891_v10, %v132904_v25 (stack54)
        %v37438_v12 = vadd.s32 %v37435_v55, %v37430_v46 (stack40)
        %v37444_v46 = vshll.u32 %v37435_v55, 24 (stack45)
        %v37445_v44 = vshrl.u32 %v37435_v55, 8 (stack46)
        %v120738_v6 = vpop.eup %120737 (stack64)
        %v36664_v40 = vadd.s32 5, %v36660_v22 (stack40)
        %v37046_v43 = vxor.u32 %v37045_v8, %v37041_v31 (stack48)
        %v37901_v54 = vadd.s32 %v37898_v32, %v121564_v0 (stack40)
        %v38326_v27 = vadd.s32 %v38322_v53, %v38318_v11 (stack40)
        %v35899_v20 = vadd.f32 %v35895_v26, %v132865_v20 (stack53)
        %v36246_v30 = vmul.f32 0.6931472, %v120738_v6 (stack65)
        %v37446_v23 = vor.u32 %v37445_v44, %v37444_v46 (stack47)
        %v37893_v60 = vadd.s32 %v37889_v60, %v121569_v1 (stack40)
        %v36666_v52 = vxor.u32 %v36664_v40, %v36652_v9 (stack48)
        %v37049_v31 = vadd.s32 %v37046_v43, %v37041_v31 (stack40)
        %v37051_v24 = vshll.u32 %v37046_v43, 29 (stack45)
        %v37052_v29 = vshrl.u32 %v37046_v43, 3 (stack46)
        %v35903_v10 = vmul.f32 %v35899_v20, %v132904_v25 (stack54)
        %v36252_v50 = vsel /*vm=*/%vm132941_vm15, /*on_true_vy=*/%v36249_v50, /*on_false_vx=*/%v36246_v30 (stack66)
        %v37447_v41 = vxor.u32 %v37446_v23, %v37438_v12 (stack48)
        %v37905_v55 = vadd.s32 1, %v37901_v54 (stack40)
        %v132962_v32 = vxor.u32 2147483648, %v36252_v50 (stack56)
        %v37053_v11 = vor.u32 %v37052_v29, %v37051_v24 (stack47)
        %v38328_v9 = vshll.u32 %v38322_v53, 13 (stack45)
        %v38329_v22 = vshrl.u32 %v38322_v53, 19 (stack46)
        %v35768_v8 = vand.u32 2147483647, %v132777_v61 (stack77)
        %v35907_v42 = vadd.f32 %v35903_v10, %v132860_v42 (stack53)
        %v37909_v53 = vadd.s32 %v37905_v55, %v37893_v60 (stack40)
        %120739 = vrsqrt.f32 %v132962_v32 (stack67)
        %v36667_v26 = vand.u32.u8 255, %v36666_v52 (stack49)
        %v35911_v25 = vmul.f32 %v35907_v42, %v132904_v25 (stack54)
        %v37450_v46 = vadd.s32 %v37447_v41, %v121574_v2 (stack40)
        %v35800_v56 = vsel /*vm=*/%vm35795_vm9, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v37054_v44 = vxor.u32 %v37053_v11, %v37049_v31 (stack48)
        %v38330_v6 = vor.u32 %v38329_v22, %v38328_v9 (stack47)
        %vm132972_vm0 = vcmp.eq.f32.partialorder %v35768_v8, 1.0 (stack68)
        %v35776_v43 = vmul.f32 inf, %v132777_v61 (stack54)
        %v35915_v54 = vadd.f32 %v35911_v25, %v35800_v56 (stack53)
        %v36229_v20 = vand.u32 2147483647, %v132908_v21 (stack77)
        %v36668_v30 = vand.u32 65535, %v36667_v26 (stack50)
        %v37057_v23 = vadd.s32 %v37054_v44, %v37049_v31 (stack40)
        %v37442_v12 = vadd.s32 %v37438_v12, %v121564_v0 (stack40)
        %v37911_v60 = vshll.u32 %v37905_v55, 17 (stack45)
        %v35919_v61 = vmul.f32 %v35915_v54, %v132777_v61 (stack54)
        %v37059_v52 = vshll.u32 %v37054_v44, 16 (stack45)
        %v37060_v31 = vshrl.u32 %v37054_v44, 16 (stack46)
        %v37454_v24 = vadd.s32 2, %v37450_v46 (stack40)
        %v36669_v29 = vshrl.u32 %v36668_v30, 1 (stack51)
        %v37912_v10 = vshrl.u32 %v37905_v55, 15 (stack46)
        %v38331_v50 = vxor.u32 %v38330_v6, %v38326_v27 (stack48)
        %v132982_v41 = vadd.s32 %v157297_v7, %v157077_v51 (stack40)
        %v35923_v55 = vsel /*vm=*/%vm132972_vm0, /*on_true_vy=*/%v35776_v43, /*on_false_vx=*/%v35919_v61 (stack44)
        %vm36256_vm1 = vcmp.lt.f32.partialorder %v132962_v32, 5.0 (stack68)
        %vm36301_vm2 = vcmp.eq.f32.partialorder %v132962_v32, inf (stack70)
        %v37061_v11 = vor.u32 %v37060_v31, %v37059_v52 (stack47)
        %v37458_v9 = vadd.s32 %v37454_v24, %v37442_v12 (stack40)
        %v37460_v22 = vshll.u32 %v37454_v24, 13 (stack45)
        %v35927_v8 = vmul.f32 1.4140625, %v35923_v55 (stack54)
        %vm36303_vm3 = vcmp.eq.f32.partialorder %v132962_v32, 0.0 (stack71)
        %v36670_v42 = vor.u32 16256, %v36669_v29 (stack47)
        %v37461_v26 = vshrl.u32 %v37454_v24, 19 (stack46)
        %v37913_v25 = vor.u32 %v37912_v10, %v37911_v60 (stack47)
        %v37062_v46 = vxor.u32 %v37061_v11, %v37057_v23 (stack48)
        %v38334_v27 = vadd.s32 %v38331_v50, %v38326_v27 (stack40)
        %v38336_v56 = vshll.u32 %v38331_v50, 15 (stack45)
        %v38337_v44 = vshrl.u32 %v38331_v50, 17 (stack46)
        %v35930_v6 = vpack.c.bf16 %v156663_v45, %v35927_v8 (stack81)
        %v36671_v40 = vand.u32.u16 65535, %v36670_v42 (stack52)
        %v37462_v43 = vor.u32 %v37461_v26, %v37460_v22 (stack47)
        %v37914_v54 = vxor.u32 %v37913_v25, %v37909_v53 (stack48)
        %v37065_v30 = vadd.s32 %v37062_v46, %v37057_v23 (stack40)
        %v37071_v23 = vshll.u32 %v37062_v46, 24 (stack45)
        %v37072_v12 = vshrl.u32 %v37062_v46, 8 (stack46)
        %v38338_v60 = vor.u32 %v38337_v44, %v38336_v56 (stack47)
        %119935 = vst [vmem:[%s123356_s30 + $0x1a4] sm:$0xf] /*vst_source=*/%v35930_v6 (stack83)
        %v119938_v61 = vadd.low.f32.bf16 -1.0, %v36671_v40 (stack53)
        %v37463_v52 = vxor.u32 %v37462_v43, %v37458_v9 (stack48)
        %v37917_v53 = vadd.s32 %v37914_v54, %v37909_v53 (stack40)
        %v37919_v31 = vshll.u32 %v37914_v54, 29 (stack45)
        %v120740_v24 = vpop.eup %120739 (stack73)
        %v36304_v29 = vand.u32 2147483648, %v132962_v32 (stack72)
        %v37073_v10 = vor.u32 %v37072_v12, %v37071_v23 (stack47)
        %v37920_v50 = vshrl.u32 %v37914_v54, 3 (stack46)
        %v38339_v55 = vxor.u32 %v38338_v60, %v38334_v27 (stack48)
        %v36300_v11 = vmul.f32 %v120740_v24, %v132962_v32 (stack74)
        %v36680_v22 = vmul.f32 2.0, %v119938_v61 (stack54)
        %v37466_v9 = vadd.s32 %v37463_v52, %v37458_v9 (stack40)
        %v37468_v8 = vshll.u32 %v37463_v52, 15 (stack45)
        %v37074_v42 = vxor.u32 %v37073_v10, %v37065_v30 (stack48)
        %v37469_v26 = vshrl.u32 %v37463_v52, 17 (stack46)
        %v37921_v25 = vor.u32 %v37920_v50, %v37919_v31 (stack47)
        %v38342_v46 = vadd.s32 %v38339_v55, %v38334_v27 (stack40)
        %v36302_v27 = vsel /*vm=*/%vm36301_vm2, /*on_true_vy=*/%v132962_v32, /*on_false_vx=*/%v36300_v11 (stack75)
        %v36684_v56 = vadd.f32 -0.99609375, %v36680_v22 (stack53)
        %v38344_v44 = vshll.u32 %v38339_v55, 26 (stack45)
        %v38345_v6 = vshrl.u32 %v38339_v55, 6 (stack46)
        %v36305_v40 = vsel /*vm=*/%vm36303_vm3, /*on_true_vy=*/%v36304_v29, /*on_false_vx=*/%v36302_v27 (stack76)
        %v37077_v43 = vadd.s32 %v37074_v42, %v121564_v0 (stack40)
        %v37470_v54 = vor.u32 %v37469_v26, %v37468_v8 (stack47)
        %v37922_v23 = vxor.u32 %v37921_v25, %v37917_v53 (stack48)
        %v36293_v12 = vsel /*vm=*/%vm36256_vm1, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v36297_v60 = vadd.f32 -2.5, %v132962_v32 (stack53)
        %v36308_v61 = vadd.f32 -3.0, %v36305_v40 (stack53)
        %v133003_v52 = vmax.f32 %v36684_v56, -0.99609375 (stack55)
        %v37069_v30 = vadd.s32 %v37065_v30, %v121569_v1 (stack40)
        %v37081_v31 = vadd.s32 4, %v37077_v43 (stack40)
        %v37471_v24 = vxor.u32 %v37470_v54, %v37466_v9 (stack48)
        %v37925_v53 = vadd.s32 %v37922_v23, %v37917_v53 (stack40)
        %v133008_v29 = vsel /*vm=*/%vm36256_vm1, /*on_true_vy=*/%v36297_v60, /*on_false_vx=*/%v36308_v61 (stack44)
        %v36700_v10 = vxor.u32 2147483648, %v133003_v52 (stack56)
        %v37927_v50 = vshll.u32 %v37922_v23, 16 (stack45)
        %v38346_v55 = vor.u32 %v38345_v6, %v38344_v44 (stack47)
        %v36316_v11 = vmul.f32 %v133008_v29, %v36293_v12 (stack54)
        %v37085_v22 = vadd.s32 %v37081_v31, %v37069_v30 (stack40)
        %v37087_v8 = vshll.u32 %v37081_v31, 13 (stack45)
        %v37088_v42 = vshrl.u32 %v37081_v31, 19 (stack46)
        %v36289_v26 = vsel /*vm=*/%vm36256_vm1, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v36703_v25 = vmul.f32 %v36700_v10, %v133003_v52 (stack54)
        %v37474_v9 = vadd.s32 %v37471_v24, %v37466_v9 (stack40)
        %v37476_v27 = vshll.u32 %v37471_v24, 26 (stack45)
        %v36320_v56 = vadd.f32 %v36316_v11, %v36289_v26 (stack53)
        %v37089_v44 = vor.u32 %v37088_v42, %v37087_v8 (stack47)
        %v37477_v6 = vshrl.u32 %v37471_v24, 6 (stack46)
        %v37928_v40 = vshrl.u32 %v37922_v23, 16 (stack46)
        %v36273_v43 = vsel /*vm=*/%vm36256_vm1, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v36277_v54 = vsel /*vm=*/%vm36256_vm1, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v36705_v23 = vadd.f32 1.0, %v36703_v25 (stack57)
        %v38347_v12 = vxor.u32 %v38346_v55, %v38342_v46 (stack48)
        %v36324_v60 = vmul.f32 %v36320_v56, %v133008_v29 (stack54)
        %v37090_v61 = vxor.u32 %v37089_v44, %v37085_v22 (stack48)
        %v37478_v30 = vor.u32 %v37477_v6, %v37476_v27 (stack47)
        %v37929_v31 = vor.u32 %v37928_v40, %v37927_v50 (stack47)
        %v36281_v24 = vsel /*vm=*/%vm36256_vm1, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v36285_v10 = vsel /*vm=*/%vm36256_vm1, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %120741 = vlog2.f32 %v36705_v23 (stack58)
        %v38350_v46 = vadd.s32 %v38347_v12, %v38342_v46 (stack40)
        %v36328_v50 = vadd.f32 %v36324_v60, %v36285_v10 (stack53)
        %v37093_v55 = vadd.s32 %v37090_v61, %v37085_v22 (stack40)
        %v37095_v11 = vshll.u32 %v37090_v61, 15 (stack45)
        %v37096_v22 = vshrl.u32 %v37090_v61, 17 (stack46)
        %v36708_v8 = vmul.f32 -0.5, %v36703_v25 (stack59)
        %v36711_v42 = vand.u32 2147483647, %v36703_v25 (stack60)
        %v37479_v26 = vxor.u32 %v37478_v30, %v37474_v9 (stack48)
        %v37930_v27 = vxor.u32 %v37929_v31, %v37925_v53 (stack48)
        %v36332_v56 = vmul.f32 %v36328_v50, %v133008_v29 (stack54)
        %v37097_v44 = vor.u32 %v37096_v22, %v37095_v11 (stack47)
        %v38356_v6 = vshll.u32 %v38347_v12, 6 (stack45)
        %v38357_v40 = vshrl.u32 %v38347_v12, 26 (stack46)
        %v37482_v9 = vadd.s32 %v37479_v26, %v37474_v9 (stack40)
        %v37488_v23 = vshll.u32 %v37479_v26, 6 (stack45)
        %v37489_v12 = vshrl.u32 %v37479_v26, 26 (stack46)
        %v37933_v53 = vadd.s32 %v37930_v27, %v37925_v53 (stack40)
        %v36336_v60 = vadd.f32 %v36332_v56, %v36281_v24 (stack53)
        %v37098_v61 = vxor.u32 %v37097_v44, %v37093_v55 (stack48)
        %v37939_v30 = vshll.u32 %v37930_v27, 24 (stack45)
        %v37940_v31 = vshrl.u32 %v37930_v27, 8 (stack46)
        %v36709_v24 = vadd.f32 1.0, %v36708_v8 (stack61)
        %v37490_v10 = vor.u32 %v37489_v12, %v37488_v23 (stack47)
        %v38358_v50 = vor.u32 %v38357_v40, %v38356_v6 (stack47)
        %v133032_v11 = vadd.s32 %v132982_v41, %v122657_v58 (stack40)
        %v36340_v22 = vmul.f32 %v36336_v60, %v133008_v29 (stack54)
        %v37101_v55 = vadd.s32 %v37098_v61, %v37093_v55 (stack40)
        %v37103_v8 = vshll.u32 %v37098_v61, 26 (stack45)
        %v37104_v26 = vshrl.u32 %v37098_v61, 6 (stack46)
        %vm133035_vm4 = vcmp.lt.f32.partialorder %v36711_v42, 0.0004427343 (stack62)
        %v37491_v27 = vxor.u32 %v37490_v10, %v37482_v9 (stack48)
        %v37941_v56 = vor.u32 %v37940_v31, %v37939_v30 (stack47)
        %v38359_v44 = vxor.u32 %v38358_v50, %v38350_v46 (stack48)
        %v36344_v54 = vadd.f32 %v36340_v22, %v36277_v54 (stack53)
        %v37105_v6 = vor.u32 %v37104_v26, %v37103_v8 (stack47)
        %vm38753_vm5 = vcmp.lt.u32.totalorder %v132982_v41, %v157077_v51 (stack43)
        %v133043_v40 = vadd.s32 %v157298_v34, %v157078_v48 (stack40)
        %v36710_v25 = vmul.f32 %v36709_v24, %v36703_v25 (stack63)
        %v37494_v23 = vadd.s32 %v37491_v27, %v121569_v1 (stack40)
        %v37942_v12 = vxor.u32 %v37941_v56, %v37933_v53 (stack48)
        %v38362_v60 = vadd.s32 %v38359_v44, %v121564_v0 (stack40)
        %v36348_v61 = vmul.f32 %v36344_v54, %v133008_v29 (stack54)
        %v37106_v30 = vxor.u32 %v37105_v6, %v37101_v55 (stack48)
        %v38354_v46 = vadd.s32 %v38350_v46, %v121569_v1 (stack40)
        %v133051_v31 = vadd.s32 %v157297_v7, %v157079_v39 (stack40)
        %v37486_v9 = vadd.s32 %v37482_v9, %v121574_v2 (stack40)
        %v37498_v24 = vadd.s32 3, %v37494_v23 (stack40)
        %v37945_v10 = vadd.s32 %v37942_v12, %v121574_v2 (stack40)
        %v38366_v50 = vadd.s32 1, %v38362_v60 (stack40)
        %v120742_v22 = vpop.eup %120741 (stack64)
        %v36352_v43 = vadd.f32 %v36348_v61, %v36273_v43 (stack53)
        %v37109_v55 = vadd.s32 %v37106_v30, %v37101_v55 (stack40)
        %v37115_v8 = vshll.u32 %v37106_v30, 6 (stack45)
        %v37116_v26 = vshrl.u32 %v37106_v30, 26 (stack46)
        %v36707_v27 = vmul.f32 0.6931472, %v120742_v22 (stack65)
        %v37502_v56 = vadd.s32 %v37498_v24, %v37486_v9 (stack40)
        %v37504_v44 = vshll.u32 %v37498_v24, 17 (stack45)
        %v37505_v54 = vshrl.u32 %v37498_v24, 15 (stack46)
        %v36356_v6 = vmul.f32 %v36352_v43, %v133008_v29 (stack54)
        %v37117_v23 = vor.u32 %v37116_v26, %v37115_v8 (stack47)
        %v37937_v53 = vadd.s32 %v37933_v53, %v121564_v0 (stack40)
        %v37949_v12 = vadd.s32 2, %v37945_v10 (stack40)
        %v36269_v60 = vsel /*vm=*/%vm36256_vm1, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v36713_v42 = vsel /*vm=*/%vm133035_vm4, /*on_true_vy=*/%v36710_v25, /*on_false_vx=*/%v36707_v27 (stack66)
        %v37506_v25 = vor.u32 %v37505_v54, %v37504_v44 (stack47)
        %v38370_v61 = vadd.s32 %v38366_v50, %v38354_v46 (stack40)
        %v36360_v30 = vadd.f32 %v36356_v6, %v36269_v60 (stack53)
        %v133062_v46 = vxor.u32 2147483648, %v36713_v42 (stack56)
        %v37118_v9 = vxor.u32 %v37117_v23, %v37109_v55 (stack48)
        %v37953_v24 = vadd.s32 %v37949_v12, %v37937_v53 (stack40)
        %v36237_v10 = vmul.f32 inf, %v132908_v21 (stack54)
        %v36261_v22 = vsel /*vm=*/%vm36256_vm1, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v37507_v43 = vxor.u32 %v37506_v25, %v37502_v56 (stack48)
        %v133070_v8 = vadd.s32 %v133032_v11, %v121569_v1 (stack40)
        %v36265_v32 = vsel /*vm=*/%vm36256_vm1, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v36364_v26 = vmul.f32 %v36360_v30, %v133008_v29 (stack54)
        %v36690_v27 = vand.u32 2147483647, %v133003_v52 (stack77)
        %120743 = vrsqrt.f32 %v133062_v46 (stack67)
        %vm133080_vm6 = vcmp.eq.f32.partialorder %v36229_v20, 1.0 (stack68)
        %vm36717_vm7 = vcmp.lt.f32.partialorder %v133062_v46, 5.0 (stack68)
        %v37121_v44 = vadd.s32 %v37118_v9, %v121574_v2 (stack40)
        %v37955_v54 = vshll.u32 %v37949_v12, 13 (stack45)
        %v37956_v6 = vshrl.u32 %v37949_v12, 19 (stack46)
        %vm38748_vm8 = vcmp.lt.u32.totalorder %v133032_v11, %v132982_v41 (stack43)
        %v36368_v23 = vadd.f32 %v36364_v26, %v36265_v32 (stack53)
        %v38372_v53 = vshll.u32 %v38366_v50, 17 (stack45)
        %v38373_v50 = vshrl.u32 %v38366_v50, 15 (stack46)
        %v38762_v12 = vadd.s32 1, %v133043_v40 (stack40)
        %v133090_v60 = vadd.f32 -2.5, %v133062_v46 (stack53)
        %v37113_v55 = vadd.s32 %v37109_v55, %v121564_v0 (stack40)
        %v37510_v56 = vadd.s32 %v37507_v43, %v37502_v56 (stack40)
        %v38789_v42 = vshll.u32 %v133070_v8, 13 (stack45)
        %v36372_v29 = vmul.f32 %v36368_v23, %v133008_v29 (stack54)
        %v133098_v25 = vsel /*vm=*/%vm36717_vm7, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v133103_v30 = vsel /*vm=*/%vm36717_vm7, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v133108_v9 = vsel /*vm=*/%vm36717_vm7, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v37125_v32 = vadd.s32 5, %v37121_v44 (stack40)
        %v37512_v26 = vshll.u32 %v37507_v43, 29 (stack45)
        %v37513_v43 = vshrl.u32 %v37507_v43, 3 (stack46)
        %v37957_v44 = vor.u32 %v37956_v6, %v37955_v54 (stack47)
        %v36376_v22 = vadd.f32 %v36372_v29, %v36261_v22 (stack53)
        %v133113_v54 = vsel /*vm=*/%vm36717_vm7, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v38374_v6 = vor.u32 %v38373_v50, %v38372_v53 (stack47)
        %v38766_v40 = vsel /*vm=*/%vm38753_vm5, /*on_true_vy=*/%v38762_v12, /*on_false_vx=*/%v133043_v40 (stack44)
        %vm36762_vm9 = vcmp.eq.f32.partialorder %v133062_v46, inf (stack70)
        %v36765_v23 = vand.u32 2147483648, %v133062_v46 (stack72)
        %v37127_v53 = vxor.u32 %v37125_v32, %v37113_v55 (stack48)
        %v37514_v50 = vor.u32 %v37513_v43, %v37512_v26 (stack47)
        %v37958_v12 = vxor.u32 %v37957_v44, %v37953_v24 (stack48)
        %v36380_v21 = vmul.f32 %v36376_v22, %v132908_v21 (stack54)
        %vm36764_vm10 = vcmp.eq.f32.partialorder %v133062_v46, 0.0 (stack71)
        %v38375_v55 = vxor.u32 %v38374_v6, %v38370_v61 (stack48)
        %v38770_v29 = vadd.s32 1, %v38766_v40 (stack40)
        %v38790_v32 = vshrl.u32 %v133070_v8, 19 (stack46)
        %v37128_v26 = vand.u32.u8 255, %v37127_v53 (stack49)
        %v37515_v43 = vxor.u32 %v37514_v50, %v37510_v56 (stack48)
        %v37961_v24 = vadd.s32 %v37958_v12, %v37953_v24 (stack40)
        %v37963_v44 = vshll.u32 %v37958_v12, 15 (stack45)
        %v36384_v10 = vsel /*vm=*/%vm133080_vm6, /*on_true_vy=*/%v36237_v10, /*on_false_vx=*/%v36380_v21 (stack44)
        %v37964_v20 = vshrl.u32 %v37958_v12, 17 (stack46)
        %v38378_v61 = vadd.s32 %v38375_v55, %v38370_v61 (stack40)
        %v38380_v22 = vshll.u32 %v38375_v55, 29 (stack45)
        %v36388_v6 = vmul.f32 1.4140625, %v36384_v10 (stack54)
        %v37129_v53 = vand.u32 65535, %v37128_v26 (stack50)
        %v37518_v56 = vadd.s32 %v37515_v43, %v37510_v56 (stack40)
        %v37520_v50 = vshll.u32 %v37515_v43, 16 (stack45)
        %v37521_v12 = vshrl.u32 %v37515_v43, 16 (stack46)
        %v37965_v21 = vor.u32 %v37964_v20, %v37963_v44 (stack47)
        %v38381_v55 = vshrl.u32 %v38375_v55, 3 (stack46)
        %v38774_v41 = vsel /*vm=*/%vm38748_vm8, /*on_true_vy=*/%v38770_v29, /*on_false_vx=*/%v38766_v40 (stack44)
        %v120744_v11 = vpop.eup %120743 (stack73)
        %v36391_v40 = vpack.c.bf16 %v156663_v45, %v36388_v6 (stack81)
        %v37130_v29 = vshrl.u32 %v37129_v53, 1 (stack51)
        %v38779_v26 = vadd.s32 %v38774_v41, %v121574_v2 (stack40)
        %v38791_v42 = vor.u32 %v38790_v32, %v38789_v42 (stack47)
        %v36761_v32 = vmul.f32 %v120744_v11, %v133062_v46 (stack74)
        %v37522_v43 = vor.u32 %v37521_v12, %v37520_v50 (stack47)
        %v37966_v44 = vxor.u32 %v37965_v21, %v37961_v24 (stack48)
        %v38382_v10 = vor.u32 %v38381_v55, %v38380_v22 (stack47)
        %119937 = vst [vmem:[%s123356_s30 + $0x224] sm:$0xf] /*vst_source=*/%v36391_v40 (stack83)
        %v37131_v20 = vor.u32 16256, %v37130_v29 (stack47)
        %v38787_v8 = vadd.s32 %v133070_v8, %v38779_v26 (stack40)
        %vm39214_vm11 = vcmp.lt.u32.totalorder %v133051_v31, %v157079_v39 (stack43)
        %v133138_v22 = vadd.s32 %v157298_v34, %v157082_v49 (stack40)
        %v36763_v6 = vsel /*vm=*/%vm36762_vm9, /*on_true_vy=*/%v133062_v46, /*on_false_vx=*/%v36761_v32 (stack75)
        %v37523_v53 = vxor.u32 %v37522_v43, %v37518_v56 (stack48)
        %v37969_v24 = vadd.s32 %v37966_v44, %v37961_v24 (stack40)
        %v37971_v50 = vshll.u32 %v37966_v44, 26 (stack45)
        %v36766_v23 = vsel /*vm=*/%vm36764_vm10, /*on_true_vy=*/%v36765_v23, /*on_false_vx=*/%v36763_v6 (stack76)
        %v37132_v12 = vand.u32.u16 65535, %v37131_v20 (stack52)
        %v37972_v21 = vshrl.u32 %v37966_v44, 6 (stack46)
        %v38383_v55 = vxor.u32 %v38382_v10, %v38378_v61 (stack48)
        %v36769_v41 = vadd.f32 -3.0, %v36766_v23 (stack53)
        %v37526_v56 = vadd.s32 %v37523_v53, %v37518_v56 (stack40)
        %v37532_v11 = vshll.u32 %v37523_v53, 24 (stack45)
        %v37533_v40 = vshrl.u32 %v37523_v53, 8 (stack46)
        %v119940_v29 = vadd.low.f32.bf16 -1.0, %v37132_v12 (stack53)
        %v37973_v26 = vor.u32 %v37972_v21, %v37971_v50 (stack47)
        %v38386_v61 = vadd.s32 %v38383_v55, %v38378_v61 (stack40)
        %v38388_v32 = vshll.u32 %v38383_v55, 16 (stack45)
        %v36754_v43 = vsel /*vm=*/%vm36717_vm7, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v133151_v60 = vsel /*vm=*/%vm36717_vm7, /*on_true_vy=*/%v133090_v60, /*on_false_vx=*/%v36769_v41 (stack44)
        %v37534_v44 = vor.u32 %v37533_v40, %v37532_v11 (stack47)
        %v38389_v10 = vshrl.u32 %v38383_v55, 16 (stack46)
        %v36777_v20 = vmul.f32 %v133151_v60, %v36754_v43 (stack54)
        %v37141_v6 = vmul.f32 2.0, %v119940_v29 (stack54)
        %v37974_v53 = vxor.u32 %v37973_v26, %v37969_v24 (stack48)
        %v38792_v42 = vxor.u32 %v38791_v42, %v38787_v8 (stack48)
        %v36742_v50 = vsel /*vm=*/%vm36717_vm7, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v36750_v23 = vsel /*vm=*/%vm36717_vm7, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v37535_v12 = vxor.u32 %v37534_v44, %v37526_v56 (stack48)
        %v38390_v21 = vor.u32 %v38389_v10, %v38388_v32 (stack47)
        %v36781_v55 = vadd.f32 %v36777_v20, %v36750_v23 (stack53)
        %v37145_v41 = vadd.f32 -0.99609375, %v37141_v6 (stack53)
        %v37977_v24 = vadd.s32 %v37974_v53, %v37969_v24 (stack40)
        %v37983_v11 = vshll.u32 %v37974_v53, 6 (stack45)
        %v37538_v40 = vadd.s32 %v37535_v12, %v121564_v0 (stack40)
        %v37984_v29 = vshrl.u32 %v37974_v53, 26 (stack46)
        %v38391_v26 = vxor.u32 %v38390_v21, %v38386_v61 (stack48)
        %v38795_v8 = vadd.s32 %v38792_v42, %v38787_v8 (stack40)
        %v36746_v32 = vsel /*vm=*/%vm36717_vm7, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v36785_v43 = vmul.f32 %v36781_v55, %v133151_v60 (stack54)
        %v133165_v44 = vmax.f32 %v37145_v41, -0.99609375 (stack55)
        %v39205_v10 = vadd.s32 %v133051_v31, %v122657_v58 (stack40)
        %v37530_v56 = vadd.s32 %v37526_v56, %v121569_v1 (stack40)
        %v37542_v20 = vadd.s32 4, %v37538_v40 (stack40)
        %v37985_v6 = vor.u32 %v37984_v29, %v37983_v11 (stack47)
        %v38394_v61 = vadd.s32 %v38391_v26, %v38386_v61 (stack40)
        %v36789_v53 = vadd.f32 %v36785_v43, %v36746_v32 (stack53)
        %v37161_v23 = vxor.u32 2147483648, %v133165_v44 (stack56)
        %v38400_v12 = vshll.u32 %v38391_v26, 24 (stack45)
        %v38797_v21 = vshll.u32 %v38792_v42, 15 (stack45)
        %v37546_v55 = vadd.s32 %v37542_v20, %v37530_v56 (stack40)
        %v37548_v41 = vshll.u32 %v37542_v20, 13 (stack45)
        %v37549_v11 = vshrl.u32 %v37542_v20, 19 (stack46)
        %v37986_v40 = vxor.u32 %v37985_v6, %v37977_v24 (stack48)
        %v36793_v29 = vmul.f32 %v36789_v53, %v133151_v60 (stack54)
        %v133173_v32 = vmul.f32 %v37161_v23, %v133165_v44 (stack54)
        %vm39209_vm12 = vcmp.lt.u32.totalorder %v39205_v10, %v133051_v31 (stack43)
        %v39223_v43 = vadd.s32 1, %v133138_v22 (stack40)
        %v37550_v56 = vor.u32 %v37549_v11, %v37548_v41 (stack47)
        %v37989_v20 = vadd.s32 %v37986_v40, %v121569_v1 (stack40)
        %v38401_v26 = vshrl.u32 %v38391_v26, 8 (stack46)
        %v38798_v42 = vshrl.u32 %v38792_v42, 17 (stack46)
        %v36797_v50 = vadd.f32 %v36793_v29, %v36742_v50 (stack53)
        %v37166_v6 = vadd.f32 1.0, %v133173_v32 (stack57)
        %v37981_v24 = vadd.s32 %v37977_v24, %v121574_v2 (stack40)
        %v133181_v53 = vadd.s32 %v39205_v10, %v121569_v1 (stack40)
        %v37551_v23 = vxor.u32 %v37550_v56, %v37546_v55 (stack48)
        %v37993_v41 = vadd.s32 3, %v37989_v20 (stack40)
        %v38402_v12 = vor.u32 %v38401_v26, %v38400_v12 (stack47)
        %v38799_v21 = vor.u32 %v38798_v42, %v38797_v21 (stack47)
        %v36801_v11 = vmul.f32 %v36797_v50, %v133151_v60 (stack54)
        %120745 = vlog2.f32 %v37166_v6 (stack58)
        %v37169_v40 = vmul.f32 -0.5, %v133173_v32 (stack59)
        %v38398_v29 = vadd.s32 %v38394_v61, %v121564_v0 (stack40)
        %v37554_v55 = vadd.s32 %v37551_v23, %v37546_v55 (stack40)
        %v37556_v56 = vshll.u32 %v37551_v23, 15 (stack45)
        %v37557_v20 = vshrl.u32 %v37551_v23, 17 (stack46)
        %v37997_v26 = vadd.s32 %v37993_v41, %v37981_v24 (stack40)
        %v36805_v54 = vadd.f32 %v36801_v11, %v133113_v54 (stack53)
        %v37172_v42 = vand.u32 2147483647, %v133173_v32 (stack60)
        %v37999_v50 = vshll.u32 %v37993_v41, 17 (stack45)
        %v38000_v6 = vshrl.u32 %v37993_v41, 15 (stack46)
        %v37558_v24 = vor.u32 %v37557_v20, %v37556_v56 (stack47)
        %v38403_v61 = vxor.u32 %v38402_v12, %v38394_v61 (stack48)
        %v38800_v23 = vxor.u32 %v38799_v21, %v38795_v8 (stack48)
        %v39227_v22 = vsel /*vm=*/%vm39214_vm11, /*on_true_vy=*/%v39223_v43, /*on_false_vx=*/%v133138_v22 (stack44)
        %v36809_v43 = vmul.f32 %v36805_v54, %v133151_v60 (stack54)
        %v37170_v41 = vadd.f32 1.0, %v37169_v40 (stack61)
        %v38001_v12 = vor.u32 %v38000_v6, %v37999_v50 (stack47)
        %v39231_v21 = vadd.s32 1, %v39227_v22 (stack40)
        %v37559_v11 = vxor.u32 %v37558_v24, %v37554_v55 (stack48)
        %v38406_v40 = vadd.s32 %v38403_v61, %v121574_v2 (stack40)
        %v38803_v8 = vadd.s32 %v38800_v23, %v38795_v8 (stack40)
        %v38805_v56 = vshll.u32 %v38800_v23, 26 (stack45)
        %v36813_v9 = vadd.f32 %v36809_v43, %v133108_v9 (stack53)
        %v38002_v20 = vxor.u32 %v38001_v12, %v37997_v26 (stack48)
        %v38806_v54 = vshrl.u32 %v38800_v23, 6 (stack46)
        %v39235_v31 = vsel /*vm=*/%vm39209_vm12, /*on_true_vy=*/%v39231_v21, /*on_false_vx=*/%v39227_v22 (stack44)
        %v37562_v10 = vadd.s32 %v37559_v11, %v37554_v55 (stack40)
        %v37564_v55 = vshll.u32 %v37559_v11, 26 (stack45)
        %v37565_v50 = vshrl.u32 %v37559_v11, 6 (stack46)
        %v38410_v6 = vadd.s32 2, %v38406_v40 (stack40)
        %v36817_v24 = vmul.f32 %v36813_v9, %v133151_v60 (stack54)
        %v38005_v26 = vadd.s32 %v38002_v20, %v37997_v26 (stack40)
        %v38007_v61 = vshll.u32 %v38002_v20, 29 (stack45)
        %v38008_v23 = vshrl.u32 %v38002_v20, 3 (stack46)
        %v37566_v22 = vor.u32 %v37565_v50, %v37564_v55 (stack47)
        %v38414_v29 = vadd.s32 %v38410_v6, %v38398_v29 (stack40)
        %v38416_v43 = vshll.u32 %v38410_v6, 13 (stack45)
        %v38417_v12 = vshrl.u32 %v38410_v6, 19 (stack46)
        %v36821_v30 = vadd.f32 %v36817_v24, %v133103_v30 (stack53)
        %v38009_v21 = vor.u32 %v38008_v23, %v38007_v61 (stack47)
        %v38807_v11 = vor.u32 %v38806_v54, %v38805_v56 (stack47)
        %v39240_v40 = vadd.s32 %v39235_v31, %v121574_v2 (stack40)
        %vm133200_vm13 = vcmp.lt.f32.partialorder %v37172_v42, 0.0004427343 (stack62)
        %v37567_v56 = vxor.u32 %v37566_v22, %v37562_v10 (stack48)
        %v38418_v9 = vor.u32 %v38417_v12, %v38416_v43 (stack47)
        %v133206_v20 = vadd.s32 %v157297_v7, %v157083_v59 (stack40)
        %v36825_v54 = vmul.f32 %v36821_v30, %v133151_v60 (stack54)
        %v38010_v31 = vxor.u32 %v38009_v21, %v38005_v26 (stack48)
        %v38808_v55 = vxor.u32 %v38807_v11, %v38803_v8 (stack48)
        %v133210_v50 = vadd.s32 %v133181_v53, %v39240_v40 (stack40)
        %v120746_v6 = vpop.eup %120745 (stack64)
        %v37570_v10 = vadd.s32 %v37567_v56, %v37562_v10 (stack40)
        %v37576_v24 = vshll.u32 %v37567_v56, 6 (stack45)
        %v37577_v61 = vshrl.u32 %v37567_v56, 26 (stack46)
        %v38419_v23 = vxor.u32 %v38418_v9, %v38414_v29 (stack48)
        %v36829_v25 = vadd.f32 %v36825_v54, %v133098_v25 (stack53)
        %v37168_v22 = vmul.f32 0.6931472, %v120746_v6 (stack65)
        %v37171_v32 = vmul.f32 %v37170_v41, %v133173_v32 (stack63)
        %v38013_v41 = vadd.s32 %v38010_v31, %v38005_v26 (stack40)
        %v37578_v26 = vor.u32 %v37577_v61, %v37576_v24 (stack47)
        %v38015_v43 = vshll.u32 %v38010_v31, 16 (stack45)
        %v38016_v12 = vshrl.u32 %v38010_v31, 16 (stack46)
        %v38422_v29 = vadd.s32 %v38419_v23, %v38414_v29 (stack40)
        %v36833_v60 = vmul.f32 %v36829_v25, %v133151_v60 (stack54)
        %v37174_v30 = vsel /*vm=*/%vm133200_vm13, /*on_true_vy=*/%v37171_v32, /*on_false_vx=*/%v37168_v22 (stack66)
        %v38424_v21 = vshll.u32 %v38419_v23, 15 (stack45)
        %v38425_v11 = vshrl.u32 %v38419_v23, 17 (stack46)
        %v36722_v46 = vsel /*vm=*/%vm36717_vm7, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v133220_v40 = vxor.u32 2147483648, %v37174_v30 (stack56)
        %v37579_v42 = vxor.u32 %v37578_v26, %v37570_v10 (stack48)
        %v38811_v8 = vadd.s32 %v38808_v55, %v38803_v8 (stack40)
        %v36837_v56 = vadd.f32 %v36833_v60, %v36722_v46 (stack53)
        %v36698_v9 = vmul.f32 inf, %v133003_v52 (stack54)
        %vm37178_vm14 = vcmp.lt.f32.partialorder %v133220_v40, 5.0 (stack68)
        %120747 = vrsqrt.f32 %v133220_v40 (stack67)
        %v38017_v54 = vor.u32 %v38016_v12, %v38015_v43 (stack47)
        %v36841_v31 = vmul.f32 %v36837_v56, %v133003_v52 (stack54)
        %v38426_v6 = vor.u32 %v38425_v11, %v38424_v21 (stack47)
        %v38817_v24 = vshll.u32 %v38808_v55, 6 (stack45)
        %v38818_v55 = vshrl.u32 %v38808_v55, 26 (stack46)
        %vm36693_vm15 = vcmp.eq.f32.partialorder %v36690_v27, 1.0 (stack68)
        %v37582_v52 = vadd.s32 %v37579_v42, %v121574_v2 (stack40)
        %v39250_v27 = vshll.u32 %v133181_v53, 13 (stack45)
        %v39251_v53 = vshrl.u32 %v133181_v53, 19 (stack46)
        %v36845_v61 = vsel /*vm=*/%vm36693_vm15, /*on_true_vy=*/%v36698_v9, /*on_false_vx=*/%v36841_v31 (stack44)
        %v133234_v23 = vsel /*vm=*/%vm37178_vm14, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v133237_v25 = vadd.f32 -2.5, %v133220_v40 (stack53)
        %v37574_v10 = vadd.s32 %v37570_v10, %v121564_v0 (stack40)
        %v36849_v22 = vmul.f32 1.4140625, %v36845_v61 (stack54)
        %v133243_v32 = vsel /*vm=*/%vm37178_vm14, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v133248_v26 = vsel /*vm=*/%vm37178_vm14, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v37586_v43 = vadd.s32 5, %v37582_v52 (stack40)
        %v133253_v12 = vsel /*vm=*/%vm37178_vm14, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v38018_v60 = vxor.u32 %v38017_v54, %v38013_v41 (stack48)
        %v38427_v30 = vxor.u32 %v38426_v6, %v38422_v29 (stack48)
        %v38819_v21 = vor.u32 %v38818_v55, %v38817_v24 (stack47)
        %v36852_v11 = vpack.c.bf16 %v156663_v45, %v36849_v22 (stack81)
        %v133259_v46 = vsel /*vm=*/%vm37178_vm14, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v37588_v42 = vxor.u32 %v37586_v43, %v37574_v10 (stack48)
        %v39252_v56 = vor.u32 %v39251_v53, %v39250_v27 (stack47)
        %vm37223_vm0 = vcmp.eq.f32.partialorder %v133220_v40, inf (stack70)
        %v38021_v41 = vadd.s32 %v38018_v60, %v38013_v41 (stack40)
        %v38027_v9 = vshll.u32 %v38018_v60, 24 (stack45)
        %v38028_v54 = vshrl.u32 %v38018_v60, 8 (stack46)
        %v38430_v29 = vadd.s32 %v38427_v30, %v38422_v29 (stack40)
        %119939 = vst [vmem:[%s123356_s30 + $0x2a4] sm:$0xf] /*vst_source=*/%v36852_v11 (stack83)
        %vm37225_vm1 = vcmp.eq.f32.partialorder %v133220_v40, 0.0 (stack71)
        %v37589_v31 = vand.u32.u8 255, %v37588_v42 (stack49)
        %v38432_v6 = vshll.u32 %v38427_v30, 26 (stack45)
        %v38433_v24 = vshrl.u32 %v38427_v30, 6 (stack46)
        %v38820_v55 = vxor.u32 %v38819_v21, %v38811_v8 (stack48)
        %v37226_v52 = vand.u32 2147483648, %v133220_v40 (stack72)
        %v38029_v27 = vor.u32 %v38028_v54, %v38027_v9 (stack47)
        %v38815_v8 = vadd.s32 %v38811_v8, %v121569_v1 (stack40)
        %v39253_v53 = vxor.u32 %v39252_v56, %v133210_v50 (stack48)
        %v37590_v61 = vand.u32 65535, %v37589_v31 (stack50)
        %v38434_v10 = vor.u32 %v38433_v24, %v38432_v6 (stack47)
        %v38823_v22 = vadd.s32 %v38820_v55, %v121564_v0 (stack40)
        %vm39675_vm2 = vcmp.lt.u32.totalorder %v133206_v20, %v157083_v59 (stack43)
        %v38030_v43 = vxor.u32 %v38029_v27, %v38021_v41 (stack48)
        %v39256_v50 = vadd.s32 %v39253_v53, %v133210_v50 (stack40)
        %v39258_v60 = vshll.u32 %v39253_v53, 15 (stack45)
        %v39259_v30 = vshrl.u32 %v39253_v53, 17 (stack46)
        %v37591_v21 = vshrl.u32 %v37590_v61, 1 (stack51)
        %v38435_v11 = vxor.u32 %v38434_v10, %v38430_v29 (stack48)
        %v38827_v42 = vadd.s32 1, %v38823_v22 (stack40)
        %v39680_v56 = vadd.s32 %v157298_v34, %v157084_v16 (stack40)
        %v120748_v9 = vpop.eup %120747 (stack73)
        %v38025_v41 = vadd.s32 %v38021_v41, %v121569_v1 (stack40)
        %v38033_v54 = vadd.s32 %v38030_v43, %v121564_v0 (stack40)
        %v39260_v31 = vor.u32 %v39259_v30, %v39258_v60 (stack47)
        %v133277_v6 = vadd.s32 %v157297_v7, %v157089_v17 (stack40)
        %v37222_v24 = vmul.f32 %v120748_v9, %v133220_v40 (stack74)
        %v37592_v55 = vor.u32 16256, %v37591_v21 (stack47)
        %v38438_v29 = vadd.s32 %v38435_v11, %v38430_v29 (stack40)
        %v38444_v27 = vshll.u32 %v38435_v11, 6 (stack45)
        %v38037_v53 = vadd.s32 4, %v38033_v54 (stack40)
        %v38445_v61 = vshrl.u32 %v38435_v11, 26 (stack46)
        %v38831_v8 = vadd.s32 %v38827_v42, %v38815_v8 (stack40)
        %v38833_v10 = vshll.u32 %v38827_v42, 17 (stack45)
        %v37224_v22 = vsel /*vm=*/%vm37223_vm0, /*on_true_vy=*/%v133220_v40, /*on_false_vx=*/%v37222_v24 (stack75)
        %v37593_v43 = vand.u32.u16 65535, %v37592_v55 (stack52)
        %v38834_v60 = vshrl.u32 %v38827_v42, 15 (stack46)
        %v133285_v30 = vadd.s32 %v133206_v20, %v122657_v58 (stack40)
        %v37227_v52 = vsel /*vm=*/%vm37225_vm1, /*on_true_vy=*/%v37226_v52, /*on_false_vx=*/%v37224_v22 (stack76)
        %v38041_v21 = vadd.s32 %v38037_v53, %v38025_v41 (stack40)
        %v38043_v11 = vshll.u32 %v38037_v53, 13 (stack45)
        %v38044_v42 = vshrl.u32 %v38037_v53, 19 (stack46)
        %v37230_v9 = vadd.f32 -3.0, %v37227_v52 (stack53)
        %v119942_v41 = vadd.low.f32.bf16 -1.0, %v37593_v43 (stack53)
        %v38446_v54 = vor.u32 %v38445_v61, %v38444_v27 (stack47)
        %v38835_v24 = vor.u32 %v38834_v60, %v38833_v10 (stack47)
        %v38045_v55 = vor.u32 %v38044_v42, %v38043_v11 (stack47)
        %v38442_v27 = vadd.s32 %v38438_v29, %v121574_v2 (stack40)
        %v39261_v31 = vxor.u32 %v39260_v31, %v39256_v50 (stack48)
        %v39684_v53 = vadd.s32 1, %v39680_v56 (stack40)
        %v133293_v25 = vsel /*vm=*/%vm37178_vm14, /*on_true_vy=*/%v133237_v25, /*on_false_vx=*/%v37230_v9 (stack44)
        %v37602_v61 = vmul.f32 2.0, %v119942_v41 (stack54)
        %v38447_v29 = vxor.u32 %v38446_v54, %v38438_v29 (stack48)
        %v38836_v10 = vxor.u32 %v38835_v24, %v38831_v8 (stack48)
        %v37238_v46 = vmul.f32 %v133293_v25, %v133259_v46 (stack54)
        %v38046_v22 = vxor.u32 %v38045_v55, %v38041_v21 (stack48)
        %v39264_v50 = vadd.s32 %v39261_v31, %v39256_v50 (stack40)
        %v39266_v43 = vshll.u32 %v39261_v31, 26 (stack45)
        %v37606_v60 = vadd.f32 -0.99609375, %v37602_v61 (stack53)
        %v38450_v52 = vadd.s32 %v38447_v29, %v121569_v1 (stack40)
        %v38839_v8 = vadd.s32 %v38836_v10, %v38831_v8 (stack40)
        %v38841_v11 = vshll.u32 %v38836_v10, 29 (stack45)
        %v37242_v12 = vadd.f32 %v37238_v46, %v133253_v12 (stack53)
        %v38049_v21 = vadd.s32 %v38046_v22, %v38041_v21 (stack40)
        %v38051_v42 = vshll.u32 %v38046_v22, 15 (stack45)
        %v38052_v9 = vshrl.u32 %v38046_v22, 17 (stack46)
        %v133299_v41 = vmax.f32 %v37606_v60, -0.99609375 (stack55)
        %v38454_v54 = vadd.s32 3, %v38450_v52 (stack40)
        %v38842_v24 = vshrl.u32 %v38836_v10, 3 (stack46)
        %v39267_v55 = vshrl.u32 %v39261_v31, 6 (stack46)
        %v37199_v31 = vsel /*vm=*/%vm37178_vm14, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v37246_v61 = vmul.f32 %v37242_v12, %v133293_v25 (stack54)
        %v38053_v29 = vor.u32 %v38052_v9, %v38051_v42 (stack47)
        %v133308_v56 = vsel /*vm=*/%vm39675_vm2, /*on_true_vy=*/%v39684_v53, /*on_false_vx=*/%v39680_v56 (stack44)
        %v37203_v53 = vsel /*vm=*/%vm37178_vm14, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v37207_v10 = vsel /*vm=*/%vm37178_vm14, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v37622_v46 = vxor.u32 2147483648, %v133299_v41 (stack56)
        %v38458_v27 = vadd.s32 %v38454_v54, %v38442_v27 (stack40)
        %v37250_v22 = vadd.f32 %v37246_v61, %v37207_v10 (stack53)
        %v38054_v60 = vxor.u32 %v38053_v29, %v38049_v21 (stack48)
        %v38460_v52 = vshll.u32 %v38454_v54, 17 (stack45)
        %v38461_v12 = vshrl.u32 %v38454_v54, 15 (stack46)
        %v133318_v42 = vmul.f32 %v37622_v46, %v133299_v41 (stack54)
        %v38843_v11 = vor.u32 %v38842_v24, %v38841_v11 (stack47)
        %v39268_v43 = vor.u32 %v39267_v55, %v39266_v43 (stack47)
        %v133322_v9 = vadd.s32 %v133285_v30, %v121569_v1 (stack40)
        %v37254_v54 = vmul.f32 %v37250_v22, %v133293_v25 (stack54)
        %v38057_v21 = vadd.s32 %v38054_v60, %v38049_v21 (stack40)
        %v38059_v24 = vshll.u32 %v38054_v60, 26 (stack45)
        %v38060_v55 = vshrl.u32 %v38054_v60, 6 (stack46)
        %v37627_v61 = vadd.f32 1.0, %v133318_v42 (stack57)
        %v37630_v29 = vmul.f32 -0.5, %v133318_v42 (stack59)
        %v38462_v10 = vor.u32 %v38461_v12, %v38460_v52 (stack47)
        %vm39670_vm3 = vcmp.lt.u32.totalorder %v133285_v30, %v133206_v20 (stack43)
        %v37258_v53 = vadd.f32 %v37254_v54, %v37203_v53 (stack53)
        %v38061_v46 = vor.u32 %v38060_v55, %v38059_v24 (stack47)
        %v38844_v22 = vxor.u32 %v38843_v11, %v38839_v8 (stack48)
        %v39269_v60 = vxor.u32 %v39268_v43, %v39264_v50 (stack48)
        %120749 = vlog2.f32 %v37627_v61 (stack58)
        %v38463_v52 = vxor.u32 %v38462_v10, %v38458_v27 (stack48)
        %v39711_v12 = vshll.u32 %v133322_v9, 13 (stack45)
        %v39712_v11 = vshrl.u32 %v133322_v9, 19 (stack46)
        %v37262_v43 = vmul.f32 %v37258_v53, %v133293_v25 (stack54)
        %v37631_v54 = vadd.f32 1.0, %v37630_v29 (stack61)
        %v38062_v24 = vxor.u32 %v38061_v46, %v38057_v21 (stack48)
        %v38847_v8 = vadd.s32 %v38844_v22, %v38839_v8 (stack40)
        %v38466_v27 = vadd.s32 %v38463_v52, %v38458_v27 (stack40)
        %v38468_v55 = vshll.u32 %v38463_v52, 29 (stack45)
        %v38469_v61 = vshrl.u32 %v38463_v52, 3 (stack46)
        %v38849_v29 = vshll.u32 %v38844_v22, 16 (stack45)
        %v37266_v31 = vadd.f32 %v37262_v43, %v37199_v31 (stack53)
        %v38065_v21 = vadd.s32 %v38062_v24, %v38057_v21 (stack40)
        %v38071_v10 = vshll.u32 %v38062_v24, 6 (stack45)
        %v38072_v53 = vshrl.u32 %v38062_v24, 26 (stack46)
        %v38470_v46 = vor.u32 %v38469_v61, %v38468_v55 (stack47)
        %v38850_v22 = vshrl.u32 %v38844_v22, 16 (stack46)
        %v39272_v50 = vadd.s32 %v39269_v60, %v39264_v50 (stack40)
        %v39278_v52 = vshll.u32 %v39269_v60, 6 (stack45)
        %v37270_v43 = vmul.f32 %v37266_v31, %v133293_v25 (stack54)
        %v37633_v24 = vand.u32 2147483647, %v133318_v42 (stack60)
        %v38073_v55 = vor.u32 %v38072_v53, %v38071_v10 (stack47)
        %v39279_v60 = vshrl.u32 %v39269_v60, 26 (stack46)
        %v37632_v42 = vmul.f32 %v37631_v54, %v133318_v42 (stack63)
        %v38471_v54 = vxor.u32 %v38470_v46, %v38466_v27 (stack48)
        %v38851_v61 = vor.u32 %v38850_v22, %v38849_v29 (stack47)
        %v39692_v29 = vadd.s32 1, %v133308_v56 (stack40)
        %v37274_v26 = vadd.f32 %v37270_v43, %v133248_v26 (stack53)
        %v38069_v31 = vadd.s32 %v38065_v21, %v121564_v0 (stack40)
        %v38074_v21 = vxor.u32 %v38073_v55, %v38065_v21 (stack48)
        %v39280_v10 = vor.u32 %v39279_v60, %v39278_v52 (stack47)
        %v38474_v27 = vadd.s32 %v38471_v54, %v38466_v27 (stack40)
        %v38476_v53 = vshll.u32 %v38471_v54, 16 (stack45)
        %v38477_v46 = vshrl.u32 %v38471_v54, 16 (stack46)
        %v38852_v22 = vxor.u32 %v38851_v61, %v38847_v8 (stack48)
        %v37278_v52 = vmul.f32 %v37274_v26, %v133293_v25 (stack54)
        %v38077_v43 = vadd.s32 %v38074_v21, %v121574_v2 (stack40)
        %v39281_v55 = vxor.u32 %v39280_v10, %v39272_v50 (stack48)
        %v39696_v20 = vsel /*vm=*/%vm39670_vm3, /*on_true_vy=*/%v39692_v29, /*on_false_vx=*/%v133308_v56 (stack44)
        %v38478_v30 = vor.u32 %v38477_v46, %v38476_v53 (stack47)
        %v38855_v56 = vadd.s32 %v38852_v22, %v38847_v8 (stack40)
        %v38861_v8 = vshll.u32 %v38852_v22, 24 (stack45)
        %v38862_v60 = vshrl.u32 %v38852_v22, 8 (stack46)
        %v37282_v32 = vadd.f32 %v37278_v52, %v133243_v32 (stack53)
        %v38081_v54 = vadd.s32 5, %v38077_v43 (stack40)
        %v39284_v61 = vadd.s32 %v39281_v55, %v121564_v0 (stack40)
        %v39701_v29 = vadd.s32 %v39696_v20, %v121574_v2 (stack40)
        %v38479_v26 = vxor.u32 %v38478_v30, %v38474_v27 (stack48)
        %v38863_v21 = vor.u32 %v38862_v60, %v38861_v8 (stack47)
        %v39276_v50 = vadd.s32 %v39272_v50, %v121569_v1 (stack40)
        %v39713_v12 = vor.u32 %v39712_v11, %v39711_v12 (stack47)
        %v120750_v11 = vpop.eup %120749 (stack64)
        %v37286_v10 = vmul.f32 %v37282_v32, %v133293_v25 (stack54)
        %v38083_v31 = vxor.u32 %v38081_v54, %v38069_v31 (stack48)
        %v39288_v53 = vadd.s32 1, %v39284_v61 (stack40)
        %v39709_v9 = vadd.s32 %v133322_v9, %v39701_v29 (stack40)
        %v37629_v46 = vmul.f32 0.6931472, %v120750_v11 (stack65)
        %v38482_v27 = vadd.s32 %v38479_v26, %v38474_v27 (stack40)
        %v38488_v22 = vshll.u32 %v38479_v26, 24 (stack45)
        %v38489_v52 = vshrl.u32 %v38479_v26, 8 (stack46)
        %v37290_v23 = vadd.f32 %v37286_v10, %v133234_v23 (stack53)
        %vm37634_vm4 = vcmp.lt.f32.partialorder %v37633_v24, 0.0004427343 (stack62)
        %v38864_v24 = vxor.u32 %v38863_v21, %v38855_v56 (stack48)
        %v39292_v43 = vadd.s32 %v39288_v53, %v39276_v50 (stack40)
        %v37635_v42 = vsel /*vm=*/%vm37634_vm4, /*on_true_vy=*/%v37632_v42, /*on_false_vx=*/%v37629_v46 (stack66)
        %v38084_v55 = vand.u32.u8 255, %v38083_v31 (stack49)
        %v38490_v20 = vor.u32 %v38489_v52, %v38488_v22 (stack47)
        %v37151_v30 = vand.u32 2147483647, %v133165_v44 (stack77)
        %v37183_v40 = vsel /*vm=*/%vm37178_vm14, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v37294_v25 = vmul.f32 %v37290_v23, %v133293_v25 (stack54)
        %v133356_v8 = vxor.u32 2147483648, %v37635_v42 (stack56)
        %v38491_v60 = vxor.u32 %v38490_v20, %v38482_v27 (stack48)
        %v39294_v32 = vshll.u32 %v39288_v53, 17 (stack45)
        %v39295_v54 = vshrl.u32 %v39288_v53, 15 (stack46)
        %v39714_v61 = vxor.u32 %v39713_v12, %v39709_v9 (stack48)
        %v37159_v29 = vmul.f32 inf, %v133165_v44 (stack54)
        %v37298_v26 = vadd.f32 %v37294_v25, %v37183_v40 (stack53)
        %120751 = vrsqrt.f32 %v133356_v8 (stack67)
        %vm37639_vm5 = vcmp.lt.f32.partialorder %v133356_v8, 5.0 (stack68)
        %v38085_v21 = vand.u32 65535, %v38084_v55 (stack50)
        %v38494_v50 = vadd.s32 %v38491_v60, %v121564_v0 (stack40)
        %v38867_v12 = vadd.s32 %v38864_v24, %v121574_v2 (stack40)
        %vm37154_vm6 = vcmp.eq.f32.partialorder %v37151_v30, 1.0 (stack68)
        %v37302_v44 = vmul.f32 %v37298_v26, %v133165_v44 (stack54)
        %v37612_v11 = vand.u32 2147483647, %v133299_v41 (stack77)
        %v38859_v56 = vadd.s32 %v38855_v56, %v121564_v0 (stack40)
        %v133367_v10 = vadd.f32 -2.5, %v133356_v8 (stack53)
        %v38486_v31 = vadd.s32 %v38482_v27, %v121569_v1 (stack40)
        %v39296_v53 = vor.u32 %v39295_v54, %v39294_v32 (stack47)
        %v133372_v46 = vadd.s32 %v133277_v6, %v122657_v58 (stack40)
        %v37306_v27 = vsel /*vm=*/%vm37154_vm6, /*on_true_vy=*/%v37159_v29, /*on_false_vx=*/%v37302_v44 (stack44)
        %v133377_v22 = vsel /*vm=*/%vm37639_vm5, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v133382_v52 = vsel /*vm=*/%vm37639_vm5, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v133387_v23 = vsel /*vm=*/%vm37639_vm5, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v37310_v24 = vmul.f32 1.4140625, %v37306_v27 (stack54)
        %v38086_v42 = vshrl.u32 %v38085_v21, 1 (stack51)
        %v38498_v55 = vadd.s32 4, %v38494_v50 (stack40)
        %v38871_v20 = vadd.s32 2, %v38867_v12 (stack40)
        %v39297_v30 = vxor.u32 %v39296_v53, %v39292_v43 (stack48)
        %v39717_v9 = vadd.s32 %v39714_v61, %v39709_v9 (stack40)
        %v39719_v40 = vshll.u32 %v39714_v61, 15 (stack45)
        %v39720_v25 = vshrl.u32 %v39714_v61, 17 (stack46)
        %v37313_v60 = vpack.c.bf16 %v156663_v45, %v37310_v24 (stack81)
        %v38087_v32 = vor.u32 16256, %v38086_v42 (stack47)
        %v38502_v54 = vadd.s32 %v38498_v55, %v38486_v31 (stack40)
        %v38504_v61 = vshll.u32 %v38498_v55, 13 (stack45)
        %v38505_v29 = vshrl.u32 %v38498_v55, 19 (stack46)
        %v38875_v26 = vadd.s32 %v38871_v20, %v38859_v56 (stack40)
        %v38877_v21 = vshll.u32 %v38871_v20, 13 (stack45)
        %v38878_v50 = vshrl.u32 %v38871_v20, 19 (stack46)
        %119941 = vst [vmem:[%s123356_s30 + $0x324] sm:$0xf] /*vst_source=*/%v37313_v60 (stack83)
        %v38088_v12 = vand.u32.u16 65535, %v38087_v32 (stack52)
        %v39300_v43 = vadd.s32 %v39297_v30, %v39292_v43 (stack40)
        %v39302_v44 = vshll.u32 %v39297_v30, 29 (stack45)
        %v39303_v56 = vshrl.u32 %v39297_v30, 3 (stack46)
        %v38506_v31 = vor.u32 %v38505_v29, %v38504_v61 (stack47)
        %v38879_v53 = vor.u32 %v38878_v50, %v38877_v21 (stack47)
        %v39721_v27 = vor.u32 %v39720_v25, %v39719_v40 (stack47)
        %vm40136_vm7 = vcmp.lt.u32.totalorder %v133277_v6, %v157089_v17 (stack43)
        %v133396_v24 = vsel /*vm=*/%vm37639_vm5, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v119948_v42 = vadd.low.f32.bf16 -1.0, %v38088_v12 (stack53)
        %v39304_v55 = vor.u32 %v39303_v56, %v39302_v44 (stack47)
        %v133400_v20 = vadd.s32 %v157298_v34, %v157090_v62 (stack40)
        %v38507_v30 = vxor.u32 %v38506_v31, %v38502_v54 (stack48)
        %v38880_v40 = vxor.u32 %v38879_v53, %v38875_v26 (stack48)
        %v133402_v25 = vxor.u32 %v39721_v27, %v39717_v9 (stack48)
        %v133406_v60 = vadd.s32 %v157297_v7, %v157091_v37 (stack40)
        %v120752_v32 = vpop.eup %120751 (stack73)
        %vm37684_vm8 = vcmp.eq.f32.partialorder %v133356_v8, inf (stack70)
        %v37687_v61 = vand.u32 2147483648, %v133356_v8 (stack72)
        %v38097_v29 = vmul.f32 2.0, %v119948_v42 (stack54)
        %v39305_v21 = vxor.u32 %v39304_v55, %v39300_v43 (stack48)
        %v37683_v50 = vmul.f32 %v120752_v32, %v133356_v8 (stack74)
        %v38510_v54 = vadd.s32 %v38507_v30, %v38502_v54 (stack40)
        %v38512_v12 = vshll.u32 %v38507_v30, 15 (stack45)
        %v38513_v44 = vshrl.u32 %v38507_v30, 17 (stack46)
        %v38101_v56 = vadd.f32 -0.99609375, %v38097_v29 (stack53)
        %v38883_v26 = vadd.s32 %v38880_v40, %v38875_v26 (stack40)
        %v38885_v31 = vshll.u32 %v38880_v40, 15 (stack45)
        %v38886_v53 = vshrl.u32 %v38880_v40, 17 (stack46)
        %v37685_v27 = vsel /*vm=*/%vm37684_vm8, /*on_true_vy=*/%v133356_v8, /*on_false_vx=*/%v37683_v50 (stack75)
        %vm37686_vm9 = vcmp.eq.f32.partialorder %v133356_v8, 0.0 (stack71)
        %v38514_v42 = vor.u32 %v38513_v44, %v38512_v12 (stack47)
        %v39308_v43 = vadd.s32 %v39305_v21, %v39300_v43 (stack40)
        %v37688_v55 = vsel /*vm=*/%vm37686_vm9, /*on_true_vy=*/%v37687_v61, /*on_false_vx=*/%v37685_v27 (stack76)
        %v133413_v30 = vmax.f32 %v38101_v56, -0.99609375 (stack55)
        %v38887_v40 = vor.u32 %v38886_v53, %v38885_v31 (stack47)
        %v39310_v32 = vshll.u32 %v39305_v21, 16 (stack45)
        %v37691_v61 = vadd.f32 -3.0, %v37688_v55 (stack53)
        %v38515_v29 = vxor.u32 %v38514_v42, %v38510_v54 (stack48)
        %v39311_v21 = vshrl.u32 %v39305_v21, 16 (stack46)
        %v133416_v9 = vadd.s32 %v133402_v25, %v39717_v9 (stack40)
        %v37668_v50 = vsel /*vm=*/%vm37639_vm5, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v37676_v12 = vsel /*vm=*/%vm37639_vm5, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v38117_v44 = vxor.u32 2147483648, %v133413_v30 (stack56)
        %v38888_v56 = vxor.u32 %v38887_v40, %v38883_v26 (stack48)
        %v133428_v10 = vsel /*vm=*/%vm37639_vm5, /*on_true_vy=*/%v133367_v10, /*on_false_vx=*/%v37691_v61 (stack44)
        %v38518_v54 = vadd.s32 %v38515_v29, %v38510_v54 (stack40)
        %v38520_v31 = vshll.u32 %v38515_v29, 26 (stack45)
        %v38521_v53 = vshrl.u32 %v38515_v29, 6 (stack46)
        %v37672_v27 = vsel /*vm=*/%vm37639_vm5, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v37699_v42 = vmul.f32 %v133428_v10, %v37676_v12 (stack54)
        %v133435_v55 = vmul.f32 %v38117_v44, %v133413_v30 (stack54)
        %v38891_v26 = vadd.s32 %v38888_v56, %v38883_v26 (stack40)
        %v38522_v40 = vor.u32 %v38521_v53, %v38520_v31 (stack47)
        %v38893_v61 = vshll.u32 %v38888_v56, 26 (stack45)
        %v38894_v29 = vshrl.u32 %v38888_v56, 6 (stack46)
        %v39312_v32 = vor.u32 %v39311_v21, %v39310_v32 (stack47)
        %vm40131_vm10 = vcmp.lt.u32.totalorder %v133372_v46, %v133277_v6 (stack43)
        %v37703_v21 = vadd.f32 %v37699_v42, %v37672_v27 (stack53)
        %v38122_v12 = vadd.f32 1.0, %v133435_v55 (stack57)
        %v38125_v44 = vmul.f32 -0.5, %v133435_v55 (stack59)
        %v40166_v56 = vadd.s32 %v133372_v46, %v121569_v1 (stack40)
        %v38523_v31 = vxor.u32 %v38522_v40, %v38518_v54 (stack48)
        %v38895_v53 = vor.u32 %v38894_v29, %v38893_v61 (stack47)
        %v39313_v27 = vxor.u32 %v39312_v32, %v39308_v43 (stack48)
        %v39727_v42 = vshll.u32 %v133402_v25, 26 (stack45)
        %v37707_v40 = vmul.f32 %v37703_v21, %v133428_v10 (stack54)
        %120753 = vlog2.f32 %v38122_v12 (stack58)
        %v38126_v61 = vadd.f32 1.0, %v38125_v44 (stack61)
        %v39728_v25 = vshrl.u32 %v133402_v25, 6 (stack46)
        %v38526_v54 = vadd.s32 %v38523_v31, %v38518_v54 (stack40)
        %v38532_v29 = vshll.u32 %v38523_v31, 6 (stack45)
        %v38533_v32 = vshrl.u32 %v38523_v31, 26 (stack46)
        %v38896_v21 = vxor.u32 %v38895_v53, %v38891_v26 (stack48)
        %v37711_v50 = vadd.f32 %v37707_v40, %v37668_v50 (stack53)
        %v39316_v43 = vadd.s32 %v39313_v27, %v39308_v43 (stack40)
        %v39322_v12 = vshll.u32 %v39313_v27, 24 (stack45)
        %v40145_v44 = vadd.s32 1, %v133400_v20 (stack40)
        %v38534_v31 = vor.u32 %v38533_v32, %v38532_v29 (stack47)
        %v38899_v26 = vadd.s32 %v38896_v21, %v38891_v26 (stack40)
        %v38905_v53 = vshll.u32 %v38896_v21, 6 (stack45)
        %v40172_v40 = vshll.u32 %v40166_v56, 13 (stack45)
        %v37715_v29 = vmul.f32 %v37711_v50, %v133428_v10 (stack54)
        %v38128_v32 = vand.u32 2147483647, %v133435_v55 (stack60)
        %v38906_v21 = vshrl.u32 %v38896_v21, 26 (stack46)
        %v39323_v27 = vshrl.u32 %v39313_v27, 8 (stack46)
        %v38127_v55 = vmul.f32 %v38126_v61, %v133435_v55 (stack63)
        %v38535_v61 = vxor.u32 %v38534_v31, %v38526_v54 (stack48)
        %v39729_v42 = vor.u32 %v39728_v25, %v39727_v42 (stack47)
        %v40149_v20 = vsel /*vm=*/%vm40136_vm7, /*on_true_vy=*/%v40145_v44, /*on_false_vx=*/%v133400_v20 (stack44)
        %v37719_v24 = vadd.f32 %v37715_v29, %v133396_v24 (stack53)
        %v38907_v25 = vor.u32 %v38906_v21, %v38905_v53 (stack47)
        %v39324_v50 = vor.u32 %v39323_v27, %v39322_v12 (stack47)
        %v40153_v12 = vadd.s32 1, %v40149_v20 (stack40)
        %v38530_v54 = vadd.s32 %v38526_v54, %v121564_v0 (stack40)
        %v38538_v44 = vadd.s32 %v38535_v61, %v121574_v2 (stack40)
        %v39730_v31 = vxor.u32 %v39729_v42, %v133416_v9 (stack48)
        %v40173_v53 = vshrl.u32 %v40166_v56, 19 (stack46)
        %v37723_v29 = vmul.f32 %v37719_v24, %v133428_v10 (stack54)
        %v38908_v21 = vxor.u32 %v38907_v25, %v38899_v26 (stack48)
        %v39325_v27 = vxor.u32 %v39324_v50, %v39316_v43 (stack48)
        %v40157_v6 = vsel /*vm=*/%vm40131_vm10, /*on_true_vy=*/%v40153_v12, /*on_false_vx=*/%v40149_v20 (stack44)
        %v38542_v46 = vadd.s32 5, %v38538_v44 (stack40)
        %v39733_v9 = vadd.s32 %v39730_v31, %v133416_v9 (stack40)
        %v39739_v61 = vshll.u32 %v39730_v31, 6 (stack45)
        %v39740_v42 = vshrl.u32 %v39730_v31, 26 (stack46)
        %v37727_v23 = vadd.f32 %v37723_v29, %v133387_v23 (stack53)
        %v38911_v20 = vadd.s32 %v38908_v21, %v121569_v1 (stack40)
        %v39328_v24 = vadd.s32 %v39325_v27, %v121574_v2 (stack40)
        %v40162_v25 = vadd.s32 %v40157_v6, %v121574_v2 (stack40)
        %v38544_v50 = vxor.u32 %v38542_v46, %v38530_v54 (stack48)
        %v38903_v26 = vadd.s32 %v38899_v26, %v121574_v2 (stack40)
        %v39320_v43 = vadd.s32 %v39316_v43, %v121564_v0 (stack40)
        %v39741_v12 = vor.u32 %v39740_v42, %v39739_v61 (stack47)
        %v37731_v54 = vmul.f32 %v37727_v23, %v133428_v10 (stack54)
        %v38915_v44 = vadd.s32 3, %v38911_v20 (stack40)
        %v39332_v31 = vadd.s32 2, %v39328_v24 (stack40)
        %v133470_v56 = vadd.s32 %v40166_v56, %v40162_v25 (stack40)
        %v120754_v29 = vpop.eup %120753 (stack64)
        %v38545_v21 = vand.u32.u8 255, %v38544_v50 (stack49)
        %v39742_v27 = vxor.u32 %v39741_v12, %v39733_v9 (stack48)
        %v40174_v40 = vor.u32 %v40173_v53, %v40172_v40 (stack47)
        %vm40597_vm11 = vcmp.lt.u32.totalorder %v133406_v60, %v157091_v37 (stack43)
        %v37735_v52 = vadd.f32 %v37731_v54, %v133382_v52 (stack53)
        %v38124_v53 = vmul.f32 0.6931472, %v120754_v29 (stack65)
        %v38919_v6 = vadd.s32 %v38915_v44, %v38903_v26 (stack40)
        %v38921_v46 = vshll.u32 %v38915_v44, 17 (stack45)
        %vm38129_vm12 = vcmp.lt.f32.partialorder %v38128_v32, 0.0004427343 (stack62)
        %v38546_v32 = vand.u32 65535, %v38545_v21 (stack50)
        %v38922_v61 = vshrl.u32 %v38915_v44, 15 (stack46)
        %v39336_v42 = vadd.s32 %v39332_v31, %v39320_v43 (stack40)
        %v37739_v23 = vmul.f32 %v37735_v52, %v133428_v10 (stack54)
        %v38130_v55 = vsel /*vm=*/%vm38129_vm12, /*on_true_vy=*/%v38127_v55, /*on_false_vx=*/%v38124_v53 (stack66)
        %v39338_v20 = vshll.u32 %v39332_v31, 13 (stack45)
        %v39339_v24 = vshrl.u32 %v39332_v31, 19 (stack46)
        %v133476_v25 = vxor.u32 2147483648, %v38130_v55 (stack56)
        %v38923_v50 = vor.u32 %v38922_v61, %v38921_v46 (stack47)
        %v39745_v26 = vadd.s32 %v39742_v27, %v121564_v0 (stack40)
        %v133480_v43 = vxor.u32 %v40174_v40, %v133470_v56 (stack48)
        %v37620_v12 = vmul.f32 inf, %v133299_v41 (stack54)
        %v37644_v54 = vsel /*vm=*/%vm37639_vm5, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v37743_v22 = vadd.f32 %v37739_v23, %v133377_v22 (stack53)
        %v133489_v44 = vadd.s32 %v157298_v34, %v157094_v36 (stack40)
        %v37648_v8 = vsel /*vm=*/%vm37639_vm5, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %vm38134_vm13 = vcmp.lt.f32.partialorder %v133476_v25, 5.0 (stack68)
        %120755 = vrsqrt.f32 %v133476_v25 (stack67)
        %v38547_v31 = vshrl.u32 %v38546_v32, 1 (stack51)
        %v37747_v29 = vmul.f32 %v37743_v22, %v133428_v10 (stack54)
        %v38107_v21 = vand.u32 2147483647, %v133413_v30 (stack77)
        %v133499_v27 = vmul.f32 inf, %v133413_v30 (stack54)
        %v39340_v40 = vor.u32 %v39339_v24, %v39338_v20 (stack47)
        %vm133503_vm14 = vcmp.eq.f32.partialorder %v37612_v11, 1.0 (stack68)
        %v38924_v52 = vxor.u32 %v38923_v50, %v38919_v6 (stack48)
        %v39737_v9 = vadd.s32 %v39733_v9, %v121569_v1 (stack40)
        %v39749_v53 = vadd.s32 1, %v39745_v26 (stack40)
        %v133510_v46 = vadd.s32 %v133406_v60, %v122657_v58 (stack40)
        %v37751_v32 = vadd.f32 %v37747_v29, %v37648_v8 (stack53)
        %v133515_v61 = vsel /*vm=*/%vm38134_vm13, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v133520_v23 = vsel /*vm=*/%vm38134_vm13, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v133523_v55 = vadd.f32 -2.5, %v133476_v25 (stack53)
        %v133528_v20 = vsel /*vm=*/%vm38134_vm13, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v133533_v24 = vsel /*vm=*/%vm38134_vm13, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v38548_v50 = vor.u32 16256, %v38547_v31 (stack47)
        %v38927_v6 = vadd.s32 %v38924_v52, %v38919_v6 (stack40)
        %v37755_v10 = vmul.f32 %v37751_v32, %v133428_v10 (stack54)
        %v38929_v26 = vshll.u32 %v38924_v52, 29 (stack45)
        %v38930_v22 = vshrl.u32 %v38924_v52, 3 (stack46)
        %v39341_v8 = vxor.u32 %v39340_v40, %v39336_v42 (stack48)
        %v38549_v31 = vand.u32.u16 65535, %v38548_v50 (stack52)
        %v39753_v29 = vadd.s32 %v39749_v53, %v39737_v9 (stack40)
        %v39755_v40 = vshll.u32 %v39749_v53, 17 (stack45)
        %v39756_v52 = vshrl.u32 %v39749_v53, 15 (stack46)
        %v37759_v54 = vadd.f32 %v37755_v10, %v37644_v54 (stack53)
        %vm38179_vm15 = vcmp.eq.f32.partialorder %v133476_v25, inf (stack70)
        %v38931_v9 = vor.u32 %v38930_v22, %v38929_v26 (stack47)
        %v39344_v42 = vadd.s32 %v39341_v8, %v39336_v42 (stack40)
        %v39346_v53 = vshll.u32 %v39341_v8, 15 (stack45)
        %v119950_v32 = vadd.low.f32.bf16 -1.0, %v38549_v31 (stack53)
        %v39347_v50 = vshrl.u32 %v39341_v8, 17 (stack46)
        %v39757_v10 = vor.u32 %v39756_v52, %v39755_v40 (stack47)
        %v133539_v56 = vadd.s32 %v133480_v43, %v133470_v56 (stack40)
        %v37763_v41 = vmul.f32 %v37759_v54, %v133299_v41 (stack54)
        %v38932_v26 = vxor.u32 %v38931_v9, %v38927_v6 (stack48)
        %v40180_v22 = vshll.u32 %v133480_v43, 15 (stack45)
        %v40181_v43 = vshrl.u32 %v133480_v43, 17 (stack46)
        %v38182_v8 = vand.u32 2147483648, %v133476_v25 (stack72)
        %v38558_v31 = vmul.f32 2.0, %v119950_v32 (stack54)
        %v39348_v40 = vor.u32 %v39347_v50, %v39346_v53 (stack47)
        %v39758_v52 = vxor.u32 %v39757_v10, %v39753_v29 (stack48)
        %v37767_v12 = vsel /*vm=*/%vm133503_vm14, /*on_true_vy=*/%v37620_v12, /*on_false_vx=*/%v37763_v41 (stack44)
        %v38935_v11 = vadd.s32 %v38932_v26, %v38927_v6 (stack40)
        %v38937_v6 = vshll.u32 %v38932_v26, 16 (stack45)
        %v38938_v54 = vshrl.u32 %v38932_v26, 16 (stack46)
        %v37771_v9 = vmul.f32 1.4140625, %v37767_v12 (stack54)
        %v38562_v53 = vadd.f32 -0.99609375, %v38558_v31 (stack53)
        %v39349_v32 = vxor.u32 %v39348_v40, %v39344_v42 (stack48)
        %v39761_v29 = vadd.s32 %v39758_v52, %v39753_v29 (stack40)
        %v120756_v50 = vpop.eup %120755 (stack73)
        %v38939_v10 = vor.u32 %v38938_v54, %v38937_v6 (stack47)
        %v39763_v41 = vshll.u32 %v39758_v52, 29 (stack45)
        %v39764_v26 = vshrl.u32 %v39758_v52, 3 (stack46)
        %v40182_v22 = vor.u32 %v40181_v43, %v40180_v22 (stack47)
        %v37774_v43 = vpack.c.bf16 %v156663_v45, %v37771_v9 (stack81)
        %v38178_v31 = vmul.f32 %v120756_v50, %v133476_v25 (stack74)
        %v133549_v40 = vmax.f32 %v38562_v53, -0.99609375 (stack55)
        %v39352_v42 = vadd.s32 %v39349_v32, %v39344_v42 (stack40)
        %v38940_v52 = vxor.u32 %v38939_v10, %v38935_v11 (stack48)
        %v39354_v12 = vshll.u32 %v39349_v32, 26 (stack45)
        %v39355_v6 = vshrl.u32 %v39349_v32, 6 (stack46)
        %v39765_v54 = vor.u32 %v39764_v26, %v39763_v41 (stack47)
        %119943 = vst [vmem:[%s123356_s30 + $0x3a4] sm:$0xf] /*vst_source=*/%v37774_v43 (stack83)
        %v133555_v9 = vsel /*vm=*/%vm38134_vm13, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v38180_v53 = vsel /*vm=*/%vm38179_vm15, /*on_true_vy=*/%v133476_v25, /*on_false_vx=*/%v38178_v31 (stack75)
        %vm38181_vm0 = vcmp.eq.f32.partialorder %v133476_v25, 0.0 (stack71)
        %v38578_v32 = vxor.u32 2147483648, %v133549_v40 (stack56)
        %v38183_v8 = vsel /*vm=*/%vm38181_vm0, /*on_true_vy=*/%v38182_v8, /*on_false_vx=*/%v38180_v53 (stack76)
        %v38943_v11 = vadd.s32 %v38940_v52, %v38935_v11 (stack40)
        %v38949_v50 = vshll.u32 %v38940_v52, 24 (stack45)
        %v38950_v10 = vshrl.u32 %v38940_v52, 8 (stack46)
        %v38159_v41 = vsel /*vm=*/%vm38134_vm13, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v38186_v26 = vadd.f32 -3.0, %v38183_v8 (stack53)
        %v133566_v43 = vmul.f32 %v38578_v32, %v133549_v40 (stack54)
        %v39356_v31 = vor.u32 %v39355_v6, %v39354_v12 (stack47)
        %v38163_v52 = vsel /*vm=*/%vm38134_vm13, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v38951_v12 = vor.u32 %v38950_v10, %v38949_v50 (stack47)
        %v39766_v6 = vxor.u32 %v39765_v54, %v39761_v29 (stack48)
        %v40183_v22 = vxor.u32 %v40182_v22, %v133539_v56 (stack48)
        %v38167_v54 = vsel /*vm=*/%vm38134_vm13, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v38171_v53 = vsel /*vm=*/%vm38134_vm13, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v133581_v25 = vsel /*vm=*/%vm38134_vm13, /*on_true_vy=*/%v133523_v55, /*on_false_vx=*/%v38186_v26 (stack44)
        %v38583_v55 = vadd.f32 1.0, %v133566_v43 (stack57)
        %vm40592_vm1 = vcmp.lt.u32.totalorder %v133510_v46, %v133406_v60 (stack43)
        %v38194_v32 = vmul.f32 %v133581_v25, %v38171_v53 (stack54)
        %v38952_v8 = vxor.u32 %v38951_v12, %v38943_v11 (stack48)
        %v39357_v50 = vxor.u32 %v39356_v31, %v39352_v42 (stack48)
        %v39769_v29 = vadd.s32 %v39766_v6, %v39761_v29 (stack40)
        %120757 = vlog2.f32 %v38583_v55 (stack58)
        %v38947_v11 = vadd.s32 %v38943_v11, %v121569_v1 (stack40)
        %v39771_v10 = vshll.u32 %v39766_v6, 16 (stack45)
        %v40606_v26 = vadd.s32 1, %v133489_v44 (stack40)
        %v38198_v31 = vadd.f32 %v38194_v32, %v38167_v54 (stack53)
        %v38955_v12 = vadd.s32 %v38952_v8, %v121564_v0 (stack40)
        %v39360_v42 = vadd.s32 %v39357_v50, %v39352_v42 (stack40)
        %v39366_v54 = vshll.u32 %v39357_v50, 6 (stack45)
        %v38586_v53 = vmul.f32 -0.5, %v133566_v43 (stack59)
        %v39367_v55 = vshrl.u32 %v39357_v50, 26 (stack46)
        %v39772_v6 = vshrl.u32 %v39766_v6, 16 (stack46)
        %v40186_v56 = vadd.s32 %v40183_v22, %v133539_v56 (stack40)
        %v38202_v32 = vmul.f32 %v38198_v31, %v133581_v25 (stack54)
        %v38589_v8 = vand.u32 2147483647, %v133566_v43 (stack60)
        %v38959_v50 = vadd.s32 4, %v38955_v12 (stack40)
        %v40188_v31 = vshll.u32 %v40183_v22, 26 (stack45)
        %v39368_v12 = vor.u32 %v39367_v55, %v39366_v54 (stack47)
        %v39773_v10 = vor.u32 %v39772_v6, %v39771_v10 (stack47)
        %v40189_v22 = vshrl.u32 %v40183_v22, 6 (stack46)
        %v40610_v44 = vsel /*vm=*/%vm40597_vm11, /*on_true_vy=*/%v40606_v26, /*on_false_vx=*/%v133489_v44 (stack44)
        %v38206_v52 = vadd.f32 %v38202_v32, %v38163_v52 (stack53)
        %v38963_v11 = vadd.s32 %v38959_v50, %v38947_v11 (stack40)
        %v38965_v26 = vshll.u32 %v38959_v50, 13 (stack45)
        %v38966_v54 = vshrl.u32 %v38959_v50, 19 (stack46)
        %v39369_v55 = vxor.u32 %v39368_v12, %v39360_v42 (stack48)
        %v39774_v6 = vxor.u32 %v39773_v10, %v39769_v29 (stack48)
        %v40190_v32 = vor.u32 %v40189_v22, %v40188_v31 (stack47)
        %v40614_v50 = vadd.s32 1, %v40610_v44 (stack40)
        %v38210_v31 = vmul.f32 %v38206_v52, %v133581_v25 (stack54)
        %v38587_v53 = vadd.f32 1.0, %v38586_v53 (stack61)
        %v38967_v12 = vor.u32 %v38966_v54, %v38965_v26 (stack47)
        %v133601_v7 = vadd.s32 %v157297_v7, %v157095_v13 (stack40)
        %v39372_v10 = vadd.s32 %v39369_v55, %v121569_v1 (stack40)
        %v39777_v29 = vadd.s32 %v39774_v6, %v39769_v29 (stack40)
        %v39783_v22 = vshll.u32 %v39774_v6, 24 (stack45)
        %v39784_v52 = vshrl.u32 %v39774_v6, 8 (stack46)
        %v38214_v41 = vadd.f32 %v38210_v31, %v38159_v41 (stack53)
        %v38968_v26 = vxor.u32 %v38967_v12, %v38963_v11 (stack48)
        %v40191_v54 = vxor.u32 %v40190_v32, %v40186_v56 (stack48)
        %v40618_v60 = vsel /*vm=*/%vm40592_vm1, /*on_true_vy=*/%v40614_v50, /*on_false_vx=*/%v40610_v44 (stack44)
        %v39364_v42 = vadd.s32 %v39360_v42, %v121574_v2 (stack40)
        %v39376_v44 = vadd.s32 3, %v39372_v10 (stack40)
        %v39785_v55 = vor.u32 %v39784_v52, %v39783_v22 (stack47)
        %v40623_v6 = vadd.s32 %v40618_v60, %v121574_v2 (stack40)
        %v38218_v32 = vmul.f32 %v38214_v41, %v133581_v25 (stack54)
        %v38971_v11 = vadd.s32 %v38968_v26, %v38963_v11 (stack40)
        %v38973_v50 = vshll.u32 %v38968_v26, 15 (stack45)
        %v38974_v31 = vshrl.u32 %v38968_v26, 17 (stack46)
        %v39380_v12 = vadd.s32 %v39376_v44, %v39364_v42 (stack40)
        %v39382_v10 = vshll.u32 %v39376_v44, 17 (stack45)
        %v39383_v22 = vshrl.u32 %v39376_v44, 15 (stack46)
        %v39786_v52 = vxor.u32 %v39785_v55, %v39777_v29 (stack48)
        %v120758_v41 = vpop.eup %120757 (stack64)
        %v38222_v9 = vadd.f32 %v38218_v32, %v133555_v9 (stack53)
        %v38975_v26 = vor.u32 %v38974_v31, %v38973_v50 (stack47)
        %v133611_v56 = vadd.s32 %v40191_v54, %v40186_v56 (stack40)
        %v133615_v46 = vadd.s32 %v133510_v46, %v121569_v1 (stack40)
        %v38585_v60 = vmul.f32 0.6931472, %v120758_v41 (stack65)
        %v38588_v43 = vmul.f32 %v38587_v53, %v133566_v43 (stack63)
        %vm38590_vm2 = vcmp.lt.f32.partialorder %v38589_v8, 0.0004427343 (stack62)
        %v39384_v8 = vor.u32 %v39383_v22, %v39382_v10 (stack47)
        %v38226_v53 = vmul.f32 %v38222_v9, %v133581_v25 (stack54)
        %v38976_v42 = vxor.u32 %v38975_v26, %v38971_v11 (stack48)
        %v40200_v44 = vshll.u32 %v40191_v54, 6 (stack45)
        %v133620_v55 = vadd.s32 %v133615_v46, %v40623_v6 (stack40)
        %v38591_v6 = vsel /*vm=*/%vm38590_vm2, /*on_true_vy=*/%v38588_v43, /*on_false_vx=*/%v38585_v60 (stack66)
        %v39385_v32 = vxor.u32 %v39384_v8, %v39380_v12 (stack48)
        %v39789_v50 = vadd.s32 %v39786_v52, %v121574_v2 (stack40)
        %v40201_v54 = vshrl.u32 %v40191_v54, 26 (stack46)
        %v38230_v24 = vadd.f32 %v38226_v53, %v133533_v24 (stack53)
        %v133624_v31 = vxor.u32 2147483648, %v38591_v6 (stack56)
        %v38979_v11 = vadd.s32 %v38976_v42, %v38971_v11 (stack40)
        %v38981_v10 = vshll.u32 %v38976_v42, 26 (stack45)
        %v38568_v22 = vand.u32 2147483647, %v133549_v40 (stack77)
        %v133628_v52 = vmul.f32 inf, %v133549_v40 (stack54)
        %v38982_v41 = vshrl.u32 %v38976_v42, 6 (stack46)
        %v39388_v12 = vadd.s32 %v39385_v32, %v39380_v12 (stack40)
        %v38234_v9 = vmul.f32 %v38230_v24, %v133581_v25 (stack54)
        %vm38595_vm3 = vcmp.lt.f32.partialorder %v133624_v31, 5.0 (stack68)
        %120759 = vrsqrt.f32 %v133624_v31 (stack67)
        %v39781_v29 = vadd.s32 %v39777_v29, %v121564_v0 (stack40)
        %v38983_v26 = vor.u32 %v38982_v41, %v38981_v10 (stack47)
        %v39390_v60 = vshll.u32 %v39385_v32, 29 (stack45)
        %v39391_v43 = vshrl.u32 %v39385_v32, 3 (stack46)
        %v133636_v8 = vadd.s32 %v133611_v56, %v121569_v1 (stack40)
        %v38238_v20 = vadd.f32 %v38234_v9, %v133528_v20 (stack53)
        %v133640_v53 = vadd.f32 -2.5, %v133624_v31 (stack53)
        %v39793_v42 = vadd.s32 2, %v39789_v50 (stack40)
        %v40202_v44 = vor.u32 %v40201_v54, %v40200_v44 (stack47)
        %v133645_v6 = vsel /*vm=*/%vm38595_vm3, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v133650_v32 = vsel /*vm=*/%vm38595_vm3, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v133655_v50 = vsel /*vm=*/%vm38595_vm3, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v38984_v54 = vxor.u32 %v38983_v26, %v38979_v11 (stack48)
        %v38242_v24 = vmul.f32 %v38238_v20, %v133581_v25 (stack54)
        %v133661_v10 = vsel /*vm=*/%vm38595_vm3, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v133666_v41 = vsel /*vm=*/%vm38595_vm3, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v133671_v9 = vsel /*vm=*/%vm38595_vm3, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %vm133675_vm4 = vcmp.eq.f32.partialorder %v38107_v21, 1.0 (stack68)
        %v38987_v11 = vadd.s32 %v38984_v54, %v38979_v11 (stack40)
        %v38993_v26 = vshll.u32 %v38984_v54, 6 (stack45)
        %v38994_v20 = vshrl.u32 %v38984_v54, 26 (stack46)
        %v39392_v60 = vor.u32 %v39391_v43, %v39390_v60 (stack47)
        %v38246_v23 = vadd.f32 %v38242_v24, %v133520_v23 (stack53)
        %v39797_v29 = vadd.s32 %v39793_v42, %v39781_v29 (stack40)
        %v39799_v43 = vshll.u32 %v39793_v42, 13 (stack45)
        %v39800_v42 = vshrl.u32 %v39793_v42, 19 (stack46)
        %vm38640_vm5 = vcmp.eq.f32.partialorder %v133624_v31, inf (stack70)
        %v38995_v54 = vor.u32 %v38994_v20, %v38993_v26 (stack47)
        %v39393_v24 = vxor.u32 %v39392_v60, %v39388_v12 (stack48)
        %v40203_v56 = vxor.u32 %v40202_v44, %v133611_v56 (stack48)
        %v38250_v25 = vmul.f32 %v38246_v23, %v133581_v25 (stack54)
        %vm38642_vm6 = vcmp.eq.f32.partialorder %v133624_v31, 0.0 (stack71)
        %v39801_v44 = vor.u32 %v39800_v42, %v39799_v43 (stack47)
        %v40633_v26 = vshll.u32 %v133615_v46, 13 (stack45)
        %v40634_v46 = vshrl.u32 %v133615_v46, 19 (stack46)
        %v38996_v20 = vxor.u32 %v38995_v54, %v38987_v11 (stack48)
        %v39396_v12 = vadd.s32 %v39393_v24, %v39388_v12 (stack40)
        %v39398_v60 = vshll.u32 %v39393_v24, 16 (stack45)
        %v39399_v23 = vshrl.u32 %v39393_v24, 16 (stack46)
        %v38254_v61 = vadd.f32 %v38250_v25, %v133515_v61 (stack53)
        %v39802_v43 = vxor.u32 %v39801_v44, %v39797_v29 (stack48)
        %v40206_v42 = vadd.s32 %v40203_v56, %v121564_v0 (stack40)
        %v40635_v54 = vor.u32 %v40634_v46, %v40633_v26 (stack47)
        %v38991_v11 = vadd.s32 %v38987_v11, %v121564_v0 (stack40)
        %v38999_v24 = vadd.s32 %v38996_v20, %v121574_v2 (stack40)
        %v39400_v56 = vor.u32 %v39399_v23, %v39398_v60 (stack47)
        %vm41058_vm7 = vcmp.lt.u32.totalorder %v133601_v7, %v157095_v13 (stack43)
        %v38258_v30 = vmul.f32 %v38254_v61, %v133413_v30 (stack54)
        %v39805_v29 = vadd.s32 %v39802_v43, %v39797_v29 (stack40)
        %v39807_v25 = vshll.u32 %v39802_v43, 15 (stack45)
        %v39808_v44 = vshrl.u32 %v39802_v43, 17 (stack46)
        %v120760_v26 = vpop.eup %120759 (stack73)
        %v39003_v46 = vadd.s32 5, %v38999_v24 (stack40)
        %v39401_v20 = vxor.u32 %v39400_v56, %v39396_v12 (stack48)
        %v40210_v60 = vadd.s32 1, %v40206_v42 (stack40)
        %v40636_v23 = vxor.u32 %v40635_v54, %v133620_v55 (stack48)
        %v38262_v27 = vsel /*vm=*/%vm133675_vm4, /*on_true_vy=*/%v133499_v27, /*on_false_vx=*/%v38258_v30 (stack44)
        %v38639_v21 = vmul.f32 %v120760_v26, %v133624_v31 (stack74)
        %v38643_v61 = vand.u32 2147483648, %v133624_v31 (stack72)
        %v39809_v43 = vor.u32 %v39808_v44, %v39807_v25 (stack47)
        %v38266_v42 = vmul.f32 1.4140625, %v38262_v27 (stack54)
        %v39005_v54 = vxor.u32 %v39003_v46, %v38991_v11 (stack48)
        %v39404_v12 = vadd.s32 %v39401_v20, %v39396_v12 (stack40)
        %v39410_v11 = vshll.u32 %v39401_v20, 24 (stack45)
        %v38641_v24 = vsel /*vm=*/%vm38640_vm5, /*on_true_vy=*/%v133624_v31, /*on_false_vx=*/%v38639_v21 (stack75)
        %v39411_v56 = vshrl.u32 %v39401_v20, 8 (stack46)
        %v39810_v30 = vxor.u32 %v39809_v43, %v39805_v29 (stack48)
        %v40214_v8 = vadd.s32 %v40210_v60, %v133636_v8 (stack40)
        %v38269_v25 = vpack.c.bf16 %v156663_v45, %v38266_v42 (stack81)
        %v38644_v44 = vsel /*vm=*/%vm38642_vm6, /*on_true_vy=*/%v38643_v61, /*on_false_vx=*/%v38641_v24 (stack76)
        %v39006_v26 = vand.u32.u8 255, %v39005_v54 (stack49)
        %v133708_v46 = vadd.s32 %v133601_v7, %v122657_v58 (stack40)
        %v38647_v20 = vadd.f32 -3.0, %v38644_v44 (stack53)
        %v39412_v27 = vor.u32 %v39411_v56, %v39410_v11 (stack47)
        %v39813_v29 = vadd.s32 %v39810_v30, %v39805_v29 (stack40)
        %v39815_v21 = vshll.u32 %v39810_v30, 26 (stack45)
        %119949 = vst [vmem:[%s123356_s30 + $0x28] sm:$0xf] /*vst_source=*/%v38269_v25 (stack83)
        %v39007_v61 = vand.u32 65535, %v39006_v26 (stack50)
        %v39816_v43 = vshrl.u32 %v39810_v30, 6 (stack46)
        %v40216_v42 = vshll.u32 %v40210_v60, 17 (stack45)
        %v40217_v60 = vshrl.u32 %v40210_v60, 15 (stack46)
        %v133714_v53 = vsel /*vm=*/%vm38595_vm3, /*on_true_vy=*/%v133640_v53, /*on_false_vx=*/%v38647_v20 (stack44)
        %v39413_v54 = vxor.u32 %v39412_v27, %v39404_v12 (stack48)
        %v40639_v55 = vadd.s32 %v40636_v23, %v133620_v55 (stack40)
        %v40641_v11 = vshll.u32 %v40636_v23, 15 (stack45)
        %v38655_v9 = vmul.f32 %v133714_v53, %v133671_v9 (stack54)
        %v39008_v24 = vshrl.u32 %v39007_v61, 1 (stack51)
        %v39817_v56 = vor.u32 %v39816_v43, %v39815_v21 (stack47)
        %v40218_v30 = vor.u32 %v40217_v60, %v40216_v42 (stack47)
        %v38628_v25 = vsel /*vm=*/%vm38595_vm3, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v39416_v44 = vadd.s32 %v39413_v54, %v121564_v0 (stack40)
        %v40642_v23 = vshrl.u32 %v40636_v23, 17 (stack46)
        %v41063_v34 = vadd.s32 %v157298_v34, %v157100_v14 (stack40)
        %v38659_v26 = vadd.f32 %v38655_v9, %v38628_v25 (stack53)
        %v39009_v20 = vor.u32 16256, %v39008_v24 (stack47)
        %v39818_v27 = vxor.u32 %v39817_v56, %v39813_v29 (stack48)
        %v40219_v21 = vxor.u32 %v40218_v30, %v40214_v8 (stack48)
        %v39408_v12 = vadd.s32 %v39404_v12, %v121569_v1 (stack40)
        %v39420_v61 = vadd.s32 4, %v39416_v44 (stack40)
        %v40643_v43 = vor.u32 %v40642_v23, %v40641_v11 (stack47)
        %vm41053_vm8 = vcmp.lt.u32.totalorder %v133708_v46, %v133601_v7 (stack43)
        %v38663_v42 = vmul.f32 %v38659_v26, %v133714_v53 (stack54)
        %v39010_v60 = vand.u32.u16 65535, %v39009_v20 (stack52)
        %v39821_v29 = vadd.s32 %v39818_v27, %v39813_v29 (stack40)
        %v39827_v54 = vshll.u32 %v39818_v27, 6 (stack45)
        %v39424_v11 = vadd.s32 %v39420_v61, %v39408_v12 (stack40)
        %v39426_v9 = vshll.u32 %v39420_v61, 13 (stack45)
        %v39427_v24 = vshrl.u32 %v39420_v61, 19 (stack46)
        %v39828_v56 = vshrl.u32 %v39818_v27, 26 (stack46)
        %v38667_v41 = vadd.f32 %v38663_v42, %v133666_v41 (stack53)
        %v119952_v30 = vadd.low.f32.bf16 -1.0, %v39010_v60 (stack53)
        %v40222_v8 = vadd.s32 %v40219_v21, %v40214_v8 (stack40)
        %v41067_v25 = vadd.s32 1, %v41063_v34 (stack40)
        %v39428_v44 = vor.u32 %v39427_v24, %v39426_v9 (stack47)
        %v39829_v23 = vor.u32 %v39828_v56, %v39827_v54 (stack47)
        %v40224_v26 = vshll.u32 %v40219_v21, 29 (stack45)
        %v40225_v20 = vshrl.u32 %v40219_v21, 3 (stack46)
        %v38671_v27 = vmul.f32 %v38667_v41, %v133714_v53 (stack54)
        %v39019_v21 = vmul.f32 2.0, %v119952_v30 (stack54)
        %v40644_v12 = vxor.u32 %v40643_v43, %v40639_v55 (stack48)
        %v41071_v34 = vsel /*vm=*/%vm41058_vm7, /*on_true_vy=*/%v41067_v25, /*on_false_vx=*/%v41063_v34 (stack44)
        %v39429_v61 = vxor.u32 %v39428_v44, %v39424_v11 (stack48)
        %v39830_v43 = vxor.u32 %v39829_v23, %v39821_v29 (stack48)
        %v40226_v42 = vor.u32 %v40225_v20, %v40224_v26 (stack47)
        %v41075_v60 = vadd.s32 1, %v41071_v34 (stack40)
        %v38675_v10 = vadd.f32 %v38671_v27, %v133661_v10 (stack53)
        %v39023_v54 = vadd.f32 -0.99609375, %v39019_v21 (stack53)
        %v133735_v55 = vadd.s32 %v40644_v12, %v40639_v55 (stack40)
        %v133739_v9 = vadd.s32 %v133708_v46, %v121569_v1 (stack40)
        %v39432_v11 = vadd.s32 %v39429_v61, %v39424_v11 (stack40)
        %v39434_v24 = vshll.u32 %v39429_v61, 15 (stack45)
        %v39435_v56 = vshrl.u32 %v39429_v61, 17 (stack46)
        %v39833_v41 = vadd.s32 %v39830_v43, %v121569_v1 (stack40)
        %v38616_v30 = vsel /*vm=*/%vm38595_vm3, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v38679_v25 = vmul.f32 %v38675_v10, %v133714_v53 (stack54)
        %v133746_v44 = vmax.f32 %v39023_v54, -0.99609375 (stack55)
        %v40227_v23 = vxor.u32 %v40226_v42, %v40222_v8 (stack48)
        %v39436_v26 = vor.u32 %v39435_v56, %v39434_v24 (stack47)
        %v39825_v29 = vadd.s32 %v39821_v29, %v121574_v2 (stack40)
        %v39837_v20 = vadd.s32 3, %v39833_v41 (stack40)
        %v41079_v7 = vsel /*vm=*/%vm41053_vm8, /*on_true_vy=*/%v41075_v60, /*on_false_vx=*/%v41071_v34 (stack44)
        %v38612_v31 = vsel /*vm=*/%vm38595_vm3, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v38683_v46 = vadd.f32 %v38679_v25, %v38616_v30 (stack53)
        %v39039_v27 = vxor.u32 2147483648, %v133746_v44 (stack56)
        %v41094_v21 = vshll.u32 %v133739_v9, 13 (stack45)
        %v39437_v34 = vxor.u32 %v39436_v26, %v39432_v11 (stack48)
        %v39841_v61 = vadd.s32 %v39837_v20, %v39825_v29 (stack40)
        %v39843_v43 = vshll.u32 %v39837_v20, 17 (stack45)
        %v39844_v42 = vshrl.u32 %v39837_v20, 15 (stack46)
        %v38687_v60 = vmul.f32 %v38683_v46, %v133714_v53 (stack54)
        %v133759_v10 = vmul.f32 %v39039_v27, %v133746_v44 (stack54)
        %v40230_v8 = vadd.s32 %v40227_v23, %v40222_v8 (stack40)
        %v40649_v54 = vshll.u32 %v40644_v12, 26 (stack45)
        %v39440_v11 = vadd.s32 %v39437_v34, %v39432_v11 (stack40)
        %v39442_v24 = vshll.u32 %v39437_v34, 26 (stack45)
        %v39443_v56 = vshrl.u32 %v39437_v34, 6 (stack46)
        %v39845_v41 = vor.u32 %v39844_v42, %v39843_v43 (stack47)
        %v38691_v30 = vadd.f32 %v38687_v60, %v38612_v31 (stack53)
        %v39044_v25 = vadd.f32 1.0, %v133759_v10 (stack57)
        %v39047_v26 = vmul.f32 -0.5, %v133759_v10 (stack59)
        %v40650_v12 = vshrl.u32 %v40644_v12, 6 (stack46)
        %v39444_v29 = vor.u32 %v39443_v56, %v39442_v24 (stack47)
        %v39846_v20 = vxor.u32 %v39845_v41, %v39841_v61 (stack48)
        %v40232_v31 = vshll.u32 %v40227_v23, 16 (stack45)
        %v40233_v23 = vshrl.u32 %v40227_v23, 16 (stack46)
        %v38695_v46 = vmul.f32 %v38691_v30, %v133714_v53 (stack54)
        %120761 = vlog2.f32 %v39044_v25 (stack58)
        %v39048_v27 = vadd.f32 1.0, %v39047_v26 (stack61)
        %v41095_v34 = vshrl.u32 %v133739_v9, 19 (stack46)
        %v39445_v43 = vxor.u32 %v39444_v29, %v39440_v11 (stack48)
        %v39849_v61 = vadd.s32 %v39846_v20, %v39841_v61 (stack40)
        %v39851_v42 = vshll.u32 %v39846_v20, 29 (stack45)
        %v39852_v60 = vshrl.u32 %v39846_v20, 3 (stack46)
        %v38699_v50 = vadd.f32 %v38695_v46, %v133655_v50 (stack53)
        %v39050_v24 = vand.u32 2147483647, %v133759_v10 (stack60)
        %v40234_v56 = vor.u32 %v40233_v23, %v40232_v31 (stack47)
        %v40651_v54 = vor.u32 %v40650_v12, %v40649_v54 (stack47)
        %v39448_v11 = vadd.s32 %v39445_v43, %v39440_v11 (stack40)
        %v39454_v41 = vshll.u32 %v39445_v43, 6 (stack45)
        %v39455_v30 = vshrl.u32 %v39445_v43, 26 (stack46)
        %v39853_v25 = vor.u32 %v39852_v60, %v39851_v42 (stack47)
        %v38703_v26 = vmul.f32 %v38699_v50, %v133714_v53 (stack54)
        %v39049_v10 = vmul.f32 %v39048_v27, %v133759_v10 (stack63)
        %v40235_v12 = vxor.u32 %v40234_v56, %v40230_v8 (stack48)
        %v40652_v29 = vxor.u32 %v40651_v54, %v133735_v55 (stack48)
        %vm133772_vm9 = vcmp.eq.f32.partialorder %v38568_v22, 1.0 (stack68)
        %v39452_v20 = vadd.s32 %v39448_v11, %v121564_v0 (stack40)
        %v39456_v31 = vor.u32 %v39455_v30, %v39454_v41 (stack47)
        %v39854_v23 = vxor.u32 %v39853_v25, %v39849_v61 (stack48)
        %v41084_v7 = vadd.s32 %v41079_v7, %v121574_v2 (stack40)
        %v38707_v32 = vadd.f32 %v38703_v26, %v133650_v32 (stack53)
        %v40238_v8 = vadd.s32 %v40235_v12, %v40230_v8 (stack40)
        %v40244_v46 = vshll.u32 %v40235_v12, 24 (stack45)
        %v40245_v27 = vshrl.u32 %v40235_v12, 8 (stack46)
        %v39457_v43 = vxor.u32 %v39456_v31, %v39448_v11 (stack48)
        %v39857_v61 = vadd.s32 %v39854_v23, %v39849_v61 (stack40)
        %v39859_v42 = vshll.u32 %v39854_v23, 16 (stack45)
        %v39860_v60 = vshrl.u32 %v39854_v23, 16 (stack46)
        %v38711_v53 = vmul.f32 %v38707_v32, %v133714_v53 (stack54)
        %v40246_v50 = vor.u32 %v40245_v27, %v40244_v46 (stack47)
        %v40655_v55 = vadd.s32 %v40652_v29, %v133735_v55 (stack40)
        %v41096_v21 = vor.u32 %v41095_v34, %v41094_v21 (stack47)
        %v39460_v34 = vadd.s32 %v39457_v43, %v121574_v2 (stack40)
        %v39861_v56 = vor.u32 %v39860_v60, %v39859_v42 (stack47)
        %v40661_v54 = vshll.u32 %v40652_v29, 6 (stack45)
        %v40662_v11 = vshrl.u32 %v40652_v29, 26 (stack46)
        %v38715_v6 = vadd.f32 %v38711_v53, %v133645_v6 (stack53)
        %v40242_v41 = vadd.s32 %v40238_v8, %v121564_v0 (stack40)
        %v40247_v30 = vxor.u32 %v40246_v50, %v40238_v8 (stack48)
        %v41092_v9 = vadd.s32 %v133739_v9, %v41084_v7 (stack40)
        %v39464_v25 = vadd.s32 5, %v39460_v34 (stack40)
        %v39862_v26 = vxor.u32 %v39861_v56, %v39857_v61 (stack48)
        %v40663_v12 = vor.u32 %v40662_v11, %v40661_v54 (stack47)
        %v157317_v29 = vld [vmem:[#allocation131_spill] sm:$0xff] (stack84)
        %v133787_v31 = vadd.s32 %v157317_v29, %v122651_v47 (stack40)
        %v38719_v40 = vmul.f32 %v38715_v6, %v133549_v40 (stack54)
        %v40250_v23 = vadd.s32 %v40247_v30, %v121574_v2 (stack40)
        %v133791_v7 = vxor.u32 %v41096_v21, %v41092_v9 (stack48)
        %v157318_v32 = vld [vmem:[#allocation91_spill] sm:$0xff] (stack84)
        %v133795_v8 = vadd.s32 %v157318_v32, %v157068_v28 (stack40)
        %v120762_v46 = vpop.eup %120761 (stack64)
        %v39466_v20 = vxor.u32 %v39464_v25, %v39452_v20 (stack48)
        %v39865_v27 = vadd.s32 %v39862_v26, %v39857_v61 (stack40)
        %v39871_v43 = vshll.u32 %v39862_v26, 24 (stack45)
        %v39872_v61 = vshrl.u32 %v39862_v26, 8 (stack46)
        %v38723_v52 = vsel /*vm=*/%vm133772_vm9, /*on_true_vy=*/%v133628_v52, /*on_false_vx=*/%v38719_v40 (stack44)
        %v39046_v22 = vmul.f32 0.6931472, %v120762_v46 (stack65)
        %v40254_v42 = vadd.s32 2, %v40250_v23 (stack40)
        %v40664_v60 = vxor.u32 %v40663_v12, %v40655_v55 (stack48)
        %v38727_v53 = vmul.f32 1.4140625, %v38723_v52 (stack54)
        %vm39051_vm10 = vcmp.lt.f32.partialorder %v39050_v24, 0.0004427343 (stack62)
        %v39467_v24 = vand.u32.u8 255, %v39466_v20 (stack49)
        %v39873_v50 = vor.u32 %v39872_v61, %v39871_v43 (stack47)
        %v39052_v10 = vsel /*vm=*/%vm39051_vm10, /*on_true_vy=*/%v39049_v10, /*on_false_vx=*/%v39046_v22 (stack66)
        %v40258_v21 = vadd.s32 %v40254_v42, %v40242_v41 (stack40)
        %v40260_v34 = vshll.u32 %v40254_v42, 13 (stack45)
        %v40261_v56 = vshrl.u32 %v40254_v42, 19 (stack46)
        %v38730_v54 = vpack.c.bf16 %v156663_v45, %v38727_v53 (stack81)
        %v133801_v11 = vxor.u32 2147483648, %v39052_v10 (stack56)
        %v39874_v6 = vxor.u32 %v39873_v50, %v39865_v27 (stack48)
        %v40262_v41 = vor.u32 %v40261_v56, %v40260_v34 (stack47)
        %v133804_v30 = vadd.s32 %v133791_v7, %v41092_v9 (stack40)
        %119951 = vst [vmem:[%s123356_s30 + $0xa8] sm:$0xf] /*vst_source=*/%v38730_v54 (stack83)
        %120763 = vrsqrt.f32 %v133801_v11 (stack67)
        %v39468_v9 = vand.u32 65535, %v39467_v24 (stack50)
        %vm39056_vm11 = vcmp.lt.f32.partialorder %v133801_v11, 5.0 (stack68)
        %v39877_v25 = vadd.s32 %v39874_v6, %v121564_v0 (stack40)
        %v40667_v26 = vadd.s32 %v40664_v60, %v121564_v0 (stack40)
        %v40263_v12 = vxor.u32 %v40262_v41, %v40258_v21 (stack48)
        %v133812_v40 = vadd.f32 -2.5, %v133801_v11 (stack53)
        %v39869_v23 = vadd.s32 %v39865_v27, %v121569_v1 (stack40)
        %v40659_v55 = vadd.s32 %v40655_v55, %v121569_v1 (stack40)
        %v41102_v46 = vshll.u32 %v133791_v7, 15 (stack45)
        %v133820_v20 = vsel /*vm=*/%vm39056_vm11, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v133825_v27 = vsel /*vm=*/%vm39056_vm11, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v39469_v43 = vshrl.u32 %v39468_v9, 1 (stack51)
        %v39881_v61 = vadd.s32 4, %v39877_v25 (stack40)
        %v40266_v52 = vadd.s32 %v40263_v12, %v40258_v21 (stack40)
        %v40268_v22 = vshll.u32 %v40263_v12, 15 (stack45)
        %v40269_v42 = vshrl.u32 %v40263_v12, 17 (stack46)
        %v40671_v60 = vadd.s32 1, %v40667_v26 (stack40)
        %v39470_v53 = vor.u32 16256, %v39469_v43 (stack47)
        %v39885_v24 = vadd.s32 %v39881_v61, %v39869_v23 (stack40)
        %v39887_v50 = vshll.u32 %v39881_v61, 13 (stack45)
        %v39888_v10 = vshrl.u32 %v39881_v61, 19 (stack46)
        %vm39101_vm12 = vcmp.eq.f32.partialorder %v133801_v11, inf (stack70)
        %v40270_v21 = vor.u32 %v40269_v42, %v40268_v22 (stack47)
        %v40675_v34 = vadd.s32 %v40671_v60, %v40659_v55 (stack40)
        %v40677_v56 = vshll.u32 %v40671_v60, 17 (stack45)
        %v40678_v54 = vshrl.u32 %v40671_v60, 15 (stack46)
        %v39471_v6 = vand.u32.u16 65535, %v39470_v53 (stack52)
        %v39889_v41 = vor.u32 %v39888_v10, %v39887_v50 (stack47)
        %v41103_v7 = vshrl.u32 %v133791_v7, 17 (stack46)
        %v133831_v9 = vadd.s32 %v133787_v31, %v122657_v58 (stack40)
        %vm39103_vm13 = vcmp.eq.f32.partialorder %v133801_v11, 0.0 (stack71)
        %v40271_v25 = vxor.u32 %v40270_v21, %v40266_v52 (stack48)
        %v40679_v26 = vor.u32 %v40678_v54, %v40677_v56 (stack47)
        %vm41553_vm14 = vcmp.lt.u32.totalorder %v133787_v31, %v122651_v47 (stack43)
        %v119954_v12 = vadd.low.f32.bf16 -1.0, %v39471_v6 (stack53)
        %v39890_v23 = vxor.u32 %v39889_v41, %v39885_v24 (stack48)
        %v41104_v55 = vor.u32 %v41103_v7, %v41102_v46 (stack47)
        %v41562_v46 = vadd.s32 1, %v133795_v8 (stack40)
        %v40274_v43 = vadd.s32 %v40271_v25, %v40266_v52 (stack40)
        %v40276_v61 = vshll.u32 %v40271_v25, 26 (stack45)
        %v40277_v52 = vshrl.u32 %v40271_v25, 6 (stack46)
        %v40680_v22 = vxor.u32 %v40679_v26, %v40675_v34 (stack48)
        %v39480_v42 = vmul.f32 2.0, %v119954_v12 (stack54)
        %v39893_v60 = vadd.s32 %v39890_v23, %v39885_v24 (stack40)
        %v39895_v53 = vshll.u32 %v39890_v23, 15 (stack45)
        %v39896_v24 = vshrl.u32 %v39890_v23, 17 (stack46)
        %v120764_v50 = vpop.eup %120763 (stack73)
        %v40278_v10 = vor.u32 %v40277_v52, %v40276_v61 (stack47)
        %v40683_v21 = vadd.s32 %v40680_v22, %v40675_v34 (stack40)
        %v40685_v34 = vshll.u32 %v40680_v22, 29 (stack45)
        %v40686_v56 = vshrl.u32 %v40680_v22, 3 (stack46)
        %v39100_v54 = vmul.f32 %v120764_v50, %v133801_v11 (stack74)
        %v39484_v6 = vadd.f32 -0.99609375, %v39480_v42 (stack53)
        %v39897_v41 = vor.u32 %v39896_v24, %v39895_v53 (stack47)
        %v41105_v7 = vxor.u32 %v41104_v55, %v133804_v30 (stack48)
        %v39104_v25 = vand.u32 2147483648, %v133801_v11 (stack72)
        %v40279_v26 = vxor.u32 %v40278_v10, %v40274_v43 (stack48)
        %v40687_v12 = vor.u32 %v40686_v56, %v40685_v34 (stack47)
        %v41566_v8 = vsel /*vm=*/%vm41553_vm14, /*on_true_vy=*/%v41562_v46, /*on_false_vx=*/%v133795_v8 (stack44)
        %v39102_v23 = vsel /*vm=*/%vm39101_vm12, /*on_true_vy=*/%v133801_v11, /*on_false_vx=*/%v39100_v54 (stack75)
        %v133847_v55 = vmax.f32 %v39484_v6, -0.99609375 (stack55)
        %v39898_v46 = vxor.u32 %v39897_v41, %v39893_v60 (stack48)
        %v133850_v30 = vadd.s32 %v41105_v7, %v133804_v30 (stack40)
        %v39105_v61 = vsel /*vm=*/%vm39103_vm13, /*on_true_vy=*/%v39104_v25, /*on_false_vx=*/%v39102_v23 (stack76)
        %v40282_v43 = vadd.s32 %v40279_v26, %v40274_v43 (stack40)
        %v40288_v52 = vshll.u32 %v40279_v26, 6 (stack45)
        %v40289_v22 = vshrl.u32 %v40279_v26, 26 (stack46)
        %v39081_v42 = vsel /*vm=*/%vm39056_vm11, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v39108_v53 = vadd.f32 -3.0, %v39105_v61 (stack53)
        %v39500_v24 = vxor.u32 2147483648, %v133847_v55 (stack56)
        %v133860_v50 = vadd.s32 %v133831_v9, %v121569_v1 (stack40)
        %v39085_v10 = vsel /*vm=*/%vm39056_vm11, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v39901_v60 = vadd.s32 %v39898_v46, %v39893_v60 (stack40)
        %v39903_v34 = vshll.u32 %v39898_v46, 26 (stack45)
        %v39904_v56 = vshrl.u32 %v39898_v46, 6 (stack46)
        %v39093_v54 = vsel /*vm=*/%vm39056_vm11, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v133871_v40 = vsel /*vm=*/%vm39056_vm11, /*on_true_vy=*/%v133812_v40, /*on_false_vx=*/%v39108_v53 (stack44)
        %v133874_v6 = vmul.f32 %v39500_v24, %v133847_v55 (stack54)
        %v40290_v41 = vor.u32 %v40289_v22, %v40288_v52 (stack47)
        %v39089_v25 = vsel /*vm=*/%vm39056_vm11, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v39116_v26 = vmul.f32 %v133871_v40, %v39093_v54 (stack54)
        %v39905_v23 = vor.u32 %v39904_v56, %v39903_v34 (stack47)
        %v40688_v12 = vxor.u32 %v40687_v12, %v40683_v21 (stack48)
        %v39505_v46 = vadd.f32 1.0, %v133874_v6 (stack57)
        %v40291_v61 = vxor.u32 %v40290_v41, %v40282_v43 (stack48)
        %vm41548_vm15 = vcmp.lt.u32.totalorder %v133831_v9, %v133787_v31 (stack43)
        %v41589_v52 = vshll.u32 %v133860_v50, 13 (stack45)
        %v39120_v22 = vadd.f32 %v39116_v26, %v39089_v25 (stack53)
        %v39508_v53 = vmul.f32 -0.5, %v133874_v6 (stack59)
        %v39906_v24 = vxor.u32 %v39905_v23, %v39901_v60 (stack48)
        %v40691_v21 = vadd.s32 %v40688_v12, %v40683_v21 (stack40)
        %120765 = vlog2.f32 %v39505_v46 (stack58)
        %v40294_v34 = vadd.s32 %v40291_v61, %v121569_v1 (stack40)
        %v40693_v56 = vshll.u32 %v40688_v12, 16 (stack45)
        %v41110_v54 = vshll.u32 %v41105_v7, 26 (stack45)
        %v39124_v41 = vmul.f32 %v39120_v22, %v133871_v40 (stack54)
        %v39909_v60 = vadd.s32 %v39906_v24, %v39901_v60 (stack40)
        %v39915_v25 = vshll.u32 %v39906_v24, 6 (stack45)
        %v39916_v26 = vshrl.u32 %v39906_v24, 26 (stack46)
        %v40286_v43 = vadd.s32 %v40282_v43, %v121574_v2 (stack40)
        %v40298_v23 = vadd.s32 3, %v40294_v34 (stack40)
        %v40694_v12 = vshrl.u32 %v40688_v12, 16 (stack46)
        %v41111_v7 = vshrl.u32 %v41105_v7, 6 (stack46)
        %v39128_v10 = vadd.f32 %v39124_v41, %v39085_v10 (stack53)
        %v39509_v46 = vadd.f32 1.0, %v39508_v53 (stack61)
        %v39917_v61 = vor.u32 %v39916_v26, %v39915_v25 (stack47)
        %v41570_v22 = vadd.s32 1, %v41566_v8 (stack40)
        %v40302_v53 = vadd.s32 %v40298_v23, %v40286_v43 (stack40)
        %v40304_v24 = vshll.u32 %v40298_v23, 17 (stack45)
        %v40305_v34 = vshrl.u32 %v40298_v23, 15 (stack46)
        %v40695_v56 = vor.u32 %v40694_v12, %v40693_v56 (stack47)
        %v39132_v41 = vmul.f32 %v39128_v10, %v133871_v40 (stack54)
        %v39918_v25 = vxor.u32 %v39917_v61, %v39909_v60 (stack48)
        %v41112_v54 = vor.u32 %v41111_v7, %v41110_v54 (stack47)
        %v41574_v31 = vsel /*vm=*/%vm41548_vm15, /*on_true_vy=*/%v41570_v22, /*on_false_vx=*/%v41566_v8 (stack44)
        %v40306_v9 = vor.u32 %v40305_v34, %v40304_v24 (stack47)
        %v40696_v8 = vxor.u32 %v40695_v56, %v40691_v21 (stack48)
        %v41579_v26 = vadd.s32 %v41574_v31, %v121574_v2 (stack40)
        %v41590_v43 = vshrl.u32 %v133860_v50, 19 (stack46)
        %v39136_v42 = vadd.f32 %v39132_v41, %v39081_v42 (stack53)
        %v39921_v23 = vadd.s32 %v39918_v25, %v121574_v2 (stack40)
        %v41113_v12 = vxor.u32 %v41112_v54, %v133850_v30 (stack48)
        %v133898_v7 = vadd.s32 %v157317_v29, %v157070_v38 (stack40)
        %v40307_v10 = vxor.u32 %v40306_v9, %v40302_v53 (stack48)
        %v40699_v21 = vadd.s32 %v40696_v8, %v40691_v21 (stack40)
        %v40705_v61 = vshll.u32 %v40696_v8, 24 (stack45)
        %v40706_v22 = vshrl.u32 %v40696_v8, 8 (stack46)
        %v39140_v24 = vmul.f32 %v39136_v42, %v133871_v40 (stack54)
        %v39913_v60 = vadd.s32 %v39909_v60, %v121564_v0 (stack40)
        %v39925_v34 = vadd.s32 5, %v39921_v23 (stack40)
        %v133903_v30 = vadd.s32 %v41113_v12, %v133850_v30 (stack40)
        %v40310_v53 = vadd.s32 %v40307_v10, %v40302_v53 (stack40)
        %v40312_v56 = vshll.u32 %v40307_v10, 29 (stack45)
        %v40313_v41 = vshrl.u32 %v40307_v10, 3 (stack46)
        %v41122_v25 = vshll.u32 %v41113_v12, 6 (stack45)
        %v39144_v27 = vadd.f32 %v39140_v24, %v133825_v27 (stack53)
        %v39511_v54 = vand.u32 2147483647, %v133874_v6 (stack60)
        %v39927_v31 = vxor.u32 %v39925_v34, %v39913_v60 (stack48)
        %v40707_v9 = vor.u32 %v40706_v22, %v40705_v61 (stack47)
        %v40314_v8 = vor.u32 %v40313_v41, %v40312_v56 (stack47)
        %v41123_v42 = vshrl.u32 %v41113_v12, 26 (stack46)
        %v41587_v50 = vadd.s32 %v133860_v50, %v41579_v26 (stack40)
        %v41591_v52 = vor.u32 %v41590_v43, %v41589_v52 (stack47)
        %v120766_v26 = vpop.eup %120765 (stack64)
        %v39148_v43 = vmul.f32 %v39144_v27, %v133871_v40 (stack54)
        %v39510_v6 = vmul.f32 %v39509_v46, %v133874_v6 (stack63)
        %v39928_v46 = vand.u32.u8 255, %v39927_v31 (stack49)
        %v40708_v23 = vxor.u32 %v40707_v9, %v40699_v21 (stack48)
        %v39507_v12 = vmul.f32 0.6931472, %v120766_v26 (stack65)
        %v40315_v10 = vxor.u32 %v40314_v8, %v40310_v53 (stack48)
        %v41124_v61 = vor.u32 %v41123_v42, %v41122_v25 (stack47)
        %v41592_v22 = vxor.u32 %v41591_v52, %v41587_v50 (stack48)
        %v39152_v20 = vadd.f32 %v39148_v43, %v133820_v20 (stack53)
        %vm39512_vm0 = vcmp.lt.f32.partialorder %v39511_v54, 0.0004427343 (stack62)
        %v39929_v24 = vand.u32 65535, %v39928_v46 (stack50)
        %v39513_v60 = vsel /*vm=*/%vm39512_vm0, /*on_true_vy=*/%v39510_v6, /*on_false_vx=*/%v39507_v12 (stack66)
        %v40318_v34 = vadd.s32 %v40315_v10, %v40310_v53 (stack40)
        %v40320_v53 = vshll.u32 %v40315_v10, 16 (stack45)
        %v40321_v56 = vshrl.u32 %v40315_v10, 16 (stack46)
        %v39029_v41 = vand.u32 2147483647, %v133746_v44 (stack77)
        %v39156_v25 = vmul.f32 %v39152_v20, %v133871_v40 (stack54)
        %v133913_v27 = vxor.u32 2147483648, %v39513_v60 (stack56)
        %v40711_v54 = vadd.s32 %v40708_v23, %v121574_v2 (stack40)
        %v39069_v31 = vsel /*vm=*/%vm39056_vm11, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v40322_v9 = vor.u32 %v40321_v56, %v40320_v53 (stack47)
        %v41125_v8 = vxor.u32 %v41124_v61, %v133903_v30 (stack48)
        %v133920_v42 = vadd.s32 %v41592_v22, %v41587_v50 (stack40)
        %v39160_v50 = vadd.f32 %v39156_v25, %v39069_v31 (stack53)
        %120767 = vrsqrt.f32 %v133913_v27 (stack67)
        %v39930_v52 = vshrl.u32 %v39929_v24, 1 (stack51)
        %v40323_v26 = vxor.u32 %v40322_v9, %v40318_v34 (stack48)
        %v39037_v43 = vmul.f32 inf, %v133746_v44 (stack54)
        %v39061_v6 = vsel /*vm=*/%vm39056_vm11, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v39164_v46 = vmul.f32 %v39160_v50, %v133871_v40 (stack54)
        %v40715_v23 = vadd.s32 2, %v40711_v54 (stack40)
        %vm133928_vm1 = vcmp.eq.f32.partialorder %v39029_v41, 1.0 (stack68)
        %v39065_v11 = vsel /*vm=*/%vm39056_vm11, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v40326_v10 = vadd.s32 %v40323_v26, %v40318_v34 (stack40)
        %v40703_v21 = vadd.s32 %v40699_v21, %v121564_v0 (stack40)
        %v41120_v30 = vadd.s32 %v133903_v30, %v121569_v1 (stack40)
        %v39168_v61 = vadd.f32 %v39164_v46, %v39065_v11 (stack53)
        %v133939_v20 = vadd.f32 -2.5, %v133913_v27 (stack53)
        %v41597_v24 = vshll.u32 %v41592_v22, 15 (stack45)
        %v133943_v60 = vadd.s32 %v133898_v7, %v122657_v58 (stack40)
        %v39565_v34 = vand.u32 2147483648, %v133913_v27 (stack72)
        %v39931_v53 = vor.u32 16256, %v39930_v52 (stack47)
        %v40332_v56 = vshll.u32 %v40323_v26, 24 (stack45)
        %v40333_v41 = vshrl.u32 %v40323_v26, 8 (stack46)
        %v39172_v40 = vmul.f32 %v39168_v61, %v133871_v40 (stack54)
        %vm39517_vm2 = vcmp.lt.f32.partialorder %v133913_v27, 5.0 (stack68)
        %v40719_v25 = vadd.s32 %v40715_v23, %v40703_v21 (stack40)
        %v40721_v54 = vshll.u32 %v40715_v23, 13 (stack45)
        %v40722_v31 = vshrl.u32 %v40715_v23, 19 (stack46)
        %vm39562_vm3 = vcmp.eq.f32.partialorder %v133913_v27, inf (stack70)
        %v39932_v9 = vand.u32.u16 65535, %v39931_v53 (stack52)
        %v40334_v50 = vor.u32 %v40333_v41, %v40332_v56 (stack47)
        %v41128_v8 = vadd.s32 %v41125_v8, %v121564_v0 (stack40)
        %v41598_v22 = vshrl.u32 %v41592_v22, 17 (stack46)
        %v39176_v52 = vadd.f32 %v39172_v40, %v39061_v6 (stack53)
        %vm39564_vm4 = vcmp.eq.f32.partialorder %v133913_v27, 0.0 (stack71)
        %v40723_v26 = vor.u32 %v40722_v31, %v40721_v54 (stack47)
        %vm42014_vm5 = vcmp.lt.u32.totalorder %v133898_v7, %v157070_v38 (stack43)
        %v42019_v6 = vadd.s32 %v157318_v32, %v157076_v35 (stack40)
        %v119956_v46 = vadd.low.f32.bf16 -1.0, %v39932_v9 (stack53)
        %v40330_v23 = vadd.s32 %v40326_v10, %v121569_v1 (stack40)
        %v40335_v11 = vxor.u32 %v40334_v50, %v40326_v10 (stack48)
        %v41132_v10 = vadd.s32 1, %v41128_v8 (stack40)
        %v39180_v44 = vmul.f32 %v39176_v52, %v133746_v44 (stack54)
        %v40724_v21 = vxor.u32 %v40723_v26, %v40719_v25 (stack48)
        %v41599_v61 = vor.u32 %v41598_v22, %v41597_v24 (stack47)
        %v42023_v24 = vadd.s32 1, %v42019_v6 (stack40)
        %v39941_v53 = vmul.f32 2.0, %v119956_v46 (stack54)
        %v40338_v56 = vadd.s32 %v40335_v11, %v121564_v0 (stack40)
        %v41136_v30 = vadd.s32 %v41132_v10, %v41120_v30 (stack40)
        %v41138_v41 = vshll.u32 %v41132_v10, 17 (stack45)
        %v39184_v43 = vsel /*vm=*/%vm133928_vm1, /*on_true_vy=*/%v39037_v43, /*on_false_vx=*/%v39180_v44 (stack44)
        %v40727_v12 = vadd.s32 %v40724_v21, %v40719_v25 (stack40)
        %v40729_v40 = vshll.u32 %v40724_v21, 15 (stack45)
        %v40730_v25 = vshrl.u32 %v40724_v21, 17 (stack46)
        %v120768_v54 = vpop.eup %120767 (stack73)
        %v39188_v31 = vmul.f32 1.4140625, %v39184_v43 (stack54)
        %v39945_v9 = vadd.f32 -0.99609375, %v39941_v53 (stack53)
        %v40342_v50 = vadd.s32 4, %v40338_v56 (stack40)
        %v41139_v8 = vshrl.u32 %v41132_v10, 15 (stack46)
        %v39561_v22 = vmul.f32 %v120768_v54, %v133913_v27 (stack74)
        %v40731_v52 = vor.u32 %v40730_v25, %v40729_v40 (stack47)
        %v41600_v26 = vxor.u32 %v41599_v61, %v133920_v42 (stack48)
        %v133965_v6 = vsel /*vm=*/%vm42014_vm5, /*on_true_vy=*/%v42023_v24, /*on_false_vx=*/%v42019_v6 (stack44)
        %v39191_v46 = vpack.c.bf16 %v156663_v45, %v39188_v31 (stack81)
        %v133968_v11 = vmax.f32 %v39945_v9, -0.99609375 (stack55)
        %v40346_v23 = vadd.s32 %v40342_v50, %v40330_v23 (stack40)
        %v40348_v10 = vshll.u32 %v40342_v50, 13 (stack45)
        %v39563_v44 = vsel /*vm=*/%vm39562_vm3, /*on_true_vy=*/%v133913_v27, /*on_false_vx=*/%v39561_v22 (stack75)
        %v40349_v21 = vshrl.u32 %v40342_v50, 19 (stack46)
        %v40732_v61 = vxor.u32 %v40731_v52, %v40727_v12 (stack48)
        %v41140_v24 = vor.u32 %v41139_v8, %v41138_v41 (stack47)
        %119953 = vst [vmem:[%s123356_s30 + $0x128] sm:$0xf] /*vst_source=*/%v39191_v46 (stack83)
        %v133977_v53 = vsel /*vm=*/%vm39517_vm2, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v133982_v56 = vsel /*vm=*/%vm39517_vm2, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v39566_v34 = vsel /*vm=*/%vm39564_vm4, /*on_true_vy=*/%v39565_v34, /*on_false_vx=*/%v39563_v44 (stack76)
        %v39961_v41 = vxor.u32 2147483648, %v133968_v11 (stack56)
        %v39569_v43 = vadd.f32 -3.0, %v39566_v34 (stack53)
        %v40350_v40 = vor.u32 %v40349_v21, %v40348_v10 (stack47)
        %v40735_v12 = vadd.s32 %v40732_v61, %v40727_v12 (stack40)
        %v40737_v25 = vshll.u32 %v40732_v61, 26 (stack45)
        %v39542_v54 = vsel /*vm=*/%vm39517_vm2, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v133991_v31 = vmul.f32 %v39961_v41, %v133968_v11 (stack54)
        %v40738_v9 = vshrl.u32 %v40732_v61, 6 (stack46)
        %v41141_v50 = vxor.u32 %v41140_v24, %v41136_v30 (stack48)
        %vm42009_vm6 = vcmp.lt.u32.totalorder %v133943_v60, %v133898_v7 (stack43)
        %v39554_v8 = vsel /*vm=*/%vm39517_vm2, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v134001_v20 = vsel /*vm=*/%vm39517_vm2, /*on_true_vy=*/%v133939_v20, /*on_false_vx=*/%v39569_v43 (stack44)
        %v40351_v22 = vxor.u32 %v40350_v40, %v40346_v23 (stack48)
        %v41603_v42 = vadd.s32 %v41600_v26, %v133920_v42 (stack40)
        %v39546_v52 = vsel /*vm=*/%vm39517_vm2, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v39550_v46 = vsel /*vm=*/%vm39517_vm2, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v39577_v10 = vmul.f32 %v134001_v20, %v39554_v8 (stack54)
        %v39966_v44 = vadd.f32 1.0, %v133991_v31 (stack57)
        %v40354_v23 = vadd.s32 %v40351_v22, %v40346_v23 (stack40)
        %v40356_v21 = vshll.u32 %v40351_v22, 15 (stack45)
        %v40357_v61 = vshrl.u32 %v40351_v22, 17 (stack46)
        %v40739_v24 = vor.u32 %v40738_v9, %v40737_v25 (stack47)
        %v39581_v34 = vadd.f32 %v39577_v10, %v39550_v46 (stack53)
        %120769 = vlog2.f32 %v39966_v44 (stack58)
        %v39969_v41 = vmul.f32 -0.5, %v133991_v31 (stack59)
        %v41605_v43 = vshll.u32 %v41600_v26, 26 (stack45)
        %v40358_v40 = vor.u32 %v40357_v61, %v40356_v21 (stack47)
        %v40740_v25 = vxor.u32 %v40739_v24, %v40735_v12 (stack48)
        %v41144_v30 = vadd.s32 %v41141_v50, %v41136_v30 (stack40)
        %v41146_v9 = vshll.u32 %v41141_v50, 29 (stack45)
        %v39585_v8 = vmul.f32 %v39581_v34, %v134001_v20 (stack54)
        %v39972_v22 = vand.u32 2147483647, %v133991_v31 (stack60)
        %v41147_v50 = vshrl.u32 %v41141_v50, 3 (stack46)
        %v41606_v26 = vshrl.u32 %v41600_v26, 6 (stack46)
        %v40359_v46 = vxor.u32 %v40358_v40, %v40354_v23 (stack48)
        %v40743_v12 = vadd.s32 %v40740_v25, %v40735_v12 (stack40)
        %v40749_v10 = vshll.u32 %v40740_v25, 6 (stack45)
        %v40750_v44 = vshrl.u32 %v40740_v25, 26 (stack46)
        %v39589_v52 = vadd.f32 %v39585_v8, %v39546_v52 (stack53)
        %v41148_v21 = vor.u32 %v41147_v50, %v41146_v9 (stack47)
        %v41607_v61 = vor.u32 %v41606_v26, %v41605_v43 (stack47)
        %v42031_v24 = vadd.s32 1, %v133965_v6 (stack40)
        %v40362_v23 = vadd.s32 %v40359_v46, %v40354_v23 (stack40)
        %v40364_v34 = vshll.u32 %v40359_v46, 26 (stack45)
        %v40365_v43 = vshrl.u32 %v40359_v46, 6 (stack46)
        %v134018_v40 = vadd.s32 %v133943_v60, %v121569_v1 (stack40)
        %v39593_v25 = vmul.f32 %v39589_v52, %v134001_v20 (stack54)
        %v40751_v9 = vor.u32 %v40750_v44, %v40749_v10 (stack47)
        %v41149_v8 = vxor.u32 %v41148_v21, %v41144_v30 (stack48)
        %v41608_v50 = vxor.u32 %v41607_v61, %v41603_v42 (stack48)
        %v39970_v41 = vadd.f32 1.0, %v39969_v41 (stack61)
        %vm134021_vm7 = vcmp.lt.f32.partialorder %v39972_v22, 0.0004427343 (stack62)
        %v40366_v26 = vor.u32 %v40365_v43, %v40364_v34 (stack47)
        %v42035_v7 = vsel /*vm=*/%vm42009_vm6, /*on_true_vy=*/%v42031_v24, /*on_false_vx=*/%v133965_v6 (stack44)
        %v39597_v60 = vadd.f32 %v39593_v25, %v39542_v54 (stack53)
        %v40752_v6 = vxor.u32 %v40751_v9, %v40743_v12 (stack48)
        %v41152_v54 = vadd.s32 %v41149_v8, %v41144_v30 (stack40)
        %v41154_v30 = vshll.u32 %v41149_v8, 16 (stack45)
        %v40367_v46 = vxor.u32 %v40366_v26, %v40362_v23 (stack48)
        %v41155_v10 = vshrl.u32 %v41149_v8, 16 (stack46)
        %v41611_v42 = vadd.s32 %v41608_v50, %v41603_v42 (stack40)
        %v41617_v44 = vshll.u32 %v41608_v50, 6 (stack45)
        %v39601_v52 = vmul.f32 %v39597_v60, %v134001_v20 (stack54)
        %v40755_v21 = vadd.s32 %v40752_v6, %v121569_v1 (stack40)
        %v41618_v61 = vshrl.u32 %v41608_v50, 26 (stack46)
        %v42040_v24 = vadd.s32 %v42035_v7, %v121574_v2 (stack40)
        %v40370_v23 = vadd.s32 %v40367_v46, %v40362_v23 (stack40)
        %v40376_v34 = vshll.u32 %v40367_v46, 6 (stack45)
        %v40377_v43 = vshrl.u32 %v40367_v46, 26 (stack46)
        %v41156_v25 = vor.u32 %v41155_v10, %v41154_v30 (stack47)
        %v39605_v56 = vadd.f32 %v39601_v52, %v133982_v56 (stack53)
        %v40747_v12 = vadd.s32 %v40743_v12, %v121574_v2 (stack40)
        %v40759_v9 = vadd.s32 3, %v40755_v21 (stack40)
        %v41619_v8 = vor.u32 %v41618_v61, %v41617_v44 (stack47)
        %v120770_v50 = vpop.eup %120769 (stack64)
        %v39971_v31 = vmul.f32 %v39970_v41, %v133991_v31 (stack63)
        %v40378_v41 = vor.u32 %v40377_v43, %v40376_v34 (stack47)
        %v41157_v26 = vxor.u32 %v41156_v25, %v41152_v54 (stack48)
        %v134036_v7 = vadd.s32 %v134018_v40, %v42040_v24 (stack40)
        %v39609_v60 = vmul.f32 %v39605_v56, %v134001_v20 (stack54)
        %v39968_v6 = vmul.f32 0.6931472, %v120770_v50 (stack65)
        %v40763_v30 = vadd.s32 %v40759_v9, %v40747_v12 (stack40)
        %v40765_v46 = vshll.u32 %v40759_v9, 17 (stack45)
        %v40379_v10 = vxor.u32 %v40378_v41, %v40370_v23 (stack48)
        %v40766_v44 = vshrl.u32 %v40759_v9, 15 (stack46)
        %v41160_v54 = vadd.s32 %v41157_v26, %v41152_v54 (stack40)
        %v41166_v52 = vshll.u32 %v41157_v26, 24 (stack45)
        %v39613_v53 = vadd.f32 %v39609_v60, %v133977_v53 (stack53)
        %v39974_v22 = vsel /*vm=*/%vm134021_vm7, /*on_true_vy=*/%v39971_v31, /*on_false_vx=*/%v39968_v6 (stack66)
        %v41167_v21 = vshrl.u32 %v41157_v26, 8 (stack46)
        %v41620_v61 = vxor.u32 %v41619_v8, %v41611_v42 (stack48)
        %v134042_v24 = vxor.u32 2147483648, %v39974_v22 (stack56)
        %v40767_v34 = vor.u32 %v40766_v44, %v40765_v46 (stack47)
        %v42050_v43 = vshll.u32 %v134018_v40, 13 (stack45)
        %v42051_v40 = vshrl.u32 %v134018_v40, 19 (stack46)
        %v39490_v25 = vand.u32 2147483647, %v133847_v55 (stack77)
        %v134048_v56 = vmul.f32 inf, %v133847_v55 (stack54)
        %v39522_v12 = vsel /*vm=*/%vm39517_vm2, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v39617_v9 = vmul.f32 %v39613_v53, %v134001_v20 (stack54)
        %v39526_v8 = vsel /*vm=*/%vm39517_vm2, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v39530_v27 = vsel /*vm=*/%vm39517_vm2, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %120771 = vrsqrt.f32 %v134042_v24 (stack67)
        %v40382_v50 = vadd.s32 %v40379_v10, %v121574_v2 (stack40)
        %v39621_v31 = vadd.f32 %v39617_v9, %v39530_v27 (stack53)
        %v39951_v41 = vand.u32 2147483647, %v133968_v11 (stack77)
        %vm39978_vm8 = vcmp.lt.f32.partialorder %v134042_v24, 5.0 (stack68)
        %v41168_v26 = vor.u32 %v41167_v21, %v41166_v52 (stack47)
        %v40768_v60 = vxor.u32 %v40767_v34, %v40763_v30 (stack48)
        %v41615_v42 = vadd.s32 %v41611_v42, %v121569_v1 (stack40)
        %v41623_v6 = vadd.s32 %v41620_v61, %v121564_v0 (stack40)
        %v42052_v46 = vor.u32 %v42051_v40, %v42050_v43 (stack47)
        %v39625_v10 = vmul.f32 %v39621_v31, %v134001_v20 (stack54)
        %v134068_v44 = vadd.f32 -2.5, %v134042_v24 (stack53)
        %v40374_v23 = vadd.s32 %v40370_v23, %v121564_v0 (stack40)
        %v41164_v52 = vadd.s32 %v41160_v54, %v121564_v0 (stack40)
        %vm134072_vm9 = vcmp.eq.f32.partialorder %v39490_v25, 1.0 (stack68)
        %v134079_v22 = vsel /*vm=*/%vm39978_vm8, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v40026_v21 = vand.u32 2147483648, %v134042_v24 (stack72)
        %v40386_v61 = vadd.s32 5, %v40382_v50 (stack40)
        %v40771_v30 = vadd.s32 %v40768_v60, %v40763_v30 (stack40)
        %v39629_v34 = vadd.f32 %v39625_v10, %v39526_v8 (stack53)
        %v40773_v43 = vshll.u32 %v40768_v60, 29 (stack45)
        %v40774_v40 = vshrl.u32 %v40768_v60, 3 (stack46)
        %v41169_v54 = vxor.u32 %v41168_v26, %v41160_v54 (stack48)
        %v40388_v25 = vxor.u32 %v40386_v61, %v40374_v23 (stack48)
        %v41627_v9 = vadd.s32 1, %v41623_v6 (stack40)
        %v42053_v8 = vxor.u32 %v42052_v46, %v134036_v7 (stack48)
        %v134085_v27 = vadd.s32 %v157317_v29, %v157077_v51 (stack40)
        %v39633_v20 = vmul.f32 %v39629_v34, %v134001_v20 (stack54)
        %vm40023_vm10 = vcmp.eq.f32.partialorder %v134042_v24, inf (stack70)
        %v40775_v50 = vor.u32 %v40774_v40, %v40773_v43 (stack47)
        %v41172_v31 = vadd.s32 %v41169_v54, %v121574_v2 (stack40)
        %v134092_v26 = vadd.s32 %v157318_v32, %v157078_v48 (stack40)
        %vm40025_vm11 = vcmp.eq.f32.partialorder %v134042_v24, 0.0 (stack71)
        %v40389_v60 = vand.u32.u8 255, %v40388_v25 (stack49)
        %v41631_v42 = vadd.s32 %v41627_v9, %v41615_v42 (stack40)
        %v41633_v6 = vshll.u32 %v41627_v9, 17 (stack45)
        %v41634_v46 = vshrl.u32 %v41627_v9, 15 (stack46)
        %v39637_v12 = vadd.f32 %v39633_v20, %v39522_v12 (stack53)
        %v40776_v10 = vxor.u32 %v40775_v50, %v40771_v30 (stack48)
        %v41176_v23 = vadd.s32 2, %v41172_v31 (stack40)
        %v42056_v7 = vadd.s32 %v42053_v8, %v134036_v7 (stack40)
        %v40390_v61 = vand.u32 65535, %v40389_v60 (stack50)
        %v41635_v34 = vor.u32 %v41634_v46, %v41633_v6 (stack47)
        %v42058_v43 = vshll.u32 %v42053_v8, 15 (stack45)
        %v42059_v40 = vshrl.u32 %v42053_v8, 17 (stack46)
        %v39641_v55 = vmul.f32 %v39637_v12, %v133847_v55 (stack54)
        %v40779_v30 = vadd.s32 %v40776_v10, %v40771_v30 (stack40)
        %v40781_v54 = vshll.u32 %v40776_v10, 16 (stack45)
        %v40782_v25 = vshrl.u32 %v40776_v10, 16 (stack46)
        %v40391_v9 = vshrl.u32 %v40390_v61, 1 (stack51)
        %v41180_v52 = vadd.s32 %v41176_v23, %v41164_v52 (stack40)
        %v41182_v8 = vshll.u32 %v41176_v23, 13 (stack45)
        %v41183_v20 = vshrl.u32 %v41176_v23, 19 (stack46)
        %v120772_v50 = vpop.eup %120771 (stack73)
        %v39645_v56 = vsel /*vm=*/%vm134072_vm9, /*on_true_vy=*/%v134048_v56, /*on_false_vx=*/%v39641_v55 (stack44)
        %v40783_v53 = vor.u32 %v40782_v25, %v40781_v54 (stack47)
        %v41636_v31 = vxor.u32 %v41635_v34, %v41631_v42 (stack48)
        %v42060_v60 = vor.u32 %v42059_v40, %v42058_v43 (stack47)
        %v39649_v6 = vmul.f32 1.4140625, %v39645_v56 (stack54)
        %v40022_v46 = vmul.f32 %v120772_v50, %v134042_v24 (stack74)
        %v40392_v12 = vor.u32 16256, %v40391_v9 (stack47)
        %v41184_v10 = vor.u32 %v41183_v20, %v41182_v8 (stack47)
        %v40784_v23 = vxor.u32 %v40783_v53, %v40779_v30 (stack48)
        %v41639_v42 = vadd.s32 %v41636_v31, %v41631_v42 (stack40)
        %v41641_v61 = vshll.u32 %v41636_v31, 29 (stack45)
        %v41642_v34 = vshrl.u32 %v41636_v31, 3 (stack46)
        %v39652_v43 = vpack.c.bf16 %v156663_v45, %v39649_v6 (stack81)
        %v40024_v40 = vsel /*vm=*/%vm40023_vm10, /*on_true_vy=*/%v134042_v24, /*on_false_vx=*/%v40022_v46 (stack75)
        %v40393_v55 = vand.u32.u16 65535, %v40392_v12 (stack52)
        %v41185_v54 = vxor.u32 %v41184_v10, %v41180_v52 (stack48)
        %v40027_v21 = vsel /*vm=*/%vm40025_vm11, /*on_true_vy=*/%v40026_v21, /*on_false_vx=*/%v40024_v40 (stack76)
        %v40787_v30 = vadd.s32 %v40784_v23, %v40779_v30 (stack40)
        %v40793_v25 = vshll.u32 %v40784_v23, 24 (stack45)
        %v40794_v9 = vshrl.u32 %v40784_v23, 8 (stack46)
        %119955 = vst [vmem:[%s123356_s30 + $0x1a8] sm:$0xf] /*vst_source=*/%v39652_v43 (stack83)
        %v40030_v8 = vadd.f32 -3.0, %v40027_v21 (stack53)
        %v119958_v20 = vadd.low.f32.bf16 -1.0, %v40393_v55 (stack53)
        %v41188_v52 = vadd.s32 %v41185_v54, %v41180_v52 (stack40)
        %v41190_v50 = vshll.u32 %v41185_v54, 15 (stack45)
        %v40015_v56 = vsel /*vm=*/%vm39978_vm8, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v40795_v53 = vor.u32 %v40794_v9, %v40793_v25 (stack47)
        %v41191_v31 = vshrl.u32 %v41185_v54, 17 (stack46)
        %v41643_v6 = vor.u32 %v41642_v34, %v41641_v61 (stack47)
        %v134114_v44 = vsel /*vm=*/%vm39978_vm8, /*on_true_vy=*/%v134068_v44, /*on_false_vx=*/%v40030_v8 (stack44)
        %v40402_v46 = vmul.f32 2.0, %v119958_v20 (stack54)
        %v40791_v12 = vadd.s32 %v40787_v30, %v121569_v1 (stack40)
        %v42061_v60 = vxor.u32 %v42060_v60, %v42056_v7 (stack48)
        %v40038_v10 = vmul.f32 %v134114_v44, %v40015_v56 (stack54)
        %v40796_v23 = vxor.u32 %v40795_v53, %v40787_v30 (stack48)
        %v41192_v61 = vor.u32 %v41191_v31, %v41190_v50 (stack47)
        %v41644_v34 = vxor.u32 %v41643_v6, %v41639_v42 (stack48)
        %v40406_v43 = vadd.f32 -0.99609375, %v40402_v46 (stack53)
        %v42064_v7 = vadd.s32 %v42061_v60, %v42056_v7 (stack40)
        %v42066_v40 = vshll.u32 %v42061_v60, 26 (stack45)
        %v42067_v55 = vshrl.u32 %v42061_v60, 6 (stack46)
        %v40042_v22 = vadd.f32 %v40038_v10, %v134079_v22 (stack53)
        %v40799_v54 = vadd.s32 %v40796_v23, %v121564_v0 (stack40)
        %v41193_v21 = vxor.u32 %v41192_v61, %v41188_v52 (stack48)
        %v41647_v42 = vadd.s32 %v41644_v34, %v41639_v42 (stack40)
        %v134120_v30 = vmax.f32 %v40406_v43, -0.99609375 (stack55)
        %v41649_v25 = vshll.u32 %v41644_v34, 16 (stack45)
        %v41650_v9 = vshrl.u32 %v41644_v34, 16 (stack46)
        %v42068_v8 = vor.u32 %v42067_v55, %v42066_v40 (stack47)
        %v40046_v20 = vmul.f32 %v40042_v22, %v134114_v44 (stack54)
        %v40803_v50 = vadd.s32 4, %v40799_v54 (stack40)
        %v41196_v52 = vadd.s32 %v41193_v21, %v41188_v52 (stack40)
        %v41198_v56 = vshll.u32 %v41193_v21, 26 (stack45)
        %v134124_v53 = vmul.f32 inf, %v133968_v11 (stack54)
        %v40007_v31 = vsel /*vm=*/%vm39978_vm8, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v40422_v6 = vxor.u32 2147483648, %v134120_v30 (stack56)
        %v41199_v46 = vshrl.u32 %v41193_v21, 6 (stack46)
        %v40050_v60 = vadd.f32 %v40046_v20, %v40007_v31 (stack53)
        %v40807_v12 = vadd.s32 %v40803_v50, %v40791_v12 (stack40)
        %v40809_v10 = vshll.u32 %v40803_v50, 13 (stack45)
        %v40810_v23 = vshrl.u32 %v40803_v50, 19 (stack46)
        %v134133_v61 = vsel /*vm=*/%vm39978_vm8, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v134136_v34 = vmul.f32 %v40422_v6, %v134120_v30 (stack54)
        %v41200_v43 = vor.u32 %v41199_v46, %v41198_v56 (stack47)
        %v41651_v40 = vor.u32 %v41650_v9, %v41649_v25 (stack47)
        %v39991_v55 = vsel /*vm=*/%vm39978_vm8, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v40054_v22 = vmul.f32 %v40050_v60, %v134114_v44 (stack54)
        %v40811_v54 = vor.u32 %v40810_v23, %v40809_v10 (stack47)
        %v42069_v21 = vxor.u32 %v42068_v8, %v42064_v7 (stack48)
        %v40003_v25 = vsel /*vm=*/%vm39978_vm8, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v40427_v9 = vadd.f32 1.0, %v134136_v34 (stack57)
        %v41201_v8 = vxor.u32 %v41200_v43, %v41196_v52 (stack48)
        %v134148_v20 = vadd.s32 %v134085_v27, %v122657_v58 (stack40)
        %v40058_v50 = vadd.f32 %v40054_v22, %v40003_v25 (stack53)
        %v40812_v56 = vxor.u32 %v40811_v54, %v40807_v12 (stack48)
        %v41652_v31 = vxor.u32 %v41651_v40, %v41647_v42 (stack48)
        %v134150_v7 = vadd.s32 %v42069_v21, %v42064_v7 (stack40)
        %v39995_v6 = vsel /*vm=*/%vm39978_vm8, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %120773 = vlog2.f32 %v40427_v9 (stack58)
        %v40430_v46 = vmul.f32 -0.5, %v134136_v34 (stack59)
        %v41204_v52 = vadd.s32 %v41201_v8, %v41196_v52 (stack40)
        %v40062_v60 = vmul.f32 %v40058_v50, %v134114_v44 (stack54)
        %v40815_v12 = vadd.s32 %v40812_v56, %v40807_v12 (stack40)
        %v40817_v10 = vshll.u32 %v40812_v56, 15 (stack45)
        %v40818_v23 = vshrl.u32 %v40812_v56, 17 (stack46)
        %v39999_v43 = vsel /*vm=*/%vm39978_vm8, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v41210_v40 = vshll.u32 %v41201_v8, 6 (stack45)
        %v41211_v22 = vshrl.u32 %v41201_v8, 26 (stack46)
        %vm42470_vm12 = vcmp.lt.u32.totalorder %v134148_v20, %v134085_v27 (stack43)
        %v40066_v54 = vadd.f32 %v40062_v60, %v39999_v43 (stack53)
        %v40819_v25 = vor.u32 %v40818_v23, %v40817_v10 (stack47)
        %v41655_v42 = vadd.s32 %v41652_v31, %v41647_v42 (stack40)
        %v41661_v9 = vshll.u32 %v41652_v31, 24 (stack45)
        %v40433_v8 = vand.u32 2147483647, %v134136_v34 (stack60)
        %v41212_v50 = vor.u32 %v41211_v22, %v41210_v40 (stack47)
        %v41662_v56 = vshrl.u32 %v41652_v31, 8 (stack46)
        %v42078_v31 = vshll.u32 %v42069_v21, 6 (stack45)
        %v40070_v60 = vmul.f32 %v40066_v54, %v134114_v44 (stack54)
        %v40431_v46 = vadd.f32 1.0, %v40430_v46 (stack61)
        %v40820_v10 = vxor.u32 %v40819_v25, %v40815_v12 (stack48)
        %v42079_v21 = vshrl.u32 %v42069_v21, 26 (stack46)
        %v41213_v23 = vxor.u32 %v41212_v50, %v41204_v52 (stack48)
        %v41663_v43 = vor.u32 %v41662_v56, %v41661_v9 (stack47)
        %vm42475_vm13 = vcmp.lt.u32.totalorder %v134085_v27, %v157077_v51 (stack43)
        %v42484_v40 = vadd.s32 1, %v134092_v26 (stack40)
        %v40074_v6 = vadd.f32 %v40070_v60, %v39995_v6 (stack53)
        %v40823_v12 = vadd.s32 %v40820_v10, %v40815_v12 (stack40)
        %v40825_v22 = vshll.u32 %v40820_v10, 26 (stack45)
        %v40826_v54 = vshrl.u32 %v40820_v10, 6 (stack46)
        %v41216_v25 = vadd.s32 %v41213_v23, %v121569_v1 (stack40)
        %v41664_v9 = vxor.u32 %v41663_v43, %v41655_v42 (stack48)
        %v42080_v50 = vor.u32 %v42079_v21, %v42078_v31 (stack47)
        %v42488_v26 = vsel /*vm=*/%vm42475_vm13, /*on_true_vy=*/%v42484_v40, /*on_false_vx=*/%v134092_v26 (stack44)
        %v40078_v56 = vmul.f32 %v40074_v6, %v134114_v44 (stack54)
        %v40827_v31 = vor.u32 %v40826_v54, %v40825_v22 (stack47)
        %v41208_v52 = vadd.s32 %v41204_v52, %v121574_v2 (stack40)
        %v42492_v60 = vadd.s32 1, %v42488_v26 (stack40)
        %v41220_v10 = vadd.s32 3, %v41216_v25 (stack40)
        %v41667_v21 = vadd.s32 %v41664_v9, %v121574_v2 (stack40)
        %v42081_v23 = vxor.u32 %v42080_v50, %v134150_v7 (stack48)
        %v134175_v43 = vadd.s32 %v157317_v29, %v157079_v39 (stack40)
        %v40082_v55 = vadd.f32 %v40078_v56, %v39991_v55 (stack53)
        %v40828_v40 = vxor.u32 %v40827_v31, %v40823_v12 (stack48)
        %v41659_v42 = vadd.s32 %v41655_v42, %v121564_v0 (stack40)
        %v42496_v27 = vsel /*vm=*/%vm42470_vm12, /*on_true_vy=*/%v42492_v60, /*on_false_vx=*/%v42488_v26 (stack44)
        %v41224_v6 = vadd.s32 %v41220_v10, %v41208_v52 (stack40)
        %v41226_v22 = vshll.u32 %v41220_v10, 17 (stack45)
        %v41227_v54 = vshrl.u32 %v41220_v10, 15 (stack46)
        %v41671_v25 = vadd.s32 2, %v41667_v21 (stack40)
        %v120774_v9 = vpop.eup %120773 (stack64)
        %v40086_v50 = vmul.f32 %v40082_v55, %v134114_v44 (stack54)
        %v40831_v12 = vadd.s32 %v40828_v40, %v40823_v12 (stack40)
        %v40837_v26 = vshll.u32 %v40828_v40, 6 (stack45)
        %v40838_v56 = vshrl.u32 %v40828_v40, 26 (stack46)
        %vm134184_vm14 = vcmp.eq.f32.partialorder %v39951_v41, 1.0 (stack68)
        %v40429_v31 = vmul.f32 0.6931472, %v120774_v9 (stack65)
        %v40432_v34 = vmul.f32 %v40431_v46, %v134136_v34 (stack63)
        %v41228_v46 = vor.u32 %v41227_v54, %v41226_v22 (stack47)
        %v41675_v52 = vadd.s32 %v41671_v25, %v41659_v42 (stack40)
        %v40090_v61 = vadd.f32 %v40086_v50, %v134133_v61 (stack53)
        %vm40434_vm15 = vcmp.lt.f32.partialorder %v40433_v8, 0.0004427343 (stack62)
        %v40839_v8 = vor.u32 %v40838_v56, %v40837_v26 (stack47)
        %v134192_v20 = vadd.s32 %v134148_v20, %v121569_v1 (stack40)
        %v40435_v60 = vsel /*vm=*/%vm40434_vm15, /*on_true_vy=*/%v40432_v34, /*on_false_vx=*/%v40429_v31 (stack66)
        %v41229_v10 = vxor.u32 %v41228_v46, %v41224_v6 (stack48)
        %v41677_v21 = vshll.u32 %v41671_v25, 13 (stack45)
        %v41678_v55 = vshrl.u32 %v41671_v25, 19 (stack46)
        %v40094_v44 = vmul.f32 %v40090_v61, %v134114_v44 (stack54)
        %v134195_v40 = vxor.u32 2147483648, %v40435_v60 (stack56)
        %v40840_v42 = vxor.u32 %v40839_v8, %v40831_v12 (stack48)
        %v42084_v23 = vadd.s32 %v42081_v23, %v121564_v0 (stack40)
        %v39983_v24 = vsel /*vm=*/%vm39978_vm8, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v41232_v6 = vadd.s32 %v41229_v10, %v41224_v6 (stack40)
        %v41234_v22 = vshll.u32 %v41229_v10, 29 (stack45)
        %v41235_v54 = vshrl.u32 %v41229_v10, 3 (stack46)
        %v40098_v25 = vadd.f32 %v40094_v44, %v39983_v24 (stack53)
        %v40412_v9 = vand.u32 2147483647, %v134120_v30 (stack77)
        %vm40439_vm0 = vcmp.lt.f32.partialorder %v134195_v40, 5.0 (stack68)
        %120775 = vrsqrt.f32 %v134195_v40 (stack67)
        %v40843_v50 = vadd.s32 %v40840_v42, %v121574_v2 (stack40)
        %v41679_v26 = vor.u32 %v41678_v55, %v41677_v21 (stack47)
        %v42076_v7 = vadd.s32 %v134150_v7, %v121569_v1 (stack40)
        %v42511_v56 = vshll.u32 %v134192_v20, 13 (stack45)
        %v40102_v11 = vmul.f32 %v40098_v25, %v133968_v11 (stack54)
        %v40835_v12 = vadd.s32 %v40831_v12, %v121564_v0 (stack40)
        %v42088_v31 = vadd.s32 1, %v42084_v23 (stack40)
        %v42501_v27 = vadd.s32 %v42496_v27, %v121574_v2 (stack40)
        %v134214_v34 = vsel /*vm=*/%vm40439_vm0, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v134219_v46 = vsel /*vm=*/%vm40439_vm0, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v134222_v61 = vadd.f32 -2.5, %v134195_v40 (stack53)
        %v41236_v8 = vor.u32 %v41235_v54, %v41234_v22 (stack47)
        %v40106_v53 = vsel /*vm=*/%vm134184_vm14, /*on_true_vy=*/%v134124_v53, /*on_false_vx=*/%v40102_v11 (stack44)
        %v134230_v41 = vsel /*vm=*/%vm40439_vm0, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v134235_v60 = vsel /*vm=*/%vm40439_vm0, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v134240_v10 = vsel /*vm=*/%vm40439_vm0, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v40110_v21 = vmul.f32 1.4140625, %v40106_v53 (stack54)
        %v40847_v55 = vadd.s32 5, %v40843_v50 (stack40)
        %v41237_v44 = vxor.u32 %v41236_v8, %v41232_v6 (stack48)
        %v41680_v42 = vxor.u32 %v41679_v26, %v41675_v52 (stack48)
        %v42092_v23 = vadd.s32 %v42088_v31, %v42076_v7 (stack40)
        %v42094_v24 = vshll.u32 %v42088_v31, 17 (stack45)
        %v42095_v22 = vshrl.u32 %v42088_v31, 15 (stack46)
        %v42509_v54 = vadd.s32 %v134192_v20, %v42501_v27 (stack40)
        %v40113_v25 = vpack.c.bf16 %v156663_v45, %v40110_v21 (stack81)
        %vm40484_vm1 = vcmp.eq.f32.partialorder %v134195_v40, inf (stack70)
        %v40849_v50 = vxor.u32 %v40847_v55, %v40835_v12 (stack48)
        %v41240_v6 = vadd.s32 %v41237_v44, %v41232_v6 (stack40)
        %v41242_v26 = vshll.u32 %v41237_v44, 16 (stack45)
        %v41243_v7 = vshrl.u32 %v41237_v44, 16 (stack46)
        %v41683_v52 = vadd.s32 %v41680_v42, %v41675_v52 (stack40)
        %v41685_v11 = vshll.u32 %v41680_v42, 15 (stack45)
        %v41686_v12 = vshrl.u32 %v41680_v42, 17 (stack46)
        %119957 = vst [vmem:[%s123356_s30 + $0x228] sm:$0xf] /*vst_source=*/%v40113_v25 (stack83)
        %vm40486_vm2 = vcmp.eq.f32.partialorder %v134195_v40, 0.0 (stack71)
        %v40850_v31 = vand.u32.u8 255, %v40849_v50 (stack49)
        %v42096_v27 = vor.u32 %v42095_v22, %v42094_v24 (stack47)
        %v42512_v20 = vshrl.u32 %v134192_v20, 19 (stack46)
        %v41244_v8 = vor.u32 %v41243_v7, %v41242_v26 (stack47)
        %v41687_v53 = vor.u32 %v41686_v12, %v41685_v11 (stack47)
        %vm42936_vm3 = vcmp.lt.u32.totalorder %v134175_v43, %v157079_v39 (stack43)
        %v42941_v21 = vadd.s32 %v157318_v32, %v157082_v49 (stack40)
        %v40487_v55 = vand.u32 2147483648, %v134195_v40 (stack72)
        %v40851_v44 = vand.u32 65535, %v40850_v31 (stack50)
        %v42097_v42 = vxor.u32 %v42096_v27, %v42092_v23 (stack48)
        %v134255_v24 = vadd.s32 %v134175_v43, %v122657_v58 (stack40)
        %v41245_v22 = vxor.u32 %v41244_v8, %v41240_v6 (stack48)
        %v41688_v25 = vxor.u32 %v41687_v53, %v41683_v52 (stack48)
        %v42513_v56 = vor.u32 %v42512_v20, %v42511_v56 (stack47)
        %v42945_v50 = vadd.s32 1, %v42941_v21 (stack40)
        %v120776_v26 = vpop.eup %120775 (stack73)
        %v40852_v7 = vshrl.u32 %v40851_v44, 1 (stack51)
        %v42100_v23 = vadd.s32 %v42097_v42, %v42092_v23 (stack40)
        %v42102_v11 = vshll.u32 %v42097_v42, 29 (stack45)
        %v42103_v12 = vshrl.u32 %v42097_v42, 3 (stack46)
        %v40483_v31 = vmul.f32 %v120776_v26, %v134195_v40 (stack74)
        %v41248_v6 = vadd.s32 %v41245_v22, %v41240_v6 (stack40)
        %v41254_v27 = vshll.u32 %v41245_v22, 24 (stack45)
        %v41255_v20 = vshrl.u32 %v41245_v22, 8 (stack46)
        %v40853_v8 = vor.u32 16256, %v40852_v7 (stack47)
        %v41691_v52 = vadd.s32 %v41688_v25, %v41683_v52 (stack40)
        %v41693_v53 = vshll.u32 %v41688_v25, 26 (stack45)
        %v41694_v44 = vshrl.u32 %v41688_v25, 6 (stack46)
        %v40485_v42 = vsel /*vm=*/%vm40484_vm1, /*on_true_vy=*/%v134195_v40, /*on_false_vx=*/%v40483_v31 (stack75)
        %v41252_v22 = vadd.s32 %v41248_v6, %v121569_v1 (stack40)
        %v41256_v25 = vor.u32 %v41255_v20, %v41254_v27 (stack47)
        %v42104_v26 = vor.u32 %v42103_v12, %v42102_v11 (stack47)
        %v40488_v55 = vsel /*vm=*/%vm40486_vm2, /*on_true_vy=*/%v40487_v55, /*on_false_vx=*/%v40485_v42 (stack76)
        %v40854_v7 = vand.u32.u16 65535, %v40853_v8 (stack52)
        %v41695_v11 = vor.u32 %v41694_v44, %v41693_v53 (stack47)
        %v42514_v56 = vxor.u32 %v42513_v56, %v42509_v54 (stack48)
        %v40491_v12 = vadd.f32 -3.0, %v40488_v55 (stack53)
        %v41257_v31 = vxor.u32 %v41256_v25, %v41248_v6 (stack48)
        %v42105_v6 = vxor.u32 %v42104_v26, %v42100_v23 (stack48)
        %v42949_v21 = vsel /*vm=*/%vm42936_vm3, /*on_true_vy=*/%v42945_v50, /*on_false_vx=*/%v42941_v21 (stack44)
        %v119960_v50 = vadd.low.f32.bf16 -1.0, %v40854_v7 (stack53)
        %v41696_v27 = vxor.u32 %v41695_v11, %v41691_v52 (stack48)
        %v134267_v54 = vadd.s32 %v42514_v56, %v42509_v54 (stack40)
        %v42519_v20 = vshll.u32 %v42514_v56, 15 (stack45)
        %v134272_v61 = vsel /*vm=*/%vm40439_vm0, /*on_true_vy=*/%v134222_v61, /*on_false_vx=*/%v40491_v12 (stack44)
        %v41260_v8 = vadd.s32 %v41257_v31, %v121564_v0 (stack40)
        %v42108_v23 = vadd.s32 %v42105_v6, %v42100_v23 (stack40)
        %v42110_v53 = vshll.u32 %v42105_v6, 16 (stack45)
        %v40499_v10 = vmul.f32 %v134272_v61, %v134240_v10 (stack54)
        %v40863_v44 = vmul.f32 2.0, %v119960_v50 (stack54)
        %v41699_v52 = vadd.s32 %v41696_v27, %v41691_v52 (stack40)
        %v41705_v42 = vshll.u32 %v41696_v27, 6 (stack45)
        %v41264_v25 = vadd.s32 4, %v41260_v8 (stack40)
        %v41706_v26 = vshrl.u32 %v41696_v27, 26 (stack46)
        %v42111_v55 = vshrl.u32 %v42105_v6, 16 (stack46)
        %v42520_v7 = vshrl.u32 %v42514_v56, 17 (stack46)
        %v40503_v60 = vadd.f32 %v40499_v10, %v134235_v60 (stack53)
        %v40867_v11 = vadd.f32 -0.99609375, %v40863_v44 (stack53)
        %vm42931_vm4 = vcmp.lt.u32.totalorder %v134255_v24, %v134175_v43 (stack43)
        %v42953_v43 = vadd.s32 1, %v42949_v21 (stack40)
        %v41268_v22 = vadd.s32 %v41264_v25, %v41252_v22 (stack40)
        %v41270_v56 = vshll.u32 %v41264_v25, 13 (stack45)
        %v41271_v12 = vshrl.u32 %v41264_v25, 19 (stack46)
        %v41707_v31 = vor.u32 %v41706_v26, %v41705_v42 (stack47)
        %v40507_v6 = vmul.f32 %v40503_v60, %v134272_v61 (stack54)
        %v134281_v50 = vmax.f32 %v40867_v11, -0.99609375 (stack55)
        %v42112_v27 = vor.u32 %v42111_v55, %v42110_v53 (stack47)
        %v42521_v20 = vor.u32 %v42520_v7, %v42519_v20 (stack47)
        %v40468_v8 = vsel /*vm=*/%vm40439_vm0, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v41272_v53 = vor.u32 %v41271_v12, %v41270_v56 (stack47)
        %v41708_v10 = vxor.u32 %v41707_v31, %v41699_v52 (stack48)
        %v42957_v21 = vsel /*vm=*/%vm42931_vm4, /*on_true_vy=*/%v42953_v43, /*on_false_vx=*/%v42949_v21 (stack44)
        %v40456_v44 = vsel /*vm=*/%vm40439_vm0, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v40511_v42 = vadd.f32 %v40507_v6, %v40468_v8 (stack53)
        %v40883_v25 = vxor.u32 2147483648, %v134281_v50 (stack56)
        %v134292_v24 = vadd.s32 %v134255_v24, %v121569_v1 (stack40)
        %v41273_v26 = vxor.u32 %v41272_v53, %v41268_v22 (stack48)
        %v41711_v55 = vadd.s32 %v41708_v10, %v121569_v1 (stack40)
        %v42113_v7 = vxor.u32 %v42112_v27, %v42108_v23 (stack48)
        %v42522_v60 = vxor.u32 %v42521_v20, %v134267_v54 (stack48)
        %v40464_v11 = vsel /*vm=*/%vm40439_vm0, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v40515_v43 = vmul.f32 %v40511_v42, %v134272_v61 (stack54)
        %v134301_v56 = vmul.f32 %v40883_v25, %v134281_v50 (stack54)
        %v41703_v52 = vadd.s32 %v41699_v52, %v121574_v2 (stack40)
        %v41276_v22 = vadd.s32 %v41273_v26, %v41268_v22 (stack40)
        %v41278_v12 = vshll.u32 %v41273_v26, 15 (stack45)
        %v41279_v31 = vshrl.u32 %v41273_v26, 17 (stack46)
        %v41715_v6 = vadd.s32 3, %v41711_v55 (stack40)
        %v40460_v40 = vsel /*vm=*/%vm40439_vm0, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v40519_v27 = vadd.f32 %v40515_v43, %v40464_v11 (stack53)
        %v40888_v20 = vadd.f32 1.0, %v134301_v56 (stack57)
        %v42972_v8 = vshll.u32 %v134292_v24, 13 (stack45)
        %v41280_v53 = vor.u32 %v41279_v31, %v41278_v12 (stack47)
        %v41719_v10 = vadd.s32 %v41715_v6, %v41703_v52 (stack40)
        %v41721_v42 = vshll.u32 %v41715_v6, 17 (stack45)
        %v41722_v25 = vshrl.u32 %v41715_v6, 15 (stack46)
        %v40523_v26 = vmul.f32 %v40519_v27, %v134272_v61 (stack54)
        %120777 = vlog2.f32 %v40888_v20 (stack58)
        %v40891_v55 = vmul.f32 -0.5, %v134301_v56 (stack59)
        %v42962_v21 = vadd.s32 %v42957_v21, %v121574_v2 (stack40)
        %v41281_v11 = vxor.u32 %v41280_v53, %v41276_v22 (stack48)
        %v41723_v43 = vor.u32 %v41722_v25, %v41721_v42 (stack47)
        %v42116_v23 = vadd.s32 %v42113_v7, %v42108_v23 (stack40)
        %v42122_v52 = vshll.u32 %v42113_v7, 24 (stack45)
        %v40527_v12 = vadd.f32 %v40523_v26, %v40460_v40 (stack53)
        %v40894_v31 = vand.u32 2147483647, %v134301_v56 (stack60)
        %v42123_v7 = vshrl.u32 %v42113_v7, 8 (stack46)
        %v42525_v54 = vadd.s32 %v42522_v60, %v134267_v54 (stack40)
        %v41284_v22 = vadd.s32 %v41281_v11, %v41276_v22 (stack40)
        %v41286_v6 = vshll.u32 %v41281_v11, 26 (stack45)
        %v41287_v40 = vshrl.u32 %v41281_v11, 6 (stack46)
        %v41724_v27 = vxor.u32 %v41723_v43, %v41719_v10 (stack48)
        %v40531_v20 = vmul.f32 %v40527_v12, %v134272_v61 (stack54)
        %v40892_v53 = vadd.f32 1.0, %v40891_v55 (stack61)
        %v42124_v42 = vor.u32 %v42123_v7, %v42122_v52 (stack47)
        %v42527_v25 = vshll.u32 %v42522_v60, 26 (stack45)
        %v41288_v26 = vor.u32 %v41287_v40, %v41286_v6 (stack47)
        %v41727_v10 = vadd.s32 %v41724_v27, %v41719_v10 (stack40)
        %v41729_v55 = vshll.u32 %v41724_v27, 29 (stack45)
        %v41730_v11 = vshrl.u32 %v41724_v27, 3 (stack46)
        %v40535_v44 = vadd.f32 %v40531_v20, %v40456_v44 (stack53)
        %v42125_v43 = vxor.u32 %v42124_v42, %v42116_v23 (stack48)
        %v42528_v60 = vshrl.u32 %v42522_v60, 6 (stack46)
        %v42970_v21 = vadd.s32 %v134292_v24, %v42962_v21 (stack40)
        %v41289_v52 = vxor.u32 %v41288_v26, %v41284_v22 (stack48)
        %v41731_v12 = vor.u32 %v41730_v11, %v41729_v55 (stack47)
        %v42973_v24 = vshrl.u32 %v134292_v24, 19 (stack46)
        %v134319_v7 = vadd.s32 %v157317_v29, %v157083_v59 (stack40)
        %v40539_v6 = vmul.f32 %v40535_v44, %v134272_v61 (stack54)
        %v42128_v40 = vadd.s32 %v42125_v43, %v121574_v2 (stack40)
        %v42529_v27 = vor.u32 %v42528_v60, %v42527_v25 (stack47)
        %v134325_v20 = vadd.s32 %v157318_v32, %v157084_v16 (stack40)
        %v41292_v22 = vadd.s32 %v41289_v52, %v41284_v22 (stack40)
        %v41298_v42 = vshll.u32 %v41289_v52, 6 (stack45)
        %v41299_v25 = vshrl.u32 %v41289_v52, 26 (stack46)
        %v41732_v26 = vxor.u32 %v41731_v12, %v41727_v10 (stack48)
        %v40543_v41 = vadd.f32 %v40539_v6, %v134230_v41 (stack53)
        %v42120_v23 = vadd.s32 %v42116_v23, %v121564_v0 (stack40)
        %v42132_v55 = vadd.s32 2, %v42128_v40 (stack40)
        %v42530_v11 = vxor.u32 %v42529_v27, %v42525_v54 (stack48)
        %v41300_v44 = vor.u32 %v41299_v25, %v41298_v42 (stack47)
        %v41735_v10 = vadd.s32 %v41732_v26, %v41727_v10 (stack40)
        %v41737_v43 = vshll.u32 %v41732_v26, 16 (stack45)
        %v42974_v8 = vor.u32 %v42973_v24, %v42972_v8 (stack47)
        %v40547_v60 = vmul.f32 %v40543_v41, %v134272_v61 (stack54)
        %v41738_v52 = vshrl.u32 %v41732_v26, 16 (stack46)
        %v42136_v12 = vadd.s32 %v42132_v55, %v42120_v23 (stack40)
        %v42138_v24 = vshll.u32 %v42132_v55, 13 (stack45)
        %v120778_v6 = vpop.eup %120777 (stack64)
        %vm134330_vm5 = vcmp.lt.f32.partialorder %v40894_v31, 0.0004427343 (stack62)
        %v41301_v40 = vxor.u32 %v41300_v44, %v41292_v22 (stack48)
        %v42139_v27 = vshrl.u32 %v42132_v55, 19 (stack46)
        %v42533_v54 = vadd.s32 %v42530_v11, %v42525_v54 (stack40)
        %v40551_v46 = vadd.f32 %v40547_v60, %v134219_v46 (stack53)
        %v40890_v42 = vmul.f32 0.6931472, %v120778_v6 (stack65)
        %v40893_v56 = vmul.f32 %v40892_v53, %v134301_v56 (stack63)
        %v41739_v53 = vor.u32 %v41738_v52, %v41737_v43 (stack47)
        %v41304_v25 = vadd.s32 %v41301_v40, %v121574_v2 (stack40)
        %v42140_v26 = vor.u32 %v42139_v27, %v42138_v24 (stack47)
        %v42539_v41 = vshll.u32 %v42530_v11, 6 (stack45)
        %v42975_v23 = vxor.u32 %v42974_v8, %v42970_v21 (stack48)
        %v40555_v61 = vmul.f32 %v40551_v46, %v134272_v61 (stack54)
        %v40896_v55 = vsel /*vm=*/%vm134330_vm5, /*on_true_vy=*/%v40893_v56, /*on_false_vx=*/%v40890_v42 (stack66)
        %v41740_v44 = vxor.u32 %v41739_v53, %v41735_v10 (stack48)
        %v42540_v11 = vshrl.u32 %v42530_v11, 26 (stack46)
        %v134340_v43 = vxor.u32 2147483648, %v40896_v55 (stack56)
        %v41308_v8 = vadd.s32 5, %v41304_v25 (stack40)
        %v42141_v60 = vxor.u32 %v42140_v26, %v42136_v12 (stack48)
        %v134342_v21 = vadd.s32 %v42975_v23, %v42970_v21 (stack40)
        %v40559_v34 = vadd.f32 %v40555_v61, %v134214_v34 (stack53)
        %v41743_v10 = vadd.s32 %v41740_v44, %v41735_v10 (stack40)
        %vm40900_vm6 = vcmp.lt.f32.partialorder %v134340_v43, 5.0 (stack68)
        %120779 = vrsqrt.f32 %v134340_v43 (stack67)
        %v41296_v22 = vadd.s32 %v41292_v22, %v121564_v0 (stack40)
        %v40420_v52 = vmul.f32 inf, %v134120_v30 (stack54)
        %v40563_v24 = vmul.f32 %v40559_v34, %v134120_v30 (stack54)
        %v41749_v6 = vshll.u32 %v41740_v44, 24 (stack45)
        %v41750_v31 = vshrl.u32 %v41740_v44, 8 (stack46)
        %vm40415_vm7 = vcmp.eq.f32.partialorder %v40412_v9, 1.0 (stack68)
        %v41310_v30 = vxor.u32 %v41308_v8, %v41296_v22 (stack48)
        %v42541_v9 = vor.u32 %v42540_v11, %v42539_v41 (stack47)
        %v40567_v40 = vsel /*vm=*/%vm40415_vm7, /*on_true_vy=*/%v40420_v52, /*on_false_vx=*/%v40563_v24 (stack44)
        %v134355_v27 = vsel /*vm=*/%vm40900_vm6, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v134358_v46 = vadd.f32 -2.5, %v134340_v43 (stack53)
        %v42537_v42 = vadd.s32 %v42533_v54, %v121569_v1 (stack40)
        %v40571_v56 = vmul.f32 1.4140625, %v40567_v40 (stack54)
        %v134364_v53 = vsel /*vm=*/%vm40900_vm6, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v134369_v25 = vsel /*vm=*/%vm40900_vm6, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v41311_v26 = vand.u32.u8 255, %v41310_v30 (stack49)
        %v134374_v41 = vsel /*vm=*/%vm40900_vm6, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v41751_v61 = vor.u32 %v41750_v31, %v41749_v6 (stack47)
        %v42144_v12 = vadd.s32 %v42141_v60, %v42136_v12 (stack40)
        %v42146_v55 = vshll.u32 %v42141_v60, 15 (stack45)
        %v40574_v44 = vpack.c.bf16 %v156663_v45, %v40571_v56 (stack81)
        %v41312_v11 = vand.u32 65535, %v41311_v26 (stack50)
        %v42147_v8 = vshrl.u32 %v42141_v60, 17 (stack46)
        %v42542_v54 = vxor.u32 %v42541_v9, %v42533_v54 (stack48)
        %v40937_v60 = vsel /*vm=*/%vm40900_vm6, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %vm40945_vm8 = vcmp.eq.f32.partialorder %v134340_v43, inf (stack70)
        %v41752_v34 = vxor.u32 %v41751_v61, %v41743_v10 (stack48)
        %v42980_v22 = vshll.u32 %v42975_v23, 15 (stack45)
        %v42981_v23 = vshrl.u32 %v42975_v23, 17 (stack46)
        %119959 = vst [vmem:[%s123356_s30 + $0x2a8] sm:$0xf] /*vst_source=*/%v40574_v44 (stack83)
        %v41313_v52 = vshrl.u32 %v41312_v11, 1 (stack51)
        %v42148_v24 = vor.u32 %v42147_v8, %v42146_v55 (stack47)
        %v42545_v6 = vadd.s32 %v42542_v54, %v121564_v0 (stack40)
        %vm43397_vm9 = vcmp.lt.u32.totalorder %v134319_v7, %v157083_v59 (stack43)
        %vm40947_vm10 = vcmp.eq.f32.partialorder %v134340_v43, 0.0 (stack71)
        %v41755_v31 = vadd.s32 %v41752_v34, %v121564_v0 (stack40)
        %v42982_v30 = vor.u32 %v42981_v23, %v42980_v22 (stack47)
        %v43406_v9 = vadd.s32 1, %v134325_v20 (stack40)
        %v41314_v40 = vor.u32 16256, %v41313_v52 (stack47)
        %v41747_v10 = vadd.s32 %v41743_v10, %v121569_v1 (stack40)
        %v42149_v56 = vxor.u32 %v42148_v24, %v42144_v12 (stack48)
        %v42549_v26 = vadd.s32 1, %v42545_v6 (stack40)
        %v41759_v61 = vadd.s32 4, %v41755_v31 (stack40)
        %v42983_v55 = vxor.u32 %v42982_v30, %v134342_v21 (stack48)
        %v134391_v20 = vsel /*vm=*/%vm43397_vm9, /*on_true_vy=*/%v43406_v9, /*on_false_vx=*/%v134325_v20 (stack44)
        %v134395_v44 = vadd.s32 %v157317_v29, %v157089_v17 (stack40)
        %v41315_v11 = vand.u32.u16 65535, %v41314_v40 (stack52)
        %v42152_v12 = vadd.s32 %v42149_v56, %v42144_v12 (stack40)
        %v42154_v8 = vshll.u32 %v42149_v56, 26 (stack45)
        %v42155_v54 = vshrl.u32 %v42149_v56, 6 (stack46)
        %v120780_v34 = vpop.eup %120779 (stack73)
        %v41763_v22 = vadd.s32 %v41759_v61, %v41747_v10 (stack40)
        %v41765_v23 = vshll.u32 %v41759_v61, 13 (stack45)
        %v41766_v52 = vshrl.u32 %v41759_v61, 19 (stack46)
        %v42553_v42 = vadd.s32 %v42549_v26, %v42537_v42 (stack40)
        %v40944_v24 = vmul.f32 %v120780_v34, %v134340_v43 (stack74)
        %v119962_v6 = vadd.low.f32.bf16 -1.0, %v41315_v11 (stack53)
        %v42156_v31 = vor.u32 %v42155_v54, %v42154_v8 (stack47)
        %v42555_v30 = vshll.u32 %v42549_v26, 17 (stack45)
        %v40948_v9 = vand.u32 2147483648, %v134340_v43 (stack72)
        %v41767_v40 = vor.u32 %v41766_v52, %v41765_v23 (stack47)
        %v42556_v10 = vshrl.u32 %v42549_v26, 15 (stack46)
        %v42986_v21 = vadd.s32 %v42983_v55, %v134342_v21 (stack40)
        %v40946_v56 = vsel /*vm=*/%vm40945_vm8, /*on_true_vy=*/%v134340_v43, /*on_false_vx=*/%v40944_v24 (stack75)
        %v41324_v26 = vmul.f32 2.0, %v119962_v6 (stack54)
        %v42157_v61 = vxor.u32 %v42156_v31, %v42152_v12 (stack48)
        %v42988_v11 = vshll.u32 %v42983_v55, 26 (stack45)
        %v40949_v8 = vsel /*vm=*/%vm40947_vm10, /*on_true_vy=*/%v40948_v9, /*on_false_vx=*/%v40946_v56 (stack76)
        %v41768_v54 = vxor.u32 %v41767_v40, %v41763_v22 (stack48)
        %v42557_v34 = vor.u32 %v42556_v10, %v42555_v30 (stack47)
        %v42989_v55 = vshrl.u32 %v42983_v55, 6 (stack46)
        %v40952_v23 = vadd.f32 -3.0, %v40949_v8 (stack53)
        %v41328_v52 = vadd.f32 -0.99609375, %v41324_v26 (stack53)
        %v42160_v12 = vadd.s32 %v42157_v61, %v42152_v12 (stack40)
        %v42166_v24 = vshll.u32 %v42157_v61, 6 (stack45)
        %v41771_v22 = vadd.s32 %v41768_v54, %v41763_v22 (stack40)
        %v41773_v6 = vshll.u32 %v41768_v54, 15 (stack45)
        %v41774_v31 = vshrl.u32 %v41768_v54, 17 (stack46)
        %v42167_v30 = vshrl.u32 %v42157_v61, 26 (stack46)
        %v134408_v46 = vsel /*vm=*/%vm40900_vm6, /*on_true_vy=*/%v134358_v46, /*on_false_vx=*/%v40952_v23 (stack44)
        %v134410_v9 = vmax.f32 %v41328_v52, -0.99609375 (stack55)
        %v42558_v40 = vxor.u32 %v42557_v34, %v42553_v42 (stack48)
        %v43388_v10 = vadd.s32 %v134319_v7, %v122657_v58 (stack40)
        %v40960_v60 = vmul.f32 %v134408_v46, %v40937_v60 (stack54)
        %v41775_v56 = vor.u32 %v41774_v31, %v41773_v6 (stack47)
        %v42168_v26 = vor.u32 %v42167_v30, %v42166_v24 (stack47)
        %v42990_v61 = vor.u32 %v42989_v55, %v42988_v11 (stack47)
        %v40929_v11 = vsel /*vm=*/%vm40900_vm6, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v40933_v8 = vsel /*vm=*/%vm40900_vm6, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v41344_v54 = vxor.u32 2147483648, %v134410_v9 (stack56)
        %v42561_v42 = vadd.s32 %v42558_v40, %v42553_v42 (stack40)
        %v40964_v34 = vadd.f32 %v40960_v60, %v40933_v8 (stack53)
        %v41776_v55 = vxor.u32 %v41775_v56, %v41771_v22 (stack48)
        %v42169_v23 = vxor.u32 %v42168_v26, %v42160_v12 (stack48)
        %v42563_v52 = vshll.u32 %v42558_v40, 29 (stack45)
        %v134423_v24 = vmul.f32 %v41344_v54, %v134410_v9 (stack54)
        %v42564_v6 = vshrl.u32 %v42558_v40, 3 (stack46)
        %v42991_v31 = vxor.u32 %v42990_v61, %v42986_v21 (stack48)
        %vm43392_vm11 = vcmp.lt.u32.totalorder %v43388_v10, %v134319_v7 (stack43)
        %v40968_v30 = vmul.f32 %v40964_v34, %v134408_v46 (stack54)
        %v41779_v22 = vadd.s32 %v41776_v55, %v41771_v22 (stack40)
        %v41781_v40 = vshll.u32 %v41776_v55, 26 (stack45)
        %v41782_v60 = vshrl.u32 %v41776_v55, 6 (stack46)
        %v41349_v56 = vadd.f32 1.0, %v134423_v24 (stack57)
        %v41352_v26 = vmul.f32 -0.5, %v134423_v24 (stack59)
        %v42172_v61 = vadd.s32 %v42169_v23, %v121569_v1 (stack40)
        %v43427_v8 = vadd.s32 %v43388_v10, %v121569_v1 (stack40)
        %v40972_v11 = vadd.f32 %v40968_v30, %v40929_v11 (stack53)
        %v41783_v54 = vor.u32 %v41782_v60, %v41781_v40 (stack47)
        %v42565_v34 = vor.u32 %v42564_v6, %v42563_v52 (stack47)
        %v134431_v21 = vadd.s32 %v42991_v31, %v42986_v21 (stack40)
        %120781 = vlog2.f32 %v41349_v56 (stack58)
        %v42164_v12 = vadd.s32 %v42160_v12, %v121574_v2 (stack40)
        %v42176_v55 = vadd.s32 3, %v42172_v61 (stack40)
        %v43414_v23 = vadd.s32 1, %v134391_v20 (stack40)
        %v40976_v52 = vmul.f32 %v40972_v11, %v134408_v46 (stack54)
        %v41355_v6 = vand.u32 2147483647, %v134423_v24 (stack60)
        %v41784_v30 = vxor.u32 %v41783_v54, %v41779_v22 (stack48)
        %v42566_v40 = vxor.u32 %v42565_v34, %v42561_v42 (stack48)
        %v41353_v60 = vadd.f32 1.0, %v41352_v26 (stack61)
        %v42180_v56 = vadd.s32 %v42176_v55, %v42164_v12 (stack40)
        %v42182_v26 = vshll.u32 %v42176_v55, 17 (stack45)
        %v42183_v61 = vshrl.u32 %v42176_v55, 15 (stack46)
        %v40980_v41 = vadd.f32 %v40976_v52, %v134374_v41 (stack53)
        %v41787_v22 = vadd.s32 %v41784_v30, %v41779_v22 (stack40)
        %v41793_v11 = vshll.u32 %v41784_v30, 6 (stack45)
        %v41794_v54 = vshrl.u32 %v41784_v30, 26 (stack46)
        %v42184_v34 = vor.u32 %v42183_v61, %v42182_v26 (stack47)
        %v42569_v42 = vadd.s32 %v42566_v40, %v42561_v42 (stack40)
        %v42571_v12 = vshll.u32 %v42566_v40, 16 (stack45)
        %v42572_v55 = vshrl.u32 %v42566_v40, 16 (stack46)
        %v40984_v52 = vmul.f32 %v40980_v41, %v134408_v46 (stack54)
        %v41791_v30 = vadd.s32 %v41787_v22, %v121564_v0 (stack40)
        %v41795_v40 = vor.u32 %v41794_v54, %v41793_v11 (stack47)
        %v43000_v26 = vshll.u32 %v42991_v31, 6 (stack45)
        %v42185_v61 = vxor.u32 %v42184_v34, %v42180_v56 (stack48)
        %v42573_v41 = vor.u32 %v42572_v55, %v42571_v12 (stack47)
        %v43001_v31 = vshrl.u32 %v42991_v31, 26 (stack46)
        %v43418_v7 = vsel /*vm=*/%vm43392_vm11, /*on_true_vy=*/%v43414_v23, /*on_false_vx=*/%v134391_v20 (stack44)
        %v40988_v25 = vadd.f32 %v40984_v52, %v134369_v25 (stack53)
        %v41796_v20 = vxor.u32 %v41795_v40, %v41787_v22 (stack48)
        %v43423_v10 = vadd.s32 %v43418_v7, %v121574_v2 (stack40)
        %v43433_v23 = vshll.u32 %v43427_v8, 13 (stack45)
        %v42188_v56 = vadd.s32 %v42185_v61, %v42180_v56 (stack40)
        %v42190_v22 = vshll.u32 %v42185_v61, 29 (stack45)
        %v42191_v11 = vshrl.u32 %v42185_v61, 3 (stack46)
        %v42574_v54 = vxor.u32 %v42573_v41, %v42569_v42 (stack48)
        %v40992_v34 = vmul.f32 %v40988_v25, %v134408_v46 (stack54)
        %v41799_v12 = vadd.s32 %v41796_v20, %v121574_v2 (stack40)
        %v43002_v55 = vor.u32 %v43001_v31, %v43000_v26 (stack47)
        %v43431_v52 = vadd.s32 %v43427_v8, %v43423_v10 (stack40)
        %v42192_v40 = vor.u32 %v42191_v11, %v42190_v22 (stack47)
        %v42577_v42 = vadd.s32 %v42574_v54, %v42569_v42 (stack40)
        %v42583_v26 = vshll.u32 %v42574_v54, 24 (stack45)
        %v42584_v61 = vshrl.u32 %v42574_v54, 8 (stack46)
        %v40996_v53 = vadd.f32 %v40992_v34, %v134364_v53 (stack53)
        %v41803_v41 = vadd.s32 5, %v41799_v12 (stack40)
        %v43003_v31 = vxor.u32 %v43002_v55, %v134431_v21 (stack48)
        %v43434_v8 = vshrl.u32 %v43427_v8, 19 (stack46)
        %v41354_v24 = vmul.f32 %v41353_v60, %v134423_v24 (stack63)
        %vm134450_vm12 = vcmp.lt.f32.partialorder %v41355_v6, 0.0004427343 (stack62)
        %v42193_v60 = vxor.u32 %v42192_v40, %v42188_v56 (stack48)
        %v42585_v7 = vor.u32 %v42584_v61, %v42583_v26 (stack47)
        %v120782_v25 = vpop.eup %120781 (stack64)
        %v41000_v20 = vmul.f32 %v40996_v53, %v134408_v46 (stack54)
        %v41805_v30 = vxor.u32 %v41803_v41, %v41791_v30 (stack48)
        %v43006_v10 = vadd.s32 %v43003_v31, %v121564_v0 (stack40)
        %v43435_v23 = vor.u32 %v43434_v8, %v43433_v23 (stack47)
        %v41351_v22 = vmul.f32 0.6931472, %v120782_v25 (stack65)
        %v42196_v56 = vadd.s32 %v42193_v60, %v42188_v56 (stack40)
        %v42198_v11 = vshll.u32 %v42193_v60, 16 (stack45)
        %v42199_v54 = vshrl.u32 %v42193_v60, 16 (stack46)
        %v41004_v27 = vadd.f32 %v41000_v20, %v134355_v27 (stack53)
        %v42586_v34 = vxor.u32 %v42585_v7, %v42577_v42 (stack48)
        %v42998_v21 = vadd.s32 %v134431_v21, %v121569_v1 (stack40)
        %v43010_v12 = vadd.s32 1, %v43006_v10 (stack40)
        %v41357_v55 = vsel /*vm=*/%vm134450_vm12, /*on_true_vy=*/%v41354_v24, /*on_false_vx=*/%v41351_v22 (stack66)
        %v41806_v40 = vand.u32.u8 255, %v41805_v30 (stack49)
        %v42200_v26 = vor.u32 %v42199_v54, %v42198_v11 (stack47)
        %v43436_v61 = vxor.u32 %v43435_v23, %v43431_v52 (stack48)
        %v41008_v53 = vmul.f32 %v41004_v27, %v134408_v46 (stack54)
        %v134462_v41 = vxor.u32 2147483648, %v41357_v55 (stack56)
        %v40873_v31 = vand.u32 2147483647, %v134281_v50 (stack77)
        %v40909_v8 = vsel /*vm=*/%vm40900_vm6, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v42201_v24 = vxor.u32 %v42200_v26, %v42196_v56 (stack48)
        %v43014_v6 = vadd.s32 %v43010_v12, %v42998_v21 (stack40)
        %v41012_v60 = vadd.f32 %v41008_v53, %v40909_v8 (stack53)
        %120783 = vrsqrt.f32 %v134462_v41 (stack67)
        %v41807_v7 = vand.u32 65535, %v41806_v40 (stack50)
        %v42204_v25 = vadd.s32 %v42201_v24, %v42196_v56 (stack40)
        %v42589_v20 = vadd.s32 %v42586_v34, %v121574_v2 (stack40)
        %v40881_v30 = vmul.f32 inf, %v134281_v50 (stack54)
        %v41016_v46 = vmul.f32 %v41012_v60, %v134408_v46 (stack54)
        %v43016_v10 = vshll.u32 %v43010_v12, 17 (stack45)
        %v43017_v23 = vshrl.u32 %v43010_v12, 15 (stack46)
        %vm134472_vm13 = vcmp.eq.f32.partialorder %v40873_v31, 1.0 (stack68)
        %v40905_v43 = vsel /*vm=*/%vm40900_vm6, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v41334_v56 = vand.u32 2147483647, %v134410_v9 (stack77)
        %v42581_v42 = vadd.s32 %v42577_v42, %v121564_v0 (stack40)
        %v41020_v11 = vadd.f32 %v41016_v46, %v40905_v43 (stack53)
        %v134482_v54 = vadd.f32 -2.5, %v134462_v41 (stack53)
        %v42208_v27 = vadd.s32 %v42204_v25, %v121569_v1 (stack40)
        %v134487_v34 = vadd.s32 %v134395_v44, %v122657_v58 (stack40)
        %v41808_v21 = vshrl.u32 %v41807_v7, 1 (stack51)
        %v42210_v12 = vshll.u32 %v42201_v24, 24 (stack45)
        %v42211_v55 = vshrl.u32 %v42201_v24, 8 (stack46)
        %v42593_v40 = vadd.s32 2, %v42589_v20 (stack40)
        %v41024_v50 = vmul.f32 %v41020_v11, %v134281_v50 (stack54)
        %vm41361_vm14 = vcmp.lt.f32.partialorder %v134462_v41, 5.0 (stack68)
        %v43018_v26 = vor.u32 %v43017_v23, %v43016_v10 (stack47)
        %v43439_v52 = vadd.s32 %v43436_v61, %v43431_v52 (stack40)
        %v43441_v53 = vshll.u32 %v43436_v61, 15 (stack45)
        %vm41406_vm15 = vcmp.eq.f32.partialorder %v134462_v41, inf (stack70)
        %v41809_v31 = vor.u32 16256, %v41808_v21 (stack47)
        %v42212_v8 = vor.u32 %v42211_v55, %v42210_v12 (stack47)
        %v42597_v24 = vadd.s32 %v42593_v40, %v42581_v42 (stack40)
        %v42599_v60 = vshll.u32 %v42593_v40, 13 (stack45)
        %v41028_v7 = vsel /*vm=*/%vm134472_vm13, /*on_true_vy=*/%v40881_v30, /*on_false_vx=*/%v41024_v50 (stack44)
        %vm41408_vm0 = vcmp.eq.f32.partialorder %v134462_v41, 0.0 (stack71)
        %v42600_v20 = vshrl.u32 %v42593_v40, 19 (stack46)
        %v43019_v30 = vxor.u32 %v43018_v26, %v43014_v6 (stack48)
        %v43442_v61 = vshrl.u32 %v43436_v61, 17 (stack46)
        %v41032_v46 = vmul.f32 1.4140625, %v41028_v7 (stack54)
        %v41810_v10 = vand.u32.u16 65535, %v41809_v31 (stack52)
        %v42213_v25 = vxor.u32 %v42212_v8, %v42204_v25 (stack48)
        %vm43858_vm1 = vcmp.lt.u32.totalorder %v134395_v44, %v157089_v17 (stack43)
        %v42601_v23 = vor.u32 %v42600_v20, %v42599_v60 (stack47)
        %v43022_v6 = vadd.s32 %v43019_v30, %v43014_v6 (stack40)
        %v43024_v22 = vshll.u32 %v43019_v30, 29 (stack45)
        %v43025_v43 = vshrl.u32 %v43019_v30, 3 (stack46)
        %v41035_v42 = vpack.c.bf16 %v156663_v45, %v41032_v46 (stack81)
        %v119968_v11 = vadd.low.f32.bf16 -1.0, %v41810_v10 (stack53)
        %v42216_v21 = vadd.s32 %v42213_v25, %v121564_v0 (stack40)
        %v43443_v12 = vor.u32 %v43442_v61, %v43441_v53 (stack47)
        %v41409_v55 = vand.u32 2147483648, %v134462_v41 (stack72)
        %v42602_v40 = vxor.u32 %v42601_v23, %v42597_v24 (stack48)
        %v43026_v50 = vor.u32 %v43025_v43, %v43024_v22 (stack47)
        %v134502_v26 = vadd.s32 %v157318_v32, %v157090_v62 (stack40)
        %v120784_v53 = vpop.eup %120783 (stack73)
        %119961 = vst [vmem:[%s123356_s30 + $0x328] sm:$0xf] /*vst_source=*/%v41035_v42 (stack83)
        %v41819_v31 = vmul.f32 2.0, %v119968_v11 (stack54)
        %v42220_v8 = vadd.s32 4, %v42216_v21 (stack40)
        %v43444_v60 = vxor.u32 %v43443_v12, %v43439_v52 (stack48)
        %v134507_v7 = vadd.s32 %v157317_v29, %v157091_v37 (stack40)
        %v41405_v20 = vmul.f32 %v120784_v53, %v134462_v41 (stack74)
        %v42605_v24 = vadd.s32 %v42602_v40, %v42597_v24 (stack40)
        %v42607_v30 = vshll.u32 %v42602_v40, 15 (stack45)
        %v42608_v61 = vshrl.u32 %v42602_v40, 17 (stack46)
        %v41823_v46 = vadd.f32 -0.99609375, %v41819_v31 (stack53)
        %v42224_v27 = vadd.s32 %v42220_v8, %v42208_v27 (stack40)
        %v42226_v10 = vshll.u32 %v42220_v8, 13 (stack45)
        %v42227_v25 = vshrl.u32 %v42220_v8, 19 (stack46)
        %v41407_v23 = vsel /*vm=*/%vm41406_vm15, /*on_true_vy=*/%v134462_v41, /*on_false_vx=*/%v41405_v20 (stack75)
        %v42609_v22 = vor.u32 %v42608_v61, %v42607_v30 (stack47)
        %v43027_v43 = vxor.u32 %v43026_v50, %v43022_v6 (stack48)
        %v134513_v52 = vadd.s32 %v43444_v60, %v43439_v52 (stack40)
        %v134518_v42 = vsel /*vm=*/%vm41361_vm14, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v41410_v11 = vsel /*vm=*/%vm41408_vm0, /*on_true_vy=*/%v41409_v55, /*on_false_vx=*/%v41407_v23 (stack76)
        %v134522_v21 = vmax.f32 %v41823_v46, -0.99609375 (stack55)
        %v42228_v12 = vor.u32 %v42227_v25, %v42226_v10 (stack47)
        %v134527_v55 = vsel /*vm=*/%vm41361_vm14, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v41413_v40 = vadd.f32 -3.0, %v41410_v11 (stack53)
        %v42610_v50 = vxor.u32 %v42609_v22, %v42605_v24 (stack48)
        %v43030_v6 = vadd.s32 %v43027_v43, %v43022_v6 (stack40)
        %v41398_v53 = vsel /*vm=*/%vm41361_vm14, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v41839_v31 = vxor.u32 2147483648, %v134522_v21 (stack56)
        %v42229_v8 = vxor.u32 %v42228_v12, %v42224_v27 (stack48)
        %v43032_v20 = vshll.u32 %v43027_v43, 16 (stack45)
        %v134536_v54 = vsel /*vm=*/%vm41361_vm14, /*on_true_vy=*/%v134482_v54, /*on_false_vx=*/%v41413_v40 (stack44)
        %v42613_v24 = vadd.s32 %v42610_v50, %v42605_v24 (stack40)
        %v42615_v30 = vshll.u32 %v42610_v50, 26 (stack45)
        %v42616_v61 = vshrl.u32 %v42610_v50, 6 (stack46)
        %v41394_v46 = vsel /*vm=*/%vm41361_vm14, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v41421_v10 = vmul.f32 %v134536_v54, %v41398_v53 (stack54)
        %v134543_v25 = vmul.f32 %v41839_v31, %v134522_v21 (stack54)
        %v42232_v27 = vadd.s32 %v42229_v8, %v42224_v27 (stack40)
        %v42234_v23 = vshll.u32 %v42229_v8, 15 (stack45)
        %v42235_v22 = vshrl.u32 %v42229_v8, 17 (stack46)
        %v42617_v11 = vor.u32 %v42616_v61, %v42615_v30 (stack47)
        %v43033_v43 = vshrl.u32 %v43027_v43, 16 (stack46)
        %v41425_v12 = vadd.f32 %v41421_v10, %v41394_v46 (stack53)
        %v41844_v40 = vadd.f32 1.0, %v134543_v25 (stack57)
        %v41847_v50 = vmul.f32 -0.5, %v134543_v25 (stack59)
        %v43449_v53 = vshll.u32 %v43444_v60, 26 (stack45)
        %v42236_v31 = vor.u32 %v42235_v22, %v42234_v23 (stack47)
        %v42618_v8 = vxor.u32 %v42617_v11, %v42613_v24 (stack48)
        %v43034_v20 = vor.u32 %v43033_v43, %v43032_v20 (stack47)
        %v43450_v60 = vshrl.u32 %v43444_v60, 6 (stack46)
        %v41386_v30 = vsel /*vm=*/%vm41361_vm14, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v41390_v61 = vsel /*vm=*/%vm41361_vm14, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v41429_v46 = vmul.f32 %v41425_v12, %v134536_v54 (stack54)
        %120785 = vlog2.f32 %v41844_v40 (stack58)
        %v42237_v10 = vxor.u32 %v42236_v31, %v42232_v27 (stack48)
        %v42621_v24 = vadd.s32 %v42618_v8, %v42613_v24 (stack40)
        %v42627_v23 = vshll.u32 %v42618_v8, 6 (stack45)
        %v42628_v22 = vshrl.u32 %v42618_v8, 26 (stack46)
        %v41433_v11 = vadd.f32 %v41429_v46, %v41390_v61 (stack53)
        %v41848_v43 = vadd.f32 1.0, %v41847_v50 (stack61)
        %v43035_v12 = vxor.u32 %v43034_v20, %v43030_v6 (stack48)
        %v43451_v40 = vor.u32 %v43450_v60, %v43449_v53 (stack47)
        %vm43853_vm2 = vcmp.lt.u32.totalorder %v134487_v34, %v134395_v44 (stack43)
        %v42240_v27 = vadd.s32 %v42237_v10, %v42232_v27 (stack40)
        %v42242_v50 = vshll.u32 %v42237_v10, 26 (stack45)
        %v42243_v53 = vshrl.u32 %v42237_v10, 6 (stack46)
        %v134558_v31 = vadd.s32 %v134487_v34, %v121569_v1 (stack40)
        %v41437_v8 = vmul.f32 %v41433_v11, %v134536_v54 (stack54)
        %v42629_v20 = vor.u32 %v42628_v22, %v42627_v23 (stack47)
        %v43038_v6 = vadd.s32 %v43035_v12, %v43030_v6 (stack40)
        %v43044_v60 = vshll.u32 %v43035_v12, 24 (stack45)
        %v41850_v61 = vand.u32 2147483647, %v134543_v25 (stack60)
        %v42244_v46 = vor.u32 %v42243_v53, %v42242_v50 (stack47)
        %v43045_v10 = vshrl.u32 %v43035_v12, 8 (stack46)
        %v43452_v23 = vxor.u32 %v43451_v40, %v134513_v52 (stack48)
        %v41441_v30 = vadd.f32 %v41437_v8, %v41386_v30 (stack53)
        %v41849_v25 = vmul.f32 %v41848_v43, %v134543_v25 (stack63)
        %v42630_v22 = vxor.u32 %v42629_v20, %v42621_v24 (stack48)
        %v43867_v11 = vadd.s32 1, %v134502_v26 (stack40)
        %v42245_v43 = vxor.u32 %v42244_v46, %v42240_v27 (stack48)
        %v43046_v12 = vor.u32 %v43045_v10, %v43044_v60 (stack47)
        %v43455_v52 = vadd.s32 %v43452_v23, %v134513_v52 (stack40)
        %v43461_v40 = vshll.u32 %v43452_v23, 6 (stack45)
        %v41445_v50 = vmul.f32 %v41441_v30, %v134536_v54 (stack54)
        %v42633_v53 = vadd.s32 %v42630_v22, %v121569_v1 (stack40)
        %v43462_v8 = vshrl.u32 %v43452_v23, 26 (stack46)
        %v43871_v26 = vsel /*vm=*/%vm43858_vm1, /*on_true_vy=*/%v43867_v11, /*on_false_vx=*/%v134502_v26 (stack44)
        %v42248_v27 = vadd.s32 %v42245_v43, %v42240_v27 (stack40)
        %v42254_v20 = vshll.u32 %v42245_v43, 6 (stack45)
        %v42255_v60 = vshrl.u32 %v42245_v43, 26 (stack46)
        %v43047_v46 = vxor.u32 %v43046_v12, %v43038_v6 (stack48)
        %v41449_v55 = vadd.f32 %v41445_v50, %v134527_v55 (stack53)
        %v42625_v24 = vadd.s32 %v42621_v24, %v121574_v2 (stack40)
        %v42637_v10 = vadd.s32 3, %v42633_v53 (stack40)
        %v43463_v23 = vor.u32 %v43462_v8, %v43461_v40 (stack47)
        %v42256_v30 = vor.u32 %v42255_v60, %v42254_v20 (stack47)
        %v43042_v6 = vadd.s32 %v43038_v6, %v121564_v0 (stack40)
        %v43050_v22 = vadd.s32 %v43047_v46, %v121574_v2 (stack40)
        %v43875_v11 = vadd.s32 1, %v43871_v26 (stack40)
        %v41453_v43 = vmul.f32 %v41449_v55, %v134536_v54 (stack54)
        %v42641_v12 = vadd.s32 %v42637_v10, %v42625_v24 (stack40)
        %v42643_v40 = vshll.u32 %v42637_v10, 17 (stack45)
        %v42644_v50 = vshrl.u32 %v42637_v10, 15 (stack46)
        %v120786_v53 = vpop.eup %120785 (stack64)
        %v42257_v8 = vxor.u32 %v42256_v30, %v42248_v27 (stack48)
        %v43054_v20 = vadd.s32 2, %v43050_v22 (stack40)
        %v43464_v60 = vxor.u32 %v43463_v23, %v43455_v52 (stack48)
        %v43879_v44 = vsel /*vm=*/%vm43853_vm2, /*on_true_vy=*/%v43875_v11, /*on_false_vx=*/%v43871_v26 (stack44)
        %v41457_v34 = vadd.f32 %v41453_v43, %v134518_v42 (stack53)
        %v41846_v42 = vmul.f32 0.6931472, %v120786_v53 (stack65)
        %v42645_v26 = vor.u32 %v42644_v50, %v42643_v40 (stack47)
        %v43884_v46 = vadd.s32 %v43879_v44, %v121574_v2 (stack40)
        %vm41851_vm3 = vcmp.lt.f32.partialorder %v41850_v61, 0.0004427343 (stack62)
        %v42260_v61 = vadd.s32 %v42257_v8, %v121574_v2 (stack40)
        %v43058_v55 = vadd.s32 %v43054_v20, %v43042_v6 (stack40)
        %v43060_v24 = vshll.u32 %v43054_v20, 13 (stack45)
        %v41461_v10 = vmul.f32 %v41457_v34, %v134536_v54 (stack54)
        %v41852_v25 = vsel /*vm=*/%vm41851_vm3, /*on_true_vy=*/%v41849_v25, /*on_false_vx=*/%v41846_v42 (stack66)
        %v42646_v23 = vxor.u32 %v42645_v26, %v42641_v12 (stack48)
        %v43061_v30 = vshrl.u32 %v43054_v20, 19 (stack46)
        %v41374_v6 = vsel /*vm=*/%vm41361_vm14, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v134587_v22 = vxor.u32 2147483648, %v41852_v25 (stack56)
        %v42264_v11 = vadd.s32 5, %v42260_v61 (stack40)
        %v134590_v43 = vadd.s32 %v134558_v31, %v43884_v46 (stack40)
        %v41342_v40 = vmul.f32 inf, %v134410_v9 (stack54)
        %v41465_v50 = vadd.f32 %v41461_v10, %v41374_v6 (stack53)
        %v42649_v12 = vadd.s32 %v42646_v23, %v42641_v12 (stack40)
        %120787 = vrsqrt.f32 %v134587_v22 (stack67)
        %v42252_v27 = vadd.s32 %v42248_v27, %v121564_v0 (stack40)
        %v42651_v53 = vshll.u32 %v42646_v23, 29 (stack45)
        %v42652_v8 = vshrl.u32 %v42646_v23, 3 (stack46)
        %v41469_v20 = vmul.f32 %v41465_v50, %v134536_v54 (stack54)
        %vm41856_vm4 = vcmp.lt.f32.partialorder %v134587_v22, 5.0 (stack68)
        %v43062_v44 = vor.u32 %v43061_v30, %v43060_v24 (stack47)
        %v43467_v60 = vadd.s32 %v43464_v60, %v121564_v0 (stack40)
        %vm134600_vm5 = vcmp.eq.f32.partialorder %v41334_v56, 1.0 (stack68)
        %v41366_v34 = vsel /*vm=*/%vm41361_vm14, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v41370_v41 = vsel /*vm=*/%vm41361_vm14, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v42266_v42 = vxor.u32 %v42264_v11, %v42252_v27 (stack48)
        %v41473_v26 = vadd.f32 %v41469_v20, %v41370_v41 (stack53)
        %v41829_v46 = vand.u32 2147483647, %v134522_v21 (stack77)
        %v43459_v52 = vadd.s32 %v43455_v52, %v121569_v1 (stack40)
        %v43894_v61 = vshll.u32 %v134558_v31, 13 (stack45)
        %v134616_v24 = vsel /*vm=*/%vm41856_vm4, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v134619_v10 = vadd.f32 -2.5, %v134587_v22 (stack53)
        %v42267_v25 = vand.u32.u8 255, %v42266_v42 (stack49)
        %v42653_v23 = vor.u32 %v42652_v8, %v42651_v53 (stack47)
        %v41477_v54 = vmul.f32 %v41473_v26, %v134536_v54 (stack54)
        %v134625_v30 = vsel /*vm=*/%vm41856_vm4, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v43063_v6 = vxor.u32 %v43062_v44, %v43058_v55 (stack48)
        %v43471_v11 = vadd.s32 1, %v43467_v60 (stack40)
        %v42268_v50 = vand.u32 65535, %v42267_v25 (stack50)
        %v42654_v27 = vxor.u32 %v42653_v23, %v42649_v12 (stack48)
        %v43895_v31 = vshrl.u32 %v134558_v31, 19 (stack46)
        %vm44319_vm6 = vcmp.lt.u32.totalorder %v134507_v7, %v157091_v37 (stack43)
        %v41481_v53 = vadd.f32 %v41477_v54, %v41366_v34 (stack53)
        %vm41901_vm7 = vcmp.eq.f32.partialorder %v134587_v22, inf (stack70)
        %v43066_v55 = vadd.s32 %v43063_v6, %v43058_v55 (stack40)
        %v43068_v8 = vshll.u32 %v43063_v6, 15 (stack45)
        %v43069_v20 = vshrl.u32 %v43063_v6, 17 (stack46)
        %v42269_v44 = vshrl.u32 %v42268_v50, 1 (stack51)
        %v42657_v12 = vadd.s32 %v42654_v27, %v42649_v12 (stack40)
        %v42659_v60 = vshll.u32 %v42654_v27, 16 (stack45)
        %v42660_v34 = vshrl.u32 %v42654_v27, 16 (stack46)
        %v41485_v9 = vmul.f32 %v41481_v53, %v134410_v9 (stack54)
        %v43070_v41 = vor.u32 %v43069_v20, %v43068_v8 (stack47)
        %v43475_v42 = vadd.s32 %v43471_v11, %v43459_v52 (stack40)
        %v43477_v26 = vshll.u32 %v43471_v11, 17 (stack45)
        %v42270_v52 = vor.u32 16256, %v42269_v44 (stack47)
        %v42661_v25 = vor.u32 %v42660_v34, %v42659_v60 (stack47)
        %v43478_v23 = vshrl.u32 %v43471_v11, 15 (stack46)
        %v43896_v61 = vor.u32 %v43895_v31, %v43894_v61 (stack47)
        %v41489_v40 = vsel /*vm=*/%vm134600_vm5, /*on_true_vy=*/%v41342_v40, /*on_false_vx=*/%v41485_v9 (stack44)
        %v41904_v56 = vand.u32 2147483648, %v134587_v22 (stack72)
        %v43071_v54 = vxor.u32 %v43070_v41, %v43066_v55 (stack48)
        %v134637_v6 = vadd.s32 %v157318_v32, %v157094_v36 (stack40)
        %v41493_v11 = vmul.f32 1.4140625, %v41489_v40 (stack54)
        %v42271_v50 = vand.u32.u16 65535, %v42270_v52 (stack52)
        %v42662_v27 = vxor.u32 %v42661_v25, %v42657_v12 (stack48)
        %v43479_v31 = vor.u32 %v43478_v23, %v43477_v26 (stack47)
        %v120788_v53 = vpop.eup %120787 (stack73)
        %v43074_v55 = vadd.s32 %v43071_v54, %v43066_v55 (stack40)
        %v43076_v8 = vshll.u32 %v43071_v54, 26 (stack45)
        %v43077_v20 = vshrl.u32 %v43071_v54, 6 (stack46)
        %v43897_v44 = vxor.u32 %v43896_v61, %v134590_v43 (stack48)
        %v41496_v60 = vpack.c.bf16 %v156663_v45, %v41493_v11 (stack81)
        %v41900_v34 = vmul.f32 %v120788_v53, %v134587_v22 (stack74)
        %v119970_v9 = vadd.low.f32.bf16 -1.0, %v42271_v50 (stack53)
        %v42665_v12 = vadd.s32 %v42662_v27, %v42657_v12 (stack40)
        %v42671_v41 = vshll.u32 %v42662_v27, 24 (stack45)
        %v42672_v26 = vshrl.u32 %v42662_v27, 8 (stack46)
        %v43078_v52 = vor.u32 %v43077_v20, %v43076_v8 (stack47)
        %v43480_v25 = vxor.u32 %v43479_v31, %v43475_v42 (stack48)
        %119963 = vst [vmem:[%s123356_s30 + $0x3a8] sm:$0xf] /*vst_source=*/%v41496_v60 (stack83)
        %v41902_v23 = vsel /*vm=*/%vm41901_vm7, /*on_true_vy=*/%v134587_v22, /*on_false_vx=*/%v41900_v34 (stack75)
        %vm41903_vm8 = vcmp.eq.f32.partialorder %v134587_v22, 0.0 (stack71)
        %v42280_v61 = vmul.f32 2.0, %v119970_v9 (stack54)
        %v134648_v43 = vadd.s32 %v43897_v44, %v134590_v43 (stack40)
        %v41905_v40 = vsel /*vm=*/%vm41903_vm8, /*on_true_vy=*/%v41904_v56, /*on_false_vx=*/%v41902_v23 (stack76)
        %v42673_v56 = vor.u32 %v42672_v26, %v42671_v41 (stack47)
        %v43079_v54 = vxor.u32 %v43078_v52, %v43074_v55 (stack48)
        %v43483_v42 = vadd.s32 %v43480_v25, %v43475_v42 (stack40)
        %v41908_v11 = vadd.f32 -3.0, %v41905_v40 (stack53)
        %v42284_v50 = vadd.f32 -0.99609375, %v42280_v61 (stack53)
        %v43485_v27 = vshll.u32 %v43480_v25, 29 (stack45)
        %v43486_v31 = vshrl.u32 %v43480_v25, 3 (stack46)
        %v42674_v53 = vxor.u32 %v42673_v56, %v42665_v12 (stack48)
        %v43082_v55 = vadd.s32 %v43079_v54, %v43074_v55 (stack40)
        %v43088_v8 = vshll.u32 %v43079_v54, 6 (stack45)
        %v43089_v20 = vshrl.u32 %v43079_v54, 26 (stack46)
        %v41893_v60 = vsel /*vm=*/%vm41856_vm4, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v134656_v10 = vsel /*vm=*/%vm41856_vm4, /*on_true_vy=*/%v134619_v10, /*on_false_vx=*/%v41908_v11 (stack44)
        %v134658_v34 = vmax.f32 %v42284_v50, -0.99609375 (stack55)
        %v43487_v9 = vor.u32 %v43486_v31, %v43485_v27 (stack47)
        %v41889_v41 = vsel /*vm=*/%vm41856_vm4, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v41916_v26 = vmul.f32 %v134656_v10, %v41893_v60 (stack54)
        %v42677_v52 = vadd.s32 %v42674_v53, %v121564_v0 (stack40)
        %v43090_v25 = vor.u32 %v43089_v20, %v43088_v8 (stack47)
        %v42300_v23 = vxor.u32 2147483648, %v134658_v34 (stack56)
        %v42669_v12 = vadd.s32 %v42665_v12, %v121569_v1 (stack40)
        %v43488_v61 = vxor.u32 %v43487_v9, %v43483_v42 (stack48)
        %v43902_v40 = vshll.u32 %v43897_v44, 15 (stack45)
        %v41920_v56 = vadd.f32 %v41916_v26, %v41889_v41 (stack53)
        %v42681_v54 = vadd.s32 4, %v42677_v52 (stack40)
        %v43091_v11 = vxor.u32 %v43090_v25, %v43082_v55 (stack48)
        %v43903_v44 = vshrl.u32 %v43897_v44, 17 (stack46)
        %v41881_v50 = vsel /*vm=*/%vm41856_vm4, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v134671_v27 = vmul.f32 %v42300_v23, %v134658_v34 (stack54)
        %v43491_v42 = vadd.s32 %v43488_v61, %v43483_v42 (stack40)
        %v43493_v31 = vshll.u32 %v43488_v61, 16 (stack45)
        %v41924_v53 = vmul.f32 %v41920_v56, %v134656_v10 (stack54)
        %v42685_v8 = vadd.s32 %v42681_v54, %v42669_v12 (stack40)
        %v42687_v20 = vshll.u32 %v42681_v54, 13 (stack45)
        %v42688_v60 = vshrl.u32 %v42681_v54, 19 (stack46)
        %v41885_v9 = vsel /*vm=*/%vm41856_vm4, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v42305_v41 = vadd.f32 1.0, %v134671_v27 (stack57)
        %v43094_v26 = vadd.s32 %v43091_v11, %v121569_v1 (stack40)
        %v134681_v52 = vadd.s32 %v134507_v7, %v122657_v58 (stack40)
        %v41928_v25 = vadd.f32 %v41924_v53, %v41885_v9 (stack53)
        %v42689_v23 = vor.u32 %v42688_v60, %v42687_v20 (stack47)
        %v43494_v12 = vshrl.u32 %v43488_v61, 16 (stack46)
        %v43904_v61 = vor.u32 %v43903_v44, %v43902_v40 (stack47)
        %120789 = vlog2.f32 %v42305_v41 (stack58)
        %v42308_v40 = vmul.f32 -0.5, %v134671_v27 (stack59)
        %v43086_v55 = vadd.s32 %v43082_v55, %v121574_v2 (stack40)
        %v43098_v56 = vadd.s32 3, %v43094_v26 (stack40)
        %v41932_v54 = vmul.f32 %v41928_v25, %v134656_v10 (stack54)
        %v42690_v11 = vxor.u32 %v42689_v23, %v42685_v8 (stack48)
        %v43495_v44 = vor.u32 %v43494_v12, %v43493_v31 (stack47)
        %v43905_v31 = vxor.u32 %v43904_v61, %v134648_v43 (stack48)
        %v42311_v53 = vand.u32 2147483647, %v134671_v27 (stack60)
        %v43102_v20 = vadd.s32 %v43098_v56, %v43086_v55 (stack40)
        %v43104_v60 = vshll.u32 %v43098_v56, 17 (stack45)
        %v43105_v9 = vshrl.u32 %v43098_v56, 15 (stack46)
        %vm44314_vm9 = vcmp.lt.u32.totalorder %v134681_v52, %v134507_v7 (stack43)
        %v41936_v50 = vadd.f32 %v41932_v54, %v41881_v50 (stack53)
        %v42693_v8 = vadd.s32 %v42690_v11, %v42685_v8 (stack40)
        %v42695_v41 = vshll.u32 %v42690_v11, 15 (stack45)
        %v42696_v26 = vshrl.u32 %v42690_v11, 17 (stack46)
        %v43106_v25 = vor.u32 %v43105_v9, %v43104_v60 (stack47)
        %v43496_v23 = vxor.u32 %v43495_v44, %v43491_v42 (stack48)
        %v43908_v43 = vadd.s32 %v43905_v31, %v134648_v43 (stack40)
        %v43910_v12 = vshll.u32 %v43905_v31, 26 (stack45)
        %v41940_v61 = vmul.f32 %v41936_v50, %v134656_v10 (stack54)
        %v42697_v55 = vor.u32 %v42696_v26, %v42695_v41 (stack47)
        %v43911_v56 = vshrl.u32 %v43905_v31, 6 (stack46)
        %v44328_v54 = vadd.s32 1, %v134637_v6 (stack40)
        %v43107_v11 = vxor.u32 %v43106_v25, %v43102_v20 (stack48)
        %v43499_v42 = vadd.s32 %v43496_v23, %v43491_v42 (stack40)
        %v43505_v44 = vshll.u32 %v43496_v23, 24 (stack45)
        %v43506_v31 = vshrl.u32 %v43496_v23, 8 (stack46)
        %v41944_v30 = vadd.f32 %v41940_v61, %v134625_v30 (stack53)
        %v42698_v60 = vxor.u32 %v42697_v55, %v42693_v8 (stack48)
        %v43912_v9 = vor.u32 %v43911_v56, %v43910_v12 (stack47)
        %v44332_v6 = vsel /*vm=*/%vm44319_vm6, /*on_true_vy=*/%v44328_v54, /*on_false_vx=*/%v134637_v6 (stack44)
        %v42309_v40 = vadd.f32 1.0, %v42308_v40 (stack61)
        %v43110_v20 = vadd.s32 %v43107_v11, %v43102_v20 (stack40)
        %v43112_v50 = vshll.u32 %v43107_v11, 29 (stack45)
        %v43113_v41 = vshrl.u32 %v43107_v11, 3 (stack46)
        %v41948_v26 = vmul.f32 %v41944_v30, %v134656_v10 (stack54)
        %v42701_v8 = vadd.s32 %v42698_v60, %v42693_v8 (stack40)
        %v42703_v25 = vshll.u32 %v42698_v60, 26 (stack45)
        %v42704_v23 = vshrl.u32 %v42698_v60, 6 (stack46)
        %v43114_v12 = vor.u32 %v43113_v41, %v43112_v50 (stack47)
        %v43507_v61 = vor.u32 %v43506_v31, %v43505_v44 (stack47)
        %v43913_v55 = vxor.u32 %v43912_v9, %v43908_v43 (stack48)
        %v44336_v56 = vadd.s32 1, %v44332_v6 (stack40)
        %v41869_v54 = vsel /*vm=*/%vm41856_vm4, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v41952_v24 = vadd.f32 %v41948_v26, %v134616_v24 (stack53)
        %v42705_v11 = vor.u32 %v42704_v23, %v42703_v25 (stack47)
        %v134705_v29 = vadd.s32 %v157317_v29, %v157095_v13 (stack40)
        %vm134707_vm10 = vcmp.lt.f32.partialorder %v42311_v53, 0.0004427343 (stack62)
        %v43115_v44 = vxor.u32 %v43114_v12, %v43110_v20 (stack48)
        %v43508_v31 = vxor.u32 %v43507_v61, %v43499_v42 (stack48)
        %v134711_v43 = vadd.s32 %v43913_v55, %v43908_v43 (stack40)
        %v120790_v30 = vpop.eup %120789 (stack64)
        %v41956_v60 = vmul.f32 %v41952_v24, %v134656_v10 (stack54)
        %v42310_v27 = vmul.f32 %v42309_v40, %v134671_v27 (stack63)
        %v42706_v9 = vxor.u32 %v42705_v11, %v42701_v8 (stack48)
        %v44340_v7 = vsel /*vm=*/%vm44314_vm9, /*on_true_vy=*/%v44336_v56, /*on_false_vx=*/%v44332_v6 (stack44)
        %v42307_v6 = vmul.f32 0.6931472, %v120790_v30 (stack65)
        %v43118_v40 = vadd.s32 %v43115_v44, %v43110_v20 (stack40)
        %v43120_v20 = vshll.u32 %v43115_v44, 16 (stack45)
        %v43121_v50 = vshrl.u32 %v43115_v44, 16 (stack46)
        %v41960_v41 = vadd.f32 %v41956_v60, %v41869_v54 (stack53)
        %v42709_v26 = vadd.s32 %v42706_v9, %v42701_v8 (stack40)
        %v42715_v8 = vshll.u32 %v42706_v9, 6 (stack45)
        %v42716_v25 = vshrl.u32 %v42706_v9, 26 (stack46)
        %v42313_v23 = vsel /*vm=*/%vm134707_vm10, /*on_true_vy=*/%v42310_v27, /*on_false_vx=*/%v42307_v6 (stack66)
        %v43122_v12 = vor.u32 %v43121_v50, %v43120_v20 (stack47)
        %v43922_v61 = vshll.u32 %v43913_v55, 6 (stack45)
        %v43923_v55 = vshrl.u32 %v43913_v55, 26 (stack46)
        %v41964_v56 = vmul.f32 %v41960_v41, %v134656_v10 (stack54)
        %v134721_v54 = vxor.u32 2147483648, %v42313_v23 (stack56)
        %v42717_v24 = vor.u32 %v42716_v25, %v42715_v8 (stack47)
        %v43511_v11 = vadd.s32 %v43508_v31, %v121574_v2 (stack40)
        %vm134726_vm11 = vcmp.eq.f32.partialorder %v41829_v46, 1.0 (stack68)
        %v41837_v53 = vmul.f32 inf, %v134522_v21 (stack54)
        %v41865_v44 = vsel /*vm=*/%vm41856_vm4, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v43123_v31 = vxor.u32 %v43122_v12, %v43118_v40 (stack48)
        %v41861_v22 = vsel /*vm=*/%vm41856_vm4, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v41968_v30 = vadd.f32 %v41964_v56, %v41865_v44 (stack53)
        %vm42317_vm12 = vcmp.lt.f32.partialorder %v134721_v54, 5.0 (stack68)
        %120791 = vrsqrt.f32 %v134721_v54 (stack67)
        %v42718_v60 = vxor.u32 %v42717_v24, %v42709_v26 (stack48)
        %v43503_v42 = vadd.s32 %v43499_v42, %v121564_v0 (stack40)
        %v43920_v27 = vadd.s32 %v134711_v43, %v121569_v1 (stack40)
        %v44349_v52 = vadd.s32 %v134681_v52, %v121569_v1 (stack40)
        %v41972_v10 = vmul.f32 %v41968_v30, %v134656_v10 (stack54)
        %v42713_v9 = vadd.s32 %v42709_v26, %v121564_v0 (stack40)
        %v43515_v6 = vadd.s32 2, %v43511_v11 (stack40)
        %v43924_v20 = vor.u32 %v43923_v55, %v43922_v61 (stack47)
        %v134749_v50 = vsel /*vm=*/%vm42317_vm12, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v134752_v41 = vadd.f32 -2.5, %v134721_v54 (stack53)
        %v42721_v26 = vadd.s32 %v42718_v60, %v121574_v2 (stack40)
        %v44345_v7 = vadd.s32 %v44340_v7, %v121574_v2 (stack40)
        %v41976_v8 = vadd.f32 %v41972_v10, %v41861_v22 (stack53)
        %v134759_v25 = vsel /*vm=*/%vm42317_vm12, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v134764_v23 = vsel /*vm=*/%vm42317_vm12, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v134769_v12 = vsel /*vm=*/%vm42317_vm12, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v42725_v61 = vadd.s32 5, %v42721_v26 (stack40)
        %v43126_v40 = vadd.s32 %v43123_v31, %v43118_v40 (stack40)
        %v43132_v55 = vshll.u32 %v43123_v31, 24 (stack45)
        %v43133_v56 = vshrl.u32 %v43123_v31, 8 (stack46)
        %v41980_v21 = vmul.f32 %v41976_v8, %v134522_v21 (stack54)
        %v43519_v24 = vadd.s32 %v43515_v6, %v43503_v42 (stack40)
        %v43521_v11 = vshll.u32 %v43515_v6, 13 (stack45)
        %v43522_v44 = vshrl.u32 %v43515_v6, 19 (stack46)
        %vm42362_vm13 = vcmp.eq.f32.partialorder %v134721_v54, inf (stack70)
        %v42365_v31 = vand.u32 2147483648, %v134721_v54 (stack72)
        %v42727_v22 = vxor.u32 %v42725_v61, %v42713_v9 (stack48)
        %v43134_v30 = vor.u32 %v43133_v56, %v43132_v55 (stack47)
        %v43925_v43 = vxor.u32 %v43924_v20, %v134711_v43 (stack48)
        %v41984_v46 = vsel /*vm=*/%vm134726_vm11, /*on_true_vy=*/%v41837_v53, /*on_false_vx=*/%v41980_v21 (stack44)
        %vm42364_vm14 = vcmp.eq.f32.partialorder %v134721_v54, 0.0 (stack71)
        %v43523_v53 = vor.u32 %v43522_v44, %v43521_v11 (stack47)
        %v44353_v60 = vadd.s32 %v44349_v52, %v44345_v7 (stack40)
        %v44355_v42 = vshll.u32 %v44349_v52, 13 (stack45)
        %v41988_v10 = vmul.f32 1.4140625, %v41984_v46 (stack54)
        %v42728_v9 = vand.u32.u8 255, %v42727_v22 (stack49)
        %v43135_v6 = vxor.u32 %v43134_v30, %v43126_v40 (stack48)
        %v43928_v20 = vadd.s32 %v43925_v43, %v121564_v0 (stack40)
        %v43130_v26 = vadd.s32 %v43126_v40, %v121569_v1 (stack40)
        %v43524_v7 = vxor.u32 %v43523_v53, %v43519_v24 (stack48)
        %v44356_v52 = vshrl.u32 %v44349_v52, 19 (stack46)
        %vm44780_vm15 = vcmp.lt.u32.totalorder %v134705_v29, %v157095_v13 (stack43)
        %v41991_v8 = vpack.c.bf16 %v156663_v45, %v41988_v10 (stack81)
        %v42729_v61 = vand.u32 65535, %v42728_v9 (stack50)
        %v43138_v40 = vadd.s32 %v43135_v6, %v121564_v0 (stack40)
        %v43932_v55 = vadd.s32 1, %v43928_v20 (stack40)
        %v43527_v56 = vadd.s32 %v43524_v7, %v43519_v24 (stack40)
        %v43529_v21 = vshll.u32 %v43524_v7, 15 (stack45)
        %v43530_v24 = vshrl.u32 %v43524_v7, 17 (stack46)
        %v44357_v11 = vor.u32 %v44356_v52, %v44355_v42 (stack47)
        %v120792_v44 = vpop.eup %120791 (stack73)
        %119969 = vst [vmem:[%s123356_s30 + $0x2c] sm:$0xf] /*vst_source=*/%v41991_v8 (stack83)
        %v42730_v22 = vshrl.u32 %v42729_v61, 1 (stack51)
        %v43142_v30 = vadd.s32 4, %v43138_v40 (stack40)
        %v43936_v27 = vadd.s32 %v43932_v55, %v43920_v27 (stack40)
        %v43938_v43 = vshll.u32 %v43932_v55, 17 (stack45)
        %v42361_v46 = vmul.f32 %v120792_v44, %v134721_v54 (stack74)
        %v43531_v53 = vor.u32 %v43530_v24, %v43529_v21 (stack47)
        %v43939_v42 = vshrl.u32 %v43932_v55, 15 (stack46)
        %v44358_v10 = vxor.u32 %v44357_v11, %v44353_v60 (stack48)
        %v42731_v9 = vor.u32 16256, %v42730_v22 (stack47)
        %v43146_v6 = vadd.s32 %v43142_v30, %v43130_v26 (stack40)
        %v43148_v20 = vshll.u32 %v43142_v30, 13 (stack45)
        %v43149_v26 = vshrl.u32 %v43142_v30, 19 (stack46)
        %v42363_v7 = vsel /*vm=*/%vm42362_vm13, /*on_true_vy=*/%v134721_v54, /*on_false_vx=*/%v42361_v46 (stack75)
        %v43532_v52 = vxor.u32 %v43531_v53, %v43527_v56 (stack48)
        %v43940_v8 = vor.u32 %v43939_v42, %v43938_v43 (stack47)
        %v44361_v60 = vadd.s32 %v44358_v10, %v44353_v60 (stack40)
        %v42366_v31 = vsel /*vm=*/%vm42364_vm14, /*on_true_vy=*/%v42365_v31, /*on_false_vx=*/%v42363_v7 (stack76)
        %v42732_v61 = vand.u32.u16 65535, %v42731_v9 (stack52)
        %v43150_v40 = vor.u32 %v43149_v26, %v43148_v20 (stack47)
        %v44363_v55 = vshll.u32 %v44358_v10, 15 (stack45)
        %v42369_v21 = vadd.f32 -3.0, %v42366_v31 (stack53)
        %v43535_v56 = vadd.s32 %v43532_v52, %v43527_v56 (stack40)
        %v43537_v24 = vshll.u32 %v43532_v52, 26 (stack45)
        %v43538_v11 = vshrl.u32 %v43532_v52, 6 (stack46)
        %v119972_v44 = vadd.low.f32.bf16 -1.0, %v42732_v61 (stack53)
        %v43151_v22 = vxor.u32 %v43150_v40, %v43146_v6 (stack48)
        %v43941_v30 = vxor.u32 %v43940_v8, %v43936_v27 (stack48)
        %v44364_v43 = vshrl.u32 %v44358_v10, 17 (stack46)
        %v134794_v41 = vsel /*vm=*/%vm42317_vm12, /*on_true_vy=*/%v134752_v41, /*on_false_vx=*/%v42369_v21 (stack44)
        %v43539_v46 = vor.u32 %v43538_v11, %v43537_v24 (stack47)
        %v134798_v53 = vadd.s32 %v134705_v29, %v122657_v58 (stack40)
        %v134802_v32 = vadd.s32 %v157318_v32, %v157100_v14 (stack40)
        %v42377_v12 = vmul.f32 %v134794_v41, %v134769_v12 (stack54)
        %v42741_v42 = vmul.f32 2.0, %v119972_v44 (stack54)
        %v43154_v10 = vadd.s32 %v43151_v22, %v43146_v6 (stack40)
        %v43156_v9 = vshll.u32 %v43151_v22, 15 (stack45)
        %v43157_v6 = vshrl.u32 %v43151_v22, 17 (stack46)
        %v43540_v20 = vxor.u32 %v43539_v46, %v43535_v56 (stack48)
        %v43944_v27 = vadd.s32 %v43941_v30, %v43936_v27 (stack40)
        %v43946_v26 = vshll.u32 %v43941_v30, 29 (stack45)
        %v42381_v23 = vadd.f32 %v42377_v12, %v134764_v23 (stack53)
        %v42745_v7 = vadd.f32 -0.99609375, %v42741_v42 (stack53)
        %v43947_v52 = vshrl.u32 %v43941_v30, 3 (stack46)
        %v44365_v8 = vor.u32 %v44364_v43, %v44363_v55 (stack47)
        %v43158_v31 = vor.u32 %v43157_v6, %v43156_v9 (stack47)
        %v43543_v61 = vadd.s32 %v43540_v20, %v43535_v56 (stack40)
        %v43549_v40 = vshll.u32 %v43540_v20, 6 (stack45)
        %v43550_v55 = vshrl.u32 %v43540_v20, 26 (stack46)
        %v42385_v21 = vmul.f32 %v42381_v23, %v134794_v41 (stack54)
        %v134808_v56 = vmax.f32 %v42745_v7, -0.99609375 (stack55)
        %v43948_v24 = vor.u32 %v43947_v52, %v43946_v26 (stack47)
        %v44366_v11 = vxor.u32 %v44365_v8, %v44361_v60 (stack48)
        %v42334_v44 = vsel /*vm=*/%vm42317_vm12, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v42346_v22 = vsel /*vm=*/%vm42317_vm12, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v43159_v30 = vxor.u32 %v43158_v31, %v43154_v10 (stack48)
        %v43551_v43 = vor.u32 %v43550_v55, %v43549_v40 (stack47)
        %v42338_v46 = vsel /*vm=*/%vm42317_vm12, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v42342_v12 = vsel /*vm=*/%vm42317_vm12, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v42389_v42 = vadd.f32 %v42385_v21, %v42346_v22 (stack53)
        %v42761_v9 = vxor.u32 2147483648, %v134808_v56 (stack56)
        %v43162_v10 = vadd.s32 %v43159_v30, %v43154_v10 (stack40)
        %v43164_v6 = vshll.u32 %v43159_v30, 26 (stack45)
        %v43165_v20 = vshrl.u32 %v43159_v30, 6 (stack46)
        %v43552_v26 = vxor.u32 %v43551_v43, %v43543_v61 (stack48)
        %v42393_v23 = vmul.f32 %v42389_v42, %v134794_v41 (stack54)
        %v134825_v7 = vmul.f32 %v42761_v9, %v134808_v56 (stack54)
        %v43949_v52 = vxor.u32 %v43948_v24, %v43944_v27 (stack48)
        %vm44775_vm0 = vcmp.lt.u32.totalorder %v134798_v53, %v134705_v29 (stack43)
        %v43166_v8 = vor.u32 %v43165_v20, %v43164_v6 (stack47)
        %v43547_v31 = vadd.s32 %v43543_v61, %v121574_v2 (stack40)
        %v43555_v61 = vadd.s32 %v43552_v26, %v121569_v1 (stack40)
        %v44369_v60 = vadd.s32 %v44366_v11, %v44361_v60 (stack40)
        %v42397_v40 = vadd.f32 %v42393_v23, %v42342_v12 (stack53)
        %v42766_v55 = vadd.f32 1.0, %v134825_v7 (stack57)
        %v42769_v21 = vmul.f32 -0.5, %v134825_v7 (stack59)
        %v44789_v24 = vadd.s32 1, %v134802_v32 (stack40)
        %v43167_v22 = vxor.u32 %v43166_v8, %v43162_v10 (stack48)
        %v43559_v30 = vadd.s32 3, %v43555_v61 (stack40)
        %v43952_v27 = vadd.s32 %v43949_v52, %v43944_v27 (stack40)
        %v44371_v43 = vshll.u32 %v44366_v11, 26 (stack45)
        %v42401_v12 = vmul.f32 %v42397_v40, %v134794_v41 (stack54)
        %120793 = vlog2.f32 %v42766_v55 (stack58)
        %v42772_v42 = vand.u32 2147483647, %v134825_v7 (stack60)
        %v43954_v9 = vshll.u32 %v43949_v52, 16 (stack45)
        %v43170_v10 = vadd.s32 %v43167_v22, %v43162_v10 (stack40)
        %v43176_v6 = vshll.u32 %v43167_v22, 6 (stack45)
        %v43177_v20 = vshrl.u32 %v43167_v22, 26 (stack46)
        %v43563_v26 = vadd.s32 %v43559_v30, %v43547_v31 (stack40)
        %v42405_v46 = vadd.f32 %v42401_v12, %v42338_v46 (stack53)
        %v42770_v23 = vadd.f32 1.0, %v42769_v21 (stack61)
        %v43565_v8 = vshll.u32 %v43559_v30, 17 (stack45)
        %v43566_v31 = vshrl.u32 %v43559_v30, 15 (stack46)
        %v43174_v61 = vadd.s32 %v43170_v10, %v121564_v0 (stack40)
        %v43178_v40 = vor.u32 %v43177_v20, %v43176_v6 (stack47)
        %v43955_v52 = vshrl.u32 %v43949_v52, 16 (stack46)
        %v44372_v11 = vshrl.u32 %v44366_v11, 6 (stack46)
        %v42409_v55 = vmul.f32 %v42405_v46, %v134794_v41 (stack54)
        %v43567_v21 = vor.u32 %v43566_v31, %v43565_v8 (stack47)
        %v44793_v32 = vsel /*vm=*/%vm44780_vm15, /*on_true_vy=*/%v44789_v24, /*on_false_vx=*/%v134802_v32 (stack44)
        %v44810_v24 = vadd.s32 %v134798_v53, %v121569_v1 (stack40)
        %v43179_v22 = vxor.u32 %v43178_v40, %v43170_v10 (stack48)
        %v43956_v30 = vor.u32 %v43955_v52, %v43954_v9 (stack47)
        %v44373_v43 = vor.u32 %v44372_v11, %v44371_v43 (stack47)
        %v44797_v12 = vadd.s32 1, %v44793_v32 (stack40)
        %v42413_v44 = vadd.f32 %v42409_v55, %v42334_v44 (stack53)
        %v43568_v9 = vxor.u32 %v43567_v21, %v43563_v26 (stack48)
        %v44816_v10 = vshll.u32 %v44810_v24, 13 (stack45)
        %v44817_v6 = vshrl.u32 %v44810_v24, 19 (stack46)
        %v43182_v20 = vadd.s32 %v43179_v22, %v121574_v2 (stack40)
        %v43957_v46 = vxor.u32 %v43956_v30, %v43952_v27 (stack48)
        %v44374_v8 = vxor.u32 %v44373_v43, %v44369_v60 (stack48)
        %v44801_v29 = vsel /*vm=*/%vm44775_vm0, /*on_true_vy=*/%v44797_v12, /*on_false_vx=*/%v44793_v32 (stack44)
        %v42417_v53 = vmul.f32 %v42413_v44, %v134794_v41 (stack54)
        %v43571_v26 = vadd.s32 %v43568_v9, %v43563_v26 (stack40)
        %v43573_v31 = vshll.u32 %v43568_v9, 29 (stack45)
        %v43574_v40 = vshrl.u32 %v43568_v9, 3 (stack46)
        %v43186_v52 = vadd.s32 5, %v43182_v20 (stack40)
        %v43960_v27 = vadd.s32 %v43957_v46, %v43952_v27 (stack40)
        %v43966_v11 = vshll.u32 %v43957_v46, 24 (stack45)
        %v43967_v55 = vshrl.u32 %v43957_v46, 8 (stack46)
        %v42421_v25 = vadd.f32 %v42417_v53, %v134759_v25 (stack53)
        %v43575_v21 = vor.u32 %v43574_v40, %v43573_v31 (stack47)
        %v44377_v60 = vadd.s32 %v44374_v8, %v44369_v60 (stack40)
        %v44383_v32 = vshll.u32 %v44374_v8, 6 (stack45)
        %vm134850_vm1 = vcmp.lt.f32.partialorder %v42772_v42, 0.0004427343 (stack62)
        %v43188_v61 = vxor.u32 %v43186_v52, %v43174_v61 (stack48)
        %v43968_v22 = vor.u32 %v43967_v55, %v43966_v11 (stack47)
        %v44384_v30 = vshrl.u32 %v44374_v8, 26 (stack46)
        %v42425_v43 = vmul.f32 %v42421_v25, %v134794_v41 (stack54)
        %v42771_v7 = vmul.f32 %v42770_v23, %v134825_v7 (stack63)
        %v43576_v23 = vxor.u32 %v43575_v21, %v43571_v26 (stack48)
        %v44806_v12 = vadd.s32 %v44801_v29, %v121574_v2 (stack40)
        %v120794_v44 = vpop.eup %120793 (stack64)
        %v43189_v9 = vand.u32.u8 255, %v43188_v61 (stack49)
        %v43969_v20 = vxor.u32 %v43968_v22, %v43960_v27 (stack48)
        %v44385_v46 = vor.u32 %v44384_v30, %v44383_v32 (stack47)
        %v44818_v10 = vor.u32 %v44817_v6, %v44816_v10 (stack47)
        %v42429_v50 = vadd.f32 %v42425_v43, %v134749_v50 (stack53)
        %v42768_v6 = vmul.f32 0.6931472, %v120794_v44 (stack65)
        %v43579_v8 = vadd.s32 %v43576_v23, %v43571_v26 (stack40)
        %v43581_v29 = vshll.u32 %v43576_v23, 16 (stack45)
        %v43190_v53 = vand.u32 65535, %v43189_v9 (stack50)
        %v43582_v26 = vshrl.u32 %v43576_v23, 16 (stack46)
        %v43972_v31 = vadd.s32 %v43969_v20, %v121574_v2 (stack40)
        %v44386_v40 = vxor.u32 %v44385_v46, %v44377_v60 (stack48)
        %v42433_v41 = vmul.f32 %v42429_v50, %v134794_v41 (stack54)
        %v42774_v52 = vsel /*vm=*/%vm134850_vm1, /*on_true_vy=*/%v42771_v7, /*on_false_vx=*/%v42768_v6 (stack66)
        %v44814_v24 = vadd.s32 %v44810_v24, %v44806_v12 (stack40)
        %v157341_v11 = vld [vmem:[#allocation136_spill] sm:$0xff] (stack84)
        %v134864_v55 = vadd.s32 %v157341_v11, %v122651_v47 (stack40)
        %v42290_v25 = vand.u32 2147483647, %v134658_v34 (stack77)
        %v42322_v54 = vsel /*vm=*/%vm42317_vm12, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v134870_v21 = vxor.u32 2147483648, %v42774_v52 (stack56)
        %v43583_v32 = vor.u32 %v43582_v26, %v43581_v29 (stack47)
        %v42437_v42 = vadd.f32 %v42433_v41, %v42322_v54 (stack53)
        %v44819_v61 = vxor.u32 %v44818_v10, %v44814_v24 (stack48)
        %120795 = vrsqrt.f32 %v134870_v21 (stack67)
        %v43191_v22 = vshrl.u32 %v43190_v53, 1 (stack51)
        %v42298_v30 = vmul.f32 inf, %v134658_v34 (stack54)
        %v42441_v34 = vmul.f32 %v42437_v42, %v134658_v34 (stack54)
        %v43976_v43 = vadd.s32 2, %v43972_v31 (stack40)
        %vm42293_vm2 = vcmp.eq.f32.partialorder %v42290_v25, 1.0 (stack68)
        %v43584_v7 = vxor.u32 %v43583_v32, %v43579_v8 (stack48)
        %v43964_v27 = vadd.s32 %v43960_v27, %v121564_v0 (stack40)
        %v42445_v23 = vsel /*vm=*/%vm42293_vm2, /*on_true_vy=*/%v42298_v30, /*on_false_vx=*/%v42441_v34 (stack44)
        %v44381_v60 = vadd.s32 %v44377_v60, %v121569_v1 (stack40)
        %v44389_v12 = vadd.s32 %v44386_v40, %v121564_v0 (stack40)
        %v134880_v44 = vadd.s32 %v134864_v55, %v122657_v58 (stack40)
        %v42449_v9 = vmul.f32 1.4140625, %v42445_v23 (stack54)
        %vm42778_vm3 = vcmp.lt.f32.partialorder %v134870_v21, 5.0 (stack68)
        %v134884_v20 = vadd.f32 -2.5, %v134870_v21 (stack53)
        %v43192_v46 = vor.u32 16256, %v43191_v22 (stack47)
        %v43587_v10 = vadd.s32 %v43584_v7, %v43579_v8 (stack40)
        %v43593_v50 = vshll.u32 %v43584_v7, 24 (stack45)
        %v43594_v6 = vshrl.u32 %v43584_v7, 8 (stack46)
        %v43980_v8 = vadd.s32 %v43976_v43, %v43964_v27 (stack40)
        %v42452_v29 = vpack.c.bf16 %v156663_v45, %v42449_v9 (stack81)
        %v43193_v53 = vand.u32.u16 65535, %v43192_v46 (stack52)
        %v43982_v26 = vshll.u32 %v43976_v43, 13 (stack45)
        %v43983_v31 = vshrl.u32 %v43976_v43, 19 (stack46)
        %v134890_v40 = vsel /*vm=*/%vm42778_vm3, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %vm42823_vm4 = vcmp.eq.f32.partialorder %v134870_v21, inf (stack70)
        %v43595_v41 = vor.u32 %v43594_v6, %v43593_v50 (stack47)
        %v44393_v52 = vadd.s32 1, %v44389_v12 (stack40)
        %v134893_v24 = vadd.s32 %v44819_v61, %v44814_v24 (stack40)
        %119971 = vst [vmem:[%s123356_s30 + $0xac] sm:$0xf] /*vst_source=*/%v42452_v29 (stack83)
        %v119974_v25 = vadd.low.f32.bf16 -1.0, %v43193_v53 (stack53)
        %v43984_v54 = vor.u32 %v43983_v31, %v43982_v26 (stack47)
        %v44824_v32 = vshll.u32 %v44819_v61, 15 (stack45)
        %v44825_v42 = vshrl.u32 %v44819_v61, 17 (stack46)
        %v43596_v61 = vxor.u32 %v43595_v41, %v43587_v10 (stack48)
        %v44397_v22 = vadd.s32 %v44393_v52, %v44381_v60 (stack40)
        %v44399_v30 = vshll.u32 %v44393_v52, 17 (stack45)
        %v44400_v34 = vshrl.u32 %v44393_v52, 15 (stack46)
        %v134899_v43 = vsel /*vm=*/%vm42778_vm3, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v43202_v7 = vmul.f32 2.0, %v119974_v25 (stack54)
        %v43985_v27 = vxor.u32 %v43984_v54, %v43980_v8 (stack48)
        %v44826_v23 = vor.u32 %v44825_v42, %v44824_v32 (stack47)
        %v43599_v60 = vadd.s32 %v43596_v61, %v121564_v0 (stack40)
        %v44401_v12 = vor.u32 %v44400_v34, %v44399_v30 (stack47)
        %vm45275_vm5 = vcmp.lt.u32.totalorder %v134864_v55, %v122651_v47 (stack43)
        %v157342_v9 = vld [vmem:[#allocation98_spill] sm:$0xff] (stack84)
        %v45280_v46 = vadd.s32 %v157342_v9, %v157068_v28 (stack40)
        %v43206_v50 = vadd.f32 -0.99609375, %v43202_v7 (stack53)
        %v43988_v6 = vadd.s32 %v43985_v27, %v43980_v8 (stack40)
        %v43990_v8 = vshll.u32 %v43985_v27, 15 (stack45)
        %v43991_v29 = vshrl.u32 %v43985_v27, 17 (stack46)
        %v120796_v53 = vpop.eup %120795 (stack73)
        %v43591_v10 = vadd.s32 %v43587_v10, %v121569_v1 (stack40)
        %v43603_v26 = vadd.s32 4, %v43599_v60 (stack40)
        %v44402_v31 = vxor.u32 %v44401_v12, %v44397_v22 (stack48)
        %v44827_v41 = vxor.u32 %v44826_v23, %v134893_v24 (stack48)
        %v42822_v52 = vmul.f32 %v120796_v53, %v134870_v21 (stack74)
        %v42826_v25 = vand.u32 2147483648, %v134870_v21 (stack72)
        %v134910_v54 = vmax.f32 %v43206_v50, -0.99609375 (stack55)
        %v43992_v32 = vor.u32 %v43991_v29, %v43990_v8 (stack47)
        %v43607_v42 = vadd.s32 %v43603_v26, %v43591_v10 (stack40)
        %v43609_v61 = vshll.u32 %v43603_v26, 13 (stack45)
        %v43610_v30 = vshrl.u32 %v43603_v26, 19 (stack46)
        %v44405_v22 = vadd.s32 %v44402_v31, %v44397_v22 (stack40)
        %v42803_v34 = vsel /*vm=*/%vm42778_vm3, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v42824_v7 = vsel /*vm=*/%vm42823_vm4, /*on_true_vy=*/%v134870_v21, /*on_false_vx=*/%v42822_v52 (stack75)
        %vm42825_vm6 = vcmp.eq.f32.partialorder %v134870_v21, 0.0 (stack71)
        %v43222_v27 = vxor.u32 2147483648, %v134910_v54 (stack56)
        %v42807_v23 = vsel /*vm=*/%vm42778_vm3, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v42827_v60 = vsel /*vm=*/%vm42825_vm6, /*on_true_vy=*/%v42826_v25, /*on_false_vx=*/%v42824_v7 (stack76)
        %v43611_v12 = vor.u32 %v43610_v30, %v43609_v61 (stack47)
        %v43993_v50 = vxor.u32 %v43992_v32, %v43988_v6 (stack48)
        %v42830_v8 = vadd.f32 -3.0, %v42827_v60 (stack53)
        %v134924_v29 = vmul.f32 %v43222_v27, %v134910_v54 (stack54)
        %v44407_v53 = vshll.u32 %v44402_v31, 29 (stack45)
        %v44408_v10 = vshrl.u32 %v44402_v31, 3 (stack46)
        %v43612_v26 = vxor.u32 %v43611_v12, %v43607_v42 (stack48)
        %v43996_v6 = vadd.s32 %v43993_v50, %v43988_v6 (stack40)
        %v43998_v31 = vshll.u32 %v43993_v50, 26 (stack45)
        %v43999_v52 = vshrl.u32 %v43993_v50, 6 (stack46)
        %v42811_v25 = vsel /*vm=*/%vm42778_vm3, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v42815_v32 = vsel /*vm=*/%vm42778_vm3, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v134935_v20 = vsel /*vm=*/%vm42778_vm3, /*on_true_vy=*/%v134884_v20, /*on_false_vx=*/%v42830_v8 (stack44)
        %v43227_v61 = vadd.f32 1.0, %v134924_v29 (stack57)
        %v42838_v30 = vmul.f32 %v134935_v20, %v42815_v32 (stack54)
        %v43615_v42 = vadd.s32 %v43612_v26, %v43607_v42 (stack40)
        %v43617_v7 = vshll.u32 %v43612_v26, 15 (stack45)
        %v43618_v27 = vshrl.u32 %v43612_v26, 17 (stack46)
        %vm45270_vm7 = vcmp.lt.u32.totalorder %v134880_v44, %v134864_v55 (stack43)
        %120797 = vlog2.f32 %v43227_v61 (stack58)
        %v43230_v60 = vmul.f32 -0.5, %v134924_v29 (stack59)
        %v44000_v12 = vor.u32 %v43999_v52, %v43998_v31 (stack47)
        %v45284_v50 = vadd.s32 1, %v45280_v46 (stack40)
        %v42842_v8 = vadd.f32 %v42838_v30, %v42811_v25 (stack53)
        %v43619_v26 = vor.u32 %v43618_v27, %v43617_v7 (stack47)
        %v44409_v53 = vor.u32 %v44408_v10, %v44407_v53 (stack47)
        %v44830_v24 = vadd.s32 %v44827_v41, %v134893_v24 (stack40)
        %v43233_v10 = vand.u32 2147483647, %v134924_v29 (stack60)
        %v44001_v31 = vxor.u32 %v44000_v12, %v43996_v6 (stack48)
        %v44832_v52 = vshll.u32 %v44827_v41, 26 (stack45)
        %v44833_v41 = vshrl.u32 %v44827_v41, 6 (stack46)
        %v42846_v25 = vmul.f32 %v42842_v8, %v134935_v20 (stack54)
        %v43620_v32 = vxor.u32 %v43619_v26, %v43615_v42 (stack48)
        %v44410_v61 = vxor.u32 %v44409_v53, %v44405_v22 (stack48)
        %v45288_v46 = vsel /*vm=*/%vm45275_vm5, /*on_true_vy=*/%v45284_v50, /*on_false_vx=*/%v45280_v46 (stack44)
        %v44004_v6 = vadd.s32 %v44001_v31, %v43996_v6 (stack40)
        %v44010_v30 = vshll.u32 %v44001_v31, 6 (stack45)
        %v44011_v7 = vshrl.u32 %v44001_v31, 26 (stack46)
        %v44834_v27 = vor.u32 %v44833_v41, %v44832_v52 (stack47)
        %v42850_v23 = vadd.f32 %v42846_v25, %v42807_v23 (stack53)
        %v43623_v42 = vadd.s32 %v43620_v32, %v43615_v42 (stack40)
        %v43625_v12 = vshll.u32 %v43620_v32, 26 (stack45)
        %v43626_v50 = vshrl.u32 %v43620_v32, 6 (stack46)
        %v44012_v8 = vor.u32 %v44011_v7, %v44010_v30 (stack47)
        %v44413_v22 = vadd.s32 %v44410_v61, %v44405_v22 (stack40)
        %v44415_v26 = vshll.u32 %v44410_v61, 16 (stack45)
        %v134950_v53 = vadd.s32 %v134880_v44, %v121569_v1 (stack40)
        %v42854_v31 = vmul.f32 %v42850_v23, %v134935_v20 (stack54)
        %v43627_v52 = vor.u32 %v43626_v50, %v43625_v12 (stack47)
        %v44416_v41 = vshrl.u32 %v44410_v61, 16 (stack46)
        %v44835_v25 = vxor.u32 %v44834_v27, %v44830_v24 (stack48)
        %v43231_v60 = vadd.f32 1.0, %v43230_v60 (stack61)
        %vm134953_vm8 = vcmp.lt.f32.partialorder %v43233_v10, 0.0004427343 (stack62)
        %v44013_v32 = vxor.u32 %v44012_v8, %v44004_v6 (stack48)
        %v45292_v61 = vadd.s32 1, %v45288_v46 (stack40)
        %v42858_v34 = vadd.f32 %v42854_v31, %v42803_v34 (stack53)
        %v43628_v30 = vxor.u32 %v43627_v52, %v43623_v42 (stack48)
        %v44417_v7 = vor.u32 %v44416_v41, %v44415_v26 (stack47)
        %v44838_v24 = vadd.s32 %v44835_v25, %v44830_v24 (stack40)
        %v44016_v27 = vadd.s32 %v44013_v32, %v121569_v1 (stack40)
        %v44844_v23 = vshll.u32 %v44835_v25, 6 (stack45)
        %v44845_v12 = vshrl.u32 %v44835_v25, 26 (stack46)
        %v45296_v55 = vsel /*vm=*/%vm45270_vm7, /*on_true_vy=*/%v45292_v61, /*on_false_vx=*/%v45288_v46 (stack44)
        %v42862_v44 = vmul.f32 %v42858_v34, %v134935_v20 (stack54)
        %v43631_v46 = vadd.s32 %v43628_v30, %v43623_v42 (stack40)
        %v43637_v42 = vshll.u32 %v43628_v30, 6 (stack45)
        %v43638_v50 = vshrl.u32 %v43628_v30, 26 (stack46)
        %v44008_v6 = vadd.s32 %v44004_v6, %v121574_v2 (stack40)
        %v44020_v8 = vadd.s32 3, %v44016_v27 (stack40)
        %v44418_v26 = vxor.u32 %v44417_v7, %v44413_v22 (stack48)
        %v44846_v31 = vor.u32 %v44845_v12, %v44844_v23 (stack47)
        %v120798_v52 = vpop.eup %120797 (stack64)
        %v42866_v43 = vadd.f32 %v42862_v44, %v134899_v43 (stack53)
        %v43232_v29 = vmul.f32 %v43231_v60, %v134924_v29 (stack63)
        %v43639_v41 = vor.u32 %v43638_v50, %v43637_v42 (stack47)
        %v45301_v25 = vadd.s32 %v45296_v55, %v121574_v2 (stack40)
        %v43229_v60 = vmul.f32 0.6931472, %v120798_v52 (stack65)
        %v44024_v32 = vadd.s32 %v44020_v8, %v44008_v6 (stack40)
        %v44026_v61 = vshll.u32 %v44020_v8, 17 (stack45)
        %v44027_v34 = vshrl.u32 %v44020_v8, 15 (stack46)
        %v42870_v30 = vmul.f32 %v42866_v43, %v134935_v20 (stack54)
        %v43640_v7 = vxor.u32 %v43639_v41, %v43631_v46 (stack48)
        %v44421_v22 = vadd.s32 %v44418_v26, %v44413_v22 (stack40)
        %v44427_v27 = vshll.u32 %v44418_v26, 24 (stack45)
        %v43235_v10 = vsel /*vm=*/%vm134953_vm8, /*on_true_vy=*/%v43232_v29, /*on_false_vx=*/%v43229_v60 (stack66)
        %v44028_v23 = vor.u32 %v44027_v34, %v44026_v61 (stack47)
        %v44428_v12 = vshrl.u32 %v44418_v26, 8 (stack46)
        %v44847_v55 = vxor.u32 %v44846_v31, %v44838_v24 (stack48)
        %v42751_v44 = vand.u32 2147483647, %v134808_v56 (stack77)
        %v134971_v42 = vmul.f32 inf, %v134808_v56 (stack54)
        %v42874_v40 = vadd.f32 %v42870_v30, %v134890_v40 (stack53)
        %v134974_v50 = vxor.u32 2147483648, %v43235_v10 (stack56)
        %v42783_v6 = vsel /*vm=*/%vm42778_vm3, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v44029_v8 = vxor.u32 %v44028_v23, %v44024_v32 (stack48)
        %v44429_v26 = vor.u32 %v44428_v12, %v44427_v27 (stack47)
        %v45309_v31 = vadd.s32 %v134950_v53, %v45301_v25 (stack40)
        %v42787_v52 = vsel /*vm=*/%vm42778_vm3, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v42791_v21 = vsel /*vm=*/%vm42778_vm3, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v42878_v43 = vmul.f32 %v42874_v40, %v134935_v20 (stack54)
        %120799 = vrsqrt.f32 %v134974_v50 (stack67)
        %v43212_v29 = vand.u32 2147483647, %v134910_v54 (stack77)
        %vm43239_vm9 = vcmp.lt.f32.partialorder %v134974_v50, 5.0 (stack68)
        %v43643_v41 = vadd.s32 %v43640_v7, %v121574_v2 (stack40)
        %v44032_v25 = vadd.s32 %v44029_v8, %v44024_v32 (stack40)
        %v42882_v60 = vadd.f32 %v42878_v43, %v42791_v21 (stack53)
        %v44850_v32 = vadd.s32 %v44847_v55, %v121564_v0 (stack40)
        %v45311_v61 = vshll.u32 %v134950_v53, 13 (stack45)
        %v45312_v53 = vshrl.u32 %v134950_v53, 19 (stack46)
        %v43635_v46 = vadd.s32 %v43631_v46, %v121564_v0 (stack40)
        %v44425_v34 = vadd.s32 %v44421_v22, %v121564_v0 (stack40)
        %v44430_v30 = vxor.u32 %v44429_v26, %v44421_v22 (stack48)
        %v44842_v24 = vadd.s32 %v44838_v24, %v121569_v1 (stack40)
        %v42886_v7 = vmul.f32 %v42882_v60, %v134935_v20 (stack54)
        %v135001_v22 = vsel /*vm=*/%vm43239_vm9, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v135004_v27 = vadd.f32 -2.5, %v134974_v50 (stack53)
        %v43287_v10 = vand.u32 2147483648, %v134974_v50 (stack72)
        %vm135007_vm10 = vcmp.eq.f32.partialorder %v42751_v44, 1.0 (stack68)
        %v43647_v12 = vadd.s32 5, %v43643_v41 (stack40)
        %v44034_v55 = vshll.u32 %v44029_v8, 29 (stack45)
        %v44035_v44 = vshrl.u32 %v44029_v8, 3 (stack46)
        %v44433_v40 = vadd.s32 %v44430_v30, %v121574_v2 (stack40)
        %v42890_v8 = vadd.f32 %v42886_v7, %v42787_v52 (stack53)
        %v44854_v26 = vadd.s32 1, %v44850_v32 (stack40)
        %v45313_v52 = vor.u32 %v45312_v53, %v45311_v61 (stack47)
        %v135014_v21 = vadd.s32 %v157341_v11, %v157070_v38 (stack40)
        %vm43284_vm11 = vcmp.eq.f32.partialorder %v134974_v50, inf (stack70)
        %v43649_v43 = vxor.u32 %v43647_v12, %v43635_v46 (stack48)
        %v44036_v41 = vor.u32 %v44035_v44, %v44034_v55 (stack47)
        %v44437_v60 = vadd.s32 2, %v44433_v40 (stack40)
        %v135019_v32 = vadd.s32 %v157342_v9, %v157076_v35 (stack40)
        %v42894_v20 = vmul.f32 %v42890_v8, %v134935_v20 (stack54)
        %vm43286_vm12 = vcmp.eq.f32.partialorder %v134974_v50, 0.0 (stack71)
        %v44858_v61 = vadd.s32 %v44854_v26, %v44842_v24 (stack40)
        %v44860_v53 = vshll.u32 %v44854_v26, 17 (stack45)
        %v44861_v46 = vshrl.u32 %v44854_v26, 15 (stack46)
        %v43650_v30 = vand.u32.u8 255, %v43649_v43 (stack49)
        %v44037_v24 = vxor.u32 %v44036_v41, %v44032_v25 (stack48)
        %v44441_v34 = vadd.s32 %v44437_v60, %v44425_v34 (stack40)
        %v44443_v7 = vshll.u32 %v44437_v60, 13 (stack45)
        %v42898_v6 = vadd.f32 %v42894_v20, %v42783_v6 (stack53)
        %v44444_v12 = vshrl.u32 %v44437_v60, 19 (stack46)
        %v44862_v55 = vor.u32 %v44861_v46, %v44860_v53 (stack47)
        %v45314_v44 = vxor.u32 %v45313_v52, %v45309_v31 (stack48)
        %v43651_v40 = vand.u32 65535, %v43650_v30 (stack50)
        %v44040_v25 = vadd.s32 %v44037_v24, %v44032_v25 (stack40)
        %v44042_v8 = vshll.u32 %v44037_v24, 16 (stack45)
        %v44043_v26 = vshrl.u32 %v44037_v24, 16 (stack46)
        %v42902_v56 = vmul.f32 %v42898_v6, %v134808_v56 (stack54)
        %v44445_v52 = vor.u32 %v44444_v12, %v44443_v7 (stack47)
        %v44863_v43 = vxor.u32 %v44862_v55, %v44858_v61 (stack48)
        %v45317_v31 = vadd.s32 %v45314_v44, %v45309_v31 (stack40)
        %v120800_v41 = vpop.eup %120799 (stack73)
        %v43652_v60 = vshrl.u32 %v43651_v40, 1 (stack51)
        %v44044_v20 = vor.u32 %v44043_v26, %v44042_v8 (stack47)
        %v45319_v53 = vshll.u32 %v45314_v44, 15 (stack45)
        %v45320_v46 = vshrl.u32 %v45314_v44, 17 (stack46)
        %v42906_v42 = vsel /*vm=*/%vm135007_vm10, /*on_true_vy=*/%v134971_v42, /*on_false_vx=*/%v42902_v56 (stack44)
        %v43283_v23 = vmul.f32 %v120800_v41, %v134974_v50 (stack74)
        %v44446_v30 = vxor.u32 %v44445_v52, %v44441_v34 (stack48)
        %v44866_v61 = vadd.s32 %v44863_v43, %v44858_v61 (stack40)
        %v42910_v24 = vmul.f32 1.4140625, %v42906_v42 (stack54)
        %v43653_v7 = vor.u32 16256, %v43652_v60 (stack47)
        %v44045_v6 = vxor.u32 %v44044_v20, %v44040_v25 (stack48)
        %v44868_v12 = vshll.u32 %v44863_v43, 29 (stack45)
        %v43285_v55 = vsel /*vm=*/%vm43284_vm11, /*on_true_vy=*/%v134974_v50, /*on_false_vx=*/%v43283_v23 (stack75)
        %v44449_v34 = vadd.s32 %v44446_v30, %v44441_v34 (stack40)
        %v44451_v44 = vshll.u32 %v44446_v30, 15 (stack45)
        %v44452_v40 = vshrl.u32 %v44446_v30, 17 (stack46)
        %v42913_v8 = vpack.c.bf16 %v156663_v45, %v42910_v24 (stack81)
        %v43288_v10 = vsel /*vm=*/%vm43286_vm12, /*on_true_vy=*/%v43287_v10, /*on_false_vx=*/%v43285_v55 (stack76)
        %v43654_v26 = vand.u32.u16 65535, %v43653_v7 (stack52)
        %v44048_v25 = vadd.s32 %v44045_v6, %v44040_v25 (stack40)
        %v43291_v56 = vadd.f32 -3.0, %v43288_v10 (stack53)
        %v44054_v52 = vshll.u32 %v44045_v6, 24 (stack45)
        %v44055_v41 = vshrl.u32 %v44045_v6, 8 (stack46)
        %v44453_v60 = vor.u32 %v44452_v40, %v44451_v44 (stack47)
        %119973 = vst [vmem:[%s123356_s30 + $0x12c] sm:$0xf] /*vst_source=*/%v42913_v8 (stack83)
        %v43272_v20 = vsel /*vm=*/%vm43239_vm9, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v119976_v42 = vadd.low.f32.bf16 -1.0, %v43654_v26 (stack53)
        %v44869_v43 = vshrl.u32 %v44863_v43, 3 (stack46)
        %v45321_v53 = vor.u32 %v45320_v46, %v45319_v53 (stack47)
        %v43276_v46 = vsel /*vm=*/%vm43239_vm9, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v135044_v27 = vsel /*vm=*/%vm43239_vm9, /*on_true_vy=*/%v135004_v27, /*on_false_vx=*/%v43291_v56 (stack44)
        %v44056_v23 = vor.u32 %v44055_v41, %v44054_v52 (stack47)
        %v44454_v30 = vxor.u32 %v44453_v60, %v44449_v34 (stack48)
        %v43299_v24 = vmul.f32 %v135044_v27, %v43276_v46 (stack54)
        %v43663_v7 = vmul.f32 2.0, %v119976_v42 (stack54)
        %v44870_v6 = vor.u32 %v44869_v43, %v44868_v12 (stack47)
        %v45322_v12 = vxor.u32 %v45321_v53, %v45317_v31 (stack48)
        %v44057_v55 = vxor.u32 %v44056_v23, %v44048_v25 (stack48)
        %v44457_v34 = vadd.s32 %v44454_v30, %v44449_v34 (stack40)
        %v44459_v44 = vshll.u32 %v44454_v30, 26 (stack45)
        %v44460_v40 = vshrl.u32 %v44454_v30, 6 (stack46)
        %v43303_v8 = vadd.f32 %v43299_v24, %v43272_v20 (stack53)
        %v43667_v10 = vadd.f32 -0.99609375, %v43663_v7 (stack53)
        %v44871_v26 = vxor.u32 %v44870_v6, %v44866_v61 (stack48)
        %v45325_v31 = vadd.s32 %v45322_v12, %v45317_v31 (stack40)
        %v44060_v56 = vadd.s32 %v44057_v55, %v121564_v0 (stack40)
        %v44461_v52 = vor.u32 %v44460_v40, %v44459_v44 (stack47)
        %v45327_v41 = vshll.u32 %v45322_v12, 26 (stack45)
        %v45328_v60 = vshrl.u32 %v45322_v12, 6 (stack46)
        %v43307_v20 = vmul.f32 %v43303_v8, %v135044_v27 (stack54)
        %v135049_v42 = vmax.f32 %v43667_v10, -0.99609375 (stack55)
        %v44052_v25 = vadd.s32 %v44048_v25, %v121569_v1 (stack40)
        %v44874_v61 = vadd.s32 %v44871_v26, %v44866_v61 (stack40)
        %v44064_v43 = vadd.s32 4, %v44060_v56 (stack40)
        %v44462_v53 = vxor.u32 %v44461_v52, %v44457_v34 (stack48)
        %v44876_v46 = vshll.u32 %v44871_v26, 16 (stack45)
        %v44877_v23 = vshrl.u32 %v44871_v26, 16 (stack46)
        %v135055_v30 = vsel /*vm=*/%vm43239_vm9, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v43311_v22 = vadd.f32 %v43307_v20, %v135001_v22 (stack53)
        %v43683_v24 = vxor.u32 2147483648, %v135049_v42 (stack56)
        %v45329_v7 = vor.u32 %v45328_v60, %v45327_v41 (stack47)
        %v44068_v6 = vadd.s32 %v44064_v43, %v44052_v25 (stack40)
        %v44070_v12 = vshll.u32 %v44064_v43, 13 (stack45)
        %v44071_v55 = vshrl.u32 %v44064_v43, 19 (stack46)
        %v44465_v34 = vadd.s32 %v44462_v53, %v44457_v34 (stack40)
        %v135062_v44 = vsel /*vm=*/%vm43239_vm9, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v43315_v40 = vmul.f32 %v43311_v22, %v135044_v27 (stack54)
        %v43686_v8 = vmul.f32 %v43683_v24, %v135049_v42 (stack54)
        %v44471_v10 = vshll.u32 %v44462_v53, 6 (stack45)
        %v43264_v26 = vsel /*vm=*/%vm43239_vm9, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v44072_v56 = vor.u32 %v44071_v55, %v44070_v12 (stack47)
        %v44472_v52 = vshrl.u32 %v44462_v53, 26 (stack46)
        %v44878_v41 = vor.u32 %v44877_v23, %v44876_v46 (stack47)
        %v43252_v60 = vsel /*vm=*/%vm43239_vm9, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v43256_v20 = vsel /*vm=*/%vm43239_vm9, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v43319_v25 = vadd.f32 %v43315_v40, %v43264_v26 (stack53)
        %v43688_v43 = vadd.f32 1.0, %v43686_v8 (stack57)
        %v44073_v53 = vxor.u32 %v44072_v56, %v44068_v6 (stack48)
        %v44473_v46 = vor.u32 %v44472_v52, %v44471_v10 (stack47)
        %v44879_v23 = vxor.u32 %v44878_v41, %v44874_v61 (stack48)
        %v45330_v22 = vxor.u32 %v45329_v7, %v45325_v31 (stack48)
        %v43260_v50 = vsel /*vm=*/%vm43239_vm9, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v43323_v24 = vmul.f32 %v43319_v25, %v135044_v27 (stack54)
        %120801 = vlog2.f32 %v43688_v43 (stack58)
        %v135081_v7 = vadd.s32 %v135014_v21, %v122657_v58 (stack40)
        %v44076_v6 = vadd.s32 %v44073_v53, %v44068_v6 (stack40)
        %v44078_v12 = vshll.u32 %v44073_v53, 15 (stack45)
        %v44079_v55 = vshrl.u32 %v44073_v53, 17 (stack46)
        %v44474_v40 = vxor.u32 %v44473_v46, %v44465_v34 (stack48)
        %v43327_v10 = vadd.f32 %v43323_v24, %v43260_v50 (stack53)
        %v43691_v26 = vmul.f32 -0.5, %v43686_v8 (stack59)
        %v44882_v61 = vadd.s32 %v44879_v23, %v44874_v61 (stack40)
        %v44888_v56 = vshll.u32 %v44879_v23, 24 (stack45)
        %v44080_v52 = vor.u32 %v44079_v55, %v44078_v12 (stack47)
        %v44477_v41 = vadd.s32 %v44474_v40, %v121569_v1 (stack40)
        %v44889_v25 = vshrl.u32 %v44879_v23, 8 (stack46)
        %v45333_v31 = vadd.s32 %v45330_v22, %v45325_v31 (stack40)
        %v43331_v43 = vmul.f32 %v43327_v10, %v135044_v27 (stack54)
        %v44469_v34 = vadd.s32 %v44465_v34, %v121574_v2 (stack40)
        %v45339_v53 = vshll.u32 %v45330_v22, 6 (stack45)
        %v45340_v46 = vshrl.u32 %v45330_v22, 26 (stack46)
        %v43694_v23 = vand.u32 2147483647, %v43686_v8 (stack60)
        %v44081_v22 = vxor.u32 %v44080_v52, %v44076_v6 (stack48)
        %v44481_v50 = vadd.s32 3, %v44477_v41 (stack40)
        %v44890_v24 = vor.u32 %v44889_v25, %v44888_v56 (stack47)
        %v43335_v20 = vadd.f32 %v43331_v43, %v43256_v20 (stack53)
        %v43692_v12 = vadd.f32 1.0, %v43691_v26 (stack61)
        %v45341_v55 = vor.u32 %v45340_v46, %v45339_v53 (stack47)
        %vm45736_vm13 = vcmp.lt.u32.totalorder %v135014_v21, %v157070_v38 (stack43)
        %v44084_v6 = vadd.s32 %v44081_v22, %v44076_v6 (stack40)
        %v44086_v40 = vshll.u32 %v44081_v22, 26 (stack45)
        %v44087_v10 = vshrl.u32 %v44081_v22, 6 (stack46)
        %v44485_v26 = vadd.s32 %v44481_v50, %v44469_v34 (stack40)
        %v43339_v56 = vmul.f32 %v43335_v20, %v135044_v27 (stack54)
        %v44487_v52 = vshll.u32 %v44481_v50, 17 (stack45)
        %v44488_v41 = vshrl.u32 %v44481_v50, 15 (stack46)
        %v44891_v25 = vxor.u32 %v44890_v24, %v44882_v61 (stack48)
        %vm135089_vm14 = vcmp.lt.f32.partialorder %v43694_v23, 0.0004427343 (stack62)
        %v44088_v34 = vor.u32 %v44087_v10, %v44086_v40 (stack47)
        %v45342_v53 = vxor.u32 %v45341_v55, %v45333_v31 (stack48)
        %v45745_v46 = vadd.s32 1, %v135019_v32 (stack40)
        %v43343_v60 = vadd.f32 %v43339_v56, %v43252_v60 (stack53)
        %v44489_v23 = vor.u32 %v44488_v41, %v44487_v52 (stack47)
        %v44894_v22 = vadd.s32 %v44891_v25, %v121574_v2 (stack40)
        %v135097_v50 = vadd.s32 %v157341_v11, %v157077_v51 (stack40)
        %v43693_v8 = vmul.f32 %v43692_v12, %v43686_v8 (stack63)
        %v44089_v24 = vxor.u32 %v44088_v34, %v44084_v6 (stack48)
        %v45345_v20 = vadd.s32 %v45342_v53, %v121564_v0 (stack40)
        %v45749_v32 = vsel /*vm=*/%vm45736_vm13, /*on_true_vy=*/%v45745_v46, /*on_false_vx=*/%v135019_v32 (stack44)
        %v43347_v12 = vmul.f32 %v43343_v60, %v135044_v27 (stack54)
        %v44490_v55 = vxor.u32 %v44489_v23, %v44485_v26 (stack48)
        %v44886_v61 = vadd.s32 %v44882_v61, %v121564_v0 (stack40)
        %v44898_v40 = vadd.s32 2, %v44894_v22 (stack40)
        %v120802_v10 = vpop.eup %120801 (stack64)
        %v44092_v6 = vadd.s32 %v44089_v24, %v44084_v6 (stack40)
        %v44098_v56 = vshll.u32 %v44089_v24, 6 (stack45)
        %v44099_v52 = vshrl.u32 %v44089_v24, 26 (stack46)
        %v45349_v41 = vadd.s32 1, %v45345_v20 (stack40)
        %v43351_v44 = vadd.f32 %v43347_v12, %v135062_v44 (stack53)
        %v43690_v25 = vmul.f32 0.6931472, %v120802_v10 (stack65)
        %v44493_v26 = vadd.s32 %v44490_v55, %v44485_v26 (stack40)
        %v45337_v31 = vadd.s32 %v45333_v31, %v121569_v1 (stack40)
        %v44100_v34 = vor.u32 %v44099_v52, %v44098_v56 (stack47)
        %v44495_v53 = vshll.u32 %v44490_v55, 29 (stack45)
        %v44496_v46 = vshrl.u32 %v44490_v55, 3 (stack46)
        %v44902_v60 = vadd.s32 %v44898_v40, %v44886_v61 (stack40)
        %v43355_v27 = vmul.f32 %v43351_v44, %v135044_v27 (stack54)
        %v43696_v43 = vsel /*vm=*/%vm135089_vm14, /*on_true_vy=*/%v43693_v8, /*on_false_vx=*/%v43690_v25 (stack66)
        %v44904_v23 = vshll.u32 %v44898_v40, 13 (stack45)
        %v44905_v22 = vshrl.u32 %v44898_v40, 19 (stack46)
        %v135111_v8 = vxor.u32 2147483648, %v43696_v43 (stack56)
        %v44101_v24 = vxor.u32 %v44100_v34, %v44092_v6 (stack48)
        %v45353_v20 = vadd.s32 %v45349_v41, %v45337_v31 (stack40)
        %v45766_v12 = vadd.s32 %v135081_v7, %v121569_v1 (stack40)
        %vm135117_vm15 = vcmp.eq.f32.partialorder %v43212_v29, 1.0 (stack68)
        %v43220_v55 = vmul.f32 inf, %v134910_v54 (stack54)
        %v43359_v30 = vadd.f32 %v43355_v27, %v135055_v30 (stack53)
        %v43673_v61 = vand.u32 2147483647, %v135049_v42 (stack77)
        %vm43700_vm0 = vcmp.lt.f32.partialorder %v135111_v8, 5.0 (stack68)
        %120803 = vrsqrt.f32 %v135111_v8 (stack67)
        %v44497_v40 = vor.u32 %v44496_v46, %v44495_v53 (stack47)
        %v45753_v10 = vadd.s32 1, %v45749_v32 (stack40)
        %v43363_v54 = vmul.f32 %v43359_v30, %v134910_v54 (stack54)
        %v44906_v56 = vor.u32 %v44905_v22, %v44904_v23 (stack47)
        %v45355_v52 = vshll.u32 %v45349_v41, 17 (stack45)
        %v45356_v41 = vshrl.u32 %v45349_v41, 15 (stack46)
        %v44096_v6 = vadd.s32 %v44092_v6, %v121564_v0 (stack40)
        %v44104_v44 = vadd.s32 %v44101_v24, %v121574_v2 (stack40)
        %vm45731_vm1 = vcmp.lt.u32.totalorder %v135081_v7, %v135014_v21 (stack43)
        %v45772_v21 = vshll.u32 %v45766_v12, 13 (stack45)
        %v43367_v7 = vsel /*vm=*/%vm135117_vm15, /*on_true_vy=*/%v43220_v55, /*on_false_vx=*/%v43363_v54 (stack44)
        %v135136_v25 = vsel /*vm=*/%vm43700_vm0, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v135141_v31 = vsel /*vm=*/%vm43700_vm0, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v135144_v34 = vadd.f32 -2.5, %v135111_v8 (stack53)
        %v43371_v53 = vmul.f32 1.4140625, %v43367_v7 (stack54)
        %v135149_v46 = vsel /*vm=*/%vm43700_vm0, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v135154_v27 = vsel /*vm=*/%vm43700_vm0, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v44108_v43 = vadd.s32 5, %v44104_v44 (stack40)
        %v44498_v23 = vxor.u32 %v44497_v40, %v44493_v26 (stack48)
        %v44907_v22 = vxor.u32 %v44906_v56, %v44902_v60 (stack48)
        %v45357_v24 = vor.u32 %v45356_v41, %v45355_v52 (stack47)
        %v45757_v32 = vsel /*vm=*/%vm45731_vm1, /*on_true_vy=*/%v45753_v10, /*on_false_vx=*/%v45749_v32 (stack44)
        %v43374_v29 = vpack.c.bf16 %v156663_v45, %v43371_v53 (stack81)
        %v44110_v55 = vxor.u32 %v44108_v43, %v44096_v6 (stack48)
        %v45762_v30 = vadd.s32 %v45757_v32, %v121574_v2 (stack40)
        %v45773_v40 = vshrl.u32 %v45766_v12, 19 (stack46)
        %vm43745_vm2 = vcmp.eq.f32.partialorder %v135111_v8, inf (stack70)
        %v44501_v26 = vadd.s32 %v44498_v23, %v44493_v26 (stack40)
        %v44503_v10 = vshll.u32 %v44498_v23, 16 (stack45)
        %v44504_v54 = vshrl.u32 %v44498_v23, 16 (stack46)
        %v44910_v60 = vadd.s32 %v44907_v22, %v44902_v60 (stack40)
        %119975 = vst [vmem:[%s123356_s30 + $0x1ac] sm:$0xf] /*vst_source=*/%v43374_v29 (stack83)
        %v44111_v56 = vand.u32.u8 255, %v44110_v55 (stack49)
        %v44912_v52 = vshll.u32 %v44907_v22, 15 (stack45)
        %v44913_v41 = vshrl.u32 %v44907_v22, 17 (stack46)
        %v45358_v6 = vxor.u32 %v45357_v24, %v45353_v20 (stack48)
        %v43733_v44 = vsel /*vm=*/%vm43700_vm0, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v44505_v7 = vor.u32 %v44504_v54, %v44503_v10 (stack47)
        %v45770_v12 = vadd.s32 %v45766_v12, %v45762_v30 (stack40)
        %v45774_v21 = vor.u32 %v45773_v40, %v45772_v21 (stack47)
        %v44112_v53 = vand.u32 65535, %v44111_v56 (stack50)
        %v44914_v43 = vor.u32 %v44913_v41, %v44912_v52 (stack47)
        %v45361_v20 = vadd.s32 %v45358_v6, %v45353_v20 (stack40)
        %v45363_v23 = vshll.u32 %v45358_v6, 29 (stack45)
        %v43737_v22 = vsel /*vm=*/%vm43700_vm0, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v44506_v24 = vxor.u32 %v44505_v7, %v44501_v26 (stack48)
        %v45364_v32 = vshrl.u32 %v45358_v6, 3 (stack46)
        %v45775_v29 = vxor.u32 %v45774_v21, %v45770_v12 (stack48)
        %v44113_v55 = vshrl.u32 %v44112_v53, 1 (stack51)
        %v44915_v30 = vxor.u32 %v44914_v43, %v44910_v60 (stack48)
        %vm46197_vm3 = vcmp.lt.u32.totalorder %v135097_v50, %v157077_v51 (stack43)
        %v135170_v40 = vadd.s32 %v157342_v9, %v157078_v48 (stack40)
        %v120804_v10 = vpop.eup %120803 (stack73)
        %v44509_v26 = vadd.s32 %v44506_v24, %v44501_v26 (stack40)
        %v44515_v54 = vshll.u32 %v44506_v24, 24 (stack45)
        %v44516_v56 = vshrl.u32 %v44506_v24, 8 (stack46)
        %v45365_v52 = vor.u32 %v45364_v32, %v45363_v23 (stack47)
        %v43744_v41 = vmul.f32 %v120804_v10, %v135111_v8 (stack74)
        %v44114_v6 = vor.u32 16256, %v44113_v55 (stack47)
        %v44918_v60 = vadd.s32 %v44915_v30, %v44910_v60 (stack40)
        %v44920_v7 = vshll.u32 %v44915_v30, 26 (stack45)
        %v43748_v21 = vand.u32 2147483648, %v135111_v8 (stack72)
        %v44517_v53 = vor.u32 %v44516_v56, %v44515_v54 (stack47)
        %v44921_v43 = vshrl.u32 %v44915_v30, 6 (stack46)
        %v45366_v23 = vxor.u32 %v45365_v52, %v45361_v20 (stack48)
        %v43746_v24 = vsel /*vm=*/%vm43745_vm2, /*on_true_vy=*/%v135111_v8, /*on_false_vx=*/%v43744_v41 (stack75)
        %vm43747_vm4 = vcmp.eq.f32.partialorder %v135111_v8, 0.0 (stack71)
        %v44115_v32 = vand.u32.u16 65535, %v44114_v6 (stack52)
        %v45778_v12 = vadd.s32 %v45775_v29, %v45770_v12 (stack40)
        %v43749_v55 = vsel /*vm=*/%vm43747_vm4, /*on_true_vy=*/%v43748_v21, /*on_false_vx=*/%v43746_v24 (stack76)
        %v44518_v30 = vxor.u32 %v44517_v53, %v44509_v26 (stack48)
        %v44922_v10 = vor.u32 %v44921_v43, %v44920_v7 (stack47)
        %v45369_v20 = vadd.s32 %v45366_v23, %v45361_v20 (stack40)
        %v43752_v54 = vadd.f32 -3.0, %v43749_v55 (stack53)
        %v119978_v56 = vadd.low.f32.bf16 -1.0, %v44115_v32 (stack53)
        %v45371_v52 = vshll.u32 %v45366_v23, 16 (stack45)
        %v45372_v41 = vshrl.u32 %v45366_v23, 16 (stack46)
        %v44513_v26 = vadd.s32 %v44509_v26, %v121569_v1 (stack40)
        %v44521_v6 = vadd.s32 %v44518_v30, %v121564_v0 (stack40)
        %v44923_v7 = vxor.u32 %v44922_v10, %v44918_v60 (stack48)
        %v45780_v21 = vshll.u32 %v45775_v29, 15 (stack45)
        %v135183_v34 = vsel /*vm=*/%vm43700_vm0, /*on_true_vy=*/%v135144_v34, /*on_false_vx=*/%v43752_v54 (stack44)
        %v44124_v53 = vmul.f32 2.0, %v119978_v56 (stack54)
        %v45373_v43 = vor.u32 %v45372_v41, %v45371_v52 (stack47)
        %v45781_v29 = vshrl.u32 %v45775_v29, 17 (stack46)
        %v43760_v22 = vmul.f32 %v135183_v34, %v43737_v22 (stack54)
        %v44525_v23 = vadd.s32 4, %v44521_v6 (stack40)
        %v44926_v60 = vadd.s32 %v44923_v7, %v44918_v60 (stack40)
        %v44932_v24 = vshll.u32 %v44923_v7, 6 (stack45)
        %v44128_v32 = vadd.f32 -0.99609375, %v44124_v53 (stack53)
        %v44933_v55 = vshrl.u32 %v44923_v7, 26 (stack46)
        %v45374_v30 = vxor.u32 %v45373_v43, %v45369_v20 (stack48)
        %v135188_v10 = vadd.s32 %v135097_v50, %v122657_v58 (stack40)
        %v43764_v44 = vadd.f32 %v43760_v22, %v43733_v44 (stack53)
        %v44529_v54 = vadd.s32 %v44525_v23, %v44513_v26 (stack40)
        %v44531_v56 = vshll.u32 %v44525_v23, 13 (stack45)
        %v44532_v52 = vshrl.u32 %v44525_v23, 19 (stack46)
        %v135190_v41 = vmax.f32 %v44128_v32, -0.99609375 (stack55)
        %v44934_v26 = vor.u32 %v44933_v55, %v44932_v24 (stack47)
        %v45377_v20 = vadd.s32 %v45374_v30, %v45369_v20 (stack40)
        %v45782_v6 = vor.u32 %v45781_v29, %v45780_v21 (stack47)
        %v43768_v7 = vmul.f32 %v43764_v44, %v135183_v34 (stack54)
        %v44533_v21 = vor.u32 %v44532_v52, %v44531_v56 (stack47)
        %v45383_v53 = vshll.u32 %v45374_v30, 24 (stack45)
        %v45384_v43 = vshrl.u32 %v45374_v30, 8 (stack46)
        %v43721_v29 = vsel /*vm=*/%vm43700_vm0, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v43729_v22 = vsel /*vm=*/%vm43700_vm0, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v44144_v23 = vxor.u32 2147483648, %v135190_v41 (stack56)
        %v44935_v24 = vxor.u32 %v44934_v26, %v44926_v60 (stack48)
        %v43725_v8 = vsel /*vm=*/%vm43700_vm0, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v43772_v32 = vadd.f32 %v43768_v7, %v43729_v22 (stack53)
        %v44534_v55 = vxor.u32 %v44533_v21, %v44529_v54 (stack48)
        %v45385_v30 = vor.u32 %v45384_v43, %v45383_v53 (stack47)
        %v135204_v44 = vmul.f32 %v44144_v23, %v135190_v41 (stack54)
        %v44938_v56 = vadd.s32 %v44935_v24, %v121569_v1 (stack40)
        %v45783_v52 = vxor.u32 %v45782_v6, %v45778_v12 (stack48)
        %vm46192_vm5 = vcmp.lt.u32.totalorder %v135188_v10, %v135097_v50 (stack43)
        %v46206_v26 = vadd.s32 1, %v135170_v40 (stack40)
        %v43776_v6 = vmul.f32 %v43772_v32, %v135183_v34 (stack54)
        %v44537_v54 = vadd.s32 %v44534_v55, %v44529_v54 (stack40)
        %v44539_v7 = vshll.u32 %v44534_v55, 15 (stack45)
        %v44540_v21 = vshrl.u32 %v44534_v55, 17 (stack46)
        %v44149_v53 = vadd.f32 1.0, %v135204_v44 (stack57)
        %v44930_v60 = vadd.s32 %v44926_v60, %v121574_v2 (stack40)
        %v44942_v43 = vadd.s32 3, %v44938_v56 (stack40)
        %v135215_v22 = vadd.s32 %v135188_v10, %v121569_v1 (stack40)
        %v43780_v23 = vadd.f32 %v43776_v6, %v43725_v8 (stack53)
        %v44541_v24 = vor.u32 %v44540_v21, %v44539_v7 (stack47)
        %v45386_v8 = vxor.u32 %v45385_v30, %v45377_v20 (stack48)
        %v45786_v12 = vadd.s32 %v45783_v52, %v45778_v12 (stack40)
        %120805 = vlog2.f32 %v44149_v53 (stack58)
        %v44152_v32 = vmul.f32 -0.5, %v135204_v44 (stack59)
        %v44946_v55 = vadd.s32 %v44942_v43, %v44930_v60 (stack40)
        %v45381_v20 = vadd.s32 %v45377_v20, %v121564_v0 (stack40)
        %v43784_v30 = vmul.f32 %v43780_v23, %v135183_v34 (stack54)
        %v44542_v56 = vxor.u32 %v44541_v24, %v44537_v54 (stack48)
        %v44948_v6 = vshll.u32 %v44942_v43, 17 (stack45)
        %v44949_v7 = vshrl.u32 %v44942_v43, 15 (stack46)
        %v44155_v21 = vand.u32 2147483647, %v135204_v44 (stack60)
        %v45389_v53 = vadd.s32 %v45386_v8, %v121574_v2 (stack40)
        %v45788_v60 = vshll.u32 %v45783_v52, 26 (stack45)
        %v45789_v52 = vshrl.u32 %v45783_v52, 6 (stack46)
        %v43788_v29 = vadd.f32 %v43784_v30, %v43721_v29 (stack53)
        %v44545_v54 = vadd.s32 %v44542_v56, %v44537_v54 (stack40)
        %v44547_v43 = vshll.u32 %v44542_v56, 26 (stack45)
        %v44548_v23 = vshrl.u32 %v44542_v56, 6 (stack46)
        %v44950_v24 = vor.u32 %v44949_v7, %v44948_v6 (stack47)
        %v45393_v8 = vadd.s32 2, %v45389_v53 (stack40)
        %v45790_v30 = vor.u32 %v45789_v52, %v45788_v60 (stack47)
        %v46210_v40 = vsel /*vm=*/%vm46197_vm3, /*on_true_vy=*/%v46206_v26, /*on_false_vx=*/%v135170_v40 (stack44)
        %v43792_v26 = vmul.f32 %v43788_v29, %v135183_v34 (stack54)
        %v44153_v32 = vadd.f32 1.0, %v44152_v32 (stack61)
        %v44549_v56 = vor.u32 %v44548_v23, %v44547_v43 (stack47)
        %v46214_v6 = vadd.s32 1, %v46210_v40 (stack40)
        %v44951_v7 = vxor.u32 %v44950_v24, %v44946_v55 (stack48)
        %v45397_v20 = vadd.s32 %v45393_v8, %v45381_v20 (stack40)
        %v45399_v53 = vshll.u32 %v45393_v8, 13 (stack45)
        %v45400_v60 = vshrl.u32 %v45393_v8, 19 (stack46)
        %v43796_v27 = vadd.f32 %v43792_v26, %v135154_v27 (stack53)
        %v44550_v52 = vxor.u32 %v44549_v56, %v44545_v54 (stack48)
        %v45791_v29 = vxor.u32 %v45790_v30, %v45786_v12 (stack48)
        %v46218_v50 = vsel /*vm=*/%vm46192_vm5, /*on_true_vy=*/%v46214_v6, /*on_false_vx=*/%v46210_v40 (stack44)
        %v44954_v10 = vadd.s32 %v44951_v7, %v44946_v55 (stack40)
        %v44956_v55 = vshll.u32 %v44951_v7, 29 (stack45)
        %v44957_v43 = vshrl.u32 %v44951_v7, 3 (stack46)
        %v45401_v23 = vor.u32 %v45400_v60, %v45399_v53 (stack47)
        %v43800_v24 = vmul.f32 %v43796_v27, %v135183_v34 (stack54)
        %v44553_v54 = vadd.s32 %v44550_v52, %v44545_v54 (stack40)
        %v44559_v8 = vshll.u32 %v44550_v52, 6 (stack45)
        %v44560_v30 = vshrl.u32 %v44550_v52, 26 (stack46)
        %v44958_v40 = vor.u32 %v44957_v43, %v44956_v55 (stack47)
        %v45402_v26 = vxor.u32 %v45401_v23, %v45397_v20 (stack48)
        %v45794_v12 = vadd.s32 %v45791_v29, %v45786_v12 (stack40)
        %v45800_v56 = vshll.u32 %v45791_v29, 6 (stack45)
        %v43804_v46 = vadd.f32 %v43800_v24, %v135149_v46 (stack53)
        %vm135233_vm6 = vcmp.lt.f32.partialorder %v44155_v21, 0.0004427343 (stack62)
        %v44561_v6 = vor.u32 %v44560_v30, %v44559_v8 (stack47)
        %v45801_v7 = vshrl.u32 %v45791_v29, 26 (stack46)
        %v44959_v53 = vxor.u32 %v44958_v40, %v44954_v10 (stack48)
        %v45405_v20 = vadd.s32 %v45402_v26, %v45397_v20 (stack40)
        %v45407_v60 = vshll.u32 %v45402_v26, 15 (stack45)
        %v45408_v27 = vshrl.u32 %v45402_v26, 17 (stack46)
        %v120806_v52 = vpop.eup %120805 (stack64)
        %v43808_v29 = vmul.f32 %v43804_v46, %v135183_v34 (stack54)
        %v44154_v44 = vmul.f32 %v44153_v32, %v135204_v44 (stack63)
        %v44562_v32 = vxor.u32 %v44561_v6, %v44553_v54 (stack48)
        %v45802_v55 = vor.u32 %v45801_v7, %v45800_v56 (stack47)
        %v44151_v43 = vmul.f32 0.6931472, %v120806_v52 (stack65)
        %v44962_v10 = vadd.s32 %v44959_v53, %v44954_v10 (stack40)
        %v44964_v23 = vshll.u32 %v44959_v53, 16 (stack45)
        %v44965_v24 = vshrl.u32 %v44959_v53, 16 (stack46)
        %v43812_v31 = vadd.f32 %v43808_v29, %v135141_v31 (stack53)
        %v44565_v8 = vadd.s32 %v44562_v32, %v121574_v2 (stack40)
        %v45409_v30 = vor.u32 %v45408_v27, %v45407_v60 (stack47)
        %v45803_v40 = vxor.u32 %v45802_v55, %v45794_v12 (stack48)
        %v44157_v26 = vsel /*vm=*/%vm135233_vm6, /*on_true_vy=*/%v44154_v44, /*on_false_vx=*/%v44151_v43 (stack66)
        %v44966_v56 = vor.u32 %v44965_v24, %v44964_v23 (stack47)
        %v46223_v50 = vadd.s32 %v46218_v50, %v121574_v2 (stack40)
        %v46233_v46 = vshll.u32 %v135215_v22, 13 (stack45)
        %v43816_v34 = vmul.f32 %v43812_v31, %v135183_v34 (stack54)
        %v135246_v21 = vxor.u32 2147483648, %v44157_v26 (stack56)
        %v44569_v6 = vadd.s32 5, %v44565_v8 (stack40)
        %v45410_v7 = vxor.u32 %v45409_v30, %v45405_v20 (stack48)
        %v44557_v54 = vadd.s32 %v44553_v54, %v121564_v0 (stack40)
        %v44967_v53 = vxor.u32 %v44966_v56, %v44962_v10 (stack48)
        %v46231_v60 = vadd.s32 %v135215_v22, %v46223_v50 (stack40)
        %v46234_v22 = vshrl.u32 %v135215_v22, 19 (stack46)
        %v43820_v25 = vadd.f32 %v43816_v34, %v135136_v25 (stack53)
        %120807 = vrsqrt.f32 %v135246_v21 (stack67)
        %v43681_v27 = vmul.f32 inf, %v135049_v42 (stack54)
        %vm44161_vm7 = vcmp.lt.f32.partialorder %v135246_v21, 5.0 (stack68)
        %v44571_v52 = vxor.u32 %v44569_v6, %v44557_v54 (stack48)
        %vm43676_vm8 = vcmp.eq.f32.partialorder %v43673_v61, 1.0 (stack68)
        %v43824_v42 = vmul.f32 %v43820_v25, %v135049_v42 (stack54)
        %v44134_v61 = vand.u32 2147483647, %v135190_v41 (stack77)
        %v45798_v12 = vadd.s32 %v45794_v12, %v121569_v1 (stack40)
        %v135261_v29 = vadd.f32 -2.5, %v135246_v21 (stack53)
        %v44970_v44 = vadd.s32 %v44967_v53, %v44962_v10 (stack40)
        %v45806_v32 = vadd.s32 %v45803_v40, %v121564_v0 (stack40)
        %v46235_v55 = vor.u32 %v46234_v22, %v46233_v46 (stack47)
        %v43828_v43 = vsel /*vm=*/%vm43676_vm8, /*on_true_vy=*/%v43681_v27, /*on_false_vx=*/%v43824_v42 (stack44)
        %v135267_v10 = vsel /*vm=*/%vm44161_vm7, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v135272_v23 = vsel /*vm=*/%vm44161_vm7, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v135277_v24 = vsel /*vm=*/%vm44161_vm7, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v43832_v31 = vmul.f32 1.4140625, %v43828_v43 (stack54)
        %v135282_v8 = vsel /*vm=*/%vm44161_vm7, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v44572_v30 = vand.u32.u8 255, %v44571_v52 (stack49)
        %v44976_v40 = vshll.u32 %v44967_v53, 24 (stack45)
        %v44977_v26 = vshrl.u32 %v44967_v53, 8 (stack46)
        %v45413_v20 = vadd.s32 %v45410_v7, %v45405_v20 (stack40)
        %v45415_v56 = vshll.u32 %v45410_v7, 26 (stack45)
        %v45416_v50 = vshrl.u32 %v45410_v7, 6 (stack46)
        %v43835_v46 = vpack.c.bf16 %v156663_v45, %v43832_v31 (stack81)
        %vm44206_vm9 = vcmp.eq.f32.partialorder %v135246_v21, inf (stack70)
        %v44573_v34 = vand.u32 65535, %v44572_v30 (stack50)
        %v45810_v6 = vadd.s32 1, %v45806_v32 (stack40)
        %v46236_v7 = vxor.u32 %v46235_v55, %v46231_v60 (stack48)
        %v44978_v54 = vor.u32 %v44977_v26, %v44976_v40 (stack47)
        %v45417_v53 = vor.u32 %v45416_v50, %v45415_v56 (stack47)
        %v135288_v22 = vadd.s32 %v157341_v11, %v157079_v39 (stack40)
        %v135292_v25 = vadd.s32 %v157342_v9, %v157082_v49 (stack40)
        %119977 = vst [vmem:[%s123356_s30 + $0x22c] sm:$0xf] /*vst_source=*/%v43835_v46 (stack83)
        %v44574_v27 = vshrl.u32 %v44573_v34, 1 (stack51)
        %v45814_v52 = vadd.s32 %v45810_v6, %v45798_v12 (stack40)
        %v45816_v42 = vshll.u32 %v45810_v6, 17 (stack45)
        %v45817_v12 = vshrl.u32 %v45810_v6, 15 (stack46)
        %v44979_v32 = vxor.u32 %v44978_v54, %v44970_v44 (stack48)
        %v45418_v55 = vxor.u32 %v45417_v53, %v45413_v20 (stack48)
        %v46239_v60 = vadd.s32 %v46236_v7, %v46231_v60 (stack40)
        %v46241_v43 = vshll.u32 %v46236_v7, 15 (stack45)
        %vm44208_vm10 = vcmp.eq.f32.partialorder %v135246_v21, 0.0 (stack71)
        %v44575_v31 = vor.u32 16256, %v44574_v27 (stack47)
        %v45818_v30 = vor.u32 %v45817_v12, %v45816_v42 (stack47)
        %v46242_v40 = vshrl.u32 %v46236_v7, 17 (stack46)
        %v44982_v26 = vadd.s32 %v44979_v32, %v121564_v0 (stack40)
        %v45421_v20 = vadd.s32 %v45418_v55, %v45413_v20 (stack40)
        %v45427_v56 = vshll.u32 %v45418_v55, 6 (stack45)
        %v45428_v50 = vshrl.u32 %v45418_v55, 26 (stack46)
        %v120808_v46 = vpop.eup %120807 (stack73)
        %v44209_v34 = vand.u32 2147483648, %v135246_v21 (stack72)
        %v44576_v6 = vand.u32.u16 65535, %v44575_v31 (stack52)
        %v44974_v44 = vadd.s32 %v44970_v44, %v121569_v1 (stack40)
        %v45819_v7 = vxor.u32 %v45818_v30, %v45814_v52 (stack48)
        %v44205_v54 = vmul.f32 %v120808_v46, %v135246_v21 (stack74)
        %v44986_v53 = vadd.s32 4, %v44982_v26 (stack40)
        %v45429_v27 = vor.u32 %v45428_v50, %v45427_v56 (stack47)
        %v46243_v42 = vor.u32 %v46242_v40, %v46241_v43 (stack47)
        %v119980_v12 = vadd.low.f32.bf16 -1.0, %v44576_v6 (stack53)
        %v45822_v52 = vadd.s32 %v45819_v7, %v45814_v52 (stack40)
        %v45824_v32 = vshll.u32 %v45819_v7, 29 (stack45)
        %v45825_v55 = vshrl.u32 %v45819_v7, 3 (stack46)
        %v44207_v43 = vsel /*vm=*/%vm44206_vm9, /*on_true_vy=*/%v135246_v21, /*on_false_vx=*/%v44205_v54 (stack75)
        %v44990_v31 = vadd.s32 %v44986_v53, %v44974_v44 (stack40)
        %v44992_v30 = vshll.u32 %v44986_v53, 13 (stack45)
        %v44993_v40 = vshrl.u32 %v44986_v53, 19 (stack46)
        %v44210_v26 = vsel /*vm=*/%vm44208_vm10, /*on_true_vy=*/%v44209_v34, /*on_false_vx=*/%v44207_v43 (stack76)
        %v44585_v56 = vmul.f32 2.0, %v119980_v12 (stack54)
        %v45430_v50 = vxor.u32 %v45429_v27, %v45421_v20 (stack48)
        %v45826_v46 = vor.u32 %v45825_v55, %v45824_v32 (stack47)
        %v44213_v34 = vadd.f32 -3.0, %v44210_v26 (stack53)
        %v44994_v6 = vor.u32 %v44993_v40, %v44992_v30 (stack47)
        %v46244_v44 = vxor.u32 %v46243_v42, %v46239_v60 (stack48)
        %vm46658_vm11 = vcmp.lt.u32.totalorder %v135288_v22, %v157079_v39 (stack43)
        %v44194_v7 = vsel /*vm=*/%vm44161_vm7, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v44589_v54 = vadd.f32 -0.99609375, %v44585_v56 (stack53)
        %v45433_v53 = vadd.s32 %v45430_v50, %v121569_v1 (stack40)
        %v45827_v27 = vxor.u32 %v45826_v46, %v45822_v52 (stack48)
        %v44198_v42 = vsel /*vm=*/%vm44161_vm7, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v135317_v29 = vsel /*vm=*/%vm44161_vm7, /*on_true_vy=*/%v135261_v29, /*on_false_vx=*/%v44213_v34 (stack44)
        %v44995_v12 = vxor.u32 %v44994_v6, %v44990_v31 (stack48)
        %v135319_v60 = vadd.s32 %v46244_v44, %v46239_v60 (stack40)
        %v44221_v32 = vmul.f32 %v135317_v29, %v44198_v42 (stack54)
        %v135322_v55 = vmax.f32 %v44589_v54, -0.99609375 (stack55)
        %v45437_v43 = vadd.s32 3, %v45433_v53 (stack40)
        %v45830_v52 = vadd.s32 %v45827_v27, %v45822_v52 (stack40)
        %v44998_v31 = vadd.s32 %v44995_v12, %v44990_v31 (stack40)
        %v45000_v30 = vshll.u32 %v44995_v12, 15 (stack45)
        %v45001_v40 = vshrl.u32 %v44995_v12, 17 (stack46)
        %v45425_v20 = vadd.s32 %v45421_v20, %v121574_v2 (stack40)
        %v44190_v26 = vsel /*vm=*/%vm44161_vm7, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v44225_v56 = vadd.f32 %v44221_v32, %v44194_v7 (stack53)
        %v44605_v50 = vxor.u32 2147483648, %v135322_v55 (stack56)
        %v46667_v46 = vadd.s32 1, %v135292_v25 (stack40)
        %v45002_v34 = vor.u32 %v45001_v40, %v45000_v30 (stack47)
        %v45441_v6 = vadd.s32 %v45437_v43, %v45425_v20 (stack40)
        %v45443_v7 = vshll.u32 %v45437_v43, 17 (stack45)
        %v45444_v54 = vshrl.u32 %v45437_v43, 15 (stack46)
        %v44229_v53 = vmul.f32 %v44225_v56, %v135317_v29 (stack54)
        %v135332_v42 = vmul.f32 %v44605_v50, %v135322_v55 (stack54)
        %v46249_v12 = vshll.u32 %v46244_v44, 26 (stack45)
        %v46649_v32 = vadd.s32 %v135288_v22, %v122657_v58 (stack40)
        %v45003_v43 = vxor.u32 %v45002_v34, %v44998_v31 (stack48)
        %v45445_v30 = vor.u32 %v45444_v54, %v45443_v7 (stack47)
        %v45832_v40 = vshll.u32 %v45827_v27, 16 (stack45)
        %v46671_v25 = vsel /*vm=*/%vm46658_vm11, /*on_true_vy=*/%v46667_v46, /*on_false_vx=*/%v135292_v25 (stack44)
        %v44233_v20 = vadd.f32 %v44229_v53, %v44190_v26 (stack53)
        %v44610_v26 = vadd.f32 1.0, %v135332_v42 (stack57)
        %v45833_v27 = vshrl.u32 %v45827_v27, 16 (stack46)
        %v46250_v44 = vshrl.u32 %v46244_v44, 6 (stack46)
        %v45006_v31 = vadd.s32 %v45003_v43, %v44998_v31 (stack40)
        %v45008_v56 = vshll.u32 %v45003_v43, 26 (stack45)
        %v45009_v50 = vshrl.u32 %v45003_v43, 6 (stack46)
        %v45446_v46 = vxor.u32 %v45445_v30, %v45441_v6 (stack48)
        %v44186_v34 = vsel /*vm=*/%vm44161_vm7, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v44237_v7 = vmul.f32 %v44233_v20, %v135317_v29 (stack54)
        %120809 = vlog2.f32 %v44610_v26 (stack58)
        %vm46653_vm12 = vcmp.lt.u32.totalorder %v46649_v32, %v135288_v22 (stack43)
        %v45010_v54 = vor.u32 %v45009_v50, %v45008_v56 (stack47)
        %v45449_v6 = vadd.s32 %v45446_v46, %v45441_v6 (stack40)
        %v45451_v53 = vshll.u32 %v45446_v46, 29 (stack45)
        %v45452_v43 = vshrl.u32 %v45446_v46, 3 (stack46)
        %v44241_v30 = vadd.f32 %v44237_v7, %v44186_v34 (stack53)
        %v44613_v20 = vmul.f32 -0.5, %v135332_v42 (stack59)
        %v45834_v40 = vor.u32 %v45833_v27, %v45832_v40 (stack47)
        %v46251_v12 = vor.u32 %v46250_v44, %v46249_v12 (stack47)
        %v44616_v26 = vand.u32 2147483647, %v135332_v42 (stack60)
        %v45011_v27 = vxor.u32 %v45010_v54, %v45006_v31 (stack48)
        %v45453_v44 = vor.u32 %v45452_v43, %v45451_v53 (stack47)
        %v46675_v56 = vadd.s32 1, %v46671_v25 (stack40)
        %v44245_v50 = vmul.f32 %v44241_v30, %v135317_v29 (stack54)
        %v45835_v46 = vxor.u32 %v45834_v40, %v45830_v52 (stack48)
        %v46252_v34 = vxor.u32 %v46251_v12, %v135319_v60 (stack48)
        %v135352_v7 = vadd.s32 %v157341_v11, %v157083_v59 (stack40)
        %v45014_v31 = vadd.s32 %v45011_v27, %v45006_v31 (stack40)
        %v45020_v54 = vshll.u32 %v45011_v27, 6 (stack45)
        %v45021_v53 = vshrl.u32 %v45011_v27, 26 (stack46)
        %v45454_v43 = vxor.u32 %v45453_v44, %v45449_v6 (stack48)
        %v44249_v8 = vadd.f32 %v44245_v50, %v135282_v8 (stack53)
        %v45838_v52 = vadd.s32 %v45835_v46, %v45830_v52 (stack40)
        %v45844_v30 = vshll.u32 %v45835_v46, 24 (stack45)
        %v45845_v40 = vshrl.u32 %v45835_v46, 8 (stack46)
        %v44614_v20 = vadd.f32 1.0, %v44613_v20 (stack61)
        %v45022_v12 = vor.u32 %v45021_v53, %v45020_v54 (stack47)
        %v45457_v6 = vadd.s32 %v45454_v43, %v45449_v6 (stack40)
        %v45459_v27 = vshll.u32 %v45454_v43, 16 (stack45)
        %v44253_v44 = vmul.f32 %v44249_v8, %v135317_v29 (stack54)
        %vm135356_vm13 = vcmp.lt.f32.partialorder %v44616_v26, 0.0004427343 (stack62)
        %v45460_v50 = vshrl.u32 %v45454_v43, 16 (stack46)
        %v45846_v46 = vor.u32 %v45845_v40, %v45844_v30 (stack47)
        %v45023_v54 = vxor.u32 %v45022_v12, %v45014_v31 (stack48)
        %v46255_v60 = vadd.s32 %v46252_v34, %v135319_v60 (stack40)
        %v46261_v53 = vshll.u32 %v46252_v34, 6 (stack45)
        %v46262_v34 = vshrl.u32 %v46252_v34, 26 (stack46)
        %v44257_v24 = vadd.f32 %v44253_v44, %v135277_v24 (stack53)
        %v45461_v43 = vor.u32 %v45460_v50, %v45459_v27 (stack47)
        %v45847_v8 = vxor.u32 %v45846_v46, %v45838_v52 (stack48)
        %v46679_v22 = vsel /*vm=*/%vm46653_vm12, /*on_true_vy=*/%v46675_v56, /*on_false_vx=*/%v46671_v25 (stack44)
        %v45026_v25 = vadd.s32 %v45023_v54, %v121574_v2 (stack40)
        %v46263_v56 = vor.u32 %v46262_v34, %v46261_v53 (stack47)
        %v46684_v30 = vadd.s32 %v46679_v22, %v121574_v2 (stack40)
        %v46688_v32 = vadd.s32 %v46649_v32, %v121569_v1 (stack40)
        %v44261_v40 = vmul.f32 %v44257_v24, %v135317_v29 (stack54)
        %v44615_v42 = vmul.f32 %v44614_v20, %v135332_v42 (stack63)
        %v45462_v20 = vxor.u32 %v45461_v43, %v45457_v6 (stack48)
        %v45850_v12 = vadd.s32 %v45847_v8, %v121574_v2 (stack40)
        %v120810_v27 = vpop.eup %120809 (stack64)
        %v45018_v31 = vadd.s32 %v45014_v31, %v121564_v0 (stack40)
        %v45030_v44 = vadd.s32 5, %v45026_v25 (stack40)
        %v46264_v50 = vxor.u32 %v46263_v56, %v46255_v60 (stack48)
        %v135371_v46 = vadd.s32 %v46688_v32, %v46684_v30 (stack40)
        %v44265_v23 = vadd.f32 %v44261_v40, %v135272_v23 (stack53)
        %v44612_v54 = vmul.f32 0.6931472, %v120810_v27 (stack65)
        %v45465_v6 = vadd.s32 %v45462_v20, %v45457_v6 (stack40)
        %v45471_v53 = vshll.u32 %v45462_v20, 24 (stack45)
        %v45032_v34 = vxor.u32 %v45030_v44, %v45018_v31 (stack48)
        %v45472_v24 = vshrl.u32 %v45462_v20, 8 (stack46)
        %v45842_v52 = vadd.s32 %v45838_v52, %v121564_v0 (stack40)
        %v45854_v43 = vadd.s32 2, %v45850_v12 (stack40)
        %v44269_v8 = vmul.f32 %v44265_v23, %v135317_v29 (stack54)
        %v44618_v26 = vsel /*vm=*/%vm135356_vm13, /*on_true_vy=*/%v44615_v42, /*on_false_vx=*/%v44612_v54 (stack66)
        %v46267_v22 = vadd.s32 %v46264_v50, %v121564_v0 (stack40)
        %v46694_v25 = vshll.u32 %v46688_v32, 13 (stack45)
        %v135379_v56 = vxor.u32 2147483648, %v44618_v26 (stack56)
        %v45473_v30 = vor.u32 %v45472_v24, %v45471_v53 (stack47)
        %v45858_v40 = vadd.s32 %v45854_v43, %v45842_v52 (stack40)
        %v46695_v32 = vshrl.u32 %v46688_v32, 19 (stack46)
        %v44142_v42 = vmul.f32 inf, %v135190_v41 (stack54)
        %v44273_v10 = vadd.f32 %v44269_v8, %v135267_v10 (stack53)
        %vm135385_vm14 = vcmp.eq.f32.partialorder %v44134_v61, 1.0 (stack68)
        %120811 = vrsqrt.f32 %v135379_v56 (stack67)
        %v45033_v20 = vand.u32.u8 255, %v45032_v34 (stack49)
        %v45860_v12 = vshll.u32 %v45854_v43, 13 (stack45)
        %v44277_v29 = vmul.f32 %v44273_v10, %v135317_v29 (stack54)
        %vm44622_vm15 = vcmp.lt.f32.partialorder %v135379_v56, 5.0 (stack68)
        %v45861_v27 = vshrl.u32 %v45854_v43, 19 (stack46)
        %v46271_v31 = vadd.s32 1, %v46267_v22 (stack40)
        %v44166_v21 = vsel /*vm=*/%vm44161_vm7, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v44595_v44 = vand.u32 2147483647, %v135322_v55 (stack77)
        %v45474_v50 = vxor.u32 %v45473_v30, %v45465_v6 (stack48)
        %v46696_v23 = vor.u32 %v46695_v32, %v46694_v25 (stack47)
        %v44281_v54 = vadd.f32 %v44277_v29, %v44166_v21 (stack53)
        %v135397_v53 = vadd.f32 -2.5, %v135379_v56 (stack53)
        %v45469_v6 = vadd.s32 %v45465_v6, %v121569_v1 (stack40)
        %v46259_v60 = vadd.s32 %v46255_v60, %v121569_v1 (stack40)
        %v135404_v34 = vsel /*vm=*/%vm44622_vm15, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v135409_v24 = vsel /*vm=*/%vm44622_vm15, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v45034_v52 = vand.u32 65535, %v45033_v20 (stack50)
        %v45477_v43 = vadd.s32 %v45474_v50, %v121564_v0 (stack40)
        %v44285_v41 = vmul.f32 %v44281_v54, %v135190_v41 (stack54)
        %v45862_v8 = vor.u32 %v45861_v27, %v45860_v12 (stack47)
        %v46275_v26 = vadd.s32 %v46271_v31, %v46259_v60 (stack40)
        %v46277_v22 = vshll.u32 %v46271_v31, 17 (stack45)
        %v45035_v25 = vshrl.u32 %v45034_v52, 1 (stack51)
        %v45481_v30 = vadd.s32 4, %v45477_v43 (stack40)
        %v46278_v32 = vshrl.u32 %v46271_v31, 15 (stack46)
        %v46697_v10 = vxor.u32 %v46696_v23, %v135371_v46 (stack48)
        %v44289_v42 = vsel /*vm=*/%vm135385_vm14, /*on_true_vy=*/%v44142_v42, /*on_false_vx=*/%v44285_v41 (stack44)
        %v135419_v61 = vsel /*vm=*/%vm44622_vm15, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %vm44667_vm0 = vcmp.eq.f32.partialorder %v135379_v56, inf (stack70)
        %v45863_v20 = vxor.u32 %v45862_v8, %v45858_v40 (stack48)
        %vm47119_vm1 = vcmp.lt.u32.totalorder %v135352_v7, %v157083_v59 (stack43)
        %v44293_v12 = vmul.f32 1.4140625, %v44289_v42 (stack54)
        %v45036_v29 = vor.u32 16256, %v45035_v25 (stack47)
        %v45485_v27 = vadd.s32 %v45481_v30, %v45469_v6 (stack40)
        %v45487_v31 = vshll.u32 %v45481_v30, 13 (stack45)
        %v45488_v21 = vshrl.u32 %v45481_v30, 19 (stack46)
        %v45866_v40 = vadd.s32 %v45863_v20, %v45858_v40 (stack40)
        %v45868_v50 = vshll.u32 %v45863_v20, 15 (stack45)
        %v45869_v23 = vshrl.u32 %v45863_v20, 17 (stack46)
        %v44296_v54 = vpack.c.bf16 %v156663_v45, %v44293_v12 (stack81)
        %v45037_v6 = vand.u32.u16 65535, %v45036_v29 (stack52)
        %v46279_v60 = vor.u32 %v46278_v32, %v46277_v22 (stack47)
        %v46700_v46 = vadd.s32 %v46697_v10, %v135371_v46 (stack40)
        %v45489_v52 = vor.u32 %v45488_v21, %v45487_v31 (stack47)
        %v45870_v43 = vor.u32 %v45869_v23, %v45868_v50 (stack47)
        %v46702_v41 = vshll.u32 %v46697_v10, 15 (stack45)
        %v46703_v8 = vshrl.u32 %v46697_v10, 17 (stack46)
        %119979 = vst [vmem:[%s123356_s30 + $0x2ac] sm:$0xf] /*vst_source=*/%v44296_v54 (stack83)
        %vm44669_vm2 = vcmp.eq.f32.partialorder %v135379_v56, 0.0 (stack71)
        %v119982_v22 = vadd.low.f32.bf16 -1.0, %v45037_v6 (stack53)
        %v46280_v25 = vxor.u32 %v46279_v60, %v46275_v26 (stack48)
        %v47124_v30 = vadd.s32 %v157342_v9, %v157084_v16 (stack40)
        %v120812_v32 = vpop.eup %120811 (stack73)
        %v44670_v10 = vand.u32 2147483648, %v135379_v56 (stack72)
        %v45490_v42 = vxor.u32 %v45489_v52, %v45485_v27 (stack48)
        %v45871_v20 = vxor.u32 %v45870_v43, %v45866_v40 (stack48)
        %v46704_v12 = vor.u32 %v46703_v8, %v46702_v41 (stack47)
        %v44666_v29 = vmul.f32 %v120812_v32, %v135379_v56 (stack74)
        %v45046_v31 = vmul.f32 2.0, %v119982_v22 (stack54)
        %v46283_v26 = vadd.s32 %v46280_v25, %v46275_v26 (stack40)
        %v46285_v21 = vshll.u32 %v46280_v25, 29 (stack45)
        %v45493_v27 = vadd.s32 %v45490_v42, %v45485_v27 (stack40)
        %v45495_v50 = vshll.u32 %v45490_v42, 15 (stack45)
        %v45496_v23 = vshrl.u32 %v45490_v42, 17 (stack46)
        %v45874_v40 = vadd.s32 %v45871_v20, %v45866_v40 (stack40)
        %v44668_v54 = vsel /*vm=*/%vm44667_vm0, /*on_true_vy=*/%v135379_v56, /*on_false_vx=*/%v44666_v29 (stack75)
        %v45050_v6 = vadd.f32 -0.99609375, %v45046_v31 (stack53)
        %v45876_v60 = vshll.u32 %v45871_v20, 26 (stack45)
        %v45877_v52 = vshrl.u32 %v45871_v20, 6 (stack46)
        %v44671_v43 = vsel /*vm=*/%vm44669_vm2, /*on_true_vy=*/%v44670_v10, /*on_false_vx=*/%v44668_v54 (stack76)
        %v45497_v41 = vor.u32 %v45496_v23, %v45495_v50 (stack47)
        %v46286_v8 = vshrl.u32 %v46280_v25, 3 (stack46)
        %v46705_v22 = vxor.u32 %v46704_v12, %v46700_v46 (stack48)
        %v44651_v25 = vsel /*vm=*/%vm44622_vm15, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v44674_v32 = vadd.f32 -3.0, %v44671_v43 (stack53)
        %v135440_v10 = vmax.f32 %v45050_v6, -0.99609375 (stack55)
        %v45878_v42 = vor.u32 %v45877_v52, %v45876_v60 (stack47)
        %v45498_v20 = vxor.u32 %v45497_v41, %v45493_v27 (stack48)
        %v46287_v12 = vor.u32 %v46286_v8, %v46285_v21 (stack47)
        %v46708_v46 = vadd.s32 %v46705_v22, %v46700_v46 (stack40)
        %v47110_v29 = vadd.s32 %v135352_v7, %v122657_v58 (stack40)
        %v44659_v31 = vsel /*vm=*/%vm44622_vm15, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v135450_v53 = vsel /*vm=*/%vm44622_vm15, /*on_true_vy=*/%v135397_v53, /*on_false_vx=*/%v44674_v32 (stack44)
        %v45066_v21 = vxor.u32 2147483648, %v135440_v10 (stack56)
        %v47128_v50 = vadd.s32 1, %v47124_v30 (stack40)
        %v44682_v23 = vmul.f32 %v135450_v53, %v44659_v31 (stack54)
        %v45501_v27 = vadd.s32 %v45498_v20, %v45493_v27 (stack40)
        %v45503_v54 = vshll.u32 %v45498_v20, 26 (stack45)
        %v45504_v6 = vshrl.u32 %v45498_v20, 6 (stack46)
        %v44655_v60 = vsel /*vm=*/%vm44622_vm15, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v135458_v52 = vmul.f32 %v45066_v21, %v135440_v10 (stack54)
        %v45879_v43 = vxor.u32 %v45878_v42, %v45874_v40 (stack48)
        %v46288_v41 = vxor.u32 %v46287_v12, %v46283_v26 (stack48)
        %v44686_v8 = vadd.f32 %v44682_v23, %v44655_v60 (stack53)
        %v45505_v32 = vor.u32 %v45504_v6, %v45503_v54 (stack47)
        %vm47114_vm3 = vcmp.lt.u32.totalorder %v47110_v29, %v135352_v7 (stack43)
        %v47132_v30 = vsel /*vm=*/%vm47119_vm1, /*on_true_vy=*/%v47128_v50, /*on_false_vx=*/%v47124_v30 (stack44)
        %v45071_v42 = vadd.f32 1.0, %v135458_v52 (stack57)
        %v45074_v20 = vmul.f32 -0.5, %v135458_v52 (stack59)
        %v45882_v40 = vadd.s32 %v45879_v43, %v45874_v40 (stack40)
        %v47149_v12 = vadd.s32 %v47110_v29, %v121569_v1 (stack40)
        %v44690_v31 = vmul.f32 %v44686_v8, %v135450_v53 (stack54)
        %v45506_v21 = vxor.u32 %v45505_v32, %v45501_v27 (stack48)
        %v45888_v50 = vshll.u32 %v45879_v43, 6 (stack45)
        %v45889_v23 = vshrl.u32 %v45879_v43, 26 (stack46)
        %120813 = vlog2.f32 %v45071_v42 (stack58)
        %v45075_v54 = vadd.f32 1.0, %v45074_v20 (stack61)
        %v46710_v6 = vshll.u32 %v46705_v22, 26 (stack45)
        %v46711_v22 = vshrl.u32 %v46705_v22, 6 (stack46)
        %v44694_v25 = vadd.f32 %v44690_v31, %v44651_v25 (stack53)
        %v45509_v27 = vadd.s32 %v45506_v21, %v45501_v27 (stack40)
        %v45515_v60 = vshll.u32 %v45506_v21, 6 (stack45)
        %v45516_v43 = vshrl.u32 %v45506_v21, 26 (stack46)
        %v45886_v8 = vadd.s32 %v45882_v40, %v121574_v2 (stack40)
        %v45890_v32 = vor.u32 %v45889_v23, %v45888_v50 (stack47)
        %v46291_v26 = vadd.s32 %v46288_v41, %v46283_v26 (stack40)
        %v46293_v42 = vshll.u32 %v46288_v41, 16 (stack45)
        %v44698_v20 = vmul.f32 %v44694_v25, %v135450_v53 (stack54)
        %v45513_v31 = vadd.s32 %v45509_v27, %v121564_v0 (stack40)
        %v45517_v21 = vor.u32 %v45516_v43, %v45515_v60 (stack47)
        %v46294_v41 = vshrl.u32 %v46288_v41, 16 (stack46)
        %v45891_v40 = vxor.u32 %v45890_v32, %v45882_v40 (stack48)
        %v46712_v50 = vor.u32 %v46711_v22, %v46710_v6 (stack47)
        %v47136_v23 = vadd.s32 1, %v47132_v30 (stack40)
        %v47155_v6 = vshll.u32 %v47149_v12, 13 (stack45)
        %v44702_v61 = vadd.f32 %v44698_v20, %v135419_v61 (stack53)
        %v45518_v22 = vxor.u32 %v45517_v21, %v45509_v27 (stack48)
        %v46295_v25 = vor.u32 %v46294_v41, %v46293_v42 (stack47)
        %v47156_v27 = vshrl.u32 %v47149_v12, 19 (stack46)
        %v45894_v60 = vadd.s32 %v45891_v40, %v121569_v1 (stack40)
        %v46713_v43 = vxor.u32 %v46712_v50, %v46708_v46 (stack48)
        %v47140_v7 = vsel /*vm=*/%vm47114_vm3, /*on_true_vy=*/%v47136_v23, /*on_false_vx=*/%v47132_v30 (stack44)
        %v135477_v29 = vadd.s32 %v157341_v11, %v157089_v17 (stack40)
        %v44706_v30 = vmul.f32 %v44702_v61, %v135450_v53 (stack54)
        %v45521_v32 = vadd.s32 %v45518_v22, %v121574_v2 (stack40)
        %v46296_v42 = vxor.u32 %v46295_v25, %v46291_v26 (stack48)
        %v47145_v20 = vadd.s32 %v47140_v7, %v121574_v2 (stack40)
        %v45898_v21 = vadd.s32 3, %v45894_v60 (stack40)
        %v46716_v46 = vadd.s32 %v46713_v43, %v46708_v46 (stack40)
        %v46722_v41 = vshll.u32 %v46713_v43, 6 (stack45)
        %v46723_v40 = vshrl.u32 %v46713_v43, 26 (stack46)
        %v44710_v24 = vadd.f32 %v44706_v30, %v135409_v24 (stack53)
        %v45525_v50 = vadd.s32 5, %v45521_v32 (stack40)
        %v46299_v26 = vadd.s32 %v46296_v42, %v46291_v26 (stack40)
        %v46305_v23 = vshll.u32 %v46296_v42, 24 (stack45)
        %v45902_v8 = vadd.s32 %v45898_v21, %v45886_v8 (stack40)
        %v45904_v61 = vshll.u32 %v45898_v21, 17 (stack45)
        %v45905_v22 = vshrl.u32 %v45898_v21, 15 (stack46)
        %v46306_v25 = vshrl.u32 %v46296_v42, 8 (stack46)
        %v44639_v60 = vsel /*vm=*/%vm44622_vm15, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v44714_v43 = vmul.f32 %v44710_v24, %v135450_v53 (stack54)
        %v45077_v7 = vand.u32 2147483647, %v135458_v52 (stack60)
        %v45527_v31 = vxor.u32 %v45525_v50, %v45513_v31 (stack48)
        %v45906_v30 = vor.u32 %v45905_v22, %v45904_v61 (stack47)
        %v46307_v32 = vor.u32 %v46306_v25, %v46305_v23 (stack47)
        %v46724_v42 = vor.u32 %v46723_v40, %v46722_v41 (stack47)
        %v47153_v12 = vadd.s32 %v47149_v12, %v47145_v20 (stack40)
        %v120814_v20 = vpop.eup %120813 (stack64)
        %v44718_v21 = vadd.f32 %v44714_v43, %v44639_v60 (stack53)
        %v45076_v52 = vmul.f32 %v45075_v54, %v135458_v52 (stack63)
        %v45528_v54 = vand.u32.u8 255, %v45527_v31 (stack49)
        %v47157_v6 = vor.u32 %v47156_v27, %v47155_v6 (stack47)
        %v45073_v27 = vmul.f32 0.6931472, %v120814_v20 (stack65)
        %v45907_v41 = vxor.u32 %v45906_v30, %v45902_v8 (stack48)
        %v46308_v40 = vxor.u32 %v46307_v32, %v46299_v26 (stack48)
        %v46725_v24 = vxor.u32 %v46724_v42, %v46716_v46 (stack48)
        %v44722_v50 = vmul.f32 %v44718_v21, %v135450_v53 (stack54)
        %vm45078_vm4 = vcmp.lt.f32.partialorder %v45077_v7, 0.0004427343 (stack62)
        %v45529_v23 = vand.u32 65535, %v45528_v54 (stack50)
        %v47158_v61 = vxor.u32 %v47157_v6, %v47153_v12 (stack48)
        %v45079_v22 = vsel /*vm=*/%vm45078_vm4, /*on_true_vy=*/%v45076_v52, /*on_false_vx=*/%v45073_v27 (stack66)
        %v45910_v8 = vadd.s32 %v45907_v41, %v45902_v8 (stack40)
        %v45912_v25 = vshll.u32 %v45907_v41, 29 (stack45)
        %v45913_v60 = vshrl.u32 %v45907_v41, 3 (stack46)
        %v44726_v34 = vadd.f32 %v44722_v50, %v135404_v34 (stack53)
        %v135491_v43 = vxor.u32 2147483648, %v45079_v22 (stack56)
        %v44603_v7 = vmul.f32 inf, %v135322_v55 (stack54)
        %v44627_v31 = vsel /*vm=*/%vm44622_vm15, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v45914_v30 = vor.u32 %v45913_v60, %v45912_v25 (stack47)
        %v135497_v32 = vadd.s32 %v47158_v61, %v47153_v12 (stack40)
        %v44631_v56 = vsel /*vm=*/%vm44622_vm15, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v44730_v42 = vmul.f32 %v44726_v34, %v135450_v53 (stack54)
        %v45056_v12 = vand.u32 2147483647, %v135440_v10 (stack77)
        %120815 = vrsqrt.f32 %v135491_v43 (stack67)
        %vm135507_vm5 = vcmp.eq.f32.partialorder %v44595_v44, 1.0 (stack68)
        %vm45083_vm6 = vcmp.lt.f32.partialorder %v135491_v43, 5.0 (stack68)
        %v45530_v20 = vshrl.u32 %v45529_v23, 1 (stack51)
        %v45915_v21 = vxor.u32 %v45914_v30, %v45910_v8 (stack48)
        %v46311_v52 = vadd.s32 %v46308_v40, %v121574_v2 (stack40)
        %v44734_v54 = vadd.f32 %v44730_v42, %v44631_v56 (stack53)
        %v135514_v6 = vmul.f32 inf, %v135440_v10 (stack54)
        %v46303_v26 = vadd.s32 %v46299_v26, %v121564_v0 (stack40)
        %v46728_v27 = vadd.s32 %v46725_v24, %v121564_v0 (stack40)
        %v45918_v41 = vadd.s32 %v45915_v21, %v45910_v8 (stack40)
        %v46720_v46 = vadd.s32 %v46716_v46, %v121569_v1 (stack40)
        %v47163_v40 = vshll.u32 %v47158_v61, 15 (stack45)
        %v135521_v24 = vadd.s32 %v135477_v29, %v122657_v58 (stack40)
        %v44738_v53 = vmul.f32 %v44734_v54, %v135450_v53 (stack54)
        %v135527_v50 = vsel /*vm=*/%vm45083_vm6, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v135532_v23 = vsel /*vm=*/%vm45083_vm6, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v135535_v22 = vadd.f32 -2.5, %v135491_v43 (stack53)
        %v45531_v8 = vor.u32 16256, %v45530_v20 (stack47)
        %v45920_v25 = vshll.u32 %v45915_v21, 16 (stack45)
        %v45921_v60 = vshrl.u32 %v45915_v21, 16 (stack46)
        %v46315_v34 = vadd.s32 2, %v46311_v52 (stack40)
        %v44742_v31 = vadd.f32 %v44738_v53, %v44627_v31 (stack53)
        %v46732_v30 = vadd.s32 1, %v46728_v27 (stack40)
        %v47164_v61 = vshrl.u32 %v47158_v61, 17 (stack46)
        %vm47580_vm7 = vcmp.lt.u32.totalorder %v135477_v29, %v157089_v17 (stack43)
        %v45532_v56 = vand.u32.u16 65535, %v45531_v8 (stack52)
        %v45922_v42 = vor.u32 %v45921_v60, %v45920_v25 (stack47)
        %v46319_v20 = vadd.s32 %v46315_v34, %v46303_v26 (stack40)
        %v46321_v21 = vshll.u32 %v46315_v34, 13 (stack45)
        %v44746_v55 = vmul.f32 %v44742_v31, %v135322_v55 (stack54)
        %v46322_v52 = vshrl.u32 %v46315_v34, 19 (stack46)
        %v46736_v54 = vadd.s32 %v46732_v30, %v46720_v46 (stack40)
        %v46738_v26 = vshll.u32 %v46732_v30, 17 (stack45)
        %v119988_v27 = vadd.low.f32.bf16 -1.0, %v45532_v56 (stack53)
        %v45923_v46 = vxor.u32 %v45922_v42, %v45918_v41 (stack48)
        %v46739_v53 = vshrl.u32 %v46732_v30, 15 (stack46)
        %v47165_v40 = vor.u32 %v47164_v61, %v47163_v40 (stack47)
        %v44750_v7 = vsel /*vm=*/%vm135507_vm5, /*on_true_vy=*/%v44603_v7, /*on_false_vx=*/%v44746_v55 (stack44)
        %v135545_v44 = vsel /*vm=*/%vm45083_vm6, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v46323_v8 = vor.u32 %v46322_v52, %v46321_v21 (stack47)
        %v135549_v25 = vadd.s32 %v157342_v9, %v157090_v62 (stack40)
        %v44754_v60 = vmul.f32 1.4140625, %v44750_v7 (stack54)
        %v45541_v34 = vmul.f32 2.0, %v119988_v27 (stack54)
        %v45926_v41 = vadd.s32 %v45923_v46, %v45918_v41 (stack40)
        %v45932_v31 = vshll.u32 %v45923_v46, 24 (stack45)
        %v45933_v30 = vshrl.u32 %v45923_v46, 8 (stack46)
        %v46324_v61 = vxor.u32 %v46323_v8, %v46319_v20 (stack48)
        %v46740_v56 = vor.u32 %v46739_v53, %v46738_v26 (stack47)
        %v47166_v42 = vxor.u32 %v47165_v40, %v135497_v32 (stack48)
        %v120816_v21 = vpop.eup %120815 (stack73)
        %v44757_v55 = vpack.c.bf16 %v156663_v45, %v44754_v60 (stack81)
        %vm45128_vm8 = vcmp.eq.f32.partialorder %v135491_v43, inf (stack70)
        %v45131_v52 = vand.u32 2147483648, %v135491_v43 (stack72)
        %v45545_v26 = vadd.f32 -0.99609375, %v45541_v34 (stack53)
        %v45127_v27 = vmul.f32 %v120816_v21, %v135491_v43 (stack74)
        %v45934_v46 = vor.u32 %v45933_v30, %v45932_v31 (stack47)
        %v46327_v20 = vadd.s32 %v46324_v61, %v46319_v20 (stack40)
        %v46329_v53 = vshll.u32 %v46324_v61, 15 (stack45)
        %119981 = vst [vmem:[%s123356_s30 + $0x32c] sm:$0xf] /*vst_source=*/%v44757_v55 (stack83)
        %v135557_v40 = vmax.f32 %v45545_v26, -0.99609375 (stack55)
        %v46330_v7 = vshrl.u32 %v46324_v61, 17 (stack46)
        %v46741_v8 = vxor.u32 %v46740_v56, %v46736_v54 (stack48)
        %v47169_v32 = vadd.s32 %v47166_v42, %v135497_v32 (stack40)
        %v45112_v60 = vsel /*vm=*/%vm45083_vm6, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v45129_v34 = vsel /*vm=*/%vm45128_vm8, /*on_true_vy=*/%v135491_v43, /*on_false_vx=*/%v45127_v27 (stack75)
        %vm45130_vm9 = vcmp.eq.f32.partialorder %v135491_v43, 0.0 (stack71)
        %v45935_v31 = vxor.u32 %v45934_v46, %v45926_v41 (stack48)
        %v45132_v30 = vsel /*vm=*/%vm45130_vm9, /*on_true_vy=*/%v45131_v52, /*on_false_vx=*/%v45129_v34 (stack76)
        %v45561_v61 = vxor.u32 2147483648, %v135557_v40 (stack56)
        %v47171_v56 = vshll.u32 %v47166_v42, 26 (stack45)
        %v47172_v42 = vshrl.u32 %v47166_v42, 6 (stack46)
        %v45135_v21 = vadd.f32 -3.0, %v45132_v30 (stack53)
        %v45938_v55 = vadd.s32 %v45935_v31, %v121564_v0 (stack40)
        %v46331_v52 = vor.u32 %v46330_v7, %v46329_v53 (stack47)
        %v46744_v54 = vadd.s32 %v46741_v8, %v46736_v54 (stack40)
        %v45120_v26 = vsel /*vm=*/%vm45083_vm6, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v135571_v27 = vmul.f32 %v45561_v61, %v135557_v40 (stack54)
        %v45930_v41 = vadd.s32 %v45926_v41, %v121569_v1 (stack40)
        %v46746_v46 = vshll.u32 %v46741_v8, 29 (stack45)
        %v135577_v22 = vsel /*vm=*/%vm45083_vm6, /*on_true_vy=*/%v135535_v22, /*on_false_vx=*/%v45135_v21 (stack44)
        %v45942_v53 = vadd.s32 4, %v45938_v55 (stack40)
        %v46332_v7 = vxor.u32 %v46331_v52, %v46327_v20 (stack48)
        %v46747_v8 = vshrl.u32 %v46741_v8, 3 (stack46)
        %v45116_v34 = vsel /*vm=*/%vm45083_vm6, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v45143_v31 = vmul.f32 %v135577_v22, %v45120_v26 (stack54)
        %v45566_v30 = vadd.f32 1.0, %v135571_v27 (stack57)
        %v47173_v61 = vor.u32 %v47172_v42, %v47171_v56 (stack47)
        %vm47575_vm10 = vcmp.lt.u32.totalorder %v135521_v24, %v135477_v29 (stack43)
        %v45946_v56 = vadd.s32 %v45942_v53, %v45930_v41 (stack40)
        %v45948_v42 = vshll.u32 %v45942_v53, 13 (stack45)
        %v45949_v21 = vshrl.u32 %v45942_v53, 19 (stack46)
        %v46335_v20 = vadd.s32 %v46332_v7, %v46327_v20 (stack40)
        %v45147_v55 = vadd.f32 %v45143_v31, %v45116_v34 (stack53)
        %120817 = vlog2.f32 %v45566_v30 (stack58)
        %v47589_v52 = vadd.s32 1, %v135549_v25 (stack40)
        %v135589_v26 = vadd.s32 %v135521_v24, %v121569_v1 (stack40)
        %v45950_v41 = vor.u32 %v45949_v21, %v45948_v42 (stack47)
        %v46337_v53 = vshll.u32 %v46332_v7, 26 (stack45)
        %v46338_v7 = vshrl.u32 %v46332_v7, 6 (stack46)
        %v46748_v46 = vor.u32 %v46747_v8, %v46746_v46 (stack47)
        %v45151_v8 = vmul.f32 %v45147_v55, %v135577_v22 (stack54)
        %v45569_v34 = vmul.f32 -0.5, %v135571_v27 (stack59)
        %v47174_v31 = vxor.u32 %v47173_v61, %v47169_v32 (stack48)
        %v47593_v25 = vsel /*vm=*/%vm47580_vm7, /*on_true_vy=*/%v47589_v52, /*on_false_vx=*/%v135549_v25 (stack44)
        %v45951_v30 = vxor.u32 %v45950_v41, %v45946_v56 (stack48)
        %v46339_v61 = vor.u32 %v46338_v7, %v46337_v53 (stack47)
        %v46749_v42 = vxor.u32 %v46748_v46, %v46744_v54 (stack48)
        %v47597_v21 = vadd.s32 1, %v47593_v25 (stack40)
        %v45155_v60 = vadd.f32 %v45151_v8, %v45112_v60 (stack53)
        %v135597_v32 = vadd.s32 %v47174_v31, %v47169_v32 (stack40)
        %v47183_v55 = vshll.u32 %v47174_v31, 6 (stack45)
        %v47184_v52 = vshrl.u32 %v47174_v31, 26 (stack46)
        %v45954_v56 = vadd.s32 %v45951_v30, %v45946_v56 (stack40)
        %v45956_v41 = vshll.u32 %v45951_v30, 15 (stack45)
        %v45957_v53 = vshrl.u32 %v45951_v30, 17 (stack46)
        %v46340_v7 = vxor.u32 %v46339_v61, %v46335_v20 (stack48)
        %v45159_v46 = vmul.f32 %v45155_v60, %v135577_v22 (stack54)
        %v46752_v54 = vadd.s32 %v46749_v42, %v46744_v54 (stack40)
        %v46754_v8 = vshll.u32 %v46749_v42, 16 (stack45)
        %v46755_v31 = vshrl.u32 %v46749_v42, 16 (stack46)
        %v45958_v30 = vor.u32 %v45957_v53, %v45956_v41 (stack47)
        %v46343_v20 = vadd.s32 %v46340_v7, %v46335_v20 (stack40)
        %v46349_v61 = vshll.u32 %v46340_v7, 6 (stack45)
        %v46350_v42 = vshrl.u32 %v46340_v7, 26 (stack46)
        %v45163_v44 = vadd.f32 %v45159_v46, %v135545_v44 (stack53)
        %v45572_v60 = vand.u32 2147483647, %v135571_v27 (stack60)
        %v46756_v41 = vor.u32 %v46755_v31, %v46754_v8 (stack47)
        %v47185_v55 = vor.u32 %v47184_v52, %v47183_v55 (stack47)
        %v45570_v34 = vadd.f32 1.0, %v45569_v34 (stack61)
        %v45959_v52 = vxor.u32 %v45958_v30, %v45954_v56 (stack48)
        %v46351_v53 = vor.u32 %v46350_v42, %v46349_v61 (stack47)
        %v47601_v29 = vsel /*vm=*/%vm47575_vm10, /*on_true_vy=*/%v47597_v21, /*on_false_vx=*/%v47593_v25 (stack44)
        %v45167_v24 = vmul.f32 %v45163_v44, %v135577_v22 (stack54)
        %v46757_v25 = vxor.u32 %v46756_v41, %v46752_v54 (stack48)
        %v47186_v21 = vxor.u32 %v47185_v55, %v135597_v32 (stack48)
        %v47606_v7 = vadd.s32 %v47601_v29, %v121574_v2 (stack40)
        %v45962_v56 = vadd.s32 %v45959_v52, %v45954_v56 (stack40)
        %v45964_v46 = vshll.u32 %v45959_v52, 26 (stack45)
        %v45965_v8 = vshrl.u32 %v45959_v52, 6 (stack46)
        %v46352_v31 = vxor.u32 %v46351_v53, %v46343_v20 (stack48)
        %v45171_v23 = vadd.f32 %v45167_v24, %v135532_v23 (stack53)
        %v46760_v54 = vadd.s32 %v46757_v25, %v46752_v54 (stack40)
        %v46766_v30 = vshll.u32 %v46757_v25, 24 (stack45)
        %v46767_v61 = vshrl.u32 %v46757_v25, 8 (stack46)
        %v120818_v42 = vpop.eup %120817 (stack64)
        %v45100_v44 = vsel /*vm=*/%vm45083_vm6, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v45966_v41 = vor.u32 %v45965_v8, %v45964_v46 (stack47)
        %v46355_v55 = vadd.s32 %v46352_v31, %v121569_v1 (stack40)
        %v135614_v52 = vadd.s32 %v135589_v26, %v47606_v7 (stack40)
        %v45175_v53 = vmul.f32 %v45171_v23, %v135577_v22 (stack54)
        %v45568_v29 = vmul.f32 0.6931472, %v120818_v42 (stack65)
        %v45571_v27 = vmul.f32 %v45570_v34, %v135571_v27 (stack63)
        %v46768_v34 = vor.u32 %v46767_v61, %v46766_v30 (stack47)
        %vm45573_vm11 = vcmp.lt.f32.partialorder %v45572_v60, 0.0004427343 (stack62)
        %v45967_v60 = vxor.u32 %v45966_v41, %v45962_v56 (stack48)
        %v46347_v20 = vadd.s32 %v46343_v20, %v121574_v2 (stack40)
        %v46359_v24 = vadd.s32 3, %v46355_v55 (stack40)
        %v45179_v25 = vadd.f32 %v45175_v53, %v45100_v44 (stack53)
        %v45574_v7 = vsel /*vm=*/%vm45573_vm11, /*on_true_vy=*/%v45571_v27, /*on_false_vx=*/%v45568_v29 (stack66)
        %v46769_v46 = vxor.u32 %v46768_v34, %v46760_v54 (stack48)
        %v47189_v21 = vadd.s32 %v47186_v21, %v121564_v0 (stack40)
        %v45092_v8 = vsel /*vm=*/%vm45083_vm6, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v45096_v43 = vsel /*vm=*/%vm45083_vm6, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v135626_v31 = vxor.u32 2147483648, %v45574_v7 (stack56)
        %v45970_v56 = vadd.s32 %v45967_v60, %v45962_v56 (stack40)
        %v45183_v23 = vmul.f32 %v45179_v25, %v135577_v22 (stack54)
        %v45976_v30 = vshll.u32 %v45967_v60, 6 (stack45)
        %v45977_v61 = vshrl.u32 %v45967_v60, 26 (stack46)
        %v46363_v42 = vadd.s32 %v46359_v24, %v46347_v20 (stack40)
        %vm45578_vm12 = vcmp.lt.f32.partialorder %v135626_v31, 5.0 (stack68)
        %120819 = vrsqrt.f32 %v135626_v31 (stack67)
        %v46365_v44 = vshll.u32 %v46359_v24, 17 (stack45)
        %v46366_v41 = vshrl.u32 %v46359_v24, 15 (stack46)
        %v45187_v55 = vadd.f32 %v45183_v23, %v45096_v43 (stack53)
        %v45551_v53 = vand.u32 2147483647, %v135557_v40 (stack77)
        %v47181_v32 = vadd.s32 %v135597_v32, %v121569_v1 (stack40)
        %v47193_v29 = vadd.s32 1, %v47189_v21 (stack40)
        %v135635_v27 = vadd.f32 -2.5, %v135626_v31 (stack53)
        %v46764_v54 = vadd.s32 %v46760_v54, %v121564_v0 (stack40)
        %v47616_v34 = vshll.u32 %v135589_v26, 13 (stack45)
        %v47617_v26 = vshrl.u32 %v135589_v26, 19 (stack46)
        %v45191_v60 = vmul.f32 %v45187_v55, %v135577_v22 (stack54)
        %v135644_v20 = vsel /*vm=*/%vm45578_vm12, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v135649_v24 = vsel /*vm=*/%vm45578_vm12, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v45974_v25 = vadd.s32 %v45970_v56, %v121564_v0 (stack40)
        %vm135654_vm13 = vcmp.eq.f32.partialorder %v45056_v12, 1.0 (stack68)
        %v135661_v7 = vsel /*vm=*/%vm45578_vm12, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v135666_v21 = vsel /*vm=*/%vm45578_vm12, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v45978_v43 = vor.u32 %v45977_v61, %v45976_v30 (stack47)
        %v46367_v23 = vor.u32 %v46366_v41, %v46365_v44 (stack47)
        %v45195_v8 = vadd.f32 %v45191_v60, %v45092_v8 (stack53)
        %v46772_v46 = vadd.s32 %v46769_v46, %v121574_v2 (stack40)
        %v47197_v30 = vadd.s32 %v47193_v29, %v47181_v32 (stack40)
        %v47199_v61 = vshll.u32 %v47193_v29, 17 (stack45)
        %v45979_v56 = vxor.u32 %v45978_v43, %v45970_v56 (stack48)
        %v46368_v44 = vxor.u32 %v46367_v23, %v46363_v42 (stack48)
        %v47200_v41 = vshrl.u32 %v47193_v29, 15 (stack46)
        %v47618_v55 = vor.u32 %v47617_v26, %v47616_v34 (stack47)
        %v45199_v22 = vmul.f32 %v45195_v8, %v135577_v22 (stack54)
        %vm45623_vm14 = vcmp.eq.f32.partialorder %v135626_v31, inf (stack70)
        %v46776_v32 = vadd.s32 2, %v46772_v46 (stack40)
        %v135673_v29 = vadd.s32 %v157341_v11, %v157091_v37 (stack40)
        %v135677_v34 = vadd.s32 %v157342_v9, %v157094_v36 (stack40)
        %vm45625_vm15 = vcmp.eq.f32.partialorder %v135626_v31, 0.0 (stack71)
        %v45982_v26 = vadd.s32 %v45979_v56, %v121574_v2 (stack40)
        %v46371_v42 = vadd.s32 %v46368_v44, %v46363_v42 (stack40)
        %v46373_v60 = vshll.u32 %v46368_v44, 29 (stack45)
        %v46374_v43 = vshrl.u32 %v46368_v44, 3 (stack46)
        %v45203_v50 = vadd.f32 %v45199_v22, %v135527_v50 (stack53)
        %v46780_v54 = vadd.s32 %v46776_v32, %v46764_v54 (stack40)
        %v46782_v23 = vshll.u32 %v46776_v32, 13 (stack45)
        %v46783_v8 = vshrl.u32 %v46776_v32, 19 (stack46)
        %v45986_v46 = vadd.s32 5, %v45982_v26 (stack40)
        %v46375_v56 = vor.u32 %v46374_v43, %v46373_v60 (stack47)
        %v47201_v61 = vor.u32 %v47200_v41, %v47199_v61 (stack47)
        %v47619_v44 = vxor.u32 %v47618_v55, %v135614_v52 (stack48)
        %v45207_v10 = vmul.f32 %v45203_v50, %v135440_v10 (stack54)
        %v45626_v41 = vand.u32 2147483648, %v135626_v31 (stack72)
        %v46784_v55 = vor.u32 %v46783_v8, %v46782_v23 (stack47)
        %vm48041_vm0 = vcmp.lt.u32.totalorder %v135673_v29, %v157091_v37 (stack43)
        %v45988_v25 = vxor.u32 %v45986_v46, %v45974_v25 (stack48)
        %v46376_v22 = vxor.u32 %v46375_v56, %v46371_v42 (stack48)
        %v47202_v32 = vxor.u32 %v47201_v61, %v47197_v30 (stack48)
        %v47622_v52 = vadd.s32 %v47619_v44, %v135614_v52 (stack40)
        %v120820_v26 = vpop.eup %120819 (stack73)
        %v45211_v6 = vsel /*vm=*/%vm135654_vm13, /*on_true_vy=*/%v135514_v6, /*on_false_vx=*/%v45207_v10 (stack44)
        %v46785_v12 = vxor.u32 %v46784_v55, %v46780_v54 (stack48)
        %v47624_v60 = vshll.u32 %v47619_v44, 15 (stack45)
        %v47625_v43 = vshrl.u32 %v47619_v44, 17 (stack46)
        %v45215_v50 = vmul.f32 1.4140625, %v45211_v6 (stack54)
        %v45622_v23 = vmul.f32 %v120820_v26, %v135626_v31 (stack74)
        %v45989_v8 = vand.u32.u8 255, %v45988_v25 (stack49)
        %v46379_v42 = vadd.s32 %v46376_v22, %v46371_v42 (stack40)
        %v46381_v46 = vshll.u32 %v46376_v22, 16 (stack45)
        %v46382_v56 = vshrl.u32 %v46376_v22, 16 (stack46)
        %v46788_v54 = vadd.s32 %v46785_v12, %v46780_v54 (stack40)
        %v46790_v61 = vshll.u32 %v46785_v12, 15 (stack45)
        %v45218_v44 = vpack.c.bf16 %v156663_v45, %v45215_v50 (stack81)
        %v45624_v10 = vsel /*vm=*/%vm45623_vm14, /*on_true_vy=*/%v135626_v31, /*on_false_vx=*/%v45622_v23 (stack75)
        %v45990_v55 = vand.u32 65535, %v45989_v8 (stack50)
        %v46791_v25 = vshrl.u32 %v46785_v12, 17 (stack46)
        %v45627_v41 = vsel /*vm=*/%vm45625_vm15, /*on_true_vy=*/%v45626_v41, /*on_false_vx=*/%v45624_v10 (stack76)
        %v46383_v22 = vor.u32 %v46382_v56, %v46381_v46 (stack47)
        %v47205_v30 = vadd.s32 %v47202_v32, %v47197_v30 (stack40)
        %v47207_v26 = vshll.u32 %v47202_v32, 29 (stack45)
        %119983 = vst [vmem:[%s123356_s30 + $0x3ac] sm:$0xf] /*vst_source=*/%v45218_v44 (stack83)
        %v45630_v6 = vadd.f32 -3.0, %v45627_v41 (stack53)
        %v45991_v12 = vshrl.u32 %v45990_v55, 1 (stack51)
        %v46792_v50 = vor.u32 %v46791_v25, %v46790_v61 (stack47)
        %v47208_v32 = vshrl.u32 %v47202_v32, 3 (stack46)
        %v46384_v23 = vxor.u32 %v46383_v22, %v46379_v42 (stack48)
        %v47626_v60 = vor.u32 %v47625_v43, %v47624_v60 (stack47)
        %v135701_v43 = vadd.s32 %v135673_v29, %v122657_v58 (stack40)
        %v48050_v8 = vadd.s32 1, %v135677_v34 (stack40)
        %v135707_v27 = vsel /*vm=*/%vm45578_vm12, /*on_true_vy=*/%v135635_v27, /*on_false_vx=*/%v45630_v6 (stack44)
        %v45992_v46 = vor.u32 16256, %v45991_v12 (stack47)
        %v46793_v56 = vxor.u32 %v46792_v50, %v46788_v54 (stack48)
        %v47209_v61 = vor.u32 %v47208_v32, %v47207_v26 (stack47)
        %v45638_v21 = vmul.f32 %v135707_v27, %v135666_v21 (stack54)
        %v46387_v42 = vadd.s32 %v46384_v23, %v46379_v42 (stack40)
        %v46393_v44 = vshll.u32 %v46384_v23, 24 (stack45)
        %v46394_v10 = vshrl.u32 %v46384_v23, 8 (stack46)
        %v45993_v55 = vand.u32.u16 65535, %v45992_v46 (stack52)
        %v46796_v54 = vadd.s32 %v46793_v56, %v46788_v54 (stack40)
        %v46798_v25 = vshll.u32 %v46793_v56, 26 (stack45)
        %v46799_v41 = vshrl.u32 %v46793_v56, 6 (stack46)
        %v45642_v7 = vadd.f32 %v45638_v21, %v135661_v7 (stack53)
        %v46391_v22 = vadd.s32 %v46387_v42, %v121569_v1 (stack40)
        %v46395_v26 = vor.u32 %v46394_v10, %v46393_v44 (stack47)
        %v47210_v6 = vxor.u32 %v47209_v61, %v47205_v30 (stack48)
        %v119990_v12 = vadd.low.f32.bf16 -1.0, %v45993_v55 (stack53)
        %v46800_v50 = vor.u32 %v46799_v41, %v46798_v25 (stack47)
        %v47627_v32 = vxor.u32 %v47626_v60, %v47622_v52 (stack48)
        %v48054_v34 = vsel /*vm=*/%vm48041_vm0, /*on_true_vy=*/%v48050_v8, /*on_false_vx=*/%v135677_v34 (stack44)
        %v45646_v23 = vmul.f32 %v45642_v7, %v135707_v27 (stack54)
        %v46396_v60 = vxor.u32 %v46395_v26, %v46387_v42 (stack48)
        %v47213_v30 = vadd.s32 %v47210_v6, %v47205_v30 (stack40)
        %v47215_v8 = vshll.u32 %v47210_v6, 16 (stack45)
        %v46002_v46 = vmul.f32 2.0, %v119990_v12 (stack54)
        %v46801_v56 = vxor.u32 %v46800_v50, %v46796_v54 (stack48)
        %v47216_v61 = vshrl.u32 %v47210_v6, 16 (stack46)
        %v47630_v52 = vadd.s32 %v47627_v32, %v47622_v52 (stack40)
        %v45650_v24 = vadd.f32 %v45646_v23, %v135649_v24 (stack53)
        %v46399_v21 = vadd.s32 %v46396_v60, %v121564_v0 (stack40)
        %v47632_v42 = vshll.u32 %v47627_v32, 26 (stack45)
        %v47633_v44 = vshrl.u32 %v47627_v32, 6 (stack46)
        %v46006_v10 = vadd.f32 -0.99609375, %v46002_v46 (stack53)
        %v46804_v55 = vadd.s32 %v46801_v56, %v46796_v54 (stack40)
        %v46810_v54 = vshll.u32 %v46801_v56, 6 (stack45)
        %v46811_v25 = vshrl.u32 %v46801_v56, 26 (stack46)
        %v45654_v41 = vmul.f32 %v45650_v24, %v135707_v27 (stack54)
        %v46403_v7 = vadd.s32 4, %v46399_v21 (stack40)
        %v47217_v26 = vor.u32 %v47216_v61, %v47215_v8 (stack47)
        %v47634_v6 = vor.u32 %v47633_v44, %v47632_v42 (stack47)
        %v135721_v12 = vmax.f32 %v46006_v10, -0.99609375 (stack55)
        %v46812_v50 = vor.u32 %v46811_v25, %v46810_v54 (stack47)
        %vm48036_vm1 = vcmp.lt.u32.totalorder %v135701_v43, %v135673_v29 (stack43)
        %v48058_v32 = vadd.s32 1, %v48054_v34 (stack40)
        %v45658_v20 = vadd.f32 %v45654_v41, %v135644_v20 (stack53)
        %v46407_v22 = vadd.s32 %v46403_v7, %v46391_v22 (stack40)
        %v46409_v23 = vshll.u32 %v46403_v7, 13 (stack45)
        %v46410_v60 = vshrl.u32 %v46403_v7, 19 (stack46)
        %v135727_v8 = vmul.f32 inf, %v135557_v40 (stack54)
        %v135732_v46 = vsel /*vm=*/%vm45578_vm12, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v46022_v56 = vxor.u32 2147483648, %v135721_v12 (stack56)
        %v46813_v61 = vxor.u32 %v46812_v50, %v46804_v55 (stack48)
        %v45662_v24 = vmul.f32 %v45658_v20, %v135707_v27 (stack54)
        %v46411_v21 = vor.u32 %v46410_v60, %v46409_v23 (stack47)
        %v47218_v42 = vxor.u32 %v47217_v26, %v47213_v30 (stack48)
        %v47635_v44 = vxor.u32 %v47634_v6, %v47630_v52 (stack48)
        %v45599_v10 = vsel /*vm=*/%vm45578_vm12, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v135740_v54 = vmul.f32 %v46022_v56, %v135721_v12 (stack54)
        %v46816_v25 = vadd.s32 %v46813_v61, %v121569_v1 (stack40)
        %v48062_v29 = vsel /*vm=*/%vm48036_vm1, /*on_true_vy=*/%v48058_v32, /*on_false_vx=*/%v48054_v34 (stack44)
        %v45587_v34 = vsel /*vm=*/%vm45578_vm12, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v45666_v41 = vadd.f32 %v45662_v24, %v45599_v10 (stack53)
        %v46412_v7 = vxor.u32 %v46411_v21, %v46407_v22 (stack48)
        %v47221_v30 = vadd.s32 %v47218_v42, %v47213_v30 (stack40)
        %v45595_v26 = vsel /*vm=*/%vm45578_vm12, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v46027_v6 = vadd.f32 1.0, %v135740_v54 (stack57)
        %v46808_v55 = vadd.s32 %v46804_v55, %v121574_v2 (stack40)
        %v46820_v50 = vadd.s32 3, %v46816_v25 (stack40)
        %v45670_v32 = vmul.f32 %v45666_v41, %v135707_v27 (stack54)
        %v46415_v20 = vadd.s32 %v46412_v7, %v46407_v22 (stack40)
        %v46417_v22 = vshll.u32 %v46412_v7, 15 (stack45)
        %v46418_v23 = vshrl.u32 %v46412_v7, 17 (stack46)
        %120821 = vlog2.f32 %v46027_v6 (stack58)
        %v46030_v60 = vmul.f32 -0.5, %v135740_v54 (stack59)
        %v46824_v56 = vadd.s32 %v46820_v50, %v46808_v55 (stack40)
        %v47227_v61 = vshll.u32 %v47218_v42, 24 (stack45)
        %v45674_v24 = vadd.f32 %v45670_v32, %v45595_v26 (stack53)
        %v46419_v21 = vor.u32 %v46418_v23, %v46417_v22 (stack47)
        %v46826_v10 = vshll.u32 %v46820_v50, 17 (stack45)
        %v46827_v25 = vshrl.u32 %v46820_v50, 15 (stack46)
        %v45591_v31 = vsel /*vm=*/%vm45578_vm12, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v46033_v41 = vand.u32 2147483647, %v135740_v54 (stack60)
        %v47228_v42 = vshrl.u32 %v47218_v42, 8 (stack46)
        %v47638_v52 = vadd.s32 %v47635_v44, %v47630_v52 (stack40)
        %v45678_v7 = vmul.f32 %v45674_v24, %v135707_v27 (stack54)
        %v46420_v26 = vxor.u32 %v46419_v21, %v46415_v20 (stack48)
        %v46828_v6 = vor.u32 %v46827_v25, %v46826_v10 (stack47)
        %v47644_v55 = vshll.u32 %v47635_v44, 6 (stack45)
        %v46031_v50 = vadd.f32 1.0, %v46030_v60 (stack61)
        %v47229_v32 = vor.u32 %v47228_v42, %v47227_v61 (stack47)
        %v47645_v44 = vshrl.u32 %v47635_v44, 26 (stack46)
        %v48067_v29 = vadd.s32 %v48062_v29, %v121574_v2 (stack40)
        %v45682_v22 = vadd.f32 %v45678_v7, %v45591_v31 (stack53)
        %v46423_v20 = vadd.s32 %v46420_v26, %v46415_v20 (stack40)
        %v46425_v23 = vshll.u32 %v46420_v26, 26 (stack45)
        %v46426_v60 = vshrl.u32 %v46420_v26, 6 (stack46)
        %v46829_v61 = vxor.u32 %v46828_v6, %v46824_v56 (stack48)
        %v47230_v24 = vxor.u32 %v47229_v32, %v47221_v30 (stack48)
        %v47646_v21 = vor.u32 %v47645_v44, %v47644_v55 (stack47)
        %v48071_v43 = vadd.s32 %v135701_v43, %v121569_v1 (stack40)
        %v45686_v10 = vmul.f32 %v45682_v22, %v135707_v27 (stack54)
        %v46427_v25 = vor.u32 %v46426_v60, %v46425_v23 (stack47)
        %v135767_v11 = vadd.s32 %v157341_v11, %v157095_v13 (stack40)
        %v135771_v9 = vadd.s32 %v157342_v9, %v157100_v14 (stack40)
        %vm135775_vm2 = vcmp.eq.f32.partialorder %v45551_v53, 1.0 (stack68)
        %v46832_v56 = vadd.s32 %v46829_v61, %v46824_v56 (stack40)
        %v46834_v31 = vshll.u32 %v46829_v61, 29 (stack45)
        %v46835_v42 = vshrl.u32 %v46829_v61, 3 (stack46)
        %v47233_v7 = vadd.s32 %v47230_v24, %v121574_v2 (stack40)
        %v45690_v34 = vadd.f32 %v45686_v10, %v45587_v34 (stack53)
        %v46428_v26 = vxor.u32 %v46427_v25, %v46423_v20 (stack48)
        %v47647_v6 = vxor.u32 %v47646_v21, %v47638_v52 (stack48)
        %v135780_v55 = vadd.s32 %v48071_v43, %v48067_v29 (stack40)
        %vm135782_vm3 = vcmp.lt.f32.partialorder %v46033_v41, 0.0004427343 (stack62)
        %v46836_v32 = vor.u32 %v46835_v42, %v46834_v31 (stack47)
        %v47225_v30 = vadd.s32 %v47221_v30, %v121564_v0 (stack40)
        %v47237_v44 = vadd.s32 2, %v47233_v7 (stack40)
        %v45694_v27 = vmul.f32 %v45690_v34, %v135707_v27 (stack54)
        %v46431_v29 = vadd.s32 %v46428_v26, %v46423_v20 (stack40)
        %v46437_v22 = vshll.u32 %v46428_v26, 6 (stack45)
        %v46438_v20 = vshrl.u32 %v46428_v26, 26 (stack46)
        %v46837_v23 = vxor.u32 %v46836_v32, %v46832_v56 (stack48)
        %v47241_v60 = vadd.s32 %v47237_v44, %v47225_v30 (stack40)
        %v47243_v61 = vshll.u32 %v47237_v44, 13 (stack45)
        %v47244_v24 = vshrl.u32 %v47237_v44, 19 (stack46)
        %v120822_v21 = vpop.eup %120821 (stack64)
        %v45698_v46 = vadd.f32 %v45694_v27, %v135732_v46 (stack53)
        %v46032_v54 = vmul.f32 %v46031_v50, %v135740_v54 (stack63)
        %v46439_v50 = vor.u32 %v46438_v20, %v46437_v22 (stack47)
        %v47650_v10 = vadd.s32 %v47647_v6, %v121564_v0 (stack40)
        %v46029_v25 = vmul.f32 0.6931472, %v120822_v21 (stack65)
        %v46840_v56 = vadd.s32 %v46837_v23, %v46832_v56 (stack40)
        %v46842_v31 = vshll.u32 %v46837_v23, 16 (stack45)
        %v46843_v42 = vshrl.u32 %v46837_v23, 16 (stack46)
        %v45702_v40 = vmul.f32 %v45698_v46, %v135557_v40 (stack54)
        %v46440_v7 = vxor.u32 %v46439_v50, %v46431_v29 (stack48)
        %v47245_v34 = vor.u32 %v47244_v24, %v47243_v61 (stack47)
        %v47654_v26 = vadd.s32 1, %v47650_v10 (stack40)
        %v46035_v6 = vsel /*vm=*/%vm135782_vm3, /*on_true_vy=*/%v46032_v54, /*on_false_vx=*/%v46029_v25 (stack66)
        %v46844_v41 = vor.u32 %v46843_v42, %v46842_v31 (stack47)
        %v47642_v52 = vadd.s32 %v47638_v52, %v121569_v1 (stack40)
        %v48077_v32 = vshll.u32 %v48071_v43, 13 (stack45)
        %v45706_v8 = vsel /*vm=*/%vm135775_vm2, /*on_true_vy=*/%v135727_v8, /*on_false_vx=*/%v45702_v40 (stack44)
        %v135798_v53 = vxor.u32 2147483648, %v46035_v6 (stack56)
        %v47246_v30 = vxor.u32 %v47245_v34, %v47241_v60 (stack48)
        %v48078_v43 = vshrl.u32 %v48071_v43, 19 (stack46)
        %v45710_v44 = vmul.f32 1.4140625, %v45706_v8 (stack54)
        %v46845_v27 = vxor.u32 %v46844_v41, %v46840_v56 (stack48)
        %v47658_v22 = vadd.s32 %v47654_v26, %v47642_v52 (stack40)
        %120823 = vrsqrt.f32 %v135798_v53 (stack67)
        %v46443_v20 = vadd.s32 %v46440_v7, %v121574_v2 (stack40)
        %v45713_v23 = vpack.c.bf16 %v156663_v45, %v45710_v44 (stack81)
        %vm46039_vm4 = vcmp.lt.f32.partialorder %v135798_v53, 5.0 (stack68)
        %v46435_v29 = vadd.s32 %v46431_v29, %v121564_v0 (stack40)
        %v46848_v61 = vadd.s32 %v46845_v27, %v46840_v56 (stack40)
        %v48079_v24 = vor.u32 %v48078_v43, %v48077_v32 (stack47)
        %119989 = vst [vmem:[%s123356_s30 + $0x30] sm:$0xf] /*vst_source=*/%v45713_v23 (stack83)
        %v135807_v21 = vadd.f32 -2.5, %v135798_v53 (stack53)
        %v47249_v60 = vadd.s32 %v47246_v30, %v47241_v60 (stack40)
        %v47660_v46 = vshll.u32 %v47654_v26, 17 (stack45)
        %v48493_v54 = vadd.s32 %v135767_v11, %v122657_v58 (stack40)
        %v135814_v50 = vsel /*vm=*/%vm46039_vm4, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v135819_v10 = vsel /*vm=*/%vm46039_vm4, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v46087_v25 = vand.u32 2147483648, %v135798_v53 (stack72)
        %v46447_v56 = vadd.s32 5, %v46443_v20 (stack40)
        %v46854_v31 = vshll.u32 %v46845_v27, 24 (stack45)
        %v46855_v42 = vshrl.u32 %v46845_v27, 8 (stack46)
        %v47251_v40 = vshll.u32 %v47246_v30, 15 (stack45)
        %v47252_v7 = vshrl.u32 %v47246_v30, 17 (stack46)
        %v46449_v34 = vxor.u32 %v46447_v56, %v46435_v29 (stack48)
        %v46852_v6 = vadd.s32 %v46848_v61, %v121569_v1 (stack40)
        %v47661_v26 = vshrl.u32 %v47654_v26, 15 (stack46)
        %v48080_v41 = vxor.u32 %v48079_v24, %v135780_v55 (stack48)
        %vm46084_vm5 = vcmp.eq.f32.partialorder %v135798_v53, inf (stack70)
        %v46856_v52 = vor.u32 %v46855_v42, %v46854_v31 (stack47)
        %v47253_v32 = vor.u32 %v47252_v7, %v47251_v40 (stack47)
        %vm48502_vm6 = vcmp.lt.u32.totalorder %v135767_v11, %v157095_v13 (stack43)
        %v48511_v8 = vadd.s32 1, %v135771_v9 (stack40)
        %vm46086_vm7 = vcmp.eq.f32.partialorder %v135798_v53, 0.0 (stack71)
        %v46450_v30 = vand.u32.u8 255, %v46449_v34 (stack49)
        %v47662_v43 = vor.u32 %v47661_v26, %v47660_v46 (stack47)
        %v48083_v55 = vadd.s32 %v48080_v41, %v135780_v55 (stack40)
        %v48085_v44 = vshll.u32 %v48080_v41, 15 (stack45)
        %v46857_v27 = vxor.u32 %v46856_v52, %v46848_v61 (stack48)
        %v47254_v20 = vxor.u32 %v47253_v32, %v47249_v60 (stack48)
        %v48086_v23 = vshrl.u32 %v48080_v41, 17 (stack46)
        %v48515_v9 = vsel /*vm=*/%vm48502_vm6, /*on_true_vy=*/%v48511_v8, /*on_false_vx=*/%v135771_v9 (stack44)
        %v46451_v29 = vand.u32 65535, %v46450_v30 (stack50)
        %v47663_v61 = vxor.u32 %v47662_v43, %v47658_v22 (stack48)
        %vm48497_vm8 = vcmp.lt.u32.totalorder %v48493_v54, %v135767_v11 (stack43)
        %v48519_v11 = vadd.s32 1, %v48515_v9 (stack40)
        %v46860_v24 = vadd.s32 %v46857_v27, %v121564_v0 (stack40)
        %v47257_v60 = vadd.s32 %v47254_v20, %v47249_v60 (stack40)
        %v47259_v46 = vshll.u32 %v47254_v20, 26 (stack45)
        %v47260_v56 = vshrl.u32 %v47254_v20, 6 (stack46)
        %v46452_v31 = vshrl.u32 %v46451_v29, 1 (stack51)
        %v47666_v22 = vadd.s32 %v47663_v61, %v47658_v22 (stack40)
        %v47668_v42 = vshll.u32 %v47663_v61, 29 (stack45)
        %v47669_v40 = vshrl.u32 %v47663_v61, 3 (stack46)
        %v120824_v7 = vpop.eup %120823 (stack73)
        %v46864_v34 = vadd.s32 4, %v46860_v24 (stack40)
        %v47261_v26 = vor.u32 %v47260_v56, %v47259_v46 (stack47)
        %v48087_v41 = vor.u32 %v48086_v23, %v48085_v44 (stack47)
        %v48523_v52 = vsel /*vm=*/%vm48497_vm8, /*on_true_vy=*/%v48519_v11, /*on_false_vx=*/%v48515_v9 (stack44)
        %v46083_v32 = vmul.f32 %v120824_v7, %v135798_v53 (stack74)
        %v46453_v8 = vor.u32 16256, %v46452_v31 (stack47)
        %v47670_v30 = vor.u32 %v47669_v40, %v47668_v42 (stack47)
        %v135835_v54 = vadd.s32 %v48493_v54, %v121569_v1 (stack40)
        %v46868_v6 = vadd.s32 %v46864_v34, %v46852_v6 (stack40)
        %v46870_v43 = vshll.u32 %v46864_v34, 13 (stack45)
        %v46871_v44 = vshrl.u32 %v46864_v34, 19 (stack46)
        %v47262_v27 = vxor.u32 %v47261_v26, %v47257_v60 (stack48)
        %v46085_v20 = vsel /*vm=*/%vm46084_vm5, /*on_true_vy=*/%v135798_v53, /*on_false_vx=*/%v46083_v32 (stack75)
        %v46454_v23 = vand.u32.u16 65535, %v46453_v8 (stack52)
        %v47671_v9 = vxor.u32 %v47670_v30, %v47666_v22 (stack48)
        %v48088_v29 = vxor.u32 %v48087_v41, %v48083_v55 (stack48)
        %v46088_v25 = vsel /*vm=*/%vm46086_vm7, /*on_true_vy=*/%v46087_v25, /*on_false_vx=*/%v46085_v20 (stack76)
        %v46872_v61 = vor.u32 %v46871_v44, %v46870_v43 (stack47)
        %v47265_v11 = vadd.s32 %v47262_v27, %v47257_v60 (stack40)
        %v47271_v24 = vshll.u32 %v47262_v27, 6 (stack45)
        %v46091_v60 = vadd.f32 -3.0, %v46088_v25 (stack53)
        %v119992_v46 = vadd.low.f32.bf16 -1.0, %v46454_v23 (stack53)
        %v47272_v56 = vshrl.u32 %v47262_v27, 26 (stack46)
        %v47674_v31 = vadd.s32 %v47671_v9, %v47666_v22 (stack40)
        %v46873_v22 = vxor.u32 %v46872_v61, %v46868_v6 (stack48)
        %v47676_v42 = vshll.u32 %v47671_v9, 16 (stack45)
        %v47677_v40 = vshrl.u32 %v47671_v9, 16 (stack46)
        %v48528_v7 = vadd.s32 %v48523_v52, %v121574_v2 (stack40)
        %v135846_v21 = vsel /*vm=*/%vm46039_vm4, /*on_true_vy=*/%v135807_v21, /*on_false_vx=*/%v46091_v60 (stack44)
        %v46463_v34 = vmul.f32 2.0, %v119992_v46 (stack54)
        %v47273_v26 = vor.u32 %v47272_v56, %v47271_v24 (stack47)
        %v135848_v55 = vadd.s32 %v48088_v29, %v48083_v55 (stack40)
        %v46099_v10 = vmul.f32 %v135846_v21, %v135819_v10 (stack54)
        %v46876_v41 = vadd.s32 %v46873_v22, %v46868_v6 (stack40)
        %v46878_v52 = vshll.u32 %v46873_v22, 15 (stack45)
        %v46879_v32 = vshrl.u32 %v46873_v22, 17 (stack46)
        %v46072_v8 = vsel /*vm=*/%vm46039_vm4, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v46467_v30 = vadd.f32 -0.99609375, %v46463_v34 (stack53)
        %v47274_v6 = vxor.u32 %v47273_v26, %v47265_v11 (stack48)
        %v47678_v43 = vor.u32 %v47677_v40, %v47676_v42 (stack47)
        %v135858_v44 = vsel /*vm=*/%vm46039_vm4, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v46103_v27 = vadd.f32 %v46099_v10, %v46072_v8 (stack53)
        %v46880_v20 = vor.u32 %v46879_v32, %v46878_v52 (stack47)
        %v135861_v23 = vadd.s32 %v135835_v54, %v48528_v7 (stack40)
        %v46064_v9 = vsel /*vm=*/%vm46039_vm4, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v135866_v25 = vmax.f32 %v46467_v30, -0.99609375 (stack55)
        %v47277_v61 = vadd.s32 %v47274_v6, %v121569_v1 (stack40)
        %v47679_v24 = vxor.u32 %v47678_v43, %v47674_v31 (stack48)
        %v46068_v60 = vsel /*vm=*/%vm46039_vm4, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v46107_v46 = vmul.f32 %v46103_v27, %v135846_v21 (stack54)
        %v46881_v56 = vxor.u32 %v46880_v20, %v46876_v41 (stack48)
        %v47269_v11 = vadd.s32 %v47265_v11, %v121574_v2 (stack40)
        %v46483_v22 = vxor.u32 2147483648, %v135866_v25 (stack56)
        %v47281_v42 = vadd.s32 3, %v47277_v61 (stack40)
        %v48093_v40 = vshll.u32 %v48088_v29, 26 (stack45)
        %v48094_v29 = vshrl.u32 %v48088_v29, 6 (stack46)
        %v46111_v7 = vadd.f32 %v46107_v46, %v46068_v60 (stack53)
        %v46884_v34 = vadd.s32 %v46881_v56, %v46876_v41 (stack40)
        %v46886_v26 = vshll.u32 %v46881_v56, 26 (stack45)
        %v46887_v10 = vshrl.u32 %v46881_v56, 6 (stack46)
        %v135876_v41 = vmul.f32 %v46483_v22, %v135866_v25 (stack54)
        %v47285_v52 = vadd.s32 %v47281_v42, %v47269_v11 (stack40)
        %v47287_v32 = vshll.u32 %v47281_v42, 17 (stack45)
        %v48538_v8 = vshll.u32 %v135835_v54, 13 (stack45)
        %v46115_v30 = vmul.f32 %v46111_v7, %v135846_v21 (stack54)
        %v46888_v6 = vor.u32 %v46887_v10, %v46886_v26 (stack47)
        %v47288_v43 = vshrl.u32 %v47281_v42, 15 (stack46)
        %v47682_v31 = vadd.s32 %v47679_v24, %v47674_v31 (stack40)
        %v46488_v27 = vadd.f32 1.0, %v135876_v41 (stack57)
        %v47688_v20 = vshll.u32 %v47679_v24, 24 (stack45)
        %v48095_v61 = vor.u32 %v48094_v29, %v48093_v40 (stack47)
        %v48539_v54 = vshrl.u32 %v135835_v54, 19 (stack46)
        %v46119_v9 = vadd.f32 %v46115_v30, %v46064_v9 (stack53)
        %v46491_v60 = vmul.f32 -0.5, %v135876_v41 (stack59)
        %v46889_v46 = vxor.u32 %v46888_v6, %v46884_v34 (stack48)
        %v47289_v56 = vor.u32 %v47288_v43, %v47287_v32 (stack47)
        %v46060_v11 = vsel /*vm=*/%vm46039_vm4, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %120825 = vlog2.f32 %v46488_v27 (stack58)
        %v46494_v22 = vand.u32 2147483647, %v135876_v41 (stack60)
        %v47689_v24 = vshrl.u32 %v47679_v24, 8 (stack46)
        %v46123_v42 = vmul.f32 %v46119_v9, %v135846_v21 (stack54)
        %v46892_v40 = vadd.s32 %v46889_v46, %v46884_v34 (stack40)
        %v46898_v29 = vshll.u32 %v46889_v46, 6 (stack45)
        %v46899_v7 = vshrl.u32 %v46889_v46, 26 (stack46)
        %v47290_v34 = vxor.u32 %v47289_v56, %v47285_v52 (stack48)
        %v47686_v26 = vadd.s32 %v47682_v31, %v121564_v0 (stack40)
        %v47690_v10 = vor.u32 %v47689_v24, %v47688_v20 (stack47)
        %v48096_v32 = vxor.u32 %v48095_v61, %v135848_v55 (stack48)
        %v46127_v30 = vadd.f32 %v46123_v42, %v46060_v11 (stack53)
        %v46492_v6 = vadd.f32 1.0, %v46491_v60 (stack61)
        %v46900_v43 = vor.u32 %v46899_v7, %v46898_v29 (stack47)
        %v48540_v8 = vor.u32 %v48539_v54, %v48538_v8 (stack47)
        %v47293_v52 = vadd.s32 %v47290_v34, %v47285_v52 (stack40)
        %v47295_v27 = vshll.u32 %v47290_v34, 29 (stack45)
        %v47296_v20 = vshrl.u32 %v47290_v34, 3 (stack46)
        %v47691_v31 = vxor.u32 %v47690_v10, %v47682_v31 (stack48)
        %v46131_v61 = vmul.f32 %v46127_v30, %v135846_v21 (stack54)
        %v46901_v54 = vxor.u32 %v46900_v43, %v46892_v40 (stack48)
        %v135892_v55 = vadd.s32 %v48096_v32, %v135848_v55 (stack40)
        %v48105_v9 = vshll.u32 %v48096_v32, 6 (stack45)
        %v47297_v60 = vor.u32 %v47296_v20, %v47295_v27 (stack47)
        %v47694_v46 = vadd.s32 %v47691_v31, %v121574_v2 (stack40)
        %v48106_v56 = vshrl.u32 %v48096_v32, 26 (stack46)
        %v48541_v11 = vxor.u32 %v48540_v8, %v135861_v23 (stack48)
        %v46135_v44 = vadd.f32 %v46131_v61, %v135858_v44 (stack53)
        %v46896_v24 = vadd.s32 %v46892_v40, %v121564_v0 (stack40)
        %v46904_v42 = vadd.s32 %v46901_v54, %v121574_v2 (stack40)
        %v157365_v40 = vld [vmem:[#allocation133_spill] sm:$0xff] (stack84)
        %v135901_v29 = vadd.s32 %v157365_v40, %v122651_v47 (stack40)
        %v47298_v7 = vxor.u32 %v47297_v60, %v47293_v52 (stack48)
        %v47698_v34 = vadd.s32 2, %v47694_v46 (stack40)
        %v48107_v10 = vor.u32 %v48106_v56, %v48105_v9 (stack47)
        %v135904_v23 = vadd.s32 %v48541_v11, %v135861_v23 (stack40)
        %v46139_v32 = vmul.f32 %v46135_v44, %v135846_v21 (stack54)
        %v46908_v30 = vadd.s32 5, %v46904_v42 (stack40)
        %v48546_v43 = vshll.u32 %v48541_v11, 15 (stack45)
        %v48547_v8 = vshrl.u32 %v48541_v11, 17 (stack46)
        %v47301_v52 = vadd.s32 %v47298_v7, %v47293_v52 (stack40)
        %v47303_v27 = vshll.u32 %v47298_v7, 16 (stack45)
        %v47304_v20 = vshrl.u32 %v47298_v7, 16 (stack46)
        %v47702_v26 = vadd.s32 %v47698_v34, %v47686_v26 (stack40)
        %v46143_v50 = vadd.f32 %v46139_v32, %v135814_v50 (stack53)
        %v46910_v31 = vxor.u32 %v46908_v30, %v46896_v24 (stack48)
        %v47704_v61 = vshll.u32 %v47698_v34, 13 (stack45)
        %v47705_v54 = vshrl.u32 %v47698_v34, 19 (stack46)
        %v46048_v9 = vsel /*vm=*/%vm46039_vm4, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v47305_v60 = vor.u32 %v47304_v20, %v47303_v27 (stack47)
        %v48108_v46 = vxor.u32 %v48107_v10, %v135892_v55 (stack48)
        %v48548_v56 = vor.u32 %v48547_v8, %v48546_v43 (stack47)
        %v120826_v11 = vpop.eup %120825 (stack64)
        %v46147_v44 = vmul.f32 %v46143_v50, %v135846_v21 (stack54)
        %v46911_v24 = vand.u32.u8 255, %v46910_v31 (stack49)
        %v47706_v42 = vor.u32 %v47705_v54, %v47704_v61 (stack47)
        %vm48997_vm9 = vcmp.lt.u32.totalorder %v135901_v29, %v122651_v47 (stack43)
        %v46490_v7 = vmul.f32 0.6931472, %v120826_v11 (stack65)
        %v46493_v41 = vmul.f32 %v46492_v6, %v135876_v41 (stack63)
        %v47306_v6 = vxor.u32 %v47305_v60, %v47301_v52 (stack48)
        %v48549_v34 = vxor.u32 %v48548_v56, %v135904_v23 (stack48)
        %v46151_v10 = vadd.f32 %v46147_v44, %v46048_v9 (stack53)
        %vm46495_vm10 = vcmp.lt.f32.partialorder %v46494_v22, 0.0004427343 (stack62)
        %v46912_v22 = vand.u32 65535, %v46911_v24 (stack50)
        %v47707_v32 = vxor.u32 %v47706_v42, %v47702_v26 (stack48)
        %v46496_v30 = vsel /*vm=*/%vm46495_vm10, /*on_true_vy=*/%v46493_v41, /*on_false_vx=*/%v46490_v7 (stack66)
        %v47309_v43 = vadd.s32 %v47306_v6, %v47301_v52 (stack40)
        %v47315_v8 = vshll.u32 %v47306_v6, 24 (stack45)
        %v47316_v52 = vshrl.u32 %v47306_v6, 8 (stack46)
        %v46012_v27 = vand.u32 2147483647, %v135721_v12 (stack77)
        %v46155_v21 = vmul.f32 %v46151_v10, %v135846_v21 (stack54)
        %v135919_v20 = vxor.u32 2147483648, %v46496_v30 (stack56)
        %v47710_v26 = vadd.s32 %v47707_v32, %v47702_v26 (stack40)
        %v46044_v53 = vsel /*vm=*/%vm46039_vm4, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v47317_v50 = vor.u32 %v47316_v52, %v47315_v8 (stack47)
        %v46159_v31 = vadd.f32 %v46155_v21, %v46044_v53 (stack53)
        %120827 = vrsqrt.f32 %v135919_v20 (stack67)
        %v46913_v61 = vshrl.u32 %v46912_v22, 1 (stack51)
        %vm46500_vm11 = vcmp.lt.f32.partialorder %v135919_v20, 5.0 (stack68)
        %v47318_v54 = vxor.u32 %v47317_v50, %v47309_v43 (stack48)
        %v47712_v9 = vshll.u32 %v47707_v32, 15 (stack45)
        %v47713_v60 = vshrl.u32 %v47707_v32, 17 (stack46)
        %vm46015_vm12 = vcmp.eq.f32.partialorder %v46012_v27, 1.0 (stack68)
        %v46020_v56 = vmul.f32 inf, %v135721_v12 (stack54)
        %v46163_v12 = vmul.f32 %v46159_v31, %v135721_v12 (stack54)
        %v48111_v46 = vadd.s32 %v48108_v46, %v121564_v0 (stack40)
        %v47313_v11 = vadd.s32 %v47309_v43, %v121569_v1 (stack40)
        %v47321_v44 = vadd.s32 %v47318_v54, %v121564_v0 (stack40)
        %v48103_v55 = vadd.s32 %v135892_v55, %v121569_v1 (stack40)
        %v135935_v24 = vadd.s32 %v135901_v29, %v122657_v58 (stack40)
        %v46167_v42 = vsel /*vm=*/%vm46015_vm12, /*on_true_vy=*/%v46020_v56, /*on_false_vx=*/%v46163_v12 (stack44)
        %v135940_v7 = vsel /*vm=*/%vm46500_vm11, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v135945_v41 = vsel /*vm=*/%vm46500_vm11, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v135948_v6 = vadd.f32 -2.5, %v135919_v20 (stack53)
        %v46171_v10 = vmul.f32 1.4140625, %v46167_v42 (stack54)
        %v46914_v22 = vor.u32 16256, %v46913_v61 (stack47)
        %v47325_v32 = vadd.s32 4, %v47321_v44 (stack40)
        %v47714_v30 = vor.u32 %v47713_v60, %v47712_v9 (stack47)
        %v48115_v43 = vadd.s32 1, %v48111_v46 (stack40)
        %v48552_v23 = vadd.s32 %v48549_v34, %v135904_v23 (stack40)
        %v48554_v8 = vshll.u32 %v48549_v34, 26 (stack45)
        %v48555_v34 = vshrl.u32 %v48549_v34, 6 (stack46)
        %v46174_v52 = vpack.c.bf16 %v156663_v45, %v46171_v10 (stack81)
        %v46915_v27 = vand.u32.u16 65535, %v46914_v22 (stack52)
        %v47329_v21 = vadd.s32 %v47325_v32, %v47313_v11 (stack40)
        %v47331_v53 = vshll.u32 %v47325_v32, 13 (stack45)
        %v47332_v50 = vshrl.u32 %v47325_v32, 19 (stack46)
        %v47715_v31 = vxor.u32 %v47714_v30, %v47710_v26 (stack48)
        %v48119_v61 = vadd.s32 %v48115_v43, %v48103_v55 (stack40)
        %v48121_v54 = vshll.u32 %v48115_v43, 17 (stack45)
        %119991 = vst [vmem:[%s123356_s30 + $0xb0] sm:$0xf] /*vst_source=*/%v46174_v52 (stack83)
        %v119994_v9 = vadd.low.f32.bf16 -1.0, %v46915_v27 (stack53)
        %v48122_v60 = vshrl.u32 %v48115_v43, 15 (stack46)
        %v48556_v56 = vor.u32 %v48555_v34, %v48554_v8 (stack47)
        %v157366_v12 = vld [vmem:[#allocation97_spill] sm:$0xff] (stack84)
        %v135955_v46 = vadd.s32 %v157366_v12, %v157068_v28 (stack40)
        %v47333_v11 = vor.u32 %v47332_v50, %v47331_v53 (stack47)
        %v47718_v26 = vadd.s32 %v47715_v31, %v47710_v26 (stack40)
        %v47720_v44 = vshll.u32 %v47715_v31, 26 (stack45)
        %v47721_v55 = vshrl.u32 %v47715_v31, 6 (stack46)
        %v135960_v42 = vsel /*vm=*/%vm46500_vm11, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v46924_v10 = vmul.f32 2.0, %v119994_v9 (stack54)
        %v48123_v22 = vor.u32 %v48122_v60, %v48121_v54 (stack47)
        %v135962_v32 = vxor.u32 %v48556_v56, %v48552_v23 (stack48)
        %vm46545_vm13 = vcmp.eq.f32.partialorder %v135919_v20, inf (stack70)
        %v47334_v30 = vxor.u32 %v47333_v11, %v47329_v21 (stack48)
        %v47722_v43 = vor.u32 %v47721_v55, %v47720_v44 (stack47)
        %v135967_v8 = vadd.s32 %v157365_v40, %v157070_v38 (stack40)
        %v120828_v34 = vpop.eup %120827 (stack73)
        %v46548_v52 = vand.u32 2147483648, %v135919_v20 (stack72)
        %v46928_v27 = vadd.f32 -0.99609375, %v46924_v10 (stack53)
        %v48124_v53 = vxor.u32 %v48123_v22, %v48119_v61 (stack48)
        %v135971_v23 = vadd.s32 %v135962_v32, %v48552_v23 (stack40)
        %v46544_v50 = vmul.f32 %v120828_v34, %v135919_v20 (stack74)
        %v47337_v21 = vadd.s32 %v47334_v30, %v47329_v21 (stack40)
        %v47339_v31 = vshll.u32 %v47334_v30, 15 (stack45)
        %v47340_v54 = vshrl.u32 %v47334_v30, 17 (stack46)
        %v135974_v9 = vmax.f32 %v46928_v27, -0.99609375 (stack55)
        %v47723_v60 = vxor.u32 %v47722_v43, %v47718_v26 (stack48)
        %v48127_v61 = vadd.s32 %v48124_v53, %v48119_v61 (stack40)
        %v48129_v56 = vshll.u32 %v48124_v53, 29 (stack45)
        %v46546_v11 = vsel /*vm=*/%vm46545_vm13, /*on_true_vy=*/%v135919_v20, /*on_false_vx=*/%v46544_v50 (stack75)
        %vm46547_vm14 = vcmp.eq.f32.partialorder %v135919_v20, 0.0 (stack71)
        %v47341_v44 = vor.u32 %v47340_v54, %v47339_v31 (stack47)
        %v48130_v55 = vshrl.u32 %v48124_v53, 3 (stack46)
        %v46529_v10 = vsel /*vm=*/%vm46500_vm11, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v46533_v22 = vsel /*vm=*/%vm46500_vm11, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v46549_v30 = vsel /*vm=*/%vm46547_vm14, /*on_true_vy=*/%v46548_v52, /*on_false_vx=*/%v46546_v11 (stack76)
        %v46944_v43 = vxor.u32 2147483648, %v135974_v9 (stack56)
        %v46552_v34 = vadd.f32 -3.0, %v46549_v30 (stack53)
        %v47342_v52 = vxor.u32 %v47341_v44, %v47337_v21 (stack48)
        %v47726_v26 = vadd.s32 %v47723_v60, %v47718_v26 (stack40)
        %v47732_v27 = vshll.u32 %v47723_v60, 6 (stack45)
        %v46537_v53 = vsel /*vm=*/%vm46500_vm11, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v135991_v50 = vmul.f32 %v46944_v43, %v135974_v9 (stack54)
        %v47733_v31 = vshrl.u32 %v47723_v60, 26 (stack46)
        %v48131_v54 = vor.u32 %v48130_v55, %v48129_v56 (stack47)
        %v135996_v6 = vsel /*vm=*/%vm46500_vm11, /*on_true_vy=*/%v135948_v6, /*on_false_vx=*/%v46552_v34 (stack44)
        %v47345_v21 = vadd.s32 %v47342_v52, %v47337_v21 (stack40)
        %v47347_v60 = vshll.u32 %v47342_v52, 26 (stack45)
        %v47348_v56 = vshrl.u32 %v47342_v52, 6 (stack46)
        %v46560_v11 = vmul.f32 %v135996_v6, %v46537_v53 (stack54)
        %v46949_v44 = vadd.f32 1.0, %v135991_v50 (stack57)
        %vm48992_vm15 = vcmp.lt.u32.totalorder %v135935_v24, %v135901_v29 (stack43)
        %v49006_v55 = vadd.s32 1, %v135955_v46 (stack40)
        %v136005_v30 = vadd.s32 %v135935_v24, %v121569_v1 (stack40)
        %v47349_v43 = vor.u32 %v47348_v56, %v47347_v60 (stack47)
        %v47734_v34 = vor.u32 %v47733_v31, %v47732_v27 (stack47)
        %v48132_v52 = vxor.u32 %v48131_v54, %v48127_v61 (stack48)
        %v48566_v27 = vshll.u32 %v135962_v32, 6 (stack45)
        %v46564_v22 = vadd.f32 %v46560_v11, %v46533_v22 (stack53)
        %120829 = vlog2.f32 %v46949_v44 (stack58)
        %v46952_v53 = vmul.f32 -0.5, %v135991_v50 (stack59)
        %v48564_v31 = vadd.s32 %v135971_v23, %v121569_v1 (stack40)
        %v47350_v54 = vxor.u32 %v47349_v43, %v47345_v21 (stack48)
        %v47735_v60 = vxor.u32 %v47734_v34, %v47726_v26 (stack48)
        %v48135_v61 = vadd.s32 %v48132_v52, %v48127_v61 (stack40)
        %v48137_v56 = vshll.u32 %v48132_v52, 16 (stack45)
        %v46568_v11 = vmul.f32 %v46564_v22, %v135996_v6 (stack54)
        %v46955_v44 = vand.u32 2147483647, %v135991_v50 (stack60)
        %v48138_v43 = vshrl.u32 %v48132_v52, 16 (stack46)
        %v48567_v32 = vshrl.u32 %v135962_v32, 26 (stack46)
        %v47353_v21 = vadd.s32 %v47350_v54, %v47345_v21 (stack40)
        %v47359_v34 = vshll.u32 %v47350_v54, 6 (stack45)
        %v47360_v52 = vshrl.u32 %v47350_v54, 26 (stack46)
        %v47738_v22 = vadd.s32 %v47735_v60, %v121569_v1 (stack40)
        %v46572_v10 = vadd.f32 %v46568_v11, %v46529_v10 (stack53)
        %v48139_v54 = vor.u32 %v48138_v43, %v48137_v56 (stack47)
        %v48568_v27 = vor.u32 %v48567_v32, %v48566_v27 (stack47)
        %v49010_v46 = vsel /*vm=*/%vm48997_vm9, /*on_true_vy=*/%v49006_v55, /*on_false_vx=*/%v135955_v46 (stack44)
        %v47361_v55 = vor.u32 %v47360_v52, %v47359_v34 (stack47)
        %v47730_v26 = vadd.s32 %v47726_v26, %v121574_v2 (stack40)
        %v47742_v60 = vadd.s32 3, %v47738_v22 (stack40)
        %v49014_v56 = vadd.s32 1, %v49010_v46 (stack40)
        %v46576_v11 = vmul.f32 %v46572_v10, %v135996_v6 (stack54)
        %v46953_v53 = vadd.f32 1.0, %v46952_v53 (stack61)
        %v48140_v43 = vxor.u32 %v48139_v54, %v48135_v61 (stack48)
        %v48569_v23 = vxor.u32 %v48568_v27, %v135971_v23 (stack48)
        %v47362_v32 = vxor.u32 %v47361_v55, %v47353_v21 (stack48)
        %v47746_v34 = vadd.s32 %v47742_v60, %v47730_v26 (stack40)
        %v47748_v52 = vshll.u32 %v47742_v60, 17 (stack45)
        %v47749_v22 = vshrl.u32 %v47742_v60, 15 (stack46)
        %v46580_v42 = vadd.f32 %v46576_v11, %v135960_v42 (stack53)
        %v48143_v61 = vadd.s32 %v48140_v43, %v48135_v61 (stack40)
        %v48149_v10 = vshll.u32 %v48140_v43, 24 (stack45)
        %v48150_v54 = vshrl.u32 %v48140_v43, 8 (stack46)
        %v47365_v27 = vadd.s32 %v47362_v32, %v121574_v2 (stack40)
        %v47750_v55 = vor.u32 %v47749_v22, %v47748_v52 (stack47)
        %v48572_v26 = vadd.s32 %v48569_v23, %v121564_v0 (stack40)
        %v49018_v29 = vsel /*vm=*/%vm48992_vm15, /*on_true_vy=*/%v49014_v56, /*on_false_vx=*/%v49010_v46 (stack44)
        %v46584_v24 = vmul.f32 %v46580_v42, %v135996_v6 (stack54)
        %vm136029_vm0 = vcmp.lt.f32.partialorder %v46955_v44, 0.0004427343 (stack62)
        %v48151_v46 = vor.u32 %v48150_v54, %v48149_v10 (stack47)
        %v49023_v60 = vadd.s32 %v49018_v29, %v121574_v2 (stack40)
        %v47357_v21 = vadd.s32 %v47353_v21, %v121564_v0 (stack40)
        %v47369_v56 = vadd.s32 5, %v47365_v27 (stack40)
        %v47751_v11 = vxor.u32 %v47750_v55, %v47746_v34 (stack48)
        %v48576_v43 = vadd.s32 1, %v48572_v26 (stack40)
        %v46588_v41 = vadd.f32 %v46584_v24, %v135945_v41 (stack53)
        %v46954_v50 = vmul.f32 %v46953_v53, %v135991_v50 (stack63)
        %v48152_v53 = vxor.u32 %v48151_v46, %v48143_v61 (stack48)
        %v49031_v23 = vadd.s32 %v136005_v30, %v49023_v60 (stack40)
        %v120830_v32 = vpop.eup %120829 (stack64)
        %v47371_v52 = vxor.u32 %v47369_v56, %v47357_v21 (stack48)
        %v47754_v34 = vadd.s32 %v47751_v11, %v47746_v34 (stack40)
        %v47756_v22 = vshll.u32 %v47751_v11, 29 (stack45)
        %v47757_v42 = vshrl.u32 %v47751_v11, 3 (stack46)
        %v46592_v10 = vmul.f32 %v46588_v41, %v135996_v6 (stack54)
        %v46951_v54 = vmul.f32 0.6931472, %v120830_v32 (stack65)
        %v48155_v27 = vadd.s32 %v48152_v53, %v121574_v2 (stack40)
        %v48580_v31 = vadd.s32 %v48576_v43, %v48564_v31 (stack40)
        %v47372_v55 = vand.u32.u8 255, %v47371_v52 (stack49)
        %v47758_v26 = vor.u32 %v47757_v42, %v47756_v22 (stack47)
        %v48147_v61 = vadd.s32 %v48143_v61, %v121564_v0 (stack40)
        %v48582_v29 = vshll.u32 %v48576_v43, 17 (stack45)
        %v46596_v7 = vadd.f32 %v46592_v10, %v135940_v7 (stack53)
        %v46957_v24 = vsel /*vm=*/%vm136029_vm0, /*on_true_vy=*/%v46954_v50, /*on_false_vx=*/%v46951_v54 (stack66)
        %v48159_v44 = vadd.s32 2, %v48155_v27 (stack40)
        %v48583_v46 = vshrl.u32 %v48576_v43, 15 (stack46)
        %v136044_v60 = vxor.u32 2147483648, %v46957_v24 (stack56)
        %v47759_v21 = vxor.u32 %v47758_v26, %v47754_v34 (stack48)
        %v49033_v56 = vshll.u32 %v136005_v30, 13 (stack45)
        %v49034_v30 = vshrl.u32 %v136005_v30, 19 (stack46)
        %v46600_v11 = vmul.f32 %v46596_v7, %v135996_v6 (stack54)
        %v48163_v43 = vadd.s32 %v48159_v44, %v48147_v61 (stack40)
        %v46473_v41 = vand.u32 2147483647, %v135866_v25 (stack77)
        %v46513_v50 = vsel /*vm=*/%vm46500_vm11, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %120831 = vrsqrt.f32 %v136044_v60 (stack67)
        %v47373_v53 = vand.u32 65535, %v47372_v55 (stack50)
        %v46604_v32 = vadd.f32 %v46600_v11, %v46513_v50 (stack53)
        %v48165_v52 = vshll.u32 %v48159_v44, 13 (stack45)
        %v48166_v22 = vshrl.u32 %v48159_v44, 19 (stack46)
        %v48584_v42 = vor.u32 %v48583_v46, %v48582_v29 (stack47)
        %v46481_v10 = vmul.f32 inf, %v135866_v25 (stack54)
        %v47762_v34 = vadd.s32 %v47759_v21, %v47754_v34 (stack40)
        %v49035_v54 = vor.u32 %v49034_v30, %v49033_v56 (stack47)
        %v46505_v27 = vsel /*vm=*/%vm46500_vm11, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v46509_v20 = vsel /*vm=*/%vm46500_vm11, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v46608_v55 = vmul.f32 %v46604_v32, %v135996_v6 (stack54)
        %v46934_v26 = vand.u32 2147483647, %v135974_v9 (stack77)
        %vm136063_vm1 = vcmp.eq.f32.partialorder %v46473_v41, 1.0 (stack68)
        %v136068_v29 = vmul.f32 inf, %v135974_v9 (stack54)
        %v47374_v7 = vshrl.u32 %v47373_v53, 1 (stack51)
        %v47764_v24 = vshll.u32 %v47759_v21, 16 (stack45)
        %v136072_v44 = vadd.s32 %v135967_v8, %v122657_v58 (stack40)
        %v46612_v46 = vadd.f32 %v46608_v55, %v46509_v20 (stack53)
        %v47765_v21 = vshrl.u32 %v47759_v21, 16 (stack46)
        %v48167_v56 = vor.u32 %v48166_v22, %v48165_v52 (stack47)
        %v48585_v30 = vxor.u32 %v48584_v42, %v48580_v31 (stack48)
        %v136075_v11 = vadd.f32 -2.5, %v136044_v60 (stack53)
        %v47375_v41 = vor.u32 16256, %v47374_v7 (stack47)
        %v49036_v50 = vxor.u32 %v49035_v54, %v49031_v23 (stack48)
        %vm49458_vm2 = vcmp.lt.u32.totalorder %v135967_v8, %v157070_v38 (stack43)
        %v46616_v6 = vmul.f32 %v46612_v46, %v135996_v6 (stack54)
        %vm46961_vm3 = vcmp.lt.f32.partialorder %v136044_v60, 5.0 (stack68)
        %vm47006_vm4 = vcmp.eq.f32.partialorder %v136044_v60, inf (stack70)
        %v47766_v53 = vor.u32 %v47765_v21, %v47764_v24 (stack47)
        %v48168_v32 = vxor.u32 %v48167_v56, %v48163_v43 (stack48)
        %v48588_v31 = vadd.s32 %v48585_v30, %v48580_v31 (stack40)
        %vm47008_vm5 = vcmp.eq.f32.partialorder %v136044_v60, 0.0 (stack71)
        %v47376_v52 = vand.u32.u16 65535, %v47375_v41 (stack52)
        %v48590_v22 = vshll.u32 %v48585_v30, 29 (stack45)
        %v48591_v42 = vshrl.u32 %v48585_v30, 3 (stack46)
        %v136083_v23 = vadd.s32 %v49036_v50, %v49031_v23 (stack40)
        %v46620_v54 = vadd.f32 %v46616_v6, %v46505_v27 (stack53)
        %v47767_v27 = vxor.u32 %v47766_v53, %v47762_v34 (stack48)
        %v48171_v43 = vadd.s32 %v48168_v32, %v48163_v43 (stack40)
        %v48173_v20 = vshll.u32 %v48168_v32, 15 (stack45)
        %v47009_v55 = vand.u32 2147483648, %v136044_v60 (stack72)
        %v119996_v7 = vadd.low.f32.bf16 -1.0, %v47376_v52 (stack53)
        %v48174_v24 = vshrl.u32 %v48168_v32, 17 (stack46)
        %v48592_v46 = vor.u32 %v48591_v42, %v48590_v22 (stack47)
        %v46624_v25 = vmul.f32 %v46620_v54, %v135866_v25 (stack54)
        %v47770_v34 = vadd.s32 %v47767_v27, %v47762_v34 (stack40)
        %v47776_v21 = vshll.u32 %v47767_v27, 24 (stack45)
        %v47777_v56 = vshrl.u32 %v47767_v27, 8 (stack46)
        %v47385_v30 = vmul.f32 2.0, %v119996_v7 (stack54)
        %v48175_v41 = vor.u32 %v48174_v24, %v48173_v20 (stack47)
        %v48593_v6 = vxor.u32 %v48592_v46, %v48588_v31 (stack48)
        %v49041_v53 = vshll.u32 %v49036_v50, 15 (stack45)
        %v120832_v32 = vpop.eup %120831 (stack73)
        %v46628_v10 = vsel /*vm=*/%vm136063_vm1, /*on_true_vy=*/%v46481_v10, /*on_false_vx=*/%v46624_v25 (stack44)
        %v47778_v61 = vor.u32 %v47777_v56, %v47776_v21 (stack47)
        %v49042_v50 = vshrl.u32 %v49036_v50, 17 (stack46)
        %v136091_v52 = vadd.s32 %v157366_v12, %v157076_v35 (stack40)
        %v46632_v22 = vmul.f32 1.4140625, %v46628_v10 (stack54)
        %v47005_v42 = vmul.f32 %v120832_v32, %v136044_v60 (stack74)
        %v47389_v54 = vadd.f32 -0.99609375, %v47385_v30 (stack53)
        %v48176_v27 = vxor.u32 %v48175_v41, %v48171_v43 (stack48)
        %v47779_v20 = vxor.u32 %v47778_v61, %v47770_v34 (stack48)
        %v48596_v31 = vadd.s32 %v48593_v6, %v48588_v31 (stack40)
        %v48598_v7 = vshll.u32 %v48593_v6, 16 (stack45)
        %v48599_v24 = vshrl.u32 %v48593_v6, 16 (stack46)
        %v46635_v46 = vpack.c.bf16 %v156663_v45, %v46632_v22 (stack81)
        %v47007_v25 = vsel /*vm=*/%vm47006_vm4, /*on_true_vy=*/%v136044_v60, /*on_false_vx=*/%v47005_v42 (stack75)
        %v136098_v21 = vmax.f32 %v47389_v54, -0.99609375 (stack55)
        %v48179_v43 = vadd.s32 %v48176_v27, %v48171_v43 (stack40)
        %v47010_v55 = vsel /*vm=*/%vm47008_vm5, /*on_true_vy=*/%v47009_v55, /*on_false_vx=*/%v47007_v25 (stack76)
        %v47782_v56 = vadd.s32 %v47779_v20, %v121564_v0 (stack40)
        %v48181_v30 = vshll.u32 %v48176_v27, 26 (stack45)
        %v48182_v41 = vshrl.u32 %v48176_v27, 6 (stack46)
        %119993 = vst [vmem:[%s123356_s30 + $0x130] sm:$0xf] /*vst_source=*/%v46635_v46 (stack83)
        %v136107_v6 = vsel /*vm=*/%vm46961_vm3, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v47013_v32 = vadd.f32 -3.0, %v47010_v55 (stack53)
        %v47405_v10 = vxor.u32 2147483648, %v136098_v21 (stack56)
        %v47774_v34 = vadd.s32 %v47770_v34, %v121569_v1 (stack40)
        %v47786_v61 = vadd.s32 4, %v47782_v56 (stack40)
        %v48183_v22 = vor.u32 %v48182_v41, %v48181_v30 (stack47)
        %v48600_v42 = vor.u32 %v48599_v24, %v48598_v7 (stack47)
        %v49043_v53 = vor.u32 %v49042_v50, %v49041_v53 (stack47)
        %v46982_v50 = vsel /*vm=*/%vm46961_vm3, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v46998_v54 = vsel /*vm=*/%vm46961_vm3, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v136120_v11 = vsel /*vm=*/%vm46961_vm3, /*on_true_vy=*/%v136075_v11, /*on_false_vx=*/%v47013_v32 (stack44)
        %v136123_v27 = vmul.f32 %v47405_v10, %v136098_v21 (stack54)
        %v47021_v20 = vmul.f32 %v136120_v11, %v46998_v54 (stack54)
        %v47790_v7 = vadd.s32 %v47786_v61, %v47774_v34 (stack40)
        %v47792_v24 = vshll.u32 %v47786_v61, 13 (stack45)
        %v47793_v46 = vshrl.u32 %v47786_v61, 19 (stack46)
        %v46986_v25 = vsel /*vm=*/%vm46961_vm3, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v46994_v55 = vsel /*vm=*/%vm46961_vm3, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v47410_v56 = vadd.f32 1.0, %v136123_v27 (stack57)
        %v48184_v30 = vxor.u32 %v48183_v22, %v48179_v43 (stack48)
        %v47025_v41 = vadd.f32 %v47021_v20, %v46994_v55 (stack53)
        %v47794_v32 = vor.u32 %v47793_v46, %v47792_v24 (stack47)
        %v48601_v10 = vxor.u32 %v48600_v42, %v48596_v31 (stack48)
        %v49044_v34 = vxor.u32 %v49043_v53, %v136083_v23 (stack48)
        %v46990_v61 = vsel /*vm=*/%vm46961_vm3, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %120833 = vlog2.f32 %v47410_v56 (stack58)
        %v48187_v43 = vadd.s32 %v48184_v30, %v48179_v43 (stack40)
        %vm49453_vm6 = vcmp.lt.u32.totalorder %v136072_v44, %v135967_v8 (stack43)
        %v47029_v22 = vmul.f32 %v47025_v41, %v136120_v11 (stack54)
        %v47795_v42 = vxor.u32 %v47794_v32, %v47790_v7 (stack48)
        %v48193_v53 = vshll.u32 %v48184_v30, 6 (stack45)
        %v48194_v54 = vshrl.u32 %v48184_v30, 26 (stack46)
        %v47413_v20 = vmul.f32 -0.5, %v136123_v27 (stack59)
        %v48604_v31 = vadd.s32 %v48601_v10, %v48596_v31 (stack40)
        %v48610_v24 = vshll.u32 %v48601_v10, 24 (stack45)
        %v49467_v46 = vadd.s32 1, %v136091_v52 (stack40)
        %v47033_v55 = vadd.f32 %v47029_v22, %v46990_v61 (stack53)
        %v47798_v7 = vadd.s32 %v47795_v42, %v47790_v7 (stack40)
        %v47800_v56 = vshll.u32 %v47795_v42, 15 (stack45)
        %v47801_v30 = vshrl.u32 %v47795_v42, 17 (stack46)
        %v47416_v41 = vand.u32 2147483647, %v136123_v27 (stack60)
        %v48195_v32 = vor.u32 %v48194_v54, %v48193_v53 (stack47)
        %v48611_v10 = vshrl.u32 %v48601_v10, 8 (stack46)
        %v49047_v23 = vadd.s32 %v49044_v34, %v136083_v23 (stack40)
        %v47037_v61 = vmul.f32 %v47033_v55, %v136120_v11 (stack54)
        %v47802_v22 = vor.u32 %v47801_v30, %v47800_v56 (stack47)
        %v49049_v42 = vshll.u32 %v49044_v34, 26 (stack45)
        %v49050_v34 = vshrl.u32 %v49044_v34, 6 (stack46)
        %v47414_v53 = vadd.f32 1.0, %v47413_v20 (stack61)
        %v48196_v54 = vxor.u32 %v48195_v32, %v48187_v43 (stack48)
        %v48612_v20 = vor.u32 %v48611_v10, %v48610_v24 (stack47)
        %v49471_v52 = vsel /*vm=*/%vm49458_vm2, /*on_true_vy=*/%v49467_v46, /*on_false_vx=*/%v136091_v52 (stack44)
        %v47041_v25 = vadd.f32 %v47037_v61, %v46986_v25 (stack53)
        %v47803_v24 = vxor.u32 %v47802_v22, %v47798_v7 (stack48)
        %v49051_v46 = vor.u32 %v49050_v34, %v49049_v42 (stack47)
        %v49475_v55 = vadd.s32 1, %v49471_v52 (stack40)
        %v48191_v43 = vadd.s32 %v48187_v43, %v121574_v2 (stack40)
        %v48199_v56 = vadd.s32 %v48196_v54, %v121569_v1 (stack40)
        %v48613_v30 = vxor.u32 %v48612_v20, %v48604_v31 (stack48)
        %v136153_v32 = vadd.s32 %v136072_v44, %v121569_v1 (stack40)
        %v47045_v10 = vmul.f32 %v47041_v25, %v136120_v11 (stack54)
        %v47806_v7 = vadd.s32 %v47803_v24, %v47798_v7 (stack40)
        %v47808_v61 = vshll.u32 %v47803_v24, 26 (stack45)
        %v47809_v22 = vshrl.u32 %v47803_v24, 6 (stack46)
        %v48203_v42 = vadd.s32 3, %v48199_v56 (stack40)
        %v48616_v34 = vadd.s32 %v48613_v30, %v121574_v2 (stack40)
        %v136157_v54 = vxor.u32 %v49051_v46, %v49047_v23 (stack48)
        %v49479_v8 = vsel /*vm=*/%vm49453_vm6, /*on_true_vy=*/%v49475_v55, /*on_false_vx=*/%v49471_v52 (stack44)
        %v47049_v44 = vadd.f32 %v47045_v10, %v46982_v50 (stack53)
        %vm136162_vm7 = vcmp.lt.f32.partialorder %v47416_v41, 0.0004427343 (stack62)
        %v47810_v41 = vor.u32 %v47809_v22, %v47808_v61 (stack47)
        %v48608_v31 = vadd.s32 %v48604_v31, %v121564_v0 (stack40)
        %v48207_v20 = vadd.s32 %v48203_v42, %v48191_v43 (stack40)
        %v48209_v52 = vshll.u32 %v48203_v42, 17 (stack45)
        %v48210_v25 = vshrl.u32 %v48203_v42, 15 (stack46)
        %v48620_v24 = vadd.s32 2, %v48616_v34 (stack40)
        %v120834_v46 = vpop.eup %120833 (stack64)
        %v47053_v55 = vmul.f32 %v47049_v44, %v136120_v11 (stack54)
        %v47415_v27 = vmul.f32 %v47414_v53, %v136123_v27 (stack63)
        %v47811_v53 = vxor.u32 %v47810_v41, %v47806_v7 (stack48)
        %v136170_v23 = vadd.s32 %v136157_v54, %v49047_v23 (stack40)
        %v47412_v43 = vmul.f32 0.6931472, %v120834_v46 (stack65)
        %v48211_v56 = vor.u32 %v48210_v25, %v48209_v52 (stack47)
        %v48624_v30 = vadd.s32 %v48620_v24, %v48608_v31 (stack40)
        %v49494_v10 = vshll.u32 %v136153_v32, 13 (stack45)
        %v47057_v6 = vadd.f32 %v47053_v55, %v136107_v6 (stack53)
        %v47814_v7 = vadd.s32 %v47811_v53, %v47806_v7 (stack40)
        %v47820_v61 = vshll.u32 %v47811_v53, 6 (stack45)
        %v47821_v22 = vshrl.u32 %v47811_v53, 26 (stack46)
        %v47418_v42 = vsel /*vm=*/%vm136162_vm7, /*on_true_vy=*/%v47415_v27, /*on_false_vx=*/%v47412_v43 (stack66)
        %v48212_v34 = vxor.u32 %v48211_v56, %v48207_v20 (stack48)
        %v48626_v44 = vshll.u32 %v48620_v24, 13 (stack45)
        %v48627_v50 = vshrl.u32 %v48620_v24, 19 (stack46)
        %v47061_v41 = vmul.f32 %v47057_v6, %v136120_v11 (stack54)
        %v136177_v31 = vxor.u32 2147483648, %v47418_v42 (stack56)
        %v47822_v52 = vor.u32 %v47821_v22, %v47820_v61 (stack47)
        %v49495_v25 = vshrl.u32 %v136153_v32, 19 (stack46)
        %v46966_v24 = vsel /*vm=*/%vm46961_vm3, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v46970_v46 = vsel /*vm=*/%vm46961_vm3, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v46974_v60 = vsel /*vm=*/%vm46961_vm3, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v48215_v20 = vadd.s32 %v48212_v34, %v48207_v20 (stack40)
        %v47065_v55 = vadd.f32 %v47061_v41, %v46974_v60 (stack53)
        %v47395_v27 = vand.u32 2147483647, %v136098_v21 (stack77)
        %120835 = vrsqrt.f32 %v136177_v31 (stack67)
        %v48217_v53 = vshll.u32 %v48212_v34, 29 (stack45)
        %vm47422_vm8 = vcmp.lt.f32.partialorder %v136177_v31, 5.0 (stack68)
        %v47823_v43 = vxor.u32 %v47822_v52, %v47814_v7 (stack48)
        %v48218_v56 = vshrl.u32 %v48212_v34, 3 (stack46)
        %v48628_v6 = vor.u32 %v48627_v50, %v48626_v44 (stack47)
        %v47069_v61 = vmul.f32 %v47065_v55, %v136120_v11 (stack54)
        %v49061_v22 = vshll.u32 %v136157_v54, 6 (stack45)
        %v49484_v8 = vadd.s32 %v49479_v8, %v121574_v2 (stack40)
        %v49496_v10 = vor.u32 %v49495_v25, %v49494_v10 (stack47)
        %vm136197_vm9 = vcmp.eq.f32.partialorder %v46934_v26, 1.0 (stack68)
        %v136202_v42 = vadd.f32 -2.5, %v136177_v31 (stack53)
        %v47818_v7 = vadd.s32 %v47814_v7, %v121564_v0 (stack40)
        %v47826_v34 = vadd.s32 %v47823_v43, %v121574_v2 (stack40)
        %v136208_v44 = vadd.s32 %v136170_v23, %v121569_v1 (stack40)
        %v47073_v50 = vadd.f32 %v47069_v61, %v46970_v46 (stack53)
        %v136213_v41 = vsel /*vm=*/%vm47422_vm8, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v136218_v52 = vsel /*vm=*/%vm47422_vm8, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v136223_v25 = vsel /*vm=*/%vm47422_vm8, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v47830_v46 = vadd.s32 5, %v47826_v34 (stack40)
        %v48219_v60 = vor.u32 %v48218_v56, %v48217_v53 (stack47)
        %v48629_v55 = vxor.u32 %v48628_v6, %v48624_v30 (stack48)
        %v49062_v54 = vshrl.u32 %v136157_v54, 26 (stack46)
        %v47077_v11 = vmul.f32 %v47073_v50, %v136120_v11 (stack54)
        %v49492_v32 = vadd.s32 %v136153_v32, %v49484_v8 (stack40)
        %v136230_v53 = vadd.s32 %v157365_v40, %v157077_v51 (stack40)
        %v136234_v43 = vadd.s32 %v157366_v12, %v157078_v48 (stack40)
        %vm47467_vm10 = vcmp.eq.f32.partialorder %v136177_v31, inf (stack70)
        %v47832_v56 = vxor.u32 %v47830_v46, %v47818_v7 (stack48)
        %v48220_v6 = vxor.u32 %v48219_v60, %v48215_v20 (stack48)
        %v48632_v30 = vadd.s32 %v48629_v55, %v48624_v30 (stack40)
        %v48634_v61 = vshll.u32 %v48629_v55, 15 (stack45)
        %v47081_v24 = vadd.f32 %v47077_v11, %v46966_v24 (stack53)
        %vm47469_vm11 = vcmp.eq.f32.partialorder %v136177_v31, 0.0 (stack71)
        %v48635_v8 = vshrl.u32 %v48629_v55, 17 (stack46)
        %v49063_v22 = vor.u32 %v49062_v54, %v49061_v22 (stack47)
        %v49497_v10 = vxor.u32 %v49496_v10, %v49492_v32 (stack48)
        %v47833_v7 = vand.u32.u8 255, %v47832_v56 (stack49)
        %v48223_v20 = vadd.s32 %v48220_v6, %v48215_v20 (stack40)
        %v48225_v34 = vshll.u32 %v48220_v6, 16 (stack45)
        %v48226_v50 = vshrl.u32 %v48220_v6, 16 (stack46)
        %v47085_v9 = vmul.f32 %v47081_v24, %v135974_v9 (stack54)
        %v48636_v46 = vor.u32 %v48635_v8, %v48634_v61 (stack47)
        %v49064_v23 = vxor.u32 %v49063_v22, %v136170_v23 (stack48)
        %v49500_v60 = vadd.s32 %v49497_v10, %v49492_v32 (stack40)
        %v47834_v55 = vand.u32 65535, %v47833_v7 (stack50)
        %v48227_v54 = vor.u32 %v48226_v50, %v48225_v34 (stack47)
        %v49502_v11 = vshll.u32 %v49497_v10, 15 (stack45)
        %v49503_v32 = vshrl.u32 %v49497_v10, 17 (stack46)
        %v47089_v29 = vsel /*vm=*/%vm136197_vm9, /*on_true_vy=*/%v136068_v29, /*on_false_vx=*/%v47085_v9 (stack44)
        %v47470_v26 = vand.u32 2147483648, %v136177_v31 (stack72)
        %v48637_v56 = vxor.u32 %v48636_v46, %v48632_v30 (stack48)
        %v49067_v6 = vadd.s32 %v49064_v23, %v121564_v0 (stack40)
        %v120836_v61 = vpop.eup %120835 (stack73)
        %v47093_v24 = vmul.f32 1.4140625, %v47089_v29 (stack54)
        %v47835_v8 = vshrl.u32 %v47834_v55, 1 (stack51)
        %v48228_v22 = vxor.u32 %v48227_v54, %v48223_v20 (stack48)
        %v49504_v10 = vor.u32 %v49503_v32, %v49502_v11 (stack47)
        %v47466_v7 = vmul.f32 %v120836_v61, %v136177_v31 (stack74)
        %v48640_v30 = vadd.s32 %v48637_v56, %v48632_v30 (stack40)
        %v48642_v34 = vshll.u32 %v48637_v56, 26 (stack45)
        %v48643_v50 = vshrl.u32 %v48637_v56, 6 (stack46)
        %v47096_v9 = vpack.c.bf16 %v156663_v45, %v47093_v24 (stack81)
        %v47836_v46 = vor.u32 16256, %v47835_v8 (stack47)
        %v48231_v20 = vadd.s32 %v48228_v22, %v48223_v20 (stack40)
        %v48237_v23 = vshll.u32 %v48228_v22, 24 (stack45)
        %v47468_v55 = vsel /*vm=*/%vm47467_vm10, /*on_true_vy=*/%v136177_v31, /*on_false_vx=*/%v47466_v7 (stack75)
        %v48238_v54 = vshrl.u32 %v48228_v22, 8 (stack46)
        %v48644_v11 = vor.u32 %v48643_v50, %v48642_v34 (stack47)
        %v49071_v32 = vadd.s32 1, %v49067_v6 (stack40)
        %119995 = vst [vmem:[%s123356_s30 + $0x1b0] sm:$0xf] /*vst_source=*/%v47096_v9 (stack83)
        %v47459_v29 = vsel /*vm=*/%vm47422_vm8, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v47471_v26 = vsel /*vm=*/%vm47469_vm11, /*on_true_vy=*/%v47470_v26, /*on_false_vx=*/%v47468_v55 (stack76)
        %v47837_v56 = vand.u32.u16 65535, %v47836_v46 (stack52)
        %v49505_v6 = vxor.u32 %v49504_v10, %v49500_v60 (stack48)
        %v47474_v61 = vadd.f32 -3.0, %v47471_v26 (stack53)
        %v48239_v24 = vor.u32 %v48238_v54, %v48237_v23 (stack47)
        %v48645_v8 = vxor.u32 %v48644_v11, %v48640_v30 (stack48)
        %v49075_v44 = vadd.s32 %v49071_v32, %v136208_v44 (stack40)
        %v119998_v22 = vadd.low.f32.bf16 -1.0, %v47837_v56 (stack53)
        %v49077_v10 = vshll.u32 %v49071_v32, 17 (stack45)
        %v49078_v7 = vshrl.u32 %v49071_v32, 15 (stack46)
        %v49508_v60 = vadd.s32 %v49505_v6, %v49500_v60 (stack40)
        %v136260_v42 = vsel /*vm=*/%vm47422_vm8, /*on_true_vy=*/%v136202_v42, /*on_false_vx=*/%v47474_v61 (stack44)
        %v48240_v34 = vxor.u32 %v48239_v24, %v48231_v20 (stack48)
        %v48648_v30 = vadd.s32 %v48645_v8, %v48640_v30 (stack40)
        %v48654_v50 = vshll.u32 %v48645_v8, 6 (stack45)
        %v47482_v9 = vmul.f32 %v136260_v42, %v47459_v29 (stack54)
        %v47846_v46 = vmul.f32 2.0, %v119998_v22 (stack54)
        %v48655_v23 = vshrl.u32 %v48645_v8, 26 (stack46)
        %v49079_v55 = vor.u32 %v49078_v7, %v49077_v10 (stack47)
        %v47455_v54 = vsel /*vm=*/%vm47422_vm8, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v48243_v11 = vadd.s32 %v48240_v34, %v121564_v0 (stack40)
        %v49510_v32 = vshll.u32 %v49505_v6, 26 (stack45)
        %v49511_v29 = vshrl.u32 %v49505_v6, 6 (stack46)
        %v47486_v26 = vadd.f32 %v47482_v9, %v47455_v54 (stack53)
        %v47850_v56 = vadd.f32 -0.99609375, %v47846_v46 (stack53)
        %v48656_v6 = vor.u32 %v48655_v23, %v48654_v50 (stack47)
        %v49080_v61 = vxor.u32 %v49079_v55, %v49075_v44 (stack48)
        %v48235_v20 = vadd.s32 %v48231_v20, %v121569_v1 (stack40)
        %v48247_v24 = vadd.s32 4, %v48243_v11 (stack40)
        %v49512_v8 = vor.u32 %v49511_v29, %v49510_v32 (stack47)
        %vm49919_vm12 = vcmp.lt.u32.totalorder %v136230_v53, %v157077_v51 (stack43)
        %v47490_v22 = vmul.f32 %v47486_v26, %v136260_v42 (stack54)
        %v136271_v10 = vmax.f32 %v47850_v56, -0.99609375 (stack55)
        %v48657_v7 = vxor.u32 %v48656_v6, %v48648_v30 (stack48)
        %v49083_v44 = vadd.s32 %v49080_v61, %v49075_v44 (stack40)
        %v48251_v34 = vadd.s32 %v48247_v24, %v48235_v20 (stack40)
        %v48253_v50 = vshll.u32 %v48247_v24, 13 (stack45)
        %v48254_v9 = vshrl.u32 %v48247_v24, 19 (stack46)
        %v49085_v46 = vshll.u32 %v49080_v61, 29 (stack45)
        %v47439_v23 = vsel /*vm=*/%vm47422_vm8, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v47447_v55 = vsel /*vm=*/%vm47422_vm8, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v47494_v25 = vadd.f32 %v47490_v22, %v136223_v25 (stack53)
        %v47866_v54 = vxor.u32 2147483648, %v136271_v10 (stack56)
        %v48255_v11 = vor.u32 %v48254_v9, %v48253_v50 (stack47)
        %v48660_v32 = vadd.s32 %v48657_v7, %v121569_v1 (stack40)
        %v49086_v29 = vshrl.u32 %v49080_v61, 3 (stack46)
        %v49513_v26 = vxor.u32 %v49512_v8, %v49508_v60 (stack48)
        %v47498_v56 = vmul.f32 %v47494_v25, %v136260_v42 (stack54)
        %v136284_v6 = vmul.f32 %v47866_v54, %v136271_v10 (stack54)
        %v48652_v30 = vadd.s32 %v48648_v30, %v121574_v2 (stack40)
        %v136289_v61 = vadd.s32 %v136230_v53, %v122657_v58 (stack40)
        %v48256_v20 = vxor.u32 %v48255_v11, %v48251_v34 (stack48)
        %v48664_v24 = vadd.s32 3, %v48660_v32 (stack40)
        %v49087_v8 = vor.u32 %v49086_v29, %v49085_v46 (stack47)
        %v136291_v60 = vadd.s32 %v49513_v26, %v49508_v60 (stack40)
        %v47443_v22 = vsel /*vm=*/%vm47422_vm8, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v47502_v7 = vadd.f32 %v47498_v56, %v47447_v55 (stack53)
        %v47871_v50 = vadd.f32 1.0, %v136284_v6 (stack57)
        %v47874_v9 = vmul.f32 -0.5, %v136284_v6 (stack59)
        %v48259_v34 = vadd.s32 %v48256_v20, %v48251_v34 (stack40)
        %v48261_v46 = vshll.u32 %v48256_v20, 15 (stack45)
        %v48262_v55 = vshrl.u32 %v48256_v20, 17 (stack46)
        %v48668_v25 = vadd.s32 %v48664_v24, %v48652_v30 (stack40)
        %v47506_v54 = vmul.f32 %v47502_v7, %v136260_v42 (stack54)
        %120837 = vlog2.f32 %v47871_v50 (stack58)
        %vm49914_vm13 = vcmp.lt.u32.totalorder %v136289_v61, %v136230_v53 (stack43)
        %v49928_v11 = vadd.s32 1, %v136234_v43 (stack40)
        %v48263_v32 = vor.u32 %v48262_v55, %v48261_v46 (stack47)
        %v48670_v29 = vshll.u32 %v48664_v24, 17 (stack45)
        %v48671_v56 = vshrl.u32 %v48664_v24, 15 (stack46)
        %v49088_v30 = vxor.u32 %v49087_v8, %v49083_v44 (stack48)
        %v47510_v20 = vadd.f32 %v47506_v54, %v47443_v22 (stack53)
        %v47875_v24 = vadd.f32 1.0, %v47874_v9 (stack61)
        %v47877_v8 = vand.u32 2147483647, %v136284_v6 (stack60)
        %v49522_v22 = vshll.u32 %v49513_v26, 6 (stack45)
        %v48264_v7 = vxor.u32 %v48263_v32, %v48259_v34 (stack48)
        %v48672_v50 = vor.u32 %v48671_v56, %v48670_v29 (stack47)
        %v49091_v44 = vadd.s32 %v49088_v30, %v49083_v44 (stack40)
        %v49093_v9 = vshll.u32 %v49088_v30, 16 (stack45)
        %v47514_v46 = vmul.f32 %v47510_v20, %v136260_v42 (stack54)
        %v49094_v55 = vshrl.u32 %v49088_v30, 16 (stack46)
        %v49523_v26 = vshrl.u32 %v49513_v26, 26 (stack46)
        %v49932_v43 = vsel /*vm=*/%vm49919_vm12, /*on_true_vy=*/%v49928_v11, /*on_false_vx=*/%v136234_v43 (stack44)
        %v48267_v34 = vadd.s32 %v48264_v7, %v48259_v34 (stack40)
        %v48269_v54 = vshll.u32 %v48264_v7, 26 (stack45)
        %v48270_v11 = vshrl.u32 %v48264_v7, 6 (stack46)
        %v48673_v32 = vxor.u32 %v48672_v50, %v48668_v25 (stack48)
        %v47518_v23 = vadd.f32 %v47514_v46, %v47439_v23 (stack53)
        %v49095_v29 = vor.u32 %v49094_v55, %v49093_v9 (stack47)
        %v49524_v56 = vor.u32 %v49523_v26, %v49522_v22 (stack47)
        %v49936_v30 = vadd.s32 1, %v49932_v43 (stack40)
        %v48271_v20 = vor.u32 %v48270_v11, %v48269_v54 (stack47)
        %v48676_v25 = vadd.s32 %v48673_v32, %v48668_v25 (stack40)
        %v48678_v22 = vshll.u32 %v48673_v32, 29 (stack45)
        %v48679_v7 = vshrl.u32 %v48673_v32, 3 (stack46)
        %v47522_v50 = vmul.f32 %v47518_v23, %v136260_v42 (stack54)
        %v49096_v9 = vxor.u32 %v49095_v29, %v49091_v44 (stack48)
        %v49525_v46 = vxor.u32 %v49524_v56, %v136291_v60 (stack48)
        %v49940_v53 = vsel /*vm=*/%vm49914_vm13, /*on_true_vy=*/%v49936_v30, /*on_false_vx=*/%v49932_v43 (stack44)
        %vm136313_vm14 = vcmp.lt.f32.partialorder %v47877_v8, 0.0004427343 (stack62)
        %v48272_v55 = vxor.u32 %v48271_v20, %v48267_v34 (stack48)
        %v48680_v26 = vor.u32 %v48679_v7, %v48678_v22 (stack47)
        %v49945_v43 = vadd.s32 %v49940_v53, %v121574_v2 (stack40)
        %v47526_v52 = vadd.f32 %v47522_v50, %v136218_v52 (stack53)
        %v49099_v44 = vadd.s32 %v49096_v9, %v49091_v44 (stack40)
        %v49105_v54 = vshll.u32 %v49096_v9, 24 (stack45)
        %v49106_v11 = vshrl.u32 %v49096_v9, 8 (stack46)
        %v48275_v34 = vadd.s32 %v48272_v55, %v48267_v34 (stack40)
        %v48281_v32 = vshll.u32 %v48272_v55, 6 (stack45)
        %v48282_v23 = vshrl.u32 %v48272_v55, 26 (stack46)
        %v48681_v29 = vxor.u32 %v48680_v26, %v48676_v25 (stack48)
        %v47530_v56 = vmul.f32 %v47526_v52, %v136260_v42 (stack54)
        %v47876_v6 = vmul.f32 %v47875_v24, %v136284_v6 (stack63)
        %v49107_v24 = vor.u32 %v49106_v11, %v49105_v54 (stack47)
        %v49528_v30 = vadd.s32 %v49525_v46, %v121564_v0 (stack40)
        %v120838_v20 = vpop.eup %120837 (stack64)
        %v48283_v22 = vor.u32 %v48282_v23, %v48281_v32 (stack47)
        %v48684_v25 = vadd.s32 %v48681_v29, %v48676_v25 (stack40)
        %v48686_v7 = vshll.u32 %v48681_v29, 16 (stack45)
        %v49949_v61 = vadd.s32 %v136289_v61, %v121569_v1 (stack40)
        %v47534_v41 = vadd.f32 %v47530_v56, %v136213_v41 (stack53)
        %v47873_v50 = vmul.f32 0.6931472, %v120838_v20 (stack65)
        %v48687_v9 = vshrl.u32 %v48681_v29, 16 (stack46)
        %v49108_v46 = vxor.u32 %v49107_v24, %v49099_v44 (stack48)
        %v48284_v53 = vxor.u32 %v48283_v22, %v48275_v34 (stack48)
        %v49520_v60 = vadd.s32 %v136291_v60, %v121569_v1 (stack40)
        %v49532_v55 = vadd.s32 1, %v49528_v30 (stack40)
        %v136327_v26 = vadd.s32 %v49949_v61, %v49945_v43 (stack40)
        %v47538_v42 = vmul.f32 %v47534_v41, %v136260_v42 (stack54)
        %v47879_v8 = vsel /*vm=*/%vm136313_vm14, /*on_true_vy=*/%v47876_v6, /*on_false_vx=*/%v47873_v50 (stack66)
        %v48688_v43 = vor.u32 %v48687_v9, %v48686_v7 (stack47)
        %v49111_v52 = vadd.s32 %v49108_v46, %v121574_v2 (stack40)
        %v47427_v31 = vsel /*vm=*/%vm47422_vm8, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v136336_v54 = vxor.u32 2147483648, %v47879_v8 (stack56)
        %v49536_v11 = vadd.s32 %v49532_v55, %v49520_v60 (stack40)
        %v47542_v32 = vadd.f32 %v47538_v42, %v47427_v31 (stack53)
        %v48689_v23 = vxor.u32 %v48688_v43, %v48684_v25 (stack48)
        %v47403_v29 = vmul.f32 inf, %v136098_v21 (stack54)
        %vm47883_vm15 = vcmp.lt.f32.partialorder %v136336_v54, 5.0 (stack68)
        %120839 = vrsqrt.f32 %v136336_v54 (stack67)
        %v48287_v56 = vadd.s32 %v48284_v53, %v121574_v2 (stack40)
        %vm47398_vm0 = vcmp.eq.f32.partialorder %v47395_v27, 1.0 (stack68)
        %v47546_v21 = vmul.f32 %v47542_v32, %v136098_v21 (stack54)
        %v49103_v27 = vadd.s32 %v49099_v44, %v121564_v0 (stack40)
        %v49115_v44 = vadd.s32 2, %v49111_v52 (stack40)
        %v48279_v34 = vadd.s32 %v48275_v34, %v121564_v0 (stack40)
        %v48692_v6 = vadd.s32 %v48689_v23, %v48684_v25 (stack40)
        %v49538_v24 = vshll.u32 %v49532_v55, 17 (stack45)
        %v49955_v30 = vshll.u32 %v49949_v61, 13 (stack45)
        %v47550_v20 = vsel /*vm=*/%vm47398_vm0, /*on_true_vy=*/%v47403_v29, /*on_false_vx=*/%v47546_v21 (stack44)
        %v136350_v22 = vsel /*vm=*/%vm47883_vm15, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v136353_v25 = vadd.f32 -2.5, %v136336_v54 (stack53)
        %v49539_v7 = vshrl.u32 %v49532_v55, 15 (stack46)
        %v47554_v41 = vmul.f32 1.4140625, %v47550_v20 (stack54)
        %v136358_v50 = vsel /*vm=*/%vm47883_vm15, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v47931_v9 = vand.u32 2147483648, %v136336_v54 (stack72)
        %v48291_v46 = vadd.s32 5, %v48287_v56 (stack40)
        %v48696_v53 = vadd.s32 %v48692_v6, %v121569_v1 (stack40)
        %v48698_v60 = vshll.u32 %v48689_v23, 24 (stack45)
        %v48699_v55 = vshrl.u32 %v48689_v23, 8 (stack46)
        %v49119_v42 = vadd.s32 %v49115_v44, %v49103_v27 (stack40)
        %v47557_v8 = vpack.c.bf16 %v156663_v45, %v47554_v41 (stack81)
        %v48293_v43 = vxor.u32 %v48291_v46, %v48279_v34 (stack48)
        %v49121_v52 = vshll.u32 %v49115_v44, 13 (stack45)
        %v49122_v31 = vshrl.u32 %v49115_v44, 19 (stack46)
        %vm47928_vm1 = vcmp.eq.f32.partialorder %v136336_v54, inf (stack70)
        %v48700_v32 = vor.u32 %v48699_v55, %v48698_v60 (stack47)
        %v49540_v23 = vor.u32 %v49539_v7, %v49538_v24 (stack47)
        %v49956_v61 = vshrl.u32 %v49949_v61, 19 (stack46)
        %v136366_v29 = vadd.s32 %v157365_v40, %v157079_v39 (stack40)
        %119997 = vst [vmem:[%s123356_s30 + $0x230] sm:$0xf] /*vst_source=*/%v47557_v8 (stack83)
        %vm47930_vm2 = vcmp.eq.f32.partialorder %v136336_v54, 0.0 (stack71)
        %v48294_v56 = vand.u32.u8 255, %v48293_v43 (stack49)
        %v49123_v21 = vor.u32 %v49122_v31, %v49121_v52 (stack47)
        %v50385_v27 = vadd.s32 %v157366_v12, %v157082_v49 (stack40)
        %v136374_v44 = vadd.s32 %v157365_v40, %v157083_v59 (stack40)
        %v48701_v34 = vxor.u32 %v48700_v32, %v48692_v6 (stack48)
        %v49541_v6 = vxor.u32 %v49540_v23, %v49536_v11 (stack48)
        %v49957_v24 = vor.u32 %v49956_v61, %v49955_v30 (stack47)
        %v136378_v30 = vadd.s32 %v136366_v29, %v122657_v58 (stack40)
        %v48295_v20 = vand.u32 65535, %v48294_v56 (stack50)
        %v49124_v7 = vxor.u32 %v49123_v21, %v49119_v42 (stack48)
        %vm50380_vm3 = vcmp.lt.u32.totalorder %v136366_v29, %v157079_v39 (stack43)
        %v50389_v41 = vadd.s32 1, %v50385_v27 (stack40)
        %v48704_v46 = vadd.s32 %v48701_v34, %v121564_v0 (stack40)
        %v49544_v11 = vadd.s32 %v49541_v6, %v49536_v11 (stack40)
        %v49546_v60 = vshll.u32 %v49541_v6, 29 (stack45)
        %v49547_v55 = vshrl.u32 %v49541_v6, 3 (stack46)
        %v48296_v8 = vshrl.u32 %v48295_v20, 1 (stack51)
        %v49127_v42 = vadd.s32 %v49124_v7, %v49119_v42 (stack40)
        %v49129_v43 = vshll.u32 %v49124_v7, 15 (stack45)
        %v49130_v52 = vshrl.u32 %v49124_v7, 17 (stack46)
        %v120840_v31 = vpop.eup %120839 (stack73)
        %v48708_v32 = vadd.s32 4, %v48704_v46 (stack40)
        %v49548_v23 = vor.u32 %v49547_v55, %v49546_v60 (stack47)
        %v49958_v61 = vxor.u32 %v49957_v24, %v136327_v26 (stack48)
        %vm50375_vm4 = vcmp.lt.u32.totalorder %v136378_v30, %v136366_v29 (stack43)
        %v47927_v56 = vmul.f32 %v120840_v31, %v136336_v54 (stack74)
        %v48297_v21 = vor.u32 16256, %v48296_v8 (stack47)
        %v49131_v34 = vor.u32 %v49130_v52, %v49129_v43 (stack47)
        %v50393_v27 = vsel /*vm=*/%vm50380_vm3, /*on_true_vy=*/%v50389_v41, /*on_false_vx=*/%v50385_v27 (stack44)
        %v48712_v53 = vadd.s32 %v48708_v32, %v48696_v53 (stack40)
        %v48714_v6 = vshll.u32 %v48708_v32, 13 (stack45)
        %v48715_v24 = vshrl.u32 %v48708_v32, 19 (stack46)
        %v49549_v20 = vxor.u32 %v49548_v23, %v49544_v11 (stack48)
        %v47929_v7 = vsel /*vm=*/%vm47928_vm1, /*on_true_vy=*/%v136336_v54, /*on_false_vx=*/%v47927_v56 (stack75)
        %v48298_v41 = vand.u32.u16 65535, %v48297_v21 (stack52)
        %v49132_v46 = vxor.u32 %v49131_v34, %v49127_v42 (stack48)
        %v136394_v26 = vadd.s32 %v49958_v61, %v136327_v26 (stack40)
        %v47932_v9 = vsel /*vm=*/%vm47930_vm2, /*on_true_vy=*/%v47931_v9, /*on_false_vx=*/%v47929_v7 (stack76)
        %v48716_v60 = vor.u32 %v48715_v24, %v48714_v6 (stack47)
        %v49552_v11 = vadd.s32 %v49549_v20, %v49544_v11 (stack40)
        %v49554_v55 = vshll.u32 %v49549_v20, 16 (stack45)
        %v47935_v8 = vadd.f32 -3.0, %v47932_v9 (stack53)
        %v120000_v43 = vadd.low.f32.bf16 -1.0, %v48298_v41 (stack53)
        %v49135_v42 = vadd.s32 %v49132_v46, %v49127_v42 (stack40)
        %v49137_v52 = vshll.u32 %v49132_v46, 26 (stack45)
        %v48717_v31 = vxor.u32 %v48716_v60, %v48712_v53 (stack48)
        %v49138_v32 = vshrl.u32 %v49132_v46, 6 (stack46)
        %v49555_v23 = vshrl.u32 %v49549_v20, 16 (stack46)
        %v49963_v56 = vshll.u32 %v49958_v61, 15 (stack45)
        %v136401_v25 = vsel /*vm=*/%vm47883_vm15, /*on_true_vy=*/%v136353_v25, /*on_false_vx=*/%v47935_v8 (stack44)
        %v48307_v21 = vmul.f32 2.0, %v120000_v43 (stack54)
        %v49964_v61 = vshrl.u32 %v49958_v61, 17 (stack46)
        %v50397_v34 = vadd.s32 1, %v50393_v27 (stack40)
        %v47943_v50 = vmul.f32 %v136401_v25, %v136358_v50 (stack54)
        %v48720_v53 = vadd.s32 %v48717_v31, %v48712_v53 (stack40)
        %v48722_v6 = vshll.u32 %v48717_v31, 15 (stack45)
        %v48723_v24 = vshrl.u32 %v48717_v31, 17 (stack46)
        %v48311_v20 = vadd.f32 -0.99609375, %v48307_v21 (stack53)
        %v49139_v7 = vor.u32 %v49138_v32, %v49137_v52 (stack47)
        %v49556_v41 = vor.u32 %v49555_v23, %v49554_v55 (stack47)
        %v49965_v46 = vor.u32 %v49964_v61, %v49963_v56 (stack47)
        %v47947_v22 = vadd.f32 %v47943_v50, %v136350_v22 (stack53)
        %v48724_v9 = vor.u32 %v48723_v24, %v48722_v6 (stack47)
        %v50401_v29 = vsel /*vm=*/%vm50375_vm4, /*on_true_vy=*/%v50397_v34, /*on_false_vx=*/%v50393_v27 (stack44)
        %v136409_v27 = vmax.f32 %v48311_v20, -0.99609375 (stack55)
        %v49140_v60 = vxor.u32 %v49139_v7, %v49135_v42 (stack48)
        %v49557_v55 = vxor.u32 %v49556_v41, %v49552_v11 (stack48)
        %v49966_v8 = vxor.u32 %v49965_v46, %v136394_v26 (stack48)
        %v47856_v43 = vand.u32 2147483647, %v136271_v10 (stack77)
        %v136416_v52 = vsel /*vm=*/%vm47883_vm15, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v47951_v31 = vmul.f32 %v47947_v22, %v136401_v25 (stack54)
        %v48725_v32 = vxor.u32 %v48724_v9, %v48720_v53 (stack48)
        %v47912_v23 = vsel /*vm=*/%vm47883_vm15, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v48327_v56 = vxor.u32 2147483648, %v136409_v27 (stack56)
        %v49143_v42 = vadd.s32 %v49140_v60, %v49135_v42 (stack40)
        %v50410_v30 = vadd.s32 %v136378_v30, %v121569_v1 (stack40)
        %v47955_v21 = vadd.f32 %v47951_v31, %v47912_v23 (stack53)
        %v48728_v61 = vadd.s32 %v48725_v32, %v48720_v53 (stack40)
        %v48730_v34 = vshll.u32 %v48725_v32, 26 (stack45)
        %v48731_v50 = vshrl.u32 %v48725_v32, 6 (stack46)
        %v47900_v53 = vsel /*vm=*/%vm47883_vm15, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v47904_v6 = vsel /*vm=*/%vm47883_vm15, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v136432_v24 = vmul.f32 %v48327_v56, %v136409_v27 (stack54)
        %v49149_v20 = vshll.u32 %v49140_v60, 6 (stack45)
        %v47959_v7 = vmul.f32 %v47955_v21, %v136401_v25 (stack54)
        %v48732_v41 = vor.u32 %v48731_v50, %v48730_v34 (stack47)
        %v49150_v46 = vshrl.u32 %v49140_v60, 26 (stack46)
        %v49560_v11 = vadd.s32 %v49557_v55, %v49552_v11 (stack40)
        %v47908_v22 = vsel /*vm=*/%vm47883_vm15, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v48332_v9 = vadd.f32 1.0, %v136432_v24 (stack57)
        %v49566_v60 = vshll.u32 %v49557_v55, 24 (stack45)
        %v50406_v29 = vadd.s32 %v50401_v29, %v121574_v2 (stack40)
        %v47963_v31 = vadd.f32 %v47959_v7, %v47908_v22 (stack53)
        %v48733_v32 = vxor.u32 %v48732_v41, %v48728_v61 (stack48)
        %v49151_v23 = vor.u32 %v49150_v46, %v49149_v20 (stack47)
        %v50416_v56 = vshll.u32 %v50410_v30, 13 (stack45)
        %120841 = vlog2.f32 %v48332_v9 (stack58)
        %v48335_v21 = vmul.f32 -0.5, %v136432_v24 (stack59)
        %v49147_v34 = vadd.s32 %v49143_v42, %v121574_v2 (stack40)
        %v49567_v55 = vshrl.u32 %v49557_v55, 8 (stack46)
        %v47967_v50 = vmul.f32 %v47963_v31, %v136401_v25 (stack54)
        %v48736_v61 = vadd.s32 %v48733_v32, %v48728_v61 (stack40)
        %v48742_v20 = vshll.u32 %v48733_v32, 6 (stack45)
        %v48743_v7 = vshrl.u32 %v48733_v32, 26 (stack46)
        %v48338_v41 = vand.u32 2147483647, %v136432_v24 (stack60)
        %v49152_v42 = vxor.u32 %v49151_v23, %v49143_v42 (stack48)
        %v49568_v46 = vor.u32 %v49567_v55, %v49566_v60 (stack47)
        %v49969_v26 = vadd.s32 %v49966_v8, %v136394_v26 (stack40)
        %v47971_v6 = vadd.f32 %v47967_v50, %v47904_v6 (stack53)
        %v48744_v22 = vor.u32 %v48743_v7, %v48742_v20 (stack47)
        %v49564_v9 = vadd.s32 %v49560_v11, %v121564_v0 (stack40)
        %v49971_v60 = vshll.u32 %v49966_v8, 26 (stack45)
        %v49155_v31 = vadd.s32 %v49152_v42, %v121569_v1 (stack40)
        %v49569_v11 = vxor.u32 %v49568_v46, %v49560_v11 (stack48)
        %v49972_v8 = vshrl.u32 %v49966_v8, 6 (stack46)
        %v50414_v29 = vadd.s32 %v50410_v30, %v50406_v29 (stack40)
        %v47975_v32 = vmul.f32 %v47971_v6, %v136401_v25 (stack54)
        %v48336_v23 = vadd.f32 1.0, %v48335_v21 (stack61)
        %v48745_v21 = vxor.u32 %v48744_v22, %v48736_v61 (stack48)
        %v50417_v30 = vshrl.u32 %v50410_v30, 19 (stack46)
        %v49159_v55 = vadd.s32 3, %v49155_v31 (stack40)
        %v49572_v50 = vadd.s32 %v49569_v11, %v121574_v2 (stack40)
        %v49973_v20 = vor.u32 %v49972_v8, %v49971_v60 (stack47)
        %vm50841_vm5 = vcmp.lt.u32.totalorder %v136374_v44, %v157083_v59 (stack43)
        %v47979_v53 = vadd.f32 %v47975_v32, %v47900_v53 (stack53)
        %v48740_v61 = vadd.s32 %v48736_v61, %v121564_v0 (stack40)
        %v48748_v7 = vadd.s32 %v48745_v21, %v121574_v2 (stack40)
        %v50418_v56 = vor.u32 %v50417_v30, %v50416_v56 (stack47)
        %v49163_v34 = vadd.s32 %v49159_v55, %v49147_v34 (stack40)
        %v49165_v42 = vshll.u32 %v49159_v55, 17 (stack45)
        %v49166_v46 = vshrl.u32 %v49159_v55, 15 (stack46)
        %v49576_v6 = vadd.s32 2, %v49572_v50 (stack40)
        %v47983_v22 = vmul.f32 %v47979_v53, %v136401_v25 (stack54)
        %v48752_v60 = vadd.s32 5, %v48748_v7 (stack40)
        %v49974_v31 = vxor.u32 %v49973_v20, %v49969_v26 (stack48)
        %v136454_v11 = vxor.u32 %v50418_v56, %v50414_v29 (stack48)
        %v49167_v8 = vor.u32 %v49166_v46, %v49165_v42 (stack47)
        %v49580_v9 = vadd.s32 %v49576_v6, %v49564_v9 (stack40)
        %v49582_v32 = vshll.u32 %v49576_v6, 13 (stack45)
        %v49583_v21 = vshrl.u32 %v49576_v6, 19 (stack46)
        %v47987_v52 = vadd.f32 %v47983_v22, %v136416_v52 (stack53)
        %v48754_v30 = vxor.u32 %v48752_v60, %v48740_v61 (stack48)
        %v49977_v26 = vadd.s32 %v49974_v31, %v49969_v26 (stack40)
        %v49983_v55 = vshll.u32 %v49974_v31, 6 (stack45)
        %v49168_v50 = vxor.u32 %v49167_v8, %v49163_v34 (stack48)
        %v49584_v20 = vor.u32 %v49583_v21, %v49582_v32 (stack47)
        %v49984_v53 = vshrl.u32 %v49974_v31, 26 (stack46)
        %v136458_v29 = vadd.s32 %v136454_v11, %v50414_v29 (stack40)
        %v120842_v61 = vpop.eup %120841 (stack64)
        %v47892_v7 = vsel /*vm=*/%vm47883_vm15, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v47991_v56 = vmul.f32 %v47987_v52, %v136401_v25 (stack54)
        %v48337_v24 = vmul.f32 %v48336_v23, %v136432_v24 (stack63)
        %v48755_v23 = vand.u32.u8 255, %v48754_v30 (stack49)
        %v48334_v42 = vmul.f32 0.6931472, %v120842_v61 (stack65)
        %v49171_v34 = vadd.s32 %v49168_v50, %v49163_v34 (stack40)
        %v49173_v46 = vshll.u32 %v49168_v50, 29 (stack45)
        %v49174_v6 = vshrl.u32 %v49168_v50, 3 (stack46)
        %v47995_v22 = vadd.f32 %v47991_v56, %v47892_v7 (stack53)
        %vm48339_vm6 = vcmp.lt.f32.partialorder %v48338_v41, 0.0004427343 (stack62)
        %v49585_v41 = vxor.u32 %v49584_v20, %v49580_v9 (stack48)
        %v49985_v60 = vor.u32 %v49984_v53, %v49983_v55 (stack47)
        %v48340_v31 = vsel /*vm=*/%vm48339_vm6, /*on_true_vy=*/%v48337_v24, /*on_false_vx=*/%v48334_v42 (stack66)
        %v48756_v8 = vand.u32 65535, %v48755_v23 (stack50)
        %v49175_v32 = vor.u32 %v49174_v6, %v49173_v46 (stack47)
        %v50846_v21 = vadd.s32 %v157366_v12, %v157084_v16 (stack40)
        %v47888_v54 = vsel /*vm=*/%vm47883_vm15, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v47999_v25 = vmul.f32 %v47995_v22, %v136401_v25 (stack54)
        %v136471_v52 = vxor.u32 2147483648, %v48340_v31 (stack56)
        %v49588_v9 = vadd.s32 %v49585_v41, %v49580_v9 (stack40)
        %v49176_v30 = vxor.u32 %v49175_v32, %v49171_v34 (stack48)
        %v49590_v55 = vshll.u32 %v49585_v41, 15 (stack45)
        %v49591_v50 = vshrl.u32 %v49585_v41, 17 (stack46)
        %v49986_v20 = vxor.u32 %v49985_v60, %v49977_v26 (stack48)
        %vm136475_vm7 = vcmp.eq.f32.partialorder %v47856_v43, 1.0 (stack68)
        %v47864_v53 = vmul.f32 inf, %v136271_v10 (stack54)
        %v48003_v61 = vadd.f32 %v47999_v25, %v47888_v54 (stack53)
        %120843 = vrsqrt.f32 %v136471_v52 (stack67)
        %v48317_v7 = vand.u32 2147483647, %v136409_v27 (stack77)
        %vm48344_vm8 = vcmp.lt.f32.partialorder %v136471_v52, 5.0 (stack68)
        %v48757_v56 = vshrl.u32 %v48756_v8, 1 (stack51)
        %v49179_v24 = vadd.s32 %v49176_v30, %v49171_v34 (stack40)
        %v48007_v10 = vmul.f32 %v48003_v61, %v136271_v10 (stack54)
        %v136485_v23 = vmul.f32 inf, %v136409_v27 (stack54)
        %v50424_v42 = vshll.u32 %v136454_v11, 15 (stack45)
        %v50425_v11 = vshrl.u32 %v136454_v11, 17 (stack46)
        %v136490_v34 = vadd.f32 -2.5, %v136471_v52 (stack53)
        %v49592_v46 = vor.u32 %v49591_v50, %v49590_v55 (stack47)
        %v49981_v26 = vadd.s32 %v49977_v26, %v121569_v1 (stack40)
        %v136495_v6 = vadd.s32 %v136374_v44, %v122657_v58 (stack40)
        %v48011_v22 = vsel /*vm=*/%vm136475_vm7, /*on_true_vy=*/%v47864_v53, /*on_false_vx=*/%v48007_v10 (stack44)
        %v136502_v41 = vsel /*vm=*/%vm48344_vm8, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v136507_v60 = vsel /*vm=*/%vm48344_vm8, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v136512_v31 = vsel /*vm=*/%vm48344_vm8, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v48015_v8 = vmul.f32 1.4140625, %v48011_v22 (stack54)
        %v48758_v32 = vor.u32 16256, %v48757_v56 (stack47)
        %v49181_v54 = vshll.u32 %v49176_v30, 16 (stack45)
        %v49182_v25 = vshrl.u32 %v49176_v30, 16 (stack46)
        %v136517_v30 = vsel /*vm=*/%vm48344_vm8, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v49593_v55 = vxor.u32 %v49592_v46, %v49588_v9 (stack48)
        %v49989_v50 = vadd.s32 %v49986_v20, %v121564_v0 (stack40)
        %v50426_v20 = vor.u32 %v50425_v11, %v50424_v42 (stack47)
        %v48018_v43 = vpack.c.bf16 %v156663_v45, %v48015_v8 (stack81)
        %v48759_v53 = vand.u32.u16 65535, %v48758_v32 (stack52)
        %v49183_v61 = vor.u32 %v49182_v25, %v49181_v54 (stack47)
        %v50850_v56 = vadd.s32 1, %v50846_v21 (stack40)
        %v49596_v9 = vadd.s32 %v49593_v55, %v49588_v9 (stack40)
        %v49598_v10 = vshll.u32 %v49593_v55, 26 (stack45)
        %v49599_v42 = vshrl.u32 %v49593_v55, 6 (stack46)
        %v49993_v11 = vadd.s32 1, %v49989_v50 (stack40)
        %119999 = vst [vmem:[%s123356_s30 + $0x2b0] sm:$0xf] /*vst_source=*/%v48018_v43 (stack83)
        %v120002_v46 = vadd.low.f32.bf16 -1.0, %v48759_v53 (stack53)
        %v49184_v22 = vxor.u32 %v49183_v61, %v49179_v24 (stack48)
        %v50427_v8 = vxor.u32 %v50426_v20, %v136458_v29 (stack48)
        %v136526_v21 = vsel /*vm=*/%vm50841_vm5, /*on_true_vy=*/%v50850_v56, /*on_false_vx=*/%v50846_v21 (stack44)
        %v49600_v32 = vor.u32 %v49599_v42, %v49598_v10 (stack47)
        %v49997_v26 = vadd.s32 %v49993_v11, %v49981_v26 (stack40)
        %v49999_v54 = vshll.u32 %v49993_v11, 17 (stack45)
        %v50000_v25 = vshrl.u32 %v49993_v11, 15 (stack46)
        %v48768_v55 = vmul.f32 2.0, %v120002_v46 (stack54)
        %v49187_v24 = vadd.s32 %v49184_v22, %v49179_v24 (stack40)
        %v49193_v50 = vshll.u32 %v49184_v22, 24 (stack45)
        %v49194_v20 = vshrl.u32 %v49184_v22, 8 (stack46)
        %v49601_v43 = vxor.u32 %v49600_v32, %v49596_v9 (stack48)
        %v50001_v53 = vor.u32 %v50000_v25, %v49999_v54 (stack47)
        %v50430_v29 = vadd.s32 %v50427_v8, %v136458_v29 (stack40)
        %v50432_v61 = vshll.u32 %v50427_v8, 26 (stack45)
        %v120844_v56 = vpop.eup %120843 (stack73)
        %vm48389_vm9 = vcmp.eq.f32.partialorder %v136471_v52, inf (stack70)
        %v48772_v10 = vadd.f32 -0.99609375, %v48768_v55 (stack53)
        %v49195_v42 = vor.u32 %v49194_v20, %v49193_v50 (stack47)
        %v50433_v11 = vshrl.u32 %v50427_v8, 6 (stack46)
        %v48388_v46 = vmul.f32 %v120844_v56, %v136471_v52 (stack74)
        %v49604_v9 = vadd.s32 %v49601_v43, %v49596_v9 (stack40)
        %v49610_v22 = vshll.u32 %v49601_v43, 6 (stack45)
        %v49611_v8 = vshrl.u32 %v49601_v43, 26 (stack46)
        %v48392_v32 = vand.u32 2147483648, %v136471_v52 (stack72)
        %v136532_v54 = vmax.f32 %v48772_v10, -0.99609375 (stack55)
        %v49196_v25 = vxor.u32 %v49195_v42, %v49187_v24 (stack48)
        %v50002_v55 = vxor.u32 %v50001_v53, %v49997_v26 (stack48)
        %v48390_v50 = vsel /*vm=*/%vm48389_vm9, /*on_true_vy=*/%v136471_v52, /*on_false_vx=*/%v48388_v46 (stack75)
        %vm48391_vm10 = vcmp.eq.f32.partialorder %v136471_v52, 0.0 (stack71)
        %v49612_v20 = vor.u32 %v49611_v8, %v49610_v22 (stack47)
        %v50434_v43 = vor.u32 %v50433_v11, %v50432_v61 (stack47)
        %vm50836_vm11 = vcmp.lt.u32.totalorder %v136495_v6, %v136374_v44 (stack43)
        %v48369_v53 = vsel /*vm=*/%vm48344_vm8, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v48377_v61 = vsel /*vm=*/%vm48344_vm8, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v48393_v56 = vsel /*vm=*/%vm48391_vm10, /*on_true_vy=*/%v48392_v32, /*on_false_vx=*/%v48390_v50 (stack76)
        %v48788_v10 = vxor.u32 2147483648, %v136532_v54 (stack56)
        %v48396_v42 = vadd.f32 -3.0, %v48393_v56 (stack53)
        %v49199_v11 = vadd.s32 %v49196_v25, %v121564_v0 (stack40)
        %v49613_v46 = vxor.u32 %v49612_v20, %v49604_v9 (stack48)
        %v50005_v26 = vadd.s32 %v50002_v55, %v49997_v26 (stack40)
        %v48381_v22 = vsel /*vm=*/%vm48344_vm8, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v136550_v8 = vmul.f32 %v48788_v10, %v136532_v54 (stack54)
        %v49191_v24 = vadd.s32 %v49187_v24, %v121569_v1 (stack40)
        %v49608_v9 = vadd.s32 %v49604_v9, %v121574_v2 (stack40)
        %v136557_v34 = vsel /*vm=*/%vm48344_vm8, /*on_true_vy=*/%v136490_v34, /*on_false_vx=*/%v48396_v42 (stack44)
        %v49203_v32 = vadd.s32 4, %v49199_v11 (stack40)
        %v49616_v25 = vadd.s32 %v49613_v46, %v121569_v1 (stack40)
        %v50435_v50 = vxor.u32 %v50434_v43, %v50430_v29 (stack48)
        %v48404_v20 = vmul.f32 %v136557_v34, %v48381_v22 (stack54)
        %v48793_v43 = vadd.f32 1.0, %v136550_v8 (stack57)
        %v50007_v56 = vshll.u32 %v50002_v55, 29 (stack45)
        %v50008_v55 = vshrl.u32 %v50002_v55, 3 (stack46)
        %v49207_v10 = vadd.s32 %v49203_v32, %v49191_v24 (stack40)
        %v49209_v42 = vshll.u32 %v49203_v32, 13 (stack45)
        %v49210_v11 = vshrl.u32 %v49203_v32, 19 (stack46)
        %v49620_v46 = vadd.s32 3, %v49616_v25 (stack40)
        %v48373_v22 = vsel /*vm=*/%vm48344_vm8, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v48408_v61 = vadd.f32 %v48404_v20, %v48377_v61 (stack53)
        %120845 = vlog2.f32 %v48793_v43 (stack58)
        %v50858_v24 = vadd.s32 1, %v136526_v21 (stack40)
        %v49211_v32 = vor.u32 %v49210_v11, %v49209_v42 (stack47)
        %v49624_v9 = vadd.s32 %v49620_v46, %v49608_v9 (stack40)
        %v49626_v25 = vshll.u32 %v49620_v46, 17 (stack45)
        %v49627_v20 = vshrl.u32 %v49620_v46, 15 (stack46)
        %v48412_v43 = vmul.f32 %v48408_v61, %v136557_v34 (stack54)
        %v50009_v56 = vor.u32 %v50008_v55, %v50007_v56 (stack47)
        %v136567_v29 = vadd.s32 %v50435_v50, %v50430_v29 (stack40)
        %v136571_v55 = vadd.s32 %v136495_v6, %v121569_v1 (stack40)
        %v48796_v42 = vmul.f32 -0.5, %v136550_v8 (stack59)
        %v49212_v11 = vxor.u32 %v49211_v32, %v49207_v10 (stack48)
        %v49628_v46 = vor.u32 %v49627_v20, %v49626_v25 (stack47)
        %v50444_v61 = vshll.u32 %v50435_v50, 6 (stack45)
        %v48416_v22 = vadd.f32 %v48412_v43, %v48373_v22 (stack53)
        %v50010_v32 = vxor.u32 %v50009_v56, %v50005_v26 (stack48)
        %v50445_v50 = vshrl.u32 %v50435_v50, 26 (stack46)
        %v50862_v44 = vsel /*vm=*/%vm50836_vm11, /*on_true_vy=*/%v50858_v24, /*on_false_vx=*/%v136526_v21 (stack44)
        %v49215_v6 = vadd.s32 %v49212_v11, %v49207_v10 (stack40)
        %v49217_v21 = vshll.u32 %v49212_v11, 15 (stack45)
        %v49218_v10 = vshrl.u32 %v49212_v11, 17 (stack46)
        %v49629_v24 = vxor.u32 %v49628_v46, %v49624_v9 (stack48)
        %v48420_v25 = vmul.f32 %v48416_v22, %v136557_v34 (stack54)
        %v50013_v26 = vadd.s32 %v50010_v32, %v50005_v26 (stack40)
        %v50015_v20 = vshll.u32 %v50010_v32, 16 (stack45)
        %v50016_v43 = vshrl.u32 %v50010_v32, 16 (stack46)
        %v49219_v56 = vor.u32 %v49218_v10, %v49217_v21 (stack47)
        %v49632_v9 = vadd.s32 %v49629_v24, %v49624_v9 (stack40)
        %v49634_v11 = vshll.u32 %v49629_v24, 29 (stack45)
        %v49635_v46 = vshrl.u32 %v49629_v24, 3 (stack46)
        %v48424_v53 = vadd.f32 %v48420_v25, %v48369_v53 (stack53)
        %v50017_v22 = vor.u32 %v50016_v43, %v50015_v20 (stack47)
        %v50446_v61 = vor.u32 %v50445_v50, %v50444_v61 (stack47)
        %v50867_v32 = vadd.s32 %v50862_v44, %v121574_v2 (stack40)
        %v48797_v42 = vadd.f32 1.0, %v48796_v42 (stack61)
        %v48799_v50 = vand.u32 2147483647, %v136550_v8 (stack60)
        %v49220_v44 = vxor.u32 %v49219_v56, %v49215_v6 (stack48)
        %v49636_v21 = vor.u32 %v49635_v46, %v49634_v11 (stack47)
        %v48428_v10 = vmul.f32 %v48424_v53, %v136557_v34 (stack54)
        %v50018_v24 = vxor.u32 %v50017_v22, %v50013_v26 (stack48)
        %v50447_v25 = vxor.u32 %v50446_v61, %v136567_v29 (stack48)
        %v136584_v20 = vadd.s32 %v136571_v55, %v50867_v32 (stack40)
        %v49223_v6 = vadd.s32 %v49220_v44, %v49215_v6 (stack40)
        %v49225_v43 = vshll.u32 %v49220_v44, 26 (stack45)
        %v49226_v56 = vshrl.u32 %v49220_v44, 6 (stack46)
        %v49637_v11 = vxor.u32 %v49636_v21, %v49632_v9 (stack48)
        %v48432_v30 = vadd.f32 %v48428_v10, %v136517_v30 (stack53)
        %v50021_v26 = vadd.s32 %v50018_v24, %v50013_v26 (stack40)
        %v50027_v46 = vshll.u32 %v50018_v24, 24 (stack45)
        %v50028_v53 = vshrl.u32 %v50018_v24, 8 (stack46)
        %v120846_v22 = vpop.eup %120845 (stack64)
        %v49227_v61 = vor.u32 %v49226_v56, %v49225_v43 (stack47)
        %v49640_v9 = vadd.s32 %v49637_v11, %v49632_v9 (stack40)
        %v49642_v32 = vshll.u32 %v49637_v11, 16 (stack45)
        %v49643_v44 = vshrl.u32 %v49637_v11, 16 (stack46)
        %v48436_v21 = vmul.f32 %v48432_v30, %v136557_v34 (stack54)
        %v48795_v10 = vmul.f32 0.6931472, %v120846_v22 (stack65)
        %v48798_v8 = vmul.f32 %v48797_v42, %v136550_v8 (stack63)
        %v50029_v42 = vor.u32 %v50028_v53, %v50027_v46 (stack47)
        %vm48800_vm12 = vcmp.lt.f32.partialorder %v48799_v50, 0.0004427343 (stack62)
        %v49228_v50 = vxor.u32 %v49227_v61, %v49223_v6 (stack48)
        %v49644_v24 = vor.u32 %v49643_v44, %v49642_v32 (stack47)
        %v50877_v43 = vshll.u32 %v136571_v55, 13 (stack45)
        %v48440_v31 = vadd.f32 %v48436_v21, %v136512_v31 (stack53)
        %v48801_v56 = vsel /*vm=*/%vm48800_vm12, /*on_true_vy=*/%v48798_v8, /*on_false_vx=*/%v48795_v10 (stack66)
        %v50030_v11 = vxor.u32 %v50029_v42, %v50021_v26 (stack48)
        %v136593_v30 = vadd.s32 %v157365_v40, %v157089_v17 (stack40)
        %v136595_v46 = vxor.u32 2147483648, %v48801_v56 (stack56)
        %v49231_v6 = vadd.s32 %v49228_v50, %v49223_v6 (stack40)
        %v50450_v25 = vadd.s32 %v50447_v25, %v121564_v0 (stack40)
        %v50878_v55 = vshrl.u32 %v136571_v55, 19 (stack46)
        %v48357_v52 = vsel /*vm=*/%vm48344_vm8, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v48444_v53 = vmul.f32 %v48440_v31, %v136557_v34 (stack54)
        %v48778_v22 = vand.u32 2147483647, %v136532_v54 (stack77)
        %v49645_v61 = vxor.u32 %v49644_v24, %v49640_v9 (stack48)
        %vm48805_vm13 = vcmp.lt.f32.partialorder %v136595_v46, 5.0 (stack68)
        %120847 = vrsqrt.f32 %v136595_v46 (stack67)
        %v49237_v32 = vshll.u32 %v49228_v50, 6 (stack45)
        %v49238_v44 = vshrl.u32 %v49228_v50, 26 (stack46)
        %v48448_v21 = vadd.f32 %v48444_v53, %v48357_v52 (stack53)
        %v136607_v10 = vmul.f32 inf, %v136532_v54 (stack54)
        %v50033_v8 = vadd.s32 %v50030_v11, %v121574_v2 (stack40)
        %v50442_v29 = vadd.s32 %v136567_v29, %v121569_v1 (stack40)
        %v136613_v42 = vadd.f32 -2.5, %v136595_v46 (stack53)
        %v50025_v26 = vadd.s32 %v50021_v26, %v121564_v0 (stack40)
        %v50454_v50 = vadd.s32 1, %v50450_v25 (stack40)
        %v50879_v24 = vor.u32 %v50878_v55, %v50877_v43 (stack47)
        %v48452_v43 = vmul.f32 %v48448_v21, %v136557_v34 (stack54)
        %v136620_v31 = vsel /*vm=*/%vm48805_vm13, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v136625_v56 = vsel /*vm=*/%vm48805_vm13, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v136630_v11 = vsel /*vm=*/%vm48805_vm13, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %vm136634_vm14 = vcmp.eq.f32.partialorder %v48317_v7, 1.0 (stack68)
        %v136641_v25 = vsel /*vm=*/%vm48805_vm13, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v49235_v55 = vadd.s32 %v49231_v6, %v121564_v0 (stack40)
        %v49239_v52 = vor.u32 %v49238_v44, %v49237_v32 (stack47)
        %v49648_v9 = vadd.s32 %v49645_v61, %v49640_v9 (stack40)
        %v48456_v60 = vadd.f32 %v48452_v43, %v136507_v60 (stack53)
        %v49654_v53 = vshll.u32 %v49645_v61, 24 (stack45)
        %v49655_v61 = vshrl.u32 %v49645_v61, 8 (stack46)
        %v50037_v32 = vadd.s32 2, %v50033_v8 (stack40)
        %v136648_v44 = vsel /*vm=*/%vm48805_vm13, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v49240_v6 = vxor.u32 %v49239_v52, %v49231_v6 (stack48)
        %v50458_v21 = vadd.s32 %v50454_v50, %v50442_v29 (stack40)
        %v50460_v8 = vshll.u32 %v50454_v50, 17 (stack45)
        %v48460_v34 = vmul.f32 %v48456_v60, %v136557_v34 (stack54)
        %vm48850_vm15 = vcmp.eq.f32.partialorder %v136595_v46, inf (stack70)
        %v49656_v29 = vor.u32 %v49655_v61, %v49654_v53 (stack47)
        %v50041_v26 = vadd.s32 %v50037_v32, %v50025_v26 (stack40)
        %v50043_v43 = vshll.u32 %v50037_v32, 13 (stack45)
        %vm48852_vm0 = vcmp.eq.f32.partialorder %v136595_v46, 0.0 (stack71)
        %v49243_v52 = vadd.s32 %v49240_v6, %v121574_v2 (stack40)
        %v50044_v60 = vshrl.u32 %v50037_v32, 19 (stack46)
        %v50461_v50 = vshrl.u32 %v50454_v50, 15 (stack46)
        %v50880_v24 = vxor.u32 %v50879_v24, %v136584_v20 (stack48)
        %v48464_v41 = vadd.f32 %v48460_v34, %v136502_v41 (stack53)
        %v48853_v53 = vand.u32 2147483648, %v136595_v46 (stack72)
        %v49657_v61 = vxor.u32 %v49656_v29, %v49648_v9 (stack48)
        %vm51302_vm1 = vcmp.lt.u32.totalorder %v136593_v30, %v157089_v17 (stack43)
        %v49247_v32 = vadd.s32 5, %v49243_v52 (stack40)
        %v50045_v6 = vor.u32 %v50044_v60, %v50043_v43 (stack47)
        %v50462_v8 = vor.u32 %v50461_v50, %v50460_v8 (stack47)
        %v50883_v20 = vadd.s32 %v50880_v24, %v136584_v20 (stack40)
        %v48468_v27 = vmul.f32 %v48464_v41, %v136409_v27 (stack54)
        %v49660_v34 = vadd.s32 %v49657_v61, %v121564_v0 (stack40)
        %v50885_v29 = vshll.u32 %v50880_v24, 15 (stack45)
        %v50886_v43 = vshrl.u32 %v50880_v24, 17 (stack46)
        %v49249_v55 = vxor.u32 %v49247_v32, %v49235_v55 (stack48)
        %v49652_v9 = vadd.s32 %v49648_v9, %v121569_v1 (stack40)
        %v50046_v52 = vxor.u32 %v50045_v6, %v50041_v26 (stack48)
        %v50463_v60 = vxor.u32 %v50462_v8, %v50458_v21 (stack48)
        %v120848_v50 = vpop.eup %120847 (stack73)
        %v48472_v23 = vsel /*vm=*/%vm136634_vm14, /*on_true_vy=*/%v136485_v23, /*on_false_vx=*/%v48468_v27 (stack44)
        %v49664_v7 = vadd.s32 4, %v49660_v34 (stack40)
        %v50887_v24 = vor.u32 %v50886_v43, %v50885_v29 (stack47)
        %v136668_v41 = vadd.s32 %v157366_v12, %v157090_v62 (stack40)
        %v48476_v61 = vmul.f32 1.4140625, %v48472_v23 (stack54)
        %v48849_v32 = vmul.f32 %v120848_v50, %v136595_v46 (stack74)
        %v49250_v6 = vand.u32.u8 255, %v49249_v55 (stack49)
        %v50049_v26 = vadd.s32 %v50046_v52, %v50041_v26 (stack40)
        %v49668_v8 = vadd.s32 %v49664_v7, %v49652_v9 (stack40)
        %v49670_v27 = vshll.u32 %v49664_v7, 13 (stack45)
        %v49671_v34 = vshrl.u32 %v49664_v7, 19 (stack46)
        %v50051_v29 = vshll.u32 %v50046_v52, 15 (stack45)
        %v48479_v43 = vpack.c.bf16 %v156663_v45, %v48476_v61 (stack81)
        %v48851_v55 = vsel /*vm=*/%vm48850_vm15, /*on_true_vy=*/%v136595_v46, /*on_false_vx=*/%v48849_v32 (stack75)
        %v49251_v9 = vand.u32 65535, %v49250_v6 (stack50)
        %v50052_v52 = vshrl.u32 %v50046_v52, 17 (stack46)
        %v48854_v53 = vsel /*vm=*/%vm48852_vm0, /*on_true_vy=*/%v48853_v53, /*on_false_vx=*/%v48851_v55 (stack76)
        %v49672_v50 = vor.u32 %v49671_v34, %v49670_v27 (stack47)
        %v50466_v21 = vadd.s32 %v50463_v60, %v50458_v21 (stack40)
        %v50468_v23 = vshll.u32 %v50463_v60, 29 (stack45)
        %120001 = vst [vmem:[%s123356_s30 + $0x330] sm:$0xf] /*vst_source=*/%v48479_v43 (stack83)
        %v48857_v7 = vadd.f32 -3.0, %v48854_v53 (stack53)
        %v49252_v61 = vshrl.u32 %v49251_v9, 1 (stack51)
        %v50053_v32 = vor.u32 %v50052_v52, %v50051_v29 (stack47)
        %v50469_v60 = vshrl.u32 %v50463_v60, 3 (stack46)
        %v48842_v6 = vsel /*vm=*/%vm48805_vm13, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v49673_v27 = vxor.u32 %v49672_v50, %v49668_v8 (stack48)
        %v50888_v24 = vxor.u32 %v50887_v24, %v50883_v20 (stack48)
        %v51311_v34 = vadd.s32 1, %v136668_v41 (stack40)
        %v136685_v42 = vsel /*vm=*/%vm48805_vm13, /*on_true_vy=*/%v136613_v42, /*on_false_vx=*/%v48857_v7 (stack44)
        %v49253_v29 = vor.u32 16256, %v49252_v61 (stack47)
        %v50054_v43 = vxor.u32 %v50053_v32, %v50049_v26 (stack48)
        %v50470_v55 = vor.u32 %v50469_v60, %v50468_v23 (stack47)
        %v48865_v9 = vmul.f32 %v136685_v42, %v48842_v6 (stack54)
        %v49676_v8 = vadd.s32 %v49673_v27, %v49668_v8 (stack40)
        %v49678_v52 = vshll.u32 %v49673_v27, 15 (stack45)
        %v49679_v53 = vshrl.u32 %v49673_v27, 17 (stack46)
        %v49254_v50 = vand.u32.u16 65535, %v49253_v29 (stack52)
        %v50057_v26 = vadd.s32 %v50054_v43, %v50049_v26 (stack40)
        %v50059_v23 = vshll.u32 %v50054_v43, 26 (stack45)
        %v50060_v7 = vshrl.u32 %v50054_v43, 6 (stack46)
        %v48869_v44 = vadd.f32 %v48865_v9, %v136648_v44 (stack53)
        %v49680_v61 = vor.u32 %v49679_v53, %v49678_v52 (stack47)
        %v50471_v32 = vxor.u32 %v50470_v55, %v50466_v21 (stack48)
        %v50891_v20 = vadd.s32 %v50888_v24, %v50883_v20 (stack40)
        %v120008_v60 = vadd.low.f32.bf16 -1.0, %v49254_v50 (stack53)
        %v50061_v6 = vor.u32 %v50060_v7, %v50059_v23 (stack47)
        %v50893_v27 = vshll.u32 %v50888_v24, 26 (stack45)
        %v50894_v24 = vshrl.u32 %v50888_v24, 6 (stack46)
        %v48873_v29 = vmul.f32 %v48869_v44, %v136685_v42 (stack54)
        %v49681_v43 = vxor.u32 %v49680_v61, %v49676_v8 (stack48)
        %v50474_v21 = vadd.s32 %v50471_v32, %v50466_v21 (stack40)
        %v50476_v55 = vshll.u32 %v50471_v32, 16 (stack45)
        %v49263_v9 = vmul.f32 2.0, %v120008_v60 (stack54)
        %v50062_v52 = vxor.u32 %v50061_v6, %v50057_v26 (stack48)
        %v50477_v53 = vshrl.u32 %v50471_v32, 16 (stack46)
        %v50895_v50 = vor.u32 %v50894_v24, %v50893_v27 (stack47)
        %v48877_v25 = vadd.f32 %v48873_v29, %v136641_v25 (stack53)
        %v49684_v8 = vadd.s32 %v49681_v43, %v49676_v8 (stack40)
        %v49686_v23 = vshll.u32 %v49681_v43, 26 (stack45)
        %v49687_v7 = vshrl.u32 %v49681_v43, 6 (stack46)
        %v49267_v44 = vadd.f32 -0.99609375, %v49263_v9 (stack53)
        %v50065_v26 = vadd.s32 %v50062_v52, %v50057_v26 (stack40)
        %v50071_v61 = vshll.u32 %v50062_v52, 6 (stack45)
        %v50072_v32 = vshrl.u32 %v50062_v52, 26 (stack46)
        %v48881_v60 = vmul.f32 %v48877_v25, %v136685_v42 (stack54)
        %v49688_v6 = vor.u32 %v49687_v7, %v49686_v23 (stack47)
        %v50478_v27 = vor.u32 %v50477_v53, %v50476_v55 (stack47)
        %v50896_v24 = vxor.u32 %v50895_v50, %v50891_v20 (stack48)
        %v136692_v29 = vmax.f32 %v49267_v44, -0.99609375 (stack55)
        %v50073_v43 = vor.u32 %v50072_v32, %v50071_v61 (stack47)
        %v51293_v55 = vadd.s32 %v136593_v30, %v122657_v58 (stack40)
        %v51315_v41 = vsel /*vm=*/%vm51302_vm1, /*on_true_vy=*/%v51311_v34, /*on_false_vx=*/%v136668_v41 (stack44)
        %v48885_v11 = vadd.f32 %v48881_v60, %v136630_v11 (stack53)
        %v49689_v34 = vxor.u32 %v49688_v6, %v49684_v8 (stack48)
        %v50479_v9 = vxor.u32 %v50478_v27, %v50474_v21 (stack48)
        %v136701_v20 = vadd.s32 %v50896_v24, %v50891_v20 (stack40)
        %v48818_v52 = vsel /*vm=*/%vm48805_vm13, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v48822_v53 = vsel /*vm=*/%vm48805_vm13, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v49283_v50 = vxor.u32 2147483648, %v136692_v29 (stack56)
        %v50074_v25 = vxor.u32 %v50073_v43, %v50065_v26 (stack48)
        %v48889_v23 = vmul.f32 %v48885_v11, %v136685_v42 (stack54)
        %v49692_v8 = vadd.s32 %v49689_v34, %v49684_v8 (stack40)
        %v49698_v7 = vshll.u32 %v49689_v34, 6 (stack45)
        %v49699_v44 = vshrl.u32 %v49689_v34, 26 (stack46)
        %v48826_v46 = vsel /*vm=*/%vm48805_vm13, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v49286_v61 = vmul.f32 %v49283_v50, %v136692_v29 (stack54)
        %v50077_v32 = vadd.s32 %v50074_v25, %v121569_v1 (stack40)
        %v50482_v21 = vadd.s32 %v50479_v9, %v50474_v21 (stack40)
        %v48893_v60 = vadd.f32 %v48889_v23, %v48826_v46 (stack53)
        %v49700_v6 = vor.u32 %v49699_v44, %v49698_v7 (stack47)
        %v50069_v26 = vadd.s32 %v50065_v26, %v121574_v2 (stack40)
        %vm51297_vm2 = vcmp.lt.u32.totalorder %v51293_v55, %v136593_v30 (stack43)
        %v49288_v27 = vadd.f32 1.0, %v49286_v61 (stack57)
        %v49291_v43 = vmul.f32 -0.5, %v49286_v61 (stack59)
        %v50081_v11 = vadd.s32 3, %v50077_v32 (stack40)
        %v50488_v34 = vshll.u32 %v50479_v9, 24 (stack45)
        %v48897_v50 = vmul.f32 %v48893_v60, %v136685_v42 (stack54)
        %v49701_v25 = vxor.u32 %v49700_v6, %v49692_v8 (stack48)
        %v50489_v9 = vshrl.u32 %v50479_v9, 8 (stack46)
        %v51332_v23 = vadd.s32 %v51293_v55, %v121569_v1 (stack40)
        %120849 = vlog2.f32 %v49288_v27 (stack58)
        %v49294_v7 = vand.u32 2147483647, %v49286_v61 (stack60)
        %v49696_v8 = vadd.s32 %v49692_v8, %v121564_v0 (stack40)
        %v50085_v44 = vadd.s32 %v50081_v11, %v50069_v26 (stack40)
        %v48901_v53 = vadd.f32 %v48897_v50, %v48822_v53 (stack53)
        %v49704_v46 = vadd.s32 %v49701_v25, %v121574_v2 (stack40)
        %v50087_v32 = vshll.u32 %v50081_v11, 17 (stack45)
        %v50088_v60 = vshrl.u32 %v50081_v11, 15 (stack46)
        %v49292_v6 = vadd.f32 1.0, %v49291_v43 (stack61)
        %v50486_v26 = vadd.s32 %v50482_v21, %v121564_v0 (stack40)
        %v50490_v27 = vor.u32 %v50489_v9, %v50488_v34 (stack47)
        %v50905_v43 = vshll.u32 %v50896_v24, 6 (stack45)
        %v48905_v11 = vmul.f32 %v48901_v53, %v136685_v42 (stack54)
        %v49708_v34 = vadd.s32 5, %v49704_v46 (stack40)
        %v50089_v50 = vor.u32 %v50088_v60, %v50087_v32 (stack47)
        %v50906_v24 = vshrl.u32 %v50896_v24, 26 (stack46)
        %v50491_v21 = vxor.u32 %v50490_v27, %v50482_v21 (stack48)
        %v51319_v25 = vadd.s32 1, %v51315_v41 (stack40)
        %v51338_v9 = vshll.u32 %v51332_v23, 13 (stack45)
        %v51339_v53 = vshrl.u32 %v51332_v23, 19 (stack46)
        %v48909_v52 = vadd.f32 %v48905_v11, %v48818_v52 (stack53)
        %v49710_v8 = vxor.u32 %v49708_v34, %v49696_v8 (stack48)
        %v50090_v46 = vxor.u32 %v50089_v50, %v50085_v44 (stack48)
        %v50907_v32 = vor.u32 %v50906_v24, %v50905_v43 (stack47)
        %v49293_v61 = vmul.f32 %v49292_v6, %v49286_v61 (stack63)
        %v50494_v60 = vadd.s32 %v50491_v21, %v121574_v2 (stack40)
        %v51323_v30 = vsel /*vm=*/%vm51297_vm2, /*on_true_vy=*/%v51319_v25, /*on_false_vx=*/%v51315_v41 (stack44)
        %v136729_v55 = vadd.s32 %v157365_v40, %v157091_v37 (stack40)
        %v48913_v41 = vmul.f32 %v48909_v52, %v136685_v42 (stack54)
        %vm136732_vm3 = vcmp.lt.f32.partialorder %v49294_v7, 0.0004427343 (stack62)
        %v49711_v6 = vand.u32.u8 255, %v49710_v8 (stack49)
        %v50093_v44 = vadd.s32 %v50090_v46, %v50085_v44 (stack40)
        %v50095_v27 = vshll.u32 %v50090_v46, 29 (stack45)
        %v50096_v43 = vshrl.u32 %v50090_v46, 3 (stack46)
        %v50498_v11 = vadd.s32 2, %v50494_v60 (stack40)
        %v50908_v34 = vxor.u32 %v50907_v32, %v136701_v20 (stack48)
        %v51328_v50 = vadd.s32 %v51323_v30, %v121574_v2 (stack40)
        %v48917_v56 = vadd.f32 %v48913_v41, %v136625_v56 (stack53)
        %v49712_v24 = vand.u32 65535, %v49711_v6 (stack50)
        %v51340_v21 = vor.u32 %v51339_v53, %v51338_v9 (stack47)
        %vm51763_vm4 = vcmp.lt.u32.totalorder %v136729_v55, %v157091_v37 (stack43)
        %v50097_v25 = vor.u32 %v50096_v43, %v50095_v27 (stack47)
        %v50502_v26 = vadd.s32 %v50498_v11, %v50486_v26 (stack40)
        %v50504_v9 = vshll.u32 %v50498_v11, 13 (stack45)
        %v50505_v53 = vshrl.u32 %v50498_v11, 19 (stack46)
        %v48921_v42 = vmul.f32 %v48917_v56, %v136685_v42 (stack54)
        %v49713_v52 = vshrl.u32 %v49712_v24, 1 (stack51)
        %v50911_v8 = vadd.s32 %v50908_v34, %v121564_v0 (stack40)
        %v51336_v23 = vadd.s32 %v51332_v23, %v51328_v50 (stack40)
        %v50098_v46 = vxor.u32 %v50097_v25, %v50093_v44 (stack48)
        %v50506_v32 = vor.u32 %v50505_v53, %v50504_v9 (stack47)
        %v50903_v20 = vadd.s32 %v136701_v20, %v121569_v1 (stack40)
        %v136747_v60 = vadd.s32 %v157366_v12, %v157094_v36 (stack40)
        %v120850_v30 = vpop.eup %120849 (stack64)
        %v48925_v31 = vadd.f32 %v48921_v42, %v136620_v31 (stack53)
        %v49714_v41 = vor.u32 16256, %v49713_v52 (stack47)
        %v50915_v6 = vadd.s32 1, %v50911_v8 (stack40)
        %v51341_v27 = vxor.u32 %v51340_v21, %v51336_v23 (stack48)
        %v49290_v43 = vmul.f32 0.6931472, %v120850_v30 (stack65)
        %v50101_v44 = vadd.s32 %v50098_v46, %v50093_v44 (stack40)
        %v50103_v11 = vshll.u32 %v50098_v46, 16 (stack45)
        %v50104_v34 = vshrl.u32 %v50098_v46, 16 (stack46)
        %v48929_v50 = vmul.f32 %v48925_v31, %v136532_v54 (stack54)
        %v49715_v56 = vand.u32.u16 65535, %v49714_v41 (stack52)
        %v50507_v24 = vxor.u32 %v50506_v32, %v50502_v26 (stack48)
        %v50919_v21 = vadd.s32 %v50915_v6, %v50903_v20 (stack40)
        %vm48781_vm5 = vcmp.eq.f32.partialorder %v48778_v22, 1.0 (stack68)
        %v49296_v54 = vsel /*vm=*/%vm136732_vm3, /*on_true_vy=*/%v49293_v61, /*on_false_vx=*/%v49290_v43 (stack66)
        %v50105_v22 = vor.u32 %v50104_v34, %v50103_v11 (stack47)
        %v48933_v10 = vsel /*vm=*/%vm48781_vm5, /*on_true_vy=*/%v136607_v10, /*on_false_vx=*/%v48929_v50 (stack44)
        %v136756_v61 = vxor.u32 2147483648, %v49296_v54 (stack56)
        %v50510_v7 = vadd.s32 %v50507_v24, %v50502_v26 (stack40)
        %v48937_v25 = vmul.f32 1.4140625, %v48933_v10 (stack54)
        %v50106_v26 = vxor.u32 %v50105_v22, %v50101_v44 (stack48)
        %v50512_v9 = vshll.u32 %v50507_v24, 15 (stack45)
        %v50513_v53 = vshrl.u32 %v50507_v24, 17 (stack46)
        %vm49300_vm6 = vcmp.lt.f32.partialorder %v136756_v61, 5.0 (stack68)
        %120851 = vrsqrt.f32 %v136756_v61 (stack67)
        %v120010_v42 = vadd.low.f32.bf16 -1.0, %v49715_v56 (stack53)
        %v48940_v52 = vpack.c.bf16 %v156663_v45, %v48937_v25 (stack81)
        %v50921_v8 = vshll.u32 %v50915_v6, 17 (stack45)
        %v50922_v46 = vshrl.u32 %v50915_v6, 15 (stack46)
        %v49273_v32 = vand.u32 2147483647, %v136692_v29 (stack77)
        %v50109_v20 = vadd.s32 %v50106_v26, %v50101_v44 (stack40)
        %120003 = vst [vmem:[%s123356_s30 + $0x3b0] sm:$0xf] /*vst_source=*/%v48940_v52 (stack83)
        %v136764_v30 = vmul.f32 inf, %v136692_v29 (stack54)
        %v136769_v31 = vsel /*vm=*/%vm49300_vm6, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v50514_v41 = vor.u32 %v50513_v53, %v50512_v9 (stack47)
        %v136773_v6 = vadd.s32 %v136729_v55, %v122657_v58 (stack40)
        %v136778_v43 = vsel /*vm=*/%vm49300_vm6, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v136783_v44 = vsel /*vm=*/%vm49300_vm6, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v136786_v11 = vadd.f32 -2.5, %v136756_v61 (stack53)
        %v49724_v34 = vmul.f32 2.0, %v120010_v42 (stack54)
        %v50115_v50 = vshll.u32 %v50106_v26, 24 (stack45)
        %v50116_v56 = vshrl.u32 %v50106_v26, 8 (stack46)
        %v50515_v24 = vxor.u32 %v50514_v41, %v50510_v7 (stack48)
        %v50923_v54 = vor.u32 %v50922_v46, %v50921_v8 (stack47)
        %v49728_v22 = vadd.f32 -0.99609375, %v49724_v34 (stack53)
        %v51344_v23 = vadd.s32 %v51341_v27, %v51336_v23 (stack40)
        %v51346_v10 = vshll.u32 %v51341_v27, 15 (stack45)
        %v51347_v27 = vshrl.u32 %v51341_v27, 17 (stack46)
        %vm49345_vm7 = vcmp.eq.f32.partialorder %v136756_v61, inf (stack70)
        %v50117_v25 = vor.u32 %v50116_v56, %v50115_v50 (stack47)
        %v50518_v7 = vadd.s32 %v50515_v24, %v50510_v7 (stack40)
        %v50520_v26 = vshll.u32 %v50515_v24, 26 (stack45)
        %v50521_v9 = vshrl.u32 %v50515_v24, 6 (stack46)
        %v136792_v53 = vsel /*vm=*/%vm49300_vm6, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v136794_v42 = vmax.f32 %v49728_v22, -0.99609375 (stack55)
        %v50924_v52 = vxor.u32 %v50923_v54, %v50919_v21 (stack48)
        %v51348_v8 = vor.u32 %v51347_v27, %v51346_v10 (stack47)
        %v136799_v46 = vsel /*vm=*/%vm49300_vm6, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v50118_v41 = vxor.u32 %v50117_v25, %v50109_v20 (stack48)
        %v50522_v34 = vor.u32 %v50521_v9, %v50520_v26 (stack47)
        %v136803_v40 = vadd.s32 %v157365_v40, %v157095_v13 (stack40)
        %v136808_v50 = vsel /*vm=*/%vm49300_vm6, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v49744_v56 = vxor.u32 2147483648, %v136794_v42 (stack56)
        %v50927_v21 = vadd.s32 %v50924_v52, %v50919_v21 (stack40)
        %v51772_v24 = vadd.s32 1, %v136747_v60 (stack40)
        %v50113_v20 = vadd.s32 %v50109_v20, %v121569_v1 (stack40)
        %v50121_v54 = vadd.s32 %v50118_v41, %v121564_v0 (stack40)
        %v50523_v22 = vxor.u32 %v50522_v34, %v50518_v7 (stack48)
        %v50929_v10 = vshll.u32 %v50924_v52, 29 (stack45)
        %v49747_v27 = vmul.f32 %v49744_v56, %v136794_v42 (stack54)
        %v50930_v25 = vshrl.u32 %v50924_v52, 3 (stack46)
        %v51349_v26 = vxor.u32 %v51348_v8, %v51344_v23 (stack48)
        %vm51758_vm8 = vcmp.lt.u32.totalorder %v136773_v6, %v136729_v55 (stack43)
        %v51776_v60 = vsel /*vm=*/%vm51763_vm4, /*on_true_vy=*/%v51772_v24, /*on_false_vx=*/%v136747_v60 (stack44)
        %v120852_v9 = vpop.eup %120851 (stack73)
        %v50125_v52 = vadd.s32 4, %v50121_v54 (stack40)
        %v50526_v7 = vadd.s32 %v50523_v22, %v50518_v7 (stack40)
        %v50532_v8 = vshll.u32 %v50523_v22, 6 (stack45)
        %v50533_v41 = vshrl.u32 %v50523_v22, 26 (stack46)
        %v49333_v34 = vsel /*vm=*/%vm49300_vm6, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v49337_v56 = vsel /*vm=*/%vm49300_vm6, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v49344_v24 = vmul.f32 %v120852_v9, %v136756_v61 (stack74)
        %v49749_v54 = vadd.f32 1.0, %v49747_v27 (stack57)
        %v49348_v22 = vand.u32 2147483648, %v136756_v61 (stack72)
        %v50129_v20 = vadd.s32 %v50125_v52, %v50113_v20 (stack40)
        %v50131_v9 = vshll.u32 %v50125_v52, 13 (stack45)
        %v50132_v52 = vshrl.u32 %v50125_v52, 19 (stack46)
        %v49346_v24 = vsel /*vm=*/%vm49345_vm7, /*on_true_vy=*/%v136756_v61, /*on_false_vx=*/%v49344_v24 (stack75)
        %vm49347_vm9 = vcmp.eq.f32.partialorder %v136756_v61, 0.0 (stack71)
        %120853 = vlog2.f32 %v49749_v54 (stack58)
        %v49752_v54 = vmul.f32 -0.5, %v49747_v27 (stack59)
        %v49349_v22 = vsel /*vm=*/%vm49347_vm9, /*on_true_vy=*/%v49348_v22, /*on_false_vx=*/%v49346_v24 (stack76)
        %v50133_v9 = vor.u32 %v50132_v52, %v50131_v9 (stack47)
        %v50534_v8 = vor.u32 %v50533_v41, %v50532_v8 (stack47)
        %v50931_v10 = vor.u32 %v50930_v25, %v50929_v10 (stack47)
        %v49352_v25 = vadd.f32 -3.0, %v49349_v22 (stack53)
        %v51352_v23 = vadd.s32 %v51349_v26, %v51344_v23 (stack40)
        %v51354_v41 = vshll.u32 %v51349_v26, 26 (stack45)
        %v136835_v52 = vadd.s32 %v136773_v6, %v121569_v1 (stack40)
        %v50134_v24 = vxor.u32 %v50133_v9, %v50129_v20 (stack48)
        %v50535_v22 = vxor.u32 %v50534_v8, %v50526_v7 (stack48)
        %v50932_v9 = vxor.u32 %v50931_v10, %v50927_v21 (stack48)
        %v51355_v26 = vshrl.u32 %v51349_v26, 6 (stack46)
        %v136840_v11 = vsel /*vm=*/%vm49300_vm6, /*on_true_vy=*/%v136786_v11, /*on_false_vx=*/%v49352_v25 (stack44)
        %v49753_v54 = vadd.f32 1.0, %v49752_v54 (stack61)
        %v49755_v8 = vand.u32 2147483647, %v49747_v27 (stack60)
        %v51780_v10 = vadd.s32 1, %v51776_v60 (stack40)
        %v49360_v56 = vmul.f32 %v136840_v11, %v49337_v56 (stack54)
        %v50137_v20 = vadd.s32 %v50134_v24, %v50129_v20 (stack40)
        %v50139_v25 = vshll.u32 %v50134_v24, 15 (stack45)
        %v50140_v24 = vshrl.u32 %v50134_v24, 17 (stack46)
        %v50538_v22 = vadd.s32 %v50535_v22, %v121569_v1 (stack40)
        %v50935_v21 = vadd.s32 %v50932_v9, %v50927_v21 (stack40)
        %v50937_v45 = vshll.u32 %v50932_v9, 16 (stack45)
        %v50938_v9 = vshrl.u32 %v50932_v9, 16 (stack46)
        %v49364_v34 = vadd.f32 %v49360_v56, %v49333_v34 (stack53)
        %v50141_v56 = vor.u32 %v50140_v24, %v50139_v25 (stack47)
        %v51356_v41 = vor.u32 %v51355_v26, %v51354_v41 (stack47)
        %v51784_v55 = vsel /*vm=*/%vm51758_vm8, /*on_true_vy=*/%v51780_v10, /*on_false_vx=*/%v51776_v60 (stack44)
        %vm136847_vm10 = vcmp.lt.f32.partialorder %v49755_v8, 0.0004427343 (stack62)
        %v50530_v60 = vadd.s32 %v50526_v7, %v121574_v2 (stack40)
        %v50542_v7 = vadd.s32 3, %v50538_v22 (stack40)
        %v50939_v45 = vor.u32 %v50938_v9, %v50937_v45 (stack47)
        %v49368_v26 = vmul.f32 %v49364_v34, %v136840_v11 (stack54)
        %v49754_v27 = vmul.f32 %v49753_v54, %v49747_v27 (stack63)
        %v50142_v54 = vxor.u32 %v50141_v56, %v50137_v20 (stack48)
        %v51357_v8 = vxor.u32 %v51356_v41, %v51352_v23 (stack48)
        %v50546_v10 = vadd.s32 %v50542_v7, %v50530_v60 (stack40)
        %v50548_v25 = vshll.u32 %v50542_v7, 17 (stack45)
        %v50549_v24 = vshrl.u32 %v50542_v7, 15 (stack46)
        %v50940_v22 = vxor.u32 %v50939_v45, %v50935_v21 (stack48)
        %v49372_v50 = vadd.f32 %v49368_v26, %v136808_v50 (stack53)
        %v50145_v20 = vadd.s32 %v50142_v54, %v50137_v20 (stack40)
        %v50147_v9 = vshll.u32 %v50142_v54, 26 (stack45)
        %v50148_v34 = vshrl.u32 %v50142_v54, 6 (stack46)
        %v50550_v56 = vor.u32 %v50549_v24, %v50548_v25 (stack47)
        %v50943_v21 = vadd.s32 %v50940_v22, %v50935_v21 (stack40)
        %v50949_v41 = vshll.u32 %v50940_v22, 24 (stack45)
        %v50950_v60 = vshrl.u32 %v50940_v22, 8 (stack46)
        %v120854_v7 = vpop.eup %120853 (stack64)
        %v49376_v45 = vmul.f32 %v49372_v50, %v136840_v11 (stack54)
        %v50149_v26 = vor.u32 %v50148_v34, %v50147_v9 (stack47)
        %v51360_v23 = vadd.s32 %v51357_v8, %v51352_v23 (stack40)
        %v51799_v54 = vshll.u32 %v136835_v52, 13 (stack45)
        %v49751_v25 = vmul.f32 0.6931472, %v120854_v7 (stack65)
        %v50551_v24 = vxor.u32 %v50550_v56, %v50546_v10 (stack48)
        %v50951_v22 = vor.u32 %v50950_v60, %v50949_v41 (stack47)
        %v51800_v50 = vshrl.u32 %v136835_v52, 19 (stack46)
        %v49380_v46 = vadd.f32 %v49376_v45, %v136799_v46 (stack53)
        %v50150_v9 = vxor.u32 %v50149_v26, %v50145_v20 (stack48)
        %v51366_v34 = vshll.u32 %v51357_v8, 6 (stack45)
        %v51367_v8 = vshrl.u32 %v51357_v8, 26 (stack46)
        %v49757_v6 = vsel /*vm=*/%vm136847_vm10, /*on_true_vy=*/%v49754_v27, /*on_false_vx=*/%v49751_v25 (stack66)
        %v50554_v27 = vadd.s32 %v50551_v24, %v50546_v10 (stack40)
        %v50556_v10 = vshll.u32 %v50551_v24, 29 (stack45)
        %v50557_v56 = vshrl.u32 %v50551_v24, 3 (stack46)
        %v49321_v61 = vsel /*vm=*/%vm49300_vm6, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v49384_v41 = vmul.f32 %v49380_v46, %v136840_v11 (stack54)
        %v136864_v60 = vxor.u32 2147483648, %v49757_v6 (stack56)
        %v50153_v20 = vadd.s32 %v50150_v9, %v50145_v20 (stack40)
        %v49734_v7 = vand.u32 2147483647, %v136794_v42 (stack77)
        %v50159_v45 = vshll.u32 %v50150_v9, 6 (stack45)
        %v50160_v26 = vshrl.u32 %v50150_v9, 26 (stack46)
        %v50952_v25 = vxor.u32 %v50951_v22, %v50943_v21 (stack48)
        %v49388_v24 = vadd.f32 %v49384_v41, %v49321_v61 (stack53)
        %vm49761_vm11 = vcmp.lt.f32.partialorder %v136864_v60, 5.0 (stack68)
        %120855 = vrsqrt.f32 %v136864_v60 (stack67)
        %v51789_v55 = vadd.s32 %v51784_v55, %v121574_v2 (stack40)
        %v50558_v22 = vor.u32 %v50557_v56, %v50556_v10 (stack47)
        %v51368_v46 = vor.u32 %v51367_v8, %v51366_v34 (stack47)
        %v51801_v54 = vor.u32 %v51800_v50, %v51799_v54 (stack47)
        %v136872_v50 = vadd.s32 %v136803_v40, %v122657_v58 (stack40)
        %v49392_v9 = vmul.f32 %v49388_v24, %v136840_v11 (stack54)
        %v136876_v34 = vadd.f32 -2.5, %v136864_v60 (stack53)
        %v50947_v21 = vadd.s32 %v50943_v21, %v121564_v0 (stack40)
        %v51364_v8 = vadd.s32 %v51360_v23, %v121569_v1 (stack40)
        %v136883_v6 = vsel /*vm=*/%vm49761_vm11, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v136888_v10 = vsel /*vm=*/%vm49761_vm11, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v136893_v56 = vsel /*vm=*/%vm49761_vm11, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v50161_v61 = vor.u32 %v50160_v26, %v50159_v45 (stack47)
        %v49396_v53 = vadd.f32 %v49392_v9, %v136792_v53 (stack53)
        %v136899_v41 = vsel /*vm=*/%vm49761_vm11, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v136904_v45 = vsel /*vm=*/%vm49761_vm11, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v50157_v26 = vadd.s32 %v50153_v20, %v121564_v0 (stack40)
        %v50162_v20 = vxor.u32 %v50161_v61, %v50153_v20 (stack48)
        %v50559_v24 = vxor.u32 %v50558_v22, %v50554_v27 (stack48)
        %v50955_v25 = vadd.s32 %v50952_v25, %v121574_v2 (stack40)
        %v51369_v23 = vxor.u32 %v51368_v46, %v51360_v23 (stack48)
        %v49400_v22 = vmul.f32 %v49396_v53, %v136840_v11 (stack54)
        %v136912_v46 = vsel /*vm=*/%vm49761_vm11, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v51797_v52 = vadd.s32 %v136835_v52, %v51789_v55 (stack40)
        %vm52224_vm12 = vcmp.lt.u32.totalorder %v136803_v40, %v157095_v13 (stack43)
        %vm49806_vm13 = vcmp.eq.f32.partialorder %v136864_v60, inf (stack70)
        %v50165_v55 = vadd.s32 %v50162_v20, %v121574_v2 (stack40)
        %v50562_v27 = vadd.s32 %v50559_v24, %v50554_v27 (stack40)
        %v50564_v9 = vshll.u32 %v50559_v24, 16 (stack45)
        %v50565_v61 = vshrl.u32 %v50559_v24, 16 (stack46)
        %v49404_v44 = vadd.f32 %v49400_v22, %v136783_v44 (stack53)
        %v50959_v53 = vadd.s32 2, %v50955_v25 (stack40)
        %v51372_v20 = vadd.s32 %v51369_v23, %v121564_v0 (stack40)
        %v51802_v54 = vxor.u32 %v51801_v54, %v51797_v52 (stack48)
        %vm49808_vm14 = vcmp.eq.f32.partialorder %v136864_v60, 0.0 (stack71)
        %v50169_v24 = vadd.s32 5, %v50165_v55 (stack40)
        %v50566_v25 = vor.u32 %v50565_v61, %v50564_v9 (stack47)
        %v136924_v12 = vadd.s32 %v157366_v12, %v157100_v14 (stack40)
        %v49408_v23 = vmul.f32 %v49404_v44, %v136840_v11 (stack54)
        %v50963_v21 = vadd.s32 %v50959_v53, %v50947_v21 (stack40)
        %v50965_v22 = vshll.u32 %v50959_v53, 13 (stack45)
        %v50966_v55 = vshrl.u32 %v50959_v53, 19 (stack46)
        %vm136929_vm15 = vcmp.eq.f32.partialorder %v49273_v32, 1.0 (stack68)
        %v50171_v26 = vxor.u32 %v50169_v24, %v50157_v26 (stack48)
        %v50567_v9 = vxor.u32 %v50566_v25, %v50562_v27 (stack48)
        %v51376_v61 = vadd.s32 1, %v51372_v20 (stack40)
        %v51805_v52 = vadd.s32 %v51802_v54, %v51797_v52 (stack40)
        %v49412_v43 = vadd.f32 %v49408_v23, %v136778_v43 (stack53)
        %v50967_v44 = vor.u32 %v50966_v55, %v50965_v22 (stack47)
        %v51807_v53 = vshll.u32 %v51802_v54, 15 (stack45)
        %v51808_v20 = vshrl.u32 %v51802_v54, 17 (stack46)
        %v120856_v54 = vpop.eup %120855 (stack73)
        %v50172_v24 = vand.u32.u8 255, %v50171_v26 (stack49)
        %v50570_v27 = vadd.s32 %v50567_v9, %v50562_v27 (stack40)
        %v50576_v25 = vshll.u32 %v50567_v9, 24 (stack45)
        %v50577_v23 = vshrl.u32 %v50567_v9, 8 (stack46)
        %v49416_v11 = vmul.f32 %v49412_v43, %v136840_v11 (stack54)
        %v49805_v22 = vmul.f32 %v120856_v54, %v136864_v60 (stack74)
        %v50968_v55 = vxor.u32 %v50967_v44, %v50963_v21 (stack48)
        %v51380_v8 = vadd.s32 %v51376_v61, %v51364_v8 (stack40)
        %v49809_v26 = vand.u32 2147483648, %v136864_v60 (stack72)
        %v50173_v9 = vand.u32 65535, %v50172_v24 (stack50)
        %v50578_v43 = vor.u32 %v50577_v23, %v50576_v25 (stack47)
        %v51382_v44 = vshll.u32 %v51376_v61, 17 (stack45)
        %v49420_v31 = vadd.f32 %v49416_v11, %v136769_v31 (stack53)
        %v49807_v54 = vsel /*vm=*/%vm49806_vm13, /*on_true_vy=*/%v136864_v60, /*on_false_vx=*/%v49805_v22 (stack75)
        %v50971_v21 = vadd.s32 %v50968_v55, %v50963_v21 (stack40)
        %v50973_v24 = vshll.u32 %v50968_v55, 15 (stack45)
        %v49810_v25 = vsel /*vm=*/%vm49808_vm14, /*on_true_vy=*/%v49809_v26, /*on_false_vx=*/%v49807_v54 (stack76)
        %v50174_v23 = vshrl.u32 %v50173_v9, 1 (stack51)
        %v50579_v11 = vxor.u32 %v50578_v43, %v50570_v27 (stack48)
        %v50974_v22 = vshrl.u32 %v50968_v55, 17 (stack46)
        %v49424_v29 = vmul.f32 %v49420_v31, %v136692_v29 (stack54)
        %v49813_v55 = vadd.f32 -3.0, %v49810_v25 (stack53)
        %v51383_v61 = vshrl.u32 %v51376_v61, 15 (stack46)
        %v51809_v53 = vor.u32 %v51808_v20, %v51807_v53 (stack47)
        %v50175_v20 = vor.u32 16256, %v50174_v23 (stack47)
        %v50574_v27 = vadd.s32 %v50570_v27, %v121569_v1 (stack40)
        %v50582_v26 = vadd.s32 %v50579_v11, %v121564_v0 (stack40)
        %v50975_v9 = vor.u32 %v50974_v22, %v50973_v24 (stack47)
        %v49428_v30 = vsel /*vm=*/%vm136929_vm15, /*on_true_vy=*/%v136764_v30, /*on_false_vx=*/%v49424_v29 (stack44)
        %v136952_v34 = vsel /*vm=*/%vm49761_vm11, /*on_true_vy=*/%v136876_v34, /*on_false_vx=*/%v49813_v55 (stack44)
        %v51384_v32 = vor.u32 %v51383_v61, %v51382_v44 (stack47)
        %v51810_v43 = vxor.u32 %v51809_v53, %v51805_v52 (stack48)
        %v49432_v44 = vmul.f32 1.4140625, %v49428_v30 (stack54)
        %v49821_v46 = vmul.f32 %v136952_v34, %v136912_v46 (stack54)
        %v50176_v31 = vand.u32.u16 65535, %v50175_v20 (stack52)
        %v50586_v54 = vadd.s32 4, %v50582_v26 (stack40)
        %v50976_v24 = vxor.u32 %v50975_v9, %v50971_v21 (stack48)
        %v51385_v25 = vxor.u32 %v51384_v32, %v51380_v8 (stack48)
        %v136956_v52 = vadd.s32 %v51810_v43, %v51805_v52 (stack40)
        %v52233_v23 = vadd.s32 1, %v136924_v12 (stack40)
        %v157387_v11 = vmov 0.0 /* materialized constant */ (stack69)
        %v49435_v22 = vpack.c.bf16 %v157387_v11, %v49432_v44 (stack81)
        %v49825_v45 = vadd.f32 %v49821_v46, %v136904_v45 (stack53)
        %v120012_v29 = vadd.low.f32.bf16 -1.0, %v50176_v31 (stack53)
        %v50590_v55 = vadd.s32 %v50586_v54, %v50574_v27 (stack40)
        %v50592_v61 = vshll.u32 %v50586_v54, 13 (stack45)
        %v50593_v53 = vshrl.u32 %v50586_v54, 19 (stack46)
        %v50979_v21 = vadd.s32 %v50976_v24, %v50971_v21 (stack40)
        %v50981_v20 = vshll.u32 %v50976_v24, 26 (stack45)
        %120009 = vst [vmem:[%s123356_s30 + $0x34] sm:$0xf] /*vst_source=*/%v49435_v22 (stack83)
        %v49829_v27 = vmul.f32 %v49825_v45, %v136952_v34 (stack54)
        %v50185_v26 = vmul.f32 2.0, %v120012_v29 (stack54)
        %v50982_v9 = vshrl.u32 %v50976_v24, 6 (stack46)
        %v51388_v8 = vadd.s32 %v51385_v25, %v51380_v8 (stack40)
        %v49790_v30 = vsel /*vm=*/%vm49761_vm11, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v50594_v32 = vor.u32 %v50593_v53, %v50592_v61 (stack47)
        %v51390_v44 = vshll.u32 %v51385_v25, 29 (stack45)
        %v51391_v46 = vshrl.u32 %v51385_v25, 3 (stack46)
        %v49833_v31 = vadd.f32 %v49829_v27, %v49790_v30 (stack53)
        %v50189_v54 = vadd.f32 -0.99609375, %v50185_v26 (stack53)
        %v50983_v24 = vor.u32 %v50982_v9, %v50981_v20 (stack47)
        %v52237_v12 = vsel /*vm=*/%vm52224_vm12, /*on_true_vy=*/%v52233_v23, /*on_false_vx=*/%v136924_v12 (stack44)
        %v49786_v25 = vsel /*vm=*/%vm49761_vm11, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v50595_v23 = vxor.u32 %v50594_v32, %v50590_v55 (stack48)
        %v51392_v22 = vor.u32 %v51391_v46, %v51390_v44 (stack47)
        %v51815_v45 = vshll.u32 %v51810_v43, 26 (stack45)
        %v49837_v29 = vmul.f32 %v49833_v31, %v136952_v34 (stack54)
        %v136974_v61 = vmax.f32 %v50189_v54, -0.99609375 (stack55)
        %v50984_v53 = vxor.u32 %v50983_v24, %v50979_v21 (stack48)
        %v51816_v43 = vshrl.u32 %v51810_v43, 6 (stack46)
        %v50598_v55 = vadd.s32 %v50595_v23, %v50590_v55 (stack40)
        %v50600_v20 = vshll.u32 %v50595_v23, 15 (stack45)
        %v50601_v27 = vshrl.u32 %v50595_v23, 17 (stack46)
        %v51393_v26 = vxor.u32 %v51392_v22, %v51388_v8 (stack48)
        %v49782_v60 = vsel /*vm=*/%vm49761_vm11, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v49841_v9 = vadd.f32 %v49837_v29, %v49786_v25 (stack53)
        %v50205_v30 = vxor.u32 2147483648, %v136974_v61 (stack56)
        %v136982_v32 = vadd.s32 %v136872_v50, %v121569_v1 (stack40)
        %v50602_v44 = vor.u32 %v50601_v27, %v50600_v20 (stack47)
        %v50987_v21 = vadd.s32 %v50984_v53, %v50979_v21 (stack40)
        %v50993_v46 = vshll.u32 %v50984_v53, 6 (stack45)
        %v50994_v31 = vshrl.u32 %v50984_v53, 26 (stack46)
        %v49845_v54 = vmul.f32 %v49841_v9, %v136952_v34 (stack54)
        %v136986_v24 = vmul.f32 %v50205_v30, %v136974_v61 (stack54)
        %v51396_v8 = vadd.s32 %v51393_v26, %v51388_v8 (stack40)
        %vm52219_vm0 = vcmp.lt.u32.totalorder %v136872_v50, %v136803_v40 (stack43)
        %v50603_v25 = vxor.u32 %v50602_v44, %v50598_v55 (stack48)
        %v50995_v23 = vor.u32 %v50994_v31, %v50993_v46 (stack47)
        %v51817_v22 = vor.u32 %v51816_v43, %v51815_v45 (stack47)
        %v52241_v45 = vadd.s32 1, %v52237_v12 (stack40)
        %v49849_v29 = vadd.f32 %v49845_v54, %v49782_v60 (stack53)
        %v50210_v53 = vadd.f32 1.0, %v136986_v24 (stack57)
        %v51398_v43 = vshll.u32 %v51393_v26, 16 (stack45)
        %v52260_v20 = vshll.u32 %v136982_v32, 13 (stack45)
        %v50606_v55 = vadd.s32 %v50603_v25, %v50598_v55 (stack40)
        %v50608_v27 = vshll.u32 %v50603_v25, 26 (stack45)
        %v50609_v60 = vshrl.u32 %v50603_v25, 6 (stack46)
        %v50996_v9 = vxor.u32 %v50995_v23, %v50987_v21 (stack48)
        %v49853_v30 = vmul.f32 %v49849_v29, %v136952_v34 (stack54)
        %120857 = vlog2.f32 %v50210_v53 (stack58)
        %v50213_v44 = vmul.f32 -0.5, %v136986_v24 (stack59)
        %v50991_v21 = vadd.s32 %v50987_v21, %v121574_v2 (stack40)
        %v50610_v46 = vor.u32 %v50609_v60, %v50608_v27 (stack47)
        %v50999_v31 = vadd.s32 %v50996_v9, %v121569_v1 (stack40)
        %v51399_v26 = vshrl.u32 %v51393_v26, 16 (stack46)
        %v51818_v54 = vxor.u32 %v51817_v22, %v136956_v52 (stack48)
        %v49857_v41 = vadd.f32 %v49853_v30, %v136899_v41 (stack53)
        %v50216_v25 = vand.u32 2147483647, %v136986_v24 (stack60)
        %v52245_v40 = vsel /*vm=*/%vm52219_vm0, /*on_true_vy=*/%v52241_v45, /*on_false_vx=*/%v52237_v12 (stack44)
        %v52261_v50 = vshrl.u32 %v136982_v32, 19 (stack46)
        %v50611_v12 = vxor.u32 %v50610_v46, %v50606_v55 (stack48)
        %v51003_v23 = vadd.s32 3, %v50999_v31 (stack40)
        %v51400_v22 = vor.u32 %v51399_v26, %v51398_v43 (stack47)
        %v51821_v52 = vadd.s32 %v51818_v54, %v136956_v52 (stack40)
        %v49861_v45 = vmul.f32 %v49857_v41, %v136952_v34 (stack54)
        %v51827_v29 = vshll.u32 %v51818_v54, 6 (stack45)
        %v51828_v53 = vshrl.u32 %v51818_v54, 26 (stack46)
        %v52250_v43 = vadd.s32 %v52245_v40, %v121574_v2 (stack40)
        %v50614_v55 = vadd.s32 %v50611_v12, %v50606_v55 (stack40)
        %v50620_v27 = vshll.u32 %v50611_v12, 6 (stack45)
        %v50621_v60 = vshrl.u32 %v50611_v12, 26 (stack46)
        %v51007_v9 = vadd.s32 %v51003_v23, %v50991_v21 (stack40)
        %v49865_v56 = vadd.f32 %v49861_v45, %v136893_v56 (stack53)
        %v51009_v30 = vshll.u32 %v51003_v23, 17 (stack45)
        %v51010_v21 = vshrl.u32 %v51003_v23, 15 (stack46)
        %v51401_v46 = vxor.u32 %v51400_v22, %v51396_v8 (stack48)
        %v50214_v44 = vadd.f32 1.0, %v50213_v44 (stack61)
        %v50618_v31 = vadd.s32 %v50614_v55, %v121564_v0 (stack40)
        %v50622_v26 = vor.u32 %v50621_v60, %v50620_v27 (stack47)
        %v51829_v54 = vor.u32 %v51828_v53, %v51827_v29 (stack47)
        %v49869_v41 = vmul.f32 %v49865_v56, %v136952_v34 (stack54)
        %v51011_v40 = vor.u32 %v51010_v21, %v51009_v30 (stack47)
        %v51404_v8 = vadd.s32 %v51401_v46, %v51396_v8 (stack40)
        %v51410_v12 = vshll.u32 %v51401_v46, 24 (stack45)
        %v50623_v23 = vxor.u32 %v50622_v26, %v50614_v55 (stack48)
        %v51411_v22 = vshrl.u32 %v51401_v46, 8 (stack46)
        %v51830_v45 = vxor.u32 %v51829_v54, %v51821_v52 (stack48)
        %v52258_v32 = vadd.s32 %v136982_v32, %v52250_v43 (stack40)
        %v49873_v10 = vadd.f32 %v49869_v41, %v136888_v10 (stack53)
        %v51012_v29 = vxor.u32 %v51011_v40, %v51007_v9 (stack48)
        %v51825_v52 = vadd.s32 %v51821_v52, %v121569_v1 (stack40)
        %v52262_v20 = vor.u32 %v52261_v50, %v52260_v20 (stack47)
        %v50626_v50 = vadd.s32 %v50623_v23, %v121574_v2 (stack40)
        %v51412_v53 = vor.u32 %v51411_v22, %v51410_v12 (stack47)
        %v51833_v43 = vadd.s32 %v51830_v45, %v121564_v0 (stack40)
        %v157388_v55 = vld [vmem:[#allocation138_spill] sm:$0xff] (stack84)
        %v137016_v27 = vadd.s32 %v157388_v55, %v122651_v47 (stack40)
        %v49877_v34 = vmul.f32 %v49873_v10, %v136952_v34 (stack54)
        %v51015_v60 = vadd.s32 %v51012_v29, %v51007_v9 (stack40)
        %v51017_v9 = vshll.u32 %v51012_v29, 29 (stack45)
        %v51018_v56 = vshrl.u32 %v51012_v29, 3 (stack46)
        %v120858_v30 = vpop.eup %120857 (stack64)
        %v50630_v21 = vadd.s32 5, %v50626_v50 (stack40)
        %v51413_v46 = vxor.u32 %v51412_v53, %v51404_v8 (stack48)
        %v51837_v26 = vadd.s32 1, %v51833_v43 (stack40)
        %v52263_v54 = vxor.u32 %v52262_v20, %v52258_v32 (stack48)
        %v49881_v6 = vadd.f32 %v49877_v34, %v136883_v6 (stack53)
        %v50212_v41 = vmul.f32 0.6931472, %v120858_v30 (stack65)
        %v50215_v24 = vmul.f32 %v50214_v44, %v136986_v24 (stack63)
        %v51019_v44 = vor.u32 %v51018_v56, %v51017_v9 (stack47)
        %v49742_v40 = vmul.f32 inf, %v136794_v42 (stack54)
        %vm50217_vm1 = vcmp.lt.f32.partialorder %v50216_v25, 0.0004427343 (stack62)
        %v50632_v25 = vxor.u32 %v50630_v21, %v50618_v31 (stack48)
        %v51841_v31 = vadd.s32 %v51837_v26, %v51825_v52 (stack40)
        %v49885_v12 = vmul.f32 %v49881_v6, %v136794_v42 (stack54)
        %v50218_v23 = vsel /*vm=*/%vm50217_vm1, /*on_true_vy=*/%v50215_v24, /*on_false_vx=*/%v50212_v41 (stack66)
        %v51020_v22 = vxor.u32 %v51019_v44, %v51015_v60 (stack48)
        %v51416_v45 = vadd.s32 %v51413_v46, %v121574_v2 (stack40)
        %vm49737_vm2 = vcmp.eq.f32.partialorder %v49734_v7, 1.0 (stack68)
        %v137026_v42 = vxor.u32 2147483648, %v50218_v23 (stack56)
        %v52266_v7 = vadd.s32 %v52263_v54, %v52258_v32 (stack40)
        %v49889_v32 = vsel /*vm=*/%vm49737_vm2, /*on_true_vy=*/%v49742_v40, /*on_false_vx=*/%v49885_v12 (stack44)
        %v51023_v10 = vadd.s32 %v51020_v22, %v51015_v60 (stack40)
        %v51025_v29 = vshll.u32 %v51020_v22, 16 (stack45)
        %v51026_v52 = vshrl.u32 %v51020_v22, 16 (stack46)
        %v49893_v20 = vmul.f32 1.4140625, %v49889_v32 (stack54)
        %vm50222_vm3 = vcmp.lt.f32.partialorder %v137026_v42, 5.0 (stack68)
        %120859 = vrsqrt.f32 %v137026_v42 (stack67)
        %v50633_v50 = vand.u32.u8 255, %v50632_v25 (stack49)
        %v51027_v53 = vor.u32 %v51026_v52, %v51025_v29 (stack47)
        %v51420_v43 = vadd.s32 2, %v51416_v45 (stack40)
        %v49896_v34 = vpack.c.bf16 %v157387_v11, %v49893_v20 (stack81)
        %v51843_v60 = vshll.u32 %v51837_v26, 17 (stack45)
        %v51844_v9 = vshrl.u32 %v51837_v26, 15 (stack46)
        %v137034_v56 = vsel /*vm=*/%vm50222_vm3, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v51028_v30 = vxor.u32 %v51027_v53, %v51023_v10 (stack48)
        %v51408_v8 = vadd.s32 %v51404_v8, %v121564_v0 (stack40)
        %v137039_v21 = vadd.s32 %v137016_v27, %v122657_v58 (stack40)
        %120011 = vst [vmem:[%s123356_s30 + $0xb4] sm:$0xf] /*vst_source=*/%v49896_v34 (stack83)
        %v137045_v46 = vsel /*vm=*/%vm50222_vm3, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v137050_v26 = vsel /*vm=*/%vm50222_vm3, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v137053_v6 = vadd.f32 -2.5, %v137026_v42 (stack53)
        %v50634_v41 = vand.u32 65535, %v50633_v50 (stack50)
        %v51031_v24 = vadd.s32 %v51028_v30, %v51023_v10 (stack40)
        %v51037_v44 = vshll.u32 %v51028_v30, 24 (stack45)
        %v51038_v40 = vshrl.u32 %v51028_v30, 8 (stack46)
        %v51424_v25 = vadd.s32 %v51420_v43, %v51408_v8 (stack40)
        %v50635_v12 = vshrl.u32 %v50634_v41, 1 (stack51)
        %v51426_v23 = vshll.u32 %v51420_v43, 13 (stack45)
        %v51427_v22 = vshrl.u32 %v51420_v43, 19 (stack46)
        %v51845_v45 = vor.u32 %v51844_v9, %v51843_v60 (stack47)
        %vm50267_vm4 = vcmp.eq.f32.partialorder %v137026_v42, inf (stack70)
        %v51039_v32 = vor.u32 %v51038_v40, %v51037_v44 (stack47)
        %v52268_v10 = vshll.u32 %v52263_v54, 15 (stack45)
        %v52269_v54 = vshrl.u32 %v52263_v54, 17 (stack46)
        %vm50269_vm5 = vcmp.eq.f32.partialorder %v137026_v42, 0.0 (stack71)
        %v50270_v29 = vand.u32 2147483648, %v137026_v42 (stack72)
        %v50636_v52 = vor.u32 16256, %v50635_v12 (stack47)
        %v51428_v20 = vor.u32 %v51427_v22, %v51426_v23 (stack47)
        %v51846_v50 = vxor.u32 %v51845_v45, %v51841_v31 (stack48)
        %v51040_v53 = vxor.u32 %v51039_v32, %v51031_v24 (stack48)
        %v52270_v43 = vor.u32 %v52269_v54, %v52268_v10 (stack47)
        %vm52719_vm6 = vcmp.lt.u32.totalorder %v137016_v27, %v122651_v47 (stack43)
        %v157389_v34 = vld [vmem:[#allocation100_spill] sm:$0xff] (stack84)
        %v137062_v60 = vadd.s32 %v157389_v34, %v157068_v28 (stack40)
        %v50637_v9 = vand.u32.u16 65535, %v50636_v52 (stack52)
        %v51429_v30 = vxor.u32 %v51428_v20, %v51424_v25 (stack48)
        %v51849_v31 = vadd.s32 %v51846_v50, %v51841_v31 (stack40)
        %v51851_v8 = vshll.u32 %v51846_v50, 29 (stack45)
        %v51035_v41 = vadd.s32 %v51031_v24, %v121569_v1 (stack40)
        %v51043_v24 = vadd.s32 %v51040_v53, %v121564_v0 (stack40)
        %v51852_v44 = vshrl.u32 %v51846_v50, 3 (stack46)
        %v52271_v40 = vxor.u32 %v52270_v43, %v52266_v7 (stack48)
        %v120014_v12 = vadd.low.f32.bf16 -1.0, %v50637_v9 (stack53)
        %v51432_v25 = vadd.s32 %v51429_v30, %v51424_v25 (stack40)
        %v51434_v23 = vshll.u32 %v51429_v30, 15 (stack45)
        %v51435_v22 = vshrl.u32 %v51429_v30, 17 (stack46)
        %v120860_v45 = vpop.eup %120859 (stack73)
        %v51047_v32 = vadd.s32 4, %v51043_v24 (stack40)
        %v51853_v10 = vor.u32 %v51852_v44, %v51851_v8 (stack47)
        %v52274_v7 = vadd.s32 %v52271_v40, %v52266_v7 (stack40)
        %v52276_v54 = vshll.u32 %v52271_v40, 26 (stack45)
        %v50266_v52 = vmul.f32 %v120860_v45, %v137026_v42 (stack74)
        %v50646_v20 = vmul.f32 2.0, %v120014_v12 (stack54)
        %v51436_v50 = vor.u32 %v51435_v22, %v51434_v23 (stack47)
        %v52277_v53 = vshrl.u32 %v52271_v40, 6 (stack46)
        %v51051_v43 = vadd.s32 %v51047_v32, %v51035_v41 (stack40)
        %v51053_v9 = vshll.u32 %v51047_v32, 13 (stack45)
        %v51054_v30 = vshrl.u32 %v51047_v32, 19 (stack46)
        %v51854_v8 = vxor.u32 %v51853_v10, %v51849_v31 (stack48)
        %v50268_v41 = vsel /*vm=*/%vm50267_vm4, /*on_true_vy=*/%v137026_v42, /*on_false_vx=*/%v50266_v52 (stack75)
        %v50650_v24 = vadd.f32 -0.99609375, %v50646_v20 (stack53)
        %v51437_v44 = vxor.u32 %v51436_v50, %v51432_v25 (stack48)
        %v52278_v40 = vor.u32 %v52277_v53, %v52276_v54 (stack47)
        %v50271_v29 = vsel /*vm=*/%vm50269_vm5, /*on_true_vy=*/%v50270_v29, /*on_false_vx=*/%v50268_v41 (stack76)
        %v51055_v12 = vor.u32 %v51054_v30, %v51053_v9 (stack47)
        %v51857_v31 = vadd.s32 %v51854_v8, %v51849_v31 (stack40)
        %v51859_v23 = vshll.u32 %v51854_v8, 16 (stack45)
        %v50274_v22 = vadd.f32 -3.0, %v50271_v29 (stack53)
        %v137072_v45 = vmax.f32 %v50650_v24, -0.99609375 (stack55)
        %v51440_v25 = vadd.s32 %v51437_v44, %v51432_v25 (stack40)
        %v51442_v32 = vshll.u32 %v51437_v44, 26 (stack45)
        %v51056_v10 = vxor.u32 %v51055_v12, %v51051_v43 (stack48)
        %v51443_v54 = vshrl.u32 %v51437_v44, 6 (stack46)
        %v51860_v52 = vshrl.u32 %v51854_v8, 16 (stack46)
        %v52279_v20 = vxor.u32 %v52278_v40, %v52274_v7 (stack48)
        %v50247_v50 = vsel /*vm=*/%vm50222_vm3, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v50259_v53 = vsel /*vm=*/%vm50222_vm3, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v137083_v6 = vsel /*vm=*/%vm50222_vm3, /*on_true_vy=*/%v137053_v6, /*on_false_vx=*/%v50274_v22 (stack44)
        %v50666_v9 = vxor.u32 2147483648, %v137072_v45 (stack56)
        %v50282_v30 = vmul.f32 %v137083_v6, %v50259_v53 (stack54)
        %v51059_v43 = vadd.s32 %v51056_v10, %v51051_v43 (stack40)
        %v51061_v8 = vshll.u32 %v51056_v10, 15 (stack45)
        %v51062_v41 = vshrl.u32 %v51056_v10, 17 (stack46)
        %v50255_v24 = vsel /*vm=*/%vm50222_vm3, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v50669_v44 = vmul.f32 %v50666_v9, %v137072_v45 (stack54)
        %v51444_v40 = vor.u32 %v51443_v54, %v51442_v32 (stack47)
        %v51861_v29 = vor.u32 %v51860_v52, %v51859_v23 (stack47)
        %v50251_v12 = vsel /*vm=*/%vm50222_vm3, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v50286_v23 = vadd.f32 %v50282_v30, %v50255_v24 (stack53)
        %v51063_v22 = vor.u32 %v51062_v41, %v51061_v8 (stack47)
        %v52282_v7 = vadd.s32 %v52279_v20, %v52274_v7 (stack40)
        %v50671_v32 = vadd.f32 1.0, %v50669_v44 (stack57)
        %v50674_v10 = vmul.f32 -0.5, %v50669_v44 (stack59)
        %v51445_v54 = vxor.u32 %v51444_v40, %v51440_v25 (stack48)
        %vm52714_vm7 = vcmp.lt.u32.totalorder %v137039_v21, %v137016_v27 (stack43)
        %v50290_v52 = vmul.f32 %v50286_v23, %v137083_v6 (stack54)
        %v51064_v53 = vxor.u32 %v51063_v22, %v51059_v43 (stack48)
        %v51862_v9 = vxor.u32 %v51861_v29, %v51857_v31 (stack48)
        %v52728_v30 = vadd.s32 1, %v137062_v60 (stack40)
        %120861 = vlog2.f32 %v50671_v32 (stack58)
        %v50675_v8 = vadd.f32 1.0, %v50674_v10 (stack61)
        %v51448_v25 = vadd.s32 %v51445_v54, %v51440_v25 (stack40)
        %v52288_v41 = vshll.u32 %v52279_v20, 6 (stack45)
        %v50294_v24 = vadd.f32 %v50290_v52, %v50251_v12 (stack53)
        %v51067_v43 = vadd.s32 %v51064_v53, %v51059_v43 (stack40)
        %v51069_v40 = vshll.u32 %v51064_v53, 26 (stack45)
        %v51070_v29 = vshrl.u32 %v51064_v53, 6 (stack46)
        %v50677_v12 = vand.u32 2147483647, %v50669_v44 (stack60)
        %v51454_v23 = vshll.u32 %v51445_v54, 6 (stack45)
        %v51455_v22 = vshrl.u32 %v51445_v54, 26 (stack46)
        %v52286_v32 = vadd.s32 %v52282_v7, %v121569_v1 (stack40)
        %v50298_v10 = vmul.f32 %v50294_v24, %v137083_v6 (stack54)
        %v51071_v54 = vor.u32 %v51070_v29, %v51069_v40 (stack47)
        %v51865_v31 = vadd.s32 %v51862_v9, %v51857_v31 (stack40)
        %v51871_v52 = vshll.u32 %v51862_v9, 24 (stack45)
        %v51456_v53 = vor.u32 %v51455_v22, %v51454_v23 (stack47)
        %v51872_v9 = vshrl.u32 %v51862_v9, 8 (stack46)
        %v52289_v20 = vshrl.u32 %v52279_v20, 26 (stack46)
        %v52732_v60 = vsel /*vm=*/%vm52719_vm6, /*on_true_vy=*/%v52728_v30, /*on_false_vx=*/%v137062_v60 (stack44)
        %v50302_v50 = vadd.f32 %v50298_v10, %v50247_v50 (stack53)
        %v50676_v44 = vmul.f32 %v50675_v8, %v50669_v44 (stack63)
        %v51072_v30 = vxor.u32 %v51071_v54, %v51067_v43 (stack48)
        %v52736_v8 = vadd.s32 1, %v52732_v60 (stack40)
        %v51452_v24 = vadd.s32 %v51448_v25, %v121574_v2 (stack40)
        %v51457_v25 = vxor.u32 %v51456_v53, %v51448_v25 (stack48)
        %v51873_v40 = vor.u32 %v51872_v9, %v51871_v52 (stack47)
        %v52290_v41 = vor.u32 %v52289_v20, %v52288_v41 (stack47)
        %v50306_v29 = vmul.f32 %v50302_v50, %v137083_v6 (stack54)
        %vm137106_vm8 = vcmp.lt.f32.partialorder %v50677_v12, 0.0004427343 (stack62)
        %v51075_v43 = vadd.s32 %v51072_v30, %v51067_v43 (stack40)
        %v51081_v23 = vshll.u32 %v51072_v30, 6 (stack45)
        %v51082_v22 = vshrl.u32 %v51072_v30, 26 (stack46)
        %v51460_v10 = vadd.s32 %v51457_v25, %v121569_v1 (stack40)
        %v51874_v54 = vxor.u32 %v51873_v40, %v51865_v31 (stack48)
        %v52291_v7 = vxor.u32 %v52290_v41, %v52282_v7 (stack48)
        %v52740_v27 = vsel /*vm=*/%vm52714_vm7, /*on_true_vy=*/%v52736_v8, /*on_false_vx=*/%v52732_v60 (stack44)
        %v50310_v26 = vadd.f32 %v50306_v29, %v137050_v26 (stack53)
        %v51083_v52 = vor.u32 %v51082_v22, %v51081_v23 (stack47)
        %v52745_v53 = vadd.s32 %v52740_v27, %v121574_v2 (stack40)
        %v52749_v21 = vadd.s32 %v137039_v21, %v121569_v1 (stack40)
        %v51464_v9 = vadd.s32 3, %v51460_v10 (stack40)
        %v51869_v31 = vadd.s32 %v51865_v31, %v121564_v0 (stack40)
        %v51877_v20 = vadd.s32 %v51874_v54, %v121574_v2 (stack40)
        %v52294_v60 = vadd.s32 %v52291_v7, %v121564_v0 (stack40)
        %v50314_v50 = vmul.f32 %v50310_v26, %v137083_v6 (stack54)
        %v51079_v30 = vadd.s32 %v51075_v43, %v121564_v0 (stack40)
        %v51084_v8 = vxor.u32 %v51083_v52, %v51075_v43 (stack48)
        %v137123_v25 = vadd.s32 %v52749_v21, %v52745_v53 (stack40)
        %v51468_v24 = vadd.s32 %v51464_v9, %v51452_v24 (stack40)
        %v51470_v40 = vshll.u32 %v51464_v9, 17 (stack45)
        %v51471_v41 = vshrl.u32 %v51464_v9, 15 (stack46)
        %v51881_v29 = vadd.s32 2, %v51877_v20 (stack40)
        %v120862_v43 = vpop.eup %120861 (stack64)
        %v50318_v46 = vadd.f32 %v50314_v50, %v137045_v46 (stack53)
        %v51087_v23 = vadd.s32 %v51084_v8, %v121574_v2 (stack40)
        %v52298_v22 = vadd.s32 1, %v52294_v60 (stack40)
        %v52755_v10 = vshll.u32 %v52749_v21, 13 (stack45)
        %v50673_v54 = vmul.f32 0.6931472, %v120862_v43 (stack65)
        %v51472_v7 = vor.u32 %v51471_v41, %v51470_v40 (stack47)
        %v51885_v27 = vadd.s32 %v51881_v29, %v51869_v31 (stack40)
        %v52756_v26 = vshrl.u32 %v52749_v21, 19 (stack46)
        %v50322_v52 = vmul.f32 %v50318_v46, %v137083_v6 (stack54)
        %v51091_v53 = vadd.s32 5, %v51087_v23 (stack40)
        %v51887_v21 = vshll.u32 %v51881_v29, 13 (stack45)
        %v52302_v32 = vadd.s32 %v52298_v22, %v52286_v32 (stack40)
        %v50679_v44 = vsel /*vm=*/%vm137106_vm8, /*on_true_vy=*/%v50676_v44, /*on_false_vx=*/%v50673_v54 (stack66)
        %v51473_v12 = vxor.u32 %v51472_v7, %v51468_v24 (stack48)
        %v51888_v9 = vshrl.u32 %v51881_v29, 19 (stack46)
        %v52304_v31 = vshll.u32 %v52298_v22, 17 (stack45)
        %v50326_v56 = vadd.f32 %v50322_v52, %v137034_v56 (stack53)
        %v137131_v20 = vxor.u32 2147483648, %v50679_v44 (stack56)
        %v51093_v60 = vxor.u32 %v51091_v53, %v51079_v30 (stack48)
        %v52305_v50 = vshrl.u32 %v52298_v22, 15 (stack46)
        %v50195_v30 = vand.u32 2147483647, %v136974_v61 (stack77)
        %v51476_v8 = vadd.s32 %v51473_v12, %v51468_v24 (stack40)
        %v51478_v24 = vshll.u32 %v51473_v12, 29 (stack45)
        %v51479_v40 = vshrl.u32 %v51473_v12, 3 (stack46)
        %v50330_v41 = vmul.f32 %v50326_v56, %v137083_v6 (stack54)
        %120863 = vrsqrt.f32 %v137131_v20 (stack67)
        %v50231_v29 = vsel /*vm=*/%vm50222_vm3, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %vm50683_vm9 = vcmp.lt.f32.partialorder %v137131_v20, 5.0 (stack68)
        %v51480_v43 = vor.u32 %v51479_v40, %v51478_v24 (stack47)
        %v50334_v46 = vadd.f32 %v50330_v41, %v50231_v29 (stack53)
        %v51889_v23 = vor.u32 %v51888_v9, %v51887_v21 (stack47)
        %v52306_v22 = vor.u32 %v52305_v50, %v52304_v31 (stack47)
        %v52757_v10 = vor.u32 %v52756_v26, %v52755_v10 (stack47)
        %vm137140_vm10 = vcmp.eq.f32.partialorder %v50195_v30, 1.0 (stack68)
        %v50203_v7 = vmul.f32 inf, %v136974_v61 (stack54)
        %v50227_v42 = vsel /*vm=*/%vm50222_vm3, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v51481_v26 = vxor.u32 %v51480_v43, %v51476_v8 (stack48)
        %v50338_v6 = vmul.f32 %v50334_v46, %v137083_v6 (stack54)
        %v50656_v52 = vand.u32 2147483647, %v137072_v45 (stack77)
        %v137153_v53 = vsel /*vm=*/%vm50683_vm9, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v137156_v21 = vadd.f32 -2.5, %v137131_v20 (stack53)
        %v51094_v44 = vand.u32.u8 255, %v51093_v60 (stack49)
        %v51484_v12 = vadd.s32 %v51481_v26, %v51476_v8 (stack40)
        %v51486_v9 = vshll.u32 %v51481_v26, 16 (stack45)
        %v51487_v31 = vshrl.u32 %v51481_v26, 16 (stack46)
        %v50342_v56 = vadd.f32 %v50338_v6, %v50227_v42 (stack53)
        %v51890_v60 = vxor.u32 %v51889_v23, %v51885_v27 (stack48)
        %v52307_v50 = vxor.u32 %v52306_v22, %v52302_v32 (stack48)
        %v52758_v30 = vxor.u32 %v52757_v10, %v137123_v25 (stack48)
        %vm50728_vm11 = vcmp.eq.f32.partialorder %v137131_v20, inf (stack70)
        %v51095_v8 = vand.u32 65535, %v51094_v44 (stack50)
        %v51488_v24 = vor.u32 %v51487_v31, %v51486_v9 (stack47)
        %v137162_v40 = vadd.s32 %v157388_v55, %v157070_v38 (stack40)
        %v137166_v41 = vadd.s32 %v157389_v34, %v157076_v35 (stack40)
        %v50346_v61 = vmul.f32 %v50342_v56, %v136974_v61 (stack54)
        %v51893_v27 = vadd.s32 %v51890_v60, %v51885_v27 (stack40)
        %v51895_v29 = vshll.u32 %v51890_v60, 15 (stack45)
        %v51896_v43 = vshrl.u32 %v51890_v60, 17 (stack46)
        %v51096_v46 = vshrl.u32 %v51095_v8, 1 (stack51)
        %v51489_v23 = vxor.u32 %v51488_v24, %v51484_v12 (stack48)
        %v52310_v32 = vadd.s32 %v52307_v50, %v52302_v32 (stack40)
        %v52312_v22 = vshll.u32 %v52307_v50, 29 (stack45)
        %v50350_v10 = vsel /*vm=*/%vm137140_vm10, /*on_true_vy=*/%v50203_v7, /*on_false_vx=*/%v50346_v61 (stack44)
        %v51897_v54 = vor.u32 %v51896_v43, %v51895_v29 (stack47)
        %v52313_v7 = vshrl.u32 %v52307_v50, 3 (stack46)
        %v52761_v25 = vadd.s32 %v52758_v30, %v137123_v25 (stack40)
        %v50354_v42 = vmul.f32 1.4140625, %v50350_v10 (stack54)
        %v51097_v26 = vor.u32 16256, %v51096_v46 (stack47)
        %v51492_v6 = vadd.s32 %v51489_v23, %v51484_v12 (stack40)
        %v51498_v44 = vshll.u32 %v51489_v23, 24 (stack45)
        %v51499_v12 = vshrl.u32 %v51489_v23, 8 (stack46)
        %v51898_v9 = vxor.u32 %v51897_v54, %v51893_v27 (stack48)
        %v52314_v31 = vor.u32 %v52313_v7, %v52312_v22 (stack47)
        %v52763_v56 = vshll.u32 %v52758_v30, 15 (stack45)
        %v120864_v60 = vpop.eup %120863 (stack73)
        %v50357_v50 = vpack.c.bf16 %v157387_v11, %v50354_v42 (stack81)
        %v50731_v8 = vand.u32 2147483648, %v137131_v20 (stack72)
        %v51098_v24 = vand.u32.u16 65535, %v51097_v26 (stack52)
        %v52764_v30 = vshrl.u32 %v52758_v30, 17 (stack46)
        %v50727_v61 = vmul.f32 %v120864_v60, %v137131_v20 (stack74)
        %v51500_v29 = vor.u32 %v51499_v12, %v51498_v44 (stack47)
        %v51901_v27 = vadd.s32 %v51898_v9, %v51893_v27 (stack40)
        %v51903_v43 = vshll.u32 %v51898_v9, 26 (stack45)
        %120013 = vst [vmem:[%s123356_s30 + $0x134] sm:$0xf] /*vst_source=*/%v50357_v50 (stack83)
        %v120016_v46 = vadd.low.f32.bf16 -1.0, %v51098_v24 (stack53)
        %v51904_v23 = vshrl.u32 %v51898_v9, 6 (stack46)
        %v52315_v22 = vxor.u32 %v52314_v31, %v52310_v32 (stack48)
        %v52765_v10 = vor.u32 %v52764_v30, %v52763_v56 (stack47)
        %v50729_v54 = vsel /*vm=*/%vm50728_vm11, /*on_true_vy=*/%v137131_v20, /*on_false_vx=*/%v50727_v61 (stack75)
        %vm50730_vm12 = vcmp.eq.f32.partialorder %v137131_v20, 0.0 (stack71)
        %v51501_v7 = vxor.u32 %v51500_v29, %v51492_v6 (stack48)
        %vm53180_vm13 = vcmp.lt.u32.totalorder %v137162_v40, %v157070_v38 (stack43)
        %v50732_v42 = vsel /*vm=*/%vm50730_vm12, /*on_true_vy=*/%v50731_v8, /*on_false_vx=*/%v50729_v54 (stack76)
        %v51107_v26 = vmul.f32 2.0, %v120016_v46 (stack54)
        %v51905_v44 = vor.u32 %v51904_v23, %v51903_v43 (stack47)
        %v52318_v32 = vadd.s32 %v52315_v22, %v52310_v32 (stack40)
        %v50735_v12 = vadd.f32 -3.0, %v50732_v42 (stack53)
        %v51504_v9 = vadd.s32 %v51501_v7, %v121564_v0 (stack40)
        %v52320_v31 = vshll.u32 %v52315_v22, 16 (stack45)
        %v52321_v56 = vshrl.u32 %v52315_v22, 16 (stack46)
        %v50720_v60 = vsel /*vm=*/%vm50683_vm9, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v51111_v50 = vadd.f32 -0.99609375, %v51107_v26 (stack53)
        %v51906_v8 = vxor.u32 %v51905_v44, %v51901_v27 (stack48)
        %v52766_v24 = vxor.u32 %v52765_v10, %v52761_v25 (stack48)
        %v137189_v21 = vsel /*vm=*/%vm50683_vm9, /*on_true_vy=*/%v137156_v21, /*on_false_vx=*/%v50735_v12 (stack44)
        %v51496_v6 = vadd.s32 %v51492_v6, %v121569_v1 (stack40)
        %v51508_v30 = vadd.s32 4, %v51504_v9 (stack40)
        %v52322_v61 = vor.u32 %v52321_v56, %v52320_v31 (stack47)
        %v50743_v29 = vmul.f32 %v137189_v21, %v50720_v60 (stack54)
        %v137193_v43 = vmax.f32 %v51111_v50, -0.99609375 (stack55)
        %v51909_v27 = vadd.s32 %v51906_v8, %v51901_v27 (stack40)
        %v51915_v46 = vshll.u32 %v51906_v8, 6 (stack45)
        %v51512_v23 = vadd.s32 %v51508_v30, %v51496_v6 (stack40)
        %v51514_v22 = vshll.u32 %v51508_v30, 13 (stack45)
        %v51515_v10 = vshrl.u32 %v51508_v30, 19 (stack46)
        %v51916_v54 = vshrl.u32 %v51906_v8, 26 (stack46)
        %v137198_v7 = vsel /*vm=*/%vm50683_vm9, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v137203_v42 = vsel /*vm=*/%vm50683_vm9, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v50747_v53 = vadd.f32 %v50743_v29, %v137153_v53 (stack53)
        %v51127_v26 = vxor.u32 2147483648, %v137193_v43 (stack56)
        %v50704_v44 = vsel /*vm=*/%vm50683_vm9, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v51516_v12 = vor.u32 %v51515_v10, %v51514_v22 (stack47)
        %v51917_v9 = vor.u32 %v51916_v54, %v51915_v46 (stack47)
        %v52323_v31 = vxor.u32 %v52322_v61, %v52318_v32 (stack48)
        %v50708_v56 = vsel /*vm=*/%vm50683_vm9, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v50751_v60 = vmul.f32 %v50747_v53, %v137189_v21 (stack54)
        %v137215_v50 = vmul.f32 %v51127_v26, %v137193_v43 (stack54)
        %v52769_v25 = vadd.s32 %v52766_v24, %v52761_v25 (stack40)
        %v50712_v8 = vsel /*vm=*/%vm50683_vm9, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v51517_v6 = vxor.u32 %v51516_v12, %v51512_v23 (stack48)
        %v51918_v30 = vxor.u32 %v51917_v9, %v51909_v27 (stack48)
        %v52326_v32 = vadd.s32 %v52323_v31, %v52318_v32 (stack40)
        %v50755_v61 = vadd.f32 %v50751_v60, %v50712_v8 (stack53)
        %v51132_v29 = vadd.f32 1.0, %v137215_v50 (stack57)
        %v137223_v46 = vadd.s32 %v137162_v40, %v122657_v58 (stack40)
        %v53189_v22 = vadd.s32 1, %v137166_v41 (stack40)
        %v51520_v23 = vadd.s32 %v51517_v6, %v51512_v23 (stack40)
        %v51522_v10 = vshll.u32 %v51517_v6, 15 (stack45)
        %v51523_v54 = vshrl.u32 %v51517_v6, 17 (stack46)
        %v51921_v53 = vadd.s32 %v51918_v30, %v121569_v1 (stack40)
        %v50759_v26 = vmul.f32 %v50755_v61, %v137189_v21 (stack54)
        %120865 = vlog2.f32 %v51132_v29 (stack58)
        %v51913_v27 = vadd.s32 %v51909_v27, %v121574_v2 (stack40)
        %v52332_v12 = vshll.u32 %v52323_v31, 24 (stack45)
        %v51135_v9 = vmul.f32 -0.5, %v137215_v50 (stack59)
        %v51524_v60 = vor.u32 %v51523_v54, %v51522_v10 (stack47)
        %v51925_v8 = vadd.s32 3, %v51921_v53 (stack40)
        %v52333_v31 = vshrl.u32 %v52323_v31, 8 (stack46)
        %v50763_v56 = vadd.f32 %v50759_v26, %v50708_v56 (stack53)
        %v51138_v6 = vand.u32 2147483647, %v137215_v50 (stack60)
        %v52771_v30 = vshll.u32 %v52766_v24, 26 (stack45)
        %v52772_v24 = vshrl.u32 %v52766_v24, 6 (stack46)
        %v51525_v61 = vxor.u32 %v51524_v60, %v51520_v23 (stack48)
        %v51929_v29 = vadd.s32 %v51925_v8, %v51913_v27 (stack40)
        %v51931_v10 = vshll.u32 %v51925_v8, 17 (stack45)
        %v51932_v54 = vshrl.u32 %v51925_v8, 15 (stack46)
        %vm53175_vm14 = vcmp.lt.u32.totalorder %v137223_v46, %v137162_v40 (stack43)
        %v50767_v53 = vmul.f32 %v50763_v56, %v137189_v21 (stack54)
        %v52334_v26 = vor.u32 %v52333_v31, %v52332_v12 (stack47)
        %v52773_v27 = vor.u32 %v52772_v24, %v52771_v30 (stack47)
        %v53193_v41 = vsel /*vm=*/%vm53180_vm13, /*on_true_vy=*/%v53189_v22, /*on_false_vx=*/%v137166_v41 (stack44)
        %v51528_v22 = vadd.s32 %v51525_v61, %v51520_v23 (stack40)
        %v51530_v23 = vshll.u32 %v51525_v61, 26 (stack45)
        %v51531_v12 = vshrl.u32 %v51525_v61, 6 (stack46)
        %v51933_v60 = vor.u32 %v51932_v54, %v51931_v10 (stack47)
        %v50771_v44 = vadd.f32 %v50767_v53, %v50704_v44 (stack53)
        %v51136_v9 = vadd.f32 1.0, %v51135_v9 (stack61)
        %v52335_v8 = vxor.u32 %v52334_v26, %v52326_v32 (stack48)
        %v52774_v31 = vxor.u32 %v52773_v27, %v52769_v25 (stack48)
        %vm137238_vm15 = vcmp.lt.f32.partialorder %v51138_v6, 0.0004427343 (stack62)
        %v51532_v6 = vor.u32 %v51531_v12, %v51530_v23 (stack47)
        %v51934_v30 = vxor.u32 %v51933_v60, %v51929_v29 (stack48)
        %v52330_v32 = vadd.s32 %v52326_v32, %v121564_v0 (stack40)
        %v137245_v24 = vadd.s32 %v157388_v55, %v157077_v51 (stack40)
        %v50775_v61 = vmul.f32 %v50771_v44, %v137189_v21 (stack54)
        %v52338_v10 = vadd.s32 %v52335_v8, %v121574_v2 (stack40)
        %v137249_v25 = vadd.s32 %v52774_v31, %v52769_v25 (stack40)
        %v52783_v54 = vshll.u32 %v52774_v31, 6 (stack45)
        %v51533_v53 = vxor.u32 %v51532_v6, %v51528_v22 (stack48)
        %v51937_v29 = vadd.s32 %v51934_v30, %v51929_v29 (stack40)
        %v51939_v26 = vshll.u32 %v51934_v30, 29 (stack45)
        %v51940_v27 = vshrl.u32 %v51934_v30, 3 (stack46)
        %v50779_v42 = vadd.f32 %v50775_v61, %v137203_v42 (stack53)
        %v52342_v23 = vadd.s32 2, %v52338_v10 (stack40)
        %v52784_v12 = vshrl.u32 %v52774_v31, 26 (stack46)
        %v53197_v60 = vadd.s32 1, %v53193_v41 (stack40)
        %v51536_v22 = vadd.s32 %v51533_v53, %v51528_v22 (stack40)
        %v51542_v44 = vshll.u32 %v51533_v53, 6 (stack45)
        %v51543_v8 = vshrl.u32 %v51533_v53, 26 (stack46)
        %v51941_v31 = vor.u32 %v51940_v27, %v51939_v26 (stack47)
        %v50783_v6 = vmul.f32 %v50779_v42, %v137189_v21 (stack54)
        %v52346_v30 = vadd.s32 %v52342_v23, %v52330_v32 (stack40)
        %v52348_v32 = vshll.u32 %v52342_v23, 13 (stack45)
        %v52349_v61 = vshrl.u32 %v52342_v23, 19 (stack46)
        %v120866_v10 = vpop.eup %120865 (stack64)
        %v51137_v50 = vmul.f32 %v51136_v9, %v137215_v50 (stack63)
        %v51544_v9 = vor.u32 %v51543_v8, %v51542_v44 (stack47)
        %v51942_v53 = vxor.u32 %v51941_v31, %v51937_v29 (stack48)
        %v52785_v54 = vor.u32 %v52784_v12, %v52783_v54 (stack47)
        %v50787_v7 = vadd.f32 %v50783_v6, %v137198_v7 (stack53)
        %v51134_v26 = vmul.f32 0.6931472, %v120866_v10 (stack65)
        %v52350_v27 = vor.u32 %v52349_v61, %v52348_v32 (stack47)
        %v53201_v40 = vsel /*vm=*/%vm53175_vm14, /*on_true_vy=*/%v53197_v60, /*on_false_vx=*/%v53193_v41 (stack44)
        %v51545_v41 = vxor.u32 %v51544_v9, %v51536_v22 (stack48)
        %v51945_v29 = vadd.s32 %v51942_v53, %v51937_v29 (stack40)
        %v51947_v42 = vshll.u32 %v51942_v53, 16 (stack45)
        %v51948_v23 = vshrl.u32 %v51942_v53, 16 (stack46)
        %v50791_v12 = vmul.f32 %v50787_v7, %v137189_v21 (stack54)
        %v51140_v56 = vsel /*vm=*/%vm137238_vm15, /*on_true_vy=*/%v51137_v50, /*on_false_vx=*/%v51134_v26 (stack66)
        %v52351_v60 = vxor.u32 %v52350_v27, %v52346_v30 (stack48)
        %v52786_v44 = vxor.u32 %v52785_v54, %v137249_v25 (stack48)
        %v50692_v8 = vsel /*vm=*/%vm50683_vm9, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v137265_v31 = vxor.u32 2147483648, %v51140_v56 (stack56)
        %v51949_v6 = vor.u32 %v51948_v23, %v51947_v42 (stack47)
        %vm137269_vm0 = vcmp.eq.f32.partialorder %v50656_v52, 1.0 (stack68)
        %v50664_v32 = vmul.f32 inf, %v137072_v45 (stack54)
        %v50795_v61 = vadd.f32 %v50791_v12, %v50692_v8 (stack53)
        %v52354_v30 = vadd.s32 %v52351_v60, %v52346_v30 (stack40)
        %v50688_v20 = vsel /*vm=*/%vm50683_vm9, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %vm51144_vm1 = vcmp.lt.f32.partialorder %v137265_v31, 5.0 (stack68)
        %120867 = vrsqrt.f32 %v137265_v31 (stack67)
        %v51548_v10 = vadd.s32 %v51545_v41, %v121574_v2 (stack40)
        %v50799_v21 = vmul.f32 %v50795_v61, %v137189_v21 (stack54)
        %v52356_v50 = vshll.u32 %v52351_v60, 15 (stack45)
        %v52357_v9 = vshrl.u32 %v52351_v60, 17 (stack46)
        %v53210_v46 = vadd.s32 %v137223_v46, %v121569_v1 (stack40)
        %v51540_v22 = vadd.s32 %v51536_v22, %v121564_v0 (stack40)
        %v51950_v53 = vxor.u32 %v51949_v6, %v51945_v29 (stack48)
        %v52781_v25 = vadd.s32 %v137249_v25, %v121569_v1 (stack40)
        %v53206_v54 = vadd.s32 %v53201_v40, %v121574_v2 (stack40)
        %v50803_v7 = vadd.f32 %v50799_v21, %v50688_v20 (stack53)
        %v137290_v26 = vsel /*vm=*/%vm51144_vm1, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v137295_v27 = vsel /*vm=*/%vm51144_vm1, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v137298_v40 = vadd.f32 -2.5, %v137265_v31 (stack53)
        %v137303_v41 = vsel /*vm=*/%vm51144_vm1, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v137308_v42 = vsel /*vm=*/%vm51144_vm1, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v51552_v23 = vadd.s32 5, %v51548_v10 (stack40)
        %v51953_v29 = vadd.s32 %v51950_v53, %v51945_v29 (stack40)
        %v50807_v45 = vmul.f32 %v50803_v7, %v137072_v45 (stack54)
        %v51959_v12 = vshll.u32 %v51950_v53, 24 (stack45)
        %v51960_v56 = vshrl.u32 %v51950_v53, 8 (stack46)
        %v52358_v60 = vor.u32 %v52357_v9, %v52356_v50 (stack47)
        %v137314_v8 = vsel /*vm=*/%vm51144_vm1, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v51554_v6 = vxor.u32 %v51552_v23, %v51540_v22 (stack48)
        %v52789_v44 = vadd.s32 %v52786_v44, %v121564_v0 (stack40)
        %v53214_v61 = vadd.s32 %v53210_v46, %v53206_v54 (stack40)
        %v50811_v52 = vsel /*vm=*/%vm137269_vm0, /*on_true_vy=*/%v50664_v32, /*on_false_vx=*/%v50807_v45 (stack44)
        %vm51189_vm2 = vcmp.eq.f32.partialorder %v137265_v31, inf (stack70)
        %v51961_v32 = vor.u32 %v51960_v56, %v51959_v12 (stack47)
        %v52359_v20 = vxor.u32 %v52358_v60, %v52354_v30 (stack48)
        %v53216_v10 = vshll.u32 %v53210_v46, 13 (stack45)
        %v50815_v21 = vmul.f32 1.4140625, %v50811_v52 (stack54)
        %v51555_v50 = vand.u32.u8 255, %v51554_v6 (stack49)
        %v52793_v9 = vadd.s32 1, %v52789_v44 (stack40)
        %v53217_v46 = vshrl.u32 %v53210_v46, 19 (stack46)
        %v51962_v22 = vxor.u32 %v51961_v32, %v51953_v29 (stack48)
        %v52362_v30 = vadd.s32 %v52359_v20, %v52354_v30 (stack40)
        %v52364_v53 = vshll.u32 %v52359_v20, 26 (stack45)
        %v52365_v54 = vshrl.u32 %v52359_v20, 6 (stack46)
        %v50818_v7 = vpack.c.bf16 %v157387_v11, %v50815_v21 (stack81)
        %v51556_v23 = vand.u32 65535, %v51555_v50 (stack50)
        %v52797_v25 = vadd.s32 %v52793_v9, %v52781_v25 (stack40)
        %v52799_v45 = vshll.u32 %v52793_v9, 17 (stack45)
        %v51965_v12 = vadd.s32 %v51962_v22, %v121564_v0 (stack40)
        %v52366_v56 = vor.u32 %v52365_v54, %v52364_v53 (stack47)
        %v52800_v60 = vshrl.u32 %v52793_v9, 15 (stack46)
        %v53218_v6 = vor.u32 %v53217_v46, %v53216_v10 (stack47)
        %120015 = vst [vmem:[%s123356_s30 + $0x1b4] sm:$0xf] /*vst_source=*/%v50818_v7 (stack83)
        %v51557_v44 = vshrl.u32 %v51556_v23, 1 (stack51)
        %v51957_v29 = vadd.s32 %v51953_v29, %v121569_v1 (stack40)
        %vm53641_vm3 = vcmp.lt.u32.totalorder %v137245_v24, %v157077_v51 (stack43)
        %v53646_v52 = vadd.s32 %v157389_v34, %v157078_v48 (stack40)
        %v120868_v32 = vpop.eup %120867 (stack73)
        %v51969_v20 = vadd.s32 4, %v51965_v12 (stack40)
        %v52367_v10 = vxor.u32 %v52366_v56, %v52362_v30 (stack48)
        %v52801_v21 = vor.u32 %v52800_v60, %v52799_v45 (stack47)
        %v53219_v50 = vxor.u32 %v53218_v6, %v53214_v61 (stack48)
        %v51188_v9 = vmul.f32 %v120868_v32, %v137265_v31 (stack74)
        %vm51191_vm4 = vcmp.eq.f32.partialorder %v137265_v31, 0.0 (stack71)
        %v51192_v46 = vand.u32 2147483648, %v137265_v31 (stack72)
        %v51558_v22 = vor.u32 16256, %v51557_v44 (stack47)
        %v51973_v53 = vadd.s32 %v51969_v20, %v51957_v29 (stack40)
        %v51975_v54 = vshll.u32 %v51969_v20, 13 (stack45)
        %v51976_v7 = vshrl.u32 %v51969_v20, 19 (stack46)
        %v52370_v30 = vadd.s32 %v52367_v10, %v52362_v30 (stack40)
        %v51190_v23 = vsel /*vm=*/%vm51189_vm2, /*on_true_vy=*/%v137265_v31, /*on_false_vx=*/%v51188_v9 (stack75)
        %v51559_v45 = vand.u32.u16 65535, %v51558_v22 (stack52)
        %v52376_v12 = vshll.u32 %v52367_v10, 6 (stack45)
        %v52377_v56 = vshrl.u32 %v52367_v10, 26 (stack46)
        %v51193_v60 = vsel /*vm=*/%vm51191_vm4, /*on_true_vy=*/%v51192_v46, /*on_false_vx=*/%v51190_v23 (stack76)
        %v51977_v6 = vor.u32 %v51976_v7, %v51975_v54 (stack47)
        %v52802_v44 = vxor.u32 %v52801_v21, %v52797_v25 (stack48)
        %v53650_v29 = vadd.s32 1, %v53646_v52 (stack40)
        %v51196_v32 = vadd.f32 -3.0, %v51193_v60 (stack53)
        %v120018_v20 = vadd.low.f32.bf16 -1.0, %v51559_v45 (stack53)
        %v52378_v10 = vor.u32 %v52377_v56, %v52376_v12 (stack47)
        %v137334_v61 = vadd.s32 %v53219_v50, %v53214_v61 (stack40)
        %v51978_v21 = vxor.u32 %v51977_v6, %v51973_v53 (stack48)
        %v52805_v25 = vadd.s32 %v52802_v44, %v52797_v25 (stack40)
        %v52807_v9 = vshll.u32 %v52802_v44, 29 (stack45)
        %v52808_v46 = vshrl.u32 %v52802_v44, 3 (stack46)
        %v137339_v40 = vsel /*vm=*/%vm51144_vm1, /*on_true_vy=*/%v137298_v40, /*on_false_vx=*/%v51196_v32 (stack44)
        %v51568_v22 = vmul.f32 2.0, %v120018_v20 (stack54)
        %v52379_v54 = vxor.u32 %v52378_v10, %v52370_v30 (stack48)
        %v53224_v7 = vshll.u32 %v53219_v50, 15 (stack45)
        %v51204_v8 = vmul.f32 %v137339_v40, %v137314_v8 (stack54)
        %v51981_v53 = vadd.s32 %v51978_v21, %v51973_v53 (stack40)
        %v51983_v23 = vshll.u32 %v51978_v21, 15 (stack45)
        %v51984_v45 = vshrl.u32 %v51978_v21, 17 (stack46)
        %v51572_v12 = vadd.f32 -0.99609375, %v51568_v22 (stack53)
        %v52382_v56 = vadd.s32 %v52379_v54, %v121569_v1 (stack40)
        %v52809_v60 = vor.u32 %v52808_v46, %v52807_v9 (stack47)
        %v53225_v50 = vshrl.u32 %v53219_v50, 17 (stack46)
        %v51208_v42 = vadd.f32 %v51204_v8, %v137308_v42 (stack53)
        %v51985_v6 = vor.u32 %v51984_v45, %v51983_v23 (stack47)
        %v53632_v44 = vadd.s32 %v137245_v24, %v122657_v58 (stack40)
        %v53654_v52 = vsel /*vm=*/%vm53641_vm3, /*on_true_vy=*/%v53650_v29, /*on_false_vx=*/%v53646_v52 (stack44)
        %v137350_v29 = vmax.f32 %v51572_v12, -0.99609375 (stack55)
        %v52374_v30 = vadd.s32 %v52370_v30, %v121574_v2 (stack40)
        %v52386_v32 = vadd.s32 3, %v52382_v56 (stack40)
        %v52810_v20 = vxor.u32 %v52809_v60, %v52805_v25 (stack48)
        %v51165_v10 = vsel /*vm=*/%vm51144_vm1, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v51169_v21 = vsel /*vm=*/%vm51144_vm1, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v51212_v9 = vmul.f32 %v51208_v42, %v137339_v40 (stack54)
        %v51986_v46 = vxor.u32 %v51985_v6, %v51981_v53 (stack48)
        %v51173_v22 = vsel /*vm=*/%vm51144_vm1, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v51588_v54 = vxor.u32 2147483648, %v137350_v29 (stack56)
        %v52390_v8 = vadd.s32 %v52386_v32, %v52374_v30 (stack40)
        %v53226_v7 = vor.u32 %v53225_v50, %v53224_v7 (stack47)
        %v51216_v23 = vadd.f32 %v51212_v9, %v51173_v22 (stack53)
        %v51989_v53 = vadd.s32 %v51986_v46, %v51981_v53 (stack40)
        %v51991_v45 = vshll.u32 %v51986_v46, 26 (stack45)
        %v51992_v12 = vshrl.u32 %v51986_v46, 6 (stack46)
        %v137365_v56 = vmul.f32 %v51588_v54, %v137350_v29 (stack54)
        %v52392_v60 = vshll.u32 %v52386_v32, 17 (stack45)
        %v52393_v50 = vshrl.u32 %v52386_v32, 15 (stack46)
        %v53671_v42 = vadd.s32 %v53632_v44, %v121569_v1 (stack40)
        %v51220_v6 = vmul.f32 %v51216_v23, %v137339_v40 (stack54)
        %v51993_v30 = vor.u32 %v51992_v12, %v51991_v45 (stack47)
        %v52813_v25 = vadd.s32 %v52810_v20, %v52805_v25 (stack40)
        %vm53636_vm5 = vcmp.lt.u32.totalorder %v53632_v44, %v137245_v24 (stack43)
        %v51593_v32 = vadd.f32 1.0, %v137365_v56 (stack57)
        %v51596_v9 = vmul.f32 -0.5, %v137365_v56 (stack59)
        %v52394_v46 = vor.u32 %v52393_v50, %v52392_v60 (stack47)
        %v52815_v22 = vshll.u32 %v52810_v20, 16 (stack45)
        %v51224_v21 = vadd.f32 %v51220_v6, %v51169_v21 (stack53)
        %v51994_v54 = vxor.u32 %v51993_v30, %v51989_v53 (stack48)
        %v52816_v20 = vshrl.u32 %v52810_v20, 16 (stack46)
        %v53227_v7 = vxor.u32 %v53226_v7, %v137334_v61 (stack48)
        %120869 = vlog2.f32 %v51593_v32 (stack58)
        %v52395_v23 = vxor.u32 %v52394_v46, %v52390_v8 (stack48)
        %v53658_v45 = vadd.s32 1, %v53654_v52 (stack40)
        %v53677_v12 = vshll.u32 %v53671_v42, 13 (stack45)
        %v51228_v60 = vmul.f32 %v51224_v21, %v137339_v40 (stack54)
        %v51997_v53 = vadd.s32 %v51994_v54, %v51989_v53 (stack40)
        %v52003_v50 = vshll.u32 %v51994_v54, 6 (stack45)
        %v52004_v6 = vshrl.u32 %v51994_v54, 26 (stack46)
        %v51599_v30 = vand.u32 2147483647, %v137365_v56 (stack60)
        %v52398_v8 = vadd.s32 %v52395_v23, %v52390_v8 (stack40)
        %v52400_v32 = vshll.u32 %v52395_v23, 29 (stack45)
        %v52401_v46 = vshrl.u32 %v52395_v23, 3 (stack46)
        %v51232_v10 = vadd.f32 %v51228_v60, %v51165_v10 (stack53)
        %v51597_v9 = vadd.f32 1.0, %v51596_v9 (stack61)
        %v52005_v21 = vor.u32 %v52004_v6, %v52003_v50 (stack47)
        %v52817_v22 = vor.u32 %v52816_v20, %v52815_v22 (stack47)
        %v52402_v54 = vor.u32 %v52401_v46, %v52400_v32 (stack47)
        %v53230_v61 = vadd.s32 %v53227_v7, %v137334_v61 (stack40)
        %v53232_v20 = vshll.u32 %v53227_v7, 26 (stack45)
        %v53233_v7 = vshrl.u32 %v53227_v7, 6 (stack46)
        %v51236_v23 = vmul.f32 %v51232_v10, %v137339_v40 (stack54)
        %v52006_v60 = vxor.u32 %v52005_v21, %v51997_v53 (stack48)
        %v52818_v50 = vxor.u32 %v52817_v22, %v52813_v25 (stack48)
        %v53662_v24 = vsel /*vm=*/%vm53636_vm5, /*on_true_vy=*/%v53658_v45, /*on_false_vx=*/%v53654_v52 (stack44)
        %v52403_v44 = vxor.u32 %v52402_v54, %v52398_v8 (stack48)
        %v53234_v52 = vor.u32 %v53233_v7, %v53232_v20 (stack47)
        %v53667_v45 = vadd.s32 %v53662_v24, %v121574_v2 (stack40)
        %v53678_v6 = vshrl.u32 %v53671_v42, 19 (stack46)
        %v51240_v41 = vadd.f32 %v51236_v23, %v137303_v41 (stack53)
        %v52009_v32 = vadd.s32 %v52006_v60, %v121574_v2 (stack40)
        %v52821_v25 = vadd.s32 %v52818_v50, %v52813_v25 (stack40)
        %v52827_v46 = vshll.u32 %v52818_v50, 24 (stack45)
        %v52406_v8 = vadd.s32 %v52403_v44, %v52398_v8 (stack40)
        %v52408_v10 = vshll.u32 %v52403_v44, 16 (stack45)
        %v52409_v21 = vshrl.u32 %v52403_v44, 16 (stack46)
        %v52828_v22 = vshrl.u32 %v52818_v50, 8 (stack46)
        %v51244_v54 = vmul.f32 %v51240_v41, %v137339_v40 (stack54)
        %v52001_v53 = vadd.s32 %v51997_v53, %v121564_v0 (stack40)
        %v52013_v20 = vadd.s32 5, %v52009_v32 (stack40)
        %v53235_v7 = vxor.u32 %v53234_v52, %v53230_v61 (stack48)
        %v52410_v23 = vor.u32 %v52409_v21, %v52408_v10 (stack47)
        %v52829_v60 = vor.u32 %v52828_v22, %v52827_v46 (stack47)
        %v53675_v42 = vadd.s32 %v53671_v42, %v53667_v45 (stack40)
        %v53679_v12 = vor.u32 %v53678_v6, %v53677_v12 (stack47)
        %v51248_v27 = vadd.f32 %v51244_v54, %v137295_v27 (stack53)
        %v52015_v50 = vxor.u32 %v52013_v20, %v52001_v53 (stack48)
        %v53238_v61 = vadd.s32 %v53235_v7, %v53230_v61 (stack40)
        %v53244_v24 = vshll.u32 %v53235_v7, 6 (stack45)
        %v52411_v44 = vxor.u32 %v52410_v23, %v52406_v8 (stack48)
        %v52830_v52 = vxor.u32 %v52829_v60, %v52821_v25 (stack48)
        %v53245_v45 = vshrl.u32 %v53235_v7, 26 (stack46)
        %v53680_v6 = vxor.u32 %v53679_v12, %v53675_v42 (stack48)
        %v120870_v41 = vpop.eup %120869 (stack64)
        %v51252_v32 = vmul.f32 %v51248_v27, %v137339_v40 (stack54)
        %v51598_v56 = vmul.f32 %v51597_v9, %v137365_v56 (stack63)
        %v52016_v9 = vand.u32.u8 255, %v52015_v50 (stack49)
        %v137389_v46 = vadd.s32 %v157388_v55, %v157079_v39 (stack40)
        %v51595_v10 = vmul.f32 0.6931472, %v120870_v41 (stack65)
        %v52414_v8 = vadd.s32 %v52411_v44, %v52406_v8 (stack40)
        %v52420_v21 = vshll.u32 %v52411_v44, 24 (stack45)
        %v52421_v22 = vshrl.u32 %v52411_v44, 8 (stack46)
        %v51256_v26 = vadd.f32 %v51252_v32, %v137290_v26 (stack53)
        %vm51600_vm6 = vcmp.lt.f32.partialorder %v51599_v30, 0.0004427343 (stack62)
        %v52833_v30 = vadd.s32 %v52830_v52, %v121574_v2 (stack40)
        %v53246_v54 = vor.u32 %v53245_v45, %v53244_v24 (stack47)
        %v51601_v53 = vsel /*vm=*/%vm51600_vm6, /*on_true_vy=*/%v51598_v56, /*on_false_vx=*/%v51595_v10 (stack66)
        %v52017_v20 = vand.u32 65535, %v52016_v9 (stack50)
        %v52422_v7 = vor.u32 %v52421_v22, %v52420_v21 (stack47)
        %v53683_v23 = vadd.s32 %v53680_v6, %v53675_v42 (stack40)
        %v51117_v60 = vand.u32 2147483647, %v137193_v43 (stack77)
        %v51260_v40 = vmul.f32 %v51256_v26, %v137339_v40 (stack54)
        %v137395_v42 = vxor.u32 2147483648, %v51601_v53 (stack56)
        %v51149_v31 = vsel /*vm=*/%vm51144_vm1, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v52423_v12 = vxor.u32 %v52422_v7, %v52414_v8 (stack48)
        %v52837_v27 = vadd.s32 2, %v52833_v30 (stack40)
        %v53247_v50 = vxor.u32 %v53246_v54, %v53238_v61 (stack48)
        %v51264_v24 = vadd.f32 %v51260_v40, %v51149_v31 (stack53)
        %120871 = vrsqrt.f32 %v137395_v42 (stack67)
        %vm51605_vm7 = vcmp.lt.f32.partialorder %v137395_v42, 5.0 (stack68)
        %v52018_v44 = vshrl.u32 %v52017_v20, 1 (stack51)
        %v52426_v52 = vadd.s32 %v52423_v12, %v121564_v0 (stack40)
        %v52825_v25 = vadd.s32 %v52821_v25, %v121564_v0 (stack40)
        %v51125_v45 = vmul.f32 inf, %v137193_v43 (stack54)
        %v51268_v43 = vmul.f32 %v51264_v24, %v137193_v43 (stack54)
        %v53685_v41 = vshll.u32 %v53680_v6, 15 (stack45)
        %v53686_v6 = vshrl.u32 %v53680_v6, 17 (stack46)
        %vm51120_vm8 = vcmp.eq.f32.partialorder %v51117_v60, 1.0 (stack68)
        %v52418_v32 = vadd.s32 %v52414_v8, %v121569_v1 (stack40)
        %v52841_v56 = vadd.s32 %v52837_v27, %v52825_v25 (stack40)
        %v53242_v61 = vadd.s32 %v53238_v61, %v121569_v1 (stack40)
        %v51272_v9 = vsel /*vm=*/%vm51120_vm8, /*on_true_vy=*/%v51125_v45, /*on_false_vx=*/%v51268_v43 (stack44)
        %v137411_v10 = vsel /*vm=*/%vm51605_vm7, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v137416_v8 = vsel /*vm=*/%vm51605_vm7, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v137419_v21 = vadd.f32 -2.5, %v137395_v42 (stack53)
        %v51276_v22 = vmul.f32 1.4140625, %v51272_v9 (stack54)
        %v52019_v26 = vor.u32 16256, %v52018_v44 (stack47)
        %v52430_v30 = vadd.s32 4, %v52426_v52 (stack40)
        %v52843_v54 = vshll.u32 %v52837_v27, 13 (stack45)
        %v137424_v53 = vsel /*vm=*/%vm51605_vm7, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v52844_v20 = vshrl.u32 %v52837_v27, 19 (stack46)
        %v53250_v7 = vadd.s32 %v53247_v50, %v121564_v0 (stack40)
        %v53687_v60 = vor.u32 %v53686_v6, %v53685_v41 (stack47)
        %v51279_v40 = vpack.c.bf16 %v157387_v11, %v51276_v22 (stack81)
        %v52020_v31 = vand.u32.u16 65535, %v52019_v26 (stack52)
        %v52434_v12 = vadd.s32 %v52430_v30, %v52418_v32 (stack40)
        %v52436_v27 = vshll.u32 %v52430_v30, 13 (stack45)
        %v52437_v50 = vshrl.u32 %v52430_v30, 19 (stack46)
        %v52845_v24 = vor.u32 %v52844_v20, %v52843_v54 (stack47)
        %v53254_v44 = vadd.s32 1, %v53250_v7 (stack40)
        %v53688_v52 = vxor.u32 %v53687_v60, %v53683_v23 (stack48)
        %120017 = vst [vmem:[%s123356_s30 + $0x234] sm:$0xf] /*vst_source=*/%v51279_v40 (stack83)
        %vm51650_vm9 = vcmp.eq.f32.partialorder %v137395_v42, inf (stack70)
        %v120020_v25 = vadd.low.f32.bf16 -1.0, %v52020_v31 (stack53)
        %vm54102_vm10 = vcmp.lt.u32.totalorder %v137389_v46, %v157079_v39 (stack43)
        %v54107_v45 = vadd.s32 %v157389_v34, %v157082_v49 (stack40)
        %v52438_v43 = vor.u32 %v52437_v50, %v52436_v27 (stack47)
        %v52846_v41 = vxor.u32 %v52845_v24, %v52841_v56 (stack48)
        %v53258_v6 = vadd.s32 %v53254_v44, %v53242_v61 (stack40)
        %v53260_v32 = vshll.u32 %v53254_v44, 17 (stack45)
        %v51653_v61 = vand.u32 2147483648, %v137395_v42 (stack72)
        %v52029_v9 = vmul.f32 2.0, %v120020_v25 (stack54)
        %v53261_v22 = vshrl.u32 %v53254_v44, 15 (stack46)
        %v137435_v23 = vadd.s32 %v53688_v52, %v53683_v23 (stack40)
        %v52439_v26 = vxor.u32 %v52438_v43, %v52434_v12 (stack48)
        %v52849_v56 = vadd.s32 %v52846_v41, %v52841_v56 (stack40)
        %v52851_v30 = vshll.u32 %v52846_v41, 15 (stack45)
        %v52852_v54 = vshrl.u32 %v52846_v41, 17 (stack46)
        %v120872_v20 = vpop.eup %120871 (stack73)
        %v52033_v7 = vadd.f32 -0.99609375, %v52029_v9 (stack53)
        %v53262_v60 = vor.u32 %v53261_v22, %v53260_v32 (stack47)
        %v53693_v40 = vshll.u32 %v53688_v52, 26 (stack45)
        %v54111_v31 = vadd.s32 1, %v54107_v45 (stack40)
        %v51649_v27 = vmul.f32 %v120872_v20, %v137395_v42 (stack74)
        %v52442_v12 = vadd.s32 %v52439_v26, %v52434_v12 (stack40)
        %v52444_v50 = vshll.u32 %v52439_v26, 15 (stack45)
        %v52445_v24 = vshrl.u32 %v52439_v26, 17 (stack46)
        %v137438_v44 = vmax.f32 %v52033_v7, -0.99609375 (stack55)
        %v52853_v25 = vor.u32 %v52852_v54, %v52851_v30 (stack47)
        %v53263_v43 = vxor.u32 %v53262_v60, %v53258_v6 (stack48)
        %v53694_v52 = vshrl.u32 %v53688_v52, 6 (stack46)
        %v51651_v41 = vsel /*vm=*/%vm51650_vm9, /*on_true_vy=*/%v137395_v42, /*on_false_vx=*/%v51649_v27 (stack75)
        %vm51652_vm11 = vcmp.eq.f32.partialorder %v137395_v42, 0.0 (stack71)
        %v52446_v32 = vor.u32 %v52445_v24, %v52444_v50 (stack47)
        %v54115_v45 = vsel /*vm=*/%vm54102_vm10, /*on_true_vy=*/%v54111_v31, /*on_false_vx=*/%v54107_v45 (stack44)
        %v51642_v9 = vsel /*vm=*/%vm51605_vm7, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v51654_v61 = vsel /*vm=*/%vm51652_vm11, /*on_true_vy=*/%v51653_v61, /*on_false_vx=*/%v51651_v41 (stack76)
        %v52049_v22 = vxor.u32 2147483648, %v137438_v44 (stack56)
        %v54093_v26 = vadd.s32 %v137389_v46, %v122657_v58 (stack40)
        %v51657_v30 = vadd.f32 -3.0, %v51654_v61 (stack53)
        %v52447_v54 = vxor.u32 %v52446_v32, %v52442_v12 (stack48)
        %v52854_v20 = vxor.u32 %v52853_v25, %v52849_v56 (stack48)
        %v53266_v6 = vadd.s32 %v53263_v43, %v53258_v6 (stack40)
        %v137454_v7 = vmul.f32 %v52049_v22, %v137438_v44 (stack54)
        %v53268_v60 = vshll.u32 %v53263_v43, 29 (stack45)
        %v53269_v31 = vshrl.u32 %v53263_v43, 3 (stack46)
        %v53695_v40 = vor.u32 %v53694_v52, %v53693_v40 (stack47)
        %v137459_v21 = vsel /*vm=*/%vm51605_vm7, /*on_true_vy=*/%v137419_v21, /*on_false_vx=*/%v51657_v30 (stack44)
        %v52450_v27 = vadd.s32 %v52447_v54, %v52442_v12 (stack40)
        %v52452_v12 = vshll.u32 %v52447_v54, 26 (stack45)
        %v52453_v50 = vshrl.u32 %v52447_v54, 6 (stack46)
        %v51638_v24 = vsel /*vm=*/%vm51605_vm7, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v51665_v25 = vmul.f32 %v137459_v21, %v51642_v9 (stack54)
        %v52054_v43 = vadd.f32 1.0, %v137454_v7 (stack57)
        %v52057_v52 = vmul.f32 -0.5, %v137454_v7 (stack59)
        %v52454_v41 = vor.u32 %v52453_v50, %v52452_v12 (stack47)
        %v52857_v56 = vadd.s32 %v52854_v20, %v52849_v56 (stack40)
        %v52859_v32 = vshll.u32 %v52854_v20, 26 (stack45)
        %v52860_v9 = vshrl.u32 %v52854_v20, 6 (stack46)
        %v51634_v61 = vsel /*vm=*/%vm51605_vm7, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v51669_v22 = vadd.f32 %v51665_v25, %v51638_v24 (stack53)
        %120873 = vlog2.f32 %v52054_v43 (stack58)
        %vm54097_vm12 = vcmp.lt.u32.totalorder %v54093_v26, %v137389_v46 (stack43)
        %v52455_v30 = vxor.u32 %v52454_v41, %v52450_v27 (stack48)
        %v52861_v54 = vor.u32 %v52860_v9, %v52859_v32 (stack47)
        %v53270_v20 = vor.u32 %v53269_v31, %v53268_v60 (stack47)
        %v53696_v60 = vxor.u32 %v53695_v40, %v137435_v23 (stack48)
        %v51673_v31 = vmul.f32 %v51669_v22, %v137459_v21 (stack54)
        %v52058_v40 = vadd.f32 1.0, %v52057_v52 (stack61)
        %v52060_v12 = vand.u32 2147483647, %v137454_v7 (stack60)
        %v54132_v50 = vadd.s32 %v54093_v26, %v121569_v1 (stack40)
        %v52458_v27 = vadd.s32 %v52455_v30, %v52450_v27 (stack40)
        %v52464_v24 = vshll.u32 %v52455_v30, 6 (stack45)
        %v52465_v25 = vshrl.u32 %v52455_v30, 26 (stack46)
        %v52862_v43 = vxor.u32 %v52861_v54, %v52857_v56 (stack48)
        %v51677_v52 = vadd.f32 %v51673_v31, %v51634_v61 (stack53)
        %v53271_v41 = vxor.u32 %v53270_v20, %v53266_v6 (stack48)
        %v137476_v23 = vadd.s32 %v53696_v60, %v137435_v23 (stack40)
        %v54119_v32 = vadd.s32 1, %v54115_v45 (stack40)
        %v52466_v9 = vor.u32 %v52465_v25, %v52464_v24 (stack47)
        %v52865_v56 = vadd.s32 %v52862_v43, %v52857_v56 (stack40)
        %v52871_v61 = vshll.u32 %v52862_v43, 6 (stack45)
        %v53705_v22 = vshll.u32 %v53696_v60, 6 (stack45)
        %v51681_v30 = vmul.f32 %v51677_v52, %v137459_v21 (stack54)
        %v52872_v54 = vshrl.u32 %v52862_v43, 26 (stack46)
        %v53274_v6 = vadd.s32 %v53271_v41, %v53266_v6 (stack40)
        %v53276_v20 = vshll.u32 %v53271_v41, 16 (stack45)
        %v52462_v31 = vadd.s32 %v52458_v27, %v121564_v0 (stack40)
        %v52467_v27 = vxor.u32 %v52466_v9, %v52458_v27 (stack48)
        %v53277_v24 = vshrl.u32 %v53271_v41, 16 (stack46)
        %v54138_v25 = vshll.u32 %v54132_v50, 13 (stack45)
        %v51685_v53 = vadd.f32 %v51681_v30, %v137424_v53 (stack53)
        %v52873_v43 = vor.u32 %v52872_v54, %v52871_v61 (stack47)
        %v53706_v60 = vshrl.u32 %v53696_v60, 26 (stack46)
        %v54123_v46 = vsel /*vm=*/%vm54097_vm12, /*on_true_vy=*/%v54119_v32, /*on_false_vx=*/%v54115_v45 (stack44)
        %v52470_v45 = vadd.s32 %v52467_v27, %v121574_v2 (stack40)
        %v53278_v26 = vor.u32 %v53277_v24, %v53276_v20 (stack47)
        %v54128_v52 = vadd.s32 %v54123_v46, %v121574_v2 (stack40)
        %v54139_v41 = vshrl.u32 %v54132_v50, 19 (stack46)
        %v51689_v32 = vmul.f32 %v51685_v53, %v137459_v21 (stack54)
        %v52874_v9 = vxor.u32 %v52873_v43, %v52865_v56 (stack48)
        %v53707_v61 = vor.u32 %v53706_v60, %v53705_v22 (stack47)
        %v137488_v22 = vadd.s32 %v157388_v55, %v157083_v59 (stack40)
        %v52474_v30 = vadd.s32 5, %v52470_v45 (stack40)
        %v53279_v54 = vxor.u32 %v53278_v26, %v53274_v6 (stack48)
        %v54136_v50 = vadd.s32 %v54132_v50, %v54128_v52 (stack40)
        %v54140_v20 = vor.u32 %v54139_v41, %v54138_v25 (stack47)
        %v51693_v8 = vadd.f32 %v51689_v32, %v137416_v8 (stack53)
        %v52059_v7 = vmul.f32 %v52058_v40, %v137454_v7 (stack63)
        %v52877_v40 = vadd.s32 %v52874_v9, %v121569_v1 (stack40)
        %v53708_v27 = vxor.u32 %v53707_v61, %v137476_v23 (stack48)
        %v120874_v24 = vpop.eup %120873 (stack64)
        %v52476_v31 = vxor.u32 %v52474_v30, %v52462_v31 (stack48)
        %v53282_v6 = vadd.s32 %v53279_v54, %v53274_v6 (stack40)
        %v53288_v25 = vshll.u32 %v53279_v54, 24 (stack45)
        %v53289_v53 = vshrl.u32 %v53279_v54, 8 (stack46)
        %v51697_v43 = vmul.f32 %v51693_v8, %v137459_v21 (stack54)
        %v52056_v60 = vmul.f32 0.6931472, %v120874_v24 (stack65)
        %v52869_v56 = vadd.s32 %v52865_v56, %v121574_v2 (stack40)
        %v52881_v46 = vadd.s32 3, %v52877_v40 (stack40)
        %vm52061_vm13 = vcmp.lt.f32.partialorder %v52060_v12, 0.0004427343 (stack62)
        %v52477_v12 = vand.u32.u8 255, %v52476_v31 (stack49)
        %v53290_v45 = vor.u32 %v53289_v53, %v53288_v25 (stack47)
        %v54141_v26 = vxor.u32 %v54140_v20, %v54136_v50 (stack48)
        %v51701_v10 = vadd.f32 %v51697_v43, %v137411_v10 (stack53)
        %v52062_v52 = vsel /*vm=*/%vm52061_vm13, /*on_true_vy=*/%v52059_v7, /*on_false_vx=*/%v52056_v60 (stack66)
        %v52885_v41 = vadd.s32 %v52881_v46, %v52869_v56 (stack40)
        %v53711_v32 = vadd.s32 %v53708_v27, %v121564_v0 (stack40)
        %v137498_v9 = vxor.u32 2147483648, %v52062_v52 (stack56)
        %v52887_v61 = vshll.u32 %v52881_v46, 17 (stack45)
        %v52888_v30 = vshrl.u32 %v52881_v46, 15 (stack46)
        %v53291_v54 = vxor.u32 %v53290_v45, %v53282_v6 (stack48)
        %v51578_v20 = vand.u32 2147483647, %v137350_v29 (stack77)
        %v51586_v8 = vmul.f32 inf, %v137350_v29 (stack54)
        %v51705_v7 = vmul.f32 %v51701_v10, %v137459_v21 (stack54)
        %v137503_v50 = vadd.s32 %v54141_v26, %v54136_v50 (stack40)
        %v51610_v40 = vsel /*vm=*/%vm51605_vm7, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v51618_v27 = vsel /*vm=*/%vm51605_vm7, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %120875 = vrsqrt.f32 %v137498_v9 (stack67)
        %v52478_v24 = vand.u32 65535, %v52477_v12 (stack50)
        %v51614_v42 = vsel /*vm=*/%vm51605_vm7, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v51709_v31 = vadd.f32 %v51705_v7, %v51618_v27 (stack53)
        %vm52066_vm14 = vcmp.lt.f32.partialorder %v137498_v9, 5.0 (stack68)
        %v53715_v25 = vadd.s32 1, %v53711_v32 (stack40)
        %v52039_v53 = vand.u32 2147483647, %v137438_v44 (stack77)
        %v137518_v43 = vmul.f32 inf, %v137438_v44 (stack54)
        %v52889_v60 = vor.u32 %v52888_v30, %v52887_v61 (stack47)
        %v53703_v23 = vadd.s32 %v137476_v23, %v121569_v1 (stack40)
        %v51713_v56 = vmul.f32 %v51709_v31, %v137459_v21 (stack54)
        %v53286_v6 = vadd.s32 %v53282_v6, %v121564_v0 (stack40)
        %v54146_v46 = vshll.u32 %v54141_v26, 15 (stack45)
        %v137526_v12 = vadd.s32 %v137488_v22, %v122657_v58 (stack40)
        %vm137528_vm15 = vcmp.eq.f32.partialorder %v51578_v20, 1.0 (stack68)
        %v137535_v10 = vsel /*vm=*/%vm52066_vm14, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v137538_v52 = vadd.f32 -2.5, %v137498_v9 (stack53)
        %v52479_v32 = vshrl.u32 %v52478_v24, 1 (stack51)
        %v52890_v61 = vxor.u32 %v52889_v60, %v52885_v41 (stack48)
        %v51717_v30 = vadd.f32 %v51713_v56, %v51614_v42 (stack53)
        %v53294_v54 = vadd.s32 %v53291_v54, %v121574_v2 (stack40)
        %v53719_v20 = vadd.s32 %v53715_v25, %v53703_v23 (stack40)
        %v53721_v7 = vshll.u32 %v53715_v25, 17 (stack45)
        %v52480_v27 = vor.u32 16256, %v52479_v32 (stack47)
        %v52893_v41 = vadd.s32 %v52890_v61, %v52885_v41 (stack40)
        %v52895_v24 = vshll.u32 %v52890_v61, 29 (stack45)
        %v52896_v42 = vshrl.u32 %v52890_v61, 3 (stack46)
        %v51721_v21 = vmul.f32 %v51717_v30, %v137459_v21 (stack54)
        %vm52111_vm0 = vcmp.eq.f32.partialorder %v137498_v9, inf (stack70)
        %v53298_v31 = vadd.s32 2, %v53294_v54 (stack40)
        %v53722_v25 = vshrl.u32 %v53715_v25, 15 (stack46)
        %v54147_v26 = vshrl.u32 %v54141_v26, 17 (stack46)
        %vm52113_vm1 = vcmp.eq.f32.partialorder %v137498_v9, 0.0 (stack71)
        %v52481_v60 = vand.u32.u16 65535, %v52480_v27 (stack52)
        %v52897_v23 = vor.u32 %v52896_v42, %v52895_v24 (stack47)
        %vm54563_vm2 = vcmp.lt.u32.totalorder %v137488_v22, %v157083_v59 (stack43)
        %v51725_v40 = vadd.f32 %v51721_v21, %v51610_v40 (stack53)
        %v53302_v56 = vadd.s32 %v53298_v31, %v53286_v6 (stack40)
        %v53304_v6 = vshll.u32 %v53298_v31, 13 (stack45)
        %v53305_v32 = vshrl.u32 %v53298_v31, 19 (stack46)
        %v120022_v61 = vadd.low.f32.bf16 -1.0, %v52481_v60 (stack53)
        %v52898_v30 = vxor.u32 %v52897_v23, %v52893_v41 (stack48)
        %v53723_v54 = vor.u32 %v53722_v25, %v53721_v7 (stack47)
        %v54148_v46 = vor.u32 %v54147_v26, %v54146_v46 (stack47)
        %v51729_v29 = vmul.f32 %v51725_v40, %v137350_v29 (stack54)
        %v52114_v7 = vand.u32 2147483648, %v137498_v9 (stack72)
        %v53306_v27 = vor.u32 %v53305_v32, %v53304_v6 (stack47)
        %v137550_v24 = vadd.s32 %v157389_v34, %v157084_v16 (stack40)
        %v52490_v42 = vmul.f32 2.0, %v120022_v61 (stack54)
        %v52901_v41 = vadd.s32 %v52898_v30, %v52893_v41 (stack40)
        %v52903_v21 = vshll.u32 %v52898_v30, 16 (stack45)
        %v52904_v31 = vshrl.u32 %v52898_v30, 16 (stack46)
        %v120876_v25 = vpop.eup %120875 (stack73)
        %v51733_v8 = vsel /*vm=*/%vm137528_vm15, /*on_true_vy=*/%v51586_v8, /*on_false_vx=*/%v51729_v29 (stack44)
        %v53307_v45 = vxor.u32 %v53306_v27, %v53302_v56 (stack48)
        %v53724_v26 = vxor.u32 %v53723_v54, %v53719_v20 (stack48)
        %v137555_v60 = vxor.u32 %v54148_v46, %v137503_v50 (stack48)
        %v51737_v23 = vmul.f32 1.4140625, %v51733_v8 (stack54)
        %v52110_v40 = vmul.f32 %v120876_v25, %v137498_v9 (stack74)
        %v52494_v6 = vadd.f32 -0.99609375, %v52490_v42 (stack53)
        %v52905_v32 = vor.u32 %v52904_v31, %v52903_v21 (stack47)
        %v53310_v56 = vadd.s32 %v53307_v45, %v53302_v56 (stack40)
        %v53312_v61 = vshll.u32 %v53307_v45, 15 (stack45)
        %v53313_v30 = vshrl.u32 %v53307_v45, 17 (stack46)
        %v53727_v20 = vadd.s32 %v53724_v26, %v53719_v20 (stack40)
        %v51740_v54 = vpack.c.bf16 %v157387_v11, %v51737_v23 (stack81)
        %v52112_v46 = vsel /*vm=*/%vm52111_vm0, /*on_true_vy=*/%v137498_v9, /*on_false_vx=*/%v52110_v40 (stack75)
        %v137562_v29 = vmax.f32 %v52494_v6, -0.99609375 (stack55)
        %v52906_v27 = vxor.u32 %v52905_v32, %v52901_v41 (stack48)
        %v52115_v7 = vsel /*vm=*/%vm52113_vm1, /*on_true_vy=*/%v52114_v7, /*on_false_vx=*/%v52112_v46 (stack76)
        %v53314_v42 = vor.u32 %v53313_v30, %v53312_v61 (stack47)
        %v53729_v21 = vshll.u32 %v53724_v26, 29 (stack45)
        %v53730_v31 = vshrl.u32 %v53724_v26, 3 (stack46)
        %120019 = vst [vmem:[%s123356_s30 + $0x2b4] sm:$0xf] /*vst_source=*/%v51740_v54 (stack83)
        %v137570_v25 = vsel /*vm=*/%vm52066_vm14, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v137575_v8 = vsel /*vm=*/%vm52066_vm14, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v52118_v45 = vadd.f32 -3.0, %v52115_v7 (stack53)
        %v52510_v26 = vxor.u32 2147483648, %v137562_v29 (stack56)
        %v52909_v41 = vadd.s32 %v52906_v27, %v52901_v41 (stack40)
        %v52915_v23 = vshll.u32 %v52906_v27, 24 (stack45)
        %v52916_v40 = vshrl.u32 %v52906_v27, 8 (stack46)
        %v53315_v6 = vxor.u32 %v53314_v42, %v53310_v56 (stack48)
        %v52103_v32 = vsel /*vm=*/%vm52066_vm14, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v137584_v52 = vsel /*vm=*/%vm52066_vm14, /*on_true_vy=*/%v137538_v52, /*on_false_vx=*/%v52118_v45 (stack44)
        %v52513_v61 = vmul.f32 %v52510_v26, %v137562_v29 (stack54)
        %v53731_v30 = vor.u32 %v53730_v31, %v53729_v21 (stack47)
        %v52091_v54 = vsel /*vm=*/%vm52066_vm14, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v52126_v46 = vmul.f32 %v137584_v52, %v52103_v32 (stack54)
        %v52917_v27 = vor.u32 %v52916_v40, %v52915_v23 (stack47)
        %v53318_v56 = vadd.s32 %v53315_v6, %v53310_v56 (stack40)
        %v52095_v7 = vsel /*vm=*/%vm52066_vm14, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v52099_v42 = vsel /*vm=*/%vm52066_vm14, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v52515_v21 = vadd.f32 1.0, %v52513_v61 (stack57)
        %v53320_v31 = vshll.u32 %v53315_v6, 26 (stack45)
        %v52130_v45 = vadd.f32 %v52126_v46, %v52099_v42 (stack53)
        %v52918_v26 = vxor.u32 %v52917_v27, %v52909_v41 (stack48)
        %v53321_v23 = vshrl.u32 %v53315_v6, 6 (stack46)
        %v53732_v40 = vxor.u32 %v53731_v30, %v53727_v20 (stack48)
        %120877 = vlog2.f32 %v52515_v21 (stack58)
        %v52518_v6 = vmul.f32 -0.5, %v52513_v61 (stack59)
        %v54152_v50 = vadd.s32 %v137555_v60, %v137503_v50 (stack40)
        %v137601_v32 = vadd.s32 %v137526_v12, %v121569_v1 (stack40)
        %v52134_v30 = vmul.f32 %v52130_v45, %v137584_v52 (stack54)
        %v52921_v46 = vadd.s32 %v52918_v26, %v121564_v0 (stack40)
        %v53322_v27 = vor.u32 %v53321_v23, %v53320_v31 (stack47)
        %v53735_v20 = vadd.s32 %v53732_v40, %v53727_v20 (stack40)
        %v52913_v41 = vadd.s32 %v52909_v41, %v121569_v1 (stack40)
        %v53737_v42 = vshll.u32 %v53732_v40, 16 (stack45)
        %v53738_v21 = vshrl.u32 %v53732_v40, 16 (stack46)
        %v54154_v31 = vshll.u32 %v137555_v60, 26 (stack45)
        %vm54558_vm3 = vcmp.lt.u32.totalorder %v137526_v12, %v137488_v22 (stack43)
        %v52138_v7 = vadd.f32 %v52134_v30, %v52095_v7 (stack53)
        %v52925_v45 = vadd.s32 4, %v52921_v46 (stack40)
        %v53323_v26 = vxor.u32 %v53322_v27, %v53318_v56 (stack48)
        %v54155_v60 = vshrl.u32 %v137555_v60, 6 (stack46)
        %v52519_v23 = vadd.f32 1.0, %v52518_v6 (stack61)
        %v52521_v40 = vand.u32 2147483647, %v52513_v61 (stack60)
        %v53739_v6 = vor.u32 %v53738_v21, %v53737_v42 (stack47)
        %v54572_v30 = vadd.s32 1, %v137550_v24 (stack40)
        %v52142_v46 = vmul.f32 %v52138_v7, %v137584_v52 (stack54)
        %v52929_v27 = vadd.s32 %v52925_v45, %v52913_v41 (stack40)
        %v52931_v41 = vshll.u32 %v52925_v45, 13 (stack45)
        %v52932_v42 = vshrl.u32 %v52925_v45, 19 (stack46)
        %v53326_v56 = vadd.s32 %v53323_v26, %v53318_v56 (stack40)
        %v53332_v21 = vshll.u32 %v53323_v26, 6 (stack45)
        %v53333_v7 = vshrl.u32 %v53323_v26, 26 (stack46)
        %v53740_v45 = vxor.u32 %v53739_v6, %v53735_v20 (stack48)
        %v52146_v54 = vadd.f32 %v52142_v46, %v52091_v54 (stack53)
        %v52933_v26 = vor.u32 %v52932_v42, %v52931_v41 (stack47)
        %v54156_v31 = vor.u32 %v54155_v60, %v54154_v31 (stack47)
        %v54576_v24 = vsel /*vm=*/%vm54563_vm2, /*on_true_vy=*/%v54572_v30, /*on_false_vx=*/%v137550_v24 (stack44)
        %vm137616_vm4 = vcmp.lt.f32.partialorder %v52521_v40, 0.0004427343 (stack62)
        %v53334_v40 = vor.u32 %v53333_v7, %v53332_v21 (stack47)
        %v53743_v20 = vadd.s32 %v53740_v45, %v53735_v20 (stack40)
        %v53749_v6 = vshll.u32 %v53740_v45, 24 (stack45)
        %v52150_v30 = vmul.f32 %v52146_v54, %v137584_v52 (stack54)
        %v52934_v46 = vxor.u32 %v52933_v26, %v52929_v27 (stack48)
        %v53750_v41 = vshrl.u32 %v53740_v45, 8 (stack46)
        %v54157_v42 = vxor.u32 %v54156_v31, %v54152_v50 (stack48)
        %v52520_v61 = vmul.f32 %v52519_v23, %v52513_v61 (stack63)
        %v53335_v23 = vxor.u32 %v53334_v40, %v53326_v56 (stack48)
        %v54580_v21 = vadd.s32 1, %v54576_v24 (stack40)
        %v54599_v7 = vshll.u32 %v137601_v32, 13 (stack45)
        %v52154_v8 = vadd.f32 %v52150_v30, %v137575_v8 (stack53)
        %v52937_v27 = vadd.s32 %v52934_v46, %v52929_v27 (stack40)
        %v52939_v45 = vshll.u32 %v52934_v46, 15 (stack45)
        %v52940_v54 = vshrl.u32 %v52934_v46, 17 (stack46)
        %v53338_v26 = vadd.s32 %v53335_v23, %v121569_v1 (stack40)
        %v53751_v31 = vor.u32 %v53750_v41, %v53749_v6 (stack47)
        %v54160_v50 = vadd.s32 %v54157_v42, %v54152_v50 (stack40)
        %v54166_v40 = vshll.u32 %v54157_v42, 6 (stack45)
        %v120878_v6 = vpop.eup %120877 (stack64)
        %v52158_v30 = vmul.f32 %v52154_v8, %v137584_v52 (stack54)
        %v52941_v46 = vor.u32 %v52940_v54, %v52939_v45 (stack47)
        %v54167_v41 = vshrl.u32 %v54157_v42, 26 (stack46)
        %v54584_v22 = vsel /*vm=*/%vm54558_vm3, /*on_true_vy=*/%v54580_v21, /*on_false_vx=*/%v54576_v24 (stack44)
        %v52517_v12 = vmul.f32 0.6931472, %v120878_v6 (stack65)
        %v53330_v56 = vadd.s32 %v53326_v56, %v121574_v2 (stack40)
        %v53342_v24 = vadd.s32 3, %v53338_v26 (stack40)
        %v53752_v42 = vxor.u32 %v53751_v31, %v53743_v20 (stack48)
        %v52162_v25 = vadd.f32 %v52158_v30, %v137570_v25 (stack53)
        %v52942_v23 = vxor.u32 %v52941_v46, %v52937_v27 (stack48)
        %v54168_v21 = vor.u32 %v54167_v41, %v54166_v40 (stack47)
        %v54600_v8 = vshrl.u32 %v137601_v32, 19 (stack46)
        %v52523_v60 = vsel /*vm=*/%vm137616_vm4, /*on_true_vy=*/%v52520_v61, /*on_false_vx=*/%v52517_v12 (stack66)
        %v53346_v61 = vadd.s32 %v53342_v24, %v53330_v56 (stack40)
        %v53348_v45 = vshll.u32 %v53342_v24, 17 (stack45)
        %v53349_v54 = vshrl.u32 %v53342_v24, 15 (stack46)
        %v52166_v26 = vmul.f32 %v52162_v25, %v137584_v52 (stack54)
        %v137634_v31 = vxor.u32 2147483648, %v52523_v60 (stack56)
        %v52945_v27 = vadd.s32 %v52942_v23, %v52937_v27 (stack40)
        %v52947_v40 = vshll.u32 %v52942_v23, 26 (stack45)
        %v52075_v6 = vsel /*vm=*/%vm52066_vm14, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v52079_v9 = vsel /*vm=*/%vm52066_vm14, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v52948_v30 = vshrl.u32 %v52942_v23, 6 (stack46)
        %v54169_v46 = vxor.u32 %v54168_v21, %v54160_v50 (stack48)
        %v52170_v41 = vadd.f32 %v52166_v26, %v52079_v9 (stack53)
        %v52500_v12 = vand.u32 2147483647, %v137562_v29 (stack77)
        %vm52527_vm5 = vcmp.lt.f32.partialorder %v137634_v31, 5.0 (stack68)
        %120879 = vrsqrt.f32 %v137634_v31 (stack67)
        %v137646_v56 = vmul.f32 inf, %v137562_v29 (stack54)
        %v52949_v24 = vor.u32 %v52948_v30, %v52947_v40 (stack47)
        %v53350_v25 = vor.u32 %v53349_v54, %v53348_v45 (stack47)
        %v53747_v20 = vadd.s32 %v53743_v20, %v121564_v0 (stack40)
        %v52174_v23 = vmul.f32 %v52170_v41, %v137584_v52 (stack54)
        %v53755_v42 = vadd.s32 %v53752_v42, %v121574_v2 (stack40)
        %v54589_v22 = vadd.s32 %v54584_v22, %v121574_v2 (stack40)
        %v54601_v7 = vor.u32 %v54600_v8, %v54599_v7 (stack47)
        %vm137654_vm6 = vcmp.eq.f32.partialorder %v52039_v53, 1.0 (stack68)
        %v137661_v21 = vsel /*vm=*/%vm52527_vm5, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v137664_v8 = vadd.f32 -2.5, %v137634_v31 (stack53)
        %v52950_v60 = vxor.u32 %v52949_v24, %v52945_v27 (stack48)
        %v54164_v50 = vadd.s32 %v54160_v50, %v121569_v1 (stack40)
        %v52178_v45 = vadd.f32 %v52174_v23, %v52075_v6 (stack53)
        %v137670_v54 = vsel /*vm=*/%vm52527_vm5, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v137675_v26 = vsel /*vm=*/%vm52527_vm5, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v52575_v40 = vand.u32 2147483648, %v137634_v31 (stack72)
        %v52953_v27 = vadd.s32 %v52950_v60, %v52945_v27 (stack40)
        %v52959_v6 = vshll.u32 %v52950_v60, 6 (stack45)
        %v52960_v9 = vshrl.u32 %v52950_v60, 26 (stack46)
        %v53351_v30 = vxor.u32 %v53350_v25, %v53346_v61 (stack48)
        %v52182_v52 = vmul.f32 %v52178_v45, %v137584_v52 (stack54)
        %v53759_v41 = vadd.s32 2, %v53755_v42 (stack40)
        %v54172_v46 = vadd.s32 %v54169_v46, %v121564_v0 (stack40)
        %v54597_v32 = vadd.s32 %v137601_v32, %v54589_v22 (stack40)
        %vm52572_vm7 = vcmp.eq.f32.partialorder %v137634_v31, inf (stack70)
        %v52957_v24 = vadd.s32 %v52953_v27, %v121564_v0 (stack40)
        %v52961_v25 = vor.u32 %v52960_v9, %v52959_v6 (stack47)
        %v53354_v61 = vadd.s32 %v53351_v30, %v53346_v61 (stack40)
        %v53356_v23 = vshll.u32 %v53351_v30, 29 (stack45)
        %v52186_v10 = vadd.f32 %v52182_v52, %v137535_v10 (stack53)
        %vm52574_vm8 = vcmp.eq.f32.partialorder %v137634_v31, 0.0 (stack71)
        %v53357_v42 = vshrl.u32 %v53351_v30, 3 (stack46)
        %v53763_v20 = vadd.s32 %v53759_v41, %v53747_v20 (stack40)
        %v53765_v22 = vshll.u32 %v53759_v41, 13 (stack45)
        %v52962_v60 = vxor.u32 %v52961_v25, %v52953_v27 (stack48)
        %v53766_v45 = vshrl.u32 %v53759_v41, 19 (stack46)
        %v54176_v27 = vadd.s32 1, %v54172_v46 (stack40)
        %v54602_v7 = vxor.u32 %v54601_v7, %v54597_v32 (stack48)
        %v52190_v44 = vmul.f32 %v52186_v10, %v137438_v44 (stack54)
        %v53358_v6 = vor.u32 %v53357_v42, %v53356_v23 (stack47)
        %v137688_v9 = vadd.s32 %v157388_v55, %v157089_v17 (stack40)
        %v137692_v30 = vadd.s32 %v157389_v34, %v157090_v62 (stack40)
        %v52965_v52 = vadd.s32 %v52962_v60, %v121574_v2 (stack40)
        %v53767_v41 = vor.u32 %v53766_v45, %v53765_v22 (stack47)
        %v54180_v50 = vadd.s32 %v54176_v27, %v54164_v50 (stack40)
        %v54182_v46 = vshll.u32 %v54176_v27, 17 (stack45)
        %v52194_v43 = vsel /*vm=*/%vm137654_vm6, /*on_true_vy=*/%v137518_v43, /*on_false_vx=*/%v52190_v44 (stack44)
        %v53359_v53 = vxor.u32 %v53358_v6, %v53354_v61 (stack48)
        %v54183_v25 = vshrl.u32 %v54176_v27, 15 (stack46)
        %v54605_v32 = vadd.s32 %v54602_v7, %v54597_v32 (stack40)
        %v120880_v23 = vpop.eup %120879 (stack73)
        %v52198_v10 = vmul.f32 1.4140625, %v52194_v43 (stack54)
        %v52969_v42 = vadd.s32 5, %v52965_v52 (stack40)
        %v53768_v22 = vxor.u32 %v53767_v41, %v53763_v20 (stack48)
        %v54607_v60 = vshll.u32 %v54602_v7, 15 (stack45)
        %v52571_v45 = vmul.f32 %v120880_v23, %v137634_v31 (stack74)
        %v53362_v61 = vadd.s32 %v53359_v53, %v53354_v61 (stack40)
        %v53364_v27 = vshll.u32 %v53359_v53, 16 (stack45)
        %v53365_v44 = vshrl.u32 %v53359_v53, 16 (stack46)
        %v52201_v6 = vpack.c.bf16 %v157387_v11, %v52198_v10 (stack81)
        %v52971_v24 = vxor.u32 %v52969_v42, %v52957_v24 (stack48)
        %v53771_v20 = vadd.s32 %v53768_v22, %v53763_v20 (stack40)
        %v53773_v52 = vshll.u32 %v53768_v22, 15 (stack45)
        %v52573_v41 = vsel /*vm=*/%vm52572_vm7, /*on_true_vy=*/%v137634_v31, /*on_false_vx=*/%v52571_v45 (stack75)
        %v53366_v43 = vor.u32 %v53365_v44, %v53364_v27 (stack47)
        %v53774_v53 = vshrl.u32 %v53768_v22, 17 (stack46)
        %v54184_v46 = vor.u32 %v54183_v25, %v54182_v46 (stack47)
        %120021 = vst [vmem:[%s123356_s30 + $0x334] sm:$0xf] /*vst_source=*/%v52201_v6 (stack83)
        %v52556_v25 = vsel /*vm=*/%vm52527_vm5, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v52576_v40 = vsel /*vm=*/%vm52574_vm8, /*on_true_vy=*/%v52575_v40, /*on_false_vx=*/%v52573_v41 (stack76)
        %v52972_v23 = vand.u32.u8 255, %v52971_v24 (stack49)
        %v54608_v7 = vshrl.u32 %v54602_v7, 17 (stack46)
        %v52579_v10 = vadd.f32 -3.0, %v52576_v40 (stack53)
        %v53367_v42 = vxor.u32 %v53366_v43, %v53362_v61 (stack48)
        %v53775_v22 = vor.u32 %v53774_v53, %v53773_v52 (stack47)
        %v54185_v45 = vxor.u32 %v54184_v46, %v54180_v50 (stack48)
        %v52564_v27 = vsel /*vm=*/%vm52527_vm5, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v52973_v44 = vand.u32 65535, %v52972_v23 (stack50)
        %v54609_v60 = vor.u32 %v54608_v7, %v54607_v60 (stack47)
        %vm55024_vm9 = vcmp.lt.u32.totalorder %v137688_v9, %v157089_v17 (stack43)
        %v137717_v8 = vsel /*vm=*/%vm52527_vm5, /*on_true_vy=*/%v137664_v8, /*on_false_vx=*/%v52579_v10 (stack44)
        %v53370_v61 = vadd.s32 %v53367_v42, %v53362_v61 (stack40)
        %v53376_v6 = vshll.u32 %v53367_v42, 24 (stack45)
        %v53377_v24 = vshrl.u32 %v53367_v42, 8 (stack46)
        %v52587_v52 = vmul.f32 %v137717_v8, %v52564_v27 (stack54)
        %v52974_v41 = vshrl.u32 %v52973_v44, 1 (stack51)
        %v53776_v43 = vxor.u32 %v53775_v22, %v53771_v20 (stack48)
        %v54188_v50 = vadd.s32 %v54185_v45, %v54180_v50 (stack40)
        %v52560_v53 = vsel /*vm=*/%vm52527_vm5, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v53378_v46 = vor.u32 %v53377_v24, %v53376_v6 (stack47)
        %v54190_v40 = vshll.u32 %v54185_v45, 29 (stack45)
        %v54191_v23 = vshrl.u32 %v54185_v45, 3 (stack46)
        %v52591_v7 = vadd.f32 %v52587_v52, %v52560_v53 (stack53)
        %v52975_v10 = vor.u32 16256, %v52974_v41 (stack47)
        %v53779_v20 = vadd.s32 %v53776_v43, %v53771_v20 (stack40)
        %v53781_v42 = vshll.u32 %v53776_v43, 26 (stack45)
        %v53379_v22 = vxor.u32 %v53378_v46, %v53370_v61 (stack48)
        %v53782_v45 = vshrl.u32 %v53776_v43, 6 (stack46)
        %v54192_v27 = vor.u32 %v54191_v23, %v54190_v40 (stack47)
        %v54610_v44 = vxor.u32 %v54609_v60, %v54605_v32 (stack48)
        %v52595_v60 = vmul.f32 %v52591_v7, %v137717_v8 (stack54)
        %v52976_v6 = vand.u32.u16 65535, %v52975_v10 (stack52)
        %v53374_v61 = vadd.s32 %v53370_v61, %v121569_v1 (stack40)
        %v55033_v24 = vadd.s32 1, %v137692_v30 (stack40)
        %v53382_v52 = vadd.s32 %v53379_v22, %v121564_v0 (stack40)
        %v53783_v41 = vor.u32 %v53782_v45, %v53781_v42 (stack47)
        %v54193_v43 = vxor.u32 %v54192_v27, %v54188_v50 (stack48)
        %v54613_v32 = vadd.s32 %v54610_v44, %v54605_v32 (stack40)
        %v52599_v25 = vadd.f32 %v52595_v60, %v52556_v25 (stack53)
        %v120028_v53 = vadd.low.f32.bf16 -1.0, %v52976_v6 (stack53)
        %v54615_v46 = vshll.u32 %v54610_v44, 26 (stack45)
        %v54616_v40 = vshrl.u32 %v54610_v44, 6 (stack46)
        %v53386_v23 = vadd.s32 4, %v53382_v52 (stack40)
        %v53784_v7 = vxor.u32 %v53783_v41, %v53779_v20 (stack48)
        %v54196_v50 = vadd.s32 %v54193_v43, %v54188_v50 (stack40)
        %v54198_v10 = vshll.u32 %v54193_v43, 16 (stack45)
        %v52603_v42 = vmul.f32 %v52599_v25, %v137717_v8 (stack54)
        %v52985_v22 = vmul.f32 2.0, %v120028_v53 (stack54)
        %v54199_v45 = vshrl.u32 %v54193_v43, 16 (stack46)
        %v54617_v27 = vor.u32 %v54616_v40, %v54615_v46 (stack47)
        %v53390_v44 = vadd.s32 %v53386_v23, %v53374_v61 (stack40)
        %v53392_v60 = vshll.u32 %v53386_v23, 13 (stack45)
        %v53393_v6 = vshrl.u32 %v53386_v23, 19 (stack46)
        %v53787_v20 = vadd.s32 %v53784_v7, %v53779_v20 (stack40)
        %v52607_v26 = vadd.f32 %v52603_v42, %v137675_v26 (stack53)
        %v52989_v61 = vadd.f32 -0.99609375, %v52985_v22 (stack53)
        %v53793_v52 = vshll.u32 %v53784_v7, 6 (stack45)
        %v53794_v41 = vshrl.u32 %v53784_v7, 26 (stack46)
        %v53394_v43 = vor.u32 %v53393_v6, %v53392_v60 (stack47)
        %v54200_v25 = vor.u32 %v54199_v45, %v54198_v10 (stack47)
        %v54618_v53 = vxor.u32 %v54617_v27, %v54613_v32 (stack48)
        %v55015_v46 = vadd.s32 %v137688_v9, %v122657_v58 (stack40)
        %v52611_v40 = vmul.f32 %v52607_v26, %v137717_v8 (stack54)
        %v137732_v23 = vmax.f32 %v52989_v61, -0.99609375 (stack55)
        %v53795_v7 = vor.u32 %v53794_v41, %v53793_v52 (stack47)
        %v55037_v30 = vsel /*vm=*/%vm55024_vm9, /*on_true_vy=*/%v55033_v24, /*on_false_vx=*/%v137692_v30 (stack44)
        %v52548_v24 = vsel /*vm=*/%vm52527_vm5, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v53395_v10 = vxor.u32 %v53394_v43, %v53390_v44 (stack48)
        %v54201_v42 = vxor.u32 %v54200_v25, %v54196_v50 (stack48)
        %v137741_v32 = vadd.s32 %v54618_v53, %v54613_v32 (stack40)
        %v52540_v22 = vsel /*vm=*/%vm52527_vm5, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v52544_v31 = vsel /*vm=*/%vm52527_vm5, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v52615_v45 = vadd.f32 %v52611_v40, %v52548_v24 (stack53)
        %v53005_v27 = vxor.u32 2147483648, %v137732_v23 (stack56)
        %v53398_v44 = vadd.s32 %v53395_v10, %v53390_v44 (stack40)
        %v53400_v60 = vshll.u32 %v53395_v10, 15 (stack45)
        %v53401_v6 = vshrl.u32 %v53395_v10, 17 (stack46)
        %v53796_v26 = vxor.u32 %v53795_v7, %v53787_v20 (stack48)
        %v52619_v61 = vmul.f32 %v52615_v45, %v137717_v8 (stack54)
        %v53008_v52 = vmul.f32 %v53005_v27, %v137732_v23 (stack54)
        %v54204_v50 = vadd.s32 %v54201_v42, %v54196_v50 (stack40)
        %vm55019_vm10 = vcmp.lt.u32.totalorder %v55015_v46, %v137688_v9 (stack43)
        %v53402_v41 = vor.u32 %v53401_v6, %v53400_v60 (stack47)
        %v53799_v43 = vadd.s32 %v53796_v26, %v121569_v1 (stack40)
        %v54210_v25 = vshll.u32 %v54201_v42, 24 (stack45)
        %v54211_v40 = vshrl.u32 %v54201_v42, 8 (stack46)
        %v52623_v7 = vadd.f32 %v52619_v61, %v52544_v31 (stack53)
        %v53010_v24 = vadd.f32 1.0, %v53008_v52 (stack57)
        %v53791_v20 = vadd.s32 %v53787_v20, %v121574_v2 (stack40)
        %v55054_v10 = vadd.s32 %v55015_v46, %v121569_v1 (stack40)
        %v53013_v42 = vmul.f32 -0.5, %v53008_v52 (stack59)
        %v53403_v31 = vxor.u32 %v53402_v41, %v53398_v44 (stack48)
        %v53803_v45 = vadd.s32 3, %v53799_v43 (stack40)
        %v54212_v27 = vor.u32 %v54211_v40, %v54210_v25 (stack47)
        %v52627_v60 = vmul.f32 %v52623_v7, %v137717_v8 (stack54)
        %120881 = vlog2.f32 %v53010_v24 (stack58)
        %v53016_v6 = vand.u32 2147483647, %v53008_v52 (stack60)
        %v54627_v26 = vshll.u32 %v54618_v53, 6 (stack45)
        %v53406_v44 = vadd.s32 %v53403_v31, %v53398_v44 (stack40)
        %v53408_v61 = vshll.u32 %v53403_v31, 26 (stack45)
        %v53409_v41 = vshrl.u32 %v53403_v31, 6 (stack46)
        %v53807_v43 = vadd.s32 %v53803_v45, %v53791_v20 (stack40)
        %v52631_v22 = vadd.f32 %v52627_v60, %v52540_v22 (stack53)
        %v53809_v25 = vshll.u32 %v53803_v45, 17 (stack45)
        %v53810_v40 = vshrl.u32 %v53803_v45, 15 (stack46)
        %v54208_v7 = vadd.s32 %v54204_v50, %v121564_v0 (stack40)
        %v53014_v24 = vadd.f32 1.0, %v53013_v42 (stack61)
        %v53410_v20 = vor.u32 %v53409_v41, %v53408_v61 (stack47)
        %v54213_v50 = vxor.u32 %v54212_v27, %v54204_v50 (stack48)
        %v54628_v53 = vshrl.u32 %v54618_v53, 26 (stack46)
        %v52635_v42 = vmul.f32 %v52631_v22, %v137717_v8 (stack54)
        %v53811_v31 = vor.u32 %v53810_v40, %v53809_v25 (stack47)
        %v55041_v45 = vadd.s32 1, %v55037_v30 (stack40)
        %v55060_v27 = vshll.u32 %v55054_v10, 13 (stack45)
        %vm137761_vm11 = vcmp.eq.f32.partialorder %v52500_v12, 1.0 (stack68)
        %v53411_v60 = vxor.u32 %v53410_v20, %v53406_v44 (stack48)
        %v54216_v61 = vadd.s32 %v54213_v50, %v121574_v2 (stack40)
        %v54629_v26 = vor.u32 %v54628_v53, %v54627_v26 (stack47)
        %v55061_v41 = vshrl.u32 %v55054_v10, 19 (stack46)
        %v52639_v54 = vadd.f32 %v52635_v42, %v137670_v54 (stack53)
        %v53812_v22 = vxor.u32 %v53811_v31, %v53807_v43 (stack48)
        %v55045_v9 = vsel /*vm=*/%vm55019_vm10, /*on_true_vy=*/%v55041_v45, /*on_false_vx=*/%v55037_v30 (stack44)
        %v137771_v46 = vadd.s32 %v157388_v55, %v157091_v37 (stack40)
        %vm137773_vm12 = vcmp.lt.f32.partialorder %v53016_v6, 0.0004427343 (stack62)
        %v53414_v6 = vadd.s32 %v53411_v60, %v53406_v44 (stack40)
        %v53420_v44 = vshll.u32 %v53411_v60, 6 (stack45)
        %v53421_v25 = vshrl.u32 %v53411_v60, 26 (stack46)
        %v54220_v40 = vadd.s32 2, %v54216_v61 (stack40)
        %v52643_v8 = vmul.f32 %v52639_v54, %v137717_v8 (stack54)
        %v53815_v43 = vadd.s32 %v53812_v22, %v53807_v43 (stack40)
        %v53817_v20 = vshll.u32 %v53812_v22, 29 (stack45)
        %v53818_v50 = vshrl.u32 %v53812_v22, 3 (stack46)
        %v53015_v52 = vmul.f32 %v53014_v24, %v53008_v52 (stack63)
        %v53422_v24 = vor.u32 %v53421_v25, %v53420_v44 (stack47)
        %v54224_v7 = vadd.s32 %v54220_v40, %v54208_v7 (stack40)
        %v54226_v53 = vshll.u32 %v54220_v40, 13 (stack45)
        %v52647_v21 = vadd.f32 %v52643_v8, %v137661_v21 (stack53)
        %v53819_v42 = vor.u32 %v53818_v50, %v53817_v20 (stack47)
        %v54227_v31 = vshrl.u32 %v54220_v40, 19 (stack46)
        %v54630_v45 = vxor.u32 %v54629_v26, %v137741_v32 (stack48)
        %v53423_v60 = vxor.u32 %v53422_v24, %v53414_v6 (stack48)
        %v54625_v32 = vadd.s32 %v137741_v32, %v121569_v1 (stack40)
        %v55050_v61 = vadd.s32 %v55045_v9, %v121574_v2 (stack40)
        %v55062_v27 = vor.u32 %v55061_v41, %v55060_v27 (stack47)
        %v52651_v29 = vmul.f32 %v52647_v21, %v137562_v29 (stack54)
        %v53820_v26 = vxor.u32 %v53819_v42, %v53815_v43 (stack48)
        %v54228_v41 = vor.u32 %v54227_v31, %v54226_v53 (stack47)
        %v54633_v54 = vadd.s32 %v54630_v45, %v121564_v0 (stack40)
        %v120882_v22 = vpop.eup %120881 (stack64)
        %v53418_v9 = vadd.s32 %v53414_v6, %v121564_v0 (stack40)
        %v53426_v6 = vadd.s32 %v53423_v60, %v121574_v2 (stack40)
        %v55058_v10 = vadd.s32 %v55054_v10, %v55050_v61 (stack40)
        %vm55485_vm13 = vcmp.lt.u32.totalorder %v137771_v46, %v157091_v37 (stack43)
        %v52655_v56 = vsel /*vm=*/%vm137761_vm11, /*on_true_vy=*/%v137646_v56, /*on_false_vx=*/%v52651_v29 (stack44)
        %v53012_v12 = vmul.f32 0.6931472, %v120882_v22 (stack65)
        %v53823_v44 = vadd.s32 %v53820_v26, %v53815_v43 (stack40)
        %v53825_v25 = vshll.u32 %v53820_v26, 16 (stack45)
        %v52659_v40 = vmul.f32 1.4140625, %v52655_v56 (stack54)
        %v53430_v8 = vadd.s32 5, %v53426_v6 (stack40)
        %v53826_v43 = vshrl.u32 %v53820_v26, 16 (stack46)
        %v54229_v20 = vxor.u32 %v54228_v41, %v54224_v7 (stack48)
        %v53018_v30 = vsel /*vm=*/%vm137773_vm12, /*on_true_vy=*/%v53015_v52, /*on_false_vx=*/%v53012_v12 (stack66)
        %v54637_v50 = vadd.s32 1, %v54633_v54 (stack40)
        %v55063_v52 = vxor.u32 %v55062_v27, %v55058_v10 (stack48)
        %v55490_v24 = vadd.s32 %v157389_v34, %v157094_v36 (stack40)
        %v52662_v53 = vpack.c.bf16 %v157387_v11, %v52659_v40 (stack81)
        %v137797_v21 = vxor.u32 2147483648, %v53018_v30 (stack56)
        %v53432_v42 = vxor.u32 %v53430_v8, %v53418_v9 (stack48)
        %v53827_v31 = vor.u32 %v53826_v43, %v53825_v25 (stack47)
        %v54232_v7 = vadd.s32 %v54229_v20, %v54224_v7 (stack40)
        %v54234_v45 = vshll.u32 %v54229_v20, 15 (stack45)
        %v54235_v60 = vshrl.u32 %v54229_v20, 17 (stack46)
        %v54641_v32 = vadd.s32 %v54637_v50, %v54625_v32 (stack40)
        %120023 = vst [vmem:[%s123356_s30 + $0x3b4] sm:$0xf] /*vst_source=*/%v52662_v53 (stack83)
        %vm53022_vm14 = vcmp.lt.f32.partialorder %v137797_v21, 5.0 (stack68)
        %120883 = vrsqrt.f32 %v137797_v21 (stack67)
        %v53828_v61 = vxor.u32 %v53827_v31, %v53823_v44 (stack48)
        %v52995_v27 = vand.u32 2147483647, %v137732_v23 (stack77)
        %v54236_v29 = vor.u32 %v54235_v60, %v54234_v45 (stack47)
        %v137806_v26 = vsel /*vm=*/%vm53022_vm14, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v137809_v41 = vadd.f32 -2.5, %v137797_v21 (stack53)
        %v53831_v54 = vadd.s32 %v53828_v61, %v53823_v44 (stack40)
        %v137813_v22 = vadd.s32 %v137771_v46, %v122657_v58 (stack40)
        %v137818_v9 = vsel /*vm=*/%vm53022_vm14, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v137823_v6 = vsel /*vm=*/%vm53022_vm14, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v53433_v56 = vand.u32.u8 255, %v53432_v42 (stack49)
        %v53837_v12 = vshll.u32 %v53828_v61, 24 (stack45)
        %v137828_v44 = vsel /*vm=*/%vm53022_vm14, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v53838_v25 = vshrl.u32 %v53828_v61, 8 (stack46)
        %v54237_v40 = vxor.u32 %v54236_v29, %v54232_v7 (stack48)
        %v54643_v8 = vshll.u32 %v54637_v50, 17 (stack45)
        %v53434_v43 = vand.u32 65535, %v53433_v56 (stack50)
        %v54644_v20 = vshrl.u32 %v54637_v50, 15 (stack46)
        %v55066_v10 = vadd.s32 %v55063_v52, %v55058_v10 (stack40)
        %v55068_v30 = vshll.u32 %v55063_v52, 15 (stack45)
        %vm53067_vm15 = vcmp.eq.f32.partialorder %v137797_v21, inf (stack70)
        %v53839_v50 = vor.u32 %v53838_v25, %v53837_v12 (stack47)
        %v54240_v53 = vadd.s32 %v54237_v40, %v54232_v7 (stack40)
        %v54242_v42 = vshll.u32 %v54237_v40, 26 (stack45)
        %v54243_v31 = vshrl.u32 %v54237_v40, 6 (stack46)
        %v53435_v7 = vshrl.u32 %v53434_v43, 1 (stack51)
        %v54645_v45 = vor.u32 %v54644_v20, %v54643_v8 (stack47)
        %v55069_v52 = vshrl.u32 %v55063_v52, 17 (stack46)
        %v55494_v60 = vadd.s32 1, %v55490_v24 (stack40)
        %vm53069_vm0 = vcmp.eq.f32.partialorder %v137797_v21, 0.0 (stack71)
        %v53840_v61 = vxor.u32 %v53839_v50, %v53831_v54 (stack48)
        %v54244_v29 = vor.u32 %v54243_v31, %v54242_v42 (stack47)
        %vm55480_vm1 = vcmp.lt.u32.totalorder %v137813_v22, %v137771_v46 (stack43)
        %v137836_v55 = vadd.s32 %v157388_v55, %v157095_v13 (stack40)
        %v53436_v56 = vor.u32 16256, %v53435_v7 (stack47)
        %v54646_v12 = vxor.u32 %v54645_v45, %v54641_v32 (stack48)
        %v55070_v25 = vor.u32 %v55069_v52, %v55068_v30 (stack47)
        %v55498_v24 = vsel /*vm=*/%vm55485_vm13, /*on_true_vy=*/%v55494_v60, /*on_false_vx=*/%v55490_v24 (stack44)
        %v53070_v40 = vand.u32 2147483648, %v137797_v21 (stack72)
        %v53835_v54 = vadd.s32 %v53831_v54, %v121569_v1 (stack40)
        %v53843_v8 = vadd.s32 %v53840_v61, %v121564_v0 (stack40)
        %v54245_v43 = vxor.u32 %v54244_v29, %v54240_v53 (stack48)
        %v53437_v20 = vand.u32.u16 65535, %v53436_v56 (stack52)
        %v54649_v32 = vadd.s32 %v54646_v12, %v54641_v32 (stack40)
        %v54651_v30 = vshll.u32 %v54646_v12, 29 (stack45)
        %v54652_v50 = vshrl.u32 %v54646_v12, 3 (stack46)
        %v120884_v42 = vpop.eup %120883 (stack73)
        %v53847_v31 = vadd.s32 4, %v53843_v8 (stack40)
        %v54248_v53 = vadd.s32 %v54245_v43, %v54240_v53 (stack40)
        %v54254_v7 = vshll.u32 %v54245_v43, 6 (stack45)
        %v54255_v45 = vshrl.u32 %v54245_v43, 26 (stack46)
        %v53066_v52 = vmul.f32 %v120884_v42, %v137797_v21 (stack74)
        %v120030_v60 = vadd.low.f32.bf16 -1.0, %v53437_v20 (stack53)
        %v54653_v61 = vor.u32 %v54652_v50, %v54651_v30 (stack47)
        %v55071_v29 = vxor.u32 %v55070_v25, %v55066_v10 (stack48)
        %v53851_v56 = vadd.s32 %v53847_v31, %v53835_v54 (stack40)
        %v53853_v12 = vshll.u32 %v53847_v31, 13 (stack45)
        %v53854_v25 = vshrl.u32 %v53847_v31, 19 (stack46)
        %v55502_v54 = vadd.s32 1, %v55498_v24 (stack40)
        %v53068_v8 = vsel /*vm=*/%vm53067_vm15, /*on_true_vy=*/%v137797_v21, /*on_false_vx=*/%v53066_v52 (stack75)
        %v53446_v43 = vmul.f32 2.0, %v120030_v60 (stack54)
        %v54256_v20 = vor.u32 %v54255_v45, %v54254_v7 (stack47)
        %v54654_v30 = vxor.u32 %v54653_v61, %v54649_v32 (stack48)
        %v53071_v40 = vsel /*vm=*/%vm53069_vm0, /*on_true_vy=*/%v53070_v40, /*on_false_vx=*/%v53068_v8 (stack76)
        %v53855_v50 = vor.u32 %v53854_v25, %v53853_v12 (stack47)
        %v55074_v10 = vadd.s32 %v55071_v29, %v55066_v10 (stack40)
        %v55076_v42 = vshll.u32 %v55071_v29, 26 (stack45)
        %v53074_v31 = vadd.f32 -3.0, %v53071_v40 (stack53)
        %v53450_v7 = vadd.f32 -0.99609375, %v53446_v43 (stack53)
        %v54257_v45 = vxor.u32 %v54256_v20, %v54248_v53 (stack48)
        %v54657_v32 = vadd.s32 %v54654_v30, %v54649_v32 (stack40)
        %v53856_v52 = vxor.u32 %v53855_v50, %v53851_v56 (stack48)
        %v54659_v60 = vshll.u32 %v54654_v30, 16 (stack45)
        %v54660_v61 = vshrl.u32 %v54654_v30, 16 (stack46)
        %v55077_v29 = vshrl.u32 %v55071_v29, 6 (stack46)
        %v137853_v41 = vsel /*vm=*/%vm53022_vm14, /*on_true_vy=*/%v137809_v41, /*on_false_vx=*/%v53074_v31 (stack44)
        %v137855_v12 = vmax.f32 %v53450_v7, -0.99609375 (stack55)
        %v54260_v25 = vadd.s32 %v54257_v45, %v121569_v1 (stack40)
        %v55506_v46 = vsel /*vm=*/%vm55480_vm1, /*on_true_vy=*/%v55502_v54, /*on_false_vx=*/%v55498_v24 (stack44)
        %v53082_v44 = vmul.f32 %v137853_v41, %v137828_v44 (stack54)
        %v53859_v24 = vadd.s32 %v53856_v52, %v53851_v56 (stack40)
        %v53861_v56 = vshll.u32 %v53856_v52, 15 (stack45)
        %v53862_v54 = vshrl.u32 %v53856_v52, 17 (stack46)
        %v53055_v8 = vsel /*vm=*/%vm53022_vm14, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v53466_v43 = vxor.u32 2147483648, %v137855_v12 (stack56)
        %v54252_v53 = vadd.s32 %v54248_v53, %v121574_v2 (stack40)
        %v54264_v20 = vadd.s32 3, %v54260_v25 (stack40)
        %v53086_v30 = vadd.f32 %v53082_v44, %v53055_v8 (stack53)
        %v53863_v40 = vor.u32 %v53862_v54, %v53861_v56 (stack47)
        %v54661_v50 = vor.u32 %v54660_v61, %v54659_v60 (stack47)
        %v55078_v42 = vor.u32 %v55077_v29, %v55076_v42 (stack47)
        %v53469_v31 = vmul.f32 %v53466_v43, %v137855_v12 (stack54)
        %v54268_v7 = vadd.s32 %v54264_v20, %v54252_v53 (stack40)
        %v54270_v45 = vshll.u32 %v54264_v20, 17 (stack45)
        %v55515_v22 = vadd.s32 %v137813_v22, %v121569_v1 (stack40)
        %v53090_v52 = vmul.f32 %v53086_v30, %v137853_v41 (stack54)
        %v53864_v60 = vxor.u32 %v53863_v40, %v53859_v24 (stack48)
        %v54271_v61 = vshrl.u32 %v54264_v20, 15 (stack46)
        %v54662_v29 = vxor.u32 %v54661_v50, %v54657_v32 (stack48)
        %v53051_v25 = vsel /*vm=*/%vm53022_vm14, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v53471_v44 = vadd.f32 1.0, %v53469_v31 (stack57)
        %v53474_v56 = vmul.f32 -0.5, %v53469_v31 (stack59)
        %v55079_v54 = vxor.u32 %v55078_v42, %v55074_v10 (stack48)
        %v53094_v8 = vadd.f32 %v53090_v52, %v53051_v25 (stack53)
        %v53867_v24 = vadd.s32 %v53864_v60, %v53859_v24 (stack40)
        %v53869_v43 = vshll.u32 %v53864_v60, 26 (stack45)
        %v53870_v53 = vshrl.u32 %v53864_v60, 6 (stack46)
        %v53047_v20 = vsel /*vm=*/%vm53022_vm14, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %120885 = vlog2.f32 %v53471_v44 (stack58)
        %v54272_v30 = vor.u32 %v54271_v61, %v54270_v45 (stack47)
        %v55521_v40 = vshll.u32 %v55515_v22, 13 (stack45)
        %v53098_v50 = vmul.f32 %v53094_v8, %v137853_v41 (stack54)
        %v53871_v42 = vor.u32 %v53870_v53, %v53869_v43 (stack47)
        %v54665_v32 = vadd.s32 %v54662_v29, %v54657_v32 (stack40)
        %v54671_v45 = vshll.u32 %v54662_v29, 24 (stack45)
        %v53475_v52 = vadd.f32 1.0, %v53474_v56 (stack61)
        %v54273_v60 = vxor.u32 %v54272_v30, %v54268_v7 (stack48)
        %v54672_v61 = vshrl.u32 %v54662_v29, 8 (stack46)
        %v55082_v10 = vadd.s32 %v55079_v54, %v55074_v10 (stack40)
        %v53102_v29 = vadd.f32 %v53098_v50, %v53047_v20 (stack53)
        %v53477_v25 = vand.u32 2147483647, %v53469_v31 (stack60)
        %v53872_v44 = vxor.u32 %v53871_v42, %v53867_v24 (stack48)
        %v55088_v56 = vshll.u32 %v55079_v54, 6 (stack45)
        %v54276_v7 = vadd.s32 %v54273_v60, %v54268_v7 (stack40)
        %v54278_v8 = vshll.u32 %v54273_v60, 29 (stack45)
        %v54279_v43 = vshrl.u32 %v54273_v60, 3 (stack46)
        %v54673_v53 = vor.u32 %v54672_v61, %v54671_v45 (stack47)
        %v53106_v20 = vmul.f32 %v53102_v29, %v137853_v41 (stack54)
        %v53875_v24 = vadd.s32 %v53872_v44, %v53867_v24 (stack40)
        %v53881_v30 = vshll.u32 %v53872_v44, 6 (stack45)
        %v53882_v50 = vshrl.u32 %v53872_v44, 26 (stack46)
        %v53476_v31 = vmul.f32 %v53475_v52, %v53469_v31 (stack63)
        %v54280_v42 = vor.u32 %v54279_v43, %v54278_v8 (stack47)
        %v54674_v45 = vxor.u32 %v54673_v53, %v54665_v32 (stack48)
        %v55089_v54 = vshrl.u32 %v55079_v54, 26 (stack46)
        %v53110_v6 = vadd.f32 %v53106_v20, %v137823_v6 (stack53)
        %vm137881_vm2 = vcmp.lt.f32.partialorder %v53477_v25, 0.0004427343 (stack62)
        %v53883_v60 = vor.u32 %v53882_v50, %v53881_v30 (stack47)
        %v54669_v32 = vadd.s32 %v54665_v32, %v121564_v0 (stack40)
        %v55511_v46 = vadd.s32 %v55506_v46, %v121574_v2 (stack40)
        %v54281_v61 = vxor.u32 %v54280_v42, %v54276_v7 (stack48)
        %v54677_v29 = vadd.s32 %v54674_v45, %v121574_v2 (stack40)
        %v55090_v25 = vor.u32 %v55089_v54, %v55088_v56 (stack47)
        %v55522_v44 = vshrl.u32 %v55515_v22, 19 (stack46)
        %v53114_v56 = vmul.f32 %v53110_v6, %v137853_v41 (stack54)
        %v53879_v8 = vadd.s32 %v53875_v24, %v121564_v0 (stack40)
        %v53884_v43 = vxor.u32 %v53883_v60, %v53875_v24 (stack48)
        %v55519_v22 = vadd.s32 %v55515_v22, %v55511_v46 (stack40)
        %v54284_v7 = vadd.s32 %v54281_v61, %v54276_v7 (stack40)
        %v54286_v53 = vshll.u32 %v54281_v61, 16 (stack45)
        %v54287_v20 = vshrl.u32 %v54281_v61, 16 (stack46)
        %v54681_v24 = vadd.s32 2, %v54677_v29 (stack40)
        %v53118_v9 = vadd.f32 %v53114_v56, %v137818_v9 (stack53)
        %v53887_v30 = vadd.s32 %v53884_v43, %v121574_v2 (stack40)
        %v55091_v50 = vxor.u32 %v55090_v25, %v55082_v10 (stack48)
        %v55523_v40 = vor.u32 %v55522_v44, %v55521_v40 (stack47)
        %v54288_v42 = vor.u32 %v54287_v20, %v54286_v53 (stack47)
        %v54685_v45 = vadd.s32 %v54681_v24, %v54669_v32 (stack40)
        %v54687_v54 = vshll.u32 %v54681_v24, 13 (stack45)
        %v54688_v6 = vshrl.u32 %v54681_v24, 19 (stack46)
        %v120886_v60 = vpop.eup %120885 (stack64)
        %v53122_v32 = vmul.f32 %v53118_v9, %v137853_v41 (stack54)
        %v53891_v46 = vadd.s32 5, %v53887_v30 (stack40)
        %v55094_v61 = vadd.s32 %v55091_v50, %v121564_v0 (stack40)
        %v137894_v29 = vxor.u32 %v55523_v40, %v55519_v22 (stack48)
        %v53473_v25 = vmul.f32 0.6931472, %v120886_v60 (stack65)
        %v54289_v44 = vxor.u32 %v54288_v42, %v54284_v7 (stack48)
        %v54689_v56 = vor.u32 %v54688_v6, %v54687_v54 (stack47)
        %v55086_v10 = vadd.s32 %v55082_v10, %v121569_v1 (stack40)
        %v53126_v26 = vadd.f32 %v53122_v32, %v137806_v26 (stack53)
        %v53893_v8 = vxor.u32 %v53891_v46, %v53879_v8 (stack48)
        %v55098_v43 = vadd.s32 1, %v55094_v61 (stack40)
        %v137899_v22 = vadd.s32 %v137894_v29, %v55519_v22 (stack40)
        %v53479_v31 = vsel /*vm=*/%vm137881_vm2, /*on_true_vy=*/%v53476_v31, /*on_false_vx=*/%v53473_v25 (stack66)
        %v54292_v52 = vadd.s32 %v54289_v44, %v54284_v7 (stack40)
        %v54298_v7 = vshll.u32 %v54289_v44, 24 (stack45)
        %v54299_v53 = vshrl.u32 %v54289_v44, 8 (stack46)
        %v53130_v20 = vmul.f32 %v53126_v26, %v137853_v41 (stack54)
        %v137904_v24 = vxor.u32 2147483648, %v53479_v31 (stack56)
        %v54690_v9 = vxor.u32 %v54689_v56, %v54685_v45 (stack48)
        %v53031_v30 = vsel /*vm=*/%vm53022_vm14, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v54300_v50 = vor.u32 %v54299_v53, %v54298_v7 (stack47)
        %v55102_v40 = vadd.s32 %v55098_v43, %v55086_v10 (stack40)
        %v53003_v42 = vmul.f32 inf, %v137732_v23 (stack54)
        %v53134_v54 = vadd.f32 %v53130_v20, %v53031_v30 (stack53)
        %vm53483_vm3 = vcmp.lt.f32.partialorder %v137904_v24, 5.0 (stack68)
        %120887 = vrsqrt.f32 %v137904_v24 (stack67)
        %vm137914_vm4 = vcmp.eq.f32.partialorder %v52995_v27, 1.0 (stack68)
        %v53027_v21 = vsel /*vm=*/%vm53022_vm14, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v53894_v6 = vand.u32.u8 255, %v53893_v8 (stack49)
        %v54301_v60 = vxor.u32 %v54300_v50, %v54292_v52 (stack48)
        %v53138_v41 = vmul.f32 %v53134_v54, %v137853_v41 (stack54)
        %v53456_v32 = vand.u32 2147483647, %v137855_v12 (stack77)
        %v54296_v46 = vadd.s32 %v54292_v52, %v121569_v1 (stack40)
        %v137926_v61 = vadd.s32 %v137836_v55, %v122657_v58 (stack40)
        %v137931_v25 = vsel /*vm=*/%vm53483_vm3, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v137934_v44 = vadd.f32 -2.5, %v137904_v24 (stack53)
        %v54304_v56 = vadd.s32 %v54301_v60, %v121564_v0 (stack40)
        %v55104_v10 = vshll.u32 %v55098_v43, 17 (stack45)
        %v53142_v26 = vadd.f32 %v53138_v41, %v53027_v21 (stack53)
        %v137940_v8 = vsel /*vm=*/%vm53483_vm3, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v137945_v31 = vsel /*vm=*/%vm53483_vm3, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v137950_v52 = vsel /*vm=*/%vm53483_vm3, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v53895_v7 = vand.u32 65535, %v53894_v6 (stack50)
        %v54308_v53 = vadd.s32 4, %v54304_v56 (stack40)
        %v54693_v45 = vadd.s32 %v54690_v9, %v54685_v45 (stack40)
        %v54695_v20 = vshll.u32 %v54690_v9, 15 (stack45)
        %v53146_v23 = vmul.f32 %v53142_v26, %v137732_v23 (stack54)
        %v54696_v9 = vshrl.u32 %v54690_v9, 17 (stack46)
        %v55105_v43 = vshrl.u32 %v55098_v43, 15 (stack46)
        %v55529_v30 = vshll.u32 %v137894_v29, 15 (stack45)
        %v53896_v50 = vshrl.u32 %v53895_v7, 1 (stack51)
        %v54312_v54 = vadd.s32 %v54308_v53, %v54296_v46 (stack40)
        %v54314_v21 = vshll.u32 %v54308_v53, 13 (stack45)
        %v54315_v6 = vshrl.u32 %v54308_v53, 19 (stack46)
        %v53150_v42 = vsel /*vm=*/%vm137914_vm4, /*on_true_vy=*/%v53003_v42, /*on_false_vx=*/%v53146_v23 (stack44)
        %v54697_v27 = vor.u32 %v54696_v9, %v54695_v20 (stack47)
        %v55106_v60 = vor.u32 %v55105_v43, %v55104_v10 (stack47)
        %v55530_v29 = vshrl.u32 %v137894_v29, 17 (stack46)
        %v53154_v41 = vmul.f32 1.4140625, %v53150_v42 (stack54)
        %v53897_v46 = vor.u32 16256, %v53896_v50 (stack47)
        %v54316_v56 = vor.u32 %v54315_v6, %v54314_v21 (stack47)
        %vm55946_vm5 = vcmp.lt.u32.totalorder %v137836_v55, %v157095_v13 (stack43)
        %vm53528_vm6 = vcmp.eq.f32.partialorder %v137904_v24, inf (stack70)
        %v54698_v10 = vxor.u32 %v54697_v27, %v54693_v45 (stack48)
        %v55107_v26 = vxor.u32 %v55106_v60, %v55102_v40 (stack48)
        %v137962_v34 = vadd.s32 %v157389_v34, %v157100_v14 (stack40)
        %v53157_v7 = vpack.c.bf16 %v157387_v11, %v53154_v41 (stack81)
        %v53898_v53 = vand.u32.u16 65535, %v53897_v46 (stack52)
        %v54317_v20 = vxor.u32 %v54316_v56, %v54312_v54 (stack48)
        %v55531_v23 = vor.u32 %v55530_v29, %v55529_v30 (stack47)
        %v54701_v45 = vadd.s32 %v54698_v10, %v54693_v45 (stack40)
        %v54703_v9 = vshll.u32 %v54698_v10, 26 (stack45)
        %v54704_v43 = vshrl.u32 %v54698_v10, 6 (stack46)
        %v55110_v40 = vadd.s32 %v55107_v26, %v55102_v40 (stack40)
        %v120888_v30 = vpop.eup %120887 (stack73)
        %120029 = vst [vmem:[%s123356_s30 + $0x38] sm:$0xf] /*vst_source=*/%v53157_v7 (stack83)
        %v120032_v50 = vadd.low.f32.bf16 -1.0, %v53898_v53 (stack53)
        %v54320_v54 = vadd.s32 %v54317_v20, %v54312_v54 (stack40)
        %v54322_v21 = vshll.u32 %v54317_v20, 15 (stack45)
        %v54323_v6 = vshrl.u32 %v54317_v20, 17 (stack46)
        %v53527_v42 = vmul.f32 %v120888_v30, %v137904_v24 (stack74)
        %v54705_v27 = vor.u32 %v54704_v43, %v54703_v9 (stack47)
        %v55112_v60 = vshll.u32 %v55107_v26, 29 (stack45)
        %v55113_v29 = vshrl.u32 %v55107_v26, 3 (stack46)
        %v53531_v41 = vand.u32 2147483648, %v137904_v24 (stack72)
        %v53907_v46 = vmul.f32 2.0, %v120032_v50 (stack54)
        %v54324_v56 = vor.u32 %v54323_v6, %v54322_v21 (stack47)
        %v55532_v10 = vxor.u32 %v55531_v23, %v137899_v22 (stack48)
        %v53529_v26 = vsel /*vm=*/%vm53528_vm6, /*on_true_vy=*/%v137904_v24, /*on_false_vx=*/%v53527_v42 (stack75)
        %vm53530_vm7 = vcmp.eq.f32.partialorder %v137904_v24, 0.0 (stack71)
        %v54706_v7 = vxor.u32 %v54705_v27, %v54701_v45 (stack48)
        %v55114_v53 = vor.u32 %v55113_v29, %v55112_v60 (stack47)
        %v53532_v20 = vsel /*vm=*/%vm53530_vm7, /*on_true_vy=*/%v53531_v41, /*on_false_vx=*/%v53529_v26 (stack76)
        %v53911_v23 = vadd.f32 -0.99609375, %v53907_v46 (stack53)
        %v54325_v9 = vxor.u32 %v54324_v56, %v54320_v54 (stack48)
        %v137974_v22 = vadd.s32 %v55532_v10, %v137899_v22 (stack40)
        %v53535_v43 = vadd.f32 -3.0, %v53532_v20 (stack53)
        %v54709_v45 = vadd.s32 %v54706_v7, %v54701_v45 (stack40)
        %v54715_v30 = vshll.u32 %v54706_v7, 6 (stack45)
        %v54716_v50 = vshrl.u32 %v54706_v7, 26 (stack46)
        %v137976_v21 = vmax.f32 %v53911_v23, -0.99609375 (stack55)
        %v54328_v54 = vadd.s32 %v54325_v9, %v54320_v54 (stack40)
        %v54330_v6 = vshll.u32 %v54325_v9, 26 (stack45)
        %v54331_v42 = vshrl.u32 %v54325_v9, 6 (stack46)
        %v53520_v27 = vsel /*vm=*/%vm53483_vm3, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v137984_v44 = vsel /*vm=*/%vm53483_vm3, /*on_true_vy=*/%v137934_v44, /*on_false_vx=*/%v53535_v43 (stack44)
        %v54717_v60 = vor.u32 %v54716_v50, %v54715_v30 (stack47)
        %v55115_v29 = vxor.u32 %v55114_v53, %v55110_v40 (stack48)
        %v53512_v41 = vsel /*vm=*/%vm53483_vm3, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v53516_v46 = vsel /*vm=*/%vm53483_vm3, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v53543_v56 = vmul.f32 %v137984_v44, %v53520_v27 (stack54)
        %v53927_v26 = vxor.u32 2147483648, %v137976_v21 (stack56)
        %v54332_v7 = vor.u32 %v54331_v42, %v54330_v6 (stack47)
        %v54718_v53 = vxor.u32 %v54717_v60, %v54709_v45 (stack48)
        %v55118_v40 = vadd.s32 %v55115_v29, %v55110_v40 (stack40)
        %v137996_v20 = vadd.s32 %v137926_v61, %v121569_v1 (stack40)
        %v53547_v23 = vadd.f32 %v53543_v56, %v53516_v46 (stack53)
        %v53930_v9 = vmul.f32 %v53927_v26, %v137976_v21 (stack54)
        %v54713_v43 = vadd.s32 %v54709_v45, %v121574_v2 (stack40)
        %v55120_v45 = vshll.u32 %v55115_v29, 16 (stack45)
        %v54333_v30 = vxor.u32 %v54332_v7, %v54328_v54 (stack48)
        %v54721_v50 = vadd.s32 %v54718_v53, %v121569_v1 (stack40)
        %v55121_v6 = vshrl.u32 %v55115_v29, 16 (stack46)
        %v55537_v42 = vshll.u32 %v55532_v10, 26 (stack45)
        %v53551_v27 = vmul.f32 %v53547_v23, %v137984_v44 (stack54)
        %v53932_v60 = vadd.f32 1.0, %v53930_v9 (stack57)
        %v53935_v29 = vmul.f32 -0.5, %v53930_v9 (stack59)
        %v55538_v10 = vshrl.u32 %v55532_v10, 6 (stack46)
        %v54336_v54 = vadd.s32 %v54333_v30, %v54328_v54 (stack40)
        %v54342_v46 = vshll.u32 %v54333_v30, 6 (stack45)
        %v54343_v56 = vshrl.u32 %v54333_v30, 26 (stack46)
        %v54725_v26 = vadd.s32 3, %v54721_v50 (stack40)
        %vm55941_vm8 = vcmp.lt.u32.totalorder %v137926_v61, %v137836_v55 (stack43)
        %v53555_v41 = vadd.f32 %v53551_v27, %v53512_v41 (stack53)
        %120889 = vlog2.f32 %v53932_v60 (stack58)
        %v55955_v7 = vadd.s32 1, %v137962_v34 (stack40)
        %v55982_v53 = vshll.u32 %v137996_v20, 13 (stack45)
        %v53938_v23 = vand.u32 2147483647, %v53930_v9 (stack60)
        %v54344_v30 = vor.u32 %v54343_v56, %v54342_v46 (stack47)
        %v54729_v43 = vadd.s32 %v54725_v26, %v54713_v43 (stack40)
        %v54731_v50 = vshll.u32 %v54725_v26, 17 (stack45)
        %v53559_v27 = vmul.f32 %v53555_v41, %v137984_v44 (stack54)
        %v53936_v60 = vadd.f32 1.0, %v53935_v29 (stack61)
        %v54732_v29 = vshrl.u32 %v54725_v26, 15 (stack46)
        %v55122_v45 = vor.u32 %v55121_v6, %v55120_v45 (stack47)
        %v54340_v6 = vadd.s32 %v54336_v54, %v121564_v0 (stack40)
        %v54345_v54 = vxor.u32 %v54344_v30, %v54336_v54 (stack48)
        %v55539_v42 = vor.u32 %v55538_v10, %v55537_v42 (stack47)
        %v55959_v34 = vsel /*vm=*/%vm55946_vm5, /*on_true_vy=*/%v55955_v7, /*on_false_vx=*/%v137962_v34 (stack44)
        %v53563_v52 = vadd.f32 %v53559_v27, %v137950_v52 (stack53)
        %v54733_v10 = vor.u32 %v54732_v29, %v54731_v50 (stack47)
        %v55123_v46 = vxor.u32 %v55122_v45, %v55118_v40 (stack48)
        %v55983_v56 = vshrl.u32 %v137996_v20, 19 (stack46)
        %v54348_v26 = vadd.s32 %v54345_v54, %v121574_v2 (stack40)
        %v55540_v41 = vxor.u32 %v55539_v42, %v137974_v22 (stack48)
        %v55963_v7 = vadd.s32 1, %v55959_v34 (stack40)
        %v157412_v30 = vld [vmem:[#allocation135_spill] sm:$0xff] (stack84)
        %v138018_v50 = vadd.s32 %v157412_v30, %v122651_v47 (stack40)
        %v53567_v27 = vmul.f32 %v53563_v52, %v137984_v44 (stack54)
        %v54734_v29 = vxor.u32 %v54733_v10, %v54729_v43 (stack48)
        %v55126_v40 = vadd.s32 %v55123_v46, %v55118_v40 (stack40)
        %v55132_v45 = vshll.u32 %v55123_v46, 24 (stack45)
        %v54352_v54 = vadd.s32 5, %v54348_v26 (stack40)
        %v55133_v42 = vshrl.u32 %v55123_v46, 8 (stack46)
        %v55543_v22 = vadd.s32 %v55540_v41, %v137974_v22 (stack40)
        %v55549_v52 = vshll.u32 %v55540_v41, 6 (stack45)
        %v53571_v31 = vadd.f32 %v53567_v27, %v137945_v31 (stack53)
        %v54737_v43 = vadd.s32 %v54734_v29, %v54729_v43 (stack40)
        %v54739_v10 = vshll.u32 %v54734_v29, 29 (stack45)
        %v54740_v46 = vshrl.u32 %v54734_v29, 3 (stack46)
        %v53937_v9 = vmul.f32 %v53936_v60, %v53930_v9 (stack63)
        %vm138023_vm9 = vcmp.lt.f32.partialorder %v53938_v23, 0.0004427343 (stack62)
        %v54354_v60 = vxor.u32 %v54352_v54, %v54340_v6 (stack48)
        %v55134_v6 = vor.u32 %v55133_v42, %v55132_v45 (stack47)
        %v53575_v26 = vmul.f32 %v53571_v31, %v137984_v44 (stack54)
        %v54741_v27 = vor.u32 %v54740_v46, %v54739_v10 (stack47)
        %v55550_v41 = vshrl.u32 %v55540_v41, 26 (stack46)
        %v55967_v55 = vsel /*vm=*/%vm55941_vm8, /*on_true_vy=*/%v55963_v7, /*on_false_vx=*/%v55959_v34 (stack44)
        %v54355_v61 = vand.u32.u8 255, %v54354_v60 (stack49)
        %v55135_v34 = vxor.u32 %v55134_v6, %v55126_v40 (stack48)
        %v55972_v7 = vadd.s32 %v55967_v55, %v121574_v2 (stack40)
        %v55984_v53 = vor.u32 %v55983_v56, %v55982_v53 (stack47)
        %v53579_v8 = vadd.f32 %v53575_v26, %v137940_v8 (stack53)
        %v54742_v56 = vxor.u32 %v54741_v27, %v54737_v43 (stack48)
        %v55551_v29 = vor.u32 %v55550_v41, %v55549_v52 (stack47)
        %vm56441_vm10 = vcmp.lt.u32.totalorder %v138018_v50, %v122651_v47 (stack43)
        %v120890_v45 = vpop.eup %120889 (stack64)
        %v54356_v54 = vand.u32 65535, %v54355_v61 (stack50)
        %v55130_v40 = vadd.s32 %v55126_v40, %v121564_v0 (stack40)
        %v55138_v42 = vadd.s32 %v55135_v34, %v121574_v2 (stack40)
        %v55980_v20 = vadd.s32 %v137996_v20, %v55972_v7 (stack40)
        %v53583_v52 = vmul.f32 %v53579_v8, %v137984_v44 (stack54)
        %v53934_v31 = vmul.f32 0.6931472, %v120890_v45 (stack65)
        %v54745_v43 = vadd.s32 %v54742_v56, %v54737_v43 (stack40)
        %v54747_v10 = vshll.u32 %v54742_v56, 16 (stack45)
        %v54357_v46 = vshrl.u32 %v54356_v54, 1 (stack51)
        %v54748_v60 = vshrl.u32 %v54742_v56, 16 (stack46)
        %v55142_v6 = vadd.s32 2, %v55138_v42 (stack40)
        %v55552_v26 = vxor.u32 %v55551_v29, %v55543_v22 (stack48)
        %v53587_v25 = vadd.f32 %v53583_v52, %v137931_v25 (stack53)
        %v53940_v9 = vsel /*vm=*/%vm138023_vm9, /*on_true_vy=*/%v53937_v9, /*on_false_vx=*/%v53934_v31 (stack66)
        %v138042_v23 = vxor.u32 %v55984_v53, %v55980_v20 (stack48)
        %v157415_v27 = vld [vmem:[#allocation99_spill] sm:$0xff] (stack84)
        %v138046_v41 = vadd.s32 %v157415_v27, %v157068_v28 (stack40)
        %v138048_v55 = vxor.u32 2147483648, %v53940_v9 (stack56)
        %v54749_v61 = vor.u32 %v54748_v60, %v54747_v10 (stack47)
        %v55146_v34 = vadd.s32 %v55142_v6, %v55130_v40 (stack40)
        %v53591_v7 = vmul.f32 %v53587_v25, %v137984_v44 (stack54)
        %v53464_v53 = vmul.f32 inf, %v137855_v12 (stack54)
        %v53492_v8 = vsel /*vm=*/%vm53483_vm3, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %120891 = vrsqrt.f32 %v138048_v55 (stack67)
        %v54358_v56 = vor.u32 16256, %v54357_v46 (stack47)
        %vm138058_vm11 = vcmp.eq.f32.partialorder %v53456_v32, 1.0 (stack68)
        %v53595_v29 = vadd.f32 %v53591_v7, %v53492_v8 (stack53)
        %v55148_v45 = vshll.u32 %v55142_v6, 13 (stack45)
        %v55149_v54 = vshrl.u32 %v55142_v6, 19 (stack46)
        %v53488_v24 = vsel /*vm=*/%vm53483_vm3, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v53917_v40 = vand.u32 2147483647, %v137976_v21 (stack77)
        %v54750_v42 = vxor.u32 %v54749_v61, %v54745_v43 (stack48)
        %v55555_v52 = vadd.s32 %v55552_v26, %v121564_v0 (stack40)
        %v53599_v44 = vmul.f32 %v53595_v29, %v137984_v44 (stack54)
        %v138069_v31 = vmul.f32 inf, %v137976_v21 (stack54)
        %vm53944_vm12 = vcmp.lt.f32.partialorder %v138048_v55, 5.0 (stack68)
        %v55547_v22 = vadd.s32 %v55543_v22, %v121569_v1 (stack40)
        %v138074_v10 = vadd.f32 -2.5, %v138048_v55 (stack53)
        %v54359_v46 = vand.u32.u16 65535, %v54358_v56 (stack52)
        %v54753_v43 = vadd.s32 %v54750_v42, %v54745_v43 (stack40)
        %v138078_v60 = vadd.s32 %v138018_v50, %v122657_v58 (stack40)
        %v53603_v6 = vadd.f32 %v53599_v44, %v53488_v24 (stack53)
        %v54759_v26 = vshll.u32 %v54750_v42, 24 (stack45)
        %v54760_v25 = vshrl.u32 %v54750_v42, 8 (stack46)
        %v55150_v9 = vor.u32 %v55149_v54, %v55148_v45 (stack47)
        %v138083_v61 = vsel /*vm=*/%vm53944_vm12, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v120034_v7 = vadd.low.f32.bf16 -1.0, %v54359_v46 (stack53)
        %v55559_v8 = vadd.s32 1, %v55555_v52 (stack40)
        %v138086_v20 = vadd.s32 %v138042_v23, %v55980_v20 (stack40)
        %v53607_v12 = vmul.f32 %v53603_v6, %v137855_v12 (stack54)
        %v138092_v56 = vsel /*vm=*/%vm53944_vm12, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %vm53989_vm13 = vcmp.eq.f32.partialorder %v138048_v55, inf (stack70)
        %v54761_v29 = vor.u32 %v54760_v25, %v54759_v26 (stack47)
        %v55151_v45 = vxor.u32 %v55150_v9, %v55146_v34 (stack48)
        %v54368_v54 = vmul.f32 2.0, %v120034_v7 (stack54)
        %v55563_v24 = vadd.s32 %v55559_v8, %v55547_v22 (stack40)
        %v55565_v42 = vshll.u32 %v55559_v8, 17 (stack45)
        %v55566_v52 = vshrl.u32 %v55559_v8, 15 (stack46)
        %v53611_v53 = vsel /*vm=*/%vm138058_vm11, /*on_true_vy=*/%v53464_v53, /*on_false_vx=*/%v53607_v12 (stack44)
        %v54762_v32 = vxor.u32 %v54761_v29, %v54753_v43 (stack48)
        %v55154_v34 = vadd.s32 %v55151_v45, %v55146_v34 (stack40)
        %v55156_v44 = vshll.u32 %v55151_v45, 15 (stack45)
        %v53615_v22 = vmul.f32 1.4140625, %v53611_v53 (stack54)
        %v54372_v46 = vadd.f32 -0.99609375, %v54368_v54 (stack53)
        %v55157_v6 = vshrl.u32 %v55151_v45, 17 (stack46)
        %v55567_v26 = vor.u32 %v55566_v52, %v55565_v42 (stack47)
        %v138100_v25 = vsel /*vm=*/%vm53944_vm12, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %vm53991_vm14 = vcmp.eq.f32.partialorder %v138048_v55, 0.0 (stack71)
        %v54765_v9 = vadd.s32 %v54762_v32, %v121564_v0 (stack40)
        %v56450_v7 = vadd.s32 1, %v138046_v41 (stack40)
        %v53618_v8 = vpack.c.bf16 %v157387_v11, %v53615_v22 (stack81)
        %v138106_v12 = vmax.f32 %v54372_v46, -0.99609375 (stack55)
        %v55158_v29 = vor.u32 %v55157_v6, %v55156_v44 (stack47)
        %v55568_v45 = vxor.u32 %v55567_v26, %v55563_v24 (stack48)
        %v120892_v54 = vpop.eup %120891 (stack73)
        %v53992_v42 = vand.u32 2147483648, %v138048_v55 (stack72)
        %v54757_v43 = vadd.s32 %v54753_v43, %v121569_v1 (stack40)
        %v54769_v52 = vadd.s32 4, %v54765_v9 (stack40)
        %v56454_v41 = vsel /*vm=*/%vm56441_vm10, /*on_true_vy=*/%v56450_v7, /*on_false_vx=*/%v138046_v41 (stack44)
        %120031 = vst [vmem:[%s123356_s30 + $0xb8] sm:$0xf] /*vst_source=*/%v53618_v8 (stack83)
        %v53988_v53 = vmul.f32 %v120892_v54, %v138048_v55 (stack74)
        %v54388_v32 = vxor.u32 2147483648, %v138106_v12 (stack56)
        %v55990_v44 = vshll.u32 %v138042_v23, 15 (stack45)
        %v55991_v23 = vshrl.u32 %v138042_v23, 17 (stack46)
        %vm56436_vm15 = vcmp.lt.u32.totalorder %v138078_v60, %v138018_v50 (stack43)
        %v54773_v22 = vadd.s32 %v54769_v52, %v54757_v43 (stack40)
        %v54775_v46 = vshll.u32 %v54769_v52, 13 (stack45)
        %v54776_v6 = vshrl.u32 %v54769_v52, 19 (stack46)
        %v55159_v26 = vxor.u32 %v55158_v29, %v55154_v34 (stack48)
        %v53990_v9 = vsel /*vm=*/%vm53989_vm13, /*on_true_vy=*/%v138048_v55, /*on_false_vx=*/%v53988_v53 (stack75)
        %v138125_v7 = vmul.f32 %v54388_v32, %v138106_v12 (stack54)
        %v55571_v24 = vadd.s32 %v55568_v45, %v55563_v24 (stack40)
        %v138129_v8 = vadd.s32 %v138078_v60, %v121569_v1 (stack40)
        %v53977_v29 = vsel /*vm=*/%vm53944_vm12, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v53993_v54 = vsel /*vm=*/%vm53991_vm14, /*on_true_vy=*/%v53992_v42, /*on_false_vx=*/%v53990_v9 (stack76)
        %v54777_v42 = vor.u32 %v54776_v6, %v54775_v46 (stack47)
        %v55162_v34 = vadd.s32 %v55159_v26, %v55154_v34 (stack40)
        %v53996_v43 = vadd.f32 -3.0, %v53993_v54 (stack53)
        %v54393_v52 = vadd.f32 1.0, %v138125_v7 (stack57)
        %v55164_v53 = vshll.u32 %v55159_v26, 26 (stack45)
        %v55992_v32 = vor.u32 %v55991_v23, %v55990_v44 (stack47)
        %v54778_v44 = vxor.u32 %v54777_v42, %v54773_v22 (stack48)
        %v55165_v23 = vshrl.u32 %v55159_v26, 6 (stack46)
        %v55573_v46 = vshll.u32 %v55568_v45, 29 (stack45)
        %v55574_v45 = vshrl.u32 %v55568_v45, 3 (stack46)
        %v53981_v6 = vsel /*vm=*/%vm53944_vm12, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v138143_v10 = vsel /*vm=*/%vm53944_vm12, /*on_true_vy=*/%v138074_v10, /*on_false_vx=*/%v53996_v43 (stack44)
        %120893 = vlog2.f32 %v54393_v52 (stack58)
        %v56477_v26 = vshll.u32 %v138129_v8, 13 (stack45)
        %v54004_v9 = vmul.f32 %v138143_v10, %v53981_v6 (stack54)
        %v54781_v22 = vadd.s32 %v54778_v44, %v54773_v22 (stack40)
        %v54783_v54 = vshll.u32 %v54778_v44, 15 (stack45)
        %v54784_v42 = vshrl.u32 %v54778_v44, 17 (stack46)
        %v54396_v43 = vmul.f32 -0.5, %v138125_v7 (stack59)
        %v55166_v52 = vor.u32 %v55165_v23, %v55164_v53 (stack47)
        %v55575_v53 = vor.u32 %v55574_v45, %v55573_v46 (stack47)
        %v55993_v32 = vxor.u32 %v55992_v32, %v138086_v20 (stack48)
        %v54008_v29 = vadd.f32 %v54004_v9, %v53977_v29 (stack53)
        %v54399_v44 = vand.u32 2147483647, %v138125_v7 (stack60)
        %v54785_v23 = vor.u32 %v54784_v42, %v54783_v54 (stack47)
        %v56458_v46 = vadd.s32 1, %v56454_v41 (stack40)
        %v55167_v45 = vxor.u32 %v55166_v52, %v55162_v34 (stack48)
        %v55576_v6 = vxor.u32 %v55575_v53, %v55571_v24 (stack48)
        %v55996_v20 = vadd.s32 %v55993_v32, %v138086_v20 (stack40)
        %v55998_v9 = vshll.u32 %v55993_v32, 26 (stack45)
        %v54012_v54 = vmul.f32 %v54008_v29, %v138143_v10 (stack54)
        %v54786_v42 = vxor.u32 %v54785_v23, %v54781_v22 (stack48)
        %v55999_v52 = vshrl.u32 %v55993_v32, 6 (stack46)
        %v56462_v50 = vsel /*vm=*/%vm56436_vm15, /*on_true_vy=*/%v56458_v46, /*on_false_vx=*/%v56454_v41 (stack44)
        %v55170_v60 = vadd.s32 %v55167_v45, %v55162_v34 (stack40)
        %v55176_v41 = vshll.u32 %v55167_v45, 6 (stack45)
        %v55177_v34 = vshrl.u32 %v55167_v45, 26 (stack46)
        %v55579_v24 = vadd.s32 %v55576_v6, %v55571_v24 (stack40)
        %v54016_v25 = vadd.f32 %v54012_v54, %v138100_v25 (stack53)
        %v54789_v22 = vadd.s32 %v54786_v42, %v54781_v22 (stack40)
        %v54791_v53 = vshll.u32 %v54786_v42, 26 (stack45)
        %v54792_v32 = vshrl.u32 %v54786_v42, 6 (stack46)
        %v54397_v43 = vadd.f32 1.0, %v54396_v43 (stack61)
        %v55178_v29 = vor.u32 %v55177_v34, %v55176_v41 (stack47)
        %v55581_v23 = vshll.u32 %v55576_v6, 16 (stack45)
        %v55582_v46 = vshrl.u32 %v55576_v6, 16 (stack46)
        %v54020_v45 = vmul.f32 %v54016_v25, %v138143_v10 (stack54)
        %v54793_v6 = vor.u32 %v54792_v32, %v54791_v53 (stack47)
        %v56000_v9 = vor.u32 %v55999_v52, %v55998_v9 (stack47)
        %v56467_v54 = vadd.s32 %v56462_v50, %v121574_v2 (stack40)
        %vm138158_vm0 = vcmp.lt.f32.partialorder %v54399_v44, 0.0004427343 (stack62)
        %v55179_v42 = vxor.u32 %v55178_v29, %v55170_v60 (stack48)
        %v55583_v52 = vor.u32 %v55582_v46, %v55581_v23 (stack47)
        %v138164_v50 = vadd.s32 %v157412_v30, %v157070_v38 (stack40)
        %v54024_v56 = vadd.f32 %v54020_v45, %v138092_v56 (stack53)
        %v54794_v41 = vxor.u32 %v54793_v6, %v54789_v22 (stack48)
        %v138167_v34 = vxor.u32 %v56000_v9, %v55996_v20 (stack48)
        %v138170_v25 = vadd.s32 %v138129_v8, %v56467_v54 (stack40)
        %v54398_v7 = vmul.f32 %v54397_v43, %v138125_v7 (stack63)
        %v55182_v53 = vadd.s32 %v55179_v42, %v121569_v1 (stack40)
        %v55584_v32 = vxor.u32 %v55583_v52, %v55579_v24 (stack48)
        %vm56902_vm1 = vcmp.lt.u32.totalorder %v138164_v50, %v157070_v38 (stack43)
        %v120894_v43 = vpop.eup %120893 (stack64)
        %v54028_v29 = vmul.f32 %v54024_v56, %v138143_v10 (stack54)
        %v54797_v22 = vadd.s32 %v54794_v41, %v54789_v22 (stack40)
        %v54803_v23 = vshll.u32 %v54794_v41, 6 (stack45)
        %v54804_v46 = vshrl.u32 %v54794_v41, 26 (stack46)
        %v54395_v45 = vmul.f32 0.6931472, %v120894_v43 (stack65)
        %v55174_v60 = vadd.s32 %v55170_v60, %v121574_v2 (stack40)
        %v55186_v6 = vadd.s32 3, %v55182_v53 (stack40)
        %v55587_v24 = vadd.s32 %v55584_v32, %v55579_v24 (stack40)
        %v54032_v61 = vadd.f32 %v54028_v29, %v138083_v61 (stack53)
        %v54805_v9 = vor.u32 %v54804_v46, %v54803_v23 (stack47)
        %v55593_v54 = vshll.u32 %v55584_v32, 24 (stack45)
        %v56478_v42 = vshrl.u32 %v138129_v8, 19 (stack46)
        %v54401_v44 = vsel /*vm=*/%vm138158_vm0, /*on_true_vy=*/%v54398_v7, /*on_false_vx=*/%v54395_v45 (stack66)
        %v55190_v52 = vadd.s32 %v55186_v6, %v55174_v60 (stack40)
        %v55192_v56 = vshll.u32 %v55186_v6, 17 (stack45)
        %v55193_v41 = vshrl.u32 %v55186_v6, 15 (stack46)
        %v54036_v7 = vmul.f32 %v54032_v61, %v138143_v10 (stack54)
        %v138183_v53 = vxor.u32 2147483648, %v54401_v44 (stack56)
        %v54806_v43 = vxor.u32 %v54805_v9, %v54797_v22 (stack48)
        %v55594_v32 = vshrl.u32 %v55584_v32, 8 (stack46)
        %v53949_v29 = vsel /*vm=*/%vm53944_vm12, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v53961_v23 = vsel /*vm=*/%vm53944_vm12, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v55194_v46 = vor.u32 %v55193_v41, %v55192_v56 (stack47)
        %v56004_v20 = vadd.s32 %v138167_v34, %v55996_v20 (stack40)
        %v53953_v45 = vsel /*vm=*/%vm53944_vm12, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v53957_v55 = vsel /*vm=*/%vm53944_vm12, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v54040_v60 = vadd.f32 %v54036_v7, %v53961_v23 (stack53)
        %120895 = vrsqrt.f32 %v138183_v53 (stack67)
        %v54378_v6 = vand.u32 2147483647, %v138106_v12 (stack77)
        %vm54405_vm2 = vcmp.lt.f32.partialorder %v138183_v53, 5.0 (stack68)
        %v54809_v61 = vadd.s32 %v54806_v43, %v121574_v2 (stack40)
        %v56479_v8 = vor.u32 %v56478_v42, %v56477_v26 (stack47)
        %v54044_v26 = vmul.f32 %v54040_v60, %v138143_v10 (stack54)
        %v54801_v22 = vadd.s32 %v54797_v22, %v121564_v0 (stack40)
        %v55595_v9 = vor.u32 %v55594_v32, %v55593_v54 (stack47)
        %v138208_v54 = vadd.s32 %v138164_v50, %v122657_v58 (stack40)
        %v138211_v42 = vadd.f32 -2.5, %v138183_v53 (stack53)
        %v55195_v44 = vxor.u32 %v55194_v46, %v55190_v52 (stack48)
        %v55591_v56 = vadd.s32 %v55587_v24, %v121564_v0 (stack40)
        %v56010_v41 = vshll.u32 %v138167_v34, 6 (stack45)
        %v54048_v7 = vadd.f32 %v54044_v26, %v53957_v55 (stack53)
        %v138218_v43 = vsel /*vm=*/%vm54405_vm2, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v138223_v32 = vsel /*vm=*/%vm54405_vm2, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v138228_v23 = vsel /*vm=*/%vm54405_vm2, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v54813_v46 = vadd.s32 5, %v54809_v61 (stack40)
        %v55198_v52 = vadd.s32 %v55195_v44, %v55190_v52 (stack40)
        %v55200_v55 = vshll.u32 %v55195_v44, 29 (stack45)
        %v55201_v60 = vshrl.u32 %v55195_v44, 3 (stack46)
        %v54052_v61 = vmul.f32 %v54048_v7, %v138143_v10 (stack54)
        %v54453_v26 = vand.u32 2147483648, %v138183_v53 (stack72)
        %v55596_v24 = vxor.u32 %v55595_v9, %v55587_v24 (stack48)
        %v56011_v34 = vshrl.u32 %v138167_v34, 26 (stack46)
        %vm138235_vm3 = vcmp.eq.f32.partialorder %v53917_v40, 1.0 (stack68)
        %vm54450_vm4 = vcmp.eq.f32.partialorder %v138183_v53, inf (stack70)
        %v54815_v22 = vxor.u32 %v54813_v46, %v54801_v22 (stack48)
        %v55202_v9 = vor.u32 %v55201_v60, %v55200_v55 (stack47)
        %v56008_v44 = vadd.s32 %v56004_v20, %v121569_v1 (stack40)
        %v56480_v8 = vxor.u32 %v56479_v8, %v138170_v25 (stack48)
        %v54056_v45 = vadd.f32 %v54052_v61, %v53953_v45 (stack53)
        %vm54452_vm5 = vcmp.eq.f32.partialorder %v138183_v53, 0.0 (stack71)
        %v55599_v7 = vadd.s32 %v55596_v24, %v121574_v2 (stack40)
        %v56012_v41 = vor.u32 %v56011_v34, %v56010_v41 (stack47)
        %v56907_v46 = vadd.s32 %v157415_v27, %v157076_v35 (stack40)
        %v54816_v55 = vand.u32.u8 255, %v54815_v22 (stack49)
        %v55203_v60 = vxor.u32 %v55202_v9, %v55198_v52 (stack48)
        %v56483_v25 = vadd.s32 %v56480_v8, %v138170_v25 (stack40)
        %v56485_v61 = vshll.u32 %v56480_v8, 15 (stack45)
        %v54060_v10 = vmul.f32 %v54056_v45, %v138143_v10 (stack54)
        %v55603_v24 = vadd.s32 2, %v55599_v7 (stack40)
        %v56013_v20 = vxor.u32 %v56012_v41, %v56004_v20 (stack48)
        %v56486_v34 = vshrl.u32 %v56480_v8, 17 (stack46)
        %v54817_v22 = vand.u32 65535, %v54816_v55 (stack50)
        %v55206_v52 = vadd.s32 %v55203_v60, %v55198_v52 (stack40)
        %v55208_v9 = vshll.u32 %v55203_v60, 16 (stack45)
        %v55209_v8 = vshrl.u32 %v55203_v60, 16 (stack46)
        %v54064_v29 = vadd.f32 %v54060_v10, %v53949_v29 (stack53)
        %v55607_v56 = vadd.s32 %v55603_v24, %v55591_v56 (stack40)
        %v55609_v45 = vshll.u32 %v55603_v24, 13 (stack45)
        %v55610_v7 = vshrl.u32 %v55603_v24, 19 (stack46)
        %v120896_v41 = vpop.eup %120895 (stack73)
        %v54818_v55 = vshrl.u32 %v54817_v22, 1 (stack51)
        %v55210_v60 = vor.u32 %v55209_v8, %v55208_v9 (stack47)
        %v56016_v10 = vadd.s32 %v56013_v20, %v121564_v0 (stack40)
        %v56487_v61 = vor.u32 %v56486_v34, %v56485_v61 (stack47)
        %v54068_v21 = vmul.f32 %v54064_v29, %v137976_v21 (stack54)
        %v54449_v24 = vmul.f32 %v120896_v41, %v138183_v53 (stack74)
        %v55611_v20 = vor.u32 %v55610_v7, %v55609_v45 (stack47)
        %v56911_v34 = vadd.s32 1, %v56907_v46 (stack40)
        %v54819_v22 = vor.u32 16256, %v54818_v55 (stack47)
        %v55211_v9 = vxor.u32 %v55210_v60, %v55206_v52 (stack48)
        %v56020_v8 = vadd.s32 1, %v56016_v10 (stack40)
        %v56488_v29 = vxor.u32 %v56487_v61, %v56483_v25 (stack48)
        %v54072_v31 = vsel /*vm=*/%vm138235_vm3, /*on_true_vy=*/%v138069_v31, /*on_false_vx=*/%v54068_v21 (stack44)
        %v54451_v40 = vsel /*vm=*/%vm54450_vm4, /*on_true_vy=*/%v138183_v53, /*on_false_vx=*/%v54449_v24 (stack75)
        %v55612_v45 = vxor.u32 %v55611_v20, %v55607_v56 (stack48)
        %v138260_v46 = vsel /*vm=*/%vm56902_vm1, /*on_true_vy=*/%v56911_v34, /*on_false_vx=*/%v56907_v46 (stack44)
        %v54076_v7 = vmul.f32 1.4140625, %v54072_v31 (stack54)
        %v54454_v26 = vsel /*vm=*/%vm54452_vm5, /*on_true_vy=*/%v54453_v26, /*on_false_vx=*/%v54451_v40 (stack76)
        %v54820_v41 = vand.u32.u16 65535, %v54819_v22 (stack52)
        %v55214_v52 = vadd.s32 %v55211_v9, %v55206_v52 (stack40)
        %v54457_v55 = vadd.f32 -3.0, %v54454_v26 (stack53)
        %v55220_v60 = vshll.u32 %v55211_v9, 24 (stack45)
        %v55221_v10 = vshrl.u32 %v55211_v9, 8 (stack46)
        %v55615_v56 = vadd.s32 %v55612_v45, %v55607_v56 (stack40)
        %v54079_v61 = vpack.c.bf16 %v157387_v11, %v54076_v7 (stack81)
        %v54442_v21 = vsel /*vm=*/%vm54405_vm2, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v120036_v24 = vadd.low.f32.bf16 -1.0, %v54820_v41 (stack53)
        %v55617_v20 = vshll.u32 %v55612_v45, 15 (stack45)
        %v138271_v42 = vsel /*vm=*/%vm54405_vm2, /*on_true_vy=*/%v138211_v42, /*on_false_vx=*/%v54457_v55 (stack44)
        %v55222_v34 = vor.u32 %v55221_v10, %v55220_v60 (stack47)
        %v55618_v22 = vshrl.u32 %v55612_v45, 17 (stack46)
        %v56024_v44 = vadd.s32 %v56020_v8, %v56008_v44 (stack40)
        %120033 = vst [vmem:[%s123356_s30 + $0x138] sm:$0xf] /*vst_source=*/%v54079_v61 (stack83)
        %v54465_v9 = vmul.f32 %v138271_v42, %v54442_v21 (stack54)
        %v54829_v31 = vmul.f32 2.0, %v120036_v24 (stack54)
        %v56026_v40 = vshll.u32 %v56020_v8, 17 (stack45)
        %v56027_v8 = vshrl.u32 %v56020_v8, 15 (stack46)
        %v54438_v45 = vsel /*vm=*/%vm54405_vm2, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v55223_v7 = vxor.u32 %v55222_v34, %v55214_v52 (stack48)
        %v55619_v26 = vor.u32 %v55618_v22, %v55617_v20 (stack47)
        %v56491_v25 = vadd.s32 %v56488_v29, %v56483_v25 (stack40)
        %v54434_v41 = vsel /*vm=*/%vm54405_vm2, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v54469_v55 = vadd.f32 %v54465_v9, %v54438_v45 (stack53)
        %v54833_v60 = vadd.f32 -0.99609375, %v54829_v31 (stack53)
        %v56028_v10 = vor.u32 %v56027_v8, %v56026_v40 (stack47)
        %v55218_v52 = vadd.s32 %v55214_v52, %v121569_v1 (stack40)
        %v55226_v61 = vadd.s32 %v55223_v7, %v121564_v0 (stack40)
        %v55620_v21 = vxor.u32 %v55619_v26, %v55615_v56 (stack48)
        %v56493_v24 = vshll.u32 %v56488_v29, 26 (stack45)
        %v54473_v20 = vmul.f32 %v54469_v55, %v138271_v42 (stack54)
        %v138284_v34 = vmax.f32 %v54833_v60, -0.99609375 (stack55)
        %v56029_v22 = vxor.u32 %v56028_v10, %v56024_v44 (stack48)
        %v56494_v29 = vshrl.u32 %v56488_v29, 6 (stack46)
        %v55230_v9 = vadd.s32 4, %v55226_v61 (stack40)
        %v55623_v56 = vadd.s32 %v55620_v21, %v55615_v56 (stack40)
        %v55625_v31 = vshll.u32 %v55620_v21, 26 (stack45)
        %v55626_v40 = vshrl.u32 %v55620_v21, 6 (stack46)
        %v54426_v8 = vsel /*vm=*/%vm54405_vm2, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v54430_v45 = vsel /*vm=*/%vm54405_vm2, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v54477_v7 = vadd.f32 %v54473_v20, %v54434_v41 (stack53)
        %v54849_v26 = vxor.u32 2147483648, %v138284_v34 (stack56)
        %v55234_v41 = vadd.s32 %v55230_v9, %v55218_v52 (stack40)
        %v55236_v55 = vshll.u32 %v55230_v9, 13 (stack45)
        %v55237_v60 = vshrl.u32 %v55230_v9, 19 (stack46)
        %v55627_v10 = vor.u32 %v55626_v40, %v55625_v31 (stack47)
        %v54481_v52 = vmul.f32 %v54477_v7, %v138271_v42 (stack54)
        %v138295_v61 = vmul.f32 %v54849_v26, %v138284_v34 (stack54)
        %v56032_v44 = vadd.s32 %v56029_v22, %v56024_v44 (stack40)
        %v56919_v21 = vadd.s32 1, %v138260_v46 (stack40)
        %v55238_v20 = vor.u32 %v55237_v60, %v55236_v55 (stack47)
        %v55628_v9 = vxor.u32 %v55627_v10, %v55623_v56 (stack48)
        %v56034_v31 = vshll.u32 %v56029_v22, 29 (stack45)
        %v56495_v24 = vor.u32 %v56494_v29, %v56493_v24 (stack47)
        %v54485_v29 = vadd.f32 %v54481_v52, %v54430_v45 (stack53)
        %v54854_v40 = vadd.f32 1.0, %v138295_v61 (stack57)
        %v54857_v45 = vmul.f32 -0.5, %v138295_v61 (stack59)
        %v56035_v22 = vshrl.u32 %v56029_v22, 3 (stack46)
        %v55239_v7 = vxor.u32 %v55238_v20, %v55234_v41 (stack48)
        %v55631_v56 = vadd.s32 %v55628_v9, %v55623_v56 (stack40)
        %v55637_v26 = vshll.u32 %v55628_v9, 6 (stack45)
        %v55638_v55 = vshrl.u32 %v55628_v9, 26 (stack46)
        %v54489_v60 = vmul.f32 %v54485_v29, %v138271_v42 (stack54)
        %120897 = vlog2.f32 %v54854_v40 (stack58)
        %vm56897_vm6 = vcmp.lt.u32.totalorder %v138208_v54, %v138164_v50 (stack43)
        %v56932_v50 = vadd.s32 %v138208_v54, %v121569_v1 (stack40)
        %v54860_v54 = vand.u32 2147483647, %v138295_v61 (stack60)
        %v55242_v41 = vadd.s32 %v55239_v7, %v55234_v41 (stack40)
        %v55244_v10 = vshll.u32 %v55239_v7, 15 (stack45)
        %v55245_v52 = vshrl.u32 %v55239_v7, 17 (stack46)
        %v54493_v8 = vadd.f32 %v54489_v60, %v54426_v8 (stack53)
        %v54858_v20 = vadd.f32 1.0, %v54857_v45 (stack61)
        %v55639_v9 = vor.u32 %v55638_v55, %v55637_v26 (stack47)
        %v56036_v31 = vor.u32 %v56035_v22, %v56034_v31 (stack47)
        %v55246_v29 = vor.u32 %v55245_v52, %v55244_v10 (stack47)
        %v55635_v40 = vadd.s32 %v55631_v56, %v121574_v2 (stack40)
        %v56496_v24 = vxor.u32 %v56495_v24, %v56491_v25 (stack48)
        %v56923_v46 = vsel /*vm=*/%vm56897_vm6, /*on_true_vy=*/%v56919_v21, /*on_false_vx=*/%v138260_v46 (stack44)
        %v54497_v21 = vmul.f32 %v54493_v8, %v138271_v42 (stack54)
        %v55640_v45 = vxor.u32 %v55639_v9, %v55631_v56 (stack48)
        %v56037_v22 = vxor.u32 %v56036_v31, %v56032_v44 (stack48)
        %v56928_v7 = vadd.s32 %v56923_v46, %v121574_v2 (stack40)
        %v55247_v56 = vxor.u32 %v55246_v29, %v55242_v41 (stack48)
        %v138310_v25 = vadd.s32 %v56496_v24, %v56491_v25 (stack40)
        %v56505_v26 = vshll.u32 %v56496_v24, 6 (stack45)
        %v56506_v55 = vshrl.u32 %v56496_v24, 26 (stack46)
        %v54501_v23 = vadd.f32 %v54497_v21, %v138228_v23 (stack53)
        %v55643_v60 = vadd.s32 %v55640_v45, %v121569_v1 (stack40)
        %v56040_v44 = vadd.s32 %v56037_v22, %v56032_v44 (stack40)
        %v56042_v10 = vshll.u32 %v56037_v22, 16 (stack45)
        %v55250_v41 = vadd.s32 %v55247_v56, %v55242_v41 (stack40)
        %v55252_v52 = vshll.u32 %v55247_v56, 26 (stack45)
        %v55253_v8 = vshrl.u32 %v55247_v56, 6 (stack46)
        %v56043_v9 = vshrl.u32 %v56037_v22, 16 (stack46)
        %v54505_v31 = vmul.f32 %v54501_v23, %v138271_v42 (stack54)
        %v55647_v29 = vadd.s32 3, %v55643_v60 (stack40)
        %v56507_v24 = vor.u32 %v56506_v55, %v56505_v26 (stack47)
        %v56938_v46 = vshll.u32 %v56932_v50, 13 (stack45)
        %v55254_v21 = vor.u32 %v55253_v8, %v55252_v52 (stack47)
        %v56044_v45 = vor.u32 %v56043_v9, %v56042_v10 (stack47)
        %v56936_v22 = vadd.s32 %v56932_v50, %v56928_v7 (stack40)
        %v56939_v50 = vshrl.u32 %v56932_v50, 19 (stack46)
        %v54509_v32 = vadd.f32 %v54505_v31, %v138223_v32 (stack53)
        %v55651_v40 = vadd.s32 %v55647_v29, %v55635_v40 (stack40)
        %v55653_v7 = vshll.u32 %v55647_v29, 17 (stack45)
        %v55654_v56 = vshrl.u32 %v55647_v29, 15 (stack46)
        %v54859_v61 = vmul.f32 %v54858_v20, %v138295_v61 (stack63)
        %v55255_v20 = vxor.u32 %v55254_v21, %v55250_v41 (stack48)
        %v56045_v26 = vxor.u32 %v56044_v45, %v56040_v44 (stack48)
        %v56508_v55 = vxor.u32 %v56507_v24, %v138310_v25 (stack48)
        %v54513_v23 = vmul.f32 %v54509_v32, %v138271_v42 (stack54)
        %v55655_v60 = vor.u32 %v55654_v56, %v55653_v7 (stack47)
        %v138321_v10 = vadd.s32 %v157412_v30, %v157077_v51 (stack40)
        %v138325_v52 = vadd.s32 %v157415_v27, %v157078_v48 (stack40)
        %v120898_v8 = vpop.eup %120897 (stack64)
        %v55258_v41 = vadd.s32 %v55255_v20, %v55250_v41 (stack40)
        %v55264_v9 = vshll.u32 %v55255_v20, 6 (stack45)
        %v55265_v31 = vshrl.u32 %v55255_v20, 26 (stack46)
        %v56048_v44 = vadd.s32 %v56045_v26, %v56040_v44 (stack40)
        %v54517_v43 = vadd.f32 %v54513_v23, %v138218_v43 (stack53)
        %v54856_v29 = vmul.f32 0.6931472, %v120898_v8 (stack65)
        %v55656_v24 = vxor.u32 %v55655_v60, %v55651_v40 (stack48)
        %v56940_v46 = vor.u32 %v56939_v50, %v56938_v46 (stack47)
        %vm54861_vm7 = vcmp.lt.f32.partialorder %v54860_v54, 0.0004427343 (stack62)
        %v55266_v54 = vor.u32 %v55265_v31, %v55264_v9 (stack47)
        %v56054_v21 = vshll.u32 %v56045_v26, 24 (stack45)
        %v54521_v42 = vmul.f32 %v54517_v43, %v138271_v42 (stack54)
        %v54862_v45 = vsel /*vm=*/%vm54861_vm7, /*on_true_vy=*/%v54859_v61, /*on_false_vx=*/%v54856_v29 (stack66)
        %v55659_v50 = vadd.s32 %v55656_v24, %v55651_v40 (stack40)
        %v56055_v32 = vshrl.u32 %v56045_v26, 8 (stack46)
        %v54410_v53 = vsel /*vm=*/%vm54405_vm2, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v138332_v40 = vxor.u32 2147483648, %v54862_v45 (stack56)
        %v55267_v7 = vxor.u32 %v55266_v54, %v55258_v41 (stack48)
        %vm138336_vm8 = vcmp.eq.f32.partialorder %v54378_v6, 1.0 (stack68)
        %v54386_v56 = vmul.f32 inf, %v138106_v12 (stack54)
        %v54525_v61 = vadd.f32 %v54521_v42, %v54410_v53 (stack53)
        %v56941_v20 = vxor.u32 %v56940_v46, %v56936_v22 (stack48)
        %v54839_v26 = vand.u32 2147483647, %v138284_v34 (stack77)
        %vm54866_vm9 = vcmp.lt.f32.partialorder %v138332_v40, 5.0 (stack68)
        %120899 = vrsqrt.f32 %v138332_v40 (stack67)
        %v55661_v23 = vshll.u32 %v55656_v24, 29 (stack45)
        %v54529_v12 = vmul.f32 %v54525_v61, %v138106_v12 (stack54)
        %v55662_v60 = vshrl.u32 %v55656_v24, 3 (stack46)
        %v56056_v8 = vor.u32 %v56055_v32, %v56054_v21 (stack47)
        %v56511_v55 = vadd.s32 %v56508_v55, %v121564_v0 (stack40)
        %v55262_v41 = vadd.s32 %v55258_v41, %v121564_v0 (stack40)
        %v55270_v9 = vadd.s32 %v55267_v7, %v121574_v2 (stack40)
        %v56052_v31 = vadd.s32 %v56048_v44, %v121564_v0 (stack40)
        %v56503_v25 = vadd.s32 %v138310_v25, %v121569_v1 (stack40)
        %v54533_v43 = vsel /*vm=*/%vm138336_vm8, /*on_true_vy=*/%v54386_v56, /*on_false_vx=*/%v54529_v12 (stack44)
        %v138356_v29 = vsel /*vm=*/%vm54866_vm9, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v138359_v24 = vadd.f32 -2.5, %v138332_v40 (stack53)
        %v138363_v46 = vadd.s32 %v138321_v10, %v122657_v58 (stack40)
        %v54537_v54 = vmul.f32 1.4140625, %v54533_v43 (stack54)
        %v138368_v21 = vsel /*vm=*/%vm54866_vm9, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v138373_v42 = vsel /*vm=*/%vm54866_vm9, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v55274_v45 = vadd.s32 5, %v55270_v9 (stack40)
        %v55663_v32 = vor.u32 %v55662_v60, %v55661_v23 (stack47)
        %v56057_v44 = vxor.u32 %v56056_v8, %v56048_v44 (stack48)
        %v56515_v53 = vadd.s32 1, %v56511_v55 (stack40)
        %v56944_v22 = vadd.s32 %v56941_v20, %v56936_v22 (stack40)
        %v54540_v7 = vpack.c.bf16 %v157387_v11, %v54537_v54 (stack81)
        %v55276_v6 = vxor.u32 %v55274_v45, %v55262_v41 (stack48)
        %v56946_v56 = vshll.u32 %v56941_v20, 15 (stack45)
        %v56947_v61 = vshrl.u32 %v56941_v20, 17 (stack46)
        %vm54911_vm10 = vcmp.eq.f32.partialorder %v138332_v40, inf (stack70)
        %v55664_v20 = vxor.u32 %v55663_v32, %v55659_v50 (stack48)
        %v56060_v23 = vadd.s32 %v56057_v44, %v121574_v2 (stack40)
        %v56519_v12 = vadd.s32 %v56515_v53, %v56503_v25 (stack40)
        %v56521_v60 = vshll.u32 %v56515_v53, 17 (stack45)
        %120035 = vst [vmem:[%s123356_s30 + $0x1b8] sm:$0xf] /*vst_source=*/%v54540_v7 (stack83)
        %vm54913_vm11 = vcmp.eq.f32.partialorder %v138332_v40, 0.0 (stack71)
        %v55277_v8 = vand.u32.u8 255, %v55276_v6 (stack49)
        %v56522_v55 = vshrl.u32 %v56515_v53, 15 (stack46)
        %v56948_v41 = vor.u32 %v56947_v61, %v56946_v56 (stack47)
        %v55667_v50 = vadd.s32 %v55664_v20, %v55659_v50 (stack40)
        %v55669_v9 = vshll.u32 %v55664_v20, 16 (stack45)
        %v55670_v25 = vshrl.u32 %v55664_v20, 16 (stack46)
        %v56064_v43 = vadd.s32 2, %v56060_v23 (stack40)
        %v55278_v54 = vand.u32 65535, %v55277_v8 (stack50)
        %v56523_v45 = vor.u32 %v56522_v55, %v56521_v60 (stack47)
        %v56949_v32 = vxor.u32 %v56948_v41, %v56944_v22 (stack48)
        %vm57363_vm12 = vcmp.lt.u32.totalorder %v138321_v10, %v157077_v51 (stack43)
        %v55671_v44 = vor.u32 %v55670_v25, %v55669_v9 (stack47)
        %v56068_v31 = vadd.s32 %v56064_v43, %v56052_v31 (stack40)
        %v56070_v53 = vshll.u32 %v56064_v43, 13 (stack45)
        %v56071_v7 = vshrl.u32 %v56064_v43, 19 (stack46)
        %v55279_v6 = vshrl.u32 %v55278_v54, 1 (stack51)
        %v56524_v56 = vxor.u32 %v56523_v45, %v56519_v12 (stack48)
        %v56952_v22 = vadd.s32 %v56949_v32, %v56944_v22 (stack40)
        %v56954_v61 = vshll.u32 %v56949_v32, 26 (stack45)
        %v120900_v20 = vpop.eup %120899 (stack73)
        %v54914_v23 = vand.u32 2147483648, %v138332_v40 (stack72)
        %v55672_v60 = vxor.u32 %v55671_v44, %v55667_v50 (stack48)
        %v56072_v8 = vor.u32 %v56071_v7, %v56070_v53 (stack47)
        %v56955_v55 = vshrl.u32 %v56949_v32, 6 (stack46)
        %v54910_v41 = vmul.f32 %v120900_v20, %v138332_v40 (stack74)
        %v55280_v9 = vor.u32 16256, %v55279_v6 (stack47)
        %v56527_v12 = vadd.s32 %v56524_v56, %v56519_v12 (stack40)
        %v56529_v25 = vshll.u32 %v56524_v56, 29 (stack45)
        %v55675_v50 = vadd.s32 %v55672_v60, %v55667_v50 (stack40)
        %v55681_v43 = vshll.u32 %v55672_v60, 24 (stack45)
        %v55682_v54 = vshrl.u32 %v55672_v60, 8 (stack46)
        %v56073_v45 = vxor.u32 %v56072_v8, %v56068_v31 (stack48)
        %v54912_v32 = vsel /*vm=*/%vm54911_vm10, /*on_true_vy=*/%v138332_v40, /*on_false_vx=*/%v54910_v41 (stack75)
        %v55281_v44 = vand.u32.u16 65535, %v55280_v9 (stack52)
        %v56530_v53 = vshrl.u32 %v56524_v56, 3 (stack46)
        %v56956_v7 = vor.u32 %v56955_v55, %v56954_v61 (stack47)
        %v54915_v6 = vsel /*vm=*/%vm54913_vm11, /*on_true_vy=*/%v54914_v23, /*on_false_vx=*/%v54912_v32 (stack76)
        %v55683_v56 = vor.u32 %v55682_v54, %v55681_v43 (stack47)
        %v56076_v31 = vadd.s32 %v56073_v45, %v56068_v31 (stack40)
        %v57372_v61 = vadd.s32 1, %v138325_v52 (stack40)
        %v54918_v20 = vadd.f32 -3.0, %v54915_v6 (stack53)
        %v120038_v23 = vadd.low.f32.bf16 -1.0, %v55281_v44 (stack53)
        %v56078_v60 = vshll.u32 %v56073_v45, 15 (stack45)
        %v56079_v8 = vshrl.u32 %v56073_v45, 17 (stack46)
        %v55684_v55 = vxor.u32 %v55683_v56, %v55675_v50 (stack48)
        %v56531_v41 = vor.u32 %v56530_v53, %v56529_v25 (stack47)
        %v56957_v9 = vxor.u32 %v56956_v7, %v56952_v22 (stack48)
        %v57376_v52 = vsel /*vm=*/%vm57363_vm12, /*on_true_vy=*/%v57372_v61, /*on_false_vx=*/%v138325_v52 (stack44)
        %v138397_v24 = vsel /*vm=*/%vm54866_vm9, /*on_true_vy=*/%v138359_v24, /*on_false_vx=*/%v54918_v20 (stack44)
        %v55290_v25 = vmul.f32 2.0, %v120038_v23 (stack54)
        %v56080_v43 = vor.u32 %v56079_v8, %v56078_v60 (stack47)
        %vm57358_vm13 = vcmp.lt.u32.totalorder %v138363_v46, %v138321_v10 (stack43)
        %v54926_v42 = vmul.f32 %v138397_v24, %v138373_v42 (stack54)
        %v55687_v54 = vadd.s32 %v55684_v55, %v121564_v0 (stack40)
        %v56532_v45 = vxor.u32 %v56531_v41, %v56527_v12 (stack48)
        %v56960_v22 = vadd.s32 %v56957_v9, %v56952_v22 (stack40)
        %v55294_v32 = vadd.f32 -0.99609375, %v55290_v25 (stack53)
        %v55679_v50 = vadd.s32 %v55675_v50, %v121569_v1 (stack40)
        %v56081_v44 = vxor.u32 %v56080_v43, %v56076_v31 (stack48)
        %v57380_v53 = vadd.s32 1, %v57376_v52 (stack40)
        %v54930_v21 = vadd.f32 %v54926_v42, %v138368_v21 (stack53)
        %v55691_v7 = vadd.s32 4, %v55687_v54 (stack40)
        %v56535_v12 = vadd.s32 %v56532_v45, %v56527_v12 (stack40)
        %v56966_v6 = vshll.u32 %v56957_v9, 6 (stack45)
        %v138406_v56 = vmax.f32 %v55294_v32, -0.99609375 (stack55)
        %v56084_v31 = vadd.s32 %v56081_v44, %v56076_v31 (stack40)
        %v56086_v61 = vshll.u32 %v56081_v44, 26 (stack45)
        %v56087_v20 = vshrl.u32 %v56081_v44, 6 (stack46)
        %v54934_v23 = vmul.f32 %v54930_v21, %v138397_v24 (stack54)
        %v55695_v60 = vadd.s32 %v55691_v7, %v55679_v50 (stack40)
        %v55697_v8 = vshll.u32 %v55691_v7, 13 (stack45)
        %v55698_v55 = vshrl.u32 %v55691_v7, 19 (stack46)
        %v55310_v41 = vxor.u32 2147483648, %v138406_v56 (stack56)
        %v56088_v25 = vor.u32 %v56087_v20, %v56086_v61 (stack47)
        %v56537_v43 = vshll.u32 %v56532_v45, 16 (stack45)
        %v56967_v9 = vshrl.u32 %v56957_v9, 26 (stack46)
        %v138413_v42 = vsel /*vm=*/%vm54866_vm9, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v54938_v29 = vadd.f32 %v54934_v23, %v138356_v29 (stack53)
        %v55699_v54 = vor.u32 %v55698_v55, %v55697_v8 (stack47)
        %v56538_v45 = vshrl.u32 %v56532_v45, 16 (stack46)
        %v54879_v32 = vsel /*vm=*/%vm54866_vm9, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v54883_v50 = vsel /*vm=*/%vm54866_vm9, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v138423_v44 = vmul.f32 %v55310_v41, %v138406_v56 (stack54)
        %v56089_v21 = vxor.u32 %v56088_v25, %v56084_v31 (stack48)
        %v54891_v7 = vsel /*vm=*/%vm54866_vm9, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v54942_v61 = vmul.f32 %v54938_v29, %v138397_v24 (stack54)
        %v55700_v20 = vxor.u32 %v55699_v54, %v55695_v60 (stack48)
        %v57384_v10 = vsel /*vm=*/%vm57358_vm13, /*on_true_vy=*/%v57380_v53, /*on_false_vx=*/%v57376_v52 (stack44)
        %v55315_v52 = vadd.f32 1.0, %v138423_v44 (stack57)
        %v56092_v53 = vadd.s32 %v56089_v21, %v56084_v31 (stack40)
        %v56539_v31 = vor.u32 %v56538_v45, %v56537_v43 (stack47)
        %v56968_v6 = vor.u32 %v56967_v9, %v56966_v6 (stack47)
        %v54946_v23 = vadd.f32 %v54942_v61, %v54891_v7 (stack53)
        %v55703_v60 = vadd.s32 %v55700_v20, %v55695_v60 (stack40)
        %v55705_v8 = vshll.u32 %v55700_v20, 15 (stack45)
        %v55706_v55 = vshrl.u32 %v55700_v20, 17 (stack46)
        %v54887_v41 = vsel /*vm=*/%vm54866_vm9, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %120901 = vlog2.f32 %v55315_v52 (stack58)
        %v55318_v25 = vmul.f32 -0.5, %v138423_v44 (stack59)
        %v56964_v43 = vadd.s32 %v56960_v22, %v121569_v1 (stack40)
        %v54950_v9 = vmul.f32 %v54946_v23, %v138397_v24 (stack54)
        %v55707_v29 = vor.u32 %v55706_v55, %v55705_v8 (stack47)
        %v56098_v54 = vshll.u32 %v56089_v21, 6 (stack45)
        %v56099_v45 = vshrl.u32 %v56089_v21, 26 (stack46)
        %v55321_v21 = vand.u32 2147483647, %v138423_v44 (stack60)
        %v56540_v7 = vxor.u32 %v56539_v31, %v56535_v12 (stack48)
        %v56969_v22 = vxor.u32 %v56968_v6, %v56960_v22 (stack48)
        %v57389_v61 = vadd.s32 %v57384_v10, %v121574_v2 (stack40)
        %v54954_v20 = vadd.f32 %v54950_v9, %v54887_v41 (stack53)
        %v55708_v10 = vxor.u32 %v55707_v29, %v55703_v60 (stack48)
        %v56100_v52 = vor.u32 %v56099_v45, %v56098_v54 (stack47)
        %v138443_v46 = vadd.s32 %v138363_v46, %v121569_v1 (stack40)
        %v56543_v12 = vadd.s32 %v56540_v7, %v56535_v12 (stack40)
        %v56549_v31 = vshll.u32 %v56540_v7, 24 (stack45)
        %v56550_v6 = vshrl.u32 %v56540_v7, 8 (stack46)
        %v56972_v23 = vadd.s32 %v56969_v22, %v121564_v0 (stack40)
        %v54958_v8 = vmul.f32 %v54954_v20, %v138397_v24 (stack54)
        %v55711_v60 = vadd.s32 %v55708_v10, %v55703_v60 (stack40)
        %v55713_v55 = vshll.u32 %v55708_v10, 26 (stack45)
        %v55714_v41 = vshrl.u32 %v55708_v10, 6 (stack46)
        %v55319_v25 = vadd.f32 1.0, %v55318_v25 (stack61)
        %v56101_v9 = vxor.u32 %v56100_v52, %v56092_v53 (stack48)
        %v56551_v29 = vor.u32 %v56550_v6, %v56549_v31 (stack47)
        %v56976_v54 = vadd.s32 1, %v56972_v23 (stack40)
        %v54962_v50 = vadd.f32 %v54958_v8, %v54883_v50 (stack53)
        %v55715_v45 = vor.u32 %v55714_v41, %v55713_v55 (stack47)
        %v56096_v53 = vadd.s32 %v56092_v53, %v121574_v2 (stack40)
        %v138449_v7 = vadd.s32 %v138443_v46, %v57389_v61 (stack40)
        %v56104_v22 = vadd.s32 %v56101_v9, %v121569_v1 (stack40)
        %v56547_v61 = vadd.s32 %v56543_v12, %v121564_v0 (stack40)
        %v56552_v20 = vxor.u32 %v56551_v29, %v56543_v12 (stack48)
        %v56980_v43 = vadd.s32 %v56976_v54, %v56964_v43 (stack40)
        %v54966_v10 = vmul.f32 %v54962_v50, %v138397_v24 (stack54)
        %v55716_v52 = vxor.u32 %v55715_v45, %v55711_v60 (stack48)
        %v56982_v12 = vshll.u32 %v56976_v54, 17 (stack45)
        %v56983_v31 = vshrl.u32 %v56976_v54, 15 (stack46)
        %v56108_v6 = vadd.s32 3, %v56104_v22 (stack40)
        %v56555_v23 = vadd.s32 %v56552_v20, %v121574_v2 (stack40)
        %v138457_v8 = vadd.s32 %v157412_v30, %v157079_v39 (stack40)
        %v138461_v55 = vadd.s32 %v157415_v27, %v157082_v49 (stack40)
        %v54970_v32 = vadd.f32 %v54966_v10, %v54879_v32 (stack53)
        %v55719_v60 = vadd.s32 %v55716_v52, %v55711_v60 (stack40)
        %v55725_v41 = vshll.u32 %v55716_v52, 6 (stack45)
        %v55726_v9 = vshrl.u32 %v55716_v52, 26 (stack46)
        %v56112_v29 = vadd.s32 %v56108_v6, %v56096_v53 (stack40)
        %v56114_v54 = vshll.u32 %v56108_v6, 17 (stack45)
        %v56115_v50 = vshrl.u32 %v56108_v6, 15 (stack46)
        %v56559_v45 = vadd.s32 2, %v56555_v23 (stack40)
        %v120902_v53 = vpop.eup %120901 (stack64)
        %v54875_v40 = vsel /*vm=*/%vm54866_vm9, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v54974_v22 = vmul.f32 %v54970_v32, %v138397_v24 (stack54)
        %v55727_v20 = vor.u32 %v55726_v9, %v55725_v41 (stack47)
        %v56984_v10 = vor.u32 %v56983_v31, %v56982_v12 (stack47)
        %v55317_v52 = vmul.f32 0.6931472, %v120902_v53 (stack65)
        %v55320_v44 = vmul.f32 %v55319_v25, %v138423_v44 (stack63)
        %v56116_v25 = vor.u32 %v56115_v50, %v56114_v54 (stack47)
        %v56563_v61 = vadd.s32 %v56559_v45, %v56547_v61 (stack40)
        %v54978_v12 = vadd.f32 %v54974_v22, %v54875_v40 (stack53)
        %vm55322_vm14 = vcmp.lt.f32.partialorder %v55321_v21, 0.0004427343 (stack62)
        %v55728_v21 = vxor.u32 %v55727_v20, %v55719_v60 (stack48)
        %v56985_v31 = vxor.u32 %v56984_v10, %v56980_v43 (stack48)
        %v55323_v6 = vsel /*vm=*/%vm55322_vm14, /*on_true_vy=*/%v55320_v44, /*on_false_vx=*/%v55317_v52 (stack66)
        %v56117_v23 = vxor.u32 %v56116_v25, %v56112_v29 (stack48)
        %v57399_v32 = vshll.u32 %v138443_v46, 13 (stack45)
        %v57400_v46 = vshrl.u32 %v138443_v46, 19 (stack46)
        %v54982_v24 = vmul.f32 %v54978_v12, %v138397_v24 (stack54)
        %v138471_v41 = vxor.u32 2147483648, %v55323_v6 (stack56)
        %v56565_v9 = vshll.u32 %v56559_v45, 13 (stack45)
        %v56566_v54 = vshrl.u32 %v56559_v45, 19 (stack46)
        %v56120_v29 = vadd.s32 %v56117_v23, %v56112_v29 (stack40)
        %v56122_v50 = vshll.u32 %v56117_v23, 29 (stack45)
        %v56123_v45 = vshrl.u32 %v56117_v23, 3 (stack46)
        %v56988_v43 = vadd.s32 %v56985_v31, %v56980_v43 (stack40)
        %v54986_v42 = vadd.f32 %v54982_v24, %v138413_v42 (stack53)
        %120903 = vrsqrt.f32 %v138471_v41 (stack67)
        %v54847_v53 = vmul.f32 inf, %v138284_v34 (stack54)
        %vm55327_vm15 = vcmp.lt.f32.partialorder %v138471_v41, 5.0 (stack68)
        %v55731_v40 = vadd.s32 %v55728_v21, %v121574_v2 (stack40)
        %v56124_v22 = vor.u32 %v56123_v45, %v56122_v50 (stack47)
        %vm54842_vm0 = vcmp.eq.f32.partialorder %v54839_v26, 1.0 (stack68)
        %v54990_v34 = vmul.f32 %v54986_v42, %v138284_v34 (stack54)
        %v55723_v26 = vadd.s32 %v55719_v60, %v121564_v0 (stack40)
        %v56567_v60 = vor.u32 %v56566_v54, %v56565_v9 (stack47)
        %v138483_v20 = vadd.f32 -2.5, %v138471_v41 (stack53)
        %v56125_v10 = vxor.u32 %v56124_v22, %v56120_v29 (stack48)
        %v57401_v52 = vor.u32 %v57400_v46, %v57399_v32 (stack47)
        %v138487_v44 = vadd.s32 %v138457_v8, %v122657_v58 (stack40)
        %v54994_v25 = vsel /*vm=*/%vm54842_vm0, /*on_true_vy=*/%v54847_v53, /*on_false_vx=*/%v54990_v34 (stack44)
        %v138492_v12 = vsel /*vm=*/%vm55327_vm15, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v138497_v21 = vsel /*vm=*/%vm55327_vm15, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v138502_v6 = vsel /*vm=*/%vm55327_vm15, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v54998_v23 = vmul.f32 1.4140625, %v54994_v25 (stack54)
        %v55735_v32 = vadd.s32 5, %v55731_v40 (stack40)
        %v56128_v46 = vadd.s32 %v56125_v10, %v56120_v29 (stack40)
        %v56130_v24 = vshll.u32 %v56125_v10, 16 (stack45)
        %v56131_v9 = vshrl.u32 %v56125_v10, 16 (stack46)
        %v56568_v54 = vxor.u32 %v56567_v60, %v56563_v61 (stack48)
        %v56990_v29 = vshll.u32 %v56985_v31, 29 (stack45)
        %v56991_v31 = vshrl.u32 %v56985_v31, 3 (stack46)
        %v55001_v50 = vpack.c.bf16 %v157387_v11, %v54998_v23 (stack81)
        %vm55372_vm1 = vcmp.eq.f32.partialorder %v138471_v41, inf (stack70)
        %v55737_v45 = vxor.u32 %v55735_v32, %v55723_v26 (stack48)
        %v57402_v42 = vxor.u32 %v57401_v52, %v138449_v7 (stack48)
        %vm55374_vm2 = vcmp.eq.f32.partialorder %v138471_v41, 0.0 (stack71)
        %v56132_v53 = vor.u32 %v56131_v9, %v56130_v24 (stack47)
        %v56571_v61 = vadd.s32 %v56568_v54, %v56563_v61 (stack40)
        %v56573_v40 = vshll.u32 %v56568_v54, 15 (stack45)
        %v56574_v22 = vshrl.u32 %v56568_v54, 17 (stack46)
        %120037 = vst [vmem:[%s123356_s30 + $0x238] sm:$0xf] /*vst_source=*/%v55001_v50 (stack83)
        %v55375_v34 = vand.u32 2147483648, %v138471_v41 (stack72)
        %v55738_v26 = vand.u32.u8 255, %v55737_v45 (stack49)
        %v56992_v60 = vor.u32 %v56991_v31, %v56990_v29 (stack47)
        %v57405_v7 = vadd.s32 %v57402_v42, %v138449_v7 (stack40)
        %v56133_v10 = vxor.u32 %v56132_v53, %v56128_v46 (stack48)
        %v56575_v52 = vor.u32 %v56574_v22, %v56573_v40 (stack47)
        %v57407_v25 = vshll.u32 %v57402_v42, 15 (stack45)
        %vm57824_vm3 = vcmp.lt.u32.totalorder %v138457_v8, %v157079_v39 (stack43)
        %v55739_v23 = vand.u32 65535, %v55738_v26 (stack50)
        %v56993_v32 = vxor.u32 %v56992_v60, %v56988_v43 (stack48)
        %v57408_v24 = vshrl.u32 %v57402_v42, 17 (stack46)
        %v57833_v9 = vadd.s32 1, %v138461_v55 (stack40)
        %v56136_v46 = vadd.s32 %v56133_v10, %v56128_v46 (stack40)
        %v56142_v54 = vshll.u32 %v56133_v10, 24 (stack45)
        %v56143_v29 = vshrl.u32 %v56133_v10, 8 (stack46)
        %v56576_v31 = vxor.u32 %v56575_v52, %v56571_v61 (stack48)
        %v120904_v50 = vpop.eup %120903 (stack73)
        %v55740_v45 = vshrl.u32 %v55739_v23, 1 (stack51)
        %v56996_v43 = vadd.s32 %v56993_v32, %v56988_v43 (stack40)
        %v56998_v42 = vshll.u32 %v56993_v32, 16 (stack45)
        %v56999_v53 = vshrl.u32 %v56993_v32, 16 (stack46)
        %v55371_v40 = vmul.f32 %v120904_v50, %v138471_v41 (stack74)
        %v56140_v22 = vadd.s32 %v56136_v46, %v121569_v1 (stack40)
        %v56144_v26 = vor.u32 %v56143_v29, %v56142_v54 (stack47)
        %v56579_v61 = vadd.s32 %v56576_v31, %v56571_v61 (stack40)
        %vm57819_vm4 = vcmp.lt.u32.totalorder %v138487_v44, %v138457_v8 (stack43)
        %v55741_v60 = vor.u32 16256, %v55740_v45 (stack47)
        %v56581_v10 = vshll.u32 %v56576_v31, 26 (stack45)
        %v56582_v52 = vshrl.u32 %v56576_v31, 6 (stack46)
        %v57000_v23 = vor.u32 %v56999_v53, %v56998_v42 (stack47)
        %v55373_v32 = vsel /*vm=*/%vm55372_vm1, /*on_true_vy=*/%v138471_v41, /*on_false_vx=*/%v55371_v40 (stack75)
        %v56145_v46 = vxor.u32 %v56144_v26, %v56136_v46 (stack48)
        %v57409_v25 = vor.u32 %v57408_v24, %v57407_v25 (stack47)
        %v57837_v55 = vsel /*vm=*/%vm57824_vm3, /*on_true_vy=*/%v57833_v9, /*on_false_vx=*/%v138461_v55 (stack44)
        %v55376_v34 = vsel /*vm=*/%vm55374_vm2, /*on_true_vy=*/%v55375_v34, /*on_false_vx=*/%v55373_v32 (stack76)
        %v55742_v24 = vand.u32.u16 65535, %v55741_v60 (stack52)
        %v56583_v9 = vor.u32 %v56582_v52, %v56581_v10 (stack47)
        %v57001_v54 = vxor.u32 %v57000_v23, %v56996_v43 (stack48)
        %v55379_v29 = vadd.f32 -3.0, %v55376_v34 (stack53)
        %v56148_v31 = vadd.s32 %v56145_v46, %v121564_v0 (stack40)
        %v57410_v50 = vxor.u32 %v57409_v25, %v57405_v7 (stack48)
        %v57841_v45 = vadd.s32 1, %v57837_v55 (stack40)
        %v120040_v42 = vadd.low.f32.bf16 -1.0, %v55742_v24 (stack53)
        %v56584_v53 = vxor.u32 %v56583_v9, %v56579_v61 (stack48)
        %v57004_v43 = vadd.s32 %v57001_v54, %v56996_v43 (stack40)
        %v57010_v40 = vshll.u32 %v57001_v54, 24 (stack45)
        %v138531_v20 = vsel /*vm=*/%vm55327_vm15, /*on_true_vy=*/%v138483_v20, /*on_false_vx=*/%v55379_v29 (stack44)
        %v56152_v26 = vadd.s32 4, %v56148_v31 (stack40)
        %v57011_v60 = vshrl.u32 %v57001_v54, 8 (stack46)
        %v138533_v7 = vadd.s32 %v57410_v50, %v57405_v7 (stack40)
        %v55387_v6 = vmul.f32 %v138531_v20, %v138502_v6 (stack54)
        %v55751_v10 = vmul.f32 2.0, %v120040_v42 (stack54)
        %v56587_v61 = vadd.s32 %v56584_v53, %v56579_v61 (stack40)
        %v56593_v52 = vshll.u32 %v56584_v53, 6 (stack45)
        %v56156_v22 = vadd.s32 %v56152_v26, %v56140_v22 (stack40)
        %v56158_v23 = vshll.u32 %v56152_v26, 13 (stack45)
        %v56159_v32 = vshrl.u32 %v56152_v26, 19 (stack46)
        %v56594_v46 = vshrl.u32 %v56584_v53, 26 (stack46)
        %v138540_v25 = vsel /*vm=*/%vm55327_vm15, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v55348_v34 = vsel /*vm=*/%vm55327_vm15, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v55391_v21 = vadd.f32 %v55387_v6, %v138497_v21 (stack53)
        %v55755_v24 = vadd.f32 -0.99609375, %v55751_v10 (stack53)
        %v55356_v9 = vsel /*vm=*/%vm55327_vm15, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v56160_v54 = vor.u32 %v56159_v32, %v56158_v23 (stack47)
        %v56595_v29 = vor.u32 %v56594_v46, %v56593_v52 (stack47)
        %v57012_v31 = vor.u32 %v57011_v60, %v57010_v40 (stack47)
        %v55395_v42 = vmul.f32 %v55391_v21, %v138531_v20 (stack54)
        %v138550_v53 = vmax.f32 %v55755_v24, -0.99609375 (stack55)
        %v57845_v8 = vsel /*vm=*/%vm57819_vm4, /*on_true_vy=*/%v57841_v45, /*on_false_vx=*/%v57837_v55 (stack44)
        %v138557_v44 = vadd.s32 %v138487_v44, %v121569_v1 (stack40)
        %v56161_v55 = vxor.u32 %v56160_v54, %v56156_v22 (stack48)
        %v56596_v45 = vxor.u32 %v56595_v29, %v56587_v61 (stack48)
        %v57013_v40 = vxor.u32 %v57012_v31, %v57004_v43 (stack48)
        %v57850_v26 = vadd.s32 %v57845_v8, %v121574_v2 (stack40)
        %v55399_v60 = vadd.f32 %v55395_v42, %v55356_v9 (stack53)
        %v55771_v6 = vxor.u32 2147483648, %v138550_v53 (stack56)
        %v57415_v10 = vshll.u32 %v57410_v50, 26 (stack45)
        %v57416_v50 = vshrl.u32 %v57410_v50, 6 (stack46)
        %v56164_v52 = vadd.s32 %v56161_v55, %v56156_v22 (stack40)
        %v56166_v22 = vshll.u32 %v56161_v55, 15 (stack45)
        %v56167_v23 = vshrl.u32 %v56161_v55, 17 (stack46)
        %v56599_v32 = vadd.s32 %v56596_v45, %v121569_v1 (stack40)
        %v55352_v46 = vsel /*vm=*/%vm55327_vm15, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v55403_v21 = vmul.f32 %v55399_v60, %v138531_v20 (stack54)
        %v55774_v24 = vmul.f32 %v55771_v6, %v138550_v53 (stack54)
        %v56591_v61 = vadd.s32 %v56587_v61, %v121574_v2 (stack40)
        %v56168_v9 = vor.u32 %v56167_v23, %v56166_v22 (stack47)
        %v56603_v54 = vadd.s32 3, %v56599_v32 (stack40)
        %v57016_v29 = vadd.s32 %v57013_v40, %v121574_v2 (stack40)
        %v138570_v31 = vadd.s32 %v138557_v44, %v57850_v26 (stack40)
        %v55407_v42 = vadd.f32 %v55403_v21, %v55352_v46 (stack53)
        %v55776_v8 = vadd.f32 1.0, %v55774_v24 (stack57)
        %v55779_v55 = vmul.f32 -0.5, %v55774_v24 (stack59)
        %v57417_v45 = vor.u32 %v57416_v50, %v57415_v10 (stack47)
        %v56169_v40 = vxor.u32 %v56168_v9, %v56164_v52 (stack48)
        %v56607_v26 = vadd.s32 %v56603_v54, %v56591_v61 (stack40)
        %v56609_v60 = vshll.u32 %v56603_v54, 17 (stack45)
        %v56610_v6 = vshrl.u32 %v56603_v54, 15 (stack46)
        %v55411_v10 = vmul.f32 %v55407_v42, %v138531_v20 (stack54)
        %120905 = vlog2.f32 %v55776_v8 (stack58)
        %v55782_v50 = vand.u32 2147483647, %v55774_v24 (stack60)
        %v57008_v43 = vadd.s32 %v57004_v43, %v121564_v0 (stack40)
        %v56172_v52 = vadd.s32 %v56169_v40, %v56164_v52 (stack40)
        %v56174_v22 = vshll.u32 %v56169_v40, 26 (stack45)
        %v56175_v23 = vshrl.u32 %v56169_v40, 6 (stack46)
        %v56611_v32 = vor.u32 %v56610_v6, %v56609_v60 (stack47)
        %v55415_v34 = vadd.f32 %v55411_v10, %v55348_v34 (stack53)
        %v55780_v46 = vadd.f32 1.0, %v55779_v55 (stack61)
        %v57020_v21 = vadd.s32 2, %v57016_v29 (stack40)
        %v57418_v61 = vxor.u32 %v57417_v45, %v138533_v7 (stack48)
        %v56176_v9 = vor.u32 %v56175_v23, %v56174_v22 (stack47)
        %v56612_v54 = vxor.u32 %v56611_v32, %v56607_v26 (stack48)
        %v57860_v29 = vshll.u32 %v138557_v44, 13 (stack45)
        %v57861_v44 = vshrl.u32 %v138557_v44, 19 (stack46)
        %v55419_v42 = vmul.f32 %v55415_v34, %v138531_v20 (stack54)
        %v57024_v8 = vadd.s32 %v57020_v21, %v57008_v43 (stack40)
        %v57026_v55 = vshll.u32 %v57020_v21, 13 (stack45)
        %v57027_v45 = vshrl.u32 %v57020_v21, 19 (stack46)
        %v56177_v40 = vxor.u32 %v56176_v9, %v56172_v52 (stack48)
        %v56615_v26 = vadd.s32 %v56612_v54, %v56607_v26 (stack40)
        %v56617_v60 = vshll.u32 %v56612_v54, 29 (stack45)
        %v56618_v6 = vshrl.u32 %v56612_v54, 3 (stack46)
        %v55340_v10 = vsel /*vm=*/%vm55327_vm15, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v55423_v25 = vadd.f32 %v55419_v42, %v138540_v25 (stack53)
        %v57028_v43 = vor.u32 %v57027_v45, %v57026_v55 (stack47)
        %v57421_v7 = vadd.s32 %v57418_v61, %v138533_v7 (stack40)
        %vm138583_vm5 = vcmp.lt.f32.partialorder %v55782_v50, 0.0004427343 (stack62)
        %v56180_v52 = vadd.s32 %v56177_v40, %v56172_v52 (stack40)
        %v56186_v22 = vshll.u32 %v56177_v40, 6 (stack45)
        %v56187_v23 = vshrl.u32 %v56177_v40, 26 (stack46)
        %v56619_v32 = vor.u32 %v56618_v6, %v56617_v60 (stack47)
        %v55427_v34 = vmul.f32 %v55423_v25, %v138531_v20 (stack54)
        %v57029_v21 = vxor.u32 %v57028_v43, %v57024_v8 (stack48)
        %v57427_v9 = vshll.u32 %v57418_v61, 6 (stack45)
        %v57428_v61 = vshrl.u32 %v57418_v61, 26 (stack46)
        %v55781_v24 = vmul.f32 %v55780_v46, %v55774_v24 (stack63)
        %v56188_v46 = vor.u32 %v56187_v23, %v56186_v22 (stack47)
        %v56620_v54 = vxor.u32 %v56619_v32, %v56615_v26 (stack48)
        %v57862_v29 = vor.u32 %v57861_v44, %v57860_v29 (stack47)
        %v55431_v44 = vadd.f32 %v55427_v34, %v55340_v10 (stack53)
        %v57032_v42 = vadd.s32 %v57029_v21, %v57024_v8 (stack40)
        %v57034_v8 = vshll.u32 %v57029_v21, 15 (stack45)
        %v57035_v55 = vshrl.u32 %v57029_v21, 17 (stack46)
        %v56189_v45 = vxor.u32 %v56188_v46, %v56180_v52 (stack48)
        %v56623_v40 = vadd.s32 %v56620_v54, %v56615_v26 (stack40)
        %v56625_v26 = vshll.u32 %v56620_v54, 16 (stack45)
        %v56626_v60 = vshrl.u32 %v56620_v54, 16 (stack46)
        %v55435_v6 = vmul.f32 %v55431_v44, %v138531_v20 (stack54)
        %v57036_v10 = vor.u32 %v57035_v55, %v57034_v8 (stack47)
        %v57429_v25 = vor.u32 %v57428_v61, %v57427_v9 (stack47)
        %v57863_v43 = vxor.u32 %v57862_v29, %v138570_v31 (stack48)
        %v120906_v22 = vpop.eup %120905 (stack64)
        %v56192_v23 = vadd.s32 %v56189_v45, %v121574_v2 (stack40)
        %v56627_v32 = vor.u32 %v56626_v60, %v56625_v26 (stack47)
        %v138593_v34 = vadd.s32 %v157412_v30, %v157083_v59 (stack40)
        %v138597_v21 = vadd.s32 %v157415_v27, %v157084_v16 (stack40)
        %v55439_v12 = vadd.f32 %v55435_v6, %v138492_v12 (stack53)
        %v55778_v9 = vmul.f32 0.6931472, %v120906_v22 (stack65)
        %v57037_v61 = vxor.u32 %v57036_v10, %v57032_v42 (stack48)
        %v57430_v46 = vxor.u32 %v57429_v25, %v57421_v7 (stack48)
        %v56184_v52 = vadd.s32 %v56180_v52, %v121564_v0 (stack40)
        %v56196_v54 = vadd.s32 5, %v56192_v23 (stack40)
        %v56628_v29 = vxor.u32 %v56627_v32, %v56623_v40 (stack48)
        %v57866_v31 = vadd.s32 %v57863_v43, %v138570_v31 (stack40)
        %v55300_v44 = vand.u32 2147483647, %v138406_v56 (stack77)
        %v55443_v20 = vmul.f32 %v55439_v12, %v138531_v20 (stack54)
        %v55784_v50 = vsel /*vm=*/%vm138583_vm5, /*on_true_vy=*/%v55781_v24, /*on_false_vx=*/%v55778_v9 (stack66)
        %v57040_v24 = vadd.s32 %v57037_v61, %v57032_v42 (stack40)
        %v55332_v41 = vsel /*vm=*/%vm55327_vm15, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v138609_v42 = vxor.u32 2147483648, %v55784_v50 (stack56)
        %v56198_v8 = vxor.u32 %v56196_v54, %v56184_v52 (stack48)
        %v56631_v55 = vadd.s32 %v56628_v29, %v56623_v40 (stack40)
        %v55308_v45 = vmul.f32 inf, %v138406_v56 (stack54)
        %v55447_v40 = vadd.f32 %v55443_v20, %v55332_v41 (stack53)
        %vm55788_vm6 = vcmp.lt.f32.partialorder %v138609_v42, 5.0 (stack68)
        %120907 = vrsqrt.f32 %v138609_v42 (stack67)
        %v56637_v26 = vshll.u32 %v56628_v29, 24 (stack45)
        %v57042_v60 = vshll.u32 %v57037_v61, 26 (stack45)
        %v55451_v56 = vmul.f32 %v55447_v40, %v138406_v56 (stack54)
        %v56638_v6 = vshrl.u32 %v56628_v29, 8 (stack46)
        %v57043_v10 = vshrl.u32 %v57037_v61, 6 (stack46)
        %v57433_v25 = vadd.s32 %v57430_v46, %v121564_v0 (stack40)
        %vm55303_vm7 = vcmp.eq.f32.partialorder %v55300_v44, 1.0 (stack68)
        %v57425_v7 = vadd.s32 %v57421_v7, %v121569_v1 (stack40)
        %v55455_v22 = vsel /*vm=*/%vm55303_vm7, /*on_true_vy=*/%v55308_v45, /*on_false_vx=*/%v55451_v56 (stack44)
        %v138620_v23 = vsel /*vm=*/%vm55788_vm6, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v138623_v32 = vadd.f32 -2.5, %v138609_v42 (stack53)
        %v57868_v12 = vshll.u32 %v57863_v43, 15 (stack45)
        %v55459_v9 = vmul.f32 1.4140625, %v55455_v22 (stack54)
        %v138628_v61 = vsel /*vm=*/%vm55788_vm6, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v138633_v46 = vsel /*vm=*/%vm55788_vm6, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v56199_v52 = vand.u32.u8 255, %v56198_v8 (stack49)
        %v56639_v54 = vor.u32 %v56638_v6, %v56637_v26 (stack47)
        %v57044_v29 = vor.u32 %v57043_v10, %v57042_v60 (stack47)
        %v57437_v44 = vadd.s32 1, %v57433_v25 (stack40)
        %v57869_v43 = vshrl.u32 %v57863_v43, 17 (stack46)
        %v55462_v20 = vpack.c.bf16 %v157387_v11, %v55459_v9 (stack81)
        %v56200_v50 = vand.u32 65535, %v56199_v52 (stack50)
        %v56635_v41 = vadd.s32 %v56631_v55, %v121569_v1 (stack40)
        %vm58285_vm8 = vcmp.lt.u32.totalorder %v138593_v34, %v157083_v59 (stack43)
        %vm55833_vm9 = vcmp.eq.f32.partialorder %v138609_v42, inf (stack70)
        %v56640_v8 = vxor.u32 %v56639_v54, %v56631_v55 (stack48)
        %v57045_v55 = vxor.u32 %v57044_v29, %v57040_v24 (stack48)
        %v57441_v45 = vadd.s32 %v57437_v44, %v57425_v7 (stack40)
        %v57443_v40 = vshll.u32 %v57437_v44, 17 (stack45)
        %120039 = vst [vmem:[%s123356_s30 + $0x2b8] sm:$0xf] /*vst_source=*/%v55462_v20 (stack83)
        %v55825_v26 = vsel /*vm=*/%vm55788_vm6, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v56201_v60 = vshrl.u32 %v56200_v50, 1 (stack51)
        %v57444_v56 = vshrl.u32 %v57437_v44, 15 (stack46)
        %v57870_v6 = vor.u32 %v57869_v43, %v57868_v12 (stack47)
        %v56643_v10 = vadd.s32 %v56640_v8, %v121564_v0 (stack40)
        %v57048_v24 = vadd.s32 %v57045_v55, %v57040_v24 (stack40)
        %v57054_v25 = vshll.u32 %v57045_v55, 6 (stack45)
        %v57055_v7 = vshrl.u32 %v57045_v55, 26 (stack46)
        %vm55835_vm10 = vcmp.eq.f32.partialorder %v138609_v42, 0.0 (stack71)
        %v56202_v22 = vor.u32 16256, %v56201_v60 (stack47)
        %v57445_v12 = vor.u32 %v57444_v56, %v57443_v40 (stack47)
        %v57871_v9 = vxor.u32 %v57870_v6, %v57866_v31 (stack48)
        %v55836_v52 = vand.u32 2147483648, %v138609_v42 (stack72)
        %v56647_v54 = vadd.s32 4, %v56643_v10 (stack40)
        %v57056_v29 = vor.u32 %v57055_v7, %v57054_v25 (stack47)
        %v58294_v44 = vadd.s32 1, %v138597_v21 (stack40)
        %v56203_v43 = vand.u32.u16 65535, %v56202_v22 (stack52)
        %v57446_v20 = vxor.u32 %v57445_v12, %v57441_v45 (stack48)
        %v138648_v31 = vadd.s32 %v57871_v9, %v57866_v31 (stack40)
        %v57876_v50 = vshll.u32 %v57871_v9, 26 (stack45)
        %v120908_v8 = vpop.eup %120907 (stack73)
        %v56651_v41 = vadd.s32 %v56647_v54, %v56635_v41 (stack40)
        %v56653_v55 = vshll.u32 %v56647_v54, 13 (stack45)
        %v56654_v40 = vshrl.u32 %v56647_v54, 19 (stack46)
        %v57057_v60 = vxor.u32 %v57056_v29, %v57048_v24 (stack48)
        %v55832_v56 = vmul.f32 %v120908_v8, %v138609_v42 (stack74)
        %v120042_v6 = vadd.low.f32.bf16 -1.0, %v56203_v43 (stack53)
        %v57449_v45 = vadd.s32 %v57446_v20, %v57441_v45 (stack40)
        %v57451_v10 = vshll.u32 %v57446_v20, 29 (stack45)
        %v56655_v25 = vor.u32 %v56654_v40, %v56653_v55 (stack47)
        %v57060_v7 = vadd.s32 %v57057_v60, %v121569_v1 (stack40)
        %v57452_v22 = vshrl.u32 %v57446_v20, 3 (stack46)
        %v57877_v12 = vshrl.u32 %v57871_v9, 6 (stack46)
        %v55834_v9 = vsel /*vm=*/%vm55833_vm9, /*on_true_vy=*/%v138609_v42, /*on_false_vx=*/%v55832_v56 (stack75)
        %v56212_v54 = vmul.f32 2.0, %v120042_v6 (stack54)
        %v57052_v24 = vadd.s32 %v57048_v24, %v121574_v2 (stack40)
        %v138660_v21 = vsel /*vm=*/%vm58285_vm8, /*on_true_vy=*/%v58294_v44, /*on_false_vx=*/%v138597_v21 (stack44)
        %v55837_v52 = vsel /*vm=*/%vm55835_vm10, /*on_true_vy=*/%v55836_v52, /*on_false_vx=*/%v55834_v9 (stack76)
        %v56656_v29 = vxor.u32 %v56655_v25, %v56651_v41 (stack48)
        %v57064_v44 = vadd.s32 3, %v57060_v7 (stack40)
        %v57453_v43 = vor.u32 %v57452_v22, %v57451_v10 (stack47)
        %v55840_v20 = vadd.f32 -3.0, %v55837_v52 (stack53)
        %v56216_v8 = vadd.f32 -0.99609375, %v56212_v54 (stack53)
        %v57878_v50 = vor.u32 %v57877_v12, %v57876_v50 (stack47)
        %v138666_v55 = vadd.s32 %v138593_v34, %v122657_v58 (stack40)
        %v56659_v41 = vadd.s32 %v56656_v29, %v56651_v41 (stack40)
        %v56661_v40 = vshll.u32 %v56656_v29, 15 (stack45)
        %v56662_v60 = vshrl.u32 %v56656_v29, 17 (stack46)
        %v57068_v56 = vadd.s32 %v57064_v44, %v57052_v24 (stack40)
        %v138671_v32 = vsel /*vm=*/%vm55788_vm6, /*on_true_vy=*/%v138623_v32, /*on_false_vx=*/%v55840_v20 (stack44)
        %v138673_v6 = vmax.f32 %v56216_v8, -0.99609375 (stack55)
        %v57070_v10 = vshll.u32 %v57064_v44, 17 (stack45)
        %v57071_v25 = vshrl.u32 %v57064_v44, 15 (stack46)
        %v55848_v26 = vmul.f32 %v138671_v32, %v55825_v26 (stack54)
        %v56663_v7 = vor.u32 %v56662_v60, %v56661_v40 (stack47)
        %v57454_v22 = vxor.u32 %v57453_v43, %v57449_v45 (stack48)
        %v57879_v12 = vxor.u32 %v57878_v50, %v138648_v31 (stack48)
        %v55813_v9 = vsel /*vm=*/%vm55788_vm6, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v55821_v54 = vsel /*vm=*/%vm55788_vm6, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v56232_v24 = vxor.u32 2147483648, %v138673_v6 (stack56)
        %v57072_v52 = vor.u32 %v57071_v25, %v57070_v10 (stack47)
        %v55817_v29 = vsel /*vm=*/%vm55788_vm6, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v55852_v44 = vadd.f32 %v55848_v26, %v55821_v54 (stack53)
        %v56664_v43 = vxor.u32 %v56663_v7, %v56659_v41 (stack48)
        %v57457_v45 = vadd.s32 %v57454_v22, %v57449_v45 (stack40)
        %v56235_v20 = vmul.f32 %v56232_v24, %v138673_v6 (stack54)
        %v57073_v8 = vxor.u32 %v57072_v52, %v57068_v56 (stack48)
        %v57459_v50 = vshll.u32 %v57454_v22, 16 (stack45)
        %v57460_v40 = vshrl.u32 %v57454_v22, 16 (stack46)
        %v55856_v60 = vmul.f32 %v55852_v44, %v138671_v32 (stack54)
        %v56667_v41 = vadd.s32 %v56664_v43, %v56659_v41 (stack40)
        %v56669_v10 = vshll.u32 %v56664_v43, 26 (stack45)
        %v56670_v25 = vshrl.u32 %v56664_v43, 6 (stack46)
        %vm58280_vm11 = vcmp.lt.u32.totalorder %v138666_v55, %v138593_v34 (stack43)
        %v56237_v26 = vadd.f32 1.0, %v56235_v20 (stack57)
        %v56240_v7 = vmul.f32 -0.5, %v56235_v20 (stack59)
        %v57076_v56 = vadd.s32 %v57073_v8, %v57068_v56 (stack40)
        %v58315_v22 = vadd.s32 %v138666_v55, %v121569_v1 (stack40)
        %v55860_v54 = vadd.f32 %v55856_v60, %v55817_v29 (stack53)
        %v56671_v24 = vor.u32 %v56670_v25, %v56669_v10 (stack47)
        %v57078_v52 = vshll.u32 %v57073_v8, 29 (stack45)
        %v57079_v29 = vshrl.u32 %v57073_v8, 3 (stack46)
        %120909 = vlog2.f32 %v56237_v26 (stack58)
        %v56241_v44 = vadd.f32 1.0, %v56240_v7 (stack61)
        %v57461_v43 = vor.u32 %v57460_v40, %v57459_v50 (stack47)
        %v58302_v8 = vadd.s32 1, %v138660_v21 (stack40)
        %v55864_v50 = vmul.f32 %v55860_v54, %v138671_v32 (stack54)
        %v56672_v40 = vxor.u32 %v56671_v24, %v56667_v41 (stack48)
        %v57080_v60 = vor.u32 %v57079_v29, %v57078_v52 (stack47)
        %v57882_v31 = vadd.s32 %v57879_v12, %v138648_v31 (stack40)
        %v56243_v10 = vand.u32 2147483647, %v56235_v20 (stack60)
        %v57462_v25 = vxor.u32 %v57461_v43, %v57457_v45 (stack48)
        %v57888_v26 = vshll.u32 %v57879_v12, 6 (stack45)
        %v57889_v12 = vshrl.u32 %v57879_v12, 26 (stack46)
        %v55868_v9 = vadd.f32 %v55864_v50, %v55813_v9 (stack53)
        %v56675_v41 = vadd.s32 %v56672_v40, %v56667_v41 (stack40)
        %v56681_v7 = vshll.u32 %v56672_v40, 6 (stack45)
        %v56682_v54 = vshrl.u32 %v56672_v40, 26 (stack46)
        %v57081_v24 = vxor.u32 %v57080_v60, %v57076_v56 (stack48)
        %v57465_v45 = vadd.s32 %v57462_v25, %v57457_v45 (stack40)
        %v57471_v52 = vshll.u32 %v57462_v25, 24 (stack45)
        %v57472_v29 = vshrl.u32 %v57462_v25, 8 (stack46)
        %v55872_v43 = vmul.f32 %v55868_v9, %v138671_v32 (stack54)
        %v56242_v20 = vmul.f32 %v56241_v44, %v56235_v20 (stack63)
        %v56683_v44 = vor.u32 %v56682_v54, %v56681_v7 (stack47)
        %v58321_v50 = vshll.u32 %v58315_v22, 13 (stack45)
        %v56679_v40 = vadd.s32 %v56675_v41, %v121564_v0 (stack40)
        %v57084_v56 = vadd.s32 %v57081_v24, %v57076_v56 (stack40)
        %v57086_v60 = vshll.u32 %v57081_v24, 16 (stack45)
        %v57087_v25 = vshrl.u32 %v57081_v24, 16 (stack46)
        %v55876_v46 = vadd.f32 %v55872_v43, %v138633_v46 (stack53)
        %vm138699_vm12 = vcmp.lt.f32.partialorder %v56243_v10, 0.0004427343 (stack62)
        %v56684_v9 = vxor.u32 %v56683_v44, %v56675_v41 (stack48)
        %v57473_v41 = vor.u32 %v57472_v29, %v57471_v52 (stack47)
        %v57890_v26 = vor.u32 %v57889_v12, %v57888_v26 (stack47)
        %v57088_v12 = vor.u32 %v57087_v25, %v57086_v60 (stack47)
        %v58306_v34 = vsel /*vm=*/%vm58280_vm11, /*on_true_vy=*/%v58302_v8, /*on_false_vx=*/%v138660_v21 (stack44)
        %v58322_v21 = vshrl.u32 %v58315_v22, 19 (stack46)
        %v138709_v55 = vadd.s32 %v157412_v30, %v157089_v17 (stack40)
        %v55880_v8 = vmul.f32 %v55876_v46, %v138671_v32 (stack54)
        %v56687_v7 = vadd.s32 %v56684_v9, %v121574_v2 (stack40)
        %v57474_v54 = vxor.u32 %v57473_v41, %v57465_v45 (stack48)
        %v57891_v24 = vxor.u32 %v57890_v26, %v57882_v31 (stack48)
        %v57089_v52 = vxor.u32 %v57088_v12, %v57084_v56 (stack48)
        %v57469_v45 = vadd.s32 %v57465_v45, %v121564_v0 (stack40)
        %v58311_v29 = vadd.s32 %v58306_v34, %v121574_v2 (stack40)
        %v58323_v43 = vor.u32 %v58322_v21, %v58321_v50 (stack47)
        %v55884_v61 = vadd.f32 %v55880_v8, %v138628_v61 (stack53)
        %v56691_v44 = vadd.s32 5, %v56687_v7 (stack40)
        %v57477_v50 = vadd.s32 %v57474_v54, %v121574_v2 (stack40)
        %v57894_v60 = vadd.s32 %v57891_v24, %v121564_v0 (stack40)
        %v57092_v56 = vadd.s32 %v57089_v52, %v57084_v56 (stack40)
        %v57098_v25 = vshll.u32 %v57089_v52, 24 (stack45)
        %v57099_v46 = vshrl.u32 %v57089_v52, 8 (stack46)
        %v58319_v22 = vadd.s32 %v58315_v22, %v58311_v29 (stack40)
        %v120910_v9 = vpop.eup %120909 (stack64)
        %v55888_v41 = vmul.f32 %v55884_v61, %v138671_v32 (stack54)
        %v56693_v40 = vxor.u32 %v56691_v44, %v56679_v40 (stack48)
        %v57481_v26 = vadd.s32 2, %v57477_v50 (stack40)
        %v57898_v12 = vadd.s32 1, %v57894_v60 (stack40)
        %v56239_v34 = vmul.f32 0.6931472, %v120910_v9 (stack65)
        %v57100_v21 = vor.u32 %v57099_v46, %v57098_v25 (stack47)
        %v57886_v31 = vadd.s32 %v57882_v31, %v121569_v1 (stack40)
        %v58324_v8 = vxor.u32 %v58323_v43, %v58319_v22 (stack48)
        %v55892_v23 = vadd.f32 %v55888_v41, %v138620_v23 (stack53)
        %v56694_v7 = vand.u32.u8 255, %v56693_v40 (stack49)
        %v57485_v54 = vadd.s32 %v57481_v26, %v57469_v45 (stack40)
        %v57487_v24 = vshll.u32 %v57481_v26, 13 (stack45)
        %v56245_v20 = vsel /*vm=*/%vm138699_vm12, /*on_true_vy=*/%v56242_v20, /*on_false_vx=*/%v56239_v34 (stack66)
        %v57101_v10 = vxor.u32 %v57100_v21, %v57092_v56 (stack48)
        %v57488_v52 = vshrl.u32 %v57481_v26, 19 (stack46)
        %v57902_v45 = vadd.s32 %v57898_v12, %v57886_v31 (stack40)
        %v55896_v29 = vmul.f32 %v55892_v23, %v138671_v32 (stack54)
        %v138724_v43 = vxor.u32 2147483648, %v56245_v20 (stack56)
        %v55761_v61 = vand.u32 2147483647, %v138550_v53 (stack77)
        %v55797_v44 = vsel /*vm=*/%vm55788_vm6, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v57489_v50 = vor.u32 %v57488_v52, %v57487_v24 (stack47)
        %v58327_v60 = vadd.s32 %v58324_v8, %v58319_v22 (stack40)
        %v55900_v25 = vadd.f32 %v55896_v29, %v55797_v44 (stack53)
        %120911 = vrsqrt.f32 %v138724_v43 (stack67)
        %v56695_v46 = vand.u32 65535, %v56694_v7 (stack50)
        %v57104_v22 = vadd.s32 %v57101_v10, %v121564_v0 (stack40)
        %v57490_v9 = vxor.u32 %v57489_v50, %v57485_v54 (stack48)
        %v55769_v41 = vmul.f32 inf, %v138550_v53 (stack54)
        %v55904_v32 = vmul.f32 %v55900_v25, %v138671_v32 (stack54)
        %v57904_v40 = vshll.u32 %v57898_v12, 17 (stack45)
        %v57905_v26 = vshrl.u32 %v57898_v12, 15 (stack46)
        %vm138734_vm13 = vcmp.eq.f32.partialorder %v55761_v61, 1.0 (stack68)
        %v55793_v42 = vsel /*vm=*/%vm55788_vm6, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v56222_v34 = vand.u32 2147483647, %v138673_v6 (stack77)
        %v57493_v21 = vadd.s32 %v57490_v9, %v57485_v54 (stack40)
        %v55908_v31 = vadd.f32 %v55904_v32, %v55793_v42 (stack53)
        %v138743_v23 = vadd.f32 -2.5, %v138724_v43 (stack53)
        %v57096_v56 = vadd.s32 %v57092_v56, %v121569_v1 (stack40)
        %v138748_v7 = vadd.s32 %v138709_v55, %v122657_v58 (stack40)
        %v56696_v54 = vshrl.u32 %v56695_v46, 1 (stack51)
        %v57108_v24 = vadd.s32 4, %v57104_v22 (stack40)
        %v57495_v20 = vshll.u32 %v57490_v9, 15 (stack45)
        %v57496_v10 = vshrl.u32 %v57490_v9, 17 (stack46)
        %v55912_v53 = vmul.f32 %v55908_v31, %v138550_v53 (stack54)
        %v57906_v52 = vor.u32 %v57905_v26, %v57904_v40 (stack47)
        %v58329_v29 = vshll.u32 %v58324_v8, 15 (stack45)
        %v58330_v8 = vshrl.u32 %v58324_v8, 17 (stack46)
        %vm56294_vm14 = vcmp.eq.f32.partialorder %v138724_v43, inf (stack70)
        %v56697_v61 = vor.u32 16256, %v56696_v54 (stack47)
        %v57112_v44 = vadd.s32 %v57108_v24, %v57096_v56 (stack40)
        %v57114_v50 = vshll.u32 %v57108_v24, 13 (stack45)
        %v57115_v25 = vshrl.u32 %v57108_v24, 19 (stack46)
        %v55916_v46 = vsel /*vm=*/%vm138734_vm13, /*on_true_vy=*/%v55769_v41, /*on_false_vx=*/%v55912_v53 (stack44)
        %vm56249_vm15 = vcmp.lt.f32.partialorder %v138724_v43, 5.0 (stack68)
        %vm56296_vm0 = vcmp.eq.f32.partialorder %v138724_v43, 0.0 (stack71)
        %v57497_v22 = vor.u32 %v57496_v10, %v57495_v20 (stack47)
        %v57907_v9 = vxor.u32 %v57906_v52, %v57902_v45 (stack48)
        %v58331_v41 = vor.u32 %v58330_v8, %v58329_v29 (stack47)
        %v55920_v32 = vmul.f32 1.4140625, %v55916_v46 (stack54)
        %v56297_v40 = vand.u32 2147483648, %v138724_v43 (stack72)
        %v56698_v26 = vand.u32.u16 65535, %v56697_v61 (stack52)
        %v57116_v12 = vor.u32 %v57115_v25, %v57114_v50 (stack47)
        %v57498_v42 = vxor.u32 %v57497_v22, %v57493_v21 (stack48)
        %v57910_v45 = vadd.s32 %v57907_v9, %v57902_v45 (stack40)
        %v57912_v31 = vshll.u32 %v57907_v9, 29 (stack45)
        %v57913_v56 = vshrl.u32 %v57907_v9, 3 (stack46)
        %v55923_v54 = vpack.c.bf16 %v157387_v11, %v55920_v32 (stack81)
        %v120048_v24 = vadd.low.f32.bf16 -1.0, %v56698_v26 (stack53)
        %v57117_v20 = vxor.u32 %v57116_v12, %v57112_v44 (stack48)
        %v58332_v10 = vxor.u32 %v58331_v41, %v58327_v60 (stack48)
        %v57501_v21 = vadd.s32 %v57498_v42, %v57493_v21 (stack40)
        %v57503_v53 = vshll.u32 %v57498_v42, 26 (stack45)
        %v57504_v52 = vshrl.u32 %v57498_v42, 6 (stack46)
        %v57914_v29 = vor.u32 %v57913_v56, %v57912_v31 (stack47)
        %v120912_v8 = vpop.eup %120911 (stack73)
        %120041 = vst [vmem:[%s123356_s30 + $0x338] sm:$0xf] /*vst_source=*/%v55923_v54 (stack83)
        %v56707_v61 = vmul.f32 2.0, %v120048_v24 (stack54)
        %v57120_v44 = vadd.s32 %v57117_v20, %v57112_v44 (stack40)
        %v57122_v50 = vshll.u32 %v57117_v20, 15 (stack45)
        %v57123_v25 = vshrl.u32 %v57117_v20, 17 (stack46)
        %v56293_v46 = vmul.f32 %v120912_v8, %v138724_v43 (stack74)
        %v57505_v22 = vor.u32 %v57504_v52, %v57503_v53 (stack47)
        %v57915_v9 = vxor.u32 %v57914_v29, %v57910_v45 (stack48)
        %v58335_v60 = vadd.s32 %v58332_v10, %v58327_v60 (stack40)
        %v56711_v41 = vadd.f32 -0.99609375, %v56707_v61 (stack53)
        %v57124_v32 = vor.u32 %v57123_v25, %v57122_v50 (stack47)
        %v58337_v26 = vshll.u32 %v58332_v10, 26 (stack45)
        %v58338_v12 = vshrl.u32 %v58332_v10, 6 (stack46)
        %v56295_v42 = vsel /*vm=*/%vm56294_vm14, /*on_true_vy=*/%v138724_v43, /*on_false_vx=*/%v56293_v46 (stack75)
        %v57506_v31 = vxor.u32 %v57505_v22, %v57501_v21 (stack48)
        %v57918_v45 = vadd.s32 %v57915_v9, %v57910_v45 (stack40)
        %v57920_v56 = vshll.u32 %v57915_v9, 16 (stack45)
        %v56298_v40 = vsel /*vm=*/%vm56296_vm0, /*on_true_vy=*/%v56297_v40, /*on_false_vx=*/%v56295_v42 (stack76)
        %v138765_v54 = vmax.f32 %v56711_v41, -0.99609375 (stack55)
        %v57125_v24 = vxor.u32 %v57124_v32, %v57120_v44 (stack48)
        %v57921_v20 = vshrl.u32 %v57915_v9, 16 (stack46)
        %v56301_v10 = vadd.f32 -3.0, %v56298_v40 (stack53)
        %v57509_v21 = vadd.s32 %v57506_v31, %v57501_v21 (stack40)
        %v57515_v53 = vshll.u32 %v57506_v31, 6 (stack45)
        %v57516_v52 = vshrl.u32 %v57506_v31, 26 (stack46)
        %v138770_v29 = vsel /*vm=*/%vm56249_vm15, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v138775_v8 = vsel /*vm=*/%vm56249_vm15, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v56727_v61 = vxor.u32 2147483648, %v138765_v54 (stack56)
        %v57128_v44 = vadd.s32 %v57125_v24, %v57120_v44 (stack40)
        %v56286_v50 = vsel /*vm=*/%vm56249_vm15, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v138784_v23 = vsel /*vm=*/%vm56249_vm15, /*on_true_vy=*/%v138743_v23, /*on_false_vx=*/%v56301_v10 (stack44)
        %v57130_v25 = vshll.u32 %v57125_v24, 26 (stack45)
        %v57131_v46 = vshrl.u32 %v57125_v24, 6 (stack46)
        %v56282_v22 = vsel /*vm=*/%vm56249_vm15, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v56309_v9 = vmul.f32 %v138784_v23, %v56286_v50 (stack54)
        %v56730_v41 = vmul.f32 %v56727_v61, %v138765_v54 (stack54)
        %v57517_v32 = vor.u32 %v57516_v52, %v57515_v53 (stack47)
        %v57132_v42 = vor.u32 %v57131_v46, %v57130_v25 (stack47)
        %v57922_v31 = vor.u32 %v57921_v20, %v57920_v56 (stack47)
        %v58339_v26 = vor.u32 %v58338_v12, %v58337_v26 (stack47)
        %vm58746_vm1 = vcmp.lt.u32.totalorder %v138709_v55, %v157089_v17 (stack43)
        %v56270_v12 = vsel /*vm=*/%vm56249_vm15, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v56313_v56 = vadd.f32 %v56309_v9, %v56282_v22 (stack53)
        %v56732_v40 = vadd.f32 1.0, %v56730_v41 (stack57)
        %v56735_v24 = vmul.f32 -0.5, %v56730_v41 (stack59)
        %v57133_v20 = vxor.u32 %v57132_v42, %v57128_v44 (stack48)
        %v57518_v10 = vxor.u32 %v57517_v32, %v57509_v21 (stack48)
        %v57923_v53 = vxor.u32 %v57922_v31, %v57918_v45 (stack48)
        %v58340_v52 = vxor.u32 %v58339_v26, %v58335_v60 (stack48)
        %v56278_v61 = vsel /*vm=*/%vm56249_vm15, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v56317_v50 = vmul.f32 %v56313_v56, %v138784_v23 (stack54)
        %120913 = vlog2.f32 %v56732_v40 (stack58)
        %v57513_v21 = vadd.s32 %v57509_v21, %v121574_v2 (stack40)
        %v57136_v44 = vadd.s32 %v57133_v20, %v57128_v44 (stack40)
        %v57142_v25 = vshll.u32 %v57133_v20, 6 (stack45)
        %v57143_v46 = vshrl.u32 %v57133_v20, 26 (stack46)
        %v57521_v22 = vadd.s32 %v57518_v10, %v121569_v1 (stack40)
        %v56321_v9 = vadd.f32 %v56317_v50, %v56278_v61 (stack53)
        %v56738_v32 = vand.u32 2147483647, %v56730_v41 (stack60)
        %v57926_v45 = vadd.s32 %v57923_v53, %v57918_v45 (stack40)
        %v57932_v42 = vshll.u32 %v57923_v53, 24 (stack45)
        %v56736_v31 = vadd.f32 1.0, %v56735_v24 (stack61)
        %v57144_v26 = vor.u32 %v57143_v46, %v57142_v25 (stack47)
        %v57525_v56 = vadd.s32 3, %v57521_v22 (stack40)
        %v57933_v40 = vshrl.u32 %v57923_v53, 8 (stack46)
        %v56274_v24 = vsel /*vm=*/%vm56249_vm15, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v56325_v20 = vmul.f32 %v56321_v9, %v138784_v23 (stack54)
        %v58343_v60 = vadd.s32 %v58340_v52, %v58335_v60 (stack40)
        %v58349_v10 = vshll.u32 %v58340_v52, 6 (stack45)
        %v57145_v53 = vxor.u32 %v57144_v26, %v57136_v44 (stack48)
        %v57529_v61 = vadd.s32 %v57525_v56, %v57513_v21 (stack40)
        %v57531_v50 = vshll.u32 %v57525_v56, 17 (stack45)
        %v57532_v21 = vshrl.u32 %v57525_v56, 15 (stack46)
        %v56329_v25 = vadd.f32 %v56325_v20, %v56274_v24 (stack53)
        %v57934_v46 = vor.u32 %v57933_v40, %v57932_v42 (stack47)
        %v58350_v52 = vshrl.u32 %v58340_v52, 26 (stack46)
        %vm58741_vm2 = vcmp.lt.u32.totalorder %v138748_v7, %v138709_v55 (stack43)
        %v56737_v41 = vmul.f32 %v56736_v31, %v56730_v41 (stack63)
        %vm138808_vm3 = vcmp.lt.f32.partialorder %v56738_v32, 0.0004427343 (stack62)
        %v57148_v9 = vadd.s32 %v57145_v53, %v121574_v2 (stack40)
        %v57533_v32 = vor.u32 %v57532_v21, %v57531_v50 (stack47)
        %v58751_v42 = vadd.s32 %v157415_v27, %v157090_v62 (stack40)
        %v56333_v31 = vmul.f32 %v56329_v25, %v138784_v23 (stack54)
        %v57935_v26 = vxor.u32 %v57934_v46, %v57926_v45 (stack48)
        %v58351_v56 = vor.u32 %v58350_v52, %v58349_v10 (stack47)
        %v138818_v40 = vadd.s32 %v157412_v30, %v157091_v37 (stack40)
        %v57140_v44 = vadd.s32 %v57136_v44, %v121564_v0 (stack40)
        %v57152_v24 = vadd.s32 5, %v57148_v9 (stack40)
        %v57534_v20 = vxor.u32 %v57533_v32, %v57529_v61 (stack48)
        %v57930_v45 = vadd.s32 %v57926_v45, %v121564_v0 (stack40)
        %v56337_v12 = vadd.f32 %v56333_v31, %v56270_v12 (stack53)
        %v57938_v10 = vadd.s32 %v57935_v26, %v121574_v2 (stack40)
        %v58352_v53 = vxor.u32 %v58351_v56, %v58343_v60 (stack48)
        %v58755_v50 = vadd.s32 1, %v58751_v42 (stack40)
        %v57154_v21 = vxor.u32 %v57152_v24, %v57140_v44 (stack48)
        %v57537_v61 = vadd.s32 %v57534_v20, %v57529_v61 (stack40)
        %v57539_v25 = vshll.u32 %v57534_v20, 29 (stack45)
        %v57540_v46 = vshrl.u32 %v57534_v20, 3 (stack46)
        %v56341_v52 = vmul.f32 %v56337_v12, %v138784_v23 (stack54)
        %v57942_v9 = vadd.s32 2, %v57938_v10 (stack40)
        %v58355_v32 = vadd.s32 %v58352_v53, %v121564_v0 (stack40)
        %v58759_v42 = vsel /*vm=*/%vm58746_vm1, /*on_true_vy=*/%v58755_v50, /*on_false_vx=*/%v58751_v42 (stack44)
        %v120914_v31 = vpop.eup %120913 (stack64)
        %v57155_v26 = vand.u32.u8 255, %v57154_v21 (stack49)
        %v57541_v56 = vor.u32 %v57540_v46, %v57539_v25 (stack47)
        %v58763_v44 = vadd.s32 1, %v58759_v42 (stack40)
        %v138830_v24 = vadd.s32 %v138748_v7, %v121569_v1 (stack40)
        %v56345_v8 = vadd.f32 %v56341_v52, %v138775_v8 (stack53)
        %v56734_v20 = vmul.f32 0.6931472, %v120914_v31 (stack65)
        %v57946_v45 = vadd.s32 %v57942_v9, %v57930_v45 (stack40)
        %v58347_v60 = vadd.s32 %v58343_v60, %v121569_v1 (stack40)
        %v57156_v12 = vand.u32 65535, %v57155_v26 (stack50)
        %v57542_v10 = vxor.u32 %v57541_v56, %v57537_v61 (stack48)
        %v57948_v53 = vshll.u32 %v57942_v9, 13 (stack45)
        %v58359_v50 = vadd.s32 1, %v58355_v32 (stack40)
        %v56349_v21 = vmul.f32 %v56345_v8, %v138784_v23 (stack54)
        %v56740_v41 = vsel /*vm=*/%vm138808_vm3, /*on_true_vy=*/%v56737_v41, /*on_false_vx=*/%v56734_v20 (stack66)
        %v57949_v22 = vshrl.u32 %v57942_v9, 19 (stack46)
        %v58767_v55 = vsel /*vm=*/%vm58741_vm2, /*on_true_vy=*/%v58763_v44, /*on_false_vx=*/%v58759_v42 (stack44)
        %v138840_v7 = vxor.u32 2147483648, %v56740_v41 (stack56)
        %v57545_v61 = vadd.s32 %v57542_v10, %v57537_v61 (stack40)
        %v57547_v25 = vshll.u32 %v57542_v10, 16 (stack45)
        %v58782_v46 = vshll.u32 %v138830_v24, 13 (stack45)
        %v56353_v29 = vadd.f32 %v56349_v21, %v138770_v29 (stack53)
        %v57548_v52 = vshrl.u32 %v57542_v10, 16 (stack46)
        %v58363_v9 = vadd.s32 %v58359_v50, %v58347_v60 (stack40)
        %v58783_v32 = vshrl.u32 %v138830_v24, 19 (stack46)
        %v56230_v42 = vmul.f32 inf, %v138673_v6 (stack54)
        %120915 = vrsqrt.f32 %v138840_v7 (stack67)
        %v57157_v31 = vshrl.u32 %v57156_v12, 1 (stack51)
        %v56254_v26 = vsel /*vm=*/%vm56249_vm15, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v56357_v56 = vmul.f32 %v56353_v29, %v138784_v23 (stack54)
        %vm56744_vm4 = vcmp.lt.f32.partialorder %v138840_v7, 5.0 (stack68)
        %v57950_v44 = vor.u32 %v57949_v22, %v57948_v53 (stack47)
        %vm138854_vm5 = vcmp.eq.f32.partialorder %v56222_v34, 1.0 (stack68)
        %v56258_v43 = vsel /*vm=*/%vm56249_vm15, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v56717_v8 = vand.u32 2147483647, %v138765_v54 (stack77)
        %v138863_v20 = vmul.f32 inf, %v138765_v54 (stack54)
        %v57549_v60 = vor.u32 %v57548_v52, %v57547_v25 (stack47)
        %v56361_v12 = vadd.f32 %v56357_v56, %v56258_v43 (stack53)
        %v138866_v10 = vadd.f32 -2.5, %v138840_v7 (stack53)
        %v58784_v53 = vor.u32 %v58783_v32, %v58782_v46 (stack47)
        %v138870_v21 = vadd.s32 %v138818_v40, %v122657_v58 (stack40)
        %v138875_v41 = vsel /*vm=*/%vm56744_vm4, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v138880_v22 = vsel /*vm=*/%vm56744_vm4, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v57158_v25 = vor.u32 16256, %v57157_v31 (stack47)
        %v57550_v46 = vxor.u32 %v57549_v60, %v57545_v61 (stack48)
        %v56365_v23 = vmul.f32 %v56361_v12, %v138784_v23 (stack54)
        %v57951_v29 = vxor.u32 %v57950_v44, %v57946_v45 (stack48)
        %v58365_v52 = vshll.u32 %v58359_v50, 17 (stack45)
        %v58366_v50 = vshrl.u32 %v58359_v50, 15 (stack46)
        %v57159_v32 = vand.u32.u16 65535, %v57158_v25 (stack52)
        %v57553_v61 = vadd.s32 %v57550_v46, %v57545_v61 (stack40)
        %v57559_v31 = vshll.u32 %v57550_v46, 24 (stack45)
        %v57560_v56 = vshrl.u32 %v57550_v46, 8 (stack46)
        %v56369_v26 = vadd.f32 %v56365_v23, %v56254_v26 (stack53)
        %vm56789_vm6 = vcmp.eq.f32.partialorder %v138840_v7, inf (stack70)
        %v57954_v45 = vadd.s32 %v57951_v29, %v57946_v45 (stack40)
        %v57956_v44 = vshll.u32 %v57951_v29, 15 (stack45)
        %v57957_v43 = vshrl.u32 %v57951_v29, 17 (stack46)
        %v138887_v60 = vsel /*vm=*/%vm56744_vm4, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v120050_v12 = vadd.low.f32.bf16 -1.0, %v57159_v32 (stack53)
        %v57561_v25 = vor.u32 %v57560_v56, %v57559_v31 (stack47)
        %v58367_v46 = vor.u32 %v58366_v50, %v58365_v52 (stack47)
        %v56373_v6 = vmul.f32 %v56369_v26, %v138673_v6 (stack54)
        %v138893_v23 = vsel /*vm=*/%vm56744_vm4, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v57958_v29 = vor.u32 %v57957_v43, %v57956_v44 (stack47)
        %v58772_v55 = vadd.s32 %v58767_v55, %v121574_v2 (stack40)
        %v57168_v52 = vmul.f32 2.0, %v120050_v12 (stack54)
        %v57562_v50 = vxor.u32 %v57561_v25, %v57553_v61 (stack48)
        %v58368_v32 = vxor.u32 %v58367_v46, %v58363_v9 (stack48)
        %vm59207_vm7 = vcmp.lt.u32.totalorder %v138818_v40, %v157091_v37 (stack43)
        %v56377_v42 = vsel /*vm=*/%vm138854_vm5, /*on_true_vy=*/%v56230_v42, /*on_false_vx=*/%v56373_v6 (stack44)
        %v57959_v34 = vxor.u32 %v57958_v29, %v57954_v45 (stack48)
        %v58780_v24 = vadd.s32 %v138830_v24, %v58772_v55 (stack40)
        %v59212_v31 = vadd.s32 %v157415_v27, %v157094_v36 (stack40)
        %v56381_v56 = vmul.f32 1.4140625, %v56377_v42 (stack54)
        %v57172_v26 = vadd.f32 -0.99609375, %v57168_v52 (stack53)
        %v57565_v44 = vadd.s32 %v57562_v50, %v121564_v0 (stack40)
        %v58371_v9 = vadd.s32 %v58368_v32, %v58363_v9 (stack40)
        %v120916_v43 = vpop.eup %120915 (stack73)
        %vm56791_vm8 = vcmp.eq.f32.partialorder %v138840_v7, 0.0 (stack71)
        %v57962_v45 = vadd.s32 %v57959_v34, %v57954_v45 (stack40)
        %v57964_v12 = vshll.u32 %v57959_v34, 26 (stack45)
        %v57965_v25 = vshrl.u32 %v57959_v34, 6 (stack46)
        %v56384_v46 = vpack.c.bf16 %v157387_v11, %v56381_v56 (stack81)
        %v56788_v6 = vmul.f32 %v120916_v43, %v138840_v7 (stack74)
        %v138907_v29 = vmax.f32 %v57172_v26, -0.99609375 (stack55)
        %v57569_v55 = vadd.s32 4, %v57565_v44 (stack40)
        %v56792_v52 = vand.u32 2147483648, %v138840_v7 (stack72)
        %v57557_v61 = vadd.s32 %v57553_v61, %v121569_v1 (stack40)
        %v57966_v50 = vor.u32 %v57965_v25, %v57964_v12 (stack47)
        %v58785_v53 = vxor.u32 %v58784_v53, %v58780_v24 (stack48)
        %120043 = vst [vmem:[%s123356_s30 + $0x3b8] sm:$0xf] /*vst_source=*/%v56384_v46 (stack83)
        %v56790_v42 = vsel /*vm=*/%vm56789_vm6, /*on_true_vy=*/%v138840_v7, /*on_false_vx=*/%v56788_v6 (stack75)
        %v57188_v34 = vxor.u32 2147483648, %v138907_v29 (stack56)
        %v58373_v56 = vshll.u32 %v58368_v32, 29 (stack45)
        %v58374_v32 = vshrl.u32 %v58368_v32, 3 (stack46)
        %v56793_v26 = vsel /*vm=*/%vm56791_vm8, /*on_true_vy=*/%v56792_v52, /*on_false_vx=*/%v56790_v42 (stack76)
        %v57573_v44 = vadd.s32 %v57569_v55, %v57557_v61 (stack40)
        %v57575_v43 = vshll.u32 %v57569_v55, 13 (stack45)
        %v57576_v12 = vshrl.u32 %v57569_v55, 19 (stack46)
        %v56777_v25 = vsel /*vm=*/%vm56744_vm4, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v56796_v46 = vadd.f32 -3.0, %v56793_v26 (stack53)
        %v57191_v6 = vmul.f32 %v57188_v34, %v138907_v29 (stack54)
        %v57967_v55 = vxor.u32 %v57966_v50, %v57962_v45 (stack48)
        %v56781_v52 = vsel /*vm=*/%vm56744_vm4, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v57577_v61 = vor.u32 %v57576_v12, %v57575_v43 (stack47)
        %v58788_v24 = vadd.s32 %v58785_v53, %v58780_v24 (stack40)
        %vm59202_vm9 = vcmp.lt.u32.totalorder %v138870_v21, %v138818_v40 (stack43)
        %v138930_v10 = vsel /*vm=*/%vm56744_vm4, /*on_true_vy=*/%v138866_v10, /*on_false_vx=*/%v56796_v46 (stack44)
        %v57193_v50 = vadd.f32 1.0, %v57191_v6 (stack57)
        %v57196_v42 = vmul.f32 -0.5, %v57191_v6 (stack59)
        %v58375_v34 = vor.u32 %v58374_v32, %v58373_v56 (stack47)
        %v56804_v56 = vmul.f32 %v138930_v10, %v56781_v52 (stack54)
        %v57578_v32 = vxor.u32 %v57577_v61, %v57573_v44 (stack48)
        %v57970_v45 = vadd.s32 %v57967_v55, %v57962_v45 (stack40)
        %v57976_v26 = vshll.u32 %v57967_v55, 6 (stack45)
        %120917 = vlog2.f32 %v57193_v50 (stack58)
        %v57977_v43 = vshrl.u32 %v57967_v55, 26 (stack46)
        %v58790_v12 = vshll.u32 %v58785_v53, 15 (stack45)
        %v59216_v46 = vadd.s32 1, %v59212_v31 (stack40)
        %v56808_v25 = vadd.f32 %v56804_v56, %v56777_v25 (stack53)
        %v57581_v44 = vadd.s32 %v57578_v32, %v57573_v44 (stack40)
        %v57583_v55 = vshll.u32 %v57578_v32, 15 (stack45)
        %v57584_v52 = vshrl.u32 %v57578_v32, 17 (stack46)
        %v57197_v61 = vadd.f32 1.0, %v57196_v42 (stack61)
        %v57199_v50 = vand.u32 2147483647, %v57191_v6 (stack60)
        %v57978_v42 = vor.u32 %v57977_v43, %v57976_v26 (stack47)
        %v58376_v34 = vxor.u32 %v58375_v34, %v58371_v9 (stack48)
        %v56812_v56 = vmul.f32 %v56808_v25, %v138930_v10 (stack54)
        %v57585_v32 = vor.u32 %v57584_v52, %v57583_v55 (stack47)
        %v58791_v53 = vshrl.u32 %v58785_v53, 17 (stack46)
        %v59220_v31 = vsel /*vm=*/%vm59207_vm7, /*on_true_vy=*/%v59216_v46, /*on_false_vx=*/%v59212_v31 (stack44)
        %v57979_v26 = vxor.u32 %v57978_v42, %v57970_v45 (stack48)
        %v58379_v9 = vadd.s32 %v58376_v34, %v58371_v9 (stack40)
        %v58381_v43 = vshll.u32 %v58376_v34, 16 (stack45)
        %v58382_v46 = vshrl.u32 %v58376_v34, 16 (stack46)
        %v56816_v23 = vadd.f32 %v56812_v56, %v138893_v23 (stack53)
        %v57586_v25 = vxor.u32 %v57585_v32, %v57581_v44 (stack48)
        %v58792_v12 = vor.u32 %v58791_v53, %v58790_v12 (stack47)
        %v59224_v55 = vadd.s32 1, %v59220_v31 (stack40)
        %v57974_v45 = vadd.s32 %v57970_v45, %v121574_v2 (stack40)
        %v57982_v52 = vadd.s32 %v57979_v26, %v121569_v1 (stack40)
        %v58383_v42 = vor.u32 %v58382_v46, %v58381_v43 (stack47)
        %v138942_v30 = vadd.s32 %v157412_v30, %v157095_v13 (stack40)
        %v56820_v34 = vmul.f32 %v56816_v23, %v138930_v10 (stack54)
        %v57589_v44 = vadd.s32 %v57586_v25, %v57581_v44 (stack40)
        %v57591_v56 = vshll.u32 %v57586_v25, 26 (stack45)
        %v57592_v32 = vshrl.u32 %v57586_v25, 6 (stack46)
        %v57986_v53 = vadd.s32 3, %v57982_v52 (stack40)
        %v58384_v26 = vxor.u32 %v58383_v42, %v58379_v9 (stack48)
        %v58793_v43 = vxor.u32 %v58792_v12, %v58788_v24 (stack48)
        %v59228_v40 = vsel /*vm=*/%vm59202_vm9, /*on_true_vy=*/%v59224_v55, /*on_false_vx=*/%v59220_v31 (stack44)
        %v56824_v60 = vadd.f32 %v56820_v34, %v138887_v60 (stack53)
        %vm138949_vm10 = vcmp.lt.f32.partialorder %v57199_v50, 0.0004427343 (stack62)
        %v57593_v31 = vor.u32 %v57592_v32, %v57591_v56 (stack47)
        %v59233_v46 = vadd.s32 %v59228_v40, %v121574_v2 (stack40)
        %v57990_v23 = vadd.s32 %v57986_v53, %v57974_v45 (stack40)
        %v57992_v25 = vshll.u32 %v57986_v53, 17 (stack45)
        %v57993_v12 = vshrl.u32 %v57986_v53, 15 (stack46)
        %v58387_v9 = vadd.s32 %v58384_v26, %v58379_v9 (stack40)
        %v56828_v55 = vmul.f32 %v56824_v60, %v138930_v10 (stack54)
        %v57594_v45 = vxor.u32 %v57593_v31, %v57589_v44 (stack48)
        %v58393_v52 = vshll.u32 %v58384_v26, 24 (stack45)
        %v58394_v42 = vshrl.u32 %v58384_v26, 8 (stack46)
        %v57198_v6 = vmul.f32 %v57197_v61, %v57191_v6 (stack63)
        %v57994_v61 = vor.u32 %v57993_v12, %v57992_v25 (stack47)
        %v138955_v24 = vadd.s32 %v58793_v43, %v58788_v24 (stack40)
        %v59237_v21 = vadd.s32 %v138870_v21, %v121569_v1 (stack40)
        %v120918_v34 = vpop.eup %120917 (stack64)
        %v56832_v22 = vadd.f32 %v56828_v55, %v138880_v22 (stack53)
        %v57597_v44 = vadd.s32 %v57594_v45, %v57589_v44 (stack40)
        %v57603_v56 = vshll.u32 %v57594_v45, 6 (stack45)
        %v57604_v32 = vshrl.u32 %v57594_v45, 26 (stack46)
        %v57195_v53 = vmul.f32 0.6931472, %v120918_v34 (stack65)
        %v57995_v26 = vxor.u32 %v57994_v61, %v57990_v23 (stack48)
        %v58395_v40 = vor.u32 %v58394_v42, %v58393_v52 (stack47)
        %v58798_v60 = vshll.u32 %v58793_v43, 26 (stack45)
        %v56836_v31 = vmul.f32 %v56832_v22, %v138930_v10 (stack54)
        %v57605_v25 = vor.u32 %v57604_v32, %v57603_v56 (stack47)
        %v58799_v43 = vshrl.u32 %v58793_v43, 6 (stack46)
        %v138961_v46 = vadd.s32 %v59237_v21, %v59233_v46 (stack40)
        %v57201_v50 = vsel /*vm=*/%vm138949_vm10, /*on_true_vy=*/%v57198_v6, /*on_false_vx=*/%v57195_v53 (stack66)
        %v57998_v23 = vadd.s32 %v57995_v26, %v57990_v23 (stack40)
        %v58000_v12 = vshll.u32 %v57995_v26, 29 (stack45)
        %v58001_v55 = vshrl.u32 %v57995_v26, 3 (stack46)
        %v56840_v41 = vadd.f32 %v56836_v31, %v138875_v41 (stack53)
        %v138966_v45 = vxor.u32 2147483648, %v57201_v50 (stack56)
        %v57606_v52 = vxor.u32 %v57605_v25, %v57597_v44 (stack48)
        %v58396_v42 = vxor.u32 %v58395_v40, %v58387_v9 (stack48)
        %v56749_v6 = vsel /*vm=*/%vm56744_vm4, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v56753_v61 = vsel /*vm=*/%vm56744_vm4, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v56757_v7 = vsel /*vm=*/%vm56744_vm4, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v58002_v34 = vor.u32 %v58001_v55, %v58000_v12 (stack47)
        %v56844_v22 = vmul.f32 %v56840_v41, %v138930_v10 (stack54)
        %v57178_v56 = vand.u32 2147483647, %v138907_v29 (stack77)
        %vm57205_vm11 = vcmp.lt.f32.partialorder %v138966_v45, 5.0 (stack68)
        %120919 = vrsqrt.f32 %v138966_v45 (stack67)
        %v57601_v44 = vadd.s32 %v57597_v44, %v121564_v0 (stack40)
        %v57609_v32 = vadd.s32 %v57606_v52, %v121574_v2 (stack40)
        %v58391_v9 = vadd.s32 %v58387_v9, %v121564_v0 (stack40)
        %v59243_v53 = vshll.u32 %v59237_v21, 13 (stack45)
        %v56848_v26 = vadd.f32 %v56844_v22, %v56757_v7 (stack53)
        %v58800_v40 = vor.u32 %v58799_v43, %v58798_v60 (stack47)
        %v59244_v21 = vshrl.u32 %v59237_v21, 19 (stack46)
        %v138986_v60 = vadd.s32 %v138942_v30, %v122657_v58 (stack40)
        %v138991_v31 = vsel /*vm=*/%vm57205_vm11, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v138996_v25 = vsel /*vm=*/%vm57205_vm11, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v138999_v43 = vadd.f32 -2.5, %v138966_v45 (stack53)
        %v58003_v50 = vxor.u32 %v58002_v34, %v57998_v23 (stack48)
        %v56852_v12 = vmul.f32 %v56848_v26, %v138930_v10 (stack54)
        %v139005_v55 = vsel /*vm=*/%vm57205_vm11, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v139010_v41 = vsel /*vm=*/%vm57205_vm11, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v139015_v52 = vsel /*vm=*/%vm57205_vm11, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %vm139019_vm12 = vcmp.eq.f32.partialorder %v56717_v8, 1.0 (stack68)
        %v57613_v7 = vadd.s32 5, %v57609_v32 (stack40)
        %v58006_v23 = vadd.s32 %v58003_v50, %v57998_v23 (stack40)
        %v58008_v34 = vshll.u32 %v58003_v50, 16 (stack45)
        %v58009_v22 = vshrl.u32 %v58003_v50, 16 (stack46)
        %v56856_v61 = vadd.f32 %v56852_v12, %v56753_v61 (stack53)
        %v58399_v42 = vadd.s32 %v58396_v42, %v121574_v2 (stack40)
        %v58801_v32 = vxor.u32 %v58800_v40, %v138955_v24 (stack48)
        %v59245_v53 = vor.u32 %v59244_v21, %v59243_v53 (stack47)
        %vm57250_vm13 = vcmp.eq.f32.partialorder %v138966_v45, inf (stack70)
        %v57615_v44 = vxor.u32 %v57613_v7, %v57601_v44 (stack48)
        %v58010_v26 = vor.u32 %v58009_v22, %v58008_v34 (stack47)
        %vm59668_vm14 = vcmp.lt.u32.totalorder %v138942_v30, %v157095_v13 (stack43)
        %v56860_v10 = vmul.f32 %v56856_v61, %v138930_v10 (stack54)
        %vm57252_vm15 = vcmp.eq.f32.partialorder %v138966_v45, 0.0 (stack71)
        %v58403_v40 = vadd.s32 2, %v58399_v42 (stack40)
        %v58804_v24 = vadd.s32 %v58801_v32, %v138955_v24 (stack40)
        %v58810_v21 = vshll.u32 %v58801_v32, 6 (stack45)
        %v57616_v50 = vand.u32.u8 255, %v57615_v44 (stack49)
        %v58011_v12 = vxor.u32 %v58010_v26, %v58006_v23 (stack48)
        %v58811_v7 = vshrl.u32 %v58801_v32, 26 (stack46)
        %v59246_v34 = vxor.u32 %v59245_v53, %v138961_v46 (stack48)
        %v56864_v6 = vadd.f32 %v56860_v10, %v56749_v6 (stack53)
        %v58407_v9 = vadd.s32 %v58403_v40, %v58391_v9 (stack40)
        %v58409_v22 = vshll.u32 %v58403_v40, 13 (stack45)
        %v58410_v61 = vshrl.u32 %v58403_v40, 19 (stack46)
        %v57617_v42 = vand.u32 65535, %v57616_v50 (stack50)
        %v58014_v23 = vadd.s32 %v58011_v12, %v58006_v23 (stack40)
        %v58020_v32 = vshll.u32 %v58011_v12, 24 (stack45)
        %v58021_v53 = vshrl.u32 %v58011_v12, 8 (stack46)
        %v56868_v54 = vmul.f32 %v56864_v6, %v138765_v54 (stack54)
        %v57253_v44 = vand.u32 2147483648, %v138966_v45 (stack72)
        %v58411_v26 = vor.u32 %v58410_v61, %v58409_v22 (stack47)
        %v58812_v10 = vor.u32 %v58811_v7, %v58810_v21 (stack47)
        %v120920_v40 = vpop.eup %120919 (stack73)
        %v57618_v21 = vshrl.u32 %v57617_v42, 1 (stack51)
        %v58022_v50 = vor.u32 %v58021_v53, %v58020_v32 (stack47)
        %v58808_v12 = vadd.s32 %v58804_v24, %v121569_v1 (stack40)
        %v59249_v46 = vadd.s32 %v59246_v34, %v138961_v46 (stack40)
        %v56872_v20 = vsel /*vm=*/%vm139019_vm12, /*on_true_vy=*/%v138863_v20, /*on_false_vx=*/%v56868_v54 (stack44)
        %v57249_v8 = vmul.f32 %v120920_v40, %v138966_v45 (stack74)
        %v58412_v7 = vxor.u32 %v58411_v26, %v58407_v9 (stack48)
        %v58813_v24 = vxor.u32 %v58812_v10, %v58804_v24 (stack48)
        %v56876_v6 = vmul.f32 1.4140625, %v56872_v20 (stack54)
        %v57619_v22 = vor.u32 16256, %v57618_v21 (stack47)
        %v58023_v61 = vxor.u32 %v58022_v50, %v58014_v23 (stack48)
        %v59251_v42 = vshll.u32 %v59246_v34, 15 (stack45)
        %v57251_v32 = vsel /*vm=*/%vm57250_vm13, /*on_true_vy=*/%v138966_v45, /*on_false_vx=*/%v57249_v8 (stack75)
        %v58415_v9 = vadd.s32 %v58412_v7, %v58407_v9 (stack40)
        %v58417_v53 = vshll.u32 %v58412_v7, 15 (stack45)
        %v58418_v54 = vshrl.u32 %v58412_v7, 17 (stack46)
        %v56879_v26 = vpack.c.bf16 %v157387_v11, %v56876_v6 (stack81)
        %v57254_v44 = vsel /*vm=*/%vm57252_vm15, /*on_true_vy=*/%v57253_v44, /*on_false_vx=*/%v57251_v32 (stack76)
        %v57620_v10 = vand.u32.u16 65535, %v57619_v22 (stack52)
        %v58026_v40 = vadd.s32 %v58023_v61, %v121564_v0 (stack40)
        %v57257_v21 = vadd.f32 -3.0, %v57254_v44 (stack53)
        %v58419_v50 = vor.u32 %v58418_v54, %v58417_v53 (stack47)
        %v58816_v20 = vadd.s32 %v58813_v24, %v121564_v0 (stack40)
        %v59252_v34 = vshrl.u32 %v59246_v34, 17 (stack46)
        %120049 = vst [vmem:[%s123356_s30 + $0x3c] sm:$0xf] /*vst_source=*/%v56879_v26 (stack83)
        %v120052_v8 = vadd.low.f32.bf16 -1.0, %v57620_v10 (stack53)
        %v58018_v23 = vadd.s32 %v58014_v23, %v121569_v1 (stack40)
        %v58030_v7 = vadd.s32 4, %v58026_v40 (stack40)
        %v139052_v27 = vadd.s32 %v157415_v27, %v157100_v14 (stack40)
        %v139057_v43 = vsel /*vm=*/%vm57205_vm11, /*on_true_vy=*/%v138999_v43, /*on_false_vx=*/%v57257_v21 (stack44)
        %v58420_v24 = vxor.u32 %v58419_v50, %v58415_v9 (stack48)
        %v58820_v6 = vadd.s32 1, %v58816_v20 (stack40)
        %v59253_v22 = vor.u32 %v59252_v34, %v59251_v42 (stack47)
        %v57265_v52 = vmul.f32 %v139057_v43, %v139015_v52 (stack54)
        %v57629_v61 = vmul.f32 2.0, %v120052_v8 (stack54)
        %v58034_v42 = vadd.s32 %v58030_v7, %v58018_v23 (stack40)
        %v58036_v32 = vshll.u32 %v58030_v7, 13 (stack45)
        %v58037_v53 = vshrl.u32 %v58030_v7, 19 (stack46)
        %v58423_v9 = vadd.s32 %v58420_v24, %v58415_v9 (stack40)
        %v58425_v54 = vshll.u32 %v58420_v24, 26 (stack45)
        %v58426_v26 = vshrl.u32 %v58420_v24, 6 (stack46)
        %v57269_v41 = vadd.f32 %v57265_v52, %v139010_v41 (stack53)
        %v57633_v44 = vadd.f32 -0.99609375, %v57629_v61 (stack53)
        %v58824_v12 = vadd.s32 %v58820_v6, %v58808_v12 (stack40)
        %v58826_v10 = vshll.u32 %v58820_v6, 17 (stack45)
        %v58038_v40 = vor.u32 %v58037_v53, %v58036_v32 (stack47)
        %v58427_v21 = vor.u32 %v58426_v26, %v58425_v54 (stack47)
        %v58827_v50 = vshrl.u32 %v58820_v6, 15 (stack46)
        %v59254_v20 = vxor.u32 %v59253_v22, %v59249_v46 (stack48)
        %v57222_v34 = vsel /*vm=*/%vm57205_vm11, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v57234_v8 = vsel /*vm=*/%vm57205_vm11, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v57273_v23 = vmul.f32 %v57269_v41, %v139057_v43 (stack54)
        %v139069_v7 = vmax.f32 %v57633_v44, -0.99609375 (stack55)
        %v58039_v24 = vxor.u32 %v58038_v40, %v58034_v42 (stack48)
        %v58428_v6 = vxor.u32 %v58427_v21, %v58423_v9 (stack48)
        %v58828_v22 = vor.u32 %v58827_v50, %v58826_v10 (stack47)
        %v139071_v46 = vadd.s32 %v59254_v20, %v59249_v46 (stack40)
        %v57226_v52 = vsel /*vm=*/%vm57205_vm11, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v57277_v61 = vadd.f32 %v57273_v23, %v57234_v8 (stack53)
        %v57649_v32 = vxor.u32 2147483648, %v139069_v7 (stack56)
        %v139079_v53 = vadd.s32 %v138986_v60, %v121569_v1 (stack40)
        %v58042_v42 = vadd.s32 %v58039_v24, %v58034_v42 (stack40)
        %v58044_v54 = vshll.u32 %v58039_v24, 15 (stack45)
        %v58045_v26 = vshrl.u32 %v58039_v24, 17 (stack46)
        %v58431_v9 = vadd.s32 %v58428_v6, %v58423_v9 (stack40)
        %v57230_v45 = vsel /*vm=*/%vm57205_vm11, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v57281_v41 = vmul.f32 %v57277_v61, %v139057_v43 (stack54)
        %v57652_v44 = vmul.f32 %v57649_v32, %v139069_v7 (stack54)
        %v58437_v10 = vshll.u32 %v58428_v6, 6 (stack45)
        %v58046_v40 = vor.u32 %v58045_v26, %v58044_v54 (stack47)
        %v58438_v21 = vshrl.u32 %v58428_v6, 26 (stack46)
        %v58829_v50 = vxor.u32 %v58828_v22, %v58824_v12 (stack48)
        %vm59663_vm0 = vcmp.lt.u32.totalorder %v138986_v60, %v138942_v30 (stack43)
        %v57285_v8 = vadd.f32 %v57281_v41, %v57230_v45 (stack53)
        %v57654_v23 = vadd.f32 1.0, %v57652_v44 (stack57)
        %v59677_v24 = vadd.s32 1, %v139052_v27 (stack40)
        %v59704_v6 = vshll.u32 %v139079_v53, 13 (stack45)
        %v58047_v22 = vxor.u32 %v58046_v40, %v58042_v42 (stack48)
        %v58435_v61 = vadd.s32 %v58431_v9, %v121574_v2 (stack40)
        %v58439_v32 = vor.u32 %v58438_v21, %v58437_v10 (stack47)
        %v58832_v12 = vadd.s32 %v58829_v50, %v58824_v12 (stack40)
        %v57289_v54 = vmul.f32 %v57285_v8, %v139057_v43 (stack54)
        %120921 = vlog2.f32 %v57654_v23 (stack58)
        %v57657_v26 = vmul.f32 -0.5, %v57652_v44 (stack59)
        %v58834_v45 = vshll.u32 %v58829_v50, 29 (stack45)
        %v58050_v42 = vadd.s32 %v58047_v22, %v58042_v42 (stack40)
        %v58052_v41 = vshll.u32 %v58047_v22, 26 (stack45)
        %v58053_v10 = vshrl.u32 %v58047_v22, 6 (stack46)
        %v58440_v9 = vxor.u32 %v58439_v32, %v58431_v9 (stack48)
        %v57293_v52 = vadd.f32 %v57289_v54, %v57226_v52 (stack53)
        %v57660_v40 = vand.u32 2147483647, %v57652_v44 (stack60)
        %v58835_v21 = vshrl.u32 %v58829_v50, 3 (stack46)
        %v59259_v50 = vshll.u32 %v59254_v20, 26 (stack45)
        %v58054_v8 = vor.u32 %v58053_v10, %v58052_v41 (stack47)
        %v58443_v23 = vadd.s32 %v58440_v9, %v121569_v1 (stack40)
        %v59260_v20 = vshrl.u32 %v59254_v20, 6 (stack46)
        %v59681_v27 = vsel /*vm=*/%vm59668_vm14, /*on_true_vy=*/%v59677_v24, /*on_false_vx=*/%v139052_v27 (stack44)
        %v57297_v24 = vmul.f32 %v57293_v52, %v139057_v43 (stack54)
        %v57658_v22 = vadd.f32 1.0, %v57657_v26 (stack61)
        %v58836_v32 = vor.u32 %v58835_v21, %v58834_v45 (stack47)
        %v59685_v54 = vadd.s32 1, %v59681_v27 (stack40)
        %v58055_v26 = vxor.u32 %v58054_v8, %v58050_v42 (stack48)
        %v58447_v45 = vadd.s32 3, %v58443_v23 (stack40)
        %v59705_v41 = vshrl.u32 %v139079_v53, 19 (stack46)
        %v157438_v10 = vld [vmem:[#allocation140_spill] sm:$0xff] (stack84)
        %v139101_v9 = vadd.s32 %v157438_v10, %v122651_v47 (stack40)
        %v57301_v34 = vadd.f32 %v57297_v24, %v57222_v34 (stack53)
        %v58837_v52 = vxor.u32 %v58836_v32, %v58832_v12 (stack48)
        %v59261_v21 = vor.u32 %v59260_v20, %v59259_v50 (stack47)
        %v59689_v30 = vsel /*vm=*/%vm59663_vm0, /*on_true_vy=*/%v59685_v54, /*on_false_vx=*/%v59681_v27 (stack44)
        %v58058_v60 = vadd.s32 %v58055_v26, %v58050_v42 (stack40)
        %v58064_v42 = vshll.u32 %v58055_v26, 6 (stack45)
        %v58065_v50 = vshrl.u32 %v58055_v26, 26 (stack46)
        %v58451_v61 = vadd.s32 %v58447_v45, %v58435_v61 (stack40)
        %v57305_v8 = vmul.f32 %v57301_v34, %v139057_v43 (stack54)
        %v58453_v23 = vshll.u32 %v58447_v45, 17 (stack45)
        %v58454_v20 = vshrl.u32 %v58447_v45, 15 (stack46)
        %v58840_v12 = vadd.s32 %v58837_v52, %v58832_v12 (stack40)
        %vm139107_vm1 = vcmp.lt.f32.partialorder %v57660_v40, 0.0004427343 (stack62)
        %v58066_v27 = vor.u32 %v58065_v50, %v58064_v42 (stack47)
        %v58842_v24 = vshll.u32 %v58837_v52, 16 (stack45)
        %v58843_v32 = vshrl.u32 %v58837_v52, 16 (stack46)
        %v57309_v55 = vadd.f32 %v57305_v8, %v139005_v55 (stack53)
        %v58455_v54 = vor.u32 %v58454_v20, %v58453_v23 (stack47)
        %v59262_v26 = vxor.u32 %v59261_v21, %v139071_v46 (stack48)
        %v59694_v45 = vadd.s32 %v59689_v30, %v121574_v2 (stack40)
        %v57659_v44 = vmul.f32 %v57658_v22, %v57652_v44 (stack63)
        %v58067_v22 = vxor.u32 %v58066_v27, %v58058_v60 (stack48)
        %v58844_v34 = vor.u32 %v58843_v32, %v58842_v24 (stack47)
        %vm60163_vm2 = vcmp.lt.u32.totalorder %v139101_v9, %v122651_v47 (stack43)
        %v57313_v52 = vmul.f32 %v57309_v55, %v139057_v43 (stack54)
        %v58456_v21 = vxor.u32 %v58455_v54, %v58451_v61 (stack48)
        %v59265_v46 = vadd.s32 %v59262_v26, %v139071_v46 (stack40)
        %v59706_v6 = vor.u32 %v59705_v41, %v59704_v6 (stack47)
        %v120922_v41 = vpop.eup %120921 (stack64)
        %v58062_v30 = vadd.s32 %v58058_v60, %v121564_v0 (stack40)
        %v58070_v60 = vadd.s32 %v58067_v22, %v121574_v2 (stack40)
        %v58845_v42 = vxor.u32 %v58844_v34, %v58840_v12 (stack48)
        %v59702_v53 = vadd.s32 %v139079_v53, %v59694_v45 (stack40)
        %v57317_v25 = vadd.f32 %v57313_v52, %v138996_v25 (stack53)
        %v57656_v50 = vmul.f32 0.6931472, %v120922_v41 (stack65)
        %v58459_v61 = vadd.s32 %v58456_v21, %v58451_v61 (stack40)
        %v58461_v8 = vshll.u32 %v58456_v21, 29 (stack45)
        %v58074_v23 = vadd.s32 5, %v58070_v60 (stack40)
        %v58462_v20 = vshrl.u32 %v58456_v21, 3 (stack46)
        %v58848_v12 = vadd.s32 %v58845_v42, %v58840_v12 (stack40)
        %v59271_v27 = vshll.u32 %v59262_v26, 6 (stack45)
        %v57321_v43 = vmul.f32 %v57317_v25, %v139057_v43 (stack54)
        %v57662_v40 = vsel /*vm=*/%vm139107_vm1, /*on_true_vy=*/%v57659_v44, /*on_false_vx=*/%v57656_v50 (stack66)
        %v58854_v24 = vshll.u32 %v58845_v42, 24 (stack45)
        %v58855_v32 = vshrl.u32 %v58845_v42, 8 (stack46)
        %v139125_v55 = vxor.u32 2147483648, %v57662_v40 (stack56)
        %v58076_v54 = vxor.u32 %v58074_v23, %v58062_v30 (stack48)
        %v58463_v45 = vor.u32 %v58462_v20, %v58461_v8 (stack47)
        %v59272_v26 = vshrl.u32 %v59262_v26, 26 (stack46)
        %v57325_v31 = vadd.f32 %v57321_v43, %v138991_v31 (stack53)
        %v59707_v44 = vxor.u32 %v59706_v6, %v59702_v53 (stack48)
        %v57186_v22 = vmul.f32 inf, %v138907_v29 (stack54)
        %120923 = vrsqrt.f32 %v139125_v55 (stack67)
        %vm57181_vm3 = vcmp.eq.f32.partialorder %v57178_v56, 1.0 (stack68)
        %v57329_v29 = vmul.f32 %v57325_v31, %v138907_v29 (stack54)
        %vm57666_vm4 = vcmp.lt.f32.partialorder %v139125_v55, 5.0 (stack68)
        %v58856_v56 = vor.u32 %v58855_v32, %v58854_v24 (stack47)
        %v57639_v34 = vand.u32 2147483647, %v139069_v7 (stack77)
        %v139136_v52 = vmul.f32 inf, %v139069_v7 (stack54)
        %v58464_v21 = vxor.u32 %v58463_v45, %v58459_v61 (stack48)
        %v59273_v6 = vor.u32 %v59272_v26, %v59271_v27 (stack47)
        %v57333_v41 = vsel /*vm=*/%vm57181_vm3, /*on_true_vy=*/%v57186_v22, /*on_false_vx=*/%v57329_v29 (stack44)
        %v58852_v30 = vadd.s32 %v58848_v12, %v121564_v0 (stack40)
        %v59269_v60 = vadd.s32 %v59265_v46, %v121569_v1 (stack40)
        %v139142_v42 = vadd.s32 %v139101_v9, %v122657_v58 (stack40)
        %v57337_v25 = vmul.f32 1.4140625, %v57333_v41 (stack54)
        %v139147_v50 = vsel /*vm=*/%vm57666_vm4, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v139150_v8 = vadd.f32 -2.5, %v139125_v55 (stack53)
        %v58077_v23 = vand.u32.u8 255, %v58076_v54 (stack49)
        %v58467_v61 = vadd.s32 %v58464_v21, %v58459_v61 (stack40)
        %v58469_v20 = vshll.u32 %v58464_v21, 16 (stack45)
        %v58470_v27 = vshrl.u32 %v58464_v21, 16 (stack46)
        %v58857_v12 = vxor.u32 %v58856_v56, %v58848_v12 (stack48)
        %v57340_v43 = vpack.c.bf16 %v157387_v11, %v57337_v25 (stack81)
        %v58078_v40 = vand.u32 65535, %v58077_v23 (stack50)
        %v59274_v46 = vxor.u32 %v59273_v6, %v59265_v46 (stack48)
        %v59710_v53 = vadd.s32 %v59707_v44, %v59702_v53 (stack40)
        %vm57711_vm5 = vcmp.eq.f32.partialorder %v139125_v55, inf (stack70)
        %v58471_v24 = vor.u32 %v58470_v27, %v58469_v20 (stack47)
        %v58860_v32 = vadd.s32 %v58857_v12, %v121574_v2 (stack40)
        %v59712_v54 = vshll.u32 %v59707_v44, 15 (stack45)
        %v59713_v45 = vshrl.u32 %v59707_v44, 17 (stack46)
        %120051 = vst [vmem:[%s123356_s30 + $0xbc] sm:$0xf] /*vst_source=*/%v57340_v43 (stack83)
        %v57703_v26 = vsel /*vm=*/%vm57666_vm4, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v58079_v31 = vshrl.u32 %v58078_v40, 1 (stack51)
        %v59277_v44 = vadd.s32 %v59274_v46, %v121564_v0 (stack40)
        %v157441_v22 = vld [vmem:[#allocation102_spill] sm:$0xff] (stack84)
        %v60168_v29 = vadd.s32 %v157441_v22, %v157068_v28 (stack40)
        %vm57713_vm6 = vcmp.eq.f32.partialorder %v139125_v55, 0.0 (stack71)
        %v57714_v56 = vand.u32 2147483648, %v139125_v55 (stack72)
        %v58472_v21 = vxor.u32 %v58471_v24, %v58467_v61 (stack48)
        %v58864_v6 = vadd.s32 2, %v58860_v32 (stack40)
        %v58080_v41 = vor.u32 16256, %v58079_v31 (stack47)
        %v59281_v25 = vadd.s32 1, %v59277_v44 (stack40)
        %v59714_v23 = vor.u32 %v59713_v45, %v59712_v54 (stack47)
        %v139166_v20 = vadd.s32 %v157438_v10, %v157070_v38 (stack40)
        %v58475_v61 = vadd.s32 %v58472_v21, %v58467_v61 (stack40)
        %v58481_v27 = vshll.u32 %v58472_v21, 24 (stack45)
        %v58482_v12 = vshrl.u32 %v58472_v21, 8 (stack46)
        %v58868_v30 = vadd.s32 %v58864_v6, %v58852_v30 (stack40)
        %v58081_v43 = vand.u32.u16 65535, %v58080_v41 (stack52)
        %v58870_v40 = vshll.u32 %v58864_v6, 13 (stack45)
        %v58871_v46 = vshrl.u32 %v58864_v6, 19 (stack46)
        %v59285_v60 = vadd.s32 %v59281_v25, %v59269_v60 (stack40)
        %v120924_v24 = vpop.eup %120923 (stack73)
        %v58483_v32 = vor.u32 %v58482_v12, %v58481_v27 (stack47)
        %v59287_v54 = vshll.u32 %v59281_v25, 17 (stack45)
        %v59288_v45 = vshrl.u32 %v59281_v25, 15 (stack46)
        %v60172_v31 = vadd.s32 1, %v60168_v29 (stack40)
        %v57710_v44 = vmul.f32 %v120924_v24, %v139125_v55 (stack74)
        %v120054_v21 = vadd.low.f32.bf16 -1.0, %v58081_v43 (stack53)
        %v58872_v6 = vor.u32 %v58871_v46, %v58870_v40 (stack47)
        %v59715_v41 = vxor.u32 %v59714_v23, %v59710_v53 (stack48)
        %v58479_v25 = vadd.s32 %v58475_v61, %v121569_v1 (stack40)
        %v58484_v23 = vxor.u32 %v58483_v32, %v58475_v61 (stack48)
        %v59289_v61 = vor.u32 %v59288_v45, %v59287_v54 (stack47)
        %v139173_v29 = vsel /*vm=*/%vm60163_vm2, /*on_true_vy=*/%v60172_v31, /*on_false_vx=*/%v60168_v29 (stack44)
        %v57712_v27 = vsel /*vm=*/%vm57711_vm5, /*on_true_vy=*/%v139125_v55, /*on_false_vx=*/%v57710_v44 (stack75)
        %v58090_v12 = vmul.f32 2.0, %v120054_v21 (stack54)
        %v58873_v43 = vxor.u32 %v58872_v6, %v58868_v30 (stack48)
        %v59718_v53 = vadd.s32 %v59715_v41, %v59710_v53 (stack40)
        %v57715_v56 = vsel /*vm=*/%vm57713_vm6, /*on_true_vy=*/%v57714_v56, /*on_false_vx=*/%v57712_v27 (stack76)
        %v58487_v40 = vadd.s32 %v58484_v23, %v121564_v0 (stack40)
        %v59290_v46 = vxor.u32 %v59289_v61, %v59285_v60 (stack48)
        %v59720_v24 = vshll.u32 %v59715_v41, 26 (stack45)
        %v57718_v32 = vadd.f32 -3.0, %v57715_v56 (stack53)
        %v58094_v54 = vadd.f32 -0.99609375, %v58090_v12 (stack53)
        %v58876_v30 = vadd.s32 %v58873_v43, %v58868_v30 (stack40)
        %v58878_v45 = vshll.u32 %v58873_v43, 15 (stack45)
        %v58491_v31 = vadd.s32 4, %v58487_v40 (stack40)
        %v58879_v44 = vshrl.u32 %v58873_v43, 17 (stack46)
        %v59293_v60 = vadd.s32 %v59290_v46, %v59285_v60 (stack40)
        %v59295_v21 = vshll.u32 %v59290_v46, 29 (stack45)
        %v139184_v8 = vsel /*vm=*/%vm57666_vm4, /*on_true_vy=*/%v139150_v8, /*on_false_vx=*/%v57718_v32 (stack44)
        %v139186_v6 = vmax.f32 %v58094_v54, -0.99609375 (stack55)
        %v59296_v23 = vshrl.u32 %v59290_v46, 3 (stack46)
        %v59721_v41 = vshrl.u32 %v59715_v41, 6 (stack46)
        %v57726_v26 = vmul.f32 %v139184_v8, %v57703_v26 (stack54)
        %v58495_v25 = vadd.s32 %v58491_v31, %v58479_v25 (stack40)
        %v58497_v61 = vshll.u32 %v58491_v31, 13 (stack45)
        %v58498_v27 = vshrl.u32 %v58491_v31, 19 (stack46)
        %v139192_v12 = vsel /*vm=*/%vm57666_vm4, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v57699_v43 = vsel /*vm=*/%vm57666_vm4, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v58110_v56 = vxor.u32 2147483648, %v139186_v6 (stack56)
        %v58880_v40 = vor.u32 %v58879_v44, %v58878_v45 (stack47)
        %v57730_v46 = vadd.f32 %v57726_v26, %v57699_v43 (stack53)
        %v58499_v32 = vor.u32 %v58498_v27, %v58497_v61 (stack47)
        %v59297_v54 = vor.u32 %v59296_v23, %v59295_v21 (stack47)
        %v59722_v24 = vor.u32 %v59721_v41, %v59720_v24 (stack47)
        %v57687_v45 = vsel /*vm=*/%vm57666_vm4, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v57691_v31 = vsel /*vm=*/%vm57666_vm4, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v139205_v44 = vmul.f32 %v58110_v56, %v139186_v6 (stack54)
        %v58881_v21 = vxor.u32 %v58880_v40, %v58876_v30 (stack48)
        %v57734_v23 = vmul.f32 %v57730_v46, %v139184_v8 (stack54)
        %v58500_v41 = vxor.u32 %v58499_v32, %v58495_v25 (stack48)
        %v59298_v26 = vxor.u32 %v59297_v54, %v59293_v60 (stack48)
        %v59723_v61 = vxor.u32 %v59722_v24, %v59718_v53 (stack48)
        %v57695_v27 = vsel /*vm=*/%vm57666_vm4, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v58115_v43 = vadd.f32 1.0, %v139205_v44 (stack57)
        %v58884_v30 = vadd.s32 %v58881_v21, %v58876_v30 (stack40)
        %vm60158_vm7 = vcmp.lt.u32.totalorder %v139142_v42, %v139101_v9 (stack43)
        %v57738_v56 = vadd.f32 %v57734_v23, %v57695_v27 (stack53)
        %v58503_v25 = vadd.s32 %v58500_v41, %v58495_v25 (stack40)
        %v58505_v40 = vshll.u32 %v58500_v41, 15 (stack45)
        %v58506_v46 = vshrl.u32 %v58500_v41, 17 (stack46)
        %120925 = vlog2.f32 %v58115_v43 (stack58)
        %v58886_v32 = vshll.u32 %v58881_v21, 26 (stack45)
        %v60180_v54 = vadd.s32 1, %v139173_v29 (stack40)
        %v60193_v24 = vadd.s32 %v139142_v42, %v121569_v1 (stack40)
        %v57742_v23 = vmul.f32 %v57738_v56, %v139184_v8 (stack54)
        %v58507_v41 = vor.u32 %v58506_v46, %v58505_v40 (stack47)
        %v58887_v21 = vshrl.u32 %v58881_v21, 6 (stack46)
        %v59301_v60 = vadd.s32 %v59298_v26, %v59293_v60 (stack40)
        %v58118_v27 = vmul.f32 -0.5, %v139205_v44 (stack59)
        %v59303_v43 = vshll.u32 %v59298_v26, 16 (stack45)
        %v59304_v26 = vshrl.u32 %v59298_v26, 16 (stack46)
        %v59726_v53 = vadd.s32 %v59723_v61, %v59718_v53 (stack40)
        %v57746_v31 = vadd.f32 %v57742_v23, %v57691_v31 (stack53)
        %v58508_v56 = vxor.u32 %v58507_v41, %v58503_v25 (stack48)
        %v58888_v40 = vor.u32 %v58887_v21, %v58886_v32 (stack47)
        %v59732_v46 = vshll.u32 %v59723_v61, 6 (stack45)
        %v59305_v32 = vor.u32 %v59304_v26, %v59303_v43 (stack47)
        %v59733_v61 = vshrl.u32 %v59723_v61, 26 (stack46)
        %v60184_v9 = vsel /*vm=*/%vm60158_vm7, /*on_true_vy=*/%v60180_v54, /*on_false_vx=*/%v139173_v29 (stack44)
        %v60199_v42 = vshll.u32 %v60193_v24, 13 (stack45)
        %v57750_v29 = vmul.f32 %v57746_v31, %v139184_v8 (stack54)
        %v58511_v25 = vadd.s32 %v58508_v56, %v58503_v25 (stack40)
        %v58513_v54 = vshll.u32 %v58508_v56, 26 (stack45)
        %v58514_v23 = vshrl.u32 %v58508_v56, 6 (stack46)
        %v58119_v41 = vadd.f32 1.0, %v58118_v27 (stack61)
        %v58889_v21 = vxor.u32 %v58888_v40, %v58884_v30 (stack48)
        %v59306_v27 = vxor.u32 %v59305_v32, %v59301_v60 (stack48)
        %v59734_v43 = vor.u32 %v59733_v61, %v59732_v46 (stack47)
        %v57754_v45 = vadd.f32 %v57750_v29, %v57687_v45 (stack53)
        %v58515_v26 = vor.u32 %v58514_v23, %v58513_v54 (stack47)
        %v60189_v31 = vadd.s32 %v60184_v9, %v121574_v2 (stack40)
        %v60200_v56 = vshrl.u32 %v60193_v24, 19 (stack46)
        %v58892_v30 = vadd.s32 %v58889_v21, %v58884_v30 (stack40)
        %v58898_v40 = vshll.u32 %v58889_v21, 6 (stack45)
        %v58899_v46 = vshrl.u32 %v58889_v21, 26 (stack46)
        %v59309_v60 = vadd.s32 %v59306_v27, %v59301_v60 (stack40)
        %v57758_v32 = vmul.f32 %v57754_v45, %v139184_v8 (stack54)
        %v58516_v61 = vxor.u32 %v58515_v26, %v58511_v25 (stack48)
        %v59315_v9 = vshll.u32 %v59306_v27, 24 (stack45)
        %v59316_v29 = vshrl.u32 %v59306_v27, 8 (stack46)
        %v58120_v54 = vmul.f32 %v58119_v41, %v139205_v44 (stack63)
        %v58121_v44 = vand.u32 2147483647, %v139205_v44 (stack60)
        %v58900_v23 = vor.u32 %v58899_v46, %v58898_v40 (stack47)
        %v59735_v41 = vxor.u32 %v59734_v43, %v59726_v53 (stack48)
        %v57762_v12 = vadd.f32 %v57758_v32, %v139192_v12 (stack53)
        %v58519_v25 = vadd.s32 %v58516_v61, %v58511_v25 (stack40)
        %v58525_v21 = vshll.u32 %v58516_v61, 6 (stack45)
        %v58526_v27 = vshrl.u32 %v58516_v61, 26 (stack46)
        %v58901_v43 = vxor.u32 %v58900_v23, %v58892_v30 (stack48)
        %v59317_v45 = vor.u32 %v59316_v29, %v59315_v9 (stack47)
        %v59738_v26 = vadd.s32 %v59735_v41, %v121564_v0 (stack40)
        %v60197_v24 = vadd.s32 %v60193_v24, %v60189_v31 (stack40)
        %v120926_v31 = vpop.eup %120925 (stack64)
        %v57766_v40 = vmul.f32 %v57762_v12, %v139184_v8 (stack54)
        %v58527_v46 = vor.u32 %v58526_v27, %v58525_v21 (stack47)
        %v59730_v53 = vadd.s32 %v59726_v53, %v121569_v1 (stack40)
        %v60201_v42 = vor.u32 %v60200_v56, %v60199_v42 (stack47)
        %v58117_v56 = vmul.f32 0.6931472, %v120926_v31 (stack65)
        %v58904_v32 = vadd.s32 %v58901_v43, %v121569_v1 (stack40)
        %v59318_v61 = vxor.u32 %v59317_v45, %v59309_v60 (stack48)
        %v59742_v9 = vadd.s32 1, %v59738_v26 (stack40)
        %v57770_v50 = vadd.f32 %v57766_v40, %v139147_v50 (stack53)
        %vm58122_vm8 = vcmp.lt.f32.partialorder %v58121_v44, 0.0004427343 (stack62)
        %v58528_v29 = vxor.u32 %v58527_v46, %v58519_v25 (stack48)
        %v60202_v44 = vxor.u32 %v60201_v42, %v60197_v24 (stack48)
        %v58123_v54 = vsel /*vm=*/%vm58122_vm8, /*on_true_vy=*/%v58120_v54, /*on_false_vx=*/%v58117_v56 (stack66)
        %v58896_v30 = vadd.s32 %v58892_v30, %v121574_v2 (stack40)
        %v58908_v23 = vadd.s32 3, %v58904_v32 (stack40)
        %v139235_v41 = vadd.s32 %v59742_v9, %v59730_v53 (stack40)
        %v57671_v12 = vsel /*vm=*/%vm57666_vm4, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v57774_v21 = vmul.f32 %v57770_v50, %v139184_v8 (stack54)
        %v139241_v27 = vxor.u32 2147483648, %v58123_v54 (stack56)
        %v59321_v43 = vadd.s32 %v59318_v61, %v121574_v2 (stack40)
        %vm139246_vm9 = vcmp.eq.f32.partialorder %v57639_v34, 1.0 (stack68)
        %v57675_v55 = vsel /*vm=*/%vm57666_vm4, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v58912_v45 = vadd.s32 %v58908_v23, %v58896_v30 (stack40)
        %v58914_v26 = vshll.u32 %v58908_v23, 17 (stack45)
        %v58915_v31 = vshrl.u32 %v58908_v23, 15 (stack46)
        %v57778_v40 = vadd.f32 %v57774_v21, %v57675_v55 (stack53)
        %v58100_v46 = vand.u32 2147483647, %v139186_v6 (stack77)
        %vm58127_vm10 = vcmp.lt.f32.partialorder %v139241_v27, 5.0 (stack68)
        %120927 = vrsqrt.f32 %v139241_v27 (stack67)
        %v58531_v53 = vadd.s32 %v58528_v29, %v121574_v2 (stack40)
        %v58916_v42 = vor.u32 %v58915_v31, %v58914_v26 (stack47)
        %v59313_v60 = vadd.s32 %v59309_v60, %v121564_v0 (stack40)
        %v139260_v56 = vadd.s32 %v139166_v20, %v122657_v58 (stack40)
        %v57782_v8 = vmul.f32 %v57778_v40, %v139184_v8 (stack54)
        %v58523_v25 = vadd.s32 %v58519_v25, %v121564_v0 (stack40)
        %v59325_v32 = vadd.s32 2, %v59321_v43 (stack40)
        %v59748_v61 = vshll.u32 %v59742_v9, 17 (stack45)
        %v139267_v50 = vsel /*vm=*/%vm58127_vm10, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v139272_v29 = vsel /*vm=*/%vm58127_vm10, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v139275_v54 = vadd.f32 -2.5, %v139241_v27 (stack53)
        %v58917_v30 = vxor.u32 %v58916_v42, %v58912_v45 (stack48)
        %v57786_v23 = vadd.f32 %v57782_v8, %v57671_v12 (stack53)
        %v139280_v12 = vsel /*vm=*/%vm58127_vm10, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v139285_v21 = vsel /*vm=*/%vm58127_vm10, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v139290_v43 = vsel /*vm=*/%vm58127_vm10, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v58535_v55 = vadd.s32 5, %v58531_v53 (stack40)
        %v58920_v45 = vadd.s32 %v58917_v30, %v58912_v45 (stack40)
        %v58922_v26 = vshll.u32 %v58917_v30, 29 (stack45)
        %v58923_v31 = vshrl.u32 %v58917_v30, 3 (stack46)
        %v57790_v7 = vmul.f32 %v57786_v23, %v139069_v7 (stack54)
        %v59329_v40 = vadd.s32 %v59325_v32, %v59313_v60 (stack40)
        %v59331_v53 = vshll.u32 %v59325_v32, 13 (stack45)
        %v59332_v42 = vshrl.u32 %v59325_v32, 19 (stack46)
        %vm58172_vm11 = vcmp.eq.f32.partialorder %v139241_v27, inf (stack70)
        %v58537_v60 = vxor.u32 %v58535_v55, %v58523_v25 (stack48)
        %v58924_v8 = vor.u32 %v58923_v31, %v58922_v26 (stack47)
        %v59749_v9 = vshrl.u32 %v59742_v9, 15 (stack46)
        %v60205_v24 = vadd.s32 %v60202_v44, %v60197_v24 (stack40)
        %v57794_v52 = vsel /*vm=*/%vm139246_vm9, /*on_true_vy=*/%v139136_v52, /*on_false_vx=*/%v57790_v7 (stack44)
        %v59333_v34 = vor.u32 %v59332_v42, %v59331_v53 (stack47)
        %v60207_v25 = vshll.u32 %v60202_v44, 15 (stack45)
        %v60208_v44 = vshrl.u32 %v60202_v44, 17 (stack46)
        %v57798_v32 = vmul.f32 1.4140625, %v57794_v52 (stack54)
        %v58538_v30 = vand.u32.u8 255, %v58537_v60 (stack49)
        %v58925_v23 = vxor.u32 %v58924_v8, %v58920_v45 (stack48)
        %v59750_v61 = vor.u32 %v59749_v9, %v59748_v61 (stack47)
        %v59334_v55 = vxor.u32 %v59333_v34, %v59329_v40 (stack48)
        %v60209_v26 = vor.u32 %v60208_v44, %v60207_v25 (stack47)
        %vm60624_vm12 = vcmp.lt.u32.totalorder %v139166_v20, %v157070_v38 (stack43)
        %v60629_v31 = vadd.s32 %v157441_v22, %v157076_v35 (stack40)
        %v57801_v7 = vpack.c.bf16 %v157387_v11, %v57798_v32 (stack81)
        %v58539_v53 = vand.u32 65535, %v58538_v30 (stack50)
        %v58928_v45 = vadd.s32 %v58925_v23, %v58920_v45 (stack40)
        %v58930_v42 = vshll.u32 %v58925_v23, 16 (stack45)
        %v58931_v60 = vshrl.u32 %v58925_v23, 16 (stack46)
        %v59337_v40 = vadd.s32 %v59334_v55, %v59329_v40 (stack40)
        %v59339_v8 = vshll.u32 %v59334_v55, 15 (stack45)
        %v59340_v9 = vshrl.u32 %v59334_v55, 17 (stack46)
        %v120928_v52 = vpop.eup %120927 (stack73)
        %120053 = vst [vmem:[%s123356_s30 + $0x13c] sm:$0xf] /*vst_source=*/%v57801_v7 (stack83)
        %vm58174_vm13 = vcmp.eq.f32.partialorder %v139241_v27, 0.0 (stack71)
        %v58540_v34 = vshrl.u32 %v58539_v53, 1 (stack51)
        %v59751_v25 = vxor.u32 %v59750_v61, %v139235_v41 (stack48)
        %v60210_v44 = vxor.u32 %v60209_v26, %v60205_v24 (stack48)
        %v58171_v32 = vmul.f32 %v120928_v52, %v139241_v27 (stack74)
        %v58175_v30 = vand.u32 2147483648, %v139241_v27 (stack72)
        %v58932_v23 = vor.u32 %v58931_v60, %v58930_v42 (stack47)
        %v59341_v61 = vor.u32 %v59340_v9, %v59339_v8 (stack47)
        %v58541_v55 = vor.u32 16256, %v58540_v34 (stack47)
        %v59754_v41 = vadd.s32 %v59751_v25, %v139235_v41 (stack40)
        %v59756_v26 = vshll.u32 %v59751_v25, 29 (stack45)
        %v59757_v7 = vshrl.u32 %v59751_v25, 3 (stack46)
        %v58173_v53 = vsel /*vm=*/%vm58172_vm11, /*on_true_vy=*/%v139241_v27, /*on_false_vx=*/%v58171_v32 (stack75)
        %v58933_v42 = vxor.u32 %v58932_v23, %v58928_v45 (stack48)
        %v59342_v60 = vxor.u32 %v59341_v61, %v59337_v40 (stack48)
        %v139311_v24 = vadd.s32 %v60210_v44, %v60205_v24 (stack40)
        %v58176_v8 = vsel /*vm=*/%vm58174_vm13, /*on_true_vy=*/%v58175_v30, /*on_false_vx=*/%v58173_v53 (stack76)
        %v58542_v9 = vand.u32.u16 65535, %v58541_v55 (stack52)
        %v59758_v52 = vor.u32 %v59757_v7, %v59756_v26 (stack47)
        %v60215_v34 = vshll.u32 %v60210_v44, 26 (stack45)
        %v58179_v25 = vadd.f32 -3.0, %v58176_v8 (stack53)
        %v58936_v45 = vadd.s32 %v58933_v42, %v58928_v45 (stack40)
        %v58942_v32 = vshll.u32 %v58933_v42, 24 (stack45)
        %v58943_v30 = vshrl.u32 %v58933_v42, 8 (stack46)
        %v120056_v23 = vadd.low.f32.bf16 -1.0, %v58542_v9 (stack53)
        %v59345_v40 = vadd.s32 %v59342_v60, %v59337_v40 (stack40)
        %v59347_v61 = vshll.u32 %v59342_v60, 26 (stack45)
        %v59348_v55 = vshrl.u32 %v59342_v60, 6 (stack46)
        %v139318_v54 = vsel /*vm=*/%vm58127_vm10, /*on_true_vy=*/%v139275_v54, /*on_false_vx=*/%v58179_v25 (stack44)
        %v58944_v26 = vor.u32 %v58943_v30, %v58942_v32 (stack47)
        %v59759_v7 = vxor.u32 %v59758_v52, %v59754_v41 (stack48)
        %v60633_v53 = vadd.s32 1, %v60629_v31 (stack40)
        %v58187_v43 = vmul.f32 %v139318_v54, %v139290_v43 (stack54)
        %v58551_v42 = vmul.f32 2.0, %v120056_v23 (stack54)
        %v59349_v60 = vor.u32 %v59348_v55, %v59347_v61 (stack47)
        %v60216_v44 = vshrl.u32 %v60210_v44, 6 (stack46)
        %v58945_v8 = vxor.u32 %v58944_v26, %v58936_v45 (stack48)
        %v59762_v41 = vadd.s32 %v59759_v7, %v59754_v41 (stack40)
        %v59764_v9 = vshll.u32 %v59759_v7, 16 (stack45)
        %v59765_v52 = vshrl.u32 %v59759_v7, 16 (stack46)
        %v58191_v21 = vadd.f32 %v58187_v43, %v139285_v21 (stack53)
        %v58555_v25 = vadd.f32 -0.99609375, %v58551_v42 (stack53)
        %v59350_v32 = vxor.u32 %v59349_v60, %v59345_v40 (stack48)
        %v60217_v34 = vor.u32 %v60216_v44, %v60215_v34 (stack47)
        %v58940_v45 = vadd.s32 %v58936_v45, %v121569_v1 (stack40)
        %v58948_v30 = vadd.s32 %v58945_v8, %v121564_v0 (stack40)
        %v59766_v23 = vor.u32 %v59765_v52, %v59764_v9 (stack47)
        %v60637_v31 = vsel /*vm=*/%vm60624_vm12, /*on_true_vy=*/%v60633_v53, /*on_false_vx=*/%v60629_v31 (stack44)
        %v58195_v61 = vmul.f32 %v58191_v21, %v139318_v54 (stack54)
        %v139329_v55 = vmax.f32 %v58555_v25, -0.99609375 (stack55)
        %v59353_v40 = vadd.s32 %v59350_v32, %v59345_v40 (stack40)
        %v59359_v26 = vshll.u32 %v59350_v32, 6 (stack45)
        %v58952_v7 = vadd.s32 4, %v58948_v30 (stack40)
        %v59360_v53 = vshrl.u32 %v59350_v32, 26 (stack46)
        %v59767_v43 = vxor.u32 %v59766_v23, %v59762_v41 (stack48)
        %v60218_v42 = vxor.u32 %v60217_v34, %v139311_v24 (stack48)
        %v139335_v60 = vsel /*vm=*/%vm58127_vm10, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v58199_v12 = vadd.f32 %v58195_v61, %v139280_v12 (stack53)
        %v58571_v44 = vxor.u32 2147483648, %v139329_v55 (stack56)
        %v139341_v8 = vadd.s32 %v139260_v56, %v121569_v1 (stack40)
        %v58144_v9 = vsel /*vm=*/%vm58127_vm10, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v58956_v52 = vadd.s32 %v58952_v7, %v58940_v45 (stack40)
        %v58958_v21 = vshll.u32 %v58952_v7, 13 (stack45)
        %v58959_v25 = vshrl.u32 %v58952_v7, 19 (stack46)
        %vm60619_vm14 = vcmp.lt.u32.totalorder %v139260_v56, %v139166_v20 (stack43)
        %v58152_v32 = vsel /*vm=*/%vm58127_vm10, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v58203_v34 = vmul.f32 %v58199_v12, %v139318_v54 (stack54)
        %v139353_v45 = vmul.f32 %v58571_v44, %v139329_v55 (stack54)
        %v59361_v30 = vor.u32 %v59360_v53, %v59359_v26 (stack47)
        %v58960_v23 = vor.u32 %v58959_v25, %v58958_v21 (stack47)
        %v59770_v41 = vadd.s32 %v59767_v43, %v59762_v41 (stack40)
        %v59776_v61 = vshll.u32 %v59767_v43, 24 (stack45)
        %v59777_v26 = vshrl.u32 %v59767_v43, 8 (stack46)
        %v58148_v27 = vsel /*vm=*/%vm58127_vm10, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v58207_v7 = vadd.f32 %v58203_v34, %v58152_v32 (stack53)
        %v58576_v53 = vadd.f32 1.0, %v139353_v45 (stack57)
        %v60660_v43 = vshll.u32 %v139341_v8, 13 (stack45)
        %v58961_v12 = vxor.u32 %v58960_v23, %v58956_v52 (stack48)
        %v59357_v44 = vadd.s32 %v59353_v40, %v121574_v2 (stack40)
        %v59362_v40 = vxor.u32 %v59361_v30, %v59353_v40 (stack48)
        %v59778_v21 = vor.u32 %v59777_v26, %v59776_v61 (stack47)
        %v58211_v25 = vmul.f32 %v58207_v7, %v139318_v54 (stack54)
        %120929 = vlog2.f32 %v58576_v53 (stack58)
        %v58579_v32 = vmul.f32 -0.5, %v139353_v45 (stack59)
        %v58582_v34 = vand.u32 2147483647, %v139353_v45 (stack60)
        %v58964_v52 = vadd.s32 %v58961_v12, %v58956_v52 (stack40)
        %v58966_v30 = vshll.u32 %v58961_v12, 15 (stack45)
        %v58967_v23 = vshrl.u32 %v58961_v12, 17 (stack46)
        %v59365_v61 = vadd.s32 %v59362_v40, %v121569_v1 (stack40)
        %v58215_v26 = vadd.f32 %v58211_v25, %v58148_v27 (stack53)
        %v59774_v27 = vadd.s32 %v59770_v41, %v121564_v0 (stack40)
        %v59779_v41 = vxor.u32 %v59778_v21, %v59770_v41 (stack48)
        %v60221_v24 = vadd.s32 %v60218_v42, %v139311_v24 (stack40)
        %v58968_v7 = vor.u32 %v58967_v23, %v58966_v30 (stack47)
        %v59369_v53 = vadd.s32 3, %v59365_v61 (stack40)
        %v60227_v12 = vshll.u32 %v60218_v42, 6 (stack45)
        %v60228_v42 = vshrl.u32 %v60218_v42, 26 (stack46)
        %v58219_v40 = vmul.f32 %v58215_v26, %v139318_v54 (stack54)
        %v58580_v21 = vadd.f32 1.0, %v58579_v32 (stack61)
        %v59782_v25 = vadd.s32 %v59779_v41, %v121574_v2 (stack40)
        %v60641_v32 = vadd.s32 1, %v60637_v31 (stack40)
        %v58969_v30 = vxor.u32 %v58968_v7, %v58964_v52 (stack48)
        %v59373_v44 = vadd.s32 %v59369_v53, %v59357_v44 (stack40)
        %v59375_v23 = vshll.u32 %v59369_v53, 17 (stack45)
        %v59376_v61 = vshrl.u32 %v59369_v53, 15 (stack46)
        %v58223_v9 = vadd.f32 %v58219_v40, %v58144_v9 (stack53)
        %v59786_v26 = vadd.s32 2, %v59782_v25 (stack40)
        %v60229_v41 = vor.u32 %v60228_v42, %v60227_v12 (stack47)
        %v60645_v20 = vsel /*vm=*/%vm60619_vm14, /*on_true_vy=*/%v60641_v32, /*on_false_vx=*/%v60637_v31 (stack44)
        %v58972_v56 = vadd.s32 %v58969_v30, %v58964_v52 (stack40)
        %v58974_v31 = vshll.u32 %v58969_v30, 26 (stack45)
        %v58975_v52 = vshrl.u32 %v58969_v30, 6 (stack46)
        %v59377_v7 = vor.u32 %v59376_v61, %v59375_v23 (stack47)
        %v58227_v53 = vmul.f32 %v58223_v9, %v139318_v54 (stack54)
        %v59790_v27 = vadd.s32 %v59786_v26, %v59774_v27 (stack40)
        %v59792_v12 = vshll.u32 %v59786_v26, 13 (stack45)
        %v59793_v42 = vshrl.u32 %v59786_v26, 19 (stack46)
        %v58976_v40 = vor.u32 %v58975_v52, %v58974_v31 (stack47)
        %v59378_v25 = vxor.u32 %v59377_v7, %v59373_v44 (stack48)
        %v60230_v32 = vxor.u32 %v60229_v41, %v60221_v24 (stack48)
        %v60650_v30 = vadd.s32 %v60645_v20, %v121574_v2 (stack40)
        %v58231_v60 = vadd.f32 %v58227_v53, %v139335_v60 (stack53)
        %vm139375_vm15 = vcmp.lt.f32.partialorder %v58582_v34, 0.0004427343 (stack62)
        %v59794_v23 = vor.u32 %v59793_v42, %v59792_v12 (stack47)
        %v139381_v61 = vadd.s32 %v157438_v10, %v157077_v51 (stack40)
        %v58977_v9 = vxor.u32 %v58976_v40, %v58972_v56 (stack48)
        %v59381_v44 = vadd.s32 %v59378_v25, %v59373_v44 (stack40)
        %v59383_v26 = vshll.u32 %v59378_v25, 29 (stack45)
        %v59384_v41 = vshrl.u32 %v59378_v25, 3 (stack46)
        %v58235_v20 = vmul.f32 %v58231_v60, %v139318_v54 (stack54)
        %v59795_v31 = vxor.u32 %v59794_v23, %v59790_v27 (stack48)
        %v60233_v52 = vadd.s32 %v60230_v32, %v121564_v0 (stack40)
        %v60658_v7 = vadd.s32 %v139341_v8, %v60650_v30 (stack40)
        %v120930_v53 = vpop.eup %120929 (stack64)
        %v58980_v56 = vadd.s32 %v58977_v9, %v58972_v56 (stack40)
        %v58986_v12 = vshll.u32 %v58977_v9, 6 (stack45)
        %v58987_v42 = vshrl.u32 %v58977_v9, 26 (stack46)
        %v59385_v40 = vor.u32 %v59384_v41, %v59383_v26 (stack47)
        %v58239_v29 = vadd.f32 %v58235_v20, %v139272_v29 (stack53)
        %v58578_v25 = vmul.f32 0.6931472, %v120930_v53 (stack65)
        %v58581_v45 = vmul.f32 %v58580_v21, %v139353_v45 (stack63)
        %v59798_v21 = vadd.s32 %v59795_v31, %v59790_v27 (stack40)
        %v58988_v27 = vor.u32 %v58987_v42, %v58986_v12 (stack47)
        %v59386_v32 = vxor.u32 %v59385_v40, %v59381_v44 (stack48)
        %v59800_v30 = vshll.u32 %v59795_v31, 15 (stack45)
        %v60225_v24 = vadd.s32 %v60221_v24, %v121569_v1 (stack40)
        %v58243_v54 = vmul.f32 %v58239_v29, %v139318_v54 (stack54)
        %v58584_v60 = vsel /*vm=*/%vm139375_vm15, /*on_true_vy=*/%v58581_v45, /*on_false_vx=*/%v58578_v25 (stack66)
        %v59801_v34 = vshrl.u32 %v59795_v31, 17 (stack46)
        %v60237_v23 = vadd.s32 1, %v60233_v52 (stack40)
        %v139392_v9 = vxor.u32 2147483648, %v58584_v60 (stack56)
        %v58989_v26 = vxor.u32 %v58988_v27, %v58980_v56 (stack48)
        %v59389_v44 = vadd.s32 %v59386_v32, %v59381_v44 (stack40)
        %v60661_v41 = vshrl.u32 %v139341_v8, 19 (stack46)
        %v58247_v50 = vadd.f32 %v58243_v54, %v139267_v50 (stack53)
        %v60241_v20 = vadd.s32 %v60237_v23, %v60225_v24 (stack40)
        %v58108_v31 = vmul.f32 inf, %v139186_v6 (stack54)
        %120931 = vrsqrt.f32 %v139392_v9 (stack67)
        %v59391_v52 = vshll.u32 %v59386_v32, 16 (stack45)
        %v58251_v53 = vmul.f32 %v58247_v50, %v139186_v6 (stack54)
        %vm58588_vm0 = vcmp.lt.f32.partialorder %v139392_v9, 5.0 (stack68)
        %v59392_v12 = vshrl.u32 %v59386_v32, 16 (stack46)
        %v59802_v42 = vor.u32 %v59801_v34, %v59800_v30 (stack47)
        %vm58103_vm1 = vcmp.eq.f32.partialorder %v58100_v46, 1.0 (stack68)
        %v58992_v6 = vadd.s32 %v58989_v26, %v121574_v2 (stack40)
        %v60662_v46 = vor.u32 %v60661_v41, %v60660_v43 (stack47)
        %v58255_v8 = vsel /*vm=*/%vm58103_vm1, /*on_true_vy=*/%v58108_v31, /*on_false_vx=*/%v58251_v53 (stack44)
        %v58561_v43 = vand.u32 2147483647, %v139329_v55 (stack77)
        %v139407_v40 = vadd.f32 -2.5, %v139392_v9 (stack53)
        %v58984_v56 = vadd.s32 %v58980_v56, %v121564_v0 (stack40)
        %v58259_v29 = vmul.f32 1.4140625, %v58255_v8 (stack54)
        %v139413_v25 = vsel /*vm=*/%vm58588_vm0, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v139418_v45 = vsel /*vm=*/%vm58588_vm0, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v58996_v27 = vadd.s32 5, %v58992_v6 (stack40)
        %v59393_v32 = vor.u32 %v59392_v12, %v59391_v52 (stack47)
        %v59803_v30 = vxor.u32 %v59802_v42, %v59798_v21 (stack48)
        %v60243_v24 = vshll.u32 %v60237_v23, 17 (stack45)
        %v60244_v54 = vshrl.u32 %v60237_v23, 15 (stack46)
        %v58262_v60 = vpack.c.bf16 %v157387_v11, %v58259_v29 (stack81)
        %v139424_v34 = vsel /*vm=*/%vm58588_vm0, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v58998_v23 = vxor.u32 %v58996_v27, %v58984_v56 (stack48)
        %v60663_v26 = vxor.u32 %v60662_v46, %v60658_v7 (stack48)
        %vm58633_vm2 = vcmp.eq.f32.partialorder %v139392_v9, inf (stack70)
        %v59394_v41 = vxor.u32 %v59393_v32, %v59389_v44 (stack48)
        %v59806_v21 = vadd.s32 %v59803_v30, %v59798_v21 (stack40)
        %v59808_v50 = vshll.u32 %v59803_v30, 26 (stack45)
        %v59809_v31 = vshrl.u32 %v59803_v30, 6 (stack46)
        %120055 = vst [vmem:[%s123356_s30 + $0x1bc] sm:$0xf] /*vst_source=*/%v58262_v60 (stack83)
        %vm58635_vm3 = vcmp.eq.f32.partialorder %v139392_v9, 0.0 (stack71)
        %v58636_v52 = vand.u32 2147483648, %v139392_v9 (stack72)
        %v58999_v53 = vand.u32.u8 255, %v58998_v23 (stack49)
        %v60245_v12 = vor.u32 %v60244_v54, %v60243_v24 (stack47)
        %v60666_v7 = vadd.s32 %v60663_v26, %v60658_v7 (stack40)
        %v59397_v44 = vadd.s32 %v59394_v41, %v59389_v44 (stack40)
        %v59403_v42 = vshll.u32 %v59394_v41, 24 (stack45)
        %v59404_v6 = vshrl.u32 %v59394_v41, 8 (stack46)
        %v59810_v46 = vor.u32 %v59809_v31, %v59808_v50 (stack47)
        %v59000_v8 = vand.u32 65535, %v58999_v53 (stack50)
        %v60246_v56 = vxor.u32 %v60245_v12, %v60241_v20 (stack48)
        %v60668_v29 = vshll.u32 %v60663_v26, 15 (stack45)
        %v60669_v27 = vshrl.u32 %v60663_v26, 17 (stack46)
        %v59401_v32 = vadd.s32 %v59397_v44, %v121569_v1 (stack40)
        %v59405_v30 = vor.u32 %v59404_v6, %v59403_v42 (stack47)
        %v59811_v24 = vxor.u32 %v59810_v46, %v59806_v21 (stack48)
        %vm61085_vm4 = vcmp.lt.u32.totalorder %v139381_v61, %v157077_v51 (stack43)
        %v59001_v54 = vshrl.u32 %v59000_v8, 1 (stack51)
        %v60249_v20 = vadd.s32 %v60246_v56, %v60241_v20 (stack40)
        %v60251_v60 = vshll.u32 %v60246_v56, 29 (stack45)
        %v60252_v23 = vshrl.u32 %v60246_v56, 3 (stack46)
        %v120932_v26 = vpop.eup %120931 (stack73)
        %v59406_v41 = vxor.u32 %v59405_v30, %v59397_v44 (stack48)
        %v59814_v21 = vadd.s32 %v59811_v24, %v59806_v21 (stack40)
        %v59820_v50 = vshll.u32 %v59811_v24, 6 (stack45)
        %v59821_v31 = vshrl.u32 %v59811_v24, 26 (stack46)
        %v58632_v53 = vmul.f32 %v120932_v26, %v139392_v9 (stack74)
        %v59002_v12 = vor.u32 16256, %v59001_v54 (stack47)
        %v60253_v44 = vor.u32 %v60252_v23, %v60251_v60 (stack47)
        %v60670_v42 = vor.u32 %v60669_v27, %v60668_v29 (stack47)
        %v59409_v6 = vadd.s32 %v59406_v41, %v121564_v0 (stack40)
        %v59818_v46 = vadd.s32 %v59814_v21, %v121574_v2 (stack40)
        %v59822_v8 = vor.u32 %v59821_v31, %v59820_v50 (stack47)
        %v61090_v56 = vadd.s32 %v157441_v22, %v157078_v48 (stack40)
        %v58634_v29 = vsel /*vm=*/%vm58633_vm2, /*on_true_vy=*/%v139392_v9, /*on_false_vx=*/%v58632_v53 (stack75)
        %v59003_v27 = vand.u32.u16 65535, %v59002_v12 (stack52)
        %v60254_v30 = vxor.u32 %v60253_v44, %v60249_v20 (stack48)
        %v60671_v24 = vxor.u32 %v60670_v42, %v60666_v7 (stack48)
        %v58637_v52 = vsel /*vm=*/%vm58635_vm3, /*on_true_vy=*/%v58636_v52, /*on_false_vx=*/%v58634_v29 (stack76)
        %v59413_v54 = vadd.s32 4, %v59409_v6 (stack40)
        %v59823_v60 = vxor.u32 %v59822_v8, %v59814_v21 (stack48)
        %v61094_v23 = vadd.s32 1, %v61090_v56 (stack40)
        %v58640_v26 = vadd.f32 -3.0, %v58637_v52 (stack53)
        %v120058_v41 = vadd.low.f32.bf16 -1.0, %v59003_v27 (stack53)
        %v60257_v20 = vadd.s32 %v60254_v30, %v60249_v20 (stack40)
        %v60259_v21 = vshll.u32 %v60254_v30, 16 (stack45)
        %v59417_v32 = vadd.s32 %v59413_v54, %v59401_v32 (stack40)
        %v59419_v50 = vshll.u32 %v59413_v54, 13 (stack45)
        %v59420_v31 = vshrl.u32 %v59413_v54, 19 (stack46)
        %v59826_v53 = vadd.s32 %v59823_v60, %v121569_v1 (stack40)
        %v139447_v40 = vsel /*vm=*/%vm58588_vm0, /*on_true_vy=*/%v139407_v40, /*on_false_vx=*/%v58640_v26 (stack44)
        %v59012_v12 = vmul.f32 2.0, %v120058_v41 (stack54)
        %v60260_v44 = vshrl.u32 %v60254_v30, 16 (stack46)
        %v60674_v7 = vadd.s32 %v60671_v24, %v60666_v7 (stack40)
        %v58648_v34 = vmul.f32 %v139447_v40, %v139424_v34 (stack54)
        %v59421_v42 = vor.u32 %v59420_v31, %v59419_v50 (stack47)
        %v59830_v6 = vadd.s32 3, %v59826_v53 (stack40)
        %v60676_v8 = vshll.u32 %v60671_v24, 26 (stack45)
        %v59016_v29 = vadd.f32 -0.99609375, %v59012_v12 (stack53)
        %v60261_v27 = vor.u32 %v60260_v44, %v60259_v21 (stack47)
        %v60677_v30 = vshrl.u32 %v60671_v24, 6 (stack46)
        %v139454_v56 = vsel /*vm=*/%vm61085_vm4, /*on_true_vy=*/%v61094_v23, /*on_false_vx=*/%v61090_v56 (stack44)
        %v58652_v45 = vadd.f32 %v58648_v34, %v139418_v45 (stack53)
        %v59422_v24 = vxor.u32 %v59421_v42, %v59417_v32 (stack48)
        %v59834_v46 = vadd.s32 %v59830_v6, %v59818_v46 (stack40)
        %v59836_v52 = vshll.u32 %v59830_v6, 17 (stack45)
        %v139457_v54 = vmax.f32 %v59016_v29, -0.99609375 (stack55)
        %v59837_v60 = vshrl.u32 %v59830_v6, 15 (stack46)
        %v60262_v23 = vxor.u32 %v60261_v27, %v60257_v20 (stack48)
        %v60678_v26 = vor.u32 %v60677_v30, %v60676_v8 (stack47)
        %v58656_v41 = vmul.f32 %v58652_v45, %v139447_v40 (stack54)
        %v59425_v21 = vadd.s32 %v59422_v24, %v59417_v32 (stack40)
        %v59427_v32 = vshll.u32 %v59422_v24, 15 (stack45)
        %v59428_v50 = vshrl.u32 %v59422_v24, 17 (stack46)
        %v139463_v31 = vsel /*vm=*/%vm58588_vm0, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v58617_v53 = vsel /*vm=*/%vm58588_vm0, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v59032_v12 = vxor.u32 2147483648, %v139457_v54 (stack56)
        %v59838_v44 = vor.u32 %v59837_v60, %v59836_v52 (stack47)
        %v58605_v34 = vsel /*vm=*/%vm58588_vm0, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v58660_v42 = vadd.f32 %v58656_v41, %v58617_v53 (stack53)
        %v59429_v6 = vor.u32 %v59428_v50, %v59427_v32 (stack47)
        %v60265_v20 = vadd.s32 %v60262_v23, %v60257_v20 (stack40)
        %v139473_v8 = vmul.f32 %v59032_v12, %v139457_v54 (stack54)
        %v59839_v29 = vxor.u32 %v59838_v44, %v59834_v46 (stack48)
        %v60271_v27 = vshll.u32 %v60262_v23, 24 (stack45)
        %v61076_v30 = vadd.s32 %v139381_v61, %v122657_v58 (stack40)
        %v58664_v45 = vmul.f32 %v58660_v42, %v139447_v40 (stack54)
        %v59430_v24 = vxor.u32 %v59429_v6, %v59425_v21 (stack48)
        %v60272_v52 = vshrl.u32 %v60262_v23, 8 (stack46)
        %v60679_v60 = vxor.u32 %v60678_v26, %v60674_v7 (stack48)
        %v58609_v23 = vsel /*vm=*/%vm58588_vm0, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v58613_v26 = vsel /*vm=*/%vm58588_vm0, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v59037_v41 = vadd.f32 1.0, %v139473_v8 (stack57)
        %v59842_v46 = vadd.s32 %v59839_v29, %v59834_v46 (stack40)
        %v58668_v32 = vadd.f32 %v58664_v45, %v58613_v26 (stack53)
        %v59433_v21 = vadd.s32 %v59430_v24, %v59425_v21 (stack40)
        %v59435_v50 = vshll.u32 %v59430_v24, 26 (stack45)
        %v59436_v53 = vshrl.u32 %v59430_v24, 6 (stack46)
        %120933 = vlog2.f32 %v59037_v41 (stack58)
        %v59040_v12 = vmul.f32 -0.5, %v139473_v8 (stack59)
        %v59844_v44 = vshll.u32 %v59839_v29, 29 (stack45)
        %vm61080_vm5 = vcmp.lt.u32.totalorder %v61076_v30, %v139381_v61 (stack43)
        %v58672_v42 = vmul.f32 %v58668_v32, %v139447_v40 (stack54)
        %v59437_v6 = vor.u32 %v59436_v53, %v59435_v50 (stack47)
        %v59845_v29 = vshrl.u32 %v59839_v29, 3 (stack46)
        %v60273_v27 = vor.u32 %v60272_v52, %v60271_v27 (stack47)
        %v59043_v45 = vand.u32 2147483647, %v139473_v8 (stack60)
        %v60682_v7 = vadd.s32 %v60679_v60, %v60674_v7 (stack40)
        %v60688_v24 = vshll.u32 %v60679_v60, 6 (stack45)
        %v60689_v52 = vshrl.u32 %v60679_v60, 26 (stack46)
        %v58676_v60 = vadd.f32 %v58672_v42, %v58609_v23 (stack53)
        %v59438_v23 = vxor.u32 %v59437_v6, %v59433_v21 (stack48)
        %v59846_v26 = vor.u32 %v59845_v29, %v59844_v44 (stack47)
        %v60274_v41 = vxor.u32 %v60273_v27, %v60265_v20 (stack48)
        %v59041_v32 = vadd.f32 1.0, %v59040_v12 (stack61)
        %v60269_v20 = vadd.s32 %v60265_v20, %v121564_v0 (stack40)
        %v60690_v50 = vor.u32 %v60689_v52, %v60688_v24 (stack47)
        %v61102_v53 = vadd.s32 1, %v139454_v56 (stack40)
        %v58680_v12 = vmul.f32 %v58676_v60, %v139447_v40 (stack54)
        %v59441_v21 = vadd.s32 %v59438_v23, %v59433_v21 (stack40)
        %v59447_v44 = vshll.u32 %v59438_v23, 6 (stack45)
        %v59448_v42 = vshrl.u32 %v59438_v23, 26 (stack46)
        %v59847_v6 = vxor.u32 %v59846_v26, %v59842_v46 (stack48)
        %v60277_v29 = vadd.s32 %v60274_v41, %v121574_v2 (stack40)
        %v60691_v27 = vxor.u32 %v60690_v50, %v60682_v7 (stack48)
        %v61106_v61 = vsel /*vm=*/%vm61080_vm5, /*on_true_vy=*/%v61102_v53, /*on_false_vx=*/%v139454_v56 (stack44)
        %v58684_v56 = vadd.f32 %v58680_v12, %v58605_v34 (stack53)
        %vm139496_vm6 = vcmp.lt.f32.partialorder %v59043_v45, 0.0004427343 (stack62)
        %v59449_v45 = vor.u32 %v59448_v42, %v59447_v44 (stack47)
        %v61111_v24 = vadd.s32 %v61106_v61, %v121574_v2 (stack40)
        %v61115_v30 = vadd.s32 %v61076_v30, %v121569_v1 (stack40)
        %v59850_v46 = vadd.s32 %v59847_v6, %v59842_v46 (stack40)
        %v59852_v52 = vshll.u32 %v59847_v6, 16 (stack45)
        %v59853_v60 = vshrl.u32 %v59847_v6, 16 (stack46)
        %v60281_v23 = vadd.s32 2, %v60277_v29 (stack40)
        %v58688_v26 = vmul.f32 %v58684_v56, %v139447_v40 (stack54)
        %v59450_v41 = vxor.u32 %v59449_v45, %v59441_v21 (stack48)
        %v60694_v50 = vadd.s32 %v60691_v27, %v121564_v0 (stack40)
        %v139504_v53 = vadd.s32 %v61115_v30, %v61111_v24 (stack40)
        %v59854_v12 = vor.u32 %v59853_v60, %v59852_v52 (stack47)
        %v60285_v20 = vadd.s32 %v60281_v23, %v60269_v20 (stack40)
        %v60287_v44 = vshll.u32 %v60281_v23, 13 (stack45)
        %v60288_v42 = vshrl.u32 %v60281_v23, 19 (stack46)
        %v58692_v31 = vadd.f32 %v58688_v26, %v139463_v31 (stack53)
        %v59453_v6 = vadd.s32 %v59450_v41, %v121574_v2 (stack40)
        %v60686_v7 = vadd.s32 %v60682_v7, %v121569_v1 (stack40)
        %v60698_v29 = vadd.s32 1, %v60694_v50 (stack40)
        %v59042_v8 = vmul.f32 %v59041_v32, %v139473_v8 (stack63)
        %v59855_v32 = vxor.u32 %v59854_v12, %v59850_v46 (stack48)
        %v60289_v27 = vor.u32 %v60288_v42, %v60287_v44 (stack47)
        %v139512_v61 = vadd.s32 %v157438_v10, %v157079_v39 (stack40)
        %v120934_v56 = vpop.eup %120933 (stack64)
        %v58696_v45 = vmul.f32 %v58692_v31, %v139447_v40 (stack54)
        %v59445_v21 = vadd.s32 %v59441_v21, %v121564_v0 (stack40)
        %v59457_v24 = vadd.s32 5, %v59453_v6 (stack40)
        %v60702_v52 = vadd.s32 %v60698_v29, %v60686_v7 (stack40)
        %v59039_v60 = vmul.f32 0.6931472, %v120934_v56 (stack65)
        %v59858_v46 = vadd.s32 %v59855_v32, %v59850_v46 (stack40)
        %v59864_v23 = vshll.u32 %v59855_v32, 24 (stack45)
        %v59865_v26 = vshrl.u32 %v59855_v32, 8 (stack46)
        %v58700_v25 = vadd.f32 %v58696_v45, %v139413_v25 (stack53)
        %v59459_v41 = vxor.u32 %v59457_v24, %v59445_v21 (stack48)
        %v60290_v50 = vxor.u32 %v60289_v27, %v60285_v20 (stack48)
        %v61121_v12 = vshll.u32 %v61115_v30, 13 (stack45)
        %v59045_v34 = vsel /*vm=*/%vm139496_vm6, /*on_true_vy=*/%v59042_v8, /*on_false_vx=*/%v59039_v60 (stack66)
        %v59866_v44 = vor.u32 %v59865_v26, %v59864_v23 (stack47)
        %v60704_v42 = vshll.u32 %v60698_v29, 17 (stack45)
        %v61122_v30 = vshrl.u32 %v61115_v30, 19 (stack46)
        %v58704_v40 = vmul.f32 %v58700_v25, %v139447_v40 (stack54)
        %v139520_v31 = vxor.u32 2147483648, %v59045_v34 (stack56)
        %v60293_v20 = vadd.s32 %v60290_v50, %v60285_v20 (stack40)
        %v60705_v6 = vshrl.u32 %v60698_v29, 15 (stack46)
        %v58593_v9 = vsel /*vm=*/%vm58588_vm0, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v59867_v7 = vxor.u32 %v59866_v44, %v59858_v46 (stack48)
        %v60295_v29 = vshll.u32 %v60290_v50, 15 (stack45)
        %v60296_v8 = vshrl.u32 %v60290_v50, 17 (stack46)
        %v58708_v32 = vadd.f32 %v58704_v40, %v58593_v9 (stack53)
        %120935 = vrsqrt.f32 %v139520_v31 (stack67)
        %vm59049_vm7 = vcmp.lt.f32.partialorder %v139520_v31, 5.0 (stack68)
        %v59460_v27 = vand.u32.u8 255, %v59459_v41 (stack49)
        %v59870_v56 = vadd.s32 %v59867_v7, %v121564_v0 (stack40)
        %v58569_v45 = vmul.f32 inf, %v139329_v55 (stack54)
        %v58712_v21 = vmul.f32 %v58708_v32, %v139329_v55 (stack54)
        %v60706_v24 = vor.u32 %v60705_v6, %v60704_v42 (stack47)
        %v61123_v60 = vor.u32 %v61122_v30, %v61121_v12 (stack47)
        %vm58564_vm8 = vcmp.eq.f32.partialorder %v58561_v43, 1.0 (stack68)
        %v59022_v55 = vand.u32 2147483647, %v139457_v54 (stack77)
        %v59862_v43 = vadd.s32 %v59858_v46, %v121569_v1 (stack40)
        %v60297_v46 = vor.u32 %v60296_v8, %v60295_v29 (stack47)
        %v58716_v23 = vsel /*vm=*/%vm58564_vm8, /*on_true_vy=*/%v58569_v45, /*on_false_vx=*/%v58712_v21 (stack44)
        %v139537_v26 = vsel /*vm=*/%vm59049_vm7, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v139542_v25 = vsel /*vm=*/%vm59049_vm7, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v139545_v41 = vadd.f32 -2.5, %v139520_v31 (stack53)
        %v58720_v50 = vmul.f32 1.4140625, %v58716_v23 (stack54)
        %v59461_v12 = vand.u32 65535, %v59460_v27 (stack50)
        %v59874_v34 = vadd.s32 4, %v59870_v56 (stack40)
        %v60298_v44 = vxor.u32 %v60297_v46, %v60293_v20 (stack48)
        %v139550_v42 = vsel /*vm=*/%vm59049_vm7, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v60707_v30 = vxor.u32 %v60706_v24, %v60702_v52 (stack48)
        %v61124_v40 = vxor.u32 %v61123_v60, %v139504_v53 (stack48)
        %vm61546_vm9 = vcmp.lt.u32.totalorder %v139512_v61, %v157079_v39 (stack43)
        %v58723_v6 = vpack.c.bf16 %v157387_v11, %v58720_v50 (stack81)
        %v59462_v9 = vshrl.u32 %v59461_v12, 1 (stack51)
        %v59878_v7 = vadd.s32 %v59874_v34, %v59862_v43 (stack40)
        %v59880_v29 = vshll.u32 %v59874_v34, 13 (stack45)
        %v59881_v8 = vshrl.u32 %v59874_v34, 19 (stack46)
        %v60301_v20 = vadd.s32 %v60298_v44, %v60293_v20 (stack40)
        %v60303_v32 = vshll.u32 %v60298_v44, 26 (stack45)
        %v60304_v27 = vshrl.u32 %v60298_v44, 6 (stack46)
        %120057 = vst [vmem:[%s123356_s30 + $0x23c] sm:$0xf] /*vst_source=*/%v58723_v6 (stack83)
        %v59463_v56 = vor.u32 16256, %v59462_v9 (stack47)
        %v60710_v52 = vadd.s32 %v60707_v30, %v60702_v52 (stack40)
        %v60712_v45 = vshll.u32 %v60707_v30, 29 (stack45)
        %v60713_v21 = vshrl.u32 %v60707_v30, 3 (stack46)
        %v59882_v24 = vor.u32 %v59881_v8, %v59880_v29 (stack47)
        %v60305_v60 = vor.u32 %v60304_v27, %v60303_v32 (stack47)
        %v61127_v53 = vadd.s32 %v61124_v40, %v139504_v53 (stack40)
        %v61129_v43 = vshll.u32 %v61124_v40, 15 (stack45)
        %vm59094_vm10 = vcmp.eq.f32.partialorder %v139520_v31, inf (stack70)
        %v59464_v46 = vand.u32.u16 65535, %v59463_v56 (stack52)
        %v60714_v23 = vor.u32 %v60713_v21, %v60712_v45 (stack47)
        %v61130_v50 = vshrl.u32 %v61124_v40, 17 (stack46)
        %v59097_v12 = vand.u32 2147483648, %v139520_v31 (stack72)
        %v59883_v34 = vxor.u32 %v59882_v24, %v59878_v7 (stack48)
        %v60306_v44 = vxor.u32 %v60305_v60, %v60301_v20 (stack48)
        %v139562_v30 = vadd.s32 %v157441_v22, %v157082_v49 (stack40)
        %v120936_v40 = vpop.eup %120935 (stack73)
        %v120060_v6 = vadd.low.f32.bf16 -1.0, %v59464_v46 (stack53)
        %v60715_v9 = vxor.u32 %v60714_v23, %v60710_v52 (stack48)
        %v61131_v29 = vor.u32 %v61130_v50, %v61129_v43 (stack47)
        %v139566_v8 = vadd.s32 %v157438_v10, %v157083_v59 (stack40)
        %v59093_v32 = vmul.f32 %v120936_v40, %v139520_v31 (stack74)
        %v59886_v7 = vadd.s32 %v59883_v34, %v59878_v7 (stack40)
        %v59888_v27 = vshll.u32 %v59883_v34, 15 (stack45)
        %v59889_v56 = vshrl.u32 %v59883_v34, 17 (stack46)
        %v59473_v45 = vmul.f32 2.0, %v120060_v6 (stack54)
        %v60309_v20 = vadd.s32 %v60306_v44, %v60301_v20 (stack40)
        %v60315_v21 = vshll.u32 %v60306_v44, 6 (stack45)
        %v60316_v24 = vshrl.u32 %v60306_v44, 26 (stack46)
        %v59095_v60 = vsel /*vm=*/%vm59094_vm10, /*on_true_vy=*/%v139520_v31, /*on_false_vx=*/%v59093_v32 (stack75)
        %vm59096_vm11 = vcmp.eq.f32.partialorder %v139520_v31, 0.0 (stack71)
        %v59890_v43 = vor.u32 %v59889_v56, %v59888_v27 (stack47)
        %v60718_v52 = vadd.s32 %v60715_v9, %v60710_v52 (stack40)
        %v59098_v46 = vsel /*vm=*/%vm59096_vm11, /*on_true_vy=*/%v59097_v12, /*on_false_vx=*/%v59095_v60 (stack76)
        %v59477_v23 = vadd.f32 -0.99609375, %v59473_v45 (stack53)
        %v60317_v50 = vor.u32 %v60316_v24, %v60315_v21 (stack47)
        %v60720_v12 = vshll.u32 %v60715_v9, 16 (stack45)
        %v59101_v34 = vadd.f32 -3.0, %v59098_v46 (stack53)
        %v59891_v44 = vxor.u32 %v59890_v43, %v59886_v7 (stack48)
        %v60721_v40 = vshrl.u32 %v60715_v9, 16 (stack46)
        %v61132_v6 = vxor.u32 %v61131_v29, %v61127_v53 (stack48)
        %v59074_v9 = vsel /*vm=*/%vm59049_vm7, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v59086_v29 = vsel /*vm=*/%vm59049_vm7, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v139579_v32 = vmax.f32 %v59477_v23, -0.99609375 (stack55)
        %v60318_v27 = vxor.u32 %v60317_v50, %v60309_v20 (stack48)
        %v139584_v41 = vsel /*vm=*/%vm59049_vm7, /*on_true_vy=*/%v139545_v41, /*on_false_vx=*/%v59101_v34 (stack44)
        %v59894_v7 = vadd.s32 %v59891_v44, %v59886_v7 (stack40)
        %v59896_v56 = vshll.u32 %v59891_v44, 26 (stack45)
        %v59897_v45 = vshrl.u32 %v59891_v44, 6 (stack46)
        %v59082_v21 = vsel /*vm=*/%vm59049_vm7, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v59109_v24 = vmul.f32 %v139584_v41, %v59086_v29 (stack54)
        %v59493_v60 = vxor.u32 2147483648, %v139579_v32 (stack56)
        %v139593_v43 = vadd.s32 %v139512_v61, %v122657_v58 (stack40)
        %v59898_v46 = vor.u32 %v59897_v45, %v59896_v56 (stack47)
        %v60321_v23 = vadd.s32 %v60318_v27, %v121569_v1 (stack40)
        %v60722_v50 = vor.u32 %v60721_v40, %v60720_v12 (stack47)
        %v61135_v53 = vadd.s32 %v61132_v6, %v61127_v53 (stack40)
        %v59078_v12 = vsel /*vm=*/%vm59049_vm7, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v59113_v34 = vadd.f32 %v59109_v24, %v59082_v21 (stack53)
        %v59496_v44 = vmul.f32 %v59493_v60, %v139579_v32 (stack54)
        %v60313_v20 = vadd.s32 %v60309_v20, %v121574_v2 (stack40)
        %v59899_v40 = vxor.u32 %v59898_v46, %v59894_v7 (stack48)
        %v60325_v29 = vadd.s32 3, %v60321_v23 (stack40)
        %v60723_v27 = vxor.u32 %v60722_v50, %v60718_v52 (stack48)
        %v61137_v56 = vshll.u32 %v61132_v6, 26 (stack45)
        %v59117_v45 = vmul.f32 %v59113_v34, %v139584_v41 (stack54)
        %v59498_v21 = vadd.f32 1.0, %v59496_v44 (stack57)
        %v59501_v24 = vmul.f32 -0.5, %v59496_v44 (stack59)
        %v61138_v6 = vshrl.u32 %v61132_v6, 6 (stack46)
        %vm61541_vm12 = vcmp.lt.u32.totalorder %v139593_v43, %v139512_v61 (stack43)
        %v59902_v7 = vadd.s32 %v59899_v40, %v59894_v7 (stack40)
        %v59908_v60 = vshll.u32 %v59899_v40, 6 (stack45)
        %v59909_v46 = vshrl.u32 %v59899_v40, 26 (stack46)
        %v60329_v23 = vadd.s32 %v60325_v29, %v60313_v20 (stack40)
        %v59121_v50 = vadd.f32 %v59117_v45, %v59078_v12 (stack53)
        %120937 = vlog2.f32 %v59498_v21 (stack58)
        %v61555_v12 = vadd.s32 1, %v139562_v30 (stack40)
        %v61576_v34 = vadd.s32 %v139593_v43, %v121569_v1 (stack40)
        %v59504_v20 = vand.u32 2147483647, %v59496_v44 (stack60)
        %v59910_v40 = vor.u32 %v59909_v46, %v59908_v60 (stack47)
        %v60331_v45 = vshll.u32 %v60325_v29, 17 (stack45)
        %v60332_v29 = vshrl.u32 %v60325_v29, 15 (stack46)
        %v59125_v21 = vmul.f32 %v59121_v50, %v139584_v41 (stack54)
        %v59502_v24 = vadd.f32 1.0, %v59501_v24 (stack61)
        %v60726_v52 = vadd.s32 %v60723_v27, %v60718_v52 (stack40)
        %v60732_v60 = vshll.u32 %v60723_v27, 24 (stack45)
        %v59911_v46 = vxor.u32 %v59910_v40, %v59902_v7 (stack48)
        %v60333_v50 = vor.u32 %v60332_v29, %v60331_v45 (stack47)
        %v60733_v27 = vshrl.u32 %v60723_v27, 8 (stack46)
        %v61139_v56 = vor.u32 %v61138_v6, %v61137_v56 (stack47)
        %v59129_v9 = vadd.f32 %v59125_v21, %v59074_v9 (stack53)
        %v59906_v6 = vadd.s32 %v59902_v7, %v121564_v0 (stack40)
        %v61559_v30 = vsel /*vm=*/%vm61546_vm9, /*on_true_vy=*/%v61555_v12, /*on_false_vx=*/%v139562_v30 (stack44)
        %v61582_v7 = vshll.u32 %v61576_v34, 13 (stack45)
        %v59914_v12 = vadd.s32 %v59911_v46, %v121574_v2 (stack40)
        %v60334_v40 = vxor.u32 %v60333_v50, %v60329_v23 (stack48)
        %v60734_v45 = vor.u32 %v60733_v27, %v60732_v60 (stack47)
        %v61140_v29 = vxor.u32 %v61139_v56, %v61135_v53 (stack48)
        %v59133_v21 = vmul.f32 %v59129_v9, %v139584_v41 (stack54)
        %v59503_v44 = vmul.f32 %v59502_v24, %v59496_v44 (stack63)
        %v61563_v24 = vadd.s32 1, %v61559_v30 (stack40)
        %v61583_v60 = vshrl.u32 %v61576_v34, 19 (stack46)
        %vm139615_vm13 = vcmp.lt.f32.partialorder %v59504_v20, 0.0004427343 (stack62)
        %v59918_v46 = vadd.s32 5, %v59914_v12 (stack40)
        %v60337_v23 = vadd.s32 %v60334_v40, %v60329_v23 (stack40)
        %v60339_v50 = vshll.u32 %v60334_v40, 29 (stack45)
        %v60340_v27 = vshrl.u32 %v60334_v40, 3 (stack46)
        %v59137_v42 = vadd.f32 %v59133_v21, %v139550_v42 (stack53)
        %v60735_v56 = vxor.u32 %v60734_v45, %v60726_v52 (stack48)
        %v61143_v53 = vadd.s32 %v61140_v29, %v61135_v53 (stack40)
        %v61149_v9 = vshll.u32 %v61140_v29, 6 (stack45)
        %v59920_v6 = vxor.u32 %v59918_v46, %v59906_v6 (stack48)
        %v60341_v12 = vor.u32 %v60340_v27, %v60339_v50 (stack47)
        %v61150_v40 = vshrl.u32 %v61140_v29, 26 (stack46)
        %v61567_v61 = vsel /*vm=*/%vm61541_vm12, /*on_true_vy=*/%v61563_v24, /*on_false_vx=*/%v61559_v30 (stack44)
        %v59141_v43 = vmul.f32 %v59137_v42, %v139584_v41 (stack54)
        %v60730_v52 = vadd.s32 %v60726_v52, %v121564_v0 (stack40)
        %v60738_v30 = vadd.s32 %v60735_v56, %v121574_v2 (stack40)
        %v61572_v45 = vadd.s32 %v61567_v61, %v121574_v2 (stack40)
        %v59921_v29 = vand.u32.u8 255, %v59920_v6 (stack49)
        %v60342_v21 = vxor.u32 %v60341_v12, %v60337_v23 (stack48)
        %v61151_v24 = vor.u32 %v61150_v40, %v61149_v9 (stack47)
        %v61584_v7 = vor.u32 %v61583_v60, %v61582_v7 (stack47)
        %v59145_v25 = vadd.f32 %v59141_v43, %v139542_v25 (stack53)
        %v60742_v60 = vadd.s32 2, %v60738_v30 (stack40)
        %v61580_v34 = vadd.s32 %v61576_v34, %v61572_v45 (stack40)
        %vm62007_vm14 = vcmp.lt.u32.totalorder %v139566_v8, %v157083_v59 (stack43)
        %v120938_v46 = vpop.eup %120937 (stack64)
        %v59922_v50 = vand.u32 65535, %v59921_v29 (stack50)
        %v60345_v23 = vadd.s32 %v60342_v21, %v60337_v23 (stack40)
        %v60347_v27 = vshll.u32 %v60342_v21, 16 (stack45)
        %v60348_v42 = vshrl.u32 %v60342_v21, 16 (stack46)
        %v59149_v56 = vmul.f32 %v59145_v25, %v139584_v41 (stack54)
        %v59500_v9 = vmul.f32 0.6931472, %v120938_v46 (stack65)
        %v60746_v6 = vadd.s32 %v60742_v60, %v60730_v52 (stack40)
        %v60748_v12 = vshll.u32 %v60742_v60, 13 (stack45)
        %v59923_v40 = vshrl.u32 %v59922_v50, 1 (stack51)
        %v60349_v61 = vor.u32 %v60348_v42, %v60347_v27 (stack47)
        %v60749_v43 = vshrl.u32 %v60742_v60, 19 (stack46)
        %v61152_v52 = vxor.u32 %v61151_v24, %v61143_v53 (stack48)
        %v59153_v26 = vadd.f32 %v59149_v56, %v139537_v26 (stack53)
        %v59506_v44 = vsel /*vm=*/%vm139615_vm13, /*on_true_vy=*/%v59503_v44, /*on_false_vx=*/%v59500_v9 (stack66)
        %v61585_v20 = vxor.u32 %v61584_v7, %v61580_v34 (stack48)
        %v62012_v30 = vadd.s32 %v157441_v22, %v157084_v16 (stack40)
        %v139636_v45 = vxor.u32 2147483648, %v59506_v44 (stack56)
        %v60350_v29 = vxor.u32 %v60349_v61, %v60345_v23 (stack48)
        %v59157_v21 = vmul.f32 %v59153_v26, %v139584_v41 (stack54)
        %v61588_v24 = vadd.s32 %v61585_v20, %v61580_v34 (stack40)
        %v59030_v7 = vmul.f32 inf, %v139457_v54 (stack54)
        %v59058_v25 = vsel /*vm=*/%vm59049_vm7, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %120939 = vrsqrt.f32 %v139636_v45 (stack67)
        %v59924_v60 = vor.u32 16256, %v59923_v40 (stack47)
        %vm139646_vm15 = vcmp.eq.f32.partialorder %v59022_v55, 1.0 (stack68)
        %v59161_v34 = vadd.f32 %v59157_v21, %v59058_v25 (stack53)
        %vm59510_vm0 = vcmp.lt.f32.partialorder %v139636_v45, 5.0 (stack68)
        %v60750_v46 = vor.u32 %v60749_v43, %v60748_v12 (stack47)
        %v59054_v31 = vsel /*vm=*/%vm59049_vm7, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v59483_v50 = vand.u32 2147483647, %v139579_v32 (stack77)
        %v60353_v23 = vadd.s32 %v60350_v29, %v60345_v23 (stack40)
        %v61155_v27 = vadd.s32 %v61152_v52, %v121564_v0 (stack40)
        %v59165_v41 = vmul.f32 %v59161_v34, %v139584_v41 (stack54)
        %v139658_v42 = vmul.f32 inf, %v139579_v32 (stack54)
        %v61147_v53 = vadd.s32 %v61143_v53, %v121569_v1 (stack40)
        %v139663_v56 = vadd.s32 %v139566_v8, %v122657_v58 (stack40)
        %v139668_v9 = vsel /*vm=*/%vm59510_vm0, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v139671_v12 = vadd.f32 -2.5, %v139636_v45 (stack53)
        %v59925_v40 = vand.u32.u16 65535, %v59924_v60 (stack52)
        %v61590_v61 = vshll.u32 %v61585_v20, 15 (stack45)
        %v59169_v43 = vadd.f32 %v59165_v41, %v59054_v31 (stack53)
        %v60359_v52 = vshll.u32 %v60350_v29, 24 (stack45)
        %v60360_v26 = vshrl.u32 %v60350_v29, 8 (stack46)
        %v60751_v44 = vxor.u32 %v60750_v46, %v60746_v6 (stack48)
        %v120062_v29 = vadd.low.f32.bf16 -1.0, %v59925_v40 (stack53)
        %v61159_v21 = vadd.s32 1, %v61155_v27 (stack40)
        %v61591_v20 = vshrl.u32 %v61585_v20, 17 (stack46)
        %v62016_v25 = vadd.s32 1, %v62012_v30 (stack40)
        %v59173_v54 = vmul.f32 %v59169_v43, %v139457_v54 (stack54)
        %vm59555_vm1 = vcmp.eq.f32.partialorder %v139636_v45, inf (stack70)
        %v60361_v60 = vor.u32 %v60360_v26, %v60359_v52 (stack47)
        %v60754_v6 = vadd.s32 %v60751_v44, %v60746_v6 (stack40)
        %v60756_v34 = vshll.u32 %v60751_v44, 15 (stack45)
        %v59934_v46 = vmul.f32 2.0, %v120062_v29 (stack54)
        %v60757_v31 = vshrl.u32 %v60751_v44, 17 (stack46)
        %v61163_v27 = vadd.s32 %v61159_v21, %v61147_v53 (stack40)
        %v61165_v41 = vshll.u32 %v61159_v21, 17 (stack45)
        %v59177_v7 = vsel /*vm=*/%vm139646_vm15, /*on_true_vy=*/%v59030_v7, /*on_false_vx=*/%v59173_v54 (stack44)
        %v60362_v55 = vxor.u32 %v60361_v60, %v60353_v23 (stack48)
        %v61166_v53 = vshrl.u32 %v61159_v21, 15 (stack46)
        %v61592_v40 = vor.u32 %v61591_v20, %v61590_v61 (stack47)
        %v59181_v61 = vmul.f32 1.4140625, %v59177_v7 (stack54)
        %v59938_v43 = vadd.f32 -0.99609375, %v59934_v46 (stack53)
        %v60758_v52 = vor.u32 %v60757_v31, %v60756_v34 (stack47)
        %v62020_v30 = vsel /*vm=*/%vm62007_vm14, /*on_true_vy=*/%v62016_v25, /*on_false_vx=*/%v62012_v30 (stack44)
        %v139683_v26 = vsel /*vm=*/%vm59510_vm0, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v60365_v44 = vadd.s32 %v60362_v55, %v121564_v0 (stack40)
        %v61167_v29 = vor.u32 %v61166_v53, %v61165_v41 (stack47)
        %v61593_v21 = vxor.u32 %v61592_v40, %v61588_v24 (stack48)
        %v59184_v20 = vpack.c.bf16 %v157387_v11, %v59181_v61 (stack81)
        %v59543_v25 = vsel /*vm=*/%vm59510_vm0, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v139690_v54 = vmax.f32 %v59938_v43, -0.99609375 (stack55)
        %v60759_v60 = vxor.u32 %v60758_v52, %v60754_v6 (stack48)
        %vm62002_vm2 = vcmp.lt.u32.totalorder %v139663_v56, %v139566_v8 (stack43)
        %v120940_v34 = vpop.eup %120939 (stack73)
        %v60357_v23 = vadd.s32 %v60353_v23, %v121569_v1 (stack40)
        %v60369_v46 = vadd.s32 4, %v60365_v44 (stack40)
        %v61168_v31 = vxor.u32 %v61167_v29, %v61163_v27 (stack48)
        %v139695_v24 = vadd.s32 %v61593_v21, %v61588_v24 (stack40)
        %120059 = vst [vmem:[%s123356_s30 + $0x2bc] sm:$0xf] /*vst_source=*/%v59184_v20 (stack83)
        %v59547_v41 = vsel /*vm=*/%vm59510_vm0, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v59554_v7 = vmul.f32 %v120940_v34, %v139636_v45 (stack74)
        %v59558_v55 = vand.u32 2147483648, %v139636_v45 (stack72)
        %v59954_v53 = vxor.u32 2147483648, %v139690_v54 (stack56)
        %v60373_v40 = vadd.s32 %v60369_v46, %v60357_v23 (stack40)
        %v60375_v61 = vshll.u32 %v60369_v46, 13 (stack45)
        %v60376_v43 = vshrl.u32 %v60369_v46, 19 (stack46)
        %v60762_v6 = vadd.s32 %v60759_v60, %v60754_v6 (stack40)
        %v59556_v52 = vsel /*vm=*/%vm59555_vm1, /*on_true_vy=*/%v139636_v45, /*on_false_vx=*/%v59554_v7 (stack75)
        %vm59557_vm3 = vcmp.eq.f32.partialorder %v139636_v45, 0.0 (stack71)
        %v59957_v44 = vmul.f32 %v59954_v53, %v139690_v54 (stack54)
        %v60764_v29 = vshll.u32 %v60759_v60, 26 (stack45)
        %v59559_v20 = vsel /*vm=*/%vm59557_vm3, /*on_true_vy=*/%v59558_v55, /*on_false_vx=*/%v59556_v52 (stack76)
        %v60377_v34 = vor.u32 %v60376_v43, %v60375_v61 (stack47)
        %v60765_v60 = vshrl.u32 %v60759_v60, 6 (stack46)
        %v61171_v27 = vadd.s32 %v61168_v31, %v61163_v27 (stack40)
        %v59562_v23 = vadd.f32 -3.0, %v59559_v20 (stack53)
        %v59959_v46 = vadd.f32 1.0, %v59957_v44 (stack57)
        %v59962_v7 = vmul.f32 -0.5, %v59957_v44 (stack59)
        %v62024_v55 = vadd.s32 1, %v62020_v30 (stack40)
        %v60378_v53 = vxor.u32 %v60377_v34, %v60373_v40 (stack48)
        %v60766_v61 = vor.u32 %v60765_v60, %v60764_v29 (stack47)
        %v61173_v43 = vshll.u32 %v61168_v31, 29 (stack45)
        %v61174_v31 = vshrl.u32 %v61168_v31, 3 (stack46)
        %v139712_v12 = vsel /*vm=*/%vm59510_vm0, /*on_true_vy=*/%v139671_v12, /*on_false_vx=*/%v59562_v23 (stack44)
        %120941 = vlog2.f32 %v59959_v46 (stack58)
        %v61598_v52 = vshll.u32 %v61593_v21, 26 (stack45)
        %v62037_v29 = vadd.s32 %v139663_v56, %v121569_v1 (stack40)
        %v59570_v41 = vmul.f32 %v139712_v12, %v59547_v41 (stack54)
        %v60381_v40 = vadd.s32 %v60378_v53, %v60373_v40 (stack40)
        %v60383_v20 = vshll.u32 %v60378_v53, 15 (stack45)
        %v60384_v34 = vshrl.u32 %v60378_v53, 17 (stack46)
        %v59965_v60 = vand.u32 2147483647, %v59957_v44 (stack60)
        %v60767_v23 = vxor.u32 %v60766_v61, %v60762_v6 (stack48)
        %v61175_v46 = vor.u32 %v61174_v31, %v61173_v43 (stack47)
        %v61599_v21 = vshrl.u32 %v61593_v21, 6 (stack46)
        %v59574_v25 = vadd.f32 %v59570_v41, %v59543_v25 (stack53)
        %v59963_v7 = vadd.f32 1.0, %v59962_v7 (stack61)
        %v60385_v53 = vor.u32 %v60384_v34, %v60383_v20 (stack47)
        %v62028_v8 = vsel /*vm=*/%vm62002_vm2, /*on_true_vy=*/%v62024_v55, /*on_false_vx=*/%v62020_v30 (stack44)
        %v60770_v56 = vadd.s32 %v60767_v23, %v60762_v6 (stack40)
        %v60776_v30 = vshll.u32 %v60767_v23, 6 (stack45)
        %v60777_v6 = vshrl.u32 %v60767_v23, 26 (stack46)
        %v61176_v55 = vxor.u32 %v61175_v46, %v61171_v27 (stack48)
        %v59578_v61 = vmul.f32 %v59574_v25, %v139712_v12 (stack54)
        %v60386_v43 = vxor.u32 %v60385_v53, %v60381_v40 (stack48)
        %v61600_v31 = vor.u32 %v61599_v21, %v61598_v52 (stack47)
        %v62033_v52 = vadd.s32 %v62028_v8, %v121574_v2 (stack40)
        %v60778_v41 = vor.u32 %v60777_v6, %v60776_v30 (stack47)
        %v61179_v27 = vadd.s32 %v61176_v55, %v61171_v27 (stack40)
        %v61181_v20 = vshll.u32 %v61176_v55, 16 (stack45)
        %v62043_v34 = vshll.u32 %v62037_v29, 13 (stack45)
        %v59582_v26 = vadd.f32 %v59578_v61, %v139683_v26 (stack53)
        %v60389_v40 = vadd.s32 %v60386_v43, %v60381_v40 (stack40)
        %v60391_v23 = vshll.u32 %v60386_v43, 26 (stack45)
        %v60392_v46 = vshrl.u32 %v60386_v43, 6 (stack46)
        %v60779_v21 = vxor.u32 %v60778_v41, %v60770_v56 (stack48)
        %v61182_v25 = vshrl.u32 %v61176_v55, 16 (stack46)
        %v61601_v53 = vxor.u32 %v61600_v31, %v139695_v24 (stack48)
        %v139724_v8 = vadd.s32 %v62037_v29, %v62033_v52 (stack40)
        %v59586_v30 = vmul.f32 %v59582_v26, %v139712_v12 (stack54)
        %v60393_v6 = vor.u32 %v60392_v46, %v60391_v23 (stack47)
        %v62044_v29 = vshrl.u32 %v62037_v29, 19 (stack46)
        %v139729_v55 = vadd.s32 %v157438_v10, %v157089_v17 (stack40)
        %v59535_v61 = vsel /*vm=*/%vm59510_vm0, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v60782_v43 = vadd.s32 %v60779_v21, %v121569_v1 (stack40)
        %v61183_v31 = vor.u32 %v61182_v25, %v61181_v20 (stack47)
        %v139736_v24 = vadd.s32 %v61601_v53, %v139695_v24 (stack40)
        %v59590_v52 = vadd.f32 %v59586_v30, %v59535_v61 (stack53)
        %v59964_v44 = vmul.f32 %v59963_v7, %v59957_v44 (stack63)
        %vm139738_vm4 = vcmp.lt.f32.partialorder %v59965_v60, 0.0004427343 (stack62)
        %v60394_v7 = vxor.u32 %v60393_v6, %v60389_v40 (stack48)
        %v60774_v56 = vadd.s32 %v60770_v56, %v121574_v2 (stack40)
        %v60786_v41 = vadd.s32 3, %v60782_v43 (stack40)
        %v61184_v20 = vxor.u32 %v61183_v31, %v61179_v27 (stack48)
        %v62045_v34 = vor.u32 %v62044_v29, %v62043_v34 (stack47)
        %v120942_v26 = vpop.eup %120941 (stack64)
        %v59594_v23 = vmul.f32 %v59590_v52, %v139712_v12 (stack54)
        %v60397_v40 = vadd.s32 %v60394_v7, %v60389_v40 (stack40)
        %v60403_v46 = vshll.u32 %v60394_v7, 6 (stack45)
        %v60404_v21 = vshrl.u32 %v60394_v7, 26 (stack46)
        %v59961_v25 = vmul.f32 0.6931472, %v120942_v26 (stack65)
        %v60790_v30 = vadd.s32 %v60786_v41, %v60774_v56 (stack40)
        %v60792_v6 = vshll.u32 %v60786_v41, 17 (stack45)
        %v60793_v29 = vshrl.u32 %v60786_v41, 15 (stack46)
        %v59598_v9 = vadd.f32 %v59594_v23, %v139668_v9 (stack53)
        %v60405_v61 = vor.u32 %v60404_v21, %v60403_v46 (stack47)
        %v61187_v27 = vadd.s32 %v61184_v20, %v61179_v27 (stack40)
        %v61610_v43 = vshll.u32 %v61601_v53, 6 (stack45)
        %v59967_v31 = vsel /*vm=*/%vm139738_vm4, /*on_true_vy=*/%v59964_v44, /*on_false_vx=*/%v59961_v25 (stack66)
        %v60794_v52 = vor.u32 %v60793_v29, %v60792_v6 (stack47)
        %v61193_v44 = vshll.u32 %v61184_v20, 24 (stack45)
        %v61194_v60 = vshrl.u32 %v61184_v20, 8 (stack46)
        %v59602_v7 = vmul.f32 %v59598_v9, %v139712_v12 (stack54)
        %v139748_v56 = vxor.u32 2147483648, %v59967_v31 (stack56)
        %v60406_v41 = vxor.u32 %v60405_v61, %v60397_v40 (stack48)
        %v61611_v53 = vshrl.u32 %v61601_v53, 26 (stack46)
        %v59515_v20 = vsel /*vm=*/%vm59510_vm0, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v59527_v26 = vsel /*vm=*/%vm59510_vm0, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v60795_v23 = vxor.u32 %v60794_v52, %v60790_v30 (stack48)
        %v62046_v34 = vxor.u32 %v62045_v34, %v139724_v8 (stack48)
        %v59519_v46 = vsel /*vm=*/%vm59510_vm0, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v59523_v45 = vsel /*vm=*/%vm59510_vm0, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v59606_v21 = vadd.f32 %v59602_v7, %v59527_v26 (stack53)
        %120943 = vrsqrt.f32 %v139748_v56 (stack67)
        %v59944_v25 = vand.u32 2147483647, %v139690_v54 (stack77)
        %vm59971_vm5 = vcmp.lt.f32.partialorder %v139748_v56, 5.0 (stack68)
        %v60409_v6 = vadd.s32 %v60406_v41, %v121574_v2 (stack40)
        %v61195_v29 = vor.u32 %v61194_v60, %v61193_v44 (stack47)
        %v59610_v9 = vmul.f32 %v59606_v21, %v139712_v12 (stack54)
        %v61608_v61 = vadd.s32 %v139736_v24, %v121569_v1 (stack40)
        %v61612_v43 = vor.u32 %v61611_v53, %v61610_v43 (stack47)
        %v139772_v31 = vadd.s32 %v139729_v55, %v122657_v58 (stack40)
        %v139775_v52 = vadd.f32 -2.5, %v139748_v56 (stack53)
        %v60401_v40 = vadd.s32 %v60397_v40, %v121564_v0 (stack40)
        %v60798_v30 = vadd.s32 %v60795_v23, %v60790_v30 (stack40)
        %v61191_v44 = vadd.s32 %v61187_v27, %v121564_v0 (stack40)
        %v59614_v60 = vadd.f32 %v59610_v9, %v59523_v45 (stack53)
        %v139782_v7 = vsel /*vm=*/%vm59971_vm5, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v139787_v41 = vsel /*vm=*/%vm59971_vm5, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v139792_v53 = vsel /*vm=*/%vm59971_vm5, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v60413_v26 = vadd.s32 5, %v60409_v6 (stack40)
        %v60800_v45 = vshll.u32 %v60795_v23, 29 (stack45)
        %v60801_v23 = vshrl.u32 %v60795_v23, 3 (stack46)
        %v61196_v27 = vxor.u32 %v61195_v29, %v61187_v27 (stack48)
        %v59618_v21 = vmul.f32 %v59614_v60, %v139712_v12 (stack54)
        %v61613_v24 = vxor.u32 %v61612_v43, %v139736_v24 (stack48)
        %v139797_v8 = vadd.s32 %v62046_v34, %v139724_v8 (stack40)
        %v62051_v6 = vshll.u32 %v62046_v34, 15 (stack45)
        %vm139801_vm6 = vcmp.eq.f32.partialorder %v59483_v50, 1.0 (stack68)
        %v60415_v29 = vxor.u32 %v60413_v26, %v60401_v40 (stack48)
        %v60802_v9 = vor.u32 %v60801_v23, %v60800_v45 (stack47)
        %v61199_v43 = vadd.s32 %v61196_v27, %v121574_v2 (stack40)
        %v62052_v34 = vshrl.u32 %v62046_v34, 17 (stack46)
        %v59622_v46 = vadd.f32 %v59618_v21, %v59519_v46 (stack53)
        %vm60016_vm7 = vcmp.eq.f32.partialorder %v139748_v56, inf (stack70)
        %v61616_v40 = vadd.s32 %v61613_v24, %v121564_v0 (stack40)
        %vm62468_vm8 = vcmp.lt.u32.totalorder %v139729_v55, %v157089_v17 (stack43)
        %vm60018_vm9 = vcmp.eq.f32.partialorder %v139748_v56, 0.0 (stack71)
        %v60416_v60 = vand.u32.u8 255, %v60415_v29 (stack49)
        %v60803_v26 = vxor.u32 %v60802_v9, %v60798_v30 (stack48)
        %v61203_v45 = vadd.s32 2, %v61199_v43 (stack40)
        %v59626_v12 = vmul.f32 %v59622_v46, %v139712_v12 (stack54)
        %v61620_v23 = vadd.s32 1, %v61616_v40 (stack40)
        %v62053_v27 = vor.u32 %v62052_v34, %v62051_v6 (stack47)
        %v62473_v21 = vadd.s32 %v157441_v22, %v157090_v62 (stack40)
        %v60417_v24 = vand.u32 65535, %v60416_v60 (stack50)
        %v60806_v30 = vadd.s32 %v60803_v26, %v60798_v30 (stack40)
        %v60808_v6 = vshll.u32 %v60803_v26, 16 (stack45)
        %v60809_v29 = vshrl.u32 %v60803_v26, 16 (stack46)
        %v59630_v20 = vadd.f32 %v59626_v12, %v59515_v20 (stack53)
        %v61207_v44 = vadd.s32 %v61203_v45, %v61191_v44 (stack40)
        %v61209_v9 = vshll.u32 %v61203_v45, 13 (stack45)
        %v61210_v43 = vshrl.u32 %v61203_v45, 19 (stack46)
        %v120944_v34 = vpop.eup %120943 (stack73)
        %v60418_v46 = vshrl.u32 %v60417_v24, 1 (stack51)
        %v60810_v40 = vor.u32 %v60809_v29, %v60808_v6 (stack47)
        %v61624_v61 = vadd.s32 %v61620_v23, %v61608_v61 (stack40)
        %v61626_v60 = vshll.u32 %v61620_v23, 17 (stack45)
        %v59634_v32 = vmul.f32 %v59630_v20, %v139579_v32 (stack54)
        %v60015_v26 = vmul.f32 %v120944_v34, %v139748_v56 (stack74)
        %v61211_v45 = vor.u32 %v61210_v43, %v61209_v9 (stack47)
        %v61627_v12 = vshrl.u32 %v61620_v23, 15 (stack46)
        %v60019_v23 = vand.u32 2147483648, %v139748_v56 (stack72)
        %v60419_v24 = vor.u32 16256, %v60418_v46 (stack47)
        %v60811_v6 = vxor.u32 %v60810_v40, %v60806_v30 (stack48)
        %v62054_v27 = vxor.u32 %v62053_v27, %v139797_v8 (stack48)
        %v59638_v42 = vsel /*vm=*/%vm139801_vm6, /*on_true_vy=*/%v139658_v42, /*on_false_vx=*/%v59634_v32 (stack44)
        %v60017_v50 = vsel /*vm=*/%vm60016_vm7, /*on_true_vy=*/%v139748_v56, /*on_false_vx=*/%v60015_v26 (stack75)
        %v61212_v29 = vxor.u32 %v61211_v45, %v61207_v44 (stack48)
        %v61628_v20 = vor.u32 %v61627_v12, %v61626_v60 (stack47)
        %v59642_v9 = vmul.f32 1.4140625, %v59638_v42 (stack54)
        %v60020_v43 = vsel /*vm=*/%vm60018_vm9, /*on_true_vy=*/%v60019_v23, /*on_false_vx=*/%v60017_v50 (stack76)
        %v60420_v34 = vand.u32.u16 65535, %v60419_v24 (stack52)
        %v60814_v30 = vadd.s32 %v60811_v6, %v60806_v30 (stack40)
        %v60023_v46 = vadd.f32 -3.0, %v60020_v43 (stack53)
        %v60820_v40 = vshll.u32 %v60811_v6, 24 (stack45)
        %v60821_v60 = vshrl.u32 %v60811_v6, 8 (stack46)
        %v61215_v44 = vadd.s32 %v61212_v29, %v61207_v44 (stack40)
        %v59645_v32 = vpack.c.bf16 %v157387_v11, %v59642_v9 (stack81)
        %v120068_v26 = vadd.low.f32.bf16 -1.0, %v60420_v34 (stack53)
        %v61217_v45 = vshll.u32 %v61212_v29, 15 (stack45)
        %v62477_v12 = vadd.s32 1, %v62473_v21 (stack40)
        %v139830_v52 = vsel /*vm=*/%vm59971_vm5, /*on_true_vy=*/%v139775_v52, /*on_false_vx=*/%v60023_v46 (stack44)
        %v60822_v23 = vor.u32 %v60821_v60, %v60820_v40 (stack47)
        %v61218_v24 = vshrl.u32 %v61212_v29, 17 (stack46)
        %v61629_v6 = vxor.u32 %v61628_v20, %v61624_v61 (stack48)
        %120061 = vst [vmem:[%s123356_s30 + $0x33c] sm:$0xf] /*vst_source=*/%v59645_v32 (stack83)
        %v60031_v53 = vmul.f32 %v139830_v52, %v139792_v53 (stack54)
        %v60429_v42 = vmul.f32 2.0, %v120068_v26 (stack54)
        %v62057_v8 = vadd.s32 %v62054_v27, %v139797_v8 (stack40)
        %v62059_v50 = vshll.u32 %v62054_v27, 26 (stack45)
        %v60823_v29 = vxor.u32 %v60822_v23, %v60814_v30 (stack48)
        %v61219_v20 = vor.u32 %v61218_v24, %v61217_v45 (stack47)
        %v61632_v61 = vadd.s32 %v61629_v6, %v61624_v61 (stack40)
        %v61634_v9 = vshll.u32 %v61629_v6, 29 (stack45)
        %v60035_v41 = vadd.f32 %v60031_v53, %v139787_v41 (stack53)
        %v60433_v43 = vadd.f32 -0.99609375, %v60429_v42 (stack53)
        %v61635_v34 = vshrl.u32 %v61629_v6, 3 (stack46)
        %v62060_v27 = vshrl.u32 %v62054_v27, 6 (stack46)
        %v60818_v30 = vadd.s32 %v60814_v30, %v121569_v1 (stack40)
        %v60826_v46 = vadd.s32 %v60823_v29, %v121564_v0 (stack40)
        %v61220_v40 = vxor.u32 %v61219_v20, %v61215_v44 (stack48)
        %v62481_v21 = vsel /*vm=*/%vm62468_vm8, /*on_true_vy=*/%v62477_v12, /*on_false_vx=*/%v62473_v21 (stack44)
        %v60039_v60 = vmul.f32 %v60035_v41, %v139830_v52 (stack54)
        %v139843_v32 = vmax.f32 %v60433_v43, -0.99609375 (stack55)
        %v61636_v26 = vor.u32 %v61635_v34, %v61634_v9 (stack47)
        %v62061_v45 = vor.u32 %v62060_v27, %v62059_v50 (stack47)
        %v60830_v12 = vadd.s32 4, %v60826_v46 (stack40)
        %v61223_v44 = vadd.s32 %v61220_v40, %v61215_v44 (stack40)
        %v61225_v23 = vshll.u32 %v61220_v40, 26 (stack45)
        %v61226_v24 = vshrl.u32 %v61220_v40, 6 (stack46)
        %v139848_v6 = vsel /*vm=*/%vm59971_vm5, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v139853_v53 = vsel /*vm=*/%vm59971_vm5, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v60043_v7 = vadd.f32 %v60039_v60, %v139782_v7 (stack53)
        %v60449_v42 = vxor.u32 2147483648, %v139843_v32 (stack56)
        %v60834_v50 = vadd.s32 %v60830_v12, %v60818_v30 (stack40)
        %v60836_v29 = vshll.u32 %v60830_v12, 13 (stack45)
        %v60837_v20 = vshrl.u32 %v60830_v12, 19 (stack46)
        %v61227_v9 = vor.u32 %v61226_v24, %v61225_v23 (stack47)
        %v59988_v41 = vsel /*vm=*/%vm59971_vm5, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v60047_v43 = vmul.f32 %v60043_v7, %v139830_v52 (stack54)
        %v139862_v34 = vmul.f32 %v60449_v42, %v139843_v32 (stack54)
        %v61637_v27 = vxor.u32 %v61636_v26, %v61632_v61 (stack48)
        %v59996_v30 = vsel /*vm=*/%vm59971_vm5, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v60838_v46 = vor.u32 %v60837_v20, %v60836_v29 (stack47)
        %v61228_v40 = vxor.u32 %v61227_v9, %v61223_v44 (stack48)
        %v62062_v60 = vxor.u32 %v62061_v45, %v62057_v8 (stack48)
        %v59992_v26 = vsel /*vm=*/%vm59971_vm5, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v60051_v45 = vadd.f32 %v60047_v43, %v59996_v30 (stack53)
        %v60454_v12 = vadd.f32 1.0, %v139862_v34 (stack57)
        %v60457_v23 = vmul.f32 -0.5, %v139862_v34 (stack59)
        %v60839_v24 = vxor.u32 %v60838_v46, %v60834_v50 (stack48)
        %v61231_v44 = vadd.s32 %v61228_v40, %v61223_v44 (stack40)
        %v61237_v7 = vshll.u32 %v61228_v40, 6 (stack45)
        %v61238_v42 = vshrl.u32 %v61228_v40, 26 (stack46)
        %v60055_v29 = vmul.f32 %v60051_v45, %v139830_v52 (stack54)
        %120945 = vlog2.f32 %v60454_v12 (stack58)
        %vm62463_vm10 = vcmp.lt.u32.totalorder %v139772_v31, %v139729_v55 (stack43)
        %v139877_v20 = vadd.s32 %v139772_v31, %v121569_v1 (stack40)
        %v60842_v50 = vadd.s32 %v60839_v24, %v60834_v50 (stack40)
        %v60844_v9 = vshll.u32 %v60839_v24, 15 (stack45)
        %v60845_v43 = vshrl.u32 %v60839_v24, 17 (stack46)
        %v62485_v30 = vadd.s32 1, %v62481_v21 (stack40)
        %v60059_v46 = vadd.f32 %v60055_v29, %v59992_v26 (stack53)
        %v60458_v40 = vadd.f32 1.0, %v60457_v23 (stack61)
        %v61239_v26 = vor.u32 %v61238_v42, %v61237_v7 (stack47)
        %v61640_v61 = vadd.s32 %v61637_v27, %v61632_v61 (stack40)
        %v60846_v45 = vor.u32 %v60845_v43, %v60844_v9 (stack47)
        %v61642_v12 = vshll.u32 %v61637_v27, 16 (stack45)
        %v61643_v27 = vshrl.u32 %v61637_v27, 16 (stack46)
        %v62065_v8 = vadd.s32 %v62062_v60, %v62057_v8 (stack40)
        %v60063_v23 = vmul.f32 %v60059_v46, %v139830_v52 (stack54)
        %v61240_v24 = vxor.u32 %v61239_v26, %v61231_v44 (stack48)
        %v62071_v7 = vshll.u32 %v62062_v60, 6 (stack45)
        %v62072_v60 = vshrl.u32 %v62062_v60, 26 (stack46)
        %v60847_v42 = vxor.u32 %v60846_v45, %v60842_v50 (stack48)
        %v61235_v44 = vadd.s32 %v61231_v44, %v121574_v2 (stack40)
        %v61644_v29 = vor.u32 %v61643_v27, %v61642_v12 (stack47)
        %v62489_v55 = vsel /*vm=*/%vm62463_vm10, /*on_true_vy=*/%v62485_v30, /*on_false_vx=*/%v62481_v21 (stack44)
        %v60067_v31 = vadd.f32 %v60063_v23, %v59988_v41 (stack53)
        %v61243_v21 = vadd.s32 %v61240_v24, %v121569_v1 (stack40)
        %v62073_v41 = vor.u32 %v62072_v60, %v62071_v7 (stack47)
        %v62494_v9 = vadd.s32 %v62489_v55, %v121574_v2 (stack40)
        %v60850_v50 = vadd.s32 %v60847_v42, %v60842_v50 (stack40)
        %v60852_v43 = vshll.u32 %v60847_v42, 26 (stack45)
        %v60853_v30 = vshrl.u32 %v60847_v42, 6 (stack46)
        %v61645_v46 = vxor.u32 %v61644_v29, %v61640_v61 (stack48)
        %v60071_v26 = vmul.f32 %v60067_v31, %v139830_v52 (stack54)
        %v61247_v45 = vadd.s32 3, %v61243_v21 (stack40)
        %v62074_v12 = vxor.u32 %v62073_v41, %v62065_v8 (stack48)
        %v139888_v27 = vadd.s32 %v139877_v20, %v62494_v9 (stack40)
        %v60854_v23 = vor.u32 %v60853_v30, %v60852_v43 (stack47)
        %v61648_v61 = vadd.s32 %v61645_v46, %v61640_v61 (stack40)
        %v61654_v24 = vshll.u32 %v61645_v46, 24 (stack45)
        %v61655_v7 = vshrl.u32 %v61645_v46, 8 (stack46)
        %v60075_v53 = vadd.f32 %v60071_v26, %v139853_v53 (stack53)
        %v61251_v60 = vadd.s32 %v61247_v45, %v61235_v44 (stack40)
        %v61253_v42 = vshll.u32 %v61247_v45, 17 (stack45)
        %v61254_v44 = vshrl.u32 %v61247_v45, 15 (stack46)
        %v60460_v29 = vand.u32 2147483647, %v139862_v34 (stack60)
        %v60855_v55 = vxor.u32 %v60854_v23, %v60850_v50 (stack48)
        %v61656_v31 = vor.u32 %v61655_v7, %v61654_v24 (stack47)
        %v62077_v21 = vadd.s32 %v62074_v12, %v121564_v0 (stack40)
        %v60079_v41 = vmul.f32 %v60075_v53, %v139830_v52 (stack54)
        %v60459_v34 = vmul.f32 %v60458_v40, %v139862_v34 (stack63)
        %v61255_v40 = vor.u32 %v61254_v44, %v61253_v42 (stack47)
        %v139897_v9 = vadd.s32 %v157438_v10, %v157091_v37 (stack40)
        %v120946_v43 = vpop.eup %120945 (stack64)
        %v60858_v50 = vadd.s32 %v60855_v55, %v60850_v50 (stack40)
        %v60864_v30 = vshll.u32 %v60855_v55, 6 (stack45)
        %v60865_v46 = vshrl.u32 %v60855_v55, 26 (stack46)
        %v61657_v26 = vxor.u32 %v61656_v31, %v61648_v61 (stack48)
        %v60083_v6 = vadd.f32 %v60079_v41, %v139848_v6 (stack53)
        %v60456_v45 = vmul.f32 0.6931472, %v120946_v43 (stack65)
        %v61256_v12 = vxor.u32 %v61255_v40, %v61251_v60 (stack48)
        %v62081_v23 = vadd.s32 1, %v62077_v21 (stack40)
        %v59976_v56 = vsel /*vm=*/%vm59971_vm5, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %vm60461_vm11 = vcmp.lt.f32.partialorder %v60460_v29, 0.0004427343 (stack62)
        %v60866_v24 = vor.u32 %v60865_v46, %v60864_v30 (stack47)
        %v62069_v8 = vadd.s32 %v62065_v8, %v121569_v1 (stack40)
        %v60087_v52 = vmul.f32 %v60083_v6, %v139830_v52 (stack54)
        %v60462_v7 = vsel /*vm=*/%vm60461_vm11, /*on_true_vy=*/%v60459_v34, /*on_false_vx=*/%v60456_v45 (stack66)
        %v61259_v53 = vadd.s32 %v61256_v12, %v61251_v60 (stack40)
        %v61660_v60 = vadd.s32 %v61657_v26, %v121574_v2 (stack40)
        %v139906_v42 = vxor.u32 2147483648, %v60462_v7 (stack56)
        %v60867_v44 = vxor.u32 %v60866_v24, %v60858_v50 (stack48)
        %v62504_v29 = vshll.u32 %v139877_v20, 13 (stack45)
        %v62505_v20 = vshrl.u32 %v139877_v20, 19 (stack46)
        %vm139912_vm12 = vcmp.eq.f32.partialorder %v59944_v25, 1.0 (stack68)
        %v59952_v55 = vmul.f32 inf, %v139690_v54 (stack54)
        %v60091_v31 = vadd.f32 %v60087_v52, %v59976_v56 (stack53)
        %v62085_v21 = vadd.s32 %v62081_v23, %v62069_v8 (stack40)
        %v60439_v41 = vand.u32 2147483647, %v139843_v32 (stack77)
        %vm60466_vm13 = vcmp.lt.f32.partialorder %v139906_v42, 5.0 (stack68)
        %120947 = vrsqrt.f32 %v139906_v42 (stack67)
        %v61652_v61 = vadd.s32 %v61648_v61, %v121564_v0 (stack40)
        %v60095_v54 = vmul.f32 %v60091_v31, %v139690_v54 (stack54)
        %v61261_v34 = vshll.u32 %v61256_v12, 29 (stack45)
        %v61262_v40 = vshrl.u32 %v61256_v12, 3 (stack46)
        %v61664_v43 = vadd.s32 2, %v61660_v60 (stack40)
        %v60870_v30 = vadd.s32 %v60867_v44, %v121574_v2 (stack40)
        %v62087_v46 = vshll.u32 %v62081_v23, 17 (stack45)
        %v62088_v26 = vshrl.u32 %v62081_v23, 15 (stack46)
        %v62506_v6 = vor.u32 %v62505_v20, %v62504_v29 (stack47)
        %v60099_v45 = vsel /*vm=*/%vm139912_vm12, /*on_true_vy=*/%v59952_v55, /*on_false_vx=*/%v60095_v54 (stack44)
        %v139928_v12 = vsel /*vm=*/%vm60466_vm13, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v139931_v23 = vadd.f32 -2.5, %v139906_v42 (stack53)
        %v60862_v50 = vadd.s32 %v60858_v50, %v121564_v0 (stack40)
        %v60103_v56 = vmul.f32 1.4140625, %v60099_v45 (stack54)
        %v139937_v24 = vsel /*vm=*/%vm60466_vm13, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v139942_v8 = vsel /*vm=*/%vm60466_vm13, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v60874_v52 = vadd.s32 5, %v60870_v30 (stack40)
        %v61263_v7 = vor.u32 %v61262_v40, %v61261_v34 (stack47)
        %v61668_v60 = vadd.s32 %v61664_v43, %v61652_v61 (stack40)
        %v61670_v44 = vshll.u32 %v61664_v43, 13 (stack45)
        %v61671_v29 = vshrl.u32 %v61664_v43, 19 (stack46)
        %v60106_v20 = vpack.c.bf16 %v157387_v11, %v60103_v56 (stack81)
        %v60876_v25 = vxor.u32 %v60874_v52, %v60862_v50 (stack48)
        %v62089_v55 = vor.u32 %v62088_v26, %v62087_v46 (stack47)
        %v62507_v31 = vxor.u32 %v62506_v6, %v139888_v27 (stack48)
        %v139949_v61 = vsel /*vm=*/%vm60466_vm13, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %vm60511_vm14 = vcmp.eq.f32.partialorder %v139906_v42, inf (stack70)
        %v61264_v54 = vxor.u32 %v61263_v7, %v61259_v53 (stack48)
        %v61672_v34 = vor.u32 %v61671_v29, %v61670_v44 (stack47)
        %vm62929_vm15 = vcmp.lt.u32.totalorder %v139897_v9, %v157091_v37 (stack43)
        %120063 = vst [vmem:[%s123356_s30 + $0x3bc] sm:$0xf] /*vst_source=*/%v60106_v20 (stack83)
        %v60877_v40 = vand.u32.u8 255, %v60876_v25 (stack49)
        %v62090_v43 = vxor.u32 %v62089_v55, %v62085_v21 (stack48)
        %v62510_v27 = vadd.s32 %v62507_v31, %v139888_v27 (stack40)
        %v62512_v30 = vshll.u32 %v62507_v31, 15 (stack45)
        %v61267_v53 = vadd.s32 %v61264_v54, %v61259_v53 (stack40)
        %v61269_v46 = vshll.u32 %v61264_v54, 16 (stack45)
        %v61270_v26 = vshrl.u32 %v61264_v54, 16 (stack46)
        %v61673_v6 = vxor.u32 %v61672_v34, %v61668_v60 (stack48)
        %v60878_v45 = vand.u32 65535, %v60877_v40 (stack50)
        %v62093_v21 = vadd.s32 %v62090_v43, %v62085_v21 (stack40)
        %v62095_v50 = vshll.u32 %v62090_v43, 29 (stack45)
        %v62096_v56 = vshrl.u32 %v62090_v43, 3 (stack46)
        %v61271_v52 = vor.u32 %v61270_v26, %v61269_v46 (stack47)
        %v61676_v7 = vadd.s32 %v61673_v6, %v61668_v60 (stack40)
        %v61678_v60 = vshll.u32 %v61673_v6, 15 (stack45)
        %v61679_v44 = vshrl.u32 %v61673_v6, 17 (stack46)
        %v60499_v29 = vsel /*vm=*/%vm60466_vm13, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v60879_v20 = vshrl.u32 %v60878_v45, 1 (stack51)
        %v62097_v25 = vor.u32 %v62096_v56, %v62095_v50 (stack47)
        %v62513_v55 = vshrl.u32 %v62507_v31, 17 (stack46)
        %v120948_v31 = vpop.eup %120947 (stack73)
        %v60514_v54 = vand.u32 2147483648, %v139906_v42 (stack72)
        %v61272_v34 = vxor.u32 %v61271_v52, %v61267_v53 (stack48)
        %v61680_v40 = vor.u32 %v61679_v44, %v61678_v60 (stack47)
        %v62934_v43 = vadd.s32 %v157441_v22, %v157094_v36 (stack40)
        %v60510_v46 = vmul.f32 %v120948_v31, %v139906_v42 (stack74)
        %v60880_v26 = vor.u32 16256, %v60879_v20 (stack47)
        %v62098_v6 = vxor.u32 %v62097_v25, %v62093_v21 (stack48)
        %v62514_v30 = vor.u32 %v62513_v55, %v62512_v30 (stack47)
        %v61275_v53 = vadd.s32 %v61272_v34, %v61267_v53 (stack40)
        %v61281_v45 = vshll.u32 %v61272_v34, 24 (stack45)
        %v61282_v50 = vshrl.u32 %v61272_v34, 8 (stack46)
        %v61681_v56 = vxor.u32 %v61680_v40, %v61676_v7 (stack48)
        %v60512_v52 = vsel /*vm=*/%vm60511_vm14, /*on_true_vy=*/%v139906_v42, /*on_false_vx=*/%v60510_v46 (stack75)
        %vm60513_vm0 = vcmp.eq.f32.partialorder %v139906_v42, 0.0 (stack71)
        %v60881_v60 = vand.u32.u16 65535, %v60880_v26 (stack52)
        %v62101_v21 = vadd.s32 %v62098_v6, %v62093_v21 (stack40)
        %v60515_v44 = vsel /*vm=*/%vm60513_vm0, /*on_true_vy=*/%v60514_v54, /*on_false_vx=*/%v60512_v52 (stack76)
        %v61283_v20 = vor.u32 %v61282_v50, %v61281_v45 (stack47)
        %v61684_v7 = vadd.s32 %v61681_v56, %v61676_v7 (stack40)
        %v62103_v25 = vshll.u32 %v62098_v6, 16 (stack45)
        %v60518_v55 = vadd.f32 -3.0, %v60515_v44 (stack53)
        %v120070_v31 = vadd.low.f32.bf16 -1.0, %v60881_v60 (stack53)
        %v61686_v54 = vshll.u32 %v61681_v56, 26 (stack45)
        %v61687_v34 = vshrl.u32 %v61681_v56, 6 (stack46)
        %v60503_v40 = vsel /*vm=*/%vm60466_vm13, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v61284_v46 = vxor.u32 %v61283_v20, %v61275_v53 (stack48)
        %v62104_v26 = vshrl.u32 %v62098_v6, 16 (stack46)
        %v62515_v6 = vxor.u32 %v62514_v30, %v62510_v27 (stack48)
        %v139973_v23 = vsel /*vm=*/%vm60466_vm13, /*on_true_vy=*/%v139931_v23, /*on_false_vx=*/%v60518_v55 (stack44)
        %v60890_v30 = vmul.f32 2.0, %v120070_v31 (stack54)
        %v61688_v45 = vor.u32 %v61687_v34, %v61686_v54 (stack47)
        %v62938_v50 = vadd.s32 1, %v62934_v43 (stack40)
        %v60526_v56 = vmul.f32 %v139973_v23, %v60503_v40 (stack54)
        %v61287_v52 = vadd.s32 %v61284_v46, %v121564_v0 (stack40)
        %v62105_v60 = vor.u32 %v62104_v26, %v62103_v25 (stack47)
        %v139977_v27 = vadd.s32 %v62515_v6, %v62510_v27 (stack40)
        %v60894_v44 = vadd.f32 -0.99609375, %v60890_v30 (stack53)
        %v61279_v53 = vadd.s32 %v61275_v53, %v121569_v1 (stack40)
        %v61689_v20 = vxor.u32 %v61688_v45, %v61684_v7 (stack48)
        %v62920_v25 = vadd.s32 %v139897_v9, %v122657_v58 (stack40)
        %v60530_v29 = vadd.f32 %v60526_v56, %v60499_v29 (stack53)
        %v61291_v55 = vadd.s32 4, %v61287_v52 (stack40)
        %v62106_v31 = vxor.u32 %v62105_v60, %v62101_v21 (stack48)
        %v62942_v43 = vsel /*vm=*/%vm62929_vm15, /*on_true_vy=*/%v62938_v50, /*on_false_vx=*/%v62934_v43 (stack44)
        %v139985_v54 = vmax.f32 %v60894_v44, -0.99609375 (stack55)
        %v61692_v7 = vadd.s32 %v61689_v20, %v61684_v7 (stack40)
        %v61698_v34 = vshll.u32 %v61689_v20, 6 (stack45)
        %v61699_v40 = vshrl.u32 %v61689_v20, 26 (stack46)
        %v60534_v46 = vmul.f32 %v60530_v29, %v139973_v23 (stack54)
        %v61295_v26 = vadd.s32 %v61291_v55, %v61279_v53 (stack40)
        %v61297_v30 = vshll.u32 %v61291_v55, 13 (stack45)
        %v61298_v45 = vshrl.u32 %v61291_v55, 19 (stack46)
        %v60495_v50 = vsel /*vm=*/%vm60466_vm13, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v60910_v56 = vxor.u32 2147483648, %v139985_v54 (stack56)
        %vm62924_vm1 = vcmp.lt.u32.totalorder %v62920_v25, %v139897_v9 (stack43)
        %v139994_v52 = vadd.s32 %v62920_v25, %v121569_v1 (stack40)
        %v60538_v60 = vadd.f32 %v60534_v46, %v60495_v50 (stack53)
        %v61299_v44 = vor.u32 %v61298_v45, %v61297_v30 (stack47)
        %v61700_v53 = vor.u32 %v61699_v40, %v61698_v34 (stack47)
        %v62109_v21 = vadd.s32 %v62106_v31, %v62101_v21 (stack40)
        %v139997_v20 = vmul.f32 %v60910_v56, %v139985_v54 (stack54)
        %v62115_v29 = vshll.u32 %v62106_v31, 24 (stack45)
        %v62116_v55 = vshrl.u32 %v62106_v31, 8 (stack46)
        %v62520_v31 = vshll.u32 %v62515_v6, 26 (stack45)
        %v60542_v34 = vmul.f32 %v60538_v60, %v139973_v23 (stack54)
        %v61300_v40 = vxor.u32 %v61299_v44, %v61295_v26 (stack48)
        %v61701_v46 = vxor.u32 %v61700_v53, %v61692_v7 (stack48)
        %v62521_v6 = vshrl.u32 %v62515_v6, 6 (stack46)
        %v60915_v30 = vadd.f32 1.0, %v139997_v20 (stack57)
        %v60918_v45 = vmul.f32 -0.5, %v139997_v20 (stack59)
        %v62117_v50 = vor.u32 %v62116_v55, %v62115_v29 (stack47)
        %v62965_v56 = vshll.u32 %v139994_v52, 13 (stack45)
        %v60546_v61 = vadd.f32 %v60542_v34, %v139949_v61 (stack53)
        %v61303_v26 = vadd.s32 %v61300_v40, %v61295_v26 (stack40)
        %v61305_v60 = vshll.u32 %v61300_v40, 15 (stack45)
        %v61306_v44 = vshrl.u32 %v61300_v40, 17 (stack46)
        %120949 = vlog2.f32 %v60915_v30 (stack58)
        %v61696_v7 = vadd.s32 %v61692_v7, %v121574_v2 (stack40)
        %v61704_v53 = vadd.s32 %v61701_v46, %v121569_v1 (stack40)
        %v62113_v29 = vadd.s32 %v62109_v21, %v121564_v0 (stack40)
        %v60550_v55 = vmul.f32 %v60546_v61, %v139973_v23 (stack54)
        %v61307_v34 = vor.u32 %v61306_v44, %v61305_v60 (stack47)
        %v62118_v21 = vxor.u32 %v62117_v50, %v62109_v21 (stack48)
        %v62522_v31 = vor.u32 %v62521_v6, %v62520_v31 (stack47)
        %v60919_v40 = vadd.f32 1.0, %v60918_v45 (stack61)
        %v60921_v46 = vand.u32 2147483647, %v139997_v20 (stack60)
        %v61708_v6 = vadd.s32 3, %v61704_v53 (stack40)
        %v62946_v30 = vadd.s32 1, %v62942_v43 (stack40)
        %v60554_v8 = vadd.f32 %v60550_v55, %v139942_v8 (stack53)
        %v61308_v45 = vxor.u32 %v61307_v34, %v61303_v26 (stack48)
        %v62121_v50 = vadd.s32 %v62118_v21, %v121574_v2 (stack40)
        %v62523_v61 = vxor.u32 %v62522_v31, %v139977_v27 (stack48)
        %v61712_v60 = vadd.s32 %v61708_v6, %v61696_v7 (stack40)
        %v61714_v44 = vshll.u32 %v61708_v6, 17 (stack45)
        %v61715_v7 = vshrl.u32 %v61708_v6, 15 (stack46)
        %v62950_v9 = vsel /*vm=*/%vm62924_vm1, /*on_true_vy=*/%v62946_v30, /*on_false_vx=*/%v62942_v43 (stack44)
        %v60558_v25 = vmul.f32 %v60554_v8, %v139973_v23 (stack54)
        %v61311_v43 = vadd.s32 %v61308_v45, %v61303_v26 (stack40)
        %v61313_v26 = vshll.u32 %v61308_v45, 26 (stack45)
        %v61314_v53 = vshrl.u32 %v61308_v45, 6 (stack46)
        %v61716_v55 = vor.u32 %v61715_v7, %v61714_v44 (stack47)
        %v62125_v34 = vadd.s32 2, %v62121_v50 (stack40)
        %v140016_v27 = vadd.s32 %v62523_v61, %v139977_v27 (stack40)
        %v62532_v21 = vshll.u32 %v62523_v61, 6 (stack45)
        %v60562_v24 = vadd.f32 %v60558_v25, %v139937_v24 (stack53)
        %v61315_v31 = vor.u32 %v61314_v53, %v61313_v26 (stack47)
        %v62533_v6 = vshrl.u32 %v62523_v61, 26 (stack46)
        %v62955_v30 = vadd.s32 %v62950_v9, %v121574_v2 (stack40)
        %v61717_v8 = vxor.u32 %v61716_v55, %v61712_v60 (stack48)
        %v62129_v29 = vadd.s32 %v62125_v34, %v62113_v29 (stack40)
        %v62131_v45 = vshll.u32 %v62125_v34, 13 (stack45)
        %v62132_v50 = vshrl.u32 %v62125_v34, 19 (stack46)
        %v60566_v61 = vmul.f32 %v60562_v24, %v139973_v23 (stack54)
        %v61316_v44 = vxor.u32 %v61315_v31, %v61311_v43 (stack48)
        %v62534_v7 = vor.u32 %v62533_v6, %v62532_v21 (stack47)
        %v62966_v9 = vshrl.u32 %v139994_v52, 19 (stack46)
        %v61720_v60 = vadd.s32 %v61717_v8, %v61712_v60 (stack40)
        %v61722_v25 = vshll.u32 %v61717_v8, 29 (stack45)
        %v61723_v26 = vshrl.u32 %v61717_v8, 3 (stack46)
        %v62133_v53 = vor.u32 %v62132_v50, %v62131_v45 (stack47)
        %v60570_v12 = vadd.f32 %v60566_v61, %v139928_v12 (stack53)
        %v61319_v43 = vadd.s32 %v61316_v44, %v61311_v43 (stack40)
        %v61325_v55 = vshll.u32 %v61316_v44, 6 (stack45)
        %v61326_v34 = vshrl.u32 %v61316_v44, 26 (stack46)
        %v61724_v21 = vor.u32 %v61723_v26, %v61722_v25 (stack47)
        %v62134_v24 = vxor.u32 %v62133_v53, %v62129_v29 (stack48)
        %v62535_v31 = vxor.u32 %v62534_v7, %v140016_v27 (stack48)
        %v62963_v6 = vadd.s32 %v139994_v52, %v62955_v30 (stack40)
        %v120950_v30 = vpop.eup %120949 (stack64)
        %v60475_v8 = vsel /*vm=*/%vm60466_vm13, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v60574_v45 = vmul.f32 %v60570_v12, %v139973_v23 (stack54)
        %v60920_v20 = vmul.f32 %v60919_v40, %v139997_v20 (stack63)
        %v61327_v40 = vor.u32 %v61326_v34, %v61325_v55 (stack47)
        %v60917_v50 = vmul.f32 0.6931472, %v120950_v30 (stack65)
        %v61725_v61 = vxor.u32 %v61724_v21, %v61720_v60 (stack48)
        %v62137_v29 = vadd.s32 %v62134_v24, %v62129_v29 (stack40)
        %v62967_v52 = vor.u32 %v62966_v9, %v62965_v56 (stack47)
        %v60578_v56 = vadd.f32 %v60574_v45, %v60475_v8 (stack53)
        %vm60922_vm2 = vcmp.lt.f32.partialorder %v60921_v46, 0.0004427343 (stack62)
        %v61328_v46 = vxor.u32 %v61327_v40, %v61319_v43 (stack48)
        %v62139_v44 = vshll.u32 %v62134_v24, 15 (stack45)
        %v60923_v7 = vsel /*vm=*/%vm60922_vm2, /*on_true_vy=*/%v60920_v20, /*on_false_vx=*/%v60917_v50 (stack66)
        %v61728_v9 = vadd.s32 %v61725_v61, %v61720_v60 (stack40)
        %v61730_v60 = vshll.u32 %v61725_v61, 16 (stack45)
        %v61731_v25 = vshrl.u32 %v61725_v61, 16 (stack46)
        %v60582_v23 = vmul.f32 %v60578_v56, %v139973_v23 (stack54)
        %v140033_v26 = vxor.u32 2147483648, %v60923_v7 (stack56)
        %v62140_v53 = vshrl.u32 %v62134_v24, 17 (stack46)
        %v62538_v12 = vadd.s32 %v62535_v31, %v121564_v0 (stack40)
        %v60471_v42 = vsel /*vm=*/%vm60466_vm13, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v61732_v55 = vor.u32 %v61731_v25, %v61730_v60 (stack47)
        %v62968_v34 = vxor.u32 %v62967_v52, %v62963_v6 (stack48)
        %v140041_v10 = vadd.s32 %v157438_v10, %v157095_v13 (stack40)
        %v60586_v21 = vadd.f32 %v60582_v23, %v60471_v42 (stack53)
        %120951 = vrsqrt.f32 %v140033_v26 (stack67)
        %v60447_v24 = vmul.f32 inf, %v139843_v32 (stack54)
        %vm60927_vm3 = vcmp.lt.f32.partialorder %v140033_v26, 5.0 (stack68)
        %v61331_v31 = vadd.s32 %v61328_v46, %v121574_v2 (stack40)
        %v61733_v30 = vxor.u32 %v61732_v55, %v61728_v9 (stack48)
        %vm60442_vm4 = vcmp.eq.f32.partialorder %v60439_v41, 1.0 (stack68)
        %v60590_v32 = vmul.f32 %v60586_v21, %v139843_v32 (stack54)
        %v62141_v41 = vor.u32 %v62140_v53, %v62139_v44 (stack47)
        %v62542_v8 = vadd.s32 1, %v62538_v12 (stack40)
        %v60900_v45 = vand.u32 2147483647, %v139985_v54 (stack77)
        %v61323_v43 = vadd.s32 %v61319_v43, %v121564_v0 (stack40)
        %v61736_v20 = vadd.s32 %v61733_v30, %v61728_v9 (stack40)
        %v62530_v27 = vadd.s32 %v140016_v27, %v121569_v1 (stack40)
        %v60594_v40 = vsel /*vm=*/%vm60442_vm4, /*on_true_vy=*/%v60447_v24, /*on_false_vx=*/%v60590_v32 (stack44)
        %v140057_v50 = vsel /*vm=*/%vm60927_vm3, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v140062_v61 = vsel /*vm=*/%vm60927_vm3, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v140065_v52 = vadd.f32 -2.5, %v140033_v26 (stack53)
        %v60598_v56 = vmul.f32 1.4140625, %v60594_v40 (stack54)
        %v140070_v46 = vsel /*vm=*/%vm60927_vm3, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v61335_v44 = vadd.s32 5, %v61331_v31 (stack40)
        %v61742_v7 = vshll.u32 %v61733_v30, 24 (stack45)
        %v61743_v9 = vshrl.u32 %v61733_v30, 8 (stack46)
        %v62142_v60 = vxor.u32 %v62141_v41, %v62137_v29 (stack48)
        %v62546_v25 = vadd.s32 %v62542_v8, %v62530_v27 (stack40)
        %v62548_v23 = vshll.u32 %v62542_v8, 17 (stack45)
        %v60601_v53 = vpack.c.bf16 %v157387_v11, %v60598_v56 (stack81)
        %vm60972_vm5 = vcmp.eq.f32.partialorder %v140033_v26, inf (stack70)
        %v61337_v12 = vxor.u32 %v61335_v44, %v61323_v43 (stack48)
        %v62549_v42 = vshrl.u32 %v62542_v8, 15 (stack46)
        %v62971_v6 = vadd.s32 %v62968_v34, %v62963_v6 (stack40)
        %v61744_v55 = vor.u32 %v61743_v9, %v61742_v7 (stack47)
        %v62145_v29 = vadd.s32 %v62142_v60, %v62137_v29 (stack40)
        %v62147_v21 = vshll.u32 %v62142_v60, 26 (stack45)
        %v62148_v24 = vshrl.u32 %v62142_v60, 6 (stack46)
        %120069 = vst [vmem:[%s123356_s30 + $0x40] sm:$0xf] /*vst_source=*/%v60601_v53 (stack83)
        %v61338_v31 = vand.u32.u8 255, %v61337_v12 (stack49)
        %v62550_v30 = vor.u32 %v62549_v42, %v62548_v23 (stack47)
        %v62973_v32 = vshll.u32 %v62968_v34, 15 (stack45)
        %v62974_v34 = vshrl.u32 %v62968_v34, 17 (stack46)
        %vm60974_vm6 = vcmp.eq.f32.partialorder %v140033_v26, 0.0 (stack71)
        %v61745_v41 = vxor.u32 %v61744_v55, %v61736_v20 (stack48)
        %v62149_v8 = vor.u32 %v62148_v24, %v62147_v21 (stack47)
        %vm63390_vm7 = vcmp.lt.u32.totalorder %v140041_v10, %v157095_v13 (stack43)
        %v61339_v43 = vand.u32 65535, %v61338_v31 (stack50)
        %v62551_v27 = vxor.u32 %v62550_v30, %v62546_v25 (stack48)
        %v62975_v40 = vor.u32 %v62974_v34, %v62973_v32 (stack47)
        %v140080_v22 = vadd.s32 %v157441_v22, %v157100_v14 (stack40)
        %v60975_v56 = vand.u32 2147483648, %v140033_v26 (stack72)
        %v61740_v20 = vadd.s32 %v61736_v20, %v121569_v1 (stack40)
        %v61748_v44 = vadd.s32 %v61745_v41, %v121564_v0 (stack40)
        %v62150_v7 = vxor.u32 %v62149_v8, %v62145_v29 (stack48)
        %v120952_v9 = vpop.eup %120951 (stack73)
        %v61340_v60 = vshrl.u32 %v61339_v43, 1 (stack51)
        %v62554_v25 = vadd.s32 %v62551_v27, %v62546_v25 (stack40)
        %v62556_v23 = vshll.u32 %v62551_v27, 29 (stack45)
        %v62557_v53 = vshrl.u32 %v62551_v27, 3 (stack46)
        %v60971_v12 = vmul.f32 %v120952_v9, %v140033_v26 (stack74)
        %v61752_v42 = vadd.s32 4, %v61748_v44 (stack40)
        %v62153_v55 = vadd.s32 %v62150_v7, %v62145_v29 (stack40)
        %v62159_v29 = vshll.u32 %v62150_v7, 6 (stack45)
        %v61341_v21 = vor.u32 16256, %v61340_v60 (stack47)
        %v62160_v24 = vshrl.u32 %v62150_v7, 26 (stack46)
        %v62558_v31 = vor.u32 %v62557_v53, %v62556_v23 (stack47)
        %v62976_v30 = vxor.u32 %v62975_v40, %v62971_v6 (stack48)
        %v60973_v32 = vsel /*vm=*/%vm60972_vm5, /*on_true_vy=*/%v140033_v26, /*on_false_vx=*/%v60971_v12 (stack75)
        %v61756_v34 = vadd.s32 %v61752_v42, %v61740_v20 (stack40)
        %v61758_v41 = vshll.u32 %v61752_v42, 13 (stack45)
        %v61759_v8 = vshrl.u32 %v61752_v42, 19 (stack46)
        %v60976_v43 = vsel /*vm=*/%vm60974_vm6, /*on_true_vy=*/%v60975_v56, /*on_false_vx=*/%v60973_v32 (stack76)
        %v61342_v27 = vand.u32.u16 65535, %v61341_v21 (stack52)
        %v62157_v40 = vadd.s32 %v62153_v55, %v121574_v2 (stack40)
        %v62161_v56 = vor.u32 %v62160_v24, %v62159_v29 (stack47)
        %v60979_v20 = vadd.f32 -3.0, %v60976_v43 (stack53)
        %v61760_v44 = vor.u32 %v61759_v8, %v61758_v41 (stack47)
        %v62559_v7 = vxor.u32 %v62558_v31, %v62554_v25 (stack48)
        %v62979_v6 = vadd.s32 %v62976_v30, %v62971_v6 (stack40)
        %v120072_v9 = vadd.low.f32.bf16 -1.0, %v61342_v27 (stack53)
        %v62162_v60 = vxor.u32 %v62161_v56, %v62153_v55 (stack48)
        %v62981_v23 = vshll.u32 %v62976_v30, 26 (stack45)
        %v62982_v53 = vshrl.u32 %v62976_v30, 6 (stack46)
        %v140095_v52 = vsel /*vm=*/%vm60927_vm3, /*on_true_vy=*/%v140065_v52, /*on_false_vx=*/%v60979_v20 (stack44)
        %v61761_v12 = vxor.u32 %v61760_v44, %v61756_v34 (stack48)
        %v62562_v25 = vadd.s32 %v62559_v7, %v62554_v25 (stack40)
        %v62564_v42 = vshll.u32 %v62559_v7, 16 (stack45)
        %v60987_v46 = vmul.f32 %v140095_v52, %v140070_v46 (stack54)
        %v61351_v55 = vmul.f32 2.0, %v120072_v9 (stack54)
        %v62165_v29 = vadd.s32 %v62162_v60, %v121569_v1 (stack40)
        %v62565_v21 = vshrl.u32 %v62559_v7, 16 (stack46)
        %v61764_v24 = vadd.s32 %v61761_v12, %v61756_v34 (stack40)
        %v61766_v31 = vshll.u32 %v61761_v12, 15 (stack45)
        %v61767_v30 = vshrl.u32 %v61761_v12, 17 (stack46)
        %v62983_v32 = vor.u32 %v62982_v53, %v62981_v23 (stack47)
        %v60991_v61 = vadd.f32 %v60987_v46, %v140062_v61 (stack53)
        %v61355_v34 = vadd.f32 -0.99609375, %v61351_v55 (stack53)
        %v62169_v41 = vadd.s32 3, %v62165_v29 (stack40)
        %v62566_v8 = vor.u32 %v62565_v21, %v62564_v42 (stack47)
        %v60956_v43 = vsel /*vm=*/%vm60927_vm3, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v61768_v27 = vor.u32 %v61767_v30, %v61766_v31 (stack47)
        %v62984_v56 = vxor.u32 %v62983_v32, %v62979_v6 (stack48)
        %v140106_v20 = vadd.s32 %v140041_v10, %v122657_v58 (stack40)
        %v60995_v44 = vmul.f32 %v60991_v61, %v140095_v52 (stack54)
        %v140109_v7 = vmax.f32 %v61355_v34, -0.99609375 (stack55)
        %v62173_v40 = vadd.s32 %v62169_v41, %v62157_v40 (stack40)
        %v62175_v9 = vshll.u32 %v62169_v41, 17 (stack45)
        %v61769_v60 = vxor.u32 %v61768_v27, %v61764_v24 (stack48)
        %v62176_v23 = vshrl.u32 %v62169_v41, 15 (stack46)
        %v62567_v53 = vxor.u32 %v62566_v8, %v62562_v25 (stack48)
        %v140111_v6 = vadd.s32 %v62984_v56, %v62979_v6 (stack40)
        %v140116_v12 = vsel /*vm=*/%vm60927_vm3, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v60944_v42 = vsel /*vm=*/%vm60927_vm3, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v60999_v46 = vadd.f32 %v60995_v44, %v60956_v43 (stack53)
        %v61371_v55 = vxor.u32 2147483648, %v140109_v7 (stack56)
        %v61772_v29 = vadd.s32 %v61769_v60, %v61764_v24 (stack40)
        %v61774_v21 = vshll.u32 %v61769_v60, 26 (stack45)
        %v61775_v24 = vshrl.u32 %v61769_v60, 6 (stack46)
        %v62177_v31 = vor.u32 %v62176_v23, %v62175_v9 (stack47)
        %v60952_v30 = vsel /*vm=*/%vm60927_vm3, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v61003_v32 = vmul.f32 %v60999_v46, %v140095_v52 (stack54)
        %v140127_v61 = vmul.f32 %v61371_v55, %v140109_v7 (stack54)
        %v62570_v25 = vadd.s32 %v62567_v53, %v62562_v25 (stack40)
        %v61776_v34 = vor.u32 %v61775_v24, %v61774_v21 (stack47)
        %v62178_v41 = vxor.u32 %v62177_v31, %v62173_v40 (stack48)
        %v62576_v8 = vshll.u32 %v62567_v53, 24 (stack45)
        %v140131_v43 = vadd.s32 %v140106_v20, %v121569_v1 (stack40)
        %v61007_v27 = vadd.f32 %v61003_v32, %v60952_v30 (stack53)
        %v61376_v44 = vadd.f32 1.0, %v140127_v61 (stack57)
        %v61379_v9 = vmul.f32 -0.5, %v140127_v61 (stack59)
        %v62577_v60 = vshrl.u32 %v62567_v53, 8 (stack46)
        %v61777_v23 = vxor.u32 %v61776_v34, %v61772_v29 (stack48)
        %v62181_v40 = vadd.s32 %v62178_v41, %v62173_v40 (stack40)
        %v62183_v53 = vshll.u32 %v62178_v41, 29 (stack45)
        %v62184_v46 = vshrl.u32 %v62178_v41, 3 (stack46)
        %v60948_v55 = vsel /*vm=*/%vm60927_vm3, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v61011_v21 = vmul.f32 %v61007_v27, %v140095_v52 (stack54)
        %120953 = vlog2.f32 %v61376_v44 (stack58)
        %vm63385_vm8 = vcmp.lt.u32.totalorder %v140106_v20, %v140041_v10 (stack43)
        %v61780_v29 = vadd.s32 %v61777_v23, %v61772_v29 (stack40)
        %v61786_v24 = vshll.u32 %v61777_v23, 6 (stack45)
        %v61787_v31 = vshrl.u32 %v61777_v23, 26 (stack46)
        %v62185_v30 = vor.u32 %v62184_v46, %v62183_v53 (stack47)
        %v61015_v32 = vadd.f32 %v61011_v21, %v60948_v55 (stack53)
        %v62578_v34 = vor.u32 %v62577_v60, %v62576_v8 (stack47)
        %v63399_v41 = vadd.s32 1, %v140080_v22 (stack40)
        %v63426_v8 = vshll.u32 %v140131_v43, 13 (stack45)
        %v61380_v27 = vadd.f32 1.0, %v61379_v9 (stack61)
        %v61382_v44 = vand.u32 2147483647, %v140127_v61 (stack60)
        %v61788_v9 = vor.u32 %v61787_v31, %v61786_v24 (stack47)
        %v62186_v60 = vxor.u32 %v62185_v30, %v62181_v40 (stack48)
        %v61019_v23 = vmul.f32 %v61015_v32, %v140095_v52 (stack54)
        %v62579_v53 = vxor.u32 %v62578_v34, %v62570_v25 (stack48)
        %v62993_v46 = vshll.u32 %v62984_v56, 6 (stack45)
        %v62994_v56 = vshrl.u32 %v62984_v56, 26 (stack46)
        %v61789_v55 = vxor.u32 %v61788_v9, %v61780_v29 (stack48)
        %v62189_v40 = vadd.s32 %v62186_v60, %v62181_v40 (stack40)
        %v62191_v21 = vshll.u32 %v62186_v60, 16 (stack45)
        %v62192_v24 = vshrl.u32 %v62186_v60, 16 (stack46)
        %v61023_v42 = vadd.f32 %v61019_v23, %v60944_v42 (stack53)
        %v62582_v31 = vadd.s32 %v62579_v53, %v121574_v2 (stack40)
        %v62995_v30 = vor.u32 %v62994_v56, %v62993_v46 (stack47)
        %v63403_v22 = vsel /*vm=*/%vm63390_vm7, /*on_true_vy=*/%v63399_v41, /*on_false_vx=*/%v140080_v22 (stack44)
        %v61792_v32 = vadd.s32 %v61789_v55, %v121574_v2 (stack40)
        %v62193_v34 = vor.u32 %v62192_v24, %v62191_v21 (stack47)
        %v62574_v25 = vadd.s32 %v62570_v25, %v121564_v0 (stack40)
        %v63407_v41 = vadd.s32 1, %v63403_v22 (stack40)
        %v61027_v9 = vmul.f32 %v61023_v42, %v140095_v52 (stack54)
        %v62586_v60 = vadd.s32 2, %v62582_v31 (stack40)
        %v62996_v23 = vxor.u32 %v62995_v30, %v140111_v6 (stack48)
        %v157458_v53 = vld [vmem:[#allocation137_spill] sm:$0xff] (stack84)
        %v140156_v46 = vadd.s32 %v157458_v53, %v122651_v47 (stack40)
        %v61784_v29 = vadd.s32 %v61780_v29, %v121564_v0 (stack40)
        %v61796_v56 = vadd.s32 5, %v61792_v32 (stack40)
        %v62194_v55 = vxor.u32 %v62193_v34, %v62189_v40 (stack48)
        %v63411_v10 = vsel /*vm=*/%vm63385_vm8, /*on_true_vy=*/%v63407_v41, /*on_false_vx=*/%v63403_v22 (stack44)
        %v61031_v20 = vadd.f32 %v61027_v9, %v140116_v12 (stack53)
        %v62590_v12 = vadd.s32 %v62586_v60, %v62574_v25 (stack40)
        %v62592_v21 = vshll.u32 %v62586_v60, 13 (stack45)
        %v62593_v24 = vshrl.u32 %v62586_v60, 19 (stack46)
        %v61798_v42 = vxor.u32 %v61796_v56, %v61784_v29 (stack48)
        %v62197_v40 = vadd.s32 %v62194_v55, %v62189_v40 (stack40)
        %v62203_v31 = vshll.u32 %v62194_v55, 24 (stack45)
        %v62204_v30 = vshrl.u32 %v62194_v55, 8 (stack46)
        %v61035_v22 = vmul.f32 %v61031_v20, %v140095_v52 (stack54)
        %v62594_v32 = vor.u32 %v62593_v24, %v62592_v21 (stack47)
        %v62999_v34 = vadd.s32 %v62996_v23, %v121564_v0 (stack40)
        %v63416_v25 = vadd.s32 %v63411_v10, %v121574_v2 (stack40)
        %v120954_v41 = vpop.eup %120953 (stack64)
        %v61381_v61 = vmul.f32 %v61380_v27, %v140127_v61 (stack63)
        %vm140167_vm9 = vcmp.lt.f32.partialorder %v61382_v44, 0.0004427343 (stack62)
        %v61799_v44 = vand.u32.u8 255, %v61798_v42 (stack49)
        %v62205_v9 = vor.u32 %v62204_v30, %v62203_v31 (stack47)
        %v61039_v50 = vadd.f32 %v61035_v22, %v140057_v50 (stack53)
        %v61378_v60 = vmul.f32 0.6931472, %v120954_v41 (stack65)
        %v62595_v23 = vxor.u32 %v62594_v32, %v62590_v12 (stack48)
        %v63003_v29 = vadd.s32 1, %v62999_v34 (stack40)
        %v61800_v56 = vand.u32 65535, %v61799_v44 (stack50)
        %v62206_v55 = vxor.u32 %v62205_v9, %v62197_v40 (stack48)
        %v63424_v10 = vadd.s32 %v140131_v43, %v63416_v25 (stack40)
        %v63427_v20 = vshrl.u32 %v140131_v43, 19 (stack46)
        %v61043_v52 = vmul.f32 %v61039_v50, %v140095_v52 (stack54)
        %v61384_v21 = vsel /*vm=*/%vm140167_vm9, /*on_true_vy=*/%v61381_v61, /*on_false_vx=*/%v61378_v60 (stack66)
        %v62598_v12 = vadd.s32 %v62595_v23, %v62590_v12 (stack40)
        %v62991_v6 = vadd.s32 %v140111_v6, %v121569_v1 (stack40)
        %v60932_v26 = vsel /*vm=*/%vm60927_vm3, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v140182_v24 = vxor.u32 2147483648, %v61384_v21 (stack56)
        %v62600_v42 = vshll.u32 %v62595_v23, 15 (stack45)
        %v62601_v31 = vshrl.u32 %v62595_v23, 17 (stack46)
        %v60908_v30 = vmul.f32 inf, %v139985_v54 (stack54)
        %v61047_v22 = vadd.f32 %v61043_v52, %v60932_v26 (stack53)
        %v63007_v32 = vadd.s32 %v63003_v29, %v62991_v6 (stack40)
        %120955 = vrsqrt.f32 %v140182_v24 (stack67)
        %v61801_v34 = vshrl.u32 %v61800_v56, 1 (stack51)
        %v62209_v25 = vadd.s32 %v62206_v55, %v121564_v0 (stack40)
        %v63428_v43 = vor.u32 %v63427_v20, %v63426_v8 (stack47)
        %v61051_v8 = vmul.f32 %v61047_v22, %v139985_v54 (stack54)
        %vm61388_vm10 = vcmp.lt.f32.partialorder %v140182_v24, 5.0 (stack68)
        %v63009_v41 = vshll.u32 %v63003_v29, 17 (stack45)
        %v63010_v61 = vshrl.u32 %v63003_v29, 15 (stack46)
        %vm60903_vm11 = vcmp.eq.f32.partialorder %v60900_v45, 1.0 (stack68)
        %v62602_v54 = vor.u32 %v62601_v31, %v62600_v42 (stack47)
        %v61055_v45 = vsel /*vm=*/%vm60903_vm11, /*on_true_vy=*/%v60908_v30, /*on_false_vx=*/%v61051_v8 (stack44)
        %v140194_v27 = vadd.f32 -2.5, %v140182_v24 (stack53)
        %v62201_v40 = vadd.s32 %v62197_v40, %v121569_v1 (stack40)
        %v140199_v44 = vadd.s32 %v140156_v46, %v122657_v58 (stack40)
        %v61059_v9 = vmul.f32 1.4140625, %v61055_v45 (stack54)
        %v140204_v50 = vsel /*vm=*/%vm61388_vm10, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v140209_v60 = vsel /*vm=*/%vm61388_vm10, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v61802_v23 = vor.u32 16256, %v61801_v34 (stack47)
        %v62213_v29 = vadd.s32 4, %v62209_v25 (stack40)
        %v62603_v56 = vxor.u32 %v62602_v54, %v62598_v12 (stack48)
        %v63011_v55 = vor.u32 %v63010_v61, %v63009_v41 (stack47)
        %v63429_v20 = vxor.u32 %v63428_v43, %v63424_v10 (stack48)
        %v61062_v52 = vpack.c.bf16 %v157387_v11, %v61059_v9 (stack81)
        %v61803_v21 = vand.u32.u16 65535, %v61802_v23 (stack52)
        %vm63885_vm12 = vcmp.lt.u32.totalorder %v140156_v46, %v122651_v47 (stack43)
        %v157461_v6 = vld [vmem:[#allocation101_spill] sm:$0xff] (stack84)
        %v140216_v26 = vadd.s32 %v157461_v6, %v157068_v28 (stack40)
        %vm61433_vm13 = vcmp.eq.f32.partialorder %v140182_v24, inf (stack70)
        %v62217_v42 = vadd.s32 %v62213_v29, %v62201_v40 (stack40)
        %v62219_v31 = vshll.u32 %v62213_v29, 13 (stack45)
        %v62220_v30 = vshrl.u32 %v62213_v29, 19 (stack46)
        %v62606_v12 = vadd.s32 %v62603_v56, %v62598_v12 (stack40)
        %120071 = vst [vmem:[%s123356_s30 + $0xc0] sm:$0xf] /*vst_source=*/%v61062_v52 (stack83)
        %v120074_v22 = vadd.low.f32.bf16 -1.0, %v61803_v21 (stack53)
        %v62608_v34 = vshll.u32 %v62603_v56, 26 (stack45)
        %v62609_v25 = vshrl.u32 %v62603_v56, 6 (stack46)
        %v63012_v43 = vxor.u32 %v63011_v55, %v63007_v32 (stack48)
        %v62221_v8 = vor.u32 %v62220_v30, %v62219_v31 (stack47)
        %v63432_v10 = vadd.s32 %v63429_v20, %v63424_v10 (stack40)
        %v63434_v41 = vshll.u32 %v63429_v20, 15 (stack45)
        %v63435_v61 = vshrl.u32 %v63429_v20, 17 (stack46)
        %v61812_v54 = vmul.f32 2.0, %v120074_v22 (stack54)
        %v62610_v45 = vor.u32 %v62609_v25, %v62608_v34 (stack47)
        %v63015_v32 = vadd.s32 %v63012_v43, %v63007_v32 (stack40)
        %v63017_v40 = vshll.u32 %v63012_v43, 29 (stack45)
        %v140223_v9 = vsel /*vm=*/%vm61388_vm10, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v62222_v23 = vxor.u32 %v62221_v8, %v62217_v42 (stack48)
        %v63018_v29 = vshrl.u32 %v63012_v43, 3 (stack46)
        %v63436_v56 = vor.u32 %v63435_v61, %v63434_v41 (stack47)
        %v61436_v55 = vand.u32 2147483648, %v140182_v24 (stack72)
        %v61816_v20 = vadd.f32 -0.99609375, %v61812_v54 (stack53)
        %v62611_v52 = vxor.u32 %v62610_v45, %v62606_v12 (stack48)
        %v140228_v21 = vadd.s32 %v157458_v53, %v157070_v38 (stack40)
        %v120956_v31 = vpop.eup %120955 (stack73)
        %v62225_v42 = vadd.s32 %v62222_v23, %v62217_v42 (stack40)
        %v62227_v30 = vshll.u32 %v62222_v23, 15 (stack45)
        %v62228_v22 = vshrl.u32 %v62222_v23, 17 (stack46)
        %v63019_v34 = vor.u32 %v63018_v29, %v63017_v40 (stack47)
        %v61432_v25 = vmul.f32 %v120956_v31, %v140182_v24 (stack74)
        %v140231_v43 = vmax.f32 %v61816_v20, -0.99609375 (stack55)
        %v62614_v12 = vadd.s32 %v62611_v52, %v62606_v12 (stack40)
        %v62620_v8 = vshll.u32 %v62611_v52, 6 (stack45)
        %v62229_v41 = vor.u32 %v62228_v22, %v62227_v30 (stack47)
        %v62621_v61 = vshrl.u32 %v62611_v52, 26 (stack46)
        %v63020_v54 = vxor.u32 %v63019_v34, %v63015_v32 (stack48)
        %v63437_v45 = vxor.u32 %v63436_v56, %v63432_v10 (stack48)
        %v61417_v40 = vsel /*vm=*/%vm61388_vm10, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v61434_v23 = vsel /*vm=*/%vm61433_vm13, /*on_true_vy=*/%v140182_v24, /*on_false_vx=*/%v61432_v25 (stack75)
        %vm61435_vm14 = vcmp.eq.f32.partialorder %v140182_v24, 0.0 (stack71)
        %v61832_v29 = vxor.u32 2147483648, %v140231_v43 (stack56)
        %v61421_v56 = vsel /*vm=*/%vm61388_vm10, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v61437_v55 = vsel /*vm=*/%vm61435_vm14, /*on_true_vy=*/%v61436_v55, /*on_false_vx=*/%v61434_v23 (stack76)
        %v62230_v20 = vxor.u32 %v62229_v41, %v62225_v42 (stack48)
        %v62622_v52 = vor.u32 %v62621_v61, %v62620_v8 (stack47)
        %v61425_v31 = vsel /*vm=*/%vm61388_vm10, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v61440_v30 = vadd.f32 -3.0, %v61437_v55 (stack53)
        %v140248_v22 = vmul.f32 %v61832_v29, %v140231_v43 (stack54)
        %v63023_v32 = vadd.s32 %v63020_v54, %v63015_v32 (stack40)
        %v62233_v42 = vadd.s32 %v62230_v20, %v62225_v42 (stack40)
        %v62235_v34 = vshll.u32 %v62230_v20, 26 (stack45)
        %v62236_v25 = vshrl.u32 %v62230_v20, 6 (stack46)
        %v62623_v8 = vxor.u32 %v62622_v52, %v62614_v12 (stack48)
        %v140253_v27 = vsel /*vm=*/%vm61388_vm10, /*on_true_vy=*/%v140194_v27, /*on_false_vx=*/%v61440_v30 (stack44)
        %v61837_v41 = vadd.f32 1.0, %v140248_v22 (stack57)
        %v63894_v61 = vadd.s32 1, %v140216_v26 (stack40)
        %v140259_v23 = vadd.s32 %v140199_v44, %v121569_v1 (stack40)
        %v61448_v29 = vmul.f32 %v140253_v27, %v61425_v31 (stack54)
        %v62237_v55 = vor.u32 %v62236_v25, %v62235_v34 (stack47)
        %v62626_v20 = vadd.s32 %v62623_v8, %v121569_v1 (stack40)
        %v63025_v52 = vshll.u32 %v63020_v54, 16 (stack45)
        %120957 = vlog2.f32 %v61837_v41 (stack58)
        %v61840_v31 = vmul.f32 -0.5, %v140248_v22 (stack59)
        %v62618_v12 = vadd.s32 %v62614_v12, %v121574_v2 (stack40)
        %v63026_v54 = vshrl.u32 %v63020_v54, 16 (stack46)
        %v61452_v56 = vadd.f32 %v61448_v29, %v61421_v56 (stack53)
        %v62238_v30 = vxor.u32 %v62237_v55, %v62233_v42 (stack48)
        %v62630_v34 = vadd.s32 3, %v62626_v20 (stack40)
        %v63440_v10 = vadd.s32 %v63437_v45, %v63432_v10 (stack40)
        %vm63880_vm15 = vcmp.lt.u32.totalorder %v140199_v44, %v140156_v46 (stack43)
        %v61843_v25 = vand.u32 2147483647, %v140248_v22 (stack60)
        %v63027_v8 = vor.u32 %v63026_v54, %v63025_v52 (stack47)
        %v63442_v41 = vshll.u32 %v63437_v45, 26 (stack45)
        %v63443_v45 = vshrl.u32 %v63437_v45, 6 (stack46)
        %v61456_v29 = vmul.f32 %v61452_v56, %v140253_v27 (stack54)
        %v62241_v42 = vadd.s32 %v62238_v30, %v62233_v42 (stack40)
        %v62247_v55 = vshll.u32 %v62238_v30, 6 (stack45)
        %v62248_v20 = vshrl.u32 %v62238_v30, 26 (stack46)
        %v62634_v52 = vadd.s32 %v62630_v34, %v62618_v12 (stack40)
        %v62636_v12 = vshll.u32 %v62630_v34, 17 (stack45)
        %v62637_v54 = vshrl.u32 %v62630_v34, 15 (stack46)
        %v63028_v56 = vxor.u32 %v63027_v8, %v63023_v32 (stack48)
        %v61460_v40 = vadd.f32 %v61456_v29, %v61417_v40 (stack53)
        %v61841_v31 = vadd.f32 1.0, %v61840_v31 (stack61)
        %v62249_v30 = vor.u32 %v62248_v20, %v62247_v55 (stack47)
        %v63444_v34 = vor.u32 %v63443_v45, %v63442_v41 (stack47)
        %v62638_v8 = vor.u32 %v62637_v54, %v62636_v12 (stack47)
        %v63031_v32 = vadd.s32 %v63028_v56, %v63023_v32 (stack40)
        %v63037_v41 = vshll.u32 %v63028_v56, 24 (stack45)
        %v63038_v45 = vshrl.u32 %v63028_v56, 8 (stack46)
        %v61464_v29 = vmul.f32 %v61460_v40, %v140253_v27 (stack54)
        %v62250_v55 = vxor.u32 %v62249_v30, %v62241_v42 (stack48)
        %v63445_v20 = vxor.u32 %v63444_v34, %v63440_v10 (stack48)
        %v63898_v26 = vsel /*vm=*/%vm63885_vm12, /*on_true_vy=*/%v63894_v61, /*on_false_vx=*/%v140216_v26 (stack44)
        %vm140274_vm0 = vcmp.lt.f32.partialorder %v61843_v25, 0.0004427343 (stack62)
        %v62639_v25 = vxor.u32 %v62638_v8, %v62634_v52 (stack48)
        %v63039_v12 = vor.u32 %v63038_v45, %v63037_v41 (stack47)
        %v63902_v54 = vadd.s32 1, %v63898_v26 (stack40)
        %v61468_v9 = vadd.f32 %v61464_v29, %v140223_v9 (stack53)
        %v62253_v56 = vadd.s32 %v62250_v55, %v121574_v2 (stack40)
        %v63448_v10 = vadd.s32 %v63445_v20, %v63440_v10 (stack40)
        %v63454_v40 = vshll.u32 %v63445_v20, 6 (stack45)
        %v62642_v52 = vadd.s32 %v62639_v25, %v62634_v52 (stack40)
        %v62644_v30 = vshll.u32 %v62639_v25, 29 (stack45)
        %v62645_v34 = vshrl.u32 %v62639_v25, 3 (stack46)
        %v63040_v8 = vxor.u32 %v63039_v12, %v63031_v32 (stack48)
        %v61472_v41 = vmul.f32 %v61468_v9, %v140253_v27 (stack54)
        %v62245_v42 = vadd.s32 %v62241_v42, %v121564_v0 (stack40)
        %v62257_v45 = vadd.s32 5, %v62253_v56 (stack40)
        %v63455_v29 = vshrl.u32 %v63445_v20, 26 (stack46)
        %v61842_v22 = vmul.f32 %v61841_v31, %v140248_v22 (stack63)
        %v62646_v31 = vor.u32 %v62645_v34, %v62644_v30 (stack47)
        %v63043_v55 = vadd.s32 %v63040_v8, %v121574_v2 (stack40)
        %v63906_v46 = vsel /*vm=*/%vm63880_vm15, /*on_true_vy=*/%v63902_v54, /*on_false_vx=*/%v63898_v26 (stack44)
        %v120958_v44 = vpop.eup %120957 (stack64)
        %v61476_v60 = vadd.f32 %v61472_v41, %v140209_v60 (stack53)
        %v62259_v20 = vxor.u32 %v62257_v45, %v62245_v42 (stack48)
        %v63456_v26 = vor.u32 %v63455_v29, %v63454_v40 (stack47)
        %v63911_v25 = vadd.s32 %v63906_v46, %v121574_v2 (stack40)
        %v61839_v12 = vmul.f32 0.6931472, %v120958_v44 (stack65)
        %v62647_v54 = vxor.u32 %v62646_v31, %v62642_v52 (stack48)
        %v63035_v32 = vadd.s32 %v63031_v32, %v121564_v0 (stack40)
        %v63047_v9 = vadd.s32 2, %v63043_v55 (stack40)
        %v61480_v56 = vmul.f32 %v61476_v60, %v140253_v27 (stack54)
        %v62260_v40 = vand.u32.u8 255, %v62259_v20 (stack49)
        %v63457_v30 = vxor.u32 %v63456_v26, %v63448_v10 (stack48)
        %v63919_v34 = vadd.s32 %v140259_v23, %v63911_v25 (stack40)
        %v61845_v61 = vsel /*vm=*/%vm140274_vm0, /*on_true_vy=*/%v61842_v22, /*on_false_vx=*/%v61839_v12 (stack66)
        %v62650_v52 = vadd.s32 %v62647_v54, %v62642_v52 (stack40)
        %v62652_v8 = vshll.u32 %v62647_v54, 16 (stack45)
        %v62653_v41 = vshrl.u32 %v62647_v54, 16 (stack46)
        %v61484_v50 = vadd.f32 %v61480_v56, %v140204_v50 (stack53)
        %v140295_v42 = vxor.u32 2147483648, %v61845_v61 (stack56)
        %v63051_v45 = vadd.s32 %v63047_v9, %v63035_v32 (stack40)
        %v62654_v29 = vor.u32 %v62653_v41, %v62652_v8 (stack47)
        %v61361_v22 = vand.u32 2147483647, %v140109_v7 (stack77)
        %v61401_v31 = vsel /*vm=*/%vm61388_vm10, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v61488_v55 = vmul.f32 %v61484_v50, %v140253_v27 (stack54)
        %120959 = vrsqrt.f32 %v140295_v42 (stack67)
        %v62261_v46 = vand.u32 65535, %v62260_v40 (stack50)
        %v62655_v44 = vxor.u32 %v62654_v29, %v62650_v52 (stack48)
        %v63921_v60 = vshll.u32 %v140259_v23, 13 (stack45)
        %v63922_v23 = vshrl.u32 %v140259_v23, 19 (stack46)
        %v61492_v20 = vadd.f32 %v61488_v55, %v61401_v31 (stack53)
        %v63053_v26 = vshll.u32 %v63047_v9, 13 (stack45)
        %v63054_v25 = vshrl.u32 %v63047_v9, 19 (stack46)
        %v63460_v12 = vadd.s32 %v63457_v30, %v121564_v0 (stack40)
        %v61369_v54 = vmul.f32 inf, %v140109_v7 (stack54)
        %v61393_v32 = vsel /*vm=*/%vm61388_vm10, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v61397_v24 = vsel /*vm=*/%vm61388_vm10, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v62658_v9 = vadd.s32 %v62655_v44, %v62650_v52 (stack40)
        %v61496_v56 = vmul.f32 %v61492_v20, %v140253_v27 (stack54)
        %v61822_v40 = vand.u32 2147483647, %v140231_v43 (stack77)
        %v140316_v30 = vmul.f32 inf, %v140231_v43 (stack54)
        %v63452_v10 = vadd.s32 %v63448_v10, %v121569_v1 (stack40)
        %vm140319_vm1 = vcmp.eq.f32.partialorder %v61361_v22, 1.0 (stack68)
        %v140324_v52 = vadd.f32 -2.5, %v140295_v42 (stack53)
        %v62262_v8 = vshrl.u32 %v62261_v46, 1 (stack51)
        %v62664_v41 = vshll.u32 %v62655_v44, 24 (stack45)
        %v62665_v50 = vshrl.u32 %v62655_v44, 8 (stack46)
        %v61500_v29 = vadd.f32 %v61496_v56, %v61397_v24 (stack53)
        %v63055_v22 = vor.u32 %v63054_v25, %v63053_v26 (stack47)
        %v63464_v31 = vadd.s32 1, %v63460_v12 (stack40)
        %v63923_v55 = vor.u32 %v63922_v23, %v63921_v60 (stack47)
        %vm61894_vm2 = vcmp.eq.f32.partialorder %v140295_v42, inf (stack70)
        %v61897_v46 = vand.u32 2147483648, %v140295_v42 (stack72)
        %v62263_v44 = vor.u32 16256, %v62262_v8 (stack47)
        %v62666_v60 = vor.u32 %v62665_v50, %v62664_v41 (stack47)
        %vm64346_vm3 = vcmp.lt.u32.totalorder %v140228_v21, %v157070_v38 (stack43)
        %v61504_v27 = vmul.f32 %v61500_v29, %v140253_v27 (stack54)
        %vm61849_vm4 = vcmp.lt.f32.partialorder %v140295_v42, 5.0 (stack68)
        %vm61896_vm5 = vcmp.eq.f32.partialorder %v140295_v42, 0.0 (stack71)
        %v63056_v23 = vxor.u32 %v63055_v22, %v63051_v45 (stack48)
        %v63468_v20 = vadd.s32 %v63464_v31, %v63452_v10 (stack40)
        %v63470_v26 = vshll.u32 %v63464_v31, 17 (stack45)
        %v62264_v25 = vand.u32.u16 65535, %v62263_v44 (stack52)
        %v62667_v12 = vxor.u32 %v62666_v60, %v62658_v9 (stack48)
        %v63471_v24 = vshrl.u32 %v63464_v31, 15 (stack46)
        %v63924_v56 = vxor.u32 %v63923_v55, %v63919_v34 (stack48)
        %v61508_v32 = vadd.f32 %v61504_v27, %v61393_v32 (stack53)
        %v63059_v45 = vadd.s32 %v63056_v23, %v63051_v45 (stack40)
        %v63061_v10 = vshll.u32 %v63056_v23, 15 (stack45)
        %v63062_v8 = vshrl.u32 %v63056_v23, 17 (stack46)
        %v120076_v41 = vadd.low.f32.bf16 -1.0, %v62264_v25 (stack53)
        %v62670_v50 = vadd.s32 %v62667_v12, %v121564_v0 (stack40)
        %v63472_v29 = vor.u32 %v63471_v24, %v63470_v26 (stack47)
        %v140334_v34 = vadd.s32 %v63924_v56, %v63919_v34 (stack40)
        %v61512_v7 = vmul.f32 %v61508_v32, %v140109_v7 (stack54)
        %v63063_v22 = vor.u32 %v63062_v8, %v63061_v10 (stack47)
        %v63929_v31 = vshll.u32 %v63924_v56, 15 (stack45)
        %v63930_v55 = vshrl.u32 %v63924_v56, 17 (stack46)
        %v120960_v44 = vpop.eup %120959 (stack73)
        %v62273_v60 = vmul.f32 2.0, %v120076_v41 (stack54)
        %v62662_v9 = vadd.s32 %v62658_v9, %v121569_v1 (stack40)
        %v62674_v27 = vadd.s32 4, %v62670_v50 (stack40)
        %v63473_v23 = vxor.u32 %v63472_v29, %v63468_v20 (stack48)
        %v61516_v54 = vsel /*vm=*/%vm140319_vm1, /*on_true_vy=*/%v61369_v54, /*on_false_vx=*/%v61512_v7 (stack44)
        %v61893_v61 = vmul.f32 %v120960_v44, %v140295_v42 (stack74)
        %v63064_v26 = vxor.u32 %v63063_v22, %v63059_v45 (stack48)
        %v63931_v25 = vor.u32 %v63930_v55, %v63929_v31 (stack47)
        %v61520_v12 = vmul.f32 1.4140625, %v61516_v54 (stack54)
        %v62277_v24 = vadd.f32 -0.99609375, %v62273_v60 (stack53)
        %v62678_v56 = vadd.s32 %v62674_v27, %v62662_v9 (stack40)
        %v62680_v32 = vshll.u32 %v62674_v27, 13 (stack45)
        %v61895_v10 = vsel /*vm=*/%vm61894_vm2, /*on_true_vy=*/%v140295_v42, /*on_false_vx=*/%v61893_v61 (stack75)
        %v62681_v8 = vshrl.u32 %v62674_v27, 19 (stack46)
        %v63067_v45 = vadd.s32 %v63064_v26, %v63059_v45 (stack40)
        %v63069_v41 = vshll.u32 %v63064_v26, 26 (stack45)
        %v61523_v50 = vpack.c.bf16 %v157387_v11, %v61520_v12 (stack81)
        %v61898_v46 = vsel /*vm=*/%vm61896_vm5, /*on_true_vy=*/%v61897_v46, /*on_false_vx=*/%v61895_v10 (stack76)
        %v140347_v29 = vmax.f32 %v62277_v24, -0.99609375 (stack55)
        %v63070_v7 = vshrl.u32 %v63064_v26, 6 (stack46)
        %v61901_v22 = vadd.f32 -3.0, %v61898_v46 (stack53)
        %v62682_v31 = vor.u32 %v62681_v8, %v62680_v32 (stack47)
        %v63476_v20 = vadd.s32 %v63473_v23, %v63468_v20 (stack40)
        %v63478_v55 = vshll.u32 %v63473_v23, 29 (stack45)
        %120073 = vst [vmem:[%s123356_s30 + $0x140] sm:$0xf] /*vst_source=*/%v61523_v50 (stack83)
        %v140353_v44 = vsel /*vm=*/%vm61849_vm4, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v61886_v60 = vsel /*vm=*/%vm61849_vm4, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v62293_v9 = vxor.u32 2147483648, %v140347_v29 (stack56)
        %v63071_v27 = vor.u32 %v63070_v7, %v63069_v41 (stack47)
        %v140362_v52 = vsel /*vm=*/%vm61849_vm4, /*on_true_vy=*/%v140324_v52, /*on_false_vx=*/%v61901_v22 (stack44)
        %v62683_v54 = vxor.u32 %v62682_v31, %v62678_v56 (stack48)
        %v63479_v23 = vshrl.u32 %v63473_v23, 3 (stack46)
        %v63932_v61 = vxor.u32 %v63931_v25, %v140334_v34 (stack48)
        %v61882_v26 = vsel /*vm=*/%vm61849_vm4, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v61909_v25 = vmul.f32 %v140362_v52, %v61886_v60 (stack54)
        %v140370_v12 = vmul.f32 %v62293_v9, %v140347_v29 (stack54)
        %v63072_v24 = vxor.u32 %v63071_v27, %v63067_v45 (stack48)
        %v62686_v56 = vadd.s32 %v62683_v54, %v62678_v56 (stack40)
        %v62688_v32 = vshll.u32 %v62683_v54, 15 (stack45)
        %v62689_v10 = vshrl.u32 %v62683_v54, 17 (stack46)
        %v63480_v8 = vor.u32 %v63479_v23, %v63478_v55 (stack47)
        %v140375_v41 = vsel /*vm=*/%vm61849_vm4, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v140380_v50 = vsel /*vm=*/%vm61849_vm4, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v61913_v46 = vadd.f32 %v61909_v25, %v61882_v26 (stack53)
        %v62298_v7 = vadd.f32 1.0, %v140370_v12 (stack57)
        %v62690_v22 = vor.u32 %v62689_v10, %v62688_v32 (stack47)
        %v63075_v45 = vadd.s32 %v63072_v24, %v63067_v45 (stack40)
        %v63081_v31 = vshll.u32 %v63072_v24, 6 (stack45)
        %v63082_v55 = vshrl.u32 %v63072_v24, 26 (stack46)
        %v61870_v60 = vsel /*vm=*/%vm61849_vm4, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v61874_v9 = vsel /*vm=*/%vm61849_vm4, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v61917_v27 = vmul.f32 %v61913_v46, %v140362_v52 (stack54)
        %120961 = vlog2.f32 %v62298_v7 (stack58)
        %v61878_v54 = vsel /*vm=*/%vm61849_vm4, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v62691_v23 = vxor.u32 %v62690_v22, %v62686_v56 (stack48)
        %v63083_v26 = vor.u32 %v63082_v55, %v63081_v31 (stack47)
        %v63481_v25 = vxor.u32 %v63480_v8, %v63476_v20 (stack48)
        %v61921_v24 = vadd.f32 %v61917_v27, %v61878_v54 (stack53)
        %v62301_v32 = vmul.f32 -0.5, %v140370_v12 (stack59)
        %v63935_v34 = vadd.s32 %v63932_v61, %v140334_v34 (stack40)
        %v63937_v10 = vshll.u32 %v63932_v61, 26 (stack45)
        %v62694_v56 = vadd.s32 %v62691_v23, %v62686_v56 (stack40)
        %v62696_v8 = vshll.u32 %v62691_v23, 26 (stack45)
        %v62697_v46 = vshrl.u32 %v62691_v23, 6 (stack46)
        %v63084_v7 = vxor.u32 %v63083_v26, %v63075_v45 (stack48)
        %v61925_v22 = vmul.f32 %v61921_v24, %v140362_v52 (stack54)
        %v63484_v20 = vadd.s32 %v63481_v25, %v63476_v20 (stack40)
        %v63486_v31 = vshll.u32 %v63481_v25, 16 (stack45)
        %v63487_v55 = vshrl.u32 %v63481_v25, 16 (stack46)
        %v62698_v27 = vor.u32 %v62697_v46, %v62696_v8 (stack47)
        %v63087_v54 = vadd.s32 %v63084_v7, %v121569_v1 (stack40)
        %v63938_v61 = vshrl.u32 %v63932_v61, 6 (stack46)
        %v64351_v23 = vadd.s32 %v157461_v6, %v157076_v35 (stack40)
        %v61929_v9 = vadd.f32 %v61925_v22, %v61874_v9 (stack53)
        %v63488_v26 = vor.u32 %v63487_v55, %v63486_v31 (stack47)
        %v140401_v25 = vadd.s32 %v140228_v21, %v122657_v58 (stack40)
        %v140405_v24 = vadd.s32 %v157458_v53, %v157077_v51 (stack40)
        %v62304_v8 = vand.u32 2147483647, %v140370_v12 (stack60)
        %v62699_v46 = vxor.u32 %v62698_v27, %v62694_v56 (stack48)
        %v63079_v45 = vadd.s32 %v63075_v45, %v121574_v2 (stack40)
        %v63091_v7 = vadd.s32 3, %v63087_v54 (stack40)
        %v61933_v22 = vmul.f32 %v61929_v9, %v140362_v52 (stack54)
        %v62302_v32 = vadd.f32 1.0, %v62301_v32 (stack61)
        %v63489_v31 = vxor.u32 %v63488_v26, %v63484_v20 (stack48)
        %v63939_v10 = vor.u32 %v63938_v61, %v63937_v10 (stack47)
        %v62702_v56 = vadd.s32 %v62699_v46, %v62694_v56 (stack40)
        %v62708_v55 = vshll.u32 %v62699_v46, 6 (stack45)
        %v62709_v27 = vshrl.u32 %v62699_v46, 26 (stack46)
        %v63095_v54 = vadd.s32 %v63091_v7, %v63079_v45 (stack40)
        %v61937_v60 = vadd.f32 %v61933_v22, %v61870_v60 (stack53)
        %v63097_v61 = vshll.u32 %v63091_v7, 17 (stack45)
        %v63098_v9 = vshrl.u32 %v63091_v7, 15 (stack46)
        %v63492_v20 = vadd.s32 %v63489_v31, %v63484_v20 (stack40)
        %v62710_v26 = vor.u32 %v62709_v27, %v62708_v55 (stack47)
        %v63498_v46 = vshll.u32 %v63489_v31, 24 (stack45)
        %v63499_v45 = vshrl.u32 %v63489_v31, 8 (stack46)
        %v64355_v7 = vadd.s32 1, %v64351_v23 (stack40)
        %v61941_v22 = vmul.f32 %v61937_v60, %v140362_v52 (stack54)
        %v62303_v12 = vmul.f32 %v62302_v32, %v140370_v12 (stack63)
        %v63099_v32 = vor.u32 %v63098_v9, %v63097_v61 (stack47)
        %v63940_v31 = vxor.u32 %v63939_v10, %v63935_v34 (stack48)
        %v120962_v10 = vpop.eup %120961 (stack64)
        %v62711_v55 = vxor.u32 %v62710_v26, %v62702_v56 (stack48)
        %v63500_v27 = vor.u32 %v63499_v45, %v63498_v46 (stack47)
        %v64359_v23 = vsel /*vm=*/%vm64346_vm3, /*on_true_vy=*/%v64355_v7, /*on_false_vx=*/%v64351_v23 (stack44)
        %v64376_v60 = vadd.s32 %v140401_v25, %v121569_v1 (stack40)
        %v61945_v50 = vadd.f32 %v61941_v22, %v140380_v50 (stack53)
        %v62300_v61 = vmul.f32 0.6931472, %v120962_v10 (stack65)
        %v63100_v9 = vxor.u32 %v63099_v32, %v63095_v54 (stack48)
        %v63943_v34 = vadd.s32 %v63940_v31, %v63935_v34 (stack40)
        %vm62305_vm6 = vcmp.lt.f32.partialorder %v62304_v8, 0.0004427343 (stack62)
        %v62714_v8 = vadd.s32 %v62711_v55, %v121574_v2 (stack40)
        %v63501_v26 = vxor.u32 %v63500_v27, %v63492_v20 (stack48)
        %v63949_v46 = vshll.u32 %v63940_v31, 6 (stack45)
        %v61949_v45 = vmul.f32 %v61945_v50, %v140362_v52 (stack54)
        %v62306_v7 = vsel /*vm=*/%vm62305_vm6, /*on_true_vy=*/%v62303_v12, /*on_false_vx=*/%v62300_v61 (stack66)
        %v63103_v54 = vadd.s32 %v63100_v9, %v63095_v54 (stack40)
        %v63950_v22 = vshrl.u32 %v63940_v31, 26 (stack46)
        %v140420_v12 = vxor.u32 2147483648, %v62306_v7 (stack56)
        %v62718_v32 = vadd.s32 5, %v62714_v8 (stack40)
        %v64382_v31 = vshll.u32 %v64376_v60, 13 (stack45)
        %v64383_v10 = vshrl.u32 %v64376_v60, 19 (stack46)
        %v61858_v42 = vsel /*vm=*/%vm61849_vm4, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v61953_v41 = vadd.f32 %v61949_v45, %v140375_v41 (stack53)
        %v62706_v56 = vadd.s32 %v62702_v56, %v121564_v0 (stack40)
        %vm64341_vm7 = vcmp.lt.u32.totalorder %v140401_v25, %v140228_v21 (stack43)
        %vm62310_vm8 = vcmp.lt.f32.partialorder %v140420_v12, 5.0 (stack68)
        %120963 = vrsqrt.f32 %v140420_v12 (stack67)
        %v63105_v55 = vshll.u32 %v63100_v9, 29 (stack45)
        %v63106_v27 = vshrl.u32 %v63100_v9, 3 (stack46)
        %v61957_v50 = vmul.f32 %v61953_v41, %v140362_v52 (stack54)
        %v63504_v61 = vadd.s32 %v63501_v26, %v121574_v2 (stack40)
        %v63951_v9 = vor.u32 %v63950_v22, %v63949_v46 (stack47)
        %v64363_v8 = vadd.s32 1, %v64359_v23 (stack40)
        %vm140435_vm9 = vcmp.eq.f32.partialorder %v61822_v40, 1.0 (stack68)
        %v62283_v26 = vand.u32 2147483647, %v140347_v29 (stack77)
        %v62720_v46 = vxor.u32 %v62718_v32, %v62706_v56 (stack48)
        %v63496_v20 = vadd.s32 %v63492_v20, %v121564_v0 (stack40)
        %v64384_v45 = vor.u32 %v64383_v10, %v64382_v31 (stack47)
        %v61961_v7 = vadd.f32 %v61957_v50, %v61858_v42 (stack53)
        %v140444_v22 = vsel /*vm=*/%vm62310_vm8, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v140447_v32 = vadd.f32 -2.5, %v140420_v12 (stack53)
        %v63947_v31 = vadd.s32 %v63943_v34, %v121569_v1 (stack40)
        %v140453_v10 = vsel /*vm=*/%vm62310_vm8, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v140458_v42 = vsel /*vm=*/%vm62310_vm8, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v62721_v41 = vand.u32.u8 255, %v62720_v46 (stack49)
        %v63107_v56 = vor.u32 %v63106_v27, %v63105_v55 (stack47)
        %v61965_v52 = vmul.f32 %v61961_v7, %v140362_v52 (stack54)
        %v63508_v55 = vadd.s32 2, %v63504_v61 (stack40)
        %v63952_v34 = vxor.u32 %v63951_v9, %v63943_v34 (stack48)
        %v64367_v21 = vsel /*vm=*/%vm64341_vm7, /*on_true_vy=*/%v64363_v8, /*on_false_vx=*/%v64359_v23 (stack44)
        %v140467_v25 = vsel /*vm=*/%vm62310_vm8, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v62722_v23 = vand.u32 65535, %v62721_v41 (stack50)
        %v63108_v27 = vxor.u32 %v63107_v56, %v63103_v54 (stack48)
        %v64372_v50 = vadd.s32 %v64367_v21, %v121574_v2 (stack40)
        %v61969_v44 = vadd.f32 %v61965_v52, %v140353_v44 (stack53)
        %vm62355_vm10 = vcmp.eq.f32.partialorder %v140420_v12, inf (stack70)
        %v63512_v61 = vadd.s32 %v63508_v55, %v63496_v20 (stack40)
        %v63514_v9 = vshll.u32 %v63508_v55, 13 (stack45)
        %v63515_v8 = vshrl.u32 %v63508_v55, 19 (stack46)
        %v62723_v46 = vshrl.u32 %v62722_v23, 1 (stack51)
        %v63111_v54 = vadd.s32 %v63108_v27, %v63103_v54 (stack40)
        %v63113_v20 = vshll.u32 %v63108_v27, 16 (stack45)
        %v63114_v7 = vshrl.u32 %v63108_v27, 16 (stack46)
        %v61973_v43 = vmul.f32 %v61969_v44, %v140231_v43 (stack54)
        %v63516_v41 = vor.u32 %v63515_v8, %v63514_v9 (stack47)
        %v63955_v56 = vadd.s32 %v63952_v34, %v121564_v0 (stack40)
        %v64380_v60 = vadd.s32 %v64376_v60, %v64372_v50 (stack40)
        %v62358_v52 = vand.u32 2147483648, %v140420_v12 (stack72)
        %v62724_v55 = vor.u32 16256, %v62723_v46 (stack47)
        %v63115_v34 = vor.u32 %v63114_v7, %v63113_v20 (stack47)
        %vm64807_vm11 = vcmp.lt.u32.totalorder %v140405_v24, %v157077_v51 (stack43)
        %v61977_v30 = vsel /*vm=*/%vm140435_vm9, /*on_true_vy=*/%v140316_v30, /*on_false_vx=*/%v61973_v43 (stack44)
        %v63517_v40 = vxor.u32 %v63516_v41, %v63512_v61 (stack48)
        %v63959_v21 = vadd.s32 1, %v63955_v56 (stack40)
        %v140480_v45 = vxor.u32 %v64384_v45, %v64380_v60 (stack48)
        %v61981_v23 = vmul.f32 1.4140625, %v61977_v30 (stack54)
        %v62725_v27 = vand.u32.u16 65535, %v62724_v55 (stack52)
        %v63116_v50 = vxor.u32 %v63115_v34, %v63111_v54 (stack48)
        %v140484_v44 = vadd.s32 %v157461_v6, %v157078_v48 (stack40)
        %v120964_v9 = vpop.eup %120963 (stack73)
        %v63520_v61 = vadd.s32 %v63517_v40, %v63512_v61 (stack40)
        %v63522_v8 = vshll.u32 %v63517_v40, 15 (stack45)
        %v63523_v46 = vshrl.u32 %v63517_v40, 17 (stack46)
        %v63963_v31 = vadd.s32 %v63959_v21, %v63947_v31 (stack40)
        %v61984_v20 = vpack.c.bf16 %v157387_v11, %v61981_v23 (stack81)
        %v62354_v7 = vmul.f32 %v120964_v9, %v140420_v12 (stack74)
        %v120078_v43 = vadd.low.f32.bf16 -1.0, %v62725_v27 (stack53)
        %v63119_v54 = vadd.s32 %v63116_v50, %v63111_v54 (stack40)
        %v63125_v41 = vshll.u32 %v63116_v50, 24 (stack45)
        %v63126_v56 = vshrl.u32 %v63116_v50, 8 (stack46)
        %v63524_v55 = vor.u32 %v63523_v46, %v63522_v8 (stack47)
        %v63965_v34 = vshll.u32 %v63959_v21, 17 (stack45)
        %120075 = vst [vmem:[%s123356_s30 + $0x1c0] sm:$0xf] /*vst_source=*/%v61984_v20 (stack83)
        %v62356_v30 = vsel /*vm=*/%vm62355_vm10, /*on_true_vy=*/%v140420_v12, /*on_false_vx=*/%v62354_v7 (stack75)
        %vm62357_vm12 = vcmp.eq.f32.partialorder %v140420_v12, 0.0 (stack71)
        %v62734_v40 = vmul.f32 2.0, %v120078_v43 (stack54)
        %v63966_v21 = vshrl.u32 %v63959_v21, 15 (stack46)
        %v62359_v52 = vsel /*vm=*/%vm62357_vm12, /*on_true_vy=*/%v62358_v52, /*on_false_vx=*/%v62356_v30 (stack76)
        %v63127_v23 = vor.u32 %v63126_v56, %v63125_v41 (stack47)
        %v63525_v27 = vxor.u32 %v63524_v55, %v63520_v61 (stack48)
        %v64388_v60 = vadd.s32 %v140480_v45, %v64380_v60 (stack40)
        %v62339_v50 = vsel /*vm=*/%vm62310_vm8, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v62362_v9 = vadd.f32 -3.0, %v62359_v52 (stack53)
        %v62738_v8 = vadd.f32 -0.99609375, %v62734_v40 (stack53)
        %v63967_v46 = vor.u32 %v63966_v21, %v63965_v34 (stack47)
        %v63128_v20 = vxor.u32 %v63127_v23, %v63119_v54 (stack48)
        %v63528_v61 = vadd.s32 %v63525_v27, %v63520_v61 (stack40)
        %v63530_v7 = vshll.u32 %v63525_v27, 26 (stack45)
        %v63531_v43 = vshrl.u32 %v63525_v27, 6 (stack46)
        %v62347_v41 = vsel /*vm=*/%vm62310_vm8, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v140503_v32 = vsel /*vm=*/%vm62310_vm8, /*on_true_vy=*/%v140447_v32, /*on_false_vx=*/%v62362_v9 (stack44)
        %v140505_v56 = vmax.f32 %v62738_v8, -0.99609375 (stack55)
        %v63968_v55 = vxor.u32 %v63967_v46, %v63963_v31 (stack48)
        %v62343_v34 = vsel /*vm=*/%vm62310_vm8, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v62370_v30 = vmul.f32 %v140503_v32, %v62347_v41 (stack54)
        %v63131_v40 = vadd.s32 %v63128_v20, %v121564_v0 (stack40)
        %v63532_v21 = vor.u32 %v63531_v43, %v63530_v7 (stack47)
        %v62754_v52 = vxor.u32 2147483648, %v140505_v56 (stack56)
        %v63971_v31 = vadd.s32 %v63968_v55, %v63963_v31 (stack40)
        %v64390_v23 = vshll.u32 %v140480_v45, 15 (stack45)
        %v64391_v45 = vshrl.u32 %v140480_v45, 17 (stack46)
        %v62374_v27 = vadd.f32 %v62370_v30, %v62343_v34 (stack53)
        %v63123_v54 = vadd.s32 %v63119_v54, %v121569_v1 (stack40)
        %v63135_v9 = vadd.s32 4, %v63131_v40 (stack40)
        %v63533_v8 = vxor.u32 %v63532_v21, %v63528_v61 (stack48)
        %v140517_v46 = vmul.f32 %v62754_v52, %v140505_v56 (stack54)
        %v63973_v20 = vshll.u32 %v63968_v55, 29 (stack45)
        %v63974_v7 = vshrl.u32 %v63968_v55, 3 (stack46)
        %v64798_v43 = vadd.s32 %v140405_v24, %v122657_v58 (stack40)
        %v62378_v41 = vmul.f32 %v62374_v27, %v140503_v32 (stack54)
        %v63139_v55 = vadd.s32 %v63135_v9, %v63123_v54 (stack40)
        %v63141_v34 = vshll.u32 %v63135_v9, 13 (stack45)
        %v63142_v30 = vshrl.u32 %v63135_v9, 19 (stack46)
        %v62759_v40 = vadd.f32 1.0, %v140517_v46 (stack57)
        %v62762_v21 = vmul.f32 -0.5, %v140517_v46 (stack59)
        %v63536_v61 = vadd.s32 %v63533_v8, %v63528_v61 (stack40)
        %v64392_v52 = vor.u32 %v64391_v45, %v64390_v23 (stack47)
        %v62382_v50 = vadd.f32 %v62378_v41, %v62339_v50 (stack53)
        %v63143_v23 = vor.u32 %v63142_v30, %v63141_v34 (stack47)
        %v63542_v45 = vshll.u32 %v63533_v8, 6 (stack45)
        %v63543_v27 = vshrl.u32 %v63533_v8, 26 (stack46)
        %120965 = vlog2.f32 %v62759_v40 (stack58)
        %v62765_v54 = vand.u32 2147483647, %v140517_v46 (stack60)
        %vm64802_vm13 = vcmp.lt.u32.totalorder %v64798_v43, %v140405_v24 (stack43)
        %v64816_v9 = vadd.s32 1, %v140484_v44 (stack40)
        %v62386_v8 = vmul.f32 %v62382_v50, %v140503_v32 (stack54)
        %v63144_v41 = vxor.u32 %v63143_v23, %v63139_v55 (stack48)
        %v63544_v34 = vor.u32 %v63543_v27, %v63542_v45 (stack47)
        %v63975_v20 = vor.u32 %v63974_v7, %v63973_v20 (stack47)
        %v62763_v7 = vadd.f32 1.0, %v62762_v21 (stack61)
        %v63540_v30 = vadd.s32 %v63536_v61, %v121574_v2 (stack40)
        %v64393_v40 = vxor.u32 %v64392_v52, %v64388_v60 (stack48)
        %v64820_v44 = vsel /*vm=*/%vm64807_vm11, /*on_true_vy=*/%v64816_v9, /*on_false_vx=*/%v140484_v44 (stack44)
        %v62390_v25 = vadd.f32 %v62386_v8, %v140467_v25 (stack53)
        %v63147_v55 = vadd.s32 %v63144_v41, %v63139_v55 (stack40)
        %v63149_v21 = vshll.u32 %v63144_v41, 15 (stack45)
        %v63150_v52 = vshrl.u32 %v63144_v41, 17 (stack46)
        %v63545_v61 = vxor.u32 %v63544_v34, %v63536_v61 (stack48)
        %v63976_v50 = vxor.u32 %v63975_v20, %v63971_v31 (stack48)
        %v64396_v60 = vadd.s32 %v64393_v40, %v64388_v60 (stack40)
        %v64398_v23 = vshll.u32 %v64393_v40, 26 (stack45)
        %v62394_v45 = vmul.f32 %v62390_v25, %v140503_v32 (stack54)
        %v63151_v27 = vor.u32 %v63150_v52, %v63149_v21 (stack47)
        %v64399_v9 = vshrl.u32 %v64393_v40, 6 (stack46)
        %v64824_v8 = vadd.s32 1, %v64820_v44 (stack40)
        %v63548_v41 = vadd.s32 %v63545_v61, %v121569_v1 (stack40)
        %v63979_v31 = vadd.s32 %v63976_v50, %v63971_v31 (stack40)
        %v63981_v34 = vshll.u32 %v63976_v50, 16 (stack45)
        %v63982_v20 = vshrl.u32 %v63976_v50, 16 (stack46)
        %v62398_v42 = vadd.f32 %v62394_v45, %v140458_v42 (stack53)
        %v63152_v40 = vxor.u32 %v63151_v27, %v63147_v55 (stack48)
        %v64400_v25 = vor.u32 %v64399_v9, %v64398_v23 (stack47)
        %v64828_v24 = vsel /*vm=*/%vm64802_vm13, /*on_true_vy=*/%v64824_v8, /*on_false_vx=*/%v64820_v44 (stack44)
        %v63552_v44 = vadd.s32 3, %v63548_v41 (stack40)
        %v63983_v21 = vor.u32 %v63982_v20, %v63981_v34 (stack47)
        %v64833_v52 = vadd.s32 %v64828_v24, %v121574_v2 (stack40)
        %v140541_v43 = vadd.s32 %v64798_v43, %v121569_v1 (stack40)
        %v62402_v61 = vmul.f32 %v62398_v42, %v140503_v32 (stack54)
        %v63155_v55 = vadd.s32 %v63152_v40, %v63147_v55 (stack40)
        %v63157_v50 = vshll.u32 %v63152_v40, 26 (stack45)
        %v63158_v23 = vshrl.u32 %v63152_v40, 6 (stack46)
        %v63556_v30 = vadd.s32 %v63552_v44, %v63540_v30 (stack40)
        %v63558_v45 = vshll.u32 %v63552_v44, 17 (stack45)
        %v63559_v27 = vshrl.u32 %v63552_v44, 15 (stack46)
        %v63984_v9 = vxor.u32 %v63983_v21, %v63979_v31 (stack48)
        %v62406_v10 = vadd.f32 %v62402_v61, %v140453_v10 (stack53)
        %v63159_v8 = vor.u32 %v63158_v23, %v63157_v50 (stack47)
        %v64401_v41 = vxor.u32 %v64400_v25, %v64396_v60 (stack48)
        %v140546_v34 = vadd.s32 %v140541_v43, %v64833_v52 (stack40)
        %v63560_v20 = vor.u32 %v63559_v27, %v63558_v45 (stack47)
        %v63987_v31 = vadd.s32 %v63984_v9, %v63979_v31 (stack40)
        %v63993_v42 = vshll.u32 %v63984_v9, 24 (stack45)
        %v63994_v40 = vshrl.u32 %v63984_v9, 8 (stack46)
        %v120966_v25 = vpop.eup %120965 (stack64)
        %v62410_v24 = vmul.f32 %v62406_v10, %v140503_v32 (stack54)
        %vm140549_vm14 = vcmp.lt.f32.partialorder %v62765_v54, 0.0004427343 (stack62)
        %v63160_v44 = vxor.u32 %v63159_v8, %v63155_v55 (stack48)
        %v140553_v60 = vadd.s32 %v64401_v41, %v64396_v60 (stack40)
        %v62761_v21 = vmul.f32 0.6931472, %v120966_v25 (stack65)
        %v62764_v46 = vmul.f32 %v62763_v7, %v140517_v46 (stack63)
        %v63561_v7 = vxor.u32 %v63560_v20, %v63556_v30 (stack48)
        %v63995_v52 = vor.u32 %v63994_v40, %v63993_v42 (stack47)
        %v62414_v22 = vadd.f32 %v62410_v24, %v140444_v22 (stack53)
        %v63163_v61 = vadd.s32 %v63160_v44, %v63155_v55 (stack40)
        %v63169_v55 = vshll.u32 %v63160_v44, 6 (stack45)
        %v63170_v50 = vshrl.u32 %v63160_v44, 26 (stack46)
        %v62767_v23 = vsel /*vm=*/%vm140549_vm14, /*on_true_vy=*/%v62764_v46, /*on_false_vx=*/%v62761_v21 (stack66)
        %v63564_v30 = vadd.s32 %v63561_v7, %v63556_v30 (stack40)
        %v63566_v45 = vshll.u32 %v63561_v7, 29 (stack45)
        %v63567_v27 = vshrl.u32 %v63561_v7, 3 (stack46)
        %v62291_v9 = vmul.f32 inf, %v140347_v29 (stack54)
        %v62418_v10 = vmul.f32 %v62414_v22, %v140503_v32 (stack54)
        %v140561_v8 = vxor.u32 2147483648, %v62767_v23 (stack56)
        %v63171_v20 = vor.u32 %v63170_v50, %v63169_v55 (stack47)
        %vm140565_vm15 = vcmp.eq.f32.partialorder %v62283_v26, 1.0 (stack68)
        %v62315_v42 = vsel /*vm=*/%vm62310_vm8, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v62319_v12 = vsel /*vm=*/%vm62310_vm8, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v62744_v40 = vand.u32 2147483647, %v140505_v56 (stack77)
        %v63996_v25 = vxor.u32 %v63995_v52, %v63987_v31 (stack48)
        %v62422_v24 = vadd.f32 %v62418_v10, %v62319_v12 (stack53)
        %vm62771_vm0 = vcmp.lt.f32.partialorder %v140561_v8, 5.0 (stack68)
        %120967 = vrsqrt.f32 %v140561_v8 (stack67)
        %v64843_v54 = vshll.u32 %v140541_v43, 13 (stack45)
        %v63172_v44 = vxor.u32 %v63171_v20, %v63163_v61 (stack48)
        %v63568_v21 = vor.u32 %v63567_v27, %v63566_v45 (stack47)
        %v64410_v46 = vshll.u32 %v64401_v41, 6 (stack45)
        %v64411_v41 = vshrl.u32 %v64401_v41, 26 (stack46)
        %v62426_v32 = vmul.f32 %v62422_v24, %v140503_v32 (stack54)
        %v63167_v7 = vadd.s32 %v63163_v61, %v121564_v0 (stack40)
        %v63991_v31 = vadd.s32 %v63987_v31, %v121564_v0 (stack40)
        %v64408_v52 = vadd.s32 %v140553_v60, %v121569_v1 (stack40)
        %v140587_v22 = vsel /*vm=*/%vm62771_vm0, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v140592_v61 = vsel /*vm=*/%vm62771_vm0, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v140595_v55 = vadd.f32 -2.5, %v140561_v8 (stack53)
        %v63175_v50 = vadd.s32 %v63172_v44, %v121574_v2 (stack40)
        %v62430_v23 = vadd.f32 %v62426_v32, %v62315_v42 (stack53)
        %v140601_v45 = vsel /*vm=*/%vm62771_vm0, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v140606_v27 = vsel /*vm=*/%vm62771_vm0, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v140611_v10 = vsel /*vm=*/%vm62771_vm0, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v63179_v20 = vadd.s32 5, %v63175_v50 (stack40)
        %v63569_v42 = vxor.u32 %v63568_v21, %v63564_v30 (stack48)
        %v63999_v12 = vadd.s32 %v63996_v25, %v121574_v2 (stack40)
        %v64412_v25 = vor.u32 %v64411_v41, %v64410_v46 (stack47)
        %v62434_v29 = vmul.f32 %v62430_v23, %v140347_v29 (stack54)
        %v64844_v43 = vshrl.u32 %v140541_v43, 19 (stack46)
        %v140618_v24 = vadd.s32 %v157458_v53, %v157079_v39 (stack40)
        %v140622_v44 = vadd.s32 %v157461_v6, %v157082_v49 (stack40)
        %vm62816_vm1 = vcmp.eq.f32.partialorder %v140561_v8, inf (stack70)
        %v63181_v21 = vxor.u32 %v63179_v20, %v63167_v7 (stack48)
        %v63572_v30 = vadd.s32 %v63569_v42, %v63564_v30 (stack40)
        %v63574_v46 = vshll.u32 %v63569_v42, 16 (stack45)
        %v63575_v41 = vshrl.u32 %v63569_v42, 16 (stack46)
        %v62438_v9 = vsel /*vm=*/%vm140565_vm15, /*on_true_vy=*/%v62291_v9, /*on_false_vx=*/%v62434_v29 (stack44)
        %v64003_v26 = vadd.s32 2, %v63999_v12 (stack40)
        %v64413_v60 = vxor.u32 %v64412_v25, %v140553_v60 (stack48)
        %v64845_v54 = vor.u32 %v64844_v43, %v64843_v54 (stack47)
        %v62442_v32 = vmul.f32 1.4140625, %v62438_v9 (stack54)
        %vm62818_vm2 = vcmp.eq.f32.partialorder %v140561_v8, 0.0 (stack71)
        %v63182_v7 = vand.u32.u8 255, %v63181_v21 (stack49)
        %v63576_v50 = vor.u32 %v63575_v41, %v63574_v46 (stack47)
        %v64007_v31 = vadd.s32 %v64003_v26, %v63991_v31 (stack40)
        %v64009_v23 = vshll.u32 %v64003_v26, 13 (stack45)
        %v64010_v20 = vshrl.u32 %v64003_v26, 19 (stack46)
        %v64416_v42 = vadd.s32 %v64413_v60, %v121564_v0 (stack40)
        %v62445_v12 = vpack.c.bf16 %v157387_v11, %v62442_v32 (stack81)
        %v63183_v25 = vand.u32 65535, %v63182_v7 (stack50)
        %v63577_v29 = vxor.u32 %v63576_v50, %v63572_v30 (stack48)
        %v64846_v43 = vxor.u32 %v64845_v54, %v140546_v34 (stack48)
        %v62819_v21 = vand.u32 2147483648, %v140561_v8 (stack72)
        %v64011_v46 = vor.u32 %v64010_v20, %v64009_v23 (stack47)
        %v64420_v41 = vadd.s32 1, %v64416_v42 (stack40)
        %vm65268_vm3 = vcmp.lt.u32.totalorder %v140618_v24, %v157079_v39 (stack43)
        %v120968_v9 = vpop.eup %120967 (stack73)
        %120077 = vst [vmem:[%s123356_s30 + $0x240] sm:$0xf] /*vst_source=*/%v62445_v12 (stack83)
        %v63184_v26 = vshrl.u32 %v63183_v25, 1 (stack51)
        %v63580_v30 = vadd.s32 %v63577_v29, %v63572_v30 (stack40)
        %v63586_v60 = vshll.u32 %v63577_v29, 24 (stack45)
        %v63587_v54 = vshrl.u32 %v63577_v29, 8 (stack46)
        %v62815_v32 = vmul.f32 %v120968_v9, %v140561_v8 (stack74)
        %v64012_v7 = vxor.u32 %v64011_v46, %v64007_v31 (stack48)
        %v64424_v52 = vadd.s32 %v64420_v41, %v64408_v52 (stack40)
        %v64426_v50 = vshll.u32 %v64420_v41, 17 (stack45)
        %v63185_v23 = vor.u32 16256, %v63184_v26 (stack47)
        %v63588_v20 = vor.u32 %v63587_v54, %v63586_v60 (stack47)
        %v64427_v42 = vshrl.u32 %v64420_v41, 15 (stack46)
        %v140639_v12 = vadd.s32 %v140618_v24, %v122657_v58 (stack40)
        %v62817_v25 = vsel /*vm=*/%vm62816_vm1, /*on_true_vy=*/%v140561_v8, /*on_false_vx=*/%v62815_v32 (stack75)
        %v64015_v31 = vadd.s32 %v64012_v7, %v64007_v31 (stack40)
        %v64017_v29 = vshll.u32 %v64012_v7, 15 (stack45)
        %v64018_v46 = vshrl.u32 %v64012_v7, 17 (stack46)
        %v62820_v21 = vsel /*vm=*/%vm62818_vm2, /*on_true_vy=*/%v62819_v21, /*on_false_vx=*/%v62817_v25 (stack76)
        %v63186_v41 = vand.u32.u16 65535, %v63185_v23 (stack52)
        %v63589_v9 = vxor.u32 %v63588_v20, %v63580_v30 (stack48)
        %v64428_v26 = vor.u32 %v64427_v42, %v64426_v50 (stack47)
        %v62823_v60 = vadd.f32 -3.0, %v62820_v21 (stack53)
        %v63584_v30 = vadd.s32 %v63580_v30, %v121569_v1 (stack40)
        %v64019_v54 = vor.u32 %v64018_v46, %v64017_v29 (stack47)
        %v140648_v34 = vadd.s32 %v64846_v43, %v140546_v34 (stack40)
        %v120080_v32 = vadd.low.f32.bf16 -1.0, %v63186_v41 (stack53)
        %v63592_v7 = vadd.s32 %v63589_v9, %v121564_v0 (stack40)
        %v64429_v50 = vxor.u32 %v64428_v26, %v64424_v52 (stack48)
        %v64851_v23 = vshll.u32 %v64846_v43, 15 (stack45)
        %v140654_v55 = vsel /*vm=*/%vm62771_vm0, /*on_true_vy=*/%v140595_v55, /*on_false_vx=*/%v62823_v60 (stack44)
        %v64020_v20 = vxor.u32 %v64019_v54, %v64015_v31 (stack48)
        %v64852_v43 = vshrl.u32 %v64846_v43, 17 (stack46)
        %v65277_v42 = vadd.s32 1, %v140622_v44 (stack40)
        %v62831_v10 = vmul.f32 %v140654_v55, %v140611_v10 (stack54)
        %v63195_v25 = vmul.f32 2.0, %v120080_v32 (stack54)
        %v63596_v29 = vadd.s32 4, %v63592_v7 (stack40)
        %v64432_v52 = vadd.s32 %v64429_v50, %v64424_v52 (stack40)
        %v64023_v31 = vadd.s32 %v64020_v20, %v64015_v31 (stack40)
        %v64025_v46 = vshll.u32 %v64020_v20, 26 (stack45)
        %v64026_v21 = vshrl.u32 %v64020_v20, 6 (stack46)
        %v64434_v41 = vshll.u32 %v64429_v50, 29 (stack45)
        %v62835_v27 = vadd.f32 %v62831_v10, %v140606_v27 (stack53)
        %v63199_v9 = vadd.f32 -0.99609375, %v63195_v25 (stack53)
        %v63600_v26 = vadd.s32 %v63596_v29, %v63584_v30 (stack40)
        %v63602_v60 = vshll.u32 %v63596_v29, 13 (stack45)
        %v63603_v30 = vshrl.u32 %v63596_v29, 19 (stack46)
        %v64027_v54 = vor.u32 %v64026_v21, %v64025_v46 (stack47)
        %v64435_v32 = vshrl.u32 %v64429_v50, 3 (stack46)
        %v64853_v7 = vor.u32 %v64852_v43, %v64851_v23 (stack47)
        %v62800_v50 = vsel /*vm=*/%vm62771_vm0, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v62839_v23 = vmul.f32 %v62835_v27, %v140654_v55 (stack54)
        %v140664_v20 = vmax.f32 %v63199_v9, -0.99609375 (stack55)
        %v65281_v44 = vsel /*vm=*/%vm65268_vm3, /*on_true_vy=*/%v65277_v42, /*on_false_vx=*/%v140622_v44 (stack44)
        %v63604_v43 = vor.u32 %v63603_v30, %v63602_v60 (stack47)
        %v64028_v42 = vxor.u32 %v64027_v54, %v64023_v31 (stack48)
        %v64436_v10 = vor.u32 %v64435_v32, %v64434_v41 (stack47)
        %v64854_v25 = vxor.u32 %v64853_v7, %v140648_v34 (stack48)
        %v62788_v29 = vsel /*vm=*/%vm62771_vm0, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v62843_v46 = vadd.f32 %v62839_v23, %v62800_v50 (stack53)
        %v63215_v21 = vxor.u32 2147483648, %v140664_v20 (stack56)
        %v140677_v41 = vadd.s32 %v140639_v12, %v121569_v1 (stack40)
        %v63605_v27 = vxor.u32 %v63604_v43, %v63600_v26 (stack48)
        %v64031_v31 = vadd.s32 %v64028_v42, %v64023_v31 (stack40)
        %v64037_v9 = vshll.u32 %v64028_v42, 6 (stack45)
        %v64038_v60 = vshrl.u32 %v64028_v42, 26 (stack46)
        %v62792_v30 = vsel /*vm=*/%vm62771_vm0, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v62847_v54 = vmul.f32 %v62843_v46, %v140654_v55 (stack54)
        %v63218_v32 = vmul.f32 %v63215_v21, %v140664_v20 (stack54)
        %v64437_v7 = vxor.u32 %v64436_v10, %v64432_v52 (stack48)
        %v62796_v8 = vsel /*vm=*/%vm62771_vm0, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v63608_v26 = vadd.s32 %v63605_v27, %v63600_v26 (stack40)
        %v63610_v50 = vshll.u32 %v63605_v27, 15 (stack45)
        %v63611_v23 = vshrl.u32 %v63605_v27, 17 (stack46)
        %v62851_v43 = vadd.f32 %v62847_v54, %v62796_v8 (stack53)
        %v63220_v42 = vadd.f32 1.0, %v63218_v32 (stack57)
        %vm65263_vm4 = vcmp.lt.u32.totalorder %v140639_v12, %v140618_v24 (stack43)
        %v65304_v10 = vshll.u32 %v140677_v41, 13 (stack45)
        %v63612_v46 = vor.u32 %v63611_v23, %v63610_v50 (stack47)
        %v64035_v21 = vadd.s32 %v64031_v31, %v121574_v2 (stack40)
        %v64039_v27 = vor.u32 %v64038_v60, %v64037_v9 (stack47)
        %v64440_v52 = vadd.s32 %v64437_v7, %v64432_v52 (stack40)
        %v62855_v9 = vmul.f32 %v62851_v43, %v140654_v55 (stack54)
        %120969 = vlog2.f32 %v63220_v42 (stack58)
        %v63223_v60 = vmul.f32 -0.5, %v63218_v32 (stack59)
        %v64442_v54 = vshll.u32 %v64437_v7, 16 (stack45)
        %v63613_v8 = vxor.u32 %v63612_v46, %v63608_v26 (stack48)
        %v64040_v31 = vxor.u32 %v64039_v27, %v64031_v31 (stack48)
        %v64443_v7 = vshrl.u32 %v64437_v7, 16 (stack46)
        %v64857_v34 = vadd.s32 %v64854_v25, %v140648_v34 (stack40)
        %v62859_v30 = vadd.f32 %v62855_v9, %v62792_v30 (stack53)
        %v63226_v50 = vand.u32 2147483647, %v63218_v32 (stack60)
        %v64859_v23 = vshll.u32 %v64854_v25, 26 (stack45)
        %v64860_v25 = vshrl.u32 %v64854_v25, 6 (stack46)
        %v63616_v26 = vadd.s32 %v63613_v8, %v63608_v26 (stack40)
        %v63618_v43 = vshll.u32 %v63613_v8, 26 (stack45)
        %v63619_v42 = vshrl.u32 %v63613_v8, 6 (stack46)
        %v64043_v46 = vadd.s32 %v64040_v31, %v121569_v1 (stack40)
        %v62863_v27 = vmul.f32 %v62859_v30, %v140654_v55 (stack54)
        %v64444_v9 = vor.u32 %v64443_v7, %v64442_v54 (stack47)
        %v64861_v54 = vor.u32 %v64860_v25, %v64859_v23 (stack47)
        %v65285_v8 = vadd.s32 1, %v65281_v44 (stack40)
        %v63224_v60 = vadd.f32 1.0, %v63223_v60 (stack61)
        %v63620_v31 = vor.u32 %v63619_v42, %v63618_v43 (stack47)
        %v64047_v7 = vadd.s32 3, %v64043_v46 (stack40)
        %v140697_v30 = vadd.s32 %v157458_v53, %v157083_v59 (stack40)
        %v62867_v29 = vadd.f32 %v62863_v27, %v62788_v29 (stack53)
        %v64445_v23 = vxor.u32 %v64444_v9, %v64440_v52 (stack48)
        %v64862_v25 = vxor.u32 %v64861_v54, %v64857_v34 (stack48)
        %v65289_v24 = vsel /*vm=*/%vm65263_vm4, /*on_true_vy=*/%v65285_v8, /*on_false_vx=*/%v65281_v44 (stack44)
        %v63621_v12 = vxor.u32 %v63620_v31, %v63616_v26 (stack48)
        %v64051_v44 = vadd.s32 %v64047_v7, %v64035_v21 (stack40)
        %v64053_v21 = vshll.u32 %v64047_v7, 17 (stack45)
        %v64054_v43 = vshrl.u32 %v64047_v7, 15 (stack46)
        %v62871_v42 = vmul.f32 %v62867_v29, %v140654_v55 (stack54)
        %v64448_v52 = vadd.s32 %v64445_v23, %v64440_v52 (stack40)
        %v64454_v46 = vshll.u32 %v64445_v23, 24 (stack45)
        %v64455_v27 = vshrl.u32 %v64445_v23, 8 (stack46)
        %v63624_v26 = vadd.s32 %v63621_v12, %v63616_v26 (stack40)
        %v63630_v9 = vshll.u32 %v63621_v12, 6 (stack45)
        %v63631_v54 = vshrl.u32 %v63621_v12, 26 (stack46)
        %v64055_v8 = vor.u32 %v64054_v43, %v64053_v21 (stack47)
        %v62875_v45 = vadd.f32 %v62871_v42, %v140601_v45 (stack53)
        %vm140704_vm5 = vcmp.lt.f32.partialorder %v63226_v50, 0.0004427343 (stack62)
        %v64456_v31 = vor.u32 %v64455_v27, %v64454_v46 (stack47)
        %v64865_v34 = vadd.s32 %v64862_v25, %v64857_v34 (stack40)
        %v63225_v32 = vmul.f32 %v63224_v60, %v63218_v32 (stack63)
        %v63632_v60 = vor.u32 %v63631_v54, %v63630_v9 (stack47)
        %v64056_v7 = vxor.u32 %v64055_v8, %v64051_v44 (stack48)
        %v64871_v29 = vshll.u32 %v64862_v25, 6 (stack45)
        %v62879_v23 = vmul.f32 %v62875_v45, %v140654_v55 (stack54)
        %v64457_v12 = vxor.u32 %v64456_v31, %v64448_v52 (stack48)
        %v64872_v25 = vshrl.u32 %v64862_v25, 26 (stack46)
        %v65305_v21 = vshrl.u32 %v140677_v41, 19 (stack46)
        %v120970_v43 = vpop.eup %120969 (stack64)
        %v63633_v42 = vxor.u32 %v63632_v60, %v63624_v26 (stack48)
        %v64059_v44 = vadd.s32 %v64056_v7, %v64051_v44 (stack40)
        %v64061_v46 = vshll.u32 %v64056_v7, 29 (stack45)
        %v64062_v27 = vshrl.u32 %v64056_v7, 3 (stack46)
        %v62883_v61 = vadd.f32 %v62879_v23, %v140592_v61 (stack53)
        %v63222_v9 = vmul.f32 0.6931472, %v120970_v43 (stack65)
        %v64460_v54 = vadd.s32 %v64457_v12, %v121574_v2 (stack40)
        %v64873_v8 = vor.u32 %v64872_v25, %v64871_v29 (stack47)
        %v63636_v45 = vadd.s32 %v63633_v42, %v121574_v2 (stack40)
        %v64063_v31 = vor.u32 %v64062_v27, %v64061_v46 (stack47)
        %v64452_v52 = vadd.s32 %v64448_v52, %v121564_v0 (stack40)
        %v65294_v24 = vadd.s32 %v65289_v24, %v121574_v2 (stack40)
        %v62887_v55 = vmul.f32 %v62883_v61, %v140654_v55 (stack54)
        %v63228_v50 = vsel /*vm=*/%vm140704_vm5, /*on_true_vy=*/%v63225_v32, /*on_false_vx=*/%v63222_v9 (stack66)
        %v64464_v32 = vadd.s32 2, %v64460_v54 (stack40)
        %v64874_v60 = vxor.u32 %v64873_v8, %v64865_v34 (stack48)
        %v140718_v7 = vxor.u32 2147483648, %v63228_v50 (stack56)
        %v63640_v29 = vadd.s32 5, %v63636_v45 (stack40)
        %v64064_v23 = vxor.u32 %v64063_v31, %v64059_v44 (stack48)
        %v65302_v12 = vadd.s32 %v140677_v41, %v65294_v24 (stack40)
        %v62891_v22 = vadd.f32 %v62887_v55, %v140587_v22 (stack53)
        %v64468_v25 = vadd.s32 %v64464_v32, %v64452_v52 (stack40)
        %v62752_v43 = vmul.f32 inf, %v140505_v56 (stack54)
        %120971 = vrsqrt.f32 %v140718_v7 (stack67)
        %v63628_v26 = vadd.s32 %v63624_v26, %v121564_v0 (stack40)
        %v62895_v42 = vmul.f32 %v62891_v22, %v140505_v56 (stack54)
        %vm63232_vm6 = vcmp.lt.f32.partialorder %v140718_v7, 5.0 (stack68)
        %v64470_v46 = vshll.u32 %v64464_v32, 13 (stack45)
        %v64471_v27 = vshrl.u32 %v64464_v32, 19 (stack46)
        %vm62747_vm7 = vcmp.eq.f32.partialorder %v62744_v40, 1.0 (stack68)
        %v63642_v56 = vxor.u32 %v63640_v29, %v63628_v26 (stack48)
        %v65306_v40 = vor.u32 %v65305_v21, %v65304_v10 (stack47)
        %v62899_v41 = vsel /*vm=*/%vm62747_vm7, /*on_true_vy=*/%v62752_v43, /*on_false_vx=*/%v62895_v42 (stack44)
        %v63205_v10 = vand.u32 2147483647, %v140664_v20 (stack77)
        %v64869_v34 = vadd.s32 %v64865_v34, %v121569_v1 (stack40)
        %v62903_v21 = vmul.f32 1.4140625, %v62899_v41 (stack54)
        %v140736_v61 = vsel /*vm=*/%vm63232_vm6, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v140739_v9 = vadd.f32 -2.5, %v140718_v7 (stack53)
        %v63643_v54 = vand.u32.u8 255, %v63642_v56 (stack49)
        %v64067_v44 = vadd.s32 %v64064_v23, %v64059_v44 (stack40)
        %v64069_v8 = vshll.u32 %v64064_v23, 16 (stack45)
        %v64070_v45 = vshrl.u32 %v64064_v23, 16 (stack46)
        %v64472_v31 = vor.u32 %v64471_v27, %v64470_v46 (stack47)
        %v62906_v52 = vpack.c.bf16 %v157387_v11, %v62903_v21 (stack81)
        %v63644_v24 = vand.u32 65535, %v63643_v54 (stack50)
        %v64877_v55 = vadd.s32 %v64874_v60, %v121564_v0 (stack40)
        %v65307_v50 = vxor.u32 %v65306_v40, %v65302_v12 (stack48)
        %v140746_v32 = vsel /*vm=*/%vm63232_vm6, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %vm63277_vm8 = vcmp.eq.f32.partialorder %v140718_v7, inf (stack70)
        %v64071_v60 = vor.u32 %v64070_v45, %v64069_v8 (stack47)
        %v64473_v29 = vxor.u32 %v64472_v31, %v64468_v25 (stack48)
        %vm65729_vm9 = vcmp.lt.u32.totalorder %v140697_v30, %v157083_v59 (stack43)
        %120079 = vst [vmem:[%s123356_s30 + $0x2c0] sm:$0xf] /*vst_source=*/%v62906_v52 (stack83)
        %v63645_v23 = vshrl.u32 %v63644_v24, 1 (stack51)
        %v64881_v22 = vadd.s32 1, %v64877_v55 (stack40)
        %v65310_v12 = vadd.s32 %v65307_v50, %v65302_v12 (stack40)
        %v65312_v43 = vshll.u32 %v65307_v50, 15 (stack45)
        %v64072_v26 = vxor.u32 %v64071_v60, %v64067_v44 (stack48)
        %v64476_v25 = vadd.s32 %v64473_v29, %v64468_v25 (stack40)
        %v64478_v42 = vshll.u32 %v64473_v29, 15 (stack45)
        %v64479_v46 = vshrl.u32 %v64473_v29, 17 (stack46)
        %v63646_v27 = vor.u32 16256, %v63645_v23 (stack47)
        %v64885_v56 = vadd.s32 %v64881_v22, %v64869_v34 (stack40)
        %v64887_v40 = vshll.u32 %v64881_v22, 17 (stack45)
        %v64888_v41 = vshrl.u32 %v64881_v22, 15 (stack46)
        %v64075_v34 = vadd.s32 %v64072_v26, %v64067_v44 (stack40)
        %v64081_v21 = vshll.u32 %v64072_v26, 24 (stack45)
        %v64082_v54 = vshrl.u32 %v64072_v26, 8 (stack46)
        %v64480_v44 = vor.u32 %v64479_v46, %v64478_v42 (stack47)
        %vm63279_vm10 = vcmp.eq.f32.partialorder %v140718_v7, 0.0 (stack71)
        %v63647_v8 = vand.u32.u16 65535, %v63646_v27 (stack52)
        %v64889_v45 = vor.u32 %v64888_v41, %v64887_v40 (stack47)
        %v65313_v31 = vshrl.u32 %v65307_v50, 17 (stack46)
        %v120972_v52 = vpop.eup %120971 (stack73)
        %v63280_v24 = vand.u32 2147483648, %v140718_v7 (stack72)
        %v64083_v55 = vor.u32 %v64082_v54, %v64081_v21 (stack47)
        %v64481_v50 = vxor.u32 %v64480_v44, %v64476_v25 (stack48)
        %v140756_v60 = vadd.s32 %v157461_v6, %v157084_v16 (stack40)
        %v63276_v29 = vmul.f32 %v120972_v52, %v140718_v7 (stack74)
        %v120082_v23 = vadd.low.f32.bf16 -1.0, %v63647_v8 (stack53)
        %v64890_v22 = vxor.u32 %v64889_v45, %v64885_v56 (stack48)
        %v65314_v43 = vor.u32 %v65313_v31, %v65312_v43 (stack47)
        %v64084_v26 = vxor.u32 %v64083_v55, %v64075_v34 (stack48)
        %v64484_v25 = vadd.s32 %v64481_v50, %v64476_v25 (stack40)
        %v64486_v42 = vshll.u32 %v64481_v50, 26 (stack45)
        %v64487_v46 = vshrl.u32 %v64481_v50, 6 (stack46)
        %v63278_v27 = vsel /*vm=*/%vm63277_vm8, /*on_true_vy=*/%v140718_v7, /*on_false_vx=*/%v63276_v29 (stack75)
        %v63656_v40 = vmul.f32 2.0, %v120082_v23 (stack54)
        %v64893_v56 = vadd.s32 %v64890_v22, %v64885_v56 (stack40)
        %v64895_v41 = vshll.u32 %v64890_v22, 29 (stack45)
        %v63281_v21 = vsel /*vm=*/%vm63279_vm10, /*on_true_vy=*/%v63280_v24, /*on_false_vx=*/%v63278_v27 (stack76)
        %v64087_v54 = vadd.s32 %v64084_v26, %v121564_v0 (stack40)
        %v64488_v44 = vor.u32 %v64487_v46, %v64486_v42 (stack47)
        %v64896_v8 = vshrl.u32 %v64890_v22, 3 (stack46)
        %v140768_v45 = vsel /*vm=*/%vm63232_vm6, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v63284_v31 = vadd.f32 -3.0, %v63281_v21 (stack53)
        %v63660_v52 = vadd.f32 -0.99609375, %v63656_v40 (stack53)
        %v65315_v24 = vxor.u32 %v65314_v43, %v65310_v12 (stack48)
        %v63269_v55 = vsel /*vm=*/%vm63232_vm6, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v64079_v34 = vadd.s32 %v64075_v34, %v121569_v1 (stack40)
        %v64091_v50 = vadd.s32 4, %v64087_v54 (stack40)
        %v64489_v29 = vxor.u32 %v64488_v44, %v64484_v25 (stack48)
        %v140777_v9 = vsel /*vm=*/%vm63232_vm6, /*on_true_vy=*/%v140739_v9, /*on_false_vx=*/%v63284_v31 (stack44)
        %v140779_v23 = vmax.f32 %v63660_v52, -0.99609375 (stack55)
        %v64897_v22 = vor.u32 %v64896_v8, %v64895_v41 (stack47)
        %v65318_v12 = vadd.s32 %v65315_v24, %v65310_v12 (stack40)
        %v63292_v43 = vmul.f32 %v140777_v9, %v63269_v55 (stack54)
        %v64095_v26 = vadd.s32 %v64091_v50, %v64079_v34 (stack40)
        %v64097_v42 = vshll.u32 %v64091_v50, 13 (stack45)
        %v64098_v46 = vshrl.u32 %v64091_v50, 19 (stack46)
        %v63265_v27 = vsel /*vm=*/%vm63232_vm6, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v63676_v40 = vxor.u32 2147483648, %v140779_v23 (stack56)
        %v64492_v25 = vadd.s32 %v64489_v29, %v64484_v25 (stack40)
        %v140788_v41 = vadd.s32 %v140697_v30, %v122657_v58 (stack40)
        %v63296_v21 = vadd.f32 %v63292_v43, %v63265_v27 (stack53)
        %v64099_v54 = vor.u32 %v64098_v46, %v64097_v42 (stack47)
        %v64498_v44 = vshll.u32 %v64489_v29, 6 (stack45)
        %v64499_v8 = vshrl.u32 %v64489_v29, 26 (stack46)
        %v63253_v31 = vsel /*vm=*/%vm63232_vm6, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v63257_v52 = vsel /*vm=*/%vm63232_vm6, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v140797_v55 = vmul.f32 %v63676_v40, %v140779_v23 (stack54)
        %v64898_v34 = vxor.u32 %v64897_v22, %v64893_v56 (stack48)
        %v63261_v50 = vsel /*vm=*/%vm63232_vm6, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v63300_v29 = vmul.f32 %v63296_v21, %v140777_v9 (stack54)
        %v64100_v22 = vxor.u32 %v64099_v54, %v64095_v26 (stack48)
        %v64500_v43 = vor.u32 %v64499_v8, %v64498_v44 (stack47)
        %v63681_v42 = vadd.f32 1.0, %v140797_v55 (stack57)
        %v64901_v56 = vadd.s32 %v64898_v34, %v64893_v56 (stack40)
        %v65320_v46 = vshll.u32 %v65315_v24, 26 (stack45)
        %v65321_v24 = vshrl.u32 %v65315_v24, 6 (stack46)
        %v63304_v27 = vadd.f32 %v63300_v29, %v63261_v50 (stack53)
        %v64103_v26 = vadd.s32 %v64100_v22, %v64095_v26 (stack40)
        %v64105_v40 = vshll.u32 %v64100_v22, 15 (stack45)
        %v64106_v21 = vshrl.u32 %v64100_v22, 17 (stack46)
        %vm65724_vm11 = vcmp.lt.u32.totalorder %v140788_v41, %v140697_v30 (stack43)
        %120973 = vlog2.f32 %v63681_v42 (stack58)
        %v64501_v54 = vxor.u32 %v64500_v43, %v64492_v25 (stack48)
        %v65738_v44 = vadd.s32 1, %v140756_v60 (stack40)
        %v140809_v8 = vadd.s32 %v140788_v41, %v121569_v1 (stack40)
        %v63308_v50 = vmul.f32 %v63304_v27, %v140777_v9 (stack54)
        %v64107_v29 = vor.u32 %v64106_v21, %v64105_v40 (stack47)
        %v64903_v22 = vshll.u32 %v64898_v34, 16 (stack45)
        %v64904_v34 = vshrl.u32 %v64898_v34, 16 (stack46)
        %v64496_v25 = vadd.s32 %v64492_v25, %v121574_v2 (stack40)
        %v64504_v43 = vadd.s32 %v64501_v54, %v121569_v1 (stack40)
        %v65322_v42 = vor.u32 %v65321_v24, %v65320_v46 (stack47)
        %v65742_v60 = vsel /*vm=*/%vm65729_vm9, /*on_true_vy=*/%v65738_v44, /*on_false_vx=*/%v140756_v60 (stack44)
        %v63312_v52 = vadd.f32 %v63308_v50, %v63257_v52 (stack53)
        %v63684_v46 = vmul.f32 -0.5, %v140797_v55 (stack59)
        %v64108_v24 = vxor.u32 %v64107_v29, %v64103_v26 (stack48)
        %v64905_v27 = vor.u32 %v64904_v34, %v64903_v22 (stack47)
        %v63687_v40 = vand.u32 2147483647, %v140797_v55 (stack60)
        %v64508_v21 = vadd.s32 3, %v64504_v43 (stack40)
        %v65323_v54 = vxor.u32 %v65322_v42, %v65318_v12 (stack48)
        %v65746_v44 = vadd.s32 1, %v65742_v60 (stack40)
        %v63316_v50 = vmul.f32 %v63312_v52, %v140777_v9 (stack54)
        %v64111_v26 = vadd.s32 %v64108_v24, %v64103_v26 (stack40)
        %v64113_v29 = vshll.u32 %v64108_v24, 26 (stack45)
        %v64114_v22 = vshrl.u32 %v64108_v24, 6 (stack46)
        %v64512_v34 = vadd.s32 %v64508_v21, %v64496_v25 (stack40)
        %v64514_v25 = vshll.u32 %v64508_v21, 17 (stack45)
        %v64515_v43 = vshrl.u32 %v64508_v21, 15 (stack46)
        %v64906_v42 = vxor.u32 %v64905_v27, %v64901_v56 (stack48)
        %v63320_v31 = vadd.f32 %v63316_v50, %v63253_v31 (stack53)
        %v63685_v52 = vadd.f32 1.0, %v63684_v46 (stack61)
        %v64115_v46 = vor.u32 %v64114_v22, %v64113_v29 (stack47)
        %v65326_v12 = vadd.s32 %v65323_v54, %v65318_v12 (stack40)
        %v64516_v24 = vor.u32 %v64515_v43, %v64514_v25 (stack47)
        %v64909_v56 = vadd.s32 %v64906_v42, %v64901_v56 (stack40)
        %v64915_v27 = vshll.u32 %v64906_v42, 24 (stack45)
        %v64916_v21 = vshrl.u32 %v64906_v42, 8 (stack46)
        %v63324_v50 = vmul.f32 %v63320_v31, %v140777_v9 (stack54)
        %v64116_v29 = vxor.u32 %v64115_v46, %v64111_v26 (stack48)
        %v65332_v22 = vshll.u32 %v65323_v54, 6 (stack45)
        %v65333_v54 = vshrl.u32 %v65323_v54, 26 (stack46)
        %vm140822_vm12 = vcmp.lt.f32.partialorder %v63687_v40, 0.0004427343 (stack62)
        %v64517_v25 = vxor.u32 %v64516_v24, %v64512_v34 (stack48)
        %v64917_v43 = vor.u32 %v64916_v21, %v64915_v27 (stack47)
        %v65750_v30 = vsel /*vm=*/%vm65724_vm11, /*on_true_vy=*/%v65746_v44, /*on_false_vx=*/%v65742_v60 (stack44)
        %v63328_v45 = vadd.f32 %v63324_v50, %v140768_v45 (stack53)
        %v64119_v41 = vadd.s32 %v64116_v29, %v64111_v26 (stack40)
        %v64125_v60 = vshll.u32 %v64116_v29, 6 (stack45)
        %v64126_v44 = vshrl.u32 %v64116_v29, 26 (stack46)
        %v64520_v26 = vadd.s32 %v64517_v25, %v64512_v34 (stack40)
        %v64522_v34 = vshll.u32 %v64517_v25, 29 (stack45)
        %v64523_v42 = vshrl.u32 %v64517_v25, 3 (stack46)
        %v64918_v31 = vxor.u32 %v64917_v43, %v64909_v56 (stack48)
        %v120974_v46 = vpop.eup %120973 (stack64)
        %v63332_v24 = vmul.f32 %v63328_v45, %v140777_v9 (stack54)
        %v63686_v55 = vmul.f32 %v63685_v52, %v140797_v55 (stack63)
        %v64127_v52 = vor.u32 %v64126_v44, %v64125_v60 (stack47)
        %v65334_v27 = vor.u32 %v65333_v54, %v65332_v22 (stack47)
        %v63683_v21 = vmul.f32 0.6931472, %v120974_v46 (stack65)
        %v64524_v50 = vor.u32 %v64523_v42, %v64522_v34 (stack47)
        %v64921_v29 = vadd.s32 %v64918_v31, %v121574_v2 (stack40)
        %v65755_v22 = vadd.s32 %v65750_v30, %v121574_v2 (stack40)
        %v63336_v32 = vadd.f32 %v63332_v24, %v140746_v32 (stack53)
        %v64128_v54 = vxor.u32 %v64127_v52, %v64119_v41 (stack48)
        %v64913_v56 = vadd.s32 %v64909_v56, %v121564_v0 (stack40)
        %v65335_v25 = vxor.u32 %v65334_v27, %v65326_v12 (stack48)
        %v63689_v40 = vsel /*vm=*/%vm140822_vm12, /*on_true_vy=*/%v63686_v55, /*on_false_vx=*/%v63683_v21 (stack66)
        %v64525_v43 = vxor.u32 %v64524_v50, %v64520_v26 (stack48)
        %v64925_v30 = vadd.s32 2, %v64921_v29 (stack40)
        %v65763_v45 = vadd.s32 %v140809_v8, %v65755_v22 (stack40)
        %v63340_v60 = vmul.f32 %v63336_v32, %v140777_v9 (stack54)
        %v140840_v44 = vxor.u32 2147483648, %v63689_v40 (stack56)
        %v65765_v34 = vshll.u32 %v140809_v8, 13 (stack45)
        %v65766_v8 = vshrl.u32 %v140809_v8, 19 (stack46)
        %v64528_v26 = vadd.s32 %v64525_v43, %v64520_v26 (stack40)
        %v64530_v42 = vshll.u32 %v64525_v43, 16 (stack45)
        %v64531_v31 = vshrl.u32 %v64525_v43, 16 (stack46)
        %v64929_v46 = vadd.s32 %v64925_v30, %v64913_v56 (stack40)
        %v63213_v24 = vmul.f32 inf, %v140664_v20 (stack54)
        %v63344_v61 = vadd.f32 %v63340_v60, %v140736_v61 (stack53)
        %120975 = vrsqrt.f32 %v140840_v44 (stack67)
        %vm140849_vm13 = vcmp.eq.f32.partialorder %v63205_v10, 1.0 (stack68)
        %vm63693_vm14 = vcmp.lt.f32.partialorder %v140840_v44, 5.0 (stack68)
        %v64131_v55 = vadd.s32 %v64128_v54, %v121574_v2 (stack40)
        %v64532_v52 = vor.u32 %v64531_v31, %v64530_v42 (stack47)
        %v63237_v7 = vsel /*vm=*/%vm63232_vm6, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v63348_v9 = vmul.f32 %v63344_v61, %v140777_v9 (stack54)
        %v63666_v27 = vand.u32 2147483647, %v140779_v23 (stack77)
        %v65338_v21 = vadd.s32 %v65335_v25, %v121564_v0 (stack40)
        %v64123_v41 = vadd.s32 %v64119_v41, %v121564_v0 (stack40)
        %v64533_v50 = vxor.u32 %v64532_v52, %v64528_v26 (stack48)
        %v65330_v12 = vadd.s32 %v65326_v12, %v121569_v1 (stack40)
        %v65767_v29 = vor.u32 %v65766_v8, %v65765_v34 (stack47)
        %v63352_v22 = vadd.f32 %v63348_v9, %v63237_v7 (stack53)
        %v140866_v32 = vsel /*vm=*/%vm63693_vm14, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v140869_v54 = vadd.f32 -2.5, %v140840_v44 (stack53)
        %v63741_v56 = vand.u32 2147483648, %v140840_v44 (stack72)
        %v64135_v25 = vadd.s32 5, %v64131_v55 (stack40)
        %v64536_v40 = vadd.s32 %v64533_v50, %v64528_v26 (stack40)
        %v64542_v43 = vshll.u32 %v64533_v50, 24 (stack45)
        %v64543_v60 = vshrl.u32 %v64533_v50, 8 (stack46)
        %v63356_v20 = vmul.f32 %v63352_v22, %v140664_v20 (stack54)
        %v64931_v34 = vshll.u32 %v64925_v30, 13 (stack45)
        %v64932_v30 = vshrl.u32 %v64925_v30, 19 (stack46)
        %v65342_v8 = vadd.s32 1, %v65338_v21 (stack40)
        %vm63738_vm15 = vcmp.eq.f32.partialorder %v140840_v44, inf (stack70)
        %v64137_v26 = vxor.u32 %v64135_v25, %v64123_v41 (stack48)
        %v64540_v42 = vadd.s32 %v64536_v40, %v121569_v1 (stack40)
        %v64544_v31 = vor.u32 %v64543_v60, %v64542_v43 (stack47)
        %v65768_v61 = vxor.u32 %v65767_v29, %v65763_v45 (stack48)
        %v63360_v24 = vsel /*vm=*/%vm140849_vm13, /*on_true_vy=*/%v63213_v24, /*on_false_vx=*/%v63356_v20 (stack44)
        %vm63740_vm0 = vcmp.eq.f32.partialorder %v140840_v44, 0.0 (stack71)
        %v64933_v10 = vor.u32 %v64932_v30, %v64931_v34 (stack47)
        %v65346_v55 = vadd.s32 %v65342_v8, %v65330_v12 (stack40)
        %v65348_v52 = vshll.u32 %v65342_v8, 17 (stack45)
        %v63364_v7 = vmul.f32 1.4140625, %v63360_v24 (stack54)
        %v64138_v9 = vand.u32.u8 255, %v64137_v26 (stack49)
        %v64545_v21 = vxor.u32 %v64544_v31, %v64536_v40 (stack48)
        %v65349_v41 = vshrl.u32 %v65342_v8, 15 (stack46)
        %v64934_v50 = vxor.u32 %v64933_v10, %v64929_v46 (stack48)
        %v65771_v45 = vadd.s32 %v65768_v61, %v65763_v45 (stack40)
        %v65773_v12 = vshll.u32 %v65768_v61, 15 (stack45)
        %v65774_v29 = vshrl.u32 %v65768_v61, 17 (stack46)
        %v63367_v22 = vpack.c.bf16 %v157387_v11, %v63364_v7 (stack81)
        %v64139_v25 = vand.u32 65535, %v64138_v9 (stack50)
        %v64548_v40 = vadd.s32 %v64545_v21, %v121564_v0 (stack40)
        %v65350_v43 = vor.u32 %v65349_v41, %v65348_v52 (stack47)
        %v64937_v46 = vadd.s32 %v64934_v50, %v64929_v46 (stack40)
        %v64939_v60 = vshll.u32 %v64934_v50, 15 (stack45)
        %v64940_v20 = vshrl.u32 %v64934_v50, 17 (stack46)
        %v65775_v34 = vor.u32 %v65774_v29, %v65773_v12 (stack47)
        %v120976_v30 = vpop.eup %120975 (stack73)
        %120081 = vst [vmem:[%s123356_s30 + $0x340] sm:$0xf] /*vst_source=*/%v63367_v22 (stack83)
        %v64140_v8 = vshrl.u32 %v64139_v25, 1 (stack51)
        %v64552_v26 = vadd.s32 4, %v64548_v40 (stack40)
        %v65351_v31 = vxor.u32 %v65350_v43, %v65346_v55 (stack48)
        %v140883_v61 = vadd.s32 %v157458_v53, %v157089_v17 (stack40)
        %v63737_v24 = vmul.f32 %v120976_v30, %v140840_v44 (stack74)
        %v64941_v10 = vor.u32 %v64940_v20, %v64939_v60 (stack47)
        %v65776_v52 = vxor.u32 %v65775_v34, %v65771_v45 (stack48)
        %v140888_v7 = vadd.s32 %v157461_v6, %v157090_v62 (stack40)
        %v64141_v9 = vor.u32 16256, %v64140_v8 (stack47)
        %v64556_v42 = vadd.s32 %v64552_v26, %v64540_v42 (stack40)
        %v64558_v21 = vshll.u32 %v64552_v26, 13 (stack45)
        %v64559_v41 = vshrl.u32 %v64552_v26, 19 (stack46)
        %v63739_v50 = vsel /*vm=*/%vm63738_vm15, /*on_true_vy=*/%v140840_v44, /*on_false_vx=*/%v63737_v24 (stack75)
        %v64942_v12 = vxor.u32 %v64941_v10, %v64937_v46 (stack48)
        %v65354_v55 = vadd.s32 %v65351_v31, %v65346_v55 (stack40)
        %v65356_v29 = vshll.u32 %v65351_v31, 29 (stack45)
        %v63742_v56 = vsel /*vm=*/%vm63740_vm0, /*on_true_vy=*/%v63741_v56, /*on_false_vx=*/%v63739_v50 (stack76)
        %v64142_v22 = vand.u32.u16 65535, %v64141_v9 (stack52)
        %v64560_v25 = vor.u32 %v64559_v41, %v64558_v21 (stack47)
        %v65357_v40 = vshrl.u32 %v65351_v31, 3 (stack46)
        %v63745_v43 = vadd.f32 -3.0, %v63742_v56 (stack53)
        %v64945_v46 = vadd.s32 %v64942_v12, %v64937_v46 (stack40)
        %v64947_v60 = vshll.u32 %v64942_v12, 26 (stack45)
        %v64948_v20 = vshrl.u32 %v64942_v12, 6 (stack46)
        %v120088_v34 = vadd.low.f32.bf16 -1.0, %v64142_v22 (stack53)
        %v64561_v30 = vxor.u32 %v64560_v25, %v64556_v42 (stack48)
        %v65358_v8 = vor.u32 %v65357_v40, %v65356_v29 (stack47)
        %v65779_v45 = vadd.s32 %v65776_v52, %v65771_v45 (stack40)
        %v63730_v26 = vsel /*vm=*/%vm63693_vm14, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v140901_v54 = vsel /*vm=*/%vm63693_vm14, /*on_true_vy=*/%v140869_v54, /*on_false_vx=*/%v63745_v43 (stack44)
        %v64949_v31 = vor.u32 %v64948_v20, %v64947_v60 (stack47)
        %v65781_v24 = vshll.u32 %v65776_v52, 26 (stack45)
        %v63753_v10 = vmul.f32 %v140901_v54, %v63730_v26 (stack54)
        %v64151_v9 = vmul.f32 2.0, %v120088_v34 (stack54)
        %v64564_v42 = vadd.s32 %v64561_v30, %v64556_v42 (stack40)
        %v64566_v21 = vshll.u32 %v64561_v30, 15 (stack45)
        %v64567_v41 = vshrl.u32 %v64561_v30, 17 (stack46)
        %v64950_v50 = vxor.u32 %v64949_v31, %v64945_v46 (stack48)
        %v65359_v12 = vxor.u32 %v65358_v8, %v65354_v55 (stack48)
        %v65782_v52 = vshrl.u32 %v65776_v52, 6 (stack46)
        %v63722_v29 = vsel /*vm=*/%vm63693_vm14, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v63757_v32 = vadd.f32 %v63753_v10, %v140866_v32 (stack53)
        %v64155_v56 = vadd.f32 -0.99609375, %v64151_v9 (stack53)
        %vm66190_vm1 = vcmp.lt.u32.totalorder %v140883_v61, %v157089_v17 (stack43)
        %v64568_v22 = vor.u32 %v64567_v41, %v64566_v21 (stack47)
        %v64953_v25 = vadd.s32 %v64950_v50, %v64945_v46 (stack40)
        %v64959_v40 = vshll.u32 %v64950_v50, 6 (stack45)
        %v64960_v43 = vshrl.u32 %v64950_v50, 26 (stack46)
        %v63761_v46 = vmul.f32 %v63757_v32, %v140901_v54 (stack54)
        %v140911_v60 = vmax.f32 %v64155_v56, -0.99609375 (stack55)
        %v65362_v55 = vadd.s32 %v65359_v12, %v65354_v55 (stack40)
        %v65364_v20 = vshll.u32 %v65359_v12, 16 (stack45)
        %v64569_v34 = vxor.u32 %v64568_v22, %v64564_v42 (stack48)
        %v64961_v30 = vor.u32 %v64960_v43, %v64959_v40 (stack47)
        %v65365_v8 = vshrl.u32 %v65359_v12, 16 (stack46)
        %v65783_v26 = vor.u32 %v65782_v52, %v65781_v24 (stack47)
        %v140916_v31 = vsel /*vm=*/%vm63693_vm14, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v140921_v24 = vsel /*vm=*/%vm63693_vm14, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v63765_v10 = vadd.f32 %v63761_v46, %v63722_v29 (stack53)
        %v64171_v9 = vxor.u32 2147483648, %v140911_v60 (stack56)
        %v64572_v42 = vadd.s32 %v64569_v34, %v64564_v42 (stack40)
        %v64574_v21 = vshll.u32 %v64569_v34, 26 (stack45)
        %v64575_v41 = vshrl.u32 %v64569_v34, 6 (stack46)
        %v64962_v50 = vxor.u32 %v64961_v30, %v64953_v25 (stack48)
        %v63714_v12 = vsel /*vm=*/%vm63693_vm14, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v63769_v52 = vmul.f32 %v63765_v10, %v140901_v54 (stack54)
        %v64174_v29 = vmul.f32 %v64171_v9, %v140911_v60 (stack54)
        %v65366_v32 = vor.u32 %v65365_v8, %v65364_v20 (stack47)
        %v63718_v56 = vsel /*vm=*/%vm63693_vm14, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v64576_v22 = vor.u32 %v64575_v41, %v64574_v21 (stack47)
        %v64965_v40 = vadd.s32 %v64962_v50, %v121569_v1 (stack40)
        %v65784_v43 = vxor.u32 %v65783_v26, %v65779_v45 (stack48)
        %v63773_v46 = vadd.f32 %v63769_v52, %v63718_v56 (stack53)
        %v64176_v20 = vadd.f32 1.0, %v64174_v29 (stack57)
        %v64179_v34 = vmul.f32 -0.5, %v64174_v29 (stack59)
        %v64957_v25 = vadd.s32 %v64953_v25, %v121574_v2 (stack40)
        %v64577_v30 = vxor.u32 %v64576_v22, %v64572_v42 (stack48)
        %v64969_v8 = vadd.s32 3, %v64965_v40 (stack40)
        %v65367_v26 = vxor.u32 %v65366_v32, %v65362_v55 (stack48)
        %v65787_v45 = vadd.s32 %v65784_v43, %v65779_v45 (stack40)
        %v63777_v10 = vmul.f32 %v63773_v46, %v140901_v54 (stack54)
        %120977 = vlog2.f32 %v64176_v20 (stack58)
        %v64180_v9 = vadd.f32 1.0, %v64179_v34 (stack61)
        %v66181_v21 = vadd.s32 %v140883_v61, %v122657_v58 (stack40)
        %v64580_v42 = vadd.s32 %v64577_v30, %v64572_v42 (stack40)
        %v64586_v41 = vshll.u32 %v64577_v30, 6 (stack45)
        %v64587_v50 = vshrl.u32 %v64577_v30, 26 (stack46)
        %v64973_v52 = vadd.s32 %v64969_v8, %v64957_v25 (stack40)
        %v63710_v32 = vsel /*vm=*/%vm63693_vm14, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v63781_v12 = vadd.f32 %v63777_v10, %v63714_v12 (stack53)
        %v64975_v56 = vshll.u32 %v64969_v8, 17 (stack45)
        %v64976_v22 = vshrl.u32 %v64969_v8, 15 (stack46)
        %v64182_v40 = vand.u32 2147483647, %v64174_v29 (stack60)
        %v64588_v46 = vor.u32 %v64587_v50, %v64586_v41 (stack47)
        %v65370_v55 = vadd.s32 %v65367_v26, %v65362_v55 (stack40)
        %v65376_v20 = vshll.u32 %v65367_v26, 24 (stack45)
        %v63785_v34 = vmul.f32 %v63781_v12, %v140901_v54 (stack54)
        %v64977_v25 = vor.u32 %v64976_v22, %v64975_v56 (stack47)
        %v65377_v30 = vshrl.u32 %v65367_v26, 8 (stack46)
        %vm66185_vm2 = vcmp.lt.u32.totalorder %v66181_v21, %v140883_v61 (stack43)
        %v64181_v29 = vmul.f32 %v64180_v9, %v64174_v29 (stack63)
        %v64589_v8 = vxor.u32 %v64588_v46, %v64580_v42 (stack48)
        %v65793_v26 = vshll.u32 %v65784_v43, 6 (stack45)
        %v65794_v43 = vshrl.u32 %v65784_v43, 26 (stack46)
        %v63789_v10 = vadd.f32 %v63785_v34, %v63710_v32 (stack53)
        %v64584_v9 = vadd.s32 %v64580_v42, %v121564_v0 (stack40)
        %v64978_v42 = vxor.u32 %v64977_v25, %v64973_v52 (stack48)
        %v65378_v41 = vor.u32 %v65377_v30, %v65376_v20 (stack47)
        %vm140943_vm3 = vcmp.lt.f32.partialorder %v64182_v40, 0.0004427343 (stack62)
        %v64592_v32 = vadd.s32 %v64589_v8, %v121574_v2 (stack40)
        %v65795_v12 = vor.u32 %v65794_v43, %v65793_v26 (stack47)
        %v66199_v56 = vadd.s32 1, %v140888_v7 (stack40)
        %v140951_v22 = vadd.s32 %v157458_v53, %v157091_v37 (stack40)
        %v63793_v40 = vmul.f32 %v63789_v10, %v140901_v54 (stack54)
        %v64981_v52 = vadd.s32 %v64978_v42, %v64973_v52 (stack40)
        %v64983_v46 = vshll.u32 %v64978_v42, 29 (stack45)
        %v64984_v20 = vshrl.u32 %v64978_v42, 3 (stack46)
        %v64596_v34 = vadd.s32 5, %v64592_v32 (stack40)
        %v65379_v25 = vxor.u32 %v65378_v41, %v65370_v55 (stack48)
        %v65796_v30 = vxor.u32 %v65795_v12, %v65787_v45 (stack48)
        %v66203_v7 = vsel /*vm=*/%vm66190_vm1, /*on_true_vy=*/%v66199_v56, /*on_false_vx=*/%v140888_v7 (stack44)
        %v63797_v24 = vadd.f32 %v63793_v40, %v140921_v24 (stack53)
        %v64985_v8 = vor.u32 %v64984_v20, %v64983_v46 (stack47)
        %v65791_v45 = vadd.s32 %v65787_v45, %v121569_v1 (stack40)
        %v66207_v26 = vadd.s32 1, %v66203_v7 (stack40)
        %v64598_v43 = vxor.u32 %v64596_v34, %v64584_v9 (stack48)
        %v65374_v55 = vadd.s32 %v65370_v55, %v121564_v0 (stack40)
        %v65382_v10 = vadd.s32 %v65379_v25, %v121574_v2 (stack40)
        %v65799_v9 = vadd.s32 %v65796_v30, %v121564_v0 (stack40)
        %v63801_v42 = vmul.f32 %v63797_v24, %v140901_v54 (stack54)
        %v64986_v41 = vxor.u32 %v64985_v8, %v64981_v52 (stack48)
        %v66211_v61 = vsel /*vm=*/%vm66185_vm2, /*on_true_vy=*/%v66207_v26, /*on_false_vx=*/%v66203_v7 (stack44)
        %v66220_v21 = vadd.s32 %v66181_v21, %v121569_v1 (stack40)
        %v120978_v32 = vpop.eup %120977 (stack64)
        %v64599_v12 = vand.u32.u8 255, %v64598_v43 (stack49)
        %v65386_v56 = vadd.s32 2, %v65382_v10 (stack40)
        %v65803_v40 = vadd.s32 1, %v65799_v9 (stack40)
        %v66216_v46 = vadd.s32 %v66211_v61, %v121574_v2 (stack40)
        %v63805_v31 = vadd.f32 %v63801_v42, %v140916_v31 (stack53)
        %v64178_v20 = vmul.f32 0.6931472, %v120978_v32 (stack65)
        %v64989_v52 = vadd.s32 %v64986_v41, %v64981_v52 (stack40)
        %v64991_v34 = vshll.u32 %v64986_v41, 16 (stack45)
        %v64600_v25 = vand.u32 65535, %v64599_v12 (stack50)
        %v64992_v30 = vshrl.u32 %v64986_v41, 16 (stack46)
        %v65390_v7 = vadd.s32 %v65386_v56, %v65374_v55 (stack40)
        %v65392_v24 = vshll.u32 %v65386_v56, 13 (stack45)
        %v63809_v54 = vmul.f32 %v63805_v31, %v140901_v54 (stack54)
        %v64184_v29 = vsel /*vm=*/%vm140943_vm3, /*on_true_vy=*/%v64181_v29, /*on_false_vx=*/%v64178_v20 (stack66)
        %v65393_v50 = vshrl.u32 %v65386_v56, 19 (stack46)
        %v65807_v8 = vadd.s32 %v65803_v40, %v65791_v45 (stack40)
        %v63698_v44 = vsel /*vm=*/%vm63693_vm14, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v140975_v45 = vxor.u32 2147483648, %v64184_v29 (stack56)
        %v64993_v26 = vor.u32 %v64992_v30, %v64991_v34 (stack47)
        %vm140979_vm4 = vcmp.eq.f32.partialorder %v63666_v27, 1.0 (stack68)
        %v63674_v43 = vmul.f32 inf, %v140779_v23 (stack54)
        %v63813_v55 = vadd.f32 %v63809_v54, %v63698_v44 (stack53)
        %v66224_v10 = vadd.s32 %v66220_v21, %v66216_v46 (stack40)
        %v64161_v9 = vand.u32 2147483647, %v140911_v60 (stack77)
        %vm64188_vm5 = vcmp.lt.f32.partialorder %v140975_v45, 5.0 (stack68)
        %120979 = vrsqrt.f32 %v140975_v45 (stack67)
        %v64601_v42 = vshrl.u32 %v64600_v25, 1 (stack51)
        %v63817_v23 = vmul.f32 %v63813_v55, %v140779_v23 (stack54)
        %v140989_v41 = vmul.f32 inf, %v140911_v60 (stack54)
        %v65394_v61 = vor.u32 %v65393_v50, %v65392_v24 (stack47)
        %v66226_v32 = vshll.u32 %v66220_v21, 13 (stack45)
        %v64994_v12 = vxor.u32 %v64993_v26, %v64989_v52 (stack48)
        %v65809_v56 = vshll.u32 %v65803_v40, 17 (stack45)
        %v65810_v40 = vshrl.u32 %v65803_v40, 15 (stack46)
        %v66227_v21 = vshrl.u32 %v66220_v21, 19 (stack46)
        %v63821_v46 = vsel /*vm=*/%vm140979_vm4, /*on_true_vy=*/%v63674_v43, /*on_false_vx=*/%v63817_v23 (stack44)
        %v140996_v31 = vsel /*vm=*/%vm64188_vm5, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v140999_v20 = vadd.f32 -2.5, %v140975_v45 (stack53)
        %v141003_v34 = vadd.s32 %v140951_v22, %v122657_v58 (stack40)
        %v63825_v25 = vmul.f32 1.4140625, %v63821_v46 (stack54)
        %v141008_v30 = vsel /*vm=*/%vm64188_vm5, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v141013_v24 = vsel /*vm=*/%vm64188_vm5, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v64602_v54 = vor.u32 16256, %v64601_v42 (stack47)
        %v64997_v52 = vadd.s32 %v64994_v12, %v64989_v52 (stack40)
        %v65003_v29 = vshll.u32 %v64994_v12, 24 (stack45)
        %v65004_v50 = vshrl.u32 %v64994_v12, 8 (stack46)
        %v65395_v44 = vxor.u32 %v65394_v61, %v65390_v7 (stack48)
        %v63828_v26 = vpack.c.bf16 %v157387_v11, %v63825_v25 (stack81)
        %v64603_v27 = vand.u32.u16 65535, %v64602_v54 (stack52)
        %v65811_v43 = vor.u32 %v65810_v40, %v65809_v56 (stack47)
        %v66228_v55 = vor.u32 %v66227_v21, %v66226_v32 (stack47)
        %v141019_v42 = vsel /*vm=*/%vm64188_vm5, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %vm64233_vm6 = vcmp.eq.f32.partialorder %v140975_v45, inf (stack70)
        %v65005_v23 = vor.u32 %v65004_v50, %v65003_v29 (stack47)
        %v65398_v7 = vadd.s32 %v65395_v44, %v65390_v7 (stack40)
        %v65400_v61 = vshll.u32 %v65395_v44, 15 (stack45)
        %120083 = vst [vmem:[%s123356_s30 + $0x3c0] sm:$0xf] /*vst_source=*/%v63828_v26 (stack83)
        %v120090_v32 = vadd.low.f32.bf16 -1.0, %v64603_v27 (stack53)
        %v65401_v12 = vshrl.u32 %v65395_v44, 17 (stack46)
        %v65812_v56 = vxor.u32 %v65811_v43, %v65807_v8 (stack48)
        %v66229_v40 = vxor.u32 %v66228_v55, %v66224_v10 (stack48)
        %v141026_v21 = vsel /*vm=*/%vm64188_vm5, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v65006_v46 = vxor.u32 %v65005_v23, %v64997_v52 (stack48)
        %vm66651_vm7 = vcmp.lt.u32.totalorder %v140951_v22, %v157091_v37 (stack43)
        %v141032_v25 = vadd.s32 %v157461_v6, %v157094_v36 (stack40)
        %v64612_v54 = vmul.f32 2.0, %v120090_v32 (stack54)
        %v65402_v29 = vor.u32 %v65401_v12, %v65400_v61 (stack47)
        %v65815_v8 = vadd.s32 %v65812_v56, %v65807_v8 (stack40)
        %v65817_v50 = vshll.u32 %v65812_v56, 29 (stack45)
        %v141037_v44 = vsel /*vm=*/%vm64188_vm5, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v65009_v26 = vadd.s32 %v65006_v46, %v121564_v0 (stack40)
        %v65818_v27 = vshrl.u32 %v65812_v56, 3 (stack46)
        %v66232_v10 = vadd.s32 %v66229_v40, %v66224_v10 (stack40)
        %vm64235_vm8 = vcmp.eq.f32.partialorder %v140975_v45, 0.0 (stack71)
        %v64236_v43 = vand.u32 2147483648, %v140975_v45 (stack72)
        %v64616_v55 = vadd.f32 -0.99609375, %v64612_v54 (stack53)
        %v65403_v23 = vxor.u32 %v65402_v29, %v65398_v7 (stack48)
        %v120980_v61 = vpop.eup %120979 (stack73)
        %v65001_v52 = vadd.s32 %v64997_v52, %v121569_v1 (stack40)
        %v65013_v32 = vadd.s32 4, %v65009_v26 (stack40)
        %v65819_v12 = vor.u32 %v65818_v27, %v65817_v50 (stack47)
        %v141045_v53 = vadd.s32 %v157458_v53, %v157095_v13 (stack40)
        %v64232_v56 = vmul.f32 %v120980_v61, %v140975_v45 (stack74)
        %v141048_v46 = vmax.f32 %v64616_v55, -0.99609375 (stack55)
        %v65406_v7 = vadd.s32 %v65403_v23, %v65398_v7 (stack40)
        %v65408_v54 = vshll.u32 %v65403_v23, 26 (stack45)
        %v65017_v29 = vadd.s32 %v65013_v32, %v65001_v52 (stack40)
        %v65019_v50 = vshll.u32 %v65013_v32, 13 (stack45)
        %v65020_v26 = vshrl.u32 %v65013_v32, 19 (stack46)
        %v65409_v27 = vshrl.u32 %v65403_v23, 6 (stack46)
        %v64234_v55 = vsel /*vm=*/%vm64233_vm6, /*on_true_vy=*/%v140975_v45, /*on_false_vx=*/%v64232_v56 (stack75)
        %v64632_v23 = vxor.u32 2147483648, %v141048_v46 (stack56)
        %v66234_v61 = vshll.u32 %v66229_v40, 15 (stack45)
        %v66235_v40 = vshrl.u32 %v66229_v40, 17 (stack46)
        %v64237_v43 = vsel /*vm=*/%vm64235_vm8, /*on_true_vy=*/%v64236_v43, /*on_false_vx=*/%v64234_v55 (stack76)
        %v65021_v52 = vor.u32 %v65020_v26, %v65019_v50 (stack47)
        %v65410_v32 = vor.u32 %v65409_v27, %v65408_v54 (stack47)
        %v65820_v12 = vxor.u32 %v65819_v12, %v65815_v8 (stack48)
        %v64217_v56 = vsel /*vm=*/%vm64188_vm5, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v64221_v54 = vsel /*vm=*/%vm64188_vm5, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v64240_v50 = vadd.f32 -3.0, %v64237_v43 (stack53)
        %v141063_v26 = vmul.f32 %v64632_v23, %v141048_v46 (stack54)
        %v64225_v27 = vsel /*vm=*/%vm64188_vm5, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v65022_v55 = vxor.u32 %v65021_v52, %v65017_v29 (stack48)
        %v65411_v23 = vxor.u32 %v65410_v32, %v65406_v7 (stack48)
        %v65823_v8 = vadd.s32 %v65820_v12, %v65815_v8 (stack40)
        %v141071_v45 = vsel /*vm=*/%vm64188_vm5, /*on_true_vy=*/%v140999_v20, /*on_false_vx=*/%v64240_v50 (stack44)
        %v64637_v20 = vadd.f32 1.0, %v141063_v26 (stack57)
        %v66236_v61 = vor.u32 %v66235_v40, %v66234_v61 (stack47)
        %vm66646_vm9 = vcmp.lt.u32.totalorder %v141003_v34, %v140951_v22 (stack43)
        %v64248_v40 = vmul.f32 %v141071_v45, %v64225_v27 (stack54)
        %v65025_v29 = vadd.s32 %v65022_v55, %v65017_v29 (stack40)
        %v65027_v43 = vshll.u32 %v65022_v55, 15 (stack45)
        %v65028_v52 = vshrl.u32 %v65022_v55, 17 (stack46)
        %120981 = vlog2.f32 %v64637_v20 (stack58)
        %v65414_v7 = vadd.s32 %v65411_v23, %v65406_v7 (stack40)
        %v65825_v32 = vshll.u32 %v65820_v12, 16 (stack45)
        %v66660_v50 = vadd.s32 1, %v141032_v25 (stack40)
        %v64252_v54 = vadd.f32 %v64248_v40, %v64221_v54 (stack53)
        %v65029_v27 = vor.u32 %v65028_v52, %v65027_v43 (stack47)
        %v65420_v55 = vshll.u32 %v65411_v23, 6 (stack45)
        %v65421_v23 = vshrl.u32 %v65411_v23, 26 (stack46)
        %v64640_v20 = vmul.f32 -0.5, %v141063_v26 (stack59)
        %v65826_v12 = vshrl.u32 %v65820_v12, 16 (stack46)
        %v66237_v61 = vxor.u32 %v66236_v61, %v66232_v10 (stack48)
        %v141081_v40 = vadd.s32 %v141003_v34, %v121569_v1 (stack40)
        %v64256_v43 = vmul.f32 %v64252_v54, %v141071_v45 (stack54)
        %v65030_v52 = vxor.u32 %v65029_v27, %v65025_v29 (stack48)
        %v65422_v54 = vor.u32 %v65421_v23, %v65420_v55 (stack47)
        %v66664_v25 = vsel /*vm=*/%vm66651_vm7, /*on_true_vy=*/%v66660_v50, /*on_false_vx=*/%v141032_v25 (stack44)
        %v65827_v32 = vor.u32 %v65826_v12, %v65825_v32 (stack47)
        %v66240_v10 = vadd.s32 %v66237_v61, %v66232_v10 (stack40)
        %v66242_v50 = vshll.u32 %v66237_v61, 26 (stack45)
        %v66243_v27 = vshrl.u32 %v66237_v61, 6 (stack46)
        %v64260_v56 = vadd.f32 %v64256_v43, %v64217_v56 (stack53)
        %v65033_v29 = vadd.s32 %v65030_v52, %v65025_v29 (stack40)
        %v65035_v55 = vshll.u32 %v65030_v52, 26 (stack45)
        %v65036_v23 = vshrl.u32 %v65030_v52, 6 (stack46)
        %v65423_v12 = vxor.u32 %v65422_v54, %v65414_v7 (stack48)
        %v65828_v61 = vxor.u32 %v65827_v32, %v65823_v8 (stack48)
        %v66244_v43 = vor.u32 %v66243_v27, %v66242_v50 (stack47)
        %v66668_v52 = vadd.s32 1, %v66664_v25 (stack40)
        %v64264_v54 = vmul.f32 %v64260_v56, %v141071_v45 (stack54)
        %v64641_v20 = vadd.f32 1.0, %v64640_v20 (stack61)
        %v64643_v32 = vand.u32 2147483647, %v141063_v26 (stack60)
        %v65037_v50 = vor.u32 %v65036_v23, %v65035_v55 (stack47)
        %v65426_v27 = vadd.s32 %v65423_v12, %v121569_v1 (stack40)
        %v65831_v8 = vadd.s32 %v65828_v61, %v65823_v8 (stack40)
        %v65837_v56 = vshll.u32 %v65828_v61, 24 (stack45)
        %v65838_v55 = vshrl.u32 %v65828_v61, 8 (stack46)
        %v64268_v44 = vadd.f32 %v64264_v54, %v141037_v44 (stack53)
        %v65038_v23 = vxor.u32 %v65037_v50, %v65033_v29 (stack48)
        %v66245_v12 = vxor.u32 %v66244_v43, %v66240_v10 (stack48)
        %v66672_v22 = vsel /*vm=*/%vm66646_vm9, /*on_true_vy=*/%v66668_v52, /*on_false_vx=*/%v66664_v25 (stack44)
        %v65418_v34 = vadd.s32 %v65414_v7, %v121574_v2 (stack40)
        %v65430_v7 = vadd.s32 3, %v65426_v27 (stack40)
        %v65839_v25 = vor.u32 %v65838_v55, %v65837_v56 (stack47)
        %v66677_v61 = vadd.s32 %v66672_v22, %v121574_v2 (stack40)
        %v64272_v43 = vmul.f32 %v64268_v44, %v141071_v45 (stack54)
        %v65041_v29 = vadd.s32 %v65038_v23, %v65033_v29 (stack40)
        %v65047_v52 = vshll.u32 %v65038_v23, 6 (stack45)
        %v65048_v54 = vshrl.u32 %v65038_v23, 26 (stack46)
        %v65434_v50 = vadd.s32 %v65430_v7, %v65418_v34 (stack40)
        %v65436_v27 = vshll.u32 %v65430_v7, 17 (stack45)
        %v65437_v56 = vshrl.u32 %v65430_v7, 15 (stack46)
        %v65840_v55 = vxor.u32 %v65839_v25, %v65831_v8 (stack48)
        %v120982_v44 = vpop.eup %120981 (stack64)
        %v64276_v21 = vadd.f32 %v64272_v43, %v141026_v21 (stack53)
        %v64622_v23 = vand.u32 2147483647, %v141048_v46 (stack77)
        %v65049_v22 = vor.u32 %v65048_v54, %v65047_v52 (stack47)
        %v66248_v10 = vadd.s32 %v66245_v12, %v66240_v10 (stack40)
        %v64639_v34 = vmul.f32 0.6931472, %v120982_v44 (stack65)
        %v64642_v26 = vmul.f32 %v64641_v20, %v141063_v26 (stack63)
        %v65438_v20 = vor.u32 %v65437_v56, %v65436_v27 (stack47)
        %v65843_v7 = vadd.s32 %v65840_v55, %v121574_v2 (stack40)
        %v64280_v25 = vmul.f32 %v64276_v21, %v141071_v45 (stack54)
        %vm64644_vm10 = vcmp.lt.f32.partialorder %v64643_v32, 0.0004427343 (stack62)
        %v65050_v32 = vxor.u32 %v65049_v22, %v65041_v29 (stack48)
        %v65835_v8 = vadd.s32 %v65831_v8, %v121564_v0 (stack40)
        %v64645_v43 = vsel /*vm=*/%vm64644_vm10, /*on_true_vy=*/%v64642_v26, /*on_false_vx=*/%v64639_v34 (stack66)
        %v65439_v52 = vxor.u32 %v65438_v20, %v65434_v50 (stack48)
        %v65847_v54 = vadd.s32 2, %v65843_v7 (stack40)
        %v141105_v61 = vadd.s32 %v141081_v40, %v66677_v61 (stack40)
        %v64284_v42 = vadd.f32 %v64280_v25, %v141019_v42 (stack53)
        %v141108_v27 = vxor.u32 2147483648, %v64645_v43 (stack56)
        %v66254_v56 = vshll.u32 %v66245_v12, 6 (stack45)
        %v66255_v12 = vshrl.u32 %v66245_v12, 26 (stack46)
        %v65442_v50 = vadd.s32 %v65439_v52, %v65434_v50 (stack40)
        %v65444_v55 = vshll.u32 %v65439_v52, 29 (stack45)
        %v65445_v44 = vshrl.u32 %v65439_v52, 3 (stack46)
        %v65851_v21 = vadd.s32 %v65847_v54, %v65835_v8 (stack40)
        %v64288_v22 = vmul.f32 %v64284_v42, %v141071_v45 (stack54)
        %vm64649_vm11 = vcmp.lt.f32.partialorder %v141108_v27, 5.0 (stack68)
        %120983 = vrsqrt.f32 %v141108_v27 (stack67)
        %v66687_v34 = vshll.u32 %v141081_v40, 13 (stack45)
        %v65045_v29 = vadd.s32 %v65041_v29, %v121564_v0 (stack40)
        %v65053_v26 = vadd.s32 %v65050_v32, %v121574_v2 (stack40)
        %v65446_v20 = vor.u32 %v65445_v44, %v65444_v55 (stack47)
        %v66688_v40 = vshrl.u32 %v141081_v40, 19 (stack46)
        %v64292_v24 = vadd.f32 %v64288_v22, %v141013_v24 (stack53)
        %v141119_v7 = vadd.f32 -2.5, %v141108_v27 (stack53)
        %v66252_v25 = vadd.s32 %v66248_v10, %v121569_v1 (stack40)
        %v66256_v32 = vor.u32 %v66255_v12, %v66254_v56 (stack47)
        %v141125_v8 = vsel /*vm=*/%vm64649_vm11, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v141130_v43 = vsel /*vm=*/%vm64649_vm11, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v141135_v52 = vsel /*vm=*/%vm64649_vm11, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v65447_v42 = vxor.u32 %v65446_v20, %v65442_v50 (stack48)
        %v64296_v56 = vmul.f32 %v64292_v24, %v141071_v45 (stack54)
        %v141141_v12 = vsel /*vm=*/%vm64649_vm11, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v141146_v55 = vsel /*vm=*/%vm64649_vm11, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v141151_v44 = vsel /*vm=*/%vm64649_vm11, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %vm141155_vm12 = vcmp.eq.f32.partialorder %v64161_v9, 1.0 (stack68)
        %v65057_v22 = vadd.s32 5, %v65053_v26 (stack40)
        %v65450_v50 = vadd.s32 %v65447_v42, %v65442_v50 (stack40)
        %v65452_v26 = vshll.u32 %v65447_v42, 16 (stack45)
        %v65453_v20 = vshrl.u32 %v65447_v42, 16 (stack46)
        %v64300_v30 = vadd.f32 %v64296_v56, %v141008_v30 (stack53)
        %v65853_v24 = vshll.u32 %v65847_v54, 13 (stack45)
        %v65854_v54 = vshrl.u32 %v65847_v54, 19 (stack46)
        %v66257_v10 = vxor.u32 %v66256_v32, %v66248_v10 (stack48)
        %vm64694_vm13 = vcmp.eq.f32.partialorder %v141108_v27, inf (stack70)
        %v65059_v29 = vxor.u32 %v65057_v22, %v65045_v29 (stack48)
        %v65454_v32 = vor.u32 %v65453_v20, %v65452_v26 (stack47)
        %v66689_v34 = vor.u32 %v66688_v40, %v66687_v34 (stack47)
        %v64304_v45 = vmul.f32 %v64300_v30, %v141071_v45 (stack54)
        %v65855_v40 = vor.u32 %v65854_v54, %v65853_v24 (stack47)
        %v66260_v42 = vadd.s32 %v66257_v10, %v121564_v0 (stack40)
        %vm67112_vm14 = vcmp.lt.u32.totalorder %v141045_v53, %v157095_v13 (stack43)
        %vm64696_vm15 = vcmp.eq.f32.partialorder %v141108_v27, 0.0 (stack71)
        %v65060_v56 = vand.u32.u8 255, %v65059_v29 (stack49)
        %v65455_v22 = vxor.u32 %v65454_v32, %v65450_v50 (stack48)
        %v141167_v26 = vxor.u32 %v66689_v34, %v141105_v61 (stack48)
        %v64308_v31 = vadd.f32 %v64304_v45, %v140996_v31 (stack53)
        %v65856_v20 = vxor.u32 %v65855_v40, %v65851_v21 (stack48)
        %v66264_v30 = vadd.s32 1, %v66260_v42 (stack40)
        %v67117_v6 = vadd.s32 %v157461_v6, %v157100_v14 (stack40)
        %v65061_v24 = vand.u32 65535, %v65060_v56 (stack50)
        %v65458_v50 = vadd.s32 %v65455_v22, %v65450_v50 (stack40)
        %v65464_v54 = vshll.u32 %v65455_v22, 24 (stack45)
        %v65465_v10 = vshrl.u32 %v65455_v22, 8 (stack46)
        %v64312_v60 = vmul.f32 %v64308_v31, %v140911_v60 (stack54)
        %v65859_v21 = vadd.s32 %v65856_v20, %v65851_v21 (stack40)
        %v65861_v29 = vshll.u32 %v65856_v20, 15 (stack45)
        %v65862_v32 = vshrl.u32 %v65856_v20, 17 (stack46)
        %v120984_v34 = vpop.eup %120983 (stack73)
        %v64697_v45 = vand.u32 2147483648, %v141108_v27 (stack72)
        %v65062_v40 = vshrl.u32 %v65061_v24, 1 (stack51)
        %v65466_v42 = vor.u32 %v65465_v10, %v65464_v54 (stack47)
        %v66268_v25 = vadd.s32 %v66264_v30, %v66252_v25 (stack40)
        %v64316_v41 = vsel /*vm=*/%vm141155_vm12, /*on_true_vy=*/%v140989_v41, /*on_false_vx=*/%v64312_v60 (stack44)
        %v64693_v9 = vmul.f32 %v120984_v34, %v141108_v27 (stack74)
        %v65863_v56 = vor.u32 %v65862_v32, %v65861_v29 (stack47)
        %v66270_v22 = vshll.u32 %v66264_v30, 17 (stack45)
        %v64320_v31 = vmul.f32 1.4140625, %v64316_v41 (stack54)
        %v65063_v20 = vor.u32 16256, %v65062_v40 (stack47)
        %v65467_v24 = vxor.u32 %v65466_v42, %v65458_v50 (stack48)
        %v66271_v30 = vshrl.u32 %v66264_v30, 15 (stack46)
        %v64695_v54 = vsel /*vm=*/%vm64694_vm13, /*on_true_vy=*/%v141108_v27, /*on_false_vx=*/%v64693_v9 (stack75)
        %v65864_v10 = vxor.u32 %v65863_v56, %v65859_v21 (stack48)
        %v141183_v61 = vadd.s32 %v141167_v26, %v141105_v61 (stack40)
        %v141187_v60 = vadd.s32 %v141045_v53, %v122657_v58 (stack40)
        %v64323_v29 = vpack.c.bf16 %v157387_v11, %v64320_v31 (stack81)
        %v64698_v32 = vsel /*vm=*/%vm64696_vm15, /*on_true_vy=*/%v64697_v45, /*on_false_vx=*/%v64695_v54 (stack76)
        %v65064_v34 = vand.u32.u16 65535, %v65063_v20 (stack52)
        %v65470_v45 = vadd.s32 %v65467_v24, %v121564_v0 (stack40)
        %v64701_v40 = vadd.f32 -3.0, %v64698_v32 (stack53)
        %v65867_v21 = vadd.s32 %v65864_v10, %v65859_v21 (stack40)
        %v65869_v42 = vshll.u32 %v65864_v10, 26 (stack45)
        %v65870_v41 = vshrl.u32 %v65864_v10, 6 (stack46)
        %120089 = vst [vmem:[%s123356_s30 + $0x44] sm:$0xf] /*vst_source=*/%v64323_v29 (stack83)
        %v120092_v9 = vadd.low.f32.bf16 -1.0, %v65064_v34 (stack53)
        %v65462_v50 = vadd.s32 %v65458_v50, %v121569_v1 (stack40)
        %v65474_v56 = vadd.s32 4, %v65470_v45 (stack40)
        %v66272_v22 = vor.u32 %v66271_v30, %v66270_v22 (stack47)
        %v141198_v7 = vsel /*vm=*/%vm64649_vm11, /*on_true_vy=*/%v141119_v7, /*on_false_vx=*/%v64701_v40 (stack44)
        %v65871_v31 = vor.u32 %v65870_v41, %v65869_v42 (stack47)
        %v66695_v20 = vshll.u32 %v141167_v26, 15 (stack45)
        %v67121_v24 = vadd.s32 1, %v67117_v6 (stack40)
        %v64709_v44 = vmul.f32 %v141198_v7, %v141151_v44 (stack54)
        %v65073_v30 = vmul.f32 2.0, %v120092_v9 (stack54)
        %v65478_v54 = vadd.s32 %v65474_v56, %v65462_v50 (stack40)
        %v65480_v10 = vshll.u32 %v65474_v56, 13 (stack45)
        %v65481_v29 = vshrl.u32 %v65474_v56, 19 (stack46)
        %v65872_v32 = vxor.u32 %v65871_v31, %v65867_v21 (stack48)
        %v66273_v34 = vxor.u32 %v66272_v22, %v66268_v25 (stack48)
        %v66696_v26 = vshrl.u32 %v141167_v26, 17 (stack46)
        %v64713_v55 = vadd.f32 %v64709_v44, %v141146_v55 (stack53)
        %v65077_v45 = vadd.f32 -0.99609375, %v65073_v30 (stack53)
        %v67125_v6 = vsel /*vm=*/%vm67112_vm14, /*on_true_vy=*/%v67121_v24, /*on_false_vx=*/%v67117_v6 (stack44)
        %v141210_v40 = vadd.s32 %v141187_v60, %v121569_v1 (stack40)
        %v65482_v42 = vor.u32 %v65481_v29, %v65480_v10 (stack47)
        %v65875_v21 = vadd.s32 %v65872_v32, %v65867_v21 (stack40)
        %v65881_v41 = vshll.u32 %v65872_v32, 6 (stack45)
        %v65882_v9 = vshrl.u32 %v65872_v32, 26 (stack46)
        %v64717_v50 = vmul.f32 %v64713_v55, %v141198_v7 (stack54)
        %v141213_v56 = vmax.f32 %v65077_v45, -0.99609375 (stack55)
        %v66276_v25 = vadd.s32 %v66273_v34, %v66268_v25 (stack40)
        %v66278_v22 = vshll.u32 %v66273_v34, 29 (stack45)
        %v65483_v31 = vxor.u32 %v65482_v42, %v65478_v54 (stack48)
        %v65883_v24 = vor.u32 %v65882_v9, %v65881_v41 (stack47)
        %v66279_v44 = vshrl.u32 %v66273_v34, 3 (stack46)
        %v66697_v20 = vor.u32 %v66696_v26, %v66695_v20 (stack47)
        %v64670_v30 = vsel /*vm=*/%vm64649_vm11, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v64674_v10 = vsel /*vm=*/%vm64649_vm11, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v64721_v12 = vadd.f32 %v64717_v50, %v141141_v12 (stack53)
        %v65093_v29 = vxor.u32 2147483648, %v141213_v56 (stack56)
        %v65486_v54 = vadd.s32 %v65483_v31, %v65478_v54 (stack40)
        %v65488_v32 = vshll.u32 %v65483_v31, 15 (stack45)
        %v65489_v34 = vshrl.u32 %v65483_v31, 17 (stack46)
        %v65884_v26 = vxor.u32 %v65883_v24, %v65875_v21 (stack48)
        %v64725_v55 = vmul.f32 %v64721_v12, %v141198_v7 (stack54)
        %v65096_v45 = vmul.f32 %v65093_v29, %v141213_v56 (stack54)
        %v66280_v42 = vor.u32 %v66279_v44, %v66278_v22 (stack47)
        %vm67107_vm0 = vcmp.lt.u32.totalorder %v141187_v60, %v141045_v53 (stack43)
        %v65490_v41 = vor.u32 %v65489_v34, %v65488_v32 (stack47)
        %v65887_v9 = vadd.s32 %v65884_v26, %v121569_v1 (stack40)
        %v66698_v50 = vxor.u32 %v66697_v20, %v141183_v61 (stack48)
        %v67148_v22 = vshll.u32 %v141210_v40, 13 (stack45)
        %v64729_v31 = vadd.f32 %v64725_v55, %v64674_v10 (stack53)
        %v65098_v24 = vadd.f32 1.0, %v65096_v45 (stack57)
        %v65101_v44 = vmul.f32 -0.5, %v65096_v45 (stack59)
        %v65879_v21 = vadd.s32 %v65875_v21, %v121574_v2 (stack40)
        %v65491_v20 = vxor.u32 %v65490_v41, %v65486_v54 (stack48)
        %v65891_v10 = vadd.s32 3, %v65887_v9 (stack40)
        %v66281_v12 = vxor.u32 %v66280_v42, %v66276_v25 (stack48)
        %v66701_v61 = vadd.s32 %v66698_v50, %v141183_v61 (stack40)
        %v64733_v29 = vmul.f32 %v64729_v31, %v141198_v7 (stack54)
        %120985 = vlog2.f32 %v65098_v24 (stack58)
        %v65104_v32 = vand.u32 2147483647, %v65096_v45 (stack60)
        %v67129_v34 = vadd.s32 1, %v67125_v6 (stack40)
        %v65494_v54 = vadd.s32 %v65491_v20, %v65486_v54 (stack40)
        %v65496_v26 = vshll.u32 %v65491_v20, 26 (stack45)
        %v65497_v55 = vshrl.u32 %v65491_v20, 6 (stack46)
        %v65895_v42 = vadd.s32 %v65891_v10, %v65879_v21 (stack40)
        %v64737_v30 = vadd.f32 %v64733_v29, %v64670_v30 (stack53)
        %v65102_v41 = vadd.f32 1.0, %v65101_v44 (stack61)
        %v65897_v9 = vshll.u32 %v65891_v10, 17 (stack45)
        %v65898_v31 = vshrl.u32 %v65891_v10, 15 (stack46)
        %v65498_v24 = vor.u32 %v65497_v55, %v65496_v26 (stack47)
        %v66284_v25 = vadd.s32 %v66281_v12, %v66276_v25 (stack40)
        %v66286_v44 = vshll.u32 %v66281_v12, 16 (stack45)
        %v66287_v21 = vshrl.u32 %v66281_v12, 16 (stack46)
        %v64741_v20 = vmul.f32 %v64737_v30, %v141198_v7 (stack54)
        %v65899_v10 = vor.u32 %v65898_v31, %v65897_v9 (stack47)
        %v66703_v12 = vshll.u32 %v66698_v50, 26 (stack45)
        %v66704_v50 = vshrl.u32 %v66698_v50, 6 (stack46)
        %v65499_v29 = vxor.u32 %v65498_v24, %v65494_v54 (stack48)
        %v66288_v26 = vor.u32 %v66287_v21, %v66286_v44 (stack47)
        %v67133_v53 = vsel /*vm=*/%vm67107_vm0, /*on_true_vy=*/%v67129_v34, /*on_false_vx=*/%v67125_v6 (stack44)
        %v67149_v60 = vshrl.u32 %v141210_v40, 19 (stack46)
        %v64745_v52 = vadd.f32 %v64741_v20, %v141135_v52 (stack53)
        %v65900_v6 = vxor.u32 %v65899_v10, %v65895_v42 (stack48)
        %v66705_v34 = vor.u32 %v66704_v50, %v66703_v12 (stack47)
        %v67138_v55 = vadd.s32 %v67133_v53, %v121574_v2 (stack40)
        %v65502_v54 = vadd.s32 %v65499_v29, %v65494_v54 (stack40)
        %v65508_v30 = vshll.u32 %v65499_v29, 6 (stack45)
        %v65509_v9 = vshrl.u32 %v65499_v29, 26 (stack46)
        %v66289_v31 = vxor.u32 %v66288_v26, %v66284_v25 (stack48)
        %v64749_v24 = vmul.f32 %v64745_v52, %v141198_v7 (stack54)
        %v65903_v42 = vadd.s32 %v65900_v6, %v65895_v42 (stack40)
        %v65905_v44 = vshll.u32 %v65900_v6, 29 (stack45)
        %v65906_v21 = vshrl.u32 %v65900_v6, 3 (stack46)
        %vm141241_vm1 = vcmp.lt.f32.partialorder %v65104_v32, 0.0004427343 (stack62)
        %v65510_v20 = vor.u32 %v65509_v9, %v65508_v30 (stack47)
        %v66292_v25 = vadd.s32 %v66289_v31, %v66284_v25 (stack40)
        %v66298_v10 = vshll.u32 %v66289_v31, 24 (stack45)
        %v64753_v43 = vadd.f32 %v64749_v24, %v141130_v43 (stack53)
        %v65907_v12 = vor.u32 %v65906_v21, %v65905_v44 (stack47)
        %v66299_v50 = vshrl.u32 %v66289_v31, 8 (stack46)
        %v66706_v29 = vxor.u32 %v66705_v34, %v66701_v61 (stack48)
        %v65103_v45 = vmul.f32 %v65102_v41, %v65096_v45 (stack63)
        %v65511_v41 = vxor.u32 %v65510_v20, %v65502_v54 (stack48)
        %v67146_v40 = vadd.s32 %v141210_v40, %v67138_v55 (stack40)
        %v67150_v22 = vor.u32 %v67149_v60, %v67148_v22 (stack47)
        %v64757_v26 = vmul.f32 %v64753_v43, %v141198_v7 (stack54)
        %v65908_v53 = vxor.u32 %v65907_v12, %v65903_v42 (stack48)
        %v66300_v60 = vor.u32 %v66299_v50, %v66298_v10 (stack47)
        %v66709_v61 = vadd.s32 %v66706_v29, %v66701_v61 (stack40)
        %v120986_v52 = vpop.eup %120985 (stack64)
        %v65514_v6 = vadd.s32 %v65511_v41, %v121574_v2 (stack40)
        %v66715_v34 = vshll.u32 %v66706_v29, 6 (stack45)
        %v66716_v55 = vshrl.u32 %v66706_v29, 26 (stack46)
        %v67151_v30 = vxor.u32 %v67150_v22, %v67146_v40 (stack48)
        %v64761_v8 = vadd.f32 %v64757_v26, %v141125_v8 (stack53)
        %v65100_v9 = vmul.f32 0.6931472, %v120986_v52 (stack65)
        %v65911_v31 = vadd.s32 %v65908_v53, %v65903_v42 (stack40)
        %v65913_v24 = vshll.u32 %v65908_v53, 16 (stack45)
        %v65506_v54 = vadd.s32 %v65502_v54, %v121564_v0 (stack40)
        %v65518_v42 = vadd.s32 5, %v65514_v6 (stack40)
        %v65914_v44 = vshrl.u32 %v65908_v53, 16 (stack46)
        %v66301_v21 = vxor.u32 %v66300_v60, %v66292_v25 (stack48)
        %v64765_v7 = vmul.f32 %v64761_v8, %v141198_v7 (stack54)
        %v65106_v32 = vsel /*vm=*/%vm141241_vm1, /*on_true_vy=*/%v65103_v45, /*on_false_vx=*/%v65100_v9 (stack66)
        %v66717_v20 = vor.u32 %v66716_v55, %v66715_v34 (stack47)
        %v67154_v10 = vadd.s32 %v67151_v30, %v67146_v40 (stack40)
        %v64654_v27 = vsel /*vm=*/%vm64649_vm11, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v141257_v43 = vxor.u32 2147483648, %v65106_v32 (stack56)
        %v65520_v12 = vxor.u32 %v65518_v42, %v65506_v54 (stack48)
        %v65915_v50 = vor.u32 %v65914_v44, %v65913_v24 (stack47)
        %v64769_v29 = vadd.f32 %v64765_v7, %v64654_v27 (stack53)
        %v66718_v45 = vxor.u32 %v66717_v20, %v66709_v61 (stack48)
        %120987 = vrsqrt.f32 %v141257_v43 (stack67)
        %v64630_v41 = vmul.f32 inf, %v141048_v46 (stack54)
        %v64773_v40 = vmul.f32 %v64769_v29, %v141048_v46 (stack54)
        %vm65110_vm2 = vcmp.lt.f32.partialorder %v141257_v43, 5.0 (stack68)
        %v66304_v22 = vadd.s32 %v66301_v21, %v121574_v2 (stack40)
        %vm64625_vm3 = vcmp.eq.f32.partialorder %v64622_v23, 1.0 (stack68)
        %v65916_v46 = vxor.u32 %v65915_v50, %v65911_v31 (stack48)
        %v67156_v23 = vshll.u32 %v67151_v30, 15 (stack45)
        %v67157_v26 = vshrl.u32 %v67151_v30, 17 (stack46)
        %v64777_v53 = vsel /*vm=*/%vm64625_vm3, /*on_true_vy=*/%v64630_v41, /*on_false_vx=*/%v64773_v40 (stack44)
        %v141267_v60 = vadd.f32 -2.5, %v141257_v43 (stack53)
        %v66296_v25 = vadd.s32 %v66292_v25, %v121564_v0 (stack40)
        %v66713_v61 = vadd.s32 %v66709_v61, %v121569_v1 (stack40)
        %v64781_v52 = vmul.f32 1.4140625, %v64777_v53 (stack54)
        %v141274_v6 = vsel /*vm=*/%vm65110_vm2, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v141279_v34 = vsel /*vm=*/%vm65110_vm2, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v65521_v55 = vand.u32.u8 255, %v65520_v12 (stack49)
        %v65919_v30 = vadd.s32 %v65916_v46, %v65911_v31 (stack40)
        %v65925_v8 = vshll.u32 %v65916_v46, 24 (stack45)
        %v65926_v9 = vshrl.u32 %v65916_v46, 8 (stack46)
        %v66308_v31 = vadd.s32 2, %v66304_v22 (stack40)
        %v64784_v24 = vpack.c.bf16 %v157387_v11, %v64781_v52 (stack81)
        %v65522_v54 = vand.u32 65535, %v65521_v55 (stack50)
        %v66721_v42 = vadd.s32 %v66718_v45, %v121564_v0 (stack40)
        %v67158_v44 = vor.u32 %v67157_v26, %v67156_v23 (stack47)
        %v141286_v21 = vsel /*vm=*/%vm65110_vm2, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %vm65155_vm4 = vcmp.eq.f32.partialorder %v141257_v43, inf (stack70)
        %v65927_v7 = vor.u32 %v65926_v9, %v65925_v8 (stack47)
        %v66312_v32 = vadd.s32 %v66308_v31, %v66296_v25 (stack40)
        %v66314_v20 = vshll.u32 %v66308_v31, 13 (stack45)
        %120091 = vst [vmem:[%s123356_s30 + $0xc4] sm:$0xf] /*vst_source=*/%v64784_v24 (stack83)
        %vm65157_vm5 = vcmp.eq.f32.partialorder %v141257_v43, 0.0 (stack71)
        %v65523_v27 = vshrl.u32 %v65522_v54, 1 (stack51)
        %v66315_v12 = vshrl.u32 %v66308_v31, 19 (stack46)
        %v66725_v50 = vadd.s32 1, %v66721_v42 (stack40)
        %v67159_v29 = vxor.u32 %v67158_v44, %v67154_v10 (stack48)
        %v65928_v45 = vxor.u32 %v65927_v7, %v65919_v30 (stack48)
        %v157486_v41 = vld [vmem:[#allocation142_spill] sm:$0xff] (stack84)
        %v141293_v40 = vadd.s32 %v157486_v41, %v122651_v47 (stack40)
        %v157487_v22 = vld [vmem:[#allocation104_spill] sm:$0xff] (stack84)
        %v67612_v46 = vadd.s32 %v157487_v22, %v157068_v28 (stack40)
        %v141299_v23 = vadd.s32 %v157486_v41, %v157070_v38 (stack40)
        %v65524_v26 = vor.u32 16256, %v65523_v27 (stack47)
        %v66316_v53 = vor.u32 %v66315_v12, %v66314_v20 (stack47)
        %v66729_v25 = vadd.s32 %v66725_v50, %v66713_v61 (stack40)
        %v66731_v61 = vshll.u32 %v66725_v50, 17 (stack45)
        %v65158_v52 = vand.u32 2147483648, %v141257_v43 (stack72)
        %v65931_v55 = vadd.s32 %v65928_v45, %v121564_v0 (stack40)
        %v66732_v8 = vshrl.u32 %v66725_v50, 15 (stack46)
        %v67162_v10 = vadd.s32 %v67159_v29, %v67154_v10 (stack40)
        %v65525_v9 = vand.u32.u16 65535, %v65524_v26 (stack52)
        %v66317_v31 = vxor.u32 %v66316_v53, %v66312_v32 (stack48)
        %v67164_v24 = vshll.u32 %v67159_v29, 26 (stack45)
        %v67165_v54 = vshrl.u32 %v67159_v29, 6 (stack46)
        %v120988_v42 = vpop.eup %120987 (stack73)
        %v65923_v30 = vadd.s32 %v65919_v30, %v121569_v1 (stack40)
        %v65935_v44 = vadd.s32 4, %v65931_v55 (stack40)
        %v66733_v7 = vor.u32 %v66732_v8, %v66731_v61 (stack47)
        %vm67607_vm6 = vcmp.lt.u32.totalorder %v141293_v40, %v122651_v47 (stack43)
        %v65154_v20 = vmul.f32 %v120988_v42, %v141257_v43 (stack74)
        %v120094_v27 = vadd.low.f32.bf16 -1.0, %v65525_v9 (stack53)
        %v66320_v32 = vadd.s32 %v66317_v31, %v66312_v32 (stack40)
        %v66322_v12 = vshll.u32 %v66317_v31, 15 (stack45)
        %v65939_v50 = vadd.s32 %v65935_v44, %v65923_v30 (stack40)
        %v65941_v29 = vshll.u32 %v65935_v44, 13 (stack45)
        %v65942_v45 = vshrl.u32 %v65935_v44, 19 (stack46)
        %v66323_v26 = vshrl.u32 %v66317_v31, 17 (stack46)
        %v65156_v53 = vsel /*vm=*/%vm65155_vm4, /*on_true_vy=*/%v141257_v43, /*on_false_vx=*/%v65154_v20 (stack75)
        %v65534_v61 = vmul.f32 2.0, %v120094_v27 (stack54)
        %v66734_v55 = vxor.u32 %v66733_v7, %v66729_v25 (stack48)
        %v67166_v8 = vor.u32 %v67165_v54, %v67164_v24 (stack47)
        %v65147_v9 = vsel /*vm=*/%vm65110_vm2, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v65159_v52 = vsel /*vm=*/%vm65157_vm5, /*on_true_vy=*/%v65158_v52, /*on_false_vx=*/%v65156_v53 (stack76)
        %v65943_v31 = vor.u32 %v65942_v45, %v65941_v29 (stack47)
        %v66324_v24 = vor.u32 %v66323_v26, %v66322_v12 (stack47)
        %v65162_v54 = vadd.f32 -3.0, %v65159_v52 (stack53)
        %v65538_v42 = vadd.f32 -0.99609375, %v65534_v61 (stack53)
        %v66737_v25 = vadd.s32 %v66734_v55, %v66729_v25 (stack40)
        %v67616_v30 = vadd.s32 1, %v67612_v46 (stack40)
        %v65944_v44 = vxor.u32 %v65943_v31, %v65939_v50 (stack48)
        %v66325_v7 = vxor.u32 %v66324_v24, %v66320_v32 (stack48)
        %v66739_v20 = vshll.u32 %v66734_v55, 29 (stack45)
        %v67167_v27 = vxor.u32 %v67166_v8, %v67162_v10 (stack48)
        %v141318_v60 = vsel /*vm=*/%vm65110_vm2, /*on_true_vy=*/%v141267_v60, /*on_false_vx=*/%v65162_v54 (stack44)
        %v141320_v12 = vmax.f32 %v65538_v42, -0.99609375 (stack55)
        %v66740_v29 = vshrl.u32 %v66734_v55, 3 (stack46)
        %v67620_v46 = vsel /*vm=*/%vm67607_vm6, /*on_true_vy=*/%v67616_v30, /*on_false_vx=*/%v67612_v46 (stack44)
        %v65170_v45 = vmul.f32 %v141318_v60, %v65147_v9 (stack54)
        %v65947_v50 = vadd.s32 %v65944_v44, %v65939_v50 (stack40)
        %v65949_v26 = vshll.u32 %v65944_v44, 15 (stack45)
        %v65950_v53 = vshrl.u32 %v65944_v44, 17 (stack46)
        %v65143_v61 = vsel /*vm=*/%vm65110_vm2, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v65554_v55 = vxor.u32 2147483648, %v141320_v12 (stack56)
        %v66328_v32 = vadd.s32 %v66325_v7, %v66320_v32 (stack40)
        %v67598_v8 = vadd.s32 %v141293_v40, %v122657_v58 (stack40)
        %v65174_v9 = vadd.f32 %v65170_v45, %v65143_v61 (stack53)
        %v65951_v52 = vor.u32 %v65950_v53, %v65949_v26 (stack47)
        %v66330_v31 = vshll.u32 %v66325_v7, 26 (stack45)
        %v66331_v24 = vshrl.u32 %v66325_v7, 6 (stack46)
        %v65135_v54 = vsel /*vm=*/%vm65110_vm2, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v141336_v42 = vmul.f32 %v65554_v55, %v141320_v12 (stack54)
        %v66741_v30 = vor.u32 %v66740_v29, %v66739_v20 (stack47)
        %v67170_v10 = vadd.s32 %v67167_v27, %v67162_v10 (stack40)
        %v65139_v44 = vsel /*vm=*/%vm65110_vm2, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v65178_v7 = vmul.f32 %v65174_v9, %v141318_v60 (stack54)
        %v65952_v20 = vxor.u32 %v65951_v52, %v65947_v50 (stack48)
        %v66332_v29 = vor.u32 %v66331_v24, %v66330_v31 (stack47)
        %v65559_v45 = vadd.f32 1.0, %v141336_v42 (stack57)
        %v65562_v26 = vmul.f32 -0.5, %v141336_v42 (stack59)
        %v66742_v53 = vxor.u32 %v66741_v30, %v66737_v25 (stack48)
        %vm67602_vm7 = vcmp.lt.u32.totalorder %v67598_v8, %v141293_v40 (stack43)
        %v65182_v61 = vadd.f32 %v65178_v7, %v65139_v44 (stack53)
        %v65955_v50 = vadd.s32 %v65952_v20, %v65947_v50 (stack40)
        %v65957_v55 = vshll.u32 %v65952_v20, 26 (stack45)
        %v65958_v9 = vshrl.u32 %v65952_v20, 6 (stack46)
        %120989 = vlog2.f32 %v65559_v45 (stack58)
        %v66333_v52 = vxor.u32 %v66332_v29, %v66328_v32 (stack48)
        %v67176_v31 = vshll.u32 %v67167_v27, 6 (stack45)
        %v67637_v24 = vadd.s32 %v67598_v8, %v121569_v1 (stack40)
        %v65186_v30 = vmul.f32 %v65182_v61, %v141318_v60 (stack54)
        %v65565_v44 = vand.u32 2147483647, %v141336_v42 (stack60)
        %v65959_v7 = vor.u32 %v65958_v9, %v65957_v55 (stack47)
        %v66745_v25 = vadd.s32 %v66742_v53, %v66737_v25 (stack40)
        %v66336_v32 = vadd.s32 %v66333_v52, %v66328_v32 (stack40)
        %v66342_v20 = vshll.u32 %v66333_v52, 6 (stack45)
        %v66343_v29 = vshrl.u32 %v66333_v52, 26 (stack46)
        %v66747_v45 = vshll.u32 %v66742_v53, 16 (stack45)
        %v65190_v54 = vadd.f32 %v65186_v30, %v65135_v54 (stack53)
        %v65563_v26 = vadd.f32 1.0, %v65562_v26 (stack61)
        %v65960_v61 = vxor.u32 %v65959_v7, %v65955_v50 (stack48)
        %v66748_v53 = vshrl.u32 %v66742_v53, 16 (stack46)
        %v66344_v55 = vor.u32 %v66343_v29, %v66342_v20 (stack47)
        %v67174_v9 = vadd.s32 %v67170_v10, %v121569_v1 (stack40)
        %v67177_v27 = vshrl.u32 %v67167_v27, 26 (stack46)
        %v67624_v52 = vadd.s32 1, %v67620_v46 (stack40)
        %v65194_v30 = vmul.f32 %v65190_v54, %v141318_v60 (stack54)
        %v65963_v50 = vadd.s32 %v65960_v61, %v65955_v50 (stack40)
        %v65969_v7 = vshll.u32 %v65960_v61, 6 (stack45)
        %v65970_v20 = vshrl.u32 %v65960_v61, 26 (stack46)
        %v66345_v29 = vxor.u32 %v66344_v55, %v66336_v32 (stack48)
        %v66749_v45 = vor.u32 %v66748_v53, %v66747_v45 (stack47)
        %v67178_v31 = vor.u32 %v67177_v27, %v67176_v31 (stack47)
        %v67628_v40 = vsel /*vm=*/%vm67602_vm7, /*on_true_vy=*/%v67624_v52, /*on_false_vx=*/%v67620_v46 (stack44)
        %v65198_v21 = vadd.f32 %v65194_v30, %v141286_v21 (stack53)
        %vm141353_vm8 = vcmp.lt.f32.partialorder %v65565_v44, 0.0004427343 (stack62)
        %v65971_v8 = vor.u32 %v65970_v20, %v65969_v7 (stack47)
        %v66340_v44 = vadd.s32 %v66336_v32, %v121574_v2 (stack40)
        %v67633_v32 = vadd.s32 %v67628_v40, %v121574_v2 (stack40)
        %v66348_v54 = vadd.s32 %v66345_v29, %v121569_v1 (stack40)
        %v66750_v61 = vxor.u32 %v66749_v45, %v66745_v25 (stack48)
        %v67179_v10 = vxor.u32 %v67178_v31, %v67170_v10 (stack48)
        %v67643_v53 = vshll.u32 %v67637_v24, 13 (stack45)
        %v65202_v55 = vmul.f32 %v65198_v21, %v141318_v60 (stack54)
        %v65972_v27 = vxor.u32 %v65971_v8, %v65963_v50 (stack48)
        %v141361_v52 = vadd.s32 %v67637_v24, %v67633_v32 (stack40)
        %v67644_v24 = vshrl.u32 %v67637_v24, 19 (stack46)
        %v66352_v30 = vadd.s32 3, %v66348_v54 (stack40)
        %v66753_v25 = vadd.s32 %v66750_v61, %v66745_v25 (stack40)
        %v66759_v7 = vshll.u32 %v66750_v61, 24 (stack45)
        %v66760_v20 = vshrl.u32 %v66750_v61, 8 (stack46)
        %v65206_v34 = vadd.f32 %v65202_v55, %v141279_v34 (stack53)
        %v65975_v29 = vadd.s32 %v65972_v27, %v121574_v2 (stack40)
        %v67182_v45 = vadd.s32 %v67179_v10, %v121564_v0 (stack40)
        %v67645_v31 = vor.u32 %v67644_v24, %v67643_v53 (stack47)
        %v65967_v50 = vadd.s32 %v65963_v50, %v121564_v0 (stack40)
        %v66356_v40 = vadd.s32 %v66352_v30, %v66340_v44 (stack40)
        %v66358_v21 = vshll.u32 %v66352_v30, 17 (stack45)
        %v66359_v8 = vshrl.u32 %v66352_v30, 15 (stack46)
        %v120990_v44 = vpop.eup %120989 (stack64)
        %v65210_v32 = vmul.f32 %v65206_v34, %v141318_v60 (stack54)
        %v65979_v54 = vadd.s32 5, %v65975_v29 (stack40)
        %v66761_v61 = vor.u32 %v66760_v20, %v66759_v7 (stack47)
        %v67186_v10 = vadd.s32 1, %v67182_v45 (stack40)
        %v65561_v53 = vmul.f32 0.6931472, %v120990_v44 (stack65)
        %v65564_v42 = vmul.f32 %v65563_v26, %v141336_v42 (stack63)
        %v66360_v26 = vor.u32 %v66359_v8, %v66358_v21 (stack47)
        %v67646_v55 = vxor.u32 %v67645_v31, %v141361_v52 (stack48)
        %v65214_v6 = vadd.f32 %v65210_v32, %v141274_v6 (stack53)
        %v65981_v27 = vxor.u32 %v65979_v54, %v65967_v50 (stack48)
        %v66762_v24 = vxor.u32 %v66761_v61, %v66753_v25 (stack48)
        %v67190_v9 = vadd.s32 %v67186_v10, %v67174_v9 (stack40)
        %v65083_v30 = vand.u32 2147483647, %v141213_v56 (stack77)
        %v65567_v46 = vsel /*vm=*/%vm141353_vm8, /*on_true_vy=*/%v65564_v42, /*on_false_vx=*/%v65561_v53 (stack66)
        %v66361_v7 = vxor.u32 %v66360_v26, %v66356_v40 (stack48)
        %v65218_v20 = vmul.f32 %v65214_v6, %v141318_v60 (stack54)
        %v141375_v34 = vxor.u32 2147483648, %v65567_v46 (stack56)
        %v67192_v29 = vshll.u32 %v67186_v10, 17 (stack45)
        %v67193_v45 = vshrl.u32 %v67186_v10, 15 (stack46)
        %v65119_v31 = vsel /*vm=*/%vm65110_vm2, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v66364_v50 = vadd.s32 %v66361_v7, %v66356_v40 (stack40)
        %v66366_v40 = vshll.u32 %v66361_v7, 29 (stack45)
        %v66367_v21 = vshrl.u32 %v66361_v7, 3 (stack46)
        %v65091_v8 = vmul.f32 inf, %v141213_v56 (stack54)
        %v65222_v44 = vadd.f32 %v65218_v20, %v65119_v31 (stack53)
        %120991 = vrsqrt.f32 %v141375_v34 (stack67)
        %vm141382_vm9 = vcmp.eq.f32.partialorder %v65083_v30, 1.0 (stack68)
        %vm65571_vm10 = vcmp.lt.f32.partialorder %v141375_v34, 5.0 (stack68)
        %v65982_v54 = vand.u32.u8 255, %v65981_v27 (stack49)
        %v66368_v61 = vor.u32 %v66367_v21, %v66366_v40 (stack47)
        %v65115_v43 = vsel /*vm=*/%vm65110_vm2, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v65226_v60 = vmul.f32 %v65222_v44, %v141318_v60 (stack54)
        %v66765_v10 = vadd.s32 %v66762_v24, %v121574_v2 (stack40)
        %v67194_v53 = vor.u32 %v67193_v45, %v67192_v29 (stack47)
        %v65544_v42 = vand.u32 2147483647, %v141320_v12 (stack77)
        %v66369_v26 = vxor.u32 %v66368_v61, %v66364_v50 (stack48)
        %v66757_v25 = vadd.s32 %v66753_v25, %v121564_v0 (stack40)
        %v141396_v6 = vadd.s32 %v141299_v23, %v122657_v58 (stack40)
        %v65230_v27 = vadd.f32 %v65226_v60, %v65115_v43 (stack53)
        %v141401_v24 = vsel /*vm=*/%vm65571_vm10, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v141406_v30 = vsel /*vm=*/%vm65571_vm10, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v141409_v46 = vadd.f32 -2.5, %v141375_v34 (stack53)
        %v65983_v7 = vand.u32 65535, %v65982_v54 (stack50)
        %v66372_v20 = vadd.s32 %v66369_v26, %v66364_v50 (stack40)
        %v66374_v29 = vshll.u32 %v66369_v26, 16 (stack45)
        %v66375_v45 = vshrl.u32 %v66369_v26, 16 (stack46)
        %v65234_v56 = vmul.f32 %v65230_v27, %v141213_v56 (stack54)
        %v66769_v31 = vadd.s32 2, %v66765_v10 (stack40)
        %v67195_v50 = vxor.u32 %v67194_v53, %v67190_v9 (stack48)
        %v67649_v52 = vadd.s32 %v67646_v55, %v141361_v52 (stack40)
        %vm65616_vm11 = vcmp.eq.f32.partialorder %v141375_v34, inf (stack70)
        %v65984_v40 = vshrl.u32 %v65983_v7, 1 (stack51)
        %v66376_v21 = vor.u32 %v66375_v45, %v66374_v29 (stack47)
        %v67651_v44 = vshll.u32 %v67646_v55, 15 (stack45)
        %v67652_v55 = vshrl.u32 %v67646_v55, 17 (stack46)
        %v65238_v8 = vsel /*vm=*/%vm141382_vm9, /*on_true_vy=*/%v65091_v8, /*on_false_vx=*/%v65234_v56 (stack44)
        %v66773_v32 = vadd.s32 %v66769_v31, %v66757_v25 (stack40)
        %v66775_v54 = vshll.u32 %v66769_v31, 13 (stack45)
        %v66776_v61 = vshrl.u32 %v66769_v31, 19 (stack46)
        %v65242_v43 = vmul.f32 1.4140625, %v65238_v8 (stack54)
        %v65985_v60 = vor.u32 16256, %v65984_v40 (stack47)
        %v66377_v10 = vxor.u32 %v66376_v21, %v66372_v20 (stack48)
        %v67198_v9 = vadd.s32 %v67195_v50, %v67190_v9 (stack40)
        %v66777_v53 = vor.u32 %v66776_v61, %v66775_v54 (stack47)
        %v67200_v26 = vshll.u32 %v67195_v50, 29 (stack45)
        %v67201_v25 = vshrl.u32 %v67195_v50, 3 (stack46)
        %v67653_v27 = vor.u32 %v67652_v55, %v67651_v44 (stack47)
        %v65245_v7 = vpack.c.bf16 %v157387_v11, %v65242_v43 (stack81)
        %v65986_v29 = vand.u32.u16 65535, %v65985_v60 (stack52)
        %v66380_v20 = vadd.s32 %v66377_v10, %v66372_v20 (stack40)
        %v66386_v45 = vshll.u32 %v66377_v10, 24 (stack45)
        %v66387_v56 = vshrl.u32 %v66377_v10, 8 (stack46)
        %v66778_v31 = vxor.u32 %v66777_v53, %v66773_v32 (stack48)
        %v67202_v50 = vor.u32 %v67201_v25, %v67200_v26 (stack47)
        %v67654_v40 = vxor.u32 %v67653_v27, %v67649_v52 (stack48)
        %v120992_v21 = vpop.eup %120991 (stack73)
        %120093 = vst [vmem:[%s123356_s30 + $0x144] sm:$0xf] /*vst_source=*/%v65245_v7 (stack83)
        %vm65618_vm12 = vcmp.eq.f32.partialorder %v141375_v34, 0.0 (stack71)
        %v65619_v44 = vand.u32 2147483648, %v141375_v34 (stack72)
        %v120096_v55 = vadd.low.f32.bf16 -1.0, %v65986_v29 (stack53)
        %vm68068_vm13 = vcmp.lt.u32.totalorder %v141299_v23, %v157070_v38 (stack43)
        %v65615_v8 = vmul.f32 %v120992_v21, %v141375_v34 (stack74)
        %v66388_v54 = vor.u32 %v66387_v56, %v66386_v45 (stack47)
        %v66781_v32 = vadd.s32 %v66778_v31, %v66773_v32 (stack40)
        %v66783_v61 = vshll.u32 %v66778_v31, 15 (stack45)
        %v65995_v43 = vmul.f32 2.0, %v120096_v55 (stack54)
        %v66784_v60 = vshrl.u32 %v66778_v31, 17 (stack46)
        %v67203_v10 = vxor.u32 %v67202_v50, %v67198_v9 (stack48)
        %v141423_v52 = vadd.s32 %v67654_v40, %v67649_v52 (stack40)
        %v65617_v53 = vsel /*vm=*/%vm65616_vm11, /*on_true_vy=*/%v141375_v34, /*on_false_vx=*/%v65615_v8 (stack75)
        %v66389_v26 = vxor.u32 %v66388_v54, %v66380_v20 (stack48)
        %v67659_v25 = vshll.u32 %v67654_v40, 26 (stack45)
        %v67660_v27 = vshrl.u32 %v67654_v40, 6 (stack46)
        %v65620_v7 = vsel /*vm=*/%vm65618_vm12, /*on_true_vy=*/%v65619_v44, /*on_false_vx=*/%v65617_v53 (stack76)
        %v65999_v29 = vadd.f32 -0.99609375, %v65995_v43 (stack53)
        %v66785_v45 = vor.u32 %v66784_v60, %v66783_v61 (stack47)
        %v67206_v9 = vadd.s32 %v67203_v10, %v67198_v9 (stack40)
        %v65623_v56 = vadd.f32 -3.0, %v65620_v7 (stack53)
        %v66392_v31 = vadd.s32 %v66389_v26, %v121564_v0 (stack40)
        %v67208_v50 = vshll.u32 %v67203_v10, 16 (stack45)
        %v67209_v40 = vshrl.u32 %v67203_v10, 16 (stack46)
        %v141431_v21 = vmax.f32 %v65999_v29, -0.99609375 (stack55)
        %v66384_v20 = vadd.s32 %v66380_v20, %v121569_v1 (stack40)
        %v66786_v44 = vxor.u32 %v66785_v45, %v66781_v32 (stack48)
        %v141436_v55 = vadd.s32 %v157487_v22, %v157076_v35 (stack40)
        %v141441_v46 = vsel /*vm=*/%vm65571_vm10, /*on_true_vy=*/%v141409_v46, /*on_false_vx=*/%v65623_v56 (stack44)
        %v66396_v8 = vadd.s32 4, %v66392_v31 (stack40)
        %v67210_v54 = vor.u32 %v67209_v40, %v67208_v50 (stack47)
        %v67661_v61 = vor.u32 %v67660_v27, %v67659_v25 (stack47)
        %v141446_v43 = vsel /*vm=*/%vm65571_vm10, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v65604_v60 = vsel /*vm=*/%vm65571_vm10, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v65631_v30 = vmul.f32 %v141441_v46, %v141406_v30 (stack54)
        %v66015_v10 = vxor.u32 2147483648, %v141431_v21 (stack56)
        %v66400_v53 = vadd.s32 %v66396_v8, %v66384_v20 (stack40)
        %v66402_v26 = vshll.u32 %v66396_v8, 13 (stack45)
        %v66403_v25 = vshrl.u32 %v66396_v8, 19 (stack46)
        %v66789_v32 = vadd.s32 %v66786_v44, %v66781_v32 (stack40)
        %v65592_v27 = vsel /*vm=*/%vm65571_vm10, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v65635_v7 = vadd.f32 %v65631_v30, %v65604_v60 (stack53)
        %v141458_v29 = vmul.f32 %v66015_v10, %v141431_v21 (stack54)
        %v66791_v45 = vshll.u32 %v66786_v44, 26 (stack45)
        %v66404_v56 = vor.u32 %v66403_v25, %v66402_v26 (stack47)
        %v66792_v31 = vshrl.u32 %v66786_v44, 6 (stack46)
        %v67211_v50 = vxor.u32 %v67210_v54, %v67206_v9 (stack48)
        %v67662_v40 = vxor.u32 %v67661_v61, %v141423_v52 (stack48)
        %v65596_v20 = vsel /*vm=*/%vm65571_vm10, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v65639_v44 = vmul.f32 %v65635_v7, %v141441_v46 (stack54)
        %v66020_v8 = vadd.f32 1.0, %v141458_v29 (stack57)
        %v66023_v54 = vmul.f32 -0.5, %v141458_v29 (stack59)
        %v65600_v61 = vsel /*vm=*/%vm65571_vm10, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v66405_v60 = vxor.u32 %v66404_v56, %v66400_v53 (stack48)
        %v66793_v30 = vor.u32 %v66792_v31, %v66791_v45 (stack47)
        %v67214_v9 = vadd.s32 %v67211_v50, %v67206_v9 (stack40)
        %v65643_v10 = vadd.f32 %v65639_v44, %v65600_v61 (stack53)
        %120993 = vlog2.f32 %v66020_v8 (stack58)
        %v67220_v26 = vshll.u32 %v67211_v50, 24 (stack45)
        %vm68063_vm14 = vcmp.lt.u32.totalorder %v141396_v6, %v141299_v23 (stack43)
        %v66408_v53 = vadd.s32 %v66405_v60, %v66400_v53 (stack40)
        %v66410_v25 = vshll.u32 %v66405_v60, 15 (stack45)
        %v66411_v7 = vshrl.u32 %v66405_v60, 17 (stack46)
        %v66794_v45 = vxor.u32 %v66793_v30, %v66789_v32 (stack48)
        %v65647_v56 = vmul.f32 %v65643_v10, %v141441_v46 (stack54)
        %v66024_v31 = vadd.f32 1.0, %v66023_v54 (stack61)
        %v67221_v50 = vshrl.u32 %v67211_v50, 8 (stack46)
        %v141475_v44 = vadd.s32 %v141396_v6, %v121569_v1 (stack40)
        %v66412_v8 = vor.u32 %v66411_v7, %v66410_v25 (stack47)
        %v66797_v32 = vadd.s32 %v66794_v45, %v66789_v32 (stack40)
        %v66803_v54 = vshll.u32 %v66794_v45, 6 (stack45)
        %v66804_v61 = vshrl.u32 %v66794_v45, 26 (stack46)
        %v65651_v20 = vadd.f32 %v65647_v56, %v65596_v20 (stack53)
        %v67222_v60 = vor.u32 %v67221_v50, %v67220_v26 (stack47)
        %v141478_v52 = vadd.s32 %v67662_v40, %v141423_v52 (stack40)
        %v67671_v30 = vshll.u32 %v67662_v40, 6 (stack45)
        %v66026_v10 = vand.u32 2147483647, %v141458_v29 (stack60)
        %v66413_v26 = vxor.u32 %v66412_v8, %v66408_v53 (stack48)
        %v66805_v25 = vor.u32 %v66804_v61, %v66803_v54 (stack47)
        %v67672_v40 = vshrl.u32 %v67662_v40, 26 (stack46)
        %v65655_v7 = vmul.f32 %v65651_v20, %v141441_v46 (stack54)
        %v66025_v29 = vmul.f32 %v66024_v31, %v141458_v29 (stack63)
        %v67223_v45 = vxor.u32 %v67222_v60, %v67214_v9 (stack48)
        %v68077_v56 = vadd.s32 1, %v141436_v55 (stack40)
        %v66416_v53 = vadd.s32 %v66413_v26, %v66408_v53 (stack40)
        %v66418_v31 = vshll.u32 %v66413_v26, 26 (stack45)
        %v66419_v50 = vshrl.u32 %v66413_v26, 6 (stack46)
        %v66806_v8 = vxor.u32 %v66805_v25, %v66797_v32 (stack48)
        %v65659_v27 = vadd.f32 %v65655_v7, %v65592_v27 (stack53)
        %v67226_v54 = vadd.s32 %v67223_v45, %v121574_v2 (stack40)
        %v67673_v61 = vor.u32 %v67672_v40, %v67671_v30 (stack47)
        %v68081_v55 = vsel /*vm=*/%vm68068_vm13, /*on_true_vy=*/%v68077_v56, /*on_false_vx=*/%v141436_v55 (stack44)
        %v66420_v20 = vor.u32 %v66419_v50, %v66418_v31 (stack47)
        %v66809_v60 = vadd.s32 %v66806_v8, %v121569_v1 (stack40)
        %v67218_v9 = vadd.s32 %v67214_v9, %v121564_v0 (stack40)
        %v68085_v30 = vadd.s32 1, %v68081_v55 (stack40)
        %v65663_v26 = vmul.f32 %v65659_v27, %v141441_v46 (stack54)
        %v66801_v32 = vadd.s32 %v66797_v32, %v121574_v2 (stack40)
        %v67230_v25 = vadd.s32 2, %v67226_v54 (stack40)
        %v67674_v40 = vxor.u32 %v67673_v61, %v141478_v52 (stack48)
        %v66421_v7 = vxor.u32 %v66420_v20, %v66416_v53 (stack48)
        %v66813_v45 = vadd.s32 3, %v66809_v60 (stack40)
        %v68089_v23 = vsel /*vm=*/%vm68063_vm14, /*on_true_vy=*/%v68085_v30, /*on_false_vx=*/%v68081_v55 (stack44)
        %v141499_v6 = vadd.s32 %v157486_v41, %v157077_v51 (stack40)
        %v65667_v43 = vadd.f32 %v65663_v26, %v141446_v43 (stack53)
        %v67234_v56 = vadd.s32 %v67230_v25, %v67218_v9 (stack40)
        %v67236_v31 = vshll.u32 %v67230_v25, 13 (stack45)
        %v67237_v50 = vshrl.u32 %v67230_v25, 19 (stack46)
        %v120994_v8 = vpop.eup %120993 (stack64)
        %v66424_v53 = vadd.s32 %v66421_v7, %v66416_v53 (stack40)
        %v66430_v27 = vshll.u32 %v66421_v7, 6 (stack45)
        %v66431_v54 = vshrl.u32 %v66421_v7, 26 (stack46)
        %v66817_v61 = vadd.s32 %v66813_v45, %v66801_v32 (stack40)
        %v65671_v55 = vmul.f32 %v65667_v43, %v141441_v46 (stack54)
        %v66022_v20 = vmul.f32 0.6931472, %v120994_v8 (stack65)
        %v66819_v60 = vshll.u32 %v66813_v45, 17 (stack45)
        %v66820_v9 = vshrl.u32 %v66813_v45, 15 (stack46)
        %vm66027_vm15 = vcmp.lt.f32.partialorder %v66026_v10, 0.0004427343 (stack62)
        %v66432_v10 = vor.u32 %v66431_v54, %v66430_v27 (stack47)
        %v67238_v30 = vor.u32 %v67237_v50, %v67236_v31 (stack47)
        %v68104_v26 = vshll.u32 %v141475_v44, 13 (stack45)
        %v65675_v24 = vadd.f32 %v65671_v55, %v141401_v24 (stack53)
        %v66028_v29 = vsel /*vm=*/%vm66027_vm15, /*on_true_vy=*/%v66025_v29, /*on_false_vx=*/%v66022_v20 (stack66)
        %v66821_v32 = vor.u32 %v66820_v9, %v66819_v60 (stack47)
        %v68094_v25 = vadd.s32 %v68089_v23, %v121574_v2 (stack40)
        %v141506_v7 = vxor.u32 2147483648, %v66028_v29 (stack56)
        %v66433_v45 = vxor.u32 %v66432_v10, %v66424_v53 (stack48)
        %v67239_v23 = vxor.u32 %v67238_v30, %v67234_v56 (stack48)
        %v67677_v40 = vadd.s32 %v67674_v40, %v121564_v0 (stack40)
        %v65679_v43 = vmul.f32 %v65675_v24, %v141441_v46 (stack54)
        %v66822_v31 = vxor.u32 %v66821_v32, %v66817_v61 (stack48)
        %v68102_v50 = vadd.s32 %v141475_v44, %v68094_v25 (stack40)
        %v68105_v44 = vshrl.u32 %v141475_v44, 19 (stack46)
        %v65552_v8 = vmul.f32 inf, %v141320_v12 (stack54)
        %v65580_v27 = vsel /*vm=*/%vm65571_vm10, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %120995 = vrsqrt.f32 %v141506_v7 (stack67)
        %vm141519_vm0 = vcmp.eq.f32.partialorder %v65544_v42, 1.0 (stack68)
        %v65576_v34 = vsel /*vm=*/%vm65571_vm10, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v65683_v54 = vadd.f32 %v65679_v43, %v65580_v27 (stack53)
        %vm66032_vm1 = vcmp.lt.f32.partialorder %v141506_v7, 5.0 (stack68)
        %v66005_v55 = vand.u32 2147483647, %v141431_v21 (stack77)
        %v66436_v20 = vadd.s32 %v66433_v45, %v121574_v2 (stack40)
        %v67669_v52 = vadd.s32 %v141478_v52, %v121569_v1 (stack40)
        %v67681_v60 = vadd.s32 1, %v67677_v40 (stack40)
        %v65687_v46 = vmul.f32 %v65683_v54, %v141441_v46 (stack54)
        %v141533_v9 = vadd.f32 -2.5, %v141506_v7 (stack53)
        %v66428_v53 = vadd.s32 %v66424_v53, %v121564_v0 (stack40)
        %v68106_v10 = vor.u32 %v68105_v44, %v68104_v26 (stack47)
        %v141539_v30 = vsel /*vm=*/%vm66032_vm1, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v141544_v26 = vsel /*vm=*/%vm66032_vm1, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v66440_v24 = vadd.s32 5, %v66436_v20 (stack40)
        %v66825_v61 = vadd.s32 %v66822_v31, %v66817_v61 (stack40)
        %v65691_v29 = vadd.f32 %v65687_v46, %v65576_v34 (stack53)
        %v66827_v32 = vshll.u32 %v66822_v31, 29 (stack45)
        %v66828_v25 = vshrl.u32 %v66822_v31, 3 (stack46)
        %v67242_v56 = vadd.s32 %v67239_v23, %v67234_v56 (stack40)
        %v66442_v45 = vxor.u32 %v66440_v24, %v66428_v53 (stack48)
        %v67244_v40 = vshll.u32 %v67239_v23, 15 (stack45)
        %v67245_v23 = vshrl.u32 %v67239_v23, 17 (stack46)
        %v67685_v43 = vadd.s32 %v67681_v60, %v67669_v52 (stack40)
        %v65695_v12 = vmul.f32 %v65691_v29, %v141320_v12 (stack54)
        %vm66077_vm2 = vcmp.eq.f32.partialorder %v141506_v7, inf (stack70)
        %v66829_v31 = vor.u32 %v66828_v25, %v66827_v32 (stack47)
        %v67687_v44 = vshll.u32 %v67681_v60, 17 (stack45)
        %v67688_v27 = vshrl.u32 %v67681_v60, 15 (stack46)
        %vm66079_vm3 = vcmp.eq.f32.partialorder %v141506_v7, 0.0 (stack71)
        %v66443_v34 = vand.u32.u8 255, %v66442_v45 (stack49)
        %v67246_v54 = vor.u32 %v67245_v23, %v67244_v40 (stack47)
        %v68107_v20 = vxor.u32 %v68106_v10, %v68102_v50 (stack48)
        %v65699_v8 = vsel /*vm=*/%vm141519_vm0, /*on_true_vy=*/%v65552_v8, /*on_false_vx=*/%v65695_v12 (stack44)
        %v66830_v42 = vxor.u32 %v66829_v31, %v66825_v61 (stack48)
        %v67689_v52 = vor.u32 %v67688_v27, %v67687_v44 (stack47)
        %vm68529_vm4 = vcmp.lt.u32.totalorder %v141499_v6, %v157077_v51 (stack43)
        %v65703_v60 = vmul.f32 1.4140625, %v65699_v8 (stack54)
        %v66444_v46 = vand.u32 65535, %v66443_v34 (stack50)
        %v67247_v53 = vxor.u32 %v67246_v54, %v67242_v56 (stack48)
        %v68110_v50 = vadd.s32 %v68107_v20, %v68102_v50 (stack40)
        %v66833_v10 = vadd.s32 %v66830_v42, %v66825_v61 (stack40)
        %v66835_v24 = vshll.u32 %v66830_v42, 16 (stack45)
        %v66836_v61 = vshrl.u32 %v66830_v42, 16 (stack46)
        %v67690_v29 = vxor.u32 %v67689_v52, %v67685_v43 (stack48)
        %v65706_v32 = vpack.c.bf16 %v157387_v11, %v65703_v60 (stack81)
        %v66445_v25 = vshrl.u32 %v66444_v46, 1 (stack51)
        %v67250_v56 = vadd.s32 %v67247_v53, %v67242_v56 (stack40)
        %v67252_v45 = vshll.u32 %v67247_v53, 26 (stack45)
        %v120996_v40 = vpop.eup %120995 (stack73)
        %v66837_v23 = vor.u32 %v66836_v61, %v66835_v24 (stack47)
        %v67253_v12 = vshrl.u32 %v67247_v53, 6 (stack46)
        %v67693_v43 = vadd.s32 %v67690_v29, %v67685_v43 (stack40)
        %v67695_v31 = vshll.u32 %v67690_v29, 29 (stack45)
        %120095 = vst [vmem:[%s123356_s30 + $0x1c4] sm:$0xf] /*vst_source=*/%v65706_v32 (stack83)
        %v66076_v44 = vmul.f32 %v120996_v40, %v141506_v7 (stack74)
        %v66080_v27 = vand.u32 2147483648, %v141506_v7 (stack72)
        %v66446_v34 = vor.u32 16256, %v66445_v25 (stack47)
        %v67696_v54 = vshrl.u32 %v67690_v29, 3 (stack46)
        %v66838_v8 = vxor.u32 %v66837_v23, %v66833_v10 (stack48)
        %v67254_v42 = vor.u32 %v67253_v12, %v67252_v45 (stack47)
        %v68112_v52 = vshll.u32 %v68107_v20, 15 (stack45)
        %v68113_v20 = vshrl.u32 %v68107_v20, 17 (stack46)
        %v66078_v60 = vsel /*vm=*/%vm66077_vm2, /*on_true_vy=*/%v141506_v7, /*on_false_vx=*/%v66076_v44 (stack75)
        %v66447_v46 = vand.u32.u16 65535, %v66446_v34 (stack52)
        %v67697_v53 = vor.u32 %v67696_v54, %v67695_v31 (stack47)
        %v68534_v24 = vadd.s32 %v157487_v22, %v157078_v48 (stack40)
        %v66081_v61 = vsel /*vm=*/%vm66079_vm3, /*on_true_vy=*/%v66080_v27, /*on_false_vx=*/%v66078_v60 (stack76)
        %v66841_v10 = vadd.s32 %v66838_v8, %v66833_v10 (stack40)
        %v66847_v29 = vshll.u32 %v66838_v8, 24 (stack45)
        %v66848_v32 = vshrl.u32 %v66838_v8, 8 (stack46)
        %v66084_v25 = vadd.f32 -3.0, %v66081_v61 (stack53)
        %v120098_v45 = vadd.low.f32.bf16 -1.0, %v66447_v46 (stack53)
        %v67255_v40 = vxor.u32 %v67254_v42, %v67250_v56 (stack48)
        %v67698_v23 = vxor.u32 %v67697_v53, %v67693_v43 (stack48)
        %v66065_v12 = vsel /*vm=*/%vm66032_vm1, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v66069_v31 = vsel /*vm=*/%vm66032_vm1, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v66849_v44 = vor.u32 %v66848_v32, %v66847_v29 (stack47)
        %v68114_v27 = vor.u32 %v68113_v20, %v68112_v52 (stack47)
        %v141573_v9 = vsel /*vm=*/%vm66032_vm1, /*on_true_vy=*/%v141533_v9, /*on_false_vx=*/%v66084_v25 (stack44)
        %v66456_v34 = vmul.f32 2.0, %v120098_v45 (stack54)
        %v67258_v56 = vadd.s32 %v67255_v40, %v67250_v56 (stack40)
        %v67264_v54 = vshll.u32 %v67255_v40, 6 (stack45)
        %v66092_v8 = vmul.f32 %v141573_v9, %v66069_v31 (stack54)
        %v66850_v42 = vxor.u32 %v66849_v44, %v66841_v10 (stack48)
        %v67265_v52 = vshrl.u32 %v67255_v40, 26 (stack46)
        %v67701_v43 = vadd.s32 %v67698_v23, %v67693_v43 (stack40)
        %v66460_v20 = vadd.f32 -0.99609375, %v66456_v34 (stack53)
        %v67703_v60 = vshll.u32 %v67698_v23, 16 (stack45)
        %v67704_v46 = vshrl.u32 %v67698_v23, 16 (stack46)
        %v68538_v53 = vadd.s32 1, %v68534_v24 (stack40)
        %v66096_v61 = vadd.f32 %v66092_v8, %v66065_v12 (stack53)
        %v66853_v29 = vadd.s32 %v66850_v42, %v121564_v0 (stack40)
        %v67266_v32 = vor.u32 %v67265_v52, %v67264_v54 (stack47)
        %v68115_v25 = vxor.u32 %v68114_v27, %v68110_v50 (stack48)
        %v141577_v45 = vmax.f32 %v66460_v20, -0.99609375 (stack55)
        %v66845_v10 = vadd.s32 %v66841_v10, %v121569_v1 (stack40)
        %v67705_v40 = vor.u32 %v67704_v46, %v67703_v60 (stack47)
        %v68542_v24 = vsel /*vm=*/%vm68529_vm4, /*on_true_vy=*/%v68538_v53, /*on_false_vx=*/%v68534_v24 (stack44)
        %v66100_v23 = vmul.f32 %v66096_v61, %v141573_v9 (stack54)
        %v66857_v12 = vadd.s32 4, %v66853_v29 (stack40)
        %v67267_v31 = vxor.u32 %v67266_v32, %v67258_v56 (stack48)
        %v141584_v50 = vadd.s32 %v68115_v25, %v68110_v50 (stack40)
        %v66049_v44 = vsel /*vm=*/%vm66032_vm1, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v66061_v27 = vsel /*vm=*/%vm66032_vm1, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v66476_v34 = vxor.u32 2147483648, %v141577_v45 (stack56)
        %v67706_v54 = vxor.u32 %v67705_v40, %v67701_v43 (stack48)
        %v66104_v8 = vadd.f32 %v66100_v23, %v66061_v27 (stack53)
        %v66861_v42 = vadd.s32 %v66857_v12, %v66845_v10 (stack40)
        %v66863_v52 = vshll.u32 %v66857_v12, 13 (stack45)
        %v66864_v20 = vshrl.u32 %v66857_v12, 19 (stack46)
        %v66479_v60 = vmul.f32 %v66476_v34, %v141577_v45 (stack54)
        %v67270_v46 = vadd.s32 %v67267_v31, %v121569_v1 (stack40)
        %v67709_v43 = vadd.s32 %v67706_v54, %v67701_v43 (stack40)
        %v68520_v53 = vadd.s32 %v141499_v6, %v122657_v58 (stack40)
        %v66108_v61 = vmul.f32 %v66104_v8, %v141573_v9 (stack54)
        %v66865_v29 = vor.u32 %v66864_v20, %v66863_v52 (stack47)
        %v67715_v32 = vshll.u32 %v67706_v54, 24 (stack45)
        %v67716_v10 = vshrl.u32 %v67706_v54, 8 (stack46)
        %v66057_v40 = vsel /*vm=*/%vm66032_vm1, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v66481_v23 = vadd.f32 1.0, %v66479_v60 (stack57)
        %v67262_v56 = vadd.s32 %v67258_v56, %v121574_v2 (stack40)
        %v67274_v12 = vadd.s32 3, %v67270_v46 (stack40)
        %v66053_v31 = vsel /*vm=*/%vm66032_vm1, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v66112_v27 = vadd.f32 %v66108_v61, %v66057_v40 (stack53)
        %v66866_v34 = vxor.u32 %v66865_v29, %v66861_v42 (stack48)
        %v67717_v54 = vor.u32 %v67716_v10, %v67715_v32 (stack47)
        %120997 = vlog2.f32 %v66481_v23 (stack58)
        %v66484_v8 = vmul.f32 -0.5, %v66479_v60 (stack59)
        %v67278_v52 = vadd.s32 %v67274_v12, %v67262_v56 (stack40)
        %vm68524_vm5 = vcmp.lt.u32.totalorder %v68520_v53, %v141499_v6 (stack43)
        %v66116_v20 = vmul.f32 %v66112_v27, %v141573_v9 (stack54)
        %v66869_v42 = vadd.s32 %v66866_v34, %v66861_v42 (stack40)
        %v66871_v46 = vshll.u32 %v66866_v34, 15 (stack45)
        %v66872_v61 = vshrl.u32 %v66866_v34, 17 (stack46)
        %v66487_v29 = vand.u32 2147483647, %v66479_v60 (stack60)
        %v67280_v32 = vshll.u32 %v67274_v12, 17 (stack45)
        %v67281_v10 = vshrl.u32 %v67274_v12, 15 (stack46)
        %v67718_v40 = vxor.u32 %v67717_v54, %v67709_v43 (stack48)
        %v66120_v23 = vadd.f32 %v66116_v20, %v66053_v31 (stack53)
        %v66873_v56 = vor.u32 %v66872_v61, %v66871_v46 (stack47)
        %v68120_v12 = vshll.u32 %v68115_v25, 26 (stack45)
        %v68121_v25 = vshrl.u32 %v68115_v25, 6 (stack46)
        %v67282_v31 = vor.u32 %v67281_v10, %v67280_v32 (stack47)
        %v67713_v43 = vadd.s32 %v67709_v43, %v121564_v0 (stack40)
        %v67721_v27 = vadd.s32 %v67718_v40, %v121574_v2 (stack40)
        %v68546_v34 = vadd.s32 1, %v68542_v24 (stack40)
        %v66124_v54 = vmul.f32 %v66120_v23, %v141573_v9 (stack54)
        %v66485_v8 = vadd.f32 1.0, %v66484_v8 (stack61)
        %v66874_v20 = vxor.u32 %v66873_v56, %v66869_v42 (stack48)
        %v68122_v46 = vor.u32 %v68121_v25, %v68120_v12 (stack47)
        %v67283_v61 = vxor.u32 %v67282_v31, %v67278_v52 (stack48)
        %v67725_v32 = vadd.s32 2, %v67721_v27 (stack40)
        %v68550_v6 = vsel /*vm=*/%vm68524_vm5, /*on_true_vy=*/%v68546_v34, /*on_false_vx=*/%v68542_v24 (stack44)
        %v141614_v24 = vadd.s32 %v157486_v41, %v157079_v39 (stack40)
        %v66128_v44 = vadd.f32 %v66124_v54, %v66049_v44 (stack53)
        %v66877_v42 = vadd.s32 %v66874_v20, %v66869_v42 (stack40)
        %v66879_v10 = vshll.u32 %v66874_v20, 26 (stack45)
        %v66880_v40 = vshrl.u32 %v66874_v20, 6 (stack46)
        %v67286_v52 = vadd.s32 %v67283_v61, %v67278_v52 (stack40)
        %v67288_v23 = vshll.u32 %v67283_v61, 29 (stack45)
        %v67289_v56 = vshrl.u32 %v67283_v61, 3 (stack46)
        %v67729_v12 = vadd.s32 %v67725_v32, %v67713_v43 (stack40)
        %v66132_v25 = vmul.f32 %v66128_v44, %v141573_v9 (stack54)
        %v66881_v31 = vor.u32 %v66880_v40, %v66879_v10 (stack47)
        %v67731_v43 = vshll.u32 %v67725_v32, 13 (stack45)
        %v67732_v27 = vshrl.u32 %v67725_v32, 19 (stack46)
        %vm141617_vm6 = vcmp.lt.f32.partialorder %v66487_v29, 0.0004427343 (stack62)
        %v67290_v34 = vor.u32 %v67289_v56, %v67288_v23 (stack47)
        %v68123_v54 = vxor.u32 %v68122_v46, %v141584_v50 (stack48)
        %v68559_v53 = vadd.s32 %v68520_v53, %v121569_v1 (stack40)
        %v66136_v26 = vadd.f32 %v66132_v25, %v141544_v26 (stack53)
        %v66486_v60 = vmul.f32 %v66485_v8, %v66479_v60 (stack63)
        %v66882_v8 = vxor.u32 %v66881_v31, %v66877_v42 (stack48)
        %v67733_v20 = vor.u32 %v67732_v27, %v67731_v43 (stack47)
        %v67291_v46 = vxor.u32 %v67290_v34, %v67286_v52 (stack48)
        %v68126_v50 = vadd.s32 %v68123_v54, %v141584_v50 (stack40)
        %v68132_v61 = vshll.u32 %v68123_v54, 6 (stack45)
        %v68133_v32 = vshrl.u32 %v68123_v54, 26 (stack46)
        %v120998_v44 = vpop.eup %120997 (stack64)
        %v66140_v10 = vmul.f32 %v66136_v26, %v141573_v9 (stack54)
        %v66885_v42 = vadd.s32 %v66882_v8, %v66877_v42 (stack40)
        %v66891_v40 = vshll.u32 %v66882_v8, 6 (stack45)
        %v66892_v23 = vshrl.u32 %v66882_v8, 26 (stack46)
        %v66483_v56 = vmul.f32 0.6931472, %v120998_v44 (stack65)
        %v67294_v52 = vadd.s32 %v67291_v46, %v67286_v52 (stack40)
        %v67296_v25 = vshll.u32 %v67291_v46, 16 (stack45)
        %v67297_v31 = vshrl.u32 %v67291_v46, 16 (stack46)
        %v66144_v30 = vadd.f32 %v66140_v10, %v141539_v30 (stack53)
        %v66893_v43 = vor.u32 %v66892_v23, %v66891_v40 (stack47)
        %v67734_v27 = vxor.u32 %v67733_v20, %v67729_v12 (stack48)
        %v68565_v34 = vshll.u32 %v68559_v53, 13 (stack45)
        %v66489_v29 = vsel /*vm=*/%vm141617_vm6, /*on_true_vy=*/%v66486_v60, /*on_false_vx=*/%v66483_v56 (stack66)
        %v67298_v54 = vor.u32 %v67297_v31, %v67296_v25 (stack47)
        %v68134_v26 = vor.u32 %v68133_v32, %v68132_v61 (stack47)
        %v68566_v60 = vshrl.u32 %v68559_v53, 19 (stack46)
        %v66148_v9 = vmul.f32 %v66144_v30, %v141573_v9 (stack54)
        %v141630_v8 = vxor.u32 2147483648, %v66489_v29 (stack56)
        %v66894_v20 = vxor.u32 %v66893_v43, %v66885_v42 (stack48)
        %v67737_v12 = vadd.s32 %v67734_v27, %v67729_v12 (stack40)
        %v66037_v7 = vsel /*vm=*/%vm66032_vm1, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v67299_v46 = vxor.u32 %v67298_v54, %v67294_v52 (stack48)
        %v68135_v61 = vxor.u32 %v68134_v26, %v68126_v50 (stack48)
        %vm141637_vm7 = vcmp.eq.f32.partialorder %v66005_v55, 1.0 (stack68)
        %v66013_v32 = vmul.f32 inf, %v141431_v21 (stack54)
        %v66152_v44 = vadd.f32 %v66148_v9, %v66037_v7 (stack53)
        %120999 = vrsqrt.f32 %v141630_v8 (stack67)
        %v66466_v10 = vand.u32 2147483647, %v141577_v45 (stack77)
        %vm66493_vm8 = vcmp.lt.f32.partialorder %v141630_v8, 5.0 (stack68)
        %v66897_v40 = vadd.s32 %v66894_v20, %v121574_v2 (stack40)
        %v68555_v6 = vadd.s32 %v68550_v6, %v121574_v2 (stack40)
        %v66156_v21 = vmul.f32 %v66152_v44, %v141431_v21 (stack54)
        %v67739_v23 = vshll.u32 %v67734_v27, 15 (stack45)
        %v67740_v56 = vshrl.u32 %v67734_v27, 17 (stack46)
        %v68567_v25 = vor.u32 %v68566_v60, %v68565_v34 (stack47)
        %v66889_v42 = vadd.s32 %v66885_v42, %v121564_v0 (stack40)
        %v67302_v52 = vadd.s32 %v67299_v46, %v67294_v52 (stack40)
        %v68130_v50 = vadd.s32 %v68126_v50, %v121569_v1 (stack40)
        %v141652_v31 = vadd.s32 %v141614_v24, %v122657_v58 (stack40)
        %v66160_v30 = vsel /*vm=*/%vm141637_vm7, /*on_true_vy=*/%v66013_v32, /*on_false_vx=*/%v66156_v21 (stack44)
        %v141659_v43 = vsel /*vm=*/%vm66493_vm8, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v141664_v27 = vsel /*vm=*/%vm66493_vm8, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v141667_v34 = vadd.f32 -2.5, %v141630_v8 (stack53)
        %v66164_v29 = vmul.f32 1.4140625, %v66160_v30 (stack54)
        %v141672_v54 = vsel /*vm=*/%vm66493_vm8, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v66901_v26 = vadd.s32 5, %v66897_v40 (stack40)
        %v67308_v60 = vshll.u32 %v67299_v46, 24 (stack45)
        %v67309_v9 = vshrl.u32 %v67299_v46, 8 (stack46)
        %v67741_v20 = vor.u32 %v67740_v56, %v67739_v23 (stack47)
        %v68138_v7 = vadd.s32 %v68135_v61, %v121564_v0 (stack40)
        %v68563_v53 = vadd.s32 %v68559_v53, %v68555_v6 (stack40)
        %v66167_v46 = vpack.c.bf16 %v157387_v11, %v66164_v29 (stack81)
        %vm66538_vm9 = vcmp.eq.f32.partialorder %v141630_v8, inf (stack70)
        %v66903_v61 = vxor.u32 %v66901_v26, %v66889_v42 (stack48)
        %vm68990_vm10 = vcmp.lt.u32.totalorder %v141614_v24, %v157079_v39 (stack43)
        %vm66540_vm11 = vcmp.eq.f32.partialorder %v141630_v8, 0.0 (stack71)
        %v67310_v55 = vor.u32 %v67309_v9, %v67308_v60 (stack47)
        %v67742_v32 = vxor.u32 %v67741_v20, %v67737_v12 (stack48)
        %v68142_v44 = vadd.s32 1, %v68138_v7 (stack40)
        %v68568_v40 = vxor.u32 %v68567_v25, %v68563_v53 (stack48)
        %120097 = vst [vmem:[%s123356_s30 + $0x244] sm:$0xf] /*vst_source=*/%v66167_v46 (stack83)
        %v66541_v6 = vand.u32 2147483648, %v141630_v8 (stack72)
        %v66904_v21 = vand.u32.u8 255, %v66903_v61 (stack49)
        %v68995_v23 = vadd.s32 %v157487_v22, %v157082_v49 (stack40)
        %v141686_v56 = vadd.s32 %v157486_v41, %v157083_v59 (stack40)
        %v67311_v25 = vxor.u32 %v67310_v55, %v67302_v52 (stack48)
        %v67745_v12 = vadd.s32 %v67742_v32, %v67737_v12 (stack40)
        %v67747_v42 = vshll.u32 %v67742_v32, 26 (stack45)
        %v67748_v30 = vshrl.u32 %v67742_v32, 6 (stack46)
        %v66905_v29 = vand.u32 65535, %v66904_v21 (stack50)
        %v68146_v50 = vadd.s32 %v68142_v44, %v68130_v50 (stack40)
        %v68148_v26 = vshll.u32 %v68142_v44, 17 (stack45)
        %v68149_v60 = vshrl.u32 %v68142_v44, 15 (stack46)
        %v67314_v9 = vadd.s32 %v67311_v25, %v121564_v0 (stack40)
        %v67749_v20 = vor.u32 %v67748_v30, %v67747_v42 (stack47)
        %v68571_v7 = vadd.s32 %v68568_v40, %v68563_v53 (stack40)
        %v68573_v53 = vshll.u32 %v68568_v40, 15 (stack45)
        %v121000_v46 = vpop.eup %120999 (stack73)
        %v66906_v61 = vshrl.u32 %v66905_v29, 1 (stack51)
        %v68150_v55 = vor.u32 %v68149_v60, %v68148_v26 (stack47)
        %v68574_v32 = vshrl.u32 %v68568_v40, 17 (stack46)
        %v68999_v44 = vadd.s32 1, %v68995_v23 (stack40)
        %v66537_v40 = vmul.f32 %v121000_v46, %v141630_v8 (stack74)
        %v67306_v52 = vadd.s32 %v67302_v52, %v121569_v1 (stack40)
        %v67318_v21 = vadd.s32 4, %v67314_v9 (stack40)
        %v67750_v25 = vxor.u32 %v67749_v20, %v67745_v12 (stack48)
        %v66907_v42 = vor.u32 16256, %v66906_v61 (stack47)
        %v68151_v30 = vxor.u32 %v68150_v55, %v68146_v50 (stack48)
        %v68575_v29 = vor.u32 %v68574_v32, %v68573_v53 (stack47)
        %v141694_v23 = vsel /*vm=*/%vm68990_vm10, /*on_true_vy=*/%v68999_v44, /*on_false_vx=*/%v68995_v23 (stack44)
        %v66539_v26 = vsel /*vm=*/%vm66538_vm9, /*on_true_vy=*/%v141630_v8, /*on_false_vx=*/%v66537_v40 (stack75)
        %v67322_v60 = vadd.s32 %v67318_v21, %v67306_v52 (stack40)
        %v67324_v9 = vshll.u32 %v67318_v21, 13 (stack45)
        %v67325_v20 = vshrl.u32 %v67318_v21, 19 (stack46)
        %v66542_v6 = vsel /*vm=*/%vm66540_vm11, /*on_true_vy=*/%v66541_v6, /*on_false_vx=*/%v66539_v26 (stack76)
        %v66908_v53 = vand.u32.u16 65535, %v66907_v42 (stack52)
        %v67753_v12 = vadd.s32 %v67750_v25, %v67745_v12 (stack40)
        %v67759_v46 = vshll.u32 %v67750_v25, 6 (stack45)
        %v66545_v61 = vadd.f32 -3.0, %v66542_v6 (stack53)
        %v67326_v55 = vor.u32 %v67325_v20, %v67324_v9 (stack47)
        %v67760_v32 = vshrl.u32 %v67750_v25, 26 (stack46)
        %v68154_v50 = vadd.s32 %v68151_v30, %v68146_v50 (stack40)
        %v66530_v44 = vsel /*vm=*/%vm66493_vm8, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v120100_v40 = vadd.low.f32.bf16 -1.0, %v66908_v53 (stack53)
        %v68156_v52 = vshll.u32 %v68151_v30, 29 (stack45)
        %v68157_v21 = vshrl.u32 %v68151_v30, 3 (stack46)
        %v141707_v34 = vsel /*vm=*/%vm66493_vm8, /*on_true_vy=*/%v141667_v34, /*on_false_vx=*/%v66545_v61 (stack44)
        %v67327_v25 = vxor.u32 %v67326_v55, %v67322_v60 (stack48)
        %v67761_v42 = vor.u32 %v67760_v32, %v67759_v46 (stack47)
        %v68576_v30 = vxor.u32 %v68575_v29, %v68571_v7 (stack48)
        %v66553_v29 = vmul.f32 %v141707_v34, %v66530_v44 (stack54)
        %v66917_v26 = vmul.f32 2.0, %v120100_v40 (stack54)
        %v67757_v9 = vadd.s32 %v67753_v12, %v121574_v2 (stack40)
        %v68158_v20 = vor.u32 %v68157_v21, %v68156_v52 (stack47)
        %v67330_v60 = vadd.s32 %v67327_v25, %v67322_v60 (stack40)
        %v67332_v6 = vshll.u32 %v67327_v25, 15 (stack45)
        %v67333_v53 = vshrl.u32 %v67327_v25, 17 (stack46)
        %v67762_v12 = vxor.u32 %v67761_v42, %v67753_v12 (stack48)
        %v66557_v54 = vadd.f32 %v66553_v29, %v141672_v54 (stack53)
        %v66921_v46 = vadd.f32 -0.99609375, %v66917_v26 (stack53)
        %v68159_v61 = vxor.u32 %v68158_v20, %v68154_v50 (stack48)
        %v68579_v7 = vadd.s32 %v68576_v30, %v68571_v7 (stack40)
        %v67334_v55 = vor.u32 %v67333_v53, %v67332_v6 (stack47)
        %v67765_v32 = vadd.s32 %v67762_v12, %v121569_v1 (stack40)
        %v68581_v44 = vshll.u32 %v68576_v30, 26 (stack45)
        %v68582_v40 = vshrl.u32 %v68576_v30, 6 (stack46)
        %v66561_v52 = vmul.f32 %v66557_v54, %v141707_v34 (stack54)
        %v141714_v21 = vmax.f32 %v66921_v46, -0.99609375 (stack55)
        %v68162_v50 = vadd.s32 %v68159_v61, %v68154_v50 (stack40)
        %v68164_v25 = vshll.u32 %v68159_v61, 16 (stack45)
        %v67335_v42 = vxor.u32 %v67334_v55, %v67330_v60 (stack48)
        %v67769_v30 = vadd.s32 3, %v67765_v32 (stack40)
        %v68165_v29 = vshrl.u32 %v68159_v61, 16 (stack46)
        %v68583_v26 = vor.u32 %v68582_v40, %v68581_v44 (stack47)
        %v141719_v20 = vsel /*vm=*/%vm66493_vm8, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v66510_v6 = vsel /*vm=*/%vm66493_vm8, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v66565_v27 = vadd.f32 %v66561_v52, %v141664_v27 (stack53)
        %v66937_v53 = vxor.u32 2147483648, %v141714_v21 (stack56)
        %v67338_v60 = vadd.s32 %v67335_v42, %v67330_v60 (stack40)
        %v67340_v12 = vshll.u32 %v67335_v42, 26 (stack45)
        %v67341_v54 = vshrl.u32 %v67335_v42, 6 (stack46)
        %v67773_v9 = vadd.s32 %v67769_v30, %v67757_v9 (stack40)
        %v66518_v46 = vsel /*vm=*/%vm66493_vm8, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v66569_v61 = vmul.f32 %v66565_v27, %v141707_v34 (stack54)
        %v141731_v55 = vmul.f32 %v66937_v53, %v141714_v21 (stack54)
        %v67775_v32 = vshll.u32 %v67769_v30, 17 (stack45)
        %v67342_v44 = vor.u32 %v67341_v54, %v67340_v12 (stack47)
        %v67776_v40 = vshrl.u32 %v67769_v30, 15 (stack46)
        %v68166_v52 = vor.u32 %v68165_v29, %v68164_v25 (stack47)
        %v68584_v25 = vxor.u32 %v68583_v26, %v68579_v7 (stack48)
        %v66514_v42 = vsel /*vm=*/%vm66493_vm8, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v66573_v30 = vadd.f32 %v66569_v61, %v66518_v46 (stack53)
        %v66942_v29 = vadd.f32 1.0, %v141731_v55 (stack57)
        %vm68985_vm12 = vcmp.lt.u32.totalorder %v141652_v31, %v141614_v24 (stack43)
        %v67343_v26 = vxor.u32 %v67342_v44, %v67338_v60 (stack48)
        %v67777_v27 = vor.u32 %v67776_v40, %v67775_v32 (stack47)
        %v68167_v53 = vxor.u32 %v68166_v52, %v68162_v50 (stack48)
        %v141739_v7 = vadd.s32 %v68584_v25, %v68579_v7 (stack40)
        %v66577_v12 = vmul.f32 %v66573_v30, %v141707_v34 (stack54)
        %121001 = vlog2.f32 %v66942_v29 (stack58)
        %v66945_v54 = vmul.f32 -0.5, %v141731_v55 (stack59)
        %v69020_v46 = vadd.s32 %v141652_v31, %v121569_v1 (stack40)
        %v67346_v60 = vadd.s32 %v67343_v26, %v67338_v60 (stack40)
        %v67352_v61 = vshll.u32 %v67343_v26, 6 (stack45)
        %v67353_v32 = vshrl.u32 %v67343_v26, 26 (stack46)
        %v67778_v44 = vxor.u32 %v67777_v27, %v67773_v9 (stack48)
        %v66581_v40 = vadd.f32 %v66577_v12, %v66514_v42 (stack53)
        %v68170_v50 = vadd.s32 %v68167_v53, %v68162_v50 (stack40)
        %v68176_v52 = vshll.u32 %v68167_v53, 24 (stack45)
        %v69007_v42 = vadd.s32 1, %v141694_v23 (stack40)
        %v66948_v30 = vand.u32 2147483647, %v141731_v55 (stack60)
        %v67354_v29 = vor.u32 %v67353_v32, %v67352_v61 (stack47)
        %v67781_v9 = vadd.s32 %v67778_v44, %v67773_v9 (stack40)
        %v67783_v26 = vshll.u32 %v67778_v44, 29 (stack45)
        %v66585_v27 = vmul.f32 %v66581_v40, %v141707_v34 (stack54)
        %v67784_v12 = vshrl.u32 %v67778_v44, 3 (stack46)
        %v68177_v53 = vshrl.u32 %v68167_v53, 8 (stack46)
        %v69026_v61 = vshll.u32 %v69020_v46, 13 (stack45)
        %v66946_v54 = vadd.f32 1.0, %v66945_v54 (stack61)
        %v67355_v32 = vxor.u32 %v67354_v29, %v67346_v60 (stack48)
        %v68593_v44 = vshll.u32 %v68584_v25, 6 (stack45)
        %v68594_v25 = vshrl.u32 %v68584_v25, 26 (stack46)
        %v66589_v6 = vadd.f32 %v66585_v27, %v66510_v6 (stack53)
        %v67785_v40 = vor.u32 %v67784_v12, %v67783_v26 (stack47)
        %v68178_v52 = vor.u32 %v68177_v53, %v68176_v52 (stack47)
        %v69011_v24 = vsel /*vm=*/%vm68985_vm12, /*on_true_vy=*/%v69007_v42, /*on_false_vx=*/%v141694_v23 (stack44)
        %vm141752_vm13 = vcmp.lt.f32.partialorder %v66948_v30, 0.0004427343 (stack62)
        %v67358_v23 = vadd.s32 %v67355_v32, %v121574_v2 (stack40)
        %v68595_v42 = vor.u32 %v68594_v25, %v68593_v44 (stack47)
        %v69016_v30 = vadd.s32 %v69011_v24, %v121574_v2 (stack40)
        %v69027_v29 = vshrl.u32 %v69020_v46, 19 (stack46)
        %v66593_v26 = vmul.f32 %v66589_v6, %v141707_v34 (stack54)
        %v67350_v60 = vadd.s32 %v67346_v60, %v121564_v0 (stack40)
        %v67786_v27 = vxor.u32 %v67785_v40, %v67781_v9 (stack48)
        %v68179_v12 = vxor.u32 %v68178_v52, %v68170_v50 (stack48)
        %v67362_v53 = vadd.s32 5, %v67358_v23 (stack40)
        %v68596_v32 = vxor.u32 %v68595_v42, %v141739_v7 (stack48)
        %v69024_v46 = vadd.s32 %v69020_v46, %v69016_v30 (stack40)
        %v69028_v61 = vor.u32 %v69027_v29, %v69026_v61 (stack47)
        %v66597_v20 = vadd.f32 %v66593_v26, %v141719_v20 (stack53)
        %v67789_v9 = vadd.s32 %v67786_v27, %v67781_v9 (stack40)
        %v67791_v44 = vshll.u32 %v67786_v27, 16 (stack45)
        %v67792_v25 = vshrl.u32 %v67786_v27, 16 (stack46)
        %v67364_v6 = vxor.u32 %v67362_v53, %v67350_v60 (stack48)
        %v68182_v40 = vadd.s32 %v68179_v12, %v121574_v2 (stack40)
        %v68599_v52 = vadd.s32 %v68596_v32, %v121564_v0 (stack40)
        %v141764_v24 = vxor.u32 %v69028_v61, %v69024_v46 (stack48)
        %v66601_v23 = vmul.f32 %v66597_v20, %v141707_v34 (stack54)
        %v66947_v55 = vmul.f32 %v66946_v54, %v141731_v55 (stack63)
        %v67793_v54 = vor.u32 %v67792_v25, %v67791_v44 (stack47)
        %vm69451_vm14 = vcmp.lt.u32.totalorder %v141686_v56, %v157083_v59 (stack43)
        %v121002_v42 = vpop.eup %121001 (stack64)
        %v67365_v30 = vand.u32.u8 255, %v67364_v6 (stack49)
        %v68174_v50 = vadd.s32 %v68170_v50, %v121564_v0 (stack40)
        %v68186_v29 = vadd.s32 2, %v68182_v40 (stack40)
        %v141772_v26 = vadd.s32 %v141764_v24, %v69024_v46 (stack40)
        %v66605_v43 = vadd.f32 %v66601_v23, %v141659_v43 (stack53)
        %v66944_v60 = vmul.f32 0.6931472, %v121002_v42 (stack65)
        %v67794_v27 = vxor.u32 %v67793_v54, %v67789_v9 (stack48)
        %v68603_v12 = vadd.s32 1, %v68599_v52 (stack40)
        %v67366_v53 = vand.u32 65535, %v67365_v30 (stack50)
        %v68190_v32 = vadd.s32 %v68186_v29, %v68174_v50 (stack40)
        %v68192_v46 = vshll.u32 %v68186_v29, 13 (stack45)
        %v68591_v7 = vadd.s32 %v141739_v7, %v121569_v1 (stack40)
        %v66609_v34 = vmul.f32 %v66605_v43, %v141707_v34 (stack54)
        %v66950_v31 = vsel /*vm=*/%vm141752_vm13, /*on_true_vy=*/%v66947_v55, /*on_false_vx=*/%v66944_v60 (stack66)
        %v67797_v61 = vadd.s32 %v67794_v27, %v67789_v9 (stack40)
        %v68193_v20 = vshrl.u32 %v68186_v29, 19 (stack46)
        %v66498_v8 = vsel /*vm=*/%vm66493_vm8, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v141783_v9 = vxor.u32 2147483648, %v66950_v31 (stack56)
        %v67803_v44 = vshll.u32 %v67794_v27, 24 (stack45)
        %v67804_v25 = vshrl.u32 %v67794_v27, 8 (stack46)
        %v66613_v6 = vadd.f32 %v66609_v34, %v66498_v8 (stack53)
        %v68607_v40 = vadd.s32 %v68603_v12, %v68591_v7 (stack40)
        %121003 = vrsqrt.f32 %v141783_v9 (stack67)
        %v67367_v52 = vshrl.u32 %v67366_v53, 1 (stack51)
        %v66474_v23 = vmul.f32 inf, %v141577_v45 (stack54)
        %v66617_v55 = vmul.f32 %v66613_v6, %v141577_v45 (stack54)
        %vm66954_vm15 = vcmp.lt.f32.partialorder %v141783_v9, 5.0 (stack68)
        %v68194_v54 = vor.u32 %v68193_v20, %v68192_v46 (stack47)
        %vm66469_vm0 = vcmp.eq.f32.partialorder %v66466_v10, 1.0 (stack68)
        %v66927_v45 = vand.u32 2147483647, %v141714_v21 (stack77)
        %v67805_v10 = vor.u32 %v67804_v25, %v67803_v44 (stack47)
        %v141794_v42 = vadd.s32 %v141686_v56, %v122657_v58 (stack40)
        %v66621_v30 = vsel /*vm=*/%vm66469_vm0, /*on_true_vy=*/%v66474_v23, /*on_false_vx=*/%v66617_v55 (stack44)
        %v67801_v50 = vadd.s32 %v67797_v61, %v121569_v1 (stack40)
        %v68609_v29 = vshll.u32 %v68603_v12, 17 (stack45)
        %v69034_v43 = vshll.u32 %v141764_v24, 15 (stack45)
        %v66625_v60 = vmul.f32 1.4140625, %v66621_v30 (stack54)
        %v141801_v27 = vsel /*vm=*/%vm66954_vm15, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v141804_v53 = vadd.f32 -2.5, %v141783_v9 (stack53)
        %v67368_v46 = vor.u32 16256, %v67367_v52 (stack47)
        %v67806_v7 = vxor.u32 %v67805_v10, %v67797_v61 (stack48)
        %v68195_v34 = vxor.u32 %v68194_v54, %v68190_v32 (stack48)
        %v68610_v12 = vshrl.u32 %v68603_v12, 15 (stack46)
        %v69035_v24 = vshrl.u32 %v141764_v24, 17 (stack46)
        %v66628_v31 = vpack.c.bf16 %v157387_v11, %v66625_v60 (stack81)
        %v141811_v61 = vsel /*vm=*/%vm66954_vm15, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v67369_v20 = vand.u32.u16 65535, %v67368_v46 (stack52)
        %v69456_v8 = vadd.s32 %v157487_v22, %v157084_v16 (stack40)
        %vm66999_vm1 = vcmp.eq.f32.partialorder %v141783_v9, inf (stack70)
        %v67809_v44 = vadd.s32 %v67806_v7, %v121564_v0 (stack40)
        %v68198_v32 = vadd.s32 %v68195_v34, %v68190_v32 (stack40)
        %v68200_v25 = vshll.u32 %v68195_v34, 15 (stack45)
        %v68201_v6 = vshrl.u32 %v68195_v34, 17 (stack46)
        %120099 = vst [vmem:[%s123356_s30 + $0x2c4] sm:$0xf] /*vst_source=*/%v66628_v31 (stack83)
        %v120102_v52 = vadd.low.f32.bf16 -1.0, %v67369_v20 (stack53)
        %v68611_v23 = vor.u32 %v68610_v12, %v68609_v29 (stack47)
        %v69036_v55 = vor.u32 %v69035_v24, %v69034_v43 (stack47)
        %v69460_v54 = vadd.s32 1, %v69456_v8 (stack40)
        %v141821_v10 = vsel /*vm=*/%vm66954_vm15, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v141826_v30 = vsel /*vm=*/%vm66954_vm15, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v67813_v29 = vadd.s32 4, %v67809_v44 (stack40)
        %v68202_v43 = vor.u32 %v68201_v6, %v68200_v25 (stack47)
        %v67378_v60 = vmul.f32 2.0, %v120102_v52 (stack54)
        %v68612_v46 = vxor.u32 %v68611_v23, %v68607_v40 (stack48)
        %v69037_v7 = vxor.u32 %v69036_v55, %v141772_v26 (stack48)
        %v141832_v34 = vsel /*vm=*/%vm69451_vm14, /*on_true_vy=*/%v69460_v54, /*on_false_vx=*/%v69456_v8 (stack44)
        %v67817_v50 = vadd.s32 %v67813_v29, %v67801_v50 (stack40)
        %v67819_v12 = vshll.u32 %v67813_v29, 13 (stack45)
        %v67820_v24 = vshrl.u32 %v67813_v29, 19 (stack46)
        %v68203_v31 = vxor.u32 %v68202_v43, %v68198_v32 (stack48)
        %v67382_v20 = vadd.f32 -0.99609375, %v67378_v60 (stack53)
        %v68615_v40 = vadd.s32 %v68612_v46, %v68607_v40 (stack40)
        %v68617_v8 = vshll.u32 %v68612_v46, 29 (stack45)
        %v68618_v44 = vshrl.u32 %v68612_v46, 3 (stack46)
        %v121004_v25 = vpop.eup %121003 (stack73)
        %v67821_v6 = vor.u32 %v67820_v24, %v67819_v12 (stack47)
        %v68206_v32 = vadd.s32 %v68203_v31, %v68198_v32 (stack40)
        %v68208_v52 = vshll.u32 %v68203_v31, 26 (stack45)
        %v68209_v23 = vshrl.u32 %v68203_v31, 6 (stack46)
        %v66998_v55 = vmul.f32 %v121004_v25, %v141783_v9 (stack74)
        %vm67001_vm2 = vcmp.eq.f32.partialorder %v141783_v9, 0.0 (stack71)
        %v141836_v54 = vmax.f32 %v67382_v20, -0.99609375 (stack55)
        %v69040_v26 = vadd.s32 %v69037_v7, %v141772_v26 (stack40)
        %v67002_v29 = vand.u32 2147483648, %v141783_v9 (stack72)
        %v67822_v43 = vxor.u32 %v67821_v6, %v67817_v50 (stack48)
        %v68210_v60 = vor.u32 %v68209_v23, %v68208_v52 (stack47)
        %v68619_v46 = vor.u32 %v68618_v44, %v68617_v8 (stack47)
        %vm69446_vm3 = vcmp.lt.u32.totalorder %v141794_v42, %v141686_v56 (stack43)
        %v67000_v12 = vsel /*vm=*/%vm66999_vm1, /*on_true_vy=*/%v141783_v9, /*on_false_vx=*/%v66998_v55 (stack75)
        %v67398_v24 = vxor.u32 2147483648, %v141836_v54 (stack56)
        %v69042_v31 = vshll.u32 %v69037_v7, 26 (stack45)
        %v69481_v20 = vadd.s32 %v141794_v42, %v121569_v1 (stack40)
        %v67003_v8 = vsel /*vm=*/%vm67001_vm2, /*on_true_vy=*/%v67002_v29, /*on_false_vx=*/%v67000_v12 (stack76)
        %v67825_v50 = vadd.s32 %v67822_v43, %v67817_v50 (stack40)
        %v67827_v44 = vshll.u32 %v67822_v43, 15 (stack45)
        %v67828_v25 = vshrl.u32 %v67822_v43, 17 (stack46)
        %v67006_v6 = vadd.f32 -3.0, %v67003_v8 (stack53)
        %v141849_v52 = vmul.f32 %v67398_v24, %v141836_v54 (stack54)
        %v68211_v23 = vxor.u32 %v68210_v60, %v68206_v32 (stack48)
        %v69043_v7 = vshrl.u32 %v69037_v7, 6 (stack46)
        %v66987_v55 = vsel /*vm=*/%vm66954_vm15, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v66991_v29 = vsel /*vm=*/%vm66954_vm15, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v67829_v43 = vor.u32 %v67828_v25, %v67827_v44 (stack47)
        %v68620_v60 = vxor.u32 %v68619_v46, %v68615_v40 (stack48)
        %v141860_v53 = vsel /*vm=*/%vm66954_vm15, /*on_true_vy=*/%v141804_v53, /*on_false_vx=*/%v67006_v6 (stack44)
        %v67403_v46 = vadd.f32 1.0, %v141849_v52 (stack57)
        %v69487_v12 = vshll.u32 %v69481_v20, 13 (stack45)
        %v69488_v24 = vshrl.u32 %v69481_v20, 19 (stack46)
        %v67014_v8 = vmul.f32 %v141860_v53, %v66991_v29 (stack54)
        %v67830_v44 = vxor.u32 %v67829_v43, %v67825_v50 (stack48)
        %v68214_v32 = vadd.s32 %v68211_v23, %v68206_v32 (stack40)
        %v68220_v25 = vshll.u32 %v68211_v23, 6 (stack45)
        %121005 = vlog2.f32 %v67403_v46 (stack58)
        %v68221_v6 = vshrl.u32 %v68211_v23, 26 (stack46)
        %v69044_v31 = vor.u32 %v69043_v7, %v69042_v31 (stack47)
        %v69468_v23 = vadd.s32 1, %v141832_v34 (stack40)
        %v67018_v7 = vadd.f32 %v67014_v8, %v66987_v55 (stack53)
        %v67833_v50 = vadd.s32 %v67830_v44, %v67825_v50 (stack40)
        %v67835_v55 = vshll.u32 %v67830_v44, 26 (stack45)
        %v67836_v29 = vshrl.u32 %v67830_v44, 6 (stack46)
        %v67406_v43 = vmul.f32 -0.5, %v141849_v52 (stack59)
        %v67409_v46 = vand.u32 2147483647, %v141849_v52 (stack60)
        %v68222_v8 = vor.u32 %v68221_v6, %v68220_v25 (stack47)
        %v68623_v40 = vadd.s32 %v68620_v60, %v68615_v40 (stack40)
        %v67022_v44 = vmul.f32 %v67018_v7, %v141860_v53 (stack54)
        %v67837_v25 = vor.u32 %v67836_v29, %v67835_v55 (stack47)
        %v68625_v6 = vshll.u32 %v68620_v60, 16 (stack45)
        %v68626_v60 = vshrl.u32 %v68620_v60, 16 (stack46)
        %v68218_v7 = vadd.s32 %v68214_v32, %v121574_v2 (stack40)
        %v68223_v32 = vxor.u32 %v68222_v8, %v68214_v32 (stack48)
        %v69045_v31 = vxor.u32 %v69044_v31, %v69040_v26 (stack48)
        %v69472_v56 = vsel /*vm=*/%vm69446_vm3, /*on_true_vy=*/%v69468_v23, /*on_false_vx=*/%v141832_v34 (stack44)
        %v67026_v42 = vadd.f32 %v67022_v44, %v141826_v30 (stack53)
        %v67838_v30 = vxor.u32 %v67837_v25, %v67833_v50 (stack48)
        %v68627_v34 = vor.u32 %v68626_v60, %v68625_v6 (stack47)
        %v69477_v23 = vadd.s32 %v69472_v56, %v121574_v2 (stack40)
        %v68226_v55 = vadd.s32 %v68223_v32, %v121569_v1 (stack40)
        %v69048_v26 = vadd.s32 %v69045_v31, %v69040_v26 (stack40)
        %v69054_v29 = vshll.u32 %v69045_v31, 6 (stack45)
        %v69055_v8 = vshrl.u32 %v69045_v31, 26 (stack46)
        %v67030_v44 = vmul.f32 %v67026_v42, %v141860_v53 (stack54)
        %v67841_v50 = vadd.s32 %v67838_v30, %v67833_v50 (stack40)
        %v67847_v25 = vshll.u32 %v67838_v30, 6 (stack45)
        %v67848_v6 = vshrl.u32 %v67838_v30, 26 (stack46)
        %v68230_v60 = vadd.s32 3, %v68226_v55 (stack40)
        %v68628_v32 = vxor.u32 %v68627_v34, %v68623_v40 (stack48)
        %v69056_v31 = vor.u32 %v69055_v8, %v69054_v29 (stack47)
        %v69489_v12 = vor.u32 %v69488_v24, %v69487_v12 (stack47)
        %v67034_v10 = vadd.f32 %v67030_v44, %v141821_v10 (stack53)
        %v67407_v24 = vadd.f32 1.0, %v67406_v43 (stack61)
        %v67849_v43 = vor.u32 %v67848_v6, %v67847_v25 (stack47)
        %v69485_v20 = vadd.s32 %v69481_v20, %v69477_v23 (stack40)
        %v68234_v7 = vadd.s32 %v68230_v60, %v68218_v7 (stack40)
        %v68236_v56 = vshll.u32 %v68230_v60, 17 (stack45)
        %v68237_v42 = vshrl.u32 %v68230_v60, 15 (stack46)
        %v68631_v40 = vadd.s32 %v68628_v32, %v68623_v40 (stack40)
        %v67038_v30 = vmul.f32 %v67034_v10, %v141860_v53 (stack54)
        %v67850_v34 = vxor.u32 %v67849_v43, %v67841_v50 (stack48)
        %v68637_v23 = vshll.u32 %v68628_v32, 24 (stack45)
        %v68638_v55 = vshrl.u32 %v68628_v32, 8 (stack46)
        %vm141879_vm4 = vcmp.lt.f32.partialorder %v67409_v46, 0.0004427343 (stack62)
        %v68238_v29 = vor.u32 %v68237_v42, %v68236_v56 (stack47)
        %v69057_v8 = vxor.u32 %v69056_v31, %v69048_v26 (stack48)
        %v141883_v44 = vxor.u32 %v69489_v12, %v69485_v20 (stack48)
        %v121006_v25 = vpop.eup %121005 (stack64)
        %v67042_v61 = vadd.f32 %v67038_v30, %v141811_v61 (stack53)
        %v67853_v6 = vadd.s32 %v67850_v34, %v121574_v2 (stack40)
        %v68639_v60 = vor.u32 %v68638_v55, %v68637_v23 (stack47)
        %v141889_v32 = vadd.s32 %v157486_v41, %v157089_v17 (stack40)
        %v67405_v31 = vmul.f32 0.6931472, %v121006_v25 (stack65)
        %v67408_v52 = vmul.f32 %v67407_v24, %v141849_v52 (stack63)
        %v68239_v12 = vxor.u32 %v68238_v29, %v68234_v7 (stack48)
        %v141893_v10 = vadd.s32 %v141883_v44, %v69485_v20 (stack40)
        %v67046_v24 = vmul.f32 %v67042_v61, %v141860_v53 (stack54)
        %v67845_v50 = vadd.s32 %v67841_v50, %v121564_v0 (stack40)
        %v67857_v43 = vadd.s32 5, %v67853_v6 (stack40)
        %v68640_v20 = vxor.u32 %v68639_v60, %v68631_v40 (stack48)
        %v67411_v56 = vsel /*vm=*/%vm141879_vm4, /*on_true_vy=*/%v67408_v52, /*on_false_vx=*/%v67405_v31 (stack66)
        %v68242_v7 = vadd.s32 %v68239_v12, %v68234_v7 (stack40)
        %v68244_v42 = vshll.u32 %v68239_v12, 29 (stack45)
        %v68245_v30 = vshrl.u32 %v68239_v12, 3 (stack46)
        %v67050_v27 = vadd.f32 %v67046_v24, %v141801_v27 (stack53)
        %v141900_v34 = vxor.u32 2147483648, %v67411_v56 (stack56)
        %v67859_v23 = vxor.u32 %v67857_v43, %v67845_v50 (stack48)
        %v69060_v55 = vadd.s32 %v69057_v8, %v121564_v0 (stack40)
        %v141904_v46 = vmul.f32 inf, %v141714_v21 (stack54)
        %v66959_v29 = vsel /*vm=*/%vm66954_vm15, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v66963_v8 = vsel /*vm=*/%vm66954_vm15, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v68246_v25 = vor.u32 %v68245_v30, %v68244_v42 (stack47)
        %v66967_v9 = vsel /*vm=*/%vm66954_vm15, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v67054_v61 = vmul.f32 %v67050_v27, %v141860_v53 (stack54)
        %v67388_v6 = vand.u32 2147483647, %v141836_v54 (stack77)
        %121007 = vrsqrt.f32 %v141900_v34 (stack67)
        %vm67415_vm5 = vcmp.lt.f32.partialorder %v141900_v34, 5.0 (stack68)
        %v68247_v60 = vxor.u32 %v68246_v25, %v68242_v7 (stack48)
        %v68643_v31 = vadd.s32 %v68640_v20, %v121574_v2 (stack40)
        %v69052_v26 = vadd.s32 %v69048_v26, %v121569_v1 (stack40)
        %v67058_v52 = vadd.f32 %v67054_v61, %v66967_v9 (stack53)
        %v68635_v40 = vadd.s32 %v68631_v40, %v121564_v0 (stack40)
        %v69064_v12 = vadd.s32 1, %v69060_v55 (stack40)
        %v69495_v24 = vshll.u32 %v141883_v44, 15 (stack45)
        %v141924_v50 = vadd.f32 -2.5, %v141900_v34 (stack53)
        %v68250_v43 = vadd.s32 %v68247_v60, %v68242_v7 (stack40)
        %v69496_v44 = vshrl.u32 %v141883_v44, 17 (stack46)
        %v141929_v20 = vadd.s32 %v141889_v32, %v122657_v58 (stack40)
        %v67062_v56 = vmul.f32 %v67058_v52, %v141860_v53 (stack54)
        %v141935_v7 = vsel /*vm=*/%vm67415_vm5, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v141940_v42 = vsel /*vm=*/%vm67415_vm5, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v141945_v30 = vsel /*vm=*/%vm67415_vm5, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %vm141949_vm6 = vcmp.eq.f32.partialorder %v66927_v45, 1.0 (stack68)
        %v67860_v27 = vand.u32.u8 255, %v67859_v23 (stack49)
        %v68252_v23 = vshll.u32 %v68247_v60, 16 (stack45)
        %v68253_v55 = vshrl.u32 %v68247_v60, 16 (stack46)
        %v68647_v25 = vadd.s32 2, %v68643_v31 (stack40)
        %v67066_v8 = vadd.f32 %v67062_v56, %v66963_v8 (stack53)
        %v69068_v9 = vadd.s32 %v69064_v12, %v69052_v26 (stack40)
        %v69070_v61 = vshll.u32 %v69064_v12, 17 (stack45)
        %v69071_v60 = vshrl.u32 %v69064_v12, 15 (stack46)
        %v67861_v31 = vand.u32 65535, %v67860_v27 (stack50)
        %v68254_v26 = vor.u32 %v68253_v55, %v68252_v23 (stack47)
        %v68651_v52 = vadd.s32 %v68647_v25, %v68635_v40 (stack40)
        %v68653_v40 = vshll.u32 %v68647_v25, 13 (stack45)
        %v67070_v53 = vmul.f32 %v67066_v8, %v141860_v53 (stack54)
        %v68654_v12 = vshrl.u32 %v68647_v25, 19 (stack46)
        %v69072_v56 = vor.u32 %v69071_v60, %v69070_v61 (stack47)
        %v69497_v24 = vor.u32 %v69496_v44, %v69495_v24 (stack47)
        %vm67460_vm7 = vcmp.eq.f32.partialorder %v141900_v34, inf (stack70)
        %v67862_v44 = vshrl.u32 %v67861_v31, 1 (stack51)
        %v68255_v27 = vxor.u32 %v68254_v26, %v68250_v43 (stack48)
        %vm69912_vm8 = vcmp.lt.u32.totalorder %v141889_v32, %v157089_v17 (stack43)
        %v67074_v29 = vadd.f32 %v67070_v53, %v66959_v29 (stack53)
        %v68655_v23 = vor.u32 %v68654_v12, %v68653_v40 (stack47)
        %v69073_v55 = vxor.u32 %v69072_v56, %v69068_v9 (stack48)
        %v69498_v25 = vxor.u32 %v69497_v24, %v141893_v10 (stack48)
        %v67863_v8 = vor.u32 16256, %v67862_v44 (stack47)
        %v68258_v43 = vadd.s32 %v68255_v27, %v68250_v43 (stack40)
        %v68264_v61 = vshll.u32 %v68255_v27, 24 (stack45)
        %v68265_v60 = vshrl.u32 %v68255_v27, 8 (stack46)
        %v67078_v21 = vmul.f32 %v67074_v29, %v141714_v21 (stack54)
        %v68656_v31 = vxor.u32 %v68655_v23, %v68651_v52 (stack48)
        %v69076_v9 = vadd.s32 %v69073_v55, %v69068_v9 (stack40)
        %v69078_v26 = vshll.u32 %v69073_v55, 29 (stack45)
        %v121008_v40 = vpop.eup %121007 (stack73)
        %v67463_v53 = vand.u32 2147483648, %v141900_v34 (stack72)
        %v67864_v12 = vand.u32.u16 65535, %v67863_v8 (stack52)
        %v68266_v56 = vor.u32 %v68265_v60, %v68264_v61 (stack47)
        %v69079_v24 = vshrl.u32 %v69073_v55, 3 (stack46)
        %v67082_v46 = vsel /*vm=*/%vm141949_vm6, /*on_true_vy=*/%v141904_v46, /*on_false_vx=*/%v67078_v21 (stack44)
        %v67459_v45 = vmul.f32 %v121008_v40, %v141900_v34 (stack74)
        %v68659_v52 = vadd.s32 %v68656_v31, %v68651_v52 (stack40)
        %v68661_v44 = vshll.u32 %v68656_v31, 15 (stack45)
        %v67086_v27 = vmul.f32 1.4140625, %v67082_v46 (stack54)
        %v120108_v29 = vadd.low.f32.bf16 -1.0, %v67864_v12 (stack53)
        %v68267_v23 = vxor.u32 %v68266_v56, %v68258_v43 (stack48)
        %v68662_v55 = vshrl.u32 %v68656_v31, 17 (stack46)
        %v67461_v8 = vsel /*vm=*/%vm67460_vm7, /*on_true_vy=*/%v141900_v34, /*on_false_vx=*/%v67459_v45 (stack75)
        %vm67462_vm9 = vcmp.eq.f32.partialorder %v141900_v34, 0.0 (stack71)
        %v69080_v61 = vor.u32 %v69079_v24, %v69078_v26 (stack47)
        %v69501_v10 = vadd.s32 %v69498_v25, %v141893_v10 (stack40)
        %v67089_v60 = vpack.c.bf16 %v157387_v11, %v67086_v27 (stack81)
        %v67464_v21 = vsel /*vm=*/%vm67462_vm9, /*on_true_vy=*/%v67463_v53, /*on_false_vx=*/%v67461_v8 (stack76)
        %v67873_v31 = vmul.f32 2.0, %v120108_v29 (stack54)
        %v68270_v26 = vadd.s32 %v68267_v23, %v121564_v0 (stack40)
        %v67467_v40 = vadd.f32 -3.0, %v67464_v21 (stack53)
        %v68262_v43 = vadd.s32 %v68258_v43, %v121569_v1 (stack40)
        %v68663_v53 = vor.u32 %v68662_v55, %v68661_v44 (stack47)
        %v69081_v12 = vxor.u32 %v69080_v61, %v69076_v9 (stack48)
        %120101 = vst [vmem:[%s123356_s30 + $0x344] sm:$0xf] /*vst_source=*/%v67089_v60 (stack83)
        %v67877_v56 = vadd.f32 -0.99609375, %v67873_v31 (stack53)
        %v68274_v24 = vadd.s32 4, %v68270_v26 (stack40)
        %v69503_v46 = vshll.u32 %v69498_v25, 26 (stack45)
        %v141975_v45 = vadd.s32 %v157487_v22, %v157090_v62 (stack40)
        %v141980_v50 = vsel /*vm=*/%vm67415_vm5, /*on_true_vy=*/%v141924_v50, /*on_false_vx=*/%v67467_v40 (stack44)
        %v68664_v44 = vxor.u32 %v68663_v53, %v68659_v52 (stack48)
        %v69084_v9 = vadd.s32 %v69081_v12, %v69076_v9 (stack40)
        %v69504_v25 = vshrl.u32 %v69498_v25, 6 (stack46)
        %v67475_v30 = vmul.f32 %v141980_v50, %v141945_v30 (stack54)
        %v141984_v27 = vmax.f32 %v67877_v56, -0.99609375 (stack55)
        %v68278_v29 = vadd.s32 %v68274_v24, %v68262_v43 (stack40)
        %v68280_v23 = vshll.u32 %v68274_v24, 13 (stack45)
        %v68281_v55 = vshrl.u32 %v68274_v24, 19 (stack46)
        %v68667_v52 = vadd.s32 %v68664_v44, %v68659_v52 (stack40)
        %v68669_v8 = vshll.u32 %v68664_v44, 26 (stack45)
        %v68670_v61 = vshrl.u32 %v68664_v44, 6 (stack46)
        %v141989_v60 = vsel /*vm=*/%vm67415_vm5, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v67479_v42 = vadd.f32 %v67475_v30, %v141940_v42 (stack53)
        %v67893_v21 = vxor.u32 2147483648, %v141984_v27 (stack56)
        %v69086_v31 = vshll.u32 %v69081_v12, 16 (stack45)
        %v68282_v26 = vor.u32 %v68281_v55, %v68280_v23 (stack47)
        %v68671_v40 = vor.u32 %v68670_v61, %v68669_v8 (stack47)
        %v69087_v43 = vshrl.u32 %v69081_v12, 16 (stack46)
        %v69505_v53 = vor.u32 %v69504_v25, %v69503_v46 (stack47)
        %v67436_v12 = vsel /*vm=*/%vm67415_vm5, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v67440_v56 = vsel /*vm=*/%vm67415_vm5, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v67483_v24 = vmul.f32 %v67479_v42, %v141980_v50 (stack54)
        %v67896_v46 = vmul.f32 %v67893_v21, %v141984_v27 (stack54)
        %v67444_v44 = vsel /*vm=*/%vm67415_vm5, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v68283_v25 = vxor.u32 %v68282_v26, %v68278_v29 (stack48)
        %v68672_v30 = vxor.u32 %v68671_v40, %v68667_v52 (stack48)
        %v69506_v23 = vxor.u32 %v69505_v53, %v69501_v10 (stack48)
        %v67487_v55 = vadd.f32 %v67483_v24, %v67444_v44 (stack53)
        %v67898_v8 = vadd.f32 1.0, %v67896_v46 (stack57)
        %v67901_v61 = vmul.f32 -0.5, %v67896_v46 (stack59)
        %v69088_v42 = vor.u32 %v69087_v43, %v69086_v31 (stack47)
        %v68286_v29 = vadd.s32 %v68283_v25, %v68278_v29 (stack40)
        %v68288_v21 = vshll.u32 %v68283_v25, 15 (stack45)
        %v68289_v31 = vshrl.u32 %v68283_v25, 17 (stack46)
        %v68675_v52 = vadd.s32 %v68672_v30, %v68667_v52 (stack40)
        %v67491_v26 = vmul.f32 %v67487_v55, %v141980_v50 (stack54)
        %121009 = vlog2.f32 %v67898_v8 (stack58)
        %vm69907_vm10 = vcmp.lt.u32.totalorder %v141929_v20, %v141889_v32 (stack43)
        %v69921_v40 = vadd.s32 1, %v141975_v45 (stack40)
        %v67904_v43 = vand.u32 2147483647, %v67896_v46 (stack60)
        %v68290_v53 = vor.u32 %v68289_v31, %v68288_v21 (stack47)
        %v68681_v24 = vshll.u32 %v68672_v30, 6 (stack45)
        %v68682_v44 = vshrl.u32 %v68672_v30, 26 (stack46)
        %v67495_v56 = vadd.f32 %v67491_v26, %v67440_v56 (stack53)
        %v67902_v25 = vadd.f32 1.0, %v67901_v61 (stack61)
        %v69089_v30 = vxor.u32 %v69088_v42, %v69084_v9 (stack48)
        %v69509_v10 = vadd.s32 %v69506_v23, %v69501_v10 (stack40)
        %v68291_v55 = vxor.u32 %v68290_v53, %v68286_v29 (stack48)
        %v68683_v8 = vor.u32 %v68682_v44, %v68681_v24 (stack47)
        %v69515_v61 = vshll.u32 %v69506_v23, 6 (stack45)
        %v69516_v23 = vshrl.u32 %v69506_v23, 26 (stack46)
        %v67499_v42 = vmul.f32 %v67495_v56, %v141980_v50 (stack54)
        %v69092_v9 = vadd.s32 %v69089_v30, %v69084_v9 (stack40)
        %v69098_v21 = vshll.u32 %v69089_v30, 24 (stack45)
        %v69099_v31 = vshrl.u32 %v69089_v30, 8 (stack46)
        %v68294_v29 = vadd.s32 %v68291_v55, %v68286_v29 (stack40)
        %v68296_v26 = vshll.u32 %v68291_v55, 26 (stack45)
        %v68297_v53 = vshrl.u32 %v68291_v55, 6 (stack46)
        %v68684_v24 = vxor.u32 %v68683_v8, %v68675_v52 (stack48)
        %v67503_v12 = vadd.f32 %v67499_v42, %v67436_v12 (stack53)
        %v68679_v52 = vadd.s32 %v68675_v52, %v121574_v2 (stack40)
        %v69100_v44 = vor.u32 %v69099_v31, %v69098_v21 (stack47)
        %v142012_v56 = vadd.s32 %v141929_v20, %v121569_v1 (stack40)
        %vm142014_vm11 = vcmp.lt.f32.partialorder %v67904_v43, 0.0004427343 (stack62)
        %v68298_v30 = vor.u32 %v68297_v53, %v68296_v26 (stack47)
        %v68687_v55 = vadd.s32 %v68684_v24, %v121569_v1 (stack40)
        %v69517_v8 = vor.u32 %v69516_v23, %v69515_v61 (stack47)
        %v69925_v45 = vsel /*vm=*/%vm69912_vm8, /*on_true_vy=*/%v69921_v40, /*on_false_vx=*/%v141975_v45 (stack44)
        %v67507_v40 = vmul.f32 %v67503_v12, %v141980_v50 (stack54)
        %v67903_v46 = vmul.f32 %v67902_v25, %v67896_v46 (stack63)
        %v69101_v25 = vxor.u32 %v69100_v44, %v69092_v9 (stack48)
        %v69929_v61 = vadd.s32 1, %v69925_v45 (stack40)
        %v68299_v23 = vxor.u32 %v68298_v30, %v68294_v29 (stack48)
        %v68691_v42 = vadd.s32 3, %v68687_v55 (stack40)
        %v69096_v9 = vadd.s32 %v69092_v9, %v121564_v0 (stack40)
        %v69518_v21 = vxor.u32 %v69517_v8, %v69509_v10 (stack48)
        %v67511_v60 = vadd.f32 %v67507_v40, %v141989_v60 (stack53)
        %v69104_v31 = vadd.s32 %v69101_v25, %v121574_v2 (stack40)
        %v69933_v32 = vsel /*vm=*/%vm69907_vm10, /*on_true_vy=*/%v69929_v61, /*on_false_vx=*/%v69925_v45 (stack44)
        %v142032_v20 = vadd.s32 %v157486_v41, %v157091_v37 (stack40)
        %v68302_v29 = vadd.s32 %v68299_v23, %v68294_v29 (stack40)
        %v68308_v26 = vshll.u32 %v68299_v23, 6 (stack45)
        %v68309_v53 = vshrl.u32 %v68299_v23, 26 (stack46)
        %v68695_v24 = vadd.s32 %v68691_v42, %v68679_v52 (stack40)
        %v67515_v12 = vmul.f32 %v67511_v60, %v141980_v50 (stack54)
        %v68697_v52 = vshll.u32 %v68691_v42, 17 (stack45)
        %v68698_v44 = vshrl.u32 %v68691_v42, 15 (stack46)
        %v69108_v30 = vadd.s32 2, %v69104_v31 (stack40)
        %v121010_v55 = vpop.eup %121009 (stack64)
        %v68310_v8 = vor.u32 %v68309_v53, %v68308_v26 (stack47)
        %v69513_v10 = vadd.s32 %v69509_v10, %v121569_v1 (stack40)
        %v69521_v45 = vadd.s32 %v69518_v21, %v121564_v0 (stack40)
        %v69938_v40 = vadd.s32 %v69933_v32, %v121574_v2 (stack40)
        %v67519_v7 = vadd.f32 %v67515_v12, %v141935_v7 (stack53)
        %v67900_v25 = vmul.f32 0.6931472, %v121010_v55 (stack65)
        %v68699_v61 = vor.u32 %v68698_v44, %v68697_v52 (stack47)
        %v69112_v23 = vadd.s32 %v69108_v30, %v69096_v9 (stack40)
        %v68311_v42 = vxor.u32 %v68310_v8, %v68302_v29 (stack48)
        %v69114_v9 = vshll.u32 %v69108_v30, 13 (stack45)
        %v69115_v21 = vshrl.u32 %v69108_v30, 19 (stack46)
        %v69525_v60 = vadd.s32 1, %v69521_v45 (stack40)
        %v67523_v31 = vmul.f32 %v67519_v7, %v141980_v50 (stack54)
        %v67906_v43 = vsel /*vm=*/%vm142014_vm11, /*on_true_vy=*/%v67903_v46, /*on_false_vx=*/%v67900_v25 (stack66)
        %v68700_v46 = vxor.u32 %v68699_v61, %v68695_v24 (stack48)
        %v142043_v32 = vadd.s32 %v142012_v56, %v69938_v40 (stack40)
        %v67396_v26 = vmul.f32 inf, %v141836_v54 (stack54)
        %v67424_v53 = vsel /*vm=*/%vm67415_vm5, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v142049_v12 = vxor.u32 2147483648, %v67906_v43 (stack56)
        %v142051_v52 = vadd.s32 %v69525_v60, %v69513_v10 (stack40)
        %v67527_v44 = vadd.f32 %v67523_v31, %v67424_v53 (stack53)
        %v68703_v24 = vadd.s32 %v68700_v46, %v68695_v24 (stack40)
        %v68705_v30 = vshll.u32 %v68700_v46, 29 (stack45)
        %v68706_v55 = vshrl.u32 %v68700_v46, 3 (stack46)
        %vm142055_vm12 = vcmp.eq.f32.partialorder %v67388_v6, 1.0 (stack68)
        %vm67910_vm13 = vcmp.lt.f32.partialorder %v142049_v12, 5.0 (stack68)
        %121011 = vrsqrt.f32 %v142049_v12 (stack67)
        %v68314_v8 = vadd.s32 %v68311_v42, %v121574_v2 (stack40)
        %v67420_v34 = vsel /*vm=*/%vm67415_vm5, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v67531_v50 = vmul.f32 %v67527_v44, %v141980_v50 (stack54)
        %v67883_v10 = vand.u32 2147483647, %v141984_v27 (stack77)
        %v69116_v45 = vor.u32 %v69115_v21, %v69114_v9 (stack47)
        %v68306_v29 = vadd.s32 %v68302_v29, %v121564_v0 (stack40)
        %v68707_v40 = vor.u32 %v68706_v55, %v68705_v30 (stack47)
        %v69948_v7 = vshll.u32 %v142012_v56, 13 (stack45)
        %v69949_v56 = vshrl.u32 %v142012_v56, 19 (stack46)
        %v67535_v25 = vadd.f32 %v67531_v50, %v67420_v34 (stack53)
        %v142073_v61 = vsel /*vm=*/%vm67910_vm13, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v142078_v42 = vsel /*vm=*/%vm67910_vm13, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v142081_v9 = vadd.f32 -2.5, %v142049_v12 (stack53)
        %v142086_v21 = vsel /*vm=*/%vm67910_vm13, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v142091_v31 = vsel /*vm=*/%vm67910_vm13, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v68318_v43 = vadd.s32 5, %v68314_v8 (stack40)
        %v68708_v46 = vxor.u32 %v68707_v40, %v68703_v24 (stack48)
        %v67539_v54 = vmul.f32 %v67535_v25, %v141836_v54 (stack54)
        %v69117_v53 = vxor.u32 %v69116_v45, %v69112_v23 (stack48)
        %v69531_v44 = vshll.u32 %v69525_v60, 17 (stack45)
        %v69532_v60 = vshrl.u32 %v69525_v60, 15 (stack46)
        %v68320_v30 = vxor.u32 %v68318_v43, %v68306_v29 (stack48)
        %v68711_v24 = vadd.s32 %v68708_v46, %v68703_v24 (stack40)
        %v68713_v55 = vshll.u32 %v68708_v46, 16 (stack45)
        %v68714_v8 = vshrl.u32 %v68708_v46, 16 (stack46)
        %v67543_v26 = vsel /*vm=*/%vm142055_vm12, /*on_true_vy=*/%v67396_v26, /*on_false_vx=*/%v67539_v54 (stack44)
        %vm67955_vm14 = vcmp.eq.f32.partialorder %v142049_v12, inf (stack70)
        %v69120_v23 = vadd.s32 %v69117_v53, %v69112_v23 (stack40)
        %v69122_v6 = vshll.u32 %v69117_v53, 15 (stack45)
        %v69123_v34 = vshrl.u32 %v69117_v53, 17 (stack46)
        %v67547_v50 = vmul.f32 1.4140625, %v67543_v26 (stack54)
        %v68321_v45 = vand.u32.u8 255, %v68320_v30 (stack49)
        %v68715_v29 = vor.u32 %v68714_v8, %v68713_v55 (stack47)
        %v69533_v40 = vor.u32 %v69532_v60, %v69531_v44 (stack47)
        %v67947_v25 = vsel /*vm=*/%vm67910_vm13, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v69124_v43 = vor.u32 %v69123_v34, %v69122_v6 (stack47)
        %v69950_v7 = vor.u32 %v69949_v56, %v69948_v7 (stack47)
        %vm70373_vm15 = vcmp.lt.u32.totalorder %v142032_v20, %v157091_v37 (stack43)
        %v67550_v56 = vpack.c.bf16 %v157387_v11, %v67547_v50 (stack81)
        %v68322_v46 = vand.u32 65535, %v68321_v45 (stack50)
        %v68716_v54 = vxor.u32 %v68715_v29, %v68711_v24 (stack48)
        %v69534_v53 = vxor.u32 %v69533_v40, %v142051_v52 (stack48)
        %vm67957_vm0 = vcmp.eq.f32.partialorder %v142049_v12, 0.0 (stack71)
        %v69125_v44 = vxor.u32 %v69124_v43, %v69120_v23 (stack48)
        %v69951_v60 = vxor.u32 %v69950_v7, %v142043_v32 (stack48)
        %v70378_v30 = vadd.s32 %v157487_v22, %v157094_v36 (stack40)
        %120103 = vst [vmem:[%s123356_s30 + $0x3c4] sm:$0xf] /*vst_source=*/%v67550_v56 (stack83)
        %v68323_v55 = vshrl.u32 %v68322_v46, 1 (stack51)
        %v68719_v24 = vadd.s32 %v68716_v54, %v68711_v24 (stack40)
        %v68725_v8 = vshll.u32 %v68716_v54, 24 (stack45)
        %v68726_v26 = vshrl.u32 %v68716_v54, 8 (stack46)
        %v121012_v6 = vpop.eup %121011 (stack73)
        %v69128_v23 = vadd.s32 %v69125_v44, %v69120_v23 (stack40)
        %v69130_v34 = vshll.u32 %v69125_v44, 26 (stack45)
        %v69131_v50 = vshrl.u32 %v69125_v44, 6 (stack46)
        %v69537_v52 = vadd.s32 %v69534_v53, %v142051_v52 (stack40)
        %v67954_v45 = vmul.f32 %v121012_v6, %v142049_v12 (stack74)
        %v67958_v29 = vand.u32 2147483648, %v142049_v12 (stack72)
        %v68324_v40 = vor.u32 16256, %v68323_v55 (stack47)
        %v68727_v43 = vor.u32 %v68726_v26, %v68725_v8 (stack47)
        %v69132_v7 = vor.u32 %v69131_v50, %v69130_v34 (stack47)
        %v69539_v56 = vshll.u32 %v69534_v53, 29 (stack45)
        %v69540_v46 = vshrl.u32 %v69534_v53, 3 (stack46)
        %v69954_v32 = vadd.s32 %v69951_v60, %v142043_v32 (stack40)
        %v67956_v54 = vsel /*vm=*/%vm67955_vm14, /*on_true_vy=*/%v142049_v12, /*on_false_vx=*/%v67954_v45 (stack75)
        %v68325_v53 = vand.u32.u16 65535, %v68324_v40 (stack52)
        %v68728_v44 = vxor.u32 %v68727_v43, %v68719_v24 (stack48)
        %v69956_v55 = vshll.u32 %v69951_v60, 15 (stack45)
        %v67959_v8 = vsel /*vm=*/%vm67957_vm0, /*on_true_vy=*/%v67958_v29, /*on_false_vx=*/%v67956_v54 (stack76)
        %v69133_v26 = vxor.u32 %v69132_v7, %v69128_v23 (stack48)
        %v69541_v6 = vor.u32 %v69540_v46, %v69539_v56 (stack47)
        %v69957_v60 = vshrl.u32 %v69951_v60, 17 (stack46)
        %v67962_v34 = vadd.f32 -3.0, %v67959_v8 (stack53)
        %v120110_v50 = vadd.low.f32.bf16 -1.0, %v68325_v53 (stack53)
        %v68723_v24 = vadd.s32 %v68719_v24, %v121569_v1 (stack40)
        %v68731_v45 = vadd.s32 %v68728_v44, %v121564_v0 (stack40)
        %v69136_v23 = vadd.s32 %v69133_v26, %v69128_v23 (stack40)
        %v69142_v29 = vshll.u32 %v69133_v26, 6 (stack45)
        %v69143_v40 = vshrl.u32 %v69133_v26, 26 (stack46)
        %v69542_v43 = vxor.u32 %v69541_v6, %v69537_v52 (stack48)
        %v142123_v9 = vsel /*vm=*/%vm67910_vm13, /*on_true_vy=*/%v142081_v9, /*on_false_vx=*/%v67962_v34 (stack44)
        %v68334_v7 = vmul.f32 2.0, %v120110_v50 (stack54)
        %v68735_v56 = vadd.s32 4, %v68731_v45 (stack40)
        %v69958_v46 = vor.u32 %v69957_v60, %v69956_v55 (stack47)
        %v67970_v25 = vmul.f32 %v142123_v9, %v67947_v25 (stack54)
        %v69144_v54 = vor.u32 %v69143_v40, %v69142_v29 (stack47)
        %v69545_v52 = vadd.s32 %v69542_v43, %v69537_v52 (stack40)
        %v70382_v53 = vadd.s32 1, %v70378_v30 (stack40)
        %v68338_v44 = vadd.f32 -0.99609375, %v68334_v7 (stack53)
        %v68739_v55 = vadd.s32 %v68735_v56, %v68723_v24 (stack40)
        %v68741_v8 = vshll.u32 %v68735_v56, 13 (stack45)
        %v68742_v26 = vshrl.u32 %v68735_v56, 19 (stack46)
        %v67974_v31 = vadd.f32 %v67970_v25, %v142091_v31 (stack53)
        %v69145_v6 = vxor.u32 %v69144_v54, %v69136_v23 (stack48)
        %v69547_v60 = vshll.u32 %v69542_v43, 16 (stack45)
        %v69548_v34 = vshrl.u32 %v69542_v43, 16 (stack46)
        %v142127_v50 = vmax.f32 %v68338_v44, -0.99609375 (stack55)
        %v68743_v24 = vor.u32 %v68742_v26, %v68741_v8 (stack47)
        %v69959_v45 = vxor.u32 %v69958_v46, %v69954_v32 (stack48)
        %v70386_v30 = vsel /*vm=*/%vm70373_vm15, /*on_true_vy=*/%v70382_v53, /*on_false_vx=*/%v70378_v30 (stack44)
        %v67939_v29 = vsel /*vm=*/%vm67910_vm13, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v67978_v40 = vmul.f32 %v67974_v31, %v142123_v9 (stack54)
        %v69148_v43 = vadd.s32 %v69145_v6, %v121569_v1 (stack40)
        %v69549_v7 = vor.u32 %v69548_v34, %v69547_v60 (stack47)
        %v68354_v56 = vxor.u32 2147483648, %v142127_v50 (stack56)
        %v68744_v46 = vxor.u32 %v68743_v24, %v68739_v55 (stack48)
        %v69140_v23 = vadd.s32 %v69136_v23, %v121574_v2 (stack40)
        %v70364_v25 = vadd.s32 %v142032_v20, %v122657_v58 (stack40)
        %v67982_v54 = vadd.f32 %v67978_v40, %v67939_v29 (stack53)
        %v69152_v53 = vadd.s32 3, %v69148_v43 (stack40)
        %v69550_v44 = vxor.u32 %v69549_v7, %v69545_v52 (stack48)
        %v142141_v32 = vadd.s32 %v69959_v45, %v69954_v32 (stack40)
        %v67931_v8 = vsel /*vm=*/%vm67910_vm13, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v142147_v26 = vmul.f32 %v68354_v56, %v142127_v50 (stack54)
        %v68747_v55 = vadd.s32 %v68744_v46, %v68739_v55 (stack40)
        %v68749_v31 = vshll.u32 %v68744_v46, 15 (stack45)
        %v67986_v6 = vmul.f32 %v67982_v54, %v142123_v9 (stack54)
        %v68750_v60 = vshrl.u32 %v68744_v46, 17 (stack46)
        %v69156_v34 = vadd.s32 %v69152_v53, %v69140_v23 (stack40)
        %v69158_v24 = vshll.u32 %v69152_v53, 17 (stack45)
        %v67935_v29 = vsel /*vm=*/%vm67910_vm13, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v68359_v40 = vadd.f32 1.0, %v142147_v26 (stack57)
        %v68362_v43 = vmul.f32 -0.5, %v142147_v26 (stack59)
        %v69159_v7 = vshrl.u32 %v69152_v53, 15 (stack46)
        %v67990_v56 = vadd.f32 %v67986_v6, %v67935_v29 (stack53)
        %v68751_v46 = vor.u32 %v68750_v60, %v68749_v31 (stack47)
        %v69553_v52 = vadd.s32 %v69550_v44, %v69545_v52 (stack40)
        %vm70368_vm1 = vcmp.lt.u32.totalorder %v70364_v25, %v142032_v20 (stack43)
        %121013 = vlog2.f32 %v68359_v40 (stack58)
        %v69160_v23 = vor.u32 %v69159_v7, %v69158_v24 (stack47)
        %v69559_v54 = vshll.u32 %v69550_v44, 24 (stack45)
        %v70390_v53 = vadd.s32 1, %v70386_v30 (stack40)
        %v67994_v31 = vmul.f32 %v67990_v56, %v142123_v9 (stack54)
        %v68365_v6 = vand.u32 2147483647, %v142147_v26 (stack60)
        %v68752_v60 = vxor.u32 %v68751_v46, %v68747_v55 (stack48)
        %v69560_v44 = vshrl.u32 %v69550_v44, 8 (stack46)
        %v68363_v24 = vadd.f32 1.0, %v68362_v43 (stack61)
        %v69161_v29 = vxor.u32 %v69160_v23, %v69156_v34 (stack48)
        %v69964_v40 = vshll.u32 %v69959_v45, 26 (stack45)
        %v69965_v45 = vshrl.u32 %v69959_v45, 6 (stack46)
        %v67998_v8 = vadd.f32 %v67994_v31, %v67931_v8 (stack53)
        %v68755_v55 = vadd.s32 %v68752_v60, %v68747_v55 (stack40)
        %v68757_v43 = vshll.u32 %v68752_v60, 26 (stack45)
        %v68758_v7 = vshrl.u32 %v68752_v60, 6 (stack46)
        %v69164_v34 = vadd.s32 %v69161_v29, %v69156_v34 (stack40)
        %v69166_v56 = vshll.u32 %v69161_v29, 29 (stack45)
        %v69167_v46 = vshrl.u32 %v69161_v29, 3 (stack46)
        %v69561_v23 = vor.u32 %v69560_v44, %v69559_v54 (stack47)
        %v68002_v54 = vmul.f32 %v67998_v8, %v142123_v9 (stack54)
        %v68759_v31 = vor.u32 %v68758_v7, %v68757_v43 (stack47)
        %v69966_v60 = vor.u32 %v69965_v45, %v69964_v40 (stack47)
        %v70394_v20 = vsel /*vm=*/%vm70368_vm1, /*on_true_vy=*/%v70390_v53, /*on_false_vx=*/%v70386_v30 (stack44)
        %v69168_v30 = vor.u32 %v69167_v46, %v69166_v56 (stack47)
        %v69562_v53 = vxor.u32 %v69561_v23, %v69553_v52 (stack48)
        %v70399_v44 = vadd.s32 %v70394_v20, %v121574_v2 (stack40)
        %v70403_v25 = vadd.s32 %v70364_v25, %v121569_v1 (stack40)
        %v68006_v21 = vadd.f32 %v68002_v54, %v142086_v21 (stack53)
        %v68760_v29 = vxor.u32 %v68759_v31, %v68755_v55 (stack48)
        %v69967_v40 = vxor.u32 %v69966_v60, %v142141_v32 (stack48)
        %v142167_v41 = vadd.s32 %v157486_v41, %v157095_v13 (stack40)
        %v69169_v45 = vxor.u32 %v69168_v30, %v69164_v34 (stack48)
        %v69557_v52 = vadd.s32 %v69553_v52, %v121564_v0 (stack40)
        %v69565_v8 = vadd.s32 %v69562_v53, %v121574_v2 (stack40)
        %v142171_v43 = vadd.s32 %v70403_v25, %v70399_v44 (stack40)
        %v68010_v7 = vmul.f32 %v68006_v21, %v142123_v9 (stack54)
        %v68763_v55 = vadd.s32 %v68760_v29, %v68755_v55 (stack40)
        %v68769_v56 = vshll.u32 %v68760_v29, 6 (stack45)
        %v68770_v46 = vshrl.u32 %v68760_v29, 26 (stack46)
        %v69172_v34 = vadd.s32 %v69169_v45, %v69164_v34 (stack40)
        %v69174_v23 = vshll.u32 %v69169_v45, 16 (stack45)
        %v69175_v54 = vshrl.u32 %v69169_v45, 16 (stack46)
        %v69569_v31 = vadd.s32 2, %v69565_v8 (stack40)
        %v68014_v42 = vadd.f32 %v68010_v7, %v142078_v42 (stack53)
        %vm142175_vm2 = vcmp.lt.f32.partialorder %v68365_v6, 0.0004427343 (stack62)
        %v68771_v60 = vor.u32 %v68770_v46, %v68769_v56 (stack47)
        %v142180_v32 = vadd.s32 %v69967_v40, %v142141_v32 (stack40)
        %v69176_v20 = vor.u32 %v69175_v54, %v69174_v23 (stack47)
        %v69573_v30 = vadd.s32 %v69569_v31, %v69557_v52 (stack40)
        %v69575_v53 = vshll.u32 %v69569_v31, 13 (stack45)
        %v69576_v44 = vshrl.u32 %v69569_v31, 19 (stack46)
        %v121014_v21 = vpop.eup %121013 (stack64)
        %v68018_v29 = vmul.f32 %v68014_v42, %v142123_v9 (stack54)
        %v68364_v26 = vmul.f32 %v68363_v24, %v142147_v26 (stack63)
        %v68772_v24 = vxor.u32 %v68771_v60, %v68763_v55 (stack48)
        %v70409_v45 = vshll.u32 %v70403_v25, 13 (stack45)
        %v68361_v52 = vmul.f32 0.6931472, %v121014_v21 (stack65)
        %v69177_v8 = vxor.u32 %v69176_v20, %v69172_v34 (stack48)
        %v69577_v7 = vor.u32 %v69576_v44, %v69575_v53 (stack47)
        %v69976_v56 = vshll.u32 %v69967_v40, 6 (stack45)
        %v68022_v61 = vadd.f32 %v68018_v29, %v142073_v61 (stack53)
        %v68775_v46 = vadd.s32 %v68772_v24, %v121574_v2 (stack40)
        %v69977_v40 = vshrl.u32 %v69967_v40, 26 (stack46)
        %v70410_v25 = vshrl.u32 %v70403_v25, 19 (stack46)
        %v68367_v23 = vsel /*vm=*/%vm142175_vm2, /*on_true_vy=*/%v68364_v26, /*on_false_vx=*/%v68361_v52 (stack66)
        %v69180_v34 = vadd.s32 %v69177_v8, %v69172_v34 (stack40)
        %v69186_v54 = vshll.u32 %v69177_v8, 24 (stack45)
        %v69187_v31 = vshrl.u32 %v69177_v8, 8 (stack46)
        %v68026_v9 = vmul.f32 %v68022_v61, %v142123_v9 (stack54)
        %v142189_v42 = vxor.u32 2147483648, %v68367_v23 (stack56)
        %v68779_v6 = vadd.s32 5, %v68775_v46 (stack40)
        %v69578_v60 = vxor.u32 %v69577_v7, %v69573_v30 (stack48)
        %v67915_v12 = vsel /*vm=*/%vm67910_vm13, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v68767_v55 = vadd.s32 %v68763_v55, %v121564_v0 (stack40)
        %v69188_v20 = vor.u32 %v69187_v31, %v69186_v54 (stack47)
        %v67891_v53 = vmul.f32 inf, %v141984_v27 (stack54)
        %v68030_v44 = vadd.f32 %v68026_v9, %v67915_v12 (stack53)
        %vm68371_vm3 = vcmp.lt.f32.partialorder %v142189_v42, 5.0 (stack68)
        %121015 = vrsqrt.f32 %v142189_v42 (stack67)
        %vm142200_vm4 = vcmp.eq.f32.partialorder %v67883_v10, 1.0 (stack68)
        %v68344_v21 = vand.u32 2147483647, %v142127_v50 (stack77)
        %v68781_v29 = vxor.u32 %v68779_v6, %v68767_v55 (stack48)
        %v69974_v26 = vadd.s32 %v142180_v32, %v121569_v1 (stack40)
        %v68034_v27 = vmul.f32 %v68030_v44, %v141984_v27 (stack54)
        %v69978_v24 = vor.u32 %v69977_v40, %v69976_v56 (stack47)
        %v70411_v45 = vor.u32 %v70410_v25, %v70409_v45 (stack47)
        %v142210_v52 = vadd.s32 %v142167_v41, %v122657_v58 (stack40)
        %v142215_v8 = vsel /*vm=*/%vm68371_vm3, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v142218_v7 = vadd.f32 -2.5, %v142189_v42 (stack53)
        %v69184_v56 = vadd.s32 %v69180_v34, %v121569_v1 (stack40)
        %v69189_v61 = vxor.u32 %v69188_v20, %v69180_v34 (stack48)
        %v68038_v46 = vsel /*vm=*/%vm142200_vm4, /*on_true_vy=*/%v67891_v53, /*on_false_vx=*/%v68034_v27 (stack44)
        %v142226_v40 = vsel /*vm=*/%vm68371_vm3, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v142231_v25 = vsel /*vm=*/%vm68371_vm3, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v142236_v23 = vsel /*vm=*/%vm68371_vm3, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v68042_v34 = vmul.f32 1.4140625, %v68038_v46 (stack54)
        %v68782_v54 = vand.u32.u8 255, %v68781_v29 (stack49)
        %v69192_v31 = vadd.s32 %v69189_v61, %v121564_v0 (stack40)
        %v69581_v30 = vadd.s32 %v69578_v60, %v69573_v30 (stack40)
        %v69583_v9 = vshll.u32 %v69578_v60, 15 (stack45)
        %v69584_v6 = vshrl.u32 %v69578_v60, 17 (stack46)
        %v69979_v32 = vxor.u32 %v69978_v24, %v142180_v32 (stack48)
        %v70412_v60 = vxor.u32 %v70411_v45, %v142171_v43 (stack48)
        %v68045_v12 = vpack.c.bf16 %v157387_v11, %v68042_v34 (stack81)
        %vm68416_vm5 = vcmp.eq.f32.partialorder %v142189_v42, inf (stack70)
        %v68783_v55 = vand.u32 65535, %v68782_v54 (stack50)
        %v69196_v20 = vadd.s32 4, %v69192_v31 (stack40)
        %vm68418_vm6 = vcmp.eq.f32.partialorder %v142189_v42, 0.0 (stack71)
        %v69585_v53 = vor.u32 %v69584_v6, %v69583_v9 (stack47)
        %v69982_v44 = vadd.s32 %v69979_v32, %v121564_v0 (stack40)
        %v70415_v43 = vadd.s32 %v70412_v60, %v142171_v43 (stack40)
        %v70417_v10 = vshll.u32 %v70412_v60, 15 (stack45)
        %120109 = vst [vmem:[%s123356_s30 + $0x48] sm:$0xf] /*vst_source=*/%v68045_v12 (stack83)
        %v68784_v29 = vshrl.u32 %v68783_v55, 1 (stack51)
        %v69200_v27 = vadd.s32 %v69196_v20, %v69184_v56 (stack40)
        %v69202_v24 = vshll.u32 %v69196_v20, 13 (stack45)
        %v69203_v45 = vshrl.u32 %v69196_v20, 19 (stack46)
        %v69586_v56 = vxor.u32 %v69585_v53, %v69581_v30 (stack48)
        %v69986_v61 = vadd.s32 1, %v69982_v44 (stack40)
        %v70418_v46 = vshrl.u32 %v70412_v60, 17 (stack46)
        %vm70834_vm7 = vcmp.lt.u32.totalorder %v142167_v41, %v157095_v13 (stack43)
        %v68419_v34 = vand.u32 2147483648, %v142189_v42 (stack72)
        %v68785_v54 = vor.u32 16256, %v68784_v29 (stack47)
        %v69204_v31 = vor.u32 %v69203_v45, %v69202_v24 (stack47)
        %v70839_v22 = vadd.s32 %v157487_v22, %v157100_v14 (stack40)
        %v69589_v30 = vadd.s32 %v69586_v56, %v69581_v30 (stack40)
        %v69591_v9 = vshll.u32 %v69586_v56, 26 (stack45)
        %v69592_v6 = vshrl.u32 %v69586_v56, 6 (stack46)
        %v69990_v26 = vadd.s32 %v69986_v61, %v69974_v26 (stack40)
        %v121016_v32 = vpop.eup %121015 (stack73)
        %v68786_v60 = vand.u32.u16 65535, %v68785_v54 (stack52)
        %v69205_v12 = vxor.u32 %v69204_v31, %v69200_v27 (stack48)
        %v69992_v55 = vshll.u32 %v69986_v61, 17 (stack45)
        %v69993_v20 = vshrl.u32 %v69986_v61, 15 (stack46)
        %v68415_v53 = vmul.f32 %v121016_v32, %v142189_v42 (stack74)
        %v69593_v44 = vor.u32 %v69592_v6, %v69591_v9 (stack47)
        %v70419_v10 = vor.u32 %v70418_v46, %v70417_v10 (stack47)
        %v70843_v29 = vadd.s32 1, %v70839_v22 (stack40)
        %v120112_v24 = vadd.low.f32.bf16 -1.0, %v68786_v60 (stack53)
        %v69208_v27 = vadd.s32 %v69205_v12, %v69200_v27 (stack40)
        %v69210_v45 = vshll.u32 %v69205_v12, 15 (stack45)
        %v69211_v56 = vshrl.u32 %v69205_v12, 17 (stack46)
        %v68417_v61 = vsel /*vm=*/%vm68416_vm5, /*on_true_vy=*/%v142189_v42, /*on_false_vx=*/%v68415_v53 (stack75)
        %v69594_v46 = vxor.u32 %v69593_v44, %v69589_v30 (stack48)
        %v69994_v54 = vor.u32 %v69993_v20, %v69992_v55 (stack47)
        %v70420_v31 = vxor.u32 %v70419_v10, %v70415_v43 (stack48)
        %v68420_v34 = vsel /*vm=*/%vm68418_vm6, /*on_true_vy=*/%v68419_v34, /*on_false_vx=*/%v68417_v61 (stack76)
        %v68795_v9 = vmul.f32 2.0, %v120112_v24 (stack54)
        %v69212_v6 = vor.u32 %v69211_v56, %v69210_v45 (stack47)
        %v70847_v22 = vsel /*vm=*/%vm70834_vm7, /*on_true_vy=*/%v70843_v29, /*on_false_vx=*/%v70839_v22 (stack44)
        %v68423_v32 = vadd.f32 -3.0, %v68420_v34 (stack53)
        %v69597_v30 = vadd.s32 %v69594_v46, %v69589_v30 (stack40)
        %v69603_v60 = vshll.u32 %v69594_v46, 6 (stack45)
        %v69604_v12 = vshrl.u32 %v69594_v46, 26 (stack46)
        %v68799_v55 = vadd.f32 -0.99609375, %v68795_v9 (stack53)
        %v69213_v20 = vxor.u32 %v69212_v6, %v69208_v27 (stack48)
        %v69995_v53 = vxor.u32 %v69994_v54, %v69990_v26 (stack48)
        %v70423_v43 = vadd.s32 %v70420_v31, %v70415_v43 (stack40)
        %v68404_v44 = vsel /*vm=*/%vm68371_vm3, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v68408_v10 = vsel /*vm=*/%vm68371_vm3, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v142270_v7 = vsel /*vm=*/%vm68371_vm3, /*on_true_vy=*/%v142218_v7, /*on_false_vx=*/%v68423_v32 (stack44)
        %v69605_v29 = vor.u32 %v69604_v12, %v69603_v60 (stack47)
        %v68431_v24 = vmul.f32 %v142270_v7, %v68408_v10 (stack54)
        %v142273_v45 = vmax.f32 %v68799_v55, -0.99609375 (stack55)
        %v69216_v27 = vadd.s32 %v69213_v20, %v69208_v27 (stack40)
        %v69218_v56 = vshll.u32 %v69213_v20, 26 (stack45)
        %v69219_v61 = vshrl.u32 %v69213_v20, 6 (stack46)
        %v69606_v46 = vxor.u32 %v69605_v29, %v69597_v30 (stack48)
        %v69998_v26 = vadd.s32 %v69995_v53, %v69990_v26 (stack40)
        %v70000_v54 = vshll.u32 %v69995_v53, 29 (stack45)
        %v68400_v34 = vsel /*vm=*/%vm68371_vm3, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v68435_v9 = vadd.f32 %v68431_v24, %v68404_v44 (stack53)
        %v68815_v6 = vxor.u32 2147483648, %v142273_v45 (stack56)
        %v70425_v32 = vshll.u32 %v70420_v31, 26 (stack45)
        %v69220_v60 = vor.u32 %v69219_v61, %v69218_v56 (stack47)
        %v69609_v12 = vadd.s32 %v69606_v46, %v121569_v1 (stack40)
        %v70001_v55 = vshrl.u32 %v69995_v53, 3 (stack46)
        %v70426_v31 = vshrl.u32 %v70420_v31, 6 (stack46)
        %v68439_v20 = vmul.f32 %v68435_v9, %v142270_v7 (stack54)
        %v142282_v53 = vmul.f32 %v68815_v6, %v142273_v45 (stack54)
        %v69601_v30 = vadd.s32 %v69597_v30, %v121574_v2 (stack40)
        %v70864_v44 = vadd.s32 %v142210_v52, %v121569_v1 (stack40)
        %v69221_v10 = vxor.u32 %v69220_v60, %v69216_v27 (stack48)
        %v69613_v29 = vadd.s32 3, %v69609_v12 (stack40)
        %v70002_v24 = vor.u32 %v70001_v55, %v70000_v54 (stack47)
        %v70851_v56 = vadd.s32 1, %v70847_v22 (stack40)
        %v68443_v61 = vadd.f32 %v68439_v20, %v68400_v34 (stack53)
        %v68820_v46 = vadd.f32 1.0, %v142282_v53 (stack57)
        %v68823_v54 = vmul.f32 -0.5, %v142282_v53 (stack59)
        %v70427_v34 = vor.u32 %v70426_v31, %v70425_v32 (stack47)
        %v69224_v27 = vadd.s32 %v69221_v10, %v69216_v27 (stack40)
        %v69230_v9 = vshll.u32 %v69221_v10, 6 (stack45)
        %v69231_v6 = vshrl.u32 %v69221_v10, 26 (stack46)
        %v69617_v32 = vadd.s32 %v69613_v29, %v69601_v30 (stack40)
        %v68447_v60 = vmul.f32 %v68443_v61, %v142270_v7 (stack54)
        %121017 = vlog2.f32 %v68820_v46 (stack58)
        %v68826_v12 = vand.u32 2147483647, %v142282_v53 (stack60)
        %vm70829_vm8 = vcmp.lt.u32.totalorder %v142210_v52, %v142167_v41 (stack43)
        %v68824_v41 = vadd.f32 1.0, %v68823_v54 (stack61)
        %v69232_v52 = vor.u32 %v69231_v6, %v69230_v9 (stack47)
        %v69619_v55 = vshll.u32 %v69613_v29, 17 (stack45)
        %v69620_v31 = vshrl.u32 %v69613_v29, 15 (stack46)
        %v68451_v23 = vadd.f32 %v68447_v60, %v142236_v23 (stack53)
        %v69228_v20 = vadd.s32 %v69224_v27, %v121564_v0 (stack40)
        %v70003_v30 = vxor.u32 %v70002_v24, %v69998_v26 (stack48)
        %v70428_v10 = vxor.u32 %v70427_v34, %v70423_v43 (stack48)
        %v69233_v29 = vxor.u32 %v69232_v52, %v69224_v27 (stack48)
        %v69621_v24 = vor.u32 %v69620_v31, %v69619_v55 (stack47)
        %v70855_v22 = vsel /*vm=*/%vm70829_vm8, /*on_true_vy=*/%v70851_v56, /*on_false_vx=*/%v70847_v22 (stack44)
        %v70870_v56 = vshll.u32 %v70864_v44, 13 (stack45)
        %v68455_v61 = vmul.f32 %v68451_v23, %v142270_v7 (stack54)
        %v70006_v26 = vadd.s32 %v70003_v30, %v69998_v26 (stack40)
        %v70008_v46 = vshll.u32 %v70003_v30, 16 (stack45)
        %v70009_v54 = vshrl.u32 %v70003_v30, 16 (stack46)
        %v69236_v34 = vadd.s32 %v69233_v29, %v121574_v2 (stack40)
        %v69622_v27 = vxor.u32 %v69621_v24, %v69617_v32 (stack48)
        %v70431_v43 = vadd.s32 %v70428_v10, %v70423_v43 (stack40)
        %v70437_v9 = vshll.u32 %v70428_v10, 6 (stack45)
        %v68459_v25 = vadd.f32 %v68455_v61, %v142231_v25 (stack53)
        %v70010_v6 = vor.u32 %v70009_v54, %v70008_v46 (stack47)
        %v70438_v60 = vshrl.u32 %v70428_v10, 26 (stack46)
        %v70860_v52 = vadd.s32 %v70855_v22, %v121574_v2 (stack40)
        %v69240_v55 = vadd.s32 5, %v69236_v34 (stack40)
        %v69625_v32 = vadd.s32 %v69622_v27, %v69617_v32 (stack40)
        %v69627_v31 = vshll.u32 %v69622_v27, 29 (stack45)
        %v69628_v23 = vshrl.u32 %v69622_v27, 3 (stack46)
        %v68463_v30 = vmul.f32 %v68459_v25, %v142270_v7 (stack54)
        %vm142300_vm9 = vcmp.lt.f32.partialorder %v68826_v12, 0.0004427343 (stack62)
        %v70011_v10 = vxor.u32 %v70010_v6, %v70006_v26 (stack48)
        %v70439_v29 = vor.u32 %v70438_v60, %v70437_v9 (stack47)
        %v69242_v20 = vxor.u32 %v69240_v55, %v69228_v20 (stack48)
        %v69629_v24 = vor.u32 %v69628_v23, %v69627_v31 (stack47)
        %v70868_v22 = vadd.s32 %v70864_v44, %v70860_v52 (stack40)
        %v70871_v44 = vshrl.u32 %v70864_v44, 19 (stack46)
        %v68467_v40 = vadd.f32 %v68463_v30, %v142226_v40 (stack53)
        %v70014_v61 = vadd.s32 %v70011_v10, %v70006_v26 (stack40)
        %v70020_v26 = vshll.u32 %v70011_v10, 24 (stack45)
        %v70021_v46 = vshrl.u32 %v70011_v10, 8 (stack46)
        %v69243_v54 = vand.u32.u8 255, %v69242_v20 (stack49)
        %v69630_v34 = vxor.u32 %v69629_v24, %v69625_v32 (stack48)
        %v70440_v27 = vxor.u32 %v70439_v29, %v70431_v43 (stack48)
        %v70872_v56 = vor.u32 %v70871_v44, %v70870_v56 (stack47)
        %v68471_v9 = vmul.f32 %v68467_v40, %v142270_v7 (stack54)
        %v68825_v53 = vmul.f32 %v68824_v41, %v142282_v53 (stack63)
        %v70022_v41 = vor.u32 %v70021_v46, %v70020_v26 (stack47)
        %v157514_v25 = vld [vmem:[#allocation139_spill] sm:$0xff] (stack84)
        %v142309_v6 = vadd.s32 %v157514_v25, %v122651_v47 (stack40)
        %v121018_v60 = vpop.eup %121017 (stack64)
        %v69244_v52 = vand.u32 65535, %v69243_v54 (stack50)
        %v69633_v55 = vadd.s32 %v69630_v34, %v69625_v32 (stack40)
        %v69635_v32 = vshll.u32 %v69630_v34, 16 (stack45)
        %v69636_v31 = vshrl.u32 %v69630_v34, 16 (stack46)
        %v68475_v8 = vadd.f32 %v68471_v9, %v142215_v8 (stack53)
        %v68822_v23 = vmul.f32 0.6931472, %v121018_v60 (stack65)
        %v70023_v30 = vxor.u32 %v70022_v41, %v70014_v61 (stack48)
        %v70443_v10 = vadd.s32 %v70440_v27, %v121564_v0 (stack40)
        %v69245_v29 = vshrl.u32 %v69244_v52, 1 (stack51)
        %v69637_v20 = vor.u32 %v69636_v31, %v69635_v32 (stack47)
        %v70435_v43 = vadd.s32 %v70431_v43, %v121569_v1 (stack40)
        %v70873_v24 = vxor.u32 %v70872_v56, %v70868_v22 (stack48)
        %v68479_v44 = vmul.f32 %v68475_v8, %v142270_v7 (stack54)
        %v68828_v12 = vsel /*vm=*/%vm142300_vm9, /*on_true_vy=*/%v68825_v53, /*on_false_vx=*/%v68822_v23 (stack66)
        %v70026_v40 = vadd.s32 %v70023_v30, %v121574_v2 (stack40)
        %v70447_v26 = vadd.s32 1, %v70443_v10 (stack40)
        %v68380_v46 = vsel /*vm=*/%vm68371_vm3, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v142321_v54 = vxor.u32 2147483648, %v68828_v12 (stack56)
        %v69638_v34 = vxor.u32 %v69637_v20, %v69633_v55 (stack48)
        %v142323_v22 = vadd.s32 %v70873_v24, %v70868_v22 (stack40)
        %v68483_v27 = vadd.f32 %v68479_v44, %v68380_v46 (stack53)
        %v70451_v56 = vadd.s32 %v70447_v26, %v70435_v43 (stack40)
        %121019 = vrsqrt.f32 %v142321_v54 (stack67)
        %v69246_v9 = vor.u32 16256, %v69245_v29 (stack47)
        %v68352_v53 = vmul.f32 inf, %v142127_v50 (stack54)
        %v68487_v7 = vmul.f32 %v68483_v27, %v142270_v7 (stack54)
        %v70030_v41 = vadd.s32 2, %v70026_v40 (stack40)
        %vm142330_vm10 = vcmp.eq.f32.partialorder %v68344_v21, 1.0 (stack68)
        %v68376_v42 = vsel /*vm=*/%vm68371_vm3, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v68805_v60 = vand.u32 2147483647, %v142273_v45 (stack77)
        %v69641_v52 = vadd.s32 %v69638_v34, %v69633_v55 (stack40)
        %v68491_v55 = vadd.f32 %v68487_v7, %v68376_v42 (stack53)
        %v142339_v32 = vmul.f32 inf, %v142273_v45 (stack54)
        %v70018_v61 = vadd.s32 %v70014_v61, %v121564_v0 (stack40)
        %v142344_v31 = vadd.s32 %v142309_v6, %v122657_v58 (stack40)
        %vm68832_vm11 = vcmp.lt.f32.partialorder %v142321_v54, 5.0 (stack68)
        %v142348_v8 = vadd.f32 -2.5, %v142321_v54 (stack53)
        %v69247_v23 = vand.u32.u16 65535, %v69246_v9 (stack52)
        %v70453_v30 = vshll.u32 %v70447_v26, 17 (stack45)
        %v68495_v50 = vmul.f32 %v68491_v55, %v142127_v50 (stack54)
        %v69647_v10 = vshll.u32 %v69638_v34, 24 (stack45)
        %v69648_v29 = vshrl.u32 %v69638_v34, 8 (stack46)
        %v70034_v20 = vadd.s32 %v70030_v41, %v70018_v61 (stack40)
        %v120114_v43 = vadd.low.f32.bf16 -1.0, %v69247_v23 (stack53)
        %v70036_v44 = vshll.u32 %v70030_v41, 13 (stack45)
        %v70037_v12 = vshrl.u32 %v70030_v41, 19 (stack46)
        %v70454_v40 = vshrl.u32 %v70447_v26, 15 (stack46)
        %v68499_v26 = vsel /*vm=*/%vm142330_vm10, /*on_true_vy=*/%v68352_v53, /*on_false_vx=*/%v68495_v50 (stack44)
        %vm68877_vm12 = vcmp.eq.f32.partialorder %v142321_v54, inf (stack70)
        %v69649_v46 = vor.u32 %v69648_v29, %v69647_v10 (stack47)
        %v70878_v34 = vshll.u32 %v70873_v24, 15 (stack45)
        %v70879_v24 = vshrl.u32 %v70873_v24, 17 (stack46)
        %v68503_v27 = vmul.f32 1.4140625, %v68499_v26 (stack54)
        %v69256_v9 = vmul.f32 2.0, %v120114_v43 (stack54)
        %v70038_v53 = vor.u32 %v70037_v12, %v70036_v44 (stack47)
        %v70455_v7 = vor.u32 %v70454_v40, %v70453_v30 (stack47)
        %v142357_v41 = vsel /*vm=*/%vm68832_vm11, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v69650_v21 = vxor.u32 %v69649_v46, %v69641_v52 (stack48)
        %v70880_v42 = vor.u32 %v70879_v24, %v70878_v34 (stack47)
        %vm71329_vm13 = vcmp.lt.u32.totalorder %v142309_v6, %v122651_v47 (stack43)
        %v68506_v55 = vpack.c.bf16 %v157387_v11, %v68503_v27 (stack81)
        %v69260_v61 = vadd.f32 -0.99609375, %v69256_v9 (stack53)
        %v70039_v23 = vxor.u32 %v70038_v53, %v70034_v20 (stack48)
        %v70456_v30 = vxor.u32 %v70455_v7, %v70451_v56 (stack48)
        %v142365_v50 = vsel /*vm=*/%vm68832_vm11, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v69653_v10 = vadd.s32 %v69650_v21, %v121564_v0 (stack40)
        %v70881_v29 = vxor.u32 %v70880_v42, %v142323_v22 (stack48)
        %v157517_v43 = vld [vmem:[#allocation103_spill] sm:$0xff] (stack84)
        %v71334_v44 = vadd.s32 %v157517_v43, %v157068_v28 (stack40)
        %120111 = vst [vmem:[%s123356_s30 + $0xc8] sm:$0xf] /*vst_source=*/%v68506_v55 (stack83)
        %v142372_v12 = vmax.f32 %v69260_v61, -0.99609375 (stack55)
        %v70042_v20 = vadd.s32 %v70039_v23, %v70034_v20 (stack40)
        %v70044_v40 = vshll.u32 %v70039_v23, 15 (stack45)
        %v70045_v26 = vshrl.u32 %v70039_v23, 17 (stack46)
        %v121020_v46 = vpop.eup %121019 (stack73)
        %v68880_v34 = vand.u32 2147483648, %v142321_v54 (stack72)
        %v69645_v52 = vadd.s32 %v69641_v52, %v121569_v1 (stack40)
        %v69657_v24 = vadd.s32 4, %v69653_v10 (stack40)
        %v70459_v56 = vadd.s32 %v70456_v30, %v70451_v56 (stack40)
        %v68876_v27 = vmul.f32 %v121020_v46, %v142321_v54 (stack74)
        %v69276_v9 = vxor.u32 2147483648, %v142372_v12 (stack56)
        %v70461_v53 = vshll.u32 %v70456_v30, 29 (stack45)
        %v70462_v7 = vshrl.u32 %v70456_v30, 3 (stack46)
        %v69661_v21 = vadd.s32 %v69657_v24, %v69645_v52 (stack40)
        %v69663_v42 = vshll.u32 %v69657_v24, 13 (stack45)
        %v69664_v55 = vshrl.u32 %v69657_v24, 19 (stack46)
        %v70046_v61 = vor.u32 %v70045_v26, %v70044_v40 (stack47)
        %v68861_v23 = vsel /*vm=*/%vm68832_vm11, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v68878_v30 = vsel /*vm=*/%vm68877_vm12, /*on_true_vy=*/%v142321_v54, /*on_false_vx=*/%v68876_v27 (stack75)
        %vm68879_vm14 = vcmp.eq.f32.partialorder %v142321_v54, 0.0 (stack71)
        %v142386_v10 = vmul.f32 %v69276_v9, %v142372_v12 (stack54)
        %v68881_v40 = vsel /*vm=*/%vm68879_vm14, /*on_true_vy=*/%v68880_v34, /*on_false_vx=*/%v68878_v30 (stack76)
        %v69665_v26 = vor.u32 %v69664_v55, %v69663_v42 (stack47)
        %v70047_v46 = vxor.u32 %v70046_v61, %v70042_v20 (stack48)
        %v70884_v22 = vadd.s32 %v70881_v29, %v142323_v22 (stack40)
        %v68884_v34 = vadd.f32 -3.0, %v68881_v40 (stack53)
        %v69281_v52 = vadd.f32 1.0, %v142386_v10 (stack57)
        %v69284_v24 = vmul.f32 -0.5, %v142386_v10 (stack59)
        %v70463_v27 = vor.u32 %v70462_v7, %v70461_v53 (stack47)
        %v69666_v9 = vxor.u32 %v69665_v26, %v69661_v21 (stack48)
        %v70050_v20 = vadd.s32 %v70047_v46, %v70042_v20 (stack40)
        %v70052_v53 = vshll.u32 %v70047_v46, 26 (stack45)
        %v70053_v7 = vshrl.u32 %v70047_v46, 6 (stack46)
        %v68865_v42 = vsel /*vm=*/%vm68832_vm11, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v68869_v55 = vsel /*vm=*/%vm68832_vm11, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v142400_v8 = vsel /*vm=*/%vm68832_vm11, /*on_true_vy=*/%v142348_v8, /*on_false_vx=*/%v68884_v34 (stack44)
        %121021 = vlog2.f32 %v69281_v52 (stack58)
        %v68892_v61 = vmul.f32 %v142400_v8, %v68869_v55 (stack54)
        %v69669_v21 = vadd.s32 %v69666_v9, %v69661_v21 (stack40)
        %v69671_v30 = vshll.u32 %v69666_v9, 15 (stack45)
        %v69672_v40 = vshrl.u32 %v69666_v9, 17 (stack46)
        %v69285_v26 = vadd.f32 1.0, %v69284_v24 (stack61)
        %v70054_v46 = vor.u32 %v70053_v7, %v70052_v53 (stack47)
        %v70464_v34 = vxor.u32 %v70463_v27, %v70459_v56 (stack48)
        %v70886_v52 = vshll.u32 %v70881_v29, 26 (stack45)
        %v68896_v24 = vadd.f32 %v68892_v61, %v68865_v42 (stack53)
        %v69673_v27 = vor.u32 %v69672_v40, %v69671_v30 (stack47)
        %v70887_v29 = vshrl.u32 %v70881_v29, 6 (stack46)
        %v71338_v9 = vadd.s32 1, %v71334_v44 (stack40)
        %v70055_v53 = vxor.u32 %v70054_v46, %v70050_v20 (stack48)
        %v70467_v56 = vadd.s32 %v70464_v34, %v70459_v56 (stack40)
        %v70469_v7 = vshll.u32 %v70464_v34, 16 (stack45)
        %v70470_v42 = vshrl.u32 %v70464_v34, 16 (stack46)
        %v68900_v55 = vmul.f32 %v68896_v24, %v142400_v8 (stack54)
        %v69674_v61 = vxor.u32 %v69673_v27, %v69669_v21 (stack48)
        %v70888_v30 = vor.u32 %v70887_v29, %v70886_v52 (stack47)
        %v71342_v44 = vsel /*vm=*/%vm71329_vm13, /*on_true_vy=*/%v71338_v9, /*on_false_vx=*/%v71334_v44 (stack44)
        %v70058_v20 = vadd.s32 %v70055_v53, %v70050_v20 (stack40)
        %v70064_v40 = vshll.u32 %v70055_v53, 6 (stack45)
        %v70065_v46 = vshrl.u32 %v70055_v53, 26 (stack46)
        %v70471_v34 = vor.u32 %v70470_v42, %v70469_v7 (stack47)
        %v68904_v23 = vadd.f32 %v68900_v55, %v68861_v23 (stack53)
        %v69677_v21 = vadd.s32 %v69674_v61, %v69669_v21 (stack40)
        %v69679_v52 = vshll.u32 %v69674_v61, 26 (stack45)
        %v69680_v24 = vshrl.u32 %v69674_v61, 6 (stack46)
        %v70066_v27 = vor.u32 %v70065_v46, %v70064_v40 (stack47)
        %v70472_v29 = vxor.u32 %v70471_v34, %v70467_v56 (stack48)
        %v70889_v9 = vxor.u32 %v70888_v30, %v70884_v22 (stack48)
        %vm71324_vm15 = vcmp.lt.u32.totalorder %v142344_v31, %v142309_v6 (stack43)
        %v68908_v53 = vmul.f32 %v68904_v23, %v142400_v8 (stack54)
        %v69286_v26 = vmul.f32 %v69285_v26, %v142386_v10 (stack63)
        %v69287_v10 = vand.u32 2147483647, %v142386_v10 (stack60)
        %v69681_v7 = vor.u32 %v69680_v24, %v69679_v52 (stack47)
        %v70067_v42 = vxor.u32 %v70066_v27, %v70058_v20 (stack48)
        %v70475_v56 = vadd.s32 %v70472_v29, %v70467_v56 (stack40)
        %v70481_v55 = vshll.u32 %v70472_v29, 24 (stack45)
        %v70482_v61 = vshrl.u32 %v70472_v29, 8 (stack46)
        %v68912_v50 = vadd.f32 %v68908_v53, %v142365_v50 (stack53)
        %v69682_v30 = vxor.u32 %v69681_v7, %v69677_v21 (stack48)
        %v70892_v22 = vadd.s32 %v70889_v9, %v70884_v22 (stack40)
        %v70898_v40 = vshll.u32 %v70889_v9, 6 (stack45)
        %v70062_v20 = vadd.s32 %v70058_v20, %v121574_v2 (stack40)
        %v70070_v46 = vadd.s32 %v70067_v42, %v121569_v1 (stack40)
        %v70483_v34 = vor.u32 %v70482_v61, %v70481_v55 (stack47)
        %v70899_v23 = vshrl.u32 %v70889_v9, 26 (stack46)
        %v121022_v52 = vpop.eup %121021 (stack64)
        %v68916_v24 = vmul.f32 %v68912_v50, %v142400_v8 (stack54)
        %v69685_v21 = vadd.s32 %v69682_v30, %v69677_v21 (stack40)
        %v69691_v27 = vshll.u32 %v69682_v30, 6 (stack45)
        %v69692_v29 = vshrl.u32 %v69682_v30, 26 (stack46)
        %v69283_v9 = vmul.f32 0.6931472, %v121022_v52 (stack65)
        %v70074_v53 = vadd.s32 3, %v70070_v46 (stack40)
        %v70484_v7 = vxor.u32 %v70483_v34, %v70475_v56 (stack48)
        %v71346_v42 = vadd.s32 1, %v71342_v44 (stack40)
        %v68920_v41 = vadd.f32 %v68916_v24, %v142357_v41 (stack53)
        %vm69288_vm0 = vcmp.lt.f32.partialorder %v69287_v10, 0.0004427343 (stack62)
        %v69693_v10 = vor.u32 %v69692_v29, %v69691_v27 (stack47)
        %v70900_v55 = vor.u32 %v70899_v23, %v70898_v40 (stack47)
        %v69289_v26 = vsel /*vm=*/%vm69288_vm0, /*on_true_vy=*/%v69286_v26, /*on_false_vx=*/%v69283_v9 (stack66)
        %v70078_v61 = vadd.s32 %v70074_v53, %v70062_v20 (stack40)
        %v70080_v50 = vshll.u32 %v70074_v53, 17 (stack45)
        %v70081_v30 = vshrl.u32 %v70074_v53, 15 (stack46)
        %v68924_v40 = vmul.f32 %v68920_v41, %v142400_v8 (stack54)
        %v142418_v20 = vxor.u32 2147483648, %v69289_v26 (stack56)
        %v69694_v46 = vxor.u32 %v69693_v10, %v69685_v21 (stack48)
        %v71359_v34 = vadd.s32 %v142344_v31, %v121569_v1 (stack40)
        %v68849_v23 = vsel /*vm=*/%vm68832_vm11, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v70082_v52 = vor.u32 %v70081_v30, %v70080_v50 (stack47)
        %v70901_v24 = vxor.u32 %v70900_v55, %v70892_v22 (stack48)
        %v71350_v6 = vsel /*vm=*/%vm71324_vm15, /*on_true_vy=*/%v71346_v42, /*on_false_vx=*/%v71342_v44 (stack44)
        %v68837_v31 = vsel /*vm=*/%vm68832_vm11, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v68841_v44 = vsel /*vm=*/%vm68832_vm11, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v68928_v27 = vadd.f32 %v68924_v40, %v68849_v23 (stack53)
        %121023 = vrsqrt.f32 %v142418_v20 (stack67)
        %v68845_v54 = vsel /*vm=*/%vm68832_vm11, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v69266_v29 = vand.u32 2147483647, %v142372_v12 (stack77)
        %vm69293_vm1 = vcmp.lt.f32.partialorder %v142418_v20, 5.0 (stack68)
        %v69697_v9 = vadd.s32 %v69694_v46, %v121574_v2 (stack40)
        %v68932_v53 = vmul.f32 %v68928_v27, %v142400_v8 (stack54)
        %v70479_v56 = vadd.s32 %v70475_v56, %v121564_v0 (stack40)
        %v70487_v7 = vadd.s32 %v70484_v7, %v121574_v2 (stack40)
        %v71365_v42 = vshll.u32 %v71359_v34, 13 (stack45)
        %v69689_v21 = vadd.s32 %v69685_v21, %v121564_v0 (stack40)
        %v70083_v41 = vxor.u32 %v70082_v52, %v70078_v61 (stack48)
        %v70896_v22 = vadd.s32 %v70892_v22, %v121569_v1 (stack40)
        %v71366_v10 = vshrl.u32 %v71359_v34, 19 (stack46)
        %v68936_v55 = vadd.f32 %v68932_v53, %v68845_v54 (stack53)
        %v142449_v26 = vsel /*vm=*/%vm69293_vm1, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v142454_v50 = vsel /*vm=*/%vm69293_vm1, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v142457_v30 = vadd.f32 -2.5, %v142418_v20 (stack53)
        %v69701_v40 = vadd.s32 5, %v69697_v9 (stack40)
        %v70086_v61 = vadd.s32 %v70083_v41, %v70078_v61 (stack40)
        %v70088_v46 = vshll.u32 %v70083_v41, 29 (stack45)
        %v70089_v23 = vshrl.u32 %v70083_v41, 3 (stack46)
        %v68940_v52 = vmul.f32 %v68936_v55, %v142400_v8 (stack54)
        %v70491_v27 = vadd.s32 2, %v70487_v7 (stack40)
        %v70904_v24 = vadd.s32 %v70901_v24, %v121564_v0 (stack40)
        %v71355_v6 = vadd.s32 %v71350_v6, %v121574_v2 (stack40)
        %vm142464_vm2 = vcmp.eq.f32.partialorder %v68805_v60, 1.0 (stack68)
        %vm69338_vm3 = vcmp.eq.f32.partialorder %v142418_v20, inf (stack70)
        %v69703_v54 = vxor.u32 %v69701_v40, %v69689_v21 (stack48)
        %v70090_v9 = vor.u32 %v70089_v23, %v70088_v46 (stack47)
        %v71367_v53 = vor.u32 %v71366_v10, %v71365_v42 (stack47)
        %v142471_v7 = vadd.s32 %v157514_v25, %v157070_v38 (stack40)
        %v68944_v44 = vadd.f32 %v68940_v52, %v68841_v44 (stack53)
        %v70495_v56 = vadd.s32 %v70491_v27, %v70479_v56 (stack40)
        %v70497_v42 = vshll.u32 %v70491_v27, 13 (stack45)
        %v70498_v21 = vshrl.u32 %v70491_v27, 19 (stack46)
        %v69704_v41 = vand.u32.u8 255, %v69703_v54 (stack49)
        %v70091_v10 = vxor.u32 %v70090_v9, %v70086_v61 (stack48)
        %v70908_v55 = vadd.s32 1, %v70904_v24 (stack40)
        %v71363_v34 = vadd.s32 %v71359_v34, %v71355_v6 (stack40)
        %v68948_v8 = vmul.f32 %v68944_v44, %v142400_v8 (stack54)
        %v69341_v40 = vand.u32 2147483648, %v142418_v20 (stack72)
        %v70499_v46 = vor.u32 %v70498_v21, %v70497_v42 (stack47)
        %vm71790_vm4 = vcmp.lt.u32.totalorder %v142471_v7, %v157070_v38 (stack43)
        %v69705_v23 = vand.u32 65535, %v69704_v41 (stack50)
        %v70094_v61 = vadd.s32 %v70091_v10, %v70086_v61 (stack40)
        %v70096_v52 = vshll.u32 %v70091_v10, 16 (stack45)
        %v70097_v27 = vshrl.u32 %v70091_v10, 16 (stack46)
        %v68952_v31 = vadd.f32 %v68948_v8, %v68837_v31 (stack53)
        %v70500_v24 = vxor.u32 %v70499_v46, %v70495_v56 (stack48)
        %v70912_v22 = vadd.s32 %v70908_v55, %v70896_v22 (stack40)
        %v70914_v6 = vshll.u32 %v70908_v55, 17 (stack45)
        %v121024_v54 = vpop.eup %121023 (stack73)
        %v69706_v9 = vshrl.u32 %v69705_v23, 1 (stack51)
        %v70098_v44 = vor.u32 %v70097_v27, %v70096_v52 (stack47)
        %v70915_v42 = vshrl.u32 %v70908_v55, 15 (stack46)
        %v71368_v53 = vxor.u32 %v71367_v53, %v71363_v34 (stack48)
        %v68956_v45 = vmul.f32 %v68952_v31, %v142273_v45 (stack54)
        %v69337_v21 = vmul.f32 %v121024_v54, %v142418_v20 (stack74)
        %v70503_v56 = vadd.s32 %v70500_v24, %v70495_v56 (stack40)
        %v70505_v41 = vshll.u32 %v70500_v24, 15 (stack45)
        %v69707_v10 = vor.u32 16256, %v69706_v9 (stack47)
        %v70099_v55 = vxor.u32 %v70098_v44, %v70094_v61 (stack48)
        %v70506_v8 = vshrl.u32 %v70500_v24, 17 (stack46)
        %v70916_v46 = vor.u32 %v70915_v42, %v70914_v6 (stack47)
        %v68960_v32 = vsel /*vm=*/%vm142464_vm2, /*on_true_vy=*/%v142339_v32, /*on_false_vx=*/%v68956_v45 (stack44)
        %v69339_v60 = vsel /*vm=*/%vm69338_vm3, /*on_true_vy=*/%v142418_v20, /*on_false_vx=*/%v69337_v21 (stack75)
        %vm69340_vm5 = vcmp.eq.f32.partialorder %v142418_v20, 0.0 (stack71)
        %v142486_v34 = vadd.s32 %v71368_v53, %v71363_v34 (stack40)
        %v68964_v23 = vmul.f32 1.4140625, %v68960_v32 (stack54)
        %v69342_v40 = vsel /*vm=*/%vm69340_vm5, /*on_true_vy=*/%v69341_v40, /*on_false_vx=*/%v69339_v60 (stack76)
        %v69708_v52 = vand.u32.u16 65535, %v69707_v10 (stack52)
        %v70102_v61 = vadd.s32 %v70099_v55, %v70094_v61 (stack40)
        %v69345_v27 = vadd.f32 -3.0, %v69342_v40 (stack53)
        %v70108_v31 = vshll.u32 %v70099_v55, 24 (stack45)
        %v70109_v24 = vshrl.u32 %v70099_v55, 8 (stack46)
        %v70507_v6 = vor.u32 %v70506_v8, %v70505_v41 (stack47)
        %v68967_v54 = vpack.c.bf16 %v157387_v11, %v68964_v23 (stack81)
        %v120116_v9 = vadd.low.f32.bf16 -1.0, %v69708_v52 (stack53)
        %v70917_v44 = vxor.u32 %v70916_v46, %v70912_v22 (stack48)
        %v71373_v42 = vshll.u32 %v71368_v53, 15 (stack45)
        %v142492_v30 = vsel /*vm=*/%vm69293_vm1, /*on_true_vy=*/%v142457_v30, /*on_false_vx=*/%v69345_v27 (stack44)
        %v70110_v45 = vor.u32 %v70109_v24, %v70108_v31 (stack47)
        %v70508_v21 = vxor.u32 %v70507_v6, %v70503_v56 (stack48)
        %v71374_v53 = vshrl.u32 %v71368_v53, 17 (stack46)
        %120113 = vst [vmem:[%s123356_s30 + $0x148] sm:$0xf] /*vst_source=*/%v68967_v54 (stack83)
        %v69353_v50 = vmul.f32 %v142492_v30, %v142454_v50 (stack54)
        %v69717_v41 = vmul.f32 2.0, %v120116_v9 (stack54)
        %v70920_v22 = vadd.s32 %v70917_v44, %v70912_v22 (stack40)
        %v70922_v10 = vshll.u32 %v70917_v44, 29 (stack45)
        %v70111_v55 = vxor.u32 %v70110_v45, %v70102_v61 (stack48)
        %v70511_v56 = vadd.s32 %v70508_v21, %v70503_v56 (stack40)
        %v70513_v8 = vshll.u32 %v70508_v21, 26 (stack45)
        %v70514_v46 = vshrl.u32 %v70508_v21, 6 (stack46)
        %v69357_v26 = vadd.f32 %v69353_v50, %v142449_v26 (stack53)
        %v69721_v32 = vadd.f32 -0.99609375, %v69717_v41 (stack53)
        %v70923_v60 = vshrl.u32 %v70917_v44, 3 (stack46)
        %v71375_v23 = vor.u32 %v71374_v53, %v71373_v42 (stack47)
        %v142501_v40 = vsel /*vm=*/%vm69293_vm1, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v70114_v52 = vadd.s32 %v70111_v55, %v121564_v0 (stack40)
        %v70515_v27 = vor.u32 %v70514_v46, %v70513_v8 (stack47)
        %v71795_v31 = vadd.s32 %v157517_v43, %v157076_v35 (stack40)
        %v69322_v24 = vsel /*vm=*/%vm69293_vm1, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v69361_v6 = vmul.f32 %v69357_v26, %v142492_v30 (stack54)
        %v142510_v54 = vmax.f32 %v69721_v32, -0.99609375 (stack55)
        %v71376_v9 = vxor.u32 %v71375_v23, %v142486_v34 (stack48)
        %v70106_v61 = vadd.s32 %v70102_v61, %v121569_v1 (stack40)
        %v70118_v44 = vadd.s32 4, %v70114_v52 (stack40)
        %v70516_v42 = vxor.u32 %v70515_v27, %v70511_v56 (stack48)
        %v70924_v45 = vor.u32 %v70923_v60, %v70922_v10 (stack47)
        %v142517_v21 = vsel /*vm=*/%vm69293_vm1, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v69365_v53 = vadd.f32 %v69361_v6, %v69322_v24 (stack53)
        %v69737_v50 = vxor.u32 2147483648, %v142510_v54 (stack56)
        %v142522_v41 = vadd.s32 %v142471_v7, %v122657_v58 (stack40)
        %v70122_v10 = vadd.s32 %v70118_v44, %v70106_v61 (stack40)
        %v70124_v55 = vshll.u32 %v70118_v44, 13 (stack45)
        %v70125_v8 = vshrl.u32 %v70118_v44, 19 (stack46)
        %v70519_v56 = vadd.s32 %v70516_v42, %v70511_v56 (stack40)
        %v69306_v46 = vsel /*vm=*/%vm69293_vm1, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v69369_v26 = vmul.f32 %v69365_v53, %v142492_v30 (stack54)
        %v142529_v32 = vmul.f32 %v69737_v50, %v142510_v54 (stack54)
        %v70525_v60 = vshll.u32 %v70516_v42, 6 (stack45)
        %v69318_v23 = vsel /*vm=*/%vm69293_vm1, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v70126_v52 = vor.u32 %v70125_v8, %v70124_v55 (stack47)
        %v70526_v27 = vshrl.u32 %v70516_v42, 26 (stack46)
        %v70925_v24 = vxor.u32 %v70924_v45, %v70920_v22 (stack48)
        %v69310_v6 = vsel /*vm=*/%vm69293_vm1, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v69314_v20 = vsel /*vm=*/%vm69293_vm1, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v69373_v61 = vadd.f32 %v69369_v26, %v69318_v23 (stack53)
        %v69742_v44 = vadd.f32 1.0, %v142529_v32 (stack57)
        %v70127_v42 = vxor.u32 %v70126_v52, %v70122_v10 (stack48)
        %v70527_v45 = vor.u32 %v70526_v27, %v70525_v60 (stack47)
        %v70928_v22 = vadd.s32 %v70925_v24, %v70920_v22 (stack40)
        %vm71785_vm6 = vcmp.lt.u32.totalorder %v142522_v41, %v142471_v7 (stack43)
        %v71799_v53 = vadd.s32 1, %v71795_v31 (stack40)
        %v69377_v50 = vmul.f32 %v69373_v61, %v142492_v30 (stack54)
        %121025 = vlog2.f32 %v69742_v44 (stack58)
        %v69745_v55 = vmul.f32 -0.5, %v142529_v32 (stack59)
        %v70930_v8 = vshll.u32 %v70925_v24, 16 (stack45)
        %v70130_v10 = vadd.s32 %v70127_v42, %v70122_v10 (stack40)
        %v70132_v26 = vshll.u32 %v70127_v42, 15 (stack45)
        %v70133_v60 = vshrl.u32 %v70127_v42, 17 (stack46)
        %v70528_v23 = vxor.u32 %v70527_v45, %v70519_v56 (stack48)
        %v69381_v52 = vadd.f32 %v69377_v50, %v69314_v20 (stack53)
        %v70931_v27 = vshrl.u32 %v70925_v24, 16 (stack46)
        %v71379_v34 = vadd.s32 %v71376_v9, %v142486_v34 (stack40)
        %v142548_v24 = vadd.s32 %v142522_v41, %v121569_v1 (stack40)
        %v70134_v20 = vor.u32 %v70133_v60, %v70132_v26 (stack47)
        %v70531_v61 = vadd.s32 %v70528_v23, %v121569_v1 (stack40)
        %v71381_v44 = vshll.u32 %v71376_v9, 26 (stack45)
        %v71382_v9 = vshrl.u32 %v71376_v9, 6 (stack46)
        %v69385_v42 = vmul.f32 %v69381_v52, %v142492_v30 (stack54)
        %v70523_v56 = vadd.s32 %v70519_v56, %v121574_v2 (stack40)
        %v70932_v45 = vor.u32 %v70931_v27, %v70930_v8 (stack47)
        %v71803_v31 = vsel /*vm=*/%vm71790_vm4, /*on_true_vy=*/%v71799_v53, /*on_false_vx=*/%v71795_v31 (stack44)
        %v69746_v53 = vadd.f32 1.0, %v69745_v55 (stack61)
        %v70135_v50 = vxor.u32 %v70134_v20, %v70130_v10 (stack48)
        %v70535_v55 = vadd.s32 3, %v70531_v61 (stack40)
        %v71383_v8 = vor.u32 %v71382_v9, %v71381_v44 (stack47)
        %v69389_v6 = vadd.f32 %v69385_v42, %v69310_v6 (stack53)
        %v70933_v26 = vxor.u32 %v70932_v45, %v70928_v22 (stack48)
        %v71807_v60 = vadd.s32 1, %v71803_v31 (stack40)
        %v142558_v23 = vadd.s32 %v157514_v25, %v157077_v51 (stack40)
        %v70138_v10 = vadd.s32 %v70135_v50, %v70130_v10 (stack40)
        %v70140_v52 = vshll.u32 %v70135_v50, 26 (stack45)
        %v70141_v27 = vshrl.u32 %v70135_v50, 6 (stack46)
        %v70539_v20 = vadd.s32 %v70535_v55, %v70523_v56 (stack40)
        %v69393_v61 = vmul.f32 %v69389_v6, %v142492_v30 (stack54)
        %v70541_v44 = vshll.u32 %v70535_v55, 17 (stack45)
        %v70542_v9 = vshrl.u32 %v70535_v55, 15 (stack46)
        %v70936_v22 = vadd.s32 %v70933_v26, %v70928_v22 (stack40)
        %v70142_v42 = vor.u32 %v70141_v27, %v70140_v52 (stack47)
        %v70942_v56 = vshll.u32 %v70933_v26, 24 (stack45)
        %v70943_v45 = vshrl.u32 %v70933_v26, 8 (stack46)
        %v71384_v50 = vxor.u32 %v71383_v8, %v71379_v34 (stack48)
        %v69397_v46 = vadd.f32 %v69393_v61, %v69306_v46 (stack53)
        %v69748_v55 = vand.u32 2147483647, %v142529_v32 (stack60)
        %v70543_v8 = vor.u32 %v70542_v9, %v70541_v44 (stack47)
        %v71811_v7 = vsel /*vm=*/%vm71785_vm6, /*on_true_vy=*/%v71807_v60, /*on_false_vx=*/%v71803_v31 (stack44)
        %v69747_v41 = vmul.f32 %v69746_v53, %v142529_v32 (stack63)
        %v70143_v32 = vxor.u32 %v70142_v42, %v70138_v10 (stack48)
        %v70944_v31 = vor.u32 %v70943_v45, %v70942_v56 (stack47)
        %v71387_v34 = vadd.s32 %v71384_v50, %v71379_v34 (stack40)
        %v69401_v53 = vmul.f32 %v69397_v46, %v142492_v30 (stack54)
        %v70544_v6 = vxor.u32 %v70543_v8, %v70539_v20 (stack48)
        %v71393_v26 = vshll.u32 %v71384_v50, 6 (stack45)
        %v71394_v60 = vshrl.u32 %v71384_v50, 26 (stack46)
        %v121026_v52 = vpop.eup %121025 (stack64)
        %v70146_v10 = vadd.s32 %v70143_v32, %v70138_v10 (stack40)
        %v70152_v27 = vshll.u32 %v70143_v32, 6 (stack45)
        %v70153_v61 = vshrl.u32 %v70143_v32, 26 (stack46)
        %v70945_v44 = vxor.u32 %v70944_v31, %v70936_v22 (stack48)
        %v69405_v21 = vadd.f32 %v69401_v53, %v142517_v21 (stack53)
        %v69744_v9 = vmul.f32 0.6931472, %v121026_v52 (stack65)
        %v70547_v20 = vadd.s32 %v70544_v6, %v70539_v20 (stack40)
        %v71816_v42 = vadd.s32 %v71811_v7, %v121574_v2 (stack40)
        %vm69749_vm7 = vcmp.lt.f32.partialorder %v69748_v55, 0.0004427343 (stack62)
        %v70154_v56 = vor.u32 %v70153_v61, %v70152_v27 (stack47)
        %v70549_v45 = vshll.u32 %v70544_v6, 29 (stack45)
        %v70550_v50 = vshrl.u32 %v70544_v6, 3 (stack46)
        %v69409_v30 = vmul.f32 %v69405_v21, %v142492_v30 (stack54)
        %v69750_v46 = vsel /*vm=*/%vm69749_vm7, /*on_true_vy=*/%v69747_v41, /*on_false_vx=*/%v69744_v9 (stack66)
        %v70948_v55 = vadd.s32 %v70945_v44, %v121574_v2 (stack40)
        %v71395_v8 = vor.u32 %v71394_v60, %v71393_v26 (stack47)
        %v142571_v7 = vxor.u32 2147483648, %v69750_v46 (stack56)
        %v70155_v41 = vxor.u32 %v70154_v56, %v70146_v10 (stack48)
        %v71826_v32 = vshll.u32 %v142548_v24, 13 (stack45)
        %v71827_v31 = vshrl.u32 %v142548_v24, 19 (stack46)
        %v69413_v40 = vadd.f32 %v69409_v30, %v142501_v40 (stack53)
        %v71396_v53 = vxor.u32 %v71395_v8, %v71387_v34 (stack48)
        %v71824_v24 = vadd.s32 %v142548_v24, %v71816_v42 (stack40)
        %v69274_v6 = vmul.f32 inf, %v142372_v12 (stack54)
        %121027 = vrsqrt.f32 %v142571_v7 (stack67)
        %v69417_v26 = vmul.f32 %v69413_v40, %v142372_v12 (stack54)
        %vm69754_vm8 = vcmp.lt.f32.partialorder %v142571_v7, 5.0 (stack68)
        %v70551_v60 = vor.u32 %v70550_v50, %v70549_v45 (stack47)
        %v70952_v52 = vadd.s32 2, %v70948_v55 (stack40)
        %vm69269_vm9 = vcmp.eq.f32.partialorder %v69266_v29, 1.0 (stack68)
        %v69727_v12 = vand.u32 2147483647, %v142510_v54 (stack77)
        %v70158_v29 = vadd.s32 %v70155_v41, %v121574_v2 (stack40)
        %v71828_v27 = vor.u32 %v71827_v31, %v71826_v32 (stack47)
        %v69421_v61 = vsel /*vm=*/%vm69269_vm9, /*on_true_vy=*/%v69274_v6, /*on_false_vx=*/%v69417_v26 (stack44)
        %v70150_v10 = vadd.s32 %v70146_v10, %v121564_v0 (stack40)
        %v70940_v22 = vadd.s32 %v70936_v22, %v121564_v0 (stack40)
        %v71391_v34 = vadd.s32 %v71387_v34, %v121569_v1 (stack40)
        %v69425_v44 = vmul.f32 1.4140625, %v69421_v61 (stack54)
        %v142591_v21 = vsel /*vm=*/%vm69754_vm8, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v142594_v9 = vadd.f32 -2.5, %v142571_v7 (stack53)
        %v70162_v42 = vadd.s32 5, %v70158_v29 (stack40)
        %v70552_v56 = vxor.u32 %v70551_v60, %v70547_v20 (stack48)
        %v70956_v45 = vadd.s32 %v70952_v52, %v70940_v22 (stack40)
        %v70958_v50 = vshll.u32 %v70952_v52, 13 (stack45)
        %v70959_v30 = vshrl.u32 %v70952_v52, 19 (stack46)
        %v69428_v46 = vpack.c.bf16 %v157387_v11, %v69425_v44 (stack81)
        %v70164_v55 = vxor.u32 %v70162_v42, %v70150_v10 (stack48)
        %v71399_v8 = vadd.s32 %v71396_v53, %v121564_v0 (stack40)
        %v71829_v41 = vxor.u32 %v71828_v27, %v71824_v24 (stack48)
        %vm69799_vm10 = vcmp.eq.f32.partialorder %v142571_v7, inf (stack70)
        %v70555_v20 = vadd.s32 %v70552_v56, %v70547_v20 (stack40)
        %v70557_v32 = vshll.u32 %v70552_v56, 16 (stack45)
        %v70558_v31 = vshrl.u32 %v70552_v56, 16 (stack46)
        %v70960_v40 = vor.u32 %v70959_v30, %v70958_v50 (stack47)
        %120115 = vst [vmem:[%s123356_s30 + $0x1c8] sm:$0xf] /*vst_source=*/%v69428_v46 (stack83)
        %v70165_v53 = vand.u32.u8 255, %v70164_v55 (stack49)
        %v71403_v6 = vadd.s32 1, %v71399_v8 (stack40)
        %v71832_v24 = vadd.s32 %v71829_v41, %v71824_v24 (stack40)
        %v71834_v26 = vshll.u32 %v71829_v41, 15 (stack45)
        %v69791_v60 = vsel /*vm=*/%vm69754_vm8, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v70559_v52 = vor.u32 %v70558_v31, %v70557_v32 (stack47)
        %v70961_v29 = vxor.u32 %v70960_v40, %v70956_v45 (stack48)
        %v71835_v27 = vshrl.u32 %v71829_v41, 17 (stack46)
        %v70166_v61 = vand.u32 65535, %v70165_v53 (stack50)
        %v71407_v10 = vadd.s32 %v71403_v6, %v71391_v34 (stack40)
        %v71409_v22 = vshll.u32 %v71403_v6, 17 (stack45)
        %v71410_v34 = vshrl.u32 %v71403_v6, 15 (stack46)
        %v70560_v44 = vxor.u32 %v70559_v52, %v70555_v20 (stack48)
        %v70964_v42 = vadd.s32 %v70961_v29, %v70956_v45 (stack40)
        %v70966_v56 = vshll.u32 %v70961_v29, 15 (stack45)
        %v70967_v45 = vshrl.u32 %v70961_v29, 17 (stack46)
        %vm69801_vm11 = vcmp.eq.f32.partialorder %v142571_v7, 0.0 (stack71)
        %v70167_v50 = vshrl.u32 %v70166_v61, 1 (stack51)
        %v71411_v30 = vor.u32 %v71410_v34, %v71409_v22 (stack47)
        %v71836_v46 = vor.u32 %v71835_v27, %v71834_v26 (stack47)
        %v121028_v55 = vpop.eup %121027 (stack73)
        %v70563_v8 = vadd.s32 %v70560_v44, %v70555_v20 (stack40)
        %v70569_v41 = vshll.u32 %v70560_v44, 24 (stack45)
        %v70570_v20 = vshrl.u32 %v70560_v44, 8 (stack46)
        %v70968_v32 = vor.u32 %v70967_v45, %v70966_v56 (stack47)
        %v69798_v31 = vmul.f32 %v121028_v55, %v142571_v7 (stack74)
        %v70168_v40 = vor.u32 16256, %v70167_v50 (stack47)
        %v71412_v53 = vxor.u32 %v71411_v30, %v71407_v10 (stack48)
        %v71837_v6 = vxor.u32 %v71836_v46, %v71832_v24 (stack48)
        %v69802_v26 = vand.u32 2147483648, %v142571_v7 (stack72)
        %v70571_v52 = vor.u32 %v70570_v20, %v70569_v41 (stack47)
        %v70969_v29 = vxor.u32 %v70968_v32, %v70964_v42 (stack48)
        %vm72251_vm12 = vcmp.lt.u32.totalorder %v142558_v23, %v157077_v51 (stack43)
        %v69800_v27 = vsel /*vm=*/%vm69799_vm10, /*on_true_vy=*/%v142571_v7, /*on_false_vx=*/%v69798_v31 (stack75)
        %v70169_v61 = vand.u32.u16 65535, %v70168_v40 (stack52)
        %v71415_v10 = vadd.s32 %v71412_v53, %v71407_v10 (stack40)
        %v71417_v22 = vshll.u32 %v71412_v53, 29 (stack45)
        %v69803_v34 = vsel /*vm=*/%vm69801_vm11, /*on_true_vy=*/%v69802_v26, /*on_false_vx=*/%v69800_v27 (stack76)
        %v70572_v44 = vxor.u32 %v70571_v52, %v70563_v8 (stack48)
        %v70972_v42 = vadd.s32 %v70969_v29, %v70964_v42 (stack40)
        %v70974_v56 = vshll.u32 %v70969_v29, 26 (stack45)
        %v69806_v45 = vadd.f32 -3.0, %v69803_v34 (stack53)
        %v120118_v50 = vadd.low.f32.bf16 -1.0, %v70169_v61 (stack53)
        %v70975_v30 = vshrl.u32 %v70969_v29, 6 (stack46)
        %v71418_v46 = vshrl.u32 %v71412_v53, 3 (stack46)
        %v70575_v55 = vadd.s32 %v70572_v44, %v121564_v0 (stack40)
        %v71840_v24 = vadd.s32 %v71837_v6, %v71832_v24 (stack40)
        %v71842_v41 = vshll.u32 %v71837_v6, 26 (stack45)
        %v71843_v20 = vshrl.u32 %v71837_v6, 6 (stack46)
        %v142617_v9 = vsel /*vm=*/%vm69754_vm8, /*on_true_vy=*/%v142594_v9, /*on_false_vx=*/%v69806_v45 (stack44)
        %v70178_v32 = vmul.f32 2.0, %v120118_v50 (stack54)
        %v70976_v31 = vor.u32 %v70975_v30, %v70974_v56 (stack47)
        %v71419_v40 = vor.u32 %v71418_v46, %v71417_v22 (stack47)
        %v69814_v60 = vmul.f32 %v142617_v9, %v69791_v60 (stack54)
        %v70567_v8 = vadd.s32 %v70563_v8, %v121569_v1 (stack40)
        %v70579_v53 = vadd.s32 4, %v70575_v55 (stack40)
        %v142623_v6 = vadd.s32 %v157517_v43, %v157078_v48 (stack40)
        %v70182_v26 = vadd.f32 -0.99609375, %v70178_v32 (stack53)
        %v70977_v52 = vxor.u32 %v70976_v31, %v70972_v42 (stack48)
        %v71420_v29 = vxor.u32 %v71419_v40, %v71415_v10 (stack48)
        %v71844_v27 = vor.u32 %v71843_v20, %v71842_v41 (stack47)
        %v69818_v21 = vadd.f32 %v69814_v60, %v142591_v21 (stack53)
        %v70583_v61 = vadd.s32 %v70579_v53, %v70567_v8 (stack40)
        %v70585_v22 = vshll.u32 %v70579_v53, 13 (stack45)
        %v70586_v34 = vshrl.u32 %v70579_v53, 19 (stack46)
        %v142626_v44 = vmax.f32 %v70182_v26, -0.99609375 (stack55)
        %v70980_v42 = vadd.s32 %v70977_v52, %v70972_v42 (stack40)
        %v70986_v56 = vshll.u32 %v70977_v52, 6 (stack45)
        %v70987_v45 = vshrl.u32 %v70977_v52, 26 (stack46)
        %v142631_v50 = vsel /*vm=*/%vm69754_vm8, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v69822_v30 = vmul.f32 %v69818_v21, %v142617_v9 (stack54)
        %v70587_v46 = vor.u32 %v70586_v34, %v70585_v22 (stack47)
        %v71423_v10 = vadd.s32 %v71420_v29, %v71415_v10 (stack40)
        %v142637_v55 = vsel /*vm=*/%vm69754_vm8, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v69783_v41 = vsel /*vm=*/%vm69754_vm8, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v70198_v20 = vxor.u32 2147483648, %v142626_v44 (stack56)
        %v71425_v32 = vshll.u32 %v71420_v29, 16 (stack45)
        %v69826_v31 = vadd.f32 %v69822_v30, %v69783_v41 (stack53)
        %v70588_v40 = vxor.u32 %v70587_v46, %v70583_v61 (stack48)
        %v70988_v60 = vor.u32 %v70987_v45, %v70986_v56 (stack47)
        %v71426_v8 = vshrl.u32 %v71420_v29, 16 (stack46)
        %v69767_v53 = vsel /*vm=*/%vm69754_vm8, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v142647_v26 = vmul.f32 %v70198_v20, %v142626_v44 (stack54)
        %v71845_v52 = vxor.u32 %v71844_v27, %v71840_v24 (stack48)
        %v142651_v29 = vadd.s32 %v142558_v23, %v122657_v58 (stack40)
        %v69830_v27 = vmul.f32 %v69826_v31, %v142617_v9 (stack54)
        %v70591_v21 = vadd.s32 %v70588_v40, %v70583_v61 (stack40)
        %v70593_v61 = vshll.u32 %v70588_v40, 15 (stack45)
        %v70594_v22 = vshrl.u32 %v70588_v40, 17 (stack46)
        %v69771_v34 = vsel /*vm=*/%vm69754_vm8, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v69779_v56 = vsel /*vm=*/%vm69754_vm8, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v70203_v45 = vadd.f32 1.0, %v142647_v26 (stack57)
        %v70989_v30 = vxor.u32 %v70988_v60, %v70980_v42 (stack48)
        %v69834_v46 = vadd.f32 %v69830_v27, %v69779_v56 (stack53)
        %v70595_v41 = vor.u32 %v70594_v22, %v70593_v61 (stack47)
        %v71427_v20 = vor.u32 %v71426_v8, %v71425_v32 (stack47)
        %v71848_v24 = vadd.s32 %v71845_v52, %v71840_v24 (stack40)
        %v69775_v7 = vsel /*vm=*/%vm69754_vm8, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %121029 = vlog2.f32 %v70203_v45 (stack58)
        %v70984_v42 = vadd.s32 %v70980_v42, %v121574_v2 (stack40)
        %v70992_v32 = vadd.s32 %v70989_v30, %v121569_v1 (stack40)
        %v69838_v31 = vmul.f32 %v69834_v46, %v142617_v9 (stack54)
        %v70596_v40 = vxor.u32 %v70595_v41, %v70591_v21 (stack48)
        %v71428_v60 = vxor.u32 %v71427_v20, %v71423_v10 (stack48)
        %vm72246_vm13 = vcmp.lt.u32.totalorder %v142651_v29, %v142558_v23 (stack43)
        %v72260_v8 = vadd.s32 1, %v142623_v6 (stack40)
        %v70206_v27 = vmul.f32 -0.5, %v142647_v26 (stack59)
        %v70996_v61 = vadd.s32 3, %v70992_v32 (stack40)
        %v71854_v22 = vshll.u32 %v71845_v52, 6 (stack45)
        %v71855_v52 = vshrl.u32 %v71845_v52, 26 (stack46)
        %v69842_v56 = vadd.f32 %v69838_v31, %v69775_v7 (stack53)
        %v70599_v21 = vadd.s32 %v70596_v40, %v70591_v21 (stack40)
        %v70601_v45 = vshll.u32 %v70596_v40, 26 (stack45)
        %v70602_v30 = vshrl.u32 %v70596_v40, 6 (stack46)
        %v71000_v46 = vadd.s32 %v70996_v61, %v70984_v42 (stack40)
        %v71002_v41 = vshll.u32 %v70996_v61, 17 (stack45)
        %v71003_v20 = vshrl.u32 %v70996_v61, 15 (stack46)
        %v71431_v10 = vadd.s32 %v71428_v60, %v71423_v10 (stack40)
        %v69846_v7 = vmul.f32 %v69842_v56, %v142617_v9 (stack54)
        %v70603_v42 = vor.u32 %v70602_v30, %v70601_v45 (stack47)
        %v71437_v32 = vshll.u32 %v71428_v60, 24 (stack45)
        %v71438_v31 = vshrl.u32 %v71428_v60, 8 (stack46)
        %v71004_v40 = vor.u32 %v71003_v20, %v71002_v41 (stack47)
        %v71856_v60 = vor.u32 %v71855_v52, %v71854_v22 (stack47)
        %v72264_v6 = vsel /*vm=*/%vm72251_vm12, /*on_true_vy=*/%v72260_v8, /*on_false_vx=*/%v142623_v6 (stack44)
        %v142678_v8 = vadd.s32 %v142651_v29, %v121569_v1 (stack40)
        %v69850_v34 = vadd.f32 %v69846_v7, %v69771_v34 (stack53)
        %v70209_v61 = vand.u32 2147483647, %v142647_v26 (stack60)
        %v70604_v22 = vxor.u32 %v70603_v42, %v70599_v21 (stack48)
        %v71439_v52 = vor.u32 %v71438_v31, %v71437_v32 (stack47)
        %v70207_v27 = vadd.f32 1.0, %v70206_v27 (stack61)
        %v71005_v56 = vxor.u32 %v71004_v40, %v71000_v46 (stack48)
        %v71857_v45 = vxor.u32 %v71856_v60, %v71848_v24 (stack48)
        %v72268_v30 = vadd.s32 1, %v72264_v6 (stack40)
        %v69854_v41 = vmul.f32 %v69850_v34, %v142617_v9 (stack54)
        %v70607_v21 = vadd.s32 %v70604_v22, %v70599_v21 (stack40)
        %v70613_v20 = vshll.u32 %v70604_v22, 6 (stack45)
        %v70614_v7 = vshrl.u32 %v70604_v22, 26 (stack46)
        %v71008_v46 = vadd.s32 %v71005_v56, %v71000_v46 (stack40)
        %v71010_v42 = vshll.u32 %v71005_v56, 29 (stack45)
        %v71011_v32 = vshrl.u32 %v71005_v56, 3 (stack46)
        %v71440_v31 = vxor.u32 %v71439_v52, %v71431_v10 (stack48)
        %v69858_v53 = vadd.f32 %v69854_v41, %v69767_v53 (stack53)
        %vm142682_vm14 = vcmp.lt.f32.partialorder %v70209_v61, 0.0004427343 (stack62)
        %v70615_v60 = vor.u32 %v70614_v7, %v70613_v20 (stack47)
        %v71860_v34 = vadd.s32 %v71857_v45, %v121564_v0 (stack40)
        %v71012_v61 = vor.u32 %v71011_v32, %v71010_v42 (stack47)
        %v71443_v22 = vadd.s32 %v71440_v31, %v121574_v2 (stack40)
        %v71852_v24 = vadd.s32 %v71848_v24, %v121569_v1 (stack40)
        %v72272_v23 = vsel /*vm=*/%vm72246_vm13, /*on_true_vy=*/%v72268_v30, /*on_false_vx=*/%v72264_v6 (stack44)
        %v121030_v29 = vpop.eup %121029 (stack64)
        %v69862_v6 = vmul.f32 %v69858_v53, %v142617_v9 (stack54)
        %v70208_v26 = vmul.f32 %v70207_v27, %v142647_v26 (stack63)
        %v70616_v52 = vxor.u32 %v70615_v60, %v70607_v21 (stack48)
        %v71864_v27 = vadd.s32 1, %v71860_v34 (stack40)
        %v70205_v56 = vmul.f32 0.6931472, %v121030_v29 (stack65)
        %v71013_v45 = vxor.u32 %v71012_v61, %v71008_v46 (stack48)
        %v71447_v30 = vadd.s32 2, %v71443_v22 (stack40)
        %v142696_v41 = vadd.s32 %v157514_v25, %v157079_v39 (stack40)
        %v69866_v55 = vadd.f32 %v69862_v6, %v142637_v55 (stack53)
        %v70619_v20 = vadd.s32 %v70616_v52, %v121574_v2 (stack40)
        %v71435_v10 = vadd.s32 %v71431_v10, %v121564_v0 (stack40)
        %v71868_v7 = vadd.s32 %v71864_v27, %v71852_v24 (stack40)
        %v70211_v42 = vsel /*vm=*/%vm142682_vm14, /*on_true_vy=*/%v70208_v26, /*on_false_vx=*/%v70205_v56 (stack66)
        %v71016_v46 = vadd.s32 %v71013_v45, %v71008_v46 (stack40)
        %v71018_v32 = vshll.u32 %v71013_v45, 16 (stack45)
        %v71019_v31 = vshrl.u32 %v71013_v45, 16 (stack46)
        %v69870_v9 = vmul.f32 %v69866_v55, %v142617_v9 (stack54)
        %v142704_v53 = vxor.u32 2147483648, %v70211_v42 (stack56)
        %v70623_v40 = vadd.s32 5, %v70619_v20 (stack40)
        %v71451_v60 = vadd.s32 %v71447_v30, %v71435_v10 (stack40)
        %v70611_v21 = vadd.s32 %v70607_v21, %v121564_v0 (stack40)
        %v71020_v34 = vor.u32 %v71019_v31, %v71018_v32 (stack47)
        %v72287_v61 = vshll.u32 %v142678_v8, 13 (stack45)
        %v72288_v22 = vshrl.u32 %v142678_v8, 19 (stack46)
        %v69735_v24 = vmul.f32 inf, %v142510_v54 (stack54)
        %v69874_v50 = vadd.f32 %v69870_v9, %v142631_v50 (stack53)
        %vm70215_vm15 = vcmp.lt.f32.partialorder %v142704_v53, 5.0 (stack68)
        %121031 = vrsqrt.f32 %v142704_v53 (stack67)
        %vm142715_vm0 = vcmp.eq.f32.partialorder %v69727_v12, 1.0 (stack68)
        %v70625_v29 = vxor.u32 %v70623_v40, %v70611_v21 (stack48)
        %v71870_v6 = vshll.u32 %v71864_v27, 17 (stack45)
        %v72277_v23 = vadd.s32 %v72272_v23, %v121574_v2 (stack40)
        %v69878_v54 = vmul.f32 %v69874_v50, %v142510_v54 (stack54)
        %v71453_v26 = vshll.u32 %v71447_v30, 13 (stack45)
        %v71454_v52 = vshrl.u32 %v71447_v30, 19 (stack46)
        %v71871_v27 = vshrl.u32 %v71864_v27, 15 (stack46)
        %v142724_v56 = vsel /*vm=*/%vm70215_vm15, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v142727_v45 = vadd.f32 -2.5, %v142704_v53 (stack53)
        %v71021_v30 = vxor.u32 %v71020_v34, %v71016_v46 (stack48)
        %v72289_v55 = vor.u32 %v72288_v22, %v72287_v61 (stack47)
        %v69882_v20 = vsel /*vm=*/%vm142715_vm0, /*on_true_vy=*/%v69735_v24, /*on_false_vx=*/%v69878_v54 (stack44)
        %v142734_v10 = vsel /*vm=*/%vm70215_vm15, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v142739_v42 = vsel /*vm=*/%vm70215_vm15, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v142744_v32 = vsel /*vm=*/%vm70215_vm15, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v69886_v31 = vmul.f32 1.4140625, %v69882_v20 (stack54)
        %v70626_v9 = vand.u32.u8 255, %v70625_v29 (stack49)
        %v71024_v46 = vadd.s32 %v71021_v30, %v71016_v46 (stack40)
        %v71030_v40 = vshll.u32 %v71021_v30, 24 (stack45)
        %v71031_v21 = vshrl.u32 %v71021_v30, 8 (stack46)
        %v71455_v34 = vor.u32 %v71454_v52, %v71453_v26 (stack47)
        %v71872_v61 = vor.u32 %v71871_v27, %v71870_v6 (stack47)
        %v72285_v8 = vadd.s32 %v142678_v8, %v72277_v23 (stack40)
        %v69889_v22 = vpack.c.bf16 %v157387_v11, %v69886_v31 (stack81)
        %v70252_v24 = vsel /*vm=*/%vm70215_vm15, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %vm70260_vm1 = vcmp.eq.f32.partialorder %v142704_v53, inf (stack70)
        %v70627_v50 = vand.u32 65535, %v70626_v9 (stack50)
        %vm70262_vm2 = vcmp.eq.f32.partialorder %v142704_v53, 0.0 (stack71)
        %v71032_v12 = vor.u32 %v71031_v21, %v71030_v40 (stack47)
        %v71456_v29 = vxor.u32 %v71455_v34, %v71451_v60 (stack48)
        %v71873_v6 = vxor.u32 %v71872_v61, %v71868_v7 (stack48)
        %v72290_v23 = vxor.u32 %v72289_v55, %v72285_v8 (stack48)
        %120117 = vst [vmem:[%s123356_s30 + $0x248] sm:$0xf] /*vst_source=*/%v69889_v22 (stack83)
        %v70263_v54 = vand.u32 2147483648, %v142704_v53 (stack72)
        %v70628_v26 = vshrl.u32 %v70627_v50, 1 (stack51)
        %vm72712_vm3 = vcmp.lt.u32.totalorder %v142696_v41, %v157079_v39 (stack43)
        %v72717_v52 = vadd.s32 %v157517_v43, %v157082_v49 (stack40)
        %v71033_v27 = vxor.u32 %v71032_v12, %v71024_v46 (stack48)
        %v71459_v60 = vadd.s32 %v71456_v29, %v71451_v60 (stack40)
        %v71461_v30 = vshll.u32 %v71456_v29, 15 (stack45)
        %v71462_v55 = vshrl.u32 %v71456_v29, 17 (stack46)
        %v70629_v20 = vor.u32 16256, %v70628_v26 (stack47)
        %v71876_v7 = vadd.s32 %v71873_v6, %v71868_v7 (stack40)
        %v71878_v31 = vshll.u32 %v71873_v6, 29 (stack45)
        %v71879_v9 = vshrl.u32 %v71873_v6, 3 (stack46)
        %v71036_v40 = vadd.s32 %v71033_v27, %v121564_v0 (stack40)
        %v71463_v21 = vor.u32 %v71462_v55, %v71461_v30 (stack47)
        %v72293_v34 = vadd.s32 %v72290_v23, %v72285_v8 (stack40)
        %v72295_v61 = vshll.u32 %v72290_v23, 15 (stack45)
        %v121032_v8 = vpop.eup %121031 (stack73)
        %v70630_v22 = vand.u32.u16 65535, %v70629_v20 (stack52)
        %v71880_v50 = vor.u32 %v71879_v9, %v71878_v31 (stack47)
        %v72296_v12 = vshrl.u32 %v72290_v23, 17 (stack46)
        %v72721_v29 = vadd.s32 1, %v72717_v52 (stack40)
        %v70259_v6 = vmul.f32 %v121032_v8, %v142704_v53 (stack74)
        %v71028_v46 = vadd.s32 %v71024_v46, %v121569_v1 (stack40)
        %v71040_v23 = vadd.s32 4, %v71036_v40 (stack40)
        %v71464_v26 = vxor.u32 %v71463_v21, %v71459_v60 (stack48)
        %v120120_v27 = vadd.low.f32.bf16 -1.0, %v70630_v22 (stack53)
        %v71881_v30 = vxor.u32 %v71880_v50, %v71876_v7 (stack48)
        %v72297_v55 = vor.u32 %v72296_v12, %v72295_v61 (stack47)
        %v142765_v52 = vsel /*vm=*/%vm72712_vm3, /*on_true_vy=*/%v72721_v29, /*on_false_vx=*/%v72717_v52 (stack44)
        %v70261_v20 = vsel /*vm=*/%vm70260_vm1, /*on_true_vy=*/%v142704_v53, /*on_false_vx=*/%v70259_v6 (stack75)
        %v71044_v31 = vadd.s32 %v71040_v23, %v71028_v46 (stack40)
        %v71046_v9 = vshll.u32 %v71040_v23, 13 (stack45)
        %v71047_v40 = vshrl.u32 %v71040_v23, 19 (stack46)
        %v70264_v54 = vsel /*vm=*/%vm70262_vm2, /*on_true_vy=*/%v70263_v54, /*on_false_vx=*/%v70261_v20 (stack76)
        %v70639_v21 = vmul.f32 2.0, %v120120_v27 (stack54)
        %v71467_v60 = vadd.s32 %v71464_v26, %v71459_v60 (stack40)
        %v71469_v61 = vshll.u32 %v71464_v26, 26 (stack45)
        %v70267_v8 = vadd.f32 -3.0, %v70264_v54 (stack53)
        %v71048_v22 = vor.u32 %v71047_v40, %v71046_v9 (stack47)
        %v71470_v50 = vshrl.u32 %v71464_v26, 6 (stack46)
        %v71884_v7 = vadd.s32 %v71881_v30, %v71876_v7 (stack40)
        %v70643_v12 = vadd.f32 -0.99609375, %v70639_v21 (stack53)
        %v71886_v29 = vshll.u32 %v71881_v30, 16 (stack45)
        %v71887_v6 = vshrl.u32 %v71881_v30, 16 (stack46)
        %v72298_v46 = vxor.u32 %v72297_v55, %v72293_v34 (stack48)
        %v142775_v45 = vsel /*vm=*/%vm70215_vm15, /*on_true_vy=*/%v142727_v45, /*on_false_vx=*/%v70267_v8 (stack44)
        %v71049_v23 = vxor.u32 %v71048_v22, %v71044_v31 (stack48)
        %v71471_v26 = vor.u32 %v71470_v50, %v71469_v61 (stack47)
        %v72703_v27 = vadd.s32 %v142696_v41, %v122657_v58 (stack40)
        %v70275_v24 = vmul.f32 %v142775_v45, %v70252_v24 (stack54)
        %v142780_v30 = vmax.f32 %v70643_v12, -0.99609375 (stack55)
        %v71888_v55 = vor.u32 %v71887_v6, %v71886_v29 (stack47)
        %v142782_v34 = vadd.s32 %v72298_v46, %v72293_v34 (stack40)
        %v71052_v20 = vadd.s32 %v71049_v23, %v71044_v31 (stack40)
        %v71054_v31 = vshll.u32 %v71049_v23, 15 (stack45)
        %v71055_v9 = vshrl.u32 %v71049_v23, 17 (stack46)
        %v71472_v40 = vxor.u32 %v71471_v26, %v71467_v60 (stack48)
        %v70240_v54 = vsel /*vm=*/%vm70215_vm15, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v70244_v21 = vsel /*vm=*/%vm70215_vm15, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v70279_v32 = vadd.f32 %v70275_v24, %v142744_v32 (stack53)
        %v70659_v61 = vxor.u32 2147483648, %v142780_v30 (stack56)
        %v71056_v8 = vor.u32 %v71055_v9, %v71054_v31 (stack47)
        %v71475_v60 = vadd.s32 %v71472_v40, %v71467_v60 (stack40)
        %v71481_v22 = vshll.u32 %v71472_v40, 6 (stack45)
        %v71482_v50 = vshrl.u32 %v71472_v40, 26 (stack46)
        %v70283_v12 = vmul.f32 %v70279_v32, %v142775_v45 (stack54)
        %v142794_v29 = vmul.f32 %v70659_v61, %v142780_v30 (stack54)
        %v71889_v6 = vxor.u32 %v71888_v55, %v71884_v7 (stack48)
        %vm72707_vm4 = vcmp.lt.u32.totalorder %v72703_v27, %v142696_v41 (stack43)
        %v71057_v23 = vxor.u32 %v71056_v8, %v71052_v20 (stack48)
        %v71483_v26 = vor.u32 %v71482_v50, %v71481_v22 (stack47)
        %v72729_v24 = vadd.s32 1, %v142765_v52 (stack40)
        %v142799_v55 = vadd.s32 %v72703_v27, %v121569_v1 (stack40)
        %v70287_v31 = vadd.f32 %v70283_v12, %v70244_v21 (stack53)
        %v70664_v9 = vadd.f32 1.0, %v142794_v29 (stack57)
        %v70667_v40 = vmul.f32 -0.5, %v142794_v29 (stack59)
        %v71479_v21 = vadd.s32 %v71475_v60, %v121574_v2 (stack40)
        %v71060_v20 = vadd.s32 %v71057_v23, %v71052_v20 (stack40)
        %v71062_v32 = vshll.u32 %v71057_v23, 26 (stack45)
        %v71063_v61 = vshrl.u32 %v71057_v23, 6 (stack46)
        %v71484_v8 = vxor.u32 %v71483_v26, %v71475_v60 (stack48)
        %v70291_v60 = vmul.f32 %v70287_v31, %v142775_v45 (stack54)
        %121033 = vlog2.f32 %v70664_v9 (stack58)
        %v70668_v22 = vadd.f32 1.0, %v70667_v40 (stack61)
        %v72303_v50 = vshll.u32 %v72298_v46, 26 (stack45)
        %v71064_v12 = vor.u32 %v71063_v61, %v71062_v32 (stack47)
        %v71487_v23 = vadd.s32 %v71484_v8, %v121569_v1 (stack40)
        %v71892_v7 = vadd.s32 %v71889_v6, %v71884_v7 (stack40)
        %v71898_v26 = vshll.u32 %v71889_v6, 24 (stack45)
        %v70295_v54 = vadd.f32 %v70291_v60, %v70240_v54 (stack53)
        %v70670_v31 = vand.u32 2147483647, %v142794_v29 (stack60)
        %v71899_v6 = vshrl.u32 %v71889_v6, 8 (stack46)
        %v72304_v46 = vshrl.u32 %v72298_v46, 6 (stack46)
        %v70669_v29 = vmul.f32 %v70668_v22, %v142794_v29 (stack63)
        %v71065_v9 = vxor.u32 %v71064_v12, %v71060_v20 (stack48)
        %v71491_v40 = vadd.s32 3, %v71487_v23 (stack40)
        %v72733_v41 = vsel /*vm=*/%vm72707_vm4, /*on_true_vy=*/%v72729_v24, /*on_false_vx=*/%v142765_v52 (stack44)
        %v70299_v52 = vmul.f32 %v70295_v54, %v142775_v45 (stack54)
        %v71900_v27 = vor.u32 %v71899_v6, %v71898_v26 (stack47)
        %v72305_v24 = vor.u32 %v72304_v46, %v72303_v50 (stack47)
        %v72738_v32 = vadd.s32 %v72733_v41, %v121574_v2 (stack40)
        %v71068_v20 = vadd.s32 %v71065_v9, %v71060_v20 (stack40)
        %v71074_v61 = vshll.u32 %v71065_v9, 6 (stack45)
        %v71075_v8 = vshrl.u32 %v71065_v9, 26 (stack46)
        %v71495_v21 = vadd.s32 %v71491_v40, %v71479_v21 (stack40)
        %v70303_v42 = vadd.f32 %v70299_v52, %v142739_v42 (stack53)
        %v71497_v60 = vshll.u32 %v71491_v40, 17 (stack45)
        %v71498_v22 = vshrl.u32 %v71491_v40, 15 (stack46)
        %v71901_v50 = vxor.u32 %v71900_v27, %v71892_v7 (stack48)
        %v71076_v12 = vor.u32 %v71075_v8, %v71074_v61 (stack47)
        %v71896_v23 = vadd.s32 %v71892_v7, %v121564_v0 (stack40)
        %v72306_v7 = vxor.u32 %v72305_v24, %v142782_v34 (stack48)
        %v142817_v26 = vadd.s32 %v142799_v55, %v72738_v32 (stack40)
        %v70307_v54 = vmul.f32 %v70303_v42, %v142775_v45 (stack54)
        %v71072_v6 = vadd.s32 %v71068_v20, %v121564_v0 (stack40)
        %v71499_v46 = vor.u32 %v71498_v22, %v71497_v60 (stack47)
        %v71904_v9 = vadd.s32 %v71901_v50, %v121574_v2 (stack40)
        %v71077_v40 = vxor.u32 %v71076_v12, %v71068_v20 (stack48)
        %v72309_v34 = vadd.s32 %v72306_v7, %v142782_v34 (stack40)
        %v72315_v41 = vshll.u32 %v72306_v7, 6 (stack45)
        %v72316_v52 = vshrl.u32 %v72306_v7, 26 (stack46)
        %v70311_v10 = vadd.f32 %v70307_v54, %v142734_v10 (stack53)
        %v71500_v27 = vxor.u32 %v71499_v46, %v71495_v21 (stack48)
        %v71908_v24 = vadd.s32 2, %v71904_v9 (stack40)
        %v72748_v32 = vshll.u32 %v142799_v55, 13 (stack45)
        %v71080_v20 = vadd.s32 %v71077_v40, %v121574_v2 (stack40)
        %v72317_v61 = vor.u32 %v72316_v52, %v72315_v41 (stack47)
        %v72749_v55 = vshrl.u32 %v142799_v55, 19 (stack46)
        %v142829_v8 = vadd.s32 %v157514_v25, %v157083_v59 (stack40)
        %v70315_v42 = vmul.f32 %v70311_v10, %v142775_v45 (stack54)
        %v71503_v21 = vadd.s32 %v71500_v27, %v71495_v21 (stack40)
        %v71505_v60 = vshll.u32 %v71500_v27, 29 (stack45)
        %v71506_v22 = vshrl.u32 %v71500_v27, 3 (stack46)
        %v121034_v50 = vpop.eup %121033 (stack64)
        %v71084_v12 = vadd.s32 5, %v71080_v20 (stack40)
        %v71912_v23 = vadd.s32 %v71908_v24, %v71896_v23 (stack40)
        %v71914_v7 = vshll.u32 %v71908_v24, 13 (stack45)
        %v71915_v54 = vshrl.u32 %v71908_v24, 19 (stack46)
        %v70319_v56 = vadd.f32 %v70315_v42, %v142724_v56 (stack53)
        %v70666_v46 = vmul.f32 0.6931472, %v121034_v50 (stack65)
        %v71507_v9 = vor.u32 %v71506_v22, %v71505_v60 (stack47)
        %v72318_v40 = vxor.u32 %v72317_v61, %v72309_v34 (stack48)
        %vm70671_vm5 = vcmp.lt.f32.partialorder %v70670_v31, 0.0004427343 (stack62)
        %v71086_v31 = vxor.u32 %v71084_v12, %v71072_v6 (stack48)
        %v71916_v6 = vor.u32 %v71915_v54, %v71914_v7 (stack47)
        %v72750_v41 = vor.u32 %v72749_v55, %v72748_v32 (stack47)
        %v70188_v52 = vand.u32 2147483647, %v142626_v44 (stack77)
        %v70323_v10 = vmul.f32 %v70319_v56, %v142775_v45 (stack54)
        %v70672_v29 = vsel /*vm=*/%vm70671_vm5, /*on_true_vy=*/%v70669_v29, /*on_false_vx=*/%v70666_v46 (stack66)
        %v71508_v27 = vxor.u32 %v71507_v9, %v71503_v21 (stack48)
        %v70224_v24 = vsel /*vm=*/%vm70215_vm15, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v142838_v32 = vxor.u32 2147483648, %v70672_v29 (stack56)
        %v71917_v20 = vxor.u32 %v71916_v6, %v71912_v23 (stack48)
        %v142841_v61 = vxor.u32 %v72750_v41, %v142817_v26 (stack48)
        %v70327_v55 = vadd.f32 %v70323_v10, %v70224_v24 (stack53)
        %v71511_v42 = vadd.s32 %v71508_v27, %v71503_v21 (stack40)
        %v71513_v21 = vshll.u32 %v71508_v27, 16 (stack45)
        %v71514_v60 = vshrl.u32 %v71508_v27, 16 (stack46)
        %121035 = vrsqrt.f32 %v142838_v32 (stack67)
        %v71087_v22 = vand.u32.u8 255, %v71086_v31 (stack49)
        %v70331_v45 = vmul.f32 %v70327_v55, %v142775_v45 (stack54)
        %vm142845_vm6 = vcmp.eq.f32.partialorder %v70188_v52, 1.0 (stack68)
        %v70196_v12 = vmul.f32 inf, %v142626_v44 (stack54)
        %v70220_v53 = vsel /*vm=*/%vm70215_vm15, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v71515_v7 = vor.u32 %v71514_v60, %v71513_v21 (stack47)
        %v70335_v54 = vadd.f32 %v70331_v45, %v70220_v53 (stack53)
        %v70649_v56 = vand.u32 2147483647, %v142780_v30 (stack77)
        %v72313_v34 = vadd.s32 %v72309_v34, %v121569_v1 (stack40)
        %v72321_v46 = vadd.s32 %v72318_v40, %v121564_v0 (stack40)
        %v142857_v9 = vadd.f32 -2.5, %v142838_v32 (stack53)
        %v71088_v40 = vand.u32 65535, %v71087_v22 (stack50)
        %v71516_v31 = vxor.u32 %v71515_v7, %v71511_v42 (stack48)
        %v142861_v6 = vadd.s32 %v142829_v8, %v122657_v58 (stack40)
        %v70339_v44 = vmul.f32 %v70335_v54, %v142626_v44 (stack54)
        %v71920_v23 = vadd.s32 %v71917_v20, %v71912_v23 (stack40)
        %v71922_v41 = vshll.u32 %v71917_v20, 15 (stack45)
        %v71923_v52 = vshrl.u32 %v71917_v20, 17 (stack46)
        %v71089_v10 = vshrl.u32 %v71088_v40, 1 (stack51)
        %v71519_v29 = vadd.s32 %v71516_v31, %v71511_v42 (stack40)
        %v71525_v27 = vshll.u32 %v71516_v31, 24 (stack45)
        %v71526_v24 = vshrl.u32 %v71516_v31, 8 (stack46)
        %v70343_v20 = vsel /*vm=*/%vm142845_vm6, /*on_true_vy=*/%v70196_v12, /*on_false_vx=*/%v70339_v44 (stack44)
        %vm70721_vm7 = vcmp.eq.f32.partialorder %v142838_v32, inf (stack70)
        %v71924_v55 = vor.u32 %v71923_v52, %v71922_v41 (stack47)
        %v72325_v42 = vadd.s32 1, %v72321_v46 (stack40)
        %v142869_v26 = vadd.s32 %v142841_v61, %v142817_v26 (stack40)
        %v70347_v21 = vmul.f32 1.4140625, %v70343_v20 (stack54)
        %vm70676_vm8 = vcmp.lt.f32.partialorder %v142838_v32, 5.0 (stack68)
        %vm70723_vm9 = vcmp.eq.f32.partialorder %v142838_v32, 0.0 (stack71)
        %v70724_v60 = vand.u32 2147483648, %v142838_v32 (stack72)
        %v71090_v22 = vor.u32 16256, %v71089_v10 (stack47)
        %v71527_v45 = vor.u32 %v71526_v24, %v71525_v27 (stack47)
        %v71925_v50 = vxor.u32 %v71924_v55, %v71920_v23 (stack48)
        %v72329_v12 = vadd.s32 %v72325_v42, %v72313_v34 (stack40)
        %v72331_v53 = vshll.u32 %v72325_v42, 17 (stack45)
        %v72332_v7 = vshrl.u32 %v72325_v42, 15 (stack46)
        %v70350_v54 = vpack.c.bf16 %v157387_v11, %v70347_v21 (stack81)
        %v71091_v34 = vand.u32.u16 65535, %v71090_v22 (stack52)
        %v71528_v46 = vxor.u32 %v71527_v45, %v71519_v29 (stack48)
        %v72756_v40 = vshll.u32 %v142841_v61, 15 (stack45)
        %v71928_v31 = vadd.s32 %v71925_v50, %v71920_v23 (stack40)
        %v71930_v44 = vshll.u32 %v71925_v50, 26 (stack45)
        %v71931_v23 = vshrl.u32 %v71925_v50, 6 (stack46)
        %v72333_v41 = vor.u32 %v72332_v7, %v72331_v53 (stack47)
        %120119 = vst [vmem:[%s123356_s30 + $0x2c8] sm:$0xf] /*vst_source=*/%v70350_v54 (stack83)
        %v120122_v52 = vadd.low.f32.bf16 -1.0, %v71091_v34 (stack53)
        %v71523_v10 = vadd.s32 %v71519_v29, %v121569_v1 (stack40)
        %v71531_v29 = vadd.s32 %v71528_v46, %v121564_v0 (stack40)
        %v72757_v61 = vshrl.u32 %v142841_v61, 17 (stack46)
        %v121036_v27 = vpop.eup %121035 (stack73)
        %v71932_v24 = vor.u32 %v71931_v23, %v71930_v44 (stack47)
        %v72334_v20 = vxor.u32 %v72333_v41, %v72329_v12 (stack48)
        %vm73173_vm10 = vcmp.lt.u32.totalorder %v142829_v8, %v157083_v59 (stack43)
        %v73178_v55 = vadd.s32 %v157517_v43, %v157084_v16 (stack40)
        %v70720_v42 = vmul.f32 %v121036_v27, %v142838_v32 (stack74)
        %v71100_v21 = vmul.f32 2.0, %v120122_v52 (stack54)
        %v71535_v22 = vadd.s32 4, %v71531_v29 (stack40)
        %v72758_v45 = vor.u32 %v72757_v61, %v72756_v40 (stack47)
        %v71933_v50 = vxor.u32 %v71932_v24, %v71928_v31 (stack48)
        %v72337_v12 = vadd.s32 %v72334_v20, %v72329_v12 (stack40)
        %v72339_v53 = vshll.u32 %v72334_v20, 29 (stack45)
        %v72340_v7 = vshrl.u32 %v72334_v20, 3 (stack46)
        %v70722_v54 = vsel /*vm=*/%vm70721_vm7, /*on_true_vy=*/%v142838_v32, /*on_false_vx=*/%v70720_v42 (stack75)
        %v71104_v34 = vadd.f32 -0.99609375, %v71100_v21 (stack53)
        %v71539_v46 = vadd.s32 %v71535_v22, %v71523_v10 (stack40)
        %v71541_v40 = vshll.u32 %v71535_v22, 13 (stack45)
        %v70725_v60 = vsel /*vm=*/%vm70723_vm9, /*on_true_vy=*/%v70724_v60, /*on_false_vx=*/%v70722_v54 (stack76)
        %v71542_v44 = vshrl.u32 %v71535_v22, 19 (stack46)
        %v71936_v31 = vadd.s32 %v71933_v50, %v71928_v31 (stack40)
        %v71942_v23 = vshll.u32 %v71933_v50, 6 (stack45)
        %v70728_v41 = vadd.f32 -3.0, %v70725_v60 (stack53)
        %v142890_v52 = vmax.f32 %v71104_v34, -0.99609375 (stack55)
        %v71943_v10 = vshrl.u32 %v71933_v50, 26 (stack46)
        %v72341_v29 = vor.u32 %v72340_v7, %v72339_v53 (stack47)
        %v142895_v61 = vsel /*vm=*/%vm70676_vm8, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v142900_v27 = vsel /*vm=*/%vm70676_vm8, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v71543_v24 = vor.u32 %v71542_v44, %v71541_v40 (stack47)
        %v72759_v20 = vxor.u32 %v72758_v45, %v142869_v26 (stack48)
        %v70701_v42 = vsel /*vm=*/%vm70676_vm8, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v70713_v21 = vsel /*vm=*/%vm70676_vm8, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v142912_v9 = vsel /*vm=*/%vm70676_vm8, /*on_true_vy=*/%v142857_v9, /*on_false_vx=*/%v70728_v41 (stack44)
        %v71120_v22 = vxor.u32 2147483648, %v142890_v52 (stack56)
        %v70736_v45 = vmul.f32 %v142912_v9, %v70713_v21 (stack54)
        %v71544_v50 = vxor.u32 %v71543_v24, %v71539_v46 (stack48)
        %v71944_v53 = vor.u32 %v71943_v10, %v71942_v23 (stack47)
        %v72342_v7 = vxor.u32 %v72341_v29, %v72337_v12 (stack48)
        %v70705_v54 = vsel /*vm=*/%vm70676_vm8, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v70709_v34 = vsel /*vm=*/%vm70676_vm8, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v71123_v40 = vmul.f32 %v71120_v22, %v142890_v52 (stack54)
        %v142924_v26 = vadd.s32 %v72759_v20, %v142869_v26 (stack40)
        %v70740_v60 = vadd.f32 %v70736_v45, %v70709_v34 (stack53)
        %v71547_v46 = vadd.s32 %v71544_v50, %v71539_v46 (stack40)
        %v71549_v44 = vshll.u32 %v71544_v50, 15 (stack45)
        %v71550_v23 = vshrl.u32 %v71544_v50, 17 (stack46)
        %v71125_v41 = vadd.f32 1.0, %v71123_v40 (stack57)
        %v71940_v10 = vadd.s32 %v71936_v31, %v121574_v2 (stack40)
        %v71945_v31 = vxor.u32 %v71944_v53, %v71936_v31 (stack48)
        %vm73168_vm11 = vcmp.lt.u32.totalorder %v142861_v6, %v142829_v8 (stack43)
        %v70744_v29 = vmul.f32 %v70740_v60, %v142912_v9 (stack54)
        %v71551_v24 = vor.u32 %v71550_v23, %v71549_v44 (stack47)
        %v72345_v12 = vadd.s32 %v72342_v7, %v72337_v12 (stack40)
        %v73182_v21 = vadd.s32 1, %v73178_v55 (stack40)
        %121037 = vlog2.f32 %v71125_v41 (stack58)
        %v71948_v22 = vadd.s32 %v71945_v31, %v121569_v1 (stack40)
        %v72347_v45 = vshll.u32 %v72342_v7, 16 (stack45)
        %v72764_v50 = vshll.u32 %v72759_v20, 26 (stack45)
        %v70748_v53 = vadd.f32 %v70744_v29, %v70705_v54 (stack53)
        %v71552_v54 = vxor.u32 %v71551_v24, %v71547_v46 (stack48)
        %v72348_v7 = vshrl.u32 %v72342_v7, 16 (stack46)
        %v72765_v20 = vshrl.u32 %v72759_v20, 6 (stack46)
        %v71128_v34 = vmul.f32 -0.5, %v71123_v40 (stack59)
        %v71131_v60 = vand.u32 2147483647, %v71123_v40 (stack60)
        %v71952_v44 = vadd.s32 3, %v71948_v22 (stack40)
        %v73186_v55 = vsel /*vm=*/%vm73173_vm10, /*on_true_vy=*/%v73182_v21, /*on_false_vx=*/%v73178_v55 (stack44)
        %v70752_v23 = vmul.f32 %v70748_v53, %v142912_v9 (stack54)
        %v71555_v46 = vadd.s32 %v71552_v54, %v71547_v46 (stack40)
        %v71557_v41 = vshll.u32 %v71552_v54, 26 (stack45)
        %v71558_v31 = vshrl.u32 %v71552_v54, 6 (stack46)
        %v71956_v10 = vadd.s32 %v71952_v44, %v71940_v10 (stack40)
        %v71958_v29 = vshll.u32 %v71952_v44, 17 (stack45)
        %v71959_v24 = vshrl.u32 %v71952_v44, 15 (stack46)
        %v72349_v21 = vor.u32 %v72348_v7, %v72347_v45 (stack47)
        %v70756_v42 = vadd.f32 %v70752_v23, %v70701_v42 (stack53)
        %v71559_v22 = vor.u32 %v71558_v31, %v71557_v41 (stack47)
        %v72766_v45 = vor.u32 %v72765_v20, %v72764_v50 (stack47)
        %v73190_v50 = vadd.s32 1, %v73186_v55 (stack40)
        %v70697_v53 = vsel /*vm=*/%vm70676_vm8, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v71129_v54 = vadd.f32 1.0, %v71128_v34 (stack61)
        %v71960_v7 = vor.u32 %v71959_v24, %v71958_v29 (stack47)
        %v72350_v20 = vxor.u32 %v72349_v21, %v72345_v12 (stack48)
        %v70760_v34 = vmul.f32 %v70756_v42, %v142912_v9 (stack54)
        %vm142939_vm12 = vcmp.lt.f32.partialorder %v71131_v60, 0.0004427343 (stack62)
        %v71560_v44 = vxor.u32 %v71559_v22, %v71555_v46 (stack48)
        %v72767_v23 = vxor.u32 %v72766_v45, %v142924_v26 (stack48)
        %v73194_v8 = vsel /*vm=*/%vm73168_vm11, /*on_true_vy=*/%v73190_v50, /*on_false_vx=*/%v73186_v55 (stack44)
        %v71961_v55 = vxor.u32 %v71960_v7, %v71956_v10 (stack48)
        %v72353_v12 = vadd.s32 %v72350_v20, %v72345_v12 (stack40)
        %v72359_v41 = vshll.u32 %v72350_v20, 24 (stack45)
        %v72360_v31 = vshrl.u32 %v72350_v20, 8 (stack46)
        %v70764_v29 = vadd.f32 %v70760_v34, %v70697_v53 (stack53)
        %v71563_v46 = vadd.s32 %v71560_v44, %v71555_v46 (stack40)
        %v71569_v24 = vshll.u32 %v71560_v44, 6 (stack45)
        %v71570_v21 = vshrl.u32 %v71560_v44, 26 (stack46)
        %v71964_v10 = vadd.s32 %v71961_v55, %v71956_v10 (stack40)
        %v71966_v42 = vshll.u32 %v71961_v55, 29 (stack45)
        %v71967_v22 = vshrl.u32 %v71961_v55, 3 (stack46)
        %v73203_v6 = vadd.s32 %v142861_v6, %v121569_v1 (stack40)
        %v70768_v45 = vmul.f32 %v70764_v29, %v142912_v9 (stack54)
        %v71130_v40 = vmul.f32 %v71129_v54, %v71123_v40 (stack63)
        %v71571_v50 = vor.u32 %v71570_v21, %v71569_v24 (stack47)
        %v72361_v53 = vor.u32 %v72360_v31, %v72359_v41 (stack47)
        %v71968_v54 = vor.u32 %v71967_v22, %v71966_v42 (stack47)
        %v72770_v26 = vadd.s32 %v72767_v23, %v142924_v26 (stack40)
        %v72776_v7 = vshll.u32 %v72767_v23, 6 (stack45)
        %v72777_v20 = vshrl.u32 %v72767_v23, 26 (stack46)
        %v121038_v34 = vpop.eup %121037 (stack64)
        %v70772_v27 = vadd.f32 %v70768_v45, %v142900_v27 (stack53)
        %v71572_v44 = vxor.u32 %v71571_v50, %v71563_v46 (stack48)
        %v72362_v23 = vxor.u32 %v72361_v53, %v72353_v12 (stack48)
        %v73199_v8 = vadd.s32 %v73194_v8, %v121574_v2 (stack40)
        %v71127_v55 = vmul.f32 0.6931472, %v121038_v34 (stack65)
        %v71969_v41 = vxor.u32 %v71968_v54, %v71964_v10 (stack48)
        %v72778_v31 = vor.u32 %v72777_v20, %v72776_v7 (stack47)
        %v73209_v29 = vshll.u32 %v73203_v6, 13 (stack45)
        %v70776_v24 = vmul.f32 %v70772_v27, %v142912_v9 (stack54)
        %v71575_v21 = vadd.s32 %v71572_v44, %v121574_v2 (stack40)
        %v73207_v42 = vadd.s32 %v73203_v6, %v73199_v8 (stack40)
        %v73210_v22 = vshrl.u32 %v73203_v6, 19 (stack46)
        %v71133_v60 = vsel /*vm=*/%vm142939_vm12, /*on_true_vy=*/%v71130_v40, /*on_false_vx=*/%v71127_v55 (stack66)
        %v71972_v10 = vadd.s32 %v71969_v41, %v71964_v10 (stack40)
        %v71974_v6 = vshll.u32 %v71969_v41, 16 (stack45)
        %v71975_v45 = vshrl.u32 %v71969_v41, 16 (stack46)
        %v70780_v61 = vadd.f32 %v70776_v24, %v142895_v61 (stack53)
        %v142958_v40 = vxor.u32 2147483648, %v71133_v60 (stack56)
        %v71579_v50 = vadd.s32 5, %v71575_v21 (stack40)
        %v72365_v53 = vadd.s32 %v72362_v23, %v121574_v2 (stack40)
        %v71567_v46 = vadd.s32 %v71563_v46, %v121564_v0 (stack40)
        %v71976_v54 = vor.u32 %v71975_v45, %v71974_v6 (stack47)
        %v72779_v7 = vxor.u32 %v72778_v31, %v72770_v26 (stack48)
        %v142964_v20 = vadd.s32 %v157514_v25, %v157089_v17 (stack40)
        %v70657_v34 = vmul.f32 inf, %v142780_v30 (stack54)
        %v70784_v27 = vmul.f32 %v70780_v61, %v142912_v9 (stack54)
        %121039 = vrsqrt.f32 %v142958_v40 (stack67)
        %vm142971_vm13 = vcmp.eq.f32.partialorder %v70649_v56, 1.0 (stack68)
        %v70681_v44 = vsel /*vm=*/%vm70676_vm8, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v70685_v32 = vsel /*vm=*/%vm70676_vm8, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %vm71137_vm14 = vcmp.lt.f32.partialorder %v142958_v40, 5.0 (stack68)
        %v71581_v23 = vxor.u32 %v71579_v50, %v71567_v46 (stack48)
        %v70788_v8 = vadd.f32 %v70784_v27, %v70685_v32 (stack53)
        %v71110_v55 = vand.u32 2147483647, %v142890_v52 (stack77)
        %v72357_v12 = vadd.s32 %v72353_v12, %v121564_v0 (stack40)
        %v72369_v41 = vadd.s32 2, %v72365_v53 (stack40)
        %v142985_v31 = vadd.f32 -2.5, %v142958_v40 (stack53)
        %v71977_v24 = vxor.u32 %v71976_v54, %v71972_v10 (stack48)
        %v72774_v26 = vadd.s32 %v72770_v26, %v121569_v1 (stack40)
        %v73211_v29 = vor.u32 %v73210_v22, %v73209_v29 (stack47)
        %v70792_v9 = vmul.f32 %v70788_v8, %v142912_v9 (stack54)
        %v142992_v21 = vsel /*vm=*/%vm71137_vm14, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v142997_v22 = vsel /*vm=*/%vm71137_vm14, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v143002_v60 = vsel /*vm=*/%vm71137_vm14, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v71582_v6 = vand.u32.u8 255, %v71581_v23 (stack49)
        %v71980_v10 = vadd.s32 %v71977_v24, %v71972_v10 (stack40)
        %v71986_v45 = vshll.u32 %v71977_v24, 24 (stack45)
        %v71987_v61 = vshrl.u32 %v71977_v24, 8 (stack46)
        %v70796_v50 = vadd.f32 %v70792_v9, %v70681_v44 (stack53)
        %v72373_v53 = vadd.s32 %v72369_v41, %v72357_v12 (stack40)
        %v72375_v46 = vshll.u32 %v72369_v41, 13 (stack45)
        %v72376_v54 = vshrl.u32 %v72369_v41, 19 (stack46)
        %vm71182_vm15 = vcmp.eq.f32.partialorder %v142958_v40, inf (stack70)
        %v71583_v27 = vand.u32 65535, %v71582_v6 (stack50)
        %v71988_v44 = vor.u32 %v71987_v61, %v71986_v45 (stack47)
        %v72782_v7 = vadd.s32 %v72779_v7, %v121564_v0 (stack40)
        %v70800_v30 = vmul.f32 %v70796_v50, %v142780_v30 (stack54)
        %vm71184_vm0 = vcmp.eq.f32.partialorder %v142958_v40, 0.0 (stack71)
        %v71984_v32 = vadd.s32 %v71980_v10, %v121569_v1 (stack40)
        %v72377_v23 = vor.u32 %v72376_v54, %v72375_v46 (stack47)
        %v73212_v8 = vxor.u32 %v73211_v29, %v73207_v42 (stack48)
        %v71584_v12 = vshrl.u32 %v71583_v27, 1 (stack51)
        %v71989_v41 = vxor.u32 %v71988_v44, %v71980_v10 (stack48)
        %v72786_v24 = vadd.s32 1, %v72782_v7 (stack40)
        %vm73634_vm1 = vcmp.lt.u32.totalorder %v142964_v20, %v157089_v17 (stack43)
        %v70804_v34 = vsel /*vm=*/%vm142971_vm13, /*on_true_vy=*/%v70657_v34, /*on_false_vx=*/%v70800_v30 (stack44)
        %v72378_v56 = vxor.u32 %v72377_v23, %v72373_v53 (stack48)
        %v143013_v42 = vadd.s32 %v73212_v8, %v73207_v42 (stack40)
        %v73217_v29 = vshll.u32 %v73212_v8, 15 (stack45)
        %v70808_v9 = vmul.f32 1.4140625, %v70804_v34 (stack54)
        %v71585_v6 = vor.u32 16256, %v71584_v12 (stack47)
        %v71992_v10 = vadd.s32 %v71989_v41, %v121564_v0 (stack40)
        %v72790_v26 = vadd.s32 %v72786_v24, %v72774_v26 (stack40)
        %v72381_v45 = vadd.s32 %v72378_v56, %v72373_v53 (stack40)
        %v72383_v61 = vshll.u32 %v72378_v56, 15 (stack45)
        %v72384_v50 = vshrl.u32 %v72378_v56, 17 (stack46)
        %v72792_v53 = vshll.u32 %v72786_v24, 17 (stack45)
        %v121040_v46 = vpop.eup %121039 (stack73)
        %v70811_v54 = vpack.c.bf16 %v157387_v11, %v70808_v9 (stack81)
        %v71586_v27 = vand.u32.u16 65535, %v71585_v6 (stack52)
        %v71996_v44 = vadd.s32 4, %v71992_v10 (stack40)
        %v72793_v7 = vshrl.u32 %v72786_v24, 15 (stack46)
        %v71181_v30 = vmul.f32 %v121040_v46, %v142958_v40 (stack74)
        %v71185_v23 = vand.u32 2147483648, %v142958_v40 (stack72)
        %v72385_v12 = vor.u32 %v72384_v50, %v72383_v61 (stack47)
        %v73218_v8 = vshrl.u32 %v73212_v8, 17 (stack46)
        %120121 = vst [vmem:[%s123356_s30 + $0x348] sm:$0xf] /*vst_source=*/%v70811_v54 (stack83)
        %v120128_v41 = vadd.low.f32.bf16 -1.0, %v71586_v27 (stack53)
        %v72000_v32 = vadd.s32 %v71996_v44, %v71984_v32 (stack40)
        %v72002_v24 = vshll.u32 %v71996_v44, 13 (stack45)
        %v72003_v34 = vshrl.u32 %v71996_v44, 19 (stack46)
        %v71183_v56 = vsel /*vm=*/%vm71182_vm15, /*on_true_vy=*/%v142958_v40, /*on_false_vx=*/%v71181_v30 (stack75)
        %v72386_v9 = vxor.u32 %v72385_v12, %v72381_v45 (stack48)
        %v72794_v6 = vor.u32 %v72793_v7, %v72792_v53 (stack47)
        %v73219_v29 = vor.u32 %v73218_v8, %v73217_v29 (stack47)
        %v71186_v10 = vsel /*vm=*/%vm71184_vm0, /*on_true_vy=*/%v71185_v23, /*on_false_vx=*/%v71183_v56 (stack76)
        %v71595_v61 = vmul.f32 2.0, %v120128_v41 (stack54)
        %v72004_v50 = vor.u32 %v72003_v34, %v72002_v24 (stack47)
        %v73639_v53 = vadd.s32 %v157517_v43, %v157090_v62 (stack40)
        %v71189_v46 = vadd.f32 -3.0, %v71186_v10 (stack53)
        %v72389_v45 = vadd.s32 %v72386_v9, %v72381_v45 (stack40)
        %v72391_v54 = vshll.u32 %v72386_v9, 26 (stack45)
        %v72392_v27 = vshrl.u32 %v72386_v9, 6 (stack46)
        %v71599_v44 = vadd.f32 -0.99609375, %v71595_v61 (stack53)
        %v72005_v7 = vxor.u32 %v72004_v50, %v72000_v32 (stack48)
        %v72795_v30 = vxor.u32 %v72794_v6, %v72790_v26 (stack48)
        %v73220_v23 = vxor.u32 %v73219_v29, %v143013_v42 (stack48)
        %v71170_v12 = vsel /*vm=*/%vm71137_vm14, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v71174_v8 = vsel /*vm=*/%vm71137_vm14, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v143037_v31 = vsel /*vm=*/%vm71137_vm14, /*on_true_vy=*/%v142985_v31, /*on_false_vx=*/%v71189_v46 (stack44)
        %v72393_v41 = vor.u32 %v72392_v27, %v72391_v54 (stack47)
        %v71197_v24 = vmul.f32 %v143037_v31, %v71174_v8 (stack54)
        %v143040_v34 = vmax.f32 %v71599_v44, -0.99609375 (stack55)
        %v72008_v32 = vadd.s32 %v72005_v7, %v72000_v32 (stack40)
        %v72010_v56 = vshll.u32 %v72005_v7, 15 (stack45)
        %v72011_v9 = vshrl.u32 %v72005_v7, 17 (stack46)
        %v72394_v6 = vxor.u32 %v72393_v41, %v72389_v45 (stack48)
        %v72798_v26 = vadd.s32 %v72795_v30, %v72790_v26 (stack40)
        %v143044_v29 = vadd.s32 %v142964_v20, %v122657_v58 (stack40)
        %v71162_v10 = vsel /*vm=*/%vm71137_vm14, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v71166_v61 = vsel /*vm=*/%vm71137_vm14, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v71201_v50 = vadd.f32 %v71197_v24, %v71170_v12 (stack53)
        %v71615_v46 = vxor.u32 2147483648, %v143040_v34 (stack56)
        %v72012_v54 = vor.u32 %v72011_v9, %v72010_v56 (stack47)
        %v72397_v45 = vadd.s32 %v72394_v6, %v72389_v45 (stack40)
        %v72403_v27 = vshll.u32 %v72394_v6, 6 (stack45)
        %v72404_v44 = vshrl.u32 %v72394_v6, 26 (stack46)
        %v71205_v7 = vmul.f32 %v71201_v50, %v143037_v31 (stack54)
        %v143055_v12 = vmul.f32 %v71615_v46, %v143040_v34 (stack54)
        %v72800_v8 = vshll.u32 %v72795_v30, 29 (stack45)
        %v73643_v41 = vadd.s32 1, %v73639_v53 (stack40)
        %v72013_v24 = vxor.u32 %v72012_v54, %v72008_v32 (stack48)
        %v72405_v56 = vor.u32 %v72404_v44, %v72403_v27 (stack47)
        %v72801_v30 = vshrl.u32 %v72795_v30, 3 (stack46)
        %v73223_v42 = vadd.s32 %v73220_v23, %v143013_v42 (stack40)
        %vm73629_vm2 = vcmp.lt.u32.totalorder %v143044_v29, %v142964_v20 (stack43)
        %v71209_v9 = vadd.f32 %v71205_v7, %v71166_v61 (stack53)
        %v71620_v6 = vadd.f32 1.0, %v143055_v12 (stack57)
        %v71623_v61 = vmul.f32 -0.5, %v143055_v12 (stack59)
        %v73664_v50 = vadd.s32 %v143044_v29, %v121569_v1 (stack40)
        %v72016_v32 = vadd.s32 %v72013_v24, %v72008_v32 (stack40)
        %v72018_v46 = vshll.u32 %v72013_v24, 26 (stack45)
        %v72019_v54 = vshrl.u32 %v72013_v24, 6 (stack46)
        %v72406_v27 = vxor.u32 %v72405_v56, %v72397_v45 (stack48)
        %v71213_v44 = vmul.f32 %v71209_v9, %v143037_v31 (stack54)
        %121041 = vlog2.f32 %v71620_v6 (stack58)
        %v71626_v7 = vand.u32 2147483647, %v143055_v12 (stack60)
        %v72401_v45 = vadd.s32 %v72397_v45, %v121574_v2 (stack40)
        %v72020_v24 = vor.u32 %v72019_v54, %v72018_v46 (stack47)
        %v72409_v56 = vadd.s32 %v72406_v27, %v121569_v1 (stack40)
        %v72802_v8 = vor.u32 %v72801_v30, %v72800_v8 (stack47)
        %v73225_v30 = vshll.u32 %v73220_v23, 26 (stack45)
        %v71217_v10 = vadd.f32 %v71213_v44, %v71162_v10 (stack53)
        %v71624_v9 = vadd.f32 1.0, %v71623_v61 (stack61)
        %v73226_v23 = vshrl.u32 %v73220_v23, 6 (stack46)
        %v73647_v53 = vsel /*vm=*/%vm73634_vm1, /*on_true_vy=*/%v73643_v41, /*on_false_vx=*/%v73639_v53 (stack44)
        %v72021_v41 = vxor.u32 %v72020_v24, %v72016_v32 (stack48)
        %v72413_v6 = vadd.s32 3, %v72409_v56 (stack40)
        %v72803_v61 = vxor.u32 %v72802_v8, %v72798_v26 (stack48)
        %v73651_v46 = vadd.s32 1, %v73647_v53 (stack40)
        %v71221_v54 = vmul.f32 %v71217_v10, %v143037_v31 (stack54)
        %v73227_v27 = vor.u32 %v73226_v23, %v73225_v30 (stack47)
        %v73670_v44 = vshll.u32 %v73664_v50, 13 (stack45)
        %v73671_v24 = vshrl.u32 %v73664_v50, 19 (stack46)
        %v72024_v32 = vadd.s32 %v72021_v41, %v72016_v32 (stack40)
        %v72030_v56 = vshll.u32 %v72021_v41, 6 (stack45)
        %v72031_v8 = vshrl.u32 %v72021_v41, 26 (stack46)
        %v72417_v45 = vadd.s32 %v72413_v6, %v72401_v45 (stack40)
        %v71225_v60 = vadd.f32 %v71221_v54, %v143002_v60 (stack53)
        %v72419_v30 = vshll.u32 %v72413_v6, 17 (stack45)
        %v72420_v10 = vshrl.u32 %v72413_v6, 15 (stack46)
        %v72806_v26 = vadd.s32 %v72803_v61, %v72798_v26 (stack40)
        %v72028_v23 = vadd.s32 %v72024_v32, %v121564_v0 (stack40)
        %v72032_v41 = vor.u32 %v72031_v8, %v72030_v56 (stack47)
        %v72808_v6 = vshll.u32 %v72803_v61, 16 (stack45)
        %v72809_v61 = vshrl.u32 %v72803_v61, 16 (stack46)
        %v71229_v54 = vmul.f32 %v71225_v60, %v143037_v31 (stack54)
        %v72421_v56 = vor.u32 %v72420_v10, %v72419_v30 (stack47)
        %v73228_v27 = vxor.u32 %v73227_v27, %v73223_v42 (stack48)
        %v73655_v20 = vsel /*vm=*/%vm73629_vm2, /*on_true_vy=*/%v73651_v46, /*on_false_vx=*/%v73647_v53 (stack44)
        %v72033_v29 = vxor.u32 %v72032_v41, %v72024_v32 (stack48)
        %v72810_v53 = vor.u32 %v72809_v61, %v72808_v6 (stack47)
        %v73660_v46 = vadd.s32 %v73655_v20, %v121574_v2 (stack40)
        %v73672_v44 = vor.u32 %v73671_v24, %v73670_v44 (stack47)
        %v71233_v22 = vadd.f32 %v71229_v54, %v142997_v22 (stack53)
        %v72422_v24 = vxor.u32 %v72421_v56, %v72417_v45 (stack48)
        %v73231_v42 = vadd.s32 %v73228_v27, %v73223_v42 (stack40)
        %v73237_v32 = vshll.u32 %v73228_v27, 6 (stack45)
        %v72036_v8 = vadd.s32 %v72033_v29, %v121574_v2 (stack40)
        %v72811_v60 = vxor.u32 %v72810_v53, %v72806_v26 (stack48)
        %v73238_v30 = vshrl.u32 %v73228_v27, 26 (stack46)
        %v73668_v50 = vadd.s32 %v73664_v50, %v73660_v46 (stack40)
        %v71237_v10 = vmul.f32 %v71233_v22, %v143037_v31 (stack54)
        %v72425_v45 = vadd.s32 %v72422_v24, %v72417_v45 (stack40)
        %v72427_v41 = vshll.u32 %v72422_v24, 29 (stack45)
        %v72428_v6 = vshrl.u32 %v72422_v24, 3 (stack46)
        %v121042_v61 = vpop.eup %121041 (stack64)
        %v72040_v54 = vadd.s32 5, %v72036_v8 (stack40)
        %v72814_v26 = vadd.s32 %v72811_v60, %v72806_v26 (stack40)
        %v72820_v56 = vshll.u32 %v72811_v60, 24 (stack45)
        %v72821_v27 = vshrl.u32 %v72811_v60, 8 (stack46)
        %v71241_v21 = vadd.f32 %v71237_v10, %v142992_v21 (stack53)
        %v71622_v20 = vmul.f32 0.6931472, %v121042_v61 (stack65)
        %v71625_v12 = vmul.f32 %v71624_v9, %v143055_v12 (stack63)
        %v72429_v9 = vor.u32 %v72428_v6, %v72427_v41 (stack47)
        %vm71627_vm3 = vcmp.lt.f32.partialorder %v71626_v7, 0.0004427343 (stack62)
        %v72042_v7 = vxor.u32 %v72040_v54, %v72028_v23 (stack48)
        %v72822_v23 = vor.u32 %v72821_v27, %v72820_v56 (stack47)
        %v73239_v29 = vor.u32 %v73238_v30, %v73237_v32 (stack47)
        %v71245_v53 = vmul.f32 %v71241_v21, %v143037_v31 (stack54)
        %v71628_v46 = vsel /*vm=*/%vm71627_vm3, /*on_true_vy=*/%v71625_v12, /*on_false_vx=*/%v71622_v20 (stack66)
        %v72430_v22 = vxor.u32 %v72429_v9, %v72425_v45 (stack48)
        %v143085_v44 = vxor.u32 %v73672_v44, %v73668_v50 (stack48)
        %v71146_v24 = vsel /*vm=*/%vm71137_vm14, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v143090_v32 = vxor.u32 2147483648, %v71628_v46 (stack56)
        %v72823_v8 = vxor.u32 %v72822_v23, %v72814_v26 (stack48)
        %v73240_v60 = vxor.u32 %v73239_v29, %v73231_v42 (stack48)
        %v71249_v30 = vadd.f32 %v71245_v53, %v71146_v24 (stack53)
        %v72433_v10 = vadd.s32 %v72430_v22, %v72425_v45 (stack40)
        %v72435_v45 = vshll.u32 %v72430_v22, 16 (stack45)
        %v72436_v41 = vshrl.u32 %v72430_v22, 16 (stack46)
        %121043 = vrsqrt.f32 %v143090_v32 (stack67)
        %v72043_v6 = vand.u32.u8 255, %v72042_v7 (stack49)
        %v71253_v31 = vmul.f32 %v71249_v30, %v143037_v31 (stack54)
        %v71118_v61 = vmul.f32 inf, %v142890_v52 (stack54)
        %v71142_v40 = vsel /*vm=*/%vm71137_vm14, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v72437_v54 = vor.u32 %v72436_v41, %v72435_v45 (stack47)
        %vm143100_vm4 = vcmp.eq.f32.partialorder %v71110_v55, 1.0 (stack68)
        %v71257_v56 = vadd.f32 %v71253_v31, %v71142_v40 (stack53)
        %v71605_v27 = vand.u32 2147483647, %v143040_v34 (stack77)
        %v73235_v42 = vadd.s32 %v73231_v42, %v121569_v1 (stack40)
        %v143107_v21 = vadd.f32 -2.5, %v143090_v32 (stack53)
        %v72044_v20 = vand.u32 65535, %v72043_v6 (stack50)
        %v72438_v12 = vxor.u32 %v72437_v54, %v72433_v10 (stack48)
        %v72818_v26 = vadd.s32 %v72814_v26, %v121564_v0 (stack40)
        %v71261_v52 = vmul.f32 %v71257_v56, %v142890_v52 (stack54)
        %v72826_v9 = vadd.s32 %v72823_v8, %v121574_v2 (stack40)
        %v73243_v7 = vadd.s32 %v73240_v60, %v121564_v0 (stack40)
        %v143114_v50 = vadd.s32 %v143085_v44, %v73668_v50 (stack40)
        %v72045_v23 = vshrl.u32 %v72044_v20, 1 (stack51)
        %v72441_v29 = vadd.s32 %v72438_v12, %v72433_v10 (stack40)
        %v72447_v53 = vshll.u32 %v72438_v12, 24 (stack45)
        %v72448_v46 = vshrl.u32 %v72438_v12, 8 (stack46)
        %v71265_v22 = vsel /*vm=*/%vm143100_vm4, /*on_true_vy=*/%v71118_v61, /*on_false_vx=*/%v71261_v52 (stack44)
        %vm71677_vm5 = vcmp.eq.f32.partialorder %v143090_v32, inf (stack70)
        %v71680_v24 = vand.u32 2147483648, %v143090_v32 (stack72)
        %v72830_v8 = vadd.s32 2, %v72826_v9 (stack40)
        %v73247_v60 = vadd.s32 1, %v73243_v7 (stack40)
        %v71269_v30 = vmul.f32 1.4140625, %v71265_v22 (stack54)
        %vm71632_vm6 = vcmp.lt.f32.partialorder %v143090_v32, 5.0 (stack68)
        %vm71679_vm7 = vcmp.eq.f32.partialorder %v143090_v32, 0.0 (stack71)
        %v72046_v10 = vor.u32 16256, %v72045_v23 (stack47)
        %v72449_v45 = vor.u32 %v72448_v46, %v72447_v53 (stack47)
        %v73678_v41 = vshll.u32 %v143085_v44, 15 (stack45)
        %v72834_v6 = vadd.s32 %v72830_v8, %v72818_v26 (stack40)
        %v72836_v31 = vshll.u32 %v72830_v8, 13 (stack45)
        %v72837_v61 = vshrl.u32 %v72830_v8, 19 (stack46)
        %v73251_v40 = vadd.s32 %v73247_v60, %v73235_v42 (stack40)
        %v71272_v54 = vpack.c.bf16 %v157387_v11, %v71269_v30 (stack81)
        %v72047_v55 = vand.u32.u16 65535, %v72046_v10 (stack52)
        %v72450_v56 = vxor.u32 %v72449_v45, %v72441_v29 (stack48)
        %v73253_v42 = vshll.u32 %v73247_v60, 17 (stack45)
        %v72838_v20 = vor.u32 %v72837_v61, %v72836_v31 (stack47)
        %v73254_v12 = vshrl.u32 %v73247_v60, 15 (stack46)
        %v73679_v44 = vshrl.u32 %v143085_v44, 17 (stack46)
        %v143127_v26 = vadd.s32 %v157514_v25, %v157091_v37 (stack40)
        %120123 = vst [vmem:[%s123356_s30 + $0x3c8] sm:$0xf] /*vst_source=*/%v71272_v54 (stack83)
        %v120130_v52 = vadd.low.f32.bf16 -1.0, %v72047_v55 (stack53)
        %v72453_v9 = vadd.s32 %v72450_v56, %v121564_v0 (stack40)
        %v143133_v7 = vadd.s32 %v157517_v43, %v157094_v36 (stack40)
        %v143137_v25 = vadd.s32 %v157514_v25, %v157095_v13 (stack40)
        %v121044_v23 = vpop.eup %121043 (stack73)
        %v72445_v29 = vadd.s32 %v72441_v29, %v121569_v1 (stack40)
        %v72839_v53 = vxor.u32 %v72838_v20, %v72834_v6 (stack48)
        %v73255_v46 = vor.u32 %v73254_v12, %v73253_v42 (stack47)
        %v73680_v22 = vor.u32 %v73679_v44, %v73678_v41 (stack47)
        %v71676_v8 = vmul.f32 %v121044_v23, %v143090_v32 (stack74)
        %v72056_v60 = vmul.f32 2.0, %v120130_v52 (stack54)
        %v72457_v30 = vadd.s32 4, %v72453_v9 (stack40)
        %vm74095_vm8 = vcmp.lt.u32.totalorder %v143127_v26, %v157091_v37 (stack43)
        %v72842_v10 = vadd.s32 %v72839_v53, %v72834_v6 (stack40)
        %v72844_v45 = vshll.u32 %v72839_v53, 15 (stack45)
        %v72845_v41 = vshrl.u32 %v72839_v53, 17 (stack46)
        %v73256_v6 = vxor.u32 %v73255_v46, %v73251_v40 (stack48)
        %v71678_v31 = vsel /*vm=*/%vm71677_vm5, /*on_true_vy=*/%v143090_v32, /*on_false_vx=*/%v71676_v8 (stack75)
        %v72060_v61 = vadd.f32 -0.99609375, %v72056_v60 (stack53)
        %v72461_v54 = vadd.s32 %v72457_v30, %v72445_v29 (stack40)
        %v72463_v55 = vshll.u32 %v72457_v30, 13 (stack45)
        %v71681_v24 = vsel /*vm=*/%vm71679_vm7, /*on_true_vy=*/%v71680_v24, /*on_false_vx=*/%v71678_v31 (stack76)
        %v72464_v56 = vshrl.u32 %v72457_v30, 19 (stack46)
        %v72846_v42 = vor.u32 %v72845_v41, %v72844_v45 (stack47)
        %v73259_v40 = vadd.s32 %v73256_v6, %v73251_v40 (stack40)
        %v71684_v20 = vadd.f32 -3.0, %v71681_v24 (stack53)
        %v143148_v12 = vmax.f32 %v72060_v61, -0.99609375 (stack55)
        %v73261_v44 = vshll.u32 %v73256_v6, 29 (stack45)
        %v73262_v52 = vshrl.u32 %v73256_v6, 3 (stack46)
        %v143153_v9 = vsel /*vm=*/%vm71632_vm6, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v72465_v23 = vor.u32 %v72464_v56, %v72463_v55 (stack47)
        %v72847_v29 = vxor.u32 %v72846_v42, %v72842_v10 (stack48)
        %v73681_v53 = vxor.u32 %v73680_v22, %v143114_v50 (stack48)
        %v143159_v46 = vsel /*vm=*/%vm71632_vm6, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v71669_v22 = vsel /*vm=*/%vm71632_vm6, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v143167_v21 = vsel /*vm=*/%vm71632_vm6, /*on_true_vy=*/%v143107_v21, /*on_false_vx=*/%v71684_v20 (stack44)
        %v72076_v8 = vxor.u32 2147483648, %v143148_v12 (stack56)
        %v71692_v60 = vmul.f32 %v143167_v21, %v71669_v22 (stack54)
        %v72466_v30 = vxor.u32 %v72465_v23, %v72461_v54 (stack48)
        %v72850_v10 = vadd.s32 %v72847_v29, %v72842_v10 (stack40)
        %v72852_v45 = vshll.u32 %v72847_v29, 26 (stack45)
        %v71665_v41 = vsel /*vm=*/%vm71632_vm6, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v72079_v6 = vmul.f32 %v72076_v8, %v143148_v12 (stack54)
        %v72853_v31 = vshrl.u32 %v72847_v29, 6 (stack46)
        %v73263_v61 = vor.u32 %v73262_v52, %v73261_v44 (stack47)
        %v71696_v55 = vadd.f32 %v71692_v60, %v71665_v41 (stack53)
        %v72469_v54 = vadd.s32 %v72466_v30, %v72461_v54 (stack40)
        %v72471_v24 = vshll.u32 %v72466_v30, 15 (stack45)
        %v72472_v56 = vshrl.u32 %v72466_v30, 17 (stack46)
        %v71653_v42 = vsel /*vm=*/%vm71632_vm6, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v71657_v20 = vsel /*vm=*/%vm71632_vm6, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v72081_v44 = vadd.f32 1.0, %v72079_v6 (stack57)
        %v72854_v52 = vor.u32 %v72853_v31, %v72852_v45 (stack47)
        %v71700_v23 = vmul.f32 %v71696_v55, %v143167_v21 (stack54)
        %v72473_v29 = vor.u32 %v72472_v56, %v72471_v24 (stack47)
        %v73264_v22 = vxor.u32 %v73263_v61, %v73259_v40 (stack48)
        %v73684_v50 = vadd.s32 %v73681_v53, %v143114_v50 (stack40)
        %v71661_v8 = vsel /*vm=*/%vm71632_vm6, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %121045 = vlog2.f32 %v72081_v44 (stack58)
        %v72855_v60 = vxor.u32 %v72854_v52, %v72850_v10 (stack48)
        %v143188_v30 = vadd.s32 %v143127_v26, %v122657_v58 (stack40)
        %v71704_v45 = vadd.f32 %v71700_v23, %v71661_v8 (stack53)
        %v72084_v41 = vmul.f32 -0.5, %v72079_v6 (stack59)
        %v72474_v31 = vxor.u32 %v72473_v29, %v72469_v54 (stack48)
        %v73267_v40 = vadd.s32 %v73264_v22, %v73259_v40 (stack40)
        %v72858_v10 = vadd.s32 %v72855_v60, %v72850_v10 (stack40)
        %v72864_v61 = vshll.u32 %v72855_v60, 6 (stack45)
        %v72865_v55 = vshrl.u32 %v72855_v60, 26 (stack46)
        %v73269_v24 = vshll.u32 %v73264_v22, 16 (stack45)
        %v71708_v56 = vmul.f32 %v71704_v45, %v143167_v21 (stack54)
        %v72477_v54 = vadd.s32 %v72474_v31, %v72469_v54 (stack40)
        %v72479_v44 = vshll.u32 %v72474_v31, 26 (stack45)
        %v72480_v52 = vshrl.u32 %v72474_v31, 6 (stack46)
        %v72087_v23 = vand.u32 2147483647, %v72079_v6 (stack60)
        %v72866_v29 = vor.u32 %v72865_v55, %v72864_v61 (stack47)
        %v73270_v22 = vshrl.u32 %v73264_v22, 16 (stack46)
        %v73686_v8 = vshll.u32 %v73681_v53, 26 (stack45)
        %v71712_v20 = vadd.f32 %v71708_v56, %v71657_v20 (stack53)
        %v72481_v60 = vor.u32 %v72480_v52, %v72479_v44 (stack47)
        %v73687_v53 = vshrl.u32 %v73681_v53, 6 (stack46)
        %v74104_v45 = vadd.s32 1, %v143133_v7 (stack40)
        %v72085_v41 = vadd.f32 1.0, %v72084_v41 (stack61)
        %v72867_v31 = vxor.u32 %v72866_v29, %v72858_v10 (stack48)
        %v73271_v61 = vor.u32 %v73270_v22, %v73269_v24 (stack47)
        %vm74090_vm9 = vcmp.lt.u32.totalorder %v143188_v30, %v143127_v26 (stack43)
        %v71716_v55 = vmul.f32 %v71712_v20, %v143167_v21 (stack54)
        %v72482_v24 = vxor.u32 %v72481_v60, %v72477_v54 (stack48)
        %v73688_v56 = vor.u32 %v73687_v53, %v73686_v8 (stack47)
        %v74108_v7 = vsel /*vm=*/%vm74095_vm8, /*on_true_vy=*/%v74104_v45, /*on_false_vx=*/%v143133_v7 (stack44)
        %vm143199_vm10 = vcmp.lt.f32.partialorder %v72087_v23, 0.0004427343 (stack62)
        %v72862_v10 = vadd.s32 %v72858_v10, %v121574_v2 (stack40)
        %v72870_v52 = vadd.s32 %v72867_v31, %v121569_v1 (stack40)
        %v73272_v23 = vxor.u32 %v73271_v61, %v73267_v40 (stack48)
        %v71720_v42 = vadd.f32 %v71716_v55, %v71653_v42 (stack53)
        %v72485_v54 = vadd.s32 %v72482_v24, %v72477_v54 (stack40)
        %v72491_v29 = vshll.u32 %v72482_v24, 6 (stack45)
        %v72492_v22 = vshrl.u32 %v72482_v24, 26 (stack46)
        %v72874_v8 = vadd.s32 3, %v72870_v52 (stack40)
        %v73275_v40 = vadd.s32 %v73272_v23, %v73267_v40 (stack40)
        %v73281_v20 = vshll.u32 %v73272_v23, 24 (stack45)
        %v73282_v60 = vshrl.u32 %v73272_v23, 8 (stack46)
        %v71724_v53 = vmul.f32 %v71720_v42, %v143167_v21 (stack54)
        %v72086_v6 = vmul.f32 %v72085_v41, %v72079_v6 (stack63)
        %v72493_v45 = vor.u32 %v72492_v22, %v72491_v29 (stack47)
        %v73689_v41 = vxor.u32 %v73688_v56, %v73684_v50 (stack48)
        %v72878_v31 = vadd.s32 %v72874_v8, %v72862_v10 (stack40)
        %v72880_v61 = vshll.u32 %v72874_v8, 17 (stack45)
        %v72881_v55 = vshrl.u32 %v72874_v8, 15 (stack46)
        %v74112_v24 = vadd.s32 1, %v74108_v7 (stack40)
        %v121046_v56 = vpop.eup %121045 (stack64)
        %v71728_v46 = vadd.f32 %v71724_v53, %v143159_v46 (stack53)
        %v72494_v10 = vxor.u32 %v72493_v45, %v72485_v54 (stack48)
        %v73283_v52 = vor.u32 %v73282_v60, %v73281_v20 (stack47)
        %v73692_v50 = vadd.s32 %v73689_v41, %v73684_v50 (stack40)
        %v72083_v23 = vmul.f32 0.6931472, %v121046_v56 (stack65)
        %v72882_v42 = vor.u32 %v72881_v55, %v72880_v61 (stack47)
        %v73698_v29 = vshll.u32 %v73689_v41, 6 (stack45)
        %v73699_v22 = vshrl.u32 %v73689_v41, 26 (stack46)
        %v71732_v8 = vmul.f32 %v71728_v46, %v143167_v21 (stack54)
        %v72497_v20 = vadd.s32 %v72494_v10, %v121574_v2 (stack40)
        %v73284_v60 = vxor.u32 %v73283_v52, %v73275_v40 (stack48)
        %v74125_v53 = vadd.s32 %v143188_v30, %v121569_v1 (stack40)
        %v72089_v44 = vsel /*vm=*/%vm143199_vm10, /*on_true_vy=*/%v72086_v6, /*on_false_vx=*/%v72083_v23 (stack66)
        %v72883_v6 = vxor.u32 %v72882_v42, %v72878_v31 (stack48)
        %v73700_v45 = vor.u32 %v73699_v22, %v73698_v29 (stack47)
        %v74116_v26 = vsel /*vm=*/%vm74090_vm9, /*on_true_vy=*/%v74112_v24, /*on_false_vx=*/%v74108_v7 (stack44)
        %v71736_v9 = vadd.f32 %v71732_v8, %v143153_v9 (stack53)
        %v143217_v30 = vxor.u32 2147483648, %v72089_v44 (stack56)
        %v72489_v7 = vadd.s32 %v72485_v54, %v121564_v0 (stack40)
        %v72501_v54 = vadd.s32 5, %v72497_v20 (stack40)
        %v72886_v41 = vadd.s32 %v72883_v6, %v72878_v31 (stack40)
        %v72888_v31 = vshll.u32 %v72883_v6, 29 (stack45)
        %v72889_v61 = vshrl.u32 %v72883_v6, 3 (stack46)
        %v73701_v55 = vxor.u32 %v73700_v45, %v73692_v50 (stack48)
        %v71740_v24 = vmul.f32 %v71736_v9, %v143167_v21 (stack54)
        %121047 = vrsqrt.f32 %v143217_v30 (stack67)
        %v71641_v56 = vsel /*vm=*/%vm71632_vm6, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %vm72093_vm11 = vcmp.lt.f32.partialorder %v143217_v30, 5.0 (stack68)
        %v72503_v46 = vxor.u32 %v72501_v54, %v72489_v7 (stack48)
        %v73287_v10 = vadd.s32 %v73284_v60, %v121574_v2 (stack40)
        %vm143229_vm12 = vcmp.eq.f32.partialorder %v71605_v27, 1.0 (stack68)
        %v71613_v52 = vmul.f32 inf, %v143040_v34 (stack54)
        %v71637_v32 = vsel /*vm=*/%vm71632_vm6, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v71744_v23 = vadd.f32 %v71740_v24, %v71641_v56 (stack53)
        %v72890_v42 = vor.u32 %v72889_v61, %v72888_v31 (stack47)
        %v73279_v40 = vadd.s32 %v73275_v40, %v121564_v0 (stack40)
        %v73696_v50 = vadd.s32 %v73692_v50, %v121569_v1 (stack40)
        %v74131_v29 = vshll.u32 %v74125_v53, 13 (stack45)
        %v71748_v21 = vmul.f32 %v71744_v23, %v143167_v21 (stack54)
        %v143243_v22 = vsel /*vm=*/%vm72093_vm11, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v143248_v8 = vsel /*vm=*/%vm72093_vm11, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v143251_v20 = vadd.f32 -2.5, %v143217_v30 (stack53)
        %v72504_v60 = vand.u32.u8 255, %v72503_v46 (stack49)
        %v72891_v44 = vxor.u32 %v72890_v42, %v72886_v41 (stack48)
        %v73291_v6 = vadd.s32 2, %v73287_v10 (stack40)
        %v73704_v45 = vadd.s32 %v73701_v55, %v121564_v0 (stack40)
        %v71752_v9 = vadd.f32 %v71748_v21, %v71637_v32 (stack53)
        %v72141_v7 = vand.u32 2147483648, %v143217_v30 (stack72)
        %v74121_v26 = vadd.s32 %v74116_v26, %v121574_v2 (stack40)
        %v74132_v54 = vshrl.u32 %v74125_v53, 19 (stack46)
        %vm72138_vm13 = vcmp.eq.f32.partialorder %v143217_v30, inf (stack70)
        %v72505_v31 = vand.u32 65535, %v72504_v60 (stack50)
        %v72894_v41 = vadd.s32 %v72891_v44, %v72886_v41 (stack40)
        %v72896_v61 = vshll.u32 %v72891_v44, 16 (stack45)
        %v72897_v55 = vshrl.u32 %v72891_v44, 16 (stack46)
        %v71756_v34 = vmul.f32 %v71752_v9, %v143040_v34 (stack54)
        %vm72140_vm14 = vcmp.eq.f32.partialorder %v143217_v30, 0.0 (stack71)
        %v73295_v24 = vadd.s32 %v73291_v6, %v73279_v40 (stack40)
        %v73297_v56 = vshll.u32 %v73291_v6, 13 (stack45)
        %v73298_v46 = vshrl.u32 %v73291_v6, 19 (stack46)
        %v72506_v10 = vshrl.u32 %v72505_v31, 1 (stack51)
        %v72898_v32 = vor.u32 %v72897_v55, %v72896_v61 (stack47)
        %v73708_v23 = vadd.s32 1, %v73704_v45 (stack40)
        %v74129_v53 = vadd.s32 %v74125_v53, %v74121_v26 (stack40)
        %v71760_v27 = vsel /*vm=*/%vm143229_vm12, /*on_true_vy=*/%v71613_v52, /*on_false_vx=*/%v71756_v34 (stack44)
        %v73299_v52 = vor.u32 %v73298_v46, %v73297_v56 (stack47)
        %v74133_v42 = vor.u32 %v74132_v54, %v74131_v29 (stack47)
        %vm74556_vm15 = vcmp.lt.u32.totalorder %v143137_v25, %v157095_v13 (stack43)
        %v71764_v40 = vmul.f32 1.4140625, %v71760_v27 (stack54)
        %v72507_v29 = vor.u32 16256, %v72506_v10 (stack47)
        %v72899_v21 = vxor.u32 %v72898_v32, %v72894_v41 (stack48)
        %v73712_v50 = vadd.s32 %v73708_v23, %v73696_v50 (stack40)
        %v73300_v60 = vxor.u32 %v73299_v52, %v73295_v24 (stack48)
        %v73714_v44 = vshll.u32 %v73708_v23, 17 (stack45)
        %v73715_v6 = vshrl.u32 %v73708_v23, 15 (stack46)
        %v74134_v45 = vxor.u32 %v74133_v42, %v74129_v53 (stack48)
        %v121048_v9 = vpop.eup %121047 (stack73)
        %v71767_v26 = vpack.c.bf16 %v157387_v11, %v71764_v40 (stack81)
        %v72508_v54 = vand.u32.u16 65535, %v72507_v29 (stack52)
        %v72902_v31 = vadd.s32 %v72899_v21, %v72894_v41 (stack40)
        %v72908_v41 = vshll.u32 %v72899_v21, 24 (stack45)
        %v72137_v61 = vmul.f32 %v121048_v9, %v143217_v30 (stack74)
        %v72909_v55 = vshrl.u32 %v72899_v21, 8 (stack46)
        %v73303_v34 = vadd.s32 %v73300_v60, %v73295_v24 (stack40)
        %v73305_v24 = vshll.u32 %v73300_v60, 15 (stack45)
        %120129 = vst [vmem:[%s123356_s30 + $0x4c] sm:$0xf] /*vst_source=*/%v71767_v26 (stack83)
        %v120132_v56 = vadd.low.f32.bf16 -1.0, %v72508_v54 (stack53)
        %v72906_v46 = vadd.s32 %v72902_v31, %v121569_v1 (stack40)
        %v73306_v10 = vshrl.u32 %v73300_v60, 17 (stack46)
        %v73716_v32 = vor.u32 %v73715_v6, %v73714_v44 (stack47)
        %v72139_v23 = vsel /*vm=*/%vm72138_vm13, /*on_true_vy=*/%v143217_v30, /*on_false_vx=*/%v72137_v61 (stack75)
        %v72910_v27 = vor.u32 %v72909_v55, %v72908_v41 (stack47)
        %v74137_v53 = vadd.s32 %v74134_v45, %v74129_v53 (stack40)
        %v74139_v52 = vshll.u32 %v74134_v45, 15 (stack45)
        %v72142_v7 = vsel /*vm=*/%vm72140_vm14, /*on_true_vy=*/%v72141_v7, /*on_false_vx=*/%v72139_v23 (stack76)
        %v72517_v42 = vmul.f32 2.0, %v120132_v56 (stack54)
        %v73307_v40 = vor.u32 %v73306_v10, %v73305_v24 (stack47)
        %v73717_v29 = vxor.u32 %v73716_v32, %v73712_v50 (stack48)
        %v72145_v21 = vadd.f32 -3.0, %v72142_v7 (stack53)
        %v72911_v60 = vxor.u32 %v72910_v27, %v72902_v31 (stack48)
        %v74140_v44 = vshrl.u32 %v74134_v45, 17 (stack46)
        %v143274_v43 = vadd.s32 %v157517_v43, %v157100_v14 (stack40)
        %v72521_v6 = vadd.f32 -0.99609375, %v72517_v42 (stack53)
        %v73308_v45 = vxor.u32 %v73307_v40, %v73303_v34 (stack48)
        %v73720_v50 = vadd.s32 %v73717_v29, %v73712_v50 (stack40)
        %v73722_v9 = vshll.u32 %v73717_v29, 29 (stack45)
        %v143279_v20 = vsel /*vm=*/%vm72093_vm11, /*on_true_vy=*/%v143251_v20, /*on_false_vx=*/%v72145_v21 (stack44)
        %v72914_v26 = vadd.s32 %v72911_v60, %v121564_v0 (stack40)
        %v73723_v54 = vshrl.u32 %v73717_v29, 3 (stack46)
        %v74141_v31 = vor.u32 %v74140_v44, %v74139_v52 (stack47)
        %v72153_v8 = vmul.f32 %v143279_v20, %v143248_v8 (stack54)
        %v143284_v41 = vmax.f32 %v72521_v6, -0.99609375 (stack55)
        %v73311_v61 = vadd.s32 %v73308_v45, %v73303_v34 (stack40)
        %v73313_v55 = vshll.u32 %v73308_v45, 26 (stack45)
        %v72918_v34 = vadd.s32 4, %v72914_v26 (stack40)
        %v73314_v24 = vshrl.u32 %v73308_v45, 6 (stack46)
        %v73724_v56 = vor.u32 %v73723_v54, %v73722_v9 (stack47)
        %v74142_v10 = vxor.u32 %v74141_v31, %v74137_v53 (stack48)
        %v72066_v32 = vand.u32 2147483647, %v143148_v12 (stack77)
        %v143288_v23 = vmul.f32 inf, %v143148_v12 (stack54)
        %v72157_v22 = vadd.f32 %v72153_v8, %v143243_v22 (stack53)
        %v72537_v27 = vxor.u32 2147483648, %v143284_v41 (stack56)
        %v72922_v46 = vadd.s32 %v72918_v34, %v72906_v46 (stack40)
        %v72924_v52 = vshll.u32 %v72918_v34, 13 (stack45)
        %v72925_v7 = vshrl.u32 %v72918_v34, 19 (stack46)
        %v73315_v42 = vor.u32 %v73314_v24, %v73313_v55 (stack47)
        %v72161_v40 = vmul.f32 %v72157_v22, %v143279_v20 (stack54)
        %v143294_v29 = vmul.f32 %v72537_v27, %v143284_v41 (stack54)
        %v73725_v21 = vxor.u32 %v73724_v56, %v73720_v50 (stack48)
        %v143298_v60 = vadd.s32 %v143137_v25, %v122657_v58 (stack40)
        %v72122_v44 = vsel /*vm=*/%vm72093_vm11, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v72926_v6 = vor.u32 %v72925_v7, %v72924_v52 (stack47)
        %v73316_v45 = vxor.u32 %v73315_v42, %v73311_v61 (stack48)
        %v74145_v53 = vadd.s32 %v74142_v10, %v74137_v53 (stack40)
        %v143306_v9 = vsel /*vm=*/%vm72093_vm11, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v72110_v26 = vsel /*vm=*/%vm72093_vm11, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v72165_v54 = vadd.f32 %v72161_v40, %v72122_v44 (stack53)
        %v72542_v31 = vadd.f32 1.0, %v143294_v29 (stack57)
        %v72927_v8 = vxor.u32 %v72926_v6, %v72922_v46 (stack48)
        %v73319_v61 = vadd.s32 %v73316_v45, %v73311_v61 (stack40)
        %v73325_v55 = vshll.u32 %v73316_v45, 6 (stack45)
        %v73326_v34 = vshrl.u32 %v73316_v45, 26 (stack46)
        %v72114_v24 = vsel /*vm=*/%vm72093_vm11, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v72118_v56 = vsel /*vm=*/%vm72093_vm11, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v72169_v22 = vmul.f32 %v72165_v54, %v143279_v20 (stack54)
        %121049 = vlog2.f32 %v72542_v31 (stack58)
        %v72930_v27 = vadd.s32 %v72927_v8, %v72922_v46 (stack40)
        %v72932_v46 = vshll.u32 %v72927_v8, 15 (stack45)
        %v72933_v52 = vshrl.u32 %v72927_v8, 17 (stack46)
        %v74147_v7 = vshll.u32 %v74142_v10, 26 (stack45)
        %v72173_v42 = vadd.f32 %v72169_v22, %v72118_v56 (stack53)
        %v72545_v40 = vmul.f32 -0.5, %v143294_v29 (stack59)
        %v73327_v44 = vor.u32 %v73326_v34, %v73325_v55 (stack47)
        %v73728_v50 = vadd.s32 %v73725_v21, %v73720_v50 (stack40)
        %v72934_v6 = vor.u32 %v72933_v52, %v72932_v46 (stack47)
        %v73730_v45 = vshll.u32 %v73725_v21, 16 (stack45)
        %v73731_v21 = vshrl.u32 %v73725_v21, 16 (stack46)
        %v74148_v10 = vshrl.u32 %v74142_v10, 6 (stack46)
        %v72177_v54 = vmul.f32 %v72173_v42, %v143279_v20 (stack54)
        %v72548_v31 = vand.u32 2147483647, %v143294_v29 (stack60)
        %v73328_v8 = vxor.u32 %v73327_v44, %v73319_v61 (stack48)
        %v74565_v55 = vadd.s32 1, %v143274_v43 (stack40)
        %v72935_v34 = vxor.u32 %v72934_v6, %v72930_v27 (stack48)
        %v73732_v56 = vor.u32 %v73731_v21, %v73730_v45 (stack47)
        %v74149_v22 = vor.u32 %v74148_v10, %v74147_v7 (stack47)
        %v157536_v46 = vld [vmem:[#allocation144_spill] sm:$0xff] (stack84)
        %v143325_v52 = vadd.s32 %v157536_v46, %v122651_v47 (stack40)
        %v72181_v24 = vadd.f32 %v72177_v54, %v72114_v24 (stack53)
        %v72546_v7 = vadd.f32 1.0, %v72545_v40 (stack61)
        %v73331_v42 = vadd.s32 %v73328_v8, %v121569_v1 (stack40)
        %v74569_v43 = vsel /*vm=*/%vm74556_vm15, /*on_true_vy=*/%v74565_v55, /*on_false_vx=*/%v143274_v43 (stack44)
        %v72938_v27 = vadd.s32 %v72935_v34, %v72930_v27 (stack40)
        %v72940_v40 = vshll.u32 %v72935_v34, 26 (stack45)
        %v72941_v44 = vshrl.u32 %v72935_v34, 6 (stack46)
        %v73733_v6 = vxor.u32 %v73732_v56, %v73728_v50 (stack48)
        %v72185_v45 = vmul.f32 %v72181_v24, %v143279_v20 (stack54)
        %v73323_v61 = vadd.s32 %v73319_v61, %v121574_v2 (stack40)
        %v73335_v21 = vadd.s32 3, %v73331_v42 (stack40)
        %v74150_v10 = vxor.u32 %v74149_v22, %v74145_v53 (stack48)
        %v72942_v54 = vor.u32 %v72941_v44, %v72940_v40 (stack47)
        %v73736_v50 = vadd.s32 %v73733_v6, %v73728_v50 (stack40)
        %v73742_v8 = vshll.u32 %v73733_v6, 24 (stack45)
        %v73743_v55 = vshrl.u32 %v73733_v6, 8 (stack46)
        %v72189_v26 = vadd.f32 %v72185_v45, %v72110_v26 (stack53)
        %v73339_v34 = vadd.s32 %v73335_v21, %v73323_v61 (stack40)
        %v73341_v56 = vshll.u32 %v73335_v21, 17 (stack45)
        %v73342_v22 = vshrl.u32 %v73335_v21, 15 (stack46)
        %v72547_v29 = vmul.f32 %v72546_v7, %v143294_v29 (stack63)
        %v72943_v24 = vxor.u32 %v72942_v54, %v72938_v27 (stack48)
        %v73744_v7 = vor.u32 %v73743_v55, %v73742_v8 (stack47)
        %v74153_v53 = vadd.s32 %v74150_v10, %v74145_v53 (stack40)
        %v72193_v42 = vmul.f32 %v72189_v26, %v143279_v20 (stack54)
        %v73343_v40 = vor.u32 %v73342_v22, %v73341_v56 (stack47)
        %v74159_v44 = vshll.u32 %v74150_v10, 6 (stack45)
        %v74160_v6 = vshrl.u32 %v74150_v10, 26 (stack46)
        %v121050_v45 = vpop.eup %121049 (stack64)
        %v72946_v27 = vadd.s32 %v72943_v24, %v72938_v27 (stack40)
        %v72952_v61 = vshll.u32 %v72943_v24, 6 (stack45)
        %v72953_v21 = vshrl.u32 %v72943_v24, 26 (stack46)
        %v73745_v10 = vxor.u32 %v73744_v7, %v73736_v50 (stack48)
        %v72197_v9 = vadd.f32 %v72193_v42, %v143306_v9 (stack53)
        %v72544_v54 = vmul.f32 0.6931472, %v121050_v45 (stack65)
        %v73344_v8 = vxor.u32 %v73343_v40, %v73339_v34 (stack48)
        %v74573_v55 = vadd.s32 1, %v74569_v43 (stack40)
        %vm72549_vm0 = vcmp.lt.f32.partialorder %v72548_v31, 0.0004427343 (stack62)
        %v72954_v31 = vor.u32 %v72953_v21, %v72952_v61 (stack47)
        %v74161_v26 = vor.u32 %v74160_v6, %v74159_v44 (stack47)
        %vm74551_vm1 = vcmp.lt.u32.totalorder %v143298_v60, %v143137_v25 (stack43)
        %v72201_v25 = vmul.f32 %v72197_v9, %v143279_v20 (stack54)
        %v72550_v56 = vsel /*vm=*/%vm72549_vm0, /*on_true_vy=*/%v72547_v29, /*on_false_vx=*/%v72544_v54 (stack66)
        %v73347_v34 = vadd.s32 %v73344_v8, %v73339_v34 (stack40)
        %v73748_v22 = vadd.s32 %v73745_v10, %v121574_v2 (stack40)
        %v72102_v29 = vsel /*vm=*/%vm72093_vm11, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v143344_v24 = vxor.u32 2147483648, %v72550_v56 (stack56)
        %v72955_v7 = vxor.u32 %v72954_v31, %v72946_v27 (stack48)
        %v74586_v60 = vadd.s32 %v143298_v60, %v121569_v1 (stack40)
        %vm143350_vm2 = vcmp.eq.f32.partialorder %v72066_v32, 1.0 (stack68)
        %v72205_v42 = vadd.f32 %v72201_v25, %v72102_v29 (stack53)
        %v74162_v40 = vxor.u32 %v74161_v26, %v74153_v53 (stack48)
        %v74577_v43 = vsel /*vm=*/%vm74551_vm1, /*on_true_vy=*/%v74573_v55, /*on_false_vx=*/%v74569_v43 (stack44)
        %v72098_v30 = vsel /*vm=*/%vm72093_vm11, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %121051 = vrsqrt.f32 %v143344_v24 (stack67)
        %v73349_v44 = vshll.u32 %v73344_v8, 29 (stack45)
        %v73350_v6 = vshrl.u32 %v73344_v8, 3 (stack46)
        %v72209_v20 = vmul.f32 %v72205_v42, %v143279_v20 (stack54)
        %v72527_v45 = vand.u32 2147483647, %v143284_v41 (stack77)
        %vm72554_vm3 = vcmp.lt.f32.partialorder %v143344_v24, 5.0 (stack68)
        %v73752_v61 = vadd.s32 2, %v73748_v22 (stack40)
        %v143362_v21 = vmul.f32 inf, %v143284_v41 (stack54)
        %v72958_v10 = vadd.s32 %v72955_v7, %v121574_v2 (stack40)
        %v73740_v50 = vadd.s32 %v73736_v50, %v121564_v0 (stack40)
        %v74592_v9 = vshll.u32 %v74586_v60, 13 (stack45)
        %v72213_v54 = vadd.f32 %v72209_v20, %v72098_v30 (stack53)
        %v72950_v27 = vadd.s32 %v72946_v27, %v121564_v0 (stack40)
        %v74157_v53 = vadd.s32 %v74153_v53, %v121569_v1 (stack40)
        %v74593_v8 = vshrl.u32 %v74586_v60, 19 (stack46)
        %v143371_v55 = vsel /*vm=*/%vm72554_vm3, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v143374_v31 = vadd.f32 -2.5, %v143344_v24 (stack53)
        %v72962_v26 = vadd.s32 5, %v72958_v10 (stack40)
        %v73351_v25 = vor.u32 %v73350_v6, %v73349_v44 (stack47)
        %v72217_v12 = vmul.f32 %v72213_v54, %v143148_v12 (stack54)
        %v73756_v56 = vadd.s32 %v73752_v61, %v73740_v50 (stack40)
        %v73758_v22 = vshll.u32 %v73752_v61, 13 (stack45)
        %v73759_v29 = vshrl.u32 %v73752_v61, 19 (stack46)
        %v72964_v7 = vxor.u32 %v72962_v26, %v72950_v27 (stack48)
        %v73352_v42 = vxor.u32 %v73351_v25, %v73347_v34 (stack48)
        %v74165_v40 = vadd.s32 %v74162_v40, %v121564_v0 (stack40)
        %v74582_v43 = vadd.s32 %v74577_v43, %v121574_v2 (stack40)
        %v72221_v23 = vsel /*vm=*/%vm143350_vm2, /*on_true_vy=*/%v143288_v23, /*on_false_vx=*/%v72217_v12 (stack44)
        %v143385_v32 = vsel /*vm=*/%vm72554_vm3, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %vm72599_vm4 = vcmp.eq.f32.partialorder %v143344_v24, inf (stack70)
        %v73760_v30 = vor.u32 %v73759_v29, %v73758_v22 (stack47)
        %v74594_v44 = vor.u32 %v74593_v8, %v74592_v9 (stack47)
        %v72225_v6 = vmul.f32 1.4140625, %v72221_v23 (stack54)
        %v72965_v20 = vand.u32.u8 255, %v72964_v7 (stack49)
        %v73355_v34 = vadd.s32 %v73352_v42, %v73347_v34 (stack40)
        %v73357_v61 = vshll.u32 %v73352_v42, 16 (stack45)
        %v73358_v10 = vshrl.u32 %v73352_v42, 16 (stack46)
        %v73761_v50 = vxor.u32 %v73760_v30, %v73756_v56 (stack48)
        %v74169_v9 = vadd.s32 1, %v74165_v40 (stack40)
        %v74590_v60 = vadd.s32 %v74586_v60, %v74582_v43 (stack40)
        %v72228_v54 = vpack.c.bf16 %v157387_v11, %v72225_v6 (stack81)
        %vm72601_vm5 = vcmp.eq.f32.partialorder %v143344_v24, 0.0 (stack71)
        %v72966_v27 = vand.u32 65535, %v72965_v20 (stack50)
        %vm75051_vm6 = vcmp.lt.u32.totalorder %v143325_v52, %v122651_v47 (stack43)
        %v73359_v8 = vor.u32 %v73358_v10, %v73357_v61 (stack47)
        %v73764_v26 = vadd.s32 %v73761_v50, %v73756_v56 (stack40)
        %v73766_v25 = vshll.u32 %v73761_v50, 15 (stack45)
        %v73767_v12 = vshrl.u32 %v73761_v50, 17 (stack46)
        %120131 = vst [vmem:[%s123356_s30 + $0xcc] sm:$0xf] /*vst_source=*/%v72228_v54 (stack83)
        %v72967_v56 = vshrl.u32 %v72966_v27, 1 (stack51)
        %v74173_v53 = vadd.s32 %v74169_v9, %v74157_v53 (stack40)
        %v74175_v22 = vshll.u32 %v74169_v9, 17 (stack45)
        %v74176_v29 = vshrl.u32 %v74169_v9, 15 (stack46)
        %v121052_v7 = vpop.eup %121051 (stack73)
        %v73360_v42 = vxor.u32 %v73359_v8, %v73355_v34 (stack48)
        %v73768_v40 = vor.u32 %v73767_v12, %v73766_v25 (stack47)
        %v74595_v43 = vxor.u32 %v74594_v44, %v74590_v60 (stack48)
        %v157539_v23 = vld [vmem:[#allocation106_spill] sm:$0xff] (stack84)
        %v143395_v30 = vadd.s32 %v157539_v23, %v157068_v28 (stack40)
        %v72598_v44 = vmul.f32 %v121052_v7, %v143344_v24 (stack74)
        %v72602_v6 = vand.u32 2147483648, %v143344_v24 (stack72)
        %v72968_v20 = vor.u32 16256, %v72967_v56 (stack47)
        %v74177_v61 = vor.u32 %v74176_v29, %v74175_v22 (stack47)
        %v73363_v34 = vadd.s32 %v73360_v42, %v73355_v34 (stack40)
        %v73369_v10 = vshll.u32 %v73360_v42, 24 (stack45)
        %v73370_v50 = vshrl.u32 %v73360_v42, 8 (stack46)
        %v73769_v9 = vxor.u32 %v73768_v40, %v73764_v26 (stack48)
        %v72600_v54 = vsel /*vm=*/%vm72599_vm4, /*on_true_vy=*/%v143344_v24, /*on_false_vx=*/%v72598_v44 (stack75)
        %v72969_v27 = vand.u32.u16 65535, %v72968_v20 (stack52)
        %v74178_v8 = vxor.u32 %v74177_v61, %v74173_v53 (stack48)
        %v143402_v60 = vadd.s32 %v74595_v43, %v74590_v60 (stack40)
        %v72591_v25 = vsel /*vm=*/%vm72554_vm3, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v72603_v12 = vsel /*vm=*/%vm72601_vm5, /*on_true_vy=*/%v72602_v6, /*on_false_vx=*/%v72600_v54 (stack76)
        %v73371_v56 = vor.u32 %v73370_v50, %v73369_v10 (stack47)
        %v73772_v26 = vadd.s32 %v73769_v9, %v73764_v26 (stack40)
        %v72606_v22 = vadd.f32 -3.0, %v72603_v12 (stack53)
        %v120134_v29 = vadd.low.f32.bf16 -1.0, %v72969_v27 (stack53)
        %v73774_v7 = vshll.u32 %v73769_v9, 26 (stack45)
        %v73775_v42 = vshrl.u32 %v73769_v9, 6 (stack46)
        %v73372_v40 = vxor.u32 %v73371_v56, %v73363_v34 (stack48)
        %v74181_v53 = vadd.s32 %v74178_v8, %v74173_v53 (stack40)
        %v74183_v44 = vshll.u32 %v74178_v8, 29 (stack45)
        %v74184_v6 = vshrl.u32 %v74178_v8, 3 (stack46)
        %v143412_v31 = vsel /*vm=*/%vm72554_vm3, /*on_true_vy=*/%v143374_v31, /*on_false_vx=*/%v72606_v22 (stack44)
        %v72978_v20 = vmul.f32 2.0, %v120134_v29 (stack54)
        %v73776_v61 = vor.u32 %v73775_v42, %v73774_v7 (stack47)
        %v74600_v10 = vshll.u32 %v74595_v43, 15 (stack45)
        %v72614_v50 = vmul.f32 %v143412_v31, %v72591_v25 (stack54)
        %v73375_v9 = vadd.s32 %v73372_v40, %v121564_v0 (stack40)
        %v74185_v54 = vor.u32 %v74184_v6, %v74183_v44 (stack47)
        %v74601_v43 = vshrl.u32 %v74595_v43, 17 (stack46)
        %v72587_v27 = vsel /*vm=*/%vm72554_vm3, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v72982_v8 = vadd.f32 -0.99609375, %v72978_v20 (stack53)
        %v73367_v34 = vadd.s32 %v73363_v34, %v121569_v1 (stack40)
        %v73777_v25 = vxor.u32 %v73776_v61, %v73772_v26 (stack48)
        %v72618_v12 = vadd.f32 %v72614_v50, %v72587_v27 (stack53)
        %v73379_v56 = vadd.s32 4, %v73375_v9 (stack40)
        %v74186_v22 = vxor.u32 %v74185_v54, %v74181_v53 (stack48)
        %v74602_v29 = vor.u32 %v74601_v43, %v74600_v10 (stack47)
        %v143420_v7 = vmax.f32 %v72982_v8, -0.99609375 (stack55)
        %v73780_v26 = vadd.s32 %v73777_v25, %v73772_v26 (stack40)
        %v73786_v42 = vshll.u32 %v73777_v25, 6 (stack45)
        %v73787_v40 = vshrl.u32 %v73777_v25, 26 (stack46)
        %v72622_v44 = vmul.f32 %v72618_v12, %v143412_v31 (stack54)
        %v73383_v6 = vadd.s32 %v73379_v56, %v73367_v34 (stack40)
        %v73385_v20 = vshll.u32 %v73379_v56, 13 (stack45)
        %v73386_v61 = vshrl.u32 %v73379_v56, 19 (stack46)
        %v72575_v10 = vsel /*vm=*/%vm72554_vm3, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v72583_v50 = vsel /*vm=*/%vm72554_vm3, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v72998_v9 = vxor.u32 2147483648, %v143420_v7 (stack56)
        %v143432_v54 = vadd.s32 %v143325_v52, %v122657_v58 (stack40)
        %v72626_v43 = vadd.f32 %v72622_v44, %v72583_v50 (stack53)
        %v73387_v27 = vor.u32 %v73386_v61, %v73385_v20 (stack47)
        %v73788_v8 = vor.u32 %v73787_v40, %v73786_v42 (stack47)
        %v74189_v53 = vadd.s32 %v74186_v22, %v74181_v53 (stack40)
        %v72579_v34 = vsel /*vm=*/%vm72554_vm3, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v143438_v25 = vmul.f32 %v72998_v9, %v143420_v7 (stack54)
        %v74191_v12 = vshll.u32 %v74186_v22, 16 (stack45)
        %v74192_v56 = vshrl.u32 %v74186_v22, 16 (stack46)
        %v72630_v22 = vmul.f32 %v72626_v43, %v143412_v31 (stack54)
        %v73388_v42 = vxor.u32 %v73387_v27, %v73383_v6 (stack48)
        %v73789_v40 = vxor.u32 %v73788_v8, %v73780_v26 (stack48)
        %v74603_v29 = vxor.u32 %v74602_v29, %v143402_v60 (stack48)
        %v73003_v44 = vadd.f32 1.0, %v143438_v25 (stack57)
        %v74193_v20 = vor.u32 %v74192_v56, %v74191_v12 (stack47)
        %v75060_v61 = vadd.s32 1, %v143395_v30 (stack40)
        %v143446_v50 = vadd.s32 %v143432_v54, %v121569_v1 (stack40)
        %v72634_v9 = vadd.f32 %v72630_v22, %v72579_v34 (stack53)
        %v73391_v6 = vadd.s32 %v73388_v42, %v73383_v6 (stack40)
        %v73393_v43 = vshll.u32 %v73388_v42, 15 (stack45)
        %v73394_v27 = vshrl.u32 %v73388_v42, 17 (stack46)
        %121053 = vlog2.f32 %v73003_v44 (stack58)
        %v73006_v8 = vmul.f32 -0.5, %v143438_v25 (stack59)
        %v73784_v26 = vadd.s32 %v73780_v26, %v121574_v2 (stack40)
        %v73792_v34 = vadd.s32 %v73789_v40, %v121569_v1 (stack40)
        %v72638_v12 = vmul.f32 %v72634_v9, %v143412_v31 (stack54)
        %v73395_v56 = vor.u32 %v73394_v27, %v73393_v43 (stack47)
        %v74194_v22 = vxor.u32 %v74193_v20, %v74189_v53 (stack48)
        %v74606_v60 = vadd.s32 %v74603_v29, %v143402_v60 (stack40)
        %v73009_v42 = vand.u32 2147483647, %v143438_v25 (stack60)
        %v73796_v40 = vadd.s32 3, %v73792_v34 (stack40)
        %v74608_v44 = vshll.u32 %v74603_v29, 26 (stack45)
        %v74609_v29 = vshrl.u32 %v74603_v29, 6 (stack46)
        %v72642_v10 = vadd.f32 %v72638_v12, %v72575_v10 (stack53)
        %v73396_v20 = vxor.u32 %v73395_v56, %v73391_v6 (stack48)
        %v74197_v53 = vadd.s32 %v74194_v22, %v74189_v53 (stack40)
        %v74203_v9 = vshll.u32 %v74194_v22, 24 (stack45)
        %v73800_v43 = vadd.s32 %v73796_v40, %v73784_v26 (stack40)
        %v73802_v27 = vshll.u32 %v73796_v40, 17 (stack45)
        %v73803_v26 = vshrl.u32 %v73796_v40, 15 (stack46)
        %v74204_v34 = vshrl.u32 %v74194_v22, 8 (stack46)
        %v72646_v12 = vmul.f32 %v72642_v10, %v143412_v31 (stack54)
        %v73399_v6 = vadd.s32 %v73396_v20, %v73391_v6 (stack40)
        %v73401_v56 = vshll.u32 %v73396_v20, 26 (stack45)
        %v73402_v22 = vshrl.u32 %v73396_v20, 6 (stack46)
        %v72571_v40 = vsel /*vm=*/%vm72554_vm3, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v73804_v10 = vor.u32 %v73803_v26, %v73802_v27 (stack47)
        %v74205_v20 = vor.u32 %v74204_v34, %v74203_v9 (stack47)
        %v74610_v44 = vor.u32 %v74609_v29, %v74608_v44 (stack47)
        %v72650_v29 = vadd.f32 %v72646_v12, %v72571_v40 (stack53)
        %v73403_v9 = vor.u32 %v73402_v22, %v73401_v56 (stack47)
        %vm75046_vm7 = vcmp.lt.u32.totalorder %v143432_v54, %v143325_v52 (stack43)
        %v75064_v30 = vsel /*vm=*/%vm75051_vm6, /*on_true_vy=*/%v75060_v61, /*on_false_vx=*/%v143395_v30 (stack44)
        %v75087_v61 = vshll.u32 %v143446_v50, 13 (stack45)
        %v73007_v8 = vadd.f32 1.0, %v73006_v8 (stack61)
        %v73805_v27 = vxor.u32 %v73804_v10, %v73800_v43 (stack48)
        %v74206_v26 = vxor.u32 %v74205_v20, %v74197_v53 (stack48)
        %v74611_v34 = vxor.u32 %v74610_v44, %v74606_v60 (stack48)
        %v72654_v12 = vmul.f32 %v72650_v29, %v143412_v31 (stack54)
        %vm143466_vm8 = vcmp.lt.f32.partialorder %v73009_v42, 0.0004427343 (stack62)
        %v73404_v56 = vxor.u32 %v73403_v9, %v73399_v6 (stack48)
        %v143472_v22 = vadd.s32 %v157536_v46, %v157070_v38 (stack40)
        %v73808_v43 = vadd.s32 %v73805_v27, %v73800_v43 (stack40)
        %v73810_v40 = vshll.u32 %v73805_v27, 29 (stack45)
        %v73811_v10 = vshrl.u32 %v73805_v27, 3 (stack46)
        %v74209_v20 = vadd.s32 %v74206_v26, %v121574_v2 (stack40)
        %v72658_v32 = vadd.f32 %v72654_v12, %v143385_v32 (stack53)
        %v73407_v6 = vadd.s32 %v73404_v56, %v73399_v6 (stack40)
        %v73413_v44 = vshll.u32 %v73404_v56, 6 (stack45)
        %v73414_v29 = vshrl.u32 %v73404_v56, 26 (stack46)
        %v73812_v9 = vor.u32 %v73811_v10, %v73810_v40 (stack47)
        %v74201_v53 = vadd.s32 %v74197_v53, %v121564_v0 (stack40)
        %v74213_v27 = vadd.s32 2, %v74209_v20 (stack40)
        %v143477_v60 = vadd.s32 %v74611_v34, %v74606_v60 (stack40)
        %v121054_v26 = vpop.eup %121053 (stack64)
        %v72662_v12 = vmul.f32 %v72658_v32, %v143412_v31 (stack54)
        %v73008_v25 = vmul.f32 %v73007_v8, %v143438_v25 (stack63)
        %v73415_v8 = vor.u32 %v73414_v29, %v73413_v44 (stack47)
        %v75088_v56 = vshrl.u32 %v143446_v50, 19 (stack46)
        %v73005_v40 = vmul.f32 0.6931472, %v121054_v26 (stack65)
        %v73813_v10 = vxor.u32 %v73812_v9, %v73808_v43 (stack48)
        %v74217_v20 = vadd.s32 %v74213_v27, %v74201_v53 (stack40)
        %v75068_v32 = vadd.s32 1, %v75064_v30 (stack40)
        %v72666_v55 = vadd.f32 %v72662_v12, %v143371_v55 (stack53)
        %v73416_v44 = vxor.u32 %v73415_v8, %v73407_v6 (stack48)
        %v74620_v29 = vshll.u32 %v74611_v34, 6 (stack45)
        %v74621_v34 = vshrl.u32 %v74611_v34, 26 (stack46)
        %v73011_v42 = vsel /*vm=*/%vm143466_vm8, /*on_true_vy=*/%v73008_v25, /*on_false_vx=*/%v73005_v40 (stack66)
        %v73816_v43 = vadd.s32 %v73813_v10, %v73808_v43 (stack40)
        %v73818_v9 = vshll.u32 %v73813_v10, 16 (stack45)
        %v73819_v53 = vshrl.u32 %v73813_v10, 16 (stack46)
        %v72670_v31 = vmul.f32 %v72666_v55, %v143412_v31 (stack54)
        %v143486_v26 = vxor.u32 2147483648, %v73011_v42 (stack56)
        %v74219_v12 = vshll.u32 %v74213_v27, 13 (stack45)
        %v74220_v27 = vshrl.u32 %v74213_v27, 19 (stack46)
        %vm143490_vm9 = vcmp.eq.f32.partialorder %v72527_v45, 1.0 (stack68)
        %v72559_v24 = vsel /*vm=*/%vm72554_vm3, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v73820_v25 = vor.u32 %v73819_v53, %v73818_v9 (stack47)
        %v75072_v52 = vsel /*vm=*/%vm75046_vm7, /*on_true_vy=*/%v75068_v32, /*on_false_vx=*/%v75064_v30 (stack44)
        %v72674_v54 = vadd.f32 %v72670_v31, %v72559_v24 (stack53)
        %vm73015_vm10 = vcmp.lt.f32.partialorder %v143486_v26, 5.0 (stack68)
        %121055 = vrsqrt.f32 %v143486_v26 (stack67)
        %v75089_v30 = vor.u32 %v75088_v56, %v75087_v61 (stack47)
        %v73411_v61 = vadd.s32 %v73407_v6, %v121564_v0 (stack40)
        %v73419_v6 = vadd.s32 %v73416_v44, %v121574_v2 (stack40)
        %v73821_v8 = vxor.u32 %v73820_v25, %v73816_v43 (stack48)
        %v74618_v56 = vadd.s32 %v143477_v60, %v121569_v1 (stack40)
        %v72678_v41 = vmul.f32 %v72674_v54, %v143284_v41 (stack54)
        %v74221_v40 = vor.u32 %v74220_v27, %v74219_v12 (stack47)
        %v74622_v10 = vor.u32 %v74621_v34, %v74620_v29 (stack47)
        %v143509_v32 = vadd.s32 %v143472_v22, %v122657_v58 (stack40)
        %v143514_v55 = vsel /*vm=*/%vm73015_vm10, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v143519_v44 = vsel /*vm=*/%vm73015_vm10, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v143522_v29 = vadd.f32 -2.5, %v143486_v26 (stack53)
        %v73824_v34 = vadd.s32 %v73821_v8, %v73816_v43 (stack40)
        %v72682_v21 = vsel /*vm=*/%vm143490_vm9, /*on_true_vy=*/%v143362_v21, /*on_false_vx=*/%v72678_v41 (stack44)
        %v143530_v42 = vsel /*vm=*/%vm73015_vm10, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v143535_v43 = vsel /*vm=*/%vm73015_vm10, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v143540_v9 = vsel /*vm=*/%vm73015_vm10, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v72686_v53 = vmul.f32 1.4140625, %v72682_v21 (stack54)
        %v143545_v31 = vsel /*vm=*/%vm73015_vm10, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v73423_v12 = vadd.s32 5, %v73419_v6 (stack40)
        %v73830_v27 = vshll.u32 %v73821_v8, 24 (stack45)
        %v73831_v45 = vshrl.u32 %v73821_v8, 8 (stack46)
        %v74222_v24 = vxor.u32 %v74221_v40, %v74217_v20 (stack48)
        %v74623_v60 = vxor.u32 %v74622_v10, %v143477_v60 (stack48)
        %v75077_v25 = vadd.s32 %v75072_v52, %v121574_v2 (stack40)
        %v72689_v52 = vpack.c.bf16 %v157387_v11, %v72686_v53 (stack81)
        %vm73060_vm11 = vcmp.eq.f32.partialorder %v143486_v26, inf (stack70)
        %v73425_v54 = vxor.u32 %v73423_v12, %v73411_v61 (stack48)
        %vm75512_vm12 = vcmp.lt.u32.totalorder %v143472_v22, %v157070_v38 (stack43)
        %v73832_v61 = vor.u32 %v73831_v45, %v73830_v27 (stack47)
        %v74225_v20 = vadd.s32 %v74222_v24, %v74217_v20 (stack40)
        %v74227_v6 = vshll.u32 %v74222_v24, 15 (stack45)
        %v74228_v8 = vshrl.u32 %v74222_v24, 17 (stack46)
        %120133 = vst [vmem:[%s123356_s30 + $0x14c] sm:$0xf] /*vst_source=*/%v72689_v52 (stack83)
        %v73426_v41 = vand.u32.u8 255, %v73425_v54 (stack49)
        %v74626_v40 = vadd.s32 %v74623_v60, %v121564_v0 (stack40)
        %v75085_v50 = vadd.s32 %v143446_v50, %v75077_v25 (stack40)
        %v75517_v10 = vadd.s32 %v157539_v23, %v157076_v35 (stack40)
        %vm73062_vm13 = vcmp.eq.f32.partialorder %v143486_v26, 0.0 (stack71)
        %v73833_v21 = vxor.u32 %v73832_v61, %v73824_v34 (stack48)
        %v74229_v53 = vor.u32 %v74228_v8, %v74227_v6 (stack47)
        %v143561_v12 = vadd.s32 %v157536_v46, %v157077_v51 (stack40)
        %v73063_v27 = vand.u32 2147483648, %v143486_v26 (stack72)
        %v73427_v45 = vand.u32 65535, %v73426_v41 (stack50)
        %v74630_v24 = vadd.s32 1, %v74626_v40 (stack40)
        %v75090_v30 = vxor.u32 %v75089_v30, %v75085_v50 (stack48)
        %v73828_v34 = vadd.s32 %v73824_v34, %v121569_v1 (stack40)
        %v73836_v60 = vadd.s32 %v73833_v21, %v121564_v0 (stack40)
        %v74230_v25 = vxor.u32 %v74229_v53, %v74225_v20 (stack48)
        %v75521_v52 = vadd.s32 1, %v75517_v10 (stack40)
        %v121056_v54 = vpop.eup %121055 (stack73)
        %v73428_v61 = vshrl.u32 %v73427_v45, 1 (stack51)
        %v74634_v56 = vadd.s32 %v74630_v24, %v74618_v56 (stack40)
        %v74636_v6 = vshll.u32 %v74630_v24, 17 (stack45)
        %v74637_v8 = vshrl.u32 %v74630_v24, 15 (stack46)
        %v73059_v41 = vmul.f32 %v121056_v54, %v143486_v26 (stack74)
        %v73840_v40 = vadd.s32 4, %v73836_v60 (stack40)
        %v74233_v20 = vadd.s32 %v74230_v25, %v74225_v20 (stack40)
        %v74235_v21 = vshll.u32 %v74230_v25, 26 (stack45)
        %v73429_v53 = vor.u32 16256, %v73428_v61 (stack47)
        %v74236_v45 = vshrl.u32 %v74230_v25, 6 (stack46)
        %v74638_v24 = vor.u32 %v74637_v8, %v74636_v6 (stack47)
        %v75093_v50 = vadd.s32 %v75090_v30, %v75085_v50 (stack40)
        %v73061_v60 = vsel /*vm=*/%vm73060_vm11, /*on_true_vy=*/%v143486_v26, /*on_false_vx=*/%v73059_v41 (stack75)
        %v73844_v34 = vadd.s32 %v73840_v40, %v73828_v34 (stack40)
        %v73846_v25 = vshll.u32 %v73840_v40, 13 (stack45)
        %v73847_v54 = vshrl.u32 %v73840_v40, 19 (stack46)
        %v73064_v27 = vsel /*vm=*/%vm73062_vm13, /*on_true_vy=*/%v73063_v27, /*on_false_vx=*/%v73061_v60 (stack76)
        %v73430_v61 = vand.u32.u16 65535, %v73429_v53 (stack52)
        %v74237_v6 = vor.u32 %v74236_v45, %v74235_v21 (stack47)
        %v74639_v8 = vxor.u32 %v74638_v24, %v74634_v56 (stack48)
        %v73067_v41 = vadd.f32 -3.0, %v73064_v27 (stack53)
        %v73848_v40 = vor.u32 %v73847_v54, %v73846_v25 (stack47)
        %v75095_v21 = vshll.u32 %v75090_v30, 15 (stack45)
        %v75096_v30 = vshrl.u32 %v75090_v30, 17 (stack46)
        %v120136_v53 = vadd.low.f32.bf16 -1.0, %v73430_v61 (stack53)
        %v74238_v45 = vxor.u32 %v74237_v6, %v74233_v20 (stack48)
        %v74642_v56 = vadd.s32 %v74639_v8, %v74634_v56 (stack40)
        %v74644_v24 = vshll.u32 %v74639_v8, 29 (stack45)
        %v143575_v29 = vsel /*vm=*/%vm73015_vm10, /*on_true_vy=*/%v143522_v29, /*on_false_vx=*/%v73067_v41 (stack44)
        %v73849_v60 = vxor.u32 %v73848_v40, %v73844_v34 (stack48)
        %v74645_v25 = vshrl.u32 %v74639_v8, 3 (stack46)
        %v75097_v54 = vor.u32 %v75096_v30, %v75095_v21 (stack47)
        %v73075_v31 = vmul.f32 %v143575_v29, %v143545_v31 (stack54)
        %v73439_v27 = vmul.f32 2.0, %v120136_v53 (stack54)
        %v74241_v20 = vadd.s32 %v74238_v45, %v74233_v20 (stack40)
        %v74247_v61 = vshll.u32 %v74238_v45, 6 (stack45)
        %v73852_v34 = vadd.s32 %v73849_v60, %v73844_v34 (stack40)
        %v73854_v6 = vshll.u32 %v73849_v60, 15 (stack45)
        %v73855_v8 = vshrl.u32 %v73849_v60, 17 (stack46)
        %v74248_v41 = vshrl.u32 %v74238_v45, 26 (stack46)
        %v73079_v9 = vadd.f32 %v73075_v31, %v143540_v9 (stack53)
        %v73443_v40 = vadd.f32 -0.99609375, %v73439_v27 (stack53)
        %v74646_v21 = vor.u32 %v74645_v25, %v74644_v24 (stack47)
        %v143582_v30 = vadd.s32 %v143509_v32, %v121569_v1 (stack40)
        %v73856_v53 = vor.u32 %v73855_v8, %v73854_v6 (stack47)
        %v74249_v45 = vor.u32 %v74248_v41, %v74247_v61 (stack47)
        %v75098_v24 = vxor.u32 %v75097_v54, %v75093_v50 (stack48)
        %v75525_v10 = vsel /*vm=*/%vm75512_vm12, /*on_true_vy=*/%v75521_v52, /*on_false_vx=*/%v75517_v10 (stack44)
        %v73040_v52 = vsel /*vm=*/%vm73015_vm10, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v73083_v60 = vmul.f32 %v73079_v9, %v143575_v29 (stack54)
        %v143591_v25 = vmax.f32 %v73443_v40, -0.99609375 (stack55)
        %v74647_v54 = vxor.u32 %v74646_v21, %v74642_v56 (stack48)
        %v73044_v31 = vsel /*vm=*/%vm73015_vm10, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v73857_v27 = vxor.u32 %v73856_v53, %v73852_v34 (stack48)
        %v74250_v61 = vxor.u32 %v74249_v45, %v74241_v20 (stack48)
        %v143596_v50 = vadd.s32 %v75098_v24, %v75093_v50 (stack40)
        %v73087_v6 = vadd.f32 %v73083_v60, %v73044_v31 (stack53)
        %v73459_v8 = vxor.u32 2147483648, %v143591_v25 (stack56)
        %vm75507_vm14 = vcmp.lt.u32.totalorder %v143509_v32, %v143472_v22 (stack43)
        %v75548_v41 = vshll.u32 %v143582_v30, 13 (stack45)
        %v73860_v34 = vadd.s32 %v73857_v27, %v73852_v34 (stack40)
        %v73862_v9 = vshll.u32 %v73857_v27, 26 (stack45)
        %v73863_v40 = vshrl.u32 %v73857_v27, 6 (stack46)
        %v74253_v21 = vadd.s32 %v74250_v61, %v121569_v1 (stack40)
        %v73091_v53 = vmul.f32 %v73087_v6, %v143575_v29 (stack54)
        %v143605_v45 = vmul.f32 %v73459_v8, %v143591_v25 (stack54)
        %v74245_v20 = vadd.s32 %v74241_v20, %v121574_v2 (stack40)
        %v74650_v56 = vadd.s32 %v74647_v54, %v74642_v56 (stack40)
        %v73864_v60 = vor.u32 %v73863_v40, %v73862_v9 (stack47)
        %v74257_v31 = vadd.s32 3, %v74253_v21 (stack40)
        %v74652_v27 = vshll.u32 %v74647_v54, 16 (stack45)
        %v75529_v61 = vadd.s32 1, %v75525_v10 (stack40)
        %v73095_v52 = vadd.f32 %v73091_v53, %v73040_v52 (stack53)
        %v73464_v6 = vadd.f32 1.0, %v143605_v45 (stack57)
        %v73467_v8 = vmul.f32 -0.5, %v143605_v45 (stack59)
        %v74653_v54 = vshrl.u32 %v74647_v54, 16 (stack46)
        %v73865_v9 = vxor.u32 %v73864_v60, %v73860_v34 (stack48)
        %v74261_v40 = vadd.s32 %v74257_v31, %v74245_v20 (stack40)
        %v74263_v21 = vshll.u32 %v74257_v31, 17 (stack45)
        %v74264_v53 = vshrl.u32 %v74257_v31, 15 (stack46)
        %v73099_v20 = vmul.f32 %v73095_v52, %v143575_v29 (stack54)
        %121057 = vlog2.f32 %v73464_v6 (stack58)
        %v75103_v60 = vshll.u32 %v75098_v24, 26 (stack45)
        %v75549_v31 = vshrl.u32 %v143582_v30, 19 (stack46)
        %v73868_v34 = vadd.s32 %v73865_v9, %v73860_v34 (stack40)
        %v73874_v52 = vshll.u32 %v73865_v9, 6 (stack45)
        %v73875_v6 = vshrl.u32 %v73865_v9, 26 (stack46)
        %v74265_v9 = vor.u32 %v74264_v53, %v74263_v21 (stack47)
        %v73103_v43 = vadd.f32 %v73099_v20, %v143535_v43 (stack53)
        %v73470_v21 = vand.u32 2147483647, %v143605_v45 (stack60)
        %v74654_v27 = vor.u32 %v74653_v54, %v74652_v27 (stack47)
        %v75104_v24 = vshrl.u32 %v75098_v24, 6 (stack46)
        %v73468_v8 = vadd.f32 1.0, %v73467_v8 (stack61)
        %v73876_v54 = vor.u32 %v73875_v6, %v73874_v52 (stack47)
        %v74266_v53 = vxor.u32 %v74265_v9, %v74261_v40 (stack48)
        %v75533_v22 = vsel /*vm=*/%vm75507_vm14, /*on_true_vy=*/%v75529_v61, /*on_false_vx=*/%v75525_v10 (stack44)
        %v73107_v32 = vmul.f32 %v73103_v43, %v143575_v29 (stack54)
        %v74655_v10 = vxor.u32 %v74654_v27, %v74650_v56 (stack48)
        %v75105_v61 = vor.u32 %v75104_v24, %v75103_v60 (stack47)
        %v75538_v20 = vadd.s32 %v75533_v22, %v121574_v2 (stack40)
        %v73877_v60 = vxor.u32 %v73876_v54, %v73868_v34 (stack48)
        %v74269_v40 = vadd.s32 %v74266_v53, %v74261_v40 (stack40)
        %v74271_v52 = vshll.u32 %v74266_v53, 29 (stack45)
        %v74272_v6 = vshrl.u32 %v74266_v53, 3 (stack46)
        %v73111_v42 = vadd.f32 %v73107_v32, %v143530_v42 (stack53)
        %v74658_v56 = vadd.s32 %v74655_v10, %v74650_v56 (stack40)
        %v74664_v9 = vshll.u32 %v74655_v10, 24 (stack45)
        %v74665_v43 = vshrl.u32 %v74655_v10, 8 (stack46)
        %v73880_v27 = vadd.s32 %v73877_v60, %v121574_v2 (stack40)
        %v74273_v24 = vor.u32 %v74272_v6, %v74271_v52 (stack47)
        %v75106_v54 = vxor.u32 %v75105_v61, %v143596_v50 (stack48)
        %v75546_v30 = vadd.s32 %v143582_v30, %v75538_v20 (stack40)
        %v73115_v53 = vmul.f32 %v73111_v42, %v143575_v29 (stack54)
        %v73872_v34 = vadd.s32 %v73868_v34, %v121564_v0 (stack40)
        %v74666_v22 = vor.u32 %v74665_v43, %v74664_v9 (stack47)
        %v75550_v41 = vor.u32 %v75549_v31, %v75548_v41 (stack47)
        %v73884_v31 = vadd.s32 5, %v73880_v27 (stack40)
        %v74274_v32 = vxor.u32 %v74273_v24, %v74269_v40 (stack48)
        %v75109_v50 = vadd.s32 %v75106_v54, %v143596_v50 (stack40)
        %v75115_v10 = vshll.u32 %v75106_v54, 6 (stack45)
        %v73119_v44 = vadd.f32 %v73115_v53, %v143519_v44 (stack53)
        %v74667_v61 = vxor.u32 %v74666_v22, %v74658_v56 (stack48)
        %v75116_v20 = vshrl.u32 %v75106_v54, 26 (stack46)
        %v75551_v60 = vxor.u32 %v75550_v41, %v75546_v30 (stack48)
        %v73886_v52 = vxor.u32 %v73884_v31, %v73872_v34 (stack48)
        %v74277_v40 = vadd.s32 %v74274_v32, %v74269_v40 (stack40)
        %v74279_v6 = vshll.u32 %v74274_v32, 16 (stack45)
        %v74280_v42 = vshrl.u32 %v74274_v32, 16 (stack46)
        %v73123_v9 = vmul.f32 %v73119_v44, %v143575_v29 (stack54)
        %v73469_v45 = vmul.f32 %v73468_v8, %v143605_v45 (stack63)
        %v74670_v8 = vadd.s32 %v74667_v61, %v121574_v2 (stack40)
        %v75117_v43 = vor.u32 %v75116_v20, %v75115_v10 (stack47)
        %v121058_v27 = vpop.eup %121057 (stack64)
        %v73887_v24 = vand.u32.u8 255, %v73886_v52 (stack49)
        %v74281_v54 = vor.u32 %v74280_v42, %v74279_v6 (stack47)
        %v74662_v56 = vadd.s32 %v74658_v56, %v121564_v0 (stack40)
        %v75554_v30 = vadd.s32 %v75551_v60, %v75546_v30 (stack40)
        %v73127_v55 = vadd.f32 %v73123_v9, %v143514_v55 (stack53)
        %v73466_v53 = vmul.f32 0.6931472, %v121058_v27 (stack65)
        %v74674_v34 = vadd.s32 2, %v74670_v8 (stack40)
        %v75118_v22 = vxor.u32 %v75117_v43, %v75109_v50 (stack48)
        %vm73471_vm15 = vcmp.lt.f32.partialorder %v73470_v21, 0.0004427343 (stack62)
        %v73888_v21 = vand.u32 65535, %v73887_v24 (stack50)
        %v74282_v41 = vxor.u32 %v74281_v54, %v74277_v40 (stack48)
        %v72988_v31 = vand.u32 2147483647, %v143420_v7 (stack77)
        %v73131_v29 = vmul.f32 %v73127_v55, %v143575_v29 (stack54)
        %v73472_v32 = vsel /*vm=*/%vm73471_vm15, /*on_true_vy=*/%v73469_v45, /*on_false_vx=*/%v73466_v53 (stack66)
        %v74678_v10 = vadd.s32 %v74674_v34, %v74662_v56 (stack40)
        %v72996_v44 = vmul.f32 inf, %v143420_v7 (stack54)
        %v73020_v26 = vsel /*vm=*/%vm73015_vm10, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v143638_v61 = vxor.u32 2147483648, %v73472_v32 (stack56)
        %v74285_v20 = vadd.s32 %v74282_v41, %v74277_v40 (stack40)
        %v73135_v52 = vadd.f32 %v73131_v29, %v73020_v26 (stack53)
        %v74680_v40 = vshll.u32 %v74674_v34, 13 (stack45)
        %v75556_v6 = vshll.u32 %v75551_v60, 15 (stack45)
        %v75557_v60 = vshrl.u32 %v75551_v60, 17 (stack46)
        %121059 = vrsqrt.f32 %v143638_v61 (stack67)
        %v73889_v42 = vshrl.u32 %v73888_v21, 1 (stack51)
        %v74291_v9 = vshll.u32 %v74282_v41, 24 (stack45)
        %v74292_v45 = vshrl.u32 %v74282_v41, 8 (stack46)
        %v73139_v7 = vmul.f32 %v73135_v52, %v143420_v7 (stack54)
        %vm73476_vm0 = vcmp.lt.f32.partialorder %v143638_v61, 5.0 (stack68)
        %v74681_v8 = vshrl.u32 %v74674_v34, 19 (stack46)
        %v75121_v43 = vadd.s32 %v75118_v22, %v121564_v0 (stack40)
        %vm72991_vm1 = vcmp.eq.f32.partialorder %v72988_v31, 1.0 (stack68)
        %v73143_v27 = vsel /*vm=*/%vm72991_vm1, /*on_true_vy=*/%v72996_v44, /*on_false_vx=*/%v73139_v7 (stack44)
        %v143645_v24 = vadd.f32 -2.5, %v143638_v61 (stack53)
        %v75113_v50 = vadd.s32 %v75109_v50, %v121569_v1 (stack40)
        %v143650_v54 = vadd.s32 %v143561_v12, %v122657_v58 (stack40)
        %v73147_v56 = vmul.f32 1.4140625, %v73143_v27 (stack54)
        %v143655_v55 = vsel /*vm=*/%vm73476_vm0, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v143660_v53 = vsel /*vm=*/%vm73476_vm0, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v73890_v34 = vor.u32 16256, %v73889_v42 (stack47)
        %v74293_v22 = vor.u32 %v74292_v45, %v74291_v9 (stack47)
        %v74682_v21 = vor.u32 %v74681_v8, %v74680_v40 (stack47)
        %v75125_v41 = vadd.s32 1, %v75121_v43 (stack40)
        %v75558_v31 = vor.u32 %v75557_v60, %v75556_v6 (stack47)
        %v73150_v29 = vpack.c.bf16 %v157387_v11, %v73147_v56 (stack81)
        %v143666_v32 = vsel /*vm=*/%vm73476_vm0, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v73891_v44 = vand.u32.u16 65535, %v73890_v34 (stack52)
        %vm75973_vm2 = vcmp.lt.u32.totalorder %v143561_v12, %v157077_v51 (stack43)
        %vm73521_vm3 = vcmp.eq.f32.partialorder %v143638_v61, inf (stack70)
        %v74294_v26 = vxor.u32 %v74293_v22, %v74285_v20 (stack48)
        %v74683_v52 = vxor.u32 %v74682_v21, %v74678_v10 (stack48)
        %v75129_v40 = vadd.s32 %v75125_v41, %v75113_v50 (stack40)
        %v75131_v6 = vshll.u32 %v75125_v41, 17 (stack45)
        %120135 = vst [vmem:[%s123356_s30 + $0x1cc] sm:$0xf] /*vst_source=*/%v73150_v29 (stack83)
        %v120138_v60 = vadd.low.f32.bf16 -1.0, %v73891_v44 (stack53)
        %v75132_v42 = vshrl.u32 %v75125_v41, 15 (stack46)
        %v75559_v9 = vxor.u32 %v75558_v31, %v75554_v30 (stack48)
        %v143674_v45 = vadd.s32 %v157539_v23, %v157078_v48 (stack40)
        %v74297_v7 = vadd.s32 %v74294_v26, %v121564_v0 (stack40)
        %v74686_v10 = vadd.s32 %v74683_v52, %v74678_v10 (stack40)
        %v74688_v8 = vshll.u32 %v74683_v52, 15 (stack45)
        %v74689_v43 = vshrl.u32 %v74683_v52, 17 (stack46)
        %v73900_v27 = vmul.f32 2.0, %v120138_v60 (stack54)
        %v74289_v20 = vadd.s32 %v74285_v20, %v121569_v1 (stack40)
        %v75133_v50 = vor.u32 %v75132_v42, %v75131_v6 (stack47)
        %v143678_v30 = vadd.s32 %v75559_v9, %v75554_v30 (stack40)
        %v143683_v56 = vsel /*vm=*/%vm73476_vm0, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v73509_v34 = vsel /*vm=*/%vm73476_vm0, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v74301_v22 = vadd.s32 4, %v74297_v7 (stack40)
        %v74690_v21 = vor.u32 %v74689_v43, %v74688_v8 (stack47)
        %vm73523_vm4 = vcmp.eq.f32.partialorder %v143638_v61, 0.0 (stack71)
        %v73904_v41 = vadd.f32 -0.99609375, %v73900_v27 (stack53)
        %v75134_v31 = vxor.u32 %v75133_v50, %v75129_v40 (stack48)
        %v143691_v29 = vadd.s32 %v157536_v46, %v157079_v39 (stack40)
        %v121060_v44 = vpop.eup %121059 (stack73)
        %v74305_v26 = vadd.s32 %v74301_v22, %v74289_v20 (stack40)
        %v74307_v52 = vshll.u32 %v74301_v22, 13 (stack45)
        %v74308_v6 = vshrl.u32 %v74301_v22, 19 (stack46)
        %v74691_v60 = vxor.u32 %v74690_v21, %v74686_v10 (stack48)
        %v73520_v42 = vmul.f32 %v121060_v44, %v143638_v61 (stack74)
        %v73524_v7 = vand.u32 2147483648, %v143638_v61 (stack72)
        %v143695_v8 = vmax.f32 %v73904_v41, -0.99609375 (stack55)
        %v75137_v40 = vadd.s32 %v75134_v31, %v75129_v40 (stack40)
        %v74309_v43 = vor.u32 %v74308_v6, %v74307_v52 (stack47)
        %v74694_v10 = vadd.s32 %v74691_v60, %v74686_v10 (stack40)
        %v74696_v27 = vshll.u32 %v74691_v60, 26 (stack45)
        %v74697_v20 = vshrl.u32 %v74691_v60, 6 (stack46)
        %v73522_v50 = vsel /*vm=*/%vm73521_vm3, /*on_true_vy=*/%v143638_v61, /*on_false_vx=*/%v73520_v42 (stack75)
        %v73920_v22 = vxor.u32 2147483648, %v143695_v8 (stack56)
        %v75564_v21 = vshll.u32 %v75559_v9, 26 (stack45)
        %v75565_v9 = vshrl.u32 %v75559_v9, 6 (stack46)
        %v73513_v41 = vsel /*vm=*/%vm73476_vm0, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v73525_v44 = vsel /*vm=*/%vm73523_vm4, /*on_true_vy=*/%v73524_v7, /*on_false_vx=*/%v73522_v50 (stack76)
        %v74310_v52 = vxor.u32 %v74309_v43, %v74305_v26 (stack48)
        %v74698_v6 = vor.u32 %v74697_v20, %v74696_v27 (stack47)
        %v73528_v60 = vadd.f32 -3.0, %v73525_v44 (stack53)
        %v73923_v42 = vmul.f32 %v73920_v22, %v143695_v8 (stack54)
        %v75139_v7 = vshll.u32 %v75134_v31, 29 (stack45)
        %v75140_v31 = vshrl.u32 %v75134_v31, 3 (stack46)
        %v74313_v26 = vadd.s32 %v74310_v52, %v74305_v26 (stack40)
        %v74315_v43 = vshll.u32 %v74310_v52, 15 (stack45)
        %v74316_v27 = vshrl.u32 %v74310_v52, 17 (stack46)
        %v74699_v20 = vxor.u32 %v74698_v6, %v74694_v10 (stack48)
        %vm75968_vm5 = vcmp.lt.u32.totalorder %v143650_v54, %v143561_v12 (stack43)
        %v143712_v24 = vsel /*vm=*/%vm73476_vm0, /*on_true_vy=*/%v143645_v24, /*on_false_vx=*/%v73528_v60 (stack44)
        %v73925_v50 = vadd.f32 1.0, %v73923_v42 (stack57)
        %v73928_v22 = vmul.f32 -0.5, %v73923_v42 (stack59)
        %v75566_v21 = vor.u32 %v75565_v9, %v75564_v21 (stack47)
        %v73536_v9 = vmul.f32 %v143712_v24, %v73513_v41 (stack54)
        %v74317_v41 = vor.u32 %v74316_v27, %v74315_v43 (stack47)
        %v74702_v10 = vadd.s32 %v74699_v20, %v74694_v10 (stack40)
        %v74708_v44 = vshll.u32 %v74699_v20, 6 (stack45)
        %121061 = vlog2.f32 %v73925_v50 (stack58)
        %v74709_v52 = vshrl.u32 %v74699_v20, 26 (stack46)
        %v75982_v6 = vadd.s32 1, %v143674_v45 (stack40)
        %v143718_v60 = vadd.s32 %v143650_v54, %v121569_v1 (stack40)
        %v73540_v34 = vadd.f32 %v73536_v9, %v73509_v34 (stack53)
        %v73931_v43 = vand.u32 2147483647, %v73923_v42 (stack60)
        %v74318_v27 = vxor.u32 %v74317_v41, %v74313_v26 (stack48)
        %v75141_v7 = vor.u32 %v75140_v31, %v75139_v7 (stack47)
        %v73929_v31 = vadd.f32 1.0, %v73928_v22 (stack61)
        %v74710_v20 = vor.u32 %v74709_v52, %v74708_v44 (stack47)
        %v75567_v50 = vxor.u32 %v75566_v21, %v143678_v30 (stack48)
        %v75986_v45 = vsel /*vm=*/%vm75973_vm2, /*on_true_vy=*/%v75982_v6, /*on_false_vx=*/%v143674_v45 (stack44)
        %v73544_v22 = vmul.f32 %v73540_v34, %v143712_v24 (stack54)
        %v74321_v26 = vadd.s32 %v74318_v27, %v74313_v26 (stack40)
        %v74323_v21 = vshll.u32 %v74318_v27, 26 (stack45)
        %v74324_v9 = vshrl.u32 %v74318_v27, 6 (stack46)
        %v74711_v41 = vxor.u32 %v74710_v20, %v74702_v10 (stack48)
        %v75142_v44 = vxor.u32 %v75141_v7, %v75137_v40 (stack48)
        %v75570_v30 = vadd.s32 %v75567_v50, %v143678_v30 (stack40)
        %v75576_v52 = vshll.u32 %v75567_v50, 6 (stack45)
        %v73548_v56 = vadd.f32 %v73544_v22, %v143683_v56 (stack53)
        %v74325_v6 = vor.u32 %v74324_v9, %v74323_v21 (stack47)
        %v75577_v34 = vshrl.u32 %v75567_v50, 26 (stack46)
        %v75990_v27 = vadd.s32 1, %v75986_v45 (stack40)
        %v74714_v7 = vadd.s32 %v74711_v41, %v121569_v1 (stack40)
        %v75145_v40 = vadd.s32 %v75142_v44, %v75137_v40 (stack40)
        %v75147_v20 = vshll.u32 %v75142_v44, 16 (stack45)
        %v75148_v50 = vshrl.u32 %v75142_v44, 16 (stack46)
        %v73552_v22 = vmul.f32 %v73548_v56, %v143712_v24 (stack54)
        %vm143730_vm6 = vcmp.lt.f32.partialorder %v73931_v43, 0.0004427343 (stack62)
        %v74326_v21 = vxor.u32 %v74325_v6, %v74321_v26 (stack48)
        %v75578_v9 = vor.u32 %v75577_v34, %v75576_v52 (stack47)
        %v74706_v10 = vadd.s32 %v74702_v10, %v121574_v2 (stack40)
        %v74718_v41 = vadd.s32 3, %v74714_v7 (stack40)
        %v75149_v44 = vor.u32 %v75148_v50, %v75147_v20 (stack47)
        %v75994_v12 = vsel /*vm=*/%vm75968_vm5, /*on_true_vy=*/%v75990_v27, /*on_false_vx=*/%v75986_v45 (stack44)
        %v73556_v54 = vadd.f32 %v73552_v22, %v143666_v32 (stack53)
        %v74329_v32 = vadd.s32 %v74326_v21, %v74321_v26 (stack40)
        %v74335_v45 = vshll.u32 %v74326_v21, 6 (stack45)
        %v74336_v26 = vshrl.u32 %v74326_v21, 26 (stack46)
        %v74722_v52 = vadd.s32 %v74718_v41, %v74706_v10 (stack40)
        %v74724_v56 = vshll.u32 %v74718_v41, 17 (stack45)
        %v74725_v6 = vshrl.u32 %v74718_v41, 15 (stack46)
        %v75150_v34 = vxor.u32 %v75149_v44, %v75145_v40 (stack48)
        %v73560_v27 = vmul.f32 %v73556_v54, %v143712_v24 (stack54)
        %v73930_v42 = vmul.f32 %v73929_v31, %v73923_v42 (stack63)
        %v74337_v31 = vor.u32 %v74336_v26, %v74335_v45 (stack47)
        %v75579_v7 = vxor.u32 %v75578_v9, %v75570_v30 (stack48)
        %v74726_v20 = vor.u32 %v74725_v6, %v74724_v56 (stack47)
        %v75153_v40 = vadd.s32 %v75150_v34, %v75145_v40 (stack40)
        %v75159_v50 = vshll.u32 %v75150_v34, 24 (stack45)
        %v75160_v22 = vshrl.u32 %v75150_v34, 8 (stack46)
        %v121062_v21 = vpop.eup %121061 (stack64)
        %v73564_v53 = vadd.f32 %v73560_v27, %v143660_v53 (stack53)
        %v74338_v9 = vxor.u32 %v74337_v31, %v74329_v32 (stack48)
        %v75582_v10 = vadd.s32 %v75579_v7, %v121564_v0 (stack40)
        %v75999_v41 = vadd.s32 %v75994_v12, %v121574_v2 (stack40)
        %v73927_v44 = vmul.f32 0.6931472, %v121062_v21 (stack65)
        %v74727_v12 = vxor.u32 %v74726_v20, %v74722_v52 (stack48)
        %v75161_v54 = vor.u32 %v75160_v22, %v75159_v50 (stack47)
        %v75574_v30 = vadd.s32 %v75570_v30, %v121569_v1 (stack40)
        %v73568_v45 = vmul.f32 %v73564_v53, %v143712_v24 (stack54)
        %v74341_v26 = vadd.s32 %v74338_v9, %v121574_v2 (stack40)
        %v75586_v56 = vadd.s32 1, %v75582_v10 (stack40)
        %v143747_v6 = vadd.s32 %v143718_v60, %v75999_v41 (stack40)
        %v73933_v43 = vsel /*vm=*/%vm143730_vm6, /*on_true_vy=*/%v73930_v42, /*on_false_vx=*/%v73927_v44 (stack66)
        %v74730_v52 = vadd.s32 %v74727_v12, %v74722_v52 (stack40)
        %v74732_v34 = vshll.u32 %v74727_v12, 29 (stack45)
        %v74733_v27 = vshrl.u32 %v74727_v12, 3 (stack46)
        %v73572_v55 = vadd.f32 %v73568_v45, %v143655_v55 (stack53)
        %v143752_v42 = vxor.u32 2147483648, %v73933_v43 (stack56)
        %v74345_v31 = vadd.s32 5, %v74341_v26 (stack40)
        %v75162_v7 = vxor.u32 %v75161_v54, %v75153_v40 (stack48)
        %v74333_v32 = vadd.s32 %v74329_v32, %v121564_v0 (stack40)
        %v74734_v20 = vor.u32 %v74733_v27, %v74732_v34 (stack47)
        %v75590_v50 = vadd.s32 %v75586_v56, %v75574_v30 (stack40)
        %v73449_v22 = vand.u32 2147483647, %v143591_v25 (stack77)
        %v73576_v21 = vmul.f32 %v73572_v55, %v143712_v24 (stack54)
        %121063 = vrsqrt.f32 %v143752_v42 (stack67)
        %v73457_v53 = vmul.f32 inf, %v143591_v25 (stack54)
        %v73489_v9 = vsel /*vm=*/%vm73476_vm0, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %vm73937_vm7 = vcmp.lt.f32.partialorder %v143752_v42, 5.0 (stack68)
        %v74347_v10 = vxor.u32 %v74345_v31, %v74333_v32 (stack48)
        %v73481_v41 = vsel /*vm=*/%vm73476_vm0, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v73580_v44 = vadd.f32 %v73576_v21, %v73489_v9 (stack53)
        %v75592_v12 = vshll.u32 %v75586_v56, 17 (stack45)
        %v75593_v54 = vshrl.u32 %v75586_v56, 15 (stack46)
        %v73485_v61 = vsel /*vm=*/%vm73476_vm0, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v74735_v30 = vxor.u32 %v74734_v20, %v74730_v52 (stack48)
        %v75157_v40 = vadd.s32 %v75153_v40, %v121564_v0 (stack40)
        %v76009_v45 = vshll.u32 %v143718_v60, 13 (stack45)
        %v73584_v26 = vmul.f32 %v73580_v44, %v143712_v24 (stack54)
        %v143775_v56 = vsel /*vm=*/%vm73937_vm7, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v143780_v43 = vsel /*vm=*/%vm73937_vm7, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v143783_v34 = vadd.f32 -2.5, %v143752_v42 (stack53)
        %vm143785_vm8 = vcmp.eq.f32.partialorder %v73449_v22, 1.0 (stack68)
        %v74348_v55 = vand.u32.u8 255, %v74347_v10 (stack49)
        %v74738_v52 = vadd.s32 %v74735_v30, %v74730_v52 (stack40)
        %v74740_v31 = vshll.u32 %v74735_v30, 16 (stack45)
        %v74741_v32 = vshrl.u32 %v74735_v30, 16 (stack46)
        %v73588_v20 = vadd.f32 %v73584_v26, %v73485_v61 (stack53)
        %v75165_v7 = vadd.s32 %v75162_v7, %v121574_v2 (stack40)
        %v75594_v22 = vor.u32 %v75593_v54, %v75592_v12 (stack47)
        %v76010_v60 = vshrl.u32 %v143718_v60, 19 (stack46)
        %vm73982_vm9 = vcmp.eq.f32.partialorder %v143752_v42, inf (stack70)
        %v74349_v21 = vand.u32 65535, %v74348_v55 (stack50)
        %v74742_v9 = vor.u32 %v74741_v32, %v74740_v31 (stack47)
        %vm76434_vm10 = vcmp.lt.u32.totalorder %v143691_v29, %v157079_v39 (stack43)
        %v73592_v24 = vmul.f32 %v73588_v20, %v143712_v24 (stack54)
        %vm73984_vm11 = vcmp.eq.f32.partialorder %v143752_v42, 0.0 (stack71)
        %v75169_v10 = vadd.s32 2, %v75165_v7 (stack40)
        %v75595_v44 = vxor.u32 %v75594_v22, %v75590_v50 (stack48)
        %v74350_v12 = vshrl.u32 %v74349_v21, 1 (stack51)
        %v74743_v54 = vxor.u32 %v74742_v9, %v74738_v52 (stack48)
        %v76011_v61 = vor.u32 %v76010_v60, %v76009_v45 (stack47)
        %v143798_v30 = vadd.s32 %v157539_v23, %v157082_v49 (stack40)
        %v73596_v41 = vadd.f32 %v73592_v24, %v73481_v41 (stack53)
        %v75173_v40 = vadd.s32 %v75169_v10, %v75157_v40 (stack40)
        %v75175_v45 = vshll.u32 %v75169_v10, 13 (stack45)
        %v75176_v26 = vshrl.u32 %v75169_v10, 19 (stack46)
        %v74351_v55 = vor.u32 16256, %v74350_v12 (stack47)
        %v74746_v52 = vadd.s32 %v74743_v54, %v74738_v52 (stack40)
        %v74752_v31 = vshll.u32 %v74743_v54, 24 (stack45)
        %v74753_v32 = vshrl.u32 %v74743_v54, 8 (stack46)
        %v73600_v25 = vmul.f32 %v73596_v41, %v143591_v25 (stack54)
        %v75177_v20 = vor.u32 %v75176_v26, %v75175_v45 (stack47)
        %v75598_v50 = vadd.s32 %v75595_v44, %v75590_v50 (stack40)
        %v75600_v7 = vshll.u32 %v75595_v44, 29 (stack45)
        %v121064_v22 = vpop.eup %121063 (stack73)
        %v73985_v60 = vand.u32 2147483648, %v143752_v42 (stack72)
        %v74352_v21 = vand.u32.u16 65535, %v74351_v55 (stack52)
        %v74754_v9 = vor.u32 %v74753_v32, %v74752_v31 (stack47)
        %v75601_v24 = vshrl.u32 %v75595_v44, 3 (stack46)
        %v73604_v53 = vsel /*vm=*/%vm143785_vm8, /*on_true_vy=*/%v73457_v53, /*on_false_vx=*/%v73600_v25 (stack44)
        %v73981_v27 = vmul.f32 %v121064_v22, %v143752_v42 (stack74)
        %v75178_v10 = vxor.u32 %v75177_v20, %v75173_v40 (stack48)
        %v76012_v44 = vxor.u32 %v76011_v61, %v143747_v6 (stack48)
        %v73608_v12 = vmul.f32 1.4140625, %v73604_v53 (stack54)
        %v120140_v54 = vadd.low.f32.bf16 -1.0, %v74352_v21 (stack53)
        %v74755_v61 = vxor.u32 %v74754_v9, %v74746_v52 (stack48)
        %v75602_v41 = vor.u32 %v75601_v24, %v75600_v7 (stack47)
        %v73983_v45 = vsel /*vm=*/%vm73982_vm9, /*on_true_vy=*/%v143752_v42, /*on_false_vx=*/%v73981_v27 (stack75)
        %v75181_v40 = vadd.s32 %v75178_v10, %v75173_v40 (stack40)
        %v75183_v26 = vshll.u32 %v75178_v10, 15 (stack45)
        %v75184_v55 = vshrl.u32 %v75178_v10, 17 (stack46)
        %v73611_v31 = vpack.c.bf16 %v157387_v11, %v73608_v12 (stack81)
        %v73986_v32 = vsel /*vm=*/%vm73984_vm11, /*on_true_vy=*/%v73985_v60, /*on_false_vx=*/%v73983_v45 (stack76)
        %v74361_v25 = vmul.f32 2.0, %v120140_v54 (stack54)
        %v74758_v20 = vadd.s32 %v74755_v61, %v121564_v0 (stack40)
        %v73989_v7 = vadd.f32 -3.0, %v73986_v32 (stack53)
        %v75185_v22 = vor.u32 %v75184_v55, %v75183_v26 (stack47)
        %v75603_v60 = vxor.u32 %v75602_v41, %v75598_v50 (stack48)
        %v76015_v6 = vadd.s32 %v76012_v44, %v143747_v6 (stack40)
        %120137 = vst [vmem:[%s123356_s30 + $0x24c] sm:$0xf] /*vst_source=*/%v73611_v31 (stack83)
        %v74365_v21 = vadd.f32 -0.99609375, %v74361_v25 (stack53)
        %v74750_v52 = vadd.s32 %v74746_v52, %v121569_v1 (stack40)
        %v74762_v9 = vadd.s32 4, %v74758_v20 (stack40)
        %v76017_v24 = vshll.u32 %v76012_v44, 15 (stack45)
        %v143819_v34 = vsel /*vm=*/%vm73937_vm7, /*on_true_vy=*/%v143783_v34, /*on_false_vx=*/%v73989_v7 (stack44)
        %v75186_v53 = vxor.u32 %v75185_v22, %v75181_v40 (stack48)
        %v75606_v50 = vadd.s32 %v75603_v60, %v75598_v50 (stack40)
        %v76018_v27 = vshrl.u32 %v76012_v44, 17 (stack46)
        %v73997_v43 = vmul.f32 %v143819_v34, %v143780_v43 (stack54)
        %v143823_v10 = vmax.f32 %v74365_v21, -0.99609375 (stack55)
        %v74766_v44 = vadd.s32 %v74762_v9, %v74750_v52 (stack40)
        %v74768_v12 = vshll.u32 %v74762_v9, 13 (stack45)
        %v74769_v54 = vshrl.u32 %v74762_v9, 19 (stack46)
        %v75189_v61 = vadd.s32 %v75186_v53, %v75181_v40 (stack40)
        %v75191_v41 = vshll.u32 %v75186_v53, 26 (stack45)
        %v75192_v45 = vshrl.u32 %v75186_v53, 6 (stack46)
        %v73910_v40 = vand.u32 2147483647, %v143695_v8 (stack77)
        %v74001_v56 = vadd.f32 %v73997_v43, %v143775_v56 (stack53)
        %v74381_v26 = vxor.u32 2147483648, %v143823_v10 (stack56)
        %v75608_v55 = vshll.u32 %v75603_v60, 16 (stack45)
        %v74770_v31 = vor.u32 %v74769_v54, %v74768_v12 (stack47)
        %v75193_v32 = vor.u32 %v75192_v45, %v75191_v41 (stack47)
        %v75609_v25 = vshrl.u32 %v75603_v60, 16 (stack46)
        %v76019_v20 = vor.u32 %v76018_v27, %v76017_v24 (stack47)
        %v143831_v7 = vsel /*vm=*/%vm73937_vm7, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v73954_v22 = vsel /*vm=*/%vm73937_vm7, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v74005_v60 = vmul.f32 %v74001_v56, %v143819_v34 (stack54)
        %v143838_v21 = vmul.f32 %v74381_v26, %v143823_v10 (stack54)
        %v73966_v52 = vsel /*vm=*/%vm73937_vm7, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v74771_v9 = vxor.u32 %v74770_v31, %v74766_v44 (stack48)
        %v75194_v24 = vxor.u32 %v75193_v32, %v75189_v61 (stack48)
        %v76020_v53 = vxor.u32 %v76019_v20, %v76015_v6 (stack48)
        %v73958_v27 = vsel /*vm=*/%vm73937_vm7, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v74009_v43 = vadd.f32 %v74005_v60, %v73966_v52 (stack53)
        %v74386_v12 = vadd.f32 1.0, %v143838_v21 (stack57)
        %v75610_v54 = vor.u32 %v75609_v25, %v75608_v55 (stack47)
        %v74774_v44 = vadd.s32 %v74771_v9, %v74766_v44 (stack40)
        %v74776_v41 = vshll.u32 %v74771_v9, 15 (stack45)
        %v74777_v45 = vshrl.u32 %v74771_v9, 17 (stack46)
        %v75197_v61 = vadd.s32 %v75194_v24, %v75189_v61 (stack40)
        %v73962_v56 = vsel /*vm=*/%vm73937_vm7, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v74013_v26 = vmul.f32 %v74009_v43, %v143819_v34 (stack54)
        %121065 = vlog2.f32 %v74386_v12 (stack58)
        %v143853_v55 = vadd.s32 %v143691_v29, %v122657_v58 (stack40)
        %v74778_v31 = vor.u32 %v74777_v45, %v74776_v41 (stack47)
        %v75203_v32 = vshll.u32 %v75194_v24, 6 (stack45)
        %v75204_v25 = vshrl.u32 %v75194_v24, 26 (stack46)
        %v76443_v20 = vadd.s32 1, %v143798_v30 (stack40)
        %v74017_v60 = vadd.f32 %v74013_v26, %v73962_v56 (stack53)
        %v74389_v52 = vmul.f32 -0.5, %v143838_v21 (stack59)
        %v75611_v9 = vxor.u32 %v75610_v54, %v75606_v50 (stack48)
        %v76023_v6 = vadd.s32 %v76020_v53, %v76015_v6 (stack40)
        %v74779_v24 = vxor.u32 %v74778_v31, %v74774_v44 (stack48)
        %v75205_v43 = vor.u32 %v75204_v25, %v75203_v32 (stack47)
        %v76025_v12 = vshll.u32 %v76020_v53, 26 (stack45)
        %v76026_v53 = vshrl.u32 %v76020_v53, 6 (stack46)
        %v74021_v54 = vmul.f32 %v74017_v60, %v143819_v34 (stack54)
        %v75614_v50 = vadd.s32 %v75611_v9, %v75606_v50 (stack40)
        %v75620_v41 = vshll.u32 %v75611_v9, 24 (stack45)
        %v75621_v45 = vshrl.u32 %v75611_v9, 8 (stack46)
        %v74782_v44 = vadd.s32 %v74779_v24, %v74774_v44 (stack40)
        %v74784_v56 = vshll.u32 %v74779_v24, 26 (stack45)
        %v74785_v26 = vshrl.u32 %v74779_v24, 6 (stack46)
        %v75206_v31 = vxor.u32 %v75205_v43, %v75197_v61 (stack48)
        %vm76429_vm12 = vcmp.lt.u32.totalorder %v143853_v55, %v143691_v29 (stack43)
        %v74025_v27 = vadd.f32 %v74021_v54, %v73958_v27 (stack53)
        %v74392_v32 = vand.u32 2147483647, %v143838_v21 (stack60)
        %v75622_v25 = vor.u32 %v75621_v45, %v75620_v41 (stack47)
        %v76027_v60 = vor.u32 %v76026_v53, %v76025_v12 (stack47)
        %v74390_v52 = vadd.f32 1.0, %v74389_v52 (stack61)
        %v74786_v9 = vor.u32 %v74785_v26, %v74784_v56 (stack47)
        %v75209_v24 = vadd.s32 %v75206_v31, %v121569_v1 (stack40)
        %v76447_v30 = vsel /*vm=*/%vm76434_vm10, /*on_true_vy=*/%v76443_v20, /*on_false_vx=*/%v143798_v30 (stack44)
        %v74029_v20 = vmul.f32 %v74025_v27, %v143819_v34 (stack54)
        %v75201_v61 = vadd.s32 %v75197_v61, %v121574_v2 (stack40)
        %v75623_v43 = vxor.u32 %v75622_v25, %v75614_v50 (stack48)
        %v76028_v12 = vxor.u32 %v76027_v60, %v76023_v6 (stack48)
        %v74787_v53 = vxor.u32 %v74786_v9, %v74782_v44 (stack48)
        %v75213_v54 = vadd.s32 3, %v75209_v24 (stack40)
        %v75618_v50 = vadd.s32 %v75614_v50, %v121564_v0 (stack40)
        %v76451_v41 = vadd.s32 1, %v76447_v30 (stack40)
        %v74033_v22 = vadd.f32 %v74029_v20, %v73954_v22 (stack53)
        %v75626_v45 = vadd.s32 %v75623_v43, %v121574_v2 (stack40)
        %v76031_v6 = vadd.s32 %v76028_v12, %v76023_v6 (stack40)
        %v76037_v56 = vshll.u32 %v76028_v12, 6 (stack45)
        %v74790_v44 = vadd.s32 %v74787_v53, %v74782_v44 (stack40)
        %v74796_v26 = vshll.u32 %v74787_v53, 6 (stack45)
        %v74797_v31 = vshrl.u32 %v74787_v53, 26 (stack46)
        %v75217_v27 = vadd.s32 %v75213_v54, %v75201_v61 (stack40)
        %v74037_v25 = vmul.f32 %v74033_v22, %v143819_v34 (stack54)
        %v75219_v60 = vshll.u32 %v75213_v54, 17 (stack45)
        %v75220_v9 = vshrl.u32 %v75213_v54, 15 (stack46)
        %v75630_v24 = vadd.s32 2, %v75626_v45 (stack40)
        %v121066_v20 = vpop.eup %121065 (stack64)
        %v74391_v21 = vmul.f32 %v74390_v52, %v143838_v21 (stack63)
        %vm143872_vm13 = vcmp.lt.f32.partialorder %v74392_v32, 0.0004427343 (stack62)
        %v74798_v52 = vor.u32 %v74797_v31, %v74796_v26 (stack47)
        %v76038_v61 = vshrl.u32 %v76028_v12, 26 (stack46)
        %v74041_v7 = vadd.f32 %v74037_v25, %v143831_v7 (stack53)
        %v74388_v43 = vmul.f32 0.6931472, %v121066_v20 (stack65)
        %v75221_v12 = vor.u32 %v75220_v9, %v75219_v60 (stack47)
        %v75634_v53 = vadd.s32 %v75630_v24, %v75618_v50 (stack40)
        %v74799_v54 = vxor.u32 %v74798_v52, %v74790_v44 (stack48)
        %v75636_v50 = vshll.u32 %v75630_v24, 13 (stack45)
        %v75637_v22 = vshrl.u32 %v75630_v24, 19 (stack46)
        %v76039_v45 = vor.u32 %v76038_v61, %v76037_v56 (stack47)
        %v74045_v56 = vmul.f32 %v74041_v7, %v143819_v34 (stack54)
        %v74394_v26 = vsel /*vm=*/%vm143872_vm13, /*on_true_vy=*/%v74391_v21, /*on_false_vx=*/%v74388_v43 (stack66)
        %v75222_v31 = vxor.u32 %v75221_v12, %v75217_v27 (stack48)
        %v76455_v29 = vsel /*vm=*/%vm76429_vm12, /*on_true_vy=*/%v76451_v41, /*on_false_vx=*/%v76447_v30 (stack44)
        %v73946_v30 = vsel /*vm=*/%vm73937_vm7, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v143886_v41 = vxor.u32 2147483648, %v74394_v26 (stack56)
        %v76040_v25 = vxor.u32 %v76039_v45, %v76031_v6 (stack48)
        %v76464_v55 = vadd.s32 %v143853_v55, %v121569_v1 (stack40)
        %v74049_v60 = vadd.f32 %v74045_v56, %v73946_v30 (stack53)
        %v75225_v27 = vadd.s32 %v75222_v31, %v75217_v27 (stack40)
        %v75227_v9 = vshll.u32 %v75222_v31, 29 (stack45)
        %v75228_v24 = vshrl.u32 %v75222_v31, 3 (stack46)
        %v73918_v20 = vmul.f32 inf, %v143695_v8 (stack54)
        %121067 = vrsqrt.f32 %v143886_v41 (stack67)
        %v74802_v21 = vadd.s32 %v74799_v54, %v121574_v2 (stack40)
        %vm143895_vm14 = vcmp.eq.f32.partialorder %v73910_v40, 1.0 (stack68)
        %v74053_v34 = vmul.f32 %v74049_v60, %v143819_v34 (stack54)
        %vm74398_vm15 = vcmp.lt.f32.partialorder %v143886_v41, 5.0 (stack68)
        %v75638_v32 = vor.u32 %v75637_v22, %v75636_v50 (stack47)
        %v73942_v42 = vsel /*vm=*/%vm73937_vm7, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v75229_v52 = vor.u32 %v75228_v24, %v75227_v9 (stack47)
        %v76470_v61 = vshll.u32 %v76464_v55, 13 (stack45)
        %v76471_v7 = vshrl.u32 %v76464_v55, 19 (stack46)
        %v74057_v43 = vadd.f32 %v74053_v34, %v73942_v42 (stack53)
        %v143905_v12 = vadd.f32 -2.5, %v143886_v41 (stack53)
        %v74794_v44 = vadd.s32 %v74790_v44, %v121564_v0 (stack40)
        %v76035_v6 = vadd.s32 %v76031_v6, %v121569_v1 (stack40)
        %v143912_v54 = vsel /*vm=*/%vm74398_vm15, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v74446_v50 = vand.u32 2147483648, %v143886_v41 (stack72)
        %v74806_v22 = vadd.s32 5, %v74802_v21 (stack40)
        %v75230_v45 = vxor.u32 %v75229_v52, %v75225_v27 (stack48)
        %v74061_v8 = vmul.f32 %v74057_v43, %v143695_v8 (stack54)
        %v75639_v56 = vxor.u32 %v75638_v32, %v75634_v53 (stack48)
        %v76043_v26 = vadd.s32 %v76040_v25, %v121564_v0 (stack40)
        %v76460_v31 = vadd.s32 %v76455_v29, %v121574_v2 (stack40)
        %v74808_v29 = vxor.u32 %v74806_v22, %v74794_v44 (stack48)
        %v75233_v30 = vadd.s32 %v75230_v45, %v75225_v27 (stack40)
        %v75235_v25 = vshll.u32 %v75230_v45, 16 (stack45)
        %v75236_v60 = vshrl.u32 %v75230_v45, 16 (stack46)
        %v74065_v27 = vsel /*vm=*/%vm143895_vm14, /*on_true_vy=*/%v73918_v20, /*on_false_vx=*/%v74061_v8 (stack44)
        %vm74443_vm0 = vcmp.eq.f32.partialorder %v143886_v41, inf (stack70)
        %v75642_v53 = vadd.s32 %v75639_v56, %v75634_v53 (stack40)
        %v75644_v9 = vshll.u32 %v75639_v56, 15 (stack45)
        %v75645_v24 = vshrl.u32 %v75639_v56, 17 (stack46)
        %v74069_v20 = vmul.f32 1.4140625, %v74065_v27 (stack54)
        %vm74445_vm1 = vcmp.eq.f32.partialorder %v143886_v41, 0.0 (stack71)
        %v74809_v21 = vand.u32.u8 255, %v74808_v29 (stack49)
        %v75237_v40 = vor.u32 %v75236_v60, %v75235_v25 (stack47)
        %v76047_v34 = vadd.s32 1, %v76043_v26 (stack40)
        %v75646_v32 = vor.u32 %v75645_v24, %v75644_v9 (stack47)
        %v76468_v55 = vadd.s32 %v76464_v55, %v76460_v31 (stack40)
        %v76472_v42 = vor.u32 %v76471_v7, %v76470_v61 (stack47)
        %v143924_v52 = vadd.s32 %v157536_v46, %v157083_v59 (stack40)
        %v74072_v61 = vpack.c.bf16 %v157387_v11, %v74069_v20 (stack81)
        %v74810_v7 = vand.u32 65535, %v74809_v21 (stack50)
        %v75238_v43 = vxor.u32 %v75237_v40, %v75233_v30 (stack48)
        %v76051_v44 = vadd.s32 %v76047_v34, %v76035_v6 (stack40)
        %v75647_v6 = vxor.u32 %v75646_v32, %v75642_v53 (stack48)
        %v76053_v22 = vshll.u32 %v76047_v34, 17 (stack45)
        %v76054_v45 = vshrl.u32 %v76047_v34, 15 (stack46)
        %v76473_v8 = vxor.u32 %v76472_v42, %v76468_v55 (stack48)
        %120139 = vst [vmem:[%s123356_s30 + $0x2cc] sm:$0xf] /*vst_source=*/%v74072_v61 (stack83)
        %v74811_v56 = vshrl.u32 %v74810_v7, 1 (stack51)
        %v75241_v26 = vadd.s32 %v75238_v43, %v75233_v30 (stack40)
        %v75247_v31 = vshll.u32 %v75238_v43, 24 (stack45)
        %v75248_v29 = vshrl.u32 %v75238_v43, 8 (stack46)
        %v121068_v30 = vpop.eup %121067 (stack73)
        %v75650_v25 = vadd.s32 %v75647_v6, %v75642_v53 (stack40)
        %v75652_v60 = vshll.u32 %v75647_v6, 26 (stack45)
        %v75653_v27 = vshrl.u32 %v75647_v6, 6 (stack46)
        %v76055_v53 = vor.u32 %v76054_v45, %v76053_v22 (stack47)
        %v74442_v9 = vmul.f32 %v121068_v30, %v143886_v41 (stack74)
        %v74812_v24 = vor.u32 16256, %v74811_v56 (stack47)
        %v75245_v20 = vadd.s32 %v75241_v26, %v121569_v1 (stack40)
        %v75249_v21 = vor.u32 %v75248_v29, %v75247_v31 (stack47)
        %v75654_v40 = vor.u32 %v75653_v27, %v75652_v60 (stack47)
        %v76056_v34 = vxor.u32 %v76055_v53, %v76051_v44 (stack48)
        %v76476_v32 = vadd.s32 %v76473_v8, %v76468_v55 (stack40)
        %v76478_v55 = vshll.u32 %v76473_v8, 15 (stack45)
        %v74444_v42 = vsel /*vm=*/%vm74443_vm0, /*on_true_vy=*/%v143886_v41, /*on_false_vx=*/%v74442_v9 (stack75)
        %v74813_v61 = vand.u32.u16 65535, %v74812_v24 (stack52)
        %v75250_v7 = vxor.u32 %v75249_v21, %v75241_v26 (stack48)
        %v76479_v43 = vshrl.u32 %v76473_v8, 17 (stack46)
        %v74447_v50 = vsel /*vm=*/%vm74445_vm1, /*on_true_vy=*/%v74446_v50, /*on_false_vx=*/%v74444_v42 (stack76)
        %v75655_v6 = vxor.u32 %v75654_v40, %v75650_v25 (stack48)
        %v76059_v44 = vadd.s32 %v76056_v34, %v76051_v44 (stack40)
        %v76061_v22 = vshll.u32 %v76056_v34, 29 (stack45)
        %v74450_v45 = vadd.f32 -3.0, %v74447_v50 (stack53)
        %v120142_v8 = vadd.low.f32.bf16 -1.0, %v74813_v61 (stack53)
        %v75253_v56 = vadd.s32 %v75250_v7, %v121564_v0 (stack40)
        %v76062_v26 = vshrl.u32 %v76056_v34, 3 (stack46)
        %v75658_v31 = vadd.s32 %v75655_v6, %v75650_v25 (stack40)
        %v75664_v29 = vshll.u32 %v75655_v6, 6 (stack45)
        %v75665_v30 = vshrl.u32 %v75655_v6, 26 (stack46)
        %v76480_v25 = vor.u32 %v76479_v43, %v76478_v55 (stack47)
        %v143939_v12 = vsel /*vm=*/%vm74398_vm15, /*on_true_vy=*/%v143905_v12, /*on_false_vx=*/%v74450_v45 (stack44)
        %v74822_v60 = vmul.f32 2.0, %v120142_v8 (stack54)
        %v75257_v27 = vadd.s32 4, %v75253_v56 (stack40)
        %v76063_v53 = vor.u32 %v76062_v26, %v76061_v22 (stack47)
        %v74431_v9 = vsel /*vm=*/%vm74398_vm15, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v74458_v54 = vmul.f32 %v143939_v12, %v143912_v54 (stack54)
        %v75666_v24 = vor.u32 %v75665_v30, %v75664_v29 (stack47)
        %v76481_v21 = vxor.u32 %v76480_v25, %v76476_v32 (stack48)
        %v74826_v40 = vadd.f32 -0.99609375, %v74822_v60 (stack53)
        %v75261_v20 = vadd.s32 %v75257_v27, %v75245_v20 (stack40)
        %v75263_v34 = vshll.u32 %v75257_v27, 13 (stack45)
        %v75264_v55 = vshrl.u32 %v75257_v27, 19 (stack46)
        %v74462_v42 = vadd.f32 %v74458_v54, %v74431_v9 (stack53)
        %v75667_v61 = vxor.u32 %v75666_v24, %v75658_v31 (stack48)
        %v76064_v7 = vxor.u32 %v76063_v53, %v76059_v44 (stack48)
        %v76484_v32 = vadd.s32 %v76481_v21, %v76476_v32 (stack40)
        %v143946_v43 = vmax.f32 %v74826_v40, -0.99609375 (stack55)
        %v75265_v50 = vor.u32 %v75264_v55, %v75263_v34 (stack47)
        %v76486_v6 = vshll.u32 %v76481_v21, 26 (stack45)
        %v76487_v22 = vshrl.u32 %v76481_v21, 6 (stack46)
        %v74427_v45 = vsel /*vm=*/%vm74398_vm15, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v74466_v8 = vmul.f32 %v74462_v42, %v143939_v12 (stack54)
        %v75670_v56 = vadd.s32 %v75667_v61, %v121569_v1 (stack40)
        %v76067_v44 = vadd.s32 %v76064_v7, %v76059_v44 (stack40)
        %v74842_v26 = vxor.u32 2147483648, %v143946_v43 (stack56)
        %v75266_v29 = vxor.u32 %v75265_v50, %v75261_v20 (stack48)
        %v75662_v31 = vadd.s32 %v75658_v31, %v121574_v2 (stack40)
        %v76069_v30 = vshll.u32 %v76064_v7, 16 (stack45)
        %v74470_v25 = vadd.f32 %v74466_v8, %v74427_v45 (stack53)
        %v75674_v60 = vadd.s32 3, %v75670_v56 (stack40)
        %v76070_v27 = vshrl.u32 %v76064_v7, 16 (stack46)
        %v76488_v53 = vor.u32 %v76487_v22, %v76486_v6 (stack47)
        %v143958_v9 = vsel /*vm=*/%vm74398_vm15, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v74845_v54 = vmul.f32 %v74842_v26, %v143946_v43 (stack54)
        %v75269_v24 = vadd.s32 %v75266_v29, %v75261_v20 (stack40)
        %v75271_v21 = vshll.u32 %v75266_v29, 15 (stack45)
        %v74474_v40 = vmul.f32 %v74470_v25, %v143939_v12 (stack54)
        %v75272_v20 = vshrl.u32 %v75266_v29, 17 (stack46)
        %v75678_v34 = vadd.s32 %v75674_v60, %v75662_v31 (stack40)
        %v75680_v55 = vshll.u32 %v75674_v60, 17 (stack45)
        %v74411_v42 = vsel /*vm=*/%vm74398_vm15, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v74423_v61 = vsel /*vm=*/%vm74398_vm15, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v74847_v7 = vadd.f32 1.0, %v74845_v54 (stack57)
        %v75681_v50 = vshrl.u32 %v75674_v60, 15 (stack46)
        %v74478_v6 = vadd.f32 %v74474_v40, %v74423_v61 (stack53)
        %v75273_v22 = vor.u32 %v75272_v20, %v75271_v21 (stack47)
        %v76071_v45 = vor.u32 %v76070_v27, %v76069_v30 (stack47)
        %v76489_v8 = vxor.u32 %v76488_v53, %v76484_v32 (stack48)
        %v74419_v56 = vsel /*vm=*/%vm74398_vm15, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %121069 = vlog2.f32 %v74847_v7 (stack58)
        %v74850_v26 = vmul.f32 -0.5, %v74845_v54 (stack59)
        %v75682_v29 = vor.u32 %v75681_v50, %v75680_v55 (stack47)
        %v74482_v31 = vmul.f32 %v74478_v6, %v143939_v12 (stack54)
        %v75274_v30 = vxor.u32 %v75273_v22, %v75269_v24 (stack48)
        %v76072_v25 = vxor.u32 %v76071_v45, %v76067_v44 (stack48)
        %v76492_v32 = vadd.s32 %v76489_v8, %v76484_v32 (stack40)
        %v74853_v60 = vand.u32 2147483647, %v74845_v54 (stack60)
        %v75683_v27 = vxor.u32 %v75682_v29, %v75678_v34 (stack48)
        %v76498_v53 = vshll.u32 %v76489_v8, 6 (stack45)
        %v76499_v21 = vshrl.u32 %v76489_v8, 26 (stack46)
        %v74486_v40 = vadd.f32 %v74482_v31, %v74419_v56 (stack53)
        %v75277_v24 = vadd.s32 %v75274_v30, %v75269_v24 (stack40)
        %v75279_v20 = vshll.u32 %v75274_v30, 26 (stack45)
        %v75280_v55 = vshrl.u32 %v75274_v30, 6 (stack46)
        %v75686_v34 = vadd.s32 %v75683_v27, %v75678_v34 (stack40)
        %v75688_v61 = vshll.u32 %v75683_v27, 29 (stack45)
        %v75689_v7 = vshrl.u32 %v75683_v27, 3 (stack46)
        %v76075_v44 = vadd.s32 %v76072_v25, %v76067_v44 (stack40)
        %v74490_v50 = vmul.f32 %v74486_v40, %v143939_v12 (stack54)
        %v75281_v6 = vor.u32 %v75280_v55, %v75279_v20 (stack47)
        %v76081_v22 = vshll.u32 %v76072_v25, 24 (stack45)
        %v76082_v45 = vshrl.u32 %v76072_v25, 8 (stack46)
        %v74415_v8 = vsel /*vm=*/%vm74398_vm15, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v74851_v56 = vadd.f32 1.0, %v74850_v26 (stack61)
        %v75690_v26 = vor.u32 %v75689_v7, %v75688_v61 (stack47)
        %v76500_v29 = vor.u32 %v76499_v21, %v76498_v53 (stack47)
        %v74494_v31 = vadd.f32 %v74490_v50, %v74415_v8 (stack53)
        %vm143976_vm2 = vcmp.lt.f32.partialorder %v74853_v60, 0.0004427343 (stack62)
        %v75282_v25 = vxor.u32 %v75281_v6, %v75277_v24 (stack48)
        %v76083_v60 = vor.u32 %v76082_v45, %v76081_v22 (stack47)
        %v75691_v27 = vxor.u32 %v75690_v26, %v75686_v34 (stack48)
        %v76501_v53 = vxor.u32 %v76500_v29, %v76492_v32 (stack48)
        %vm76895_vm3 = vcmp.lt.u32.totalorder %v143924_v52, %v157083_v59 (stack43)
        %v76900_v21 = vadd.s32 %v157539_v23, %v157084_v16 (stack40)
        %v74498_v40 = vmul.f32 %v74494_v31, %v143939_v12 (stack54)
        %v75285_v24 = vadd.s32 %v75282_v25, %v75277_v24 (stack40)
        %v75291_v20 = vshll.u32 %v75282_v25, 6 (stack45)
        %v75292_v55 = vshrl.u32 %v75282_v25, 26 (stack46)
        %v75694_v34 = vadd.s32 %v75691_v27, %v75686_v34 (stack40)
        %v75696_v61 = vshll.u32 %v75691_v27, 16 (stack45)
        %v75697_v7 = vshrl.u32 %v75691_v27, 16 (stack46)
        %v76084_v50 = vxor.u32 %v76083_v60, %v76075_v44 (stack48)
        %v74502_v42 = vadd.f32 %v74498_v40, %v74411_v42 (stack53)
        %v74852_v54 = vmul.f32 %v74851_v56, %v74845_v54 (stack63)
        %v75293_v6 = vor.u32 %v75292_v55, %v75291_v20 (stack47)
        %v76504_v22 = vadd.s32 %v76501_v53, %v121564_v0 (stack40)
        %v75698_v45 = vor.u32 %v75697_v7, %v75696_v61 (stack47)
        %v76079_v44 = vadd.s32 %v76075_v44, %v121564_v0 (stack40)
        %v76087_v8 = vadd.s32 %v76084_v50, %v121574_v2 (stack40)
        %v76904_v56 = vadd.s32 1, %v76900_v21 (stack40)
        %v121070_v26 = vpop.eup %121069 (stack64)
        %v74506_v29 = vmul.f32 %v74502_v42, %v143939_v12 (stack54)
        %v75294_v31 = vxor.u32 %v75293_v6, %v75285_v24 (stack48)
        %v76496_v32 = vadd.s32 %v76492_v32, %v121569_v1 (stack40)
        %v76508_v25 = vadd.s32 1, %v76504_v22 (stack40)
        %v74849_v60 = vmul.f32 0.6931472, %v121070_v26 (stack65)
        %v75699_v27 = vxor.u32 %v75698_v45, %v75694_v34 (stack48)
        %v76091_v53 = vadd.s32 2, %v76087_v8 (stack40)
        %v76908_v21 = vsel /*vm=*/%vm76895_vm3, /*on_true_vy=*/%v76904_v56, /*on_false_vx=*/%v76900_v21 (stack44)
        %v74510_v9 = vadd.f32 %v74506_v29, %v143958_v9 (stack53)
        %v75297_v40 = vadd.s32 %v75294_v31, %v121574_v2 (stack40)
        %v143995_v20 = vadd.s32 %v76508_v25, %v76496_v32 (stack40)
        %v76886_v55 = vadd.s32 %v143924_v52, %v122657_v58 (stack40)
        %v74855_v30 = vsel /*vm=*/%vm143976_vm2, /*on_true_vy=*/%v74852_v54, /*on_false_vx=*/%v74849_v60 (stack66)
        %v75702_v34 = vadd.s32 %v75699_v27, %v75694_v34 (stack40)
        %v75708_v61 = vshll.u32 %v75699_v27, 24 (stack45)
        %v75709_v7 = vshrl.u32 %v75699_v27, 8 (stack46)
        %v74514_v12 = vmul.f32 %v74510_v9, %v143939_v12 (stack54)
        %v144002_v50 = vxor.u32 2147483648, %v74855_v30 (stack56)
        %v75301_v42 = vadd.s32 5, %v75297_v40 (stack40)
        %v76095_v54 = vadd.s32 %v76091_v53, %v76079_v44 (stack40)
        %v74371_v6 = vand.u32 2147483647, %v143823_v10 (stack77)
        %v74403_v41 = vsel /*vm=*/%vm74398_vm15, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v75289_v24 = vadd.s32 %v75285_v24, %v121564_v0 (stack40)
        %v75710_v22 = vor.u32 %v75709_v7, %v75708_v61 (stack47)
        %v74518_v45 = vadd.f32 %v74514_v12, %v74403_v41 (stack53)
        %121071 = vrsqrt.f32 %v144002_v50 (stack67)
        %vm74859_vm4 = vcmp.lt.f32.partialorder %v144002_v50, 5.0 (stack68)
        %v75303_v44 = vxor.u32 %v75301_v42, %v75289_v24 (stack48)
        %v76097_v8 = vshll.u32 %v76091_v53, 13 (stack45)
        %v76098_v56 = vshrl.u32 %v76091_v53, 19 (stack46)
        %v74379_v26 = vmul.f32 inf, %v143823_v10 (stack54)
        %v74522_v10 = vmul.f32 %v74518_v45, %v143823_v10 (stack54)
        %v76925_v29 = vadd.s32 %v76886_v55, %v121569_v1 (stack40)
        %vm74374_vm5 = vcmp.eq.f32.partialorder %v74371_v6, 1.0 (stack68)
        %v75711_v31 = vxor.u32 %v75710_v22, %v75702_v34 (stack48)
        %v76514_v32 = vshll.u32 %v76508_v25, 17 (stack45)
        %vm76890_vm6 = vcmp.lt.u32.totalorder %v76886_v55, %v143924_v52 (stack43)
        %v74526_v60 = vsel /*vm=*/%vm74374_vm5, /*on_true_vy=*/%v74379_v26, /*on_false_vx=*/%v74522_v10 (stack44)
        %v144018_v27 = vsel /*vm=*/%vm74859_vm4, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v144021_v53 = vadd.f32 -2.5, %v144002_v50 (stack53)
        %v75706_v9 = vadd.s32 %v75702_v34, %v121569_v1 (stack40)
        %v74530_v40 = vmul.f32 1.4140625, %v74526_v60 (stack54)
        %v75304_v30 = vand.u32.u8 255, %v75303_v44 (stack49)
        %v75714_v34 = vadd.s32 %v75711_v31, %v121564_v0 (stack40)
        %v76099_v61 = vor.u32 %v76098_v56, %v76097_v8 (stack47)
        %v144028_v7 = vsel /*vm=*/%vm74859_vm4, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v76515_v25 = vshrl.u32 %v76508_v25, 15 (stack46)
        %v76912_v12 = vadd.s32 1, %v76908_v21 (stack40)
        %v76931_v42 = vshll.u32 %v76925_v29, 13 (stack45)
        %v74533_v6 = vpack.c.bf16 %v157387_v11, %v74530_v40 (stack81)
        %vm74904_vm7 = vcmp.eq.f32.partialorder %v144002_v50, inf (stack70)
        %v75305_v41 = vand.u32 65535, %v75304_v30 (stack50)
        %v75718_v24 = vadd.s32 4, %v75714_v34 (stack40)
        %v76100_v22 = vxor.u32 %v76099_v61, %v76095_v54 (stack48)
        %vm74906_vm8 = vcmp.eq.f32.partialorder %v144002_v50, 0.0 (stack71)
        %v76516_v45 = vor.u32 %v76515_v25, %v76514_v32 (stack47)
        %v76916_v52 = vsel /*vm=*/%vm76890_vm6, /*on_true_vy=*/%v76912_v12, /*on_false_vx=*/%v76908_v21 (stack44)
        %v76932_v21 = vshrl.u32 %v76925_v29, 19 (stack46)
        %v144037_v55 = vadd.s32 %v157536_v46, %v157089_v17 (stack40)
        %120141 = vst [vmem:[%s123356_s30 + $0x34c] sm:$0xf] /*vst_source=*/%v74533_v6 (stack83)
        %v75306_v44 = vshrl.u32 %v75305_v41, 1 (stack51)
        %v75722_v8 = vadd.s32 %v75718_v24, %v75706_v9 (stack40)
        %v75724_v56 = vshll.u32 %v75718_v24, 13 (stack45)
        %v75725_v26 = vshrl.u32 %v75718_v24, 19 (stack46)
        %v76103_v54 = vadd.s32 %v76100_v22, %v76095_v54 (stack40)
        %v76105_v10 = vshll.u32 %v76100_v22, 15 (stack45)
        %v76106_v31 = vshrl.u32 %v76100_v22, 17 (stack46)
        %v76517_v32 = vxor.u32 %v76516_v45, %v143995_v20 (stack48)
        %v74907_v60 = vand.u32 2147483648, %v144002_v50 (stack72)
        %v75307_v9 = vor.u32 16256, %v75306_v44 (stack47)
        %v75726_v40 = vor.u32 %v75725_v26, %v75724_v56 (stack47)
        %v76921_v30 = vadd.s32 %v76916_v52, %v121574_v2 (stack40)
        %v76107_v34 = vor.u32 %v76106_v31, %v76105_v10 (stack47)
        %v76520_v20 = vadd.s32 %v76517_v32, %v143995_v20 (stack40)
        %v76522_v61 = vshll.u32 %v76517_v32, 29 (stack45)
        %v76523_v25 = vshrl.u32 %v76517_v32, 3 (stack46)
        %v121072_v12 = vpop.eup %121071 (stack73)
        %v75308_v6 = vand.u32.u16 65535, %v75307_v9 (stack52)
        %v75727_v41 = vxor.u32 %v75726_v40, %v75722_v8 (stack48)
        %v76929_v29 = vadd.s32 %v76925_v29, %v76921_v30 (stack40)
        %v76933_v42 = vor.u32 %v76932_v21, %v76931_v42 (stack47)
        %v74903_v24 = vmul.f32 %v121072_v12, %v144002_v50 (stack74)
        %v76108_v22 = vxor.u32 %v76107_v34, %v76103_v54 (stack48)
        %v76524_v45 = vor.u32 %v76523_v25, %v76522_v61 (stack47)
        %vm77356_vm9 = vcmp.lt.u32.totalorder %v144037_v55, %v157089_v17 (stack43)
        %v120148_v52 = vadd.low.f32.bf16 -1.0, %v75308_v6 (stack53)
        %v75730_v21 = vadd.s32 %v75727_v41, %v75722_v8 (stack40)
        %v75732_v44 = vshll.u32 %v75727_v41, 15 (stack45)
        %v75733_v8 = vshrl.u32 %v75727_v41, 17 (stack46)
        %v74905_v56 = vsel /*vm=*/%vm74904_vm7, /*on_true_vy=*/%v144002_v50, /*on_false_vx=*/%v74903_v24 (stack75)
        %v76111_v26 = vadd.s32 %v76108_v22, %v76103_v54 (stack40)
        %v76113_v54 = vshll.u32 %v76108_v22, 26 (stack45)
        %v76114_v10 = vshrl.u32 %v76108_v22, 6 (stack46)
        %v74908_v31 = vsel /*vm=*/%vm74906_vm8, /*on_true_vy=*/%v74907_v60, /*on_false_vx=*/%v74905_v56 (stack76)
        %v75317_v32 = vmul.f32 2.0, %v120148_v52 (stack54)
        %v75734_v60 = vor.u32 %v75733_v8, %v75732_v44 (stack47)
        %v76525_v9 = vxor.u32 %v76524_v45, %v76520_v20 (stack48)
        %v74911_v40 = vadd.f32 -3.0, %v74908_v31 (stack53)
        %v76115_v30 = vor.u32 %v76114_v10, %v76113_v54 (stack47)
        %v144052_v34 = vxor.u32 %v76933_v42, %v76929_v29 (stack48)
        %v144056_v61 = vadd.s32 %v157539_v23, %v157090_v62 (stack40)
        %v75321_v25 = vadd.f32 -0.99609375, %v75317_v32 (stack53)
        %v75735_v12 = vxor.u32 %v75734_v60, %v75730_v21 (stack48)
        %v76528_v20 = vadd.s32 %v76525_v9, %v76520_v20 (stack40)
        %v76530_v6 = vshll.u32 %v76525_v9, 16 (stack45)
        %v144061_v53 = vsel /*vm=*/%vm74859_vm4, /*on_true_vy=*/%v144021_v53, /*on_false_vx=*/%v74911_v40 (stack44)
        %v76116_v41 = vxor.u32 %v76115_v30, %v76111_v26 (stack48)
        %v76531_v42 = vshrl.u32 %v76525_v9, 16 (stack46)
        %v144064_v29 = vadd.s32 %v144052_v34, %v76929_v29 (stack40)
        %v74919_v7 = vmul.f32 %v144061_v53, %v144028_v7 (stack54)
        %v144068_v24 = vmax.f32 %v75321_v25, -0.99609375 (stack55)
        %v75738_v22 = vadd.s32 %v75735_v12, %v75730_v21 (stack40)
        %v75740_v45 = vshll.u32 %v75735_v12, 26 (stack45)
        %v75741_v52 = vshrl.u32 %v75735_v12, 6 (stack46)
        %v76119_v21 = vadd.s32 %v76116_v41, %v76111_v26 (stack40)
        %v76125_v44 = vshll.u32 %v76116_v41, 6 (stack45)
        %v76126_v8 = vshrl.u32 %v76116_v41, 26 (stack46)
        %v74832_v56 = vand.u32 2147483647, %v143946_v43 (stack77)
        %v144074_v26 = vsel /*vm=*/%vm74859_vm4, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v74923_v27 = vadd.f32 %v74919_v7, %v144018_v27 (stack53)
        %v75337_v54 = vxor.u32 2147483648, %v144068_v24 (stack56)
        %v74876_v10 = vsel /*vm=*/%vm74859_vm4, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v75742_v31 = vor.u32 %v75741_v52, %v75740_v45 (stack47)
        %v76127_v32 = vor.u32 %v76126_v8, %v76125_v44 (stack47)
        %v76532_v60 = vor.u32 %v76531_v42, %v76530_v6 (stack47)
        %v74880_v9 = vsel /*vm=*/%vm74859_vm4, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v74884_v40 = vsel /*vm=*/%vm74859_vm4, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v74927_v30 = vmul.f32 %v74923_v27, %v144061_v53 (stack54)
        %v75340_v25 = vmul.f32 %v75337_v54, %v144068_v24 (stack54)
        %v74888_v12 = vsel /*vm=*/%vm74859_vm4, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v75743_v6 = vxor.u32 %v75742_v31, %v75738_v22 (stack48)
        %v76128_v41 = vxor.u32 %v76127_v32, %v76119_v21 (stack48)
        %v76533_v42 = vxor.u32 %v76532_v60, %v76528_v20 (stack48)
        %v74931_v7 = vadd.f32 %v74927_v30, %v74888_v12 (stack53)
        %v75342_v45 = vadd.f32 1.0, %v75340_v25 (stack57)
        %v76939_v52 = vshll.u32 %v144052_v34, 15 (stack45)
        %v144095_v44 = vadd.s32 %v144037_v55, %v122657_v58 (stack40)
        %v75746_v22 = vadd.s32 %v75743_v6, %v75738_v22 (stack40)
        %v75752_v8 = vshll.u32 %v75743_v6, 6 (stack45)
        %v75753_v27 = vshrl.u32 %v75743_v6, 26 (stack46)
        %v76131_v54 = vadd.s32 %v76128_v41, %v121569_v1 (stack40)
        %v74935_v31 = vmul.f32 %v74931_v7, %v144061_v53 (stack54)
        %121073 = vlog2.f32 %v75342_v45 (stack58)
        %v75345_v32 = vmul.f32 -0.5, %v75340_v25 (stack59)
        %v76940_v34 = vshrl.u32 %v144052_v34, 17 (stack46)
        %v75754_v60 = vor.u32 %v75753_v27, %v75752_v8 (stack47)
        %v76123_v21 = vadd.s32 %v76119_v21, %v121574_v2 (stack40)
        %v76135_v30 = vadd.s32 3, %v76131_v54 (stack40)
        %v76536_v20 = vadd.s32 %v76533_v42, %v76528_v20 (stack40)
        %v74939_v40 = vadd.f32 %v74935_v31, %v74884_v40 (stack53)
        %v75348_v12 = vand.u32 2147483647, %v75340_v25 (stack60)
        %v76542_v6 = vshll.u32 %v76533_v42, 24 (stack45)
        %v76543_v41 = vshrl.u32 %v76533_v42, 8 (stack46)
        %vm77351_vm10 = vcmp.lt.u32.totalorder %v144095_v44, %v144037_v55 (stack43)
        %v75755_v42 = vxor.u32 %v75754_v60, %v75746_v22 (stack48)
        %v76139_v7 = vadd.s32 %v76135_v30, %v76123_v21 (stack40)
        %v76141_v45 = vshll.u32 %v76135_v30, 17 (stack45)
        %v76142_v8 = vshrl.u32 %v76135_v30, 15 (stack46)
        %v74943_v27 = vmul.f32 %v74939_v40, %v144061_v53 (stack54)
        %v75346_v54 = vadd.f32 1.0, %v75345_v32 (stack61)
        %v76544_v31 = vor.u32 %v76543_v41, %v76542_v6 (stack47)
        %v76941_v52 = vor.u32 %v76940_v34, %v76939_v52 (stack47)
        %v75750_v22 = vadd.s32 %v75746_v22, %v121564_v0 (stack40)
        %v75758_v32 = vadd.s32 %v75755_v42, %v121574_v2 (stack40)
        %v76143_v34 = vor.u32 %v76142_v8, %v76141_v45 (stack47)
        %v77365_v60 = vadd.s32 1, %v144056_v61 (stack40)
        %v74947_v9 = vadd.f32 %v74943_v27, %v74880_v9 (stack53)
        %v76545_v21 = vxor.u32 %v76544_v31, %v76536_v20 (stack48)
        %v76942_v30 = vxor.u32 %v76941_v52, %v144064_v29 (stack48)
        %v144110_v40 = vadd.s32 %v157536_v46, %v157091_v37 (stack40)
        %vm144112_vm11 = vcmp.lt.f32.partialorder %v75348_v12, 0.0004427343 (stack62)
        %v75762_v6 = vadd.s32 5, %v75758_v32 (stack40)
        %v76144_v41 = vxor.u32 %v76143_v34, %v76139_v7 (stack48)
        %v76540_v20 = vadd.s32 %v76536_v20, %v121564_v0 (stack40)
        %v77369_v61 = vsel /*vm=*/%vm77356_vm9, /*on_true_vy=*/%v77365_v60, /*on_false_vx=*/%v144056_v61 (stack44)
        %v74951_v42 = vmul.f32 %v74947_v9, %v144061_v53 (stack54)
        %v76548_v45 = vadd.s32 %v76545_v21, %v121574_v2 (stack40)
        %v144124_v29 = vadd.s32 %v76942_v30, %v144064_v29 (stack40)
        %v76947_v8 = vshll.u32 %v76942_v30, 26 (stack45)
        %v75764_v27 = vxor.u32 %v75762_v6, %v75750_v22 (stack48)
        %v76147_v7 = vadd.s32 %v76144_v41, %v76139_v7 (stack40)
        %v76149_v31 = vshll.u32 %v76144_v41, 29 (stack45)
        %v76150_v52 = vshrl.u32 %v76144_v41, 3 (stack46)
        %v74955_v10 = vadd.f32 %v74951_v42, %v74876_v10 (stack53)
        %v76552_v22 = vadd.s32 2, %v76548_v45 (stack40)
        %v76948_v32 = vshrl.u32 %v76942_v30, 6 (stack46)
        %v77373_v34 = vadd.s32 1, %v77369_v61 (stack40)
        %v75347_v25 = vmul.f32 %v75346_v54, %v75340_v25 (stack63)
        %v75765_v54 = vand.u32.u8 255, %v75764_v27 (stack49)
        %v76151_v60 = vor.u32 %v76150_v52, %v76149_v31 (stack47)
        %v144128_v9 = vadd.s32 %v144095_v44, %v121569_v1 (stack40)
        %v74959_v21 = vmul.f32 %v74955_v10, %v144061_v53 (stack54)
        %v76556_v30 = vadd.s32 %v76552_v22, %v76540_v20 (stack40)
        %v76558_v6 = vshll.u32 %v76552_v22, 13 (stack45)
        %v76559_v41 = vshrl.u32 %v76552_v22, 19 (stack46)
        %v121074_v20 = vpop.eup %121073 (stack64)
        %v75766_v42 = vand.u32 65535, %v75765_v54 (stack50)
        %v76152_v45 = vxor.u32 %v76151_v60, %v76147_v7 (stack48)
        %v76949_v8 = vor.u32 %v76948_v32, %v76947_v8 (stack47)
        %v77377_v55 = vsel /*vm=*/%vm77351_vm10, /*on_true_vy=*/%v77373_v34, /*on_false_vx=*/%v77369_v61 (stack44)
        %v74963_v26 = vadd.f32 %v74959_v21, %v144074_v26 (stack53)
        %v75344_v44 = vmul.f32 0.6931472, %v121074_v20 (stack65)
        %v76560_v61 = vor.u32 %v76559_v41, %v76558_v6 (stack47)
        %v77382_v27 = vadd.s32 %v77377_v55, %v121574_v2 (stack40)
        %v75767_v31 = vshrl.u32 %v75766_v42, 1 (stack51)
        %v76155_v7 = vadd.s32 %v76152_v45, %v76147_v7 (stack40)
        %v76157_v52 = vshll.u32 %v76152_v45, 16 (stack45)
        %v76158_v10 = vshrl.u32 %v76152_v45, 16 (stack46)
        %v74967_v22 = vmul.f32 %v74963_v26, %v144061_v53 (stack54)
        %v75350_v12 = vsel /*vm=*/%vm144112_vm11, /*on_true_vy=*/%v75347_v25, /*on_false_vx=*/%v75344_v44 (stack66)
        %v76561_v32 = vxor.u32 %v76560_v61, %v76556_v30 (stack48)
        %v76950_v34 = vxor.u32 %v76949_v8, %v144124_v29 (stack48)
        %v74868_v25 = vsel /*vm=*/%vm74859_vm4, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v144143_v54 = vxor.u32 2147483648, %v75350_v12 (stack56)
        %v76159_v60 = vor.u32 %v76158_v10, %v76157_v52 (stack47)
        %v77390_v21 = vadd.s32 %v144128_v9, %v77382_v27 (stack40)
        %v74971_v6 = vadd.f32 %v74967_v22, %v74868_v25 (stack53)
        %v76564_v30 = vadd.s32 %v76561_v32, %v76556_v30 (stack40)
        %121075 = vrsqrt.f32 %v144143_v54 (stack67)
        %v75768_v41 = vor.u32 16256, %v75767_v31 (stack47)
        %v74840_v20 = vmul.f32 inf, %v143946_v43 (stack54)
        %v74975_v53 = vmul.f32 %v74971_v6, %v144061_v53 (stack54)
        %v76566_v42 = vshll.u32 %v76561_v32, 15 (stack45)
        %v76567_v45 = vshrl.u32 %v76561_v32, 17 (stack46)
        %vm144151_vm12 = vcmp.eq.f32.partialorder %v74832_v56, 1.0 (stack68)
        %v74864_v50 = vsel /*vm=*/%vm74859_vm4, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v75327_v8 = vand.u32 2147483647, %v144068_v24 (stack77)
        %v76160_v55 = vxor.u32 %v76159_v60, %v76155_v7 (stack48)
        %v74979_v26 = vadd.f32 %v74975_v53, %v74864_v50 (stack53)
        %vm75354_vm13 = vcmp.lt.f32.partialorder %v144143_v54, 5.0 (stack68)
        %v77392_v44 = vshll.u32 %v144128_v9, 13 (stack45)
        %v77393_v9 = vshrl.u32 %v144128_v9, 19 (stack46)
        %v144163_v61 = vadd.f32 -2.5, %v144143_v54 (stack53)
        %v75769_v27 = vand.u32.u16 65535, %v75768_v41 (stack52)
        %v76163_v31 = vadd.s32 %v76160_v55, %v76155_v7 (stack40)
        %v144167_v7 = vadd.s32 %v144110_v40, %v122657_v58 (stack40)
        %v74983_v43 = vmul.f32 %v74979_v26, %v143946_v43 (stack54)
        %v76169_v52 = vshll.u32 %v76160_v55, 24 (stack45)
        %v76170_v10 = vshrl.u32 %v76160_v55, 8 (stack46)
        %v76568_v22 = vor.u32 %v76567_v45, %v76566_v42 (stack47)
        %v144173_v12 = vsel /*vm=*/%vm75354_vm13, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v120150_v32 = vadd.low.f32.bf16 -1.0, %v75769_v27 (stack53)
        %v76953_v29 = vadd.s32 %v76950_v34, %v144124_v29 (stack40)
        %v76959_v25 = vshll.u32 %v76950_v34, 6 (stack45)
        %v74987_v60 = vsel /*vm=*/%vm144151_vm12, /*on_true_vy=*/%v74840_v20, /*on_false_vx=*/%v74983_v43 (stack44)
        %vm75399_vm14 = vcmp.eq.f32.partialorder %v144143_v54, inf (stack70)
        %v76171_v6 = vor.u32 %v76170_v10, %v76169_v52 (stack47)
        %v76569_v41 = vxor.u32 %v76568_v22, %v76564_v30 (stack48)
        %v76960_v34 = vshrl.u32 %v76950_v34, 26 (stack46)
        %v74991_v20 = vmul.f32 1.4140625, %v74987_v60 (stack54)
        %v144182_v53 = vsel /*vm=*/%vm75354_vm13, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v75778_v42 = vmul.f32 2.0, %v120150_v32 (stack54)
        %v77394_v45 = vor.u32 %v77393_v9, %v77392_v44 (stack47)
        %v76172_v56 = vxor.u32 %v76171_v6, %v76163_v31 (stack48)
        %v76572_v30 = vadd.s32 %v76569_v41, %v76564_v30 (stack40)
        %v76574_v50 = vshll.u32 %v76569_v41, 26 (stack45)
        %v76575_v55 = vshrl.u32 %v76569_v41, 6 (stack46)
        %v74994_v26 = vpack.c.bf16 %v157387_v11, %v74991_v20 (stack81)
        %v75782_v44 = vadd.f32 -0.99609375, %v75778_v42 (stack53)
        %v76961_v9 = vor.u32 %v76960_v34, %v76959_v25 (stack47)
        %v77395_v27 = vxor.u32 %v77394_v45, %v77390_v21 (stack48)
        %v75387_v43 = vsel /*vm=*/%vm75354_vm13, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v76175_v52 = vadd.s32 %v76172_v56, %v121564_v0 (stack40)
        %v76576_v10 = vor.u32 %v76575_v55, %v76574_v50 (stack47)
        %vm77817_vm15 = vcmp.lt.u32.totalorder %v144110_v40, %v157091_v37 (stack43)
        %120143 = vst [vmem:[%s123356_s30 + $0x3cc] sm:$0xf] /*vst_source=*/%v74994_v26 (stack83)
        %v75402_v22 = vand.u32 2147483648, %v144143_v54 (stack72)
        %v144193_v32 = vmax.f32 %v75782_v44, -0.99609375 (stack55)
        %v76962_v25 = vxor.u32 %v76961_v9, %v76953_v29 (stack48)
        %v77398_v21 = vadd.s32 %v77395_v27, %v77390_v21 (stack40)
        %v121076_v60 = vpop.eup %121075 (stack73)
        %v76167_v31 = vadd.s32 %v76163_v31, %v121569_v1 (stack40)
        %v76179_v6 = vadd.s32 4, %v76175_v52 (stack40)
        %v76577_v41 = vxor.u32 %v76576_v10, %v76572_v30 (stack48)
        %v77822_v34 = vadd.s32 %v157539_v23, %v157094_v36 (stack40)
        %v75398_v20 = vmul.f32 %v121076_v60, %v144143_v54 (stack74)
        %v75798_v42 = vxor.u32 2147483648, %v144193_v32 (stack56)
        %v77400_v45 = vshll.u32 %v77395_v27, 15 (stack45)
        %v77401_v56 = vshrl.u32 %v77395_v27, 17 (stack46)
        %v76183_v50 = vadd.s32 %v76179_v6, %v76167_v31 (stack40)
        %v76185_v55 = vshll.u32 %v76179_v6, 13 (stack45)
        %v76186_v26 = vshrl.u32 %v76179_v6, 19 (stack46)
        %v76580_v30 = vadd.s32 %v76577_v41, %v76572_v30 (stack40)
        %v75400_v44 = vsel /*vm=*/%vm75399_vm14, /*on_true_vy=*/%v144143_v54, /*on_false_vx=*/%v75398_v20 (stack75)
        %vm75401_vm0 = vcmp.eq.f32.partialorder %v144143_v54, 0.0 (stack71)
        %v144205_v9 = vmul.f32 %v75798_v42, %v144193_v32 (stack54)
        %v76586_v27 = vshll.u32 %v76577_v41, 6 (stack45)
        %v75391_v52 = vsel /*vm=*/%vm75354_vm13, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v75403_v10 = vsel /*vm=*/%vm75401_vm0, /*on_true_vy=*/%v75402_v22, /*on_false_vx=*/%v75400_v44 (stack76)
        %v76187_v22 = vor.u32 %v76186_v26, %v76185_v55 (stack47)
        %v76587_v60 = vshrl.u32 %v76577_v41, 26 (stack46)
        %v75406_v31 = vadd.f32 -3.0, %v75403_v10 (stack53)
        %v75803_v6 = vadd.f32 1.0, %v144205_v9 (stack57)
        %v75806_v41 = vmul.f32 -0.5, %v144205_v9 (stack59)
        %v76957_v29 = vadd.s32 %v76953_v29, %v121569_v1 (stack40)
        %v76188_v20 = vxor.u32 %v76187_v22, %v76183_v50 (stack48)
        %v76588_v42 = vor.u32 %v76587_v60, %v76586_v27 (stack47)
        %v76965_v25 = vadd.s32 %v76962_v25, %v121564_v0 (stack40)
        %v77402_v45 = vor.u32 %v77401_v56, %v77400_v45 (stack47)
        %v144217_v61 = vsel /*vm=*/%vm75354_vm13, /*on_true_vy=*/%v144163_v61, /*on_false_vx=*/%v75406_v31 (stack44)
        %121077 = vlog2.f32 %v75803_v6 (stack58)
        %v76584_v56 = vadd.s32 %v76580_v30, %v121574_v2 (stack40)
        %vm77812_vm1 = vcmp.lt.u32.totalorder %v144167_v7, %v144110_v40 (stack43)
        %v75414_v55 = vmul.f32 %v144217_v61, %v75391_v52 (stack54)
        %v76191_v50 = vadd.s32 %v76188_v20, %v76183_v50 (stack40)
        %v76193_v26 = vshll.u32 %v76188_v20, 15 (stack45)
        %v76194_v44 = vshrl.u32 %v76188_v20, 17 (stack46)
        %v75809_v27 = vand.u32 2147483647, %v144205_v9 (stack60)
        %v76589_v30 = vxor.u32 %v76588_v42, %v76580_v30 (stack48)
        %v76969_v52 = vadd.s32 1, %v76965_v25 (stack40)
        %v77403_v10 = vxor.u32 %v77402_v45, %v77398_v21 (stack48)
        %v75418_v43 = vadd.f32 %v75414_v55, %v75387_v43 (stack53)
        %v75807_v22 = vadd.f32 1.0, %v75806_v41 (stack61)
        %v76195_v60 = vor.u32 %v76194_v44, %v76193_v26 (stack47)
        %v77826_v31 = vadd.s32 1, %v77822_v34 (stack40)
        %v76592_v6 = vadd.s32 %v76589_v30, %v121569_v1 (stack40)
        %v76973_v41 = vadd.s32 %v76969_v52, %v76957_v29 (stack40)
        %v76975_v29 = vshll.u32 %v76969_v52, 17 (stack45)
        %v76976_v20 = vshrl.u32 %v76969_v52, 15 (stack46)
        %v75422_v42 = vmul.f32 %v75418_v43, %v144217_v61 (stack54)
        %v76196_v25 = vxor.u32 %v76195_v60, %v76191_v50 (stack48)
        %v77406_v21 = vadd.s32 %v77403_v10, %v77398_v21 (stack40)
        %v77408_v45 = vshll.u32 %v77403_v10, 26 (stack45)
        %v76596_v55 = vadd.s32 3, %v76592_v6 (stack40)
        %v76977_v26 = vor.u32 %v76976_v20, %v76975_v29 (stack47)
        %v77409_v44 = vshrl.u32 %v77403_v10, 6 (stack46)
        %v77830_v34 = vsel /*vm=*/%vm77817_vm15, /*on_true_vy=*/%v77826_v31, /*on_false_vx=*/%v77822_v34 (stack44)
        %v75426_v53 = vadd.f32 %v75422_v42, %v144182_v53 (stack53)
        %v76199_v50 = vadd.s32 %v76196_v25, %v76191_v50 (stack40)
        %v76201_v30 = vshll.u32 %v76196_v25, 26 (stack45)
        %v76202_v52 = vshrl.u32 %v76196_v25, 6 (stack46)
        %v76600_v56 = vadd.s32 %v76596_v55, %v76584_v56 (stack40)
        %v76602_v10 = vshll.u32 %v76596_v55, 17 (stack45)
        %v76603_v43 = vshrl.u32 %v76596_v55, 15 (stack46)
        %v76978_v60 = vxor.u32 %v76977_v26, %v76973_v41 (stack48)
        %v75430_v31 = vmul.f32 %v75426_v53, %v144217_v61 (stack54)
        %v76203_v6 = vor.u32 %v76202_v52, %v76201_v30 (stack47)
        %v77410_v29 = vor.u32 %v77409_v44, %v77408_v45 (stack47)
        %v77834_v20 = vadd.s32 1, %v77830_v34 (stack40)
        %v76604_v42 = vor.u32 %v76603_v43, %v76602_v10 (stack47)
        %v76981_v41 = vadd.s32 %v76978_v60, %v76973_v41 (stack40)
        %v76983_v25 = vshll.u32 %v76978_v60, 29 (stack45)
        %v76984_v45 = vshrl.u32 %v76978_v60, 3 (stack46)
        %v75434_v12 = vadd.f32 %v75430_v31, %v144173_v12 (stack53)
        %v76204_v55 = vxor.u32 %v76203_v6, %v76199_v50 (stack48)
        %v144232_v26 = vxor.u32 %v77410_v29, %v77406_v21 (stack48)
        %v77838_v40 = vsel /*vm=*/%vm77812_vm1, /*on_true_vy=*/%v77834_v20, /*on_false_vx=*/%v77830_v34 (stack44)
        %v75375_v44 = vsel /*vm=*/%vm75354_vm13, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v75808_v9 = vmul.f32 %v75807_v22, %v144205_v9 (stack63)
        %v76605_v22 = vxor.u32 %v76604_v42, %v76600_v56 (stack48)
        %v76985_v34 = vor.u32 %v76984_v45, %v76983_v25 (stack47)
        %v121078_v53 = vpop.eup %121077 (stack64)
        %v75438_v30 = vmul.f32 %v75434_v12, %v144217_v61 (stack54)
        %v76207_v50 = vadd.s32 %v76204_v55, %v76199_v50 (stack40)
        %v76213_v52 = vshll.u32 %v76204_v55, 6 (stack45)
        %v76214_v10 = vshrl.u32 %v76204_v55, 26 (stack46)
        %v75805_v43 = vmul.f32 0.6931472, %v121078_v53 (stack65)
        %v76608_v56 = vadd.s32 %v76605_v22, %v76600_v56 (stack40)
        %v76610_v60 = vshll.u32 %v76605_v22, 29 (stack45)
        %v76611_v31 = vshrl.u32 %v76605_v22, 3 (stack46)
        %v75442_v6 = vadd.f32 %v75438_v30, %v75375_v44 (stack53)
        %vm75810_vm2 = vcmp.lt.f32.partialorder %v75809_v27, 0.0004427343 (stack62)
        %v76215_v27 = vor.u32 %v76214_v10, %v76213_v52 (stack47)
        %v76986_v29 = vxor.u32 %v76985_v34, %v76981_v41 (stack48)
        %v75811_v20 = vsel /*vm=*/%vm75810_vm2, /*on_true_vy=*/%v75808_v9, /*on_false_vx=*/%v75805_v43 (stack66)
        %v76612_v42 = vor.u32 %v76611_v31, %v76610_v60 (stack47)
        %v144243_v21 = vadd.s32 %v144232_v26, %v77406_v21 (stack40)
        %v77847_v7 = vadd.s32 %v144167_v7, %v121569_v1 (stack40)
        %v75446_v25 = vmul.f32 %v75442_v6, %v144217_v61 (stack54)
        %v144248_v45 = vxor.u32 2147483648, %v75811_v20 (stack56)
        %v76216_v12 = vxor.u32 %v76215_v27, %v76207_v50 (stack48)
        %v76989_v41 = vadd.s32 %v76986_v29, %v76981_v41 (stack40)
        %v144251_v55 = vmul.f32 inf, %v144068_v24 (stack54)
        %v75359_v44 = vsel /*vm=*/%vm75354_vm13, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v75371_v9 = vsel /*vm=*/%vm75354_vm13, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v76613_v22 = vxor.u32 %v76612_v42, %v76608_v56 (stack48)
        %v75363_v34 = vsel /*vm=*/%vm75354_vm13, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v75367_v54 = vsel /*vm=*/%vm75354_vm13, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v75450_v53 = vadd.f32 %v75446_v25, %v75371_v9 (stack53)
        %121079 = vrsqrt.f32 %v144248_v45 (stack67)
        %vm75815_vm3 = vcmp.lt.f32.partialorder %v144248_v45, 5.0 (stack68)
        %v76219_v30 = vadd.s32 %v76216_v12, %v121574_v2 (stack40)
        %v76991_v52 = vshll.u32 %v76986_v29, 16 (stack45)
        %v76992_v10 = vshrl.u32 %v76986_v29, 16 (stack46)
        %v75454_v43 = vmul.f32 %v75450_v53, %v144217_v61 (stack54)
        %v76211_v50 = vadd.s32 %v76207_v50, %v121564_v0 (stack40)
        %v77843_v40 = vadd.s32 %v77838_v40, %v121574_v2 (stack40)
        %v77853_v60 = vshll.u32 %v77847_v7, 13 (stack45)
        %v144272_v31 = vadd.f32 -2.5, %v144248_v45 (stack53)
        %v76616_v56 = vadd.s32 %v76613_v22, %v76608_v56 (stack40)
        %v77418_v6 = vadd.s32 %v144243_v21, %v121569_v1 (stack40)
        %v77420_v27 = vshll.u32 %v144232_v26, 6 (stack45)
        %v75458_v29 = vadd.f32 %v75454_v43, %v75367_v54 (stack53)
        %v144280_v20 = vsel /*vm=*/%vm75815_vm3, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v144285_v42 = vsel /*vm=*/%vm75815_vm3, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v75863_v25 = vand.u32 2147483648, %v144248_v45 (stack72)
        %v76223_v12 = vadd.s32 5, %v76219_v30 (stack40)
        %v76618_v9 = vshll.u32 %v76613_v22, 16 (stack45)
        %v76619_v22 = vshrl.u32 %v76613_v22, 16 (stack46)
        %v76993_v54 = vor.u32 %v76992_v10, %v76991_v52 (stack47)
        %v75462_v53 = vmul.f32 %v75458_v29, %v144217_v61 (stack54)
        %v77421_v26 = vshrl.u32 %v144232_v26, 26 (stack46)
        %v77851_v30 = vadd.s32 %v77847_v7, %v77843_v40 (stack40)
        %v77854_v7 = vshrl.u32 %v77847_v7, 19 (stack46)
        %vm144292_vm4 = vcmp.eq.f32.partialorder %v75327_v8, 1.0 (stack68)
        %vm75860_vm5 = vcmp.eq.f32.partialorder %v144248_v45, inf (stack70)
        %v76225_v52 = vxor.u32 %v76223_v12, %v76211_v50 (stack48)
        %v76620_v10 = vor.u32 %v76619_v22, %v76618_v9 (stack47)
        %v76994_v43 = vxor.u32 %v76993_v54, %v76989_v41 (stack48)
        %v144299_v46 = vadd.s32 %v157536_v46, %v157095_v13 (stack40)
        %v75466_v34 = vadd.f32 %v75462_v53, %v75363_v34 (stack53)
        %vm75862_vm6 = vcmp.eq.f32.partialorder %v144248_v45, 0.0 (stack71)
        %v77422_v50 = vor.u32 %v77421_v26, %v77420_v27 (stack47)
        %v77855_v40 = vor.u32 %v77854_v7, %v77853_v60 (stack47)
        %v144304_v23 = vadd.s32 %v157539_v23, %v157100_v14 (stack40)
        %v76226_v60 = vand.u32.u8 255, %v76225_v52 (stack49)
        %v76621_v27 = vxor.u32 %v76620_v10, %v76616_v56 (stack48)
        %v76997_v41 = vadd.s32 %v76994_v43, %v76989_v41 (stack40)
        %v77003_v29 = vshll.u32 %v76994_v43, 24 (stack45)
        %v75470_v61 = vmul.f32 %v75466_v34, %v144217_v61 (stack54)
        %v77004_v12 = vshrl.u32 %v76994_v43, 8 (stack46)
        %v77423_v21 = vxor.u32 %v77422_v50, %v144243_v21 (stack48)
        %v77856_v9 = vxor.u32 %v77855_v40, %v77851_v30 (stack48)
        %v76227_v22 = vand.u32 65535, %v76226_v60 (stack50)
        %v76624_v56 = vadd.s32 %v76621_v27, %v76616_v56 (stack40)
        %v76630_v54 = vshll.u32 %v76621_v27, 24 (stack45)
        %v76631_v53 = vshrl.u32 %v76621_v27, 8 (stack46)
        %v75474_v44 = vadd.f32 %v75470_v61, %v75359_v44 (stack53)
        %v77001_v26 = vadd.s32 %v76997_v41, %v121564_v0 (stack40)
        %v77005_v7 = vor.u32 %v77004_v12, %v77003_v29 (stack47)
        %v77426_v52 = vadd.s32 %v77423_v21, %v121564_v0 (stack40)
        %v121080_v10 = vpop.eup %121079 (stack73)
        %v76228_v43 = vshrl.u32 %v76227_v22, 1 (stack51)
        %v76628_v34 = vadd.s32 %v76624_v56, %v121569_v1 (stack40)
        %v76632_v50 = vor.u32 %v76631_v53, %v76630_v54 (stack47)
        %v77859_v30 = vadd.s32 %v77856_v9, %v77851_v30 (stack40)
        %v75478_v24 = vmul.f32 %v75474_v44, %v144068_v24 (stack54)
        %v75859_v40 = vmul.f32 %v121080_v10, %v144248_v45 (stack74)
        %v77006_v60 = vxor.u32 %v77005_v7, %v76997_v41 (stack48)
        %v77430_v27 = vadd.s32 1, %v77426_v52 (stack40)
        %v76229_v41 = vor.u32 16256, %v76228_v43 (stack47)
        %v76633_v29 = vxor.u32 %v76632_v50, %v76624_v56 (stack48)
        %v77861_v61 = vshll.u32 %v77856_v9, 15 (stack45)
        %v77862_v12 = vshrl.u32 %v77856_v9, 17 (stack46)
        %v75482_v55 = vsel /*vm=*/%vm144292_vm4, /*on_true_vy=*/%v144251_v55, /*on_false_vx=*/%v75478_v24 (stack44)
        %v75861_v8 = vsel /*vm=*/%vm75860_vm5, /*on_true_vy=*/%v144248_v45, /*on_false_vx=*/%v75859_v40 (stack75)
        %v77009_v21 = vadd.s32 %v77006_v60, %v121574_v2 (stack40)
        %v77434_v6 = vadd.s32 %v77430_v27, %v77418_v6 (stack40)
        %v75486_v9 = vmul.f32 1.4140625, %v75482_v55 (stack54)
        %v75864_v25 = vsel /*vm=*/%vm75862_vm6, /*on_true_vy=*/%v75863_v25, /*on_false_vx=*/%v75861_v8 (stack76)
        %v76230_v22 = vand.u32.u16 65535, %v76229_v41 (stack52)
        %v76636_v56 = vadd.s32 %v76633_v29, %v121564_v0 (stack40)
        %v75867_v54 = vadd.f32 -3.0, %v75864_v25 (stack53)
        %v77013_v53 = vadd.s32 2, %v77009_v21 (stack40)
        %v77436_v44 = vshll.u32 %v77430_v27, 17 (stack45)
        %v77437_v7 = vshrl.u32 %v77430_v27, 15 (stack46)
        %v75489_v52 = vpack.c.bf16 %v157387_v11, %v75486_v9 (stack81)
        %v120152_v10 = vadd.low.f32.bf16 -1.0, %v76230_v22 (stack53)
        %v76640_v43 = vadd.s32 4, %v76636_v56 (stack40)
        %v77863_v50 = vor.u32 %v77862_v12, %v77861_v61 (stack47)
        %v144327_v31 = vsel /*vm=*/%vm75815_vm3, /*on_true_vy=*/%v144272_v31, /*on_false_vx=*/%v75867_v54 (stack44)
        %v77017_v26 = vadd.s32 %v77013_v53, %v77001_v26 (stack40)
        %v77019_v24 = vshll.u32 %v77013_v53, 13 (stack45)
        %v77020_v40 = vshrl.u32 %v77013_v53, 19 (stack46)
        %120149 = vst [vmem:[%s123356_s30 + $0x50] sm:$0xf] /*vst_source=*/%v75489_v52 (stack83)
        %v75875_v42 = vmul.f32 %v144327_v31, %v144285_v42 (stack54)
        %v76239_v60 = vmul.f32 2.0, %v120152_v10 (stack54)
        %v76644_v34 = vadd.s32 %v76640_v43, %v76628_v34 (stack40)
        %v76646_v27 = vshll.u32 %v76640_v43, 13 (stack45)
        %v76647_v41 = vshrl.u32 %v76640_v43, 19 (stack46)
        %v77021_v29 = vor.u32 %v77020_v40, %v77019_v24 (stack47)
        %v77438_v61 = vor.u32 %v77437_v7, %v77436_v44 (stack47)
        %v77864_v12 = vxor.u32 %v77863_v50, %v77859_v30 (stack48)
        %v75788_v55 = vand.u32 2147483647, %v144193_v32 (stack77)
        %v75879_v20 = vadd.f32 %v75875_v42, %v144280_v20 (stack53)
        %v76243_v8 = vadd.f32 -0.99609375, %v76239_v60 (stack53)
        %vm78278_vm7 = vcmp.lt.u32.totalorder %v144299_v46, %v157095_v13 (stack43)
        %v76648_v21 = vor.u32 %v76647_v41, %v76646_v27 (stack47)
        %v77022_v9 = vxor.u32 %v77021_v29, %v77017_v26 (stack48)
        %v77439_v25 = vxor.u32 %v77438_v61, %v77434_v6 (stack48)
        %v144336_v30 = vadd.s32 %v77864_v12, %v77859_v30 (stack40)
        %v144341_v22 = vsel /*vm=*/%vm75815_vm3, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v75844_v56 = vsel /*vm=*/%vm75815_vm3, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v75883_v54 = vmul.f32 %v75879_v20, %v144327_v31 (stack54)
        %v144347_v53 = vmax.f32 %v76243_v8, -0.99609375 (stack55)
        %v76649_v44 = vxor.u32 %v76648_v21, %v76644_v34 (stack48)
        %v77025_v7 = vadd.s32 %v77022_v9, %v77017_v26 (stack40)
        %v77027_v52 = vshll.u32 %v77022_v9, 15 (stack45)
        %v77028_v10 = vshrl.u32 %v77022_v9, 17 (stack46)
        %v144352_v43 = vsel /*vm=*/%vm75815_vm3, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v75840_v50 = vsel /*vm=*/%vm75815_vm3, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v75887_v26 = vadd.f32 %v75883_v54, %v75844_v56 (stack53)
        %v76259_v24 = vxor.u32 2147483648, %v144347_v53 (stack56)
        %v76652_v40 = vadd.s32 %v76649_v44, %v76644_v34 (stack40)
        %v76654_v42 = vshll.u32 %v76649_v44, 15 (stack45)
        %v76655_v60 = vshrl.u32 %v76649_v44, 17 (stack46)
        %v77029_v34 = vor.u32 %v77028_v10, %v77027_v52 (stack47)
        %v75891_v27 = vmul.f32 %v75887_v26, %v144327_v31 (stack54)
        %v76262_v41 = vmul.f32 %v76259_v24, %v144347_v53 (stack54)
        %v77442_v6 = vadd.s32 %v77439_v25, %v77434_v6 (stack40)
        %v77869_v29 = vshll.u32 %v77864_v12, 26 (stack45)
        %v76656_v61 = vor.u32 %v76655_v60, %v76654_v42 (stack47)
        %v77030_v20 = vxor.u32 %v77029_v34, %v77025_v7 (stack48)
        %v77444_v8 = vshll.u32 %v77439_v25, 29 (stack45)
        %v77870_v12 = vshrl.u32 %v77864_v12, 6 (stack46)
        %v75895_v21 = vadd.f32 %v75891_v27, %v75840_v50 (stack53)
        %v76264_v9 = vadd.f32 1.0, %v76262_v41 (stack57)
        %v76267_v56 = vmul.f32 -0.5, %v76262_v41 (stack59)
        %v77445_v25 = vshrl.u32 %v77439_v25, 3 (stack46)
        %v76657_v54 = vxor.u32 %v76656_v61, %v76652_v40 (stack48)
        %v77033_v44 = vadd.s32 %v77030_v20, %v77025_v7 (stack40)
        %v77035_v7 = vshll.u32 %v77030_v20, 26 (stack45)
        %v77036_v52 = vshrl.u32 %v77030_v20, 6 (stack46)
        %v75828_v10 = vsel /*vm=*/%vm75815_vm3, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v75836_v50 = vsel /*vm=*/%vm75815_vm3, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v75899_v26 = vmul.f32 %v75895_v21, %v144327_v31 (stack54)
        %121081 = vlog2.f32 %v76264_v9 (stack58)
        %v76660_v24 = vadd.s32 %v76657_v54, %v76652_v40 (stack40)
        %v76662_v40 = vshll.u32 %v76657_v54, 26 (stack45)
        %v76663_v42 = vshrl.u32 %v76657_v54, 6 (stack46)
        %v77037_v60 = vor.u32 %v77036_v52, %v77035_v7 (stack47)
        %v75832_v45 = vsel /*vm=*/%vm75815_vm3, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v75903_v34 = vadd.f32 %v75899_v26, %v75836_v50 (stack53)
        %v77446_v27 = vor.u32 %v77445_v25, %v77444_v8 (stack47)
        %v77871_v29 = vor.u32 %v77870_v12, %v77869_v29 (stack47)
        %v76268_v61 = vadd.f32 1.0, %v76267_v56 (stack61)
        %v76270_v20 = vand.u32 2147483647, %v76262_v41 (stack60)
        %v76664_v8 = vor.u32 %v76663_v42, %v76662_v40 (stack47)
        %v77038_v12 = vxor.u32 %v77037_v60, %v77033_v44 (stack48)
        %v75907_v21 = vmul.f32 %v75903_v34, %v144327_v31 (stack54)
        %v77447_v9 = vxor.u32 %v77446_v27, %v77442_v6 (stack48)
        %v77872_v56 = vxor.u32 %v77871_v29, %v144336_v30 (stack48)
        %v78269_v25 = vadd.s32 %v144299_v46, %v122657_v58 (stack40)
        %v76665_v54 = vxor.u32 %v76664_v8, %v76660_v24 (stack48)
        %v77041_v44 = vadd.s32 %v77038_v12, %v77033_v44 (stack40)
        %v77047_v7 = vshll.u32 %v77038_v12, 6 (stack45)
        %v77048_v52 = vshrl.u32 %v77038_v12, 26 (stack46)
        %v75911_v50 = vadd.f32 %v75907_v21, %v75832_v45 (stack53)
        %v77450_v6 = vadd.s32 %v77447_v9, %v77442_v6 (stack40)
        %v77452_v26 = vshll.u32 %v77447_v9, 16 (stack45)
        %v77453_v40 = vshrl.u32 %v77447_v9, 16 (stack46)
        %v76269_v41 = vmul.f32 %v76268_v61, %v76262_v41 (stack63)
        %vm144374_vm8 = vcmp.lt.f32.partialorder %v76270_v20, 0.0004427343 (stack62)
        %v76668_v24 = vadd.s32 %v76665_v54, %v76660_v24 (stack40)
        %v76674_v60 = vshll.u32 %v76665_v54, 6 (stack45)
        %v76675_v45 = vshrl.u32 %v76665_v54, 26 (stack46)
        %v75915_v34 = vmul.f32 %v75911_v50, %v144327_v31 (stack54)
        %v77049_v27 = vor.u32 %v77048_v52, %v77047_v7 (stack47)
        %v77454_v29 = vor.u32 %v77453_v40, %v77452_v26 (stack47)
        %v77875_v30 = vadd.s32 %v77872_v56, %v144336_v30 (stack40)
        %v76676_v61 = vor.u32 %v76675_v45, %v76674_v60 (stack47)
        %v77881_v20 = vshll.u32 %v77872_v56, 6 (stack45)
        %v77882_v8 = vshrl.u32 %v77872_v56, 26 (stack46)
        %v78287_v12 = vadd.s32 1, %v144304_v23 (stack40)
        %v75919_v10 = vadd.f32 %v75915_v34, %v75828_v10 (stack53)
        %v77050_v21 = vxor.u32 %v77049_v27, %v77041_v44 (stack48)
        %v77455_v9 = vxor.u32 %v77454_v29, %v77450_v6 (stack48)
        %vm78273_vm9 = vcmp.lt.u32.totalorder %v78269_v25, %v144299_v46 (stack43)
        %v76677_v56 = vxor.u32 %v76676_v61, %v76668_v24 (stack48)
        %v77045_v54 = vadd.s32 %v77041_v44, %v121574_v2 (stack40)
        %v77883_v44 = vor.u32 %v77882_v8, %v77881_v20 (stack47)
        %v78291_v23 = vsel /*vm=*/%vm78278_vm7, /*on_true_vy=*/%v78287_v12, /*on_false_vx=*/%v144304_v23 (stack44)
        %v75923_v7 = vmul.f32 %v75919_v10, %v144327_v31 (stack54)
        %v77053_v52 = vadd.s32 %v77050_v21, %v121569_v1 (stack40)
        %v77458_v50 = vadd.s32 %v77455_v9, %v77450_v6 (stack40)
        %v77464_v6 = vshll.u32 %v77455_v9, 24 (stack45)
        %v121082_v26 = vpop.eup %121081 (stack64)
        %v76680_v40 = vadd.s32 %v76677_v56, %v121574_v2 (stack40)
        %v77465_v60 = vshrl.u32 %v77455_v9, 8 (stack46)
        %v77884_v45 = vxor.u32 %v77883_v44, %v77875_v30 (stack48)
        %v78295_v34 = vadd.s32 1, %v78291_v23 (stack40)
        %v75927_v43 = vadd.f32 %v75923_v7, %v144352_v43 (stack53)
        %v76266_v27 = vmul.f32 0.6931472, %v121082_v26 (stack65)
        %v76672_v24 = vadd.s32 %v76668_v24, %v121564_v0 (stack40)
        %v77057_v29 = vadd.s32 3, %v77053_v52 (stack40)
        %v76684_v61 = vadd.s32 5, %v76680_v40 (stack40)
        %v77466_v20 = vor.u32 %v77465_v60, %v77464_v6 (stack47)
        %v77887_v8 = vadd.s32 %v77884_v45, %v121564_v0 (stack40)
        %v78299_v46 = vsel /*vm=*/%vm78273_vm9, /*on_true_vy=*/%v78295_v34, /*on_false_vx=*/%v78291_v23 (stack44)
        %v75931_v31 = vmul.f32 %v75927_v43, %v144327_v31 (stack54)
        %v76272_v41 = vsel /*vm=*/%vm144374_vm8, /*on_true_vy=*/%v76269_v41, /*on_false_vx=*/%v76266_v27 (stack66)
        %v77061_v42 = vadd.s32 %v77057_v29, %v77045_v54 (stack40)
        %v77063_v12 = vshll.u32 %v77057_v29, 17 (stack45)
        %v144398_v10 = vxor.u32 2147483648, %v76272_v41 (stack56)
        %v76686_v21 = vxor.u32 %v76684_v61, %v76672_v24 (stack48)
        %v77064_v9 = vshrl.u32 %v77057_v29, 15 (stack46)
        %v77467_v56 = vxor.u32 %v77466_v20, %v77458_v50 (stack48)
        %v75935_v22 = vadd.f32 %v75931_v31, %v144341_v22 (stack53)
        %v78308_v25 = vadd.s32 %v78269_v25, %v121569_v1 (stack40)
        %vm75791_vm10 = vcmp.eq.f32.partialorder %v75788_v55, 1.0 (stack68)
        %v75796_v55 = vmul.f32 inf, %v144193_v32 (stack54)
        %121083 = vrsqrt.f32 %v144398_v10 (stack67)
        %v75939_v32 = vmul.f32 %v75935_v22, %v144193_v32 (stack54)
        %v76249_v54 = vand.u32 2147483647, %v144347_v53 (stack77)
        %vm76276_vm11 = vcmp.lt.f32.partialorder %v144398_v10, 5.0 (stack68)
        %v77891_v44 = vadd.s32 1, %v77887_v8 (stack40)
        %v144410_v23 = vmul.f32 inf, %v144347_v53 (stack54)
        %v77065_v7 = vor.u32 %v77064_v9, %v77063_v12 (stack47)
        %v77879_v30 = vadd.s32 %v77875_v30, %v121569_v1 (stack40)
        %v78304_v52 = vadd.s32 %v78299_v46, %v121574_v2 (stack40)
        %v75943_v6 = vsel /*vm=*/%vm75791_vm10, /*on_true_vy=*/%v75796_v55, /*on_false_vx=*/%v75939_v32 (stack44)
        %v77462_v50 = vadd.s32 %v77458_v50, %v121564_v0 (stack40)
        %v78314_v26 = vshll.u32 %v78308_v25, 13 (stack45)
        %v78315_v40 = vshrl.u32 %v78308_v25, 19 (stack46)
        %v75947_v60 = vmul.f32 1.4140625, %v75943_v6 (stack54)
        %v144418_v45 = vsel /*vm=*/%vm76276_vm11, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v144421_v34 = vadd.f32 -2.5, %v144398_v10 (stack53)
        %v76687_v43 = vand.u32.u8 255, %v76686_v21 (stack49)
        %v77066_v27 = vxor.u32 %v77065_v7, %v77061_v42 (stack48)
        %v77470_v24 = vadd.s32 %v77467_v56, %v121574_v2 (stack40)
        %v77895_v29 = vadd.s32 %v77891_v44, %v77879_v30 (stack40)
        %v77897_v61 = vshll.u32 %v77891_v44, 17 (stack45)
        %v75950_v20 = vpack.c.bf16 %v157387_v11, %v75947_v60 (stack81)
        %v76688_v8 = vand.u32 65535, %v76687_v43 (stack50)
        %v77898_v46 = vshrl.u32 %v77891_v44, 15 (stack46)
        %v78312_v31 = vadd.s32 %v78308_v25, %v78304_v52 (stack40)
        %vm76321_vm12 = vcmp.eq.f32.partialorder %v144398_v10, inf (stack70)
        %v77069_v41 = vadd.s32 %v77066_v27, %v77061_v42 (stack40)
        %v77071_v42 = vshll.u32 %v77066_v27, 29 (stack45)
        %v77072_v12 = vshrl.u32 %v77066_v27, 3 (stack46)
        %v77474_v21 = vadd.s32 2, %v77470_v24 (stack40)
        %120151 = vst [vmem:[%s123356_s30 + $0xd0] sm:$0xf] /*vst_source=*/%v75950_v20 (stack83)
        %vm76323_vm13 = vcmp.eq.f32.partialorder %v144398_v10, 0.0 (stack71)
        %v76689_v9 = vshrl.u32 %v76688_v8, 1 (stack51)
        %v77899_v56 = vor.u32 %v77898_v46, %v77897_v61 (stack47)
        %v78316_v22 = vor.u32 %v78315_v40, %v78314_v26 (stack47)
        %v157562_v25 = vld [vmem:[#allocation141_spill] sm:$0xff] (stack84)
        %v144430_v55 = vadd.s32 %v157562_v25, %v122651_v47 (stack40)
        %v77073_v32 = vor.u32 %v77072_v12, %v77071_v42 (stack47)
        %v77478_v44 = vadd.s32 %v77474_v21, %v77462_v50 (stack40)
        %v77480_v7 = vshll.u32 %v77474_v21, 13 (stack45)
        %v77481_v30 = vshrl.u32 %v77474_v21, 19 (stack46)
        %v76324_v52 = vand.u32 2147483648, %v144398_v10 (stack72)
        %v76690_v6 = vor.u32 16256, %v76689_v9 (stack47)
        %v77900_v50 = vxor.u32 %v77899_v56, %v77895_v29 (stack48)
        %v78317_v26 = vxor.u32 %v78316_v22, %v78312_v31 (stack48)
        %v77074_v40 = vxor.u32 %v77073_v32, %v77069_v41 (stack48)
        %v77482_v60 = vor.u32 %v77481_v30, %v77480_v7 (stack47)
        %vm78773_vm14 = vcmp.lt.u32.totalorder %v144430_v55, %v122651_v47 (stack43)
        %v157563_v43 = vld [vmem:[#allocation105_spill] sm:$0xff] (stack84)
        %v144437_v27 = vadd.s32 %v157563_v43, %v157068_v28 (stack40)
        %v76691_v24 = vand.u32.u16 65535, %v76690_v6 (stack52)
        %v77903_v29 = vadd.s32 %v77900_v50, %v77895_v29 (stack40)
        %v77905_v61 = vshll.u32 %v77900_v50, 29 (stack45)
        %v77906_v20 = vshrl.u32 %v77900_v50, 3 (stack46)
        %v121084_v8 = vpop.eup %121083 (stack73)
        %v77077_v46 = vadd.s32 %v77074_v40, %v77069_v41 (stack40)
        %v77079_v41 = vshll.u32 %v77074_v40, 16 (stack45)
        %v77080_v42 = vshrl.u32 %v77074_v40, 16 (stack46)
        %v77483_v12 = vxor.u32 %v77482_v60, %v77478_v44 (stack48)
        %v76320_v21 = vmul.f32 %v121084_v8, %v144398_v10 (stack74)
        %v120154_v9 = vadd.low.f32.bf16 -1.0, %v76691_v24 (stack53)
        %v77907_v56 = vor.u32 %v77906_v20, %v77905_v61 (stack47)
        %v78320_v31 = vadd.s32 %v78317_v26, %v78312_v31 (stack40)
        %v77081_v22 = vor.u32 %v77080_v42, %v77079_v41 (stack47)
        %v77486_v32 = vadd.s32 %v77483_v12, %v77478_v44 (stack40)
        %v77488_v44 = vshll.u32 %v77483_v12, 15 (stack45)
        %v77489_v7 = vshrl.u32 %v77483_v12, 17 (stack46)
        %v76322_v30 = vsel /*vm=*/%vm76321_vm12, /*on_true_vy=*/%v144398_v10, /*on_false_vx=*/%v76320_v21 (stack75)
        %v76700_v6 = vmul.f32 2.0, %v120154_v9 (stack54)
        %v77908_v50 = vxor.u32 %v77907_v56, %v77903_v29 (stack48)
        %v78322_v40 = vshll.u32 %v78317_v26, 15 (stack45)
        %v76325_v52 = vsel /*vm=*/%vm76323_vm13, /*on_true_vy=*/%v76324_v52, /*on_false_vx=*/%v76322_v30 (stack76)
        %v77082_v60 = vxor.u32 %v77081_v22, %v77077_v46 (stack48)
        %v77490_v24 = vor.u32 %v77489_v7, %v77488_v44 (stack47)
        %v78323_v26 = vshrl.u32 %v78317_v26, 17 (stack46)
        %v76328_v61 = vadd.f32 -3.0, %v76325_v52 (stack53)
        %v76704_v20 = vadd.f32 -0.99609375, %v76700_v6 (stack53)
        %v77911_v29 = vadd.s32 %v77908_v50, %v77903_v29 (stack40)
        %v77913_v8 = vshll.u32 %v77908_v50, 16 (stack45)
        %v77085_v46 = vadd.s32 %v77082_v60, %v77077_v46 (stack40)
        %v77091_v41 = vshll.u32 %v77082_v60, 24 (stack45)
        %v77092_v42 = vshrl.u32 %v77082_v60, 8 (stack46)
        %v77491_v12 = vxor.u32 %v77490_v24, %v77486_v32 (stack48)
        %v144448_v34 = vsel /*vm=*/%vm76276_vm11, /*on_true_vy=*/%v144421_v34, /*on_false_vx=*/%v76328_v61 (stack44)
        %v144450_v21 = vmax.f32 %v76704_v20, -0.99609375 (stack55)
        %v77914_v9 = vshrl.u32 %v77908_v50, 16 (stack46)
        %v78324_v56 = vor.u32 %v78323_v26, %v78322_v40 (stack47)
        %v144455_v22 = vsel /*vm=*/%vm76276_vm11, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v76336_v45 = vmul.f32 %v144448_v34, %v144418_v45 (stack54)
        %v77093_v44 = vor.u32 %v77092_v42, %v77091_v41 (stack47)
        %v77494_v32 = vadd.s32 %v77491_v12, %v77486_v32 (stack40)
        %v144462_v7 = vsel /*vm=*/%vm76276_vm11, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v76309_v30 = vsel /*vm=*/%vm76276_vm11, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v76720_v6 = vxor.u32 2147483648, %v144450_v21 (stack56)
        %v77496_v50 = vshll.u32 %v77491_v12, 26 (stack45)
        %v76340_v40 = vadd.f32 %v76336_v45, %v76309_v30 (stack53)
        %v77094_v52 = vxor.u32 %v77093_v44, %v77085_v46 (stack48)
        %v77497_v60 = vshrl.u32 %v77491_v12, 6 (stack46)
        %v77915_v24 = vor.u32 %v77914_v9, %v77913_v8 (stack47)
        %v76297_v26 = vsel /*vm=*/%vm76276_vm11, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v76305_v61 = vsel /*vm=*/%vm76276_vm11, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v144475_v20 = vmul.f32 %v76720_v6, %v144450_v21 (stack54)
        %v78325_v8 = vxor.u32 %v78324_v56, %v78320_v31 (stack48)
        %v76344_v41 = vmul.f32 %v76340_v40, %v144448_v34 (stack54)
        %v77097_v42 = vadd.s32 %v77094_v52, %v121564_v0 (stack40)
        %v77498_v12 = vor.u32 %v77497_v60, %v77496_v50 (stack47)
        %v77916_v9 = vxor.u32 %v77915_v24, %v77911_v29 (stack48)
        %v76725_v56 = vadd.f32 1.0, %v144475_v20 (stack57)
        %v77089_v46 = vadd.s32 %v77085_v46, %v121569_v1 (stack40)
        %v78328_v31 = vadd.s32 %v78325_v8, %v78320_v31 (stack40)
        %v144483_v45 = vadd.s32 %v144430_v55, %v122657_v58 (stack40)
        %v76348_v44 = vadd.f32 %v76344_v41, %v76305_v61 (stack53)
        %v77101_v30 = vadd.s32 4, %v77097_v42 (stack40)
        %v77499_v6 = vxor.u32 %v77498_v12, %v77494_v32 (stack48)
        %v77919_v29 = vadd.s32 %v77916_v9, %v77911_v29 (stack40)
        %v76301_v50 = vsel /*vm=*/%vm76276_vm11, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %121085 = vlog2.f32 %v76725_v56 (stack58)
        %v76728_v40 = vmul.f32 -0.5, %v144475_v20 (stack59)
        %v77925_v52 = vshll.u32 %v77916_v9, 24 (stack45)
        %v76352_v60 = vmul.f32 %v76348_v44, %v144448_v34 (stack54)
        %v77105_v24 = vadd.s32 %v77101_v30, %v77089_v46 (stack40)
        %v77107_v61 = vshll.u32 %v77101_v30, 13 (stack45)
        %v77108_v41 = vshrl.u32 %v77101_v30, 19 (stack46)
        %v77502_v32 = vadd.s32 %v77499_v6, %v77494_v32 (stack40)
        %v77508_v42 = vshll.u32 %v77499_v6, 6 (stack45)
        %v77509_v12 = vshrl.u32 %v77499_v6, 26 (stack46)
        %vm78768_vm15 = vcmp.lt.u32.totalorder %v144483_v45, %v144430_v55 (stack43)
        %v76356_v56 = vadd.f32 %v76352_v60, %v76301_v50 (stack53)
        %v76731_v46 = vand.u32 2147483647, %v144475_v20 (stack60)
        %v77109_v44 = vor.u32 %v77108_v41, %v77107_v61 (stack47)
        %v77926_v9 = vshrl.u32 %v77916_v9, 8 (stack46)
        %v76729_v30 = vadd.f32 1.0, %v76728_v40 (stack61)
        %v77510_v6 = vor.u32 %v77509_v12, %v77508_v42 (stack47)
        %v78330_v50 = vshll.u32 %v78325_v8, 26 (stack45)
        %v78331_v8 = vshrl.u32 %v78325_v8, 6 (stack46)
        %v76360_v40 = vmul.f32 %v76356_v56, %v144448_v34 (stack54)
        %v77110_v60 = vxor.u32 %v77109_v44, %v77105_v24 (stack48)
        %v77923_v61 = vadd.s32 %v77919_v29, %v121564_v0 (stack40)
        %v77927_v52 = vor.u32 %v77926_v9, %v77925_v52 (stack47)
        %v77511_v41 = vxor.u32 %v77510_v6, %v77502_v32 (stack48)
        %v78332_v42 = vor.u32 %v78331_v8, %v78330_v50 (stack47)
        %v78782_v12 = vadd.s32 1, %v144437_v27 (stack40)
        %v144498_v56 = vadd.s32 %v157562_v25, %v157070_v38 (stack40)
        %v76364_v26 = vadd.f32 %v76360_v40, %v76297_v26 (stack53)
        %v77113_v24 = vadd.s32 %v77110_v60, %v77105_v24 (stack40)
        %v77115_v44 = vshll.u32 %v77110_v60, 15 (stack45)
        %v77116_v9 = vshrl.u32 %v77110_v60, 17 (stack46)
        %v77514_v6 = vadd.s32 %v77511_v41, %v121569_v1 (stack40)
        %v77928_v29 = vxor.u32 %v77927_v52, %v77919_v29 (stack48)
        %v78333_v50 = vxor.u32 %v78332_v42, %v78328_v31 (stack48)
        %v78786_v27 = vsel /*vm=*/%vm78773_vm14, /*on_true_vy=*/%v78782_v12, /*on_false_vx=*/%v144437_v27 (stack44)
        %v76368_v8 = vmul.f32 %v76364_v26, %v144448_v34 (stack54)
        %v77117_v40 = vor.u32 %v77116_v9, %v77115_v44 (stack47)
        %v77506_v32 = vadd.s32 %v77502_v32, %v121574_v2 (stack40)
        %v78790_v60 = vadd.s32 1, %v78786_v27 (stack40)
        %v77518_v52 = vadd.s32 3, %v77514_v6 (stack40)
        %v77931_v41 = vadd.s32 %v77928_v29, %v121574_v2 (stack40)
        %v78336_v31 = vadd.s32 %v78333_v50, %v78328_v31 (stack40)
        %v78342_v42 = vshll.u32 %v78333_v50, 6 (stack45)
        %v76372_v7 = vadd.f32 %v76368_v8, %v144462_v7 (stack53)
        %v77118_v12 = vxor.u32 %v77117_v40, %v77113_v24 (stack48)
        %v78343_v26 = vshrl.u32 %v78333_v50, 26 (stack46)
        %v78794_v55 = vsel /*vm=*/%vm78768_vm15, /*on_true_vy=*/%v78790_v60, /*on_false_vx=*/%v78786_v27 (stack44)
        %v77522_v44 = vadd.s32 %v77518_v52, %v77506_v32 (stack40)
        %v77524_v9 = vshll.u32 %v77518_v52, 17 (stack45)
        %v77525_v6 = vshrl.u32 %v77518_v52, 15 (stack46)
        %v77935_v29 = vadd.s32 2, %v77931_v41 (stack40)
        %v121086_v50 = vpop.eup %121085 (stack64)
        %v76376_v27 = vmul.f32 %v76372_v7, %v144448_v34 (stack54)
        %v77121_v24 = vadd.s32 %v77118_v12, %v77113_v24 (stack40)
        %v77123_v8 = vshll.u32 %v77118_v12, 26 (stack45)
        %v77124_v40 = vshrl.u32 %v77118_v12, 6 (stack46)
        %v76727_v32 = vmul.f32 0.6931472, %v121086_v50 (stack65)
        %v76730_v20 = vmul.f32 %v76729_v30, %v144475_v20 (stack63)
        %v77526_v30 = vor.u32 %v77525_v6, %v77524_v9 (stack47)
        %v77939_v61 = vadd.s32 %v77935_v29, %v77923_v61 (stack40)
        %v76380_v22 = vadd.f32 %v76376_v27, %v144455_v22 (stack53)
        %vm76732_vm0 = vcmp.lt.f32.partialorder %v76731_v46, 0.0004427343 (stack62)
        %v77125_v46 = vor.u32 %v77124_v40, %v77123_v8 (stack47)
        %v77941_v60 = vshll.u32 %v77935_v29, 13 (stack45)
        %v76733_v52 = vsel /*vm=*/%vm76732_vm0, /*on_true_vy=*/%v76730_v20, /*on_false_vx=*/%v76727_v32 (stack66)
        %v77527_v41 = vxor.u32 %v77526_v30, %v77522_v44 (stack48)
        %v77942_v7 = vshrl.u32 %v77935_v29, 19 (stack46)
        %v78344_v42 = vor.u32 %v78343_v26, %v78342_v42 (stack47)
        %v76384_v12 = vmul.f32 %v76380_v22, %v144448_v34 (stack54)
        %v144516_v26 = vxor.u32 2147483648, %v76733_v52 (stack56)
        %v77126_v9 = vxor.u32 %v77125_v46, %v77121_v24 (stack48)
        %v78803_v45 = vadd.s32 %v144483_v45, %v121569_v1 (stack40)
        %vm144522_vm1 = vcmp.eq.f32.partialorder %v76249_v54, 1.0 (stack68)
        %v76281_v6 = vsel /*vm=*/%vm76276_vm11, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v76285_v10 = vsel /*vm=*/%vm76276_vm11, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v77530_v44 = vadd.s32 %v77527_v41, %v77522_v44 (stack40)
        %v78345_v29 = vxor.u32 %v78344_v42, %v78336_v31 (stack48)
        %v76388_v50 = vadd.f32 %v76384_v12, %v76285_v10 (stack53)
        %v76710_v27 = vand.u32 2147483647, %v144450_v21 (stack77)
        %vm76737_vm2 = vcmp.lt.f32.partialorder %v144516_v26, 5.0 (stack68)
        %121087 = vrsqrt.f32 %v144516_v26 (stack67)
        %v77129_v24 = vadd.s32 %v77126_v9, %v77121_v24 (stack40)
        %v77532_v8 = vshll.u32 %v77527_v41, 29 (stack45)
        %v77533_v40 = vshrl.u32 %v77527_v41, 3 (stack46)
        %v77943_v32 = vor.u32 %v77942_v7, %v77941_v60 (stack47)
        %v76392_v34 = vmul.f32 %v76388_v50, %v144448_v34 (stack54)
        %v144537_v20 = vmul.f32 inf, %v144450_v21 (stack54)
        %v78799_v55 = vadd.s32 %v78794_v55, %v121574_v2 (stack40)
        %v78809_v30 = vshll.u32 %v78803_v45, 13 (stack45)
        %v144543_v22 = vsel /*vm=*/%vm76737_vm2, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v144548_v46 = vsel /*vm=*/%vm76737_vm2, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v144551_v60 = vadd.f32 -2.5, %v144516_v26 (stack53)
        %v78340_v31 = vadd.s32 %v78336_v31, %v121569_v1 (stack40)
        %v76396_v52 = vadd.f32 %v76392_v34, %v76281_v6 (stack53)
        %v144557_v41 = vsel /*vm=*/%vm76737_vm2, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v144562_v7 = vsel /*vm=*/%vm76737_vm2, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v77133_v42 = vadd.s32 %v77129_v24, %v121564_v0 (stack40)
        %v77135_v12 = vshll.u32 %v77126_v9, 6 (stack45)
        %v77136_v9 = vshrl.u32 %v77126_v9, 26 (stack46)
        %v77534_v6 = vor.u32 %v77533_v40, %v77532_v8 (stack47)
        %v77944_v10 = vxor.u32 %v77943_v32, %v77939_v61 (stack48)
        %v76400_v53 = vmul.f32 %v76396_v52, %v144347_v53 (stack54)
        %v78348_v29 = vadd.s32 %v78345_v29, %v121564_v0 (stack40)
        %v78807_v50 = vadd.s32 %v78803_v45, %v78799_v55 (stack40)
        %v78810_v45 = vshrl.u32 %v78803_v45, 19 (stack46)
        %vm76782_vm3 = vcmp.eq.f32.partialorder %v144516_v26, inf (stack70)
        %v77137_v8 = vor.u32 %v77136_v9, %v77135_v12 (stack47)
        %v77535_v40 = vxor.u32 %v77534_v6, %v77530_v44 (stack48)
        %v77947_v61 = vadd.s32 %v77944_v10, %v77939_v61 (stack40)
        %v77949_v32 = vshll.u32 %v77944_v10, 15 (stack45)
        %v76404_v23 = vsel /*vm=*/%vm144522_vm1, /*on_true_vy=*/%v144410_v23, /*on_false_vx=*/%v76400_v53 (stack44)
        %vm76784_vm4 = vcmp.eq.f32.partialorder %v144516_v26, 0.0 (stack71)
        %v77950_v54 = vshrl.u32 %v77944_v10, 17 (stack46)
        %v78352_v34 = vadd.s32 1, %v78348_v29 (stack40)
        %v78811_v55 = vor.u32 %v78810_v45, %v78809_v30 (stack47)
        %v76408_v30 = vmul.f32 1.4140625, %v76404_v23 (stack54)
        %v77138_v24 = vxor.u32 %v77137_v8, %v77129_v24 (stack48)
        %v77538_v44 = vadd.s32 %v77535_v40, %v77530_v44 (stack40)
        %v77540_v52 = vshll.u32 %v77535_v40, 16 (stack45)
        %v77541_v12 = vshrl.u32 %v77535_v40, 16 (stack46)
        %v77951_v9 = vor.u32 %v77950_v54, %v77949_v32 (stack47)
        %v78356_v31 = vadd.s32 %v78352_v34, %v78340_v31 (stack40)
        %v78358_v6 = vshll.u32 %v78352_v34, 17 (stack45)
        %v76411_v10 = vpack.c.bf16 %v157387_v11, %v76408_v30 (stack81)
        %v77141_v53 = vadd.s32 %v77138_v24, %v121574_v2 (stack40)
        %v78359_v29 = vshrl.u32 %v78352_v34, 15 (stack46)
        %v78812_v45 = vxor.u32 %v78811_v55, %v78807_v50 (stack48)
        %v76785_v8 = vand.u32 2147483648, %v144516_v26 (stack72)
        %v77542_v40 = vor.u32 %v77541_v12, %v77540_v52 (stack47)
        %v77952_v32 = vxor.u32 %v77951_v9, %v77947_v61 (stack48)
        %vm79234_vm5 = vcmp.lt.u32.totalorder %v144498_v56, %v157070_v38 (stack43)
        %v121088_v23 = vpop.eup %121087 (stack73)
        %120153 = vst [vmem:[%s123356_s30 + $0x150] sm:$0xf] /*vst_source=*/%v76411_v10 (stack83)
        %v77145_v54 = vadd.s32 5, %v77141_v53 (stack40)
        %v78360_v34 = vor.u32 %v78359_v29, %v78358_v6 (stack47)
        %v78815_v50 = vadd.s32 %v78812_v45, %v78807_v50 (stack40)
        %v78817_v55 = vshll.u32 %v78812_v45, 15 (stack45)
        %v76781_v30 = vmul.f32 %v121088_v23, %v144516_v26 (stack74)
        %v77543_v24 = vxor.u32 %v77542_v40, %v77538_v44 (stack48)
        %v77955_v61 = vadd.s32 %v77952_v32, %v77947_v61 (stack40)
        %v77957_v52 = vshll.u32 %v77952_v32, 26 (stack45)
        %v77147_v42 = vxor.u32 %v77145_v54, %v77133_v42 (stack48)
        %v77958_v12 = vshrl.u32 %v77952_v32, 6 (stack46)
        %v78361_v9 = vxor.u32 %v78360_v34, %v78356_v31 (stack48)
        %v78818_v6 = vshrl.u32 %v78812_v45, 17 (stack46)
        %v76783_v10 = vsel /*vm=*/%vm76782_vm3, /*on_true_vy=*/%v144516_v26, /*on_false_vx=*/%v76781_v30 (stack75)
        %v77546_v44 = vadd.s32 %v77543_v24, %v77538_v44 (stack40)
        %v77552_v53 = vshll.u32 %v77543_v24, 24 (stack45)
        %v77553_v29 = vshrl.u32 %v77543_v24, 8 (stack46)
        %v76786_v45 = vsel /*vm=*/%vm76784_vm4, /*on_true_vy=*/%v76785_v8, /*on_false_vx=*/%v76783_v10 (stack76)
        %v77148_v8 = vand.u32.u8 255, %v77147_v42 (stack49)
        %v77959_v40 = vor.u32 %v77958_v12, %v77957_v52 (stack47)
        %v78364_v31 = vadd.s32 %v78361_v9, %v78356_v31 (stack40)
        %v76770_v32 = vsel /*vm=*/%vm76737_vm2, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v76789_v23 = vadd.f32 -3.0, %v76786_v45 (stack53)
        %v77554_v54 = vor.u32 %v77553_v29, %v77552_v53 (stack47)
        %v78366_v34 = vshll.u32 %v78361_v9, 29 (stack45)
        %v77149_v30 = vand.u32 65535, %v77148_v8 (stack50)
        %v77960_v24 = vxor.u32 %v77959_v40, %v77955_v61 (stack48)
        %v78367_v52 = vshrl.u32 %v78361_v9, 3 (stack46)
        %v78819_v55 = vor.u32 %v78818_v6, %v78817_v55 (stack47)
        %v76774_v42 = vsel /*vm=*/%vm76737_vm2, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v144593_v60 = vsel /*vm=*/%vm76737_vm2, /*on_true_vy=*/%v144551_v60, /*on_false_vx=*/%v76789_v23 (stack44)
        %v77555_v12 = vxor.u32 %v77554_v54, %v77546_v44 (stack48)
        %v79239_v9 = vadd.s32 %v157563_v43, %v157076_v35 (stack40)
        %v76797_v6 = vmul.f32 %v144593_v60, %v76774_v42 (stack54)
        %v77150_v10 = vshrl.u32 %v77149_v30, 1 (stack51)
        %v77963_v61 = vadd.s32 %v77960_v24, %v77955_v61 (stack40)
        %v77969_v53 = vshll.u32 %v77960_v24, 6 (stack45)
        %v77558_v29 = vadd.s32 %v77555_v12, %v121564_v0 (stack40)
        %v77970_v45 = vshrl.u32 %v77960_v24, 26 (stack46)
        %v78368_v8 = vor.u32 %v78367_v52, %v78366_v34 (stack47)
        %v78820_v40 = vxor.u32 %v78819_v55, %v78815_v50 (stack48)
        %v76801_v32 = vadd.f32 %v76797_v6, %v76770_v32 (stack53)
        %v77151_v23 = vor.u32 16256, %v77150_v10 (stack47)
        %v77550_v44 = vadd.s32 %v77546_v44, %v121569_v1 (stack40)
        %v79243_v54 = vadd.s32 1, %v79239_v9 (stack40)
        %v77562_v34 = vadd.s32 4, %v77558_v29 (stack40)
        %v77971_v30 = vor.u32 %v77970_v45, %v77969_v53 (stack47)
        %v78369_v24 = vxor.u32 %v78368_v8, %v78364_v31 (stack48)
        %v78823_v50 = vadd.s32 %v78820_v40, %v78815_v50 (stack40)
        %v76805_v52 = vmul.f32 %v76801_v32, %v144593_v60 (stack54)
        %v77152_v55 = vand.u32.u16 65535, %v77151_v23 (stack52)
        %v78825_v42 = vshll.u32 %v78820_v40, 26 (stack45)
        %v78826_v12 = vshrl.u32 %v78820_v40, 6 (stack46)
        %v77566_v6 = vadd.s32 %v77562_v34, %v77550_v44 (stack40)
        %v77568_v10 = vshll.u32 %v77562_v34, 13 (stack45)
        %v77569_v53 = vshrl.u32 %v77562_v34, 19 (stack46)
        %v77972_v29 = vxor.u32 %v77971_v30, %v77963_v61 (stack48)
        %v76809_v7 = vadd.f32 %v76805_v52, %v144562_v7 (stack53)
        %v120156_v45 = vadd.low.f32.bf16 -1.0, %v77152_v55 (stack53)
        %v78372_v31 = vadd.s32 %v78369_v24, %v78364_v31 (stack40)
        %v78374_v8 = vshll.u32 %v78369_v24, 16 (stack45)
        %v77570_v40 = vor.u32 %v77569_v53, %v77568_v10 (stack47)
        %v77975_v32 = vadd.s32 %v77972_v29, %v121569_v1 (stack40)
        %v78375_v23 = vshrl.u32 %v78369_v24, 16 (stack46)
        %v78827_v44 = vor.u32 %v78826_v12, %v78825_v42 (stack47)
        %v76813_v34 = vmul.f32 %v76809_v7, %v144593_v60 (stack54)
        %v77161_v30 = vmul.f32 2.0, %v120156_v45 (stack54)
        %v77967_v61 = vadd.s32 %v77963_v61, %v121574_v2 (stack40)
        %v144608_v9 = vsel /*vm=*/%vm79234_vm5, /*on_true_vy=*/%v79243_v54, /*on_false_vx=*/%v79239_v9 (stack44)
        %v77571_v54 = vxor.u32 %v77570_v40, %v77566_v6 (stack48)
        %v77979_v24 = vadd.s32 3, %v77975_v32 (stack40)
        %v78376_v52 = vor.u32 %v78375_v23, %v78374_v8 (stack47)
        %v78828_v55 = vxor.u32 %v78827_v44, %v78823_v50 (stack48)
        %v76750_v42 = vsel /*vm=*/%vm76737_vm2, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v76817_v41 = vadd.f32 %v76813_v34, %v144557_v41 (stack53)
        %v77165_v12 = vadd.f32 -0.99609375, %v77161_v30 (stack53)
        %v79225_v10 = vadd.s32 %v144498_v56, %v122657_v58 (stack40)
        %v77574_v6 = vadd.s32 %v77571_v54, %v77566_v6 (stack40)
        %v77576_v53 = vshll.u32 %v77571_v54, 15 (stack45)
        %v77577_v29 = vshrl.u32 %v77571_v54, 17 (stack46)
        %v77983_v7 = vadd.s32 %v77979_v24, %v77967_v61 (stack40)
        %v76821_v45 = vmul.f32 %v76817_v41, %v144593_v60 (stack54)
        %v144617_v8 = vmax.f32 %v77165_v12, -0.99609375 (stack55)
        %v77985_v40 = vshll.u32 %v77979_v24, 17 (stack45)
        %v77986_v32 = vshrl.u32 %v77979_v24, 15 (stack46)
        %v76758_v23 = vsel /*vm=*/%vm76737_vm2, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v77578_v44 = vor.u32 %v77577_v29, %v77576_v53 (stack47)
        %v78377_v34 = vxor.u32 %v78376_v52, %v78372_v31 (stack48)
        %v144622_v50 = vadd.s32 %v78828_v55, %v78823_v50 (stack40)
        %v76754_v26 = vsel /*vm=*/%vm76737_vm2, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v76825_v30 = vadd.f32 %v76821_v45, %v76758_v23 (stack53)
        %v77181_v61 = vxor.u32 2147483648, %v144617_v8 (stack56)
        %vm79229_vm6 = vcmp.lt.u32.totalorder %v79225_v10, %v144498_v56 (stack43)
        %v77579_v54 = vxor.u32 %v77578_v44, %v77574_v6 (stack48)
        %v77987_v24 = vor.u32 %v77986_v32, %v77985_v40 (stack47)
        %v78380_v31 = vadd.s32 %v78377_v34, %v78372_v31 (stack40)
        %v79264_v52 = vadd.s32 %v79225_v10, %v121569_v1 (stack40)
        %v76829_v41 = vmul.f32 %v76825_v30, %v144593_v60 (stack54)
        %v144632_v12 = vmul.f32 %v77181_v61, %v144617_v8 (stack54)
        %v78386_v53 = vshll.u32 %v78377_v34, 24 (stack45)
        %v78387_v29 = vshrl.u32 %v78377_v34, 8 (stack46)
        %v77582_v6 = vadd.s32 %v77579_v54, %v77574_v6 (stack40)
        %v77584_v45 = vshll.u32 %v77579_v54, 26 (stack45)
        %v77585_v40 = vshrl.u32 %v77579_v54, 6 (stack46)
        %v77988_v32 = vxor.u32 %v77987_v24, %v77983_v7 (stack48)
        %v76833_v23 = vadd.f32 %v76829_v41, %v76754_v26 (stack53)
        %v77186_v44 = vadd.f32 1.0, %v144632_v12 (stack57)
        %v77189_v34 = vmul.f32 -0.5, %v144632_v12 (stack59)
        %v79251_v26 = vadd.s32 1, %v144608_v9 (stack40)
        %v77586_v30 = vor.u32 %v77585_v40, %v77584_v45 (stack47)
        %v77991_v7 = vadd.s32 %v77988_v32, %v77983_v7 (stack40)
        %v77993_v61 = vshll.u32 %v77988_v32, 29 (stack45)
        %v77994_v54 = vshrl.u32 %v77988_v32, 3 (stack46)
        %v76837_v24 = vmul.f32 %v76833_v23, %v144593_v60 (stack54)
        %121089 = vlog2.f32 %v77186_v44 (stack58)
        %v78837_v41 = vshll.u32 %v78828_v55, 6 (stack45)
        %v79270_v45 = vshll.u32 %v79264_v52, 13 (stack45)
        %v77192_v40 = vand.u32 2147483647, %v144632_v12 (stack60)
        %v77587_v32 = vxor.u32 %v77586_v30, %v77582_v6 (stack48)
        %v77995_v23 = vor.u32 %v77994_v54, %v77993_v61 (stack47)
        %v78388_v53 = vor.u32 %v78387_v29, %v78386_v53 (stack47)
        %v76841_v42 = vadd.f32 %v76837_v24, %v76750_v42 (stack53)
        %v77190_v29 = vadd.f32 1.0, %v77189_v34 (stack61)
        %v78384_v44 = vadd.s32 %v78380_v31, %v121564_v0 (stack40)
        %v78838_v55 = vshrl.u32 %v78828_v55, 26 (stack46)
        %v77590_v6 = vadd.s32 %v77587_v32, %v77582_v6 (stack40)
        %v77596_v34 = vshll.u32 %v77587_v32, 6 (stack45)
        %v77597_v30 = vshrl.u32 %v77587_v32, 26 (stack46)
        %v77996_v61 = vxor.u32 %v77995_v23, %v77991_v7 (stack48)
        %v76845_v54 = vmul.f32 %v76841_v42, %v144593_v60 (stack54)
        %v78389_v31 = vxor.u32 %v78388_v53, %v78380_v31 (stack48)
        %v78839_v24 = vor.u32 %v78838_v55, %v78837_v41 (stack47)
        %v79255_v56 = vsel /*vm=*/%vm79229_vm6, /*on_true_vy=*/%v79251_v26, /*on_false_vx=*/%v144608_v9 (stack44)
        %vm144646_vm7 = vcmp.eq.f32.partialorder %v76710_v27, 1.0 (stack68)
        %v77598_v9 = vor.u32 %v77597_v30, %v77596_v34 (stack47)
        %v77999_v10 = vadd.s32 %v77996_v61, %v77991_v7 (stack40)
        %v78001_v26 = vshll.u32 %v77996_v61, 16 (stack45)
        %v78835_v7 = vadd.s32 %v144622_v50, %v121569_v1 (stack40)
        %v76849_v46 = vadd.f32 %v76845_v54, %v144548_v46 (stack53)
        %v78002_v41 = vshrl.u32 %v77996_v61, 16 (stack46)
        %v78392_v32 = vadd.s32 %v78389_v31, %v121574_v2 (stack40)
        %v78840_v50 = vxor.u32 %v78839_v24, %v144622_v50 (stack48)
        %vm144655_vm8 = vcmp.lt.f32.partialorder %v77192_v40, 0.0004427343 (stack62)
        %v77599_v23 = vxor.u32 %v77598_v9, %v77590_v6 (stack48)
        %v79260_v53 = vadd.s32 %v79255_v56, %v121574_v2 (stack40)
        %v79271_v42 = vshrl.u32 %v79264_v52, 19 (stack46)
        %v144662_v55 = vadd.s32 %v157562_v25, %v157077_v51 (stack40)
        %v76853_v60 = vmul.f32 %v76849_v46, %v144593_v60 (stack54)
        %v78003_v34 = vor.u32 %v78002_v41, %v78001_v26 (stack47)
        %v78396_v30 = vadd.s32 2, %v78392_v32 (stack40)
        %v78843_v61 = vadd.s32 %v78840_v50, %v121564_v0 (stack40)
        %v77594_v6 = vadd.s32 %v77590_v6, %v121564_v0 (stack40)
        %v77602_v54 = vadd.s32 %v77599_v23, %v121574_v2 (stack40)
        %v79268_v52 = vadd.s32 %v79264_v52, %v79260_v53 (stack40)
        %v79272_v45 = vor.u32 %v79271_v42, %v79270_v45 (stack47)
        %v76857_v22 = vadd.f32 %v76853_v60, %v144543_v22 (stack53)
        %v78004_v31 = vxor.u32 %v78003_v34, %v77999_v10 (stack48)
        %v78400_v44 = vadd.s32 %v78396_v30, %v78384_v44 (stack40)
        %v78402_v24 = vshll.u32 %v78396_v30, 13 (stack45)
        %v77606_v56 = vadd.s32 5, %v77602_v54 (stack40)
        %v78403_v9 = vshrl.u32 %v78396_v30, 19 (stack46)
        %v78847_v26 = vadd.s32 1, %v78843_v61 (stack40)
        %v144669_v46 = vxor.u32 %v79272_v45, %v79268_v52 (stack48)
        %v76861_v21 = vmul.f32 %v76857_v22, %v144450_v21 (stack54)
        %v78007_v10 = vadd.s32 %v78004_v31, %v77999_v10 (stack40)
        %v78013_v41 = vshll.u32 %v78004_v31, 24 (stack45)
        %v78014_v32 = vshrl.u32 %v78004_v31, 8 (stack46)
        %v121090_v50 = vpop.eup %121089 (stack64)
        %v77191_v12 = vmul.f32 %v77190_v29, %v144632_v12 (stack63)
        %v77608_v29 = vxor.u32 %v77606_v56, %v77594_v6 (stack48)
        %v78404_v23 = vor.u32 %v78403_v9, %v78402_v24 (stack47)
        %v78851_v7 = vadd.s32 %v78847_v26, %v78835_v7 (stack40)
        %v76865_v20 = vsel /*vm=*/%vm144646_vm7, /*on_true_vy=*/%v144537_v20, /*on_false_vx=*/%v76861_v21 (stack44)
        %v77188_v27 = vmul.f32 0.6931472, %v121090_v50 (stack65)
        %v78015_v53 = vor.u32 %v78014_v32, %v78013_v41 (stack47)
        %v78853_v42 = vshll.u32 %v78847_v26, 17 (stack45)
        %v76869_v60 = vmul.f32 1.4140625, %v76865_v20 (stack54)
        %v77609_v34 = vand.u32.u8 255, %v77608_v29 (stack49)
        %v78405_v30 = vxor.u32 %v78404_v23, %v78400_v44 (stack48)
        %v78854_v61 = vshrl.u32 %v78847_v26, 15 (stack46)
        %v77194_v40 = vsel /*vm=*/%vm144655_vm8, /*on_true_vy=*/%v77191_v12, /*on_false_vx=*/%v77188_v27 (stack66)
        %v78016_v6 = vxor.u32 %v78015_v53, %v78007_v10 (stack48)
        %v144679_v54 = vadd.s32 %v144669_v46, %v79268_v52 (stack40)
        %v76872_v52 = vpack.c.bf16 %v157387_v11, %v76869_v60 (stack81)
        %v144682_v45 = vxor.u32 2147483648, %v77194_v40 (stack56)
        %v78408_v22 = vadd.s32 %v78405_v30, %v78400_v44 (stack40)
        %v78410_v31 = vshll.u32 %v78405_v30, 15 (stack45)
        %v78411_v44 = vshrl.u32 %v78405_v30, 17 (stack46)
        %v78855_v24 = vor.u32 %v78854_v61, %v78853_v42 (stack47)
        %120155 = vst [vmem:[%s123356_s30 + $0x1d0] sm:$0xf] /*vst_source=*/%v76872_v52 (stack83)
        %121091 = vrsqrt.f32 %v144682_v45 (stack67)
        %v77610_v56 = vand.u32 65535, %v77609_v34 (stack50)
        %v78019_v9 = vadd.s32 %v78016_v6, %v121564_v0 (stack40)
        %v78412_v26 = vor.u32 %v78411_v44, %v78410_v31 (stack47)
        %v78856_v21 = vxor.u32 %v78855_v24, %v78851_v7 (stack48)
        %v78011_v10 = vadd.s32 %v78007_v10, %v121569_v1 (stack40)
        %v78413_v41 = vxor.u32 %v78412_v26, %v78408_v22 (stack48)
        %v79278_v32 = vshll.u32 %v144669_v46, 15 (stack45)
        %v144691_v50 = vadd.s32 %v144662_v55, %v122657_v58 (stack40)
        %vm77198_vm9 = vcmp.lt.f32.partialorder %v144682_v45, 5.0 (stack68)
        %v144695_v12 = vadd.f32 -2.5, %v144682_v45 (stack53)
        %v77611_v29 = vshrl.u32 %v77610_v56, 1 (stack51)
        %v78023_v23 = vadd.s32 4, %v78019_v9 (stack40)
        %v78416_v20 = vadd.s32 %v78413_v41, %v78408_v22 (stack40)
        %v78418_v27 = vshll.u32 %v78413_v41, 26 (stack45)
        %v78419_v53 = vshrl.u32 %v78413_v41, 6 (stack46)
        %v78859_v7 = vadd.s32 %v78856_v21, %v78851_v7 (stack40)
        %v77612_v42 = vor.u32 16256, %v77611_v29 (stack47)
        %v78027_v60 = vadd.s32 %v78023_v23, %v78011_v10 (stack40)
        %v78029_v34 = vshll.u32 %v78023_v23, 13 (stack45)
        %v78030_v30 = vshrl.u32 %v78023_v23, 19 (stack46)
        %vm77243_vm10 = vcmp.eq.f32.partialorder %v144682_v45, inf (stack70)
        %v78420_v61 = vor.u32 %v78419_v53, %v78418_v27 (stack47)
        %v78861_v40 = vshll.u32 %v78856_v21, 29 (stack45)
        %v78862_v6 = vshrl.u32 %v78856_v21, 3 (stack46)
        %v79279_v46 = vshrl.u32 %v144669_v46, 17 (stack46)
        %v144702_v52 = vsel /*vm=*/%vm77198_vm9, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v77613_v22 = vand.u32.u16 65535, %v77612_v42 (stack52)
        %v78031_v31 = vor.u32 %v78030_v30, %v78029_v34 (stack47)
        %vm79695_vm11 = vcmp.lt.u32.totalorder %v144662_v55, %v157077_v51 (stack43)
        %v144709_v44 = vsel /*vm=*/%vm77198_vm9, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v78421_v24 = vxor.u32 %v78420_v61, %v78416_v20 (stack48)
        %v78863_v56 = vor.u32 %v78862_v6, %v78861_v40 (stack47)
        %v144713_v9 = vadd.s32 %v157563_v43, %v157078_v48 (stack40)
        %v120158_v26 = vadd.low.f32.bf16 -1.0, %v77613_v22 (stack53)
        %v78032_v21 = vxor.u32 %v78031_v31, %v78027_v60 (stack48)
        %v79280_v10 = vor.u32 %v79279_v46, %v79278_v32 (stack47)
        %v144717_v41 = vadd.s32 %v157562_v25, %v157079_v39 (stack40)
        %v78424_v32 = vadd.s32 %v78421_v24, %v78416_v20 (stack40)
        %v78430_v29 = vshll.u32 %v78421_v24, 6 (stack45)
        %v78431_v23 = vshrl.u32 %v78421_v24, 26 (stack46)
        %v78864_v20 = vxor.u32 %v78863_v56, %v78859_v7 (stack48)
        %v77622_v27 = vmul.f32 2.0, %v120158_v26 (stack54)
        %v78035_v53 = vadd.s32 %v78032_v21, %v78027_v60 (stack40)
        %v78037_v42 = vshll.u32 %v78032_v21, 15 (stack45)
        %v78038_v60 = vshrl.u32 %v78032_v21, 17 (stack46)
        %v121092_v34 = vpop.eup %121091 (stack73)
        %v144722_v30 = vsel /*vm=*/%vm77198_vm9, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v78432_v61 = vor.u32 %v78431_v23, %v78430_v29 (stack47)
        %v78867_v7 = vadd.s32 %v78864_v20, %v78859_v7 (stack40)
        %v78869_v40 = vshll.u32 %v78864_v20, 16 (stack45)
        %v77242_v6 = vmul.f32 %v121092_v34, %v144682_v45 (stack74)
        %v77626_v46 = vadd.f32 -0.99609375, %v77622_v27 (stack53)
        %v78039_v22 = vor.u32 %v78038_v60, %v78037_v42 (stack47)
        %v78870_v31 = vshrl.u32 %v78864_v20, 16 (stack46)
        %vm77245_vm12 = vcmp.eq.f32.partialorder %v144682_v45, 0.0 (stack71)
        %v77246_v24 = vand.u32 2147483648, %v144682_v45 (stack72)
        %v78433_v56 = vxor.u32 %v78432_v61, %v78424_v32 (stack48)
        %v79281_v26 = vxor.u32 %v79280_v10, %v144679_v54 (stack48)
        %v77244_v21 = vsel /*vm=*/%vm77243_vm10, /*on_true_vy=*/%v144682_v45, /*on_false_vx=*/%v77242_v6 (stack75)
        %v144731_v10 = vmax.f32 %v77626_v46, -0.99609375 (stack55)
        %v78040_v29 = vxor.u32 %v78039_v22, %v78035_v53 (stack48)
        %v78871_v23 = vor.u32 %v78870_v31, %v78869_v40 (stack47)
        %v77227_v20 = vsel /*vm=*/%vm77198_vm9, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v77247_v27 = vsel /*vm=*/%vm77245_vm12, /*on_true_vy=*/%v77246_v24, /*on_false_vx=*/%v77244_v21 (stack76)
        %v78436_v42 = vadd.s32 %v78433_v56, %v121569_v1 (stack40)
        %v144738_v54 = vadd.s32 %v79281_v26, %v144679_v54 (stack40)
        %v77231_v60 = vsel /*vm=*/%vm77198_vm9, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v77250_v34 = vadd.f32 -3.0, %v77247_v27 (stack53)
        %v77642_v61 = vxor.u32 2147483648, %v144731_v10 (stack56)
        %v78428_v32 = vadd.s32 %v78424_v32, %v121574_v2 (stack40)
        %v78043_v53 = vadd.s32 %v78040_v29, %v78035_v53 (stack40)
        %v78045_v40 = vshll.u32 %v78040_v29, 26 (stack45)
        %v78046_v6 = vshrl.u32 %v78040_v29, 6 (stack46)
        %v78440_v46 = vadd.s32 3, %v78436_v42 (stack40)
        %v77235_v22 = vsel /*vm=*/%vm77198_vm9, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v144751_v12 = vsel /*vm=*/%vm77198_vm9, /*on_true_vy=*/%v144695_v12, /*on_false_vx=*/%v77250_v34 (stack44)
        %v77645_v31 = vmul.f32 %v77642_v61, %v144731_v10 (stack54)
        %v78872_v24 = vxor.u32 %v78871_v23, %v78867_v7 (stack48)
        %v77258_v56 = vmul.f32 %v144751_v12, %v77235_v22 (stack54)
        %v78047_v21 = vor.u32 %v78046_v6, %v78045_v40 (stack47)
        %v78444_v29 = vadd.s32 %v78440_v46, %v78428_v32 (stack40)
        %v78446_v23 = vshll.u32 %v78440_v46, 17 (stack45)
        %vm79690_vm13 = vcmp.lt.u32.totalorder %v144691_v50, %v144662_v55 (stack43)
        %v77647_v27 = vadd.f32 1.0, %v77645_v31 (stack57)
        %v78447_v42 = vshrl.u32 %v78440_v46, 15 (stack46)
        %v79704_v34 = vadd.s32 1, %v144713_v9 (stack40)
        %v144760_v61 = vadd.s32 %v144691_v50, %v121569_v1 (stack40)
        %v77262_v60 = vadd.f32 %v77258_v56, %v77231_v60 (stack53)
        %v77650_v32 = vmul.f32 -0.5, %v77645_v31 (stack59)
        %v78048_v40 = vxor.u32 %v78047_v21, %v78043_v53 (stack48)
        %v78875_v7 = vadd.s32 %v78872_v24, %v78867_v7 (stack40)
        %121093 = vlog2.f32 %v77647_v27 (stack58)
        %v78448_v6 = vor.u32 %v78447_v42, %v78446_v23 (stack47)
        %v78881_v46 = vshll.u32 %v78872_v24, 24 (stack45)
        %v79286_v22 = vshll.u32 %v79281_v26, 26 (stack45)
        %v77266_v56 = vmul.f32 %v77262_v60, %v144751_v12 (stack54)
        %v78051_v53 = vadd.s32 %v78048_v40, %v78043_v53 (stack40)
        %v78057_v21 = vshll.u32 %v78048_v40, 6 (stack45)
        %v78058_v23 = vshrl.u32 %v78048_v40, 26 (stack46)
        %v77653_v27 = vand.u32 2147483647, %v77645_v31 (stack60)
        %v78449_v42 = vxor.u32 %v78448_v6, %v78444_v29 (stack48)
        %v78882_v24 = vshrl.u32 %v78872_v24, 8 (stack46)
        %v79731_v60 = vshll.u32 %v144760_v61, 13 (stack45)
        %v77270_v20 = vadd.f32 %v77266_v56, %v77227_v20 (stack53)
        %v77651_v32 = vadd.f32 1.0, %v77650_v32 (stack61)
        %v78059_v40 = vor.u32 %v78058_v23, %v78057_v21 (stack47)
        %v79287_v26 = vshrl.u32 %v79281_v26, 6 (stack46)
        %v78452_v29 = vadd.s32 %v78449_v42, %v78444_v29 (stack40)
        %v78454_v6 = vshll.u32 %v78449_v42, 29 (stack45)
        %v78455_v56 = vshrl.u32 %v78449_v42, 3 (stack46)
        %v78883_v46 = vor.u32 %v78882_v24, %v78881_v46 (stack47)
        %v77274_v21 = vmul.f32 %v77270_v20, %v144751_v12 (stack54)
        %v78060_v23 = vxor.u32 %v78059_v40, %v78051_v53 (stack48)
        %v79288_v22 = vor.u32 %v79287_v26, %v79286_v22 (stack47)
        %v79708_v9 = vsel /*vm=*/%vm79695_vm11, /*on_true_vy=*/%v79704_v34, /*on_false_vx=*/%v144713_v9 (stack44)
        %v78456_v34 = vor.u32 %v78455_v56, %v78454_v6 (stack47)
        %v78879_v42 = vadd.s32 %v78875_v7, %v121564_v0 (stack40)
        %v78884_v7 = vxor.u32 %v78883_v46, %v78875_v7 (stack48)
        %v79712_v24 = vadd.s32 1, %v79708_v9 (stack40)
        %v77278_v30 = vadd.f32 %v77274_v21, %v144722_v30 (stack53)
        %vm144771_vm14 = vcmp.lt.f32.partialorder %v77653_v27, 0.0004427343 (stack62)
        %v78055_v53 = vadd.s32 %v78051_v53, %v121564_v0 (stack40)
        %v78063_v20 = vadd.s32 %v78060_v23, %v121574_v2 (stack40)
        %v79289_v40 = vxor.u32 %v79288_v22, %v144738_v54 (stack48)
        %v78457_v26 = vxor.u32 %v78456_v34, %v78452_v29 (stack48)
        %v78887_v6 = vadd.s32 %v78884_v7, %v121574_v2 (stack40)
        %v79716_v55 = vsel /*vm=*/%vm79690_vm13, /*on_true_vy=*/%v79712_v24, /*on_false_vx=*/%v79708_v9 (stack44)
        %v79732_v50 = vshrl.u32 %v144760_v61, 19 (stack46)
        %v77282_v56 = vmul.f32 %v77278_v30, %v144751_v12 (stack54)
        %v78067_v46 = vadd.s32 5, %v78063_v20 (stack40)
        %v79292_v54 = vadd.s32 %v79289_v40, %v144738_v54 (stack40)
        %v79298_v21 = vshll.u32 %v79289_v40, 6 (stack45)
        %v78460_v29 = vadd.s32 %v78457_v26, %v78452_v29 (stack40)
        %v78462_v23 = vshll.u32 %v78457_v26, 16 (stack45)
        %v78463_v22 = vshrl.u32 %v78457_v26, 16 (stack46)
        %v78891_v9 = vadd.s32 2, %v78887_v6 (stack40)
        %v77286_v44 = vadd.f32 %v77282_v56, %v144709_v44 (stack53)
        %v77652_v31 = vmul.f32 %v77651_v32, %v77645_v31 (stack63)
        %v78069_v32 = vxor.u32 %v78067_v46, %v78055_v53 (stack48)
        %v79299_v34 = vshrl.u32 %v79289_v40, 26 (stack46)
        %v78464_v7 = vor.u32 %v78463_v22, %v78462_v23 (stack47)
        %v78895_v42 = vadd.s32 %v78891_v9, %v78879_v42 (stack40)
        %v78897_v24 = vshll.u32 %v78891_v9, 13 (stack45)
        %v78898_v30 = vshrl.u32 %v78891_v9, 19 (stack46)
        %v121094_v53 = vpop.eup %121093 (stack64)
        %v77290_v20 = vmul.f32 %v77286_v44, %v144751_v12 (stack54)
        %v78070_v40 = vand.u32.u8 255, %v78069_v32 (stack49)
        %v79300_v26 = vor.u32 %v79299_v34, %v79298_v21 (stack47)
        %v79721_v6 = vadd.s32 %v79716_v55, %v121574_v2 (stack40)
        %v77649_v55 = vmul.f32 0.6931472, %v121094_v53 (stack65)
        %v78465_v56 = vxor.u32 %v78464_v7, %v78460_v29 (stack48)
        %v78899_v46 = vor.u32 %v78898_v30, %v78897_v24 (stack47)
        %v79733_v60 = vor.u32 %v79732_v50, %v79731_v60 (stack47)
        %v77294_v52 = vadd.f32 %v77290_v20, %v144702_v52 (stack53)
        %v78071_v50 = vand.u32 65535, %v78070_v40 (stack50)
        %v79301_v21 = vxor.u32 %v79300_v26, %v79292_v54 (stack48)
        %v79729_v61 = vadd.s32 %v144760_v61, %v79721_v6 (stack40)
        %v77655_v27 = vsel /*vm=*/%vm144771_vm14, /*on_true_vy=*/%v77652_v31, /*on_false_vx=*/%v77649_v55 (stack66)
        %v78468_v29 = vadd.s32 %v78465_v56, %v78460_v29 (stack40)
        %v78474_v23 = vshll.u32 %v78465_v56, 24 (stack45)
        %v78475_v22 = vshrl.u32 %v78465_v56, 8 (stack46)
        %v77298_v9 = vmul.f32 %v77294_v52, %v144751_v12 (stack54)
        %v144793_v44 = vxor.u32 2147483648, %v77655_v27 (stack56)
        %v78900_v31 = vxor.u32 %v78899_v46, %v78895_v42 (stack48)
        %v77171_v32 = vand.u32 2147483647, %v144617_v8 (stack77)
        %v77211_v34 = vsel /*vm=*/%vm77198_vm9, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v78476_v7 = vor.u32 %v78475_v22, %v78474_v23 (stack47)
        %v144799_v24 = vxor.u32 %v79733_v60, %v79729_v61 (stack48)
        %v77302_v30 = vadd.f32 %v77298_v9, %v77211_v34 (stack53)
        %121095 = vrsqrt.f32 %v144793_v44 (stack67)
        %vm77659_vm15 = vcmp.lt.f32.partialorder %v144793_v44, 5.0 (stack68)
        %v78072_v53 = vshrl.u32 %v78071_v50, 1 (stack51)
        %v78477_v20 = vxor.u32 %v78476_v7, %v78468_v29 (stack48)
        %v77179_v40 = vmul.f32 inf, %v144617_v8 (stack54)
        %v77203_v26 = vsel /*vm=*/%vm77198_vm9, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v77306_v6 = vmul.f32 %v77302_v30, %v144751_v12 (stack54)
        %v79304_v55 = vadd.s32 %v79301_v21, %v121564_v0 (stack40)
        %vm144809_vm0 = vcmp.eq.f32.partialorder %v77171_v32, 1.0 (stack68)
        %v77207_v45 = vsel /*vm=*/%vm77198_vm9, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v78480_v46 = vadd.s32 %v78477_v20, %v121564_v0 (stack40)
        %v79296_v54 = vadd.s32 %v79292_v54, %v121569_v1 (stack40)
        %v144820_v60 = vadd.s32 %v144717_v41, %v122657_v58 (stack40)
        %v77310_v52 = vadd.f32 %v77306_v6, %v77207_v45 (stack53)
        %v144825_v50 = vsel /*vm=*/%vm77659_vm15, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v144828_v21 = vadd.f32 -2.5, %v144793_v44 (stack53)
        %v78472_v27 = vadd.s32 %v78468_v29, %v121569_v1 (stack40)
        %v78073_v29 = vor.u32 16256, %v78072_v53 (stack47)
        %v78484_v23 = vadd.s32 4, %v78480_v46 (stack40)
        %v78903_v42 = vadd.s32 %v78900_v31, %v78895_v42 (stack40)
        %v78905_v22 = vshll.u32 %v78900_v31, 15 (stack45)
        %v77314_v12 = vmul.f32 %v77310_v52, %v144751_v12 (stack54)
        %v78906_v9 = vshrl.u32 %v78900_v31, 17 (stack46)
        %v79308_v31 = vadd.s32 1, %v79304_v55 (stack40)
        %v144833_v61 = vadd.s32 %v144799_v24, %v79729_v61 (stack40)
        %vm77704_vm1 = vcmp.eq.f32.partialorder %v144793_v44, inf (stack70)
        %v78074_v32 = vand.u32.u16 65535, %v78073_v29 (stack52)
        %v78488_v34 = vadd.s32 %v78484_v23, %v78472_v27 (stack40)
        %v78490_v7 = vshll.u32 %v78484_v23, 13 (stack45)
        %v78491_v30 = vshrl.u32 %v78484_v23, 19 (stack46)
        %v77318_v53 = vadd.f32 %v77314_v12, %v77203_v26 (stack53)
        %v78907_v20 = vor.u32 %v78906_v9, %v78905_v22 (stack47)
        %v79312_v26 = vadd.s32 %v79308_v31, %v79296_v54 (stack40)
        %v79314_v6 = vshll.u32 %v79308_v31, 17 (stack45)
        %vm77706_vm2 = vcmp.eq.f32.partialorder %v144793_v44, 0.0 (stack71)
        %v120160_v55 = vadd.low.f32.bf16 -1.0, %v78074_v32 (stack53)
        %v78492_v45 = vor.u32 %v78491_v30, %v78490_v7 (stack47)
        %v79315_v46 = vshrl.u32 %v79308_v31, 15 (stack46)
        %v77322_v8 = vmul.f32 %v77318_v53, %v144617_v8 (stack54)
        %v77707_v54 = vand.u32 2147483648, %v144793_v44 (stack72)
        %v78908_v52 = vxor.u32 %v78907_v20, %v78903_v42 (stack48)
        %vm80156_vm3 = vcmp.lt.u32.totalorder %v144717_v41, %v157079_v39 (stack43)
        %v78083_v27 = vmul.f32 2.0, %v120160_v55 (stack54)
        %v78493_v29 = vxor.u32 %v78492_v45, %v78488_v34 (stack48)
        %v79316_v23 = vor.u32 %v79315_v46, %v79314_v6 (stack47)
        %v80161_v22 = vadd.s32 %v157563_v43, %v157082_v49 (stack40)
        %v77326_v40 = vsel /*vm=*/%vm144809_vm0, /*on_true_vy=*/%v77179_v40, /*on_false_vx=*/%v77322_v8 (stack44)
        %v78911_v56 = vadd.s32 %v78908_v52, %v78903_v42 (stack40)
        %v78913_v42 = vshll.u32 %v78908_v52, 26 (stack45)
        %v78914_v12 = vshrl.u32 %v78908_v52, 6 (stack46)
        %v121096_v9 = vpop.eup %121095 (stack73)
        %v77330_v31 = vmul.f32 1.4140625, %v77326_v40 (stack54)
        %v78087_v32 = vadd.f32 -0.99609375, %v78083_v27 (stack53)
        %v78496_v34 = vadd.s32 %v78493_v29, %v78488_v34 (stack40)
        %v78498_v7 = vshll.u32 %v78493_v29, 15 (stack45)
        %v77703_v30 = vmul.f32 %v121096_v9, %v144793_v44 (stack74)
        %v78499_v53 = vshrl.u32 %v78493_v29, 17 (stack46)
        %v78915_v20 = vor.u32 %v78914_v12, %v78913_v42 (stack47)
        %v79317_v6 = vxor.u32 %v79316_v23, %v79312_v26 (stack48)
        %v77333_v55 = vpack.c.bf16 %v157387_v11, %v77330_v31 (stack81)
        %v144847_v45 = vmax.f32 %v78087_v32, -0.99609375 (stack55)
        %v79739_v46 = vshll.u32 %v144799_v24, 15 (stack45)
        %v79740_v24 = vshrl.u32 %v144799_v24, 17 (stack46)
        %v77705_v8 = vsel /*vm=*/%vm77704_vm1, /*on_true_vy=*/%v144793_v44, /*on_false_vx=*/%v77703_v30 (stack75)
        %v78500_v52 = vor.u32 %v78499_v53, %v78498_v7 (stack47)
        %v78916_v27 = vxor.u32 %v78915_v20, %v78911_v56 (stack48)
        %v79320_v26 = vadd.s32 %v79317_v6, %v79312_v26 (stack40)
        %120157 = vst [vmem:[%s123356_s30 + $0x250] sm:$0xf] /*vst_source=*/%v77333_v55 (stack83)
        %v144858_v29 = vsel /*vm=*/%vm77659_vm15, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v77696_v23 = vsel /*vm=*/%vm77659_vm15, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v77708_v54 = vsel /*vm=*/%vm77706_vm2, /*on_true_vy=*/%v77707_v54, /*on_false_vx=*/%v77705_v8 (stack76)
        %v78103_v40 = vxor.u32 2147483648, %v144847_v45 (stack56)
        %v77711_v42 = vadd.f32 -3.0, %v77708_v54 (stack53)
        %v78501_v12 = vxor.u32 %v78500_v52, %v78496_v34 (stack48)
        %v78919_v56 = vadd.s32 %v78916_v27, %v78911_v56 (stack40)
        %v78925_v9 = vshll.u32 %v78916_v27, 6 (stack45)
        %v78106_v31 = vmul.f32 %v78103_v40, %v144847_v45 (stack54)
        %v78926_v32 = vshrl.u32 %v78916_v27, 26 (stack46)
        %v79322_v7 = vshll.u32 %v79317_v6, 29 (stack45)
        %v79741_v30 = vor.u32 %v79740_v24, %v79739_v46 (stack47)
        %v144870_v21 = vsel /*vm=*/%vm77659_vm15, /*on_true_vy=*/%v144828_v21, /*on_false_vx=*/%v77711_v42 (stack44)
        %v78504_v34 = vadd.s32 %v78501_v12, %v78496_v34 (stack40)
        %v78506_v53 = vshll.u32 %v78501_v12, 26 (stack45)
        %v78507_v20 = vshrl.u32 %v78501_v12, 6 (stack46)
        %v77684_v55 = vsel /*vm=*/%vm77659_vm15, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v77688_v46 = vsel /*vm=*/%vm77659_vm15, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v77719_v24 = vmul.f32 %v144870_v21, %v77696_v23 (stack54)
        %v78108_v8 = vadd.f32 1.0, %v78106_v31 (stack57)
        %v77692_v52 = vsel /*vm=*/%vm77659_vm15, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v78508_v27 = vor.u32 %v78507_v20, %v78506_v53 (stack47)
        %v78927_v23 = vor.u32 %v78926_v32, %v78925_v9 (stack47)
        %v79323_v6 = vshrl.u32 %v79317_v6, 3 (stack46)
        %vm80151_vm4 = vcmp.lt.u32.totalorder %v144820_v60, %v144717_v41 (stack43)
        %v77723_v54 = vadd.f32 %v77719_v24, %v77692_v52 (stack53)
        %121097 = vlog2.f32 %v78108_v8 (stack58)
        %v78111_v40 = vmul.f32 -0.5, %v78106_v31 (stack59)
        %v80165_v42 = vadd.s32 1, %v80161_v22 (stack40)
        %v78509_v12 = vxor.u32 %v78508_v27, %v78504_v34 (stack48)
        %v78928_v9 = vxor.u32 %v78927_v23, %v78919_v56 (stack48)
        %v79324_v32 = vor.u32 %v79323_v6, %v79322_v7 (stack47)
        %v79742_v7 = vxor.u32 %v79741_v30, %v144833_v61 (stack48)
        %v77727_v30 = vmul.f32 %v77723_v54, %v144870_v21 (stack54)
        %v78114_v53 = vand.u32 2147483647, %v78106_v31 (stack60)
        %v78923_v56 = vadd.s32 %v78919_v56, %v121574_v2 (stack40)
        %v80169_v22 = vsel /*vm=*/%vm80156_vm3, /*on_true_vy=*/%v80165_v42, /*on_false_vx=*/%v80161_v22 (stack44)
        %v78512_v34 = vadd.s32 %v78509_v12, %v78504_v34 (stack40)
        %v78518_v20 = vshll.u32 %v78509_v12, 6 (stack45)
        %v78519_v24 = vshrl.u32 %v78509_v12, 26 (stack46)
        %v78931_v8 = vadd.s32 %v78928_v9, %v121569_v1 (stack40)
        %v77731_v46 = vadd.f32 %v77727_v30, %v77688_v46 (stack53)
        %v79325_v52 = vxor.u32 %v79324_v32, %v79320_v26 (stack48)
        %v79745_v61 = vadd.s32 %v79742_v7, %v144833_v61 (stack40)
        %v79747_v27 = vshll.u32 %v79742_v7, 26 (stack45)
        %v78112_v23 = vadd.f32 1.0, %v78111_v40 (stack61)
        %v78520_v6 = vor.u32 %v78519_v24, %v78518_v20 (stack47)
        %v78935_v54 = vadd.s32 3, %v78931_v8 (stack40)
        %v79748_v40 = vshrl.u32 %v79742_v7, 6 (stack46)
        %v77735_v42 = vmul.f32 %v77731_v46, %v144870_v21 (stack54)
        %v79328_v26 = vadd.s32 %v79325_v52, %v79320_v26 (stack40)
        %v79330_v12 = vshll.u32 %v79325_v52, 16 (stack45)
        %v79331_v9 = vshrl.u32 %v79325_v52, 16 (stack46)
        %v78521_v32 = vxor.u32 %v78520_v6, %v78512_v34 (stack48)
        %v78939_v7 = vadd.s32 %v78935_v54, %v78923_v56 (stack40)
        %v78941_v30 = vshll.u32 %v78935_v54, 17 (stack45)
        %v78942_v56 = vshrl.u32 %v78935_v54, 15 (stack46)
        %v77739_v55 = vadd.f32 %v77735_v42, %v77684_v55 (stack53)
        %v79332_v20 = vor.u32 %v79331_v9, %v79330_v12 (stack47)
        %v79749_v24 = vor.u32 %v79748_v40, %v79747_v27 (stack47)
        %v80173_v8 = vadd.s32 1, %v80169_v22 (stack40)
        %v78113_v31 = vmul.f32 %v78112_v23, %v78106_v31 (stack63)
        %vm144893_vm5 = vcmp.lt.f32.partialorder %v78114_v53, 0.0004427343 (stack62)
        %v78524_v46 = vadd.s32 %v78521_v32, %v121574_v2 (stack40)
        %v78943_v52 = vor.u32 %v78942_v56, %v78941_v30 (stack47)
        %v77743_v27 = vmul.f32 %v77739_v55, %v144870_v21 (stack54)
        %v79333_v23 = vxor.u32 %v79332_v20, %v79328_v26 (stack48)
        %v79750_v6 = vxor.u32 %v79749_v24, %v79745_v61 (stack48)
        %v80177_v41 = vsel /*vm=*/%vm80151_vm4, /*on_true_vy=*/%v80173_v8, /*on_false_vx=*/%v80169_v22 (stack44)
        %v78516_v22 = vadd.s32 %v78512_v34, %v121564_v0 (stack40)
        %v78528_v34 = vadd.s32 5, %v78524_v46 (stack40)
        %v78944_v54 = vxor.u32 %v78943_v52, %v78939_v7 (stack48)
        %v80186_v60 = vadd.s32 %v144820_v60, %v121569_v1 (stack40)
        %v77747_v29 = vadd.f32 %v77743_v27, %v144858_v29 (stack53)
        %v79336_v40 = vadd.s32 %v79333_v23, %v79328_v26 (stack40)
        %v79342_v42 = vshll.u32 %v79333_v23, 24 (stack45)
        %v79343_v26 = vshrl.u32 %v79333_v23, 8 (stack46)
        %v121098_v12 = vpop.eup %121097 (stack64)
        %v78530_v9 = vxor.u32 %v78528_v34, %v78516_v22 (stack48)
        %v78947_v32 = vadd.s32 %v78944_v54, %v78939_v7 (stack40)
        %v78949_v7 = vshll.u32 %v78944_v54, 29 (stack45)
        %v78950_v30 = vshrl.u32 %v78944_v54, 3 (stack46)
        %v77751_v56 = vmul.f32 %v77747_v29, %v144870_v21 (stack54)
        %v78110_v55 = vmul.f32 0.6931472, %v121098_v12 (stack65)
        %v79344_v20 = vor.u32 %v79343_v26, %v79342_v42 (stack47)
        %v80182_v24 = vadd.s32 %v80177_v41, %v121574_v2 (stack40)
        %v78531_v8 = vand.u32.u8 255, %v78530_v9 (stack49)
        %v78951_v46 = vor.u32 %v78950_v30, %v78949_v7 (stack47)
        %v79753_v61 = vadd.s32 %v79750_v6, %v79745_v61 (stack40)
        %v79759_v52 = vshll.u32 %v79750_v6, 6 (stack45)
        %v77755_v50 = vadd.f32 %v77751_v56, %v144825_v50 (stack53)
        %v78116_v31 = vsel /*vm=*/%vm144893_vm5, /*on_true_vy=*/%v78113_v31, /*on_false_vx=*/%v78110_v55 (stack66)
        %v79345_v53 = vxor.u32 %v79344_v20, %v79336_v40 (stack48)
        %v79760_v27 = vshrl.u32 %v79750_v6, 26 (stack46)
        %v144911_v23 = vxor.u32 2147483648, %v78116_v31 (stack56)
        %v78952_v6 = vxor.u32 %v78951_v46, %v78947_v32 (stack48)
        %v80192_v41 = vshll.u32 %v80186_v60, 13 (stack45)
        %v80193_v22 = vshrl.u32 %v80186_v60, 19 (stack46)
        %v77759_v34 = vmul.f32 %v77755_v50, %v144870_v21 (stack54)
        %v80190_v54 = vadd.s32 %v80186_v60, %v80182_v24 (stack40)
        %v77632_v60 = vand.u32 2147483647, %v144731_v10 (stack77)
        %v77672_v29 = vsel /*vm=*/%vm77659_vm15, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %121099 = vrsqrt.f32 %v144911_v23 (stack67)
        %v78532_v42 = vand.u32 65535, %v78531_v8 (stack50)
        %v77763_v26 = vadd.f32 %v77759_v34, %v77672_v29 (stack53)
        %vm78120_vm6 = vcmp.lt.f32.partialorder %v144911_v23, 5.0 (stack68)
        %v79348_v12 = vadd.s32 %v79345_v53, %v121574_v2 (stack40)
        %v79761_v9 = vor.u32 %v79760_v27, %v79759_v52 (stack47)
        %v77640_v7 = vmul.f32 inf, %v144731_v10 (stack54)
        %v77664_v30 = vsel /*vm=*/%vm77659_vm15, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v78955_v32 = vadd.s32 %v78952_v6, %v78947_v32 (stack40)
        %v80194_v56 = vor.u32 %v80193_v22, %v80192_v41 (stack47)
        %v77668_v44 = vsel /*vm=*/%vm77659_vm15, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v77767_v55 = vmul.f32 %v77763_v26, %v144870_v21 (stack54)
        %v79340_v40 = vadd.s32 %v79336_v40, %v121564_v0 (stack40)
        %v79757_v20 = vadd.s32 %v79753_v61, %v121569_v1 (stack40)
        %vm144931_vm7 = vcmp.eq.f32.partialorder %v77632_v60, 1.0 (stack68)
        %v144938_v8 = vsel /*vm=*/%vm78120_vm6, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v144941_v46 = vadd.f32 -2.5, %v144911_v23 (stack53)
        %v78533_v52 = vshrl.u32 %v78532_v42, 1 (stack51)
        %v78957_v50 = vshll.u32 %v78952_v6, 16 (stack45)
        %v77771_v31 = vadd.f32 %v77767_v55, %v77668_v44 (stack53)
        %v78958_v53 = vshrl.u32 %v78952_v6, 16 (stack46)
        %v79352_v27 = vadd.s32 2, %v79348_v12 (stack40)
        %v79762_v61 = vxor.u32 %v79761_v9, %v79753_v61 (stack48)
        %v78534_v6 = vor.u32 16256, %v78533_v52 (stack47)
        %v80195_v41 = vxor.u32 %v80194_v56, %v80190_v54 (stack48)
        %v144945_v22 = vadd.s32 %v157562_v25, %v157083_v59 (stack40)
        %v144949_v34 = vadd.s32 %v157563_v43, %v157084_v16 (stack40)
        %v77775_v21 = vmul.f32 %v77771_v31, %v144870_v21 (stack54)
        %vm78165_vm8 = vcmp.eq.f32.partialorder %v144911_v23, inf (stack70)
        %v78959_v60 = vor.u32 %v78958_v53, %v78957_v50 (stack47)
        %v79356_v29 = vadd.s32 %v79352_v27, %v79340_v40 (stack40)
        %v79358_v42 = vshll.u32 %v79352_v27, 13 (stack45)
        %v78535_v26 = vand.u32.u16 65535, %v78534_v6 (stack52)
        %v79359_v12 = vshrl.u32 %v79352_v27, 19 (stack46)
        %v79765_v9 = vadd.s32 %v79762_v61, %v121564_v0 (stack40)
        %v144954_v54 = vadd.s32 %v80195_v41, %v80190_v54 (stack40)
        %v77779_v30 = vadd.f32 %v77775_v21, %v77664_v30 (stack53)
        %v144959_v56 = vsel /*vm=*/%vm78120_vm6, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v78168_v44 = vand.u32 2147483648, %v144911_v23 (stack72)
        %v78960_v55 = vxor.u32 %v78959_v60, %v78955_v32 (stack48)
        %v120162_v40 = vadd.low.f32.bf16 -1.0, %v78535_v26 (stack53)
        %v79360_v52 = vor.u32 %v79359_v12, %v79358_v42 (stack47)
        %v79769_v50 = vadd.s32 1, %v79765_v9 (stack40)
        %v80200_v31 = vshll.u32 %v80195_v41, 15 (stack45)
        %v77783_v10 = vmul.f32 %v77779_v30, %v144731_v10 (stack54)
        %v78963_v32 = vadd.s32 %v78960_v55, %v78955_v32 (stack40)
        %v78969_v53 = vshll.u32 %v78960_v55, 24 (stack45)
        %v78970_v27 = vshrl.u32 %v78960_v55, 8 (stack46)
        %v78544_v61 = vmul.f32 2.0, %v120162_v40 (stack54)
        %v79361_v6 = vxor.u32 %v79360_v52, %v79356_v29 (stack48)
        %v79773_v20 = vadd.s32 %v79769_v50, %v79757_v20 (stack40)
        %v79775_v21 = vshll.u32 %v79769_v50, 17 (stack45)
        %v121100_v60 = vpop.eup %121099 (stack73)
        %v77787_v7 = vsel /*vm=*/%vm144931_vm7, /*on_true_vy=*/%v77640_v7, /*on_false_vx=*/%v77783_v10 (stack44)
        %v78971_v24 = vor.u32 %v78970_v27, %v78969_v53 (stack47)
        %v79776_v42 = vshrl.u32 %v79769_v50, 15 (stack46)
        %v80201_v41 = vshrl.u32 %v80195_v41, 17 (stack46)
        %v77791_v26 = vmul.f32 1.4140625, %v77787_v7 (stack54)
        %v78164_v12 = vmul.f32 %v121100_v60, %v144911_v23 (stack74)
        %v78548_v9 = vadd.f32 -0.99609375, %v78544_v61 (stack53)
        %v79364_v29 = vadd.s32 %v79361_v6, %v79356_v29 (stack40)
        %v78972_v30 = vxor.u32 %v78971_v24, %v78963_v32 (stack48)
        %v79366_v55 = vshll.u32 %v79361_v6, 15 (stack45)
        %v79367_v40 = vshrl.u32 %v79361_v6, 17 (stack46)
        %v79777_v52 = vor.u32 %v79776_v42, %v79775_v21 (stack47)
        %v77794_v50 = vpack.c.bf16 %v157387_v11, %v77791_v26 (stack81)
        %v78166_v10 = vsel /*vm=*/%vm78165_vm8, /*on_true_vy=*/%v144911_v23, /*on_false_vx=*/%v78164_v12 (stack75)
        %vm78167_vm9 = vcmp.eq.f32.partialorder %v144911_v23, 0.0 (stack71)
        %v144971_v53 = vmax.f32 %v78548_v9, -0.99609375 (stack55)
        %v78169_v44 = vsel /*vm=*/%vm78167_vm9, /*on_true_vy=*/%v78168_v44, /*on_false_vx=*/%v78166_v10 (stack76)
        %v78975_v27 = vadd.s32 %v78972_v30, %v121564_v0 (stack40)
        %v79368_v61 = vor.u32 %v79367_v40, %v79366_v55 (stack47)
        %v79778_v6 = vxor.u32 %v79777_v52, %v79773_v20 (stack48)
        %120159 = vst [vmem:[%s123356_s30 + $0x2d0] sm:$0xf] /*vst_source=*/%v77794_v50 (stack83)
        %v78157_v21 = vsel /*vm=*/%vm78120_vm6, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v78172_v60 = vadd.f32 -3.0, %v78169_v44 (stack53)
        %v78564_v7 = vxor.u32 2147483648, %v144971_v53 (stack56)
        %v78967_v32 = vadd.s32 %v78963_v32, %v121569_v1 (stack40)
        %v78979_v24 = vadd.s32 4, %v78975_v27 (stack40)
        %v79369_v42 = vxor.u32 %v79368_v61, %v79364_v29 (stack48)
        %v79781_v20 = vadd.s32 %v79778_v6, %v79773_v20 (stack40)
        %v80202_v31 = vor.u32 %v80201_v41, %v80200_v31 (stack47)
        %v144983_v46 = vsel /*vm=*/%vm78120_vm6, /*on_true_vy=*/%v144941_v46, /*on_false_vx=*/%v78172_v60 (stack44)
        %v144986_v41 = vmul.f32 %v78564_v7, %v144971_v53 (stack54)
        %v79783_v26 = vshll.u32 %v79778_v6, 29 (stack45)
        %v79784_v12 = vshrl.u32 %v79778_v6, 3 (stack46)
        %v78180_v9 = vmul.f32 %v144983_v46, %v78157_v21 (stack54)
        %v78983_v30 = vadd.s32 %v78979_v24, %v78967_v32 (stack40)
        %v78985_v55 = vshll.u32 %v78979_v24, 13 (stack45)
        %v78986_v40 = vshrl.u32 %v78979_v24, 19 (stack46)
        %v78145_v52 = vsel /*vm=*/%vm78120_vm6, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v78153_v50 = vsel /*vm=*/%vm78120_vm6, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v78569_v10 = vadd.f32 1.0, %v144986_v41 (stack57)
        %v79372_v29 = vadd.s32 %v79369_v42, %v79364_v29 (stack40)
        %v78184_v44 = vadd.f32 %v78180_v9, %v78153_v50 (stack53)
        %v78987_v27 = vor.u32 %v78986_v40, %v78985_v55 (stack47)
        %v79374_v61 = vshll.u32 %v79369_v42, 26 (stack45)
        %v79375_v6 = vshrl.u32 %v79369_v42, 6 (stack46)
        %v78149_v21 = vsel /*vm=*/%vm78120_vm6, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %121101 = vlog2.f32 %v78569_v10 (stack58)
        %v78572_v60 = vmul.f32 -0.5, %v144986_v41 (stack59)
        %v79785_v7 = vor.u32 %v79784_v12, %v79783_v26 (stack47)
        %v78188_v32 = vmul.f32 %v78184_v44, %v144983_v46 (stack54)
        %v78988_v24 = vxor.u32 %v78987_v27, %v78983_v30 (stack48)
        %v79376_v42 = vor.u32 %v79375_v6, %v79374_v61 (stack47)
        %v80203_v31 = vxor.u32 %v80202_v31, %v144954_v54 (stack48)
        %v78575_v26 = vand.u32 2147483647, %v144986_v41 (stack60)
        %v79786_v12 = vxor.u32 %v79785_v7, %v79781_v20 (stack48)
        %v145005_v9 = vadd.s32 %v144945_v22, %v122657_v58 (stack40)
        %vm80617_vm10 = vcmp.lt.u32.totalorder %v144945_v22, %v157083_v59 (stack43)
        %v78192_v55 = vadd.f32 %v78188_v32, %v78149_v21 (stack53)
        %v78991_v30 = vadd.s32 %v78988_v24, %v78983_v30 (stack40)
        %v78993_v40 = vshll.u32 %v78988_v24, 15 (stack45)
        %v78994_v50 = vshrl.u32 %v78988_v24, 17 (stack46)
        %v79377_v10 = vxor.u32 %v79376_v42, %v79372_v29 (stack48)
        %v79789_v20 = vadd.s32 %v79786_v12, %v79781_v20 (stack40)
        %v79791_v44 = vshll.u32 %v79786_v12, 16 (stack45)
        %v79792_v27 = vshrl.u32 %v79786_v12, 16 (stack46)
        %v78196_v61 = vmul.f32 %v78192_v55, %v144983_v46 (stack54)
        %v78573_v6 = vadd.f32 1.0, %v78572_v60 (stack61)
        %v78995_v21 = vor.u32 %v78994_v50, %v78993_v40 (stack47)
        %v80206_v54 = vadd.s32 %v80203_v31, %v144954_v54 (stack40)
        %v79380_v29 = vadd.s32 %v79377_v10, %v79372_v29 (stack40)
        %v79386_v60 = vshll.u32 %v79377_v10, 6 (stack45)
        %v79387_v7 = vshrl.u32 %v79377_v10, 26 (stack46)
        %v79793_v32 = vor.u32 %v79792_v27, %v79791_v44 (stack47)
        %v78200_v52 = vadd.f32 %v78196_v61, %v78145_v52 (stack53)
        %vm145011_vm11 = vcmp.lt.f32.partialorder %v78575_v26, 0.0004427343 (stack62)
        %v78996_v42 = vxor.u32 %v78995_v21, %v78991_v30 (stack48)
        %v80208_v26 = vshll.u32 %v80203_v31, 26 (stack45)
        %v80209_v31 = vshrl.u32 %v80203_v31, 6 (stack46)
        %v79388_v12 = vor.u32 %v79387_v7, %v79386_v60 (stack47)
        %v79794_v55 = vxor.u32 %v79793_v32, %v79789_v20 (stack48)
        %vm80612_vm12 = vcmp.lt.u32.totalorder %v145005_v9, %v144945_v22 (stack43)
        %v80626_v40 = vadd.s32 1, %v144949_v34 (stack40)
        %v78204_v50 = vmul.f32 %v78200_v52, %v144983_v46 (stack54)
        %v78999_v30 = vadd.s32 %v78996_v42, %v78991_v30 (stack40)
        %v79001_v10 = vshll.u32 %v78996_v42, 26 (stack45)
        %v79002_v44 = vshrl.u32 %v78996_v42, 6 (stack46)
        %v79389_v27 = vxor.u32 %v79388_v12, %v79380_v29 (stack48)
        %v79797_v20 = vadd.s32 %v79794_v55, %v79789_v20 (stack40)
        %v79803_v61 = vshll.u32 %v79794_v55, 24 (stack45)
        %v79804_v21 = vshrl.u32 %v79794_v55, 8 (stack46)
        %v78208_v56 = vadd.f32 %v78204_v50, %v144959_v56 (stack53)
        %v79003_v60 = vor.u32 %v79002_v44, %v79001_v10 (stack47)
        %v80210_v7 = vor.u32 %v80209_v31, %v80208_v26 (stack47)
        %v80630_v34 = vsel /*vm=*/%vm80617_vm10, /*on_true_vy=*/%v80626_v40, /*on_false_vx=*/%v144949_v34 (stack44)
        %v78574_v41 = vmul.f32 %v78573_v6, %v144986_v41 (stack63)
        %v79392_v6 = vadd.s32 %v79389_v27, %v121569_v1 (stack40)
        %v79805_v32 = vor.u32 %v79804_v21, %v79803_v61 (stack47)
        %v80634_v52 = vadd.s32 1, %v80630_v34 (stack40)
        %v121102_v42 = vpop.eup %121101 (stack64)
        %v78212_v26 = vmul.f32 %v78208_v56, %v144983_v46 (stack54)
        %v79004_v31 = vxor.u32 %v79003_v60, %v78999_v30 (stack48)
        %v79384_v29 = vadd.s32 %v79380_v29, %v121574_v2 (stack40)
        %v80211_v12 = vxor.u32 %v80210_v7, %v80206_v54 (stack48)
        %v78571_v55 = vmul.f32 0.6931472, %v121102_v42 (stack65)
        %v79396_v40 = vadd.s32 3, %v79392_v6 (stack40)
        %v79806_v50 = vxor.u32 %v79805_v32, %v79797_v20 (stack48)
        %v80638_v22 = vsel /*vm=*/%vm80612_vm12, /*on_true_vy=*/%v80634_v52, /*on_false_vx=*/%v80630_v34 (stack44)
        %v78216_v8 = vadd.f32 %v78212_v26, %v144938_v8 (stack53)
        %v79007_v30 = vadd.s32 %v79004_v31, %v78999_v30 (stack40)
        %v79013_v10 = vshll.u32 %v79004_v31, 6 (stack45)
        %v79014_v44 = vshrl.u32 %v79004_v31, 26 (stack46)
        %v78577_v24 = vsel /*vm=*/%vm145011_vm11, /*on_true_vy=*/%v78574_v41, /*on_false_vx=*/%v78571_v55 (stack66)
        %v79400_v27 = vadd.s32 %v79396_v40, %v79384_v29 (stack40)
        %v79402_v61 = vshll.u32 %v79396_v40, 17 (stack45)
        %v79403_v21 = vshrl.u32 %v79396_v40, 15 (stack46)
        %v78220_v56 = vmul.f32 %v78216_v8, %v144983_v46 (stack54)
        %v145035_v60 = vxor.u32 2147483648, %v78577_v24 (stack56)
        %v79015_v7 = vor.u32 %v79014_v44, %v79013_v10 (stack47)
        %v78093_v34 = vand.u32 2147483647, %v144847_v45 (stack77)
        %v78133_v41 = vsel /*vm=*/%vm78120_vm6, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v145041_v54 = vadd.s32 %v80211_v12, %v80206_v54 (stack40)
        %v80647_v9 = vadd.s32 %v145005_v9, %v121569_v1 (stack40)
        %v78101_v6 = vmul.f32 inf, %v144847_v45 (stack54)
        %v78125_v32 = vsel /*vm=*/%vm78120_vm6, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v78224_v52 = vadd.f32 %v78220_v56, %v78133_v41 (stack53)
        %121103 = vrsqrt.f32 %v145035_v60 (stack67)
        %vm78581_vm13 = vcmp.lt.f32.partialorder %v145035_v60, 5.0 (stack68)
        %v79016_v42 = vxor.u32 %v79015_v7, %v79007_v30 (stack48)
        %v79404_v26 = vor.u32 %v79403_v21, %v79402_v61 (stack47)
        %v79809_v31 = vadd.s32 %v79806_v50, %v121574_v2 (stack40)
        %v78129_v23 = vsel /*vm=*/%vm78120_vm6, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v78228_v29 = vmul.f32 %v78224_v52, %v144983_v46 (stack54)
        %v78554_v55 = vand.u32 2147483647, %v144971_v53 (stack77)
        %v79801_v20 = vadd.s32 %v79797_v20, %v121564_v0 (stack40)
        %vm145058_vm14 = vcmp.eq.f32.partialorder %v78093_v34, 1.0 (stack68)
        %v79011_v50 = vadd.s32 %v79007_v30, %v121564_v0 (stack40)
        %v79019_v8 = vadd.s32 %v79016_v42, %v121574_v2 (stack40)
        %v80220_v30 = vshll.u32 %v80211_v12, 6 (stack45)
        %v80653_v10 = vshll.u32 %v80647_v9, 13 (stack45)
        %v78232_v44 = vadd.f32 %v78228_v29, %v78129_v23 (stack53)
        %v145067_v24 = vsel /*vm=*/%vm78581_vm13, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v145072_v61 = vsel /*vm=*/%vm78581_vm13, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v145075_v21 = vadd.f32 -2.5, %v145035_v60 (stack53)
        %v145080_v56 = vsel /*vm=*/%vm78581_vm13, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v79023_v7 = vadd.s32 5, %v79019_v8 (stack40)
        %v79405_v34 = vxor.u32 %v79404_v26, %v79400_v27 (stack48)
        %v79813_v41 = vadd.s32 2, %v79809_v31 (stack40)
        %v78236_v46 = vmul.f32 %v78232_v44, %v144983_v46 (stack54)
        %v80221_v12 = vshrl.u32 %v80211_v12, 26 (stack46)
        %v80643_v22 = vadd.s32 %v80638_v22, %v121574_v2 (stack40)
        %v80654_v52 = vshrl.u32 %v80647_v9, 19 (stack46)
        %vm78626_vm15 = vcmp.eq.f32.partialorder %v145035_v60, inf (stack70)
        %v79025_v42 = vxor.u32 %v79023_v7, %v79011_v50 (stack48)
        %v79408_v27 = vadd.s32 %v79405_v34, %v79400_v27 (stack40)
        %v79410_v26 = vshll.u32 %v79405_v34, 29 (stack45)
        %v79411_v31 = vshrl.u32 %v79405_v34, 3 (stack46)
        %v78240_v32 = vadd.f32 %v78236_v46, %v78125_v32 (stack53)
        %vm78628_vm0 = vcmp.eq.f32.partialorder %v145035_v60, 0.0 (stack71)
        %v79817_v23 = vadd.s32 %v79813_v41, %v79801_v20 (stack40)
        %v79819_v29 = vshll.u32 %v79813_v41, 13 (stack45)
        %v79820_v20 = vshrl.u32 %v79813_v41, 19 (stack46)
        %v79026_v50 = vand.u32.u8 255, %v79025_v42 (stack49)
        %v79412_v8 = vor.u32 %v79411_v31, %v79410_v26 (stack47)
        %v80222_v30 = vor.u32 %v80221_v12, %v80220_v30 (stack47)
        %v80651_v9 = vadd.s32 %v80647_v9, %v80643_v22 (stack40)
        %v78244_v45 = vmul.f32 %v78240_v32, %v144847_v45 (stack54)
        %v79821_v44 = vor.u32 %v79820_v20, %v79819_v29 (stack47)
        %v80655_v10 = vor.u32 %v80654_v52, %v80653_v10 (stack47)
        %v145089_v7 = vadd.s32 %v157562_v25, %v157089_v17 (stack40)
        %v79027_v34 = vand.u32 65535, %v79026_v50 (stack50)
        %v79413_v41 = vxor.u32 %v79412_v8, %v79408_v27 (stack48)
        %v80223_v46 = vxor.u32 %v80222_v30, %v145041_v54 (stack48)
        %v145094_v12 = vadd.s32 %v157563_v43, %v157090_v62 (stack40)
        %v78248_v6 = vsel /*vm=*/%vm145058_vm14, /*on_true_vy=*/%v78101_v6, /*on_false_vx=*/%v78244_v45 (stack44)
        %v78629_v40 = vand.u32 2147483648, %v145035_v60 (stack72)
        %v79822_v22 = vxor.u32 %v79821_v44, %v79817_v23 (stack48)
        %v80656_v52 = vxor.u32 %v80655_v10, %v80651_v9 (stack48)
        %v121104_v42 = vpop.eup %121103 (stack73)
        %v78252_v26 = vmul.f32 1.4140625, %v78248_v6 (stack54)
        %v79028_v31 = vshrl.u32 %v79027_v34, 1 (stack51)
        %v79416_v27 = vadd.s32 %v79413_v41, %v79408_v27 (stack40)
        %v79418_v32 = vshll.u32 %v79413_v41, 16 (stack45)
        %v78625_v29 = vmul.f32 %v121104_v42, %v145035_v60 (stack74)
        %v79419_v20 = vshrl.u32 %v79413_v41, 16 (stack46)
        %v79825_v23 = vadd.s32 %v79822_v22, %v79817_v23 (stack40)
        %v79827_v50 = vshll.u32 %v79822_v22, 15 (stack45)
        %v78255_v8 = vpack.c.bf16 %v157387_v11, %v78252_v26 (stack81)
        %v79029_v30 = vor.u32 16256, %v79028_v31 (stack47)
        %v79828_v45 = vshrl.u32 %v79822_v22, 17 (stack46)
        %v80226_v44 = vadd.s32 %v80223_v46, %v121564_v0 (stack40)
        %v78627_v10 = vsel /*vm=*/%vm78626_vm15, /*on_true_vy=*/%v145035_v60, /*on_false_vx=*/%v78625_v29 (stack75)
        %v79420_v34 = vor.u32 %v79419_v20, %v79418_v32 (stack47)
        %v80218_v54 = vadd.s32 %v145041_v54, %v121569_v1 (stack40)
        %v145107_v9 = vadd.s32 %v80656_v52, %v80651_v9 (stack40)
        %120161 = vst [vmem:[%s123356_s30 + $0x350] sm:$0xf] /*vst_source=*/%v78255_v8 (stack83)
        %v78630_v41 = vsel /*vm=*/%vm78628_vm0, /*on_true_vy=*/%v78629_v40, /*on_false_vx=*/%v78627_v10 (stack76)
        %v79030_v46 = vand.u32.u16 65535, %v79029_v30 (stack52)
        %v79829_v6 = vor.u32 %v79828_v45, %v79827_v50 (stack47)
        %v80230_v40 = vadd.s32 1, %v80226_v44 (stack40)
        %v78633_v22 = vadd.f32 -3.0, %v78630_v41 (stack53)
        %v79421_v42 = vxor.u32 %v79420_v34, %v79416_v27 (stack48)
        %v80661_v26 = vshll.u32 %v80656_v52, 15 (stack45)
        %v80662_v52 = vshrl.u32 %v80656_v52, 17 (stack46)
        %v120168_v31 = vadd.low.f32.bf16 -1.0, %v79030_v46 (stack53)
        %v79830_v32 = vxor.u32 %v79829_v6, %v79825_v23 (stack48)
        %v80234_v29 = vadd.s32 %v80230_v40, %v80218_v54 (stack40)
        %v80236_v20 = vshll.u32 %v80230_v40, 17 (stack45)
        %v145115_v21 = vsel /*vm=*/%vm78581_vm13, /*on_true_vy=*/%v145075_v21, /*on_false_vx=*/%v78633_v22 (stack44)
        %v79424_v27 = vadd.s32 %v79421_v42, %v79416_v27 (stack40)
        %v79430_v50 = vshll.u32 %v79421_v42, 24 (stack45)
        %v79431_v8 = vshrl.u32 %v79421_v42, 8 (stack46)
        %v78641_v56 = vmul.f32 %v145115_v21, %v145080_v56 (stack54)
        %v79039_v30 = vmul.f32 2.0, %v120168_v31 (stack54)
        %v79833_v23 = vadd.s32 %v79830_v32, %v79825_v23 (stack40)
        %v79835_v45 = vshll.u32 %v79830_v32, 26 (stack45)
        %v78614_v44 = vsel /*vm=*/%vm78581_vm13, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v79432_v10 = vor.u32 %v79431_v8, %v79430_v50 (stack47)
        %v79836_v34 = vshrl.u32 %v79830_v32, 6 (stack46)
        %v80237_v54 = vshrl.u32 %v80230_v40, 15 (stack46)
        %v78645_v41 = vadd.f32 %v78641_v56, %v78614_v44 (stack53)
        %v79043_v46 = vadd.f32 -0.99609375, %v79039_v30 (stack53)
        %v80663_v6 = vor.u32 %v80662_v52, %v80661_v26 (stack47)
        %vm81078_vm1 = vcmp.lt.u32.totalorder %v145089_v7, %v157089_v17 (stack43)
        %v79433_v40 = vxor.u32 %v79432_v10, %v79424_v27 (stack48)
        %v79837_v22 = vor.u32 %v79836_v34, %v79835_v45 (stack47)
        %v80238_v42 = vor.u32 %v80237_v54, %v80236_v20 (stack47)
        %v81087_v26 = vadd.s32 1, %v145094_v12 (stack40)
        %v78610_v52 = vsel /*vm=*/%vm78581_vm13, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v78649_v31 = vmul.f32 %v78645_v41, %v145115_v21 (stack54)
        %v145129_v32 = vmax.f32 %v79043_v46, -0.99609375 (stack55)
        %v80664_v20 = vxor.u32 %v80663_v6, %v145107_v9 (stack48)
        %v79436_v50 = vadd.s32 %v79433_v40, %v121564_v0 (stack40)
        %v79838_v8 = vxor.u32 %v79837_v22, %v79833_v23 (stack48)
        %v80239_v56 = vxor.u32 %v80238_v42, %v80234_v29 (stack48)
        %v81091_v12 = vsel /*vm=*/%vm81078_vm1, /*on_true_vy=*/%v81087_v26, /*on_false_vx=*/%v145094_v12 (stack44)
        %v145137_v30 = vsel /*vm=*/%vm78581_vm13, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v78653_v45 = vadd.f32 %v78649_v31, %v78610_v52 (stack53)
        %v79059_v44 = vxor.u32 2147483648, %v145129_v32 (stack56)
        %v79428_v27 = vadd.s32 %v79424_v27, %v121569_v1 (stack40)
        %v79440_v10 = vadd.s32 4, %v79436_v50 (stack40)
        %v79841_v23 = vadd.s32 %v79838_v8, %v79833_v23 (stack40)
        %v79847_v34 = vshll.u32 %v79838_v8, 6 (stack45)
        %v79848_v54 = vshrl.u32 %v79838_v8, 26 (stack46)
        %v78657_v41 = vmul.f32 %v78653_v45, %v145115_v21 (stack54)
        %v79062_v46 = vmul.f32 %v79059_v44, %v145129_v32 (stack54)
        %v80242_v29 = vadd.s32 %v80239_v56, %v80234_v29 (stack40)
        %v81069_v6 = vadd.s32 %v145089_v7, %v122657_v58 (stack40)
        %v78606_v40 = vsel /*vm=*/%vm78581_vm13, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v79444_v22 = vadd.s32 %v79440_v10, %v79428_v27 (stack40)
        %v79446_v42 = vshll.u32 %v79440_v10, 13 (stack45)
        %v79447_v26 = vshrl.u32 %v79440_v10, 19 (stack46)
        %v78598_v52 = vsel /*vm=*/%vm78581_vm13, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v78602_v60 = vsel /*vm=*/%vm78581_vm13, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v78661_v31 = vadd.f32 %v78657_v41, %v78606_v40 (stack53)
        %v79064_v50 = vadd.f32 1.0, %v79062_v46 (stack57)
        %v79448_v8 = vor.u32 %v79447_v26, %v79446_v42 (stack47)
        %v79849_v45 = vor.u32 %v79848_v54, %v79847_v34 (stack47)
        %v80244_v44 = vshll.u32 %v80239_v56, 29 (stack45)
        %v80245_v56 = vshrl.u32 %v80239_v56, 3 (stack46)
        %v78665_v27 = vmul.f32 %v78661_v31, %v145115_v21 (stack54)
        %121105 = vlog2.f32 %v79064_v50 (stack58)
        %v79067_v10 = vmul.f32 -0.5, %v79062_v46 (stack59)
        %vm81073_vm2 = vcmp.lt.u32.totalorder %v81069_v6, %v145089_v7 (stack43)
        %v79449_v34 = vxor.u32 %v79448_v8, %v79444_v22 (stack48)
        %v79850_v54 = vxor.u32 %v79849_v45, %v79841_v23 (stack48)
        %v80246_v41 = vor.u32 %v80245_v56, %v80244_v44 (stack47)
        %v80667_v9 = vadd.s32 %v80664_v20, %v145107_v9 (stack40)
        %v78669_v40 = vadd.f32 %v78665_v27, %v78602_v60 (stack53)
        %v79845_v23 = vadd.s32 %v79841_v23, %v121574_v2 (stack40)
        %v80669_v42 = vshll.u32 %v80664_v20, 26 (stack45)
        %v80670_v20 = vshrl.u32 %v80664_v20, 6 (stack46)
        %v79452_v22 = vadd.s32 %v79449_v34, %v79444_v22 (stack40)
        %v79454_v26 = vshll.u32 %v79449_v34, 15 (stack45)
        %v79455_v60 = vshrl.u32 %v79449_v34, 17 (stack46)
        %v79853_v31 = vadd.s32 %v79850_v54, %v121569_v1 (stack40)
        %v78673_v50 = vmul.f32 %v78669_v40, %v145115_v21 (stack54)
        %v80247_v8 = vxor.u32 %v80246_v41, %v80242_v29 (stack48)
        %v80671_v45 = vor.u32 %v80670_v20, %v80669_v42 (stack47)
        %v81095_v44 = vadd.s32 1, %v81091_v12 (stack40)
        %v79068_v56 = vadd.f32 1.0, %v79067_v10 (stack61)
        %v79070_v27 = vand.u32 2147483647, %v79062_v46 (stack60)
        %v79456_v10 = vor.u32 %v79455_v60, %v79454_v26 (stack47)
        %v79857_v34 = vadd.s32 3, %v79853_v31 (stack40)
        %v78677_v52 = vadd.f32 %v78673_v50, %v78598_v52 (stack53)
        %v80250_v29 = vadd.s32 %v80247_v8, %v80242_v29 (stack40)
        %v80252_v54 = vshll.u32 %v80247_v8, 16 (stack45)
        %v80253_v41 = vshrl.u32 %v80247_v8, 16 (stack46)
        %v79457_v40 = vxor.u32 %v79456_v10, %v79452_v22 (stack48)
        %v79861_v23 = vadd.s32 %v79857_v34, %v79845_v23 (stack40)
        %v79863_v42 = vshll.u32 %v79857_v34, 17 (stack45)
        %v79864_v20 = vshrl.u32 %v79857_v34, 15 (stack46)
        %v78681_v26 = vmul.f32 %v78677_v52, %v145115_v21 (stack54)
        %v80254_v60 = vor.u32 %v80253_v41, %v80252_v54 (stack47)
        %v80672_v31 = vxor.u32 %v80671_v45, %v80667_v9 (stack48)
        %v81099_v7 = vsel /*vm=*/%vm81073_vm2, /*on_true_vy=*/%v81095_v44, /*on_false_vx=*/%v81091_v12 (stack44)
        %v79460_v12 = vadd.s32 %v79457_v40, %v79452_v22 (stack40)
        %v79462_v22 = vshll.u32 %v79457_v40, 26 (stack45)
        %v79463_v50 = vshrl.u32 %v79457_v40, 6 (stack46)
        %v79865_v8 = vor.u32 %v79864_v20, %v79863_v42 (stack47)
        %v78685_v30 = vadd.f32 %v78681_v26, %v145137_v30 (stack53)
        %v80255_v45 = vxor.u32 %v80254_v60, %v80250_v29 (stack48)
        %v145164_v9 = vadd.s32 %v80672_v31, %v80667_v9 (stack40)
        %v81108_v6 = vadd.s32 %v81069_v6, %v121569_v1 (stack40)
        %v79069_v46 = vmul.f32 %v79068_v56, %v79062_v46 (stack63)
        %vm145167_vm3 = vcmp.lt.f32.partialorder %v79070_v27, 0.0004427343 (stack62)
        %v79464_v56 = vor.u32 %v79463_v50, %v79462_v22 (stack47)
        %v79866_v27 = vxor.u32 %v79865_v8, %v79861_v23 (stack48)
        %v78689_v10 = vmul.f32 %v78685_v30, %v145115_v21 (stack54)
        %v80258_v34 = vadd.s32 %v80255_v45, %v80250_v29 (stack40)
        %v80264_v52 = vshll.u32 %v80255_v45, 24 (stack45)
        %v80265_v29 = vshrl.u32 %v80255_v45, 8 (stack46)
        %v121106_v54 = vpop.eup %121105 (stack64)
        %v79465_v41 = vxor.u32 %v79464_v56, %v79460_v12 (stack48)
        %v79869_v40 = vadd.s32 %v79866_v27, %v79861_v23 (stack40)
        %v79871_v23 = vshll.u32 %v79866_v27, 29 (stack45)
        %v79872_v42 = vshrl.u32 %v79866_v27, 3 (stack46)
        %v78693_v61 = vadd.f32 %v78689_v10, %v145072_v61 (stack53)
        %v79066_v20 = vmul.f32 0.6931472, %v121106_v54 (stack65)
        %v80266_v26 = vor.u32 %v80265_v29, %v80264_v52 (stack47)
        %v81104_v60 = vadd.s32 %v81099_v7, %v121574_v2 (stack40)
        %v79468_v7 = vadd.s32 %v79465_v41, %v79460_v12 (stack40)
        %v79474_v12 = vshll.u32 %v79465_v41, 6 (stack45)
        %v79475_v22 = vshrl.u32 %v79465_v41, 26 (stack46)
        %v79873_v50 = vor.u32 %v79872_v42, %v79871_v23 (stack47)
        %v78697_v21 = vmul.f32 %v78693_v61, %v145115_v21 (stack54)
        %v79072_v8 = vsel /*vm=*/%vm145167_vm3, /*on_true_vy=*/%v79069_v46, /*on_false_vx=*/%v79066_v20 (stack66)
        %v80267_v30 = vxor.u32 %v80266_v26, %v80258_v34 (stack48)
        %v80681_v45 = vshll.u32 %v80672_v31, 6 (stack45)
        %v145177_v46 = vxor.u32 2147483648, %v79072_v8 (stack56)
        %v79476_v44 = vor.u32 %v79475_v22, %v79474_v12 (stack47)
        %v79874_v56 = vxor.u32 %v79873_v50, %v79869_v40 (stack48)
        %v80682_v31 = vshrl.u32 %v80672_v31, 26 (stack46)
        %v78701_v24 = vadd.f32 %v78697_v21, %v145067_v24 (stack53)
        %v81112_v27 = vadd.s32 %v81108_v6, %v81104_v60 (stack40)
        %vm145182_vm4 = vcmp.eq.f32.partialorder %v78554_v55, 1.0 (stack68)
        %v78562_v10 = vmul.f32 inf, %v144971_v53 (stack54)
        %v79049_v52 = vand.u32 2147483647, %v145129_v32 (stack77)
        %121107 = vrsqrt.f32 %v145177_v46 (stack67)
        %v78705_v53 = vmul.f32 %v78701_v24, %v144971_v53 (stack54)
        %vm79076_vm5 = vcmp.lt.f32.partialorder %v145177_v46, 5.0 (stack68)
        %v80270_v29 = vadd.s32 %v80267_v30, %v121574_v2 (stack40)
        %v81114_v54 = vshll.u32 %v81108_v6, 13 (stack45)
        %v79477_v41 = vxor.u32 %v79476_v44, %v79468_v7 (stack48)
        %v80262_v34 = vadd.s32 %v80258_v34, %v121564_v0 (stack40)
        %v80683_v23 = vor.u32 %v80682_v31, %v80681_v45 (stack47)
        %v81115_v6 = vshrl.u32 %v81108_v6, 19 (stack46)
        %v78709_v42 = vsel /*vm=*/%vm145182_vm4, /*on_true_vy=*/%v78562_v10, /*on_false_vx=*/%v78705_v53 (stack44)
        %v145196_v61 = vadd.f32 -2.5, %v145177_v46 (stack53)
        %v79472_v20 = vadd.s32 %v79468_v7, %v121564_v0 (stack40)
        %v80679_v26 = vadd.s32 %v145164_v9, %v121569_v1 (stack40)
        %v78713_v60 = vmul.f32 1.4140625, %v78709_v42 (stack54)
        %v145204_v7 = vsel /*vm=*/%vm79076_vm5, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v145209_v12 = vsel /*vm=*/%vm79076_vm5, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v79480_v22 = vadd.s32 %v79477_v41, %v121574_v2 (stack40)
        %v79877_v40 = vadd.s32 %v79874_v56, %v79869_v40 (stack40)
        %v79879_v50 = vshll.u32 %v79874_v56, 16 (stack45)
        %v79880_v21 = vshrl.u32 %v79874_v56, 16 (stack46)
        %v80274_v8 = vadd.s32 2, %v80270_v29 (stack40)
        %v78716_v30 = vpack.c.bf16 %v157387_v11, %v78713_v60 (stack81)
        %v79484_v45 = vadd.s32 5, %v79480_v22 (stack40)
        %v80684_v9 = vxor.u32 %v80683_v23, %v145164_v9 (stack48)
        %v81116_v44 = vor.u32 %v81115_v6, %v81114_v54 (stack47)
        %vm79121_vm6 = vcmp.eq.f32.partialorder %v145177_v46, inf (stack70)
        %v79881_v56 = vor.u32 %v79880_v21, %v79879_v50 (stack47)
        %v80278_v31 = vadd.s32 %v80274_v8, %v80262_v34 (stack40)
        %v80280_v24 = vshll.u32 %v80274_v8, 13 (stack45)
        %v80281_v55 = vshrl.u32 %v80274_v8, 19 (stack46)
        %120163 = vst [vmem:[%s123356_s30 + $0x3d0] sm:$0xf] /*vst_source=*/%v78716_v30 (stack83)
        %v79486_v10 = vxor.u32 %v79484_v45, %v79472_v20 (stack48)
        %v80687_v53 = vadd.s32 %v80684_v9, %v121564_v0 (stack40)
        %v81117_v29 = vxor.u32 %v81116_v44, %v81112_v27 (stack48)
        %v145219_v54 = vadd.s32 %v157562_v25, %v157091_v37 (stack40)
        %v79882_v41 = vxor.u32 %v79881_v56, %v79877_v40 (stack48)
        %v80282_v34 = vor.u32 %v80281_v55, %v80280_v24 (stack47)
        %v145223_v23 = vadd.s32 %v157563_v43, %v157094_v36 (stack40)
        %v145227_v25 = vadd.s32 %v157562_v25, %v157095_v13 (stack40)
        %vm79123_vm7 = vcmp.eq.f32.partialorder %v145177_v46, 0.0 (stack71)
        %v79487_v6 = vand.u32.u8 255, %v79486_v10 (stack49)
        %v80691_v42 = vadd.s32 1, %v80687_v53 (stack40)
        %v81120_v27 = vadd.s32 %v81117_v29, %v81112_v27 (stack40)
        %v79885_v20 = vadd.s32 %v79882_v41, %v79877_v40 (stack40)
        %v79891_v60 = vshll.u32 %v79882_v41, 24 (stack45)
        %v79892_v22 = vshrl.u32 %v79882_v41, 8 (stack46)
        %v80283_v40 = vxor.u32 %v80282_v34, %v80278_v31 (stack48)
        %v79488_v50 = vand.u32 65535, %v79487_v6 (stack50)
        %v80695_v26 = vadd.s32 %v80691_v42, %v80679_v26 (stack40)
        %v80697_v21 = vshll.u32 %v80691_v42, 17 (stack45)
        %v80698_v8 = vshrl.u32 %v80691_v42, 15 (stack46)
        %v121108_v30 = vpop.eup %121107 (stack73)
        %v79893_v45 = vor.u32 %v79892_v22, %v79891_v60 (stack47)
        %v80286_v9 = vadd.s32 %v80283_v40, %v80278_v31 (stack40)
        %v80288_v44 = vshll.u32 %v80283_v40, 15 (stack45)
        %v81122_v56 = vshll.u32 %v81117_v29, 15 (stack45)
        %v79120_v31 = vmul.f32 %v121108_v30, %v145177_v46 (stack74)
        %v79489_v24 = vshrl.u32 %v79488_v50, 1 (stack51)
        %v80289_v55 = vshrl.u32 %v80283_v40, 17 (stack46)
        %v80699_v10 = vor.u32 %v80698_v8, %v80697_v21 (stack47)
        %v79124_v53 = vand.u32 2147483648, %v145177_v46 (stack72)
        %v79894_v41 = vxor.u32 %v79893_v45, %v79885_v20 (stack48)
        %v81123_v29 = vshrl.u32 %v81117_v29, 17 (stack46)
        %vm81539_vm8 = vcmp.lt.u32.totalorder %v145219_v54, %v157091_v37 (stack43)
        %v79122_v34 = vsel /*vm=*/%vm79121_vm6, /*on_true_vy=*/%v145177_v46, /*on_false_vx=*/%v79120_v31 (stack75)
        %v79490_v6 = vor.u32 16256, %v79489_v24 (stack47)
        %v80290_v42 = vor.u32 %v80289_v55, %v80288_v44 (stack47)
        %v80700_v60 = vxor.u32 %v80699_v10, %v80695_v26 (stack48)
        %v79125_v22 = vsel /*vm=*/%vm79123_vm7, /*on_true_vy=*/%v79124_v53, /*on_false_vx=*/%v79122_v34 (stack76)
        %v79889_v20 = vadd.s32 %v79885_v20, %v121569_v1 (stack40)
        %v79897_v40 = vadd.s32 %v79894_v41, %v121564_v0 (stack40)
        %v81124_v50 = vor.u32 %v81123_v29, %v81122_v56 (stack47)
        %v79128_v21 = vadd.f32 -3.0, %v79125_v22 (stack53)
        %v79491_v8 = vand.u32.u16 65535, %v79490_v6 (stack52)
        %v80291_v30 = vxor.u32 %v80290_v42, %v80286_v9 (stack48)
        %v80703_v26 = vadd.s32 %v80700_v60, %v80695_v26 (stack40)
        %v79901_v45 = vadd.s32 4, %v79897_v40 (stack40)
        %v80705_v44 = vshll.u32 %v80700_v60, 29 (stack45)
        %v80706_v56 = vshrl.u32 %v80700_v60, 3 (stack46)
        %v81125_v31 = vxor.u32 %v81124_v50, %v81120_v27 (stack48)
        %v145244_v61 = vsel /*vm=*/%vm79076_vm5, /*on_true_vy=*/%v145196_v61, /*on_false_vx=*/%v79128_v21 (stack44)
        %v120170_v24 = vadd.low.f32.bf16 -1.0, %v79491_v8 (stack53)
        %v80294_v9 = vadd.s32 %v80291_v30, %v80286_v9 (stack40)
        %v80296_v55 = vshll.u32 %v80291_v30, 26 (stack45)
        %v79136_v12 = vmul.f32 %v145244_v61, %v145209_v12 (stack54)
        %v79905_v10 = vadd.s32 %v79901_v45, %v79889_v20 (stack40)
        %v79907_v53 = vshll.u32 %v79901_v45, 13 (stack45)
        %v79908_v41 = vshrl.u32 %v79901_v45, 19 (stack46)
        %v79500_v29 = vmul.f32 2.0, %v120170_v24 (stack54)
        %v80297_v34 = vshrl.u32 %v80291_v30, 6 (stack46)
        %v80707_v6 = vor.u32 %v80706_v56, %v80705_v44 (stack47)
        %v81128_v27 = vadd.s32 %v81125_v31, %v81120_v27 (stack40)
        %v79140_v7 = vadd.f32 %v79136_v12, %v145204_v7 (stack53)
        %v79909_v42 = vor.u32 %v79908_v41, %v79907_v53 (stack47)
        %v81130_v60 = vshll.u32 %v81125_v31, 26 (stack45)
        %v81131_v22 = vshrl.u32 %v81125_v31, 6 (stack46)
        %v145252_v20 = vsel /*vm=*/%vm79076_vm5, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v79504_v40 = vadd.f32 -0.99609375, %v79500_v29 (stack53)
        %v80298_v50 = vor.u32 %v80297_v34, %v80296_v55 (stack47)
        %v80708_v21 = vxor.u32 %v80707_v6, %v80703_v26 (stack48)
        %v145257_v8 = vsel /*vm=*/%vm79076_vm5, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v79105_v30 = vsel /*vm=*/%vm79076_vm5, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v79144_v45 = vmul.f32 %v79140_v7, %v145244_v61 (stack54)
        %v79910_v44 = vxor.u32 %v79909_v42, %v79905_v10 (stack48)
        %v145263_v56 = vmax.f32 %v79504_v40, -0.99609375 (stack55)
        %v80299_v31 = vxor.u32 %v80298_v50, %v80294_v9 (stack48)
        %v80711_v26 = vadd.s32 %v80708_v21, %v80703_v26 (stack40)
        %v81132_v24 = vor.u32 %v81131_v22, %v81130_v60 (stack47)
        %v79148_v55 = vadd.f32 %v79144_v45, %v79105_v30 (stack53)
        %v79913_v12 = vadd.s32 %v79910_v44, %v79905_v10 (stack40)
        %v79915_v10 = vshll.u32 %v79910_v44, 15 (stack45)
        %v79916_v53 = vshrl.u32 %v79910_v44, 17 (stack46)
        %v79089_v41 = vsel /*vm=*/%vm79076_vm5, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v79520_v29 = vxor.u32 2147483648, %v145263_v56 (stack56)
        %v80302_v9 = vadd.s32 %v80299_v31, %v80294_v9 (stack40)
        %v80713_v34 = vshll.u32 %v80708_v21, 16 (stack45)
        %v79152_v6 = vmul.f32 %v79148_v55, %v145244_v61 (stack54)
        %v79917_v7 = vor.u32 %v79916_v53, %v79915_v10 (stack47)
        %v80308_v42 = vshll.u32 %v80299_v31, 6 (stack45)
        %v80309_v60 = vshrl.u32 %v80299_v31, 26 (stack46)
        %v79101_v22 = vsel /*vm=*/%vm79076_vm5, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v145274_v40 = vmul.f32 %v79520_v29, %v145263_v56 (stack54)
        %v80714_v50 = vshrl.u32 %v80708_v21, 16 (stack46)
        %v145278_v21 = vadd.s32 %v145219_v54, %v122657_v58 (stack40)
        %v79156_v30 = vadd.f32 %v79152_v6, %v79101_v22 (stack53)
        %v79918_v45 = vxor.u32 %v79917_v7, %v79913_v12 (stack48)
        %v80310_v44 = vor.u32 %v80309_v60, %v80308_v42 (stack47)
        %v81133_v31 = vxor.u32 %v81132_v24, %v81128_v27 (stack48)
        %v79093_v24 = vsel /*vm=*/%vm79076_vm5, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v79097_v46 = vsel /*vm=*/%vm79076_vm5, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v79525_v55 = vadd.f32 1.0, %v145274_v40 (stack57)
        %v80715_v10 = vor.u32 %v80714_v50, %v80713_v34 (stack47)
        %v79160_v53 = vmul.f32 %v79156_v30, %v145244_v61 (stack54)
        %v79921_v12 = vadd.s32 %v79918_v45, %v79913_v12 (stack40)
        %v79923_v29 = vshll.u32 %v79918_v45, 26 (stack45)
        %v79924_v34 = vshrl.u32 %v79918_v45, 6 (stack46)
        %121109 = vlog2.f32 %v79525_v55 (stack58)
        %v80311_v6 = vxor.u32 %v80310_v44, %v80302_v9 (stack48)
        %vm81534_vm9 = vcmp.lt.u32.totalorder %v145278_v21, %v145219_v54 (stack43)
        %v81548_v7 = vadd.s32 1, %v145223_v23 (stack40)
        %v145293_v42 = vadd.s32 %v145278_v21, %v121569_v1 (stack40)
        %v79164_v60 = vadd.f32 %v79160_v53, %v79097_v46 (stack53)
        %v79925_v22 = vor.u32 %v79924_v34, %v79923_v29 (stack47)
        %v80716_v50 = vxor.u32 %v80715_v10, %v80711_v26 (stack48)
        %v81136_v27 = vadd.s32 %v81133_v31, %v81128_v27 (stack40)
        %v79528_v30 = vmul.f32 -0.5, %v145274_v40 (stack59)
        %v80314_v45 = vadd.s32 %v80311_v6, %v121569_v1 (stack40)
        %v81142_v44 = vshll.u32 %v81133_v31, 6 (stack45)
        %v81143_v31 = vshrl.u32 %v81133_v31, 26 (stack46)
        %v79168_v46 = vmul.f32 %v79164_v60, %v145244_v61 (stack54)
        %v79926_v55 = vxor.u32 %v79925_v22, %v79921_v12 (stack48)
        %v80719_v26 = vadd.s32 %v80716_v50, %v80711_v26 (stack40)
        %v80725_v10 = vshll.u32 %v80716_v50, 24 (stack45)
        %v80306_v9 = vadd.s32 %v80302_v9, %v121574_v2 (stack40)
        %v80318_v53 = vadd.s32 3, %v80314_v45 (stack40)
        %v80726_v29 = vshrl.u32 %v80716_v50, 8 (stack46)
        %v81144_v34 = vor.u32 %v81143_v31, %v81142_v44 (stack47)
        %v79172_v24 = vadd.f32 %v79168_v46, %v79093_v24 (stack53)
        %v79929_v12 = vadd.s32 %v79926_v55, %v79921_v12 (stack40)
        %v79935_v6 = vshll.u32 %v79926_v55, 6 (stack45)
        %v79936_v60 = vshrl.u32 %v79926_v55, 26 (stack46)
        %v79531_v22 = vand.u32 2147483647, %v145274_v40 (stack60)
        %v80322_v50 = vadd.s32 %v80318_v53, %v80306_v9 (stack40)
        %v80324_v45 = vshll.u32 %v80318_v53, 17 (stack45)
        %v80325_v44 = vshrl.u32 %v80318_v53, 15 (stack46)
        %v79176_v31 = vmul.f32 %v79172_v24, %v145244_v61 (stack54)
        %v79529_v30 = vadd.f32 1.0, %v79528_v30 (stack61)
        %v79937_v46 = vor.u32 %v79936_v60, %v79935_v6 (stack47)
        %v80727_v55 = vor.u32 %v80726_v29, %v80725_v10 (stack47)
        %v80326_v10 = vor.u32 %v80325_v44, %v80324_v45 (stack47)
        %v81140_v9 = vadd.s32 %v81136_v27, %v121569_v1 (stack40)
        %v81145_v27 = vxor.u32 %v81144_v34, %v81136_v27 (stack48)
        %v81552_v23 = vsel /*vm=*/%vm81539_vm8, /*on_true_vy=*/%v81548_v7, /*on_false_vx=*/%v145223_v23 (stack44)
        %v79180_v41 = vadd.f32 %v79176_v31, %v79089_v41 (stack53)
        %v79938_v7 = vxor.u32 %v79937_v46, %v79929_v12 (stack48)
        %v80728_v53 = vxor.u32 %v80727_v55, %v80719_v26 (stack48)
        %v81556_v29 = vadd.s32 1, %v81552_v23 (stack40)
        %v79933_v34 = vadd.s32 %v79929_v12, %v121564_v0 (stack40)
        %v80327_v24 = vxor.u32 %v80326_v10, %v80322_v50 (stack48)
        %v80723_v26 = vadd.s32 %v80719_v26, %v121564_v0 (stack40)
        %v81148_v12 = vadd.s32 %v81145_v27, %v121564_v0 (stack40)
        %v79184_v6 = vmul.f32 %v79180_v41, %v145244_v61 (stack54)
        %v79941_v60 = vadd.s32 %v79938_v7, %v121574_v2 (stack40)
        %v80731_v45 = vadd.s32 %v80728_v53, %v121574_v2 (stack40)
        %v81560_v54 = vsel /*vm=*/%vm81534_vm9, /*on_true_vy=*/%v81556_v29, /*on_false_vx=*/%v81552_v23 (stack44)
        %v80330_v21 = vadd.s32 %v80327_v24, %v80322_v50 (stack40)
        %v80332_v50 = vshll.u32 %v80327_v24, 29 (stack45)
        %v80333_v44 = vshrl.u32 %v80327_v24, 3 (stack46)
        %v81152_v31 = vadd.s32 1, %v81148_v12 (stack40)
        %v121110_v46 = vpop.eup %121109 (stack64)
        %v79188_v8 = vadd.f32 %v79184_v6, %v145257_v8 (stack53)
        %v79945_v55 = vadd.s32 5, %v79941_v60 (stack40)
        %v80735_v10 = vadd.s32 2, %v80731_v45 (stack40)
        %v81565_v27 = vadd.s32 %v81560_v54, %v121574_v2 (stack40)
        %v79527_v23 = vmul.f32 0.6931472, %v121110_v46 (stack65)
        %v79530_v40 = vmul.f32 %v79529_v30, %v145274_v40 (stack63)
        %v80334_v30 = vor.u32 %v80333_v44, %v80332_v50 (stack47)
        %v81156_v9 = vadd.s32 %v81152_v31, %v81140_v9 (stack40)
        %v79192_v61 = vmul.f32 %v79188_v8, %v145244_v61 (stack54)
        %vm79532_vm10 = vcmp.lt.f32.partialorder %v79531_v22, 0.0004427343 (stack62)
        %v79947_v22 = vxor.u32 %v79945_v55, %v79933_v34 (stack48)
        %v80739_v41 = vadd.s32 %v80735_v10, %v80723_v26 (stack40)
        %v79533_v7 = vsel /*vm=*/%vm79532_vm10, /*on_true_vy=*/%v79530_v40, /*on_false_vx=*/%v79527_v23 (stack66)
        %v80335_v53 = vxor.u32 %v80334_v30, %v80330_v21 (stack48)
        %v80741_v29 = vshll.u32 %v80735_v10, 13 (stack45)
        %v80742_v34 = vshrl.u32 %v80735_v10, 19 (stack46)
        %v79057_v24 = vmul.f32 inf, %v145129_v32 (stack54)
        %v79196_v20 = vadd.f32 %v79192_v61, %v145252_v20 (stack53)
        %v145321_v26 = vxor.u32 2147483648, %v79533_v7 (stack56)
        %v81573_v12 = vadd.s32 %v145293_v42, %v81565_v27 (stack40)
        %vm79052_vm11 = vcmp.eq.f32.partialorder %v79049_v52, 1.0 (stack68)
        %v80338_v52 = vadd.s32 %v80335_v53, %v80330_v21 (stack40)
        %v80340_v6 = vshll.u32 %v80335_v53, 16 (stack45)
        %v80341_v60 = vshrl.u32 %v80335_v53, 16 (stack46)
        %v79200_v32 = vmul.f32 %v79196_v20, %v145129_v32 (stack54)
        %121111 = vrsqrt.f32 %v145321_v26 (stack67)
        %v79948_v45 = vand.u32.u8 255, %v79947_v22 (stack49)
        %v81158_v54 = vshll.u32 %v81152_v31, 17 (stack45)
        %vm79537_vm12 = vcmp.lt.f32.partialorder %v145321_v26, 5.0 (stack68)
        %v80342_v21 = vor.u32 %v80341_v60, %v80340_v6 (stack47)
        %v80743_v50 = vor.u32 %v80742_v34, %v80741_v29 (stack47)
        %v81159_v44 = vshrl.u32 %v81152_v31, 15 (stack46)
        %v79204_v31 = vsel /*vm=*/%vm79052_vm11, /*on_true_vy=*/%v79057_v24, /*on_false_vx=*/%v79200_v32 (stack44)
        %v81575_v46 = vshll.u32 %v145293_v42, 13 (stack45)
        %v81576_v42 = vshrl.u32 %v145293_v42, 19 (stack46)
        %v79208_v8 = vmul.f32 1.4140625, %v79204_v31 (stack54)
        %v79510_v55 = vand.u32 2147483647, %v145263_v56 (stack77)
        %v145334_v10 = vadd.s32 %v145227_v25, %v122657_v58 (stack40)
        %v145339_v27 = vsel /*vm=*/%vm79537_vm12, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v145344_v23 = vsel /*vm=*/%vm79537_vm12, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v145347_v40 = vadd.f32 -2.5, %v145321_v26 (stack53)
        %v79949_v30 = vand.u32 65535, %v79948_v45 (stack50)
        %v79211_v61 = vpack.c.bf16 %v157387_v11, %v79208_v8 (stack81)
        %v80343_v22 = vxor.u32 %v80342_v21, %v80338_v52 (stack48)
        %v80744_v7 = vxor.u32 %v80743_v50, %v80739_v41 (stack48)
        %v81160_v53 = vor.u32 %v81159_v44, %v81158_v54 (stack47)
        %v145353_v29 = vsel /*vm=*/%vm79537_vm12, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v79950_v34 = vshrl.u32 %v79949_v30, 1 (stack51)
        %v81577_v24 = vor.u32 %v81576_v42, %v81575_v46 (stack47)
        %vm82000_vm13 = vcmp.lt.u32.totalorder %v145227_v25, %v157095_v13 (stack43)
        %120169 = vst [vmem:[%s123356_s30 + $0x54] sm:$0xf] /*vst_source=*/%v79211_v61 (stack83)
        %vm79582_vm14 = vcmp.eq.f32.partialorder %v145321_v26, inf (stack70)
        %v80346_v20 = vadd.s32 %v80343_v22, %v80338_v52 (stack40)
        %v80352_v52 = vshll.u32 %v80343_v22, 24 (stack45)
        %v80353_v6 = vshrl.u32 %v80343_v22, 8 (stack46)
        %v80747_v41 = vadd.s32 %v80744_v7, %v80739_v41 (stack40)
        %v79951_v60 = vor.u32 16256, %v79950_v34 (stack47)
        %v80749_v32 = vshll.u32 %v80744_v7, 15 (stack45)
        %v80750_v45 = vshrl.u32 %v80744_v7, 17 (stack46)
        %v81161_v54 = vxor.u32 %v81160_v53, %v81156_v9 (stack48)
        %v79585_v21 = vand.u32 2147483648, %v145321_v26 (stack72)
        %v80354_v50 = vor.u32 %v80353_v6, %v80352_v52 (stack47)
        %v81578_v44 = vxor.u32 %v81577_v24, %v81573_v12 (stack48)
        %v82005_v43 = vadd.s32 %v157563_v43, %v157100_v14 (stack40)
        %v79952_v31 = vand.u32.u16 65535, %v79951_v60 (stack52)
        %v80751_v46 = vor.u32 %v80750_v45, %v80749_v32 (stack47)
        %v81164_v9 = vadd.s32 %v81161_v54, %v81156_v9 (stack40)
        %v81166_v42 = vshll.u32 %v81161_v54, 29 (stack45)
        %v80355_v8 = vxor.u32 %v80354_v50, %v80346_v20 (stack48)
        %v81167_v30 = vshrl.u32 %v81161_v54, 3 (stack46)
        %v81581_v12 = vadd.s32 %v81578_v44, %v81573_v12 (stack40)
        %v81583_v61 = vshll.u32 %v81578_v44, 15 (stack45)
        %v120172_v22 = vadd.low.f32.bf16 -1.0, %v79952_v31 (stack53)
        %v80350_v7 = vadd.s32 %v80346_v20, %v121569_v1 (stack40)
        %v80752_v53 = vxor.u32 %v80751_v46, %v80747_v41 (stack48)
        %v81584_v34 = vshrl.u32 %v81578_v44, 17 (stack46)
        %v121112_v24 = vpop.eup %121111 (stack73)
        %v80358_v20 = vadd.s32 %v80355_v8, %v121564_v0 (stack40)
        %v81168_v52 = vor.u32 %v81167_v30, %v81166_v42 (stack47)
        %v82009_v6 = vadd.s32 1, %v82005_v43 (stack40)
        %v157586_v60 = vld [vmem:[#allocation146_spill] sm:$0xff] (stack84)
        %v145366_v32 = vadd.s32 %v157586_v60, %v122651_v47 (stack40)
        %v79581_v45 = vmul.f32 %v121112_v24, %v145321_v26 (stack74)
        %v79961_v54 = vmul.f32 2.0, %v120172_v22 (stack54)
        %v80755_v41 = vadd.s32 %v80752_v53, %v80747_v41 (stack40)
        %v80757_v50 = vshll.u32 %v80752_v53, 26 (stack45)
        %v80362_v44 = vadd.s32 4, %v80358_v20 (stack40)
        %v80758_v31 = vshrl.u32 %v80752_v53, 6 (stack46)
        %v81169_v46 = vxor.u32 %v81168_v52, %v81164_v9 (stack48)
        %v81585_v42 = vor.u32 %v81584_v34, %v81583_v61 (stack47)
        %v79583_v8 = vsel /*vm=*/%vm79582_vm14, /*on_true_vy=*/%v145321_v26, /*on_false_vx=*/%v79581_v45 (stack75)
        %vm79584_vm15 = vcmp.eq.f32.partialorder %v145321_v26, 0.0 (stack71)
        %v79965_v30 = vadd.f32 -0.99609375, %v79961_v54 (stack53)
        %v82013_v43 = vsel /*vm=*/%vm82000_vm13, /*on_true_vy=*/%v82009_v6, /*on_false_vx=*/%v82005_v43 (stack44)
        %v79586_v21 = vsel /*vm=*/%vm79584_vm15, /*on_true_vy=*/%v79585_v21, /*on_false_vx=*/%v79583_v8 (stack76)
        %v80366_v61 = vadd.s32 %v80362_v44, %v80350_v7 (stack40)
        %v80368_v22 = vshll.u32 %v80362_v44, 13 (stack45)
        %v80369_v7 = vshrl.u32 %v80362_v44, 19 (stack46)
        %v79589_v53 = vadd.f32 -3.0, %v79586_v21 (stack53)
        %v145376_v34 = vmax.f32 %v79965_v30, -0.99609375 (stack55)
        %v80759_v24 = vor.u32 %v80758_v31, %v80757_v50 (stack47)
        %v81172_v9 = vadd.s32 %v81169_v46, %v81164_v9 (stack40)
        %v80370_v20 = vor.u32 %v80369_v7, %v80368_v22 (stack47)
        %v81174_v52 = vshll.u32 %v81169_v46, 16 (stack45)
        %v81175_v6 = vshrl.u32 %v81169_v46, 16 (stack46)
        %v81586_v45 = vxor.u32 %v81585_v42, %v81581_v12 (stack48)
        %v79562_v54 = vsel /*vm=*/%vm79537_vm12, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v79574_v50 = vsel /*vm=*/%vm79537_vm12, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v145387_v40 = vsel /*vm=*/%vm79537_vm12, /*on_true_vy=*/%v145347_v40, /*on_false_vx=*/%v79589_v53 (stack44)
        %v79981_v44 = vxor.u32 2147483648, %v145376_v34 (stack56)
        %v79570_v31 = vsel /*vm=*/%vm79537_vm12, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v79597_v46 = vmul.f32 %v145387_v40, %v79574_v50 (stack54)
        %v80371_v42 = vxor.u32 %v80370_v20, %v80366_v61 (stack48)
        %v80760_v8 = vxor.u32 %v80759_v24, %v80755_v41 (stack48)
        %v145395_v30 = vmul.f32 %v79981_v44, %v145376_v34 (stack54)
        %v81176_v21 = vor.u32 %v81175_v6, %v81174_v52 (stack47)
        %v81589_v12 = vadd.s32 %v81586_v45, %v81581_v12 (stack40)
        %v82030_v22 = vadd.s32 %v145334_v10, %v121569_v1 (stack40)
        %v79601_v7 = vadd.f32 %v79597_v46, %v79570_v31 (stack53)
        %v80374_v61 = vadd.s32 %v80371_v42, %v80366_v61 (stack40)
        %v80376_v53 = vshll.u32 %v80371_v42, 15 (stack45)
        %v80377_v24 = vshrl.u32 %v80371_v42, 17 (stack46)
        %v79566_v20 = vsel /*vm=*/%vm79537_vm12, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v79986_v52 = vadd.f32 1.0, %v145395_v30 (stack57)
        %v80763_v41 = vadd.s32 %v80760_v8, %v80755_v41 (stack40)
        %vm81995_vm0 = vcmp.lt.u32.totalorder %v145334_v10, %v145227_v25 (stack43)
        %v79605_v6 = vmul.f32 %v79601_v7, %v145387_v40 (stack54)
        %v80378_v50 = vor.u32 %v80377_v24, %v80376_v53 (stack47)
        %v80769_v44 = vshll.u32 %v80760_v8, 6 (stack45)
        %v80770_v31 = vshrl.u32 %v80760_v8, 26 (stack46)
        %121113 = vlog2.f32 %v79986_v52 (stack58)
        %v79989_v46 = vmul.f32 -0.5, %v145395_v30 (stack59)
        %v81591_v42 = vshll.u32 %v81586_v45, 26 (stack45)
        %v82036_v8 = vshll.u32 %v82030_v22, 13 (stack45)
        %v79609_v7 = vadd.f32 %v79605_v6, %v79566_v20 (stack53)
        %v80379_v53 = vxor.u32 %v80378_v50, %v80374_v61 (stack48)
        %v80771_v24 = vor.u32 %v80770_v31, %v80769_v44 (stack47)
        %v81177_v21 = vxor.u32 %v81176_v21, %v81172_v9 (stack48)
        %v79992_v20 = vand.u32 2147483647, %v145395_v30 (stack60)
        %v81592_v45 = vshrl.u32 %v81586_v45, 6 (stack46)
        %v82017_v52 = vadd.s32 1, %v82013_v43 (stack40)
        %v82037_v6 = vshrl.u32 %v82030_v22, 19 (stack46)
        %v79613_v50 = vmul.f32 %v79609_v7, %v145387_v40 (stack54)
        %v80382_v61 = vadd.s32 %v80379_v53, %v80374_v61 (stack40)
        %v80384_v44 = vshll.u32 %v80379_v53, 26 (stack45)
        %v80385_v31 = vshrl.u32 %v80379_v53, 6 (stack46)
        %v80772_v7 = vxor.u32 %v80771_v24, %v80763_v41 (stack48)
        %v81180_v9 = vadd.s32 %v81177_v21, %v81172_v9 (stack40)
        %v81186_v53 = vshll.u32 %v81177_v21, 24 (stack45)
        %v81187_v24 = vshrl.u32 %v81177_v21, 8 (stack46)
        %v79617_v54 = vadd.f32 %v79613_v50, %v79562_v54 (stack53)
        %v80386_v21 = vor.u32 %v80385_v31, %v80384_v44 (stack47)
        %v81593_v42 = vor.u32 %v81592_v45, %v81591_v42 (stack47)
        %v82021_v25 = vsel /*vm=*/%vm81995_vm0, /*on_true_vy=*/%v82017_v52, /*on_false_vx=*/%v82013_v43 (stack44)
        %v79990_v10 = vadd.f32 1.0, %v79989_v46 (stack61)
        %v80775_v43 = vadd.s32 %v80772_v7, %v121569_v1 (stack40)
        %v81188_v46 = vor.u32 %v81187_v24, %v81186_v53 (stack47)
        %v82026_v45 = vadd.s32 %v82021_v25, %v121574_v2 (stack40)
        %v79621_v52 = vmul.f32 %v79617_v54, %v145387_v40 (stack54)
        %v80387_v50 = vxor.u32 %v80386_v21, %v80382_v61 (stack48)
        %v80767_v41 = vadd.s32 %v80763_v41, %v121574_v2 (stack40)
        %v81594_v44 = vxor.u32 %v81593_v42, %v81589_v12 (stack48)
        %v80779_v31 = vadd.s32 3, %v80775_v43 (stack40)
        %v81189_v7 = vxor.u32 %v81188_v46, %v81180_v9 (stack48)
        %v82034_v22 = vadd.s32 %v82030_v22, %v82026_v45 (stack40)
        %v82038_v8 = vor.u32 %v82037_v6, %v82036_v8 (stack47)
        %v79625_v29 = vadd.f32 %v79621_v52, %v145353_v29 (stack53)
        %v80390_v6 = vadd.s32 %v80387_v50, %v80382_v61 (stack40)
        %v80396_v61 = vshll.u32 %v80387_v50, 6 (stack45)
        %v80397_v53 = vshrl.u32 %v80387_v50, 26 (stack46)
        %v80783_v24 = vadd.s32 %v80779_v31, %v80767_v41 (stack40)
        %v80785_v54 = vshll.u32 %v80779_v31, 17 (stack45)
        %v80786_v21 = vshrl.u32 %v80779_v31, 15 (stack46)
        %v81192_v42 = vadd.s32 %v81189_v7, %v121574_v2 (stack40)
        %v79629_v25 = vmul.f32 %v79625_v29, %v145387_v40 (stack54)
        %v80398_v43 = vor.u32 %v80397_v53, %v80396_v61 (stack47)
        %v81184_v9 = vadd.s32 %v81180_v9, %v121564_v0 (stack40)
        %v81597_v12 = vadd.s32 %v81594_v44, %v81589_v12 (stack40)
        %v80787_v46 = vor.u32 %v80786_v21, %v80785_v54 (stack47)
        %v81196_v45 = vadd.s32 2, %v81192_v42 (stack40)
        %v81603_v52 = vshll.u32 %v81594_v44, 6 (stack45)
        %v81604_v50 = vshrl.u32 %v81594_v44, 26 (stack46)
        %v121114_v41 = vpop.eup %121113 (stack64)
        %v79633_v23 = vadd.f32 %v79629_v25, %v145344_v23 (stack53)
        %vm145421_vm1 = vcmp.lt.f32.partialorder %v79992_v20, 0.0004427343 (stack62)
        %v80399_v44 = vxor.u32 %v80398_v43, %v80390_v6 (stack48)
        %v82039_v31 = vxor.u32 %v82038_v8, %v82034_v22 (stack48)
        %v79988_v7 = vmul.f32 0.6931472, %v121114_v41 (stack65)
        %v79991_v30 = vmul.f32 %v79990_v10, %v145395_v30 (stack63)
        %v80788_v10 = vxor.u32 %v80787_v46, %v80783_v24 (stack48)
        %v81200_v8 = vadd.s32 %v81196_v45, %v81184_v9 (stack40)
        %v79637_v29 = vmul.f32 %v79633_v23, %v145387_v40 (stack54)
        %v80402_v61 = vadd.s32 %v80399_v44, %v121574_v2 (stack40)
        %v81202_v53 = vshll.u32 %v81196_v45, 13 (stack45)
        %v81605_v54 = vor.u32 %v81604_v50, %v81603_v52 (stack47)
        %v79994_v21 = vsel /*vm=*/%vm145421_vm1, /*on_true_vy=*/%v79991_v30, /*on_false_vx=*/%v79988_v7 (stack66)
        %v80791_v24 = vadd.s32 %v80788_v10, %v80783_v24 (stack40)
        %v80793_v42 = vshll.u32 %v80788_v10, 29 (stack45)
        %v80794_v25 = vshrl.u32 %v80788_v10, 3 (stack46)
        %v79641_v27 = vadd.f32 %v79637_v29, %v145339_v27 (stack53)
        %v145431_v43 = vxor.u32 2147483648, %v79994_v21 (stack56)
        %v80406_v9 = vadd.s32 5, %v80402_v61 (stack40)
        %v81203_v46 = vshrl.u32 %v81196_v45, 19 (stack46)
        %v80394_v6 = vadd.s32 %v80390_v6, %v121564_v0 (stack40)
        %v80795_v45 = vor.u32 %v80794_v25, %v80793_v42 (stack47)
        %v81606_v52 = vxor.u32 %v81605_v54, %v81597_v12 (stack48)
        %v145434_v22 = vadd.s32 %v82039_v31, %v82034_v22 (stack40)
        %v79645_v50 = vmul.f32 %v79641_v27, %v145387_v40 (stack54)
        %121115 = vrsqrt.f32 %v145431_v43 (stack67)
        %v79518_v41 = vmul.f32 inf, %v145263_v56 (stack54)
        %v79546_v23 = vsel /*vm=*/%vm79537_vm12, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %vm79998_vm2 = vcmp.lt.f32.partialorder %v145431_v43, 5.0 (stack68)
        %v80408_v20 = vxor.u32 %v80406_v9, %v80394_v6 (stack48)
        %vm145445_vm3 = vcmp.eq.f32.partialorder %v79510_v55, 1.0 (stack68)
        %v79542_v26 = vsel /*vm=*/%vm79537_vm12, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v79649_v44 = vadd.f32 %v79645_v50, %v79546_v23 (stack53)
        %v81204_v7 = vor.u32 %v81203_v46, %v81202_v53 (stack47)
        %v79971_v30 = vand.u32 2147483647, %v145376_v34 (stack77)
        %v80796_v10 = vxor.u32 %v80795_v45, %v80791_v24 (stack48)
        %v81601_v12 = vadd.s32 %v81597_v12, %v121569_v1 (stack40)
        %v145456_v29 = vadd.s32 %v145366_v32, %v122657_v58 (stack40)
        %v79653_v40 = vmul.f32 %v79649_v44, %v145387_v40 (stack54)
        %v145462_v61 = vsel /*vm=*/%vm79998_vm2, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v145465_v53 = vadd.f32 -2.5, %v145431_v43 (stack53)
        %v82044_v54 = vshll.u32 %v82039_v31, 15 (stack45)
        %v80409_v21 = vand.u32.u8 255, %v80408_v20 (stack49)
        %v80799_v24 = vadd.s32 %v80796_v10, %v80791_v24 (stack40)
        %v80801_v42 = vshll.u32 %v80796_v10, 16 (stack45)
        %v80802_v25 = vshrl.u32 %v80796_v10, 16 (stack46)
        %v79657_v27 = vadd.f32 %v79653_v40, %v79542_v26 (stack53)
        %v81205_v9 = vxor.u32 %v81204_v7, %v81200_v8 (stack48)
        %v81609_v46 = vadd.s32 %v81606_v52, %v121564_v0 (stack40)
        %v82045_v31 = vshrl.u32 %v82039_v31, 17 (stack46)
        %v145471_v6 = vsel /*vm=*/%vm79998_vm2, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v80410_v45 = vand.u32 65535, %v80409_v21 (stack50)
        %v80803_v52 = vor.u32 %v80802_v25, %v80801_v42 (stack47)
        %vm82495_vm4 = vcmp.lt.u32.totalorder %v145366_v32, %v122651_v47 (stack43)
        %v79661_v56 = vmul.f32 %v79657_v27, %v145263_v56 (stack54)
        %v81208_v8 = vadd.s32 %v81205_v9, %v81200_v8 (stack40)
        %v81210_v50 = vshll.u32 %v81205_v9, 15 (stack45)
        %v81211_v23 = vshrl.u32 %v81205_v9, 17 (stack46)
        %vm80043_vm5 = vcmp.eq.f32.partialorder %v145431_v43, inf (stack70)
        %v80411_v20 = vshrl.u32 %v80410_v45, 1 (stack51)
        %v80804_v26 = vxor.u32 %v80803_v52, %v80799_v24 (stack48)
        %v81613_v44 = vadd.s32 1, %v81609_v46 (stack40)
        %v79665_v41 = vsel /*vm=*/%vm145445_vm3, /*on_true_vy=*/%v79518_v41, /*on_false_vx=*/%v79661_v56 (stack44)
        %v81212_v55 = vor.u32 %v81211_v23, %v81210_v50 (stack47)
        %v82046_v7 = vor.u32 %v82045_v31, %v82044_v54 (stack47)
        %v157591_v10 = vld [vmem:[#allocation108_spill] sm:$0xff] (stack84)
        %v145481_v40 = vadd.s32 %v157591_v10, %v157068_v28 (stack40)
        %v79669_v54 = vmul.f32 1.4140625, %v79665_v41 (stack54)
        %v80412_v21 = vor.u32 16256, %v80411_v20 (stack47)
        %v80807_v24 = vadd.s32 %v80804_v26, %v80799_v24 (stack40)
        %v80813_v42 = vshll.u32 %v80804_v26, 24 (stack45)
        %v80814_v25 = vshrl.u32 %v80804_v26, 8 (stack46)
        %v81213_v27 = vxor.u32 %v81212_v55, %v81208_v8 (stack48)
        %v81617_v12 = vadd.s32 %v81613_v44, %v81601_v12 (stack40)
        %v81619_v9 = vshll.u32 %v81613_v44, 17 (stack45)
        %v121116_v46 = vpop.eup %121115 (stack73)
        %v79672_v31 = vpack.c.bf16 %v157387_v11, %v79669_v54 (stack81)
        %v80046_v45 = vand.u32 2147483648, %v145431_v43 (stack72)
        %v80413_v52 = vand.u32.u16 65535, %v80412_v21 (stack52)
        %v81620_v56 = vshrl.u32 %v81613_v44, 15 (stack46)
        %v80042_v50 = vmul.f32 %v121116_v46, %v145431_v43 (stack74)
        %v80815_v23 = vor.u32 %v80814_v25, %v80813_v42 (stack47)
        %v81216_v8 = vadd.s32 %v81213_v27, %v81208_v8 (stack40)
        %v81218_v20 = vshll.u32 %v81213_v27, 26 (stack45)
        %120171 = vst [vmem:[%s123356_s30 + $0xd4] sm:$0xf] /*vst_source=*/%v79672_v31 (stack83)
        %v120174_v26 = vadd.low.f32.bf16 -1.0, %v80413_v52 (stack53)
        %v81219_v44 = vshrl.u32 %v81213_v27, 6 (stack46)
        %v81621_v41 = vor.u32 %v81620_v56, %v81619_v9 (stack47)
        %v82047_v55 = vxor.u32 %v82046_v7, %v145434_v22 (stack48)
        %v80031_v7 = vsel /*vm=*/%vm79998_vm2, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v80044_v54 = vsel /*vm=*/%vm80043_vm5, /*on_true_vy=*/%v145431_v43, /*on_false_vx=*/%v80042_v50 (stack75)
        %vm80045_vm6 = vcmp.eq.f32.partialorder %v145431_v43, 0.0 (stack71)
        %v80816_v21 = vxor.u32 %v80815_v23, %v80807_v24 (stack48)
        %v80047_v42 = vsel /*vm=*/%vm80045_vm6, /*on_true_vy=*/%v80046_v45, /*on_false_vx=*/%v80044_v54 (stack76)
        %v80422_v25 = vmul.f32 2.0, %v120174_v26 (stack54)
        %v81220_v27 = vor.u32 %v81219_v44, %v81218_v20 (stack47)
        %v81622_v9 = vxor.u32 %v81621_v41, %v81617_v12 (stack48)
        %v80035_v46 = vsel /*vm=*/%vm79998_vm2, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v80050_v31 = vadd.f32 -3.0, %v80047_v42 (stack53)
        %v80819_v45 = vadd.s32 %v80816_v21, %v121564_v0 (stack40)
        %v82050_v22 = vadd.s32 %v82047_v55, %v145434_v22 (stack40)
        %v80426_v52 = vadd.f32 -0.99609375, %v80422_v25 (stack53)
        %v80811_v24 = vadd.s32 %v80807_v24, %v121569_v1 (stack40)
        %v81221_v56 = vxor.u32 %v81220_v27, %v81216_v8 (stack48)
        %v81625_v12 = vadd.s32 %v81622_v9, %v81617_v12 (stack40)
        %v145504_v53 = vsel /*vm=*/%vm79998_vm2, /*on_true_vy=*/%v145465_v53, /*on_false_vx=*/%v80050_v31 (stack44)
        %v80823_v50 = vadd.s32 4, %v80819_v45 (stack40)
        %v81627_v23 = vshll.u32 %v81622_v9, 29 (stack45)
        %v81628_v20 = vshrl.u32 %v81622_v9, 3 (stack46)
        %v80058_v26 = vmul.f32 %v145504_v53, %v80035_v46 (stack54)
        %v145507_v44 = vmax.f32 %v80426_v52, -0.99609375 (stack55)
        %v81224_v8 = vadd.s32 %v81221_v56, %v81216_v8 (stack40)
        %v81230_v41 = vshll.u32 %v81221_v56, 6 (stack45)
        %v80827_v54 = vadd.s32 %v80823_v50, %v80811_v24 (stack40)
        %v80829_v21 = vshll.u32 %v80823_v50, 13 (stack45)
        %v80830_v42 = vshrl.u32 %v80823_v50, 19 (stack46)
        %v81231_v25 = vshrl.u32 %v81221_v56, 26 (stack46)
        %v80062_v7 = vadd.f32 %v80058_v26, %v80031_v7 (stack53)
        %v80442_v27 = vxor.u32 2147483648, %v145507_v44 (stack56)
        %v82052_v9 = vshll.u32 %v82047_v55, 26 (stack45)
        %v82053_v55 = vshrl.u32 %v82047_v55, 6 (stack46)
        %v80831_v46 = vor.u32 %v80830_v42, %v80829_v21 (stack47)
        %v81232_v31 = vor.u32 %v81231_v25, %v81230_v41 (stack47)
        %v81629_v45 = vor.u32 %v81628_v20, %v81627_v23 (stack47)
        %v82504_v52 = vadd.s32 1, %v145481_v40 (stack40)
        %v80015_v24 = vsel /*vm=*/%vm79998_vm2, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v80027_v56 = vsel /*vm=*/%vm79998_vm2, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v80066_v50 = vmul.f32 %v80062_v7, %v145504_v53 (stack54)
        %v145519_v23 = vmul.f32 %v80442_v27, %v145507_v44 (stack54)
        %v80832_v20 = vxor.u32 %v80831_v46, %v80827_v54 (stack48)
        %v81233_v26 = vxor.u32 %v81232_v31, %v81224_v8 (stack48)
        %v81630_v41 = vxor.u32 %v81629_v45, %v81625_v12 (stack48)
        %v82508_v40 = vsel /*vm=*/%vm82495_vm4, /*on_true_vy=*/%v82504_v52, /*on_false_vx=*/%v145481_v40 (stack44)
        %v80019_v21 = vsel /*vm=*/%vm79998_vm2, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v80070_v42 = vadd.f32 %v80066_v50, %v80027_v56 (stack53)
        %v80447_v25 = vadd.f32 1.0, %v145519_v23 (stack57)
        %v82054_v7 = vor.u32 %v82053_v55, %v82052_v9 (stack47)
        %v80835_v54 = vadd.s32 %v80832_v20, %v80827_v54 (stack40)
        %v80837_v27 = vshll.u32 %v80832_v20, 15 (stack45)
        %v80838_v9 = vshrl.u32 %v80832_v20, 17 (stack46)
        %v81236_v55 = vadd.s32 %v81233_v26, %v121569_v1 (stack40)
        %v80023_v46 = vsel /*vm=*/%vm79998_vm2, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v80074_v31 = vmul.f32 %v80070_v42, %v145504_v53 (stack54)
        %121117 = vlog2.f32 %v80447_v25 (stack58)
        %v81228_v8 = vadd.s32 %v81224_v8, %v121574_v2 (stack40)
        %v80839_v45 = vor.u32 %v80838_v9, %v80837_v27 (stack47)
        %v81240_v52 = vadd.s32 3, %v81236_v55 (stack40)
        %v81633_v12 = vadd.s32 %v81630_v41, %v81625_v12 (stack40)
        %v81635_v56 = vshll.u32 %v81630_v41, 16 (stack45)
        %vm82490_vm7 = vcmp.lt.u32.totalorder %v145456_v29, %v145366_v32 (stack43)
        %v80078_v50 = vadd.f32 %v80074_v31, %v80023_v46 (stack53)
        %v81636_v20 = vshrl.u32 %v81630_v41, 16 (stack46)
        %v82055_v26 = vxor.u32 %v82054_v7, %v82050_v22 (stack48)
        %v145539_v41 = vadd.s32 %v145456_v29, %v121569_v1 (stack40)
        %v80840_v42 = vxor.u32 %v80839_v45, %v80835_v54 (stack48)
        %v81244_v25 = vadd.s32 %v81240_v52, %v81228_v8 (stack40)
        %v81246_v7 = vshll.u32 %v81240_v52, 17 (stack45)
        %v81247_v27 = vshrl.u32 %v81240_v52, 15 (stack46)
        %v80082_v9 = vmul.f32 %v80078_v50, %v145504_v53 (stack54)
        %v80450_v55 = vmul.f32 -0.5, %v145519_v23 (stack59)
        %v81637_v46 = vor.u32 %v81636_v20, %v81635_v56 (stack47)
        %v145543_v22 = vadd.s32 %v82055_v26, %v82050_v22 (stack40)
        %v80843_v54 = vadd.s32 %v80840_v42, %v80835_v54 (stack40)
        %v80845_v31 = vshll.u32 %v80840_v42, 26 (stack45)
        %v80846_v8 = vshrl.u32 %v80840_v42, 6 (stack46)
        %v81248_v45 = vor.u32 %v81247_v27, %v81246_v7 (stack47)
        %v80086_v21 = vadd.f32 %v80082_v9, %v80019_v21 (stack53)
        %v81638_v52 = vxor.u32 %v81637_v46, %v81633_v12 (stack48)
        %v82064_v56 = vshll.u32 %v82055_v26, 6 (stack45)
        %v82065_v50 = vshrl.u32 %v82055_v26, 26 (stack46)
        %v80453_v20 = vand.u32 2147483647, %v145519_v23 (stack60)
        %v80847_v26 = vor.u32 %v80846_v8, %v80845_v31 (stack47)
        %v81249_v42 = vxor.u32 %v81248_v45, %v81244_v25 (stack48)
        %v82512_v7 = vadd.s32 1, %v82508_v40 (stack40)
        %v80090_v27 = vmul.f32 %v80086_v21, %v145504_v53 (stack54)
        %v81641_v12 = vadd.s32 %v81638_v52, %v81633_v12 (stack40)
        %v81647_v9 = vshll.u32 %v81638_v52, 24 (stack45)
        %v81648_v46 = vshrl.u32 %v81638_v52, 8 (stack46)
        %v80848_v31 = vxor.u32 %v80847_v26, %v80843_v54 (stack48)
        %v81252_v25 = vadd.s32 %v81249_v42, %v81244_v25 (stack40)
        %v81254_v8 = vshll.u32 %v81249_v42, 29 (stack45)
        %v81255_v45 = vshrl.u32 %v81249_v42, 3 (stack46)
        %v80094_v24 = vadd.f32 %v80090_v27, %v80015_v24 (stack53)
        %v80451_v55 = vadd.f32 1.0, %v80450_v55 (stack61)
        %v81649_v21 = vor.u32 %v81648_v46, %v81647_v9 (stack47)
        %v82066_v52 = vor.u32 %v82065_v50, %v82064_v56 (stack47)
        %v80851_v54 = vadd.s32 %v80848_v31, %v80843_v54 (stack40)
        %v80857_v56 = vshll.u32 %v80848_v31, 6 (stack45)
        %v80858_v50 = vshrl.u32 %v80848_v31, 26 (stack46)
        %v81256_v26 = vor.u32 %v81255_v45, %v81254_v8 (stack47)
        %v80098_v42 = vmul.f32 %v80094_v24, %v145504_v53 (stack54)
        %v81650_v27 = vxor.u32 %v81649_v21, %v81641_v12 (stack48)
        %v82067_v9 = vxor.u32 %v82066_v52, %v145543_v22 (stack48)
        %v82516_v32 = vsel /*vm=*/%vm82490_vm7, /*on_true_vy=*/%v82512_v7, /*on_false_vx=*/%v82508_v40 (stack44)
        %v121118_v29 = vpop.eup %121117 (stack64)
        %vm145552_vm8 = vcmp.lt.f32.partialorder %v80453_v20, 0.0004427343 (stack62)
        %v80859_v20 = vor.u32 %v80858_v50, %v80857_v56 (stack47)
        %v81257_v7 = vxor.u32 %v81256_v26, %v81252_v25 (stack48)
        %v82521_v46 = vadd.s32 %v82516_v32, %v121574_v2 (stack40)
        %v80102_v6 = vadd.f32 %v80098_v42, %v145471_v6 (stack53)
        %v80449_v31 = vmul.f32 0.6931472, %v121118_v29 (stack65)
        %v80452_v23 = vmul.f32 %v80451_v55, %v145519_v23 (stack63)
        %v81653_v8 = vadd.s32 %v81650_v27, %v121574_v2 (stack40)
        %v80860_v45 = vxor.u32 %v80859_v20, %v80851_v54 (stack48)
        %v81260_v25 = vadd.s32 %v81257_v7, %v81252_v25 (stack40)
        %v81262_v24 = vshll.u32 %v81257_v7, 16 (stack45)
        %v81263_v55 = vshrl.u32 %v81257_v7, 16 (stack46)
        %v80106_v21 = vmul.f32 %v80102_v6, %v145504_v53 (stack54)
        %v80455_v52 = vsel /*vm=*/%vm145552_vm8, /*on_true_vy=*/%v80452_v23, /*on_false_vx=*/%v80449_v31 (stack66)
        %v81645_v12 = vadd.s32 %v81641_v12, %v121564_v0 (stack40)
        %v81657_v56 = vadd.s32 2, %v81653_v8 (stack40)
        %v145564_v50 = vxor.u32 2147483648, %v80455_v52 (stack56)
        %v81264_v26 = vor.u32 %v81263_v55, %v81262_v24 (stack47)
        %v82070_v42 = vadd.s32 %v82067_v9, %v121564_v0 (stack40)
        %v82529_v27 = vadd.s32 %v145539_v41, %v82521_v46 (stack40)
        %vm145570_vm9 = vcmp.eq.f32.partialorder %v79971_v30, 1.0 (stack68)
        %v79979_v9 = vmul.f32 inf, %v145376_v34 (stack54)
        %v80110_v61 = vadd.f32 %v80106_v21, %v145462_v61 (stack53)
        %v81661_v32 = vadd.s32 %v81657_v56, %v81645_v12 (stack40)
        %v80003_v43 = vsel /*vm=*/%vm79998_vm2, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %vm80459_vm10 = vcmp.lt.f32.partialorder %v145564_v50, 5.0 (stack68)
        %121119 = vrsqrt.f32 %v145564_v50 (stack67)
        %v80863_v29 = vadd.s32 %v80860_v45, %v121574_v2 (stack40)
        %v80114_v53 = vmul.f32 %v80110_v61, %v145504_v53 (stack54)
        %v81663_v40 = vshll.u32 %v81657_v56, 13 (stack45)
        %v81664_v20 = vshrl.u32 %v81657_v56, 19 (stack46)
        %v82531_v7 = vshll.u32 %v145539_v41, 13 (stack45)
        %v81265_v46 = vxor.u32 %v81264_v26, %v81260_v25 (stack48)
        %v82062_v22 = vadd.s32 %v145543_v22, %v121569_v1 (stack40)
        %v82074_v6 = vadd.s32 1, %v82070_v42 (stack40)
        %v82532_v41 = vshrl.u32 %v145539_v41, 19 (stack46)
        %v80118_v31 = vadd.f32 %v80114_v53, %v80003_v43 (stack53)
        %v145590_v23 = vsel /*vm=*/%vm80459_vm10, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v145593_v8 = vadd.f32 -2.5, %v145564_v50 (stack53)
        %v80855_v54 = vadd.s32 %v80851_v54, %v121564_v0 (stack40)
        %v145599_v45 = vsel /*vm=*/%vm80459_vm10, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v145604_v24 = vsel /*vm=*/%vm80459_vm10, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v80867_v55 = vadd.s32 5, %v80863_v29 (stack40)
        %v81268_v25 = vadd.s32 %v81265_v46, %v81260_v25 (stack40)
        %v80122_v34 = vmul.f32 %v80118_v31, %v145376_v34 (stack54)
        %v81274_v21 = vshll.u32 %v81265_v46, 24 (stack45)
        %v81275_v52 = vshrl.u32 %v81265_v46, 8 (stack46)
        %v81665_v12 = vor.u32 %v81664_v20, %v81663_v40 (stack47)
        %v145610_v56 = vsel /*vm=*/%vm80459_vm10, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v80869_v26 = vxor.u32 %v80867_v55, %v80855_v54 (stack48)
        %v82078_v42 = vadd.s32 %v82074_v6, %v82062_v22 (stack40)
        %v82080_v61 = vshll.u32 %v82074_v6, 17 (stack45)
        %v80126_v30 = vsel /*vm=*/%vm145570_vm9, /*on_true_vy=*/%v79979_v9, /*on_false_vx=*/%v80122_v34 (stack44)
        %vm80504_vm11 = vcmp.eq.f32.partialorder %v145564_v50, inf (stack70)
        %v81276_v9 = vor.u32 %v81275_v52, %v81274_v21 (stack47)
        %v81666_v43 = vxor.u32 %v81665_v12, %v81661_v32 (stack48)
        %v82081_v29 = vshrl.u32 %v82074_v6, 15 (stack46)
        %v80130_v53 = vmul.f32 1.4140625, %v80126_v30 (stack54)
        %vm80506_vm12 = vcmp.eq.f32.partialorder %v145564_v50, 0.0 (stack71)
        %v80870_v40 = vand.u32.u8 255, %v80869_v26 (stack49)
        %v82533_v20 = vor.u32 %v82532_v41, %v82531_v7 (stack47)
        %v145618_v7 = vadd.s32 %v157586_v60, %v157070_v38 (stack40)
        %v81277_v46 = vxor.u32 %v81276_v9, %v81268_v25 (stack48)
        %v81669_v32 = vadd.s32 %v81666_v43, %v81661_v32 (stack40)
        %v81671_v22 = vshll.u32 %v81666_v43, 15 (stack45)
        %v81672_v6 = vshrl.u32 %v81666_v43, 17 (stack46)
        %v80133_v41 = vpack.c.bf16 %v157387_v11, %v80130_v53 (stack81)
        %v80871_v31 = vand.u32 65535, %v80870_v40 (stack50)
        %v82082_v54 = vor.u32 %v82081_v29, %v82080_v61 (stack47)
        %v82534_v55 = vxor.u32 %v82533_v20, %v82529_v27 (stack48)
        %v80507_v34 = vand.u32 2147483648, %v145564_v50 (stack72)
        %v81280_v21 = vadd.s32 %v81277_v46, %v121564_v0 (stack40)
        %v81673_v52 = vor.u32 %v81672_v6, %v81671_v22 (stack47)
        %vm82956_vm13 = vcmp.lt.u32.totalorder %v145618_v7, %v157070_v38 (stack43)
        %120173 = vst [vmem:[%s123356_s30 + $0x154] sm:$0xf] /*vst_source=*/%v80133_v41 (stack83)
        %v80872_v12 = vshrl.u32 %v80871_v31, 1 (stack51)
        %v81272_v25 = vadd.s32 %v81268_v25, %v121569_v1 (stack40)
        %v82083_v26 = vxor.u32 %v82082_v54, %v82078_v42 (stack48)
        %v82537_v27 = vadd.s32 %v82534_v55, %v82529_v27 (stack40)
        %v121120_v61 = vpop.eup %121119 (stack73)
        %v81284_v30 = vadd.s32 4, %v81280_v21 (stack40)
        %v81674_v9 = vxor.u32 %v81673_v52, %v81669_v32 (stack48)
        %v82539_v43 = vshll.u32 %v82534_v55, 15 (stack45)
        %v82540_v29 = vshrl.u32 %v82534_v55, 17 (stack46)
        %v80503_v53 = vmul.f32 %v121120_v61, %v145564_v50 (stack74)
        %v80873_v40 = vor.u32 16256, %v80872_v12 (stack47)
        %v82086_v42 = vadd.s32 %v82083_v26, %v82078_v42 (stack40)
        %v82088_v20 = vshll.u32 %v82083_v26, 29 (stack45)
        %v81288_v46 = vadd.s32 %v81284_v30, %v81272_v25 (stack40)
        %v81290_v22 = vshll.u32 %v81284_v30, 13 (stack45)
        %v81291_v6 = vshrl.u32 %v81284_v30, 19 (stack46)
        %v81677_v32 = vadd.s32 %v81674_v9, %v81669_v32 (stack40)
        %v80505_v41 = vsel /*vm=*/%vm80504_vm11, /*on_true_vy=*/%v145564_v50, /*on_false_vx=*/%v80503_v53 (stack75)
        %v80874_v31 = vand.u32.u16 65535, %v80873_v40 (stack52)
        %v81679_v54 = vshll.u32 %v81674_v9, 26 (stack45)
        %v81680_v55 = vshrl.u32 %v81674_v9, 6 (stack46)
        %v80508_v34 = vsel /*vm=*/%vm80506_vm12, /*on_true_vy=*/%v80507_v34, /*on_false_vx=*/%v80505_v41 (stack76)
        %v81292_v21 = vor.u32 %v81291_v6, %v81290_v22 (stack47)
        %v82089_v52 = vshrl.u32 %v82083_v26, 3 (stack46)
        %v82541_v12 = vor.u32 %v82540_v29, %v82539_v43 (stack47)
        %v80511_v25 = vadd.f32 -3.0, %v80508_v34 (stack53)
        %v120176_v26 = vadd.low.f32.bf16 -1.0, %v80874_v31 (stack53)
        %v81681_v61 = vor.u32 %v81680_v55, %v81679_v54 (stack47)
        %v82961_v30 = vadd.s32 %v157591_v10, %v157076_v35 (stack40)
        %v80492_v9 = vsel /*vm=*/%vm80459_vm10, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v81293_v43 = vxor.u32 %v81292_v21, %v81288_v46 (stack48)
        %v82090_v29 = vor.u32 %v82089_v52, %v82088_v20 (stack47)
        %v82542_v53 = vxor.u32 %v82541_v12, %v82537_v27 (stack48)
        %v80496_v40 = vsel /*vm=*/%vm80459_vm10, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v145644_v8 = vsel /*vm=*/%vm80459_vm10, /*on_true_vy=*/%v145593_v8, /*on_false_vx=*/%v80511_v25 (stack44)
        %v80883_v20 = vmul.f32 2.0, %v120176_v26 (stack54)
        %v81682_v22 = vxor.u32 %v81681_v61, %v81677_v32 (stack48)
        %v80519_v6 = vmul.f32 %v145644_v8, %v80496_v40 (stack54)
        %v81296_v46 = vadd.s32 %v81293_v43, %v81288_v46 (stack40)
        %v81298_v41 = vshll.u32 %v81293_v43, 15 (stack45)
        %v81299_v31 = vshrl.u32 %v81293_v43, 17 (stack46)
        %v80887_v54 = vadd.f32 -0.99609375, %v80883_v20 (stack53)
        %v81685_v32 = vadd.s32 %v81682_v22, %v81677_v32 (stack40)
        %v81691_v55 = vshll.u32 %v81682_v22, 6 (stack45)
        %v81692_v34 = vshrl.u32 %v81682_v22, 26 (stack46)
        %v80523_v21 = vadd.f32 %v80519_v6, %v80492_v9 (stack53)
        %v81300_v52 = vor.u32 %v81299_v31, %v81298_v41 (stack47)
        %v82091_v12 = vxor.u32 %v82090_v29, %v82086_v42 (stack48)
        %v82545_v27 = vadd.s32 %v82542_v53, %v82537_v27 (stack40)
        %v80488_v25 = vsel /*vm=*/%vm80459_vm10, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v145650_v26 = vmax.f32 %v80887_v54, -0.99609375 (stack55)
        %v81693_v61 = vor.u32 %v81692_v34, %v81691_v55 (stack47)
        %v145654_v9 = vadd.s32 %v145618_v7, %v122657_v58 (stack40)
        %v80527_v43 = vmul.f32 %v80523_v21, %v145644_v8 (stack54)
        %v81301_v29 = vxor.u32 %v81300_v52, %v81296_v46 (stack48)
        %v82094_v42 = vadd.s32 %v82091_v12, %v82086_v42 (stack40)
        %v82965_v40 = vadd.s32 1, %v82961_v30 (stack40)
        %v80903_v20 = vxor.u32 2147483648, %v145650_v26 (stack56)
        %v81694_v22 = vxor.u32 %v81693_v61, %v81685_v32 (stack48)
        %v82096_v6 = vshll.u32 %v82091_v12, 16 (stack45)
        %v82547_v41 = vshll.u32 %v82542_v53, 26 (stack45)
        %v80531_v31 = vadd.f32 %v80527_v43, %v80488_v25 (stack53)
        %v81304_v46 = vadd.s32 %v81301_v29, %v81296_v46 (stack40)
        %v81306_v54 = vshll.u32 %v81301_v29, 26 (stack45)
        %v81307_v55 = vshrl.u32 %v81301_v29, 6 (stack46)
        %v80484_v34 = vsel /*vm=*/%vm80459_vm10, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v80906_v21 = vmul.f32 %v80903_v20, %v145650_v26 (stack54)
        %v81697_v52 = vadd.s32 %v81694_v22, %v121569_v1 (stack40)
        %v82097_v12 = vshrl.u32 %v82091_v12, 16 (stack46)
        %v80535_v25 = vmul.f32 %v80531_v31, %v145644_v8 (stack54)
        %v81308_v61 = vor.u32 %v81307_v55, %v81306_v54 (stack47)
        %v82548_v53 = vshrl.u32 %v82542_v53, 6 (stack46)
        %v82969_v30 = vsel /*vm=*/%vm82956_vm13, /*on_true_vy=*/%v82965_v40, /*on_false_vx=*/%v82961_v30 (stack44)
        %v80908_v43 = vadd.f32 1.0, %v80906_v21 (stack57)
        %v80911_v29 = vmul.f32 -0.5, %v80906_v21 (stack59)
        %v81689_v32 = vadd.s32 %v81685_v32, %v121574_v2 (stack40)
        %v81701_v40 = vadd.s32 3, %v81697_v52 (stack40)
        %vm82951_vm14 = vcmp.lt.u32.totalorder %v145654_v9, %v145618_v7 (stack43)
        %v80539_v20 = vadd.f32 %v80535_v25, %v80484_v34 (stack53)
        %v81309_v22 = vxor.u32 %v81308_v61, %v81304_v46 (stack48)
        %v82098_v6 = vor.u32 %v82097_v12, %v82096_v6 (stack47)
        %v82549_v41 = vor.u32 %v82548_v53, %v82547_v41 (stack47)
        %121121 = vlog2.f32 %v80908_v43 (stack58)
        %v80912_v31 = vadd.f32 1.0, %v80911_v29 (stack61)
        %v81705_v54 = vadd.s32 %v81701_v40, %v81689_v32 (stack40)
        %v82986_v55 = vadd.s32 %v145654_v9, %v121569_v1 (stack40)
        %v80543_v34 = vmul.f32 %v80539_v20, %v145644_v8 (stack54)
        %v81312_v46 = vadd.s32 %v81309_v22, %v81304_v46 (stack40)
        %v81318_v52 = vshll.u32 %v81309_v22, 6 (stack45)
        %v81319_v12 = vshrl.u32 %v81309_v22, 26 (stack46)
        %v80914_v25 = vand.u32 2147483647, %v80906_v21 (stack60)
        %v81707_v61 = vshll.u32 %v81701_v40, 17 (stack45)
        %v81708_v53 = vshrl.u32 %v81701_v40, 15 (stack46)
        %v82099_v43 = vxor.u32 %v82098_v6, %v82094_v42 (stack48)
        %v80547_v56 = vadd.f32 %v80543_v34, %v145610_v56 (stack53)
        %v80913_v21 = vmul.f32 %v80912_v31, %v80906_v21 (stack63)
        %v81320_v29 = vor.u32 %v81319_v12, %v81318_v52 (stack47)
        %v82550_v32 = vxor.u32 %v82549_v41, %v82545_v27 (stack48)
        %v81709_v40 = vor.u32 %v81708_v53, %v81707_v61 (stack47)
        %v82102_v42 = vadd.s32 %v82099_v43, %v82094_v42 (stack40)
        %v82108_v20 = vshll.u32 %v82099_v43, 24 (stack45)
        %v82109_v22 = vshrl.u32 %v82099_v43, 8 (stack46)
        %v80551_v6 = vmul.f32 %v80547_v56, %v145644_v8 (stack54)
        %v81321_v41 = vxor.u32 %v81320_v29, %v81312_v46 (stack48)
        %v82553_v27 = vadd.s32 %v82550_v32, %v82545_v27 (stack40)
        %v82559_v31 = vshll.u32 %v82550_v32, 6 (stack45)
        %v81316_v34 = vadd.s32 %v81312_v46, %v121564_v0 (stack40)
        %v81710_v46 = vxor.u32 %v81709_v40, %v81705_v54 (stack48)
        %v82110_v52 = vor.u32 %v82109_v22, %v82108_v20 (stack47)
        %v82560_v12 = vshrl.u32 %v82550_v32, 26 (stack46)
        %v80555_v24 = vadd.f32 %v80551_v6, %v145604_v24 (stack53)
        %vm145677_vm15 = vcmp.lt.f32.partialorder %v80914_v25, 0.0004427343 (stack62)
        %v81324_v61 = vadd.s32 %v81321_v41, %v121574_v2 (stack40)
        %v82106_v53 = vadd.s32 %v82102_v42, %v121564_v0 (stack40)
        %v82973_v43 = vadd.s32 1, %v82969_v30 (stack40)
        %v81713_v54 = vadd.s32 %v81710_v46, %v81705_v54 (stack40)
        %v81715_v56 = vshll.u32 %v81710_v46, 29 (stack45)
        %v81716_v29 = vshrl.u32 %v81710_v46, 3 (stack46)
        %v82111_v32 = vxor.u32 %v82110_v52, %v82102_v42 (stack48)
        %v80559_v40 = vmul.f32 %v80555_v24, %v145644_v8 (stack54)
        %v81328_v42 = vadd.s32 5, %v81324_v61 (stack40)
        %v82561_v20 = vor.u32 %v82560_v12, %v82559_v31 (stack47)
        %v82977_v7 = vsel /*vm=*/%vm82951_vm14, /*on_true_vy=*/%v82973_v43, /*on_false_vx=*/%v82969_v30 (stack44)
        %v81717_v9 = vor.u32 %v81716_v29, %v81715_v56 (stack47)
        %v82114_v30 = vadd.s32 %v82111_v32, %v121574_v2 (stack40)
        %v82982_v22 = vadd.s32 %v82977_v7, %v121574_v2 (stack40)
        %v82992_v6 = vshll.u32 %v82986_v55, 13 (stack45)
        %v80563_v45 = vadd.f32 %v80559_v40, %v145599_v45 (stack53)
        %v81330_v41 = vxor.u32 %v81328_v42, %v81316_v34 (stack48)
        %v82562_v31 = vxor.u32 %v82561_v20, %v82553_v27 (stack48)
        %v82993_v34 = vshrl.u32 %v82986_v55, 19 (stack46)
        %v81718_v46 = vxor.u32 %v81717_v9, %v81713_v54 (stack48)
        %v82118_v52 = vadd.s32 2, %v82114_v30 (stack40)
        %v82990_v55 = vadd.s32 %v82986_v55, %v82982_v22 (stack40)
        %v145692_v12 = vadd.s32 %v157586_v60, %v157077_v51 (stack40)
        %v121122_v24 = vpop.eup %121121 (stack64)
        %v80567_v61 = vmul.f32 %v80563_v45, %v145644_v8 (stack54)
        %v81331_v43 = vand.u32.u8 255, %v81330_v41 (stack49)
        %v82565_v56 = vadd.s32 %v82562_v31, %v121564_v0 (stack40)
        %v82994_v29 = vor.u32 %v82993_v34, %v82992_v6 (stack47)
        %v80910_v32 = vmul.f32 0.6931472, %v121122_v24 (stack65)
        %v81721_v54 = vadd.s32 %v81718_v46, %v81713_v54 (stack40)
        %v81723_v40 = vshll.u32 %v81718_v46, 16 (stack45)
        %v81724_v42 = vshrl.u32 %v81718_v46, 16 (stack46)
        %v80571_v23 = vadd.f32 %v80567_v61, %v145590_v23 (stack53)
        %v81332_v20 = vand.u32 65535, %v81331_v43 (stack50)
        %v82122_v53 = vadd.s32 %v82118_v52, %v82106_v53 (stack40)
        %v82557_v27 = vadd.s32 %v82553_v27, %v121569_v1 (stack40)
        %v80916_v21 = vsel /*vm=*/%vm145677_vm15, /*on_true_vy=*/%v80913_v21, /*on_false_vx=*/%v80910_v32 (stack66)
        %v81725_v25 = vor.u32 %v81724_v42, %v81723_v40 (stack47)
        %v82124_v7 = vshll.u32 %v82118_v52, 13 (stack45)
        %v82569_v9 = vadd.s32 1, %v82565_v56 (stack40)
        %v80575_v8 = vmul.f32 %v80571_v23, %v145644_v8 (stack54)
        %v145701_v30 = vxor.u32 2147483648, %v80916_v21 (stack56)
        %v82125_v22 = vshrl.u32 %v82118_v52, 19 (stack46)
        %v82995_v6 = vxor.u32 %v82994_v29, %v82990_v55 (stack48)
        %v80432_v45 = vand.u32 2147483647, %v145507_v44 (stack77)
        %v80464_v50 = vsel /*vm=*/%vm80459_vm10, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v81726_v41 = vxor.u32 %v81725_v25, %v81721_v54 (stack48)
        %v82573_v31 = vadd.s32 %v82569_v9, %v82557_v27 (stack40)
        %v80579_v34 = vadd.f32 %v80575_v8, %v80464_v50 (stack53)
        %121123 = vrsqrt.f32 %v145701_v30 (stack67)
        %vm80920_vm0 = vcmp.lt.f32.partialorder %v145701_v30, 5.0 (stack68)
        %v81333_v46 = vshrl.u32 %v81332_v20, 1 (stack51)
        %v81729_v52 = vadd.s32 %v81726_v41, %v81721_v54 (stack40)
        %v80440_v24 = vmul.f32 inf, %v145507_v44 (stack54)
        %v80583_v44 = vmul.f32 %v80579_v34, %v145507_v44 (stack54)
        %v82126_v61 = vor.u32 %v82125_v22, %v82124_v7 (stack47)
        %vm80435_vm1 = vcmp.eq.f32.partialorder %v80432_v45, 1.0 (stack68)
        %v80893_v43 = vand.u32 2147483647, %v145650_v26 (stack77)
        %v145713_v56 = vmul.f32 inf, %v145650_v26 (stack54)
        %v82575_v29 = vshll.u32 %v82569_v9, 17 (stack45)
        %v80587_v32 = vsel /*vm=*/%vm80435_vm1, /*on_true_vy=*/%v80440_v24, /*on_false_vx=*/%v80583_v44 (stack44)
        %v145718_v54 = vsel /*vm=*/%vm80920_vm0, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v145723_v40 = vsel /*vm=*/%vm80920_vm0, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v145726_v42 = vadd.f32 -2.5, %v145701_v30 (stack53)
        %v80591_v23 = vmul.f32 1.4140625, %v80587_v32 (stack54)
        %v81334_v20 = vor.u32 16256, %v81333_v46 (stack47)
        %v81735_v27 = vshll.u32 %v81726_v41, 24 (stack45)
        %v81736_v21 = vshrl.u32 %v81726_v41, 8 (stack46)
        %v82127_v25 = vxor.u32 %v82126_v61, %v82122_v53 (stack48)
        %v82576_v7 = vshrl.u32 %v82569_v9, 15 (stack46)
        %v82998_v55 = vadd.s32 %v82995_v6, %v82990_v55 (stack40)
        %v83000_v9 = vshll.u32 %v82995_v6, 15 (stack45)
        %v80594_v8 = vpack.c.bf16 %v157387_v11, %v80591_v23 (stack81)
        %v81335_v22 = vand.u32.u16 65535, %v81334_v20 (stack52)
        %v81737_v45 = vor.u32 %v81736_v21, %v81735_v27 (stack47)
        %v83001_v6 = vshrl.u32 %v82995_v6, 17 (stack46)
        %v82130_v53 = vadd.s32 %v82127_v25, %v82122_v53 (stack40)
        %v82132_v50 = vshll.u32 %v82127_v25, 15 (stack45)
        %v82133_v41 = vshrl.u32 %v82127_v25, 17 (stack46)
        %v82577_v34 = vor.u32 %v82576_v7, %v82575_v29 (stack47)
        %120175 = vst [vmem:[%s123356_s30 + $0x1d4] sm:$0xf] /*vst_source=*/%v80594_v8 (stack83)
        %v120178_v46 = vadd.low.f32.bf16 -1.0, %v81335_v22 (stack53)
        %v81733_v24 = vadd.s32 %v81729_v52, %v121569_v1 (stack40)
        %v81738_v52 = vxor.u32 %v81737_v45, %v81729_v52 (stack48)
        %v83002_v44 = vor.u32 %v83001_v6, %v83000_v9 (stack47)
        %v82134_v61 = vor.u32 %v82133_v41, %v82132_v50 (stack47)
        %v82578_v29 = vxor.u32 %v82577_v34, %v82573_v31 (stack48)
        %vm83417_vm2 = vcmp.lt.u32.totalorder %v145692_v12, %v157077_v51 (stack43)
        %v145735_v32 = vadd.s32 %v157591_v10, %v157078_v48 (stack40)
        %vm80965_vm3 = vcmp.eq.f32.partialorder %v145701_v30, inf (stack70)
        %v81344_v23 = vmul.f32 2.0, %v120178_v46 (stack54)
        %v81741_v20 = vadd.s32 %v81738_v52, %v121564_v0 (stack40)
        %v83003_v27 = vxor.u32 %v83002_v44, %v82998_v55 (stack48)
        %v82135_v21 = vxor.u32 %v82134_v61, %v82130_v53 (stack48)
        %v82581_v31 = vadd.s32 %v82578_v29, %v82573_v31 (stack40)
        %v82583_v25 = vshll.u32 %v82578_v29, 29 (stack45)
        %v82584_v7 = vshrl.u32 %v82578_v29, 3 (stack46)
        %v121124_v9 = vpop.eup %121123 (stack73)
        %v80968_v8 = vand.u32 2147483648, %v145701_v30 (stack72)
        %v81348_v22 = vadd.f32 -0.99609375, %v81344_v23 (stack53)
        %v81745_v45 = vadd.s32 4, %v81741_v20 (stack40)
        %v83006_v55 = vadd.s32 %v83003_v27, %v82998_v55 (stack40)
        %v80964_v6 = vmul.f32 %v121124_v9, %v145701_v30 (stack74)
        %v82138_v53 = vadd.s32 %v82135_v21, %v82130_v53 (stack40)
        %v82140_v50 = vshll.u32 %v82135_v21, 26 (stack45)
        %v82141_v41 = vshrl.u32 %v82135_v21, 6 (stack46)
        %v145741_v34 = vmax.f32 %v81348_v22, -0.99609375 (stack55)
        %v81749_v46 = vadd.s32 %v81745_v45, %v81733_v24 (stack40)
        %v81751_v24 = vshll.u32 %v81745_v45, 13 (stack45)
        %v81752_v52 = vshrl.u32 %v81745_v45, 19 (stack46)
        %v80966_v44 = vsel /*vm=*/%vm80965_vm3, /*on_true_vy=*/%v145701_v30, /*on_false_vx=*/%v80964_v6 (stack75)
        %vm80967_vm4 = vcmp.eq.f32.partialorder %v145701_v30, 0.0 (stack71)
        %v82142_v61 = vor.u32 %v82141_v41, %v82140_v50 (stack47)
        %v82585_v29 = vor.u32 %v82584_v7, %v82583_v25 (stack47)
        %v80969_v23 = vsel /*vm=*/%vm80967_vm4, /*on_true_vy=*/%v80968_v8, /*on_false_vx=*/%v80966_v44 (stack76)
        %v81364_v20 = vxor.u32 2147483648, %v145741_v34 (stack56)
        %v83008_v21 = vshll.u32 %v83003_v27, 26 (stack45)
        %v83009_v27 = vshrl.u32 %v83003_v27, 6 (stack46)
        %v80972_v25 = vadd.f32 -3.0, %v80969_v23 (stack53)
        %v81753_v7 = vor.u32 %v81752_v52, %v81751_v24 (stack47)
        %v82143_v9 = vxor.u32 %v82142_v61, %v82138_v53 (stack48)
        %v82586_v8 = vxor.u32 %v82585_v29, %v82581_v31 (stack48)
        %v80945_v22 = vsel /*vm=*/%vm80920_vm0, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v80949_v45 = vsel /*vm=*/%vm80920_vm0, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v145755_v6 = vmul.f32 %v81364_v20, %v145741_v34 (stack54)
        %v83408_v50 = vadd.s32 %v145692_v12, %v122657_v58 (stack40)
        %v80957_v41 = vsel /*vm=*/%vm80920_vm0, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v145765_v42 = vsel /*vm=*/%vm80920_vm0, /*on_true_vy=*/%v145726_v42, /*on_false_vx=*/%v80972_v25 (stack44)
        %v81754_v24 = vxor.u32 %v81753_v7, %v81749_v46 (stack48)
        %v82146_v53 = vadd.s32 %v82143_v9, %v82138_v53 (stack40)
        %v80953_v52 = vsel /*vm=*/%vm80920_vm0, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v80980_v44 = vmul.f32 %v145765_v42, %v80957_v41 (stack54)
        %v81369_v61 = vadd.f32 1.0, %v145755_v6 (stack57)
        %v83010_v29 = vor.u32 %v83009_v27, %v83008_v21 (stack47)
        %v81757_v46 = vadd.s32 %v81754_v24, %v81749_v46 (stack40)
        %v81759_v23 = vshll.u32 %v81754_v24, 15 (stack45)
        %v81760_v20 = vshrl.u32 %v81754_v24, 17 (stack46)
        %v82152_v21 = vshll.u32 %v82143_v9, 6 (stack45)
        %v80984_v27 = vadd.f32 %v80980_v44, %v80953_v52 (stack53)
        %121125 = vlog2.f32 %v81369_v61 (stack58)
        %vm83412_vm5 = vcmp.lt.u32.totalorder %v83408_v50, %v145692_v12 (stack43)
        %v83426_v25 = vadd.s32 1, %v145735_v32 (stack40)
        %v81761_v7 = vor.u32 %v81760_v20, %v81759_v23 (stack47)
        %v82153_v9 = vshrl.u32 %v82143_v9, 26 (stack46)
        %v82589_v31 = vadd.s32 %v82586_v8, %v82581_v31 (stack40)
        %v82591_v41 = vshll.u32 %v82586_v8, 16 (stack45)
        %v80988_v24 = vmul.f32 %v80984_v27, %v145765_v42 (stack54)
        %v81372_v52 = vmul.f32 -0.5, %v145755_v6 (stack59)
        %v82592_v8 = vshrl.u32 %v82586_v8, 16 (stack46)
        %v83011_v44 = vxor.u32 %v83010_v29, %v83006_v55 (stack48)
        %v81375_v61 = vand.u32 2147483647, %v145755_v6 (stack60)
        %v81762_v29 = vxor.u32 %v81761_v7, %v81757_v46 (stack48)
        %v82154_v23 = vor.u32 %v82153_v9, %v82152_v21 (stack47)
        %v83430_v32 = vsel /*vm=*/%vm83417_vm2, /*on_true_vy=*/%v83426_v25, /*on_false_vx=*/%v145735_v32 (stack44)
        %v80992_v45 = vadd.f32 %v80988_v24, %v80949_v45 (stack53)
        %v82593_v20 = vor.u32 %v82592_v8, %v82591_v41 (stack47)
        %v145781_v55 = vadd.s32 %v83011_v44, %v83006_v55 (stack40)
        %v83020_v21 = vshll.u32 %v83011_v44, 6 (stack45)
        %v81765_v46 = vadd.s32 %v81762_v29, %v81757_v46 (stack40)
        %v81767_v27 = vshll.u32 %v81762_v29, 26 (stack45)
        %v81768_v25 = vshrl.u32 %v81762_v29, 6 (stack46)
        %v82155_v7 = vxor.u32 %v82154_v23, %v82146_v53 (stack48)
        %v80996_v9 = vmul.f32 %v80992_v45, %v145765_v42 (stack54)
        %v82150_v53 = vadd.s32 %v82146_v53, %v121574_v2 (stack40)
        %v82594_v41 = vxor.u32 %v82593_v20, %v82589_v31 (stack48)
        %v83021_v24 = vshrl.u32 %v83011_v44, 26 (stack46)
        %v81373_v52 = vadd.f32 1.0, %v81372_v52 (stack61)
        %v81769_v8 = vor.u32 %v81768_v25, %v81767_v27 (stack47)
        %v82158_v44 = vadd.s32 %v82155_v7, %v121569_v1 (stack40)
        %v83434_v29 = vadd.s32 1, %v83430_v32 (stack40)
        %v81000_v22 = vadd.f32 %v80996_v9, %v80945_v22 (stack53)
        %v82597_v31 = vadd.s32 %v82594_v41, %v82589_v31 (stack40)
        %v82603_v23 = vshll.u32 %v82594_v41, 24 (stack45)
        %v82604_v45 = vshrl.u32 %v82594_v41, 8 (stack46)
        %v81770_v20 = vxor.u32 %v81769_v8, %v81765_v46 (stack48)
        %v82162_v27 = vadd.s32 3, %v82158_v44 (stack40)
        %v83022_v21 = vor.u32 %v83021_v24, %v83020_v21 (stack47)
        %v83438_v12 = vsel /*vm=*/%vm83412_vm5, /*on_true_vy=*/%v83434_v29, /*on_false_vx=*/%v83430_v32 (stack44)
        %v81004_v32 = vmul.f32 %v81000_v22, %v145765_v42 (stack54)
        %v82605_v25 = vor.u32 %v82604_v45, %v82603_v23 (stack47)
        %v83443_v7 = vadd.s32 %v83438_v12, %v121574_v2 (stack40)
        %v83447_v50 = vadd.s32 %v83408_v50, %v121569_v1 (stack40)
        %v81773_v46 = vadd.s32 %v81770_v20, %v81765_v46 (stack40)
        %v81779_v9 = vshll.u32 %v81770_v20, 6 (stack45)
        %v81780_v41 = vshrl.u32 %v81770_v20, 26 (stack46)
        %v82166_v53 = vadd.s32 %v82162_v27, %v82150_v53 (stack40)
        %v81008_v40 = vadd.f32 %v81004_v32, %v145723_v40 (stack53)
        %v82168_v24 = vshll.u32 %v82162_v27, 17 (stack45)
        %v82169_v8 = vshrl.u32 %v82162_v27, 15 (stack46)
        %v82606_v44 = vxor.u32 %v82605_v25, %v82597_v31 (stack48)
        %v121126_v29 = vpop.eup %121125 (stack64)
        %v80929_v22 = vsel /*vm=*/%vm80920_vm0, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v81781_v23 = vor.u32 %v81780_v41, %v81779_v9 (stack47)
        %v83023_v45 = vxor.u32 %v83022_v21, %v145781_v55 (stack48)
        %v145796_v20 = vadd.s32 %v83447_v50, %v83443_v7 (stack40)
        %v81012_v27 = vmul.f32 %v81008_v40, %v145765_v42 (stack54)
        %v81371_v21 = vmul.f32 0.6931472, %v121126_v29 (stack65)
        %v81374_v6 = vmul.f32 %v81373_v52, %v145755_v6 (stack63)
        %v82170_v52 = vor.u32 %v82169_v8, %v82168_v24 (stack47)
        %v80937_v12 = vsel /*vm=*/%vm80920_vm0, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %vm81376_vm6 = vcmp.lt.f32.partialorder %v81375_v61, 0.0004427343 (stack62)
        %v81782_v61 = vxor.u32 %v81781_v23, %v81773_v46 (stack48)
        %v145805_v32 = vadd.s32 %v157586_v60, %v157079_v39 (stack40)
        %v81016_v25 = vadd.f32 %v81012_v27, %v80937_v12 (stack53)
        %v81377_v7 = vsel /*vm=*/%vm81376_vm6, /*on_true_vy=*/%v81374_v6, /*on_false_vx=*/%v81371_v21 (stack66)
        %v82171_v9 = vxor.u32 %v82170_v52, %v82166_v53 (stack48)
        %v82609_v41 = vadd.s32 %v82606_v44, %v121574_v2 (stack40)
        %v145808_v40 = vxor.u32 2147483648, %v81377_v7 (stack56)
        %v83026_v24 = vadd.s32 %v83023_v45, %v121564_v0 (stack40)
        %v83453_v8 = vshll.u32 %v83447_v50, 13 (stack45)
        %v83454_v50 = vshrl.u32 %v83447_v50, 19 (stack46)
        %v81020_v44 = vmul.f32 %v81016_v25, %v145765_v42 (stack54)
        %v82174_v53 = vadd.s32 %v82171_v9, %v82166_v53 (stack40)
        %v82176_v29 = vshll.u32 %v82171_v9, 29 (stack45)
        %v82177_v23 = vshrl.u32 %v82171_v9, 3 (stack46)
        %v80933_v30 = vsel /*vm=*/%vm80920_vm0, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %vm81381_vm7 = vcmp.lt.f32.partialorder %v145808_v40, 5.0 (stack68)
        %121127 = vrsqrt.f32 %v145808_v40 (stack67)
        %v81785_v45 = vadd.s32 %v81782_v61, %v121574_v2 (stack40)
        %v81024_v27 = vadd.f32 %v81020_v44, %v80933_v30 (stack53)
        %v81354_v21 = vand.u32 2147483647, %v145741_v34 (stack77)
        %v82613_v6 = vadd.s32 2, %v82609_v41 (stack40)
        %v83018_v55 = vadd.s32 %v145781_v55, %v121569_v1 (stack40)
        %v81777_v46 = vadd.s32 %v81773_v46, %v121564_v0 (stack40)
        %v82178_v52 = vor.u32 %v82177_v23, %v82176_v29 (stack47)
        %v82601_v31 = vadd.s32 %v82597_v31, %v121564_v0 (stack40)
        %v83030_v12 = vadd.s32 1, %v83026_v24 (stack40)
        %v81028_v61 = vmul.f32 %v81024_v27, %v145765_v42 (stack54)
        %v145827_v25 = vsel /*vm=*/%vm81381_vm7, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v145830_v7 = vadd.f32 -2.5, %v145808_v40 (stack53)
        %v83455_v9 = vor.u32 %v83454_v50, %v83453_v8 (stack47)
        %vm145834_vm8 = vcmp.eq.f32.partialorder %v80893_v43, 1.0 (stack68)
        %v145841_v41 = vsel /*vm=*/%vm81381_vm7, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v145846_v24 = vsel /*vm=*/%vm81381_vm7, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v81789_v8 = vadd.s32 5, %v81785_v45 (stack40)
        %v82179_v50 = vxor.u32 %v82178_v52, %v82174_v53 (stack48)
        %v81032_v22 = vadd.f32 %v81028_v61, %v80929_v22 (stack53)
        %v82617_v44 = vadd.s32 %v82613_v6, %v82601_v31 (stack40)
        %v82619_v29 = vshll.u32 %v82613_v6, 13 (stack45)
        %v82620_v23 = vshrl.u32 %v82613_v6, 19 (stack46)
        %v81791_v30 = vxor.u32 %v81789_v8, %v81777_v46 (stack48)
        %v82182_v53 = vadd.s32 %v82179_v50, %v82174_v53 (stack40)
        %v82184_v45 = vshll.u32 %v82179_v50, 16 (stack45)
        %v82185_v27 = vshrl.u32 %v82179_v50, 16 (stack46)
        %v81036_v42 = vmul.f32 %v81032_v22, %v145765_v42 (stack54)
        %vm81426_vm9 = vcmp.eq.f32.partialorder %v145808_v40, inf (stack70)
        %v82621_v6 = vor.u32 %v82620_v23, %v82619_v29 (stack47)
        %v83034_v55 = vadd.s32 %v83030_v12, %v83018_v55 (stack40)
        %v83036_v46 = vshll.u32 %v83030_v12, 17 (stack45)
        %v81792_v52 = vand.u32.u8 255, %v81791_v30 (stack49)
        %v82186_v31 = vor.u32 %v82185_v27, %v82184_v45 (stack47)
        %v83037_v12 = vshrl.u32 %v83030_v12, 15 (stack46)
        %v83456_v61 = vxor.u32 %v83455_v9, %v145796_v20 (stack48)
        %v81040_v54 = vadd.f32 %v81036_v42, %v145718_v54 (stack53)
        %vm81428_vm10 = vcmp.eq.f32.partialorder %v145808_v40, 0.0 (stack71)
        %v82622_v9 = vxor.u32 %v82621_v6, %v82617_v44 (stack48)
        %vm83878_vm11 = vcmp.lt.u32.totalorder %v145805_v32, %v157079_v39 (stack43)
        %v81793_v8 = vand.u32 65535, %v81792_v52 (stack50)
        %v82187_v50 = vxor.u32 %v82186_v31, %v82182_v53 (stack48)
        %v83038_v22 = vor.u32 %v83037_v12, %v83036_v46 (stack47)
        %v145856_v20 = vadd.s32 %v83456_v61, %v145796_v20 (stack40)
        %v81044_v26 = vmul.f32 %v81040_v54, %v145650_v26 (stack54)
        %v82625_v44 = vadd.s32 %v82622_v9, %v82617_v44 (stack40)
        %v82627_v29 = vshll.u32 %v82622_v9, 15 (stack45)
        %v82628_v23 = vshrl.u32 %v82622_v9, 17 (stack46)
        %v81794_v30 = vshrl.u32 %v81793_v8, 1 (stack51)
        %v82190_v53 = vadd.s32 %v82187_v50, %v82182_v53 (stack40)
        %v82196_v45 = vshll.u32 %v82187_v50, 24 (stack45)
        %v82197_v27 = vshrl.u32 %v82187_v50, 8 (stack46)
        %v121128_v42 = vpop.eup %121127 (stack73)
        %v81048_v56 = vsel /*vm=*/%vm145834_vm8, /*on_true_vy=*/%v145713_v56, /*on_false_vx=*/%v81044_v26 (stack44)
        %v81429_v43 = vand.u32 2147483648, %v145808_v40 (stack72)
        %v82629_v6 = vor.u32 %v82628_v23, %v82627_v29 (stack47)
        %v83039_v46 = vxor.u32 %v83038_v22, %v83034_v55 (stack48)
        %v81052_v52 = vmul.f32 1.4140625, %v81048_v56 (stack54)
        %v81425_v31 = vmul.f32 %v121128_v42, %v145808_v40 (stack74)
        %v81795_v12 = vor.u32 16256, %v81794_v30 (stack47)
        %v83461_v54 = vshll.u32 %v83456_v61, 15 (stack45)
        %v82198_v9 = vor.u32 %v82197_v27, %v82196_v45 (stack47)
        %v82630_v8 = vxor.u32 %v82629_v6, %v82625_v44 (stack48)
        %v83042_v55 = vadd.s32 %v83039_v46, %v83034_v55 (stack40)
        %v83044_v50 = vshll.u32 %v83039_v46, 29 (stack45)
        %v81055_v22 = vpack.c.bf16 %v157387_v11, %v81052_v52 (stack81)
        %v81427_v26 = vsel /*vm=*/%vm81426_vm9, /*on_true_vy=*/%v145808_v40, /*on_false_vx=*/%v81425_v31 (stack75)
        %v81796_v29 = vand.u32.u16 65535, %v81795_v12 (stack52)
        %v83045_v23 = vshrl.u32 %v83039_v46, 3 (stack46)
        %v81430_v30 = vsel /*vm=*/%vm81428_vm10, /*on_true_vy=*/%v81429_v43, /*on_false_vx=*/%v81427_v26 (stack76)
        %v82199_v45 = vxor.u32 %v82198_v9, %v82190_v53 (stack48)
        %v82633_v44 = vadd.s32 %v82630_v8, %v82625_v44 (stack40)
        %v82635_v27 = vshll.u32 %v82630_v8, 26 (stack45)
        %120177 = vst [vmem:[%s123356_s30 + $0x254] sm:$0xf] /*vst_source=*/%v81055_v22 (stack83)
        %v81433_v42 = vadd.f32 -3.0, %v81430_v30 (stack53)
        %v120180_v56 = vadd.low.f32.bf16 -1.0, %v81796_v29 (stack53)
        %v82636_v43 = vshrl.u32 %v82630_v8, 6 (stack46)
        %v83046_v6 = vor.u32 %v83045_v23, %v83044_v50 (stack47)
        %v81418_v46 = vsel /*vm=*/%vm81381_vm7, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v82202_v52 = vadd.s32 %v82199_v45, %v121564_v0 (stack40)
        %v83462_v61 = vshrl.u32 %v83456_v61, 17 (stack46)
        %v145877_v31 = vadd.s32 %v157591_v10, %v157082_v49 (stack40)
        %v145882_v7 = vsel /*vm=*/%vm81381_vm7, /*on_true_vy=*/%v145830_v7, /*on_false_vx=*/%v81433_v42 (stack44)
        %v81805_v12 = vmul.f32 2.0, %v120180_v56 (stack54)
        %v82637_v9 = vor.u32 %v82636_v43, %v82635_v27 (stack47)
        %v83047_v8 = vxor.u32 %v83046_v6, %v83042_v55 (stack48)
        %v81441_v50 = vmul.f32 %v145882_v7, %v81418_v46 (stack54)
        %v82194_v53 = vadd.s32 %v82190_v53, %v121569_v1 (stack40)
        %v82206_v22 = vadd.s32 4, %v82202_v52 (stack40)
        %v83463_v54 = vor.u32 %v83462_v61, %v83461_v54 (stack47)
        %v81809_v26 = vadd.f32 -0.99609375, %v81805_v12 (stack53)
        %v82638_v29 = vxor.u32 %v82637_v9, %v82633_v44 (stack48)
        %v83050_v55 = vadd.s32 %v83047_v8, %v83042_v55 (stack40)
        %v83052_v23 = vshll.u32 %v83047_v8, 16 (stack45)
        %v81445_v24 = vadd.f32 %v81441_v50, %v145846_v24 (stack53)
        %v82210_v30 = vadd.s32 %v82206_v22, %v82194_v53 (stack40)
        %v82212_v45 = vshll.u32 %v82206_v22, 13 (stack45)
        %v82213_v27 = vshrl.u32 %v82206_v22, 19 (stack46)
        %v145887_v42 = vmax.f32 %v81809_v26, -0.99609375 (stack55)
        %v82641_v44 = vadd.s32 %v82638_v29, %v82633_v44 (stack40)
        %v82647_v56 = vshll.u32 %v82638_v29, 6 (stack45)
        %v82648_v43 = vshrl.u32 %v82638_v29, 26 (stack46)
        %v81449_v6 = vmul.f32 %v81445_v24, %v145882_v7 (stack54)
        %v82214_v46 = vor.u32 %v82213_v27, %v82212_v45 (stack47)
        %v83053_v52 = vshrl.u32 %v83047_v8, 16 (stack46)
        %v83464_v61 = vxor.u32 %v83463_v54, %v145856_v20 (stack48)
        %v81398_v12 = vsel /*vm=*/%vm81381_vm7, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v81410_v9 = vsel /*vm=*/%vm81381_vm7, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v81825_v8 = vxor.u32 2147483648, %v145887_v42 (stack56)
        %v81453_v50 = vadd.f32 %v81449_v6, %v81410_v9 (stack53)
        %v82215_v53 = vxor.u32 %v82214_v46, %v82210_v30 (stack48)
        %v82649_v22 = vor.u32 %v82648_v43, %v82647_v56 (stack47)
        %v83054_v54 = vor.u32 %v83053_v52, %v83052_v23 (stack47)
        %v81402_v26 = vsel /*vm=*/%vm81381_vm7, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v145902_v29 = vmul.f32 %v81825_v8, %v145887_v42 (stack54)
        %v83467_v20 = vadd.s32 %v83464_v61, %v145856_v20 (stack40)
        %v145907_v23 = vadd.s32 %v145805_v32, %v122657_v58 (stack40)
        %v81457_v24 = vmul.f32 %v81453_v50, %v145882_v7 (stack54)
        %v82218_v30 = vadd.s32 %v82215_v53, %v82210_v30 (stack40)
        %v82220_v45 = vshll.u32 %v82215_v53, 15 (stack45)
        %v82221_v27 = vshrl.u32 %v82215_v53, 17 (stack46)
        %v81406_v56 = vsel /*vm=*/%vm81381_vm7, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v81830_v43 = vadd.f32 1.0, %v145902_v29 (stack57)
        %v82650_v6 = vxor.u32 %v82649_v22, %v82641_v44 (stack48)
        %v83469_v46 = vshll.u32 %v83464_v61, 26 (stack45)
        %v81461_v52 = vadd.f32 %v81457_v24, %v81406_v56 (stack53)
        %v82222_v9 = vor.u32 %v82221_v27, %v82220_v45 (stack47)
        %v83055_v8 = vxor.u32 %v83054_v54, %v83050_v55 (stack48)
        %v83470_v61 = vshrl.u32 %v83464_v61, 6 (stack46)
        %121129 = vlog2.f32 %v81830_v43 (stack58)
        %v82645_v44 = vadd.s32 %v82641_v44, %v121574_v2 (stack40)
        %v82653_v50 = vadd.s32 %v82650_v6, %v121569_v1 (stack40)
        %v83887_v53 = vadd.s32 1, %v145877_v31 (stack40)
        %v81465_v22 = vmul.f32 %v81461_v52, %v145882_v7 (stack54)
        %v82223_v54 = vxor.u32 %v82222_v9, %v82218_v30 (stack48)
        %v83058_v55 = vadd.s32 %v83055_v8, %v83050_v55 (stack40)
        %v83064_v24 = vshll.u32 %v83055_v8, 24 (stack45)
        %vm83873_vm12 = vcmp.lt.u32.totalorder %v145907_v23, %v145805_v32 (stack43)
        %v81833_v45 = vmul.f32 -0.5, %v145902_v29 (stack59)
        %v82657_v27 = vadd.s32 3, %v82653_v50 (stack40)
        %v83065_v56 = vshrl.u32 %v83055_v8, 8 (stack46)
        %v83471_v43 = vor.u32 %v83470_v61, %v83469_v46 (stack47)
        %v81469_v26 = vadd.f32 %v81465_v22, %v81402_v26 (stack53)
        %v82226_v30 = vadd.s32 %v82223_v54, %v82218_v30 (stack40)
        %v82228_v6 = vshll.u32 %v82223_v54, 26 (stack45)
        %v82229_v46 = vshrl.u32 %v82223_v54, 6 (stack46)
        %v81836_v52 = vand.u32 2147483647, %v145902_v29 (stack60)
        %v82661_v9 = vadd.s32 %v82657_v27, %v82645_v44 (stack40)
        %v82663_v8 = vshll.u32 %v82657_v27, 17 (stack45)
        %v82664_v61 = vshrl.u32 %v82657_v27, 15 (stack46)
        %v81473_v44 = vmul.f32 %v81469_v26, %v145882_v7 (stack54)
        %v82230_v50 = vor.u32 %v82229_v46, %v82228_v6 (stack47)
        %v83066_v22 = vor.u32 %v83065_v56, %v83064_v24 (stack47)
        %v83472_v54 = vxor.u32 %v83471_v43, %v83467_v20 (stack48)
        %v81834_v24 = vadd.f32 1.0, %v81833_v45 (stack61)
        %v82665_v45 = vor.u32 %v82664_v61, %v82663_v8 (stack47)
        %v83891_v31 = vsel /*vm=*/%vm83878_vm11, /*on_true_vy=*/%v83887_v53, /*on_false_vx=*/%v145877_v31 (stack44)
        %v145929_v53 = vadd.s32 %v157586_v60, %v157083_v59 (stack40)
        %v81477_v12 = vadd.f32 %v81473_v44, %v81398_v12 (stack53)
        %v82231_v27 = vxor.u32 %v82230_v50, %v82226_v30 (stack48)
        %v83067_v56 = vxor.u32 %v83066_v22, %v83058_v55 (stack48)
        %v83475_v20 = vadd.s32 %v83472_v54, %v83467_v20 (stack40)
        %v82666_v43 = vxor.u32 %v82665_v45, %v82661_v9 (stack48)
        %v83481_v26 = vshll.u32 %v83472_v54, 6 (stack45)
        %v83482_v6 = vshrl.u32 %v83472_v54, 26 (stack46)
        %v83895_v46 = vadd.s32 1, %v83891_v31 (stack40)
        %v81481_v8 = vmul.f32 %v81477_v12, %v145882_v7 (stack54)
        %v82234_v30 = vadd.s32 %v82231_v27, %v82226_v30 (stack40)
        %v82240_v61 = vshll.u32 %v82231_v27, 6 (stack45)
        %v82241_v44 = vshrl.u32 %v82231_v27, 26 (stack46)
        %v82669_v9 = vadd.s32 %v82666_v43, %v82661_v9 (stack40)
        %v82671_v50 = vshll.u32 %v82666_v43, 29 (stack45)
        %v82672_v22 = vshrl.u32 %v82666_v43, 3 (stack46)
        %v83070_v54 = vadd.s32 %v83067_v56, %v121574_v2 (stack40)
        %v81485_v41 = vadd.f32 %v81481_v8, %v145841_v41 (stack53)
        %vm145934_vm13 = vcmp.lt.f32.partialorder %v81836_v52, 0.0004427343 (stack62)
        %v82242_v45 = vor.u32 %v82241_v44, %v82240_v61 (stack47)
        %v83062_v55 = vadd.s32 %v83058_v55, %v121564_v0 (stack40)
        %v82673_v12 = vor.u32 %v82672_v22, %v82671_v50 (stack47)
        %v83074_v27 = vadd.s32 2, %v83070_v54 (stack40)
        %v83483_v56 = vor.u32 %v83482_v6, %v83481_v26 (stack47)
        %v83899_v32 = vsel /*vm=*/%vm83873_vm12, /*on_true_vy=*/%v83895_v46, /*on_false_vx=*/%v83891_v31 (stack44)
        %v121130_v31 = vpop.eup %121129 (stack64)
        %v81489_v43 = vmul.f32 %v81485_v41, %v145882_v7 (stack54)
        %v81835_v29 = vmul.f32 %v81834_v24, %v145902_v29 (stack63)
        %v82243_v24 = vxor.u32 %v82242_v45, %v82234_v30 (stack48)
        %v83908_v23 = vadd.s32 %v145907_v23, %v121569_v1 (stack40)
        %v81832_v26 = vmul.f32 0.6931472, %v121130_v31 (stack65)
        %v82674_v6 = vxor.u32 %v82673_v12, %v82669_v9 (stack48)
        %v83078_v46 = vadd.s32 %v83074_v27, %v83062_v55 (stack40)
        %v83904_v8 = vadd.s32 %v83899_v32, %v121574_v2 (stack40)
        %v81493_v25 = vadd.f32 %v81489_v43, %v145827_v25 (stack53)
        %v82246_v61 = vadd.s32 %v82243_v24, %v121574_v2 (stack40)
        %v83080_v44 = vshll.u32 %v83074_v27, 13 (stack45)
        %v83484_v50 = vxor.u32 %v83483_v56, %v83475_v20 (stack48)
        %v81838_v22 = vsel /*vm=*/%vm145934_vm13, /*on_true_vy=*/%v81835_v29, /*on_false_vx=*/%v81832_v26 (stack66)
        %v82677_v9 = vadd.s32 %v82674_v6, %v82669_v9 (stack40)
        %v82679_v54 = vshll.u32 %v82674_v6, 16 (stack45)
        %v82680_v41 = vshrl.u32 %v82674_v6, 16 (stack46)
        %v81497_v7 = vmul.f32 %v81493_v25, %v145882_v7 (stack54)
        %v145952_v52 = vxor.u32 2147483648, %v81838_v22 (stack56)
        %v82250_v45 = vadd.s32 5, %v82246_v61 (stack40)
        %v83081_v55 = vshrl.u32 %v83074_v27, 19 (stack46)
        %v81386_v40 = vsel /*vm=*/%vm81381_vm7, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v82238_v30 = vadd.s32 %v82234_v30, %v121564_v0 (stack40)
        %v82681_v12 = vor.u32 %v82680_v41, %v82679_v54 (stack47)
        %v83912_v27 = vadd.s32 %v83908_v23, %v83904_v8 (stack40)
        %v81362_v56 = vmul.f32 inf, %v145741_v34 (stack54)
        %v81501_v32 = vadd.f32 %v81497_v7, %v81386_v40 (stack53)
        %vm81842_vm14 = vcmp.lt.f32.partialorder %v145952_v52, 5.0 (stack68)
        %121131 = vrsqrt.f32 %v145952_v52 (stack67)
        %vm145963_vm15 = vcmp.eq.f32.partialorder %v81354_v21, 1.0 (stack68)
        %v81815_v31 = vand.u32 2147483647, %v145887_v42 (stack77)
        %v82252_v43 = vxor.u32 %v82250_v45, %v82238_v30 (stack48)
        %v83914_v29 = vshll.u32 %v83908_v23, 13 (stack45)
        %v81505_v34 = vmul.f32 %v81501_v32, %v145741_v34 (stack54)
        %v83082_v24 = vor.u32 %v83081_v55, %v83080_v44 (stack47)
        %v83487_v26 = vadd.s32 %v83484_v50, %v121564_v0 (stack40)
        %v83915_v23 = vshrl.u32 %v83908_v23, 19 (stack46)
        %v145973_v6 = vsel /*vm=*/%vm81842_vm14, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v145976_v8 = vadd.f32 -2.5, %v145952_v52 (stack53)
        %v82682_v25 = vxor.u32 %v82681_v12, %v82677_v9 (stack48)
        %v83479_v20 = vadd.s32 %v83475_v20, %v121569_v1 (stack40)
        %v81509_v61 = vsel /*vm=*/%vm145963_vm15, /*on_true_vy=*/%v81362_v56, /*on_false_vx=*/%v81505_v34 (stack44)
        %v145984_v44 = vsel /*vm=*/%vm81842_vm14, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v145989_v50 = vsel /*vm=*/%vm81842_vm14, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v145994_v22 = vsel /*vm=*/%vm81842_vm14, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v81513_v54 = vmul.f32 1.4140625, %v81509_v61 (stack54)
        %v82253_v41 = vand.u32.u8 255, %v82252_v43 (stack49)
        %v82685_v9 = vadd.s32 %v82682_v25, %v82677_v9 (stack40)
        %v82691_v7 = vshll.u32 %v82682_v25, 24 (stack45)
        %v82692_v45 = vshrl.u32 %v82682_v25, 8 (stack46)
        %v83083_v55 = vxor.u32 %v83082_v24, %v83078_v46 (stack48)
        %v83491_v40 = vadd.s32 1, %v83487_v26 (stack40)
        %v83916_v30 = vor.u32 %v83915_v23, %v83914_v29 (stack47)
        %v81516_v12 = vpack.c.bf16 %v157387_v11, %v81513_v54 (stack81)
        %vm81887_vm0 = vcmp.eq.f32.partialorder %v145952_v52, inf (stack70)
        %v81890_v56 = vand.u32 2147483648, %v145952_v52 (stack72)
        %v82254_v32 = vand.u32 65535, %v82253_v41 (stack50)
        %vm81889_vm1 = vcmp.eq.f32.partialorder %v145952_v52, 0.0 (stack71)
        %v82693_v21 = vor.u32 %v82692_v45, %v82691_v7 (stack47)
        %v83086_v46 = vadd.s32 %v83083_v55, %v83078_v46 (stack40)
        %v83088_v43 = vshll.u32 %v83083_v55, 15 (stack45)
        %v83089_v29 = vshrl.u32 %v83083_v55, 17 (stack46)
        %120179 = vst [vmem:[%s123356_s30 + $0x2d4] sm:$0xf] /*vst_source=*/%v81516_v12 (stack83)
        %v82255_v34 = vshrl.u32 %v82254_v32, 1 (stack51)
        %v83495_v24 = vadd.s32 %v83491_v40, %v83479_v20 (stack40)
        %v83497_v26 = vshll.u32 %v83491_v40, 17 (stack45)
        %v83498_v23 = vshrl.u32 %v83491_v40, 15 (stack46)
        %v82689_v25 = vadd.s32 %v82685_v9, %v121569_v1 (stack40)
        %v82694_v20 = vxor.u32 %v82693_v21, %v82685_v9 (stack48)
        %v83090_v61 = vor.u32 %v83089_v29, %v83088_v43 (stack47)
        %v83917_v54 = vxor.u32 %v83916_v30, %v83912_v27 (stack48)
        %v82256_v41 = vor.u32 16256, %v82255_v34 (stack47)
        %v83499_v9 = vor.u32 %v83498_v23, %v83497_v26 (stack47)
        %vm84339_vm2 = vcmp.lt.u32.totalorder %v145929_v53, %v157083_v59 (stack43)
        %v84344_v7 = vadd.s32 %v157591_v10, %v157084_v16 (stack40)
        %v82697_v45 = vadd.s32 %v82694_v20, %v121564_v0 (stack40)
        %v83091_v55 = vxor.u32 %v83090_v61, %v83086_v46 (stack48)
        %v83920_v27 = vadd.s32 %v83917_v54, %v83912_v27 (stack40)
        %v83922_v40 = vshll.u32 %v83917_v54, 15 (stack45)
        %v121132_v30 = vpop.eup %121131 (stack73)
        %v82257_v12 = vand.u32.u16 65535, %v82256_v41 (stack52)
        %v83500_v32 = vxor.u32 %v83499_v9, %v83495_v24 (stack48)
        %v83923_v21 = vshrl.u32 %v83917_v54, 17 (stack46)
        %v84348_v43 = vadd.s32 1, %v84344_v7 (stack40)
        %v81886_v29 = vmul.f32 %v121132_v30, %v145952_v52 (stack74)
        %v82701_v34 = vadd.s32 4, %v82697_v45 (stack40)
        %v83094_v46 = vadd.s32 %v83091_v55, %v83086_v46 (stack40)
        %v83096_v26 = vshll.u32 %v83091_v55, 26 (stack45)
        %v120182_v23 = vadd.low.f32.bf16 -1.0, %v82257_v12 (stack53)
        %v83097_v20 = vshrl.u32 %v83091_v55, 6 (stack46)
        %v83503_v24 = vadd.s32 %v83500_v32, %v83495_v24 (stack40)
        %v83505_v61 = vshll.u32 %v83500_v32, 29 (stack45)
        %v81888_v54 = vsel /*vm=*/%vm81887_vm0, /*on_true_vy=*/%v145952_v52, /*on_false_vx=*/%v81886_v29 (stack75)
        %v82705_v25 = vadd.s32 %v82701_v34, %v82689_v25 (stack40)
        %v82707_v41 = vshll.u32 %v82701_v34, 13 (stack45)
        %v82708_v9 = vshrl.u32 %v82701_v34, 19 (stack46)
        %v81891_v56 = vsel /*vm=*/%vm81889_vm1, /*on_true_vy=*/%v81890_v56, /*on_false_vx=*/%v81888_v54 (stack76)
        %v82266_v45 = vmul.f32 2.0, %v120182_v23 (stack54)
        %v83098_v55 = vor.u32 %v83097_v20, %v83096_v26 (stack47)
        %v83506_v30 = vshrl.u32 %v83500_v32, 3 (stack46)
        %v81894_v12 = vadd.f32 -3.0, %v81891_v56 (stack53)
        %v82709_v32 = vor.u32 %v82708_v9, %v82707_v41 (stack47)
        %v83924_v40 = vor.u32 %v83923_v21, %v83922_v40 (stack47)
        %v84352_v7 = vsel /*vm=*/%vm84339_vm2, /*on_true_vy=*/%v84348_v43, /*on_false_vx=*/%v84344_v7 (stack44)
        %v81879_v21 = vsel /*vm=*/%vm81842_vm14, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v82270_v43 = vadd.f32 -0.99609375, %v82266_v45 (stack53)
        %v83099_v29 = vxor.u32 %v83098_v55, %v83094_v46 (stack48)
        %v84330_v34 = vadd.s32 %v145929_v53, %v122657_v58 (stack40)
        %v146024_v8 = vsel /*vm=*/%vm81842_vm14, /*on_true_vy=*/%v145976_v8, /*on_false_vx=*/%v81894_v12 (stack44)
        %v82710_v26 = vxor.u32 %v82709_v32, %v82705_v25 (stack48)
        %v83507_v23 = vor.u32 %v83506_v30, %v83505_v61 (stack47)
        %v83925_v20 = vxor.u32 %v83924_v40, %v83920_v27 (stack48)
        %v81902_v61 = vmul.f32 %v146024_v8, %v81879_v21 (stack54)
        %v146027_v54 = vmax.f32 %v82270_v43, -0.99609375 (stack55)
        %v83102_v46 = vadd.s32 %v83099_v29, %v83094_v46 (stack40)
        %v83108_v41 = vshll.u32 %v83099_v29, 6 (stack45)
        %v82713_v25 = vadd.s32 %v82710_v26, %v82705_v25 (stack40)
        %v82715_v9 = vshll.u32 %v82710_v26, 15 (stack45)
        %v82716_v56 = vshrl.u32 %v82710_v26, 17 (stack46)
        %v83109_v45 = vshrl.u32 %v83099_v29, 26 (stack46)
        %v81867_v55 = vsel /*vm=*/%vm81842_vm14, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v81871_v30 = vsel /*vm=*/%vm81842_vm14, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v81906_v22 = vadd.f32 %v81902_v61, %v145994_v22 (stack53)
        %v82286_v12 = vxor.u32 2147483648, %v146027_v54 (stack56)
        %v82717_v32 = vor.u32 %v82716_v56, %v82715_v9 (stack47)
        %v83110_v40 = vor.u32 %v83109_v45, %v83108_v41 (stack47)
        %v83508_v21 = vxor.u32 %v83507_v23, %v83503_v24 (stack48)
        %vm84334_vm3 = vcmp.lt.u32.totalorder %v84330_v34, %v145929_v53 (stack43)
        %v81910_v43 = vmul.f32 %v81906_v22, %v146024_v8 (stack54)
        %v82289_v29 = vmul.f32 %v82286_v12, %v146027_v54 (stack54)
        %v83928_v27 = vadd.s32 %v83925_v20, %v83920_v27 (stack40)
        %v84356_v26 = vadd.s32 1, %v84352_v7 (stack40)
        %v82718_v23 = vxor.u32 %v82717_v32, %v82713_v25 (stack48)
        %v83111_v61 = vxor.u32 %v83110_v40, %v83102_v46 (stack48)
        %v83511_v24 = vadd.s32 %v83508_v21, %v83503_v24 (stack40)
        %v146041_v41 = vadd.s32 %v84330_v34, %v121569_v1 (stack40)
        %v81914_v9 = vadd.f32 %v81910_v43, %v81871_v30 (stack53)
        %v82291_v56 = vadd.f32 1.0, %v82289_v29 (stack57)
        %v82294_v45 = vmul.f32 -0.5, %v82289_v29 (stack59)
        %v83106_v46 = vadd.s32 %v83102_v46, %v121574_v2 (stack40)
        %v82721_v25 = vadd.s32 %v82718_v23, %v82713_v25 (stack40)
        %v82723_v30 = vshll.u32 %v82718_v23, 26 (stack45)
        %v82724_v22 = vshrl.u32 %v82718_v23, 6 (stack46)
        %v83114_v12 = vadd.s32 %v83111_v61, %v121569_v1 (stack40)
        %v81918_v32 = vmul.f32 %v81914_v9, %v146024_v8 (stack54)
        %121133 = vlog2.f32 %v82291_v56 (stack58)
        %v82297_v40 = vand.u32 2147483647, %v82289_v29 (stack60)
        %v83513_v43 = vshll.u32 %v83508_v21, 16 (stack45)
        %v82725_v23 = vor.u32 %v82724_v22, %v82723_v30 (stack47)
        %v83118_v61 = vadd.s32 3, %v83114_v12 (stack40)
        %v83514_v21 = vshrl.u32 %v83508_v21, 16 (stack46)
        %v83930_v9 = vshll.u32 %v83925_v20, 26 (stack45)
        %v81922_v55 = vadd.f32 %v81918_v32, %v81867_v55 (stack53)
        %v82295_v56 = vadd.f32 1.0, %v82294_v45 (stack61)
        %v83931_v20 = vshrl.u32 %v83925_v20, 6 (stack46)
        %v84360_v53 = vsel /*vm=*/%vm84334_vm3, /*on_true_vy=*/%v84356_v26, /*on_false_vx=*/%v84352_v7 (stack44)
        %v82726_v7 = vxor.u32 %v82725_v23, %v82721_v25 (stack48)
        %v83122_v34 = vadd.s32 %v83118_v61, %v83106_v46 (stack40)
        %v83124_v26 = vshll.u32 %v83118_v61, 17 (stack45)
        %v83125_v45 = vshrl.u32 %v83118_v61, 15 (stack46)
        %v81926_v46 = vmul.f32 %v81922_v55, %v146024_v8 (stack54)
        %v83515_v30 = vor.u32 %v83514_v21, %v83513_v43 (stack47)
        %v83932_v22 = vor.u32 %v83931_v20, %v83930_v9 (stack47)
        %v84365_v12 = vadd.s32 %v84360_v53, %v121574_v2 (stack40)
        %v82729_v25 = vadd.s32 %v82726_v7, %v82721_v25 (stack40)
        %v82735_v32 = vshll.u32 %v82726_v7, 6 (stack45)
        %v82736_v43 = vshrl.u32 %v82726_v7, 26 (stack46)
        %v83126_v23 = vor.u32 %v83125_v45, %v83124_v26 (stack47)
        %v81930_v50 = vadd.f32 %v81926_v46, %v145989_v50 (stack53)
        %v83516_v61 = vxor.u32 %v83515_v30, %v83511_v24 (stack48)
        %v83933_v21 = vxor.u32 %v83932_v22, %v83928_v27 (stack48)
        %v146052_v9 = vadd.s32 %v146041_v41, %v84365_v12 (stack40)
        %v82296_v29 = vmul.f32 %v82295_v56, %v82289_v29 (stack63)
        %vm146054_vm4 = vcmp.lt.f32.partialorder %v82297_v40, 0.0004427343 (stack62)
        %v82733_v55 = vadd.s32 %v82729_v25, %v121564_v0 (stack40)
        %v82737_v56 = vor.u32 %v82736_v43, %v82735_v32 (stack47)
        %v83127_v20 = vxor.u32 %v83126_v23, %v83122_v34 (stack48)
        %v81934_v53 = vmul.f32 %v81930_v50, %v146024_v8 (stack54)
        %v83519_v24 = vadd.s32 %v83516_v61, %v83511_v24 (stack40)
        %v83525_v7 = vshll.u32 %v83516_v61, 24 (stack45)
        %v83526_v26 = vshrl.u32 %v83516_v61, 8 (stack46)
        %v82738_v45 = vxor.u32 %v82737_v56, %v82729_v25 (stack48)
        %v83130_v34 = vadd.s32 %v83127_v20, %v83122_v34 (stack40)
        %v83132_v46 = vshll.u32 %v83127_v20, 29 (stack45)
        %v83133_v30 = vshrl.u32 %v83127_v20, 3 (stack46)
        %v81938_v44 = vadd.f32 %v81934_v53, %v145984_v44 (stack53)
        %v83527_v22 = vor.u32 %v83526_v26, %v83525_v7 (stack47)
        %v83936_v27 = vadd.s32 %v83933_v21, %v83928_v27 (stack40)
        %v84375_v12 = vshll.u32 %v146041_v41, 13 (stack45)
        %v82741_v25 = vadd.s32 %v82738_v45, %v121574_v2 (stack40)
        %v83134_v32 = vor.u32 %v83133_v30, %v83132_v46 (stack47)
        %v83942_v43 = vshll.u32 %v83933_v21, 6 (stack45)
        %v83943_v23 = vshrl.u32 %v83933_v21, 26 (stack46)
        %v81942_v50 = vmul.f32 %v81938_v44, %v146024_v8 (stack54)
        %v83523_v61 = vadd.s32 %v83519_v24, %v121564_v0 (stack40)
        %v83528_v21 = vxor.u32 %v83527_v22, %v83519_v24 (stack48)
        %v84376_v41 = vshrl.u32 %v146041_v41, 19 (stack46)
        %v121134_v56 = vpop.eup %121133 (stack64)
        %v82745_v20 = vadd.s32 5, %v82741_v25 (stack40)
        %v83135_v53 = vxor.u32 %v83134_v32, %v83130_v34 (stack48)
        %v83944_v24 = vor.u32 %v83943_v23, %v83942_v43 (stack47)
        %v146068_v7 = vadd.s32 %v157586_v60, %v157089_v17 (stack40)
        %v81946_v6 = vadd.f32 %v81942_v50, %v145973_v6 (stack53)
        %v82293_v26 = vmul.f32 0.6931472, %v121134_v56 (stack65)
        %v83531_v45 = vadd.s32 %v83528_v21, %v121574_v2 (stack40)
        %v84377_v46 = vor.u32 %v84376_v41, %v84375_v12 (stack47)
        %v82747_v55 = vxor.u32 %v82745_v20, %v82733_v55 (stack48)
        %v83138_v34 = vadd.s32 %v83135_v53, %v83130_v34 (stack40)
        %v83140_v30 = vshll.u32 %v83135_v53, 16 (stack45)
        %v83141_v44 = vshrl.u32 %v83135_v53, 16 (stack46)
        %v81950_v22 = vmul.f32 %v81946_v6, %v146024_v8 (stack54)
        %v82299_v29 = vsel /*vm=*/%vm146054_vm4, /*on_true_vy=*/%v82296_v29, /*on_false_vx=*/%v82293_v26 (stack66)
        %v83535_v40 = vadd.s32 2, %v83531_v45 (stack40)
        %v83945_v12 = vxor.u32 %v83944_v24, %v83936_v27 (stack48)
        %v81851_v25 = vsel /*vm=*/%vm81842_vm14, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v146078_v32 = vxor.u32 2147483648, %v82299_v29 (stack56)
        %v83142_v43 = vor.u32 %v83141_v44, %v83140_v30 (stack47)
        %v84378_v23 = vxor.u32 %v84377_v46, %v146052_v9 (stack48)
        %v81954_v50 = vadd.f32 %v81950_v22, %v81851_v25 (stack53)
        %v83539_v61 = vadd.s32 %v83535_v40, %v83523_v61 (stack40)
        %121135 = vrsqrt.f32 %v146078_v32 (stack67)
        %v82748_v21 = vand.u32.u8 255, %v82747_v55 (stack49)
        %v81958_v8 = vmul.f32 %v81954_v50, %v146024_v8 (stack54)
        %vm82303_vm5 = vcmp.lt.f32.partialorder %v146078_v32, 5.0 (stack68)
        %v83541_v41 = vshll.u32 %v83535_v40, 13 (stack45)
        %v83542_v56 = vshrl.u32 %v83535_v40, 19 (stack46)
        %vm146086_vm6 = vcmp.eq.f32.partialorder %v81815_v31, 1.0 (stack68)
        %v81823_v20 = vmul.f32 inf, %v145887_v42 (stack54)
        %v81847_v52 = vsel /*vm=*/%vm81842_vm14, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v83143_v53 = vxor.u32 %v83142_v43, %v83138_v34 (stack48)
        %v81962_v24 = vadd.f32 %v81958_v8, %v81847_v52 (stack53)
        %v82276_v6 = vand.u32 2147483647, %v146027_v54 (stack77)
        %v146096_v26 = vadd.f32 -2.5, %v146078_v32 (stack53)
        %v83940_v27 = vadd.s32 %v83936_v27, %v121569_v1 (stack40)
        %v146102_v45 = vsel /*vm=*/%vm82303_vm5, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v146107_v46 = vsel /*vm=*/%vm82303_vm5, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v82749_v55 = vand.u32 65535, %v82748_v21 (stack50)
        %v83146_v34 = vadd.s32 %v83143_v53, %v83138_v34 (stack40)
        %v81966_v42 = vmul.f32 %v81962_v24, %v145887_v42 (stack54)
        %v83152_v30 = vshll.u32 %v83143_v53, 24 (stack45)
        %v83153_v44 = vshrl.u32 %v83143_v53, 8 (stack46)
        %v83543_v22 = vor.u32 %v83542_v56, %v83541_v41 (stack47)
        %v146113_v29 = vsel /*vm=*/%vm82303_vm5, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v82750_v40 = vshrl.u32 %v82749_v55, 1 (stack51)
        %v83948_v12 = vadd.s32 %v83945_v12, %v121564_v0 (stack40)
        %v84381_v9 = vadd.s32 %v84378_v23, %v146052_v9 (stack40)
        %v81970_v25 = vsel /*vm=*/%vm146086_vm6, /*on_true_vy=*/%v81823_v20, /*on_false_vx=*/%v81966_v42 (stack44)
        %vm82348_vm7 = vcmp.eq.f32.partialorder %v146078_v32, inf (stack70)
        %v83154_v43 = vor.u32 %v83153_v44, %v83152_v30 (stack47)
        %v83544_v50 = vxor.u32 %v83543_v22, %v83539_v61 (stack48)
        %v84383_v21 = vshll.u32 %v84378_v23, 15 (stack45)
        %v81974_v8 = vmul.f32 1.4140625, %v81970_v25 (stack54)
        %v82751_v41 = vor.u32 16256, %v82750_v40 (stack47)
        %v83952_v56 = vadd.s32 1, %v83948_v12 (stack40)
        %v84384_v23 = vshrl.u32 %v84378_v23, 17 (stack46)
        %v83155_v31 = vxor.u32 %v83154_v43, %v83146_v34 (stack48)
        %v83547_v61 = vadd.s32 %v83544_v50, %v83539_v61 (stack40)
        %v83549_v20 = vshll.u32 %v83544_v50, 15 (stack45)
        %v83550_v52 = vshrl.u32 %v83544_v50, 17 (stack46)
        %v81977_v53 = vpack.c.bf16 %v157387_v11, %v81974_v8 (stack81)
        %v82752_v24 = vand.u32.u16 65535, %v82751_v41 (stack52)
        %v83956_v27 = vadd.s32 %v83952_v56, %v83940_v27 (stack40)
        %v83958_v55 = vshll.u32 %v83952_v56, 17 (stack45)
        %v83158_v42 = vadd.s32 %v83155_v31, %v121564_v0 (stack40)
        %v83551_v30 = vor.u32 %v83550_v52, %v83549_v20 (stack47)
        %v83959_v44 = vshrl.u32 %v83952_v56, 15 (stack46)
        %v84385_v22 = vor.u32 %v84384_v23, %v84383_v21 (stack47)
        %120181 = vst [vmem:[%s123356_s30 + $0x354] sm:$0xf] /*vst_source=*/%v81977_v53 (stack83)
        %v120188_v40 = vadd.low.f32.bf16 -1.0, %v82752_v24 (stack53)
        %v83150_v34 = vadd.s32 %v83146_v34, %v121569_v1 (stack40)
        %vm84800_vm8 = vcmp.lt.u32.totalorder %v146068_v7, %v157089_v17 (stack43)
        %v84805_v12 = vadd.s32 %v157591_v10, %v157090_v62 (stack40)
        %v121136_v25 = vpop.eup %121135 (stack73)
        %v83162_v43 = vadd.s32 4, %v83158_v42 (stack40)
        %v83552_v50 = vxor.u32 %v83551_v30, %v83547_v61 (stack48)
        %v83960_v21 = vor.u32 %v83959_v44, %v83958_v55 (stack47)
        %v84386_v8 = vxor.u32 %v84385_v22, %v84381_v9 (stack48)
        %v82347_v41 = vmul.f32 %v121136_v25, %v146078_v32 (stack74)
        %vm82350_vm9 = vcmp.eq.f32.partialorder %v146078_v32, 0.0 (stack71)
        %v82351_v56 = vand.u32 2147483648, %v146078_v32 (stack72)
        %v82761_v23 = vmul.f32 2.0, %v120188_v40 (stack54)
        %v83166_v31 = vadd.s32 %v83162_v43, %v83150_v34 (stack40)
        %v83168_v20 = vshll.u32 %v83162_v43, 13 (stack45)
        %v83169_v52 = vshrl.u32 %v83162_v43, 19 (stack46)
        %v83555_v61 = vadd.s32 %v83552_v50, %v83547_v61 (stack40)
        %v82349_v53 = vsel /*vm=*/%vm82348_vm7, /*on_true_vy=*/%v146078_v32, /*on_false_vx=*/%v82347_v41 (stack75)
        %v82765_v24 = vadd.f32 -0.99609375, %v82761_v23 (stack53)
        %v83557_v55 = vshll.u32 %v83552_v50, 26 (stack45)
        %v83558_v42 = vshrl.u32 %v83552_v50, 6 (stack46)
        %v82352_v30 = vsel /*vm=*/%vm82350_vm9, /*on_true_vy=*/%v82351_v56, /*on_false_vx=*/%v82349_v53 (stack76)
        %v83170_v44 = vor.u32 %v83169_v52, %v83168_v20 (stack47)
        %v83961_v22 = vxor.u32 %v83960_v21, %v83956_v27 (stack48)
        %v146134_v9 = vadd.s32 %v84386_v8, %v84381_v9 (stack40)
        %v82336_v40 = vsel /*vm=*/%vm82303_vm5, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v82355_v34 = vadd.f32 -3.0, %v82352_v30 (stack53)
        %v146139_v25 = vmax.f32 %v82765_v24, -0.99609375 (stack55)
        %v83559_v43 = vor.u32 %v83558_v42, %v83557_v55 (stack47)
        %v83171_v50 = vxor.u32 %v83170_v44, %v83166_v31 (stack48)
        %v83964_v27 = vadd.s32 %v83961_v22, %v83956_v27 (stack40)
        %v83966_v21 = vshll.u32 %v83961_v22, 29 (stack45)
        %v83967_v41 = vshrl.u32 %v83961_v22, 3 (stack46)
        %v82340_v56 = vsel /*vm=*/%vm82303_vm5, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v146147_v26 = vsel /*vm=*/%vm82303_vm5, /*on_true_vy=*/%v146096_v26, /*on_false_vx=*/%v82355_v34 (stack44)
        %v82781_v23 = vxor.u32 2147483648, %v146139_v25 (stack56)
        %v84809_v20 = vadd.s32 1, %v84805_v12 (stack40)
        %v82363_v52 = vmul.f32 %v146147_v26, %v82340_v56 (stack54)
        %v83174_v31 = vadd.s32 %v83171_v50, %v83166_v31 (stack40)
        %v83176_v53 = vshll.u32 %v83171_v50, 15 (stack45)
        %v83177_v24 = vshrl.u32 %v83171_v50, 17 (stack46)
        %v146152_v55 = vmul.f32 %v82781_v23, %v146139_v25 (stack54)
        %v83560_v42 = vxor.u32 %v83559_v43, %v83555_v61 (stack48)
        %v84391_v30 = vshll.u32 %v84386_v8, 26 (stack45)
        %v84791_v44 = vadd.s32 %v146068_v7, %v122657_v58 (stack40)
        %v82367_v22 = vadd.f32 %v82363_v52, %v82336_v40 (stack53)
        %v83178_v40 = vor.u32 %v83177_v24, %v83176_v53 (stack47)
        %v83968_v34 = vor.u32 %v83967_v41, %v83966_v21 (stack47)
        %v84813_v12 = vsel /*vm=*/%vm84800_vm8, /*on_true_vy=*/%v84809_v20, /*on_false_vx=*/%v84805_v12 (stack44)
        %v82786_v43 = vadd.f32 1.0, %v146152_v55 (stack57)
        %v82789_v50 = vmul.f32 -0.5, %v146152_v55 (stack59)
        %v83563_v61 = vadd.s32 %v83560_v42, %v83555_v61 (stack40)
        %v84392_v8 = vshrl.u32 %v84386_v8, 6 (stack46)
        %v82371_v21 = vmul.f32 %v82367_v22, %v146147_v26 (stack54)
        %v83179_v41 = vxor.u32 %v83178_v40, %v83174_v31 (stack48)
        %v83569_v56 = vshll.u32 %v83560_v42, 6 (stack45)
        %v83570_v23 = vshrl.u32 %v83560_v42, 26 (stack46)
        %v82328_v20 = vsel /*vm=*/%vm82303_vm5, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v82332_v52 = vsel /*vm=*/%vm82303_vm5, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %121137 = vlog2.f32 %v82786_v43 (stack58)
        %vm84795_vm10 = vcmp.lt.u32.totalorder %v84791_v44, %v146068_v7 (stack43)
        %v82375_v53 = vadd.f32 %v82371_v21, %v82332_v52 (stack53)
        %v83182_v31 = vadd.s32 %v83179_v41, %v83174_v31 (stack40)
        %v83184_v24 = vshll.u32 %v83179_v41, 26 (stack45)
        %v83185_v42 = vshrl.u32 %v83179_v41, 6 (stack46)
        %v82792_v22 = vand.u32 2147483647, %v146152_v55 (stack60)
        %v83571_v40 = vor.u32 %v83570_v23, %v83569_v56 (stack47)
        %v83969_v34 = vxor.u32 %v83968_v34, %v83964_v27 (stack48)
        %v84393_v30 = vor.u32 %v84392_v8, %v84391_v30 (stack47)
        %v82379_v43 = vmul.f32 %v82375_v53, %v146147_v26 (stack54)
        %v82790_v50 = vadd.f32 1.0, %v82789_v50 (stack61)
        %v83186_v8 = vor.u32 %v83185_v42, %v83184_v24 (stack47)
        %v84817_v21 = vadd.s32 1, %v84813_v12 (stack40)
        %v83572_v41 = vxor.u32 %v83571_v40, %v83563_v61 (stack48)
        %v83972_v27 = vadd.s32 %v83969_v34, %v83964_v27 (stack40)
        %v83974_v56 = vshll.u32 %v83969_v34, 16 (stack45)
        %v83975_v23 = vshrl.u32 %v83969_v34, 16 (stack46)
        %v82383_v20 = vadd.f32 %v82379_v43, %v82328_v20 (stack53)
        %v83187_v52 = vxor.u32 %v83186_v8, %v83182_v31 (stack48)
        %v84394_v53 = vxor.u32 %v84393_v30, %v146134_v9 (stack48)
        %v84821_v7 = vsel /*vm=*/%vm84795_vm10, /*on_true_vy=*/%v84817_v21, /*on_false_vx=*/%v84813_v12 (stack44)
        %v83567_v12 = vadd.s32 %v83563_v61, %v121574_v2 (stack40)
        %v83575_v61 = vadd.s32 %v83572_v41, %v121569_v1 (stack40)
        %v83976_v24 = vor.u32 %v83975_v23, %v83974_v56 (stack47)
        %v84830_v44 = vadd.s32 %v84791_v44, %v121569_v1 (stack40)
        %v82387_v42 = vmul.f32 %v82383_v20, %v146147_v26 (stack54)
        %vm146178_vm11 = vcmp.lt.f32.partialorder %v82792_v22, 0.0004427343 (stack62)
        %v83190_v31 = vadd.s32 %v83187_v52, %v83182_v31 (stack40)
        %v83196_v40 = vshll.u32 %v83187_v52, 6 (stack45)
        %v83197_v34 = vshrl.u32 %v83187_v52, 26 (stack46)
        %v83579_v30 = vadd.s32 3, %v83575_v61 (stack40)
        %v83977_v43 = vxor.u32 %v83976_v24, %v83972_v27 (stack48)
        %v84397_v9 = vadd.s32 %v84394_v53, %v146134_v9 (stack40)
        %v84403_v8 = vshll.u32 %v84394_v53, 6 (stack45)
        %v82391_v29 = vadd.f32 %v82387_v42, %v146113_v29 (stack53)
        %v83198_v21 = vor.u32 %v83197_v34, %v83196_v40 (stack47)
        %v84404_v41 = vshrl.u32 %v84394_v53, 26 (stack46)
        %v84826_v56 = vadd.s32 %v84821_v7, %v121574_v2 (stack40)
        %v83583_v23 = vadd.s32 %v83579_v30, %v83567_v12 (stack40)
        %v83585_v20 = vshll.u32 %v83579_v30, 17 (stack45)
        %v83586_v52 = vshrl.u32 %v83579_v30, 15 (stack46)
        %v83980_v27 = vadd.s32 %v83977_v43, %v83972_v27 (stack40)
        %v82395_v53 = vmul.f32 %v82391_v29, %v146147_v26 (stack54)
        %v83199_v7 = vxor.u32 %v83198_v21, %v83190_v31 (stack48)
        %v83986_v12 = vshll.u32 %v83977_v43, 24 (stack45)
        %v83987_v61 = vshrl.u32 %v83977_v43, 8 (stack46)
        %v82791_v55 = vmul.f32 %v82790_v50, %v146152_v55 (stack63)
        %v83587_v50 = vor.u32 %v83586_v52, %v83585_v20 (stack47)
        %v84405_v24 = vor.u32 %v84404_v41, %v84403_v8 (stack47)
        %v84836_v42 = vshll.u32 %v84830_v44, 13 (stack45)
        %v121138_v40 = vpop.eup %121137 (stack64)
        %v82399_v46 = vadd.f32 %v82395_v53, %v146107_v46 (stack53)
        %v83202_v34 = vadd.s32 %v83199_v7, %v121574_v2 (stack40)
        %v83988_v30 = vor.u32 %v83987_v61, %v83986_v12 (stack47)
        %v84834_v43 = vadd.s32 %v84830_v44, %v84826_v56 (stack40)
        %v82788_v8 = vmul.f32 0.6931472, %v121138_v40 (stack65)
        %v83194_v31 = vadd.s32 %v83190_v31, %v121564_v0 (stack40)
        %v83588_v29 = vxor.u32 %v83587_v50, %v83583_v23 (stack48)
        %v84406_v21 = vxor.u32 %v84405_v24, %v84397_v9 (stack48)
        %v82403_v41 = vmul.f32 %v82399_v46, %v146147_v26 (stack54)
        %v83206_v56 = vadd.s32 5, %v83202_v34 (stack40)
        %v83989_v20 = vxor.u32 %v83988_v30, %v83980_v27 (stack48)
        %v146193_v52 = vadd.s32 %v157586_v60, %v157091_v37 (stack40)
        %v82794_v22 = vsel /*vm=*/%vm146178_vm11, /*on_true_vy=*/%v82791_v55, /*on_false_vx=*/%v82788_v8 (stack66)
        %v83591_v23 = vadd.s32 %v83588_v29, %v83583_v23 (stack40)
        %v83593_v53 = vshll.u32 %v83588_v29, 29 (stack45)
        %v83594_v7 = vshrl.u32 %v83588_v29, 3 (stack46)
        %v82407_v45 = vadd.f32 %v82403_v41, %v146102_v45 (stack53)
        %v146198_v12 = vxor.u32 2147483648, %v82794_v22 (stack56)
        %v83208_v61 = vxor.u32 %v83206_v56, %v83194_v31 (stack48)
        %v84837_v44 = vshrl.u32 %v84830_v44, 19 (stack46)
        %v83595_v55 = vor.u32 %v83594_v7, %v83593_v53 (stack47)
        %v82284_v50 = vmul.f32 inf, %v146027_v54 (stack54)
        %v82411_v24 = vmul.f32 %v82407_v45, %v146147_v26 (stack54)
        %121139 = vrsqrt.f32 %v146198_v12 (stack67)
        %vm146205_vm12 = vcmp.eq.f32.partialorder %v82276_v6, 1.0 (stack68)
        %v82308_v40 = vsel /*vm=*/%vm82303_vm5, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v82312_v32 = vsel /*vm=*/%vm82303_vm5, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v83596_v46 = vxor.u32 %v83595_v55, %v83591_v23 (stack48)
        %v83992_v34 = vadd.s32 %v83989_v20, %v121574_v2 (stack40)
        %v82415_v30 = vadd.f32 %v82411_v24, %v82312_v32 (stack53)
        %v82771_v8 = vand.u32 2147483647, %v146139_v25 (stack77)
        %v84409_v31 = vadd.s32 %v84406_v21, %v121564_v0 (stack40)
        %v84838_v42 = vor.u32 %v84837_v44, %v84836_v42 (stack47)
        %v146219_v29 = vmul.f32 inf, %v146139_v25 (stack54)
        %vm82798_vm13 = vcmp.lt.f32.partialorder %v146198_v12, 5.0 (stack68)
        %v83599_v21 = vadd.s32 %v83596_v46, %v83591_v23 (stack40)
        %v83984_v27 = vadd.s32 %v83980_v27, %v121564_v0 (stack40)
        %v82419_v26 = vmul.f32 %v82415_v30, %v146147_v26 (stack54)
        %v146225_v41 = vadd.f32 -2.5, %v146198_v12 (stack53)
        %v84401_v9 = vadd.s32 %v84397_v9, %v121569_v1 (stack40)
        %v146230_v56 = vadd.s32 %v146193_v52, %v122657_v58 (stack40)
        %v83209_v20 = vand.u32.u8 255, %v83208_v61 (stack49)
        %v83601_v22 = vshll.u32 %v83596_v46, 16 (stack45)
        %v83602_v23 = vshrl.u32 %v83596_v46, 16 (stack46)
        %v83996_v53 = vadd.s32 2, %v83992_v34 (stack40)
        %v82423_v7 = vadd.f32 %v82419_v26, %v82308_v40 (stack53)
        %v146235_v45 = vsel /*vm=*/%vm82798_vm13, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v84413_v61 = vadd.s32 1, %v84409_v31 (stack40)
        %v84839_v44 = vxor.u32 %v84838_v42, %v84834_v43 (stack48)
        %vm82843_vm14 = vcmp.eq.f32.partialorder %v146198_v12, inf (stack70)
        %v83210_v55 = vand.u32 65535, %v83209_v20 (stack50)
        %v83603_v24 = vor.u32 %v83602_v23, %v83601_v22 (stack47)
        %v84000_v40 = vadd.s32 %v83996_v53, %v83984_v27 (stack40)
        %v84002_v32 = vshll.u32 %v83996_v53, 13 (stack45)
        %v82427_v54 = vmul.f32 %v82423_v7, %v146027_v54 (stack54)
        %v84003_v46 = vshrl.u32 %v83996_v53, 19 (stack46)
        %v84417_v34 = vadd.s32 %v84413_v61, %v84401_v9 (stack40)
        %v84419_v30 = vshll.u32 %v84413_v61, 17 (stack45)
        %v83211_v31 = vshrl.u32 %v83210_v55, 1 (stack51)
        %v83604_v42 = vxor.u32 %v83603_v24, %v83599_v21 (stack48)
        %v84420_v27 = vshrl.u32 %v84413_v61, 15 (stack46)
        %v84842_v43 = vadd.s32 %v84839_v44, %v84834_v43 (stack40)
        %v82431_v50 = vsel /*vm=*/%vm146205_vm12, /*on_true_vy=*/%v82284_v50, /*on_false_vx=*/%v82427_v54 (stack44)
        %v84004_v6 = vor.u32 %v84003_v46, %v84002_v32 (stack47)
        %v84844_v26 = vshll.u32 %v84839_v44, 15 (stack45)
        %v84845_v9 = vshrl.u32 %v84839_v44, 17 (stack46)
        %v82435_v20 = vmul.f32 1.4140625, %v82431_v50 (stack54)
        %v83212_v22 = vor.u32 16256, %v83211_v31 (stack47)
        %v83607_v21 = vadd.s32 %v83604_v42, %v83599_v21 (stack40)
        %v83613_v23 = vshll.u32 %v83604_v42, 24 (stack45)
        %v83614_v53 = vshrl.u32 %v83604_v42, 8 (stack46)
        %v84005_v7 = vxor.u32 %v84004_v6, %v84000_v40 (stack48)
        %v84421_v61 = vor.u32 %v84420_v27, %v84419_v30 (stack47)
        %v84846_v44 = vor.u32 %v84845_v9, %v84844_v26 (stack47)
        %v121140_v55 = vpop.eup %121139 (stack73)
        %v82438_v24 = vpack.c.bf16 %v157387_v11, %v82435_v20 (stack81)
        %v82846_v32 = vand.u32 2147483648, %v146198_v12 (stack72)
        %v83213_v54 = vand.u32.u16 65535, %v83212_v22 (stack52)
        %vm85261_vm15 = vcmp.lt.u32.totalorder %v146193_v52, %v157091_v37 (stack43)
        %v82842_v46 = vmul.f32 %v121140_v55, %v146198_v12 (stack74)
        %v83615_v30 = vor.u32 %v83614_v53, %v83613_v23 (stack47)
        %v84008_v40 = vadd.s32 %v84005_v7, %v84000_v40 (stack40)
        %v84010_v31 = vshll.u32 %v84005_v7, 15 (stack45)
        %120183 = vst [vmem:[%s123356_s30 + $0x3d4] sm:$0xf] /*vst_source=*/%v82438_v24 (stack83)
        %v120190_v42 = vadd.low.f32.bf16 -1.0, %v83213_v54 (stack53)
        %v84011_v27 = vshrl.u32 %v84005_v7, 17 (stack46)
        %v84422_v50 = vxor.u32 %v84421_v61, %v84417_v34 (stack48)
        %v84847_v6 = vxor.u32 %v84846_v44, %v84842_v43 (stack48)
        %v82844_v26 = vsel /*vm=*/%vm82843_vm14, /*on_true_vy=*/%v146198_v12, /*on_false_vx=*/%v82842_v46 (stack75)
        %vm82845_vm0 = vcmp.eq.f32.partialorder %v146198_v12, 0.0 (stack71)
        %v83616_v9 = vxor.u32 %v83615_v30, %v83607_v21 (stack48)
        %v146253_v20 = vadd.s32 %v157591_v10, %v157094_v36 (stack40)
        %v82847_v22 = vsel /*vm=*/%vm82845_vm0, /*on_true_vy=*/%v82846_v32, /*on_false_vx=*/%v82844_v26 (stack76)
        %v83222_v23 = vmul.f32 2.0, %v120190_v42 (stack54)
        %v84012_v53 = vor.u32 %v84011_v27, %v84010_v31 (stack47)
        %v84425_v34 = vadd.s32 %v84422_v50, %v84417_v34 (stack40)
        %v82850_v7 = vadd.f32 -3.0, %v82847_v22 (stack53)
        %v83619_v61 = vadd.s32 %v83616_v9, %v121564_v0 (stack40)
        %v84427_v44 = vshll.u32 %v84422_v50, 29 (stack45)
        %v84428_v55 = vshrl.u32 %v84422_v50, 3 (stack46)
        %v82835_v24 = vsel /*vm=*/%vm82798_vm13, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v83226_v32 = vadd.f32 -0.99609375, %v83222_v23 (stack53)
        %v84013_v54 = vxor.u32 %v84012_v53, %v84008_v40 (stack48)
        %v84850_v43 = vadd.s32 %v84847_v6, %v84842_v43 (stack40)
        %v146262_v41 = vsel /*vm=*/%vm82798_vm13, /*on_true_vy=*/%v146225_v41, /*on_false_vx=*/%v82850_v7 (stack44)
        %v83611_v21 = vadd.s32 %v83607_v21, %v121569_v1 (stack40)
        %v83623_v46 = vadd.s32 4, %v83619_v61 (stack40)
        %v84429_v30 = vor.u32 %v84428_v55, %v84427_v44 (stack47)
        %v82858_v31 = vmul.f32 %v146262_v41, %v82835_v24 (stack54)
        %v146266_v42 = vmax.f32 %v83226_v32, -0.99609375 (stack55)
        %v84016_v40 = vadd.s32 %v84013_v54, %v84008_v40 (stack40)
        %v84018_v27 = vshll.u32 %v84013_v54, 26 (stack45)
        %v83627_v50 = vadd.s32 %v83623_v46, %v83611_v21 (stack40)
        %v83629_v26 = vshll.u32 %v83623_v46, 13 (stack45)
        %v83630_v9 = vshrl.u32 %v83623_v46, 19 (stack46)
        %v84019_v22 = vshrl.u32 %v84013_v54, 6 (stack46)
        %v82862_v45 = vadd.f32 %v82858_v31, %v146235_v45 (stack53)
        %v83242_v23 = vxor.u32 2147483648, %v146266_v42 (stack56)
        %v84852_v53 = vshll.u32 %v84847_v6, 26 (stack45)
        %v84853_v6 = vshrl.u32 %v84847_v6, 6 (stack46)
        %v82815_v7 = vsel /*vm=*/%vm82798_vm13, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v83631_v61 = vor.u32 %v83630_v9, %v83629_v26 (stack47)
        %v84020_v44 = vor.u32 %v84019_v22, %v84018_v27 (stack47)
        %v84430_v55 = vxor.u32 %v84429_v30, %v84425_v34 (stack48)
        %v82819_v24 = vsel /*vm=*/%vm82798_vm13, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v82823_v32 = vsel /*vm=*/%vm82798_vm13, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v82866_v54 = vmul.f32 %v82862_v45, %v146262_v41 (stack54)
        %v146281_v21 = vmul.f32 %v83242_v23, %v146266_v42 (stack54)
        %v82827_v46 = vsel /*vm=*/%vm82798_vm13, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v83632_v30 = vxor.u32 %v83631_v61, %v83627_v50 (stack48)
        %v84021_v31 = vxor.u32 %v84020_v44, %v84016_v40 (stack48)
        %v84433_v34 = vadd.s32 %v84430_v55, %v84425_v34 (stack40)
        %v82870_v27 = vadd.f32 %v82866_v54, %v82827_v46 (stack53)
        %v83247_v26 = vadd.f32 1.0, %v146281_v21 (stack57)
        %v83250_v9 = vmul.f32 -0.5, %v146281_v21 (stack59)
        %v84854_v22 = vor.u32 %v84853_v6, %v84852_v53 (stack47)
        %vm85256_vm1 = vcmp.lt.u32.totalorder %v146230_v56, %v146193_v52 (stack43)
        %v83635_v50 = vadd.s32 %v83632_v30, %v83627_v50 (stack40)
        %v83637_v45 = vshll.u32 %v83632_v30, 15 (stack45)
        %v83638_v23 = vshrl.u32 %v83632_v30, 17 (stack46)
        %v84024_v40 = vadd.s32 %v84021_v31, %v84016_v40 (stack40)
        %v82874_v53 = vmul.f32 %v82870_v27, %v146262_v41 (stack54)
        %121141 = vlog2.f32 %v83247_v26 (stack58)
        %v84435_v6 = vshll.u32 %v84430_v55, 16 (stack45)
        %v85291_v61 = vadd.s32 %v146230_v56, %v121569_v1 (stack40)
        %v83639_v44 = vor.u32 %v83638_v23, %v83637_v45 (stack47)
        %v84030_v54 = vshll.u32 %v84021_v31, 6 (stack45)
        %v84031_v46 = vshrl.u32 %v84021_v31, 26 (stack46)
        %v85270_v30 = vadd.s32 1, %v146253_v20 (stack40)
        %v82878_v32 = vadd.f32 %v82874_v53, %v82823_v32 (stack53)
        %v83253_v31 = vand.u32 2147483647, %v146281_v21 (stack60)
        %v84436_v55 = vshrl.u32 %v84430_v55, 16 (stack46)
        %v84855_v27 = vxor.u32 %v84854_v22, %v84850_v43 (stack48)
        %v83251_v26 = vadd.f32 1.0, %v83250_v9 (stack61)
        %v83640_v9 = vxor.u32 %v83639_v44, %v83635_v50 (stack48)
        %v84032_v22 = vor.u32 %v84031_v46, %v84030_v54 (stack47)
        %v85274_v20 = vsel /*vm=*/%vm85261_vm15, /*on_true_vy=*/%v85270_v30, /*on_false_vx=*/%v146253_v20 (stack44)
        %v82882_v45 = vmul.f32 %v82878_v32, %v146262_v41 (stack54)
        %v84437_v23 = vor.u32 %v84436_v55, %v84435_v6 (stack47)
        %v146300_v43 = vadd.s32 %v84855_v27, %v84850_v43 (stack40)
        %v84864_v53 = vshll.u32 %v84855_v27, 6 (stack45)
        %v83643_v50 = vadd.s32 %v83640_v9, %v83635_v50 (stack40)
        %v83645_v6 = vshll.u32 %v83640_v9, 26 (stack45)
        %v83646_v44 = vshrl.u32 %v83640_v9, 6 (stack46)
        %v84033_v54 = vxor.u32 %v84032_v22, %v84024_v40 (stack48)
        %v82886_v24 = vadd.f32 %v82882_v45, %v82819_v24 (stack53)
        %v84028_v40 = vadd.s32 %v84024_v40, %v121574_v2 (stack40)
        %v84438_v46 = vxor.u32 %v84437_v23, %v84433_v34 (stack48)
        %v84865_v30 = vshrl.u32 %v84855_v27, 26 (stack46)
        %v83647_v32 = vor.u32 %v83646_v44, %v83645_v6 (stack47)
        %v84036_v55 = vadd.s32 %v84033_v54, %v121569_v1 (stack40)
        %v85278_v27 = vadd.s32 1, %v85274_v20 (stack40)
        %v85297_v9 = vshll.u32 %v85291_v61, 13 (stack45)
        %v82890_v22 = vmul.f32 %v82886_v24, %v146262_v41 (stack54)
        %v84441_v34 = vadd.s32 %v84438_v46, %v84433_v34 (stack40)
        %v84447_v45 = vshll.u32 %v84438_v46, 24 (stack45)
        %v84448_v23 = vshrl.u32 %v84438_v46, 8 (stack46)
        %v83648_v6 = vxor.u32 %v83647_v32, %v83643_v50 (stack48)
        %v84040_v44 = vadd.s32 3, %v84036_v55 (stack40)
        %v84866_v53 = vor.u32 %v84865_v30, %v84864_v53 (stack47)
        %v85282_v52 = vsel /*vm=*/%vm85256_vm1, /*on_true_vy=*/%v85278_v27, /*on_false_vx=*/%v85274_v20 (stack44)
        %v82894_v56 = vadd.f32 %v82890_v22, %v82815_v7 (stack53)
        %v84449_v7 = vor.u32 %v84448_v23, %v84447_v45 (stack47)
        %v85287_v20 = vadd.s32 %v85282_v52, %v121574_v2 (stack40)
        %v85298_v54 = vshrl.u32 %v85291_v61, 19 (stack46)
        %v83651_v50 = vadd.s32 %v83648_v6, %v83643_v50 (stack40)
        %v83657_v24 = vshll.u32 %v83648_v6, 6 (stack45)
        %v83658_v46 = vshrl.u32 %v83648_v6, 26 (stack46)
        %v84044_v40 = vadd.s32 %v84040_v44, %v84028_v40 (stack40)
        %v82898_v30 = vmul.f32 %v82894_v56, %v146262_v41 (stack54)
        %v84046_v32 = vshll.u32 %v84040_v44, 17 (stack45)
        %v84047_v55 = vshrl.u32 %v84040_v44, 15 (stack46)
        %v84450_v27 = vxor.u32 %v84449_v7, %v84441_v34 (stack48)
        %v121142_v22 = vpop.eup %121141 (stack64)
        %v82811_v45 = vsel /*vm=*/%vm82798_vm13, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v83659_v23 = vor.u32 %v83658_v46, %v83657_v24 (stack47)
        %v84867_v6 = vxor.u32 %v84866_v53, %v146300_v43 (stack48)
        %v85295_v61 = vadd.s32 %v85291_v61, %v85287_v20 (stack40)
        %v82902_v44 = vadd.f32 %v82898_v30, %v82811_v45 (stack53)
        %v83249_v53 = vmul.f32 0.6931472, %v121142_v22 (stack65)
        %v83252_v21 = vmul.f32 %v83251_v26, %v146281_v21 (stack63)
        %v84048_v26 = vor.u32 %v84047_v55, %v84046_v32 (stack47)
        %vm83254_vm2 = vcmp.lt.f32.partialorder %v83253_v31, 0.0004427343 (stack62)
        %v83660_v31 = vxor.u32 %v83659_v23, %v83651_v50 (stack48)
        %v85299_v9 = vor.u32 %v85298_v54, %v85297_v9 (stack47)
        %v146317_v60 = vadd.s32 %v157586_v60, %v157095_v13 (stack40)
        %v82906_v52 = vmul.f32 %v82902_v44, %v146262_v41 (stack54)
        %v83255_v56 = vsel /*vm=*/%vm83254_vm2, /*on_true_vy=*/%v83252_v21, /*on_false_vx=*/%v83249_v53 (stack66)
        %v84049_v7 = vxor.u32 %v84048_v26, %v84044_v40 (stack48)
        %v84453_v20 = vadd.s32 %v84450_v27, %v121574_v2 (stack40)
        %v82807_v54 = vsel /*vm=*/%vm82798_vm13, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v146324_v24 = vxor.u32 2147483648, %v83255_v56 (stack56)
        %v84870_v46 = vadd.s32 %v84867_v6, %v121564_v0 (stack40)
        %v85300_v30 = vxor.u32 %v85299_v9, %v85295_v61 (stack48)
        %v82910_v32 = vadd.f32 %v82906_v52, %v82807_v54 (stack53)
        %v84052_v40 = vadd.s32 %v84049_v7, %v84044_v40 (stack40)
        %v84054_v55 = vshll.u32 %v84049_v7, 29 (stack45)
        %v84055_v27 = vshrl.u32 %v84049_v7, 3 (stack46)
        %vm146329_vm3 = vcmp.eq.f32.partialorder %v82771_v8, 1.0 (stack68)
        %vm83259_vm4 = vcmp.lt.f32.partialorder %v146324_v24, 5.0 (stack68)
        %121143 = vrsqrt.f32 %v146324_v24 (stack67)
        %v83663_v22 = vadd.s32 %v83660_v31, %v121574_v2 (stack40)
        %v82803_v12 = vsel /*vm=*/%vm82798_vm13, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v82914_v41 = vmul.f32 %v82910_v32, %v146262_v41 (stack54)
        %v83232_v45 = vand.u32 2147483647, %v146266_v42 (stack77)
        %v84457_v23 = vadd.s32 2, %v84453_v20 (stack40)
        %v83655_v50 = vadd.s32 %v83651_v50, %v121564_v0 (stack40)
        %v84056_v6 = vor.u32 %v84055_v27, %v84054_v55 (stack47)
        %v84445_v34 = vadd.s32 %v84441_v34, %v121564_v0 (stack40)
        %v84862_v43 = vadd.s32 %v146300_v43, %v121569_v1 (stack40)
        %v82918_v44 = vadd.f32 %v82914_v41, %v82803_v12 (stack53)
        %v146348_v53 = vsel /*vm=*/%vm83259_vm4, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v146351_v21 = vadd.f32 -2.5, %v146324_v24 (stack53)
        %v84874_v26 = vadd.s32 1, %v84870_v46 (stack40)
        %v146356_v31 = vsel /*vm=*/%vm83259_vm4, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v146361_v9 = vsel /*vm=*/%vm83259_vm4, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v83667_v52 = vadd.s32 5, %v83663_v22 (stack40)
        %v84057_v56 = vxor.u32 %v84056_v6, %v84052_v40 (stack48)
        %v82922_v25 = vmul.f32 %v82918_v44, %v146139_v25 (stack54)
        %v84461_v7 = vadd.s32 %v84457_v23, %v84445_v34 (stack40)
        %v84463_v20 = vshll.u32 %v84457_v23, 13 (stack45)
        %v84464_v54 = vshrl.u32 %v84457_v23, 19 (stack46)
        %v83669_v46 = vxor.u32 %v83667_v52, %v83655_v50 (stack48)
        %v84060_v32 = vadd.s32 %v84057_v56, %v84052_v40 (stack40)
        %v84062_v40 = vshll.u32 %v84057_v56, 16 (stack45)
        %v84063_v55 = vshrl.u32 %v84057_v56, 16 (stack46)
        %v82926_v29 = vsel /*vm=*/%vm146329_vm3, /*on_true_vy=*/%v146219_v29, /*on_false_vx=*/%v82922_v25 (stack44)
        %vm83304_vm5 = vcmp.eq.f32.partialorder %v146324_v24, inf (stack70)
        %v84465_v27 = vor.u32 %v84464_v54, %v84463_v20 (stack47)
        %v84878_v8 = vadd.s32 %v84874_v26, %v84862_v43 (stack40)
        %v84880_v22 = vshll.u32 %v84874_v26, 17 (stack45)
        %v82930_v12 = vmul.f32 1.4140625, %v82926_v29 (stack54)
        %v83670_v41 = vand.u32.u8 255, %v83669_v46 (stack49)
        %v84064_v23 = vor.u32 %v84063_v55, %v84062_v40 (stack47)
        %v84881_v50 = vshrl.u32 %v84874_v26, 15 (stack46)
        %v84466_v6 = vxor.u32 %v84465_v27, %v84461_v7 (stack48)
        %v85303_v61 = vadd.s32 %v85300_v30, %v85295_v61 (stack40)
        %v85305_v34 = vshll.u32 %v85300_v30, 15 (stack45)
        %v85306_v30 = vshrl.u32 %v85300_v30, 17 (stack46)
        %v82933_v43 = vpack.c.bf16 %v157387_v11, %v82930_v12 (stack81)
        %v83671_v44 = vand.u32 65535, %v83670_v41 (stack50)
        %v84065_v26 = vxor.u32 %v84064_v23, %v84060_v32 (stack48)
        %v84882_v52 = vor.u32 %v84881_v50, %v84880_v22 (stack47)
        %v84469_v56 = vadd.s32 %v84466_v6, %v84461_v7 (stack40)
        %v84471_v25 = vshll.u32 %v84466_v6, 15 (stack45)
        %v84472_v7 = vshrl.u32 %v84466_v6, 17 (stack46)
        %v85307_v20 = vor.u32 %v85306_v30, %v85305_v34 (stack47)
        %120189 = vst [vmem:[%s123356_s30 + $0x58] sm:$0xf] /*vst_source=*/%v82933_v43 (stack83)
        %v83672_v54 = vshrl.u32 %v83671_v44, 1 (stack51)
        %v84068_v46 = vadd.s32 %v84065_v26, %v84060_v32 (stack40)
        %v84074_v32 = vshll.u32 %v84065_v26, 24 (stack45)
        %v84075_v40 = vshrl.u32 %v84065_v26, 8 (stack46)
        %v121144_v55 = vpop.eup %121143 (stack73)
        %vm83306_vm6 = vcmp.eq.f32.partialorder %v146324_v24, 0.0 (stack71)
        %v84473_v29 = vor.u32 %v84472_v7, %v84471_v25 (stack47)
        %v84883_v27 = vxor.u32 %v84882_v52, %v84878_v8 (stack48)
        %v85308_v22 = vxor.u32 %v85307_v20, %v85303_v61 (stack48)
        %v83303_v12 = vmul.f32 %v121144_v55, %v146324_v24 (stack74)
        %v83307_v41 = vand.u32 2147483648, %v146324_v24 (stack72)
        %v83673_v23 = vor.u32 16256, %v83672_v54 (stack47)
        %v84076_v50 = vor.u32 %v84075_v40, %v84074_v32 (stack47)
        %v84474_v6 = vxor.u32 %v84473_v29, %v84469_v56 (stack48)
        %v84886_v8 = vadd.s32 %v84883_v27, %v84878_v8 (stack40)
        %v84888_v34 = vshll.u32 %v84883_v27, 29 (stack45)
        %v84889_v30 = vshrl.u32 %v84883_v27, 3 (stack46)
        %v83305_v43 = vsel /*vm=*/%vm83304_vm5, /*on_true_vy=*/%v146324_v24, /*on_false_vx=*/%v83303_v12 (stack75)
        %v83674_v44 = vand.u32.u16 65535, %v83673_v23 (stack52)
        %v84077_v26 = vxor.u32 %v84076_v50, %v84068_v46 (stack48)
        %v85311_v61 = vadd.s32 %v85308_v22, %v85303_v61 (stack40)
        %v83308_v52 = vsel /*vm=*/%vm83306_vm6, /*on_true_vy=*/%v83307_v41, /*on_false_vx=*/%v83305_v43 (stack76)
        %v84477_v56 = vadd.s32 %v84474_v6, %v84469_v56 (stack40)
        %v84479_v25 = vshll.u32 %v84474_v6, 26 (stack45)
        %v84480_v7 = vshrl.u32 %v84474_v6, 6 (stack46)
        %v83311_v20 = vadd.f32 -3.0, %v83308_v52 (stack53)
        %v120192_v54 = vadd.low.f32.bf16 -1.0, %v83674_v44 (stack53)
        %v84080_v32 = vadd.s32 %v84077_v26, %v121564_v0 (stack40)
        %v84890_v40 = vor.u32 %v84889_v30, %v84888_v34 (stack47)
        %v84072_v46 = vadd.s32 %v84068_v46, %v121569_v1 (stack40)
        %v84481_v55 = vor.u32 %v84480_v7, %v84479_v25 (stack47)
        %v85313_v29 = vshll.u32 %v85308_v22, 26 (stack45)
        %v85314_v27 = vshrl.u32 %v85308_v22, 6 (stack46)
        %v146383_v21 = vsel /*vm=*/%vm83259_vm4, /*on_true_vy=*/%v146351_v21, /*on_false_vx=*/%v83311_v20 (stack44)
        %v83683_v22 = vmul.f32 2.0, %v120192_v54 (stack54)
        %v84084_v12 = vadd.s32 4, %v84080_v32 (stack40)
        %v84891_v41 = vxor.u32 %v84890_v40, %v84886_v8 (stack48)
        %v83319_v9 = vmul.f32 %v146383_v21, %v146361_v9 (stack54)
        %v84482_v23 = vxor.u32 %v84481_v55, %v84477_v56 (stack48)
        %v85315_v50 = vor.u32 %v85314_v27, %v85313_v29 (stack47)
        %vm85722_vm7 = vcmp.lt.u32.totalorder %v146317_v60, %v157095_v13 (stack43)
        %v83687_v6 = vadd.f32 -0.99609375, %v83683_v22 (stack53)
        %v84088_v34 = vadd.s32 %v84084_v12, %v84072_v46 (stack40)
        %v84090_v30 = vshll.u32 %v84084_v12, 13 (stack45)
        %v84091_v43 = vshrl.u32 %v84084_v12, 19 (stack46)
        %v83323_v31 = vadd.f32 %v83319_v9, %v146356_v31 (stack53)
        %v84485_v44 = vadd.s32 %v84482_v23, %v84477_v56 (stack40)
        %v84491_v26 = vshll.u32 %v84482_v23, 6 (stack45)
        %v84492_v52 = vshrl.u32 %v84482_v23, 26 (stack46)
        %v146390_v56 = vmax.f32 %v83687_v6, -0.99609375 (stack55)
        %v84092_v25 = vor.u32 %v84091_v43, %v84090_v30 (stack47)
        %v84894_v8 = vadd.s32 %v84891_v41, %v84886_v8 (stack40)
        %v84896_v7 = vshll.u32 %v84891_v41, 16 (stack45)
        %v146395_v20 = vsel /*vm=*/%vm83259_vm4, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v83327_v54 = vmul.f32 %v83323_v31, %v146383_v21 (stack54)
        %v84493_v32 = vor.u32 %v84492_v52, %v84491_v26 (stack47)
        %v84897_v40 = vshrl.u32 %v84891_v41, 16 (stack46)
        %v83276_v46 = vsel /*vm=*/%vm83259_vm4, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v83288_v55 = vsel /*vm=*/%vm83259_vm4, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v83703_v29 = vxor.u32 2147483648, %v146390_v56 (stack56)
        %v84093_v27 = vxor.u32 %v84092_v25, %v84088_v34 (stack48)
        %v83331_v22 = vadd.f32 %v83327_v54, %v83288_v55 (stack53)
        %v84494_v12 = vxor.u32 %v84493_v32, %v84485_v44 (stack48)
        %v84898_v41 = vor.u32 %v84897_v40, %v84896_v7 (stack47)
        %v85316_v9 = vxor.u32 %v85315_v50, %v85311_v61 (stack48)
        %v83284_v23 = vsel /*vm=*/%vm83259_vm4, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v83706_v50 = vmul.f32 %v83703_v29, %v146390_v56 (stack54)
        %v84096_v6 = vadd.s32 %v84093_v27, %v84088_v34 (stack40)
        %v84098_v34 = vshll.u32 %v84093_v27, 15 (stack45)
        %v83335_v30 = vmul.f32 %v83331_v22, %v146383_v21 (stack54)
        %v84099_v43 = vshrl.u32 %v84093_v27, 17 (stack46)
        %v84497_v31 = vadd.s32 %v84494_v12, %v121569_v1 (stack40)
        %v84899_v26 = vxor.u32 %v84898_v41, %v84894_v8 (stack48)
        %v83708_v52 = vadd.f32 1.0, %v83706_v50 (stack57)
        %v84489_v44 = vadd.s32 %v84485_v44, %v121574_v2 (stack40)
        %v146412_v61 = vadd.s32 %v85316_v9, %v85311_v61 (stack40)
        %v146416_v25 = vadd.s32 %v146317_v60, %v122657_v58 (stack40)
        %v83339_v7 = vadd.f32 %v83335_v30, %v83284_v23 (stack53)
        %v84100_v54 = vor.u32 %v84099_v43, %v84098_v34 (stack47)
        %v84501_v32 = vadd.s32 3, %v84497_v31 (stack40)
        %v84902_v8 = vadd.s32 %v84899_v26, %v84894_v8 (stack40)
        %v83280_v40 = vsel /*vm=*/%vm83259_vm4, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %121145 = vlog2.f32 %v83708_v52 (stack58)
        %v83711_v55 = vmul.f32 -0.5, %v83706_v50 (stack59)
        %v84908_v29 = vshll.u32 %v84899_v26, 24 (stack45)
        %v83343_v27 = vmul.f32 %v83339_v7, %v146383_v21 (stack54)
        %v84101_v22 = vxor.u32 %v84100_v54, %v84096_v6 (stack48)
        %v84505_v12 = vadd.s32 %v84501_v32, %v84489_v44 (stack40)
        %v84507_v41 = vshll.u32 %v84501_v32, 17 (stack45)
        %v83714_v23 = vand.u32 2147483647, %v83706_v50 (stack60)
        %v84508_v34 = vshrl.u32 %v84501_v32, 15 (stack46)
        %v84909_v30 = vshrl.u32 %v84899_v26, 8 (stack46)
        %vm85717_vm8 = vcmp.lt.u32.totalorder %v146416_v25, %v146317_v60 (stack43)
        %v83347_v43 = vadd.f32 %v83343_v27, %v83280_v40 (stack53)
        %v84104_v6 = vadd.s32 %v84101_v22, %v84096_v6 (stack40)
        %v84106_v31 = vshll.u32 %v84101_v22, 26 (stack45)
        %v84107_v26 = vshrl.u32 %v84101_v22, 6 (stack46)
        %v83712_v52 = vadd.f32 1.0, %v83711_v55 (stack61)
        %v84509_v44 = vor.u32 %v84508_v34, %v84507_v41 (stack47)
        %v84910_v7 = vor.u32 %v84909_v30, %v84908_v29 (stack47)
        %v85325_v54 = vshll.u32 %v85316_v9, 6 (stack45)
        %v83351_v32 = vmul.f32 %v83347_v43, %v146383_v21 (stack54)
        %v84108_v40 = vor.u32 %v84107_v26, %v84106_v31 (stack47)
        %v85326_v9 = vshrl.u32 %v85316_v9, 26 (stack46)
        %v85727_v10 = vadd.s32 %v157591_v10, %v157100_v14 (stack40)
        %v84510_v55 = vxor.u32 %v84509_v44, %v84505_v12 (stack48)
        %v84906_v29 = vadd.s32 %v84902_v8, %v121564_v0 (stack40)
        %v84911_v8 = vxor.u32 %v84910_v7, %v84902_v8 (stack48)
        %v157614_v27 = vld [vmem:[#allocation143_spill] sm:$0xff] (stack84)
        %v146430_v22 = vadd.s32 %v157614_v27, %v122651_v47 (stack40)
        %v83355_v46 = vadd.f32 %v83351_v32, %v83276_v46 (stack53)
        %vm146432_vm9 = vcmp.lt.f32.partialorder %v83714_v23, 0.0004427343 (stack62)
        %v84109_v23 = vxor.u32 %v84108_v40, %v84104_v6 (stack48)
        %v85327_v34 = vor.u32 %v85326_v9, %v85325_v54 (stack47)
        %v85731_v30 = vadd.s32 1, %v85727_v10 (stack40)
        %v84513_v12 = vadd.s32 %v84510_v55, %v84505_v12 (stack40)
        %v84515_v43 = vshll.u32 %v84510_v55, 29 (stack45)
        %v84516_v31 = vshrl.u32 %v84510_v55, 3 (stack46)
        %v84914_v26 = vadd.s32 %v84911_v8, %v121574_v2 (stack40)
        %v83359_v44 = vmul.f32 %v83355_v46, %v146383_v21 (stack54)
        %v84112_v6 = vadd.s32 %v84109_v23, %v84104_v6 (stack40)
        %v84118_v7 = vshll.u32 %v84109_v23, 6 (stack45)
        %v84119_v54 = vshrl.u32 %v84109_v23, 26 (stack46)
        %v84517_v32 = vor.u32 %v84516_v31, %v84515_v43 (stack47)
        %v84918_v40 = vadd.s32 2, %v84914_v26 (stack40)
        %v85328_v9 = vxor.u32 %v85327_v34, %v146412_v61 (stack48)
        %v85735_v10 = vsel /*vm=*/%vm85722_vm7, /*on_true_vy=*/%v85731_v30, /*on_false_vx=*/%v85727_v10 (stack44)
        %v83363_v20 = vadd.f32 %v83359_v44, %v146395_v20 (stack53)
        %v83713_v50 = vmul.f32 %v83712_v52, %v83706_v50 (stack63)
        %v84120_v52 = vor.u32 %v84119_v54, %v84118_v7 (stack47)
        %v85739_v55 = vadd.s32 1, %v85735_v10 (stack40)
        %v84518_v8 = vxor.u32 %v84517_v32, %v84513_v12 (stack48)
        %v84922_v29 = vadd.s32 %v84918_v40, %v84906_v29 (stack40)
        %v84924_v46 = vshll.u32 %v84918_v40, 13 (stack45)
        %v84925_v23 = vshrl.u32 %v84918_v40, 19 (stack46)
        %v121146_v34 = vpop.eup %121145 (stack64)
        %v83367_v30 = vmul.f32 %v83363_v20, %v146383_v21 (stack54)
        %v84121_v43 = vxor.u32 %v84120_v52, %v84112_v6 (stack48)
        %v85331_v31 = vadd.s32 %v85328_v9, %v121564_v0 (stack40)
        %v85743_v60 = vsel /*vm=*/%vm85717_vm8, /*on_true_vy=*/%v85739_v55, /*on_false_vx=*/%v85735_v10 (stack44)
        %v83710_v26 = vmul.f32 0.6931472, %v121146_v34 (stack65)
        %v84521_v12 = vadd.s32 %v84518_v8, %v84513_v12 (stack40)
        %v84523_v44 = vshll.u32 %v84518_v8, 16 (stack45)
        %v84524_v7 = vshrl.u32 %v84518_v8, 16 (stack46)
        %v83371_v53 = vadd.f32 %v83367_v30, %v146348_v53 (stack53)
        %v84124_v54 = vadd.s32 %v84121_v43, %v121574_v2 (stack40)
        %v84926_v32 = vor.u32 %v84925_v23, %v84924_v46 (stack47)
        %v85335_v40 = vadd.s32 1, %v85331_v31 (stack40)
        %v83716_v41 = vsel /*vm=*/%vm146432_vm9, /*on_true_vy=*/%v83713_v50, /*on_false_vx=*/%v83710_v26 (stack66)
        %v84525_v9 = vor.u32 %v84524_v7, %v84523_v44 (stack47)
        %v85323_v61 = vadd.s32 %v146412_v61, %v121569_v1 (stack40)
        %v85752_v25 = vadd.s32 %v146416_v25, %v121569_v1 (stack40)
        %v83375_v21 = vmul.f32 %v83371_v53, %v146383_v21 (stack54)
        %v146457_v10 = vxor.u32 2147483648, %v83716_v41 (stack56)
        %v84128_v20 = vadd.s32 5, %v84124_v54 (stack40)
        %v84927_v50 = vxor.u32 %v84926_v32, %v84922_v29 (stack48)
        %v83264_v24 = vsel /*vm=*/%vm83259_vm4, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v84116_v6 = vadd.s32 %v84112_v6, %v121564_v0 (stack40)
        %v84526_v52 = vxor.u32 %v84525_v9, %v84521_v12 (stack48)
        %v85339_v55 = vadd.s32 %v85335_v40, %v85323_v61 (stack40)
        %v83379_v8 = vadd.f32 %v83375_v21, %v83264_v24 (stack53)
        %121147 = vrsqrt.f32 %v146457_v10 (stack67)
        %v83240_v46 = vmul.f32 inf, %v146266_v42 (stack54)
        %vm83720_vm10 = vcmp.lt.f32.partialorder %v146457_v10, 5.0 (stack68)
        %v84130_v23 = vxor.u32 %v84128_v20, %v84116_v6 (stack48)
        %vm83235_vm11 = vcmp.eq.f32.partialorder %v83232_v45, 1.0 (stack68)
        %v83383_v42 = vmul.f32 %v83379_v8, %v146266_v42 (stack54)
        %v85748_v45 = vadd.s32 %v85743_v60, %v121574_v2 (stack40)
        %v85758_v34 = vshll.u32 %v85752_v25, 13 (stack45)
        %v146471_v30 = vadd.f32 -2.5, %v146457_v10 (stack53)
        %v84529_v43 = vadd.s32 %v84526_v52, %v84521_v12 (stack40)
        %v85341_v31 = vshll.u32 %v85335_v40, 17 (stack45)
        %v85342_v60 = vshrl.u32 %v85335_v40, 15 (stack46)
        %v83387_v26 = vsel /*vm=*/%vm83235_vm11, /*on_true_vy=*/%v83240_v46, /*on_false_vx=*/%v83383_v42 (stack44)
        %v146476_v12 = vsel /*vm=*/%vm83720_vm10, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v146481_v44 = vsel /*vm=*/%vm83720_vm10, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v146486_v7 = vsel /*vm=*/%vm83720_vm10, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v83391_v53 = vmul.f32 1.4140625, %v83387_v26 (stack54)
        %v146491_v54 = vsel /*vm=*/%vm83720_vm10, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v84131_v32 = vand.u32.u8 255, %v84130_v23 (stack49)
        %v84535_v40 = vshll.u32 %v84526_v52, 24 (stack45)
        %v84536_v41 = vshrl.u32 %v84526_v52, 8 (stack46)
        %v84930_v29 = vadd.s32 %v84927_v50, %v84922_v29 (stack40)
        %v84932_v9 = vshll.u32 %v84927_v50, 15 (stack45)
        %v84933_v61 = vshrl.u32 %v84927_v50, 17 (stack46)
        %v83394_v21 = vpack.c.bf16 %v157387_v11, %v83391_v53 (stack81)
        %v84132_v20 = vand.u32 65535, %v84131_v32 (stack50)
        %v85343_v50 = vor.u32 %v85342_v60, %v85341_v31 (stack47)
        %v85756_v24 = vadd.s32 %v85752_v25, %v85748_v45 (stack40)
        %v83753_v6 = vsel /*vm=*/%vm83720_vm10, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v84537_v52 = vor.u32 %v84536_v41, %v84535_v40 (stack47)
        %v84934_v8 = vor.u32 %v84933_v61, %v84932_v9 (stack47)
        %v85759_v25 = vshrl.u32 %v85752_v25, 19 (stack46)
        %120191 = vst [vmem:[%s123356_s30 + $0xd8] sm:$0xf] /*vst_source=*/%v83394_v21 (stack83)
        %v84133_v46 = vshrl.u32 %v84132_v20, 1 (stack51)
        %v85344_v23 = vxor.u32 %v85343_v50, %v85339_v55 (stack48)
        %vm86217_vm12 = vcmp.lt.u32.totalorder %v146430_v22, %v122651_v47 (stack43)
        %v157617_v42 = vld [vmem:[#allocation107_spill] sm:$0xff] (stack84)
        %v146502_v45 = vadd.s32 %v157617_v42, %v157068_v28 (stack40)
        %vm83765_vm13 = vcmp.eq.f32.partialorder %v146457_v10, inf (stack70)
        %v84538_v31 = vxor.u32 %v84537_v52, %v84529_v43 (stack48)
        %v84935_v60 = vxor.u32 %v84934_v8, %v84930_v29 (stack48)
        %v85760_v34 = vor.u32 %v85759_v25, %v85758_v34 (stack47)
        %v84134_v26 = vor.u32 16256, %v84133_v46 (stack47)
        %v85347_v55 = vadd.s32 %v85344_v23, %v85339_v55 (stack40)
        %v85349_v53 = vshll.u32 %v85344_v23, 29 (stack45)
        %v85350_v32 = vshrl.u32 %v85344_v23, 3 (stack46)
        %v84541_v40 = vadd.s32 %v84538_v31, %v121564_v0 (stack40)
        %v84938_v41 = vadd.s32 %v84935_v60, %v84930_v29 (stack40)
        %v84940_v29 = vshll.u32 %v84935_v60, 26 (stack45)
        %v84941_v9 = vshrl.u32 %v84935_v60, 6 (stack46)
        %v121148_v61 = vpop.eup %121147 (stack73)
        %vm83767_vm14 = vcmp.eq.f32.partialorder %v146457_v10, 0.0 (stack71)
        %v84135_v21 = vand.u32.u16 65535, %v84134_v26 (stack52)
        %v85351_v20 = vor.u32 %v85350_v32, %v85349_v53 (stack47)
        %v85761_v50 = vxor.u32 %v85760_v34, %v85756_v24 (stack48)
        %v83764_v52 = vmul.f32 %v121148_v61, %v146457_v10 (stack74)
        %v84533_v43 = vadd.s32 %v84529_v43, %v121569_v1 (stack40)
        %v84545_v8 = vadd.s32 4, %v84541_v40 (stack40)
        %v84942_v25 = vor.u32 %v84941_v9, %v84940_v29 (stack47)
        %v83768_v46 = vand.u32 2147483648, %v146457_v10 (stack72)
        %v120194_v23 = vadd.low.f32.bf16 -1.0, %v84135_v21 (stack53)
        %v85352_v31 = vxor.u32 %v85351_v20, %v85347_v55 (stack48)
        %v146510_v24 = vadd.s32 %v85761_v50, %v85756_v24 (stack40)
        %v83766_v60 = vsel /*vm=*/%vm83765_vm13, /*on_true_vy=*/%v146457_v10, /*on_false_vx=*/%v83764_v52 (stack75)
        %v84549_v34 = vadd.s32 %v84545_v8, %v84533_v43 (stack40)
        %v84551_v26 = vshll.u32 %v84545_v8, 13 (stack45)
        %v84552_v53 = vshrl.u32 %v84545_v8, 19 (stack46)
        %v83769_v32 = vsel /*vm=*/%vm83767_vm14, /*on_true_vy=*/%v83768_v46, /*on_false_vx=*/%v83766_v60 (stack76)
        %v84144_v40 = vmul.f32 2.0, %v120194_v23 (stack54)
        %v84943_v29 = vxor.u32 %v84942_v25, %v84938_v41 (stack48)
        %v85355_v55 = vadd.s32 %v85352_v31, %v85347_v55 (stack40)
        %v83772_v9 = vadd.f32 -3.0, %v83769_v32 (stack53)
        %v84553_v61 = vor.u32 %v84552_v53, %v84551_v26 (stack47)
        %v85357_v21 = vshll.u32 %v85352_v31, 16 (stack45)
        %v85358_v20 = vshrl.u32 %v85352_v31, 16 (stack46)
        %v84148_v52 = vadd.f32 -0.99609375, %v84144_v40 (stack53)
        %v84946_v41 = vadd.s32 %v84943_v29, %v84938_v41 (stack40)
        %v84952_v43 = vshll.u32 %v84943_v29, 6 (stack45)
        %v84953_v8 = vshrl.u32 %v84943_v29, 26 (stack46)
        %v83757_v25 = vsel /*vm=*/%vm83720_vm10, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v146523_v30 = vsel /*vm=*/%vm83720_vm10, /*on_true_vy=*/%v146471_v30, /*on_false_vx=*/%v83772_v9 (stack44)
        %v84554_v46 = vxor.u32 %v84553_v61, %v84549_v34 (stack48)
        %v85359_v23 = vor.u32 %v85358_v20, %v85357_v21 (stack47)
        %v83780_v31 = vmul.f32 %v146523_v30, %v83757_v25 (stack54)
        %v146526_v60 = vmax.f32 %v84148_v52, -0.99609375 (stack55)
        %v84954_v26 = vor.u32 %v84953_v8, %v84952_v43 (stack47)
        %v146530_v53 = vadd.s32 %v146430_v22, %v122657_v58 (stack40)
        %v84557_v34 = vadd.s32 %v84554_v46, %v84549_v34 (stack40)
        %v84559_v32 = vshll.u32 %v84554_v46, 15 (stack45)
        %v84560_v40 = vshrl.u32 %v84554_v46, 17 (stack46)
        %v85360_v29 = vxor.u32 %v85359_v23, %v85355_v55 (stack48)
        %v83784_v6 = vadd.f32 %v83780_v31, %v83753_v6 (stack53)
        %v84164_v9 = vxor.u32 2147483648, %v146526_v60 (stack56)
        %v85766_v61 = vshll.u32 %v85761_v50, 15 (stack45)
        %v85767_v50 = vshrl.u32 %v85761_v50, 17 (stack46)
        %v83745_v21 = vsel /*vm=*/%vm83720_vm10, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v84561_v20 = vor.u32 %v84560_v40, %v84559_v32 (stack47)
        %v84955_v52 = vxor.u32 %v84954_v26, %v84946_v41 (stack48)
        %v85363_v55 = vadd.s32 %v85360_v29, %v85355_v55 (stack40)
        %v83749_v43 = vsel /*vm=*/%vm83720_vm10, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v83788_v8 = vmul.f32 %v83784_v6, %v146523_v30 (stack54)
        %v84167_v25 = vmul.f32 %v84164_v9, %v146526_v60 (stack54)
        %v86226_v46 = vadd.s32 1, %v146502_v45 (stack40)
        %v84562_v23 = vxor.u32 %v84561_v20, %v84557_v34 (stack48)
        %v84950_v41 = vadd.s32 %v84946_v41, %v121574_v2 (stack40)
        %v84958_v31 = vadd.s32 %v84955_v52, %v121569_v1 (stack40)
        %v85369_v26 = vshll.u32 %v85360_v29, 24 (stack45)
        %v83792_v32 = vadd.f32 %v83788_v8, %v83749_v43 (stack53)
        %v84169_v40 = vadd.f32 1.0, %v84167_v25 (stack57)
        %v85370_v29 = vshrl.u32 %v85360_v29, 8 (stack46)
        %v85768_v6 = vor.u32 %v85767_v50, %v85766_v61 (stack47)
        %vm86212_vm15 = vcmp.lt.u32.totalorder %v146530_v53, %v146430_v22 (stack43)
        %v84565_v34 = vadd.s32 %v84562_v23, %v84557_v34 (stack40)
        %v84567_v9 = vshll.u32 %v84562_v23, 26 (stack45)
        %v84568_v61 = vshrl.u32 %v84562_v23, 6 (stack46)
        %v84962_v50 = vadd.s32 3, %v84958_v31 (stack40)
        %v83796_v20 = vmul.f32 %v83792_v32, %v146523_v30 (stack54)
        %121149 = vlog2.f32 %v84169_v40 (stack58)
        %v85367_v52 = vadd.s32 %v85363_v55, %v121564_v0 (stack40)
        %v146550_v43 = vadd.s32 %v146530_v53, %v121569_v1 (stack40)
        %v84569_v8 = vor.u32 %v84568_v61, %v84567_v9 (stack47)
        %v84966_v23 = vadd.s32 %v84962_v50, %v84950_v41 (stack40)
        %v84968_v41 = vshll.u32 %v84962_v50, 17 (stack45)
        %v84969_v31 = vshrl.u32 %v84962_v50, 15 (stack46)
        %v83800_v21 = vadd.f32 %v83796_v20, %v83745_v21 (stack53)
        %v84172_v32 = vmul.f32 -0.5, %v84167_v25 (stack59)
        %v85371_v26 = vor.u32 %v85370_v29, %v85369_v26 (stack47)
        %v85769_v40 = vxor.u32 %v85768_v6, %v146510_v24 (stack48)
        %v84175_v29 = vand.u32 2147483647, %v84167_v25 (stack60)
        %v84570_v6 = vxor.u32 %v84569_v8, %v84565_v34 (stack48)
        %v84970_v9 = vor.u32 %v84969_v31, %v84968_v41 (stack47)
        %v86230_v45 = vsel /*vm=*/%vm86217_vm12, /*on_true_vy=*/%v86226_v46, /*on_false_vx=*/%v146502_v45 (stack44)
        %v83804_v46 = vmul.f32 %v83800_v21, %v146523_v30 (stack54)
        %v85372_v55 = vxor.u32 %v85371_v26, %v85363_v55 (stack48)
        %v85772_v24 = vadd.s32 %v85769_v40, %v146510_v24 (stack40)
        %v85774_v61 = vshll.u32 %v85769_v40, 26 (stack45)
        %v84573_v34 = vadd.s32 %v84570_v6, %v84565_v34 (stack40)
        %v84579_v50 = vshll.u32 %v84570_v6, 6 (stack45)
        %v84580_v20 = vshrl.u32 %v84570_v6, 26 (stack46)
        %v84971_v8 = vxor.u32 %v84970_v9, %v84966_v23 (stack48)
        %v83808_v54 = vadd.f32 %v83804_v46, %v146491_v54 (stack53)
        %v85375_v41 = vadd.s32 %v85372_v55, %v121574_v2 (stack40)
        %v85775_v31 = vshrl.u32 %v85769_v40, 6 (stack46)
        %v86234_v21 = vadd.s32 1, %v86230_v45 (stack40)
        %v84173_v32 = vadd.f32 1.0, %v84172_v32 (stack61)
        %v84581_v26 = vor.u32 %v84580_v20, %v84579_v50 (stack47)
        %v84974_v23 = vadd.s32 %v84971_v8, %v84966_v23 (stack40)
        %v84976_v40 = vshll.u32 %v84971_v8, 29 (stack45)
        %v83812_v6 = vmul.f32 %v83808_v54, %v146523_v30 (stack54)
        %v84977_v9 = vshrl.u32 %v84971_v8, 3 (stack46)
        %v85379_v46 = vadd.s32 2, %v85375_v41 (stack40)
        %v85776_v55 = vor.u32 %v85775_v31, %v85774_v61 (stack47)
        %vm146562_vm0 = vcmp.lt.f32.partialorder %v84175_v29, 0.0004427343 (stack62)
        %v84582_v61 = vxor.u32 %v84581_v26, %v84573_v34 (stack48)
        %v86238_v22 = vsel /*vm=*/%vm86212_vm15, /*on_true_vy=*/%v86234_v21, /*on_false_vx=*/%v86230_v45 (stack44)
        %v146571_v53 = vadd.s32 %v157614_v27, %v157070_v38 (stack40)
        %v83816_v7 = vadd.f32 %v83812_v6, %v146486_v7 (stack53)
        %v84978_v45 = vor.u32 %v84977_v9, %v84976_v40 (stack47)
        %v85383_v52 = vadd.s32 %v85379_v46, %v85367_v52 (stack40)
        %v85385_v50 = vshll.u32 %v85379_v46, 13 (stack45)
        %v84174_v25 = vmul.f32 %v84173_v32, %v84167_v25 (stack63)
        %v84585_v20 = vadd.s32 %v84582_v61, %v121574_v2 (stack40)
        %v85386_v8 = vshrl.u32 %v85379_v46, 19 (stack46)
        %v85777_v54 = vxor.u32 %v85776_v55, %v85772_v24 (stack48)
        %v83820_v41 = vmul.f32 %v83816_v7, %v146523_v30 (stack54)
        %v84979_v31 = vxor.u32 %v84978_v45, %v84974_v23 (stack48)
        %v86243_v21 = vadd.s32 %v86238_v22, %v121574_v2 (stack40)
        %v86253_v32 = vshll.u32 %v146550_v43, 13 (stack45)
        %v121150_v26 = vpop.eup %121149 (stack64)
        %v84577_v34 = vadd.s32 %v84573_v34, %v121564_v0 (stack40)
        %v84589_v40 = vadd.s32 5, %v84585_v20 (stack40)
        %v85387_v6 = vor.u32 %v85386_v8, %v85385_v50 (stack47)
        %v85780_v24 = vadd.s32 %v85777_v54, %v85772_v24 (stack40)
        %v83824_v44 = vadd.f32 %v83820_v41, %v146481_v44 (stack53)
        %v84171_v9 = vmul.f32 0.6931472, %v121150_v26 (stack65)
        %v84982_v23 = vadd.s32 %v84979_v31, %v84974_v23 (stack40)
        %v84984_v46 = vshll.u32 %v84979_v31, 16 (stack45)
        %v84591_v55 = vxor.u32 %v84589_v40, %v84577_v34 (stack48)
        %v84985_v61 = vshrl.u32 %v84979_v31, 16 (stack46)
        %v85388_v22 = vxor.u32 %v85387_v6, %v85383_v52 (stack48)
        %v86254_v7 = vshrl.u32 %v146550_v43, 19 (stack46)
        %v83828_v45 = vmul.f32 %v83824_v44, %v146523_v30 (stack54)
        %v84177_v29 = vsel /*vm=*/%vm146562_vm0, /*on_true_vy=*/%v84174_v25, /*on_false_vx=*/%v84171_v9 (stack66)
        %v85786_v50 = vshll.u32 %v85777_v54, 6 (stack45)
        %v86251_v43 = vadd.s32 %v146550_v43, %v86243_v21 (stack40)
        %v146585_v25 = vxor.u32 2147483648, %v84177_v29 (stack56)
        %v84986_v20 = vor.u32 %v84985_v61, %v84984_v46 (stack47)
        %v85391_v52 = vadd.s32 %v85388_v22, %v85383_v52 (stack40)
        %v85787_v8 = vshrl.u32 %v85777_v54, 26 (stack46)
        %v83693_v54 = vand.u32 2147483647, %v146390_v56 (stack77)
        %v83832_v12 = vadd.f32 %v83828_v45, %v146476_v12 (stack53)
        %121151 = vrsqrt.f32 %v146585_v25 (stack67)
        %v84592_v41 = vand.u32.u8 255, %v84591_v55 (stack49)
        %v83836_v30 = vmul.f32 %v83832_v12, %v146523_v30 (stack54)
        %v85393_v31 = vshll.u32 %v85388_v22, 15 (stack45)
        %v85394_v21 = vshrl.u32 %v85388_v22, 17 (stack46)
        %v83725_v10 = vsel /*vm=*/%vm83720_vm10, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v84987_v26 = vxor.u32 %v84986_v20, %v84982_v23 (stack48)
        %v85788_v34 = vor.u32 %v85787_v8, %v85786_v50 (stack47)
        %v86255_v32 = vor.u32 %v86254_v7, %v86253_v32 (stack47)
        %vm146594_vm1 = vcmp.eq.f32.partialorder %v83693_v54, 1.0 (stack68)
        %v83701_v6 = vmul.f32 inf, %v146390_v56 (stack54)
        %v83840_v44 = vadd.f32 %v83836_v30, %v83725_v10 (stack53)
        %v84154_v9 = vand.u32 2147483647, %v146526_v60 (stack77)
        %v84593_v46 = vand.u32 65535, %v84592_v41 (stack50)
        %v84990_v23 = vadd.s32 %v84987_v26, %v84982_v23 (stack40)
        %v85784_v55 = vadd.s32 %v85780_v24, %v121569_v1 (stack40)
        %v146603_v61 = vadd.s32 %v146571_v53, %v122657_v58 (stack40)
        %v83844_v56 = vmul.f32 %v83840_v44, %v146390_v56 (stack54)
        %v84996_v22 = vshll.u32 %v84987_v26, 24 (stack45)
        %v84997_v7 = vshrl.u32 %v84987_v26, 8 (stack46)
        %v85395_v45 = vor.u32 %v85394_v21, %v85393_v31 (stack47)
        %vm84181_vm2 = vcmp.lt.f32.partialorder %v146585_v25, 5.0 (stack68)
        %v146608_v29 = vadd.f32 -2.5, %v146585_v25 (stack53)
        %v84594_v50 = vshrl.u32 %v84593_v46, 1 (stack51)
        %v85789_v24 = vxor.u32 %v85788_v34, %v85780_v24 (stack48)
        %v86256_v20 = vxor.u32 %v86255_v32, %v86251_v43 (stack48)
        %v83848_v8 = vsel /*vm=*/%vm146594_vm1, /*on_true_vy=*/%v83701_v6, /*on_false_vx=*/%v83844_v56 (stack44)
        %vm84226_vm3 = vcmp.eq.f32.partialorder %v146585_v25, inf (stack70)
        %v84229_v54 = vand.u32 2147483648, %v146585_v25 (stack72)
        %v84998_v12 = vor.u32 %v84997_v7, %v84996_v22 (stack47)
        %v85396_v41 = vxor.u32 %v85395_v45, %v85391_v52 (stack48)
        %v83852_v30 = vmul.f32 1.4140625, %v83848_v8 (stack54)
        %vm84228_vm4 = vcmp.eq.f32.partialorder %v146585_v25, 0.0 (stack71)
        %v84595_v31 = vor.u32 16256, %v84594_v50 (stack47)
        %v85792_v21 = vadd.s32 %v85789_v24, %v121564_v0 (stack40)
        %v86259_v43 = vadd.s32 %v86256_v20, %v86251_v43 (stack40)
        %v84999_v10 = vxor.u32 %v84998_v12, %v84990_v23 (stack48)
        %v85399_v52 = vadd.s32 %v85396_v41, %v85391_v52 (stack40)
        %v85401_v26 = vshll.u32 %v85396_v41, 26 (stack45)
        %v85402_v34 = vshrl.u32 %v85396_v41, 6 (stack46)
        %v83855_v32 = vpack.c.bf16 %v157387_v11, %v83852_v30 (stack81)
        %v84596_v40 = vand.u32.u16 65535, %v84595_v31 (stack52)
        %v85796_v6 = vadd.s32 1, %v85792_v21 (stack40)
        %v86261_v44 = vshll.u32 %v86256_v20, 15 (stack45)
        %v85002_v46 = vadd.s32 %v84999_v10, %v121564_v0 (stack40)
        %v85403_v56 = vor.u32 %v85402_v34, %v85401_v26 (stack47)
        %v86262_v22 = vshrl.u32 %v86256_v20, 17 (stack46)
        %vm86678_vm5 = vcmp.lt.u32.totalorder %v146571_v53, %v157070_v38 (stack43)
        %120193 = vst [vmem:[%s123356_s30 + $0x158] sm:$0xf] /*vst_source=*/%v83855_v32 (stack83)
        %v120196_v7 = vadd.low.f32.bf16 -1.0, %v84596_v40 (stack53)
        %v85800_v55 = vadd.s32 %v85796_v6, %v85784_v55 (stack40)
        %v85802_v45 = vshll.u32 %v85796_v6, 17 (stack45)
        %v85803_v50 = vshrl.u32 %v85796_v6, 15 (stack46)
        %v121152_v24 = vpop.eup %121151 (stack73)
        %v84994_v23 = vadd.s32 %v84990_v23, %v121569_v1 (stack40)
        %v85006_v20 = vadd.s32 4, %v85002_v46 (stack40)
        %v85404_v8 = vxor.u32 %v85403_v56, %v85399_v52 (stack48)
        %v146624_v12 = vadd.s32 %v157617_v42, %v157076_v35 (stack40)
        %v84225_v41 = vmul.f32 %v121152_v24, %v146585_v25 (stack74)
        %v84605_v30 = vmul.f32 2.0, %v120196_v7 (stack54)
        %v85804_v31 = vor.u32 %v85803_v50, %v85802_v45 (stack47)
        %v86263_v21 = vor.u32 %v86262_v22, %v86261_v44 (stack47)
        %v85010_v10 = vadd.s32 %v85006_v20, %v84994_v23 (stack40)
        %v85012_v26 = vshll.u32 %v85006_v20, 13 (stack45)
        %v85013_v34 = vshrl.u32 %v85006_v20, 19 (stack46)
        %v85407_v52 = vadd.s32 %v85404_v8, %v85399_v52 (stack40)
        %v84227_v32 = vsel /*vm=*/%vm84226_vm3, /*on_true_vy=*/%v146585_v25, /*on_false_vx=*/%v84225_v41 (stack75)
        %v84609_v40 = vadd.f32 -0.99609375, %v84605_v30 (stack53)
        %v85413_v6 = vshll.u32 %v85404_v8, 6 (stack45)
        %v85414_v44 = vshrl.u32 %v85404_v8, 26 (stack46)
        %v146633_v46 = vsel /*vm=*/%vm84181_vm2, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v84230_v54 = vsel /*vm=*/%vm84228_vm4, /*on_true_vy=*/%v84229_v54, /*on_false_vx=*/%v84227_v32 (stack76)
        %v85014_v56 = vor.u32 %v85013_v34, %v85012_v26 (stack47)
        %v85805_v22 = vxor.u32 %v85804_v31, %v85800_v55 (stack48)
        %v84233_v7 = vadd.f32 -3.0, %v84230_v54 (stack53)
        %v146637_v45 = vmax.f32 %v84609_v40, -0.99609375 (stack55)
        %v85415_v50 = vor.u32 %v85414_v44, %v85413_v6 (stack47)
        %v86264_v24 = vxor.u32 %v86263_v21, %v86259_v43 (stack48)
        %v85015_v23 = vxor.u32 %v85014_v56, %v85010_v10 (stack48)
        %v85808_v55 = vadd.s32 %v85805_v22, %v85800_v55 (stack40)
        %v85810_v20 = vshll.u32 %v85805_v22, 29 (stack45)
        %v85811_v8 = vshrl.u32 %v85805_v22, 3 (stack46)
        %v146642_v41 = vsel /*vm=*/%vm84181_vm2, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v84218_v30 = vsel /*vm=*/%vm84181_vm2, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v146650_v29 = vsel /*vm=*/%vm84181_vm2, /*on_true_vy=*/%v146608_v29, /*on_false_vx=*/%v84233_v7 (stack44)
        %v84625_v31 = vxor.u32 2147483648, %v146637_v45 (stack56)
        %v84241_v21 = vmul.f32 %v146650_v29, %v84218_v30 (stack54)
        %v85018_v10 = vadd.s32 %v85015_v23, %v85010_v10 (stack40)
        %v85020_v26 = vshll.u32 %v85015_v23, 15 (stack45)
        %v85021_v34 = vshrl.u32 %v85015_v23, 17 (stack46)
        %v84214_v32 = vsel /*vm=*/%vm84181_vm2, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v146658_v40 = vmul.f32 %v84625_v31, %v146637_v45 (stack54)
        %v85416_v6 = vxor.u32 %v85415_v50, %v85407_v52 (stack48)
        %v85812_v44 = vor.u32 %v85811_v8, %v85810_v20 (stack47)
        %v84202_v54 = vsel /*vm=*/%vm84181_vm2, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v84245_v56 = vadd.f32 %v84241_v21, %v84214_v32 (stack53)
        %v85022_v22 = vor.u32 %v85021_v34, %v85020_v26 (stack47)
        %v86267_v43 = vadd.s32 %v86264_v24, %v86259_v43 (stack40)
        %v84210_v7 = vsel /*vm=*/%vm84181_vm2, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v84630_v50 = vadd.f32 1.0, %v146658_v40 (stack57)
        %v85411_v52 = vadd.s32 %v85407_v52, %v121574_v2 (stack40)
        %v85419_v23 = vadd.s32 %v85416_v6, %v121569_v1 (stack40)
        %v84249_v20 = vmul.f32 %v84245_v56, %v146650_v29 (stack54)
        %v85023_v8 = vxor.u32 %v85022_v22, %v85018_v10 (stack48)
        %v85813_v30 = vxor.u32 %v85812_v44, %v85808_v55 (stack48)
        %v86269_v31 = vshll.u32 %v86264_v24, 26 (stack45)
        %121153 = vlog2.f32 %v84630_v50 (stack58)
        %v84633_v21 = vmul.f32 -0.5, %v146658_v40 (stack59)
        %v85423_v26 = vadd.s32 3, %v85419_v23 (stack40)
        %v86270_v24 = vshrl.u32 %v86264_v24, 6 (stack46)
        %v84253_v34 = vadd.f32 %v84249_v20, %v84210_v7 (stack53)
        %v85026_v10 = vadd.s32 %v85023_v8, %v85018_v10 (stack40)
        %v85028_v32 = vshll.u32 %v85023_v8, 26 (stack45)
        %v85029_v6 = vshrl.u32 %v85023_v8, 6 (stack46)
        %v84206_v44 = vsel /*vm=*/%vm84181_vm2, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v85427_v56 = vadd.s32 %v85423_v26, %v85411_v52 (stack40)
        %v85429_v22 = vshll.u32 %v85423_v26, 17 (stack45)
        %v85430_v7 = vshrl.u32 %v85423_v26, 15 (stack46)
        %v84257_v50 = vmul.f32 %v84253_v34, %v146650_v29 (stack54)
        %v85030_v52 = vor.u32 %v85029_v6, %v85028_v32 (stack47)
        %v85816_v55 = vadd.s32 %v85813_v30, %v85808_v55 (stack40)
        %v85818_v23 = vshll.u32 %v85813_v30, 16 (stack45)
        %v85431_v20 = vor.u32 %v85430_v7, %v85429_v22 (stack47)
        %v85819_v8 = vshrl.u32 %v85813_v30, 16 (stack46)
        %v86271_v30 = vor.u32 %v86270_v24, %v86269_v31 (stack47)
        %v86687_v31 = vadd.s32 1, %v146624_v12 (stack40)
        %v84261_v26 = vadd.f32 %v84257_v50, %v84206_v44 (stack53)
        %v84634_v21 = vadd.f32 1.0, %v84633_v21 (stack61)
        %v84636_v24 = vand.u32 2147483647, %v146658_v40 (stack60)
        %v85031_v34 = vxor.u32 %v85030_v52, %v85026_v10 (stack48)
        %vm86673_vm6 = vcmp.lt.u32.totalorder %v146603_v61, %v146571_v53 (stack43)
        %v85432_v32 = vxor.u32 %v85431_v20, %v85427_v56 (stack48)
        %v85820_v6 = vor.u32 %v85819_v8, %v85818_v23 (stack47)
        %v86272_v44 = vxor.u32 %v86271_v30, %v86267_v43 (stack48)
        %v86691_v12 = vsel /*vm=*/%vm86678_vm5, /*on_true_vy=*/%v86687_v31, /*on_false_vx=*/%v146624_v12 (stack44)
        %v84265_v22 = vmul.f32 %v84261_v26, %v146650_v29 (stack54)
        %v85034_v10 = vadd.s32 %v85031_v34, %v85026_v10 (stack40)
        %v85040_v7 = vshll.u32 %v85031_v34, 6 (stack45)
        %v85041_v50 = vshrl.u32 %v85031_v34, 26 (stack46)
        %v85435_v56 = vadd.s32 %v85432_v32, %v85427_v56 (stack40)
        %v85437_v52 = vshll.u32 %v85432_v32, 29 (stack45)
        %v85438_v23 = vshrl.u32 %v85432_v32, 3 (stack46)
        %v85821_v20 = vxor.u32 %v85820_v6, %v85816_v55 (stack48)
        %v84269_v54 = vadd.f32 %v84265_v22, %v84202_v54 (stack53)
        %v85042_v8 = vor.u32 %v85041_v50, %v85040_v7 (stack47)
        %v146684_v43 = vadd.s32 %v86272_v44, %v86267_v43 (stack40)
        %v146688_v30 = vadd.s32 %v146603_v61, %v121569_v1 (stack40)
        %v85439_v31 = vor.u32 %v85438_v23, %v85437_v52 (stack47)
        %v85824_v55 = vadd.s32 %v85821_v20, %v85816_v55 (stack40)
        %v85830_v26 = vshll.u32 %v85821_v20, 24 (stack45)
        %v85831_v34 = vshrl.u32 %v85821_v20, 8 (stack46)
        %v84273_v32 = vmul.f32 %v84269_v54, %v146650_v29 (stack54)
        %vm146691_vm7 = vcmp.lt.f32.partialorder %v84636_v24, 0.0004427343 (stack62)
        %v85043_v6 = vxor.u32 %v85042_v8, %v85034_v10 (stack48)
        %v86281_v22 = vshll.u32 %v86272_v44, 6 (stack45)
        %v84635_v40 = vmul.f32 %v84634_v21, %v146658_v40 (stack63)
        %v85440_v21 = vxor.u32 %v85439_v31, %v85435_v56 (stack48)
        %v85832_v7 = vor.u32 %v85831_v34, %v85830_v26 (stack47)
        %v86282_v44 = vshrl.u32 %v86272_v44, 26 (stack46)
        %v121154_v50 = vpop.eup %121153 (stack64)
        %v84277_v41 = vadd.f32 %v84273_v32, %v146642_v41 (stack53)
        %v85038_v10 = vadd.s32 %v85034_v10, %v121564_v0 (stack40)
        %v85046_v52 = vadd.s32 %v85043_v6, %v121574_v2 (stack40)
        %v86695_v23 = vadd.s32 1, %v86691_v12 (stack40)
        %v84632_v20 = vmul.f32 0.6931472, %v121154_v50 (stack65)
        %v85443_v56 = vadd.s32 %v85440_v21, %v85435_v56 (stack40)
        %v85445_v54 = vshll.u32 %v85440_v21, 16 (stack45)
        %v85446_v8 = vshrl.u32 %v85440_v21, 16 (stack46)
        %v84281_v31 = vmul.f32 %v84277_v41, %v146650_v29 (stack54)
        %v85050_v26 = vadd.s32 5, %v85046_v52 (stack40)
        %v85833_v34 = vxor.u32 %v85832_v7, %v85824_v55 (stack48)
        %v86283_v32 = vor.u32 %v86282_v44, %v86281_v22 (stack47)
        %v84638_v24 = vsel /*vm=*/%vm146691_vm7, /*on_true_vy=*/%v84635_v40, /*on_false_vx=*/%v84632_v20 (stack66)
        %v85447_v6 = vor.u32 %v85446_v8, %v85445_v54 (stack47)
        %v86699_v53 = vsel /*vm=*/%vm86673_vm6, /*on_true_vy=*/%v86695_v23, /*on_false_vx=*/%v86691_v12 (stack44)
        %v146707_v61 = vadd.s32 %v157614_v27, %v157077_v51 (stack40)
        %v84285_v46 = vadd.f32 %v84281_v31, %v146633_v46 (stack53)
        %v146710_v12 = vxor.u32 2147483648, %v84638_v24 (stack56)
        %v85052_v22 = vxor.u32 %v85050_v26, %v85038_v10 (stack48)
        %v85448_v40 = vxor.u32 %v85447_v6, %v85443_v56 (stack48)
        %v86284_v21 = vxor.u32 %v86283_v32, %v146684_v43 (stack48)
        %v86714_v7 = vshll.u32 %v146688_v30, 13 (stack45)
        %v86715_v44 = vshrl.u32 %v146688_v30, 19 (stack46)
        %v84162_v50 = vmul.f32 inf, %v146526_v60 (stack54)
        %v84289_v41 = vmul.f32 %v84285_v46, %v146650_v29 (stack54)
        %121155 = vrsqrt.f32 %v146710_v12 (stack67)
        %vm146720_vm8 = vcmp.eq.f32.partialorder %v84154_v9, 1.0 (stack68)
        %v84190_v10 = vsel /*vm=*/%vm84181_vm2, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %vm84642_vm9 = vcmp.lt.f32.partialorder %v146710_v12, 5.0 (stack68)
        %v85451_v52 = vadd.s32 %v85448_v40, %v85443_v56 (stack40)
        %v85836_v23 = vadd.s32 %v85833_v34, %v121574_v2 (stack40)
        %v84186_v25 = vsel /*vm=*/%vm84181_vm2, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v84293_v20 = vadd.f32 %v84289_v41, %v84190_v10 (stack53)
        %v84615_v56 = vand.u32 2147483647, %v146637_v45 (stack77)
        %v86704_v54 = vadd.s32 %v86699_v53, %v121574_v2 (stack40)
        %v85828_v55 = vadd.s32 %v85824_v55, %v121564_v0 (stack40)
        %v86279_v43 = vadd.s32 %v146684_v43, %v121569_v1 (stack40)
        %v86716_v8 = vor.u32 %v86715_v44, %v86714_v7 (stack47)
        %v146739_v31 = vadd.s32 %v146707_v61, %v122657_v58 (stack40)
        %v84297_v29 = vmul.f32 %v84293_v20, %v146650_v29 (stack54)
        %v146745_v26 = vsel /*vm=*/%vm84642_vm9, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v146748_v34 = vadd.f32 -2.5, %v146710_v12 (stack53)
        %v85455_v32 = vadd.s32 %v85451_v52, %v121569_v1 (stack40)
        %v85053_v24 = vand.u32.u8 255, %v85052_v22 (stack49)
        %v85457_v6 = vshll.u32 %v85448_v40, 24 (stack45)
        %v85458_v53 = vshrl.u32 %v85448_v40, 8 (stack46)
        %v85840_v46 = vadd.s32 2, %v85836_v23 (stack40)
        %v84301_v22 = vadd.f32 %v84297_v29, %v84186_v25 (stack53)
        %v84690_v40 = vand.u32 2147483648, %v146710_v12 (stack72)
        %v86287_v21 = vadd.s32 %v86284_v21, %v121564_v0 (stack40)
        %v86712_v30 = vadd.s32 %v146688_v30, %v86704_v54 (stack40)
        %vm84687_vm10 = vcmp.eq.f32.partialorder %v146710_v12, inf (stack70)
        %v85054_v7 = vand.u32 65535, %v85053_v24 (stack50)
        %v85459_v44 = vor.u32 %v85458_v53, %v85457_v6 (stack47)
        %v85844_v41 = vadd.s32 %v85840_v46, %v85828_v55 (stack40)
        %v85846_v10 = vshll.u32 %v85840_v46, 13 (stack45)
        %v84305_v60 = vmul.f32 %v84301_v22, %v146526_v60 (stack54)
        %vm84689_vm11 = vcmp.eq.f32.partialorder %v146710_v12, 0.0 (stack71)
        %v85847_v23 = vshrl.u32 %v85840_v46, 19 (stack46)
        %v86291_v25 = vadd.s32 1, %v86287_v21 (stack40)
        %v86717_v20 = vxor.u32 %v86716_v8, %v86712_v30 (stack48)
        %v85055_v54 = vshrl.u32 %v85054_v7, 1 (stack51)
        %v85460_v52 = vxor.u32 %v85459_v44, %v85451_v52 (stack48)
        %vm87139_vm12 = vcmp.lt.u32.totalorder %v146707_v61, %v157077_v51 (stack43)
        %v146761_v55 = vadd.s32 %v157617_v42, %v157078_v48 (stack40)
        %v84309_v50 = vsel /*vm=*/%vm146720_vm8, /*on_true_vy=*/%v84162_v50, /*on_false_vx=*/%v84305_v60 (stack44)
        %v85848_v9 = vor.u32 %v85847_v23, %v85846_v10 (stack47)
        %v86295_v43 = vadd.s32 %v86291_v25, %v86279_v43 (stack40)
        %v86297_v8 = vshll.u32 %v86291_v25, 17 (stack45)
        %v84313_v29 = vmul.f32 1.4140625, %v84309_v50 (stack54)
        %v85056_v24 = vor.u32 16256, %v85055_v54 (stack47)
        %v85463_v6 = vadd.s32 %v85460_v52, %v121564_v0 (stack40)
        %v86298_v53 = vshrl.u32 %v86291_v25, 15 (stack46)
        %v85849_v46 = vxor.u32 %v85848_v9, %v85844_v41 (stack48)
        %v86720_v22 = vadd.s32 %v86717_v20, %v86712_v30 (stack40)
        %v86722_v21 = vshll.u32 %v86717_v20, 15 (stack45)
        %v86723_v30 = vshrl.u32 %v86717_v20, 17 (stack46)
        %v121156_v7 = vpop.eup %121155 (stack73)
        %v84316_v44 = vpack.c.bf16 %v157387_v11, %v84313_v29 (stack81)
        %v85057_v10 = vand.u32.u16 65535, %v85056_v24 (stack52)
        %v85467_v60 = vadd.s32 4, %v85463_v6 (stack40)
        %v86299_v23 = vor.u32 %v86298_v53, %v86297_v8 (stack47)
        %v84686_v25 = vmul.f32 %v121156_v7, %v146710_v12 (stack74)
        %v85852_v41 = vadd.s32 %v85849_v46, %v85844_v41 (stack40)
        %v85854_v20 = vshll.u32 %v85849_v46, 15 (stack45)
        %v85855_v54 = vshrl.u32 %v85849_v46, 17 (stack46)
        %120195 = vst [vmem:[%s123356_s30 + $0x1d8] sm:$0xf] /*vst_source=*/%v84316_v44 (stack83)
        %v120198_v52 = vadd.low.f32.bf16 -1.0, %v85057_v10 (stack53)
        %v85471_v32 = vadd.s32 %v85467_v60, %v85455_v32 (stack40)
        %v85473_v50 = vshll.u32 %v85467_v60, 13 (stack45)
        %v85474_v9 = vshrl.u32 %v85467_v60, 19 (stack46)
        %v84688_v8 = vsel /*vm=*/%vm84687_vm10, /*on_true_vy=*/%v146710_v12, /*on_false_vx=*/%v84686_v25 (stack75)
        %v85856_v29 = vor.u32 %v85855_v54, %v85854_v20 (stack47)
        %v86300_v24 = vxor.u32 %v86299_v23, %v86295_v43 (stack48)
        %v86724_v6 = vor.u32 %v86723_v30, %v86722_v21 (stack47)
        %v84679_v53 = vsel /*vm=*/%vm84642_vm9, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v84691_v40 = vsel /*vm=*/%vm84689_vm11, /*on_true_vy=*/%v84690_v40, /*on_false_vx=*/%v84688_v8 (stack76)
        %v85066_v46 = vmul.f32 2.0, %v120198_v52 (stack54)
        %v85475_v21 = vor.u32 %v85474_v9, %v85473_v50 (stack47)
        %v84694_v30 = vadd.f32 -3.0, %v84691_v40 (stack53)
        %v85857_v7 = vxor.u32 %v85856_v29, %v85852_v41 (stack48)
        %v86303_v43 = vadd.s32 %v86300_v24, %v86295_v43 (stack40)
        %v86305_v44 = vshll.u32 %v86300_v24, 29 (stack45)
        %v85070_v10 = vadd.f32 -0.99609375, %v85066_v46 (stack53)
        %v85476_v60 = vxor.u32 %v85475_v21, %v85471_v32 (stack48)
        %v86306_v23 = vshrl.u32 %v86300_v24, 3 (stack46)
        %v86725_v25 = vxor.u32 %v86724_v6, %v86720_v22 (stack48)
        %v146780_v34 = vsel /*vm=*/%vm84642_vm9, /*on_true_vy=*/%v146748_v34, /*on_false_vx=*/%v84694_v30 (stack44)
        %v85860_v41 = vadd.s32 %v85857_v7, %v85852_v41 (stack40)
        %v85862_v20 = vshll.u32 %v85857_v7, 26 (stack45)
        %v85863_v54 = vshrl.u32 %v85857_v7, 6 (stack46)
        %v84702_v52 = vmul.f32 %v146780_v34, %v84679_v53 (stack54)
        %v146783_v50 = vmax.f32 %v85070_v10, -0.99609375 (stack55)
        %v85479_v32 = vadd.s32 %v85476_v60, %v85471_v32 (stack40)
        %v85481_v9 = vshll.u32 %v85476_v60, 15 (stack45)
        %v85482_v8 = vshrl.u32 %v85476_v60, 17 (stack46)
        %v85864_v29 = vor.u32 %v85863_v54, %v85862_v20 (stack47)
        %v86307_v24 = vor.u32 %v86306_v23, %v86305_v44 (stack47)
        %v86728_v22 = vadd.s32 %v86725_v25, %v86720_v22 (stack40)
        %v146788_v6 = vsel /*vm=*/%vm84642_vm9, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v146793_v53 = vsel /*vm=*/%vm84642_vm9, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v84706_v26 = vadd.f32 %v84702_v52, %v146745_v26 (stack53)
        %v85086_v40 = vxor.u32 2147483648, %v146783_v50 (stack56)
        %v84659_v46 = vsel /*vm=*/%vm84642_vm9, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v85483_v21 = vor.u32 %v85482_v8, %v85481_v9 (stack47)
        %v85865_v30 = vxor.u32 %v85864_v29, %v85860_v41 (stack48)
        %v86308_v7 = vxor.u32 %v86307_v24, %v86303_v43 (stack48)
        %v84663_v44 = vsel /*vm=*/%vm84642_vm9, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v84671_v10 = vsel /*vm=*/%vm84642_vm9, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v84710_v60 = vmul.f32 %v84706_v26, %v146780_v34 (stack54)
        %v85089_v23 = vmul.f32 %v85086_v40, %v146783_v50 (stack54)
        %v85484_v20 = vxor.u32 %v85483_v21, %v85479_v32 (stack48)
        %v85868_v41 = vadd.s32 %v85865_v30, %v85860_v41 (stack40)
        %v85874_v54 = vshll.u32 %v85865_v30, 6 (stack45)
        %v85875_v52 = vshrl.u32 %v85865_v30, 26 (stack46)
        %v84714_v9 = vadd.f32 %v84710_v60, %v84671_v10 (stack53)
        %v85091_v8 = vadd.f32 1.0, %v85089_v23 (stack57)
        %v86730_v29 = vshll.u32 %v86725_v25, 26 (stack45)
        %v86731_v25 = vshrl.u32 %v86725_v25, 6 (stack46)
        %v84667_v24 = vsel /*vm=*/%vm84642_vm9, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v85487_v32 = vadd.s32 %v85484_v20, %v85479_v32 (stack40)
        %v85489_v26 = vshll.u32 %v85484_v20, 26 (stack45)
        %v85490_v40 = vshrl.u32 %v85484_v20, 6 (stack46)
        %v84718_v21 = vmul.f32 %v84714_v9, %v146780_v34 (stack54)
        %121157 = vlog2.f32 %v85091_v8 (stack58)
        %v85094_v30 = vmul.f32 -0.5, %v85089_v23 (stack59)
        %vm87134_vm13 = vcmp.lt.u32.totalorder %v146739_v31, %v146707_v61 (stack43)
        %v87148_v10 = vadd.s32 1, %v146761_v55 (stack40)
        %v85491_v60 = vor.u32 %v85490_v40, %v85489_v26 (stack47)
        %v85876_v20 = vor.u32 %v85875_v52, %v85874_v54 (stack47)
        %v86311_v43 = vadd.s32 %v86308_v7, %v86303_v43 (stack40)
        %v86313_v54 = vshll.u32 %v86308_v7, 16 (stack45)
        %v84722_v52 = vadd.f32 %v84718_v21, %v84667_v24 (stack53)
        %v85097_v9 = vand.u32 2147483647, %v85089_v23 (stack60)
        %v86314_v7 = vshrl.u32 %v86308_v7, 16 (stack46)
        %v86732_v8 = vor.u32 %v86731_v25, %v86730_v29 (stack47)
        %v85492_v29 = vxor.u32 %v85491_v60, %v85487_v32 (stack48)
        %v85872_v25 = vadd.s32 %v85868_v41, %v121574_v2 (stack40)
        %v85877_v41 = vxor.u32 %v85876_v20, %v85868_v41 (stack48)
        %v87152_v55 = vsel /*vm=*/%vm87139_vm12, /*on_true_vy=*/%v87148_v10, /*on_false_vx=*/%v146761_v55 (stack44)
        %v84726_v24 = vmul.f32 %v84722_v52, %v146780_v34 (stack54)
        %v85095_v26 = vadd.f32 1.0, %v85094_v30 (stack61)
        %v86315_v40 = vor.u32 %v86314_v7, %v86313_v54 (stack47)
        %v86733_v21 = vxor.u32 %v86732_v8, %v86728_v22 (stack48)
        %v85495_v32 = vadd.s32 %v85492_v29, %v85487_v32 (stack40)
        %v85501_v30 = vshll.u32 %v85492_v29, 6 (stack45)
        %v85502_v10 = vshrl.u32 %v85492_v29, 26 (stack46)
        %v85880_v60 = vadd.s32 %v85877_v41, %v121569_v1 (stack40)
        %v84730_v44 = vadd.f32 %v84726_v24, %v84663_v44 (stack53)
        %v86316_v20 = vxor.u32 %v86315_v40, %v86311_v43 (stack48)
        %v146822_v22 = vadd.s32 %v86733_v21, %v86728_v22 (stack40)
        %v87156_v54 = vadd.s32 1, %v87152_v55 (stack40)
        %v85503_v52 = vor.u32 %v85502_v10, %v85501_v30 (stack47)
        %v85884_v7 = vadd.s32 3, %v85880_v60 (stack40)
        %v86742_v8 = vshll.u32 %v86733_v21, 6 (stack45)
        %v86743_v29 = vshrl.u32 %v86733_v21, 26 (stack46)
        %v84734_v41 = vmul.f32 %v84730_v44, %v146780_v34 (stack54)
        %v86319_v43 = vadd.s32 %v86316_v20, %v86311_v43 (stack40)
        %v86325_v24 = vshll.u32 %v86316_v20, 24 (stack45)
        %v86326_v40 = vshrl.u32 %v86316_v20, 8 (stack46)
        %v85504_v21 = vxor.u32 %v85503_v52, %v85495_v32 (stack48)
        %v85888_v25 = vadd.s32 %v85884_v7, %v85872_v25 (stack40)
        %v85890_v30 = vshll.u32 %v85884_v7, 17 (stack45)
        %v85891_v10 = vshrl.u32 %v85884_v7, 15 (stack46)
        %v84738_v46 = vadd.f32 %v84734_v41, %v84659_v46 (stack53)
        %v85096_v23 = vmul.f32 %v85095_v26, %v85089_v23 (stack63)
        %vm146825_vm14 = vcmp.lt.f32.partialorder %v85097_v9, 0.0004427343 (stack62)
        %v86327_v26 = vor.u32 %v86326_v40, %v86325_v24 (stack47)
        %v85507_v60 = vadd.s32 %v85504_v21, %v121574_v2 (stack40)
        %v85892_v44 = vor.u32 %v85891_v10, %v85890_v30 (stack47)
        %v86744_v20 = vor.u32 %v86743_v29, %v86742_v8 (stack47)
        %v87160_v61 = vsel /*vm=*/%vm87134_vm13, /*on_true_vy=*/%v87156_v54, /*on_false_vx=*/%v87152_v55 (stack44)
        %v84742_v55 = vmul.f32 %v84738_v46, %v146780_v34 (stack54)
        %v86328_v54 = vxor.u32 %v86327_v26, %v86319_v43 (stack48)
        %v87165_v52 = vadd.s32 %v87160_v61, %v121574_v2 (stack40)
        %v87169_v31 = vadd.s32 %v146739_v31, %v121569_v1 (stack40)
        %v121158_v7 = vpop.eup %121157 (stack64)
        %v85499_v32 = vadd.s32 %v85495_v32, %v121564_v0 (stack40)
        %v85511_v8 = vadd.s32 5, %v85507_v60 (stack40)
        %v85893_v29 = vxor.u32 %v85892_v44, %v85888_v25 (stack48)
        %v86745_v41 = vxor.u32 %v86744_v20, %v146822_v22 (stack48)
        %v84746_v53 = vadd.f32 %v84742_v55, %v146793_v53 (stack53)
        %v85093_v24 = vmul.f32 0.6931472, %v121158_v7 (stack65)
        %v86331_v40 = vadd.s32 %v86328_v54, %v121574_v2 (stack40)
        %v87173_v21 = vadd.s32 %v87169_v31, %v87165_v52 (stack40)
        %v85513_v30 = vxor.u32 %v85511_v8, %v85499_v32 (stack48)
        %v85896_v25 = vadd.s32 %v85893_v29, %v85888_v25 (stack40)
        %v85898_v10 = vshll.u32 %v85893_v29, 29 (stack45)
        %v85899_v46 = vshrl.u32 %v85893_v29, 3 (stack46)
        %v84750_v26 = vmul.f32 %v84746_v53, %v146780_v34 (stack54)
        %v85099_v23 = vsel /*vm=*/%vm146825_vm14, /*on_true_vy=*/%v85096_v23, /*on_false_vx=*/%v85093_v24 (stack66)
        %v86323_v43 = vadd.s32 %v86319_v43, %v121564_v0 (stack40)
        %v86335_v9 = vadd.s32 2, %v86331_v40 (stack40)
        %v146845_v60 = vxor.u32 2147483648, %v85099_v23 (stack56)
        %v85900_v44 = vor.u32 %v85899_v46, %v85898_v10 (stack47)
        %v87175_v20 = vshll.u32 %v87169_v31, 13 (stack45)
        %v87176_v61 = vshrl.u32 %v87169_v31, 19 (stack46)
        %v84754_v6 = vadd.f32 %v84750_v26, %v146788_v6 (stack53)
        %v86339_v55 = vadd.s32 %v86335_v9, %v86323_v43 (stack40)
        %vm146850_vm15 = vcmp.eq.f32.partialorder %v84615_v56, 1.0 (stack68)
        %v84623_v54 = vmul.f32 inf, %v146637_v45 (stack54)
        %121159 = vrsqrt.f32 %v146845_v60 (stack67)
        %v85514_v52 = vand.u32.u8 255, %v85513_v30 (stack49)
        %v84758_v34 = vmul.f32 %v84754_v6, %v146780_v34 (stack54)
        %vm85103_vm0 = vcmp.lt.f32.partialorder %v146845_v60, 5.0 (stack68)
        %v86341_v31 = vshll.u32 %v86335_v9, 13 (stack45)
        %v86342_v7 = vshrl.u32 %v86335_v9, 19 (stack46)
        %v84647_v12 = vsel /*vm=*/%vm84642_vm9, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v85901_v32 = vxor.u32 %v85900_v44, %v85896_v25 (stack48)
        %v86748_v8 = vadd.s32 %v86745_v41, %v121564_v0 (stack40)
        %v87177_v29 = vor.u32 %v87176_v61, %v87175_v20 (stack47)
        %v84762_v41 = vadd.f32 %v84758_v34, %v84647_v12 (stack53)
        %v85076_v53 = vand.u32 2147483647, %v146783_v50 (stack77)
        %v146864_v24 = vadd.f32 -2.5, %v146845_v60 (stack53)
        %v86740_v22 = vadd.s32 %v146822_v22, %v121569_v1 (stack40)
        %v146871_v40 = vsel /*vm=*/%vm85103_vm0, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v146876_v30 = vsel /*vm=*/%vm85103_vm0, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v85515_v10 = vand.u32 65535, %v85514_v52 (stack50)
        %v85904_v25 = vadd.s32 %v85901_v32, %v85896_v25 (stack40)
        %v84766_v45 = vmul.f32 %v84762_v41, %v146637_v45 (stack54)
        %v85906_v46 = vshll.u32 %v85901_v32, 16 (stack45)
        %v85907_v26 = vshrl.u32 %v85901_v32, 16 (stack46)
        %v86343_v23 = vor.u32 %v86342_v7, %v86341_v31 (stack47)
        %v85516_v43 = vshrl.u32 %v85515_v10, 1 (stack51)
        %v86752_v9 = vadd.s32 1, %v86748_v8 (stack40)
        %v87178_v44 = vxor.u32 %v87177_v29, %v87173_v21 (stack48)
        %v146881_v20 = vadd.s32 %v157614_v27, %v157079_v39 (stack40)
        %v84770_v61 = vsel /*vm=*/%vm146850_vm15, /*on_true_vy=*/%v84623_v54, /*on_false_vx=*/%v84766_v45 (stack44)
        %vm85148_vm1 = vcmp.eq.f32.partialorder %v146845_v60, inf (stack70)
        %v85908_v6 = vor.u32 %v85907_v26, %v85906_v46 (stack47)
        %v86344_v56 = vxor.u32 %v86343_v23, %v86339_v55 (stack48)
        %v146888_v54 = vadd.s32 %v157617_v42, %v157082_v49 (stack40)
        %v84774_v52 = vmul.f32 1.4140625, %v84770_v61 (stack54)
        %v85517_v34 = vor.u32 16256, %v85516_v43 (stack47)
        %v86756_v31 = vadd.s32 %v86752_v9, %v86740_v22 (stack40)
        %v86758_v7 = vshll.u32 %v86752_v9, 17 (stack45)
        %v85909_v12 = vxor.u32 %v85908_v6, %v85904_v25 (stack48)
        %v86347_v55 = vadd.s32 %v86344_v56, %v86339_v55 (stack40)
        %v86349_v32 = vshll.u32 %v86344_v56, 15 (stack45)
        %v86350_v8 = vshrl.u32 %v86344_v56, 17 (stack46)
        %v84777_v29 = vpack.c.bf16 %v157387_v11, %v84774_v52 (stack81)
        %v85518_v41 = vand.u32.u16 65535, %v85517_v34 (stack52)
        %v86759_v22 = vshrl.u32 %v86752_v9, 15 (stack46)
        %v146891_v21 = vadd.s32 %v87178_v44, %v87173_v21 (stack40)
        %v85912_v10 = vadd.s32 %v85909_v12, %v85904_v25 (stack40)
        %v85918_v25 = vshll.u32 %v85909_v12, 24 (stack45)
        %v85919_v45 = vshrl.u32 %v85909_v12, 8 (stack46)
        %v86351_v46 = vor.u32 %v86350_v8, %v86349_v32 (stack47)
        %120197 = vst [vmem:[%s123356_s30 + $0x258] sm:$0xf] /*vst_source=*/%v84777_v29 (stack83)
        %v120200_v26 = vadd.low.f32.bf16 -1.0, %v85518_v41 (stack53)
        %v86760_v23 = vor.u32 %v86759_v22, %v86758_v7 (stack47)
        %v87183_v43 = vshll.u32 %v87178_v44, 15 (stack45)
        %v87184_v9 = vshrl.u32 %v87178_v44, 17 (stack46)
        %v121160_v44 = vpop.eup %121159 (stack73)
        %vm85150_vm2 = vcmp.eq.f32.partialorder %v146845_v60, 0.0 (stack71)
        %v85151_v61 = vand.u32 2147483648, %v146845_v60 (stack72)
        %v85920_v6 = vor.u32 %v85919_v45, %v85918_v25 (stack47)
        %v86352_v56 = vxor.u32 %v86351_v46, %v86347_v55 (stack48)
        %v85147_v52 = vmul.f32 %v121160_v44, %v146845_v60 (stack74)
        %v85527_v34 = vmul.f32 2.0, %v120200_v26 (stack54)
        %v86761_v7 = vxor.u32 %v86760_v23, %v86756_v31 (stack48)
        %v87185_v12 = vor.u32 %v87184_v9, %v87183_v43 (stack47)
        %v85921_v32 = vxor.u32 %v85920_v6, %v85912_v10 (stack48)
        %v86355_v55 = vadd.s32 %v86352_v56, %v86347_v55 (stack40)
        %v86357_v8 = vshll.u32 %v86352_v56, 26 (stack45)
        %v86358_v29 = vshrl.u32 %v86352_v56, 6 (stack46)
        %v85149_v41 = vsel /*vm=*/%vm85148_vm1, /*on_true_vy=*/%v146845_v60, /*on_false_vx=*/%v85147_v52 (stack75)
        %v85531_v22 = vadd.f32 -0.99609375, %v85527_v34 (stack53)
        %v86764_v31 = vadd.s32 %v86761_v7, %v86756_v31 (stack40)
        %v86766_v25 = vshll.u32 %v86761_v7, 29 (stack45)
        %v85152_v45 = vsel /*vm=*/%vm85150_vm2, /*on_true_vy=*/%v85151_v61, /*on_false_vx=*/%v85149_v41 (stack76)
        %v85924_v46 = vadd.s32 %v85921_v32, %v121564_v0 (stack40)
        %v86359_v26 = vor.u32 %v86358_v29, %v86357_v8 (stack47)
        %v86767_v23 = vshrl.u32 %v86761_v7, 3 (stack46)
        %v85155_v43 = vadd.f32 -3.0, %v85152_v45 (stack53)
        %v146903_v9 = vmax.f32 %v85531_v22, -0.99609375 (stack55)
        %v85916_v10 = vadd.s32 %v85912_v10, %v121569_v1 (stack40)
        %v87186_v44 = vxor.u32 %v87185_v12, %v146891_v21 (stack48)
        %v85928_v61 = vadd.s32 4, %v85924_v46 (stack40)
        %v86360_v6 = vxor.u32 %v86359_v26, %v86355_v55 (stack48)
        %v86768_v56 = vor.u32 %v86767_v23, %v86766_v25 (stack47)
        %vm87600_vm3 = vcmp.lt.u32.totalorder %v146881_v20, %v157079_v39 (stack43)
        %v85124_v52 = vsel /*vm=*/%vm85103_vm0, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v85140_v34 = vsel /*vm=*/%vm85103_vm0, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v146918_v24 = vsel /*vm=*/%vm85103_vm0, /*on_true_vy=*/%v146864_v24, /*on_false_vx=*/%v85155_v43 (stack44)
        %v85547_v7 = vxor.u32 2147483648, %v146903_v9 (stack56)
        %v85163_v12 = vmul.f32 %v146918_v24, %v85140_v34 (stack54)
        %v85932_v32 = vadd.s32 %v85928_v61, %v85916_v10 (stack40)
        %v85934_v8 = vshll.u32 %v85928_v61, 13 (stack45)
        %v85935_v29 = vshrl.u32 %v85928_v61, 19 (stack46)
        %v85136_v41 = vsel /*vm=*/%vm85103_vm0, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v146926_v22 = vmul.f32 %v85547_v7, %v146903_v9 (stack54)
        %v86363_v55 = vadd.s32 %v86360_v6, %v86355_v55 (stack40)
        %v86369_v25 = vshll.u32 %v86360_v6, 6 (stack45)
        %v85167_v45 = vadd.f32 %v85163_v12, %v85136_v41 (stack53)
        %v85936_v46 = vor.u32 %v85935_v29, %v85934_v8 (stack47)
        %v86370_v26 = vshrl.u32 %v86360_v6, 26 (stack46)
        %v86769_v23 = vxor.u32 %v86768_v56, %v86764_v31 (stack48)
        %v146929_v43 = vmul.f32 inf, %v146783_v50 (stack54)
        %v85128_v10 = vsel /*vm=*/%vm85103_vm0, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v85132_v61 = vsel /*vm=*/%vm85103_vm0, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v85552_v6 = vadd.f32 1.0, %v146926_v22 (stack57)
        %v85171_v56 = vmul.f32 %v85167_v45, %v146918_v24 (stack54)
        %v85937_v34 = vxor.u32 %v85936_v46, %v85932_v32 (stack48)
        %v86371_v7 = vor.u32 %v86370_v26, %v86369_v25 (stack47)
        %v86772_v31 = vadd.s32 %v86769_v23, %v86764_v31 (stack40)
        %121161 = vlog2.f32 %v85552_v6 (stack58)
        %v85555_v12 = vmul.f32 -0.5, %v146926_v22 (stack59)
        %v86774_v8 = vshll.u32 %v86769_v23, 16 (stack45)
        %v146942_v29 = vadd.s32 %v146881_v20, %v122657_v58 (stack40)
        %v85175_v41 = vadd.f32 %v85171_v56, %v85132_v61 (stack53)
        %v85940_v32 = vadd.s32 %v85937_v34, %v85932_v32 (stack40)
        %v85942_v25 = vshll.u32 %v85937_v34, 15 (stack45)
        %v85943_v45 = vshrl.u32 %v85937_v34, 17 (stack46)
        %v85558_v46 = vand.u32 2147483647, %v146926_v22 (stack60)
        %v86372_v26 = vxor.u32 %v86371_v7, %v86363_v55 (stack48)
        %v86775_v23 = vshrl.u32 %v86769_v23, 16 (stack46)
        %v87189_v21 = vadd.s32 %v87186_v44, %v146891_v21 (stack40)
        %v85179_v61 = vmul.f32 %v85175_v41, %v146918_v24 (stack54)
        %v85944_v6 = vor.u32 %v85943_v45, %v85942_v25 (stack47)
        %v87191_v56 = vshll.u32 %v87186_v44, 26 (stack45)
        %v87192_v44 = vshrl.u32 %v87186_v44, 6 (stack46)
        %v86367_v55 = vadd.s32 %v86363_v55, %v121574_v2 (stack40)
        %v86375_v34 = vadd.s32 %v86372_v26, %v121569_v1 (stack40)
        %v86776_v7 = vor.u32 %v86775_v23, %v86774_v8 (stack47)
        %v87609_v8 = vadd.s32 1, %v146888_v54 (stack40)
        %v85183_v10 = vadd.f32 %v85179_v61, %v85128_v10 (stack53)
        %v85556_v12 = vadd.f32 1.0, %v85555_v12 (stack61)
        %v85945_v41 = vxor.u32 %v85944_v6, %v85940_v32 (stack48)
        %v146952_v25 = vadd.s32 %v157614_v27, %v157083_v59 (stack40)
        %v86379_v45 = vadd.s32 3, %v86375_v34 (stack40)
        %v86777_v26 = vxor.u32 %v86776_v7, %v86772_v31 (stack48)
        %v87193_v23 = vor.u32 %v87192_v44, %v87191_v56 (stack47)
        %v87613_v54 = vsel /*vm=*/%vm87600_vm3, /*on_true_vy=*/%v87609_v8, /*on_false_vx=*/%v146888_v54 (stack44)
        %v85187_v61 = vmul.f32 %v85183_v10, %v146918_v24 (stack54)
        %v85948_v32 = vadd.s32 %v85945_v41, %v85940_v32 (stack40)
        %v85950_v6 = vshll.u32 %v85945_v41, 26 (stack45)
        %v85951_v56 = vshrl.u32 %v85945_v41, 6 (stack46)
        %vm87595_vm4 = vcmp.lt.u32.totalorder %v146942_v29, %v146881_v20 (stack43)
        %v86383_v44 = vadd.s32 %v86379_v45, %v86367_v55 (stack40)
        %v86385_v55 = vshll.u32 %v86379_v45, 17 (stack45)
        %v86386_v34 = vshrl.u32 %v86379_v45, 15 (stack46)
        %v86780_v31 = vadd.s32 %v86777_v26, %v86772_v31 (stack40)
        %v85191_v52 = vadd.f32 %v85187_v61, %v85124_v52 (stack53)
        %v85952_v7 = vor.u32 %v85951_v56, %v85950_v6 (stack47)
        %v86786_v8 = vshll.u32 %v86777_v26, 24 (stack45)
        %v86787_v10 = vshrl.u32 %v86777_v26, 8 (stack46)
        %v85557_v22 = vmul.f32 %v85556_v12, %v146926_v22 (stack63)
        %v86387_v12 = vor.u32 %v86386_v34, %v86385_v55 (stack47)
        %v87194_v41 = vxor.u32 %v87193_v23, %v87189_v21 (stack48)
        %v146964_v45 = vadd.s32 %v146942_v29, %v121569_v1 (stack40)
        %v85195_v26 = vmul.f32 %v85191_v52, %v146918_v24 (stack54)
        %v85953_v23 = vxor.u32 %v85952_v7, %v85948_v32 (stack48)
        %v86788_v61 = vor.u32 %v86787_v10, %v86786_v8 (stack47)
        %v87617_v6 = vadd.s32 1, %v87613_v54 (stack40)
        %v86388_v56 = vxor.u32 %v86387_v12, %v86383_v44 (stack48)
        %v87197_v21 = vadd.s32 %v87194_v41, %v87189_v21 (stack40)
        %v87203_v55 = vshll.u32 %v87194_v41, 6 (stack45)
        %v87204_v34 = vshrl.u32 %v87194_v41, 26 (stack46)
        %v121162_v52 = vpop.eup %121161 (stack64)
        %v85199_v30 = vadd.f32 %v85195_v26, %v146876_v30 (stack53)
        %v85956_v32 = vadd.s32 %v85953_v23, %v85948_v32 (stack40)
        %v85962_v7 = vshll.u32 %v85953_v23, 6 (stack45)
        %v85963_v8 = vshrl.u32 %v85953_v23, 26 (stack46)
        %v85554_v10 = vmul.f32 0.6931472, %v121162_v52 (stack65)
        %v86391_v44 = vadd.s32 %v86388_v56, %v86383_v44 (stack40)
        %v86393_v12 = vshll.u32 %v86388_v56, 29 (stack45)
        %v86394_v41 = vshrl.u32 %v86388_v56, 3 (stack46)
        %v85203_v26 = vmul.f32 %v85199_v30, %v146918_v24 (stack54)
        %vm85559_vm5 = vcmp.lt.f32.partialorder %v85558_v46, 0.0004427343 (stack62)
        %v85964_v46 = vor.u32 %v85963_v8, %v85962_v7 (stack47)
        %v86789_v23 = vxor.u32 %v86788_v61, %v86780_v31 (stack48)
        %v85560_v22 = vsel /*vm=*/%vm85559_vm5, /*on_true_vy=*/%v85557_v22, /*on_false_vx=*/%v85554_v10 (stack66)
        %v86395_v61 = vor.u32 %v86394_v41, %v86393_v12 (stack47)
        %v87205_v56 = vor.u32 %v87204_v34, %v87203_v55 (stack47)
        %v87636_v55 = vshll.u32 %v146964_v45, 13 (stack45)
        %v85207_v40 = vadd.f32 %v85203_v26, %v146871_v40 (stack53)
        %v146971_v34 = vxor.u32 2147483648, %v85560_v22 (stack56)
        %v85965_v52 = vxor.u32 %v85964_v46, %v85956_v32 (stack48)
        %v87637_v30 = vshrl.u32 %v146964_v45, 19 (stack46)
        %v85108_v7 = vsel /*vm=*/%vm85103_vm0, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v86396_v8 = vxor.u32 %v86395_v61, %v86391_v44 (stack48)
        %v87206_v10 = vxor.u32 %v87205_v56, %v87197_v21 (stack48)
        %v87621_v20 = vsel /*vm=*/%vm87595_vm4, /*on_true_vy=*/%v87617_v6, /*on_false_vx=*/%v87613_v54 (stack44)
        %v85112_v60 = vsel /*vm=*/%vm85103_vm0, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v85211_v29 = vmul.f32 %v85207_v40, %v146918_v24 (stack54)
        %vm85564_vm6 = vcmp.lt.f32.partialorder %v146971_v34, 5.0 (stack68)
        %121163 = vrsqrt.f32 %v146971_v34 (stack67)
        %vm146988_vm7 = vcmp.eq.f32.partialorder %v85076_v53, 1.0 (stack68)
        %v85537_v54 = vand.u32 2147483647, %v146903_v9 (stack77)
        %v85968_v6 = vadd.s32 %v85965_v52, %v121574_v2 (stack40)
        %v86784_v31 = vadd.s32 %v86780_v31, %v121564_v0 (stack40)
        %v86792_v12 = vadd.s32 %v86789_v23, %v121574_v2 (stack40)
        %v85215_v41 = vadd.f32 %v85211_v29, %v85112_v60 (stack53)
        %v85960_v32 = vadd.s32 %v85956_v32, %v121564_v0 (stack40)
        %v87201_v21 = vadd.s32 %v87197_v21, %v121569_v1 (stack40)
        %v87638_v26 = vor.u32 %v87637_v30, %v87636_v55 (stack47)
        %v147001_v46 = vsel /*vm=*/%vm85564_vm6, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v147006_v23 = vsel /*vm=*/%vm85564_vm6, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v147009_v22 = vadd.f32 -2.5, %v146971_v34 (stack53)
        %v86399_v44 = vadd.s32 %v86396_v8, %v86391_v44 (stack40)
        %v85219_v24 = vmul.f32 %v85215_v41, %v146918_v24 (stack54)
        %v147015_v61 = vsel /*vm=*/%vm85564_vm6, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v147020_v56 = vsel /*vm=*/%vm85564_vm6, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v147025_v55 = vsel /*vm=*/%vm85564_vm6, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v85972_v40 = vadd.s32 5, %v85968_v6 (stack40)
        %v86401_v52 = vshll.u32 %v86396_v8, 16 (stack45)
        %v86402_v30 = vshrl.u32 %v86396_v8, 16 (stack46)
        %v86796_v8 = vadd.s32 2, %v86792_v12 (stack40)
        %v85223_v7 = vadd.f32 %v85219_v24, %v85108_v7 (stack53)
        %v147030_v60 = vsel /*vm=*/%vm85564_vm6, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v87209_v10 = vadd.s32 %v87206_v10, %v121564_v0 (stack40)
        %v87626_v20 = vadd.s32 %v87621_v20, %v121574_v2 (stack40)
        %vm85609_vm8 = vcmp.eq.f32.partialorder %v146971_v34, inf (stack70)
        %v85974_v29 = vxor.u32 %v85972_v40, %v85960_v32 (stack48)
        %v86403_v6 = vor.u32 %v86402_v30, %v86401_v52 (stack47)
        %v86800_v31 = vadd.s32 %v86796_v8, %v86784_v31 (stack40)
        %v86802_v12 = vshll.u32 %v86796_v8, 13 (stack45)
        %v85227_v50 = vmul.f32 %v85223_v7, %v146783_v50 (stack54)
        %vm85611_vm9 = vcmp.eq.f32.partialorder %v146971_v34, 0.0 (stack71)
        %v86803_v41 = vshrl.u32 %v86796_v8, 19 (stack46)
        %v87213_v32 = vadd.s32 1, %v87209_v10 (stack40)
        %v87634_v45 = vadd.s32 %v146964_v45, %v87626_v20 (stack40)
        %v85612_v24 = vand.u32 2147483648, %v146971_v34 (stack72)
        %v85975_v40 = vand.u32.u8 255, %v85974_v29 (stack49)
        %v86404_v52 = vxor.u32 %v86403_v6, %v86399_v44 (stack48)
        %vm88061_vm10 = vcmp.lt.u32.totalorder %v146952_v25, %v157083_v59 (stack43)
        %v85231_v43 = vsel /*vm=*/%vm146988_vm7, /*on_true_vy=*/%v146929_v43, /*on_false_vx=*/%v85227_v50 (stack44)
        %v86804_v53 = vor.u32 %v86803_v41, %v86802_v12 (stack47)
        %v87217_v21 = vadd.s32 %v87213_v32, %v87201_v21 (stack40)
        %v87219_v30 = vshll.u32 %v87213_v32, 17 (stack45)
        %v85235_v8 = vmul.f32 1.4140625, %v85231_v43 (stack54)
        %v85976_v7 = vand.u32 65535, %v85975_v40 (stack50)
        %v86407_v44 = vadd.s32 %v86404_v52, %v86399_v44 (stack40)
        %v86413_v10 = vshll.u32 %v86404_v52, 24 (stack45)
        %v86414_v20 = vshrl.u32 %v86404_v52, 8 (stack46)
        %v86805_v29 = vxor.u32 %v86804_v53, %v86800_v31 (stack48)
        %v87220_v6 = vshrl.u32 %v87213_v32, 15 (stack46)
        %v87639_v26 = vxor.u32 %v87638_v26, %v87634_v45 (stack48)
        %v121164_v12 = vpop.eup %121163 (stack73)
        %v85238_v50 = vpack.c.bf16 %v157387_v11, %v85235_v8 (stack81)
        %v85977_v41 = vshrl.u32 %v85976_v7, 1 (stack51)
        %v86411_v32 = vadd.s32 %v86407_v44, %v121569_v1 (stack40)
        %v88066_v40 = vadd.s32 %v157617_v42, %v157084_v16 (stack40)
        %v85608_v52 = vmul.f32 %v121164_v12, %v146971_v34 (stack74)
        %v86415_v43 = vor.u32 %v86414_v20, %v86413_v10 (stack47)
        %v86808_v31 = vadd.s32 %v86805_v29, %v86800_v31 (stack40)
        %v86810_v53 = vshll.u32 %v86805_v29, 15 (stack45)
        %120199 = vst [vmem:[%s123356_s30 + $0x2d8] sm:$0xf] /*vst_source=*/%v85238_v50 (stack83)
        %v85978_v8 = vor.u32 16256, %v85977_v41 (stack47)
        %v86811_v7 = vshrl.u32 %v86805_v29, 17 (stack46)
        %v87221_v30 = vor.u32 %v87220_v6, %v87219_v30 (stack47)
        %v87642_v45 = vadd.s32 %v87639_v26, %v87634_v45 (stack40)
        %v85610_v10 = vsel /*vm=*/%vm85609_vm8, /*on_true_vy=*/%v146971_v34, /*on_false_vx=*/%v85608_v52 (stack75)
        %v86416_v44 = vxor.u32 %v86415_v43, %v86407_v44 (stack48)
        %v87644_v20 = vshll.u32 %v87639_v26, 15 (stack45)
        %v87645_v29 = vshrl.u32 %v87639_v26, 17 (stack46)
        %v85613_v24 = vsel /*vm=*/%vm85611_vm9, /*on_true_vy=*/%v85612_v24, /*on_false_vx=*/%v85610_v10 (stack76)
        %v85979_v6 = vand.u32.u16 65535, %v85978_v8 (stack52)
        %v86812_v26 = vor.u32 %v86811_v7, %v86810_v53 (stack47)
        %v87222_v12 = vxor.u32 %v87221_v30, %v87217_v21 (stack48)
        %v85616_v50 = vadd.f32 -3.0, %v85613_v24 (stack53)
        %v86419_v41 = vadd.s32 %v86416_v44, %v121564_v0 (stack40)
        %v87646_v52 = vor.u32 %v87645_v29, %v87644_v20 (stack47)
        %v88070_v43 = vadd.s32 1, %v88066_v40 (stack40)
        %v120202_v53 = vadd.low.f32.bf16 -1.0, %v85979_v6 (stack53)
        %v86813_v8 = vxor.u32 %v86812_v26, %v86808_v31 (stack48)
        %v87225_v21 = vadd.s32 %v87222_v12, %v87217_v21 (stack40)
        %v87227_v7 = vshll.u32 %v87222_v12, 29 (stack45)
        %v147059_v22 = vsel /*vm=*/%vm85564_vm6, /*on_true_vy=*/%v147009_v22, /*on_false_vx=*/%v85616_v50 (stack44)
        %v86423_v30 = vadd.s32 4, %v86419_v41 (stack40)
        %v87228_v10 = vshrl.u32 %v87222_v12, 3 (stack46)
        %v87647_v44 = vxor.u32 %v87646_v52, %v87642_v45 (stack48)
        %v85624_v60 = vmul.f32 %v147059_v22, %v147030_v60 (stack54)
        %v85988_v20 = vmul.f32 2.0, %v120202_v53 (stack54)
        %v86816_v31 = vadd.s32 %v86813_v8, %v86808_v31 (stack40)
        %v86818_v29 = vshll.u32 %v86813_v8, 26 (stack45)
        %v86427_v32 = vadd.s32 %v86423_v30, %v86411_v32 (stack40)
        %v86429_v24 = vshll.u32 %v86423_v30, 13 (stack45)
        %v86430_v6 = vshrl.u32 %v86423_v30, 19 (stack46)
        %v86819_v26 = vshrl.u32 %v86813_v8, 6 (stack46)
        %v85628_v55 = vadd.f32 %v85624_v60, %v147025_v55 (stack53)
        %v85992_v12 = vadd.f32 -0.99609375, %v85988_v20 (stack53)
        %v87229_v50 = vor.u32 %v87228_v10, %v87227_v7 (stack47)
        %v87650_v45 = vadd.s32 %v87647_v44, %v87642_v45 (stack40)
        %v85593_v41 = vsel /*vm=*/%vm85564_vm6, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v86431_v52 = vor.u32 %v86430_v6, %v86429_v24 (stack47)
        %v86820_v53 = vor.u32 %v86819_v26, %v86818_v29 (stack47)
        %v88052_v8 = vadd.s32 %v146952_v25, %v122657_v58 (stack40)
        %v85632_v7 = vmul.f32 %v85628_v55, %v147059_v22 (stack54)
        %v147070_v30 = vmax.f32 %v85992_v12, -0.99609375 (stack55)
        %v87230_v10 = vxor.u32 %v87229_v50, %v87225_v21 (stack48)
        %v88074_v40 = vsel /*vm=*/%vm88061_vm10, /*on_true_vy=*/%v88070_v43, /*on_false_vx=*/%v88066_v40 (stack44)
        %v86432_v43 = vxor.u32 %v86431_v52, %v86427_v32 (stack48)
        %v86821_v60 = vxor.u32 %v86820_v53, %v86816_v31 (stack48)
        %v87652_v20 = vshll.u32 %v87647_v44, 26 (stack45)
        %v87653_v44 = vshrl.u32 %v87647_v44, 6 (stack46)
        %v85585_v29 = vsel /*vm=*/%vm85564_vm6, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v85589_v34 = vsel /*vm=*/%vm85564_vm6, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v85636_v24 = vadd.f32 %v85632_v7, %v85593_v41 (stack53)
        %v86008_v6 = vxor.u32 2147483648, %v147070_v30 (stack56)
        %v86435_v32 = vadd.s32 %v86432_v43, %v86427_v32 (stack40)
        %v86437_v26 = vshll.u32 %v86432_v43, 15 (stack45)
        %v86438_v55 = vshrl.u32 %v86432_v43, 17 (stack46)
        %v86824_v31 = vadd.s32 %v86821_v60, %v86816_v31 (stack40)
        %v85640_v12 = vmul.f32 %v85636_v24, %v147059_v22 (stack54)
        %v86011_v50 = vmul.f32 %v86008_v6, %v147070_v30 (stack54)
        %v86830_v41 = vshll.u32 %v86821_v60, 6 (stack45)
        %vm88056_vm11 = vcmp.lt.u32.totalorder %v88052_v8, %v146952_v25 (stack43)
        %v86439_v52 = vor.u32 %v86438_v55, %v86437_v26 (stack47)
        %v86831_v53 = vshrl.u32 %v86821_v60, 26 (stack46)
        %v87233_v21 = vadd.s32 %v87230_v10, %v87225_v21 (stack40)
        %v87654_v7 = vor.u32 %v87653_v44, %v87652_v20 (stack47)
        %v85644_v43 = vadd.f32 %v85640_v12, %v85589_v34 (stack53)
        %v86013_v60 = vadd.f32 1.0, %v86011_v50 (stack57)
        %v86016_v20 = vmul.f32 -0.5, %v86011_v50 (stack59)
        %v88078_v44 = vadd.s32 1, %v88074_v40 (stack40)
        %v86440_v34 = vxor.u32 %v86439_v52, %v86435_v32 (stack48)
        %v86832_v24 = vor.u32 %v86831_v53, %v86830_v41 (stack47)
        %v87235_v6 = vshll.u32 %v87230_v10, 16 (stack45)
        %v87236_v10 = vshrl.u32 %v87230_v10, 16 (stack46)
        %v85648_v26 = vmul.f32 %v85644_v43, %v147059_v22 (stack54)
        %121165 = vlog2.f32 %v86013_v60 (stack58)
        %v86019_v55 = vand.u32 2147483647, %v86011_v50 (stack60)
        %v86828_v12 = vadd.s32 %v86824_v31, %v121574_v2 (stack40)
        %v86443_v32 = vadd.s32 %v86440_v34, %v86435_v32 (stack40)
        %v86445_v41 = vshll.u32 %v86440_v34, 26 (stack45)
        %v86446_v52 = vshrl.u32 %v86440_v34, 6 (stack46)
        %v86833_v31 = vxor.u32 %v86832_v24, %v86824_v31 (stack48)
        %v85652_v29 = vadd.f32 %v85648_v26, %v85585_v29 (stack53)
        %v86017_v53 = vadd.f32 1.0, %v86016_v20 (stack61)
        %v87237_v43 = vor.u32 %v87236_v10, %v87235_v6 (stack47)
        %v87655_v7 = vxor.u32 %v87654_v7, %v87650_v45 (stack48)
        %v86447_v60 = vor.u32 %v86446_v52, %v86445_v41 (stack47)
        %v86836_v20 = vadd.s32 %v86833_v31, %v121569_v1 (stack40)
        %v88082_v25 = vsel /*vm=*/%vm88056_vm11, /*on_true_vy=*/%v88078_v44, /*on_false_vx=*/%v88074_v40 (stack44)
        %v88091_v8 = vadd.s32 %v88052_v8, %v121569_v1 (stack40)
        %v85656_v40 = vmul.f32 %v85652_v29, %v147059_v22 (stack54)
        %v87238_v44 = vxor.u32 %v87237_v43, %v87233_v21 (stack48)
        %v147092_v45 = vadd.s32 %v87655_v7, %v87650_v45 (stack40)
        %v87664_v34 = vshll.u32 %v87655_v7, 6 (stack45)
        %v86448_v24 = vxor.u32 %v86447_v60, %v86443_v32 (stack48)
        %v86840_v6 = vadd.s32 3, %v86836_v20 (stack40)
        %v87665_v10 = vshrl.u32 %v87655_v7, 26 (stack46)
        %v88087_v26 = vadd.s32 %v88082_v25, %v121574_v2 (stack40)
        %v85660_v56 = vadd.f32 %v85656_v40, %v147020_v56 (stack53)
        %v87241_v21 = vadd.s32 %v87238_v44, %v87233_v21 (stack40)
        %v87247_v41 = vshll.u32 %v87238_v44, 24 (stack45)
        %v87248_v52 = vshrl.u32 %v87238_v44, 8 (stack46)
        %v86451_v32 = vadd.s32 %v86448_v24, %v86443_v32 (stack40)
        %v86457_v31 = vshll.u32 %v86448_v24, 6 (stack45)
        %v86458_v29 = vshrl.u32 %v86448_v24, 26 (stack46)
        %v86844_v12 = vadd.s32 %v86840_v6, %v86828_v12 (stack40)
        %v85664_v43 = vmul.f32 %v85660_v56, %v147059_v22 (stack54)
        %vm147097_vm12 = vcmp.lt.f32.partialorder %v86019_v55, 0.0004427343 (stack62)
        %v86846_v7 = vshll.u32 %v86840_v6, 17 (stack45)
        %v86847_v60 = vshrl.u32 %v86840_v6, 15 (stack46)
        %v86018_v50 = vmul.f32 %v86017_v53, %v86011_v50 (stack63)
        %v86459_v53 = vor.u32 %v86458_v29, %v86457_v31 (stack47)
        %v87245_v20 = vadd.s32 %v87241_v21, %v121564_v0 (stack40)
        %v87249_v25 = vor.u32 %v87248_v52, %v87247_v41 (stack47)
        %v85668_v61 = vadd.f32 %v85664_v43, %v147015_v61 (stack53)
        %v86848_v40 = vor.u32 %v86847_v60, %v86846_v7 (stack47)
        %v87666_v44 = vor.u32 %v87665_v10, %v87664_v34 (stack47)
        %v147103_v34 = vadd.s32 %v88091_v8, %v88087_v26 (stack40)
        %v86460_v24 = vxor.u32 %v86459_v53, %v86451_v32 (stack48)
        %v87250_v6 = vxor.u32 %v87249_v25, %v87241_v21 (stack48)
        %v88097_v10 = vshll.u32 %v88091_v8, 13 (stack45)
        %v88098_v8 = vshrl.u32 %v88091_v8, 19 (stack46)
        %v85672_v26 = vmul.f32 %v85668_v61, %v147059_v22 (stack54)
        %v86849_v56 = vxor.u32 %v86848_v40, %v86844_v12 (stack48)
        %v87667_v21 = vxor.u32 %v87666_v44, %v147092_v45 (stack48)
        %v147109_v41 = vadd.s32 %v157614_v27, %v157089_v17 (stack40)
        %v121166_v52 = vpop.eup %121165 (stack64)
        %v86463_v31 = vadd.s32 %v86460_v24, %v121574_v2 (stack40)
        %v87253_v29 = vadd.s32 %v87250_v6, %v121574_v2 (stack40)
        %v88099_v43 = vor.u32 %v88098_v8, %v88097_v10 (stack47)
        %v147115_v7 = vadd.s32 %v157617_v42, %v157090_v62 (stack40)
        %v85676_v23 = vadd.f32 %v85672_v26, %v147006_v23 (stack53)
        %v86015_v60 = vmul.f32 0.6931472, %v121166_v52 (stack65)
        %v86852_v12 = vadd.s32 %v86849_v56, %v86844_v12 (stack40)
        %v86854_v53 = vshll.u32 %v86849_v56, 29 (stack45)
        %v86455_v32 = vadd.s32 %v86451_v32, %v121564_v0 (stack40)
        %v86467_v25 = vadd.s32 5, %v86463_v31 (stack40)
        %v86855_v61 = vshrl.u32 %v86849_v56, 3 (stack46)
        %v87257_v40 = vadd.s32 2, %v87253_v29 (stack40)
        %v85680_v22 = vmul.f32 %v85676_v23, %v147059_v22 (stack54)
        %v86021_v55 = vsel /*vm=*/%vm147097_vm12, /*on_true_vy=*/%v86018_v50, /*on_false_vx=*/%v86015_v60 (stack66)
        %v87670_v50 = vadd.s32 %v87667_v21, %v121564_v0 (stack40)
        %v88100_v44 = vxor.u32 %v88099_v43, %v147103_v34 (stack48)
        %v147124_v24 = vxor.u32 2147483648, %v86021_v55 (stack56)
        %v86469_v6 = vxor.u32 %v86467_v25, %v86455_v32 (stack48)
        %v86856_v10 = vor.u32 %v86855_v61, %v86854_v53 (stack47)
        %v87261_v20 = vadd.s32 %v87257_v40, %v87245_v20 (stack40)
        %v85684_v46 = vadd.f32 %v85680_v22, %v147001_v46 (stack53)
        %vm147129_vm13 = vcmp.eq.f32.partialorder %v85537_v54, 1.0 (stack68)
        %v85545_v8 = vmul.f32 inf, %v146903_v9 (stack54)
        %vm86025_vm14 = vcmp.lt.f32.partialorder %v147124_v24, 5.0 (stack68)
        %121167 = vrsqrt.f32 %v147124_v24 (stack67)
        %v85688_v9 = vmul.f32 %v85684_v46, %v146903_v9 (stack54)
        %v85998_v26 = vand.u32 2147483647, %v147070_v30 (stack77)
        %v87263_v56 = vshll.u32 %v87257_v40, 13 (stack45)
        %v87264_v21 = vshrl.u32 %v87257_v40, 19 (stack46)
        %v86857_v52 = vxor.u32 %v86856_v10, %v86852_v12 (stack48)
        %v87662_v45 = vadd.s32 %v147092_v45, %v121569_v1 (stack40)
        %v87674_v31 = vadd.s32 1, %v87670_v50 (stack40)
        %v147142_v29 = vadd.s32 %v147109_v41, %v122657_v58 (stack40)
        %v85692_v43 = vsel /*vm=*/%vm147129_vm13, /*on_true_vy=*/%v85545_v8, /*on_false_vx=*/%v85688_v9 (stack44)
        %v147149_v23 = vsel /*vm=*/%vm86025_vm14, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v147154_v60 = vsel /*vm=*/%vm86025_vm14, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v147157_v53 = vadd.f32 -2.5, %v147124_v24 (stack53)
        %v85696_v32 = vmul.f32 1.4140625, %v85692_v43 (stack54)
        %v147162_v25 = vsel /*vm=*/%vm86025_vm14, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v147167_v61 = vsel /*vm=*/%vm86025_vm14, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v86470_v40 = vand.u32.u8 255, %v86469_v6 (stack49)
        %v86860_v12 = vadd.s32 %v86857_v52, %v86852_v12 (stack40)
        %v86862_v22 = vshll.u32 %v86857_v52, 16 (stack45)
        %v86863_v55 = vshrl.u32 %v86857_v52, 16 (stack46)
        %v87265_v50 = vor.u32 %v87264_v21, %v87263_v56 (stack47)
        %v85699_v6 = vpack.c.bf16 %v157387_v11, %v85696_v32 (stack81)
        %v86471_v10 = vand.u32 65535, %v86470_v40 (stack50)
        %v87678_v46 = vadd.s32 %v87674_v31, %v87662_v45 (stack40)
        %v87680_v54 = vshll.u32 %v87674_v31, 17 (stack45)
        %vm86070_vm15 = vcmp.eq.f32.partialorder %v147124_v24, inf (stack70)
        %v86864_v8 = vor.u32 %v86863_v55, %v86862_v22 (stack47)
        %v87266_v9 = vxor.u32 %v87265_v50, %v87261_v20 (stack48)
        %v87681_v56 = vshrl.u32 %v87674_v31, 15 (stack46)
        %v88103_v34 = vadd.s32 %v88100_v44, %v147103_v34 (stack40)
        %120201 = vst [vmem:[%s123356_s30 + $0x358] sm:$0xf] /*vst_source=*/%v85699_v6 (stack83)
        %v147176_v21 = vsel /*vm=*/%vm86025_vm14, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v86472_v52 = vshrl.u32 %v86471_v10, 1 (stack51)
        %v88105_v45 = vshll.u32 %v88100_v44, 15 (stack45)
        %v88106_v44 = vshrl.u32 %v88100_v44, 17 (stack46)
        %v86865_v31 = vxor.u32 %v86864_v8, %v86860_v12 (stack48)
        %v87269_v20 = vadd.s32 %v87266_v9, %v87261_v20 (stack40)
        %v87271_v43 = vshll.u32 %v87266_v9, 15 (stack45)
        %v87272_v32 = vshrl.u32 %v87266_v9, 17 (stack46)
        %v86473_v40 = vor.u32 16256, %v86472_v52 (stack47)
        %v87682_v22 = vor.u32 %v87681_v56, %v87680_v54 (stack47)
        %v88107_v55 = vor.u32 %v88106_v44, %v88105_v45 (stack47)
        %vm88522_vm0 = vcmp.lt.u32.totalorder %v147109_v41, %v157089_v17 (stack43)
        %v86868_v12 = vadd.s32 %v86865_v31, %v86860_v12 (stack40)
        %v86874_v50 = vshll.u32 %v86865_v31, 24 (stack45)
        %v86875_v6 = vshrl.u32 %v86865_v31, 8 (stack46)
        %v87273_v10 = vor.u32 %v87272_v32, %v87271_v43 (stack47)
        %v86062_v54 = vsel /*vm=*/%vm86025_vm14, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v86474_v8 = vand.u32.u16 65535, %v86473_v40 (stack52)
        %v87683_v9 = vxor.u32 %v87682_v22, %v87678_v46 (stack48)
        %v88108_v56 = vxor.u32 %v88107_v55, %v88103_v34 (stack48)
        %v121168_v52 = vpop.eup %121167 (stack73)
        %vm86072_vm1 = vcmp.eq.f32.partialorder %v147124_v24, 0.0 (stack71)
        %v86073_v45 = vand.u32 2147483648, %v147124_v24 (stack72)
        %v86876_v44 = vor.u32 %v86875_v6, %v86874_v50 (stack47)
        %v87274_v31 = vxor.u32 %v87273_v10, %v87269_v20 (stack48)
        %v86069_v43 = vmul.f32 %v121168_v52, %v147124_v24 (stack74)
        %v120208_v32 = vadd.low.f32.bf16 -1.0, %v86474_v8 (stack53)
        %v87686_v46 = vadd.s32 %v87683_v9, %v87678_v46 (stack40)
        %v87688_v40 = vshll.u32 %v87683_v9, 29 (stack45)
        %v86877_v22 = vxor.u32 %v86876_v44, %v86868_v12 (stack48)
        %v87277_v20 = vadd.s32 %v87274_v31, %v87269_v20 (stack40)
        %v87279_v55 = vshll.u32 %v87274_v31, 26 (stack45)
        %v87280_v50 = vshrl.u32 %v87274_v31, 6 (stack46)
        %v86071_v6 = vsel /*vm=*/%vm86070_vm15, /*on_true_vy=*/%v147124_v24, /*on_false_vx=*/%v86069_v43 (stack75)
        %v86483_v10 = vmul.f32 2.0, %v120208_v32 (stack54)
        %v87689_v8 = vshrl.u32 %v87683_v9, 3 (stack46)
        %v88111_v34 = vadd.s32 %v88108_v56, %v88103_v34 (stack40)
        %v86074_v9 = vsel /*vm=*/%vm86072_vm1, /*on_true_vy=*/%v86073_v45, /*on_false_vx=*/%v86071_v6 (stack76)
        %v86880_v52 = vadd.s32 %v86877_v22, %v121564_v0 (stack40)
        %v87281_v45 = vor.u32 %v87280_v50, %v87279_v55 (stack47)
        %v88531_v44 = vadd.s32 1, %v147115_v7 (stack40)
        %v86077_v31 = vadd.f32 -3.0, %v86074_v9 (stack53)
        %v86487_v43 = vadd.f32 -0.99609375, %v86483_v10 (stack53)
        %v86872_v12 = vadd.s32 %v86868_v12, %v121569_v1 (stack40)
        %v87690_v32 = vor.u32 %v87689_v8, %v87688_v40 (stack47)
        %v86884_v40 = vadd.s32 4, %v86880_v52 (stack40)
        %v87282_v22 = vxor.u32 %v87281_v45, %v87277_v20 (stack48)
        %v88113_v55 = vshll.u32 %v88108_v56, 26 (stack45)
        %v88535_v7 = vsel /*vm=*/%vm88522_vm0, /*on_true_vy=*/%v88531_v44, /*on_false_vx=*/%v147115_v7 (stack44)
        %v147201_v53 = vsel /*vm=*/%vm86025_vm14, /*on_true_vy=*/%v147157_v53, /*on_false_vx=*/%v86077_v31 (stack44)
        %v147203_v50 = vmax.f32 %v86487_v43, -0.99609375 (stack55)
        %v87691_v6 = vxor.u32 %v87690_v32, %v87686_v46 (stack48)
        %v88114_v56 = vshrl.u32 %v88108_v56, 6 (stack46)
        %v86085_v54 = vmul.f32 %v147201_v53, %v86062_v54 (stack54)
        %v86888_v10 = vadd.s32 %v86884_v40, %v86872_v12 (stack40)
        %v86890_v8 = vshll.u32 %v86884_v40, 13 (stack45)
        %v86891_v9 = vshrl.u32 %v86884_v40, 19 (stack46)
        %v86058_v52 = vsel /*vm=*/%vm86025_vm14, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v86503_v45 = vxor.u32 2147483648, %v147203_v50 (stack56)
        %v87285_v20 = vadd.s32 %v87282_v22, %v87277_v20 (stack40)
        %v147212_v44 = vadd.s32 %v147142_v29, %v121569_v1 (stack40)
        %v86089_v31 = vadd.f32 %v86085_v54, %v86058_v52 (stack53)
        %v86892_v43 = vor.u32 %v86891_v9, %v86890_v8 (stack47)
        %v87291_v12 = vshll.u32 %v87282_v22, 6 (stack45)
        %v87292_v32 = vshrl.u32 %v87282_v22, 26 (stack46)
        %v86506_v40 = vmul.f32 %v86503_v45, %v147203_v50 (stack54)
        %v87694_v46 = vadd.s32 %v87691_v6, %v87686_v46 (stack40)
        %v88115_v22 = vor.u32 %v88114_v56, %v88113_v55 (stack47)
        %vm88517_vm2 = vcmp.lt.u32.totalorder %v147142_v29, %v147109_v41 (stack43)
        %v86093_v55 = vmul.f32 %v86089_v31, %v147201_v53 (stack54)
        %v86893_v56 = vxor.u32 %v86892_v43, %v86888_v10 (stack48)
        %v87293_v54 = vor.u32 %v87292_v32, %v87291_v12 (stack47)
        %v87696_v8 = vshll.u32 %v87691_v6, 16 (stack45)
        %v86508_v9 = vadd.f32 1.0, %v86506_v40 (stack57)
        %v86511_v52 = vmul.f32 -0.5, %v86506_v40 (stack59)
        %v87697_v6 = vshrl.u32 %v87691_v6, 16 (stack46)
        %v88558_v45 = vshll.u32 %v147212_v44, 13 (stack45)
        %v86097_v21 = vadd.f32 %v86093_v55, %v147176_v21 (stack53)
        %v86896_v10 = vadd.s32 %v86893_v56, %v86888_v10 (stack40)
        %v86898_v31 = vshll.u32 %v86893_v56, 15 (stack45)
        %v86899_v43 = vshrl.u32 %v86893_v56, 17 (stack46)
        %121169 = vlog2.f32 %v86508_v9 (stack58)
        %v86514_v12 = vand.u32 2147483647, %v86506_v40 (stack60)
        %v87289_v32 = vadd.s32 %v87285_v20, %v121574_v2 (stack40)
        %v87294_v20 = vxor.u32 %v87293_v54, %v87285_v20 (stack48)
        %v86101_v55 = vmul.f32 %v86097_v21, %v147201_v53 (stack54)
        %v86900_v56 = vor.u32 %v86899_v43, %v86898_v31 (stack47)
        %v87698_v54 = vor.u32 %v87697_v6, %v87696_v8 (stack47)
        %v88116_v22 = vxor.u32 %v88115_v22, %v88111_v34 (stack48)
        %v86512_v8 = vadd.f32 1.0, %v86511_v52 (stack61)
        %v87297_v9 = vadd.s32 %v87294_v20, %v121569_v1 (stack40)
        %v88539_v52 = vadd.s32 1, %v88535_v7 (stack40)
        %v88559_v6 = vshrl.u32 %v147212_v44, 19 (stack46)
        %v86105_v61 = vadd.f32 %v86101_v55, %v147167_v61 (stack53)
        %v86901_v21 = vxor.u32 %v86900_v56, %v86896_v10 (stack48)
        %v87699_v31 = vxor.u32 %v87698_v54, %v87694_v46 (stack48)
        %v88119_v34 = vadd.s32 %v88116_v22, %v88111_v34 (stack40)
        %v87301_v43 = vadd.s32 3, %v87297_v9 (stack40)
        %v88125_v20 = vshll.u32 %v88116_v22, 6 (stack45)
        %v88126_v55 = vshrl.u32 %v88116_v22, 26 (stack46)
        %v88543_v41 = vsel /*vm=*/%vm88517_vm2, /*on_true_vy=*/%v88539_v52, /*on_false_vx=*/%v88535_v7 (stack44)
        %v86109_v29 = vmul.f32 %v86105_v61, %v147201_v53 (stack54)
        %v86904_v7 = vadd.s32 %v86901_v21, %v86896_v10 (stack40)
        %v86906_v10 = vshll.u32 %v86901_v21, 26 (stack45)
        %v86907_v56 = vshrl.u32 %v86901_v21, 6 (stack46)
        %v87305_v32 = vadd.s32 %v87301_v43, %v87289_v32 (stack40)
        %v87307_v54 = vshll.u32 %v87301_v43, 17 (stack45)
        %v87308_v22 = vshrl.u32 %v87301_v43, 15 (stack46)
        %v87702_v46 = vadd.s32 %v87699_v31, %v87694_v46 (stack40)
        %v86113_v25 = vadd.f32 %v86109_v29, %v147162_v25 (stack53)
        %v86908_v9 = vor.u32 %v86907_v56, %v86906_v10 (stack47)
        %v87708_v52 = vshll.u32 %v87699_v31, 24 (stack45)
        %v87709_v61 = vshrl.u32 %v87699_v31, 8 (stack46)
        %v86513_v40 = vmul.f32 %v86512_v8, %v86506_v40 (stack63)
        %vm147230_vm3 = vcmp.lt.f32.partialorder %v86514_v12, 0.0004427343 (stack62)
        %v87309_v8 = vor.u32 %v87308_v22, %v87307_v54 (stack47)
        %v88127_v21 = vor.u32 %v88126_v55, %v88125_v20 (stack47)
        %v86117_v31 = vmul.f32 %v86113_v25, %v147201_v53 (stack54)
        %v86909_v43 = vxor.u32 %v86908_v9, %v86904_v7 (stack48)
        %v87710_v20 = vor.u32 %v87709_v61, %v87708_v52 (stack47)
        %v88548_v55 = vadd.s32 %v88543_v41, %v121574_v2 (stack40)
        %v87310_v41 = vxor.u32 %v87309_v8, %v87305_v32 (stack48)
        %v88128_v29 = vxor.u32 %v88127_v21, %v88119_v34 (stack48)
        %v88560_v45 = vor.u32 %v88559_v6, %v88558_v45 (stack47)
        %v147238_v6 = vadd.s32 %v157614_v27, %v157091_v37 (stack40)
        %v86121_v60 = vadd.f32 %v86117_v31, %v147154_v60 (stack53)
        %v86912_v7 = vadd.s32 %v86909_v43, %v86904_v7 (stack40)
        %v86918_v10 = vshll.u32 %v86909_v43, 6 (stack45)
        %v86919_v56 = vshrl.u32 %v86909_v43, 26 (stack46)
        %v87313_v32 = vadd.s32 %v87310_v41, %v87305_v32 (stack40)
        %v87315_v54 = vshll.u32 %v87310_v41, 29 (stack45)
        %v87316_v22 = vshrl.u32 %v87310_v41, 3 (stack46)
        %v87711_v25 = vxor.u32 %v87710_v20, %v87702_v46 (stack48)
        %v121170_v9 = vpop.eup %121169 (stack64)
        %v86125_v52 = vmul.f32 %v86121_v60, %v147201_v53 (stack54)
        %v86920_v61 = vor.u32 %v86919_v56, %v86918_v10 (stack47)
        %v87706_v46 = vadd.s32 %v87702_v46, %v121564_v0 (stack40)
        %v88131_v8 = vadd.s32 %v88128_v29, %v121564_v0 (stack40)
        %v86510_v21 = vmul.f32 0.6931472, %v121170_v9 (stack65)
        %v87317_v31 = vor.u32 %v87316_v22, %v87315_v54 (stack47)
        %v87714_v43 = vadd.s32 %v87711_v25, %v121574_v2 (stack40)
        %v88556_v44 = vadd.s32 %v147212_v44, %v88548_v55 (stack40)
        %v86129_v23 = vadd.f32 %v86125_v52, %v147149_v23 (stack53)
        %v86921_v20 = vxor.u32 %v86920_v61, %v86912_v7 (stack48)
        %v88123_v34 = vadd.s32 %v88119_v34, %v121569_v1 (stack40)
        %v88135_v55 = vadd.s32 1, %v88131_v8 (stack40)
        %v86516_v40 = vsel /*vm=*/%vm147230_vm3, /*on_true_vy=*/%v86513_v40, /*on_false_vx=*/%v86510_v21 (stack66)
        %v87318_v12 = vxor.u32 %v87317_v31, %v87313_v32 (stack48)
        %v87718_v41 = vadd.s32 2, %v87714_v43 (stack40)
        %v88561_v29 = vxor.u32 %v88560_v45, %v88556_v44 (stack48)
        %v86034_v45 = vsel /*vm=*/%vm86025_vm14, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v86133_v60 = vmul.f32 %v86129_v23, %v147201_v53 (stack54)
        %v147254_v10 = vxor.u32 2147483648, %v86516_v40 (stack56)
        %v88139_v56 = vadd.s32 %v88135_v55, %v88123_v34 (stack40)
        %v87321_v32 = vadd.s32 %v87318_v12, %v87313_v32 (stack40)
        %v87323_v54 = vshll.u32 %v87318_v12, 16 (stack45)
        %v87324_v22 = vshrl.u32 %v87318_v12, 16 (stack46)
        %v87722_v25 = vadd.s32 %v87718_v41, %v87706_v46 (stack40)
        %v86137_v9 = vadd.f32 %v86133_v60, %v86034_v45 (stack53)
        %121171 = vrsqrt.f32 %v147254_v10 (stack67)
        %vm86520_vm4 = vcmp.lt.f32.partialorder %v147254_v10, 5.0 (stack68)
        %v86924_v52 = vadd.s32 %v86921_v20, %v121574_v2 (stack40)
        %v87325_v61 = vor.u32 %v87324_v22, %v87323_v54 (stack47)
        %vm147261_vm5 = vcmp.eq.f32.partialorder %v85998_v26, 1.0 (stack68)
        %v86006_v46 = vmul.f32 inf, %v147070_v30 (stack54)
        %v86030_v24 = vsel /*vm=*/%vm86025_vm14, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v86141_v53 = vmul.f32 %v86137_v9, %v147201_v53 (stack54)
        %v86493_v8 = vand.u32 2147483647, %v147203_v50 (stack77)
        %v86916_v7 = vadd.s32 %v86912_v7, %v121564_v0 (stack40)
        %v87326_v21 = vxor.u32 %v87325_v61, %v87321_v32 (stack48)
        %v147274_v31 = vadd.s32 %v147238_v6, %v122657_v58 (stack40)
        %v86145_v43 = vadd.f32 %v86141_v53, %v86030_v24 (stack53)
        %v147279_v23 = vsel /*vm=*/%vm86520_vm4, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v147284_v20 = vsel /*vm=*/%vm86520_vm4, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v147287_v34 = vadd.f32 -2.5, %v147254_v10 (stack53)
        %v86928_v40 = vadd.s32 5, %v86924_v52 (stack40)
        %v87329_v12 = vadd.s32 %v87326_v21, %v87321_v32 (stack40)
        %v87335_v45 = vshll.u32 %v87326_v21, 24 (stack45)
        %v87336_v60 = vshrl.u32 %v87326_v21, 8 (stack46)
        %v86149_v30 = vmul.f32 %v86145_v43, %v147070_v30 (stack54)
        %v87724_v32 = vshll.u32 %v87718_v41, 13 (stack45)
        %v87725_v41 = vshrl.u32 %v87718_v41, 19 (stack46)
        %v88141_v54 = vshll.u32 %v88135_v55, 17 (stack45)
        %vm86565_vm6 = vcmp.eq.f32.partialorder %v147254_v10, inf (stack70)
        %v86568_v22 = vand.u32 2147483648, %v147254_v10 (stack72)
        %v86930_v9 = vxor.u32 %v86928_v40, %v86916_v7 (stack48)
        %v87337_v52 = vor.u32 %v87336_v60, %v87335_v45 (stack47)
        %v88142_v55 = vshrl.u32 %v88135_v55, 15 (stack46)
        %v86153_v61 = vsel /*vm=*/%vm147261_vm5, /*on_true_vy=*/%v86006_v46, /*on_false_vx=*/%v86149_v30 (stack44)
        %vm86567_vm7 = vcmp.eq.f32.partialorder %v147254_v10, 0.0 (stack71)
        %v87726_v26 = vor.u32 %v87725_v41, %v87724_v32 (stack47)
        %v88564_v44 = vadd.s32 %v88561_v29, %v88556_v44 (stack40)
        %v88566_v46 = vshll.u32 %v88561_v29, 15 (stack45)
        %v86157_v24 = vmul.f32 1.4140625, %v86153_v61 (stack54)
        %v86931_v53 = vand.u32.u8 255, %v86930_v9 (stack49)
        %v87338_v7 = vxor.u32 %v87337_v52, %v87329_v12 (stack48)
        %v88143_v21 = vor.u32 %v88142_v55, %v88141_v54 (stack47)
        %v87333_v43 = vadd.s32 %v87329_v12, %v121569_v1 (stack40)
        %v87727_v40 = vxor.u32 %v87726_v26, %v87722_v25 (stack48)
        %v88567_v29 = vshrl.u32 %v88561_v29, 17 (stack46)
        %vm88983_vm8 = vcmp.lt.u32.totalorder %v147238_v6, %v157091_v37 (stack43)
        %v86160_v12 = vpack.c.bf16 %v157387_v11, %v86157_v24 (stack81)
        %v86932_v45 = vand.u32 65535, %v86931_v53 (stack50)
        %v87341_v60 = vadd.s32 %v87338_v7, %v121564_v0 (stack40)
        %v88144_v30 = vxor.u32 %v88143_v21, %v88139_v56 (stack48)
        %v87730_v25 = vadd.s32 %v87727_v40, %v87722_v25 (stack40)
        %v87732_v32 = vshll.u32 %v87727_v40, 15 (stack45)
        %v87733_v41 = vshrl.u32 %v87727_v40, 17 (stack46)
        %v88568_v54 = vor.u32 %v88567_v29, %v88566_v46 (stack47)
        %v121172_v9 = vpop.eup %121171 (stack73)
        %120203 = vst [vmem:[%s123356_s30 + $0x3d8] sm:$0xf] /*vst_source=*/%v86160_v12 (stack83)
        %v86933_v52 = vshrl.u32 %v86932_v45, 1 (stack51)
        %v87345_v55 = vadd.s32 4, %v87341_v60 (stack40)
        %v88147_v56 = vadd.s32 %v88144_v30, %v88139_v56 (stack40)
        %v88149_v61 = vshll.u32 %v88144_v30, 29 (stack45)
        %v86564_v26 = vmul.f32 %v121172_v9, %v147254_v10 (stack74)
        %v87734_v46 = vor.u32 %v87733_v41, %v87732_v32 (stack47)
        %v88150_v24 = vshrl.u32 %v88144_v30, 3 (stack46)
        %v88569_v53 = vxor.u32 %v88568_v54, %v88564_v44 (stack48)
        %v86934_v7 = vor.u32 16256, %v86933_v52 (stack47)
        %v87349_v21 = vadd.s32 %v87345_v55, %v87333_v43 (stack40)
        %v87351_v43 = vshll.u32 %v87345_v55, 13 (stack45)
        %v87352_v40 = vshrl.u32 %v87345_v55, 19 (stack46)
        %v86566_v29 = vsel /*vm=*/%vm86565_vm6, /*on_true_vy=*/%v147254_v10, /*on_false_vx=*/%v86564_v26 (stack75)
        %v87735_v12 = vxor.u32 %v87734_v46, %v87730_v25 (stack48)
        %v88151_v45 = vor.u32 %v88150_v24, %v88149_v61 (stack47)
        %v88572_v44 = vadd.s32 %v88569_v53, %v88564_v44 (stack40)
        %v86569_v22 = vsel /*vm=*/%vm86567_vm7, /*on_true_vy=*/%v86568_v22, /*on_false_vx=*/%v86566_v29 (stack76)
        %v86935_v60 = vand.u32.u16 65535, %v86934_v7 (stack52)
        %v87353_v30 = vor.u32 %v87352_v40, %v87351_v43 (stack47)
        %v88574_v32 = vshll.u32 %v88569_v53, 26 (stack45)
        %v86572_v41 = vadd.f32 -3.0, %v86569_v22 (stack53)
        %v87738_v25 = vadd.s32 %v87735_v12, %v87730_v25 (stack40)
        %v87740_v54 = vshll.u32 %v87735_v12, 26 (stack45)
        %v87741_v9 = vshrl.u32 %v87735_v12, 6 (stack46)
        %v120210_v52 = vadd.low.f32.bf16 -1.0, %v86935_v60 (stack53)
        %v87354_v55 = vxor.u32 %v87353_v30, %v87349_v21 (stack48)
        %v88152_v61 = vxor.u32 %v88151_v45, %v88147_v56 (stack48)
        %v88575_v26 = vshrl.u32 %v88569_v53, 6 (stack46)
        %v86557_v46 = vsel /*vm=*/%vm86520_vm4, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v147313_v34 = vsel /*vm=*/%vm86520_vm4, /*on_true_vy=*/%v147287_v34, /*on_false_vx=*/%v86572_v41 (stack44)
        %v87742_v24 = vor.u32 %v87741_v9, %v87740_v54 (stack47)
        %v147317_v53 = vadd.s32 %v157617_v42, %v157094_v36 (stack40)
        %v86580_v7 = vmul.f32 %v147313_v34, %v86557_v46 (stack54)
        %v86944_v43 = vmul.f32 2.0, %v120210_v52 (stack54)
        %v87357_v21 = vadd.s32 %v87354_v55, %v87349_v21 (stack40)
        %v87359_v40 = vshll.u32 %v87354_v55, 15 (stack45)
        %v87360_v29 = vshrl.u32 %v87354_v55, 17 (stack46)
        %v87743_v12 = vxor.u32 %v87742_v24, %v87738_v25 (stack48)
        %v88155_v56 = vadd.s32 %v88152_v61, %v88147_v56 (stack40)
        %v88157_v45 = vshll.u32 %v88152_v61, 16 (stack45)
        %v86584_v20 = vadd.f32 %v86580_v7, %v147284_v20 (stack53)
        %v86948_v22 = vadd.f32 -0.99609375, %v86944_v43 (stack53)
        %v88158_v60 = vshrl.u32 %v88152_v61, 16 (stack46)
        %v88576_v30 = vor.u32 %v88575_v26, %v88574_v32 (stack47)
        %v87361_v32 = vor.u32 %v87360_v29, %v87359_v40 (stack47)
        %v87746_v41 = vadd.s32 %v87743_v12, %v87738_v25 (stack40)
        %v87752_v25 = vshll.u32 %v87743_v12, 6 (stack45)
        %v87753_v54 = vshrl.u32 %v87743_v12, 26 (stack46)
        %v86588_v9 = vmul.f32 %v86584_v20, %v147313_v34 (stack54)
        %v147322_v52 = vmax.f32 %v86948_v22, -0.99609375 (stack55)
        %v88159_v55 = vor.u32 %v88158_v60, %v88157_v45 (stack47)
        %v88577_v61 = vxor.u32 %v88576_v30, %v88572_v44 (stack48)
        %v147327_v26 = vsel /*vm=*/%vm86520_vm4, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v86549_v46 = vsel /*vm=*/%vm86520_vm4, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v87362_v24 = vxor.u32 %v87361_v32, %v87357_v21 (stack48)
        %v87754_v7 = vor.u32 %v87753_v54, %v87752_v25 (stack47)
        %v86537_v43 = vsel /*vm=*/%vm86520_vm4, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v86541_v40 = vsel /*vm=*/%vm86520_vm4, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v86592_v29 = vadd.f32 %v86588_v9, %v86549_v46 (stack53)
        %v86964_v12 = vxor.u32 2147483648, %v147322_v52 (stack56)
        %v87365_v21 = vadd.s32 %v87362_v24, %v87357_v21 (stack40)
        %v87367_v45 = vshll.u32 %v87362_v24, 26 (stack45)
        %v87368_v20 = vshrl.u32 %v87362_v24, 6 (stack46)
        %v87755_v22 = vxor.u32 %v87754_v7, %v87746_v41 (stack48)
        %v86545_v60 = vsel /*vm=*/%vm86520_vm4, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v86596_v30 = vmul.f32 %v86592_v29, %v147313_v34 (stack54)
        %v86967_v32 = vmul.f32 %v86964_v12, %v147322_v52 (stack54)
        %v88160_v25 = vxor.u32 %v88159_v55, %v88155_v56 (stack48)
        %v87369_v54 = vor.u32 %v87368_v20, %v87367_v45 (stack47)
        %v87758_v9 = vadd.s32 %v87755_v22, %v121569_v1 (stack40)
        %v147345_v44 = vadd.s32 %v88577_v61, %v88572_v44 (stack40)
        %v89013_v55 = vadd.s32 %v147274_v31, %v121569_v1 (stack40)
        %v86600_v46 = vadd.f32 %v86596_v30, %v86545_v60 (stack53)
        %v86969_v24 = vadd.f32 1.0, %v86967_v32 (stack57)
        %v86972_v7 = vmul.f32 -0.5, %v86967_v32 (stack59)
        %v87750_v41 = vadd.s32 %v87746_v41, %v121574_v2 (stack40)
        %vm88978_vm9 = vcmp.lt.u32.totalorder %v147274_v31, %v147238_v6 (stack43)
        %v87370_v29 = vxor.u32 %v87369_v54, %v87365_v21 (stack48)
        %v87762_v12 = vadd.s32 3, %v87758_v9 (stack40)
        %v88163_v56 = vadd.s32 %v88160_v25, %v88155_v56 (stack40)
        %v88992_v45 = vadd.s32 1, %v147317_v53 (stack40)
        %v86604_v20 = vmul.f32 %v86600_v46, %v147313_v34 (stack54)
        %121173 = vlog2.f32 %v86969_v24 (stack58)
        %v86973_v22 = vadd.f32 1.0, %v86972_v7 (stack61)
        %v88169_v60 = vshll.u32 %v88160_v25, 24 (stack45)
        %v87373_v21 = vadd.s32 %v87370_v29, %v87365_v21 (stack40)
        %v87379_v30 = vshll.u32 %v87370_v29, 6 (stack45)
        %v87380_v54 = vshrl.u32 %v87370_v29, 26 (stack46)
        %v87766_v9 = vadd.s32 %v87762_v12, %v87750_v41 (stack40)
        %v86608_v40 = vadd.f32 %v86604_v20, %v86541_v40 (stack53)
        %v87768_v46 = vshll.u32 %v87762_v12, 17 (stack45)
        %v87769_v24 = vshrl.u32 %v87762_v12, 15 (stack46)
        %v88586_v7 = vshll.u32 %v88577_v61, 6 (stack45)
        %v86974_v41 = vmul.f32 %v86973_v22, %v86967_v32 (stack63)
        %v86975_v32 = vand.u32 2147483647, %v86967_v32 (stack60)
        %v87381_v29 = vor.u32 %v87380_v54, %v87379_v30 (stack47)
        %v88170_v25 = vshrl.u32 %v88160_v25, 8 (stack46)
        %v86612_v12 = vmul.f32 %v86608_v40, %v147313_v34 (stack54)
        %v87377_v20 = vadd.s32 %v87373_v21, %v121564_v0 (stack40)
        %v87770_v22 = vor.u32 %v87769_v24, %v87768_v46 (stack47)
        %v88587_v61 = vshrl.u32 %v88577_v61, 26 (stack46)
        %v87382_v21 = vxor.u32 %v87381_v29, %v87373_v21 (stack48)
        %v88171_v60 = vor.u32 %v88170_v25, %v88169_v60 (stack47)
        %v88996_v53 = vsel /*vm=*/%vm88983_vm8, /*on_true_vy=*/%v88992_v45, /*on_false_vx=*/%v147317_v53 (stack44)
        %v89019_v45 = vshll.u32 %v89013_v55, 13 (stack45)
        %v86616_v43 = vadd.f32 %v86612_v12, %v86537_v43 (stack53)
        %v87771_v30 = vxor.u32 %v87770_v22, %v87766_v9 (stack48)
        %v88588_v54 = vor.u32 %v88587_v61, %v88586_v7 (stack47)
        %v89000_v40 = vadd.s32 1, %v88996_v53 (stack40)
        %vm147360_vm10 = vcmp.lt.f32.partialorder %v86975_v32, 0.0004427343 (stack62)
        %v87385_v24 = vadd.s32 %v87382_v21, %v121574_v2 (stack40)
        %v88172_v7 = vxor.u32 %v88171_v60, %v88163_v56 (stack48)
        %v89020_v32 = vshrl.u32 %v89013_v55, 19 (stack46)
        %v147367_v27 = vadd.s32 %v157614_v27, %v157095_v13 (stack40)
        %v86620_v29 = vmul.f32 %v86616_v43, %v147313_v34 (stack54)
        %v87774_v9 = vadd.s32 %v87771_v30, %v87766_v9 (stack40)
        %v87776_v25 = vshll.u32 %v87771_v30, 29 (stack45)
        %v87777_v12 = vshrl.u32 %v87771_v30, 3 (stack46)
        %v87389_v22 = vadd.s32 5, %v87385_v24 (stack40)
        %v88175_v61 = vadd.s32 %v88172_v7, %v121574_v2 (stack40)
        %v88589_v21 = vxor.u32 %v88588_v54, %v147345_v44 (stack48)
        %v89004_v6 = vsel /*vm=*/%vm88978_vm9, /*on_true_vy=*/%v89000_v40, /*on_false_vx=*/%v88996_v53 (stack44)
        %v86624_v31 = vadd.f32 %v86620_v29, %v147327_v26 (stack53)
        %v87778_v26 = vor.u32 %v87777_v12, %v87776_v25 (stack47)
        %v88167_v56 = vadd.s32 %v88163_v56, %v121564_v0 (stack40)
        %v89009_v60 = vadd.s32 %v89004_v6, %v121574_v2 (stack40)
        %v87391_v20 = vxor.u32 %v87389_v22, %v87377_v20 (stack48)
        %v88179_v53 = vadd.s32 2, %v88175_v61 (stack40)
        %v88592_v43 = vadd.s32 %v88589_v21, %v121564_v0 (stack40)
        %v89021_v45 = vor.u32 %v89020_v32, %v89019_v45 (stack47)
        %v86628_v30 = vmul.f32 %v86624_v31, %v147313_v34 (stack54)
        %v87779_v54 = vxor.u32 %v87778_v26, %v87774_v9 (stack48)
        %v89017_v55 = vadd.s32 %v89013_v55, %v89009_v60 (stack40)
        %vm89444_vm11 = vcmp.lt.u32.totalorder %v147367_v27, %v157095_v13 (stack43)
        %v121174_v40 = vpop.eup %121173 (stack64)
        %v87392_v24 = vand.u32.u8 255, %v87391_v20 (stack49)
        %v88183_v7 = vadd.s32 %v88179_v53, %v88167_v56 (stack40)
        %v88185_v32 = vshll.u32 %v88179_v53, 13 (stack45)
        %v88186_v29 = vshrl.u32 %v88179_v53, 19 (stack46)
        %v86632_v23 = vadd.f32 %v86628_v30, %v147279_v23 (stack53)
        %v86971_v25 = vmul.f32 0.6931472, %v121174_v40 (stack65)
        %v87782_v9 = vadd.s32 %v87779_v54, %v87774_v9 (stack40)
        %v87784_v12 = vshll.u32 %v87779_v54, 16 (stack45)
        %v87393_v22 = vand.u32 65535, %v87392_v24 (stack50)
        %v87785_v61 = vshrl.u32 %v87779_v54, 16 (stack46)
        %v88187_v21 = vor.u32 %v88186_v29, %v88185_v32 (stack47)
        %v88596_v6 = vadd.s32 1, %v88592_v43 (stack40)
        %v86636_v34 = vmul.f32 %v86632_v23, %v147313_v34 (stack54)
        %v86977_v41 = vsel /*vm=*/%vm147360_vm10, /*on_true_vy=*/%v86974_v41, /*on_false_vx=*/%v86971_v25 (stack66)
        %v88584_v44 = vadd.s32 %v147345_v44, %v121569_v1 (stack40)
        %v89022_v46 = vxor.u32 %v89021_v45, %v89017_v55 (stack48)
        %v86525_v10 = vsel /*vm=*/%vm86520_vm4, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v147391_v31 = vxor.u32 2147483648, %v86977_v41 (stack56)
        %v87786_v26 = vor.u32 %v87785_v61, %v87784_v12 (stack47)
        %v88188_v56 = vxor.u32 %v88187_v21, %v88183_v7 (stack48)
        %v86640_v60 = vadd.f32 %v86636_v34, %v86525_v10 (stack53)
        %v88600_v20 = vadd.s32 %v88596_v6, %v88584_v44 (stack40)
        %121175 = vrsqrt.f32 %v147391_v31 (stack67)
        %v87394_v53 = vshrl.u32 %v87393_v22, 1 (stack51)
        %v86501_v43 = vmul.f32 inf, %v147203_v50 (stack54)
        %v86644_v45 = vmul.f32 %v86640_v60, %v147203_v50 (stack54)
        %vm86496_vm12 = vcmp.eq.f32.partialorder %v86493_v8, 1.0 (stack68)
        %v87787_v50 = vxor.u32 %v87786_v26, %v87782_v9 (stack48)
        %v86648_v8 = vsel /*vm=*/%vm86496_vm12, /*on_true_vy=*/%v86501_v43, /*on_false_vx=*/%v86644_v45 (stack44)
        %v86954_v30 = vand.u32 2147483647, %v147322_v52 (stack77)
        %v88602_v54 = vshll.u32 %v88596_v6, 17 (stack45)
        %v88603_v40 = vshrl.u32 %v88596_v6, 15 (stack46)
        %v86652_v24 = vmul.f32 1.4140625, %v86648_v8 (stack54)
        %v147400_v32 = vmul.f32 inf, %v147322_v52 (stack54)
        %v87395_v29 = vor.u32 16256, %v87394_v53 (stack47)
        %v147404_v23 = vadd.s32 %v147367_v27, %v122657_v58 (stack40)
        %vm86981_vm13 = vcmp.lt.f32.partialorder %v147391_v31, 5.0 (stack68)
        %v87790_v25 = vadd.s32 %v87787_v50, %v87782_v9 (stack40)
        %v87796_v9 = vshll.u32 %v87787_v50, 24 (stack45)
        %v87797_v12 = vshrl.u32 %v87787_v50, 8 (stack46)
        %v88191_v7 = vadd.s32 %v88188_v56, %v88183_v7 (stack40)
        %v86655_v22 = vpack.c.bf16 %v157387_v11, %v86652_v24 (stack81)
        %v87396_v61 = vand.u32.u16 65535, %v87395_v29 (stack52)
        %v88193_v21 = vshll.u32 %v88188_v56, 15 (stack45)
        %v88194_v6 = vshrl.u32 %v88188_v56, 17 (stack46)
        %v87022_v34 = vadd.f32 -2.5, %v147391_v31 (stack53)
        %v87798_v41 = vor.u32 %v87797_v12, %v87796_v9 (stack47)
        %v88604_v44 = vor.u32 %v88603_v40, %v88602_v54 (stack47)
        %v147409_v55 = vadd.s32 %v89022_v46, %v89017_v55 (stack40)
        %120209 = vst [vmem:[%s123356_s30 + $0x5c] sm:$0xf] /*vst_source=*/%v86655_v22 (stack83)
        %v120212_v10 = vadd.low.f32.bf16 -1.0, %v87396_v61 (stack53)
        %v88195_v26 = vor.u32 %v88194_v6, %v88193_v21 (stack47)
        %v89027_v56 = vshll.u32 %v89022_v46, 15 (stack45)
        %v89028_v46 = vshrl.u32 %v89022_v46, 17 (stack46)
        %vm87026_vm14 = vcmp.eq.f32.partialorder %v147391_v31, inf (stack70)
        %v87799_v60 = vxor.u32 %v87798_v41, %v87790_v25 (stack48)
        %v88605_v53 = vxor.u32 %v88604_v44, %v88600_v20 (stack48)
        %v147415_v42 = vadd.s32 %v157617_v42, %v157100_v14 (stack40)
        %v87405_v43 = vmul.f32 2.0, %v120212_v10 (stack54)
        %v88196_v45 = vxor.u32 %v88195_v26, %v88191_v7 (stack48)
        %v89029_v50 = vor.u32 %v89028_v46, %v89027_v56 (stack47)
        %v157642_v8 = vld [vmem:[#allocation148_spill] sm:$0xff] (stack84)
        %v147419_v54 = vadd.s32 %v157642_v8, %v122651_v47 (stack40)
        %v87802_v40 = vadd.s32 %v87799_v60, %v121564_v0 (stack40)
        %v88608_v20 = vadd.s32 %v88605_v53, %v88600_v20 (stack40)
        %v88610_v24 = vshll.u32 %v88605_v53, 29 (stack45)
        %v88611_v29 = vshrl.u32 %v88605_v53, 3 (stack46)
        %v87409_v9 = vadd.f32 -0.99609375, %v87405_v43 (stack53)
        %v88199_v12 = vadd.s32 %v88196_v45, %v88191_v7 (stack40)
        %v88201_v7 = vshll.u32 %v88196_v45, 26 (stack45)
        %v88202_v22 = vshrl.u32 %v88196_v45, 6 (stack46)
        %v121176_v61 = vpop.eup %121175 (stack73)
        %v87794_v25 = vadd.s32 %v87790_v25, %v121569_v1 (stack40)
        %v87806_v21 = vadd.s32 4, %v87802_v40 (stack40)
        %v88612_v6 = vor.u32 %v88611_v29, %v88610_v24 (stack47)
        %v89030_v41 = vxor.u32 %v89029_v50, %v147409_v55 (stack48)
        %v87025_v44 = vmul.f32 %v121176_v61, %v147391_v31 (stack74)
        %v87029_v10 = vand.u32 2147483648, %v147391_v31 (stack72)
        %v147426_v26 = vmax.f32 %v87409_v9, -0.99609375 (stack55)
        %v88203_v56 = vor.u32 %v88202_v22, %v88201_v7 (stack47)
        %v87810_v46 = vadd.s32 %v87806_v21, %v87794_v25 (stack40)
        %v87812_v60 = vshll.u32 %v87806_v21, 13 (stack45)
        %v87813_v53 = vshrl.u32 %v87806_v21, 19 (stack46)
        %v88613_v43 = vxor.u32 %v88612_v6, %v88608_v20 (stack48)
        %v147431_v45 = vsel /*vm=*/%vm86981_vm13, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v87027_v50 = vsel /*vm=*/%vm87026_vm14, /*on_true_vy=*/%v147391_v31, /*on_false_vx=*/%v87025_v44 (stack75)
        %vm87028_vm15 = vcmp.eq.f32.partialorder %v147391_v31, 0.0 (stack71)
        %v87425_v40 = vxor.u32 2147483648, %v147426_v26 (stack56)
        %v87030_v24 = vsel /*vm=*/%vm87028_vm15, /*on_true_vy=*/%v87029_v10, /*on_false_vx=*/%v87027_v50 (stack76)
        %v87814_v29 = vor.u32 %v87813_v53, %v87812_v60 (stack47)
        %v88204_v9 = vxor.u32 %v88203_v56, %v88199_v12 (stack48)
        %v88616_v20 = vadd.s32 %v88613_v43, %v88608_v20 (stack40)
        %v147441_v7 = vsel /*vm=*/%vm86981_vm13, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v147446_v22 = vsel /*vm=*/%vm86981_vm13, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v87033_v61 = vadd.f32 -3.0, %v87030_v24 (stack53)
        %v147449_v25 = vmul.f32 %v87425_v40, %v147426_v26 (stack54)
        %v87815_v21 = vxor.u32 %v87814_v29, %v87810_v46 (stack48)
        %v88207_v12 = vadd.s32 %v88204_v9, %v88199_v12 (stack40)
        %v88213_v6 = vshll.u32 %v88204_v9, 6 (stack45)
        %v88214_v44 = vshrl.u32 %v88204_v9, 26 (stack46)
        %v87018_v10 = vsel /*vm=*/%vm86981_vm13, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v147456_v34 = vsel /*vm=*/%vm86981_vm13, /*on_true_vy=*/%v87022_v34, /*on_false_vx=*/%v87033_v61 (stack44)
        %v87430_v56 = vadd.f32 1.0, %v147449_v25 (stack57)
        %v88618_v60 = vshll.u32 %v88613_v43, 16 (stack45)
        %v87041_v53 = vmul.f32 %v147456_v34, %v87018_v10 (stack54)
        %v87818_v46 = vadd.s32 %v87815_v21, %v87810_v46 (stack40)
        %v87820_v50 = vshll.u32 %v87815_v21, 15 (stack45)
        %v87821_v40 = vshrl.u32 %v87815_v21, 17 (stack46)
        %v87006_v24 = vsel /*vm=*/%vm86981_vm13, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v87014_v29 = vsel /*vm=*/%vm86981_vm13, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %121177 = vlog2.f32 %v87430_v56 (stack58)
        %v89453_v9 = vadd.s32 1, %v147415_v42 (stack40)
        %v87045_v61 = vadd.f32 %v87041_v53, %v87014_v29 (stack53)
        %v87822_v21 = vor.u32 %v87821_v40, %v87820_v50 (stack47)
        %v88215_v6 = vor.u32 %v88214_v44, %v88213_v6 (stack47)
        %v88619_v43 = vshrl.u32 %v88613_v43, 16 (stack46)
        %v87433_v44 = vmul.f32 -0.5, %v147449_v25 (stack59)
        %v89033_v55 = vadd.s32 %v89030_v41, %v147409_v55 (stack40)
        %v89035_v10 = vshll.u32 %v89030_v41, 26 (stack45)
        %v89036_v41 = vshrl.u32 %v89030_v41, 6 (stack46)
        %vm89439_vm0 = vcmp.lt.u32.totalorder %v147404_v23, %v147367_v27 (stack43)
        %v87049_v56 = vmul.f32 %v87045_v61, %v147456_v34 (stack54)
        %v87823_v53 = vxor.u32 %v87822_v21, %v87818_v46 (stack48)
        %v88216_v50 = vxor.u32 %v88215_v6, %v88207_v12 (stack48)
        %v88620_v60 = vor.u32 %v88619_v43, %v88618_v60 (stack47)
        %v87010_v40 = vsel /*vm=*/%vm86981_vm13, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v89037_v29 = vor.u32 %v89036_v41, %v89035_v10 (stack47)
        %v89457_v42 = vsel /*vm=*/%vm89444_vm11, /*on_true_vy=*/%v89453_v9, /*on_false_vx=*/%v147415_v42 (stack44)
        %v147481_v9 = vadd.s32 %v147404_v23, %v121569_v1 (stack40)
        %v87053_v61 = vadd.f32 %v87049_v56, %v87010_v40 (stack53)
        %v87826_v46 = vadd.s32 %v87823_v53, %v87818_v46 (stack40)
        %v87828_v21 = vshll.u32 %v87823_v53, 26 (stack45)
        %v87829_v6 = vshrl.u32 %v87823_v53, 6 (stack46)
        %v87436_v43 = vand.u32 2147483647, %v147449_v25 (stack60)
        %v88219_v10 = vadd.s32 %v88216_v50, %v121569_v1 (stack40)
        %v88621_v41 = vxor.u32 %v88620_v60, %v88616_v20 (stack48)
        %v89038_v56 = vxor.u32 %v89037_v29, %v89033_v55 (stack48)
        %v87057_v53 = vmul.f32 %v87053_v61, %v147456_v34 (stack54)
        %v87434_v44 = vadd.f32 1.0, %v87433_v44 (stack61)
        %v87830_v50 = vor.u32 %v87829_v6, %v87828_v21 (stack47)
        %v88211_v12 = vadd.s32 %v88207_v12, %v121574_v2 (stack40)
        %v88223_v60 = vadd.s32 3, %v88219_v10 (stack40)
        %v88624_v20 = vadd.s32 %v88621_v41, %v88616_v20 (stack40)
        %v88630_v40 = vshll.u32 %v88621_v41, 24 (stack45)
        %v88631_v29 = vshrl.u32 %v88621_v41, 8 (stack46)
        %v87061_v24 = vadd.f32 %v87057_v53, %v87006_v24 (stack53)
        %v87831_v61 = vxor.u32 %v87830_v50, %v87826_v46 (stack48)
        %v147487_v55 = vadd.s32 %v89038_v56, %v89033_v55 (stack40)
        %v89461_v21 = vadd.s32 1, %v89457_v42 (stack40)
        %v88227_v6 = vadd.s32 %v88223_v60, %v88211_v12 (stack40)
        %v88229_v10 = vshll.u32 %v88223_v60, 17 (stack45)
        %v88230_v41 = vshrl.u32 %v88223_v60, 15 (stack46)
        %v89047_v53 = vshll.u32 %v89038_v56, 6 (stack45)
        %v87065_v50 = vmul.f32 %v87061_v24, %v147456_v34 (stack54)
        %v87834_v46 = vadd.s32 %v87831_v61, %v87826_v46 (stack40)
        %v87840_v12 = vshll.u32 %v87831_v61, 6 (stack45)
        %v87841_v60 = vshrl.u32 %v87831_v61, 26 (stack46)
        %vm147490_vm1 = vcmp.lt.f32.partialorder %v87436_v43, 0.0004427343 (stack62)
        %v88231_v24 = vor.u32 %v88230_v41, %v88229_v10 (stack47)
        %v88632_v40 = vor.u32 %v88631_v29, %v88630_v40 (stack47)
        %v89048_v56 = vshrl.u32 %v89038_v56, 26 (stack46)
        %v121178_v29 = vpop.eup %121177 (stack64)
        %v87069_v22 = vadd.f32 %v87065_v50, %v147446_v22 (stack53)
        %v87435_v25 = vmul.f32 %v87434_v44, %v147449_v25 (stack63)
        %v87842_v44 = vor.u32 %v87841_v60, %v87840_v12 (stack47)
        %v89465_v27 = vsel /*vm=*/%vm89439_vm0, /*on_true_vy=*/%v89461_v21, /*on_false_vx=*/%v89457_v42 (stack44)
        %v87432_v23 = vmul.f32 0.6931472, %v121178_v29 (stack65)
        %v88232_v42 = vxor.u32 %v88231_v24, %v88227_v6 (stack48)
        %v88633_v61 = vxor.u32 %v88632_v40, %v88624_v20 (stack48)
        %v89049_v21 = vor.u32 %v89048_v56, %v89047_v53 (stack47)
        %v87073_v10 = vmul.f32 %v87069_v22, %v147456_v34 (stack54)
        %v87843_v41 = vxor.u32 %v87842_v44, %v87834_v46 (stack48)
        %v89470_v53 = vadd.s32 %v89465_v27, %v121574_v2 (stack40)
        %vm89939_vm2 = vcmp.lt.u32.totalorder %v147419_v54, %v122651_v47 (stack43)
        %v87438_v50 = vsel /*vm=*/%vm147490_vm1, /*on_true_vy=*/%v87435_v25, /*on_false_vx=*/%v87432_v23 (stack66)
        %v88235_v6 = vadd.s32 %v88232_v42, %v88227_v6 (stack40)
        %v88237_v12 = vshll.u32 %v88232_v42, 29 (stack45)
        %v88238_v60 = vshrl.u32 %v88232_v42, 3 (stack46)
        %v87077_v7 = vadd.f32 %v87073_v10, %v147441_v7 (stack53)
        %v147506_v43 = vxor.u32 2147483648, %v87438_v50 (stack56)
        %v89480_v24 = vshll.u32 %v147481_v9, 13 (stack45)
        %v89481_v40 = vshrl.u32 %v147481_v9, 19 (stack46)
        %v88239_v56 = vor.u32 %v88238_v60, %v88237_v12 (stack47)
        %v89050_v29 = vxor.u32 %v89049_v21, %v147487_v55 (stack48)
        %v89478_v9 = vadd.s32 %v147481_v9, %v89470_v53 (stack40)
        %v157645_v22 = vld [vmem:[#allocation110_spill] sm:$0xff] (stack84)
        %v89944_v25 = vadd.s32 %v157645_v22, %v157068_v28 (stack40)
        %v86990_v44 = vsel /*vm=*/%vm86981_vm13, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v86994_v31 = vsel /*vm=*/%vm86981_vm13, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v87081_v27 = vmul.f32 %v87077_v7, %v147456_v34 (stack54)
        %121179 = vrsqrt.f32 %v147506_v43 (stack67)
        %vm87442_vm3 = vcmp.lt.f32.partialorder %v147506_v43, 5.0 (stack68)
        %v87846_v23 = vadd.s32 %v87843_v41, %v121574_v2 (stack40)
        %v88240_v42 = vxor.u32 %v88239_v56, %v88235_v6 (stack48)
        %v88636_v61 = vadd.s32 %v88633_v61, %v121574_v2 (stack40)
        %v87085_v21 = vadd.f32 %v87081_v27, %v86994_v31 (stack53)
        %v88628_v20 = vadd.s32 %v88624_v20, %v121564_v0 (stack40)
        %v89482_v10 = vor.u32 %v89481_v40, %v89480_v24 (stack47)
        %v147528_v41 = vadd.s32 %v147419_v54, %v122657_v58 (stack40)
        %v147531_v53 = vadd.f32 -2.5, %v147506_v43 (stack53)
        %v87838_v46 = vadd.s32 %v87834_v46, %v121564_v0 (stack40)
        %v88243_v50 = vadd.s32 %v88240_v42, %v88235_v6 (stack40)
        %v89045_v55 = vadd.s32 %v147487_v55, %v121569_v1 (stack40)
        %v87089_v6 = vmul.f32 %v87085_v21, %v147456_v34 (stack54)
        %v147540_v12 = vsel /*vm=*/%vm87442_vm3, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v147545_v60 = vsel /*vm=*/%vm87442_vm3, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v87490_v7 = vand.u32 2147483648, %v147506_v43 (stack72)
        %vm147550_vm4 = vcmp.eq.f32.partialorder %v86954_v30, 1.0 (stack68)
        %v87850_v24 = vadd.s32 5, %v87846_v23 (stack40)
        %v88245_v40 = vshll.u32 %v88240_v42, 16 (stack45)
        %v88246_v56 = vshrl.u32 %v88240_v42, 16 (stack46)
        %v88640_v31 = vadd.s32 2, %v88636_v61 (stack40)
        %v87093_v44 = vadd.f32 %v87089_v6, %v86990_v44 (stack53)
        %v89053_v29 = vadd.s32 %v89050_v29, %v121564_v0 (stack40)
        %v89483_v27 = vxor.u32 %v89482_v10, %v89478_v9 (stack48)
        %v89948_v23 = vadd.s32 1, %v89944_v25 (stack40)
        %vm87487_vm5 = vcmp.eq.f32.partialorder %v147506_v43, inf (stack70)
        %v87852_v42 = vxor.u32 %v87850_v24, %v87838_v46 (stack48)
        %v88247_v61 = vor.u32 %v88246_v56, %v88245_v40 (stack47)
        %v88644_v21 = vadd.s32 %v88640_v31, %v88628_v20 (stack40)
        %v88646_v20 = vshll.u32 %v88640_v31, 13 (stack45)
        %v87097_v34 = vmul.f32 %v87093_v44, %v147456_v34 (stack54)
        %vm87489_vm6 = vcmp.eq.f32.partialorder %v147506_v43, 0.0 (stack71)
        %v88647_v10 = vshrl.u32 %v88640_v31, 19 (stack46)
        %v89057_v46 = vadd.s32 1, %v89053_v29 (stack40)
        %v89486_v9 = vadd.s32 %v89483_v27, %v89478_v9 (stack40)
        %v87853_v6 = vand.u32.u8 255, %v87852_v42 (stack49)
        %v88248_v24 = vxor.u32 %v88247_v61, %v88243_v50 (stack48)
        %v89488_v40 = vshll.u32 %v89483_v27, 15 (stack45)
        %v89489_v56 = vshrl.u32 %v89483_v27, 17 (stack46)
        %v87101_v45 = vadd.f32 %v87097_v34, %v147431_v45 (stack53)
        %v88648_v31 = vor.u32 %v88647_v10, %v88646_v20 (stack47)
        %v89061_v55 = vadd.s32 %v89057_v46, %v89045_v55 (stack40)
        %v89063_v44 = vshll.u32 %v89057_v46, 17 (stack45)
        %v87854_v29 = vand.u32 65535, %v87853_v6 (stack50)
        %v88251_v50 = vadd.s32 %v88248_v24, %v88243_v50 (stack40)
        %v88257_v27 = vshll.u32 %v88248_v24, 24 (stack45)
        %v88258_v42 = vshrl.u32 %v88248_v24, 8 (stack46)
        %v87105_v52 = vmul.f32 %v87101_v45, %v147322_v52 (stack54)
        %v88649_v61 = vxor.u32 %v88648_v31, %v88644_v21 (stack48)
        %v89064_v20 = vshrl.u32 %v89057_v46, 15 (stack46)
        %v89490_v34 = vor.u32 %v89489_v56, %v89488_v40 (stack47)
        %v121180_v10 = vpop.eup %121179 (stack73)
        %v87855_v46 = vshrl.u32 %v87854_v29, 1 (stack51)
        %v88255_v6 = vadd.s32 %v88251_v50, %v121569_v1 (stack40)
        %v88259_v24 = vor.u32 %v88258_v42, %v88257_v27 (stack47)
        %vm89934_vm7 = vcmp.lt.u32.totalorder %v147528_v41, %v147419_v54 (stack43)
        %v89952_v25 = vsel /*vm=*/%vm89939_vm2, /*on_true_vy=*/%v89948_v23, /*on_false_vx=*/%v89944_v25 (stack44)
        %v87109_v32 = vsel /*vm=*/%vm147550_vm4, /*on_true_vy=*/%v147400_v32, /*on_false_vx=*/%v87105_v52 (stack44)
        %v87486_v30 = vmul.f32 %v121180_v10, %v147506_v43 (stack74)
        %v88652_v23 = vadd.s32 %v88649_v61, %v88644_v21 (stack40)
        %v88654_v21 = vshll.u32 %v88649_v61, 15 (stack45)
        %v87113_v40 = vmul.f32 1.4140625, %v87109_v32 (stack54)
        %v87856_v56 = vor.u32 16256, %v87855_v46 (stack47)
        %v88260_v45 = vxor.u32 %v88259_v24, %v88251_v50 (stack48)
        %v88655_v31 = vshrl.u32 %v88649_v61, 17 (stack46)
        %v87488_v29 = vsel /*vm=*/%vm87487_vm5, /*on_true_vy=*/%v147506_v43, /*on_false_vx=*/%v87486_v30 (stack75)
        %v89065_v44 = vor.u32 %v89064_v20, %v89063_v44 (stack47)
        %v89491_v50 = vxor.u32 %v89490_v34, %v89486_v9 (stack48)
        %v89956_v27 = vadd.s32 1, %v89952_v25 (stack40)
        %v87116_v42 = vpack.c.bf16 %v157387_v11, %v87113_v40 (stack81)
        %v87491_v7 = vsel /*vm=*/%vm87489_vm6, /*on_true_vy=*/%v87490_v7, /*on_false_vx=*/%v87488_v29 (stack76)
        %v87857_v52 = vand.u32.u16 65535, %v87856_v56 (stack52)
        %v88263_v61 = vadd.s32 %v88260_v45, %v121564_v0 (stack40)
        %v87494_v20 = vadd.f32 -3.0, %v87491_v7 (stack53)
        %v88656_v34 = vor.u32 %v88655_v31, %v88654_v21 (stack47)
        %v89066_v10 = vxor.u32 %v89065_v44, %v89061_v55 (stack48)
        %v147577_v9 = vadd.s32 %v89491_v50, %v89486_v9 (stack40)
        %120211 = vst [vmem:[%s123356_s30 + $0xdc] sm:$0xf] /*vst_source=*/%v87116_v42 (stack83)
        %v120214_v46 = vadd.low.f32.bf16 -1.0, %v87857_v52 (stack53)
        %v88267_v24 = vadd.s32 4, %v88263_v61 (stack40)
        %v89496_v32 = vshll.u32 %v89491_v50, 26 (stack45)
        %v89497_v30 = vshrl.u32 %v89491_v50, 6 (stack46)
        %v147583_v53 = vsel /*vm=*/%vm87442_vm3, /*on_true_vy=*/%v147531_v53, /*on_false_vx=*/%v87494_v20 (stack44)
        %v88657_v21 = vxor.u32 %v88656_v34, %v88652_v23 (stack48)
        %v89069_v55 = vadd.s32 %v89066_v10, %v89061_v55 (stack40)
        %v89071_v40 = vshll.u32 %v89066_v10, 29 (stack45)
        %v87502_v60 = vmul.f32 %v147583_v53, %v147545_v60 (stack54)
        %v87866_v56 = vmul.f32 2.0, %v120214_v46 (stack54)
        %v88271_v6 = vadd.s32 %v88267_v24, %v88255_v6 (stack40)
        %v88273_v45 = vshll.u32 %v88267_v24, 13 (stack45)
        %v88274_v31 = vshrl.u32 %v88267_v24, 19 (stack46)
        %v88660_v23 = vadd.s32 %v88657_v21, %v88652_v23 (stack40)
        %v88662_v29 = vshll.u32 %v88657_v21, 26 (stack45)
        %v88663_v44 = vshrl.u32 %v88657_v21, 6 (stack46)
        %v87506_v12 = vadd.f32 %v87502_v60, %v147540_v12 (stack53)
        %v87870_v50 = vadd.f32 -0.99609375, %v87866_v56 (stack53)
        %v89072_v42 = vshrl.u32 %v89066_v10, 3 (stack46)
        %v89498_v7 = vor.u32 %v89497_v30, %v89496_v32 (stack47)
        %v87415_v52 = vand.u32 2147483647, %v147426_v26 (stack77)
        %v88275_v61 = vor.u32 %v88274_v31, %v88273_v45 (stack47)
        %v88664_v20 = vor.u32 %v88663_v44, %v88662_v29 (stack47)
        %v89960_v54 = vsel /*vm=*/%vm89934_vm7, /*on_true_vy=*/%v89956_v27, /*on_false_vx=*/%v89952_v25 (stack44)
        %v147595_v25 = vsel /*vm=*/%vm87442_vm3, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v87510_v27 = vmul.f32 %v87506_v12, %v147583_v53 (stack54)
        %v147598_v34 = vmax.f32 %v87870_v50, -0.99609375 (stack55)
        %v89499_v10 = vxor.u32 %v89498_v7, %v147577_v9 (stack48)
        %v87471_v46 = vsel /*vm=*/%vm87442_vm3, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v88276_v24 = vxor.u32 %v88275_v61, %v88271_v6 (stack48)
        %v88665_v32 = vxor.u32 %v88664_v20, %v88660_v23 (stack48)
        %v89073_v30 = vor.u32 %v89072_v42, %v89071_v40 (stack47)
        %v87459_v21 = vsel /*vm=*/%vm87442_vm3, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v87514_v40 = vadd.f32 %v87510_v27, %v87471_v46 (stack53)
        %v87886_v60 = vxor.u32 2147483648, %v147598_v34 (stack56)
        %v147610_v41 = vadd.s32 %v147528_v41, %v121569_v1 (stack40)
        %v88279_v56 = vadd.s32 %v88276_v24, %v88271_v6 (stack40)
        %v88281_v6 = vshll.u32 %v88276_v24, 15 (stack45)
        %v88282_v45 = vshrl.u32 %v88276_v24, 17 (stack46)
        %v88668_v31 = vadd.s32 %v88665_v32, %v88660_v23 (stack40)
        %v87463_v23 = vsel /*vm=*/%vm87442_vm3, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v87518_v29 = vmul.f32 %v87514_v40, %v147583_v53 (stack54)
        %v87889_v44 = vmul.f32 %v87886_v60, %v147598_v34 (stack54)
        %v88674_v12 = vshll.u32 %v88665_v32, 6 (stack45)
        %v87467_v50 = vsel /*vm=*/%vm87442_vm3, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v88283_v42 = vor.u32 %v88282_v45, %v88281_v6 (stack47)
        %v88675_v7 = vshrl.u32 %v88665_v32, 26 (stack46)
        %v89074_v61 = vxor.u32 %v89073_v30, %v89069_v55 (stack48)
        %v87522_v20 = vadd.f32 %v87518_v29, %v87467_v50 (stack53)
        %v87891_v27 = vadd.f32 1.0, %v87889_v44 (stack57)
        %v89965_v54 = vadd.s32 %v89960_v54, %v121574_v2 (stack40)
        %v89975_v46 = vshll.u32 %v147610_v41, 13 (stack45)
        %v88284_v24 = vxor.u32 %v88283_v42, %v88279_v56 (stack48)
        %v88672_v32 = vadd.s32 %v88668_v31, %v121574_v2 (stack40)
        %v88676_v30 = vor.u32 %v88675_v7, %v88674_v12 (stack47)
        %v89077_v55 = vadd.s32 %v89074_v61, %v89069_v55 (stack40)
        %v87526_v40 = vmul.f32 %v87522_v20, %v147583_v53 (stack54)
        %121181 = vlog2.f32 %v87891_v27 (stack58)
        %v87894_v60 = vmul.f32 -0.5, %v87889_v44 (stack59)
        %v89079_v6 = vshll.u32 %v89074_v61, 16 (stack45)
        %v88287_v56 = vadd.s32 %v88284_v24, %v88279_v56 (stack40)
        %v88289_v45 = vshll.u32 %v88284_v24, 26 (stack45)
        %v88290_v29 = vshrl.u32 %v88284_v24, 6 (stack46)
        %v88677_v31 = vxor.u32 %v88676_v30, %v88668_v31 (stack48)
        %v87530_v23 = vadd.f32 %v87526_v40, %v87463_v23 (stack53)
        %v87897_v12 = vand.u32 2147483647, %v87889_v44 (stack60)
        %v89080_v50 = vshrl.u32 %v89074_v61, 16 (stack46)
        %v89502_v9 = vadd.s32 %v89499_v10, %v147577_v9 (stack40)
        %v88291_v42 = vor.u32 %v88290_v29, %v88289_v45 (stack47)
        %v88680_v7 = vadd.s32 %v88677_v31, %v121569_v1 (stack40)
        %v89508_v61 = vshll.u32 %v89499_v10, 6 (stack45)
        %v89509_v10 = vshrl.u32 %v89499_v10, 26 (stack46)
        %v87534_v20 = vmul.f32 %v87530_v23, %v147583_v53 (stack54)
        %v87895_v27 = vadd.f32 1.0, %v87894_v60 (stack61)
        %v89081_v24 = vor.u32 %v89080_v50, %v89079_v6 (stack47)
        %v89973_v54 = vadd.s32 %v147610_v41, %v89965_v54 (stack40)
        %v88292_v30 = vxor.u32 %v88291_v42, %v88287_v56 (stack48)
        %v88684_v40 = vadd.s32 3, %v88680_v7 (stack40)
        %v89510_v60 = vor.u32 %v89509_v10, %v89508_v61 (stack47)
        %v89976_v41 = vshrl.u32 %v147610_v41, 19 (stack46)
        %v87538_v21 = vadd.f32 %v87534_v20, %v87459_v21 (stack53)
        %v89082_v6 = vxor.u32 %v89081_v24, %v89077_v55 (stack48)
        %v147631_v45 = vadd.s32 %v157642_v8, %v157070_v38 (stack40)
        %v147635_v29 = vadd.s32 %v157645_v22, %v157076_v35 (stack40)
        %v88295_v56 = vadd.s32 %v88292_v30, %v88287_v56 (stack40)
        %v88301_v31 = vshll.u32 %v88292_v30, 6 (stack45)
        %v88302_v23 = vshrl.u32 %v88292_v30, 26 (stack46)
        %v88688_v32 = vadd.s32 %v88684_v40, %v88672_v32 (stack40)
        %v87542_v50 = vmul.f32 %v87538_v21, %v147583_v53 (stack54)
        %v88690_v42 = vshll.u32 %v88684_v40, 17 (stack45)
        %v88691_v7 = vshrl.u32 %v88684_v40, 15 (stack46)
        %v89085_v55 = vadd.s32 %v89082_v6, %v89077_v55 (stack40)
        %v87455_v61 = vsel /*vm=*/%vm87442_vm3, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v88303_v10 = vor.u32 %v88302_v23, %v88301_v31 (stack47)
        %v89091_v20 = vshll.u32 %v89082_v6, 24 (stack45)
        %v89092_v24 = vshrl.u32 %v89082_v6, 8 (stack46)
        %v87546_v30 = vadd.f32 %v87542_v50, %v87455_v61 (stack53)
        %vm147641_vm8 = vcmp.lt.f32.partialorder %v87897_v12, 0.0004427343 (stack62)
        %v88692_v40 = vor.u32 %v88691_v7, %v88690_v42 (stack47)
        %v89511_v60 = vxor.u32 %v89510_v60, %v89502_v9 (stack48)
        %v87896_v44 = vmul.f32 %v87895_v27, %v87889_v44 (stack63)
        %v88304_v27 = vxor.u32 %v88303_v10, %v88295_v56 (stack48)
        %v89093_v21 = vor.u32 %v89092_v24, %v89091_v20 (stack47)
        %v89977_v46 = vor.u32 %v89976_v41, %v89975_v46 (stack47)
        %v87550_v41 = vmul.f32 %v87546_v30, %v147583_v53 (stack54)
        %v88693_v6 = vxor.u32 %v88692_v40, %v88688_v32 (stack48)
        %v89514_v31 = vadd.s32 %v89511_v60, %v121564_v0 (stack40)
        %vm90400_vm9 = vcmp.lt.u32.totalorder %v147631_v45, %v157070_v38 (stack43)
        %v121182_v23 = vpop.eup %121181 (stack64)
        %v88307_v50 = vadd.s32 %v88304_v27, %v121574_v2 (stack40)
        %v89094_v42 = vxor.u32 %v89093_v21, %v89085_v55 (stack48)
        %v89506_v9 = vadd.s32 %v89502_v9, %v121569_v1 (stack40)
        %v147651_v7 = vxor.u32 %v89977_v46, %v89973_v54 (stack48)
        %v87554_v25 = vadd.f32 %v87550_v41, %v147595_v25 (stack53)
        %v87893_v61 = vmul.f32 0.6931472, %v121182_v23 (stack65)
        %v88696_v32 = vadd.s32 %v88693_v6, %v88688_v32 (stack40)
        %v88698_v10 = vshll.u32 %v88693_v6, 29 (stack45)
        %v88299_v56 = vadd.s32 %v88295_v56, %v121564_v0 (stack40)
        %v88311_v20 = vadd.s32 5, %v88307_v50 (stack40)
        %v88699_v24 = vshrl.u32 %v88693_v6, 3 (stack46)
        %v89518_v30 = vadd.s32 1, %v89514_v31 (stack40)
        %v87558_v53 = vmul.f32 %v87554_v25, %v147583_v53 (stack54)
        %v87899_v12 = vsel /*vm=*/%vm147641_vm8, /*on_true_vy=*/%v87896_v44, /*on_false_vx=*/%v87893_v61 (stack66)
        %v89097_v40 = vadd.s32 %v89094_v42, %v121574_v2 (stack40)
        %v147660_v54 = vadd.s32 %v147651_v7, %v89973_v54 (stack40)
        %v87447_v43 = vsel /*vm=*/%vm87442_vm3, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v147665_v60 = vxor.u32 2147483648, %v87899_v12 (stack56)
        %v88313_v44 = vxor.u32 %v88311_v20, %v88299_v56 (stack48)
        %v88700_v27 = vor.u32 %v88699_v24, %v88698_v10 (stack47)
        %v87562_v21 = vadd.f32 %v87558_v53, %v87447_v43 (stack53)
        %v89522_v46 = vadd.s32 %v89518_v30, %v89506_v9 (stack40)
        %vm147669_vm10 = vcmp.eq.f32.partialorder %v87415_v52, 1.0 (stack68)
        %v87423_v41 = vmul.f32 inf, %v147426_v26 (stack54)
        %121183 = vrsqrt.f32 %v147665_v60 (stack67)
        %v147677_v6 = vadd.s32 %v147631_v45, %v122657_v58 (stack40)
        %v87566_v26 = vmul.f32 %v87562_v21, %v147426_v26 (stack54)
        %v87876_v31 = vand.u32 2147483647, %v147598_v34 (stack77)
        %vm87903_vm11 = vcmp.lt.f32.partialorder %v147665_v60, 5.0 (stack68)
        %v89101_v23 = vadd.s32 2, %v89097_v40 (stack40)
        %v147683_v50 = vmul.f32 inf, %v147598_v34 (stack54)
        %v88701_v42 = vxor.u32 %v88700_v27, %v88696_v32 (stack48)
        %v89089_v55 = vadd.s32 %v89085_v55, %v121564_v0 (stack40)
        %v89983_v9 = vshll.u32 %v147651_v7, 15 (stack45)
        %v87570_v25 = vsel /*vm=*/%vm147669_vm10, /*on_true_vy=*/%v87423_v41, /*on_false_vx=*/%v87566_v26 (stack44)
        %v147690_v61 = vadd.f32 -2.5, %v147665_v60 (stack53)
        %v89524_v10 = vshll.u32 %v89518_v30, 17 (stack45)
        %v89525_v56 = vshrl.u32 %v89518_v30, 15 (stack46)
        %v87574_v20 = vmul.f32 1.4140625, %v87570_v25 (stack54)
        %v147695_v24 = vsel /*vm=*/%vm87903_vm11, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v147700_v30 = vsel /*vm=*/%vm87903_vm11, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v88314_v53 = vand.u32.u8 255, %v88313_v44 (stack49)
        %vm90395_vm12 = vcmp.lt.u32.totalorder %v147677_v6, %v147631_v45 (stack43)
        %v88704_v32 = vadd.s32 %v88701_v42, %v88696_v32 (stack40)
        %v88706_v12 = vshll.u32 %v88701_v42, 16 (stack45)
        %v88707_v40 = vshrl.u32 %v88701_v42, 16 (stack46)
        %v89105_v43 = vadd.s32 %v89101_v23, %v89089_v55 (stack40)
        %v87577_v44 = vpack.c.bf16 %v157387_v11, %v87574_v20 (stack81)
        %v88315_v27 = vand.u32 65535, %v88314_v53 (stack50)
        %v89107_v21 = vshll.u32 %v89101_v23, 13 (stack45)
        %v89108_v52 = vshrl.u32 %v89101_v23, 19 (stack46)
        %vm87948_vm13 = vcmp.eq.f32.partialorder %v147665_v60, inf (stack70)
        %v88708_v41 = vor.u32 %v88707_v40, %v88706_v12 (stack47)
        %v89526_v26 = vor.u32 %v89525_v56, %v89524_v10 (stack47)
        %v89984_v7 = vshrl.u32 %v147651_v7, 17 (stack46)
        %v90409_v23 = vadd.s32 1, %v147635_v29 (stack40)
        %120213 = vst [vmem:[%s123356_s30 + $0x15c] sm:$0xf] /*vst_source=*/%v87577_v44 (stack83)
        %v87940_v42 = vsel /*vm=*/%vm87903_vm11, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v88316_v55 = vshrl.u32 %v88315_v27, 1 (stack51)
        %v89109_v25 = vor.u32 %v89108_v52, %v89107_v21 (stack47)
        %v147714_v10 = vadd.s32 %v157642_v8, %v157077_v51 (stack40)
        %vm87950_vm14 = vcmp.eq.f32.partialorder %v147665_v60, 0.0 (stack71)
        %v88709_v56 = vxor.u32 %v88708_v41, %v88704_v32 (stack48)
        %v89527_v20 = vxor.u32 %v89526_v26, %v89522_v46 (stack48)
        %v90413_v29 = vsel /*vm=*/%vm90400_vm9, /*on_true_vy=*/%v90409_v23, /*on_false_vx=*/%v147635_v29 (stack44)
        %v88317_v53 = vor.u32 16256, %v88316_v55 (stack47)
        %v89110_v12 = vxor.u32 %v89109_v25, %v89105_v43 (stack48)
        %v89985_v9 = vor.u32 %v89984_v7, %v89983_v9 (stack47)
        %v90417_v40 = vadd.s32 1, %v90413_v29 (stack40)
        %v88712_v32 = vadd.s32 %v88709_v56, %v88704_v32 (stack40)
        %v88718_v44 = vshll.u32 %v88709_v56, 24 (stack45)
        %v88719_v27 = vshrl.u32 %v88709_v56, 8 (stack46)
        %v89530_v46 = vadd.s32 %v89527_v20, %v89522_v46 (stack40)
        %v88318_v21 = vand.u32.u16 65535, %v88317_v53 (stack52)
        %v89113_v43 = vadd.s32 %v89110_v12, %v89105_v43 (stack40)
        %v89115_v52 = vshll.u32 %v89110_v12, 15 (stack45)
        %v89116_v41 = vshrl.u32 %v89110_v12, 17 (stack46)
        %v121184_v26 = vpop.eup %121183 (stack73)
        %v87951_v7 = vand.u32 2147483648, %v147665_v60 (stack72)
        %v88720_v23 = vor.u32 %v88719_v27, %v88718_v44 (stack47)
        %v89532_v55 = vshll.u32 %v89527_v20, 29 (stack45)
        %v89533_v25 = vshrl.u32 %v89527_v20, 3 (stack46)
        %v87947_v56 = vmul.f32 %v121184_v26, %v147665_v60 (stack74)
        %v120216_v20 = vadd.low.f32.bf16 -1.0, %v88318_v21 (stack53)
        %v89117_v53 = vor.u32 %v89116_v41, %v89115_v52 (stack47)
        %v89986_v12 = vxor.u32 %v89985_v9, %v147660_v54 (stack48)
        %v88716_v9 = vadd.s32 %v88712_v32, %v121569_v1 (stack40)
        %v88721_v32 = vxor.u32 %v88720_v23, %v88712_v32 (stack48)
        %v89534_v44 = vor.u32 %v89533_v25, %v89532_v55 (stack47)
        %v90421_v45 = vsel /*vm=*/%vm90395_vm12, /*on_true_vy=*/%v90417_v40, /*on_false_vx=*/%v90413_v29 (stack44)
        %v87949_v29 = vsel /*vm=*/%vm87948_vm13, /*on_true_vy=*/%v147665_v60, /*on_false_vx=*/%v87947_v56 (stack75)
        %v88327_v40 = vmul.f32 2.0, %v120216_v20 (stack54)
        %v89118_v27 = vxor.u32 %v89117_v53, %v89113_v43 (stack48)
        %v89989_v54 = vadd.s32 %v89986_v12, %v147660_v54 (stack40)
        %v87952_v21 = vsel /*vm=*/%vm87950_vm14, /*on_true_vy=*/%v87951_v7, /*on_false_vx=*/%v87949_v29 (stack76)
        %v88724_v52 = vadd.s32 %v88721_v32, %v121564_v0 (stack40)
        %v89535_v41 = vxor.u32 %v89534_v44, %v89530_v46 (stack48)
        %v89991_v26 = vshll.u32 %v89986_v12, 26 (stack45)
        %v87955_v7 = vadd.f32 -3.0, %v87952_v21 (stack53)
        %v88331_v23 = vadd.f32 -0.99609375, %v88327_v40 (stack53)
        %v89121_v43 = vadd.s32 %v89118_v27, %v89113_v43 (stack40)
        %v89123_v55 = vshll.u32 %v89118_v27, 26 (stack45)
        %v88728_v25 = vadd.s32 4, %v88724_v52 (stack40)
        %v89124_v56 = vshrl.u32 %v89118_v27, 6 (stack46)
        %v89538_v46 = vadd.s32 %v89535_v41, %v89530_v46 (stack40)
        %v89540_v20 = vshll.u32 %v89535_v41, 16 (stack45)
        %v147738_v61 = vsel /*vm=*/%vm87903_vm11, /*on_true_vy=*/%v147690_v61, /*on_false_vx=*/%v87955_v7 (stack44)
        %v147740_v53 = vmax.f32 %v88331_v23, -0.99609375 (stack55)
        %v89541_v32 = vshrl.u32 %v89535_v41, 16 (stack46)
        %v89992_v12 = vshrl.u32 %v89986_v12, 6 (stack46)
        %v87963_v42 = vmul.f32 %v147738_v61, %v87940_v42 (stack54)
        %v88732_v9 = vadd.s32 %v88728_v25, %v88716_v9 (stack40)
        %v88734_v44 = vshll.u32 %v88728_v25, 13 (stack45)
        %v88735_v29 = vshrl.u32 %v88728_v25, 19 (stack46)
        %v87936_v40 = vsel /*vm=*/%vm87903_vm11, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v88347_v27 = vxor.u32 2147483648, %v147740_v53 (stack56)
        %v89125_v21 = vor.u32 %v89124_v56, %v89123_v55 (stack47)
        %v90430_v6 = vadd.s32 %v147677_v6, %v121569_v1 (stack40)
        %v87967_v52 = vadd.f32 %v87963_v42, %v87936_v40 (stack53)
        %v88736_v41 = vor.u32 %v88735_v29, %v88734_v44 (stack47)
        %v89542_v7 = vor.u32 %v89541_v32, %v89540_v20 (stack47)
        %v89993_v26 = vor.u32 %v89992_v12, %v89991_v26 (stack47)
        %v87924_v23 = vsel /*vm=*/%vm87903_vm11, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v87928_v55 = vsel /*vm=*/%vm87903_vm11, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v147756_v25 = vmul.f32 %v88347_v27, %v147740_v53 (stack54)
        %v89126_v56 = vxor.u32 %v89125_v21, %v89121_v43 (stack48)
        %v87971_v20 = vmul.f32 %v87967_v52, %v147738_v61 (stack54)
        %v88737_v32 = vxor.u32 %v88736_v41, %v88732_v9 (stack48)
        %v89543_v12 = vxor.u32 %v89542_v7, %v89538_v46 (stack48)
        %v89994_v42 = vxor.u32 %v89993_v26, %v89989_v54 (stack48)
        %v87932_v44 = vsel /*vm=*/%vm87903_vm11, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v88352_v29 = vadd.f32 1.0, %v147756_v25 (stack57)
        %v89129_v43 = vadd.s32 %v89126_v56, %v89121_v43 (stack40)
        %v90436_v40 = vshll.u32 %v90430_v6, 13 (stack45)
        %v87975_v27 = vadd.f32 %v87971_v20, %v87932_v44 (stack53)
        %v88740_v9 = vadd.s32 %v88737_v32, %v88732_v9 (stack40)
        %v88742_v21 = vshll.u32 %v88737_v32, 15 (stack45)
        %v88743_v52 = vshrl.u32 %v88737_v32, 17 (stack46)
        %121185 = vlog2.f32 %v88352_v29 (stack58)
        %v88355_v41 = vmul.f32 -0.5, %v147756_v25 (stack59)
        %v90426_v45 = vadd.s32 %v90421_v45, %v121574_v2 (stack40)
        %v90437_v7 = vshrl.u32 %v90430_v6, 19 (stack46)
        %v87979_v26 = vmul.f32 %v87975_v27, %v147738_v61 (stack54)
        %v88744_v20 = vor.u32 %v88743_v52, %v88742_v21 (stack47)
        %v89135_v32 = vshll.u32 %v89126_v56, 6 (stack45)
        %v89136_v56 = vshrl.u32 %v89126_v56, 26 (stack46)
        %v88358_v44 = vand.u32 2147483647, %v147756_v25 (stack60)
        %v89546_v46 = vadd.s32 %v89543_v12, %v89538_v46 (stack40)
        %v89552_v29 = vshll.u32 %v89543_v12, 24 (stack45)
        %v89553_v12 = vshrl.u32 %v89543_v12, 8 (stack46)
        %v87983_v55 = vadd.f32 %v87979_v26, %v87928_v55 (stack53)
        %v88745_v27 = vxor.u32 %v88744_v20, %v88740_v9 (stack48)
        %v89137_v21 = vor.u32 %v89136_v56, %v89135_v32 (stack47)
        %v89997_v54 = vadd.s32 %v89994_v42, %v89989_v54 (stack40)
        %v88356_v52 = vadd.f32 1.0, %v88355_v41 (stack61)
        %v89554_v41 = vor.u32 %v89553_v12, %v89552_v29 (stack47)
        %v90003_v26 = vshll.u32 %v89994_v42, 6 (stack45)
        %v90004_v42 = vshrl.u32 %v89994_v42, 26 (stack46)
        %v87987_v20 = vmul.f32 %v87983_v55, %v147738_v61 (stack54)
        %v88748_v9 = vadd.s32 %v88745_v27, %v88740_v9 (stack40)
        %v88750_v32 = vshll.u32 %v88745_v27, 26 (stack45)
        %v88751_v56 = vshrl.u32 %v88745_v27, 6 (stack46)
        %v89133_v29 = vadd.s32 %v89129_v43, %v121574_v2 (stack40)
        %v89138_v43 = vxor.u32 %v89137_v21, %v89129_v43 (stack48)
        %v89555_v12 = vxor.u32 %v89554_v41, %v89546_v46 (stack48)
        %v90005_v55 = vor.u32 %v90004_v42, %v90003_v26 (stack47)
        %v87991_v23 = vadd.f32 %v87987_v20, %v87924_v23 (stack53)
        %v88752_v27 = vor.u32 %v88751_v56, %v88750_v32 (stack47)
        %v90434_v6 = vadd.s32 %v90430_v6, %v90426_v45 (stack40)
        %v90438_v40 = vor.u32 %v90437_v7, %v90436_v40 (stack47)
        %v88357_v25 = vmul.f32 %v88356_v52, %v147756_v25 (stack63)
        %v89141_v45 = vadd.s32 %v89138_v43, %v121569_v1 (stack40)
        %v89558_v7 = vadd.s32 %v89555_v12, %v121574_v2 (stack40)
        %v90006_v21 = vxor.u32 %v90005_v55, %v89997_v54 (stack48)
        %v87995_v52 = vmul.f32 %v87991_v23, %v147738_v61 (stack54)
        %v88753_v41 = vxor.u32 %v88752_v27, %v88748_v9 (stack48)
        %v147773_v26 = vxor.u32 %v90438_v40, %v90434_v6 (stack48)
        %vm90861_vm15 = vcmp.lt.u32.totalorder %v147714_v10, %v157077_v51 (stack43)
        %v89145_v42 = vadd.s32 3, %v89141_v45 (stack40)
        %v89550_v46 = vadd.s32 %v89546_v46, %v121564_v0 (stack40)
        %v89562_v20 = vadd.s32 2, %v89558_v7 (stack40)
        %v90009_v32 = vadd.s32 %v90006_v21, %v121564_v0 (stack40)
        %v87999_v30 = vadd.f32 %v87995_v52, %v147700_v30 (stack53)
        %v88756_v9 = vadd.s32 %v88753_v41, %v88748_v9 (stack40)
        %v88762_v56 = vshll.u32 %v88753_v41, 6 (stack45)
        %v88763_v43 = vshrl.u32 %v88753_v41, 26 (stack46)
        %v89149_v29 = vadd.s32 %v89145_v42, %v89133_v29 (stack40)
        %v89151_v12 = vshll.u32 %v89145_v42, 17 (stack45)
        %v89152_v55 = vshrl.u32 %v89145_v42, 15 (stack46)
        %v89566_v23 = vadd.s32 %v89562_v20, %v89550_v46 (stack40)
        %v121186_v27 = vpop.eup %121185 (stack64)
        %v88003_v40 = vmul.f32 %v87999_v30, %v147738_v61 (stack54)
        %v88764_v45 = vor.u32 %v88763_v43, %v88762_v56 (stack47)
        %v89568_v7 = vshll.u32 %v89562_v20, 13 (stack45)
        %v90001_v54 = vadd.s32 %v89997_v54, %v121569_v1 (stack40)
        %v88354_v21 = vmul.f32 0.6931472, %v121186_v27 (stack65)
        %v89153_v52 = vor.u32 %v89152_v55, %v89151_v12 (stack47)
        %v89569_v41 = vshrl.u32 %v89562_v20, 19 (stack46)
        %v90013_v42 = vadd.s32 1, %v90009_v32 (stack40)
        %v88007_v24 = vadd.f32 %v88003_v40, %v147695_v24 (stack53)
        %vm88359_vm0 = vcmp.lt.f32.partialorder %v88358_v44, 0.0004427343 (stack62)
        %v88765_v44 = vxor.u32 %v88764_v45, %v88756_v9 (stack48)
        %v147784_v6 = vadd.s32 %v147773_v26, %v90434_v6 (stack40)
        %v88360_v25 = vsel /*vm=*/%vm88359_vm0, /*on_true_vy=*/%v88357_v25, /*on_false_vx=*/%v88354_v21 (stack66)
        %v89154_v46 = vxor.u32 %v89153_v52, %v89149_v29 (stack48)
        %v89570_v20 = vor.u32 %v89569_v41, %v89568_v7 (stack47)
        %v147786_v32 = vadd.s32 %v90013_v42, %v90001_v54 (stack40)
        %v87908_v30 = vsel /*vm=*/%vm87903_vm11, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v87912_v60 = vsel /*vm=*/%vm87903_vm11, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v88011_v56 = vmul.f32 %v88007_v24, %v147738_v61 (stack54)
        %v147795_v43 = vxor.u32 2147483648, %v88360_v25 (stack56)
        %vm147799_vm1 = vcmp.eq.f32.partialorder %v87876_v31, 1.0 (stack68)
        %v89157_v29 = vadd.s32 %v89154_v46, %v89149_v29 (stack40)
        %v89159_v12 = vshll.u32 %v89154_v46, 29 (stack45)
        %v89160_v55 = vshrl.u32 %v89154_v46, 3 (stack46)
        %v89571_v27 = vxor.u32 %v89570_v20, %v89566_v23 (stack48)
        %v88015_v40 = vadd.f32 %v88011_v56, %v87912_v60 (stack53)
        %v88337_v45 = vand.u32 2147483647, %v147740_v53 (stack77)
        %vm88364_vm2 = vcmp.lt.f32.partialorder %v147795_v43, 5.0 (stack68)
        %121187 = vrsqrt.f32 %v147795_v43 (stack67)
        %v88760_v9 = vadd.s32 %v88756_v9, %v121564_v0 (stack40)
        %v88768_v7 = vadd.s32 %v88765_v44, %v121574_v2 (stack40)
        %v89161_v54 = vor.u32 %v89160_v55, %v89159_v12 (stack47)
        %v147810_v21 = vadd.s32 %v147714_v10, %v122657_v58 (stack40)
        %v88019_v61 = vmul.f32 %v88015_v40, %v147738_v61 (stack54)
        %v147814_v52 = vadd.f32 -2.5, %v147795_v43 (stack53)
        %v90019_v41 = vshll.u32 %v90013_v42, 17 (stack45)
        %v90444_v24 = vshll.u32 %v147773_v26, 15 (stack45)
        %v147820_v44 = vsel /*vm=*/%vm88364_vm2, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v147825_v25 = vsel /*vm=*/%vm88364_vm2, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v147830_v46 = vsel /*vm=*/%vm88364_vm2, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v89162_v20 = vxor.u32 %v89161_v54, %v89157_v29 (stack48)
        %v88023_v30 = vadd.f32 %v88019_v61, %v87908_v30 (stack53)
        %v147835_v60 = vsel /*vm=*/%vm88364_vm2, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v147840_v56 = vsel /*vm=*/%vm88364_vm2, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v147845_v12 = vsel /*vm=*/%vm88364_vm2, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v88772_v55 = vadd.s32 5, %v88768_v7 (stack40)
        %v89165_v29 = vadd.s32 %v89162_v20, %v89157_v29 (stack40)
        %v89167_v40 = vshll.u32 %v89162_v20, 16 (stack45)
        %v89168_v7 = vshrl.u32 %v89162_v20, 16 (stack46)
        %v88027_v34 = vmul.f32 %v88023_v30, %v147598_v34 (stack54)
        %v89574_v23 = vadd.s32 %v89571_v27, %v89566_v23 (stack40)
        %v89576_v54 = vshll.u32 %v89571_v27, 15 (stack45)
        %v89577_v27 = vshrl.u32 %v89571_v27, 17 (stack46)
        %vm88409_vm3 = vcmp.eq.f32.partialorder %v147795_v43, inf (stack70)
        %v88774_v9 = vxor.u32 %v88772_v55, %v88760_v9 (stack48)
        %v89169_v61 = vor.u32 %v89168_v7, %v89167_v40 (stack47)
        %v90020_v42 = vshrl.u32 %v90013_v42, 15 (stack46)
        %v90445_v26 = vshrl.u32 %v147773_v26, 17 (stack46)
        %v88031_v50 = vsel /*vm=*/%vm147799_vm1, /*on_true_vy=*/%v147683_v50, /*on_false_vx=*/%v88027_v34 (stack44)
        %vm88411_vm4 = vcmp.eq.f32.partialorder %v147795_v43, 0.0 (stack71)
        %v89578_v31 = vor.u32 %v89577_v27, %v89576_v54 (stack47)
        %v90866_v20 = vadd.s32 %v157645_v22, %v157078_v48 (stack40)
        %v88035_v30 = vmul.f32 1.4140625, %v88031_v50 (stack54)
        %v88775_v55 = vand.u32.u8 255, %v88774_v9 (stack49)
        %v89170_v40 = vxor.u32 %v89169_v61, %v89165_v29 (stack48)
        %v90021_v41 = vor.u32 %v90020_v42, %v90019_v41 (stack47)
        %v88412_v7 = vand.u32 2147483648, %v147795_v43 (stack72)
        %v89579_v34 = vxor.u32 %v89578_v31, %v89574_v23 (stack48)
        %v90446_v24 = vor.u32 %v90445_v26, %v90444_v24 (stack47)
        %v90870_v54 = vadd.s32 1, %v90866_v20 (stack40)
        %v88038_v27 = vpack.c.bf16 %v157387_v11, %v88035_v30 (stack81)
        %v88776_v9 = vand.u32 65535, %v88775_v55 (stack50)
        %v89173_v29 = vadd.s32 %v89170_v40, %v89165_v29 (stack40)
        %v89179_v61 = vshll.u32 %v89170_v40, 24 (stack45)
        %v89180_v42 = vshrl.u32 %v89170_v40, 8 (stack46)
        %v89582_v23 = vadd.s32 %v89579_v34, %v89574_v23 (stack40)
        %v89584_v26 = vshll.u32 %v89579_v34, 26 (stack45)
        %v89585_v50 = vshrl.u32 %v89579_v34, 6 (stack46)
        %v121188_v31 = vpop.eup %121187 (stack73)
        %120215 = vst [vmem:[%s123356_s30 + $0x1dc] sm:$0xf] /*vst_source=*/%v88038_v27 (stack83)
        %v88777_v30 = vshrl.u32 %v88776_v9, 1 (stack51)
        %v90022_v55 = vxor.u32 %v90021_v41, %v147786_v32 (stack48)
        %v90447_v40 = vxor.u32 %v90446_v24, %v147784_v6 (stack48)
        %vm90856_vm5 = vcmp.lt.u32.totalorder %v147810_v21, %v147714_v10 (stack43)
        %v147865_v41 = vadd.s32 %v147810_v21, %v121569_v1 (stack40)
        %v88408_v34 = vmul.f32 %v121188_v31, %v147795_v43 (stack74)
        %v89181_v24 = vor.u32 %v89180_v42, %v89179_v61 (stack47)
        %v89586_v27 = vor.u32 %v89585_v50, %v89584_v26 (stack47)
        %v90874_v20 = vsel /*vm=*/%vm90861_vm15, /*on_true_vy=*/%v90870_v54, /*on_false_vx=*/%v90866_v20 (stack44)
        %v88778_v54 = vor.u32 16256, %v88777_v30 (stack47)
        %v90025_v32 = vadd.s32 %v90022_v55, %v147786_v32 (stack40)
        %v90027_v9 = vshll.u32 %v90022_v55, 29 (stack45)
        %v90028_v61 = vshrl.u32 %v90022_v55, 3 (stack46)
        %v88410_v42 = vsel /*vm=*/%vm88409_vm3, /*on_true_vy=*/%v147795_v43, /*on_false_vx=*/%v88408_v34 (stack75)
        %v89182_v26 = vxor.u32 %v89181_v24, %v89173_v29 (stack48)
        %v89587_v50 = vxor.u32 %v89586_v27, %v89582_v23 (stack48)
        %v147876_v6 = vadd.s32 %v90447_v40, %v147784_v6 (stack40)
        %v88413_v7 = vsel /*vm=*/%vm88411_vm4, /*on_true_vy=*/%v88412_v7, /*on_false_vx=*/%v88410_v42 (stack76)
        %v88779_v31 = vand.u32.u16 65535, %v88778_v54 (stack52)
        %v89177_v29 = vadd.s32 %v89173_v29, %v121569_v1 (stack40)
        %v90029_v30 = vor.u32 %v90028_v61, %v90027_v9 (stack47)
        %v88416_v55 = vadd.f32 -3.0, %v88413_v7 (stack53)
        %v89185_v34 = vadd.s32 %v89182_v26, %v121564_v0 (stack40)
        %v89590_v23 = vadd.s32 %v89587_v50, %v89582_v23 (stack40)
        %v89596_v24 = vshll.u32 %v89587_v50, 6 (stack45)
        %v120218_v27 = vadd.low.f32.bf16 -1.0, %v88779_v31 (stack53)
        %v89597_v54 = vshrl.u32 %v89587_v50, 26 (stack46)
        %v90030_v9 = vxor.u32 %v90029_v30, %v90025_v32 (stack48)
        %v90452_v61 = vshll.u32 %v90447_v40, 26 (stack45)
        %v147885_v52 = vsel /*vm=*/%vm88364_vm2, /*on_true_vy=*/%v147814_v52, /*on_false_vx=*/%v88416_v55 (stack44)
        %v89189_v42 = vadd.s32 4, %v89185_v34 (stack40)
        %v90453_v40 = vshrl.u32 %v90447_v40, 6 (stack46)
        %v90878_v26 = vadd.s32 1, %v90874_v20 (stack40)
        %v88424_v12 = vmul.f32 %v147885_v52, %v147845_v12 (stack54)
        %v88788_v50 = vmul.f32 2.0, %v120218_v27 (stack54)
        %v89598_v7 = vor.u32 %v89597_v54, %v89596_v24 (stack47)
        %v90033_v32 = vadd.s32 %v90030_v9, %v90025_v32 (stack40)
        %v89193_v31 = vadd.s32 %v89189_v42, %v89177_v29 (stack40)
        %v89195_v29 = vshll.u32 %v89189_v42, 13 (stack45)
        %v89196_v30 = vshrl.u32 %v89189_v42, 19 (stack46)
        %v90035_v55 = vshll.u32 %v90030_v9, 16 (stack45)
        %v88428_v56 = vadd.f32 %v88424_v12, %v147840_v56 (stack53)
        %v88792_v34 = vadd.f32 -0.99609375, %v88788_v50 (stack53)
        %v89599_v24 = vxor.u32 %v89598_v7, %v89590_v23 (stack48)
        %v90036_v27 = vshrl.u32 %v90030_v9, 16 (stack46)
        %v88385_v54 = vsel /*vm=*/%vm88364_vm2, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v89197_v9 = vor.u32 %v89196_v30, %v89195_v29 (stack47)
        %v90454_v61 = vor.u32 %v90453_v40, %v90452_v61 (stack47)
        %v90882_v10 = vsel /*vm=*/%vm90856_vm5, /*on_true_vy=*/%v90878_v26, /*on_false_vx=*/%v90874_v20 (stack44)
        %v88432_v21 = vmul.f32 %v88428_v56, %v147885_v52 (stack54)
        %v147897_v20 = vmax.f32 %v88792_v34, -0.99609375 (stack55)
        %v89602_v42 = vadd.s32 %v89599_v24, %v121569_v1 (stack40)
        %v90037_v40 = vor.u32 %v90036_v27, %v90035_v55 (stack47)
        %v88393_v26 = vsel /*vm=*/%vm88364_vm2, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v89198_v12 = vxor.u32 %v89197_v9, %v89193_v31 (stack48)
        %v90455_v50 = vxor.u32 %v90454_v61, %v147876_v6 (stack48)
        %v90897_v7 = vshll.u32 %v147865_v41, 13 (stack45)
        %v88436_v29 = vadd.f32 %v88432_v21, %v88393_v26 (stack53)
        %v88808_v30 = vxor.u32 2147483648, %v147897_v20 (stack56)
        %v89594_v23 = vadd.s32 %v89590_v23, %v121574_v2 (stack40)
        %v90898_v55 = vshrl.u32 %v147865_v41, 19 (stack46)
        %v89201_v31 = vadd.s32 %v89198_v12, %v89193_v31 (stack40)
        %v89203_v56 = vshll.u32 %v89198_v12, 15 (stack45)
        %v89204_v34 = vshrl.u32 %v89198_v12, 17 (stack46)
        %v89606_v24 = vadd.s32 3, %v89602_v42 (stack40)
        %v88389_v43 = vsel /*vm=*/%vm88364_vm2, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v88440_v27 = vmul.f32 %v88436_v29, %v147885_v52 (stack54)
        %v88811_v9 = vmul.f32 %v88808_v30, %v147897_v20 (stack54)
        %v90038_v61 = vxor.u32 %v90037_v40, %v90033_v32 (stack48)
        %v89205_v21 = vor.u32 %v89204_v34, %v89203_v56 (stack47)
        %v89610_v42 = vadd.s32 %v89606_v24, %v89594_v23 (stack40)
        %v89612_v40 = vshll.u32 %v89606_v24, 17 (stack45)
        %v89613_v26 = vshrl.u32 %v89606_v24, 15 (stack46)
        %v88444_v12 = vadd.f32 %v88440_v27, %v88389_v43 (stack53)
        %v88813_v29 = vadd.f32 1.0, %v88811_v9 (stack57)
        %v88816_v30 = vmul.f32 -0.5, %v88811_v9 (stack59)
        %v90887_v10 = vadd.s32 %v90882_v10, %v121574_v2 (stack40)
        %v89206_v23 = vxor.u32 %v89205_v21, %v89201_v31 (stack48)
        %v89614_v56 = vor.u32 %v89613_v26, %v89612_v40 (stack47)
        %v90041_v32 = vadd.s32 %v90038_v61, %v90033_v32 (stack40)
        %v90899_v7 = vor.u32 %v90898_v55, %v90897_v7 (stack47)
        %v88448_v55 = vmul.f32 %v88444_v12, %v147885_v52 (stack54)
        %121189 = vlog2.f32 %v88813_v29 (stack58)
        %v88817_v34 = vadd.f32 1.0, %v88816_v30 (stack61)
        %v90047_v24 = vshll.u32 %v90038_v61, 24 (stack45)
        %v89209_v31 = vadd.s32 %v89206_v23, %v89201_v31 (stack40)
        %v89211_v43 = vshll.u32 %v89206_v23, 26 (stack45)
        %v89212_v27 = vshrl.u32 %v89206_v23, 6 (stack46)
        %v89615_v21 = vxor.u32 %v89614_v56, %v89610_v42 (stack48)
        %v88452_v54 = vadd.f32 %v88448_v55, %v88385_v54 (stack53)
        %v88818_v40 = vmul.f32 %v88817_v34, %v88811_v9 (stack63)
        %v88819_v9 = vand.u32 2147483647, %v88811_v9 (stack60)
        %v90048_v61 = vshrl.u32 %v90038_v61, 8 (stack46)
        %v89213_v26 = vor.u32 %v89212_v27, %v89211_v43 (stack47)
        %v89618_v42 = vadd.s32 %v89615_v21, %v89610_v42 (stack40)
        %v89620_v12 = vshll.u32 %v89615_v21, 29 (stack45)
        %v89621_v29 = vshrl.u32 %v89615_v21, 3 (stack46)
        %v88456_v30 = vmul.f32 %v88452_v54, %v147885_v52 (stack54)
        %v90049_v23 = vor.u32 %v90048_v61, %v90047_v24 (stack47)
        %v90458_v6 = vadd.s32 %v90455_v50, %v147876_v6 (stack40)
        %v90464_v56 = vshll.u32 %v90455_v50, 6 (stack45)
        %v89214_v55 = vxor.u32 %v89213_v26, %v89209_v31 (stack48)
        %v89622_v34 = vor.u32 %v89621_v29, %v89620_v12 (stack47)
        %v90465_v50 = vshrl.u32 %v90455_v50, 26 (stack46)
        %v90895_v41 = vadd.s32 %v147865_v41, %v90887_v10 (stack40)
        %v88460_v60 = vadd.f32 %v88456_v30, %v147835_v60 (stack53)
        %v90045_v10 = vadd.s32 %v90041_v32, %v121564_v0 (stack40)
        %v90050_v32 = vxor.u32 %v90049_v23, %v90041_v32 (stack48)
        %v147922_v24 = vadd.s32 %v157642_v8, %v157079_v39 (stack40)
        %vm147924_vm6 = vcmp.lt.f32.partialorder %v88819_v9, 0.0004427343 (stack62)
        %v89217_v31 = vadd.s32 %v89214_v55, %v89209_v31 (stack40)
        %v89223_v27 = vshll.u32 %v89214_v55, 6 (stack45)
        %v89224_v21 = vshrl.u32 %v89214_v55, 26 (stack46)
        %v89623_v54 = vxor.u32 %v89622_v34, %v89618_v42 (stack48)
        %v88464_v9 = vmul.f32 %v88460_v60, %v147885_v52 (stack54)
        %v90053_v61 = vadd.s32 %v90050_v32, %v121574_v2 (stack40)
        %v90466_v26 = vor.u32 %v90465_v50, %v90464_v56 (stack47)
        %v90900_v7 = vxor.u32 %v90899_v7, %v90895_v41 (stack48)
        %v89225_v12 = vor.u32 %v89224_v21, %v89223_v27 (stack47)
        %v89626_v42 = vadd.s32 %v89623_v54, %v89618_v42 (stack40)
        %v89628_v29 = vshll.u32 %v89623_v54, 16 (stack45)
        %v90462_v30 = vadd.s32 %v90458_v6, %v121569_v1 (stack40)
        %v88468_v46 = vadd.f32 %v88464_v9, %v147830_v46 (stack53)
        %v89629_v23 = vshrl.u32 %v89623_v54, 16 (stack46)
        %v90057_v56 = vadd.s32 2, %v90053_v61 (stack40)
        %v90467_v6 = vxor.u32 %v90466_v26, %v90458_v6 (stack48)
        %v89226_v55 = vxor.u32 %v89225_v12, %v89217_v31 (stack48)
        %v90903_v34 = vadd.s32 %v90900_v7, %v90895_v41 (stack40)
        %v90905_v50 = vshll.u32 %v90900_v7, 15 (stack45)
        %v90906_v41 = vshrl.u32 %v90900_v7, 17 (stack46)
        %v88472_v60 = vmul.f32 %v88468_v46, %v147885_v52 (stack54)
        %v89630_v32 = vor.u32 %v89629_v23, %v89628_v29 (stack47)
        %v90061_v10 = vadd.s32 %v90057_v56, %v90045_v10 (stack40)
        %v90063_v27 = vshll.u32 %v90057_v56, 13 (stack45)
        %v121190_v21 = vpop.eup %121189 (stack64)
        %v89229_v54 = vadd.s32 %v89226_v55, %v121574_v2 (stack40)
        %v90064_v9 = vshrl.u32 %v90057_v56, 19 (stack46)
        %v90470_v61 = vadd.s32 %v90467_v6, %v121564_v0 (stack40)
        %v90907_v26 = vor.u32 %v90906_v41, %v90905_v50 (stack47)
        %v88476_v25 = vadd.f32 %v88472_v60, %v147825_v25 (stack53)
        %v88815_v7 = vmul.f32 0.6931472, %v121190_v21 (stack65)
        %v89221_v31 = vadd.s32 %v89217_v31, %v121564_v0 (stack40)
        %v89631_v12 = vxor.u32 %v89630_v32, %v89626_v42 (stack48)
        %v89233_v29 = vadd.s32 5, %v89229_v54 (stack40)
        %v90065_v46 = vor.u32 %v90064_v9, %v90063_v27 (stack47)
        %v90474_v23 = vadd.s32 1, %v90470_v61 (stack40)
        %v90908_v56 = vxor.u32 %v90907_v26, %v90903_v34 (stack48)
        %v88480_v52 = vmul.f32 %v88476_v25, %v147885_v52 (stack54)
        %v88821_v40 = vsel /*vm=*/%vm147924_vm6, /*on_true_vy=*/%v88818_v40, /*on_false_vx=*/%v88815_v7 (stack66)
        %v89634_v43 = vadd.s32 %v89631_v12, %v89626_v42 (stack40)
        %v89640_v42 = vshll.u32 %v89631_v12, 24 (stack45)
        %v147940_v6 = vxor.u32 2147483648, %v88821_v40 (stack56)
        %v89235_v55 = vxor.u32 %v89233_v29, %v89221_v31 (stack48)
        %v89641_v50 = vshrl.u32 %v89631_v12, 8 (stack46)
        %v90066_v41 = vxor.u32 %v90065_v46, %v90061_v10 (stack48)
        %v88484_v44 = vadd.f32 %v88480_v52, %v147820_v44 (stack53)
        %v90478_v30 = vadd.s32 %v90474_v23, %v90462_v30 (stack40)
        %121191 = vrsqrt.f32 %v147940_v6 (stack67)
        %v88345_v60 = vmul.f32 inf, %v147740_v53 (stack54)
        %v88488_v32 = vmul.f32 %v88484_v44, %v147740_v53 (stack54)
        %vm88825_vm7 = vcmp.lt.f32.partialorder %v147940_v6, 5.0 (stack68)
        %vm88340_vm8 = vcmp.eq.f32.partialorder %v88337_v45, 1.0 (stack68)
        %v89642_v53 = vor.u32 %v89641_v50, %v89640_v42 (stack47)
        %v147951_v45 = vadd.s32 %v147922_v24, %v122657_v58 (stack40)
        %v88492_v27 = vsel /*vm=*/%vm88340_vm8, /*on_true_vy=*/%v88345_v60, /*on_false_vx=*/%v88488_v32 (stack44)
        %v147954_v21 = vadd.f32 -2.5, %v147940_v6 (stack53)
        %v89638_v54 = vadd.s32 %v89634_v43, %v121569_v1 (stack40)
        %v90480_v9 = vshll.u32 %v90474_v23, 17 (stack45)
        %v88496_v61 = vmul.f32 1.4140625, %v88492_v27 (stack54)
        %v147960_v26 = vsel /*vm=*/%vm88825_vm7, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v147965_v25 = vsel /*vm=*/%vm88825_vm7, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v89236_v7 = vand.u32.u8 255, %v89235_v55 (stack49)
        %v89643_v31 = vxor.u32 %v89642_v53, %v89634_v43 (stack48)
        %v90069_v10 = vadd.s32 %v90066_v41, %v90061_v10 (stack40)
        %v90071_v12 = vshll.u32 %v90066_v41, 15 (stack45)
        %v90072_v29 = vshrl.u32 %v90066_v41, 17 (stack46)
        %v88499_v46 = vpack.c.bf16 %v157387_v11, %v88496_v61 (stack81)
        %v89237_v52 = vand.u32 65535, %v89236_v7 (stack50)
        %v90481_v23 = vshrl.u32 %v90474_v23, 15 (stack46)
        %v90911_v34 = vadd.s32 %v90908_v56, %v90903_v34 (stack40)
        %vm88870_vm9 = vcmp.eq.f32.partialorder %v147940_v6, inf (stack70)
        %v89646_v40 = vadd.s32 %v89643_v31, %v121564_v0 (stack40)
        %v90073_v43 = vor.u32 %v90072_v29, %v90071_v12 (stack47)
        %v90913_v42 = vshll.u32 %v90908_v56, 26 (stack45)
        %v90914_v56 = vshrl.u32 %v90908_v56, 6 (stack46)
        %120217 = vst [vmem:[%s123356_s30 + $0x25c] sm:$0xf] /*vst_source=*/%v88499_v46 (stack83)
        %v147974_v55 = vsel /*vm=*/%vm88825_vm7, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v89238_v50 = vshrl.u32 %v89237_v52, 1 (stack51)
        %v90482_v41 = vor.u32 %v90481_v23, %v90480_v9 (stack47)
        %vm91322_vm10 = vcmp.lt.u32.totalorder %v147922_v24, %v157079_v39 (stack43)
        %v89650_v44 = vadd.s32 4, %v89646_v40 (stack40)
        %v90074_v60 = vxor.u32 %v90073_v43, %v90069_v10 (stack48)
        %v90915_v32 = vor.u32 %v90914_v56, %v90913_v42 (stack47)
        %v147980_v53 = vadd.s32 %v157645_v22, %v157082_v49 (stack40)
        %vm88872_vm11 = vcmp.eq.f32.partialorder %v147940_v6, 0.0 (stack71)
        %v89239_v27 = vor.u32 16256, %v89238_v50 (stack47)
        %v90483_v9 = vxor.u32 %v90482_v41, %v90478_v30 (stack48)
        %v147985_v61 = vadd.s32 %v157642_v8, %v157083_v59 (stack40)
        %v89654_v54 = vadd.s32 %v89650_v44, %v89638_v54 (stack40)
        %v89656_v7 = vshll.u32 %v89650_v44, 13 (stack45)
        %v89657_v31 = vshrl.u32 %v89650_v44, 19 (stack46)
        %v90077_v10 = vadd.s32 %v90074_v60, %v90069_v10 (stack40)
        %v89240_v12 = vand.u32.u16 65535, %v89239_v27 (stack52)
        %v90079_v29 = vshll.u32 %v90074_v60, 26 (stack45)
        %v90080_v46 = vshrl.u32 %v90074_v60, 6 (stack46)
        %v90486_v30 = vadd.s32 %v90483_v9, %v90478_v30 (stack40)
        %v121192_v52 = vpop.eup %121191 (stack73)
        %v89658_v23 = vor.u32 %v89657_v31, %v89656_v7 (stack47)
        %v90488_v40 = vshll.u32 %v90483_v9, 29 (stack45)
        %v90489_v43 = vshrl.u32 %v90483_v9, 3 (stack46)
        %v90916_v42 = vxor.u32 %v90915_v32, %v90911_v34 (stack48)
        %v88869_v56 = vmul.f32 %v121192_v52, %v147940_v6 (stack74)
        %v88873_v50 = vand.u32 2147483648, %v147940_v6 (stack72)
        %v120220_v41 = vadd.low.f32.bf16 -1.0, %v89240_v12 (stack53)
        %v90081_v44 = vor.u32 %v90080_v46, %v90079_v29 (stack47)
        %v89659_v60 = vxor.u32 %v89658_v23, %v89654_v54 (stack48)
        %v90490_v32 = vor.u32 %v90489_v43, %v90488_v40 (stack47)
        %v90919_v34 = vadd.s32 %v90916_v42, %v90911_v34 (stack40)
        %v90925_v27 = vshll.u32 %v90916_v42, 6 (stack45)
        %v88871_v9 = vsel /*vm=*/%vm88870_vm9, /*on_true_vy=*/%v147940_v6, /*on_false_vx=*/%v88869_v56 (stack75)
        %v89249_v7 = vmul.f32 2.0, %v120220_v41 (stack54)
        %v90082_v31 = vxor.u32 %v90081_v44, %v90077_v10 (stack48)
        %v90926_v12 = vshrl.u32 %v90916_v42, 26 (stack46)
        %v88874_v29 = vsel /*vm=*/%vm88872_vm11, /*on_true_vy=*/%v88873_v50, /*on_false_vx=*/%v88871_v9 (stack76)
        %v89662_v54 = vadd.s32 %v89659_v60, %v89654_v54 (stack40)
        %v89664_v46 = vshll.u32 %v89659_v60, 15 (stack45)
        %v89665_v52 = vshrl.u32 %v89659_v60, 17 (stack46)
        %v88877_v23 = vadd.f32 -3.0, %v88874_v29 (stack53)
        %v89253_v40 = vadd.f32 -0.99609375, %v89249_v7 (stack53)
        %v90085_v10 = vadd.s32 %v90082_v31, %v90077_v10 (stack40)
        %v90091_v43 = vshll.u32 %v90082_v31, 6 (stack45)
        %v88850_v42 = vsel /*vm=*/%vm88825_vm7, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v89666_v56 = vor.u32 %v89665_v52, %v89664_v46 (stack47)
        %v90092_v50 = vshrl.u32 %v90082_v31, 26 (stack46)
        %v90491_v41 = vxor.u32 %v90490_v32, %v90486_v30 (stack48)
        %v88862_v44 = vsel /*vm=*/%vm88825_vm7, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v148003_v21 = vsel /*vm=*/%vm88825_vm7, /*on_true_vy=*/%v147954_v21, /*on_false_vx=*/%v88877_v23 (stack44)
        %v148005_v60 = vmax.f32 %v89253_v40, -0.99609375 (stack55)
        %v90927_v32 = vor.u32 %v90926_v12, %v90925_v27 (stack47)
        %v88885_v27 = vmul.f32 %v148003_v21, %v88862_v44 (stack54)
        %v89667_v9 = vxor.u32 %v89666_v56, %v89662_v54 (stack48)
        %v90093_v7 = vor.u32 %v90092_v50, %v90091_v43 (stack47)
        %v90494_v30 = vadd.s32 %v90491_v41, %v90486_v30 (stack40)
        %v88858_v31 = vsel /*vm=*/%vm88825_vm7, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v89269_v12 = vxor.u32 2147483648, %v148005_v60 (stack56)
        %v90496_v29 = vshll.u32 %v90491_v41, 16 (stack45)
        %v91331_v46 = vadd.s32 1, %v147980_v53 (stack40)
        %v88889_v52 = vadd.f32 %v88885_v27, %v88858_v31 (stack53)
        %v89670_v54 = vadd.s32 %v89667_v9, %v89662_v54 (stack40)
        %v89672_v23 = vshll.u32 %v89667_v9, 26 (stack45)
        %v89673_v40 = vshrl.u32 %v89667_v9, 6 (stack46)
        %v88854_v43 = vsel /*vm=*/%vm88825_vm7, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v148017_v56 = vmul.f32 %v89269_v12, %v148005_v60 (stack54)
        %v90094_v50 = vxor.u32 %v90093_v7, %v90085_v10 (stack48)
        %v90497_v41 = vshrl.u32 %v90491_v41, 16 (stack46)
        %v88893_v44 = vmul.f32 %v88889_v52, %v148003_v21 (stack54)
        %v89674_v27 = vor.u32 %v89673_v40, %v89672_v23 (stack47)
        %v90928_v32 = vxor.u32 %v90927_v32, %v90919_v34 (stack48)
        %v91335_v53 = vsel /*vm=*/%vm91322_vm10, /*on_true_vy=*/%v91331_v46, /*on_false_vx=*/%v147980_v53 (stack44)
        %v89274_v9 = vadd.f32 1.0, %v148017_v56 (stack57)
        %v90097_v7 = vadd.s32 %v90094_v50, %v121569_v1 (stack40)
        %v90923_v34 = vadd.s32 %v90919_v34, %v121569_v1 (stack40)
        %vm91317_vm12 = vcmp.lt.u32.totalorder %v147951_v45, %v147922_v24 (stack43)
        %v91352_v31 = vadd.s32 %v147951_v45, %v121569_v1 (stack40)
        %v88897_v12 = vadd.f32 %v88893_v44, %v88854_v43 (stack53)
        %v89277_v46 = vmul.f32 -0.5, %v148017_v56 (stack59)
        %v89675_v52 = vxor.u32 %v89674_v27, %v89670_v54 (stack48)
        %v90498_v29 = vor.u32 %v90497_v41, %v90496_v29 (stack47)
        %121193 = vlog2.f32 %v89274_v9 (stack58)
        %v90089_v10 = vadd.s32 %v90085_v10, %v121574_v2 (stack40)
        %v90101_v23 = vadd.s32 3, %v90097_v7 (stack40)
        %v90931_v40 = vadd.s32 %v90928_v32, %v121564_v0 (stack40)
        %v88901_v43 = vmul.f32 %v88897_v12, %v148003_v21 (stack54)
        %v89678_v54 = vadd.s32 %v89675_v52, %v89670_v54 (stack40)
        %v89684_v50 = vshll.u32 %v89675_v52, 6 (stack45)
        %v89685_v41 = vshrl.u32 %v89675_v52, 26 (stack46)
        %v89280_v44 = vand.u32 2147483647, %v148017_v56 (stack60)
        %v90105_v27 = vadd.s32 %v90101_v23, %v90089_v10 (stack40)
        %v90107_v32 = vshll.u32 %v90101_v23, 17 (stack45)
        %v90108_v9 = vshrl.u32 %v90101_v23, 15 (stack46)
        %v88905_v42 = vadd.f32 %v88901_v43, %v88850_v42 (stack53)
        %v89278_v7 = vadd.f32 1.0, %v89277_v46 (stack61)
        %v89686_v12 = vor.u32 %v89685_v41, %v89684_v50 (stack47)
        %v90499_v46 = vxor.u32 %v90498_v29, %v90494_v30 (stack48)
        %v89682_v52 = vadd.s32 %v89678_v54, %v121564_v0 (stack40)
        %v90109_v29 = vor.u32 %v90108_v9, %v90107_v32 (stack47)
        %v90935_v10 = vadd.s32 1, %v90931_v40 (stack40)
        %v91339_v23 = vadd.s32 1, %v91335_v53 (stack40)
        %v88909_v40 = vmul.f32 %v88905_v42, %v148003_v21 (stack54)
        %v89687_v43 = vxor.u32 %v89686_v12, %v89678_v54 (stack48)
        %v90502_v30 = vadd.s32 %v90499_v46, %v90494_v30 (stack40)
        %v90508_v54 = vshll.u32 %v90499_v46, 24 (stack45)
        %v90110_v50 = vxor.u32 %v90109_v29, %v90105_v27 (stack48)
        %v90509_v41 = vshrl.u32 %v90499_v46, 8 (stack46)
        %v90939_v34 = vadd.s32 %v90935_v10, %v90923_v34 (stack40)
        %v90941_v32 = vshll.u32 %v90935_v10, 17 (stack45)
        %v88913_v55 = vadd.f32 %v88909_v40, %v147974_v55 (stack53)
        %v89690_v9 = vadd.s32 %v89687_v43, %v121574_v2 (stack40)
        %v90942_v42 = vshrl.u32 %v90935_v10, 15 (stack46)
        %v91358_v12 = vshll.u32 %v91352_v31, 13 (stack45)
        %v90113_v27 = vadd.s32 %v90110_v50, %v90105_v27 (stack40)
        %v90115_v46 = vshll.u32 %v90110_v50, 29 (stack45)
        %v90116_v29 = vshrl.u32 %v90110_v50, 3 (stack46)
        %v90510_v10 = vor.u32 %v90509_v41, %v90508_v54 (stack47)
        %v88917_v40 = vmul.f32 %v88913_v55, %v148003_v21 (stack54)
        %v89694_v43 = vadd.s32 5, %v89690_v9 (stack40)
        %v90943_v54 = vor.u32 %v90942_v42, %v90941_v32 (stack47)
        %v91343_v24 = vsel /*vm=*/%vm91317_vm12, /*on_true_vy=*/%v91339_v23, /*on_false_vx=*/%v91335_v53 (stack44)
        %v90117_v45 = vor.u32 %v90116_v29, %v90115_v46 (stack47)
        %v90511_v53 = vxor.u32 %v90510_v10, %v90502_v30 (stack48)
        %v91348_v23 = vadd.s32 %v91343_v24, %v121574_v2 (stack40)
        %v91359_v50 = vshrl.u32 %v91352_v31, 19 (stack46)
        %v88921_v25 = vadd.f32 %v88917_v40, %v147965_v25 (stack53)
        %vm148046_vm13 = vcmp.lt.f32.partialorder %v89280_v44, 0.0004427343 (stack62)
        %v89696_v52 = vxor.u32 %v89694_v43, %v89682_v52 (stack48)
        %v90944_v41 = vxor.u32 %v90943_v54, %v90939_v34 (stack48)
        %v90118_v32 = vxor.u32 %v90117_v45, %v90113_v27 (stack48)
        %v90514_v55 = vadd.s32 %v90511_v53, %v121574_v2 (stack40)
        %v91356_v31 = vadd.s32 %v91352_v31, %v91348_v23 (stack40)
        %v91360_v9 = vor.u32 %v91359_v50, %v91358_v12 (stack47)
        %v121194_v42 = vpop.eup %121193 (stack64)
        %v88925_v12 = vmul.f32 %v88921_v25, %v148003_v21 (stack54)
        %v89279_v56 = vmul.f32 %v89278_v7, %v148017_v56 (stack63)
        %v89697_v7 = vand.u32.u8 255, %v89696_v52 (stack49)
        %v90947_v34 = vadd.s32 %v90944_v41, %v90939_v34 (stack40)
        %v89276_v46 = vmul.f32 0.6931472, %v121194_v42 (stack65)
        %v90121_v27 = vadd.s32 %v90118_v32, %v90113_v27 (stack40)
        %v90123_v29 = vshll.u32 %v90118_v32, 16 (stack45)
        %v90124_v10 = vshrl.u32 %v90118_v32, 16 (stack46)
        %v88929_v26 = vadd.f32 %v88925_v12, %v147960_v26 (stack53)
        %v90506_v30 = vadd.s32 %v90502_v30, %v121564_v0 (stack40)
        %v90518_v40 = vadd.s32 2, %v90514_v55 (stack40)
        %v90949_v43 = vshll.u32 %v90944_v41, 29 (stack45)
        %v89282_v54 = vsel /*vm=*/%vm148046_vm13, /*on_true_vy=*/%v89279_v56, /*on_false_vx=*/%v89276_v46 (stack66)
        %v89698_v24 = vand.u32 65535, %v89697_v7 (stack50)
        %v90125_v45 = vor.u32 %v90124_v10, %v90123_v29 (stack47)
        %v91361_v53 = vxor.u32 %v91360_v9, %v91356_v31 (stack48)
        %v88933_v23 = vmul.f32 %v88929_v26, %v148003_v21 (stack54)
        %v148058_v50 = vxor.u32 2147483648, %v89282_v54 (stack56)
        %v90522_v25 = vadd.s32 %v90518_v40, %v90506_v30 (stack40)
        %v90950_v44 = vshrl.u32 %v90944_v41, 3 (stack46)
        %v88798_v52 = vand.u32 2147483647, %v147897_v20 (stack77)
        %v88834_v41 = vsel /*vm=*/%vm88825_vm7, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v90126_v32 = vxor.u32 %v90125_v45, %v90121_v27 (stack48)
        %v88937_v55 = vadd.f32 %v88933_v23, %v88834_v41 (stack53)
        %121195 = vrsqrt.f32 %v148058_v50 (stack67)
        %v89699_v9 = vshrl.u32 %v89698_v24, 1 (stack51)
        %v90129_v42 = vadd.s32 %v90126_v32, %v90121_v27 (stack40)
        %v90524_v12 = vshll.u32 %v90518_v40, 13 (stack45)
        %v90525_v56 = vshrl.u32 %v90518_v40, 19 (stack46)
        %v88941_v21 = vmul.f32 %v88937_v55, %v148003_v21 (stack54)
        %v90951_v7 = vor.u32 %v90950_v44, %v90949_v43 (stack47)
        %vm148066_vm14 = vcmp.eq.f32.partialorder %v88798_v52, 1.0 (stack68)
        %v88806_v27 = vmul.f32 inf, %v147897_v20 (stack54)
        %v88830_v6 = vsel /*vm=*/%vm88825_vm7, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v89259_v29 = vand.u32 2147483647, %v148005_v60 (stack77)
        %v88945_v10 = vadd.f32 %v88941_v21, %v88830_v6 (stack53)
        %v148076_v26 = vmul.f32 inf, %v148005_v60 (stack54)
        %v90133_v30 = vadd.s32 %v90129_v42, %v121569_v1 (stack40)
        %v148081_v40 = vadd.s32 %v147985_v61, %v122657_v58 (stack40)
        %v89700_v43 = vor.u32 16256, %v89699_v9 (stack47)
        %v90135_v54 = vshll.u32 %v90126_v32, 24 (stack45)
        %v90136_v24 = vshrl.u32 %v90126_v32, 8 (stack46)
        %v90526_v45 = vor.u32 %v90525_v56, %v90524_v12 (stack47)
        %v88949_v20 = vmul.f32 %v88945_v10, %v147897_v20 (stack54)
        %vm89286_vm15 = vcmp.lt.f32.partialorder %v148058_v50, 5.0 (stack68)
        %v90952_v23 = vxor.u32 %v90951_v7, %v90947_v34 (stack48)
        %v91364_v31 = vadd.s32 %v91361_v53, %v91356_v31 (stack40)
        %v91366_v44 = vshll.u32 %v91361_v53, 15 (stack45)
        %vm89331_vm0 = vcmp.eq.f32.partialorder %v148058_v50, inf (stack70)
        %v89701_v52 = vand.u32.u16 65535, %v89700_v43 (stack52)
        %v90137_v41 = vor.u32 %v90136_v24, %v90135_v54 (stack47)
        %v90527_v32 = vxor.u32 %v90526_v45, %v90522_v25 (stack48)
        %v91367_v53 = vshrl.u32 %v91361_v53, 17 (stack46)
        %v88953_v55 = vsel /*vm=*/%vm148066_vm14, /*on_true_vy=*/%v88806_v27, /*on_false_vx=*/%v88949_v20 (stack44)
        %v90955_v34 = vadd.s32 %v90952_v23, %v90947_v34 (stack40)
        %v90957_v9 = vshll.u32 %v90952_v23, 16 (stack45)
        %v90958_v12 = vshrl.u32 %v90952_v23, 16 (stack46)
        %v88957_v56 = vmul.f32 1.4140625, %v88953_v55 (stack54)
        %v120222_v21 = vadd.low.f32.bf16 -1.0, %v89701_v52 (stack53)
        %v90138_v42 = vxor.u32 %v90137_v41, %v90129_v42 (stack48)
        %v90530_v25 = vadd.s32 %v90527_v32, %v90522_v25 (stack40)
        %v90532_v7 = vshll.u32 %v90527_v32, 15 (stack45)
        %v90533_v46 = vshrl.u32 %v90527_v32, 17 (stack46)
        %v90959_v27 = vor.u32 %v90958_v12, %v90957_v9 (stack47)
        %v91368_v6 = vor.u32 %v91367_v53, %v91366_v44 (stack47)
        %v88960_v10 = vpack.c.bf16 %v157387_v11, %v88957_v56 (stack81)
        %v89710_v43 = vmul.f32 2.0, %v120222_v21 (stack54)
        %v90141_v54 = vadd.s32 %v90138_v42, %v121564_v0 (stack40)
        %vm91783_vm1 = vcmp.lt.u32.totalorder %v147985_v61, %v157083_v59 (stack43)
        %v90534_v24 = vor.u32 %v90533_v46, %v90532_v7 (stack47)
        %v90960_v45 = vxor.u32 %v90959_v27, %v90955_v34 (stack48)
        %v148092_v20 = vxor.u32 %v91368_v6, %v91364_v31 (stack48)
        %v148096_v23 = vadd.s32 %v157645_v22, %v157084_v16 (stack40)
        %v121196_v44 = vpop.eup %121195 (stack73)
        %120219 = vst [vmem:[%s123356_s30 + $0x2dc] sm:$0xf] /*vst_source=*/%v88960_v10 (stack83)
        %vm89333_vm2 = vcmp.eq.f32.partialorder %v148058_v50, 0.0 (stack71)
        %v89714_v52 = vadd.f32 -0.99609375, %v89710_v43 (stack53)
        %v90145_v41 = vadd.s32 4, %v90141_v54 (stack40)
        %v148102_v32 = vadd.s32 %v157642_v8, %v157089_v17 (stack40)
        %v89330_v53 = vmul.f32 %v121196_v44, %v148058_v50 (stack74)
        %v89334_v55 = vand.u32 2147483648, %v148058_v50 (stack72)
        %v90535_v9 = vxor.u32 %v90534_v24, %v90530_v25 (stack48)
        %v90963_v34 = vadd.s32 %v90960_v45, %v90955_v34 (stack40)
        %v148106_v12 = vmax.f32 %v89714_v52, -0.99609375 (stack55)
        %v90149_v30 = vadd.s32 %v90145_v41, %v90133_v30 (stack40)
        %v90151_v56 = vshll.u32 %v90145_v41, 13 (stack45)
        %v90152_v21 = vshrl.u32 %v90145_v41, 19 (stack46)
        %v89332_v42 = vsel /*vm=*/%vm89331_vm0, /*on_true_vy=*/%v148058_v50, /*on_false_vx=*/%v89330_v53 (stack75)
        %v90538_v25 = vadd.s32 %v90535_v9, %v90530_v25 (stack40)
        %v90540_v7 = vshll.u32 %v90535_v9, 26 (stack45)
        %v90541_v46 = vshrl.u32 %v90535_v9, 6 (stack46)
        %v148114_v27 = vsel /*vm=*/%vm89286_vm15, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v89327_v6 = vadd.f32 -2.5, %v148058_v50 (stack53)
        %v89335_v10 = vsel /*vm=*/%vm89333_vm2, /*on_true_vy=*/%v89334_v55, /*on_false_vx=*/%v89332_v42 (stack76)
        %v89730_v43 = vxor.u32 2147483648, %v148106_v12 (stack56)
        %v148123_v54 = vsel /*vm=*/%vm89286_vm15, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v89338_v24 = vadd.f32 -3.0, %v89335_v10 (stack53)
        %v90153_v44 = vor.u32 %v90152_v21, %v90151_v56 (stack47)
        %v90542_v52 = vor.u32 %v90541_v46, %v90540_v7 (stack47)
        %v89319_v41 = vsel /*vm=*/%vm89286_vm15, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v89323_v53 = vsel /*vm=*/%vm89286_vm15, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v148132_v55 = vmul.f32 %v89730_v43, %v148106_v12 (stack54)
        %v91372_v31 = vadd.s32 %v148092_v20, %v91364_v31 (stack40)
        %v148137_v9 = vsel /*vm=*/%vm89286_vm15, /*on_true_vy=*/%v89327_v6, /*on_false_vx=*/%v89338_v24 (stack44)
        %v90154_v56 = vxor.u32 %v90153_v44, %v90149_v30 (stack48)
        %v90543_v21 = vxor.u32 %v90542_v52, %v90538_v25 (stack48)
        %v90969_v42 = vshll.u32 %v90960_v45, 24 (stack45)
        %v89346_v7 = vmul.f32 %v148137_v9, %v89323_v53 (stack54)
        %v89735_v46 = vadd.f32 1.0, %v148132_v55 (stack57)
        %v89738_v6 = vmul.f32 -0.5, %v148132_v55 (stack59)
        %v90970_v45 = vshrl.u32 %v90960_v45, 8 (stack46)
        %vm91778_vm3 = vcmp.lt.u32.totalorder %v148081_v40, %v147985_v61 (stack43)
        %v90157_v30 = vadd.s32 %v90154_v56, %v90149_v30 (stack40)
        %v90159_v10 = vshll.u32 %v90154_v56, 15 (stack45)
        %v90160_v43 = vshrl.u32 %v90154_v56, 17 (stack46)
        %v90546_v25 = vadd.s32 %v90543_v21, %v90538_v25 (stack40)
        %v89311_v24 = vsel /*vm=*/%vm89286_vm15, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v89350_v44 = vadd.f32 %v89346_v7, %v89319_v41 (stack53)
        %121197 = vlog2.f32 %v89735_v46 (stack58)
        %v91374_v52 = vshll.u32 %v148092_v20, 26 (stack45)
        %v89315_v41 = vsel /*vm=*/%vm89286_vm15, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v90161_v53 = vor.u32 %v90160_v43, %v90159_v10 (stack47)
        %v90552_v56 = vshll.u32 %v90543_v21, 6 (stack45)
        %v90553_v21 = vshrl.u32 %v90543_v21, 26 (stack46)
        %v89354_v7 = vmul.f32 %v89350_v44, %v148137_v9 (stack54)
        %v90967_v46 = vadd.s32 %v90963_v34, %v121564_v0 (stack40)
        %v90971_v42 = vor.u32 %v90970_v45, %v90969_v42 (stack47)
        %v91375_v20 = vshrl.u32 %v148092_v20, 6 (stack46)
        %v89739_v6 = vadd.f32 1.0, %v89738_v6 (stack61)
        %v89741_v45 = vand.u32 2147483647, %v148132_v55 (stack60)
        %v90162_v10 = vxor.u32 %v90161_v53, %v90157_v30 (stack48)
        %v90554_v43 = vor.u32 %v90553_v21, %v90552_v56 (stack47)
        %v89358_v44 = vadd.f32 %v89354_v7, %v89315_v41 (stack53)
        %v90972_v34 = vxor.u32 %v90971_v42, %v90963_v34 (stack48)
        %v91376_v52 = vor.u32 %v91375_v20, %v91374_v52 (stack47)
        %v91792_v41 = vadd.s32 1, %v148096_v23 (stack40)
        %v90165_v30 = vadd.s32 %v90162_v10, %v90157_v30 (stack40)
        %v90167_v53 = vshll.u32 %v90162_v10, 26 (stack45)
        %v90168_v56 = vshrl.u32 %v90162_v10, 6 (stack46)
        %v90555_v21 = vxor.u32 %v90554_v43, %v90546_v25 (stack48)
        %v89362_v7 = vmul.f32 %v89358_v44, %v148137_v9 (stack54)
        %v90975_v42 = vadd.s32 %v90972_v34, %v121574_v2 (stack40)
        %v91377_v20 = vxor.u32 %v91376_v52, %v91372_v31 (stack48)
        %v91796_v23 = vsel /*vm=*/%vm91783_vm1, /*on_true_vy=*/%v91792_v41, /*on_false_vx=*/%v148096_v23 (stack44)
        %v90169_v10 = vor.u32 %v90168_v56, %v90167_v53 (stack47)
        %v90550_v25 = vadd.s32 %v90546_v25, %v121574_v2 (stack40)
        %v90558_v43 = vadd.s32 %v90555_v21, %v121569_v1 (stack40)
        %v91800_v44 = vadd.s32 1, %v91796_v23 (stack40)
        %v89366_v24 = vadd.f32 %v89362_v7, %v89311_v24 (stack53)
        %v90979_v34 = vadd.s32 2, %v90975_v42 (stack40)
        %v148164_v31 = vadd.s32 %v91377_v20, %v91372_v31 (stack40)
        %v91386_v52 = vshll.u32 %v91377_v20, 6 (stack45)
        %v90170_v41 = vxor.u32 %v90169_v10, %v90165_v30 (stack48)
        %v90562_v53 = vadd.s32 3, %v90558_v43 (stack40)
        %v91387_v56 = vshrl.u32 %v91377_v20, 26 (stack46)
        %v91804_v61 = vsel /*vm=*/%vm91778_vm3, /*on_true_vy=*/%v91800_v44, /*on_false_vx=*/%v91796_v23 (stack44)
        %v89370_v21 = vmul.f32 %v89366_v24, %v148137_v9 (stack54)
        %v90983_v46 = vadd.s32 %v90979_v34, %v90967_v46 (stack40)
        %v90985_v7 = vshll.u32 %v90979_v34, 13 (stack45)
        %v90986_v42 = vshrl.u32 %v90979_v34, 19 (stack46)
        %v90173_v30 = vadd.s32 %v90170_v41, %v90165_v30 (stack40)
        %v90179_v20 = vshll.u32 %v90170_v41, 6 (stack45)
        %v90180_v23 = vshrl.u32 %v90170_v41, 26 (stack46)
        %v90566_v10 = vadd.s32 %v90562_v53, %v90550_v25 (stack40)
        %v89374_v54 = vadd.f32 %v89370_v21, %v148123_v54 (stack53)
        %v90568_v25 = vshll.u32 %v90562_v53, 17 (stack45)
        %v90569_v43 = vshrl.u32 %v90562_v53, 15 (stack46)
        %v90987_v44 = vor.u32 %v90986_v42, %v90985_v7 (stack47)
        %v121198_v24 = vpop.eup %121197 (stack64)
        %v89740_v55 = vmul.f32 %v89739_v6, %v148132_v55 (stack63)
        %v90181_v6 = vor.u32 %v90180_v23, %v90179_v20 (stack47)
        %v91388_v34 = vor.u32 %v91387_v56, %v91386_v52 (stack47)
        %v91813_v40 = vadd.s32 %v148081_v40, %v121569_v1 (stack40)
        %v89378_v52 = vmul.f32 %v89374_v54, %v148137_v9 (stack54)
        %v89737_v41 = vmul.f32 0.6931472, %v121198_v24 (stack65)
        %v90570_v53 = vor.u32 %v90569_v43, %v90568_v25 (stack47)
        %v90988_v56 = vxor.u32 %v90987_v44, %v90983_v46 (stack48)
        %v89303_v21 = vsel /*vm=*/%vm89286_vm15, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %vm89742_vm4 = vcmp.lt.f32.partialorder %v89741_v45, 0.0004427343 (stack62)
        %v90182_v45 = vxor.u32 %v90181_v6, %v90173_v30 (stack48)
        %v91389_v7 = vxor.u32 %v91388_v34, %v148164_v31 (stack48)
        %v89382_v42 = vadd.f32 %v89378_v52, %v89303_v21 (stack53)
        %v89743_v20 = vsel /*vm=*/%vm89742_vm4, /*on_true_vy=*/%v89740_v55, /*on_false_vx=*/%v89737_v41 (stack66)
        %v90571_v23 = vxor.u32 %v90570_v53, %v90566_v10 (stack48)
        %v90991_v46 = vadd.s32 %v90988_v56, %v90983_v46 (stack40)
        %v89295_v54 = vsel /*vm=*/%vm89286_vm15, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v148182_v25 = vxor.u32 2147483648, %v89743_v20 (stack56)
        %v91819_v43 = vshll.u32 %v91813_v40, 13 (stack45)
        %v91820_v44 = vshrl.u32 %v91813_v40, 19 (stack46)
        %v89386_v24 = vmul.f32 %v89382_v42, %v148137_v9 (stack54)
        %v90574_v10 = vadd.s32 %v90571_v23, %v90566_v10 (stack40)
        %v90576_v55 = vshll.u32 %v90571_v23, 29 (stack45)
        %v90577_v6 = vshrl.u32 %v90571_v23, 3 (stack46)
        %v89299_v50 = vsel /*vm=*/%vm89286_vm15, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %vm89747_vm5 = vcmp.lt.f32.partialorder %v148182_v25, 5.0 (stack68)
        %121199 = vrsqrt.f32 %v148182_v25 (stack67)
        %v90185_v34 = vadd.s32 %v90182_v45, %v121574_v2 (stack40)
        %v89390_v52 = vadd.f32 %v89386_v24, %v89299_v50 (stack53)
        %v90993_v41 = vshll.u32 %v90988_v56, 15 (stack45)
        %v90994_v53 = vshrl.u32 %v90988_v56, 17 (stack46)
        %v91809_v61 = vadd.s32 %v91804_v61, %v121574_v2 (stack40)
        %v90177_v30 = vadd.s32 %v90173_v30, %v121564_v0 (stack40)
        %v90578_v56 = vor.u32 %v90577_v6, %v90576_v55 (stack47)
        %v91384_v31 = vadd.s32 %v148164_v31, %v121569_v1 (stack40)
        %v91821_v21 = vor.u32 %v91820_v44, %v91819_v43 (stack47)
        %v89394_v45 = vmul.f32 %v89390_v52, %v148137_v9 (stack54)
        %v148199_v42 = vsel /*vm=*/%vm89747_vm5, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v148202_v20 = vadd.f32 -2.5, %v148182_v25 (stack53)
        %v148206_v23 = vadd.s32 %v148102_v32, %v122657_v58 (stack40)
        %vm148210_vm6 = vcmp.eq.f32.partialorder %v89259_v29, 1.0 (stack68)
        %v148217_v43 = vsel /*vm=*/%vm89747_vm5, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v148222_v44 = vsel /*vm=*/%vm89747_vm5, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v90189_v24 = vadd.s32 5, %v90185_v34 (stack40)
        %v90579_v55 = vxor.u32 %v90578_v56, %v90574_v10 (stack48)
        %v89398_v54 = vadd.f32 %v89394_v45, %v89295_v54 (stack53)
        %v90995_v6 = vor.u32 %v90994_v53, %v90993_v41 (stack47)
        %v91392_v7 = vadd.s32 %v91389_v7, %v121564_v0 (stack40)
        %v91817_v40 = vadd.s32 %v91813_v40, %v91809_v61 (stack40)
        %v90191_v50 = vxor.u32 %v90189_v24, %v90177_v30 (stack48)
        %v90582_v10 = vadd.s32 %v90579_v55, %v90574_v10 (stack40)
        %v90584_v34 = vshll.u32 %v90579_v55, 16 (stack45)
        %v90585_v52 = vshrl.u32 %v90579_v55, 16 (stack46)
        %v89402_v9 = vmul.f32 %v89398_v54, %v148137_v9 (stack54)
        %vm89792_vm7 = vcmp.eq.f32.partialorder %v148182_v25, inf (stack70)
        %v90996_v41 = vxor.u32 %v90995_v6, %v90991_v46 (stack48)
        %v91396_v53 = vadd.s32 1, %v91392_v7 (stack40)
        %v91822_v61 = vxor.u32 %v91821_v21, %v91817_v40 (stack48)
        %v89784_v30 = vsel /*vm=*/%vm89747_vm5, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v90192_v56 = vand.u32.u8 255, %v90191_v50 (stack49)
        %v90586_v21 = vor.u32 %v90585_v52, %v90584_v34 (stack47)
        %vm92244_vm8 = vcmp.lt.u32.totalorder %v148102_v32, %v157089_v17 (stack43)
        %v89406_v27 = vadd.f32 %v89402_v9, %v148114_v27 (stack53)
        %v90999_v46 = vadd.s32 %v90996_v41, %v90991_v46 (stack40)
        %v91001_v45 = vshll.u32 %v90996_v41, 26 (stack45)
        %v91002_v24 = vshrl.u32 %v90996_v41, 6 (stack46)
        %v90193_v55 = vand.u32 65535, %v90192_v56 (stack50)
        %v90587_v54 = vxor.u32 %v90586_v21, %v90582_v10 (stack48)
        %v91400_v31 = vadd.s32 %v91396_v53, %v91384_v31 (stack40)
        %v91402_v6 = vshll.u32 %v91396_v53, 17 (stack45)
        %v89410_v60 = vmul.f32 %v89406_v27, %v148005_v60 (stack54)
        %v91003_v7 = vor.u32 %v91002_v24, %v91001_v45 (stack47)
        %v91403_v50 = vshrl.u32 %v91396_v53, 15 (stack46)
        %v148234_v40 = vadd.s32 %v91822_v61, %v91817_v40 (stack40)
        %v90194_v34 = vshrl.u32 %v90193_v55, 1 (stack51)
        %v90590_v10 = vadd.s32 %v90587_v54, %v90582_v10 (stack40)
        %v90596_v52 = vshll.u32 %v90587_v54, 24 (stack45)
        %v90597_v9 = vshrl.u32 %v90587_v54, 8 (stack46)
        %v121200_v41 = vpop.eup %121199 (stack73)
        %v89414_v26 = vsel /*vm=*/%vm148210_vm6, /*on_true_vy=*/%v148076_v26, /*on_false_vx=*/%v89410_v60 (stack44)
        %vm89794_vm9 = vcmp.eq.f32.partialorder %v148182_v25, 0.0 (stack71)
        %v91004_v29 = vxor.u32 %v91003_v7, %v90999_v46 (stack48)
        %v91404_v53 = vor.u32 %v91403_v50, %v91402_v6 (stack47)
        %v89418_v56 = vmul.f32 1.4140625, %v89414_v26 (stack54)
        %v89791_v21 = vmul.f32 %v121200_v41, %v148182_v25 (stack74)
        %v89795_v27 = vand.u32 2147483648, %v148182_v25 (stack72)
        %v90195_v45 = vor.u32 16256, %v90194_v34 (stack47)
        %v90598_v24 = vor.u32 %v90597_v9, %v90596_v52 (stack47)
        %v91007_v46 = vadd.s32 %v91004_v29, %v90999_v46 (stack40)
        %v91013_v55 = vshll.u32 %v91004_v29, 6 (stack45)
        %v91014_v54 = vshrl.u32 %v91004_v29, 26 (stack46)
        %v89421_v6 = vpack.c.bf16 %v157387_v11, %v89418_v56 (stack81)
        %v89793_v60 = vsel /*vm=*/%vm89792_vm7, /*on_true_vy=*/%v148182_v25, /*on_false_vx=*/%v89791_v21 (stack75)
        %v90196_v7 = vand.u32.u16 65535, %v90195_v45 (stack52)
        %v91405_v50 = vxor.u32 %v91404_v53, %v91400_v31 (stack48)
        %v89796_v34 = vsel /*vm=*/%vm89794_vm9, /*on_true_vy=*/%v89795_v27, /*on_false_vx=*/%v89793_v60 (stack76)
        %v90599_v52 = vxor.u32 %v90598_v24, %v90590_v10 (stack48)
        %v91015_v9 = vor.u32 %v91014_v54, %v91013_v55 (stack47)
        %v91827_v41 = vshll.u32 %v91822_v61, 15 (stack45)
        %120221 = vst [vmem:[%s123356_s30 + $0x35c] sm:$0xf] /*vst_source=*/%v89421_v6 (stack83)
        %v89799_v26 = vadd.f32 -3.0, %v89796_v34 (stack53)
        %v120228_v29 = vadd.low.f32.bf16 -1.0, %v90196_v7 (stack53)
        %v91408_v31 = vadd.s32 %v91405_v50, %v91400_v31 (stack40)
        %v91410_v53 = vshll.u32 %v91405_v50, 29 (stack45)
        %v90602_v56 = vadd.s32 %v90599_v52, %v121564_v0 (stack40)
        %v91016_v21 = vxor.u32 %v91015_v9, %v91007_v46 (stack48)
        %v91411_v27 = vshrl.u32 %v91405_v50, 3 (stack46)
        %v91828_v61 = vshrl.u32 %v91822_v61, 17 (stack46)
        %v148251_v20 = vsel /*vm=*/%vm89747_vm5, /*on_true_vy=*/%v148202_v20, /*on_false_vx=*/%v89799_v26 (stack44)
        %v90205_v45 = vmul.f32 2.0, %v120228_v29 (stack54)
        %v90594_v10 = vadd.s32 %v90590_v10, %v121569_v1 (stack40)
        %v92249_v24 = vadd.s32 %v157645_v22, %v157090_v62 (stack40)
        %v89807_v30 = vmul.f32 %v148251_v20, %v89784_v30 (stack54)
        %v90606_v55 = vadd.s32 4, %v90602_v56 (stack40)
        %v91019_v54 = vadd.s32 %v91016_v21, %v121569_v1 (stack40)
        %v91412_v6 = vor.u32 %v91411_v27, %v91410_v53 (stack47)
        %v90209_v60 = vadd.f32 -0.99609375, %v90205_v45 (stack53)
        %v91011_v46 = vadd.s32 %v91007_v46, %v121574_v2 (stack40)
        %v91829_v7 = vor.u32 %v91828_v61, %v91827_v41 (stack47)
        %v92253_v50 = vadd.s32 1, %v92249_v24 (stack40)
        %v89811_v44 = vadd.f32 %v89807_v30, %v148222_v44 (stack53)
        %v90610_v34 = vadd.s32 %v90606_v55, %v90594_v10 (stack40)
        %v90612_v52 = vshll.u32 %v90606_v55, 13 (stack45)
        %v90613_v9 = vshrl.u32 %v90606_v55, 19 (stack46)
        %v148260_v41 = vmax.f32 %v90209_v60, -0.99609375 (stack55)
        %v91023_v26 = vadd.s32 3, %v91019_v54 (stack40)
        %v91413_v29 = vxor.u32 %v91412_v6, %v91408_v31 (stack48)
        %v91830_v53 = vxor.u32 %v91829_v7, %v148234_v40 (stack48)
        %v89764_v56 = vsel /*vm=*/%vm89747_vm5, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v89815_v21 = vmul.f32 %v89811_v44, %v148251_v20 (stack54)
        %v90614_v27 = vor.u32 %v90613_v9, %v90612_v52 (stack47)
        %v92257_v61 = vsel /*vm=*/%vm92244_vm8, /*on_true_vy=*/%v92253_v50, /*on_false_vx=*/%v92249_v24 (stack44)
        %v89768_v45 = vsel /*vm=*/%vm89747_vm5, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v89776_v10 = vsel /*vm=*/%vm89747_vm5, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v90225_v24 = vxor.u32 2147483648, %v148260_v41 (stack56)
        %v91027_v30 = vadd.s32 %v91023_v26, %v91011_v46 (stack40)
        %v89819_v55 = vadd.f32 %v89815_v21, %v89776_v10 (stack53)
        %v90615_v54 = vxor.u32 %v90614_v27, %v90610_v34 (stack48)
        %v91029_v6 = vshll.u32 %v91023_v26, 17 (stack45)
        %v91030_v60 = vshrl.u32 %v91023_v26, 15 (stack46)
        %v148278_v46 = vmul.f32 %v90225_v24, %v148260_v41 (stack54)
        %v91416_v31 = vadd.s32 %v91413_v29, %v91408_v31 (stack40)
        %v91418_v7 = vshll.u32 %v91413_v29, 16 (stack45)
        %v148282_v50 = vadd.s32 %v148206_v23, %v121569_v1 (stack40)
        %v89823_v44 = vmul.f32 %v89819_v55, %v148251_v20 (stack54)
        %v90618_v34 = vadd.s32 %v90615_v54, %v90610_v34 (stack40)
        %v90620_v52 = vshll.u32 %v90615_v54, 15 (stack45)
        %v90621_v9 = vshrl.u32 %v90615_v54, 17 (stack46)
        %v89772_v26 = vsel /*vm=*/%vm89747_vm5, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v90230_v21 = vadd.f32 1.0, %v148278_v46 (stack57)
        %v91031_v27 = vor.u32 %v91030_v60, %v91029_v6 (stack47)
        %vm92239_vm10 = vcmp.lt.u32.totalorder %v148206_v23, %v148102_v32 (stack43)
        %v89827_v10 = vadd.f32 %v89823_v44, %v89772_v26 (stack53)
        %v90622_v24 = vor.u32 %v90621_v9, %v90620_v52 (stack47)
        %v91419_v29 = vshrl.u32 %v91413_v29, 16 (stack46)
        %v91833_v40 = vadd.s32 %v91830_v53, %v148234_v40 (stack40)
        %121201 = vlog2.f32 %v90230_v21 (stack58)
        %v91032_v55 = vxor.u32 %v91031_v27, %v91027_v30 (stack48)
        %v92280_v54 = vshll.u32 %v148282_v50, 13 (stack45)
        %v92281_v6 = vshrl.u32 %v148282_v50, 19 (stack46)
        %v89831_v60 = vmul.f32 %v89827_v10, %v148251_v20 (stack54)
        %v90233_v44 = vmul.f32 -0.5, %v148278_v46 (stack59)
        %v90623_v52 = vxor.u32 %v90622_v24, %v90618_v34 (stack48)
        %v91420_v7 = vor.u32 %v91419_v29, %v91418_v7 (stack47)
        %v91035_v30 = vadd.s32 %v91032_v55, %v91027_v30 (stack40)
        %v91037_v9 = vshll.u32 %v91032_v55, 29 (stack45)
        %v91038_v26 = vshrl.u32 %v91032_v55, 3 (stack46)
        %v91835_v21 = vshll.u32 %v91830_v53, 26 (stack45)
        %v89835_v45 = vadd.f32 %v89831_v60, %v89768_v45 (stack53)
        %v90626_v34 = vadd.s32 %v90623_v52, %v90618_v34 (stack40)
        %v90628_v27 = vshll.u32 %v90623_v52, 26 (stack45)
        %v90629_v10 = vshrl.u32 %v90623_v52, 6 (stack46)
        %v91039_v24 = vor.u32 %v91038_v26, %v91037_v9 (stack47)
        %v91421_v29 = vxor.u32 %v91420_v7, %v91416_v31 (stack48)
        %v91836_v53 = vshrl.u32 %v91830_v53, 6 (stack46)
        %v92261_v55 = vadd.s32 1, %v92257_v61 (stack40)
        %v89839_v60 = vmul.f32 %v89835_v45, %v148251_v20 (stack54)
        %v90234_v44 = vadd.f32 1.0, %v90233_v44 (stack61)
        %v90630_v52 = vor.u32 %v90629_v10, %v90628_v27 (stack47)
        %v148299_v7 = vadd.s32 %v157642_v8, %v157091_v37 (stack40)
        %v91040_v9 = vxor.u32 %v91039_v24, %v91035_v30 (stack48)
        %v91424_v31 = vadd.s32 %v91421_v29, %v91416_v31 (stack40)
        %v91430_v26 = vshll.u32 %v91421_v29, 24 (stack45)
        %v91431_v45 = vshrl.u32 %v91421_v29, 8 (stack46)
        %v89843_v56 = vadd.f32 %v89839_v60, %v89764_v56 (stack53)
        %v90631_v27 = vxor.u32 %v90630_v52, %v90626_v34 (stack48)
        %v91837_v21 = vor.u32 %v91836_v53, %v91835_v21 (stack47)
        %v92265_v32 = vsel /*vm=*/%vm92239_vm10, /*on_true_vy=*/%v92261_v55, /*on_false_vx=*/%v92257_v61 (stack44)
        %v90236_v23 = vand.u32 2147483647, %v148278_v46 (stack60)
        %v91043_v61 = vadd.s32 %v91040_v9, %v91035_v30 (stack40)
        %v91045_v30 = vshll.u32 %v91040_v9, 16 (stack45)
        %v91046_v10 = vshrl.u32 %v91040_v9, 16 (stack46)
        %v89847_v24 = vmul.f32 %v89843_v56, %v148251_v20 (stack54)
        %v90634_v34 = vadd.s32 %v90631_v27, %v90626_v34 (stack40)
        %v90640_v29 = vshll.u32 %v90631_v27, 6 (stack45)
        %v90641_v53 = vshrl.u32 %v90631_v27, 26 (stack46)
        %v91047_v55 = vor.u32 %v91046_v10, %v91045_v30 (stack47)
        %v91432_v60 = vor.u32 %v91431_v45, %v91430_v26 (stack47)
        %v91838_v52 = vxor.u32 %v91837_v21, %v91833_v40 (stack48)
        %v92270_v9 = vadd.s32 %v92265_v32, %v121574_v2 (stack40)
        %v89851_v43 = vadd.f32 %v89847_v24, %v148217_v43 (stack53)
        %v90235_v46 = vmul.f32 %v90234_v44, %v148278_v46 (stack63)
        %v90642_v44 = vor.u32 %v90641_v53, %v90640_v29 (stack47)
        %v92282_v54 = vor.u32 %v92281_v6, %v92280_v54 (stack47)
        %v91048_v6 = vxor.u32 %v91047_v55, %v91043_v61 (stack48)
        %v91433_v26 = vxor.u32 %v91432_v60, %v91424_v31 (stack48)
        %v91841_v40 = vadd.s32 %v91838_v52, %v91833_v40 (stack40)
        %v91847_v45 = vshll.u32 %v91838_v52, 6 (stack45)
        %v121202_v56 = vpop.eup %121201 (stack64)
        %v89855_v27 = vmul.f32 %v89851_v43, %v148251_v20 (stack54)
        %v90643_v21 = vxor.u32 %v90642_v44, %v90634_v34 (stack48)
        %v91848_v32 = vshrl.u32 %v91838_v52, 26 (stack46)
        %v92278_v50 = vadd.s32 %v148282_v50, %v92270_v9 (stack40)
        %v90232_v30 = vmul.f32 0.6931472, %v121202_v56 (stack65)
        %v91051_v61 = vadd.s32 %v91048_v6, %v91043_v61 (stack40)
        %v91057_v10 = vshll.u32 %v91048_v6, 24 (stack45)
        %v91058_v24 = vshrl.u32 %v91048_v6, 8 (stack46)
        %v89720_v29 = vand.u32 2147483647, %v148106_v12 (stack77)
        %v89859_v42 = vadd.f32 %v89855_v27, %v148199_v42 (stack53)
        %vm90237_vm11 = vcmp.lt.f32.partialorder %v90236_v23, 0.0004427343 (stack62)
        %v90646_v23 = vadd.s32 %v90643_v21, %v121574_v2 (stack40)
        %v90238_v53 = vsel /*vm=*/%vm90237_vm11, /*on_true_vy=*/%v90235_v46, /*on_false_vx=*/%v90232_v30 (stack66)
        %v91059_v55 = vor.u32 %v91058_v24, %v91057_v10 (stack47)
        %v91436_v60 = vadd.s32 %v91433_v26, %v121574_v2 (stack40)
        %v91849_v52 = vor.u32 %v91848_v32, %v91847_v45 (stack47)
        %v89752_v25 = vsel /*vm=*/%vm89747_vm5, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v89863_v20 = vmul.f32 %v89859_v42, %v148251_v20 (stack54)
        %v148319_v9 = vxor.u32 2147483648, %v90238_v53 (stack56)
        %v90650_v43 = vadd.s32 5, %v90646_v23 (stack40)
        %v90638_v34 = vadd.s32 %v90634_v34, %v121564_v0 (stack40)
        %v91060_v46 = vxor.u32 %v91059_v55, %v91051_v61 (stack48)
        %v91850_v44 = vxor.u32 %v91849_v52, %v91841_v40 (stack48)
        %v92283_v54 = vxor.u32 %v92282_v54, %v92278_v50 (stack48)
        %v89867_v6 = vadd.f32 %v89863_v20, %v89752_v25 (stack53)
        %121203 = vrsqrt.f32 %v148319_v9 (stack67)
        %vm90242_vm12 = vcmp.lt.f32.partialorder %v148319_v9, 5.0 (stack68)
        %v90652_v26 = vxor.u32 %v90650_v43, %v90638_v34 (stack48)
        %v91440_v45 = vadd.s32 2, %v91436_v60 (stack40)
        %vm89723_vm13 = vcmp.eq.f32.partialorder %v89720_v29, 1.0 (stack68)
        %v89728_v56 = vmul.f32 inf, %v148106_v12 (stack54)
        %v89871_v12 = vmul.f32 %v89867_v6, %v148106_v12 (stack54)
        %v91428_v31 = vadd.s32 %v91424_v31, %v121564_v0 (stack40)
        %v91055_v27 = vadd.s32 %v91051_v61, %v121569_v1 (stack40)
        %v91063_v21 = vadd.s32 %v91060_v46, %v121564_v0 (stack40)
        %v91845_v40 = vadd.s32 %v91841_v40, %v121569_v1 (stack40)
        %v148332_v32 = vadd.s32 %v148299_v7, %v122657_v58 (stack40)
        %v89875_v30 = vsel /*vm=*/%vm89723_vm13, /*on_true_vy=*/%v89728_v56, /*on_false_vx=*/%v89871_v12 (stack44)
        %v148337_v61 = vsel /*vm=*/%vm90242_vm12, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v148340_v10 = vadd.f32 -2.5, %v148319_v9 (stack53)
        %v90290_v24 = vand.u32 2147483648, %v148319_v9 (stack72)
        %v89879_v29 = vmul.f32 1.4140625, %v89875_v30 (stack54)
        %v90653_v42 = vand.u32.u8 255, %v90652_v26 (stack49)
        %v91067_v23 = vadd.s32 4, %v91063_v21 (stack40)
        %v91444_v53 = vadd.s32 %v91440_v45, %v91428_v31 (stack40)
        %v91446_v55 = vshll.u32 %v91440_v45, 13 (stack45)
        %v91447_v60 = vshrl.u32 %v91440_v45, 19 (stack46)
        %v91853_v52 = vadd.s32 %v91850_v44, %v121564_v0 (stack40)
        %v92286_v50 = vadd.s32 %v92283_v54, %v92278_v50 (stack40)
        %v89882_v25 = vpack.c.bf16 %v157387_v11, %v89879_v29 (stack81)
        %vm90287_vm14 = vcmp.eq.f32.partialorder %v148319_v9, inf (stack70)
        %v90654_v20 = vand.u32 65535, %v90653_v42 (stack50)
        %v91071_v43 = vadd.s32 %v91067_v23, %v91055_v27 (stack40)
        %v91073_v34 = vshll.u32 %v91067_v23, 13 (stack45)
        %vm90289_vm15 = vcmp.eq.f32.partialorder %v148319_v9, 0.0 (stack71)
        %v91074_v46 = vshrl.u32 %v91067_v23, 19 (stack46)
        %v91448_v44 = vor.u32 %v91447_v60, %v91446_v55 (stack47)
        %v91857_v6 = vadd.s32 1, %v91853_v52 (stack40)
        %v92288_v26 = vshll.u32 %v92283_v54, 15 (stack45)
        %120223 = vst [vmem:[%s123356_s30 + $0x3dc] sm:$0xf] /*vst_source=*/%v89882_v25 (stack83)
        %v90655_v45 = vshrl.u32 %v90654_v20, 1 (stack51)
        %v92289_v54 = vshrl.u32 %v92283_v54, 17 (stack46)
        %vm92705_vm0 = vcmp.lt.u32.totalorder %v148299_v7, %v157091_v37 (stack43)
        %v92710_v56 = vadd.s32 %v157645_v22, %v157094_v36 (stack40)
        %v91075_v12 = vor.u32 %v91074_v46, %v91073_v34 (stack47)
        %v91449_v31 = vxor.u32 %v91448_v44, %v91444_v53 (stack48)
        %v91861_v27 = vadd.s32 %v91857_v6, %v91845_v40 (stack40)
        %v91863_v21 = vshll.u32 %v91857_v6, 17 (stack45)
        %v90656_v40 = vor.u32 16256, %v90655_v45 (stack47)
        %v91864_v30 = vshrl.u32 %v91857_v6, 15 (stack46)
        %v92290_v29 = vor.u32 %v92289_v54, %v92288_v26 (stack47)
        %v92714_v42 = vadd.s32 1, %v92710_v56 (stack40)
        %v91076_v23 = vxor.u32 %v91075_v12, %v91071_v43 (stack48)
        %v91452_v53 = vadd.s32 %v91449_v31, %v91444_v53 (stack40)
        %v91454_v55 = vshll.u32 %v91449_v31, 15 (stack45)
        %v91455_v60 = vshrl.u32 %v91449_v31, 17 (stack46)
        %v121204_v52 = vpop.eup %121203 (stack73)
        %v90657_v25 = vand.u32.u16 65535, %v90656_v40 (stack52)
        %v91865_v20 = vor.u32 %v91864_v30, %v91863_v21 (stack47)
        %v92291_v34 = vxor.u32 %v92290_v29, %v92286_v50 (stack48)
        %v92718_v46 = vsel /*vm=*/%vm92705_vm0, /*on_true_vy=*/%v92714_v42, /*on_false_vx=*/%v92710_v56 (stack44)
        %v90286_v44 = vmul.f32 %v121204_v52, %v148319_v9 (stack74)
        %v91079_v43 = vadd.s32 %v91076_v23, %v91071_v43 (stack40)
        %v91081_v6 = vshll.u32 %v91076_v23, 15 (stack45)
        %v91082_v26 = vshrl.u32 %v91076_v23, 17 (stack46)
        %vm92700_vm1 = vcmp.lt.u32.totalorder %v148332_v32, %v148299_v7 (stack43)
        %v120230_v45 = vadd.low.f32.bf16 -1.0, %v90657_v25 (stack53)
        %v91456_v54 = vor.u32 %v91455_v60, %v91454_v55 (stack47)
        %v91866_v56 = vxor.u32 %v91865_v20, %v91861_v27 (stack48)
        %v148358_v50 = vadd.s32 %v92291_v34, %v92286_v50 (stack40)
        %v90288_v12 = vsel /*vm=*/%vm90287_vm14, /*on_true_vy=*/%v148319_v9, /*on_false_vx=*/%v90286_v44 (stack75)
        %v91083_v31 = vor.u32 %v91082_v26, %v91081_v6 (stack47)
        %v92296_v21 = vshll.u32 %v92291_v34, 26 (stack45)
        %v92297_v40 = vshrl.u32 %v92291_v34, 6 (stack46)
        %v90291_v24 = vsel /*vm=*/%vm90289_vm15, /*on_true_vy=*/%v90290_v24, /*on_false_vx=*/%v90288_v12 (stack76)
        %v90666_v30 = vmul.f32 2.0, %v120230_v45 (stack54)
        %v91457_v29 = vxor.u32 %v91456_v54, %v91452_v53 (stack48)
        %v91869_v27 = vadd.s32 %v91866_v56, %v91861_v27 (stack40)
        %v90294_v42 = vadd.f32 -3.0, %v90291_v24 (stack53)
        %v91084_v23 = vxor.u32 %v91083_v31, %v91079_v43 (stack48)
        %v91871_v55 = vshll.u32 %v91866_v56, 29 (stack45)
        %v91872_v60 = vshrl.u32 %v91866_v56, 3 (stack46)
        %v90670_v52 = vadd.f32 -0.99609375, %v90666_v30 (stack53)
        %v91460_v53 = vadd.s32 %v91457_v29, %v91452_v53 (stack40)
        %v91462_v25 = vshll.u32 %v91457_v29, 26 (stack45)
        %v91463_v20 = vshrl.u32 %v91457_v29, 6 (stack46)
        %v148368_v10 = vsel /*vm=*/%vm90242_vm12, /*on_true_vy=*/%v148340_v10, /*on_false_vx=*/%v90294_v42 (stack44)
        %v91087_v34 = vadd.s32 %v91084_v23, %v91079_v43 (stack40)
        %v91089_v44 = vshll.u32 %v91084_v23, 26 (stack45)
        %v91090_v43 = vshrl.u32 %v91084_v23, 6 (stack46)
        %v90302_v61 = vmul.f32 %v148368_v10, %v148337_v61 (stack54)
        %v148372_v6 = vmax.f32 %v90670_v52, -0.99609375 (stack55)
        %v91464_v26 = vor.u32 %v91463_v20, %v91462_v25 (stack47)
        %v91873_v45 = vor.u32 %v91872_v60, %v91871_v55 (stack47)
        %v90275_v54 = vsel /*vm=*/%vm90242_vm12, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v91091_v56 = vor.u32 %v91090_v43, %v91089_v44 (stack47)
        %v92298_v12 = vor.u32 %v92297_v40, %v92296_v21 (stack47)
        %v92722_v31 = vadd.s32 1, %v92718_v46 (stack40)
        %v90215_v21 = vand.u32 2147483647, %v148260_v41 (stack77)
        %v148381_v40 = vsel /*vm=*/%vm90242_vm12, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v90306_v24 = vadd.f32 %v90302_v61, %v90275_v54 (stack53)
        %v90686_v30 = vxor.u32 2147483648, %v148372_v6 (stack56)
        %v91092_v29 = vxor.u32 %v91091_v56, %v91087_v34 (stack48)
        %v91465_v42 = vxor.u32 %v91464_v26, %v91460_v53 (stack48)
        %v91874_v23 = vxor.u32 %v91873_v45, %v91869_v27 (stack48)
        %v92299_v55 = vxor.u32 %v92298_v12, %v148358_v50 (stack48)
        %v90271_v60 = vsel /*vm=*/%vm90242_vm12, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v90310_v52 = vmul.f32 %v90306_v24, %v148368_v10 (stack54)
        %v148390_v25 = vmul.f32 %v90686_v30, %v148372_v6 (stack54)
        %v92726_v7 = vsel /*vm=*/%vm92700_vm1, /*on_true_vy=*/%v92722_v31, /*on_false_vx=*/%v92718_v46 (stack44)
        %v91095_v46 = vadd.s32 %v91092_v29, %v91087_v34 (stack40)
        %v91101_v20 = vshll.u32 %v91092_v29, 6 (stack45)
        %v91102_v34 = vshrl.u32 %v91092_v29, 26 (stack46)
        %v91468_v53 = vadd.s32 %v91465_v42, %v91460_v53 (stack40)
        %v90259_v44 = vsel /*vm=*/%vm90242_vm12, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v90263_v43 = vsel /*vm=*/%vm90242_vm12, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v90314_v61 = vadd.f32 %v90310_v52, %v90271_v60 (stack53)
        %v90691_v26 = vadd.f32 1.0, %v148390_v25 (stack57)
        %v90267_v45 = vsel /*vm=*/%vm90242_vm12, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v91103_v54 = vor.u32 %v91102_v34, %v91101_v20 (stack47)
        %v91474_v56 = vshll.u32 %v91465_v42, 6 (stack45)
        %v92735_v32 = vadd.s32 %v148332_v32, %v121569_v1 (stack40)
        %v90318_v12 = vmul.f32 %v90314_v61, %v148368_v10 (stack54)
        %121205 = vlog2.f32 %v90691_v26 (stack58)
        %v90694_v31 = vmul.f32 -0.5, %v148390_v25 (stack59)
        %v91099_v24 = vadd.s32 %v91095_v46, %v121564_v0 (stack40)
        %v91104_v30 = vxor.u32 %v91103_v54, %v91095_v46 (stack48)
        %v91475_v29 = vshrl.u32 %v91465_v42, 26 (stack46)
        %v91877_v27 = vadd.s32 %v91874_v23, %v91869_v27 (stack40)
        %v91879_v42 = vshll.u32 %v91874_v23, 16 (stack45)
        %v90322_v60 = vadd.f32 %v90318_v12, %v90267_v45 (stack53)
        %v91472_v52 = vadd.s32 %v91468_v53, %v121574_v2 (stack40)
        %v91880_v23 = vshrl.u32 %v91874_v23, 16 (stack46)
        %v92302_v50 = vadd.s32 %v92299_v55, %v148358_v50 (stack40)
        %v91107_v46 = vadd.s32 %v91104_v30, %v121574_v2 (stack40)
        %v91476_v20 = vor.u32 %v91475_v29, %v91474_v56 (stack47)
        %v92308_v34 = vshll.u32 %v92299_v55, 6 (stack45)
        %v92309_v55 = vshrl.u32 %v92299_v55, 26 (stack46)
        %v90326_v61 = vmul.f32 %v90322_v60, %v148368_v10 (stack54)
        %v90695_v26 = vadd.f32 1.0, %v90694_v31 (stack61)
        %v91881_v45 = vor.u32 %v91880_v23, %v91879_v42 (stack47)
        %v92731_v7 = vadd.s32 %v92726_v7, %v121574_v2 (stack40)
        %v91111_v54 = vadd.s32 5, %v91107_v46 (stack40)
        %v91477_v53 = vxor.u32 %v91476_v20, %v91468_v53 (stack48)
        %v92310_v56 = vor.u32 %v92309_v55, %v92308_v34 (stack47)
        %v92741_v12 = vshll.u32 %v92735_v32, 13 (stack45)
        %v90330_v43 = vadd.f32 %v90326_v61, %v90263_v43 (stack53)
        %v91882_v31 = vxor.u32 %v91881_v45, %v91877_v27 (stack48)
        %v92739_v30 = vadd.s32 %v92735_v32, %v92731_v7 (stack40)
        %v92742_v32 = vshrl.u32 %v92735_v32, 19 (stack46)
        %v91113_v24 = vxor.u32 %v91111_v54, %v91099_v24 (stack48)
        %v91480_v29 = vadd.s32 %v91477_v53, %v121569_v1 (stack40)
        %v92311_v42 = vxor.u32 %v92310_v56, %v92302_v50 (stack48)
        %v148418_v8 = vadd.s32 %v157642_v8, %v157095_v13 (stack40)
        %v90334_v60 = vmul.f32 %v90330_v43, %v148368_v10 (stack54)
        %v91885_v27 = vadd.s32 %v91882_v31, %v91877_v27 (stack40)
        %v91891_v23 = vshll.u32 %v91882_v31, 24 (stack45)
        %v91892_v46 = vshrl.u32 %v91882_v31, 8 (stack46)
        %v91114_v20 = vand.u32.u8 255, %v91113_v24 (stack49)
        %v91484_v34 = vadd.s32 3, %v91480_v29 (stack40)
        %v92314_v55 = vadd.s32 %v92311_v42, %v121564_v0 (stack40)
        %v92743_v61 = vor.u32 %v92742_v32, %v92741_v12 (stack47)
        %v90338_v44 = vadd.f32 %v90334_v60, %v90259_v44 (stack53)
        %v90697_v45 = vand.u32 2147483647, %v148390_v25 (stack60)
        %v91893_v7 = vor.u32 %v91892_v46, %v91891_v23 (stack47)
        %v92306_v50 = vadd.s32 %v92302_v50, %v121569_v1 (stack40)
        %v91115_v54 = vand.u32 65535, %v91114_v20 (stack50)
        %v91488_v52 = vadd.s32 %v91484_v34, %v91472_v52 (stack40)
        %v91490_v53 = vshll.u32 %v91484_v34, 17 (stack45)
        %v91491_v56 = vshrl.u32 %v91484_v34, 15 (stack46)
        %v90342_v12 = vmul.f32 %v90338_v44, %v148368_v10 (stack54)
        %v91894_v43 = vxor.u32 %v91893_v7, %v91885_v27 (stack48)
        %v92318_v31 = vadd.s32 1, %v92314_v55 (stack40)
        %v148425_v32 = vxor.u32 %v92743_v61, %v92739_v30 (stack48)
        %v121206_v24 = vpop.eup %121205 (stack64)
        %v90696_v25 = vmul.f32 %v90695_v26, %v148390_v25 (stack63)
        %v91116_v26 = vshrl.u32 %v91115_v54, 1 (stack51)
        %v91492_v29 = vor.u32 %v91491_v56, %v91490_v53 (stack47)
        %vm93166_vm2 = vcmp.lt.u32.totalorder %v148418_v8, %v157095_v13 (stack43)
        %v90346_v40 = vadd.f32 %v90342_v12, %v148381_v40 (stack53)
        %v90693_v42 = vmul.f32 0.6931472, %v121206_v24 (stack65)
        %v91897_v60 = vadd.s32 %v91894_v43, %v121574_v2 (stack40)
        %v92322_v23 = vadd.s32 %v92318_v31, %v92306_v50 (stack40)
        %vm90698_vm3 = vcmp.lt.f32.partialorder %v90697_v45, 0.0004427343 (stack62)
        %v91117_v46 = vor.u32 16256, %v91116_v26 (stack47)
        %v91493_v20 = vxor.u32 %v91492_v29, %v91488_v52 (stack48)
        %v91889_v27 = vadd.s32 %v91885_v27, %v121564_v0 (stack40)
        %v90350_v34 = vmul.f32 %v90346_v40, %v148368_v10 (stack54)
        %v90699_v55 = vsel /*vm=*/%vm90698_vm3, /*on_true_vy=*/%v90696_v25, /*on_false_vx=*/%v90693_v42 (stack66)
        %v91901_v61 = vadd.s32 2, %v91897_v60 (stack40)
        %v148435_v30 = vadd.s32 %v148425_v32, %v92739_v30 (stack40)
        %v90251_v44 = vsel /*vm=*/%vm90242_vm12, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v148440_v45 = vxor.u32 2147483648, %v90699_v55 (stack56)
        %v91496_v7 = vadd.s32 %v91493_v20, %v91488_v52 (stack40)
        %v91498_v50 = vshll.u32 %v91493_v20, 29 (stack45)
        %v90354_v54 = vadd.f32 %v90350_v34, %v90251_v44 (stack53)
        %v91499_v52 = vshrl.u32 %v91493_v20, 3 (stack46)
        %v91905_v53 = vadd.s32 %v91901_v61, %v91889_v27 (stack40)
        %121207 = vrsqrt.f32 %v148440_v45 (stack67)
        %v91118_v56 = vand.u32.u16 65535, %v91117_v46 (stack52)
        %v90358_v10 = vmul.f32 %v90354_v54, %v148368_v10 (stack54)
        %v92324_v12 = vshll.u32 %v92318_v31, 17 (stack45)
        %v92325_v43 = vshrl.u32 %v92318_v31, 15 (stack46)
        %vm148446_vm4 = vcmp.eq.f32.partialorder %v90215_v21, 1.0 (stack68)
        %v90223_v31 = vmul.f32 inf, %v148260_v41 (stack54)
        %v90247_v9 = vsel /*vm=*/%vm90242_vm12, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v91500_v24 = vor.u32 %v91499_v52, %v91498_v50 (stack47)
        %v90362_v25 = vadd.f32 %v90358_v10, %v90247_v9 (stack53)
        %v90676_v26 = vand.u32 2147483647, %v148372_v6 (stack77)
        %v148456_v29 = vmul.f32 inf, %v148372_v6 (stack54)
        %v91907_v40 = vshll.u32 %v91901_v61, 13 (stack45)
        %vm90703_vm5 = vcmp.lt.f32.partialorder %v148440_v45, 5.0 (stack68)
        %v120232_v42 = vadd.low.f32.bf16 -1.0, %v91118_v56 (stack53)
        %v91501_v60 = vxor.u32 %v91500_v24, %v91496_v7 (stack48)
        %v148461_v46 = vadd.s32 %v148418_v8, %v122657_v58 (stack40)
        %v90366_v41 = vmul.f32 %v90362_v25, %v148260_v41 (stack54)
        %v148465_v20 = vadd.f32 -2.5, %v148440_v45 (stack53)
        %v91908_v27 = vshrl.u32 %v91901_v61, 19 (stack46)
        %v92326_v34 = vor.u32 %v92325_v43, %v92324_v12 (stack47)
        %v91127_v55 = vmul.f32 2.0, %v120232_v42 (stack54)
        %v91504_v61 = vadd.s32 %v91501_v60, %v91496_v7 (stack40)
        %v91506_v44 = vshll.u32 %v91501_v60, 16 (stack45)
        %v91507_v7 = vshrl.u32 %v91501_v60, 16 (stack46)
        %v90370_v50 = vsel /*vm=*/%vm148446_vm4, /*on_true_vy=*/%v90223_v31, /*on_false_vx=*/%v90366_v41 (stack44)
        %vm90748_vm6 = vcmp.eq.f32.partialorder %v148440_v45, inf (stack70)
        %v91909_v54 = vor.u32 %v91908_v27, %v91907_v40 (stack47)
        %v92327_v52 = vxor.u32 %v92326_v34, %v92322_v23 (stack48)
        %v92749_v56 = vshll.u32 %v148425_v32, 15 (stack45)
        %v90374_v10 = vmul.f32 1.4140625, %v90370_v50 (stack54)
        %v91131_v12 = vadd.f32 -0.99609375, %v91127_v55 (stack53)
        %v91508_v43 = vor.u32 %v91507_v7, %v91506_v44 (stack47)
        %v93171_v22 = vadd.s32 %v157645_v22, %v157100_v14 (stack40)
        %v91910_v21 = vxor.u32 %v91909_v54, %v91905_v53 (stack48)
        %v92330_v23 = vadd.s32 %v92327_v52, %v92322_v23 (stack40)
        %v92332_v31 = vshll.u32 %v92327_v52, 29 (stack45)
        %v92333_v9 = vshrl.u32 %v92327_v52, 3 (stack46)
        %v90377_v24 = vpack.c.bf16 %v157387_v11, %v90374_v10 (stack81)
        %v148474_v25 = vmax.f32 %v91131_v12, -0.99609375 (stack55)
        %v91509_v40 = vxor.u32 %v91508_v43, %v91504_v61 (stack48)
        %v92750_v32 = vshrl.u32 %v148425_v32, 17 (stack46)
        %v91913_v53 = vadd.s32 %v91910_v21, %v91905_v53 (stack40)
        %v91915_v42 = vshll.u32 %v91910_v21, 15 (stack45)
        %v91916_v60 = vshrl.u32 %v91910_v21, 17 (stack46)
        %v92334_v41 = vor.u32 %v92333_v9, %v92332_v31 (stack47)
        %120229 = vst [vmem:[%s123356_s30 + $0x60] sm:$0xf] /*vst_source=*/%v90377_v24 (stack83)
        %v148481_v27 = vsel /*vm=*/%vm90703_vm5, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v148486_v34 = vsel /*vm=*/%vm90703_vm5, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v91147_v55 = vxor.u32 2147483648, %v148474_v25 (stack56)
        %v91512_v61 = vadd.s32 %v91509_v40, %v91504_v61 (stack40)
        %v121208_v44 = vpop.eup %121207 (stack73)
        %v91518_v7 = vshll.u32 %v91509_v40, 24 (stack45)
        %v91519_v50 = vshrl.u32 %v91509_v40, 8 (stack46)
        %v91917_v54 = vor.u32 %v91916_v60, %v91915_v42 (stack47)
        %v92335_v52 = vxor.u32 %v92334_v41, %v92330_v23 (stack48)
        %v148492_v10 = vsel /*vm=*/%vm90703_vm5, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v90747_v12 = vmul.f32 %v121208_v44, %v148440_v45 (stack74)
        %v90751_v43 = vand.u32 2147483648, %v148440_v45 (stack72)
        %v148497_v21 = vmul.f32 %v91147_v55, %v148474_v25 (stack54)
        %v91520_v31 = vor.u32 %v91519_v50, %v91518_v7 (stack47)
        %v91918_v9 = vxor.u32 %v91917_v54, %v91913_v53 (stack48)
        %v92338_v23 = vadd.s32 %v92335_v52, %v92330_v23 (stack40)
        %v92751_v56 = vor.u32 %v92750_v32, %v92749_v56 (stack47)
        %v90749_v24 = vsel /*vm=*/%vm90748_vm6, /*on_true_vy=*/%v148440_v45, /*on_false_vx=*/%v90747_v12 (stack75)
        %vm90750_vm7 = vcmp.eq.f32.partialorder %v148440_v45, 0.0 (stack71)
        %v91152_v40 = vadd.f32 1.0, %v148497_v21 (stack57)
        %v92340_v32 = vshll.u32 %v92335_v52, 16 (stack45)
        %v90752_v42 = vsel /*vm=*/%vm90750_vm7, /*on_true_vy=*/%v90751_v43, /*on_false_vx=*/%v90749_v24 (stack76)
        %v91521_v60 = vxor.u32 %v91520_v31, %v91512_v61 (stack48)
        %v91921_v53 = vadd.s32 %v91918_v9, %v91913_v53 (stack40)
        %v91923_v41 = vshll.u32 %v91918_v9, 26 (stack45)
        %v90736_v55 = vsel /*vm=*/%vm90703_vm5, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v90740_v44 = vsel /*vm=*/%vm90703_vm5, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v90755_v7 = vadd.f32 -3.0, %v90752_v42 (stack53)
        %121209 = vlog2.f32 %v91152_v40 (stack58)
        %v91524_v50 = vadd.s32 %v91521_v60, %v121564_v0 (stack40)
        %v91924_v54 = vshrl.u32 %v91918_v9, 6 (stack46)
        %v92341_v52 = vshrl.u32 %v92335_v52, 16 (stack46)
        %v92752_v12 = vxor.u32 %v92751_v56, %v148435_v30 (stack48)
        %v148515_v20 = vsel /*vm=*/%vm90703_vm5, /*on_true_vy=*/%v148465_v20, /*on_false_vx=*/%v90755_v7 (stack44)
        %v91155_v43 = vmul.f32 -0.5, %v148497_v21 (stack59)
        %v91516_v61 = vadd.s32 %v91512_v61, %v121569_v1 (stack40)
        %vm93161_vm8 = vcmp.lt.u32.totalorder %v148461_v46, %v148418_v8 (stack43)
        %v93175_v31 = vadd.s32 1, %v93171_v22 (stack40)
        %v90763_v9 = vmul.f32 %v148515_v20, %v90740_v44 (stack54)
        %v91528_v56 = vadd.s32 4, %v91524_v50 (stack40)
        %v91925_v24 = vor.u32 %v91924_v54, %v91923_v41 (stack47)
        %v92342_v40 = vor.u32 %v92341_v52, %v92340_v32 (stack47)
        %v92755_v30 = vadd.s32 %v92752_v12, %v148435_v30 (stack40)
        %v92757_v32 = vshll.u32 %v92752_v12, 26 (stack45)
        %v92758_v42 = vshrl.u32 %v92752_v12, 6 (stack46)
        %v93179_v22 = vsel /*vm=*/%vm93166_vm2, /*on_true_vy=*/%v93175_v31, /*on_false_vx=*/%v93171_v22 (stack44)
        %v90767_v60 = vadd.f32 %v90763_v9, %v90736_v55 (stack53)
        %v91532_v41 = vadd.s32 %v91528_v56, %v91516_v61 (stack40)
        %v91534_v55 = vshll.u32 %v91528_v56, 13 (stack45)
        %v91535_v44 = vshrl.u32 %v91528_v56, 19 (stack46)
        %v90732_v7 = vsel /*vm=*/%vm90703_vm5, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v91926_v50 = vxor.u32 %v91925_v24, %v91921_v53 (stack48)
        %v92343_v54 = vxor.u32 %v92342_v40, %v92338_v23 (stack48)
        %v92759_v52 = vor.u32 %v92758_v42, %v92757_v32 (stack47)
        %v90771_v12 = vmul.f32 %v90767_v60, %v148515_v20 (stack54)
        %v91156_v43 = vadd.f32 1.0, %v91155_v43 (stack61)
        %v91536_v61 = vor.u32 %v91535_v44, %v91534_v55 (stack47)
        %v93183_v31 = vadd.s32 1, %v93179_v22 (stack40)
        %v91929_v53 = vadd.s32 %v91926_v50, %v91921_v53 (stack40)
        %v91935_v9 = vshll.u32 %v91926_v50, 6 (stack45)
        %v91936_v56 = vshrl.u32 %v91926_v50, 26 (stack46)
        %v92346_v23 = vadd.s32 %v92343_v54, %v92338_v23 (stack40)
        %v90775_v24 = vadd.f32 %v90771_v12, %v90732_v7 (stack53)
        %v91537_v40 = vxor.u32 %v91536_v61, %v91532_v41 (stack48)
        %v92352_v32 = vshll.u32 %v92343_v54, 24 (stack45)
        %v92353_v42 = vshrl.u32 %v92343_v54, 8 (stack46)
        %v90724_v60 = vsel /*vm=*/%vm90703_vm5, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v91158_v55 = vand.u32 2147483647, %v148497_v21 (stack60)
        %v91937_v44 = vor.u32 %v91936_v56, %v91935_v9 (stack47)
        %v92760_v7 = vxor.u32 %v92759_v52, %v92755_v30 (stack48)
        %v90779_v50 = vmul.f32 %v90775_v24, %v148515_v20 (stack54)
        %v91540_v41 = vadd.s32 %v91537_v40, %v91532_v41 (stack40)
        %v91542_v54 = vshll.u32 %v91537_v40, 15 (stack45)
        %v91543_v52 = vshrl.u32 %v91537_v40, 17 (stack46)
        %v90728_v12 = vsel /*vm=*/%vm90703_vm5, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v91938_v61 = vxor.u32 %v91937_v44, %v91929_v53 (stack48)
        %v92354_v9 = vor.u32 %v92353_v42, %v92352_v32 (stack47)
        %v148538_v30 = vadd.s32 %v92760_v7, %v92755_v30 (stack40)
        %v121210_v56 = vpop.eup %121209 (stack64)
        %v90783_v24 = vadd.f32 %v90779_v50, %v90728_v12 (stack53)
        %v91157_v21 = vmul.f32 %v91156_v43, %v148497_v21 (stack63)
        %v91544_v43 = vor.u32 %v91543_v52, %v91542_v54 (stack47)
        %v93187_v8 = vsel /*vm=*/%vm93161_vm8, /*on_true_vy=*/%v93183_v31, /*on_false_vx=*/%v93179_v22 (stack44)
        %v91154_v22 = vmul.f32 0.6931472, %v121210_v56 (stack65)
        %v91941_v31 = vadd.s32 %v91938_v61, %v121569_v1 (stack40)
        %v92355_v40 = vxor.u32 %v92354_v9, %v92346_v23 (stack48)
        %v93196_v46 = vadd.s32 %v148461_v46, %v121569_v1 (stack40)
        %v90787_v32 = vmul.f32 %v90783_v24, %v148515_v20 (stack54)
        %vm91159_vm9 = vcmp.lt.f32.partialorder %v91158_v55, 0.0004427343 (stack62)
        %v91545_v42 = vxor.u32 %v91544_v43, %v91540_v41 (stack48)
        %v91933_v53 = vadd.s32 %v91929_v53, %v121574_v2 (stack40)
        %v91160_v55 = vsel /*vm=*/%vm91159_vm9, /*on_true_vy=*/%v91157_v21, /*on_false_vx=*/%v91154_v22 (stack66)
        %v91945_v44 = vadd.s32 3, %v91941_v31 (stack40)
        %v92769_v50 = vshll.u32 %v92760_v7, 6 (stack45)
        %v92770_v7 = vshrl.u32 %v92760_v7, 26 (stack46)
        %v90791_v60 = vadd.f32 %v90787_v32, %v90724_v60 (stack53)
        %v148549_v54 = vxor.u32 2147483648, %v91160_v55 (stack56)
        %v91548_v41 = vadd.s32 %v91545_v42, %v91540_v41 (stack40)
        %v91550_v52 = vshll.u32 %v91545_v42, 26 (stack45)
        %v91551_v12 = vshrl.u32 %v91545_v42, 6 (stack46)
        %v91949_v61 = vadd.s32 %v91945_v44, %v91933_v53 (stack40)
        %v93202_v9 = vshll.u32 %v93196_v46, 13 (stack45)
        %v93203_v56 = vshrl.u32 %v93196_v46, 19 (stack46)
        %v90720_v45 = vsel /*vm=*/%vm90703_vm5, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v90795_v24 = vmul.f32 %v90791_v60, %v148515_v20 (stack54)
        %v91137_v21 = vand.u32 2147483647, %v148474_v25 (stack77)
        %121211 = vrsqrt.f32 %v148549_v54 (stack67)
        %vm91164_vm10 = vcmp.lt.f32.partialorder %v148549_v54, 5.0 (stack68)
        %v91552_v43 = vor.u32 %v91551_v12, %v91550_v52 (stack47)
        %v91951_v22 = vshll.u32 %v91945_v44, 17 (stack45)
        %v91952_v31 = vshrl.u32 %v91945_v44, 15 (stack46)
        %v90799_v32 = vadd.f32 %v90795_v24, %v90720_v45 (stack53)
        %v92358_v40 = vadd.s32 %v92355_v40, %v121574_v2 (stack40)
        %v92771_v42 = vor.u32 %v92770_v7, %v92769_v50 (stack47)
        %v93192_v8 = vadd.s32 %v93187_v8, %v121574_v2 (stack40)
        %v91553_v53 = vxor.u32 %v91552_v43, %v91548_v41 (stack48)
        %v92350_v23 = vadd.s32 %v92346_v23, %v121564_v0 (stack40)
        %v92767_v55 = vadd.s32 %v148538_v30, %v121569_v1 (stack40)
        %v93204_v44 = vor.u32 %v93203_v56, %v93202_v9 (stack47)
        %v90803_v50 = vmul.f32 %v90799_v32, %v148515_v20 (stack54)
        %v148567_v7 = vsel /*vm=*/%vm91164_vm10, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v148572_v60 = vsel /*vm=*/%vm91164_vm10, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v148575_v52 = vadd.f32 -2.5, %v148549_v54 (stack53)
        %v91556_v41 = vadd.s32 %v91553_v53, %v91548_v41 (stack40)
        %v91562_v12 = vshll.u32 %v91553_v53, 6 (stack45)
        %v91563_v9 = vshrl.u32 %v91553_v53, 26 (stack46)
        %v91953_v56 = vor.u32 %v91952_v31, %v91951_v22 (stack47)
        %v90807_v10 = vadd.f32 %v90803_v50, %v148492_v10 (stack53)
        %v92362_v45 = vadd.s32 2, %v92358_v40 (stack40)
        %v92772_v30 = vxor.u32 %v92771_v42, %v148538_v30 (stack48)
        %v93200_v46 = vadd.s32 %v93196_v46, %v93192_v8 (stack40)
        %vm91209_vm11 = vcmp.eq.f32.partialorder %v148549_v54, inf (stack70)
        %v91212_v24 = vand.u32 2147483648, %v148549_v54 (stack72)
        %v91564_v43 = vor.u32 %v91563_v9, %v91562_v12 (stack47)
        %v91954_v22 = vxor.u32 %v91953_v56, %v91949_v61 (stack48)
        %v157664_v31 = vld [vmem:[#allocation145_spill] sm:$0xff] (stack84)
        %v148583_v32 = vadd.s32 %v157664_v31, %v122651_v47 (stack40)
        %v90811_v40 = vmul.f32 %v90807_v10, %v148515_v20 (stack54)
        %vm91211_vm12 = vcmp.eq.f32.partialorder %v148549_v54, 0.0 (stack71)
        %v92366_v42 = vadd.s32 %v92362_v45, %v92350_v23 (stack40)
        %v92368_v8 = vshll.u32 %v92362_v45, 13 (stack45)
        %v92369_v53 = vshrl.u32 %v92362_v45, 19 (stack46)
        %vm148589_vm13 = vcmp.eq.f32.partialorder %v90676_v26, 1.0 (stack68)
        %v91565_v23 = vxor.u32 %v91564_v43, %v91556_v41 (stack48)
        %v91957_v61 = vadd.s32 %v91954_v22, %v91949_v61 (stack40)
        %v91959_v50 = vshll.u32 %v91954_v22, 29 (stack45)
        %v91960_v12 = vshrl.u32 %v91954_v22, 3 (stack46)
        %v90815_v34 = vadd.f32 %v90811_v40, %v148486_v34 (stack53)
        %v92370_v9 = vor.u32 %v92369_v53, %v92368_v8 (stack47)
        %v92775_v56 = vadd.s32 %v92772_v30, %v121564_v0 (stack40)
        %v93205_v44 = vxor.u32 %v93204_v44, %v93200_v46 (stack48)
        %v91560_v41 = vadd.s32 %v91556_v41, %v121564_v0 (stack40)
        %v91568_v10 = vadd.s32 %v91565_v23, %v121574_v2 (stack40)
        %v91961_v45 = vor.u32 %v91960_v12, %v91959_v50 (stack47)
        %vm93661_vm14 = vcmp.lt.u32.totalorder %v148583_v32, %v122651_v47 (stack43)
        %v90819_v20 = vmul.f32 %v90815_v34, %v148515_v20 (stack54)
        %v92371_v30 = vxor.u32 %v92370_v9, %v92366_v42 (stack48)
        %v92779_v43 = vadd.s32 1, %v92775_v56 (stack40)
        %v93208_v46 = vadd.s32 %v93205_v44, %v93200_v46 (stack40)
        %v121212_v22 = vpop.eup %121211 (stack73)
        %v91572_v40 = vadd.s32 5, %v91568_v10 (stack40)
        %v91962_v8 = vxor.u32 %v91961_v45, %v91957_v61 (stack48)
        %v93210_v53 = vshll.u32 %v93205_v44, 15 (stack45)
        %v93211_v23 = vshrl.u32 %v93205_v44, 17 (stack46)
        %v90823_v27 = vadd.f32 %v90819_v20, %v148481_v27 (stack53)
        %v91208_v50 = vmul.f32 %v121212_v22, %v148549_v54 (stack74)
        %v92374_v42 = vadd.s32 %v92371_v30, %v92366_v42 (stack40)
        %v92376_v12 = vshll.u32 %v92371_v30, 15 (stack45)
        %v91574_v34 = vxor.u32 %v91572_v40, %v91560_v41 (stack48)
        %v91965_v61 = vadd.s32 %v91962_v8, %v91957_v61 (stack40)
        %v91967_v9 = vshll.u32 %v91962_v8, 16 (stack45)
        %v91968_v56 = vshrl.u32 %v91962_v8, 16 (stack46)
        %v90827_v6 = vmul.f32 %v90823_v27, %v148372_v6 (stack54)
        %v91210_v44 = vsel /*vm=*/%vm91209_vm11, /*on_true_vy=*/%v148549_v54, /*on_false_vx=*/%v91208_v50 (stack75)
        %v92377_v41 = vshrl.u32 %v92371_v30, 17 (stack46)
        %v92783_v55 = vadd.s32 %v92779_v43, %v92767_v55 (stack40)
        %v91213_v24 = vsel /*vm=*/%vm91211_vm12, /*on_true_vy=*/%v91212_v24, /*on_false_vx=*/%v91210_v44 (stack76)
        %v91575_v10 = vand.u32.u8 255, %v91574_v34 (stack49)
        %v91969_v45 = vor.u32 %v91968_v56, %v91967_v9 (stack47)
        %v92785_v20 = vshll.u32 %v92779_v43, 17 (stack45)
        %v90831_v29 = vsel /*vm=*/%vm148589_vm13, /*on_true_vy=*/%v148456_v29, /*on_false_vx=*/%v90827_v6 (stack44)
        %v91216_v26 = vadd.f32 -3.0, %v91213_v24 (stack53)
        %v92378_v30 = vor.u32 %v92377_v41, %v92376_v12 (stack47)
        %v92786_v43 = vshrl.u32 %v92779_v43, 15 (stack46)
        %v90835_v22 = vmul.f32 1.4140625, %v90831_v29 (stack54)
        %v91201_v40 = vsel /*vm=*/%vm91164_vm10, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v91576_v8 = vand.u32 65535, %v91575_v10 (stack50)
        %v91970_v27 = vxor.u32 %v91969_v45, %v91965_v61 (stack48)
        %v148617_v52 = vsel /*vm=*/%vm91164_vm10, /*on_true_vy=*/%v148575_v52, /*on_false_vx=*/%v91216_v26 (stack44)
        %v92379_v50 = vxor.u32 %v92378_v30, %v92374_v42 (stack48)
        %v92787_v12 = vor.u32 %v92786_v43, %v92785_v20 (stack47)
        %v93212_v53 = vor.u32 %v93211_v23, %v93210_v53 (stack47)
        %v90838_v23 = vpack.c.bf16 %v157387_v11, %v90835_v22 (stack81)
        %v91224_v34 = vmul.f32 %v148617_v52, %v91201_v40 (stack54)
        %v91577_v9 = vshrl.u32 %v91576_v8, 1 (stack51)
        %v91973_v61 = vadd.s32 %v91970_v27, %v91965_v61 (stack40)
        %v91979_v56 = vshll.u32 %v91970_v27, 24 (stack45)
        %v91980_v6 = vshrl.u32 %v91970_v27, 8 (stack46)
        %v92382_v42 = vadd.s32 %v92379_v50, %v92374_v42 (stack40)
        %v92384_v44 = vshll.u32 %v92379_v50, 26 (stack45)
        %120231 = vst [vmem:[%s123356_s30 + $0xe0] sm:$0xf] /*vst_source=*/%v90838_v23 (stack83)
        %v91193_v41 = vsel /*vm=*/%vm91164_vm10, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v91228_v60 = vadd.f32 %v91224_v34, %v148572_v60 (stack53)
        %v91578_v24 = vor.u32 16256, %v91577_v9 (stack47)
        %v92385_v10 = vshrl.u32 %v92379_v50, 6 (stack46)
        %v91981_v45 = vor.u32 %v91980_v6, %v91979_v56 (stack47)
        %v92788_v20 = vxor.u32 %v92787_v12, %v92783_v55 (stack48)
        %v93213_v29 = vxor.u32 %v93212_v53, %v93208_v46 (stack48)
        %v157667_v26 = vld [vmem:[#allocation109_spill] sm:$0xff] (stack84)
        %v148628_v30 = vadd.s32 %v157667_v26, %v157068_v28 (stack40)
        %v91232_v43 = vmul.f32 %v91228_v60, %v148617_v52 (stack54)
        %v91579_v22 = vand.u32.u16 65535, %v91578_v24 (stack52)
        %v91977_v40 = vadd.s32 %v91973_v61, %v121569_v1 (stack40)
        %v92386_v8 = vor.u32 %v92385_v10, %v92384_v44 (stack47)
        %v91982_v27 = vxor.u32 %v91981_v45, %v91973_v61 (stack48)
        %v92791_v55 = vadd.s32 %v92788_v20, %v92783_v55 (stack40)
        %v92793_v50 = vshll.u32 %v92788_v20, 29 (stack45)
        %v92794_v12 = vshrl.u32 %v92788_v20, 3 (stack46)
        %v91236_v53 = vadd.f32 %v91232_v43, %v91193_v41 (stack53)
        %v120234_v23 = vadd.low.f32.bf16 -1.0, %v91579_v22 (stack53)
        %v92387_v34 = vxor.u32 %v92386_v8, %v92382_v42 (stack48)
        %v93216_v46 = vadd.s32 %v93213_v29, %v93208_v46 (stack40)
        %v91985_v9 = vadd.s32 %v91982_v27, %v121564_v0 (stack40)
        %v92795_v61 = vor.u32 %v92794_v12, %v92793_v50 (stack47)
        %v93218_v56 = vshll.u32 %v93213_v29, 26 (stack45)
        %v93219_v6 = vshrl.u32 %v93213_v29, 6 (stack46)
        %v91240_v44 = vmul.f32 %v91236_v53, %v148617_v52 (stack54)
        %v91588_v41 = vmul.f32 2.0, %v120234_v23 (stack54)
        %v92390_v42 = vadd.s32 %v92387_v34, %v92382_v42 (stack40)
        %v92396_v60 = vshll.u32 %v92387_v34, 6 (stack45)
        %v91989_v24 = vadd.s32 4, %v91985_v9 (stack40)
        %v92397_v10 = vshrl.u32 %v92387_v34, 26 (stack46)
        %v92796_v45 = vxor.u32 %v92795_v61, %v92791_v55 (stack48)
        %v93220_v20 = vor.u32 %v93219_v6, %v93218_v56 (stack47)
        %v148635_v29 = vmul.f32 inf, %v148474_v25 (stack54)
        %v91185_v43 = vsel /*vm=*/%vm91164_vm10, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v91244_v7 = vadd.f32 %v91240_v44, %v148567_v7 (stack53)
        %v91592_v22 = vadd.f32 -0.99609375, %v91588_v41 (stack53)
        %v91993_v40 = vadd.s32 %v91989_v24, %v91977_v40 (stack40)
        %v91995_v8 = vshll.u32 %v91989_v24, 13 (stack45)
        %v91996_v27 = vshrl.u32 %v91989_v24, 19 (stack46)
        %v92398_v50 = vor.u32 %v92397_v10, %v92396_v60 (stack47)
        %v91248_v12 = vmul.f32 %v91244_v7, %v148617_v52 (stack54)
        %v148642_v53 = vmax.f32 %v91592_v22, -0.99609375 (stack55)
        %v92799_v55 = vadd.s32 %v92796_v45, %v92791_v55 (stack40)
        %v92801_v23 = vshll.u32 %v92796_v45, 16 (stack45)
        %v91997_v34 = vor.u32 %v91996_v27, %v91995_v8 (stack47)
        %v92399_v9 = vxor.u32 %v92398_v50, %v92390_v42 (stack48)
        %v92802_v61 = vshrl.u32 %v92796_v45, 16 (stack46)
        %v93221_v56 = vxor.u32 %v93220_v20, %v93216_v46 (stack48)
        %v148647_v6 = vsel /*vm=*/%vm91164_vm10, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v91181_v44 = vsel /*vm=*/%vm91164_vm10, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v91252_v41 = vadd.f32 %v91248_v12, %v91185_v43 (stack53)
        %v91608_v60 = vxor.u32 2147483648, %v148642_v53 (stack56)
        %v91998_v24 = vxor.u32 %v91997_v34, %v91993_v40 (stack48)
        %v92402_v10 = vadd.s32 %v92399_v9, %v121569_v1 (stack40)
        %v148654_v46 = vadd.s32 %v93221_v56, %v93216_v46 (stack40)
        %v148658_v45 = vadd.s32 %v148583_v32, %v122657_v58 (stack40)
        %v91256_v20 = vmul.f32 %v91252_v41, %v148617_v52 (stack54)
        %v148662_v43 = vmul.f32 %v91608_v60, %v148642_v53 (stack54)
        %v92394_v42 = vadd.s32 %v92390_v42, %v121574_v2 (stack40)
        %v92803_v7 = vor.u32 %v92802_v61, %v92801_v23 (stack47)
        %v92001_v22 = vadd.s32 %v91998_v24, %v91993_v40 (stack40)
        %v92003_v40 = vshll.u32 %v91998_v24, 15 (stack45)
        %v92004_v8 = vshrl.u32 %v91998_v24, 17 (stack46)
        %v92406_v27 = vadd.s32 3, %v92402_v10 (stack40)
        %v91173_v50 = vsel /*vm=*/%vm91164_vm10, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v91177_v54 = vsel /*vm=*/%vm91164_vm10, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v91260_v12 = vadd.f32 %v91256_v20, %v91181_v44 (stack53)
        %v91613_v23 = vadd.f32 1.0, %v148662_v43 (stack57)
        %v92005_v34 = vor.u32 %v92004_v8, %v92003_v40 (stack47)
        %v92410_v9 = vadd.s32 %v92406_v27, %v92394_v42 (stack40)
        %v92412_v61 = vshll.u32 %v92406_v27, 17 (stack45)
        %v92413_v44 = vshrl.u32 %v92406_v27, 15 (stack46)
        %vm93656_vm15 = vcmp.lt.u32.totalorder %v148658_v45, %v148583_v32 (stack43)
        %v91264_v41 = vmul.f32 %v91260_v12, %v148617_v52 (stack54)
        %121213 = vlog2.f32 %v91613_v23 (stack58)
        %v93230_v60 = vshll.u32 %v93221_v56, 6 (stack45)
        %v93670_v24 = vadd.s32 1, %v148628_v30 (stack40)
        %v91616_v10 = vmul.f32 -0.5, %v148662_v43 (stack59)
        %v92006_v20 = vxor.u32 %v92005_v34, %v92001_v22 (stack48)
        %v92414_v42 = vor.u32 %v92413_v44, %v92412_v61 (stack47)
        %v92804_v7 = vxor.u32 %v92803_v7, %v92799_v55 (stack48)
        %v91268_v40 = vadd.f32 %v91264_v41, %v91177_v54 (stack53)
        %v91619_v8 = vand.u32 2147483647, %v148662_v43 (stack60)
        %v93231_v56 = vshrl.u32 %v93221_v56, 26 (stack46)
        %v93674_v30 = vsel /*vm=*/%vm93661_vm14, /*on_true_vy=*/%v93670_v24, /*on_false_vx=*/%v148628_v30 (stack44)
        %v92009_v22 = vadd.s32 %v92006_v20, %v92001_v22 (stack40)
        %v92011_v27 = vshll.u32 %v92006_v20, 26 (stack45)
        %v92012_v54 = vshrl.u32 %v92006_v20, 6 (stack46)
        %v92415_v12 = vxor.u32 %v92414_v42, %v92410_v9 (stack48)
        %v91272_v23 = vmul.f32 %v91268_v40, %v148617_v52 (stack54)
        %v92807_v55 = vadd.s32 %v92804_v7, %v92799_v55 (stack40)
        %v92813_v34 = vshll.u32 %v92804_v7, 24 (stack45)
        %v92814_v61 = vshrl.u32 %v92804_v7, 8 (stack46)
        %vm148685_vm0 = vcmp.eq.f32.partialorder %v91137_v21, 1.0 (stack68)
        %v92013_v44 = vor.u32 %v92012_v54, %v92011_v27 (stack47)
        %v92418_v9 = vadd.s32 %v92415_v12, %v92410_v9 (stack40)
        %v92420_v41 = vshll.u32 %v92415_v12, 29 (stack45)
        %v92421_v24 = vshrl.u32 %v92415_v12, 3 (stack46)
        %v91276_v50 = vadd.f32 %v91272_v23, %v91173_v50 (stack53)
        %v92815_v20 = vor.u32 %v92814_v61, %v92813_v34 (stack47)
        %v93232_v60 = vor.u32 %v93231_v56, %v93230_v60 (stack47)
        %v148691_v42 = vadd.s32 %v148658_v45, %v121569_v1 (stack40)
        %v91617_v10 = vadd.f32 1.0, %v91616_v10 (stack61)
        %v92014_v7 = vxor.u32 %v92013_v44, %v92009_v22 (stack48)
        %v92422_v40 = vor.u32 %v92421_v24, %v92420_v41 (stack47)
        %v93678_v56 = vadd.s32 1, %v93674_v30 (stack40)
        %v91280_v52 = vmul.f32 %v91276_v50, %v148617_v52 (stack54)
        %vm148694_vm1 = vcmp.lt.f32.partialorder %v91619_v8, 0.0004427343 (stack62)
        %v92816_v27 = vxor.u32 %v92815_v20, %v92807_v55 (stack48)
        %v93233_v54 = vxor.u32 %v93232_v60, %v148654_v46 (stack48)
        %v92017_v22 = vadd.s32 %v92014_v7, %v92009_v22 (stack40)
        %v92023_v12 = vshll.u32 %v92014_v7, 6 (stack45)
        %v92024_v23 = vshrl.u32 %v92014_v7, 26 (stack46)
        %v92423_v34 = vxor.u32 %v92422_v40, %v92418_v9 (stack48)
        %v91284_v6 = vadd.f32 %v91280_v52, %v148647_v6 (stack53)
        %v92819_v61 = vadd.s32 %v92816_v27, %v121574_v2 (stack40)
        %v93236_v44 = vadd.s32 %v93233_v54, %v121564_v0 (stack40)
        %v93682_v32 = vsel /*vm=*/%vm93656_vm15, /*on_true_vy=*/%v93678_v56, /*on_false_vx=*/%v93674_v30 (stack44)
        %v92025_v45 = vor.u32 %v92024_v23, %v92023_v12 (stack47)
        %v92426_v30 = vadd.s32 %v92423_v34, %v92418_v9 (stack40)
        %v92428_v9 = vshll.u32 %v92423_v34, 16 (stack45)
        %v92811_v55 = vadd.s32 %v92807_v55, %v121564_v0 (stack40)
        %v91288_v25 = vmul.f32 %v91284_v6, %v148474_v25 (stack54)
        %v92429_v41 = vshrl.u32 %v92423_v34, 16 (stack46)
        %v92823_v24 = vadd.s32 2, %v92819_v61 (stack40)
        %v93240_v50 = vadd.s32 1, %v93236_v44 (stack40)
        %v121214_v20 = vpop.eup %121213 (stack64)
        %v91618_v43 = vmul.f32 %v91617_v10, %v148662_v43 (stack63)
        %v92026_v60 = vxor.u32 %v92025_v45, %v92017_v22 (stack48)
        %v93228_v46 = vadd.s32 %v148654_v46, %v121569_v1 (stack40)
        %v148712_v10 = vadd.s32 %v157664_v31, %v157070_v38 (stack40)
        %v91292_v29 = vsel /*vm=*/%vm148685_vm0, /*on_true_vy=*/%v148635_v29, /*on_false_vx=*/%v91288_v25 (stack44)
        %v91615_v21 = vmul.f32 0.6931472, %v121214_v20 (stack65)
        %v92430_v7 = vor.u32 %v92429_v41, %v92428_v9 (stack47)
        %v92827_v40 = vadd.s32 %v92823_v24, %v92811_v55 (stack40)
        %v91296_v56 = vmul.f32 1.4140625, %v91292_v29 (stack54)
        %v92029_v52 = vadd.s32 %v92026_v60, %v121574_v2 (stack40)
        %v92829_v27 = vshll.u32 %v92823_v24, 13 (stack45)
        %v92830_v54 = vshrl.u32 %v92823_v24, 19 (stack46)
        %v91621_v8 = vsel /*vm=*/%vm148694_vm1, /*on_true_vy=*/%v91618_v43, /*on_false_vx=*/%v91615_v21 (stack66)
        %v92431_v12 = vxor.u32 %v92430_v7, %v92426_v30 (stack48)
        %v93244_v23 = vadd.s32 %v93240_v50, %v93228_v46 (stack40)
        %v93697_v34 = vshll.u32 %v148691_v42, 13 (stack45)
        %v91299_v6 = vpack.c.bf16 %v157387_v11, %v91296_v56 (stack81)
        %v148722_v61 = vxor.u32 2147483648, %v91621_v8 (stack56)
        %v92033_v44 = vadd.s32 5, %v92029_v52 (stack40)
        %v93698_v45 = vshrl.u32 %v148691_v42, 19 (stack46)
        %v92021_v22 = vadd.s32 %v92017_v22, %v121564_v0 (stack40)
        %v92434_v30 = vadd.s32 %v92431_v12, %v92426_v30 (stack40)
        %v92440_v9 = vshll.u32 %v92431_v12, 24 (stack45)
        %v92441_v55 = vshrl.u32 %v92431_v12, 8 (stack46)
        %120233 = vst [vmem:[%s123356_s30 + $0x160] sm:$0xf] /*vst_source=*/%v91299_v6 (stack83)
        %vm91625_vm2 = vcmp.lt.f32.partialorder %v148722_v61, 5.0 (stack68)
        %121215 = vrsqrt.f32 %v148722_v61 (stack67)
        %v92831_v25 = vor.u32 %v92830_v54, %v92829_v27 (stack47)
        %v92035_v41 = vxor.u32 %v92033_v44, %v92021_v22 (stack48)
        %v93246_v24 = vshll.u32 %v93240_v50, 17 (stack45)
        %v93247_v50 = vshrl.u32 %v93240_v50, 15 (stack46)
        %v93687_v32 = vadd.s32 %v93682_v32, %v121574_v2 (stack40)
        %v93699_v20 = vor.u32 %v93698_v45, %v93697_v34 (stack47)
        %v148733_v43 = vsel /*vm=*/%vm91625_vm2, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v148738_v60 = vsel /*vm=*/%vm91625_vm2, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v148741_v46 = vadd.f32 -2.5, %v148722_v61 (stack53)
        %v92442_v29 = vor.u32 %v92441_v55, %v92440_v9 (stack47)
        %v148746_v21 = vsel /*vm=*/%vm91625_vm2, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v148751_v7 = vsel /*vm=*/%vm91625_vm2, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v92036_v56 = vand.u32.u8 255, %v92035_v41 (stack49)
        %v92832_v52 = vxor.u32 %v92831_v25, %v92827_v40 (stack48)
        %v92438_v27 = vadd.s32 %v92434_v30, %v121569_v1 (stack40)
        %v92443_v54 = vxor.u32 %v92442_v29, %v92434_v30 (stack48)
        %v93248_v8 = vor.u32 %v93247_v50, %v93246_v24 (stack47)
        %v93695_v42 = vadd.s32 %v148691_v42, %v93687_v32 (stack40)
        %v92037_v12 = vand.u32 65535, %v92036_v56 (stack50)
        %v92835_v40 = vadd.s32 %v92832_v52, %v92827_v40 (stack40)
        %v92837_v34 = vshll.u32 %v92832_v52, 15 (stack45)
        %v92838_v6 = vshrl.u32 %v92832_v52, 17 (stack46)
        %v91662_v44 = vsel /*vm=*/%vm91625_vm2, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %vm91670_vm3 = vcmp.eq.f32.partialorder %v148722_v61, inf (stack70)
        %v92446_v45 = vadd.s32 %v92443_v54, %v121564_v0 (stack40)
        %v93249_v22 = vxor.u32 %v93248_v8, %v93244_v23 (stack48)
        %v93700_v30 = vxor.u32 %v93699_v20, %v93695_v42 (stack48)
        %vm91672_vm4 = vcmp.eq.f32.partialorder %v148722_v61, 0.0 (stack71)
        %v92038_v9 = vshrl.u32 %v92037_v12, 1 (stack51)
        %v92839_v55 = vor.u32 %v92838_v6, %v92837_v34 (stack47)
        %vm94122_vm5 = vcmp.lt.u32.totalorder %v148712_v10, %v157070_v38 (stack43)
        %v94127_v25 = vadd.s32 %v157667_v26, %v157076_v35 (stack40)
        %v92450_v41 = vadd.s32 4, %v92446_v45 (stack40)
        %v93252_v23 = vadd.s32 %v93249_v22, %v93244_v23 (stack40)
        %v93254_v24 = vshll.u32 %v93249_v22, 29 (stack45)
        %v93255_v50 = vshrl.u32 %v93249_v22, 3 (stack46)
        %v92039_v32 = vor.u32 16256, %v92038_v9 (stack47)
        %v92840_v20 = vxor.u32 %v92839_v55, %v92835_v40 (stack48)
        %v93703_v29 = vadd.s32 %v93700_v30, %v93695_v42 (stack40)
        %v93705_v56 = vshll.u32 %v93700_v30, 15 (stack45)
        %v92454_v52 = vadd.s32 %v92450_v41, %v92438_v27 (stack40)
        %v92456_v27 = vshll.u32 %v92450_v41, 13 (stack45)
        %v92457_v54 = vshrl.u32 %v92450_v41, 19 (stack46)
        %v93256_v8 = vor.u32 %v93255_v50, %v93254_v24 (stack47)
        %v92040_v42 = vand.u32.u16 65535, %v92039_v32 (stack52)
        %v92843_v12 = vadd.s32 %v92840_v20, %v92835_v40 (stack40)
        %v92845_v40 = vshll.u32 %v92840_v20, 26 (stack45)
        %v92846_v34 = vshrl.u32 %v92840_v20, 6 (stack46)
        %v121216_v6 = vpop.eup %121215 (stack73)
        %v91673_v45 = vand.u32 2147483648, %v148722_v61 (stack72)
        %v92458_v22 = vor.u32 %v92457_v54, %v92456_v27 (stack47)
        %v93257_v9 = vxor.u32 %v93256_v8, %v93252_v23 (stack48)
        %v93706_v30 = vshrl.u32 %v93700_v30, 17 (stack46)
        %v91669_v55 = vmul.f32 %v121216_v6, %v148722_v61 (stack74)
        %v120236_v41 = vadd.low.f32.bf16 -1.0, %v92040_v42 (stack53)
        %v92847_v24 = vor.u32 %v92846_v34, %v92845_v40 (stack47)
        %v94131_v50 = vadd.s32 1, %v94127_v25 (stack40)
        %v92459_v32 = vxor.u32 %v92458_v22, %v92454_v52 (stack48)
        %v93260_v23 = vadd.s32 %v93257_v9, %v93252_v23 (stack40)
        %v93262_v20 = vshll.u32 %v93257_v9, 16 (stack45)
        %v93263_v27 = vshrl.u32 %v93257_v9, 16 (stack46)
        %v91671_v54 = vsel /*vm=*/%vm91670_vm3, /*on_true_vy=*/%v148722_v61, /*on_false_vx=*/%v91669_v55 (stack75)
        %v92049_v8 = vmul.f32 2.0, %v120236_v41 (stack54)
        %v92848_v42 = vxor.u32 %v92847_v24, %v92843_v12 (stack48)
        %v93707_v56 = vor.u32 %v93706_v30, %v93705_v56 (stack47)
        %v91674_v40 = vsel /*vm=*/%vm91672_vm4, /*on_true_vy=*/%v91673_v45, /*on_false_vx=*/%v91671_v54 (stack76)
        %v92462_v52 = vadd.s32 %v92459_v32, %v92454_v52 (stack40)
        %v92464_v34 = vshll.u32 %v92459_v32, 15 (stack45)
        %v92465_v6 = vshrl.u32 %v92459_v32, 17 (stack46)
        %v91677_v45 = vadd.f32 -3.0, %v91674_v40 (stack53)
        %v92053_v22 = vadd.f32 -0.99609375, %v92049_v8 (stack53)
        %v92851_v12 = vadd.s32 %v92848_v42, %v92843_v12 (stack40)
        %v92857_v9 = vshll.u32 %v92848_v42, 6 (stack45)
        %v92466_v30 = vor.u32 %v92465_v6, %v92464_v34 (stack47)
        %v92858_v55 = vshrl.u32 %v92848_v42, 26 (stack46)
        %v93264_v41 = vor.u32 %v93263_v27, %v93262_v20 (stack47)
        %v93708_v24 = vxor.u32 %v93707_v56, %v93703_v29 (stack48)
        %v148775_v46 = vsel /*vm=*/%vm91625_vm2, /*on_true_vy=*/%v148741_v46, /*on_false_vx=*/%v91677_v45 (stack44)
        %v148777_v32 = vmax.f32 %v92053_v22, -0.99609375 (stack55)
        %v94113_v20 = vadd.s32 %v148712_v10, %v122657_v58 (stack40)
        %v94135_v25 = vsel /*vm=*/%vm94122_vm5, /*on_true_vy=*/%v94131_v50, /*on_false_vx=*/%v94127_v25 (stack44)
        %v91685_v44 = vmul.f32 %v148775_v46, %v91662_v44 (stack54)
        %v92467_v50 = vxor.u32 %v92466_v30, %v92462_v52 (stack48)
        %v92859_v27 = vor.u32 %v92858_v55, %v92857_v9 (stack47)
        %v93265_v54 = vxor.u32 %v93264_v41, %v93260_v23 (stack48)
        %v91654_v8 = vsel /*vm=*/%vm91625_vm2, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v91658_v42 = vsel /*vm=*/%vm91625_vm2, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v92069_v56 = vxor.u32 2147483648, %v148777_v32 (stack56)
        %v148792_v29 = vadd.s32 %v93708_v24, %v93703_v29 (stack40)
        %v91689_v40 = vadd.f32 %v91685_v44, %v91658_v42 (stack53)
        %v92470_v52 = vadd.s32 %v92467_v50, %v92462_v52 (stack40)
        %v92472_v34 = vshll.u32 %v92467_v50, 26 (stack45)
        %v92473_v6 = vshrl.u32 %v92467_v50, 6 (stack46)
        %v148795_v45 = vmul.f32 %v92069_v56, %v148777_v32 (stack54)
        %v92860_v22 = vxor.u32 %v92859_v27, %v92851_v12 (stack48)
        %v93268_v23 = vadd.s32 %v93265_v54, %v93260_v23 (stack40)
        %vm94117_vm6 = vcmp.lt.u32.totalorder %v94113_v20, %v148712_v10 (stack43)
        %v91693_v9 = vmul.f32 %v91689_v40, %v148775_v46 (stack54)
        %v92474_v30 = vor.u32 %v92473_v6, %v92472_v34 (stack47)
        %v93274_v55 = vshll.u32 %v93265_v54, 24 (stack45)
        %v93275_v41 = vshrl.u32 %v93265_v54, 8 (stack46)
        %v92074_v44 = vadd.f32 1.0, %v148795_v45 (stack57)
        %v92077_v50 = vmul.f32 -0.5, %v148795_v45 (stack59)
        %v92863_v27 = vadd.s32 %v92860_v22, %v121569_v1 (stack40)
        %v94152_v54 = vadd.s32 %v94113_v20, %v121569_v1 (stack40)
        %v91697_v8 = vadd.f32 %v91693_v9, %v91654_v8 (stack53)
        %v92475_v42 = vxor.u32 %v92474_v30, %v92470_v52 (stack48)
        %v92855_v12 = vadd.s32 %v92851_v12, %v121574_v2 (stack40)
        %v93276_v56 = vor.u32 %v93275_v41, %v93274_v55 (stack47)
        %121217 = vlog2.f32 %v92074_v44 (stack58)
        %v92080_v40 = vand.u32 2147483647, %v148795_v45 (stack60)
        %v92867_v34 = vadd.s32 3, %v92863_v27 (stack40)
        %v93272_v6 = vadd.s32 %v93268_v23, %v121564_v0 (stack40)
        %v91701_v22 = vmul.f32 %v91697_v8, %v148775_v46 (stack54)
        %v92478_v52 = vadd.s32 %v92475_v42, %v92470_v52 (stack40)
        %v92484_v9 = vshll.u32 %v92475_v42, 6 (stack45)
        %v92485_v30 = vshrl.u32 %v92475_v42, 26 (stack46)
        %v92078_v55 = vadd.f32 1.0, %v92077_v50 (stack61)
        %v92871_v41 = vadd.s32 %v92867_v34, %v92855_v12 (stack40)
        %v92873_v44 = vshll.u32 %v92867_v34, 17 (stack45)
        %v92874_v50 = vshrl.u32 %v92867_v34, 15 (stack46)
        %v91705_v7 = vadd.f32 %v91701_v22, %v148751_v7 (stack53)
        %v92482_v27 = vadd.s32 %v92478_v52, %v121564_v0 (stack40)
        %v92486_v8 = vor.u32 %v92485_v30, %v92484_v9 (stack47)
        %v93277_v23 = vxor.u32 %v93276_v56, %v93268_v23 (stack48)
        %v92875_v42 = vor.u32 %v92874_v50, %v92873_v44 (stack47)
        %v93713_v12 = vshll.u32 %v93708_v24, 26 (stack45)
        %v93714_v24 = vshrl.u32 %v93708_v24, 6 (stack46)
        %v94139_v56 = vadd.s32 1, %v94135_v25 (stack40)
        %v91709_v34 = vmul.f32 %v91705_v7, %v148775_v46 (stack54)
        %v92487_v22 = vxor.u32 %v92486_v8, %v92478_v52 (stack48)
        %v93280_v52 = vadd.s32 %v93277_v23, %v121574_v2 (stack40)
        %v94158_v9 = vshll.u32 %v94152_v54, 13 (stack45)
        %v92876_v30 = vxor.u32 %v92875_v42, %v92871_v41 (stack48)
        %v93715_v44 = vor.u32 %v93714_v24, %v93713_v12 (stack47)
        %v94143_v10 = vsel /*vm=*/%vm94117_vm6, /*on_true_vy=*/%v94139_v56, /*on_false_vx=*/%v94135_v25 (stack44)
        %v94159_v20 = vshrl.u32 %v94152_v54, 19 (stack46)
        %v91713_v21 = vadd.f32 %v91709_v34, %v148746_v21 (stack53)
        %v92490_v25 = vadd.s32 %v92487_v22, %v121574_v2 (stack40)
        %v93284_v50 = vadd.s32 2, %v93280_v52 (stack40)
        %v94148_v7 = vadd.s32 %v94143_v10, %v121574_v2 (stack40)
        %v92879_v41 = vadd.s32 %v92876_v30, %v92871_v41 (stack40)
        %v92881_v8 = vshll.u32 %v92876_v30, 29 (stack45)
        %v92882_v23 = vshrl.u32 %v92876_v30, 3 (stack46)
        %v93716_v42 = vxor.u32 %v93715_v44, %v148792_v29 (stack48)
        %v91717_v12 = vmul.f32 %v91713_v21, %v148775_v46 (stack54)
        %v92494_v24 = vadd.s32 5, %v92490_v25 (stack40)
        %v93288_v6 = vadd.s32 %v93284_v50, %v93272_v6 (stack40)
        %v93290_v56 = vshll.u32 %v93284_v50, 13 (stack45)
        %v92883_v34 = vor.u32 %v92882_v23, %v92881_v8 (stack47)
        %v93291_v22 = vshrl.u32 %v93284_v50, 19 (stack46)
        %v93719_v29 = vadd.s32 %v93716_v42, %v148792_v29 (stack40)
        %v93725_v52 = vshll.u32 %v93716_v42, 6 (stack45)
        %v91721_v60 = vadd.f32 %v91717_v12, %v148738_v60 (stack53)
        %v92496_v27 = vxor.u32 %v92494_v24, %v92482_v27 (stack48)
        %v93726_v30 = vshrl.u32 %v93716_v42, 26 (stack46)
        %v94156_v54 = vadd.s32 %v94152_v54, %v94148_v7 (stack40)
        %v92079_v45 = vmul.f32 %v92078_v55, %v148795_v45 (stack63)
        %v92884_v55 = vxor.u32 %v92883_v34, %v92879_v41 (stack48)
        %v93292_v44 = vor.u32 %v93291_v22, %v93290_v56 (stack47)
        %v94160_v9 = vor.u32 %v94159_v20, %v94158_v9 (stack47)
        %v121218_v10 = vpop.eup %121217 (stack64)
        %v91725_v20 = vmul.f32 %v91721_v60, %v148775_v46 (stack54)
        %v92497_v21 = vand.u32.u8 255, %v92496_v27 (stack49)
        %v93727_v25 = vor.u32 %v93726_v30, %v93725_v52 (stack47)
        %v148824_v50 = vadd.s32 %v157664_v31, %v157077_v51 (stack40)
        %v92076_v7 = vmul.f32 0.6931472, %v121218_v10 (stack65)
        %v92887_v41 = vadd.s32 %v92884_v55, %v92879_v41 (stack40)
        %v92889_v8 = vshll.u32 %v92884_v55, 16 (stack45)
        %v92890_v23 = vshrl.u32 %v92884_v55, 16 (stack46)
        %v91729_v43 = vadd.f32 %v91725_v20, %v148733_v43 (stack53)
        %vm92081_vm7 = vcmp.lt.f32.partialorder %v92080_v40, 0.0004427343 (stack62)
        %v93293_v40 = vxor.u32 %v93292_v44, %v93288_v6 (stack48)
        %v93728_v42 = vxor.u32 %v93727_v25, %v93719_v29 (stack48)
        %v92082_v12 = vsel /*vm=*/%vm92081_vm7, /*on_true_vy=*/%v92079_v45, /*on_false_vx=*/%v92076_v7 (stack66)
        %v92498_v24 = vand.u32 65535, %v92497_v21 (stack50)
        %v92891_v56 = vor.u32 %v92890_v23, %v92889_v8 (stack47)
        %v94161_v34 = vxor.u32 %v94160_v9, %v94156_v54 (stack48)
        %v91598_v22 = vand.u32 2147483647, %v148642_v53 (stack77)
        %v91733_v52 = vmul.f32 %v91729_v43, %v148775_v46 (stack54)
        %v148829_v60 = vxor.u32 2147483648, %v92082_v12 (stack56)
        %v93296_v6 = vadd.s32 %v93293_v40, %v93288_v6 (stack40)
        %v91634_v27 = vsel /*vm=*/%vm91625_vm2, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v92892_v30 = vxor.u32 %v92891_v56, %v92887_v41 (stack48)
        %v91737_v45 = vadd.f32 %v91733_v52, %v91634_v27 (stack53)
        %121219 = vrsqrt.f32 %v148829_v60 (stack67)
        %v92499_v55 = vshrl.u32 %v92498_v24, 1 (stack51)
        %v92895_v44 = vadd.s32 %v92892_v30, %v92887_v41 (stack40)
        %v93298_v9 = vshll.u32 %v93293_v40, 15 (stack45)
        %v93299_v10 = vshrl.u32 %v93293_v40, 17 (stack46)
        %vm148835_vm8 = vcmp.eq.f32.partialorder %v91598_v22, 1.0 (stack68)
        %v91606_v21 = vmul.f32 inf, %v148642_v53 (stack54)
        %v91741_v46 = vmul.f32 %v91737_v45, %v148775_v46 (stack54)
        %v93731_v25 = vadd.s32 %v93728_v42, %v121564_v0 (stack40)
        %v91630_v61 = vsel /*vm=*/%vm91625_vm2, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v92059_v7 = vand.u32 2147483647, %v148777_v32 (stack77)
        %v148847_v41 = vmul.f32 inf, %v148777_v32 (stack54)
        %v93723_v29 = vadd.s32 %v93719_v29, %v121569_v1 (stack40)
        %v91745_v8 = vadd.f32 %v91741_v46, %v91630_v61 (stack53)
        %v148851_v23 = vadd.f32 -2.5, %v148829_v60 (stack53)
        %v92899_v43 = vadd.s32 %v92895_v44, %v121569_v1 (stack40)
        %v148856_v40 = vadd.s32 %v148824_v50, %v122657_v58 (stack40)
        %v92500_v42 = vor.u32 16256, %v92499_v55 (stack47)
        %v92901_v12 = vshll.u32 %v92892_v30, 24 (stack45)
        %v92902_v24 = vshrl.u32 %v92892_v30, 8 (stack46)
        %v93300_v56 = vor.u32 %v93299_v10, %v93298_v9 (stack47)
        %v91749_v53 = vmul.f32 %v91745_v8, %v148642_v53 (stack54)
        %vm92086_vm9 = vcmp.lt.f32.partialorder %v148829_v60, 5.0 (stack68)
        %v93735_v22 = vadd.s32 1, %v93731_v25 (stack40)
        %v94164_v54 = vadd.s32 %v94161_v34, %v94156_v54 (stack40)
        %v94166_v52 = vshll.u32 %v94161_v34, 15 (stack45)
        %v92501_v27 = vand.u32.u16 65535, %v92500_v42 (stack52)
        %v92903_v30 = vor.u32 %v92902_v24, %v92901_v12 (stack47)
        %v93301_v45 = vxor.u32 %v93300_v56, %v93296_v6 (stack48)
        %v94167_v34 = vshrl.u32 %v94161_v34, 17 (stack46)
        %v91753_v55 = vsel /*vm=*/%vm148835_vm8, /*on_true_vy=*/%v91606_v21, /*on_false_vx=*/%v91749_v53 (stack44)
        %v93739_v9 = vadd.s32 %v93735_v22, %v93723_v29 (stack40)
        %v93741_v10 = vshll.u32 %v93735_v22, 17 (stack45)
        %v93742_v20 = vshrl.u32 %v93735_v22, 15 (stack46)
        %v91757_v21 = vmul.f32 1.4140625, %v91753_v55 (stack54)
        %v120238_v46 = vadd.low.f32.bf16 -1.0, %v92501_v27 (stack53)
        %v92904_v44 = vxor.u32 %v92903_v30, %v92895_v44 (stack48)
        %v93304_v6 = vadd.s32 %v93301_v45, %v93296_v6 (stack40)
        %v93306_v25 = vshll.u32 %v93301_v45, 26 (stack45)
        %v93307_v61 = vshrl.u32 %v93301_v45, 6 (stack46)
        %v93743_v29 = vor.u32 %v93742_v20, %v93741_v10 (stack47)
        %v94168_v8 = vor.u32 %v94167_v34, %v94166_v52 (stack47)
        %v91760_v42 = vpack.c.bf16 %v157387_v11, %v91757_v21 (stack81)
        %vm92131_vm10 = vcmp.eq.f32.partialorder %v148829_v60, inf (stack70)
        %v92510_v12 = vmul.f32 2.0, %v120238_v46 (stack54)
        %v92907_v24 = vadd.s32 %v92904_v44, %v121564_v0 (stack40)
        %v93308_v56 = vor.u32 %v93307_v61, %v93306_v25 (stack47)
        %v93744_v53 = vxor.u32 %v93743_v29, %v93739_v9 (stack48)
        %v148865_v22 = vxor.u32 %v94168_v8, %v94164_v54 (stack48)
        %vm94583_vm11 = vcmp.lt.u32.totalorder %v148824_v50, %v157077_v51 (stack43)
        %v121220_v52 = vpop.eup %121219 (stack73)
        %120235 = vst [vmem:[%s123356_s30 + $0x1e0] sm:$0xf] /*vst_source=*/%v91760_v42 (stack83)
        %vm92133_vm12 = vcmp.eq.f32.partialorder %v148829_v60, 0.0 (stack71)
        %v92514_v27 = vadd.f32 -0.99609375, %v92510_v12 (stack53)
        %v92911_v30 = vadd.s32 4, %v92907_v24 (stack40)
        %v94588_v45 = vadd.s32 %v157667_v26, %v157078_v48 (stack40)
        %v92130_v34 = vmul.f32 %v121220_v52, %v148829_v60 (stack74)
        %v92134_v55 = vand.u32 2147483648, %v148829_v60 (stack72)
        %v93309_v10 = vxor.u32 %v93308_v56, %v93304_v6 (stack48)
        %v93747_v9 = vadd.s32 %v93744_v53, %v93739_v9 (stack40)
        %v148875_v20 = vmax.f32 %v92514_v27, -0.99609375 (stack55)
        %v92915_v43 = vadd.s32 %v92911_v30, %v92899_v43 (stack40)
        %v92917_v21 = vshll.u32 %v92911_v30, 13 (stack45)
        %v92918_v46 = vshrl.u32 %v92911_v30, 19 (stack46)
        %v92132_v44 = vsel /*vm=*/%vm92131_vm10, /*on_true_vy=*/%v148829_v60, /*on_false_vx=*/%v92130_v34 (stack75)
        %v93312_v6 = vadd.s32 %v93309_v10, %v93304_v6 (stack40)
        %v93318_v25 = vshll.u32 %v93309_v10, 6 (stack45)
        %v93319_v61 = vshrl.u32 %v93309_v10, 26 (stack46)
        %v148883_v29 = vsel /*vm=*/%vm92086_vm9, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v148888_v8 = vsel /*vm=*/%vm92086_vm9, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v92135_v42 = vsel /*vm=*/%vm92133_vm12, /*on_true_vy=*/%v92134_v55, /*on_false_vx=*/%v92132_v44 (stack76)
        %v92530_v12 = vxor.u32 2147483648, %v148875_v20 (stack56)
        %v148896_v24 = vsel /*vm=*/%vm92086_vm9, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v92138_v56 = vadd.f32 -3.0, %v92135_v42 (stack53)
        %v92919_v52 = vor.u32 %v92918_v46, %v92917_v21 (stack47)
        %v93320_v27 = vor.u32 %v93319_v61, %v93318_v25 (stack47)
        %v92123_v30 = vsel /*vm=*/%vm92086_vm9, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v148902_v34 = vmul.f32 %v92530_v12, %v148875_v20 (stack54)
        %v93749_v55 = vshll.u32 %v93744_v53, 29 (stack45)
        %v94172_v54 = vadd.s32 %v148865_v22, %v94164_v54 (stack40)
        %v148908_v23 = vsel /*vm=*/%vm92086_vm9, /*on_true_vy=*/%v148851_v23, /*on_false_vx=*/%v92138_v56 (stack44)
        %v92920_v10 = vxor.u32 %v92919_v52, %v92915_v43 (stack48)
        %v93321_v21 = vxor.u32 %v93320_v27, %v93312_v6 (stack48)
        %v93750_v53 = vshrl.u32 %v93744_v53, 3 (stack46)
        %v92111_v46 = vsel /*vm=*/%vm92086_vm9, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v92119_v44 = vsel /*vm=*/%vm92086_vm9, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v92146_v25 = vmul.f32 %v148908_v23, %v92123_v30 (stack54)
        %v92535_v61 = vadd.f32 1.0, %v148902_v34 (stack57)
        %v92923_v43 = vadd.s32 %v92920_v10, %v92915_v43 (stack40)
        %v92925_v42 = vshll.u32 %v92920_v10, 15 (stack45)
        %v92926_v12 = vshrl.u32 %v92920_v10, 17 (stack46)
        %v93324_v56 = vadd.s32 %v93321_v21, %v121569_v1 (stack40)
        %v92150_v52 = vadd.f32 %v92146_v25, %v92119_v44 (stack53)
        %121221 = vlog2.f32 %v92535_v61 (stack58)
        %v93316_v6 = vadd.s32 %v93312_v6, %v121574_v2 (stack40)
        %v94174_v27 = vshll.u32 %v148865_v22, 26 (stack45)
        %v92927_v30 = vor.u32 %v92926_v12, %v92925_v42 (stack47)
        %v93328_v10 = vadd.s32 3, %v93324_v56 (stack40)
        %v93751_v55 = vor.u32 %v93750_v53, %v93749_v55 (stack47)
        %v94175_v22 = vshrl.u32 %v148865_v22, 6 (stack46)
        %v92115_v21 = vsel /*vm=*/%vm92086_vm9, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v92154_v53 = vmul.f32 %v92150_v52, %v148908_v23 (stack54)
        %v92538_v44 = vmul.f32 -0.5, %v148902_v34 (stack59)
        %v94592_v25 = vadd.s32 1, %v94588_v45 (stack40)
        %v92928_v61 = vxor.u32 %v92927_v30, %v92923_v43 (stack48)
        %v93332_v42 = vadd.s32 %v93328_v10, %v93316_v6 (stack40)
        %v93334_v12 = vshll.u32 %v93328_v10, 17 (stack45)
        %v93335_v56 = vshrl.u32 %v93328_v10, 15 (stack46)
        %v92158_v52 = vadd.f32 %v92154_v53, %v92115_v21 (stack53)
        %v93752_v6 = vxor.u32 %v93751_v55, %v93747_v9 (stack48)
        %v94176_v27 = vor.u32 %v94175_v22, %v94174_v27 (stack47)
        %v94596_v45 = vsel /*vm=*/%vm94583_vm11, /*on_true_vy=*/%v94592_v25, /*on_false_vx=*/%v94588_v45 (stack44)
        %v92931_v43 = vadd.s32 %v92928_v61, %v92923_v43 (stack40)
        %v92933_v30 = vshll.u32 %v92928_v61, 26 (stack45)
        %v92934_v10 = vshrl.u32 %v92928_v61, 6 (stack46)
        %v93336_v55 = vor.u32 %v93335_v56, %v93334_v12 (stack47)
        %v92162_v22 = vmul.f32 %v92158_v52, %v148908_v23 (stack54)
        %v93755_v9 = vadd.s32 %v93752_v6, %v93747_v9 (stack40)
        %v93757_v21 = vshll.u32 %v93752_v6, 16 (stack45)
        %v93758_v53 = vshrl.u32 %v93752_v6, 16 (stack46)
        %vm94578_vm13 = vcmp.lt.u32.totalorder %v148856_v40, %v148824_v50 (stack43)
        %v92935_v25 = vor.u32 %v92934_v10, %v92933_v30 (stack47)
        %v93337_v61 = vxor.u32 %v93336_v55, %v93332_v42 (stack48)
        %v94177_v12 = vxor.u32 %v94176_v27, %v94172_v54 (stack48)
        %v148935_v56 = vadd.s32 %v148856_v40, %v121569_v1 (stack40)
        %v92166_v46 = vadd.f32 %v92162_v22, %v92111_v46 (stack53)
        %v92541_v52 = vand.u32 2147483647, %v148902_v34 (stack60)
        %v93759_v6 = vor.u32 %v93758_v53, %v93757_v21 (stack47)
        %v148940_v27 = vadd.s32 %v157664_v31, %v157079_v39 (stack40)
        %v92936_v30 = vxor.u32 %v92935_v25, %v92931_v43 (stack48)
        %v93340_v42 = vadd.s32 %v93337_v61, %v93332_v42 (stack40)
        %v93342_v10 = vshll.u32 %v93337_v61, 29 (stack45)
        %v93343_v55 = vshrl.u32 %v93337_v61, 3 (stack46)
        %v92170_v22 = vmul.f32 %v92166_v46, %v148908_v23 (stack54)
        %v92539_v44 = vadd.f32 1.0, %v92538_v44 (stack61)
        %v93760_v21 = vxor.u32 %v93759_v6, %v93755_v9 (stack48)
        %v148943_v54 = vadd.s32 %v94177_v12, %v94172_v54 (stack40)
        %v92939_v43 = vadd.s32 %v92936_v30, %v92931_v43 (stack40)
        %v92945_v53 = vshll.u32 %v92936_v30, 6 (stack45)
        %v92946_v25 = vshrl.u32 %v92936_v30, 26 (stack46)
        %v93344_v61 = vor.u32 %v93343_v55, %v93342_v10 (stack47)
        %v92174_v24 = vadd.f32 %v92170_v22, %v148896_v24 (stack53)
        %v93763_v9 = vadd.s32 %v93760_v21, %v93755_v9 (stack40)
        %v93769_v46 = vshll.u32 %v93760_v21, 24 (stack45)
        %v93770_v6 = vshrl.u32 %v93760_v21, 8 (stack46)
        %v121222_v30 = vpop.eup %121221 (stack64)
        %vm148946_vm14 = vcmp.lt.f32.partialorder %v92541_v52, 0.0004427343 (stack62)
        %v92947_v10 = vor.u32 %v92946_v25, %v92945_v53 (stack47)
        %v93345_v55 = vxor.u32 %v93344_v61, %v93340_v42 (stack48)
        %v94600_v22 = vadd.s32 1, %v94596_v45 (stack40)
        %v92178_v21 = vmul.f32 %v92174_v24, %v148908_v23 (stack54)
        %v92537_v53 = vmul.f32 0.6931472, %v121222_v30 (stack65)
        %v92540_v34 = vmul.f32 %v92539_v44, %v148902_v34 (stack63)
        %v93771_v44 = vor.u32 %v93770_v6, %v93769_v46 (stack47)
        %v92948_v25 = vxor.u32 %v92947_v10, %v92939_v43 (stack48)
        %v93348_v42 = vadd.s32 %v93345_v55, %v93340_v42 (stack40)
        %v93350_v61 = vshll.u32 %v93345_v55, 16 (stack45)
        %v93351_v24 = vshrl.u32 %v93345_v55, 16 (stack46)
        %v92182_v8 = vadd.f32 %v92178_v21, %v148888_v8 (stack53)
        %v92543_v46 = vsel /*vm=*/%vm148946_vm14, /*on_true_vy=*/%v92540_v34, /*on_false_vx=*/%v92537_v53 (stack66)
        %v93772_v6 = vxor.u32 %v93771_v44, %v93763_v9 (stack48)
        %v94186_v30 = vshll.u32 %v94177_v12, 6 (stack45)
        %v148955_v52 = vxor.u32 2147483648, %v92543_v46 (stack56)
        %v93352_v10 = vor.u32 %v93351_v24, %v93350_v61 (stack47)
        %v94187_v12 = vshrl.u32 %v94177_v12, 26 (stack46)
        %v94604_v50 = vsel /*vm=*/%vm94578_vm13, /*on_true_vy=*/%v94600_v22, /*on_false_vx=*/%v94596_v45 (stack44)
        %v92095_v40 = vsel /*vm=*/%vm92086_vm9, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v92099_v60 = vsel /*vm=*/%vm92086_vm9, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v92186_v45 = vmul.f32 %v92182_v8, %v148908_v23 (stack54)
        %v92520_v55 = vand.u32 2147483647, %v148875_v20 (stack77)
        %vm92547_vm15 = vcmp.lt.f32.partialorder %v148955_v52, 5.0 (stack68)
        %121223 = vrsqrt.f32 %v148955_v52 (stack67)
        %v92951_v22 = vadd.s32 %v92948_v25, %v121574_v2 (stack40)
        %v94619_v21 = vshll.u32 %v148935_v56, 13 (stack45)
        %v92190_v53 = vadd.f32 %v92186_v45, %v92099_v60 (stack53)
        %v92943_v43 = vadd.s32 %v92939_v43, %v121564_v0 (stack40)
        %v93775_v34 = vadd.s32 %v93772_v6, %v121574_v2 (stack40)
        %v94620_v44 = vshrl.u32 %v148935_v56, 19 (stack46)
        %v93353_v25 = vxor.u32 %v93352_v10, %v93348_v42 (stack48)
        %v94184_v61 = vadd.s32 %v148943_v54, %v121569_v1 (stack40)
        %v94188_v24 = vor.u32 %v94187_v12, %v94186_v30 (stack47)
        %v94609_v8 = vadd.s32 %v94604_v50, %v121574_v2 (stack40)
        %v92194_v46 = vmul.f32 %v92190_v53, %v148908_v23 (stack54)
        %v148982_v6 = vsel /*vm=*/%vm92547_vm15, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v148985_v30 = vadd.f32 -2.5, %v148955_v52 (stack53)
        %v93767_v9 = vadd.s32 %v93763_v9, %v121564_v0 (stack40)
        %vm148990_vm0 = vcmp.eq.f32.partialorder %v92059_v7, 1.0 (stack68)
        %v148997_v10 = vsel /*vm=*/%vm92547_vm15, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v149002_v12 = vsel /*vm=*/%vm92547_vm15, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v92955_v50 = vadd.s32 5, %v92951_v22 (stack40)
        %v93356_v42 = vadd.s32 %v93353_v25, %v93348_v42 (stack40)
        %v92198_v40 = vadd.f32 %v92194_v46, %v92095_v40 (stack53)
        %v93362_v60 = vshll.u32 %v93353_v25, 24 (stack45)
        %v93363_v45 = vshrl.u32 %v93353_v25, 8 (stack46)
        %v93779_v22 = vadd.s32 2, %v93775_v34 (stack40)
        %v149007_v53 = vsel /*vm=*/%vm92547_vm15, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v92957_v43 = vxor.u32 %v92955_v50, %v92943_v43 (stack48)
        %v94189_v54 = vxor.u32 %v94188_v24, %v148943_v54 (stack48)
        %v94617_v56 = vadd.s32 %v148935_v56, %v94609_v8 (stack40)
        %v92202_v23 = vmul.f32 %v92198_v40, %v148908_v23 (stack54)
        %vm92592_vm1 = vcmp.eq.f32.partialorder %v148955_v52, inf (stack70)
        %v93364_v34 = vor.u32 %v93363_v45, %v93362_v60 (stack47)
        %v93783_v25 = vadd.s32 %v93779_v22, %v93767_v9 (stack40)
        %v93785_v24 = vshll.u32 %v93779_v22, 13 (stack45)
        %vm92594_vm2 = vcmp.eq.f32.partialorder %v148955_v52, 0.0 (stack71)
        %v92958_v8 = vand.u32.u8 255, %v92957_v43 (stack49)
        %v93786_v46 = vshrl.u32 %v93779_v22, 19 (stack46)
        %v94192_v9 = vadd.s32 %v94189_v54, %v121564_v0 (stack40)
        %v94621_v21 = vor.u32 %v94620_v44, %v94619_v21 (stack47)
        %v92206_v29 = vadd.f32 %v92202_v23, %v148883_v29 (stack53)
        %v92595_v44 = vand.u32 2147483648, %v148955_v52 (stack72)
        %v93365_v50 = vxor.u32 %v93364_v34, %v93356_v42 (stack48)
        %vm95044_vm3 = vcmp.lt.u32.totalorder %v148940_v27, %v157079_v39 (stack43)
        %v92959_v40 = vand.u32 65535, %v92958_v8 (stack50)
        %v93787_v60 = vor.u32 %v93786_v46, %v93785_v24 (stack47)
        %v94196_v45 = vadd.s32 1, %v94192_v9 (stack40)
        %v94622_v22 = vxor.u32 %v94621_v21, %v94617_v56 (stack48)
        %v92210_v32 = vmul.f32 %v92206_v29, %v148777_v32 (stack54)
        %v93360_v42 = vadd.s32 %v93356_v42, %v121569_v1 (stack40)
        %v93368_v43 = vadd.s32 %v93365_v50, %v121564_v0 (stack40)
        %v95049_v54 = vadd.s32 %v157667_v26, %v157082_v49 (stack40)
        %v92960_v23 = vshrl.u32 %v92959_v40, 1 (stack51)
        %v93788_v34 = vxor.u32 %v93787_v60, %v93783_v25 (stack48)
        %v94200_v61 = vadd.s32 %v94196_v45, %v94184_v61 (stack40)
        %v94202_v24 = vshll.u32 %v94196_v45, 17 (stack45)
        %v121224_v8 = vpop.eup %121223 (stack73)
        %v92214_v41 = vsel /*vm=*/%vm148990_vm0, /*on_true_vy=*/%v148847_v41, /*on_false_vx=*/%v92210_v32 (stack44)
        %v93372_v7 = vadd.s32 4, %v93368_v43 (stack40)
        %v94203_v46 = vshrl.u32 %v94196_v45, 15 (stack46)
        %v149027_v56 = vadd.s32 %v94622_v22, %v94617_v56 (stack40)
        %v92218_v9 = vmul.f32 1.4140625, %v92214_v41 (stack54)
        %v92591_v21 = vmul.f32 %v121224_v8, %v148955_v52 (stack74)
        %v92961_v29 = vor.u32 16256, %v92960_v23 (stack47)
        %v93791_v25 = vadd.s32 %v93788_v34, %v93783_v25 (stack40)
        %v93376_v50 = vadd.s32 %v93372_v7, %v93360_v42 (stack40)
        %v93378_v40 = vshll.u32 %v93372_v7, 13 (stack45)
        %v93379_v60 = vshrl.u32 %v93372_v7, 19 (stack46)
        %v93793_v45 = vshll.u32 %v93788_v34, 15 (stack45)
        %v92221_v32 = vpack.c.bf16 %v157387_v11, %v92218_v9 (stack81)
        %v92593_v42 = vsel /*vm=*/%vm92592_vm1, /*on_true_vy=*/%v148955_v52, /*on_false_vx=*/%v92591_v21 (stack75)
        %v92962_v43 = vand.u32.u16 65535, %v92961_v29 (stack52)
        %v93794_v23 = vshrl.u32 %v93788_v34, 17 (stack46)
        %v92596_v44 = vsel /*vm=*/%vm92594_vm2, /*on_true_vy=*/%v92595_v44, /*on_false_vx=*/%v92593_v42 (stack76)
        %v93380_v34 = vor.u32 %v93379_v60, %v93378_v40 (stack47)
        %v94204_v24 = vor.u32 %v94203_v46, %v94202_v24 (stack47)
        %v94627_v8 = vshll.u32 %v94622_v22, 15 (stack45)
        %120237 = vst [vmem:[%s123356_s30 + $0x260] sm:$0xf] /*vst_source=*/%v92221_v32 (stack83)
        %v92599_v41 = vadd.f32 -3.0, %v92596_v44 (stack53)
        %v120240_v7 = vadd.low.f32.bf16 -1.0, %v92962_v43 (stack53)
        %v93795_v46 = vor.u32 %v93794_v23, %v93793_v45 (stack47)
        %v94628_v22 = vshrl.u32 %v94622_v22, 17 (stack46)
        %v92584_v9 = vsel /*vm=*/%vm92547_vm15, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v93381_v21 = vxor.u32 %v93380_v34, %v93376_v50 (stack48)
        %v94205_v29 = vxor.u32 %v94204_v24, %v94200_v61 (stack48)
        %v149042_v40 = vadd.s32 %v148940_v27, %v122657_v58 (stack40)
        %v149047_v30 = vsel /*vm=*/%vm92547_vm15, /*on_true_vy=*/%v148985_v30, /*on_false_vx=*/%v92599_v41 (stack44)
        %v92971_v60 = vmul.f32 2.0, %v120240_v7 (stack54)
        %v93796_v45 = vxor.u32 %v93795_v46, %v93791_v25 (stack48)
        %v94629_v32 = vor.u32 %v94628_v22, %v94627_v8 (stack47)
        %v92607_v42 = vmul.f32 %v149047_v30, %v92584_v9 (stack54)
        %v93384_v50 = vadd.s32 %v93381_v21, %v93376_v50 (stack40)
        %v93386_v43 = vshll.u32 %v93381_v21, 15 (stack45)
        %v93387_v23 = vshrl.u32 %v93381_v21, 17 (stack46)
        %v92975_v44 = vadd.f32 -0.99609375, %v92971_v60 (stack53)
        %v93799_v25 = vadd.s32 %v93796_v45, %v93791_v25 (stack40)
        %v93801_v34 = vshll.u32 %v93796_v45, 26 (stack45)
        %v93802_v24 = vshrl.u32 %v93796_v45, 6 (stack46)
        %v92611_v53 = vadd.f32 %v92607_v42, %v149007_v53 (stack53)
        %v93388_v8 = vor.u32 %v93387_v23, %v93386_v43 (stack47)
        %v94208_v61 = vadd.s32 %v94205_v29, %v94200_v61 (stack40)
        %v95053_v41 = vadd.s32 1, %v95049_v54 (stack40)
        %v149051_v7 = vmax.f32 %v92975_v44, -0.99609375 (stack55)
        %v93803_v46 = vor.u32 %v93802_v24, %v93801_v34 (stack47)
        %v94210_v22 = vshll.u32 %v94205_v29, 29 (stack45)
        %v94630_v9 = vxor.u32 %v94629_v32, %v149027_v56 (stack48)
        %v92615_v21 = vmul.f32 %v92611_v53, %v149047_v30 (stack54)
        %v93389_v60 = vxor.u32 %v93388_v8, %v93384_v50 (stack48)
        %v94211_v29 = vshrl.u32 %v94205_v29, 3 (stack46)
        %v95057_v54 = vsel /*vm=*/%vm95044_vm3, /*on_true_vy=*/%v95053_v41, /*on_false_vx=*/%v95049_v54 (stack44)
        %v92568_v45 = vsel /*vm=*/%vm92547_vm15, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v92576_v32 = vsel /*vm=*/%vm92547_vm15, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v92991_v42 = vxor.u32 2147483648, %v149051_v7 (stack56)
        %v93804_v43 = vxor.u32 %v93803_v46, %v93799_v25 (stack48)
        %v92619_v23 = vadd.f32 %v92615_v21, %v92576_v32 (stack53)
        %v93392_v50 = vadd.s32 %v93389_v60, %v93384_v50 (stack40)
        %v93394_v44 = vshll.u32 %v93389_v60, 26 (stack45)
        %v93395_v34 = vshrl.u32 %v93389_v60, 6 (stack46)
        %v149066_v24 = vmul.f32 %v92991_v42, %v149051_v7 (stack54)
        %v93807_v25 = vadd.s32 %v93804_v43, %v93799_v25 (stack40)
        %v93813_v53 = vshll.u32 %v93804_v43, 6 (stack45)
        %v149070_v8 = vadd.s32 %v149042_v40, %v121569_v1 (stack40)
        %v92623_v41 = vmul.f32 %v92619_v23, %v149047_v30 (stack54)
        %v93396_v46 = vor.u32 %v93395_v34, %v93394_v44 (stack47)
        %v93814_v21 = vshrl.u32 %v93804_v43, 26 (stack46)
        %v94212_v22 = vor.u32 %v94211_v29, %v94210_v22 (stack47)
        %v92572_v60 = vsel /*vm=*/%vm92547_vm15, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v92996_v29 = vadd.f32 1.0, %v149066_v24 (stack57)
        %v92999_v32 = vmul.f32 -0.5, %v149066_v24 (stack59)
        %vm95039_vm4 = vcmp.lt.u32.totalorder %v149042_v40, %v148940_v27 (stack43)
        %v92627_v42 = vadd.f32 %v92623_v41, %v92572_v60 (stack53)
        %v93397_v43 = vxor.u32 %v93396_v46, %v93392_v50 (stack48)
        %v93815_v23 = vor.u32 %v93814_v21, %v93813_v53 (stack47)
        %v94213_v44 = vxor.u32 %v94212_v22, %v94208_v61 (stack48)
        %121225 = vlog2.f32 %v92996_v29 (stack58)
        %v93811_v34 = vadd.s32 %v93807_v25, %v121574_v2 (stack40)
        %v94633_v56 = vadd.s32 %v94630_v9, %v149027_v56 (stack40)
        %v95080_v53 = vshll.u32 %v149070_v8, 13 (stack45)
        %v92631_v41 = vmul.f32 %v92627_v42, %v149047_v30 (stack54)
        %v93400_v50 = vadd.s32 %v93397_v43, %v93392_v50 (stack40)
        %v93406_v46 = vshll.u32 %v93397_v43, 6 (stack45)
        %v93407_v21 = vshrl.u32 %v93397_v43, 26 (stack46)
        %v93000_v22 = vadd.f32 1.0, %v92999_v32 (stack61)
        %v93816_v25 = vxor.u32 %v93815_v23, %v93807_v25 (stack48)
        %v94216_v61 = vadd.s32 %v94213_v44, %v94208_v61 (stack40)
        %v94218_v60 = vshll.u32 %v94213_v44, 16 (stack45)
        %v92635_v45 = vadd.f32 %v92631_v41, %v92568_v45 (stack53)
        %v93404_v29 = vadd.s32 %v93400_v50, %v121564_v0 (stack40)
        %v93408_v32 = vor.u32 %v93407_v21, %v93406_v46 (stack47)
        %v94219_v42 = vshrl.u32 %v94213_v44, 16 (stack46)
        %v93819_v43 = vadd.s32 %v93816_v25, %v121569_v1 (stack40)
        %v94635_v23 = vshll.u32 %v94630_v9, 26 (stack45)
        %v94636_v9 = vshrl.u32 %v94630_v9, 6 (stack46)
        %v95061_v44 = vadd.s32 1, %v95057_v54 (stack40)
        %v92639_v41 = vmul.f32 %v92635_v45, %v149047_v30 (stack54)
        %v93409_v50 = vxor.u32 %v93408_v32, %v93400_v50 (stack48)
        %v94220_v46 = vor.u32 %v94219_v42, %v94218_v60 (stack47)
        %v95081_v21 = vshrl.u32 %v149070_v8, 19 (stack46)
        %v93823_v25 = vadd.s32 3, %v93819_v43 (stack40)
        %v94637_v60 = vor.u32 %v94636_v9, %v94635_v23 (stack47)
        %v95065_v27 = vsel /*vm=*/%vm95039_vm4, /*on_true_vy=*/%v95061_v44, /*on_false_vx=*/%v95057_v54 (stack44)
        %v149093_v40 = vadd.s32 %v157664_v31, %v157083_v59 (stack40)
        %v92643_v12 = vadd.f32 %v92639_v41, %v149002_v12 (stack53)
        %v93412_v54 = vadd.s32 %v93409_v50, %v121574_v2 (stack40)
        %v94221_v45 = vxor.u32 %v94220_v46, %v94216_v61 (stack48)
        %v95070_v32 = vadd.s32 %v95065_v27, %v121574_v2 (stack40)
        %v93827_v34 = vadd.s32 %v93823_v25, %v93811_v34 (stack40)
        %v93829_v42 = vshll.u32 %v93823_v25, 17 (stack45)
        %v93830_v43 = vshrl.u32 %v93823_v25, 15 (stack46)
        %v94638_v23 = vxor.u32 %v94637_v60, %v94633_v56 (stack48)
        %v92647_v9 = vmul.f32 %v92643_v12, %v149047_v30 (stack54)
        %v93416_v44 = vadd.s32 5, %v93412_v54 (stack40)
        %v94224_v61 = vadd.s32 %v94221_v45, %v94216_v61 (stack40)
        %v94230_v41 = vshll.u32 %v94221_v45, 24 (stack45)
        %v93831_v50 = vor.u32 %v93830_v43, %v93829_v42 (stack47)
        %v94231_v46 = vshrl.u32 %v94221_v45, 8 (stack46)
        %v94641_v56 = vadd.s32 %v94638_v23, %v94633_v56 (stack40)
        %v94647_v25 = vshll.u32 %v94638_v23, 6 (stack45)
        %v92651_v10 = vadd.f32 %v92647_v9, %v148997_v10 (stack53)
        %v93002_v60 = vand.u32 2147483647, %v149066_v24 (stack60)
        %v93418_v29 = vxor.u32 %v93416_v44, %v93404_v29 (stack48)
        %v94648_v27 = vshrl.u32 %v94638_v23, 26 (stack46)
        %v93001_v24 = vmul.f32 %v93000_v22, %v149066_v24 (stack63)
        %v93832_v22 = vxor.u32 %v93831_v50, %v93827_v34 (stack48)
        %v94232_v12 = vor.u32 %v94231_v46, %v94230_v41 (stack47)
        %v95078_v8 = vadd.s32 %v149070_v8, %v95070_v32 (stack40)
        %v121226_v54 = vpop.eup %121225 (stack64)
        %v92655_v45 = vmul.f32 %v92651_v10, %v149047_v30 (stack54)
        %v93419_v32 = vand.u32.u8 255, %v93418_v29 (stack49)
        %v94649_v42 = vor.u32 %v94648_v27, %v94647_v25 (stack47)
        %v95082_v53 = vor.u32 %v95081_v21, %v95080_v53 (stack47)
        %v92998_v21 = vmul.f32 0.6931472, %v121226_v54 (stack65)
        %v93835_v34 = vadd.s32 %v93832_v22, %v93827_v34 (stack40)
        %v93837_v43 = vshll.u32 %v93832_v22, 29 (stack45)
        %v93838_v23 = vshrl.u32 %v93832_v22, 3 (stack46)
        %v92659_v6 = vadd.f32 %v92655_v45, %v148982_v6 (stack53)
        %vm93003_vm5 = vcmp.lt.f32.partialorder %v93002_v60, 0.0004427343 (stack62)
        %v94233_v9 = vxor.u32 %v94232_v12, %v94224_v61 (stack48)
        %v94650_v44 = vxor.u32 %v94649_v42, %v94641_v56 (stack48)
        %v93004_v41 = vsel /*vm=*/%vm93003_vm5, /*on_true_vy=*/%v93001_v24, /*on_false_vx=*/%v92998_v21 (stack66)
        %v93420_v50 = vand.u32 65535, %v93419_v32 (stack50)
        %v93839_v46 = vor.u32 %v93838_v23, %v93837_v43 (stack47)
        %v95083_v25 = vxor.u32 %v95082_v53, %v95078_v8 (stack48)
        %v92528_v10 = vmul.f32 inf, %v148875_v20 (stack54)
        %v92663_v30 = vmul.f32 %v92659_v6, %v149047_v30 (stack54)
        %v149107_v60 = vxor.u32 2147483648, %v93004_v41 (stack56)
        %vm149111_vm6 = vcmp.eq.f32.partialorder %v92520_v55, 1.0 (stack68)
        %v92552_v52 = vsel /*vm=*/%vm92547_vm15, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v93840_v29 = vxor.u32 %v93839_v46, %v93835_v34 (stack48)
        %v149118_v27 = vadd.s32 %v95083_v25, %v95078_v8 (stack40)
        %v92667_v24 = vadd.f32 %v92663_v30, %v92552_v52 (stack53)
        %v92981_v22 = vand.u32 2147483647, %v149051_v7 (stack77)
        %vm93008_vm7 = vcmp.lt.f32.partialorder %v149107_v60, 5.0 (stack68)
        %121227 = vrsqrt.f32 %v149107_v60 (stack67)
        %v149124_v12 = vmul.f32 inf, %v149051_v7 (stack54)
        %v93421_v8 = vshrl.u32 %v93420_v50, 1 (stack51)
        %v93843_v54 = vadd.s32 %v93840_v29, %v93835_v34 (stack40)
        %v94228_v61 = vadd.s32 %v94224_v61, %v121564_v0 (stack40)
        %v92671_v20 = vmul.f32 %v92667_v24, %v148875_v20 (stack54)
        %v94236_v45 = vadd.s32 %v94233_v9, %v121574_v2 (stack40)
        %v94645_v56 = vadd.s32 %v94641_v56, %v121569_v1 (stack40)
        %v94653_v32 = vadd.s32 %v94650_v44, %v121564_v0 (stack40)
        %v149134_v42 = vsel /*vm=*/%vm93008_vm7, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v149137_v53 = vadd.f32 -2.5, %v149107_v60 (stack53)
        %v95088_v21 = vshll.u32 %v95083_v25, 15 (stack45)
        %v149141_v34 = vadd.s32 %v149093_v40, %v122657_v58 (stack40)
        %v92675_v43 = vsel /*vm=*/%vm149111_vm6, /*on_true_vy=*/%v92528_v10, /*on_false_vx=*/%v92671_v20 (stack44)
        %v149148_v23 = vsel /*vm=*/%vm93008_vm7, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v149153_v6 = vsel /*vm=*/%vm93008_vm7, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v149158_v9 = vsel /*vm=*/%vm93008_vm7, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v92679_v44 = vmul.f32 1.4140625, %v92675_v43 (stack54)
        %v93422_v41 = vor.u32 16256, %v93421_v8 (stack47)
        %v93845_v50 = vshll.u32 %v93840_v29, 16 (stack45)
        %v93846_v46 = vshrl.u32 %v93840_v29, 16 (stack46)
        %v94240_v10 = vadd.s32 2, %v94236_v45 (stack40)
        %v94657_v30 = vadd.s32 1, %v94653_v32 (stack40)
        %v95089_v25 = vshrl.u32 %v95083_v25, 17 (stack46)
        %vm95505_vm8 = vcmp.lt.u32.totalorder %v149093_v40, %v157083_v59 (stack43)
        %v92682_v55 = vpack.c.bf16 %v157387_v11, %v92679_v44 (stack81)
        %v93423_v52 = vand.u32.u16 65535, %v93422_v41 (stack52)
        %v93847_v29 = vor.u32 %v93846_v46, %v93845_v50 (stack47)
        %v95510_v24 = vadd.s32 %v157667_v26, %v157084_v16 (stack40)
        %v94244_v8 = vadd.s32 %v94240_v10, %v94228_v61 (stack40)
        %v94246_v61 = vshll.u32 %v94240_v10, 13 (stack45)
        %v94247_v20 = vshrl.u32 %v94240_v10, 19 (stack46)
        %v94661_v45 = vadd.s32 %v94657_v30, %v94645_v56 (stack40)
        %120239 = vst [vmem:[%s123356_s30 + $0x2e0] sm:$0xf] /*vst_source=*/%v92682_v55 (stack83)
        %v120242_v56 = vadd.low.f32.bf16 -1.0, %v93423_v52 (stack53)
        %v93848_v32 = vxor.u32 %v93847_v29, %v93843_v54 (stack48)
        %v94663_v43 = vshll.u32 %v94657_v30, 17 (stack45)
        %v94664_v44 = vshrl.u32 %v94657_v30, 15 (stack46)
        %v93045_v41 = vsel /*vm=*/%vm93008_vm7, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v94248_v50 = vor.u32 %v94247_v20, %v94246_v61 (stack47)
        %v95090_v21 = vor.u32 %v95089_v25, %v95088_v21 (stack47)
        %v95514_v46 = vadd.s32 1, %v95510_v24 (stack40)
        %v93432_v10 = vmul.f32 2.0, %v120242_v56 (stack54)
        %v93851_v54 = vadd.s32 %v93848_v32, %v93843_v54 (stack40)
        %v93857_v30 = vshll.u32 %v93848_v32, 24 (stack45)
        %v93858_v25 = vshrl.u32 %v93848_v32, 8 (stack46)
        %v94249_v55 = vxor.u32 %v94248_v50, %v94244_v8 (stack48)
        %v94665_v52 = vor.u32 %v94664_v44, %v94663_v43 (stack47)
        %v95091_v29 = vxor.u32 %v95090_v21, %v149118_v27 (stack48)
        %v95518_v24 = vsel /*vm=*/%vm95505_vm8, /*on_true_vy=*/%v95514_v46, /*on_false_vx=*/%v95510_v24 (stack44)
        %v121228_v61 = vpop.eup %121227 (stack73)
        %vm93053_vm9 = vcmp.eq.f32.partialorder %v149107_v60, inf (stack70)
        %v93056_v20 = vand.u32 2147483648, %v149107_v60 (stack72)
        %v93436_v56 = vadd.f32 -0.99609375, %v93432_v10 (stack53)
        %v93859_v32 = vor.u32 %v93858_v25, %v93857_v30 (stack47)
        %v93052_v43 = vmul.f32 %v121228_v61, %v149107_v60 (stack74)
        %v94252_v8 = vadd.s32 %v94249_v55, %v94244_v8 (stack40)
        %v94254_v44 = vshll.u32 %v94249_v55, 15 (stack45)
        %v94255_v50 = vshrl.u32 %v94249_v55, 17 (stack46)
        %vm95500_vm10 = vcmp.lt.u32.totalorder %v149141_v34, %v149093_v40 (stack43)
        %v149178_v21 = vmax.f32 %v93436_v56, -0.99609375 (stack55)
        %v93860_v46 = vxor.u32 %v93859_v32, %v93851_v54 (stack48)
        %v94666_v10 = vxor.u32 %v94665_v52, %v94661_v45 (stack48)
        %v149181_v27 = vadd.s32 %v95091_v29, %v149118_v27 (stack40)
        %v93054_v30 = vsel /*vm=*/%vm93053_vm9, /*on_true_vy=*/%v149107_v60, /*on_false_vx=*/%v93052_v43 (stack75)
        %vm93055_vm11 = vcmp.eq.f32.partialorder %v149107_v60, 0.0 (stack71)
        %v94256_v25 = vor.u32 %v94255_v50, %v94254_v44 (stack47)
        %v149187_v55 = vadd.s32 %v149141_v34, %v121569_v1 (stack40)
        %v93057_v52 = vsel /*vm=*/%vm93055_vm11, /*on_true_vy=*/%v93056_v20, /*on_false_vx=*/%v93054_v30 (stack76)
        %v93452_v61 = vxor.u32 2147483648, %v149178_v21 (stack56)
        %v93855_v54 = vadd.s32 %v93851_v54, %v121569_v1 (stack40)
        %v95096_v20 = vshll.u32 %v95091_v29, 26 (stack45)
        %v93060_v56 = vadd.f32 -3.0, %v93057_v52 (stack53)
        %v93863_v32 = vadd.s32 %v93860_v46, %v121564_v0 (stack40)
        %v94257_v43 = vxor.u32 %v94256_v25, %v94252_v8 (stack48)
        %v94669_v45 = vadd.s32 %v94666_v10, %v94661_v45 (stack40)
        %v149193_v44 = vmul.f32 %v93452_v61, %v149178_v21 (stack54)
        %v94671_v50 = vshll.u32 %v94666_v10, 29 (stack45)
        %v94672_v46 = vshrl.u32 %v94666_v10, 3 (stack46)
        %v95097_v29 = vshrl.u32 %v95091_v29, 6 (stack46)
        %v149198_v53 = vsel /*vm=*/%vm93008_vm7, /*on_true_vy=*/%v149137_v53, /*on_false_vx=*/%v93060_v56 (stack44)
        %v93867_v10 = vadd.s32 4, %v93863_v32 (stack40)
        %v94260_v8 = vadd.s32 %v94257_v43, %v94252_v8 (stack40)
        %v94262_v30 = vshll.u32 %v94257_v43, 26 (stack45)
        %v93068_v41 = vmul.f32 %v149198_v53, %v93045_v41 (stack54)
        %v93457_v25 = vadd.f32 1.0, %v149193_v44 (stack57)
        %v93460_v52 = vmul.f32 -0.5, %v149193_v44 (stack59)
        %v95522_v61 = vadd.s32 1, %v95518_v24 (stack40)
        %v93871_v54 = vadd.s32 %v93867_v10, %v93855_v54 (stack40)
        %v93873_v56 = vshll.u32 %v93867_v10, 13 (stack45)
        %v93874_v32 = vshrl.u32 %v93867_v10, 19 (stack46)
        %v94263_v43 = vshrl.u32 %v94257_v43, 6 (stack46)
        %v93037_v10 = vsel /*vm=*/%vm93008_vm7, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v93072_v9 = vadd.f32 %v93068_v41, %v149158_v9 (stack53)
        %121229 = vlog2.f32 %v93457_v25 (stack58)
        %v93463_v41 = vand.u32 2147483647, %v149193_v44 (stack60)
        %v93875_v25 = vor.u32 %v93874_v32, %v93873_v56 (stack47)
        %v94264_v30 = vor.u32 %v94263_v43, %v94262_v30 (stack47)
        %v94673_v50 = vor.u32 %v94672_v46, %v94671_v50 (stack47)
        %v95098_v20 = vor.u32 %v95097_v29, %v95096_v20 (stack47)
        %v93076_v46 = vmul.f32 %v93072_v9, %v149198_v53 (stack54)
        %v93461_v29 = vadd.f32 1.0, %v93460_v52 (stack61)
        %v95526_v40 = vsel /*vm=*/%vm95500_vm10, /*on_true_vy=*/%v95522_v61, /*on_false_vx=*/%v95518_v24 (stack44)
        %v95541_v34 = vshll.u32 %v149187_v55, 13 (stack45)
        %v93876_v24 = vxor.u32 %v93875_v25, %v93871_v54 (stack48)
        %v94265_v52 = vxor.u32 %v94264_v30, %v94260_v8 (stack48)
        %v94674_v61 = vxor.u32 %v94673_v50, %v94669_v45 (stack48)
        %v95099_v56 = vxor.u32 %v95098_v20, %v149181_v27 (stack48)
        %v93080_v32 = vadd.f32 %v93076_v46, %v93037_v10 (stack53)
        %v95531_v43 = vadd.s32 %v95526_v40, %v121574_v2 (stack40)
        %v95542_v10 = vshrl.u32 %v149187_v55, 19 (stack46)
        %v149218_v9 = vadd.s32 %v157664_v31, %v157089_v17 (stack40)
        %v93879_v54 = vadd.s32 %v93876_v24, %v93871_v54 (stack40)
        %v93881_v25 = vshll.u32 %v93876_v24, 15 (stack45)
        %v93882_v30 = vshrl.u32 %v93876_v24, 17 (stack46)
        %v94268_v8 = vadd.s32 %v94265_v52, %v94260_v8 (stack40)
        %v93084_v50 = vmul.f32 %v93080_v32, %v149198_v53 (stack54)
        %v94274_v20 = vshll.u32 %v94265_v52, 6 (stack45)
        %v94275_v46 = vshrl.u32 %v94265_v52, 26 (stack46)
        %v94677_v45 = vadd.s32 %v94674_v61, %v94669_v45 (stack40)
        %v93462_v44 = vmul.f32 %v93461_v29, %v149193_v44 (stack63)
        %v93883_v29 = vor.u32 %v93882_v30, %v93881_v25 (stack47)
        %v94679_v40 = vshll.u32 %v94674_v61, 16 (stack45)
        %v94680_v24 = vshrl.u32 %v94674_v61, 16 (stack46)
        %v93088_v6 = vadd.f32 %v93084_v50, %v149153_v6 (stack53)
        %v94276_v52 = vor.u32 %v94275_v46, %v94274_v20 (stack47)
        %v95102_v27 = vadd.s32 %v95099_v56, %v149181_v27 (stack40)
        %v95108_v61 = vshll.u32 %v95099_v56, 6 (stack45)
        %v93884_v32 = vxor.u32 %v93883_v29, %v93879_v54 (stack48)
        %v94681_v25 = vor.u32 %v94680_v24, %v94679_v40 (stack47)
        %v95109_v56 = vshrl.u32 %v95099_v56, 26 (stack46)
        %v95539_v55 = vadd.s32 %v149187_v55, %v95531_v43 (stack40)
        %v93092_v43 = vmul.f32 %v93088_v6, %v149198_v53 (stack54)
        %v94272_v30 = vadd.s32 %v94268_v8, %v121574_v2 (stack40)
        %v94277_v8 = vxor.u32 %v94276_v52, %v94268_v8 (stack48)
        %v95543_v34 = vor.u32 %v95542_v10, %v95541_v34 (stack47)
        %v93887_v10 = vadd.s32 %v93884_v32, %v93879_v54 (stack40)
        %v93889_v54 = vshll.u32 %v93884_v32, 26 (stack45)
        %v93890_v50 = vshrl.u32 %v93884_v32, 6 (stack46)
        %v94682_v20 = vxor.u32 %v94681_v25, %v94677_v45 (stack48)
        %v93096_v23 = vadd.f32 %v93092_v43, %v149148_v23 (stack53)
        %v94280_v46 = vadd.s32 %v94277_v8, %v121569_v1 (stack40)
        %v95110_v29 = vor.u32 %v95109_v56, %v95108_v61 (stack47)
        %v149229_v40 = vxor.u32 %v95543_v34, %v95539_v55 (stack48)
        %v121230_v24 = vpop.eup %121229 (stack64)
        %v93891_v6 = vor.u32 %v93890_v50, %v93889_v54 (stack47)
        %v94685_v45 = vadd.s32 %v94682_v20, %v94677_v45 (stack40)
        %v94691_v52 = vshll.u32 %v94682_v20, 24 (stack45)
        %v94692_v61 = vshrl.u32 %v94682_v20, 8 (stack46)
        %v93100_v32 = vmul.f32 %v93096_v23, %v149198_v53 (stack54)
        %v93459_v25 = vmul.f32 0.6931472, %v121230_v24 (stack65)
        %v94284_v56 = vadd.s32 3, %v94280_v46 (stack40)
        %v95111_v43 = vxor.u32 %v95110_v29, %v95102_v27 (stack48)
        %vm93464_vm12 = vcmp.lt.f32.partialorder %v93463_v41, 0.0004427343 (stack62)
        %v93892_v41 = vxor.u32 %v93891_v6, %v93887_v10 (stack48)
        %v94693_v8 = vor.u32 %v94692_v61, %v94691_v52 (stack47)
        %v149233_v55 = vadd.s32 %v149229_v40, %v95539_v55 (stack40)
        %v93013_v34 = vsel /*vm=*/%vm93008_vm7, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v93104_v42 = vadd.f32 %v93100_v32, %v149134_v42 (stack53)
        %v93465_v44 = vsel /*vm=*/%vm93464_vm12, /*on_true_vy=*/%v93462_v44, /*on_false_vx=*/%v93459_v25 (stack66)
        %v94288_v30 = vadd.s32 %v94284_v56, %v94272_v30 (stack40)
        %v93017_v54 = vsel /*vm=*/%vm93008_vm7, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v93021_v60 = vsel /*vm=*/%vm93008_vm7, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v149245_v50 = vxor.u32 2147483648, %v93465_v44 (stack56)
        %v93895_v10 = vadd.s32 %v93892_v41, %v93887_v10 (stack40)
        %v93108_v20 = vmul.f32 %v93104_v42, %v149198_v53 (stack54)
        %v93901_v23 = vshll.u32 %v93892_v41, 6 (stack45)
        %v94290_v46 = vshll.u32 %v94284_v56, 17 (stack45)
        %v94694_v29 = vxor.u32 %v94693_v8, %v94685_v45 (stack48)
        %vm93469_vm13 = vcmp.lt.f32.partialorder %v149245_v50, 5.0 (stack68)
        %121231 = vrsqrt.f32 %v149245_v50 (stack67)
        %v93902_v24 = vshrl.u32 %v93892_v41, 26 (stack46)
        %v94291_v6 = vshrl.u32 %v94284_v56, 15 (stack46)
        %v93112_v52 = vadd.f32 %v93108_v20, %v93021_v60 (stack53)
        %v93442_v61 = vand.u32 2147483647, %v149178_v21 (stack77)
        %v149252_v32 = vmul.f32 inf, %v149178_v21 (stack54)
        %v95114_v25 = vadd.s32 %v95111_v43, %v121564_v0 (stack40)
        %v149258_v56 = vsel /*vm=*/%vm93469_vm13, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v149261_v43 = vadd.f32 -2.5, %v149245_v50 (stack53)
        %v94689_v45 = vadd.s32 %v94685_v45, %v121564_v0 (stack40)
        %v95106_v27 = vadd.s32 %v95102_v27, %v121569_v1 (stack40)
        %v93116_v41 = vmul.f32 %v93112_v52, %v149198_v53 (stack54)
        %v149269_v8 = vsel /*vm=*/%vm93469_vm13, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v149274_v42 = vsel /*vm=*/%vm93469_vm13, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v93899_v44 = vadd.s32 %v93895_v10, %v121564_v0 (stack40)
        %vm149279_vm14 = vcmp.eq.f32.partialorder %v92981_v22, 1.0 (stack68)
        %v149286_v60 = vsel /*vm=*/%vm93469_vm13, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v149291_v20 = vsel /*vm=*/%vm93469_vm13, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v93903_v23 = vor.u32 %v93902_v24, %v93901_v23 (stack47)
        %v94292_v46 = vor.u32 %v94291_v6, %v94290_v46 (stack47)
        %v93120_v54 = vadd.f32 %v93116_v41, %v93017_v54 (stack53)
        %v149296_v24 = vsel /*vm=*/%vm93469_vm13, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v94697_v29 = vadd.s32 %v94694_v29, %v121574_v2 (stack40)
        %v95118_v6 = vadd.s32 1, %v95114_v25 (stack40)
        %v93904_v10 = vxor.u32 %v93903_v23, %v93895_v10 (stack48)
        %v94293_v52 = vxor.u32 %v94292_v46, %v94288_v30 (stack48)
        %v95549_v25 = vshll.u32 %v149229_v40, 15 (stack45)
        %v95550_v40 = vshrl.u32 %v149229_v40, 17 (stack46)
        %v93124_v53 = vmul.f32 %v93120_v54, %v149198_v53 (stack54)
        %vm93514_vm15 = vcmp.eq.f32.partialorder %v149245_v50, inf (stack70)
        %v94701_v41 = vadd.s32 2, %v94697_v29 (stack40)
        %v95122_v27 = vadd.s32 %v95118_v6, %v95106_v27 (stack40)
        %v95124_v23 = vshll.u32 %v95118_v6, 17 (stack45)
        %v93907_v46 = vadd.s32 %v93904_v10, %v121574_v2 (stack40)
        %v94296_v30 = vadd.s32 %v94293_v52, %v94288_v30 (stack40)
        %v94298_v54 = vshll.u32 %v94293_v52, 29 (stack45)
        %v94299_v29 = vshrl.u32 %v94293_v52, 3 (stack46)
        %v93128_v34 = vadd.f32 %v93124_v53, %v93013_v34 (stack53)
        %v94705_v45 = vadd.s32 %v94701_v41, %v94689_v45 (stack40)
        %v94707_v10 = vshll.u32 %v94701_v41, 13 (stack45)
        %v94708_v52 = vshrl.u32 %v94701_v41, 19 (stack46)
        %v93911_v53 = vadd.s32 5, %v93907_v46 (stack40)
        %v94300_v41 = vor.u32 %v94299_v29, %v94298_v54 (stack47)
        %v95125_v6 = vshrl.u32 %v95118_v6, 15 (stack46)
        %v95551_v25 = vor.u32 %v95550_v40, %v95549_v25 (stack47)
        %v93132_v7 = vmul.f32 %v93128_v34, %v149051_v7 (stack54)
        %vm93516_vm0 = vcmp.eq.f32.partialorder %v149245_v50, 0.0 (stack71)
        %v94709_v40 = vor.u32 %v94708_v52, %v94707_v10 (stack47)
        %vm95966_vm1 = vcmp.lt.u32.totalorder %v149218_v9, %v157089_v17 (stack43)
        %v93517_v46 = vand.u32 2147483648, %v149245_v50 (stack72)
        %v93913_v44 = vxor.u32 %v93911_v53, %v93899_v44 (stack48)
        %v94301_v54 = vxor.u32 %v94300_v41, %v94296_v30 (stack48)
        %v95552_v29 = vxor.u32 %v95551_v25, %v149233_v55 (stack48)
        %v121232_v34 = vpop.eup %121231 (stack73)
        %v93136_v12 = vsel /*vm=*/%vm149279_vm14, /*on_true_vy=*/%v149124_v12, /*on_false_vx=*/%v93132_v7 (stack44)
        %v94710_v22 = vxor.u32 %v94709_v40, %v94705_v45 (stack48)
        %v95126_v23 = vor.u32 %v95125_v6, %v95124_v23 (stack47)
        %v95971_v10 = vadd.s32 %v157667_v26, %v157090_v62 (stack40)
        %v93140_v52 = vmul.f32 1.4140625, %v93136_v12 (stack54)
        %v93513_v53 = vmul.f32 %v121232_v34, %v149245_v50 (stack74)
        %v93914_v41 = vand.u32.u8 255, %v93913_v44 (stack49)
        %v94304_v30 = vadd.s32 %v94301_v54, %v94296_v30 (stack40)
        %v94306_v6 = vshll.u32 %v94301_v54, 16 (stack45)
        %v94307_v25 = vshrl.u32 %v94301_v54, 16 (stack46)
        %v94713_v45 = vadd.s32 %v94710_v22, %v94705_v45 (stack40)
        %v94715_v7 = vshll.u32 %v94710_v22, 15 (stack45)
        %v93143_v40 = vpack.c.bf16 %v157387_v11, %v93140_v52 (stack81)
        %v93515_v44 = vsel /*vm=*/%vm93514_vm15, /*on_true_vy=*/%v149245_v50, /*on_false_vx=*/%v93513_v53 (stack75)
        %v93915_v54 = vand.u32 65535, %v93914_v41 (stack50)
        %v94716_v34 = vshrl.u32 %v94710_v22, 17 (stack46)
        %v93518_v46 = vsel /*vm=*/%vm93516_vm0, /*on_true_vy=*/%v93517_v46, /*on_false_vx=*/%v93515_v44 (stack76)
        %v94308_v12 = vor.u32 %v94307_v25, %v94306_v6 (stack47)
        %v95127_v22 = vxor.u32 %v95126_v23, %v95122_v27 (stack48)
        %v95555_v55 = vadd.s32 %v95552_v29, %v149233_v55 (stack40)
        %120241 = vst [vmem:[%s123356_s30 + $0x360] sm:$0xf] /*vst_source=*/%v93143_v40 (stack83)
        %v93521_v23 = vadd.f32 -3.0, %v93518_v46 (stack53)
        %v93916_v52 = vshrl.u32 %v93915_v54, 1 (stack51)
        %v94717_v53 = vor.u32 %v94716_v34, %v94715_v7 (stack47)
        %v95557_v41 = vshll.u32 %v95552_v29, 26 (stack45)
        %v94309_v6 = vxor.u32 %v94308_v12, %v94304_v30 (stack48)
        %v95130_v27 = vadd.s32 %v95127_v22, %v95122_v27 (stack40)
        %v95132_v25 = vshll.u32 %v95127_v22, 29 (stack45)
        %v95133_v7 = vshrl.u32 %v95127_v22, 3 (stack46)
        %v149327_v43 = vsel /*vm=*/%vm93469_vm13, /*on_true_vy=*/%v149261_v43, /*on_false_vx=*/%v93521_v23 (stack44)
        %v93917_v40 = vor.u32 16256, %v93916_v52 (stack47)
        %v94718_v44 = vxor.u32 %v94717_v53, %v94713_v45 (stack48)
        %v95558_v29 = vshrl.u32 %v95552_v29, 6 (stack46)
        %v93529_v24 = vmul.f32 %v149327_v43, %v149296_v24 (stack54)
        %v94312_v30 = vadd.s32 %v94309_v6, %v94304_v30 (stack40)
        %v94318_v54 = vshll.u32 %v94309_v6, 24 (stack45)
        %v94319_v34 = vshrl.u32 %v94309_v6, 8 (stack46)
        %v93918_v46 = vand.u32.u16 65535, %v93917_v40 (stack52)
        %v94721_v45 = vadd.s32 %v94718_v44, %v94713_v45 (stack40)
        %v94723_v12 = vshll.u32 %v94718_v44, 26 (stack45)
        %v94724_v22 = vshrl.u32 %v94718_v44, 6 (stack46)
        %v93533_v20 = vadd.f32 %v93529_v24, %v149291_v20 (stack53)
        %v94320_v23 = vor.u32 %v94319_v34, %v94318_v54 (stack47)
        %v95134_v52 = vor.u32 %v95133_v7, %v95132_v25 (stack47)
        %v149334_v53 = vadd.s32 %v149218_v9, %v122657_v58 (stack40)
        %v120248_v6 = vadd.low.f32.bf16 -1.0, %v93918_v46 (stack53)
        %v94725_v25 = vor.u32 %v94724_v22, %v94723_v12 (stack47)
        %v95559_v41 = vor.u32 %v95558_v29, %v95557_v41 (stack47)
        %v95975_v7 = vadd.s32 1, %v95971_v10 (stack40)
        %v93537_v40 = vmul.f32 %v93533_v20, %v149327_v43 (stack54)
        %v94316_v44 = vadd.s32 %v94312_v30, %v121569_v1 (stack40)
        %v94321_v29 = vxor.u32 %v94320_v23, %v94312_v30 (stack48)
        %v95135_v24 = vxor.u32 %v95134_v52, %v95130_v27 (stack48)
        %v93927_v30 = vmul.f32 2.0, %v120248_v6 (stack54)
        %v94726_v54 = vxor.u32 %v94725_v25, %v94721_v45 (stack48)
        %v95560_v34 = vxor.u32 %v95559_v41, %v95555_v55 (stack48)
        %v149341_v10 = vsel /*vm=*/%vm95966_vm1, /*on_true_vy=*/%v95975_v7, /*on_false_vx=*/%v95971_v10 (stack44)
        %v93541_v60 = vadd.f32 %v93537_v40, %v149286_v60 (stack53)
        %v94324_v46 = vadd.s32 %v94321_v29, %v121564_v0 (stack40)
        %v95138_v27 = vadd.s32 %v95135_v24, %v95130_v27 (stack40)
        %v95140_v12 = vshll.u32 %v95135_v24, 16 (stack45)
        %v93931_v22 = vadd.f32 -0.99609375, %v93927_v30 (stack53)
        %v94729_v45 = vadd.s32 %v94726_v54, %v94721_v45 (stack40)
        %v94735_v20 = vshll.u32 %v94726_v54, 6 (stack45)
        %v94736_v23 = vshrl.u32 %v94726_v54, 26 (stack46)
        %v93545_v52 = vmul.f32 %v93541_v60, %v149327_v43 (stack54)
        %v94328_v6 = vadd.s32 4, %v94324_v46 (stack40)
        %v95141_v25 = vshrl.u32 %v95135_v24, 16 (stack46)
        %v149346_v55 = vadd.s32 %v95560_v34, %v95555_v55 (stack40)
        %v93494_v41 = vsel /*vm=*/%vm93469_vm13, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v149351_v7 = vmax.f32 %v93931_v22, -0.99609375 (stack55)
        %v94737_v40 = vor.u32 %v94736_v23, %v94735_v20 (stack47)
        %v149355_v29 = vadd.s32 %v149334_v53, %v121569_v1 (stack40)
        %v93549_v24 = vadd.f32 %v93545_v52, %v93494_v41 (stack53)
        %v94332_v44 = vadd.s32 %v94328_v6, %v94316_v44 (stack40)
        %v94334_v30 = vshll.u32 %v94328_v6, 13 (stack45)
        %v94335_v54 = vshrl.u32 %v94328_v6, 19 (stack46)
        %v93486_v60 = vsel /*vm=*/%vm93469_vm13, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v93490_v50 = vsel /*vm=*/%vm93469_vm13, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v93947_v46 = vxor.u32 2147483648, %v149351_v7 (stack56)
        %v94738_v22 = vxor.u32 %v94737_v40, %v94729_v45 (stack48)
        %v93553_v20 = vmul.f32 %v93549_v24, %v149327_v43 (stack54)
        %v94336_v23 = vor.u32 %v94335_v54, %v94334_v30 (stack47)
        %v95142_v12 = vor.u32 %v95141_v25, %v95140_v12 (stack47)
        %vm95961_vm2 = vcmp.lt.u32.totalorder %v149334_v53, %v149218_v9 (stack43)
        %v93950_v52 = vmul.f32 %v93947_v46, %v149351_v7 (stack54)
        %v94733_v45 = vadd.s32 %v94729_v45, %v121574_v2 (stack40)
        %v94741_v6 = vadd.s32 %v94738_v22, %v121569_v1 (stack40)
        %v96002_v25 = vshll.u32 %v149355_v29, 13 (stack45)
        %v93557_v41 = vadd.f32 %v93553_v20, %v93490_v50 (stack53)
        %v94337_v40 = vxor.u32 %v94336_v23, %v94332_v44 (stack48)
        %v95143_v24 = vxor.u32 %v95142_v12, %v95138_v27 (stack48)
        %v95569_v30 = vshll.u32 %v95560_v34, 6 (stack45)
        %v93952_v54 = vadd.f32 1.0, %v93950_v52 (stack57)
        %v93955_v50 = vmul.f32 -0.5, %v93950_v52 (stack59)
        %v94745_v46 = vadd.s32 3, %v94741_v6 (stack40)
        %v95570_v34 = vshrl.u32 %v95560_v34, 26 (stack46)
        %v93561_v22 = vmul.f32 %v93557_v41, %v149327_v43 (stack54)
        %v94340_v44 = vadd.s32 %v94337_v40, %v94332_v44 (stack40)
        %v94342_v20 = vshll.u32 %v94337_v40, 15 (stack45)
        %v94343_v23 = vshrl.u32 %v94337_v40, 17 (stack46)
        %121233 = vlog2.f32 %v93952_v54 (stack58)
        %v93956_v12 = vadd.f32 1.0, %v93955_v50 (stack61)
        %v94749_v45 = vadd.s32 %v94745_v46, %v94733_v45 (stack40)
        %v95983_v6 = vadd.s32 1, %v149341_v10 (stack40)
        %v93565_v60 = vadd.f32 %v93561_v22, %v93486_v60 (stack53)
        %v94344_v41 = vor.u32 %v94343_v23, %v94342_v20 (stack47)
        %v94751_v40 = vshll.u32 %v94745_v46, 17 (stack45)
        %v94752_v54 = vshrl.u32 %v94745_v46, 15 (stack46)
        %v93958_v50 = vand.u32 2147483647, %v93950_v52 (stack60)
        %v95146_v27 = vadd.s32 %v95143_v24, %v95138_v27 (stack40)
        %v95152_v46 = vshll.u32 %v95143_v24, 24 (stack45)
        %v95153_v24 = vshrl.u32 %v95143_v24, 8 (stack46)
        %v93569_v22 = vmul.f32 %v93565_v60, %v149327_v43 (stack54)
        %v94345_v20 = vxor.u32 %v94344_v41, %v94340_v44 (stack48)
        %v94753_v23 = vor.u32 %v94752_v54, %v94751_v40 (stack47)
        %v95571_v30 = vor.u32 %v95570_v34, %v95569_v30 (stack47)
        %v93957_v52 = vmul.f32 %v93956_v12, %v93950_v52 (stack63)
        %v95154_v34 = vor.u32 %v95153_v24, %v95152_v46 (stack47)
        %v95567_v12 = vadd.s32 %v149346_v55, %v121569_v1 (stack40)
        %v95987_v9 = vsel /*vm=*/%vm95961_vm2, /*on_true_vy=*/%v95983_v6, /*on_false_vx=*/%v149341_v10 (stack44)
        %v93573_v42 = vadd.f32 %v93569_v22, %v149274_v42 (stack53)
        %v94348_v53 = vadd.s32 %v94345_v20, %v94340_v44 (stack40)
        %v94350_v10 = vshll.u32 %v94345_v20, 26 (stack45)
        %v94351_v44 = vshrl.u32 %v94345_v20, 6 (stack46)
        %v94754_v6 = vxor.u32 %v94753_v23, %v94749_v45 (stack48)
        %v95155_v60 = vxor.u32 %v95154_v34, %v95146_v27 (stack48)
        %v95572_v55 = vxor.u32 %v95571_v30, %v149346_v55 (stack48)
        %v95992_v41 = vadd.s32 %v95987_v9, %v121574_v2 (stack40)
        %v93577_v40 = vmul.f32 %v93573_v42, %v149327_v43 (stack54)
        %vm149384_vm3 = vcmp.lt.f32.partialorder %v93958_v50, 0.0004427343 (stack62)
        %v94352_v50 = vor.u32 %v94351_v44, %v94350_v10 (stack47)
        %v96003_v46 = vshrl.u32 %v149355_v29, 19 (stack46)
        %v149391_v24 = vadd.s32 %v157664_v31, %v157091_v37 (stack40)
        %v94757_v45 = vadd.s32 %v94754_v6, %v94749_v45 (stack40)
        %v94759_v22 = vshll.u32 %v94754_v6, 29 (stack45)
        %v94760_v20 = vshrl.u32 %v94754_v6, 3 (stack46)
        %v95158_v23 = vadd.s32 %v95155_v60, %v121574_v2 (stack40)
        %v93581_v8 = vadd.f32 %v93577_v40, %v149269_v8 (stack53)
        %v94353_v30 = vxor.u32 %v94352_v50, %v94348_v53 (stack48)
        %v95575_v34 = vadd.s32 %v95572_v55, %v121564_v0 (stack40)
        %v96000_v9 = vadd.s32 %v149355_v29, %v95992_v41 (stack40)
        %v94761_v42 = vor.u32 %v94760_v20, %v94759_v22 (stack47)
        %v95150_v27 = vadd.s32 %v95146_v27, %v121564_v0 (stack40)
        %v95162_v10 = vadd.s32 2, %v95158_v23 (stack40)
        %vm96427_vm4 = vcmp.lt.u32.totalorder %v149391_v24, %v157091_v37 (stack43)
        %v93585_v43 = vmul.f32 %v93581_v8, %v149327_v43 (stack54)
        %v94356_v53 = vadd.s32 %v94353_v30, %v94348_v53 (stack40)
        %v94362_v44 = vshll.u32 %v94353_v30, 6 (stack45)
        %v94363_v6 = vshrl.u32 %v94353_v30, 26 (stack46)
        %v94762_v60 = vxor.u32 %v94761_v42, %v94757_v45 (stack48)
        %v95166_v55 = vadd.s32 %v95162_v10, %v95150_v27 (stack40)
        %v95168_v41 = vshll.u32 %v95162_v10, 13 (stack45)
        %v95169_v40 = vshrl.u32 %v95162_v10, 19 (stack46)
        %v121234_v50 = vpop.eup %121233 (stack64)
        %v93589_v56 = vadd.f32 %v93585_v43, %v149258_v56 (stack53)
        %v94364_v22 = vor.u32 %v94363_v6, %v94362_v44 (stack47)
        %v95579_v20 = vadd.s32 1, %v95575_v34 (stack40)
        %v96004_v29 = vor.u32 %v96003_v46, %v96002_v25 (stack47)
        %v93954_v25 = vmul.f32 0.6931472, %v121234_v50 (stack65)
        %v94765_v46 = vadd.s32 %v94762_v60, %v94757_v45 (stack40)
        %v94767_v45 = vshll.u32 %v94762_v60, 16 (stack45)
        %v94768_v23 = vshrl.u32 %v94762_v60, 16 (stack46)
        %v93593_v8 = vmul.f32 %v93589_v56, %v149178_v21 (stack54)
        %v94365_v30 = vxor.u32 %v94364_v22, %v94356_v53 (stack48)
        %v95170_v34 = vor.u32 %v95169_v40, %v95168_v41 (stack47)
        %v95583_v12 = vadd.s32 %v95579_v20, %v95567_v12 (stack40)
        %vm93445_vm5 = vcmp.eq.f32.partialorder %v93442_v61, 1.0 (stack68)
        %v93960_v21 = vsel /*vm=*/%vm149384_vm3, /*on_true_vy=*/%v93957_v52, /*on_false_vx=*/%v93954_v25 (stack66)
        %v94769_v61 = vor.u32 %v94768_v23, %v94767_v45 (stack47)
        %v95585_v52 = vshll.u32 %v95579_v20, 17 (stack45)
        %v93597_v32 = vsel /*vm=*/%vm93445_vm5, /*on_true_vy=*/%v149252_v32, /*on_false_vx=*/%v93593_v8 (stack44)
        %v149410_v54 = vxor.u32 2147483648, %v93960_v21 (stack56)
        %v95171_v42 = vxor.u32 %v95170_v34, %v95166_v55 (stack48)
        %v95586_v27 = vshrl.u32 %v95579_v20, 15 (stack46)
        %v93601_v10 = vmul.f32 1.4140625, %v93597_v32 (stack54)
        %v94770_v43 = vxor.u32 %v94769_v61, %v94765_v46 (stack48)
        %v96005_v44 = vxor.u32 %v96004_v29, %v96000_v9 (stack48)
        %vm93964_vm6 = vcmp.lt.f32.partialorder %v149410_v54, 5.0 (stack68)
        %121235 = vrsqrt.f32 %v149410_v54 (stack67)
        %v94368_v6 = vadd.s32 %v94365_v30, %v121574_v2 (stack40)
        %v93604_v60 = vpack.c.bf16 %v157387_v11, %v93601_v10 (stack81)
        %v94773_v41 = vadd.s32 %v94770_v43, %v94765_v46 (stack40)
        %v95587_v40 = vor.u32 %v95586_v27, %v95585_v52 (stack47)
        %v149418_v50 = vadd.s32 %v149391_v24, %v122657_v58 (stack40)
        %120243 = vst [vmem:[%s123356_s30 + $0x3e0] sm:$0xf] /*vst_source=*/%v93604_v60 (stack83)
        %v149424_v56 = vsel /*vm=*/%vm93964_vm6, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v149429_v22 = vsel /*vm=*/%vm93964_vm6, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v94360_v53 = vadd.s32 %v94356_v53, %v121564_v0 (stack40)
        %v95174_v55 = vadd.s32 %v95171_v42, %v95166_v55 (stack40)
        %v149435_v20 = vsel /*vm=*/%vm93964_vm6, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v149440_v29 = vsel /*vm=*/%vm93964_vm6, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v149443_v25 = vadd.f32 -2.5, %v149410_v54 (stack53)
        %v94372_v46 = vadd.s32 5, %v94368_v6 (stack40)
        %v94779_v45 = vshll.u32 %v94770_v43, 24 (stack45)
        %v94780_v23 = vshrl.u32 %v94770_v43, 8 (stack46)
        %v95176_v8 = vshll.u32 %v95171_v42, 15 (stack45)
        %v95177_v30 = vshrl.u32 %v95171_v42, 17 (stack46)
        %v94374_v34 = vxor.u32 %v94372_v46, %v94360_v53 (stack48)
        %v95588_v21 = vxor.u32 %v95587_v40, %v95583_v12 (stack48)
        %v96008_v9 = vadd.s32 %v96005_v44, %v96000_v9 (stack40)
        %v96010_v61 = vshll.u32 %v96005_v44, 15 (stack45)
        %v149448_v52 = vsel /*vm=*/%vm93964_vm6, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %vm94009_vm7 = vcmp.eq.f32.partialorder %v149410_v54, inf (stack70)
        %v94781_v32 = vor.u32 %v94780_v23, %v94779_v45 (stack47)
        %v95178_v42 = vor.u32 %v95177_v30, %v95176_v8 (stack47)
        %v96011_v27 = vshrl.u32 %v96005_v44, 17 (stack46)
        %v94375_v10 = vand.u32.u8 255, %v94374_v34 (stack49)
        %v95591_v12 = vadd.s32 %v95588_v21, %v95583_v12 (stack40)
        %v95593_v43 = vshll.u32 %v95588_v21, 29 (stack45)
        %v95594_v44 = vshrl.u32 %v95588_v21, 3 (stack46)
        %v94782_v6 = vxor.u32 %v94781_v32, %v94773_v41 (stack48)
        %v95179_v60 = vxor.u32 %v95178_v42, %v95174_v55 (stack48)
        %v96012_v40 = vor.u32 %v96011_v27, %v96010_v61 (stack47)
        %v96432_v53 = vadd.s32 %v157667_v26, %v157094_v36 (stack40)
        %v94001_v46 = vsel /*vm=*/%vm93964_vm6, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v94376_v45 = vand.u32 65535, %v94375_v10 (stack50)
        %v95595_v23 = vor.u32 %v95594_v44, %v95593_v43 (stack47)
        %v149458_v31 = vadd.s32 %v157664_v31, %v157095_v13 (stack40)
        %v94785_v8 = vadd.s32 %v94782_v6, %v121564_v0 (stack40)
        %v95182_v55 = vadd.s32 %v95179_v60, %v95174_v55 (stack40)
        %v95184_v30 = vshll.u32 %v95179_v60, 26 (stack45)
        %v95185_v34 = vshrl.u32 %v95179_v60, 6 (stack46)
        %vm94011_vm8 = vcmp.eq.f32.partialorder %v149410_v54, 0.0 (stack71)
        %v94377_v21 = vshrl.u32 %v94376_v45, 1 (stack51)
        %v95596_v61 = vxor.u32 %v95595_v23, %v95591_v12 (stack48)
        %v96013_v32 = vxor.u32 %v96012_v40, %v96008_v9 (stack48)
        %v121236_v42 = vpop.eup %121235 (stack73)
        %v94012_v27 = vand.u32 2147483648, %v149410_v54 (stack72)
        %v94777_v41 = vadd.s32 %v94773_v41, %v121569_v1 (stack40)
        %v94789_v10 = vadd.s32 4, %v94785_v8 (stack40)
        %v95186_v43 = vor.u32 %v95185_v34, %v95184_v30 (stack47)
        %v94008_v44 = vmul.f32 %v121236_v42, %v149410_v54 (stack74)
        %v94378_v6 = vor.u32 16256, %v94377_v21 (stack47)
        %v95599_v12 = vadd.s32 %v95596_v61, %v95591_v12 (stack40)
        %v95601_v60 = vshll.u32 %v95596_v61, 16 (stack45)
        %v94793_v40 = vadd.s32 %v94789_v10, %v94777_v41 (stack40)
        %v94795_v45 = vshll.u32 %v94789_v10, 13 (stack45)
        %v94796_v23 = vshrl.u32 %v94789_v10, 19 (stack46)
        %v95187_v8 = vxor.u32 %v95186_v43, %v95182_v55 (stack48)
        %v94010_v30 = vsel /*vm=*/%vm94009_vm7, /*on_true_vy=*/%v149410_v54, /*on_false_vx=*/%v94008_v44 (stack75)
        %v94379_v34 = vand.u32.u16 65535, %v94378_v6 (stack52)
        %v95602_v21 = vshrl.u32 %v95596_v61, 16 (stack46)
        %v96016_v9 = vadd.s32 %v96013_v32, %v96008_v9 (stack40)
        %v94013_v61 = vsel /*vm=*/%vm94011_vm8, /*on_true_vy=*/%v94012_v27, /*on_false_vx=*/%v94010_v30 (stack76)
        %v94797_v42 = vor.u32 %v94796_v23, %v94795_v45 (stack47)
        %v95190_v55 = vadd.s32 %v95187_v8, %v95182_v55 (stack40)
        %v95196_v27 = vshll.u32 %v95187_v8, 6 (stack45)
        %v94016_v41 = vadd.f32 -3.0, %v94013_v61 (stack53)
        %v120250_v10 = vadd.low.f32.bf16 -1.0, %v94379_v34 (stack53)
        %v95197_v43 = vshrl.u32 %v95187_v8, 26 (stack46)
        %v95603_v44 = vor.u32 %v95602_v21, %v95601_v60 (stack47)
        %v94798_v6 = vxor.u32 %v94797_v42, %v94793_v40 (stack48)
        %v96018_v60 = vshll.u32 %v96013_v32, 26 (stack45)
        %v96019_v32 = vshrl.u32 %v96013_v32, 6 (stack46)
        %v96436_v45 = vadd.s32 1, %v96432_v53 (stack40)
        %v149473_v25 = vsel /*vm=*/%vm93964_vm6, /*on_true_vy=*/%v149443_v25, /*on_false_vx=*/%v94016_v41 (stack44)
        %v94388_v23 = vmul.f32 2.0, %v120250_v10 (stack54)
        %v95198_v8 = vor.u32 %v95197_v43, %v95196_v27 (stack47)
        %v95604_v30 = vxor.u32 %v95603_v44, %v95599_v12 (stack48)
        %v94024_v46 = vmul.f32 %v149473_v25, %v94001_v46 (stack54)
        %v94801_v40 = vadd.s32 %v94798_v6, %v94793_v40 (stack40)
        %v94803_v34 = vshll.u32 %v94798_v6, 15 (stack45)
        %v94804_v21 = vshrl.u32 %v94798_v6, 17 (stack46)
        %v94392_v61 = vadd.f32 -0.99609375, %v94388_v23 (stack53)
        %v95199_v42 = vxor.u32 %v95198_v8, %v95190_v55 (stack48)
        %v95607_v12 = vadd.s32 %v95604_v30, %v95599_v12 (stack40)
        %v95613_v27 = vshll.u32 %v95604_v30, 24 (stack45)
        %v94028_v52 = vadd.f32 %v94024_v46, %v149448_v52 (stack53)
        %v94805_v41 = vor.u32 %v94804_v21, %v94803_v34 (stack47)
        %v95614_v10 = vshrl.u32 %v95604_v30, 8 (stack46)
        %v96020_v43 = vor.u32 %v96019_v32, %v96018_v60 (stack47)
        %v93993_v44 = vsel /*vm=*/%vm93964_vm6, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v149480_v6 = vmax.f32 %v94392_v61, -0.99609375 (stack55)
        %v95202_v60 = vadd.s32 %v95199_v42, %v121569_v1 (stack40)
        %v149486_v53 = vsel /*vm=*/%vm96427_vm4, /*on_true_vy=*/%v96436_v45, /*on_false_vx=*/%v96432_v53 (stack44)
        %v94032_v32 = vmul.f32 %v94028_v52, %v149473_v25 (stack54)
        %v94806_v45 = vxor.u32 %v94805_v41, %v94801_v40 (stack48)
        %v95615_v23 = vor.u32 %v95614_v10, %v95613_v27 (stack47)
        %v96021_v8 = vxor.u32 %v96020_v43, %v96016_v9 (stack48)
        %v94408_v30 = vxor.u32 2147483648, %v149480_v6 (stack56)
        %v95194_v55 = vadd.s32 %v95190_v55, %v121574_v2 (stack40)
        %v95206_v46 = vadd.s32 3, %v95202_v60 (stack40)
        %v149493_v34 = vadd.s32 %v149418_v50, %v121569_v1 (stack40)
        %v94036_v21 = vadd.f32 %v94032_v32, %v93993_v44 (stack53)
        %v94809_v40 = vadd.s32 %v94806_v45, %v94801_v40 (stack40)
        %v94811_v61 = vshll.u32 %v94806_v45, 26 (stack45)
        %v94812_v42 = vshrl.u32 %v94806_v45, 6 (stack46)
        %v93989_v27 = vsel /*vm=*/%vm93964_vm6, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v149499_v52 = vmul.f32 %v94408_v30, %v149480_v6 (stack54)
        %v95210_v41 = vadd.s32 %v95206_v46, %v95194_v55 (stack40)
        %v95212_v10 = vshll.u32 %v95206_v46, 17 (stack45)
        %v94040_v43 = vmul.f32 %v94036_v21, %v149473_v25 (stack54)
        %v94813_v44 = vor.u32 %v94812_v42, %v94811_v61 (stack47)
        %v95213_v60 = vshrl.u32 %v95206_v46, 15 (stack46)
        %v95616_v32 = vxor.u32 %v95615_v23, %v95607_v12 (stack48)
        %vm96422_vm9 = vcmp.lt.u32.totalorder %v149418_v50, %v149391_v24 (stack43)
        %v94413_v45 = vadd.f32 1.0, %v149499_v52 (stack57)
        %v94416_v23 = vmul.f32 -0.5, %v149499_v52 (stack59)
        %v96024_v9 = vadd.s32 %v96021_v8, %v96016_v9 (stack40)
        %v96463_v30 = vshll.u32 %v149493_v34, 13 (stack45)
        %v94044_v55 = vadd.f32 %v94040_v43, %v93989_v27 (stack53)
        %v94814_v46 = vxor.u32 %v94813_v44, %v94809_v40 (stack48)
        %v95214_v21 = vor.u32 %v95213_v60, %v95212_v10 (stack47)
        %v95619_v61 = vadd.s32 %v95616_v32, %v121574_v2 (stack40)
        %121237 = vlog2.f32 %v94413_v45 (stack58)
        %v94419_v42 = vand.u32 2147483647, %v149499_v52 (stack60)
        %v95611_v12 = vadd.s32 %v95607_v12, %v121564_v0 (stack40)
        %v96464_v27 = vshrl.u32 %v149493_v34, 19 (stack46)
        %v94048_v10 = vmul.f32 %v94044_v55, %v149473_v25 (stack54)
        %v94817_v40 = vadd.s32 %v94814_v46, %v94809_v40 (stack40)
        %v94823_v43 = vshll.u32 %v94814_v46, 6 (stack45)
        %v94824_v44 = vshrl.u32 %v94814_v46, 26 (stack46)
        %v94417_v60 = vadd.f32 1.0, %v94416_v23 (stack61)
        %v95215_v32 = vxor.u32 %v95214_v21, %v95210_v41 (stack48)
        %v95623_v45 = vadd.s32 2, %v95619_v61 (stack40)
        %v96030_v23 = vshll.u32 %v96021_v8, 6 (stack45)
        %v94052_v29 = vadd.f32 %v94048_v10, %v149440_v29 (stack53)
        %v94825_v55 = vor.u32 %v94824_v44, %v94823_v43 (stack47)
        %v96028_v46 = vadd.s32 %v96024_v9, %v121569_v1 (stack40)
        %v96031_v8 = vshrl.u32 %v96021_v8, 26 (stack46)
        %v95218_v41 = vadd.s32 %v95215_v32, %v95210_v41 (stack40)
        %v95220_v21 = vshll.u32 %v95215_v32, 29 (stack45)
        %v95221_v61 = vshrl.u32 %v95215_v32, 3 (stack46)
        %v95627_v12 = vadd.s32 %v95623_v45, %v95611_v12 (stack40)
        %v94056_v10 = vmul.f32 %v94052_v29, %v149473_v25 (stack54)
        %v94826_v43 = vxor.u32 %v94825_v55, %v94817_v40 (stack48)
        %v95629_v44 = vshll.u32 %v95623_v45, 13 (stack45)
        %v95630_v32 = vshrl.u32 %v95623_v45, 19 (stack46)
        %v94418_v52 = vmul.f32 %v94417_v60, %v149499_v52 (stack63)
        %v95222_v60 = vor.u32 %v95221_v61, %v95220_v21 (stack47)
        %v96032_v45 = vor.u32 %v96031_v8, %v96030_v23 (stack47)
        %v96444_v23 = vadd.s32 1, %v149486_v53 (stack40)
        %v94060_v20 = vadd.f32 %v94056_v10, %v149435_v20 (stack53)
        %v94821_v40 = vadd.s32 %v94817_v40, %v121564_v0 (stack40)
        %v94829_v29 = vadd.s32 %v94826_v43, %v121574_v2 (stack40)
        %v95631_v55 = vor.u32 %v95630_v32, %v95629_v44 (stack47)
        %v95223_v8 = vxor.u32 %v95222_v60, %v95218_v41 (stack48)
        %v96033_v9 = vxor.u32 %v96032_v45, %v96024_v9 (stack48)
        %v96448_v24 = vsel /*vm=*/%vm96422_vm9, /*on_true_vy=*/%v96444_v23, /*on_false_vx=*/%v149486_v53 (stack44)
        %vm96888_vm10 = vcmp.lt.u32.totalorder %v149458_v31, %v157095_v13 (stack43)
        %v94064_v50 = vmul.f32 %v94060_v20, %v149473_v25 (stack54)
        %v94833_v53 = vadd.s32 5, %v94829_v29 (stack40)
        %v95632_v21 = vxor.u32 %v95631_v55, %v95627_v12 (stack48)
        %v96453_v61 = vadd.s32 %v96448_v24, %v121574_v2 (stack40)
        %v95226_v41 = vadd.s32 %v95223_v8, %v95218_v41 (stack40)
        %v95228_v10 = vshll.u32 %v95223_v8, 16 (stack45)
        %v95229_v43 = vshrl.u32 %v95223_v8, 16 (stack46)
        %v96036_v44 = vadd.s32 %v96033_v9, %v121564_v0 (stack40)
        %v94068_v22 = vadd.f32 %v94064_v50, %v149429_v22 (stack53)
        %v94835_v32 = vxor.u32 %v94833_v53, %v94821_v40 (stack48)
        %v95635_v12 = vadd.s32 %v95632_v21, %v95627_v12 (stack40)
        %v95637_v60 = vshll.u32 %v95632_v21, 15 (stack45)
        %v95230_v45 = vor.u32 %v95229_v43, %v95228_v10 (stack47)
        %v95638_v23 = vshrl.u32 %v95632_v21, 17 (stack46)
        %v96040_v20 = vadd.s32 1, %v96036_v44 (stack40)
        %v96461_v34 = vadd.s32 %v149493_v34, %v96453_v61 (stack40)
        %v121238_v40 = vpop.eup %121237 (stack64)
        %v94072_v29 = vmul.f32 %v94068_v22, %v149473_v25 (stack54)
        %v94836_v55 = vand.u32.u8 255, %v94835_v32 (stack49)
        %v96465_v30 = vor.u32 %v96464_v27, %v96463_v30 (stack47)
        %v149534_v26 = vadd.s32 %v157667_v26, %v157100_v14 (stack40)
        %v94415_v27 = vmul.f32 0.6931472, %v121238_v40 (stack65)
        %v95231_v8 = vxor.u32 %v95230_v45, %v95226_v41 (stack48)
        %v95639_v9 = vor.u32 %v95638_v23, %v95637_v60 (stack47)
        %v96044_v46 = vadd.s32 %v96040_v20, %v96028_v46 (stack40)
        %v94076_v56 = vadd.f32 %v94072_v29, %v149424_v56 (stack53)
        %vm94420_vm11 = vcmp.lt.f32.partialorder %v94419_v42, 0.0004427343 (stack62)
        %v94837_v42 = vand.u32 65535, %v94836_v55 (stack50)
        %v96046_v24 = vshll.u32 %v96040_v20, 17 (stack45)
        %v94421_v52 = vsel /*vm=*/%vm94420_vm11, /*on_true_vy=*/%v94418_v52, /*on_false_vx=*/%v94415_v27 (stack66)
        %v95234_v50 = vadd.s32 %v95231_v8, %v95226_v41 (stack40)
        %v95240_v53 = vshll.u32 %v95231_v8, 24 (stack45)
        %v95241_v21 = vshrl.u32 %v95231_v8, 8 (stack46)
        %v94080_v25 = vmul.f32 %v94076_v56, %v149473_v25 (stack54)
        %v149538_v61 = vxor.u32 2147483648, %v94421_v52 (stack56)
        %v95640_v41 = vxor.u32 %v95639_v9, %v95635_v12 (stack48)
        %v96047_v10 = vshrl.u32 %v96040_v20, 15 (stack46)
        %v93937_v43 = vand.u32 2147483647, %v149351_v7 (stack77)
        %v93969_v54 = vsel /*vm=*/%vm93964_vm6, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v95242_v44 = vor.u32 %v95241_v21, %v95240_v53 (stack47)
        %v96466_v22 = vxor.u32 %v96465_v30, %v96461_v34 (stack48)
        %v94084_v32 = vadd.f32 %v94080_v25, %v93969_v54 (stack53)
        %121239 = vrsqrt.f32 %v149538_v61 (stack67)
        %vm94425_vm12 = vcmp.lt.f32.partialorder %v149538_v61, 5.0 (stack68)
        %v94838_v60 = vshrl.u32 %v94837_v42, 1 (stack51)
        %v95243_v45 = vxor.u32 %v95242_v44, %v95234_v50 (stack48)
        %v93945_v23 = vmul.f32 inf, %v149351_v7 (stack54)
        %v94088_v7 = vmul.f32 %v94084_v32, %v149351_v7 (stack54)
        %v96048_v20 = vor.u32 %v96047_v10, %v96046_v24 (stack47)
        %vm93940_vm13 = vcmp.eq.f32.partialorder %v93937_v43, 1.0 (stack68)
        %v95238_v40 = vadd.s32 %v95234_v50, %v121569_v1 (stack40)
        %v95246_v29 = vadd.s32 %v95243_v45, %v121564_v0 (stack40)
        %v149552_v55 = vadd.s32 %v149458_v31, %v122657_v58 (stack40)
        %v94092_v30 = vsel /*vm=*/%vm93940_vm13, /*on_true_vy=*/%v93945_v23, /*on_false_vx=*/%v94088_v7 (stack44)
        %v149557_v27 = vsel /*vm=*/%vm94425_vm12, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v149562_v8 = vsel /*vm=*/%vm94425_vm12, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v149565_v9 = vadd.f32 -2.5, %v149538_v61 (stack53)
        %v94096_v56 = vmul.f32 1.4140625, %v94092_v30 (stack54)
        %v94839_v42 = vor.u32 16256, %v94838_v60 (stack47)
        %v95250_v24 = vadd.s32 4, %v95246_v29 (stack40)
        %v95643_v12 = vadd.s32 %v95640_v41, %v95635_v12 (stack40)
        %v95645_v52 = vshll.u32 %v95640_v41, 26 (stack45)
        %v95646_v50 = vshrl.u32 %v95640_v41, 6 (stack46)
        %v96049_v53 = vxor.u32 %v96048_v20, %v96044_v46 (stack48)
        %v96469_v34 = vadd.s32 %v96466_v22, %v96461_v34 (stack40)
        %v94099_v21 = vpack.c.bf16 %v157387_v11, %v94096_v56 (stack81)
        %vm94470_vm14 = vcmp.eq.f32.partialorder %v149538_v61, inf (stack70)
        %v94840_v25 = vand.u32.u16 65535, %v94839_v42 (stack52)
        %v95254_v41 = vadd.s32 %v95250_v24, %v95238_v40 (stack40)
        %v95256_v10 = vshll.u32 %v95250_v24, 13 (stack45)
        %v95257_v43 = vshrl.u32 %v95250_v24, 19 (stack46)
        %v95647_v54 = vor.u32 %v95646_v50, %v95645_v52 (stack47)
        %v96052_v46 = vadd.s32 %v96049_v53, %v96044_v46 (stack40)
        %v96054_v44 = vshll.u32 %v96049_v53, 29 (stack45)
        %120249 = vst [vmem:[%s123356_s30 + $0x64] sm:$0xf] /*vst_source=*/%v94099_v21 (stack83)
        %v120252_v32 = vadd.low.f32.bf16 -1.0, %v94840_v25 (stack53)
        %v96055_v60 = vshrl.u32 %v96049_v53, 3 (stack46)
        %v96471_v45 = vshll.u32 %v96466_v22, 15 (stack45)
        %v96472_v22 = vshrl.u32 %v96466_v22, 17 (stack46)
        %vm94472_vm15 = vcmp.eq.f32.partialorder %v149538_v61, 0.0 (stack71)
        %v95258_v23 = vor.u32 %v95257_v43, %v95256_v10 (stack47)
        %v95648_v7 = vxor.u32 %v95647_v54, %v95643_v12 (stack48)
        %v96897_v20 = vadd.s32 1, %v149534_v26 (stack40)
        %v94849_v40 = vmul.f32 2.0, %v120252_v32 (stack54)
        %v96056_v29 = vor.u32 %v96055_v60, %v96054_v44 (stack47)
        %v96473_v30 = vor.u32 %v96472_v22, %v96471_v45 (stack47)
        %v157684_v56 = vld [vmem:[#allocation150_spill] sm:$0xff] (stack84)
        %v149574_v42 = vadd.s32 %v157684_v56, %v122651_v47 (stack40)
        %v95259_v24 = vxor.u32 %v95258_v23, %v95254_v41 (stack48)
        %v95651_v12 = vadd.s32 %v95648_v7, %v95643_v12 (stack40)
        %v95657_v52 = vshll.u32 %v95648_v7, 6 (stack45)
        %v95658_v50 = vshrl.u32 %v95648_v7, 26 (stack46)
        %v121240_v53 = vpop.eup %121239 (stack73)
        %v94853_v21 = vadd.f32 -0.99609375, %v94849_v40 (stack53)
        %v96057_v25 = vxor.u32 %v96056_v29, %v96052_v46 (stack48)
        %v96474_v10 = vxor.u32 %v96473_v30, %v96469_v34 (stack48)
        %v149580_v26 = vsel /*vm=*/%vm96888_vm10, /*on_true_vy=*/%v96897_v20, /*on_false_vx=*/%v149534_v26 (stack44)
        %v94469_v43 = vmul.f32 %v121240_v53, %v149538_v61 (stack74)
        %v95262_v41 = vadd.s32 %v95259_v24, %v95254_v41 (stack40)
        %v95264_v54 = vshll.u32 %v95259_v24, 15 (stack45)
        %v95265_v44 = vshrl.u32 %v95259_v24, 17 (stack46)
        %v94473_v32 = vand.u32 2147483648, %v149538_v61 (stack72)
        %v149584_v60 = vmax.f32 %v94853_v21, -0.99609375 (stack55)
        %v95659_v45 = vor.u32 %v95658_v50, %v95657_v52 (stack47)
        %v96060_v46 = vadd.s32 %v96057_v25, %v96052_v46 (stack40)
        %v94471_v22 = vsel /*vm=*/%vm94470_vm14, /*on_true_vy=*/%v149538_v61, /*on_false_vx=*/%v94469_v43 (stack75)
        %v95266_v23 = vor.u32 %v95265_v44, %v95264_v54 (stack47)
        %v96062_v7 = vshll.u32 %v96057_v25, 16 (stack45)
        %v96063_v20 = vshrl.u32 %v96057_v25, 16 (stack46)
        %v94450_v40 = vsel /*vm=*/%vm94425_vm12, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v94454_v29 = vsel /*vm=*/%vm94425_vm12, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v94474_v30 = vsel /*vm=*/%vm94472_vm15, /*on_true_vy=*/%v94473_v32, /*on_false_vx=*/%v94471_v22 (stack76)
        %v94869_v24 = vxor.u32 2147483648, %v149584_v60 (stack56)
        %v94477_v52 = vadd.f32 -3.0, %v94474_v30 (stack53)
        %v95267_v50 = vxor.u32 %v95266_v23, %v95262_v41 (stack48)
        %v95660_v53 = vxor.u32 %v95659_v45, %v95651_v12 (stack48)
        %v96064_v21 = vor.u32 %v96063_v20, %v96062_v7 (stack47)
        %v94458_v25 = vsel /*vm=*/%vm94425_vm12, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v94462_v43 = vsel /*vm=*/%vm94425_vm12, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v149605_v54 = vmul.f32 %v94869_v24, %v149584_v60 (stack54)
        %v96477_v34 = vadd.s32 %v96474_v10, %v96469_v34 (stack40)
        %v149610_v9 = vsel /*vm=*/%vm94425_vm12, /*on_true_vy=*/%v149565_v9, /*on_false_vx=*/%v94477_v52 (stack44)
        %v95270_v41 = vadd.s32 %v95267_v50, %v95262_v41 (stack40)
        %v95272_v44 = vshll.u32 %v95267_v50, 26 (stack45)
        %v95273_v32 = vshrl.u32 %v95267_v50, 6 (stack46)
        %vm96883_vm0 = vcmp.lt.u32.totalorder %v149552_v55, %v149458_v31 (stack43)
        %v94485_v45 = vmul.f32 %v149610_v9, %v94462_v43 (stack54)
        %v94874_v22 = vadd.f32 1.0, %v149605_v54 (stack57)
        %v96479_v23 = vshll.u32 %v96474_v10, 26 (stack45)
        %v149618_v7 = vadd.s32 %v149552_v55, %v121569_v1 (stack40)
        %v95274_v20 = vor.u32 %v95273_v32, %v95272_v44 (stack47)
        %v95663_v30 = vadd.s32 %v95660_v53, %v121569_v1 (stack40)
        %v96065_v24 = vxor.u32 %v96064_v21, %v96060_v46 (stack48)
        %v96480_v10 = vshrl.u32 %v96474_v10, 6 (stack46)
        %v94489_v52 = vadd.f32 %v94485_v45, %v94458_v25 (stack53)
        %121241 = vlog2.f32 %v94874_v22 (stack58)
        %v94877_v50 = vmul.f32 -0.5, %v149605_v54 (stack59)
        %v95655_v12 = vadd.s32 %v95651_v12, %v121574_v2 (stack40)
        %v95275_v53 = vxor.u32 %v95274_v20, %v95270_v41 (stack48)
        %v95667_v21 = vadd.s32 3, %v95663_v30 (stack40)
        %v96068_v46 = vadd.s32 %v96065_v24, %v96060_v46 (stack40)
        %v96074_v25 = vshll.u32 %v96065_v24, 24 (stack45)
        %v94493_v43 = vmul.f32 %v94489_v52, %v149610_v9 (stack54)
        %v94880_v44 = vand.u32 2147483647, %v149605_v54 (stack60)
        %v96075_v32 = vshrl.u32 %v96065_v24, 8 (stack46)
        %v96481_v45 = vor.u32 %v96480_v10, %v96479_v23 (stack47)
        %v95278_v41 = vadd.s32 %v95275_v53, %v95270_v41 (stack40)
        %v95284_v22 = vshll.u32 %v95275_v53, 6 (stack45)
        %v95285_v23 = vshrl.u32 %v95275_v53, 26 (stack46)
        %v95671_v20 = vadd.s32 %v95667_v21, %v95655_v12 (stack40)
        %v94497_v29 = vadd.f32 %v94493_v43, %v94454_v29 (stack53)
        %v94878_v30 = vadd.f32 1.0, %v94877_v50 (stack61)
        %v95673_v24 = vshll.u32 %v95667_v21, 17 (stack45)
        %v95674_v10 = vshrl.u32 %v95667_v21, 15 (stack46)
        %v95286_v52 = vor.u32 %v95285_v23, %v95284_v22 (stack47)
        %v96072_v50 = vadd.s32 %v96068_v46, %v121564_v0 (stack40)
        %v96076_v12 = vor.u32 %v96075_v32, %v96074_v25 (stack47)
        %v96482_v53 = vxor.u32 %v96481_v45, %v96477_v34 (stack48)
        %v94501_v21 = vmul.f32 %v94497_v29, %v149610_v9 (stack54)
        %v95282_v25 = vadd.s32 %v95278_v41, %v121564_v0 (stack40)
        %v95675_v43 = vor.u32 %v95674_v10, %v95673_v24 (stack47)
        %v96905_v32 = vadd.s32 1, %v149580_v26 (stack40)
        %v95287_v45 = vxor.u32 %v95286_v52, %v95278_v41 (stack48)
        %v96077_v46 = vxor.u32 %v96076_v12, %v96068_v46 (stack48)
        %v96485_v34 = vadd.s32 %v96482_v53, %v96477_v34 (stack40)
        %v96491_v41 = vshll.u32 %v96482_v53, 6 (stack45)
        %v94505_v40 = vadd.f32 %v94501_v21, %v94450_v40 (stack53)
        %v95676_v22 = vxor.u32 %v95675_v43, %v95671_v20 (stack48)
        %v96492_v23 = vshrl.u32 %v96482_v53, 26 (stack46)
        %v96909_v31 = vsel /*vm=*/%vm96883_vm0, /*on_true_vy=*/%v96905_v32, /*on_false_vx=*/%v149580_v26 (stack44)
        %v95290_v55 = vadd.s32 %v95287_v45, %v121574_v2 (stack40)
        %v96080_v26 = vadd.s32 %v96077_v46, %v121574_v2 (stack40)
        %v96914_v29 = vadd.s32 %v96909_v31, %v121574_v2 (stack40)
        %v96924_v24 = vshll.u32 %v149618_v7, 13 (stack45)
        %v94509_v10 = vmul.f32 %v94505_v40, %v149610_v9 (stack54)
        %v95679_v20 = vadd.s32 %v95676_v22, %v95671_v20 (stack40)
        %v95681_v52 = vshll.u32 %v95676_v22, 29 (stack45)
        %v95682_v12 = vshrl.u32 %v95676_v22, 3 (stack46)
        %v95294_v53 = vadd.s32 5, %v95290_v55 (stack40)
        %v96084_v21 = vadd.s32 2, %v96080_v26 (stack40)
        %v96493_v43 = vor.u32 %v96492_v23, %v96491_v41 (stack47)
        %v96922_v32 = vadd.s32 %v149618_v7, %v96914_v29 (stack40)
        %v94513_v8 = vadd.f32 %v94509_v10, %v149562_v8 (stack53)
        %v94879_v54 = vmul.f32 %v94878_v30, %v149605_v54 (stack63)
        %v95683_v30 = vor.u32 %v95682_v12, %v95681_v52 (stack47)
        %v96925_v7 = vshrl.u32 %v149618_v7, 19 (stack46)
        %v121242_v45 = vpop.eup %121241 (stack64)
        %v95296_v25 = vxor.u32 %v95294_v53, %v95282_v25 (stack48)
        %v96088_v50 = vadd.s32 %v96084_v21, %v96072_v50 (stack40)
        %v96090_v46 = vshll.u32 %v96084_v21, 13 (stack45)
        %v96091_v41 = vshrl.u32 %v96084_v21, 19 (stack46)
        %v94517_v40 = vmul.f32 %v94513_v8, %v149610_v9 (stack54)
        %v94876_v22 = vmul.f32 0.6931472, %v121242_v45 (stack65)
        %v95684_v23 = vxor.u32 %v95683_v30, %v95679_v20 (stack48)
        %v96494_v31 = vxor.u32 %v96493_v43, %v96485_v34 (stack48)
        %vm94881_vm1 = vcmp.lt.f32.partialorder %v94880_v44, 0.0004427343 (stack62)
        %v95297_v44 = vand.u32.u8 255, %v95296_v25 (stack49)
        %v96092_v55 = vor.u32 %v96091_v41, %v96090_v46 (stack47)
        %v96926_v26 = vor.u32 %v96925_v7, %v96924_v24 (stack47)
        %v94521_v27 = vadd.f32 %v94517_v40, %v149557_v27 (stack53)
        %v94882_v29 = vsel /*vm=*/%vm94881_vm1, /*on_true_vy=*/%v94879_v54, /*on_false_vx=*/%v94876_v22 (stack66)
        %v95687_v24 = vadd.s32 %v95684_v23, %v95679_v20 (stack40)
        %v149644_v10 = vxor.u32 2147483648, %v94882_v29 (stack56)
        %v95689_v20 = vshll.u32 %v95684_v23, 16 (stack45)
        %v95690_v52 = vshrl.u32 %v95684_v23, 16 (stack46)
        %v96093_v12 = vxor.u32 %v96092_v55, %v96088_v50 (stack48)
        %v94525_v53 = vmul.f32 %v94521_v27, %v149610_v9 (stack54)
        %v96927_v21 = vxor.u32 %v96926_v26, %v96922_v32 (stack48)
        %vm97383_vm2 = vcmp.lt.u32.totalorder %v149574_v42, %v122651_v47 (stack43)
        %v94398_v43 = vand.u32 2147483647, %v149480_v6 (stack77)
        %v94438_v8 = vsel /*vm=*/%vm94425_vm12, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %121243 = vrsqrt.f32 %v149644_v10 (stack67)
        %v95298_v54 = vand.u32 65535, %v95297_v44 (stack50)
        %v94406_v30 = vmul.f32 inf, %v149480_v6 (stack54)
        %v94529_v7 = vadd.f32 %v94525_v53, %v94438_v8 (stack53)
        %v94430_v45 = vsel /*vm=*/%vm94425_vm12, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v94434_v61 = vsel /*vm=*/%vm94425_vm12, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v94859_v25 = vand.u32 2147483647, %v149584_v60 (stack77)
        %v95691_v46 = vor.u32 %v95690_v52, %v95689_v20 (stack47)
        %v94533_v41 = vmul.f32 %v94529_v7, %v149610_v9 (stack54)
        %v149664_v40 = vmul.f32 inf, %v149584_v60 (stack54)
        %v96489_v34 = vadd.s32 %v96485_v34, %v121569_v1 (stack40)
        %v96497_v22 = vadd.s32 %v96494_v31, %v121564_v0 (stack40)
        %vm149668_vm3 = vcmp.eq.f32.partialorder %v94398_v43, 1.0 (stack68)
        %v149673_v31 = vadd.f32 -2.5, %v149644_v10 (stack53)
        %v95299_v44 = vshrl.u32 %v95298_v54, 1 (stack51)
        %v95692_v55 = vxor.u32 %v95691_v46, %v95687_v24 (stack48)
        %v149677_v26 = vadd.s32 %v149574_v42, %v122657_v58 (stack40)
        %v94537_v27 = vadd.f32 %v94533_v41, %v94434_v61 (stack53)
        %v96096_v50 = vadd.s32 %v96093_v12, %v96088_v50 (stack40)
        %v96098_v29 = vshll.u32 %v96093_v12, 15 (stack45)
        %v96099_v20 = vshrl.u32 %v96093_v12, 17 (stack46)
        %v95300_v52 = vor.u32 16256, %v95299_v44 (stack47)
        %v95695_v24 = vadd.s32 %v95692_v55, %v95687_v24 (stack40)
        %v95701_v12 = vshll.u32 %v95692_v55, 24 (stack45)
        %v95702_v53 = vshrl.u32 %v95692_v55, 8 (stack46)
        %v94541_v9 = vmul.f32 %v94537_v27, %v149610_v9 (stack54)
        %vm94886_vm4 = vcmp.lt.f32.partialorder %v149644_v10, 5.0 (stack68)
        %vm94931_vm5 = vcmp.eq.f32.partialorder %v149644_v10, inf (stack70)
        %v96100_v43 = vor.u32 %v96099_v20, %v96098_v29 (stack47)
        %v96501_v8 = vadd.s32 1, %v96497_v22 (stack40)
        %v149682_v32 = vadd.s32 %v96927_v21, %v96922_v32 (stack40)
        %vm94933_vm6 = vcmp.eq.f32.partialorder %v149644_v10, 0.0 (stack71)
        %v95301_v54 = vand.u32.u16 65535, %v95300_v52 (stack52)
        %v95703_v7 = vor.u32 %v95702_v53, %v95701_v12 (stack47)
        %v96932_v61 = vshll.u32 %v96927_v21, 15 (stack45)
        %v94545_v45 = vadd.f32 %v94541_v9, %v94430_v45 (stack53)
        %v96101_v46 = vxor.u32 %v96100_v43, %v96096_v50 (stack48)
        %v96505_v41 = vadd.s32 %v96501_v8, %v96489_v34 (stack40)
        %v96507_v34 = vshll.u32 %v96501_v8, 17 (stack45)
        %v120254_v22 = vadd.low.f32.bf16 -1.0, %v95301_v54 (stack53)
        %v95704_v44 = vxor.u32 %v95703_v7, %v95695_v24 (stack48)
        %v96508_v55 = vshrl.u32 %v96501_v8, 15 (stack46)
        %v96933_v21 = vshrl.u32 %v96927_v21, 17 (stack46)
        %v94549_v6 = vmul.f32 %v94545_v45, %v149480_v6 (stack54)
        %v96104_v27 = vadd.s32 %v96101_v46, %v96096_v50 (stack40)
        %v96106_v50 = vshll.u32 %v96101_v46, 26 (stack45)
        %v96107_v29 = vshrl.u32 %v96101_v46, 6 (stack46)
        %v95310_v20 = vmul.f32 2.0, %v120254_v22 (stack54)
        %v95707_v52 = vadd.s32 %v95704_v44, %v121564_v0 (stack40)
        %v96509_v12 = vor.u32 %v96508_v55, %v96507_v34 (stack47)
        %v96934_v53 = vor.u32 %v96933_v21, %v96932_v61 (stack47)
        %v121244_v9 = vpop.eup %121243 (stack73)
        %v94553_v30 = vsel /*vm=*/%vm149668_vm3, /*on_true_vy=*/%v94406_v30, /*on_false_vx=*/%v94549_v6 (stack44)
        %v95699_v23 = vadd.s32 %v95695_v24, %v121569_v1 (stack40)
        %v96108_v24 = vor.u32 %v96107_v29, %v96106_v50 (stack47)
        %v157687_v43 = vld [vmem:[#allocation112_spill] sm:$0xff] (stack84)
        %v97388_v8 = vadd.s32 %v157687_v43, %v157068_v28 (stack40)
        %v94557_v54 = vmul.f32 1.4140625, %v94553_v30 (stack54)
        %v94930_v7 = vmul.f32 %v121244_v9, %v149644_v10 (stack74)
        %v95314_v61 = vadd.f32 -0.99609375, %v95310_v20 (stack53)
        %v95711_v45 = vadd.s32 4, %v95707_v52 (stack40)
        %v94934_v46 = vand.u32 2147483648, %v149644_v10 (stack72)
        %v96109_v34 = vxor.u32 %v96108_v24, %v96104_v27 (stack48)
        %v96510_v22 = vxor.u32 %v96509_v12, %v96505_v41 (stack48)
        %v96935_v44 = vxor.u32 %v96934_v53, %v149682_v32 (stack48)
        %v94560_v55 = vpack.c.bf16 %v157387_v11, %v94557_v54 (stack81)
        %v94932_v21 = vsel /*vm=*/%vm94931_vm5, /*on_true_vy=*/%v149644_v10, /*on_false_vx=*/%v94930_v7 (stack75)
        %v149699_v6 = vmax.f32 %v95314_v61, -0.99609375 (stack55)
        %v95715_v50 = vadd.s32 %v95711_v45, %v95699_v23 (stack40)
        %v94935_v29 = vsel /*vm=*/%vm94933_vm6, /*on_true_vy=*/%v94934_v46, /*on_false_vx=*/%v94932_v21 (stack76)
        %v95717_v20 = vshll.u32 %v95711_v45, 13 (stack45)
        %v95718_v52 = vshrl.u32 %v95711_v45, 19 (stack46)
        %v96112_v27 = vadd.s32 %v96109_v34, %v96104_v27 (stack40)
        %120251 = vst [vmem:[%s123356_s30 + $0xe4] sm:$0xf] /*vst_source=*/%v94560_v55 (stack83)
        %v149707_v12 = vsel /*vm=*/%vm94886_vm4, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v149712_v53 = vsel /*vm=*/%vm94886_vm4, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v94938_v9 = vadd.f32 -3.0, %v94935_v29 (stack53)
        %v95330_v30 = vxor.u32 2147483648, %v149699_v6 (stack56)
        %v94911_v23 = vsel /*vm=*/%vm94886_vm4, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v95719_v24 = vor.u32 %v95718_v52, %v95717_v20 (stack47)
        %v96118_v54 = vshll.u32 %v96109_v34, 6 (stack45)
        %v96119_v7 = vshrl.u32 %v96109_v34, 26 (stack46)
        %v94923_v61 = vsel /*vm=*/%vm94886_vm4, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v149724_v31 = vsel /*vm=*/%vm94886_vm4, /*on_true_vy=*/%v149673_v31, /*on_false_vx=*/%v94938_v9 (stack44)
        %v149727_v45 = vmul.f32 %v95330_v30, %v149699_v6 (stack54)
        %v96513_v41 = vadd.s32 %v96510_v22, %v96505_v41 (stack40)
        %v94946_v46 = vmul.f32 %v149724_v31, %v94923_v61 (stack54)
        %v95720_v34 = vxor.u32 %v95719_v24, %v95715_v50 (stack48)
        %v96120_v55 = vor.u32 %v96119_v7, %v96118_v54 (stack47)
        %v96515_v21 = vshll.u32 %v96510_v22, 29 (stack45)
        %vm97378_vm7 = vcmp.lt.u32.totalorder %v149677_v26, %v149574_v42 (stack43)
        %v94915_v29 = vsel /*vm=*/%vm94886_vm4, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v94919_v20 = vsel /*vm=*/%vm94886_vm4, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v95335_v52 = vadd.f32 1.0, %v149727_v45 (stack57)
        %v96516_v22 = vshrl.u32 %v96510_v22, 3 (stack46)
        %v94950_v9 = vadd.f32 %v94946_v46, %v94919_v20 (stack53)
        %v95723_v50 = vadd.s32 %v95720_v34, %v95715_v50 (stack40)
        %v95725_v30 = vshll.u32 %v95720_v34, 15 (stack45)
        %v95726_v24 = vshrl.u32 %v95720_v34, 17 (stack46)
        %121245 = vlog2.f32 %v95335_v52 (stack58)
        %v96116_v54 = vadd.s32 %v96112_v27, %v121574_v2 (stack40)
        %v96121_v27 = vxor.u32 %v96120_v55, %v96112_v27 (stack48)
        %v97392_v7 = vadd.s32 1, %v97388_v8 (stack40)
        %v94954_v61 = vmul.f32 %v94950_v9, %v149724_v31 (stack54)
        %v95727_v46 = vor.u32 %v95726_v24, %v95725_v30 (stack47)
        %v96517_v34 = vor.u32 %v96516_v22, %v96515_v21 (stack47)
        %v96938_v32 = vadd.s32 %v96935_v44, %v149682_v32 (stack40)
        %v95338_v55 = vmul.f32 -0.5, %v149727_v45 (stack59)
        %v96124_v21 = vadd.s32 %v96121_v27, %v121569_v1 (stack40)
        %v96940_v20 = vshll.u32 %v96935_v44, 26 (stack45)
        %v96941_v44 = vshrl.u32 %v96935_v44, 6 (stack46)
        %v94958_v29 = vadd.f32 %v94954_v61, %v94915_v29 (stack53)
        %v95728_v52 = vxor.u32 %v95727_v46, %v95723_v50 (stack48)
        %v96518_v22 = vxor.u32 %v96517_v34, %v96513_v41 (stack48)
        %v97396_v8 = vsel /*vm=*/%vm97383_vm2, /*on_true_vy=*/%v97392_v7, /*on_false_vx=*/%v97388_v8 (stack44)
        %v95341_v9 = vand.u32 2147483647, %v149727_v45 (stack60)
        %v96128_v30 = vadd.s32 3, %v96124_v21 (stack40)
        %v96942_v24 = vor.u32 %v96941_v44, %v96940_v20 (stack47)
        %v97400_v27 = vadd.s32 1, %v97396_v8 (stack40)
        %v94962_v7 = vmul.f32 %v94958_v29, %v149724_v31 (stack54)
        %v95731_v50 = vadd.s32 %v95728_v52, %v95723_v50 (stack40)
        %v95733_v61 = vshll.u32 %v95728_v52, 26 (stack45)
        %v95734_v46 = vshrl.u32 %v95728_v52, 6 (stack46)
        %v96132_v54 = vadd.s32 %v96128_v30, %v96116_v54 (stack40)
        %v96134_v34 = vshll.u32 %v96128_v30, 17 (stack45)
        %v96135_v21 = vshrl.u32 %v96128_v30, 15 (stack46)
        %v96521_v41 = vadd.s32 %v96518_v22, %v96513_v41 (stack40)
        %v94966_v23 = vadd.f32 %v94962_v7, %v94911_v23 (stack53)
        %v95735_v20 = vor.u32 %v95734_v46, %v95733_v61 (stack47)
        %v96523_v44 = vshll.u32 %v96518_v22, 16 (stack45)
        %v96524_v29 = vshrl.u32 %v96518_v22, 16 (stack46)
        %v95339_v55 = vadd.f32 1.0, %v95338_v55 (stack61)
        %v96136_v52 = vor.u32 %v96135_v21, %v96134_v34 (stack47)
        %v96943_v22 = vxor.u32 %v96942_v24, %v96938_v32 (stack48)
        %v97404_v42 = vsel /*vm=*/%vm97378_vm7, /*on_true_vy=*/%v97400_v27, /*on_false_vx=*/%v97396_v8 (stack44)
        %v94970_v8 = vmul.f32 %v94966_v23, %v149724_v31 (stack54)
        %v95736_v30 = vxor.u32 %v95735_v20, %v95731_v50 (stack48)
        %v96525_v24 = vor.u32 %v96524_v29, %v96523_v44 (stack47)
        %v97409_v27 = vadd.s32 %v97404_v42, %v121574_v2 (stack40)
        %v96137_v7 = vxor.u32 %v96136_v52, %v96132_v54 (stack48)
        %v149754_v32 = vadd.s32 %v96943_v22, %v96938_v32 (stack40)
        %v96952_v61 = vshll.u32 %v96943_v22, 6 (stack45)
        %v96953_v46 = vshrl.u32 %v96943_v22, 26 (stack46)
        %v94974_v53 = vadd.f32 %v94970_v8, %v149712_v53 (stack53)
        %v95739_v50 = vadd.s32 %v95736_v30, %v95731_v50 (stack40)
        %v95745_v34 = vshll.u32 %v95736_v30, 6 (stack45)
        %v95746_v21 = vshrl.u32 %v95736_v30, 26 (stack46)
        %v96140_v54 = vadd.s32 %v96137_v7, %v96132_v54 (stack40)
        %v96142_v23 = vshll.u32 %v96137_v7, 29 (stack45)
        %v96143_v20 = vshrl.u32 %v96137_v7, 3 (stack46)
        %v96526_v44 = vxor.u32 %v96525_v24, %v96521_v41 (stack48)
        %v121246_v29 = vpop.eup %121245 (stack64)
        %v94903_v52 = vsel /*vm=*/%vm94886_vm4, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v94978_v22 = vmul.f32 %v94974_v53, %v149724_v31 (stack54)
        %v95747_v42 = vor.u32 %v95746_v21, %v95745_v34 (stack47)
        %v97413_v26 = vadd.s32 %v149677_v26, %v121569_v1 (stack40)
        %v95337_v8 = vmul.f32 0.6931472, %v121246_v29 (stack65)
        %v95340_v45 = vmul.f32 %v95339_v55, %v149727_v45 (stack63)
        %v96144_v55 = vor.u32 %v96143_v20, %v96142_v23 (stack47)
        %v96529_v41 = vadd.s32 %v96526_v44, %v96521_v41 (stack40)
        %v94982_v30 = vadd.f32 %v94978_v22, %v94903_v52 (stack53)
        %vm95342_vm8 = vcmp.lt.f32.partialorder %v95341_v9, 0.0004427343 (stack62)
        %v95748_v9 = vxor.u32 %v95747_v42, %v95739_v50 (stack48)
        %v96954_v24 = vor.u32 %v96953_v46, %v96952_v61 (stack47)
        %v94899_v7 = vsel /*vm=*/%vm94886_vm4, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v95343_v61 = vsel /*vm=*/%vm95342_vm8, /*on_true_vy=*/%v95340_v45, /*on_false_vx=*/%v95337_v8 (stack66)
        %v96145_v46 = vxor.u32 %v96144_v55, %v96140_v54 (stack48)
        %v97417_v27 = vadd.s32 %v97413_v26, %v97409_v27 (stack40)
        %v94986_v53 = vmul.f32 %v94982_v30, %v149724_v31 (stack54)
        %v149768_v34 = vxor.u32 2147483648, %v95343_v61 (stack56)
        %v96535_v21 = vshll.u32 %v96526_v44, 24 (stack45)
        %v96536_v23 = vshrl.u32 %v96526_v44, 8 (stack46)
        %v96148_v54 = vadd.s32 %v96145_v46, %v96140_v54 (stack40)
        %v96150_v20 = vshll.u32 %v96145_v46, 16 (stack45)
        %v96151_v44 = vshrl.u32 %v96145_v46, 16 (stack46)
        %v96955_v29 = vxor.u32 %v96954_v24, %v149754_v32 (stack48)
        %v94895_v10 = vsel /*vm=*/%vm94886_vm4, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v94990_v52 = vadd.f32 %v94986_v53, %v94899_v7 (stack53)
        %v95320_v22 = vand.u32 2147483647, %v149699_v6 (stack77)
        %121247 = vrsqrt.f32 %v149768_v34 (stack67)
        %vm95347_vm9 = vcmp.lt.f32.partialorder %v149768_v34, 5.0 (stack68)
        %v95751_v42 = vadd.s32 %v95748_v9, %v121574_v2 (stack40)
        %v96152_v8 = vor.u32 %v96151_v44, %v96150_v20 (stack47)
        %v97419_v45 = vshll.u32 %v97413_v26, 13 (stack45)
        %v94994_v55 = vmul.f32 %v94990_v52, %v149724_v31 (stack54)
        %v95743_v50 = vadd.s32 %v95739_v50, %v121564_v0 (stack40)
        %v96537_v30 = vor.u32 %v96536_v23, %v96535_v21 (stack47)
        %v97420_v26 = vshrl.u32 %v97413_v26, 19 (stack46)
        %vm149782_vm10 = vcmp.eq.f32.partialorder %v94859_v25, 1.0 (stack68)
        %v149787_v9 = vadd.f32 -2.5, %v149768_v34 (stack53)
        %v96153_v24 = vxor.u32 %v96152_v8, %v96148_v54 (stack48)
        %v96533_v7 = vadd.s32 %v96529_v41, %v121564_v0 (stack40)
        %v96950_v32 = vadd.s32 %v149754_v32, %v121569_v1 (stack40)
        %v94998_v61 = vadd.f32 %v94994_v55, %v94895_v10 (stack53)
        %v149795_v46 = vsel /*vm=*/%vm95347_vm9, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v149800_v53 = vsel /*vm=*/%vm95347_vm9, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v149805_v21 = vsel /*vm=*/%vm95347_vm9, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v95755_v23 = vadd.s32 5, %v95751_v42 (stack40)
        %v96156_v54 = vadd.s32 %v96153_v24, %v96148_v54 (stack40)
        %v96162_v20 = vshll.u32 %v96153_v24, 24 (stack45)
        %v96163_v44 = vshrl.u32 %v96153_v24, 8 (stack46)
        %v95002_v31 = vmul.f32 %v94998_v61, %v149724_v31 (stack54)
        %v96538_v41 = vxor.u32 %v96537_v30, %v96529_v41 (stack48)
        %v96958_v29 = vadd.s32 %v96955_v29, %v121564_v0 (stack40)
        %v97421_v10 = vor.u32 %v97420_v26, %v97419_v45 (stack47)
        %vm95392_vm11 = vcmp.eq.f32.partialorder %v149768_v34, inf (stack70)
        %v95395_v52 = vand.u32 2147483648, %v149768_v34 (stack72)
        %v95757_v42 = vxor.u32 %v95755_v23, %v95743_v50 (stack48)
        %v96164_v8 = vor.u32 %v96163_v44, %v96162_v20 (stack47)
        %v149813_v45 = vadd.s32 %v157684_v56, %v157070_v38 (stack40)
        %v95006_v12 = vadd.f32 %v95002_v31, %v149707_v12 (stack53)
        %vm95394_vm12 = vcmp.eq.f32.partialorder %v149768_v34, 0.0 (stack71)
        %v96541_v55 = vadd.s32 %v96538_v41, %v121574_v2 (stack40)
        %v96962_v50 = vadd.s32 1, %v96958_v29 (stack40)
        %v97422_v30 = vxor.u32 %v97421_v10, %v97417_v27 (stack48)
        %v95758_v26 = vand.u32.u8 255, %v95757_v42 (stack49)
        %v96160_v24 = vadd.s32 %v96156_v54, %v121569_v1 (stack40)
        %v96165_v61 = vxor.u32 %v96164_v8, %v96156_v54 (stack48)
        %vm97844_vm13 = vcmp.lt.u32.totalorder %v149813_v45, %v157070_v38 (stack43)
        %v95010_v60 = vmul.f32 %v95006_v12, %v149584_v60 (stack54)
        %v96545_v23 = vadd.s32 2, %v96541_v55 (stack40)
        %v96966_v32 = vadd.s32 %v96962_v50, %v96950_v32 (stack40)
        %v96968_v54 = vshll.u32 %v96962_v50, 17 (stack45)
        %v95759_v20 = vand.u32 65535, %v95758_v26 (stack50)
        %v96168_v44 = vadd.s32 %v96165_v61, %v121564_v0 (stack40)
        %v96969_v31 = vshrl.u32 %v96962_v50, 15 (stack46)
        %v97425_v27 = vadd.s32 %v97422_v30, %v97417_v27 (stack40)
        %v95014_v40 = vsel /*vm=*/%vm149782_vm10, /*on_true_vy=*/%v149664_v40, /*on_false_vx=*/%v95010_v60 (stack44)
        %v96549_v25 = vadd.s32 %v96545_v23, %v96533_v7 (stack40)
        %v96551_v7 = vshll.u32 %v96545_v23, 13 (stack45)
        %v96552_v41 = vshrl.u32 %v96545_v23, 19 (stack46)
        %v121248_v29 = vpop.eup %121247 (stack73)
        %v95018_v10 = vmul.f32 1.4140625, %v95014_v40 (stack54)
        %v95760_v42 = vshrl.u32 %v95759_v20, 1 (stack51)
        %v96172_v8 = vadd.s32 4, %v96168_v44 (stack40)
        %v96970_v12 = vor.u32 %v96969_v31, %v96968_v54 (stack47)
        %v95391_v55 = vmul.f32 %v121248_v29, %v149768_v34 (stack74)
        %v96553_v50 = vor.u32 %v96552_v41, %v96551_v7 (stack47)
        %v97427_v26 = vshll.u32 %v97422_v30, 15 (stack45)
        %v97428_v30 = vshrl.u32 %v97422_v30, 17 (stack46)
        %v95021_v61 = vpack.c.bf16 %v157387_v11, %v95018_v10 (stack81)
        %v95761_v60 = vor.u32 16256, %v95760_v42 (stack47)
        %v96176_v24 = vadd.s32 %v96172_v8, %v96160_v24 (stack40)
        %v96178_v23 = vshll.u32 %v96172_v8, 13 (stack45)
        %v95393_v54 = vsel /*vm=*/%vm95392_vm11, /*on_true_vy=*/%v149768_v34, /*on_false_vx=*/%v95391_v55 (stack75)
        %v96179_v20 = vshrl.u32 %v96172_v8, 19 (stack46)
        %v96554_v44 = vxor.u32 %v96553_v50, %v96549_v25 (stack48)
        %v96971_v31 = vxor.u32 %v96970_v12, %v96966_v32 (stack48)
        %120253 = vst [vmem:[%s123356_s30 + $0x164] sm:$0xf] /*vst_source=*/%v95021_v61 (stack83)
        %v95384_v40 = vsel /*vm=*/%vm95347_vm9, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v95396_v52 = vsel /*vm=*/%vm95394_vm12, /*on_true_vy=*/%v95395_v52, /*on_false_vx=*/%v95393_v54 (stack76)
        %v95762_v7 = vand.u32.u16 65535, %v95761_v60 (stack52)
        %v97429_v41 = vor.u32 %v97428_v30, %v97427_v26 (stack47)
        %v95399_v29 = vadd.f32 -3.0, %v95396_v52 (stack53)
        %v96180_v10 = vor.u32 %v96179_v20, %v96178_v23 (stack47)
        %v96557_v25 = vadd.s32 %v96554_v44, %v96549_v25 (stack40)
        %v96559_v42 = vshll.u32 %v96554_v44, 15 (stack45)
        %v120256_v8 = vadd.low.f32.bf16 -1.0, %v95762_v7 (stack53)
        %v96560_v12 = vshrl.u32 %v96554_v44, 17 (stack46)
        %v96974_v32 = vadd.s32 %v96971_v31, %v96966_v32 (stack40)
        %v96976_v55 = vshll.u32 %v96971_v31, 29 (stack45)
        %v149840_v9 = vsel /*vm=*/%vm95347_vm9, /*on_true_vy=*/%v149787_v9, /*on_false_vx=*/%v95399_v29 (stack44)
        %v96181_v50 = vxor.u32 %v96180_v10, %v96176_v24 (stack48)
        %v96977_v26 = vshrl.u32 %v96971_v31, 3 (stack46)
        %v97430_v30 = vxor.u32 %v97429_v41, %v97425_v27 (stack48)
        %v95407_v61 = vmul.f32 %v149840_v9, %v95384_v40 (stack54)
        %v95771_v60 = vmul.f32 2.0, %v120256_v8 (stack54)
        %v96561_v23 = vor.u32 %v96560_v12, %v96559_v42 (stack47)
        %v97849_v54 = vadd.s32 %v157687_v43, %v157076_v35 (stack40)
        %v96184_v24 = vadd.s32 %v96181_v50, %v96176_v24 (stack40)
        %v96186_v20 = vshll.u32 %v96181_v50, 15 (stack45)
        %v96187_v44 = vshrl.u32 %v96181_v50, 17 (stack46)
        %v96978_v31 = vor.u32 %v96977_v26, %v96976_v55 (stack47)
        %v95411_v21 = vadd.f32 %v95407_v61, %v149805_v21 (stack53)
        %v95775_v40 = vadd.f32 -0.99609375, %v95771_v60 (stack53)
        %v96562_v52 = vxor.u32 %v96561_v23, %v96557_v25 (stack48)
        %v97433_v27 = vadd.s32 %v97430_v30, %v97425_v27 (stack40)
        %v95364_v7 = vsel /*vm=*/%vm95347_vm9, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v95368_v41 = vsel /*vm=*/%vm95347_vm9, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v96188_v29 = vor.u32 %v96187_v44, %v96186_v20 (stack47)
        %v96979_v10 = vxor.u32 %v96978_v31, %v96974_v32 (stack48)
        %v95415_v42 = vmul.f32 %v95411_v21, %v149840_v9 (stack54)
        %v149853_v8 = vmax.f32 %v95775_v40, -0.99609375 (stack55)
        %v96565_v25 = vadd.s32 %v96562_v52, %v96557_v25 (stack40)
        %v96567_v12 = vshll.u32 %v96562_v52, 26 (stack45)
        %v95376_v55 = vsel /*vm=*/%vm95347_vm9, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v96189_v50 = vxor.u32 %v96188_v29, %v96184_v24 (stack48)
        %v96568_v26 = vshrl.u32 %v96562_v52, 6 (stack46)
        %v96982_v32 = vadd.s32 %v96979_v10, %v96974_v32 (stack40)
        %v95419_v61 = vadd.f32 %v95415_v42, %v95376_v55 (stack53)
        %v95791_v60 = vxor.u32 2147483648, %v149853_v8 (stack56)
        %v97435_v23 = vshll.u32 %v97430_v30, 26 (stack45)
        %v97436_v30 = vshrl.u32 %v97430_v30, 6 (stack46)
        %v96192_v24 = vadd.s32 %v96189_v50, %v96184_v24 (stack40)
        %v96194_v20 = vshll.u32 %v96189_v50, 26 (stack45)
        %v96195_v44 = vshrl.u32 %v96189_v50, 6 (stack46)
        %v96569_v31 = vor.u32 %v96568_v26, %v96567_v12 (stack47)
        %v95372_v21 = vsel /*vm=*/%vm95347_vm9, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v95423_v40 = vmul.f32 %v95419_v61, %v149840_v9 (stack54)
        %v149864_v52 = vmul.f32 %v95791_v60, %v149853_v8 (stack54)
        %v97835_v29 = vadd.s32 %v149813_v45, %v122657_v58 (stack40)
        %v96196_v42 = vor.u32 %v96195_v44, %v96194_v20 (stack47)
        %v96570_v12 = vxor.u32 %v96569_v31, %v96565_v25 (stack48)
        %v96984_v55 = vshll.u32 %v96979_v10, 16 (stack45)
        %v96985_v10 = vshrl.u32 %v96979_v10, 16 (stack46)
        %v95427_v50 = vadd.f32 %v95423_v40, %v95372_v21 (stack53)
        %v95796_v26 = vadd.f32 1.0, %v149864_v52 (stack57)
        %v95799_v61 = vmul.f32 -0.5, %v149864_v52 (stack59)
        %v97437_v60 = vor.u32 %v97436_v30, %v97435_v23 (stack47)
        %v96197_v23 = vxor.u32 %v96196_v42, %v96192_v24 (stack48)
        %v96573_v25 = vadd.s32 %v96570_v12, %v96565_v25 (stack40)
        %v96579_v30 = vshll.u32 %v96570_v12, 6 (stack45)
        %v96580_v20 = vshrl.u32 %v96570_v12, 26 (stack46)
        %v95431_v44 = vmul.f32 %v95427_v50, %v149840_v9 (stack54)
        %121249 = vlog2.f32 %v95796_v26 (stack58)
        %vm97839_vm14 = vcmp.lt.u32.totalorder %v97835_v29, %v149813_v45 (stack43)
        %v97853_v31 = vadd.s32 1, %v97849_v54 (stack40)
        %v95802_v21 = vand.u32 2147483647, %v149864_v52 (stack60)
        %v96200_v24 = vadd.s32 %v96197_v23, %v96192_v24 (stack40)
        %v96206_v40 = vshll.u32 %v96197_v23, 6 (stack45)
        %v96207_v42 = vshrl.u32 %v96197_v23, 26 (stack46)
        %v95435_v41 = vadd.f32 %v95431_v44, %v95368_v41 (stack53)
        %v95800_v12 = vadd.f32 1.0, %v95799_v61 (stack61)
        %v96581_v50 = vor.u32 %v96580_v20, %v96579_v30 (stack47)
        %v96986_v55 = vor.u32 %v96985_v10, %v96984_v55 (stack47)
        %v96208_v10 = vor.u32 %v96207_v42, %v96206_v40 (stack47)
        %v96577_v26 = vadd.s32 %v96573_v25, %v121574_v2 (stack40)
        %v97438_v61 = vxor.u32 %v97437_v60, %v97433_v27 (stack48)
        %v97857_v54 = vsel /*vm=*/%vm97844_vm13, /*on_true_vy=*/%v97853_v31, /*on_false_vx=*/%v97849_v54 (stack44)
        %v95439_v60 = vmul.f32 %v95435_v41, %v149840_v9 (stack54)
        %v96582_v23 = vxor.u32 %v96581_v50, %v96573_v25 (stack48)
        %v96987_v25 = vxor.u32 %v96986_v55, %v96982_v32 (stack48)
        %v97861_v30 = vadd.s32 1, %v97857_v54 (stack40)
        %v96209_v20 = vxor.u32 %v96208_v10, %v96200_v24 (stack48)
        %v97441_v27 = vadd.s32 %v97438_v61, %v97433_v27 (stack40)
        %v97447_v44 = vshll.u32 %v97438_v61, 6 (stack45)
        %v97448_v31 = vshrl.u32 %v97438_v61, 26 (stack46)
        %v95443_v7 = vadd.f32 %v95439_v60, %v95364_v7 (stack53)
        %v96585_v40 = vadd.s32 %v96582_v23, %v121569_v1 (stack40)
        %v96990_v32 = vadd.s32 %v96987_v25, %v96982_v32 (stack40)
        %v96996_v42 = vshll.u32 %v96987_v25, 24 (stack45)
        %vm149879_vm15 = vcmp.lt.f32.partialorder %v95802_v21, 0.0004427343 (stack62)
        %v96204_v24 = vadd.s32 %v96200_v24, %v121564_v0 (stack40)
        %v96212_v41 = vadd.s32 %v96209_v20, %v121574_v2 (stack40)
        %v96997_v50 = vshrl.u32 %v96987_v25, 8 (stack46)
        %v97449_v55 = vor.u32 %v97448_v31, %v97447_v44 (stack47)
        %v95447_v10 = vmul.f32 %v95443_v7, %v149840_v9 (stack54)
        %v96589_v61 = vadd.s32 3, %v96585_v40 (stack40)
        %v97445_v60 = vadd.s32 %v97441_v27, %v121569_v1 (stack40)
        %v97865_v45 = vsel /*vm=*/%vm97839_vm14, /*on_true_vy=*/%v97861_v30, /*on_false_vx=*/%v97857_v54 (stack44)
        %v96216_v54 = vadd.s32 5, %v96212_v41 (stack40)
        %v96998_v23 = vor.u32 %v96997_v50, %v96996_v42 (stack47)
        %v97450_v25 = vxor.u32 %v97449_v55, %v97441_v27 (stack48)
        %v97870_v30 = vadd.s32 %v97865_v45, %v121574_v2 (stack40)
        %v95451_v53 = vadd.f32 %v95447_v10, %v149800_v53 (stack53)
        %v96593_v26 = vadd.s32 %v96589_v61, %v96577_v26 (stack40)
        %v96595_v20 = vshll.u32 %v96589_v61, 17 (stack45)
        %v96596_v27 = vshrl.u32 %v96589_v61, 15 (stack46)
        %v96218_v44 = vxor.u32 %v96216_v54, %v96204_v24 (stack48)
        %v96999_v31 = vxor.u32 %v96998_v23, %v96990_v32 (stack48)
        %v97453_v7 = vadd.s32 %v97450_v25, %v121564_v0 (stack40)
        %v149893_v29 = vadd.s32 %v97835_v29, %v121569_v1 (stack40)
        %v95455_v40 = vmul.f32 %v95451_v53, %v149840_v9 (stack54)
        %v96597_v42 = vor.u32 %v96596_v27, %v96595_v20 (stack47)
        %v149898_v24 = vadd.s32 %v157684_v56, %v157077_v51 (stack40)
        %v149902_v41 = vadd.s32 %v157687_v43, %v157078_v48 (stack40)
        %v121250_v50 = vpop.eup %121249 (stack64)
        %v96219_v55 = vand.u32.u8 255, %v96218_v44 (stack49)
        %v97002_v10 = vadd.s32 %v96999_v31, %v121574_v2 (stack40)
        %v97457_v61 = vadd.s32 1, %v97453_v7 (stack40)
        %v149906_v45 = vadd.s32 %v149893_v29, %v97870_v30 (stack40)
        %v95459_v46 = vadd.f32 %v95455_v40, %v149795_v46 (stack53)
        %v95798_v54 = vmul.f32 0.6931472, %v121250_v50 (stack65)
        %v95801_v52 = vmul.f32 %v95800_v12, %v149864_v52 (stack63)
        %v96598_v12 = vxor.u32 %v96597_v42, %v96593_v26 (stack48)
        %v96220_v23 = vand.u32 65535, %v96219_v55 (stack50)
        %v96994_v32 = vadd.s32 %v96990_v32, %v121564_v0 (stack40)
        %v97006_v25 = vadd.s32 2, %v97002_v10 (stack40)
        %v97461_v60 = vadd.s32 %v97457_v61, %v97445_v60 (stack40)
        %v95352_v34 = vsel /*vm=*/%vm95347_vm9, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v95463_v9 = vmul.f32 %v95459_v46, %v149840_v9 (stack54)
        %v95804_v21 = vsel /*vm=*/%vm149879_vm15, /*on_true_vy=*/%v95801_v52, /*on_false_vx=*/%v95798_v54 (stack66)
        %v96601_v30 = vadd.s32 %v96598_v12, %v96593_v26 (stack40)
        %v149917_v53 = vxor.u32 2147483648, %v95804_v21 (stack56)
        %v96603_v26 = vshll.u32 %v96598_v12, 29 (stack45)
        %v96604_v20 = vshrl.u32 %v96598_v12, 3 (stack46)
        %v97010_v27 = vadd.s32 %v97006_v25, %v96994_v32 (stack40)
        %v95328_v44 = vmul.f32 inf, %v149699_v6 (stack54)
        %v95467_v31 = vadd.f32 %v95463_v9, %v95352_v34 (stack53)
        %vm95808_vm0 = vcmp.lt.f32.partialorder %v149917_v53, 5.0 (stack68)
        %121251 = vrsqrt.f32 %v149917_v53 (stack67)
        %v96221_v7 = vshrl.u32 %v96220_v23, 1 (stack51)
        %v97463_v40 = vshll.u32 %v97457_v61, 17 (stack45)
        %v95471_v42 = vmul.f32 %v95467_v31, %v149699_v6 (stack54)
        %v97012_v50 = vshll.u32 %v97006_v25, 13 (stack45)
        %v97013_v55 = vshrl.u32 %v97006_v25, 19 (stack46)
        %v97464_v10 = vshrl.u32 %v97457_v61, 15 (stack46)
        %vm95323_vm1 = vcmp.eq.f32.partialorder %v95320_v22, 1.0 (stack68)
        %v95781_v6 = vand.u32 2147483647, %v149853_v8 (stack77)
        %v149927_v22 = vmul.f32 inf, %v149853_v8 (stack54)
        %v96605_v61 = vor.u32 %v96604_v20, %v96603_v26 (stack47)
        %v95475_v46 = vsel /*vm=*/%vm95323_vm1, /*on_true_vy=*/%v95328_v44, /*on_false_vx=*/%v95471_v42 (stack44)
        %v149932_v54 = vsel /*vm=*/%vm95808_vm0, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v149935_v52 = vadd.f32 -2.5, %v149917_v53 (stack53)
        %v97880_v12 = vshll.u32 %v149893_v29, 13 (stack45)
        %v95479_v23 = vmul.f32 1.4140625, %v95475_v46 (stack54)
        %v149941_v32 = vsel /*vm=*/%vm95808_vm0, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v149946_v25 = vsel /*vm=*/%vm95808_vm0, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v96222_v34 = vor.u32 16256, %v96221_v7 (stack47)
        %v96606_v9 = vxor.u32 %v96605_v61, %v96601_v30 (stack48)
        %v97014_v21 = vor.u32 %v97013_v55, %v97012_v50 (stack47)
        %v97465_v26 = vor.u32 %v97464_v10, %v97463_v40 (stack47)
        %v97881_v29 = vshrl.u32 %v149893_v29, 19 (stack46)
        %v95482_v20 = vpack.c.bf16 %v157387_v11, %v95479_v23 (stack81)
        %v149953_v44 = vsel /*vm=*/%vm95808_vm0, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v96223_v31 = vand.u32.u16 65535, %v96222_v34 (stack52)
        %vm98305_vm2 = vcmp.lt.u32.totalorder %v149898_v24, %v157077_v51 (stack43)
        %vm95853_vm3 = vcmp.eq.f32.partialorder %v149917_v53, inf (stack70)
        %v96609_v30 = vadd.s32 %v96606_v9, %v96601_v30 (stack40)
        %v96611_v7 = vshll.u32 %v96606_v9, 16 (stack45)
        %v96612_v40 = vshrl.u32 %v96606_v9, 16 (stack46)
        %v97015_v42 = vxor.u32 %v97014_v21, %v97010_v27 (stack48)
        %120255 = vst [vmem:[%s123356_s30 + $0x1e4] sm:$0xf] /*vst_source=*/%v95482_v20 (stack83)
        %v149962_v50 = vsel /*vm=*/%vm95808_vm0, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v120258_v55 = vadd.low.f32.bf16 -1.0, %v96223_v31 (stack53)
        %v97466_v10 = vxor.u32 %v97465_v26, %v97461_v60 (stack48)
        %v97882_v61 = vor.u32 %v97881_v29, %v97880_v12 (stack47)
        %v96613_v46 = vor.u32 %v96612_v40, %v96611_v7 (stack47)
        %v97018_v27 = vadd.s32 %v97015_v42, %v97010_v27 (stack40)
        %v97020_v12 = vshll.u32 %v97015_v42, 15 (stack45)
        %v97021_v23 = vshrl.u32 %v97015_v42, 17 (stack46)
        %v96232_v34 = vmul.f32 2.0, %v120258_v55 (stack54)
        %v97469_v60 = vadd.s32 %v97466_v10, %v97461_v60 (stack40)
        %v97471_v9 = vshll.u32 %v97466_v10, 29 (stack45)
        %v97472_v21 = vshrl.u32 %v97466_v10, 3 (stack46)
        %v149967_v26 = vsel /*vm=*/%vm95808_vm0, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v96614_v29 = vxor.u32 %v96613_v46, %v96609_v30 (stack48)
        %v97022_v20 = vor.u32 %v97021_v23, %v97020_v12 (stack47)
        %v97883_v31 = vxor.u32 %v97882_v61, %v149906_v45 (stack48)
        %v95841_v7 = vsel /*vm=*/%vm95808_vm0, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v96236_v40 = vadd.f32 -0.99609375, %v96232_v34 (stack53)
        %v97473_v42 = vor.u32 %v97472_v21, %v97471_v9 (stack47)
        %v149975_v55 = vadd.s32 %v157684_v56, %v157079_v39 (stack40)
        %v121252_v10 = vpop.eup %121251 (stack73)
        %v96617_v30 = vadd.s32 %v96614_v29, %v96609_v30 (stack40)
        %v96623_v61 = vshll.u32 %v96614_v29, 24 (stack45)
        %v96624_v46 = vshrl.u32 %v96614_v29, 8 (stack46)
        %v97023_v12 = vxor.u32 %v97022_v20, %v97018_v27 (stack48)
        %v95852_v23 = vmul.f32 %v121252_v10, %v149917_v53 (stack74)
        %v149978_v34 = vmax.f32 %v96236_v40, -0.99609375 (stack55)
        %v97474_v9 = vxor.u32 %v97473_v42, %v97469_v60 (stack48)
        %v149981_v45 = vadd.s32 %v97883_v31, %v149906_v45 (stack40)
        %v95856_v21 = vand.u32 2147483648, %v149917_v53 (stack72)
        %v96625_v29 = vor.u32 %v96624_v46, %v96623_v61 (stack47)
        %v97026_v27 = vadd.s32 %v97023_v12, %v97018_v27 (stack40)
        %v97028_v20 = vshll.u32 %v97023_v12, 26 (stack45)
        %v95854_v40 = vsel /*vm=*/%vm95853_vm3, /*on_true_vy=*/%v149917_v53, /*on_false_vx=*/%v95852_v23 (stack75)
        %vm95855_vm4 = vcmp.eq.f32.partialorder %v149917_v53, 0.0 (stack71)
        %v96252_v42 = vxor.u32 2147483648, %v149978_v34 (stack56)
        %v149991_v10 = vadd.s32 %v149898_v24, %v122657_v58 (stack40)
        %v95857_v61 = vsel /*vm=*/%vm95855_vm4, /*on_true_vy=*/%v95856_v21, /*on_false_vx=*/%v95854_v40 (stack76)
        %v96626_v46 = vxor.u32 %v96625_v29, %v96617_v30 (stack48)
        %v97029_v12 = vshrl.u32 %v97023_v12, 6 (stack46)
        %v97477_v60 = vadd.s32 %v97474_v9, %v97469_v60 (stack40)
        %v95845_v23 = vsel /*vm=*/%vm95808_vm0, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v95860_v21 = vadd.f32 -3.0, %v95857_v61 (stack53)
        %v149997_v29 = vmul.f32 %v96252_v42, %v149978_v34 (stack54)
        %v97479_v40 = vshll.u32 %v97474_v9, 16 (stack45)
        %v96621_v30 = vadd.s32 %v96617_v30, %v121569_v1 (stack40)
        %v96629_v42 = vadd.s32 %v96626_v46, %v121564_v0 (stack40)
        %v97030_v20 = vor.u32 %v97029_v12, %v97028_v20 (stack47)
        %v97480_v9 = vshrl.u32 %v97474_v9, 16 (stack46)
        %v150004_v52 = vsel /*vm=*/%vm95808_vm0, /*on_true_vy=*/%v149935_v52, /*on_false_vx=*/%v95860_v21 (stack44)
        %v96257_v61 = vadd.f32 1.0, %v149997_v29 (stack57)
        %v96260_v46 = vmul.f32 -0.5, %v149997_v29 (stack59)
        %v97888_v12 = vshll.u32 %v97883_v31, 15 (stack45)
        %v95868_v23 = vmul.f32 %v150004_v52, %v95845_v23 (stack54)
        %v96633_v21 = vadd.s32 4, %v96629_v42 (stack40)
        %v97031_v42 = vxor.u32 %v97030_v20, %v97026_v27 (stack48)
        %v97481_v40 = vor.u32 %v97480_v9, %v97479_v40 (stack47)
        %vm98300_vm5 = vcmp.lt.u32.totalorder %v149991_v10, %v149898_v24 (stack43)
        %121253 = vlog2.f32 %v96257_v61 (stack58)
        %v96261_v20 = vadd.f32 1.0, %v96260_v46 (stack61)
        %v97889_v31 = vshrl.u32 %v97883_v31, 17 (stack46)
        %v98314_v9 = vadd.s32 1, %v149902_v41 (stack40)
        %v95872_v7 = vadd.f32 %v95868_v23, %v95841_v7 (stack53)
        %v96637_v30 = vadd.s32 %v96633_v21, %v96621_v30 (stack40)
        %v96639_v61 = vshll.u32 %v96633_v21, 13 (stack45)
        %v96640_v46 = vshrl.u32 %v96633_v21, 19 (stack46)
        %v97034_v27 = vadd.s32 %v97031_v42, %v97026_v27 (stack40)
        %v97040_v23 = vshll.u32 %v97031_v42, 6 (stack45)
        %v97041_v21 = vshrl.u32 %v97031_v42, 26 (stack46)
        %v150014_v42 = vadd.s32 %v149991_v10, %v121569_v1 (stack40)
        %v95876_v7 = vmul.f32 %v95872_v7, %v150004_v52 (stack54)
        %v96641_v61 = vor.u32 %v96640_v46, %v96639_v61 (stack47)
        %v97482_v40 = vxor.u32 %v97481_v40, %v97477_v60 (stack48)
        %v97890_v12 = vor.u32 %v97889_v31, %v97888_v12 (stack47)
        %v96262_v20 = vmul.f32 %v96261_v20, %v149997_v29 (stack63)
        %v96263_v29 = vand.u32 2147483647, %v149997_v29 (stack60)
        %v97042_v31 = vor.u32 %v97041_v21, %v97040_v23 (stack47)
        %v98318_v41 = vsel /*vm=*/%vm98305_vm2, /*on_true_vy=*/%v98314_v9, /*on_false_vx=*/%v149902_v41 (stack44)
        %v95880_v26 = vadd.f32 %v95876_v7, %v149967_v26 (stack53)
        %v96642_v9 = vxor.u32 %v96641_v61, %v96637_v30 (stack48)
        %v97485_v60 = vadd.s32 %v97482_v40, %v97477_v60 (stack40)
        %v97491_v46 = vshll.u32 %v97482_v40, 24 (stack45)
        %v97043_v23 = vxor.u32 %v97042_v31, %v97034_v27 (stack48)
        %v97492_v21 = vshrl.u32 %v97482_v40, 8 (stack46)
        %v97891_v7 = vxor.u32 %v97890_v12, %v149981_v45 (stack48)
        %v98322_v61 = vadd.s32 1, %v98318_v41 (stack40)
        %v95884_v40 = vmul.f32 %v95880_v26, %v150004_v52 (stack54)
        %v96645_v30 = vadd.s32 %v96642_v9, %v96637_v30 (stack40)
        %v96647_v12 = vshll.u32 %v96642_v9, 15 (stack45)
        %v96648_v31 = vshrl.u32 %v96642_v9, 17 (stack46)
        %v97038_v27 = vadd.s32 %v97034_v27, %v121574_v2 (stack40)
        %v97046_v26 = vadd.s32 %v97043_v23, %v121569_v1 (stack40)
        %v97493_v9 = vor.u32 %v97492_v21, %v97491_v46 (stack47)
        %v97894_v45 = vadd.s32 %v97891_v7, %v149981_v45 (stack40)
        %v95888_v50 = vadd.f32 %v95884_v40, %v149962_v50 (stack53)
        %v96649_v46 = vor.u32 %v96648_v31, %v96647_v12 (stack47)
        %v97896_v23 = vshll.u32 %v97891_v7, 26 (stack45)
        %v97897_v21 = vshrl.u32 %v97891_v7, 6 (stack46)
        %v97050_v7 = vadd.s32 3, %v97046_v26 (stack40)
        %v97489_v40 = vadd.s32 %v97485_v60, %v121564_v0 (stack40)
        %v97494_v60 = vxor.u32 %v97493_v9, %v97485_v60 (stack48)
        %v98326_v24 = vsel /*vm=*/%vm98300_vm5, /*on_true_vy=*/%v98322_v61, /*on_false_vx=*/%v98318_v41 (stack44)
        %v95892_v10 = vmul.f32 %v95888_v50, %v150004_v52 (stack54)
        %v96650_v41 = vxor.u32 %v96649_v46, %v96645_v30 (stack48)
        %v97898_v61 = vor.u32 %v97897_v21, %v97896_v23 (stack47)
        %v98331_v12 = vadd.s32 %v98326_v24, %v121574_v2 (stack40)
        %v97054_v31 = vadd.s32 %v97050_v7, %v97038_v27 (stack40)
        %v97056_v27 = vshll.u32 %v97050_v7, 17 (stack45)
        %v97057_v26 = vshrl.u32 %v97050_v7, 15 (stack46)
        %v97497_v9 = vadd.s32 %v97494_v60, %v121574_v2 (stack40)
        %v121254_v50 = vpop.eup %121253 (stack64)
        %v95896_v44 = vadd.f32 %v95892_v10, %v149953_v44 (stack53)
        %v96653_v30 = vadd.s32 %v96650_v41, %v96645_v30 (stack40)
        %v96655_v46 = vshll.u32 %v96650_v41, 26 (stack45)
        %v96656_v23 = vshrl.u32 %v96650_v41, 6 (stack46)
        %v96259_v21 = vmul.f32 0.6931472, %v121254_v50 (stack65)
        %v97058_v7 = vor.u32 %v97057_v26, %v97056_v27 (stack47)
        %v97501_v60 = vadd.s32 2, %v97497_v9 (stack40)
        %v97899_v24 = vxor.u32 %v97898_v61, %v97894_v45 (stack48)
        %v95900_v10 = vmul.f32 %v95896_v44, %v150004_v52 (stack54)
        %vm96264_vm6 = vcmp.lt.f32.partialorder %v96263_v29, 0.0004427343 (stack62)
        %v96657_v29 = vor.u32 %v96656_v23, %v96655_v46 (stack47)
        %v98339_v41 = vadd.s32 %v150014_v42, %v98331_v12 (stack40)
        %v95825_v53 = vsel /*vm=*/%vm95808_vm0, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v96265_v20 = vsel /*vm=*/%vm96264_vm6, /*on_true_vy=*/%v96262_v20, /*on_false_vx=*/%v96259_v21 (stack66)
        %v97059_v61 = vxor.u32 %v97058_v7, %v97054_v31 (stack48)
        %v97505_v40 = vadd.s32 %v97501_v60, %v97489_v40 (stack40)
        %v95904_v12 = vadd.f32 %v95900_v10, %v95825_v53 (stack53)
        %v150044_v26 = vxor.u32 2147483648, %v96265_v20 (stack56)
        %v96658_v9 = vxor.u32 %v96657_v29, %v96653_v30 (stack48)
        %v97062_v31 = vadd.s32 %v97059_v61, %v97054_v31 (stack40)
        %v150046_v45 = vadd.s32 %v97899_v24, %v97894_v45 (stack40)
        %v98341_v50 = vshll.u32 %v150014_v42, 13 (stack45)
        %v98342_v42 = vshrl.u32 %v150014_v42, 19 (stack46)
        %v95908_v44 = vmul.f32 %v95904_v12, %v150004_v52 (stack54)
        %vm96269_vm7 = vcmp.lt.f32.partialorder %v150044_v26, 5.0 (stack68)
        %121255 = vrsqrt.f32 %v150044_v26 (stack67)
        %v97507_v46 = vshll.u32 %v97501_v60, 13 (stack45)
        %v96661_v30 = vadd.s32 %v96658_v9, %v96653_v30 (stack40)
        %v97064_v23 = vshll.u32 %v97059_v61, 29 (stack45)
        %v97065_v21 = vshrl.u32 %v97059_v61, 3 (stack46)
        %v97508_v7 = vshrl.u32 %v97501_v60, 19 (stack46)
        %v95912_v25 = vadd.f32 %v95908_v44, %v149946_v25 (stack53)
        %v150055_v60 = vmul.f32 inf, %v149978_v34 (stack54)
        %v150060_v10 = vsel /*vm=*/%vm96269_vm7, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v150063_v29 = vadd.f32 -2.5, %v150044_v26 (stack53)
        %v150068_v53 = vsel /*vm=*/%vm96269_vm7, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v150073_v20 = vsel /*vm=*/%vm96269_vm7, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v150078_v61 = vsel /*vm=*/%vm96269_vm7, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v98343_v12 = vor.u32 %v98342_v42, %v98341_v50 (stack47)
        %v95916_v50 = vmul.f32 %v95912_v25, %v150004_v52 (stack54)
        %v150084_v42 = vsel /*vm=*/%vm96269_vm7, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v150089_v44 = vsel /*vm=*/%vm96269_vm7, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v150094_v25 = vsel /*vm=*/%vm96269_vm7, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %vm150098_vm8 = vcmp.eq.f32.partialorder %v95781_v6, 1.0 (stack68)
        %v96667_v27 = vshll.u32 %v96658_v9, 6 (stack45)
        %v96668_v9 = vshrl.u32 %v96658_v9, 26 (stack46)
        %v97066_v23 = vor.u32 %v97065_v21, %v97064_v23 (stack47)
        %v97509_v46 = vor.u32 %v97508_v7, %v97507_v46 (stack47)
        %v95920_v32 = vadd.f32 %v95916_v50, %v149941_v32 (stack53)
        %v96665_v21 = vadd.s32 %v96661_v30, %v121564_v0 (stack40)
        %v97908_v7 = vshll.u32 %v97899_v24, 6 (stack45)
        %v97909_v24 = vshrl.u32 %v97899_v24, 26 (stack46)
        %vm96314_vm9 = vcmp.eq.f32.partialorder %v150044_v26, inf (stack70)
        %v96669_v27 = vor.u32 %v96668_v9, %v96667_v27 (stack47)
        %v97067_v50 = vxor.u32 %v97066_v23, %v97062_v31 (stack48)
        %v97510_v9 = vxor.u32 %v97509_v46, %v97505_v40 (stack48)
        %v98344_v12 = vxor.u32 %v98343_v12, %v98339_v41 (stack48)
        %v95924_v52 = vmul.f32 %v95920_v32, %v150004_v52 (stack54)
        %vm96316_vm10 = vcmp.eq.f32.partialorder %v150044_v26, 0.0 (stack71)
        %v97910_v23 = vor.u32 %v97909_v24, %v97908_v7 (stack47)
        %vm98766_vm11 = vcmp.lt.u32.totalorder %v149975_v55, %v157079_v39 (stack43)
        %v96670_v30 = vxor.u32 %v96669_v27, %v96661_v30 (stack48)
        %v97070_v31 = vadd.s32 %v97067_v50, %v97062_v31 (stack40)
        %v97072_v46 = vshll.u32 %v97067_v50, 16 (stack45)
        %v97073_v32 = vshrl.u32 %v97067_v50, 16 (stack46)
        %v95928_v54 = vadd.f32 %v95924_v52, %v149932_v54 (stack53)
        %v97513_v40 = vadd.s32 %v97510_v9, %v97505_v40 (stack40)
        %v97515_v7 = vshll.u32 %v97510_v9, 15 (stack45)
        %v97516_v24 = vshrl.u32 %v97510_v9, 17 (stack46)
        %v96673_v27 = vadd.s32 %v96670_v30, %v121574_v2 (stack40)
        %v97074_v50 = vor.u32 %v97073_v32, %v97072_v46 (stack47)
        %v97911_v9 = vxor.u32 %v97910_v23, %v150046_v45 (stack48)
        %v98347_v41 = vadd.s32 %v98344_v12, %v98339_v41 (stack40)
        %v95932_v8 = vmul.f32 %v95928_v54, %v149853_v8 (stack54)
        %v97517_v52 = vor.u32 %v97516_v24, %v97515_v7 (stack47)
        %v98349_v23 = vshll.u32 %v98344_v12, 15 (stack45)
        %v98350_v12 = vshrl.u32 %v98344_v12, 17 (stack46)
        %v121256_v30 = vpop.eup %121255 (stack73)
        %v96317_v46 = vand.u32 2147483648, %v150044_v26 (stack72)
        %v96677_v32 = vadd.s32 5, %v96673_v27 (stack40)
        %v97075_v54 = vxor.u32 %v97074_v50, %v97070_v31 (stack48)
        %v97914_v7 = vadd.s32 %v97911_v9, %v121564_v0 (stack40)
        %v95936_v22 = vsel /*vm=*/%vm150098_vm8, /*on_true_vy=*/%v149927_v22, /*on_false_vx=*/%v95932_v8 (stack44)
        %v96313_v6 = vmul.f32 %v121256_v30, %v150044_v26 (stack74)
        %v97518_v24 = vxor.u32 %v97517_v52, %v97513_v40 (stack48)
        %v98351_v27 = vor.u32 %v98350_v12, %v98349_v23 (stack47)
        %v95940_v50 = vmul.f32 1.4140625, %v95936_v22 (stack54)
        %v96679_v21 = vxor.u32 %v96677_v32, %v96665_v21 (stack48)
        %v97078_v31 = vadd.s32 %v97075_v54, %v97070_v31 (stack40)
        %v97084_v9 = vshll.u32 %v97075_v54, 24 (stack45)
        %v96315_v8 = vsel /*vm=*/%vm96314_vm9, /*on_true_vy=*/%v150044_v26, /*on_false_vx=*/%v96313_v6 (stack75)
        %v97085_v52 = vshrl.u32 %v97075_v54, 8 (stack46)
        %v97521_v40 = vadd.s32 %v97518_v24, %v97513_v40 (stack40)
        %v97523_v23 = vshll.u32 %v97518_v24, 26 (stack45)
        %v95943_v12 = vpack.c.bf16 %v157387_v11, %v95940_v50 (stack81)
        %v96318_v30 = vsel /*vm=*/%vm96316_vm10, /*on_true_vy=*/%v96317_v46, /*on_false_vx=*/%v96315_v8 (stack76)
        %v96680_v46 = vand.u32.u8 255, %v96679_v21 (stack49)
        %v97906_v45 = vadd.s32 %v150046_v45, %v121569_v1 (stack40)
        %v96321_v32 = vadd.f32 -3.0, %v96318_v30 (stack53)
        %v97086_v54 = vor.u32 %v97085_v52, %v97084_v9 (stack47)
        %v97524_v22 = vshrl.u32 %v97518_v24, 6 (stack46)
        %v97918_v7 = vadd.s32 1, %v97914_v7 (stack40)
        %120257 = vst [vmem:[%s123356_s30 + $0x264] sm:$0xf] /*vst_source=*/%v95943_v12 (stack83)
        %v96681_v6 = vand.u32 65535, %v96680_v46 (stack50)
        %v97082_v24 = vadd.s32 %v97078_v31, %v121569_v1 (stack40)
        %v98352_v27 = vxor.u32 %v98351_v27, %v98347_v41 (stack48)
        %v150131_v50 = vadd.s32 %v157687_v43, %v157082_v49 (stack40)
        %v150136_v29 = vsel /*vm=*/%vm96269_vm7, /*on_true_vy=*/%v150063_v29, /*on_false_vx=*/%v96321_v32 (stack44)
        %v97087_v21 = vxor.u32 %v97086_v54, %v97078_v31 (stack48)
        %v97525_v31 = vor.u32 %v97524_v22, %v97523_v23 (stack47)
        %v97922_v9 = vadd.s32 %v97918_v7, %v97906_v45 (stack40)
        %v96329_v25 = vmul.f32 %v150136_v29, %v150094_v25 (stack54)
        %v96682_v8 = vshrl.u32 %v96681_v6, 1 (stack51)
        %v97924_v52 = vshll.u32 %v97918_v7, 17 (stack45)
        %v97925_v23 = vshrl.u32 %v97918_v7, 15 (stack46)
        %v97090_v12 = vadd.s32 %v97087_v21, %v121564_v0 (stack40)
        %v97526_v30 = vxor.u32 %v97525_v31, %v97521_v40 (stack48)
        %v98355_v41 = vadd.s32 %v98352_v27, %v98347_v41 (stack40)
        %v98357_v46 = vshll.u32 %v98352_v27, 26 (stack45)
        %v96333_v44 = vadd.f32 %v96329_v25, %v150089_v44 (stack53)
        %v96683_v45 = vor.u32 16256, %v96682_v8 (stack47)
        %v97926_v32 = vor.u32 %v97925_v23, %v97924_v52 (stack47)
        %v98358_v54 = vshrl.u32 %v98352_v27, 6 (stack46)
        %v97094_v22 = vadd.s32 4, %v97090_v12 (stack40)
        %v97529_v40 = vadd.s32 %v97526_v30, %v97521_v40 (stack40)
        %v97535_v7 = vshll.u32 %v97526_v30, 6 (stack45)
        %v97536_v6 = vshrl.u32 %v97526_v30, 26 (stack46)
        %v96337_v27 = vmul.f32 %v96333_v44, %v150136_v29 (stack54)
        %v96684_v21 = vand.u32.u16 65535, %v96683_v45 (stack52)
        %v97927_v31 = vxor.u32 %v97926_v32, %v97922_v9 (stack48)
        %v98359_v25 = vor.u32 %v98358_v54, %v98357_v46 (stack47)
        %v97098_v24 = vadd.s32 %v97094_v22, %v97082_v24 (stack40)
        %v97100_v8 = vshll.u32 %v97094_v22, 13 (stack45)
        %v97101_v52 = vshrl.u32 %v97094_v22, 19 (stack46)
        %v150145_v23 = vadd.s32 %v149975_v55, %v122657_v58 (stack40)
        %v96341_v42 = vadd.f32 %v96337_v27, %v150084_v42 (stack53)
        %v120260_v12 = vadd.low.f32.bf16 -1.0, %v96684_v21 (stack53)
        %v97537_v30 = vor.u32 %v97536_v6, %v97535_v7 (stack47)
        %v97930_v9 = vadd.s32 %v97927_v31, %v97922_v9 (stack40)
        %v97102_v46 = vor.u32 %v97101_v52, %v97100_v8 (stack47)
        %v97932_v44 = vshll.u32 %v97927_v31, 29 (stack45)
        %v97933_v45 = vshrl.u32 %v97927_v31, 3 (stack46)
        %v98360_v32 = vxor.u32 %v98359_v25, %v98355_v41 (stack48)
        %v96290_v54 = vsel /*vm=*/%vm96269_vm7, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v96345_v22 = vmul.f32 %v96341_v42, %v150136_v29 (stack54)
        %v96693_v7 = vmul.f32 2.0, %v120260_v12 (stack54)
        %v97538_v6 = vxor.u32 %v97537_v30, %v97529_v40 (stack48)
        %v96294_v26 = vsel /*vm=*/%vm96269_vm7, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v97103_v27 = vxor.u32 %v97102_v46, %v97098_v24 (stack48)
        %v97934_v21 = vor.u32 %v97933_v45, %v97932_v44 (stack47)
        %v150155_v41 = vadd.s32 %v98360_v32, %v98355_v41 (stack40)
        %v96349_v31 = vadd.f32 %v96345_v22, %v96294_v26 (stack53)
        %v96697_v25 = vadd.f32 -0.99609375, %v96693_v7 (stack53)
        %v97541_v8 = vadd.s32 %v97538_v6, %v121569_v1 (stack40)
        %v150160_v52 = vadd.s32 %v150145_v23, %v121569_v1 (stack40)
        %v97106_v24 = vadd.s32 %v97103_v27, %v97098_v24 (stack40)
        %v97108_v42 = vshll.u32 %v97103_v27, 15 (stack45)
        %v97109_v12 = vshrl.u32 %v97103_v27, 17 (stack46)
        %v97935_v30 = vxor.u32 %v97934_v21, %v97930_v9 (stack48)
        %v96353_v46 = vmul.f32 %v96349_v31, %v150136_v29 (stack54)
        %v150163_v44 = vmax.f32 %v96697_v25, -0.99609375 (stack55)
        %v97533_v40 = vadd.s32 %v97529_v40, %v121574_v2 (stack40)
        %v97545_v45 = vadd.s32 3, %v97541_v8 (stack40)
        %v97110_v22 = vor.u32 %v97109_v12, %v97108_v42 (stack47)
        %v97938_v9 = vadd.s32 %v97935_v30, %v97930_v9 (stack40)
        %v97940_v7 = vshll.u32 %v97935_v30, 16 (stack45)
        %v97941_v6 = vshrl.u32 %v97935_v30, 16 (stack46)
        %v96357_v54 = vadd.f32 %v96353_v46, %v96290_v54 (stack53)
        %v96713_v26 = vxor.u32 2147483648, %v150163_v44 (stack56)
        %v98369_v27 = vshll.u32 %v98360_v32, 6 (stack45)
        %v98775_v21 = vadd.s32 1, %v150131_v50 (stack40)
        %v97111_v31 = vxor.u32 %v97110_v22, %v97106_v24 (stack48)
        %v97549_v25 = vadd.s32 %v97545_v45, %v97533_v40 (stack40)
        %v97551_v8 = vshll.u32 %v97545_v45, 17 (stack45)
        %v97552_v42 = vshrl.u32 %v97545_v45, 15 (stack46)
        %v96361_v12 = vmul.f32 %v96357_v54, %v150136_v29 (stack54)
        %v150170_v30 = vmul.f32 %v96713_v26, %v150163_v44 (stack54)
        %v97942_v46 = vor.u32 %v97941_v6, %v97940_v7 (stack47)
        %v98370_v32 = vshrl.u32 %v98360_v32, 26 (stack46)
        %v97114_v24 = vadd.s32 %v97111_v31, %v97106_v24 (stack40)
        %v97116_v40 = vshll.u32 %v97111_v31, 26 (stack45)
        %v97117_v45 = vshrl.u32 %v97111_v31, 6 (stack46)
        %v97553_v22 = vor.u32 %v97552_v42, %v97551_v8 (stack47)
        %vm98761_vm12 = vcmp.lt.u32.totalorder %v150145_v23, %v149975_v55 (stack43)
        %v96365_v61 = vadd.f32 %v96361_v12, %v150078_v61 (stack53)
        %v96718_v7 = vadd.f32 1.0, %v150170_v30 (stack57)
        %v96721_v6 = vmul.f32 -0.5, %v150170_v30 (stack59)
        %v98367_v54 = vadd.s32 %v150155_v41, %v121569_v1 (stack40)
        %v96724_v26 = vand.u32 2147483647, %v150170_v30 (stack60)
        %v97118_v31 = vor.u32 %v97117_v45, %v97116_v40 (stack47)
        %v97554_v8 = vxor.u32 %v97553_v22, %v97549_v25 (stack48)
        %v97943_v42 = vxor.u32 %v97942_v46, %v97938_v9 (stack48)
        %v96369_v12 = vmul.f32 %v96365_v61, %v150136_v29 (stack54)
        %121257 = vlog2.f32 %v96718_v7 (stack58)
        %v96722_v46 = vadd.f32 1.0, %v96721_v6 (stack61)
        %v98371_v27 = vor.u32 %v98370_v32, %v98369_v27 (stack47)
        %v97119_v32 = vxor.u32 %v97118_v31, %v97114_v24 (stack48)
        %v97557_v25 = vadd.s32 %v97554_v8, %v97549_v25 (stack40)
        %v97559_v40 = vshll.u32 %v97554_v8, 29 (stack45)
        %v97560_v45 = vshrl.u32 %v97554_v8, 3 (stack46)
        %v96373_v20 = vadd.f32 %v96369_v12, %v150073_v20 (stack53)
        %v96723_v22 = vmul.f32 %v96722_v46, %v150170_v30 (stack63)
        %v97946_v9 = vadd.s32 %v97943_v42, %v97938_v9 (stack40)
        %v97952_v61 = vshll.u32 %v97943_v42, 24 (stack45)
        %v97122_v24 = vadd.s32 %v97119_v32, %v97114_v24 (stack40)
        %v97128_v7 = vshll.u32 %v97119_v32, 6 (stack45)
        %v97129_v6 = vshrl.u32 %v97119_v32, 26 (stack46)
        %v97561_v31 = vor.u32 %v97560_v45, %v97559_v40 (stack47)
        %v96377_v8 = vmul.f32 %v96373_v20, %v150136_v29 (stack54)
        %v97950_v12 = vadd.s32 %v97946_v9, %v121564_v0 (stack40)
        %v97953_v42 = vshrl.u32 %v97943_v42, 8 (stack46)
        %v98372_v41 = vxor.u32 %v98371_v27, %v150155_v41 (stack48)
        %v157694_v46 = vand.u32 2147483647, %v149978_v34 (stack77)
        %vm150188_vm13 = vcmp.eq.f32.partialorder %v157694_v46, 1.0 (stack68)
        %v97126_v32 = vadd.s32 %v97122_v24, %v121564_v0 (stack40)
        %v97130_v40 = vor.u32 %v97129_v6, %v97128_v7 (stack47)
        %v97562_v45 = vxor.u32 %v97561_v31, %v97557_v25 (stack48)
        %v98779_v50 = vsel /*vm=*/%vm98766_vm11, /*on_true_vy=*/%v98775_v21, /*on_false_vx=*/%v150131_v50 (stack44)
        %v96381_v53 = vadd.f32 %v96377_v8, %v150068_v53 (stack53)
        %v97954_v21 = vor.u32 %v97953_v42, %v97952_v61 (stack47)
        %v98375_v20 = vadd.s32 %v98372_v41, %v121564_v0 (stack40)
        %v98783_v61 = vadd.s32 1, %v98779_v50 (stack40)
        %v97131_v24 = vxor.u32 %v97130_v40, %v97122_v24 (stack48)
        %v97565_v25 = vadd.s32 %v97562_v45, %v97557_v25 (stack40)
        %v97567_v7 = vshll.u32 %v97562_v45, 16 (stack45)
        %v97568_v6 = vshrl.u32 %v97562_v45, 16 (stack46)
        %v96385_v29 = vmul.f32 %v96381_v53, %v150136_v29 (stack54)
        %v97955_v9 = vxor.u32 %v97954_v21, %v97946_v9 (stack48)
        %v98379_v31 = vadd.s32 1, %v98375_v20 (stack40)
        %v98787_v55 = vsel /*vm=*/%vm98761_vm12, /*on_true_vy=*/%v98783_v61, /*on_false_vx=*/%v98779_v50 (stack44)
        %v97134_v23 = vadd.s32 %v97131_v24, %v121574_v2 (stack40)
        %v97569_v8 = vor.u32 %v97568_v6, %v97567_v7 (stack47)
        %v98792_v42 = vadd.s32 %v98787_v55, %v121574_v2 (stack40)
        %v98802_v41 = vshll.u32 %v150160_v52, 13 (stack45)
        %v96389_v10 = vadd.f32 %v96385_v29, %v150060_v10 (stack53)
        %v97958_v46 = vadd.s32 %v97955_v9, %v121574_v2 (stack40)
        %v98383_v54 = vadd.s32 %v98379_v31, %v98367_v54 (stack40)
        %v98385_v40 = vshll.u32 %v98379_v31, 17 (stack45)
        %v97138_v45 = vadd.s32 5, %v97134_v23 (stack40)
        %v97570_v50 = vxor.u32 %v97569_v8, %v97565_v25 (stack48)
        %v98386_v53 = vshrl.u32 %v98379_v31, 15 (stack46)
        %v98800_v21 = vadd.s32 %v150160_v52, %v98792_v42 (stack40)
        %v96393_v34 = vmul.f32 %v96389_v10, %v149978_v34 (stack54)
        %v97962_v20 = vadd.s32 2, %v97958_v46 (stack40)
        %v98803_v52 = vshrl.u32 %v150160_v52, 19 (stack46)
        %v150213_v61 = vadd.s32 %v157684_v56, %v157083_v59 (stack40)
        %v121258_v24 = vpop.eup %121257 (stack64)
        %v97140_v32 = vxor.u32 %v97138_v45, %v97126_v32 (stack48)
        %v97573_v25 = vadd.s32 %v97570_v50, %v97565_v25 (stack40)
        %v97579_v7 = vshll.u32 %v97570_v50, 24 (stack45)
        %v97580_v6 = vshrl.u32 %v97570_v50, 8 (stack46)
        %v96397_v60 = vsel /*vm=*/%vm150188_vm13, /*on_true_vy=*/%v150055_v60, /*on_false_vx=*/%v96393_v34 (stack44)
        %v96720_v27 = vmul.f32 0.6931472, %v121258_v24 (stack65)
        %v97966_v12 = vadd.s32 %v97962_v20, %v97950_v12 (stack40)
        %v97968_v29 = vshll.u32 %v97962_v20, 13 (stack45)
        %v96401_v9 = vmul.f32 1.4140625, %v96397_v60 (stack54)
        %vm96725_vm14 = vcmp.lt.f32.partialorder %v96724_v26, 0.0004427343 (stack62)
        %v97141_v30 = vand.u32.u8 255, %v97140_v32 (stack49)
        %v97581_v26 = vor.u32 %v97580_v6, %v97579_v7 (stack47)
        %v96726_v22 = vsel /*vm=*/%vm96725_vm14, /*on_true_vy=*/%v96723_v22, /*on_false_vx=*/%v96720_v27 (stack66)
        %v97969_v31 = vshrl.u32 %v97962_v20, 19 (stack46)
        %v98387_v55 = vor.u32 %v98386_v53, %v98385_v40 (stack47)
        %v98804_v23 = vor.u32 %v98803_v52, %v98802_v41 (stack47)
        %v96404_v8 = vpack.c.bf16 %v157387_v11, %v96401_v9 (stack81)
        %v150221_v42 = vxor.u32 2147483648, %v96726_v22 (stack56)
        %v97582_v41 = vxor.u32 %v97581_v26, %v97573_v25 (stack48)
        %v97970_v10 = vor.u32 %v97969_v31, %v97968_v29 (stack47)
        %v98388_v46 = vxor.u32 %v98387_v55, %v98383_v54 (stack48)
        %v98805_v40 = vxor.u32 %v98804_v23, %v98800_v21 (stack48)
        %120259 = vst [vmem:[%s123356_s30 + $0x2e4] sm:$0xf] /*vst_source=*/%v96404_v8 (stack83)
        %121259 = vrsqrt.f32 %v150221_v42 (stack67)
        %v97142_v45 = vand.u32 65535, %v97141_v30 (stack50)
        %vm96730_vm15 = vcmp.lt.f32.partialorder %v150221_v42, 5.0 (stack68)
        %v97585_v50 = vadd.s32 %v97582_v41, %v121564_v0 (stack40)
        %v97971_v53 = vxor.u32 %v97970_v10, %v97966_v12 (stack48)
        %v97577_v34 = vadd.s32 %v97573_v25, %v121569_v1 (stack40)
        %v98391_v54 = vadd.s32 %v98388_v46, %v98383_v54 (stack40)
        %v150230_v20 = vadd.s32 %v150213_v61, %v122657_v58 (stack40)
        %v150235_v52 = vsel /*vm=*/%vm96730_vm15, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v150238_v24 = vadd.f32 -2.5, %v150221_v42 (stack53)
        %v97143_v32 = vshrl.u32 %v97142_v45, 1 (stack51)
        %v97589_v25 = vadd.s32 4, %v97585_v50 (stack40)
        %v97974_v7 = vadd.s32 %v97971_v53, %v97966_v12 (stack40)
        %v97976_v6 = vshll.u32 %v97971_v53, 15 (stack45)
        %v97977_v60 = vshrl.u32 %v97971_v53, 17 (stack46)
        %v98393_v27 = vshll.u32 %v98388_v46, 29 (stack45)
        %v97144_v12 = vor.u32 16256, %v97143_v32 (stack47)
        %v97593_v29 = vadd.s32 %v97589_v25, %v97577_v34 (stack40)
        %v97595_v9 = vshll.u32 %v97589_v25, 13 (stack45)
        %v97596_v30 = vshrl.u32 %v97589_v25, 19 (stack46)
        %vm96775_vm0 = vcmp.eq.f32.partialorder %v150221_v42, inf (stack70)
        %v97978_v26 = vor.u32 %v97977_v60, %v97976_v6 (stack47)
        %v98394_v22 = vshrl.u32 %v98388_v46, 3 (stack46)
        %v98808_v21 = vadd.s32 %v98805_v40, %v98800_v21 (stack40)
        %v98810_v31 = vshll.u32 %v98805_v40, 15 (stack45)
        %v150244_v55 = vsel /*vm=*/%vm96730_vm15, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v97145_v23 = vand.u32.u16 65535, %v97144_v12 (stack52)
        %v97597_v8 = vor.u32 %v97596_v30, %v97595_v9 (stack47)
        %v98811_v41 = vshrl.u32 %v98805_v40, 17 (stack46)
        %v97979_v10 = vxor.u32 %v97978_v26, %v97974_v7 (stack48)
        %v98395_v46 = vor.u32 %v98394_v22, %v98393_v27 (stack47)
        %vm99227_vm1 = vcmp.lt.u32.totalorder %v150213_v61, %v157083_v59 (stack43)
        %v150250_v40 = vadd.s32 %v157687_v43, %v157084_v16 (stack40)
        %v150255_v45 = vsel /*vm=*/%vm96730_vm15, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v120262_v50 = vadd.low.f32.bf16 -1.0, %v97145_v23 (stack53)
        %v97598_v53 = vxor.u32 %v97597_v8, %v97593_v29 (stack48)
        %v98812_v34 = vor.u32 %v98811_v41, %v98810_v31 (stack47)
        %v97982_v32 = vadd.s32 %v97979_v10, %v97974_v7 (stack40)
        %v97984_v25 = vshll.u32 %v97979_v10, 26 (stack45)
        %v97985_v7 = vshrl.u32 %v97979_v10, 6 (stack46)
        %v98396_v6 = vxor.u32 %v98395_v46, %v98391_v54 (stack48)
        %v97154_v60 = vmul.f32 2.0, %v120262_v50 (stack54)
        %v97601_v27 = vadd.s32 %v97598_v53, %v97593_v29 (stack40)
        %v97603_v12 = vshll.u32 %v97598_v53, 15 (stack45)
        %v97604_v29 = vshrl.u32 %v97598_v53, 17 (stack46)
        %v121260_v9 = vpop.eup %121259 (stack73)
        %v97986_v30 = vor.u32 %v97985_v7, %v97984_v25 (stack47)
        %v98399_v54 = vadd.s32 %v98396_v6, %v98391_v54 (stack40)
        %v98401_v26 = vshll.u32 %v98396_v6, 16 (stack45)
        %v98402_v22 = vshrl.u32 %v98396_v6, 16 (stack46)
        %v96774_v31 = vmul.f32 %v121260_v9, %v150221_v42 (stack74)
        %v97158_v23 = vadd.f32 -0.99609375, %v97154_v60 (stack53)
        %v97605_v8 = vor.u32 %v97604_v29, %v97603_v12 (stack47)
        %v98813_v41 = vxor.u32 %v98812_v34, %v98808_v21 (stack48)
        %vm96777_vm2 = vcmp.eq.f32.partialorder %v150221_v42, 0.0 (stack71)
        %v96778_v10 = vand.u32 2147483648, %v150221_v42 (stack72)
        %v97987_v46 = vxor.u32 %v97986_v30, %v97982_v32 (stack48)
        %v98403_v50 = vor.u32 %v98402_v22, %v98401_v26 (stack47)
        %v96776_v53 = vsel /*vm=*/%vm96775_vm0, /*on_true_vy=*/%v150221_v42, /*on_false_vx=*/%v96774_v31 (stack75)
        %v150263_v34 = vmax.f32 %v97158_v23, -0.99609375 (stack55)
        %v97606_v25 = vxor.u32 %v97605_v8, %v97601_v27 (stack48)
        %v150265_v21 = vadd.s32 %v98813_v41, %v98808_v21 (stack40)
        %v96779_v7 = vsel /*vm=*/%vm96777_vm2, /*on_true_vy=*/%v96778_v10, /*on_false_vx=*/%v96776_v53 (stack76)
        %v97990_v32 = vadd.s32 %v97987_v46, %v97982_v32 (stack40)
        %v97996_v6 = vshll.u32 %v97987_v46, 6 (stack45)
        %v97997_v60 = vshrl.u32 %v97987_v46, 26 (stack46)
        %v96759_v12 = vsel /*vm=*/%vm96730_vm15, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v96782_v29 = vadd.f32 -3.0, %v96779_v7 (stack53)
        %v97174_v9 = vxor.u32 2147483648, %v150263_v34 (stack56)
        %v150273_v30 = vadd.s32 %v150230_v20, %v121569_v1 (stack40)
        %v96763_v26 = vsel /*vm=*/%vm96730_vm15, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v97609_v27 = vadd.s32 %v97606_v25, %v97601_v27 (stack40)
        %v97611_v22 = vshll.u32 %v97606_v25, 26 (stack45)
        %v97612_v31 = vshrl.u32 %v97606_v25, 6 (stack46)
        %v96767_v23 = vsel /*vm=*/%vm96730_vm15, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v150284_v24 = vsel /*vm=*/%vm96730_vm15, /*on_true_vy=*/%v150238_v24, /*on_false_vx=*/%v96782_v29 (stack44)
        %v97177_v8 = vmul.f32 %v97174_v9, %v150263_v34 (stack54)
        %v97998_v10 = vor.u32 %v97997_v60, %v97996_v6 (stack47)
        %v96790_v46 = vmul.f32 %v150284_v24, %v96767_v23 (stack54)
        %v97613_v53 = vor.u32 %v97612_v31, %v97611_v22 (stack47)
        %v98404_v50 = vxor.u32 %v98403_v50, %v98399_v54 (stack48)
        %vm99222_vm3 = vcmp.lt.u32.totalorder %v150230_v20, %v150213_v61 (stack43)
        %v99236_v25 = vadd.s32 1, %v150250_v40 (stack40)
        %v97179_v7 = vadd.f32 1.0, %v97177_v8 (stack57)
        %v97182_v6 = vmul.f32 -0.5, %v97177_v8 (stack59)
        %v97999_v60 = vxor.u32 %v97998_v10, %v97990_v32 (stack48)
        %v99263_v29 = vshll.u32 %v150273_v30, 13 (stack45)
        %v96794_v9 = vadd.f32 %v96790_v46, %v96763_v26 (stack53)
        %v97614_v26 = vxor.u32 %v97613_v53, %v97609_v27 (stack48)
        %v97994_v32 = vadd.s32 %v97990_v32, %v121574_v2 (stack40)
        %v98407_v54 = vadd.s32 %v98404_v50, %v98399_v54 (stack40)
        %121261 = vlog2.f32 %v97179_v7 (stack58)
        %v98002_v22 = vadd.s32 %v97999_v60, %v121569_v1 (stack40)
        %v98413_v31 = vshll.u32 %v98404_v50, 24 (stack45)
        %v98818_v23 = vshll.u32 %v98813_v41, 26 (stack45)
        %v96798_v10 = vmul.f32 %v96794_v9, %v150284_v24 (stack54)
        %v97617_v27 = vadd.s32 %v97614_v26, %v97609_v27 (stack40)
        %v97623_v46 = vshll.u32 %v97614_v26, 6 (stack45)
        %v97624_v53 = vshrl.u32 %v97614_v26, 26 (stack46)
        %v97183_v7 = vadd.f32 1.0, %v97182_v6 (stack61)
        %v97185_v6 = vand.u32 2147483647, %v97177_v8 (stack60)
        %v98006_v60 = vadd.s32 3, %v98002_v22 (stack40)
        %v98414_v50 = vshrl.u32 %v98404_v50, 8 (stack46)
        %v96802_v12 = vadd.f32 %v96798_v10, %v96759_v12 (stack53)
        %v97625_v9 = vor.u32 %v97624_v53, %v97623_v46 (stack47)
        %v98411_v26 = vadd.s32 %v98407_v54, %v121564_v0 (stack40)
        %v98819_v41 = vshrl.u32 %v98813_v41, 6 (stack46)
        %v98010_v32 = vadd.s32 %v98006_v60, %v97994_v32 (stack40)
        %v98012_v22 = vshll.u32 %v98006_v60, 17 (stack45)
        %v98013_v10 = vshrl.u32 %v98006_v60, 15 (stack46)
        %v98415_v31 = vor.u32 %v98414_v50, %v98413_v31 (stack47)
        %v96806_v46 = vmul.f32 %v96802_v12, %v150284_v24 (stack54)
        %v97626_v53 = vxor.u32 %v97625_v9, %v97617_v27 (stack48)
        %v98820_v23 = vor.u32 %v98819_v41, %v98818_v23 (stack47)
        %v99240_v40 = vsel /*vm=*/%vm99227_vm1, /*on_true_vy=*/%v99236_v25, /*on_false_vx=*/%v150250_v40 (stack44)
        %v97621_v25 = vadd.s32 %v97617_v27, %v121564_v0 (stack40)
        %v98014_v27 = vor.u32 %v98013_v10, %v98012_v22 (stack47)
        %v98416_v54 = vxor.u32 %v98415_v31, %v98407_v54 (stack48)
        %v99244_v60 = vadd.s32 1, %v99240_v40 (stack40)
        %v96810_v45 = vadd.f32 %v96806_v46, %v150255_v45 (stack53)
        %vm150303_vm4 = vcmp.lt.f32.partialorder %v97185_v6, 0.0004427343 (stack62)
        %v97629_v50 = vadd.s32 %v97626_v53, %v121574_v2 (stack40)
        %v98821_v12 = vxor.u32 %v98820_v23, %v150265_v21 (stack48)
        %v150311_v9 = vadd.s32 %v157684_v56, %v157089_v17 (stack40)
        %v98015_v41 = vxor.u32 %v98014_v27, %v98010_v32 (stack48)
        %v98419_v22 = vadd.s32 %v98416_v54, %v121574_v2 (stack40)
        %v99248_v61 = vsel /*vm=*/%vm99222_vm3, /*on_true_vy=*/%v99244_v60, /*on_false_vx=*/%v99240_v40 (stack44)
        %v99264_v20 = vshrl.u32 %v150273_v30, 19 (stack46)
        %v96814_v10 = vmul.f32 %v96810_v45, %v150284_v24 (stack54)
        %v97633_v31 = vadd.s32 5, %v97629_v50 (stack40)
        %v98824_v21 = vadd.s32 %v98821_v12, %v150265_v21 (stack40)
        %v98830_v46 = vshll.u32 %v98821_v12, 6 (stack45)
        %v98018_v32 = vadd.s32 %v98015_v41, %v98010_v32 (stack40)
        %v98020_v53 = vshll.u32 %v98015_v41, 29 (stack45)
        %v98021_v23 = vshrl.u32 %v98015_v41, 3 (stack46)
        %v98423_v40 = vadd.s32 2, %v98419_v22 (stack40)
        %v96818_v55 = vadd.f32 %v96814_v10, %v150244_v55 (stack53)
        %v97184_v8 = vmul.f32 %v97183_v7, %v97177_v8 (stack63)
        %v97635_v7 = vxor.u32 %v97633_v31, %v97621_v25 (stack48)
        %v98831_v25 = vshrl.u32 %v98821_v12, 26 (stack46)
        %v98022_v27 = vor.u32 %v98021_v23, %v98020_v53 (stack47)
        %v98427_v26 = vadd.s32 %v98423_v40, %v98411_v26 (stack40)
        %v98429_v54 = vshll.u32 %v98423_v40, 13 (stack45)
        %v98430_v60 = vshrl.u32 %v98423_v40, 19 (stack46)
        %v121262_v45 = vpop.eup %121261 (stack64)
        %v96822_v50 = vmul.f32 %v96818_v55, %v150284_v24 (stack54)
        %v97636_v12 = vand.u32.u8 255, %v97635_v7 (stack49)
        %v98832_v41 = vor.u32 %v98831_v25, %v98830_v46 (stack47)
        %v99253_v22 = vadd.s32 %v99248_v61, %v121574_v2 (stack40)
        %v97181_v61 = vmul.f32 0.6931472, %v121262_v45 (stack65)
        %v98023_v10 = vxor.u32 %v98022_v27, %v98018_v32 (stack48)
        %v98431_v31 = vor.u32 %v98430_v60, %v98429_v54 (stack47)
        %v99265_v29 = vor.u32 %v99264_v20, %v99263_v29 (stack47)
        %v96826_v52 = vadd.f32 %v96822_v50, %v150235_v52 (stack53)
        %v97637_v20 = vand.u32 65535, %v97636_v12 (stack50)
        %v98833_v46 = vxor.u32 %v98832_v41, %v98824_v21 (stack48)
        %v99261_v30 = vadd.s32 %v150273_v30, %v99253_v22 (stack40)
        %v97187_v6 = vsel /*vm=*/%vm150303_vm4, /*on_true_vy=*/%v97184_v8, /*on_false_vx=*/%v97181_v61 (stack66)
        %v98026_v32 = vadd.s32 %v98023_v10, %v98018_v32 (stack40)
        %v98028_v53 = vshll.u32 %v98023_v10, 16 (stack45)
        %v98029_v23 = vshrl.u32 %v98023_v10, 16 (stack46)
        %v96830_v40 = vmul.f32 %v96826_v52, %v150284_v24 (stack54)
        %v150330_v55 = vxor.u32 2147483648, %v97187_v6 (stack56)
        %v98432_v8 = vxor.u32 %v98431_v31, %v98427_v26 (stack48)
        %v96703_v7 = vand.u32 2147483647, %v150163_v44 (stack77)
        %v96743_v25 = vsel /*vm=*/%vm96730_vm15, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v98030_v27 = vor.u32 %v98029_v23, %v98028_v53 (stack47)
        %v99266_v54 = vxor.u32 %v99265_v29, %v99261_v30 (stack48)
        %v96834_v60 = vadd.f32 %v96830_v40, %v96743_v25 (stack53)
        %121263 = vrsqrt.f32 %v150330_v55 (stack67)
        %vm97191_vm5 = vcmp.lt.f32.partialorder %v150330_v55, 5.0 (stack68)
        %v97638_v45 = vshrl.u32 %v97637_v20, 1 (stack51)
        %v98031_v50 = vxor.u32 %v98030_v27, %v98026_v32 (stack48)
        %v96711_v12 = vmul.f32 inf, %v150163_v44 (stack54)
        %v96735_v41 = vsel /*vm=*/%vm96730_vm15, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v96838_v22 = vmul.f32 %v96834_v60, %v150284_v24 (stack54)
        %vm150343_vm6 = vcmp.eq.f32.partialorder %v96703_v7, 1.0 (stack68)
        %v96739_v42 = vsel /*vm=*/%vm96730_vm15, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v98034_v10 = vadd.s32 %v98031_v50, %v98026_v32 (stack40)
        %v98828_v21 = vadd.s32 %v98824_v21, %v121569_v1 (stack40)
        %v98836_v31 = vadd.s32 %v98833_v46, %v121564_v0 (stack40)
        %v96842_v29 = vadd.f32 %v96838_v22, %v96739_v42 (stack53)
        %v150355_v52 = vsel /*vm=*/%vm97191_vm5, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v150358_v20 = vadd.f32 -2.5, %v150330_v55 (stack53)
        %v150362_v46 = vadd.s32 %v150311_v9, %v122657_v58 (stack40)
        %v97639_v6 = vor.u32 16256, %v97638_v45 (stack47)
        %v98038_v32 = vadd.s32 %v98034_v10, %v121569_v1 (stack40)
        %v98040_v53 = vshll.u32 %v98031_v50, 24 (stack45)
        %v98041_v23 = vshrl.u32 %v98031_v50, 8 (stack46)
        %v96846_v24 = vmul.f32 %v96842_v29, %v150284_v24 (stack54)
        %v98435_v26 = vadd.s32 %v98432_v8, %v98427_v26 (stack40)
        %v98437_v40 = vshll.u32 %v98432_v8, 15 (stack45)
        %v98438_v8 = vshrl.u32 %v98432_v8, 17 (stack46)
        %vm97236_vm7 = vcmp.eq.f32.partialorder %v150330_v55, inf (stack70)
        %v97640_v7 = vand.u32.u16 65535, %v97639_v6 (stack52)
        %v98042_v25 = vor.u32 %v98041_v23, %v98040_v53 (stack47)
        %v98840_v27 = vadd.s32 1, %v98836_v31 (stack40)
        %v150367_v30 = vadd.s32 %v99266_v54, %v99261_v30 (stack40)
        %v96850_v60 = vadd.f32 %v96846_v24, %v96735_v41 (stack53)
        %vm97238_vm8 = vcmp.eq.f32.partialorder %v150330_v55, 0.0 (stack71)
        %v98439_v45 = vor.u32 %v98438_v8, %v98437_v40 (stack47)
        %v99271_v50 = vshll.u32 %v99266_v54, 15 (stack45)
        %v99272_v54 = vshrl.u32 %v99266_v54, 17 (stack46)
        %v120268_v41 = vadd.low.f32.bf16 -1.0, %v97640_v7 (stack53)
        %v98043_v22 = vxor.u32 %v98042_v25, %v98034_v10 (stack48)
        %v98844_v42 = vadd.s32 %v98840_v27, %v98828_v21 (stack40)
        %v98846_v10 = vshll.u32 %v98840_v27, 17 (stack45)
        %v96854_v44 = vmul.f32 %v96850_v60, %v150163_v44 (stack54)
        %v98440_v21 = vxor.u32 %v98439_v45, %v98435_v26 (stack48)
        %v98847_v31 = vshrl.u32 %v98840_v27, 15 (stack46)
        %v99273_v29 = vor.u32 %v99272_v54, %v99271_v50 (stack47)
        %v97649_v6 = vmul.f32 2.0, %v120268_v41 (stack54)
        %v98046_v53 = vadd.s32 %v98043_v22, %v121564_v0 (stack40)
        %vm99688_vm9 = vcmp.lt.u32.totalorder %v150311_v9, %v157089_v17 (stack43)
        %v150376_v23 = vadd.s32 %v157687_v43, %v157090_v62 (stack40)
        %v96858_v12 = vsel /*vm=*/%vm150343_vm6, /*on_true_vy=*/%v96711_v12, /*on_false_vx=*/%v96854_v44 (stack44)
        %v98443_v61 = vadd.s32 %v98440_v21, %v98435_v26 (stack40)
        %v98445_v24 = vshll.u32 %v98440_v21, 26 (stack45)
        %v98446_v26 = vshrl.u32 %v98440_v21, 6 (stack46)
        %v121264_v40 = vpop.eup %121263 (stack73)
        %v96862_v8 = vmul.f32 1.4140625, %v96858_v12 (stack54)
        %v97653_v7 = vadd.f32 -0.99609375, %v97649_v6 (stack53)
        %v98050_v25 = vadd.s32 4, %v98046_v53 (stack40)
        %v98848_v27 = vor.u32 %v98847_v31, %v98846_v10 (stack47)
        %v97235_v60 = vmul.f32 %v121264_v40, %v150330_v55 (stack74)
        %v97239_v45 = vand.u32 2147483648, %v150330_v55 (stack72)
        %v98447_v50 = vor.u32 %v98446_v26, %v98445_v24 (stack47)
        %v99274_v54 = vxor.u32 %v99273_v29, %v150367_v30 (stack48)
        %v96865_v41 = vpack.c.bf16 %v157387_v11, %v96862_v8 (stack81)
        %v150384_v22 = vmax.f32 %v97653_v7, -0.99609375 (stack55)
        %v98054_v32 = vadd.s32 %v98050_v25, %v98038_v32 (stack40)
        %v98056_v10 = vshll.u32 %v98050_v25, 13 (stack45)
        %v97237_v44 = vsel /*vm=*/%vm97236_vm7, /*on_true_vy=*/%v150330_v55, /*on_false_vx=*/%v97235_v60 (stack75)
        %v98057_v21 = vshrl.u32 %v98050_v25, 19 (stack46)
        %v98448_v31 = vxor.u32 %v98447_v50, %v98443_v61 (stack48)
        %v98849_v29 = vxor.u32 %v98848_v27, %v98844_v42 (stack48)
        %120261 = vst [vmem:[%s123356_s30 + $0x364] sm:$0xf] /*vst_source=*/%v96865_v41 (stack83)
        %v150393_v6 = vsel /*vm=*/%vm97191_vm5, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v97216_v53 = vsel /*vm=*/%vm97191_vm5, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v97240_v12 = vsel /*vm=*/%vm97238_vm8, /*on_true_vy=*/%v97239_v45, /*on_false_vx=*/%v97237_v44 (stack76)
        %v97669_v24 = vxor.u32 2147483648, %v150384_v22 (stack56)
        %v97243_v26 = vadd.f32 -3.0, %v97240_v12 (stack53)
        %v98058_v40 = vor.u32 %v98057_v21, %v98056_v10 (stack47)
        %v98451_v61 = vadd.s32 %v98448_v31, %v98443_v61 (stack40)
        %v98457_v8 = vshll.u32 %v98448_v31, 6 (stack45)
        %vm99683_vm10 = vcmp.lt.u32.totalorder %v150362_v46, %v150311_v9 (stack43)
        %v97220_v7 = vsel /*vm=*/%vm97191_vm5, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v150407_v25 = vmul.f32 %v97669_v24, %v150384_v22 (stack54)
        %v98458_v27 = vshrl.u32 %v98448_v31, 26 (stack46)
        %v98852_v42 = vadd.s32 %v98849_v29, %v98844_v42 (stack40)
        %v97224_v60 = vsel /*vm=*/%vm97191_vm5, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v97228_v45 = vsel /*vm=*/%vm97191_vm5, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v150418_v20 = vsel /*vm=*/%vm97191_vm5, /*on_true_vy=*/%v150358_v20, /*on_false_vx=*/%v97243_v26 (stack44)
        %v98059_v50 = vxor.u32 %v98058_v40, %v98054_v32 (stack48)
        %v97251_v41 = vmul.f32 %v150418_v20, %v97228_v45 (stack54)
        %v97674_v10 = vadd.f32 1.0, %v150407_v25 (stack57)
        %v98854_v44 = vshll.u32 %v98849_v29, 29 (stack45)
        %v99697_v21 = vadd.s32 1, %v150376_v23 (stack40)
        %v98062_v32 = vadd.s32 %v98059_v50, %v98054_v32 (stack40)
        %v98064_v31 = vshll.u32 %v98059_v50, 15 (stack45)
        %v98065_v12 = vshrl.u32 %v98059_v50, 17 (stack46)
        %v98459_v24 = vor.u32 %v98458_v27, %v98457_v8 (stack47)
        %v97255_v26 = vadd.f32 %v97251_v41, %v97224_v60 (stack53)
        %121265 = vlog2.f32 %v97674_v10 (stack58)
        %v97677_v40 = vmul.f32 -0.5, %v150407_v25 (stack59)
        %v98455_v8 = vadd.s32 %v98451_v61, %v121574_v2 (stack40)
        %v98066_v27 = vor.u32 %v98065_v12, %v98064_v31 (stack47)
        %v98460_v61 = vxor.u32 %v98459_v24, %v98451_v61 (stack48)
        %v98855_v29 = vshrl.u32 %v98849_v29, 3 (stack46)
        %v99277_v30 = vadd.s32 %v99274_v54, %v150367_v30 (stack40)
        %v97259_v60 = vmul.f32 %v97255_v26, %v150418_v20 (stack54)
        %v97680_v45 = vand.u32 2147483647, %v150407_v25 (stack60)
        %v99279_v50 = vshll.u32 %v99274_v54, 26 (stack45)
        %v99280_v54 = vshrl.u32 %v99274_v54, 6 (stack46)
        %v98067_v41 = vxor.u32 %v98066_v27, %v98062_v32 (stack48)
        %v98463_v10 = vadd.s32 %v98460_v61, %v121569_v1 (stack40)
        %v98856_v44 = vor.u32 %v98855_v29, %v98854_v44 (stack47)
        %v99701_v23 = vsel /*vm=*/%vm99688_vm9, /*on_true_vy=*/%v99697_v21, /*on_false_vx=*/%v150376_v23 (stack44)
        %v97263_v7 = vadd.f32 %v97259_v60, %v97220_v7 (stack53)
        %v97678_v21 = vadd.f32 1.0, %v97677_v40 (stack61)
        %v99281_v31 = vor.u32 %v99280_v54, %v99279_v50 (stack47)
        %v99705_v12 = vadd.s32 1, %v99701_v23 (stack40)
        %v98070_v32 = vadd.s32 %v98067_v41, %v98062_v32 (stack40)
        %v98072_v24 = vshll.u32 %v98067_v41, 26 (stack45)
        %v98073_v26 = vshrl.u32 %v98067_v41, 6 (stack46)
        %v98467_v40 = vadd.s32 3, %v98463_v10 (stack40)
        %v97267_v27 = vmul.f32 %v97263_v7, %v150418_v20 (stack54)
        %v98857_v61 = vxor.u32 %v98856_v44, %v98852_v42 (stack48)
        %v99282_v29 = vxor.u32 %v99281_v31, %v99277_v30 (stack48)
        %v99709_v9 = vsel /*vm=*/%vm99683_vm10, /*on_true_vy=*/%v99705_v12, /*on_false_vx=*/%v99701_v23 (stack44)
        %v98074_v60 = vor.u32 %v98073_v26, %v98072_v24 (stack47)
        %v98471_v8 = vadd.s32 %v98467_v40, %v98455_v8 (stack40)
        %v98473_v50 = vshll.u32 %v98467_v40, 17 (stack45)
        %v98474_v54 = vshrl.u32 %v98467_v40, 15 (stack46)
        %v97271_v53 = vadd.f32 %v97267_v27, %v97216_v53 (stack53)
        %v98860_v42 = vadd.s32 %v98857_v61, %v98852_v42 (stack40)
        %v98862_v41 = vshll.u32 %v98857_v61, 16 (stack45)
        %v98863_v10 = vshrl.u32 %v98857_v61, 16 (stack46)
        %v98075_v44 = vxor.u32 %v98074_v60, %v98070_v32 (stack48)
        %v98475_v23 = vor.u32 %v98474_v54, %v98473_v50 (stack47)
        %v99285_v30 = vadd.s32 %v99282_v29, %v99277_v30 (stack40)
        %v99291_v7 = vshll.u32 %v99282_v29, 6 (stack45)
        %v97275_v31 = vmul.f32 %v97271_v53, %v150418_v20 (stack54)
        %vm150438_vm11 = vcmp.lt.f32.partialorder %v97680_v45, 0.0004427343 (stack62)
        %v98864_v12 = vor.u32 %v98863_v10, %v98862_v41 (stack47)
        %v99292_v24 = vshrl.u32 %v99282_v29, 26 (stack46)
        %v98078_v32 = vadd.s32 %v98075_v44, %v98070_v32 (stack40)
        %v98084_v26 = vshll.u32 %v98075_v44, 6 (stack45)
        %v98085_v40 = vshrl.u32 %v98075_v44, 26 (stack46)
        %v98476_v27 = vxor.u32 %v98475_v23, %v98471_v8 (stack48)
        %v97279_v6 = vadd.f32 %v97275_v31, %v150393_v6 (stack53)
        %v97679_v25 = vmul.f32 %v97678_v21, %v150407_v25 (stack63)
        %v98865_v21 = vxor.u32 %v98864_v12, %v98860_v42 (stack48)
        %v99293_v61 = vor.u32 %v99292_v24, %v99291_v7 (stack47)
        %v121266_v29 = vpop.eup %121265 (stack64)
        %v98086_v60 = vor.u32 %v98085_v40, %v98084_v26 (stack47)
        %v98479_v8 = vadd.s32 %v98476_v27, %v98471_v8 (stack40)
        %v98481_v50 = vshll.u32 %v98476_v27, 29 (stack45)
        %v99714_v9 = vadd.s32 %v99709_v9, %v121574_v2 (stack40)
        %v97283_v54 = vmul.f32 %v97279_v6, %v150418_v20 (stack54)
        %v97676_v53 = vmul.f32 0.6931472, %v121266_v29 (stack65)
        %v98482_v41 = vshrl.u32 %v98476_v27, 3 (stack46)
        %v98868_v42 = vadd.s32 %v98865_v21, %v98860_v42 (stack40)
        %v98087_v10 = vxor.u32 %v98086_v60, %v98078_v32 (stack48)
        %v98874_v44 = vshll.u32 %v98865_v21, 24 (stack45)
        %v99294_v23 = vxor.u32 %v99293_v61, %v99285_v30 (stack48)
        %v99718_v46 = vadd.s32 %v150362_v46, %v121569_v1 (stack40)
        %v97287_v52 = vadd.f32 %v97283_v54, %v150355_v52 (stack53)
        %v97682_v7 = vsel /*vm=*/%vm150438_vm11, /*on_true_vy=*/%v97679_v25, /*on_false_vx=*/%v97676_v53 (stack66)
        %v98483_v31 = vor.u32 %v98482_v41, %v98481_v50 (stack47)
        %v98875_v45 = vshrl.u32 %v98865_v21, 8 (stack46)
        %v97164_v12 = vand.u32 2147483647, %v150263_v34 (stack77)
        %v150453_v24 = vmul.f32 inf, %v150263_v34 (stack54)
        %v150455_v26 = vxor.u32 2147483648, %v97682_v7 (stack56)
        %v97196_v40 = vsel /*vm=*/%vm97191_vm5, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v97291_v27 = vmul.f32 %v97287_v52, %v150418_v20 (stack54)
        %v98484_v6 = vxor.u32 %v98483_v31, %v98479_v8 (stack48)
        %v150461_v25 = vadd.s32 %v99718_v46, %v99714_v9 (stack40)
        %v97200_v21 = vsel /*vm=*/%vm97191_vm5, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v97204_v55 = vsel /*vm=*/%vm97191_vm5, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %121267 = vrsqrt.f32 %v150455_v26 (stack67)
        %v98090_v61 = vadd.s32 %v98087_v10, %v121574_v2 (stack40)
        %v97295_v29 = vadd.f32 %v97291_v27, %v97204_v55 (stack53)
        %vm97686_vm12 = vcmp.lt.f32.partialorder %v150455_v26, 5.0 (stack68)
        %v98876_v60 = vor.u32 %v98875_v45, %v98874_v44 (stack47)
        %v99297_v50 = vadd.s32 %v99294_v23, %v121564_v0 (stack40)
        %v97659_v9 = vand.u32 2147483647, %v150384_v22 (stack77)
        %v98082_v32 = vadd.s32 %v98078_v32, %v121564_v0 (stack40)
        %v98487_v8 = vadd.s32 %v98484_v6, %v98479_v8 (stack40)
        %v99289_v30 = vadd.s32 %v99285_v30, %v121569_v1 (stack40)
        %v97299_v54 = vmul.f32 %v97295_v29, %v150418_v20 (stack54)
        %v150478_v53 = vadd.f32 -2.5, %v150455_v26 (stack53)
        %v98872_v41 = vadd.s32 %v98868_v42, %v121564_v0 (stack40)
        %v99724_v10 = vshll.u32 %v99718_v46, 13 (stack45)
        %vm150481_vm13 = vcmp.eq.f32.partialorder %v97164_v12, 1.0 (stack68)
        %v150488_v23 = vsel /*vm=*/%vm97686_vm12, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v150493_v52 = vsel /*vm=*/%vm97686_vm12, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v98094_v7 = vadd.s32 5, %v98090_v61 (stack40)
        %v98489_v31 = vshll.u32 %v98484_v6, 16 (stack45)
        %v97303_v45 = vadd.f32 %v97299_v54, %v97200_v21 (stack53)
        %v98490_v12 = vshrl.u32 %v98484_v6, 16 (stack46)
        %v98877_v42 = vxor.u32 %v98876_v60, %v98868_v42 (stack48)
        %v99301_v27 = vadd.s32 1, %v99297_v50 (stack40)
        %v98096_v6 = vxor.u32 %v98094_v7, %v98082_v32 (stack48)
        %v99725_v46 = vshrl.u32 %v99718_v46, 19 (stack46)
        %v150497_v21 = vadd.s32 %v157684_v56, %v157091_v37 (stack40)
        %v150501_v55 = vadd.s32 %v157687_v43, %v157094_v36 (stack40)
        %v97307_v20 = vmul.f32 %v97303_v45, %v150418_v20 (stack54)
        %vm97731_vm14 = vcmp.eq.f32.partialorder %v150455_v26, inf (stack70)
        %v98491_v61 = vor.u32 %v98490_v12, %v98489_v31 (stack47)
        %v98880_v29 = vadd.s32 %v98877_v42, %v121574_v2 (stack40)
        %v99305_v60 = vadd.s32 %v99301_v27, %v99289_v30 (stack40)
        %vm97733_vm15 = vcmp.eq.f32.partialorder %v150455_v26, 0.0 (stack71)
        %v98097_v50 = vand.u32.u8 255, %v98096_v6 (stack49)
        %v99307_v32 = vshll.u32 %v99301_v27, 17 (stack45)
        %v99308_v30 = vshrl.u32 %v99301_v27, 15 (stack46)
        %v99726_v54 = vor.u32 %v99725_v46, %v99724_v10 (stack47)
        %v97311_v40 = vadd.f32 %v97307_v20, %v97196_v40 (stack53)
        %v97734_v10 = vand.u32 2147483648, %v150455_v26 (stack72)
        %v98492_v7 = vxor.u32 %v98491_v61, %v98487_v8 (stack48)
        %v98884_v31 = vadd.s32 2, %v98880_v29 (stack40)
        %v98098_v45 = vand.u32 65535, %v98097_v50 (stack50)
        %v99309_v12 = vor.u32 %v99308_v30, %v99307_v32 (stack47)
        %v99727_v42 = vxor.u32 %v99726_v54, %v150461_v25 (stack48)
        %vm100149_vm0 = vcmp.lt.u32.totalorder %v150497_v21, %v157091_v37 (stack43)
        %v97315_v34 = vmul.f32 %v97311_v40, %v150263_v34 (stack54)
        %v98495_v8 = vadd.s32 %v98492_v7, %v98487_v8 (stack40)
        %v98501_v27 = vshll.u32 %v98492_v7, 24 (stack45)
        %v98502_v6 = vshrl.u32 %v98492_v7, 8 (stack46)
        %v98099_v46 = vshrl.u32 %v98098_v45, 1 (stack51)
        %v98888_v41 = vadd.s32 %v98884_v31, %v98872_v41 (stack40)
        %v98890_v20 = vshll.u32 %v98884_v31, 13 (stack45)
        %v98891_v61 = vshrl.u32 %v98884_v31, 19 (stack46)
        %v121268_v29 = vpop.eup %121267 (stack73)
        %v97319_v24 = vsel /*vm=*/%vm150481_vm13, /*on_true_vy=*/%v150453_v24, /*on_false_vx=*/%v97315_v34 (stack44)
        %v98499_v44 = vadd.s32 %v98495_v8, %v121569_v1 (stack40)
        %v98503_v50 = vor.u32 %v98502_v6, %v98501_v27 (stack47)
        %v99310_v32 = vxor.u32 %v99309_v12, %v99305_v60 (stack48)
        %v97323_v30 = vmul.f32 1.4140625, %v97319_v24 (stack54)
        %v97730_v54 = vmul.f32 %v121268_v29, %v150455_v26 (stack74)
        %v98100_v40 = vor.u32 16256, %v98099_v46 (stack47)
        %v98892_v7 = vor.u32 %v98891_v61, %v98890_v20 (stack47)
        %v98504_v31 = vxor.u32 %v98503_v50, %v98495_v8 (stack48)
        %v99313_v60 = vadd.s32 %v99310_v32, %v99305_v60 (stack40)
        %v99315_v45 = vshll.u32 %v99310_v32, 29 (stack45)
        %v99316_v12 = vshrl.u32 %v99310_v32, 3 (stack46)
        %v97326_v34 = vpack.c.bf16 %v157387_v11, %v97323_v30 (stack81)
        %v97732_v8 = vsel /*vm=*/%vm97731_vm14, /*on_true_vy=*/%v150455_v26, /*on_false_vx=*/%v97730_v54 (stack75)
        %v98101_v27 = vand.u32.u16 65535, %v98100_v40 (stack52)
        %v98893_v6 = vxor.u32 %v98892_v7, %v98888_v41 (stack48)
        %v97735_v10 = vsel /*vm=*/%vm97733_vm15, /*on_true_vy=*/%v97734_v10, /*on_false_vx=*/%v97732_v8 (stack76)
        %v98507_v46 = vadd.s32 %v98504_v31, %v121564_v0 (stack40)
        %v99317_v20 = vor.u32 %v99316_v12, %v99315_v45 (stack47)
        %v99730_v25 = vadd.s32 %v99727_v42, %v150461_v25 (stack40)
        %120263 = vst [vmem:[%s123356_s30 + $0x3e4] sm:$0xf] /*vst_source=*/%v97326_v34 (stack83)
        %v97738_v61 = vadd.f32 -3.0, %v97735_v10 (stack53)
        %v120270_v29 = vadd.low.f32.bf16 -1.0, %v98101_v27 (stack53)
        %v98896_v41 = vadd.s32 %v98893_v6, %v98888_v41 (stack40)
        %v98898_v24 = vshll.u32 %v98893_v6, 15 (stack45)
        %v98511_v50 = vadd.s32 4, %v98507_v46 (stack40)
        %v98899_v32 = vshrl.u32 %v98893_v6, 17 (stack46)
        %v99318_v30 = vxor.u32 %v99317_v20, %v99313_v60 (stack48)
        %v99732_v54 = vshll.u32 %v99727_v42, 15 (stack45)
        %v97723_v40 = vsel /*vm=*/%vm97686_vm12, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v150532_v53 = vsel /*vm=*/%vm97686_vm12, /*on_true_vy=*/%v150478_v53, /*on_false_vx=*/%v97738_v61 (stack44)
        %v98110_v7 = vmul.f32 2.0, %v120270_v29 (stack54)
        %v99733_v42 = vshrl.u32 %v99727_v42, 17 (stack46)
        %v97746_v31 = vmul.f32 %v150532_v53, %v97723_v40 (stack54)
        %v98515_v44 = vadd.s32 %v98511_v50, %v98499_v44 (stack40)
        %v98517_v45 = vshll.u32 %v98511_v50, 13 (stack45)
        %v98518_v12 = vshrl.u32 %v98511_v50, 19 (stack46)
        %v98114_v34 = vadd.f32 -0.99609375, %v98110_v7 (stack53)
        %v98900_v8 = vor.u32 %v98899_v32, %v98898_v24 (stack47)
        %v99321_v60 = vadd.s32 %v99318_v30, %v99313_v60 (stack40)
        %v99323_v27 = vshll.u32 %v99318_v30, 16 (stack45)
        %v97750_v52 = vadd.f32 %v97746_v31, %v150493_v52 (stack53)
        %v98519_v6 = vor.u32 %v98518_v12, %v98517_v45 (stack47)
        %v99324_v10 = vshrl.u32 %v99318_v30, 16 (stack46)
        %v99734_v46 = vor.u32 %v99733_v42, %v99732_v54 (stack47)
        %v150539_v20 = vsel /*vm=*/%vm97686_vm12, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v97703_v61 = vsel /*vm=*/%vm97686_vm12, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v150544_v29 = vmax.f32 %v98114_v34, -0.99609375 (stack55)
        %v98901_v24 = vxor.u32 %v98900_v8, %v98896_v41 (stack48)
        %v97754_v50 = vmul.f32 %v97750_v52, %v150532_v53 (stack54)
        %v98520_v32 = vxor.u32 %v98519_v6, %v98515_v44 (stack48)
        %v99325_v30 = vor.u32 %v99324_v10, %v99323_v27 (stack47)
        %v99735_v54 = vxor.u32 %v99734_v46, %v99730_v25 (stack48)
        %v97715_v40 = vsel /*vm=*/%vm97686_vm12, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v98130_v7 = vxor.u32 2147483648, %v150544_v29 (stack56)
        %v98904_v41 = vadd.s32 %v98901_v24, %v98896_v41 (stack40)
        %v100140_v42 = vadd.s32 %v150497_v21, %v122657_v58 (stack40)
        %v97758_v31 = vadd.f32 %v97754_v50, %v97715_v40 (stack53)
        %v98523_v44 = vadd.s32 %v98520_v32, %v98515_v44 (stack40)
        %v98525_v45 = vshll.u32 %v98520_v32, 15 (stack45)
        %v98526_v12 = vshrl.u32 %v98520_v32, 17 (stack46)
        %v97707_v34 = vsel /*vm=*/%vm97686_vm12, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v150557_v8 = vmul.f32 %v98130_v7, %v150544_v29 (stack54)
        %v98906_v27 = vshll.u32 %v98901_v24, 26 (stack45)
        %v98907_v52 = vshrl.u32 %v98901_v24, 6 (stack46)
        %v97762_v6 = vmul.f32 %v97758_v31, %v150532_v53 (stack54)
        %v98527_v10 = vor.u32 %v98526_v12, %v98525_v45 (stack47)
        %v99326_v46 = vxor.u32 %v99325_v30, %v99321_v60 (stack48)
        %v99738_v25 = vadd.s32 %v99735_v54, %v99730_v25 (stack40)
        %v97711_v24 = vsel /*vm=*/%vm97686_vm12, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v98135_v50 = vadd.f32 1.0, %v150557_v8 (stack57)
        %v98908_v32 = vor.u32 %v98907_v52, %v98906_v27 (stack47)
        %vm100144_vm1 = vcmp.lt.u32.totalorder %v100140_v42, %v150497_v21 (stack43)
        %v97766_v30 = vadd.f32 %v97762_v6, %v97711_v24 (stack53)
        %v98528_v40 = vxor.u32 %v98527_v10, %v98523_v44 (stack48)
        %v99329_v60 = vadd.s32 %v99326_v46, %v99321_v60 (stack40)
        %v100158_v7 = vadd.s32 1, %v150501_v55 (stack40)
        %121269 = vlog2.f32 %v98135_v50 (stack58)
        %v98138_v31 = vmul.f32 -0.5, %v150557_v8 (stack59)
        %v98909_v45 = vxor.u32 %v98908_v32, %v98904_v41 (stack48)
        %v99335_v12 = vshll.u32 %v99326_v46, 24 (stack45)
        %v97770_v27 = vmul.f32 %v97766_v30, %v150532_v53 (stack54)
        %v98531_v44 = vadd.s32 %v98528_v40, %v98523_v44 (stack40)
        %v98533_v52 = vshll.u32 %v98528_v40, 26 (stack45)
        %v98534_v6 = vshrl.u32 %v98528_v40, 6 (stack46)
        %v98912_v41 = vadd.s32 %v98909_v45, %v98904_v41 (stack40)
        %v98918_v10 = vshll.u32 %v98909_v45, 6 (stack45)
        %v98919_v24 = vshrl.u32 %v98909_v45, 26 (stack46)
        %v150569_v50 = vadd.s32 %v100140_v42, %v121569_v1 (stack40)
        %v97774_v34 = vadd.f32 %v97770_v27, %v97707_v34 (stack53)
        %v98141_v32 = vand.u32 2147483647, %v150557_v8 (stack60)
        %v98535_v30 = vor.u32 %v98534_v6, %v98533_v52 (stack47)
        %v99336_v46 = vshrl.u32 %v99326_v46, 8 (stack46)
        %v98139_v40 = vadd.f32 1.0, %v98138_v31 (stack61)
        %v98920_v31 = vor.u32 %v98919_v24, %v98918_v10 (stack47)
        %v99740_v45 = vshll.u32 %v99735_v54, 26 (stack45)
        %v99741_v54 = vshrl.u32 %v99735_v54, 6 (stack46)
        %v97778_v27 = vmul.f32 %v97774_v34, %v150532_v53 (stack54)
        %v98536_v52 = vxor.u32 %v98535_v30, %v98531_v44 (stack48)
        %v99337_v12 = vor.u32 %v99336_v46, %v99335_v12 (stack47)
        %v100162_v55 = vsel /*vm=*/%vm100149_vm0, /*on_true_vy=*/%v100158_v7, /*on_false_vx=*/%v150501_v55 (stack44)
        %v98921_v7 = vxor.u32 %v98920_v31, %v98912_v41 (stack48)
        %v99333_v6 = vadd.s32 %v99329_v60, %v121564_v0 (stack40)
        %v99742_v10 = vor.u32 %v99741_v54, %v99740_v45 (stack47)
        %v100166_v24 = vadd.s32 1, %v100162_v55 (stack40)
        %v97782_v61 = vadd.f32 %v97778_v27, %v97703_v61 (stack53)
        %v98539_v44 = vadd.s32 %v98536_v52, %v98531_v44 (stack40)
        %v98545_v34 = vshll.u32 %v98536_v52, 6 (stack45)
        %v98546_v30 = vshrl.u32 %v98536_v52, 26 (stack46)
        %v98924_v46 = vadd.s32 %v98921_v7, %v121569_v1 (stack40)
        %v99338_v60 = vxor.u32 %v99337_v12, %v99329_v60 (stack48)
        %v99743_v31 = vxor.u32 %v99742_v10, %v99738_v25 (stack48)
        %v100170_v21 = vsel /*vm=*/%vm100144_vm1, /*on_true_vy=*/%v100166_v24, /*on_false_vx=*/%v100162_v55 (stack44)
        %v97786_v42 = vmul.f32 %v97782_v61, %v150532_v53 (stack54)
        %v98547_v45 = vor.u32 %v98546_v30, %v98545_v34 (stack47)
        %v98916_v41 = vadd.s32 %v98912_v41, %v121574_v2 (stack40)
        %v100175_v54 = vadd.s32 %v100170_v21, %v121574_v2 (stack40)
        %v98928_v27 = vadd.s32 3, %v98924_v46 (stack40)
        %v99341_v52 = vadd.s32 %v99338_v60, %v121574_v2 (stack40)
        %v99746_v25 = vadd.s32 %v99743_v31, %v99738_v25 (stack40)
        %v99752_v12 = vshll.u32 %v99743_v31, 6 (stack45)
        %v97790_v20 = vadd.f32 %v97786_v42, %v150539_v20 (stack53)
        %v98548_v55 = vxor.u32 %v98547_v45, %v98539_v44 (stack48)
        %v99753_v7 = vshrl.u32 %v99743_v31, 26 (stack46)
        %v150587_v10 = vadd.s32 %v150569_v50, %v100175_v54 (stack40)
        %v98932_v24 = vadd.s32 %v98928_v27, %v98916_v41 (stack40)
        %v98934_v61 = vshll.u32 %v98928_v27, 17 (stack45)
        %v98935_v34 = vshrl.u32 %v98928_v27, 15 (stack46)
        %v99345_v30 = vadd.s32 2, %v99341_v52 (stack40)
        %v121270_v46 = vpop.eup %121269 (stack64)
        %v97794_v60 = vmul.f32 %v97790_v20, %v150532_v53 (stack54)
        %vm150590_vm2 = vcmp.lt.f32.partialorder %v98141_v32, 0.0004427343 (stack62)
        %v98551_v31 = vadd.s32 %v98548_v55, %v121574_v2 (stack40)
        %v99754_v21 = vor.u32 %v99753_v7, %v99752_v12 (stack47)
        %v98137_v42 = vmul.f32 0.6931472, %v121270_v46 (stack65)
        %v98140_v8 = vmul.f32 %v98139_v40, %v150557_v8 (stack63)
        %v98936_v40 = vor.u32 %v98935_v34, %v98934_v61 (stack47)
        %v99349_v6 = vadd.s32 %v99345_v30, %v99333_v6 (stack40)
        %v97798_v23 = vadd.f32 %v97794_v60, %v150488_v23 (stack53)
        %v98543_v44 = vadd.s32 %v98539_v44, %v121564_v0 (stack40)
        %v98555_v45 = vadd.s32 5, %v98551_v31 (stack40)
        %v99755_v41 = vxor.u32 %v99754_v21, %v99746_v25 (stack48)
        %v98143_v54 = vsel /*vm=*/%vm150590_vm2, /*on_true_vy=*/%v98140_v8, /*on_false_vx=*/%v98137_v42 (stack66)
        %v98937_v27 = vxor.u32 %v98936_v40, %v98932_v24 (stack48)
        %v99351_v52 = vshll.u32 %v99345_v30, 13 (stack45)
        %v150602_v56 = vadd.s32 %v157684_v56, %v157095_v13 (stack40)
        %v97802_v53 = vmul.f32 %v97798_v23, %v150532_v53 (stack54)
        %v150605_v12 = vxor.u32 2147483648, %v98143_v54 (stack56)
        %v98557_v20 = vxor.u32 %v98555_v45, %v98543_v44 (stack48)
        %v99352_v55 = vshrl.u32 %v99345_v30, 19 (stack46)
        %v97691_v26 = vsel /*vm=*/%vm97686_vm12, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v98940_v7 = vadd.s32 %v98937_v27, %v98932_v24 (stack40)
        %v98942_v24 = vshll.u32 %v98937_v27, 29 (stack45)
        %v98943_v61 = vshrl.u32 %v98937_v27, 3 (stack46)
        %v97667_v34 = vmul.f32 inf, %v150384_v22 (stack54)
        %v97806_v30 = vadd.f32 %v97802_v53, %v97691_v26 (stack53)
        %vm98147_vm3 = vcmp.lt.f32.partialorder %v150605_v12, 5.0 (stack68)
        %121271 = vrsqrt.f32 %v150605_v12 (stack67)
        %vm150615_vm4 = vcmp.eq.f32.partialorder %v97659_v9, 1.0 (stack68)
        %v98120_v46 = vand.u32 2147483647, %v150544_v29 (stack77)
        %v98944_v60 = vor.u32 %v98943_v61, %v98942_v24 (stack47)
        %v100185_v32 = vshll.u32 %v150569_v50, 13 (stack45)
        %v97810_v22 = vmul.f32 %v97806_v30, %v150384_v22 (stack54)
        %v99353_v31 = vor.u32 %v99352_v55, %v99351_v52 (stack47)
        %v99758_v21 = vadd.s32 %v99755_v41, %v121564_v0 (stack40)
        %v100186_v50 = vshrl.u32 %v150569_v50, 19 (stack46)
        %v150627_v42 = vsel /*vm=*/%vm98147_vm3, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v150630_v8 = vadd.f32 -2.5, %v150605_v12 (stack53)
        %v98945_v40 = vxor.u32 %v98944_v60, %v98940_v7 (stack48)
        %v99750_v25 = vadd.s32 %v99746_v25, %v121569_v1 (stack40)
        %v97814_v23 = vsel /*vm=*/%vm150615_vm4, /*on_true_vy=*/%v97667_v34, /*on_false_vx=*/%v97810_v22 (stack44)
        %v150638_v44 = vsel /*vm=*/%vm98147_vm3, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v150643_v45 = vsel /*vm=*/%vm98147_vm3, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v150648_v41 = vsel /*vm=*/%vm98147_vm3, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v97818_v54 = vmul.f32 1.4140625, %v97814_v23 (stack54)
        %v98558_v27 = vand.u32.u8 255, %v98557_v20 (stack49)
        %v98948_v52 = vadd.s32 %v98945_v40, %v98940_v7 (stack40)
        %v98950_v53 = vshll.u32 %v98945_v40, 16 (stack45)
        %v98951_v20 = vshrl.u32 %v98945_v40, 16 (stack46)
        %v99354_v55 = vxor.u32 %v99353_v31, %v99349_v6 (stack48)
        %v99762_v26 = vadd.s32 1, %v99758_v21 (stack40)
        %v100187_v7 = vor.u32 %v100186_v50, %v100185_v32 (stack47)
        %v97821_v24 = vpack.c.bf16 %v157387_v11, %v97818_v54 (stack81)
        %vm98192_vm5 = vcmp.eq.f32.partialorder %v150605_v12, inf (stack70)
        %v98559_v61 = vand.u32 65535, %v98558_v27 (stack50)
        %vm100610_vm6 = vcmp.lt.u32.totalorder %v150602_v56, %v157095_v13 (stack43)
        %v98952_v34 = vor.u32 %v98951_v20, %v98950_v53 (stack47)
        %v99357_v6 = vadd.s32 %v99354_v55, %v99349_v6 (stack40)
        %v99359_v30 = vshll.u32 %v99354_v55, 15 (stack45)
        %v99360_v9 = vshrl.u32 %v99354_v55, 17 (stack46)
        %120269 = vst [vmem:[%s123356_s30 + $0x68] sm:$0xf] /*vst_source=*/%v97821_v24 (stack83)
        %v98560_v60 = vshrl.u32 %v98559_v61, 1 (stack51)
        %v99766_v32 = vadd.s32 %v99762_v26, %v99750_v25 (stack40)
        %v99768_v22 = vshll.u32 %v99762_v26, 17 (stack45)
        %v99769_v31 = vshrl.u32 %v99762_v26, 15 (stack46)
        %vm98194_vm7 = vcmp.eq.f32.partialorder %v150605_v12, 0.0 (stack71)
        %v98953_v21 = vxor.u32 %v98952_v34, %v98948_v52 (stack48)
        %v99361_v50 = vor.u32 %v99360_v9, %v99359_v30 (stack47)
        %v100188_v40 = vxor.u32 %v100187_v7, %v150587_v10 (stack48)
        %v98195_v25 = vand.u32 2147483648, %v150605_v12 (stack72)
        %v98561_v23 = vor.u32 16256, %v98560_v60 (stack47)
        %v99770_v54 = vor.u32 %v99769_v31, %v99768_v22 (stack47)
        %v100615_v43 = vadd.s32 %v157687_v43, %v157100_v14 (stack40)
        %v98956_v27 = vadd.s32 %v98953_v21, %v98948_v52 (stack40)
        %v98962_v52 = vshll.u32 %v98953_v21, 24 (stack45)
        %v98963_v53 = vshrl.u32 %v98953_v21, 8 (stack46)
        %v99362_v20 = vxor.u32 %v99361_v50, %v99357_v6 (stack48)
        %v121272_v55 = vpop.eup %121271 (stack73)
        %v98562_v26 = vand.u32.u16 65535, %v98561_v23 (stack52)
        %v99771_v7 = vxor.u32 %v99770_v54, %v99766_v32 (stack48)
        %v150661_v10 = vadd.s32 %v100188_v40, %v150587_v10 (stack40)
        %v150665_v24 = vadd.s32 %v150602_v56, %v122657_v58 (stack40)
        %v98191_v61 = vmul.f32 %v121272_v55, %v150605_v12 (stack74)
        %v98964_v34 = vor.u32 %v98963_v53, %v98962_v52 (stack47)
        %v99365_v6 = vadd.s32 %v99362_v20, %v99357_v6 (stack40)
        %v100193_v30 = vshll.u32 %v100188_v40, 15 (stack45)
        %v120272_v9 = vadd.low.f32.bf16 -1.0, %v98562_v26 (stack53)
        %v99367_v60 = vshll.u32 %v99362_v20, 26 (stack45)
        %v99368_v22 = vshrl.u32 %v99362_v20, 6 (stack46)
        %v99774_v32 = vadd.s32 %v99771_v7, %v99766_v32 (stack40)
        %v98193_v31 = vsel /*vm=*/%vm98192_vm5, /*on_true_vy=*/%v150605_v12, /*on_false_vx=*/%v98191_v61 (stack75)
        %v98965_v21 = vxor.u32 %v98964_v34, %v98956_v27 (stack48)
        %v99776_v50 = vshll.u32 %v99771_v7, 29 (stack45)
        %v99777_v23 = vshrl.u32 %v99771_v7, 3 (stack46)
        %v98196_v25 = vsel /*vm=*/%vm98194_vm7, /*on_true_vy=*/%v98195_v25, /*on_false_vx=*/%v98193_v31 (stack76)
        %v98571_v54 = vmul.f32 2.0, %v120272_v9 (stack54)
        %v99369_v52 = vor.u32 %v99368_v22, %v99367_v60 (stack47)
        %v100194_v40 = vshrl.u32 %v100188_v40, 17 (stack46)
        %v98199_v53 = vadd.f32 -3.0, %v98196_v25 (stack53)
        %v98968_v20 = vadd.s32 %v98965_v21, %v121564_v0 (stack40)
        %v99778_v55 = vor.u32 %v99777_v23, %v99776_v50 (stack47)
        %v100619_v26 = vadd.s32 1, %v100615_v43 (stack40)
        %v98575_v7 = vadd.f32 -0.99609375, %v98571_v54 (stack53)
        %v98960_v27 = vadd.s32 %v98956_v27, %v121569_v1 (stack40)
        %v99370_v61 = vxor.u32 %v99369_v52, %v99365_v6 (stack48)
        %v100195_v34 = vor.u32 %v100194_v40, %v100193_v30 (stack47)
        %v150678_v8 = vsel /*vm=*/%vm98147_vm3, /*on_true_vy=*/%v150630_v8, /*on_false_vx=*/%v98199_v53 (stack44)
        %v98972_v30 = vadd.s32 4, %v98968_v20 (stack40)
        %v99779_v9 = vxor.u32 %v99778_v55, %v99774_v32 (stack48)
        %v150683_v43 = vsel /*vm=*/%vm100610_vm6, /*on_true_vy=*/%v100619_v26, /*on_false_vx=*/%v100615_v43 (stack44)
        %v98207_v41 = vmul.f32 %v150678_v8, %v150648_v41 (stack54)
        %v150687_v60 = vmax.f32 %v98575_v7, -0.99609375 (stack55)
        %v99373_v6 = vadd.s32 %v99370_v61, %v99365_v6 (stack40)
        %v99379_v22 = vshll.u32 %v99370_v61, 6 (stack45)
        %v98976_v31 = vadd.s32 %v98972_v30, %v98960_v27 (stack40)
        %v98978_v21 = vshll.u32 %v98972_v30, 13 (stack45)
        %v98979_v50 = vshrl.u32 %v98972_v30, 19 (stack46)
        %v99380_v23 = vshrl.u32 %v99370_v61, 26 (stack46)
        %v98168_v25 = vsel /*vm=*/%vm98147_vm3, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v98172_v54 = vsel /*vm=*/%vm98147_vm3, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v98211_v45 = vadd.f32 %v98207_v41, %v150643_v45 (stack53)
        %v98591_v52 = vxor.u32 2147483648, %v150687_v60 (stack56)
        %v98176_v40 = vsel /*vm=*/%vm98147_vm3, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v98980_v53 = vor.u32 %v98979_v50, %v98978_v21 (stack47)
        %v99381_v20 = vor.u32 %v99380_v23, %v99379_v22 (stack47)
        %v99782_v32 = vadd.s32 %v99779_v9, %v99774_v32 (stack40)
        %v98215_v55 = vmul.f32 %v98211_v45, %v150678_v8 (stack54)
        %v150702_v26 = vmul.f32 %v98591_v52, %v150687_v60 (stack54)
        %v99784_v7 = vshll.u32 %v99779_v9, 16 (stack45)
        %vm100605_vm8 = vcmp.lt.u32.totalorder %v150665_v24, %v150602_v56 (stack43)
        %v98981_v27 = vxor.u32 %v98980_v53, %v98976_v31 (stack48)
        %v99382_v61 = vxor.u32 %v99381_v20, %v99373_v6 (stack48)
        %v99785_v30 = vshrl.u32 %v99779_v9, 16 (stack46)
        %v100196_v34 = vxor.u32 %v100195_v34, %v150661_v10 (stack48)
        %v98219_v9 = vadd.f32 %v98215_v55, %v98176_v40 (stack53)
        %v98596_v41 = vadd.f32 1.0, %v150702_v26 (stack57)
        %v98599_v22 = vmul.f32 -0.5, %v150702_v26 (stack59)
        %v150711_v21 = vadd.s32 %v150665_v24, %v121569_v1 (stack40)
        %v98984_v31 = vadd.s32 %v98981_v27, %v98976_v31 (stack40)
        %v98986_v50 = vshll.u32 %v98981_v27, 15 (stack45)
        %v98987_v23 = vshrl.u32 %v98981_v27, 17 (stack46)
        %v99385_v45 = vadd.s32 %v99382_v61, %v121569_v1 (stack40)
        %v98223_v52 = vmul.f32 %v98219_v9, %v150678_v8 (stack54)
        %121273 = vlog2.f32 %v98596_v41 (stack58)
        %v98602_v40 = vand.u32 2147483647, %v150702_v26 (stack60)
        %v99377_v6 = vadd.s32 %v99373_v6, %v121574_v2 (stack40)
        %v98988_v53 = vor.u32 %v98987_v23, %v98986_v50 (stack47)
        %v99389_v20 = vadd.s32 3, %v99385_v45 (stack40)
        %v99786_v55 = vor.u32 %v99785_v30, %v99784_v7 (stack47)
        %v100199_v10 = vadd.s32 %v100196_v34, %v150661_v10 (stack40)
        %v98227_v54 = vadd.f32 %v98223_v52, %v98172_v54 (stack53)
        %v98600_v7 = vadd.f32 1.0, %v98599_v22 (stack61)
        %v100201_v27 = vshll.u32 %v100196_v34, 26 (stack45)
        %v100202_v61 = vshrl.u32 %v100196_v34, 6 (stack46)
        %v98989_v30 = vxor.u32 %v98988_v53, %v98984_v31 (stack48)
        %v99393_v34 = vadd.s32 %v99389_v20, %v99377_v6 (stack40)
        %v99395_v9 = vshll.u32 %v99389_v20, 17 (stack45)
        %v99396_v41 = vshrl.u32 %v99389_v20, 15 (stack46)
        %v98231_v22 = vmul.f32 %v98227_v54, %v150678_v8 (stack54)
        %v99787_v50 = vxor.u32 %v99786_v55, %v99782_v32 (stack48)
        %v100203_v23 = vor.u32 %v100202_v61, %v100201_v27 (stack47)
        %v100627_v45 = vadd.s32 1, %v150683_v43 (stack40)
        %v98992_v31 = vadd.s32 %v98989_v30, %v98984_v31 (stack40)
        %v98994_v52 = vshll.u32 %v98989_v30, 26 (stack45)
        %v98995_v6 = vshrl.u32 %v98989_v30, 6 (stack46)
        %v99397_v53 = vor.u32 %v99396_v41, %v99395_v9 (stack47)
        %v98235_v25 = vadd.f32 %v98231_v22, %v98168_v25 (stack53)
        %v99790_v32 = vadd.s32 %v99787_v50, %v99782_v32 (stack40)
        %v99796_v20 = vshll.u32 %v99787_v50, 24 (stack45)
        %v99797_v55 = vshrl.u32 %v99787_v50, 8 (stack46)
        %v98996_v54 = vor.u32 %v98995_v6, %v98994_v52 (stack47)
        %v99398_v27 = vxor.u32 %v99397_v53, %v99393_v34 (stack48)
        %v100204_v61 = vxor.u32 %v100203_v23, %v100199_v10 (stack48)
        %v100631_v56 = vsel /*vm=*/%vm100605_vm8, /*on_true_vy=*/%v100627_v45, /*on_false_vx=*/%v150683_v43 (stack44)
        %v98239_v24 = vmul.f32 %v98235_v25, %v150678_v8 (stack54)
        %vm150725_vm9 = vcmp.lt.f32.partialorder %v98602_v40, 0.0004427343 (stack62)
        %v99798_v40 = vor.u32 %v99797_v55, %v99796_v20 (stack47)
        %v100636_v30 = vadd.s32 %v100631_v56, %v121574_v2 (stack40)
        %v98997_v9 = vxor.u32 %v98996_v54, %v98992_v31 (stack48)
        %v99401_v34 = vadd.s32 %v99398_v27, %v99393_v34 (stack40)
        %v99403_v41 = vshll.u32 %v99398_v27, 29 (stack45)
        %v99404_v22 = vshrl.u32 %v99398_v27, 3 (stack46)
        %v98243_v44 = vadd.f32 %v98239_v24, %v150638_v44 (stack53)
        %v99799_v50 = vxor.u32 %v99798_v40, %v99790_v32 (stack48)
        %v100207_v10 = vadd.s32 %v100204_v61, %v100199_v10 (stack40)
        %v100213_v23 = vshll.u32 %v100204_v61, 6 (stack45)
        %v99000_v45 = vadd.s32 %v98997_v9, %v98992_v31 (stack40)
        %v99006_v31 = vshll.u32 %v98997_v9, 6 (stack45)
        %v99007_v52 = vshrl.u32 %v98997_v9, 26 (stack46)
        %v99405_v6 = vor.u32 %v99404_v22, %v99403_v41 (stack47)
        %v98247_v53 = vmul.f32 %v98243_v44, %v150678_v8 (stack54)
        %v98601_v26 = vmul.f32 %v98600_v7, %v150702_v26 (stack63)
        %v99802_v7 = vadd.s32 %v99799_v50, %v121574_v2 (stack40)
        %v100214_v25 = vshrl.u32 %v100204_v61, 26 (stack46)
        %v121274_v20 = vpop.eup %121273 (stack64)
        %v99008_v55 = vor.u32 %v99007_v52, %v99006_v31 (stack47)
        %v99406_v54 = vxor.u32 %v99405_v6, %v99401_v34 (stack48)
        %v99794_v32 = vadd.s32 %v99790_v32, %v121564_v0 (stack40)
        %v150736_v27 = vadd.s32 %v150711_v21, %v100636_v30 (stack40)
        %v98251_v42 = vadd.f32 %v98247_v53, %v150627_v42 (stack53)
        %v98598_v61 = vmul.f32 0.6931472, %v121274_v20 (stack65)
        %v99806_v56 = vadd.s32 2, %v99802_v7 (stack40)
        %v100215_v24 = vor.u32 %v100214_v25, %v100213_v23 (stack47)
        %v99009_v40 = vxor.u32 %v99008_v55, %v99000_v45 (stack48)
        %v99409_v30 = vadd.s32 %v99406_v54, %v99401_v34 (stack40)
        %v99411_v9 = vshll.u32 %v99406_v54, 16 (stack45)
        %v99412_v34 = vshrl.u32 %v99406_v54, 16 (stack46)
        %v98255_v41 = vmul.f32 %v98251_v42, %v150678_v8 (stack54)
        %v98604_v43 = vsel /*vm=*/%vm150725_vm9, /*on_true_vy=*/%v98601_v26, /*on_false_vx=*/%v98598_v61 (stack66)
        %v99810_v22 = vadd.s32 %v99806_v56, %v99794_v32 (stack40)
        %v98156_v44 = vsel /*vm=*/%vm98147_vm3, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v150745_v50 = vxor.u32 2147483648, %v98604_v43 (stack56)
        %v99413_v23 = vor.u32 %v99412_v34, %v99411_v9 (stack47)
        %v98128_v31 = vmul.f32 inf, %v150544_v29 (stack54)
        %v98259_v52 = vadd.f32 %v98255_v41, %v98156_v44 (stack53)
        %v100216_v6 = vxor.u32 %v100215_v24, %v100207_v10 (stack48)
        %v157711_v53 = vld [vmem:[#allocation147_spill] sm:$0xff] (stack84)
        %v150750_v26 = vadd.s32 %v157711_v53, %v122651_v47 (stack40)
        %vm150754_vm10 = vcmp.eq.f32.partialorder %v98120_v46, 1.0 (stack68)
        %vm98608_vm11 = vcmp.lt.f32.partialorder %v150745_v50, 5.0 (stack68)
        %121275 = vrsqrt.f32 %v150745_v50 (stack67)
        %v99012_v7 = vadd.s32 %v99009_v40, %v121574_v2 (stack40)
        %v98152_v12 = vsel /*vm=*/%vm98147_vm3, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v98263_v8 = vmul.f32 %v98259_v52, %v150678_v8 (stack54)
        %v99812_v25 = vshll.u32 %v99806_v56, 13 (stack45)
        %v99813_v20 = vshrl.u32 %v99806_v56, 19 (stack46)
        %v99414_v55 = vxor.u32 %v99413_v23, %v99409_v30 (stack48)
        %v100211_v10 = vadd.s32 %v100207_v10, %v121569_v1 (stack40)
        %v100646_v54 = vshll.u32 %v150711_v21, 13 (stack45)
        %v100647_v21 = vshrl.u32 %v150711_v21, 19 (stack46)
        %v98267_v32 = vadd.f32 %v98263_v8, %v98152_v12 (stack53)
        %v150771_v42 = vsel /*vm=*/%vm98608_vm11, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v150774_v61 = vadd.f32 -2.5, %v150745_v50 (stack53)
        %v99004_v45 = vadd.s32 %v99000_v45, %v121564_v0 (stack40)
        %v150780_v56 = vsel /*vm=*/%vm98608_vm11, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v150785_v24 = vsel /*vm=*/%vm98608_vm11, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v99016_v40 = vadd.s32 5, %v99012_v7 (stack40)
        %v99417_v30 = vadd.s32 %v99414_v55, %v99409_v30 (stack40)
        %v98271_v29 = vmul.f32 %v98267_v32, %v150544_v29 (stack54)
        %v99423_v9 = vshll.u32 %v99414_v55, 24 (stack45)
        %v99424_v34 = vshrl.u32 %v99414_v55, 8 (stack46)
        %v99814_v41 = vor.u32 %v99813_v20, %v99812_v25 (stack47)
        %v150791_v43 = vsel /*vm=*/%vm98608_vm11, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v99018_v44 = vxor.u32 %v99016_v40, %v99004_v45 (stack48)
        %v100219_v23 = vadd.s32 %v100216_v6, %v121564_v0 (stack40)
        %v100648_v52 = vor.u32 %v100647_v21, %v100646_v54 (stack47)
        %v98275_v31 = vsel /*vm=*/%vm150754_vm10, /*on_true_vy=*/%v98128_v31, /*on_false_vx=*/%v98271_v29 (stack44)
        %vm98653_vm12 = vcmp.eq.f32.partialorder %v150745_v50, inf (stack70)
        %v98656_v6 = vand.u32 2147483648, %v150745_v50 (stack72)
        %v99425_v46 = vor.u32 %v99424_v34, %v99423_v9 (stack47)
        %v99815_v7 = vxor.u32 %v99814_v41, %v99810_v22 (stack48)
        %v98279_v12 = vmul.f32 1.4140625, %v98275_v31 (stack54)
        %vm98655_vm13 = vcmp.eq.f32.partialorder %v150745_v50, 0.0 (stack71)
        %v99019_v8 = vand.u32.u8 255, %v99018_v44 (stack49)
        %v100223_v25 = vadd.s32 1, %v100219_v23 (stack40)
        %v100649_v20 = vxor.u32 %v100648_v52, %v150736_v27 (stack48)
        %v99426_v55 = vxor.u32 %v99425_v46, %v99417_v30 (stack48)
        %v99818_v22 = vadd.s32 %v99815_v7, %v99810_v22 (stack40)
        %v99820_v54 = vshll.u32 %v99815_v7, 15 (stack45)
        %v99821_v21 = vshrl.u32 %v99815_v7, 17 (stack46)
        %v98282_v32 = vpack.c.bf16 %v157387_v11, %v98279_v12 (stack81)
        %v99020_v45 = vand.u32 65535, %v99019_v8 (stack50)
        %v100227_v10 = vadd.s32 %v100223_v25, %v100211_v10 (stack40)
        %v100229_v40 = vshll.u32 %v100223_v25, 17 (stack45)
        %v99429_v29 = vadd.s32 %v99426_v55, %v121564_v0 (stack40)
        %v99822_v9 = vor.u32 %v99821_v21, %v99820_v54 (stack47)
        %v100230_v34 = vshrl.u32 %v100223_v25, 15 (stack46)
        %v100652_v27 = vadd.s32 %v100649_v20, %v150736_v27 (stack40)
        %120271 = vst [vmem:[%s123356_s30 + $0xe8] sm:$0xf] /*vst_source=*/%v98282_v32 (stack83)
        %v99021_v41 = vshrl.u32 %v99020_v45, 1 (stack51)
        %v99421_v30 = vadd.s32 %v99417_v30, %v121569_v1 (stack40)
        %v100654_v44 = vshll.u32 %v100649_v20, 15 (stack45)
        %v100655_v23 = vshrl.u32 %v100649_v20, 17 (stack46)
        %v121276_v52 = vpop.eup %121275 (stack73)
        %v99433_v31 = vadd.s32 4, %v99429_v29 (stack40)
        %v99823_v46 = vxor.u32 %v99822_v9, %v99818_v22 (stack48)
        %v100231_v7 = vor.u32 %v100230_v34, %v100229_v40 (stack47)
        %vm101105_vm14 = vcmp.lt.u32.totalorder %v150750_v26, %v122651_v47 (stack43)
        %v98652_v12 = vmul.f32 %v121276_v52, %v150745_v50 (stack74)
        %v99022_v8 = vor.u32 16256, %v99021_v41 (stack47)
        %v100656_v25 = vor.u32 %v100655_v23, %v100654_v44 (stack47)
        %v157714_v20 = vld [vmem:[#allocation111_spill] sm:$0xff] (stack84)
        %v101110_v55 = vadd.s32 %v157714_v20, %v157068_v28 (stack40)
        %v99437_v54 = vadd.s32 %v99433_v31, %v99421_v30 (stack40)
        %v99439_v21 = vshll.u32 %v99433_v31, 13 (stack45)
        %v99440_v32 = vshrl.u32 %v99433_v31, 19 (stack46)
        %v99826_v22 = vadd.s32 %v99823_v46, %v99818_v22 (stack40)
        %v98654_v45 = vsel /*vm=*/%vm98653_vm12, /*on_true_vy=*/%v150745_v50, /*on_false_vx=*/%v98652_v12 (stack75)
        %v99023_v40 = vand.u32.u16 65535, %v99022_v8 (stack52)
        %v99828_v29 = vshll.u32 %v99823_v46, 26 (stack45)
        %v99829_v9 = vshrl.u32 %v99823_v46, 6 (stack46)
        %v98657_v6 = vsel /*vm=*/%vm98655_vm13, /*on_true_vy=*/%v98656_v6, /*on_false_vx=*/%v98654_v45 (stack76)
        %v99441_v34 = vor.u32 %v99440_v32, %v99439_v21 (stack47)
        %v100232_v41 = vxor.u32 %v100231_v7, %v100227_v10 (stack48)
        %v100657_v30 = vxor.u32 %v100656_v25, %v100652_v27 (stack48)
        %v98645_v44 = vsel /*vm=*/%vm98608_vm11, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v98660_v23 = vadd.f32 -3.0, %v98657_v6 (stack53)
        %v120274_v52 = vadd.low.f32.bf16 -1.0, %v99023_v40 (stack53)
        %v99830_v31 = vor.u32 %v99829_v9, %v99828_v29 (stack47)
        %v99442_v46 = vxor.u32 %v99441_v34, %v99437_v54 (stack48)
        %v100235_v10 = vadd.s32 %v100232_v41, %v100227_v10 (stack40)
        %v100237_v7 = vshll.u32 %v100232_v41, 29 (stack45)
        %v100238_v12 = vshrl.u32 %v100232_v41, 3 (stack46)
        %v150821_v61 = vsel /*vm=*/%vm98608_vm11, /*on_true_vy=*/%v150774_v61, /*on_false_vx=*/%v98660_v23 (stack44)
        %v99032_v8 = vmul.f32 2.0, %v120274_v52 (stack54)
        %v99831_v25 = vxor.u32 %v99830_v31, %v99826_v22 (stack48)
        %v150823_v27 = vadd.s32 %v100657_v30, %v100652_v27 (stack40)
        %v98668_v21 = vmul.f32 %v150821_v61, %v98645_v44 (stack54)
        %v99445_v54 = vadd.s32 %v99442_v46, %v99437_v54 (stack40)
        %v99447_v32 = vshll.u32 %v99442_v46, 15 (stack45)
        %v99448_v45 = vshrl.u32 %v99442_v46, 17 (stack46)
        %v99036_v40 = vadd.f32 -0.99609375, %v99032_v8 (stack53)
        %v99834_v22 = vadd.s32 %v99831_v25, %v99826_v22 (stack40)
        %v99840_v29 = vshll.u32 %v99831_v25, 6 (stack45)
        %v99841_v9 = vshrl.u32 %v99831_v25, 26 (stack46)
        %v98672_v43 = vadd.f32 %v98668_v21, %v150791_v43 (stack53)
        %v99449_v6 = vor.u32 %v99448_v45, %v99447_v32 (stack47)
        %v100239_v34 = vor.u32 %v100238_v12, %v100237_v7 (stack47)
        %v101114_v41 = vadd.s32 1, %v101110_v55 (stack40)
        %v98633_v44 = vsel /*vm=*/%vm98608_vm11, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v98637_v23 = vsel /*vm=*/%vm98608_vm11, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v150833_v52 = vmax.f32 %v99036_v40, -0.99609375 (stack55)
        %v99842_v31 = vor.u32 %v99841_v9, %v99840_v29 (stack47)
        %v98676_v46 = vmul.f32 %v98672_v43, %v150821_v61 (stack54)
        %v99450_v7 = vxor.u32 %v99449_v6, %v99445_v54 (stack48)
        %v100240_v12 = vxor.u32 %v100239_v34, %v100235_v10 (stack48)
        %v150839_v55 = vsel /*vm=*/%vm101105_vm14, /*on_true_vy=*/%v101114_v41, /*on_false_vx=*/%v101110_v55 (stack44)
        %v99052_v8 = vxor.u32 2147483648, %v150833_v52 (stack56)
        %v99843_v25 = vxor.u32 %v99842_v31, %v99834_v22 (stack48)
        %v100662_v21 = vshll.u32 %v100657_v30, 26 (stack45)
        %v100663_v30 = vshrl.u32 %v100657_v30, 6 (stack46)
        %v98680_v32 = vadd.f32 %v98676_v46, %v98637_v23 (stack53)
        %v99453_v54 = vadd.s32 %v99450_v7, %v99445_v54 (stack40)
        %v99455_v45 = vshll.u32 %v99450_v7, 26 (stack45)
        %v99456_v40 = vshrl.u32 %v99450_v7, 6 (stack46)
        %v99055_v29 = vmul.f32 %v99052_v8, %v150833_v52 (stack54)
        %v99846_v9 = vadd.s32 %v99843_v25, %v121569_v1 (stack40)
        %v100243_v10 = vadd.s32 %v100240_v12, %v100235_v10 (stack40)
        %v101096_v43 = vadd.s32 %v150750_v26, %v122657_v58 (stack40)
        %v98684_v6 = vmul.f32 %v98680_v32, %v150821_v61 (stack54)
        %v99457_v34 = vor.u32 %v99456_v40, %v99455_v45 (stack47)
        %v100245_v41 = vshll.u32 %v100240_v12, 16 (stack45)
        %v100246_v23 = vshrl.u32 %v100240_v12, 16 (stack46)
        %v99057_v31 = vadd.f32 1.0, %v99055_v29 (stack57)
        %v99060_v46 = vmul.f32 -0.5, %v99055_v29 (stack59)
        %v99838_v22 = vadd.s32 %v99834_v22, %v121574_v2 (stack40)
        %v99850_v7 = vadd.s32 3, %v99846_v9 (stack40)
        %v98688_v44 = vadd.f32 %v98684_v6, %v98633_v44 (stack53)
        %v99458_v12 = vxor.u32 %v99457_v34, %v99453_v54 (stack48)
        %v100247_v8 = vor.u32 %v100246_v23, %v100245_v41 (stack47)
        %v100664_v25 = vor.u32 %v100663_v30, %v100662_v21 (stack47)
        %v98629_v21 = vsel /*vm=*/%vm98608_vm11, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %121277 = vlog2.f32 %v99057_v31 (stack58)
        %v99854_v30 = vadd.s32 %v99850_v7, %v99838_v22 (stack40)
        %vm101100_vm15 = vcmp.lt.u32.totalorder %v101096_v43, %v150750_v26 (stack43)
        %v98692_v32 = vmul.f32 %v98688_v44, %v150821_v61 (stack54)
        %v99461_v54 = vadd.s32 %v99458_v12, %v99453_v54 (stack40)
        %v99467_v45 = vshll.u32 %v99458_v12, 6 (stack45)
        %v99468_v40 = vshrl.u32 %v99458_v12, 26 (stack46)
        %v99061_v9 = vadd.f32 1.0, %v99060_v46 (stack61)
        %v99856_v6 = vshll.u32 %v99850_v7, 17 (stack45)
        %v99857_v34 = vshrl.u32 %v99850_v7, 15 (stack46)
        %v100248_v41 = vxor.u32 %v100247_v8, %v100243_v10 (stack48)
        %v98696_v23 = vadd.f32 %v98692_v32, %v98629_v21 (stack53)
        %v99063_v31 = vand.u32 2147483647, %v99055_v29 (stack60)
        %v99469_v46 = vor.u32 %v99468_v40, %v99467_v45 (stack47)
        %v100665_v22 = vxor.u32 %v100664_v25, %v150823_v27 (stack48)
        %v99858_v7 = vor.u32 %v99857_v34, %v99856_v6 (stack47)
        %v100251_v10 = vadd.s32 %v100248_v41, %v100243_v10 (stack40)
        %v100257_v44 = vshll.u32 %v100248_v41, 24 (stack45)
        %v100258_v12 = vshrl.u32 %v100248_v41, 8 (stack46)
        %v98700_v8 = vmul.f32 %v98696_v23, %v150821_v61 (stack54)
        %v99470_v25 = vxor.u32 %v99469_v46, %v99461_v54 (stack48)
        %v100668_v27 = vadd.s32 %v100665_v22, %v150823_v27 (stack40)
        %v100674_v21 = vshll.u32 %v100665_v22, 6 (stack45)
        %v99062_v29 = vmul.f32 %v99061_v9, %v99055_v29 (stack63)
        %v99859_v32 = vxor.u32 %v99858_v7, %v99854_v30 (stack48)
        %v100259_v45 = vor.u32 %v100258_v12, %v100257_v44 (stack47)
        %v100675_v40 = vshrl.u32 %v100665_v22, 26 (stack46)
        %v98704_v24 = vadd.f32 %v98700_v8, %v150785_v24 (stack53)
        %vm150857_vm0 = vcmp.lt.f32.partialorder %v99063_v31, 0.0004427343 (stack62)
        %v99465_v54 = vadd.s32 %v99461_v54, %v121564_v0 (stack40)
        %v99473_v6 = vadd.s32 %v99470_v25, %v121574_v2 (stack40)
        %v101122_v34 = vadd.s32 1, %v150839_v55 (stack40)
        %v99862_v30 = vadd.s32 %v99859_v32, %v99854_v30 (stack40)
        %v99864_v41 = vshll.u32 %v99859_v32, 29 (stack45)
        %v99865_v23 = vshrl.u32 %v99859_v32, 3 (stack46)
        %v100260_v31 = vxor.u32 %v100259_v45, %v100251_v10 (stack48)
        %v98708_v46 = vmul.f32 %v98704_v24, %v150821_v61 (stack54)
        %v99477_v22 = vadd.s32 5, %v99473_v6 (stack40)
        %v100676_v7 = vor.u32 %v100675_v40, %v100674_v21 (stack47)
        %v101126_v26 = vsel /*vm=*/%vm101100_vm15, /*on_true_vy=*/%v101122_v34, /*on_false_vx=*/%v150839_v55 (stack44)
        %v99866_v55 = vor.u32 %v99865_v23, %v99864_v41 (stack47)
        %v100263_v44 = vadd.s32 %v100260_v31, %v121574_v2 (stack40)
        %v101131_v12 = vadd.s32 %v101126_v26, %v121574_v2 (stack40)
        %v101135_v43 = vadd.s32 %v101096_v43, %v121569_v1 (stack40)
        %v98712_v56 = vadd.f32 %v98708_v46, %v150780_v56 (stack53)
        %v99479_v8 = vxor.u32 %v99477_v22, %v99465_v54 (stack48)
        %v100677_v25 = vxor.u32 %v100676_v7, %v100668_v27 (stack48)
        %v150874_v21 = vadd.s32 %v157711_v53, %v157070_v38 (stack40)
        %v99867_v32 = vxor.u32 %v99866_v55, %v99862_v30 (stack48)
        %v100255_v10 = vadd.s32 %v100251_v10, %v121564_v0 (stack40)
        %v100267_v45 = vadd.s32 2, %v100263_v44 (stack40)
        %v101139_v40 = vadd.s32 %v101135_v43, %v101131_v12 (stack40)
        %v121278_v24 = vpop.eup %121277 (stack64)
        %v98716_v54 = vmul.f32 %v98712_v56, %v150821_v61 (stack54)
        %v99480_v6 = vand.u32.u8 255, %v99479_v8 (stack49)
        %v100672_v27 = vadd.s32 %v100668_v27, %v121569_v1 (stack40)
        %v100680_v34 = vadd.s32 %v100677_v25, %v121564_v0 (stack40)
        %v99059_v41 = vmul.f32 0.6931472, %v121278_v24 (stack65)
        %v99870_v30 = vadd.s32 %v99867_v32, %v99862_v30 (stack40)
        %v99872_v23 = vshll.u32 %v99867_v32, 16 (stack45)
        %v99873_v31 = vshrl.u32 %v99867_v32, 16 (stack46)
        %v98720_v42 = vadd.f32 %v98716_v54, %v150771_v42 (stack53)
        %v100271_v46 = vadd.s32 %v100267_v45, %v100255_v10 (stack40)
        %v101141_v22 = vshll.u32 %v101135_v43, 13 (stack45)
        %v101142_v7 = vshrl.u32 %v101135_v43, 19 (stack46)
        %v99065_v29 = vsel /*vm=*/%vm150857_vm0, /*on_true_vy=*/%v99062_v29, /*on_false_vx=*/%v99059_v41 (stack66)
        %v99481_v9 = vand.u32 65535, %v99480_v6 (stack50)
        %v99874_v26 = vor.u32 %v99873_v31, %v99872_v23 (stack47)
        %v100684_v55 = vadd.s32 1, %v100680_v34 (stack40)
        %v98724_v61 = vmul.f32 %v98720_v42, %v150821_v61 (stack54)
        %v150884_v44 = vxor.u32 2147483648, %v99065_v29 (stack56)
        %v100273_v12 = vshll.u32 %v100267_v45, 13 (stack45)
        %v100274_v43 = vshrl.u32 %v100267_v45, 19 (stack46)
        %v98581_v56 = vand.u32 2147483647, %v150687_v60 (stack77)
        %v98613_v50 = vsel /*vm=*/%vm98608_vm11, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v99875_v8 = vxor.u32 %v99874_v26, %v99870_v30 (stack48)
        %v100688_v25 = vadd.s32 %v100684_v55, %v100672_v27 (stack40)
        %v98728_v32 = vadd.f32 %v98724_v61, %v98613_v50 (stack53)
        %121279 = vrsqrt.f32 %v150884_v44 (stack67)
        %vm99069_vm1 = vcmp.lt.f32.partialorder %v150884_v44, 5.0 (stack68)
        %v99482_v10 = vshrl.u32 %v99481_v9, 1 (stack51)
        %v99878_v45 = vadd.s32 %v99875_v8, %v99870_v30 (stack40)
        %v98589_v24 = vmul.f32 inf, %v150687_v60 (stack54)
        %v98732_v60 = vmul.f32 %v98728_v32, %v150687_v60 (stack54)
        %v100275_v54 = vor.u32 %v100274_v43, %v100273_v12 (stack47)
        %v101143_v6 = vor.u32 %v101142_v7, %v101141_v22 (stack47)
        %vm98584_vm2 = vcmp.eq.f32.partialorder %v98581_v56, 1.0 (stack68)
        %v100690_v27 = vshll.u32 %v100684_v55, 17 (stack45)
        %v98736_v34 = vsel /*vm=*/%vm98584_vm2, /*on_true_vy=*/%v98589_v24, /*on_false_vx=*/%v98732_v60 (stack44)
        %v150897_v41 = vsel /*vm=*/%vm99069_vm1, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v150902_v30 = vsel /*vm=*/%vm99069_vm1, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v150905_v23 = vadd.f32 -2.5, %v150884_v44 (stack53)
        %v98740_v31 = vmul.f32 1.4140625, %v98736_v34 (stack54)
        %v99483_v42 = vor.u32 16256, %v99482_v10 (stack47)
        %v99884_v22 = vshll.u32 %v99875_v8, 24 (stack45)
        %v99885_v7 = vshrl.u32 %v99875_v8, 8 (stack46)
        %v99882_v29 = vadd.s32 %v99878_v45, %v121569_v1 (stack40)
        %v100276_v9 = vxor.u32 %v100275_v54, %v100271_v46 (stack48)
        %v100691_v26 = vshrl.u32 %v100684_v55, 15 (stack46)
        %v101144_v55 = vxor.u32 %v101143_v6, %v101139_v40 (stack48)
        %v98743_v61 = vpack.c.bf16 %v157387_v11, %v98740_v31 (stack81)
        %vm99114_vm3 = vcmp.eq.f32.partialorder %v150884_v44, inf (stack70)
        %v99484_v12 = vand.u32.u16 65535, %v99483_v42 (stack52)
        %v99886_v43 = vor.u32 %v99885_v7, %v99884_v22 (stack47)
        %vm101566_vm4 = vcmp.lt.u32.totalorder %v150874_v21, %v157070_v38 (stack43)
        %v100279_v46 = vadd.s32 %v100276_v9, %v100271_v46 (stack40)
        %v100281_v56 = vshll.u32 %v100276_v9, 15 (stack45)
        %v100282_v50 = vshrl.u32 %v100276_v9, 17 (stack46)
        %v100692_v8 = vor.u32 %v100691_v26, %v100690_v27 (stack47)
        %120273 = vst [vmem:[%s123356_s30 + $0x168] sm:$0xf] /*vst_source=*/%v98743_v61 (stack83)
        %v120276_v32 = vadd.low.f32.bf16 -1.0, %v99484_v12 (stack53)
        %v99887_v10 = vxor.u32 %v99886_v43, %v99878_v45 (stack48)
        %v101147_v40 = vadd.s32 %v101144_v55, %v101139_v40 (stack40)
        %v101149_v45 = vshll.u32 %v101144_v55, 15 (stack45)
        %vm99116_vm5 = vcmp.eq.f32.partialorder %v150884_v44, 0.0 (stack71)
        %v100283_v24 = vor.u32 %v100282_v50, %v100281_v56 (stack47)
        %v100693_v60 = vxor.u32 %v100692_v8, %v100688_v25 (stack48)
        %v101150_v54 = vshrl.u32 %v101144_v55, 17 (stack46)
        %v99117_v6 = vand.u32 2147483648, %v150884_v44 (stack72)
        %v99493_v27 = vmul.f32 2.0, %v120276_v32 (stack54)
        %v99890_v34 = vadd.s32 %v99887_v10, %v121564_v0 (stack40)
        %v101571_v31 = vadd.s32 %v157714_v20, %v157076_v35 (stack40)
        %v100284_v42 = vxor.u32 %v100283_v24, %v100279_v46 (stack48)
        %v100696_v25 = vadd.s32 %v100693_v60, %v100688_v25 (stack40)
        %v100698_v22 = vshll.u32 %v100693_v60, 29 (stack45)
        %v100699_v7 = vshrl.u32 %v100693_v60, 3 (stack46)
        %v121280_v9 = vpop.eup %121279 (stack73)
        %v99497_v26 = vadd.f32 -0.99609375, %v99493_v27 (stack53)
        %v99894_v55 = vadd.s32 4, %v99890_v34 (stack40)
        %v101151_v61 = vor.u32 %v101150_v54, %v101149_v45 (stack47)
        %v150920_v12 = vadd.s32 %v150874_v21, %v122657_v58 (stack40)
        %v99113_v43 = vmul.f32 %v121280_v9, %v150884_v44 (stack74)
        %v100287_v46 = vadd.s32 %v100284_v42, %v100279_v46 (stack40)
        %v100289_v56 = vshll.u32 %v100284_v42, 26 (stack45)
        %v100290_v50 = vshrl.u32 %v100284_v42, 6 (stack46)
        %v150923_v8 = vmax.f32 %v99497_v26, -0.99609375 (stack55)
        %v99898_v29 = vadd.s32 %v99894_v55, %v99882_v29 (stack40)
        %v99900_v32 = vshll.u32 %v99894_v55, 13 (stack45)
        %v99901_v10 = vshrl.u32 %v99894_v55, 19 (stack46)
        %v99115_v45 = vsel /*vm=*/%vm99114_vm3, /*on_true_vy=*/%v150884_v44, /*on_false_vx=*/%v99113_v43 (stack75)
        %v100291_v24 = vor.u32 %v100290_v50, %v100289_v56 (stack47)
        %v100700_v60 = vor.u32 %v100699_v7, %v100698_v22 (stack47)
        %v101152_v54 = vxor.u32 %v101151_v61, %v101147_v40 (stack48)
        %v99098_v27 = vsel /*vm=*/%vm99069_vm1, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v99102_v34 = vsel /*vm=*/%vm99069_vm1, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v99118_v6 = vsel /*vm=*/%vm99116_vm5, /*on_true_vy=*/%v99117_v6, /*on_false_vx=*/%v99115_v45 (stack76)
        %v99513_v42 = vxor.u32 2147483648, %v150923_v8 (stack56)
        %v99121_v22 = vadd.f32 -3.0, %v99118_v6 (stack53)
        %v99902_v7 = vor.u32 %v99901_v10, %v99900_v32 (stack47)
        %v100292_v9 = vxor.u32 %v100291_v24, %v100287_v46 (stack48)
        %v100701_v26 = vxor.u32 %v100700_v60, %v100696_v25 (stack48)
        %v99106_v55 = vsel /*vm=*/%vm99069_vm1, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v150941_v61 = vmul.f32 %v99513_v42, %v150923_v8 (stack54)
        %v101155_v40 = vadd.s32 %v101152_v54, %v101147_v40 (stack40)
        %vm101561_vm6 = vcmp.lt.u32.totalorder %v150920_v12, %v150874_v21 (stack43)
        %v150948_v23 = vsel /*vm=*/%vm99069_vm1, /*on_true_vy=*/%v150905_v23, /*on_false_vx=*/%v99121_v22 (stack44)
        %v99903_v43 = vxor.u32 %v99902_v7, %v99898_v29 (stack48)
        %v100295_v46 = vadd.s32 %v100292_v9, %v100287_v46 (stack40)
        %v150952_v56 = vadd.s32 %v150920_v12, %v121569_v1 (stack40)
        %v99129_v50 = vmul.f32 %v150948_v23, %v99106_v55 (stack54)
        %v99518_v32 = vadd.f32 1.0, %v150941_v61 (stack57)
        %v100301_v10 = vshll.u32 %v100292_v9, 6 (stack45)
        %v101575_v45 = vadd.s32 1, %v101571_v31 (stack40)
        %v99521_v24 = vmul.f32 -0.5, %v150941_v61 (stack59)
        %v99906_v29 = vadd.s32 %v99903_v43, %v99898_v29 (stack40)
        %v99908_v60 = vshll.u32 %v99903_v43, 15 (stack45)
        %v99909_v6 = vshrl.u32 %v99903_v43, 17 (stack46)
        %v99133_v34 = vadd.f32 %v99129_v50, %v99102_v34 (stack53)
        %121281 = vlog2.f32 %v99518_v32 (stack58)
        %v99524_v42 = vand.u32 2147483647, %v150941_v61 (stack60)
        %v101157_v22 = vshll.u32 %v101152_v54, 26 (stack45)
        %v99910_v7 = vor.u32 %v99909_v6, %v99908_v60 (stack47)
        %v100302_v9 = vshrl.u32 %v100292_v9, 26 (stack46)
        %v100704_v25 = vadd.s32 %v100701_v26, %v100696_v25 (stack40)
        %v100706_v55 = vshll.u32 %v100701_v26, 16 (stack45)
        %v99137_v43 = vmul.f32 %v99133_v34, %v150948_v23 (stack54)
        %v100299_v50 = vadd.s32 %v100295_v46, %v121574_v2 (stack40)
        %v100707_v26 = vshrl.u32 %v100701_v26, 16 (stack46)
        %v101158_v54 = vshrl.u32 %v101152_v54, 6 (stack46)
        %v99522_v32 = vadd.f32 1.0, %v99521_v24 (stack61)
        %v99911_v24 = vxor.u32 %v99910_v7, %v99906_v29 (stack48)
        %v100303_v10 = vor.u32 %v100302_v9, %v100301_v10 (stack47)
        %v101579_v31 = vsel /*vm=*/%vm101566_vm4, /*on_true_vy=*/%v101575_v45, /*on_false_vx=*/%v101571_v31 (stack44)
        %v99141_v27 = vadd.f32 %v99137_v43, %v99098_v27 (stack53)
        %v100708_v45 = vor.u32 %v100707_v26, %v100706_v55 (stack47)
        %v101159_v60 = vor.u32 %v101158_v54, %v101157_v22 (stack47)
        %v101583_v6 = vadd.s32 1, %v101579_v31 (stack40)
        %v99914_v29 = vadd.s32 %v99911_v24, %v99906_v29 (stack40)
        %v99916_v34 = vshll.u32 %v99911_v24, 26 (stack45)
        %v99917_v22 = vshrl.u32 %v99911_v24, 6 (stack46)
        %v100304_v46 = vxor.u32 %v100303_v10, %v100295_v46 (stack48)
        %v99145_v7 = vmul.f32 %v99141_v27, %v150948_v23 (stack54)
        %v100709_v9 = vxor.u32 %v100708_v45, %v100704_v25 (stack48)
        %v101160_v55 = vxor.u32 %v101159_v60, %v101155_v40 (stack48)
        %v101587_v21 = vsel /*vm=*/%vm101561_vm6, /*on_true_vy=*/%v101583_v6, /*on_false_vx=*/%v101579_v31 (stack44)
        %v99918_v12 = vor.u32 %v99917_v22, %v99916_v34 (stack47)
        %v100307_v43 = vadd.s32 %v100304_v46, %v121569_v1 (stack40)
        %v101592_v26 = vadd.s32 %v101587_v21, %v121574_v2 (stack40)
        %v101602_v54 = vshll.u32 %v150952_v56, 13 (stack45)
        %v99149_v30 = vadd.f32 %v99145_v7, %v150902_v30 (stack53)
        %v100712_v25 = vadd.s32 %v100709_v9, %v100704_v25 (stack40)
        %v100718_v24 = vshll.u32 %v100709_v9, 24 (stack45)
        %v100719_v10 = vshrl.u32 %v100709_v9, 8 (stack46)
        %v99919_v31 = vxor.u32 %v99918_v12, %v99914_v29 (stack48)
        %v100311_v27 = vadd.s32 3, %v100307_v43 (stack40)
        %v101163_v40 = vadd.s32 %v101160_v55, %v101155_v40 (stack40)
        %v101169_v45 = vshll.u32 %v101160_v55, 6 (stack45)
        %v99153_v60 = vmul.f32 %v99149_v30, %v150948_v23 (stack54)
        %v100720_v6 = vor.u32 %v100719_v10, %v100718_v24 (stack47)
        %v101170_v34 = vshrl.u32 %v101160_v55, 26 (stack46)
        %v101603_v22 = vshrl.u32 %v150952_v56, 19 (stack46)
        %v99922_v29 = vadd.s32 %v99919_v31, %v99914_v29 (stack40)
        %v99928_v46 = vshll.u32 %v99919_v31, 6 (stack45)
        %v99929_v7 = vshrl.u32 %v99919_v31, 26 (stack46)
        %v100315_v50 = vadd.s32 %v100311_v27, %v100299_v50 (stack40)
        %v99157_v41 = vadd.f32 %v99153_v60, %v150897_v41 (stack53)
        %v100317_v9 = vshll.u32 %v100311_v27, 17 (stack45)
        %v100318_v55 = vshrl.u32 %v100311_v27, 15 (stack46)
        %v100721_v21 = vxor.u32 %v100720_v6, %v100712_v25 (stack48)
        %v121282_v12 = vpop.eup %121281 (stack64)
        %v99086_v43 = vsel /*vm=*/%vm99069_vm1, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %vm150977_vm7 = vcmp.lt.f32.partialorder %v99524_v42, 0.0004427343 (stack62)
        %v99930_v30 = vor.u32 %v99929_v7, %v99928_v46 (stack47)
        %v101171_v24 = vor.u32 %v101170_v34, %v101169_v45 (stack47)
        %v99161_v10 = vmul.f32 %v99157_v41, %v150948_v23 (stack54)
        %v99520_v31 = vmul.f32 0.6931472, %v121282_v12 (stack65)
        %v99523_v61 = vmul.f32 %v99522_v32, %v150941_v61 (stack63)
        %v100319_v32 = vor.u32 %v100318_v55, %v100317_v9 (stack47)
        %v99931_v27 = vxor.u32 %v99930_v30, %v99922_v29 (stack48)
        %v101172_v45 = vxor.u32 %v101171_v24, %v101163_v40 (stack48)
        %v101600_v56 = vadd.s32 %v150952_v56, %v101592_v26 (stack40)
        %v101604_v26 = vor.u32 %v101603_v22, %v101602_v54 (stack47)
        %v99165_v54 = vadd.f32 %v99161_v10, %v99086_v43 (stack53)
        %v99526_v60 = vsel /*vm=*/%vm150977_vm7, /*on_true_vy=*/%v99523_v61, /*on_false_vx=*/%v99520_v31 (stack66)
        %v100320_v6 = vxor.u32 %v100319_v32, %v100315_v50 (stack48)
        %v100724_v34 = vadd.s32 %v100721_v21, %v121574_v2 (stack40)
        %v99042_v22 = vand.u32 2147483647, %v150833_v52 (stack77)
        %v150988_v46 = vxor.u32 2147483648, %v99526_v60 (stack56)
        %v101605_v7 = vxor.u32 %v101604_v26, %v101600_v56 (stack48)
        %v99169_v41 = vmul.f32 %v99165_v54, %v150948_v23 (stack54)
        %v100323_v50 = vadd.s32 %v100320_v6, %v100315_v50 (stack40)
        %v100325_v9 = vshll.u32 %v100320_v6, 29 (stack45)
        %v100326_v55 = vshrl.u32 %v100320_v6, 3 (stack46)
        %v99050_v21 = vmul.f32 inf, %v150833_v52 (stack54)
        %v99082_v12 = vsel /*vm=*/%vm99069_vm1, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %121283 = vrsqrt.f32 %v150988_v46 (stack67)
        %v99934_v43 = vadd.s32 %v99931_v27, %v121574_v2 (stack40)
        %v99074_v42 = vsel /*vm=*/%vm99069_vm1, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v99173_v30 = vadd.f32 %v99169_v41, %v99082_v12 (stack53)
        %vm99530_vm8 = vcmp.lt.f32.partialorder %v150988_v46, 5.0 (stack68)
        %v100728_v24 = vadd.s32 2, %v100724_v34 (stack40)
        %v99078_v44 = vsel /*vm=*/%vm99069_vm1, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v99926_v29 = vadd.s32 %v99922_v29, %v121564_v0 (stack40)
        %v100327_v10 = vor.u32 %v100326_v55, %v100325_v9 (stack47)
        %v100716_v25 = vadd.s32 %v100712_v25, %v121564_v0 (stack40)
        %v99177_v31 = vmul.f32 %v99173_v30, %v150948_v23 (stack54)
        %v151008_v61 = vadd.f32 -2.5, %v150988_v46 (stack53)
        %v101167_v40 = vadd.s32 %v101163_v40, %v121569_v1 (stack40)
        %v101175_v32 = vadd.s32 %v101172_v45, %v121564_v0 (stack40)
        %vm151012_vm9 = vcmp.eq.f32.partialorder %v99042_v22, 1.0 (stack68)
        %v151019_v45 = vsel /*vm=*/%vm99530_vm8, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v99578_v26 = vand.u32 2147483648, %v150988_v46 (stack72)
        %v99938_v54 = vadd.s32 5, %v99934_v43 (stack40)
        %v100328_v60 = vxor.u32 %v100327_v10, %v100323_v50 (stack48)
        %v99181_v6 = vadd.f32 %v99177_v31, %v99078_v44 (stack53)
        %v100732_v34 = vadd.s32 %v100728_v24, %v100716_v25 (stack40)
        %v100734_v22 = vshll.u32 %v100728_v24, 13 (stack45)
        %v100735_v41 = vshrl.u32 %v100728_v24, 19 (stack46)
        %v99940_v9 = vxor.u32 %v99938_v54, %v99926_v29 (stack48)
        %v100331_v50 = vadd.s32 %v100328_v60, %v100323_v50 (stack40)
        %v100333_v55 = vshll.u32 %v100328_v60, 16 (stack45)
        %v100334_v12 = vshrl.u32 %v100328_v60, 16 (stack46)
        %v99185_v23 = vmul.f32 %v99181_v6, %v150948_v23 (stack54)
        %vm99575_vm10 = vcmp.eq.f32.partialorder %v150988_v46, inf (stack70)
        %v100736_v43 = vor.u32 %v100735_v41, %v100734_v22 (stack47)
        %v101179_v30 = vadd.s32 1, %v101175_v32 (stack40)
        %v101608_v56 = vadd.s32 %v101605_v7, %v101600_v56 (stack40)
        %vm99577_vm11 = vcmp.eq.f32.partialorder %v150988_v46, 0.0 (stack71)
        %v99941_v24 = vand.u32.u8 255, %v99940_v9 (stack49)
        %v100335_v44 = vor.u32 %v100334_v12, %v100333_v55 (stack47)
        %v101610_v29 = vshll.u32 %v101605_v7, 15 (stack45)
        %v101611_v7 = vshrl.u32 %v101605_v7, 17 (stack46)
        %v99189_v42 = vadd.f32 %v99185_v23, %v99074_v42 (stack53)
        %v100737_v10 = vxor.u32 %v100736_v43, %v100732_v34 (stack48)
        %v101183_v25 = vadd.s32 %v101179_v30, %v101167_v40 (stack40)
        %v101185_v31 = vshll.u32 %v101179_v30, 17 (stack45)
        %v99942_v40 = vand.u32 65535, %v99941_v24 (stack50)
        %v100336_v32 = vxor.u32 %v100335_v44, %v100331_v50 (stack48)
        %v101186_v54 = vshrl.u32 %v101179_v30, 15 (stack46)
        %v101612_v60 = vor.u32 %v101611_v7, %v101610_v29 (stack47)
        %v99193_v52 = vmul.f32 %v99189_v42, %v150833_v52 (stack54)
        %v100740_v6 = vadd.s32 %v100737_v10, %v100732_v34 (stack40)
        %v100742_v34 = vshll.u32 %v100737_v10, 15 (stack45)
        %v100743_v22 = vshrl.u32 %v100737_v10, 17 (stack46)
        %v99943_v41 = vshrl.u32 %v99942_v40, 1 (stack51)
        %v100339_v9 = vadd.s32 %v100336_v32, %v100331_v50 (stack40)
        %v100345_v50 = vshll.u32 %v100336_v32, 24 (stack45)
        %v100346_v55 = vshrl.u32 %v100336_v32, 8 (stack46)
        %v121284_v12 = vpop.eup %121283 (stack73)
        %v99197_v21 = vsel /*vm=*/%vm151012_vm9, /*on_true_vy=*/%v99050_v21, /*on_false_vx=*/%v99193_v52 (stack44)
        %v100744_v27 = vor.u32 %v100743_v22, %v100742_v34 (stack47)
        %v101187_v23 = vor.u32 %v101186_v54, %v101185_v31 (stack47)
        %v101613_v43 = vxor.u32 %v101612_v60, %v101608_v56 (stack48)
        %v99201_v30 = vmul.f32 1.4140625, %v99197_v21 (stack54)
        %v99574_v24 = vmul.f32 %v121284_v12, %v150988_v46 (stack74)
        %v99944_v44 = vor.u32 16256, %v99943_v41 (stack47)
        %v100343_v29 = vadd.s32 %v100339_v9, %v121569_v1 (stack40)
        %v100347_v7 = vor.u32 %v100346_v55, %v100345_v50 (stack47)
        %v100745_v42 = vxor.u32 %v100744_v27, %v100740_v6 (stack48)
        %v101188_v10 = vxor.u32 %v101187_v23, %v101183_v25 (stack48)
        %v151030_v56 = vadd.s32 %v101613_v43, %v101608_v56 (stack40)
        %v99204_v31 = vpack.c.bf16 %v157387_v11, %v99201_v30 (stack81)
        %v99576_v40 = vsel /*vm=*/%vm99575_vm10, /*on_true_vy=*/%v150988_v46, /*on_false_vx=*/%v99574_v24 (stack75)
        %v99945_v32 = vand.u32.u16 65535, %v99944_v44 (stack52)
        %v101618_v54 = vshll.u32 %v101613_v43, 26 (stack45)
        %v99579_v26 = vsel /*vm=*/%vm99577_vm11, /*on_true_vy=*/%v99578_v26, /*on_false_vx=*/%v99576_v40 (stack76)
        %v100348_v60 = vxor.u32 %v100347_v7, %v100339_v9 (stack48)
        %v100748_v52 = vadd.s32 %v100745_v42, %v100740_v6 (stack40)
        %v100750_v6 = vshll.u32 %v100745_v42, 26 (stack45)
        %120275 = vst [vmem:[%s123356_s30 + $0x1e8] sm:$0xf] /*vst_source=*/%v99204_v31 (stack83)
        %v99582_v34 = vadd.f32 -3.0, %v99579_v26 (stack53)
        %v120278_v22 = vadd.low.f32.bf16 -1.0, %v99945_v32 (stack53)
        %v100751_v41 = vshrl.u32 %v100745_v42, 6 (stack46)
        %v101191_v25 = vadd.s32 %v101188_v10, %v101183_v25 (stack40)
        %v100351_v9 = vadd.s32 %v100348_v60, %v121564_v0 (stack40)
        %v101193_v50 = vshll.u32 %v101188_v10, 29 (stack45)
        %v101194_v55 = vshrl.u32 %v101188_v10, 3 (stack46)
        %v101619_v12 = vshrl.u32 %v101613_v43, 6 (stack46)
        %v151043_v61 = vsel /*vm=*/%vm99530_vm8, /*on_true_vy=*/%v151008_v61, /*on_false_vx=*/%v99582_v34 (stack44)
        %v99954_v21 = vmul.f32 2.0, %v120278_v22 (stack54)
        %v100752_v27 = vor.u32 %v100751_v41, %v100750_v6 (stack47)
        %v151047_v23 = vadd.s32 %v157711_v53, %v157077_v51 (stack40)
        %v99590_v45 = vmul.f32 %v151043_v61, %v151019_v45 (stack54)
        %v100355_v43 = vadd.s32 4, %v100351_v9 (stack40)
        %v101195_v30 = vor.u32 %v101194_v55, %v101193_v50 (stack47)
        %v101620_v24 = vor.u32 %v101619_v12, %v101618_v54 (stack47)
        %v99563_v44 = vsel /*vm=*/%vm99530_vm8, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v99958_v7 = vadd.f32 -0.99609375, %v99954_v21 (stack53)
        %v100753_v42 = vxor.u32 %v100752_v27, %v100748_v52 (stack48)
        %vm102027_vm12 = vcmp.lt.u32.totalorder %v151047_v23, %v157077_v51 (stack43)
        %v99594_v10 = vadd.f32 %v99590_v45, %v99563_v44 (stack53)
        %v100359_v29 = vadd.s32 %v100355_v43, %v100343_v29 (stack40)
        %v100361_v31 = vshll.u32 %v100355_v43, 13 (stack45)
        %v100362_v40 = vshrl.u32 %v100355_v43, 19 (stack46)
        %v151056_v32 = vmax.f32 %v99958_v7, -0.99609375 (stack55)
        %v100756_v54 = vadd.s32 %v100753_v42, %v100748_v52 (stack40)
        %v100762_v26 = vshll.u32 %v100753_v42, 6 (stack45)
        %v100763_v60 = vshrl.u32 %v100753_v42, 26 (stack46)
        %v99598_v52 = vmul.f32 %v99594_v10, %v151043_v61 (stack54)
        %v100363_v6 = vor.u32 %v100362_v40, %v100361_v31 (stack47)
        %v101196_v34 = vxor.u32 %v101195_v30, %v101191_v25 (stack48)
        %v101621_v22 = vxor.u32 %v101620_v24, %v151030_v56 (stack48)
        %v99503_v41 = vand.u32 2147483647, %v150923_v8 (stack77)
        %v99559_v9 = vsel /*vm=*/%vm99530_vm8, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v99974_v50 = vxor.u32 2147483648, %v151056_v32 (stack56)
        %v99602_v55 = vadd.f32 %v99598_v52, %v99559_v9 (stack53)
        %v100364_v12 = vxor.u32 %v100363_v6, %v100359_v29 (stack48)
        %v100764_v21 = vor.u32 %v100763_v60, %v100762_v26 (stack47)
        %v101199_v25 = vadd.s32 %v101196_v34, %v101191_v25 (stack40)
        %v151068_v27 = vsel /*vm=*/%vm99530_vm8, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v151071_v45 = vmul.f32 %v99974_v50, %v151056_v32 (stack54)
        %v101201_v43 = vshll.u32 %v101196_v34, 16 (stack45)
        %v101202_v30 = vshrl.u32 %v101196_v34, 16 (stack46)
        %v99606_v24 = vmul.f32 %v99602_v55, %v151043_v61 (stack54)
        %v100367_v44 = vadd.s32 %v100364_v12, %v100359_v29 (stack40)
        %v100369_v7 = vshll.u32 %v100364_v12, 15 (stack45)
        %v100370_v42 = vshrl.u32 %v100364_v12, 17 (stack46)
        %v99543_v10 = vsel /*vm=*/%vm99530_vm8, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v99555_v29 = vsel /*vm=*/%vm99530_vm8, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v99979_v31 = vadd.f32 1.0, %v151071_v45 (stack57)
        %v100765_v40 = vxor.u32 %v100764_v21, %v100756_v54 (stack48)
        %v99610_v26 = vadd.f32 %v99606_v24, %v99555_v29 (stack53)
        %v100371_v60 = vor.u32 %v100370_v42, %v100369_v7 (stack47)
        %v101203_v52 = vor.u32 %v101202_v30, %v101201_v43 (stack47)
        %v101624_v56 = vadd.s32 %v101621_v22, %v151030_v56 (stack40)
        %v99547_v6 = vsel /*vm=*/%vm99530_vm8, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v99551_v34 = vsel /*vm=*/%vm99530_vm8, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %121285 = vlog2.f32 %v99979_v31 (stack58)
        %v100768_v9 = vadd.s32 %v100765_v40, %v121569_v1 (stack40)
        %v99614_v50 = vmul.f32 %v99610_v26, %v151043_v61 (stack54)
        %v100372_v55 = vxor.u32 %v100371_v60, %v100367_v44 (stack48)
        %v100760_v54 = vadd.s32 %v100756_v54, %v121574_v2 (stack40)
        %v101204_v12 = vxor.u32 %v101203_v52, %v101199_v25 (stack48)
        %v99982_v21 = vmul.f32 -0.5, %v151071_v45 (stack59)
        %v100772_v43 = vadd.s32 3, %v100768_v9 (stack40)
        %v101630_v30 = vshll.u32 %v101621_v22, 6 (stack45)
        %v101631_v22 = vshrl.u32 %v101621_v22, 26 (stack46)
        %v99618_v24 = vadd.f32 %v99614_v50, %v99551_v34 (stack53)
        %v100375_v44 = vadd.s32 %v100372_v55, %v100367_v44 (stack40)
        %v100377_v7 = vshll.u32 %v100372_v55, 26 (stack45)
        %v100378_v42 = vshrl.u32 %v100372_v55, 6 (stack46)
        %v100776_v29 = vadd.s32 %v100772_v43, %v100760_v54 (stack40)
        %v100778_v31 = vshll.u32 %v100772_v43, 17 (stack45)
        %v100779_v40 = vshrl.u32 %v100772_v43, 15 (stack46)
        %v101207_v25 = vadd.s32 %v101204_v12, %v101199_v25 (stack40)
        %v99622_v26 = vmul.f32 %v99618_v24, %v151043_v61 (stack54)
        %v100379_v60 = vor.u32 %v100378_v42, %v100377_v7 (stack47)
        %v101213_v52 = vshll.u32 %v101204_v12, 24 (stack45)
        %v101214_v34 = vshrl.u32 %v101204_v12, 8 (stack46)
        %v99985_v9 = vand.u32 2147483647, %v151071_v45 (stack60)
        %v100780_v50 = vor.u32 %v100779_v40, %v100778_v31 (stack47)
        %v101632_v55 = vor.u32 %v101631_v22, %v101630_v30 (stack47)
        %v151096_v54 = vadd.s32 %v151047_v23, %v122657_v58 (stack40)
        %v99626_v6 = vadd.f32 %v99622_v26, %v99547_v6 (stack53)
        %v100380_v12 = vxor.u32 %v100379_v60, %v100375_v44 (stack48)
        %v101215_v43 = vor.u32 %v101214_v34, %v101213_v52 (stack47)
        %v102032_v30 = vadd.s32 %v157714_v20, %v157078_v48 (stack40)
        %v99983_v21 = vadd.f32 1.0, %v99982_v21 (stack61)
        %v100781_v22 = vxor.u32 %v100780_v50, %v100776_v29 (stack48)
        %v101633_v24 = vxor.u32 %v101632_v55, %v101624_v56 (stack48)
        %v151102_v7 = vadd.s32 %v157711_v53, %v157079_v39 (stack40)
        %v99630_v42 = vmul.f32 %v99626_v6, %v151043_v61 (stack54)
        %v100383_v44 = vadd.s32 %v100380_v12, %v100375_v44 (stack40)
        %v100389_v31 = vshll.u32 %v100380_v12, 6 (stack45)
        %v100390_v40 = vshrl.u32 %v100380_v12, 26 (stack46)
        %v100784_v29 = vadd.s32 %v100781_v22, %v100776_v29 (stack40)
        %v100786_v26 = vshll.u32 %v100781_v22, 29 (stack45)
        %v100787_v60 = vshrl.u32 %v100781_v22, 3 (stack46)
        %v101216_v52 = vxor.u32 %v101215_v43, %v101207_v25 (stack48)
        %v99634_v10 = vadd.f32 %v99630_v42, %v99543_v10 (stack53)
        %vm151105_vm13 = vcmp.lt.f32.partialorder %v99985_v9, 0.0004427343 (stack62)
        %v100391_v9 = vor.u32 %v100390_v40, %v100389_v31 (stack47)
        %v101636_v50 = vadd.s32 %v101633_v24, %v121564_v0 (stack40)
        %v100788_v55 = vor.u32 %v100787_v60, %v100786_v26 (stack47)
        %v101219_v6 = vadd.s32 %v101216_v52, %v121574_v2 (stack40)
        %v101628_v56 = vadd.s32 %v101624_v56, %v121569_v1 (stack40)
        %v102036_v12 = vadd.s32 1, %v102032_v30 (stack40)
        %v121286_v43 = vpop.eup %121285 (stack64)
        %v99638_v22 = vmul.f32 %v99634_v10, %v151043_v61 (stack54)
        %v99984_v45 = vmul.f32 %v99983_v21, %v151071_v45 (stack63)
        %v100392_v21 = vxor.u32 %v100391_v9, %v100383_v44 (stack48)
        %v101640_v24 = vadd.s32 1, %v101636_v50 (stack40)
        %v99981_v42 = vmul.f32 0.6931472, %v121286_v43 (stack65)
        %v100789_v31 = vxor.u32 %v100788_v55, %v100784_v29 (stack48)
        %v101223_v40 = vadd.s32 2, %v101219_v6 (stack40)
        %v102040_v30 = vsel /*vm=*/%vm102027_vm12, /*on_true_vy=*/%v102036_v12, /*on_false_vx=*/%v102032_v30 (stack44)
        %v99642_v27 = vadd.f32 %v99638_v22, %v151068_v27 (stack53)
        %v100395_v26 = vadd.s32 %v100392_v21, %v121574_v2 (stack40)
        %v101211_v25 = vadd.s32 %v101207_v25, %v121564_v0 (stack40)
        %v101644_v60 = vadd.s32 %v101640_v24, %v101628_v56 (stack40)
        %v99987_v52 = vsel /*vm=*/%vm151105_vm13, /*on_true_vy=*/%v99984_v45, /*on_false_vx=*/%v99981_v42 (stack66)
        %v100792_v29 = vadd.s32 %v100789_v31, %v100784_v29 (stack40)
        %v100794_v10 = vshll.u32 %v100789_v31, 16 (stack45)
        %v100795_v34 = vshrl.u32 %v100789_v31, 16 (stack46)
        %v99646_v61 = vmul.f32 %v99642_v27, %v151043_v61 (stack54)
        %v151123_v9 = vxor.u32 2147483648, %v99987_v52 (stack56)
        %v100399_v50 = vadd.s32 5, %v100395_v26 (stack40)
        %v101227_v55 = vadd.s32 %v101223_v40, %v101211_v25 (stack40)
        %v99535_v46 = vsel /*vm=*/%vm99530_vm8, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v100387_v44 = vadd.s32 %v100383_v44, %v121564_v0 (stack40)
        %v100796_v6 = vor.u32 %v100795_v34, %v100794_v10 (stack47)
        %v102057_v56 = vadd.s32 %v151096_v54, %v121569_v1 (stack40)
        %vm151133_vm14 = vcmp.eq.f32.partialorder %v99503_v41, 1.0 (stack68)
        %v99511_v12 = vmul.f32 inf, %v150923_v8 (stack54)
        %v99650_v43 = vadd.f32 %v99646_v61, %v99535_v46 (stack53)
        %121287 = vrsqrt.f32 %v151123_v9 (stack67)
        %v99964_v22 = vand.u32 2147483647, %v151056_v32 (stack77)
        %vm99991_vm15 = vcmp.lt.f32.partialorder %v151123_v9, 5.0 (stack68)
        %v100401_v45 = vxor.u32 %v100399_v50, %v100387_v44 (stack48)
        %v101646_v21 = vshll.u32 %v101640_v24, 17 (stack45)
        %v99654_v8 = vmul.f32 %v99650_v43, %v150923_v8 (stack54)
        %v101229_v42 = vshll.u32 %v101223_v40, 13 (stack45)
        %v101230_v31 = vshrl.u32 %v101223_v40, 19 (stack46)
        %v101647_v24 = vshrl.u32 %v101640_v24, 15 (stack46)
        %v100797_v40 = vxor.u32 %v100796_v6, %v100792_v29 (stack48)
        %vm102022_vm0 = vcmp.lt.u32.totalorder %v151096_v54, %v151047_v23 (stack43)
        %v102063_v27 = vshll.u32 %v102057_v56, 13 (stack45)
        %v102064_v26 = vshrl.u32 %v102057_v56, 19 (stack46)
        %v99658_v25 = vsel /*vm=*/%vm151133_vm14, /*on_true_vy=*/%v99511_v12, /*on_false_vx=*/%v99654_v8 (stack44)
        %v151149_v52 = vsel /*vm=*/%vm99991_vm15, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v151154_v10 = vsel /*vm=*/%vm99991_vm15, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v151157_v34 = vadd.f32 -2.5, %v151123_v9 (stack53)
        %v99662_v61 = vmul.f32 1.4140625, %v99658_v25 (stack54)
        %v100402_v50 = vand.u32.u8 255, %v100401_v45 (stack49)
        %v100800_v29 = vadd.s32 %v100797_v40, %v100792_v29 (stack40)
        %v100806_v46 = vshll.u32 %v100797_v40, 24 (stack45)
        %v100807_v44 = vshrl.u32 %v100797_v40, 8 (stack46)
        %v101231_v6 = vor.u32 %v101230_v31, %v101229_v42 (stack47)
        %v101648_v41 = vor.u32 %v101647_v24, %v101646_v21 (stack47)
        %v102044_v12 = vadd.s32 1, %v102040_v30 (stack40)
        %v99665_v43 = vpack.c.bf16 %v157387_v11, %v99662_v61 (stack81)
        %v151163_v45 = vsel /*vm=*/%vm99991_vm15, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v151168_v21 = vsel /*vm=*/%vm99991_vm15, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v100403_v8 = vand.u32 65535, %v100402_v50 (stack50)
        %v100808_v42 = vor.u32 %v100807_v44, %v100806_v46 (stack47)
        %v101232_v31 = vxor.u32 %v101231_v6, %v101227_v55 (stack48)
        %v101649_v24 = vxor.u32 %v101648_v41, %v101644_v60 (stack48)
        %v102048_v23 = vsel /*vm=*/%vm102022_vm0, /*on_true_vy=*/%v102044_v12, /*on_false_vx=*/%v102040_v30 (stack44)
        %120277 = vst [vmem:[%s123356_s30 + $0x268] sm:$0xf] /*vst_source=*/%v99665_v43 (stack83)
        %v100404_v54 = vshrl.u32 %v100403_v8, 1 (stack51)
        %v102053_v30 = vadd.s32 %v102048_v23, %v121574_v2 (stack40)
        %v102065_v40 = vor.u32 %v102064_v26, %v102063_v27 (stack47)
        %vm102488_vm1 = vcmp.lt.u32.totalorder %v151102_v7, %v157079_v39 (stack43)
        %v100809_v27 = vxor.u32 %v100808_v42, %v100800_v29 (stack48)
        %v101235_v55 = vadd.s32 %v101232_v31, %v101227_v55 (stack40)
        %v101237_v26 = vshll.u32 %v101232_v31, 15 (stack45)
        %v101238_v25 = vshrl.u32 %v101232_v31, 17 (stack46)
        %v100405_v61 = vor.u32 16256, %v100404_v54 (stack47)
        %v101652_v60 = vadd.s32 %v101649_v24, %v101644_v60 (stack40)
        %v101654_v50 = vshll.u32 %v101649_v24, 29 (stack45)
        %v101655_v46 = vshrl.u32 %v101649_v24, 3 (stack46)
        %vm100036_vm2 = vcmp.eq.f32.partialorder %v151123_v9, inf (stack70)
        %v100812_v44 = vadd.s32 %v100809_v27, %v121564_v0 (stack40)
        %v101239_v6 = vor.u32 %v101238_v25, %v101237_v26 (stack47)
        %v102061_v56 = vadd.s32 %v102057_v56, %v102053_v30 (stack40)
        %v121288_v41 = vpop.eup %121287 (stack73)
        %v100406_v12 = vand.u32.u16 65535, %v100405_v61 (stack52)
        %v100804_v29 = vadd.s32 %v100800_v29, %v121569_v1 (stack40)
        %v101656_v43 = vor.u32 %v101655_v46, %v101654_v50 (stack47)
        %v151182_v8 = vadd.s32 %v157714_v20, %v157082_v49 (stack40)
        %v100035_v42 = vmul.f32 %v121288_v41, %v151123_v9 (stack74)
        %v100816_v31 = vadd.s32 4, %v100812_v44 (stack40)
        %v101240_v24 = vxor.u32 %v101239_v6, %v101235_v55 (stack48)
        %v102066_v23 = vxor.u32 %v102065_v40, %v102061_v56 (stack48)
        %vm100038_vm3 = vcmp.eq.f32.partialorder %v151123_v9, 0.0 (stack71)
        %v100039_v54 = vand.u32 2147483648, %v151123_v9 (stack72)
        %v120280_v30 = vadd.low.f32.bf16 -1.0, %v100406_v12 (stack53)
        %v101657_v40 = vxor.u32 %v101656_v43, %v101652_v60 (stack48)
        %v100037_v27 = vsel /*vm=*/%vm100036_vm2, /*on_true_vy=*/%v151123_v9, /*on_false_vx=*/%v100035_v42 (stack75)
        %v100820_v26 = vadd.s32 %v100816_v31, %v100804_v29 (stack40)
        %v100822_v25 = vshll.u32 %v100816_v31, 13 (stack45)
        %v100823_v61 = vshrl.u32 %v100816_v31, 19 (stack46)
        %v100040_v50 = vsel /*vm=*/%vm100038_vm3, /*on_true_vy=*/%v100039_v54, /*on_false_vx=*/%v100037_v27 (stack76)
        %v100415_v46 = vmul.f32 2.0, %v120280_v30 (stack54)
        %v101243_v55 = vadd.s32 %v101240_v24, %v101235_v55 (stack40)
        %v101245_v44 = vshll.u32 %v101240_v24, 26 (stack45)
        %v100043_v6 = vadd.f32 -3.0, %v100040_v50 (stack53)
        %v100824_v41 = vor.u32 %v100823_v61, %v100822_v25 (stack47)
        %v101246_v12 = vshrl.u32 %v101240_v24, 6 (stack46)
        %v101660_v60 = vadd.s32 %v101657_v40, %v101652_v60 (stack40)
        %v100419_v29 = vadd.f32 -0.99609375, %v100415_v46 (stack53)
        %v101662_v43 = vshll.u32 %v101657_v40, 16 (stack45)
        %v101663_v42 = vshrl.u32 %v101657_v40, 16 (stack46)
        %v102069_v56 = vadd.s32 %v102066_v23, %v102061_v56 (stack40)
        %v100028_v31 = vsel /*vm=*/%vm99991_vm15, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v151196_v34 = vsel /*vm=*/%vm99991_vm15, /*on_true_vy=*/%v151157_v34, /*on_false_vx=*/%v100043_v6 (stack44)
        %v100825_v24 = vxor.u32 %v100824_v41, %v100820_v26 (stack48)
        %v101247_v54 = vor.u32 %v101246_v12, %v101245_v44 (stack47)
        %v100024_v30 = vsel /*vm=*/%vm99991_vm15, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v100051_v40 = vmul.f32 %v151196_v34, %v100028_v31 (stack54)
        %v151202_v27 = vmax.f32 %v100419_v29, -0.99609375 (stack55)
        %v101664_v25 = vor.u32 %v101663_v42, %v101662_v43 (stack47)
        %v100828_v26 = vadd.s32 %v100825_v24, %v100820_v26 (stack40)
        %v100830_v61 = vshll.u32 %v100825_v24, 15 (stack45)
        %v100831_v50 = vshrl.u32 %v100825_v24, 17 (stack46)
        %v101248_v46 = vxor.u32 %v101247_v54, %v101243_v55 (stack48)
        %v100055_v44 = vadd.f32 %v100051_v40, %v100024_v30 (stack53)
        %v100435_v6 = vxor.u32 2147483648, %v151202_v27 (stack56)
        %v102071_v41 = vshll.u32 %v102066_v23, 15 (stack45)
        %v102072_v23 = vshrl.u32 %v102066_v23, 17 (stack46)
        %v100832_v12 = vor.u32 %v100831_v50, %v100830_v61 (stack47)
        %v101251_v55 = vadd.s32 %v101248_v46, %v101243_v55 (stack40)
        %v101257_v29 = vshll.u32 %v101248_v46, 6 (stack45)
        %v101258_v43 = vshrl.u32 %v101248_v46, 26 (stack46)
        %v100059_v42 = vmul.f32 %v100055_v44, %v151196_v34 (stack54)
        %v151207_v31 = vmul.f32 %v100435_v6, %v151202_v27 (stack54)
        %v101665_v24 = vxor.u32 %v101664_v25, %v101660_v60 (stack48)
        %v102479_v54 = vadd.s32 %v151102_v7, %v122657_v58 (stack40)
        %v100016_v30 = vsel /*vm=*/%vm99991_vm15, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v100020_v40 = vsel /*vm=*/%vm99991_vm15, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v100833_v25 = vxor.u32 %v100832_v12, %v100828_v26 (stack48)
        %v101259_v61 = vor.u32 %v101258_v43, %v101257_v29 (stack47)
        %v100063_v50 = vadd.f32 %v100059_v42, %v100020_v40 (stack53)
        %v100440_v46 = vadd.f32 1.0, %v151207_v31 (stack57)
        %v100443_v44 = vmul.f32 -0.5, %v151207_v31 (stack59)
        %v102073_v6 = vor.u32 %v102072_v23, %v102071_v41 (stack47)
        %v100836_v26 = vadd.s32 %v100833_v25, %v100828_v26 (stack40)
        %v100838_v41 = vshll.u32 %v100833_v25, 26 (stack45)
        %v100839_v23 = vshrl.u32 %v100833_v25, 6 (stack46)
        %v101260_v12 = vxor.u32 %v101259_v61, %v101251_v55 (stack48)
        %v100067_v29 = vmul.f32 %v100063_v50, %v151196_v34 (stack54)
        %121289 = vlog2.f32 %v100440_v46 (stack58)
        %vm102483_vm4 = vcmp.lt.u32.totalorder %v102479_v54, %v151102_v7 (stack43)
        %v102497_v43 = vadd.s32 1, %v151182_v8 (stack40)
        %v100840_v42 = vor.u32 %v100839_v23, %v100838_v41 (stack47)
        %v101263_v40 = vadd.s32 %v101260_v12, %v121569_v1 (stack40)
        %v101668_v60 = vadd.s32 %v101665_v24, %v101660_v60 (stack40)
        %v101674_v25 = vshll.u32 %v101665_v24, 24 (stack45)
        %v100071_v30 = vadd.f32 %v100067_v29, %v100016_v30 (stack53)
        %v101255_v55 = vadd.s32 %v101251_v55, %v121574_v2 (stack40)
        %v101675_v24 = vshrl.u32 %v101665_v24, 8 (stack46)
        %v102074_v61 = vxor.u32 %v102073_v6, %v102069_v56 (stack48)
        %v100444_v50 = vadd.f32 1.0, %v100443_v44 (stack61)
        %v100841_v46 = vxor.u32 %v100840_v42, %v100836_v26 (stack48)
        %v101267_v44 = vadd.s32 3, %v101263_v40 (stack40)
        %v102501_v8 = vsel /*vm=*/%vm102488_vm1, /*on_true_vy=*/%v102497_v43, /*on_false_vx=*/%v151182_v8 (stack44)
        %v100075_v6 = vmul.f32 %v100071_v30, %v151196_v34 (stack54)
        %v101676_v41 = vor.u32 %v101675_v24, %v101674_v25 (stack47)
        %v102077_v56 = vadd.s32 %v102074_v61, %v102069_v56 (stack40)
        %v102079_v23 = vshll.u32 %v102074_v61, 26 (stack45)
        %v100844_v26 = vadd.s32 %v100841_v46, %v100836_v26 (stack40)
        %v100850_v12 = vshll.u32 %v100841_v46, 6 (stack45)
        %v100851_v29 = vshrl.u32 %v100841_v46, 26 (stack46)
        %v101271_v43 = vadd.s32 %v101267_v44, %v101255_v55 (stack40)
        %v100079_v21 = vadd.f32 %v100075_v6, %v151168_v21 (stack53)
        %v101273_v42 = vshll.u32 %v101267_v44, 17 (stack45)
        %v101274_v40 = vshrl.u32 %v101267_v44, 15 (stack46)
        %v101677_v25 = vxor.u32 %v101676_v41, %v101668_v60 (stack48)
        %v100852_v30 = vor.u32 %v100851_v29, %v100850_v12 (stack47)
        %v102080_v55 = vshrl.u32 %v102074_v61, 6 (stack46)
        %v102505_v24 = vadd.s32 1, %v102501_v8 (stack40)
        %v151231_v61 = vadd.s32 %v102479_v54, %v121569_v1 (stack40)
        %v100083_v46 = vmul.f32 %v100079_v21, %v151196_v34 (stack54)
        %v100446_v44 = vand.u32 2147483647, %v151207_v31 (stack60)
        %v101275_v6 = vor.u32 %v101274_v40, %v101273_v42 (stack47)
        %v101680_v41 = vadd.s32 %v101677_v25, %v121574_v2 (stack40)
        %v100853_v12 = vxor.u32 %v100852_v30, %v100844_v26 (stack48)
        %v102081_v23 = vor.u32 %v102080_v55, %v102079_v23 (stack47)
        %v102509_v7 = vsel /*vm=*/%vm102483_vm4, /*on_true_vy=*/%v102505_v24, /*on_false_vx=*/%v102501_v8 (stack44)
        %v151240_v54 = vadd.s32 %v157711_v53, %v157083_v59 (stack40)
        %v100087_v45 = vadd.f32 %v100083_v46, %v151163_v45 (stack53)
        %v100445_v31 = vmul.f32 %v100444_v50, %v151207_v31 (stack63)
        %v101276_v50 = vxor.u32 %v101275_v6, %v101271_v43 (stack48)
        %v101684_v8 = vadd.s32 2, %v101680_v41 (stack40)
        %v100848_v26 = vadd.s32 %v100844_v26, %v121564_v0 (stack40)
        %v100856_v29 = vadd.s32 %v100853_v12, %v121574_v2 (stack40)
        %v101672_v60 = vadd.s32 %v101668_v60, %v121564_v0 (stack40)
        %v102082_v21 = vxor.u32 %v102081_v23, %v102077_v56 (stack48)
        %v100091_v42 = vmul.f32 %v100087_v45, %v151196_v34 (stack54)
        %v101279_v43 = vadd.s32 %v101276_v50, %v101271_v43 (stack40)
        %v101281_v40 = vshll.u32 %v101276_v50, 29 (stack45)
        %v101282_v25 = vshrl.u32 %v101276_v50, 3 (stack46)
        %v121290_v30 = vpop.eup %121289 (stack64)
        %v100860_v55 = vadd.s32 5, %v100856_v29 (stack40)
        %v101688_v24 = vadd.s32 %v101684_v8, %v101672_v60 (stack40)
        %v101690_v46 = vshll.u32 %v101684_v8, 13 (stack45)
        %v101691_v6 = vshrl.u32 %v101684_v8, 19 (stack46)
        %v100095_v10 = vadd.f32 %v100091_v42, %v151154_v10 (stack53)
        %v100442_v41 = vmul.f32 0.6931472, %v121290_v30 (stack65)
        %v101283_v12 = vor.u32 %v101282_v25, %v101281_v40 (stack47)
        %v102085_v56 = vadd.s32 %v102082_v21, %v102077_v56 (stack40)
        %vm100447_vm5 = vcmp.lt.f32.partialorder %v100446_v44, 0.0004427343 (stack62)
        %v100862_v44 = vxor.u32 %v100860_v55, %v100848_v26 (stack48)
        %v101692_v23 = vor.u32 %v101691_v6, %v101690_v46 (stack47)
        %v102524_v45 = vshll.u32 %v151231_v61, 13 (stack45)
        %v100099_v50 = vmul.f32 %v100095_v10, %v151196_v34 (stack54)
        %v100448_v31 = vsel /*vm=*/%vm100447_vm5, /*on_true_vy=*/%v100445_v31, /*on_false_vx=*/%v100442_v41 (stack66)
        %v101284_v8 = vxor.u32 %v101283_v12, %v101279_v43 (stack48)
        %v102525_v26 = vshrl.u32 %v151231_v61, 19 (stack46)
        %v151252_v29 = vxor.u32 2147483648, %v100448_v31 (stack56)
        %v101693_v60 = vxor.u32 %v101692_v23, %v101688_v24 (stack48)
        %v102091_v42 = vshll.u32 %v102082_v21, 6 (stack45)
        %v102092_v21 = vshrl.u32 %v102082_v21, 26 (stack46)
        %v100103_v52 = vadd.f32 %v100099_v50, %v151149_v52 (stack53)
        %v101287_v43 = vadd.s32 %v101284_v8, %v101279_v43 (stack40)
        %v101289_v40 = vshll.u32 %v101284_v8, 16 (stack45)
        %v101290_v25 = vshrl.u32 %v101284_v8, 16 (stack46)
        %121291 = vrsqrt.f32 %v151252_v29 (stack67)
        %v100863_v30 = vand.u32.u8 255, %v100862_v44 (stack49)
        %vm151258_vm6 = vcmp.eq.f32.partialorder %v99964_v22, 1.0 (stack68)
        %v99972_v55 = vmul.f32 inf, %v151056_v32 (stack54)
        %v100107_v34 = vmul.f32 %v100103_v52, %v151196_v34 (stack54)
        %v99996_v9 = vsel /*vm=*/%vm99991_vm15, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v100425_v46 = vand.u32 2147483647, %v151202_v27 (stack77)
        %v101291_v6 = vor.u32 %v101290_v25, %v101289_v40 (stack47)
        %v102514_v7 = vadd.s32 %v102509_v7, %v121574_v2 (stack40)
        %v100111_v10 = vadd.f32 %v100107_v34, %v99996_v9 (stack53)
        %v102093_v41 = vor.u32 %v102092_v21, %v102091_v42 (stack47)
        %v102526_v12 = vor.u32 %v102525_v26, %v102524_v45 (stack47)
        %v151271_v44 = vadd.s32 %v151240_v54, %v122657_v58 (stack40)
        %v151274_v23 = vadd.f32 -2.5, %v151252_v29 (stack53)
        %v100864_v45 = vand.u32 65535, %v100863_v30 (stack50)
        %v101292_v50 = vxor.u32 %v101291_v6, %v101287_v43 (stack48)
        %v102089_v31 = vadd.s32 %v102085_v56, %v121569_v1 (stack40)
        %v100115_v32 = vmul.f32 %v100111_v10, %v151056_v32 (stack54)
        %v101696_v24 = vadd.s32 %v101693_v60, %v101688_v24 (stack40)
        %v101698_v8 = vshll.u32 %v101693_v60, 15 (stack45)
        %v101699_v26 = vshrl.u32 %v101693_v60, 17 (stack46)
        %v100865_v60 = vshrl.u32 %v100864_v45, 1 (stack51)
        %v101295_v42 = vadd.s32 %v101292_v50, %v101287_v43 (stack40)
        %v101301_v21 = vshll.u32 %v101292_v50, 24 (stack45)
        %v101302_v52 = vshrl.u32 %v101292_v50, 8 (stack46)
        %v100119_v43 = vsel /*vm=*/%vm151258_vm6, /*on_true_vy=*/%v99972_v55, /*on_false_vx=*/%v100115_v32 (stack44)
        %vm100497_vm7 = vcmp.eq.f32.partialorder %v151252_v29, inf (stack70)
        %v101700_v40 = vor.u32 %v101699_v26, %v101698_v8 (stack47)
        %v102094_v56 = vxor.u32 %v102093_v41, %v102085_v56 (stack48)
        %v102522_v61 = vadd.s32 %v151231_v61, %v102514_v7 (stack40)
        %v100123_v25 = vmul.f32 1.4140625, %v100119_v43 (stack54)
        %vm100452_vm8 = vcmp.lt.f32.partialorder %v151252_v29, 5.0 (stack68)
        %vm100499_vm9 = vcmp.eq.f32.partialorder %v151252_v29, 0.0 (stack71)
        %v100866_v30 = vor.u32 16256, %v100865_v60 (stack47)
        %v101303_v22 = vor.u32 %v101302_v52, %v101301_v21 (stack47)
        %v100500_v55 = vand.u32 2147483648, %v151252_v29 (stack72)
        %v101701_v34 = vxor.u32 %v101700_v40, %v101696_v24 (stack48)
        %v102097_v9 = vadd.s32 %v102094_v56, %v121564_v0 (stack40)
        %v102527_v6 = vxor.u32 %v102526_v12, %v102522_v61 (stack48)
        %v100126_v7 = vpack.c.bf16 %v157387_v11, %v100123_v25 (stack81)
        %v100867_v10 = vand.u32.u16 65535, %v100866_v30 (stack52)
        %v101304_v41 = vxor.u32 %v101303_v22, %v101295_v42 (stack48)
        %vm102949_vm10 = vcmp.lt.u32.totalorder %v151240_v54, %v157083_v59 (stack43)
        %v101704_v12 = vadd.s32 %v101701_v34, %v101696_v24 (stack40)
        %v101706_v45 = vshll.u32 %v101701_v34, 26 (stack45)
        %v101707_v50 = vshrl.u32 %v101701_v34, 6 (stack46)
        %v102101_v32 = vadd.s32 1, %v102097_v9 (stack40)
        %120279 = vst [vmem:[%s123356_s30 + $0x2e8] sm:$0xf] /*vst_source=*/%v100126_v7 (stack83)
        %v120282_v24 = vadd.low.f32.bf16 -1.0, %v100867_v10 (stack53)
        %v101299_v8 = vadd.s32 %v101295_v42, %v121569_v1 (stack40)
        %v101307_v26 = vadd.s32 %v101304_v41, %v121564_v0 (stack40)
        %v102530_v60 = vadd.s32 %v102527_v6, %v102522_v61 (stack40)
        %v121292_v42 = vpop.eup %121291 (stack73)
        %v101708_v21 = vor.u32 %v101707_v50, %v101706_v45 (stack47)
        %v102105_v31 = vadd.s32 %v102101_v32, %v102089_v31 (stack40)
        %v102107_v52 = vshll.u32 %v102101_v32, 17 (stack45)
        %v102108_v43 = vshrl.u32 %v102101_v32, 15 (stack46)
        %v100496_v40 = vmul.f32 %v121292_v42, %v151252_v29 (stack74)
        %v100876_v56 = vmul.f32 2.0, %v120282_v24 (stack54)
        %v101311_v61 = vadd.s32 4, %v101307_v26 (stack40)
        %v102532_v25 = vshll.u32 %v102527_v6, 15 (stack45)
        %v101709_v30 = vxor.u32 %v101708_v21, %v101704_v12 (stack48)
        %v102109_v22 = vor.u32 %v102108_v43, %v102107_v52 (stack47)
        %v102533_v34 = vshrl.u32 %v102527_v6, 17 (stack46)
        %v151295_v9 = vadd.s32 %v157714_v20, %v157084_v16 (stack40)
        %v100498_v6 = vsel /*vm=*/%vm100497_vm7, /*on_true_vy=*/%v151252_v29, /*on_false_vx=*/%v100496_v40 (stack75)
        %v100880_v7 = vadd.f32 -0.99609375, %v100876_v56 (stack53)
        %v101315_v10 = vadd.s32 %v101311_v61, %v101299_v8 (stack40)
        %v101317_v41 = vshll.u32 %v101311_v61, 13 (stack45)
        %v100501_v55 = vsel /*vm=*/%vm100499_vm9, /*on_true_vy=*/%v100500_v55, /*on_false_vx=*/%v100498_v6 (stack76)
        %v101318_v45 = vshrl.u32 %v101311_v61, 19 (stack46)
        %v101712_v12 = vadd.s32 %v101709_v30, %v101704_v12 (stack40)
        %v101718_v50 = vshll.u32 %v101709_v30, 6 (stack45)
        %v100504_v32 = vadd.f32 -3.0, %v100501_v55 (stack53)
        %v151302_v24 = vmax.f32 %v100880_v7, -0.99609375 (stack55)
        %v101719_v8 = vshrl.u32 %v101709_v30, 26 (stack46)
        %v102110_v26 = vxor.u32 %v102109_v22, %v102105_v31 (stack48)
        %v151307_v42 = vsel /*vm=*/%vm100452_vm8, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v151312_v21 = vsel /*vm=*/%vm100452_vm8, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v151317_v52 = vsel /*vm=*/%vm100452_vm8, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v101319_v43 = vor.u32 %v101318_v45, %v101317_v41 (stack47)
        %v100489_v40 = vsel /*vm=*/%vm100452_vm8, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v151325_v23 = vsel /*vm=*/%vm100452_vm8, /*on_true_vy=*/%v151274_v23, /*on_false_vx=*/%v100504_v32 (stack44)
        %v100896_v56 = vxor.u32 2147483648, %v151302_v24 (stack56)
        %v102534_v61 = vor.u32 %v102533_v34, %v102532_v25 (stack47)
        %v100512_v25 = vmul.f32 %v151325_v23, %v100489_v40 (stack54)
        %v101320_v30 = vxor.u32 %v101319_v43, %v101315_v10 (stack48)
        %v101720_v22 = vor.u32 %v101719_v8, %v101718_v50 (stack47)
        %v102113_v31 = vadd.s32 %v102110_v26, %v102105_v31 (stack40)
        %v100485_v34 = vsel /*vm=*/%vm100452_vm8, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v151333_v6 = vmul.f32 %v100896_v56, %v151302_v24 (stack54)
        %v102115_v7 = vshll.u32 %v102110_v26, 29 (stack45)
        %v102116_v41 = vshrl.u32 %v102110_v26, 3 (stack46)
        %v100516_v55 = vadd.f32 %v100512_v25, %v100485_v34 (stack53)
        %v101323_v10 = vadd.s32 %v101320_v30, %v101315_v10 (stack40)
        %v101325_v45 = vshll.u32 %v101320_v30, 15 (stack45)
        %v101326_v50 = vshrl.u32 %v101320_v30, 17 (stack46)
        %v100477_v32 = vsel /*vm=*/%vm100452_vm8, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v100481_v8 = vsel /*vm=*/%vm100452_vm8, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v100901_v26 = vadd.f32 1.0, %v151333_v6 (stack57)
        %v101721_v43 = vxor.u32 %v101720_v22, %v101712_v12 (stack48)
        %v100520_v40 = vmul.f32 %v100516_v55, %v151325_v23 (stack54)
        %v101327_v56 = vor.u32 %v101326_v50, %v101325_v45 (stack47)
        %v102117_v25 = vor.u32 %v102116_v41, %v102115_v7 (stack47)
        %v102535_v61 = vxor.u32 %v102534_v61, %v102530_v60 (stack48)
        %121293 = vlog2.f32 %v100901_v26 (stack58)
        %v101716_v12 = vadd.s32 %v101712_v12, %v121574_v2 (stack40)
        %v101724_v30 = vadd.s32 %v101721_v43, %v121569_v1 (stack40)
        %v102958_v22 = vadd.s32 1, %v151295_v9 (stack40)
        %v100524_v34 = vadd.f32 %v100520_v40, %v100481_v8 (stack53)
        %v101328_v7 = vxor.u32 %v101327_v56, %v101323_v10 (stack48)
        %v102118_v41 = vxor.u32 %v102117_v25, %v102113_v31 (stack48)
        %v102538_v60 = vadd.s32 %v102535_v61, %v102530_v60 (stack40)
        %v100904_v55 = vmul.f32 -0.5, %v151333_v6 (stack59)
        %v101728_v45 = vadd.s32 3, %v101724_v30 (stack40)
        %v102540_v50 = vshll.u32 %v102535_v61, 26 (stack45)
        %v102541_v8 = vshrl.u32 %v102535_v61, 6 (stack46)
        %v100528_v26 = vmul.f32 %v100524_v34, %v151325_v23 (stack54)
        %v101331_v10 = vadd.s32 %v101328_v7, %v101323_v10 (stack40)
        %v101333_v43 = vshll.u32 %v101328_v7, 26 (stack45)
        %v101334_v40 = vshrl.u32 %v101328_v7, 6 (stack46)
        %v101732_v56 = vadd.s32 %v101728_v45, %v101716_v12 (stack40)
        %v101734_v25 = vshll.u32 %v101728_v45, 17 (stack45)
        %v101735_v61 = vshrl.u32 %v101728_v45, 15 (stack46)
        %v102121_v31 = vadd.s32 %v102118_v41, %v102113_v31 (stack40)
        %vm102944_vm11 = vcmp.lt.u32.totalorder %v151271_v44, %v151240_v54 (stack43)
        %v100532_v32 = vadd.f32 %v100528_v26, %v100477_v32 (stack53)
        %v101335_v12 = vor.u32 %v101334_v40, %v101333_v43 (stack47)
        %v102123_v30 = vshll.u32 %v102118_v41, 16 (stack45)
        %v102124_v34 = vshrl.u32 %v102118_v41, 16 (stack46)
        %v101736_v7 = vor.u32 %v101735_v61, %v101734_v25 (stack47)
        %v102542_v41 = vor.u32 %v102541_v8, %v102540_v50 (stack47)
        %v102962_v9 = vsel /*vm=*/%vm102949_vm10, /*on_true_vy=*/%v102958_v22, /*on_false_vx=*/%v151295_v9 (stack44)
        %v151356_v22 = vadd.s32 %v151271_v44, %v121569_v1 (stack40)
        %v100536_v45 = vmul.f32 %v100532_v32, %v151325_v23 (stack54)
        %v100907_v50 = vand.u32 2147483647, %v151333_v6 (stack60)
        %v101336_v8 = vxor.u32 %v101335_v12, %v101331_v10 (stack48)
        %v102125_v26 = vor.u32 %v102124_v34, %v102123_v30 (stack47)
        %v100905_v55 = vadd.f32 1.0, %v100904_v55 (stack61)
        %v101737_v43 = vxor.u32 %v101736_v7, %v101732_v56 (stack48)
        %v102543_v40 = vxor.u32 %v102542_v41, %v102538_v60 (stack48)
        %v151362_v25 = vadd.s32 %v157711_v53, %v157089_v17 (stack40)
        %v100540_v52 = vadd.f32 %v100536_v45, %v151317_v52 (stack53)
        %v101339_v10 = vadd.s32 %v101336_v8, %v101331_v10 (stack40)
        %v101345_v61 = vshll.u32 %v101336_v8, 6 (stack45)
        %v101346_v32 = vshrl.u32 %v101336_v8, 26 (stack46)
        %v101740_v56 = vadd.s32 %v101737_v43, %v101732_v56 (stack40)
        %v101742_v12 = vshll.u32 %v101737_v43, 29 (stack45)
        %v101743_v30 = vshrl.u32 %v101737_v43, 3 (stack46)
        %v102126_v34 = vxor.u32 %v102125_v26, %v102121_v31 (stack48)
        %v100544_v7 = vmul.f32 %v100540_v52, %v151325_v23 (stack54)
        %v101347_v41 = vor.u32 %v101346_v32, %v101345_v61 (stack47)
        %v151366_v60 = vadd.s32 %v102543_v40, %v102538_v60 (stack40)
        %v102966_v45 = vadd.s32 1, %v102962_v9 (stack40)
        %v101744_v8 = vor.u32 %v101743_v30, %v101742_v12 (stack47)
        %v102129_v31 = vadd.s32 %v102126_v34, %v102121_v31 (stack40)
        %v102135_v26 = vshll.u32 %v102126_v34, 24 (stack45)
        %v102136_v43 = vshrl.u32 %v102126_v34, 8 (stack46)
        %v121294_v52 = vpop.eup %121293 (stack64)
        %v100548_v21 = vadd.f32 %v100544_v7, %v151312_v21 (stack53)
        %v100906_v6 = vmul.f32 %v100905_v55, %v151333_v6 (stack63)
        %vm100908_vm12 = vcmp.lt.f32.partialorder %v100907_v50, 0.0004427343 (stack62)
        %v101348_v50 = vxor.u32 %v101347_v41, %v101339_v10 (stack48)
        %v100903_v55 = vmul.f32 0.6931472, %v121294_v52 (stack65)
        %v101745_v61 = vxor.u32 %v101744_v8, %v101740_v56 (stack48)
        %v102137_v32 = vor.u32 %v102136_v43, %v102135_v26 (stack47)
        %v102552_v12 = vshll.u32 %v102543_v40, 6 (stack45)
        %v100552_v30 = vmul.f32 %v100548_v21, %v151325_v23 (stack54)
        %v101351_v34 = vadd.s32 %v101348_v50, %v121574_v2 (stack40)
        %v102553_v40 = vshrl.u32 %v102543_v40, 26 (stack46)
        %v102970_v54 = vsel /*vm=*/%vm102944_vm11, /*on_true_vy=*/%v102966_v45, /*on_false_vx=*/%v102962_v9 (stack44)
        %v100909_v44 = vsel /*vm=*/%vm100908_vm12, /*on_true_vy=*/%v100906_v6, /*on_false_vx=*/%v100903_v55 (stack66)
        %v101748_v9 = vadd.s32 %v101745_v61, %v101740_v56 (stack40)
        %v101750_v56 = vshll.u32 %v101745_v61, 16 (stack45)
        %v101751_v7 = vshrl.u32 %v101745_v61, 16 (stack46)
        %v100556_v42 = vadd.f32 %v100552_v30, %v151307_v42 (stack53)
        %v151376_v41 = vxor.u32 2147483648, %v100909_v44 (stack56)
        %v101355_v45 = vadd.s32 5, %v101351_v34 (stack40)
        %v102138_v8 = vxor.u32 %v102137_v32, %v102129_v31 (stack48)
        %v101343_v10 = vadd.s32 %v101339_v10, %v121564_v0 (stack40)
        %v101752_v26 = vor.u32 %v101751_v7, %v101750_v56 (stack47)
        %v100560_v43 = vmul.f32 %v100556_v42, %v151325_v23 (stack54)
        %121295 = vrsqrt.f32 %v151376_v41 (stack67)
        %v102985_v52 = vshll.u32 %v151356_v22, 13 (stack45)
        %v102986_v21 = vshrl.u32 %v151356_v22, 19 (stack46)
        %v100433_v6 = vmul.f32 inf, %v151202_v27 (stack54)
        %v100461_v50 = vsel /*vm=*/%vm100452_vm8, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %vm100913_vm13 = vcmp.lt.f32.partialorder %v151376_v41, 5.0 (stack68)
        %v101357_v55 = vxor.u32 %v101355_v45, %v101343_v10 (stack48)
        %vm151390_vm14 = vcmp.eq.f32.partialorder %v100425_v46, 1.0 (stack68)
        %v100564_v61 = vadd.f32 %v100560_v43, %v100461_v50 (stack53)
        %v102554_v32 = vor.u32 %v102553_v40, %v102552_v12 (stack47)
        %v102975_v12 = vadd.s32 %v102970_v54, %v121574_v2 (stack40)
        %v100457_v29 = vsel /*vm=*/%vm100452_vm8, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v101753_v30 = vxor.u32 %v101752_v26, %v101748_v9 (stack48)
        %v102133_v31 = vadd.s32 %v102129_v31, %v121564_v0 (stack40)
        %v102550_v34 = vadd.s32 %v151366_v60, %v121569_v1 (stack40)
        %v100568_v23 = vmul.f32 %v100564_v61, %v151325_v23 (stack54)
        %v151405_v40 = vsel /*vm=*/%vm100913_vm13, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v151408_v54 = vadd.f32 -2.5, %v151376_v41 (stack53)
        %v102987_v44 = vor.u32 %v102986_v21, %v102985_v52 (stack47)
        %v101358_v56 = vand.u32.u8 255, %v101357_v55 (stack49)
        %v101756_v9 = vadd.s32 %v101753_v30, %v101748_v9 (stack40)
        %v101762_v7 = vshll.u32 %v101753_v30, 24 (stack45)
        %v101763_v42 = vshrl.u32 %v101753_v30, 8 (stack46)
        %v100572_v45 = vadd.f32 %v100568_v23, %v100457_v29 (stack53)
        %v102141_v8 = vadd.s32 %v102138_v8, %v121574_v2 (stack40)
        %v102555_v60 = vxor.u32 %v102554_v32, %v151366_v60 (stack48)
        %v102983_v22 = vadd.s32 %v151356_v22, %v102975_v12 (stack40)
        %vm100958_vm15 = vcmp.eq.f32.partialorder %v151376_v41, inf (stack70)
        %v100961_v10 = vand.u32 2147483648, %v151376_v41 (stack72)
        %v101359_v26 = vand.u32 65535, %v101358_v56 (stack50)
        %v101764_v43 = vor.u32 %v101763_v42, %v101762_v7 (stack47)
        %v100576_v27 = vmul.f32 %v100572_v45, %v151202_v27 (stack54)
        %vm100960_vm0 = vcmp.eq.f32.partialorder %v151376_v41, 0.0 (stack71)
        %v102145_v52 = vadd.s32 2, %v102141_v8 (stack40)
        %v102558_v21 = vadd.s32 %v102555_v60, %v121564_v0 (stack40)
        %v102988_v50 = vxor.u32 %v102987_v44, %v102983_v22 (stack48)
        %v101360_v55 = vshrl.u32 %v101359_v26, 1 (stack51)
        %v101760_v61 = vadd.s32 %v101756_v9, %v121569_v1 (stack40)
        %v101765_v32 = vxor.u32 %v101764_v43, %v101756_v9 (stack48)
        %vm103410_vm1 = vcmp.lt.u32.totalorder %v151362_v25, %v157089_v17 (stack43)
        %v100580_v6 = vsel /*vm=*/%vm151390_vm14, /*on_true_vy=*/%v100433_v6, /*on_false_vx=*/%v100576_v27 (stack44)
        %v102149_v46 = vadd.s32 %v102145_v52, %v102133_v31 (stack40)
        %v102151_v12 = vshll.u32 %v102145_v52, 13 (stack45)
        %v102152_v29 = vshrl.u32 %v102145_v52, 19 (stack46)
        %v100584_v30 = vmul.f32 1.4140625, %v100580_v6 (stack54)
        %v101361_v31 = vor.u32 16256, %v101360_v55 (stack47)
        %v101768_v23 = vadd.s32 %v101765_v32, %v121564_v0 (stack40)
        %v102562_v44 = vadd.s32 1, %v102558_v21 (stack40)
        %v102153_v56 = vor.u32 %v102152_v29, %v102151_v12 (stack47)
        %v102991_v9 = vadd.s32 %v102988_v50, %v102983_v22 (stack40)
        %v102993_v7 = vshll.u32 %v102988_v50, 15 (stack45)
        %v102994_v42 = vshrl.u32 %v102988_v50, 17 (stack46)
        %v121296_v45 = vpop.eup %121295 (stack73)
        %v100587_v8 = vpack.c.bf16 %v157387_v11, %v100584_v30 (stack81)
        %v101362_v60 = vand.u32.u16 65535, %v101361_v31 (stack52)
        %v101772_v22 = vadd.s32 4, %v101768_v23 (stack40)
        %v102566_v34 = vadd.s32 %v102562_v44, %v102550_v34 (stack40)
        %v100957_v26 = vmul.f32 %v121296_v45, %v151376_v41 (stack74)
        %v102154_v43 = vxor.u32 %v102153_v56, %v102149_v46 (stack48)
        %v102568_v27 = vshll.u32 %v102562_v44, 17 (stack45)
        %v102569_v52 = vshrl.u32 %v102562_v44, 15 (stack46)
        %120281 = vst [vmem:[%s123356_s30 + $0x368] sm:$0xf] /*vst_source=*/%v100587_v8 (stack83)
        %v120288_v21 = vadd.low.f32.bf16 -1.0, %v101362_v60 (stack53)
        %v101776_v50 = vadd.s32 %v101772_v22, %v101760_v61 (stack40)
        %v101778_v55 = vshll.u32 %v101772_v22, 13 (stack45)
        %v101779_v61 = vshrl.u32 %v101772_v22, 19 (stack46)
        %v100959_v32 = vsel /*vm=*/%vm100958_vm15, /*on_true_vy=*/%v151376_v41, /*on_false_vx=*/%v100957_v26 (stack75)
        %v102157_v6 = vadd.s32 %v102154_v43, %v102149_v46 (stack40)
        %v102159_v46 = vshll.u32 %v102154_v43, 15 (stack45)
        %v102160_v12 = vshrl.u32 %v102154_v43, 17 (stack46)
        %v100962_v10 = vsel /*vm=*/%vm100960_vm0, /*on_true_vy=*/%v100961_v10, /*on_false_vx=*/%v100959_v32 (stack76)
        %v101371_v29 = vmul.f32 2.0, %v120288_v21 (stack54)
        %v101780_v30 = vor.u32 %v101779_v61, %v101778_v55 (stack47)
        %v102570_v31 = vor.u32 %v102569_v52, %v102568_v27 (stack47)
        %v100965_v23 = vadd.f32 -3.0, %v100962_v10 (stack53)
        %v102161_v44 = vor.u32 %v102160_v12, %v102159_v46 (stack47)
        %v102995_v56 = vor.u32 %v102994_v42, %v102993_v7 (stack47)
        %v103415_v7 = vadd.s32 %v157714_v20, %v157090_v62 (stack40)
        %v100950_v42 = vsel /*vm=*/%vm100913_vm13, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v101375_v45 = vadd.f32 -0.99609375, %v101371_v29 (stack53)
        %v101781_v8 = vxor.u32 %v101780_v30, %v101776_v50 (stack48)
        %v102571_v60 = vxor.u32 %v102570_v31, %v102566_v34 (stack48)
        %v151440_v54 = vsel /*vm=*/%vm100913_vm13, /*on_true_vy=*/%v151408_v54, /*on_false_vx=*/%v100965_v23 (stack44)
        %v102162_v22 = vxor.u32 %v102161_v44, %v102157_v6 (stack48)
        %v102996_v26 = vxor.u32 %v102995_v56, %v102991_v9 (stack48)
        %v151444_v43 = vadd.s32 %v151362_v25, %v122657_v58 (stack40)
        %v100973_v27 = vmul.f32 %v151440_v54, %v100950_v42 (stack54)
        %v151447_v52 = vmax.f32 %v101375_v45, -0.99609375 (stack55)
        %v101784_v21 = vadd.s32 %v101781_v8, %v101776_v50 (stack40)
        %v101786_v50 = vshll.u32 %v101781_v8, 15 (stack45)
        %v101787_v55 = vshrl.u32 %v101781_v8, 17 (stack46)
        %v102165_v61 = vadd.s32 %v102162_v22, %v102157_v6 (stack40)
        %v102167_v32 = vshll.u32 %v102162_v22, 26 (stack45)
        %v102168_v6 = vshrl.u32 %v102162_v22, 6 (stack46)
        %v151452_v46 = vsel /*vm=*/%vm100913_vm13, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v151457_v12 = vsel /*vm=*/%vm100913_vm13, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v100977_v40 = vadd.f32 %v100973_v27, %v151405_v40 (stack53)
        %v101391_v10 = vxor.u32 2147483648, %v151447_v52 (stack56)
        %v100934_v29 = vsel /*vm=*/%vm100913_vm13, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v101788_v30 = vor.u32 %v101787_v55, %v101786_v50 (stack47)
        %v102169_v31 = vor.u32 %v102168_v6, %v102167_v32 (stack47)
        %v102574_v34 = vadd.s32 %v102571_v60, %v102566_v34 (stack40)
        %v100938_v23 = vsel /*vm=*/%vm100913_vm13, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v100942_v44 = vsel /*vm=*/%vm100913_vm13, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v100981_v56 = vmul.f32 %v100977_v40, %v151440_v54 (stack54)
        %v101394_v42 = vmul.f32 %v101391_v10, %v151447_v52 (stack54)
        %v101789_v45 = vxor.u32 %v101788_v30, %v101784_v21 (stack48)
        %v102170_v8 = vxor.u32 %v102169_v31, %v102165_v61 (stack48)
        %v102576_v22 = vshll.u32 %v102571_v60, 29 (stack45)
        %v102999_v9 = vadd.s32 %v102996_v26, %v102991_v9 (stack40)
        %vm103405_vm2 = vcmp.lt.u32.totalorder %v151444_v43, %v151362_v25 (stack43)
        %v100985_v27 = vadd.f32 %v100981_v56, %v100942_v44 (stack53)
        %v101396_v50 = vadd.f32 1.0, %v101394_v42 (stack57)
        %v101399_v55 = vmul.f32 -0.5, %v101394_v42 (stack59)
        %v102577_v60 = vshrl.u32 %v102571_v60, 3 (stack46)
        %v101792_v21 = vadd.s32 %v101789_v45, %v101784_v21 (stack40)
        %v101794_v32 = vshll.u32 %v101789_v45, 26 (stack45)
        %v101795_v6 = vshrl.u32 %v101789_v45, 6 (stack46)
        %v102173_v61 = vadd.s32 %v102170_v8, %v102165_v61 (stack40)
        %v100989_v40 = vmul.f32 %v100985_v27, %v151440_v54 (stack54)
        %121297 = vlog2.f32 %v101396_v50 (stack58)
        %v103001_v10 = vshll.u32 %v102996_v26, 26 (stack45)
        %v151477_v30 = vadd.s32 %v151444_v43, %v121569_v1 (stack40)
        %v101796_v31 = vor.u32 %v101795_v6, %v101794_v32 (stack47)
        %v102179_v44 = vshll.u32 %v102170_v8, 6 (stack45)
        %v102180_v56 = vshrl.u32 %v102170_v8, 26 (stack46)
        %v103419_v45 = vadd.s32 1, %v103415_v7 (stack40)
        %v100993_v23 = vadd.f32 %v100989_v40, %v100938_v23 (stack53)
        %v101402_v8 = vand.u32 2147483647, %v101394_v42 (stack60)
        %v102578_v22 = vor.u32 %v102577_v60, %v102576_v22 (stack47)
        %v103002_v26 = vshrl.u32 %v102996_v26, 6 (stack46)
        %v101400_v27 = vadd.f32 1.0, %v101399_v55 (stack61)
        %v101797_v50 = vxor.u32 %v101796_v31, %v101792_v21 (stack48)
        %v102181_v55 = vor.u32 %v102180_v56, %v102179_v44 (stack47)
        %v103423_v7 = vsel /*vm=*/%vm103410_vm1, /*on_true_vy=*/%v103419_v45, /*on_false_vx=*/%v103415_v7 (stack44)
        %v100997_v60 = vmul.f32 %v100993_v23, %v151440_v54 (stack54)
        %v102579_v32 = vxor.u32 %v102578_v22, %v102574_v34 (stack48)
        %v103003_v6 = vor.u32 %v103002_v26, %v103001_v10 (stack47)
        %v103427_v40 = vadd.s32 1, %v103423_v7 (stack40)
        %v101800_v21 = vadd.s32 %v101797_v50, %v101792_v21 (stack40)
        %v101806_v10 = vshll.u32 %v101797_v50, 6 (stack45)
        %v101807_v31 = vshrl.u32 %v101797_v50, 26 (stack46)
        %v102182_v44 = vxor.u32 %v102181_v55, %v102173_v61 (stack48)
        %v101001_v29 = vadd.f32 %v100997_v60, %v100934_v29 (stack53)
        %v102582_v34 = vadd.s32 %v102579_v32, %v102574_v34 (stack40)
        %v102584_v56 = vshll.u32 %v102579_v32, 16 (stack45)
        %v102585_v45 = vshrl.u32 %v102579_v32, 16 (stack46)
        %vm151483_vm3 = vcmp.lt.f32.partialorder %v101402_v8, 0.0004427343 (stack62)
        %v101808_v8 = vor.u32 %v101807_v31, %v101806_v10 (stack47)
        %v102177_v61 = vadd.s32 %v102173_v61, %v121574_v2 (stack40)
        %v102185_v22 = vadd.s32 %v102182_v44, %v121569_v1 (stack40)
        %v103004_v26 = vxor.u32 %v103003_v6, %v102999_v9 (stack48)
        %v101005_v50 = vmul.f32 %v101001_v29, %v151440_v54 (stack54)
        %v101401_v42 = vmul.f32 %v101400_v27, %v101394_v42 (stack63)
        %v102586_v27 = vor.u32 %v102585_v45, %v102584_v56 (stack47)
        %v103431_v25 = vsel /*vm=*/%vm103405_vm2, /*on_true_vy=*/%v103427_v40, /*on_false_vx=*/%v103423_v7 (stack44)
        %v101809_v43 = vxor.u32 %v101808_v8, %v101800_v21 (stack48)
        %v102189_v55 = vadd.s32 3, %v102185_v22 (stack40)
        %v103007_v9 = vadd.s32 %v103004_v26, %v102999_v9 (stack40)
        %v103013_v7 = vshll.u32 %v103004_v26, 6 (stack45)
        %v101009_v12 = vadd.f32 %v101005_v50, %v151457_v12 (stack53)
        %v102587_v60 = vxor.u32 %v102586_v27, %v102582_v34 (stack48)
        %v103014_v32 = vshrl.u32 %v103004_v26, 26 (stack46)
        %v103436_v6 = vadd.s32 %v103431_v25, %v121574_v2 (stack40)
        %v101812_v40 = vadd.s32 %v101809_v43, %v121574_v2 (stack40)
        %v102193_v10 = vadd.s32 %v102189_v55, %v102177_v61 (stack40)
        %v102195_v31 = vshll.u32 %v102189_v55, 17 (stack45)
        %v102196_v44 = vshrl.u32 %v102189_v55, 15 (stack46)
        %v101013_v29 = vmul.f32 %v101009_v12, %v151440_v54 (stack54)
        %v102590_v34 = vadd.s32 %v102587_v60, %v102582_v34 (stack40)
        %v102596_v56 = vshll.u32 %v102587_v60, 24 (stack45)
        %v102597_v45 = vshrl.u32 %v102587_v60, 8 (stack46)
        %v121298_v8 = vpop.eup %121297 (stack64)
        %v101804_v21 = vadd.s32 %v101800_v21, %v121564_v0 (stack40)
        %v101816_v61 = vadd.s32 5, %v101812_v40 (stack40)
        %v102197_v22 = vor.u32 %v102196_v44, %v102195_v31 (stack47)
        %v103015_v26 = vor.u32 %v103014_v32, %v103013_v7 (stack47)
        %v101017_v46 = vadd.f32 %v101013_v29, %v151452_v46 (stack53)
        %v101398_v50 = vmul.f32 0.6931472, %v121298_v8 (stack65)
        %v102598_v27 = vor.u32 %v102597_v45, %v102596_v56 (stack47)
        %v103446_v25 = vshll.u32 %v151477_v30, 13 (stack45)
        %v101818_v43 = vxor.u32 %v101816_v61, %v101804_v21 (stack48)
        %v102198_v55 = vxor.u32 %v102197_v22, %v102193_v10 (stack48)
        %v103016_v7 = vxor.u32 %v103015_v26, %v103007_v9 (stack48)
        %v103444_v12 = vadd.s32 %v151477_v30, %v103436_v6 (stack40)
        %v101021_v60 = vmul.f32 %v101017_v46, %v151440_v54 (stack54)
        %v101404_v23 = vsel /*vm=*/%vm151483_vm3, /*on_true_vy=*/%v101401_v42, /*on_false_vx=*/%v101398_v50 (stack66)
        %v102599_v42 = vxor.u32 %v102598_v27, %v102590_v34 (stack48)
        %v103447_v30 = vshrl.u32 %v151477_v30, 19 (stack46)
        %v100922_v32 = vsel /*vm=*/%vm100913_vm13, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v151508_v6 = vxor.u32 2147483648, %v101404_v23 (stack56)
        %v102201_v40 = vadd.s32 %v102198_v55, %v102193_v10 (stack40)
        %v102203_v10 = vshll.u32 %v102198_v55, 29 (stack45)
        %v100886_v31 = vand.u32 2147483647, %v151302_v24 (stack77)
        %v101025_v44 = vadd.f32 %v101021_v60, %v100922_v32 (stack53)
        %v102204_v29 = vshrl.u32 %v102198_v55, 3 (stack46)
        %121299 = vrsqrt.f32 %v151508_v6 (stack67)
        %v101819_v56 = vand.u32.u8 255, %v101818_v43 (stack49)
        %v101029_v54 = vmul.f32 %v101025_v44, %v151440_v54 (stack54)
        %v102602_v45 = vadd.s32 %v102599_v42, %v121574_v2 (stack40)
        %v103019_v8 = vadd.s32 %v103016_v7, %v121564_v0 (stack40)
        %v103448_v21 = vor.u32 %v103447_v30, %v103446_v25 (stack47)
        %v100918_v41 = vsel /*vm=*/%vm100913_vm13, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v102205_v61 = vor.u32 %v102204_v29, %v102203_v10 (stack47)
        %vm151518_vm4 = vcmp.eq.f32.partialorder %v100886_v31, 1.0 (stack68)
        %v100894_v26 = vmul.f32 inf, %v151302_v24 (stack54)
        %v101033_v46 = vadd.f32 %v101029_v54, %v100918_v41 (stack53)
        %v101820_v50 = vand.u32 65535, %v101819_v56 (stack50)
        %v102206_v27 = vxor.u32 %v102205_v61, %v102201_v40 (stack48)
        %v102594_v34 = vadd.s32 %v102590_v34, %v121564_v0 (stack40)
        %v103011_v9 = vadd.s32 %v103007_v9, %v121569_v1 (stack40)
        %v101037_v24 = vmul.f32 %v101033_v46, %v151302_v24 (stack54)
        %v102606_v25 = vadd.s32 2, %v102602_v45 (stack40)
        %v103023_v43 = vadd.s32 1, %v103019_v8 (stack40)
        %v103449_v55 = vxor.u32 %v103448_v21, %v103444_v12 (stack48)
        %v101821_v7 = vshrl.u32 %v101820_v50, 1 (stack51)
        %v102209_v60 = vadd.s32 %v102206_v27, %v102201_v40 (stack40)
        %v102211_v23 = vshll.u32 %v102206_v27, 16 (stack45)
        %v102212_v42 = vshrl.u32 %v102206_v27, 16 (stack46)
        %v101041_v30 = vsel /*vm=*/%vm151518_vm4, /*on_true_vy=*/%v100894_v26, /*on_false_vx=*/%v101037_v24 (stack44)
        %vm101453_vm5 = vcmp.eq.f32.partialorder %v151508_v6, inf (stack70)
        %v102610_v32 = vadd.s32 %v102606_v25, %v102594_v34 (stack40)
        %v102612_v40 = vshll.u32 %v102606_v25, 13 (stack45)
        %v102613_v10 = vshrl.u32 %v102606_v25, 19 (stack46)
        %v101045_v31 = vmul.f32 1.4140625, %v101041_v30 (stack54)
        %vm101455_vm6 = vcmp.eq.f32.partialorder %v151508_v6, 0.0 (stack71)
        %v101822_v44 = vor.u32 16256, %v101821_v7 (stack47)
        %v102213_v29 = vor.u32 %v102212_v42, %v102211_v23 (stack47)
        %v103027_v56 = vadd.s32 %v103023_v43, %v103011_v9 (stack40)
        %vm101408_vm7 = vcmp.lt.f32.partialorder %v151508_v6, 5.0 (stack68)
        %v102614_v54 = vor.u32 %v102613_v10, %v102612_v40 (stack47)
        %v103029_v45 = vshll.u32 %v103023_v43, 17 (stack45)
        %v103030_v8 = vshrl.u32 %v103023_v43, 15 (stack46)
        %v151531_v12 = vadd.s32 %v103449_v55, %v103444_v12 (stack40)
        %v101048_v21 = vpack.c.bf16 %v157387_v11, %v101045_v31 (stack81)
        %v101823_v41 = vand.u32.u16 65535, %v101822_v44 (stack52)
        %v102214_v61 = vxor.u32 %v102213_v29, %v102209_v60 (stack48)
        %v103454_v22 = vshll.u32 %v103449_v55, 15 (stack45)
        %v102615_v26 = vxor.u32 %v102614_v54, %v102610_v32 (stack48)
        %v103031_v46 = vor.u32 %v103030_v8, %v103029_v45 (stack47)
        %v103455_v50 = vshrl.u32 %v103449_v55, 17 (stack46)
        %v151536_v27 = vadd.s32 %v157711_v53, %v157091_v37 (stack40)
        %120283 = vst [vmem:[%s123356_s30 + $0x3e8] sm:$0xf] /*vst_source=*/%v101048_v21 (stack83)
        %v120290_v34 = vadd.low.f32.bf16 -1.0, %v101823_v41 (stack53)
        %v102217_v9 = vadd.s32 %v102214_v61, %v102209_v60 (stack40)
        %v102223_v24 = vshll.u32 %v102214_v61, 24 (stack45)
        %v102224_v25 = vshrl.u32 %v102214_v61, 8 (stack46)
        %v121300_v43 = vpop.eup %121299 (stack73)
        %v102618_v55 = vadd.s32 %v102615_v26, %v102610_v32 (stack40)
        %v102620_v7 = vshll.u32 %v102615_v26, 15 (stack45)
        %v102621_v60 = vshrl.u32 %v102615_v26, 17 (stack46)
        %v103032_v23 = vxor.u32 %v103031_v46, %v103027_v56 (stack48)
        %v101452_v42 = vmul.f32 %v121300_v43, %v151508_v6 (stack74)
        %v101456_v30 = vand.u32 2147483648, %v151508_v6 (stack72)
        %v101832_v32 = vmul.f32 2.0, %v120290_v34 (stack54)
        %v102225_v40 = vor.u32 %v102224_v25, %v102223_v24 (stack47)
        %v102622_v10 = vor.u32 %v102621_v60, %v102620_v7 (stack47)
        %v103035_v31 = vadd.s32 %v103032_v23, %v103027_v56 (stack40)
        %v103037_v44 = vshll.u32 %v103032_v23, 29 (stack45)
        %v103038_v29 = vshrl.u32 %v103032_v23, 3 (stack46)
        %v101454_v56 = vsel /*vm=*/%vm101453_vm5, /*on_true_vy=*/%v151508_v6, /*on_false_vx=*/%v101452_v42 (stack75)
        %v101836_v54 = vadd.f32 -0.99609375, %v101832_v32 (stack53)
        %v102226_v45 = vxor.u32 %v102225_v40, %v102217_v9 (stack48)
        %v103456_v8 = vor.u32 %v103455_v50, %v103454_v22 (stack47)
        %v101449_v21 = vadd.f32 -2.5, %v151508_v6 (stack53)
        %v101457_v41 = vsel /*vm=*/%vm101455_vm6, /*on_true_vy=*/%v101456_v30, /*on_false_vx=*/%v101454_v56 (stack76)
        %v102623_v61 = vxor.u32 %v102622_v10, %v102618_v55 (stack48)
        %v103039_v22 = vor.u32 %v103038_v29, %v103037_v44 (stack47)
        %v101460_v26 = vadd.f32 -3.0, %v101457_v41 (stack53)
        %v151547_v46 = vmax.f32 %v101836_v54, -0.99609375 (stack55)
        %v102229_v50 = vadd.s32 %v102226_v45, %v121564_v0 (stack40)
        %v103457_v34 = vxor.u32 %v103456_v8, %v151531_v12 (stack48)
        %v102626_v24 = vadd.s32 %v102623_v61, %v102618_v55 (stack40)
        %v102628_v25 = vshll.u32 %v102623_v61, 26 (stack45)
        %v102629_v43 = vshrl.u32 %v102623_v61, 6 (stack46)
        %v103040_v55 = vxor.u32 %v103039_v22, %v103035_v31 (stack48)
        %v101445_v7 = vsel /*vm=*/%vm101408_vm7, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v151556_v60 = vsel /*vm=*/%vm101408_vm7, /*on_true_vy=*/%v101449_v21, /*on_false_vx=*/%v101460_v26 (stack44)
        %v101852_v23 = vxor.u32 2147483648, %v151547_v46 (stack56)
        %v102221_v9 = vadd.s32 %v102217_v9, %v121569_v1 (stack40)
        %v101468_v42 = vmul.f32 %v151556_v60, %v101445_v7 (stack54)
        %v102233_v30 = vadd.s32 4, %v102229_v50 (stack40)
        %v102630_v32 = vor.u32 %v102629_v43, %v102628_v25 (stack47)
        %v103043_v40 = vadd.s32 %v103040_v55, %v103035_v31 (stack40)
        %v101441_v10 = vsel /*vm=*/%vm101408_vm7, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v151565_v31 = vmul.f32 %v101852_v23, %v151547_v46 (stack54)
        %v103045_v44 = vshll.u32 %v103040_v55, 16 (stack45)
        %v103046_v29 = vshrl.u32 %v103040_v55, 16 (stack46)
        %v101472_v56 = vadd.f32 %v101468_v42, %v101441_v10 (stack53)
        %v102237_v54 = vadd.s32 %v102233_v30, %v102221_v9 (stack40)
        %v102239_v45 = vshll.u32 %v102233_v30, 13 (stack45)
        %v102240_v8 = vshrl.u32 %v102233_v30, 19 (stack46)
        %v101381_v21 = vand.u32 2147483647, %v151447_v52 (stack77)
        %v151571_v41 = vsel /*vm=*/%vm101408_vm7, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v101857_v61 = vadd.f32 1.0, %v151565_v31 (stack57)
        %v102631_v22 = vxor.u32 %v102630_v32, %v102626_v24 (stack48)
        %v101476_v26 = vmul.f32 %v101472_v56, %v151556_v60 (stack54)
        %v102241_v50 = vor.u32 %v102240_v8, %v102239_v45 (stack47)
        %v103047_v25 = vor.u32 %v103046_v29, %v103045_v44 (stack47)
        %v103460_v12 = vadd.s32 %v103457_v34, %v151531_v12 (stack40)
        %v101425_v43 = vsel /*vm=*/%vm101408_vm7, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v101437_v55 = vsel /*vm=*/%vm101408_vm7, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %121301 = vlog2.f32 %v101857_v61 (stack58)
        %v102634_v24 = vadd.s32 %v102631_v22, %v102626_v24 (stack40)
        %v101480_v7 = vadd.f32 %v101476_v26, %v101437_v55 (stack53)
        %v102242_v23 = vxor.u32 %v102241_v50, %v102237_v54 (stack48)
        %v102640_v9 = vshll.u32 %v102631_v22, 6 (stack45)
        %v102641_v42 = vshrl.u32 %v102631_v22, 26 (stack46)
        %v101433_v30 = vsel /*vm=*/%vm101408_vm7, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v101860_v32 = vmul.f32 -0.5, %v151565_v31 (stack59)
        %v103048_v10 = vxor.u32 %v103047_v25, %v103043_v40 (stack48)
        %v103462_v44 = vshll.u32 %v103457_v34, 26 (stack45)
        %v101484_v29 = vmul.f32 %v101480_v7, %v151556_v60 (stack54)
        %v102245_v56 = vadd.s32 %v102242_v23, %v102237_v54 (stack40)
        %v102247_v54 = vshll.u32 %v102242_v23, 15 (stack45)
        %v102248_v45 = vshrl.u32 %v102242_v23, 17 (stack46)
        %v102642_v8 = vor.u32 %v102641_v42, %v102640_v9 (stack47)
        %v103051_v40 = vadd.s32 %v103048_v10, %v103043_v40 (stack40)
        %v103057_v61 = vshll.u32 %v103048_v10, 24 (stack45)
        %v103058_v22 = vshrl.u32 %v103048_v10, 8 (stack46)
        %v101429_v26 = vsel /*vm=*/%vm101408_vm7, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v101488_v50 = vadd.f32 %v101484_v29, %v101433_v30 (stack53)
        %v102249_v25 = vor.u32 %v102248_v45, %v102247_v54 (stack47)
        %v103463_v34 = vshrl.u32 %v103457_v34, 6 (stack46)
        %v101863_v55 = vand.u32 2147483647, %v151565_v31 (stack60)
        %v102643_v7 = vxor.u32 %v102642_v8, %v102634_v24 (stack48)
        %v103059_v23 = vor.u32 %v103058_v22, %v103057_v61 (stack47)
        %vm103871_vm8 = vcmp.lt.u32.totalorder %v151536_v27, %v157091_v37 (stack43)
        %v101492_v9 = vmul.f32 %v101488_v50, %v151556_v60 (stack54)
        %v102250_v42 = vxor.u32 %v102249_v25, %v102245_v56 (stack48)
        %v103464_v30 = vor.u32 %v103463_v34, %v103462_v44 (stack47)
        %v151596_v10 = vadd.s32 %v157714_v20, %v157094_v36 (stack40)
        %v101861_v32 = vadd.f32 1.0, %v101860_v32 (stack61)
        %v102646_v44 = vadd.s32 %v102643_v7, %v121569_v1 (stack40)
        %v103060_v29 = vxor.u32 %v103059_v23, %v103051_v40 (stack48)
        %v151601_v53 = vadd.s32 %v157711_v53, %v157095_v13 (stack40)
        %v101496_v54 = vadd.f32 %v101492_v9, %v101429_v26 (stack53)
        %v102253_v56 = vadd.s32 %v102250_v42, %v102245_v56 (stack40)
        %v102255_v45 = vshll.u32 %v102250_v42, 26 (stack45)
        %v102256_v8 = vshrl.u32 %v102250_v42, 6 (stack46)
        %v102638_v24 = vadd.s32 %v102634_v24, %v121574_v2 (stack40)
        %v102650_v61 = vadd.s32 3, %v102646_v44 (stack40)
        %v103063_v22 = vadd.s32 %v103060_v29, %v121574_v2 (stack40)
        %v151605_v26 = vxor.u32 %v103464_v30, %v103460_v12 (stack48)
        %v101500_v50 = vmul.f32 %v101496_v54, %v151556_v60 (stack54)
        %v102257_v25 = vor.u32 %v102256_v8, %v102255_v45 (stack47)
        %v103055_v40 = vadd.s32 %v103051_v40, %v121564_v0 (stack40)
        %v151611_v34 = vadd.s32 %v151536_v27, %v122657_v58 (stack40)
        %v102654_v7 = vadd.s32 %v102650_v61, %v102638_v24 (stack40)
        %v102656_v23 = vshll.u32 %v102650_v61, 17 (stack45)
        %v102657_v9 = vshrl.u32 %v102650_v61, 15 (stack46)
        %v103067_v42 = vadd.s32 2, %v103063_v22 (stack40)
        %v121302_v30 = vpop.eup %121301 (stack64)
        %v101504_v43 = vadd.f32 %v101500_v50, %v101425_v43 (stack53)
        %vm151613_vm9 = vcmp.lt.f32.partialorder %v101863_v55, 0.0004427343 (stack62)
        %v102258_v44 = vxor.u32 %v102257_v25, %v102253_v56 (stack48)
        %v151618_v12 = vadd.s32 %v151605_v26, %v103460_v12 (stack40)
        %v101859_v29 = vmul.f32 0.6931472, %v121302_v30 (stack65)
        %v101862_v31 = vmul.f32 %v101861_v32, %v151565_v31 (stack63)
        %v102658_v32 = vor.u32 %v102657_v9, %v102656_v23 (stack47)
        %v103071_v54 = vadd.s32 %v103067_v42, %v103055_v40 (stack40)
        %v101508_v45 = vmul.f32 %v101504_v43, %v151556_v60 (stack54)
        %v102261_v56 = vadd.s32 %v102258_v44, %v102253_v56 (stack40)
        %v102267_v8 = vshll.u32 %v102258_v44, 6 (stack45)
        %v102268_v24 = vshrl.u32 %v102258_v44, 26 (stack46)
        %v101865_v61 = vsel /*vm=*/%vm151613_vm9, /*on_true_vy=*/%v101862_v31, /*on_false_vx=*/%v101859_v29 (stack66)
        %v102659_v22 = vxor.u32 %v102658_v32, %v102654_v7 (stack48)
        %v103073_v50 = vshll.u32 %v103067_v42, 13 (stack45)
        %v103074_v25 = vshrl.u32 %v103067_v42, 19 (stack46)
        %v101512_v41 = vadd.f32 %v101508_v45, %v151571_v41 (stack53)
        %v151625_v40 = vxor.u32 2147483648, %v101865_v61 (stack56)
        %v102269_v23 = vor.u32 %v102268_v24, %v102267_v8 (stack47)
        %v151629_v9 = vadd.s32 %v151611_v34, %v121569_v1 (stack40)
        %v101389_v42 = vmul.f32 inf, %v151447_v52 (stack54)
        %v101413_v30 = vsel /*vm=*/%vm101408_vm7, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v101417_v6 = vsel /*vm=*/%vm101408_vm7, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v102662_v7 = vadd.s32 %v102659_v22, %v102654_v7 (stack40)
        %v101516_v43 = vmul.f32 %v101512_v41, %v151556_v60 (stack54)
        %v101842_v55 = vand.u32 2147483647, %v151547_v46 (stack77)
        %121303 = vrsqrt.f32 %v151625_v40 (stack67)
        %v102664_v44 = vshll.u32 %v102659_v22, 29 (stack45)
        %vm151643_vm10 = vcmp.eq.f32.partialorder %v101381_v21, 1.0 (stack68)
        %vm101869_vm11 = vcmp.lt.f32.partialorder %v151625_v40, 5.0 (stack68)
        %v102270_v29 = vxor.u32 %v102269_v23, %v102261_v56 (stack48)
        %v102665_v31 = vshrl.u32 %v102659_v22, 3 (stack46)
        %v103075_v32 = vor.u32 %v103074_v25, %v103073_v50 (stack47)
        %v101520_v45 = vadd.f32 %v101516_v43, %v101417_v6 (stack53)
        %vm103866_vm12 = vcmp.lt.u32.totalorder %v151611_v34, %v151536_v27 (stack43)
        %v103880_v8 = vadd.s32 1, %v151596_v10 (stack40)
        %v103907_v24 = vshll.u32 %v151629_v9, 13 (stack45)
        %v102273_v61 = vadd.s32 %v102270_v29, %v121574_v2 (stack40)
        %v151655_v22 = vadd.s32 %v151618_v12, %v121569_v1 (stack40)
        %v103474_v50 = vshll.u32 %v151605_v26, 6 (stack45)
        %v103908_v25 = vshrl.u32 %v151629_v9, 19 (stack46)
        %v101524_v60 = vmul.f32 %v101520_v45, %v151556_v60 (stack54)
        %v151663_v41 = vsel /*vm=*/%vm101869_vm11, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v151666_v23 = vadd.f32 -2.5, %v151625_v40 (stack53)
        %v102265_v56 = vadd.s32 %v102261_v56, %v121564_v0 (stack40)
        %v102277_v6 = vadd.s32 5, %v102273_v61 (stack40)
        %v102666_v43 = vor.u32 %v102665_v31, %v102664_v44 (stack47)
        %v103076_v44 = vxor.u32 %v103075_v32, %v103071_v54 (stack48)
        %v103475_v26 = vshrl.u32 %v151605_v26, 26 (stack46)
        %v101528_v30 = vadd.f32 %v101524_v60, %v101413_v30 (stack53)
        %v151673_v29 = vsel /*vm=*/%vm101869_vm11, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v101917_v31 = vand.u32 2147483648, %v151625_v40 (stack72)
        %v103884_v10 = vsel /*vm=*/%vm103871_vm8, /*on_true_vy=*/%v103880_v8, /*on_false_vx=*/%v151596_v10 (stack44)
        %vm101914_vm13 = vcmp.eq.f32.partialorder %v151625_v40, inf (stack70)
        %v102279_v32 = vxor.u32 %v102277_v6, %v102265_v56 (stack48)
        %v102667_v45 = vxor.u32 %v102666_v43, %v102662_v7 (stack48)
        %v103079_v54 = vadd.s32 %v103076_v44, %v103071_v54 (stack40)
        %v103081_v8 = vshll.u32 %v103076_v44, 15 (stack45)
        %v101532_v52 = vmul.f32 %v101528_v30, %v151447_v52 (stack54)
        %vm101916_vm14 = vcmp.eq.f32.partialorder %v151625_v40, 0.0 (stack71)
        %v103082_v61 = vshrl.u32 %v103076_v44, 17 (stack46)
        %v103476_v50 = vor.u32 %v103475_v26, %v103474_v50 (stack47)
        %v103888_v60 = vadd.s32 1, %v103884_v10 (stack40)
        %v102280_v56 = vand.u32.u8 255, %v102279_v32 (stack49)
        %v102670_v7 = vadd.s32 %v102667_v45, %v102662_v7 (stack40)
        %v102672_v6 = vshll.u32 %v102667_v45, 16 (stack45)
        %v102673_v43 = vshrl.u32 %v102667_v45, 16 (stack46)
        %v101536_v42 = vsel /*vm=*/%vm151643_vm10, /*on_true_vy=*/%v101389_v42, /*on_false_vx=*/%v101532_v52 (stack44)
        %v103083_v21 = vor.u32 %v103082_v61, %v103081_v8 (stack47)
        %v103477_v12 = vxor.u32 %v103476_v50, %v151618_v12 (stack48)
        %v103892_v27 = vsel /*vm=*/%vm103866_vm12, /*on_true_vy=*/%v103888_v60, /*on_false_vx=*/%v103884_v10 (stack44)
        %v101540_v34 = vmul.f32 1.4140625, %v101536_v42 (stack54)
        %v102281_v44 = vand.u32 65535, %v102280_v56 (stack50)
        %v102674_v26 = vor.u32 %v102673_v43, %v102672_v6 (stack47)
        %v103897_v30 = vadd.s32 %v103892_v27, %v121574_v2 (stack40)
        %v103084_v10 = vxor.u32 %v103083_v21, %v103079_v54 (stack48)
        %v103480_v32 = vadd.s32 %v103477_v12, %v121564_v0 (stack40)
        %v103909_v24 = vor.u32 %v103908_v25, %v103907_v24 (stack47)
        %vm104332_vm15 = vcmp.lt.u32.totalorder %v151601_v53, %v157095_v13 (stack43)
        %v121304_v25 = vpop.eup %121303 (stack73)
        %v101543_v45 = vpack.c.bf16 %v157387_v11, %v101540_v34 (stack81)
        %v102282_v8 = vshrl.u32 %v102281_v44, 1 (stack51)
        %v102675_v52 = vxor.u32 %v102674_v26, %v102670_v7 (stack48)
        %v103905_v9 = vadd.s32 %v151629_v9, %v103897_v30 (stack40)
        %v101913_v61 = vmul.f32 %v121304_v25, %v151625_v40 (stack74)
        %v103087_v54 = vadd.s32 %v103084_v10, %v103079_v54 (stack40)
        %v103089_v50 = vshll.u32 %v103084_v10, 26 (stack45)
        %v103090_v60 = vshrl.u32 %v103084_v10, 6 (stack46)
        %120289 = vst [vmem:[%s123356_s30 + $0x6c] sm:$0xf] /*vst_source=*/%v101543_v45 (stack83)
        %v102283_v56 = vor.u32 16256, %v102282_v8 (stack47)
        %v102678_v7 = vadd.s32 %v102675_v52, %v102670_v7 (stack40)
        %v102684_v6 = vshll.u32 %v102675_v52, 24 (stack45)
        %v102685_v43 = vshrl.u32 %v102675_v52, 8 (stack46)
        %v101915_v42 = vsel /*vm=*/%vm101914_vm13, /*on_true_vy=*/%v151625_v40, /*on_false_vx=*/%v101913_v61 (stack75)
        %v103091_v21 = vor.u32 %v103090_v60, %v103089_v50 (stack47)
        %v103484_v12 = vadd.s32 1, %v103480_v32 (stack40)
        %v103910_v27 = vxor.u32 %v103909_v24, %v103905_v9 (stack48)
        %v101906_v34 = vsel /*vm=*/%vm101869_vm11, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v101918_v31 = vsel /*vm=*/%vm101916_vm14, /*on_true_vy=*/%v101917_v31, /*on_false_vx=*/%v101915_v42 (stack76)
        %v102284_v44 = vand.u32.u16 65535, %v102283_v56 (stack52)
        %v102686_v26 = vor.u32 %v102685_v43, %v102684_v6 (stack47)
        %v101921_v30 = vadd.f32 -3.0, %v101918_v31 (stack53)
        %v103092_v10 = vxor.u32 %v103091_v21, %v103087_v54 (stack48)
        %v103488_v22 = vadd.s32 %v103484_v12, %v151655_v22 (stack40)
        %v103490_v32 = vshll.u32 %v103484_v12, 17 (stack45)
        %v120292_v24 = vadd.low.f32.bf16 -1.0, %v102284_v44 (stack53)
        %v102687_v25 = vxor.u32 %v102686_v26, %v102678_v7 (stack48)
        %v103491_v45 = vshrl.u32 %v103484_v12, 15 (stack46)
        %v103913_v8 = vadd.s32 %v103910_v27, %v103905_v9 (stack40)
        %v151709_v23 = vsel /*vm=*/%vm101869_vm11, /*on_true_vy=*/%v151666_v23, /*on_false_vx=*/%v101921_v30 (stack44)
        %v103095_v52 = vadd.s32 %v103092_v10, %v103087_v54 (stack40)
        %v103101_v9 = vshll.u32 %v103092_v10, 6 (stack45)
        %v103102_v61 = vshrl.u32 %v103092_v10, 26 (stack46)
        %v101929_v54 = vmul.f32 %v151709_v23, %v101906_v34 (stack54)
        %v102293_v50 = vmul.f32 2.0, %v120292_v24 (stack54)
        %v102690_v60 = vadd.s32 %v102687_v25, %v121564_v0 (stack40)
        %v103492_v56 = vor.u32 %v103491_v45, %v103490_v32 (stack47)
        %v102682_v7 = vadd.s32 %v102678_v7, %v121569_v1 (stack40)
        %v103103_v6 = vor.u32 %v103102_v61, %v103101_v9 (stack47)
        %v103915_v43 = vshll.u32 %v103910_v27, 15 (stack45)
        %v103916_v42 = vshrl.u32 %v103910_v27, 17 (stack46)
        %v101933_v29 = vadd.f32 %v101929_v54, %v151673_v29 (stack53)
        %v102297_v21 = vadd.f32 -0.99609375, %v102293_v50 (stack53)
        %v102694_v12 = vadd.s32 4, %v102690_v60 (stack40)
        %v103493_v27 = vxor.u32 %v103492_v56, %v103488_v22 (stack48)
        %v151718_v34 = vsel /*vm=*/%vm101869_vm11, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v103104_v31 = vxor.u32 %v103103_v6, %v103095_v52 (stack48)
        %v103917_v44 = vor.u32 %v103916_v42, %v103915_v43 (stack47)
        %v104337_v20 = vadd.s32 %v157714_v20, %v157100_v14 (stack40)
        %v101937_v26 = vmul.f32 %v101933_v29, %v151709_v23 (stack54)
        %v151723_v30 = vmax.f32 %v102297_v21, -0.99609375 (stack55)
        %v102698_v10 = vadd.s32 %v102694_v12, %v102682_v7 (stack40)
        %v102700_v32 = vshll.u32 %v102694_v12, 13 (stack45)
        %v101898_v24 = vsel /*vm=*/%vm101869_vm11, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v102701_v25 = vshrl.u32 %v102694_v12, 19 (stack46)
        %v103107_v45 = vadd.s32 %v103104_v31, %v121569_v1 (stack40)
        %v103496_v22 = vadd.s32 %v103493_v27, %v103488_v22 (stack40)
        %v101886_v9 = vsel /*vm=*/%vm101869_vm11, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v101894_v61 = vsel /*vm=*/%vm101869_vm11, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v101941_v54 = vadd.f32 %v101937_v26, %v101898_v24 (stack53)
        %v102313_v50 = vxor.u32 2147483648, %v151723_v30 (stack56)
        %v102702_v60 = vor.u32 %v102701_v25, %v102700_v32 (stack47)
        %v103099_v52 = vadd.s32 %v103095_v52, %v121574_v2 (stack40)
        %v103111_v56 = vadd.s32 3, %v103107_v45 (stack40)
        %v103918_v7 = vxor.u32 %v103917_v44, %v103913_v8 (stack48)
        %v101945_v6 = vmul.f32 %v101941_v54, %v151709_v23 (stack54)
        %v151739_v43 = vmul.f32 %v102313_v50, %v151723_v30 (stack54)
        %v103498_v42 = vshll.u32 %v103493_v27, 29 (stack45)
        %v103499_v29 = vshrl.u32 %v103493_v27, 3 (stack46)
        %v102703_v21 = vxor.u32 %v102702_v60, %v102698_v10 (stack48)
        %v103115_v12 = vadd.s32 %v103111_v56, %v103099_v52 (stack40)
        %v103117_v27 = vshll.u32 %v103111_v56, 17 (stack45)
        %v103118_v31 = vshrl.u32 %v103111_v56, 15 (stack46)
        %v101890_v44 = vsel /*vm=*/%vm101869_vm11, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v101949_v26 = vadd.f32 %v101945_v6, %v101894_v61 (stack53)
        %v102318_v32 = vadd.f32 1.0, %v151739_v43 (stack57)
        %v151747_v24 = vadd.s32 %v151601_v53, %v122657_v58 (stack40)
        %v102706_v10 = vadd.s32 %v102703_v21, %v102698_v10 (stack40)
        %v102708_v25 = vshll.u32 %v102703_v21, 15 (stack45)
        %v102709_v45 = vshrl.u32 %v102703_v21, 17 (stack46)
        %v103119_v61 = vor.u32 %v103118_v31, %v103117_v27 (stack47)
        %v101953_v54 = vmul.f32 %v101949_v26, %v151709_v23 (stack54)
        %121305 = vlog2.f32 %v102318_v32 (stack58)
        %v102321_v50 = vmul.f32 -0.5, %v151739_v43 (stack59)
        %v104341_v60 = vadd.s32 1, %v104337_v20 (stack40)
        %v102710_v52 = vor.u32 %v102709_v45, %v102708_v25 (stack47)
        %v103120_v56 = vxor.u32 %v103119_v61, %v103115_v12 (stack48)
        %v103500_v6 = vor.u32 %v103499_v29, %v103498_v42 (stack47)
        %v103921_v8 = vadd.s32 %v103918_v7, %v103913_v8 (stack40)
        %v101957_v42 = vadd.f32 %v101953_v54, %v101890_v44 (stack53)
        %v102324_v29 = vand.u32 2147483647, %v151739_v43 (stack60)
        %v103923_v21 = vshll.u32 %v103918_v7, 26 (stack45)
        %v103924_v7 = vshrl.u32 %v103918_v7, 6 (stack46)
        %v102711_v27 = vxor.u32 %v102710_v52, %v102706_v10 (stack48)
        %v103123_v12 = vadd.s32 %v103120_v56, %v103115_v12 (stack40)
        %v103125_v31 = vshll.u32 %v103120_v56, 29 (stack45)
        %v103126_v44 = vshrl.u32 %v103120_v56, 3 (stack46)
        %v101961_v26 = vmul.f32 %v101957_v42, %v151709_v23 (stack54)
        %v103501_v32 = vxor.u32 %v103500_v6, %v103496_v22 (stack48)
        %v103925_v25 = vor.u32 %v103924_v7, %v103923_v21 (stack47)
        %v104345_v20 = vsel /*vm=*/%vm104332_vm15, /*on_true_vy=*/%v104341_v60, /*on_false_vx=*/%v104337_v20 (stack44)
        %v102714_v10 = vadd.s32 %v102711_v27, %v102706_v10 (stack40)
        %v102716_v45 = vshll.u32 %v102711_v27, 26 (stack45)
        %v102717_v61 = vshrl.u32 %v102711_v27, 6 (stack46)
        %v103127_v54 = vor.u32 %v103126_v44, %v103125_v31 (stack47)
        %v101965_v9 = vadd.f32 %v101961_v26, %v101886_v9 (stack53)
        %v103504_v22 = vadd.s32 %v103501_v32, %v103496_v22 (stack40)
        %v103506_v60 = vshll.u32 %v103501_v32, 16 (stack45)
        %v103507_v52 = vshrl.u32 %v103501_v32, 16 (stack46)
        %v102718_v56 = vor.u32 %v102717_v61, %v102716_v45 (stack47)
        %v103128_v6 = vxor.u32 %v103127_v54, %v103123_v12 (stack48)
        %v103926_v42 = vxor.u32 %v103925_v25, %v103921_v8 (stack48)
        %vm104327_vm0 = vcmp.lt.u32.totalorder %v151747_v24, %v151601_v53 (stack43)
        %v101969_v21 = vmul.f32 %v101965_v9, %v151709_v23 (stack54)
        %v102322_v50 = vadd.f32 1.0, %v102321_v50 (stack61)
        %v103508_v7 = vor.u32 %v103507_v52, %v103506_v60 (stack47)
        %v151761_v27 = vadd.s32 %v151747_v24, %v121569_v1 (stack40)
        %v102719_v31 = vxor.u32 %v102718_v56, %v102714_v10 (stack48)
        %v103131_v12 = vadd.s32 %v103128_v6, %v103123_v12 (stack40)
        %v103133_v44 = vshll.u32 %v103128_v6, 16 (stack45)
        %v103134_v26 = vshrl.u32 %v103128_v6, 16 (stack46)
        %v101973_v34 = vadd.f32 %v101969_v21, %v151718_v34 (stack53)
        %vm151764_vm1 = vcmp.lt.f32.partialorder %v102324_v29, 0.0004427343 (stack62)
        %v103509_v32 = vxor.u32 %v103508_v7, %v103504_v22 (stack48)
        %v151768_v8 = vadd.s32 %v103926_v42, %v103921_v8 (stack40)
        %v102722_v25 = vadd.s32 %v102719_v31, %v102714_v10 (stack40)
        %v102728_v10 = vshll.u32 %v102719_v31, 6 (stack45)
        %v102729_v45 = vshrl.u32 %v102719_v31, 26 (stack46)
        %v103135_v61 = vor.u32 %v103134_v26, %v103133_v44 (stack47)
        %v101977_v54 = vmul.f32 %v101973_v34, %v151709_v23 (stack54)
        %v103512_v9 = vadd.s32 %v103509_v32, %v103504_v22 (stack40)
        %v103518_v22 = vshll.u32 %v103509_v32, 24 (stack45)
        %v103519_v60 = vshrl.u32 %v103509_v32, 8 (stack46)
        %v121306_v52 = vpop.eup %121305 (stack64)
        %v102323_v43 = vmul.f32 %v102322_v50, %v151739_v43 (stack63)
        %v102730_v56 = vor.u32 %v102729_v45, %v102728_v10 (stack47)
        %v103136_v6 = vxor.u32 %v103135_v61, %v103131_v12 (stack48)
        %v104349_v21 = vadd.s32 1, %v104345_v20 (stack40)
        %v101981_v41 = vadd.f32 %v101977_v54, %v151663_v41 (stack53)
        %v102320_v50 = vmul.f32 0.6931472, %v121306_v52 (stack65)
        %v103520_v7 = vor.u32 %v103519_v60, %v103518_v22 (stack47)
        %v103935_v31 = vshll.u32 %v103926_v42, 6 (stack45)
        %v102731_v44 = vxor.u32 %v102730_v56, %v102722_v25 (stack48)
        %v103139_v12 = vadd.s32 %v103136_v6, %v103131_v12 (stack40)
        %v103145_v26 = vshll.u32 %v103136_v6, 24 (stack45)
        %v103146_v34 = vshrl.u32 %v103136_v6, 8 (stack46)
        %v101985_v23 = vmul.f32 %v101981_v41, %v151709_v23 (stack54)
        %v102326_v29 = vsel /*vm=*/%vm151764_vm1, /*on_true_vy=*/%v102323_v43, /*on_false_vx=*/%v102320_v50 (stack66)
        %v103521_v32 = vxor.u32 %v103520_v7, %v103512_v9 (stack48)
        %v103936_v42 = vshrl.u32 %v103926_v42, 26 (stack46)
        %v101874_v40 = vsel /*vm=*/%vm101869_vm11, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v151779_v10 = vxor.u32 2147483648, %v102326_v29 (stack56)
        %v103147_v45 = vor.u32 %v103146_v34, %v103145_v26 (stack47)
        %vm151783_vm2 = vcmp.eq.f32.partialorder %v101842_v55, 1.0 (stack68)
        %v101850_v61 = vmul.f32 inf, %v151547_v46 (stack54)
        %v101989_v54 = vadd.f32 %v101985_v23, %v101874_v40 (stack53)
        %v104353_v53 = vsel /*vm=*/%vm104327_vm0, /*on_true_vy=*/%v104349_v21, /*on_false_vx=*/%v104345_v20 (stack44)
        %v102303_v24 = vand.u32 2147483647, %v151723_v30 (stack77)
        %121307 = vrsqrt.f32 %v151779_v10 (stack67)
        %v102734_v20 = vadd.s32 %v102731_v44, %v121574_v2 (stack40)
        %v104368_v22 = vshll.u32 %v151761_v27, 13 (stack45)
        %v101993_v46 = vmul.f32 %v101989_v54, %v151547_v46 (stack54)
        %vm102330_vm3 = vcmp.lt.f32.partialorder %v151779_v10, 5.0 (stack68)
        %v103524_v60 = vadd.s32 %v103521_v32, %v121574_v2 (stack40)
        %v103937_v52 = vor.u32 %v103936_v42, %v103935_v31 (stack47)
        %v102726_v25 = vadd.s32 %v102722_v25, %v121564_v0 (stack40)
        %v103148_v43 = vxor.u32 %v103147_v45, %v103139_v12 (stack48)
        %v103933_v56 = vadd.s32 %v151768_v8, %v121569_v1 (stack40)
        %v104369_v6 = vshrl.u32 %v151761_v27, 19 (stack46)
        %v101997_v21 = vsel /*vm=*/%vm151783_vm2, /*on_true_vy=*/%v101850_v61, /*on_false_vx=*/%v101993_v46 (stack44)
        %v151805_v41 = vadd.f32 -2.5, %v151779_v10 (stack53)
        %v103143_v50 = vadd.s32 %v103139_v12, %v121569_v1 (stack40)
        %v103516_v9 = vadd.s32 %v103512_v9, %v121564_v0 (stack40)
        %v102001_v7 = vmul.f32 1.4140625, %v101997_v21 (stack54)
        %v151812_v31 = vsel /*vm=*/%vm102330_vm3, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v151817_v44 = vsel /*vm=*/%vm102330_vm3, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v102738_v12 = vadd.s32 5, %v102734_v20 (stack40)
        %v103151_v26 = vadd.s32 %v103148_v43, %v121564_v0 (stack40)
        %v103528_v34 = vadd.s32 2, %v103524_v60 (stack40)
        %v103938_v8 = vxor.u32 %v103937_v52, %v151768_v8 (stack48)
        %v104358_v23 = vadd.s32 %v104353_v53, %v121574_v2 (stack40)
        %v102004_v29 = vpack.c.bf16 %v157387_v11, %v102001_v7 (stack81)
        %v102740_v32 = vxor.u32 %v102738_v12, %v102726_v25 (stack48)
        %v104370_v42 = vor.u32 %v104369_v6, %v104368_v22 (stack47)
        %v157741_v40 = vld [vmem:[#allocation152_spill] sm:$0xff] (stack84)
        %v151825_v45 = vadd.s32 %v157741_v40, %v122651_v47 (stack40)
        %vm102375_vm4 = vcmp.eq.f32.partialorder %v151779_v10, inf (stack70)
        %v103155_v55 = vadd.s32 4, %v103151_v26 (stack40)
        %v103532_v61 = vadd.s32 %v103528_v34, %v103516_v9 (stack40)
        %v103534_v54 = vshll.u32 %v103528_v34, 13 (stack45)
        %v103535_v53 = vshrl.u32 %v103528_v34, 19 (stack46)
        %120291 = vst [vmem:[%s123356_s30 + $0xec] sm:$0xf] /*vst_source=*/%v102004_v29 (stack83)
        %vm102377_vm5 = vcmp.eq.f32.partialorder %v151779_v10, 0.0 (stack71)
        %v102741_v20 = vand.u32.u8 255, %v102740_v32 (stack49)
        %v103941_v22 = vadd.s32 %v103938_v8, %v121564_v0 (stack40)
        %v104366_v27 = vadd.s32 %v151761_v27, %v104358_v23 (stack40)
        %v103159_v46 = vadd.s32 %v103155_v55, %v103143_v50 (stack40)
        %v103161_v60 = vshll.u32 %v103155_v55, 13 (stack45)
        %v103162_v52 = vshrl.u32 %v103155_v55, 19 (stack46)
        %v103536_v25 = vor.u32 %v103535_v53, %v103534_v54 (stack47)
        %v102378_v43 = vand.u32 2147483648, %v151779_v10 (stack72)
        %v102742_v6 = vand.u32 65535, %v102741_v20 (stack50)
        %v103945_v21 = vadd.s32 1, %v103941_v22 (stack40)
        %v104371_v50 = vxor.u32 %v104370_v42, %v104366_v27 (stack48)
        %v103163_v9 = vor.u32 %v103162_v52, %v103161_v60 (stack47)
        %v103537_v7 = vxor.u32 %v103536_v25, %v103532_v61 (stack48)
        %vm104827_vm6 = vcmp.lt.u32.totalorder %v151825_v45, %v122651_v47 (stack43)
        %v157742_v12 = vld [vmem:[#allocation114_spill] sm:$0xff] (stack84)
        %v151837_v26 = vadd.s32 %v157742_v12, %v157068_v28 (stack40)
        %v102743_v34 = vshrl.u32 %v102742_v6, 1 (stack51)
        %v103949_v56 = vadd.s32 %v103945_v21, %v103933_v56 (stack40)
        %v103951_v8 = vshll.u32 %v103945_v21, 17 (stack45)
        %v103952_v23 = vshrl.u32 %v103945_v21, 15 (stack46)
        %v121308_v29 = vpop.eup %121307 (stack73)
        %v103164_v32 = vxor.u32 %v103163_v9, %v103159_v46 (stack48)
        %v103540_v42 = vadd.s32 %v103537_v7, %v103532_v61 (stack40)
        %v103542_v55 = vshll.u32 %v103537_v7, 15 (stack45)
        %v103543_v61 = vshrl.u32 %v103537_v7, 17 (stack46)
        %v102374_v54 = vmul.f32 %v121308_v29, %v151779_v10 (stack74)
        %v102744_v53 = vor.u32 16256, %v102743_v34 (stack47)
        %v103953_v20 = vor.u32 %v103952_v23, %v103951_v8 (stack47)
        %v104374_v22 = vadd.s32 %v104371_v50, %v104366_v27 (stack40)
        %v103167_v27 = vadd.s32 %v103164_v32, %v103159_v46 (stack40)
        %v103169_v46 = vshll.u32 %v103164_v32, 15 (stack45)
        %v103170_v60 = vshrl.u32 %v103164_v32, 17 (stack46)
        %v103544_v52 = vor.u32 %v103543_v61, %v103542_v55 (stack47)
        %v102376_v25 = vsel /*vm=*/%vm102375_vm4, /*on_true_vy=*/%v151779_v10, /*on_false_vx=*/%v102374_v54 (stack75)
        %v102745_v6 = vand.u32.u16 65535, %v102744_v53 (stack52)
        %v103954_v21 = vxor.u32 %v103953_v20, %v103949_v56 (stack48)
        %v104376_v9 = vshll.u32 %v104371_v50, 15 (stack45)
        %v102379_v43 = vsel /*vm=*/%vm102377_vm5, /*on_true_vy=*/%v102378_v43, /*on_false_vx=*/%v102376_v25 (stack76)
        %v103171_v7 = vor.u32 %v103170_v60, %v103169_v46 (stack47)
        %v103545_v34 = vxor.u32 %v103544_v52, %v103540_v42 (stack48)
        %v104377_v50 = vshrl.u32 %v104371_v50, 17 (stack46)
        %v102382_v8 = vadd.f32 -3.0, %v102379_v43 (stack53)
        %v120294_v23 = vadd.low.f32.bf16 -1.0, %v102745_v6 (stack53)
        %v103957_v56 = vadd.s32 %v103954_v21, %v103949_v56 (stack40)
        %v103959_v29 = vshll.u32 %v103954_v21, 29 (stack45)
        %v103172_v32 = vxor.u32 %v103171_v7, %v103167_v27 (stack48)
        %v103548_v42 = vadd.s32 %v103545_v34, %v103540_v42 (stack40)
        %v103550_v55 = vshll.u32 %v103545_v34, 26 (stack45)
        %v103551_v61 = vshrl.u32 %v103545_v34, 6 (stack46)
        %v151848_v41 = vsel /*vm=*/%vm102330_vm3, /*on_true_vy=*/%v151805_v41, /*on_false_vx=*/%v102382_v8 (stack44)
        %v102754_v54 = vmul.f32 2.0, %v120294_v23 (stack54)
        %v103960_v53 = vshrl.u32 %v103954_v21, 3 (stack46)
        %v104378_v20 = vor.u32 %v104377_v50, %v104376_v9 (stack47)
        %v102390_v44 = vmul.f32 %v151848_v41, %v151817_v44 (stack54)
        %v103175_v27 = vadd.s32 %v103172_v32, %v103167_v27 (stack40)
        %v103177_v46 = vshll.u32 %v103172_v32, 26 (stack45)
        %v103178_v60 = vshrl.u32 %v103172_v32, 6 (stack46)
        %v102758_v52 = vadd.f32 -0.99609375, %v102754_v54 (stack53)
        %v103552_v25 = vor.u32 %v103551_v61, %v103550_v55 (stack47)
        %v103961_v6 = vor.u32 %v103960_v53, %v103959_v29 (stack47)
        %v104379_v21 = vxor.u32 %v104378_v20, %v104374_v22 (stack48)
        %v151855_v9 = vsel /*vm=*/%vm102330_vm3, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v151860_v43 = vsel /*vm=*/%vm102330_vm3, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v102394_v31 = vadd.f32 %v102390_v44, %v151812_v31 (stack53)
        %v103179_v7 = vor.u32 %v103178_v60, %v103177_v46 (stack47)
        %v151863_v34 = vmax.f32 %v102758_v52, -0.99609375 (stack55)
        %v103553_v50 = vxor.u32 %v103552_v25, %v103548_v42 (stack48)
        %v103962_v8 = vxor.u32 %v103961_v6, %v103957_v56 (stack48)
        %v104382_v22 = vadd.s32 %v104379_v21, %v104374_v22 (stack40)
        %v102351_v23 = vsel /*vm=*/%vm102330_vm3, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v102355_v29 = vsel /*vm=*/%vm102330_vm3, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v102398_v32 = vmul.f32 %v102394_v31, %v151848_v41 (stack54)
        %v103180_v55 = vxor.u32 %v103179_v7, %v103175_v27 (stack48)
        %v102359_v61 = vsel /*vm=*/%vm102330_vm3, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v102774_v54 = vxor.u32 2147483648, %v151863_v34 (stack56)
        %v103556_v42 = vadd.s32 %v103553_v50, %v103548_v42 (stack40)
        %v151878_v53 = vadd.s32 %v151825_v45, %v122657_v58 (stack40)
        %v102402_v20 = vadd.f32 %v102398_v32, %v102359_v61 (stack53)
        %v103183_v44 = vadd.s32 %v103180_v55, %v103175_v27 (stack40)
        %v103189_v27 = vshll.u32 %v103180_v55, 6 (stack45)
        %v103190_v46 = vshrl.u32 %v103180_v55, 26 (stack46)
        %v151881_v60 = vmul.f32 %v102774_v54, %v151863_v34 (stack54)
        %v103562_v52 = vshll.u32 %v103553_v50, 6 (stack45)
        %v104384_v25 = vshll.u32 %v104379_v21, 26 (stack45)
        %v104836_v6 = vadd.s32 1, %v151837_v26 (stack40)
        %v102406_v31 = vmul.f32 %v102402_v20, %v151848_v41 (stack54)
        %v103191_v7 = vor.u32 %v103190_v46, %v103189_v27 (stack47)
        %v103563_v50 = vshrl.u32 %v103553_v50, 26 (stack46)
        %v104385_v21 = vshrl.u32 %v104379_v21, 6 (stack46)
        %v102779_v32 = vadd.f32 1.0, %v151881_v60 (stack57)
        %v103560_v55 = vadd.s32 %v103556_v42, %v121574_v2 (stack40)
        %v103965_v56 = vadd.s32 %v103962_v8, %v103957_v56 (stack40)
        %vm104822_vm7 = vcmp.lt.u32.totalorder %v151878_v53, %v151825_v45 (stack43)
        %v104857_v61 = vadd.s32 %v151878_v53, %v121569_v1 (stack40)
        %v102410_v29 = vadd.f32 %v102406_v31, %v102355_v29 (stack53)
        %v103192_v54 = vxor.u32 %v103191_v7, %v103183_v44 (stack48)
        %v103564_v20 = vor.u32 %v103563_v50, %v103562_v52 (stack47)
        %v103967_v27 = vshll.u32 %v103962_v8, 16 (stack45)
        %121309 = vlog2.f32 %v102779_v32 (stack58)
        %v102782_v46 = vmul.f32 -0.5, %v151881_v60 (stack59)
        %v103187_v44 = vadd.s32 %v103183_v44, %v121564_v0 (stack40)
        %v103968_v8 = vshrl.u32 %v103962_v8, 16 (stack46)
        %v102414_v52 = vmul.f32 %v102410_v29, %v151848_v41 (stack54)
        %v103195_v31 = vadd.s32 %v103192_v54, %v121574_v2 (stack40)
        %v103565_v42 = vxor.u32 %v103564_v20, %v103556_v42 (stack48)
        %v104386_v25 = vor.u32 %v104385_v21, %v104384_v25 (stack47)
        %v102785_v7 = vand.u32 2147483647, %v151881_v60 (stack60)
        %v103969_v50 = vor.u32 %v103968_v8, %v103967_v27 (stack47)
        %v104840_v26 = vsel /*vm=*/%vm104827_vm6, /*on_true_vy=*/%v104836_v6, /*on_false_vx=*/%v151837_v26 (stack44)
        %v104863_v6 = vshll.u32 %v104857_v61, 13 (stack45)
        %v102418_v23 = vadd.f32 %v102414_v52, %v102351_v23 (stack53)
        %v103199_v21 = vadd.s32 5, %v103195_v31 (stack40)
        %v103568_v32 = vadd.s32 %v103565_v42, %v121569_v1 (stack40)
        %v104387_v29 = vxor.u32 %v104386_v25, %v104382_v22 (stack48)
        %v103970_v54 = vxor.u32 %v103969_v50, %v103965_v56 (stack48)
        %v104844_v20 = vadd.s32 1, %v104840_v26 (stack40)
        %v104864_v27 = vshrl.u32 %v104857_v61, 19 (stack46)
        %v151903_v8 = vadd.s32 %v157741_v40, %v157070_v38 (stack40)
        %v102422_v52 = vmul.f32 %v102418_v23, %v151848_v41 (stack54)
        %v103201_v44 = vxor.u32 %v103199_v21, %v103187_v44 (stack48)
        %v103572_v31 = vadd.s32 3, %v103568_v32 (stack40)
        %v151906_v22 = vadd.s32 %v104387_v29, %v104382_v22 (stack40)
        %v103973_v56 = vadd.s32 %v103970_v54, %v103965_v56 (stack40)
        %v103979_v42 = vshll.u32 %v103970_v54, 24 (stack45)
        %v103980_v25 = vshrl.u32 %v103970_v54, 8 (stack46)
        %v104396_v50 = vshll.u32 %v104387_v29, 6 (stack45)
        %v102426_v43 = vadd.f32 %v102422_v52, %v151860_v43 (stack53)
        %v103202_v23 = vand.u32.u8 255, %v103201_v44 (stack49)
        %v103576_v55 = vadd.s32 %v103572_v31, %v103560_v55 (stack40)
        %v103578_v21 = vshll.u32 %v103572_v31, 17 (stack45)
        %v102343_v32 = vsel /*vm=*/%vm102330_vm3, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v102783_v46 = vadd.f32 1.0, %v102782_v46 (stack61)
        %v103579_v54 = vshrl.u32 %v103572_v31, 15 (stack46)
        %v103981_v52 = vor.u32 %v103980_v25, %v103979_v42 (stack47)
        %v102430_v44 = vmul.f32 %v102426_v43, %v151848_v41 (stack54)
        %v103203_v31 = vand.u32 65535, %v103202_v23 (stack50)
        %v104397_v29 = vshrl.u32 %v104387_v29, 26 (stack46)
        %v104848_v45 = vsel /*vm=*/%vm104822_vm7, /*on_true_vy=*/%v104844_v20, /*on_false_vx=*/%v104840_v26 (stack44)
        %vm151916_vm8 = vcmp.lt.f32.partialorder %v102785_v7, 0.0004427343 (stack62)
        %v103580_v7 = vor.u32 %v103579_v54, %v103578_v21 (stack47)
        %v103982_v26 = vxor.u32 %v103981_v52, %v103973_v56 (stack48)
        %v104853_v20 = vadd.s32 %v104848_v45, %v121574_v2 (stack40)
        %v102434_v42 = vadd.f32 %v102430_v44, %v102343_v32 (stack53)
        %v103204_v25 = vshrl.u32 %v103203_v31, 1 (stack51)
        %v104398_v50 = vor.u32 %v104397_v29, %v104396_v50 (stack47)
        %v104865_v6 = vor.u32 %v104864_v27, %v104863_v6 (stack47)
        %v103581_v27 = vxor.u32 %v103580_v7, %v103576_v55 (stack48)
        %v103985_v43 = vadd.s32 %v103982_v26, %v121574_v2 (stack40)
        %v104861_v61 = vadd.s32 %v104857_v61, %v104853_v20 (stack40)
        %vm105288_vm9 = vcmp.lt.u32.totalorder %v151903_v8, %v157070_v38 (stack43)
        %v121310_v23 = vpop.eup %121309 (stack64)
        %v102438_v21 = vmul.f32 %v102434_v42, %v151848_v41 (stack54)
        %v102784_v60 = vmul.f32 %v102783_v46, %v151881_v60 (stack63)
        %v103205_v32 = vor.u32 16256, %v103204_v25 (stack47)
        %v104399_v46 = vxor.u32 %v104398_v50, %v151906_v22 (stack48)
        %v102781_v54 = vmul.f32 0.6931472, %v121310_v23 (stack65)
        %v103584_v55 = vadd.s32 %v103581_v27, %v103576_v55 (stack40)
        %v103586_v52 = vshll.u32 %v103581_v27, 29 (stack45)
        %v103587_v44 = vshrl.u32 %v103581_v27, 3 (stack46)
        %v102442_v9 = vadd.f32 %v102438_v21, %v151855_v9 (stack53)
        %v103206_v31 = vand.u32.u16 65535, %v103205_v32 (stack52)
        %v103977_v56 = vadd.s32 %v103973_v56, %v121564_v0 (stack40)
        %v103989_v29 = vadd.s32 2, %v103985_v43 (stack40)
        %v102787_v45 = vsel /*vm=*/%vm151916_vm8, /*on_true_vy=*/%v102784_v60, /*on_false_vx=*/%v102781_v54 (stack66)
        %v103588_v53 = vor.u32 %v103587_v44, %v103586_v52 (stack47)
        %v151931_v7 = vxor.u32 %v104865_v6, %v104861_v61 (stack48)
        %v151935_v26 = vadd.s32 %v157742_v12, %v157076_v35 (stack40)
        %v102446_v41 = vmul.f32 %v102442_v9, %v151848_v41 (stack54)
        %v151938_v20 = vxor.u32 2147483648, %v102787_v45 (stack56)
        %v103993_v42 = vadd.s32 %v103989_v29, %v103977_v56 (stack40)
        %v104402_v25 = vadd.s32 %v104399_v46, %v121564_v0 (stack40)
        %v102335_v10 = vsel /*vm=*/%vm102330_vm3, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v103589_v50 = vxor.u32 %v103588_v53, %v103584_v55 (stack48)
        %v103995_v6 = vshll.u32 %v103989_v29, 13 (stack45)
        %v103996_v27 = vshrl.u32 %v103989_v29, 19 (stack46)
        %v102311_v43 = vmul.f32 inf, %v151723_v30 (stack54)
        %v102450_v23 = vadd.f32 %v102446_v41, %v102335_v10 (stack53)
        %vm102791_vm10 = vcmp.lt.f32.partialorder %v151938_v20, 5.0 (stack68)
        %121311 = vrsqrt.f32 %v151938_v20 (stack67)
        %vm151949_vm11 = vcmp.eq.f32.partialorder %v102303_v24, 1.0 (stack68)
        %v120296_v60 = vadd.low.f32.bf16 -1.0, %v103206_v31 (stack53)
        %v103592_v32 = vadd.s32 %v103589_v50, %v103584_v55 (stack40)
        %v102454_v30 = vmul.f32 %v102450_v23, %v151723_v30 (stack54)
        %v151956_v46 = vmul.f32 inf, %v151863_v34 (stack54)
        %v104394_v22 = vadd.s32 %v151906_v22, %v121569_v1 (stack40)
        %v104406_v54 = vadd.s32 1, %v104402_v25 (stack40)
        %v151963_v55 = vsel /*vm=*/%vm102791_vm10, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v151966_v52 = vadd.f32 -2.5, %v151938_v20 (stack53)
        %v103997_v44 = vor.u32 %v103996_v27, %v103995_v6 (stack47)
        %v151970_v9 = vadd.s32 %v151903_v8, %v122657_v58 (stack40)
        %v102458_v31 = vsel /*vm=*/%vm151949_vm11, /*on_true_vy=*/%v102311_v43, /*on_false_vx=*/%v102454_v30 (stack44)
        %v151977_v56 = vsel /*vm=*/%vm102791_vm10, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v151982_v29 = vsel /*vm=*/%vm102791_vm10, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v151987_v45 = vsel /*vm=*/%vm102791_vm10, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v102462_v53 = vmul.f32 1.4140625, %v102458_v31 (stack54)
        %v103215_v41 = vmul.f32 2.0, %v120296_v60 (stack54)
        %v103594_v25 = vshll.u32 %v103589_v50, 16 (stack45)
        %v103595_v10 = vshrl.u32 %v103589_v50, 16 (stack46)
        %v103998_v50 = vxor.u32 %v103997_v44, %v103993_v42 (stack48)
        %v104410_v6 = vadd.s32 %v104406_v54, %v104394_v22 (stack40)
        %v104412_v27 = vshll.u32 %v104406_v54, 17 (stack45)
        %v104413_v43 = vshrl.u32 %v104406_v54, 15 (stack46)
        %v102465_v23 = vpack.c.bf16 %v157387_v11, %v102462_v53 (stack81)
        %v103219_v24 = vadd.f32 -0.99609375, %v103215_v41 (stack53)
        %v103596_v60 = vor.u32 %v103595_v10, %v103594_v25 (stack47)
        %v104869_v61 = vadd.s32 %v151931_v7, %v104861_v61 (stack40)
        %v104001_v42 = vadd.s32 %v103998_v50, %v103993_v42 (stack40)
        %v104003_v30 = vshll.u32 %v103998_v50, 15 (stack45)
        %v104004_v22 = vshrl.u32 %v103998_v50, 17 (stack46)
        %v104414_v54 = vor.u32 %v104413_v43, %v104412_v27 (stack47)
        %120293 = vst [vmem:[%s123356_s30 + $0x16c] sm:$0xf] /*vst_source=*/%v102465_v23 (stack83)
        %v151995_v44 = vsel /*vm=*/%vm102791_vm10, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v152000_v31 = vsel /*vm=*/%vm102791_vm10, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v152002_v53 = vmax.f32 %v103219_v24, -0.99609375 (stack55)
        %v103597_v41 = vxor.u32 %v103596_v60, %v103592_v32 (stack48)
        %v152007_v25 = vsel /*vm=*/%vm102791_vm10, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v102824_v10 = vsel /*vm=*/%vm102791_vm10, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v104005_v50 = vor.u32 %v104004_v22, %v104003_v30 (stack47)
        %v104415_v27 = vxor.u32 %v104414_v54, %v104410_v6 (stack48)
        %v103235_v43 = vxor.u32 2147483648, %v152002_v53 (stack56)
        %v103600_v32 = vadd.s32 %v103597_v41, %v103592_v32 (stack40)
        %v104871_v23 = vshll.u32 %v151931_v7, 15 (stack45)
        %v104872_v7 = vshrl.u32 %v151931_v7, 17 (stack46)
        %v103606_v24 = vshll.u32 %v103597_v41, 24 (stack45)
        %v103607_v60 = vshrl.u32 %v103597_v41, 8 (stack46)
        %v104006_v30 = vxor.u32 %v104005_v50, %v104001_v42 (stack48)
        %v104418_v6 = vadd.s32 %v104415_v27, %v104410_v6 (stack40)
        %v121312_v22 = vpop.eup %121311 (stack73)
        %v102828_v54 = vsel /*vm=*/%vm102791_vm10, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %vm102836_vm12 = vcmp.eq.f32.partialorder %v151938_v20, inf (stack70)
        %v152020_v41 = vmul.f32 %v103235_v43, %v152002_v53 (stack54)
        %v104420_v50 = vshll.u32 %v104415_v27, 29 (stack45)
        %v102835_v43 = vmul.f32 %v121312_v22, %v151938_v20 (stack74)
        %v103608_v24 = vor.u32 %v103607_v60, %v103606_v24 (stack47)
        %v104009_v42 = vadd.s32 %v104006_v30, %v104001_v42 (stack40)
        %v104011_v60 = vshll.u32 %v104006_v30, 26 (stack45)
        %vm102838_vm13 = vcmp.eq.f32.partialorder %v151938_v20, 0.0 (stack71)
        %v102839_v22 = vand.u32 2147483648, %v151938_v20 (stack72)
        %v103240_v21 = vadd.f32 1.0, %v152020_v41 (stack57)
        %v104012_v30 = vshrl.u32 %v104006_v30, 6 (stack46)
        %v102837_v43 = vsel /*vm=*/%vm102836_vm12, /*on_true_vy=*/%v151938_v20, /*on_false_vx=*/%v102835_v43 (stack75)
        %v103609_v24 = vxor.u32 %v103608_v24, %v103600_v32 (stack48)
        %v104421_v27 = vshrl.u32 %v104415_v27, 3 (stack46)
        %v104873_v23 = vor.u32 %v104872_v7, %v104871_v23 (stack47)
        %vm105283_vm14 = vcmp.lt.u32.totalorder %v151970_v9, %v151903_v8 (stack43)
        %v102840_v7 = vsel /*vm=*/%vm102838_vm13, /*on_true_vy=*/%v102839_v22, /*on_false_vx=*/%v102837_v43 (stack76)
        %121313 = vlog2.f32 %v103240_v21 (stack58)
        %v105297_v21 = vadd.s32 1, %v151935_v26 (stack40)
        %v152032_v22 = vadd.s32 %v151970_v9, %v121569_v1 (stack40)
        %v102843_v43 = vadd.f32 -3.0, %v102840_v7 (stack53)
        %v103612_v24 = vadd.s32 %v103609_v24, %v121564_v0 (stack40)
        %v104013_v60 = vor.u32 %v104012_v30, %v104011_v60 (stack47)
        %v104422_v50 = vor.u32 %v104421_v27, %v104420_v50 (stack47)
        %v103243_v30 = vmul.f32 -0.5, %v152020_v41 (stack59)
        %v103604_v32 = vadd.s32 %v103600_v32, %v121569_v1 (stack40)
        %v104874_v27 = vxor.u32 %v104873_v23, %v104869_v61 (stack48)
        %v105301_v26 = vsel /*vm=*/%vm105288_vm9, /*on_true_vy=*/%v105297_v21, /*on_false_vx=*/%v151935_v26 (stack44)
        %v152044_v20 = vsel /*vm=*/%vm102791_vm10, /*on_true_vy=*/%v151966_v52, /*on_false_vx=*/%v102843_v43 (stack44)
        %v103616_v52 = vadd.s32 4, %v103612_v24 (stack40)
        %v104014_v23 = vxor.u32 %v104013_v60, %v104009_v42 (stack48)
        %v104423_v7 = vxor.u32 %v104422_v50, %v104418_v6 (stack48)
        %v102851_v54 = vmul.f32 %v152044_v20, %v102828_v54 (stack54)
        %v104877_v61 = vadd.s32 %v104874_v27, %v104869_v61 (stack40)
        %v104879_v21 = vshll.u32 %v104874_v27, 26 (stack45)
        %v104880_v43 = vshrl.u32 %v104874_v27, 6 (stack46)
        %v103620_v24 = vadd.s32 %v103616_v52, %v103604_v32 (stack40)
        %v103622_v60 = vshll.u32 %v103616_v52, 13 (stack45)
        %v103623_v50 = vshrl.u32 %v103616_v52, 19 (stack46)
        %v104017_v42 = vadd.s32 %v104014_v23, %v104009_v42 (stack40)
        %v102855_v10 = vadd.f32 %v102851_v54, %v102824_v10 (stack53)
        %v104023_v32 = vshll.u32 %v104014_v23, 6 (stack45)
        %v104024_v27 = vshrl.u32 %v104014_v23, 26 (stack46)
        %v104426_v6 = vadd.s32 %v104423_v7, %v104418_v6 (stack40)
        %v103244_v30 = vadd.f32 1.0, %v103243_v30 (stack61)
        %v103624_v52 = vor.u32 %v103623_v50, %v103622_v60 (stack47)
        %v104428_v23 = vshll.u32 %v104423_v7, 16 (stack45)
        %v104429_v7 = vshrl.u32 %v104423_v7, 16 (stack46)
        %v102859_v54 = vmul.f32 %v102855_v10, %v152044_v20 (stack54)
        %v104025_v60 = vor.u32 %v104024_v27, %v104023_v32 (stack47)
        %v104881_v21 = vor.u32 %v104880_v43, %v104879_v21 (stack47)
        %v105305_v43 = vadd.s32 1, %v105301_v26 (stack40)
        %v103246_v50 = vand.u32 2147483647, %v152020_v41 (stack60)
        %v103625_v10 = vxor.u32 %v103624_v52, %v103620_v24 (stack48)
        %v104430_v32 = vor.u32 %v104429_v7, %v104428_v23 (stack47)
        %v152051_v27 = vadd.s32 %v157741_v40, %v157077_v51 (stack40)
        %v102863_v25 = vadd.f32 %v102859_v54, %v152007_v25 (stack53)
        %v104026_v52 = vxor.u32 %v104025_v60, %v104017_v42 (stack48)
        %v104882_v23 = vxor.u32 %v104881_v21, %v104877_v61 (stack48)
        %v105309_v8 = vsel /*vm=*/%vm105283_vm14, /*on_true_vy=*/%v105305_v43, /*on_false_vx=*/%v105301_v26 (stack44)
        %v103628_v9 = vadd.s32 %v103625_v10, %v103620_v24 (stack40)
        %v103630_v26 = vshll.u32 %v103625_v10, 15 (stack45)
        %v103631_v24 = vshrl.u32 %v103625_v10, 17 (stack46)
        %v104431_v7 = vxor.u32 %v104430_v32, %v104426_v6 (stack48)
        %v102867_v54 = vmul.f32 %v102863_v25, %v152044_v20 (stack54)
        %v103245_v41 = vmul.f32 %v103244_v30, %v152020_v41 (stack63)
        %v104029_v30 = vadd.s32 %v104026_v52, %v121569_v1 (stack40)
        %v104885_v61 = vadd.s32 %v104882_v23, %v104877_v61 (stack40)
        %v121314_v60 = vpop.eup %121313 (stack64)
        %v103632_v21 = vor.u32 %v103631_v24, %v103630_v26 (stack47)
        %v104434_v6 = vadd.s32 %v104431_v7, %v104426_v6 (stack40)
        %v104440_v43 = vshll.u32 %v104431_v7, 24 (stack45)
        %v104441_v10 = vshrl.u32 %v104431_v7, 8 (stack46)
        %v102871_v31 = vadd.f32 %v102867_v54, %v152000_v31 (stack53)
        %v103242_v32 = vmul.f32 0.6931472, %v121314_v60 (stack65)
        %v104021_v42 = vadd.s32 %v104017_v42, %v121574_v2 (stack40)
        %v104033_v25 = vadd.s32 3, %v104029_v30 (stack40)
        %vm103247_vm15 = vcmp.lt.f32.partialorder %v103246_v50, 0.0004427343 (stack62)
        %v103633_v50 = vxor.u32 %v103632_v21, %v103628_v9 (stack48)
        %v104442_v52 = vor.u32 %v104441_v10, %v104440_v43 (stack47)
        %v104891_v26 = vshll.u32 %v104882_v23, 6 (stack45)
        %v102875_v24 = vmul.f32 %v102871_v31, %v152044_v20 (stack54)
        %v103248_v7 = vsel /*vm=*/%vm103247_vm15, /*on_true_vy=*/%v103245_v41, /*on_false_vx=*/%v103242_v32 (stack66)
        %v104037_v54 = vadd.s32 %v104033_v25, %v104021_v42 (stack40)
        %v104892_v23 = vshrl.u32 %v104882_v23, 26 (stack46)
        %v152063_v41 = vxor.u32 2147483648, %v103248_v7 (stack56)
        %v103636_v9 = vadd.s32 %v103633_v50, %v103628_v9 (stack40)
        %v103638_v30 = vshll.u32 %v103633_v50, 26 (stack45)
        %v103639_v60 = vshrl.u32 %v103633_v50, 6 (stack46)
        %v102879_v44 = vadd.f32 %v102875_v24, %v151995_v44 (stack53)
        %v103225_v21 = vand.u32 2147483647, %v152002_v53 (stack77)
        %v152068_v43 = vmul.f32 inf, %v152002_v53 (stack54)
        %v104443_v10 = vxor.u32 %v104442_v52, %v104434_v6 (stack48)
        %vm103252_vm0 = vcmp.lt.f32.partialorder %v152063_v41, 5.0 (stack68)
        %121315 = vrsqrt.f32 %v152063_v41 (stack67)
        %v104039_v31 = vshll.u32 %v104033_v25, 17 (stack45)
        %v104040_v32 = vshrl.u32 %v104033_v25, 15 (stack46)
        %v102883_v42 = vmul.f32 %v102879_v44, %v152044_v20 (stack54)
        %v104893_v25 = vor.u32 %v104892_v23, %v104891_v26 (stack47)
        %v105324_v50 = vshll.u32 %v152032_v22, 13 (stack45)
        %v105325_v52 = vshrl.u32 %v152032_v22, 19 (stack46)
        %v152076_v26 = vadd.f32 -2.5, %v152063_v41 (stack53)
        %v103640_v24 = vor.u32 %v103639_v60, %v103638_v30 (stack47)
        %v104438_v6 = vadd.s32 %v104434_v6, %v121564_v0 (stack40)
        %v104889_v7 = vadd.s32 %v104885_v61, %v121569_v1 (stack40)
        %v102887_v45 = vadd.f32 %v102883_v42, %v151987_v45 (stack53)
        %v152084_v23 = vsel /*vm=*/%vm103252_vm0, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v152089_v30 = vsel /*vm=*/%vm103252_vm0, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v152094_v60 = vsel /*vm=*/%vm103252_vm0, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v152099_v44 = vsel /*vm=*/%vm103252_vm0, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v152104_v42 = vsel /*vm=*/%vm103252_vm0, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v103641_v24 = vxor.u32 %v103640_v24, %v103636_v9 (stack48)
        %v104041_v31 = vor.u32 %v104040_v32, %v104039_v31 (stack47)
        %v102891_v32 = vmul.f32 %v102887_v45, %v152044_v20 (stack54)
        %v104446_v10 = vadd.s32 %v104443_v10, %v121574_v2 (stack40)
        %v104894_v61 = vxor.u32 %v104893_v25, %v104885_v61 (stack48)
        %v105314_v8 = vadd.s32 %v105309_v8, %v121574_v2 (stack40)
        %v103644_v9 = vadd.s32 %v103641_v24, %v103636_v9 (stack40)
        %v103650_v25 = vshll.u32 %v103641_v24, 6 (stack45)
        %v103651_v45 = vshrl.u32 %v103641_v24, 26 (stack46)
        %v104042_v24 = vxor.u32 %v104041_v31, %v104037_v54 (stack48)
        %v102895_v29 = vadd.f32 %v102891_v32, %v151982_v29 (stack53)
        %vm103297_vm1 = vcmp.eq.f32.partialorder %v152063_v41, inf (stack70)
        %v104450_v31 = vadd.s32 2, %v104446_v10 (stack40)
        %v104897_v32 = vadd.s32 %v104894_v61, %v121564_v0 (stack40)
        %v105322_v22 = vadd.s32 %v152032_v22, %v105314_v8 (stack40)
        %vm103299_vm2 = vcmp.eq.f32.partialorder %v152063_v41, 0.0 (stack71)
        %v103652_v10 = vor.u32 %v103651_v45, %v103650_v25 (stack47)
        %v104045_v54 = vadd.s32 %v104042_v24, %v104037_v54 (stack40)
        %v104047_v61 = vshll.u32 %v104042_v24, 29 (stack45)
        %v102899_v8 = vmul.f32 %v102895_v29, %v152044_v20 (stack54)
        %v104048_v25 = vshrl.u32 %v104042_v24, 3 (stack46)
        %v104454_v6 = vadd.s32 %v104450_v31, %v104438_v6 (stack40)
        %v104456_v45 = vshll.u32 %v104450_v31, 13 (stack45)
        %v157747_v24 = vand.u32 2147483647, %v151863_v34 (stack77)
        %vm152117_vm3 = vcmp.eq.f32.partialorder %v157747_v24, 1.0 (stack68)
        %v103653_v10 = vxor.u32 %v103652_v10, %v103644_v9 (stack48)
        %v104457_v31 = vshrl.u32 %v104450_v31, 19 (stack46)
        %v104901_v32 = vadd.s32 1, %v104897_v32 (stack40)
        %v105326_v50 = vor.u32 %v105325_v52, %v105324_v50 (stack47)
        %v102903_v56 = vadd.f32 %v102899_v8, %v151977_v56 (stack53)
        %v103300_v52 = vand.u32 2147483648, %v152063_v41 (stack72)
        %v104049_v61 = vor.u32 %v104048_v25, %v104047_v61 (stack47)
        %vm105749_vm4 = vcmp.lt.u32.totalorder %v152051_v27, %v157077_v51 (stack43)
        %v103648_v9 = vadd.s32 %v103644_v9, %v121564_v0 (stack40)
        %v103656_v8 = vadd.s32 %v103653_v10, %v121574_v2 (stack40)
        %v104458_v25 = vor.u32 %v104457_v31, %v104456_v45 (stack47)
        %v104905_v7 = vadd.s32 %v104901_v32, %v104889_v7 (stack40)
        %v121316_v45 = vpop.eup %121315 (stack73)
        %v102907_v20 = vmul.f32 %v102903_v56, %v152044_v20 (stack54)
        %v104050_v24 = vxor.u32 %v104049_v61, %v104045_v54 (stack48)
        %v104907_v10 = vshll.u32 %v104901_v32, 17 (stack45)
        %v105327_v31 = vxor.u32 %v105326_v50, %v105322_v22 (stack48)
        %v103296_v50 = vmul.f32 %v121316_v45, %v152063_v41 (stack74)
        %v103660_v56 = vadd.s32 5, %v103656_v8 (stack40)
        %v104459_v61 = vxor.u32 %v104458_v25, %v104454_v6 (stack48)
        %v104908_v32 = vshrl.u32 %v104901_v32, 15 (stack46)
        %v102911_v55 = vadd.f32 %v102907_v20, %v151963_v55 (stack53)
        %v104053_v54 = vadd.s32 %v104050_v24, %v104045_v54 (stack40)
        %v104055_v8 = vshll.u32 %v104050_v24, 16 (stack45)
        %v104056_v25 = vshrl.u32 %v104050_v24, 16 (stack46)
        %v103298_v45 = vsel /*vm=*/%vm103297_vm1, /*on_true_vy=*/%v152063_v41, /*on_false_vx=*/%v103296_v50 (stack75)
        %v103662_v9 = vxor.u32 %v103660_v56, %v103648_v9 (stack48)
        %v104462_v6 = vadd.s32 %v104459_v61, %v104454_v6 (stack40)
        %v104464_v20 = vshll.u32 %v104459_v61, 15 (stack45)
        %v102915_v34 = vmul.f32 %v102911_v55, %v151863_v34 (stack54)
        %v103301_v52 = vsel /*vm=*/%vm103299_vm2, /*on_true_vy=*/%v103300_v52, /*on_false_vx=*/%v103298_v45 (stack76)
        %v104057_v24 = vor.u32 %v104056_v25, %v104055_v8 (stack47)
        %v104465_v50 = vshrl.u32 %v104459_v61, 17 (stack46)
        %v103304_v56 = vadd.f32 -3.0, %v103301_v52 (stack53)
        %v103663_v61 = vand.u32.u8 255, %v103662_v9 (stack49)
        %v104909_v10 = vor.u32 %v104908_v32, %v104907_v10 (stack47)
        %v152136_v22 = vadd.s32 %v105327_v31, %v105322_v22 (stack40)
        %v102919_v46 = vsel /*vm=*/%vm152117_vm3, /*on_true_vy=*/%v151956_v46, /*on_false_vx=*/%v102915_v34 (stack44)
        %v103289_v29 = vsel /*vm=*/%vm103252_vm0, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v104058_v32 = vxor.u32 %v104057_v24, %v104053_v54 (stack48)
        %v104466_v55 = vor.u32 %v104465_v50, %v104464_v20 (stack47)
        %v102923_v8 = vmul.f32 1.4140625, %v102919_v46 (stack54)
        %v152147_v26 = vsel /*vm=*/%vm103252_vm0, /*on_true_vy=*/%v152076_v26, /*on_false_vx=*/%v103304_v56 (stack44)
        %v103664_v25 = vand.u32 65535, %v103663_v61 (stack50)
        %v104910_v45 = vxor.u32 %v104909_v10, %v104905_v7 (stack48)
        %v103312_v9 = vmul.f32 %v152147_v26, %v103289_v29 (stack54)
        %v104061_v54 = vadd.s32 %v104058_v32, %v104053_v54 (stack40)
        %v104067_v20 = vshll.u32 %v104058_v32, 24 (stack45)
        %v104068_v34 = vshrl.u32 %v104058_v32, 8 (stack46)
        %v102926_v52 = vpack.c.bf16 %v157387_v11, %v102923_v8 (stack81)
        %v103665_v24 = vshrl.u32 %v103664_v25, 1 (stack51)
        %v104467_v50 = vxor.u32 %v104466_v55, %v104462_v6 (stack48)
        %v104913_v7 = vadd.s32 %v104910_v45, %v104905_v7 (stack40)
        %v103316_v42 = vadd.f32 %v103312_v9, %v152104_v42 (stack53)
        %v104069_v56 = vor.u32 %v104068_v34, %v104067_v20 (stack47)
        %v104915_v61 = vshll.u32 %v104910_v45, 29 (stack45)
        %v105332_v10 = vshll.u32 %v105327_v31, 15 (stack45)
        %120295 = vst [vmem:[%s123356_s30 + $0x1ec] sm:$0xf] /*vst_source=*/%v102926_v52 (stack83)
        %v103666_v46 = vor.u32 16256, %v103665_v24 (stack47)
        %v104470_v6 = vadd.s32 %v104467_v50, %v104462_v6 (stack40)
        %v104472_v29 = vshll.u32 %v104467_v50, 26 (stack45)
        %v104473_v32 = vshrl.u32 %v104467_v50, 6 (stack46)
        %v103320_v55 = vmul.f32 %v103316_v42, %v152147_v26 (stack54)
        %v104070_v8 = vxor.u32 %v104069_v56, %v104061_v54 (stack48)
        %v104916_v25 = vshrl.u32 %v104910_v45, 3 (stack46)
        %v105333_v31 = vshrl.u32 %v105327_v31, 17 (stack46)
        %v103281_v45 = vsel /*vm=*/%vm103252_vm0, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v103667_v9 = vand.u32.u16 65535, %v103666_v46 (stack52)
        %v104474_v20 = vor.u32 %v104473_v32, %v104472_v29 (stack47)
        %v105754_v34 = vadd.s32 %v157742_v12, %v157078_v48 (stack40)
        %v103324_v52 = vadd.f32 %v103320_v55, %v103281_v45 (stack53)
        %v104073_v24 = vadd.s32 %v104070_v8, %v121564_v0 (stack40)
        %v104917_v50 = vor.u32 %v104916_v25, %v104915_v61 (stack47)
        %v105334_v42 = vor.u32 %v105333_v31, %v105332_v10 (stack47)
        %v120298_v56 = vadd.low.f32.bf16 -1.0, %v103667_v9 (stack53)
        %v104065_v54 = vadd.s32 %v104061_v54, %v121569_v1 (stack40)
        %v104475_v61 = vxor.u32 %v104474_v20, %v104470_v6 (stack48)
        %v152163_v10 = vadd.s32 %v152051_v27, %v122657_v58 (stack40)
        %v103328_v46 = vmul.f32 %v103324_v52, %v152147_v26 (stack54)
        %v104077_v29 = vadd.s32 4, %v104073_v24 (stack40)
        %v104918_v32 = vxor.u32 %v104917_v50, %v104913_v7 (stack48)
        %v105335_v55 = vxor.u32 %v105334_v42, %v152136_v22 (stack48)
        %v103676_v8 = vmul.f32 2.0, %v120298_v56 (stack54)
        %v104478_v6 = vadd.s32 %v104475_v61, %v104470_v6 (stack40)
        %v104484_v25 = vshll.u32 %v104475_v61, 6 (stack45)
        %v104485_v31 = vshrl.u32 %v104475_v61, 26 (stack46)
        %v103332_v44 = vadd.f32 %v103328_v46, %v152099_v44 (stack53)
        %v104081_v45 = vadd.s32 %v104077_v29, %v104065_v54 (stack40)
        %v104083_v9 = vshll.u32 %v104077_v29, 13 (stack45)
        %v104084_v20 = vshrl.u32 %v104077_v29, 19 (stack46)
        %v103273_v52 = vsel /*vm=*/%vm103252_vm0, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v103680_v24 = vadd.f32 -0.99609375, %v103676_v8 (stack53)
        %v104486_v50 = vor.u32 %v104485_v31, %v104484_v25 (stack47)
        %v104921_v7 = vadd.s32 %v104918_v32, %v104913_v7 (stack40)
        %v103336_v42 = vmul.f32 %v103332_v44, %v152147_v26 (stack54)
        %v104085_v56 = vor.u32 %v104084_v20, %v104083_v9 (stack47)
        %v104923_v54 = vshll.u32 %v104918_v32, 16 (stack45)
        %v104924_v61 = vshrl.u32 %v104918_v32, 16 (stack46)
        %v152172_v46 = vmax.f32 %v103680_v24, -0.99609375 (stack55)
        %v104487_v29 = vxor.u32 %v104486_v50, %v104478_v6 (stack48)
        %v105338_v22 = vadd.s32 %v105335_v55, %v152136_v22 (stack40)
        %v152177_v32 = vadd.s32 %v152163_v10, %v121569_v1 (stack40)
        %v103340_v8 = vadd.f32 %v103336_v42, %v103273_v52 (stack53)
        %v104086_v25 = vxor.u32 %v104085_v56, %v104081_v45 (stack48)
        %v104925_v31 = vor.u32 %v104924_v61, %v104923_v54 (stack47)
        %v105758_v44 = vadd.s32 1, %v105754_v34 (stack40)
        %v103696_v9 = vxor.u32 2147483648, %v152172_v46 (stack56)
        %v104490_v20 = vadd.s32 %v104487_v29, %v121569_v1 (stack40)
        %v105340_v52 = vshll.u32 %v105335_v55, 26 (stack45)
        %v105341_v55 = vshrl.u32 %v105335_v55, 6 (stack46)
        %v103344_v24 = vmul.f32 %v103340_v8, %v152147_v26 (stack54)
        %v104089_v45 = vadd.s32 %v104086_v25, %v104081_v45 (stack40)
        %v104091_v50 = vshll.u32 %v104086_v25, 15 (stack45)
        %v104092_v42 = vshrl.u32 %v104086_v25, 17 (stack46)
        %v103699_v56 = vmul.f32 %v103696_v9, %v152172_v46 (stack54)
        %v104482_v6 = vadd.s32 %v104478_v6, %v121574_v2 (stack40)
        %v104494_v54 = vadd.s32 3, %v104490_v20 (stack40)
        %v104926_v61 = vxor.u32 %v104925_v31, %v104921_v7 (stack48)
        %v103265_v41 = vsel /*vm=*/%vm103252_vm0, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v103348_v60 = vadd.f32 %v103344_v24, %v152094_v60 (stack53)
        %v104093_v29 = vor.u32 %v104092_v42, %v104091_v50 (stack47)
        %v105762_v34 = vsel /*vm=*/%vm105749_vm4, /*on_true_vy=*/%v105758_v44, /*on_false_vx=*/%v105754_v34 (stack44)
        %v103701_v8 = vadd.f32 1.0, %v103699_v56 (stack57)
        %v103704_v25 = vmul.f32 -0.5, %v103699_v56 (stack59)
        %v104498_v31 = vadd.s32 %v104494_v54, %v104482_v6 (stack40)
        %v105342_v44 = vor.u32 %v105341_v55, %v105340_v52 (stack47)
        %v103352_v9 = vmul.f32 %v103348_v60, %v152147_v26 (stack54)
        %v104094_v20 = vxor.u32 %v104093_v29, %v104089_v45 (stack48)
        %v104500_v52 = vshll.u32 %v104494_v54, 17 (stack45)
        %v104501_v55 = vshrl.u32 %v104494_v54, 15 (stack46)
        %121317 = vlog2.f32 %v103701_v8 (stack58)
        %v104929_v7 = vadd.s32 %v104926_v61, %v104921_v7 (stack40)
        %vm105744_vm5 = vcmp.lt.u32.totalorder %v152163_v10, %v152051_v27 (stack43)
        %v105785_v24 = vshll.u32 %v152177_v32, 13 (stack45)
        %v103356_v50 = vadd.f32 %v103352_v9, %v103265_v41 (stack53)
        %v104097_v45 = vadd.s32 %v104094_v20, %v104089_v45 (stack40)
        %v104099_v42 = vshll.u32 %v104094_v20, 26 (stack45)
        %v104100_v6 = vshrl.u32 %v104094_v20, 6 (stack46)
        %v103705_v54 = vadd.f32 1.0, %v103704_v25 (stack61)
        %v103707_v41 = vand.u32 2147483647, %v103699_v56 (stack60)
        %v104502_v60 = vor.u32 %v104501_v55, %v104500_v52 (stack47)
        %v104935_v29 = vshll.u32 %v104926_v61, 24 (stack45)
        %v103360_v8 = vmul.f32 %v103356_v50, %v152147_v26 (stack54)
        %v104101_v25 = vor.u32 %v104100_v6, %v104099_v42 (stack47)
        %v104936_v61 = vshrl.u32 %v104926_v61, 8 (stack46)
        %v105343_v44 = vxor.u32 %v105342_v44, %v105338_v22 (stack48)
        %vm152198_vm6 = vcmp.eq.f32.partialorder %v103225_v21, 1.0 (stack68)
        %v104503_v9 = vxor.u32 %v104502_v60, %v104498_v31 (stack48)
        %v105766_v20 = vadd.s32 1, %v105762_v34 (stack40)
        %v105786_v52 = vshrl.u32 %v152177_v32, 19 (stack46)
        %v152205_v55 = vadd.s32 %v157741_v40, %v157079_v39 (stack40)
        %v103364_v30 = vadd.f32 %v103360_v8, %v152089_v30 (stack53)
        %v104102_v50 = vxor.u32 %v104101_v25, %v104097_v45 (stack48)
        %v104937_v42 = vor.u32 %v104936_v61, %v104935_v29 (stack47)
        %v105346_v22 = vadd.s32 %v105343_v44, %v105338_v22 (stack40)
        %v104506_v31 = vadd.s32 %v104503_v9, %v104498_v31 (stack40)
        %v104508_v6 = vshll.u32 %v104503_v9, 29 (stack45)
        %v104509_v60 = vshrl.u32 %v104503_v9, 3 (stack46)
        %v105352_v29 = vshll.u32 %v105343_v44, 6 (stack45)
        %v103368_v26 = vmul.f32 %v103364_v30, %v152147_v26 (stack54)
        %vm152209_vm7 = vcmp.lt.f32.partialorder %v103707_v41, 0.0004427343 (stack62)
        %v104105_v45 = vadd.s32 %v104102_v50, %v104097_v45 (stack40)
        %v104111_v8 = vshll.u32 %v104102_v50, 6 (stack45)
        %v104112_v25 = vshrl.u32 %v104102_v50, 26 (stack46)
        %v103706_v56 = vmul.f32 %v103705_v54, %v103699_v56 (stack63)
        %v104510_v54 = vor.u32 %v104509_v60, %v104508_v6 (stack47)
        %v104938_v61 = vxor.u32 %v104937_v42, %v104929_v7 (stack48)
        %v105353_v44 = vshrl.u32 %v105343_v44, 26 (stack46)
        %v103372_v23 = vadd.f32 %v103368_v26, %v152084_v23 (stack53)
        %v104113_v9 = vor.u32 %v104112_v25, %v104111_v8 (stack47)
        %v104933_v7 = vadd.s32 %v104929_v7, %v121564_v0 (stack40)
        %v105770_v27 = vsel /*vm=*/%vm105744_vm5, /*on_true_vy=*/%v105766_v20, /*on_false_vx=*/%v105762_v34 (stack44)
        %v104511_v10 = vxor.u32 %v104510_v54, %v104506_v31 (stack48)
        %v104941_v34 = vadd.s32 %v104938_v61, %v121574_v2 (stack40)
        %v105354_v20 = vor.u32 %v105353_v44, %v105352_v29 (stack47)
        %v105775_v30 = vadd.s32 %v105770_v27, %v121574_v2 (stack40)
        %v103376_v53 = vmul.f32 %v103372_v23, %v152002_v53 (stack54)
        %v104109_v50 = vadd.s32 %v104105_v45, %v121564_v0 (stack40)
        %v104114_v42 = vxor.u32 %v104113_v9, %v104105_v45 (stack48)
        %v105787_v24 = vor.u32 %v105786_v52, %v105785_v24 (stack47)
        %v104514_v52 = vadd.s32 %v104511_v10, %v104506_v31 (stack40)
        %v104516_v31 = vshll.u32 %v104511_v10, 16 (stack45)
        %v104517_v6 = vshrl.u32 %v104511_v10, 16 (stack46)
        %v104945_v60 = vadd.s32 2, %v104941_v34 (stack40)
        %v121318_v29 = vpop.eup %121317 (stack64)
        %v103380_v43 = vsel /*vm=*/%vm152198_vm6, /*on_true_vy=*/%v152068_v43, /*on_false_vx=*/%v103376_v53 (stack44)
        %v104117_v21 = vadd.s32 %v104114_v42, %v121574_v2 (stack40)
        %v105355_v26 = vxor.u32 %v105354_v20, %v105346_v22 (stack48)
        %v105783_v32 = vadd.s32 %v152177_v32, %v105775_v30 (stack40)
        %v103384_v45 = vmul.f32 1.4140625, %v103380_v43 (stack54)
        %v103703_v8 = vmul.f32 0.6931472, %v121318_v29 (stack65)
        %v104518_v25 = vor.u32 %v104517_v6, %v104516_v31 (stack47)
        %v104949_v54 = vadd.s32 %v104945_v60, %v104933_v7 (stack40)
        %v104121_v61 = vadd.s32 5, %v104117_v21 (stack40)
        %v104951_v44 = vshll.u32 %v104945_v60, 13 (stack45)
        %v104952_v23 = vshrl.u32 %v104945_v60, 19 (stack46)
        %v105358_v9 = vadd.s32 %v105355_v26, %v121564_v0 (stack40)
        %v103387_v7 = vpack.c.bf16 %v157387_v11, %v103384_v45 (stack81)
        %v103709_v41 = vsel /*vm=*/%vm152209_vm7, /*on_true_vy=*/%v103706_v56, /*on_false_vx=*/%v103703_v8 (stack66)
        %v104519_v56 = vxor.u32 %v104518_v25, %v104514_v52 (stack48)
        %v105788_v27 = vxor.u32 %v105787_v24, %v105783_v32 (stack48)
        %v152231_v10 = vxor.u32 2147483648, %v103709_v41 (stack56)
        %v104123_v34 = vxor.u32 %v104121_v61, %v104109_v50 (stack48)
        %v104953_v20 = vor.u32 %v104952_v23, %v104951_v44 (stack47)
        %120297 = vst [vmem:[%s123356_s30 + $0x26c] sm:$0xf] /*vst_source=*/%v103387_v7 (stack83)
        %v104522_v30 = vadd.s32 %v104519_v56, %v104514_v52 (stack40)
        %v104528_v53 = vshll.u32 %v104519_v56, 24 (stack45)
        %v104529_v50 = vshrl.u32 %v104519_v56, 8 (stack46)
        %v105791_v42 = vadd.s32 %v105788_v27, %v105783_v32 (stack40)
        %vm103713_vm8 = vcmp.lt.f32.partialorder %v152231_v10, 5.0 (stack68)
        %121319 = vrsqrt.f32 %v152231_v10 (stack67)
        %v105362_v24 = vadd.s32 1, %v105358_v9 (stack40)
        %v104530_v52 = vor.u32 %v104529_v50, %v104528_v53 (stack47)
        %v105350_v22 = vadd.s32 %v105346_v22, %v121569_v1 (stack40)
        %v152239_v31 = vadd.s32 %v152205_v55, %v122657_v58 (stack40)
        %v152244_v6 = vsel /*vm=*/%vm103713_vm8, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v152247_v60 = vadd.f32 -2.5, %v152231_v10 (stack53)
        %v104526_v29 = vadd.s32 %v104522_v30, %v121569_v1 (stack40)
        %v104954_v43 = vxor.u32 %v104953_v20, %v104949_v54 (stack48)
        %v152253_v21 = vsel /*vm=*/%vm103713_vm8, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v152258_v26 = vsel /*vm=*/%vm103713_vm8, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v104124_v32 = vand.u32.u8 255, %v104123_v34 (stack49)
        %v104531_v45 = vxor.u32 %v104530_v52, %v104522_v30 (stack48)
        %v104957_v8 = vadd.s32 %v104954_v43, %v104949_v54 (stack40)
        %v104959_v25 = vshll.u32 %v104954_v43, 15 (stack45)
        %v104960_v54 = vshrl.u32 %v104954_v43, 17 (stack46)
        %v105366_v61 = vadd.s32 %v105362_v24, %v105350_v22 (stack40)
        %v104125_v44 = vand.u32 65535, %v104124_v32 (stack50)
        %v104534_v23 = vadd.s32 %v104531_v45, %v121564_v0 (stack40)
        %v105368_v9 = vshll.u32 %v105362_v24, 17 (stack45)
        %v105369_v7 = vshrl.u32 %v105362_v24, 15 (stack46)
        %v152264_v41 = vsel /*vm=*/%vm103713_vm8, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %vm103758_vm9 = vcmp.eq.f32.partialorder %v152231_v10, inf (stack70)
        %v104961_v56 = vor.u32 %v104960_v54, %v104959_v25 (stack47)
        %v105793_v34 = vshll.u32 %v105788_v27, 15 (stack45)
        %v105794_v27 = vshrl.u32 %v105788_v27, 17 (stack46)
        %vm103760_vm10 = vcmp.eq.f32.partialorder %v152231_v10, 0.0 (stack71)
        %v104126_v20 = vshrl.u32 %v104125_v44, 1 (stack51)
        %v104538_v30 = vadd.s32 4, %v104534_v23 (stack40)
        %v105370_v53 = vor.u32 %v105369_v7, %v105368_v9 (stack47)
        %vm106210_vm11 = vcmp.lt.u32.totalorder %v152205_v55, %v157079_v39 (stack43)
        %v103761_v50 = vand.u32 2147483648, %v152231_v10 (stack72)
        %v104962_v24 = vxor.u32 %v104961_v56, %v104957_v8 (stack48)
        %v105795_v52 = vor.u32 %v105794_v27, %v105793_v34 (stack47)
        %v106215_v22 = vadd.s32 %v157742_v12, %v157082_v49 (stack40)
        %v104127_v43 = vor.u32 16256, %v104126_v20 (stack47)
        %v104542_v29 = vadd.s32 %v104538_v30, %v104526_v29 (stack40)
        %v104544_v32 = vshll.u32 %v104538_v30, 13 (stack45)
        %v104545_v45 = vshrl.u32 %v104538_v30, 19 (stack46)
        %v104965_v8 = vadd.s32 %v104962_v24, %v104957_v8 (stack40)
        %v104967_v25 = vshll.u32 %v104962_v24, 26 (stack45)
        %v104968_v54 = vshrl.u32 %v104962_v24, 6 (stack46)
        %v105371_v44 = vxor.u32 %v105370_v53, %v105366_v61 (stack48)
        %v104128_v23 = vand.u32.u16 65535, %v104127_v43 (stack52)
        %v104546_v9 = vor.u32 %v104545_v45, %v104544_v32 (stack47)
        %v105796_v7 = vxor.u32 %v105795_v52, %v105791_v42 (stack48)
        %v106219_v56 = vadd.s32 1, %v106215_v22 (stack40)
        %v121320_v34 = vpop.eup %121319 (stack73)
        %v104969_v27 = vor.u32 %v104968_v54, %v104967_v25 (stack47)
        %v105374_v61 = vadd.s32 %v105371_v44, %v105366_v61 (stack40)
        %v105376_v20 = vshll.u32 %v105371_v44, 29 (stack45)
        %v105377_v30 = vshrl.u32 %v105371_v44, 3 (stack46)
        %v103757_v53 = vmul.f32 %v121320_v34, %v152231_v10 (stack74)
        %v120300_v24 = vadd.low.f32.bf16 -1.0, %v104128_v23 (stack53)
        %v104547_v52 = vxor.u32 %v104546_v9, %v104542_v29 (stack48)
        %v105799_v42 = vadd.s32 %v105796_v7, %v105791_v42 (stack40)
        %v104970_v43 = vxor.u32 %v104969_v27, %v104965_v8 (stack48)
        %v105378_v32 = vor.u32 %v105377_v30, %v105376_v20 (stack47)
        %v105801_v45 = vshll.u32 %v105796_v7, 26 (stack45)
        %v105802_v25 = vshrl.u32 %v105796_v7, 6 (stack46)
        %v103759_v54 = vsel /*vm=*/%vm103758_vm9, /*on_true_vy=*/%v152231_v10, /*on_false_vx=*/%v103757_v53 (stack75)
        %v104137_v44 = vmul.f32 2.0, %v120300_v24 (stack54)
        %v104550_v29 = vadd.s32 %v104547_v52, %v104542_v29 (stack40)
        %v104552_v23 = vshll.u32 %v104547_v52, 15 (stack45)
        %v103762_v50 = vsel /*vm=*/%vm103760_vm10, /*on_true_vy=*/%v103761_v50, /*on_false_vx=*/%v103759_v54 (stack76)
        %v104553_v9 = vshrl.u32 %v104547_v52, 17 (stack46)
        %v104973_v8 = vadd.s32 %v104970_v43, %v104965_v8 (stack40)
        %v104979_v7 = vshll.u32 %v104970_v43, 6 (stack45)
        %v103765_v34 = vadd.f32 -3.0, %v103762_v50 (stack53)
        %v104141_v27 = vadd.f32 -0.99609375, %v104137_v44 (stack53)
        %v104980_v20 = vshrl.u32 %v104970_v43, 26 (stack46)
        %v105379_v30 = vxor.u32 %v105378_v32, %v105374_v61 (stack48)
        %v103750_v53 = vsel /*vm=*/%vm103713_vm8, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v104554_v24 = vor.u32 %v104553_v9, %v104552_v23 (stack47)
        %v105803_v52 = vor.u32 %v105802_v25, %v105801_v45 (stack47)
        %v106223_v22 = vsel /*vm=*/%vm106210_vm11, /*on_true_vy=*/%v106219_v56, /*on_false_vx=*/%v106215_v22 (stack44)
        %v152288_v60 = vsel /*vm=*/%vm103713_vm8, /*on_true_vy=*/%v152247_v60, /*on_false_vx=*/%v103765_v34 (stack44)
        %v152290_v56 = vmax.f32 %v104141_v27, -0.99609375 (stack55)
        %v104981_v43 = vor.u32 %v104980_v20, %v104979_v7 (stack47)
        %v105382_v61 = vadd.s32 %v105379_v30, %v105374_v61 (stack40)
        %v103773_v32 = vmul.f32 %v152288_v60, %v103750_v53 (stack54)
        %v104555_v45 = vxor.u32 %v104554_v24, %v104550_v29 (stack48)
        %v105384_v25 = vshll.u32 %v105379_v30, 16 (stack45)
        %v105385_v54 = vshrl.u32 %v105379_v30, 16 (stack46)
        %v103742_v44 = vsel /*vm=*/%vm103713_vm8, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v103746_v23 = vsel /*vm=*/%vm103713_vm8, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v104157_v50 = vxor.u32 2147483648, %v152290_v56 (stack56)
        %v104982_v9 = vxor.u32 %v104981_v43, %v104973_v8 (stack48)
        %v103777_v7 = vadd.f32 %v103773_v32, %v103746_v23 (stack53)
        %v104558_v29 = vadd.s32 %v104555_v45, %v104550_v29 (stack40)
        %v104560_v34 = vshll.u32 %v104555_v45, 26 (stack45)
        %v104561_v27 = vshrl.u32 %v104555_v45, 6 (stack46)
        %v104160_v20 = vmul.f32 %v104157_v50, %v152290_v56 (stack54)
        %v104985_v30 = vadd.s32 %v104982_v9, %v121569_v1 (stack40)
        %v105386_v53 = vor.u32 %v105385_v54, %v105384_v25 (stack47)
        %vm106205_vm12 = vcmp.lt.u32.totalorder %v152239_v31, %v152205_v55 (stack43)
        %v103781_v24 = vmul.f32 %v103777_v7, %v152288_v60 (stack54)
        %v104562_v43 = vor.u32 %v104561_v27, %v104560_v34 (stack47)
        %v105804_v52 = vxor.u32 %v105803_v52, %v105799_v42 (stack48)
        %v106240_v32 = vadd.s32 %v152239_v31, %v121569_v1 (stack40)
        %v104162_v45 = vadd.f32 1.0, %v104160_v20 (stack57)
        %v104165_v25 = vmul.f32 -0.5, %v104160_v20 (stack59)
        %v104977_v8 = vadd.s32 %v104973_v8, %v121574_v2 (stack40)
        %v104989_v54 = vadd.s32 3, %v104985_v30 (stack40)
        %v103785_v44 = vadd.f32 %v103781_v24, %v103742_v44 (stack53)
        %v104563_v23 = vxor.u32 %v104562_v43, %v104558_v29 (stack48)
        %v105387_v50 = vxor.u32 %v105386_v53, %v105382_v61 (stack48)
        %v105807_v42 = vadd.s32 %v105804_v52, %v105799_v42 (stack40)
        %121321 = vlog2.f32 %v104162_v45 (stack58)
        %v104166_v9 = vadd.f32 1.0, %v104165_v25 (stack61)
        %v104993_v7 = vadd.s32 %v104989_v54, %v104977_v8 (stack40)
        %v106227_v34 = vadd.s32 1, %v106223_v22 (stack40)
        %v103789_v27 = vmul.f32 %v103785_v44, %v152288_v60 (stack54)
        %v104566_v29 = vadd.s32 %v104563_v23, %v104558_v29 (stack40)
        %v104572_v30 = vshll.u32 %v104563_v23, 6 (stack45)
        %v104573_v53 = vshrl.u32 %v104563_v23, 26 (stack46)
        %v104168_v24 = vand.u32 2147483647, %v104160_v20 (stack60)
        %v104995_v43 = vshll.u32 %v104989_v54, 17 (stack45)
        %v104996_v45 = vshrl.u32 %v104989_v54, 15 (stack46)
        %v105390_v61 = vadd.s32 %v105387_v50, %v105382_v61 (stack40)
        %v103793_v41 = vadd.f32 %v103789_v27, %v152264_v41 (stack53)
        %v104167_v20 = vmul.f32 %v104166_v9, %v104160_v20 (stack63)
        %v104574_v25 = vor.u32 %v104573_v53, %v104572_v30 (stack47)
        %v105396_v8 = vshll.u32 %v105387_v50, 24 (stack45)
        %v104570_v54 = vadd.s32 %v104566_v29, %v121564_v0 (stack40)
        %v104997_v44 = vor.u32 %v104996_v45, %v104995_v43 (stack47)
        %v105394_v23 = vadd.s32 %v105390_v61, %v121564_v0 (stack40)
        %v105397_v50 = vshrl.u32 %v105387_v50, 8 (stack46)
        %v103797_v9 = vmul.f32 %v103793_v41, %v152288_v60 (stack54)
        %v104575_v27 = vxor.u32 %v104574_v25, %v104566_v29 (stack48)
        %v105813_v29 = vshll.u32 %v105804_v52, 6 (stack45)
        %v105814_v52 = vshrl.u32 %v105804_v52, 26 (stack46)
        %v104998_v30 = vxor.u32 %v104997_v44, %v104993_v7 (stack48)
        %v105398_v53 = vor.u32 %v105397_v50, %v105396_v8 (stack47)
        %v106231_v55 = vsel /*vm=*/%vm106205_vm12, /*on_true_vy=*/%v106227_v34, /*on_false_vx=*/%v106223_v22 (stack44)
        %v106246_v31 = vshll.u32 %v106240_v32, 13 (stack45)
        %v103801_v26 = vadd.f32 %v103797_v9, %v152258_v26 (stack53)
        %vm152317_vm13 = vcmp.lt.f32.partialorder %v104168_v24, 0.0004427343 (stack62)
        %v104578_v34 = vadd.s32 %v104575_v27, %v121574_v2 (stack40)
        %v105815_v24 = vor.u32 %v105814_v52, %v105813_v29 (stack47)
        %v106236_v43 = vadd.s32 %v106231_v55, %v121574_v2 (stack40)
        %v105001_v7 = vadd.s32 %v104998_v30, %v104993_v7 (stack40)
        %v105003_v45 = vshll.u32 %v104998_v30, 29 (stack45)
        %v105004_v41 = vshrl.u32 %v104998_v30, 3 (stack46)
        %v105399_v61 = vxor.u32 %v105398_v53, %v105390_v61 (stack48)
        %v103805_v25 = vmul.f32 %v103801_v26, %v152288_v60 (stack54)
        %v104582_v8 = vadd.s32 5, %v104578_v34 (stack40)
        %v105816_v44 = vxor.u32 %v105815_v24, %v105807_v42 (stack48)
        %v106244_v50 = vadd.s32 %v106240_v32, %v106236_v43 (stack40)
        %v105005_v9 = vor.u32 %v105004_v41, %v105003_v45 (stack47)
        %v105402_v27 = vadd.s32 %v105399_v61, %v121574_v2 (stack40)
        %v106247_v32 = vshrl.u32 %v106240_v32, 19 (stack46)
        %v152327_v29 = vadd.s32 %v157741_v40, %v157083_v59 (stack40)
        %v103809_v21 = vadd.f32 %v103805_v25, %v152253_v21 (stack53)
        %v104584_v54 = vxor.u32 %v104582_v8, %v104570_v54 (stack48)
        %v105819_v52 = vadd.s32 %v105816_v44, %v121564_v0 (stack40)
        %v152333_v30 = vadd.s32 %v157742_v12, %v157084_v16 (stack40)
        %v105006_v53 = vxor.u32 %v105005_v9, %v105001_v7 (stack48)
        %v105406_v55 = vadd.s32 2, %v105402_v27 (stack40)
        %v105811_v42 = vadd.s32 %v105807_v42, %v121569_v1 (stack40)
        %v106248_v31 = vor.u32 %v106247_v32, %v106246_v31 (stack47)
        %v121322_v26 = vpop.eup %121321 (stack64)
        %v103813_v34 = vmul.f32 %v103809_v21, %v152288_v60 (stack54)
        %v104585_v24 = vand.u32.u8 255, %v104584_v54 (stack49)
        %v105823_v43 = vadd.s32 1, %v105819_v52 (stack40)
        %vm106671_vm14 = vcmp.lt.u32.totalorder %v152327_v29, %v157083_v59 (stack43)
        %v104164_v45 = vmul.f32 0.6931472, %v121322_v26 (stack65)
        %v105009_v7 = vadd.s32 %v105006_v53, %v105001_v7 (stack40)
        %v105011_v41 = vshll.u32 %v105006_v53, 16 (stack45)
        %v105012_v61 = vshrl.u32 %v105006_v53, 16 (stack46)
        %v103817_v6 = vadd.f32 %v103813_v34, %v152244_v6 (stack53)
        %v104586_v25 = vand.u32 65535, %v104585_v24 (stack50)
        %v105410_v23 = vadd.s32 %v105406_v55, %v105394_v23 (stack40)
        %v105412_v8 = vshll.u32 %v105406_v55, 13 (stack45)
        %v104170_v20 = vsel /*vm=*/%vm152317_vm13, /*on_true_vy=*/%v104167_v20, /*on_false_vx=*/%v104164_v45 (stack66)
        %v105013_v22 = vor.u32 %v105012_v61, %v105011_v41 (stack47)
        %v105413_v44 = vshrl.u32 %v105406_v55, 19 (stack46)
        %v105827_v9 = vadd.s32 %v105823_v43, %v105811_v42 (stack40)
        %v103821_v27 = vmul.f32 %v103817_v6, %v152288_v60 (stack54)
        %v152343_v32 = vxor.u32 2147483648, %v104170_v20 (stack56)
        %v103686_v21 = vand.u32 2147483647, %v152172_v46 (stack77)
        %v103722_v54 = vsel /*vm=*/%vm103713_vm8, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v105014_v52 = vxor.u32 %v105013_v22, %v105009_v7 (stack48)
        %v106249_v53 = vxor.u32 %v106248_v31, %v106244_v50 (stack48)
        %v103825_v55 = vadd.f32 %v103821_v27, %v103722_v54 (stack53)
        %121323 = vrsqrt.f32 %v152343_v32 (stack67)
        %vm104174_vm15 = vcmp.lt.f32.partialorder %v152343_v32, 5.0 (stack68)
        %v104587_v42 = vshrl.u32 %v104586_v25, 1 (stack51)
        %v105017_v31 = vadd.s32 %v105014_v52, %v105009_v7 (stack40)
        %v105414_v26 = vor.u32 %v105413_v44, %v105412_v8 (stack47)
        %v103694_v34 = vmul.f32 inf, %v152172_v46 (stack54)
        %v103829_v60 = vmul.f32 %v103825_v55, %v152288_v60 (stack54)
        %v105829_v24 = vshll.u32 %v105823_v43, 17 (stack45)
        %v105830_v43 = vshrl.u32 %v105823_v43, 15 (stack46)
        %vm152353_vm0 = vcmp.eq.f32.partialorder %v103686_v21, 1.0 (stack68)
        %v103718_v10 = vsel /*vm=*/%vm103713_vm8, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v152361_v7 = vadd.f32 -2.5, %v152343_v32 (stack53)
        %v152365_v41 = vadd.s32 %v152327_v29, %v122657_v58 (stack40)
        %v103833_v61 = vadd.f32 %v103829_v60, %v103718_v10 (stack53)
        %v152370_v6 = vsel /*vm=*/%vm104174_vm15, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v152375_v25 = vsel /*vm=*/%vm104174_vm15, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v105021_v8 = vadd.s32 %v105017_v31, %v121569_v1 (stack40)
        %v104588_v20 = vor.u32 16256, %v104587_v42 (stack47)
        %v105023_v22 = vshll.u32 %v105014_v52, 24 (stack45)
        %v105024_v44 = vshrl.u32 %v105014_v52, 8 (stack46)
        %v105415_v27 = vxor.u32 %v105414_v26, %v105410_v23 (stack48)
        %v103837_v46 = vmul.f32 %v103833_v61, %v152172_v46 (stack54)
        %v105831_v21 = vor.u32 %v105830_v43, %v105829_v24 (stack47)
        %v106252_v50 = vadd.s32 %v106249_v53, %v106244_v50 (stack40)
        %v106254_v54 = vshll.u32 %v106249_v53, 15 (stack45)
        %v104589_v52 = vand.u32.u16 65535, %v104588_v20 (stack52)
        %v105025_v55 = vor.u32 %v105024_v44, %v105023_v22 (stack47)
        %v105418_v23 = vadd.s32 %v105415_v27, %v105410_v23 (stack40)
        %v105420_v42 = vshll.u32 %v105415_v27, 15 (stack45)
        %v103841_v26 = vsel /*vm=*/%vm152353_vm0, /*on_true_vy=*/%v103694_v34, /*on_false_vx=*/%v103837_v46 (stack44)
        %v105421_v34 = vshrl.u32 %v105415_v27, 17 (stack46)
        %v105832_v60 = vxor.u32 %v105831_v21, %v105827_v9 (stack48)
        %v106255_v53 = vshrl.u32 %v106249_v53, 17 (stack46)
        %v103845_v24 = vmul.f32 1.4140625, %v103841_v26 (stack54)
        %vm104219_vm1 = vcmp.eq.f32.partialorder %v152343_v32, inf (stack70)
        %v120302_v43 = vadd.low.f32.bf16 -1.0, %v104589_v52 (stack53)
        %v105026_v31 = vxor.u32 %v105025_v55, %v105017_v31 (stack48)
        %v105422_v45 = vor.u32 %v105421_v34, %v105420_v42 (stack47)
        %v105835_v9 = vadd.s32 %v105832_v60, %v105827_v9 (stack40)
        %v105837_v10 = vshll.u32 %v105832_v60, 29 (stack45)
        %v105838_v61 = vshrl.u32 %v105832_v60, 3 (stack46)
        %v103848_v20 = vpack.c.bf16 %v157387_v11, %v103845_v24 (stack81)
        %v104598_v22 = vmul.f32 2.0, %v120302_v43 (stack54)
        %v105029_v44 = vadd.s32 %v105026_v31, %v121564_v0 (stack40)
        %v106256_v27 = vor.u32 %v106255_v53, %v106254_v54 (stack47)
        %vm104221_vm2 = vcmp.eq.f32.partialorder %v152343_v32, 0.0 (stack71)
        %v104222_v46 = vand.u32 2147483648, %v152343_v32 (stack72)
        %v105423_v21 = vxor.u32 %v105422_v45, %v105418_v23 (stack48)
        %v105839_v54 = vor.u32 %v105838_v61, %v105837_v10 (stack47)
        %v121324_v52 = vpop.eup %121323 (stack73)
        %120299 = vst [vmem:[%s123356_s30 + $0x2ec] sm:$0xf] /*vst_source=*/%v103848_v20 (stack83)
        %v104602_v55 = vadd.f32 -0.99609375, %v104598_v22 (stack53)
        %v105033_v42 = vadd.s32 4, %v105029_v44 (stack40)
        %v106257_v26 = vxor.u32 %v106256_v27, %v106252_v50 (stack48)
        %v152389_v34 = vadd.s32 %v157741_v40, %v157089_v17 (stack40)
        %v104218_v60 = vmul.f32 %v121324_v52, %v152343_v32 (stack74)
        %v105426_v23 = vadd.s32 %v105423_v21, %v105418_v23 (stack40)
        %v105428_v53 = vshll.u32 %v105423_v21, 26 (stack45)
        %v105429_v24 = vshrl.u32 %v105423_v21, 6 (stack46)
        %v152392_v43 = vmax.f32 %v104602_v55, -0.99609375 (stack55)
        %v105037_v8 = vadd.s32 %v105033_v42, %v105021_v8 (stack40)
        %v105039_v31 = vshll.u32 %v105033_v42, 13 (stack45)
        %v105040_v45 = vshrl.u32 %v105033_v42, 19 (stack46)
        %v104220_v10 = vsel /*vm=*/%vm104219_vm1, /*on_true_vy=*/%v152343_v32, /*on_false_vx=*/%v104218_v60 (stack75)
        %v105430_v61 = vor.u32 %v105429_v24, %v105428_v53 (stack47)
        %v105840_v20 = vxor.u32 %v105839_v54, %v105835_v9 (stack48)
        %v152397_v50 = vadd.s32 %v106257_v26, %v106252_v50 (stack40)
        %v104199_v22 = vsel /*vm=*/%vm104174_vm15, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v104203_v44 = vsel /*vm=*/%vm104174_vm15, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v104223_v27 = vsel /*vm=*/%vm104221_vm2, /*on_true_vy=*/%v104222_v46, /*on_false_vx=*/%v104220_v10 (stack76)
        %v104618_v46 = vxor.u32 2147483648, %v152392_v43 (stack56)
        %v104226_v21 = vadd.f32 -3.0, %v104223_v27 (stack53)
        %v105041_v54 = vor.u32 %v105040_v45, %v105039_v31 (stack47)
        %v105431_v52 = vxor.u32 %v105430_v61, %v105426_v23 (stack48)
        %v105843_v9 = vadd.s32 %v105840_v20, %v105835_v9 (stack40)
        %v104207_v55 = vsel /*vm=*/%vm104174_vm15, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v104211_v42 = vsel /*vm=*/%vm104174_vm15, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v152415_v60 = vmul.f32 %v104618_v46, %v152392_v43 (stack54)
        %v105845_v53 = vshll.u32 %v105840_v20, 16 (stack45)
        %v152420_v7 = vsel /*vm=*/%vm104174_vm15, /*on_true_vy=*/%v152361_v7, /*on_false_vx=*/%v104226_v21 (stack44)
        %v105042_v24 = vxor.u32 %v105041_v54, %v105037_v8 (stack48)
        %v105434_v23 = vadd.s32 %v105431_v52, %v105426_v23 (stack40)
        %v105846_v31 = vshrl.u32 %v105840_v20, 16 (stack46)
        %v104234_v45 = vmul.f32 %v152420_v7, %v104211_v42 (stack54)
        %v104623_v10 = vadd.f32 1.0, %v152415_v60 (stack57)
        %vm106666_vm3 = vcmp.lt.u32.totalorder %v152365_v41, %v152327_v29 (stack43)
        %v106680_v61 = vadd.s32 1, %v152333_v30 (stack40)
        %v105045_v8 = vadd.s32 %v105042_v24, %v105037_v8 (stack40)
        %v105047_v20 = vshll.u32 %v105042_v24, 15 (stack45)
        %v105048_v27 = vshrl.u32 %v105042_v24, 17 (stack46)
        %v105440_v46 = vshll.u32 %v105431_v52, 6 (stack45)
        %v104238_v21 = vadd.f32 %v104234_v45, %v104207_v55 (stack53)
        %121325 = vlog2.f32 %v104623_v10 (stack58)
        %v104626_v54 = vmul.f32 -0.5, %v152415_v60 (stack59)
        %v152430_v55 = vadd.s32 %v152365_v41, %v121569_v1 (stack40)
        %v105049_v42 = vor.u32 %v105048_v27, %v105047_v20 (stack47)
        %v105441_v52 = vshrl.u32 %v105431_v52, 26 (stack46)
        %v105847_v53 = vor.u32 %v105846_v31, %v105845_v53 (stack47)
        %v106262_v24 = vshll.u32 %v106257_v26, 26 (stack45)
        %v104242_v31 = vmul.f32 %v104238_v21, %v152420_v7 (stack54)
        %v104629_v45 = vand.u32 2147483647, %v152415_v60 (stack60)
        %v106263_v26 = vshrl.u32 %v106257_v26, 6 (stack46)
        %v106684_v30 = vsel /*vm=*/%vm106671_vm14, /*on_true_vy=*/%v106680_v61, /*on_false_vx=*/%v152333_v30 (stack44)
        %v105050_v10 = vxor.u32 %v105049_v42, %v105045_v8 (stack48)
        %v105442_v61 = vor.u32 %v105441_v52, %v105440_v46 (stack47)
        %v105848_v20 = vxor.u32 %v105847_v53, %v105843_v9 (stack48)
        %v106688_v27 = vadd.s32 1, %v106684_v30 (stack40)
        %v104246_v44 = vadd.f32 %v104242_v31, %v104203_v44 (stack53)
        %v104627_v46 = vadd.f32 1.0, %v104626_v54 (stack61)
        %v105438_v21 = vadd.s32 %v105434_v23, %v121574_v2 (stack40)
        %v106264_v54 = vor.u32 %v106263_v26, %v106262_v24 (stack47)
        %v105053_v8 = vadd.s32 %v105050_v10, %v105045_v8 (stack40)
        %v105055_v42 = vshll.u32 %v105050_v10, 26 (stack45)
        %v105056_v52 = vshrl.u32 %v105050_v10, 6 (stack46)
        %v105443_v23 = vxor.u32 %v105442_v61, %v105434_v23 (stack48)
        %v104250_v53 = vmul.f32 %v104246_v44, %v152420_v7 (stack54)
        %v105851_v9 = vadd.s32 %v105848_v20, %v105843_v9 (stack40)
        %v105857_v24 = vshll.u32 %v105848_v20, 24 (stack45)
        %v105858_v31 = vshrl.u32 %v105848_v20, 8 (stack46)
        %v105057_v26 = vor.u32 %v105056_v52, %v105055_v42 (stack47)
        %v105446_v10 = vadd.s32 %v105443_v23, %v121569_v1 (stack40)
        %v106265_v61 = vxor.u32 %v106264_v54, %v152397_v50 (stack48)
        %v106692_v29 = vsel /*vm=*/%vm106666_vm3, /*on_true_vy=*/%v106688_v27, /*on_false_vx=*/%v106684_v30 (stack44)
        %v104254_v41 = vadd.f32 %v104250_v53, %v104199_v22 (stack53)
        %vm152445_vm4 = vcmp.lt.f32.partialorder %v104629_v45, 0.0004427343 (stack62)
        %v105859_v45 = vor.u32 %v105858_v31, %v105857_v24 (stack47)
        %v106697_v30 = vadd.s32 %v106692_v29, %v121574_v2 (stack40)
        %v105058_v20 = vxor.u32 %v105057_v26, %v105053_v8 (stack48)
        %v105450_v27 = vadd.s32 3, %v105446_v10 (stack40)
        %v152451_v50 = vadd.s32 %v106265_v61, %v152397_v50 (stack40)
        %v106274_v44 = vshll.u32 %v106265_v61, 6 (stack45)
        %v104258_v54 = vmul.f32 %v104254_v41, %v152420_v7 (stack54)
        %v105860_v42 = vxor.u32 %v105859_v45, %v105851_v9 (stack48)
        %v106275_v52 = vshrl.u32 %v106265_v61, 26 (stack46)
        %v152455_v23 = vadd.s32 %v152430_v55, %v106697_v30 (stack40)
        %v105061_v8 = vadd.s32 %v105058_v20, %v105053_v8 (stack40)
        %v105067_v53 = vshll.u32 %v105058_v20, 6 (stack45)
        %v105068_v24 = vshrl.u32 %v105058_v20, 26 (stack46)
        %v105454_v21 = vadd.s32 %v105450_v27, %v105438_v21 (stack40)
        %v104262_v25 = vadd.f32 %v104258_v54, %v152375_v25 (stack53)
        %v105456_v31 = vshll.u32 %v105450_v27, 17 (stack45)
        %v105457_v26 = vshrl.u32 %v105450_v27, 15 (stack46)
        %v105863_v10 = vadd.s32 %v105860_v42, %v121574_v2 (stack40)
        %v121326_v61 = vpop.eup %121325 (stack64)
        %v104628_v60 = vmul.f32 %v104627_v46, %v152415_v60 (stack63)
        %v105069_v46 = vor.u32 %v105068_v24, %v105067_v53 (stack47)
        %v105855_v9 = vadd.s32 %v105851_v9, %v121564_v0 (stack40)
        %v106276_v29 = vor.u32 %v106275_v52, %v106274_v44 (stack47)
        %v104266_v41 = vmul.f32 %v104262_v25, %v152420_v7 (stack54)
        %v104625_v45 = vmul.f32 0.6931472, %v121326_v61 (stack65)
        %v105458_v30 = vor.u32 %v105457_v26, %v105456_v31 (stack47)
        %v105867_v20 = vadd.s32 2, %v105863_v10 (stack40)
        %v105070_v27 = vxor.u32 %v105069_v46, %v105061_v8 (stack48)
        %v106277_v44 = vxor.u32 %v106276_v29, %v152451_v50 (stack48)
        %v106707_v54 = vshll.u32 %v152430_v55, 13 (stack45)
        %v106708_v55 = vshrl.u32 %v152430_v55, 19 (stack46)
        %v104270_v6 = vadd.f32 %v104266_v41, %v152370_v6 (stack53)
        %v104631_v22 = vsel /*vm=*/%vm152445_vm4, /*on_true_vy=*/%v104628_v60, /*on_false_vx=*/%v104625_v45 (stack66)
        %v105459_v42 = vxor.u32 %v105458_v30, %v105454_v21 (stack48)
        %v105871_v52 = vadd.s32 %v105867_v20, %v105855_v9 (stack40)
        %v104147_v53 = vand.u32 2147483647, %v152290_v56 (stack77)
        %v152470_v24 = vmul.f32 inf, %v152290_v56 (stack54)
        %v104179_v25 = vsel /*vm=*/%vm104174_vm15, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v152475_v31 = vxor.u32 2147483648, %v104631_v22 (stack56)
        %v104274_v26 = vmul.f32 %v104270_v6, %v152420_v7 (stack54)
        %v105462_v21 = vadd.s32 %v105459_v42, %v105454_v21 (stack40)
        %v105464_v10 = vshll.u32 %v105459_v42, 29 (stack45)
        %v105465_v61 = vshrl.u32 %v105459_v42, 3 (stack46)
        %v104187_v60 = vsel /*vm=*/%vm104174_vm15, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %121327 = vrsqrt.f32 %v152475_v31 (stack67)
        %v105073_v46 = vadd.s32 %v105070_v27, %v121574_v2 (stack40)
        %v106709_v9 = vor.u32 %v106708_v55, %v106707_v54 (stack47)
        %v104278_v29 = vadd.f32 %v104274_v26, %v104187_v60 (stack53)
        %vm104635_vm5 = vcmp.lt.f32.partialorder %v152475_v31, 5.0 (stack68)
        %v105873_v41 = vshll.u32 %v105867_v20, 13 (stack45)
        %v105874_v45 = vshrl.u32 %v105867_v20, 19 (stack46)
        %v104183_v32 = vsel /*vm=*/%vm104174_vm15, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v104608_v30 = vand.u32 2147483647, %v152392_v43 (stack77)
        %v105065_v8 = vadd.s32 %v105061_v8, %v121564_v0 (stack40)
        %v105466_v20 = vor.u32 %v105465_v61, %v105464_v10 (stack47)
        %v104282_v27 = vmul.f32 %v104278_v29, %v152420_v7 (stack54)
        %v152491_v54 = vadd.f32 -2.5, %v152475_v31 (stack53)
        %v106272_v50 = vadd.s32 %v152451_v50, %v121569_v1 (stack40)
        %v152497_v55 = vadd.s32 %v152389_v34, %v122657_v58 (stack40)
        %vm152499_vm6 = vcmp.eq.f32.partialorder %v104147_v53, 1.0 (stack68)
        %v152506_v22 = vsel /*vm=*/%vm104635_vm5, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v152511_v42 = vsel /*vm=*/%vm104635_vm5, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v105077_v53 = vadd.s32 5, %v105073_v46 (stack40)
        %v105467_v26 = vxor.u32 %v105466_v20, %v105462_v21 (stack48)
        %v104286_v10 = vadd.f32 %v104282_v27, %v104183_v32 (stack53)
        %v105875_v61 = vor.u32 %v105874_v45, %v105873_v41 (stack47)
        %v106280_v44 = vadd.s32 %v106277_v44, %v121564_v0 (stack40)
        %v106710_v60 = vxor.u32 %v106709_v9, %v152455_v23 (stack48)
        %v105079_v46 = vxor.u32 %v105077_v53, %v105065_v8 (stack48)
        %v105470_v21 = vadd.s32 %v105467_v26, %v105462_v21 (stack40)
        %v105472_v9 = vshll.u32 %v105467_v26, 16 (stack45)
        %v105473_v29 = vshrl.u32 %v105467_v26, 16 (stack46)
        %v104290_v7 = vmul.f32 %v104286_v10, %v152420_v7 (stack54)
        %vm104680_vm7 = vcmp.eq.f32.partialorder %v152475_v31, inf (stack70)
        %v105876_v41 = vxor.u32 %v105875_v61, %v105871_v52 (stack48)
        %v106284_v45 = vadd.s32 1, %v106280_v44 (stack40)
        %v106713_v23 = vadd.s32 %v106710_v60, %v152455_v23 (stack40)
        %vm104682_vm8 = vcmp.eq.f32.partialorder %v152475_v31, 0.0 (stack71)
        %v105080_v32 = vand.u32.u8 255, %v105079_v46 (stack49)
        %v105474_v8 = vor.u32 %v105473_v29, %v105472_v9 (stack47)
        %v106715_v20 = vshll.u32 %v106710_v60, 15 (stack45)
        %v106716_v27 = vshrl.u32 %v106710_v60, 17 (stack46)
        %v104294_v25 = vadd.f32 %v104290_v7, %v104179_v25 (stack53)
        %v105879_v52 = vadd.s32 %v105876_v41, %v105871_v52 (stack40)
        %v105881_v53 = vshll.u32 %v105876_v41, 15 (stack45)
        %v105882_v26 = vshrl.u32 %v105876_v41, 17 (stack46)
        %v105081_v10 = vand.u32 65535, %v105080_v32 (stack50)
        %v105475_v61 = vxor.u32 %v105474_v8, %v105470_v21 (stack48)
        %v106288_v50 = vadd.s32 %v106284_v45, %v106272_v50 (stack40)
        %v106290_v44 = vshll.u32 %v106284_v45, 17 (stack45)
        %v104298_v56 = vmul.f32 %v104294_v25, %v152290_v56 (stack54)
        %v105883_v60 = vor.u32 %v105882_v26, %v105881_v53 (stack47)
        %v106291_v46 = vshrl.u32 %v106284_v45, 15 (stack46)
        %v106717_v9 = vor.u32 %v106716_v27, %v106715_v20 (stack47)
        %v105082_v29 = vshrl.u32 %v105081_v10, 1 (stack51)
        %v105478_v21 = vadd.s32 %v105475_v61, %v105470_v21 (stack40)
        %v105484_v7 = vshll.u32 %v105475_v61, 24 (stack45)
        %v105485_v41 = vshrl.u32 %v105475_v61, 8 (stack46)
        %v121328_v45 = vpop.eup %121327 (stack73)
        %v104302_v24 = vsel /*vm=*/%vm152499_vm6, /*on_true_vy=*/%v152470_v24, /*on_false_vx=*/%v104298_v56 (stack44)
        %v105884_v6 = vxor.u32 %v105883_v60, %v105879_v52 (stack48)
        %v106292_v32 = vor.u32 %v106291_v46, %v106290_v44 (stack47)
        %v106718_v8 = vxor.u32 %v106717_v9, %v106713_v23 (stack48)
        %v104306_v20 = vmul.f32 1.4140625, %v104302_v24 (stack54)
        %v104679_v27 = vmul.f32 %v121328_v45, %v152475_v31 (stack74)
        %v104683_v25 = vand.u32 2147483648, %v152475_v31 (stack72)
        %v105083_v53 = vor.u32 16256, %v105082_v29 (stack47)
        %v105486_v26 = vor.u32 %v105485_v41, %v105484_v7 (stack47)
        %v105887_v52 = vadd.s32 %v105884_v6, %v105879_v52 (stack40)
        %v105889_v10 = vshll.u32 %v105884_v6, 26 (stack45)
        %v105890_v61 = vshrl.u32 %v105884_v6, 6 (stack46)
        %v104309_v44 = vpack.c.bf16 %v157387_v11, %v104306_v20 (stack81)
        %v104681_v56 = vsel /*vm=*/%vm104680_vm7, /*on_true_vy=*/%v152475_v31, /*on_false_vx=*/%v104679_v27 (stack75)
        %v105084_v60 = vand.u32.u16 65535, %v105083_v53 (stack52)
        %v106293_v46 = vxor.u32 %v106292_v32, %v106288_v50 (stack48)
        %v104684_v9 = vsel /*vm=*/%vm104682_vm8, /*on_true_vy=*/%v104683_v25, /*on_false_vx=*/%v104681_v56 (stack76)
        %v105487_v29 = vxor.u32 %v105486_v26, %v105478_v21 (stack48)
        %v105891_v7 = vor.u32 %v105890_v61, %v105889_v10 (stack47)
        %v106721_v23 = vadd.s32 %v106718_v8, %v106713_v23 (stack40)
        %120301 = vst [vmem:[%s123356_s30 + $0x36c] sm:$0xf] /*vst_source=*/%v104309_v44 (stack83)
        %v104687_v41 = vadd.f32 -3.0, %v104684_v9 (stack53)
        %v120308_v45 = vadd.low.f32.bf16 -1.0, %v105084_v60 (stack53)
        %v106296_v50 = vadd.s32 %v106293_v46, %v106288_v50 (stack40)
        %v106298_v24 = vshll.u32 %v106293_v46, 29 (stack45)
        %v105490_v6 = vadd.s32 %v105487_v29, %v121564_v0 (stack40)
        %v105892_v32 = vxor.u32 %v105891_v7, %v105887_v52 (stack48)
        %v106299_v20 = vshrl.u32 %v106293_v46, 3 (stack46)
        %v106723_v27 = vshll.u32 %v106718_v8, 26 (stack45)
        %v152536_v54 = vsel /*vm=*/%vm104635_vm5, /*on_true_vy=*/%v152491_v54, /*on_false_vx=*/%v104687_v41 (stack44)
        %v105093_v25 = vmul.f32 2.0, %v120308_v45 (stack54)
        %v105482_v21 = vadd.s32 %v105478_v21, %v121569_v1 (stack40)
        %v106724_v8 = vshrl.u32 %v106718_v8, 6 (stack46)
        %v104695_v42 = vmul.f32 %v152536_v54, %v152511_v42 (stack54)
        %v105494_v53 = vadd.s32 4, %v105490_v6 (stack40)
        %v105895_v26 = vadd.s32 %v105892_v32, %v105887_v52 (stack40)
        %v105901_v52 = vshll.u32 %v105892_v32, 6 (stack45)
        %v105097_v10 = vadd.f32 -0.99609375, %v105093_v25 (stack53)
        %v105902_v61 = vshrl.u32 %v105892_v32, 26 (stack46)
        %v106300_v44 = vor.u32 %v106299_v20, %v106298_v24 (stack47)
        %v106725_v56 = vor.u32 %v106724_v8, %v106723_v27 (stack47)
        %v104699_v22 = vadd.f32 %v104695_v42, %v152506_v22 (stack53)
        %v105498_v60 = vadd.s32 %v105494_v53, %v105482_v21 (stack40)
        %v105500_v46 = vshll.u32 %v105494_v53, 13 (stack45)
        %v105501_v9 = vshrl.u32 %v105494_v53, 19 (stack46)
        %v152545_v29 = vsel /*vm=*/%vm104635_vm5, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v152547_v7 = vmax.f32 %v105097_v10, -0.99609375 (stack55)
        %v105903_v41 = vor.u32 %v105902_v61, %v105901_v52 (stack47)
        %v106301_v45 = vxor.u32 %v106300_v44, %v106296_v50 (stack48)
        %v104703_v24 = vmul.f32 %v104699_v22, %v152536_v54 (stack54)
        %v105502_v6 = vor.u32 %v105501_v9, %v105500_v46 (stack47)
        %v106726_v32 = vxor.u32 %v106725_v56, %v106721_v23 (stack48)
        %vm107132_vm9 = vcmp.lt.u32.totalorder %v152389_v34, %v157089_v17 (stack43)
        %v152555_v20 = vsel /*vm=*/%vm104635_vm5, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v104664_v27 = vsel /*vm=*/%vm104635_vm5, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v105113_v25 = vxor.u32 2147483648, %v152547_v7 (stack56)
        %v105904_v21 = vxor.u32 %v105903_v41, %v105895_v26 (stack48)
        %v104707_v8 = vadd.f32 %v104703_v24, %v104664_v27 (stack53)
        %v105503_v42 = vxor.u32 %v105502_v6, %v105498_v60 (stack48)
        %v106304_v50 = vadd.s32 %v106301_v45, %v106296_v50 (stack40)
        %v106306_v53 = vshll.u32 %v106301_v45, 16 (stack45)
        %v104648_v52 = vsel /*vm=*/%vm104635_vm5, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v152565_v10 = vmul.f32 %v105113_v25, %v152547_v7 (stack54)
        %v105907_v61 = vadd.s32 %v105904_v21, %v121569_v1 (stack40)
        %v106307_v44 = vshrl.u32 %v106301_v45, 16 (stack46)
        %v104711_v56 = vmul.f32 %v104707_v8, %v152536_v54 (stack54)
        %v105506_v22 = vadd.s32 %v105503_v42, %v105498_v60 (stack40)
        %v105508_v60 = vshll.u32 %v105503_v42, 15 (stack45)
        %v105509_v46 = vshrl.u32 %v105503_v42, 17 (stack46)
        %v104660_v9 = vsel /*vm=*/%vm104635_vm5, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v105118_v41 = vadd.f32 1.0, %v152565_v10 (stack57)
        %v105899_v26 = vadd.s32 %v105895_v26, %v121574_v2 (stack40)
        %v105911_v45 = vadd.s32 3, %v105907_v61 (stack40)
        %v104715_v24 = vadd.f32 %v104711_v56, %v104660_v9 (stack53)
        %v105510_v6 = vor.u32 %v105509_v46, %v105508_v60 (stack47)
        %v106308_v27 = vor.u32 %v106307_v44, %v106306_v53 (stack47)
        %v152574_v23 = vadd.s32 %v106726_v32, %v106721_v23 (stack40)
        %v104652_v25 = vsel /*vm=*/%vm104635_vm5, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v104656_v31 = vsel /*vm=*/%vm104635_vm5, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %121329 = vlog2.f32 %v105118_v41 (stack58)
        %v105915_v21 = vadd.s32 %v105911_v45, %v105899_v26 (stack40)
        %v104719_v8 = vmul.f32 %v104715_v24, %v152536_v54 (stack54)
        %v105511_v42 = vxor.u32 %v105510_v6, %v105506_v22 (stack48)
        %v105917_v53 = vshll.u32 %v105911_v45, 17 (stack45)
        %v105918_v61 = vshrl.u32 %v105911_v45, 15 (stack46)
        %v105121_v44 = vmul.f32 -0.5, %v152565_v10 (stack59)
        %v106309_v56 = vxor.u32 %v106308_v27, %v106304_v50 (stack48)
        %v106735_v60 = vshll.u32 %v106726_v32, 6 (stack45)
        %vm107127_vm10 = vcmp.lt.u32.totalorder %v152497_v55, %v152389_v34 (stack43)
        %v104723_v46 = vadd.f32 %v104719_v8, %v104656_v31 (stack53)
        %v105514_v22 = vadd.s32 %v105511_v42, %v105506_v22 (stack40)
        %v105516_v9 = vshll.u32 %v105511_v42, 26 (stack45)
        %v105517_v41 = vshrl.u32 %v105511_v42, 6 (stack46)
        %v105919_v26 = vor.u32 %v105918_v61, %v105917_v53 (stack47)
        %v106312_v50 = vadd.s32 %v106309_v56, %v106304_v50 (stack40)
        %v106318_v45 = vshll.u32 %v106309_v56, 24 (stack45)
        %v106319_v24 = vshrl.u32 %v106309_v56, 8 (stack46)
        %v104727_v6 = vmul.f32 %v104723_v46, %v152536_v54 (stack54)
        %v105518_v27 = vor.u32 %v105517_v41, %v105516_v9 (stack47)
        %v106736_v32 = vshrl.u32 %v106726_v32, 26 (stack46)
        %v107137_v31 = vadd.s32 %v157742_v12, %v157090_v62 (stack40)
        %v105122_v8 = vadd.f32 1.0, %v105121_v44 (stack61)
        %v105124_v42 = vand.u32 2147483647, %v152565_v10 (stack60)
        %v105920_v53 = vxor.u32 %v105919_v26, %v105915_v21 (stack48)
        %v106320_v61 = vor.u32 %v106319_v24, %v106318_v45 (stack47)
        %v104731_v25 = vadd.f32 %v104727_v6, %v104652_v25 (stack53)
        %v105519_v44 = vxor.u32 %v105518_v27, %v105514_v22 (stack48)
        %v106737_v56 = vor.u32 %v106736_v32, %v106735_v60 (stack47)
        %v107141_v60 = vadd.s32 1, %v107137_v31 (stack40)
        %v105923_v21 = vadd.s32 %v105920_v53, %v105915_v21 (stack40)
        %v105925_v46 = vshll.u32 %v105920_v53, 29 (stack45)
        %v105926_v9 = vshrl.u32 %v105920_v53, 3 (stack46)
        %v106321_v41 = vxor.u32 %v106320_v61, %v106312_v50 (stack48)
        %v104735_v26 = vmul.f32 %v104731_v25, %v152536_v54 (stack54)
        %v105522_v22 = vadd.s32 %v105519_v44, %v105514_v22 (stack40)
        %v105528_v45 = vshll.u32 %v105519_v44, 6 (stack45)
        %v105529_v24 = vshrl.u32 %v105519_v44, 26 (stack46)
        %v105927_v6 = vor.u32 %v105926_v9, %v105925_v46 (stack47)
        %v106324_v27 = vadd.s32 %v106321_v41, %v121574_v2 (stack40)
        %v106738_v32 = vxor.u32 %v106737_v56, %v152574_v23 (stack48)
        %v107145_v31 = vsel /*vm=*/%vm107132_vm9, /*on_true_vy=*/%v107141_v60, /*on_false_vx=*/%v107137_v31 (stack44)
        %v104739_v52 = vadd.f32 %v104735_v26, %v104648_v52 (stack53)
        %vm152596_vm11 = vcmp.lt.f32.partialorder %v105124_v42, 0.0004427343 (stack62)
        %v105530_v53 = vor.u32 %v105529_v24, %v105528_v45 (stack47)
        %v107149_v61 = vadd.s32 1, %v107145_v31 (stack40)
        %v105123_v10 = vmul.f32 %v105122_v8, %v152565_v10 (stack63)
        %v105928_v8 = vxor.u32 %v105927_v6, %v105923_v21 (stack48)
        %v106328_v25 = vadd.s32 2, %v106324_v27 (stack40)
        %v106741_v44 = vadd.s32 %v106738_v32, %v121564_v0 (stack40)
        %v121330_v56 = vpop.eup %121329 (stack64)
        %v104743_v60 = vmul.f32 %v104739_v52, %v152536_v54 (stack54)
        %v105531_v46 = vxor.u32 %v105530_v53, %v105522_v22 (stack48)
        %v106316_v50 = vadd.s32 %v106312_v50, %v121564_v0 (stack40)
        %v107153_v34 = vsel /*vm=*/%vm107127_vm10, /*on_true_vy=*/%v107149_v61, /*on_false_vx=*/%v107145_v31 (stack44)
        %v105120_v9 = vmul.f32 0.6931472, %v121330_v56 (stack65)
        %v105931_v21 = vadd.s32 %v105928_v8, %v105923_v21 (stack40)
        %v105933_v41 = vshll.u32 %v105928_v8, 16 (stack45)
        %v105934_v26 = vshrl.u32 %v105928_v8, 16 (stack46)
        %v104747_v20 = vadd.f32 %v104743_v60, %v152555_v20 (stack53)
        %v105534_v45 = vadd.s32 %v105531_v46, %v121574_v2 (stack40)
        %v106332_v24 = vadd.s32 %v106328_v25, %v106316_v50 (stack40)
        %v106733_v23 = vadd.s32 %v152574_v23, %v121569_v1 (stack40)
        %v105126_v6 = vsel /*vm=*/%vm152596_vm11, /*on_true_vy=*/%v105123_v10, /*on_false_vx=*/%v105120_v9 (stack66)
        %v105935_v27 = vor.u32 %v105934_v26, %v105933_v41 (stack47)
        %v106334_v32 = vshll.u32 %v106328_v25, 13 (stack45)
        %v106745_v31 = vadd.s32 1, %v106741_v44 (stack40)
        %v104751_v54 = vmul.f32 %v104747_v20, %v152536_v54 (stack54)
        %v152614_v52 = vxor.u32 2147483648, %v105126_v6 (stack56)
        %v105538_v42 = vadd.s32 5, %v105534_v45 (stack40)
        %v106335_v53 = vshrl.u32 %v106328_v25, 19 (stack46)
        %v105526_v22 = vadd.s32 %v105522_v22, %v121564_v0 (stack40)
        %v105936_v61 = vxor.u32 %v105935_v27, %v105931_v21 (stack48)
        %v106749_v10 = vadd.s32 %v106745_v31, %v106733_v23 (stack40)
        %v107162_v55 = vadd.s32 %v152497_v55, %v121569_v1 (stack40)
        %v104755_v29 = vadd.f32 %v104751_v54, %v152545_v29 (stack53)
        %121331 = vrsqrt.f32 %v152614_v52 (stack67)
        %v104616_v8 = vmul.f32 inf, %v152392_v43 (stack54)
        %vm105130_vm12 = vcmp.lt.f32.partialorder %v152614_v52, 5.0 (stack68)
        %v105540_v25 = vxor.u32 %v105538_v42, %v105526_v22 (stack48)
        %vm104611_vm13 = vcmp.eq.f32.partialorder %v104608_v30, 1.0 (stack68)
        %v104759_v43 = vmul.f32 %v104755_v29, %v152392_v43 (stack54)
        %v106336_v30 = vor.u32 %v106335_v53, %v106334_v32 (stack47)
        %v107158_v44 = vadd.s32 %v107153_v34, %v121574_v2 (stack40)
        %v105939_v56 = vadd.s32 %v105936_v61, %v105931_v21 (stack40)
        %v106751_v60 = vshll.u32 %v106745_v31, 17 (stack45)
        %v107168_v46 = vshll.u32 %v107162_v55, 13 (stack45)
        %v107169_v50 = vshrl.u32 %v107162_v55, 19 (stack46)
        %v104763_v34 = vsel /*vm=*/%vm104611_vm13, /*on_true_vy=*/%v104616_v8, /*on_false_vx=*/%v104759_v43 (stack44)
        %v152630_v9 = vsel /*vm=*/%vm105130_vm12, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v152635_v21 = vsel /*vm=*/%vm105130_vm12, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v152638_v41 = vadd.f32 -2.5, %v152614_v52 (stack53)
        %v104767_v26 = vmul.f32 1.4140625, %v104763_v34 (stack54)
        %v152643_v20 = vsel /*vm=*/%vm105130_vm12, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v105541_v45 = vand.u32.u8 255, %v105540_v25 (stack49)
        %v105945_v23 = vshll.u32 %v105936_v61, 24 (stack45)
        %v105946_v6 = vshrl.u32 %v105936_v61, 8 (stack46)
        %v106337_v27 = vxor.u32 %v106336_v30, %v106332_v24 (stack48)
        %v106752_v32 = vshrl.u32 %v106745_v31, 15 (stack46)
        %v107166_v31 = vadd.s32 %v107162_v55, %v107158_v44 (stack40)
        %v104770_v54 = vpack.c.bf16 %v157387_v11, %v104767_v26 (stack81)
        %vm105175_vm14 = vcmp.eq.f32.partialorder %v152614_v52, inf (stack70)
        %v105542_v42 = vand.u32 65535, %v105541_v45 (stack50)
        %v107170_v53 = vor.u32 %v107169_v50, %v107168_v46 (stack47)
        %v152649_v22 = vadd.s32 %v157741_v40, %v157091_v37 (stack40)
        %vm105177_vm15 = vcmp.eq.f32.partialorder %v152614_v52, 0.0 (stack71)
        %v105947_v61 = vor.u32 %v105946_v6, %v105945_v23 (stack47)
        %v106340_v24 = vadd.s32 %v106337_v27, %v106332_v24 (stack40)
        %v106342_v55 = vshll.u32 %v106337_v27, 15 (stack45)
        %v106343_v29 = vshrl.u32 %v106337_v27, 17 (stack46)
        %120303 = vst [vmem:[%s123356_s30 + $0x3ec] sm:$0xf] /*vst_source=*/%v104770_v54 (stack83)
        %v105178_v8 = vand.u32 2147483648, %v152614_v52 (stack72)
        %v105543_v25 = vshrl.u32 %v105542_v42, 1 (stack51)
        %v106753_v43 = vor.u32 %v106752_v32, %v106751_v60 (stack47)
        %v107171_v30 = vxor.u32 %v107170_v53, %v107166_v31 (stack48)
        %v105948_v44 = vxor.u32 %v105947_v61, %v105939_v56 (stack48)
        %v106344_v60 = vor.u32 %v106343_v29, %v106342_v55 (stack47)
        %vm107593_vm0 = vcmp.lt.u32.totalorder %v152649_v22, %v157091_v37 (stack43)
        %v152658_v46 = vadd.s32 %v157742_v12, %v157094_v36 (stack40)
        %v105544_v50 = vor.u32 16256, %v105543_v25 (stack47)
        %v106754_v34 = vxor.u32 %v106753_v43, %v106749_v10 (stack48)
        %v107174_v26 = vadd.s32 %v107171_v30, %v107166_v31 (stack40)
        %v107176_v45 = vshll.u32 %v107171_v30, 15 (stack45)
        %v105943_v56 = vadd.s32 %v105939_v56, %v121569_v1 (stack40)
        %v105951_v23 = vadd.s32 %v105948_v44, %v121564_v0 (stack40)
        %v106345_v6 = vxor.u32 %v106344_v60, %v106340_v24 (stack48)
        %v107177_v27 = vshrl.u32 %v107171_v30, 17 (stack46)
        %v121332_v32 = vpop.eup %121331 (stack73)
        %v105545_v31 = vand.u32.u16 65535, %v105544_v50 (stack52)
        %v106757_v10 = vadd.s32 %v106754_v34, %v106749_v10 (stack40)
        %v106759_v54 = vshll.u32 %v106754_v34, 29 (stack45)
        %v106760_v42 = vshrl.u32 %v106754_v34, 3 (stack46)
        %v105174_v53 = vmul.f32 %v121332_v32, %v152614_v52 (stack74)
        %v105955_v61 = vadd.s32 4, %v105951_v23 (stack40)
        %v106348_v24 = vadd.s32 %v106345_v6, %v106340_v24 (stack40)
        %v106350_v55 = vshll.u32 %v106345_v6, 26 (stack45)
        %v120310_v29 = vadd.low.f32.bf16 -1.0, %v105545_v31 (stack53)
        %v106351_v25 = vshrl.u32 %v106345_v6, 6 (stack46)
        %v106761_v43 = vor.u32 %v106760_v42, %v106759_v54 (stack47)
        %v107178_v30 = vor.u32 %v107177_v27, %v107176_v45 (stack47)
        %v105176_v44 = vsel /*vm=*/%vm105175_vm14, /*on_true_vy=*/%v152614_v52, /*on_false_vx=*/%v105174_v53 (stack75)
        %v105959_v60 = vadd.s32 %v105955_v61, %v105943_v56 (stack40)
        %v105961_v50 = vshll.u32 %v105955_v61, 13 (stack45)
        %v105962_v34 = vshrl.u32 %v105955_v61, 19 (stack46)
        %v105179_v8 = vsel /*vm=*/%vm105177_vm15, /*on_true_vy=*/%v105178_v8, /*on_false_vx=*/%v105176_v44 (stack76)
        %v105554_v45 = vmul.f32 2.0, %v120310_v29 (stack54)
        %v106352_v56 = vor.u32 %v106351_v25, %v106350_v55 (stack47)
        %v106762_v23 = vxor.u32 %v106761_v43, %v106757_v10 (stack48)
        %v105167_v6 = vsel /*vm=*/%vm105130_vm12, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v105182_v27 = vadd.f32 -3.0, %v105179_v8 (stack53)
        %v105963_v32 = vor.u32 %v105962_v34, %v105961_v50 (stack47)
        %v107179_v31 = vxor.u32 %v107178_v30, %v107174_v26 (stack48)
        %v105558_v54 = vadd.f32 -0.99609375, %v105554_v45 (stack53)
        %v106353_v42 = vxor.u32 %v106352_v56, %v106348_v24 (stack48)
        %v106765_v10 = vadd.s32 %v106762_v23, %v106757_v10 (stack40)
        %v106767_v53 = vshll.u32 %v106762_v23, 16 (stack45)
        %v152674_v41 = vsel /*vm=*/%vm105130_vm12, /*on_true_vy=*/%v152638_v41, /*on_false_vx=*/%v105182_v27 (stack44)
        %v105964_v61 = vxor.u32 %v105963_v32, %v105959_v60 (stack48)
        %v106768_v55 = vshrl.u32 %v106762_v23, 16 (stack46)
        %v107182_v26 = vadd.s32 %v107179_v31, %v107174_v26 (stack40)
        %v105190_v29 = vmul.f32 %v152674_v41, %v105167_v6 (stack54)
        %v152677_v25 = vmax.f32 %v105558_v54, -0.99609375 (stack55)
        %v106356_v24 = vadd.s32 %v106353_v42, %v106348_v24 (stack40)
        %v106362_v43 = vshll.u32 %v106353_v42, 6 (stack45)
        %v105967_v30 = vadd.s32 %v105964_v61, %v105959_v60 (stack40)
        %v105969_v44 = vshll.u32 %v105964_v61, 15 (stack45)
        %v105970_v60 = vshrl.u32 %v105964_v61, 17 (stack46)
        %v106363_v50 = vshrl.u32 %v106353_v42, 26 (stack46)
        %v105151_v34 = vsel /*vm=*/%vm105130_vm12, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v105155_v8 = vsel /*vm=*/%vm105130_vm12, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v105194_v20 = vadd.f32 %v105190_v29, %v152643_v20 (stack53)
        %v105574_v45 = vxor.u32 2147483648, %v152677_v25 (stack56)
        %v105159_v56 = vsel /*vm=*/%vm105130_vm12, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v105971_v23 = vor.u32 %v105970_v60, %v105969_v44 (stack47)
        %v106364_v6 = vor.u32 %v106363_v50, %v106362_v43 (stack47)
        %v106769_v27 = vor.u32 %v106768_v55, %v106767_v53 (stack47)
        %v105198_v32 = vmul.f32 %v105194_v20, %v152674_v41 (stack54)
        %v105577_v54 = vmul.f32 %v105574_v45, %v152677_v25 (stack54)
        %v152694_v42 = vadd.s32 %v152649_v22, %v122657_v58 (stack40)
        %v107602_v53 = vadd.s32 1, %v152658_v46 (stack40)
        %v105972_v61 = vxor.u32 %v105971_v23, %v105967_v30 (stack48)
        %v106365_v55 = vxor.u32 %v106364_v6, %v106356_v24 (stack48)
        %v106770_v29 = vxor.u32 %v106769_v27, %v106765_v10 (stack48)
        %v107184_v43 = vshll.u32 %v107179_v31, 26 (stack45)
        %v105202_v44 = vadd.f32 %v105198_v32, %v105159_v56 (stack53)
        %v105579_v60 = vadd.f32 1.0, %v105577_v54 (stack57)
        %v105582_v50 = vmul.f32 -0.5, %v105577_v54 (stack59)
        %v107185_v31 = vshrl.u32 %v107179_v31, 6 (stack46)
        %v105975_v30 = vadd.s32 %v105972_v61, %v105967_v30 (stack40)
        %v105977_v20 = vshll.u32 %v105972_v61, 26 (stack45)
        %v105978_v45 = vshrl.u32 %v105972_v61, 6 (stack46)
        %v106368_v56 = vadd.s32 %v106365_v55, %v121569_v1 (stack40)
        %v105206_v23 = vmul.f32 %v105202_v44, %v152674_v41 (stack54)
        %121333 = vlog2.f32 %v105579_v60 (stack58)
        %v105583_v6 = vadd.f32 1.0, %v105582_v50 (stack61)
        %v106360_v24 = vadd.s32 %v106356_v24, %v121574_v2 (stack40)
        %v105979_v27 = vor.u32 %v105978_v45, %v105977_v20 (stack47)
        %v106372_v32 = vadd.s32 3, %v106368_v56 (stack40)
        %v106773_v10 = vadd.s32 %v106770_v29, %v106765_v10 (stack40)
        %v106779_v61 = vshll.u32 %v106770_v29, 24 (stack45)
        %v105210_v8 = vadd.f32 %v105206_v23, %v105155_v8 (stack53)
        %v105585_v55 = vand.u32 2147483647, %v105577_v54 (stack60)
        %v106780_v29 = vshrl.u32 %v106770_v29, 8 (stack46)
        %v107186_v43 = vor.u32 %v107185_v31, %v107184_v43 (stack47)
        %vm107588_vm1 = vcmp.lt.u32.totalorder %v152694_v42, %v152649_v22 (stack43)
        %v105980_v44 = vxor.u32 %v105979_v27, %v105975_v30 (stack48)
        %v106376_v60 = vadd.s32 %v106372_v32, %v106360_v24 (stack40)
        %v106378_v50 = vshll.u32 %v106372_v32, 17 (stack45)
        %v106379_v31 = vshrl.u32 %v106372_v32, 15 (stack46)
        %v105214_v20 = vmul.f32 %v105210_v8, %v152674_v41 (stack54)
        %v105584_v54 = vmul.f32 %v105583_v6, %v105577_v54 (stack63)
        %v106781_v45 = vor.u32 %v106780_v29, %v106779_v61 (stack47)
        %v107187_v56 = vxor.u32 %v107186_v43, %v107182_v26 (stack48)
        %v105983_v30 = vadd.s32 %v105980_v44, %v105975_v30 (stack40)
        %v105989_v23 = vshll.u32 %v105980_v44, 6 (stack45)
        %v105990_v6 = vshrl.u32 %v105980_v44, 26 (stack46)
        %v106380_v24 = vor.u32 %v106379_v31, %v106378_v50 (stack47)
        %v105218_v34 = vadd.f32 %v105214_v20, %v105151_v34 (stack53)
        %v106782_v27 = vxor.u32 %v106781_v45, %v106773_v10 (stack48)
        %v152703_v26 = vadd.s32 %v107187_v56, %v107182_v26 (stack40)
        %v107196_v32 = vshll.u32 %v107187_v56, 6 (stack45)
        %vm152705_vm2 = vcmp.lt.f32.partialorder %v105585_v55, 0.0004427343 (stack62)
        %v105991_v8 = vor.u32 %v105990_v6, %v105989_v23 (stack47)
        %v106381_v55 = vxor.u32 %v106380_v24, %v106376_v60 (stack48)
        %v106777_v10 = vadd.s32 %v106773_v10, %v121564_v0 (stack40)
        %v107197_v29 = vshrl.u32 %v107187_v56, 26 (stack46)
        %v105222_v43 = vmul.f32 %v105218_v34, %v152674_v41 (stack54)
        %v105987_v44 = vadd.s32 %v105983_v30, %v121564_v0 (stack40)
        %v106785_v50 = vadd.s32 %v106782_v27, %v121574_v2 (stack40)
        %v107606_v46 = vsel /*vm=*/%vm107593_vm0, /*on_true_vy=*/%v107602_v53, /*on_false_vx=*/%v152658_v46 (stack44)
        %v105992_v53 = vxor.u32 %v105991_v8, %v105983_v30 (stack48)
        %v106384_v60 = vadd.s32 %v106381_v55, %v106376_v60 (stack40)
        %v106386_v31 = vshll.u32 %v106381_v55, 29 (stack45)
        %v106387_v20 = vshrl.u32 %v106381_v55, 3 (stack46)
        %v105226_v21 = vadd.f32 %v105222_v43, %v152635_v21 (stack53)
        %v106789_v45 = vadd.s32 2, %v106785_v50 (stack40)
        %v107198_v56 = vor.u32 %v107197_v29, %v107196_v32 (stack47)
        %v107610_v30 = vadd.s32 1, %v107606_v46 (stack40)
        %v105995_v23 = vadd.s32 %v105992_v53, %v121574_v2 (stack40)
        %v106388_v6 = vor.u32 %v106387_v20, %v106386_v31 (stack47)
        %v152721_v24 = vadd.s32 %v152694_v42, %v121569_v1 (stack40)
        %v152725_v40 = vadd.s32 %v157741_v40, %v157095_v13 (stack40)
        %v105230_v34 = vmul.f32 %v105226_v21, %v152674_v41 (stack54)
        %v106793_v27 = vadd.s32 %v106789_v45, %v106777_v10 (stack40)
        %v106795_v32 = vshll.u32 %v106789_v45, 13 (stack45)
        %v106796_v8 = vshrl.u32 %v106789_v45, 19 (stack46)
        %v121334_v55 = vpop.eup %121333 (stack64)
        %v105999_v10 = vadd.s32 5, %v105995_v23 (stack40)
        %v106389_v29 = vxor.u32 %v106388_v6, %v106384_v60 (stack48)
        %v107199_v43 = vxor.u32 %v107198_v56, %v152703_v26 (stack48)
        %v107614_v22 = vsel /*vm=*/%vm107588_vm1, /*on_true_vy=*/%v107610_v30, /*on_false_vx=*/%v107606_v46 (stack44)
        %v105234_v9 = vadd.f32 %v105230_v34, %v152630_v9 (stack53)
        %v105581_v42 = vmul.f32 0.6931472, %v121334_v55 (stack65)
        %v106797_v50 = vor.u32 %v106796_v8, %v106795_v32 (stack47)
        %v107619_v46 = vadd.s32 %v107614_v22, %v121574_v2 (stack40)
        %v106001_v44 = vxor.u32 %v105999_v10, %v105987_v44 (stack48)
        %v106392_v53 = vadd.s32 %v106389_v29, %v106384_v60 (stack40)
        %v106394_v60 = vshll.u32 %v106389_v29, 16 (stack45)
        %v106395_v31 = vshrl.u32 %v106389_v29, 16 (stack46)
        %v105238_v20 = vmul.f32 %v105234_v9, %v152674_v41 (stack54)
        %v105587_v54 = vsel /*vm=*/%vm152705_vm2, /*on_true_vy=*/%v105584_v54, /*on_false_vx=*/%v105581_v42 (stack66)
        %v106798_v61 = vxor.u32 %v106797_v50, %v106793_v27 (stack48)
        %v105139_v21 = vsel /*vm=*/%vm105130_vm12, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v152740_v45 = vxor.u32 2147483648, %v105587_v54 (stack56)
        %v106396_v56 = vor.u32 %v106395_v31, %v106394_v60 (stack47)
        %v152743_v30 = vadd.s32 %v152721_v24, %v107619_v46 (stack40)
        %v105103_v23 = vand.u32 2147483647, %v152547_v7 (stack77)
        %v105242_v6 = vadd.f32 %v105238_v20, %v105139_v21 (stack53)
        %v106801_v34 = vadd.s32 %v106798_v61, %v106793_v27 (stack40)
        %121335 = vrsqrt.f32 %v152740_v45 (stack67)
        %v106002_v27 = vand.u32.u8 255, %v106001_v44 (stack49)
        %v105246_v41 = vmul.f32 %v105242_v6, %v152674_v41 (stack54)
        %vm105591_vm3 = vcmp.lt.f32.partialorder %v152740_v45, 5.0 (stack68)
        %v106803_v32 = vshll.u32 %v106798_v61, 15 (stack45)
        %v106804_v8 = vshrl.u32 %v106798_v61, 17 (stack46)
        %v105111_v55 = vmul.f32 inf, %v152547_v7 (stack54)
        %v105135_v52 = vsel /*vm=*/%vm105130_vm12, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v106397_v10 = vxor.u32 %v106396_v56, %v106392_v53 (stack48)
        %v107202_v29 = vadd.s32 %v107199_v43, %v121564_v0 (stack40)
        %vm152754_vm4 = vcmp.eq.f32.partialorder %v105103_v23, 1.0 (stack68)
        %v105250_v22 = vadd.f32 %v105246_v41, %v105135_v52 (stack53)
        %v105564_v9 = vand.u32 2147483647, %v152677_v25 (stack77)
        %v107194_v26 = vadd.s32 %v152703_v26, %v121569_v1 (stack40)
        %v152764_v42 = vsel /*vm=*/%vm105591_vm3, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v152767_v50 = vadd.f32 -2.5, %v152740_v45 (stack53)
        %v106003_v46 = vand.u32 65535, %v106002_v27 (stack50)
        %v106400_v44 = vadd.s32 %v106397_v10, %v106392_v53 (stack40)
        %v105254_v7 = vmul.f32 %v105250_v22, %v152547_v7 (stack54)
        %v106406_v53 = vshll.u32 %v106397_v10, 24 (stack45)
        %v106407_v60 = vshrl.u32 %v106397_v10, 8 (stack46)
        %v106805_v31 = vor.u32 %v106804_v8, %v106803_v32 (stack47)
        %v152773_v20 = vsel /*vm=*/%vm105591_vm3, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v106004_v54 = vshrl.u32 %v106003_v46, 1 (stack51)
        %v107206_v61 = vadd.s32 1, %v107202_v29 (stack40)
        %v107629_v21 = vshll.u32 %v152721_v24, 13 (stack45)
        %v105258_v56 = vsel /*vm=*/%vm152754_vm4, /*on_true_vy=*/%v105111_v55, /*on_false_vx=*/%v105254_v7 (stack44)
        %vm105636_vm5 = vcmp.eq.f32.partialorder %v152740_v45, inf (stack70)
        %v106408_v23 = vor.u32 %v106407_v60, %v106406_v53 (stack47)
        %v106806_v6 = vxor.u32 %v106805_v31, %v106801_v34 (stack48)
        %v107630_v24 = vshrl.u32 %v152721_v24, 19 (stack46)
        %v105262_v27 = vmul.f32 1.4140625, %v105258_v56 (stack54)
        %v106005_v41 = vor.u32 16256, %v106004_v54 (stack47)
        %v107210_v32 = vadd.s32 %v107206_v61, %v107194_v26 (stack40)
        %v107212_v8 = vshll.u32 %v107206_v61, 17 (stack45)
        %v106409_v55 = vxor.u32 %v106408_v23, %v106400_v44 (stack48)
        %v106809_v34 = vadd.s32 %v106806_v6, %v106801_v34 (stack40)
        %v106811_v52 = vshll.u32 %v106806_v6, 26 (stack45)
        %v106812_v10 = vshrl.u32 %v106806_v6, 6 (stack46)
        %v105265_v29 = vpack.c.bf16 %v157387_v11, %v105262_v27 (stack81)
        %v106006_v43 = vand.u32.u16 65535, %v106005_v41 (stack52)
        %v107213_v22 = vshrl.u32 %v107206_v61, 15 (stack46)
        %v107631_v26 = vor.u32 %v107630_v24, %v107629_v21 (stack47)
        %vm105638_vm6 = vcmp.eq.f32.partialorder %v152740_v45, 0.0 (stack71)
        %v106412_v46 = vadd.s32 %v106409_v55, %v121564_v0 (stack40)
        %v106813_v7 = vor.u32 %v106812_v10, %v106811_v52 (stack47)
        %vm108054_vm7 = vcmp.lt.u32.totalorder %v152725_v40, %v157095_v13 (stack43)
        %120309 = vst [vmem:[%s123356_s30 + $0x70] sm:$0xf] /*vst_source=*/%v105265_v29 (stack83)
        %v120312_v53 = vadd.low.f32.bf16 -1.0, %v106006_v43 (stack53)
        %v107214_v60 = vor.u32 %v107213_v22, %v107212_v8 (stack47)
        %v107632_v31 = vxor.u32 %v107631_v26, %v152743_v30 (stack48)
        %v152789_v12 = vadd.s32 %v157742_v12, %v157100_v14 (stack40)
        %v121336_v54 = vpop.eup %121335 (stack73)
        %v105639_v61 = vand.u32 2147483648, %v152740_v45 (stack72)
        %v106404_v44 = vadd.s32 %v106400_v44, %v121569_v1 (stack40)
        %v106416_v21 = vadd.s32 4, %v106412_v46 (stack40)
        %v106814_v56 = vxor.u32 %v106813_v7, %v106809_v34 (stack48)
        %v105635_v23 = vmul.f32 %v121336_v54, %v152740_v45 (stack74)
        %v106015_v6 = vmul.f32 2.0, %v120312_v53 (stack54)
        %v107215_v24 = vxor.u32 %v107214_v60, %v107210_v32 (stack48)
        %v152795_v30 = vadd.s32 %v107632_v31, %v152743_v30 (stack40)
        %v106420_v27 = vadd.s32 %v106416_v21, %v106404_v44 (stack40)
        %v106422_v41 = vshll.u32 %v106416_v21, 13 (stack45)
        %v106423_v8 = vshrl.u32 %v106416_v21, 19 (stack46)
        %v106817_v55 = vadd.s32 %v106814_v56, %v106809_v34 (stack40)
        %v105637_v34 = vsel /*vm=*/%vm105636_vm5, /*on_true_vy=*/%v152740_v45, /*on_false_vx=*/%v105635_v23 (stack75)
        %v106019_v52 = vadd.f32 -0.99609375, %v106015_v6 (stack53)
        %v106823_v10 = vshll.u32 %v106814_v56, 6 (stack45)
        %v106824_v29 = vshrl.u32 %v106814_v56, 26 (stack46)
        %v152803_v43 = vsel /*vm=*/%vm105591_vm3, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v105640_v22 = vsel /*vm=*/%vm105638_vm6, /*on_true_vy=*/%v105639_v61, /*on_false_vx=*/%v105637_v34 (stack76)
        %v106424_v26 = vor.u32 %v106423_v8, %v106422_v41 (stack47)
        %v107218_v32 = vadd.s32 %v107215_v24, %v107210_v32 (stack40)
        %v105643_v46 = vadd.f32 -3.0, %v105640_v22 (stack53)
        %v152807_v7 = vmax.f32 %v106019_v52, -0.99609375 (stack55)
        %v106825_v53 = vor.u32 %v106824_v29, %v106823_v10 (stack47)
        %v107220_v60 = vshll.u32 %v107215_v24, 29 (stack45)
        %v106425_v54 = vxor.u32 %v106424_v26, %v106420_v27 (stack48)
        %v107221_v61 = vshrl.u32 %v107215_v24, 3 (stack46)
        %v107637_v44 = vshll.u32 %v107632_v31, 15 (stack45)
        %v107638_v31 = vshrl.u32 %v107632_v31, 17 (stack46)
        %v105628_v21 = vsel /*vm=*/%vm105591_vm3, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v152815_v50 = vsel /*vm=*/%vm105591_vm3, /*on_true_vy=*/%v152767_v50, /*on_false_vx=*/%v105643_v46 (stack44)
        %v106035_v56 = vxor.u32 2147483648, %v152807_v7 (stack56)
        %v152820_v23 = vadd.s32 %v152725_v40, %v122657_v58 (stack40)
        %v105651_v6 = vmul.f32 %v152815_v50, %v105628_v21 (stack54)
        %v106428_v24 = vadd.s32 %v106425_v54, %v106420_v27 (stack40)
        %v106430_v27 = vshll.u32 %v106425_v54, 15 (stack45)
        %v106431_v41 = vshrl.u32 %v106425_v54, 17 (stack46)
        %v105624_v8 = vsel /*vm=*/%vm105591_vm3, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v152827_v34 = vmul.f32 %v106035_v56, %v152807_v7 (stack54)
        %v106826_v52 = vxor.u32 %v106825_v53, %v106817_v55 (stack48)
        %v107222_v10 = vor.u32 %v107221_v61, %v107220_v60 (stack47)
        %v105616_v29 = vsel /*vm=*/%vm105591_vm3, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v105655_v22 = vadd.f32 %v105651_v6, %v105624_v8 (stack53)
        %v106432_v26 = vor.u32 %v106431_v41, %v106430_v27 (stack47)
        %v107639_v46 = vor.u32 %v107638_v31, %v107637_v44 (stack47)
        %v105620_v53 = vsel /*vm=*/%vm105591_vm3, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v106040_v60 = vadd.f32 1.0, %v152827_v34 (stack57)
        %v106829_v54 = vadd.s32 %v106826_v52, %v121569_v1 (stack40)
        %v152839_v61 = vadd.s32 %v152820_v23, %v121569_v1 (stack40)
        %v105659_v44 = vmul.f32 %v105655_v22, %v152815_v50 (stack54)
        %v106433_v31 = vxor.u32 %v106432_v26, %v106428_v24 (stack48)
        %v107223_v21 = vxor.u32 %v107222_v10, %v107218_v32 (stack48)
        %v107640_v56 = vxor.u32 %v107639_v46, %v152795_v30 (stack48)
        %121337 = vlog2.f32 %v106040_v60 (stack58)
        %v106821_v55 = vadd.s32 %v106817_v55, %v121574_v2 (stack40)
        %v106833_v6 = vadd.s32 3, %v106829_v54 (stack40)
        %vm108049_vm8 = vcmp.lt.u32.totalorder %v152820_v23, %v152725_v40 (stack43)
        %v108063_v27 = vadd.s32 1, %v152789_v12 (stack40)
        %v105663_v41 = vadd.f32 %v105659_v44, %v105620_v53 (stack53)
        %v106436_v24 = vadd.s32 %v106433_v31, %v106428_v24 (stack40)
        %v106438_v8 = vshll.u32 %v106433_v31, 26 (stack45)
        %v106439_v52 = vshrl.u32 %v106433_v31, 6 (stack46)
        %v106043_v10 = vmul.f32 -0.5, %v152827_v34 (stack59)
        %v106837_v22 = vadd.s32 %v106833_v6, %v106821_v55 (stack40)
        %v106839_v26 = vshll.u32 %v106833_v6, 17 (stack45)
        %v106840_v46 = vshrl.u32 %v106833_v6, 15 (stack46)
        %v105667_v53 = vmul.f32 %v105663_v41, %v152815_v50 (stack54)
        %v106440_v60 = vor.u32 %v106439_v52, %v106438_v8 (stack47)
        %v107226_v32 = vadd.s32 %v107223_v21, %v107218_v32 (stack40)
        %v107228_v54 = vshll.u32 %v107223_v21, 16 (stack45)
        %v106841_v44 = vor.u32 %v106840_v46, %v106839_v26 (stack47)
        %v107229_v31 = vshrl.u32 %v107223_v21, 16 (stack46)
        %v107643_v30 = vadd.s32 %v107640_v56, %v152795_v30 (stack40)
        %v107645_v21 = vshll.u32 %v107640_v56, 26 (stack45)
        %v105671_v29 = vadd.f32 %v105667_v53, %v105616_v29 (stack53)
        %v106441_v55 = vxor.u32 %v106440_v60, %v106436_v24 (stack48)
        %v107646_v56 = vshrl.u32 %v107640_v56, 6 (stack46)
        %v108067_v12 = vsel /*vm=*/%vm108054_vm7, /*on_true_vy=*/%v108063_v27, /*on_false_vx=*/%v152789_v12 (stack44)
        %v106046_v6 = vand.u32 2147483647, %v152827_v34 (stack60)
        %v106842_v27 = vxor.u32 %v106841_v44, %v106837_v22 (stack48)
        %v107230_v41 = vor.u32 %v107229_v31, %v107228_v54 (stack47)
        %v108071_v8 = vadd.s32 1, %v108067_v12 (stack40)
        %v105675_v52 = vmul.f32 %v105671_v29, %v152815_v50 (stack54)
        %v106444_v24 = vadd.s32 %v106441_v55, %v106436_v24 (stack40)
        %v106450_v26 = vshll.u32 %v106441_v55, 6 (stack45)
        %v106451_v46 = vshrl.u32 %v106441_v55, 26 (stack46)
        %v106845_v22 = vadd.s32 %v106842_v27, %v106837_v22 (stack40)
        %v106847_v53 = vshll.u32 %v106842_v27, 29 (stack45)
        %v106848_v60 = vshrl.u32 %v106842_v27, 3 (stack46)
        %v107231_v54 = vxor.u32 %v107230_v41, %v107226_v32 (stack48)
        %v105679_v43 = vadd.f32 %v105675_v52, %v152803_v43 (stack53)
        %v106044_v10 = vadd.f32 1.0, %v106043_v10 (stack61)
        %v106452_v44 = vor.u32 %v106451_v46, %v106450_v26 (stack47)
        %v107647_v31 = vor.u32 %v107646_v56, %v107645_v21 (stack47)
        %v106849_v21 = vor.u32 %v106848_v60, %v106847_v53 (stack47)
        %v107234_v32 = vadd.s32 %v107231_v54, %v107226_v32 (stack40)
        %v107240_v29 = vshll.u32 %v107231_v54, 24 (stack45)
        %v107241_v55 = vshrl.u32 %v107231_v54, 8 (stack46)
        %v105683_v56 = vmul.f32 %v105679_v43, %v152815_v50 (stack54)
        %v106453_v27 = vxor.u32 %v106452_v44, %v106444_v24 (stack48)
        %v107648_v41 = vxor.u32 %v107647_v31, %v107643_v30 (stack48)
        %v108075_v40 = vsel /*vm=*/%vm108049_vm8, /*on_true_vy=*/%v108071_v8, /*on_false_vx=*/%v108067_v12 (stack44)
        %vm152861_vm9 = vcmp.lt.f32.partialorder %v106046_v6, 0.0004427343 (stack62)
        %v106850_v12 = vxor.u32 %v106849_v21, %v106845_v22 (stack48)
        %v107242_v6 = vor.u32 %v107241_v55, %v107240_v29 (stack47)
        %v108080_v8 = vadd.s32 %v108075_v40, %v121574_v2 (stack40)
        %v121338_v52 = vpop.eup %121337 (stack64)
        %v105687_v20 = vadd.f32 %v105683_v56, %v152773_v20 (stack53)
        %v106045_v34 = vmul.f32 %v106044_v10, %v152827_v34 (stack63)
        %v106456_v26 = vadd.s32 %v106453_v27, %v121574_v2 (stack40)
        %v107651_v30 = vadd.s32 %v107648_v41, %v107643_v30 (stack40)
        %v106042_v46 = vmul.f32 0.6931472, %v121338_v52 (stack65)
        %v106853_v22 = vadd.s32 %v106850_v12, %v106845_v22 (stack40)
        %v106855_v53 = vshll.u32 %v106850_v12, 16 (stack45)
        %v106856_v60 = vshrl.u32 %v106850_v12, 16 (stack46)
        %v105691_v54 = vmul.f32 %v105687_v20, %v152815_v50 (stack54)
        %v106448_v24 = vadd.s32 %v106444_v24, %v121564_v0 (stack40)
        %v106460_v43 = vadd.s32 5, %v106456_v26 (stack40)
        %v107243_v10 = vxor.u32 %v107242_v6, %v107234_v32 (stack48)
        %v106048_v44 = vsel /*vm=*/%vm152861_vm9, /*on_true_vy=*/%v106045_v34, /*on_false_vx=*/%v106042_v46 (stack66)
        %v106857_v31 = vor.u32 %v106856_v60, %v106855_v53 (stack47)
        %v107657_v21 = vshll.u32 %v107648_v41, 6 (stack45)
        %v108088_v29 = vadd.s32 %v152839_v61, %v108080_v8 (stack40)
        %v105695_v42 = vadd.f32 %v105691_v54, %v152764_v42 (stack53)
        %v152875_v55 = vxor.u32 2147483648, %v106048_v44 (stack56)
        %v106462_v56 = vxor.u32 %v106460_v43, %v106448_v24 (stack48)
        %v107658_v27 = vshrl.u32 %v107648_v41, 26 (stack46)
        %v106858_v41 = vxor.u32 %v106857_v31, %v106853_v22 (stack48)
        %v157770_v40 = vld [vmem:[#allocation149_spill] sm:$0xff] (stack84)
        %v152879_v23 = vadd.s32 %v157770_v40, %v122651_v47 (stack40)
        %v105572_v12 = vmul.f32 inf, %v152677_v25 (stack54)
        %v105596_v6 = vsel /*vm=*/%vm105591_vm3, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v105699_v8 = vmul.f32 %v105695_v42, %v152815_v50 (stack54)
        %121339 = vrsqrt.f32 %v152875_v55 (stack67)
        %vm152889_vm10 = vcmp.eq.f32.partialorder %v105564_v9, 1.0 (stack68)
        %v105600_v45 = vsel /*vm=*/%vm105591_vm3, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %vm106052_vm11 = vcmp.lt.f32.partialorder %v152875_v55, 5.0 (stack68)
        %v106861_v52 = vadd.s32 %v106858_v41, %v106853_v22 (stack40)
        %v107246_v20 = vadd.s32 %v107243_v10, %v121574_v2 (stack40)
        %v105703_v34 = vadd.f32 %v105699_v8, %v105600_v45 (stack53)
        %v107659_v26 = vor.u32 %v107658_v27, %v107657_v21 (stack47)
        %v108090_v46 = vshll.u32 %v152839_v61, 13 (stack45)
        %v108091_v61 = vshrl.u32 %v152839_v61, 19 (stack46)
        %v106025_v22 = vand.u32 2147483647, %v152807_v7 (stack77)
        %v152902_v53 = vadd.f32 -2.5, %v152875_v55 (stack53)
        %v107238_v32 = vadd.s32 %v107234_v32, %v121564_v0 (stack40)
        %v107655_v60 = vadd.s32 %v107651_v30, %v121569_v1 (stack40)
        %v105707_v50 = vmul.f32 %v105703_v34, %v152815_v50 (stack54)
        %v152910_v54 = vsel /*vm=*/%vm106052_vm11, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v152915_v24 = vsel /*vm=*/%vm106052_vm11, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v152920_v43 = vsel /*vm=*/%vm106052_vm11, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v106463_v10 = vand.u32.u8 255, %v106462_v56 (stack49)
        %v106867_v44 = vshll.u32 %v106858_v41, 24 (stack45)
        %v106868_v31 = vshrl.u32 %v106858_v41, 8 (stack46)
        %v107250_v21 = vadd.s32 2, %v107246_v20 (stack40)
        %v105711_v42 = vadd.f32 %v105707_v50, %v105596_v6 (stack53)
        %v106865_v56 = vadd.s32 %v106861_v52, %v121569_v1 (stack40)
        %v107660_v30 = vxor.u32 %v107659_v26, %v107651_v30 (stack48)
        %v108092_v27 = vor.u32 %v108091_v61, %v108090_v46 (stack47)
        %vm106097_vm12 = vcmp.eq.f32.partialorder %v152875_v55, inf (stack70)
        %v106464_v41 = vand.u32 65535, %v106463_v10 (stack50)
        %v106869_v6 = vor.u32 %v106868_v31, %v106867_v44 (stack47)
        %v107254_v8 = vadd.s32 %v107250_v21, %v107238_v32 (stack40)
        %v107256_v45 = vshll.u32 %v107250_v21, 13 (stack45)
        %v105715_v25 = vmul.f32 %v105711_v42, %v152677_v25 (stack54)
        %vm106099_vm13 = vcmp.eq.f32.partialorder %v152875_v55, 0.0 (stack71)
        %v107257_v20 = vshrl.u32 %v107250_v21, 19 (stack46)
        %v107663_v34 = vadd.s32 %v107660_v30, %v121564_v0 (stack40)
        %v108093_v26 = vxor.u32 %v108092_v27, %v108088_v29 (stack48)
        %v106100_v46 = vand.u32 2147483648, %v152875_v55 (stack72)
        %v106465_v61 = vshrl.u32 %v106464_v41, 1 (stack51)
        %v106870_v52 = vxor.u32 %v106869_v6, %v106861_v52 (stack48)
        %vm108549_vm14 = vcmp.lt.u32.totalorder %v152879_v23, %v122651_v47 (stack43)
        %v105719_v12 = vsel /*vm=*/%vm152889_vm10, /*on_true_vy=*/%v105572_v12, /*on_false_vx=*/%v105715_v25 (stack44)
        %v107258_v9 = vor.u32 %v107257_v20, %v107256_v45 (stack47)
        %v107667_v32 = vadd.s32 1, %v107663_v34 (stack40)
        %v108096_v29 = vadd.s32 %v108093_v26, %v108088_v29 (stack40)
        %v105723_v50 = vmul.f32 1.4140625, %v105719_v12 (stack54)
        %v106466_v10 = vor.u32 16256, %v106465_v61 (stack47)
        %v106873_v44 = vadd.s32 %v106870_v52, %v121564_v0 (stack40)
        %v108098_v31 = vshll.u32 %v108093_v26, 15 (stack45)
        %v107259_v21 = vxor.u32 %v107258_v9, %v107254_v8 (stack48)
        %v107671_v60 = vadd.s32 %v107667_v32, %v107655_v60 (stack40)
        %v107673_v42 = vshll.u32 %v107667_v32, 17 (stack45)
        %v107674_v30 = vshrl.u32 %v107667_v32, 15 (stack46)
        %v121340_v27 = vpop.eup %121339 (stack73)
        %v105726_v41 = vpack.c.bf16 %v157387_v11, %v105723_v50 (stack81)
        %v106467_v6 = vand.u32.u16 65535, %v106466_v10 (stack52)
        %v106877_v45 = vadd.s32 4, %v106873_v44 (stack40)
        %v108099_v25 = vshrl.u32 %v108093_v26, 17 (stack46)
        %v106096_v20 = vmul.f32 %v121340_v27, %v152875_v55 (stack74)
        %v107262_v8 = vadd.s32 %v107259_v21, %v107254_v8 (stack40)
        %v107264_v34 = vshll.u32 %v107259_v21, 15 (stack45)
        %v107265_v26 = vshrl.u32 %v107259_v21, 17 (stack46)
        %120311 = vst [vmem:[%s123356_s30 + $0xf0] sm:$0xf] /*vst_source=*/%v105726_v41 (stack83)
        %v120314_v61 = vadd.low.f32.bf16 -1.0, %v106467_v6 (stack53)
        %v106881_v56 = vadd.s32 %v106877_v45, %v106865_v56 (stack40)
        %v106883_v52 = vshll.u32 %v106877_v45, 13 (stack45)
        %v106884_v12 = vshrl.u32 %v106877_v45, 19 (stack46)
        %v106098_v9 = vsel /*vm=*/%vm106097_vm12, /*on_true_vy=*/%v152875_v55, /*on_false_vx=*/%v106096_v20 (stack75)
        %v107266_v32 = vor.u32 %v107265_v26, %v107264_v34 (stack47)
        %v107675_v50 = vor.u32 %v107674_v30, %v107673_v42 (stack47)
        %v108100_v10 = vor.u32 %v108099_v25, %v108098_v31 (stack47)
        %v106101_v46 = vsel /*vm=*/%vm106099_vm13, /*on_true_vy=*/%v106100_v46, /*on_false_vx=*/%v106098_v9 (stack76)
        %v106476_v44 = vmul.f32 2.0, %v120314_v61 (stack54)
        %v106885_v31 = vor.u32 %v106884_v12, %v106883_v52 (stack47)
        %v157773_v21 = vld [vmem:[#allocation113_spill] sm:$0xff] (stack84)
        %v108554_v42 = vadd.s32 %v157773_v21, %v157068_v28 (stack40)
        %v106104_v30 = vadd.f32 -3.0, %v106101_v46 (stack53)
        %v107267_v27 = vxor.u32 %v107266_v32, %v107262_v8 (stack48)
        %v107676_v41 = vxor.u32 %v107675_v50, %v107671_v60 (stack48)
        %v108101_v6 = vxor.u32 %v108100_v10, %v108096_v29 (stack48)
        %v152946_v45 = vsel /*vm=*/%vm106052_vm11, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v106089_v25 = vsel /*vm=*/%vm106052_vm11, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v106480_v20 = vadd.f32 -0.99609375, %v106476_v44 (stack53)
        %v106886_v34 = vxor.u32 %v106885_v31, %v106881_v56 (stack48)
        %v152954_v53 = vsel /*vm=*/%vm106052_vm11, /*on_true_vy=*/%v152902_v53, /*on_false_vx=*/%v106104_v30 (stack44)
        %v107270_v8 = vadd.s32 %v107267_v27, %v107262_v8 (stack40)
        %v107272_v26 = vshll.u32 %v107267_v27, 26 (stack45)
        %v107273_v61 = vshrl.u32 %v107267_v27, 6 (stack46)
        %v106112_v52 = vmul.f32 %v152954_v53, %v106089_v25 (stack54)
        %v152957_v12 = vmax.f32 %v106480_v20, -0.99609375 (stack55)
        %v106889_v56 = vadd.s32 %v106886_v34, %v106881_v56 (stack40)
        %v106891_v9 = vshll.u32 %v106886_v34, 15 (stack45)
        %v106085_v32 = vsel /*vm=*/%vm106052_vm11, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v106892_v50 = vshrl.u32 %v106886_v34, 17 (stack46)
        %v107274_v10 = vor.u32 %v107273_v61, %v107272_v26 (stack47)
        %v107679_v60 = vadd.s32 %v107676_v41, %v107671_v60 (stack40)
        %v106077_v46 = vsel /*vm=*/%vm106052_vm11, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v106116_v44 = vadd.f32 %v106112_v52, %v106085_v32 (stack53)
        %v106496_v31 = vxor.u32 2147483648, %v152957_v12 (stack56)
        %v108540_v30 = vadd.s32 %v152879_v23, %v122657_v58 (stack40)
        %v106081_v27 = vsel /*vm=*/%vm106052_vm11, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v106893_v25 = vor.u32 %v106892_v50, %v106891_v9 (stack47)
        %v107275_v20 = vxor.u32 %v107274_v10, %v107270_v8 (stack48)
        %v108104_v29 = vadd.s32 %v108101_v6, %v108096_v29 (stack40)
        %v106120_v34 = vmul.f32 %v106116_v44, %v152954_v53 (stack54)
        %v106499_v26 = vmul.f32 %v106496_v31, %v152957_v12 (stack54)
        %v107681_v61 = vshll.u32 %v107676_v41, 29 (stack45)
        %v107682_v41 = vshrl.u32 %v107676_v41, 3 (stack46)
        %v106894_v52 = vxor.u32 %v106893_v25, %v106889_v56 (stack48)
        %v107278_v8 = vadd.s32 %v107275_v20, %v107270_v8 (stack40)
        %v107284_v9 = vshll.u32 %v107275_v20, 6 (stack45)
        %v107285_v32 = vshrl.u32 %v107275_v20, 26 (stack46)
        %v106124_v50 = vadd.f32 %v106120_v34, %v106081_v27 (stack53)
        %v106501_v10 = vadd.f32 1.0, %v106499_v26 (stack57)
        %vm108544_vm15 = vcmp.lt.u32.totalorder %v108540_v30, %v152879_v23 (stack43)
        %v108558_v44 = vadd.s32 1, %v108554_v42 (stack40)
        %v106897_v56 = vadd.s32 %v106894_v52, %v106889_v56 (stack40)
        %v106899_v31 = vshll.u32 %v106894_v52, 26 (stack45)
        %v106900_v27 = vshrl.u32 %v106894_v52, 6 (stack46)
        %v108106_v25 = vshll.u32 %v108101_v6, 26 (stack45)
        %v106128_v20 = vmul.f32 %v106124_v50, %v152954_v53 (stack54)
        %121341 = vlog2.f32 %v106501_v10 (stack58)
        %v106504_v34 = vmul.f32 -0.5, %v106499_v26 (stack59)
        %v152976_v52 = vadd.s32 %v108540_v30, %v121569_v1 (stack40)
        %v106901_v50 = vor.u32 %v106900_v27, %v106899_v31 (stack47)
        %v107286_v9 = vor.u32 %v107285_v32, %v107284_v9 (stack47)
        %v107683_v61 = vor.u32 %v107682_v41, %v107681_v61 (stack47)
        %v108107_v6 = vshrl.u32 %v108101_v6, 6 (stack46)
        %v106132_v46 = vadd.f32 %v106128_v20, %v106077_v46 (stack53)
        %v106507_v41 = vand.u32 2147483647, %v106499_v26 (stack60)
        %v107282_v32 = vadd.s32 %v107278_v8, %v121574_v2 (stack40)
        %v108562_v42 = vsel /*vm=*/%vm108549_vm14, /*on_true_vy=*/%v108558_v44, /*on_false_vx=*/%v108554_v42 (stack44)
        %v106902_v10 = vxor.u32 %v106901_v50, %v106897_v56 (stack48)
        %v107287_v8 = vxor.u32 %v107286_v9, %v107278_v8 (stack48)
        %v107684_v44 = vxor.u32 %v107683_v61, %v107679_v60 (stack48)
        %v108108_v31 = vor.u32 %v108107_v6, %v108106_v25 (stack47)
        %v106136_v27 = vmul.f32 %v106132_v46, %v152954_v53 (stack54)
        %v106505_v25 = vadd.f32 1.0, %v106504_v34 (stack61)
        %v108566_v20 = vadd.s32 1, %v108562_v42 (stack40)
        %v152985_v34 = vadd.s32 %v157770_v40, %v157070_v38 (stack40)
        %v106905_v56 = vadd.s32 %v106902_v10, %v106897_v56 (stack40)
        %v106911_v50 = vshll.u32 %v106902_v10, 6 (stack45)
        %v106912_v9 = vshrl.u32 %v106902_v10, 26 (stack46)
        %v107290_v61 = vadd.s32 %v107287_v8, %v121569_v1 (stack40)
        %v106140_v45 = vadd.f32 %v106136_v27, %v152946_v45 (stack53)
        %v107687_v60 = vadd.s32 %v107684_v44, %v107679_v60 (stack40)
        %v107689_v6 = vshll.u32 %v107684_v44, 16 (stack45)
        %v107690_v46 = vshrl.u32 %v107684_v44, 16 (stack46)
        %vm152989_vm0 = vcmp.lt.f32.partialorder %v106507_v41, 0.0004427343 (stack62)
        %v106913_v10 = vor.u32 %v106912_v9, %v106911_v50 (stack47)
        %v107294_v8 = vadd.s32 3, %v107290_v61 (stack40)
        %v108109_v44 = vxor.u32 %v108108_v31, %v108104_v29 (stack48)
        %v106144_v31 = vmul.f32 %v106140_v45, %v152954_v53 (stack54)
        %v106506_v26 = vmul.f32 %v106505_v25, %v106499_v26 (stack63)
        %v107691_v27 = vor.u32 %v107690_v46, %v107689_v6 (stack47)
        %v108570_v23 = vsel /*vm=*/%vm108544_vm15, /*on_true_vy=*/%v108566_v20, /*on_false_vx=*/%v108562_v42 (stack44)
        %v106914_v30 = vxor.u32 %v106913_v10, %v106905_v56 (stack48)
        %v107298_v32 = vadd.s32 %v107294_v8, %v107282_v32 (stack40)
        %v107300_v42 = vshll.u32 %v107294_v8, 17 (stack45)
        %v107301_v25 = vshrl.u32 %v107294_v8, 15 (stack46)
        %v106148_v43 = vadd.f32 %v106144_v31, %v152920_v43 (stack53)
        %v107692_v20 = vxor.u32 %v107691_v27, %v107687_v60 (stack48)
        %v108112_v29 = vadd.s32 %v108109_v44, %v108104_v29 (stack40)
        %v108118_v50 = vshll.u32 %v108109_v44, 6 (stack45)
        %v106909_v56 = vadd.s32 %v106905_v56, %v121564_v0 (stack40)
        %v106917_v9 = vadd.s32 %v106914_v30, %v121574_v2 (stack40)
        %v107302_v61 = vor.u32 %v107301_v25, %v107300_v42 (stack47)
        %v108119_v45 = vshrl.u32 %v108109_v44, 26 (stack46)
        %v106152_v6 = vmul.f32 %v106148_v43, %v152954_v53 (stack54)
        %v107695_v60 = vadd.s32 %v107692_v20, %v107687_v60 (stack40)
        %v107701_v46 = vshll.u32 %v107692_v20, 24 (stack45)
        %v107702_v10 = vshrl.u32 %v107692_v20, 8 (stack46)
        %v121342_v8 = vpop.eup %121341 (stack64)
        %v106921_v44 = vadd.s32 5, %v106917_v9 (stack40)
        %v107303_v31 = vxor.u32 %v107302_v61, %v107298_v32 (stack48)
        %v108120_v27 = vor.u32 %v108119_v45, %v108118_v50 (stack47)
        %v108575_v23 = vadd.s32 %v108570_v23, %v121574_v2 (stack40)
        %v106156_v24 = vadd.f32 %v106152_v6, %v152915_v24 (stack53)
        %v106503_v30 = vmul.f32 0.6931472, %v121342_v8 (stack65)
        %v107703_v42 = vor.u32 %v107702_v10, %v107701_v46 (stack47)
        %v108585_v25 = vshll.u32 %v152976_v52, 13 (stack45)
        %v106923_v43 = vxor.u32 %v106921_v44, %v106909_v56 (stack48)
        %v107306_v32 = vadd.s32 %v107303_v31, %v107298_v32 (stack40)
        %v107308_v20 = vshll.u32 %v107303_v31, 29 (stack45)
        %v107309_v50 = vshrl.u32 %v107303_v31, 3 (stack46)
        %v106160_v56 = vmul.f32 %v106156_v24, %v152954_v53 (stack54)
        %v106509_v41 = vsel /*vm=*/%vm152989_vm0, /*on_true_vy=*/%v106506_v26, /*on_false_vx=*/%v106503_v30 (stack66)
        %v107704_v26 = vxor.u32 %v107703_v42, %v107695_v60 (stack48)
        %v108121_v9 = vxor.u32 %v108120_v27, %v108112_v29 (stack48)
        %v153006_v61 = vxor.u32 2147483648, %v106509_v41 (stack56)
        %v107310_v45 = vor.u32 %v107309_v50, %v107308_v20 (stack47)
        %v108583_v6 = vadd.s32 %v152976_v52, %v108575_v23 (stack40)
        %v108586_v52 = vshrl.u32 %v152976_v52, 19 (stack46)
        %v106164_v54 = vadd.f32 %v106160_v56, %v152910_v54 (stack53)
        %v106033_v46 = vmul.f32 inf, %v152807_v7 (stack54)
        %121343 = vrsqrt.f32 %v153006_v61 (stack67)
        %v106924_v10 = vand.u32.u8 255, %v106923_v43 (stack49)
        %vm153015_vm1 = vcmp.eq.f32.partialorder %v106025_v22, 1.0 (stack68)
        %v106057_v55 = vsel /*vm=*/%vm106052_vm11, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v106168_v53 = vmul.f32 %v106164_v54, %v152954_v53 (stack54)
        %v107707_v8 = vadd.s32 %v107704_v26, %v121574_v2 (stack40)
        %v106486_v44 = vand.u32 2147483647, %v152957_v12 (stack77)
        %v107311_v31 = vxor.u32 %v107310_v45, %v107306_v32 (stack48)
        %v108124_v27 = vadd.s32 %v108121_v9, %v121564_v0 (stack40)
        %v108587_v23 = vor.u32 %v108586_v52, %v108585_v25 (stack47)
        %v106172_v24 = vadd.f32 %v106168_v53, %v106057_v55 (stack53)
        %vm106513_vm2 = vcmp.lt.f32.partialorder %v153006_v61, 5.0 (stack68)
        %v107699_v60 = vadd.s32 %v107695_v60, %v121564_v0 (stack40)
        %v108116_v29 = vadd.s32 %v108112_v29, %v121569_v1 (stack40)
        %v153030_v30 = vadd.f32 -2.5, %v153006_v61 (stack53)
        %v106925_v42 = vand.u32 65535, %v106924_v10 (stack50)
        %v107314_v25 = vadd.s32 %v107311_v31, %v107306_v32 (stack40)
        %v153034_v43 = vadd.s32 %v152985_v34, %v122657_v58 (stack40)
        %v106176_v7 = vmul.f32 %v106172_v24, %v152807_v7 (stack54)
        %v107316_v32 = vshll.u32 %v107311_v31, 16 (stack45)
        %v107317_v20 = vshrl.u32 %v107311_v31, 16 (stack46)
        %v107711_v50 = vadd.s32 2, %v107707_v8 (stack40)
        %v153040_v56 = vsel /*vm=*/%vm106513_vm2, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v106926_v41 = vshrl.u32 %v106925_v42, 1 (stack51)
        %v108128_v26 = vadd.s32 1, %v108124_v27 (stack40)
        %v108588_v9 = vxor.u32 %v108587_v23, %v108583_v6 (stack48)
        %v106180_v45 = vsel /*vm=*/%vm153015_vm1, /*on_true_vy=*/%v106033_v46, /*on_false_vx=*/%v106176_v7 (stack44)
        %vm106558_vm3 = vcmp.eq.f32.partialorder %v153006_v61, inf (stack70)
        %v107318_v52 = vor.u32 %v107317_v20, %v107316_v32 (stack47)
        %v107715_v54 = vadd.s32 %v107711_v50, %v107699_v60 (stack40)
        %v107717_v46 = vshll.u32 %v107711_v50, 13 (stack45)
        %v106184_v10 = vmul.f32 1.4140625, %v106180_v45 (stack54)
        %vm106560_vm4 = vcmp.eq.f32.partialorder %v153006_v61, 0.0 (stack71)
        %v106927_v22 = vor.u32 16256, %v106926_v41 (stack47)
        %v107718_v55 = vshrl.u32 %v107711_v50, 19 (stack46)
        %v108132_v53 = vadd.s32 %v108128_v26, %v108116_v29 (stack40)
        %v107319_v8 = vxor.u32 %v107318_v52, %v107314_v25 (stack48)
        %v108134_v31 = vshll.u32 %v108128_v26, 17 (stack45)
        %v108135_v27 = vshrl.u32 %v108128_v26, 15 (stack46)
        %v108591_v6 = vadd.s32 %v108588_v9, %v108583_v6 (stack40)
        %v106187_v23 = vpack.c.bf16 %v157387_v11, %v106184_v10 (stack81)
        %v106928_v24 = vand.u32.u16 65535, %v106927_v22 (stack52)
        %v107719_v60 = vor.u32 %v107718_v55, %v107717_v46 (stack47)
        %v108593_v29 = vshll.u32 %v108588_v9, 15 (stack45)
        %v107322_v42 = vadd.s32 %v107319_v8, %v107314_v25 (stack40)
        %v107328_v25 = vshll.u32 %v107319_v8, 24 (stack45)
        %v107329_v7 = vshrl.u32 %v107319_v8, 8 (stack46)
        %v108136_v32 = vor.u32 %v108135_v27, %v108134_v31 (stack47)
        %120313 = vst [vmem:[%s123356_s30 + $0x170] sm:$0xf] /*vst_source=*/%v106187_v23 (stack83)
        %v120316_v20 = vadd.low.f32.bf16 -1.0, %v106928_v24 (stack53)
        %v107720_v50 = vxor.u32 %v107719_v60, %v107715_v54 (stack48)
        %v108594_v41 = vshrl.u32 %v108588_v9, 17 (stack46)
        %vm109010_vm5 = vcmp.lt.u32.totalorder %v152985_v34, %v157070_v38 (stack43)
        %v121344_v26 = vpop.eup %121343 (stack73)
        %v106561_v9 = vand.u32 2147483648, %v153006_v61 (stack72)
        %v107330_v45 = vor.u32 %v107329_v7, %v107328_v25 (stack47)
        %v108137_v52 = vxor.u32 %v108136_v32, %v108132_v53 (stack48)
        %v109015_v46 = vadd.s32 %v157773_v21, %v157076_v35 (stack40)
        %v106557_v10 = vmul.f32 %v121344_v26, %v153006_v61 (stack74)
        %v106937_v22 = vmul.f32 2.0, %v120316_v20 (stack54)
        %v107723_v54 = vadd.s32 %v107720_v50, %v107715_v54 (stack40)
        %v107725_v55 = vshll.u32 %v107720_v50, 15 (stack45)
        %v107331_v8 = vxor.u32 %v107330_v45, %v107322_v42 (stack48)
        %v107726_v31 = vshrl.u32 %v107720_v50, 17 (stack46)
        %v108140_v53 = vadd.s32 %v108137_v52, %v108132_v53 (stack40)
        %v108142_v27 = vshll.u32 %v108137_v52, 29 (stack45)
        %v106559_v23 = vsel /*vm=*/%vm106558_vm3, /*on_true_vy=*/%v153006_v61, /*on_false_vx=*/%v106557_v10 (stack75)
        %v106941_v24 = vadd.f32 -0.99609375, %v106937_v22 (stack53)
        %v108143_v60 = vshrl.u32 %v108137_v52, 3 (stack46)
        %v108595_v29 = vor.u32 %v108594_v41, %v108593_v29 (stack47)
        %v106562_v25 = vsel /*vm=*/%vm106560_vm4, /*on_true_vy=*/%v106561_v9, /*on_false_vx=*/%v106559_v23 (stack76)
        %v107334_v7 = vadd.s32 %v107331_v8, %v121564_v0 (stack40)
        %v107727_v32 = vor.u32 %v107726_v31, %v107725_v55 (stack47)
        %v109019_v20 = vadd.s32 1, %v109015_v46 (stack40)
        %v106565_v50 = vadd.f32 -3.0, %v106562_v25 (stack53)
        %v153060_v41 = vmax.f32 %v106941_v24, -0.99609375 (stack55)
        %v107326_v42 = vadd.s32 %v107322_v42, %v121569_v1 (stack40)
        %v108596_v26 = vxor.u32 %v108595_v29, %v108591_v6 (stack48)
        %v107338_v9 = vadd.s32 4, %v107334_v7 (stack40)
        %v107728_v45 = vxor.u32 %v107727_v32, %v107723_v54 (stack48)
        %v108144_v52 = vor.u32 %v108143_v60, %v108142_v27 (stack47)
        %v109023_v46 = vsel /*vm=*/%vm109010_vm5, /*on_true_vy=*/%v109019_v20, /*on_false_vx=*/%v109015_v46 (stack44)
        %v106534_v10 = vsel /*vm=*/%vm106513_vm2, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v106550_v22 = vsel /*vm=*/%vm106513_vm2, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v153075_v30 = vsel /*vm=*/%vm106513_vm2, /*on_true_vy=*/%v153030_v30, /*on_false_vx=*/%v106565_v50 (stack44)
        %v106957_v55 = vxor.u32 2147483648, %v153060_v41 (stack56)
        %v106573_v8 = vmul.f32 %v153075_v30, %v106550_v22 (stack54)
        %v107342_v31 = vadd.s32 %v107338_v9, %v107326_v42 (stack40)
        %v107344_v27 = vshll.u32 %v107338_v9, 13 (stack45)
        %v107345_v23 = vshrl.u32 %v107338_v9, 19 (stack46)
        %v106546_v24 = vsel /*vm=*/%vm106513_vm2, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v153083_v60 = vmul.f32 %v106957_v55, %v153060_v41 (stack54)
        %v107731_v54 = vadd.s32 %v107728_v45, %v107723_v54 (stack40)
        %v107733_v29 = vshll.u32 %v107728_v45, 26 (stack45)
        %v106577_v25 = vadd.f32 %v106573_v8, %v106546_v24 (stack53)
        %v107346_v7 = vor.u32 %v107345_v23, %v107344_v27 (stack47)
        %v107734_v32 = vshrl.u32 %v107728_v45, 6 (stack46)
        %v108145_v20 = vxor.u32 %v108144_v52, %v108140_v53 (stack48)
        %v106538_v50 = vsel /*vm=*/%vm106513_vm2, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v106542_v42 = vsel /*vm=*/%vm106513_vm2, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v106962_v9 = vadd.f32 1.0, %v153083_v60 (stack57)
        %v108599_v6 = vadd.s32 %v108596_v26, %v108591_v6 (stack40)
        %v106581_v45 = vmul.f32 %v106577_v25, %v153075_v30 (stack54)
        %v107347_v52 = vxor.u32 %v107346_v7, %v107342_v31 (stack48)
        %v107735_v22 = vor.u32 %v107734_v32, %v107733_v29 (stack47)
        %v108148_v53 = vadd.s32 %v108145_v20, %v108140_v53 (stack40)
        %121345 = vlog2.f32 %v106962_v9 (stack58)
        %v108150_v55 = vshll.u32 %v108145_v20, 16 (stack45)
        %vm109005_vm6 = vcmp.lt.u32.totalorder %v153034_v43, %v152985_v34 (stack43)
        %v153097_v8 = vadd.s32 %v153034_v43, %v121569_v1 (stack40)
        %v106585_v27 = vadd.f32 %v106581_v45, %v106542_v42 (stack53)
        %v107350_v31 = vadd.s32 %v107347_v52, %v107342_v31 (stack40)
        %v107352_v23 = vshll.u32 %v107347_v52, 15 (stack45)
        %v107353_v24 = vshrl.u32 %v107347_v52, 17 (stack46)
        %v106965_v29 = vmul.f32 -0.5, %v153083_v60 (stack59)
        %v107736_v25 = vxor.u32 %v107735_v22, %v107731_v54 (stack48)
        %v108151_v7 = vshrl.u32 %v108145_v20, 16 (stack46)
        %v108601_v32 = vshll.u32 %v108596_v26, 26 (stack45)
        %v106589_v20 = vmul.f32 %v106585_v27, %v153075_v30 (stack54)
        %v107354_v42 = vor.u32 %v107353_v24, %v107352_v23 (stack47)
        %v108602_v26 = vshrl.u32 %v108596_v26, 6 (stack46)
        %v109027_v9 = vadd.s32 1, %v109023_v46 (stack40)
        %v107739_v54 = vadd.s32 %v107736_v25, %v107731_v54 (stack40)
        %v107745_v45 = vshll.u32 %v107736_v25, 6 (stack45)
        %v107746_v52 = vshrl.u32 %v107736_v25, 26 (stack46)
        %v108152_v22 = vor.u32 %v108151_v7, %v108150_v55 (stack47)
        %v106593_v50 = vadd.f32 %v106589_v20, %v106538_v50 (stack53)
        %v107355_v55 = vxor.u32 %v107354_v42, %v107350_v31 (stack48)
        %v108603_v27 = vor.u32 %v108602_v26, %v108601_v32 (stack47)
        %v109031_v34 = vsel /*vm=*/%vm109005_vm6, /*on_true_vy=*/%v109027_v9, /*on_false_vx=*/%v109023_v46 (stack44)
        %v106966_v43 = vadd.f32 1.0, %v106965_v29 (stack61)
        %v107747_v46 = vor.u32 %v107746_v52, %v107745_v45 (stack47)
        %v108153_v23 = vxor.u32 %v108152_v22, %v108148_v53 (stack48)
        %v109036_v24 = vadd.s32 %v109031_v34, %v121574_v2 (stack40)
        %v106597_v29 = vmul.f32 %v106593_v50, %v153075_v30 (stack54)
        %v107358_v31 = vadd.s32 %v107355_v55, %v107350_v31 (stack40)
        %v107360_v25 = vshll.u32 %v107355_v55, 26 (stack45)
        %v107361_v7 = vshrl.u32 %v107355_v55, 6 (stack46)
        %v107748_v32 = vxor.u32 %v107747_v46, %v107739_v54 (stack48)
        %v108156_v53 = vadd.s32 %v108153_v23, %v108148_v53 (stack40)
        %v108162_v20 = vshll.u32 %v108153_v23, 24 (stack45)
        %v108163_v42 = vshrl.u32 %v108153_v23, 8 (stack46)
        %v106601_v10 = vadd.f32 %v106597_v29, %v106534_v10 (stack53)
        %v107362_v26 = vor.u32 %v107361_v7, %v107360_v25 (stack47)
        %v108604_v9 = vxor.u32 %v108603_v27, %v108599_v6 (stack48)
        %v153107_v45 = vadd.s32 %v153097_v8, %v109036_v24 (stack40)
        %v106967_v52 = vmul.f32 %v106966_v43, %v153083_v60 (stack63)
        %v106968_v60 = vand.u32 2147483647, %v153083_v60 (stack60)
        %v107751_v22 = vadd.s32 %v107748_v32, %v121569_v1 (stack40)
        %v108164_v50 = vor.u32 %v108163_v42, %v108162_v20 (stack47)
        %v106605_v55 = vmul.f32 %v106601_v10, %v153075_v30 (stack54)
        %v107363_v27 = vxor.u32 %v107362_v26, %v107358_v31 (stack48)
        %v107743_v54 = vadd.s32 %v107739_v54, %v121574_v2 (stack40)
        %v108607_v6 = vadd.s32 %v108604_v9, %v108599_v6 (stack40)
        %v107755_v34 = vadd.s32 3, %v107751_v22 (stack40)
        %v108165_v43 = vxor.u32 %v108164_v50, %v108156_v53 (stack48)
        %v108613_v46 = vshll.u32 %v108604_v9, 6 (stack45)
        %v108614_v23 = vshrl.u32 %v108604_v9, 26 (stack46)
        %v121346_v24 = vpop.eup %121345 (stack64)
        %v106609_v56 = vadd.f32 %v106605_v55, %v153040_v56 (stack53)
        %v107366_v29 = vadd.s32 %v107363_v27, %v107358_v31 (stack40)
        %v107372_v31 = vshll.u32 %v107363_v27, 6 (stack45)
        %v107373_v25 = vshrl.u32 %v107363_v27, 26 (stack46)
        %v106964_v7 = vmul.f32 0.6931472, %v121346_v24 (stack65)
        %v107759_v32 = vadd.s32 %v107755_v34, %v107743_v54 (stack40)
        %v107761_v20 = vshll.u32 %v107755_v34, 17 (stack45)
        %v107762_v42 = vshrl.u32 %v107755_v34, 15 (stack46)
        %v106526_v10 = vsel /*vm=*/%vm106513_vm2, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v106613_v26 = vmul.f32 %v106609_v56, %v153075_v30 (stack54)
        %vm106969_vm7 = vcmp.lt.f32.partialorder %v106968_v60, 0.0004427343 (stack62)
        %v107374_v9 = vor.u32 %v107373_v25, %v107372_v31 (stack47)
        %v106970_v52 = vsel /*vm=*/%vm106969_vm7, /*on_true_vy=*/%v106967_v52, /*on_false_vx=*/%v106964_v7 (stack66)
        %v107763_v60 = vor.u32 %v107762_v42, %v107761_v20 (stack47)
        %v108168_v22 = vadd.s32 %v108165_v43, %v121574_v2 (stack40)
        %v108615_v50 = vor.u32 %v108614_v23, %v108613_v46 (stack47)
        %v106617_v55 = vadd.f32 %v106613_v26, %v106526_v10 (stack53)
        %v153120_v27 = vxor.u32 2147483648, %v106970_v52 (stack56)
        %v107375_v54 = vxor.u32 %v107374_v9, %v107366_v29 (stack48)
        %v109046_v34 = vshll.u32 %v153097_v8, 13 (stack45)
        %v107764_v43 = vxor.u32 %v107763_v60, %v107759_v32 (stack48)
        %v108616_v46 = vxor.u32 %v108615_v50, %v108607_v6 (stack48)
        %v109047_v8 = vshrl.u32 %v153097_v8, 19 (stack46)
        %v153126_v23 = vadd.s32 %v157770_v40, %v157077_v51 (stack40)
        %v106494_v24 = vmul.f32 inf, %v152957_v12 (stack54)
        %v106621_v56 = vmul.f32 %v106617_v55, %v153075_v30 (stack54)
        %121347 = vrsqrt.f32 %v153120_v27 (stack67)
        %vm153133_vm8 = vcmp.eq.f32.partialorder %v106486_v44, 1.0 (stack68)
        %v106522_v31 = vsel /*vm=*/%vm106513_vm2, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %vm106974_vm9 = vcmp.lt.f32.partialorder %v153120_v27, 5.0 (stack68)
        %v107378_v25 = vadd.s32 %v107375_v54, %v121574_v2 (stack40)
        %v108172_v7 = vadd.s32 2, %v108168_v22 (stack40)
        %v106518_v61 = vsel /*vm=*/%vm106513_vm2, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v106625_v20 = vadd.f32 %v106621_v56, %v106522_v31 (stack53)
        %v106947_v42 = vand.u32 2147483647, %v153060_v41 (stack77)
        %v108160_v53 = vadd.s32 %v108156_v53, %v121564_v0 (stack40)
        %v107370_v29 = vadd.s32 %v107366_v29, %v121564_v0 (stack40)
        %v107767_v32 = vadd.s32 %v107764_v43, %v107759_v32 (stack40)
        %v108611_v6 = vadd.s32 %v108607_v6, %v121569_v1 (stack40)
        %v109048_v10 = vor.u32 %v109047_v8, %v109046_v34 (stack47)
        %v106629_v30 = vmul.f32 %v106625_v20, %v153075_v30 (stack54)
        %v153153_v26 = vsel /*vm=*/%vm106974_vm9, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v153158_v9 = vsel /*vm=*/%vm106974_vm9, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v153161_v52 = vadd.f32 -2.5, %v153120_v27 (stack53)
        %v107382_v60 = vadd.s32 5, %v107378_v25 (stack40)
        %v107769_v22 = vshll.u32 %v107764_v43, 29 (stack45)
        %v107770_v50 = vshrl.u32 %v107764_v43, 3 (stack46)
        %v108176_v55 = vadd.s32 %v108172_v7, %v108160_v53 (stack40)
        %v106633_v54 = vadd.f32 %v106629_v30, %v106518_v61 (stack53)
        %v108178_v34 = vshll.u32 %v108172_v7, 13 (stack45)
        %v108179_v43 = vshrl.u32 %v108172_v7, 19 (stack46)
        %v108619_v46 = vadd.s32 %v108616_v46, %v121564_v0 (stack40)
        %vm107019_vm10 = vcmp.eq.f32.partialorder %v153120_v27, inf (stack70)
        %v107384_v8 = vxor.u32 %v107382_v60, %v107370_v29 (stack48)
        %v107771_v56 = vor.u32 %v107770_v50, %v107769_v22 (stack47)
        %v109049_v31 = vxor.u32 %v109048_v10, %v153107_v45 (stack48)
        %v106637_v12 = vmul.f32 %v106633_v54, %v152957_v12 (stack54)
        %v108180_v25 = vor.u32 %v108179_v43, %v108178_v34 (stack47)
        %v108623_v7 = vadd.s32 1, %v108619_v46 (stack40)
        %vm109471_vm11 = vcmp.lt.u32.totalorder %v153126_v23, %v157077_v51 (stack43)
        %v107385_v61 = vand.u32.u8 255, %v107384_v8 (stack49)
        %v107772_v20 = vxor.u32 %v107771_v56, %v107767_v32 (stack48)
        %v109052_v45 = vadd.s32 %v109049_v31, %v153107_v45 (stack40)
        %v109054_v53 = vshll.u32 %v109049_v31, 15 (stack45)
        %v106641_v24 = vsel /*vm=*/%vm153133_vm8, /*on_true_vy=*/%v106494_v24, /*on_false_vx=*/%v106637_v12 (stack44)
        %v108181_v44 = vxor.u32 %v108180_v25, %v108176_v55 (stack48)
        %v108627_v29 = vadd.s32 %v108623_v7, %v108611_v6 (stack40)
        %v108629_v6 = vshll.u32 %v108623_v7, 17 (stack45)
        %v106645_v10 = vmul.f32 1.4140625, %v106641_v24 (stack54)
        %v107386_v30 = vand.u32 65535, %v107385_v61 (stack50)
        %v107775_v32 = vadd.s32 %v107772_v20, %v107767_v32 (stack40)
        %v107777_v60 = vshll.u32 %v107772_v20, 16 (stack45)
        %v107778_v22 = vshrl.u32 %v107772_v20, 16 (stack46)
        %v108184_v50 = vadd.s32 %v108181_v44, %v108176_v55 (stack40)
        %v108186_v55 = vshll.u32 %v108181_v44, 15 (stack45)
        %v108187_v54 = vshrl.u32 %v108181_v44, 17 (stack46)
        %v121348_v34 = vpop.eup %121347 (stack73)
        %v106648_v43 = vpack.c.bf16 %v157387_v11, %v106645_v10 (stack81)
        %v107387_v46 = vshrl.u32 %v107386_v30, 1 (stack51)
        %v108630_v8 = vshrl.u32 %v108623_v7, 15 (stack46)
        %v109055_v56 = vshrl.u32 %v109049_v31, 17 (stack46)
        %v107018_v31 = vmul.f32 %v121348_v34, %v153120_v27 (stack74)
        %v107022_v12 = vand.u32 2147483648, %v153120_v27 (stack72)
        %v107779_v25 = vor.u32 %v107778_v22, %v107777_v60 (stack47)
        %v108188_v7 = vor.u32 %v108187_v54, %v108186_v55 (stack47)
        %120315 = vst [vmem:[%s123356_s30 + $0x1f0] sm:$0xf] /*vst_source=*/%v106648_v43 (stack83)
        %v107388_v61 = vor.u32 16256, %v107387_v46 (stack47)
        %v108631_v20 = vor.u32 %v108630_v8, %v108629_v6 (stack47)
        %v109056_v53 = vor.u32 %v109055_v56, %v109054_v53 (stack47)
        %v153178_v24 = vadd.s32 %v157773_v21, %v157078_v48 (stack40)
        %v107020_v44 = vsel /*vm=*/%vm107019_vm10, /*on_true_vy=*/%v153120_v27, /*on_false_vx=*/%v107018_v31 (stack75)
        %vm107021_vm12 = vcmp.eq.f32.partialorder %v153120_v27, 0.0 (stack71)
        %v107780_v6 = vxor.u32 %v107779_v25, %v107775_v32 (stack48)
        %v108189_v10 = vxor.u32 %v108188_v7, %v108184_v50 (stack48)
        %v107023_v30 = vsel /*vm=*/%vm107021_vm12, /*on_true_vy=*/%v107022_v12, /*on_false_vx=*/%v107020_v44 (stack76)
        %v107389_v60 = vand.u32.u16 65535, %v107388_v61 (stack52)
        %v108632_v22 = vxor.u32 %v108631_v20, %v108627_v29 (stack48)
        %v109057_v55 = vxor.u32 %v109056_v53, %v109052_v45 (stack48)
        %v107026_v54 = vadd.f32 -3.0, %v107023_v30 (stack53)
        %v107783_v32 = vadd.s32 %v107780_v6, %v107775_v32 (stack40)
        %v107789_v34 = vshll.u32 %v107780_v6, 24 (stack45)
        %v107790_v43 = vshrl.u32 %v107780_v6, 8 (stack46)
        %v120318_v46 = vadd.low.f32.bf16 -1.0, %v107389_v60 (stack53)
        %v108192_v50 = vadd.s32 %v108189_v10, %v108184_v50 (stack40)
        %v108194_v8 = vshll.u32 %v108189_v10, 26 (stack45)
        %v108195_v56 = vshrl.u32 %v108189_v10, 6 (stack46)
        %v107011_v31 = vsel /*vm=*/%vm106974_vm9, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v153190_v52 = vsel /*vm=*/%vm106974_vm9, /*on_true_vy=*/%v153161_v52, /*on_false_vx=*/%v107026_v54 (stack44)
        %v107791_v12 = vor.u32 %v107790_v43, %v107789_v34 (stack47)
        %v108635_v29 = vadd.s32 %v108632_v22, %v108627_v29 (stack40)
        %v107034_v25 = vmul.f32 %v153190_v52, %v107011_v31 (stack54)
        %v107398_v7 = vmul.f32 2.0, %v120318_v46 (stack54)
        %v108196_v61 = vor.u32 %v108195_v56, %v108194_v8 (stack47)
        %v108637_v20 = vshll.u32 %v108632_v22, 29 (stack45)
        %v107007_v53 = vsel /*vm=*/%vm106974_vm9, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v107792_v44 = vxor.u32 %v107791_v12, %v107783_v32 (stack48)
        %v108638_v6 = vshrl.u32 %v108632_v22, 3 (stack46)
        %v109060_v45 = vadd.s32 %v109057_v55, %v109052_v45 (stack40)
        %v107003_v10 = vsel /*vm=*/%vm106974_vm9, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v107038_v30 = vadd.f32 %v107034_v25, %v107007_v53 (stack53)
        %v107402_v60 = vadd.f32 -0.99609375, %v107398_v7 (stack53)
        %v108197_v22 = vxor.u32 %v108196_v61, %v108192_v50 (stack48)
        %v107795_v54 = vadd.s32 %v107792_v44, %v121564_v0 (stack40)
        %v108639_v34 = vor.u32 %v108638_v6, %v108637_v20 (stack47)
        %v109062_v43 = vshll.u32 %v109057_v55, 26 (stack45)
        %v109063_v55 = vshrl.u32 %v109057_v55, 6 (stack46)
        %v107042_v46 = vmul.f32 %v107038_v30, %v153190_v52 (stack54)
        %v153201_v8 = vmax.f32 %v107402_v60, -0.99609375 (stack55)
        %v108200_v50 = vadd.s32 %v108197_v22, %v108192_v50 (stack40)
        %v108206_v56 = vshll.u32 %v108197_v22, 6 (stack45)
        %v107787_v32 = vadd.s32 %v107783_v32, %v121569_v1 (stack40)
        %v107799_v31 = vadd.s32 4, %v107795_v54 (stack40)
        %v108207_v12 = vshrl.u32 %v108197_v22, 26 (stack46)
        %v108640_v25 = vxor.u32 %v108639_v34, %v108635_v29 (stack48)
        %v106991_v7 = vsel /*vm=*/%vm106974_vm9, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v107046_v61 = vadd.f32 %v107042_v46, %v107003_v10 (stack53)
        %v107418_v20 = vxor.u32 2147483648, %v153201_v8 (stack56)
        %v153210_v53 = vadd.s32 %v153126_v23, %v122657_v58 (stack40)
        %v107803_v44 = vadd.s32 %v107799_v31, %v107787_v32 (stack40)
        %v107805_v6 = vshll.u32 %v107799_v31, 13 (stack45)
        %v107806_v10 = vshrl.u32 %v107799_v31, 19 (stack46)
        %v109064_v30 = vor.u32 %v109063_v55, %v109062_v43 (stack47)
        %v106999_v60 = vsel /*vm=*/%vm106974_vm9, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v107050_v22 = vmul.f32 %v107046_v61, %v153190_v52 (stack54)
        %v153217_v54 = vmul.f32 %v107418_v20, %v153201_v8 (stack54)
        %v108208_v34 = vor.u32 %v108207_v12, %v108206_v56 (stack47)
        %v107807_v43 = vor.u32 %v107806_v10, %v107805_v6 (stack47)
        %v108643_v29 = vadd.s32 %v108640_v25, %v108635_v29 (stack40)
        %v108645_v55 = vshll.u32 %v108640_v25, 16 (stack45)
        %v108646_v46 = vshrl.u32 %v108640_v25, 16 (stack46)
        %v106995_v56 = vsel /*vm=*/%vm106974_vm9, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v107054_v32 = vadd.f32 %v107050_v22, %v106999_v60 (stack53)
        %v107423_v31 = vadd.f32 1.0, %v153217_v54 (stack57)
        %v153225_v12 = vadd.s32 %v153210_v53, %v121569_v1 (stack40)
        %v107808_v25 = vxor.u32 %v107807_v43, %v107803_v44 (stack48)
        %v108209_v61 = vxor.u32 %v108208_v34, %v108200_v50 (stack48)
        %v108647_v20 = vor.u32 %v108646_v46, %v108645_v55 (stack47)
        %v109065_v6 = vxor.u32 %v109064_v30, %v109060_v45 (stack48)
        %v107058_v10 = vmul.f32 %v107054_v32, %v153190_v52 (stack54)
        %121349 = vlog2.f32 %v107423_v31 (stack58)
        %v107426_v30 = vmul.f32 -0.5, %v153217_v54 (stack59)
        %v108204_v50 = vadd.s32 %v108200_v50, %v121574_v2 (stack40)
        %v107811_v44 = vadd.s32 %v107808_v25, %v107803_v44 (stack40)
        %v107813_v60 = vshll.u32 %v107808_v25, 15 (stack45)
        %v107814_v22 = vshrl.u32 %v107808_v25, 17 (stack46)
        %v108212_v34 = vadd.s32 %v108209_v61, %v121569_v1 (stack40)
        %vm109466_vm13 = vcmp.lt.u32.totalorder %v153210_v53, %v153126_v23 (stack43)
        %v107062_v43 = vadd.f32 %v107058_v10, %v106995_v56 (stack53)
        %v107429_v55 = vand.u32 2147483647, %v153217_v54 (stack60)
        %v108648_v46 = vxor.u32 %v108647_v20, %v108643_v29 (stack48)
        %v109068_v45 = vadd.s32 %v109065_v6, %v109060_v45 (stack40)
        %v107815_v56 = vor.u32 %v107814_v22, %v107813_v60 (stack47)
        %v108216_v32 = vadd.s32 3, %v108212_v34 (stack40)
        %v109074_v31 = vshll.u32 %v109065_v6, 6 (stack45)
        %v109075_v25 = vshrl.u32 %v109065_v6, 26 (stack46)
        %v107066_v61 = vmul.f32 %v107062_v43, %v153190_v52 (stack54)
        %v108651_v29 = vadd.s32 %v108648_v46, %v108643_v29 (stack40)
        %v108657_v20 = vshll.u32 %v108648_v46, 24 (stack45)
        %v108658_v6 = vshrl.u32 %v108648_v46, 8 (stack46)
        %v107816_v10 = vxor.u32 %v107815_v56, %v107811_v44 (stack48)
        %v108220_v50 = vadd.s32 %v108216_v32, %v108204_v50 (stack40)
        %v108222_v60 = vshll.u32 %v108216_v32, 17 (stack45)
        %v108223_v22 = vshrl.u32 %v108216_v32, 15 (stack46)
        %v107070_v7 = vadd.f32 %v107066_v61, %v106991_v7 (stack53)
        %v107427_v30 = vadd.f32 1.0, %v107426_v30 (stack61)
        %v108659_v34 = vor.u32 %v108658_v6, %v108657_v20 (stack47)
        %v109480_v43 = vadd.s32 1, %v153178_v24 (stack40)
        %vm153236_vm14 = vcmp.lt.f32.partialorder %v107429_v55, 0.0004427343 (stack62)
        %v107819_v44 = vadd.s32 %v107816_v10, %v107811_v44 (stack40)
        %v107821_v46 = vshll.u32 %v107816_v10, 26 (stack45)
        %v107822_v56 = vshrl.u32 %v107816_v10, 6 (stack46)
        %v108224_v32 = vor.u32 %v108223_v22, %v108222_v60 (stack47)
        %v107074_v61 = vmul.f32 %v107070_v7, %v153190_v52 (stack54)
        %v108660_v20 = vxor.u32 %v108659_v34, %v108651_v29 (stack48)
        %v109076_v31 = vor.u32 %v109075_v25, %v109074_v31 (stack47)
        %v109484_v24 = vsel /*vm=*/%vm109471_vm11, /*on_true_vy=*/%v109480_v43, /*on_false_vx=*/%v153178_v24 (stack44)
        %v107823_v25 = vor.u32 %v107822_v56, %v107821_v46 (stack47)
        %v108225_v6 = vxor.u32 %v108224_v32, %v108220_v50 (stack48)
        %v108655_v29 = vadd.s32 %v108651_v29, %v121564_v0 (stack40)
        %v109488_v10 = vadd.s32 1, %v109484_v24 (stack40)
        %v107078_v9 = vadd.f32 %v107074_v61, %v153158_v9 (stack53)
        %v108663_v60 = vadd.s32 %v108660_v20, %v121574_v2 (stack40)
        %v109077_v22 = vxor.u32 %v109076_v31, %v109068_v45 (stack48)
        %v153250_v7 = vadd.s32 %v157770_v40, %v157079_v39 (stack40)
        %v107824_v34 = vxor.u32 %v107823_v25, %v107819_v44 (stack48)
        %v108228_v50 = vadd.s32 %v108225_v6, %v108220_v50 (stack40)
        %v108230_v43 = vshll.u32 %v108225_v6, 29 (stack45)
        %v108231_v46 = vshrl.u32 %v108225_v6, 3 (stack46)
        %v107082_v56 = vmul.f32 %v107078_v9, %v153190_v52 (stack54)
        %v108667_v32 = vadd.s32 2, %v108663_v60 (stack40)
        %v109080_v61 = vadd.s32 %v109077_v22, %v121564_v0 (stack40)
        %v109492_v23 = vsel /*vm=*/%vm109466_vm13, /*on_true_vy=*/%v109488_v10, /*on_false_vx=*/%v109484_v24 (stack44)
        %v121350_v53 = vpop.eup %121349 (stack64)
        %v107827_v44 = vadd.s32 %v107824_v34, %v107819_v44 (stack40)
        %v107833_v20 = vshll.u32 %v107824_v34, 6 (stack45)
        %v107834_v31 = vshrl.u32 %v107824_v34, 26 (stack46)
        %v108232_v24 = vor.u32 %v108231_v46, %v108230_v43 (stack47)
        %v107086_v26 = vadd.f32 %v107082_v56, %v153153_v26 (stack53)
        %v107425_v25 = vmul.f32 0.6931472, %v121350_v53 (stack65)
        %v107428_v54 = vmul.f32 %v107427_v30, %v153217_v54 (stack63)
        %v108671_v30 = vadd.s32 %v108667_v32, %v108655_v29 (stack40)
        %v107835_v6 = vor.u32 %v107834_v31, %v107833_v20 (stack47)
        %v108233_v29 = vxor.u32 %v108232_v24, %v108228_v50 (stack48)
        %v108673_v10 = vshll.u32 %v108667_v32, 13 (stack45)
        %v109072_v45 = vadd.s32 %v109068_v45, %v121569_v1 (stack40)
        %v107090_v52 = vmul.f32 %v107086_v26, %v153190_v52 (stack54)
        %v107431_v55 = vsel /*vm=*/%vm153236_vm14, /*on_true_vy=*/%v107428_v54, /*on_false_vx=*/%v107425_v25 (stack66)
        %v108674_v9 = vshrl.u32 %v108667_v32, 19 (stack46)
        %v109084_v60 = vadd.s32 1, %v109080_v61 (stack40)
        %v106979_v27 = vsel /*vm=*/%vm106974_vm9, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v153266_v22 = vxor.u32 2147483648, %v107431_v55 (stack56)
        %v107836_v34 = vxor.u32 %v107835_v6, %v107827_v44 (stack48)
        %v108236_v50 = vadd.s32 %v108233_v29, %v108228_v50 (stack40)
        %vm153270_vm15 = vcmp.eq.f32.partialorder %v106947_v42, 1.0 (stack68)
        %v106955_v43 = vmul.f32 inf, %v153060_v41 (stack54)
        %v107094_v46 = vadd.f32 %v107090_v52, %v106979_v27 (stack53)
        %v109088_v56 = vadd.s32 %v109084_v60, %v109072_v45 (stack40)
        %vm107435_vm0 = vcmp.lt.f32.partialorder %v153266_v22, 5.0 (stack68)
        %121351 = vrsqrt.f32 %v153266_v22 (stack67)
        %v109507_v32 = vshll.u32 %v153225_v12, 13 (stack45)
        %v109508_v61 = vshrl.u32 %v153225_v12, 19 (stack46)
        %v107098_v41 = vmul.f32 %v107094_v46, %v153060_v41 (stack54)
        %v108238_v53 = vshll.u32 %v108233_v29, 16 (stack45)
        %v108239_v20 = vshrl.u32 %v108233_v29, 16 (stack46)
        %v108675_v31 = vor.u32 %v108674_v9, %v108673_v10 (stack47)
        %v153281_v24 = vadd.f32 -2.5, %v153266_v22 (stack53)
        %v107831_v44 = vadd.s32 %v107827_v44, %v121564_v0 (stack40)
        %v107839_v26 = vadd.s32 %v107836_v34, %v121574_v2 (stack40)
        %v109497_v23 = vadd.s32 %v109492_v23, %v121574_v2 (stack40)
        %v107102_v25 = vsel /*vm=*/%vm153270_vm15, /*on_true_vy=*/%v106955_v43, /*on_false_vx=*/%v107098_v41 (stack44)
        %v153291_v54 = vsel /*vm=*/%vm107435_vm0, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v153296_v6 = vsel /*vm=*/%vm107435_vm0, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v153301_v29 = vsel /*vm=*/%vm107435_vm0, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v107106_v10 = vmul.f32 1.4140625, %v107102_v25 (stack54)
        %v153306_v45 = vsel /*vm=*/%vm107435_vm0, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v153311_v52 = vsel /*vm=*/%vm107435_vm0, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v107843_v55 = vadd.s32 5, %v107839_v26 (stack40)
        %v108240_v9 = vor.u32 %v108239_v20, %v108238_v53 (stack47)
        %v108676_v27 = vxor.u32 %v108675_v31, %v108671_v30 (stack48)
        %v109090_v34 = vshll.u32 %v109084_v60, 17 (stack45)
        %v109091_v60 = vshrl.u32 %v109084_v60, 15 (stack46)
        %v107109_v42 = vpack.c.bf16 %v157387_v11, %v107106_v10 (stack81)
        %v107845_v43 = vxor.u32 %v107843_v55, %v107831_v44 (stack48)
        %v109505_v12 = vadd.s32 %v153225_v12, %v109497_v23 (stack40)
        %v109509_v46 = vor.u32 %v109508_v61, %v109507_v32 (stack47)
        %vm107480_vm1 = vcmp.eq.f32.partialorder %v153266_v22, inf (stack70)
        %v108241_v32 = vxor.u32 %v108240_v9, %v108236_v50 (stack48)
        %v108679_v30 = vadd.s32 %v108676_v27, %v108671_v30 (stack40)
        %v108681_v61 = vshll.u32 %v108676_v27, 15 (stack45)
        %v108682_v41 = vshrl.u32 %v108676_v27, 17 (stack46)
        %120317 = vst [vmem:[%s123356_s30 + $0x270] sm:$0xf] /*vst_source=*/%v107109_v42 (stack83)
        %vm107482_vm2 = vcmp.eq.f32.partialorder %v153266_v22, 0.0 (stack71)
        %v107846_v53 = vand.u32.u8 255, %v107845_v43 (stack49)
        %v109092_v20 = vor.u32 %v109091_v60, %v109090_v34 (stack47)
        %v109510_v31 = vxor.u32 %v109509_v46, %v109505_v12 (stack48)
        %v108244_v50 = vadd.s32 %v108241_v32, %v108236_v50 (stack40)
        %v108250_v44 = vshll.u32 %v108241_v32, 24 (stack45)
        %v108251_v26 = vshrl.u32 %v108241_v32, 8 (stack46)
        %v108683_v23 = vor.u32 %v108682_v41, %v108681_v61 (stack47)
        %v107847_v25 = vand.u32 65535, %v107846_v53 (stack50)
        %v109093_v10 = vxor.u32 %v109092_v20, %v109088_v56 (stack48)
        %v109513_v55 = vadd.s32 %v109510_v31, %v109505_v12 (stack40)
        %v109515_v9 = vshll.u32 %v109510_v31, 15 (stack45)
        %v107483_v27 = vand.u32 2147483648, %v153266_v22 (stack72)
        %v108252_v34 = vor.u32 %v108251_v26, %v108250_v44 (stack47)
        %v108684_v60 = vxor.u32 %v108683_v23, %v108679_v30 (stack48)
        %v109516_v42 = vshrl.u32 %v109510_v31, 17 (stack46)
        %v107848_v43 = vshrl.u32 %v107847_v25, 1 (stack51)
        %v109096_v56 = vadd.s32 %v109093_v10, %v109088_v56 (stack40)
        %v109098_v12 = vshll.u32 %v109093_v10, 29 (stack45)
        %v109099_v46 = vshrl.u32 %v109093_v10, 3 (stack46)
        %v121352_v32 = vpop.eup %121351 (stack73)
        %v108253_v61 = vxor.u32 %v108252_v34, %v108244_v50 (stack48)
        %v108687_v30 = vadd.s32 %v108684_v60, %v108679_v30 (stack40)
        %v108689_v41 = vshll.u32 %v108684_v60, 26 (stack45)
        %v108690_v53 = vshrl.u32 %v108684_v60, 6 (stack46)
        %v107479_v20 = vmul.f32 %v121352_v32, %v153266_v22 (stack74)
        %v107849_v31 = vor.u32 16256, %v107848_v43 (stack47)
        %v109100_v44 = vor.u32 %v109099_v46, %v109098_v12 (stack47)
        %v109517_v26 = vor.u32 %v109516_v42, %v109515_v9 (stack47)
        %v108248_v50 = vadd.s32 %v108244_v50, %v121569_v1 (stack40)
        %v108256_v23 = vadd.s32 %v108253_v61, %v121564_v0 (stack40)
        %v108691_v25 = vor.u32 %v108690_v53, %v108689_v41 (stack47)
        %vm109932_vm3 = vcmp.lt.u32.totalorder %v153250_v7, %v157079_v39 (stack43)
        %v107481_v10 = vsel /*vm=*/%vm107480_vm1, /*on_true_vy=*/%v153266_v22, /*on_false_vx=*/%v107479_v20 (stack75)
        %v107850_v9 = vand.u32.u16 65535, %v107849_v31 (stack52)
        %v109101_v34 = vxor.u32 %v109100_v44, %v109096_v56 (stack48)
        %v109518_v60 = vxor.u32 %v109517_v26, %v109513_v55 (stack48)
        %v107484_v27 = vsel /*vm=*/%vm107482_vm2, /*on_true_vy=*/%v107483_v27, /*on_false_vx=*/%v107481_v10 (stack76)
        %v108260_v42 = vadd.s32 4, %v108256_v23 (stack40)
        %v108692_v43 = vxor.u32 %v108691_v25, %v108687_v30 (stack48)
        %v109937_v12 = vadd.s32 %v157773_v21, %v157082_v49 (stack40)
        %v107487_v46 = vadd.f32 -3.0, %v107484_v27 (stack53)
        %v120320_v32 = vadd.low.f32.bf16 -1.0, %v107850_v9 (stack53)
        %v109104_v56 = vadd.s32 %v109101_v34, %v109096_v56 (stack40)
        %v109106_v61 = vshll.u32 %v109101_v34, 16 (stack45)
        %v108264_v41 = vadd.s32 %v108260_v42, %v108248_v50 (stack40)
        %v108266_v53 = vshll.u32 %v108260_v42, 13 (stack45)
        %v108267_v20 = vshrl.u32 %v108260_v42, 19 (stack46)
        %v108695_v30 = vadd.s32 %v108692_v43, %v108687_v30 (stack40)
        %v153334_v24 = vsel /*vm=*/%vm107435_vm0, /*on_true_vy=*/%v153281_v24, /*on_false_vx=*/%v107487_v46 (stack44)
        %v107859_v31 = vmul.f32 2.0, %v120320_v32 (stack54)
        %v108701_v44 = vshll.u32 %v108692_v43, 6 (stack45)
        %v108702_v26 = vshrl.u32 %v108692_v43, 26 (stack46)
        %v107460_v50 = vsel /*vm=*/%vm107435_vm0, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v107495_v52 = vmul.f32 %v153334_v24, %v153311_v52 (stack54)
        %v108268_v23 = vor.u32 %v108267_v20, %v108266_v53 (stack47)
        %v109107_v25 = vshrl.u32 %v109101_v34, 16 (stack46)
        %v107468_v10 = vsel /*vm=*/%vm107435_vm0, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v107863_v9 = vadd.f32 -0.99609375, %v107859_v31 (stack53)
        %v108703_v34 = vor.u32 %v108702_v26, %v108701_v44 (stack47)
        %v109521_v55 = vadd.s32 %v109518_v60, %v109513_v55 (stack40)
        %v107499_v27 = vadd.f32 %v107495_v52, %v107468_v10 (stack53)
        %v108269_v42 = vxor.u32 %v108268_v23, %v108264_v41 (stack48)
        %v109108_v43 = vor.u32 %v109107_v25, %v109106_v61 (stack47)
        %v153346_v46 = vadd.s32 %v153250_v7, %v122657_v58 (stack40)
        %v153348_v32 = vmax.f32 %v107863_v9, -0.99609375 (stack55)
        %v108704_v61 = vxor.u32 %v108703_v34, %v108695_v30 (stack48)
        %v109523_v53 = vshll.u32 %v109518_v60, 26 (stack45)
        %v109524_v60 = vshrl.u32 %v109518_v60, 6 (stack46)
        %v107503_v20 = vmul.f32 %v107499_v27, %v153334_v24 (stack54)
        %v108272_v41 = vadd.s32 %v108269_v42, %v108264_v41 (stack40)
        %v108274_v31 = vshll.u32 %v108269_v42, 15 (stack45)
        %v108275_v44 = vshrl.u32 %v108269_v42, 17 (stack46)
        %v107464_v26 = vsel /*vm=*/%vm107435_vm0, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v107879_v52 = vxor.u32 2147483648, %v153348_v32 (stack56)
        %v108707_v23 = vadd.s32 %v108704_v61, %v121569_v1 (stack40)
        %v109941_v25 = vadd.s32 1, %v109937_v12 (stack40)
        %v107507_v10 = vadd.f32 %v107503_v20, %v107464_v26 (stack53)
        %v108276_v9 = vor.u32 %v108275_v44, %v108274_v31 (stack47)
        %v108699_v30 = vadd.s32 %v108695_v30, %v121574_v2 (stack40)
        %v109109_v34 = vxor.u32 %v109108_v43, %v109104_v56 (stack48)
        %v107882_v27 = vmul.f32 %v107879_v52, %v153348_v32 (stack54)
        %v108711_v42 = vadd.s32 3, %v108707_v23 (stack40)
        %vm109927_vm4 = vcmp.lt.u32.totalorder %v153346_v46, %v153250_v7 (stack43)
        %v109945_v12 = vsel /*vm=*/%vm109932_vm3, /*on_true_vy=*/%v109941_v25, /*on_false_vx=*/%v109937_v12 (stack44)
        %v153365_v43 = vadd.s32 %v153346_v46, %v121569_v1 (stack40)
        %v107511_v61 = vmul.f32 %v107507_v10, %v153334_v24 (stack54)
        %v108277_v20 = vxor.u32 %v108276_v9, %v108272_v41 (stack48)
        %v109112_v56 = vadd.s32 %v109109_v34, %v109104_v56 (stack40)
        %v109525_v53 = vor.u32 %v109524_v60, %v109523_v53 (stack47)
        %v107884_v60 = vadd.f32 1.0, %v107882_v27 (stack57)
        %v107887_v31 = vmul.f32 -0.5, %v107882_v27 (stack59)
        %v108715_v44 = vadd.s32 %v108711_v42, %v108699_v30 (stack40)
        %v109118_v26 = vshll.u32 %v109109_v34, 24 (stack45)
        %v107515_v50 = vadd.f32 %v107511_v61, %v107460_v50 (stack53)
        %v108280_v41 = vadd.s32 %v108277_v20, %v108272_v41 (stack40)
        %v108282_v52 = vshll.u32 %v108277_v20, 26 (stack45)
        %v108283_v23 = vshrl.u32 %v108277_v20, 6 (stack46)
        %121353 = vlog2.f32 %v107884_v60 (stack58)
        %v107888_v25 = vadd.f32 1.0, %v107887_v31 (stack61)
        %v107890_v10 = vand.u32 2147483647, %v107882_v27 (stack60)
        %v108717_v9 = vshll.u32 %v108711_v42, 17 (stack45)
        %v107519_v30 = vmul.f32 %v107515_v50, %v153334_v24 (stack54)
        %v108284_v61 = vor.u32 %v108283_v23, %v108282_v52 (stack47)
        %v108718_v42 = vshrl.u32 %v108711_v42, 15 (stack46)
        %v109116_v20 = vadd.s32 %v109112_v56, %v121564_v0 (stack40)
        %v107889_v27 = vmul.f32 %v107888_v25, %v107882_v27 (stack63)
        %v109119_v34 = vshrl.u32 %v109109_v34, 8 (stack46)
        %v109526_v53 = vxor.u32 %v109525_v53, %v109521_v55 (stack48)
        %v109949_v60 = vadd.s32 1, %v109945_v12 (stack40)
        %v107523_v45 = vadd.f32 %v107519_v30, %v153306_v45 (stack53)
        %v108285_v31 = vxor.u32 %v108284_v61, %v108280_v41 (stack48)
        %v108719_v50 = vor.u32 %v108718_v42, %v108717_v9 (stack47)
        %v109968_v52 = vshll.u32 %v153365_v43, 13 (stack45)
        %v109120_v26 = vor.u32 %v109119_v34, %v109118_v26 (stack47)
        %v109529_v55 = vadd.s32 %v109526_v53, %v109521_v55 (stack40)
        %v109535_v23 = vshll.u32 %v109526_v53, 6 (stack45)
        %v109536_v25 = vshrl.u32 %v109526_v53, 26 (stack46)
        %v107527_v9 = vmul.f32 %v107523_v45, %v153334_v24 (stack54)
        %v108288_v41 = vadd.s32 %v108285_v31, %v108280_v41 (stack40)
        %v108294_v30 = vshll.u32 %v108285_v31, 6 (stack45)
        %v108295_v61 = vshrl.u32 %v108285_v31, 26 (stack46)
        %v108720_v42 = vxor.u32 %v108719_v50, %v108715_v44 (stack48)
        %v109121_v56 = vxor.u32 %v109120_v26, %v109112_v56 (stack48)
        %v109533_v34 = vadd.s32 %v109529_v55, %v121569_v1 (stack40)
        %v109537_v53 = vor.u32 %v109536_v25, %v109535_v23 (stack47)
        %v107531_v29 = vadd.f32 %v107527_v9, %v153301_v29 (stack53)
        %vm153375_vm5 = vcmp.lt.f32.partialorder %v107890_v10, 0.0004427343 (stack62)
        %v108292_v45 = vadd.s32 %v108288_v41, %v121564_v0 (stack40)
        %v108296_v31 = vor.u32 %v108295_v61, %v108294_v30 (stack47)
        %v109953_v7 = vsel /*vm=*/%vm109927_vm4, /*on_true_vy=*/%v109949_v60, /*on_false_vx=*/%v109945_v12 (stack44)
        %v108723_v46 = vadd.s32 %v108720_v42, %v108715_v44 (stack40)
        %v108725_v12 = vshll.u32 %v108720_v42, 29 (stack45)
        %v108726_v44 = vshrl.u32 %v108720_v42, 3 (stack46)
        %v109124_v60 = vadd.s32 %v109121_v56, %v121574_v2 (stack40)
        %v107535_v50 = vmul.f32 %v107531_v29, %v153334_v24 (stack54)
        %v108297_v26 = vxor.u32 %v108296_v31, %v108288_v41 (stack48)
        %v109538_v55 = vxor.u32 %v109537_v53, %v109529_v55 (stack48)
        %v109958_v23 = vadd.s32 %v109953_v7, %v121574_v2 (stack40)
        %v108727_v25 = vor.u32 %v108726_v44, %v108725_v12 (stack47)
        %v109128_v9 = vadd.s32 2, %v109124_v60 (stack40)
        %v109969_v41 = vshrl.u32 %v153365_v43, 19 (stack46)
        %v153389_v30 = vadd.s32 %v157770_v40, %v157083_v59 (stack40)
        %v107539_v6 = vadd.f32 %v107535_v50, %v153296_v6 (stack53)
        %v108300_v61 = vadd.s32 %v108297_v26, %v121574_v2 (stack40)
        %v109541_v42 = vadd.s32 %v109538_v55, %v121564_v0 (stack40)
        %v109966_v43 = vadd.s32 %v153365_v43, %v109958_v23 (stack40)
        %v108728_v56 = vxor.u32 %v108727_v25, %v108723_v46 (stack48)
        %v109132_v20 = vadd.s32 %v109128_v9, %v109116_v20 (stack40)
        %v109134_v53 = vshll.u32 %v109128_v9, 13 (stack45)
        %v109135_v29 = vshrl.u32 %v109128_v9, 19 (stack46)
        %v121354_v31 = vpop.eup %121353 (stack64)
        %v107543_v7 = vmul.f32 %v107539_v6, %v153334_v24 (stack54)
        %v108304_v12 = vadd.s32 5, %v108300_v61 (stack40)
        %v109545_v44 = vadd.s32 1, %v109541_v42 (stack40)
        %v109970_v52 = vor.u32 %v109969_v41, %v109968_v52 (stack47)
        %v107886_v60 = vmul.f32 0.6931472, %v121354_v31 (stack65)
        %v108731_v46 = vadd.s32 %v108728_v56, %v108723_v46 (stack40)
        %v108733_v50 = vshll.u32 %v108728_v56, 16 (stack45)
        %v108734_v26 = vshrl.u32 %v108728_v56, 16 (stack46)
        %v107547_v54 = vadd.f32 %v107543_v7, %v153291_v54 (stack53)
        %v108306_v45 = vxor.u32 %v108304_v12, %v108292_v45 (stack48)
        %v109136_v55 = vor.u32 %v109135_v29, %v109134_v53 (stack47)
        %v109549_v34 = vadd.s32 %v109545_v44, %v109533_v34 (stack40)
        %v107892_v27 = vsel /*vm=*/%vm153375_vm5, /*on_true_vy=*/%v107889_v27, /*on_false_vx=*/%v107886_v60 (stack66)
        %v108735_v10 = vor.u32 %v108734_v26, %v108733_v50 (stack47)
        %v109551_v23 = vshll.u32 %v109545_v44, 17 (stack45)
        %v107551_v24 = vmul.f32 %v107547_v54, %v153334_v24 (stack54)
        %v153400_v25 = vxor.u32 2147483648, %v107892_v27 (stack56)
        %v109137_v9 = vxor.u32 %v109136_v55, %v109132_v20 (stack48)
        %v109552_v41 = vshrl.u32 %v109545_v44, 15 (stack46)
        %v107408_v6 = vand.u32 2147483647, %v153201_v8 (stack77)
        %v107440_v22 = vsel /*vm=*/%vm107435_vm0, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v108736_v61 = vxor.u32 %v108735_v10, %v108731_v46 (stack48)
        %v109971_v42 = vxor.u32 %v109970_v52, %v109966_v43 (stack48)
        %v107555_v56 = vadd.f32 %v107551_v24, %v107440_v22 (stack53)
        %vm107896_vm6 = vcmp.lt.f32.partialorder %v153400_v25, 5.0 (stack68)
        %121355 = vrsqrt.f32 %v153400_v25 (stack67)
        %v108307_v53 = vand.u32.u8 255, %v108306_v45 (stack49)
        %v108739_v29 = vadd.s32 %v108736_v61, %v108731_v46 (stack40)
        %v107416_v31 = vmul.f32 inf, %v153201_v8 (stack54)
        %v107559_v8 = vmul.f32 %v107555_v56, %v153201_v8 (stack54)
        %v109553_v7 = vor.u32 %v109552_v41, %v109551_v23 (stack47)
        %vm107411_vm7 = vcmp.eq.f32.partialorder %v107408_v6, 1.0 (stack68)
        %v153413_v12 = vsel /*vm=*/%vm107896_vm6, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v153416_v44 = vadd.f32 -2.5, %v153400_v25 (stack53)
        %v153420_v52 = vadd.s32 %v153389_v30, %v122657_v58 (stack40)
        %v107563_v60 = vsel /*vm=*/%vm107411_vm7, /*on_true_vy=*/%v107416_v31, /*on_false_vx=*/%v107559_v8 (stack44)
        %v153425_v46 = vsel /*vm=*/%vm107896_vm6, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v153430_v50 = vsel /*vm=*/%vm107896_vm6, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v108743_v26 = vadd.s32 %v108739_v29, %v121569_v1 (stack40)
        %v107567_v54 = vmul.f32 1.4140625, %v107563_v60 (stack54)
        %v108308_v45 = vand.u32 65535, %v108307_v53 (stack50)
        %v108745_v55 = vshll.u32 %v108736_v61, 24 (stack45)
        %v108746_v27 = vshrl.u32 %v108736_v61, 8 (stack46)
        %v109140_v20 = vadd.s32 %v109137_v9, %v109132_v20 (stack40)
        %v109142_v10 = vshll.u32 %v109137_v9, 15 (stack45)
        %v109143_v23 = vshrl.u32 %v109137_v9, 17 (stack46)
        %v109554_v24 = vxor.u32 %v109553_v7, %v109549_v34 (stack48)
        %v107570_v9 = vpack.c.bf16 %v157387_v11, %v107567_v54 (stack81)
        %vm107941_vm8 = vcmp.eq.f32.partialorder %v153400_v25, inf (stack70)
        %v108309_v41 = vshrl.u32 %v108308_v45, 1 (stack51)
        %v108747_v6 = vor.u32 %v108746_v27, %v108745_v55 (stack47)
        %v109974_v43 = vadd.s32 %v109971_v42, %v109966_v43 (stack40)
        %v109144_v22 = vor.u32 %v109143_v23, %v109142_v10 (stack47)
        %v109557_v34 = vadd.s32 %v109554_v24, %v109549_v34 (stack40)
        %v109559_v61 = vshll.u32 %v109554_v24, 29 (stack45)
        %v109560_v56 = vshrl.u32 %v109554_v24, 3 (stack46)
        %120319 = vst [vmem:[%s123356_s30 + $0x2f0] sm:$0xf] /*vst_source=*/%v107570_v9 (stack83)
        %v108310_v53 = vor.u32 16256, %v108309_v41 (stack47)
        %v108748_v29 = vxor.u32 %v108747_v6, %v108739_v29 (stack48)
        %v109976_v31 = vshll.u32 %v109971_v42, 15 (stack45)
        %v109977_v42 = vshrl.u32 %v109971_v42, 17 (stack46)
        %vm107943_vm9 = vcmp.eq.f32.partialorder %v153400_v25, 0.0 (stack71)
        %v109145_v8 = vxor.u32 %v109144_v22, %v109140_v20 (stack48)
        %v109561_v7 = vor.u32 %v109560_v56, %v109559_v61 (stack47)
        %vm110393_vm10 = vcmp.lt.u32.totalorder %v153389_v30, %v157083_v59 (stack43)
        %v108311_v60 = vand.u32.u16 65535, %v108310_v53 (stack52)
        %v108751_v54 = vadd.s32 %v108748_v29, %v121564_v0 (stack40)
        %v109978_v45 = vor.u32 %v109977_v42, %v109976_v31 (stack47)
        %v110398_v55 = vadd.s32 %v157773_v21, %v157084_v16 (stack40)
        %v109148_v27 = vadd.s32 %v109145_v8, %v109140_v20 (stack40)
        %v109150_v20 = vshll.u32 %v109145_v8, 26 (stack45)
        %v109151_v10 = vshrl.u32 %v109145_v8, 6 (stack46)
        %v109562_v23 = vxor.u32 %v109561_v7, %v109557_v34 (stack48)
        %v121356_v24 = vpop.eup %121355 (stack73)
        %v107944_v9 = vand.u32 2147483648, %v153400_v25 (stack72)
        %v120322_v41 = vadd.low.f32.bf16 -1.0, %v108311_v60 (stack53)
        %v108755_v6 = vadd.s32 4, %v108751_v54 (stack40)
        %v109979_v22 = vxor.u32 %v109978_v45, %v109974_v43 (stack48)
        %v107940_v61 = vmul.f32 %v121356_v24, %v153400_v25 (stack74)
        %v109152_v56 = vor.u32 %v109151_v10, %v109150_v20 (stack47)
        %v109565_v34 = vadd.s32 %v109562_v23, %v109557_v34 (stack40)
        %v109567_v53 = vshll.u32 %v109562_v23, 16 (stack45)
        %v108320_v29 = vmul.f32 2.0, %v120322_v41 (stack54)
        %v108759_v26 = vadd.s32 %v108755_v6, %v108743_v26 (stack40)
        %v108761_v31 = vshll.u32 %v108755_v6, 13 (stack45)
        %v108762_v42 = vshrl.u32 %v108755_v6, 19 (stack46)
        %v107942_v8 = vsel /*vm=*/%vm107941_vm8, /*on_true_vy=*/%v153400_v25, /*on_false_vx=*/%v107940_v61 (stack75)
        %v109153_v7 = vxor.u32 %v109152_v56, %v109148_v27 (stack48)
        %v109568_v60 = vshrl.u32 %v109562_v23, 16 (stack46)
        %v153447_v43 = vadd.s32 %v109979_v22, %v109974_v43 (stack40)
        %v107945_v54 = vsel /*vm=*/%vm107943_vm9, /*on_true_vy=*/%v107944_v9, /*on_false_vx=*/%v107942_v8 (stack76)
        %v108324_v45 = vadd.f32 -0.99609375, %v108320_v29 (stack53)
        %v108763_v20 = vor.u32 %v108762_v42, %v108761_v31 (stack47)
        %v110402_v10 = vadd.s32 1, %v110398_v55 (stack40)
        %v107948_v23 = vadd.f32 -3.0, %v107945_v54 (stack53)
        %v109156_v27 = vadd.s32 %v109153_v7, %v109148_v27 (stack40)
        %v109162_v24 = vshll.u32 %v109153_v7, 6 (stack45)
        %v109163_v9 = vshrl.u32 %v109153_v7, 26 (stack46)
        %v107929_v41 = vsel /*vm=*/%vm107896_vm6, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v153454_v6 = vmax.f32 %v108324_v45, -0.99609375 (stack55)
        %v108764_v61 = vxor.u32 %v108763_v20, %v108759_v26 (stack48)
        %v109569_v56 = vor.u32 %v109568_v60, %v109567_v53 (stack47)
        %v107933_v53 = vsel /*vm=*/%vm107896_vm6, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v153462_v44 = vsel /*vm=*/%vm107896_vm6, /*on_true_vy=*/%v153416_v44, /*on_false_vx=*/%v107948_v23 (stack44)
        %v109164_v29 = vor.u32 %v109163_v9, %v109162_v24 (stack47)
        %v110406_v55 = vsel /*vm=*/%vm110393_vm10, /*on_true_vy=*/%v110402_v10, /*on_false_vx=*/%v110398_v55 (stack44)
        %v107956_v31 = vmul.f32 %v153462_v44, %v107933_v53 (stack54)
        %v108340_v42 = vxor.u32 2147483648, %v153454_v6 (stack56)
        %v109984_v8 = vshll.u32 %v109979_v22, 26 (stack45)
        %v109985_v22 = vshrl.u32 %v109979_v22, 6 (stack46)
        %v108767_v26 = vadd.s32 %v108764_v61, %v108759_v26 (stack40)
        %v108769_v7 = vshll.u32 %v108764_v61, 15 (stack45)
        %v108770_v60 = vshrl.u32 %v108764_v61, 17 (stack46)
        %v109165_v54 = vxor.u32 %v109164_v29, %v109156_v27 (stack48)
        %v107921_v45 = vsel /*vm=*/%vm107896_vm6, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v107960_v20 = vadd.f32 %v107956_v31, %v107929_v41 (stack53)
        %v108343_v10 = vmul.f32 %v108340_v42, %v153454_v6 (stack54)
        %v109570_v23 = vxor.u32 %v109569_v56, %v109565_v34 (stack48)
        %v107925_v24 = vsel /*vm=*/%vm107896_vm6, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v108771_v9 = vor.u32 %v108770_v60, %v108769_v7 (stack47)
        %v109168_v41 = vadd.s32 %v109165_v54, %v121569_v1 (stack40)
        %vm110388_vm11 = vcmp.lt.u32.totalorder %v153420_v52, %v153389_v30 (stack43)
        %v107964_v61 = vmul.f32 %v107960_v20, %v153462_v44 (stack54)
        %v108345_v56 = vadd.f32 1.0, %v108343_v10 (stack57)
        %v109160_v27 = vadd.s32 %v109156_v27, %v121574_v2 (stack40)
        %v109986_v53 = vor.u32 %v109985_v22, %v109984_v8 (stack47)
        %v108348_v29 = vmul.f32 -0.5, %v108343_v10 (stack59)
        %v108772_v31 = vxor.u32 %v108771_v9, %v108767_v26 (stack48)
        %v109172_v42 = vadd.s32 3, %v109168_v41 (stack40)
        %v109573_v34 = vadd.s32 %v109570_v23, %v109565_v34 (stack40)
        %v107968_v8 = vadd.f32 %v107964_v61, %v107925_v24 (stack53)
        %121357 = vlog2.f32 %v108345_v56 (stack58)
        %v109579_v22 = vshll.u32 %v109570_v23, 24 (stack45)
        %v110410_v7 = vadd.s32 1, %v110406_v55 (stack40)
        %v108775_v26 = vadd.s32 %v108772_v31, %v108767_v26 (stack40)
        %v108777_v60 = vshll.u32 %v108772_v31, 26 (stack45)
        %v108778_v54 = vshrl.u32 %v108772_v31, 6 (stack46)
        %v109176_v20 = vadd.s32 %v109172_v42, %v109160_v27 (stack40)
        %v107972_v24 = vmul.f32 %v107968_v8, %v153462_v44 (stack54)
        %v108351_v9 = vand.u32 2147483647, %v108343_v10 (stack60)
        %v109178_v41 = vshll.u32 %v109172_v42, 17 (stack45)
        %v109179_v61 = vshrl.u32 %v109172_v42, 15 (stack46)
        %v108349_v56 = vadd.f32 1.0, %v108348_v29 (stack61)
        %v108779_v27 = vor.u32 %v108778_v54, %v108777_v60 (stack47)
        %v109580_v23 = vshrl.u32 %v109570_v23, 8 (stack46)
        %v109987_v53 = vxor.u32 %v109986_v53, %v153447_v43 (stack48)
        %v107976_v45 = vadd.f32 %v107972_v24, %v107921_v45 (stack53)
        %v109180_v29 = vor.u32 %v109179_v61, %v109178_v41 (stack47)
        %v110414_v30 = vsel /*vm=*/%vm110388_vm11, /*on_true_vy=*/%v110410_v7, /*on_false_vx=*/%v110406_v55 (stack44)
        %v110423_v52 = vadd.s32 %v153420_v52, %v121569_v1 (stack40)
        %v108780_v55 = vxor.u32 %v108779_v27, %v108775_v26 (stack48)
        %v109581_v31 = vor.u32 %v109580_v23, %v109579_v22 (stack47)
        %v153489_v43 = vadd.s32 %v109987_v53, %v153447_v43 (stack40)
        %v109996_v42 = vshll.u32 %v109987_v53, 6 (stack45)
        %v107980_v8 = vmul.f32 %v107976_v45, %v153462_v44 (stack54)
        %v109181_v22 = vxor.u32 %v109180_v29, %v109176_v20 (stack48)
        %v109997_v7 = vshrl.u32 %v109987_v53, 26 (stack46)
        %v110419_v60 = vadd.s32 %v110414_v30, %v121574_v2 (stack40)
        %vm153493_vm12 = vcmp.lt.f32.partialorder %v108351_v9, 0.0004427343 (stack62)
        %v108783_v26 = vadd.s32 %v108780_v55, %v108775_v26 (stack40)
        %v108789_v24 = vshll.u32 %v108780_v55, 6 (stack45)
        %v108790_v9 = vshrl.u32 %v108780_v55, 26 (stack46)
        %v109582_v41 = vxor.u32 %v109581_v31, %v109573_v34 (stack48)
        %v107984_v50 = vadd.f32 %v107980_v8, %v153430_v50 (stack53)
        %v109184_v20 = vadd.s32 %v109181_v22, %v109176_v20 (stack40)
        %v109186_v61 = vshll.u32 %v109181_v22, 29 (stack45)
        %v109187_v27 = vshrl.u32 %v109181_v22, 3 (stack46)
        %v108350_v10 = vmul.f32 %v108349_v56, %v108343_v10 (stack63)
        %v108791_v56 = vor.u32 %v108790_v9, %v108789_v24 (stack47)
        %v109577_v34 = vadd.s32 %v109573_v34, %v121564_v0 (stack40)
        %v109585_v23 = vadd.s32 %v109582_v41, %v121574_v2 (stack40)
        %v107988_v53 = vmul.f32 %v107984_v50, %v153462_v44 (stack54)
        %v109188_v45 = vor.u32 %v109187_v27, %v109186_v61 (stack47)
        %v109998_v29 = vor.u32 %v109997_v7, %v109996_v42 (stack47)
        %v153501_v30 = vadd.s32 %v110423_v52, %v110419_v60 (stack40)
        %v108792_v55 = vxor.u32 %v108791_v56, %v108783_v26 (stack48)
        %v109589_v31 = vadd.s32 2, %v109585_v23 (stack40)
        %v110429_v42 = vshll.u32 %v110423_v52, 13 (stack45)
        %v110430_v52 = vshrl.u32 %v110423_v52, 19 (stack46)
        %v107992_v46 = vadd.f32 %v107988_v53, %v153425_v46 (stack53)
        %v109189_v8 = vxor.u32 %v109188_v45, %v109184_v20 (stack48)
        %v109999_v22 = vxor.u32 %v109998_v29, %v153489_v43 (stack48)
        %v153507_v7 = vadd.s32 %v157770_v40, %v157089_v17 (stack40)
        %v121358_v60 = vpop.eup %121357 (stack64)
        %v108795_v24 = vadd.s32 %v108792_v55, %v121574_v2 (stack40)
        %v109593_v9 = vadd.s32 %v109589_v31, %v109577_v34 (stack40)
        %v109595_v41 = vshll.u32 %v109589_v31, 13 (stack45)
        %v109596_v50 = vshrl.u32 %v109589_v31, 19 (stack46)
        %v107996_v61 = vmul.f32 %v107992_v46, %v153462_v44 (stack54)
        %v108347_v27 = vmul.f32 0.6931472, %v121358_v60 (stack65)
        %v109192_v20 = vadd.s32 %v109189_v8, %v109184_v20 (stack40)
        %v109194_v56 = vshll.u32 %v109189_v8, 16 (stack45)
        %v108787_v26 = vadd.s32 %v108783_v26, %v121564_v0 (stack40)
        %v108799_v34 = vadd.s32 5, %v108795_v24 (stack40)
        %v109195_v23 = vshrl.u32 %v109189_v8, 16 (stack46)
        %v109597_v53 = vor.u32 %v109596_v50, %v109595_v41 (stack47)
        %v107869_v45 = vand.u32 2147483647, %v153348_v32 (stack77)
        %v108000_v12 = vadd.f32 %v107996_v61, %v153413_v12 (stack53)
        %v108353_v54 = vsel /*vm=*/%vm153493_vm12, /*on_true_vy=*/%v108350_v10, /*on_false_vx=*/%v108347_v27 (stack66)
        %v110431_v10 = vor.u32 %v110430_v52, %v110429_v42 (stack47)
        %v153516_v29 = vxor.u32 2147483648, %v108353_v54 (stack56)
        %v108801_v55 = vxor.u32 %v108799_v34, %v108787_v26 (stack48)
        %v109196_v31 = vor.u32 %v109195_v23, %v109194_v56 (stack47)
        %v109598_v42 = vxor.u32 %v109597_v53, %v109593_v9 (stack48)
        %v108004_v52 = vmul.f32 %v108000_v12, %v153462_v44 (stack54)
        %v110002_v46 = vadd.s32 %v109999_v22, %v121564_v0 (stack40)
        %v110432_v8 = vxor.u32 %v110431_v10, %v153501_v30 (stack48)
        %v107905_v22 = vsel /*vm=*/%vm107896_vm6, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %121359 = vrsqrt.f32 %v153516_v29 (stack67)
        %v108008_v60 = vadd.f32 %v108004_v52, %v107905_v22 (stack53)
        %vm108357_vm13 = vcmp.lt.f32.partialorder %v153516_v29, 5.0 (stack68)
        %vm153526_vm14 = vcmp.eq.f32.partialorder %v107869_v45, 1.0 (stack68)
        %v107877_v41 = vmul.f32 inf, %v153348_v32 (stack54)
        %v107901_v25 = vsel /*vm=*/%vm107896_vm6, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v109197_v50 = vxor.u32 %v109196_v31, %v109192_v20 (stack48)
        %v108012_v44 = vmul.f32 %v108008_v60, %v153462_v44 (stack54)
        %v109994_v43 = vadd.s32 %v153489_v43, %v121569_v1 (stack40)
        %v110006_v61 = vadd.s32 1, %v110002_v46 (stack40)
        %v153539_v27 = vadd.s32 %v153507_v7, %v122657_v58 (stack40)
        %v153544_v56 = vsel /*vm=*/%vm108357_vm13, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v153547_v26 = vadd.f32 -2.5, %v153516_v29 (stack53)
        %v108802_v34 = vand.u32.u8 255, %v108801_v55 (stack49)
        %v109200_v20 = vadd.s32 %v109197_v50, %v109192_v20 (stack40)
        %v108016_v23 = vadd.f32 %v108012_v44, %v107901_v25 (stack53)
        %v109206_v53 = vshll.u32 %v109197_v50, 24 (stack45)
        %v109207_v45 = vshrl.u32 %v109197_v50, 8 (stack46)
        %v109601_v9 = vadd.s32 %v109598_v42, %v109593_v9 (stack40)
        %v108803_v12 = vand.u32 65535, %v108802_v34 (stack50)
        %v109204_v54 = vadd.s32 %v109200_v20, %v121569_v1 (stack40)
        %v109603_v10 = vshll.u32 %v109598_v42, 15 (stack45)
        %v109604_v55 = vshrl.u32 %v109598_v42, 17 (stack46)
        %v108020_v32 = vmul.f32 %v108016_v23, %v153348_v32 (stack54)
        %vm108402_vm15 = vcmp.eq.f32.partialorder %v153516_v29, inf (stack70)
        %v109208_v31 = vor.u32 %v109207_v45, %v109206_v53 (stack47)
        %v110010_v42 = vadd.s32 %v110006_v61, %v109994_v43 (stack40)
        %v110012_v52 = vshll.u32 %v110006_v61, 17 (stack45)
        %v108804_v46 = vshrl.u32 %v108803_v12, 1 (stack51)
        %v109605_v22 = vor.u32 %v109604_v55, %v109603_v10 (stack47)
        %v110013_v60 = vshrl.u32 %v110006_v61, 15 (stack46)
        %v110435_v30 = vadd.s32 %v110432_v8, %v153501_v30 (stack40)
        %v108024_v24 = vsel /*vm=*/%vm153526_vm14, /*on_true_vy=*/%v107877_v41, /*on_false_vx=*/%v108020_v32 (stack44)
        %v109209_v41 = vxor.u32 %v109208_v31, %v109200_v20 (stack48)
        %v110437_v25 = vshll.u32 %v110432_v8, 15 (stack45)
        %v110438_v8 = vshrl.u32 %v110432_v8, 17 (stack46)
        %v108028_v50 = vmul.f32 1.4140625, %v108024_v24 (stack54)
        %v108805_v44 = vor.u32 16256, %v108804_v46 (stack47)
        %v109606_v43 = vxor.u32 %v109605_v22, %v109601_v9 (stack48)
        %v110014_v61 = vor.u32 %v110013_v60, %v110012_v52 (stack47)
        %v109212_v34 = vadd.s32 %v109209_v41, %v121564_v0 (stack40)
        %v110439_v20 = vor.u32 %v110438_v8, %v110437_v25 (stack47)
        %vm110854_vm0 = vcmp.lt.u32.totalorder %v153507_v7, %v157089_v17 (stack43)
        %v110859_v23 = vadd.s32 %v157773_v21, %v157090_v62 (stack40)
        %v108031_v53 = vpack.c.bf16 %v157387_v11, %v108028_v50 (stack81)
        %v108806_v45 = vand.u32.u16 65535, %v108805_v44 (stack52)
        %v109609_v9 = vadd.s32 %v109606_v43, %v109601_v9 (stack40)
        %v109611_v12 = vshll.u32 %v109606_v43, 26 (stack45)
        %v121360_v10 = vpop.eup %121359 (stack73)
        %v109216_v55 = vadd.s32 4, %v109212_v34 (stack40)
        %v109612_v32 = vshrl.u32 %v109606_v43, 6 (stack46)
        %v110015_v31 = vxor.u32 %v110014_v61, %v110010_v42 (stack48)
        %v110440_v52 = vxor.u32 %v110439_v20, %v110435_v30 (stack48)
        %120321 = vst [vmem:[%s123356_s30 + $0x370] sm:$0xf] /*vst_source=*/%v108031_v53 (stack83)
        %v108401_v46 = vmul.f32 %v121360_v10, %v153516_v29 (stack74)
        %vm108404_vm1 = vcmp.eq.f32.partialorder %v153516_v29, 0.0 (stack71)
        %v108405_v22 = vand.u32 2147483648, %v153516_v29 (stack72)
        %v120328_v60 = vadd.low.f32.bf16 -1.0, %v108806_v45 (stack53)
        %v109220_v54 = vadd.s32 %v109216_v55, %v109204_v54 (stack40)
        %v109222_v24 = vshll.u32 %v109216_v55, 13 (stack45)
        %v109223_v41 = vshrl.u32 %v109216_v55, 19 (stack46)
        %v109613_v25 = vor.u32 %v109612_v32, %v109611_v12 (stack47)
        %v108403_v8 = vsel /*vm=*/%vm108402_vm15, /*on_true_vy=*/%v153516_v29, /*on_false_vx=*/%v108401_v46 (stack75)
        %v108815_v50 = vmul.f32 2.0, %v120328_v60 (stack54)
        %v110018_v42 = vadd.s32 %v110015_v31, %v110010_v42 (stack40)
        %v110020_v44 = vshll.u32 %v110015_v31, 29 (stack45)
        %v108406_v43 = vsel /*vm=*/%vm108404_vm1, /*on_true_vy=*/%v108405_v22, /*on_false_vx=*/%v108403_v8 (stack76)
        %v109224_v61 = vor.u32 %v109223_v41, %v109222_v24 (stack47)
        %v109614_v34 = vxor.u32 %v109613_v25, %v109609_v9 (stack48)
        %v110021_v20 = vshrl.u32 %v110015_v31, 3 (stack46)
        %v108409_v53 = vadd.f32 -3.0, %v108406_v43 (stack53)
        %v108819_v45 = vadd.f32 -0.99609375, %v108815_v50 (stack53)
        %v110443_v30 = vadd.s32 %v110440_v52, %v110435_v30 (stack40)
        %v110445_v12 = vshll.u32 %v110440_v52, 26 (stack45)
        %v109225_v10 = vxor.u32 %v109224_v61, %v109220_v54 (stack48)
        %v109617_v9 = vadd.s32 %v109614_v34, %v109609_v9 (stack40)
        %v109623_v55 = vshll.u32 %v109614_v34, 6 (stack45)
        %v109624_v32 = vshrl.u32 %v109614_v34, 26 (stack46)
        %v153571_v26 = vsel /*vm=*/%vm108357_vm13, /*on_true_vy=*/%v153547_v26, /*on_false_vx=*/%v108409_v53 (stack44)
        %v153573_v31 = vmax.f32 %v108819_v45, -0.99609375 (stack55)
        %v110022_v46 = vor.u32 %v110021_v20, %v110020_v44 (stack47)
        %v110446_v52 = vshrl.u32 %v110440_v52, 6 (stack46)
        %v108417_v56 = vmul.f32 %v153571_v26, %v153544_v56 (stack54)
        %v109228_v22 = vadd.s32 %v109225_v10, %v109220_v54 (stack40)
        %v109230_v60 = vshll.u32 %v109225_v10, 15 (stack45)
        %v109231_v54 = vshrl.u32 %v109225_v10, 17 (stack46)
        %v108330_v24 = vand.u32 2147483647, %v153454_v6 (stack77)
        %v108390_v41 = vsel /*vm=*/%vm108357_vm13, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v108835_v25 = vxor.u32 2147483648, %v153573_v31 (stack56)
        %v110863_v8 = vadd.s32 1, %v110859_v23 (stack40)
        %v108421_v50 = vadd.f32 %v108417_v56, %v108390_v41 (stack53)
        %v109232_v44 = vor.u32 %v109231_v54, %v109230_v60 (stack47)
        %v109625_v43 = vor.u32 %v109624_v32, %v109623_v55 (stack47)
        %v110023_v61 = vxor.u32 %v110022_v46, %v110018_v42 (stack48)
        %v153585_v34 = vsel /*vm=*/%vm108357_vm13, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v153588_v20 = vmul.f32 %v108835_v25, %v153573_v31 (stack54)
        %v110447_v53 = vor.u32 %v110446_v52, %v110445_v12 (stack47)
        %vm110849_vm2 = vcmp.lt.u32.totalorder %v153539_v27, %v153507_v7 (stack43)
        %v110867_v23 = vsel /*vm=*/%vm110854_vm0, /*on_true_vy=*/%v110863_v8, /*on_false_vx=*/%v110859_v23 (stack44)
        %v108425_v45 = vmul.f32 %v108421_v50, %v153571_v26 (stack54)
        %v109233_v12 = vxor.u32 %v109232_v44, %v109228_v22 (stack48)
        %v109626_v10 = vxor.u32 %v109625_v43, %v109617_v9 (stack48)
        %v110026_v42 = vadd.s32 %v110023_v61, %v110018_v42 (stack40)
        %v108374_v55 = vsel /*vm=*/%vm108357_vm13, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v108386_v32 = vsel /*vm=*/%vm108357_vm13, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v108840_v46 = vadd.f32 1.0, %v153588_v20 (stack57)
        %v110028_v52 = vshll.u32 %v110023_v61, 16 (stack45)
        %v108429_v56 = vadd.f32 %v108425_v45, %v108386_v32 (stack53)
        %v109236_v22 = vadd.s32 %v109233_v12, %v109228_v22 (stack40)
        %v109238_v60 = vshll.u32 %v109233_v12, 26 (stack45)
        %v109239_v54 = vshrl.u32 %v109233_v12, 6 (stack46)
        %v108378_v41 = vsel /*vm=*/%vm108357_vm13, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v108382_v25 = vsel /*vm=*/%vm108357_vm13, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %121361 = vlog2.f32 %v108840_v46 (stack58)
        %v109629_v8 = vadd.s32 %v109626_v10, %v121569_v1 (stack40)
        %v108433_v50 = vmul.f32 %v108429_v56, %v153571_v26 (stack54)
        %v109240_v44 = vor.u32 %v109239_v54, %v109238_v60 (stack47)
        %v110029_v43 = vshrl.u32 %v110023_v61, 16 (stack46)
        %v110448_v61 = vxor.u32 %v110447_v53, %v110443_v30 (stack48)
        %v109621_v9 = vadd.s32 %v109617_v9, %v121574_v2 (stack40)
        %v109633_v53 = vadd.s32 3, %v109629_v8 (stack40)
        %v110871_v45 = vadd.s32 1, %v110867_v23 (stack40)
        %v153614_v12 = vadd.s32 %v153539_v27, %v121569_v1 (stack40)
        %v108437_v10 = vadd.f32 %v108433_v50, %v108382_v25 (stack53)
        %v109241_v32 = vxor.u32 %v109240_v44, %v109236_v22 (stack48)
        %v110030_v46 = vor.u32 %v110029_v43, %v110028_v52 (stack47)
        %v110451_v30 = vadd.s32 %v110448_v61, %v110443_v30 (stack40)
        %v109637_v52 = vadd.s32 %v109633_v53, %v109621_v9 (stack40)
        %v109639_v56 = vshll.u32 %v109633_v53, 17 (stack45)
        %v109640_v60 = vshrl.u32 %v109633_v53, 15 (stack46)
        %v110457_v54 = vshll.u32 %v110448_v61, 6 (stack45)
        %v108441_v25 = vmul.f32 %v108437_v10, %v153571_v26 (stack54)
        %v109244_v22 = vadd.s32 %v109241_v32, %v109236_v22 (stack40)
        %v109250_v8 = vshll.u32 %v109241_v32, 6 (stack45)
        %v109251_v50 = vshrl.u32 %v109241_v32, 26 (stack46)
        %v108843_v44 = vmul.f32 -0.5, %v153588_v20 (stack59)
        %v109641_v43 = vor.u32 %v109640_v60, %v109639_v56 (stack47)
        %v110031_v9 = vxor.u32 %v110030_v46, %v110026_v42 (stack48)
        %v110458_v61 = vshrl.u32 %v110448_v61, 26 (stack46)
        %v108445_v41 = vadd.f32 %v108441_v25, %v108378_v41 (stack53)
        %v108846_v53 = vand.u32 2147483647, %v153588_v20 (stack60)
        %v109252_v10 = vor.u32 %v109251_v50, %v109250_v8 (stack47)
        %v110875_v7 = vsel /*vm=*/%vm110849_vm2, /*on_true_vy=*/%v110871_v45, /*on_false_vx=*/%v110867_v23 (stack44)
        %v109642_v27 = vxor.u32 %v109641_v43, %v109637_v52 (stack48)
        %v110034_v23 = vadd.s32 %v110031_v9, %v110026_v42 (stack40)
        %v110040_v42 = vshll.u32 %v110031_v9, 24 (stack45)
        %v110041_v45 = vshrl.u32 %v110031_v9, 8 (stack46)
        %v108449_v32 = vmul.f32 %v108445_v41, %v153571_v26 (stack54)
        %v109253_v46 = vxor.u32 %v109252_v10, %v109244_v22 (stack48)
        %v110459_v56 = vor.u32 %v110458_v61, %v110457_v54 (stack47)
        %v110880_v60 = vadd.s32 %v110875_v7, %v121574_v2 (stack40)
        %v108844_v54 = vadd.f32 1.0, %v108843_v44 (stack61)
        %v109645_v52 = vadd.s32 %v109642_v27, %v109637_v52 (stack40)
        %v109647_v25 = vshll.u32 %v109642_v27, 29 (stack45)
        %v109648_v8 = vshrl.u32 %v109642_v27, 3 (stack46)
        %v108453_v55 = vadd.f32 %v108449_v32, %v108374_v55 (stack53)
        %v109256_v50 = vadd.s32 %v109253_v46, %v121574_v2 (stack40)
        %v110042_v44 = vor.u32 %v110041_v45, %v110040_v42 (stack47)
        %v110460_v43 = vxor.u32 %v110459_v56, %v110451_v30 (stack48)
        %v109248_v22 = vadd.s32 %v109244_v22, %v121564_v0 (stack40)
        %v109649_v9 = vor.u32 %v109648_v8, %v109647_v25 (stack47)
        %v153627_v61 = vadd.s32 %v153614_v12, %v110880_v60 (stack40)
        %v153631_v41 = vadd.s32 %v157770_v40, %v157091_v37 (stack40)
        %v121362_v10 = vpop.eup %121361 (stack64)
        %v108457_v7 = vmul.f32 %v108453_v55, %v153571_v26 (stack54)
        %v109260_v27 = vadd.s32 5, %v109256_v50 (stack40)
        %v110043_v42 = vxor.u32 %v110042_v44, %v110034_v23 (stack48)
        %v110463_v45 = vadd.s32 %v110460_v43, %v121564_v0 (stack40)
        %v108842_v32 = vmul.f32 0.6931472, %v121362_v10 (stack65)
        %v108845_v20 = vmul.f32 %v108844_v54, %v153588_v20 (stack63)
        %vm108847_vm3 = vcmp.lt.f32.partialorder %v108846_v53, 0.0004427343 (stack62)
        %v109650_v53 = vxor.u32 %v109649_v9, %v109645_v52 (stack48)
        %v108461_v34 = vadd.f32 %v108457_v7, %v153585_v34 (stack53)
        %v109262_v46 = vxor.u32 %v109260_v27, %v109248_v22 (stack48)
        %v110455_v30 = vadd.s32 %v110451_v30, %v121569_v1 (stack40)
        %v110467_v56 = vadd.s32 1, %v110463_v45 (stack40)
        %v108848_v60 = vsel /*vm=*/%vm108847_vm3, /*on_true_vy=*/%v108845_v20, /*on_false_vx=*/%v108842_v32 (stack66)
        %v109653_v54 = vadd.s32 %v109650_v53, %v109645_v52 (stack40)
        %v109655_v52 = vshll.u32 %v109650_v53, 16 (stack45)
        %v109656_v25 = vshrl.u32 %v109650_v53, 16 (stack46)
        %v108366_v8 = vsel /*vm=*/%vm108357_vm13, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v108465_v55 = vmul.f32 %v108461_v34, %v153571_v26 (stack54)
        %v153642_v50 = vxor.u32 2147483648, %v108848_v60 (stack56)
        %v110046_v44 = vadd.s32 %v110043_v42, %v121574_v2 (stack40)
        %v109657_v43 = vor.u32 %v109656_v25, %v109655_v52 (stack47)
        %v110471_v22 = vadd.s32 %v110467_v56, %v110455_v30 (stack40)
        %v110890_v9 = vshll.u32 %v153614_v12, 13 (stack45)
        %v110891_v12 = vshrl.u32 %v153614_v12, 19 (stack46)
        %v108338_v10 = vmul.f32 inf, %v153454_v6 (stack54)
        %v108469_v7 = vadd.f32 %v108465_v55, %v108366_v8 (stack53)
        %121363 = vrsqrt.f32 %v153642_v50 (stack67)
        %vm153651_vm4 = vcmp.eq.f32.partialorder %v108330_v24, 1.0 (stack68)
        %v108362_v29 = vsel /*vm=*/%vm108357_vm13, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v109263_v27 = vand.u32.u8 255, %v109262_v46 (stack49)
        %v109658_v42 = vxor.u32 %v109657_v43, %v109653_v54 (stack48)
        %v108473_v26 = vmul.f32 %v108469_v7, %v153571_v26 (stack54)
        %v108825_v45 = vand.u32 2147483647, %v153573_v31 (stack77)
        %vm108852_vm5 = vcmp.lt.f32.partialorder %v153642_v50, 5.0 (stack68)
        %v110050_v32 = vadd.s32 2, %v110046_v44 (stack40)
        %v109661_v20 = vadd.s32 %v109658_v42, %v109653_v54 (stack40)
        %v110473_v53 = vshll.u32 %v110467_v56, 17 (stack45)
        %v110474_v34 = vshrl.u32 %v110467_v56, 15 (stack46)
        %v110892_v46 = vor.u32 %v110891_v12, %v110890_v9 (stack47)
        %v108477_v30 = vadd.f32 %v108473_v26, %v108362_v29 (stack53)
        %v153662_v56 = vadd.f32 -2.5, %v153642_v50 (stack53)
        %v110038_v23 = vadd.s32 %v110034_v23, %v121564_v0 (stack40)
        %v153667_v60 = vadd.s32 %v153631_v41, %v122657_v58 (stack40)
        %v153672_v54 = vsel /*vm=*/%vm108852_vm5, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v109264_v52 = vand.u32 65535, %v109263_v27 (stack50)
        %v109667_v25 = vshll.u32 %v109658_v42, 24 (stack45)
        %v109668_v8 = vshrl.u32 %v109658_v42, 8 (stack46)
        %v108481_v6 = vmul.f32 %v108477_v30, %v153454_v6 (stack54)
        %v110054_v55 = vadd.s32 %v110050_v32, %v110038_v23 (stack40)
        %v110056_v44 = vshll.u32 %v110050_v32, 13 (stack45)
        %v110057_v43 = vshrl.u32 %v110050_v32, 19 (stack46)
        %vm108897_vm6 = vcmp.eq.f32.partialorder %v153642_v50, inf (stack70)
        %v109265_v9 = vshrl.u32 %v109264_v52, 1 (stack51)
        %v109669_v12 = vor.u32 %v109668_v8, %v109667_v25 (stack47)
        %v110475_v7 = vor.u32 %v110474_v34, %v110473_v53 (stack47)
        %v110893_v29 = vxor.u32 %v110892_v46, %v153627_v61 (stack48)
        %v108485_v10 = vsel /*vm=*/%vm153651_vm4, /*on_true_vy=*/%v108338_v10, /*on_false_vx=*/%v108481_v6 (stack44)
        %vm108899_vm7 = vcmp.eq.f32.partialorder %v153642_v50, 0.0 (stack71)
        %v109665_v24 = vadd.s32 %v109661_v20, %v121569_v1 (stack40)
        %v110058_v27 = vor.u32 %v110057_v43, %v110056_v44 (stack47)
        %vm111315_vm8 = vcmp.lt.u32.totalorder %v153631_v41, %v157091_v37 (stack43)
        %v108489_v42 = vmul.f32 1.4140625, %v108485_v10 (stack54)
        %v109266_v26 = vor.u32 16256, %v109265_v9 (stack47)
        %v109670_v32 = vxor.u32 %v109669_v12, %v109661_v20 (stack48)
        %v110476_v20 = vxor.u32 %v110475_v7, %v110471_v22 (stack48)
        %v110059_v53 = vxor.u32 %v110058_v27, %v110054_v55 (stack48)
        %v110896_v61 = vadd.s32 %v110893_v29, %v153627_v61 (stack40)
        %v110898_v34 = vshll.u32 %v110893_v29, 15 (stack45)
        %v110899_v46 = vshrl.u32 %v110893_v29, 17 (stack46)
        %v108492_v30 = vpack.c.bf16 %v157387_v11, %v108489_v42 (stack81)
        %v109267_v23 = vand.u32.u16 65535, %v109266_v26 (stack52)
        %v109673_v52 = vadd.s32 %v109670_v32, %v121564_v0 (stack40)
        %v110479_v22 = vadd.s32 %v110476_v20, %v110471_v22 (stack40)
        %v110062_v25 = vadd.s32 %v110059_v53, %v110054_v55 (stack40)
        %v110064_v8 = vshll.u32 %v110059_v53, 15 (stack45)
        %v110065_v6 = vshrl.u32 %v110059_v53, 17 (stack46)
        %v110481_v55 = vshll.u32 %v110476_v20, 29 (stack45)
        %v121364_v44 = vpop.eup %121363 (stack73)
        %120323 = vst [vmem:[%s123356_s30 + $0x3f0] sm:$0xf] /*vst_source=*/%v108492_v30 (stack83)
        %v120330_v43 = vadd.low.f32.bf16 -1.0, %v109267_v23 (stack53)
        %v109677_v9 = vadd.s32 4, %v109673_v52 (stack40)
        %v110482_v12 = vshrl.u32 %v110476_v20, 3 (stack46)
        %v110900_v7 = vor.u32 %v110899_v46, %v110898_v34 (stack47)
        %v108896_v29 = vmul.f32 %v121364_v44, %v153642_v50 (stack74)
        %v108900_v10 = vand.u32 2147483648, %v153642_v50 (stack72)
        %v110066_v27 = vor.u32 %v110065_v6, %v110064_v8 (stack47)
        %v153691_v42 = vadd.s32 %v157773_v21, %v157094_v36 (stack40)
        %v109276_v26 = vmul.f32 2.0, %v120330_v43 (stack54)
        %v109681_v24 = vadd.s32 %v109677_v9, %v109665_v24 (stack40)
        %v109683_v32 = vshll.u32 %v109677_v9, 13 (stack45)
        %v109684_v20 = vshrl.u32 %v109677_v9, 19 (stack46)
        %v108898_v53 = vsel /*vm=*/%vm108897_vm6, /*on_true_vy=*/%v153642_v50, /*on_false_vx=*/%v108896_v29 (stack75)
        %v110067_v34 = vxor.u32 %v110066_v27, %v110062_v25 (stack48)
        %v110483_v46 = vor.u32 %v110482_v12, %v110481_v55 (stack47)
        %v110901_v30 = vxor.u32 %v110900_v7, %v110896_v61 (stack48)
        %v153699_v23 = vsel /*vm=*/%vm108852_vm5, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v108901_v52 = vsel /*vm=*/%vm108899_vm7, /*on_true_vy=*/%v108900_v10, /*on_false_vx=*/%v108898_v53 (stack76)
        %v109280_v8 = vadd.f32 -0.99609375, %v109276_v26 (stack53)
        %v109685_v6 = vor.u32 %v109684_v20, %v109683_v32 (stack47)
        %v108904_v55 = vadd.f32 -3.0, %v108901_v52 (stack53)
        %v110070_v25 = vadd.s32 %v110067_v34, %v110062_v25 (stack40)
        %v110072_v44 = vshll.u32 %v110067_v34, 26 (stack45)
        %v110073_v43 = vshrl.u32 %v110067_v34, 6 (stack46)
        %v153703_v9 = vmax.f32 %v109280_v8, -0.99609375 (stack55)
        %v109686_v12 = vxor.u32 %v109685_v6, %v109681_v24 (stack48)
        %v110484_v7 = vxor.u32 %v110483_v46, %v110479_v22 (stack48)
        %v110904_v61 = vadd.s32 %v110901_v30, %v110896_v61 (stack40)
        %v108877_v29 = vsel /*vm=*/%vm108852_vm5, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v108889_v10 = vsel /*vm=*/%vm108852_vm5, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v153714_v56 = vsel /*vm=*/%vm108852_vm5, /*on_true_vy=*/%v153662_v56, /*on_false_vx=*/%v108904_v55 (stack44)
        %v110074_v27 = vor.u32 %v110073_v43, %v110072_v44 (stack47)
        %v108881_v26 = vsel /*vm=*/%vm108852_vm5, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v108885_v32 = vsel /*vm=*/%vm108852_vm5, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v108912_v20 = vmul.f32 %v153714_v56, %v108889_v10 (stack54)
        %v109296_v53 = vxor.u32 2147483648, %v153703_v9 (stack56)
        %v109689_v24 = vadd.s32 %v109686_v12, %v109681_v24 (stack40)
        %v109691_v34 = vshll.u32 %v109686_v12, 15 (stack45)
        %v109692_v46 = vshrl.u32 %v109686_v12, 17 (stack46)
        %v110075_v52 = vxor.u32 %v110074_v27, %v110070_v25 (stack48)
        %v108916_v8 = vadd.f32 %v108912_v20, %v108885_v32 (stack53)
        %v153725_v6 = vmul.f32 %v109296_v53, %v153703_v9 (stack54)
        %v110487_v22 = vadd.s32 %v110484_v7, %v110479_v22 (stack40)
        %v153729_v55 = vadd.s32 %v153667_v60, %v121569_v1 (stack40)
        %v109693_v44 = vor.u32 %v109692_v46, %v109691_v34 (stack47)
        %v110078_v25 = vadd.s32 %v110075_v52, %v110070_v25 (stack40)
        %v110084_v43 = vshll.u32 %v110075_v52, 6 (stack45)
        %v110085_v12 = vshrl.u32 %v110075_v52, 26 (stack46)
        %v108920_v10 = vmul.f32 %v108916_v8, %v153714_v56 (stack54)
        %v109301_v27 = vadd.f32 1.0, %v153725_v6 (stack57)
        %v110906_v32 = vshll.u32 %v110901_v30, 26 (stack45)
        %v110907_v30 = vshrl.u32 %v110901_v30, 6 (stack46)
        %v109304_v20 = vmul.f32 -0.5, %v153725_v6 (stack59)
        %v109694_v53 = vxor.u32 %v109693_v44, %v109689_v24 (stack48)
        %v110086_v34 = vor.u32 %v110085_v12, %v110084_v43 (stack47)
        %v111324_v46 = vadd.s32 1, %v153691_v42 (stack40)
        %v108924_v26 = vadd.f32 %v108920_v10, %v108881_v26 (stack53)
        %121365 = vlog2.f32 %v109301_v27 (stack58)
        %v109307_v52 = vand.u32 2147483647, %v153725_v6 (stack60)
        %v110489_v8 = vshll.u32 %v110484_v7, 16 (stack45)
        %vm111310_vm9 = vcmp.lt.u32.totalorder %v153667_v60, %v153631_v41 (stack43)
        %v109697_v24 = vadd.s32 %v109694_v53, %v109689_v24 (stack40)
        %v109699_v44 = vshll.u32 %v109694_v53, 26 (stack45)
        %v109700_v43 = vshrl.u32 %v109694_v53, 6 (stack46)
        %v110087_v12 = vxor.u32 %v110086_v34, %v110078_v25 (stack48)
        %v108928_v10 = vmul.f32 %v108924_v26, %v153714_v56 (stack54)
        %v110082_v25 = vadd.s32 %v110078_v25, %v121574_v2 (stack40)
        %v110490_v7 = vshrl.u32 %v110484_v7, 16 (stack46)
        %v110908_v27 = vor.u32 %v110907_v30, %v110906_v32 (stack47)
        %v109305_v32 = vadd.f32 1.0, %v109304_v20 (stack61)
        %v109701_v30 = vor.u32 %v109700_v43, %v109699_v44 (stack47)
        %v110090_v20 = vadd.s32 %v110087_v12, %v121569_v1 (stack40)
        %v111328_v42 = vsel /*vm=*/%vm111315_vm8, /*on_true_vy=*/%v111324_v46, /*on_false_vx=*/%v153691_v42 (stack44)
        %v108932_v29 = vadd.f32 %v108928_v10, %v108877_v29 (stack53)
        %v110491_v53 = vor.u32 %v110490_v7, %v110489_v8 (stack47)
        %v110909_v34 = vxor.u32 %v110908_v27, %v110904_v61 (stack48)
        %v111351_v46 = vshll.u32 %v153729_v55, 13 (stack45)
        %v109702_v26 = vxor.u32 %v109701_v30, %v109697_v24 (stack48)
        %v110094_v8 = vadd.s32 3, %v110090_v20 (stack40)
        %v111332_v44 = vadd.s32 1, %v111328_v42 (stack40)
        %v153748_v40 = vadd.s32 %v157770_v40, %v157095_v13 (stack40)
        %v108936_v43 = vmul.f32 %v108932_v29, %v153714_v56 (stack54)
        %v110492_v12 = vxor.u32 %v110491_v53, %v110487_v22 (stack48)
        %v110912_v61 = vadd.s32 %v110909_v34, %v110904_v61 (stack40)
        %v111352_v10 = vshrl.u32 %v153729_v55, 19 (stack46)
        %v109705_v24 = vadd.s32 %v109702_v26, %v109697_v24 (stack40)
        %v109711_v7 = vshll.u32 %v109702_v26, 6 (stack45)
        %v109712_v27 = vshrl.u32 %v109702_v26, 26 (stack46)
        %v110098_v25 = vadd.s32 %v110094_v8, %v110082_v25 (stack40)
        %v108940_v23 = vadd.f32 %v108936_v43, %v153699_v23 (stack53)
        %v110100_v30 = vshll.u32 %v110094_v8, 17 (stack45)
        %v110101_v20 = vshrl.u32 %v110094_v8, 15 (stack46)
        %v110495_v22 = vadd.s32 %v110492_v12, %v110487_v22 (stack40)
        %v109713_v29 = vor.u32 %v109712_v27, %v109711_v7 (stack47)
        %v110501_v53 = vshll.u32 %v110492_v12, 24 (stack45)
        %v110502_v26 = vshrl.u32 %v110492_v12, 8 (stack46)
        %v110918_v8 = vshll.u32 %v110909_v34, 6 (stack45)
        %v108869_v43 = vsel /*vm=*/%vm108852_vm5, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v108944_v12 = vmul.f32 %v108940_v23, %v153714_v56 (stack54)
        %vm153757_vm10 = vcmp.lt.f32.partialorder %v109307_v52, 0.0004427343 (stack62)
        %v110102_v7 = vor.u32 %v110101_v20, %v110100_v30 (stack47)
        %v109714_v27 = vxor.u32 %v109713_v29, %v109705_v24 (stack48)
        %v110503_v23 = vor.u32 %v110502_v26, %v110501_v53 (stack47)
        %v110919_v34 = vshrl.u32 %v110909_v34, 26 (stack46)
        %v111336_v41 = vsel /*vm=*/%vm111310_vm9, /*on_true_vy=*/%v111332_v44, /*on_false_vx=*/%v111328_v42 (stack44)
        %v108948_v60 = vadd.f32 %v108944_v12, %v108869_v43 (stack53)
        %v109306_v6 = vmul.f32 %v109305_v32, %v153725_v6 (stack63)
        %v110103_v32 = vxor.u32 %v110102_v7, %v110098_v25 (stack48)
        %v111341_v42 = vadd.s32 %v111336_v41, %v121574_v2 (stack40)
        %v121366_v44 = vpop.eup %121365 (stack64)
        %v109717_v30 = vadd.s32 %v109714_v27, %v121574_v2 (stack40)
        %v110504_v20 = vxor.u32 %v110503_v23, %v110495_v22 (stack48)
        %v110920_v29 = vor.u32 %v110919_v34, %v110918_v8 (stack47)
        %v111353_v46 = vor.u32 %v111352_v10, %v111351_v46 (stack47)
        %v108952_v10 = vmul.f32 %v108948_v60, %v153714_v56 (stack54)
        %v109303_v53 = vmul.f32 0.6931472, %v121366_v44 (stack65)
        %v110106_v25 = vadd.s32 %v110103_v32, %v110098_v25 (stack40)
        %v110108_v26 = vshll.u32 %v110103_v32, 29 (stack45)
        %v109709_v24 = vadd.s32 %v109705_v24, %v121564_v0 (stack40)
        %v109721_v8 = vadd.s32 5, %v109717_v30 (stack40)
        %v110109_v43 = vshrl.u32 %v110103_v32, 3 (stack46)
        %v110921_v12 = vxor.u32 %v110920_v29, %v110912_v61 (stack48)
        %v108956_v54 = vadd.f32 %v108952_v10, %v153672_v54 (stack53)
        %v109309_v52 = vsel /*vm=*/%vm153757_vm10, /*on_true_vy=*/%v109306_v6, /*on_false_vx=*/%v109303_v53 (stack66)
        %v110507_v7 = vadd.s32 %v110504_v20, %v121574_v2 (stack40)
        %v111349_v55 = vadd.s32 %v153729_v55, %v111341_v42 (stack40)
        %v153774_v27 = vxor.u32 2147483648, %v109309_v52 (stack56)
        %v109723_v23 = vxor.u32 %v109721_v8, %v109709_v24 (stack48)
        %v110110_v34 = vor.u32 %v110109_v43, %v110108_v26 (stack47)
        %v108960_v41 = vmul.f32 %v108956_v54, %v153714_v56 (stack54)
        %v153777_v60 = vxor.u32 %v111353_v46, %v111349_v55 (stack48)
        %vm111776_vm11 = vcmp.lt.u32.totalorder %v153748_v40, %v157095_v13 (stack43)
        %v108833_v6 = vmul.f32 inf, %v153573_v31 (stack54)
        %v108861_v32 = vsel /*vm=*/%vm108852_vm5, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %121367 = vrsqrt.f32 %v153774_v27 (stack67)
        %vm153788_vm12 = vcmp.eq.f32.partialorder %v108825_v45, 1.0 (stack68)
        %v108857_v50 = vsel /*vm=*/%vm108852_vm5, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v108964_v42 = vadd.f32 %v108960_v41, %v108861_v32 (stack53)
        %v110511_v44 = vadd.s32 2, %v110507_v7 (stack40)
        %v109286_v30 = vand.u32 2147483647, %v153703_v9 (stack77)
        %v153797_v20 = vmul.f32 inf, %v153703_v9 (stack54)
        %v110111_v29 = vxor.u32 %v110110_v34, %v110106_v25 (stack48)
        %v110924_v46 = vadd.s32 %v110921_v12, %v121564_v0 (stack40)
        %v108968_v56 = vmul.f32 %v108964_v42, %v153714_v56 (stack54)
        %v110499_v22 = vadd.s32 %v110495_v22, %v121564_v0 (stack40)
        %v110916_v61 = vadd.s32 %v110912_v61, %v121569_v1 (stack40)
        %v153805_v10 = vadd.s32 %v153748_v40, %v122657_v58 (stack40)
        %v153808_v53 = vadd.f32 -2.5, %v153774_v27 (stack53)
        %v109361_v26 = vand.u32 2147483648, %v153774_v27 (stack72)
        %v109724_v24 = vand.u32.u8 255, %v109723_v23 (stack49)
        %v110114_v25 = vadd.s32 %v110111_v29, %v110106_v25 (stack40)
        %v108972_v8 = vadd.f32 %v108968_v56, %v108857_v50 (stack53)
        %v110116_v43 = vshll.u32 %v110111_v29, 16 (stack45)
        %v110117_v12 = vshrl.u32 %v110111_v29, 16 (stack46)
        %v110515_v54 = vadd.s32 %v110511_v44, %v110499_v22 (stack40)
        %v109725_v52 = vand.u32 65535, %v109724_v24 (stack50)
        %v110517_v7 = vshll.u32 %v110511_v44, 13 (stack45)
        %v110518_v23 = vshrl.u32 %v110511_v44, 19 (stack46)
        %v110928_v34 = vadd.s32 1, %v110924_v46 (stack40)
        %v108976_v31 = vmul.f32 %v108972_v8, %v153573_v31 (stack54)
        %vm109358_vm13 = vcmp.eq.f32.partialorder %v153774_v27, inf (stack70)
        %v110118_v41 = vor.u32 %v110117_v12, %v110116_v43 (stack47)
        %v111357_v55 = vadd.s32 %v153777_v60, %v111349_v55 (stack40)
        %v111359_v32 = vshll.u32 %v153777_v60, 15 (stack45)
        %vm109360_vm14 = vcmp.eq.f32.partialorder %v153774_v27, 0.0 (stack71)
        %v109726_v50 = vshrl.u32 %v109725_v52, 1 (stack51)
        %v110519_v42 = vor.u32 %v110518_v23, %v110517_v7 (stack47)
        %v110932_v44 = vadd.s32 %v110928_v34, %v110916_v61 (stack40)
        %v110934_v29 = vshll.u32 %v110928_v34, 17 (stack45)
        %v108980_v6 = vsel /*vm=*/%vm153788_vm12, /*on_true_vy=*/%v108833_v6, /*on_false_vx=*/%v108976_v31 (stack44)
        %vm109313_vm15 = vcmp.lt.f32.partialorder %v153774_v27, 5.0 (stack68)
        %v110119_v45 = vxor.u32 %v110118_v41, %v110114_v25 (stack48)
        %v110935_v46 = vshrl.u32 %v110928_v34, 15 (stack46)
        %v111360_v60 = vshrl.u32 %v153777_v60, 17 (stack46)
        %v108984_v56 = vmul.f32 1.4140625, %v108980_v6 (stack54)
        %v109727_v22 = vor.u32 16256, %v109726_v50 (stack47)
        %v110520_v61 = vxor.u32 %v110519_v42, %v110515_v54 (stack48)
        %v111781_v21 = vadd.s32 %v157773_v21, %v157100_v14 (stack40)
        %v110122_v24 = vadd.s32 %v110119_v45, %v110114_v25 (stack40)
        %v110128_v25 = vshll.u32 %v110119_v45, 24 (stack45)
        %v110129_v8 = vshrl.u32 %v110119_v45, 8 (stack46)
        %v110936_v43 = vor.u32 %v110935_v46, %v110934_v29 (stack47)
        %v108987_v12 = vpack.c.bf16 %v157387_v11, %v108984_v56 (stack81)
        %v109728_v52 = vand.u32.u16 65535, %v109727_v22 (stack52)
        %v110523_v54 = vadd.s32 %v110520_v61, %v110515_v54 (stack40)
        %v110525_v7 = vshll.u32 %v110520_v61, 15 (stack45)
        %v121368_v23 = vpop.eup %121367 (stack73)
        %v110126_v34 = vadd.s32 %v110122_v24, %v121569_v1 (stack40)
        %v110130_v31 = vor.u32 %v110129_v8, %v110128_v25 (stack47)
        %v110526_v41 = vshrl.u32 %v110520_v61, 17 (stack46)
        %v110937_v50 = vxor.u32 %v110936_v43, %v110932_v44 (stack48)
        %120329 = vst [vmem:[%s123356_s30 + $0x74] sm:$0xf] /*vst_source=*/%v108987_v12 (stack83)
        %v109357_v42 = vmul.f32 %v121368_v23, %v153774_v27 (stack74)
        %v120332_v29 = vadd.low.f32.bf16 -1.0, %v109728_v52 (stack53)
        %v111361_v32 = vor.u32 %v111360_v60, %v111359_v32 (stack47)
        %v111785_v6 = vadd.s32 1, %v111781_v21 (stack40)
        %v110131_v45 = vxor.u32 %v110130_v31, %v110122_v24 (stack48)
        %v110527_v46 = vor.u32 %v110526_v41, %v110525_v7 (stack47)
        %v110940_v44 = vadd.s32 %v110937_v50, %v110932_v44 (stack40)
        %v110942_v60 = vshll.u32 %v110937_v50, 29 (stack45)
        %v109359_v56 = vsel /*vm=*/%vm109358_vm13, /*on_true_vy=*/%v153774_v27, /*on_false_vx=*/%v109357_v42 (stack75)
        %v109737_v22 = vmul.f32 2.0, %v120332_v29 (stack54)
        %v110943_v61 = vshrl.u32 %v110937_v50, 3 (stack46)
        %v111362_v24 = vxor.u32 %v111361_v32, %v111357_v55 (stack48)
        %v109362_v26 = vsel /*vm=*/%vm109360_vm14, /*on_true_vy=*/%v109361_v26, /*on_false_vx=*/%v109359_v56 (stack76)
        %v110134_v25 = vadd.s32 %v110131_v45, %v121564_v0 (stack40)
        %v110528_v8 = vxor.u32 %v110527_v46, %v110523_v54 (stack48)
        %v111789_v21 = vsel /*vm=*/%vm111776_vm11, /*on_true_vy=*/%v111785_v6, /*on_false_vx=*/%v111781_v21 (stack44)
        %v109365_v43 = vadd.f32 -3.0, %v109362_v26 (stack53)
        %v109741_v12 = vadd.f32 -0.99609375, %v109737_v22 (stack53)
        %v110944_v52 = vor.u32 %v110943_v61, %v110942_v60 (stack47)
        %v153835_v55 = vadd.s32 %v111362_v24, %v111357_v55 (stack40)
        %v110138_v7 = vadd.s32 4, %v110134_v25 (stack40)
        %v110531_v54 = vadd.s32 %v110528_v8, %v110523_v54 (stack40)
        %v110533_v23 = vshll.u32 %v110528_v8, 26 (stack45)
        %v110534_v31 = vshrl.u32 %v110528_v8, 6 (stack46)
        %v109350_v41 = vsel /*vm=*/%vm109313_vm15, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v153843_v53 = vsel /*vm=*/%vm109313_vm15, /*on_true_vy=*/%v153808_v53, /*on_false_vx=*/%v109365_v43 (stack44)
        %v153845_v50 = vmax.f32 %v109741_v12, -0.99609375 (stack55)
        %v110945_v42 = vxor.u32 %v110944_v52, %v110940_v44 (stack48)
        %v109373_v29 = vmul.f32 %v153843_v53, %v109350_v41 (stack54)
        %v110142_v34 = vadd.s32 %v110138_v7, %v110126_v34 (stack40)
        %v110144_v32 = vshll.u32 %v110138_v7, 13 (stack45)
        %v110145_v6 = vshrl.u32 %v110138_v7, 19 (stack46)
        %v109346_v45 = vsel /*vm=*/%vm109313_vm15, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v109757_v46 = vxor.u32 2147483648, %v153845_v50 (stack56)
        %v110535_v60 = vor.u32 %v110534_v31, %v110533_v23 (stack47)
        %vm111771_vm0 = vcmp.lt.u32.totalorder %v153805_v10, %v153748_v40 (stack43)
        %v153857_v56 = vsel /*vm=*/%vm109313_vm15, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v109377_v22 = vadd.f32 %v109373_v29, %v109346_v45 (stack53)
        %v110146_v61 = vor.u32 %v110145_v6, %v110144_v32 (stack47)
        %v110948_v44 = vadd.s32 %v110945_v42, %v110940_v44 (stack40)
        %v109342_v26 = vsel /*vm=*/%vm109313_vm15, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v153863_v25 = vmul.f32 %v109757_v46, %v153845_v50 (stack54)
        %v110536_v8 = vxor.u32 %v110535_v60, %v110531_v54 (stack48)
        %v111367_v43 = vshll.u32 %v111362_v24, 26 (stack45)
        %v109381_v12 = vmul.f32 %v109377_v22, %v153843_v53 (stack54)
        %v110147_v52 = vxor.u32 %v110146_v61, %v110142_v34 (stack48)
        %v110950_v7 = vshll.u32 %v110945_v42, 16 (stack45)
        %v110951_v23 = vshrl.u32 %v110945_v42, 16 (stack46)
        %v109762_v31 = vadd.f32 1.0, %v153863_v25 (stack57)
        %v110539_v54 = vadd.s32 %v110536_v8, %v110531_v54 (stack40)
        %v111368_v24 = vshrl.u32 %v111362_v24, 6 (stack46)
        %v111793_v41 = vadd.s32 1, %v111789_v21 (stack40)
        %v109385_v42 = vadd.f32 %v109381_v12, %v109342_v26 (stack53)
        %v110150_v29 = vadd.s32 %v110147_v52, %v110142_v34 (stack40)
        %v110152_v34 = vshll.u32 %v110147_v52, 15 (stack45)
        %v110153_v32 = vshrl.u32 %v110147_v52, 17 (stack46)
        %v109330_v6 = vsel /*vm=*/%vm109313_vm15, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v109334_v45 = vsel /*vm=*/%vm109313_vm15, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v109338_v46 = vsel /*vm=*/%vm109313_vm15, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %121369 = vlog2.f32 %v109762_v31 (stack58)
        %v109389_v60 = vmul.f32 %v109385_v42, %v153843_v53 (stack54)
        %v110154_v22 = vor.u32 %v110153_v32, %v110152_v34 (stack47)
        %v110545_v61 = vshll.u32 %v110536_v8, 6 (stack45)
        %v110546_v26 = vshrl.u32 %v110536_v8, 26 (stack46)
        %v109765_v8 = vmul.f32 -0.5, %v153863_v25 (stack59)
        %v110952_v12 = vor.u32 %v110951_v23, %v110950_v7 (stack47)
        %v111369_v43 = vor.u32 %v111368_v24, %v111367_v43 (stack47)
        %v111797_v40 = vsel /*vm=*/%vm111771_vm0, /*on_true_vy=*/%v111793_v41, /*on_false_vx=*/%v111789_v21 (stack44)
        %v109393_v21 = vadd.f32 %v109389_v60, %v109338_v46 (stack53)
        %v110155_v52 = vxor.u32 %v110154_v22, %v110150_v29 (stack48)
        %v110547_v7 = vor.u32 %v110546_v26, %v110545_v61 (stack47)
        %v111802_v23 = vadd.s32 %v111797_v40, %v121574_v2 (stack40)
        %v110953_v31 = vxor.u32 %v110952_v12, %v110948_v44 (stack48)
        %v111370_v24 = vxor.u32 %v111369_v43, %v153835_v55 (stack48)
        %v153885_v10 = vadd.s32 %v153805_v10, %v121569_v1 (stack40)
        %v157796_v41 = vld [vmem:[#allocation153_spill] sm:$0xff] (stack84)
        %v153889_v42 = vadd.s32 %v157796_v41, %v122651_v47 (stack40)
        %v109397_v34 = vmul.f32 %v109393_v21, %v153843_v53 (stack54)
        %v110158_v29 = vadd.s32 %v110155_v52, %v110150_v29 (stack40)
        %v110160_v32 = vshll.u32 %v110155_v52, 26 (stack45)
        %v110161_v46 = vshrl.u32 %v110155_v52, 6 (stack46)
        %v110548_v60 = vxor.u32 %v110547_v7, %v110539_v54 (stack48)
        %v110956_v44 = vadd.s32 %v110953_v31, %v110948_v44 (stack40)
        %v110962_v22 = vshll.u32 %v110953_v31, 24 (stack45)
        %v110963_v61 = vshrl.u32 %v110953_v31, 8 (stack46)
        %v109401_v45 = vadd.f32 %v109397_v34, %v109334_v45 (stack53)
        %v110162_v26 = vor.u32 %v110161_v46, %v110160_v32 (stack47)
        %v111373_v55 = vadd.s32 %v111370_v24, %v153835_v55 (stack40)
        %v111379_v12 = vshll.u32 %v111370_v24, 6 (stack45)
        %v109768_v43 = vand.u32 2147483647, %v153863_v25 (stack60)
        %v110551_v40 = vadd.s32 %v110548_v60, %v121569_v1 (stack40)
        %v110964_v21 = vor.u32 %v110963_v61, %v110962_v22 (stack47)
        %v111380_v52 = vshrl.u32 %v111370_v24, 26 (stack46)
        %v109405_v7 = vmul.f32 %v109401_v45, %v153843_v53 (stack54)
        %v109766_v8 = vadd.f32 1.0, %v109765_v8 (stack61)
        %v110163_v31 = vxor.u32 %v110162_v26, %v110158_v29 (stack48)
        %v153897_v23 = vadd.s32 %v153885_v10, %v111802_v23 (stack40)
        %v110543_v54 = vadd.s32 %v110539_v54, %v121574_v2 (stack40)
        %v110555_v24 = vadd.s32 3, %v110551_v40 (stack40)
        %v110965_v34 = vxor.u32 %v110964_v21, %v110956_v44 (stack48)
        %v111381_v32 = vor.u32 %v111380_v52, %v111379_v12 (stack47)
        %v109409_v6 = vadd.f32 %v109405_v7, %v109330_v6 (stack53)
        %v110166_v29 = vadd.s32 %v110163_v31, %v110158_v29 (stack40)
        %v110172_v46 = vshll.u32 %v110163_v31, 6 (stack45)
        %v110173_v60 = vshrl.u32 %v110163_v31, 26 (stack46)
        %v110559_v22 = vadd.s32 %v110555_v24, %v110543_v54 (stack40)
        %v110561_v61 = vshll.u32 %v110555_v24, 17 (stack45)
        %v110562_v45 = vshrl.u32 %v110555_v24, 15 (stack46)
        %v110968_v26 = vadd.s32 %v110965_v34, %v121574_v2 (stack40)
        %v121370_v12 = vpop.eup %121369 (stack64)
        %v109413_v40 = vmul.f32 %v109409_v6, %v153843_v53 (stack54)
        %v109767_v25 = vmul.f32 %v109766_v8, %v153863_v25 (stack63)
        %v110174_v21 = vor.u32 %v110173_v60, %v110172_v46 (stack47)
        %v111382_v52 = vxor.u32 %v111381_v32, %v111373_v55 (stack48)
        %v109764_v7 = vmul.f32 0.6931472, %v121370_v12 (stack65)
        %v110563_v8 = vor.u32 %v110562_v45, %v110561_v61 (stack47)
        %v110960_v44 = vadd.s32 %v110956_v44, %v121564_v0 (stack40)
        %v110972_v31 = vadd.s32 2, %v110968_v26 (stack40)
        %v109318_v54 = vsel /*vm=*/%vm109313_vm15, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v109417_v56 = vadd.f32 %v109413_v40, %v153857_v56 (stack53)
        %vm109769_vm1 = vcmp.lt.f32.partialorder %v109768_v43, 0.0004427343 (stack62)
        %v110175_v43 = vxor.u32 %v110174_v21, %v110166_v29 (stack48)
        %v109322_v27 = vsel /*vm=*/%vm109313_vm15, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v109770_v24 = vsel /*vm=*/%vm109769_vm1, /*on_true_vy=*/%v109767_v25, /*on_false_vx=*/%v109764_v7 (stack66)
        %v110564_v34 = vxor.u32 %v110563_v8, %v110559_v22 (stack48)
        %v110976_v32 = vadd.s32 %v110972_v31, %v110960_v44 (stack40)
        %v109421_v6 = vmul.f32 %v109417_v56, %v153843_v53 (stack54)
        %v109747_v46 = vand.u32 2147483647, %v153845_v50 (stack77)
        %v153913_v60 = vxor.u32 2147483648, %v109770_v24 (stack56)
        %v111385_v61 = vadd.s32 %v111382_v52, %v121564_v0 (stack40)
        %vm153918_vm2 = vcmp.eq.f32.partialorder %v109286_v30, 1.0 (stack68)
        %v110567_v22 = vadd.s32 %v110564_v34, %v110559_v22 (stack40)
        %v110569_v45 = vshll.u32 %v110564_v34, 29 (stack45)
        %v110570_v26 = vshrl.u32 %v110564_v34, 3 (stack46)
        %v111377_v55 = vadd.s32 %v111373_v55, %v121569_v1 (stack40)
        %v109425_v12 = vadd.f32 %v109421_v6, %v109322_v27 (stack53)
        %vm109774_vm3 = vcmp.lt.f32.partialorder %v153913_v60, 5.0 (stack68)
        %121371 = vrsqrt.f32 %v153913_v60 (stack67)
        %v111812_v40 = vshll.u32 %v153885_v10, 13 (stack45)
        %v110170_v29 = vadd.s32 %v110166_v29, %v121564_v0 (stack40)
        %v110178_v25 = vadd.s32 %v110175_v43, %v121574_v2 (stack40)
        %v110571_v21 = vor.u32 %v110570_v26, %v110569_v45 (stack47)
        %v111813_v10 = vshrl.u32 %v153885_v10, 19 (stack46)
        %v109429_v53 = vmul.f32 %v109425_v12, %v153843_v53 (stack54)
        %v110978_v52 = vshll.u32 %v110972_v31, 13 (stack45)
        %v110979_v7 = vshrl.u32 %v110972_v31, 19 (stack46)
        %v111389_v8 = vadd.s32 1, %v111385_v61 (stack40)
        %v153933_v44 = vsel /*vm=*/%vm109774_vm3, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v153936_v31 = vadd.f32 -2.5, %v153913_v60 (stack53)
        %v110572_v56 = vxor.u32 %v110571_v21, %v110567_v22 (stack48)
        %v153940_v43 = vadd.s32 %v153889_v42, %v122657_v58 (stack40)
        %v109433_v54 = vadd.f32 %v109429_v53, %v109318_v54 (stack53)
        %v153945_v27 = vsel /*vm=*/%vm109774_vm3, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v153950_v24 = vsel /*vm=*/%vm109774_vm3, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v153955_v34 = vsel /*vm=*/%vm109774_vm3, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v110182_v6 = vadd.s32 5, %v110178_v25 (stack40)
        %v110575_v61 = vadd.s32 %v110572_v56, %v110567_v22 (stack40)
        %v110577_v22 = vshll.u32 %v110572_v56, 16 (stack45)
        %v110578_v45 = vshrl.u32 %v110572_v56, 16 (stack46)
        %v109437_v9 = vmul.f32 %v109433_v54, %v153703_v9 (stack54)
        %v110980_v26 = vor.u32 %v110979_v7, %v110978_v52 (stack47)
        %v111393_v55 = vadd.s32 %v111389_v8, %v111377_v55 (stack40)
        %v111395_v12 = vshll.u32 %v111389_v8, 17 (stack45)
        %vm109819_vm4 = vcmp.eq.f32.partialorder %v153913_v60, inf (stack70)
        %v110184_v29 = vxor.u32 %v110182_v6, %v110170_v29 (stack48)
        %v110579_v25 = vor.u32 %v110578_v45, %v110577_v22 (stack47)
        %v111396_v21 = vshrl.u32 %v111389_v8, 15 (stack46)
        %v111814_v40 = vor.u32 %v111813_v10, %v111812_v40 (stack47)
        %v109441_v20 = vsel /*vm=*/%vm153918_vm2, /*on_true_vy=*/%v153797_v20, /*on_false_vx=*/%v109437_v9 (stack44)
        %vm109821_vm5 = vcmp.eq.f32.partialorder %v153913_v60, 0.0 (stack71)
        %v110981_v30 = vxor.u32 %v110980_v26, %v110976_v32 (stack48)
        %vm112271_vm6 = vcmp.lt.u32.totalorder %v153889_v42, %v122651_v47 (stack43)
        %v109445_v10 = vmul.f32 1.4140625, %v109441_v20 (stack54)
        %v110185_v53 = vand.u32.u8 255, %v110184_v29 (stack49)
        %v110580_v52 = vxor.u32 %v110579_v25, %v110575_v61 (stack48)
        %v111397_v7 = vor.u32 %v111396_v21, %v111395_v12 (stack47)
        %v110984_v32 = vadd.s32 %v110981_v30, %v110976_v32 (stack40)
        %v110986_v8 = vshll.u32 %v110981_v30, 15 (stack45)
        %v110987_v56 = vshrl.u32 %v110981_v30, 17 (stack46)
        %v111815_v54 = vxor.u32 %v111814_v40, %v153897_v23 (stack48)
        %v109448_v6 = vpack.c.bf16 %v157387_v11, %v109445_v10 (stack81)
        %v110186_v22 = vand.u32 65535, %v110185_v53 (stack50)
        %v110583_v61 = vadd.s32 %v110580_v52, %v110575_v61 (stack40)
        %v110589_v45 = vshll.u32 %v110580_v52, 24 (stack45)
        %v110590_v9 = vshrl.u32 %v110580_v52, 8 (stack46)
        %v110988_v26 = vor.u32 %v110987_v56, %v110986_v8 (stack47)
        %v111398_v12 = vxor.u32 %v111397_v7, %v111393_v55 (stack48)
        %v111818_v23 = vadd.s32 %v111815_v54, %v153897_v23 (stack40)
        %v121372_v29 = vpop.eup %121371 (stack73)
        %120331 = vst [vmem:[%s123356_s30 + $0xf4] sm:$0xf] /*vst_source=*/%v109448_v6 (stack83)
        %v109822_v25 = vand.u32 2147483648, %v153913_v60 (stack72)
        %v110187_v21 = vshrl.u32 %v110186_v22, 1 (stack51)
        %v111820_v40 = vshll.u32 %v111815_v54, 15 (stack45)
        %v111821_v20 = vshrl.u32 %v111815_v54, 17 (stack46)
        %v109818_v30 = vmul.f32 %v121372_v29, %v153913_v60 (stack74)
        %v110591_v10 = vor.u32 %v110590_v9, %v110589_v45 (stack47)
        %v110989_v53 = vxor.u32 %v110988_v26, %v110984_v32 (stack48)
        %v111401_v55 = vadd.s32 %v111398_v12, %v111393_v55 (stack40)
        %v110188_v52 = vor.u32 16256, %v110187_v21 (stack47)
        %v111403_v7 = vshll.u32 %v111398_v12, 29 (stack45)
        %v111404_v8 = vshrl.u32 %v111398_v12, 3 (stack46)
        %v111822_v56 = vor.u32 %v111821_v20, %v111820_v40 (stack47)
        %v109820_v54 = vsel /*vm=*/%vm109819_vm4, /*on_true_vy=*/%v153913_v60, /*on_false_vx=*/%v109818_v30 (stack75)
        %v110592_v6 = vxor.u32 %v110591_v10, %v110583_v61 (stack48)
        %v110992_v32 = vadd.s32 %v110989_v53, %v110984_v32 (stack40)
        %v110994_v22 = vshll.u32 %v110989_v53, 26 (stack45)
        %v109823_v45 = vsel /*vm=*/%vm109821_vm5, /*on_true_vy=*/%v109822_v25, /*on_false_vx=*/%v109820_v54 (stack76)
        %v110189_v9 = vand.u32.u16 65535, %v110188_v52 (stack52)
        %v110995_v26 = vshrl.u32 %v110989_v53, 6 (stack46)
        %v111405_v12 = vor.u32 %v111404_v8, %v111403_v7 (stack47)
        %v109826_v29 = vadd.f32 -3.0, %v109823_v45 (stack53)
        %v110595_v25 = vadd.s32 %v110592_v6, %v121564_v0 (stack40)
        %v111823_v21 = vxor.u32 %v111822_v56, %v111818_v23 (stack48)
        %v157799_v40 = vld [vmem:[#allocation116_spill] sm:$0xff] (stack84)
        %v112276_v20 = vadd.s32 %v157799_v40, %v157068_v28 (stack40)
        %v120334_v30 = vadd.low.f32.bf16 -1.0, %v110189_v9 (stack53)
        %v110587_v61 = vadd.s32 %v110583_v61, %v121569_v1 (stack40)
        %v110996_v10 = vor.u32 %v110995_v26, %v110994_v22 (stack47)
        %v111406_v53 = vxor.u32 %v111405_v12, %v111401_v55 (stack48)
        %v153983_v31 = vsel /*vm=*/%vm109774_vm3, /*on_true_vy=*/%v153936_v31, /*on_false_vx=*/%v109826_v29 (stack44)
        %v110599_v52 = vadd.s32 4, %v110595_v25 (stack40)
        %v153985_v23 = vadd.s32 %v111823_v21, %v111818_v23 (stack40)
        %v111828_v7 = vshll.u32 %v111823_v21, 26 (stack45)
        %v109834_v34 = vmul.f32 %v153983_v31, %v153955_v34 (stack54)
        %v110198_v8 = vmul.f32 2.0, %v120334_v30 (stack54)
        %v110997_v56 = vxor.u32 %v110996_v10, %v110992_v32 (stack48)
        %v111409_v55 = vadd.s32 %v111406_v53, %v111401_v55 (stack40)
        %v110603_v54 = vadd.s32 %v110599_v52, %v110587_v61 (stack40)
        %v110605_v6 = vshll.u32 %v110599_v52, 13 (stack45)
        %v110606_v22 = vshrl.u32 %v110599_v52, 19 (stack46)
        %v111411_v45 = vshll.u32 %v111406_v53, 16 (stack45)
        %v109838_v24 = vadd.f32 %v109834_v34, %v153950_v24 (stack53)
        %v110202_v9 = vadd.f32 -0.99609375, %v110198_v8 (stack53)
        %v111000_v32 = vadd.s32 %v110997_v56, %v110992_v32 (stack40)
        %v111006_v26 = vshll.u32 %v110997_v56, 6 (stack45)
        %v110607_v12 = vor.u32 %v110606_v22, %v110605_v6 (stack47)
        %v111007_v29 = vshrl.u32 %v110997_v56, 26 (stack46)
        %v111412_v25 = vshrl.u32 %v111406_v53, 16 (stack46)
        %v111829_v21 = vshrl.u32 %v111823_v21, 6 (stack46)
        %v153993_v30 = vsel /*vm=*/%vm109774_vm3, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v109803_v61 = vsel /*vm=*/%vm109774_vm3, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v109842_v10 = vmul.f32 %v109838_v24, %v153983_v31 (stack54)
        %v153999_v53 = vmax.f32 %v110202_v9, -0.99609375 (stack55)
        %v110608_v52 = vxor.u32 %v110607_v12, %v110603_v54 (stack48)
        %v111008_v34 = vor.u32 %v111007_v29, %v111006_v26 (stack47)
        %v111413_v8 = vor.u32 %v111412_v25, %v111411_v45 (stack47)
        %v111830_v7 = vor.u32 %v111829_v21, %v111828_v7 (stack47)
        %v109791_v56 = vsel /*vm=*/%vm109774_vm3, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v109846_v6 = vadd.f32 %v109842_v10, %v109803_v61 (stack53)
        %v110218_v22 = vxor.u32 2147483648, %v153999_v53 (stack56)
        %v112280_v45 = vadd.s32 1, %v112276_v20 (stack40)
        %v110611_v54 = vadd.s32 %v110608_v52, %v110603_v54 (stack40)
        %v110613_v24 = vshll.u32 %v110608_v52, 15 (stack45)
        %v110614_v9 = vshrl.u32 %v110608_v52, 17 (stack46)
        %v111009_v26 = vxor.u32 %v111008_v34, %v111000_v32 (stack48)
        %v109799_v12 = vsel /*vm=*/%vm109774_vm3, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v109850_v29 = vmul.f32 %v109846_v6, %v153983_v31 (stack54)
        %v110221_v25 = vmul.f32 %v110218_v22, %v153999_v53 (stack54)
        %v111414_v21 = vxor.u32 %v111413_v8, %v111409_v55 (stack48)
        %v110615_v61 = vor.u32 %v110614_v9, %v110613_v24 (stack47)
        %v111012_v10 = vadd.s32 %v111009_v26, %v121569_v1 (stack40)
        %v111831_v52 = vxor.u32 %v111830_v7, %v153985_v23 (stack48)
        %v112284_v20 = vsel /*vm=*/%vm112271_vm6, /*on_true_vy=*/%v112280_v45, /*on_false_vx=*/%v112276_v20 (stack44)
        %v109795_v60 = vsel /*vm=*/%vm109774_vm3, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v109854_v34 = vadd.f32 %v109850_v29, %v109799_v12 (stack53)
        %v110223_v8 = vadd.f32 1.0, %v110221_v25 (stack57)
        %v110226_v7 = vmul.f32 -0.5, %v110221_v25 (stack59)
        %v110616_v6 = vxor.u32 %v110615_v61, %v110611_v54 (stack48)
        %v111004_v32 = vadd.s32 %v111000_v32, %v121574_v2 (stack40)
        %v111016_v22 = vadd.s32 3, %v111012_v10 (stack40)
        %v111417_v55 = vadd.s32 %v111414_v21, %v111409_v55 (stack40)
        %vm112266_vm7 = vcmp.lt.u32.totalorder %v153940_v43, %v153889_v42 (stack43)
        %v109858_v45 = vmul.f32 %v109854_v34, %v153983_v31 (stack54)
        %121373 = vlog2.f32 %v110223_v8 (stack58)
        %v110227_v24 = vadd.f32 1.0, %v110226_v7 (stack61)
        %v111423_v9 = vshll.u32 %v111414_v21, 24 (stack45)
        %v110619_v54 = vadd.s32 %v110616_v6, %v110611_v54 (stack40)
        %v110621_v26 = vshll.u32 %v110616_v6, 26 (stack45)
        %v110622_v12 = vshrl.u32 %v110616_v6, 6 (stack46)
        %v111020_v29 = vadd.s32 %v111016_v22, %v111004_v32 (stack40)
        %v109862_v61 = vadd.f32 %v109858_v45, %v109795_v60 (stack53)
        %v111022_v10 = vshll.u32 %v111016_v22, 17 (stack45)
        %v111023_v60 = vshrl.u32 %v111016_v22, 15 (stack46)
        %v154024_v34 = vadd.s32 %v153940_v43, %v121569_v1 (stack40)
        %v110229_v8 = vand.u32 2147483647, %v110221_v25 (stack60)
        %v110623_v7 = vor.u32 %v110622_v12, %v110621_v26 (stack47)
        %v111424_v21 = vshrl.u32 %v111414_v21, 8 (stack46)
        %v111834_v23 = vadd.s32 %v111831_v52, %v153985_v23 (stack40)
        %v109866_v6 = vmul.f32 %v109862_v61, %v153983_v31 (stack54)
        %v111024_v32 = vor.u32 %v111023_v60, %v111022_v10 (stack47)
        %v111840_v22 = vshll.u32 %v111831_v52, 6 (stack45)
        %v111841_v52 = vshrl.u32 %v111831_v52, 26 (stack46)
        %v110228_v25 = vmul.f32 %v110227_v24, %v110221_v25 (stack63)
        %v110624_v45 = vxor.u32 %v110623_v7, %v110619_v54 (stack48)
        %v111421_v24 = vadd.s32 %v111417_v55, %v121564_v0 (stack40)
        %v111425_v9 = vor.u32 %v111424_v21, %v111423_v9 (stack47)
        %v109870_v56 = vadd.f32 %v109866_v6, %v109791_v56 (stack53)
        %v111025_v26 = vxor.u32 %v111024_v32, %v111020_v29 (stack48)
        %v111842_v12 = vor.u32 %v111841_v52, %v111840_v22 (stack47)
        %v112288_v61 = vadd.s32 1, %v112284_v20 (stack40)
        %vm154029_vm8 = vcmp.lt.f32.partialorder %v110229_v8, 0.0004427343 (stack62)
        %v110627_v54 = vadd.s32 %v110624_v45, %v110619_v54 (stack40)
        %v110633_v60 = vshll.u32 %v110624_v45, 6 (stack45)
        %v110634_v8 = vshrl.u32 %v110624_v45, 26 (stack46)
        %v111426_v55 = vxor.u32 %v111425_v9, %v111417_v55 (stack48)
        %v109874_v7 = vmul.f32 %v109870_v56, %v153983_v31 (stack54)
        %v111028_v29 = vadd.s32 %v111025_v26, %v111020_v29 (stack40)
        %v111030_v21 = vshll.u32 %v111025_v26, 29 (stack45)
        %v111031_v6 = vshrl.u32 %v111025_v26, 3 (stack46)
        %v110635_v32 = vor.u32 %v110634_v8, %v110633_v60 (stack47)
        %v111429_v22 = vadd.s32 %v111426_v55, %v121574_v2 (stack40)
        %v111838_v52 = vadd.s32 %v111834_v23, %v121569_v1 (stack40)
        %v111843_v23 = vxor.u32 %v111842_v12, %v111834_v23 (stack48)
        %v109878_v30 = vadd.f32 %v109874_v7, %v153993_v30 (stack53)
        %v111032_v45 = vor.u32 %v111031_v6, %v111030_v21 (stack47)
        %v112292_v42 = vsel /*vm=*/%vm112266_vm7, /*on_true_vy=*/%v112288_v61, /*on_false_vx=*/%v112284_v20 (stack44)
        %v112307_v43 = vshll.u32 %v154024_v34, 13 (stack45)
        %v110631_v20 = vadd.s32 %v110627_v54, %v121564_v0 (stack40)
        %v110636_v9 = vxor.u32 %v110635_v32, %v110627_v54 (stack48)
        %v111433_v56 = vadd.s32 2, %v111429_v22 (stack40)
        %v111846_v26 = vadd.s32 %v111843_v23, %v121564_v0 (stack40)
        %v109882_v12 = vmul.f32 %v109878_v30, %v153983_v31 (stack54)
        %v111033_v61 = vxor.u32 %v111032_v45, %v111028_v29 (stack48)
        %v112297_v54 = vadd.s32 %v112292_v42, %v121574_v2 (stack40)
        %v154047_v60 = vadd.s32 %v157796_v41, %v157070_v38 (stack40)
        %v121374_v8 = vpop.eup %121373 (stack64)
        %v110639_v55 = vadd.s32 %v110636_v9, %v121574_v2 (stack40)
        %v111437_v24 = vadd.s32 %v111433_v56, %v111421_v24 (stack40)
        %v111439_v7 = vshll.u32 %v111433_v56, 13 (stack45)
        %v111440_v21 = vshrl.u32 %v111433_v56, 19 (stack46)
        %v109886_v27 = vadd.f32 %v109882_v12, %v153945_v27 (stack53)
        %v110225_v6 = vmul.f32 0.6931472, %v121374_v8 (stack65)
        %v111036_v29 = vadd.s32 %v111033_v61, %v111028_v29 (stack40)
        %v111038_v32 = vshll.u32 %v111033_v61, 16 (stack45)
        %v110643_v22 = vadd.s32 5, %v110639_v55 (stack40)
        %v111039_v23 = vshrl.u32 %v111033_v61, 16 (stack46)
        %v111441_v30 = vor.u32 %v111440_v21, %v111439_v7 (stack47)
        %v111850_v45 = vadd.s32 1, %v111846_v26 (stack40)
        %v109890_v31 = vmul.f32 %v109886_v27, %v153983_v31 (stack54)
        %v110231_v25 = vsel /*vm=*/%vm154029_vm8, /*on_true_vy=*/%v110228_v25, /*on_false_vx=*/%v110225_v6 (stack66)
        %v112305_v10 = vadd.s32 %v154024_v34, %v112297_v54 (stack40)
        %v112308_v34 = vshrl.u32 %v154024_v34, 19 (stack46)
        %v154056_v42 = vxor.u32 2147483648, %v110231_v25 (stack56)
        %v110645_v20 = vxor.u32 %v110643_v22, %v110631_v20 (stack48)
        %v111040_v9 = vor.u32 %v111039_v23, %v111038_v32 (stack47)
        %v111442_v56 = vxor.u32 %v111441_v30, %v111437_v24 (stack48)
        %v109894_v44 = vadd.f32 %v109890_v31, %v153933_v44 (stack53)
        %v111854_v52 = vadd.s32 %v111850_v45, %v111838_v52 (stack40)
        %vm110235_vm9 = vcmp.lt.f32.partialorder %v154056_v42, 5.0 (stack68)
        %121375 = vrsqrt.f32 %v154056_v42 (stack67)
        %vm109750_vm10 = vcmp.eq.f32.partialorder %v109747_v46, 1.0 (stack68)
        %v109755_v46 = vmul.f32 inf, %v153845_v50 (stack54)
        %v109898_v50 = vmul.f32 %v109894_v44, %v153845_v50 (stack54)
        %v112309_v43 = vor.u32 %v112308_v34, %v112307_v43 (stack47)
        %v111041_v26 = vxor.u32 %v111040_v9, %v111036_v29 (stack48)
        %v111856_v12 = vshll.u32 %v111850_v45, 17 (stack45)
        %v111857_v61 = vshrl.u32 %v111850_v45, 15 (stack46)
        %v154067_v54 = vadd.s32 %v154047_v60, %v122657_v58 (stack40)
        %v109902_v8 = vsel /*vm=*/%vm109750_vm10, /*on_true_vy=*/%v109755_v46, /*on_false_vx=*/%v109898_v50 (stack44)
        %v154072_v55 = vsel /*vm=*/%vm110235_vm9, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v154077_v7 = vsel /*vm=*/%vm110235_vm9, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v154080_v21 = vadd.f32 -2.5, %v154056_v42 (stack53)
        %v109906_v27 = vmul.f32 1.4140625, %v109902_v8 (stack54)
        %v154085_v6 = vsel /*vm=*/%vm110235_vm9, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v154090_v32 = vsel /*vm=*/%vm110235_vm9, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v110646_v22 = vand.u32.u8 255, %v110645_v20 (stack49)
        %v111044_v29 = vadd.s32 %v111041_v26, %v111036_v29 (stack40)
        %v111050_v23 = vshll.u32 %v111041_v26, 24 (stack45)
        %v111051_v30 = vshrl.u32 %v111041_v26, 8 (stack46)
        %v111445_v24 = vadd.s32 %v111442_v56, %v111437_v24 (stack40)
        %v109909_v45 = vpack.c.bf16 %v157387_v11, %v109906_v27 (stack81)
        %v110647_v31 = vand.u32 65535, %v110646_v22 (stack50)
        %v111447_v25 = vshll.u32 %v111442_v56, 15 (stack45)
        %v111448_v34 = vshrl.u32 %v111442_v56, 17 (stack46)
        %v154096_v20 = vsel /*vm=*/%vm110235_vm9, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %vm110280_vm11 = vcmp.eq.f32.partialorder %v154056_v42, inf (stack70)
        %v111052_v9 = vor.u32 %v111051_v30, %v111050_v23 (stack47)
        %v111858_v56 = vor.u32 %v111857_v61, %v111856_v12 (stack47)
        %v112310_v44 = vxor.u32 %v112309_v43, %v112305_v10 (stack48)
        %120333 = vst [vmem:[%s123356_s30 + $0x174] sm:$0xf] /*vst_source=*/%v109909_v45 (stack83)
        %vm110282_vm12 = vcmp.eq.f32.partialorder %v154056_v42, 0.0 (stack71)
        %v110648_v46 = vshrl.u32 %v110647_v31, 1 (stack51)
        %v111449_v50 = vor.u32 %v111448_v34, %v111447_v25 (stack47)
        %vm112732_vm13 = vcmp.lt.u32.totalorder %v154047_v60, %v157070_v38 (stack43)
        %v111053_v43 = vxor.u32 %v111052_v9, %v111044_v29 (stack48)
        %v111859_v26 = vxor.u32 %v111858_v56, %v111854_v52 (stack48)
        %v112313_v10 = vadd.s32 %v112310_v44, %v112305_v10 (stack40)
        %v112315_v12 = vshll.u32 %v112310_v44, 15 (stack45)
        %v110649_v61 = vor.u32 16256, %v110648_v46 (stack47)
        %v111450_v8 = vxor.u32 %v111449_v50, %v111445_v24 (stack48)
        %v112316_v27 = vshrl.u32 %v112310_v44, 17 (stack46)
        %v112737_v22 = vadd.s32 %v157799_v40, %v157076_v35 (stack40)
        %v111056_v23 = vadd.s32 %v111053_v43, %v121564_v0 (stack40)
        %v111862_v52 = vadd.s32 %v111859_v26, %v111854_v52 (stack40)
        %v111864_v30 = vshll.u32 %v111859_v26, 29 (stack45)
        %v111865_v45 = vshrl.u32 %v111859_v26, 3 (stack46)
        %v110650_v31 = vand.u32.u16 65535, %v110649_v61 (stack52)
        %v111453_v24 = vadd.s32 %v111450_v8, %v111445_v24 (stack40)
        %v111455_v25 = vshll.u32 %v111450_v8, 26 (stack45)
        %v111456_v34 = vshrl.u32 %v111450_v8, 6 (stack46)
        %v121376_v9 = vpop.eup %121375 (stack73)
        %v111048_v29 = vadd.s32 %v111044_v29, %v121569_v1 (stack40)
        %v111060_v56 = vadd.s32 4, %v111056_v23 (stack40)
        %v111866_v44 = vor.u32 %v111865_v45, %v111864_v30 (stack47)
        %v112317_v46 = vor.u32 %v112316_v27, %v112315_v12 (stack47)
        %v110279_v50 = vmul.f32 %v121376_v9, %v154056_v42 (stack74)
        %v110283_v43 = vand.u32 2147483648, %v154056_v42 (stack72)
        %v120336_v26 = vadd.low.f32.bf16 -1.0, %v110650_v31 (stack53)
        %v111457_v12 = vor.u32 %v111456_v34, %v111455_v25 (stack47)
        %v111064_v61 = vadd.s32 %v111060_v56, %v111048_v29 (stack40)
        %v111066_v8 = vshll.u32 %v111060_v56, 13 (stack45)
        %v111067_v27 = vshrl.u32 %v111060_v56, 19 (stack46)
        %v111867_v23 = vxor.u32 %v111866_v44, %v111862_v52 (stack48)
        %v110281_v30 = vsel /*vm=*/%vm110280_vm11, /*on_true_vy=*/%v154056_v42, /*on_false_vx=*/%v110279_v50 (stack75)
        %v110659_v45 = vmul.f32 2.0, %v120336_v26 (stack54)
        %v111458_v31 = vxor.u32 %v111457_v12, %v111453_v24 (stack48)
        %v112318_v25 = vxor.u32 %v112317_v46, %v112313_v10 (stack48)
        %v110284_v34 = vsel /*vm=*/%vm110282_vm12, /*on_true_vy=*/%v110283_v43, /*on_false_vx=*/%v110281_v30 (stack76)
        %v111068_v9 = vor.u32 %v111067_v27, %v111066_v8 (stack47)
        %v111870_v52 = vadd.s32 %v111867_v23, %v111862_v52 (stack40)
        %v111872_v29 = vshll.u32 %v111867_v23, 16 (stack45)
        %v110287_v56 = vadd.f32 -3.0, %v110284_v34 (stack53)
        %v110663_v44 = vadd.f32 -0.99609375, %v110659_v45 (stack53)
        %v111461_v24 = vadd.s32 %v111458_v31, %v111453_v24 (stack40)
        %v111467_v46 = vshll.u32 %v111458_v31, 6 (stack45)
        %v111069_v50 = vxor.u32 %v111068_v9, %v111064_v61 (stack48)
        %v111468_v43 = vshrl.u32 %v111458_v31, 26 (stack46)
        %v111873_v26 = vshrl.u32 %v111867_v23, 16 (stack46)
        %v112321_v10 = vadd.s32 %v112318_v25, %v112313_v10 (stack40)
        %v110268_v12 = vsel /*vm=*/%vm110235_vm9, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v110272_v8 = vsel /*vm=*/%vm110235_vm9, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v154123_v21 = vsel /*vm=*/%vm110235_vm9, /*on_true_vy=*/%v154080_v21, /*on_false_vx=*/%v110287_v56 (stack44)
        %v154125_v27 = vmax.f32 %v110663_v44, -0.99609375 (stack55)
        %v110295_v23 = vmul.f32 %v154123_v21, %v110272_v8 (stack54)
        %v111072_v61 = vadd.s32 %v111069_v50, %v111064_v61 (stack40)
        %v111074_v30 = vshll.u32 %v111069_v50, 15 (stack45)
        %v111075_v45 = vshrl.u32 %v111069_v50, 17 (stack46)
        %v110679_v31 = vxor.u32 2147483648, %v154125_v27 (stack56)
        %v111469_v34 = vor.u32 %v111468_v43, %v111467_v46 (stack47)
        %v112323_v9 = vshll.u32 %v112318_v25, 26 (stack45)
        %v112741_v56 = vadd.s32 1, %v112737_v22 (stack40)
        %v110299_v44 = vadd.f32 %v110295_v23, %v110268_v12 (stack53)
        %v111076_v46 = vor.u32 %v111075_v45, %v111074_v30 (stack47)
        %v111874_v29 = vor.u32 %v111873_v26, %v111872_v29 (stack47)
        %v112324_v25 = vshrl.u32 %v112318_v25, 6 (stack46)
        %v110682_v50 = vmul.f32 %v110679_v31, %v154125_v27 (stack54)
        %v111470_v43 = vxor.u32 %v111469_v34, %v111461_v24 (stack48)
        %v112745_v22 = vsel /*vm=*/%vm112732_vm13, /*on_true_vy=*/%v112741_v56, /*on_false_vx=*/%v112737_v22 (stack44)
        %v154135_v26 = vadd.s32 %v154067_v54, %v121569_v1 (stack40)
        %v110303_v12 = vmul.f32 %v110299_v44, %v154123_v21 (stack54)
        %v111077_v8 = vxor.u32 %v111076_v46, %v111072_v61 (stack48)
        %v111465_v24 = vadd.s32 %v111461_v24, %v121574_v2 (stack40)
        %v111875_v23 = vxor.u32 %v111874_v29, %v111870_v52 (stack48)
        %v110684_v30 = vadd.f32 1.0, %v110682_v50 (stack57)
        %v110687_v45 = vmul.f32 -0.5, %v110682_v50 (stack59)
        %v111473_v31 = vadd.s32 %v111470_v43, %v121569_v1 (stack40)
        %v112325_v34 = vor.u32 %v112324_v25, %v112323_v9 (stack47)
        %v110307_v20 = vadd.f32 %v110303_v12, %v154096_v20 (stack53)
        %v111080_v61 = vadd.s32 %v111077_v8, %v111072_v61 (stack40)
        %v111082_v9 = vshll.u32 %v111077_v8, 26 (stack45)
        %v111083_v56 = vshrl.u32 %v111077_v8, 6 (stack46)
        %vm112727_vm14 = vcmp.lt.u32.totalorder %v154067_v54, %v154047_v60 (stack43)
        %121377 = vlog2.f32 %v110684_v30 (stack58)
        %v110688_v44 = vadd.f32 1.0, %v110687_v45 (stack61)
        %v110690_v46 = vand.u32 2147483647, %v110682_v50 (stack60)
        %v111477_v29 = vadd.s32 3, %v111473_v31 (stack40)
        %v110311_v25 = vmul.f32 %v110307_v20, %v154123_v21 (stack54)
        %v111084_v43 = vor.u32 %v111083_v56, %v111082_v9 (stack47)
        %v111878_v52 = vadd.s32 %v111875_v23, %v111870_v52 (stack40)
        %v111884_v12 = vshll.u32 %v111875_v23, 24 (stack45)
        %v154144_v50 = vmul.f32 %v110688_v44, %v110682_v50 (stack63)
        %v111481_v8 = vadd.s32 %v111477_v29, %v111465_v24 (stack40)
        %v111483_v24 = vshll.u32 %v111477_v29, 17 (stack45)
        %v111484_v30 = vshrl.u32 %v111477_v29, 15 (stack46)
        %v110315_v32 = vadd.f32 %v110311_v25, %v154090_v32 (stack53)
        %v111085_v45 = vxor.u32 %v111084_v43, %v111080_v61 (stack48)
        %v111882_v31 = vadd.s32 %v111878_v52, %v121564_v0 (stack40)
        %v111885_v23 = vshrl.u32 %v111875_v23, 8 (stack46)
        %v111485_v20 = vor.u32 %v111484_v30, %v111483_v24 (stack47)
        %v112326_v34 = vxor.u32 %v112325_v34, %v112321_v10 (stack48)
        %v112749_v9 = vadd.s32 1, %v112745_v22 (stack40)
        %v112768_v56 = vshll.u32 %v154135_v26, 13 (stack45)
        %v110319_v44 = vmul.f32 %v110315_v32, %v154123_v21 (stack54)
        %v111088_v61 = vadd.s32 %v111085_v45, %v111080_v61 (stack40)
        %v111094_v29 = vshll.u32 %v111085_v45, 6 (stack45)
        %v111095_v25 = vshrl.u32 %v111085_v45, 26 (stack46)
        %v111486_v43 = vxor.u32 %v111485_v20, %v111481_v8 (stack48)
        %v111886_v12 = vor.u32 %v111885_v23, %v111884_v12 (stack47)
        %v112329_v10 = vadd.s32 %v112326_v34, %v112321_v10 (stack40)
        %v112335_v24 = vshll.u32 %v112326_v34, 6 (stack45)
        %v110323_v6 = vadd.f32 %v110319_v44, %v154085_v6 (stack53)
        %vm154151_vm15 = vcmp.lt.f32.partialorder %v110690_v46, 0.0004427343 (stack62)
        %v111092_v30 = vadd.s32 %v111088_v61, %v121564_v0 (stack40)
        %v111096_v32 = vor.u32 %v111095_v25, %v111094_v29 (stack47)
        %v112336_v45 = vshrl.u32 %v112326_v34, 26 (stack46)
        %v111489_v8 = vadd.s32 %v111486_v43, %v111481_v8 (stack40)
        %v111491_v23 = vshll.u32 %v111486_v43, 29 (stack45)
        %v111492_v20 = vshrl.u32 %v111486_v43, 3 (stack46)
        %v111887_v52 = vxor.u32 %v111886_v12, %v111878_v52 (stack48)
        %v110327_v34 = vmul.f32 %v110323_v6, %v154123_v21 (stack54)
        %v111097_v44 = vxor.u32 %v111096_v32, %v111088_v61 (stack48)
        %v112333_v61 = vadd.s32 %v112329_v10, %v121569_v1 (stack40)
        %v112337_v29 = vor.u32 %v112336_v45, %v112335_v24 (stack47)
        %v111493_v25 = vor.u32 %v111492_v20, %v111491_v23 (stack47)
        %v111890_v43 = vadd.s32 %v111887_v52, %v121574_v2 (stack40)
        %v112753_v60 = vsel /*vm=*/%vm112727_vm14, /*on_true_vy=*/%v112749_v9, /*on_false_vx=*/%v112745_v22 (stack44)
        %v112769_v54 = vshrl.u32 %v154135_v26, 19 (stack46)
        %v110331_v7 = vadd.f32 %v110327_v34, %v154077_v7 (stack53)
        %v111100_v22 = vadd.s32 %v111097_v44, %v121574_v2 (stack40)
        %v112338_v9 = vxor.u32 %v112337_v29, %v112329_v10 (stack48)
        %v112758_v12 = vadd.s32 %v112753_v60, %v121574_v2 (stack40)
        %v111494_v10 = vxor.u32 %v111493_v25, %v111489_v8 (stack48)
        %v111894_v24 = vadd.s32 2, %v111890_v43 (stack40)
        %v112770_v56 = vor.u32 %v112769_v54, %v112768_v56 (stack47)
        %v154168_v6 = vadd.s32 %v157796_v41, %v157077_v51 (stack40)
        %v121378_v32 = vpop.eup %121377 (stack64)
        %v110335_v45 = vmul.f32 %v110331_v7, %v154123_v21 (stack54)
        %v111104_v23 = vadd.s32 5, %v111100_v22 (stack40)
        %v112341_v20 = vadd.s32 %v112338_v9, %v121564_v0 (stack40)
        %v112766_v26 = vadd.s32 %v154135_v26, %v112758_v12 (stack40)
        %v110686_v52 = vmul.f32 0.6931472, %v121378_v32 (stack65)
        %v111497_v8 = vadd.s32 %v111494_v10, %v111489_v8 (stack40)
        %v111499_v34 = vshll.u32 %v111494_v10, 16 (stack45)
        %v111500_v44 = vshrl.u32 %v111494_v10, 16 (stack46)
        %v110339_v55 = vadd.f32 %v110335_v45, %v154072_v55 (stack53)
        %v111106_v30 = vxor.u32 %v111104_v23, %v111092_v30 (stack48)
        %v111898_v31 = vadd.s32 %v111894_v24, %v111882_v31 (stack40)
        %v111900_v29 = vshll.u32 %v111894_v24, 13 (stack45)
        %v110692_v50 = vsel /*vm=*/%vm154151_vm15, /*on_true_vy=*/%v154144_v50, /*on_false_vx=*/%v110686_v52 (stack66)
        %v111501_v46 = vor.u32 %v111500_v44, %v111499_v34 (stack47)
        %v111901_v25 = vshrl.u32 %v111894_v24, 19 (stack46)
        %v112345_v43 = vadd.s32 1, %v112341_v20 (stack40)
        %v110343_v60 = vmul.f32 %v110339_v55, %v154123_v21 (stack54)
        %v154178_v54 = vxor.u32 2147483648, %v110692_v50 (stack56)
        %v112771_v7 = vxor.u32 %v112770_v56, %v112766_v26 (stack48)
        %v110208_v22 = vand.u32 2147483647, %v153999_v53 (stack77)
        %v110244_v9 = vsel /*vm=*/%vm110235_vm9, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v111502_v12 = vxor.u32 %v111501_v46, %v111497_v8 (stack48)
        %v112349_v61 = vadd.s32 %v112345_v43, %v112333_v61 (stack40)
        %v110347_v10 = vadd.f32 %v110343_v60, %v110244_v9 (stack53)
        %121379 = vrsqrt.f32 %v154178_v54 (stack67)
        %vm110696_vm0 = vcmp.lt.f32.partialorder %v154178_v54, 5.0 (stack68)
        %v111107_v24 = vand.u32.u8 255, %v111106_v30 (stack49)
        %v111505_v56 = vadd.s32 %v111502_v12, %v111497_v8 (stack40)
        %v111902_v32 = vor.u32 %v111901_v25, %v111900_v29 (stack47)
        %v110216_v45 = vmul.f32 inf, %v153999_v53 (stack54)
        %v110351_v21 = vmul.f32 %v110347_v10, %v154123_v21 (stack54)
        %vm154188_vm1 = vcmp.eq.f32.partialorder %v110208_v22, 1.0 (stack68)
        %v110240_v42 = vsel /*vm=*/%vm110235_vm9, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v154196_v20 = vadd.f32 -2.5, %v154178_v54 (stack53)
        %v112351_v52 = vshll.u32 %v112345_v43, 17 (stack45)
        %v110355_v8 = vadd.f32 %v110351_v21, %v110240_v42 (stack53)
        %v154201_v34 = vsel /*vm=*/%vm110696_vm0, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v154206_v44 = vsel /*vm=*/%vm110696_vm0, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v111509_v55 = vadd.s32 %v111505_v56, %v121569_v1 (stack40)
        %v111108_v30 = vand.u32 65535, %v111107_v24 (stack50)
        %v111511_v29 = vshll.u32 %v111502_v12, 24 (stack45)
        %v111512_v50 = vshrl.u32 %v111502_v12, 8 (stack46)
        %v111903_v46 = vxor.u32 %v111902_v32, %v111898_v31 (stack48)
        %v110359_v53 = vmul.f32 %v110355_v8, %v153999_v53 (stack54)
        %v112352_v25 = vshrl.u32 %v112345_v43, 15 (stack46)
        %v112774_v26 = vadd.s32 %v112771_v7, %v112766_v26 (stack40)
        %v112776_v43 = vshll.u32 %v112771_v7, 15 (stack45)
        %vm110741_vm2 = vcmp.eq.f32.partialorder %v154178_v54, inf (stack70)
        %v111109_v60 = vshrl.u32 %v111108_v30, 1 (stack51)
        %v111513_v22 = vor.u32 %v111512_v50, %v111511_v29 (stack47)
        %v111906_v31 = vadd.s32 %v111903_v46, %v111898_v31 (stack40)
        %v111908_v9 = vshll.u32 %v111903_v46, 15 (stack45)
        %v110363_v12 = vsel /*vm=*/%vm154188_vm1, /*on_true_vy=*/%v110216_v45, /*on_false_vx=*/%v110359_v53 (stack44)
        %v111909_v10 = vshrl.u32 %v111903_v46, 17 (stack46)
        %v112353_v24 = vor.u32 %v112352_v25, %v112351_v52 (stack47)
        %v112777_v7 = vshrl.u32 %v112771_v7, 17 (stack46)
        %v110367_v32 = vmul.f32 1.4140625, %v110363_v12 (stack54)
        %vm110743_vm3 = vcmp.eq.f32.partialorder %v154178_v54, 0.0 (stack71)
        %v111110_v45 = vor.u32 16256, %v111109_v60 (stack47)
        %v111514_v56 = vxor.u32 %v111513_v22, %v111505_v56 (stack48)
        %v111910_v21 = vor.u32 %v111909_v10, %v111908_v9 (stack47)
        %v112354_v23 = vxor.u32 %v112353_v24, %v112349_v61 (stack48)
        %v112778_v42 = vor.u32 %v112777_v7, %v112776_v43 (stack47)
        %vm113193_vm4 = vcmp.lt.u32.totalorder %v154168_v6, %v157077_v51 (stack43)
        %v110370_v52 = vpack.c.bf16 %v157387_v11, %v110367_v32 (stack81)
        %v110744_v8 = vand.u32 2147483648, %v154178_v54 (stack72)
        %v111111_v30 = vand.u32.u16 65535, %v111110_v45 (stack52)
        %v111517_v29 = vadd.s32 %v111514_v56, %v121564_v0 (stack40)
        %v111911_v50 = vxor.u32 %v111910_v21, %v111906_v31 (stack48)
        %v112357_v61 = vadd.s32 %v112354_v23, %v112349_v61 (stack40)
        %v112359_v46 = vshll.u32 %v112354_v23, 29 (stack45)
        %v112360_v53 = vshrl.u32 %v112354_v23, 3 (stack46)
        %v121380_v25 = vpop.eup %121379 (stack73)
        %120335 = vst [vmem:[%s123356_s30 + $0x1f4] sm:$0xf] /*vst_source=*/%v110370_v52 (stack83)
        %v120338_v43 = vadd.low.f32.bf16 -1.0, %v111111_v30 (stack53)
        %v111521_v60 = vadd.s32 4, %v111517_v29 (stack40)
        %v112779_v22 = vxor.u32 %v112778_v42, %v112774_v26 (stack48)
        %v154222_v9 = vadd.s32 %v157799_v40, %v157078_v48 (stack40)
        %v110740_v12 = vmul.f32 %v121380_v25, %v154178_v54 (stack74)
        %v111914_v31 = vadd.s32 %v111911_v50, %v111906_v31 (stack40)
        %v111916_v10 = vshll.u32 %v111911_v50, 26 (stack45)
        %v111917_v24 = vshrl.u32 %v111911_v50, 6 (stack46)
        %v111120_v7 = vmul.f32 2.0, %v120338_v43 (stack54)
        %v111525_v55 = vadd.s32 %v111521_v60, %v111509_v55 (stack40)
        %v111527_v32 = vshll.u32 %v111521_v60, 13 (stack45)
        %v111528_v45 = vshrl.u32 %v111521_v60, 19 (stack46)
        %v110742_v56 = vsel /*vm=*/%vm110741_vm2, /*on_true_vy=*/%v154178_v54, /*on_false_vx=*/%v110740_v12 (stack75)
        %v111918_v21 = vor.u32 %v111917_v24, %v111916_v10 (stack47)
        %v112361_v23 = vor.u32 %v112360_v53, %v112359_v46 (stack47)
        %v154228_v26 = vadd.s32 %v112779_v22, %v112774_v26 (stack40)
        %v154233_v42 = vsel /*vm=*/%vm110696_vm0, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v110745_v52 = vsel /*vm=*/%vm110743_vm3, /*on_true_vy=*/%v110744_v8, /*on_false_vx=*/%v110742_v56 (stack76)
        %v111124_v8 = vadd.f32 -0.99609375, %v111120_v7 (stack53)
        %v111529_v30 = vor.u32 %v111528_v45, %v111527_v32 (stack47)
        %v110721_v29 = vsel /*vm=*/%vm110696_vm0, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v110748_v50 = vadd.f32 -3.0, %v110745_v52 (stack53)
        %v111919_v46 = vxor.u32 %v111918_v21, %v111914_v31 (stack48)
        %v112362_v53 = vxor.u32 %v112361_v23, %v112357_v61 (stack48)
        %v110725_v25 = vsel /*vm=*/%vm110696_vm0, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v110733_v43 = vsel /*vm=*/%vm110696_vm0, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v154246_v60 = vmax.f32 %v111124_v8, -0.99609375 (stack55)
        %v111530_v12 = vxor.u32 %v111529_v30, %v111525_v55 (stack48)
        %v154251_v20 = vsel /*vm=*/%vm110696_vm0, /*on_true_vy=*/%v154196_v20, /*on_false_vx=*/%v110748_v50 (stack44)
        %v111922_v31 = vadd.s32 %v111919_v46, %v111914_v31 (stack40)
        %v111928_v10 = vshll.u32 %v111919_v46, 6 (stack45)
        %v111929_v24 = vshrl.u32 %v111919_v46, 26 (stack46)
        %v110729_v7 = vsel /*vm=*/%vm110696_vm0, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v110756_v32 = vmul.f32 %v154251_v20, %v110733_v43 (stack54)
        %v111140_v45 = vxor.u32 2147483648, %v154246_v60 (stack56)
        %v112784_v56 = vshll.u32 %v112779_v22, 26 (stack45)
        %v111533_v55 = vadd.s32 %v111530_v12, %v111525_v55 (stack40)
        %v111535_v21 = vshll.u32 %v111530_v12, 15 (stack45)
        %v111536_v23 = vshrl.u32 %v111530_v12, 17 (stack46)
        %v112785_v22 = vshrl.u32 %v112779_v22, 6 (stack46)
        %v110760_v52 = vadd.f32 %v110756_v32, %v110729_v7 (stack53)
        %v111143_v8 = vmul.f32 %v111140_v45, %v154246_v60 (stack54)
        %v111930_v30 = vor.u32 %v111929_v24, %v111928_v10 (stack47)
        %v154261_v50 = vadd.s32 %v154168_v6, %v122657_v58 (stack40)
        %v111537_v46 = vor.u32 %v111536_v23, %v111535_v21 (stack47)
        %v112365_v61 = vadd.s32 %v112362_v53, %v112357_v61 (stack40)
        %v112367_v43 = vshll.u32 %v112362_v53, 16 (stack45)
        %v112368_v53 = vshrl.u32 %v112362_v53, 16 (stack46)
        %v110764_v12 = vmul.f32 %v110760_v52, %v154251_v20 (stack54)
        %v111145_v10 = vadd.f32 1.0, %v111143_v8 (stack57)
        %v111148_v24 = vmul.f32 -0.5, %v111143_v8 (stack59)
        %v113202_v7 = vadd.s32 1, %v154222_v9 (stack40)
        %v111538_v32 = vxor.u32 %v111537_v46, %v111533_v55 (stack48)
        %v111931_v45 = vxor.u32 %v111930_v30, %v111922_v31 (stack48)
        %v112369_v21 = vor.u32 %v112368_v53, %v112367_v43 (stack47)
        %v112786_v56 = vor.u32 %v112785_v22, %v112784_v56 (stack47)
        %v110768_v25 = vadd.f32 %v110764_v12, %v110725_v25 (stack53)
        %121381 = vlog2.f32 %v111145_v10 (stack58)
        %v111926_v31 = vadd.s32 %v111922_v31, %v121574_v2 (stack40)
        %v154268_v23 = vadd.s32 %v154261_v50, %v121569_v1 (stack40)
        %v111541_v55 = vadd.s32 %v111538_v32, %v111533_v55 (stack40)
        %v111543_v22 = vshll.u32 %v111538_v32, 26 (stack45)
        %v111544_v52 = vshrl.u32 %v111538_v32, 6 (stack46)
        %v111934_v30 = vadd.s32 %v111931_v45, %v121569_v1 (stack40)
        %vm113188_vm5 = vcmp.lt.u32.totalorder %v154261_v50, %v154168_v6 (stack43)
        %v110772_v46 = vmul.f32 %v110768_v25, %v154251_v20 (stack54)
        %v111149_v43 = vadd.f32 1.0, %v111148_v24 (stack61)
        %v112370_v53 = vxor.u32 %v112369_v21, %v112365_v61 (stack48)
        %v112787_v12 = vxor.u32 %v112786_v56, %v154228_v26 (stack48)
        %v111151_v10 = vand.u32 2147483647, %v111143_v8 (stack60)
        %v111545_v24 = vor.u32 %v111544_v52, %v111543_v22 (stack47)
        %v111938_v32 = vadd.s32 3, %v111934_v30 (stack40)
        %v113206_v9 = vsel /*vm=*/%vm113193_vm4, /*on_true_vy=*/%v113202_v7, /*on_false_vx=*/%v154222_v9 (stack44)
        %v110776_v29 = vadd.f32 %v110772_v46, %v110721_v29 (stack53)
        %v112373_v61 = vadd.s32 %v112370_v53, %v112365_v61 (stack40)
        %v112379_v7 = vshll.u32 %v112370_v53, 24 (stack45)
        %v112380_v45 = vshrl.u32 %v112370_v53, 8 (stack46)
        %v111546_v21 = vxor.u32 %v111545_v24, %v111541_v55 (stack48)
        %v111942_v56 = vadd.s32 %v111938_v32, %v111926_v31 (stack40)
        %v111944_v25 = vshll.u32 %v111938_v32, 17 (stack45)
        %v111945_v31 = vshrl.u32 %v111938_v32, 15 (stack46)
        %v110780_v22 = vmul.f32 %v110776_v29, %v154251_v20 (stack54)
        %v111150_v8 = vmul.f32 %v111149_v43, %v111143_v8 (stack63)
        %v112381_v52 = vor.u32 %v112380_v45, %v112379_v7 (stack47)
        %v112790_v26 = vadd.s32 %v112787_v12, %v154228_v26 (stack40)
        %vm154281_vm6 = vcmp.lt.f32.partialorder %v111151_v10, 0.0004427343 (stack62)
        %v111549_v55 = vadd.s32 %v111546_v21, %v111541_v55 (stack40)
        %v111555_v46 = vshll.u32 %v111546_v21, 6 (stack45)
        %v111556_v43 = vshrl.u32 %v111546_v21, 26 (stack46)
        %v111946_v53 = vor.u32 %v111945_v31, %v111944_v25 (stack47)
        %v110784_v42 = vadd.f32 %v110780_v22, %v154233_v42 (stack53)
        %v112382_v10 = vxor.u32 %v112381_v52, %v112373_v61 (stack48)
        %v112796_v24 = vshll.u32 %v112787_v12, 6 (stack45)
        %v113229_v32 = vshll.u32 %v154268_v23, 13 (stack45)
        %v111557_v29 = vor.u32 %v111556_v43, %v111555_v46 (stack47)
        %v111947_v7 = vxor.u32 %v111946_v53, %v111942_v56 (stack48)
        %v112377_v61 = vadd.s32 %v112373_v61, %v121564_v0 (stack40)
        %v112797_v12 = vshrl.u32 %v112787_v12, 26 (stack46)
        %v110788_v45 = vmul.f32 %v110784_v42, %v154251_v20 (stack54)
        %v111553_v21 = vadd.s32 %v111549_v55, %v121564_v0 (stack40)
        %v112385_v25 = vadd.s32 %v112382_v10, %v121574_v2 (stack40)
        %v113210_v31 = vadd.s32 1, %v113206_v9 (stack40)
        %v111558_v22 = vxor.u32 %v111557_v29, %v111549_v55 (stack48)
        %v111950_v56 = vadd.s32 %v111947_v7, %v111942_v56 (stack40)
        %v111952_v52 = vshll.u32 %v111947_v7, 29 (stack45)
        %v111953_v55 = vshrl.u32 %v111947_v7, 3 (stack46)
        %v110792_v44 = vadd.f32 %v110788_v45, %v154206_v44 (stack53)
        %v112389_v46 = vadd.s32 2, %v112385_v25 (stack40)
        %v112798_v43 = vor.u32 %v112797_v12, %v112796_v24 (stack47)
        %v113214_v6 = vsel /*vm=*/%vm113188_vm5, /*on_true_vy=*/%v113210_v31, /*on_false_vx=*/%v113206_v9 (stack44)
        %v121382_v50 = vpop.eup %121381 (stack64)
        %v111561_v9 = vadd.s32 %v111558_v22, %v121574_v2 (stack40)
        %v111954_v53 = vor.u32 %v111953_v55, %v111952_v52 (stack47)
        %v113219_v42 = vadd.s32 %v113214_v6, %v121574_v2 (stack40)
        %v113230_v10 = vshrl.u32 %v154268_v23, 19 (stack46)
        %v110796_v24 = vmul.f32 %v110792_v44, %v154251_v20 (stack54)
        %v111147_v29 = vmul.f32 0.6931472, %v121382_v50 (stack65)
        %v112393_v7 = vadd.s32 %v112389_v46, %v112377_v61 (stack40)
        %v112395_v61 = vshll.u32 %v112389_v46, 13 (stack45)
        %v111565_v12 = vadd.s32 5, %v111561_v9 (stack40)
        %v111955_v45 = vxor.u32 %v111954_v53, %v111950_v56 (stack48)
        %v112396_v25 = vshrl.u32 %v112389_v46, 19 (stack46)
        %v112799_v31 = vxor.u32 %v112798_v43, %v112790_v26 (stack48)
        %v110800_v34 = vadd.f32 %v110796_v24, %v154201_v34 (stack53)
        %v111153_v8 = vsel /*vm=*/%vm154281_vm6, /*on_true_vy=*/%v111150_v8, /*on_false_vx=*/%v111147_v29 (stack66)
        %v113227_v23 = vadd.s32 %v154268_v23, %v113219_v42 (stack40)
        %v154305_v30 = vadd.s32 %v157796_v41, %v157079_v39 (stack40)
        %v154307_v22 = vxor.u32 2147483648, %v111153_v8 (stack56)
        %v111567_v21 = vxor.u32 %v111565_v12, %v111553_v21 (stack48)
        %v111958_v56 = vadd.s32 %v111955_v45, %v111950_v56 (stack40)
        %v111960_v52 = vshll.u32 %v111955_v45, 16 (stack45)
        %v110669_v55 = vand.u32 2147483647, %v154125_v27 (stack77)
        %v110804_v44 = vmul.f32 %v110800_v34, %v154251_v20 (stack54)
        %v111961_v46 = vshrl.u32 %v111955_v45, 16 (stack46)
        %v110705_v43 = vsel /*vm=*/%vm110696_vm0, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %121383 = vrsqrt.f32 %v154307_v22 (stack67)
        %v113231_v32 = vor.u32 %v113230_v10, %v113229_v32 (stack47)
        %v110808_v6 = vadd.f32 %v110804_v44, %v110705_v43 (stack53)
        %vm111157_vm7 = vcmp.lt.f32.partialorder %v154307_v22, 5.0 (stack68)
        %v112397_v50 = vor.u32 %v112396_v25, %v112395_v61 (stack47)
        %v112802_v9 = vadd.s32 %v112799_v31, %v121564_v0 (stack40)
        %v110677_v53 = vmul.f32 inf, %v154125_v27 (stack54)
        %v111962_v42 = vor.u32 %v111961_v46, %v111960_v52 (stack47)
        %vm154318_vm8 = vcmp.eq.f32.partialorder %v110669_v55, 1.0 (stack68)
        %v110701_v54 = vsel /*vm=*/%vm110696_vm0, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v110812_v20 = vmul.f32 %v110808_v6, %v154251_v20 (stack54)
        %v112794_v26 = vadd.s32 %v112790_v26, %v121569_v1 (stack40)
        %v154330_v24 = vsel /*vm=*/%vm111157_vm7, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v154333_v29 = vadd.f32 -2.5, %v154307_v22 (stack53)
        %v111568_v61 = vand.u32.u8 255, %v111567_v21 (stack49)
        %v111963_v12 = vxor.u32 %v111962_v42, %v111958_v56 (stack48)
        %v110816_v45 = vadd.f32 %v110812_v20, %v110701_v54 (stack53)
        %v112398_v25 = vxor.u32 %v112397_v50, %v112393_v7 (stack48)
        %v112806_v31 = vadd.s32 1, %v112802_v9 (stack40)
        %v113232_v34 = vxor.u32 %v113231_v32, %v113227_v23 (stack48)
        %v111569_v8 = vand.u32 65535, %v111568_v61 (stack50)
        %v111966_v21 = vadd.s32 %v111963_v12, %v111958_v56 (stack40)
        %v111972_v56 = vshll.u32 %v111963_v12, 24 (stack45)
        %v111973_v52 = vshrl.u32 %v111963_v12, 8 (stack46)
        %v110820_v27 = vmul.f32 %v110816_v45, %v154125_v27 (stack54)
        %vm111202_vm9 = vcmp.eq.f32.partialorder %v154307_v22, inf (stack70)
        %v112401_v7 = vadd.s32 %v112398_v25, %v112393_v7 (stack40)
        %v112403_v55 = vshll.u32 %v112398_v25, 15 (stack45)
        %v112404_v44 = vshrl.u32 %v112398_v25, 17 (stack46)
        %vm111204_vm10 = vcmp.eq.f32.partialorder %v154307_v22, 0.0 (stack71)
        %v111205_v46 = vand.u32 2147483648, %v154307_v22 (stack72)
        %v111570_v43 = vshrl.u32 %v111569_v8, 1 (stack51)
        %v111974_v32 = vor.u32 %v111973_v52, %v111972_v56 (stack47)
        %v112810_v6 = vadd.s32 %v112806_v31, %v112794_v26 (stack40)
        %v110824_v50 = vsel /*vm=*/%vm154318_vm8, /*on_true_vy=*/%v110677_v53, /*on_false_vx=*/%v110820_v27 (stack44)
        %v112405_v9 = vor.u32 %v112404_v44, %v112403_v55 (stack47)
        %v112812_v53 = vshll.u32 %v112806_v31, 17 (stack45)
        %v112813_v42 = vshrl.u32 %v112806_v31, 15 (stack46)
        %v110828_v10 = vmul.f32 1.4140625, %v110824_v50 (stack54)
        %v111571_v54 = vor.u32 16256, %v111570_v43 (stack47)
        %v111975_v20 = vxor.u32 %v111974_v32, %v111966_v21 (stack48)
        %v113235_v23 = vadd.s32 %v113232_v34, %v113227_v23 (stack40)
        %v112406_v26 = vxor.u32 %v112405_v9, %v112401_v7 (stack48)
        %v112814_v61 = vor.u32 %v112813_v42, %v112812_v53 (stack47)
        %v113237_v12 = vshll.u32 %v113232_v34, 15 (stack45)
        %v113238_v45 = vshrl.u32 %v113232_v34, 17 (stack46)
        %v110831_v25 = vpack.c.bf16 %v157387_v11, %v110828_v10 (stack81)
        %v111572_v31 = vand.u32.u16 65535, %v111571_v54 (stack52)
        %v111970_v34 = vadd.s32 %v111966_v21, %v121569_v1 (stack40)
        %v111978_v8 = vadd.s32 %v111975_v20, %v121564_v0 (stack40)
        %v121384_v21 = vpop.eup %121383 (stack73)
        %v112409_v56 = vadd.s32 %v112406_v26, %v112401_v7 (stack40)
        %v112411_v52 = vshll.u32 %v112406_v26, 26 (stack45)
        %v112412_v27 = vshrl.u32 %v112406_v26, 6 (stack46)
        %v112815_v7 = vxor.u32 %v112814_v61, %v112810_v6 (stack48)
        %120337 = vst [vmem:[%s123356_s30 + $0x274] sm:$0xf] /*vst_source=*/%v110831_v25 (stack83)
        %v111201_v55 = vmul.f32 %v121384_v21, %v154307_v22 (stack74)
        %v120340_v44 = vadd.low.f32.bf16 -1.0, %v111572_v31 (stack53)
        %v111982_v43 = vadd.s32 4, %v111978_v8 (stack40)
        %v113239_v32 = vor.u32 %v113238_v45, %v113237_v12 (stack47)
        %v112413_v50 = vor.u32 %v112412_v27, %v112411_v52 (stack47)
        %v112818_v6 = vadd.s32 %v112815_v7, %v112810_v6 (stack40)
        %v112820_v9 = vshll.u32 %v112815_v7, 29 (stack45)
        %v112821_v53 = vshrl.u32 %v112815_v7, 3 (stack46)
        %v111203_v42 = vsel /*vm=*/%vm111202_vm9, /*on_true_vy=*/%v154307_v22, /*on_false_vx=*/%v111201_v55 (stack75)
        %v111581_v10 = vmul.f32 2.0, %v120340_v44 (stack54)
        %v111986_v54 = vadd.s32 %v111982_v43, %v111970_v34 (stack40)
        %v111988_v20 = vshll.u32 %v111982_v43, 13 (stack45)
        %v111206_v46 = vsel /*vm=*/%vm111204_vm10, /*on_true_vy=*/%v111205_v46, /*on_false_vx=*/%v111203_v42 (stack76)
        %v111989_v26 = vshrl.u32 %v111982_v43, 19 (stack46)
        %v112414_v61 = vxor.u32 %v112413_v50, %v112409_v56 (stack48)
        %v112822_v12 = vor.u32 %v112821_v53, %v112820_v9 (stack47)
        %v111194_v45 = vsel /*vm=*/%vm111157_vm7, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v111209_v25 = vadd.f32 -3.0, %v111206_v46 (stack53)
        %v111585_v31 = vadd.f32 -0.99609375, %v111581_v10 (stack53)
        %v113240_v34 = vxor.u32 %v113239_v32, %v113235_v23 (stack48)
        %v111990_v8 = vor.u32 %v111989_v26, %v111988_v20 (stack47)
        %v112417_v21 = vadd.s32 %v112414_v61, %v112409_v56 (stack40)
        %v112423_v56 = vshll.u32 %v112414_v61, 6 (stack45)
        %v112424_v52 = vshrl.u32 %v112414_v61, 26 (stack46)
        %v154357_v29 = vsel /*vm=*/%vm111157_vm7, /*on_true_vy=*/%v154333_v29, /*on_false_vx=*/%v111209_v25 (stack44)
        %v154359_v27 = vmax.f32 %v111585_v31, -0.99609375 (stack55)
        %v112823_v7 = vxor.u32 %v112822_v12, %v112818_v6 (stack48)
        %v154361_v23 = vadd.s32 %v113240_v34, %v113235_v23 (stack40)
        %v154366_v55 = vsel /*vm=*/%vm111157_vm7, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v111217_v44 = vmul.f32 %v154357_v29, %v111194_v45 (stack54)
        %v111991_v43 = vxor.u32 %v111990_v8, %v111986_v54 (stack48)
        %v112425_v32 = vor.u32 %v112424_v52, %v112423_v56 (stack47)
        %v111178_v50 = vsel /*vm=*/%vm111157_vm7, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v111190_v9 = vsel /*vm=*/%vm111157_vm7, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v111601_v53 = vxor.u32 2147483648, %v154359_v27 (stack56)
        %v112826_v6 = vadd.s32 %v112823_v7, %v112818_v6 (stack40)
        %v111221_v42 = vadd.f32 %v111217_v44, %v111190_v9 (stack53)
        %v111994_v10 = vadd.s32 %v111991_v43, %v111986_v54 (stack40)
        %v111996_v54 = vshll.u32 %v111991_v43, 15 (stack45)
        %v111997_v20 = vshrl.u32 %v111991_v43, 17 (stack46)
        %v111182_v46 = vsel /*vm=*/%vm111157_vm7, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v111604_v26 = vmul.f32 %v111601_v53, %v154359_v27 (stack54)
        %v112426_v61 = vxor.u32 %v112425_v32, %v112417_v21 (stack48)
        %v112828_v12 = vshll.u32 %v112823_v7, 16 (stack45)
        %v111186_v45 = vsel /*vm=*/%vm111157_vm7, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v111225_v25 = vmul.f32 %v111221_v42, %v154357_v29 (stack54)
        %v111998_v31 = vor.u32 %v111997_v20, %v111996_v54 (stack47)
        %v112829_v8 = vshrl.u32 %v112823_v7, 16 (stack46)
        %v111606_v56 = vadd.f32 1.0, %v111604_v26 (stack57)
        %v112429_v52 = vadd.s32 %v112426_v61, %v121569_v1 (stack40)
        %v113245_v7 = vshll.u32 %v113240_v34, 26 (stack45)
        %v154387_v44 = vadd.s32 %v154305_v30, %v122657_v58 (stack40)
        %v111229_v43 = vadd.f32 %v111225_v25, %v111186_v45 (stack53)
        %v111999_v32 = vxor.u32 %v111998_v31, %v111994_v10 (stack48)
        %v112830_v9 = vor.u32 %v112829_v8, %v112828_v12 (stack47)
        %v113246_v34 = vshrl.u32 %v113240_v34, 6 (stack46)
        %121385 = vlog2.f32 %v111606_v56 (stack58)
        %v111609_v53 = vmul.f32 -0.5, %v111604_v26 (stack59)
        %v112421_v21 = vadd.s32 %v112417_v21, %v121574_v2 (stack40)
        %v112433_v42 = vadd.s32 3, %v112429_v52 (stack40)
        %v111233_v54 = vmul.f32 %v111229_v43, %v154357_v29 (stack54)
        %v112002_v10 = vadd.s32 %v111999_v32, %v111994_v10 (stack40)
        %v112004_v20 = vshll.u32 %v111999_v32, 26 (stack45)
        %v112005_v61 = vshrl.u32 %v111999_v32, 6 (stack46)
        %v111612_v12 = vand.u32 2147483647, %v111604_v26 (stack60)
        %v112437_v45 = vadd.s32 %v112433_v42, %v112421_v21 (stack40)
        %v112439_v25 = vshll.u32 %v112433_v42, 17 (stack45)
        %v112440_v31 = vshrl.u32 %v112433_v42, 15 (stack46)
        %v111237_v46 = vadd.f32 %v111233_v54, %v111182_v46 (stack53)
        %v112006_v8 = vor.u32 %v112005_v61, %v112004_v20 (stack47)
        %v112831_v56 = vxor.u32 %v112830_v9, %v112826_v6 (stack48)
        %v113247_v52 = vor.u32 %v113246_v34, %v113245_v7 (stack47)
        %v111610_v7 = vadd.f32 1.0, %v111609_v53 (stack61)
        %v112441_v43 = vor.u32 %v112440_v31, %v112439_v25 (stack47)
        %vm113654_vm11 = vcmp.lt.u32.totalorder %v154305_v30, %v157079_v39 (stack43)
        %v113659_v32 = vadd.s32 %v157799_v40, %v157082_v49 (stack40)
        %v111241_v9 = vmul.f32 %v111237_v46, %v154357_v29 (stack54)
        %v112007_v34 = vxor.u32 %v112006_v8, %v112002_v10 (stack48)
        %v112834_v6 = vadd.s32 %v112831_v56, %v112826_v6 (stack40)
        %v112840_v53 = vshll.u32 %v112831_v56, 24 (stack45)
        %v112442_v21 = vxor.u32 %v112441_v43, %v112437_v45 (stack48)
        %v112841_v42 = vshrl.u32 %v112831_v56, 8 (stack46)
        %v113248_v54 = vxor.u32 %v113247_v52, %v154361_v23 (stack48)
        %vm113649_vm12 = vcmp.lt.u32.totalorder %v154387_v44, %v154305_v30 (stack43)
        %v111245_v50 = vadd.f32 %v111241_v9, %v111178_v50 (stack53)
        %vm154399_vm13 = vcmp.lt.f32.partialorder %v111612_v12, 0.0004427343 (stack62)
        %v112010_v10 = vadd.s32 %v112007_v34, %v112002_v10 (stack40)
        %v112016_v61 = vshll.u32 %v112007_v34, 6 (stack45)
        %v112017_v12 = vshrl.u32 %v112007_v34, 26 (stack46)
        %v111611_v26 = vmul.f32 %v111610_v7, %v111604_v26 (stack63)
        %v112445_v45 = vadd.s32 %v112442_v21, %v112437_v45 (stack40)
        %v112447_v25 = vshll.u32 %v112442_v21, 29 (stack45)
        %v112448_v31 = vshrl.u32 %v112442_v21, 3 (stack46)
        %v111249_v46 = vmul.f32 %v111245_v50, %v154357_v29 (stack54)
        %v112018_v8 = vor.u32 %v112017_v12, %v112016_v61 (stack47)
        %v112842_v56 = vor.u32 %v112841_v42, %v112840_v53 (stack47)
        %v113663_v52 = vadd.s32 1, %v113659_v32 (stack40)
        %v112449_v7 = vor.u32 %v112448_v31, %v112447_v25 (stack47)
        %v113251_v23 = vadd.s32 %v113248_v54, %v154361_v23 (stack40)
        %v113257_v43 = vshll.u32 %v113248_v54, 6 (stack45)
        %v113258_v9 = vshrl.u32 %v113248_v54, 26 (stack46)
        %v111253_v55 = vadd.f32 %v111249_v46, %v154366_v55 (stack53)
        %v112019_v34 = vxor.u32 %v112018_v8, %v112010_v10 (stack48)
        %v112843_v53 = vxor.u32 %v112842_v56, %v112834_v6 (stack48)
        %v113667_v32 = vsel /*vm=*/%vm113654_vm11, /*on_true_vy=*/%v113663_v52, /*on_false_vx=*/%v113659_v32 (stack44)
        %v112450_v21 = vxor.u32 %v112449_v7, %v112445_v45 (stack48)
        %v112838_v6 = vadd.s32 %v112834_v6, %v121564_v0 (stack40)
        %v113259_v42 = vor.u32 %v113258_v9, %v113257_v43 (stack47)
        %v113671_v54 = vadd.s32 1, %v113667_v32 (stack40)
        %v121386_v50 = vpop.eup %121385 (stack64)
        %v111257_v61 = vmul.f32 %v111253_v55, %v154357_v29 (stack54)
        %v112014_v10 = vadd.s32 %v112010_v10, %v121564_v0 (stack40)
        %v112022_v12 = vadd.s32 %v112019_v34, %v121574_v2 (stack40)
        %v112846_v25 = vadd.s32 %v112843_v53, %v121574_v2 (stack40)
        %v111608_v31 = vmul.f32 0.6931472, %v121386_v50 (stack65)
        %v112453_v45 = vadd.s32 %v112450_v21, %v112445_v45 (stack40)
        %v112455_v46 = vshll.u32 %v112450_v21, 16 (stack45)
        %v112456_v8 = vshrl.u32 %v112450_v21, 16 (stack46)
        %v111261_v24 = vadd.f32 %v111257_v61, %v154330_v24 (stack53)
        %v112026_v56 = vadd.s32 5, %v112022_v12 (stack40)
        %v112850_v52 = vadd.s32 2, %v112846_v25 (stack40)
        %v113260_v7 = vxor.u32 %v113259_v42, %v113251_v23 (stack48)
        %v111614_v20 = vsel /*vm=*/%vm154399_vm13, /*on_true_vy=*/%v111611_v26, /*on_false_vx=*/%v111608_v31 (stack66)
        %v112457_v26 = vor.u32 %v112456_v8, %v112455_v46 (stack47)
        %v113675_v30 = vsel /*vm=*/%vm113649_vm12, /*on_true_vy=*/%v113671_v54, /*on_false_vx=*/%v113667_v32 (stack44)
        %v113684_v44 = vadd.s32 %v154387_v44, %v121569_v1 (stack40)
        %v111265_v43 = vmul.f32 %v111261_v24, %v154357_v29 (stack54)
        %v154423_v9 = vxor.u32 2147483648, %v111614_v20 (stack56)
        %v112028_v55 = vxor.u32 %v112026_v56, %v112014_v10 (stack48)
        %v112854_v34 = vadd.s32 %v112850_v52, %v112838_v6 (stack40)
        %v111130_v53 = vand.u32 2147483647, %v154246_v60 (stack77)
        %v111166_v32 = vsel /*vm=*/%vm111157_vm7, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v112458_v21 = vxor.u32 %v112457_v26, %v112453_v45 (stack48)
        %v111138_v6 = vmul.f32 inf, %v154246_v60 (stack54)
        %v111269_v42 = vadd.f32 %v111265_v43, %v111166_v32 (stack53)
        %121387 = vrsqrt.f32 %v154423_v9 (stack67)
        %vm111618_vm14 = vcmp.lt.f32.partialorder %v154423_v9, 5.0 (stack68)
        %v112461_v54 = vadd.s32 %v112458_v21, %v112453_v45 (stack40)
        %v112856_v50 = vshll.u32 %v112850_v52, 13 (stack45)
        %v112857_v61 = vshrl.u32 %v112850_v52, 19 (stack46)
        %v111273_v29 = vmul.f32 %v111269_v42, %v154357_v29 (stack54)
        %v113263_v10 = vadd.s32 %v113260_v7, %v121564_v0 (stack40)
        %v113690_v12 = vshll.u32 %v113684_v44, 13 (stack45)
        %v113691_v25 = vshrl.u32 %v113684_v44, 19 (stack46)
        %vm154434_vm15 = vcmp.eq.f32.partialorder %v111130_v53, 1.0 (stack68)
        %v111162_v22 = vsel /*vm=*/%vm111157_vm7, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v111591_v45 = vand.u32 2147483647, %v154359_v27 (stack77)
        %v113255_v23 = vadd.s32 %v113251_v23, %v121569_v1 (stack40)
        %v111277_v46 = vadd.f32 %v111273_v29, %v111162_v22 (stack53)
        %v154446_v8 = vsel /*vm=*/%vm111618_vm14, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v154449_v24 = vadd.f32 -2.5, %v154423_v9 (stack53)
        %v112465_v56 = vadd.s32 %v112461_v54, %v121569_v1 (stack40)
        %v112029_v52 = vand.u32.u8 255, %v112028_v55 (stack49)
        %v112467_v7 = vshll.u32 %v112458_v21, 24 (stack45)
        %v112468_v20 = vshrl.u32 %v112458_v21, 8 (stack46)
        %v112858_v26 = vor.u32 %v112857_v61, %v112856_v50 (stack47)
        %v111281_v60 = vmul.f32 %v111277_v46, %v154246_v60 (stack54)
        %v113267_v43 = vadd.s32 1, %v113263_v10 (stack40)
        %v113680_v30 = vadd.s32 %v113675_v30, %v121574_v2 (stack40)
        %v113692_v55 = vor.u32 %v113691_v25, %v113690_v12 (stack47)
        %vm111663_vm0 = vcmp.eq.f32.partialorder %v154423_v9, inf (stack70)
        %v112030_v53 = vand.u32 65535, %v112029_v52 (stack50)
        %v112469_v32 = vor.u32 %v112468_v20, %v112467_v7 (stack47)
        %v112859_v21 = vxor.u32 %v112858_v26, %v112854_v34 (stack48)
        %v154457_v42 = vadd.s32 %v157796_v41, %v157083_v59 (stack40)
        %v111285_v6 = vsel /*vm=*/%vm154434_vm15, /*on_true_vy=*/%v111138_v6, /*on_false_vx=*/%v111281_v60 (stack44)
        %v113271_v50 = vadd.s32 %v113267_v43, %v113255_v23 (stack40)
        %v113273_v61 = vshll.u32 %v113267_v43, 17 (stack45)
        %v113274_v29 = vshrl.u32 %v113267_v43, 15 (stack46)
        %v111289_v10 = vmul.f32 1.4140625, %v111285_v6 (stack54)
        %v112031_v12 = vshrl.u32 %v112030_v53, 1 (stack51)
        %v112470_v54 = vxor.u32 %v112469_v32, %v112461_v54 (stack48)
        %v112862_v34 = vadd.s32 %v112859_v21, %v112854_v34 (stack40)
        %v112864_v25 = vshll.u32 %v112859_v21, 15 (stack45)
        %v112865_v31 = vshrl.u32 %v112859_v21, 17 (stack46)
        %v113275_v22 = vor.u32 %v113274_v29, %v113273_v61 (stack47)
        %v113688_v44 = vadd.s32 %v113684_v44, %v113680_v30 (stack40)
        %v111292_v23 = vpack.c.bf16 %v157387_v11, %v111289_v10 (stack81)
        %vm111665_vm1 = vcmp.eq.f32.partialorder %v154423_v9, 0.0 (stack71)
        %v112032_v46 = vor.u32 16256, %v112031_v12 (stack47)
        %v112473_v52 = vadd.s32 %v112470_v54, %v121564_v0 (stack40)
        %v112866_v7 = vor.u32 %v112865_v31, %v112864_v25 (stack47)
        %v113276_v20 = vxor.u32 %v113275_v22, %v113271_v50 (stack48)
        %v113693_v26 = vxor.u32 %v113692_v55, %v113688_v44 (stack48)
        %vm114115_vm2 = vcmp.lt.u32.totalorder %v154457_v42, %v157083_v59 (stack43)
        %v121388_v60 = vpop.eup %121387 (stack73)
        %120339 = vst [vmem:[%s123356_s30 + $0x2f4] sm:$0xf] /*vst_source=*/%v111292_v23 (stack83)
        %v111666_v43 = vand.u32 2147483648, %v154423_v9 (stack72)
        %v112033_v30 = vand.u32.u16 65535, %v112032_v46 (stack52)
        %v112477_v55 = vadd.s32 4, %v112473_v52 (stack40)
        %v154470_v53 = vadd.s32 %v157799_v40, %v157084_v16 (stack40)
        %v111662_v32 = vmul.f32 %v121388_v60, %v154423_v9 (stack74)
        %v112867_v21 = vxor.u32 %v112866_v7, %v112862_v34 (stack48)
        %v113279_v6 = vadd.s32 %v113276_v20, %v113271_v50 (stack40)
        %v113281_v50 = vshll.u32 %v113276_v20, 29 (stack45)
        %v120342_v61 = vadd.low.f32.bf16 -1.0, %v112033_v30 (stack53)
        %v112481_v56 = vadd.s32 %v112477_v55, %v112465_v56 (stack40)
        %v112483_v29 = vshll.u32 %v112477_v55, 13 (stack45)
        %v112484_v10 = vshrl.u32 %v112477_v55, 19 (stack46)
        %v111664_v12 = vsel /*vm=*/%vm111663_vm0, /*on_true_vy=*/%v154423_v9, /*on_false_vx=*/%v111662_v32 (stack75)
        %v112870_v54 = vadd.s32 %v112867_v21, %v112862_v34 (stack40)
        %v112872_v34 = vshll.u32 %v112867_v21, 26 (stack45)
        %v112873_v25 = vshrl.u32 %v112867_v21, 6 (stack46)
        %v111667_v31 = vsel /*vm=*/%vm111665_vm1, /*on_true_vy=*/%v111666_v43, /*on_false_vx=*/%v111664_v12 (stack76)
        %v112042_v22 = vmul.f32 2.0, %v120342_v61 (stack54)
        %v112485_v23 = vor.u32 %v112484_v10, %v112483_v29 (stack47)
        %v113282_v46 = vshrl.u32 %v113276_v20, 3 (stack46)
        %v111651_v52 = vsel /*vm=*/%vm111618_vm14, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v111670_v7 = vadd.f32 -3.0, %v111667_v31 (stack53)
        %v112874_v20 = vor.u32 %v112873_v25, %v112872_v34 (stack47)
        %v113696_v44 = vadd.s32 %v113693_v26, %v113688_v44 (stack40)
        %v111655_v60 = vsel /*vm=*/%vm111618_vm14, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v112046_v43 = vadd.f32 -0.99609375, %v112042_v22 (stack53)
        %v112486_v30 = vxor.u32 %v112485_v23, %v112481_v56 (stack48)
        %v113698_v55 = vshll.u32 %v113693_v26, 15 (stack45)
        %v154487_v24 = vsel /*vm=*/%vm111618_vm14, /*on_true_vy=*/%v154449_v24, /*on_false_vx=*/%v111670_v7 (stack44)
        %v112875_v32 = vxor.u32 %v112874_v20, %v112870_v54 (stack48)
        %v113283_v21 = vor.u32 %v113282_v46, %v113281_v50 (stack47)
        %v113699_v26 = vshrl.u32 %v113693_v26, 17 (stack46)
        %v111678_v50 = vmul.f32 %v154487_v24, %v111655_v60 (stack54)
        %v154490_v61 = vmax.f32 %v112046_v43, -0.99609375 (stack55)
        %v112489_v56 = vadd.s32 %v112486_v30, %v112481_v56 (stack40)
        %v112491_v29 = vshll.u32 %v112486_v30, 15 (stack45)
        %v112492_v10 = vshrl.u32 %v112486_v30, 17 (stack46)
        %v112878_v12 = vadd.s32 %v112875_v32, %v112870_v54 (stack40)
        %v112884_v54 = vshll.u32 %v112875_v32, 6 (stack45)
        %v112885_v34 = vshrl.u32 %v112875_v32, 26 (stack46)
        %v154495_v25 = vsel /*vm=*/%vm111618_vm14, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v154500_v31 = vsel /*vm=*/%vm111618_vm14, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v111682_v22 = vadd.f32 %v111678_v50, %v111651_v52 (stack53)
        %v112062_v23 = vxor.u32 2147483648, %v154490_v61 (stack56)
        %v111639_v46 = vsel /*vm=*/%vm111618_vm14, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v112493_v52 = vor.u32 %v112492_v10, %v112491_v29 (stack47)
        %v112886_v7 = vor.u32 %v112885_v34, %v112884_v54 (stack47)
        %v113284_v20 = vxor.u32 %v113283_v21, %v113279_v6 (stack48)
        %v111647_v60 = vsel /*vm=*/%vm111618_vm14, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v111686_v43 = vmul.f32 %v111682_v22, %v154487_v24 (stack54)
        %v112065_v30 = vmul.f32 %v112062_v23, %v154490_v61 (stack54)
        %v154513_v32 = vadd.s32 %v154457_v42, %v122657_v58 (stack40)
        %v112494_v21 = vxor.u32 %v112493_v52, %v112489_v56 (stack48)
        %v112887_v50 = vxor.u32 %v112886_v7, %v112878_v12 (stack48)
        %v113287_v6 = vadd.s32 %v113284_v20, %v113279_v6 (stack40)
        %v113700_v55 = vor.u32 %v113699_v26, %v113698_v55 (stack47)
        %v111643_v26 = vsel /*vm=*/%vm111618_vm14, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v111690_v29 = vadd.f32 %v111686_v43, %v111647_v60 (stack53)
        %v112067_v10 = vadd.f32 1.0, %v112065_v30 (stack57)
        %v114124_v54 = vadd.s32 1, %v154470_v53 (stack40)
        %v112497_v56 = vadd.s32 %v112494_v21, %v112489_v56 (stack40)
        %v112499_v34 = vshll.u32 %v112494_v21, 26 (stack45)
        %v112500_v22 = vshrl.u32 %v112494_v21, 6 (stack46)
        %v112890_v23 = vadd.s32 %v112887_v50, %v121569_v1 (stack40)
        %v111694_v52 = vmul.f32 %v111690_v29, %v154487_v24 (stack54)
        %121389 = vlog2.f32 %v112067_v10 (stack58)
        %v112882_v12 = vadd.s32 %v112878_v12, %v121574_v2 (stack40)
        %v113289_v7 = vshll.u32 %v113284_v20, 16 (stack45)
        %vm114110_vm3 = vcmp.lt.u32.totalorder %v154513_v32, %v154457_v42 (stack43)
        %v112501_v60 = vor.u32 %v112500_v22, %v112499_v34 (stack47)
        %v112894_v43 = vadd.s32 3, %v112890_v23 (stack40)
        %v113290_v20 = vshrl.u32 %v113284_v20, 16 (stack46)
        %v113701_v21 = vxor.u32 %v113700_v55, %v113696_v44 (stack48)
        %v111698_v50 = vadd.f32 %v111694_v52, %v111643_v26 (stack53)
        %v112070_v55 = vmul.f32 -0.5, %v112065_v30 (stack59)
        %v114128_v53 = vsel /*vm=*/%vm114115_vm2, /*on_true_vy=*/%v114124_v54, /*on_false_vx=*/%v154470_v53 (stack44)
        %v154530_v26 = vadd.s32 %v154513_v32, %v121569_v1 (stack40)
        %v112502_v29 = vxor.u32 %v112501_v60, %v112497_v56 (stack48)
        %v112898_v10 = vadd.s32 %v112894_v43, %v112882_v12 (stack40)
        %v112900_v54 = vshll.u32 %v112894_v43, 17 (stack45)
        %v112901_v34 = vshrl.u32 %v112894_v43, 15 (stack46)
        %v111702_v22 = vmul.f32 %v111698_v50, %v154487_v24 (stack54)
        %v112073_v23 = vand.u32 2147483647, %v112065_v30 (stack60)
        %v113291_v52 = vor.u32 %v113290_v20, %v113289_v7 (stack47)
        %v113704_v44 = vadd.s32 %v113701_v21, %v113696_v44 (stack40)
        %v112505_v56 = vadd.s32 %v112502_v29, %v112497_v56 (stack40)
        %v112511_v12 = vshll.u32 %v112502_v29, 6 (stack45)
        %v112512_v7 = vshrl.u32 %v112502_v29, 26 (stack46)
        %v112902_v60 = vor.u32 %v112901_v34, %v112900_v54 (stack47)
        %v111706_v46 = vadd.f32 %v111702_v22, %v111639_v46 (stack53)
        %v113292_v43 = vxor.u32 %v113291_v52, %v113287_v6 (stack48)
        %v113706_v20 = vshll.u32 %v113701_v21, 26 (stack45)
        %v113707_v21 = vshrl.u32 %v113701_v21, 6 (stack46)
        %v112071_v50 = vadd.f32 1.0, %v112070_v55 (stack61)
        %v112513_v55 = vor.u32 %v112512_v7, %v112511_v12 (stack47)
        %v112903_v29 = vxor.u32 %v112902_v60, %v112898_v10 (stack48)
        %v114132_v54 = vadd.s32 1, %v114128_v53 (stack40)
        %v111710_v34 = vmul.f32 %v111706_v46, %v154487_v24 (stack54)
        %v113295_v6 = vadd.s32 %v113292_v43, %v113287_v6 (stack40)
        %v113301_v22 = vshll.u32 %v113292_v43, 24 (stack45)
        %v113302_v52 = vshrl.u32 %v113292_v43, 8 (stack46)
        %v112514_v12 = vxor.u32 %v112513_v55, %v112505_v56 (stack48)
        %v112906_v10 = vadd.s32 %v112903_v29, %v112898_v10 (stack40)
        %v112908_v7 = vshll.u32 %v112903_v29, 29 (stack45)
        %v112909_v60 = vshrl.u32 %v112903_v29, 3 (stack46)
        %v111714_v31 = vadd.f32 %v111710_v34, %v154500_v31 (stack53)
        %vm154535_vm4 = vcmp.lt.f32.partialorder %v112073_v23, 0.0004427343 (stack62)
        %v113303_v46 = vor.u32 %v113302_v52, %v113301_v22 (stack47)
        %v113708_v43 = vor.u32 %v113707_v21, %v113706_v20 (stack47)
        %v112072_v30 = vmul.f32 %v112071_v50, %v112065_v30 (stack63)
        %v112517_v20 = vadd.s32 %v112514_v12, %v121574_v2 (stack40)
        %v112910_v21 = vor.u32 %v112909_v60, %v112908_v7 (stack47)
        %v114136_v42 = vsel /*vm=*/%vm114110_vm3, /*on_true_vy=*/%v114132_v54, /*on_false_vx=*/%v114128_v53 (stack44)
        %v111718_v32 = vmul.f32 %v111714_v31, %v154487_v24 (stack54)
        %v112509_v53 = vadd.s32 %v112505_v56, %v121564_v0 (stack40)
        %v113304_v56 = vxor.u32 %v113303_v46, %v113295_v6 (stack48)
        %v154545_v50 = vxor.u32 %v113708_v43, %v113704_v44 (stack48)
        %v121390_v55 = vpop.eup %121389 (stack64)
        %v112521_v29 = vadd.s32 5, %v112517_v20 (stack40)
        %v112911_v54 = vxor.u32 %v112910_v21, %v112906_v10 (stack48)
        %v154549_v34 = vadd.s32 %v157796_v41, %v157089_v17 (stack40)
        %v154553_v22 = vadd.s32 %v157799_v40, %v157090_v62 (stack40)
        %v111722_v25 = vadd.f32 %v111718_v32, %v154495_v25 (stack53)
        %v112069_v52 = vmul.f32 0.6931472, %v121390_v55 (stack65)
        %v113307_v12 = vadd.s32 %v113304_v56, %v121574_v2 (stack40)
        %v154558_v44 = vadd.s32 %v154545_v50, %v113704_v44 (stack40)
        %v112523_v7 = vxor.u32 %v112521_v29, %v112509_v53 (stack48)
        %v112914_v10 = vadd.s32 %v112911_v54, %v112906_v10 (stack40)
        %v112916_v60 = vshll.u32 %v112911_v54, 16 (stack45)
        %v112917_v31 = vshrl.u32 %v112911_v54, 16 (stack46)
        %v111726_v46 = vmul.f32 %v111722_v25, %v154487_v24 (stack54)
        %v112075_v23 = vsel /*vm=*/%vm154535_vm4, /*on_true_vy=*/%v112072_v30, /*on_false_vx=*/%v112069_v52 (stack66)
        %v113299_v6 = vadd.s32 %v113295_v6, %v121564_v0 (stack40)
        %v113311_v43 = vadd.s32 2, %v113307_v12 (stack40)
        %v154564_v30 = vxor.u32 2147483648, %v112075_v23 (stack56)
        %v112918_v20 = vor.u32 %v112917_v31, %v112916_v60 (stack47)
        %v114151_v21 = vshll.u32 %v154530_v26, 13 (stack45)
        %v114152_v32 = vshrl.u32 %v154530_v26, 19 (stack46)
        %vm154570_vm5 = vcmp.eq.f32.partialorder %v111591_v45, 1.0 (stack68)
        %v111599_v53 = vmul.f32 inf, %v154359_v27 (stack54)
        %v111730_v8 = vadd.f32 %v111726_v46, %v154446_v8 (stack53)
        %v113315_v56 = vadd.s32 %v113311_v43, %v113299_v6 (stack40)
        %v111623_v9 = vsel /*vm=*/%vm111618_vm14, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %vm112079_vm6 = vcmp.lt.f32.partialorder %v154564_v30, 5.0 (stack68)
        %121391 = vrsqrt.f32 %v154564_v30 (stack67)
        %v112524_v55 = vand.u32.u8 255, %v112523_v7 (stack49)
        %v111734_v24 = vmul.f32 %v111730_v8, %v154487_v24 (stack54)
        %v112052_v29 = vand.u32 2147483647, %v154490_v61 (stack77)
        %v113317_v54 = vshll.u32 %v113311_v43, 13 (stack45)
        %v113318_v25 = vshrl.u32 %v113311_v43, 19 (stack46)
        %v112919_v52 = vxor.u32 %v112918_v20, %v112914_v10 (stack48)
        %v154585_v12 = vadd.s32 %v154558_v44, %v121569_v1 (stack40)
        %v114141_v42 = vadd.s32 %v114136_v42, %v121574_v2 (stack40)
        %v114153_v7 = vor.u32 %v114152_v32, %v114151_v21 (stack47)
        %v111738_v60 = vadd.f32 %v111734_v24, %v111623_v9 (stack53)
        %v154591_v31 = vsel /*vm=*/%vm112079_vm6, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v154594_v46 = vadd.f32 -2.5, %v154564_v30 (stack53)
        %v113718_v23 = vshll.u32 %v154545_v50, 6 (stack45)
        %v154600_v6 = vsel /*vm=*/%vm112079_vm6, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v154605_v43 = vsel /*vm=*/%vm112079_vm6, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v112525_v20 = vand.u32 65535, %v112524_v55 (stack50)
        %v112922_v10 = vadd.s32 %v112919_v52, %v112914_v10 (stack40)
        %v111742_v27 = vmul.f32 %v111738_v60, %v154359_v27 (stack54)
        %v112928_v21 = vshll.u32 %v112919_v52, 24 (stack45)
        %v112929_v32 = vshrl.u32 %v112919_v52, 8 (stack46)
        %v113319_v8 = vor.u32 %v113318_v25, %v113317_v54 (stack47)
        %v154611_v9 = vsel /*vm=*/%vm112079_vm6, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v112526_v55 = vshrl.u32 %v112525_v20, 1 (stack51)
        %v113719_v50 = vshrl.u32 %v154545_v50, 26 (stack46)
        %v114149_v26 = vadd.s32 %v154530_v26, %v114141_v42 (stack40)
        %v111746_v45 = vsel /*vm=*/%vm154570_vm5, /*on_true_vy=*/%v111599_v53, /*on_false_vx=*/%v111742_v27 (stack44)
        %v154620_v53 = vsel /*vm=*/%vm112079_vm6, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %vm112124_vm7 = vcmp.eq.f32.partialorder %v154564_v30, inf (stack70)
        %v112930_v24 = vor.u32 %v112929_v32, %v112928_v21 (stack47)
        %v113320_v54 = vxor.u32 %v113319_v8, %v113315_v56 (stack48)
        %v111750_v25 = vmul.f32 1.4140625, %v111746_v45 (stack54)
        %vm112126_vm8 = vcmp.eq.f32.partialorder %v154564_v30, 0.0 (stack71)
        %v112527_v52 = vor.u32 16256, %v112526_v55 (stack47)
        %v113720_v42 = vor.u32 %v113719_v50, %v113718_v23 (stack47)
        %v114154_v7 = vxor.u32 %v114153_v7, %v114149_v26 (stack48)
        %v112931_v60 = vxor.u32 %v112930_v24, %v112922_v10 (stack48)
        %v113323_v56 = vadd.s32 %v113320_v54, %v113315_v56 (stack40)
        %v113325_v23 = vshll.u32 %v113320_v54, 15 (stack45)
        %v113326_v20 = vshrl.u32 %v113320_v54, 17 (stack46)
        %v111753_v27 = vpack.c.bf16 %v157387_v11, %v111750_v25 (stack81)
        %v112528_v21 = vand.u32.u16 65535, %v112527_v52 (stack52)
        %v113721_v44 = vxor.u32 %v113720_v42, %v154558_v44 (stack48)
        %v114157_v32 = vadd.s32 %v114154_v7, %v114149_v26 (stack40)
        %v112934_v8 = vadd.s32 %v112931_v60, %v121564_v0 (stack40)
        %v113327_v55 = vor.u32 %v113326_v20, %v113325_v23 (stack47)
        %v114159_v50 = vshll.u32 %v114154_v7, 15 (stack45)
        %v114160_v26 = vshrl.u32 %v114154_v7, 17 (stack46)
        %120341 = vst [vmem:[%s123356_s30 + $0x374] sm:$0xf] /*vst_source=*/%v111753_v27 (stack83)
        %v112127_v45 = vand.u32 2147483648, %v154564_v30 (stack72)
        %v120348_v24 = vadd.low.f32.bf16 -1.0, %v112528_v21 (stack53)
        %v113724_v54 = vadd.s32 %v113721_v44, %v121564_v0 (stack40)
        %vm114576_vm9 = vcmp.lt.u32.totalorder %v154549_v34, %v157089_v17 (stack43)
        %v121392_v25 = vpop.eup %121391 (stack73)
        %v112926_v10 = vadd.s32 %v112922_v10, %v121569_v1 (stack40)
        %v112938_v52 = vadd.s32 4, %v112934_v8 (stack40)
        %v113328_v42 = vxor.u32 %v113327_v55, %v113323_v56 (stack48)
        %v154635_v7 = vadd.s32 %v154549_v34, %v122657_v58 (stack40)
        %v112123_v60 = vmul.f32 %v121392_v25, %v154564_v30 (stack74)
        %v112537_v23 = vmul.f32 2.0, %v120348_v24 (stack54)
        %v113728_v20 = vadd.s32 1, %v113724_v54 (stack40)
        %v114161_v27 = vor.u32 %v114160_v26, %v114159_v50 (stack47)
        %v112942_v21 = vadd.s32 %v112938_v52, %v112926_v10 (stack40)
        %v112944_v44 = vshll.u32 %v112938_v52, 13 (stack45)
        %v112945_v8 = vshrl.u32 %v112938_v52, 19 (stack46)
        %v113331_v56 = vadd.s32 %v113328_v42, %v113323_v56 (stack40)
        %v112125_v55 = vsel /*vm=*/%vm112124_vm7, /*on_true_vy=*/%v154564_v30, /*on_false_vx=*/%v112123_v60 (stack75)
        %v112541_v50 = vadd.f32 -0.99609375, %v112537_v23 (stack53)
        %v113333_v26 = vshll.u32 %v113328_v42, 26 (stack45)
        %v113334_v24 = vshrl.u32 %v113328_v42, 6 (stack46)
        %v112128_v45 = vsel /*vm=*/%vm112126_vm8, /*on_true_vy=*/%v112127_v45, /*on_false_vx=*/%v112125_v55 (stack76)
        %v112946_v54 = vor.u32 %v112945_v8, %v112944_v44 (stack47)
        %v113732_v12 = vadd.s32 %v113728_v20, %v154585_v12 (stack40)
        %v114585_v25 = vadd.s32 1, %v154553_v22 (stack40)
        %v112116_v10 = vsel /*vm=*/%vm112079_vm6, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v112131_v52 = vadd.f32 -3.0, %v112128_v45 (stack53)
        %v154648_v42 = vmax.f32 %v112541_v50, -0.99609375 (stack55)
        %v113335_v60 = vor.u32 %v113334_v24, %v113333_v26 (stack47)
        %v112947_v23 = vxor.u32 %v112946_v54, %v112942_v21 (stack48)
        %v114162_v27 = vxor.u32 %v114161_v27, %v114157_v32 (stack48)
        %v114589_v22 = vsel /*vm=*/%vm114576_vm9, /*on_true_vy=*/%v114585_v25, /*on_false_vx=*/%v154553_v22 (stack44)
        %v154656_v44 = vadd.s32 %v154635_v7, %v121569_v1 (stack40)
        %v154661_v46 = vsel /*vm=*/%vm112079_vm6, /*on_true_vy=*/%v154594_v46, /*on_false_vx=*/%v112131_v52 (stack44)
        %v112557_v8 = vxor.u32 2147483648, %v154648_v42 (stack56)
        %v113734_v55 = vshll.u32 %v113728_v20, 17 (stack45)
        %v113735_v20 = vshrl.u32 %v113728_v20, 15 (stack46)
        %v112139_v50 = vmul.f32 %v154661_v46, %v112116_v10 (stack54)
        %v112950_v21 = vadd.s32 %v112947_v23, %v112942_v21 (stack40)
        %v112952_v26 = vshll.u32 %v112947_v23, 15 (stack45)
        %v112953_v24 = vshrl.u32 %v112947_v23, 17 (stack46)
        %v112112_v45 = vsel /*vm=*/%vm112079_vm6, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v112560_v54 = vmul.f32 %v112557_v8, %v154648_v42 (stack54)
        %v113336_v25 = vxor.u32 %v113335_v60, %v113331_v56 (stack48)
        %vm114571_vm10 = vcmp.lt.u32.totalorder %v154635_v7, %v154549_v34 (stack43)
        %v112143_v10 = vadd.f32 %v112139_v50, %v112112_v45 (stack53)
        %v112954_v52 = vor.u32 %v112953_v24, %v112952_v26 (stack47)
        %v114165_v32 = vadd.s32 %v114162_v27, %v114157_v32 (stack40)
        %v114612_v60 = vshll.u32 %v154656_v44, 13 (stack45)
        %v112562_v23 = vadd.f32 1.0, %v112560_v54 (stack57)
        %v112565_v8 = vmul.f32 -0.5, %v112560_v54 (stack59)
        %v113339_v56 = vadd.s32 %v113336_v25, %v113331_v56 (stack40)
        %v113736_v55 = vor.u32 %v113735_v20, %v113734_v55 (stack47)
        %v112147_v20 = vmul.f32 %v112143_v10, %v154661_v46 (stack54)
        %v112955_v50 = vxor.u32 %v112954_v52, %v112950_v21 (stack48)
        %v113345_v26 = vshll.u32 %v113336_v25, 6 (stack45)
        %v113346_v24 = vshrl.u32 %v113336_v25, 26 (stack46)
        %121393 = vlog2.f32 %v112562_v23 (stack58)
        %v112566_v45 = vadd.f32 1.0, %v112565_v8 (stack61)
        %v112568_v25 = vand.u32 2147483647, %v112560_v54 (stack60)
        %v114167_v10 = vshll.u32 %v114162_v27, 26 (stack45)
        %v112151_v53 = vadd.f32 %v112147_v20, %v154620_v53 (stack53)
        %v112958_v21 = vadd.s32 %v112955_v50, %v112950_v21 (stack40)
        %v112960_v52 = vshll.u32 %v112955_v50, 26 (stack45)
        %v112961_v23 = vshrl.u32 %v112955_v50, 6 (stack46)
        %v113343_v8 = vadd.s32 %v113339_v56, %v121574_v2 (stack40)
        %v113347_v20 = vor.u32 %v113346_v24, %v113345_v26 (stack47)
        %v113737_v55 = vxor.u32 %v113736_v55, %v113732_v12 (stack48)
        %v114168_v27 = vshrl.u32 %v114162_v27, 6 (stack46)
        %v112155_v50 = vmul.f32 %v112151_v53, %v154661_v46 (stack54)
        %v112962_v26 = vor.u32 %v112961_v23, %v112960_v52 (stack47)
        %v114593_v24 = vadd.s32 1, %v114589_v22 (stack40)
        %v114613_v53 = vshrl.u32 %v154656_v44, 19 (stack46)
        %v113348_v56 = vxor.u32 %v113347_v20, %v113339_v56 (stack48)
        %v113740_v12 = vadd.s32 %v113737_v55, %v113732_v12 (stack40)
        %v113742_v52 = vshll.u32 %v113737_v55, 29 (stack45)
        %v113743_v23 = vshrl.u32 %v113737_v55, 3 (stack46)
        %v112159_v9 = vadd.f32 %v112155_v50, %v154611_v9 (stack53)
        %v112963_v20 = vxor.u32 %v112962_v26, %v112958_v21 (stack48)
        %v114169_v10 = vor.u32 %v114168_v27, %v114167_v10 (stack47)
        %v114597_v34 = vsel /*vm=*/%vm114571_vm10, /*on_true_vy=*/%v114593_v24, /*on_false_vx=*/%v114589_v22 (stack44)
        %v112567_v7 = vmul.f32 %v112566_v45, %v112560_v54 (stack63)
        %v113351_v22 = vadd.s32 %v113348_v56, %v121569_v1 (stack40)
        %v113744_v54 = vor.u32 %v113743_v23, %v113742_v52 (stack47)
        %v114602_v45 = vadd.s32 %v114597_v34, %v121574_v2 (stack40)
        %v112163_v55 = vmul.f32 %v112159_v9, %v154661_v46 (stack54)
        %vm154684_vm11 = vcmp.lt.f32.partialorder %v112568_v25, 0.0004427343 (stack62)
        %v112966_v21 = vadd.s32 %v112963_v20, %v112958_v21 (stack40)
        %v112972_v27 = vshll.u32 %v112963_v20, 6 (stack45)
        %v112973_v50 = vshrl.u32 %v112963_v20, 26 (stack46)
        %v113355_v26 = vadd.s32 3, %v113351_v22 (stack40)
        %v113745_v24 = vxor.u32 %v113744_v54, %v113740_v12 (stack48)
        %v114170_v56 = vxor.u32 %v114169_v10, %v114165_v32 (stack48)
        %v114610_v44 = vadd.s32 %v154656_v44, %v114602_v45 (stack40)
        %v112167_v43 = vadd.f32 %v112163_v55, %v154605_v43 (stack53)
        %v112974_v52 = vor.u32 %v112973_v50, %v112972_v27 (stack47)
        %v114614_v60 = vor.u32 %v114613_v53, %v114612_v60 (stack47)
        %v154692_v53 = vadd.s32 %v157796_v41, %v157091_v37 (stack40)
        %v113359_v8 = vadd.s32 %v113355_v26, %v113343_v8 (stack40)
        %v113361_v23 = vshll.u32 %v113355_v26, 17 (stack45)
        %v113362_v9 = vshrl.u32 %v113355_v26, 15 (stack46)
        %v113748_v12 = vadd.s32 %v113745_v24, %v113740_v12 (stack40)
        %v112171_v20 = vmul.f32 %v112167_v43, %v154661_v46 (stack54)
        %v112975_v10 = vxor.u32 %v112974_v52, %v112966_v21 (stack48)
        %v113750_v34 = vshll.u32 %v113745_v24, 16 (stack45)
        %v113751_v22 = vshrl.u32 %v113745_v24, 16 (stack46)
        %v113363_v54 = vor.u32 %v113362_v9, %v113361_v23 (stack47)
        %v114173_v32 = vadd.s32 %v114170_v56, %v114165_v32 (stack40)
        %v114179_v45 = vshll.u32 %v114170_v56, 6 (stack45)
        %v114180_v55 = vshrl.u32 %v114170_v56, 26 (stack46)
        %v121394_v27 = vpop.eup %121393 (stack64)
        %v112175_v6 = vadd.f32 %v112171_v20, %v154600_v6 (stack53)
        %v112978_v50 = vadd.s32 %v112975_v10, %v121574_v2 (stack40)
        %v113752_v26 = vor.u32 %v113751_v22, %v113750_v34 (stack47)
        %v114615_v24 = vxor.u32 %v114614_v60, %v114610_v44 (stack48)
        %v112564_v56 = vmul.f32 0.6931472, %v121394_v27 (stack65)
        %v112970_v21 = vadd.s32 %v112966_v21, %v121564_v0 (stack40)
        %v113364_v43 = vxor.u32 %v113363_v54, %v113359_v8 (stack48)
        %v114181_v52 = vor.u32 %v114180_v55, %v114179_v45 (stack47)
        %v112179_v60 = vmul.f32 %v112175_v6, %v154661_v46 (stack54)
        %v112982_v23 = vadd.s32 5, %v112978_v50 (stack40)
        %v113753_v9 = vxor.u32 %v113752_v26, %v113748_v12 (stack48)
        %v154699_v44 = vadd.s32 %v114615_v24, %v114610_v44 (stack40)
        %v112570_v7 = vsel /*vm=*/%vm154684_vm11, /*on_true_vy=*/%v112567_v7, /*on_false_vx=*/%v112564_v56 (stack66)
        %v113367_v25 = vadd.s32 %v113364_v43, %v113359_v8 (stack40)
        %v113369_v8 = vshll.u32 %v113364_v43, 29 (stack45)
        %v113370_v20 = vshrl.u32 %v113364_v43, 3 (stack46)
        %v112183_v31 = vadd.f32 %v112179_v60, %v154591_v31 (stack53)
        %v154704_v10 = vxor.u32 2147483648, %v112570_v7 (stack56)
        %v112984_v34 = vxor.u32 %v112982_v23, %v112970_v21 (stack48)
        %v113756_v12 = vadd.s32 %v113753_v9, %v113748_v12 (stack40)
        %v113371_v22 = vor.u32 %v113370_v20, %v113369_v8 (stack47)
        %v114182_v54 = vxor.u32 %v114181_v52, %v114173_v32 (stack48)
        %v112187_v45 = vmul.f32 %v112183_v31, %v154661_v46 (stack54)
        %121395 = vrsqrt.f32 %v154704_v10 (stack67)
        %v112060_v55 = vmul.f32 inf, %v154490_v61 (stack54)
        %v112088_v27 = vsel /*vm=*/%vm112079_vm6, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %vm112574_vm12 = vcmp.lt.f32.partialorder %v154704_v10, 5.0 (stack68)
        %v113372_v6 = vxor.u32 %v113371_v22, %v113367_v25 (stack48)
        %vm154715_vm13 = vcmp.eq.f32.partialorder %v112052_v29, 1.0 (stack68)
        %v112191_v50 = vadd.f32 %v112187_v45, %v112088_v27 (stack53)
        %v113762_v26 = vshll.u32 %v113753_v9, 24 (stack45)
        %v113763_v56 = vshrl.u32 %v113753_v9, 8 (stack46)
        %v112084_v30 = vsel /*vm=*/%vm112079_vm6, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v112547_v21 = vand.u32 2147483647, %v154648_v42 (stack77)
        %v113375_v43 = vadd.s32 %v113372_v6, %v113367_v25 (stack40)
        %v114177_v32 = vadd.s32 %v114173_v32, %v121569_v1 (stack40)
        %v112195_v46 = vmul.f32 %v112191_v50, %v154661_v46 (stack54)
        %v154728_v52 = vsel /*vm=*/%vm112574_vm12, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v154733_v60 = vsel /*vm=*/%vm112574_vm12, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v154736_v23 = vadd.f32 -2.5, %v154704_v10 (stack53)
        %v154741_v9 = vsel /*vm=*/%vm112574_vm12, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v112985_v7 = vand.u32.u8 255, %v112984_v34 (stack49)
        %v113377_v25 = vshll.u32 %v113372_v6, 16 (stack45)
        %v113378_v8 = vshrl.u32 %v113372_v6, 16 (stack46)
        %v112199_v20 = vadd.f32 %v112195_v46, %v112084_v30 (stack53)
        %v113764_v31 = vor.u32 %v113763_v56, %v113762_v26 (stack47)
        %v114185_v34 = vadd.s32 %v114182_v54, %v121564_v0 (stack40)
        %v114620_v22 = vshll.u32 %v114615_v24, 15 (stack45)
        %vm112619_vm14 = vcmp.eq.f32.partialorder %v154704_v10, inf (stack70)
        %v112622_v54 = vand.u32 2147483648, %v154704_v10 (stack72)
        %v112986_v45 = vand.u32 65535, %v112985_v7 (stack50)
        %v113379_v27 = vor.u32 %v113378_v8, %v113377_v25 (stack47)
        %v114621_v24 = vshrl.u32 %v114615_v24, 17 (stack46)
        %v112203_v61 = vmul.f32 %v112199_v20, %v154490_v61 (stack54)
        %vm112621_vm15 = vcmp.eq.f32.partialorder %v154704_v10, 0.0 (stack71)
        %v113765_v6 = vxor.u32 %v113764_v31, %v113756_v12 (stack48)
        %v114189_v50 = vadd.s32 1, %v114185_v34 (stack40)
        %vm115037_vm0 = vcmp.lt.u32.totalorder %v154692_v53, %v157091_v37 (stack43)
        %v112987_v26 = vshrl.u32 %v112986_v45, 1 (stack51)
        %v113380_v56 = vxor.u32 %v113379_v27, %v113375_v43 (stack48)
        %v113760_v12 = vadd.s32 %v113756_v12, %v121564_v0 (stack40)
        %v114622_v30 = vor.u32 %v114621_v24, %v114620_v22 (stack47)
        %v112207_v55 = vsel /*vm=*/%vm154715_vm13, /*on_true_vy=*/%v112060_v55, /*on_false_vx=*/%v112203_v61 (stack44)
        %v113768_v29 = vadd.s32 %v113765_v6, %v121574_v2 (stack40)
        %v114193_v32 = vadd.s32 %v114189_v50, %v114177_v32 (stack40)
        %v114195_v46 = vshll.u32 %v114189_v50, 17 (stack45)
        %v112211_v7 = vmul.f32 1.4140625, %v112207_v55 (stack54)
        %v112988_v25 = vor.u32 16256, %v112987_v26 (stack47)
        %v113383_v43 = vadd.s32 %v113380_v56, %v113375_v43 (stack40)
        %v113389_v8 = vshll.u32 %v113380_v56, 24 (stack45)
        %v113390_v20 = vshrl.u32 %v113380_v56, 8 (stack46)
        %v113772_v31 = vadd.s32 2, %v113768_v29 (stack40)
        %v114196_v34 = vshrl.u32 %v114189_v50, 15 (stack46)
        %v114623_v22 = vxor.u32 %v114622_v30, %v154699_v44 (stack48)
        %v121396_v45 = vpop.eup %121395 (stack73)
        %v112214_v27 = vpack.c.bf16 %v157387_v11, %v112211_v7 (stack81)
        %v112989_v24 = vand.u32.u16 65535, %v112988_v25 (stack52)
        %v154758_v61 = vadd.s32 %v154692_v53, %v122657_v58 (stack40)
        %v154762_v6 = vadd.s32 %v157799_v40, %v157094_v36 (stack40)
        %v112618_v50 = vmul.f32 %v121396_v45, %v154704_v10 (stack74)
        %v113391_v26 = vor.u32 %v113390_v20, %v113389_v8 (stack47)
        %v113776_v56 = vadd.s32 %v113772_v31, %v113760_v12 (stack40)
        %v113778_v12 = vshll.u32 %v113772_v31, 13 (stack45)
        %120343 = vst [vmem:[%s123356_s30 + $0x3f4] sm:$0xf] /*vst_source=*/%v112214_v27 (stack83)
        %v120350_v30 = vadd.low.f32.bf16 -1.0, %v112989_v24 (stack53)
        %v113779_v55 = vshrl.u32 %v113772_v31, 19 (stack46)
        %v114197_v29 = vor.u32 %v114196_v34, %v114195_v46 (stack47)
        %v114626_v44 = vadd.s32 %v114623_v22, %v154699_v44 (stack40)
        %v112620_v46 = vsel /*vm=*/%vm112619_vm14, /*on_true_vy=*/%v154704_v10, /*on_false_vx=*/%v112618_v50 (stack75)
        %v113392_v7 = vxor.u32 %v113391_v26, %v113383_v43 (stack48)
        %v114628_v25 = vshll.u32 %v114623_v22, 26 (stack45)
        %v114629_v8 = vshrl.u32 %v114623_v22, 6 (stack46)
        %v112623_v54 = vsel /*vm=*/%vm112621_vm15, /*on_true_vy=*/%v112622_v54, /*on_false_vx=*/%v112620_v46 (stack76)
        %v112998_v20 = vmul.f32 2.0, %v120350_v30 (stack54)
        %v113780_v31 = vor.u32 %v113779_v55, %v113778_v12 (stack47)
        %v114198_v34 = vxor.u32 %v114197_v29, %v114193_v32 (stack48)
        %v112626_v22 = vadd.f32 -3.0, %v112623_v54 (stack53)
        %v113387_v43 = vadd.s32 %v113383_v43, %v121569_v1 (stack40)
        %v113395_v45 = vadd.s32 %v113392_v7, %v121564_v0 (stack40)
        %v114630_v27 = vor.u32 %v114629_v8, %v114628_v25 (stack47)
        %v113002_v24 = vadd.f32 -0.99609375, %v112998_v20 (stack53)
        %v113781_v50 = vxor.u32 %v113780_v31, %v113776_v56 (stack48)
        %v114201_v32 = vadd.s32 %v114198_v34, %v114193_v32 (stack40)
        %v114203_v26 = vshll.u32 %v114198_v34, 29 (stack45)
        %v154777_v23 = vsel /*vm=*/%vm112574_vm12, /*on_true_vy=*/%v154736_v23, /*on_false_vx=*/%v112626_v22 (stack44)
        %v113399_v12 = vadd.s32 4, %v113395_v45 (stack40)
        %v114204_v30 = vshrl.u32 %v114198_v34, 3 (stack46)
        %v114631_v55 = vxor.u32 %v114630_v27, %v114626_v44 (stack48)
        %v112634_v9 = vmul.f32 %v154777_v23, %v154741_v9 (stack54)
        %v154781_v29 = vmax.f32 %v113002_v24, -0.99609375 (stack55)
        %v113784_v56 = vadd.s32 %v113781_v50, %v113776_v56 (stack40)
        %v113786_v46 = vshll.u32 %v113781_v50, 15 (stack45)
        %v113403_v7 = vadd.s32 %v113399_v12, %v113387_v43 (stack40)
        %v113405_v25 = vshll.u32 %v113399_v12, 13 (stack45)
        %v113406_v8 = vshrl.u32 %v113399_v12, 19 (stack46)
        %v113787_v54 = vshrl.u32 %v113781_v50, 17 (stack46)
        %v154786_v20 = vsel /*vm=*/%vm112574_vm12, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v112595_v31 = vsel /*vm=*/%vm112574_vm12, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v112638_v60 = vadd.f32 %v112634_v9, %v154733_v60 (stack53)
        %v113018_v34 = vxor.u32 2147483648, %v154781_v29 (stack56)
        %v113407_v22 = vor.u32 %v113406_v8, %v113405_v25 (stack47)
        %v113788_v43 = vor.u32 %v113787_v54, %v113786_v46 (stack47)
        %v114205_v45 = vor.u32 %v114204_v30, %v114203_v26 (stack47)
        %v154793_v44 = vadd.s32 %v114631_v55, %v114626_v44 (stack40)
        %v112599_v27 = vsel /*vm=*/%vm112574_vm12, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v112603_v24 = vsel /*vm=*/%vm112574_vm12, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v112642_v50 = vmul.f32 %v112638_v60, %v154777_v23 (stack54)
        %v154803_v26 = vmul.f32 %v113018_v34, %v154781_v29 (stack54)
        %v113408_v12 = vxor.u32 %v113407_v22, %v113403_v7 (stack48)
        %v113789_v30 = vxor.u32 %v113788_v43, %v113784_v56 (stack48)
        %v114206_v9 = vxor.u32 %v114205_v45, %v114201_v32 (stack48)
        %vm115032_vm1 = vcmp.lt.u32.totalorder %v154758_v61, %v154692_v53 (stack43)
        %v112646_v46 = vadd.f32 %v112642_v50, %v112603_v24 (stack53)
        %v113023_v25 = vadd.f32 1.0, %v154803_v26 (stack57)
        %v114640_v8 = vshll.u32 %v114631_v55, 6 (stack45)
        %v115046_v54 = vadd.s32 1, %v154762_v6 (stack40)
        %v113411_v7 = vadd.s32 %v113408_v12, %v113403_v7 (stack40)
        %v113413_v60 = vshll.u32 %v113408_v12, 15 (stack45)
        %v113414_v34 = vshrl.u32 %v113408_v12, 17 (stack46)
        %v113792_v56 = vadd.s32 %v113789_v30, %v113784_v56 (stack40)
        %v112650_v22 = vmul.f32 %v112646_v46, %v154777_v23 (stack54)
        %121397 = vlog2.f32 %v113023_v25 (stack58)
        %v113026_v43 = vmul.f32 -0.5, %v154803_v26 (stack59)
        %v154813_v45 = vadd.s32 %v154793_v44, %v121569_v1 (stack40)
        %v113415_v24 = vor.u32 %v113414_v34, %v113413_v60 (stack47)
        %v113794_v50 = vshll.u32 %v113789_v30, 26 (stack45)
        %v113795_v12 = vshrl.u32 %v113789_v30, 6 (stack46)
        %v114209_v32 = vadd.s32 %v114206_v9, %v114201_v32 (stack40)
        %v112654_v27 = vadd.f32 %v112650_v22, %v112599_v27 (stack53)
        %v113029_v30 = vand.u32 2147483647, %v154803_v26 (stack60)
        %v114211_v46 = vshll.u32 %v114206_v9, 16 (stack45)
        %v114212_v9 = vshrl.u32 %v114206_v9, 16 (stack46)
        %v113416_v25 = vxor.u32 %v113415_v24, %v113411_v7 (stack48)
        %v113796_v60 = vor.u32 %v113795_v12, %v113794_v50 (stack47)
        %v114641_v55 = vshrl.u32 %v114631_v55, 26 (stack46)
        %v115050_v6 = vsel /*vm=*/%vm115037_vm0, /*on_true_vy=*/%v115046_v54, /*on_false_vx=*/%v154762_v6 (stack44)
        %v112658_v54 = vmul.f32 %v112654_v27, %v154777_v23 (stack54)
        %v113027_v34 = vadd.f32 1.0, %v113026_v43 (stack61)
        %v114213_v22 = vor.u32 %v114212_v9, %v114211_v46 (stack47)
        %v115054_v43 = vadd.s32 1, %v115050_v6 (stack40)
        %v113419_v7 = vadd.s32 %v113416_v25, %v113411_v7 (stack40)
        %v113421_v24 = vshll.u32 %v113416_v25, 26 (stack45)
        %v113422_v50 = vshrl.u32 %v113416_v25, 6 (stack46)
        %v113797_v12 = vxor.u32 %v113796_v60, %v113792_v56 (stack48)
        %v112662_v31 = vadd.f32 %v112658_v54, %v112595_v31 (stack53)
        %v114214_v27 = vxor.u32 %v114213_v22, %v114209_v32 (stack48)
        %v114642_v8 = vor.u32 %v114641_v55, %v114640_v8 (stack47)
        %v115058_v53 = vsel /*vm=*/%vm115032_vm1, /*on_true_vy=*/%v115054_v43, /*on_false_vx=*/%v115050_v6 (stack44)
        %v113423_v46 = vor.u32 %v113422_v50, %v113421_v24 (stack47)
        %v113800_v56 = vadd.s32 %v113797_v12, %v113792_v56 (stack40)
        %v113806_v9 = vshll.u32 %v113797_v12, 6 (stack45)
        %v113807_v25 = vshrl.u32 %v113797_v12, 26 (stack46)
        %v112666_v60 = vmul.f32 %v112662_v31, %v154777_v23 (stack54)
        %v114217_v32 = vadd.s32 %v114214_v27, %v114209_v32 (stack40)
        %v114223_v55 = vshll.u32 %v114214_v27, 24 (stack45)
        %v114224_v6 = vshrl.u32 %v114214_v27, 8 (stack46)
        %vm154825_vm2 = vcmp.lt.f32.partialorder %v113029_v30, 0.0004427343 (stack62)
        %v113424_v54 = vxor.u32 %v113423_v46, %v113419_v7 (stack48)
        %v113808_v22 = vor.u32 %v113807_v25, %v113806_v9 (stack47)
        %v114643_v44 = vxor.u32 %v114642_v8, %v154793_v44 (stack48)
        %v112670_v20 = vadd.f32 %v112666_v60, %v154786_v20 (stack53)
        %v114225_v43 = vor.u32 %v114224_v6, %v114223_v55 (stack47)
        %v115063_v24 = vadd.s32 %v115058_v53, %v121574_v2 (stack40)
        %v154834_v61 = vadd.s32 %v154758_v61, %v121569_v1 (stack40)
        %v113427_v7 = vadd.s32 %v113424_v54, %v113419_v7 (stack40)
        %v113433_v50 = vshll.u32 %v113424_v54, 6 (stack45)
        %v113434_v12 = vshrl.u32 %v113424_v54, 26 (stack46)
        %v113809_v31 = vxor.u32 %v113808_v22, %v113800_v56 (stack48)
        %v112674_v27 = vmul.f32 %v112670_v20, %v154777_v23 (stack54)
        %v114226_v8 = vxor.u32 %v114225_v43, %v114217_v32 (stack48)
        %v114646_v53 = vadd.s32 %v114643_v44, %v121564_v0 (stack40)
        %v154839_v46 = vadd.s32 %v154834_v61, %v115063_v24 (stack40)
        %v121398_v9 = vpop.eup %121397 (stack64)
        %v113028_v26 = vmul.f32 %v113027_v34, %v154803_v26 (stack63)
        %v113435_v34 = vor.u32 %v113434_v12, %v113433_v50 (stack47)
        %v113804_v56 = vadd.s32 %v113800_v56, %v121574_v2 (stack40)
        %v113812_v25 = vadd.s32 %v113809_v31, %v121569_v1 (stack40)
        %v112678_v52 = vadd.f32 %v112674_v27, %v154728_v52 (stack53)
        %v113025_v60 = vmul.f32 0.6931472, %v121398_v9 (stack65)
        %v114229_v55 = vadd.s32 %v114226_v8, %v121574_v2 (stack40)
        %v114650_v6 = vadd.s32 1, %v114646_v53 (stack40)
        %v113436_v54 = vxor.u32 %v113435_v34, %v113427_v7 (stack48)
        %v113816_v22 = vadd.s32 3, %v113812_v25 (stack40)
        %v114221_v32 = vadd.s32 %v114217_v32, %v121564_v0 (stack40)
        %v154849_v41 = vadd.s32 %v157796_v41, %v157095_v13 (stack40)
        %v112682_v44 = vmul.f32 %v112678_v52, %v154777_v23 (stack54)
        %v113031_v30 = vsel /*vm=*/%vm154825_vm2, /*on_true_vy=*/%v113028_v26, /*on_false_vx=*/%v113025_v60 (stack66)
        %v114233_v20 = vadd.s32 2, %v114229_v55 (stack40)
        %v114654_v45 = vadd.s32 %v114650_v6, %v154813_v45 (stack40)
        %v112583_v43 = vsel /*vm=*/%vm112574_vm12, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v154858_v24 = vxor.u32 2147483648, %v113031_v30 (stack56)
        %v113820_v50 = vadd.s32 %v113816_v22, %v113804_v56 (stack40)
        %v113822_v12 = vshll.u32 %v113816_v22, 17 (stack45)
        %v112686_v31 = vadd.f32 %v112682_v44, %v112583_v43 (stack53)
        %v113823_v27 = vshrl.u32 %v113816_v22, 15 (stack46)
        %v114237_v8 = vadd.s32 %v114233_v20, %v114221_v32 (stack40)
        %v112555_v53 = vmul.f32 inf, %v154648_v42 (stack54)
        %vm113035_vm3 = vcmp.lt.f32.partialorder %v154858_v24, 5.0 (stack68)
        %121399 = vrsqrt.f32 %v154858_v24 (stack67)
        %v113439_v9 = vadd.s32 %v113436_v54, %v121574_v2 (stack40)
        %vm154866_vm4 = vcmp.eq.f32.partialorder %v112547_v21, 1.0 (stack68)
        %v112579_v10 = vsel /*vm=*/%vm112574_vm12, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v112690_v23 = vmul.f32 %v112686_v31, %v154777_v23 (stack54)
        %v113431_v7 = vadd.s32 %v113427_v7, %v121564_v0 (stack40)
        %v113824_v26 = vor.u32 %v113823_v27, %v113822_v12 (stack47)
        %v114239_v34 = vshll.u32 %v114233_v20, 13 (stack45)
        %v115073_v56 = vshll.u32 %v154834_v61, 13 (stack45)
        %v115074_v61 = vshrl.u32 %v154834_v61, 19 (stack46)
        %v112694_v25 = vadd.f32 %v112690_v23, %v112579_v10 (stack53)
        %v154880_v52 = vsel /*vm=*/%vm113035_vm3, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v154885_v60 = vsel /*vm=*/%vm113035_vm3, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v154888_v55 = vadd.f32 -2.5, %v154858_v24 (stack53)
        %v154893_v54 = vsel /*vm=*/%vm113035_vm3, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v154898_v22 = vsel /*vm=*/%vm113035_vm3, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v113443_v32 = vadd.s32 5, %v113439_v9 (stack40)
        %v113825_v44 = vxor.u32 %v113824_v26, %v113820_v50 (stack48)
        %v112698_v42 = vmul.f32 %v112694_v25, %v154648_v42 (stack54)
        %v114240_v30 = vshrl.u32 %v114233_v20, 19 (stack46)
        %v114656_v20 = vshll.u32 %v114650_v6, 17 (stack45)
        %v114657_v6 = vshrl.u32 %v114650_v6, 15 (stack46)
        %v113445_v43 = vxor.u32 %v113443_v32, %v113431_v7 (stack48)
        %v113828_v50 = vadd.s32 %v113825_v44, %v113820_v50 (stack40)
        %v113830_v12 = vshll.u32 %v113825_v44, 29 (stack45)
        %v113831_v31 = vshrl.u32 %v113825_v44, 3 (stack46)
        %v112702_v27 = vsel /*vm=*/%vm154866_vm4, /*on_true_vy=*/%v112555_v53, /*on_false_vx=*/%v112698_v42 (stack44)
        %vm113080_vm5 = vcmp.eq.f32.partialorder %v154858_v24, inf (stack70)
        %v114241_v53 = vor.u32 %v114240_v30, %v114239_v34 (stack47)
        %v114658_v9 = vor.u32 %v114657_v6, %v114656_v20 (stack47)
        %v115075_v21 = vor.u32 %v115074_v61, %v115073_v56 (stack47)
        %v112706_v10 = vmul.f32 1.4140625, %v112702_v27 (stack54)
        %v113068_v23 = vsel /*vm=*/%vm113035_vm3, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v113446_v7 = vand.u32.u8 255, %v113445_v43 (stack49)
        %v113832_v26 = vor.u32 %v113831_v31, %v113830_v12 (stack47)
        %v114242_v34 = vxor.u32 %v114241_v53, %v114237_v8 (stack48)
        %v114659_v56 = vxor.u32 %v114658_v9, %v114654_v45 (stack48)
        %v115076_v61 = vxor.u32 %v115075_v21, %v154839_v46 (stack48)
        %vm115498_vm6 = vcmp.lt.u32.totalorder %v154849_v41, %v157095_v13 (stack43)
        %v112709_v25 = vpack.c.bf16 %v157387_v11, %v112706_v10 (stack81)
        %v113083_v32 = vand.u32 2147483648, %v154858_v24 (stack72)
        %v113447_v44 = vand.u32 65535, %v113446_v7 (stack50)
        %v113833_v42 = vxor.u32 %v113832_v26, %v113828_v50 (stack48)
        %v114245_v8 = vadd.s32 %v114242_v34, %v114237_v8 (stack40)
        %v114247_v30 = vshll.u32 %v114242_v34, 15 (stack45)
        %v114248_v20 = vshrl.u32 %v114242_v34, 17 (stack46)
        %v114662_v45 = vadd.s32 %v114659_v56, %v114654_v45 (stack40)
        %120349 = vst [vmem:[%s123356_s30 + $0x78] sm:$0xf] /*vst_source=*/%v112709_v25 (stack83)
        %v113448_v6 = vshrl.u32 %v113447_v44, 1 (stack51)
        %v113836_v43 = vadd.s32 %v113833_v42, %v113828_v50 (stack40)
        %v113838_v50 = vshll.u32 %v113833_v42, 16 (stack45)
        %v113839_v12 = vshrl.u32 %v113833_v42, 16 (stack46)
        %v121400_v31 = vpop.eup %121399 (stack73)
        %v114249_v27 = vor.u32 %v114248_v20, %v114247_v30 (stack47)
        %v114664_v53 = vshll.u32 %v114659_v56, 29 (stack45)
        %v114665_v9 = vshrl.u32 %v114659_v56, 3 (stack46)
        %v115079_v46 = vadd.s32 %v115076_v61, %v154839_v46 (stack40)
        %v113079_v21 = vmul.f32 %v121400_v31, %v154858_v24 (stack74)
        %v113449_v10 = vor.u32 16256, %v113448_v6 (stack47)
        %v113840_v7 = vor.u32 %v113839_v12, %v113838_v50 (stack47)
        %v115081_v26 = vshll.u32 %v115076_v61, 15 (stack45)
        %v114250_v34 = vxor.u32 %v114249_v27, %v114245_v8 (stack48)
        %v114666_v56 = vor.u32 %v114665_v9, %v114664_v53 (stack47)
        %v115082_v61 = vshrl.u32 %v115076_v61, 17 (stack46)
        %v115503_v40 = vadd.s32 %v157799_v40, %v157100_v14 (stack40)
        %v113081_v25 = vsel /*vm=*/%vm113080_vm5, /*on_true_vy=*/%v154858_v24, /*on_false_vx=*/%v113079_v21 (stack75)
        %vm113082_vm7 = vcmp.eq.f32.partialorder %v154858_v24, 0.0 (stack71)
        %v113450_v44 = vand.u32.u16 65535, %v113449_v10 (stack52)
        %v113841_v42 = vxor.u32 %v113840_v7, %v113836_v43 (stack48)
        %v113084_v32 = vsel /*vm=*/%vm113082_vm7, /*on_true_vy=*/%v113083_v32, /*on_false_vx=*/%v113081_v25 (stack76)
        %v114253_v8 = vadd.s32 %v114250_v34, %v114245_v8 (stack40)
        %v114255_v30 = vshll.u32 %v114250_v34, 26 (stack45)
        %v114256_v20 = vshrl.u32 %v114250_v34, 6 (stack46)
        %v113087_v6 = vadd.f32 -3.0, %v113084_v32 (stack53)
        %v120352_v50 = vadd.low.f32.bf16 -1.0, %v113450_v44 (stack53)
        %v113844_v43 = vadd.s32 %v113841_v42, %v113836_v43 (stack40)
        %v113850_v12 = vshll.u32 %v113841_v42, 24 (stack45)
        %v113851_v31 = vshrl.u32 %v113841_v42, 8 (stack46)
        %v114257_v27 = vor.u32 %v114256_v20, %v114255_v30 (stack47)
        %v114667_v53 = vxor.u32 %v114666_v56, %v114662_v45 (stack48)
        %v115083_v9 = vor.u32 %v115082_v61, %v115081_v26 (stack47)
        %v113072_v21 = vsel /*vm=*/%vm113035_vm3, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v154927_v55 = vsel /*vm=*/%vm113035_vm3, /*on_true_vy=*/%v154888_v55, /*on_false_vx=*/%v113087_v6 (stack44)
        %v113459_v10 = vmul.f32 2.0, %v120352_v50 (stack54)
        %v154931_v7 = vadd.s32 %v154849_v41, %v122657_v58 (stack40)
        %v113095_v26 = vmul.f32 %v154927_v55, %v113072_v21 (stack54)
        %v113852_v34 = vor.u32 %v113851_v31, %v113850_v12 (stack47)
        %v114258_v56 = vxor.u32 %v114257_v27, %v114253_v8 (stack48)
        %v114670_v45 = vadd.s32 %v114667_v53, %v114662_v45 (stack40)
        %v113463_v61 = vadd.f32 -0.99609375, %v113459_v10 (stack53)
        %v114672_v25 = vshll.u32 %v114667_v53, 16 (stack45)
        %v114673_v44 = vshrl.u32 %v114667_v53, 16 (stack46)
        %v115084_v42 = vxor.u32 %v115083_v9, %v115079_v46 (stack48)
        %v113099_v23 = vadd.f32 %v113095_v26, %v113068_v23 (stack53)
        %v113853_v32 = vxor.u32 %v113852_v34, %v113844_v43 (stack48)
        %v114261_v8 = vadd.s32 %v114258_v56, %v114253_v8 (stack40)
        %v114267_v30 = vshll.u32 %v114258_v56, 6 (stack45)
        %v154934_v20 = vmax.f32 %v113463_v61, -0.99609375 (stack55)
        %v114268_v6 = vshrl.u32 %v114258_v56, 26 (stack46)
        %v114674_v50 = vor.u32 %v114673_v44, %v114672_v25 (stack47)
        %v154936_v46 = vadd.s32 %v115084_v42, %v115079_v46 (stack40)
        %v113060_v12 = vsel /*vm=*/%vm113035_vm3, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v113064_v31 = vsel /*vm=*/%vm113035_vm3, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v113103_v27 = vmul.f32 %v113099_v23, %v154927_v55 (stack54)
        %v113856_v53 = vadd.s32 %v113853_v32, %v121564_v0 (stack40)
        %v113479_v9 = vxor.u32 2147483648, %v154934_v20 (stack56)
        %v114269_v21 = vor.u32 %v114268_v6, %v114267_v30 (stack47)
        %v115507_v10 = vadd.s32 1, %v115503_v40 (stack40)
        %v154949_v26 = vadd.s32 %v154931_v7, %v121569_v1 (stack40)
        %v113107_v34 = vadd.f32 %v113103_v27, %v113064_v31 (stack53)
        %v113848_v43 = vadd.s32 %v113844_v43, %v121569_v1 (stack40)
        %v113860_v56 = vadd.s32 4, %v113856_v53 (stack40)
        %v114675_v61 = vxor.u32 %v114674_v50, %v114670_v45 (stack48)
        %vm115493_vm8 = vcmp.lt.u32.totalorder %v154931_v7, %v154849_v41 (stack43)
        %v113482_v25 = vmul.f32 %v113479_v9, %v154934_v20 (stack54)
        %v114265_v44 = vadd.s32 %v114261_v8, %v121574_v2 (stack40)
        %v114270_v23 = vxor.u32 %v114269_v21, %v114261_v8 (stack48)
        %v115511_v40 = vsel /*vm=*/%vm115498_vm6, /*on_true_vy=*/%v115507_v10, /*on_false_vx=*/%v115503_v40 (stack44)
        %v113111_v32 = vmul.f32 %v113107_v34, %v154927_v55 (stack54)
        %v113864_v8 = vadd.s32 %v113860_v56, %v113848_v43 (stack40)
        %v113866_v30 = vshll.u32 %v113860_v56, 13 (stack45)
        %v113867_v6 = vshrl.u32 %v113860_v56, 19 (stack46)
        %v113484_v50 = vadd.f32 1.0, %v113482_v25 (stack57)
        %v113487_v31 = vmul.f32 -0.5, %v113482_v25 (stack59)
        %v114273_v27 = vadd.s32 %v114270_v23, %v121569_v1 (stack40)
        %v115089_v53 = vshll.u32 %v115084_v42, 26 (stack45)
        %v113115_v12 = vadd.f32 %v113111_v32, %v113060_v12 (stack53)
        %v113868_v9 = vor.u32 %v113867_v6, %v113866_v30 (stack47)
        %v114678_v45 = vadd.s32 %v114675_v61, %v114670_v45 (stack40)
        %v115090_v42 = vshrl.u32 %v115084_v42, 6 (stack46)
        %121401 = vlog2.f32 %v113484_v50 (stack58)
        %v113490_v21 = vand.u32 2147483647, %v113482_v25 (stack60)
        %v114277_v10 = vadd.s32 3, %v114273_v27 (stack40)
        %v114684_v34 = vshll.u32 %v114675_v61, 24 (stack45)
        %v113119_v43 = vmul.f32 %v113115_v12, %v154927_v55 (stack54)
        %v113488_v56 = vadd.f32 1.0, %v113487_v31 (stack61)
        %v113869_v23 = vxor.u32 %v113868_v9, %v113864_v8 (stack48)
        %v114685_v61 = vshrl.u32 %v114675_v61, 8 (stack46)
        %v114281_v44 = vadd.s32 %v114277_v10, %v114265_v44 (stack40)
        %v114283_v32 = vshll.u32 %v114277_v10, 17 (stack45)
        %v114284_v30 = vshrl.u32 %v114277_v10, 15 (stack46)
        %v114682_v6 = vadd.s32 %v114678_v45, %v121564_v0 (stack40)
        %v113123_v22 = vadd.f32 %v113119_v43, %v154898_v22 (stack53)
        %v113872_v8 = vadd.s32 %v113869_v23, %v113864_v8 (stack40)
        %v113874_v50 = vshll.u32 %v113869_v23, 15 (stack45)
        %v113875_v31 = vshrl.u32 %v113869_v23, 17 (stack46)
        %v114285_v27 = vor.u32 %v114284_v30, %v114283_v32 (stack47)
        %v114686_v12 = vor.u32 %v114685_v61, %v114684_v34 (stack47)
        %v115091_v53 = vor.u32 %v115090_v42, %v115089_v53 (stack47)
        %v115515_v9 = vadd.s32 1, %v115511_v40 (stack40)
        %v113127_v42 = vmul.f32 %v113123_v22, %v154927_v55 (stack54)
        %v113489_v25 = vmul.f32 %v113488_v56, %v113482_v25 (stack63)
        %v113876_v10 = vor.u32 %v113875_v31, %v113874_v50 (stack47)
        %v115534_v34 = vshll.u32 %v154949_v26, 13 (stack45)
        %v114286_v43 = vxor.u32 %v114285_v27, %v114281_v44 (stack48)
        %v114687_v45 = vxor.u32 %v114686_v12, %v114678_v45 (stack48)
        %v115092_v56 = vxor.u32 %v115091_v53, %v154936_v46 (stack48)
        %v115519_v41 = vsel /*vm=*/%vm115493_vm8, /*on_true_vy=*/%v115515_v9, /*on_false_vx=*/%v115511_v40 (stack44)
        %v113131_v54 = vadd.f32 %v113127_v42, %v154893_v54 (stack53)
        %vm154971_vm9 = vcmp.lt.f32.partialorder %v113490_v21, 0.0004427343 (stack62)
        %v113877_v40 = vxor.u32 %v113876_v10, %v113872_v8 (stack48)
        %v115524_v21 = vadd.s32 %v115519_v41, %v121574_v2 (stack40)
        %v115535_v23 = vshrl.u32 %v154949_v26, 19 (stack46)
        %v114289_v61 = vadd.s32 %v114286_v43, %v114281_v44 (stack40)
        %v114291_v44 = vshll.u32 %v114286_v43, 29 (stack45)
        %v114292_v32 = vshrl.u32 %v114286_v43, 3 (stack46)
        %v114690_v30 = vadd.s32 %v114687_v45, %v121574_v2 (stack40)
        %v113135_v22 = vmul.f32 %v113131_v54, %v154927_v55 (stack54)
        %v113880_v8 = vadd.s32 %v113877_v40, %v113872_v8 (stack40)
        %v113882_v50 = vshll.u32 %v113877_v40, 26 (stack45)
        %v113883_v31 = vshrl.u32 %v113877_v40, 6 (stack46)
        %v114293_v27 = vor.u32 %v114292_v32, %v114291_v44 (stack47)
        %v114694_v12 = vadd.s32 2, %v114690_v30 (stack40)
        %v115095_v46 = vadd.s32 %v115092_v56, %v154936_v46 (stack40)
        %v115101_v53 = vshll.u32 %v115092_v56, 6 (stack45)
        %v113139_v60 = vadd.f32 %v113135_v22, %v154885_v60 (stack53)
        %v113884_v9 = vor.u32 %v113883_v31, %v113882_v50 (stack47)
        %v115102_v42 = vshrl.u32 %v115092_v56, 26 (stack46)
        %v154982_v26 = vadd.s32 %v154949_v26, %v115524_v21 (stack40)
        %v114294_v10 = vxor.u32 %v114293_v27, %v114289_v61 (stack48)
        %v114698_v6 = vadd.s32 %v114694_v12, %v114682_v6 (stack40)
        %v114700_v43 = vshll.u32 %v114694_v12, 13 (stack45)
        %v114701_v45 = vshrl.u32 %v114694_v12, 19 (stack46)
        %v121402_v56 = vpop.eup %121401 (stack64)
        %v113143_v41 = vmul.f32 %v113139_v60, %v154927_v55 (stack54)
        %v113885_v54 = vxor.u32 %v113884_v9, %v113880_v8 (stack48)
        %v115103_v40 = vor.u32 %v115102_v42, %v115101_v53 (stack47)
        %v115536_v34 = vor.u32 %v115535_v23, %v115534_v34 (stack47)
        %v113486_v21 = vmul.f32 0.6931472, %v121402_v56 (stack65)
        %v114297_v23 = vadd.s32 %v114294_v10, %v114289_v61 (stack40)
        %v114299_v61 = vshll.u32 %v114294_v10, 16 (stack45)
        %v114300_v44 = vshrl.u32 %v114294_v10, 16 (stack46)
        %v113147_v52 = vadd.f32 %v113143_v41, %v154880_v52 (stack53)
        %v113888_v32 = vadd.s32 %v113885_v54, %v113880_v8 (stack40)
        %v113894_v30 = vshll.u32 %v113885_v54, 6 (stack45)
        %v113895_v22 = vshrl.u32 %v113885_v54, 26 (stack46)
        %v113492_v25 = vsel /*vm=*/%vm154971_vm9, /*on_true_vy=*/%v113489_v25, /*on_false_vx=*/%v113486_v21 (stack66)
        %v114301_v7 = vor.u32 %v114300_v44, %v114299_v61 (stack47)
        %v114702_v8 = vor.u32 %v114701_v45, %v114700_v43 (stack47)
        %v115104_v50 = vxor.u32 %v115103_v40, %v115095_v46 (stack48)
        %v113008_v31 = vand.u32 2147483647, %v154781_v29 (stack77)
        %v113151_v55 = vmul.f32 %v113147_v52, %v154927_v55 (stack54)
        %v154990_v27 = vxor.u32 2147483648, %v113492_v25 (stack56)
        %v113896_v12 = vor.u32 %v113895_v22, %v113894_v30 (stack47)
        %v113040_v24 = vsel /*vm=*/%vm113035_vm3, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v114302_v53 = vxor.u32 %v114301_v7, %v114297_v23 (stack48)
        %v114703_v60 = vxor.u32 %v114702_v8, %v114698_v6 (stack48)
        %v115537_v9 = vxor.u32 %v115536_v34, %v154982_v26 (stack48)
        %v113155_v42 = vadd.f32 %v113151_v55, %v113040_v24 (stack53)
        %121403 = vrsqrt.f32 %v154990_v27 (stack67)
        %v113016_v10 = vmul.f32 inf, %v154781_v29 (stack54)
        %vm113496_vm10 = vcmp.lt.f32.partialorder %v154990_v27, 5.0 (stack68)
        %v113897_v43 = vxor.u32 %v113896_v12, %v113888_v32 (stack48)
        %vm113011_vm11 = vcmp.eq.f32.partialorder %v113008_v31, 1.0 (stack68)
        %v113159_v29 = vmul.f32 %v113155_v42, %v154781_v29 (stack54)
        %v113469_v45 = vand.u32 2147483647, %v154934_v20 (stack77)
        %v115099_v46 = vadd.s32 %v115095_v46, %v121569_v1 (stack40)
        %v155003_v56 = vadd.f32 -2.5, %v154990_v27 (stack53)
        %v113892_v41 = vadd.s32 %v113888_v32, %v121564_v0 (stack40)
        %v113900_v54 = vadd.s32 %v113897_v43, %v121574_v2 (stack40)
        %v115107_v40 = vadd.s32 %v115104_v50, %v121564_v0 (stack40)
        %v113163_v34 = vsel /*vm=*/%vm113011_vm11, /*on_true_vy=*/%v113016_v10, /*on_false_vx=*/%v113159_v29 (stack44)
        %v155011_v21 = vsel /*vm=*/%vm113496_vm10, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v155016_v61 = vsel /*vm=*/%vm113496_vm10, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v155021_v44 = vsel /*vm=*/%vm113496_vm10, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v113167_v52 = vmul.f32 1.4140625, %v113163_v34 (stack54)
        %v113904_v32 = vadd.s32 5, %v113900_v54 (stack40)
        %v114305_v23 = vadd.s32 %v114302_v53, %v114297_v23 (stack40)
        %v114311_v30 = vshll.u32 %v114302_v53, 24 (stack45)
        %v114312_v22 = vshrl.u32 %v114302_v53, 8 (stack46)
        %v114706_v6 = vadd.s32 %v114703_v60, %v114698_v6 (stack40)
        %v114708_v25 = vshll.u32 %v114703_v60, 15 (stack45)
        %v114709_v7 = vshrl.u32 %v114703_v60, 17 (stack46)
        %v113170_v8 = vpack.c.bf16 %v157387_v11, %v113167_v52 (stack81)
        %vm113541_vm12 = vcmp.eq.f32.partialorder %v154990_v27, inf (stack70)
        %v113544_v50 = vand.u32 2147483648, %v154990_v27 (stack72)
        %v113906_v31 = vxor.u32 %v113904_v32, %v113892_v41 (stack48)
        %v115111_v55 = vadd.s32 1, %v115107_v40 (stack40)
        %vm113543_vm13 = vcmp.eq.f32.partialorder %v154990_v27, 0.0 (stack71)
        %v114313_v12 = vor.u32 %v114312_v22, %v114311_v30 (stack47)
        %v114710_v24 = vor.u32 %v114709_v7, %v114708_v25 (stack47)
        %v115540_v26 = vadd.s32 %v115537_v9, %v154982_v26 (stack40)
        %v115542_v53 = vshll.u32 %v115537_v9, 15 (stack45)
        %120351 = vst [vmem:[%s123356_s30 + $0xf8] sm:$0xf] /*vst_source=*/%v113170_v8 (stack83)
        %v113907_v60 = vand.u32.u8 255, %v113906_v31 (stack49)
        %v115115_v42 = vadd.s32 %v115111_v55, %v115099_v46 (stack40)
        %v115117_v10 = vshll.u32 %v115111_v55, 17 (stack45)
        %v115118_v43 = vshrl.u32 %v115111_v55, 15 (stack46)
        %v114314_v29 = vxor.u32 %v114313_v12, %v114305_v23 (stack48)
        %v114711_v46 = vxor.u32 %v114710_v24, %v114706_v6 (stack48)
        %v115543_v9 = vshrl.u32 %v115537_v9, 17 (stack46)
        %v157828_v41 = vld [vmem:[#allocation151_spill] sm:$0xff] (stack84)
        %v155031_v54 = vadd.s32 %v157828_v41, %v122651_v47 (stack40)
        %v113908_v40 = vand.u32 65535, %v113907_v60 (stack50)
        %v115119_v34 = vor.u32 %v115118_v43, %v115117_v10 (stack47)
        %v157829_v52 = vld [vmem:[#allocation115_spill] sm:$0xff] (stack84)
        %v155035_v28 = vadd.s32 %v157829_v52, %v157068_v28 (stack40)
        %v155039_v32 = vadd.s32 %v157828_v41, %v157070_v38 (stack40)
        %v114317_v30 = vadd.s32 %v114314_v29, %v121564_v0 (stack40)
        %v114714_v22 = vadd.s32 %v114711_v46, %v114706_v6 (stack40)
        %v114716_v6 = vshll.u32 %v114711_v46, 26 (stack45)
        %v114717_v25 = vshrl.u32 %v114711_v46, 6 (stack46)
        %v121404_v7 = vpop.eup %121403 (stack73)
        %v113909_v8 = vshrl.u32 %v113908_v40, 1 (stack51)
        %v114309_v23 = vadd.s32 %v114305_v23, %v121569_v1 (stack40)
        %v115120_v31 = vxor.u32 %v115119_v34, %v115115_v42 (stack48)
        %v115544_v55 = vor.u32 %v115543_v9, %v115542_v53 (stack47)
        %v113540_v12 = vmul.f32 %v121404_v7, %v154990_v27 (stack74)
        %v114321_v24 = vadd.s32 4, %v114317_v30 (stack40)
        %v114718_v53 = vor.u32 %v114717_v25, %v114716_v6 (stack47)
        %vm115993_vm14 = vcmp.lt.u32.totalorder %v155031_v54, %v122651_v47 (stack43)
        %v113910_v60 = vor.u32 16256, %v113909_v8 (stack47)
        %v115123_v42 = vadd.s32 %v115120_v31, %v115115_v42 (stack40)
        %v115125_v10 = vshll.u32 %v115120_v31, 29 (stack45)
        %v115126_v43 = vshrl.u32 %v115120_v31, 3 (stack46)
        %v113542_v29 = vsel /*vm=*/%vm113541_vm12, /*on_true_vy=*/%v154990_v27, /*on_false_vx=*/%v113540_v12 (stack75)
        %v114325_v46 = vadd.s32 %v114321_v24, %v114309_v23 (stack40)
        %v114327_v9 = vshll.u32 %v114321_v24, 13 (stack45)
        %v114328_v40 = vshrl.u32 %v114321_v24, 19 (stack46)
        %v113545_v50 = vsel /*vm=*/%vm113543_vm13, /*on_true_vy=*/%v113544_v50, /*on_false_vx=*/%v113542_v29 (stack76)
        %v113911_v34 = vand.u32.u16 65535, %v113910_v60 (stack52)
        %v114719_v30 = vxor.u32 %v114718_v53, %v114714_v22 (stack48)
        %v115127_v6 = vor.u32 %v115126_v43, %v115125_v10 (stack47)
        %v113533_v25 = vsel /*vm=*/%vm113496_vm10, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v113548_v7 = vadd.f32 -3.0, %v113545_v50 (stack53)
        %v114329_v8 = vor.u32 %v114328_v40, %v114327_v9 (stack47)
        %v115545_v23 = vxor.u32 %v115544_v55, %v115540_v26 (stack48)
        %v120354_v31 = vadd.low.f32.bf16 -1.0, %v113911_v34 (stack53)
        %v114722_v22 = vadd.s32 %v114719_v30, %v114714_v22 (stack40)
        %v114728_v55 = vshll.u32 %v114719_v30, 6 (stack45)
        %v114729_v12 = vshrl.u32 %v114719_v30, 26 (stack46)
        %v155057_v56 = vsel /*vm=*/%vm113496_vm10, /*on_true_vy=*/%v155003_v56, /*on_false_vx=*/%v113548_v7 (stack44)
        %v114330_v24 = vxor.u32 %v114329_v8, %v114325_v46 (stack48)
        %v115128_v53 = vxor.u32 %v115127_v6, %v115123_v42 (stack48)
        %v155059_v26 = vadd.s32 %v115545_v23, %v115540_v26 (stack40)
        %v113529_v60 = vsel /*vm=*/%vm113496_vm10, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v113556_v10 = vmul.f32 %v155057_v56, %v113533_v25 (stack54)
        %v113920_v43 = vmul.f32 2.0, %v120354_v31 (stack54)
        %v114730_v29 = vor.u32 %v114729_v12, %v114728_v55 (stack47)
        %v114333_v46 = vadd.s32 %v114330_v24, %v114325_v46 (stack40)
        %v114335_v9 = vshll.u32 %v114330_v24, 15 (stack45)
        %v114336_v40 = vshrl.u32 %v114330_v24, 17 (stack46)
        %v115131_v42 = vadd.s32 %v115128_v53, %v115123_v42 (stack40)
        %v113560_v50 = vadd.f32 %v113556_v10, %v113529_v60 (stack53)
        %v113924_v34 = vadd.f32 -0.99609375, %v113920_v43 (stack53)
        %v114731_v30 = vxor.u32 %v114730_v29, %v114722_v22 (stack48)
        %v115133_v6 = vshll.u32 %v115128_v53, 16 (stack45)
        %v113513_v25 = vsel /*vm=*/%vm113496_vm10, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v113517_v7 = vsel /*vm=*/%vm113496_vm10, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v114337_v8 = vor.u32 %v114336_v40, %v114335_v9 (stack47)
        %v115134_v31 = vshrl.u32 %v115128_v53, 16 (stack46)
        %v113521_v55 = vsel /*vm=*/%vm113496_vm10, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v113564_v12 = vmul.f32 %v113560_v50, %v155057_v56 (stack54)
        %v155075_v24 = vmax.f32 %v113924_v34, -0.99609375 (stack55)
        %v114734_v53 = vadd.s32 %v114731_v30, %v121569_v1 (stack40)
        %v113525_v27 = vsel /*vm=*/%vm113496_vm10, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v114338_v60 = vxor.u32 %v114337_v8, %v114333_v46 (stack48)
        %v115135_v10 = vor.u32 %v115134_v31, %v115133_v6 (stack47)
        %v155083_v43 = vadd.s32 %v155031_v54, %v122657_v58 (stack40)
        %v113568_v29 = vadd.f32 %v113564_v12, %v113525_v27 (stack53)
        %v113940_v9 = vxor.u32 2147483648, %v155075_v24 (stack56)
        %v114726_v22 = vadd.s32 %v114722_v22, %v121574_v2 (stack40)
        %v115550_v40 = vshll.u32 %v115545_v23, 26 (stack45)
        %v114341_v46 = vadd.s32 %v114338_v60, %v114333_v46 (stack40)
        %v114343_v50 = vshll.u32 %v114338_v60, 26 (stack45)
        %v114344_v34 = vshrl.u32 %v114338_v60, 6 (stack46)
        %v114738_v30 = vadd.s32 3, %v114734_v53 (stack40)
        %v113572_v6 = vmul.f32 %v113568_v29, %v155057_v56 (stack54)
        %v155089_v8 = vmul.f32 %v113940_v9, %v155075_v24 (stack54)
        %v115136_v31 = vxor.u32 %v115135_v10, %v115131_v42 (stack48)
        %v115551_v23 = vshrl.u32 %v115545_v23, 6 (stack46)
        %v114345_v12 = vor.u32 %v114344_v34, %v114343_v50 (stack47)
        %v114742_v53 = vadd.s32 %v114738_v30, %v114726_v22 (stack40)
        %v114744_v27 = vshll.u32 %v114738_v30, 17 (stack45)
        %v114745_v60 = vshrl.u32 %v114738_v30, 15 (stack46)
        %v113576_v55 = vadd.f32 %v113572_v6, %v113521_v55 (stack53)
        %v113945_v10 = vadd.f32 1.0, %v155089_v8 (stack57)
        %vm115988_vm15 = vcmp.lt.u32.totalorder %v155083_v43, %v155031_v54 (stack43)
        %v116002_v29 = vadd.s32 1, %v155035_v28 (stack40)
        %v113948_v9 = vmul.f32 -0.5, %v155089_v8 (stack59)
        %v114346_v22 = vxor.u32 %v114345_v12, %v114341_v46 (stack48)
        %v114746_v50 = vor.u32 %v114745_v60, %v114744_v27 (stack47)
        %v115139_v42 = vadd.s32 %v115136_v31, %v115131_v42 (stack40)
        %v113580_v34 = vmul.f32 %v113576_v55, %v155057_v56 (stack54)
        %121405 = vlog2.f32 %v113945_v10 (stack58)
        %v115145_v30 = vshll.u32 %v115136_v31, 24 (stack45)
        %v115552_v40 = vor.u32 %v115551_v23, %v115550_v40 (stack47)
        %v114349_v46 = vadd.s32 %v114346_v22, %v114341_v46 (stack40)
        %v114355_v6 = vshll.u32 %v114346_v22, 6 (stack45)
        %v114356_v23 = vshrl.u32 %v114346_v22, 26 (stack46)
        %v114747_v12 = vxor.u32 %v114746_v50, %v114742_v53 (stack48)
        %v113584_v7 = vadd.f32 %v113580_v34, %v113517_v7 (stack53)
        %v113951_v27 = vand.u32 2147483647, %v155089_v8 (stack60)
        %v115146_v31 = vshrl.u32 %v115136_v31, 8 (stack46)
        %v116023_v60 = vadd.s32 %v155083_v43, %v121569_v1 (stack40)
        %v113949_v55 = vadd.f32 1.0, %v113948_v9 (stack61)
        %v114357_v10 = vor.u32 %v114356_v23, %v114355_v6 (stack47)
        %v114750_v53 = vadd.s32 %v114747_v12, %v114742_v53 (stack40)
        %v114752_v9 = vshll.u32 %v114747_v12, 29 (stack45)
        %v113588_v22 = vmul.f32 %v113584_v7, %v155057_v56 (stack54)
        %v114753_v50 = vshrl.u32 %v114747_v12, 3 (stack46)
        %v115147_v34 = vor.u32 %v115146_v31, %v115145_v30 (stack47)
        %v115553_v30 = vxor.u32 %v115552_v40, %v155059_v26 (stack48)
        %v114353_v40 = vadd.s32 %v114349_v46, %v121564_v0 (stack40)
        %v114358_v46 = vxor.u32 %v114357_v10, %v114349_v46 (stack48)
        %v115143_v6 = vadd.s32 %v115139_v42, %v121564_v0 (stack40)
        %v116006_v47 = vsel /*vm=*/%vm115993_vm14, /*on_true_vy=*/%v116002_v29, /*on_false_vx=*/%v155035_v28 (stack44)
        %v113592_v28 = vadd.f32 %v113588_v22, %v113513_v25 (stack53)
        %v114754_v25 = vor.u32 %v114753_v50, %v114752_v9 (stack47)
        %v115148_v29 = vxor.u32 %v115147_v34, %v115139_v42 (stack48)
        %v115556_v26 = vadd.s32 %v115553_v30, %v155059_v26 (stack40)
        %v114361_v42 = vadd.s32 %v114358_v46, %v121574_v2 (stack40)
        %v115562_v23 = vshll.u32 %v115553_v30, 6 (stack45)
        %v115563_v12 = vshrl.u32 %v115553_v30, 26 (stack46)
        %v116010_v7 = vadd.s32 1, %v116006_v47 (stack40)
        %v113596_v31 = vmul.f32 %v113592_v28, %v155057_v56 (stack54)
        %v114755_v10 = vxor.u32 %v114754_v25, %v114750_v53 (stack48)
        %v115151_v9 = vadd.s32 %v115148_v29, %v121574_v2 (stack40)
        %v116029_v22 = vshll.u32 %v116023_v60, 13 (stack45)
        %v114365_v50 = vadd.s32 5, %v114361_v42 (stack40)
        %v115564_v34 = vor.u32 %v115563_v12, %v115562_v23 (stack47)
        %v116014_v54 = vsel /*vm=*/%vm115988_vm15, /*on_true_vy=*/%v116010_v7, /*on_false_vx=*/%v116006_v47 (stack44)
        %v116030_v43 = vshrl.u32 %v116023_v60, 19 (stack46)
        %v113600_v44 = vadd.f32 %v113596_v31, %v155021_v44 (stack53)
        %v114758_v53 = vadd.s32 %v114755_v10, %v114750_v53 (stack40)
        %v114760_v30 = vshll.u32 %v114755_v10, 16 (stack45)
        %v114761_v46 = vshrl.u32 %v114755_v10, 16 (stack46)
        %v114367_v40 = vxor.u32 %v114365_v50, %v114353_v40 (stack48)
        %v115155_v47 = vadd.s32 2, %v115151_v9 (stack40)
        %v115565_v28 = vxor.u32 %v115564_v34, %v115556_v26 (stack48)
        %v116019_v25 = vadd.s32 %v116014_v54, %v121574_v2 (stack40)
        %v113604_v29 = vmul.f32 %v113600_v44, %v155057_v56 (stack54)
        %v113950_v8 = vmul.f32 %v113949_v55, %v155089_v8 (stack63)
        %v114762_v55 = vor.u32 %v114761_v46, %v114760_v30 (stack47)
        %vm116454_vm0 = vcmp.lt.u32.totalorder %v155039_v32, %v157070_v38 (stack43)
        %v121406_v42 = vpop.eup %121405 (stack64)
        %v114368_v23 = vand.u32.u8 255, %v114367_v40 (stack49)
        %v115159_v6 = vadd.s32 %v115155_v47, %v115143_v6 (stack40)
        %v115161_v12 = vshll.u32 %v115155_v47, 13 (stack45)
        %v115162_v7 = vshrl.u32 %v115155_v47, 19 (stack46)
        %v113608_v61 = vadd.f32 %v113604_v29, %v155016_v61 (stack53)
        %v113947_v31 = vmul.f32 0.6931472, %v121406_v42 (stack65)
        %v114763_v10 = vxor.u32 %v114762_v55, %v114758_v53 (stack48)
        %v116031_v9 = vor.u32 %v116030_v43, %v116029_v22 (stack47)
        %vm113952_vm1 = vcmp.lt.f32.partialorder %v113951_v27, 0.0004427343 (stack62)
        %v114369_v27 = vand.u32 65535, %v114368_v23 (stack50)
        %v115163_v22 = vor.u32 %v115162_v7, %v115161_v12 (stack47)
        %v116027_v60 = vadd.s32 %v116023_v60, %v116019_v25 (stack40)
        %v113612_v56 = vmul.f32 %v113608_v61, %v155057_v56 (stack54)
        %v113953_v50 = vsel /*vm=*/%vm113952_vm1, /*on_true_vy=*/%v113950_v8, /*on_false_vx=*/%v113947_v31 (stack66)
        %v114766_v34 = vadd.s32 %v114763_v10, %v114758_v53 (stack40)
        %v115568_v54 = vadd.s32 %v115565_v28, %v121564_v0 (stack40)
        %v155124_v43 = vxor.u32 2147483648, %v113953_v50 (stack56)
        %v114772_v44 = vshll.u32 %v114763_v10, 24 (stack45)
        %v114773_v53 = vshrl.u32 %v114763_v10, 8 (stack46)
        %v115164_v30 = vxor.u32 %v115163_v22, %v115159_v6 (stack48)
        %v113616_v21 = vadd.f32 %v113612_v56, %v155011_v21 (stack53)
        %v116032_v46 = vxor.u32 %v116031_v9, %v116027_v60 (stack48)
        %121407 = vrsqrt.f32 %v155124_v43 (stack67)
        %v114370_v40 = vshrl.u32 %v114369_v27, 1 (stack51)
        %v113477_v47 = vmul.f32 inf, %v154934_v20 (stack54)
        %v113620_v28 = vmul.f32 %v113616_v21, %v154934_v20 (stack54)
        %vm113957_vm2 = vcmp.lt.f32.partialorder %v155124_v43, 5.0 (stack68)
        %vm113472_vm3 = vcmp.eq.f32.partialorder %v113469_v45, 1.0 (stack68)
        %v114774_v20 = vor.u32 %v114773_v53, %v114772_v44 (stack47)
        %v115560_v45 = vadd.s32 %v115556_v26, %v121569_v1 (stack40)
        %v115572_v26 = vadd.s32 1, %v115568_v54 (stack40)
        %v113624_v25 = vsel /*vm=*/%vm113472_vm3, /*on_true_vy=*/%v113477_v47, /*on_false_vx=*/%v113620_v28 (stack44)
        %v155135_v29 = vadd.f32 -2.5, %v155124_v43 (stack53)
        %v114770_v8 = vadd.s32 %v114766_v34, %v121569_v1 (stack40)
        %v155140_v55 = vadd.s32 %v155039_v32, %v122657_v58 (stack40)
        %v113628_v42 = vmul.f32 1.4140625, %v113624_v25 (stack54)
        %v155145_v23 = vsel /*vm=*/%vm113957_vm2, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v155150_v12 = vsel /*vm=*/%vm113957_vm2, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v114371_v7 = vor.u32 16256, %v114370_v40 (stack47)
        %v114775_v61 = vxor.u32 %v114774_v20, %v114766_v34 (stack48)
        %v115167_v6 = vadd.s32 %v115164_v30, %v115159_v6 (stack40)
        %v115169_v31 = vshll.u32 %v115164_v30, 15 (stack45)
        %v115170_v10 = vshrl.u32 %v115164_v30, 17 (stack46)
        %v113631_v9 = vpack.c.bf16 %v157387_v11, %v113628_v42 (stack81)
        %v114372_v27 = vand.u32.u16 65535, %v114371_v7 (stack52)
        %v115576_v22 = vadd.s32 %v115572_v26, %v115560_v45 (stack40)
        %v115578_v56 = vshll.u32 %v115572_v26, 17 (stack45)
        %vm114002_vm4 = vcmp.eq.f32.partialorder %v155124_v43, inf (stack70)
        %v114778_v50 = vadd.s32 %v114775_v61, %v121564_v0 (stack40)
        %v115171_v34 = vor.u32 %v115170_v10, %v115169_v31 (stack47)
        %v115579_v54 = vshrl.u32 %v115572_v26, 15 (stack46)
        %v116035_v60 = vadd.s32 %v116032_v46, %v116027_v60 (stack40)
        %120353 = vst [vmem:[%s123356_s30 + $0x178] sm:$0xf] /*vst_source=*/%v113631_v9 (stack83)
        %v120356_v44 = vadd.low.f32.bf16 -1.0, %v114372_v27 (stack53)
        %v116037_v53 = vshll.u32 %v116032_v46, 15 (stack45)
        %v116038_v30 = vshrl.u32 %v116032_v46, 17 (stack46)
        %v116459_v35 = vadd.s32 %v157829_v52, %v157076_v35 (stack40)
        %v155161_v21 = vsel /*vm=*/%vm113957_vm2, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v114782_v46 = vadd.s32 4, %v114778_v50 (stack40)
        %v115172_v40 = vxor.u32 %v115171_v34, %v115167_v6 (stack48)
        %v115580_v47 = vor.u32 %v115579_v54, %v115578_v56 (stack47)
        %v114381_v28 = vmul.f32 2.0, %v120356_v44 (stack54)
        %v116039_v20 = vor.u32 %v116038_v30, %v116037_v53 (stack47)
        %v116463_v45 = vadd.s32 1, %v116459_v35 (stack40)
        %v155165_v26 = vadd.s32 %v157828_v41, %v157077_v51 (stack40)
        %v114786_v25 = vadd.s32 %v114782_v46, %v114770_v8 (stack40)
        %v114788_v8 = vshll.u32 %v114782_v46, 13 (stack45)
        %v114789_v42 = vshrl.u32 %v114782_v46, 19 (stack46)
        %v115175_v7 = vadd.s32 %v115172_v40, %v115167_v6 (stack40)
        %v114385_v61 = vadd.f32 -0.99609375, %v114381_v28 (stack53)
        %v115177_v6 = vshll.u32 %v115172_v40, 26 (stack45)
        %v115178_v31 = vshrl.u32 %v115172_v40, 6 (stack46)
        %v115581_v10 = vxor.u32 %v115580_v47, %v115576_v22 (stack48)
        %v121408_v9 = vpop.eup %121407 (stack73)
        %v114005_v27 = vand.u32 2147483648, %v155124_v43 (stack72)
        %v114790_v56 = vor.u32 %v114789_v42, %v114788_v8 (stack47)
        %v116040_v50 = vxor.u32 %v116039_v20, %v116035_v60 (stack48)
        %v116467_v38 = vsel /*vm=*/%vm116454_vm0, /*on_true_vy=*/%v116463_v45, /*on_false_vx=*/%v116459_v35 (stack44)
        %v114001_v34 = vmul.f32 %v121408_v9, %v155124_v43 (stack74)
        %v155172_v54 = vmax.f32 %v114385_v61, -0.99609375 (stack55)
        %v115179_v44 = vor.u32 %v115178_v31, %v115177_v6 (stack47)
        %v115584_v22 = vadd.s32 %v115581_v10, %v115576_v22 (stack40)
        %v114791_v53 = vxor.u32 %v114790_v56, %v114786_v25 (stack48)
        %v115586_v30 = vshll.u32 %v115581_v10, 29 (stack45)
        %v115587_v35 = vshrl.u32 %v115581_v10, 3 (stack46)
        %v116043_v60 = vadd.s32 %v116040_v50, %v116035_v60 (stack40)
        %v113986_v46 = vsel /*vm=*/%vm113957_vm2, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v114003_v40 = vsel /*vm=*/%vm114002_vm4, /*on_true_vy=*/%v155124_v43, /*on_false_vx=*/%v114001_v34 (stack75)
        %vm114004_vm5 = vcmp.eq.f32.partialorder %v155124_v43, 0.0 (stack71)
        %v114401_v47 = vxor.u32 2147483648, %v155172_v54 (stack56)
        %vm116449_vm6 = vcmp.lt.u32.totalorder %v155140_v55, %v155039_v32 (stack43)
        %v114006_v28 = vsel /*vm=*/%vm114004_vm5, /*on_true_vy=*/%v114005_v27, /*on_false_vx=*/%v114003_v40 (stack76)
        %v114794_v20 = vadd.s32 %v114791_v53, %v114786_v25 (stack40)
        %v114796_v45 = vshll.u32 %v114791_v53, 15 (stack45)
        %v114797_v25 = vshrl.u32 %v114791_v53, 17 (stack46)
        %v114009_v8 = vadd.f32 -3.0, %v114006_v28 (stack53)
        %v155185_v42 = vmul.f32 %v114401_v47, %v155172_v54 (stack54)
        %v115180_v61 = vxor.u32 %v115179_v44, %v115175_v7 (stack48)
        %v155189_v6 = vadd.s32 %v155140_v55, %v121569_v1 (stack40)
        %v113994_v31 = vsel /*vm=*/%vm113957_vm2, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v114798_v10 = vor.u32 %v114797_v25, %v114796_v45 (stack47)
        %v115588_v9 = vor.u32 %v115587_v35, %v115586_v30 (stack47)
        %v116045_v27 = vshll.u32 %v116040_v50, 26 (stack45)
        %v155197_v29 = vsel /*vm=*/%vm113957_vm2, /*on_true_vy=*/%v155135_v29, /*on_false_vx=*/%v114009_v8 (stack44)
        %v114406_v56 = vadd.f32 1.0, %v155185_v42 (stack57)
        %v114409_v34 = vmul.f32 -0.5, %v155185_v42 (stack59)
        %v116046_v50 = vshrl.u32 %v116040_v50, 6 (stack46)
        %v114017_v44 = vmul.f32 %v155197_v29, %v113994_v31 (stack54)
        %v114799_v53 = vxor.u32 %v114798_v10, %v114794_v20 (stack48)
        %v115183_v7 = vadd.s32 %v115180_v61, %v115175_v7 (stack40)
        %v115189_v30 = vshll.u32 %v115180_v61, 6 (stack45)
        %v113990_v35 = vsel /*vm=*/%vm113957_vm2, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %121409 = vlog2.f32 %v114406_v56 (stack58)
        %v115190_v40 = vshrl.u32 %v115180_v61, 26 (stack46)
        %v116490_v47 = vshll.u32 %v155189_v6, 13 (stack45)
        %v114021_v28 = vadd.f32 %v114017_v44, %v113990_v35 (stack53)
        %v114802_v20 = vadd.s32 %v114799_v53, %v114794_v20 (stack40)
        %v114804_v45 = vshll.u32 %v114799_v53, 26 (stack45)
        %v114805_v25 = vshrl.u32 %v114799_v53, 6 (stack46)
        %v114410_v8 = vadd.f32 1.0, %v114409_v34 (stack61)
        %v114412_v61 = vand.u32 2147483647, %v155185_v42 (stack60)
        %v115191_v31 = vor.u32 %v115190_v40, %v115189_v30 (stack47)
        %v115589_v10 = vxor.u32 %v115588_v9, %v115584_v22 (stack48)
        %v114025_v9 = vmul.f32 %v114021_v28, %v155197_v29 (stack54)
        %v114806_v56 = vor.u32 %v114805_v25, %v114804_v45 (stack47)
        %v116047_v27 = vor.u32 %v116046_v50, %v116045_v27 (stack47)
        %v116471_v34 = vadd.s32 1, %v116467_v38 (stack40)
        %v115192_v50 = vxor.u32 %v115191_v31, %v115183_v7 (stack48)
        %v115592_v22 = vadd.s32 %v115589_v10, %v115584_v22 (stack40)
        %v115594_v44 = vshll.u32 %v115589_v10, 16 (stack45)
        %v115595_v53 = vshrl.u32 %v115589_v10, 16 (stack46)
        %v114029_v46 = vadd.f32 %v114025_v9, %v113986_v46 (stack53)
        %v114807_v30 = vxor.u32 %v114806_v56, %v114802_v20 (stack48)
        %v116048_v35 = vxor.u32 %v116047_v27, %v116043_v60 (stack48)
        %v116475_v32 = vsel /*vm=*/%vm116449_vm6, /*on_true_vy=*/%v116471_v34, /*on_false_vx=*/%v116467_v38 (stack44)
        %v115187_v55 = vadd.s32 %v115183_v7, %v121574_v2 (stack40)
        %v115195_v38 = vadd.s32 %v115192_v50, %v121569_v1 (stack40)
        %v115596_v7 = vor.u32 %v115595_v53, %v115594_v44 (stack47)
        %v116480_v40 = vadd.s32 %v116475_v32, %v121574_v2 (stack40)
        %v114033_v28 = vmul.f32 %v114029_v46, %v155197_v29 (stack54)
        %v114810_v20 = vadd.s32 %v114807_v30, %v114802_v20 (stack40)
        %v114816_v45 = vshll.u32 %v114807_v30, 6 (stack45)
        %v114817_v25 = vshrl.u32 %v114807_v30, 26 (stack46)
        %v115199_v31 = vadd.s32 3, %v115195_v38 (stack40)
        %v115597_v10 = vxor.u32 %v115596_v7, %v115592_v22 (stack48)
        %v116051_v60 = vadd.s32 %v116048_v35, %v116043_v60 (stack40)
        %v116057_v9 = vshll.u32 %v116048_v35, 6 (stack45)
        %v114037_v21 = vadd.f32 %v114033_v28, %v155161_v21 (stack53)
        %v114818_v56 = vor.u32 %v114817_v25, %v114816_v45 (stack47)
        %v116058_v27 = vshrl.u32 %v116048_v35, 26 (stack46)
        %v116491_v34 = vshrl.u32 %v155189_v6, 19 (stack46)
        %v115203_v50 = vadd.s32 %v115199_v31, %v115187_v55 (stack40)
        %v115205_v44 = vshll.u32 %v115199_v31, 17 (stack45)
        %v115206_v53 = vshrl.u32 %v115199_v31, 15 (stack46)
        %v115600_v22 = vadd.s32 %v115597_v10, %v115592_v22 (stack40)
        %v114041_v46 = vmul.f32 %v114037_v21, %v155197_v29 (stack54)
        %v114819_v30 = vxor.u32 %v114818_v56, %v114810_v20 (stack48)
        %v115606_v35 = vshll.u32 %v115597_v10, 24 (stack45)
        %v115607_v32 = vshrl.u32 %v115597_v10, 8 (stack46)
        %v114411_v42 = vmul.f32 %v114410_v8, %v155185_v42 (stack63)
        %vm155219_vm7 = vcmp.lt.f32.partialorder %v114412_v61, 0.0004427343 (stack62)
        %v115207_v61 = vor.u32 %v115206_v53, %v115205_v44 (stack47)
        %v116059_v55 = vor.u32 %v116058_v27, %v116057_v9 (stack47)
        %v121410_v38 = vpop.eup %121409 (stack64)
        %v114045_v12 = vadd.f32 %v114041_v46, %v155150_v12 (stack53)
        %v114822_v7 = vadd.s32 %v114819_v30, %v121574_v2 (stack40)
        %v115608_v28 = vor.u32 %v115607_v32, %v115606_v35 (stack47)
        %v116488_v6 = vadd.s32 %v155189_v6, %v116480_v40 (stack40)
        %v114408_v40 = vmul.f32 0.6931472, %v121410_v38 (stack65)
        %v115208_v45 = vxor.u32 %v115207_v61, %v115203_v50 (stack48)
        %v116060_v25 = vxor.u32 %v116059_v55, %v116051_v60 (stack48)
        %v116492_v47 = vor.u32 %v116491_v34, %v116490_v47 (stack47)
        %v114049_v31 = vmul.f32 %v114045_v12, %v155197_v29 (stack54)
        %v114814_v20 = vadd.s32 %v114810_v20, %v121564_v0 (stack40)
        %v114826_v10 = vadd.s32 5, %v114822_v7 (stack40)
        %v115609_v9 = vxor.u32 %v115608_v28, %v115600_v22 (stack48)
        %v114414_v21 = vsel /*vm=*/%vm155219_vm7, /*on_true_vy=*/%v114411_v42, /*on_false_vx=*/%v114408_v40 (stack66)
        %v115211_v56 = vadd.s32 %v115208_v45, %v115203_v50 (stack40)
        %v115213_v27 = vshll.u32 %v115208_v45, 29 (stack45)
        %v115214_v34 = vshrl.u32 %v115208_v45, 3 (stack46)
        %v114053_v23 = vadd.f32 %v114049_v31, %v155145_v23 (stack53)
        %v155231_v50 = vxor.u32 2147483648, %v114414_v21 (stack56)
        %v114828_v44 = vxor.u32 %v114826_v10, %v114814_v20 (stack48)
        %v113930_v53 = vand.u32 2147483647, %v155075_v24 (stack77)
        %v115215_v46 = vor.u32 %v115214_v34, %v115213_v27 (stack47)
        %v116493_v30 = vxor.u32 %v116492_v47, %v116488_v6 (stack48)
        %v155235_v35 = vmul.f32 inf, %v155075_v24 (stack54)
        %v113962_v32 = vsel /*vm=*/%vm113957_vm2, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v114057_v42 = vmul.f32 %v114053_v23, %v155197_v29 (stack54)
        %121411 = vrsqrt.f32 %v155231_v50 (stack67)
        %v113970_v8 = vsel /*vm=*/%vm113957_vm2, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %vm114418_vm8 = vcmp.lt.f32.partialorder %v155231_v50, 5.0 (stack68)
        %v115216_v61 = vxor.u32 %v115215_v46, %v115211_v56 (stack48)
        %v115612_v55 = vadd.s32 %v115609_v9, %v121574_v2 (stack40)
        %v113966_v43 = vsel /*vm=*/%vm113957_vm2, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v114061_v38 = vadd.f32 %v114057_v42, %v113970_v8 (stack53)
        %v115604_v22 = vadd.s32 %v115600_v22, %v121564_v0 (stack40)
        %v116063_v12 = vadd.s32 %v116060_v25, %v121564_v0 (stack40)
        %v155253_v7 = vadd.f32 -2.5, %v155231_v50 (stack53)
        %v115219_v28 = vadd.s32 %v115216_v61, %v115211_v56 (stack40)
        %v116055_v60 = vadd.s32 %v116051_v60, %v121569_v1 (stack40)
        %v155258_v40 = vadd.s32 %v155165_v26, %v122657_v58 (stack40)
        %v114065_v45 = vmul.f32 %v114061_v38, %v155197_v29 (stack54)
        %v155264_v25 = vsel /*vm=*/%vm114418_vm8, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v155269_v47 = vsel /*vm=*/%vm114418_vm8, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v114466_v31 = vand.u32 2147483648, %v155231_v50 (stack72)
        %vm155272_vm9 = vcmp.eq.f32.partialorder %v113930_v53, 1.0 (stack68)
        %v114829_v10 = vand.u32.u8 255, %v114828_v44 (stack49)
        %v115221_v9 = vshll.u32 %v115216_v61, 16 (stack45)
        %v115222_v21 = vshrl.u32 %v115216_v61, 16 (stack46)
        %v115616_v56 = vadd.s32 2, %v115612_v55 (stack40)
        %v114069_v27 = vadd.f32 %v114065_v45, %v113966_v43 (stack53)
        %v116067_v34 = vadd.s32 1, %v116063_v12 (stack40)
        %v116496_v6 = vadd.s32 %v116493_v30, %v116488_v6 (stack40)
        %v116498_v23 = vshll.u32 %v116493_v30, 15 (stack45)
        %vm114463_vm10 = vcmp.eq.f32.partialorder %v155231_v50, inf (stack70)
        %v114830_v44 = vand.u32 65535, %v114829_v10 (stack50)
        %v115223_v53 = vor.u32 %v115222_v21, %v115221_v9 (stack47)
        %v115620_v46 = vadd.s32 %v115616_v56, %v115604_v22 (stack40)
        %v115622_v42 = vshll.u32 %v115616_v56, 13 (stack45)
        %v114073_v29 = vmul.f32 %v114069_v27, %v155197_v29 (stack54)
        %vm114465_vm11 = vcmp.eq.f32.partialorder %v155231_v50, 0.0 (stack71)
        %v115623_v8 = vshrl.u32 %v115616_v56, 19 (stack46)
        %v116071_v61 = vadd.s32 %v116067_v34, %v116055_v60 (stack40)
        %v116073_v55 = vshll.u32 %v116067_v34, 17 (stack45)
        %v114831_v43 = vshrl.u32 %v114830_v44, 1 (stack51)
        %v115224_v38 = vxor.u32 %v115223_v53, %v115219_v28 (stack48)
        %v116074_v22 = vshrl.u32 %v116067_v34, 15 (stack46)
        %v116499_v30 = vshrl.u32 %v116493_v30, 17 (stack46)
        %v114077_v32 = vadd.f32 %v114073_v29, %v113962_v32 (stack53)
        %v115624_v12 = vor.u32 %v115623_v8, %v115622_v42 (stack47)
        %vm116915_vm12 = vcmp.lt.u32.totalorder %v155165_v26, %v157077_v51 (stack43)
        %v116920_v48 = vadd.s32 %v157829_v52, %v157078_v48 (stack40)
        %v114832_v60 = vor.u32 16256, %v114831_v43 (stack47)
        %v115227_v28 = vadd.s32 %v115224_v38, %v115219_v28 (stack40)
        %v115233_v45 = vshll.u32 %v115224_v38, 24 (stack45)
        %v115234_v10 = vshrl.u32 %v115224_v38, 8 (stack46)
        %v114081_v24 = vmul.f32 %v114077_v32, %v155075_v24 (stack54)
        %v115625_v9 = vxor.u32 %v115624_v12, %v115620_v46 (stack48)
        %v116075_v21 = vor.u32 %v116074_v22, %v116073_v55 (stack47)
        %v116500_v56 = vor.u32 %v116499_v30, %v116498_v23 (stack47)
        %v121412_v27 = vpop.eup %121411 (stack73)
        %v114833_v34 = vand.u32.u16 65535, %v114832_v60 (stack52)
        %v115231_v23 = vadd.s32 %v115227_v28, %v121569_v1 (stack40)
        %v115235_v44 = vor.u32 %v115234_v10, %v115233_v45 (stack47)
        %v116924_v53 = vadd.s32 1, %v116920_v48 (stack40)
        %v114085_v35 = vsel /*vm=*/%vm155272_vm9, /*on_true_vy=*/%v155235_v35, /*on_false_vx=*/%v114081_v24 (stack44)
        %v114462_v20 = vmul.f32 %v121412_v27, %v155231_v50 (stack74)
        %v115628_v46 = vadd.s32 %v115625_v9, %v115620_v46 (stack40)
        %v115630_v42 = vshll.u32 %v115625_v9, 15 (stack45)
        %v114089_v29 = vmul.f32 1.4140625, %v114085_v35 (stack54)
        %v120358_v8 = vadd.low.f32.bf16 -1.0, %v114833_v34 (stack53)
        %v115236_v55 = vxor.u32 %v115235_v44, %v115227_v28 (stack48)
        %v115631_v43 = vshrl.u32 %v115625_v9, 17 (stack46)
        %v114464_v38 = vsel /*vm=*/%vm114463_vm10, /*on_true_vy=*/%v155231_v50, /*on_false_vx=*/%v114462_v20 (stack75)
        %v116076_v22 = vxor.u32 %v116075_v21, %v116071_v61 (stack48)
        %v116501_v30 = vxor.u32 %v116500_v56, %v116496_v6 (stack48)
        %v155295_v51 = vsel /*vm=*/%vm116915_vm12, /*on_true_vy=*/%v116924_v53, /*on_false_vx=*/%v116920_v48 (stack44)
        %v114092_v32 = vpack.c.bf16 %v157387_v11, %v114089_v29 (stack81)
        %v114467_v31 = vsel /*vm=*/%vm114465_vm11, /*on_true_vy=*/%v114466_v31, /*on_false_vx=*/%v114464_v38 (stack76)
        %v114842_v12 = vmul.f32 2.0, %v120358_v8 (stack54)
        %v115239_v48 = vadd.s32 %v115236_v55, %v121564_v0 (stack40)
        %v114470_v60 = vadd.f32 -3.0, %v114467_v31 (stack53)
        %v115632_v28 = vor.u32 %v115631_v43, %v115630_v42 (stack47)
        %v116079_v61 = vadd.s32 %v116076_v22, %v116071_v61 (stack40)
        %v116081_v45 = vshll.u32 %v116076_v22, 29 (stack45)
        %120355 = vst [vmem:[%s123356_s30 + $0x1f8] sm:$0xf] /*vst_source=*/%v114092_v32 (stack83)
        %v114846_v10 = vadd.f32 -0.99609375, %v114842_v12 (stack53)
        %v115243_v24 = vadd.s32 4, %v115239_v48 (stack40)
        %v116082_v9 = vshrl.u32 %v116076_v22, 3 (stack46)
        %v116504_v6 = vadd.s32 %v116501_v30, %v116496_v6 (stack40)
        %v155305_v7 = vsel /*vm=*/%vm114418_vm8, /*on_true_vy=*/%v155253_v7, /*on_false_vx=*/%v114470_v60 (stack44)
        %v115633_v21 = vxor.u32 %v115632_v28, %v115628_v46 (stack48)
        %v116506_v56 = vshll.u32 %v116501_v30, 26 (stack45)
        %v116507_v27 = vshrl.u32 %v116501_v30, 6 (stack46)
        %v114478_v47 = vmul.f32 %v155305_v7, %v155269_v47 (stack54)
        %v155309_v34 = vmax.f32 %v114846_v10, -0.99609375 (stack55)
        %v115247_v23 = vadd.s32 %v115243_v24, %v115231_v23 (stack40)
        %v115249_v44 = vshll.u32 %v115243_v24, 13 (stack45)
        %v115250_v53 = vshrl.u32 %v115243_v24, 19 (stack46)
        %v115636_v35 = vadd.s32 %v115633_v21, %v115628_v46 (stack40)
        %v115638_v20 = vshll.u32 %v115633_v21, 26 (stack45)
        %v115639_v46 = vshrl.u32 %v115633_v21, 6 (stack46)
        %v114391_v42 = vand.u32 2147483647, %v155172_v54 (stack77)
        %v155313_v29 = vmul.f32 inf, %v155172_v54 (stack54)
        %v114482_v25 = vadd.f32 %v114478_v47, %v155264_v25 (stack53)
        %v114862_v8 = vxor.u32 2147483648, %v155309_v34 (stack56)
        %v115251_v55 = vor.u32 %v115250_v53, %v115249_v44 (stack47)
        %v115640_v43 = vor.u32 %v115639_v46, %v115638_v20 (stack47)
        %v116083_v38 = vor.u32 %v116082_v9, %v116081_v45 (stack47)
        %v116508_v22 = vor.u32 %v116507_v27, %v116506_v56 (stack47)
        %v114447_v30 = vsel /*vm=*/%vm114418_vm8, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v114486_v32 = vmul.f32 %v114482_v25, %v155305_v7 (stack54)
        %v155322_v31 = vmul.f32 %v114862_v8, %v155309_v34 (stack54)
        %vm116910_vm13 = vcmp.lt.u32.totalorder %v155258_v40, %v155165_v26 (stack43)
        %v115252_v12 = vxor.u32 %v115251_v55, %v115247_v23 (stack48)
        %v115641_v48 = vxor.u32 %v115640_v43, %v115636_v35 (stack48)
        %v116084_v60 = vxor.u32 %v116083_v38, %v116079_v61 (stack48)
        %v116509_v28 = vxor.u32 %v116508_v22, %v116504_v6 (stack48)
        %v114435_v45 = vsel /*vm=*/%vm114418_vm8, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v114439_v10 = vsel /*vm=*/%vm114418_vm8, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v114490_v24 = vadd.f32 %v114486_v32, %v114447_v30 (stack53)
        %v114867_v9 = vadd.f32 1.0, %v155322_v31 (stack57)
        %v115255_v21 = vadd.s32 %v115252_v12, %v115247_v23 (stack40)
        %v115257_v56 = vshll.u32 %v115252_v12, 15 (stack45)
        %v115258_v27 = vshrl.u32 %v115252_v12, 17 (stack46)
        %v115644_v47 = vadd.s32 %v115641_v48, %v115636_v35 (stack40)
        %v114443_v23 = vsel /*vm=*/%vm114418_vm8, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v114494_v44 = vmul.f32 %v114490_v24, %v155305_v7 (stack54)
        %121413 = vlog2.f32 %v114867_v9 (stack58)
        %v116932_v53 = vadd.s32 1, %v155295_v51 (stack40)
        %v114870_v35 = vmul.f32 -0.5, %v155322_v31 (stack59)
        %v115259_v20 = vor.u32 %v115258_v27, %v115257_v56 (stack47)
        %v115650_v46 = vshll.u32 %v115641_v48, 6 (stack45)
        %v115651_v25 = vshrl.u32 %v115641_v48, 26 (stack46)
        %v114498_v8 = vadd.f32 %v114494_v44, %v114443_v23 (stack53)
        %v114873_v55 = vand.u32 2147483647, %v155322_v31 (stack60)
        %v116087_v61 = vadd.s32 %v116084_v60, %v116079_v61 (stack40)
        %v116089_v43 = vshll.u32 %v116084_v60, 16 (stack45)
        %v115260_v38 = vxor.u32 %v115259_v20, %v115255_v21 (stack48)
        %v115652_v22 = vor.u32 %v115651_v25, %v115650_v46 (stack47)
        %v116090_v30 = vshrl.u32 %v116084_v60, 16 (stack46)
        %v116512_v6 = vadd.s32 %v116509_v28, %v116504_v6 (stack40)
        %v114502_v32 = vmul.f32 %v114498_v8, %v155305_v7 (stack54)
        %v116518_v12 = vshll.u32 %v116509_v28, 6 (stack45)
        %v116519_v48 = vshrl.u32 %v116509_v28, 26 (stack46)
        %v116936_v26 = vsel /*vm=*/%vm116910_vm13, /*on_true_vy=*/%v116932_v53, /*on_false_vx=*/%v155295_v51 (stack44)
        %v115263_v51 = vadd.s32 %v115260_v38, %v115255_v21 (stack40)
        %v115265_v60 = vshll.u32 %v115260_v38, 26 (stack45)
        %v115266_v28 = vshrl.u32 %v115260_v38, 6 (stack46)
        %v115653_v24 = vxor.u32 %v115652_v22, %v115644_v47 (stack48)
        %v114506_v10 = vadd.f32 %v114502_v32, %v114439_v10 (stack53)
        %v114871_v9 = vadd.f32 1.0, %v114870_v35 (stack61)
        %v116091_v21 = vor.u32 %v116090_v30, %v116089_v43 (stack47)
        %v116520_v56 = vor.u32 %v116519_v48, %v116518_v12 (stack47)
        %v115267_v27 = vor.u32 %v115266_v28, %v115265_v60 (stack47)
        %v115656_v23 = vadd.s32 %v115653_v24, %v121569_v1 (stack40)
        %v116941_v44 = vadd.s32 %v116936_v26, %v121574_v2 (stack40)
        %v116945_v40 = vadd.s32 %v155258_v40, %v121569_v1 (stack40)
        %v114510_v53 = vmul.f32 %v114506_v10, %v155305_v7 (stack54)
        %v116092_v35 = vxor.u32 %v116091_v21, %v116087_v61 (stack48)
        %v116521_v20 = vxor.u32 %v116520_v56, %v116512_v6 (stack48)
        %v155352_v46 = vadd.s32 %v157828_v41, %v157079_v39 (stack40)
        %v115268_v25 = vxor.u32 %v115267_v27, %v115263_v51 (stack48)
        %v115648_v47 = vadd.s32 %v115644_v47, %v121574_v2 (stack40)
        %v115660_v8 = vadd.s32 3, %v115656_v23 (stack40)
        %v155355_v43 = vadd.s32 %v116945_v40, %v116941_v44 (stack40)
        %v114514_v45 = vadd.f32 %v114510_v53, %v114435_v45 (stack53)
        %v116095_v61 = vadd.s32 %v116092_v35, %v116087_v61 (stack40)
        %v116101_v38 = vshll.u32 %v116092_v35, 24 (stack45)
        %v116102_v22 = vshrl.u32 %v116092_v35, 8 (stack46)
        %v115271_v30 = vadd.s32 %v115268_v25, %v115263_v51 (stack40)
        %v115277_v32 = vshll.u32 %v115268_v25, 6 (stack45)
        %v115278_v12 = vshrl.u32 %v115268_v25, 26 (stack46)
        %v115664_v48 = vadd.s32 %v115660_v8, %v115648_v47 (stack40)
        %v114431_v26 = vsel /*vm=*/%vm114418_vm8, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v114518_v51 = vmul.f32 %v114514_v45, %v155305_v7 (stack54)
        %v115666_v60 = vshll.u32 %v115660_v8, 17 (stack45)
        %v115667_v28 = vshrl.u32 %v115660_v8, 15 (stack46)
        %v121414_v24 = vpop.eup %121413 (stack64)
        %vm155361_vm14 = vcmp.lt.f32.partialorder %v114873_v55, 0.0004427343 (stack62)
        %v115279_v10 = vor.u32 %v115278_v12, %v115277_v32 (stack47)
        %v116103_v21 = vor.u32 %v116102_v22, %v116101_v38 (stack47)
        %v116524_v56 = vadd.s32 %v116521_v20, %v121564_v0 (stack40)
        %v114522_v27 = vadd.f32 %v114518_v51, %v114431_v26 (stack53)
        %v114869_v23 = vmul.f32 0.6931472, %v121414_v24 (stack65)
        %v114872_v31 = vmul.f32 %v114871_v9, %v155322_v31 (stack63)
        %v115668_v9 = vor.u32 %v115667_v28, %v115666_v60 (stack47)
        %v115280_v44 = vxor.u32 %v115279_v10, %v115271_v30 (stack48)
        %v116104_v53 = vxor.u32 %v116103_v21, %v116095_v61 (stack48)
        %v116516_v6 = vadd.s32 %v116512_v6, %v121569_v1 (stack40)
        %v116528_v35 = vadd.s32 1, %v116524_v56 (stack40)
        %v114427_v20 = vsel /*vm=*/%vm114418_vm8, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v114526_v25 = vmul.f32 %v114522_v27, %v155305_v7 (stack54)
        %v114875_v47 = vsel /*vm=*/%vm155361_vm14, /*on_true_vy=*/%v114872_v31, /*on_false_vx=*/%v114869_v23 (stack66)
        %v115669_v8 = vxor.u32 %v115668_v9, %v115664_v48 (stack48)
        %vm155376_vm15 = vcmp.eq.f32.partialorder %v114391_v42, 1.0 (stack68)
        %v155380_v45 = vxor.u32 2147483648, %v114875_v47 (stack56)
        %v155382_v38 = vadd.s32 %v116528_v35, %v116516_v6 (stack40)
        %v116951_v22 = vshll.u32 %v116945_v40, 13 (stack45)
        %v116952_v40 = vshrl.u32 %v116945_v40, 19 (stack46)
        %v114530_v32 = vadd.f32 %v114526_v25, %v114427_v20 (stack53)
        %v115672_v12 = vadd.s32 %v115669_v8, %v115664_v48 (stack40)
        %v115674_v48 = vshll.u32 %v115669_v8, 29 (stack45)
        %v115675_v26 = vshrl.u32 %v115669_v8, 3 (stack46)
        %v114423_v50 = vsel /*vm=*/%vm114418_vm8, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %vm114879_vm0 = vcmp.lt.f32.partialorder %v155380_v45, 5.0 (stack68)
        %121415 = vrsqrt.f32 %v155380_v45 (stack67)
        %v115283_v51 = vadd.s32 %v115280_v44, %v121574_v2 (stack40)
        %v114534_v7 = vmul.f32 %v114530_v32, %v155305_v7 (stack54)
        %v114852_v60 = vand.u32 2147483647, %v155309_v34 (stack77)
        %v116099_v61 = vadd.s32 %v116095_v61, %v121564_v0 (stack40)
        %v116107_v28 = vadd.s32 %v116104_v53, %v121574_v2 (stack40)
        %v115275_v30 = vadd.s32 %v115271_v30, %v121564_v0 (stack40)
        %v115676_v24 = vor.u32 %v115675_v26, %v115674_v48 (stack47)
        %v116953_v55 = vor.u32 %v116952_v40, %v116951_v22 (stack47)
        %v155397_v10 = vadd.s32 %v155352_v46, %v122657_v58 (stack40)
        %v114538_v21 = vadd.f32 %v114534_v7, %v114423_v50 (stack53)
        %v155402_v56 = vsel /*vm=*/%vm114879_vm0, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v155407_v27 = vsel /*vm=*/%vm114879_vm0, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v155410_v23 = vadd.f32 -2.5, %v155380_v45 (stack53)
        %v155415_v31 = vsel /*vm=*/%vm114879_vm0, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v155420_v9 = vsel /*vm=*/%vm114879_vm0, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v115287_v44 = vadd.s32 5, %v115283_v51 (stack40)
        %v115677_v53 = vxor.u32 %v115676_v24, %v115672_v12 (stack48)
        %v114542_v54 = vmul.f32 %v114538_v21, %v155172_v54 (stack54)
        %v116111_v6 = vadd.s32 2, %v116107_v28 (stack40)
        %v116534_v20 = vshll.u32 %v116528_v35, 17 (stack45)
        %v116535_v35 = vshrl.u32 %v116528_v35, 15 (stack46)
        %v115289_v25 = vxor.u32 %v115287_v44, %v115275_v30 (stack48)
        %v115680_v47 = vadd.s32 %v115677_v53, %v115672_v12 (stack40)
        %v115682_v8 = vshll.u32 %v115677_v53, 16 (stack45)
        %v115683_v22 = vshrl.u32 %v115677_v53, 16 (stack46)
        %v114546_v29 = vsel /*vm=*/%vm155376_vm15, /*on_true_vy=*/%v155313_v29, /*on_false_vx=*/%v114542_v54 (stack44)
        %vm114924_vm1 = vcmp.eq.f32.partialorder %v155380_v45, inf (stack70)
        %v116115_v42 = vadd.s32 %v116111_v6, %v116099_v61 (stack40)
        %v116117_v40 = vshll.u32 %v116111_v6, 13 (stack45)
        %v116118_v32 = vshrl.u32 %v116111_v6, 19 (stack46)
        %v114550_v12 = vmul.f32 1.4140625, %v114546_v29 (stack54)
        %v115290_v48 = vand.u32.u8 255, %v115289_v25 (stack49)
        %v115684_v26 = vor.u32 %v115683_v22, %v115682_v8 (stack47)
        %v116536_v50 = vor.u32 %v116535_v35, %v116534_v20 (stack47)
        %vm114926_vm2 = vcmp.eq.f32.partialorder %v155380_v45, 0.0 (stack71)
        %v116119_v51 = vor.u32 %v116118_v32, %v116117_v40 (stack47)
        %v116954_v7 = vxor.u32 %v116953_v55, %v155355_v43 (stack48)
        %vm117376_vm3 = vcmp.lt.u32.totalorder %v155352_v46, %v157079_v39 (stack43)
        %v114553_v61 = vpack.c.bf16 %v157387_v11, %v114550_v12 (stack81)
        %v115291_v28 = vand.u32 65535, %v115290_v48 (stack50)
        %v115685_v30 = vxor.u32 %v115684_v26, %v115680_v47 (stack48)
        %v116537_v24 = vxor.u32 %v116536_v50, %v155382_v38 (stack48)
        %v116120_v55 = vxor.u32 %v116119_v51, %v116115_v42 (stack48)
        %v116957_v43 = vadd.s32 %v116954_v7, %v155355_v43 (stack40)
        %v116959_v21 = vshll.u32 %v116954_v7, 15 (stack45)
        %v116960_v44 = vshrl.u32 %v116954_v7, 17 (stack46)
        %120357 = vst [vmem:[%s123356_s30 + $0x278] sm:$0xf] /*vst_source=*/%v114553_v61 (stack83)
        %v115292_v53 = vshrl.u32 %v115291_v28, 1 (stack51)
        %v115688_v54 = vadd.s32 %v115685_v30, %v115680_v47 (stack40)
        %v115694_v6 = vshll.u32 %v115685_v30, 24 (stack45)
        %v115695_v20 = vshrl.u32 %v115685_v30, 8 (stack46)
        %v121416_v35 = vpop.eup %121415 (stack73)
        %v116123_v25 = vadd.s32 %v116120_v55, %v116115_v42 (stack40)
        %v116125_v47 = vshll.u32 %v116120_v55, 15 (stack45)
        %v116126_v8 = vshrl.u32 %v116120_v55, 17 (stack46)
        %v116540_v38 = vadd.s32 %v116537_v24, %v155382_v38 (stack40)
        %v114923_v22 = vmul.f32 %v121416_v35, %v155380_v45 (stack74)
        %v114927_v29 = vand.u32 2147483648, %v155380_v45 (stack72)
        %v115293_v42 = vor.u32 16256, %v115292_v53 (stack47)
        %v115696_v40 = vor.u32 %v115695_v20, %v115694_v6 (stack47)
        %v116127_v32 = vor.u32 %v116126_v8, %v116125_v47 (stack47)
        %v116542_v12 = vshll.u32 %v116537_v24, 29 (stack45)
        %v116543_v48 = vshrl.u32 %v116537_v24, 3 (stack46)
        %v116961_v26 = vor.u32 %v116960_v44, %v116959_v21 (stack47)
        %v114925_v50 = vsel /*vm=*/%vm114924_vm1, /*on_true_vy=*/%v155380_v45, /*on_false_vx=*/%v114923_v22 (stack75)
        %v115294_v51 = vand.u32.u16 65535, %v115293_v42 (stack52)
        %v115697_v7 = vxor.u32 %v115696_v40, %v115688_v54 (stack48)
        %v117381_v49 = vadd.s32 %v157829_v52, %v157082_v49 (stack40)
        %v114928_v61 = vsel /*vm=*/%vm114926_vm2, /*on_true_vy=*/%v114927_v29, /*on_false_vx=*/%v114925_v50 (stack76)
        %v116128_v28 = vxor.u32 %v116127_v32, %v116123_v25 (stack48)
        %v116544_v30 = vor.u32 %v116543_v48, %v116542_v12 (stack47)
        %v116962_v24 = vxor.u32 %v116961_v26, %v116957_v43 (stack48)
        %v114931_v55 = vadd.f32 -3.0, %v114928_v61 (stack53)
        %v120360_v21 = vadd.low.f32.bf16 -1.0, %v115294_v51 (stack53)
        %v115692_v44 = vadd.s32 %v115688_v54, %v121569_v1 (stack40)
        %v115700_v53 = vadd.s32 %v115697_v7, %v121564_v0 (stack40)
        %v116131_v54 = vadd.s32 %v116128_v28, %v116123_v25 (stack40)
        %v116133_v6 = vshll.u32 %v116128_v28, 26 (stack45)
        %v116134_v20 = vshrl.u32 %v116128_v28, 6 (stack46)
        %v116545_v35 = vxor.u32 %v116544_v30, %v116540_v38 (stack48)
        %v155450_v23 = vsel /*vm=*/%vm114879_vm0, /*on_true_vy=*/%v155410_v23, /*on_false_vx=*/%v114931_v55 (stack44)
        %v115303_v25 = vmul.f32 2.0, %v120360_v21 (stack54)
        %v115704_v47 = vadd.s32 4, %v115700_v53 (stack40)
        %v155452_v43 = vadd.s32 %v116962_v24, %v116957_v43 (stack40)
        %v114939_v9 = vmul.f32 %v155450_v23, %v155420_v9 (stack54)
        %v116135_v8 = vor.u32 %v116134_v20, %v116133_v6 (stack47)
        %v116548_v38 = vadd.s32 %v116545_v35, %v116540_v38 (stack40)
        %v117385_v22 = vadd.s32 1, %v117381_v49 (stack40)
        %v115307_v29 = vadd.f32 -0.99609375, %v115303_v25 (stack53)
        %v115708_v42 = vadd.s32 %v115704_v47, %v115692_v44 (stack40)
        %v115710_v40 = vshll.u32 %v115704_v47, 13 (stack45)
        %v115711_v32 = vshrl.u32 %v115704_v47, 19 (stack46)
        %v114943_v31 = vadd.f32 %v114939_v9, %v155415_v31 (stack53)
        %v116136_v12 = vxor.u32 %v116135_v8, %v116131_v54 (stack48)
        %v116550_v48 = vshll.u32 %v116545_v35, 16 (stack45)
        %v116551_v26 = vshrl.u32 %v116545_v35, 16 (stack46)
        %v114908_v50 = vsel /*vm=*/%vm114879_vm0, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v155460_v51 = vmax.f32 %v115307_v29, -0.99609375 (stack55)
        %v115712_v7 = vor.u32 %v115711_v32, %v115710_v40 (stack47)
        %v117389_v39 = vsel /*vm=*/%vm117376_vm3, /*on_true_vy=*/%v117385_v22, /*on_false_vx=*/%v117381_v49 (stack44)
        %v114947_v49 = vmul.f32 %v114943_v31, %v155450_v23 (stack54)
        %v116139_v61 = vadd.s32 %v116136_v12, %v116131_v54 (stack40)
        %v116145_v28 = vshll.u32 %v116136_v12, 6 (stack45)
        %v116146_v30 = vshrl.u32 %v116136_v12, 26 (stack46)
        %v115323_v55 = vxor.u32 2147483648, %v155460_v51 (stack56)
        %v115713_v21 = vxor.u32 %v115712_v7, %v115708_v42 (stack48)
        %v116967_v44 = vshll.u32 %v116962_v24, 26 (stack45)
        %v116968_v24 = vshrl.u32 %v116962_v24, 6 (stack46)
        %v114896_v53 = vsel /*vm=*/%vm114879_vm0, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v114951_v54 = vadd.f32 %v114947_v49, %v114908_v50 (stack53)
        %v116147_v6 = vor.u32 %v116146_v30, %v116145_v28 (stack47)
        %v116552_v20 = vor.u32 %v116551_v26, %v116550_v48 (stack47)
        %v114900_v35 = vsel /*vm=*/%vm114879_vm0, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v155474_v25 = vmul.f32 %v115323_v55, %v155460_v51 (stack54)
        %v115716_v47 = vadd.s32 %v115713_v21, %v115708_v42 (stack40)
        %v115718_v9 = vshll.u32 %v115713_v21, 15 (stack45)
        %v114955_v8 = vmul.f32 %v114951_v54, %v155450_v23 (stack54)
        %v115719_v22 = vshrl.u32 %v115713_v21, 17 (stack46)
        %v116148_v29 = vxor.u32 %v116147_v6, %v116139_v61 (stack48)
        %v116553_v42 = vxor.u32 %v116552_v20, %v116548_v38 (stack48)
        %v114904_v40 = vsel /*vm=*/%vm114879_vm0, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v115328_v32 = vadd.f32 1.0, %v155474_v25 (stack57)
        %v115331_v31 = vmul.f32 -0.5, %v155474_v25 (stack59)
        %v116969_v12 = vor.u32 %v116968_v24, %v116967_v44 (stack47)
        %v114959_v48 = vadd.f32 %v114955_v8, %v114904_v40 (stack53)
        %v115720_v26 = vor.u32 %v115719_v22, %v115718_v9 (stack47)
        %v116151_v50 = vadd.s32 %v116148_v29, %v121569_v1 (stack40)
        %v116556_v38 = vadd.s32 %v116553_v42, %v116548_v38 (stack40)
        %121417 = vlog2.f32 %v115328_v32 (stack58)
        %v116143_v7 = vadd.s32 %v116139_v61, %v121574_v2 (stack40)
        %v116562_v49 = vshll.u32 %v116553_v42, 24 (stack45)
        %vm117371_vm4 = vcmp.lt.u32.totalorder %v155397_v10, %v155352_v46 (stack43)
        %v114963_v61 = vmul.f32 %v114959_v48, %v155450_v23 (stack54)
        %v115334_v28 = vand.u32 2147483647, %v155474_v25 (stack60)
        %v115721_v30 = vxor.u32 %v115720_v26, %v115716_v47 (stack48)
        %v116155_v55 = vadd.s32 3, %v116151_v50 (stack40)
        %v115332_v21 = vadd.f32 1.0, %v115331_v31 (stack61)
        %v116563_v44 = vshrl.u32 %v116553_v42, 8 (stack46)
        %v116970_v24 = vxor.u32 %v116969_v12, %v155452_v43 (stack48)
        %v117393_v54 = vadd.s32 1, %v117389_v39 (stack40)
        %v114967_v6 = vadd.f32 %v114963_v61, %v114900_v35 (stack53)
        %v115724_v20 = vadd.s32 %v115721_v30, %v115716_v47 (stack40)
        %v115726_v35 = vshll.u32 %v115721_v30, 26 (stack45)
        %v115727_v47 = vshrl.u32 %v115721_v30, 6 (stack46)
        %v116159_v9 = vadd.s32 %v116155_v55, %v116143_v7 (stack40)
        %v116161_v8 = vshll.u32 %v116155_v55, 17 (stack45)
        %v116162_v22 = vshrl.u32 %v116155_v55, 15 (stack46)
        %v116564_v29 = vor.u32 %v116563_v44, %v116562_v49 (stack47)
        %v114971_v42 = vmul.f32 %v114967_v6, %v155450_v23 (stack54)
        %v115728_v40 = vor.u32 %v115727_v47, %v115726_v35 (stack47)
        %v116973_v43 = vadd.s32 %v116970_v24, %v155452_v43 (stack40)
        %v116979_v32 = vshll.u32 %v116970_v24, 6 (stack45)
        %v116163_v31 = vor.u32 %v116162_v22, %v116161_v8 (stack47)
        %v116565_v12 = vxor.u32 %v116564_v29, %v116556_v38 (stack48)
        %v116980_v48 = vshrl.u32 %v116970_v24, 26 (stack46)
        %v117397_v46 = vsel /*vm=*/%vm117371_vm4, /*on_true_vy=*/%v117393_v54, /*on_false_vx=*/%v117389_v39 (stack44)
        %v114975_v39 = vadd.f32 %v114971_v42, %v114896_v53 (stack53)
        %vm155494_vm5 = vcmp.lt.f32.partialorder %v115334_v28, 0.0004427343 (stack62)
        %v115729_v26 = vxor.u32 %v115728_v40, %v115724_v20 (stack48)
        %v116560_v50 = vadd.s32 %v116556_v38, %v121564_v0 (stack40)
        %v116164_v38 = vxor.u32 %v116163_v31, %v116159_v9 (stack48)
        %v116568_v7 = vadd.s32 %v116565_v12, %v121574_v2 (stack40)
        %v116981_v49 = vor.u32 %v116980_v48, %v116979_v32 (stack47)
        %v117402_v61 = vadd.s32 %v117397_v46, %v121574_v2 (stack40)
        %v114979_v28 = vmul.f32 %v114975_v39, %v155450_v23 (stack54)
        %v115732_v30 = vadd.s32 %v115729_v26, %v115724_v20 (stack40)
        %v115738_v55 = vshll.u32 %v115729_v26, 6 (stack45)
        %v115739_v44 = vshrl.u32 %v115729_v26, 26 (stack46)
        %v116167_v24 = vadd.s32 %v116164_v38, %v116159_v9 (stack40)
        %v116169_v54 = vshll.u32 %v116164_v38, 29 (stack45)
        %v116170_v6 = vshrl.u32 %v116164_v38, 3 (stack46)
        %v116572_v20 = vadd.s32 2, %v116568_v7 (stack40)
        %v114983_v27 = vadd.f32 %v114979_v28, %v155407_v27 (stack53)
        %v115740_v35 = vor.u32 %v115739_v44, %v115738_v55 (stack47)
        %v116982_v47 = vxor.u32 %v116981_v49, %v116973_v43 (stack48)
        %v155505_v10 = vadd.s32 %v155397_v10, %v121569_v1 (stack40)
        %v116171_v9 = vor.u32 %v116170_v6, %v116169_v54 (stack47)
        %v116576_v8 = vadd.s32 %v116572_v20, %v116560_v50 (stack40)
        %v116578_v22 = vshll.u32 %v116572_v20, 13 (stack45)
        %v116579_v29 = vshrl.u32 %v116572_v20, 19 (stack46)
        %v121418_v42 = vpop.eup %121417 (stack64)
        %v114987_v40 = vmul.f32 %v114983_v27, %v155450_v23 (stack54)
        %v115741_v32 = vxor.u32 %v115740_v35, %v115732_v30 (stack48)
        %v116985_v31 = vadd.s32 %v116982_v47, %v121564_v0 (stack40)
        %v155510_v12 = vadd.s32 %v155505_v10, %v117402_v61 (stack40)
        %v115330_v48 = vmul.f32 0.6931472, %v121418_v42 (stack65)
        %v115333_v25 = vmul.f32 %v115332_v21, %v155474_v25 (stack63)
        %v116172_v21 = vxor.u32 %v116171_v9, %v116167_v24 (stack48)
        %v116580_v46 = vor.u32 %v116579_v29, %v116578_v22 (stack47)
        %v114991_v56 = vadd.f32 %v114987_v40, %v155402_v56 (stack53)
        %v115744_v39 = vadd.s32 %v115741_v32, %v121574_v2 (stack40)
        %v116977_v43 = vadd.s32 %v116973_v43, %v121569_v1 (stack40)
        %v116989_v26 = vadd.s32 1, %v116985_v31 (stack40)
        %v115336_v53 = vsel /*vm=*/%vm155494_vm5, /*on_true_vy=*/%v115333_v25, /*on_false_vx=*/%v115330_v48 (stack66)
        %v116175_v50 = vadd.s32 %v116172_v21, %v116167_v24 (stack40)
        %v116177_v38 = vshll.u32 %v116172_v21, 16 (stack45)
        %v116178_v7 = vshrl.u32 %v116172_v21, 16 (stack46)
        %v114995_v23 = vmul.f32 %v114991_v56, %v155450_v23 (stack54)
        %v155519_v49 = vxor.u32 2147483648, %v115336_v53 (stack56)
        %v115748_v61 = vadd.s32 5, %v115744_v39 (stack40)
        %v116581_v28 = vxor.u32 %v116580_v46, %v116576_v8 (stack48)
        %v114884_v45 = vsel /*vm=*/%vm114879_vm0, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v115736_v30 = vadd.s32 %v115732_v30, %v121564_v0 (stack40)
        %v116179_v55 = vor.u32 %v116178_v7, %v116177_v38 (stack47)
        %v116993_v44 = vadd.s32 %v116989_v26, %v116977_v43 (stack40)
        %v114999_v24 = vadd.f32 %v114995_v23, %v114884_v45 (stack53)
        %121419 = vrsqrt.f32 %v155519_v49 (stack67)
        %v114860_v54 = vmul.f32 inf, %v155309_v34 (stack54)
        %vm115340_vm6 = vcmp.lt.f32.partialorder %v155519_v49, 5.0 (stack68)
        %v115750_v6 = vxor.u32 %v115748_v61, %v115736_v30 (stack48)
        %vm114855_vm7 = vcmp.eq.f32.partialorder %v114852_v60, 1.0 (stack68)
        %v115003_v34 = vmul.f32 %v114999_v24, %v155309_v34 (stack54)
        %v117412_v60 = vshll.u32 %v155505_v10, 13 (stack45)
        %v117413_v20 = vshrl.u32 %v155505_v10, 19 (stack46)
        %v155534_v27 = vadd.f32 -2.5, %v155519_v49 (stack53)
        %v116180_v35 = vxor.u32 %v116179_v55, %v116175_v50 (stack48)
        %v116995_v47 = vshll.u32 %v116989_v26, 17 (stack45)
        %v116996_v10 = vshrl.u32 %v116989_v26, 15 (stack46)
        %v115007_v9 = vsel /*vm=*/%vm114855_vm7, /*on_true_vy=*/%v114860_v54, /*on_false_vx=*/%v115003_v34 (stack44)
        %v155539_v22 = vsel /*vm=*/%vm115340_vm6, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v155544_v29 = vsel /*vm=*/%vm115340_vm6, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v155549_v42 = vsel /*vm=*/%vm115340_vm6, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v115011_v40 = vmul.f32 1.4140625, %v115007_v9 (stack54)
        %v115751_v32 = vand.u32.u8 255, %v115750_v6 (stack49)
        %v116183_v31 = vadd.s32 %v116180_v35, %v116175_v50 (stack40)
        %v116189_v48 = vshll.u32 %v116180_v35, 24 (stack45)
        %v116190_v25 = vshrl.u32 %v116180_v35, 8 (stack46)
        %v116584_v8 = vadd.s32 %v116581_v28, %v116576_v8 (stack40)
        %v116586_v21 = vshll.u32 %v116581_v28, 15 (stack45)
        %v116587_v46 = vshrl.u32 %v116581_v28, 17 (stack46)
        %v115014_v56 = vpack.c.bf16 %v157387_v11, %v115011_v40 (stack81)
        %vm115385_vm8 = vcmp.eq.f32.partialorder %v155519_v49, inf (stack70)
        %v115752_v39 = vand.u32 65535, %v115751_v32 (stack50)
        %v116997_v43 = vor.u32 %v116996_v10, %v116995_v47 (stack47)
        %vm115387_vm9 = vcmp.eq.f32.partialorder %v155519_v49, 0.0 (stack71)
        %v116191_v26 = vor.u32 %v116190_v25, %v116189_v48 (stack47)
        %v116588_v53 = vor.u32 %v116587_v46, %v116586_v21 (stack47)
        %v117414_v50 = vor.u32 %v117413_v20, %v117412_v60 (stack47)
        %v155556_v38 = vadd.s32 %v157828_v41, %v157083_v59 (stack40)
        %120359 = vst [vmem:[%s123356_s30 + $0x2f8] sm:$0xf] /*vst_source=*/%v115014_v56 (stack83)
        %v115753_v7 = vshrl.u32 %v115752_v39, 1 (stack51)
        %v116998_v23 = vxor.u32 %v116997_v43, %v116993_v44 (stack48)
        %v155561_v16 = vadd.s32 %v157829_v52, %v157084_v16 (stack40)
        %v155565_v61 = vadd.s32 %v157828_v41, %v157089_v17 (stack40)
        %v115388_v28 = vand.u32 2147483648, %v155519_v49 (stack72)
        %v116192_v45 = vxor.u32 %v116191_v26, %v116183_v31 (stack48)
        %v116589_v30 = vxor.u32 %v116588_v53, %v116584_v8 (stack48)
        %v117415_v55 = vxor.u32 %v117414_v50, %v155510_v12 (stack48)
        %v115754_v24 = vor.u32 16256, %v115753_v7 (stack47)
        %v117001_v44 = vadd.s32 %v116998_v23, %v116993_v44 (stack40)
        %v117003_v54 = vshll.u32 %v116998_v23, 29 (stack45)
        %v117004_v6 = vshrl.u32 %v116998_v23, 3 (stack46)
        %v116195_v34 = vadd.s32 %v116192_v45, %v121564_v0 (stack40)
        %v116592_v60 = vadd.s32 %v116589_v30, %v116584_v8 (stack40)
        %v116594_v20 = vshll.u32 %v116589_v30, 26 (stack45)
        %v116595_v35 = vshrl.u32 %v116589_v30, 6 (stack46)
        %v121420_v47 = vpop.eup %121419 (stack73)
        %v115755_v10 = vand.u32.u16 65535, %v115754_v24 (stack52)
        %v116187_v9 = vadd.s32 %v116183_v31, %v121569_v1 (stack40)
        %v117005_v40 = vor.u32 %v117004_v6, %v117003_v54 (stack47)
        %v155572_v12 = vadd.s32 %v117415_v55, %v155510_v12 (stack40)
        %v115384_v32 = vmul.f32 %v121420_v47, %v155519_v49 (stack74)
        %v116199_v31 = vadd.s32 4, %v116195_v34 (stack40)
        %v116596_v48 = vor.u32 %v116595_v35, %v116594_v20 (stack47)
        %v117420_v25 = vshll.u32 %v117415_v55, 15 (stack45)
        %v120362_v8 = vadd.low.f32.bf16 -1.0, %v115755_v10 (stack53)
        %v117006_v21 = vxor.u32 %v117005_v40, %v117001_v44 (stack48)
        %v117421_v46 = vshrl.u32 %v117415_v55, 17 (stack46)
        %vm117837_vm10 = vcmp.lt.u32.totalorder %v155556_v38, %v157083_v59 (stack43)
        %v115386_v56 = vsel /*vm=*/%vm115385_vm8, /*on_true_vy=*/%v155519_v49, /*on_false_vx=*/%v115384_v32 (stack75)
        %v116203_v39 = vadd.s32 %v116199_v31, %v116187_v9 (stack40)
        %v116205_v43 = vshll.u32 %v116199_v31, 13 (stack45)
        %v116206_v26 = vshrl.u32 %v116199_v31, 19 (stack46)
        %v115389_v53 = vsel /*vm=*/%vm115387_vm9, /*on_true_vy=*/%v115388_v28, /*on_false_vx=*/%v115386_v56 (stack76)
        %v115764_v50 = vmul.f32 2.0, %v120362_v8 (stack54)
        %v116597_v7 = vxor.u32 %v116596_v48, %v116592_v60 (stack48)
        %v117009_v23 = vadd.s32 %v117006_v21, %v117001_v44 (stack40)
        %v115392_v28 = vadd.f32 -3.0, %v115389_v53 (stack53)
        %v116207_v45 = vor.u32 %v116206_v26, %v116205_v43 (stack47)
        %v117011_v30 = vshll.u32 %v117006_v21, 16 (stack45)
        %v117012_v55 = vshrl.u32 %v117006_v21, 16 (stack46)
        %v115768_v24 = vadd.f32 -0.99609375, %v115764_v50 (stack53)
        %v116600_v44 = vadd.s32 %v116597_v7, %v116592_v60 (stack40)
        %v116606_v54 = vshll.u32 %v116597_v7, 6 (stack45)
        %v116607_v6 = vshrl.u32 %v116597_v7, 26 (stack46)
        %v115377_v34 = vsel /*vm=*/%vm115340_vm6, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v155588_v27 = vsel /*vm=*/%vm115340_vm6, /*on_true_vy=*/%v155534_v27, /*on_false_vx=*/%v115392_v28 (stack44)
        %v116208_v60 = vxor.u32 %v116207_v45, %v116203_v39 (stack48)
        %v117013_v20 = vor.u32 %v117012_v55, %v117011_v30 (stack47)
        %v115400_v35 = vmul.f32 %v155588_v27, %v115377_v34 (stack54)
        %v155591_v47 = vmax.f32 %v115768_v24, -0.99609375 (stack55)
        %v116608_v10 = vor.u32 %v116607_v6, %v116606_v54 (stack47)
        %v117422_v9 = vor.u32 %v117421_v46, %v117420_v25 (stack47)
        %v116211_v40 = vadd.s32 %v116208_v60, %v116203_v39 (stack40)
        %v116213_v32 = vshll.u32 %v116208_v60, 15 (stack45)
        %v116214_v31 = vshrl.u32 %v116208_v60, 17 (stack46)
        %v117014_v48 = vxor.u32 %v117013_v20, %v117009_v23 (stack48)
        %v155596_v25 = vsel /*vm=*/%vm115340_vm6, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v115361_v8 = vsel /*vm=*/%vm115340_vm6, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v115404_v42 = vadd.f32 %v115400_v35, %v155549_v42 (stack53)
        %v115784_v21 = vxor.u32 2147483648, %v155591_v47 (stack56)
        %v115365_v46 = vsel /*vm=*/%vm115340_vm6, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v116215_v56 = vor.u32 %v116214_v31, %v116213_v32 (stack47)
        %v116609_v39 = vxor.u32 %v116608_v10, %v116600_v44 (stack48)
        %v117017_v43 = vadd.s32 %v117014_v48, %v117009_v23 (stack40)
        %v115369_v26 = vsel /*vm=*/%vm115340_vm6, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v115408_v53 = vmul.f32 %v115404_v42, %v155588_v27 (stack54)
        %v115787_v50 = vmul.f32 %v115784_v21, %v155591_v47 (stack54)
        %v155613_v7 = vadd.s32 %v155556_v38, %v122657_v58 (stack40)
        %v116216_v23 = vxor.u32 %v116215_v56, %v116211_v40 (stack48)
        %v116604_v28 = vadd.s32 %v116600_v44, %v121574_v2 (stack40)
        %v116612_v45 = vadd.s32 %v116609_v39, %v121569_v1 (stack40)
        %v117423_v30 = vxor.u32 %v117422_v9, %v155572_v12 (stack48)
        %v115412_v55 = vadd.f32 %v115408_v53, %v115369_v26 (stack53)
        %v115789_v24 = vadd.f32 1.0, %v115787_v50 (stack57)
        %v117023_v44 = vshll.u32 %v117014_v48, 24 (stack45)
        %v117024_v54 = vshrl.u32 %v117014_v48, 8 (stack46)
        %v116219_v6 = vadd.s32 %v116216_v23, %v116211_v40 (stack40)
        %v116221_v34 = vshll.u32 %v116216_v23, 26 (stack45)
        %v116222_v60 = vshrl.u32 %v116216_v23, 6 (stack46)
        %v116616_v20 = vadd.s32 3, %v116612_v45 (stack40)
        %v115416_v35 = vmul.f32 %v115412_v55, %v155588_v27 (stack54)
        %121421 = vlog2.f32 %v115789_v24 (stack58)
        %v115792_v10 = vmul.f32 -0.5, %v115787_v50 (stack59)
        %v117021_v9 = vadd.s32 %v117017_v43, %v121564_v0 (stack40)
        %v116223_v40 = vor.u32 %v116222_v60, %v116221_v34 (stack47)
        %v116620_v32 = vadd.s32 %v116616_v20, %v116604_v28 (stack40)
        %v116622_v31 = vshll.u32 %v116616_v20, 17 (stack45)
        %v116623_v48 = vshrl.u32 %v116616_v20, 15 (stack46)
        %vm117832_vm11 = vcmp.lt.u32.totalorder %v155613_v7, %v155556_v38 (stack43)
        %v115420_v42 = vadd.f32 %v115416_v35, %v115365_v46 (stack53)
        %v115795_v21 = vand.u32 2147483647, %v115787_v50 (stack60)
        %v117025_v46 = vor.u32 %v117024_v54, %v117023_v44 (stack47)
        %v117426_v12 = vadd.s32 %v117423_v30, %v155572_v12 (stack40)
        %v116224_v56 = vxor.u32 %v116223_v40, %v116219_v6 (stack48)
        %v116624_v39 = vor.u32 %v116623_v48, %v116622_v31 (stack47)
        %v117428_v26 = vshll.u32 %v117423_v30, 26 (stack45)
        %v117429_v53 = vshrl.u32 %v117423_v30, 6 (stack46)
        %v115424_v23 = vmul.f32 %v115420_v42, %v155588_v27 (stack54)
        %v115793_v28 = vadd.f32 1.0, %v115792_v10 (stack61)
        %v117026_v43 = vxor.u32 %v117025_v46, %v117017_v43 (stack48)
        %v117846_v45 = vadd.s32 1, %v155561_v16 (stack40)
        %v116227_v30 = vadd.s32 %v116224_v56, %v116219_v6 (stack40)
        %v116233_v55 = vshll.u32 %v116224_v56, 6 (stack45)
        %v116234_v24 = vshrl.u32 %v116224_v56, 26 (stack46)
        %v116625_v44 = vxor.u32 %v116624_v39, %v116620_v32 (stack48)
        %v115428_v8 = vadd.f32 %v115424_v23, %v115361_v8 (stack53)
        %v117029_v54 = vadd.s32 %v117026_v43, %v121574_v2 (stack40)
        %v117430_v6 = vor.u32 %v117429_v53, %v117428_v26 (stack47)
        %v117850_v59 = vsel /*vm=*/%vm117837_vm10, /*on_true_vy=*/%v117846_v45, /*on_false_vx=*/%v155561_v16 (stack44)
        %vm155630_vm12 = vcmp.lt.f32.partialorder %v115795_v21, 0.0004427343 (stack62)
        %v116235_v34 = vor.u32 %v116234_v24, %v116233_v55 (stack47)
        %v116628_v60 = vadd.s32 %v116625_v44, %v116620_v32 (stack40)
        %v116630_v20 = vshll.u32 %v116625_v44, 29 (stack45)
        %v115432_v35 = vmul.f32 %v115428_v8, %v155588_v27 (stack54)
        %v116631_v10 = vshrl.u32 %v116625_v44, 3 (stack46)
        %v117033_v40 = vadd.s32 2, %v117029_v54 (stack40)
        %v117431_v32 = vxor.u32 %v117430_v6, %v117426_v12 (stack48)
        %v115794_v50 = vmul.f32 %v115793_v28, %v115787_v50 (stack63)
        %v116236_v31 = vxor.u32 %v116235_v34, %v116227_v30 (stack48)
        %v117854_v48 = vadd.s32 1, %v117850_v59 (stack40)
        %v117867_v42 = vadd.s32 %v155613_v7, %v121569_v1 (stack40)
        %v115436_v25 = vadd.f32 %v115432_v35, %v155596_v25 (stack53)
        %v116632_v21 = vor.u32 %v116631_v10, %v116630_v20 (stack47)
        %v117037_v9 = vadd.s32 %v117033_v40, %v117021_v9 (stack40)
        %v117039_v46 = vshll.u32 %v117033_v40, 13 (stack45)
        %v116239_v56 = vadd.s32 %v116236_v31, %v121574_v2 (stack40)
        %v117040_v39 = vshrl.u32 %v117033_v40, 19 (stack46)
        %v117434_v12 = vadd.s32 %v117431_v32, %v117426_v12 (stack40)
        %v117440_v26 = vshll.u32 %v117431_v32, 6 (stack45)
        %v115440_v53 = vmul.f32 %v115436_v25, %v155588_v27 (stack54)
        %v116633_v23 = vxor.u32 %v116632_v21, %v116628_v60 (stack48)
        %v117441_v28 = vshrl.u32 %v117431_v32, 26 (stack46)
        %v117858_v38 = vsel /*vm=*/%vm117832_vm11, /*on_true_vy=*/%v117854_v48, /*on_false_vx=*/%v117850_v59 (stack44)
        %v121422_v7 = vpop.eup %121421 (stack64)
        %v116231_v43 = vadd.s32 %v116227_v30, %v121564_v0 (stack40)
        %v116243_v45 = vadd.s32 5, %v116239_v56 (stack40)
        %v117041_v30 = vor.u32 %v117040_v39, %v117039_v46 (stack47)
        %v117863_v55 = vadd.s32 %v117858_v38, %v121574_v2 (stack40)
        %v115444_v29 = vadd.f32 %v115440_v53, %v155544_v29 (stack53)
        %v115791_v24 = vmul.f32 0.6931472, %v121422_v7 (stack65)
        %v116636_v44 = vadd.s32 %v116633_v23, %v116628_v60 (stack40)
        %v116638_v8 = vshll.u32 %v116633_v23, 16 (stack45)
        %v116245_v54 = vxor.u32 %v116243_v45, %v116231_v43 (stack48)
        %v116639_v6 = vshrl.u32 %v116633_v23, 16 (stack46)
        %v117042_v59 = vxor.u32 %v117041_v30, %v117037_v9 (stack48)
        %v117442_v34 = vor.u32 %v117441_v28, %v117440_v26 (stack47)
        %v115448_v60 = vmul.f32 %v115444_v29, %v155588_v27 (stack54)
        %v115797_v16 = vsel /*vm=*/%vm155630_vm12, /*on_true_vy=*/%v115794_v50, /*on_false_vx=*/%v115791_v24 (stack66)
        %v117871_v20 = vadd.s32 %v117867_v42, %v117863_v55 (stack40)
        %v117873_v35 = vshll.u32 %v117867_v42, 13 (stack45)
        %v155649_v10 = vxor.u32 2147483648, %v115797_v16 (stack56)
        %v116640_v40 = vor.u32 %v116639_v6, %v116638_v8 (stack47)
        %v117045_v32 = vadd.s32 %v117042_v59, %v117037_v9 (stack40)
        %v117874_v50 = vshrl.u32 %v117867_v42, 19 (stack46)
        %v115313_v31 = vand.u32 2147483647, %v155460_v51 (stack77)
        %v115452_v22 = vadd.f32 %v115448_v60, %v155539_v22 (stack53)
        %v117443_v48 = vxor.u32 %v117442_v34, %v117434_v12 (stack48)
        %121423 = vrsqrt.f32 %v155649_v10 (stack67)
        %v116246_v42 = vand.u32.u8 255, %v116245_v54 (stack49)
        %v115456_v27 = vmul.f32 %v115452_v22, %v155588_v27 (stack54)
        %v117047_v25 = vshll.u32 %v117042_v59, 15 (stack45)
        %v117048_v21 = vshrl.u32 %v117042_v59, 17 (stack46)
        %v115345_v49 = vsel /*vm=*/%vm115340_vm6, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v116641_v9 = vxor.u32 %v116640_v40, %v116636_v44 (stack48)
        %v117875_v46 = vor.u32 %v117874_v50, %v117873_v35 (stack47)
        %vm155658_vm13 = vcmp.eq.f32.partialorder %v115313_v31, 1.0 (stack68)
        %v115321_v39 = vmul.f32 inf, %v155460_v51 (stack54)
        %v115460_v26 = vadd.f32 %v115456_v27, %v115345_v49 (stack53)
        %vm115801_vm14 = vcmp.lt.f32.partialorder %v155649_v10, 5.0 (stack68)
        %v116247_v53 = vand.u32 65535, %v116246_v42 (stack50)
        %v116644_v23 = vadd.s32 %v116641_v9, %v116636_v44 (stack40)
        %v117438_v12 = vadd.s32 %v117434_v12, %v121569_v1 (stack40)
        %v115464_v51 = vmul.f32 %v115460_v26, %v155460_v51 (stack54)
        %v116650_v28 = vshll.u32 %v116641_v9, 24 (stack45)
        %v116651_v38 = vshrl.u32 %v116641_v9, 8 (stack46)
        %v117049_v7 = vor.u32 %v117048_v21, %v117047_v25 (stack47)
        %v155667_v43 = vadd.f32 -2.5, %v155649_v10 (stack53)
        %v116248_v45 = vshrl.u32 %v116247_v53, 1 (stack51)
        %v117446_v30 = vadd.s32 %v117443_v48, %v121564_v0 (stack40)
        %v117876_v55 = vxor.u32 %v117875_v46, %v117871_v20 (stack48)
        %v115468_v29 = vsel /*vm=*/%vm155658_vm13, /*on_true_vy=*/%v115321_v39, /*on_false_vx=*/%v115464_v51 (stack44)
        %v155675_v24 = vsel /*vm=*/%vm115801_vm14, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %vm115846_vm15 = vcmp.eq.f32.partialorder %v155649_v10, inf (stack70)
        %v116652_v44 = vor.u32 %v116651_v38, %v116650_v28 (stack47)
        %v117050_v8 = vxor.u32 %v117049_v7, %v117045_v32 (stack48)
        %v115472_v54 = vmul.f32 1.4140625, %v115468_v29 (stack54)
        %vm115848_vm0 = vcmp.eq.f32.partialorder %v155649_v10, 0.0 (stack71)
        %v116249_v6 = vor.u32 16256, %v116248_v45 (stack47)
        %v117450_v59 = vadd.s32 1, %v117446_v30 (stack40)
        %v117879_v34 = vadd.s32 %v117876_v55, %v117871_v20 (stack40)
        %v116653_v60 = vxor.u32 %v116652_v44, %v116644_v23 (stack48)
        %v117053_v16 = vadd.s32 %v117050_v8, %v117045_v32 (stack40)
        %v117055_v20 = vshll.u32 %v117050_v8, 26 (stack45)
        %v117056_v35 = vshrl.u32 %v117050_v8, 6 (stack46)
        %v115475_v40 = vpack.c.bf16 %v157387_v11, %v115472_v54 (stack81)
        %v116250_v32 = vand.u32.u16 65535, %v116249_v6 (stack52)
        %v117454_v50 = vadd.s32 %v117450_v59, %v117438_v12 (stack40)
        %v117456_v31 = vshll.u32 %v117450_v59, 17 (stack45)
        %v116656_v22 = vadd.s32 %v116653_v60, %v121564_v0 (stack40)
        %v117057_v48 = vor.u32 %v117056_v35, %v117055_v20 (stack47)
        %v117457_v42 = vshrl.u32 %v117450_v59, 15 (stack46)
        %v117881_v27 = vshll.u32 %v117876_v55, 15 (stack45)
        %120361 = vst [vmem:[%s123356_s30 + $0x378] sm:$0xf] /*vst_source=*/%v115475_v40 (stack83)
        %v120368_v25 = vadd.low.f32.bf16 -1.0, %v116250_v32 (stack53)
        %v116648_v21 = vadd.s32 %v116644_v23, %v121569_v1 (stack40)
        %v117882_v49 = vshrl.u32 %v117876_v55, 17 (stack46)
        %vm118298_vm1 = vcmp.lt.u32.totalorder %v155565_v61, %v157089_v17 (stack43)
        %v121424_v9 = vpop.eup %121423 (stack73)
        %v116660_v46 = vadd.s32 4, %v116656_v22 (stack40)
        %v117058_v56 = vxor.u32 %v117057_v48, %v117053_v16 (stack48)
        %v117458_v39 = vor.u32 %v117457_v42, %v117456_v31 (stack47)
        %v155687_v62 = vadd.s32 %v157829_v52, %v157090_v62 (stack40)
        %v115845_v26 = vmul.f32 %v121424_v9, %v155649_v10 (stack74)
        %v115849_v53 = vand.u32 2147483648, %v155649_v10 (stack72)
        %v116259_v23 = vmul.f32 2.0, %v120368_v25 (stack54)
        %v117883_v12 = vor.u32 %v117882_v49, %v117881_v27 (stack47)
        %v116664_v51 = vadd.s32 %v116660_v46, %v116648_v21 (stack40)
        %v116666_v28 = vshll.u32 %v116660_v46, 13 (stack45)
        %v116667_v38 = vshrl.u32 %v116660_v46, 19 (stack46)
        %v117061_v7 = vadd.s32 %v117058_v56, %v117053_v16 (stack40)
        %v115847_v45 = vsel /*vm=*/%vm115846_vm15, /*on_true_vy=*/%v155649_v10, /*on_false_vx=*/%v115845_v26 (stack75)
        %v116263_v30 = vadd.f32 -0.99609375, %v116259_v23 (stack53)
        %v117067_v55 = vshll.u32 %v117058_v56, 6 (stack45)
        %v117068_v29 = vshrl.u32 %v117058_v56, 26 (stack46)
        %v155697_v44 = vsel /*vm=*/%vm115801_vm14, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v115850_v8 = vsel /*vm=*/%vm115848_vm0, /*on_true_vy=*/%v115849_v53, /*on_false_vx=*/%v115847_v45 (stack76)
        %v116668_v54 = vor.u32 %v116667_v38, %v116666_v28 (stack47)
        %v117459_v6 = vxor.u32 %v117458_v39, %v117454_v50 (stack48)
        %v115853_v59 = vadd.f32 -3.0, %v115850_v8 (stack53)
        %v155701_v60 = vmax.f32 %v116263_v30, -0.99609375 (stack55)
        %v117069_v16 = vor.u32 %v117068_v29, %v117067_v55 (stack47)
        %v117884_v20 = vxor.u32 %v117883_v12, %v117879_v34 (stack48)
        %v116669_v35 = vxor.u32 %v116668_v54, %v116664_v51 (stack48)
        %v117462_v40 = vadd.s32 %v117459_v6, %v117454_v50 (stack40)
        %v117464_v32 = vshll.u32 %v117459_v6, 29 (stack45)
        %v117465_v50 = vshrl.u32 %v117459_v6, 3 (stack46)
        %v115822_v31 = vsel /*vm=*/%vm115801_vm14, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v115838_v22 = vsel /*vm=*/%vm115801_vm14, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v155712_v43 = vsel /*vm=*/%vm115801_vm14, /*on_true_vy=*/%v155667_v43, /*on_false_vx=*/%v115853_v59 (stack44)
        %v116279_v48 = vxor.u32 2147483648, %v155701_v60 (stack56)
        %v115861_v42 = vmul.f32 %v155712_v43, %v115838_v22 (stack54)
        %v116672_v27 = vadd.s32 %v116669_v35, %v116664_v51 (stack40)
        %v116674_v25 = vshll.u32 %v116669_v35, 15 (stack45)
        %v116675_v21 = vshrl.u32 %v116669_v35, 17 (stack46)
        %v115834_v49 = vsel /*vm=*/%vm115801_vm14, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v155720_v9 = vmul.f32 %v116279_v48, %v155701_v60 (stack54)
        %v117070_v46 = vxor.u32 %v117069_v16, %v117061_v7 (stack48)
        %v117466_v56 = vor.u32 %v117465_v50, %v117464_v32 (stack47)
        %v115830_v39 = vsel /*vm=*/%vm115801_vm14, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v115865_v26 = vadd.f32 %v115861_v42, %v115834_v49 (stack53)
        %v116676_v53 = vor.u32 %v116675_v21, %v116674_v25 (stack47)
        %v117887_v34 = vadd.s32 %v117884_v20, %v117879_v34 (stack40)
        %v116284_v23 = vadd.f32 1.0, %v155720_v9 (stack57)
        %v117065_v12 = vadd.s32 %v117061_v7, %v121574_v2 (stack40)
        %v117073_v51 = vadd.s32 %v117070_v46, %v121569_v1 (stack40)
        %v155730_v28 = vadd.s32 %v155565_v61, %v122657_v58 (stack40)
        %v115869_v38 = vmul.f32 %v115865_v26, %v155712_v43 (stack54)
        %v116677_v7 = vxor.u32 %v116676_v53, %v116672_v27 (stack48)
        %v117467_v45 = vxor.u32 %v117466_v56, %v117462_v40 (stack48)
        %v117889_v30 = vshll.u32 %v117884_v20, 26 (stack45)
        %121425 = vlog2.f32 %v116284_v23 (stack58)
        %v116287_v55 = vmul.f32 -0.5, %v155720_v9 (stack59)
        %v117077_v29 = vadd.s32 3, %v117073_v51 (stack40)
        %v117890_v8 = vshrl.u32 %v117884_v20, 6 (stack46)
        %v115873_v54 = vadd.f32 %v115869_v38, %v115830_v39 (stack53)
        %v116680_v6 = vadd.s32 %v116677_v7, %v116672_v27 (stack40)
        %v116682_v59 = vshll.u32 %v116677_v7, 26 (stack45)
        %v116683_v16 = vshrl.u32 %v116677_v7, 6 (stack46)
        %v115826_v20 = vsel /*vm=*/%vm115801_vm14, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v117081_v35 = vadd.s32 %v117077_v29, %v117065_v12 (stack40)
        %v117083_v32 = vshll.u32 %v117077_v29, 17 (stack45)
        %v117084_v50 = vshrl.u32 %v117077_v29, 15 (stack46)
        %v115877_v22 = vmul.f32 %v115873_v54, %v155712_v43 (stack54)
        %v116684_v48 = vor.u32 %v116683_v16, %v116682_v59 (stack47)
        %v117470_v40 = vadd.s32 %v117467_v45, %v117462_v40 (stack40)
        %v117472_v42 = vshll.u32 %v117467_v45, 16 (stack45)
        %v117085_v27 = vor.u32 %v117084_v50, %v117083_v32 (stack47)
        %v117473_v25 = vshrl.u32 %v117467_v45, 16 (stack46)
        %v117891_v21 = vor.u32 %v117890_v8, %v117889_v30 (stack47)
        %v118307_v49 = vadd.s32 1, %v155687_v62 (stack40)
        %v115881_v46 = vadd.f32 %v115877_v22, %v115826_v20 (stack53)
        %v116288_v56 = vadd.f32 1.0, %v116287_v55 (stack61)
        %v116290_v39 = vand.u32 2147483647, %v155720_v9 (stack60)
        %v116685_v26 = vxor.u32 %v116684_v48, %v116680_v6 (stack48)
        %vm118293_vm2 = vcmp.lt.u32.totalorder %v155730_v28, %v155565_v61 (stack43)
        %v117086_v53 = vxor.u32 %v117085_v27, %v117081_v35 (stack48)
        %v117474_v23 = vor.u32 %v117473_v25, %v117472_v42 (stack47)
        %v117892_v12 = vxor.u32 %v117891_v21, %v117887_v34 (stack48)
        %v118311_v17 = vsel /*vm=*/%vm118298_vm1, /*on_true_vy=*/%v118307_v49, /*on_false_vx=*/%v155687_v62 (stack44)
        %v115885_v62 = vmul.f32 %v115881_v46, %v155712_v43 (stack54)
        %v116688_v51 = vadd.s32 %v116685_v26, %v116680_v6 (stack40)
        %v116694_v38 = vshll.u32 %v116685_v26, 6 (stack45)
        %v116695_v7 = vshrl.u32 %v116685_v26, 26 (stack46)
        %v117089_v45 = vadd.s32 %v117086_v53, %v117081_v35 (stack40)
        %v117091_v30 = vshll.u32 %v117086_v53, 29 (stack45)
        %v117092_v55 = vshrl.u32 %v117086_v53, 3 (stack46)
        %v117475_v29 = vxor.u32 %v117474_v23, %v117470_v40 (stack48)
        %v115889_v31 = vadd.f32 %v115885_v62, %v115822_v31 (stack53)
        %v116696_v8 = vor.u32 %v116695_v7, %v116694_v38 (stack47)
        %v155747_v34 = vadd.s32 %v117892_v12, %v117887_v34 (stack40)
        %v155751_v54 = vadd.s32 %v155730_v28, %v121569_v1 (stack40)
        %v117093_v6 = vor.u32 %v117092_v55, %v117091_v30 (stack47)
        %v117478_v59 = vadd.s32 %v117475_v29, %v117470_v40 (stack40)
        %v117484_v16 = vshll.u32 %v117475_v29, 24 (stack45)
        %v117485_v20 = vshrl.u32 %v117475_v29, 8 (stack46)
        %v115893_v35 = vmul.f32 %v115889_v31, %v155712_v43 (stack54)
        %vm155754_vm3 = vcmp.lt.f32.partialorder %v116290_v39, 0.0004427343 (stack62)
        %v116697_v50 = vxor.u32 %v116696_v8, %v116688_v51 (stack48)
        %v117901_v22 = vshll.u32 %v117892_v12, 6 (stack45)
        %v116289_v9 = vmul.f32 %v116288_v56, %v155720_v9 (stack63)
        %v117094_v48 = vxor.u32 %v117093_v6, %v117089_v45 (stack48)
        %v117486_v40 = vor.u32 %v117485_v20, %v117484_v16 (stack47)
        %v117902_v42 = vshrl.u32 %v117892_v12, 26 (stack46)
        %v121426_v27 = vpop.eup %121425 (stack64)
        %v115897_v44 = vadd.f32 %v115893_v35, %v155697_v44 (stack53)
        %v116692_v25 = vadd.s32 %v116688_v51, %v121564_v0 (stack40)
        %v116700_v21 = vadd.s32 %v116697_v50, %v121574_v2 (stack40)
        %v118315_v49 = vadd.s32 1, %v118311_v17 (stack40)
        %v116286_v46 = vmul.f32 0.6931472, %v121426_v27 (stack65)
        %v117097_v56 = vadd.s32 %v117094_v48, %v117089_v45 (stack40)
        %v117099_v39 = vshll.u32 %v117094_v48, 16 (stack45)
        %v117100_v26 = vshrl.u32 %v117094_v48, 16 (stack46)
        %v115901_v53 = vmul.f32 %v115897_v44, %v155712_v43 (stack54)
        %v116704_v23 = vadd.s32 5, %v116700_v21 (stack40)
        %v117487_v12 = vxor.u32 %v117486_v40, %v117478_v59 (stack48)
        %v117903_v62 = vor.u32 %v117902_v42, %v117901_v22 (stack47)
        %v116292_v51 = vsel /*vm=*/%vm155754_vm3, /*on_true_vy=*/%v116289_v9, /*on_false_vx=*/%v116286_v46 (stack66)
        %v117101_v38 = vor.u32 %v117100_v26, %v117099_v39 (stack47)
        %v118319_v61 = vsel /*vm=*/%vm118293_vm2, /*on_true_vy=*/%v118315_v49, /*on_false_vx=*/%v118311_v17 (stack44)
        %v155770_v28 = vadd.s32 %v157828_v41, %v157091_v37 (stack40)
        %v115774_v17 = vand.u32 2147483647, %v155591_v47 (stack77)
        %v115905_v24 = vadd.f32 %v115901_v53, %v155675_v24 (stack53)
        %v155774_v7 = vxor.u32 2147483648, %v116292_v51 (stack56)
        %v116706_v45 = vxor.u32 %v116704_v23, %v116692_v25 (stack48)
        %v117102_v30 = vxor.u32 %v117101_v38, %v117097_v56 (stack48)
        %v117904_v55 = vxor.u32 %v117903_v62, %v155747_v34 (stack48)
        %v118334_v29 = vshll.u32 %v155751_v54, 13 (stack45)
        %v118335_v31 = vshrl.u32 %v155751_v54, 19 (stack46)
        %v115782_v8 = vmul.f32 inf, %v155591_v47 (stack54)
        %v115909_v6 = vmul.f32 %v115905_v24, %v155712_v43 (stack54)
        %121427 = vrsqrt.f32 %v155774_v7 (stack67)
        %v115810_v16 = vsel /*vm=*/%vm115801_vm14, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %vm116296_vm4 = vcmp.lt.f32.partialorder %v155774_v7, 5.0 (stack68)
        %v117105_v20 = vadd.s32 %v117102_v30, %v117097_v56 (stack40)
        %v117490_v35 = vadd.s32 %v117487_v12, %v121574_v2 (stack40)
        %vm155787_vm5 = vcmp.eq.f32.partialorder %v115774_v17, 1.0 (stack68)
        %v115806_v10 = vsel /*vm=*/%vm115801_vm14, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v115913_v50 = vadd.f32 %v115909_v6, %v115810_v16 (stack53)
        %v118324_v22 = vadd.s32 %v118319_v61, %v121574_v2 (stack40)
        %v117482_v59 = vadd.s32 %v117478_v59, %v121564_v0 (stack40)
        %v117899_v34 = vadd.s32 %v155747_v34, %v121569_v1 (stack40)
        %v118336_v9 = vor.u32 %v118335_v31, %v118334_v29 (stack47)
        %v155800_v48 = vadd.s32 %v155770_v28, %v122657_v58 (stack40)
        %v115917_v43 = vmul.f32 %v115913_v50, %v155712_v43 (stack54)
        %v155806_v40 = vsel /*vm=*/%vm116296_vm4, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v155809_v42 = vadd.f32 -2.5, %v155774_v7 (stack53)
        %v117109_v27 = vadd.s32 %v117105_v20, %v121569_v1 (stack40)
        %v116707_v44 = vand.u32.u8 255, %v116706_v45 (stack49)
        %v117111_v25 = vshll.u32 %v117102_v30, 24 (stack45)
        %v117112_v21 = vshrl.u32 %v117102_v30, 8 (stack46)
        %v117494_v49 = vadd.s32 2, %v117490_v35 (stack40)
        %v115921_v46 = vadd.f32 %v115917_v43, %v115806_v10 (stack53)
        %v116344_v56 = vand.u32 2147483648, %v155774_v7 (stack72)
        %v117907_v39 = vadd.s32 %v117904_v55, %v121564_v0 (stack40)
        %v118332_v54 = vadd.s32 %v155751_v54, %v118324_v22 (stack40)
        %vm116341_vm6 = vcmp.eq.f32.partialorder %v155774_v7, inf (stack70)
        %v116708_v26 = vand.u32 65535, %v116707_v44 (stack50)
        %v117113_v53 = vor.u32 %v117112_v21, %v117111_v25 (stack47)
        %v117498_v23 = vadd.s32 %v117494_v49, %v117482_v59 (stack40)
        %v117500_v12 = vshll.u32 %v117494_v49, 13 (stack45)
        %v115925_v47 = vmul.f32 %v115921_v46, %v155591_v47 (stack54)
        %vm116343_vm7 = vcmp.eq.f32.partialorder %v155774_v7, 0.0 (stack71)
        %v117501_v62 = vshrl.u32 %v117494_v49, 19 (stack46)
        %v117911_v51 = vadd.s32 1, %v117907_v39 (stack40)
        %v118337_v38 = vxor.u32 %v118336_v9, %v118332_v54 (stack48)
        %v116709_v61 = vshrl.u32 %v116708_v26, 1 (stack51)
        %v117114_v17 = vxor.u32 %v117113_v53, %v117105_v20 (stack48)
        %vm118759_vm8 = vcmp.lt.u32.totalorder %v155770_v28, %v157091_v37 (stack43)
        %v155822_v36 = vadd.s32 %v157829_v52, %v157094_v36 (stack40)
        %v115929_v24 = vsel /*vm=*/%vm155787_vm5, /*on_true_vy=*/%v115782_v8, /*on_false_vx=*/%v115925_v47 (stack44)
        %v117502_v45 = vor.u32 %v117501_v62, %v117500_v12 (stack47)
        %v117915_v30 = vadd.s32 %v117911_v51, %v117899_v34 (stack40)
        %v117917_v55 = vshll.u32 %v117911_v51, 17 (stack45)
        %v115933_v29 = vmul.f32 1.4140625, %v115929_v24 (stack54)
        %v116710_v31 = vor.u32 16256, %v116709_v61 (stack47)
        %v117117_v8 = vadd.s32 %v117114_v17, %v121564_v0 (stack40)
        %v117918_v6 = vshrl.u32 %v117911_v51, 15 (stack46)
        %v117503_v16 = vxor.u32 %v117502_v45, %v117498_v23 (stack48)
        %v118340_v20 = vadd.s32 %v118337_v38, %v118332_v54 (stack40)
        %v118342_v35 = vshll.u32 %v118337_v38, 15 (stack45)
        %v118343_v32 = vshrl.u32 %v118337_v38, 17 (stack46)
        %v121428_v10 = vpop.eup %121427 (stack73)
        %v115936_v50 = vpack.c.bf16 %v157387_v11, %v115933_v29 (stack81)
        %v116711_v22 = vand.u32.u16 65535, %v116710_v31 (stack52)
        %v117121_v59 = vadd.s32 4, %v117117_v8 (stack40)
        %v117919_v34 = vor.u32 %v117918_v6, %v117917_v55 (stack47)
        %v116340_v9 = vmul.f32 %v121428_v10, %v155774_v7 (stack74)
        %v117506_v43 = vadd.s32 %v117503_v16, %v117498_v23 (stack40)
        %v117508_v44 = vshll.u32 %v117503_v16, 15 (stack45)
        %v117509_v25 = vshrl.u32 %v117503_v16, 17 (stack46)
        %120363 = vst [vmem:[%s123356_s30 + $0x3f8] sm:$0xf] /*vst_source=*/%v115936_v50 (stack83)
        %v120370_v21 = vadd.low.f32.bf16 -1.0, %v116711_v22 (stack53)
        %v117125_v27 = vadd.s32 %v117121_v59, %v117109_v27 (stack40)
        %v117127_v49 = vshll.u32 %v117121_v59, 13 (stack45)
        %v117128_v46 = vshrl.u32 %v117121_v59, 19 (stack46)
        %v116342_v39 = vsel /*vm=*/%vm116341_vm6, /*on_true_vy=*/%v155774_v7, /*on_false_vx=*/%v116340_v9 (stack75)
        %v117510_v54 = vor.u32 %v117509_v25, %v117508_v44 (stack47)
        %v117920_v26 = vxor.u32 %v117919_v34, %v117915_v30 (stack48)
        %v118344_v53 = vor.u32 %v118343_v32, %v118342_v35 (stack47)
        %v116333_v23 = vsel /*vm=*/%vm116296_vm4, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v116345_v56 = vsel /*vm=*/%vm116343_vm7, /*on_true_vy=*/%v116344_v56, /*on_false_vx=*/%v116342_v39 (stack76)
        %v116720_v12 = vmul.f32 2.0, %v120370_v21 (stack54)
        %v117129_v47 = vor.u32 %v117128_v46, %v117127_v49 (stack47)
        %v116348_v62 = vadd.f32 -3.0, %v116345_v56 (stack53)
        %v117511_v51 = vxor.u32 %v117510_v54, %v117506_v43 (stack48)
        %v117923_v38 = vadd.s32 %v117920_v26, %v117915_v30 (stack40)
        %v117925_v61 = vshll.u32 %v117920_v26, 29 (stack45)
        %v116724_v17 = vadd.f32 -0.99609375, %v116720_v12 (stack53)
        %v117130_v24 = vxor.u32 %v117129_v47, %v117125_v27 (stack48)
        %v117926_v45 = vshrl.u32 %v117920_v26, 3 (stack46)
        %v118345_v30 = vxor.u32 %v118344_v53, %v118340_v20 (stack48)
        %v155841_v42 = vsel /*vm=*/%vm116296_vm4, /*on_true_vy=*/%v155809_v42, /*on_false_vx=*/%v116348_v62 (stack44)
        %v117514_v55 = vadd.s32 %v117511_v51, %v117506_v43 (stack40)
        %v117516_v29 = vshll.u32 %v117511_v51, 26 (stack45)
        %v117517_v31 = vshrl.u32 %v117511_v51, 6 (stack46)
        %v116356_v8 = vmul.f32 %v155841_v42, %v116333_v23 (stack54)
        %v155844_v6 = vmax.f32 %v116724_v17, -0.99609375 (stack55)
        %v117133_v16 = vadd.s32 %v117130_v24, %v117125_v27 (stack40)
        %v117135_v35 = vshll.u32 %v117130_v24, 15 (stack45)
        %v117136_v32 = vshrl.u32 %v117130_v24, 17 (stack46)
        %v117518_v10 = vor.u32 %v117517_v31, %v117516_v29 (stack47)
        %v117927_v50 = vor.u32 %v117926_v45, %v117925_v61 (stack47)
        %v118348_v20 = vadd.s32 %v118345_v30, %v118340_v20 (stack40)
        %v155849_v22 = vsel /*vm=*/%vm116296_vm4, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v155854_v59 = vsel /*vm=*/%vm116296_vm4, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v116360_v40 = vadd.f32 %v116356_v8, %v155806_v40 (stack53)
        %v116740_v34 = vxor.u32 2147483648, %v155844_v6 (stack56)
        %v116313_v9 = vsel /*vm=*/%vm116296_vm4, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v117137_v43 = vor.u32 %v117136_v32, %v117135_v35 (stack47)
        %v117519_v44 = vxor.u32 %v117518_v10, %v117514_v55 (stack48)
        %v117928_v25 = vxor.u32 %v117927_v50, %v117923_v38 (stack48)
        %v116317_v21 = vsel /*vm=*/%vm116296_vm4, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v116325_v27 = vsel /*vm=*/%vm116296_vm4, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v116364_v49 = vmul.f32 %v116360_v40, %v155841_v42 (stack54)
        %v116743_v46 = vmul.f32 %v116740_v34, %v155844_v6 (stack54)
        %v117138_v39 = vxor.u32 %v117137_v43, %v117133_v16 (stack48)
        %v117522_v54 = vadd.s32 %v117519_v44, %v117514_v55 (stack40)
        %v117528_v26 = vshll.u32 %v117519_v44, 6 (stack45)
        %v117529_v53 = vshrl.u32 %v117519_v44, 26 (stack46)
        %v116368_v23 = vadd.f32 %v116364_v49, %v116325_v27 (stack53)
        %v116745_v56 = vadd.f32 1.0, %v116743_v46 (stack57)
        %v118350_v12 = vshll.u32 %v118345_v30, 26 (stack45)
        %v118351_v47 = vshrl.u32 %v118345_v30, 6 (stack46)
        %v116321_v62 = vsel /*vm=*/%vm116296_vm4, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v117141_v51 = vadd.s32 %v117138_v39, %v117133_v16 (stack40)
        %v117143_v61 = vshll.u32 %v117138_v39, 26 (stack45)
        %v117144_v17 = vshrl.u32 %v117138_v39, 6 (stack46)
        %v116372_v24 = vmul.f32 %v116368_v23, %v155841_v42 (stack54)
        %121429 = vlog2.f32 %v116745_v56 (stack58)
        %v116748_v45 = vmul.f32 -0.5, %v116743_v46 (stack59)
        %vm118754_vm9 = vcmp.lt.u32.totalorder %v155800_v48, %v155770_v28 (stack43)
        %v118768_v30 = vadd.s32 1, %v155822_v36 (stack40)
        %v117145_v55 = vor.u32 %v117144_v17, %v117143_v61 (stack47)
        %v117530_v29 = vor.u32 %v117529_v53, %v117528_v26 (stack47)
        %v117931_v38 = vadd.s32 %v117928_v25, %v117923_v38 (stack40)
        %v117933_v31 = vshll.u32 %v117928_v25, 16 (stack45)
        %v116376_v8 = vadd.f32 %v116372_v24, %v116321_v62 (stack53)
        %v116751_v16 = vand.u32 2147483647, %v116743_v46 (stack60)
        %v117934_v35 = vshrl.u32 %v117928_v25, 16 (stack46)
        %v118352_v32 = vor.u32 %v118351_v47, %v118350_v12 (stack47)
        %v117146_v10 = vxor.u32 %v117145_v55, %v117141_v51 (stack48)
        %v117526_v50 = vadd.s32 %v117522_v54, %v121574_v2 (stack40)
        %v117531_v40 = vxor.u32 %v117530_v29, %v117522_v54 (stack48)
        %v118772_v37 = vsel /*vm=*/%vm118759_vm8, /*on_true_vy=*/%v118768_v30, /*on_false_vx=*/%v155822_v36 (stack44)
        %v116380_v36 = vmul.f32 %v116376_v8, %v155841_v42 (stack54)
        %v116749_v34 = vadd.f32 1.0, %v116748_v45 (stack61)
        %v117935_v43 = vor.u32 %v117934_v35, %v117933_v31 (stack47)
        %v118353_v44 = vxor.u32 %v118352_v32, %v118348_v20 (stack48)
        %v117149_v25 = vadd.s32 %v117146_v10, %v117141_v51 (stack40)
        %v117155_v27 = vshll.u32 %v117146_v10, 6 (stack45)
        %v117156_v49 = vshrl.u32 %v117146_v10, 26 (stack46)
        %v117534_v39 = vadd.s32 %v117531_v40, %v121569_v1 (stack40)
        %v116384_v21 = vadd.f32 %v116380_v36, %v116317_v21 (stack53)
        %v117936_v54 = vxor.u32 %v117935_v43, %v117931_v38 (stack48)
        %v155883_v20 = vadd.s32 %v118353_v44, %v118348_v20 (stack40)
        %v118776_v26 = vadd.s32 1, %v118772_v37 (stack40)
        %v117157_v53 = vor.u32 %v117156_v49, %v117155_v27 (stack47)
        %v117538_v23 = vadd.s32 3, %v117534_v39 (stack40)
        %v118362_v56 = vshll.u32 %v118353_v44, 6 (stack45)
        %v118363_v12 = vshrl.u32 %v118353_v44, 26 (stack46)
        %v116388_v47 = vmul.f32 %v116384_v21, %v155841_v42 (stack54)
        %v117939_v62 = vadd.s32 %v117936_v54, %v117931_v38 (stack40)
        %v117945_v51 = vshll.u32 %v117936_v54, 24 (stack45)
        %v117946_v61 = vshrl.u32 %v117936_v54, 8 (stack46)
        %v117158_v17 = vxor.u32 %v117157_v53, %v117149_v25 (stack48)
        %v117542_v24 = vadd.s32 %v117538_v23, %v117526_v50 (stack40)
        %v117544_v45 = vshll.u32 %v117538_v23, 17 (stack45)
        %v117545_v30 = vshrl.u32 %v117538_v23, 15 (stack46)
        %v116392_v9 = vadd.f32 %v116388_v47, %v116313_v9 (stack53)
        %v116750_v46 = vmul.f32 %v116749_v34, %v116743_v46 (stack63)
        %vm155886_vm10 = vcmp.lt.f32.partialorder %v116751_v16, 0.0004427343 (stack62)
        %v117947_v29 = vor.u32 %v117946_v61, %v117945_v51 (stack47)
        %v117161_v38 = vadd.s32 %v117158_v17, %v121574_v2 (stack40)
        %v117546_v31 = vor.u32 %v117545_v30, %v117544_v45 (stack47)
        %v118364_v8 = vor.u32 %v118363_v12, %v118362_v56 (stack47)
        %v118780_v28 = vsel /*vm=*/%vm118754_vm9, /*on_true_vy=*/%v118776_v26, /*on_false_vx=*/%v118772_v37 (stack44)
        %v116396_v16 = vmul.f32 %v116392_v9, %v155841_v42 (stack54)
        %v117948_v35 = vxor.u32 %v117947_v29, %v117939_v62 (stack48)
        %v118785_v32 = vadd.s32 %v118780_v28, %v121574_v2 (stack40)
        %v118789_v48 = vadd.s32 %v155800_v48, %v121569_v1 (stack40)
        %v121430_v10 = vpop.eup %121429 (stack64)
        %v117153_v50 = vadd.s32 %v117149_v25, %v121564_v0 (stack40)
        %v117165_v40 = vadd.s32 5, %v117161_v38 (stack40)
        %v117547_v37 = vxor.u32 %v117546_v31, %v117542_v24 (stack48)
        %v118365_v36 = vxor.u32 %v118364_v8, %v155883_v20 (stack48)
        %v116400_v59 = vadd.f32 %v116396_v16, %v155854_v59 (stack53)
        %v116747_v34 = vmul.f32 0.6931472, %v121430_v10 (stack65)
        %v117951_v43 = vadd.s32 %v117948_v35, %v121574_v2 (stack40)
        %v118793_v44 = vadd.s32 %v118789_v48, %v118785_v32 (stack40)
        %v117167_v25 = vxor.u32 %v117165_v40, %v117153_v50 (stack48)
        %v117550_v27 = vadd.s32 %v117547_v37, %v117542_v24 (stack40)
        %v117552_v49 = vshll.u32 %v117547_v37, 29 (stack45)
        %v117553_v39 = vshrl.u32 %v117547_v37, 3 (stack46)
        %v116404_v21 = vmul.f32 %v116400_v59, %v155841_v42 (stack54)
        %v116753_v54 = vsel /*vm=*/%vm155886_vm10, /*on_true_vy=*/%v116750_v46, /*on_false_vx=*/%v116747_v34 (stack66)
        %v117943_v26 = vadd.s32 %v117939_v62, %v121564_v0 (stack40)
        %v117955_v53 = vadd.s32 2, %v117951_v43 (stack40)
        %v155906_v23 = vxor.u32 2147483648, %v116753_v54 (stack56)
        %v117554_v56 = vor.u32 %v117553_v39, %v117552_v49 (stack47)
        %v118795_v12 = vshll.u32 %v118789_v48, 13 (stack45)
        %v118796_v47 = vshrl.u32 %v118789_v48, 19 (stack46)
        %v116269_v62 = vand.u32 2147483647, %v155701_v60 (stack77)
        %v116408_v22 = vadd.f32 %v116404_v21, %v155849_v22 (stack53)
        %v117959_v51 = vadd.s32 %v117955_v53, %v117943_v26 (stack40)
        %121431 = vrsqrt.f32 %v155906_v23 (stack67)
        %v117168_v61 = vand.u32.u8 255, %v117167_v25 (stack49)
        %v116412_v42 = vmul.f32 %v116408_v22, %v155841_v42 (stack54)
        %v117961_v17 = vshll.u32 %v117955_v53, 13 (stack45)
        %v117962_v24 = vshrl.u32 %v117955_v53, 19 (stack46)
        %v116301_v7 = vsel /*vm=*/%vm116296_vm4, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v117555_v45 = vxor.u32 %v117554_v56, %v117550_v27 (stack48)
        %v118368_v30 = vadd.s32 %v118365_v36, %v121564_v0 (stack40)
        %v118797_v9 = vor.u32 %v118796_v47, %v118795_v12 (stack47)
        %vm155916_vm11 = vcmp.eq.f32.partialorder %v116269_v62, 1.0 (stack68)
        %v116277_v55 = vmul.f32 inf, %v155701_v60 (stack54)
        %v116416_v29 = vadd.f32 %v116412_v42, %v116301_v7 (stack53)
        %v155922_v38 = vadd.f32 -2.5, %v155906_v23 (stack53)
        %v117169_v31 = vand.u32 65535, %v117168_v61 (stack50)
        %v117558_v8 = vadd.s32 %v117555_v45, %v117550_v27 (stack40)
        %v118360_v20 = vadd.s32 %v155883_v20, %v121569_v1 (stack40)
        %v116420_v60 = vmul.f32 %v116416_v29, %v155701_v60 (stack54)
        %v117560_v28 = vshll.u32 %v117555_v45, 16 (stack45)
        %v117561_v16 = vshrl.u32 %v117555_v45, 16 (stack46)
        %v117963_v35 = vor.u32 %v117962_v24, %v117961_v17 (stack47)
        %v117170_v32 = vshrl.u32 %v117169_v31, 1 (stack51)
        %v118372_v48 = vadd.s32 1, %v118368_v30 (stack40)
        %v118798_v10 = vxor.u32 %v118797_v9, %v118793_v44 (stack48)
        %v155929_v41 = vadd.s32 %v157828_v41, %v157095_v13 (stack40)
        %v116424_v50 = vsel /*vm=*/%vm155916_vm11, /*on_true_vy=*/%v116277_v55, /*on_false_vx=*/%v116420_v60 (stack44)
        %vm116802_vm12 = vcmp.eq.f32.partialorder %v155906_v23, inf (stack70)
        %v117562_v40 = vor.u32 %v117561_v16, %v117560_v28 (stack47)
        %v117964_v37 = vxor.u32 %v117963_v35, %v117959_v51 (stack48)
        %v155936_v14 = vadd.s32 %v157829_v52, %v157100_v14 (stack40)
        %v116428_v52 = vmul.f32 1.4140625, %v116424_v50 (stack54)
        %v117171_v36 = vor.u32 16256, %v117170_v32 (stack47)
        %v118376_v59 = vadd.s32 %v118372_v48, %v118360_v20 (stack40)
        %v118378_v34 = vshll.u32 %v118372_v48, 17 (stack45)
        %vm116757_vm13 = vcmp.lt.f32.partialorder %v155906_v23, 5.0 (stack68)
        %v117563_v43 = vxor.u32 %v117562_v40, %v117558_v8 (stack48)
        %v117967_v25 = vadd.s32 %v117964_v37, %v117959_v51 (stack40)
        %v117969_v27 = vshll.u32 %v117964_v37, 15 (stack45)
        %v117970_v49 = vshrl.u32 %v117964_v37, 17 (stack46)
        %v116431_v39 = vpack.c.bf16 %v157387_v11, %v116428_v52 (stack81)
        %v117172_v21 = vand.u32.u16 65535, %v117171_v36 (stack52)
        %v118379_v54 = vshrl.u32 %v118372_v48, 15 (stack46)
        %v155940_v44 = vadd.s32 %v118798_v10, %v118793_v44 (stack40)
        %v117566_v26 = vadd.s32 %v117563_v43, %v117558_v8 (stack40)
        %v117572_v53 = vshll.u32 %v117563_v43, 24 (stack45)
        %v117573_v56 = vshrl.u32 %v117563_v43, 8 (stack46)
        %v117971_v12 = vor.u32 %v117970_v49, %v117969_v27 (stack47)
        %120369 = vst [vmem:[%s123356_s30 + $0x7c] sm:$0xf] /*vst_source=*/%v116431_v39 (stack83)
        %v120372_v47 = vadd.low.f32.bf16 -1.0, %v117172_v21 (stack53)
        %v118380_v62 = vor.u32 %v118379_v54, %v118378_v34 (stack47)
        %v118803_v22 = vshll.u32 %v118798_v10, 15 (stack45)
        %v118804_v51 = vshrl.u32 %v118798_v10, 17 (stack46)
        %v121432_v61 = vpop.eup %121431 (stack73)
        %vm116804_vm14 = vcmp.eq.f32.partialorder %v155906_v23, 0.0 (stack71)
        %v116805_v42 = vand.u32 2147483648, %v155906_v23 (stack72)
        %v117574_v17 = vor.u32 %v117573_v56, %v117572_v53 (stack47)
        %v117972_v24 = vxor.u32 %v117971_v12, %v117967_v25 (stack48)
        %v116801_v7 = vmul.f32 %v121432_v61, %v155906_v23 (stack74)
        %v117181_v45 = vmul.f32 2.0, %v120372_v47 (stack54)
        %v118381_v30 = vxor.u32 %v118380_v62, %v118376_v59 (stack48)
        %v118805_v9 = vor.u32 %v118804_v51, %v118803_v22 (stack47)
        %v117575_v46 = vxor.u32 %v117574_v17, %v117566_v26 (stack48)
        %v117975_v55 = vadd.s32 %v117972_v24, %v117967_v25 (stack40)
        %v117977_v29 = vshll.u32 %v117972_v24, 26 (stack45)
        %v117978_v31 = vshrl.u32 %v117972_v24, 6 (stack46)
        %v116803_v8 = vsel /*vm=*/%vm116802_vm12, /*on_true_vy=*/%v155906_v23, /*on_false_vx=*/%v116801_v7 (stack75)
        %v117185_v20 = vadd.f32 -0.99609375, %v117181_v45 (stack53)
        %v118384_v60 = vadd.s32 %v118381_v30, %v118376_v59 (stack40)
        %v118386_v28 = vshll.u32 %v118381_v30, 29 (stack45)
        %v116806_v16 = vsel /*vm=*/%vm116804_vm14, /*on_true_vy=*/%v116805_v42, /*on_false_vx=*/%v116803_v8 (stack76)
        %v117578_v35 = vadd.s32 %v117575_v46, %v121564_v0 (stack40)
        %v117979_v32 = vor.u32 %v117978_v31, %v117977_v29 (stack47)
        %v118387_v48 = vshrl.u32 %v118381_v30, 3 (stack46)
        %v116809_v10 = vadd.f32 -3.0, %v116806_v16 (stack53)
        %v155952_v50 = vmax.f32 %v117185_v20, -0.99609375 (stack55)
        %v117570_v40 = vadd.s32 %v117566_v26, %v121569_v1 (stack40)
        %v118806_v37 = vxor.u32 %v118805_v9, %v155940_v44 (stack48)
        %v117582_v52 = vadd.s32 4, %v117578_v35 (stack40)
        %v117980_v36 = vxor.u32 %v117979_v32, %v117975_v55 (stack48)
        %v118388_v59 = vor.u32 %v118387_v48, %v118386_v28 (stack47)
        %vm119220_vm15 = vcmp.lt.u32.totalorder %v155929_v41, %v157095_v13 (stack43)
        %v155961_v34 = vsel /*vm=*/%vm116757_vm13, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v116794_v43 = vsel /*vm=*/%vm116757_vm13, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v155969_v38 = vsel /*vm=*/%vm116757_vm13, /*on_true_vy=*/%v155922_v38, /*on_false_vx=*/%v116809_v10 (stack44)
        %v117201_v25 = vxor.u32 2147483648, %v155952_v50 (stack56)
        %v116817_v27 = vmul.f32 %v155969_v38, %v116794_v43 (stack54)
        %v117586_v49 = vadd.s32 %v117582_v52, %v117570_v40 (stack40)
        %v117588_v39 = vshll.u32 %v117582_v52, 13 (stack45)
        %v117589_v21 = vshrl.u32 %v117582_v52, 19 (stack46)
        %v116790_v54 = vsel /*vm=*/%vm116757_vm13, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v117204_v26 = vmul.f32 %v117201_v25, %v155952_v50 (stack54)
        %v117983_v53 = vadd.s32 %v117980_v36, %v117975_v55 (stack40)
        %v117989_v56 = vshll.u32 %v117980_v36, 6 (stack45)
        %v116821_v12 = vadd.f32 %v116817_v27, %v116790_v54 (stack53)
        %v117590_v47 = vor.u32 %v117589_v21, %v117588_v39 (stack47)
        %v117990_v62 = vshrl.u32 %v117980_v36, 26 (stack46)
        %v118389_v22 = vxor.u32 %v118388_v59, %v118384_v60 (stack48)
        %v116778_v51 = vsel /*vm=*/%vm116757_vm13, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v116782_v61 = vsel /*vm=*/%vm116757_vm13, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v117206_v42 = vadd.f32 1.0, %v117204_v26 (stack57)
        %v116825_v17 = vmul.f32 %v116821_v12, %v155969_v38 (stack54)
        %v117591_v24 = vxor.u32 %v117590_v47, %v117586_v49 (stack48)
        %v117991_v7 = vor.u32 %v117990_v62, %v117989_v56 (stack47)
        %v118392_v45 = vadd.s32 %v118389_v22, %v118384_v60 (stack40)
        %v116786_v30 = vsel /*vm=*/%vm116757_vm13, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %121433 = vlog2.f32 %v117206_v42 (stack58)
        %v117209_v9 = vmul.f32 -0.5, %v117204_v26 (stack59)
        %v118394_v46 = vshll.u32 %v118389_v22, 16 (stack45)
        %v116829_v55 = vadd.f32 %v116825_v17, %v116786_v30 (stack53)
        %v117594_v29 = vadd.s32 %v117591_v24, %v117586_v49 (stack40)
        %v117596_v31 = vshll.u32 %v117591_v24, 15 (stack45)
        %v117597_v8 = vshrl.u32 %v117591_v24, 17 (stack46)
        %v117992_v20 = vxor.u32 %v117991_v7, %v117983_v53 (stack48)
        %v118395_v60 = vshrl.u32 %v118389_v22, 16 (stack46)
        %v118809_v44 = vadd.s32 %v118806_v37, %v155940_v44 (stack40)
        %v155990_v58 = vadd.s32 %v155929_v41, %v122657_v58 (stack40)
        %v116833_v28 = vmul.f32 %v116829_v55, %v155969_v38 (stack54)
        %v117598_v16 = vor.u32 %v117597_v8, %v117596_v31 (stack47)
        %v118811_v35 = vshll.u32 %v118806_v37, 26 (stack45)
        %v118812_v32 = vshrl.u32 %v118806_v37, 6 (stack46)
        %v117212_v48 = vand.u32 2147483647, %v117204_v26 (stack60)
        %v117995_v10 = vadd.s32 %v117992_v20, %v121569_v1 (stack40)
        %v118396_v40 = vor.u32 %v118395_v60, %v118394_v46 (stack47)
        %v119229_v37 = vadd.s32 1, %v155936_v14 (stack40)
        %v116837_v52 = vadd.f32 %v116833_v28, %v116782_v61 (stack53)
        %v117210_v36 = vadd.f32 1.0, %v117209_v9 (stack61)
        %v117599_v59 = vxor.u32 %v117598_v16, %v117594_v29 (stack48)
        %v117987_v43 = vadd.s32 %v117983_v53, %v121574_v2 (stack40)
        %v117999_v25 = vadd.s32 3, %v117995_v10 (stack40)
        %v118397_v27 = vxor.u32 %v118396_v40, %v118392_v45 (stack48)
        %v118813_v49 = vor.u32 %v118812_v32, %v118811_v35 (stack47)
        %v119233_v13 = vsel /*vm=*/%vm119220_vm15, /*on_true_vy=*/%v119229_v37, /*on_false_vx=*/%v155936_v14 (stack44)
        %v116841_v14 = vmul.f32 %v116837_v52, %v155969_v38 (stack54)
        %v117602_v39 = vadd.s32 %v117599_v59, %v117594_v29 (stack40)
        %v117604_v21 = vshll.u32 %v117599_v59, 26 (stack45)
        %v117605_v54 = vshrl.u32 %v117599_v59, 6 (stack46)
        %vm119215_vm0 = vcmp.lt.u32.totalorder %v155990_v58, %v155929_v41 (stack43)
        %v118003_v53 = vadd.s32 %v117999_v25, %v117987_v43 (stack40)
        %v118005_v56 = vshll.u32 %v117999_v25, 17 (stack45)
        %v118006_v12 = vshrl.u32 %v117999_v25, 15 (stack46)
        %v118400_v47 = vadd.s32 %v118397_v27, %v118392_v45 (stack40)
        %v116845_v62 = vadd.f32 %v116841_v14, %v116778_v51 (stack53)
        %v117606_v22 = vor.u32 %v117605_v54, %v117604_v21 (stack47)
        %v118406_v51 = vshll.u32 %v118397_v27, 24 (stack45)
        %v118407_v61 = vshrl.u32 %v118397_v27, 8 (stack46)
        %v117211_v26 = vmul.f32 %v117210_v36, %v117204_v26 (stack63)
        %vm156003_vm1 = vcmp.lt.f32.partialorder %v117212_v48, 0.0004427343 (stack62)
        %v118007_v17 = vor.u32 %v118006_v12, %v118005_v56 (stack47)
        %v118814_v24 = vxor.u32 %v118813_v49, %v118809_v44 (stack48)
        %v116849_v7 = vmul.f32 %v116845_v62, %v155969_v38 (stack54)
        %v117607_v45 = vxor.u32 %v117606_v22, %v117602_v39 (stack48)
        %v118408_v30 = vor.u32 %v118407_v61, %v118406_v51 (stack47)
        %v119237_v9 = vadd.s32 1, %v119233_v13 (stack40)
        %v118008_v46 = vxor.u32 %v118007_v17, %v118003_v53 (stack48)
        %v118817_v55 = vadd.s32 %v118814_v24, %v118809_v44 (stack40)
        %v118823_v29 = vshll.u32 %v118814_v24, 6 (stack45)
        %v118824_v31 = vshrl.u32 %v118814_v24, 26 (stack46)
        %v121434_v8 = vpop.eup %121433 (stack64)
        %v116853_v34 = vadd.f32 %v116849_v7, %v155961_v34 (stack53)
        %v117610_v20 = vadd.s32 %v117607_v45, %v117602_v39 (stack40)
        %v117616_v60 = vshll.u32 %v117607_v45, 6 (stack45)
        %v117617_v44 = vshrl.u32 %v117607_v45, 26 (stack46)
        %v117208_v28 = vmul.f32 0.6931472, %v121434_v8 (stack65)
        %v118011_v16 = vadd.s32 %v118008_v46, %v118003_v53 (stack40)
        %v118013_v35 = vshll.u32 %v118008_v46, 29 (stack45)
        %v118014_v32 = vshrl.u32 %v118008_v46, 3 (stack46)
        %v116857_v48 = vmul.f32 %v116853_v34, %v155969_v38 (stack54)
        %v117618_v10 = vor.u32 %v117617_v44, %v117616_v60 (stack47)
        %v118409_v40 = vxor.u32 %v118408_v30, %v118400_v47 (stack48)
        %v119250_v37 = vadd.s32 %v155990_v58, %v121569_v1 (stack40)
        %v116770_v52 = vsel /*vm=*/%vm116757_vm13, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v117214_v36 = vsel /*vm=*/%vm156003_vm1, /*on_true_vy=*/%v117211_v26, /*on_false_vx=*/%v117208_v28 (stack66)
        %v118015_v59 = vor.u32 %v118014_v32, %v118013_v35 (stack47)
        %v118825_v43 = vor.u32 %v118824_v31, %v118823_v29 (stack47)
        %v116730_v25 = vand.u32 2147483647, %v155844_v6 (stack77)
        %v116861_v27 = vadd.f32 %v116857_v48, %v116770_v52 (stack53)
        %v156018_v49 = vxor.u32 2147483648, %v117214_v36 (stack56)
        %v117619_v14 = vxor.u32 %v117618_v10, %v117610_v20 (stack48)
        %v118016_v39 = vxor.u32 %v118015_v59, %v118011_v16 (stack48)
        %v118826_v21 = vxor.u32 %v118825_v43, %v118817_v55 (stack48)
        %v119241_v41 = vsel /*vm=*/%vm119215_vm0, /*on_true_vy=*/%v119237_v9, /*on_false_vx=*/%v119233_v13 (stack44)
        %v116865_v58 = vmul.f32 %v116861_v27, %v155969_v38 (stack54)
        %121435 = vrsqrt.f32 %v156018_v49 (stack67)
        %v119256_v13 = vshll.u32 %v119250_v37, 13 (stack45)
        %v119257_v54 = vshrl.u32 %v119250_v37, 19 (stack46)
        %v116766_v53 = vsel /*vm=*/%vm116757_vm13, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v117622_v56 = vadd.s32 %v117619_v14, %v121574_v2 (stack40)
        %v118412_v12 = vadd.s32 %v118409_v40, %v121574_v2 (stack40)
        %vm156030_vm2 = vcmp.eq.f32.partialorder %v116730_v25, 1.0 (stack68)
        %v116738_v22 = vmul.f32 inf, %v155844_v6 (stack54)
        %v116762_v23 = vsel /*vm=*/%vm116757_vm13, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v116869_v51 = vadd.f32 %v116865_v58, %v116766_v53 (stack53)
        %vm117218_vm3 = vcmp.lt.f32.partialorder %v156018_v49, 5.0 (stack68)
        %v117614_v61 = vadd.s32 %v117610_v20, %v121564_v0 (stack40)
        %v118019_v26 = vadd.s32 %v118016_v39, %v118011_v16 (stack40)
        %v118404_v47 = vadd.s32 %v118400_v47, %v121564_v0 (stack40)
        %v116873_v38 = vmul.f32 %v116869_v51, %v155969_v38 (stack54)
        %v156043_v42 = vadd.f32 -2.5, %v156018_v49 (stack53)
        %v118821_v17 = vadd.s32 %v118817_v55, %v121569_v1 (stack40)
        %v119258_v24 = vor.u32 %v119257_v54, %v119256_v13 (stack47)
        %v117626_v7 = vadd.s32 5, %v117622_v56 (stack40)
        %v118021_v45 = vshll.u32 %v118016_v39, 16 (stack45)
        %v118022_v30 = vshrl.u32 %v118016_v39, 16 (stack46)
        %v118416_v9 = vadd.s32 2, %v118412_v12 (stack40)
        %v116877_v46 = vadd.f32 %v116873_v38, %v116762_v23 (stack53)
        %v156049_v55 = vsel /*vm=*/%vm117218_vm3, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v118829_v29 = vadd.s32 %v118826_v21, %v121564_v0 (stack40)
        %v119246_v31 = vadd.s32 %v119241_v41, %v121574_v2 (stack40)
        %v117628_v8 = vxor.u32 %v117626_v7, %v117614_v61 (stack48)
        %v118023_v34 = vor.u32 %v118022_v30, %v118021_v45 (stack47)
        %v118420_v20 = vadd.s32 %v118416_v9, %v118404_v47 (stack40)
        %v118422_v60 = vshll.u32 %v118416_v9, 13 (stack45)
        %v116881_v6 = vmul.f32 %v116877_v46, %v155844_v6 (stack54)
        %v118423_v44 = vshrl.u32 %v118416_v9, 19 (stack46)
        %v118833_v28 = vadd.s32 1, %v118829_v29 (stack40)
        %v119254_v16 = vadd.s32 %v119250_v37, %v119246_v31 (stack40)
        %v117255_v35 = vsel /*vm=*/%vm117218_vm3, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %vm117263_vm4 = vcmp.eq.f32.partialorder %v156018_v49, inf (stack70)
        %v117629_v32 = vand.u32.u8 255, %v117628_v8 (stack49)
        %v118024_v48 = vxor.u32 %v118023_v34, %v118019_v26 (stack48)
        %v116885_v10 = vsel /*vm=*/%vm156030_vm2, /*on_true_vy=*/%v116738_v22, /*on_false_vx=*/%v116881_v6 (stack44)
        %v118424_v40 = vor.u32 %v118423_v44, %v118422_v60 (stack47)
        %v118837_v37 = vadd.s32 %v118833_v28, %v118821_v17 (stack40)
        %v118839_v52 = vshll.u32 %v118833_v28, 17 (stack45)
        %v116889_v36 = vmul.f32 1.4140625, %v116885_v10 (stack54)
        %v117630_v59 = vand.u32 65535, %v117629_v32 (stack50)
        %v118027_v43 = vadd.s32 %v118024_v48, %v118019_v26 (stack40)
        %v118033_v25 = vshll.u32 %v118024_v48, 24 (stack45)
        %v118034_v27 = vshrl.u32 %v118024_v48, 8 (stack46)
        %v118425_v14 = vxor.u32 %v118424_v40, %v118420_v20 (stack48)
        %v118840_v39 = vshrl.u32 %v118833_v28, 15 (stack46)
        %v119259_v21 = vxor.u32 %v119258_v24, %v119254_v16 (stack48)
        %v121436_v41 = vpop.eup %121435 (stack73)
        %v116892_v58 = vpack.c.bf16 %v157387_v11, %v116889_v36 (stack81)
        %vm117265_vm5 = vcmp.eq.f32.partialorder %v156018_v49, 0.0 (stack71)
        %v117266_v13 = vand.u32 2147483648, %v156018_v49 (stack72)
        %v117631_v54 = vshrl.u32 %v117630_v59, 1 (stack51)
        %v117262_v53 = vmul.f32 %v121436_v41, %v156018_v49 (stack74)
        %v118035_v56 = vor.u32 %v118034_v27, %v118033_v25 (stack47)
        %v118428_v12 = vadd.s32 %v118425_v14, %v118420_v20 (stack40)
        %v118430_v62 = vshll.u32 %v118425_v14, 15 (stack45)
        %120371 = vst [vmem:[%s123356_s30 + $0xfc] sm:$0xf] /*vst_source=*/%v116892_v58 (stack83)
        %v117632_v22 = vor.u32 16256, %v117631_v54 (stack47)
        %v118431_v23 = vshrl.u32 %v118425_v14, 17 (stack46)
        %v118841_v51 = vor.u32 %v118840_v39, %v118839_v52 (stack47)
        %v119262_v61 = vadd.s32 %v119259_v21, %v119254_v16 (stack40)
        %v117264_v26 = vsel /*vm=*/%vm117263_vm4, /*on_true_vy=*/%v156018_v49, /*on_false_vx=*/%v117262_v53 (stack75)
        %v118036_v47 = vxor.u32 %v118035_v56, %v118027_v43 (stack48)
        %v119264_v38 = vshll.u32 %v119259_v21, 15 (stack45)
        %v119265_v17 = vshrl.u32 %v119259_v21, 17 (stack46)
        %v117267_v24 = vsel /*vm=*/%vm117265_vm5, /*on_true_vy=*/%v117266_v13, /*on_false_vx=*/%v117264_v26 (stack76)
        %v117633_v7 = vand.u32.u16 65535, %v117632_v22 (stack52)
        %v118432_v45 = vor.u32 %v118431_v23, %v118430_v62 (stack47)
        %v118842_v30 = vxor.u32 %v118841_v51, %v118837_v37 (stack48)
        %v117270_v9 = vadd.f32 -3.0, %v117267_v24 (stack53)
        %v118031_v46 = vadd.s32 %v118027_v43, %v121569_v1 (stack40)
        %v118039_v29 = vadd.s32 %v118036_v47, %v121564_v0 (stack40)
        %v119266_v31 = vor.u32 %v119265_v17, %v119264_v38 (stack47)
        %v120374_v8 = vadd.low.f32.bf16 -1.0, %v117633_v7 (stack53)
        %v118433_v34 = vxor.u32 %v118432_v45, %v118428_v12 (stack48)
        %v118845_v20 = vadd.s32 %v118842_v30, %v118837_v37 (stack40)
        %v118847_v60 = vshll.u32 %v118842_v30, 29 (stack45)
        %v156075_v42 = vsel /*vm=*/%vm117218_vm3, /*on_true_vy=*/%v156043_v42, /*on_false_vx=*/%v117270_v9 (stack44)
        %v118043_v6 = vadd.s32 4, %v118039_v29 (stack40)
        %v118848_v44 = vshrl.u32 %v118842_v30, 3 (stack46)
        %v119267_v28 = vxor.u32 %v119266_v31, %v119262_v61 (stack48)
        %v117278_v16 = vmul.f32 %v156075_v42, %v117255_v35 (stack54)
        %v117642_v35 = vmul.f32 2.0, %v120374_v8 (stack54)
        %v118436_v32 = vadd.s32 %v118433_v34, %v118428_v12 (stack40)
        %v118438_v48 = vshll.u32 %v118433_v34, 26 (stack45)
        %v118047_v10 = vadd.s32 %v118043_v6, %v118031_v46 (stack40)
        %v118049_v40 = vshll.u32 %v118043_v6, 13 (stack45)
        %v118050_v37 = vshrl.u32 %v118043_v6, 19 (stack46)
        %v118439_v52 = vshrl.u32 %v118433_v34, 6 (stack46)
        %v117282_v55 = vadd.f32 %v117278_v16, %v156049_v55 (stack53)
        %v117646_v36 = vadd.f32 -0.99609375, %v117642_v35 (stack53)
        %v118849_v59 = vor.u32 %v118848_v44, %v118847_v60 (stack47)
        %v119270_v43 = vadd.s32 %v119267_v28, %v119262_v61 (stack40)
        %v118051_v25 = vor.u32 %v118050_v37, %v118049_v40 (stack47)
        %v118440_v27 = vor.u32 %v118439_v52, %v118438_v48 (stack47)
        %v117286_v14 = vmul.f32 %v117282_v55, %v156075_v42 (stack54)
        %v156080_v39 = vmax.f32 %v117646_v36, -0.99609375 (stack55)
        %v118850_v21 = vxor.u32 %v118849_v59, %v118845_v20 (stack48)
        %v117247_v41 = vsel /*vm=*/%vm117218_vm3, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v118052_v58 = vxor.u32 %v118051_v25, %v118047_v10 (stack48)
        %v118441_v13 = vxor.u32 %v118440_v27, %v118436_v32 (stack48)
        %v117290_v54 = vadd.f32 %v117286_v14, %v117247_v41 (stack53)
        %v117662_v53 = vxor.u32 2147483648, %v156080_v39 (stack56)
        %v119272_v56 = vshll.u32 %v119267_v28, 26 (stack45)
        %v119273_v12 = vshrl.u32 %v119267_v28, 6 (stack46)
        %v118055_v62 = vadd.s32 %v118052_v58, %v118047_v10 (stack40)
        %v118057_v22 = vshll.u32 %v118052_v58, 15 (stack45)
        %v118058_v23 = vshrl.u32 %v118052_v58, 17 (stack46)
        %v118444_v51 = vadd.s32 %v118441_v13, %v118436_v32 (stack40)
        %v117294_v61 = vmul.f32 %v117290_v54, %v156075_v42 (stack54)
        %v156088_v26 = vmul.f32 %v117662_v53, %v156080_v39 (stack54)
        %v118450_v47 = vshll.u32 %v118441_v13, 6 (stack45)
        %v117243_v38 = vsel /*vm=*/%vm117218_vm3, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v118059_v17 = vor.u32 %v118058_v23, %v118057_v22 (stack47)
        %v118451_v24 = vshrl.u32 %v118441_v13, 26 (stack46)
        %v118853_v7 = vadd.s32 %v118850_v21, %v118845_v20 (stack40)
        %v117298_v45 = vadd.f32 %v117294_v61, %v117243_v38 (stack53)
        %v117667_v30 = vadd.f32 1.0, %v156088_v26 (stack57)
        %v119274_v9 = vor.u32 %v119273_v12, %v119272_v56 (stack47)
        %v118060_v46 = vxor.u32 %v118059_v17, %v118055_v62 (stack48)
        %v118452_v29 = vor.u32 %v118451_v24, %v118450_v47 (stack47)
        %v118855_v31 = vshll.u32 %v118850_v21, 16 (stack45)
        %v118856_v8 = vshrl.u32 %v118850_v21, 16 (stack46)
        %v117239_v34 = vsel /*vm=*/%vm117218_vm3, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v117302_v20 = vmul.f32 %v117298_v45, %v156075_v42 (stack54)
        %121437 = vlog2.f32 %v117667_v30 (stack58)
        %v118063_v60 = vadd.s32 %v118060_v46, %v118055_v62 (stack40)
        %v118065_v6 = vshll.u32 %v118060_v46, 26 (stack45)
        %v118066_v44 = vshrl.u32 %v118060_v46, 6 (stack46)
        %v118453_v28 = vxor.u32 %v118452_v29, %v118444_v51 (stack48)
        %v117306_v16 = vadd.f32 %v117302_v20, %v117239_v34 (stack53)
        %v118857_v35 = vor.u32 %v118856_v8, %v118855_v31 (stack47)
        %v119275_v32 = vxor.u32 %v119274_v9, %v119270_v43 (stack48)
        %v117235_v48 = vsel /*vm=*/%vm117218_vm3, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v118067_v10 = vor.u32 %v118066_v44, %v118065_v6 (stack47)
        %v118448_v40 = vadd.s32 %v118444_v51, %v121574_v2 (stack40)
        %v118456_v37 = vadd.s32 %v118453_v28, %v121569_v1 (stack40)
        %v117310_v52 = vmul.f32 %v117306_v16, %v156075_v42 (stack54)
        %v117670_v55 = vmul.f32 -0.5, %v156088_v26 (stack59)
        %v118858_v36 = vxor.u32 %v118857_v35, %v118853_v7 (stack48)
        %v156105_v59 = vadd.s32 %v119275_v32, %v119270_v43 (stack40)
        %v118068_v43 = vxor.u32 %v118067_v10, %v118063_v60 (stack48)
        %v118460_v25 = vadd.s32 3, %v118456_v37 (stack40)
        %v119284_v27 = vshll.u32 %v119275_v32, 6 (stack45)
        %v119285_v14 = vshrl.u32 %v119275_v32, 26 (stack46)
        %v117314_v21 = vadd.f32 %v117310_v52, %v117235_v48 (stack53)
        %v118861_v41 = vadd.s32 %v118858_v36, %v118853_v7 (stack40)
        %v118867_v58 = vshll.u32 %v118858_v36, 24 (stack45)
        %v118868_v13 = vshrl.u32 %v118858_v36, 8 (stack46)
        %v118071_v54 = vadd.s32 %v118068_v43, %v118063_v60 (stack40)
        %v118077_v53 = vshll.u32 %v118068_v43, 6 (stack45)
        %v118078_v56 = vshrl.u32 %v118068_v43, 26 (stack46)
        %v118464_v12 = vadd.s32 %v118460_v25, %v118448_v40 (stack40)
        %v117318_v62 = vmul.f32 %v117314_v21, %v156075_v42 (stack54)
        %v117673_v22 = vand.u32 2147483647, %v156088_v26 (stack60)
        %v118466_v23 = vshll.u32 %v118460_v25, 17 (stack45)
        %v118467_v51 = vshrl.u32 %v118460_v25, 15 (stack46)
        %v117231_v61 = vsel /*vm=*/%vm117218_vm3, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v117671_v47 = vadd.f32 1.0, %v117670_v55 (stack61)
        %v118079_v38 = vor.u32 %v118078_v56, %v118077_v53 (stack47)
        %v118869_v17 = vor.u32 %v118868_v13, %v118867_v58 (stack47)
        %v117322_v24 = vadd.f32 %v117318_v62, %v117231_v61 (stack53)
        %v118468_v7 = vor.u32 %v118467_v51, %v118466_v23 (stack47)
        %v119286_v45 = vor.u32 %v119285_v14, %v119284_v27 (stack47)
        %v117191_v30 = vand.u32 2147483647, %v155952_v50 (stack77)
        %v117227_v9 = vsel /*vm=*/%vm117218_vm3, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v118080_v46 = vxor.u32 %v118079_v38, %v118071_v54 (stack48)
        %v118870_v29 = vxor.u32 %v118869_v17, %v118861_v41 (stack48)
        %v117326_v31 = vmul.f32 %v117322_v24, %v156075_v42 (stack54)
        %vm156117_vm6 = vcmp.lt.f32.partialorder %v117673_v22, 0.0004427343 (stack62)
        %v118469_v34 = vxor.u32 %v118468_v7, %v118464_v12 (stack48)
        %v119287_v20 = vxor.u32 %v119286_v45, %v156105_v59 (stack48)
        %v121438_v60 = vpop.eup %121437 (stack64)
        %v117672_v26 = vmul.f32 %v117671_v47, %v156088_v26 (stack63)
        %v118083_v6 = vadd.s32 %v118080_v46, %v121574_v2 (stack40)
        %v118865_v44 = vadd.s32 %v118861_v41, %v121564_v0 (stack40)
        %v118873_v28 = vadd.s32 %v118870_v29, %v121574_v2 (stack40)
        %v117330_v16 = vadd.f32 %v117326_v31, %v117227_v9 (stack53)
        %v117669_v35 = vmul.f32 0.6931472, %v121438_v60 (stack65)
        %v118472_v32 = vadd.s32 %v118469_v34, %v118464_v12 (stack40)
        %v118474_v48 = vshll.u32 %v118469_v34, 29 (stack45)
        %v118075_v10 = vadd.s32 %v118071_v54, %v121564_v0 (stack40)
        %v118087_v40 = vadd.s32 5, %v118083_v6 (stack40)
        %v118475_v37 = vshrl.u32 %v118469_v34, 3 (stack46)
        %v118877_v52 = vadd.s32 2, %v118873_v28 (stack40)
        %v117223_v49 = vsel /*vm=*/%vm117218_vm3, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v117334_v42 = vmul.f32 %v117330_v16, %v156075_v42 (stack54)
        %v117675_v55 = vsel /*vm=*/%vm156117_vm6, /*on_true_vy=*/%v117672_v26, /*on_false_vx=*/%v117669_v35 (stack66)
        %v119290_v36 = vadd.s32 %v119287_v20, %v121564_v0 (stack40)
        %v156134_v43 = vxor.u32 2147483648, %v117675_v55 (stack56)
        %v118089_v25 = vxor.u32 %v118087_v40, %v118075_v10 (stack48)
        %v118476_v27 = vor.u32 %v118475_v37, %v118474_v48 (stack47)
        %v118881_v14 = vadd.s32 %v118877_v52, %v118865_v44 (stack40)
        %v117338_v21 = vadd.f32 %v117334_v42, %v117223_v49 (stack53)
        %121439 = vrsqrt.f32 %v156134_v43 (stack67)
        %v117199_v41 = vmul.f32 inf, %v155952_v50 (stack54)
        %v117342_v50 = vmul.f32 %v117338_v21, %v155952_v50 (stack54)
        %v118883_v58 = vshll.u32 %v118877_v52, 13 (stack45)
        %v118884_v13 = vshrl.u32 %v118877_v52, 19 (stack46)
        %vm117194_vm7 = vcmp.eq.f32.partialorder %v117191_v30, 1.0 (stack68)
        %v118477_v54 = vxor.u32 %v118476_v27, %v118472_v32 (stack48)
        %v119294_v53 = vadd.s32 1, %v119290_v36 (stack40)
        %v117346_v56 = vsel /*vm=*/%vm117194_vm7, /*on_true_vy=*/%v117199_v41, /*on_false_vx=*/%v117342_v50 (stack44)
        %v117350_v12 = vmul.f32 1.4140625, %v117346_v56 (stack54)
        %v118090_v62 = vand.u32.u8 255, %v118089_v25 (stack49)
        %v119282_v59 = vadd.s32 %v156105_v59, %v121569_v1 (stack40)
        %v118480_v22 = vadd.s32 %v118477_v54, %v118472_v32 (stack40)
        %v118482_v23 = vshll.u32 %v118477_v54, 16 (stack45)
        %v118483_v51 = vshrl.u32 %v118477_v54, 16 (stack46)
        %v118885_v61 = vor.u32 %v118884_v13, %v118883_v58 (stack47)
        %v117353_v47 = vpack.c.bf16 %v157387_v11, %v117350_v12 (stack81)
        %v118091_v38 = vand.u32 65535, %v118090_v62 (stack50)
        %v119298_v17 = vadd.s32 %v119294_v53, %v119282_v59 (stack40)
        %v119300_v24 = vshll.u32 %v119294_v53, 17 (stack45)
        %v118484_v7 = vor.u32 %v118483_v51, %v118482_v23 (stack47)
        %v118886_v45 = vxor.u32 %v118885_v61, %v118881_v14 (stack48)
        %v119301_v30 = vshrl.u32 %v119294_v53, 15 (stack46)
        %120373 = vst [vmem:[%s123356_s30 + $0x17c] sm:$0xf] /*vst_source=*/%v117353_v47 (stack83)
        %v118092_v9 = vshrl.u32 %v118091_v38, 1 (stack51)
        %v118485_v46 = vxor.u32 %v118484_v7, %v118480_v22 (stack48)
        %v118889_v29 = vadd.s32 %v118886_v45, %v118881_v14 (stack40)
        %v118891_v31 = vshll.u32 %v118886_v45, 15 (stack45)
        %v118892_v8 = vshrl.u32 %v118886_v45, 17 (stack46)
        %v118093_v34 = vor.u32 16256, %v118092_v9 (stack47)
        %v119302_v20 = vor.u32 %v119301_v30, %v119300_v24 (stack47)
        %v118488_v60 = vadd.s32 %v118485_v46, %v118480_v22 (stack40)
        %v118494_v26 = vshll.u32 %v118485_v46, 24 (stack45)
        %v118495_v6 = vshrl.u32 %v118485_v46, 8 (stack46)
        %v118893_v44 = vor.u32 %v118892_v8, %v118891_v31 (stack47)
        %v118094_v28 = vand.u32.u16 65535, %v118093_v34 (stack52)
        %v119303_v16 = vxor.u32 %v119302_v20, %v119298_v17 (stack48)
        %v121440_v35 = vpop.eup %121439 (stack73)
        %vm117724_vm8 = vcmp.eq.f32.partialorder %v156134_v43, inf (stack70)
        %v117727_v32 = vand.u32 2147483648, %v156134_v43 (stack72)
        %v118496_v48 = vor.u32 %v118495_v6, %v118494_v26 (stack47)
        %v118894_v10 = vxor.u32 %v118893_v44, %v118889_v29 (stack48)
        %v117723_v40 = vmul.f32 %v121440_v35, %v156134_v43 (stack74)
        %v120376_v37 = vadd.low.f32.bf16 -1.0, %v118094_v28 (stack53)
        %v119306_v52 = vadd.s32 %v119303_v16, %v119298_v17 (stack40)
        %v119308_v49 = vshll.u32 %v119303_v16, 29 (stack45)
        %v118497_v42 = vxor.u32 %v118496_v48, %v118488_v60 (stack48)
        %v118897_v55 = vadd.s32 %v118894_v10, %v118889_v29 (stack40)
        %v118899_v36 = vshll.u32 %v118894_v10, 26 (stack45)
        %v118900_v25 = vshrl.u32 %v118894_v10, 6 (stack46)
        %v117725_v27 = vsel /*vm=*/%vm117724_vm8, /*on_true_vy=*/%v156134_v43, /*on_false_vx=*/%v117723_v40 (stack75)
        %vm117726_vm9 = vcmp.eq.f32.partialorder %v156134_v43, 0.0 (stack71)
        %v118103_v14 = vmul.f32 2.0, %v120376_v37 (stack54)
        %v119309_v21 = vshrl.u32 %v119303_v16, 3 (stack46)
        %vm117679_vm10 = vcmp.lt.f32.partialorder %v156134_v43, 5.0 (stack68)
        %v117728_v41 = vsel /*vm=*/%vm117726_vm9, /*on_true_vy=*/%v117727_v32, /*on_false_vx=*/%v117725_v27 (stack76)
        %v118500_v50 = vadd.s32 %v118497_v42, %v121564_v0 (stack40)
        %v118901_v58 = vor.u32 %v118900_v25, %v118899_v36 (stack47)
        %v117720_v13 = vadd.f32 -2.5, %v156134_v43 (stack53)
        %v117731_v54 = vadd.f32 -3.0, %v117728_v41 (stack53)
        %v118107_v53 = vadd.f32 -0.99609375, %v118103_v14 (stack53)
        %v119310_v56 = vor.u32 %v119309_v21, %v119308_v49 (stack47)
        %v118492_v12 = vadd.s32 %v118488_v60, %v121569_v1 (stack40)
        %v118504_v62 = vadd.s32 4, %v118500_v50 (stack40)
        %v118902_v59 = vxor.u32 %v118901_v58, %v118897_v55 (stack48)
        %v117716_v22 = vsel /*vm=*/%vm117679_vm10, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v156157_v23 = vsel /*vm=*/%vm117679_vm10, /*on_true_vy=*/%v117720_v13, /*on_false_vx=*/%v117731_v54 (stack44)
        %v156159_v51 = vmax.f32 %v118107_v53, -0.99609375 (stack55)
        %v119311_v61 = vxor.u32 %v119310_v56, %v119306_v52 (stack48)
        %v117739_v47 = vmul.f32 %v156157_v23, %v117716_v22 (stack54)
        %v118508_v38 = vadd.s32 %v118504_v62, %v118492_v12 (stack40)
        %v118510_v17 = vshll.u32 %v118504_v62, 13 (stack45)
        %v118511_v24 = vshrl.u32 %v118504_v62, 19 (stack46)
        %v117712_v7 = vsel /*vm=*/%vm117679_vm10, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v118123_v45 = vxor.u32 2147483648, %v156159_v51 (stack56)
        %v118905_v30 = vadd.s32 %v118902_v59, %v118897_v55 (stack40)
        %v117743_v9 = vadd.f32 %v117739_v47, %v117712_v7 (stack53)
        %v118512_v46 = vor.u32 %v118511_v24, %v118510_v17 (stack47)
        %v118911_v29 = vshll.u32 %v118902_v59, 6 (stack45)
        %v118912_v31 = vshrl.u32 %v118902_v59, 26 (stack46)
        %v156167_v8 = vmul.f32 %v118123_v45, %v156159_v51 (stack54)
        %v119314_v34 = vadd.s32 %v119311_v61, %v119306_v52 (stack40)
        %v117747_v20 = vmul.f32 %v117743_v9, %v156157_v23 (stack54)
        %v118513_v60 = vxor.u32 %v118512_v46, %v118508_v38 (stack48)
        %v118913_v26 = vor.u32 %v118912_v31, %v118911_v29 (stack47)
        %v119316_v6 = vshll.u32 %v119311_v61, 16 (stack45)
        %v117708_v44 = vsel /*vm=*/%vm117679_vm10, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v118128_v28 = vadd.f32 1.0, %v156167_v8 (stack57)
        %v119317_v16 = vshrl.u32 %v119311_v61, 16 (stack46)
        %v117751_v35 = vadd.f32 %v117747_v20, %v117708_v44 (stack53)
        %v118516_v32 = vadd.s32 %v118513_v60, %v118508_v38 (stack40)
        %v118518_v48 = vshll.u32 %v118513_v60, 15 (stack45)
        %v118519_v10 = vshrl.u32 %v118513_v60, 17 (stack46)
        %121441 = vlog2.f32 %v118128_v28 (stack58)
        %v118914_v40 = vxor.u32 %v118913_v26, %v118905_v30 (stack48)
        %v117755_v37 = vmul.f32 %v117751_v35, %v156157_v23 (stack54)
        %v118520_v52 = vor.u32 %v118519_v10, %v118518_v48 (stack47)
        %v119318_v49 = vor.u32 %v119317_v16, %v119316_v6 (stack47)
        %v117704_v42 = vsel /*vm=*/%vm117679_vm10, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v118917_v55 = vadd.s32 %v118914_v40, %v121569_v1 (stack40)
        %v117759_v36 = vadd.f32 %v117755_v37, %v117704_v42 (stack53)
        %v118521_v25 = vxor.u32 %v118520_v52, %v118516_v32 (stack48)
        %v119319_v27 = vxor.u32 %v119318_v49, %v119314_v34 (stack48)
        %v117700_v14 = vsel /*vm=*/%vm117679_vm10, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v118131_v21 = vmul.f32 -0.5, %v156167_v8 (stack59)
        %v118909_v41 = vadd.s32 %v118905_v30, %v121574_v2 (stack40)
        %v118921_v50 = vadd.s32 3, %v118917_v55 (stack40)
        %v117763_v58 = vmul.f32 %v117759_v36, %v156157_v23 (stack54)
        %v118524_v13 = vadd.s32 %v118521_v25, %v118516_v32 (stack40)
        %v118526_v54 = vshll.u32 %v118521_v25, 26 (stack45)
        %v118527_v53 = vshrl.u32 %v118521_v25, 6 (stack46)
        %v118925_v56 = vadd.s32 %v118921_v50, %v118909_v41 (stack40)
        %v118927_v12 = vshll.u32 %v118921_v50, 17 (stack45)
        %v118928_v62 = vshrl.u32 %v118921_v50, 15 (stack46)
        %v119322_v59 = vadd.s32 %v119319_v27, %v119314_v34 (stack40)
        %v117767_v22 = vadd.f32 %v117763_v58, %v117700_v14 (stack53)
        %v118528_v61 = vor.u32 %v118527_v53, %v118526_v54 (stack47)
        %v119328_v47 = vshll.u32 %v119319_v27, 24 (stack45)
        %v119329_v38 = vshrl.u32 %v119319_v27, 8 (stack46)
        %v118929_v17 = vor.u32 %v118928_v62, %v118927_v12 (stack47)
        %v117771_v24 = vmul.f32 %v117767_v22, %v156157_v23 (stack54)
        %v118529_v7 = vxor.u32 %v118528_v61, %v118524_v13 (stack48)
        %v119330_v45 = vor.u32 %v119329_v38, %v119328_v47 (stack47)
        %v117696_v30 = vsel /*vm=*/%vm117679_vm10, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v118132_v9 = vadd.f32 1.0, %v118131_v21 (stack61)
        %v118134_v46 = vand.u32 2147483647, %v156167_v8 (stack60)
        %v118930_v29 = vxor.u32 %v118929_v17, %v118925_v56 (stack48)
        %v117775_v31 = vadd.f32 %v117771_v24, %v117696_v30 (stack53)
        %v118532_v34 = vadd.s32 %v118529_v7, %v118524_v13 (stack40)
        %v118538_v20 = vshll.u32 %v118529_v7, 6 (stack45)
        %v118539_v60 = vshrl.u32 %v118529_v7, 26 (stack46)
        %v118933_v26 = vadd.s32 %v118930_v29, %v118925_v56 (stack40)
        %v118935_v6 = vshll.u32 %v118930_v29, 29 (stack45)
        %v118936_v44 = vshrl.u32 %v118930_v29, 3 (stack46)
        %v119331_v28 = vxor.u32 %v119330_v45, %v119322_v59 (stack48)
        %v121442_v16 = vpop.eup %121441 (stack64)
        %v117692_v35 = vsel /*vm=*/%vm117679_vm10, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v117779_v32 = vmul.f32 %v117775_v31, %v156157_v23 (stack54)
        %v118540_v48 = vor.u32 %v118539_v60, %v118538_v20 (stack47)
        %v118130_v10 = vmul.f32 0.6931472, %v121442_v16 (stack65)
        %v118133_v8 = vmul.f32 %v118132_v9, %v156167_v8 (stack63)
        %v118937_v40 = vor.u32 %v118936_v44, %v118935_v6 (stack47)
        %v119334_v37 = vadd.s32 %v119331_v28, %v121574_v2 (stack40)
        %v117783_v52 = vadd.f32 %v117779_v32, %v117692_v35 (stack53)
        %vm118135_vm11 = vcmp.lt.f32.partialorder %v118134_v46, 0.0004427343 (stack62)
        %v118541_v49 = vxor.u32 %v118540_v48, %v118532_v34 (stack48)
        %v118136_v42 = vsel /*vm=*/%vm118135_vm11, /*on_true_vy=*/%v118133_v8, /*on_false_vx=*/%v118130_v10 (stack66)
        %v118938_v55 = vxor.u32 %v118937_v40, %v118933_v26 (stack48)
        %v119326_v36 = vadd.s32 %v119322_v59, %v121564_v0 (stack40)
        %v119338_v25 = vadd.s32 2, %v119334_v37 (stack40)
        %v117688_v27 = vsel /*vm=*/%vm117679_vm10, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v117787_v14 = vmul.f32 %v117783_v52, %v156157_v23 (stack54)
        %v156201_v21 = vxor.u32 2147483648, %v118136_v42 (stack56)
        %v118941_v41 = vadd.s32 %v118938_v55, %v118933_v26 (stack40)
        %v118943_v50 = vshll.u32 %v118938_v55, 16 (stack45)
        %v118944_v58 = vshrl.u32 %v118938_v55, 16 (stack46)
        %v119342_v13 = vadd.s32 %v119338_v25, %v119326_v36 (stack40)
        %v117791_v54 = vadd.f32 %v117787_v14, %v117688_v27 (stack53)
        %121443 = vrsqrt.f32 %v156201_v21 (stack67)
        %v118544_v53 = vadd.s32 %v118541_v49, %v121574_v2 (stack40)
        %v118945_v56 = vor.u32 %v118944_v58, %v118943_v50 (stack47)
        %v117795_v23 = vmul.f32 %v117791_v54, %v156157_v23 (stack54)
        %v117652_v12 = vand.u32 2147483647, %v156080_v39 (stack77)
        %v117684_v43 = vsel /*vm=*/%vm117679_vm10, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v118946_v62 = vxor.u32 %v118945_v56, %v118941_v41 (stack48)
        %v117799_v59 = vadd.f32 %v117795_v23, %v117684_v43 (stack53)
        %v118536_v22 = vadd.s32 %v118532_v34, %v121564_v0 (stack40)
        %v118548_v61 = vadd.s32 5, %v118544_v53 (stack40)
        %v118949_v47 = vadd.s32 %v118946_v62, %v118941_v41 (stack40)
        %v118955_v38 = vshll.u32 %v118946_v62, 24 (stack45)
        %v118956_v17 = vshrl.u32 %v118946_v62, 8 (stack46)
        %v117660_v24 = vmul.f32 inf, %v156080_v39 (stack54)
        %v117803_v39 = vmul.f32 %v117799_v59, %v156080_v39 (stack54)
        %v119344_v7 = vshll.u32 %v119338_v25, 13 (stack45)
        %v119345_v45 = vshrl.u32 %v119338_v25, 19 (stack46)
        %vm117655_vm12 = vcmp.eq.f32.partialorder %v117652_v12, 1.0 (stack68)
        %v118550_v30 = vxor.u32 %v118548_v61, %v118536_v22 (stack48)
        %v118957_v9 = vor.u32 %v118956_v17, %v118955_v38 (stack47)
        %v117807_v46 = vsel /*vm=*/%vm117655_vm12, /*on_true_vy=*/%v117660_v24, /*on_false_vx=*/%v117803_v39 (stack44)
        %v119346_v29 = vor.u32 %v119345_v45, %v119344_v7 (stack47)
        %v117811_v31 = vmul.f32 1.4140625, %v117807_v46 (stack54)
        %v118551_v34 = vand.u32.u8 255, %v118550_v30 (stack49)
        %v118958_v20 = vxor.u32 %v118957_v9, %v118949_v47 (stack48)
        %v119347_v60 = vxor.u32 %v119346_v29, %v119342_v13 (stack48)
        %v117814_v26 = vpack.c.bf16 %v157387_v11, %v117811_v31 (stack81)
        %v118552_v6 = vand.u32 65535, %v118551_v34 (stack50)
        %v118961_v44 = vadd.s32 %v118958_v20, %v121564_v0 (stack40)
        %v119350_v28 = vadd.s32 %v119347_v60, %v119342_v13 (stack40)
        %v119352_v16 = vshll.u32 %v119347_v60, 15 (stack45)
        %v119353_v35 = vshrl.u32 %v119347_v60, 17 (stack46)
        %v121444_v32 = vpop.eup %121443 (stack73)
        %120375 = vst [vmem:[%s123356_s30 + $0x1fc] sm:$0xf] /*vst_source=*/%v117814_v26 (stack83)
        %v118553_v48 = vshrl.u32 %v118552_v6, 1 (stack51)
        %v118953_v10 = vadd.s32 %v118949_v47, %v121569_v1 (stack40)
        %v118965_v8 = vadd.s32 4, %v118961_v44 (stack40)
        %v118184_v40 = vmul.f32 %v121444_v32, %v156201_v21 (stack74)
        %vm118185_vm13 = vcmp.eq.f32.partialorder %v156201_v21, inf (stack70)
        %v118188_v37 = vand.u32 2147483648, %v156201_v21 (stack72)
        %v119354_v52 = vor.u32 %v119353_v35, %v119352_v16 (stack47)
        %v118554_v49 = vor.u32 16256, %v118553_v48 (stack47)
        %v118969_v42 = vadd.s32 %v118965_v8, %v118953_v10 (stack40)
        %v118971_v55 = vshll.u32 %v118965_v8, 13 (stack45)
        %v118972_v36 = vshrl.u32 %v118965_v8, 19 (stack46)
        %vm118140_vm14 = vcmp.lt.f32.partialorder %v156201_v21, 5.0 (stack68)
        %v118186_v25 = vsel /*vm=*/%vm118185_vm13, /*on_true_vy=*/%v156201_v21, /*on_false_vx=*/%v118184_v40 (stack75)
        %vm118187_vm15 = vcmp.eq.f32.partialorder %v156201_v21, 0.0 (stack71)
        %v119355_v27 = vxor.u32 %v119354_v52, %v119350_v28 (stack48)
        %v118181_v14 = vadd.f32 -2.5, %v156201_v21 (stack53)
        %v118189_v41 = vsel /*vm=*/%vm118187_vm15, /*on_true_vy=*/%v118188_v37, /*on_false_vx=*/%v118186_v25 (stack76)
        %v118555_v50 = vand.u32.u16 65535, %v118554_v49 (stack52)
        %v118973_v58 = vor.u32 %v118972_v36, %v118971_v55 (stack47)
        %v118192_v13 = vadd.f32 -3.0, %v118189_v41 (stack53)
        %v119358_v54 = vadd.s32 %v119355_v27, %v119350_v28 (stack40)
        %v119360_v53 = vshll.u32 %v119355_v27, 26 (stack45)
        %v119361_v56 = vshrl.u32 %v119355_v27, 6 (stack46)
        %v120378_v23 = vadd.low.f32.bf16 -1.0, %v118555_v50 (stack53)
        %v118974_v12 = vxor.u32 %v118973_v58, %v118969_v42 (stack48)
        %v118177_v43 = vsel /*vm=*/%vm118140_vm14, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v156229_v62 = vsel /*vm=*/%vm118140_vm14, /*on_true_vy=*/%v118181_v14, /*on_false_vx=*/%v118192_v13 (stack44)
        %v119362_v59 = vor.u32 %v119361_v56, %v119360_v53 (stack47)
        %v118200_v22 = vmul.f32 %v156229_v62, %v118177_v43 (stack54)
        %v118564_v61 = vmul.f32 2.0, %v120378_v23 (stack54)
        %v118977_v47 = vadd.s32 %v118974_v12, %v118969_v42 (stack40)
        %v118979_v38 = vshll.u32 %v118974_v12, 15 (stack45)
        %v118173_v17 = vsel /*vm=*/%vm118140_vm14, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v118980_v24 = vshrl.u32 %v118974_v12, 17 (stack46)
        %v119363_v39 = vxor.u32 %v119362_v59, %v119358_v54 (stack48)
        %v118204_v7 = vadd.f32 %v118200_v22, %v118173_v17 (stack53)
        %v118568_v45 = vadd.f32 -0.99609375, %v118564_v61 (stack53)
        %v118981_v30 = vor.u32 %v118980_v24, %v118979_v38 (stack47)
        %v119366_v9 = vadd.s32 %v119363_v39, %v119358_v54 (stack40)
        %v119372_v46 = vshll.u32 %v119363_v39, 6 (stack45)
        %v119373_v29 = vshrl.u32 %v119363_v39, 26 (stack46)
        %v118208_v31 = vmul.f32 %v118204_v7, %v156229_v62 (stack54)
        %v156236_v34 = vmax.f32 %v118568_v45, -0.99609375 (stack55)
        %v118169_v20 = vsel /*vm=*/%vm118140_vm14, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v118982_v60 = vxor.u32 %v118981_v30, %v118977_v47 (stack48)
        %v119374_v26 = vor.u32 %v119373_v29, %v119372_v46 (stack47)
        %v118212_v6 = vadd.f32 %v118208_v31, %v118169_v20 (stack53)
        %v118584_v44 = vxor.u32 2147483648, %v156236_v34 (stack56)
        %v118985_v28 = vadd.s32 %v118982_v60, %v118977_v47 (stack40)
        %v118987_v16 = vshll.u32 %v118982_v60, 26 (stack45)
        %v118988_v35 = vshrl.u32 %v118982_v60, 6 (stack46)
        %v119375_v32 = vxor.u32 %v119374_v26, %v119366_v9 (stack48)
        %v118216_v48 = vmul.f32 %v118212_v6, %v156229_v62 (stack54)
        %v118587_v10 = vmul.f32 %v118584_v44, %v156236_v34 (stack54)
        %v118165_v8 = vsel /*vm=*/%vm118140_vm14, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v118989_v40 = vor.u32 %v118988_v35, %v118987_v16 (stack47)
        %v119378_v37 = vadd.s32 %v119375_v32, %v121569_v1 (stack40)
        %v118220_v52 = vadd.f32 %v118216_v48, %v118165_v8 (stack53)
        %v118589_v49 = vadd.f32 1.0, %v118587_v10 (stack57)
        %v118990_v42 = vxor.u32 %v118989_v40, %v118985_v28 (stack48)
        %v119370_v55 = vadd.s32 %v119366_v9, %v121574_v2 (stack40)
        %v119382_v36 = vadd.s32 3, %v119378_v37 (stack40)
        %v118161_v25 = vsel /*vm=*/%vm118140_vm14, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v118224_v27 = vmul.f32 %v118220_v52, %v156229_v62 (stack54)
        %121445 = vlog2.f32 %v118589_v49 (stack58)
        %v118993_v14 = vadd.s32 %v118990_v42, %v118985_v28 (stack40)
        %v118999_v41 = vshll.u32 %v118990_v42, 6 (stack45)
        %v119000_v50 = vshrl.u32 %v118990_v42, 26 (stack46)
        %v119386_v58 = vadd.s32 %v119382_v36, %v119370_v55 (stack40)
        %v118228_v13 = vadd.f32 %v118224_v27, %v118161_v25 (stack53)
        %v119388_v54 = vshll.u32 %v119382_v36, 17 (stack45)
        %v119389_v53 = vshrl.u32 %v119382_v36, 15 (stack46)
        %v119001_v56 = vor.u32 %v119000_v50, %v118999_v41 (stack47)
        %v118232_v23 = vmul.f32 %v118228_v13, %v156229_v62 (stack54)
        %v119390_v12 = vor.u32 %v119389_v53, %v119388_v54 (stack47)
        %v118157_v43 = vsel /*vm=*/%vm118140_vm14, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v118592_v59 = vmul.f32 -0.5, %v118587_v10 (stack59)
        %v119002_v22 = vxor.u32 %v119001_v56, %v118993_v14 (stack48)
        %v118236_v61 = vadd.f32 %v118232_v23, %v118157_v43 (stack53)
        %v119391_v47 = vxor.u32 %v119390_v12, %v119386_v58 (stack48)
        %v119005_v38 = vadd.s32 %v119002_v22, %v121574_v2 (stack40)
        %v118240_v17 = vmul.f32 %v118236_v61, %v156229_v62 (stack54)
        %v119394_v24 = vadd.s32 %v119391_v47, %v119386_v58 (stack40)
        %v119396_v39 = vshll.u32 %v119391_v47, 29 (stack45)
        %v119397_v7 = vshrl.u32 %v119391_v47, 3 (stack46)
        %v118153_v45 = vsel /*vm=*/%vm118140_vm14, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v118593_v30 = vadd.f32 1.0, %v118592_v59 (stack61)
        %v118997_v9 = vadd.s32 %v118993_v14, %v121564_v0 (stack40)
        %v119009_v46 = vadd.s32 5, %v119005_v38 (stack40)
        %v118244_v29 = vadd.f32 %v118240_v17, %v118153_v45 (stack53)
        %v119398_v31 = vor.u32 %v119397_v7, %v119396_v39 (stack47)
        %v118595_v20 = vand.u32 2147483647, %v118587_v10 (stack60)
        %v119011_v60 = vxor.u32 %v119009_v46, %v118997_v9 (stack48)
        %v118248_v26 = vmul.f32 %v118244_v29, %v156229_v62 (stack54)
        %v119399_v6 = vxor.u32 %v119398_v31, %v119394_v24 (stack48)
        %v121446_v44 = vpop.eup %121445 (stack64)
        %v118149_v28 = vsel /*vm=*/%vm118140_vm14, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v118594_v16 = vmul.f32 %v118593_v30, %v118587_v10 (stack63)
        %v119012_v35 = vand.u32.u8 255, %v119011_v60 (stack49)
        %v118252_v32 = vadd.f32 %v118248_v26, %v118149_v28 (stack53)
        %v118591_v48 = vmul.f32 0.6931472, %v121446_v44 (stack65)
        %v119402_v10 = vadd.s32 %v119399_v6, %v119394_v24 (stack40)
        %v119404_v8 = vshll.u32 %v119399_v6, 16 (stack45)
        %vm118596_vm0 = vcmp.lt.f32.partialorder %v118595_v20, 0.0004427343 (stack62)
        %v119013_v40 = vand.u32 65535, %v119012_v35 (stack50)
        %v119405_v37 = vshrl.u32 %v119399_v6, 16 (stack46)
        %v118256_v62 = vmul.f32 %v118252_v32, %v156229_v62 (stack54)
        %v118597_v52 = vsel /*vm=*/%vm118596_vm0, /*on_true_vy=*/%v118594_v16, /*on_false_vx=*/%v118591_v48 (stack66)
        %v118113_v49 = vand.u32 2147483647, %v156159_v51 (stack77)
        %v118145_v21 = vsel /*vm=*/%vm118140_vm14, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v156272_v42 = vxor.u32 2147483648, %v118597_v52 (stack56)
        %v119406_v55 = vor.u32 %v119405_v37, %v119404_v8 (stack47)
        %v118260_v36 = vadd.f32 %v118256_v62, %v118145_v21 (stack53)
        %121447 = vrsqrt.f32 %v156272_v42 (stack67)
        %v119014_v25 = vshrl.u32 %v119013_v40, 1 (stack51)
        %v118121_v27 = vmul.f32 inf, %v156159_v51 (stack54)
        %v118264_v51 = vmul.f32 %v118260_v36, %v156159_v51 (stack54)
        %vm118116_vm1 = vcmp.eq.f32.partialorder %v118113_v49, 1.0 (stack68)
        %v119407_v14 = vxor.u32 %v119406_v55, %v119402_v10 (stack48)
        %v118268_v41 = vsel /*vm=*/%vm118116_vm1, /*on_true_vy=*/%v118121_v27, /*on_false_vx=*/%v118264_v51 (stack44)
        %v118272_v50 = vmul.f32 1.4140625, %v118268_v41 (stack54)
        %v119015_v58 = vor.u32 16256, %v119014_v25 (stack47)
        %v119410_v13 = vadd.s32 %v119407_v14, %v119402_v10 (stack40)
        %v119416_v54 = vshll.u32 %v119407_v14, 24 (stack45)
        %v119417_v53 = vshrl.u32 %v119407_v14, 8 (stack46)
        %v118275_v56 = vpack.c.bf16 %v157387_v11, %v118272_v50 (stack81)
        %v119016_v23 = vand.u32.u16 65535, %v119015_v58 (stack52)
        %v119418_v12 = vor.u32 %v119417_v53, %v119416_v54 (stack47)
        %120377 = vst [vmem:[%s123356_s30 + $0x27c] sm:$0xf] /*vst_source=*/%v118275_v56 (stack83)
        %v120380_v43 = vadd.low.f32.bf16 -1.0, %v119016_v23 (stack53)
        %v119419_v59 = vxor.u32 %v119418_v12, %v119410_v13 (stack48)
        %v119025_v22 = vmul.f32 2.0, %v120380_v43 (stack54)
        %v119422_v61 = vadd.s32 %v119419_v59, %v121564_v0 (stack40)
        %v119029_v47 = vadd.f32 -0.99609375, %v119025_v22 (stack53)
        %v121448_v38 = vpop.eup %121447 (stack73)
        %v119414_v17 = vadd.s32 %v119410_v13, %v121569_v1 (stack40)
        %v119426_v24 = vadd.s32 4, %v119422_v61 (stack40)
        %v118645_v39 = vmul.f32 %v121448_v38, %v156272_v42 (stack74)
        %vm118646_vm2 = vcmp.eq.f32.partialorder %v156272_v42, inf (stack70)
        %v156283_v7 = vmax.f32 %v119029_v47, -0.99609375 (stack55)
        %v118649_v45 = vand.u32 2147483648, %v156272_v42 (stack72)
        %v119430_v30 = vadd.s32 %v119426_v24, %v119414_v17 (stack40)
        %v119432_v9 = vshll.u32 %v119426_v24, 13 (stack45)
        %v119433_v46 = vshrl.u32 %v119426_v24, 19 (stack46)
        %v118647_v29 = vsel /*vm=*/%vm118646_vm2, /*on_true_vy=*/%v156272_v42, /*on_false_vx=*/%v118645_v39 (stack75)
        %vm118648_vm3 = vcmp.eq.f32.partialorder %v156272_v42, 0.0 (stack71)
        %v119045_v31 = vxor.u32 2147483648, %v156283_v7 (stack56)
        %vm118601_vm4 = vcmp.lt.f32.partialorder %v156272_v42, 5.0 (stack68)
        %v118650_v20 = vsel /*vm=*/%vm118648_vm3, /*on_true_vy=*/%v118649_v45, /*on_false_vx=*/%v118647_v29 (stack76)
        %v119434_v60 = vor.u32 %v119433_v46, %v119432_v9 (stack47)
        %v118642_v26 = vadd.f32 -2.5, %v156272_v42 (stack53)
        %v118653_v6 = vadd.f32 -3.0, %v118650_v20 (stack53)
        %v119048_v44 = vmul.f32 %v119045_v31, %v156283_v7 (stack54)
        %v119435_v28 = vxor.u32 %v119434_v60, %v119430_v30 (stack48)
        %v118638_v16 = vsel /*vm=*/%vm118601_vm4, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v118657_v35 = vsel /*vm=*/%vm118601_vm4, /*on_true_vy=*/%v118642_v26, /*on_false_vx=*/%v118653_v6 (stack44)
        %v119050_v32 = vadd.f32 1.0, %v119048_v44 (stack57)
        %v118661_v48 = vmul.f32 %v118657_v35, %v118638_v16 (stack54)
        %v119438_v10 = vadd.s32 %v119435_v28, %v119430_v30 (stack40)
        %v119440_v8 = vshll.u32 %v119435_v28, 15 (stack45)
        %v119441_v40 = vshrl.u32 %v119435_v28, 17 (stack46)
        %v118634_v37 = vsel /*vm=*/%vm118601_vm4, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %121449 = vlog2.f32 %v119050_v32 (stack58)
        %v118665_v62 = vadd.f32 %v118661_v48, %v118634_v37 (stack53)
        %v119442_v52 = vor.u32 %v119441_v40, %v119440_v8 (stack47)
        %v118669_v49 = vmul.f32 %v118665_v62, %v118657_v35 (stack54)
        %v119443_v21 = vxor.u32 %v119442_v52, %v119438_v10 (stack48)
        %v118630_v55 = vsel /*vm=*/%vm118601_vm4, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v118673_v36 = vadd.f32 %v118669_v49, %v118630_v55 (stack53)
        %v119446_v25 = vadd.s32 %v119443_v21, %v119438_v10 (stack40)
        %v119448_v27 = vshll.u32 %v119443_v21, 26 (stack45)
        %v119449_v51 = vshrl.u32 %v119443_v21, 6 (stack46)
        %v119053_v14 = vmul.f32 -0.5, %v119048_v44 (stack59)
        %v118677_v41 = vmul.f32 %v118673_v36, %v118657_v35 (stack54)
        %v119450_v50 = vor.u32 %v119449_v51, %v119448_v27 (stack47)
        %v118626_v58 = vsel /*vm=*/%vm118601_vm4, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v118681_v13 = vadd.f32 %v118677_v41, %v118626_v58 (stack53)
        %v119451_v54 = vxor.u32 %v119450_v50, %v119446_v25 (stack48)
        %v119054_v53 = vadd.f32 1.0, %v119053_v14 (stack61)
        %v119056_v56 = vand.u32 2147483647, %v119048_v44 (stack60)
        %v118685_v23 = vmul.f32 %v118681_v13, %v118657_v35 (stack54)
        %v119454_v12 = vadd.s32 %v119451_v54, %v119446_v25 (stack40)
        %v119460_v43 = vshll.u32 %v119451_v54, 6 (stack45)
        %v119461_v59 = vshrl.u32 %v119451_v54, 26 (stack46)
        %v118622_v22 = vsel /*vm=*/%vm118601_vm4, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v121450_v61 = vpop.eup %121449 (stack64)
        %v118689_v47 = vadd.f32 %v118685_v23, %v118622_v22 (stack53)
        %v119462_v38 = vor.u32 %v119461_v59, %v119460_v43 (stack47)
        %v119052_v17 = vmul.f32 0.6931472, %v121450_v61 (stack65)
        %v119055_v24 = vmul.f32 %v119054_v53, %v119048_v44 (stack63)
        %v118693_v39 = vmul.f32 %v118689_v47, %v118657_v35 (stack54)
        %vm119057_vm5 = vcmp.lt.f32.partialorder %v119056_v56, 0.0004427343 (stack62)
        %v119463_v45 = vxor.u32 %v119462_v38, %v119454_v12 (stack48)
        %v118618_v30 = vsel /*vm=*/%vm118601_vm4, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v119058_v9 = vsel /*vm=*/%vm119057_vm5, /*on_true_vy=*/%v119055_v24, /*on_false_vx=*/%v119052_v17 (stack66)
        %v118697_v46 = vadd.f32 %v118693_v39, %v118618_v30 (stack53)
        %v156312_v29 = vxor.u32 2147483648, %v119058_v9 (stack56)
        %v118701_v31 = vmul.f32 %v118697_v46, %v118657_v35 (stack54)
        %121451 = vrsqrt.f32 %v156312_v29 (stack67)
        %v118614_v20 = vsel /*vm=*/%vm118601_vm4, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v119466_v60 = vadd.s32 %v119463_v45, %v121574_v2 (stack40)
        %v118705_v26 = vadd.f32 %v118701_v31, %v118614_v20 (stack53)
        %v118709_v6 = vmul.f32 %v118705_v26, %v118657_v35 (stack54)
        %v118610_v44 = vsel /*vm=*/%vm118601_vm4, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v119458_v28 = vadd.s32 %v119454_v12, %v121564_v0 (stack40)
        %v119470_v16 = vadd.s32 5, %v119466_v60 (stack40)
        %v118713_v32 = vadd.f32 %v118709_v6, %v118610_v44 (stack53)
        %v119472_v48 = vxor.u32 %v119470_v16, %v119458_v28 (stack48)
        %v118717_v35 = vmul.f32 %v118713_v32, %v118657_v35 (stack54)
        %v118574_v10 = vand.u32 2147483647, %v156236_v34 (stack77)
        %v118606_v42 = vsel /*vm=*/%vm118601_vm4, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v119473_v8 = vand.u32.u8 255, %v119472_v48 (stack49)
        %v118721_v40 = vadd.f32 %v118717_v35, %v118606_v42 (stack53)
        %v119474_v37 = vand.u32 65535, %v119473_v8 (stack50)
        %v118582_v62 = vmul.f32 inf, %v156236_v34 (stack54)
        %v118725_v34 = vmul.f32 %v118721_v40, %v156236_v34 (stack54)
        %v121452_v52 = vpop.eup %121451 (stack73)
        %vm118577_vm6 = vcmp.eq.f32.partialorder %v118574_v10, 1.0 (stack68)
        %v119475_v49 = vshrl.u32 %v119474_v37, 1 (stack51)
        %v118729_v21 = vsel /*vm=*/%vm118577_vm6, /*on_true_vy=*/%v118582_v62, /*on_false_vx=*/%v118725_v34 (stack44)
        %v119106_v55 = vmul.f32 %v121452_v52, %v156312_v29 (stack74)
        %v118733_v36 = vmul.f32 1.4140625, %v118729_v21 (stack54)
        %vm119107_vm7 = vcmp.eq.f32.partialorder %v156312_v29, inf (stack70)
        %v119110_v25 = vand.u32 2147483648, %v156312_v29 (stack72)
        %v119476_v27 = vor.u32 16256, %v119475_v49 (stack47)
        %v119108_v51 = vsel /*vm=*/%vm119107_vm7, /*on_true_vy=*/%v156312_v29, /*on_false_vx=*/%v119106_v55 (stack75)
        %vm119109_vm8 = vcmp.eq.f32.partialorder %v156312_v29, 0.0 (stack71)
        %v118736_v14 = vpack.c.bf16 %v157387_v11, %v118733_v36 (stack81)
        %vm119062_vm9 = vcmp.lt.f32.partialorder %v156312_v29, 5.0 (stack68)
        %v119111_v41 = vsel /*vm=*/%vm119109_vm8, /*on_true_vy=*/%v119110_v25, /*on_false_vx=*/%v119108_v51 (stack76)
        %v119477_v50 = vand.u32.u16 65535, %v119476_v27 (stack52)
        %v119103_v58 = vadd.f32 -2.5, %v156312_v29 (stack53)
        %v119114_v13 = vadd.f32 -3.0, %v119111_v41 (stack53)
        %120379 = vst [vmem:[%s123356_s30 + $0x2fc] sm:$0xf] /*vst_source=*/%v118736_v14 (stack83)
        %v120382_v54 = vadd.low.f32.bf16 -1.0, %v119477_v50 (stack53)
        %v119099_v53 = vsel /*vm=*/%vm119062_vm9, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v119118_v56 = vsel /*vm=*/%vm119062_vm9, /*on_true_vy=*/%v119103_v58, /*on_false_vx=*/%v119114_v13 (stack44)
        %v119122_v23 = vmul.f32 %v119118_v56, %v119099_v53 (stack54)
        %v119486_v12 = vmul.f32 2.0, %v120382_v54 (stack54)
        %v119095_v43 = vsel /*vm=*/%vm119062_vm9, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v119126_v59 = vadd.f32 %v119122_v23, %v119095_v43 (stack53)
        %v119490_v22 = vadd.f32 -0.99609375, %v119486_v12 (stack53)
        %v119130_v61 = vmul.f32 %v119126_v59, %v119118_v56 (stack54)
        %v156346_v47 = vmax.f32 %v119490_v22, -0.99609375 (stack55)
        %v119091_v38 = vsel /*vm=*/%vm119062_vm9, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v119134_v17 = vadd.f32 %v119130_v61, %v119091_v38 (stack53)
        %v119506_v24 = vxor.u32 2147483648, %v156346_v47 (stack56)
        %v119138_v39 = vmul.f32 %v119134_v17, %v119118_v56 (stack54)
        %v119509_v45 = vmul.f32 %v119506_v24, %v156346_v47 (stack54)
        %v119087_v30 = vsel /*vm=*/%vm119062_vm9, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v119142_v9 = vadd.f32 %v119138_v39, %v119087_v30 (stack53)
        %v119511_v46 = vadd.f32 1.0, %v119509_v45 (stack57)
        %v119146_v31 = vmul.f32 %v119142_v9, %v119118_v56 (stack54)
        %121453 = vlog2.f32 %v119511_v46 (stack58)
        %v119083_v20 = vsel /*vm=*/%vm119062_vm9, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v119150_v60 = vadd.f32 %v119146_v31, %v119083_v20 (stack53)
        %v119154_v26 = vmul.f32 %v119150_v60, %v119118_v56 (stack54)
        %v119079_v6 = vsel /*vm=*/%vm119062_vm9, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v119158_v44 = vadd.f32 %v119154_v26, %v119079_v6 (stack53)
        %v119514_v28 = vmul.f32 -0.5, %v119509_v45 (stack59)
        %v119162_v16 = vmul.f32 %v119158_v44, %v119118_v56 (stack54)
        %v119075_v32 = vsel /*vm=*/%vm119062_vm9, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v119166_v48 = vadd.f32 %v119162_v16, %v119075_v32 (stack53)
        %v119515_v35 = vadd.f32 1.0, %v119514_v28 (stack61)
        %v119517_v10 = vand.u32 2147483647, %v119509_v45 (stack60)
        %v119170_v42 = vmul.f32 %v119166_v48, %v119118_v56 (stack54)
        %v121454_v8 = vpop.eup %121453 (stack64)
        %v119071_v40 = vsel /*vm=*/%vm119062_vm9, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v119174_v37 = vadd.f32 %v119170_v42, %v119071_v40 (stack53)
        %v119513_v62 = vmul.f32 0.6931472, %v121454_v8 (stack65)
        %v119516_v34 = vmul.f32 %v119515_v35, %v119509_v45 (stack63)
        %vm119518_vm10 = vcmp.lt.f32.partialorder %v119517_v10, 0.0004427343 (stack62)
        %v119178_v52 = vmul.f32 %v119174_v37, %v119118_v56 (stack54)
        %v119519_v49 = vsel /*vm=*/%vm119518_vm10, /*on_true_vy=*/%v119516_v34, /*on_false_vx=*/%v119513_v62 (stack66)
        %v119035_v21 = vand.u32 2147483647, %v156283_v7 (stack77)
        %v119067_v29 = vsel /*vm=*/%vm119062_vm9, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v119520_v55 = vxor.u32 2147483648, %v119519_v49 (stack56)
        %v119182_v36 = vadd.f32 %v119178_v52, %v119067_v29 (stack53)
        %121455 = vrsqrt.f32 %v119520_v55 (stack67)
        %v119043_v25 = vmul.f32 inf, %v156283_v7 (stack54)
        %v119186_v7 = vmul.f32 %v119182_v36, %v156283_v7 (stack54)
        %vm119038_vm11 = vcmp.eq.f32.partialorder %v119035_v21, 1.0 (stack68)
        %v119190_v27 = vsel /*vm=*/%vm119038_vm11, /*on_true_vy=*/%v119043_v25, /*on_false_vx=*/%v119186_v7 (stack44)
        %v119194_v51 = vmul.f32 1.4140625, %v119190_v27 (stack54)
        %v119197_v14 = vpack.c.bf16 %v157387_v11, %v119194_v51 (stack81)
        %120381 = vst [vmem:[%s123356_s30 + $0x37c] sm:$0xf] /*vst_source=*/%v119197_v14 (stack83)
        %v121456_v41 = vpop.eup %121455 (stack73)
        %v119567_v50 = vmul.f32 %v121456_v41, %v119520_v55 (stack74)
        %vm119568_vm12 = vcmp.eq.f32.partialorder %v119520_v55, inf (stack70)
        %v119571_v58 = vand.u32 2147483648, %v119520_v55 (stack72)
        %v119569_v13 = vsel /*vm=*/%vm119568_vm12, /*on_true_vy=*/%v119520_v55, /*on_false_vx=*/%v119567_v50 (stack75)
        %vm119570_vm13 = vcmp.eq.f32.partialorder %v119520_v55, 0.0 (stack71)
        %vm119523_vm14 = vcmp.lt.f32.partialorder %v119520_v55, 5.0 (stack68)
        %v119572_v54 = vsel /*vm=*/%vm119570_vm13, /*on_true_vy=*/%v119571_v58, /*on_false_vx=*/%v119569_v13 (stack76)
        %v119564_v53 = vadd.f32 -2.5, %v119520_v55 (stack53)
        %v119575_v56 = vadd.f32 -3.0, %v119572_v54 (stack53)
        %v119560_v15 = vsel /*vm=*/%vm119523_vm14, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v157054_v15 (stack44)
        %v119579_v23 = vsel /*vm=*/%vm119523_vm14, /*on_true_vy=*/%v119564_v53, /*on_false_vx=*/%v119575_v56 (stack44)
        %v119583_v12 = vmul.f32 %v119579_v23, %v119560_v15 (stack54)
        %v119556_v5 = vsel /*vm=*/%vm119523_vm14, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v157053_v5 (stack44)
        %v119587_v43 = vadd.f32 %v119583_v12, %v119556_v5 (stack53)
        %v119591_v59 = vmul.f32 %v119587_v43, %v119579_v23 (stack54)
        %v119552_v19 = vsel /*vm=*/%vm119523_vm14, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v157048_v19 (stack44)
        %v119595_v22 = vadd.f32 %v119591_v59, %v119552_v19 (stack53)
        %v119599_v61 = vmul.f32 %v119595_v22, %v119579_v23 (stack54)
        %v119548_v63 = vsel /*vm=*/%vm119523_vm14, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v157047_v63 (stack44)
        %v119603_v38 = vadd.f32 %v119599_v61, %v119548_v63 (stack53)
        %v119607_v17 = vmul.f32 %v119603_v38, %v119579_v23 (stack54)
        %v119544_v4 = vsel /*vm=*/%vm119523_vm14, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v157046_v4 (stack44)
        %v119611_v24 = vadd.f32 %v119607_v17, %v119544_v4 (stack53)
        %s157858_s12 = sld [smem:[#allocation4_spill]] (stack21)
        %v119615_v39 = vmul.f32 %v119611_v24, %v119579_v23 (stack54)
        %v119540_v3 = vsel /*vm=*/%vm119523_vm14, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v157052_v3 (stack44)
        %v119619_v45 = vadd.f32 %v119615_v39, %v119540_v3 (stack53)
        %v119623_v30 = vmul.f32 %v119619_v45, %v119579_v23 (stack54)
        %v119536_v18 = vsel /*vm=*/%vm119523_vm14, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v157051_v18 (stack44)
        %v119627_v9 = vadd.f32 %v119623_v30, %v119536_v18 (stack53)
        %v119631_v46 = vmul.f32 %v119627_v9, %v119579_v23 (stack54)
        %v119532_v33 = vsel /*vm=*/%vm119523_vm14, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v157050_v33 (stack44)
        %v119635_v31 = vadd.f32 %v119631_v46, %v119532_v33 (stack53)
        %v119639_v20 = vmul.f32 %v119635_v31, %v119579_v23 (stack54)
        %v119496_v60 = vand.u32 2147483647, %v156346_v47 (stack77)
        %v119528_v57 = vsel /*vm=*/%vm119523_vm14, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v157071_v57 (stack44)
        %v119643_v26 = vadd.f32 %v119639_v20, %v119528_v57 (stack53)
        %v119504_v6 = vmul.f32 inf, %v156346_v47 (stack54)
        %v119647_v47 = vmul.f32 %v119643_v26, %v156346_v47 (stack54)
        %s120392_s21 = sshll.u32 %s157858_s12, 11 (stack85)
        %vm119499_vm15 = vcmp.eq.f32.partialorder %v119496_v60, 1.0 (stack68)
        %s119675_s18 = sshll.u32 %s123356_s30, 4 (stack86)
        %v119651_v44 = vsel /*vm=*/%vm119499_vm15, /*on_true_vy=*/%v119504_v6, /*on_false_vx=*/%v119647_v47 (stack44)
        %v119655_v28 = vmul.f32 1.4140625, %v119651_v44 (stack54)
        %s157859_s13 = sld [smem:[#allocation156_spill]] (stack21)
        %s156403_s17 = scalar_lea.hbm %s157859_s13, %s120392_s21 (stack87)
        %s156405_s18 = int_to_ptr.vmem [resolvable:$true] %s119675_s18 (stack88)
        %v119658_v11 = vpack.c.bf16 %v157387_v11, %v119655_v28 (stack81)
        %120383 = vst [vmem:[%s123356_s30 + $0x3fc] sm:$0xf] /*vst_source=*/%v119658_v11 (stack83)
        %s119661_s9 = scalar_lea.sflag [#allocation2], %s123318_s25 (stack89)
        %s121457_s26 = scalar_lea.vmem %s156405_s18, 16384 (stack90)
        %p121458_p8 = scmp.ne.s32.totalorder %s156405_s18, %s121457_s26 (stack91)
        %s121517_s14 = smov [#allocation0] /* materialized constant */ (stack92)
        %s121459_s19 = sshll.u32 %s121517_s14, 4 (stack93)
        %s121460_s19 = int_to_ptr.vmem [resolvable:$false] %s121459_s19 (stack94)
        %s121461_s20 = scalar_lea.vmem %s121460_s19, 32768 (stack95)
        %p121462_p9 = scmp.lt.s32.totalorder %s156405_s18, %s121460_s19 (stack96)
        %p121463_p10 = scmp.lt.s32.totalorder %s121461_s20, %s121457_s26 (stack97)
        %p121464_p11 = por %p121463_p10, %p121462_p9 (stack98)
        %p121465_p12 = pnand %p121464_p11, %p121458_p8 (stack99)
        %121468 = shalt.err (!%p121465_p12) /* BoundsCheck 322 [deref of %s119676] for %119681 = dma.vmem_to_hbm [thread:$0]  /*vmem=*/%s119676, /*size_in_granules=*/16384, /*hbm=*/%s119674, /*dst_syncflagno=*/%s119661, /*src_stride=*/2048, /*dst_stride=*/16384, /*steps_per_stride=*/128 /* 
base_bounds: (8, 256, 1)
dynamic_base_bounds: (8, 256, 1)
window_bounds: (8, 32, 1)
iteration_bounds: (1, 8, 1)
strides: (8, 32, 1)
pad_low: (0, 0, 0)
pad_high: (0, 0, 0)
element_size_in_bytes: 2048 */
hlo: fusion.21
 */ (stack100)
        %s121469_s22 = scalar_lea.hbm %s156403_s17, 16384 (stack90)
        %p121470_p13 = scmp.ne.s32.totalorder %s156403_s17, %s121469_s22 (stack91)
        %s121471_s1 = scalar_lea.hbm %s157859_s13, 131072 (stack95)
        %p121472_p0 = scmp.lt.s32.totalorder %s156403_s17, %s157859_s13 (stack96)
        %p121473_p1 = scmp.lt.s32.totalorder %s121471_s1, %s121469_s22 (stack97)
        %p121474_p2 = por %p121473_p1, %p121472_p0 (stack98)
        %p121475_p3 = pnand %p121474_p2, %p121470_p13 (stack99)
        %121478 = shalt.err (!%p121475_p3) /* BoundsCheck 322 [deref of %s119674] for %119681 = dma.vmem_to_hbm [thread:$0]  /*vmem=*/%s119676, /*size_in_granules=*/16384, /*hbm=*/%s119674, /*dst_syncflagno=*/%s119661, /*src_stride=*/2048, /*dst_stride=*/16384, /*steps_per_stride=*/128 /* 
base_bounds: (8, 256, 1)
dynamic_base_bounds: (8, 256, 1)
window_bounds: (8, 32, 1)
iteration_bounds: (1, 8, 1)
strides: (8, 32, 1)
pad_low: (0, 0, 0)
pad_high: (0, 0, 0)
element_size_in_bytes: 2048 */
hlo: fusion.21
 */ (stack100)
        %s121518_s10 = smov 2048 /* materialized constant */ (stack92)
        %s121519_s0 = smov 16384 /* materialized constant */ (stack92)
        %s121520_s24 = smov 128 /* materialized constant */ (stack92)
        %119681 = dma.vmem_to_hbm [thread:$0]  /*vmem=*/%s156405_s18, /*size_in_granules=*/16384, /*hbm=*/%s156403_s17, /*dst_syncflagno=*/%s119661_s9, /*src_stride=*/%s121518_s10, /*dst_stride=*/%s121519_s0, /*steps_per_stride=*/%s121520_s24 /* 
base_bounds: (8, 256, 1)
dynamic_base_bounds: (8, 256, 1)
window_bounds: (8, 32, 1)
iteration_bounds: (1, 8, 1)
strides: (8, 32, 1)
pad_low: (0, 0, 0)
pad_high: (0, 0, 0)
element_size_in_bytes: 2048 */ (stack101)
      $region36: #{fusion.21} parent=50 // pred_fallthru
        // region range: [12590, 12590)
      %s157860_s4 = sld [smem:[#allocation6_spill]] (stack21)
      %p120395_p4 = scmp.ge.s32.totalorder %s157860_s4, 2 (stack102)
      %s120389_s16 = sadd.s32 4294967294, %s157860_s4 (stack103)
      %s119687_s28 = sand.u32 1, %s120389_s16 /* smod.u32 w/div 2 */ (stack104)
      %s119688_s27 = scalar_lea.sflag [#allocation2], %s119687_s28 (stack105)
      %121492 = dma.done.wait (%p120395_p4), %s119688_s27, 16384 /* pipeline-emitter-dma-wait */ (stack106)
      %121494 = vsyncadd (%p120395_p4), %s119688_s27, 4294950912 (stack106)
    $region6: #{fusion.21} parent=1 // loop_footer
      // region range: [12600, 12601)
      %s19_s29 = sadd.s32 1, %s157860_s4 /* copy for cssa */ (stack107)
    $region7: #{fusion.21} parent=1 // loop_footer_branch
      // region range: [12600, 12601)
    $region3: #{fusion.21} parent=1 // loop_header
      // region range: [12600, 12602)
      %p16_p5 = scmp.ge.s32.totalorder %s19_s29, 10 /* loop exit test */ (stack108)
      %s157861_s2 = sld [smem:[#allocation5_spill]] (stack21)
      %s157862_s28 = sld [smem:[#allocation7_spill]] (stack21)
    $region4: #{fusion.21} parent=1 // loop_header_branch
      // region range: [12600, 12608)
      %18 = sbr.rel (!%p16_p5) target bundleno = 7 (0x7), region = 50 (stack109)
    $region49: #{fusion.21} parent=1 // loop_exit
      // region range: [12600, 12608)
    %119693 = vsyncpa [#allocation2], 1 (stack110)
    %119695 = vsyncpa [#allocation2 + $0x1], 1 (stack110)

stack0
    @     0x787f0f52271e  (unknown)
    @     0x787f0f5226ce  (unknown)
    @     0x787f0f526cec  (unknown)
    @     0x787f0f526fe5  (unknown)
    @     0x787f0b748189  (unknown)
    @     0x787f0b74581b  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack1
    @     0x787f0f52271e  (unknown)
    @     0x787f0a72e587  (unknown)
    @     0x787f0a722fe5  (unknown)
    @     0x787f0a71d983  (unknown)
    @     0x787f0a7088cf  (unknown)
    @     0x787f0a7085c4  (unknown)
    @     0x787f0998a114  (unknown)
    @     0x787f099970b3  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack2
    @     0x787f0f4f5115  (unknown)
    @     0x787f0f557ab8  (unknown)
    @     0x787f09c9a1eb  (unknown)
    @     0x787f09c972c3  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack3
    @     0x787f0f4f5115  (unknown)
    @     0x787f0f557ab8  (unknown)
    @     0x787f09c9a1eb  (unknown)
    @     0x787f09c9733c  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack4
    @     0x787f0f4ee8c2  (unknown)
    @     0x787f0f555836  (unknown)
    @     0x787f0a732072  (unknown)
    @     0x787f0a730098  (unknown)
    @     0x787f0a723dc4  (unknown)
    @     0x787f0a71d9f5  (unknown)
    @     0x787f0a7088cf  (unknown)
    @     0x787f0a7085c4  (unknown)
    @     0x787f0998a114  (unknown)
    @     0x787f099970b3  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack5
    @     0x787f0f4df370  (unknown)
    @     0x787f0f52b3aa  (unknown)
    @     0x787f0f315bce  (unknown)
    @     0x787f0b72ea4a  (unknown)
    @     0x787f0b74d53c  (unknown)
    @     0x787f0b74b642  (unknown)
    @     0x787f0b75005f  (unknown)
    @     0x787f0b74af97  (unknown)
    @     0x787f0b74e1fb  (unknown)
    @     0x787f0b74d898  (unknown)
    @     0x787f0b74511f  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack6
    @     0x787f0f52271e  (unknown)
    @     0x787f0f5226ce  (unknown)
    @     0x787f0f526cec  (unknown)
    @     0x787f0f32b5e0  (unknown)
    @     0x787f0f32485a  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack7
    @     0x787f0f52271e  (unknown)
    @     0x787f0f5226ce  (unknown)
    @     0x787f0f526cec  (unknown)
    @     0x787f0f527060  (unknown)
    @     0x787f0f32edb3  (unknown)
    @     0x787f0f32b263  (unknown)
    @     0x787f0f32485a  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack8
    @     0x787f0f52271e  (unknown)
    @     0x787f0f5226ce  (unknown)
    @     0x787f0f526cec  (unknown)
    @     0x787f0f527060  (unknown)
    @     0x787f0f32edef  (unknown)
    @     0x787f0f32b263  (unknown)
    @     0x787f0f32485a  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack9
    @     0x787f0f52271e  (unknown)
    @     0x787f0a72e587  (unknown)
    @     0x787f0a722be2  (unknown)
    @     0x787f0a71d983  (unknown)
    @     0x787f0a7088cf  (unknown)
    @     0x787f0a7085c4  (unknown)
    @     0x787f0998a114  (unknown)
    @     0x787f099970b3  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack10
    @     0x787f0f4ea266  (unknown)
    @     0x787f0f55872d  (unknown)
    @     0x787f0f324e23  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack11
    @     0x787f0f4debc1  (unknown)
    @     0x787f0f565854  (unknown)
    @     0x787f09bf1d10  (unknown)
    @     0x787f09bf18b2  (unknown)
    @     0x787f09bf20ad  (unknown)
    @     0x787f099d2df5  (unknown)
    @     0x787f09998ad5  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack12
    @     0x787f09bf18fe  (unknown)
    @     0x787f09bf20ad  (unknown)
    @     0x787f099d2df5  (unknown)
    @     0x787f09998ad5  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack13
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53d2ca  (unknown)
    @     0x787f0f529008  (unknown)
    @     0x787f0f4828c4  (unknown)
    @     0x787f0f3229bc  (unknown)
    @     0x787f0f327519  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack14
    @     0x787f0f4e363c  (unknown)
    @     0x787f0f565a16  (unknown)
    @     0x787f0f565cf9  (unknown)
    @     0x787f0f32e779  (unknown)
    @     0x787f0f327af8  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack15
    @     0x787f0f4e363c  (unknown)
    @     0x787f0f565a16  (unknown)
    @     0x787f0f52a459  (unknown)
    @     0x787f0f4828ec  (unknown)
    @     0x787f0f3229bc  (unknown)
    @     0x787f0f327519  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack16
    @     0x787f0f4e363c  (unknown)
    @     0x787f0f565a16  (unknown)
    @     0x787f0f52f4f9  (unknown)
    @     0x787f0f32e7f7  (unknown)
    @     0x787f0f327af8  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack17
    @     0x787f0f4debc1  (unknown)
    @     0x787f0a75479d  (unknown)
    @     0x787f0a708932  (unknown)
    @     0x787f0a7085c4  (unknown)
    @     0x787f0998a114  (unknown)
    @     0x787f099970b3  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack18
    @     0x787f0f4de766  (unknown)
    @     0x787f0f52eb6d  (unknown)
    @     0x787f0f32e80b  (unknown)
    @     0x787f0f327af8  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack19
    @     0x787f0f4f426f  (unknown)
    @     0x787f0f57a997  (unknown)
    @     0x787f0f519b3c  (unknown)
    @     0x787f0f555576  (unknown)
    @     0x787f0f32e79f  (unknown)
    @     0x787f0f327af8  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack20
    @     0x787f0f52271e  (unknown)
    @     0x787f0a72e551  (unknown)
    @     0x787f0a722be2  (unknown)
    @     0x787f0a71d983  (unknown)
    @     0x787f0a7088cf  (unknown)
    @     0x787f0a7085c4  (unknown)
    @     0x787f0998a114  (unknown)
    @     0x787f099970b3  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack21
    @     0x787f0f4ed993  (unknown)
    @     0x787f0a731aac  (unknown)
    @     0x787f0a73025a  (unknown)
    @     0x787f0a723dc4  (unknown)
    @     0x787f0a71d9f5  (unknown)
    @     0x787f0a7088cf  (unknown)
    @     0x787f0a7085c4  (unknown)
    @     0x787f0998a114  (unknown)
    @     0x787f099970b3  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack22
    @     0x787f0f4ebbdf  (unknown)
    @     0x787f0f549909  (unknown)
    @     0x787f0b77d205  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack23
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53dd92  (unknown)
    @     0x787f0b77da82  (unknown)
    @     0x787f0b757234  (unknown)
    @     0x787f0b76e38a  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack24
    @     0x787f0f4e307c  (unknown)
    @     0x787f0f53a85f  (unknown)
    @     0x787f0f312f7f  (unknown)
    @     0x787f0b77d284  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack25
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f56964f  (unknown)
    @     0x787f0b77cd4f  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack26
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f530505  (unknown)
    @     0x787f0b77cf49  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack27
    @     0x787f0f4e363c  (unknown)
    @     0x787f0f565a16  (unknown)
    @     0x787f0f567291  (unknown)
    @     0x787f0b77cf32  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack28
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f56964f  (unknown)
    @     0x787f0f527cd6  (unknown)
    @     0x787f0b77d02b  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack29
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f530505  (unknown)
    @     0x787f0f527ce7  (unknown)
    @     0x787f0b77d02b  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack30
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53d2ca  (unknown)
    @     0x787f0f529008  (unknown)
    @     0x787f0b77cd3d  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack31
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53a225  (unknown)
    @     0x787f0f53a847  (unknown)
    @     0x787f0c4bf709  (unknown)
    @     0x787f0b77d329  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack32
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53dd92  (unknown)
    @     0x787f0f545f5c  (unknown)
    @     0x787f0b77d0d6  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack33
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53a2f1  (unknown)
    @     0x787f0f53a847  (unknown)
    @     0x787f0c4bf709  (unknown)
    @     0x787f0b77d329  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack34
    @     0x787f0f4df5ff  (unknown)
    @     0x787f0f545c3a  (unknown)
    @     0x787f0b77d0d6  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack35
    @     0x787f0f4df5ff  (unknown)
    @     0x787f0f545c3a  (unknown)
    @     0x787f0b77d1f8  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack36
    @     0x787f0f4e307c  (unknown)
    @     0x787f0f53a85f  (unknown)
    @     0x787f0c4bf709  (unknown)
    @     0x787f0b77d329  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack37
    @     0x787f0f4e2e33  (unknown)
    @     0x787f0f539d88  (unknown)
    @     0x787f0f312f8c  (unknown)
    @     0x787f0b77d284  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack38
    @     0x787f0f4edfa8  (unknown)
    @     0x787f0f4edc1b  (unknown)
    @     0x787f0f55a4f6  (unknown)
    @     0x787f0a732133  (unknown)
    @     0x787f0a730098  (unknown)
    @     0x787f0a723dc4  (unknown)
    @     0x787f0a71d9f5  (unknown)
    @     0x787f0a7088cf  (unknown)
    @     0x787f0a7085c4  (unknown)
    @     0x787f0998a114  (unknown)
    @     0x787f099970b3  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack39
    @     0x787f0f4e2e33  (unknown)
    @     0x787f0f539d88  (unknown)
    @     0x787f0c4bf716  (unknown)
    @     0x787f0b77d329  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack40
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f5691eb  (unknown)
    @     0x787f0c15ce44  (unknown)
    @     0x787f0f557bb7  (unknown)
    @     0x787f0c158ac3  (unknown)
    @     0x787f1136d73e  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack41
    @     0x787f0f4de147  (unknown)
    @     0x787f0f52b798  (unknown)
    @     0x787f0f30a807  (unknown)
    @     0x787f0b7637de  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack42
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f52b807  (unknown)
    @     0x787f0f30a807  (unknown)
    @     0x787f0b7637de  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack43
    @     0x787f0f4e8df6  (unknown)
    @     0x787f0f568b6e  (unknown)
    @     0x787f0f56827a  (unknown)
    @     0x787f0c15bf00  (unknown)
    @     0x787f0f557bb7  (unknown)
    @     0x787f0c158ac3  (unknown)
    @     0x787f1136d73e  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack44
    @     0x787f0f4e7674  (unknown)
    @     0x787f0f52e22d  (unknown)
    @     0x787f0c15bb18  (unknown)
    @     0x787f0f557bb7  (unknown)
    @     0x787f0c158ac3  (unknown)
    @     0x787f1136d73e  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack45
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f52cb80  (unknown)
    @     0x787f0c157250  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack46
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f52c03e  (unknown)
    @     0x787f0c15759b  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack47
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f52d8e9  (unknown)
    @     0x787f0c156f76  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack48
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f565769  (unknown)
    @     0x787f0c157036  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack49
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f52b94b  (unknown)
    @     0x787f0c158583  (unknown)
    @     0x787f0c155364  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack50
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f52b94b  (unknown)
    @     0x787f0c157622  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack51
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f52c03e  (unknown)
    @     0x787f0c157640  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack52
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f52b94b  (unknown)
    @     0x787f0c158583  (unknown)
    @     0x787f0c155a1d  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack53
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f564248  (unknown)
    @     0x787f0c15cdb6  (unknown)
    @     0x787f0f557bb7  (unknown)
    @     0x787f0c158ac3  (unknown)
    @     0x787f1136d73e  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack54
    @     0x787f0f4eb946  (unknown)
    @     0x787f0f534643  (unknown)
    @     0x787f0c15caf7  (unknown)
    @     0x787f0f557bb7  (unknown)
    @     0x787f0c158ac3  (unknown)
    @     0x787f1136d73e  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack55
    @     0x787f0f4e7a26  (unknown)
    @     0x787f0f565643  (unknown)
    @     0x787f0c15c675  (unknown)
    @     0x787f0f557bb7  (unknown)
    @     0x787f0c158ac3  (unknown)
    @     0x787f1136d73e  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack56
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f534cdd  (unknown)
    @     0x787f0c1523d0  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack57
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f563f30  (unknown)
    @     0x787f0f541ddc  (unknown)
    @     0x787f0c153eb3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack58
    @     0x787f0f4e4951  (unknown)
    @     0x787f0f5634c6  (unknown)
    @     0x787f0a65d745  (unknown)
    @     0x787f0a65a379  (unknown)
    @     0x787f0a65392f  (unknown)
    @     0x787f0a657c07  (unknown)
    @     0x787f0f58b5fa  (unknown)
    @     0x787f0f58aee9  (unknown)
    @     0x787f0a652165  (unknown)
    @     0x787f099997cf  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack59
    @     0x787f0f4eb946  (unknown)
    @     0x787f0f563fcd  (unknown)
    @     0x787f0f541ddc  (unknown)
    @     0x787f0c153eb3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack60
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f56409b  (unknown)
    @     0x787f0f541ddc  (unknown)
    @     0x787f0c153eb3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack61
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f56400b  (unknown)
    @     0x787f0f541ddc  (unknown)
    @     0x787f0c153eb3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack62
    @     0x787f0f4e8df6  (unknown)
    @     0x787f0f568b6e  (unknown)
    @     0x787f0f5640df  (unknown)
    @     0x787f0f541ddc  (unknown)
    @     0x787f0c153eb3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack63
    @     0x787f0f4eb946  (unknown)
    @     0x787f0f564044  (unknown)
    @     0x787f0f541ddc  (unknown)
    @     0x787f0c153eb3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack64
    @     0x787f0f4e71c8  (unknown)
    @     0x787f0f5634e1  (unknown)
    @     0x787f0a65d745  (unknown)
    @     0x787f0a65a379  (unknown)
    @     0x787f0a65392f  (unknown)
    @     0x787f0a657c07  (unknown)
    @     0x787f0f58b5fa  (unknown)
    @     0x787f0f58aee9  (unknown)
    @     0x787f0a652165  (unknown)
    @     0x787f099997cf  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack65
    @     0x787f0f4eb946  (unknown)
    @     0x787f0f564143  (unknown)
    @     0x787f0f541ddc  (unknown)
    @     0x787f0c153eb3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack66
    @     0x787f0f4e7674  (unknown)
    @     0x787f0f564112  (unknown)
    @     0x787f0f541ddc  (unknown)
    @     0x787f0c153eb3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack67
    @     0x787f0f4e4951  (unknown)
    @     0x787f0f5646a8  (unknown)
    @     0x787f0a65d63c  (unknown)
    @     0x787f0a65a379  (unknown)
    @     0x787f0a65392f  (unknown)
    @     0x787f0a657c07  (unknown)
    @     0x787f0f58b5fa  (unknown)
    @     0x787f0f58aee9  (unknown)
    @     0x787f0a652165  (unknown)
    @     0x787f099997cf  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack68
    @     0x787f0f4e8df6  (unknown)
    @     0x787f0f568b6e  (unknown)
    @     0x787f0f56825c  (unknown)
    @     0x787f0c15bf00  (unknown)
    @     0x787f0f557bb7  (unknown)
    @     0x787f0c158ac3  (unknown)
    @     0x787f1136d73e  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack69
    @     0x787f0f4ded9e  (unknown)
    @     0x787f0f565854  (unknown)
    @     0x787f09bebd7a  (unknown)
    @     0x787f09beaf9f  (unknown)
    @     0x787f09998b6e  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack70
    @     0x787f0f4e8df6  (unknown)
    @     0x787f0f568b6e  (unknown)
    @     0x787f0f5433ac  (unknown)
    @     0x787f0c1565f3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack71
    @     0x787f0f4e8df6  (unknown)
    @     0x787f0f568b6e  (unknown)
    @     0x787f0f54341b  (unknown)
    @     0x787f0c1565f3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack72
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f531bf5  (unknown)
    @     0x787f0f54343d  (unknown)
    @     0x787f0c1565f3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack73
    @     0x787f0f4e71c8  (unknown)
    @     0x787f0f5646c3  (unknown)
    @     0x787f0a65d63c  (unknown)
    @     0x787f0a65a379  (unknown)
    @     0x787f0a65392f  (unknown)
    @     0x787f0a657c07  (unknown)
    @     0x787f0f58b5fa  (unknown)
    @     0x787f0f58aee9  (unknown)
    @     0x787f0a652165  (unknown)
    @     0x787f099997cf  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack74
    @     0x787f0f4eb946  (unknown)
    @     0x787f0f54336b  (unknown)
    @     0x787f0c1565f3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack75
    @     0x787f0f4e7674  (unknown)
    @     0x787f0f5433de  (unknown)
    @     0x787f0c1565f3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack76
    @     0x787f0f4e7674  (unknown)
    @     0x787f0f54346c  (unknown)
    @     0x787f0c1565f3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack77
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f531cdf  (unknown)
    @     0x787f0c152d8e  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack78
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53da6a  (unknown)
    @     0x787f0f5266c8  (unknown)
    @     0x787f0f327b27  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack79
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f530505  (unknown)
    @     0x787f0f32f97e  (unknown)
    @     0x787f0f32cdf1  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack80
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53dd92  (unknown)
    @     0x787f0f545f5c  (unknown)
    @     0x787f0f32fce7  (unknown)
    @     0x787f0f32cdf1  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack81
    @     0x787f0f4e0a1d  (unknown)
    @     0x787f0f570e15  (unknown)
    @     0x787f0f57137e  (unknown)
    @     0x787f0b785933  (unknown)
    @     0x787f0b784874  (unknown)
    @     0x787f0b784256  (unknown)
    @     0x787f0b754fe2  (unknown)
    @     0x787f0b76ea43  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack82
    @     0x787f0f4df5ff  (unknown)
    @     0x787f0f545c3a  (unknown)
    @     0x787f0f32fce7  (unknown)
    @     0x787f0f32cdf1  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack83
    @     0x787f0f4edfa8  (unknown)
    @     0x787f0f4edc1b  (unknown)
    @     0x787f0f577bfc  (unknown)
    @     0x787f0b783feb  (unknown)
    @     0x787f0b78594f  (unknown)
    @     0x787f0b784874  (unknown)
    @     0x787f0b784256  (unknown)
    @     0x787f0b754fe2  (unknown)
    @     0x787f0b76ea43  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack84
    @     0x787f0f4ebbdf  (unknown)
    @     0x787f0a731b92  (unknown)
    @     0x787f0a73025a  (unknown)
    @     0x787f0a723dc4  (unknown)
    @     0x787f0a71d9f5  (unknown)
    @     0x787f0a7088cf  (unknown)
    @     0x787f0a7085c4  (unknown)
    @     0x787f0998a114  (unknown)
    @     0x787f099970b3  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack85
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53dd92  (unknown)
    @     0x787f0f545f5c  (unknown)
    @     0x787f0f4725c5  (unknown)
    @     0x787f0f472c0b  (unknown)
    @     0x787f0f473b7f  (unknown)
    @     0x787f0f334dc9  (unknown)
    @     0x787f0f32e178  (unknown)
    @     0x787f0f32810b  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack86
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f555df0  (unknown)
    @     0x787f0f54cbc7  (unknown)
    @     0x787f0f54f8ab  (unknown)
    @     0x787f0f479fa4  (unknown)
    @     0x787f0f47b136  (unknown)
    @     0x787f0f4737ce  (unknown)
    @     0x787f0f473b7f  (unknown)
    @     0x787f0f334dc9  (unknown)
    @     0x787f0f32e178  (unknown)
    @     0x787f0f32810b  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack87
    @     0x787f0f4df5ff  (unknown)
    @     0x787f0f545c3a  (unknown)
    @     0x787f0f4725c5  (unknown)
    @     0x787f0f472c0b  (unknown)
    @     0x787f0f473b7f  (unknown)
    @     0x787f0f334dc9  (unknown)
    @     0x787f0f32e178  (unknown)
    @     0x787f0f32810b  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack88
    @     0x787f0f4df9d1  (unknown)
    @     0x787f0f52763d  (unknown)
    @     0x787f0f54cbd7  (unknown)
    @     0x787f0f54f8ab  (unknown)
    @     0x787f0f479fa4  (unknown)
    @     0x787f0f47b136  (unknown)
    @     0x787f0f4737ce  (unknown)
    @     0x787f0f473b7f  (unknown)
    @     0x787f0f334dc9  (unknown)
    @     0x787f0f32e178  (unknown)
    @     0x787f0f32810b  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack89
    @     0x787f0f4df5ff  (unknown)
    @     0x787f0f545c3a  (unknown)
    @     0x787f0f32f95e  (unknown)
    @     0x787f0f32db2b  (unknown)
    @     0x787f0f32810b  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack90
    @     0x787f0f4df5ff  (unknown)
    @     0x787f0f545c3a  (unknown)
    @     0x787f0f075fbd  (unknown)
    @     0x787f0f076ce7  (unknown)
    @     0x787f0f0689fa  (unknown)
    @     0x787f0f065ef4  (unknown)
    @     0x787f0f06541c  (unknown)
    @     0x787f0f06ae8a  (unknown)
    @     0x787f099d2c8f  (unknown)
    @     0x787f09998653  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack91
    @     0x787f0f4e363c  (unknown)
    @     0x787f0f565a16  (unknown)
    @     0x787f0f52f479  (unknown)
    @     0x787f0f065fe1  (unknown)
    @     0x787f0f06541c  (unknown)
    @     0x787f0f06ae8a  (unknown)
    @     0x787f099d2c8f  (unknown)
    @     0x787f09998653  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack92
    @     0x787f0f4debc1  (unknown)
    @     0x787f0f565854  (unknown)
    @     0x787f09bebd7a  (unknown)
    @     0x787f09beaf9f  (unknown)
    @     0x787f09998b6e  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack93
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f555df0  (unknown)
    @     0x787f0f0697cb  (unknown)
    @     0x787f0f06688b  (unknown)
    @     0x787f0f06541c  (unknown)
    @     0x787f0f06ae8a  (unknown)
    @     0x787f099d2c8f  (unknown)
    @     0x787f09998653  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack94
    @     0x787f0f4df9d1  (unknown)
    @     0x787f0f52763d  (unknown)
    @     0x787f0f069844  (unknown)
    @     0x787f0f06688b  (unknown)
    @     0x787f0f06541c  (unknown)
    @     0x787f0f06ae8a  (unknown)
    @     0x787f099d2c8f  (unknown)
    @     0x787f09998653  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack95
    @     0x787f0f4df5ff  (unknown)
    @     0x787f0f545c3a  (unknown)
    @     0x787f0f066f66  (unknown)
    @     0x787f0f06541c  (unknown)
    @     0x787f0f06ae8a  (unknown)
    @     0x787f099d2c8f  (unknown)
    @     0x787f09998653  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack96
    @     0x787f0f4e363c  (unknown)
    @     0x787f0f565a16  (unknown)
    @     0x787f0f52f4f9  (unknown)
    @     0x787f0f064a65  (unknown)
    @     0x787f0f066fbe  (unknown)
    @     0x787f0f06541c  (unknown)
    @     0x787f0f06ae8a  (unknown)
    @     0x787f099d2c8f  (unknown)
    @     0x787f09998653  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack97
    @     0x787f0f4e363c  (unknown)
    @     0x787f0f565a16  (unknown)
    @     0x787f0f52f4f9  (unknown)
    @     0x787f0f064a65  (unknown)
    @     0x787f0f066ff0  (unknown)
    @     0x787f0f06541c  (unknown)
    @     0x787f0f06ae8a  (unknown)
    @     0x787f099d2c8f  (unknown)
    @     0x787f09998653  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack98
    @     0x787f0f4de266  (unknown)
    @     0x787f0f52eb04  (unknown)
    @     0x787f0f067002  (unknown)
    @     0x787f0f06541c  (unknown)
    @     0x787f0f06ae8a  (unknown)
    @     0x787f099d2c8f  (unknown)
    @     0x787f09998653  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack99
    @     0x787f0f4de766  (unknown)
    @     0x787f0f52eb6d  (unknown)
    @     0x787f0f06711e  (unknown)
    @     0x787f0f06541c  (unknown)
    @     0x787f0f06ae8a  (unknown)
    @     0x787f099d2c8f  (unknown)
    @     0x787f09998653  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack100
    @     0x787f0f4df0c3  (unknown)
    @     0x787f0f52ee54  (unknown)
    @     0x787f0f0665b9  (unknown)
    @     0x787f0f06541c  (unknown)
    @     0x787f0f06ae8a  (unknown)
    @     0x787f099d2c8f  (unknown)
    @     0x787f09998653  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack101
    @     0x787f0f4f13ba  (unknown)
    @     0x787f0f54fbb4  (unknown)
    @     0x787f0f479fa4  (unknown)
    @     0x787f0f47b136  (unknown)
    @     0x787f0f4737ce  (unknown)
    @     0x787f0f473b7f  (unknown)
    @     0x787f0f334dc9  (unknown)
    @     0x787f0f32e178  (unknown)
    @     0x787f0f32810b  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack102
    @     0x787f0f4de55e  (unknown)
    @     0x787f0f52ebf2  (unknown)
    @     0x787f09b683e5  (unknown)
    @     0x787f099992fd  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack103
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53da6a  (unknown)
    @     0x787f0f5266c8  (unknown)
    @     0x787f0f328406  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack104
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f530505  (unknown)
    @     0x787f0f32f91c  (unknown)
    @     0x787f0f32e659  (unknown)
    @     0x787f0f3285d0  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack105
    @     0x787f0f4df5ff  (unknown)
    @     0x787f0f545c3a  (unknown)
    @     0x787f0f32f95e  (unknown)
    @     0x787f0f32e659  (unknown)
    @     0x787f0f3285d0  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack106
    @     0x787f0f4f31b6  (unknown)
    @     0x787f0f556c30  (unknown)
    @     0x787f0f3351d6  (unknown)
    @     0x787f0f32e66a  (unknown)
    @     0x787f0f3285d0  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack107
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53d2ca  (unknown)
    @     0x787f0f529008  (unknown)
    @     0x787f0f506741  (unknown)
    @     0x787f0f529dfb  (unknown)
    @     0x787f0f3274d3  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack108
    @     0x787f0f4e363c  (unknown)
    @     0x787f0f565a16  (unknown)
    @     0x787f0f52a459  (unknown)
    @     0x787f0f5066e6  (unknown)
    @     0x787f0f529dfb  (unknown)
    @     0x787f0f3274d3  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack109
    @     0x787f0f4f426f  (unknown)
    @     0x787f0f57a997  (unknown)
    @     0x787f0f506719  (unknown)
    @     0x787f0f529dfb  (unknown)
    @     0x787f0f3274d3  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack110
    @     0x787f0f4ea266  (unknown)
    @     0x787f0f55872d  (unknown)
    @     0x787f0f328938  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

