// Slow dumping with stack traces? Try building with --dynamic_mode=fully
$region0: #{fusion.21}
  #allocation3 [shape = 's32[1]{0}', space=sflag, size = 0x4, tag = 'scoped memory for fusion.21'] (stack0)
  %s0 = inlined_call_operand.<no memory space> [shape: u32[], index: 0, kind: input, shape index: {}] /* operand 0 */ (stack1)
  %s1 = inlined_call_operand.<no memory space> [shape: u32[], index: 1, kind: input, shape index: {}] /* operand 1 */ (stack1)
  %s2 = inlined_call_operand.<no memory space> [shape: u32[], index: 2, kind: input, shape index: {}] /* operand 2 */ (stack1)
  %s3 = inlined_call_operand.vmem [shape: u32[2048], index: 3, kind: input, shape index: {}] /* operand 3 */ (stack1)
  %s4 = inlined_call_operand.vmem [shape: u32[8], index: 4, kind: input, shape index: {}] (stack1)
  %s5 = inlined_call_operand.vmem [shape: u32[2048], index: 5, kind: input, shape index: {}] /* operand 5 */ (stack1)
  %s6 = inlined_call_operand.vmem [shape: u32[8], index: 6, kind: input, shape index: {}] (stack1)
  %s7 = inlined_call_operand.hbm [shape: bf16[8,2048,128], index: 7, kind: output, shape index: {}] /* operand 7 */ (stack2)
  %v8 = vstv %s0 (stack3)
  %v9 = vstv %s1 (stack3)
  %v10 = vstv %s2 (stack3)
  $region1: #{fusion.21} parent=0
    #allocation0 [shape = 'u8[1048576]{0}', space=vmem, size = 0x100000, tag = 'operand span for operand 7'] (stack4)
    #allocation1 [shape = 's32[2]{0}', space=sflag, size = 0x8, tag = 'scoped memory for fusion.21'] (stack5)
    #allocation2 [shape = 's32[2]{0}', space=sflag, size = 0x8, tag = 'scoped memory for fusion.21'] (stack6)
    %11 = vsyncpa [#allocation2], 0 (stack7)
    %13 = vsyncpa [#allocation2 + $0x1], 0 (stack7)
    loop: start=0, step=1, limit=10
    $region45: #{fusion.21} parent=1 // loop_pre_header
      %s120396 = smov 0 /* copy for cssa */ (stack8)
      %s120400 = smov 0 /* copy for cssa */ (stack8)
      %s120404 = smov 0 /* copy for cssa */ (stack8)
    $region50: #{fusion.21} parent=1 // loop_body
      %s120406 = sphi %s120404, %s120405 /* iteration index, stage = 1 iter bound = 1 */ (stack9)
      %s120402 = sphi %s120400, %s120401 /* iteration index, stage = 0 iter bound = 1 */ (stack9)
      %s120398 = sphi %s120396, %s120397 /* iteration index, stage = 0 */ (stack9)
      %s120399 = smov %s120398 /* phi copy :: iteration index, stage = 0 */ (stack10)
      %s120403 = smov %s120402 /* phi copy :: iteration index, stage = 0 iter bound = 1 */ (stack10)
      %s120407 = smov %s120406 /* phi copy :: iteration index, stage = 1 iter bound = 1 */ (stack10)
      %s34 = sadd.s32 1, %s120403 (stack11)
      %p36 = scmp.ge.s32.totalorder %s34, 8 (stack12)
      %s37 = scalar_select /*predicate=*/%p36, /*on_true=*/0, /*on_false=*/%s34 (stack13)
      %p119738 = scmp.ge.s32.totalorder %s120399, 1 (stack14)
      %p232 = scmp.lt.s32.totalorder %s120399, 9 (stack15)
      %p233 = pnand %p119738, %p232 (stack16)
      // Predicated region
      $region33: #{fusion.21} parent=50 // pred_check
        _
      $region34: #{fusion.21} parent=50 // pred_check_branch
        %236 = sbr.rel (%p233) target = $region36 (stack17)
      $region35: #{fusion.21} parent=50 // pred_region
        %s119739 = sadd.s32 4294967295, %s120399 (stack18)
        %s278 = sand.u32 1, %s119739 /* smod.u32 w/div 2 */ (stack19)
        %s119740 = sshll.u32 %s278, 10 (stack20)
        %s280 = scalar_lea.vmem [#allocation0], %s119740 (stack21)
        %s120390 = sshll.u32 %s120407, 8 (stack22)
        %s353 = sshrl.u32 %s120390, 10 (stack23)
        %p119745 = scmp.gt.s32.totalorder %s353, 1 (stack24)
        %s355 = scalar_select /*predicate=*/%p119745, /*on_true=*/1, /*on_false=*/%s353 (stack25)
        %s356 = sand.u32 1023, %s120390 /* smod.u32 w/div 1024 */ (stack26)
        %s357 = sshrl.u32 %s356, 7 (stack27)
        %s358 = sand.u32 127, %s356 /* smod.u32 w/div 128 */ (stack28)
        %s119746 = sshll.u32 %s355, 3 (stack29)
        %s360 = scalar_lea.vmem %s3, %s119746 (stack30)
        %s362 = scalar_lea.vmem %s360, %s357 (stack31)
        %v363 = vld [vmem:[%s362] ss:$0 sm:$0xff] (stack32)
        %s364 = sand.u32 255, %s358 (stack33)
        %s366 = sor.u32 256, %s364 (stack34)
        %367 = vbcast.lane.b32.xlu0 %v363, %s366 (stack35)
        %v368 = vpop.permute.xlu0 %367 (stack36)
        %v378 = vld [vmem:[%s4] ss:$0 sm:$0xff] (stack32)
        %379 = vbcast.lane.b32.xlu0 %v378, 0 (stack37)
        %v380 = vpop.permute.xlu0 %379 (stack38)
        %s388 = scalar_lea.vmem %s5, %s119746 (stack30)
        %s390 = scalar_lea.vmem %s388, %s357 (stack31)
        %v391 = vld [vmem:[%s390] ss:$0 sm:$0xff] (stack32)
        %395 = vbcast.lane.b32.xlu0 %v391, %s366 (stack35)
        %v396 = vpop.permute.xlu0 %395 (stack36)
        %v406 = vld [vmem:[%s6] ss:$0 sm:$0xff] (stack32)
        %407 = vbcast.lane.b32.xlu0 %v406, 0 (stack37)
        %v408 = vpop.permute.xlu0 %407 (stack38)
        %v411 = vadd.s32 %v408, %v396 (stack39)
        %v414 = vlaneseq (stack40)
        %v415 = vand.u32 127, %v414 (stack41)
        %v421 = vadd.s32 %v415, %v411 (stack39)
        %vm425 = vcmp.lt.u32.totalorder %v421, %v411 (stack42)
        %vm430 = vcmp.lt.u32.totalorder %v411, %v408 (stack42)
        %v435 = vadd.s32 %v380, %v368 (stack39)
        %v439 = vadd.s32 1, %v435 (stack39)
        %v443 = vsel /*vm=*/%vm430, /*on_true_vy=*/%v439, /*on_false_vx=*/%v435 (stack43)
        %v447 = vadd.s32 1, %v443 (stack39)
        %v451 = vsel /*vm=*/%vm425, /*on_true_vy=*/%v447, /*on_false_vx=*/%v443 (stack43)
        %v456 = vadd.s32 %v451, %v10 (stack39)
        %v460 = vadd.s32 %v421, %v9 (stack39)
        %v464 = vadd.s32 %v460, %v456 (stack39)
        %v466 = vshll.u32 %v460, 13 (stack44)
        %v467 = vshrl.u32 %v460, 19 (stack45)
        %v468 = vor.u32 %v467, %v466 (stack46)
        %v469 = vxor.u32 %v468, %v464 (stack47)
        %v472 = vadd.s32 %v469, %v464 (stack39)
        %v474 = vshll.u32 %v469, 15 (stack44)
        %v475 = vshrl.u32 %v469, 17 (stack45)
        %v476 = vor.u32 %v475, %v474 (stack46)
        %v477 = vxor.u32 %v476, %v472 (stack47)
        %v480 = vadd.s32 %v477, %v472 (stack39)
        %v482 = vshll.u32 %v477, 26 (stack44)
        %v483 = vshrl.u32 %v477, 6 (stack45)
        %v484 = vor.u32 %v483, %v482 (stack46)
        %v485 = vxor.u32 %v484, %v480 (stack47)
        %v488 = vadd.s32 %v485, %v480 (stack39)
        %v492 = vadd.s32 %v488, %v9 (stack39)
        %v494 = vshll.u32 %v485, 6 (stack44)
        %v495 = vshrl.u32 %v485, 26 (stack45)
        %v496 = vor.u32 %v495, %v494 (stack46)
        %v497 = vxor.u32 %v496, %v488 (stack47)
        %v500 = vadd.s32 %v497, %v8 (stack39)
        %v504 = vadd.s32 1, %v500 (stack39)
        %v508 = vadd.s32 %v504, %v492 (stack39)
        %v510 = vshll.u32 %v504, 17 (stack44)
        %v511 = vshrl.u32 %v504, 15 (stack45)
        %v512 = vor.u32 %v511, %v510 (stack46)
        %v513 = vxor.u32 %v512, %v508 (stack47)
        %v516 = vadd.s32 %v513, %v508 (stack39)
        %v518 = vshll.u32 %v513, 29 (stack44)
        %v519 = vshrl.u32 %v513, 3 (stack45)
        %v520 = vor.u32 %v519, %v518 (stack46)
        %v521 = vxor.u32 %v520, %v516 (stack47)
        %v524 = vadd.s32 %v521, %v516 (stack39)
        %v526 = vshll.u32 %v521, 16 (stack44)
        %v527 = vshrl.u32 %v521, 16 (stack45)
        %v528 = vor.u32 %v527, %v526 (stack46)
        %v529 = vxor.u32 %v528, %v524 (stack47)
        %v532 = vadd.s32 %v529, %v524 (stack39)
        %v536 = vadd.s32 %v532, %v8 (stack39)
        %v538 = vshll.u32 %v529, 24 (stack44)
        %v539 = vshrl.u32 %v529, 8 (stack45)
        %v540 = vor.u32 %v539, %v538 (stack46)
        %v541 = vxor.u32 %v540, %v532 (stack47)
        %v544 = vadd.s32 %v541, %v10 (stack39)
        %v548 = vadd.s32 2, %v544 (stack39)
        %v552 = vadd.s32 %v548, %v536 (stack39)
        %v554 = vshll.u32 %v548, 13 (stack44)
        %v555 = vshrl.u32 %v548, 19 (stack45)
        %v556 = vor.u32 %v555, %v554 (stack46)
        %v557 = vxor.u32 %v556, %v552 (stack47)
        %v560 = vadd.s32 %v557, %v552 (stack39)
        %v562 = vshll.u32 %v557, 15 (stack44)
        %v563 = vshrl.u32 %v557, 17 (stack45)
        %v564 = vor.u32 %v563, %v562 (stack46)
        %v565 = vxor.u32 %v564, %v560 (stack47)
        %v568 = vadd.s32 %v565, %v560 (stack39)
        %v570 = vshll.u32 %v565, 26 (stack44)
        %v571 = vshrl.u32 %v565, 6 (stack45)
        %v572 = vor.u32 %v571, %v570 (stack46)
        %v573 = vxor.u32 %v572, %v568 (stack47)
        %v576 = vadd.s32 %v573, %v568 (stack39)
        %v580 = vadd.s32 %v576, %v10 (stack39)
        %v582 = vshll.u32 %v573, 6 (stack44)
        %v583 = vshrl.u32 %v573, 26 (stack45)
        %v584 = vor.u32 %v583, %v582 (stack46)
        %v585 = vxor.u32 %v584, %v576 (stack47)
        %v588 = vadd.s32 %v585, %v9 (stack39)
        %v592 = vadd.s32 3, %v588 (stack39)
        %v596 = vadd.s32 %v592, %v580 (stack39)
        %v598 = vshll.u32 %v592, 17 (stack44)
        %v599 = vshrl.u32 %v592, 15 (stack45)
        %v600 = vor.u32 %v599, %v598 (stack46)
        %v601 = vxor.u32 %v600, %v596 (stack47)
        %v604 = vadd.s32 %v601, %v596 (stack39)
        %v606 = vshll.u32 %v601, 29 (stack44)
        %v607 = vshrl.u32 %v601, 3 (stack45)
        %v608 = vor.u32 %v607, %v606 (stack46)
        %v609 = vxor.u32 %v608, %v604 (stack47)
        %v612 = vadd.s32 %v609, %v604 (stack39)
        %v614 = vshll.u32 %v609, 16 (stack44)
        %v615 = vshrl.u32 %v609, 16 (stack45)
        %v616 = vor.u32 %v615, %v614 (stack46)
        %v617 = vxor.u32 %v616, %v612 (stack47)
        %v620 = vadd.s32 %v617, %v612 (stack39)
        %v624 = vadd.s32 %v620, %v9 (stack39)
        %v626 = vshll.u32 %v617, 24 (stack44)
        %v627 = vshrl.u32 %v617, 8 (stack45)
        %v628 = vor.u32 %v627, %v626 (stack46)
        %v629 = vxor.u32 %v628, %v620 (stack47)
        %v632 = vadd.s32 %v629, %v8 (stack39)
        %v636 = vadd.s32 4, %v632 (stack39)
        %v640 = vadd.s32 %v636, %v624 (stack39)
        %v642 = vshll.u32 %v636, 13 (stack44)
        %v643 = vshrl.u32 %v636, 19 (stack45)
        %v644 = vor.u32 %v643, %v642 (stack46)
        %v645 = vxor.u32 %v644, %v640 (stack47)
        %v648 = vadd.s32 %v645, %v640 (stack39)
        %v650 = vshll.u32 %v645, 15 (stack44)
        %v651 = vshrl.u32 %v645, 17 (stack45)
        %v652 = vor.u32 %v651, %v650 (stack46)
        %v653 = vxor.u32 %v652, %v648 (stack47)
        %v656 = vadd.s32 %v653, %v648 (stack39)
        %v658 = vshll.u32 %v653, 26 (stack44)
        %v659 = vshrl.u32 %v653, 6 (stack45)
        %v660 = vor.u32 %v659, %v658 (stack46)
        %v661 = vxor.u32 %v660, %v656 (stack47)
        %v664 = vadd.s32 %v661, %v656 (stack39)
        %v668 = vadd.s32 %v664, %v8 (stack39)
        %v670 = vshll.u32 %v661, 6 (stack44)
        %v671 = vshrl.u32 %v661, 26 (stack45)
        %v672 = vor.u32 %v671, %v670 (stack46)
        %v673 = vxor.u32 %v672, %v664 (stack47)
        %v676 = vadd.s32 %v673, %v10 (stack39)
        %v680 = vadd.s32 5, %v676 (stack39)
        %v682 = vxor.u32 %v680, %v668 (stack47)
        %v683 = vand.u32.u8 255, %v682 (stack48)
        %v684 = vand.u32 65535, %v683 (stack49)
        %v685 = vshrl.u32 %v684, 1 (stack50)
        %v686 = vor.u32 16256, %v685 (stack46)
        %v687 = vand.u32.u16 65535, %v686 (stack51)
        %v119749 = vadd.low.f32.bf16 -1.0, %v687 (stack52)
        %v696 = vmul.f32 2.0, %v119749 (stack53)
        %v700 = vadd.f32 -0.99609375, %v696 (stack52)
        %v704 = vmax.f32 %v700, -0.99609375 (stack54)
        %v706 = vand.u32 2147483647, %v704 (stack55)
        %vm709 = vcmp.eq.f32.partialorder %v706, 1.0 (stack56)
        %v714 = vmul.f32 inf, %v704 (stack53)
        %v716 = vxor.u32 2147483648, %v704 (stack57)
        %v719 = vmul.f32 %v716, %v704 (stack53)
        %v721 = vadd.f32 1.0, %v719 (stack58)
        %v722 = vlog2.pop %v721 (stack59)
        %v723 = vmul.f32 0.6931472, %v722 (stack60)
        %v724 = vmul.f32 -0.5, %v719 (stack61)
        %v725 = vadd.f32 1.0, %v724 (stack62)
        %v726 = vmul.f32 %v725, %v719 (stack63)
        %v727 = vand.u32 2147483647, %v719 (stack64)
        %vm728 = vcmp.lt.f32.partialorder %v727, 0.0004427343 (stack65)
        %v729 = vsel /*vm=*/%vm728, /*on_true_vy=*/%v726, /*on_false_vx=*/%v723 (stack66)
        %v730 = vxor.u32 2147483648, %v729 (stack57)
        %vm733 = vcmp.lt.f32.partialorder %v730, 5.0 (stack56)
        %v738 = vsel /*vm=*/%vm733, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v742 = vsel /*vm=*/%vm733, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v746 = vsel /*vm=*/%vm733, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v750 = vsel /*vm=*/%vm733, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v754 = vsel /*vm=*/%vm733, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v758 = vsel /*vm=*/%vm733, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v762 = vsel /*vm=*/%vm733, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v766 = vsel /*vm=*/%vm733, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v770 = vsel /*vm=*/%vm733, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v774 = vadd.f32 -2.5, %v730 (stack52)
        %v776 = vrsqrt.pop %v730 (stack67)
        %v777 = vmul.f32 %v776, %v730 (stack68)
        %vm778 = vcmp.eq.f32.partialorder %v730, inf (stack69)
        %v779 = vsel /*vm=*/%vm778, /*on_true_vy=*/%v730, /*on_false_vx=*/%v777 (stack70)
        %vm780 = vcmp.eq.f32.partialorder %v730, 0.0 (stack71)
        %v781 = vand.u32 2147483648, %v730 (stack72)
        %v782 = vsel /*vm=*/%vm780, /*on_true_vy=*/%v781, /*on_false_vx=*/%v779 (stack73)
        %v785 = vadd.f32 -3.0, %v782 (stack52)
        %v789 = vsel /*vm=*/%vm733, /*on_true_vy=*/%v774, /*on_false_vx=*/%v785 (stack43)
        %v793 = vmul.f32 %v789, %v770 (stack53)
        %v797 = vadd.f32 %v793, %v766 (stack52)
        %v801 = vmul.f32 %v797, %v789 (stack53)
        %v805 = vadd.f32 %v801, %v762 (stack52)
        %v809 = vmul.f32 %v805, %v789 (stack53)
        %v813 = vadd.f32 %v809, %v758 (stack52)
        %v817 = vmul.f32 %v813, %v789 (stack53)
        %v821 = vadd.f32 %v817, %v754 (stack52)
        %v825 = vmul.f32 %v821, %v789 (stack53)
        %v829 = vadd.f32 %v825, %v750 (stack52)
        %v833 = vmul.f32 %v829, %v789 (stack53)
        %v837 = vadd.f32 %v833, %v746 (stack52)
        %v841 = vmul.f32 %v837, %v789 (stack53)
        %v845 = vadd.f32 %v841, %v742 (stack52)
        %v849 = vmul.f32 %v845, %v789 (stack53)
        %v853 = vadd.f32 %v849, %v738 (stack52)
        %v857 = vmul.f32 %v853, %v704 (stack53)
        %v861 = vsel /*vm=*/%vm709, /*on_true_vy=*/%v714, /*on_false_vx=*/%v857 (stack43)
        %v865 = vmul.f32 1.4140625, %v861 (stack53)
        %v867 = vpack.c.bf16 0.0, %v865 (stack74)
        %868 = vst [vmem:[%s280] sm:$0xf] /*vst_source=*/%v867 (stack75)
        %v879 = vld [vmem:[%s4] ss:$0 sm:$0xff] (stack32)
        %880 = vbcast.lane.b32.xlu0 %v879, 1 (stack37)
        %v881 = vpop.permute.xlu0 %880 (stack38)
        %v892 = vld [vmem:[%s6] ss:$0 sm:$0xff] (stack32)
        %893 = vbcast.lane.b32.xlu0 %v892, 1 (stack37)
        %v894 = vpop.permute.xlu0 %893 (stack38)
        %v897 = vadd.s32 %v894, %v396 (stack39)
        %v907 = vadd.s32 %v897, %v415 (stack39)
        %vm911 = vcmp.lt.u32.totalorder %v907, %v897 (stack42)
        %vm916 = vcmp.lt.u32.totalorder %v897, %v894 (stack42)
        %v921 = vadd.s32 %v881, %v368 (stack39)
        %v925 = vadd.s32 1, %v921 (stack39)
        %v929 = vsel /*vm=*/%vm916, /*on_true_vy=*/%v925, /*on_false_vx=*/%v921 (stack43)
        %v933 = vadd.s32 1, %v929 (stack39)
        %v937 = vsel /*vm=*/%vm911, /*on_true_vy=*/%v933, /*on_false_vx=*/%v929 (stack43)
        %v942 = vadd.s32 %v937, %v10 (stack39)
        %v946 = vadd.s32 %v907, %v9 (stack39)
        %v950 = vadd.s32 %v946, %v942 (stack39)
        %v952 = vshll.u32 %v946, 13 (stack44)
        %v953 = vshrl.u32 %v946, 19 (stack45)
        %v954 = vor.u32 %v953, %v952 (stack46)
        %v955 = vxor.u32 %v954, %v950 (stack47)
        %v958 = vadd.s32 %v955, %v950 (stack39)
        %v960 = vshll.u32 %v955, 15 (stack44)
        %v961 = vshrl.u32 %v955, 17 (stack45)
        %v962 = vor.u32 %v961, %v960 (stack46)
        %v963 = vxor.u32 %v962, %v958 (stack47)
        %v966 = vadd.s32 %v963, %v958 (stack39)
        %v968 = vshll.u32 %v963, 26 (stack44)
        %v969 = vshrl.u32 %v963, 6 (stack45)
        %v970 = vor.u32 %v969, %v968 (stack46)
        %v971 = vxor.u32 %v970, %v966 (stack47)
        %v974 = vadd.s32 %v971, %v966 (stack39)
        %v978 = vadd.s32 %v974, %v9 (stack39)
        %v980 = vshll.u32 %v971, 6 (stack44)
        %v981 = vshrl.u32 %v971, 26 (stack45)
        %v982 = vor.u32 %v981, %v980 (stack46)
        %v983 = vxor.u32 %v982, %v974 (stack47)
        %v986 = vadd.s32 %v983, %v8 (stack39)
        %v990 = vadd.s32 1, %v986 (stack39)
        %v994 = vadd.s32 %v990, %v978 (stack39)
        %v996 = vshll.u32 %v990, 17 (stack44)
        %v997 = vshrl.u32 %v990, 15 (stack45)
        %v998 = vor.u32 %v997, %v996 (stack46)
        %v999 = vxor.u32 %v998, %v994 (stack47)
        %v1002 = vadd.s32 %v999, %v994 (stack39)
        %v1004 = vshll.u32 %v999, 29 (stack44)
        %v1005 = vshrl.u32 %v999, 3 (stack45)
        %v1006 = vor.u32 %v1005, %v1004 (stack46)
        %v1007 = vxor.u32 %v1006, %v1002 (stack47)
        %v1010 = vadd.s32 %v1007, %v1002 (stack39)
        %v1012 = vshll.u32 %v1007, 16 (stack44)
        %v1013 = vshrl.u32 %v1007, 16 (stack45)
        %v1014 = vor.u32 %v1013, %v1012 (stack46)
        %v1015 = vxor.u32 %v1014, %v1010 (stack47)
        %v1018 = vadd.s32 %v1015, %v1010 (stack39)
        %v1022 = vadd.s32 %v1018, %v8 (stack39)
        %v1024 = vshll.u32 %v1015, 24 (stack44)
        %v1025 = vshrl.u32 %v1015, 8 (stack45)
        %v1026 = vor.u32 %v1025, %v1024 (stack46)
        %v1027 = vxor.u32 %v1026, %v1018 (stack47)
        %v1030 = vadd.s32 %v1027, %v10 (stack39)
        %v1034 = vadd.s32 2, %v1030 (stack39)
        %v1038 = vadd.s32 %v1034, %v1022 (stack39)
        %v1040 = vshll.u32 %v1034, 13 (stack44)
        %v1041 = vshrl.u32 %v1034, 19 (stack45)
        %v1042 = vor.u32 %v1041, %v1040 (stack46)
        %v1043 = vxor.u32 %v1042, %v1038 (stack47)
        %v1046 = vadd.s32 %v1043, %v1038 (stack39)
        %v1048 = vshll.u32 %v1043, 15 (stack44)
        %v1049 = vshrl.u32 %v1043, 17 (stack45)
        %v1050 = vor.u32 %v1049, %v1048 (stack46)
        %v1051 = vxor.u32 %v1050, %v1046 (stack47)
        %v1054 = vadd.s32 %v1051, %v1046 (stack39)
        %v1056 = vshll.u32 %v1051, 26 (stack44)
        %v1057 = vshrl.u32 %v1051, 6 (stack45)
        %v1058 = vor.u32 %v1057, %v1056 (stack46)
        %v1059 = vxor.u32 %v1058, %v1054 (stack47)
        %v1062 = vadd.s32 %v1059, %v1054 (stack39)
        %v1066 = vadd.s32 %v1062, %v10 (stack39)
        %v1068 = vshll.u32 %v1059, 6 (stack44)
        %v1069 = vshrl.u32 %v1059, 26 (stack45)
        %v1070 = vor.u32 %v1069, %v1068 (stack46)
        %v1071 = vxor.u32 %v1070, %v1062 (stack47)
        %v1074 = vadd.s32 %v1071, %v9 (stack39)
        %v1078 = vadd.s32 3, %v1074 (stack39)
        %v1082 = vadd.s32 %v1078, %v1066 (stack39)
        %v1084 = vshll.u32 %v1078, 17 (stack44)
        %v1085 = vshrl.u32 %v1078, 15 (stack45)
        %v1086 = vor.u32 %v1085, %v1084 (stack46)
        %v1087 = vxor.u32 %v1086, %v1082 (stack47)
        %v1090 = vadd.s32 %v1087, %v1082 (stack39)
        %v1092 = vshll.u32 %v1087, 29 (stack44)
        %v1093 = vshrl.u32 %v1087, 3 (stack45)
        %v1094 = vor.u32 %v1093, %v1092 (stack46)
        %v1095 = vxor.u32 %v1094, %v1090 (stack47)
        %v1098 = vadd.s32 %v1095, %v1090 (stack39)
        %v1100 = vshll.u32 %v1095, 16 (stack44)
        %v1101 = vshrl.u32 %v1095, 16 (stack45)
        %v1102 = vor.u32 %v1101, %v1100 (stack46)
        %v1103 = vxor.u32 %v1102, %v1098 (stack47)
        %v1106 = vadd.s32 %v1103, %v1098 (stack39)
        %v1110 = vadd.s32 %v1106, %v9 (stack39)
        %v1112 = vshll.u32 %v1103, 24 (stack44)
        %v1113 = vshrl.u32 %v1103, 8 (stack45)
        %v1114 = vor.u32 %v1113, %v1112 (stack46)
        %v1115 = vxor.u32 %v1114, %v1106 (stack47)
        %v1118 = vadd.s32 %v1115, %v8 (stack39)
        %v1122 = vadd.s32 4, %v1118 (stack39)
        %v1126 = vadd.s32 %v1122, %v1110 (stack39)
        %v1128 = vshll.u32 %v1122, 13 (stack44)
        %v1129 = vshrl.u32 %v1122, 19 (stack45)
        %v1130 = vor.u32 %v1129, %v1128 (stack46)
        %v1131 = vxor.u32 %v1130, %v1126 (stack47)
        %v1134 = vadd.s32 %v1131, %v1126 (stack39)
        %v1136 = vshll.u32 %v1131, 15 (stack44)
        %v1137 = vshrl.u32 %v1131, 17 (stack45)
        %v1138 = vor.u32 %v1137, %v1136 (stack46)
        %v1139 = vxor.u32 %v1138, %v1134 (stack47)
        %v1142 = vadd.s32 %v1139, %v1134 (stack39)
        %v1144 = vshll.u32 %v1139, 26 (stack44)
        %v1145 = vshrl.u32 %v1139, 6 (stack45)
        %v1146 = vor.u32 %v1145, %v1144 (stack46)
        %v1147 = vxor.u32 %v1146, %v1142 (stack47)
        %v1150 = vadd.s32 %v1147, %v1142 (stack39)
        %v1154 = vadd.s32 %v1150, %v8 (stack39)
        %v1156 = vshll.u32 %v1147, 6 (stack44)
        %v1157 = vshrl.u32 %v1147, 26 (stack45)
        %v1158 = vor.u32 %v1157, %v1156 (stack46)
        %v1159 = vxor.u32 %v1158, %v1150 (stack47)
        %v1162 = vadd.s32 %v1159, %v10 (stack39)
        %v1166 = vadd.s32 5, %v1162 (stack39)
        %v1168 = vxor.u32 %v1166, %v1154 (stack47)
        %v1169 = vand.u32.u8 255, %v1168 (stack48)
        %v1170 = vand.u32 65535, %v1169 (stack49)
        %v1171 = vshrl.u32 %v1170, 1 (stack50)
        %v1172 = vor.u32 16256, %v1171 (stack46)
        %v1173 = vand.u32.u16 65535, %v1172 (stack51)
        %v119750 = vadd.low.f32.bf16 -1.0, %v1173 (stack52)
        %v1182 = vmul.f32 2.0, %v119750 (stack53)
        %v1186 = vadd.f32 -0.99609375, %v1182 (stack52)
        %v1190 = vmax.f32 %v1186, -0.99609375 (stack54)
        %v1192 = vand.u32 2147483647, %v1190 (stack55)
        %vm1195 = vcmp.eq.f32.partialorder %v1192, 1.0 (stack56)
        %v1200 = vmul.f32 inf, %v1190 (stack53)
        %v1202 = vxor.u32 2147483648, %v1190 (stack57)
        %v1205 = vmul.f32 %v1202, %v1190 (stack53)
        %v1207 = vadd.f32 1.0, %v1205 (stack58)
        %v1208 = vlog2.pop %v1207 (stack59)
        %v1209 = vmul.f32 0.6931472, %v1208 (stack60)
        %v1210 = vmul.f32 -0.5, %v1205 (stack61)
        %v1211 = vadd.f32 1.0, %v1210 (stack62)
        %v1212 = vmul.f32 %v1211, %v1205 (stack63)
        %v1213 = vand.u32 2147483647, %v1205 (stack64)
        %vm1214 = vcmp.lt.f32.partialorder %v1213, 0.0004427343 (stack65)
        %v1215 = vsel /*vm=*/%vm1214, /*on_true_vy=*/%v1212, /*on_false_vx=*/%v1209 (stack66)
        %v1216 = vxor.u32 2147483648, %v1215 (stack57)
        %vm1219 = vcmp.lt.f32.partialorder %v1216, 5.0 (stack56)
        %v1224 = vsel /*vm=*/%vm1219, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v1228 = vsel /*vm=*/%vm1219, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v1232 = vsel /*vm=*/%vm1219, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v1236 = vsel /*vm=*/%vm1219, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v1240 = vsel /*vm=*/%vm1219, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v1244 = vsel /*vm=*/%vm1219, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v1248 = vsel /*vm=*/%vm1219, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v1252 = vsel /*vm=*/%vm1219, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v1256 = vsel /*vm=*/%vm1219, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v1260 = vadd.f32 -2.5, %v1216 (stack52)
        %v1262 = vrsqrt.pop %v1216 (stack67)
        %v1263 = vmul.f32 %v1262, %v1216 (stack68)
        %vm1264 = vcmp.eq.f32.partialorder %v1216, inf (stack69)
        %v1265 = vsel /*vm=*/%vm1264, /*on_true_vy=*/%v1216, /*on_false_vx=*/%v1263 (stack70)
        %vm1266 = vcmp.eq.f32.partialorder %v1216, 0.0 (stack71)
        %v1267 = vand.u32 2147483648, %v1216 (stack72)
        %v1268 = vsel /*vm=*/%vm1266, /*on_true_vy=*/%v1267, /*on_false_vx=*/%v1265 (stack73)
        %v1271 = vadd.f32 -3.0, %v1268 (stack52)
        %v1275 = vsel /*vm=*/%vm1219, /*on_true_vy=*/%v1260, /*on_false_vx=*/%v1271 (stack43)
        %v1279 = vmul.f32 %v1275, %v1256 (stack53)
        %v1283 = vadd.f32 %v1279, %v1252 (stack52)
        %v1287 = vmul.f32 %v1283, %v1275 (stack53)
        %v1291 = vadd.f32 %v1287, %v1248 (stack52)
        %v1295 = vmul.f32 %v1291, %v1275 (stack53)
        %v1299 = vadd.f32 %v1295, %v1244 (stack52)
        %v1303 = vmul.f32 %v1299, %v1275 (stack53)
        %v1307 = vadd.f32 %v1303, %v1240 (stack52)
        %v1311 = vmul.f32 %v1307, %v1275 (stack53)
        %v1315 = vadd.f32 %v1311, %v1236 (stack52)
        %v1319 = vmul.f32 %v1315, %v1275 (stack53)
        %v1323 = vadd.f32 %v1319, %v1232 (stack52)
        %v1327 = vmul.f32 %v1323, %v1275 (stack53)
        %v1331 = vadd.f32 %v1327, %v1228 (stack52)
        %v1335 = vmul.f32 %v1331, %v1275 (stack53)
        %v1339 = vadd.f32 %v1335, %v1224 (stack52)
        %v1343 = vmul.f32 %v1339, %v1190 (stack53)
        %v1347 = vsel /*vm=*/%vm1195, /*on_true_vy=*/%v1200, /*on_false_vx=*/%v1343 (stack43)
        %v1351 = vmul.f32 1.4140625, %v1347 (stack53)
        %v1354 = vpack.c.bf16 0.0, %v1351 (stack74)
        %119751 = vst [vmem:[%s280 + $0x80] sm:$0xf] /*vst_source=*/%v1354 (stack75)
        %v1366 = vld [vmem:[%s4] ss:$0 sm:$0xff] (stack32)
        %1367 = vbcast.lane.b32.xlu0 %v1366, 2 (stack37)
        %v1368 = vpop.permute.xlu0 %1367 (stack38)
        %v1379 = vld [vmem:[%s6] ss:$0 sm:$0xff] (stack32)
        %1380 = vbcast.lane.b32.xlu0 %v1379, 2 (stack37)
        %v1381 = vpop.permute.xlu0 %1380 (stack38)
        %v1384 = vadd.s32 %v1381, %v396 (stack39)
        %v1394 = vadd.s32 %v1384, %v415 (stack39)
        %vm1398 = vcmp.lt.u32.totalorder %v1394, %v1384 (stack42)
        %vm1403 = vcmp.lt.u32.totalorder %v1384, %v1381 (stack42)
        %v1408 = vadd.s32 %v1368, %v368 (stack39)
        %v1412 = vadd.s32 1, %v1408 (stack39)
        %v1416 = vsel /*vm=*/%vm1403, /*on_true_vy=*/%v1412, /*on_false_vx=*/%v1408 (stack43)
        %v1420 = vadd.s32 1, %v1416 (stack39)
        %v1424 = vsel /*vm=*/%vm1398, /*on_true_vy=*/%v1420, /*on_false_vx=*/%v1416 (stack43)
        %v1429 = vadd.s32 %v1424, %v10 (stack39)
        %v1433 = vadd.s32 %v1394, %v9 (stack39)
        %v1437 = vadd.s32 %v1433, %v1429 (stack39)
        %v1439 = vshll.u32 %v1433, 13 (stack44)
        %v1440 = vshrl.u32 %v1433, 19 (stack45)
        %v1441 = vor.u32 %v1440, %v1439 (stack46)
        %v1442 = vxor.u32 %v1441, %v1437 (stack47)
        %v1445 = vadd.s32 %v1442, %v1437 (stack39)
        %v1447 = vshll.u32 %v1442, 15 (stack44)
        %v1448 = vshrl.u32 %v1442, 17 (stack45)
        %v1449 = vor.u32 %v1448, %v1447 (stack46)
        %v1450 = vxor.u32 %v1449, %v1445 (stack47)
        %v1453 = vadd.s32 %v1450, %v1445 (stack39)
        %v1455 = vshll.u32 %v1450, 26 (stack44)
        %v1456 = vshrl.u32 %v1450, 6 (stack45)
        %v1457 = vor.u32 %v1456, %v1455 (stack46)
        %v1458 = vxor.u32 %v1457, %v1453 (stack47)
        %v1461 = vadd.s32 %v1458, %v1453 (stack39)
        %v1465 = vadd.s32 %v1461, %v9 (stack39)
        %v1467 = vshll.u32 %v1458, 6 (stack44)
        %v1468 = vshrl.u32 %v1458, 26 (stack45)
        %v1469 = vor.u32 %v1468, %v1467 (stack46)
        %v1470 = vxor.u32 %v1469, %v1461 (stack47)
        %v1473 = vadd.s32 %v1470, %v8 (stack39)
        %v1477 = vadd.s32 1, %v1473 (stack39)
        %v1481 = vadd.s32 %v1477, %v1465 (stack39)
        %v1483 = vshll.u32 %v1477, 17 (stack44)
        %v1484 = vshrl.u32 %v1477, 15 (stack45)
        %v1485 = vor.u32 %v1484, %v1483 (stack46)
        %v1486 = vxor.u32 %v1485, %v1481 (stack47)
        %v1489 = vadd.s32 %v1486, %v1481 (stack39)
        %v1491 = vshll.u32 %v1486, 29 (stack44)
        %v1492 = vshrl.u32 %v1486, 3 (stack45)
        %v1493 = vor.u32 %v1492, %v1491 (stack46)
        %v1494 = vxor.u32 %v1493, %v1489 (stack47)
        %v1497 = vadd.s32 %v1494, %v1489 (stack39)
        %v1499 = vshll.u32 %v1494, 16 (stack44)
        %v1500 = vshrl.u32 %v1494, 16 (stack45)
        %v1501 = vor.u32 %v1500, %v1499 (stack46)
        %v1502 = vxor.u32 %v1501, %v1497 (stack47)
        %v1505 = vadd.s32 %v1502, %v1497 (stack39)
        %v1509 = vadd.s32 %v1505, %v8 (stack39)
        %v1511 = vshll.u32 %v1502, 24 (stack44)
        %v1512 = vshrl.u32 %v1502, 8 (stack45)
        %v1513 = vor.u32 %v1512, %v1511 (stack46)
        %v1514 = vxor.u32 %v1513, %v1505 (stack47)
        %v1517 = vadd.s32 %v1514, %v10 (stack39)
        %v1521 = vadd.s32 2, %v1517 (stack39)
        %v1525 = vadd.s32 %v1521, %v1509 (stack39)
        %v1527 = vshll.u32 %v1521, 13 (stack44)
        %v1528 = vshrl.u32 %v1521, 19 (stack45)
        %v1529 = vor.u32 %v1528, %v1527 (stack46)
        %v1530 = vxor.u32 %v1529, %v1525 (stack47)
        %v1533 = vadd.s32 %v1530, %v1525 (stack39)
        %v1535 = vshll.u32 %v1530, 15 (stack44)
        %v1536 = vshrl.u32 %v1530, 17 (stack45)
        %v1537 = vor.u32 %v1536, %v1535 (stack46)
        %v1538 = vxor.u32 %v1537, %v1533 (stack47)
        %v1541 = vadd.s32 %v1538, %v1533 (stack39)
        %v1543 = vshll.u32 %v1538, 26 (stack44)
        %v1544 = vshrl.u32 %v1538, 6 (stack45)
        %v1545 = vor.u32 %v1544, %v1543 (stack46)
        %v1546 = vxor.u32 %v1545, %v1541 (stack47)
        %v1549 = vadd.s32 %v1546, %v1541 (stack39)
        %v1553 = vadd.s32 %v1549, %v10 (stack39)
        %v1555 = vshll.u32 %v1546, 6 (stack44)
        %v1556 = vshrl.u32 %v1546, 26 (stack45)
        %v1557 = vor.u32 %v1556, %v1555 (stack46)
        %v1558 = vxor.u32 %v1557, %v1549 (stack47)
        %v1561 = vadd.s32 %v1558, %v9 (stack39)
        %v1565 = vadd.s32 3, %v1561 (stack39)
        %v1569 = vadd.s32 %v1565, %v1553 (stack39)
        %v1571 = vshll.u32 %v1565, 17 (stack44)
        %v1572 = vshrl.u32 %v1565, 15 (stack45)
        %v1573 = vor.u32 %v1572, %v1571 (stack46)
        %v1574 = vxor.u32 %v1573, %v1569 (stack47)
        %v1577 = vadd.s32 %v1574, %v1569 (stack39)
        %v1579 = vshll.u32 %v1574, 29 (stack44)
        %v1580 = vshrl.u32 %v1574, 3 (stack45)
        %v1581 = vor.u32 %v1580, %v1579 (stack46)
        %v1582 = vxor.u32 %v1581, %v1577 (stack47)
        %v1585 = vadd.s32 %v1582, %v1577 (stack39)
        %v1587 = vshll.u32 %v1582, 16 (stack44)
        %v1588 = vshrl.u32 %v1582, 16 (stack45)
        %v1589 = vor.u32 %v1588, %v1587 (stack46)
        %v1590 = vxor.u32 %v1589, %v1585 (stack47)
        %v1593 = vadd.s32 %v1590, %v1585 (stack39)
        %v1597 = vadd.s32 %v1593, %v9 (stack39)
        %v1599 = vshll.u32 %v1590, 24 (stack44)
        %v1600 = vshrl.u32 %v1590, 8 (stack45)
        %v1601 = vor.u32 %v1600, %v1599 (stack46)
        %v1602 = vxor.u32 %v1601, %v1593 (stack47)
        %v1605 = vadd.s32 %v1602, %v8 (stack39)
        %v1609 = vadd.s32 4, %v1605 (stack39)
        %v1613 = vadd.s32 %v1609, %v1597 (stack39)
        %v1615 = vshll.u32 %v1609, 13 (stack44)
        %v1616 = vshrl.u32 %v1609, 19 (stack45)
        %v1617 = vor.u32 %v1616, %v1615 (stack46)
        %v1618 = vxor.u32 %v1617, %v1613 (stack47)
        %v1621 = vadd.s32 %v1618, %v1613 (stack39)
        %v1623 = vshll.u32 %v1618, 15 (stack44)
        %v1624 = vshrl.u32 %v1618, 17 (stack45)
        %v1625 = vor.u32 %v1624, %v1623 (stack46)
        %v1626 = vxor.u32 %v1625, %v1621 (stack47)
        %v1629 = vadd.s32 %v1626, %v1621 (stack39)
        %v1631 = vshll.u32 %v1626, 26 (stack44)
        %v1632 = vshrl.u32 %v1626, 6 (stack45)
        %v1633 = vor.u32 %v1632, %v1631 (stack46)
        %v1634 = vxor.u32 %v1633, %v1629 (stack47)
        %v1637 = vadd.s32 %v1634, %v1629 (stack39)
        %v1641 = vadd.s32 %v1637, %v8 (stack39)
        %v1643 = vshll.u32 %v1634, 6 (stack44)
        %v1644 = vshrl.u32 %v1634, 26 (stack45)
        %v1645 = vor.u32 %v1644, %v1643 (stack46)
        %v1646 = vxor.u32 %v1645, %v1637 (stack47)
        %v1649 = vadd.s32 %v1646, %v10 (stack39)
        %v1653 = vadd.s32 5, %v1649 (stack39)
        %v1655 = vxor.u32 %v1653, %v1641 (stack47)
        %v1656 = vand.u32.u8 255, %v1655 (stack48)
        %v1657 = vand.u32 65535, %v1656 (stack49)
        %v1658 = vshrl.u32 %v1657, 1 (stack50)
        %v1659 = vor.u32 16256, %v1658 (stack46)
        %v1660 = vand.u32.u16 65535, %v1659 (stack51)
        %v119752 = vadd.low.f32.bf16 -1.0, %v1660 (stack52)
        %v1669 = vmul.f32 2.0, %v119752 (stack53)
        %v1673 = vadd.f32 -0.99609375, %v1669 (stack52)
        %v1677 = vmax.f32 %v1673, -0.99609375 (stack54)
        %v1679 = vand.u32 2147483647, %v1677 (stack55)
        %vm1682 = vcmp.eq.f32.partialorder %v1679, 1.0 (stack56)
        %v1687 = vmul.f32 inf, %v1677 (stack53)
        %v1689 = vxor.u32 2147483648, %v1677 (stack57)
        %v1692 = vmul.f32 %v1689, %v1677 (stack53)
        %v1694 = vadd.f32 1.0, %v1692 (stack58)
        %v1695 = vlog2.pop %v1694 (stack59)
        %v1696 = vmul.f32 0.6931472, %v1695 (stack60)
        %v1697 = vmul.f32 -0.5, %v1692 (stack61)
        %v1698 = vadd.f32 1.0, %v1697 (stack62)
        %v1699 = vmul.f32 %v1698, %v1692 (stack63)
        %v1700 = vand.u32 2147483647, %v1692 (stack64)
        %vm1701 = vcmp.lt.f32.partialorder %v1700, 0.0004427343 (stack65)
        %v1702 = vsel /*vm=*/%vm1701, /*on_true_vy=*/%v1699, /*on_false_vx=*/%v1696 (stack66)
        %v1703 = vxor.u32 2147483648, %v1702 (stack57)
        %vm1706 = vcmp.lt.f32.partialorder %v1703, 5.0 (stack56)
        %v1711 = vsel /*vm=*/%vm1706, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v1715 = vsel /*vm=*/%vm1706, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v1719 = vsel /*vm=*/%vm1706, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v1723 = vsel /*vm=*/%vm1706, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v1727 = vsel /*vm=*/%vm1706, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v1731 = vsel /*vm=*/%vm1706, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v1735 = vsel /*vm=*/%vm1706, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v1739 = vsel /*vm=*/%vm1706, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v1743 = vsel /*vm=*/%vm1706, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v1747 = vadd.f32 -2.5, %v1703 (stack52)
        %v1749 = vrsqrt.pop %v1703 (stack67)
        %v1750 = vmul.f32 %v1749, %v1703 (stack68)
        %vm1751 = vcmp.eq.f32.partialorder %v1703, inf (stack69)
        %v1752 = vsel /*vm=*/%vm1751, /*on_true_vy=*/%v1703, /*on_false_vx=*/%v1750 (stack70)
        %vm1753 = vcmp.eq.f32.partialorder %v1703, 0.0 (stack71)
        %v1754 = vand.u32 2147483648, %v1703 (stack72)
        %v1755 = vsel /*vm=*/%vm1753, /*on_true_vy=*/%v1754, /*on_false_vx=*/%v1752 (stack73)
        %v1758 = vadd.f32 -3.0, %v1755 (stack52)
        %v1762 = vsel /*vm=*/%vm1706, /*on_true_vy=*/%v1747, /*on_false_vx=*/%v1758 (stack43)
        %v1766 = vmul.f32 %v1762, %v1743 (stack53)
        %v1770 = vadd.f32 %v1766, %v1739 (stack52)
        %v1774 = vmul.f32 %v1770, %v1762 (stack53)
        %v1778 = vadd.f32 %v1774, %v1735 (stack52)
        %v1782 = vmul.f32 %v1778, %v1762 (stack53)
        %v1786 = vadd.f32 %v1782, %v1731 (stack52)
        %v1790 = vmul.f32 %v1786, %v1762 (stack53)
        %v1794 = vadd.f32 %v1790, %v1727 (stack52)
        %v1798 = vmul.f32 %v1794, %v1762 (stack53)
        %v1802 = vadd.f32 %v1798, %v1723 (stack52)
        %v1806 = vmul.f32 %v1802, %v1762 (stack53)
        %v1810 = vadd.f32 %v1806, %v1719 (stack52)
        %v1814 = vmul.f32 %v1810, %v1762 (stack53)
        %v1818 = vadd.f32 %v1814, %v1715 (stack52)
        %v1822 = vmul.f32 %v1818, %v1762 (stack53)
        %v1826 = vadd.f32 %v1822, %v1711 (stack52)
        %v1830 = vmul.f32 %v1826, %v1677 (stack53)
        %v1834 = vsel /*vm=*/%vm1682, /*on_true_vy=*/%v1687, /*on_false_vx=*/%v1830 (stack43)
        %v1838 = vmul.f32 1.4140625, %v1834 (stack53)
        %v1841 = vpack.c.bf16 0.0, %v1838 (stack74)
        %119753 = vst [vmem:[%s280 + $0x100] sm:$0xf] /*vst_source=*/%v1841 (stack75)
        %v1853 = vld [vmem:[%s4] ss:$0 sm:$0xff] (stack32)
        %1854 = vbcast.lane.b32.xlu0 %v1853, 3 (stack37)
        %v1855 = vpop.permute.xlu0 %1854 (stack38)
        %v1866 = vld [vmem:[%s6] ss:$0 sm:$0xff] (stack32)
        %1867 = vbcast.lane.b32.xlu0 %v1866, 3 (stack37)
        %v1868 = vpop.permute.xlu0 %1867 (stack38)
        %v1871 = vadd.s32 %v1868, %v396 (stack39)
        %v1881 = vadd.s32 %v1871, %v415 (stack39)
        %vm1885 = vcmp.lt.u32.totalorder %v1881, %v1871 (stack42)
        %vm1890 = vcmp.lt.u32.totalorder %v1871, %v1868 (stack42)
        %v1895 = vadd.s32 %v1855, %v368 (stack39)
        %v1899 = vadd.s32 1, %v1895 (stack39)
        %v1903 = vsel /*vm=*/%vm1890, /*on_true_vy=*/%v1899, /*on_false_vx=*/%v1895 (stack43)
        %v1907 = vadd.s32 1, %v1903 (stack39)
        %v1911 = vsel /*vm=*/%vm1885, /*on_true_vy=*/%v1907, /*on_false_vx=*/%v1903 (stack43)
        %v1916 = vadd.s32 %v1911, %v10 (stack39)
        %v1920 = vadd.s32 %v1881, %v9 (stack39)
        %v1924 = vadd.s32 %v1920, %v1916 (stack39)
        %v1926 = vshll.u32 %v1920, 13 (stack44)
        %v1927 = vshrl.u32 %v1920, 19 (stack45)
        %v1928 = vor.u32 %v1927, %v1926 (stack46)
        %v1929 = vxor.u32 %v1928, %v1924 (stack47)
        %v1932 = vadd.s32 %v1929, %v1924 (stack39)
        %v1934 = vshll.u32 %v1929, 15 (stack44)
        %v1935 = vshrl.u32 %v1929, 17 (stack45)
        %v1936 = vor.u32 %v1935, %v1934 (stack46)
        %v1937 = vxor.u32 %v1936, %v1932 (stack47)
        %v1940 = vadd.s32 %v1937, %v1932 (stack39)
        %v1942 = vshll.u32 %v1937, 26 (stack44)
        %v1943 = vshrl.u32 %v1937, 6 (stack45)
        %v1944 = vor.u32 %v1943, %v1942 (stack46)
        %v1945 = vxor.u32 %v1944, %v1940 (stack47)
        %v1948 = vadd.s32 %v1945, %v1940 (stack39)
        %v1952 = vadd.s32 %v1948, %v9 (stack39)
        %v1954 = vshll.u32 %v1945, 6 (stack44)
        %v1955 = vshrl.u32 %v1945, 26 (stack45)
        %v1956 = vor.u32 %v1955, %v1954 (stack46)
        %v1957 = vxor.u32 %v1956, %v1948 (stack47)
        %v1960 = vadd.s32 %v1957, %v8 (stack39)
        %v1964 = vadd.s32 1, %v1960 (stack39)
        %v1968 = vadd.s32 %v1964, %v1952 (stack39)
        %v1970 = vshll.u32 %v1964, 17 (stack44)
        %v1971 = vshrl.u32 %v1964, 15 (stack45)
        %v1972 = vor.u32 %v1971, %v1970 (stack46)
        %v1973 = vxor.u32 %v1972, %v1968 (stack47)
        %v1976 = vadd.s32 %v1973, %v1968 (stack39)
        %v1978 = vshll.u32 %v1973, 29 (stack44)
        %v1979 = vshrl.u32 %v1973, 3 (stack45)
        %v1980 = vor.u32 %v1979, %v1978 (stack46)
        %v1981 = vxor.u32 %v1980, %v1976 (stack47)
        %v1984 = vadd.s32 %v1981, %v1976 (stack39)
        %v1986 = vshll.u32 %v1981, 16 (stack44)
        %v1987 = vshrl.u32 %v1981, 16 (stack45)
        %v1988 = vor.u32 %v1987, %v1986 (stack46)
        %v1989 = vxor.u32 %v1988, %v1984 (stack47)
        %v1992 = vadd.s32 %v1989, %v1984 (stack39)
        %v1996 = vadd.s32 %v1992, %v8 (stack39)
        %v1998 = vshll.u32 %v1989, 24 (stack44)
        %v1999 = vshrl.u32 %v1989, 8 (stack45)
        %v2000 = vor.u32 %v1999, %v1998 (stack46)
        %v2001 = vxor.u32 %v2000, %v1992 (stack47)
        %v2004 = vadd.s32 %v2001, %v10 (stack39)
        %v2008 = vadd.s32 2, %v2004 (stack39)
        %v2012 = vadd.s32 %v2008, %v1996 (stack39)
        %v2014 = vshll.u32 %v2008, 13 (stack44)
        %v2015 = vshrl.u32 %v2008, 19 (stack45)
        %v2016 = vor.u32 %v2015, %v2014 (stack46)
        %v2017 = vxor.u32 %v2016, %v2012 (stack47)
        %v2020 = vadd.s32 %v2017, %v2012 (stack39)
        %v2022 = vshll.u32 %v2017, 15 (stack44)
        %v2023 = vshrl.u32 %v2017, 17 (stack45)
        %v2024 = vor.u32 %v2023, %v2022 (stack46)
        %v2025 = vxor.u32 %v2024, %v2020 (stack47)
        %v2028 = vadd.s32 %v2025, %v2020 (stack39)
        %v2030 = vshll.u32 %v2025, 26 (stack44)
        %v2031 = vshrl.u32 %v2025, 6 (stack45)
        %v2032 = vor.u32 %v2031, %v2030 (stack46)
        %v2033 = vxor.u32 %v2032, %v2028 (stack47)
        %v2036 = vadd.s32 %v2033, %v2028 (stack39)
        %v2040 = vadd.s32 %v2036, %v10 (stack39)
        %v2042 = vshll.u32 %v2033, 6 (stack44)
        %v2043 = vshrl.u32 %v2033, 26 (stack45)
        %v2044 = vor.u32 %v2043, %v2042 (stack46)
        %v2045 = vxor.u32 %v2044, %v2036 (stack47)
        %v2048 = vadd.s32 %v2045, %v9 (stack39)
        %v2052 = vadd.s32 3, %v2048 (stack39)
        %v2056 = vadd.s32 %v2052, %v2040 (stack39)
        %v2058 = vshll.u32 %v2052, 17 (stack44)
        %v2059 = vshrl.u32 %v2052, 15 (stack45)
        %v2060 = vor.u32 %v2059, %v2058 (stack46)
        %v2061 = vxor.u32 %v2060, %v2056 (stack47)
        %v2064 = vadd.s32 %v2061, %v2056 (stack39)
        %v2066 = vshll.u32 %v2061, 29 (stack44)
        %v2067 = vshrl.u32 %v2061, 3 (stack45)
        %v2068 = vor.u32 %v2067, %v2066 (stack46)
        %v2069 = vxor.u32 %v2068, %v2064 (stack47)
        %v2072 = vadd.s32 %v2069, %v2064 (stack39)
        %v2074 = vshll.u32 %v2069, 16 (stack44)
        %v2075 = vshrl.u32 %v2069, 16 (stack45)
        %v2076 = vor.u32 %v2075, %v2074 (stack46)
        %v2077 = vxor.u32 %v2076, %v2072 (stack47)
        %v2080 = vadd.s32 %v2077, %v2072 (stack39)
        %v2084 = vadd.s32 %v2080, %v9 (stack39)
        %v2086 = vshll.u32 %v2077, 24 (stack44)
        %v2087 = vshrl.u32 %v2077, 8 (stack45)
        %v2088 = vor.u32 %v2087, %v2086 (stack46)
        %v2089 = vxor.u32 %v2088, %v2080 (stack47)
        %v2092 = vadd.s32 %v2089, %v8 (stack39)
        %v2096 = vadd.s32 4, %v2092 (stack39)
        %v2100 = vadd.s32 %v2096, %v2084 (stack39)
        %v2102 = vshll.u32 %v2096, 13 (stack44)
        %v2103 = vshrl.u32 %v2096, 19 (stack45)
        %v2104 = vor.u32 %v2103, %v2102 (stack46)
        %v2105 = vxor.u32 %v2104, %v2100 (stack47)
        %v2108 = vadd.s32 %v2105, %v2100 (stack39)
        %v2110 = vshll.u32 %v2105, 15 (stack44)
        %v2111 = vshrl.u32 %v2105, 17 (stack45)
        %v2112 = vor.u32 %v2111, %v2110 (stack46)
        %v2113 = vxor.u32 %v2112, %v2108 (stack47)
        %v2116 = vadd.s32 %v2113, %v2108 (stack39)
        %v2118 = vshll.u32 %v2113, 26 (stack44)
        %v2119 = vshrl.u32 %v2113, 6 (stack45)
        %v2120 = vor.u32 %v2119, %v2118 (stack46)
        %v2121 = vxor.u32 %v2120, %v2116 (stack47)
        %v2124 = vadd.s32 %v2121, %v2116 (stack39)
        %v2128 = vadd.s32 %v2124, %v8 (stack39)
        %v2130 = vshll.u32 %v2121, 6 (stack44)
        %v2131 = vshrl.u32 %v2121, 26 (stack45)
        %v2132 = vor.u32 %v2131, %v2130 (stack46)
        %v2133 = vxor.u32 %v2132, %v2124 (stack47)
        %v2136 = vadd.s32 %v2133, %v10 (stack39)
        %v2140 = vadd.s32 5, %v2136 (stack39)
        %v2142 = vxor.u32 %v2140, %v2128 (stack47)
        %v2143 = vand.u32.u8 255, %v2142 (stack48)
        %v2144 = vand.u32 65535, %v2143 (stack49)
        %v2145 = vshrl.u32 %v2144, 1 (stack50)
        %v2146 = vor.u32 16256, %v2145 (stack46)
        %v2147 = vand.u32.u16 65535, %v2146 (stack51)
        %v119754 = vadd.low.f32.bf16 -1.0, %v2147 (stack52)
        %v2156 = vmul.f32 2.0, %v119754 (stack53)
        %v2160 = vadd.f32 -0.99609375, %v2156 (stack52)
        %v2164 = vmax.f32 %v2160, -0.99609375 (stack54)
        %v2166 = vand.u32 2147483647, %v2164 (stack55)
        %vm2169 = vcmp.eq.f32.partialorder %v2166, 1.0 (stack56)
        %v2174 = vmul.f32 inf, %v2164 (stack53)
        %v2176 = vxor.u32 2147483648, %v2164 (stack57)
        %v2179 = vmul.f32 %v2176, %v2164 (stack53)
        %v2181 = vadd.f32 1.0, %v2179 (stack58)
        %v2182 = vlog2.pop %v2181 (stack59)
        %v2183 = vmul.f32 0.6931472, %v2182 (stack60)
        %v2184 = vmul.f32 -0.5, %v2179 (stack61)
        %v2185 = vadd.f32 1.0, %v2184 (stack62)
        %v2186 = vmul.f32 %v2185, %v2179 (stack63)
        %v2187 = vand.u32 2147483647, %v2179 (stack64)
        %vm2188 = vcmp.lt.f32.partialorder %v2187, 0.0004427343 (stack65)
        %v2189 = vsel /*vm=*/%vm2188, /*on_true_vy=*/%v2186, /*on_false_vx=*/%v2183 (stack66)
        %v2190 = vxor.u32 2147483648, %v2189 (stack57)
        %vm2193 = vcmp.lt.f32.partialorder %v2190, 5.0 (stack56)
        %v2198 = vsel /*vm=*/%vm2193, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v2202 = vsel /*vm=*/%vm2193, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v2206 = vsel /*vm=*/%vm2193, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v2210 = vsel /*vm=*/%vm2193, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v2214 = vsel /*vm=*/%vm2193, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v2218 = vsel /*vm=*/%vm2193, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v2222 = vsel /*vm=*/%vm2193, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v2226 = vsel /*vm=*/%vm2193, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v2230 = vsel /*vm=*/%vm2193, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v2234 = vadd.f32 -2.5, %v2190 (stack52)
        %v2236 = vrsqrt.pop %v2190 (stack67)
        %v2237 = vmul.f32 %v2236, %v2190 (stack68)
        %vm2238 = vcmp.eq.f32.partialorder %v2190, inf (stack69)
        %v2239 = vsel /*vm=*/%vm2238, /*on_true_vy=*/%v2190, /*on_false_vx=*/%v2237 (stack70)
        %vm2240 = vcmp.eq.f32.partialorder %v2190, 0.0 (stack71)
        %v2241 = vand.u32 2147483648, %v2190 (stack72)
        %v2242 = vsel /*vm=*/%vm2240, /*on_true_vy=*/%v2241, /*on_false_vx=*/%v2239 (stack73)
        %v2245 = vadd.f32 -3.0, %v2242 (stack52)
        %v2249 = vsel /*vm=*/%vm2193, /*on_true_vy=*/%v2234, /*on_false_vx=*/%v2245 (stack43)
        %v2253 = vmul.f32 %v2249, %v2230 (stack53)
        %v2257 = vadd.f32 %v2253, %v2226 (stack52)
        %v2261 = vmul.f32 %v2257, %v2249 (stack53)
        %v2265 = vadd.f32 %v2261, %v2222 (stack52)
        %v2269 = vmul.f32 %v2265, %v2249 (stack53)
        %v2273 = vadd.f32 %v2269, %v2218 (stack52)
        %v2277 = vmul.f32 %v2273, %v2249 (stack53)
        %v2281 = vadd.f32 %v2277, %v2214 (stack52)
        %v2285 = vmul.f32 %v2281, %v2249 (stack53)
        %v2289 = vadd.f32 %v2285, %v2210 (stack52)
        %v2293 = vmul.f32 %v2289, %v2249 (stack53)
        %v2297 = vadd.f32 %v2293, %v2206 (stack52)
        %v2301 = vmul.f32 %v2297, %v2249 (stack53)
        %v2305 = vadd.f32 %v2301, %v2202 (stack52)
        %v2309 = vmul.f32 %v2305, %v2249 (stack53)
        %v2313 = vadd.f32 %v2309, %v2198 (stack52)
        %v2317 = vmul.f32 %v2313, %v2164 (stack53)
        %v2321 = vsel /*vm=*/%vm2169, /*on_true_vy=*/%v2174, /*on_false_vx=*/%v2317 (stack43)
        %v2325 = vmul.f32 1.4140625, %v2321 (stack53)
        %v2328 = vpack.c.bf16 0.0, %v2325 (stack74)
        %119755 = vst [vmem:[%s280 + $0x180] sm:$0xf] /*vst_source=*/%v2328 (stack75)
        %v2340 = vld [vmem:[%s4] ss:$0 sm:$0xff] (stack32)
        %2341 = vbcast.lane.b32.xlu0 %v2340, 4 (stack37)
        %v2342 = vpop.permute.xlu0 %2341 (stack38)
        %v2353 = vld [vmem:[%s6] ss:$0 sm:$0xff] (stack32)
        %2354 = vbcast.lane.b32.xlu0 %v2353, 4 (stack37)
        %v2355 = vpop.permute.xlu0 %2354 (stack38)
        %v2358 = vadd.s32 %v2355, %v396 (stack39)
        %v2368 = vadd.s32 %v2358, %v415 (stack39)
        %vm2372 = vcmp.lt.u32.totalorder %v2368, %v2358 (stack42)
        %vm2377 = vcmp.lt.u32.totalorder %v2358, %v2355 (stack42)
        %v2382 = vadd.s32 %v2342, %v368 (stack39)
        %v2386 = vadd.s32 1, %v2382 (stack39)
        %v2390 = vsel /*vm=*/%vm2377, /*on_true_vy=*/%v2386, /*on_false_vx=*/%v2382 (stack43)
        %v2394 = vadd.s32 1, %v2390 (stack39)
        %v2398 = vsel /*vm=*/%vm2372, /*on_true_vy=*/%v2394, /*on_false_vx=*/%v2390 (stack43)
        %v2403 = vadd.s32 %v2398, %v10 (stack39)
        %v2407 = vadd.s32 %v2368, %v9 (stack39)
        %v2411 = vadd.s32 %v2407, %v2403 (stack39)
        %v2413 = vshll.u32 %v2407, 13 (stack44)
        %v2414 = vshrl.u32 %v2407, 19 (stack45)
        %v2415 = vor.u32 %v2414, %v2413 (stack46)
        %v2416 = vxor.u32 %v2415, %v2411 (stack47)
        %v2419 = vadd.s32 %v2416, %v2411 (stack39)
        %v2421 = vshll.u32 %v2416, 15 (stack44)
        %v2422 = vshrl.u32 %v2416, 17 (stack45)
        %v2423 = vor.u32 %v2422, %v2421 (stack46)
        %v2424 = vxor.u32 %v2423, %v2419 (stack47)
        %v2427 = vadd.s32 %v2424, %v2419 (stack39)
        %v2429 = vshll.u32 %v2424, 26 (stack44)
        %v2430 = vshrl.u32 %v2424, 6 (stack45)
        %v2431 = vor.u32 %v2430, %v2429 (stack46)
        %v2432 = vxor.u32 %v2431, %v2427 (stack47)
        %v2435 = vadd.s32 %v2432, %v2427 (stack39)
        %v2439 = vadd.s32 %v2435, %v9 (stack39)
        %v2441 = vshll.u32 %v2432, 6 (stack44)
        %v2442 = vshrl.u32 %v2432, 26 (stack45)
        %v2443 = vor.u32 %v2442, %v2441 (stack46)
        %v2444 = vxor.u32 %v2443, %v2435 (stack47)
        %v2447 = vadd.s32 %v2444, %v8 (stack39)
        %v2451 = vadd.s32 1, %v2447 (stack39)
        %v2455 = vadd.s32 %v2451, %v2439 (stack39)
        %v2457 = vshll.u32 %v2451, 17 (stack44)
        %v2458 = vshrl.u32 %v2451, 15 (stack45)
        %v2459 = vor.u32 %v2458, %v2457 (stack46)
        %v2460 = vxor.u32 %v2459, %v2455 (stack47)
        %v2463 = vadd.s32 %v2460, %v2455 (stack39)
        %v2465 = vshll.u32 %v2460, 29 (stack44)
        %v2466 = vshrl.u32 %v2460, 3 (stack45)
        %v2467 = vor.u32 %v2466, %v2465 (stack46)
        %v2468 = vxor.u32 %v2467, %v2463 (stack47)
        %v2471 = vadd.s32 %v2468, %v2463 (stack39)
        %v2473 = vshll.u32 %v2468, 16 (stack44)
        %v2474 = vshrl.u32 %v2468, 16 (stack45)
        %v2475 = vor.u32 %v2474, %v2473 (stack46)
        %v2476 = vxor.u32 %v2475, %v2471 (stack47)
        %v2479 = vadd.s32 %v2476, %v2471 (stack39)
        %v2483 = vadd.s32 %v2479, %v8 (stack39)
        %v2485 = vshll.u32 %v2476, 24 (stack44)
        %v2486 = vshrl.u32 %v2476, 8 (stack45)
        %v2487 = vor.u32 %v2486, %v2485 (stack46)
        %v2488 = vxor.u32 %v2487, %v2479 (stack47)
        %v2491 = vadd.s32 %v2488, %v10 (stack39)
        %v2495 = vadd.s32 2, %v2491 (stack39)
        %v2499 = vadd.s32 %v2495, %v2483 (stack39)
        %v2501 = vshll.u32 %v2495, 13 (stack44)
        %v2502 = vshrl.u32 %v2495, 19 (stack45)
        %v2503 = vor.u32 %v2502, %v2501 (stack46)
        %v2504 = vxor.u32 %v2503, %v2499 (stack47)
        %v2507 = vadd.s32 %v2504, %v2499 (stack39)
        %v2509 = vshll.u32 %v2504, 15 (stack44)
        %v2510 = vshrl.u32 %v2504, 17 (stack45)
        %v2511 = vor.u32 %v2510, %v2509 (stack46)
        %v2512 = vxor.u32 %v2511, %v2507 (stack47)
        %v2515 = vadd.s32 %v2512, %v2507 (stack39)
        %v2517 = vshll.u32 %v2512, 26 (stack44)
        %v2518 = vshrl.u32 %v2512, 6 (stack45)
        %v2519 = vor.u32 %v2518, %v2517 (stack46)
        %v2520 = vxor.u32 %v2519, %v2515 (stack47)
        %v2523 = vadd.s32 %v2520, %v2515 (stack39)
        %v2527 = vadd.s32 %v2523, %v10 (stack39)
        %v2529 = vshll.u32 %v2520, 6 (stack44)
        %v2530 = vshrl.u32 %v2520, 26 (stack45)
        %v2531 = vor.u32 %v2530, %v2529 (stack46)
        %v2532 = vxor.u32 %v2531, %v2523 (stack47)
        %v2535 = vadd.s32 %v2532, %v9 (stack39)
        %v2539 = vadd.s32 3, %v2535 (stack39)
        %v2543 = vadd.s32 %v2539, %v2527 (stack39)
        %v2545 = vshll.u32 %v2539, 17 (stack44)
        %v2546 = vshrl.u32 %v2539, 15 (stack45)
        %v2547 = vor.u32 %v2546, %v2545 (stack46)
        %v2548 = vxor.u32 %v2547, %v2543 (stack47)
        %v2551 = vadd.s32 %v2548, %v2543 (stack39)
        %v2553 = vshll.u32 %v2548, 29 (stack44)
        %v2554 = vshrl.u32 %v2548, 3 (stack45)
        %v2555 = vor.u32 %v2554, %v2553 (stack46)
        %v2556 = vxor.u32 %v2555, %v2551 (stack47)
        %v2559 = vadd.s32 %v2556, %v2551 (stack39)
        %v2561 = vshll.u32 %v2556, 16 (stack44)
        %v2562 = vshrl.u32 %v2556, 16 (stack45)
        %v2563 = vor.u32 %v2562, %v2561 (stack46)
        %v2564 = vxor.u32 %v2563, %v2559 (stack47)
        %v2567 = vadd.s32 %v2564, %v2559 (stack39)
        %v2571 = vadd.s32 %v2567, %v9 (stack39)
        %v2573 = vshll.u32 %v2564, 24 (stack44)
        %v2574 = vshrl.u32 %v2564, 8 (stack45)
        %v2575 = vor.u32 %v2574, %v2573 (stack46)
        %v2576 = vxor.u32 %v2575, %v2567 (stack47)
        %v2579 = vadd.s32 %v2576, %v8 (stack39)
        %v2583 = vadd.s32 4, %v2579 (stack39)
        %v2587 = vadd.s32 %v2583, %v2571 (stack39)
        %v2589 = vshll.u32 %v2583, 13 (stack44)
        %v2590 = vshrl.u32 %v2583, 19 (stack45)
        %v2591 = vor.u32 %v2590, %v2589 (stack46)
        %v2592 = vxor.u32 %v2591, %v2587 (stack47)
        %v2595 = vadd.s32 %v2592, %v2587 (stack39)
        %v2597 = vshll.u32 %v2592, 15 (stack44)
        %v2598 = vshrl.u32 %v2592, 17 (stack45)
        %v2599 = vor.u32 %v2598, %v2597 (stack46)
        %v2600 = vxor.u32 %v2599, %v2595 (stack47)
        %v2603 = vadd.s32 %v2600, %v2595 (stack39)
        %v2605 = vshll.u32 %v2600, 26 (stack44)
        %v2606 = vshrl.u32 %v2600, 6 (stack45)
        %v2607 = vor.u32 %v2606, %v2605 (stack46)
        %v2608 = vxor.u32 %v2607, %v2603 (stack47)
        %v2611 = vadd.s32 %v2608, %v2603 (stack39)
        %v2615 = vadd.s32 %v2611, %v8 (stack39)
        %v2617 = vshll.u32 %v2608, 6 (stack44)
        %v2618 = vshrl.u32 %v2608, 26 (stack45)
        %v2619 = vor.u32 %v2618, %v2617 (stack46)
        %v2620 = vxor.u32 %v2619, %v2611 (stack47)
        %v2623 = vadd.s32 %v2620, %v10 (stack39)
        %v2627 = vadd.s32 5, %v2623 (stack39)
        %v2629 = vxor.u32 %v2627, %v2615 (stack47)
        %v2630 = vand.u32.u8 255, %v2629 (stack48)
        %v2631 = vand.u32 65535, %v2630 (stack49)
        %v2632 = vshrl.u32 %v2631, 1 (stack50)
        %v2633 = vor.u32 16256, %v2632 (stack46)
        %v2634 = vand.u32.u16 65535, %v2633 (stack51)
        %v119756 = vadd.low.f32.bf16 -1.0, %v2634 (stack52)
        %v2643 = vmul.f32 2.0, %v119756 (stack53)
        %v2647 = vadd.f32 -0.99609375, %v2643 (stack52)
        %v2651 = vmax.f32 %v2647, -0.99609375 (stack54)
        %v2653 = vand.u32 2147483647, %v2651 (stack55)
        %vm2656 = vcmp.eq.f32.partialorder %v2653, 1.0 (stack56)
        %v2661 = vmul.f32 inf, %v2651 (stack53)
        %v2663 = vxor.u32 2147483648, %v2651 (stack57)
        %v2666 = vmul.f32 %v2663, %v2651 (stack53)
        %v2668 = vadd.f32 1.0, %v2666 (stack58)
        %v2669 = vlog2.pop %v2668 (stack59)
        %v2670 = vmul.f32 0.6931472, %v2669 (stack60)
        %v2671 = vmul.f32 -0.5, %v2666 (stack61)
        %v2672 = vadd.f32 1.0, %v2671 (stack62)
        %v2673 = vmul.f32 %v2672, %v2666 (stack63)
        %v2674 = vand.u32 2147483647, %v2666 (stack64)
        %vm2675 = vcmp.lt.f32.partialorder %v2674, 0.0004427343 (stack65)
        %v2676 = vsel /*vm=*/%vm2675, /*on_true_vy=*/%v2673, /*on_false_vx=*/%v2670 (stack66)
        %v2677 = vxor.u32 2147483648, %v2676 (stack57)
        %vm2680 = vcmp.lt.f32.partialorder %v2677, 5.0 (stack56)
        %v2685 = vsel /*vm=*/%vm2680, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v2689 = vsel /*vm=*/%vm2680, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v2693 = vsel /*vm=*/%vm2680, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v2697 = vsel /*vm=*/%vm2680, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v2701 = vsel /*vm=*/%vm2680, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v2705 = vsel /*vm=*/%vm2680, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v2709 = vsel /*vm=*/%vm2680, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v2713 = vsel /*vm=*/%vm2680, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v2717 = vsel /*vm=*/%vm2680, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v2721 = vadd.f32 -2.5, %v2677 (stack52)
        %v2723 = vrsqrt.pop %v2677 (stack67)
        %v2724 = vmul.f32 %v2723, %v2677 (stack68)
        %vm2725 = vcmp.eq.f32.partialorder %v2677, inf (stack69)
        %v2726 = vsel /*vm=*/%vm2725, /*on_true_vy=*/%v2677, /*on_false_vx=*/%v2724 (stack70)
        %vm2727 = vcmp.eq.f32.partialorder %v2677, 0.0 (stack71)
        %v2728 = vand.u32 2147483648, %v2677 (stack72)
        %v2729 = vsel /*vm=*/%vm2727, /*on_true_vy=*/%v2728, /*on_false_vx=*/%v2726 (stack73)
        %v2732 = vadd.f32 -3.0, %v2729 (stack52)
        %v2736 = vsel /*vm=*/%vm2680, /*on_true_vy=*/%v2721, /*on_false_vx=*/%v2732 (stack43)
        %v2740 = vmul.f32 %v2736, %v2717 (stack53)
        %v2744 = vadd.f32 %v2740, %v2713 (stack52)
        %v2748 = vmul.f32 %v2744, %v2736 (stack53)
        %v2752 = vadd.f32 %v2748, %v2709 (stack52)
        %v2756 = vmul.f32 %v2752, %v2736 (stack53)
        %v2760 = vadd.f32 %v2756, %v2705 (stack52)
        %v2764 = vmul.f32 %v2760, %v2736 (stack53)
        %v2768 = vadd.f32 %v2764, %v2701 (stack52)
        %v2772 = vmul.f32 %v2768, %v2736 (stack53)
        %v2776 = vadd.f32 %v2772, %v2697 (stack52)
        %v2780 = vmul.f32 %v2776, %v2736 (stack53)
        %v2784 = vadd.f32 %v2780, %v2693 (stack52)
        %v2788 = vmul.f32 %v2784, %v2736 (stack53)
        %v2792 = vadd.f32 %v2788, %v2689 (stack52)
        %v2796 = vmul.f32 %v2792, %v2736 (stack53)
        %v2800 = vadd.f32 %v2796, %v2685 (stack52)
        %v2804 = vmul.f32 %v2800, %v2651 (stack53)
        %v2808 = vsel /*vm=*/%vm2656, /*on_true_vy=*/%v2661, /*on_false_vx=*/%v2804 (stack43)
        %v2812 = vmul.f32 1.4140625, %v2808 (stack53)
        %v2815 = vpack.c.bf16 0.0, %v2812 (stack74)
        %119757 = vst [vmem:[%s280 + $0x200] sm:$0xf] /*vst_source=*/%v2815 (stack75)
        %v2827 = vld [vmem:[%s4] ss:$0 sm:$0xff] (stack32)
        %2828 = vbcast.lane.b32.xlu0 %v2827, 5 (stack37)
        %v2829 = vpop.permute.xlu0 %2828 (stack38)
        %v2840 = vld [vmem:[%s6] ss:$0 sm:$0xff] (stack32)
        %2841 = vbcast.lane.b32.xlu0 %v2840, 5 (stack37)
        %v2842 = vpop.permute.xlu0 %2841 (stack38)
        %v2845 = vadd.s32 %v2842, %v396 (stack39)
        %v2855 = vadd.s32 %v2845, %v415 (stack39)
        %vm2859 = vcmp.lt.u32.totalorder %v2855, %v2845 (stack42)
        %vm2864 = vcmp.lt.u32.totalorder %v2845, %v2842 (stack42)
        %v2869 = vadd.s32 %v2829, %v368 (stack39)
        %v2873 = vadd.s32 1, %v2869 (stack39)
        %v2877 = vsel /*vm=*/%vm2864, /*on_true_vy=*/%v2873, /*on_false_vx=*/%v2869 (stack43)
        %v2881 = vadd.s32 1, %v2877 (stack39)
        %v2885 = vsel /*vm=*/%vm2859, /*on_true_vy=*/%v2881, /*on_false_vx=*/%v2877 (stack43)
        %v2890 = vadd.s32 %v2885, %v10 (stack39)
        %v2894 = vadd.s32 %v2855, %v9 (stack39)
        %v2898 = vadd.s32 %v2894, %v2890 (stack39)
        %v2900 = vshll.u32 %v2894, 13 (stack44)
        %v2901 = vshrl.u32 %v2894, 19 (stack45)
        %v2902 = vor.u32 %v2901, %v2900 (stack46)
        %v2903 = vxor.u32 %v2902, %v2898 (stack47)
        %v2906 = vadd.s32 %v2903, %v2898 (stack39)
        %v2908 = vshll.u32 %v2903, 15 (stack44)
        %v2909 = vshrl.u32 %v2903, 17 (stack45)
        %v2910 = vor.u32 %v2909, %v2908 (stack46)
        %v2911 = vxor.u32 %v2910, %v2906 (stack47)
        %v2914 = vadd.s32 %v2911, %v2906 (stack39)
        %v2916 = vshll.u32 %v2911, 26 (stack44)
        %v2917 = vshrl.u32 %v2911, 6 (stack45)
        %v2918 = vor.u32 %v2917, %v2916 (stack46)
        %v2919 = vxor.u32 %v2918, %v2914 (stack47)
        %v2922 = vadd.s32 %v2919, %v2914 (stack39)
        %v2926 = vadd.s32 %v2922, %v9 (stack39)
        %v2928 = vshll.u32 %v2919, 6 (stack44)
        %v2929 = vshrl.u32 %v2919, 26 (stack45)
        %v2930 = vor.u32 %v2929, %v2928 (stack46)
        %v2931 = vxor.u32 %v2930, %v2922 (stack47)
        %v2934 = vadd.s32 %v2931, %v8 (stack39)
        %v2938 = vadd.s32 1, %v2934 (stack39)
        %v2942 = vadd.s32 %v2938, %v2926 (stack39)
        %v2944 = vshll.u32 %v2938, 17 (stack44)
        %v2945 = vshrl.u32 %v2938, 15 (stack45)
        %v2946 = vor.u32 %v2945, %v2944 (stack46)
        %v2947 = vxor.u32 %v2946, %v2942 (stack47)
        %v2950 = vadd.s32 %v2947, %v2942 (stack39)
        %v2952 = vshll.u32 %v2947, 29 (stack44)
        %v2953 = vshrl.u32 %v2947, 3 (stack45)
        %v2954 = vor.u32 %v2953, %v2952 (stack46)
        %v2955 = vxor.u32 %v2954, %v2950 (stack47)
        %v2958 = vadd.s32 %v2955, %v2950 (stack39)
        %v2960 = vshll.u32 %v2955, 16 (stack44)
        %v2961 = vshrl.u32 %v2955, 16 (stack45)
        %v2962 = vor.u32 %v2961, %v2960 (stack46)
        %v2963 = vxor.u32 %v2962, %v2958 (stack47)
        %v2966 = vadd.s32 %v2963, %v2958 (stack39)
        %v2970 = vadd.s32 %v2966, %v8 (stack39)
        %v2972 = vshll.u32 %v2963, 24 (stack44)
        %v2973 = vshrl.u32 %v2963, 8 (stack45)
        %v2974 = vor.u32 %v2973, %v2972 (stack46)
        %v2975 = vxor.u32 %v2974, %v2966 (stack47)
        %v2978 = vadd.s32 %v2975, %v10 (stack39)
        %v2982 = vadd.s32 2, %v2978 (stack39)
        %v2986 = vadd.s32 %v2982, %v2970 (stack39)
        %v2988 = vshll.u32 %v2982, 13 (stack44)
        %v2989 = vshrl.u32 %v2982, 19 (stack45)
        %v2990 = vor.u32 %v2989, %v2988 (stack46)
        %v2991 = vxor.u32 %v2990, %v2986 (stack47)
        %v2994 = vadd.s32 %v2991, %v2986 (stack39)
        %v2996 = vshll.u32 %v2991, 15 (stack44)
        %v2997 = vshrl.u32 %v2991, 17 (stack45)
        %v2998 = vor.u32 %v2997, %v2996 (stack46)
        %v2999 = vxor.u32 %v2998, %v2994 (stack47)
        %v3002 = vadd.s32 %v2999, %v2994 (stack39)
        %v3004 = vshll.u32 %v2999, 26 (stack44)
        %v3005 = vshrl.u32 %v2999, 6 (stack45)
        %v3006 = vor.u32 %v3005, %v3004 (stack46)
        %v3007 = vxor.u32 %v3006, %v3002 (stack47)
        %v3010 = vadd.s32 %v3007, %v3002 (stack39)
        %v3014 = vadd.s32 %v3010, %v10 (stack39)
        %v3016 = vshll.u32 %v3007, 6 (stack44)
        %v3017 = vshrl.u32 %v3007, 26 (stack45)
        %v3018 = vor.u32 %v3017, %v3016 (stack46)
        %v3019 = vxor.u32 %v3018, %v3010 (stack47)
        %v3022 = vadd.s32 %v3019, %v9 (stack39)
        %v3026 = vadd.s32 3, %v3022 (stack39)
        %v3030 = vadd.s32 %v3026, %v3014 (stack39)
        %v3032 = vshll.u32 %v3026, 17 (stack44)
        %v3033 = vshrl.u32 %v3026, 15 (stack45)
        %v3034 = vor.u32 %v3033, %v3032 (stack46)
        %v3035 = vxor.u32 %v3034, %v3030 (stack47)
        %v3038 = vadd.s32 %v3035, %v3030 (stack39)
        %v3040 = vshll.u32 %v3035, 29 (stack44)
        %v3041 = vshrl.u32 %v3035, 3 (stack45)
        %v3042 = vor.u32 %v3041, %v3040 (stack46)
        %v3043 = vxor.u32 %v3042, %v3038 (stack47)
        %v3046 = vadd.s32 %v3043, %v3038 (stack39)
        %v3048 = vshll.u32 %v3043, 16 (stack44)
        %v3049 = vshrl.u32 %v3043, 16 (stack45)
        %v3050 = vor.u32 %v3049, %v3048 (stack46)
        %v3051 = vxor.u32 %v3050, %v3046 (stack47)
        %v3054 = vadd.s32 %v3051, %v3046 (stack39)
        %v3058 = vadd.s32 %v3054, %v9 (stack39)
        %v3060 = vshll.u32 %v3051, 24 (stack44)
        %v3061 = vshrl.u32 %v3051, 8 (stack45)
        %v3062 = vor.u32 %v3061, %v3060 (stack46)
        %v3063 = vxor.u32 %v3062, %v3054 (stack47)
        %v3066 = vadd.s32 %v3063, %v8 (stack39)
        %v3070 = vadd.s32 4, %v3066 (stack39)
        %v3074 = vadd.s32 %v3070, %v3058 (stack39)
        %v3076 = vshll.u32 %v3070, 13 (stack44)
        %v3077 = vshrl.u32 %v3070, 19 (stack45)
        %v3078 = vor.u32 %v3077, %v3076 (stack46)
        %v3079 = vxor.u32 %v3078, %v3074 (stack47)
        %v3082 = vadd.s32 %v3079, %v3074 (stack39)
        %v3084 = vshll.u32 %v3079, 15 (stack44)
        %v3085 = vshrl.u32 %v3079, 17 (stack45)
        %v3086 = vor.u32 %v3085, %v3084 (stack46)
        %v3087 = vxor.u32 %v3086, %v3082 (stack47)
        %v3090 = vadd.s32 %v3087, %v3082 (stack39)
        %v3092 = vshll.u32 %v3087, 26 (stack44)
        %v3093 = vshrl.u32 %v3087, 6 (stack45)
        %v3094 = vor.u32 %v3093, %v3092 (stack46)
        %v3095 = vxor.u32 %v3094, %v3090 (stack47)
        %v3098 = vadd.s32 %v3095, %v3090 (stack39)
        %v3102 = vadd.s32 %v3098, %v8 (stack39)
        %v3104 = vshll.u32 %v3095, 6 (stack44)
        %v3105 = vshrl.u32 %v3095, 26 (stack45)
        %v3106 = vor.u32 %v3105, %v3104 (stack46)
        %v3107 = vxor.u32 %v3106, %v3098 (stack47)
        %v3110 = vadd.s32 %v3107, %v10 (stack39)
        %v3114 = vadd.s32 5, %v3110 (stack39)
        %v3116 = vxor.u32 %v3114, %v3102 (stack47)
        %v3117 = vand.u32.u8 255, %v3116 (stack48)
        %v3118 = vand.u32 65535, %v3117 (stack49)
        %v3119 = vshrl.u32 %v3118, 1 (stack50)
        %v3120 = vor.u32 16256, %v3119 (stack46)
        %v3121 = vand.u32.u16 65535, %v3120 (stack51)
        %v119758 = vadd.low.f32.bf16 -1.0, %v3121 (stack52)
        %v3130 = vmul.f32 2.0, %v119758 (stack53)
        %v3134 = vadd.f32 -0.99609375, %v3130 (stack52)
        %v3138 = vmax.f32 %v3134, -0.99609375 (stack54)
        %v3140 = vand.u32 2147483647, %v3138 (stack55)
        %vm3143 = vcmp.eq.f32.partialorder %v3140, 1.0 (stack56)
        %v3148 = vmul.f32 inf, %v3138 (stack53)
        %v3150 = vxor.u32 2147483648, %v3138 (stack57)
        %v3153 = vmul.f32 %v3150, %v3138 (stack53)
        %v3155 = vadd.f32 1.0, %v3153 (stack58)
        %v3156 = vlog2.pop %v3155 (stack59)
        %v3157 = vmul.f32 0.6931472, %v3156 (stack60)
        %v3158 = vmul.f32 -0.5, %v3153 (stack61)
        %v3159 = vadd.f32 1.0, %v3158 (stack62)
        %v3160 = vmul.f32 %v3159, %v3153 (stack63)
        %v3161 = vand.u32 2147483647, %v3153 (stack64)
        %vm3162 = vcmp.lt.f32.partialorder %v3161, 0.0004427343 (stack65)
        %v3163 = vsel /*vm=*/%vm3162, /*on_true_vy=*/%v3160, /*on_false_vx=*/%v3157 (stack66)
        %v3164 = vxor.u32 2147483648, %v3163 (stack57)
        %vm3167 = vcmp.lt.f32.partialorder %v3164, 5.0 (stack56)
        %v3172 = vsel /*vm=*/%vm3167, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v3176 = vsel /*vm=*/%vm3167, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v3180 = vsel /*vm=*/%vm3167, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v3184 = vsel /*vm=*/%vm3167, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v3188 = vsel /*vm=*/%vm3167, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v3192 = vsel /*vm=*/%vm3167, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v3196 = vsel /*vm=*/%vm3167, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v3200 = vsel /*vm=*/%vm3167, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v3204 = vsel /*vm=*/%vm3167, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v3208 = vadd.f32 -2.5, %v3164 (stack52)
        %v3210 = vrsqrt.pop %v3164 (stack67)
        %v3211 = vmul.f32 %v3210, %v3164 (stack68)
        %vm3212 = vcmp.eq.f32.partialorder %v3164, inf (stack69)
        %v3213 = vsel /*vm=*/%vm3212, /*on_true_vy=*/%v3164, /*on_false_vx=*/%v3211 (stack70)
        %vm3214 = vcmp.eq.f32.partialorder %v3164, 0.0 (stack71)
        %v3215 = vand.u32 2147483648, %v3164 (stack72)
        %v3216 = vsel /*vm=*/%vm3214, /*on_true_vy=*/%v3215, /*on_false_vx=*/%v3213 (stack73)
        %v3219 = vadd.f32 -3.0, %v3216 (stack52)
        %v3223 = vsel /*vm=*/%vm3167, /*on_true_vy=*/%v3208, /*on_false_vx=*/%v3219 (stack43)
        %v3227 = vmul.f32 %v3223, %v3204 (stack53)
        %v3231 = vadd.f32 %v3227, %v3200 (stack52)
        %v3235 = vmul.f32 %v3231, %v3223 (stack53)
        %v3239 = vadd.f32 %v3235, %v3196 (stack52)
        %v3243 = vmul.f32 %v3239, %v3223 (stack53)
        %v3247 = vadd.f32 %v3243, %v3192 (stack52)
        %v3251 = vmul.f32 %v3247, %v3223 (stack53)
        %v3255 = vadd.f32 %v3251, %v3188 (stack52)
        %v3259 = vmul.f32 %v3255, %v3223 (stack53)
        %v3263 = vadd.f32 %v3259, %v3184 (stack52)
        %v3267 = vmul.f32 %v3263, %v3223 (stack53)
        %v3271 = vadd.f32 %v3267, %v3180 (stack52)
        %v3275 = vmul.f32 %v3271, %v3223 (stack53)
        %v3279 = vadd.f32 %v3275, %v3176 (stack52)
        %v3283 = vmul.f32 %v3279, %v3223 (stack53)
        %v3287 = vadd.f32 %v3283, %v3172 (stack52)
        %v3291 = vmul.f32 %v3287, %v3138 (stack53)
        %v3295 = vsel /*vm=*/%vm3143, /*on_true_vy=*/%v3148, /*on_false_vx=*/%v3291 (stack43)
        %v3299 = vmul.f32 1.4140625, %v3295 (stack53)
        %v3302 = vpack.c.bf16 0.0, %v3299 (stack74)
        %119759 = vst [vmem:[%s280 + $0x280] sm:$0xf] /*vst_source=*/%v3302 (stack75)
        %v3314 = vld [vmem:[%s4] ss:$0 sm:$0xff] (stack32)
        %3315 = vbcast.lane.b32.xlu0 %v3314, 6 (stack37)
        %v3316 = vpop.permute.xlu0 %3315 (stack38)
        %v3327 = vld [vmem:[%s6] ss:$0 sm:$0xff] (stack32)
        %3328 = vbcast.lane.b32.xlu0 %v3327, 6 (stack37)
        %v3329 = vpop.permute.xlu0 %3328 (stack38)
        %v3332 = vadd.s32 %v3329, %v396 (stack39)
        %v3342 = vadd.s32 %v3332, %v415 (stack39)
        %vm3346 = vcmp.lt.u32.totalorder %v3342, %v3332 (stack42)
        %vm3351 = vcmp.lt.u32.totalorder %v3332, %v3329 (stack42)
        %v3356 = vadd.s32 %v3316, %v368 (stack39)
        %v3360 = vadd.s32 1, %v3356 (stack39)
        %v3364 = vsel /*vm=*/%vm3351, /*on_true_vy=*/%v3360, /*on_false_vx=*/%v3356 (stack43)
        %v3368 = vadd.s32 1, %v3364 (stack39)
        %v3372 = vsel /*vm=*/%vm3346, /*on_true_vy=*/%v3368, /*on_false_vx=*/%v3364 (stack43)
        %v3377 = vadd.s32 %v3372, %v10 (stack39)
        %v3381 = vadd.s32 %v3342, %v9 (stack39)
        %v3385 = vadd.s32 %v3381, %v3377 (stack39)
        %v3387 = vshll.u32 %v3381, 13 (stack44)
        %v3388 = vshrl.u32 %v3381, 19 (stack45)
        %v3389 = vor.u32 %v3388, %v3387 (stack46)
        %v3390 = vxor.u32 %v3389, %v3385 (stack47)
        %v3393 = vadd.s32 %v3390, %v3385 (stack39)
        %v3395 = vshll.u32 %v3390, 15 (stack44)
        %v3396 = vshrl.u32 %v3390, 17 (stack45)
        %v3397 = vor.u32 %v3396, %v3395 (stack46)
        %v3398 = vxor.u32 %v3397, %v3393 (stack47)
        %v3401 = vadd.s32 %v3398, %v3393 (stack39)
        %v3403 = vshll.u32 %v3398, 26 (stack44)
        %v3404 = vshrl.u32 %v3398, 6 (stack45)
        %v3405 = vor.u32 %v3404, %v3403 (stack46)
        %v3406 = vxor.u32 %v3405, %v3401 (stack47)
        %v3409 = vadd.s32 %v3406, %v3401 (stack39)
        %v3413 = vadd.s32 %v3409, %v9 (stack39)
        %v3415 = vshll.u32 %v3406, 6 (stack44)
        %v3416 = vshrl.u32 %v3406, 26 (stack45)
        %v3417 = vor.u32 %v3416, %v3415 (stack46)
        %v3418 = vxor.u32 %v3417, %v3409 (stack47)
        %v3421 = vadd.s32 %v3418, %v8 (stack39)
        %v3425 = vadd.s32 1, %v3421 (stack39)
        %v3429 = vadd.s32 %v3425, %v3413 (stack39)
        %v3431 = vshll.u32 %v3425, 17 (stack44)
        %v3432 = vshrl.u32 %v3425, 15 (stack45)
        %v3433 = vor.u32 %v3432, %v3431 (stack46)
        %v3434 = vxor.u32 %v3433, %v3429 (stack47)
        %v3437 = vadd.s32 %v3434, %v3429 (stack39)
        %v3439 = vshll.u32 %v3434, 29 (stack44)
        %v3440 = vshrl.u32 %v3434, 3 (stack45)
        %v3441 = vor.u32 %v3440, %v3439 (stack46)
        %v3442 = vxor.u32 %v3441, %v3437 (stack47)
        %v3445 = vadd.s32 %v3442, %v3437 (stack39)
        %v3447 = vshll.u32 %v3442, 16 (stack44)
        %v3448 = vshrl.u32 %v3442, 16 (stack45)
        %v3449 = vor.u32 %v3448, %v3447 (stack46)
        %v3450 = vxor.u32 %v3449, %v3445 (stack47)
        %v3453 = vadd.s32 %v3450, %v3445 (stack39)
        %v3457 = vadd.s32 %v3453, %v8 (stack39)
        %v3459 = vshll.u32 %v3450, 24 (stack44)
        %v3460 = vshrl.u32 %v3450, 8 (stack45)
        %v3461 = vor.u32 %v3460, %v3459 (stack46)
        %v3462 = vxor.u32 %v3461, %v3453 (stack47)
        %v3465 = vadd.s32 %v3462, %v10 (stack39)
        %v3469 = vadd.s32 2, %v3465 (stack39)
        %v3473 = vadd.s32 %v3469, %v3457 (stack39)
        %v3475 = vshll.u32 %v3469, 13 (stack44)
        %v3476 = vshrl.u32 %v3469, 19 (stack45)
        %v3477 = vor.u32 %v3476, %v3475 (stack46)
        %v3478 = vxor.u32 %v3477, %v3473 (stack47)
        %v3481 = vadd.s32 %v3478, %v3473 (stack39)
        %v3483 = vshll.u32 %v3478, 15 (stack44)
        %v3484 = vshrl.u32 %v3478, 17 (stack45)
        %v3485 = vor.u32 %v3484, %v3483 (stack46)
        %v3486 = vxor.u32 %v3485, %v3481 (stack47)
        %v3489 = vadd.s32 %v3486, %v3481 (stack39)
        %v3491 = vshll.u32 %v3486, 26 (stack44)
        %v3492 = vshrl.u32 %v3486, 6 (stack45)
        %v3493 = vor.u32 %v3492, %v3491 (stack46)
        %v3494 = vxor.u32 %v3493, %v3489 (stack47)
        %v3497 = vadd.s32 %v3494, %v3489 (stack39)
        %v3501 = vadd.s32 %v3497, %v10 (stack39)
        %v3503 = vshll.u32 %v3494, 6 (stack44)
        %v3504 = vshrl.u32 %v3494, 26 (stack45)
        %v3505 = vor.u32 %v3504, %v3503 (stack46)
        %v3506 = vxor.u32 %v3505, %v3497 (stack47)
        %v3509 = vadd.s32 %v3506, %v9 (stack39)
        %v3513 = vadd.s32 3, %v3509 (stack39)
        %v3517 = vadd.s32 %v3513, %v3501 (stack39)
        %v3519 = vshll.u32 %v3513, 17 (stack44)
        %v3520 = vshrl.u32 %v3513, 15 (stack45)
        %v3521 = vor.u32 %v3520, %v3519 (stack46)
        %v3522 = vxor.u32 %v3521, %v3517 (stack47)
        %v3525 = vadd.s32 %v3522, %v3517 (stack39)
        %v3527 = vshll.u32 %v3522, 29 (stack44)
        %v3528 = vshrl.u32 %v3522, 3 (stack45)
        %v3529 = vor.u32 %v3528, %v3527 (stack46)
        %v3530 = vxor.u32 %v3529, %v3525 (stack47)
        %v3533 = vadd.s32 %v3530, %v3525 (stack39)
        %v3535 = vshll.u32 %v3530, 16 (stack44)
        %v3536 = vshrl.u32 %v3530, 16 (stack45)
        %v3537 = vor.u32 %v3536, %v3535 (stack46)
        %v3538 = vxor.u32 %v3537, %v3533 (stack47)
        %v3541 = vadd.s32 %v3538, %v3533 (stack39)
        %v3545 = vadd.s32 %v3541, %v9 (stack39)
        %v3547 = vshll.u32 %v3538, 24 (stack44)
        %v3548 = vshrl.u32 %v3538, 8 (stack45)
        %v3549 = vor.u32 %v3548, %v3547 (stack46)
        %v3550 = vxor.u32 %v3549, %v3541 (stack47)
        %v3553 = vadd.s32 %v3550, %v8 (stack39)
        %v3557 = vadd.s32 4, %v3553 (stack39)
        %v3561 = vadd.s32 %v3557, %v3545 (stack39)
        %v3563 = vshll.u32 %v3557, 13 (stack44)
        %v3564 = vshrl.u32 %v3557, 19 (stack45)
        %v3565 = vor.u32 %v3564, %v3563 (stack46)
        %v3566 = vxor.u32 %v3565, %v3561 (stack47)
        %v3569 = vadd.s32 %v3566, %v3561 (stack39)
        %v3571 = vshll.u32 %v3566, 15 (stack44)
        %v3572 = vshrl.u32 %v3566, 17 (stack45)
        %v3573 = vor.u32 %v3572, %v3571 (stack46)
        %v3574 = vxor.u32 %v3573, %v3569 (stack47)
        %v3577 = vadd.s32 %v3574, %v3569 (stack39)
        %v3579 = vshll.u32 %v3574, 26 (stack44)
        %v3580 = vshrl.u32 %v3574, 6 (stack45)
        %v3581 = vor.u32 %v3580, %v3579 (stack46)
        %v3582 = vxor.u32 %v3581, %v3577 (stack47)
        %v3585 = vadd.s32 %v3582, %v3577 (stack39)
        %v3589 = vadd.s32 %v3585, %v8 (stack39)
        %v3591 = vshll.u32 %v3582, 6 (stack44)
        %v3592 = vshrl.u32 %v3582, 26 (stack45)
        %v3593 = vor.u32 %v3592, %v3591 (stack46)
        %v3594 = vxor.u32 %v3593, %v3585 (stack47)
        %v3597 = vadd.s32 %v3594, %v10 (stack39)
        %v3601 = vadd.s32 5, %v3597 (stack39)
        %v3603 = vxor.u32 %v3601, %v3589 (stack47)
        %v3604 = vand.u32.u8 255, %v3603 (stack48)
        %v3605 = vand.u32 65535, %v3604 (stack49)
        %v3606 = vshrl.u32 %v3605, 1 (stack50)
        %v3607 = vor.u32 16256, %v3606 (stack46)
        %v3608 = vand.u32.u16 65535, %v3607 (stack51)
        %v119760 = vadd.low.f32.bf16 -1.0, %v3608 (stack52)
        %v3617 = vmul.f32 2.0, %v119760 (stack53)
        %v3621 = vadd.f32 -0.99609375, %v3617 (stack52)
        %v3625 = vmax.f32 %v3621, -0.99609375 (stack54)
        %v3627 = vand.u32 2147483647, %v3625 (stack55)
        %vm3630 = vcmp.eq.f32.partialorder %v3627, 1.0 (stack56)
        %v3635 = vmul.f32 inf, %v3625 (stack53)
        %v3637 = vxor.u32 2147483648, %v3625 (stack57)
        %v3640 = vmul.f32 %v3637, %v3625 (stack53)
        %v3642 = vadd.f32 1.0, %v3640 (stack58)
        %v3643 = vlog2.pop %v3642 (stack59)
        %v3644 = vmul.f32 0.6931472, %v3643 (stack60)
        %v3645 = vmul.f32 -0.5, %v3640 (stack61)
        %v3646 = vadd.f32 1.0, %v3645 (stack62)
        %v3647 = vmul.f32 %v3646, %v3640 (stack63)
        %v3648 = vand.u32 2147483647, %v3640 (stack64)
        %vm3649 = vcmp.lt.f32.partialorder %v3648, 0.0004427343 (stack65)
        %v3650 = vsel /*vm=*/%vm3649, /*on_true_vy=*/%v3647, /*on_false_vx=*/%v3644 (stack66)
        %v3651 = vxor.u32 2147483648, %v3650 (stack57)
        %vm3654 = vcmp.lt.f32.partialorder %v3651, 5.0 (stack56)
        %v3659 = vsel /*vm=*/%vm3654, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v3663 = vsel /*vm=*/%vm3654, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v3667 = vsel /*vm=*/%vm3654, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v3671 = vsel /*vm=*/%vm3654, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v3675 = vsel /*vm=*/%vm3654, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v3679 = vsel /*vm=*/%vm3654, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v3683 = vsel /*vm=*/%vm3654, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v3687 = vsel /*vm=*/%vm3654, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v3691 = vsel /*vm=*/%vm3654, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v3695 = vadd.f32 -2.5, %v3651 (stack52)
        %v3697 = vrsqrt.pop %v3651 (stack67)
        %v3698 = vmul.f32 %v3697, %v3651 (stack68)
        %vm3699 = vcmp.eq.f32.partialorder %v3651, inf (stack69)
        %v3700 = vsel /*vm=*/%vm3699, /*on_true_vy=*/%v3651, /*on_false_vx=*/%v3698 (stack70)
        %vm3701 = vcmp.eq.f32.partialorder %v3651, 0.0 (stack71)
        %v3702 = vand.u32 2147483648, %v3651 (stack72)
        %v3703 = vsel /*vm=*/%vm3701, /*on_true_vy=*/%v3702, /*on_false_vx=*/%v3700 (stack73)
        %v3706 = vadd.f32 -3.0, %v3703 (stack52)
        %v3710 = vsel /*vm=*/%vm3654, /*on_true_vy=*/%v3695, /*on_false_vx=*/%v3706 (stack43)
        %v3714 = vmul.f32 %v3710, %v3691 (stack53)
        %v3718 = vadd.f32 %v3714, %v3687 (stack52)
        %v3722 = vmul.f32 %v3718, %v3710 (stack53)
        %v3726 = vadd.f32 %v3722, %v3683 (stack52)
        %v3730 = vmul.f32 %v3726, %v3710 (stack53)
        %v3734 = vadd.f32 %v3730, %v3679 (stack52)
        %v3738 = vmul.f32 %v3734, %v3710 (stack53)
        %v3742 = vadd.f32 %v3738, %v3675 (stack52)
        %v3746 = vmul.f32 %v3742, %v3710 (stack53)
        %v3750 = vadd.f32 %v3746, %v3671 (stack52)
        %v3754 = vmul.f32 %v3750, %v3710 (stack53)
        %v3758 = vadd.f32 %v3754, %v3667 (stack52)
        %v3762 = vmul.f32 %v3758, %v3710 (stack53)
        %v3766 = vadd.f32 %v3762, %v3663 (stack52)
        %v3770 = vmul.f32 %v3766, %v3710 (stack53)
        %v3774 = vadd.f32 %v3770, %v3659 (stack52)
        %v3778 = vmul.f32 %v3774, %v3625 (stack53)
        %v3782 = vsel /*vm=*/%vm3630, /*on_true_vy=*/%v3635, /*on_false_vx=*/%v3778 (stack43)
        %v3786 = vmul.f32 1.4140625, %v3782 (stack53)
        %v3789 = vpack.c.bf16 0.0, %v3786 (stack74)
        %119761 = vst [vmem:[%s280 + $0x300] sm:$0xf] /*vst_source=*/%v3789 (stack75)
        %v3801 = vld [vmem:[%s4] ss:$0 sm:$0xff] (stack32)
        %3802 = vbcast.lane.b32.xlu0 %v3801, 7 (stack37)
        %v3803 = vpop.permute.xlu0 %3802 (stack38)
        %v3814 = vld [vmem:[%s6] ss:$0 sm:$0xff] (stack32)
        %3815 = vbcast.lane.b32.xlu0 %v3814, 7 (stack37)
        %v3816 = vpop.permute.xlu0 %3815 (stack38)
        %v3819 = vadd.s32 %v3816, %v396 (stack39)
        %v3829 = vadd.s32 %v3819, %v415 (stack39)
        %vm3833 = vcmp.lt.u32.totalorder %v3829, %v3819 (stack42)
        %vm3838 = vcmp.lt.u32.totalorder %v3819, %v3816 (stack42)
        %v3843 = vadd.s32 %v3803, %v368 (stack39)
        %v3847 = vadd.s32 1, %v3843 (stack39)
        %v3851 = vsel /*vm=*/%vm3838, /*on_true_vy=*/%v3847, /*on_false_vx=*/%v3843 (stack43)
        %v3855 = vadd.s32 1, %v3851 (stack39)
        %v3859 = vsel /*vm=*/%vm3833, /*on_true_vy=*/%v3855, /*on_false_vx=*/%v3851 (stack43)
        %v3864 = vadd.s32 %v3859, %v10 (stack39)
        %v3868 = vadd.s32 %v3829, %v9 (stack39)
        %v3872 = vadd.s32 %v3868, %v3864 (stack39)
        %v3874 = vshll.u32 %v3868, 13 (stack44)
        %v3875 = vshrl.u32 %v3868, 19 (stack45)
        %v3876 = vor.u32 %v3875, %v3874 (stack46)
        %v3877 = vxor.u32 %v3876, %v3872 (stack47)
        %v3880 = vadd.s32 %v3877, %v3872 (stack39)
        %v3882 = vshll.u32 %v3877, 15 (stack44)
        %v3883 = vshrl.u32 %v3877, 17 (stack45)
        %v3884 = vor.u32 %v3883, %v3882 (stack46)
        %v3885 = vxor.u32 %v3884, %v3880 (stack47)
        %v3888 = vadd.s32 %v3885, %v3880 (stack39)
        %v3890 = vshll.u32 %v3885, 26 (stack44)
        %v3891 = vshrl.u32 %v3885, 6 (stack45)
        %v3892 = vor.u32 %v3891, %v3890 (stack46)
        %v3893 = vxor.u32 %v3892, %v3888 (stack47)
        %v3896 = vadd.s32 %v3893, %v3888 (stack39)
        %v3900 = vadd.s32 %v3896, %v9 (stack39)
        %v3902 = vshll.u32 %v3893, 6 (stack44)
        %v3903 = vshrl.u32 %v3893, 26 (stack45)
        %v3904 = vor.u32 %v3903, %v3902 (stack46)
        %v3905 = vxor.u32 %v3904, %v3896 (stack47)
        %v3908 = vadd.s32 %v3905, %v8 (stack39)
        %v3912 = vadd.s32 1, %v3908 (stack39)
        %v3916 = vadd.s32 %v3912, %v3900 (stack39)
        %v3918 = vshll.u32 %v3912, 17 (stack44)
        %v3919 = vshrl.u32 %v3912, 15 (stack45)
        %v3920 = vor.u32 %v3919, %v3918 (stack46)
        %v3921 = vxor.u32 %v3920, %v3916 (stack47)
        %v3924 = vadd.s32 %v3921, %v3916 (stack39)
        %v3926 = vshll.u32 %v3921, 29 (stack44)
        %v3927 = vshrl.u32 %v3921, 3 (stack45)
        %v3928 = vor.u32 %v3927, %v3926 (stack46)
        %v3929 = vxor.u32 %v3928, %v3924 (stack47)
        %v3932 = vadd.s32 %v3929, %v3924 (stack39)
        %v3934 = vshll.u32 %v3929, 16 (stack44)
        %v3935 = vshrl.u32 %v3929, 16 (stack45)
        %v3936 = vor.u32 %v3935, %v3934 (stack46)
        %v3937 = vxor.u32 %v3936, %v3932 (stack47)
        %v3940 = vadd.s32 %v3937, %v3932 (stack39)
        %v3944 = vadd.s32 %v3940, %v8 (stack39)
        %v3946 = vshll.u32 %v3937, 24 (stack44)
        %v3947 = vshrl.u32 %v3937, 8 (stack45)
        %v3948 = vor.u32 %v3947, %v3946 (stack46)
        %v3949 = vxor.u32 %v3948, %v3940 (stack47)
        %v3952 = vadd.s32 %v3949, %v10 (stack39)
        %v3956 = vadd.s32 2, %v3952 (stack39)
        %v3960 = vadd.s32 %v3956, %v3944 (stack39)
        %v3962 = vshll.u32 %v3956, 13 (stack44)
        %v3963 = vshrl.u32 %v3956, 19 (stack45)
        %v3964 = vor.u32 %v3963, %v3962 (stack46)
        %v3965 = vxor.u32 %v3964, %v3960 (stack47)
        %v3968 = vadd.s32 %v3965, %v3960 (stack39)
        %v3970 = vshll.u32 %v3965, 15 (stack44)
        %v3971 = vshrl.u32 %v3965, 17 (stack45)
        %v3972 = vor.u32 %v3971, %v3970 (stack46)
        %v3973 = vxor.u32 %v3972, %v3968 (stack47)
        %v3976 = vadd.s32 %v3973, %v3968 (stack39)
        %v3978 = vshll.u32 %v3973, 26 (stack44)
        %v3979 = vshrl.u32 %v3973, 6 (stack45)
        %v3980 = vor.u32 %v3979, %v3978 (stack46)
        %v3981 = vxor.u32 %v3980, %v3976 (stack47)
        %v3984 = vadd.s32 %v3981, %v3976 (stack39)
        %v3988 = vadd.s32 %v3984, %v10 (stack39)
        %v3990 = vshll.u32 %v3981, 6 (stack44)
        %v3991 = vshrl.u32 %v3981, 26 (stack45)
        %v3992 = vor.u32 %v3991, %v3990 (stack46)
        %v3993 = vxor.u32 %v3992, %v3984 (stack47)
        %v3996 = vadd.s32 %v3993, %v9 (stack39)
        %v4000 = vadd.s32 3, %v3996 (stack39)
        %v4004 = vadd.s32 %v4000, %v3988 (stack39)
        %v4006 = vshll.u32 %v4000, 17 (stack44)
        %v4007 = vshrl.u32 %v4000, 15 (stack45)
        %v4008 = vor.u32 %v4007, %v4006 (stack46)
        %v4009 = vxor.u32 %v4008, %v4004 (stack47)
        %v4012 = vadd.s32 %v4009, %v4004 (stack39)
        %v4014 = vshll.u32 %v4009, 29 (stack44)
        %v4015 = vshrl.u32 %v4009, 3 (stack45)
        %v4016 = vor.u32 %v4015, %v4014 (stack46)
        %v4017 = vxor.u32 %v4016, %v4012 (stack47)
        %v4020 = vadd.s32 %v4017, %v4012 (stack39)
        %v4022 = vshll.u32 %v4017, 16 (stack44)
        %v4023 = vshrl.u32 %v4017, 16 (stack45)
        %v4024 = vor.u32 %v4023, %v4022 (stack46)
        %v4025 = vxor.u32 %v4024, %v4020 (stack47)
        %v4028 = vadd.s32 %v4025, %v4020 (stack39)
        %v4032 = vadd.s32 %v4028, %v9 (stack39)
        %v4034 = vshll.u32 %v4025, 24 (stack44)
        %v4035 = vshrl.u32 %v4025, 8 (stack45)
        %v4036 = vor.u32 %v4035, %v4034 (stack46)
        %v4037 = vxor.u32 %v4036, %v4028 (stack47)
        %v4040 = vadd.s32 %v4037, %v8 (stack39)
        %v4044 = vadd.s32 4, %v4040 (stack39)
        %v4048 = vadd.s32 %v4044, %v4032 (stack39)
        %v4050 = vshll.u32 %v4044, 13 (stack44)
        %v4051 = vshrl.u32 %v4044, 19 (stack45)
        %v4052 = vor.u32 %v4051, %v4050 (stack46)
        %v4053 = vxor.u32 %v4052, %v4048 (stack47)
        %v4056 = vadd.s32 %v4053, %v4048 (stack39)
        %v4058 = vshll.u32 %v4053, 15 (stack44)
        %v4059 = vshrl.u32 %v4053, 17 (stack45)
        %v4060 = vor.u32 %v4059, %v4058 (stack46)
        %v4061 = vxor.u32 %v4060, %v4056 (stack47)
        %v4064 = vadd.s32 %v4061, %v4056 (stack39)
        %v4066 = vshll.u32 %v4061, 26 (stack44)
        %v4067 = vshrl.u32 %v4061, 6 (stack45)
        %v4068 = vor.u32 %v4067, %v4066 (stack46)
        %v4069 = vxor.u32 %v4068, %v4064 (stack47)
        %v4072 = vadd.s32 %v4069, %v4064 (stack39)
        %v4076 = vadd.s32 %v4072, %v8 (stack39)
        %v4078 = vshll.u32 %v4069, 6 (stack44)
        %v4079 = vshrl.u32 %v4069, 26 (stack45)
        %v4080 = vor.u32 %v4079, %v4078 (stack46)
        %v4081 = vxor.u32 %v4080, %v4072 (stack47)
        %v4084 = vadd.s32 %v4081, %v10 (stack39)
        %v4088 = vadd.s32 5, %v4084 (stack39)
        %v4090 = vxor.u32 %v4088, %v4076 (stack47)
        %v4091 = vand.u32.u8 255, %v4090 (stack48)
        %v4092 = vand.u32 65535, %v4091 (stack49)
        %v4093 = vshrl.u32 %v4092, 1 (stack50)
        %v4094 = vor.u32 16256, %v4093 (stack46)
        %v4095 = vand.u32.u16 65535, %v4094 (stack51)
        %v119762 = vadd.low.f32.bf16 -1.0, %v4095 (stack52)
        %v4104 = vmul.f32 2.0, %v119762 (stack53)
        %v4108 = vadd.f32 -0.99609375, %v4104 (stack52)
        %v4112 = vmax.f32 %v4108, -0.99609375 (stack54)
        %v4114 = vand.u32 2147483647, %v4112 (stack55)
        %vm4117 = vcmp.eq.f32.partialorder %v4114, 1.0 (stack56)
        %v4122 = vmul.f32 inf, %v4112 (stack53)
        %v4124 = vxor.u32 2147483648, %v4112 (stack57)
        %v4127 = vmul.f32 %v4124, %v4112 (stack53)
        %v4129 = vadd.f32 1.0, %v4127 (stack58)
        %v4130 = vlog2.pop %v4129 (stack59)
        %v4131 = vmul.f32 0.6931472, %v4130 (stack60)
        %v4132 = vmul.f32 -0.5, %v4127 (stack61)
        %v4133 = vadd.f32 1.0, %v4132 (stack62)
        %v4134 = vmul.f32 %v4133, %v4127 (stack63)
        %v4135 = vand.u32 2147483647, %v4127 (stack64)
        %vm4136 = vcmp.lt.f32.partialorder %v4135, 0.0004427343 (stack65)
        %v4137 = vsel /*vm=*/%vm4136, /*on_true_vy=*/%v4134, /*on_false_vx=*/%v4131 (stack66)
        %v4138 = vxor.u32 2147483648, %v4137 (stack57)
        %vm4141 = vcmp.lt.f32.partialorder %v4138, 5.0 (stack56)
        %v4146 = vsel /*vm=*/%vm4141, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v4150 = vsel /*vm=*/%vm4141, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v4154 = vsel /*vm=*/%vm4141, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v4158 = vsel /*vm=*/%vm4141, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v4162 = vsel /*vm=*/%vm4141, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v4166 = vsel /*vm=*/%vm4141, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v4170 = vsel /*vm=*/%vm4141, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v4174 = vsel /*vm=*/%vm4141, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v4178 = vsel /*vm=*/%vm4141, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v4182 = vadd.f32 -2.5, %v4138 (stack52)
        %v4184 = vrsqrt.pop %v4138 (stack67)
        %v4185 = vmul.f32 %v4184, %v4138 (stack68)
        %vm4186 = vcmp.eq.f32.partialorder %v4138, inf (stack69)
        %v4187 = vsel /*vm=*/%vm4186, /*on_true_vy=*/%v4138, /*on_false_vx=*/%v4185 (stack70)
        %vm4188 = vcmp.eq.f32.partialorder %v4138, 0.0 (stack71)
        %v4189 = vand.u32 2147483648, %v4138 (stack72)
        %v4190 = vsel /*vm=*/%vm4188, /*on_true_vy=*/%v4189, /*on_false_vx=*/%v4187 (stack73)
        %v4193 = vadd.f32 -3.0, %v4190 (stack52)
        %v4197 = vsel /*vm=*/%vm4141, /*on_true_vy=*/%v4182, /*on_false_vx=*/%v4193 (stack43)
        %v4201 = vmul.f32 %v4197, %v4178 (stack53)
        %v4205 = vadd.f32 %v4201, %v4174 (stack52)
        %v4209 = vmul.f32 %v4205, %v4197 (stack53)
        %v4213 = vadd.f32 %v4209, %v4170 (stack52)
        %v4217 = vmul.f32 %v4213, %v4197 (stack53)
        %v4221 = vadd.f32 %v4217, %v4166 (stack52)
        %v4225 = vmul.f32 %v4221, %v4197 (stack53)
        %v4229 = vadd.f32 %v4225, %v4162 (stack52)
        %v4233 = vmul.f32 %v4229, %v4197 (stack53)
        %v4237 = vadd.f32 %v4233, %v4158 (stack52)
        %v4241 = vmul.f32 %v4237, %v4197 (stack53)
        %v4245 = vadd.f32 %v4241, %v4154 (stack52)
        %v4249 = vmul.f32 %v4245, %v4197 (stack53)
        %v4253 = vadd.f32 %v4249, %v4150 (stack52)
        %v4257 = vmul.f32 %v4253, %v4197 (stack53)
        %v4261 = vadd.f32 %v4257, %v4146 (stack52)
        %v4265 = vmul.f32 %v4261, %v4112 (stack53)
        %v4269 = vsel /*vm=*/%vm4117, /*on_true_vy=*/%v4122, /*on_false_vx=*/%v4265 (stack43)
        %v4273 = vmul.f32 1.4140625, %v4269 (stack53)
        %v4276 = vpack.c.bf16 0.0, %v4273 (stack74)
        %119763 = vst [vmem:[%s280 + $0x380] sm:$0xf] /*vst_source=*/%v4276 (stack75)
        %s4278 = sadd.s32 8, %s120390 (stack76)
        %s4279 = sshrl.u32 %s4278, 10 (stack23)
        %p119764 = scmp.gt.s32.totalorder %s4279, 1 (stack24)
        %s4281 = scalar_select /*predicate=*/%p119764, /*on_true=*/1, /*on_false=*/%s4279 (stack25)
        %s4282 = sand.u32 1023, %s4278 /* smod.u32 w/div 1024 */ (stack26)
        %s4283 = sshrl.u32 %s4282, 7 (stack27)
        %s4284 = sand.u32 127, %s4282 /* smod.u32 w/div 128 */ (stack28)
        %s119765 = sshll.u32 %s4281, 3 (stack29)
        %s4286 = scalar_lea.vmem %s3, %s119765 (stack30)
        %s4288 = scalar_lea.vmem %s4286, %s4283 (stack31)
        %v4289 = vld [vmem:[%s4288] ss:$0 sm:$0xff] (stack32)
        %s4290 = sand.u32 255, %s4284 (stack33)
        %s4292 = sor.u32 256, %s4290 (stack34)
        %4293 = vbcast.lane.b32.xlu0 %v4289, %s4292 (stack35)
        %v4294 = vpop.permute.xlu0 %4293 (stack36)
        %s4303 = scalar_lea.vmem %s5, %s119765 (stack30)
        %s4305 = scalar_lea.vmem %s4303, %s4283 (stack31)
        %v4306 = vld [vmem:[%s4305] ss:$0 sm:$0xff] (stack32)
        %4310 = vbcast.lane.b32.xlu0 %v4306, %s4292 (stack35)
        %v4311 = vpop.permute.xlu0 %4310 (stack36)
        %v4314 = vadd.s32 %v4311, %v408 (stack39)
        %v4324 = vadd.s32 %v4314, %v415 (stack39)
        %vm4328 = vcmp.lt.u32.totalorder %v4324, %v4314 (stack42)
        %vm4333 = vcmp.lt.u32.totalorder %v4314, %v408 (stack42)
        %v4338 = vadd.s32 %v4294, %v380 (stack39)
        %v4342 = vadd.s32 1, %v4338 (stack39)
        %v4346 = vsel /*vm=*/%vm4333, /*on_true_vy=*/%v4342, /*on_false_vx=*/%v4338 (stack43)
        %v4350 = vadd.s32 1, %v4346 (stack39)
        %v4354 = vsel /*vm=*/%vm4328, /*on_true_vy=*/%v4350, /*on_false_vx=*/%v4346 (stack43)
        %v4359 = vadd.s32 %v4354, %v10 (stack39)
        %v4363 = vadd.s32 %v4324, %v9 (stack39)
        %v4367 = vadd.s32 %v4363, %v4359 (stack39)
        %v4369 = vshll.u32 %v4363, 13 (stack44)
        %v4370 = vshrl.u32 %v4363, 19 (stack45)
        %v4371 = vor.u32 %v4370, %v4369 (stack46)
        %v4372 = vxor.u32 %v4371, %v4367 (stack47)
        %v4375 = vadd.s32 %v4372, %v4367 (stack39)
        %v4377 = vshll.u32 %v4372, 15 (stack44)
        %v4378 = vshrl.u32 %v4372, 17 (stack45)
        %v4379 = vor.u32 %v4378, %v4377 (stack46)
        %v4380 = vxor.u32 %v4379, %v4375 (stack47)
        %v4383 = vadd.s32 %v4380, %v4375 (stack39)
        %v4385 = vshll.u32 %v4380, 26 (stack44)
        %v4386 = vshrl.u32 %v4380, 6 (stack45)
        %v4387 = vor.u32 %v4386, %v4385 (stack46)
        %v4388 = vxor.u32 %v4387, %v4383 (stack47)
        %v4391 = vadd.s32 %v4388, %v4383 (stack39)
        %v4395 = vadd.s32 %v4391, %v9 (stack39)
        %v4397 = vshll.u32 %v4388, 6 (stack44)
        %v4398 = vshrl.u32 %v4388, 26 (stack45)
        %v4399 = vor.u32 %v4398, %v4397 (stack46)
        %v4400 = vxor.u32 %v4399, %v4391 (stack47)
        %v4403 = vadd.s32 %v4400, %v8 (stack39)
        %v4407 = vadd.s32 1, %v4403 (stack39)
        %v4411 = vadd.s32 %v4407, %v4395 (stack39)
        %v4413 = vshll.u32 %v4407, 17 (stack44)
        %v4414 = vshrl.u32 %v4407, 15 (stack45)
        %v4415 = vor.u32 %v4414, %v4413 (stack46)
        %v4416 = vxor.u32 %v4415, %v4411 (stack47)
        %v4419 = vadd.s32 %v4416, %v4411 (stack39)
        %v4421 = vshll.u32 %v4416, 29 (stack44)
        %v4422 = vshrl.u32 %v4416, 3 (stack45)
        %v4423 = vor.u32 %v4422, %v4421 (stack46)
        %v4424 = vxor.u32 %v4423, %v4419 (stack47)
        %v4427 = vadd.s32 %v4424, %v4419 (stack39)
        %v4429 = vshll.u32 %v4424, 16 (stack44)
        %v4430 = vshrl.u32 %v4424, 16 (stack45)
        %v4431 = vor.u32 %v4430, %v4429 (stack46)
        %v4432 = vxor.u32 %v4431, %v4427 (stack47)
        %v4435 = vadd.s32 %v4432, %v4427 (stack39)
        %v4439 = vadd.s32 %v4435, %v8 (stack39)
        %v4441 = vshll.u32 %v4432, 24 (stack44)
        %v4442 = vshrl.u32 %v4432, 8 (stack45)
        %v4443 = vor.u32 %v4442, %v4441 (stack46)
        %v4444 = vxor.u32 %v4443, %v4435 (stack47)
        %v4447 = vadd.s32 %v4444, %v10 (stack39)
        %v4451 = vadd.s32 2, %v4447 (stack39)
        %v4455 = vadd.s32 %v4451, %v4439 (stack39)
        %v4457 = vshll.u32 %v4451, 13 (stack44)
        %v4458 = vshrl.u32 %v4451, 19 (stack45)
        %v4459 = vor.u32 %v4458, %v4457 (stack46)
        %v4460 = vxor.u32 %v4459, %v4455 (stack47)
        %v4463 = vadd.s32 %v4460, %v4455 (stack39)
        %v4465 = vshll.u32 %v4460, 15 (stack44)
        %v4466 = vshrl.u32 %v4460, 17 (stack45)
        %v4467 = vor.u32 %v4466, %v4465 (stack46)
        %v4468 = vxor.u32 %v4467, %v4463 (stack47)
        %v4471 = vadd.s32 %v4468, %v4463 (stack39)
        %v4473 = vshll.u32 %v4468, 26 (stack44)
        %v4474 = vshrl.u32 %v4468, 6 (stack45)
        %v4475 = vor.u32 %v4474, %v4473 (stack46)
        %v4476 = vxor.u32 %v4475, %v4471 (stack47)
        %v4479 = vadd.s32 %v4476, %v4471 (stack39)
        %v4483 = vadd.s32 %v4479, %v10 (stack39)
        %v4485 = vshll.u32 %v4476, 6 (stack44)
        %v4486 = vshrl.u32 %v4476, 26 (stack45)
        %v4487 = vor.u32 %v4486, %v4485 (stack46)
        %v4488 = vxor.u32 %v4487, %v4479 (stack47)
        %v4491 = vadd.s32 %v4488, %v9 (stack39)
        %v4495 = vadd.s32 3, %v4491 (stack39)
        %v4499 = vadd.s32 %v4495, %v4483 (stack39)
        %v4501 = vshll.u32 %v4495, 17 (stack44)
        %v4502 = vshrl.u32 %v4495, 15 (stack45)
        %v4503 = vor.u32 %v4502, %v4501 (stack46)
        %v4504 = vxor.u32 %v4503, %v4499 (stack47)
        %v4507 = vadd.s32 %v4504, %v4499 (stack39)
        %v4509 = vshll.u32 %v4504, 29 (stack44)
        %v4510 = vshrl.u32 %v4504, 3 (stack45)
        %v4511 = vor.u32 %v4510, %v4509 (stack46)
        %v4512 = vxor.u32 %v4511, %v4507 (stack47)
        %v4515 = vadd.s32 %v4512, %v4507 (stack39)
        %v4517 = vshll.u32 %v4512, 16 (stack44)
        %v4518 = vshrl.u32 %v4512, 16 (stack45)
        %v4519 = vor.u32 %v4518, %v4517 (stack46)
        %v4520 = vxor.u32 %v4519, %v4515 (stack47)
        %v4523 = vadd.s32 %v4520, %v4515 (stack39)
        %v4527 = vadd.s32 %v4523, %v9 (stack39)
        %v4529 = vshll.u32 %v4520, 24 (stack44)
        %v4530 = vshrl.u32 %v4520, 8 (stack45)
        %v4531 = vor.u32 %v4530, %v4529 (stack46)
        %v4532 = vxor.u32 %v4531, %v4523 (stack47)
        %v4535 = vadd.s32 %v4532, %v8 (stack39)
        %v4539 = vadd.s32 4, %v4535 (stack39)
        %v4543 = vadd.s32 %v4539, %v4527 (stack39)
        %v4545 = vshll.u32 %v4539, 13 (stack44)
        %v4546 = vshrl.u32 %v4539, 19 (stack45)
        %v4547 = vor.u32 %v4546, %v4545 (stack46)
        %v4548 = vxor.u32 %v4547, %v4543 (stack47)
        %v4551 = vadd.s32 %v4548, %v4543 (stack39)
        %v4553 = vshll.u32 %v4548, 15 (stack44)
        %v4554 = vshrl.u32 %v4548, 17 (stack45)
        %v4555 = vor.u32 %v4554, %v4553 (stack46)
        %v4556 = vxor.u32 %v4555, %v4551 (stack47)
        %v4559 = vadd.s32 %v4556, %v4551 (stack39)
        %v4561 = vshll.u32 %v4556, 26 (stack44)
        %v4562 = vshrl.u32 %v4556, 6 (stack45)
        %v4563 = vor.u32 %v4562, %v4561 (stack46)
        %v4564 = vxor.u32 %v4563, %v4559 (stack47)
        %v4567 = vadd.s32 %v4564, %v4559 (stack39)
        %v4571 = vadd.s32 %v4567, %v8 (stack39)
        %v4573 = vshll.u32 %v4564, 6 (stack44)
        %v4574 = vshrl.u32 %v4564, 26 (stack45)
        %v4575 = vor.u32 %v4574, %v4573 (stack46)
        %v4576 = vxor.u32 %v4575, %v4567 (stack47)
        %v4579 = vadd.s32 %v4576, %v10 (stack39)
        %v4583 = vadd.s32 5, %v4579 (stack39)
        %v4585 = vxor.u32 %v4583, %v4571 (stack47)
        %v4586 = vand.u32.u8 255, %v4585 (stack48)
        %v4587 = vand.u32 65535, %v4586 (stack49)
        %v4588 = vshrl.u32 %v4587, 1 (stack50)
        %v4589 = vor.u32 16256, %v4588 (stack46)
        %v4590 = vand.u32.u16 65535, %v4589 (stack51)
        %v119768 = vadd.low.f32.bf16 -1.0, %v4590 (stack52)
        %v4599 = vmul.f32 2.0, %v119768 (stack53)
        %v4603 = vadd.f32 -0.99609375, %v4599 (stack52)
        %v4607 = vmax.f32 %v4603, -0.99609375 (stack54)
        %v4609 = vand.u32 2147483647, %v4607 (stack55)
        %vm4612 = vcmp.eq.f32.partialorder %v4609, 1.0 (stack56)
        %v4617 = vmul.f32 inf, %v4607 (stack53)
        %v4619 = vxor.u32 2147483648, %v4607 (stack57)
        %v4622 = vmul.f32 %v4619, %v4607 (stack53)
        %v4624 = vadd.f32 1.0, %v4622 (stack58)
        %v4625 = vlog2.pop %v4624 (stack59)
        %v4626 = vmul.f32 0.6931472, %v4625 (stack60)
        %v4627 = vmul.f32 -0.5, %v4622 (stack61)
        %v4628 = vadd.f32 1.0, %v4627 (stack62)
        %v4629 = vmul.f32 %v4628, %v4622 (stack63)
        %v4630 = vand.u32 2147483647, %v4622 (stack64)
        %vm4631 = vcmp.lt.f32.partialorder %v4630, 0.0004427343 (stack65)
        %v4632 = vsel /*vm=*/%vm4631, /*on_true_vy=*/%v4629, /*on_false_vx=*/%v4626 (stack66)
        %v4633 = vxor.u32 2147483648, %v4632 (stack57)
        %vm4636 = vcmp.lt.f32.partialorder %v4633, 5.0 (stack56)
        %v4641 = vsel /*vm=*/%vm4636, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v4645 = vsel /*vm=*/%vm4636, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v4649 = vsel /*vm=*/%vm4636, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v4653 = vsel /*vm=*/%vm4636, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v4657 = vsel /*vm=*/%vm4636, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v4661 = vsel /*vm=*/%vm4636, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v4665 = vsel /*vm=*/%vm4636, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v4669 = vsel /*vm=*/%vm4636, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v4673 = vsel /*vm=*/%vm4636, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v4677 = vadd.f32 -2.5, %v4633 (stack52)
        %v4679 = vrsqrt.pop %v4633 (stack67)
        %v4680 = vmul.f32 %v4679, %v4633 (stack68)
        %vm4681 = vcmp.eq.f32.partialorder %v4633, inf (stack69)
        %v4682 = vsel /*vm=*/%vm4681, /*on_true_vy=*/%v4633, /*on_false_vx=*/%v4680 (stack70)
        %vm4683 = vcmp.eq.f32.partialorder %v4633, 0.0 (stack71)
        %v4684 = vand.u32 2147483648, %v4633 (stack72)
        %v4685 = vsel /*vm=*/%vm4683, /*on_true_vy=*/%v4684, /*on_false_vx=*/%v4682 (stack73)
        %v4688 = vadd.f32 -3.0, %v4685 (stack52)
        %v4692 = vsel /*vm=*/%vm4636, /*on_true_vy=*/%v4677, /*on_false_vx=*/%v4688 (stack43)
        %v4696 = vmul.f32 %v4692, %v4673 (stack53)
        %v4700 = vadd.f32 %v4696, %v4669 (stack52)
        %v4704 = vmul.f32 %v4700, %v4692 (stack53)
        %v4708 = vadd.f32 %v4704, %v4665 (stack52)
        %v4712 = vmul.f32 %v4708, %v4692 (stack53)
        %v4716 = vadd.f32 %v4712, %v4661 (stack52)
        %v4720 = vmul.f32 %v4716, %v4692 (stack53)
        %v4724 = vadd.f32 %v4720, %v4657 (stack52)
        %v4728 = vmul.f32 %v4724, %v4692 (stack53)
        %v4732 = vadd.f32 %v4728, %v4653 (stack52)
        %v4736 = vmul.f32 %v4732, %v4692 (stack53)
        %v4740 = vadd.f32 %v4736, %v4649 (stack52)
        %v4744 = vmul.f32 %v4740, %v4692 (stack53)
        %v4748 = vadd.f32 %v4744, %v4645 (stack52)
        %v4752 = vmul.f32 %v4748, %v4692 (stack53)
        %v4756 = vadd.f32 %v4752, %v4641 (stack52)
        %v4760 = vmul.f32 %v4756, %v4607 (stack53)
        %v4764 = vsel /*vm=*/%vm4612, /*on_true_vy=*/%v4617, /*on_false_vx=*/%v4760 (stack43)
        %v4768 = vmul.f32 1.4140625, %v4764 (stack53)
        %v4771 = vpack.c.bf16 0.0, %v4768 (stack74)
        %119769 = vst [vmem:[%s280 + $0x4] sm:$0xf] /*vst_source=*/%v4771 (stack75)
        %v4775 = vadd.s32 %v4311, %v894 (stack39)
        %v4785 = vadd.s32 %v4775, %v415 (stack39)
        %vm4789 = vcmp.lt.u32.totalorder %v4785, %v4775 (stack42)
        %vm4794 = vcmp.lt.u32.totalorder %v4775, %v894 (stack42)
        %v4799 = vadd.s32 %v4294, %v881 (stack39)
        %v4803 = vadd.s32 1, %v4799 (stack39)
        %v4807 = vsel /*vm=*/%vm4794, /*on_true_vy=*/%v4803, /*on_false_vx=*/%v4799 (stack43)
        %v4811 = vadd.s32 1, %v4807 (stack39)
        %v4815 = vsel /*vm=*/%vm4789, /*on_true_vy=*/%v4811, /*on_false_vx=*/%v4807 (stack43)
        %v4820 = vadd.s32 %v4815, %v10 (stack39)
        %v4824 = vadd.s32 %v4785, %v9 (stack39)
        %v4828 = vadd.s32 %v4824, %v4820 (stack39)
        %v4830 = vshll.u32 %v4824, 13 (stack44)
        %v4831 = vshrl.u32 %v4824, 19 (stack45)
        %v4832 = vor.u32 %v4831, %v4830 (stack46)
        %v4833 = vxor.u32 %v4832, %v4828 (stack47)
        %v4836 = vadd.s32 %v4833, %v4828 (stack39)
        %v4838 = vshll.u32 %v4833, 15 (stack44)
        %v4839 = vshrl.u32 %v4833, 17 (stack45)
        %v4840 = vor.u32 %v4839, %v4838 (stack46)
        %v4841 = vxor.u32 %v4840, %v4836 (stack47)
        %v4844 = vadd.s32 %v4841, %v4836 (stack39)
        %v4846 = vshll.u32 %v4841, 26 (stack44)
        %v4847 = vshrl.u32 %v4841, 6 (stack45)
        %v4848 = vor.u32 %v4847, %v4846 (stack46)
        %v4849 = vxor.u32 %v4848, %v4844 (stack47)
        %v4852 = vadd.s32 %v4849, %v4844 (stack39)
        %v4856 = vadd.s32 %v4852, %v9 (stack39)
        %v4858 = vshll.u32 %v4849, 6 (stack44)
        %v4859 = vshrl.u32 %v4849, 26 (stack45)
        %v4860 = vor.u32 %v4859, %v4858 (stack46)
        %v4861 = vxor.u32 %v4860, %v4852 (stack47)
        %v4864 = vadd.s32 %v4861, %v8 (stack39)
        %v4868 = vadd.s32 1, %v4864 (stack39)
        %v4872 = vadd.s32 %v4868, %v4856 (stack39)
        %v4874 = vshll.u32 %v4868, 17 (stack44)
        %v4875 = vshrl.u32 %v4868, 15 (stack45)
        %v4876 = vor.u32 %v4875, %v4874 (stack46)
        %v4877 = vxor.u32 %v4876, %v4872 (stack47)
        %v4880 = vadd.s32 %v4877, %v4872 (stack39)
        %v4882 = vshll.u32 %v4877, 29 (stack44)
        %v4883 = vshrl.u32 %v4877, 3 (stack45)
        %v4884 = vor.u32 %v4883, %v4882 (stack46)
        %v4885 = vxor.u32 %v4884, %v4880 (stack47)
        %v4888 = vadd.s32 %v4885, %v4880 (stack39)
        %v4890 = vshll.u32 %v4885, 16 (stack44)
        %v4891 = vshrl.u32 %v4885, 16 (stack45)
        %v4892 = vor.u32 %v4891, %v4890 (stack46)
        %v4893 = vxor.u32 %v4892, %v4888 (stack47)
        %v4896 = vadd.s32 %v4893, %v4888 (stack39)
        %v4900 = vadd.s32 %v4896, %v8 (stack39)
        %v4902 = vshll.u32 %v4893, 24 (stack44)
        %v4903 = vshrl.u32 %v4893, 8 (stack45)
        %v4904 = vor.u32 %v4903, %v4902 (stack46)
        %v4905 = vxor.u32 %v4904, %v4896 (stack47)
        %v4908 = vadd.s32 %v4905, %v10 (stack39)
        %v4912 = vadd.s32 2, %v4908 (stack39)
        %v4916 = vadd.s32 %v4912, %v4900 (stack39)
        %v4918 = vshll.u32 %v4912, 13 (stack44)
        %v4919 = vshrl.u32 %v4912, 19 (stack45)
        %v4920 = vor.u32 %v4919, %v4918 (stack46)
        %v4921 = vxor.u32 %v4920, %v4916 (stack47)
        %v4924 = vadd.s32 %v4921, %v4916 (stack39)
        %v4926 = vshll.u32 %v4921, 15 (stack44)
        %v4927 = vshrl.u32 %v4921, 17 (stack45)
        %v4928 = vor.u32 %v4927, %v4926 (stack46)
        %v4929 = vxor.u32 %v4928, %v4924 (stack47)
        %v4932 = vadd.s32 %v4929, %v4924 (stack39)
        %v4934 = vshll.u32 %v4929, 26 (stack44)
        %v4935 = vshrl.u32 %v4929, 6 (stack45)
        %v4936 = vor.u32 %v4935, %v4934 (stack46)
        %v4937 = vxor.u32 %v4936, %v4932 (stack47)
        %v4940 = vadd.s32 %v4937, %v4932 (stack39)
        %v4944 = vadd.s32 %v4940, %v10 (stack39)
        %v4946 = vshll.u32 %v4937, 6 (stack44)
        %v4947 = vshrl.u32 %v4937, 26 (stack45)
        %v4948 = vor.u32 %v4947, %v4946 (stack46)
        %v4949 = vxor.u32 %v4948, %v4940 (stack47)
        %v4952 = vadd.s32 %v4949, %v9 (stack39)
        %v4956 = vadd.s32 3, %v4952 (stack39)
        %v4960 = vadd.s32 %v4956, %v4944 (stack39)
        %v4962 = vshll.u32 %v4956, 17 (stack44)
        %v4963 = vshrl.u32 %v4956, 15 (stack45)
        %v4964 = vor.u32 %v4963, %v4962 (stack46)
        %v4965 = vxor.u32 %v4964, %v4960 (stack47)
        %v4968 = vadd.s32 %v4965, %v4960 (stack39)
        %v4970 = vshll.u32 %v4965, 29 (stack44)
        %v4971 = vshrl.u32 %v4965, 3 (stack45)
        %v4972 = vor.u32 %v4971, %v4970 (stack46)
        %v4973 = vxor.u32 %v4972, %v4968 (stack47)
        %v4976 = vadd.s32 %v4973, %v4968 (stack39)
        %v4978 = vshll.u32 %v4973, 16 (stack44)
        %v4979 = vshrl.u32 %v4973, 16 (stack45)
        %v4980 = vor.u32 %v4979, %v4978 (stack46)
        %v4981 = vxor.u32 %v4980, %v4976 (stack47)
        %v4984 = vadd.s32 %v4981, %v4976 (stack39)
        %v4988 = vadd.s32 %v4984, %v9 (stack39)
        %v4990 = vshll.u32 %v4981, 24 (stack44)
        %v4991 = vshrl.u32 %v4981, 8 (stack45)
        %v4992 = vor.u32 %v4991, %v4990 (stack46)
        %v4993 = vxor.u32 %v4992, %v4984 (stack47)
        %v4996 = vadd.s32 %v4993, %v8 (stack39)
        %v5000 = vadd.s32 4, %v4996 (stack39)
        %v5004 = vadd.s32 %v5000, %v4988 (stack39)
        %v5006 = vshll.u32 %v5000, 13 (stack44)
        %v5007 = vshrl.u32 %v5000, 19 (stack45)
        %v5008 = vor.u32 %v5007, %v5006 (stack46)
        %v5009 = vxor.u32 %v5008, %v5004 (stack47)
        %v5012 = vadd.s32 %v5009, %v5004 (stack39)
        %v5014 = vshll.u32 %v5009, 15 (stack44)
        %v5015 = vshrl.u32 %v5009, 17 (stack45)
        %v5016 = vor.u32 %v5015, %v5014 (stack46)
        %v5017 = vxor.u32 %v5016, %v5012 (stack47)
        %v5020 = vadd.s32 %v5017, %v5012 (stack39)
        %v5022 = vshll.u32 %v5017, 26 (stack44)
        %v5023 = vshrl.u32 %v5017, 6 (stack45)
        %v5024 = vor.u32 %v5023, %v5022 (stack46)
        %v5025 = vxor.u32 %v5024, %v5020 (stack47)
        %v5028 = vadd.s32 %v5025, %v5020 (stack39)
        %v5032 = vadd.s32 %v5028, %v8 (stack39)
        %v5034 = vshll.u32 %v5025, 6 (stack44)
        %v5035 = vshrl.u32 %v5025, 26 (stack45)
        %v5036 = vor.u32 %v5035, %v5034 (stack46)
        %v5037 = vxor.u32 %v5036, %v5028 (stack47)
        %v5040 = vadd.s32 %v5037, %v10 (stack39)
        %v5044 = vadd.s32 5, %v5040 (stack39)
        %v5046 = vxor.u32 %v5044, %v5032 (stack47)
        %v5047 = vand.u32.u8 255, %v5046 (stack48)
        %v5048 = vand.u32 65535, %v5047 (stack49)
        %v5049 = vshrl.u32 %v5048, 1 (stack50)
        %v5050 = vor.u32 16256, %v5049 (stack46)
        %v5051 = vand.u32.u16 65535, %v5050 (stack51)
        %v119770 = vadd.low.f32.bf16 -1.0, %v5051 (stack52)
        %v5060 = vmul.f32 2.0, %v119770 (stack53)
        %v5064 = vadd.f32 -0.99609375, %v5060 (stack52)
        %v5068 = vmax.f32 %v5064, -0.99609375 (stack54)
        %v5070 = vand.u32 2147483647, %v5068 (stack55)
        %vm5073 = vcmp.eq.f32.partialorder %v5070, 1.0 (stack56)
        %v5078 = vmul.f32 inf, %v5068 (stack53)
        %v5080 = vxor.u32 2147483648, %v5068 (stack57)
        %v5083 = vmul.f32 %v5080, %v5068 (stack53)
        %v5085 = vadd.f32 1.0, %v5083 (stack58)
        %v5086 = vlog2.pop %v5085 (stack59)
        %v5087 = vmul.f32 0.6931472, %v5086 (stack60)
        %v5088 = vmul.f32 -0.5, %v5083 (stack61)
        %v5089 = vadd.f32 1.0, %v5088 (stack62)
        %v5090 = vmul.f32 %v5089, %v5083 (stack63)
        %v5091 = vand.u32 2147483647, %v5083 (stack64)
        %vm5092 = vcmp.lt.f32.partialorder %v5091, 0.0004427343 (stack65)
        %v5093 = vsel /*vm=*/%vm5092, /*on_true_vy=*/%v5090, /*on_false_vx=*/%v5087 (stack66)
        %v5094 = vxor.u32 2147483648, %v5093 (stack57)
        %vm5097 = vcmp.lt.f32.partialorder %v5094, 5.0 (stack56)
        %v5102 = vsel /*vm=*/%vm5097, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v5106 = vsel /*vm=*/%vm5097, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v5110 = vsel /*vm=*/%vm5097, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v5114 = vsel /*vm=*/%vm5097, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v5118 = vsel /*vm=*/%vm5097, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v5122 = vsel /*vm=*/%vm5097, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v5126 = vsel /*vm=*/%vm5097, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v5130 = vsel /*vm=*/%vm5097, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v5134 = vsel /*vm=*/%vm5097, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v5138 = vadd.f32 -2.5, %v5094 (stack52)
        %v5140 = vrsqrt.pop %v5094 (stack67)
        %v5141 = vmul.f32 %v5140, %v5094 (stack68)
        %vm5142 = vcmp.eq.f32.partialorder %v5094, inf (stack69)
        %v5143 = vsel /*vm=*/%vm5142, /*on_true_vy=*/%v5094, /*on_false_vx=*/%v5141 (stack70)
        %vm5144 = vcmp.eq.f32.partialorder %v5094, 0.0 (stack71)
        %v5145 = vand.u32 2147483648, %v5094 (stack72)
        %v5146 = vsel /*vm=*/%vm5144, /*on_true_vy=*/%v5145, /*on_false_vx=*/%v5143 (stack73)
        %v5149 = vadd.f32 -3.0, %v5146 (stack52)
        %v5153 = vsel /*vm=*/%vm5097, /*on_true_vy=*/%v5138, /*on_false_vx=*/%v5149 (stack43)
        %v5157 = vmul.f32 %v5153, %v5134 (stack53)
        %v5161 = vadd.f32 %v5157, %v5130 (stack52)
        %v5165 = vmul.f32 %v5161, %v5153 (stack53)
        %v5169 = vadd.f32 %v5165, %v5126 (stack52)
        %v5173 = vmul.f32 %v5169, %v5153 (stack53)
        %v5177 = vadd.f32 %v5173, %v5122 (stack52)
        %v5181 = vmul.f32 %v5177, %v5153 (stack53)
        %v5185 = vadd.f32 %v5181, %v5118 (stack52)
        %v5189 = vmul.f32 %v5185, %v5153 (stack53)
        %v5193 = vadd.f32 %v5189, %v5114 (stack52)
        %v5197 = vmul.f32 %v5193, %v5153 (stack53)
        %v5201 = vadd.f32 %v5197, %v5110 (stack52)
        %v5205 = vmul.f32 %v5201, %v5153 (stack53)
        %v5209 = vadd.f32 %v5205, %v5106 (stack52)
        %v5213 = vmul.f32 %v5209, %v5153 (stack53)
        %v5217 = vadd.f32 %v5213, %v5102 (stack52)
        %v5221 = vmul.f32 %v5217, %v5068 (stack53)
        %v5225 = vsel /*vm=*/%vm5073, /*on_true_vy=*/%v5078, /*on_false_vx=*/%v5221 (stack43)
        %v5229 = vmul.f32 1.4140625, %v5225 (stack53)
        %v5232 = vpack.c.bf16 0.0, %v5229 (stack74)
        %119771 = vst [vmem:[%s280 + $0x84] sm:$0xf] /*vst_source=*/%v5232 (stack75)
        %v5236 = vadd.s32 %v4311, %v1381 (stack39)
        %v5246 = vadd.s32 %v5236, %v415 (stack39)
        %vm5250 = vcmp.lt.u32.totalorder %v5246, %v5236 (stack42)
        %vm5255 = vcmp.lt.u32.totalorder %v5236, %v1381 (stack42)
        %v5260 = vadd.s32 %v4294, %v1368 (stack39)
        %v5264 = vadd.s32 1, %v5260 (stack39)
        %v5268 = vsel /*vm=*/%vm5255, /*on_true_vy=*/%v5264, /*on_false_vx=*/%v5260 (stack43)
        %v5272 = vadd.s32 1, %v5268 (stack39)
        %v5276 = vsel /*vm=*/%vm5250, /*on_true_vy=*/%v5272, /*on_false_vx=*/%v5268 (stack43)
        %v5281 = vadd.s32 %v5276, %v10 (stack39)
        %v5285 = vadd.s32 %v5246, %v9 (stack39)
        %v5289 = vadd.s32 %v5285, %v5281 (stack39)
        %v5291 = vshll.u32 %v5285, 13 (stack44)
        %v5292 = vshrl.u32 %v5285, 19 (stack45)
        %v5293 = vor.u32 %v5292, %v5291 (stack46)
        %v5294 = vxor.u32 %v5293, %v5289 (stack47)
        %v5297 = vadd.s32 %v5294, %v5289 (stack39)
        %v5299 = vshll.u32 %v5294, 15 (stack44)
        %v5300 = vshrl.u32 %v5294, 17 (stack45)
        %v5301 = vor.u32 %v5300, %v5299 (stack46)
        %v5302 = vxor.u32 %v5301, %v5297 (stack47)
        %v5305 = vadd.s32 %v5302, %v5297 (stack39)
        %v5307 = vshll.u32 %v5302, 26 (stack44)
        %v5308 = vshrl.u32 %v5302, 6 (stack45)
        %v5309 = vor.u32 %v5308, %v5307 (stack46)
        %v5310 = vxor.u32 %v5309, %v5305 (stack47)
        %v5313 = vadd.s32 %v5310, %v5305 (stack39)
        %v5317 = vadd.s32 %v5313, %v9 (stack39)
        %v5319 = vshll.u32 %v5310, 6 (stack44)
        %v5320 = vshrl.u32 %v5310, 26 (stack45)
        %v5321 = vor.u32 %v5320, %v5319 (stack46)
        %v5322 = vxor.u32 %v5321, %v5313 (stack47)
        %v5325 = vadd.s32 %v5322, %v8 (stack39)
        %v5329 = vadd.s32 1, %v5325 (stack39)
        %v5333 = vadd.s32 %v5329, %v5317 (stack39)
        %v5335 = vshll.u32 %v5329, 17 (stack44)
        %v5336 = vshrl.u32 %v5329, 15 (stack45)
        %v5337 = vor.u32 %v5336, %v5335 (stack46)
        %v5338 = vxor.u32 %v5337, %v5333 (stack47)
        %v5341 = vadd.s32 %v5338, %v5333 (stack39)
        %v5343 = vshll.u32 %v5338, 29 (stack44)
        %v5344 = vshrl.u32 %v5338, 3 (stack45)
        %v5345 = vor.u32 %v5344, %v5343 (stack46)
        %v5346 = vxor.u32 %v5345, %v5341 (stack47)
        %v5349 = vadd.s32 %v5346, %v5341 (stack39)
        %v5351 = vshll.u32 %v5346, 16 (stack44)
        %v5352 = vshrl.u32 %v5346, 16 (stack45)
        %v5353 = vor.u32 %v5352, %v5351 (stack46)
        %v5354 = vxor.u32 %v5353, %v5349 (stack47)
        %v5357 = vadd.s32 %v5354, %v5349 (stack39)
        %v5361 = vadd.s32 %v5357, %v8 (stack39)
        %v5363 = vshll.u32 %v5354, 24 (stack44)
        %v5364 = vshrl.u32 %v5354, 8 (stack45)
        %v5365 = vor.u32 %v5364, %v5363 (stack46)
        %v5366 = vxor.u32 %v5365, %v5357 (stack47)
        %v5369 = vadd.s32 %v5366, %v10 (stack39)
        %v5373 = vadd.s32 2, %v5369 (stack39)
        %v5377 = vadd.s32 %v5373, %v5361 (stack39)
        %v5379 = vshll.u32 %v5373, 13 (stack44)
        %v5380 = vshrl.u32 %v5373, 19 (stack45)
        %v5381 = vor.u32 %v5380, %v5379 (stack46)
        %v5382 = vxor.u32 %v5381, %v5377 (stack47)
        %v5385 = vadd.s32 %v5382, %v5377 (stack39)
        %v5387 = vshll.u32 %v5382, 15 (stack44)
        %v5388 = vshrl.u32 %v5382, 17 (stack45)
        %v5389 = vor.u32 %v5388, %v5387 (stack46)
        %v5390 = vxor.u32 %v5389, %v5385 (stack47)
        %v5393 = vadd.s32 %v5390, %v5385 (stack39)
        %v5395 = vshll.u32 %v5390, 26 (stack44)
        %v5396 = vshrl.u32 %v5390, 6 (stack45)
        %v5397 = vor.u32 %v5396, %v5395 (stack46)
        %v5398 = vxor.u32 %v5397, %v5393 (stack47)
        %v5401 = vadd.s32 %v5398, %v5393 (stack39)
        %v5405 = vadd.s32 %v5401, %v10 (stack39)
        %v5407 = vshll.u32 %v5398, 6 (stack44)
        %v5408 = vshrl.u32 %v5398, 26 (stack45)
        %v5409 = vor.u32 %v5408, %v5407 (stack46)
        %v5410 = vxor.u32 %v5409, %v5401 (stack47)
        %v5413 = vadd.s32 %v5410, %v9 (stack39)
        %v5417 = vadd.s32 3, %v5413 (stack39)
        %v5421 = vadd.s32 %v5417, %v5405 (stack39)
        %v5423 = vshll.u32 %v5417, 17 (stack44)
        %v5424 = vshrl.u32 %v5417, 15 (stack45)
        %v5425 = vor.u32 %v5424, %v5423 (stack46)
        %v5426 = vxor.u32 %v5425, %v5421 (stack47)
        %v5429 = vadd.s32 %v5426, %v5421 (stack39)
        %v5431 = vshll.u32 %v5426, 29 (stack44)
        %v5432 = vshrl.u32 %v5426, 3 (stack45)
        %v5433 = vor.u32 %v5432, %v5431 (stack46)
        %v5434 = vxor.u32 %v5433, %v5429 (stack47)
        %v5437 = vadd.s32 %v5434, %v5429 (stack39)
        %v5439 = vshll.u32 %v5434, 16 (stack44)
        %v5440 = vshrl.u32 %v5434, 16 (stack45)
        %v5441 = vor.u32 %v5440, %v5439 (stack46)
        %v5442 = vxor.u32 %v5441, %v5437 (stack47)
        %v5445 = vadd.s32 %v5442, %v5437 (stack39)
        %v5449 = vadd.s32 %v5445, %v9 (stack39)
        %v5451 = vshll.u32 %v5442, 24 (stack44)
        %v5452 = vshrl.u32 %v5442, 8 (stack45)
        %v5453 = vor.u32 %v5452, %v5451 (stack46)
        %v5454 = vxor.u32 %v5453, %v5445 (stack47)
        %v5457 = vadd.s32 %v5454, %v8 (stack39)
        %v5461 = vadd.s32 4, %v5457 (stack39)
        %v5465 = vadd.s32 %v5461, %v5449 (stack39)
        %v5467 = vshll.u32 %v5461, 13 (stack44)
        %v5468 = vshrl.u32 %v5461, 19 (stack45)
        %v5469 = vor.u32 %v5468, %v5467 (stack46)
        %v5470 = vxor.u32 %v5469, %v5465 (stack47)
        %v5473 = vadd.s32 %v5470, %v5465 (stack39)
        %v5475 = vshll.u32 %v5470, 15 (stack44)
        %v5476 = vshrl.u32 %v5470, 17 (stack45)
        %v5477 = vor.u32 %v5476, %v5475 (stack46)
        %v5478 = vxor.u32 %v5477, %v5473 (stack47)
        %v5481 = vadd.s32 %v5478, %v5473 (stack39)
        %v5483 = vshll.u32 %v5478, 26 (stack44)
        %v5484 = vshrl.u32 %v5478, 6 (stack45)
        %v5485 = vor.u32 %v5484, %v5483 (stack46)
        %v5486 = vxor.u32 %v5485, %v5481 (stack47)
        %v5489 = vadd.s32 %v5486, %v5481 (stack39)
        %v5493 = vadd.s32 %v5489, %v8 (stack39)
        %v5495 = vshll.u32 %v5486, 6 (stack44)
        %v5496 = vshrl.u32 %v5486, 26 (stack45)
        %v5497 = vor.u32 %v5496, %v5495 (stack46)
        %v5498 = vxor.u32 %v5497, %v5489 (stack47)
        %v5501 = vadd.s32 %v5498, %v10 (stack39)
        %v5505 = vadd.s32 5, %v5501 (stack39)
        %v5507 = vxor.u32 %v5505, %v5493 (stack47)
        %v5508 = vand.u32.u8 255, %v5507 (stack48)
        %v5509 = vand.u32 65535, %v5508 (stack49)
        %v5510 = vshrl.u32 %v5509, 1 (stack50)
        %v5511 = vor.u32 16256, %v5510 (stack46)
        %v5512 = vand.u32.u16 65535, %v5511 (stack51)
        %v119772 = vadd.low.f32.bf16 -1.0, %v5512 (stack52)
        %v5521 = vmul.f32 2.0, %v119772 (stack53)
        %v5525 = vadd.f32 -0.99609375, %v5521 (stack52)
        %v5529 = vmax.f32 %v5525, -0.99609375 (stack54)
        %v5531 = vand.u32 2147483647, %v5529 (stack55)
        %vm5534 = vcmp.eq.f32.partialorder %v5531, 1.0 (stack56)
        %v5539 = vmul.f32 inf, %v5529 (stack53)
        %v5541 = vxor.u32 2147483648, %v5529 (stack57)
        %v5544 = vmul.f32 %v5541, %v5529 (stack53)
        %v5546 = vadd.f32 1.0, %v5544 (stack58)
        %v5547 = vlog2.pop %v5546 (stack59)
        %v5548 = vmul.f32 0.6931472, %v5547 (stack60)
        %v5549 = vmul.f32 -0.5, %v5544 (stack61)
        %v5550 = vadd.f32 1.0, %v5549 (stack62)
        %v5551 = vmul.f32 %v5550, %v5544 (stack63)
        %v5552 = vand.u32 2147483647, %v5544 (stack64)
        %vm5553 = vcmp.lt.f32.partialorder %v5552, 0.0004427343 (stack65)
        %v5554 = vsel /*vm=*/%vm5553, /*on_true_vy=*/%v5551, /*on_false_vx=*/%v5548 (stack66)
        %v5555 = vxor.u32 2147483648, %v5554 (stack57)
        %vm5558 = vcmp.lt.f32.partialorder %v5555, 5.0 (stack56)
        %v5563 = vsel /*vm=*/%vm5558, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v5567 = vsel /*vm=*/%vm5558, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v5571 = vsel /*vm=*/%vm5558, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v5575 = vsel /*vm=*/%vm5558, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v5579 = vsel /*vm=*/%vm5558, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v5583 = vsel /*vm=*/%vm5558, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v5587 = vsel /*vm=*/%vm5558, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v5591 = vsel /*vm=*/%vm5558, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v5595 = vsel /*vm=*/%vm5558, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v5599 = vadd.f32 -2.5, %v5555 (stack52)
        %v5601 = vrsqrt.pop %v5555 (stack67)
        %v5602 = vmul.f32 %v5601, %v5555 (stack68)
        %vm5603 = vcmp.eq.f32.partialorder %v5555, inf (stack69)
        %v5604 = vsel /*vm=*/%vm5603, /*on_true_vy=*/%v5555, /*on_false_vx=*/%v5602 (stack70)
        %vm5605 = vcmp.eq.f32.partialorder %v5555, 0.0 (stack71)
        %v5606 = vand.u32 2147483648, %v5555 (stack72)
        %v5607 = vsel /*vm=*/%vm5605, /*on_true_vy=*/%v5606, /*on_false_vx=*/%v5604 (stack73)
        %v5610 = vadd.f32 -3.0, %v5607 (stack52)
        %v5614 = vsel /*vm=*/%vm5558, /*on_true_vy=*/%v5599, /*on_false_vx=*/%v5610 (stack43)
        %v5618 = vmul.f32 %v5614, %v5595 (stack53)
        %v5622 = vadd.f32 %v5618, %v5591 (stack52)
        %v5626 = vmul.f32 %v5622, %v5614 (stack53)
        %v5630 = vadd.f32 %v5626, %v5587 (stack52)
        %v5634 = vmul.f32 %v5630, %v5614 (stack53)
        %v5638 = vadd.f32 %v5634, %v5583 (stack52)
        %v5642 = vmul.f32 %v5638, %v5614 (stack53)
        %v5646 = vadd.f32 %v5642, %v5579 (stack52)
        %v5650 = vmul.f32 %v5646, %v5614 (stack53)
        %v5654 = vadd.f32 %v5650, %v5575 (stack52)
        %v5658 = vmul.f32 %v5654, %v5614 (stack53)
        %v5662 = vadd.f32 %v5658, %v5571 (stack52)
        %v5666 = vmul.f32 %v5662, %v5614 (stack53)
        %v5670 = vadd.f32 %v5666, %v5567 (stack52)
        %v5674 = vmul.f32 %v5670, %v5614 (stack53)
        %v5678 = vadd.f32 %v5674, %v5563 (stack52)
        %v5682 = vmul.f32 %v5678, %v5529 (stack53)
        %v5686 = vsel /*vm=*/%vm5534, /*on_true_vy=*/%v5539, /*on_false_vx=*/%v5682 (stack43)
        %v5690 = vmul.f32 1.4140625, %v5686 (stack53)
        %v5693 = vpack.c.bf16 0.0, %v5690 (stack74)
        %119773 = vst [vmem:[%s280 + $0x104] sm:$0xf] /*vst_source=*/%v5693 (stack75)
        %v5697 = vadd.s32 %v4311, %v1868 (stack39)
        %v5707 = vadd.s32 %v5697, %v415 (stack39)
        %vm5711 = vcmp.lt.u32.totalorder %v5707, %v5697 (stack42)
        %vm5716 = vcmp.lt.u32.totalorder %v5697, %v1868 (stack42)
        %v5721 = vadd.s32 %v4294, %v1855 (stack39)
        %v5725 = vadd.s32 1, %v5721 (stack39)
        %v5729 = vsel /*vm=*/%vm5716, /*on_true_vy=*/%v5725, /*on_false_vx=*/%v5721 (stack43)
        %v5733 = vadd.s32 1, %v5729 (stack39)
        %v5737 = vsel /*vm=*/%vm5711, /*on_true_vy=*/%v5733, /*on_false_vx=*/%v5729 (stack43)
        %v5742 = vadd.s32 %v5737, %v10 (stack39)
        %v5746 = vadd.s32 %v5707, %v9 (stack39)
        %v5750 = vadd.s32 %v5746, %v5742 (stack39)
        %v5752 = vshll.u32 %v5746, 13 (stack44)
        %v5753 = vshrl.u32 %v5746, 19 (stack45)
        %v5754 = vor.u32 %v5753, %v5752 (stack46)
        %v5755 = vxor.u32 %v5754, %v5750 (stack47)
        %v5758 = vadd.s32 %v5755, %v5750 (stack39)
        %v5760 = vshll.u32 %v5755, 15 (stack44)
        %v5761 = vshrl.u32 %v5755, 17 (stack45)
        %v5762 = vor.u32 %v5761, %v5760 (stack46)
        %v5763 = vxor.u32 %v5762, %v5758 (stack47)
        %v5766 = vadd.s32 %v5763, %v5758 (stack39)
        %v5768 = vshll.u32 %v5763, 26 (stack44)
        %v5769 = vshrl.u32 %v5763, 6 (stack45)
        %v5770 = vor.u32 %v5769, %v5768 (stack46)
        %v5771 = vxor.u32 %v5770, %v5766 (stack47)
        %v5774 = vadd.s32 %v5771, %v5766 (stack39)
        %v5778 = vadd.s32 %v5774, %v9 (stack39)
        %v5780 = vshll.u32 %v5771, 6 (stack44)
        %v5781 = vshrl.u32 %v5771, 26 (stack45)
        %v5782 = vor.u32 %v5781, %v5780 (stack46)
        %v5783 = vxor.u32 %v5782, %v5774 (stack47)
        %v5786 = vadd.s32 %v5783, %v8 (stack39)
        %v5790 = vadd.s32 1, %v5786 (stack39)
        %v5794 = vadd.s32 %v5790, %v5778 (stack39)
        %v5796 = vshll.u32 %v5790, 17 (stack44)
        %v5797 = vshrl.u32 %v5790, 15 (stack45)
        %v5798 = vor.u32 %v5797, %v5796 (stack46)
        %v5799 = vxor.u32 %v5798, %v5794 (stack47)
        %v5802 = vadd.s32 %v5799, %v5794 (stack39)
        %v5804 = vshll.u32 %v5799, 29 (stack44)
        %v5805 = vshrl.u32 %v5799, 3 (stack45)
        %v5806 = vor.u32 %v5805, %v5804 (stack46)
        %v5807 = vxor.u32 %v5806, %v5802 (stack47)
        %v5810 = vadd.s32 %v5807, %v5802 (stack39)
        %v5812 = vshll.u32 %v5807, 16 (stack44)
        %v5813 = vshrl.u32 %v5807, 16 (stack45)
        %v5814 = vor.u32 %v5813, %v5812 (stack46)
        %v5815 = vxor.u32 %v5814, %v5810 (stack47)
        %v5818 = vadd.s32 %v5815, %v5810 (stack39)
        %v5822 = vadd.s32 %v5818, %v8 (stack39)
        %v5824 = vshll.u32 %v5815, 24 (stack44)
        %v5825 = vshrl.u32 %v5815, 8 (stack45)
        %v5826 = vor.u32 %v5825, %v5824 (stack46)
        %v5827 = vxor.u32 %v5826, %v5818 (stack47)
        %v5830 = vadd.s32 %v5827, %v10 (stack39)
        %v5834 = vadd.s32 2, %v5830 (stack39)
        %v5838 = vadd.s32 %v5834, %v5822 (stack39)
        %v5840 = vshll.u32 %v5834, 13 (stack44)
        %v5841 = vshrl.u32 %v5834, 19 (stack45)
        %v5842 = vor.u32 %v5841, %v5840 (stack46)
        %v5843 = vxor.u32 %v5842, %v5838 (stack47)
        %v5846 = vadd.s32 %v5843, %v5838 (stack39)
        %v5848 = vshll.u32 %v5843, 15 (stack44)
        %v5849 = vshrl.u32 %v5843, 17 (stack45)
        %v5850 = vor.u32 %v5849, %v5848 (stack46)
        %v5851 = vxor.u32 %v5850, %v5846 (stack47)
        %v5854 = vadd.s32 %v5851, %v5846 (stack39)
        %v5856 = vshll.u32 %v5851, 26 (stack44)
        %v5857 = vshrl.u32 %v5851, 6 (stack45)
        %v5858 = vor.u32 %v5857, %v5856 (stack46)
        %v5859 = vxor.u32 %v5858, %v5854 (stack47)
        %v5862 = vadd.s32 %v5859, %v5854 (stack39)
        %v5866 = vadd.s32 %v5862, %v10 (stack39)
        %v5868 = vshll.u32 %v5859, 6 (stack44)
        %v5869 = vshrl.u32 %v5859, 26 (stack45)
        %v5870 = vor.u32 %v5869, %v5868 (stack46)
        %v5871 = vxor.u32 %v5870, %v5862 (stack47)
        %v5874 = vadd.s32 %v5871, %v9 (stack39)
        %v5878 = vadd.s32 3, %v5874 (stack39)
        %v5882 = vadd.s32 %v5878, %v5866 (stack39)
        %v5884 = vshll.u32 %v5878, 17 (stack44)
        %v5885 = vshrl.u32 %v5878, 15 (stack45)
        %v5886 = vor.u32 %v5885, %v5884 (stack46)
        %v5887 = vxor.u32 %v5886, %v5882 (stack47)
        %v5890 = vadd.s32 %v5887, %v5882 (stack39)
        %v5892 = vshll.u32 %v5887, 29 (stack44)
        %v5893 = vshrl.u32 %v5887, 3 (stack45)
        %v5894 = vor.u32 %v5893, %v5892 (stack46)
        %v5895 = vxor.u32 %v5894, %v5890 (stack47)
        %v5898 = vadd.s32 %v5895, %v5890 (stack39)
        %v5900 = vshll.u32 %v5895, 16 (stack44)
        %v5901 = vshrl.u32 %v5895, 16 (stack45)
        %v5902 = vor.u32 %v5901, %v5900 (stack46)
        %v5903 = vxor.u32 %v5902, %v5898 (stack47)
        %v5906 = vadd.s32 %v5903, %v5898 (stack39)
        %v5910 = vadd.s32 %v5906, %v9 (stack39)
        %v5912 = vshll.u32 %v5903, 24 (stack44)
        %v5913 = vshrl.u32 %v5903, 8 (stack45)
        %v5914 = vor.u32 %v5913, %v5912 (stack46)
        %v5915 = vxor.u32 %v5914, %v5906 (stack47)
        %v5918 = vadd.s32 %v5915, %v8 (stack39)
        %v5922 = vadd.s32 4, %v5918 (stack39)
        %v5926 = vadd.s32 %v5922, %v5910 (stack39)
        %v5928 = vshll.u32 %v5922, 13 (stack44)
        %v5929 = vshrl.u32 %v5922, 19 (stack45)
        %v5930 = vor.u32 %v5929, %v5928 (stack46)
        %v5931 = vxor.u32 %v5930, %v5926 (stack47)
        %v5934 = vadd.s32 %v5931, %v5926 (stack39)
        %v5936 = vshll.u32 %v5931, 15 (stack44)
        %v5937 = vshrl.u32 %v5931, 17 (stack45)
        %v5938 = vor.u32 %v5937, %v5936 (stack46)
        %v5939 = vxor.u32 %v5938, %v5934 (stack47)
        %v5942 = vadd.s32 %v5939, %v5934 (stack39)
        %v5944 = vshll.u32 %v5939, 26 (stack44)
        %v5945 = vshrl.u32 %v5939, 6 (stack45)
        %v5946 = vor.u32 %v5945, %v5944 (stack46)
        %v5947 = vxor.u32 %v5946, %v5942 (stack47)
        %v5950 = vadd.s32 %v5947, %v5942 (stack39)
        %v5954 = vadd.s32 %v5950, %v8 (stack39)
        %v5956 = vshll.u32 %v5947, 6 (stack44)
        %v5957 = vshrl.u32 %v5947, 26 (stack45)
        %v5958 = vor.u32 %v5957, %v5956 (stack46)
        %v5959 = vxor.u32 %v5958, %v5950 (stack47)
        %v5962 = vadd.s32 %v5959, %v10 (stack39)
        %v5966 = vadd.s32 5, %v5962 (stack39)
        %v5968 = vxor.u32 %v5966, %v5954 (stack47)
        %v5969 = vand.u32.u8 255, %v5968 (stack48)
        %v5970 = vand.u32 65535, %v5969 (stack49)
        %v5971 = vshrl.u32 %v5970, 1 (stack50)
        %v5972 = vor.u32 16256, %v5971 (stack46)
        %v5973 = vand.u32.u16 65535, %v5972 (stack51)
        %v119774 = vadd.low.f32.bf16 -1.0, %v5973 (stack52)
        %v5982 = vmul.f32 2.0, %v119774 (stack53)
        %v5986 = vadd.f32 -0.99609375, %v5982 (stack52)
        %v5990 = vmax.f32 %v5986, -0.99609375 (stack54)
        %v5992 = vand.u32 2147483647, %v5990 (stack55)
        %vm5995 = vcmp.eq.f32.partialorder %v5992, 1.0 (stack56)
        %v6000 = vmul.f32 inf, %v5990 (stack53)
        %v6002 = vxor.u32 2147483648, %v5990 (stack57)
        %v6005 = vmul.f32 %v6002, %v5990 (stack53)
        %v6007 = vadd.f32 1.0, %v6005 (stack58)
        %v6008 = vlog2.pop %v6007 (stack59)
        %v6009 = vmul.f32 0.6931472, %v6008 (stack60)
        %v6010 = vmul.f32 -0.5, %v6005 (stack61)
        %v6011 = vadd.f32 1.0, %v6010 (stack62)
        %v6012 = vmul.f32 %v6011, %v6005 (stack63)
        %v6013 = vand.u32 2147483647, %v6005 (stack64)
        %vm6014 = vcmp.lt.f32.partialorder %v6013, 0.0004427343 (stack65)
        %v6015 = vsel /*vm=*/%vm6014, /*on_true_vy=*/%v6012, /*on_false_vx=*/%v6009 (stack66)
        %v6016 = vxor.u32 2147483648, %v6015 (stack57)
        %vm6019 = vcmp.lt.f32.partialorder %v6016, 5.0 (stack56)
        %v6024 = vsel /*vm=*/%vm6019, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v6028 = vsel /*vm=*/%vm6019, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v6032 = vsel /*vm=*/%vm6019, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v6036 = vsel /*vm=*/%vm6019, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v6040 = vsel /*vm=*/%vm6019, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v6044 = vsel /*vm=*/%vm6019, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v6048 = vsel /*vm=*/%vm6019, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v6052 = vsel /*vm=*/%vm6019, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v6056 = vsel /*vm=*/%vm6019, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v6060 = vadd.f32 -2.5, %v6016 (stack52)
        %v6062 = vrsqrt.pop %v6016 (stack67)
        %v6063 = vmul.f32 %v6062, %v6016 (stack68)
        %vm6064 = vcmp.eq.f32.partialorder %v6016, inf (stack69)
        %v6065 = vsel /*vm=*/%vm6064, /*on_true_vy=*/%v6016, /*on_false_vx=*/%v6063 (stack70)
        %vm6066 = vcmp.eq.f32.partialorder %v6016, 0.0 (stack71)
        %v6067 = vand.u32 2147483648, %v6016 (stack72)
        %v6068 = vsel /*vm=*/%vm6066, /*on_true_vy=*/%v6067, /*on_false_vx=*/%v6065 (stack73)
        %v6071 = vadd.f32 -3.0, %v6068 (stack52)
        %v6075 = vsel /*vm=*/%vm6019, /*on_true_vy=*/%v6060, /*on_false_vx=*/%v6071 (stack43)
        %v6079 = vmul.f32 %v6075, %v6056 (stack53)
        %v6083 = vadd.f32 %v6079, %v6052 (stack52)
        %v6087 = vmul.f32 %v6083, %v6075 (stack53)
        %v6091 = vadd.f32 %v6087, %v6048 (stack52)
        %v6095 = vmul.f32 %v6091, %v6075 (stack53)
        %v6099 = vadd.f32 %v6095, %v6044 (stack52)
        %v6103 = vmul.f32 %v6099, %v6075 (stack53)
        %v6107 = vadd.f32 %v6103, %v6040 (stack52)
        %v6111 = vmul.f32 %v6107, %v6075 (stack53)
        %v6115 = vadd.f32 %v6111, %v6036 (stack52)
        %v6119 = vmul.f32 %v6115, %v6075 (stack53)
        %v6123 = vadd.f32 %v6119, %v6032 (stack52)
        %v6127 = vmul.f32 %v6123, %v6075 (stack53)
        %v6131 = vadd.f32 %v6127, %v6028 (stack52)
        %v6135 = vmul.f32 %v6131, %v6075 (stack53)
        %v6139 = vadd.f32 %v6135, %v6024 (stack52)
        %v6143 = vmul.f32 %v6139, %v5990 (stack53)
        %v6147 = vsel /*vm=*/%vm5995, /*on_true_vy=*/%v6000, /*on_false_vx=*/%v6143 (stack43)
        %v6151 = vmul.f32 1.4140625, %v6147 (stack53)
        %v6154 = vpack.c.bf16 0.0, %v6151 (stack74)
        %119775 = vst [vmem:[%s280 + $0x184] sm:$0xf] /*vst_source=*/%v6154 (stack75)
        %v6158 = vadd.s32 %v4311, %v2355 (stack39)
        %v6168 = vadd.s32 %v6158, %v415 (stack39)
        %vm6172 = vcmp.lt.u32.totalorder %v6168, %v6158 (stack42)
        %vm6177 = vcmp.lt.u32.totalorder %v6158, %v2355 (stack42)
        %v6182 = vadd.s32 %v4294, %v2342 (stack39)
        %v6186 = vadd.s32 1, %v6182 (stack39)
        %v6190 = vsel /*vm=*/%vm6177, /*on_true_vy=*/%v6186, /*on_false_vx=*/%v6182 (stack43)
        %v6194 = vadd.s32 1, %v6190 (stack39)
        %v6198 = vsel /*vm=*/%vm6172, /*on_true_vy=*/%v6194, /*on_false_vx=*/%v6190 (stack43)
        %v6203 = vadd.s32 %v6198, %v10 (stack39)
        %v6207 = vadd.s32 %v6168, %v9 (stack39)
        %v6211 = vadd.s32 %v6207, %v6203 (stack39)
        %v6213 = vshll.u32 %v6207, 13 (stack44)
        %v6214 = vshrl.u32 %v6207, 19 (stack45)
        %v6215 = vor.u32 %v6214, %v6213 (stack46)
        %v6216 = vxor.u32 %v6215, %v6211 (stack47)
        %v6219 = vadd.s32 %v6216, %v6211 (stack39)
        %v6221 = vshll.u32 %v6216, 15 (stack44)
        %v6222 = vshrl.u32 %v6216, 17 (stack45)
        %v6223 = vor.u32 %v6222, %v6221 (stack46)
        %v6224 = vxor.u32 %v6223, %v6219 (stack47)
        %v6227 = vadd.s32 %v6224, %v6219 (stack39)
        %v6229 = vshll.u32 %v6224, 26 (stack44)
        %v6230 = vshrl.u32 %v6224, 6 (stack45)
        %v6231 = vor.u32 %v6230, %v6229 (stack46)
        %v6232 = vxor.u32 %v6231, %v6227 (stack47)
        %v6235 = vadd.s32 %v6232, %v6227 (stack39)
        %v6239 = vadd.s32 %v6235, %v9 (stack39)
        %v6241 = vshll.u32 %v6232, 6 (stack44)
        %v6242 = vshrl.u32 %v6232, 26 (stack45)
        %v6243 = vor.u32 %v6242, %v6241 (stack46)
        %v6244 = vxor.u32 %v6243, %v6235 (stack47)
        %v6247 = vadd.s32 %v6244, %v8 (stack39)
        %v6251 = vadd.s32 1, %v6247 (stack39)
        %v6255 = vadd.s32 %v6251, %v6239 (stack39)
        %v6257 = vshll.u32 %v6251, 17 (stack44)
        %v6258 = vshrl.u32 %v6251, 15 (stack45)
        %v6259 = vor.u32 %v6258, %v6257 (stack46)
        %v6260 = vxor.u32 %v6259, %v6255 (stack47)
        %v6263 = vadd.s32 %v6260, %v6255 (stack39)
        %v6265 = vshll.u32 %v6260, 29 (stack44)
        %v6266 = vshrl.u32 %v6260, 3 (stack45)
        %v6267 = vor.u32 %v6266, %v6265 (stack46)
        %v6268 = vxor.u32 %v6267, %v6263 (stack47)
        %v6271 = vadd.s32 %v6268, %v6263 (stack39)
        %v6273 = vshll.u32 %v6268, 16 (stack44)
        %v6274 = vshrl.u32 %v6268, 16 (stack45)
        %v6275 = vor.u32 %v6274, %v6273 (stack46)
        %v6276 = vxor.u32 %v6275, %v6271 (stack47)
        %v6279 = vadd.s32 %v6276, %v6271 (stack39)
        %v6283 = vadd.s32 %v6279, %v8 (stack39)
        %v6285 = vshll.u32 %v6276, 24 (stack44)
        %v6286 = vshrl.u32 %v6276, 8 (stack45)
        %v6287 = vor.u32 %v6286, %v6285 (stack46)
        %v6288 = vxor.u32 %v6287, %v6279 (stack47)
        %v6291 = vadd.s32 %v6288, %v10 (stack39)
        %v6295 = vadd.s32 2, %v6291 (stack39)
        %v6299 = vadd.s32 %v6295, %v6283 (stack39)
        %v6301 = vshll.u32 %v6295, 13 (stack44)
        %v6302 = vshrl.u32 %v6295, 19 (stack45)
        %v6303 = vor.u32 %v6302, %v6301 (stack46)
        %v6304 = vxor.u32 %v6303, %v6299 (stack47)
        %v6307 = vadd.s32 %v6304, %v6299 (stack39)
        %v6309 = vshll.u32 %v6304, 15 (stack44)
        %v6310 = vshrl.u32 %v6304, 17 (stack45)
        %v6311 = vor.u32 %v6310, %v6309 (stack46)
        %v6312 = vxor.u32 %v6311, %v6307 (stack47)
        %v6315 = vadd.s32 %v6312, %v6307 (stack39)
        %v6317 = vshll.u32 %v6312, 26 (stack44)
        %v6318 = vshrl.u32 %v6312, 6 (stack45)
        %v6319 = vor.u32 %v6318, %v6317 (stack46)
        %v6320 = vxor.u32 %v6319, %v6315 (stack47)
        %v6323 = vadd.s32 %v6320, %v6315 (stack39)
        %v6327 = vadd.s32 %v6323, %v10 (stack39)
        %v6329 = vshll.u32 %v6320, 6 (stack44)
        %v6330 = vshrl.u32 %v6320, 26 (stack45)
        %v6331 = vor.u32 %v6330, %v6329 (stack46)
        %v6332 = vxor.u32 %v6331, %v6323 (stack47)
        %v6335 = vadd.s32 %v6332, %v9 (stack39)
        %v6339 = vadd.s32 3, %v6335 (stack39)
        %v6343 = vadd.s32 %v6339, %v6327 (stack39)
        %v6345 = vshll.u32 %v6339, 17 (stack44)
        %v6346 = vshrl.u32 %v6339, 15 (stack45)
        %v6347 = vor.u32 %v6346, %v6345 (stack46)
        %v6348 = vxor.u32 %v6347, %v6343 (stack47)
        %v6351 = vadd.s32 %v6348, %v6343 (stack39)
        %v6353 = vshll.u32 %v6348, 29 (stack44)
        %v6354 = vshrl.u32 %v6348, 3 (stack45)
        %v6355 = vor.u32 %v6354, %v6353 (stack46)
        %v6356 = vxor.u32 %v6355, %v6351 (stack47)
        %v6359 = vadd.s32 %v6356, %v6351 (stack39)
        %v6361 = vshll.u32 %v6356, 16 (stack44)
        %v6362 = vshrl.u32 %v6356, 16 (stack45)
        %v6363 = vor.u32 %v6362, %v6361 (stack46)
        %v6364 = vxor.u32 %v6363, %v6359 (stack47)
        %v6367 = vadd.s32 %v6364, %v6359 (stack39)
        %v6371 = vadd.s32 %v6367, %v9 (stack39)
        %v6373 = vshll.u32 %v6364, 24 (stack44)
        %v6374 = vshrl.u32 %v6364, 8 (stack45)
        %v6375 = vor.u32 %v6374, %v6373 (stack46)
        %v6376 = vxor.u32 %v6375, %v6367 (stack47)
        %v6379 = vadd.s32 %v6376, %v8 (stack39)
        %v6383 = vadd.s32 4, %v6379 (stack39)
        %v6387 = vadd.s32 %v6383, %v6371 (stack39)
        %v6389 = vshll.u32 %v6383, 13 (stack44)
        %v6390 = vshrl.u32 %v6383, 19 (stack45)
        %v6391 = vor.u32 %v6390, %v6389 (stack46)
        %v6392 = vxor.u32 %v6391, %v6387 (stack47)
        %v6395 = vadd.s32 %v6392, %v6387 (stack39)
        %v6397 = vshll.u32 %v6392, 15 (stack44)
        %v6398 = vshrl.u32 %v6392, 17 (stack45)
        %v6399 = vor.u32 %v6398, %v6397 (stack46)
        %v6400 = vxor.u32 %v6399, %v6395 (stack47)
        %v6403 = vadd.s32 %v6400, %v6395 (stack39)
        %v6405 = vshll.u32 %v6400, 26 (stack44)
        %v6406 = vshrl.u32 %v6400, 6 (stack45)
        %v6407 = vor.u32 %v6406, %v6405 (stack46)
        %v6408 = vxor.u32 %v6407, %v6403 (stack47)
        %v6411 = vadd.s32 %v6408, %v6403 (stack39)
        %v6415 = vadd.s32 %v6411, %v8 (stack39)
        %v6417 = vshll.u32 %v6408, 6 (stack44)
        %v6418 = vshrl.u32 %v6408, 26 (stack45)
        %v6419 = vor.u32 %v6418, %v6417 (stack46)
        %v6420 = vxor.u32 %v6419, %v6411 (stack47)
        %v6423 = vadd.s32 %v6420, %v10 (stack39)
        %v6427 = vadd.s32 5, %v6423 (stack39)
        %v6429 = vxor.u32 %v6427, %v6415 (stack47)
        %v6430 = vand.u32.u8 255, %v6429 (stack48)
        %v6431 = vand.u32 65535, %v6430 (stack49)
        %v6432 = vshrl.u32 %v6431, 1 (stack50)
        %v6433 = vor.u32 16256, %v6432 (stack46)
        %v6434 = vand.u32.u16 65535, %v6433 (stack51)
        %v119776 = vadd.low.f32.bf16 -1.0, %v6434 (stack52)
        %v6443 = vmul.f32 2.0, %v119776 (stack53)
        %v6447 = vadd.f32 -0.99609375, %v6443 (stack52)
        %v6451 = vmax.f32 %v6447, -0.99609375 (stack54)
        %v6453 = vand.u32 2147483647, %v6451 (stack55)
        %vm6456 = vcmp.eq.f32.partialorder %v6453, 1.0 (stack56)
        %v6461 = vmul.f32 inf, %v6451 (stack53)
        %v6463 = vxor.u32 2147483648, %v6451 (stack57)
        %v6466 = vmul.f32 %v6463, %v6451 (stack53)
        %v6468 = vadd.f32 1.0, %v6466 (stack58)
        %v6469 = vlog2.pop %v6468 (stack59)
        %v6470 = vmul.f32 0.6931472, %v6469 (stack60)
        %v6471 = vmul.f32 -0.5, %v6466 (stack61)
        %v6472 = vadd.f32 1.0, %v6471 (stack62)
        %v6473 = vmul.f32 %v6472, %v6466 (stack63)
        %v6474 = vand.u32 2147483647, %v6466 (stack64)
        %vm6475 = vcmp.lt.f32.partialorder %v6474, 0.0004427343 (stack65)
        %v6476 = vsel /*vm=*/%vm6475, /*on_true_vy=*/%v6473, /*on_false_vx=*/%v6470 (stack66)
        %v6477 = vxor.u32 2147483648, %v6476 (stack57)
        %vm6480 = vcmp.lt.f32.partialorder %v6477, 5.0 (stack56)
        %v6485 = vsel /*vm=*/%vm6480, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v6489 = vsel /*vm=*/%vm6480, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v6493 = vsel /*vm=*/%vm6480, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v6497 = vsel /*vm=*/%vm6480, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v6501 = vsel /*vm=*/%vm6480, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v6505 = vsel /*vm=*/%vm6480, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v6509 = vsel /*vm=*/%vm6480, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v6513 = vsel /*vm=*/%vm6480, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v6517 = vsel /*vm=*/%vm6480, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v6521 = vadd.f32 -2.5, %v6477 (stack52)
        %v6523 = vrsqrt.pop %v6477 (stack67)
        %v6524 = vmul.f32 %v6523, %v6477 (stack68)
        %vm6525 = vcmp.eq.f32.partialorder %v6477, inf (stack69)
        %v6526 = vsel /*vm=*/%vm6525, /*on_true_vy=*/%v6477, /*on_false_vx=*/%v6524 (stack70)
        %vm6527 = vcmp.eq.f32.partialorder %v6477, 0.0 (stack71)
        %v6528 = vand.u32 2147483648, %v6477 (stack72)
        %v6529 = vsel /*vm=*/%vm6527, /*on_true_vy=*/%v6528, /*on_false_vx=*/%v6526 (stack73)
        %v6532 = vadd.f32 -3.0, %v6529 (stack52)
        %v6536 = vsel /*vm=*/%vm6480, /*on_true_vy=*/%v6521, /*on_false_vx=*/%v6532 (stack43)
        %v6540 = vmul.f32 %v6536, %v6517 (stack53)
        %v6544 = vadd.f32 %v6540, %v6513 (stack52)
        %v6548 = vmul.f32 %v6544, %v6536 (stack53)
        %v6552 = vadd.f32 %v6548, %v6509 (stack52)
        %v6556 = vmul.f32 %v6552, %v6536 (stack53)
        %v6560 = vadd.f32 %v6556, %v6505 (stack52)
        %v6564 = vmul.f32 %v6560, %v6536 (stack53)
        %v6568 = vadd.f32 %v6564, %v6501 (stack52)
        %v6572 = vmul.f32 %v6568, %v6536 (stack53)
        %v6576 = vadd.f32 %v6572, %v6497 (stack52)
        %v6580 = vmul.f32 %v6576, %v6536 (stack53)
        %v6584 = vadd.f32 %v6580, %v6493 (stack52)
        %v6588 = vmul.f32 %v6584, %v6536 (stack53)
        %v6592 = vadd.f32 %v6588, %v6489 (stack52)
        %v6596 = vmul.f32 %v6592, %v6536 (stack53)
        %v6600 = vadd.f32 %v6596, %v6485 (stack52)
        %v6604 = vmul.f32 %v6600, %v6451 (stack53)
        %v6608 = vsel /*vm=*/%vm6456, /*on_true_vy=*/%v6461, /*on_false_vx=*/%v6604 (stack43)
        %v6612 = vmul.f32 1.4140625, %v6608 (stack53)
        %v6615 = vpack.c.bf16 0.0, %v6612 (stack74)
        %119777 = vst [vmem:[%s280 + $0x204] sm:$0xf] /*vst_source=*/%v6615 (stack75)
        %v6619 = vadd.s32 %v4311, %v2842 (stack39)
        %v6629 = vadd.s32 %v6619, %v415 (stack39)
        %vm6633 = vcmp.lt.u32.totalorder %v6629, %v6619 (stack42)
        %vm6638 = vcmp.lt.u32.totalorder %v6619, %v2842 (stack42)
        %v6643 = vadd.s32 %v4294, %v2829 (stack39)
        %v6647 = vadd.s32 1, %v6643 (stack39)
        %v6651 = vsel /*vm=*/%vm6638, /*on_true_vy=*/%v6647, /*on_false_vx=*/%v6643 (stack43)
        %v6655 = vadd.s32 1, %v6651 (stack39)
        %v6659 = vsel /*vm=*/%vm6633, /*on_true_vy=*/%v6655, /*on_false_vx=*/%v6651 (stack43)
        %v6664 = vadd.s32 %v6659, %v10 (stack39)
        %v6668 = vadd.s32 %v6629, %v9 (stack39)
        %v6672 = vadd.s32 %v6668, %v6664 (stack39)
        %v6674 = vshll.u32 %v6668, 13 (stack44)
        %v6675 = vshrl.u32 %v6668, 19 (stack45)
        %v6676 = vor.u32 %v6675, %v6674 (stack46)
        %v6677 = vxor.u32 %v6676, %v6672 (stack47)
        %v6680 = vadd.s32 %v6677, %v6672 (stack39)
        %v6682 = vshll.u32 %v6677, 15 (stack44)
        %v6683 = vshrl.u32 %v6677, 17 (stack45)
        %v6684 = vor.u32 %v6683, %v6682 (stack46)
        %v6685 = vxor.u32 %v6684, %v6680 (stack47)
        %v6688 = vadd.s32 %v6685, %v6680 (stack39)
        %v6690 = vshll.u32 %v6685, 26 (stack44)
        %v6691 = vshrl.u32 %v6685, 6 (stack45)
        %v6692 = vor.u32 %v6691, %v6690 (stack46)
        %v6693 = vxor.u32 %v6692, %v6688 (stack47)
        %v6696 = vadd.s32 %v6693, %v6688 (stack39)
        %v6700 = vadd.s32 %v6696, %v9 (stack39)
        %v6702 = vshll.u32 %v6693, 6 (stack44)
        %v6703 = vshrl.u32 %v6693, 26 (stack45)
        %v6704 = vor.u32 %v6703, %v6702 (stack46)
        %v6705 = vxor.u32 %v6704, %v6696 (stack47)
        %v6708 = vadd.s32 %v6705, %v8 (stack39)
        %v6712 = vadd.s32 1, %v6708 (stack39)
        %v6716 = vadd.s32 %v6712, %v6700 (stack39)
        %v6718 = vshll.u32 %v6712, 17 (stack44)
        %v6719 = vshrl.u32 %v6712, 15 (stack45)
        %v6720 = vor.u32 %v6719, %v6718 (stack46)
        %v6721 = vxor.u32 %v6720, %v6716 (stack47)
        %v6724 = vadd.s32 %v6721, %v6716 (stack39)
        %v6726 = vshll.u32 %v6721, 29 (stack44)
        %v6727 = vshrl.u32 %v6721, 3 (stack45)
        %v6728 = vor.u32 %v6727, %v6726 (stack46)
        %v6729 = vxor.u32 %v6728, %v6724 (stack47)
        %v6732 = vadd.s32 %v6729, %v6724 (stack39)
        %v6734 = vshll.u32 %v6729, 16 (stack44)
        %v6735 = vshrl.u32 %v6729, 16 (stack45)
        %v6736 = vor.u32 %v6735, %v6734 (stack46)
        %v6737 = vxor.u32 %v6736, %v6732 (stack47)
        %v6740 = vadd.s32 %v6737, %v6732 (stack39)
        %v6744 = vadd.s32 %v6740, %v8 (stack39)
        %v6746 = vshll.u32 %v6737, 24 (stack44)
        %v6747 = vshrl.u32 %v6737, 8 (stack45)
        %v6748 = vor.u32 %v6747, %v6746 (stack46)
        %v6749 = vxor.u32 %v6748, %v6740 (stack47)
        %v6752 = vadd.s32 %v6749, %v10 (stack39)
        %v6756 = vadd.s32 2, %v6752 (stack39)
        %v6760 = vadd.s32 %v6756, %v6744 (stack39)
        %v6762 = vshll.u32 %v6756, 13 (stack44)
        %v6763 = vshrl.u32 %v6756, 19 (stack45)
        %v6764 = vor.u32 %v6763, %v6762 (stack46)
        %v6765 = vxor.u32 %v6764, %v6760 (stack47)
        %v6768 = vadd.s32 %v6765, %v6760 (stack39)
        %v6770 = vshll.u32 %v6765, 15 (stack44)
        %v6771 = vshrl.u32 %v6765, 17 (stack45)
        %v6772 = vor.u32 %v6771, %v6770 (stack46)
        %v6773 = vxor.u32 %v6772, %v6768 (stack47)
        %v6776 = vadd.s32 %v6773, %v6768 (stack39)
        %v6778 = vshll.u32 %v6773, 26 (stack44)
        %v6779 = vshrl.u32 %v6773, 6 (stack45)
        %v6780 = vor.u32 %v6779, %v6778 (stack46)
        %v6781 = vxor.u32 %v6780, %v6776 (stack47)
        %v6784 = vadd.s32 %v6781, %v6776 (stack39)
        %v6788 = vadd.s32 %v6784, %v10 (stack39)
        %v6790 = vshll.u32 %v6781, 6 (stack44)
        %v6791 = vshrl.u32 %v6781, 26 (stack45)
        %v6792 = vor.u32 %v6791, %v6790 (stack46)
        %v6793 = vxor.u32 %v6792, %v6784 (stack47)
        %v6796 = vadd.s32 %v6793, %v9 (stack39)
        %v6800 = vadd.s32 3, %v6796 (stack39)
        %v6804 = vadd.s32 %v6800, %v6788 (stack39)
        %v6806 = vshll.u32 %v6800, 17 (stack44)
        %v6807 = vshrl.u32 %v6800, 15 (stack45)
        %v6808 = vor.u32 %v6807, %v6806 (stack46)
        %v6809 = vxor.u32 %v6808, %v6804 (stack47)
        %v6812 = vadd.s32 %v6809, %v6804 (stack39)
        %v6814 = vshll.u32 %v6809, 29 (stack44)
        %v6815 = vshrl.u32 %v6809, 3 (stack45)
        %v6816 = vor.u32 %v6815, %v6814 (stack46)
        %v6817 = vxor.u32 %v6816, %v6812 (stack47)
        %v6820 = vadd.s32 %v6817, %v6812 (stack39)
        %v6822 = vshll.u32 %v6817, 16 (stack44)
        %v6823 = vshrl.u32 %v6817, 16 (stack45)
        %v6824 = vor.u32 %v6823, %v6822 (stack46)
        %v6825 = vxor.u32 %v6824, %v6820 (stack47)
        %v6828 = vadd.s32 %v6825, %v6820 (stack39)
        %v6832 = vadd.s32 %v6828, %v9 (stack39)
        %v6834 = vshll.u32 %v6825, 24 (stack44)
        %v6835 = vshrl.u32 %v6825, 8 (stack45)
        %v6836 = vor.u32 %v6835, %v6834 (stack46)
        %v6837 = vxor.u32 %v6836, %v6828 (stack47)
        %v6840 = vadd.s32 %v6837, %v8 (stack39)
        %v6844 = vadd.s32 4, %v6840 (stack39)
        %v6848 = vadd.s32 %v6844, %v6832 (stack39)
        %v6850 = vshll.u32 %v6844, 13 (stack44)
        %v6851 = vshrl.u32 %v6844, 19 (stack45)
        %v6852 = vor.u32 %v6851, %v6850 (stack46)
        %v6853 = vxor.u32 %v6852, %v6848 (stack47)
        %v6856 = vadd.s32 %v6853, %v6848 (stack39)
        %v6858 = vshll.u32 %v6853, 15 (stack44)
        %v6859 = vshrl.u32 %v6853, 17 (stack45)
        %v6860 = vor.u32 %v6859, %v6858 (stack46)
        %v6861 = vxor.u32 %v6860, %v6856 (stack47)
        %v6864 = vadd.s32 %v6861, %v6856 (stack39)
        %v6866 = vshll.u32 %v6861, 26 (stack44)
        %v6867 = vshrl.u32 %v6861, 6 (stack45)
        %v6868 = vor.u32 %v6867, %v6866 (stack46)
        %v6869 = vxor.u32 %v6868, %v6864 (stack47)
        %v6872 = vadd.s32 %v6869, %v6864 (stack39)
        %v6876 = vadd.s32 %v6872, %v8 (stack39)
        %v6878 = vshll.u32 %v6869, 6 (stack44)
        %v6879 = vshrl.u32 %v6869, 26 (stack45)
        %v6880 = vor.u32 %v6879, %v6878 (stack46)
        %v6881 = vxor.u32 %v6880, %v6872 (stack47)
        %v6884 = vadd.s32 %v6881, %v10 (stack39)
        %v6888 = vadd.s32 5, %v6884 (stack39)
        %v6890 = vxor.u32 %v6888, %v6876 (stack47)
        %v6891 = vand.u32.u8 255, %v6890 (stack48)
        %v6892 = vand.u32 65535, %v6891 (stack49)
        %v6893 = vshrl.u32 %v6892, 1 (stack50)
        %v6894 = vor.u32 16256, %v6893 (stack46)
        %v6895 = vand.u32.u16 65535, %v6894 (stack51)
        %v119778 = vadd.low.f32.bf16 -1.0, %v6895 (stack52)
        %v6904 = vmul.f32 2.0, %v119778 (stack53)
        %v6908 = vadd.f32 -0.99609375, %v6904 (stack52)
        %v6912 = vmax.f32 %v6908, -0.99609375 (stack54)
        %v6914 = vand.u32 2147483647, %v6912 (stack55)
        %vm6917 = vcmp.eq.f32.partialorder %v6914, 1.0 (stack56)
        %v6922 = vmul.f32 inf, %v6912 (stack53)
        %v6924 = vxor.u32 2147483648, %v6912 (stack57)
        %v6927 = vmul.f32 %v6924, %v6912 (stack53)
        %v6929 = vadd.f32 1.0, %v6927 (stack58)
        %v6930 = vlog2.pop %v6929 (stack59)
        %v6931 = vmul.f32 0.6931472, %v6930 (stack60)
        %v6932 = vmul.f32 -0.5, %v6927 (stack61)
        %v6933 = vadd.f32 1.0, %v6932 (stack62)
        %v6934 = vmul.f32 %v6933, %v6927 (stack63)
        %v6935 = vand.u32 2147483647, %v6927 (stack64)
        %vm6936 = vcmp.lt.f32.partialorder %v6935, 0.0004427343 (stack65)
        %v6937 = vsel /*vm=*/%vm6936, /*on_true_vy=*/%v6934, /*on_false_vx=*/%v6931 (stack66)
        %v6938 = vxor.u32 2147483648, %v6937 (stack57)
        %vm6941 = vcmp.lt.f32.partialorder %v6938, 5.0 (stack56)
        %v6946 = vsel /*vm=*/%vm6941, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v6950 = vsel /*vm=*/%vm6941, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v6954 = vsel /*vm=*/%vm6941, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v6958 = vsel /*vm=*/%vm6941, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v6962 = vsel /*vm=*/%vm6941, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v6966 = vsel /*vm=*/%vm6941, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v6970 = vsel /*vm=*/%vm6941, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v6974 = vsel /*vm=*/%vm6941, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v6978 = vsel /*vm=*/%vm6941, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v6982 = vadd.f32 -2.5, %v6938 (stack52)
        %v6984 = vrsqrt.pop %v6938 (stack67)
        %v6985 = vmul.f32 %v6984, %v6938 (stack68)
        %vm6986 = vcmp.eq.f32.partialorder %v6938, inf (stack69)
        %v6987 = vsel /*vm=*/%vm6986, /*on_true_vy=*/%v6938, /*on_false_vx=*/%v6985 (stack70)
        %vm6988 = vcmp.eq.f32.partialorder %v6938, 0.0 (stack71)
        %v6989 = vand.u32 2147483648, %v6938 (stack72)
        %v6990 = vsel /*vm=*/%vm6988, /*on_true_vy=*/%v6989, /*on_false_vx=*/%v6987 (stack73)
        %v6993 = vadd.f32 -3.0, %v6990 (stack52)
        %v6997 = vsel /*vm=*/%vm6941, /*on_true_vy=*/%v6982, /*on_false_vx=*/%v6993 (stack43)
        %v7001 = vmul.f32 %v6997, %v6978 (stack53)
        %v7005 = vadd.f32 %v7001, %v6974 (stack52)
        %v7009 = vmul.f32 %v7005, %v6997 (stack53)
        %v7013 = vadd.f32 %v7009, %v6970 (stack52)
        %v7017 = vmul.f32 %v7013, %v6997 (stack53)
        %v7021 = vadd.f32 %v7017, %v6966 (stack52)
        %v7025 = vmul.f32 %v7021, %v6997 (stack53)
        %v7029 = vadd.f32 %v7025, %v6962 (stack52)
        %v7033 = vmul.f32 %v7029, %v6997 (stack53)
        %v7037 = vadd.f32 %v7033, %v6958 (stack52)
        %v7041 = vmul.f32 %v7037, %v6997 (stack53)
        %v7045 = vadd.f32 %v7041, %v6954 (stack52)
        %v7049 = vmul.f32 %v7045, %v6997 (stack53)
        %v7053 = vadd.f32 %v7049, %v6950 (stack52)
        %v7057 = vmul.f32 %v7053, %v6997 (stack53)
        %v7061 = vadd.f32 %v7057, %v6946 (stack52)
        %v7065 = vmul.f32 %v7061, %v6912 (stack53)
        %v7069 = vsel /*vm=*/%vm6917, /*on_true_vy=*/%v6922, /*on_false_vx=*/%v7065 (stack43)
        %v7073 = vmul.f32 1.4140625, %v7069 (stack53)
        %v7076 = vpack.c.bf16 0.0, %v7073 (stack74)
        %119779 = vst [vmem:[%s280 + $0x284] sm:$0xf] /*vst_source=*/%v7076 (stack75)
        %v7080 = vadd.s32 %v4311, %v3329 (stack39)
        %v7090 = vadd.s32 %v7080, %v415 (stack39)
        %vm7094 = vcmp.lt.u32.totalorder %v7090, %v7080 (stack42)
        %vm7099 = vcmp.lt.u32.totalorder %v7080, %v3329 (stack42)
        %v7104 = vadd.s32 %v4294, %v3316 (stack39)
        %v7108 = vadd.s32 1, %v7104 (stack39)
        %v7112 = vsel /*vm=*/%vm7099, /*on_true_vy=*/%v7108, /*on_false_vx=*/%v7104 (stack43)
        %v7116 = vadd.s32 1, %v7112 (stack39)
        %v7120 = vsel /*vm=*/%vm7094, /*on_true_vy=*/%v7116, /*on_false_vx=*/%v7112 (stack43)
        %v7125 = vadd.s32 %v7120, %v10 (stack39)
        %v7129 = vadd.s32 %v7090, %v9 (stack39)
        %v7133 = vadd.s32 %v7129, %v7125 (stack39)
        %v7135 = vshll.u32 %v7129, 13 (stack44)
        %v7136 = vshrl.u32 %v7129, 19 (stack45)
        %v7137 = vor.u32 %v7136, %v7135 (stack46)
        %v7138 = vxor.u32 %v7137, %v7133 (stack47)
        %v7141 = vadd.s32 %v7138, %v7133 (stack39)
        %v7143 = vshll.u32 %v7138, 15 (stack44)
        %v7144 = vshrl.u32 %v7138, 17 (stack45)
        %v7145 = vor.u32 %v7144, %v7143 (stack46)
        %v7146 = vxor.u32 %v7145, %v7141 (stack47)
        %v7149 = vadd.s32 %v7146, %v7141 (stack39)
        %v7151 = vshll.u32 %v7146, 26 (stack44)
        %v7152 = vshrl.u32 %v7146, 6 (stack45)
        %v7153 = vor.u32 %v7152, %v7151 (stack46)
        %v7154 = vxor.u32 %v7153, %v7149 (stack47)
        %v7157 = vadd.s32 %v7154, %v7149 (stack39)
        %v7161 = vadd.s32 %v7157, %v9 (stack39)
        %v7163 = vshll.u32 %v7154, 6 (stack44)
        %v7164 = vshrl.u32 %v7154, 26 (stack45)
        %v7165 = vor.u32 %v7164, %v7163 (stack46)
        %v7166 = vxor.u32 %v7165, %v7157 (stack47)
        %v7169 = vadd.s32 %v7166, %v8 (stack39)
        %v7173 = vadd.s32 1, %v7169 (stack39)
        %v7177 = vadd.s32 %v7173, %v7161 (stack39)
        %v7179 = vshll.u32 %v7173, 17 (stack44)
        %v7180 = vshrl.u32 %v7173, 15 (stack45)
        %v7181 = vor.u32 %v7180, %v7179 (stack46)
        %v7182 = vxor.u32 %v7181, %v7177 (stack47)
        %v7185 = vadd.s32 %v7182, %v7177 (stack39)
        %v7187 = vshll.u32 %v7182, 29 (stack44)
        %v7188 = vshrl.u32 %v7182, 3 (stack45)
        %v7189 = vor.u32 %v7188, %v7187 (stack46)
        %v7190 = vxor.u32 %v7189, %v7185 (stack47)
        %v7193 = vadd.s32 %v7190, %v7185 (stack39)
        %v7195 = vshll.u32 %v7190, 16 (stack44)
        %v7196 = vshrl.u32 %v7190, 16 (stack45)
        %v7197 = vor.u32 %v7196, %v7195 (stack46)
        %v7198 = vxor.u32 %v7197, %v7193 (stack47)
        %v7201 = vadd.s32 %v7198, %v7193 (stack39)
        %v7205 = vadd.s32 %v7201, %v8 (stack39)
        %v7207 = vshll.u32 %v7198, 24 (stack44)
        %v7208 = vshrl.u32 %v7198, 8 (stack45)
        %v7209 = vor.u32 %v7208, %v7207 (stack46)
        %v7210 = vxor.u32 %v7209, %v7201 (stack47)
        %v7213 = vadd.s32 %v7210, %v10 (stack39)
        %v7217 = vadd.s32 2, %v7213 (stack39)
        %v7221 = vadd.s32 %v7217, %v7205 (stack39)
        %v7223 = vshll.u32 %v7217, 13 (stack44)
        %v7224 = vshrl.u32 %v7217, 19 (stack45)
        %v7225 = vor.u32 %v7224, %v7223 (stack46)
        %v7226 = vxor.u32 %v7225, %v7221 (stack47)
        %v7229 = vadd.s32 %v7226, %v7221 (stack39)
        %v7231 = vshll.u32 %v7226, 15 (stack44)
        %v7232 = vshrl.u32 %v7226, 17 (stack45)
        %v7233 = vor.u32 %v7232, %v7231 (stack46)
        %v7234 = vxor.u32 %v7233, %v7229 (stack47)
        %v7237 = vadd.s32 %v7234, %v7229 (stack39)
        %v7239 = vshll.u32 %v7234, 26 (stack44)
        %v7240 = vshrl.u32 %v7234, 6 (stack45)
        %v7241 = vor.u32 %v7240, %v7239 (stack46)
        %v7242 = vxor.u32 %v7241, %v7237 (stack47)
        %v7245 = vadd.s32 %v7242, %v7237 (stack39)
        %v7249 = vadd.s32 %v7245, %v10 (stack39)
        %v7251 = vshll.u32 %v7242, 6 (stack44)
        %v7252 = vshrl.u32 %v7242, 26 (stack45)
        %v7253 = vor.u32 %v7252, %v7251 (stack46)
        %v7254 = vxor.u32 %v7253, %v7245 (stack47)
        %v7257 = vadd.s32 %v7254, %v9 (stack39)
        %v7261 = vadd.s32 3, %v7257 (stack39)
        %v7265 = vadd.s32 %v7261, %v7249 (stack39)
        %v7267 = vshll.u32 %v7261, 17 (stack44)
        %v7268 = vshrl.u32 %v7261, 15 (stack45)
        %v7269 = vor.u32 %v7268, %v7267 (stack46)
        %v7270 = vxor.u32 %v7269, %v7265 (stack47)
        %v7273 = vadd.s32 %v7270, %v7265 (stack39)
        %v7275 = vshll.u32 %v7270, 29 (stack44)
        %v7276 = vshrl.u32 %v7270, 3 (stack45)
        %v7277 = vor.u32 %v7276, %v7275 (stack46)
        %v7278 = vxor.u32 %v7277, %v7273 (stack47)
        %v7281 = vadd.s32 %v7278, %v7273 (stack39)
        %v7283 = vshll.u32 %v7278, 16 (stack44)
        %v7284 = vshrl.u32 %v7278, 16 (stack45)
        %v7285 = vor.u32 %v7284, %v7283 (stack46)
        %v7286 = vxor.u32 %v7285, %v7281 (stack47)
        %v7289 = vadd.s32 %v7286, %v7281 (stack39)
        %v7293 = vadd.s32 %v7289, %v9 (stack39)
        %v7295 = vshll.u32 %v7286, 24 (stack44)
        %v7296 = vshrl.u32 %v7286, 8 (stack45)
        %v7297 = vor.u32 %v7296, %v7295 (stack46)
        %v7298 = vxor.u32 %v7297, %v7289 (stack47)
        %v7301 = vadd.s32 %v7298, %v8 (stack39)
        %v7305 = vadd.s32 4, %v7301 (stack39)
        %v7309 = vadd.s32 %v7305, %v7293 (stack39)
        %v7311 = vshll.u32 %v7305, 13 (stack44)
        %v7312 = vshrl.u32 %v7305, 19 (stack45)
        %v7313 = vor.u32 %v7312, %v7311 (stack46)
        %v7314 = vxor.u32 %v7313, %v7309 (stack47)
        %v7317 = vadd.s32 %v7314, %v7309 (stack39)
        %v7319 = vshll.u32 %v7314, 15 (stack44)
        %v7320 = vshrl.u32 %v7314, 17 (stack45)
        %v7321 = vor.u32 %v7320, %v7319 (stack46)
        %v7322 = vxor.u32 %v7321, %v7317 (stack47)
        %v7325 = vadd.s32 %v7322, %v7317 (stack39)
        %v7327 = vshll.u32 %v7322, 26 (stack44)
        %v7328 = vshrl.u32 %v7322, 6 (stack45)
        %v7329 = vor.u32 %v7328, %v7327 (stack46)
        %v7330 = vxor.u32 %v7329, %v7325 (stack47)
        %v7333 = vadd.s32 %v7330, %v7325 (stack39)
        %v7337 = vadd.s32 %v7333, %v8 (stack39)
        %v7339 = vshll.u32 %v7330, 6 (stack44)
        %v7340 = vshrl.u32 %v7330, 26 (stack45)
        %v7341 = vor.u32 %v7340, %v7339 (stack46)
        %v7342 = vxor.u32 %v7341, %v7333 (stack47)
        %v7345 = vadd.s32 %v7342, %v10 (stack39)
        %v7349 = vadd.s32 5, %v7345 (stack39)
        %v7351 = vxor.u32 %v7349, %v7337 (stack47)
        %v7352 = vand.u32.u8 255, %v7351 (stack48)
        %v7353 = vand.u32 65535, %v7352 (stack49)
        %v7354 = vshrl.u32 %v7353, 1 (stack50)
        %v7355 = vor.u32 16256, %v7354 (stack46)
        %v7356 = vand.u32.u16 65535, %v7355 (stack51)
        %v119780 = vadd.low.f32.bf16 -1.0, %v7356 (stack52)
        %v7365 = vmul.f32 2.0, %v119780 (stack53)
        %v7369 = vadd.f32 -0.99609375, %v7365 (stack52)
        %v7373 = vmax.f32 %v7369, -0.99609375 (stack54)
        %v7375 = vand.u32 2147483647, %v7373 (stack55)
        %vm7378 = vcmp.eq.f32.partialorder %v7375, 1.0 (stack56)
        %v7383 = vmul.f32 inf, %v7373 (stack53)
        %v7385 = vxor.u32 2147483648, %v7373 (stack57)
        %v7388 = vmul.f32 %v7385, %v7373 (stack53)
        %v7390 = vadd.f32 1.0, %v7388 (stack58)
        %v7391 = vlog2.pop %v7390 (stack59)
        %v7392 = vmul.f32 0.6931472, %v7391 (stack60)
        %v7393 = vmul.f32 -0.5, %v7388 (stack61)
        %v7394 = vadd.f32 1.0, %v7393 (stack62)
        %v7395 = vmul.f32 %v7394, %v7388 (stack63)
        %v7396 = vand.u32 2147483647, %v7388 (stack64)
        %vm7397 = vcmp.lt.f32.partialorder %v7396, 0.0004427343 (stack65)
        %v7398 = vsel /*vm=*/%vm7397, /*on_true_vy=*/%v7395, /*on_false_vx=*/%v7392 (stack66)
        %v7399 = vxor.u32 2147483648, %v7398 (stack57)
        %vm7402 = vcmp.lt.f32.partialorder %v7399, 5.0 (stack56)
        %v7407 = vsel /*vm=*/%vm7402, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v7411 = vsel /*vm=*/%vm7402, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v7415 = vsel /*vm=*/%vm7402, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v7419 = vsel /*vm=*/%vm7402, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v7423 = vsel /*vm=*/%vm7402, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v7427 = vsel /*vm=*/%vm7402, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v7431 = vsel /*vm=*/%vm7402, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v7435 = vsel /*vm=*/%vm7402, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v7439 = vsel /*vm=*/%vm7402, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v7443 = vadd.f32 -2.5, %v7399 (stack52)
        %v7445 = vrsqrt.pop %v7399 (stack67)
        %v7446 = vmul.f32 %v7445, %v7399 (stack68)
        %vm7447 = vcmp.eq.f32.partialorder %v7399, inf (stack69)
        %v7448 = vsel /*vm=*/%vm7447, /*on_true_vy=*/%v7399, /*on_false_vx=*/%v7446 (stack70)
        %vm7449 = vcmp.eq.f32.partialorder %v7399, 0.0 (stack71)
        %v7450 = vand.u32 2147483648, %v7399 (stack72)
        %v7451 = vsel /*vm=*/%vm7449, /*on_true_vy=*/%v7450, /*on_false_vx=*/%v7448 (stack73)
        %v7454 = vadd.f32 -3.0, %v7451 (stack52)
        %v7458 = vsel /*vm=*/%vm7402, /*on_true_vy=*/%v7443, /*on_false_vx=*/%v7454 (stack43)
        %v7462 = vmul.f32 %v7458, %v7439 (stack53)
        %v7466 = vadd.f32 %v7462, %v7435 (stack52)
        %v7470 = vmul.f32 %v7466, %v7458 (stack53)
        %v7474 = vadd.f32 %v7470, %v7431 (stack52)
        %v7478 = vmul.f32 %v7474, %v7458 (stack53)
        %v7482 = vadd.f32 %v7478, %v7427 (stack52)
        %v7486 = vmul.f32 %v7482, %v7458 (stack53)
        %v7490 = vadd.f32 %v7486, %v7423 (stack52)
        %v7494 = vmul.f32 %v7490, %v7458 (stack53)
        %v7498 = vadd.f32 %v7494, %v7419 (stack52)
        %v7502 = vmul.f32 %v7498, %v7458 (stack53)
        %v7506 = vadd.f32 %v7502, %v7415 (stack52)
        %v7510 = vmul.f32 %v7506, %v7458 (stack53)
        %v7514 = vadd.f32 %v7510, %v7411 (stack52)
        %v7518 = vmul.f32 %v7514, %v7458 (stack53)
        %v7522 = vadd.f32 %v7518, %v7407 (stack52)
        %v7526 = vmul.f32 %v7522, %v7373 (stack53)
        %v7530 = vsel /*vm=*/%vm7378, /*on_true_vy=*/%v7383, /*on_false_vx=*/%v7526 (stack43)
        %v7534 = vmul.f32 1.4140625, %v7530 (stack53)
        %v7537 = vpack.c.bf16 0.0, %v7534 (stack74)
        %119781 = vst [vmem:[%s280 + $0x304] sm:$0xf] /*vst_source=*/%v7537 (stack75)
        %v7541 = vadd.s32 %v4311, %v3816 (stack39)
        %v7551 = vadd.s32 %v7541, %v415 (stack39)
        %vm7555 = vcmp.lt.u32.totalorder %v7551, %v7541 (stack42)
        %vm7560 = vcmp.lt.u32.totalorder %v7541, %v3816 (stack42)
        %v7565 = vadd.s32 %v4294, %v3803 (stack39)
        %v7569 = vadd.s32 1, %v7565 (stack39)
        %v7573 = vsel /*vm=*/%vm7560, /*on_true_vy=*/%v7569, /*on_false_vx=*/%v7565 (stack43)
        %v7577 = vadd.s32 1, %v7573 (stack39)
        %v7581 = vsel /*vm=*/%vm7555, /*on_true_vy=*/%v7577, /*on_false_vx=*/%v7573 (stack43)
        %v7586 = vadd.s32 %v7581, %v10 (stack39)
        %v7590 = vadd.s32 %v7551, %v9 (stack39)
        %v7594 = vadd.s32 %v7590, %v7586 (stack39)
        %v7596 = vshll.u32 %v7590, 13 (stack44)
        %v7597 = vshrl.u32 %v7590, 19 (stack45)
        %v7598 = vor.u32 %v7597, %v7596 (stack46)
        %v7599 = vxor.u32 %v7598, %v7594 (stack47)
        %v7602 = vadd.s32 %v7599, %v7594 (stack39)
        %v7604 = vshll.u32 %v7599, 15 (stack44)
        %v7605 = vshrl.u32 %v7599, 17 (stack45)
        %v7606 = vor.u32 %v7605, %v7604 (stack46)
        %v7607 = vxor.u32 %v7606, %v7602 (stack47)
        %v7610 = vadd.s32 %v7607, %v7602 (stack39)
        %v7612 = vshll.u32 %v7607, 26 (stack44)
        %v7613 = vshrl.u32 %v7607, 6 (stack45)
        %v7614 = vor.u32 %v7613, %v7612 (stack46)
        %v7615 = vxor.u32 %v7614, %v7610 (stack47)
        %v7618 = vadd.s32 %v7615, %v7610 (stack39)
        %v7622 = vadd.s32 %v7618, %v9 (stack39)
        %v7624 = vshll.u32 %v7615, 6 (stack44)
        %v7625 = vshrl.u32 %v7615, 26 (stack45)
        %v7626 = vor.u32 %v7625, %v7624 (stack46)
        %v7627 = vxor.u32 %v7626, %v7618 (stack47)
        %v7630 = vadd.s32 %v7627, %v8 (stack39)
        %v7634 = vadd.s32 1, %v7630 (stack39)
        %v7638 = vadd.s32 %v7634, %v7622 (stack39)
        %v7640 = vshll.u32 %v7634, 17 (stack44)
        %v7641 = vshrl.u32 %v7634, 15 (stack45)
        %v7642 = vor.u32 %v7641, %v7640 (stack46)
        %v7643 = vxor.u32 %v7642, %v7638 (stack47)
        %v7646 = vadd.s32 %v7643, %v7638 (stack39)
        %v7648 = vshll.u32 %v7643, 29 (stack44)
        %v7649 = vshrl.u32 %v7643, 3 (stack45)
        %v7650 = vor.u32 %v7649, %v7648 (stack46)
        %v7651 = vxor.u32 %v7650, %v7646 (stack47)
        %v7654 = vadd.s32 %v7651, %v7646 (stack39)
        %v7656 = vshll.u32 %v7651, 16 (stack44)
        %v7657 = vshrl.u32 %v7651, 16 (stack45)
        %v7658 = vor.u32 %v7657, %v7656 (stack46)
        %v7659 = vxor.u32 %v7658, %v7654 (stack47)
        %v7662 = vadd.s32 %v7659, %v7654 (stack39)
        %v7666 = vadd.s32 %v7662, %v8 (stack39)
        %v7668 = vshll.u32 %v7659, 24 (stack44)
        %v7669 = vshrl.u32 %v7659, 8 (stack45)
        %v7670 = vor.u32 %v7669, %v7668 (stack46)
        %v7671 = vxor.u32 %v7670, %v7662 (stack47)
        %v7674 = vadd.s32 %v7671, %v10 (stack39)
        %v7678 = vadd.s32 2, %v7674 (stack39)
        %v7682 = vadd.s32 %v7678, %v7666 (stack39)
        %v7684 = vshll.u32 %v7678, 13 (stack44)
        %v7685 = vshrl.u32 %v7678, 19 (stack45)
        %v7686 = vor.u32 %v7685, %v7684 (stack46)
        %v7687 = vxor.u32 %v7686, %v7682 (stack47)
        %v7690 = vadd.s32 %v7687, %v7682 (stack39)
        %v7692 = vshll.u32 %v7687, 15 (stack44)
        %v7693 = vshrl.u32 %v7687, 17 (stack45)
        %v7694 = vor.u32 %v7693, %v7692 (stack46)
        %v7695 = vxor.u32 %v7694, %v7690 (stack47)
        %v7698 = vadd.s32 %v7695, %v7690 (stack39)
        %v7700 = vshll.u32 %v7695, 26 (stack44)
        %v7701 = vshrl.u32 %v7695, 6 (stack45)
        %v7702 = vor.u32 %v7701, %v7700 (stack46)
        %v7703 = vxor.u32 %v7702, %v7698 (stack47)
        %v7706 = vadd.s32 %v7703, %v7698 (stack39)
        %v7710 = vadd.s32 %v7706, %v10 (stack39)
        %v7712 = vshll.u32 %v7703, 6 (stack44)
        %v7713 = vshrl.u32 %v7703, 26 (stack45)
        %v7714 = vor.u32 %v7713, %v7712 (stack46)
        %v7715 = vxor.u32 %v7714, %v7706 (stack47)
        %v7718 = vadd.s32 %v7715, %v9 (stack39)
        %v7722 = vadd.s32 3, %v7718 (stack39)
        %v7726 = vadd.s32 %v7722, %v7710 (stack39)
        %v7728 = vshll.u32 %v7722, 17 (stack44)
        %v7729 = vshrl.u32 %v7722, 15 (stack45)
        %v7730 = vor.u32 %v7729, %v7728 (stack46)
        %v7731 = vxor.u32 %v7730, %v7726 (stack47)
        %v7734 = vadd.s32 %v7731, %v7726 (stack39)
        %v7736 = vshll.u32 %v7731, 29 (stack44)
        %v7737 = vshrl.u32 %v7731, 3 (stack45)
        %v7738 = vor.u32 %v7737, %v7736 (stack46)
        %v7739 = vxor.u32 %v7738, %v7734 (stack47)
        %v7742 = vadd.s32 %v7739, %v7734 (stack39)
        %v7744 = vshll.u32 %v7739, 16 (stack44)
        %v7745 = vshrl.u32 %v7739, 16 (stack45)
        %v7746 = vor.u32 %v7745, %v7744 (stack46)
        %v7747 = vxor.u32 %v7746, %v7742 (stack47)
        %v7750 = vadd.s32 %v7747, %v7742 (stack39)
        %v7754 = vadd.s32 %v7750, %v9 (stack39)
        %v7756 = vshll.u32 %v7747, 24 (stack44)
        %v7757 = vshrl.u32 %v7747, 8 (stack45)
        %v7758 = vor.u32 %v7757, %v7756 (stack46)
        %v7759 = vxor.u32 %v7758, %v7750 (stack47)
        %v7762 = vadd.s32 %v7759, %v8 (stack39)
        %v7766 = vadd.s32 4, %v7762 (stack39)
        %v7770 = vadd.s32 %v7766, %v7754 (stack39)
        %v7772 = vshll.u32 %v7766, 13 (stack44)
        %v7773 = vshrl.u32 %v7766, 19 (stack45)
        %v7774 = vor.u32 %v7773, %v7772 (stack46)
        %v7775 = vxor.u32 %v7774, %v7770 (stack47)
        %v7778 = vadd.s32 %v7775, %v7770 (stack39)
        %v7780 = vshll.u32 %v7775, 15 (stack44)
        %v7781 = vshrl.u32 %v7775, 17 (stack45)
        %v7782 = vor.u32 %v7781, %v7780 (stack46)
        %v7783 = vxor.u32 %v7782, %v7778 (stack47)
        %v7786 = vadd.s32 %v7783, %v7778 (stack39)
        %v7788 = vshll.u32 %v7783, 26 (stack44)
        %v7789 = vshrl.u32 %v7783, 6 (stack45)
        %v7790 = vor.u32 %v7789, %v7788 (stack46)
        %v7791 = vxor.u32 %v7790, %v7786 (stack47)
        %v7794 = vadd.s32 %v7791, %v7786 (stack39)
        %v7798 = vadd.s32 %v7794, %v8 (stack39)
        %v7800 = vshll.u32 %v7791, 6 (stack44)
        %v7801 = vshrl.u32 %v7791, 26 (stack45)
        %v7802 = vor.u32 %v7801, %v7800 (stack46)
        %v7803 = vxor.u32 %v7802, %v7794 (stack47)
        %v7806 = vadd.s32 %v7803, %v10 (stack39)
        %v7810 = vadd.s32 5, %v7806 (stack39)
        %v7812 = vxor.u32 %v7810, %v7798 (stack47)
        %v7813 = vand.u32.u8 255, %v7812 (stack48)
        %v7814 = vand.u32 65535, %v7813 (stack49)
        %v7815 = vshrl.u32 %v7814, 1 (stack50)
        %v7816 = vor.u32 16256, %v7815 (stack46)
        %v7817 = vand.u32.u16 65535, %v7816 (stack51)
        %v119782 = vadd.low.f32.bf16 -1.0, %v7817 (stack52)
        %v7826 = vmul.f32 2.0, %v119782 (stack53)
        %v7830 = vadd.f32 -0.99609375, %v7826 (stack52)
        %v7834 = vmax.f32 %v7830, -0.99609375 (stack54)
        %v7836 = vand.u32 2147483647, %v7834 (stack55)
        %vm7839 = vcmp.eq.f32.partialorder %v7836, 1.0 (stack56)
        %v7844 = vmul.f32 inf, %v7834 (stack53)
        %v7846 = vxor.u32 2147483648, %v7834 (stack57)
        %v7849 = vmul.f32 %v7846, %v7834 (stack53)
        %v7851 = vadd.f32 1.0, %v7849 (stack58)
        %v7852 = vlog2.pop %v7851 (stack59)
        %v7853 = vmul.f32 0.6931472, %v7852 (stack60)
        %v7854 = vmul.f32 -0.5, %v7849 (stack61)
        %v7855 = vadd.f32 1.0, %v7854 (stack62)
        %v7856 = vmul.f32 %v7855, %v7849 (stack63)
        %v7857 = vand.u32 2147483647, %v7849 (stack64)
        %vm7858 = vcmp.lt.f32.partialorder %v7857, 0.0004427343 (stack65)
        %v7859 = vsel /*vm=*/%vm7858, /*on_true_vy=*/%v7856, /*on_false_vx=*/%v7853 (stack66)
        %v7860 = vxor.u32 2147483648, %v7859 (stack57)
        %vm7863 = vcmp.lt.f32.partialorder %v7860, 5.0 (stack56)
        %v7868 = vsel /*vm=*/%vm7863, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v7872 = vsel /*vm=*/%vm7863, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v7876 = vsel /*vm=*/%vm7863, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v7880 = vsel /*vm=*/%vm7863, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v7884 = vsel /*vm=*/%vm7863, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v7888 = vsel /*vm=*/%vm7863, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v7892 = vsel /*vm=*/%vm7863, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v7896 = vsel /*vm=*/%vm7863, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v7900 = vsel /*vm=*/%vm7863, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v7904 = vadd.f32 -2.5, %v7860 (stack52)
        %v7906 = vrsqrt.pop %v7860 (stack67)
        %v7907 = vmul.f32 %v7906, %v7860 (stack68)
        %vm7908 = vcmp.eq.f32.partialorder %v7860, inf (stack69)
        %v7909 = vsel /*vm=*/%vm7908, /*on_true_vy=*/%v7860, /*on_false_vx=*/%v7907 (stack70)
        %vm7910 = vcmp.eq.f32.partialorder %v7860, 0.0 (stack71)
        %v7911 = vand.u32 2147483648, %v7860 (stack72)
        %v7912 = vsel /*vm=*/%vm7910, /*on_true_vy=*/%v7911, /*on_false_vx=*/%v7909 (stack73)
        %v7915 = vadd.f32 -3.0, %v7912 (stack52)
        %v7919 = vsel /*vm=*/%vm7863, /*on_true_vy=*/%v7904, /*on_false_vx=*/%v7915 (stack43)
        %v7923 = vmul.f32 %v7919, %v7900 (stack53)
        %v7927 = vadd.f32 %v7923, %v7896 (stack52)
        %v7931 = vmul.f32 %v7927, %v7919 (stack53)
        %v7935 = vadd.f32 %v7931, %v7892 (stack52)
        %v7939 = vmul.f32 %v7935, %v7919 (stack53)
        %v7943 = vadd.f32 %v7939, %v7888 (stack52)
        %v7947 = vmul.f32 %v7943, %v7919 (stack53)
        %v7951 = vadd.f32 %v7947, %v7884 (stack52)
        %v7955 = vmul.f32 %v7951, %v7919 (stack53)
        %v7959 = vadd.f32 %v7955, %v7880 (stack52)
        %v7963 = vmul.f32 %v7959, %v7919 (stack53)
        %v7967 = vadd.f32 %v7963, %v7876 (stack52)
        %v7971 = vmul.f32 %v7967, %v7919 (stack53)
        %v7975 = vadd.f32 %v7971, %v7872 (stack52)
        %v7979 = vmul.f32 %v7975, %v7919 (stack53)
        %v7983 = vadd.f32 %v7979, %v7868 (stack52)
        %v7987 = vmul.f32 %v7983, %v7834 (stack53)
        %v7991 = vsel /*vm=*/%vm7839, /*on_true_vy=*/%v7844, /*on_false_vx=*/%v7987 (stack43)
        %v7995 = vmul.f32 1.4140625, %v7991 (stack53)
        %v7998 = vpack.c.bf16 0.0, %v7995 (stack74)
        %119783 = vst [vmem:[%s280 + $0x384] sm:$0xf] /*vst_source=*/%v7998 (stack75)
        %s8000 = sadd.s32 16, %s120390 (stack76)
        %s8001 = sshrl.u32 %s8000, 10 (stack23)
        %p119784 = scmp.gt.s32.totalorder %s8001, 1 (stack24)
        %s8003 = scalar_select /*predicate=*/%p119784, /*on_true=*/1, /*on_false=*/%s8001 (stack25)
        %s8004 = sand.u32 1023, %s8000 /* smod.u32 w/div 1024 */ (stack26)
        %s8005 = sshrl.u32 %s8004, 7 (stack27)
        %s8006 = sand.u32 127, %s8004 /* smod.u32 w/div 128 */ (stack28)
        %s119785 = sshll.u32 %s8003, 3 (stack29)
        %s8008 = scalar_lea.vmem %s3, %s119785 (stack30)
        %s8010 = scalar_lea.vmem %s8008, %s8005 (stack31)
        %v8011 = vld [vmem:[%s8010] ss:$0 sm:$0xff] (stack32)
        %s8012 = sand.u32 255, %s8006 (stack33)
        %s8014 = sor.u32 256, %s8012 (stack34)
        %8015 = vbcast.lane.b32.xlu0 %v8011, %s8014 (stack35)
        %v8016 = vpop.permute.xlu0 %8015 (stack36)
        %s8025 = scalar_lea.vmem %s5, %s119785 (stack30)
        %s8027 = scalar_lea.vmem %s8025, %s8005 (stack31)
        %v8028 = vld [vmem:[%s8027] ss:$0 sm:$0xff] (stack32)
        %8032 = vbcast.lane.b32.xlu0 %v8028, %s8014 (stack35)
        %v8033 = vpop.permute.xlu0 %8032 (stack36)
        %v8036 = vadd.s32 %v8033, %v408 (stack39)
        %v8046 = vadd.s32 %v8036, %v415 (stack39)
        %vm8050 = vcmp.lt.u32.totalorder %v8046, %v8036 (stack42)
        %vm8055 = vcmp.lt.u32.totalorder %v8036, %v408 (stack42)
        %v8060 = vadd.s32 %v8016, %v380 (stack39)
        %v8064 = vadd.s32 1, %v8060 (stack39)
        %v8068 = vsel /*vm=*/%vm8055, /*on_true_vy=*/%v8064, /*on_false_vx=*/%v8060 (stack43)
        %v8072 = vadd.s32 1, %v8068 (stack39)
        %v8076 = vsel /*vm=*/%vm8050, /*on_true_vy=*/%v8072, /*on_false_vx=*/%v8068 (stack43)
        %v8081 = vadd.s32 %v8076, %v10 (stack39)
        %v8085 = vadd.s32 %v8046, %v9 (stack39)
        %v8089 = vadd.s32 %v8085, %v8081 (stack39)
        %v8091 = vshll.u32 %v8085, 13 (stack44)
        %v8092 = vshrl.u32 %v8085, 19 (stack45)
        %v8093 = vor.u32 %v8092, %v8091 (stack46)
        %v8094 = vxor.u32 %v8093, %v8089 (stack47)
        %v8097 = vadd.s32 %v8094, %v8089 (stack39)
        %v8099 = vshll.u32 %v8094, 15 (stack44)
        %v8100 = vshrl.u32 %v8094, 17 (stack45)
        %v8101 = vor.u32 %v8100, %v8099 (stack46)
        %v8102 = vxor.u32 %v8101, %v8097 (stack47)
        %v8105 = vadd.s32 %v8102, %v8097 (stack39)
        %v8107 = vshll.u32 %v8102, 26 (stack44)
        %v8108 = vshrl.u32 %v8102, 6 (stack45)
        %v8109 = vor.u32 %v8108, %v8107 (stack46)
        %v8110 = vxor.u32 %v8109, %v8105 (stack47)
        %v8113 = vadd.s32 %v8110, %v8105 (stack39)
        %v8117 = vadd.s32 %v8113, %v9 (stack39)
        %v8119 = vshll.u32 %v8110, 6 (stack44)
        %v8120 = vshrl.u32 %v8110, 26 (stack45)
        %v8121 = vor.u32 %v8120, %v8119 (stack46)
        %v8122 = vxor.u32 %v8121, %v8113 (stack47)
        %v8125 = vadd.s32 %v8122, %v8 (stack39)
        %v8129 = vadd.s32 1, %v8125 (stack39)
        %v8133 = vadd.s32 %v8129, %v8117 (stack39)
        %v8135 = vshll.u32 %v8129, 17 (stack44)
        %v8136 = vshrl.u32 %v8129, 15 (stack45)
        %v8137 = vor.u32 %v8136, %v8135 (stack46)
        %v8138 = vxor.u32 %v8137, %v8133 (stack47)
        %v8141 = vadd.s32 %v8138, %v8133 (stack39)
        %v8143 = vshll.u32 %v8138, 29 (stack44)
        %v8144 = vshrl.u32 %v8138, 3 (stack45)
        %v8145 = vor.u32 %v8144, %v8143 (stack46)
        %v8146 = vxor.u32 %v8145, %v8141 (stack47)
        %v8149 = vadd.s32 %v8146, %v8141 (stack39)
        %v8151 = vshll.u32 %v8146, 16 (stack44)
        %v8152 = vshrl.u32 %v8146, 16 (stack45)
        %v8153 = vor.u32 %v8152, %v8151 (stack46)
        %v8154 = vxor.u32 %v8153, %v8149 (stack47)
        %v8157 = vadd.s32 %v8154, %v8149 (stack39)
        %v8161 = vadd.s32 %v8157, %v8 (stack39)
        %v8163 = vshll.u32 %v8154, 24 (stack44)
        %v8164 = vshrl.u32 %v8154, 8 (stack45)
        %v8165 = vor.u32 %v8164, %v8163 (stack46)
        %v8166 = vxor.u32 %v8165, %v8157 (stack47)
        %v8169 = vadd.s32 %v8166, %v10 (stack39)
        %v8173 = vadd.s32 2, %v8169 (stack39)
        %v8177 = vadd.s32 %v8173, %v8161 (stack39)
        %v8179 = vshll.u32 %v8173, 13 (stack44)
        %v8180 = vshrl.u32 %v8173, 19 (stack45)
        %v8181 = vor.u32 %v8180, %v8179 (stack46)
        %v8182 = vxor.u32 %v8181, %v8177 (stack47)
        %v8185 = vadd.s32 %v8182, %v8177 (stack39)
        %v8187 = vshll.u32 %v8182, 15 (stack44)
        %v8188 = vshrl.u32 %v8182, 17 (stack45)
        %v8189 = vor.u32 %v8188, %v8187 (stack46)
        %v8190 = vxor.u32 %v8189, %v8185 (stack47)
        %v8193 = vadd.s32 %v8190, %v8185 (stack39)
        %v8195 = vshll.u32 %v8190, 26 (stack44)
        %v8196 = vshrl.u32 %v8190, 6 (stack45)
        %v8197 = vor.u32 %v8196, %v8195 (stack46)
        %v8198 = vxor.u32 %v8197, %v8193 (stack47)
        %v8201 = vadd.s32 %v8198, %v8193 (stack39)
        %v8205 = vadd.s32 %v8201, %v10 (stack39)
        %v8207 = vshll.u32 %v8198, 6 (stack44)
        %v8208 = vshrl.u32 %v8198, 26 (stack45)
        %v8209 = vor.u32 %v8208, %v8207 (stack46)
        %v8210 = vxor.u32 %v8209, %v8201 (stack47)
        %v8213 = vadd.s32 %v8210, %v9 (stack39)
        %v8217 = vadd.s32 3, %v8213 (stack39)
        %v8221 = vadd.s32 %v8217, %v8205 (stack39)
        %v8223 = vshll.u32 %v8217, 17 (stack44)
        %v8224 = vshrl.u32 %v8217, 15 (stack45)
        %v8225 = vor.u32 %v8224, %v8223 (stack46)
        %v8226 = vxor.u32 %v8225, %v8221 (stack47)
        %v8229 = vadd.s32 %v8226, %v8221 (stack39)
        %v8231 = vshll.u32 %v8226, 29 (stack44)
        %v8232 = vshrl.u32 %v8226, 3 (stack45)
        %v8233 = vor.u32 %v8232, %v8231 (stack46)
        %v8234 = vxor.u32 %v8233, %v8229 (stack47)
        %v8237 = vadd.s32 %v8234, %v8229 (stack39)
        %v8239 = vshll.u32 %v8234, 16 (stack44)
        %v8240 = vshrl.u32 %v8234, 16 (stack45)
        %v8241 = vor.u32 %v8240, %v8239 (stack46)
        %v8242 = vxor.u32 %v8241, %v8237 (stack47)
        %v8245 = vadd.s32 %v8242, %v8237 (stack39)
        %v8249 = vadd.s32 %v8245, %v9 (stack39)
        %v8251 = vshll.u32 %v8242, 24 (stack44)
        %v8252 = vshrl.u32 %v8242, 8 (stack45)
        %v8253 = vor.u32 %v8252, %v8251 (stack46)
        %v8254 = vxor.u32 %v8253, %v8245 (stack47)
        %v8257 = vadd.s32 %v8254, %v8 (stack39)
        %v8261 = vadd.s32 4, %v8257 (stack39)
        %v8265 = vadd.s32 %v8261, %v8249 (stack39)
        %v8267 = vshll.u32 %v8261, 13 (stack44)
        %v8268 = vshrl.u32 %v8261, 19 (stack45)
        %v8269 = vor.u32 %v8268, %v8267 (stack46)
        %v8270 = vxor.u32 %v8269, %v8265 (stack47)
        %v8273 = vadd.s32 %v8270, %v8265 (stack39)
        %v8275 = vshll.u32 %v8270, 15 (stack44)
        %v8276 = vshrl.u32 %v8270, 17 (stack45)
        %v8277 = vor.u32 %v8276, %v8275 (stack46)
        %v8278 = vxor.u32 %v8277, %v8273 (stack47)
        %v8281 = vadd.s32 %v8278, %v8273 (stack39)
        %v8283 = vshll.u32 %v8278, 26 (stack44)
        %v8284 = vshrl.u32 %v8278, 6 (stack45)
        %v8285 = vor.u32 %v8284, %v8283 (stack46)
        %v8286 = vxor.u32 %v8285, %v8281 (stack47)
        %v8289 = vadd.s32 %v8286, %v8281 (stack39)
        %v8293 = vadd.s32 %v8289, %v8 (stack39)
        %v8295 = vshll.u32 %v8286, 6 (stack44)
        %v8296 = vshrl.u32 %v8286, 26 (stack45)
        %v8297 = vor.u32 %v8296, %v8295 (stack46)
        %v8298 = vxor.u32 %v8297, %v8289 (stack47)
        %v8301 = vadd.s32 %v8298, %v10 (stack39)
        %v8305 = vadd.s32 5, %v8301 (stack39)
        %v8307 = vxor.u32 %v8305, %v8293 (stack47)
        %v8308 = vand.u32.u8 255, %v8307 (stack48)
        %v8309 = vand.u32 65535, %v8308 (stack49)
        %v8310 = vshrl.u32 %v8309, 1 (stack50)
        %v8311 = vor.u32 16256, %v8310 (stack46)
        %v8312 = vand.u32.u16 65535, %v8311 (stack51)
        %v119788 = vadd.low.f32.bf16 -1.0, %v8312 (stack52)
        %v8321 = vmul.f32 2.0, %v119788 (stack53)
        %v8325 = vadd.f32 -0.99609375, %v8321 (stack52)
        %v8329 = vmax.f32 %v8325, -0.99609375 (stack54)
        %v8331 = vand.u32 2147483647, %v8329 (stack55)
        %vm8334 = vcmp.eq.f32.partialorder %v8331, 1.0 (stack56)
        %v8339 = vmul.f32 inf, %v8329 (stack53)
        %v8341 = vxor.u32 2147483648, %v8329 (stack57)
        %v8344 = vmul.f32 %v8341, %v8329 (stack53)
        %v8346 = vadd.f32 1.0, %v8344 (stack58)
        %v8347 = vlog2.pop %v8346 (stack59)
        %v8348 = vmul.f32 0.6931472, %v8347 (stack60)
        %v8349 = vmul.f32 -0.5, %v8344 (stack61)
        %v8350 = vadd.f32 1.0, %v8349 (stack62)
        %v8351 = vmul.f32 %v8350, %v8344 (stack63)
        %v8352 = vand.u32 2147483647, %v8344 (stack64)
        %vm8353 = vcmp.lt.f32.partialorder %v8352, 0.0004427343 (stack65)
        %v8354 = vsel /*vm=*/%vm8353, /*on_true_vy=*/%v8351, /*on_false_vx=*/%v8348 (stack66)
        %v8355 = vxor.u32 2147483648, %v8354 (stack57)
        %vm8358 = vcmp.lt.f32.partialorder %v8355, 5.0 (stack56)
        %v8363 = vsel /*vm=*/%vm8358, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v8367 = vsel /*vm=*/%vm8358, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v8371 = vsel /*vm=*/%vm8358, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v8375 = vsel /*vm=*/%vm8358, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v8379 = vsel /*vm=*/%vm8358, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v8383 = vsel /*vm=*/%vm8358, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v8387 = vsel /*vm=*/%vm8358, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v8391 = vsel /*vm=*/%vm8358, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v8395 = vsel /*vm=*/%vm8358, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v8399 = vadd.f32 -2.5, %v8355 (stack52)
        %v8401 = vrsqrt.pop %v8355 (stack67)
        %v8402 = vmul.f32 %v8401, %v8355 (stack68)
        %vm8403 = vcmp.eq.f32.partialorder %v8355, inf (stack69)
        %v8404 = vsel /*vm=*/%vm8403, /*on_true_vy=*/%v8355, /*on_false_vx=*/%v8402 (stack70)
        %vm8405 = vcmp.eq.f32.partialorder %v8355, 0.0 (stack71)
        %v8406 = vand.u32 2147483648, %v8355 (stack72)
        %v8407 = vsel /*vm=*/%vm8405, /*on_true_vy=*/%v8406, /*on_false_vx=*/%v8404 (stack73)
        %v8410 = vadd.f32 -3.0, %v8407 (stack52)
        %v8414 = vsel /*vm=*/%vm8358, /*on_true_vy=*/%v8399, /*on_false_vx=*/%v8410 (stack43)
        %v8418 = vmul.f32 %v8414, %v8395 (stack53)
        %v8422 = vadd.f32 %v8418, %v8391 (stack52)
        %v8426 = vmul.f32 %v8422, %v8414 (stack53)
        %v8430 = vadd.f32 %v8426, %v8387 (stack52)
        %v8434 = vmul.f32 %v8430, %v8414 (stack53)
        %v8438 = vadd.f32 %v8434, %v8383 (stack52)
        %v8442 = vmul.f32 %v8438, %v8414 (stack53)
        %v8446 = vadd.f32 %v8442, %v8379 (stack52)
        %v8450 = vmul.f32 %v8446, %v8414 (stack53)
        %v8454 = vadd.f32 %v8450, %v8375 (stack52)
        %v8458 = vmul.f32 %v8454, %v8414 (stack53)
        %v8462 = vadd.f32 %v8458, %v8371 (stack52)
        %v8466 = vmul.f32 %v8462, %v8414 (stack53)
        %v8470 = vadd.f32 %v8466, %v8367 (stack52)
        %v8474 = vmul.f32 %v8470, %v8414 (stack53)
        %v8478 = vadd.f32 %v8474, %v8363 (stack52)
        %v8482 = vmul.f32 %v8478, %v8329 (stack53)
        %v8486 = vsel /*vm=*/%vm8334, /*on_true_vy=*/%v8339, /*on_false_vx=*/%v8482 (stack43)
        %v8490 = vmul.f32 1.4140625, %v8486 (stack53)
        %v8493 = vpack.c.bf16 0.0, %v8490 (stack74)
        %119789 = vst [vmem:[%s280 + $0x8] sm:$0xf] /*vst_source=*/%v8493 (stack75)
        %v8497 = vadd.s32 %v8033, %v894 (stack39)
        %v8507 = vadd.s32 %v8497, %v415 (stack39)
        %vm8511 = vcmp.lt.u32.totalorder %v8507, %v8497 (stack42)
        %vm8516 = vcmp.lt.u32.totalorder %v8497, %v894 (stack42)
        %v8521 = vadd.s32 %v8016, %v881 (stack39)
        %v8525 = vadd.s32 1, %v8521 (stack39)
        %v8529 = vsel /*vm=*/%vm8516, /*on_true_vy=*/%v8525, /*on_false_vx=*/%v8521 (stack43)
        %v8533 = vadd.s32 1, %v8529 (stack39)
        %v8537 = vsel /*vm=*/%vm8511, /*on_true_vy=*/%v8533, /*on_false_vx=*/%v8529 (stack43)
        %v8542 = vadd.s32 %v8537, %v10 (stack39)
        %v8546 = vadd.s32 %v8507, %v9 (stack39)
        %v8550 = vadd.s32 %v8546, %v8542 (stack39)
        %v8552 = vshll.u32 %v8546, 13 (stack44)
        %v8553 = vshrl.u32 %v8546, 19 (stack45)
        %v8554 = vor.u32 %v8553, %v8552 (stack46)
        %v8555 = vxor.u32 %v8554, %v8550 (stack47)
        %v8558 = vadd.s32 %v8555, %v8550 (stack39)
        %v8560 = vshll.u32 %v8555, 15 (stack44)
        %v8561 = vshrl.u32 %v8555, 17 (stack45)
        %v8562 = vor.u32 %v8561, %v8560 (stack46)
        %v8563 = vxor.u32 %v8562, %v8558 (stack47)
        %v8566 = vadd.s32 %v8563, %v8558 (stack39)
        %v8568 = vshll.u32 %v8563, 26 (stack44)
        %v8569 = vshrl.u32 %v8563, 6 (stack45)
        %v8570 = vor.u32 %v8569, %v8568 (stack46)
        %v8571 = vxor.u32 %v8570, %v8566 (stack47)
        %v8574 = vadd.s32 %v8571, %v8566 (stack39)
        %v8578 = vadd.s32 %v8574, %v9 (stack39)
        %v8580 = vshll.u32 %v8571, 6 (stack44)
        %v8581 = vshrl.u32 %v8571, 26 (stack45)
        %v8582 = vor.u32 %v8581, %v8580 (stack46)
        %v8583 = vxor.u32 %v8582, %v8574 (stack47)
        %v8586 = vadd.s32 %v8583, %v8 (stack39)
        %v8590 = vadd.s32 1, %v8586 (stack39)
        %v8594 = vadd.s32 %v8590, %v8578 (stack39)
        %v8596 = vshll.u32 %v8590, 17 (stack44)
        %v8597 = vshrl.u32 %v8590, 15 (stack45)
        %v8598 = vor.u32 %v8597, %v8596 (stack46)
        %v8599 = vxor.u32 %v8598, %v8594 (stack47)
        %v8602 = vadd.s32 %v8599, %v8594 (stack39)
        %v8604 = vshll.u32 %v8599, 29 (stack44)
        %v8605 = vshrl.u32 %v8599, 3 (stack45)
        %v8606 = vor.u32 %v8605, %v8604 (stack46)
        %v8607 = vxor.u32 %v8606, %v8602 (stack47)
        %v8610 = vadd.s32 %v8607, %v8602 (stack39)
        %v8612 = vshll.u32 %v8607, 16 (stack44)
        %v8613 = vshrl.u32 %v8607, 16 (stack45)
        %v8614 = vor.u32 %v8613, %v8612 (stack46)
        %v8615 = vxor.u32 %v8614, %v8610 (stack47)
        %v8618 = vadd.s32 %v8615, %v8610 (stack39)
        %v8622 = vadd.s32 %v8618, %v8 (stack39)
        %v8624 = vshll.u32 %v8615, 24 (stack44)
        %v8625 = vshrl.u32 %v8615, 8 (stack45)
        %v8626 = vor.u32 %v8625, %v8624 (stack46)
        %v8627 = vxor.u32 %v8626, %v8618 (stack47)
        %v8630 = vadd.s32 %v8627, %v10 (stack39)
        %v8634 = vadd.s32 2, %v8630 (stack39)
        %v8638 = vadd.s32 %v8634, %v8622 (stack39)
        %v8640 = vshll.u32 %v8634, 13 (stack44)
        %v8641 = vshrl.u32 %v8634, 19 (stack45)
        %v8642 = vor.u32 %v8641, %v8640 (stack46)
        %v8643 = vxor.u32 %v8642, %v8638 (stack47)
        %v8646 = vadd.s32 %v8643, %v8638 (stack39)
        %v8648 = vshll.u32 %v8643, 15 (stack44)
        %v8649 = vshrl.u32 %v8643, 17 (stack45)
        %v8650 = vor.u32 %v8649, %v8648 (stack46)
        %v8651 = vxor.u32 %v8650, %v8646 (stack47)
        %v8654 = vadd.s32 %v8651, %v8646 (stack39)
        %v8656 = vshll.u32 %v8651, 26 (stack44)
        %v8657 = vshrl.u32 %v8651, 6 (stack45)
        %v8658 = vor.u32 %v8657, %v8656 (stack46)
        %v8659 = vxor.u32 %v8658, %v8654 (stack47)
        %v8662 = vadd.s32 %v8659, %v8654 (stack39)
        %v8666 = vadd.s32 %v8662, %v10 (stack39)
        %v8668 = vshll.u32 %v8659, 6 (stack44)
        %v8669 = vshrl.u32 %v8659, 26 (stack45)
        %v8670 = vor.u32 %v8669, %v8668 (stack46)
        %v8671 = vxor.u32 %v8670, %v8662 (stack47)
        %v8674 = vadd.s32 %v8671, %v9 (stack39)
        %v8678 = vadd.s32 3, %v8674 (stack39)
        %v8682 = vadd.s32 %v8678, %v8666 (stack39)
        %v8684 = vshll.u32 %v8678, 17 (stack44)
        %v8685 = vshrl.u32 %v8678, 15 (stack45)
        %v8686 = vor.u32 %v8685, %v8684 (stack46)
        %v8687 = vxor.u32 %v8686, %v8682 (stack47)
        %v8690 = vadd.s32 %v8687, %v8682 (stack39)
        %v8692 = vshll.u32 %v8687, 29 (stack44)
        %v8693 = vshrl.u32 %v8687, 3 (stack45)
        %v8694 = vor.u32 %v8693, %v8692 (stack46)
        %v8695 = vxor.u32 %v8694, %v8690 (stack47)
        %v8698 = vadd.s32 %v8695, %v8690 (stack39)
        %v8700 = vshll.u32 %v8695, 16 (stack44)
        %v8701 = vshrl.u32 %v8695, 16 (stack45)
        %v8702 = vor.u32 %v8701, %v8700 (stack46)
        %v8703 = vxor.u32 %v8702, %v8698 (stack47)
        %v8706 = vadd.s32 %v8703, %v8698 (stack39)
        %v8710 = vadd.s32 %v8706, %v9 (stack39)
        %v8712 = vshll.u32 %v8703, 24 (stack44)
        %v8713 = vshrl.u32 %v8703, 8 (stack45)
        %v8714 = vor.u32 %v8713, %v8712 (stack46)
        %v8715 = vxor.u32 %v8714, %v8706 (stack47)
        %v8718 = vadd.s32 %v8715, %v8 (stack39)
        %v8722 = vadd.s32 4, %v8718 (stack39)
        %v8726 = vadd.s32 %v8722, %v8710 (stack39)
        %v8728 = vshll.u32 %v8722, 13 (stack44)
        %v8729 = vshrl.u32 %v8722, 19 (stack45)
        %v8730 = vor.u32 %v8729, %v8728 (stack46)
        %v8731 = vxor.u32 %v8730, %v8726 (stack47)
        %v8734 = vadd.s32 %v8731, %v8726 (stack39)
        %v8736 = vshll.u32 %v8731, 15 (stack44)
        %v8737 = vshrl.u32 %v8731, 17 (stack45)
        %v8738 = vor.u32 %v8737, %v8736 (stack46)
        %v8739 = vxor.u32 %v8738, %v8734 (stack47)
        %v8742 = vadd.s32 %v8739, %v8734 (stack39)
        %v8744 = vshll.u32 %v8739, 26 (stack44)
        %v8745 = vshrl.u32 %v8739, 6 (stack45)
        %v8746 = vor.u32 %v8745, %v8744 (stack46)
        %v8747 = vxor.u32 %v8746, %v8742 (stack47)
        %v8750 = vadd.s32 %v8747, %v8742 (stack39)
        %v8754 = vadd.s32 %v8750, %v8 (stack39)
        %v8756 = vshll.u32 %v8747, 6 (stack44)
        %v8757 = vshrl.u32 %v8747, 26 (stack45)
        %v8758 = vor.u32 %v8757, %v8756 (stack46)
        %v8759 = vxor.u32 %v8758, %v8750 (stack47)
        %v8762 = vadd.s32 %v8759, %v10 (stack39)
        %v8766 = vadd.s32 5, %v8762 (stack39)
        %v8768 = vxor.u32 %v8766, %v8754 (stack47)
        %v8769 = vand.u32.u8 255, %v8768 (stack48)
        %v8770 = vand.u32 65535, %v8769 (stack49)
        %v8771 = vshrl.u32 %v8770, 1 (stack50)
        %v8772 = vor.u32 16256, %v8771 (stack46)
        %v8773 = vand.u32.u16 65535, %v8772 (stack51)
        %v119790 = vadd.low.f32.bf16 -1.0, %v8773 (stack52)
        %v8782 = vmul.f32 2.0, %v119790 (stack53)
        %v8786 = vadd.f32 -0.99609375, %v8782 (stack52)
        %v8790 = vmax.f32 %v8786, -0.99609375 (stack54)
        %v8792 = vand.u32 2147483647, %v8790 (stack55)
        %vm8795 = vcmp.eq.f32.partialorder %v8792, 1.0 (stack56)
        %v8800 = vmul.f32 inf, %v8790 (stack53)
        %v8802 = vxor.u32 2147483648, %v8790 (stack57)
        %v8805 = vmul.f32 %v8802, %v8790 (stack53)
        %v8807 = vadd.f32 1.0, %v8805 (stack58)
        %v8808 = vlog2.pop %v8807 (stack59)
        %v8809 = vmul.f32 0.6931472, %v8808 (stack60)
        %v8810 = vmul.f32 -0.5, %v8805 (stack61)
        %v8811 = vadd.f32 1.0, %v8810 (stack62)
        %v8812 = vmul.f32 %v8811, %v8805 (stack63)
        %v8813 = vand.u32 2147483647, %v8805 (stack64)
        %vm8814 = vcmp.lt.f32.partialorder %v8813, 0.0004427343 (stack65)
        %v8815 = vsel /*vm=*/%vm8814, /*on_true_vy=*/%v8812, /*on_false_vx=*/%v8809 (stack66)
        %v8816 = vxor.u32 2147483648, %v8815 (stack57)
        %vm8819 = vcmp.lt.f32.partialorder %v8816, 5.0 (stack56)
        %v8824 = vsel /*vm=*/%vm8819, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v8828 = vsel /*vm=*/%vm8819, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v8832 = vsel /*vm=*/%vm8819, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v8836 = vsel /*vm=*/%vm8819, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v8840 = vsel /*vm=*/%vm8819, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v8844 = vsel /*vm=*/%vm8819, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v8848 = vsel /*vm=*/%vm8819, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v8852 = vsel /*vm=*/%vm8819, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v8856 = vsel /*vm=*/%vm8819, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v8860 = vadd.f32 -2.5, %v8816 (stack52)
        %v8862 = vrsqrt.pop %v8816 (stack67)
        %v8863 = vmul.f32 %v8862, %v8816 (stack68)
        %vm8864 = vcmp.eq.f32.partialorder %v8816, inf (stack69)
        %v8865 = vsel /*vm=*/%vm8864, /*on_true_vy=*/%v8816, /*on_false_vx=*/%v8863 (stack70)
        %vm8866 = vcmp.eq.f32.partialorder %v8816, 0.0 (stack71)
        %v8867 = vand.u32 2147483648, %v8816 (stack72)
        %v8868 = vsel /*vm=*/%vm8866, /*on_true_vy=*/%v8867, /*on_false_vx=*/%v8865 (stack73)
        %v8871 = vadd.f32 -3.0, %v8868 (stack52)
        %v8875 = vsel /*vm=*/%vm8819, /*on_true_vy=*/%v8860, /*on_false_vx=*/%v8871 (stack43)
        %v8879 = vmul.f32 %v8875, %v8856 (stack53)
        %v8883 = vadd.f32 %v8879, %v8852 (stack52)
        %v8887 = vmul.f32 %v8883, %v8875 (stack53)
        %v8891 = vadd.f32 %v8887, %v8848 (stack52)
        %v8895 = vmul.f32 %v8891, %v8875 (stack53)
        %v8899 = vadd.f32 %v8895, %v8844 (stack52)
        %v8903 = vmul.f32 %v8899, %v8875 (stack53)
        %v8907 = vadd.f32 %v8903, %v8840 (stack52)
        %v8911 = vmul.f32 %v8907, %v8875 (stack53)
        %v8915 = vadd.f32 %v8911, %v8836 (stack52)
        %v8919 = vmul.f32 %v8915, %v8875 (stack53)
        %v8923 = vadd.f32 %v8919, %v8832 (stack52)
        %v8927 = vmul.f32 %v8923, %v8875 (stack53)
        %v8931 = vadd.f32 %v8927, %v8828 (stack52)
        %v8935 = vmul.f32 %v8931, %v8875 (stack53)
        %v8939 = vadd.f32 %v8935, %v8824 (stack52)
        %v8943 = vmul.f32 %v8939, %v8790 (stack53)
        %v8947 = vsel /*vm=*/%vm8795, /*on_true_vy=*/%v8800, /*on_false_vx=*/%v8943 (stack43)
        %v8951 = vmul.f32 1.4140625, %v8947 (stack53)
        %v8954 = vpack.c.bf16 0.0, %v8951 (stack74)
        %119791 = vst [vmem:[%s280 + $0x88] sm:$0xf] /*vst_source=*/%v8954 (stack75)
        %v8958 = vadd.s32 %v8033, %v1381 (stack39)
        %v8968 = vadd.s32 %v8958, %v415 (stack39)
        %vm8972 = vcmp.lt.u32.totalorder %v8968, %v8958 (stack42)
        %vm8977 = vcmp.lt.u32.totalorder %v8958, %v1381 (stack42)
        %v8982 = vadd.s32 %v8016, %v1368 (stack39)
        %v8986 = vadd.s32 1, %v8982 (stack39)
        %v8990 = vsel /*vm=*/%vm8977, /*on_true_vy=*/%v8986, /*on_false_vx=*/%v8982 (stack43)
        %v8994 = vadd.s32 1, %v8990 (stack39)
        %v8998 = vsel /*vm=*/%vm8972, /*on_true_vy=*/%v8994, /*on_false_vx=*/%v8990 (stack43)
        %v9003 = vadd.s32 %v8998, %v10 (stack39)
        %v9007 = vadd.s32 %v8968, %v9 (stack39)
        %v9011 = vadd.s32 %v9007, %v9003 (stack39)
        %v9013 = vshll.u32 %v9007, 13 (stack44)
        %v9014 = vshrl.u32 %v9007, 19 (stack45)
        %v9015 = vor.u32 %v9014, %v9013 (stack46)
        %v9016 = vxor.u32 %v9015, %v9011 (stack47)
        %v9019 = vadd.s32 %v9016, %v9011 (stack39)
        %v9021 = vshll.u32 %v9016, 15 (stack44)
        %v9022 = vshrl.u32 %v9016, 17 (stack45)
        %v9023 = vor.u32 %v9022, %v9021 (stack46)
        %v9024 = vxor.u32 %v9023, %v9019 (stack47)
        %v9027 = vadd.s32 %v9024, %v9019 (stack39)
        %v9029 = vshll.u32 %v9024, 26 (stack44)
        %v9030 = vshrl.u32 %v9024, 6 (stack45)
        %v9031 = vor.u32 %v9030, %v9029 (stack46)
        %v9032 = vxor.u32 %v9031, %v9027 (stack47)
        %v9035 = vadd.s32 %v9032, %v9027 (stack39)
        %v9039 = vadd.s32 %v9035, %v9 (stack39)
        %v9041 = vshll.u32 %v9032, 6 (stack44)
        %v9042 = vshrl.u32 %v9032, 26 (stack45)
        %v9043 = vor.u32 %v9042, %v9041 (stack46)
        %v9044 = vxor.u32 %v9043, %v9035 (stack47)
        %v9047 = vadd.s32 %v9044, %v8 (stack39)
        %v9051 = vadd.s32 1, %v9047 (stack39)
        %v9055 = vadd.s32 %v9051, %v9039 (stack39)
        %v9057 = vshll.u32 %v9051, 17 (stack44)
        %v9058 = vshrl.u32 %v9051, 15 (stack45)
        %v9059 = vor.u32 %v9058, %v9057 (stack46)
        %v9060 = vxor.u32 %v9059, %v9055 (stack47)
        %v9063 = vadd.s32 %v9060, %v9055 (stack39)
        %v9065 = vshll.u32 %v9060, 29 (stack44)
        %v9066 = vshrl.u32 %v9060, 3 (stack45)
        %v9067 = vor.u32 %v9066, %v9065 (stack46)
        %v9068 = vxor.u32 %v9067, %v9063 (stack47)
        %v9071 = vadd.s32 %v9068, %v9063 (stack39)
        %v9073 = vshll.u32 %v9068, 16 (stack44)
        %v9074 = vshrl.u32 %v9068, 16 (stack45)
        %v9075 = vor.u32 %v9074, %v9073 (stack46)
        %v9076 = vxor.u32 %v9075, %v9071 (stack47)
        %v9079 = vadd.s32 %v9076, %v9071 (stack39)
        %v9083 = vadd.s32 %v9079, %v8 (stack39)
        %v9085 = vshll.u32 %v9076, 24 (stack44)
        %v9086 = vshrl.u32 %v9076, 8 (stack45)
        %v9087 = vor.u32 %v9086, %v9085 (stack46)
        %v9088 = vxor.u32 %v9087, %v9079 (stack47)
        %v9091 = vadd.s32 %v9088, %v10 (stack39)
        %v9095 = vadd.s32 2, %v9091 (stack39)
        %v9099 = vadd.s32 %v9095, %v9083 (stack39)
        %v9101 = vshll.u32 %v9095, 13 (stack44)
        %v9102 = vshrl.u32 %v9095, 19 (stack45)
        %v9103 = vor.u32 %v9102, %v9101 (stack46)
        %v9104 = vxor.u32 %v9103, %v9099 (stack47)
        %v9107 = vadd.s32 %v9104, %v9099 (stack39)
        %v9109 = vshll.u32 %v9104, 15 (stack44)
        %v9110 = vshrl.u32 %v9104, 17 (stack45)
        %v9111 = vor.u32 %v9110, %v9109 (stack46)
        %v9112 = vxor.u32 %v9111, %v9107 (stack47)
        %v9115 = vadd.s32 %v9112, %v9107 (stack39)
        %v9117 = vshll.u32 %v9112, 26 (stack44)
        %v9118 = vshrl.u32 %v9112, 6 (stack45)
        %v9119 = vor.u32 %v9118, %v9117 (stack46)
        %v9120 = vxor.u32 %v9119, %v9115 (stack47)
        %v9123 = vadd.s32 %v9120, %v9115 (stack39)
        %v9127 = vadd.s32 %v9123, %v10 (stack39)
        %v9129 = vshll.u32 %v9120, 6 (stack44)
        %v9130 = vshrl.u32 %v9120, 26 (stack45)
        %v9131 = vor.u32 %v9130, %v9129 (stack46)
        %v9132 = vxor.u32 %v9131, %v9123 (stack47)
        %v9135 = vadd.s32 %v9132, %v9 (stack39)
        %v9139 = vadd.s32 3, %v9135 (stack39)
        %v9143 = vadd.s32 %v9139, %v9127 (stack39)
        %v9145 = vshll.u32 %v9139, 17 (stack44)
        %v9146 = vshrl.u32 %v9139, 15 (stack45)
        %v9147 = vor.u32 %v9146, %v9145 (stack46)
        %v9148 = vxor.u32 %v9147, %v9143 (stack47)
        %v9151 = vadd.s32 %v9148, %v9143 (stack39)
        %v9153 = vshll.u32 %v9148, 29 (stack44)
        %v9154 = vshrl.u32 %v9148, 3 (stack45)
        %v9155 = vor.u32 %v9154, %v9153 (stack46)
        %v9156 = vxor.u32 %v9155, %v9151 (stack47)
        %v9159 = vadd.s32 %v9156, %v9151 (stack39)
        %v9161 = vshll.u32 %v9156, 16 (stack44)
        %v9162 = vshrl.u32 %v9156, 16 (stack45)
        %v9163 = vor.u32 %v9162, %v9161 (stack46)
        %v9164 = vxor.u32 %v9163, %v9159 (stack47)
        %v9167 = vadd.s32 %v9164, %v9159 (stack39)
        %v9171 = vadd.s32 %v9167, %v9 (stack39)
        %v9173 = vshll.u32 %v9164, 24 (stack44)
        %v9174 = vshrl.u32 %v9164, 8 (stack45)
        %v9175 = vor.u32 %v9174, %v9173 (stack46)
        %v9176 = vxor.u32 %v9175, %v9167 (stack47)
        %v9179 = vadd.s32 %v9176, %v8 (stack39)
        %v9183 = vadd.s32 4, %v9179 (stack39)
        %v9187 = vadd.s32 %v9183, %v9171 (stack39)
        %v9189 = vshll.u32 %v9183, 13 (stack44)
        %v9190 = vshrl.u32 %v9183, 19 (stack45)
        %v9191 = vor.u32 %v9190, %v9189 (stack46)
        %v9192 = vxor.u32 %v9191, %v9187 (stack47)
        %v9195 = vadd.s32 %v9192, %v9187 (stack39)
        %v9197 = vshll.u32 %v9192, 15 (stack44)
        %v9198 = vshrl.u32 %v9192, 17 (stack45)
        %v9199 = vor.u32 %v9198, %v9197 (stack46)
        %v9200 = vxor.u32 %v9199, %v9195 (stack47)
        %v9203 = vadd.s32 %v9200, %v9195 (stack39)
        %v9205 = vshll.u32 %v9200, 26 (stack44)
        %v9206 = vshrl.u32 %v9200, 6 (stack45)
        %v9207 = vor.u32 %v9206, %v9205 (stack46)
        %v9208 = vxor.u32 %v9207, %v9203 (stack47)
        %v9211 = vadd.s32 %v9208, %v9203 (stack39)
        %v9215 = vadd.s32 %v9211, %v8 (stack39)
        %v9217 = vshll.u32 %v9208, 6 (stack44)
        %v9218 = vshrl.u32 %v9208, 26 (stack45)
        %v9219 = vor.u32 %v9218, %v9217 (stack46)
        %v9220 = vxor.u32 %v9219, %v9211 (stack47)
        %v9223 = vadd.s32 %v9220, %v10 (stack39)
        %v9227 = vadd.s32 5, %v9223 (stack39)
        %v9229 = vxor.u32 %v9227, %v9215 (stack47)
        %v9230 = vand.u32.u8 255, %v9229 (stack48)
        %v9231 = vand.u32 65535, %v9230 (stack49)
        %v9232 = vshrl.u32 %v9231, 1 (stack50)
        %v9233 = vor.u32 16256, %v9232 (stack46)
        %v9234 = vand.u32.u16 65535, %v9233 (stack51)
        %v119792 = vadd.low.f32.bf16 -1.0, %v9234 (stack52)
        %v9243 = vmul.f32 2.0, %v119792 (stack53)
        %v9247 = vadd.f32 -0.99609375, %v9243 (stack52)
        %v9251 = vmax.f32 %v9247, -0.99609375 (stack54)
        %v9253 = vand.u32 2147483647, %v9251 (stack55)
        %vm9256 = vcmp.eq.f32.partialorder %v9253, 1.0 (stack56)
        %v9261 = vmul.f32 inf, %v9251 (stack53)
        %v9263 = vxor.u32 2147483648, %v9251 (stack57)
        %v9266 = vmul.f32 %v9263, %v9251 (stack53)
        %v9268 = vadd.f32 1.0, %v9266 (stack58)
        %v9269 = vlog2.pop %v9268 (stack59)
        %v9270 = vmul.f32 0.6931472, %v9269 (stack60)
        %v9271 = vmul.f32 -0.5, %v9266 (stack61)
        %v9272 = vadd.f32 1.0, %v9271 (stack62)
        %v9273 = vmul.f32 %v9272, %v9266 (stack63)
        %v9274 = vand.u32 2147483647, %v9266 (stack64)
        %vm9275 = vcmp.lt.f32.partialorder %v9274, 0.0004427343 (stack65)
        %v9276 = vsel /*vm=*/%vm9275, /*on_true_vy=*/%v9273, /*on_false_vx=*/%v9270 (stack66)
        %v9277 = vxor.u32 2147483648, %v9276 (stack57)
        %vm9280 = vcmp.lt.f32.partialorder %v9277, 5.0 (stack56)
        %v9285 = vsel /*vm=*/%vm9280, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v9289 = vsel /*vm=*/%vm9280, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v9293 = vsel /*vm=*/%vm9280, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v9297 = vsel /*vm=*/%vm9280, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v9301 = vsel /*vm=*/%vm9280, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v9305 = vsel /*vm=*/%vm9280, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v9309 = vsel /*vm=*/%vm9280, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v9313 = vsel /*vm=*/%vm9280, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v9317 = vsel /*vm=*/%vm9280, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v9321 = vadd.f32 -2.5, %v9277 (stack52)
        %v9323 = vrsqrt.pop %v9277 (stack67)
        %v9324 = vmul.f32 %v9323, %v9277 (stack68)
        %vm9325 = vcmp.eq.f32.partialorder %v9277, inf (stack69)
        %v9326 = vsel /*vm=*/%vm9325, /*on_true_vy=*/%v9277, /*on_false_vx=*/%v9324 (stack70)
        %vm9327 = vcmp.eq.f32.partialorder %v9277, 0.0 (stack71)
        %v9328 = vand.u32 2147483648, %v9277 (stack72)
        %v9329 = vsel /*vm=*/%vm9327, /*on_true_vy=*/%v9328, /*on_false_vx=*/%v9326 (stack73)
        %v9332 = vadd.f32 -3.0, %v9329 (stack52)
        %v9336 = vsel /*vm=*/%vm9280, /*on_true_vy=*/%v9321, /*on_false_vx=*/%v9332 (stack43)
        %v9340 = vmul.f32 %v9336, %v9317 (stack53)
        %v9344 = vadd.f32 %v9340, %v9313 (stack52)
        %v9348 = vmul.f32 %v9344, %v9336 (stack53)
        %v9352 = vadd.f32 %v9348, %v9309 (stack52)
        %v9356 = vmul.f32 %v9352, %v9336 (stack53)
        %v9360 = vadd.f32 %v9356, %v9305 (stack52)
        %v9364 = vmul.f32 %v9360, %v9336 (stack53)
        %v9368 = vadd.f32 %v9364, %v9301 (stack52)
        %v9372 = vmul.f32 %v9368, %v9336 (stack53)
        %v9376 = vadd.f32 %v9372, %v9297 (stack52)
        %v9380 = vmul.f32 %v9376, %v9336 (stack53)
        %v9384 = vadd.f32 %v9380, %v9293 (stack52)
        %v9388 = vmul.f32 %v9384, %v9336 (stack53)
        %v9392 = vadd.f32 %v9388, %v9289 (stack52)
        %v9396 = vmul.f32 %v9392, %v9336 (stack53)
        %v9400 = vadd.f32 %v9396, %v9285 (stack52)
        %v9404 = vmul.f32 %v9400, %v9251 (stack53)
        %v9408 = vsel /*vm=*/%vm9256, /*on_true_vy=*/%v9261, /*on_false_vx=*/%v9404 (stack43)
        %v9412 = vmul.f32 1.4140625, %v9408 (stack53)
        %v9415 = vpack.c.bf16 0.0, %v9412 (stack74)
        %119793 = vst [vmem:[%s280 + $0x108] sm:$0xf] /*vst_source=*/%v9415 (stack75)
        %v9419 = vadd.s32 %v8033, %v1868 (stack39)
        %v9429 = vadd.s32 %v9419, %v415 (stack39)
        %vm9433 = vcmp.lt.u32.totalorder %v9429, %v9419 (stack42)
        %vm9438 = vcmp.lt.u32.totalorder %v9419, %v1868 (stack42)
        %v9443 = vadd.s32 %v8016, %v1855 (stack39)
        %v9447 = vadd.s32 1, %v9443 (stack39)
        %v9451 = vsel /*vm=*/%vm9438, /*on_true_vy=*/%v9447, /*on_false_vx=*/%v9443 (stack43)
        %v9455 = vadd.s32 1, %v9451 (stack39)
        %v9459 = vsel /*vm=*/%vm9433, /*on_true_vy=*/%v9455, /*on_false_vx=*/%v9451 (stack43)
        %v9464 = vadd.s32 %v9459, %v10 (stack39)
        %v9468 = vadd.s32 %v9429, %v9 (stack39)
        %v9472 = vadd.s32 %v9468, %v9464 (stack39)
        %v9474 = vshll.u32 %v9468, 13 (stack44)
        %v9475 = vshrl.u32 %v9468, 19 (stack45)
        %v9476 = vor.u32 %v9475, %v9474 (stack46)
        %v9477 = vxor.u32 %v9476, %v9472 (stack47)
        %v9480 = vadd.s32 %v9477, %v9472 (stack39)
        %v9482 = vshll.u32 %v9477, 15 (stack44)
        %v9483 = vshrl.u32 %v9477, 17 (stack45)
        %v9484 = vor.u32 %v9483, %v9482 (stack46)
        %v9485 = vxor.u32 %v9484, %v9480 (stack47)
        %v9488 = vadd.s32 %v9485, %v9480 (stack39)
        %v9490 = vshll.u32 %v9485, 26 (stack44)
        %v9491 = vshrl.u32 %v9485, 6 (stack45)
        %v9492 = vor.u32 %v9491, %v9490 (stack46)
        %v9493 = vxor.u32 %v9492, %v9488 (stack47)
        %v9496 = vadd.s32 %v9493, %v9488 (stack39)
        %v9500 = vadd.s32 %v9496, %v9 (stack39)
        %v9502 = vshll.u32 %v9493, 6 (stack44)
        %v9503 = vshrl.u32 %v9493, 26 (stack45)
        %v9504 = vor.u32 %v9503, %v9502 (stack46)
        %v9505 = vxor.u32 %v9504, %v9496 (stack47)
        %v9508 = vadd.s32 %v9505, %v8 (stack39)
        %v9512 = vadd.s32 1, %v9508 (stack39)
        %v9516 = vadd.s32 %v9512, %v9500 (stack39)
        %v9518 = vshll.u32 %v9512, 17 (stack44)
        %v9519 = vshrl.u32 %v9512, 15 (stack45)
        %v9520 = vor.u32 %v9519, %v9518 (stack46)
        %v9521 = vxor.u32 %v9520, %v9516 (stack47)
        %v9524 = vadd.s32 %v9521, %v9516 (stack39)
        %v9526 = vshll.u32 %v9521, 29 (stack44)
        %v9527 = vshrl.u32 %v9521, 3 (stack45)
        %v9528 = vor.u32 %v9527, %v9526 (stack46)
        %v9529 = vxor.u32 %v9528, %v9524 (stack47)
        %v9532 = vadd.s32 %v9529, %v9524 (stack39)
        %v9534 = vshll.u32 %v9529, 16 (stack44)
        %v9535 = vshrl.u32 %v9529, 16 (stack45)
        %v9536 = vor.u32 %v9535, %v9534 (stack46)
        %v9537 = vxor.u32 %v9536, %v9532 (stack47)
        %v9540 = vadd.s32 %v9537, %v9532 (stack39)
        %v9544 = vadd.s32 %v9540, %v8 (stack39)
        %v9546 = vshll.u32 %v9537, 24 (stack44)
        %v9547 = vshrl.u32 %v9537, 8 (stack45)
        %v9548 = vor.u32 %v9547, %v9546 (stack46)
        %v9549 = vxor.u32 %v9548, %v9540 (stack47)
        %v9552 = vadd.s32 %v9549, %v10 (stack39)
        %v9556 = vadd.s32 2, %v9552 (stack39)
        %v9560 = vadd.s32 %v9556, %v9544 (stack39)
        %v9562 = vshll.u32 %v9556, 13 (stack44)
        %v9563 = vshrl.u32 %v9556, 19 (stack45)
        %v9564 = vor.u32 %v9563, %v9562 (stack46)
        %v9565 = vxor.u32 %v9564, %v9560 (stack47)
        %v9568 = vadd.s32 %v9565, %v9560 (stack39)
        %v9570 = vshll.u32 %v9565, 15 (stack44)
        %v9571 = vshrl.u32 %v9565, 17 (stack45)
        %v9572 = vor.u32 %v9571, %v9570 (stack46)
        %v9573 = vxor.u32 %v9572, %v9568 (stack47)
        %v9576 = vadd.s32 %v9573, %v9568 (stack39)
        %v9578 = vshll.u32 %v9573, 26 (stack44)
        %v9579 = vshrl.u32 %v9573, 6 (stack45)
        %v9580 = vor.u32 %v9579, %v9578 (stack46)
        %v9581 = vxor.u32 %v9580, %v9576 (stack47)
        %v9584 = vadd.s32 %v9581, %v9576 (stack39)
        %v9588 = vadd.s32 %v9584, %v10 (stack39)
        %v9590 = vshll.u32 %v9581, 6 (stack44)
        %v9591 = vshrl.u32 %v9581, 26 (stack45)
        %v9592 = vor.u32 %v9591, %v9590 (stack46)
        %v9593 = vxor.u32 %v9592, %v9584 (stack47)
        %v9596 = vadd.s32 %v9593, %v9 (stack39)
        %v9600 = vadd.s32 3, %v9596 (stack39)
        %v9604 = vadd.s32 %v9600, %v9588 (stack39)
        %v9606 = vshll.u32 %v9600, 17 (stack44)
        %v9607 = vshrl.u32 %v9600, 15 (stack45)
        %v9608 = vor.u32 %v9607, %v9606 (stack46)
        %v9609 = vxor.u32 %v9608, %v9604 (stack47)
        %v9612 = vadd.s32 %v9609, %v9604 (stack39)
        %v9614 = vshll.u32 %v9609, 29 (stack44)
        %v9615 = vshrl.u32 %v9609, 3 (stack45)
        %v9616 = vor.u32 %v9615, %v9614 (stack46)
        %v9617 = vxor.u32 %v9616, %v9612 (stack47)
        %v9620 = vadd.s32 %v9617, %v9612 (stack39)
        %v9622 = vshll.u32 %v9617, 16 (stack44)
        %v9623 = vshrl.u32 %v9617, 16 (stack45)
        %v9624 = vor.u32 %v9623, %v9622 (stack46)
        %v9625 = vxor.u32 %v9624, %v9620 (stack47)
        %v9628 = vadd.s32 %v9625, %v9620 (stack39)
        %v9632 = vadd.s32 %v9628, %v9 (stack39)
        %v9634 = vshll.u32 %v9625, 24 (stack44)
        %v9635 = vshrl.u32 %v9625, 8 (stack45)
        %v9636 = vor.u32 %v9635, %v9634 (stack46)
        %v9637 = vxor.u32 %v9636, %v9628 (stack47)
        %v9640 = vadd.s32 %v9637, %v8 (stack39)
        %v9644 = vadd.s32 4, %v9640 (stack39)
        %v9648 = vadd.s32 %v9644, %v9632 (stack39)
        %v9650 = vshll.u32 %v9644, 13 (stack44)
        %v9651 = vshrl.u32 %v9644, 19 (stack45)
        %v9652 = vor.u32 %v9651, %v9650 (stack46)
        %v9653 = vxor.u32 %v9652, %v9648 (stack47)
        %v9656 = vadd.s32 %v9653, %v9648 (stack39)
        %v9658 = vshll.u32 %v9653, 15 (stack44)
        %v9659 = vshrl.u32 %v9653, 17 (stack45)
        %v9660 = vor.u32 %v9659, %v9658 (stack46)
        %v9661 = vxor.u32 %v9660, %v9656 (stack47)
        %v9664 = vadd.s32 %v9661, %v9656 (stack39)
        %v9666 = vshll.u32 %v9661, 26 (stack44)
        %v9667 = vshrl.u32 %v9661, 6 (stack45)
        %v9668 = vor.u32 %v9667, %v9666 (stack46)
        %v9669 = vxor.u32 %v9668, %v9664 (stack47)
        %v9672 = vadd.s32 %v9669, %v9664 (stack39)
        %v9676 = vadd.s32 %v9672, %v8 (stack39)
        %v9678 = vshll.u32 %v9669, 6 (stack44)
        %v9679 = vshrl.u32 %v9669, 26 (stack45)
        %v9680 = vor.u32 %v9679, %v9678 (stack46)
        %v9681 = vxor.u32 %v9680, %v9672 (stack47)
        %v9684 = vadd.s32 %v9681, %v10 (stack39)
        %v9688 = vadd.s32 5, %v9684 (stack39)
        %v9690 = vxor.u32 %v9688, %v9676 (stack47)
        %v9691 = vand.u32.u8 255, %v9690 (stack48)
        %v9692 = vand.u32 65535, %v9691 (stack49)
        %v9693 = vshrl.u32 %v9692, 1 (stack50)
        %v9694 = vor.u32 16256, %v9693 (stack46)
        %v9695 = vand.u32.u16 65535, %v9694 (stack51)
        %v119794 = vadd.low.f32.bf16 -1.0, %v9695 (stack52)
        %v9704 = vmul.f32 2.0, %v119794 (stack53)
        %v9708 = vadd.f32 -0.99609375, %v9704 (stack52)
        %v9712 = vmax.f32 %v9708, -0.99609375 (stack54)
        %v9714 = vand.u32 2147483647, %v9712 (stack55)
        %vm9717 = vcmp.eq.f32.partialorder %v9714, 1.0 (stack56)
        %v9722 = vmul.f32 inf, %v9712 (stack53)
        %v9724 = vxor.u32 2147483648, %v9712 (stack57)
        %v9727 = vmul.f32 %v9724, %v9712 (stack53)
        %v9729 = vadd.f32 1.0, %v9727 (stack58)
        %v9730 = vlog2.pop %v9729 (stack59)
        %v9731 = vmul.f32 0.6931472, %v9730 (stack60)
        %v9732 = vmul.f32 -0.5, %v9727 (stack61)
        %v9733 = vadd.f32 1.0, %v9732 (stack62)
        %v9734 = vmul.f32 %v9733, %v9727 (stack63)
        %v9735 = vand.u32 2147483647, %v9727 (stack64)
        %vm9736 = vcmp.lt.f32.partialorder %v9735, 0.0004427343 (stack65)
        %v9737 = vsel /*vm=*/%vm9736, /*on_true_vy=*/%v9734, /*on_false_vx=*/%v9731 (stack66)
        %v9738 = vxor.u32 2147483648, %v9737 (stack57)
        %vm9741 = vcmp.lt.f32.partialorder %v9738, 5.0 (stack56)
        %v9746 = vsel /*vm=*/%vm9741, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v9750 = vsel /*vm=*/%vm9741, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v9754 = vsel /*vm=*/%vm9741, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v9758 = vsel /*vm=*/%vm9741, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v9762 = vsel /*vm=*/%vm9741, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v9766 = vsel /*vm=*/%vm9741, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v9770 = vsel /*vm=*/%vm9741, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v9774 = vsel /*vm=*/%vm9741, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v9778 = vsel /*vm=*/%vm9741, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v9782 = vadd.f32 -2.5, %v9738 (stack52)
        %v9784 = vrsqrt.pop %v9738 (stack67)
        %v9785 = vmul.f32 %v9784, %v9738 (stack68)
        %vm9786 = vcmp.eq.f32.partialorder %v9738, inf (stack69)
        %v9787 = vsel /*vm=*/%vm9786, /*on_true_vy=*/%v9738, /*on_false_vx=*/%v9785 (stack70)
        %vm9788 = vcmp.eq.f32.partialorder %v9738, 0.0 (stack71)
        %v9789 = vand.u32 2147483648, %v9738 (stack72)
        %v9790 = vsel /*vm=*/%vm9788, /*on_true_vy=*/%v9789, /*on_false_vx=*/%v9787 (stack73)
        %v9793 = vadd.f32 -3.0, %v9790 (stack52)
        %v9797 = vsel /*vm=*/%vm9741, /*on_true_vy=*/%v9782, /*on_false_vx=*/%v9793 (stack43)
        %v9801 = vmul.f32 %v9797, %v9778 (stack53)
        %v9805 = vadd.f32 %v9801, %v9774 (stack52)
        %v9809 = vmul.f32 %v9805, %v9797 (stack53)
        %v9813 = vadd.f32 %v9809, %v9770 (stack52)
        %v9817 = vmul.f32 %v9813, %v9797 (stack53)
        %v9821 = vadd.f32 %v9817, %v9766 (stack52)
        %v9825 = vmul.f32 %v9821, %v9797 (stack53)
        %v9829 = vadd.f32 %v9825, %v9762 (stack52)
        %v9833 = vmul.f32 %v9829, %v9797 (stack53)
        %v9837 = vadd.f32 %v9833, %v9758 (stack52)
        %v9841 = vmul.f32 %v9837, %v9797 (stack53)
        %v9845 = vadd.f32 %v9841, %v9754 (stack52)
        %v9849 = vmul.f32 %v9845, %v9797 (stack53)
        %v9853 = vadd.f32 %v9849, %v9750 (stack52)
        %v9857 = vmul.f32 %v9853, %v9797 (stack53)
        %v9861 = vadd.f32 %v9857, %v9746 (stack52)
        %v9865 = vmul.f32 %v9861, %v9712 (stack53)
        %v9869 = vsel /*vm=*/%vm9717, /*on_true_vy=*/%v9722, /*on_false_vx=*/%v9865 (stack43)
        %v9873 = vmul.f32 1.4140625, %v9869 (stack53)
        %v9876 = vpack.c.bf16 0.0, %v9873 (stack74)
        %119795 = vst [vmem:[%s280 + $0x188] sm:$0xf] /*vst_source=*/%v9876 (stack75)
        %v9880 = vadd.s32 %v8033, %v2355 (stack39)
        %v9890 = vadd.s32 %v9880, %v415 (stack39)
        %vm9894 = vcmp.lt.u32.totalorder %v9890, %v9880 (stack42)
        %vm9899 = vcmp.lt.u32.totalorder %v9880, %v2355 (stack42)
        %v9904 = vadd.s32 %v8016, %v2342 (stack39)
        %v9908 = vadd.s32 1, %v9904 (stack39)
        %v9912 = vsel /*vm=*/%vm9899, /*on_true_vy=*/%v9908, /*on_false_vx=*/%v9904 (stack43)
        %v9916 = vadd.s32 1, %v9912 (stack39)
        %v9920 = vsel /*vm=*/%vm9894, /*on_true_vy=*/%v9916, /*on_false_vx=*/%v9912 (stack43)
        %v9925 = vadd.s32 %v9920, %v10 (stack39)
        %v9929 = vadd.s32 %v9890, %v9 (stack39)
        %v9933 = vadd.s32 %v9929, %v9925 (stack39)
        %v9935 = vshll.u32 %v9929, 13 (stack44)
        %v9936 = vshrl.u32 %v9929, 19 (stack45)
        %v9937 = vor.u32 %v9936, %v9935 (stack46)
        %v9938 = vxor.u32 %v9937, %v9933 (stack47)
        %v9941 = vadd.s32 %v9938, %v9933 (stack39)
        %v9943 = vshll.u32 %v9938, 15 (stack44)
        %v9944 = vshrl.u32 %v9938, 17 (stack45)
        %v9945 = vor.u32 %v9944, %v9943 (stack46)
        %v9946 = vxor.u32 %v9945, %v9941 (stack47)
        %v9949 = vadd.s32 %v9946, %v9941 (stack39)
        %v9951 = vshll.u32 %v9946, 26 (stack44)
        %v9952 = vshrl.u32 %v9946, 6 (stack45)
        %v9953 = vor.u32 %v9952, %v9951 (stack46)
        %v9954 = vxor.u32 %v9953, %v9949 (stack47)
        %v9957 = vadd.s32 %v9954, %v9949 (stack39)
        %v9961 = vadd.s32 %v9957, %v9 (stack39)
        %v9963 = vshll.u32 %v9954, 6 (stack44)
        %v9964 = vshrl.u32 %v9954, 26 (stack45)
        %v9965 = vor.u32 %v9964, %v9963 (stack46)
        %v9966 = vxor.u32 %v9965, %v9957 (stack47)
        %v9969 = vadd.s32 %v9966, %v8 (stack39)
        %v9973 = vadd.s32 1, %v9969 (stack39)
        %v9977 = vadd.s32 %v9973, %v9961 (stack39)
        %v9979 = vshll.u32 %v9973, 17 (stack44)
        %v9980 = vshrl.u32 %v9973, 15 (stack45)
        %v9981 = vor.u32 %v9980, %v9979 (stack46)
        %v9982 = vxor.u32 %v9981, %v9977 (stack47)
        %v9985 = vadd.s32 %v9982, %v9977 (stack39)
        %v9987 = vshll.u32 %v9982, 29 (stack44)
        %v9988 = vshrl.u32 %v9982, 3 (stack45)
        %v9989 = vor.u32 %v9988, %v9987 (stack46)
        %v9990 = vxor.u32 %v9989, %v9985 (stack47)
        %v9993 = vadd.s32 %v9990, %v9985 (stack39)
        %v9995 = vshll.u32 %v9990, 16 (stack44)
        %v9996 = vshrl.u32 %v9990, 16 (stack45)
        %v9997 = vor.u32 %v9996, %v9995 (stack46)
        %v9998 = vxor.u32 %v9997, %v9993 (stack47)
        %v10001 = vadd.s32 %v9998, %v9993 (stack39)
        %v10005 = vadd.s32 %v10001, %v8 (stack39)
        %v10007 = vshll.u32 %v9998, 24 (stack44)
        %v10008 = vshrl.u32 %v9998, 8 (stack45)
        %v10009 = vor.u32 %v10008, %v10007 (stack46)
        %v10010 = vxor.u32 %v10009, %v10001 (stack47)
        %v10013 = vadd.s32 %v10010, %v10 (stack39)
        %v10017 = vadd.s32 2, %v10013 (stack39)
        %v10021 = vadd.s32 %v10017, %v10005 (stack39)
        %v10023 = vshll.u32 %v10017, 13 (stack44)
        %v10024 = vshrl.u32 %v10017, 19 (stack45)
        %v10025 = vor.u32 %v10024, %v10023 (stack46)
        %v10026 = vxor.u32 %v10025, %v10021 (stack47)
        %v10029 = vadd.s32 %v10026, %v10021 (stack39)
        %v10031 = vshll.u32 %v10026, 15 (stack44)
        %v10032 = vshrl.u32 %v10026, 17 (stack45)
        %v10033 = vor.u32 %v10032, %v10031 (stack46)
        %v10034 = vxor.u32 %v10033, %v10029 (stack47)
        %v10037 = vadd.s32 %v10034, %v10029 (stack39)
        %v10039 = vshll.u32 %v10034, 26 (stack44)
        %v10040 = vshrl.u32 %v10034, 6 (stack45)
        %v10041 = vor.u32 %v10040, %v10039 (stack46)
        %v10042 = vxor.u32 %v10041, %v10037 (stack47)
        %v10045 = vadd.s32 %v10042, %v10037 (stack39)
        %v10049 = vadd.s32 %v10045, %v10 (stack39)
        %v10051 = vshll.u32 %v10042, 6 (stack44)
        %v10052 = vshrl.u32 %v10042, 26 (stack45)
        %v10053 = vor.u32 %v10052, %v10051 (stack46)
        %v10054 = vxor.u32 %v10053, %v10045 (stack47)
        %v10057 = vadd.s32 %v10054, %v9 (stack39)
        %v10061 = vadd.s32 3, %v10057 (stack39)
        %v10065 = vadd.s32 %v10061, %v10049 (stack39)
        %v10067 = vshll.u32 %v10061, 17 (stack44)
        %v10068 = vshrl.u32 %v10061, 15 (stack45)
        %v10069 = vor.u32 %v10068, %v10067 (stack46)
        %v10070 = vxor.u32 %v10069, %v10065 (stack47)
        %v10073 = vadd.s32 %v10070, %v10065 (stack39)
        %v10075 = vshll.u32 %v10070, 29 (stack44)
        %v10076 = vshrl.u32 %v10070, 3 (stack45)
        %v10077 = vor.u32 %v10076, %v10075 (stack46)
        %v10078 = vxor.u32 %v10077, %v10073 (stack47)
        %v10081 = vadd.s32 %v10078, %v10073 (stack39)
        %v10083 = vshll.u32 %v10078, 16 (stack44)
        %v10084 = vshrl.u32 %v10078, 16 (stack45)
        %v10085 = vor.u32 %v10084, %v10083 (stack46)
        %v10086 = vxor.u32 %v10085, %v10081 (stack47)
        %v10089 = vadd.s32 %v10086, %v10081 (stack39)
        %v10093 = vadd.s32 %v10089, %v9 (stack39)
        %v10095 = vshll.u32 %v10086, 24 (stack44)
        %v10096 = vshrl.u32 %v10086, 8 (stack45)
        %v10097 = vor.u32 %v10096, %v10095 (stack46)
        %v10098 = vxor.u32 %v10097, %v10089 (stack47)
        %v10101 = vadd.s32 %v10098, %v8 (stack39)
        %v10105 = vadd.s32 4, %v10101 (stack39)
        %v10109 = vadd.s32 %v10105, %v10093 (stack39)
        %v10111 = vshll.u32 %v10105, 13 (stack44)
        %v10112 = vshrl.u32 %v10105, 19 (stack45)
        %v10113 = vor.u32 %v10112, %v10111 (stack46)
        %v10114 = vxor.u32 %v10113, %v10109 (stack47)
        %v10117 = vadd.s32 %v10114, %v10109 (stack39)
        %v10119 = vshll.u32 %v10114, 15 (stack44)
        %v10120 = vshrl.u32 %v10114, 17 (stack45)
        %v10121 = vor.u32 %v10120, %v10119 (stack46)
        %v10122 = vxor.u32 %v10121, %v10117 (stack47)
        %v10125 = vadd.s32 %v10122, %v10117 (stack39)
        %v10127 = vshll.u32 %v10122, 26 (stack44)
        %v10128 = vshrl.u32 %v10122, 6 (stack45)
        %v10129 = vor.u32 %v10128, %v10127 (stack46)
        %v10130 = vxor.u32 %v10129, %v10125 (stack47)
        %v10133 = vadd.s32 %v10130, %v10125 (stack39)
        %v10137 = vadd.s32 %v10133, %v8 (stack39)
        %v10139 = vshll.u32 %v10130, 6 (stack44)
        %v10140 = vshrl.u32 %v10130, 26 (stack45)
        %v10141 = vor.u32 %v10140, %v10139 (stack46)
        %v10142 = vxor.u32 %v10141, %v10133 (stack47)
        %v10145 = vadd.s32 %v10142, %v10 (stack39)
        %v10149 = vadd.s32 5, %v10145 (stack39)
        %v10151 = vxor.u32 %v10149, %v10137 (stack47)
        %v10152 = vand.u32.u8 255, %v10151 (stack48)
        %v10153 = vand.u32 65535, %v10152 (stack49)
        %v10154 = vshrl.u32 %v10153, 1 (stack50)
        %v10155 = vor.u32 16256, %v10154 (stack46)
        %v10156 = vand.u32.u16 65535, %v10155 (stack51)
        %v119796 = vadd.low.f32.bf16 -1.0, %v10156 (stack52)
        %v10165 = vmul.f32 2.0, %v119796 (stack53)
        %v10169 = vadd.f32 -0.99609375, %v10165 (stack52)
        %v10173 = vmax.f32 %v10169, -0.99609375 (stack54)
        %v10175 = vand.u32 2147483647, %v10173 (stack55)
        %vm10178 = vcmp.eq.f32.partialorder %v10175, 1.0 (stack56)
        %v10183 = vmul.f32 inf, %v10173 (stack53)
        %v10185 = vxor.u32 2147483648, %v10173 (stack57)
        %v10188 = vmul.f32 %v10185, %v10173 (stack53)
        %v10190 = vadd.f32 1.0, %v10188 (stack58)
        %v10191 = vlog2.pop %v10190 (stack59)
        %v10192 = vmul.f32 0.6931472, %v10191 (stack60)
        %v10193 = vmul.f32 -0.5, %v10188 (stack61)
        %v10194 = vadd.f32 1.0, %v10193 (stack62)
        %v10195 = vmul.f32 %v10194, %v10188 (stack63)
        %v10196 = vand.u32 2147483647, %v10188 (stack64)
        %vm10197 = vcmp.lt.f32.partialorder %v10196, 0.0004427343 (stack65)
        %v10198 = vsel /*vm=*/%vm10197, /*on_true_vy=*/%v10195, /*on_false_vx=*/%v10192 (stack66)
        %v10199 = vxor.u32 2147483648, %v10198 (stack57)
        %vm10202 = vcmp.lt.f32.partialorder %v10199, 5.0 (stack56)
        %v10207 = vsel /*vm=*/%vm10202, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v10211 = vsel /*vm=*/%vm10202, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v10215 = vsel /*vm=*/%vm10202, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v10219 = vsel /*vm=*/%vm10202, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v10223 = vsel /*vm=*/%vm10202, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v10227 = vsel /*vm=*/%vm10202, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v10231 = vsel /*vm=*/%vm10202, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v10235 = vsel /*vm=*/%vm10202, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v10239 = vsel /*vm=*/%vm10202, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v10243 = vadd.f32 -2.5, %v10199 (stack52)
        %v10245 = vrsqrt.pop %v10199 (stack67)
        %v10246 = vmul.f32 %v10245, %v10199 (stack68)
        %vm10247 = vcmp.eq.f32.partialorder %v10199, inf (stack69)
        %v10248 = vsel /*vm=*/%vm10247, /*on_true_vy=*/%v10199, /*on_false_vx=*/%v10246 (stack70)
        %vm10249 = vcmp.eq.f32.partialorder %v10199, 0.0 (stack71)
        %v10250 = vand.u32 2147483648, %v10199 (stack72)
        %v10251 = vsel /*vm=*/%vm10249, /*on_true_vy=*/%v10250, /*on_false_vx=*/%v10248 (stack73)
        %v10254 = vadd.f32 -3.0, %v10251 (stack52)
        %v10258 = vsel /*vm=*/%vm10202, /*on_true_vy=*/%v10243, /*on_false_vx=*/%v10254 (stack43)
        %v10262 = vmul.f32 %v10258, %v10239 (stack53)
        %v10266 = vadd.f32 %v10262, %v10235 (stack52)
        %v10270 = vmul.f32 %v10266, %v10258 (stack53)
        %v10274 = vadd.f32 %v10270, %v10231 (stack52)
        %v10278 = vmul.f32 %v10274, %v10258 (stack53)
        %v10282 = vadd.f32 %v10278, %v10227 (stack52)
        %v10286 = vmul.f32 %v10282, %v10258 (stack53)
        %v10290 = vadd.f32 %v10286, %v10223 (stack52)
        %v10294 = vmul.f32 %v10290, %v10258 (stack53)
        %v10298 = vadd.f32 %v10294, %v10219 (stack52)
        %v10302 = vmul.f32 %v10298, %v10258 (stack53)
        %v10306 = vadd.f32 %v10302, %v10215 (stack52)
        %v10310 = vmul.f32 %v10306, %v10258 (stack53)
        %v10314 = vadd.f32 %v10310, %v10211 (stack52)
        %v10318 = vmul.f32 %v10314, %v10258 (stack53)
        %v10322 = vadd.f32 %v10318, %v10207 (stack52)
        %v10326 = vmul.f32 %v10322, %v10173 (stack53)
        %v10330 = vsel /*vm=*/%vm10178, /*on_true_vy=*/%v10183, /*on_false_vx=*/%v10326 (stack43)
        %v10334 = vmul.f32 1.4140625, %v10330 (stack53)
        %v10337 = vpack.c.bf16 0.0, %v10334 (stack74)
        %119797 = vst [vmem:[%s280 + $0x208] sm:$0xf] /*vst_source=*/%v10337 (stack75)
        %v10341 = vadd.s32 %v8033, %v2842 (stack39)
        %v10351 = vadd.s32 %v10341, %v415 (stack39)
        %vm10355 = vcmp.lt.u32.totalorder %v10351, %v10341 (stack42)
        %vm10360 = vcmp.lt.u32.totalorder %v10341, %v2842 (stack42)
        %v10365 = vadd.s32 %v8016, %v2829 (stack39)
        %v10369 = vadd.s32 1, %v10365 (stack39)
        %v10373 = vsel /*vm=*/%vm10360, /*on_true_vy=*/%v10369, /*on_false_vx=*/%v10365 (stack43)
        %v10377 = vadd.s32 1, %v10373 (stack39)
        %v10381 = vsel /*vm=*/%vm10355, /*on_true_vy=*/%v10377, /*on_false_vx=*/%v10373 (stack43)
        %v10386 = vadd.s32 %v10381, %v10 (stack39)
        %v10390 = vadd.s32 %v10351, %v9 (stack39)
        %v10394 = vadd.s32 %v10390, %v10386 (stack39)
        %v10396 = vshll.u32 %v10390, 13 (stack44)
        %v10397 = vshrl.u32 %v10390, 19 (stack45)
        %v10398 = vor.u32 %v10397, %v10396 (stack46)
        %v10399 = vxor.u32 %v10398, %v10394 (stack47)
        %v10402 = vadd.s32 %v10399, %v10394 (stack39)
        %v10404 = vshll.u32 %v10399, 15 (stack44)
        %v10405 = vshrl.u32 %v10399, 17 (stack45)
        %v10406 = vor.u32 %v10405, %v10404 (stack46)
        %v10407 = vxor.u32 %v10406, %v10402 (stack47)
        %v10410 = vadd.s32 %v10407, %v10402 (stack39)
        %v10412 = vshll.u32 %v10407, 26 (stack44)
        %v10413 = vshrl.u32 %v10407, 6 (stack45)
        %v10414 = vor.u32 %v10413, %v10412 (stack46)
        %v10415 = vxor.u32 %v10414, %v10410 (stack47)
        %v10418 = vadd.s32 %v10415, %v10410 (stack39)
        %v10422 = vadd.s32 %v10418, %v9 (stack39)
        %v10424 = vshll.u32 %v10415, 6 (stack44)
        %v10425 = vshrl.u32 %v10415, 26 (stack45)
        %v10426 = vor.u32 %v10425, %v10424 (stack46)
        %v10427 = vxor.u32 %v10426, %v10418 (stack47)
        %v10430 = vadd.s32 %v10427, %v8 (stack39)
        %v10434 = vadd.s32 1, %v10430 (stack39)
        %v10438 = vadd.s32 %v10434, %v10422 (stack39)
        %v10440 = vshll.u32 %v10434, 17 (stack44)
        %v10441 = vshrl.u32 %v10434, 15 (stack45)
        %v10442 = vor.u32 %v10441, %v10440 (stack46)
        %v10443 = vxor.u32 %v10442, %v10438 (stack47)
        %v10446 = vadd.s32 %v10443, %v10438 (stack39)
        %v10448 = vshll.u32 %v10443, 29 (stack44)
        %v10449 = vshrl.u32 %v10443, 3 (stack45)
        %v10450 = vor.u32 %v10449, %v10448 (stack46)
        %v10451 = vxor.u32 %v10450, %v10446 (stack47)
        %v10454 = vadd.s32 %v10451, %v10446 (stack39)
        %v10456 = vshll.u32 %v10451, 16 (stack44)
        %v10457 = vshrl.u32 %v10451, 16 (stack45)
        %v10458 = vor.u32 %v10457, %v10456 (stack46)
        %v10459 = vxor.u32 %v10458, %v10454 (stack47)
        %v10462 = vadd.s32 %v10459, %v10454 (stack39)
        %v10466 = vadd.s32 %v10462, %v8 (stack39)
        %v10468 = vshll.u32 %v10459, 24 (stack44)
        %v10469 = vshrl.u32 %v10459, 8 (stack45)
        %v10470 = vor.u32 %v10469, %v10468 (stack46)
        %v10471 = vxor.u32 %v10470, %v10462 (stack47)
        %v10474 = vadd.s32 %v10471, %v10 (stack39)
        %v10478 = vadd.s32 2, %v10474 (stack39)
        %v10482 = vadd.s32 %v10478, %v10466 (stack39)
        %v10484 = vshll.u32 %v10478, 13 (stack44)
        %v10485 = vshrl.u32 %v10478, 19 (stack45)
        %v10486 = vor.u32 %v10485, %v10484 (stack46)
        %v10487 = vxor.u32 %v10486, %v10482 (stack47)
        %v10490 = vadd.s32 %v10487, %v10482 (stack39)
        %v10492 = vshll.u32 %v10487, 15 (stack44)
        %v10493 = vshrl.u32 %v10487, 17 (stack45)
        %v10494 = vor.u32 %v10493, %v10492 (stack46)
        %v10495 = vxor.u32 %v10494, %v10490 (stack47)
        %v10498 = vadd.s32 %v10495, %v10490 (stack39)
        %v10500 = vshll.u32 %v10495, 26 (stack44)
        %v10501 = vshrl.u32 %v10495, 6 (stack45)
        %v10502 = vor.u32 %v10501, %v10500 (stack46)
        %v10503 = vxor.u32 %v10502, %v10498 (stack47)
        %v10506 = vadd.s32 %v10503, %v10498 (stack39)
        %v10510 = vadd.s32 %v10506, %v10 (stack39)
        %v10512 = vshll.u32 %v10503, 6 (stack44)
        %v10513 = vshrl.u32 %v10503, 26 (stack45)
        %v10514 = vor.u32 %v10513, %v10512 (stack46)
        %v10515 = vxor.u32 %v10514, %v10506 (stack47)
        %v10518 = vadd.s32 %v10515, %v9 (stack39)
        %v10522 = vadd.s32 3, %v10518 (stack39)
        %v10526 = vadd.s32 %v10522, %v10510 (stack39)
        %v10528 = vshll.u32 %v10522, 17 (stack44)
        %v10529 = vshrl.u32 %v10522, 15 (stack45)
        %v10530 = vor.u32 %v10529, %v10528 (stack46)
        %v10531 = vxor.u32 %v10530, %v10526 (stack47)
        %v10534 = vadd.s32 %v10531, %v10526 (stack39)
        %v10536 = vshll.u32 %v10531, 29 (stack44)
        %v10537 = vshrl.u32 %v10531, 3 (stack45)
        %v10538 = vor.u32 %v10537, %v10536 (stack46)
        %v10539 = vxor.u32 %v10538, %v10534 (stack47)
        %v10542 = vadd.s32 %v10539, %v10534 (stack39)
        %v10544 = vshll.u32 %v10539, 16 (stack44)
        %v10545 = vshrl.u32 %v10539, 16 (stack45)
        %v10546 = vor.u32 %v10545, %v10544 (stack46)
        %v10547 = vxor.u32 %v10546, %v10542 (stack47)
        %v10550 = vadd.s32 %v10547, %v10542 (stack39)
        %v10554 = vadd.s32 %v10550, %v9 (stack39)
        %v10556 = vshll.u32 %v10547, 24 (stack44)
        %v10557 = vshrl.u32 %v10547, 8 (stack45)
        %v10558 = vor.u32 %v10557, %v10556 (stack46)
        %v10559 = vxor.u32 %v10558, %v10550 (stack47)
        %v10562 = vadd.s32 %v10559, %v8 (stack39)
        %v10566 = vadd.s32 4, %v10562 (stack39)
        %v10570 = vadd.s32 %v10566, %v10554 (stack39)
        %v10572 = vshll.u32 %v10566, 13 (stack44)
        %v10573 = vshrl.u32 %v10566, 19 (stack45)
        %v10574 = vor.u32 %v10573, %v10572 (stack46)
        %v10575 = vxor.u32 %v10574, %v10570 (stack47)
        %v10578 = vadd.s32 %v10575, %v10570 (stack39)
        %v10580 = vshll.u32 %v10575, 15 (stack44)
        %v10581 = vshrl.u32 %v10575, 17 (stack45)
        %v10582 = vor.u32 %v10581, %v10580 (stack46)
        %v10583 = vxor.u32 %v10582, %v10578 (stack47)
        %v10586 = vadd.s32 %v10583, %v10578 (stack39)
        %v10588 = vshll.u32 %v10583, 26 (stack44)
        %v10589 = vshrl.u32 %v10583, 6 (stack45)
        %v10590 = vor.u32 %v10589, %v10588 (stack46)
        %v10591 = vxor.u32 %v10590, %v10586 (stack47)
        %v10594 = vadd.s32 %v10591, %v10586 (stack39)
        %v10598 = vadd.s32 %v10594, %v8 (stack39)
        %v10600 = vshll.u32 %v10591, 6 (stack44)
        %v10601 = vshrl.u32 %v10591, 26 (stack45)
        %v10602 = vor.u32 %v10601, %v10600 (stack46)
        %v10603 = vxor.u32 %v10602, %v10594 (stack47)
        %v10606 = vadd.s32 %v10603, %v10 (stack39)
        %v10610 = vadd.s32 5, %v10606 (stack39)
        %v10612 = vxor.u32 %v10610, %v10598 (stack47)
        %v10613 = vand.u32.u8 255, %v10612 (stack48)
        %v10614 = vand.u32 65535, %v10613 (stack49)
        %v10615 = vshrl.u32 %v10614, 1 (stack50)
        %v10616 = vor.u32 16256, %v10615 (stack46)
        %v10617 = vand.u32.u16 65535, %v10616 (stack51)
        %v119798 = vadd.low.f32.bf16 -1.0, %v10617 (stack52)
        %v10626 = vmul.f32 2.0, %v119798 (stack53)
        %v10630 = vadd.f32 -0.99609375, %v10626 (stack52)
        %v10634 = vmax.f32 %v10630, -0.99609375 (stack54)
        %v10636 = vand.u32 2147483647, %v10634 (stack55)
        %vm10639 = vcmp.eq.f32.partialorder %v10636, 1.0 (stack56)
        %v10644 = vmul.f32 inf, %v10634 (stack53)
        %v10646 = vxor.u32 2147483648, %v10634 (stack57)
        %v10649 = vmul.f32 %v10646, %v10634 (stack53)
        %v10651 = vadd.f32 1.0, %v10649 (stack58)
        %v10652 = vlog2.pop %v10651 (stack59)
        %v10653 = vmul.f32 0.6931472, %v10652 (stack60)
        %v10654 = vmul.f32 -0.5, %v10649 (stack61)
        %v10655 = vadd.f32 1.0, %v10654 (stack62)
        %v10656 = vmul.f32 %v10655, %v10649 (stack63)
        %v10657 = vand.u32 2147483647, %v10649 (stack64)
        %vm10658 = vcmp.lt.f32.partialorder %v10657, 0.0004427343 (stack65)
        %v10659 = vsel /*vm=*/%vm10658, /*on_true_vy=*/%v10656, /*on_false_vx=*/%v10653 (stack66)
        %v10660 = vxor.u32 2147483648, %v10659 (stack57)
        %vm10663 = vcmp.lt.f32.partialorder %v10660, 5.0 (stack56)
        %v10668 = vsel /*vm=*/%vm10663, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v10672 = vsel /*vm=*/%vm10663, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v10676 = vsel /*vm=*/%vm10663, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v10680 = vsel /*vm=*/%vm10663, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v10684 = vsel /*vm=*/%vm10663, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v10688 = vsel /*vm=*/%vm10663, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v10692 = vsel /*vm=*/%vm10663, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v10696 = vsel /*vm=*/%vm10663, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v10700 = vsel /*vm=*/%vm10663, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v10704 = vadd.f32 -2.5, %v10660 (stack52)
        %v10706 = vrsqrt.pop %v10660 (stack67)
        %v10707 = vmul.f32 %v10706, %v10660 (stack68)
        %vm10708 = vcmp.eq.f32.partialorder %v10660, inf (stack69)
        %v10709 = vsel /*vm=*/%vm10708, /*on_true_vy=*/%v10660, /*on_false_vx=*/%v10707 (stack70)
        %vm10710 = vcmp.eq.f32.partialorder %v10660, 0.0 (stack71)
        %v10711 = vand.u32 2147483648, %v10660 (stack72)
        %v10712 = vsel /*vm=*/%vm10710, /*on_true_vy=*/%v10711, /*on_false_vx=*/%v10709 (stack73)
        %v10715 = vadd.f32 -3.0, %v10712 (stack52)
        %v10719 = vsel /*vm=*/%vm10663, /*on_true_vy=*/%v10704, /*on_false_vx=*/%v10715 (stack43)
        %v10723 = vmul.f32 %v10719, %v10700 (stack53)
        %v10727 = vadd.f32 %v10723, %v10696 (stack52)
        %v10731 = vmul.f32 %v10727, %v10719 (stack53)
        %v10735 = vadd.f32 %v10731, %v10692 (stack52)
        %v10739 = vmul.f32 %v10735, %v10719 (stack53)
        %v10743 = vadd.f32 %v10739, %v10688 (stack52)
        %v10747 = vmul.f32 %v10743, %v10719 (stack53)
        %v10751 = vadd.f32 %v10747, %v10684 (stack52)
        %v10755 = vmul.f32 %v10751, %v10719 (stack53)
        %v10759 = vadd.f32 %v10755, %v10680 (stack52)
        %v10763 = vmul.f32 %v10759, %v10719 (stack53)
        %v10767 = vadd.f32 %v10763, %v10676 (stack52)
        %v10771 = vmul.f32 %v10767, %v10719 (stack53)
        %v10775 = vadd.f32 %v10771, %v10672 (stack52)
        %v10779 = vmul.f32 %v10775, %v10719 (stack53)
        %v10783 = vadd.f32 %v10779, %v10668 (stack52)
        %v10787 = vmul.f32 %v10783, %v10634 (stack53)
        %v10791 = vsel /*vm=*/%vm10639, /*on_true_vy=*/%v10644, /*on_false_vx=*/%v10787 (stack43)
        %v10795 = vmul.f32 1.4140625, %v10791 (stack53)
        %v10798 = vpack.c.bf16 0.0, %v10795 (stack74)
        %119799 = vst [vmem:[%s280 + $0x288] sm:$0xf] /*vst_source=*/%v10798 (stack75)
        %v10802 = vadd.s32 %v8033, %v3329 (stack39)
        %v10812 = vadd.s32 %v10802, %v415 (stack39)
        %vm10816 = vcmp.lt.u32.totalorder %v10812, %v10802 (stack42)
        %vm10821 = vcmp.lt.u32.totalorder %v10802, %v3329 (stack42)
        %v10826 = vadd.s32 %v8016, %v3316 (stack39)
        %v10830 = vadd.s32 1, %v10826 (stack39)
        %v10834 = vsel /*vm=*/%vm10821, /*on_true_vy=*/%v10830, /*on_false_vx=*/%v10826 (stack43)
        %v10838 = vadd.s32 1, %v10834 (stack39)
        %v10842 = vsel /*vm=*/%vm10816, /*on_true_vy=*/%v10838, /*on_false_vx=*/%v10834 (stack43)
        %v10847 = vadd.s32 %v10842, %v10 (stack39)
        %v10851 = vadd.s32 %v10812, %v9 (stack39)
        %v10855 = vadd.s32 %v10851, %v10847 (stack39)
        %v10857 = vshll.u32 %v10851, 13 (stack44)
        %v10858 = vshrl.u32 %v10851, 19 (stack45)
        %v10859 = vor.u32 %v10858, %v10857 (stack46)
        %v10860 = vxor.u32 %v10859, %v10855 (stack47)
        %v10863 = vadd.s32 %v10860, %v10855 (stack39)
        %v10865 = vshll.u32 %v10860, 15 (stack44)
        %v10866 = vshrl.u32 %v10860, 17 (stack45)
        %v10867 = vor.u32 %v10866, %v10865 (stack46)
        %v10868 = vxor.u32 %v10867, %v10863 (stack47)
        %v10871 = vadd.s32 %v10868, %v10863 (stack39)
        %v10873 = vshll.u32 %v10868, 26 (stack44)
        %v10874 = vshrl.u32 %v10868, 6 (stack45)
        %v10875 = vor.u32 %v10874, %v10873 (stack46)
        %v10876 = vxor.u32 %v10875, %v10871 (stack47)
        %v10879 = vadd.s32 %v10876, %v10871 (stack39)
        %v10883 = vadd.s32 %v10879, %v9 (stack39)
        %v10885 = vshll.u32 %v10876, 6 (stack44)
        %v10886 = vshrl.u32 %v10876, 26 (stack45)
        %v10887 = vor.u32 %v10886, %v10885 (stack46)
        %v10888 = vxor.u32 %v10887, %v10879 (stack47)
        %v10891 = vadd.s32 %v10888, %v8 (stack39)
        %v10895 = vadd.s32 1, %v10891 (stack39)
        %v10899 = vadd.s32 %v10895, %v10883 (stack39)
        %v10901 = vshll.u32 %v10895, 17 (stack44)
        %v10902 = vshrl.u32 %v10895, 15 (stack45)
        %v10903 = vor.u32 %v10902, %v10901 (stack46)
        %v10904 = vxor.u32 %v10903, %v10899 (stack47)
        %v10907 = vadd.s32 %v10904, %v10899 (stack39)
        %v10909 = vshll.u32 %v10904, 29 (stack44)
        %v10910 = vshrl.u32 %v10904, 3 (stack45)
        %v10911 = vor.u32 %v10910, %v10909 (stack46)
        %v10912 = vxor.u32 %v10911, %v10907 (stack47)
        %v10915 = vadd.s32 %v10912, %v10907 (stack39)
        %v10917 = vshll.u32 %v10912, 16 (stack44)
        %v10918 = vshrl.u32 %v10912, 16 (stack45)
        %v10919 = vor.u32 %v10918, %v10917 (stack46)
        %v10920 = vxor.u32 %v10919, %v10915 (stack47)
        %v10923 = vadd.s32 %v10920, %v10915 (stack39)
        %v10927 = vadd.s32 %v10923, %v8 (stack39)
        %v10929 = vshll.u32 %v10920, 24 (stack44)
        %v10930 = vshrl.u32 %v10920, 8 (stack45)
        %v10931 = vor.u32 %v10930, %v10929 (stack46)
        %v10932 = vxor.u32 %v10931, %v10923 (stack47)
        %v10935 = vadd.s32 %v10932, %v10 (stack39)
        %v10939 = vadd.s32 2, %v10935 (stack39)
        %v10943 = vadd.s32 %v10939, %v10927 (stack39)
        %v10945 = vshll.u32 %v10939, 13 (stack44)
        %v10946 = vshrl.u32 %v10939, 19 (stack45)
        %v10947 = vor.u32 %v10946, %v10945 (stack46)
        %v10948 = vxor.u32 %v10947, %v10943 (stack47)
        %v10951 = vadd.s32 %v10948, %v10943 (stack39)
        %v10953 = vshll.u32 %v10948, 15 (stack44)
        %v10954 = vshrl.u32 %v10948, 17 (stack45)
        %v10955 = vor.u32 %v10954, %v10953 (stack46)
        %v10956 = vxor.u32 %v10955, %v10951 (stack47)
        %v10959 = vadd.s32 %v10956, %v10951 (stack39)
        %v10961 = vshll.u32 %v10956, 26 (stack44)
        %v10962 = vshrl.u32 %v10956, 6 (stack45)
        %v10963 = vor.u32 %v10962, %v10961 (stack46)
        %v10964 = vxor.u32 %v10963, %v10959 (stack47)
        %v10967 = vadd.s32 %v10964, %v10959 (stack39)
        %v10971 = vadd.s32 %v10967, %v10 (stack39)
        %v10973 = vshll.u32 %v10964, 6 (stack44)
        %v10974 = vshrl.u32 %v10964, 26 (stack45)
        %v10975 = vor.u32 %v10974, %v10973 (stack46)
        %v10976 = vxor.u32 %v10975, %v10967 (stack47)
        %v10979 = vadd.s32 %v10976, %v9 (stack39)
        %v10983 = vadd.s32 3, %v10979 (stack39)
        %v10987 = vadd.s32 %v10983, %v10971 (stack39)
        %v10989 = vshll.u32 %v10983, 17 (stack44)
        %v10990 = vshrl.u32 %v10983, 15 (stack45)
        %v10991 = vor.u32 %v10990, %v10989 (stack46)
        %v10992 = vxor.u32 %v10991, %v10987 (stack47)
        %v10995 = vadd.s32 %v10992, %v10987 (stack39)
        %v10997 = vshll.u32 %v10992, 29 (stack44)
        %v10998 = vshrl.u32 %v10992, 3 (stack45)
        %v10999 = vor.u32 %v10998, %v10997 (stack46)
        %v11000 = vxor.u32 %v10999, %v10995 (stack47)
        %v11003 = vadd.s32 %v11000, %v10995 (stack39)
        %v11005 = vshll.u32 %v11000, 16 (stack44)
        %v11006 = vshrl.u32 %v11000, 16 (stack45)
        %v11007 = vor.u32 %v11006, %v11005 (stack46)
        %v11008 = vxor.u32 %v11007, %v11003 (stack47)
        %v11011 = vadd.s32 %v11008, %v11003 (stack39)
        %v11015 = vadd.s32 %v11011, %v9 (stack39)
        %v11017 = vshll.u32 %v11008, 24 (stack44)
        %v11018 = vshrl.u32 %v11008, 8 (stack45)
        %v11019 = vor.u32 %v11018, %v11017 (stack46)
        %v11020 = vxor.u32 %v11019, %v11011 (stack47)
        %v11023 = vadd.s32 %v11020, %v8 (stack39)
        %v11027 = vadd.s32 4, %v11023 (stack39)
        %v11031 = vadd.s32 %v11027, %v11015 (stack39)
        %v11033 = vshll.u32 %v11027, 13 (stack44)
        %v11034 = vshrl.u32 %v11027, 19 (stack45)
        %v11035 = vor.u32 %v11034, %v11033 (stack46)
        %v11036 = vxor.u32 %v11035, %v11031 (stack47)
        %v11039 = vadd.s32 %v11036, %v11031 (stack39)
        %v11041 = vshll.u32 %v11036, 15 (stack44)
        %v11042 = vshrl.u32 %v11036, 17 (stack45)
        %v11043 = vor.u32 %v11042, %v11041 (stack46)
        %v11044 = vxor.u32 %v11043, %v11039 (stack47)
        %v11047 = vadd.s32 %v11044, %v11039 (stack39)
        %v11049 = vshll.u32 %v11044, 26 (stack44)
        %v11050 = vshrl.u32 %v11044, 6 (stack45)
        %v11051 = vor.u32 %v11050, %v11049 (stack46)
        %v11052 = vxor.u32 %v11051, %v11047 (stack47)
        %v11055 = vadd.s32 %v11052, %v11047 (stack39)
        %v11059 = vadd.s32 %v11055, %v8 (stack39)
        %v11061 = vshll.u32 %v11052, 6 (stack44)
        %v11062 = vshrl.u32 %v11052, 26 (stack45)
        %v11063 = vor.u32 %v11062, %v11061 (stack46)
        %v11064 = vxor.u32 %v11063, %v11055 (stack47)
        %v11067 = vadd.s32 %v11064, %v10 (stack39)
        %v11071 = vadd.s32 5, %v11067 (stack39)
        %v11073 = vxor.u32 %v11071, %v11059 (stack47)
        %v11074 = vand.u32.u8 255, %v11073 (stack48)
        %v11075 = vand.u32 65535, %v11074 (stack49)
        %v11076 = vshrl.u32 %v11075, 1 (stack50)
        %v11077 = vor.u32 16256, %v11076 (stack46)
        %v11078 = vand.u32.u16 65535, %v11077 (stack51)
        %v119800 = vadd.low.f32.bf16 -1.0, %v11078 (stack52)
        %v11087 = vmul.f32 2.0, %v119800 (stack53)
        %v11091 = vadd.f32 -0.99609375, %v11087 (stack52)
        %v11095 = vmax.f32 %v11091, -0.99609375 (stack54)
        %v11097 = vand.u32 2147483647, %v11095 (stack55)
        %vm11100 = vcmp.eq.f32.partialorder %v11097, 1.0 (stack56)
        %v11105 = vmul.f32 inf, %v11095 (stack53)
        %v11107 = vxor.u32 2147483648, %v11095 (stack57)
        %v11110 = vmul.f32 %v11107, %v11095 (stack53)
        %v11112 = vadd.f32 1.0, %v11110 (stack58)
        %v11113 = vlog2.pop %v11112 (stack59)
        %v11114 = vmul.f32 0.6931472, %v11113 (stack60)
        %v11115 = vmul.f32 -0.5, %v11110 (stack61)
        %v11116 = vadd.f32 1.0, %v11115 (stack62)
        %v11117 = vmul.f32 %v11116, %v11110 (stack63)
        %v11118 = vand.u32 2147483647, %v11110 (stack64)
        %vm11119 = vcmp.lt.f32.partialorder %v11118, 0.0004427343 (stack65)
        %v11120 = vsel /*vm=*/%vm11119, /*on_true_vy=*/%v11117, /*on_false_vx=*/%v11114 (stack66)
        %v11121 = vxor.u32 2147483648, %v11120 (stack57)
        %vm11124 = vcmp.lt.f32.partialorder %v11121, 5.0 (stack56)
        %v11129 = vsel /*vm=*/%vm11124, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v11133 = vsel /*vm=*/%vm11124, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v11137 = vsel /*vm=*/%vm11124, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v11141 = vsel /*vm=*/%vm11124, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v11145 = vsel /*vm=*/%vm11124, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v11149 = vsel /*vm=*/%vm11124, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v11153 = vsel /*vm=*/%vm11124, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v11157 = vsel /*vm=*/%vm11124, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v11161 = vsel /*vm=*/%vm11124, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v11165 = vadd.f32 -2.5, %v11121 (stack52)
        %v11167 = vrsqrt.pop %v11121 (stack67)
        %v11168 = vmul.f32 %v11167, %v11121 (stack68)
        %vm11169 = vcmp.eq.f32.partialorder %v11121, inf (stack69)
        %v11170 = vsel /*vm=*/%vm11169, /*on_true_vy=*/%v11121, /*on_false_vx=*/%v11168 (stack70)
        %vm11171 = vcmp.eq.f32.partialorder %v11121, 0.0 (stack71)
        %v11172 = vand.u32 2147483648, %v11121 (stack72)
        %v11173 = vsel /*vm=*/%vm11171, /*on_true_vy=*/%v11172, /*on_false_vx=*/%v11170 (stack73)
        %v11176 = vadd.f32 -3.0, %v11173 (stack52)
        %v11180 = vsel /*vm=*/%vm11124, /*on_true_vy=*/%v11165, /*on_false_vx=*/%v11176 (stack43)
        %v11184 = vmul.f32 %v11180, %v11161 (stack53)
        %v11188 = vadd.f32 %v11184, %v11157 (stack52)
        %v11192 = vmul.f32 %v11188, %v11180 (stack53)
        %v11196 = vadd.f32 %v11192, %v11153 (stack52)
        %v11200 = vmul.f32 %v11196, %v11180 (stack53)
        %v11204 = vadd.f32 %v11200, %v11149 (stack52)
        %v11208 = vmul.f32 %v11204, %v11180 (stack53)
        %v11212 = vadd.f32 %v11208, %v11145 (stack52)
        %v11216 = vmul.f32 %v11212, %v11180 (stack53)
        %v11220 = vadd.f32 %v11216, %v11141 (stack52)
        %v11224 = vmul.f32 %v11220, %v11180 (stack53)
        %v11228 = vadd.f32 %v11224, %v11137 (stack52)
        %v11232 = vmul.f32 %v11228, %v11180 (stack53)
        %v11236 = vadd.f32 %v11232, %v11133 (stack52)
        %v11240 = vmul.f32 %v11236, %v11180 (stack53)
        %v11244 = vadd.f32 %v11240, %v11129 (stack52)
        %v11248 = vmul.f32 %v11244, %v11095 (stack53)
        %v11252 = vsel /*vm=*/%vm11100, /*on_true_vy=*/%v11105, /*on_false_vx=*/%v11248 (stack43)
        %v11256 = vmul.f32 1.4140625, %v11252 (stack53)
        %v11259 = vpack.c.bf16 0.0, %v11256 (stack74)
        %119801 = vst [vmem:[%s280 + $0x308] sm:$0xf] /*vst_source=*/%v11259 (stack75)
        %v11263 = vadd.s32 %v8033, %v3816 (stack39)
        %v11273 = vadd.s32 %v11263, %v415 (stack39)
        %vm11277 = vcmp.lt.u32.totalorder %v11273, %v11263 (stack42)
        %vm11282 = vcmp.lt.u32.totalorder %v11263, %v3816 (stack42)
        %v11287 = vadd.s32 %v8016, %v3803 (stack39)
        %v11291 = vadd.s32 1, %v11287 (stack39)
        %v11295 = vsel /*vm=*/%vm11282, /*on_true_vy=*/%v11291, /*on_false_vx=*/%v11287 (stack43)
        %v11299 = vadd.s32 1, %v11295 (stack39)
        %v11303 = vsel /*vm=*/%vm11277, /*on_true_vy=*/%v11299, /*on_false_vx=*/%v11295 (stack43)
        %v11308 = vadd.s32 %v11303, %v10 (stack39)
        %v11312 = vadd.s32 %v11273, %v9 (stack39)
        %v11316 = vadd.s32 %v11312, %v11308 (stack39)
        %v11318 = vshll.u32 %v11312, 13 (stack44)
        %v11319 = vshrl.u32 %v11312, 19 (stack45)
        %v11320 = vor.u32 %v11319, %v11318 (stack46)
        %v11321 = vxor.u32 %v11320, %v11316 (stack47)
        %v11324 = vadd.s32 %v11321, %v11316 (stack39)
        %v11326 = vshll.u32 %v11321, 15 (stack44)
        %v11327 = vshrl.u32 %v11321, 17 (stack45)
        %v11328 = vor.u32 %v11327, %v11326 (stack46)
        %v11329 = vxor.u32 %v11328, %v11324 (stack47)
        %v11332 = vadd.s32 %v11329, %v11324 (stack39)
        %v11334 = vshll.u32 %v11329, 26 (stack44)
        %v11335 = vshrl.u32 %v11329, 6 (stack45)
        %v11336 = vor.u32 %v11335, %v11334 (stack46)
        %v11337 = vxor.u32 %v11336, %v11332 (stack47)
        %v11340 = vadd.s32 %v11337, %v11332 (stack39)
        %v11344 = vadd.s32 %v11340, %v9 (stack39)
        %v11346 = vshll.u32 %v11337, 6 (stack44)
        %v11347 = vshrl.u32 %v11337, 26 (stack45)
        %v11348 = vor.u32 %v11347, %v11346 (stack46)
        %v11349 = vxor.u32 %v11348, %v11340 (stack47)
        %v11352 = vadd.s32 %v11349, %v8 (stack39)
        %v11356 = vadd.s32 1, %v11352 (stack39)
        %v11360 = vadd.s32 %v11356, %v11344 (stack39)
        %v11362 = vshll.u32 %v11356, 17 (stack44)
        %v11363 = vshrl.u32 %v11356, 15 (stack45)
        %v11364 = vor.u32 %v11363, %v11362 (stack46)
        %v11365 = vxor.u32 %v11364, %v11360 (stack47)
        %v11368 = vadd.s32 %v11365, %v11360 (stack39)
        %v11370 = vshll.u32 %v11365, 29 (stack44)
        %v11371 = vshrl.u32 %v11365, 3 (stack45)
        %v11372 = vor.u32 %v11371, %v11370 (stack46)
        %v11373 = vxor.u32 %v11372, %v11368 (stack47)
        %v11376 = vadd.s32 %v11373, %v11368 (stack39)
        %v11378 = vshll.u32 %v11373, 16 (stack44)
        %v11379 = vshrl.u32 %v11373, 16 (stack45)
        %v11380 = vor.u32 %v11379, %v11378 (stack46)
        %v11381 = vxor.u32 %v11380, %v11376 (stack47)
        %v11384 = vadd.s32 %v11381, %v11376 (stack39)
        %v11388 = vadd.s32 %v11384, %v8 (stack39)
        %v11390 = vshll.u32 %v11381, 24 (stack44)
        %v11391 = vshrl.u32 %v11381, 8 (stack45)
        %v11392 = vor.u32 %v11391, %v11390 (stack46)
        %v11393 = vxor.u32 %v11392, %v11384 (stack47)
        %v11396 = vadd.s32 %v11393, %v10 (stack39)
        %v11400 = vadd.s32 2, %v11396 (stack39)
        %v11404 = vadd.s32 %v11400, %v11388 (stack39)
        %v11406 = vshll.u32 %v11400, 13 (stack44)
        %v11407 = vshrl.u32 %v11400, 19 (stack45)
        %v11408 = vor.u32 %v11407, %v11406 (stack46)
        %v11409 = vxor.u32 %v11408, %v11404 (stack47)
        %v11412 = vadd.s32 %v11409, %v11404 (stack39)
        %v11414 = vshll.u32 %v11409, 15 (stack44)
        %v11415 = vshrl.u32 %v11409, 17 (stack45)
        %v11416 = vor.u32 %v11415, %v11414 (stack46)
        %v11417 = vxor.u32 %v11416, %v11412 (stack47)
        %v11420 = vadd.s32 %v11417, %v11412 (stack39)
        %v11422 = vshll.u32 %v11417, 26 (stack44)
        %v11423 = vshrl.u32 %v11417, 6 (stack45)
        %v11424 = vor.u32 %v11423, %v11422 (stack46)
        %v11425 = vxor.u32 %v11424, %v11420 (stack47)
        %v11428 = vadd.s32 %v11425, %v11420 (stack39)
        %v11432 = vadd.s32 %v11428, %v10 (stack39)
        %v11434 = vshll.u32 %v11425, 6 (stack44)
        %v11435 = vshrl.u32 %v11425, 26 (stack45)
        %v11436 = vor.u32 %v11435, %v11434 (stack46)
        %v11437 = vxor.u32 %v11436, %v11428 (stack47)
        %v11440 = vadd.s32 %v11437, %v9 (stack39)
        %v11444 = vadd.s32 3, %v11440 (stack39)
        %v11448 = vadd.s32 %v11444, %v11432 (stack39)
        %v11450 = vshll.u32 %v11444, 17 (stack44)
        %v11451 = vshrl.u32 %v11444, 15 (stack45)
        %v11452 = vor.u32 %v11451, %v11450 (stack46)
        %v11453 = vxor.u32 %v11452, %v11448 (stack47)
        %v11456 = vadd.s32 %v11453, %v11448 (stack39)
        %v11458 = vshll.u32 %v11453, 29 (stack44)
        %v11459 = vshrl.u32 %v11453, 3 (stack45)
        %v11460 = vor.u32 %v11459, %v11458 (stack46)
        %v11461 = vxor.u32 %v11460, %v11456 (stack47)
        %v11464 = vadd.s32 %v11461, %v11456 (stack39)
        %v11466 = vshll.u32 %v11461, 16 (stack44)
        %v11467 = vshrl.u32 %v11461, 16 (stack45)
        %v11468 = vor.u32 %v11467, %v11466 (stack46)
        %v11469 = vxor.u32 %v11468, %v11464 (stack47)
        %v11472 = vadd.s32 %v11469, %v11464 (stack39)
        %v11476 = vadd.s32 %v11472, %v9 (stack39)
        %v11478 = vshll.u32 %v11469, 24 (stack44)
        %v11479 = vshrl.u32 %v11469, 8 (stack45)
        %v11480 = vor.u32 %v11479, %v11478 (stack46)
        %v11481 = vxor.u32 %v11480, %v11472 (stack47)
        %v11484 = vadd.s32 %v11481, %v8 (stack39)
        %v11488 = vadd.s32 4, %v11484 (stack39)
        %v11492 = vadd.s32 %v11488, %v11476 (stack39)
        %v11494 = vshll.u32 %v11488, 13 (stack44)
        %v11495 = vshrl.u32 %v11488, 19 (stack45)
        %v11496 = vor.u32 %v11495, %v11494 (stack46)
        %v11497 = vxor.u32 %v11496, %v11492 (stack47)
        %v11500 = vadd.s32 %v11497, %v11492 (stack39)
        %v11502 = vshll.u32 %v11497, 15 (stack44)
        %v11503 = vshrl.u32 %v11497, 17 (stack45)
        %v11504 = vor.u32 %v11503, %v11502 (stack46)
        %v11505 = vxor.u32 %v11504, %v11500 (stack47)
        %v11508 = vadd.s32 %v11505, %v11500 (stack39)
        %v11510 = vshll.u32 %v11505, 26 (stack44)
        %v11511 = vshrl.u32 %v11505, 6 (stack45)
        %v11512 = vor.u32 %v11511, %v11510 (stack46)
        %v11513 = vxor.u32 %v11512, %v11508 (stack47)
        %v11516 = vadd.s32 %v11513, %v11508 (stack39)
        %v11520 = vadd.s32 %v11516, %v8 (stack39)
        %v11522 = vshll.u32 %v11513, 6 (stack44)
        %v11523 = vshrl.u32 %v11513, 26 (stack45)
        %v11524 = vor.u32 %v11523, %v11522 (stack46)
        %v11525 = vxor.u32 %v11524, %v11516 (stack47)
        %v11528 = vadd.s32 %v11525, %v10 (stack39)
        %v11532 = vadd.s32 5, %v11528 (stack39)
        %v11534 = vxor.u32 %v11532, %v11520 (stack47)
        %v11535 = vand.u32.u8 255, %v11534 (stack48)
        %v11536 = vand.u32 65535, %v11535 (stack49)
        %v11537 = vshrl.u32 %v11536, 1 (stack50)
        %v11538 = vor.u32 16256, %v11537 (stack46)
        %v11539 = vand.u32.u16 65535, %v11538 (stack51)
        %v119802 = vadd.low.f32.bf16 -1.0, %v11539 (stack52)
        %v11548 = vmul.f32 2.0, %v119802 (stack53)
        %v11552 = vadd.f32 -0.99609375, %v11548 (stack52)
        %v11556 = vmax.f32 %v11552, -0.99609375 (stack54)
        %v11558 = vand.u32 2147483647, %v11556 (stack55)
        %vm11561 = vcmp.eq.f32.partialorder %v11558, 1.0 (stack56)
        %v11566 = vmul.f32 inf, %v11556 (stack53)
        %v11568 = vxor.u32 2147483648, %v11556 (stack57)
        %v11571 = vmul.f32 %v11568, %v11556 (stack53)
        %v11573 = vadd.f32 1.0, %v11571 (stack58)
        %v11574 = vlog2.pop %v11573 (stack59)
        %v11575 = vmul.f32 0.6931472, %v11574 (stack60)
        %v11576 = vmul.f32 -0.5, %v11571 (stack61)
        %v11577 = vadd.f32 1.0, %v11576 (stack62)
        %v11578 = vmul.f32 %v11577, %v11571 (stack63)
        %v11579 = vand.u32 2147483647, %v11571 (stack64)
        %vm11580 = vcmp.lt.f32.partialorder %v11579, 0.0004427343 (stack65)
        %v11581 = vsel /*vm=*/%vm11580, /*on_true_vy=*/%v11578, /*on_false_vx=*/%v11575 (stack66)
        %v11582 = vxor.u32 2147483648, %v11581 (stack57)
        %vm11585 = vcmp.lt.f32.partialorder %v11582, 5.0 (stack56)
        %v11590 = vsel /*vm=*/%vm11585, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v11594 = vsel /*vm=*/%vm11585, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v11598 = vsel /*vm=*/%vm11585, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v11602 = vsel /*vm=*/%vm11585, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v11606 = vsel /*vm=*/%vm11585, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v11610 = vsel /*vm=*/%vm11585, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v11614 = vsel /*vm=*/%vm11585, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v11618 = vsel /*vm=*/%vm11585, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v11622 = vsel /*vm=*/%vm11585, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v11626 = vadd.f32 -2.5, %v11582 (stack52)
        %v11628 = vrsqrt.pop %v11582 (stack67)
        %v11629 = vmul.f32 %v11628, %v11582 (stack68)
        %vm11630 = vcmp.eq.f32.partialorder %v11582, inf (stack69)
        %v11631 = vsel /*vm=*/%vm11630, /*on_true_vy=*/%v11582, /*on_false_vx=*/%v11629 (stack70)
        %vm11632 = vcmp.eq.f32.partialorder %v11582, 0.0 (stack71)
        %v11633 = vand.u32 2147483648, %v11582 (stack72)
        %v11634 = vsel /*vm=*/%vm11632, /*on_true_vy=*/%v11633, /*on_false_vx=*/%v11631 (stack73)
        %v11637 = vadd.f32 -3.0, %v11634 (stack52)
        %v11641 = vsel /*vm=*/%vm11585, /*on_true_vy=*/%v11626, /*on_false_vx=*/%v11637 (stack43)
        %v11645 = vmul.f32 %v11641, %v11622 (stack53)
        %v11649 = vadd.f32 %v11645, %v11618 (stack52)
        %v11653 = vmul.f32 %v11649, %v11641 (stack53)
        %v11657 = vadd.f32 %v11653, %v11614 (stack52)
        %v11661 = vmul.f32 %v11657, %v11641 (stack53)
        %v11665 = vadd.f32 %v11661, %v11610 (stack52)
        %v11669 = vmul.f32 %v11665, %v11641 (stack53)
        %v11673 = vadd.f32 %v11669, %v11606 (stack52)
        %v11677 = vmul.f32 %v11673, %v11641 (stack53)
        %v11681 = vadd.f32 %v11677, %v11602 (stack52)
        %v11685 = vmul.f32 %v11681, %v11641 (stack53)
        %v11689 = vadd.f32 %v11685, %v11598 (stack52)
        %v11693 = vmul.f32 %v11689, %v11641 (stack53)
        %v11697 = vadd.f32 %v11693, %v11594 (stack52)
        %v11701 = vmul.f32 %v11697, %v11641 (stack53)
        %v11705 = vadd.f32 %v11701, %v11590 (stack52)
        %v11709 = vmul.f32 %v11705, %v11556 (stack53)
        %v11713 = vsel /*vm=*/%vm11561, /*on_true_vy=*/%v11566, /*on_false_vx=*/%v11709 (stack43)
        %v11717 = vmul.f32 1.4140625, %v11713 (stack53)
        %v11720 = vpack.c.bf16 0.0, %v11717 (stack74)
        %119803 = vst [vmem:[%s280 + $0x388] sm:$0xf] /*vst_source=*/%v11720 (stack75)
        %s11722 = sadd.s32 24, %s120390 (stack76)
        %s11723 = sshrl.u32 %s11722, 10 (stack23)
        %p119804 = scmp.gt.s32.totalorder %s11723, 1 (stack24)
        %s11725 = scalar_select /*predicate=*/%p119804, /*on_true=*/1, /*on_false=*/%s11723 (stack25)
        %s11726 = sand.u32 1023, %s11722 /* smod.u32 w/div 1024 */ (stack26)
        %s11727 = sshrl.u32 %s11726, 7 (stack27)
        %s11728 = sand.u32 127, %s11726 /* smod.u32 w/div 128 */ (stack28)
        %s119805 = sshll.u32 %s11725, 3 (stack29)
        %s11730 = scalar_lea.vmem %s3, %s119805 (stack30)
        %s11732 = scalar_lea.vmem %s11730, %s11727 (stack31)
        %v11733 = vld [vmem:[%s11732] ss:$0 sm:$0xff] (stack32)
        %s11734 = sand.u32 255, %s11728 (stack33)
        %s11736 = sor.u32 256, %s11734 (stack34)
        %11737 = vbcast.lane.b32.xlu0 %v11733, %s11736 (stack35)
        %v11738 = vpop.permute.xlu0 %11737 (stack36)
        %s11747 = scalar_lea.vmem %s5, %s119805 (stack30)
        %s11749 = scalar_lea.vmem %s11747, %s11727 (stack31)
        %v11750 = vld [vmem:[%s11749] ss:$0 sm:$0xff] (stack32)
        %11754 = vbcast.lane.b32.xlu0 %v11750, %s11736 (stack35)
        %v11755 = vpop.permute.xlu0 %11754 (stack36)
        %v11758 = vadd.s32 %v11755, %v408 (stack39)
        %v11768 = vadd.s32 %v11758, %v415 (stack39)
        %vm11772 = vcmp.lt.u32.totalorder %v11768, %v11758 (stack42)
        %vm11777 = vcmp.lt.u32.totalorder %v11758, %v408 (stack42)
        %v11782 = vadd.s32 %v11738, %v380 (stack39)
        %v11786 = vadd.s32 1, %v11782 (stack39)
        %v11790 = vsel /*vm=*/%vm11777, /*on_true_vy=*/%v11786, /*on_false_vx=*/%v11782 (stack43)
        %v11794 = vadd.s32 1, %v11790 (stack39)
        %v11798 = vsel /*vm=*/%vm11772, /*on_true_vy=*/%v11794, /*on_false_vx=*/%v11790 (stack43)
        %v11803 = vadd.s32 %v11798, %v10 (stack39)
        %v11807 = vadd.s32 %v11768, %v9 (stack39)
        %v11811 = vadd.s32 %v11807, %v11803 (stack39)
        %v11813 = vshll.u32 %v11807, 13 (stack44)
        %v11814 = vshrl.u32 %v11807, 19 (stack45)
        %v11815 = vor.u32 %v11814, %v11813 (stack46)
        %v11816 = vxor.u32 %v11815, %v11811 (stack47)
        %v11819 = vadd.s32 %v11816, %v11811 (stack39)
        %v11821 = vshll.u32 %v11816, 15 (stack44)
        %v11822 = vshrl.u32 %v11816, 17 (stack45)
        %v11823 = vor.u32 %v11822, %v11821 (stack46)
        %v11824 = vxor.u32 %v11823, %v11819 (stack47)
        %v11827 = vadd.s32 %v11824, %v11819 (stack39)
        %v11829 = vshll.u32 %v11824, 26 (stack44)
        %v11830 = vshrl.u32 %v11824, 6 (stack45)
        %v11831 = vor.u32 %v11830, %v11829 (stack46)
        %v11832 = vxor.u32 %v11831, %v11827 (stack47)
        %v11835 = vadd.s32 %v11832, %v11827 (stack39)
        %v11839 = vadd.s32 %v11835, %v9 (stack39)
        %v11841 = vshll.u32 %v11832, 6 (stack44)
        %v11842 = vshrl.u32 %v11832, 26 (stack45)
        %v11843 = vor.u32 %v11842, %v11841 (stack46)
        %v11844 = vxor.u32 %v11843, %v11835 (stack47)
        %v11847 = vadd.s32 %v11844, %v8 (stack39)
        %v11851 = vadd.s32 1, %v11847 (stack39)
        %v11855 = vadd.s32 %v11851, %v11839 (stack39)
        %v11857 = vshll.u32 %v11851, 17 (stack44)
        %v11858 = vshrl.u32 %v11851, 15 (stack45)
        %v11859 = vor.u32 %v11858, %v11857 (stack46)
        %v11860 = vxor.u32 %v11859, %v11855 (stack47)
        %v11863 = vadd.s32 %v11860, %v11855 (stack39)
        %v11865 = vshll.u32 %v11860, 29 (stack44)
        %v11866 = vshrl.u32 %v11860, 3 (stack45)
        %v11867 = vor.u32 %v11866, %v11865 (stack46)
        %v11868 = vxor.u32 %v11867, %v11863 (stack47)
        %v11871 = vadd.s32 %v11868, %v11863 (stack39)
        %v11873 = vshll.u32 %v11868, 16 (stack44)
        %v11874 = vshrl.u32 %v11868, 16 (stack45)
        %v11875 = vor.u32 %v11874, %v11873 (stack46)
        %v11876 = vxor.u32 %v11875, %v11871 (stack47)
        %v11879 = vadd.s32 %v11876, %v11871 (stack39)
        %v11883 = vadd.s32 %v11879, %v8 (stack39)
        %v11885 = vshll.u32 %v11876, 24 (stack44)
        %v11886 = vshrl.u32 %v11876, 8 (stack45)
        %v11887 = vor.u32 %v11886, %v11885 (stack46)
        %v11888 = vxor.u32 %v11887, %v11879 (stack47)
        %v11891 = vadd.s32 %v11888, %v10 (stack39)
        %v11895 = vadd.s32 2, %v11891 (stack39)
        %v11899 = vadd.s32 %v11895, %v11883 (stack39)
        %v11901 = vshll.u32 %v11895, 13 (stack44)
        %v11902 = vshrl.u32 %v11895, 19 (stack45)
        %v11903 = vor.u32 %v11902, %v11901 (stack46)
        %v11904 = vxor.u32 %v11903, %v11899 (stack47)
        %v11907 = vadd.s32 %v11904, %v11899 (stack39)
        %v11909 = vshll.u32 %v11904, 15 (stack44)
        %v11910 = vshrl.u32 %v11904, 17 (stack45)
        %v11911 = vor.u32 %v11910, %v11909 (stack46)
        %v11912 = vxor.u32 %v11911, %v11907 (stack47)
        %v11915 = vadd.s32 %v11912, %v11907 (stack39)
        %v11917 = vshll.u32 %v11912, 26 (stack44)
        %v11918 = vshrl.u32 %v11912, 6 (stack45)
        %v11919 = vor.u32 %v11918, %v11917 (stack46)
        %v11920 = vxor.u32 %v11919, %v11915 (stack47)
        %v11923 = vadd.s32 %v11920, %v11915 (stack39)
        %v11927 = vadd.s32 %v11923, %v10 (stack39)
        %v11929 = vshll.u32 %v11920, 6 (stack44)
        %v11930 = vshrl.u32 %v11920, 26 (stack45)
        %v11931 = vor.u32 %v11930, %v11929 (stack46)
        %v11932 = vxor.u32 %v11931, %v11923 (stack47)
        %v11935 = vadd.s32 %v11932, %v9 (stack39)
        %v11939 = vadd.s32 3, %v11935 (stack39)
        %v11943 = vadd.s32 %v11939, %v11927 (stack39)
        %v11945 = vshll.u32 %v11939, 17 (stack44)
        %v11946 = vshrl.u32 %v11939, 15 (stack45)
        %v11947 = vor.u32 %v11946, %v11945 (stack46)
        %v11948 = vxor.u32 %v11947, %v11943 (stack47)
        %v11951 = vadd.s32 %v11948, %v11943 (stack39)
        %v11953 = vshll.u32 %v11948, 29 (stack44)
        %v11954 = vshrl.u32 %v11948, 3 (stack45)
        %v11955 = vor.u32 %v11954, %v11953 (stack46)
        %v11956 = vxor.u32 %v11955, %v11951 (stack47)
        %v11959 = vadd.s32 %v11956, %v11951 (stack39)
        %v11961 = vshll.u32 %v11956, 16 (stack44)
        %v11962 = vshrl.u32 %v11956, 16 (stack45)
        %v11963 = vor.u32 %v11962, %v11961 (stack46)
        %v11964 = vxor.u32 %v11963, %v11959 (stack47)
        %v11967 = vadd.s32 %v11964, %v11959 (stack39)
        %v11971 = vadd.s32 %v11967, %v9 (stack39)
        %v11973 = vshll.u32 %v11964, 24 (stack44)
        %v11974 = vshrl.u32 %v11964, 8 (stack45)
        %v11975 = vor.u32 %v11974, %v11973 (stack46)
        %v11976 = vxor.u32 %v11975, %v11967 (stack47)
        %v11979 = vadd.s32 %v11976, %v8 (stack39)
        %v11983 = vadd.s32 4, %v11979 (stack39)
        %v11987 = vadd.s32 %v11983, %v11971 (stack39)
        %v11989 = vshll.u32 %v11983, 13 (stack44)
        %v11990 = vshrl.u32 %v11983, 19 (stack45)
        %v11991 = vor.u32 %v11990, %v11989 (stack46)
        %v11992 = vxor.u32 %v11991, %v11987 (stack47)
        %v11995 = vadd.s32 %v11992, %v11987 (stack39)
        %v11997 = vshll.u32 %v11992, 15 (stack44)
        %v11998 = vshrl.u32 %v11992, 17 (stack45)
        %v11999 = vor.u32 %v11998, %v11997 (stack46)
        %v12000 = vxor.u32 %v11999, %v11995 (stack47)
        %v12003 = vadd.s32 %v12000, %v11995 (stack39)
        %v12005 = vshll.u32 %v12000, 26 (stack44)
        %v12006 = vshrl.u32 %v12000, 6 (stack45)
        %v12007 = vor.u32 %v12006, %v12005 (stack46)
        %v12008 = vxor.u32 %v12007, %v12003 (stack47)
        %v12011 = vadd.s32 %v12008, %v12003 (stack39)
        %v12015 = vadd.s32 %v12011, %v8 (stack39)
        %v12017 = vshll.u32 %v12008, 6 (stack44)
        %v12018 = vshrl.u32 %v12008, 26 (stack45)
        %v12019 = vor.u32 %v12018, %v12017 (stack46)
        %v12020 = vxor.u32 %v12019, %v12011 (stack47)
        %v12023 = vadd.s32 %v12020, %v10 (stack39)
        %v12027 = vadd.s32 5, %v12023 (stack39)
        %v12029 = vxor.u32 %v12027, %v12015 (stack47)
        %v12030 = vand.u32.u8 255, %v12029 (stack48)
        %v12031 = vand.u32 65535, %v12030 (stack49)
        %v12032 = vshrl.u32 %v12031, 1 (stack50)
        %v12033 = vor.u32 16256, %v12032 (stack46)
        %v12034 = vand.u32.u16 65535, %v12033 (stack51)
        %v119808 = vadd.low.f32.bf16 -1.0, %v12034 (stack52)
        %v12043 = vmul.f32 2.0, %v119808 (stack53)
        %v12047 = vadd.f32 -0.99609375, %v12043 (stack52)
        %v12051 = vmax.f32 %v12047, -0.99609375 (stack54)
        %v12053 = vand.u32 2147483647, %v12051 (stack55)
        %vm12056 = vcmp.eq.f32.partialorder %v12053, 1.0 (stack56)
        %v12061 = vmul.f32 inf, %v12051 (stack53)
        %v12063 = vxor.u32 2147483648, %v12051 (stack57)
        %v12066 = vmul.f32 %v12063, %v12051 (stack53)
        %v12068 = vadd.f32 1.0, %v12066 (stack58)
        %v12069 = vlog2.pop %v12068 (stack59)
        %v12070 = vmul.f32 0.6931472, %v12069 (stack60)
        %v12071 = vmul.f32 -0.5, %v12066 (stack61)
        %v12072 = vadd.f32 1.0, %v12071 (stack62)
        %v12073 = vmul.f32 %v12072, %v12066 (stack63)
        %v12074 = vand.u32 2147483647, %v12066 (stack64)
        %vm12075 = vcmp.lt.f32.partialorder %v12074, 0.0004427343 (stack65)
        %v12076 = vsel /*vm=*/%vm12075, /*on_true_vy=*/%v12073, /*on_false_vx=*/%v12070 (stack66)
        %v12077 = vxor.u32 2147483648, %v12076 (stack57)
        %vm12080 = vcmp.lt.f32.partialorder %v12077, 5.0 (stack56)
        %v12085 = vsel /*vm=*/%vm12080, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v12089 = vsel /*vm=*/%vm12080, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v12093 = vsel /*vm=*/%vm12080, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v12097 = vsel /*vm=*/%vm12080, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v12101 = vsel /*vm=*/%vm12080, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v12105 = vsel /*vm=*/%vm12080, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v12109 = vsel /*vm=*/%vm12080, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v12113 = vsel /*vm=*/%vm12080, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v12117 = vsel /*vm=*/%vm12080, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v12121 = vadd.f32 -2.5, %v12077 (stack52)
        %v12123 = vrsqrt.pop %v12077 (stack67)
        %v12124 = vmul.f32 %v12123, %v12077 (stack68)
        %vm12125 = vcmp.eq.f32.partialorder %v12077, inf (stack69)
        %v12126 = vsel /*vm=*/%vm12125, /*on_true_vy=*/%v12077, /*on_false_vx=*/%v12124 (stack70)
        %vm12127 = vcmp.eq.f32.partialorder %v12077, 0.0 (stack71)
        %v12128 = vand.u32 2147483648, %v12077 (stack72)
        %v12129 = vsel /*vm=*/%vm12127, /*on_true_vy=*/%v12128, /*on_false_vx=*/%v12126 (stack73)
        %v12132 = vadd.f32 -3.0, %v12129 (stack52)
        %v12136 = vsel /*vm=*/%vm12080, /*on_true_vy=*/%v12121, /*on_false_vx=*/%v12132 (stack43)
        %v12140 = vmul.f32 %v12136, %v12117 (stack53)
        %v12144 = vadd.f32 %v12140, %v12113 (stack52)
        %v12148 = vmul.f32 %v12144, %v12136 (stack53)
        %v12152 = vadd.f32 %v12148, %v12109 (stack52)
        %v12156 = vmul.f32 %v12152, %v12136 (stack53)
        %v12160 = vadd.f32 %v12156, %v12105 (stack52)
        %v12164 = vmul.f32 %v12160, %v12136 (stack53)
        %v12168 = vadd.f32 %v12164, %v12101 (stack52)
        %v12172 = vmul.f32 %v12168, %v12136 (stack53)
        %v12176 = vadd.f32 %v12172, %v12097 (stack52)
        %v12180 = vmul.f32 %v12176, %v12136 (stack53)
        %v12184 = vadd.f32 %v12180, %v12093 (stack52)
        %v12188 = vmul.f32 %v12184, %v12136 (stack53)
        %v12192 = vadd.f32 %v12188, %v12089 (stack52)
        %v12196 = vmul.f32 %v12192, %v12136 (stack53)
        %v12200 = vadd.f32 %v12196, %v12085 (stack52)
        %v12204 = vmul.f32 %v12200, %v12051 (stack53)
        %v12208 = vsel /*vm=*/%vm12056, /*on_true_vy=*/%v12061, /*on_false_vx=*/%v12204 (stack43)
        %v12212 = vmul.f32 1.4140625, %v12208 (stack53)
        %v12215 = vpack.c.bf16 0.0, %v12212 (stack74)
        %119809 = vst [vmem:[%s280 + $0xc] sm:$0xf] /*vst_source=*/%v12215 (stack75)
        %v12219 = vadd.s32 %v11755, %v894 (stack39)
        %v12229 = vadd.s32 %v12219, %v415 (stack39)
        %vm12233 = vcmp.lt.u32.totalorder %v12229, %v12219 (stack42)
        %vm12238 = vcmp.lt.u32.totalorder %v12219, %v894 (stack42)
        %v12243 = vadd.s32 %v11738, %v881 (stack39)
        %v12247 = vadd.s32 1, %v12243 (stack39)
        %v12251 = vsel /*vm=*/%vm12238, /*on_true_vy=*/%v12247, /*on_false_vx=*/%v12243 (stack43)
        %v12255 = vadd.s32 1, %v12251 (stack39)
        %v12259 = vsel /*vm=*/%vm12233, /*on_true_vy=*/%v12255, /*on_false_vx=*/%v12251 (stack43)
        %v12264 = vadd.s32 %v12259, %v10 (stack39)
        %v12268 = vadd.s32 %v12229, %v9 (stack39)
        %v12272 = vadd.s32 %v12268, %v12264 (stack39)
        %v12274 = vshll.u32 %v12268, 13 (stack44)
        %v12275 = vshrl.u32 %v12268, 19 (stack45)
        %v12276 = vor.u32 %v12275, %v12274 (stack46)
        %v12277 = vxor.u32 %v12276, %v12272 (stack47)
        %v12280 = vadd.s32 %v12277, %v12272 (stack39)
        %v12282 = vshll.u32 %v12277, 15 (stack44)
        %v12283 = vshrl.u32 %v12277, 17 (stack45)
        %v12284 = vor.u32 %v12283, %v12282 (stack46)
        %v12285 = vxor.u32 %v12284, %v12280 (stack47)
        %v12288 = vadd.s32 %v12285, %v12280 (stack39)
        %v12290 = vshll.u32 %v12285, 26 (stack44)
        %v12291 = vshrl.u32 %v12285, 6 (stack45)
        %v12292 = vor.u32 %v12291, %v12290 (stack46)
        %v12293 = vxor.u32 %v12292, %v12288 (stack47)
        %v12296 = vadd.s32 %v12293, %v12288 (stack39)
        %v12300 = vadd.s32 %v12296, %v9 (stack39)
        %v12302 = vshll.u32 %v12293, 6 (stack44)
        %v12303 = vshrl.u32 %v12293, 26 (stack45)
        %v12304 = vor.u32 %v12303, %v12302 (stack46)
        %v12305 = vxor.u32 %v12304, %v12296 (stack47)
        %v12308 = vadd.s32 %v12305, %v8 (stack39)
        %v12312 = vadd.s32 1, %v12308 (stack39)
        %v12316 = vadd.s32 %v12312, %v12300 (stack39)
        %v12318 = vshll.u32 %v12312, 17 (stack44)
        %v12319 = vshrl.u32 %v12312, 15 (stack45)
        %v12320 = vor.u32 %v12319, %v12318 (stack46)
        %v12321 = vxor.u32 %v12320, %v12316 (stack47)
        %v12324 = vadd.s32 %v12321, %v12316 (stack39)
        %v12326 = vshll.u32 %v12321, 29 (stack44)
        %v12327 = vshrl.u32 %v12321, 3 (stack45)
        %v12328 = vor.u32 %v12327, %v12326 (stack46)
        %v12329 = vxor.u32 %v12328, %v12324 (stack47)
        %v12332 = vadd.s32 %v12329, %v12324 (stack39)
        %v12334 = vshll.u32 %v12329, 16 (stack44)
        %v12335 = vshrl.u32 %v12329, 16 (stack45)
        %v12336 = vor.u32 %v12335, %v12334 (stack46)
        %v12337 = vxor.u32 %v12336, %v12332 (stack47)
        %v12340 = vadd.s32 %v12337, %v12332 (stack39)
        %v12344 = vadd.s32 %v12340, %v8 (stack39)
        %v12346 = vshll.u32 %v12337, 24 (stack44)
        %v12347 = vshrl.u32 %v12337, 8 (stack45)
        %v12348 = vor.u32 %v12347, %v12346 (stack46)
        %v12349 = vxor.u32 %v12348, %v12340 (stack47)
        %v12352 = vadd.s32 %v12349, %v10 (stack39)
        %v12356 = vadd.s32 2, %v12352 (stack39)
        %v12360 = vadd.s32 %v12356, %v12344 (stack39)
        %v12362 = vshll.u32 %v12356, 13 (stack44)
        %v12363 = vshrl.u32 %v12356, 19 (stack45)
        %v12364 = vor.u32 %v12363, %v12362 (stack46)
        %v12365 = vxor.u32 %v12364, %v12360 (stack47)
        %v12368 = vadd.s32 %v12365, %v12360 (stack39)
        %v12370 = vshll.u32 %v12365, 15 (stack44)
        %v12371 = vshrl.u32 %v12365, 17 (stack45)
        %v12372 = vor.u32 %v12371, %v12370 (stack46)
        %v12373 = vxor.u32 %v12372, %v12368 (stack47)
        %v12376 = vadd.s32 %v12373, %v12368 (stack39)
        %v12378 = vshll.u32 %v12373, 26 (stack44)
        %v12379 = vshrl.u32 %v12373, 6 (stack45)
        %v12380 = vor.u32 %v12379, %v12378 (stack46)
        %v12381 = vxor.u32 %v12380, %v12376 (stack47)
        %v12384 = vadd.s32 %v12381, %v12376 (stack39)
        %v12388 = vadd.s32 %v12384, %v10 (stack39)
        %v12390 = vshll.u32 %v12381, 6 (stack44)
        %v12391 = vshrl.u32 %v12381, 26 (stack45)
        %v12392 = vor.u32 %v12391, %v12390 (stack46)
        %v12393 = vxor.u32 %v12392, %v12384 (stack47)
        %v12396 = vadd.s32 %v12393, %v9 (stack39)
        %v12400 = vadd.s32 3, %v12396 (stack39)
        %v12404 = vadd.s32 %v12400, %v12388 (stack39)
        %v12406 = vshll.u32 %v12400, 17 (stack44)
        %v12407 = vshrl.u32 %v12400, 15 (stack45)
        %v12408 = vor.u32 %v12407, %v12406 (stack46)
        %v12409 = vxor.u32 %v12408, %v12404 (stack47)
        %v12412 = vadd.s32 %v12409, %v12404 (stack39)
        %v12414 = vshll.u32 %v12409, 29 (stack44)
        %v12415 = vshrl.u32 %v12409, 3 (stack45)
        %v12416 = vor.u32 %v12415, %v12414 (stack46)
        %v12417 = vxor.u32 %v12416, %v12412 (stack47)
        %v12420 = vadd.s32 %v12417, %v12412 (stack39)
        %v12422 = vshll.u32 %v12417, 16 (stack44)
        %v12423 = vshrl.u32 %v12417, 16 (stack45)
        %v12424 = vor.u32 %v12423, %v12422 (stack46)
        %v12425 = vxor.u32 %v12424, %v12420 (stack47)
        %v12428 = vadd.s32 %v12425, %v12420 (stack39)
        %v12432 = vadd.s32 %v12428, %v9 (stack39)
        %v12434 = vshll.u32 %v12425, 24 (stack44)
        %v12435 = vshrl.u32 %v12425, 8 (stack45)
        %v12436 = vor.u32 %v12435, %v12434 (stack46)
        %v12437 = vxor.u32 %v12436, %v12428 (stack47)
        %v12440 = vadd.s32 %v12437, %v8 (stack39)
        %v12444 = vadd.s32 4, %v12440 (stack39)
        %v12448 = vadd.s32 %v12444, %v12432 (stack39)
        %v12450 = vshll.u32 %v12444, 13 (stack44)
        %v12451 = vshrl.u32 %v12444, 19 (stack45)
        %v12452 = vor.u32 %v12451, %v12450 (stack46)
        %v12453 = vxor.u32 %v12452, %v12448 (stack47)
        %v12456 = vadd.s32 %v12453, %v12448 (stack39)
        %v12458 = vshll.u32 %v12453, 15 (stack44)
        %v12459 = vshrl.u32 %v12453, 17 (stack45)
        %v12460 = vor.u32 %v12459, %v12458 (stack46)
        %v12461 = vxor.u32 %v12460, %v12456 (stack47)
        %v12464 = vadd.s32 %v12461, %v12456 (stack39)
        %v12466 = vshll.u32 %v12461, 26 (stack44)
        %v12467 = vshrl.u32 %v12461, 6 (stack45)
        %v12468 = vor.u32 %v12467, %v12466 (stack46)
        %v12469 = vxor.u32 %v12468, %v12464 (stack47)
        %v12472 = vadd.s32 %v12469, %v12464 (stack39)
        %v12476 = vadd.s32 %v12472, %v8 (stack39)
        %v12478 = vshll.u32 %v12469, 6 (stack44)
        %v12479 = vshrl.u32 %v12469, 26 (stack45)
        %v12480 = vor.u32 %v12479, %v12478 (stack46)
        %v12481 = vxor.u32 %v12480, %v12472 (stack47)
        %v12484 = vadd.s32 %v12481, %v10 (stack39)
        %v12488 = vadd.s32 5, %v12484 (stack39)
        %v12490 = vxor.u32 %v12488, %v12476 (stack47)
        %v12491 = vand.u32.u8 255, %v12490 (stack48)
        %v12492 = vand.u32 65535, %v12491 (stack49)
        %v12493 = vshrl.u32 %v12492, 1 (stack50)
        %v12494 = vor.u32 16256, %v12493 (stack46)
        %v12495 = vand.u32.u16 65535, %v12494 (stack51)
        %v119810 = vadd.low.f32.bf16 -1.0, %v12495 (stack52)
        %v12504 = vmul.f32 2.0, %v119810 (stack53)
        %v12508 = vadd.f32 -0.99609375, %v12504 (stack52)
        %v12512 = vmax.f32 %v12508, -0.99609375 (stack54)
        %v12514 = vand.u32 2147483647, %v12512 (stack55)
        %vm12517 = vcmp.eq.f32.partialorder %v12514, 1.0 (stack56)
        %v12522 = vmul.f32 inf, %v12512 (stack53)
        %v12524 = vxor.u32 2147483648, %v12512 (stack57)
        %v12527 = vmul.f32 %v12524, %v12512 (stack53)
        %v12529 = vadd.f32 1.0, %v12527 (stack58)
        %v12530 = vlog2.pop %v12529 (stack59)
        %v12531 = vmul.f32 0.6931472, %v12530 (stack60)
        %v12532 = vmul.f32 -0.5, %v12527 (stack61)
        %v12533 = vadd.f32 1.0, %v12532 (stack62)
        %v12534 = vmul.f32 %v12533, %v12527 (stack63)
        %v12535 = vand.u32 2147483647, %v12527 (stack64)
        %vm12536 = vcmp.lt.f32.partialorder %v12535, 0.0004427343 (stack65)
        %v12537 = vsel /*vm=*/%vm12536, /*on_true_vy=*/%v12534, /*on_false_vx=*/%v12531 (stack66)
        %v12538 = vxor.u32 2147483648, %v12537 (stack57)
        %vm12541 = vcmp.lt.f32.partialorder %v12538, 5.0 (stack56)
        %v12546 = vsel /*vm=*/%vm12541, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v12550 = vsel /*vm=*/%vm12541, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v12554 = vsel /*vm=*/%vm12541, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v12558 = vsel /*vm=*/%vm12541, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v12562 = vsel /*vm=*/%vm12541, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v12566 = vsel /*vm=*/%vm12541, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v12570 = vsel /*vm=*/%vm12541, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v12574 = vsel /*vm=*/%vm12541, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v12578 = vsel /*vm=*/%vm12541, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v12582 = vadd.f32 -2.5, %v12538 (stack52)
        %v12584 = vrsqrt.pop %v12538 (stack67)
        %v12585 = vmul.f32 %v12584, %v12538 (stack68)
        %vm12586 = vcmp.eq.f32.partialorder %v12538, inf (stack69)
        %v12587 = vsel /*vm=*/%vm12586, /*on_true_vy=*/%v12538, /*on_false_vx=*/%v12585 (stack70)
        %vm12588 = vcmp.eq.f32.partialorder %v12538, 0.0 (stack71)
        %v12589 = vand.u32 2147483648, %v12538 (stack72)
        %v12590 = vsel /*vm=*/%vm12588, /*on_true_vy=*/%v12589, /*on_false_vx=*/%v12587 (stack73)
        %v12593 = vadd.f32 -3.0, %v12590 (stack52)
        %v12597 = vsel /*vm=*/%vm12541, /*on_true_vy=*/%v12582, /*on_false_vx=*/%v12593 (stack43)
        %v12601 = vmul.f32 %v12597, %v12578 (stack53)
        %v12605 = vadd.f32 %v12601, %v12574 (stack52)
        %v12609 = vmul.f32 %v12605, %v12597 (stack53)
        %v12613 = vadd.f32 %v12609, %v12570 (stack52)
        %v12617 = vmul.f32 %v12613, %v12597 (stack53)
        %v12621 = vadd.f32 %v12617, %v12566 (stack52)
        %v12625 = vmul.f32 %v12621, %v12597 (stack53)
        %v12629 = vadd.f32 %v12625, %v12562 (stack52)
        %v12633 = vmul.f32 %v12629, %v12597 (stack53)
        %v12637 = vadd.f32 %v12633, %v12558 (stack52)
        %v12641 = vmul.f32 %v12637, %v12597 (stack53)
        %v12645 = vadd.f32 %v12641, %v12554 (stack52)
        %v12649 = vmul.f32 %v12645, %v12597 (stack53)
        %v12653 = vadd.f32 %v12649, %v12550 (stack52)
        %v12657 = vmul.f32 %v12653, %v12597 (stack53)
        %v12661 = vadd.f32 %v12657, %v12546 (stack52)
        %v12665 = vmul.f32 %v12661, %v12512 (stack53)
        %v12669 = vsel /*vm=*/%vm12517, /*on_true_vy=*/%v12522, /*on_false_vx=*/%v12665 (stack43)
        %v12673 = vmul.f32 1.4140625, %v12669 (stack53)
        %v12676 = vpack.c.bf16 0.0, %v12673 (stack74)
        %119811 = vst [vmem:[%s280 + $0x8c] sm:$0xf] /*vst_source=*/%v12676 (stack75)
        %v12680 = vadd.s32 %v11755, %v1381 (stack39)
        %v12690 = vadd.s32 %v12680, %v415 (stack39)
        %vm12694 = vcmp.lt.u32.totalorder %v12690, %v12680 (stack42)
        %vm12699 = vcmp.lt.u32.totalorder %v12680, %v1381 (stack42)
        %v12704 = vadd.s32 %v11738, %v1368 (stack39)
        %v12708 = vadd.s32 1, %v12704 (stack39)
        %v12712 = vsel /*vm=*/%vm12699, /*on_true_vy=*/%v12708, /*on_false_vx=*/%v12704 (stack43)
        %v12716 = vadd.s32 1, %v12712 (stack39)
        %v12720 = vsel /*vm=*/%vm12694, /*on_true_vy=*/%v12716, /*on_false_vx=*/%v12712 (stack43)
        %v12725 = vadd.s32 %v12720, %v10 (stack39)
        %v12729 = vadd.s32 %v12690, %v9 (stack39)
        %v12733 = vadd.s32 %v12729, %v12725 (stack39)
        %v12735 = vshll.u32 %v12729, 13 (stack44)
        %v12736 = vshrl.u32 %v12729, 19 (stack45)
        %v12737 = vor.u32 %v12736, %v12735 (stack46)
        %v12738 = vxor.u32 %v12737, %v12733 (stack47)
        %v12741 = vadd.s32 %v12738, %v12733 (stack39)
        %v12743 = vshll.u32 %v12738, 15 (stack44)
        %v12744 = vshrl.u32 %v12738, 17 (stack45)
        %v12745 = vor.u32 %v12744, %v12743 (stack46)
        %v12746 = vxor.u32 %v12745, %v12741 (stack47)
        %v12749 = vadd.s32 %v12746, %v12741 (stack39)
        %v12751 = vshll.u32 %v12746, 26 (stack44)
        %v12752 = vshrl.u32 %v12746, 6 (stack45)
        %v12753 = vor.u32 %v12752, %v12751 (stack46)
        %v12754 = vxor.u32 %v12753, %v12749 (stack47)
        %v12757 = vadd.s32 %v12754, %v12749 (stack39)
        %v12761 = vadd.s32 %v12757, %v9 (stack39)
        %v12763 = vshll.u32 %v12754, 6 (stack44)
        %v12764 = vshrl.u32 %v12754, 26 (stack45)
        %v12765 = vor.u32 %v12764, %v12763 (stack46)
        %v12766 = vxor.u32 %v12765, %v12757 (stack47)
        %v12769 = vadd.s32 %v12766, %v8 (stack39)
        %v12773 = vadd.s32 1, %v12769 (stack39)
        %v12777 = vadd.s32 %v12773, %v12761 (stack39)
        %v12779 = vshll.u32 %v12773, 17 (stack44)
        %v12780 = vshrl.u32 %v12773, 15 (stack45)
        %v12781 = vor.u32 %v12780, %v12779 (stack46)
        %v12782 = vxor.u32 %v12781, %v12777 (stack47)
        %v12785 = vadd.s32 %v12782, %v12777 (stack39)
        %v12787 = vshll.u32 %v12782, 29 (stack44)
        %v12788 = vshrl.u32 %v12782, 3 (stack45)
        %v12789 = vor.u32 %v12788, %v12787 (stack46)
        %v12790 = vxor.u32 %v12789, %v12785 (stack47)
        %v12793 = vadd.s32 %v12790, %v12785 (stack39)
        %v12795 = vshll.u32 %v12790, 16 (stack44)
        %v12796 = vshrl.u32 %v12790, 16 (stack45)
        %v12797 = vor.u32 %v12796, %v12795 (stack46)
        %v12798 = vxor.u32 %v12797, %v12793 (stack47)
        %v12801 = vadd.s32 %v12798, %v12793 (stack39)
        %v12805 = vadd.s32 %v12801, %v8 (stack39)
        %v12807 = vshll.u32 %v12798, 24 (stack44)
        %v12808 = vshrl.u32 %v12798, 8 (stack45)
        %v12809 = vor.u32 %v12808, %v12807 (stack46)
        %v12810 = vxor.u32 %v12809, %v12801 (stack47)
        %v12813 = vadd.s32 %v12810, %v10 (stack39)
        %v12817 = vadd.s32 2, %v12813 (stack39)
        %v12821 = vadd.s32 %v12817, %v12805 (stack39)
        %v12823 = vshll.u32 %v12817, 13 (stack44)
        %v12824 = vshrl.u32 %v12817, 19 (stack45)
        %v12825 = vor.u32 %v12824, %v12823 (stack46)
        %v12826 = vxor.u32 %v12825, %v12821 (stack47)
        %v12829 = vadd.s32 %v12826, %v12821 (stack39)
        %v12831 = vshll.u32 %v12826, 15 (stack44)
        %v12832 = vshrl.u32 %v12826, 17 (stack45)
        %v12833 = vor.u32 %v12832, %v12831 (stack46)
        %v12834 = vxor.u32 %v12833, %v12829 (stack47)
        %v12837 = vadd.s32 %v12834, %v12829 (stack39)
        %v12839 = vshll.u32 %v12834, 26 (stack44)
        %v12840 = vshrl.u32 %v12834, 6 (stack45)
        %v12841 = vor.u32 %v12840, %v12839 (stack46)
        %v12842 = vxor.u32 %v12841, %v12837 (stack47)
        %v12845 = vadd.s32 %v12842, %v12837 (stack39)
        %v12849 = vadd.s32 %v12845, %v10 (stack39)
        %v12851 = vshll.u32 %v12842, 6 (stack44)
        %v12852 = vshrl.u32 %v12842, 26 (stack45)
        %v12853 = vor.u32 %v12852, %v12851 (stack46)
        %v12854 = vxor.u32 %v12853, %v12845 (stack47)
        %v12857 = vadd.s32 %v12854, %v9 (stack39)
        %v12861 = vadd.s32 3, %v12857 (stack39)
        %v12865 = vadd.s32 %v12861, %v12849 (stack39)
        %v12867 = vshll.u32 %v12861, 17 (stack44)
        %v12868 = vshrl.u32 %v12861, 15 (stack45)
        %v12869 = vor.u32 %v12868, %v12867 (stack46)
        %v12870 = vxor.u32 %v12869, %v12865 (stack47)
        %v12873 = vadd.s32 %v12870, %v12865 (stack39)
        %v12875 = vshll.u32 %v12870, 29 (stack44)
        %v12876 = vshrl.u32 %v12870, 3 (stack45)
        %v12877 = vor.u32 %v12876, %v12875 (stack46)
        %v12878 = vxor.u32 %v12877, %v12873 (stack47)
        %v12881 = vadd.s32 %v12878, %v12873 (stack39)
        %v12883 = vshll.u32 %v12878, 16 (stack44)
        %v12884 = vshrl.u32 %v12878, 16 (stack45)
        %v12885 = vor.u32 %v12884, %v12883 (stack46)
        %v12886 = vxor.u32 %v12885, %v12881 (stack47)
        %v12889 = vadd.s32 %v12886, %v12881 (stack39)
        %v12893 = vadd.s32 %v12889, %v9 (stack39)
        %v12895 = vshll.u32 %v12886, 24 (stack44)
        %v12896 = vshrl.u32 %v12886, 8 (stack45)
        %v12897 = vor.u32 %v12896, %v12895 (stack46)
        %v12898 = vxor.u32 %v12897, %v12889 (stack47)
        %v12901 = vadd.s32 %v12898, %v8 (stack39)
        %v12905 = vadd.s32 4, %v12901 (stack39)
        %v12909 = vadd.s32 %v12905, %v12893 (stack39)
        %v12911 = vshll.u32 %v12905, 13 (stack44)
        %v12912 = vshrl.u32 %v12905, 19 (stack45)
        %v12913 = vor.u32 %v12912, %v12911 (stack46)
        %v12914 = vxor.u32 %v12913, %v12909 (stack47)
        %v12917 = vadd.s32 %v12914, %v12909 (stack39)
        %v12919 = vshll.u32 %v12914, 15 (stack44)
        %v12920 = vshrl.u32 %v12914, 17 (stack45)
        %v12921 = vor.u32 %v12920, %v12919 (stack46)
        %v12922 = vxor.u32 %v12921, %v12917 (stack47)
        %v12925 = vadd.s32 %v12922, %v12917 (stack39)
        %v12927 = vshll.u32 %v12922, 26 (stack44)
        %v12928 = vshrl.u32 %v12922, 6 (stack45)
        %v12929 = vor.u32 %v12928, %v12927 (stack46)
        %v12930 = vxor.u32 %v12929, %v12925 (stack47)
        %v12933 = vadd.s32 %v12930, %v12925 (stack39)
        %v12937 = vadd.s32 %v12933, %v8 (stack39)
        %v12939 = vshll.u32 %v12930, 6 (stack44)
        %v12940 = vshrl.u32 %v12930, 26 (stack45)
        %v12941 = vor.u32 %v12940, %v12939 (stack46)
        %v12942 = vxor.u32 %v12941, %v12933 (stack47)
        %v12945 = vadd.s32 %v12942, %v10 (stack39)
        %v12949 = vadd.s32 5, %v12945 (stack39)
        %v12951 = vxor.u32 %v12949, %v12937 (stack47)
        %v12952 = vand.u32.u8 255, %v12951 (stack48)
        %v12953 = vand.u32 65535, %v12952 (stack49)
        %v12954 = vshrl.u32 %v12953, 1 (stack50)
        %v12955 = vor.u32 16256, %v12954 (stack46)
        %v12956 = vand.u32.u16 65535, %v12955 (stack51)
        %v119812 = vadd.low.f32.bf16 -1.0, %v12956 (stack52)
        %v12965 = vmul.f32 2.0, %v119812 (stack53)
        %v12969 = vadd.f32 -0.99609375, %v12965 (stack52)
        %v12973 = vmax.f32 %v12969, -0.99609375 (stack54)
        %v12975 = vand.u32 2147483647, %v12973 (stack55)
        %vm12978 = vcmp.eq.f32.partialorder %v12975, 1.0 (stack56)
        %v12983 = vmul.f32 inf, %v12973 (stack53)
        %v12985 = vxor.u32 2147483648, %v12973 (stack57)
        %v12988 = vmul.f32 %v12985, %v12973 (stack53)
        %v12990 = vadd.f32 1.0, %v12988 (stack58)
        %v12991 = vlog2.pop %v12990 (stack59)
        %v12992 = vmul.f32 0.6931472, %v12991 (stack60)
        %v12993 = vmul.f32 -0.5, %v12988 (stack61)
        %v12994 = vadd.f32 1.0, %v12993 (stack62)
        %v12995 = vmul.f32 %v12994, %v12988 (stack63)
        %v12996 = vand.u32 2147483647, %v12988 (stack64)
        %vm12997 = vcmp.lt.f32.partialorder %v12996, 0.0004427343 (stack65)
        %v12998 = vsel /*vm=*/%vm12997, /*on_true_vy=*/%v12995, /*on_false_vx=*/%v12992 (stack66)
        %v12999 = vxor.u32 2147483648, %v12998 (stack57)
        %vm13002 = vcmp.lt.f32.partialorder %v12999, 5.0 (stack56)
        %v13007 = vsel /*vm=*/%vm13002, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v13011 = vsel /*vm=*/%vm13002, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v13015 = vsel /*vm=*/%vm13002, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v13019 = vsel /*vm=*/%vm13002, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v13023 = vsel /*vm=*/%vm13002, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v13027 = vsel /*vm=*/%vm13002, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v13031 = vsel /*vm=*/%vm13002, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v13035 = vsel /*vm=*/%vm13002, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v13039 = vsel /*vm=*/%vm13002, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v13043 = vadd.f32 -2.5, %v12999 (stack52)
        %v13045 = vrsqrt.pop %v12999 (stack67)
        %v13046 = vmul.f32 %v13045, %v12999 (stack68)
        %vm13047 = vcmp.eq.f32.partialorder %v12999, inf (stack69)
        %v13048 = vsel /*vm=*/%vm13047, /*on_true_vy=*/%v12999, /*on_false_vx=*/%v13046 (stack70)
        %vm13049 = vcmp.eq.f32.partialorder %v12999, 0.0 (stack71)
        %v13050 = vand.u32 2147483648, %v12999 (stack72)
        %v13051 = vsel /*vm=*/%vm13049, /*on_true_vy=*/%v13050, /*on_false_vx=*/%v13048 (stack73)
        %v13054 = vadd.f32 -3.0, %v13051 (stack52)
        %v13058 = vsel /*vm=*/%vm13002, /*on_true_vy=*/%v13043, /*on_false_vx=*/%v13054 (stack43)
        %v13062 = vmul.f32 %v13058, %v13039 (stack53)
        %v13066 = vadd.f32 %v13062, %v13035 (stack52)
        %v13070 = vmul.f32 %v13066, %v13058 (stack53)
        %v13074 = vadd.f32 %v13070, %v13031 (stack52)
        %v13078 = vmul.f32 %v13074, %v13058 (stack53)
        %v13082 = vadd.f32 %v13078, %v13027 (stack52)
        %v13086 = vmul.f32 %v13082, %v13058 (stack53)
        %v13090 = vadd.f32 %v13086, %v13023 (stack52)
        %v13094 = vmul.f32 %v13090, %v13058 (stack53)
        %v13098 = vadd.f32 %v13094, %v13019 (stack52)
        %v13102 = vmul.f32 %v13098, %v13058 (stack53)
        %v13106 = vadd.f32 %v13102, %v13015 (stack52)
        %v13110 = vmul.f32 %v13106, %v13058 (stack53)
        %v13114 = vadd.f32 %v13110, %v13011 (stack52)
        %v13118 = vmul.f32 %v13114, %v13058 (stack53)
        %v13122 = vadd.f32 %v13118, %v13007 (stack52)
        %v13126 = vmul.f32 %v13122, %v12973 (stack53)
        %v13130 = vsel /*vm=*/%vm12978, /*on_true_vy=*/%v12983, /*on_false_vx=*/%v13126 (stack43)
        %v13134 = vmul.f32 1.4140625, %v13130 (stack53)
        %v13137 = vpack.c.bf16 0.0, %v13134 (stack74)
        %119813 = vst [vmem:[%s280 + $0x10c] sm:$0xf] /*vst_source=*/%v13137 (stack75)
        %v13141 = vadd.s32 %v11755, %v1868 (stack39)
        %v13151 = vadd.s32 %v13141, %v415 (stack39)
        %vm13155 = vcmp.lt.u32.totalorder %v13151, %v13141 (stack42)
        %vm13160 = vcmp.lt.u32.totalorder %v13141, %v1868 (stack42)
        %v13165 = vadd.s32 %v11738, %v1855 (stack39)
        %v13169 = vadd.s32 1, %v13165 (stack39)
        %v13173 = vsel /*vm=*/%vm13160, /*on_true_vy=*/%v13169, /*on_false_vx=*/%v13165 (stack43)
        %v13177 = vadd.s32 1, %v13173 (stack39)
        %v13181 = vsel /*vm=*/%vm13155, /*on_true_vy=*/%v13177, /*on_false_vx=*/%v13173 (stack43)
        %v13186 = vadd.s32 %v13181, %v10 (stack39)
        %v13190 = vadd.s32 %v13151, %v9 (stack39)
        %v13194 = vadd.s32 %v13190, %v13186 (stack39)
        %v13196 = vshll.u32 %v13190, 13 (stack44)
        %v13197 = vshrl.u32 %v13190, 19 (stack45)
        %v13198 = vor.u32 %v13197, %v13196 (stack46)
        %v13199 = vxor.u32 %v13198, %v13194 (stack47)
        %v13202 = vadd.s32 %v13199, %v13194 (stack39)
        %v13204 = vshll.u32 %v13199, 15 (stack44)
        %v13205 = vshrl.u32 %v13199, 17 (stack45)
        %v13206 = vor.u32 %v13205, %v13204 (stack46)
        %v13207 = vxor.u32 %v13206, %v13202 (stack47)
        %v13210 = vadd.s32 %v13207, %v13202 (stack39)
        %v13212 = vshll.u32 %v13207, 26 (stack44)
        %v13213 = vshrl.u32 %v13207, 6 (stack45)
        %v13214 = vor.u32 %v13213, %v13212 (stack46)
        %v13215 = vxor.u32 %v13214, %v13210 (stack47)
        %v13218 = vadd.s32 %v13215, %v13210 (stack39)
        %v13222 = vadd.s32 %v13218, %v9 (stack39)
        %v13224 = vshll.u32 %v13215, 6 (stack44)
        %v13225 = vshrl.u32 %v13215, 26 (stack45)
        %v13226 = vor.u32 %v13225, %v13224 (stack46)
        %v13227 = vxor.u32 %v13226, %v13218 (stack47)
        %v13230 = vadd.s32 %v13227, %v8 (stack39)
        %v13234 = vadd.s32 1, %v13230 (stack39)
        %v13238 = vadd.s32 %v13234, %v13222 (stack39)
        %v13240 = vshll.u32 %v13234, 17 (stack44)
        %v13241 = vshrl.u32 %v13234, 15 (stack45)
        %v13242 = vor.u32 %v13241, %v13240 (stack46)
        %v13243 = vxor.u32 %v13242, %v13238 (stack47)
        %v13246 = vadd.s32 %v13243, %v13238 (stack39)
        %v13248 = vshll.u32 %v13243, 29 (stack44)
        %v13249 = vshrl.u32 %v13243, 3 (stack45)
        %v13250 = vor.u32 %v13249, %v13248 (stack46)
        %v13251 = vxor.u32 %v13250, %v13246 (stack47)
        %v13254 = vadd.s32 %v13251, %v13246 (stack39)
        %v13256 = vshll.u32 %v13251, 16 (stack44)
        %v13257 = vshrl.u32 %v13251, 16 (stack45)
        %v13258 = vor.u32 %v13257, %v13256 (stack46)
        %v13259 = vxor.u32 %v13258, %v13254 (stack47)
        %v13262 = vadd.s32 %v13259, %v13254 (stack39)
        %v13266 = vadd.s32 %v13262, %v8 (stack39)
        %v13268 = vshll.u32 %v13259, 24 (stack44)
        %v13269 = vshrl.u32 %v13259, 8 (stack45)
        %v13270 = vor.u32 %v13269, %v13268 (stack46)
        %v13271 = vxor.u32 %v13270, %v13262 (stack47)
        %v13274 = vadd.s32 %v13271, %v10 (stack39)
        %v13278 = vadd.s32 2, %v13274 (stack39)
        %v13282 = vadd.s32 %v13278, %v13266 (stack39)
        %v13284 = vshll.u32 %v13278, 13 (stack44)
        %v13285 = vshrl.u32 %v13278, 19 (stack45)
        %v13286 = vor.u32 %v13285, %v13284 (stack46)
        %v13287 = vxor.u32 %v13286, %v13282 (stack47)
        %v13290 = vadd.s32 %v13287, %v13282 (stack39)
        %v13292 = vshll.u32 %v13287, 15 (stack44)
        %v13293 = vshrl.u32 %v13287, 17 (stack45)
        %v13294 = vor.u32 %v13293, %v13292 (stack46)
        %v13295 = vxor.u32 %v13294, %v13290 (stack47)
        %v13298 = vadd.s32 %v13295, %v13290 (stack39)
        %v13300 = vshll.u32 %v13295, 26 (stack44)
        %v13301 = vshrl.u32 %v13295, 6 (stack45)
        %v13302 = vor.u32 %v13301, %v13300 (stack46)
        %v13303 = vxor.u32 %v13302, %v13298 (stack47)
        %v13306 = vadd.s32 %v13303, %v13298 (stack39)
        %v13310 = vadd.s32 %v13306, %v10 (stack39)
        %v13312 = vshll.u32 %v13303, 6 (stack44)
        %v13313 = vshrl.u32 %v13303, 26 (stack45)
        %v13314 = vor.u32 %v13313, %v13312 (stack46)
        %v13315 = vxor.u32 %v13314, %v13306 (stack47)
        %v13318 = vadd.s32 %v13315, %v9 (stack39)
        %v13322 = vadd.s32 3, %v13318 (stack39)
        %v13326 = vadd.s32 %v13322, %v13310 (stack39)
        %v13328 = vshll.u32 %v13322, 17 (stack44)
        %v13329 = vshrl.u32 %v13322, 15 (stack45)
        %v13330 = vor.u32 %v13329, %v13328 (stack46)
        %v13331 = vxor.u32 %v13330, %v13326 (stack47)
        %v13334 = vadd.s32 %v13331, %v13326 (stack39)
        %v13336 = vshll.u32 %v13331, 29 (stack44)
        %v13337 = vshrl.u32 %v13331, 3 (stack45)
        %v13338 = vor.u32 %v13337, %v13336 (stack46)
        %v13339 = vxor.u32 %v13338, %v13334 (stack47)
        %v13342 = vadd.s32 %v13339, %v13334 (stack39)
        %v13344 = vshll.u32 %v13339, 16 (stack44)
        %v13345 = vshrl.u32 %v13339, 16 (stack45)
        %v13346 = vor.u32 %v13345, %v13344 (stack46)
        %v13347 = vxor.u32 %v13346, %v13342 (stack47)
        %v13350 = vadd.s32 %v13347, %v13342 (stack39)
        %v13354 = vadd.s32 %v13350, %v9 (stack39)
        %v13356 = vshll.u32 %v13347, 24 (stack44)
        %v13357 = vshrl.u32 %v13347, 8 (stack45)
        %v13358 = vor.u32 %v13357, %v13356 (stack46)
        %v13359 = vxor.u32 %v13358, %v13350 (stack47)
        %v13362 = vadd.s32 %v13359, %v8 (stack39)
        %v13366 = vadd.s32 4, %v13362 (stack39)
        %v13370 = vadd.s32 %v13366, %v13354 (stack39)
        %v13372 = vshll.u32 %v13366, 13 (stack44)
        %v13373 = vshrl.u32 %v13366, 19 (stack45)
        %v13374 = vor.u32 %v13373, %v13372 (stack46)
        %v13375 = vxor.u32 %v13374, %v13370 (stack47)
        %v13378 = vadd.s32 %v13375, %v13370 (stack39)
        %v13380 = vshll.u32 %v13375, 15 (stack44)
        %v13381 = vshrl.u32 %v13375, 17 (stack45)
        %v13382 = vor.u32 %v13381, %v13380 (stack46)
        %v13383 = vxor.u32 %v13382, %v13378 (stack47)
        %v13386 = vadd.s32 %v13383, %v13378 (stack39)
        %v13388 = vshll.u32 %v13383, 26 (stack44)
        %v13389 = vshrl.u32 %v13383, 6 (stack45)
        %v13390 = vor.u32 %v13389, %v13388 (stack46)
        %v13391 = vxor.u32 %v13390, %v13386 (stack47)
        %v13394 = vadd.s32 %v13391, %v13386 (stack39)
        %v13398 = vadd.s32 %v13394, %v8 (stack39)
        %v13400 = vshll.u32 %v13391, 6 (stack44)
        %v13401 = vshrl.u32 %v13391, 26 (stack45)
        %v13402 = vor.u32 %v13401, %v13400 (stack46)
        %v13403 = vxor.u32 %v13402, %v13394 (stack47)
        %v13406 = vadd.s32 %v13403, %v10 (stack39)
        %v13410 = vadd.s32 5, %v13406 (stack39)
        %v13412 = vxor.u32 %v13410, %v13398 (stack47)
        %v13413 = vand.u32.u8 255, %v13412 (stack48)
        %v13414 = vand.u32 65535, %v13413 (stack49)
        %v13415 = vshrl.u32 %v13414, 1 (stack50)
        %v13416 = vor.u32 16256, %v13415 (stack46)
        %v13417 = vand.u32.u16 65535, %v13416 (stack51)
        %v119814 = vadd.low.f32.bf16 -1.0, %v13417 (stack52)
        %v13426 = vmul.f32 2.0, %v119814 (stack53)
        %v13430 = vadd.f32 -0.99609375, %v13426 (stack52)
        %v13434 = vmax.f32 %v13430, -0.99609375 (stack54)
        %v13436 = vand.u32 2147483647, %v13434 (stack55)
        %vm13439 = vcmp.eq.f32.partialorder %v13436, 1.0 (stack56)
        %v13444 = vmul.f32 inf, %v13434 (stack53)
        %v13446 = vxor.u32 2147483648, %v13434 (stack57)
        %v13449 = vmul.f32 %v13446, %v13434 (stack53)
        %v13451 = vadd.f32 1.0, %v13449 (stack58)
        %v13452 = vlog2.pop %v13451 (stack59)
        %v13453 = vmul.f32 0.6931472, %v13452 (stack60)
        %v13454 = vmul.f32 -0.5, %v13449 (stack61)
        %v13455 = vadd.f32 1.0, %v13454 (stack62)
        %v13456 = vmul.f32 %v13455, %v13449 (stack63)
        %v13457 = vand.u32 2147483647, %v13449 (stack64)
        %vm13458 = vcmp.lt.f32.partialorder %v13457, 0.0004427343 (stack65)
        %v13459 = vsel /*vm=*/%vm13458, /*on_true_vy=*/%v13456, /*on_false_vx=*/%v13453 (stack66)
        %v13460 = vxor.u32 2147483648, %v13459 (stack57)
        %vm13463 = vcmp.lt.f32.partialorder %v13460, 5.0 (stack56)
        %v13468 = vsel /*vm=*/%vm13463, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v13472 = vsel /*vm=*/%vm13463, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v13476 = vsel /*vm=*/%vm13463, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v13480 = vsel /*vm=*/%vm13463, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v13484 = vsel /*vm=*/%vm13463, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v13488 = vsel /*vm=*/%vm13463, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v13492 = vsel /*vm=*/%vm13463, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v13496 = vsel /*vm=*/%vm13463, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v13500 = vsel /*vm=*/%vm13463, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v13504 = vadd.f32 -2.5, %v13460 (stack52)
        %v13506 = vrsqrt.pop %v13460 (stack67)
        %v13507 = vmul.f32 %v13506, %v13460 (stack68)
        %vm13508 = vcmp.eq.f32.partialorder %v13460, inf (stack69)
        %v13509 = vsel /*vm=*/%vm13508, /*on_true_vy=*/%v13460, /*on_false_vx=*/%v13507 (stack70)
        %vm13510 = vcmp.eq.f32.partialorder %v13460, 0.0 (stack71)
        %v13511 = vand.u32 2147483648, %v13460 (stack72)
        %v13512 = vsel /*vm=*/%vm13510, /*on_true_vy=*/%v13511, /*on_false_vx=*/%v13509 (stack73)
        %v13515 = vadd.f32 -3.0, %v13512 (stack52)
        %v13519 = vsel /*vm=*/%vm13463, /*on_true_vy=*/%v13504, /*on_false_vx=*/%v13515 (stack43)
        %v13523 = vmul.f32 %v13519, %v13500 (stack53)
        %v13527 = vadd.f32 %v13523, %v13496 (stack52)
        %v13531 = vmul.f32 %v13527, %v13519 (stack53)
        %v13535 = vadd.f32 %v13531, %v13492 (stack52)
        %v13539 = vmul.f32 %v13535, %v13519 (stack53)
        %v13543 = vadd.f32 %v13539, %v13488 (stack52)
        %v13547 = vmul.f32 %v13543, %v13519 (stack53)
        %v13551 = vadd.f32 %v13547, %v13484 (stack52)
        %v13555 = vmul.f32 %v13551, %v13519 (stack53)
        %v13559 = vadd.f32 %v13555, %v13480 (stack52)
        %v13563 = vmul.f32 %v13559, %v13519 (stack53)
        %v13567 = vadd.f32 %v13563, %v13476 (stack52)
        %v13571 = vmul.f32 %v13567, %v13519 (stack53)
        %v13575 = vadd.f32 %v13571, %v13472 (stack52)
        %v13579 = vmul.f32 %v13575, %v13519 (stack53)
        %v13583 = vadd.f32 %v13579, %v13468 (stack52)
        %v13587 = vmul.f32 %v13583, %v13434 (stack53)
        %v13591 = vsel /*vm=*/%vm13439, /*on_true_vy=*/%v13444, /*on_false_vx=*/%v13587 (stack43)
        %v13595 = vmul.f32 1.4140625, %v13591 (stack53)
        %v13598 = vpack.c.bf16 0.0, %v13595 (stack74)
        %119815 = vst [vmem:[%s280 + $0x18c] sm:$0xf] /*vst_source=*/%v13598 (stack75)
        %v13602 = vadd.s32 %v11755, %v2355 (stack39)
        %v13612 = vadd.s32 %v13602, %v415 (stack39)
        %vm13616 = vcmp.lt.u32.totalorder %v13612, %v13602 (stack42)
        %vm13621 = vcmp.lt.u32.totalorder %v13602, %v2355 (stack42)
        %v13626 = vadd.s32 %v11738, %v2342 (stack39)
        %v13630 = vadd.s32 1, %v13626 (stack39)
        %v13634 = vsel /*vm=*/%vm13621, /*on_true_vy=*/%v13630, /*on_false_vx=*/%v13626 (stack43)
        %v13638 = vadd.s32 1, %v13634 (stack39)
        %v13642 = vsel /*vm=*/%vm13616, /*on_true_vy=*/%v13638, /*on_false_vx=*/%v13634 (stack43)
        %v13647 = vadd.s32 %v13642, %v10 (stack39)
        %v13651 = vadd.s32 %v13612, %v9 (stack39)
        %v13655 = vadd.s32 %v13651, %v13647 (stack39)
        %v13657 = vshll.u32 %v13651, 13 (stack44)
        %v13658 = vshrl.u32 %v13651, 19 (stack45)
        %v13659 = vor.u32 %v13658, %v13657 (stack46)
        %v13660 = vxor.u32 %v13659, %v13655 (stack47)
        %v13663 = vadd.s32 %v13660, %v13655 (stack39)
        %v13665 = vshll.u32 %v13660, 15 (stack44)
        %v13666 = vshrl.u32 %v13660, 17 (stack45)
        %v13667 = vor.u32 %v13666, %v13665 (stack46)
        %v13668 = vxor.u32 %v13667, %v13663 (stack47)
        %v13671 = vadd.s32 %v13668, %v13663 (stack39)
        %v13673 = vshll.u32 %v13668, 26 (stack44)
        %v13674 = vshrl.u32 %v13668, 6 (stack45)
        %v13675 = vor.u32 %v13674, %v13673 (stack46)
        %v13676 = vxor.u32 %v13675, %v13671 (stack47)
        %v13679 = vadd.s32 %v13676, %v13671 (stack39)
        %v13683 = vadd.s32 %v13679, %v9 (stack39)
        %v13685 = vshll.u32 %v13676, 6 (stack44)
        %v13686 = vshrl.u32 %v13676, 26 (stack45)
        %v13687 = vor.u32 %v13686, %v13685 (stack46)
        %v13688 = vxor.u32 %v13687, %v13679 (stack47)
        %v13691 = vadd.s32 %v13688, %v8 (stack39)
        %v13695 = vadd.s32 1, %v13691 (stack39)
        %v13699 = vadd.s32 %v13695, %v13683 (stack39)
        %v13701 = vshll.u32 %v13695, 17 (stack44)
        %v13702 = vshrl.u32 %v13695, 15 (stack45)
        %v13703 = vor.u32 %v13702, %v13701 (stack46)
        %v13704 = vxor.u32 %v13703, %v13699 (stack47)
        %v13707 = vadd.s32 %v13704, %v13699 (stack39)
        %v13709 = vshll.u32 %v13704, 29 (stack44)
        %v13710 = vshrl.u32 %v13704, 3 (stack45)
        %v13711 = vor.u32 %v13710, %v13709 (stack46)
        %v13712 = vxor.u32 %v13711, %v13707 (stack47)
        %v13715 = vadd.s32 %v13712, %v13707 (stack39)
        %v13717 = vshll.u32 %v13712, 16 (stack44)
        %v13718 = vshrl.u32 %v13712, 16 (stack45)
        %v13719 = vor.u32 %v13718, %v13717 (stack46)
        %v13720 = vxor.u32 %v13719, %v13715 (stack47)
        %v13723 = vadd.s32 %v13720, %v13715 (stack39)
        %v13727 = vadd.s32 %v13723, %v8 (stack39)
        %v13729 = vshll.u32 %v13720, 24 (stack44)
        %v13730 = vshrl.u32 %v13720, 8 (stack45)
        %v13731 = vor.u32 %v13730, %v13729 (stack46)
        %v13732 = vxor.u32 %v13731, %v13723 (stack47)
        %v13735 = vadd.s32 %v13732, %v10 (stack39)
        %v13739 = vadd.s32 2, %v13735 (stack39)
        %v13743 = vadd.s32 %v13739, %v13727 (stack39)
        %v13745 = vshll.u32 %v13739, 13 (stack44)
        %v13746 = vshrl.u32 %v13739, 19 (stack45)
        %v13747 = vor.u32 %v13746, %v13745 (stack46)
        %v13748 = vxor.u32 %v13747, %v13743 (stack47)
        %v13751 = vadd.s32 %v13748, %v13743 (stack39)
        %v13753 = vshll.u32 %v13748, 15 (stack44)
        %v13754 = vshrl.u32 %v13748, 17 (stack45)
        %v13755 = vor.u32 %v13754, %v13753 (stack46)
        %v13756 = vxor.u32 %v13755, %v13751 (stack47)
        %v13759 = vadd.s32 %v13756, %v13751 (stack39)
        %v13761 = vshll.u32 %v13756, 26 (stack44)
        %v13762 = vshrl.u32 %v13756, 6 (stack45)
        %v13763 = vor.u32 %v13762, %v13761 (stack46)
        %v13764 = vxor.u32 %v13763, %v13759 (stack47)
        %v13767 = vadd.s32 %v13764, %v13759 (stack39)
        %v13771 = vadd.s32 %v13767, %v10 (stack39)
        %v13773 = vshll.u32 %v13764, 6 (stack44)
        %v13774 = vshrl.u32 %v13764, 26 (stack45)
        %v13775 = vor.u32 %v13774, %v13773 (stack46)
        %v13776 = vxor.u32 %v13775, %v13767 (stack47)
        %v13779 = vadd.s32 %v13776, %v9 (stack39)
        %v13783 = vadd.s32 3, %v13779 (stack39)
        %v13787 = vadd.s32 %v13783, %v13771 (stack39)
        %v13789 = vshll.u32 %v13783, 17 (stack44)
        %v13790 = vshrl.u32 %v13783, 15 (stack45)
        %v13791 = vor.u32 %v13790, %v13789 (stack46)
        %v13792 = vxor.u32 %v13791, %v13787 (stack47)
        %v13795 = vadd.s32 %v13792, %v13787 (stack39)
        %v13797 = vshll.u32 %v13792, 29 (stack44)
        %v13798 = vshrl.u32 %v13792, 3 (stack45)
        %v13799 = vor.u32 %v13798, %v13797 (stack46)
        %v13800 = vxor.u32 %v13799, %v13795 (stack47)
        %v13803 = vadd.s32 %v13800, %v13795 (stack39)
        %v13805 = vshll.u32 %v13800, 16 (stack44)
        %v13806 = vshrl.u32 %v13800, 16 (stack45)
        %v13807 = vor.u32 %v13806, %v13805 (stack46)
        %v13808 = vxor.u32 %v13807, %v13803 (stack47)
        %v13811 = vadd.s32 %v13808, %v13803 (stack39)
        %v13815 = vadd.s32 %v13811, %v9 (stack39)
        %v13817 = vshll.u32 %v13808, 24 (stack44)
        %v13818 = vshrl.u32 %v13808, 8 (stack45)
        %v13819 = vor.u32 %v13818, %v13817 (stack46)
        %v13820 = vxor.u32 %v13819, %v13811 (stack47)
        %v13823 = vadd.s32 %v13820, %v8 (stack39)
        %v13827 = vadd.s32 4, %v13823 (stack39)
        %v13831 = vadd.s32 %v13827, %v13815 (stack39)
        %v13833 = vshll.u32 %v13827, 13 (stack44)
        %v13834 = vshrl.u32 %v13827, 19 (stack45)
        %v13835 = vor.u32 %v13834, %v13833 (stack46)
        %v13836 = vxor.u32 %v13835, %v13831 (stack47)
        %v13839 = vadd.s32 %v13836, %v13831 (stack39)
        %v13841 = vshll.u32 %v13836, 15 (stack44)
        %v13842 = vshrl.u32 %v13836, 17 (stack45)
        %v13843 = vor.u32 %v13842, %v13841 (stack46)
        %v13844 = vxor.u32 %v13843, %v13839 (stack47)
        %v13847 = vadd.s32 %v13844, %v13839 (stack39)
        %v13849 = vshll.u32 %v13844, 26 (stack44)
        %v13850 = vshrl.u32 %v13844, 6 (stack45)
        %v13851 = vor.u32 %v13850, %v13849 (stack46)
        %v13852 = vxor.u32 %v13851, %v13847 (stack47)
        %v13855 = vadd.s32 %v13852, %v13847 (stack39)
        %v13859 = vadd.s32 %v13855, %v8 (stack39)
        %v13861 = vshll.u32 %v13852, 6 (stack44)
        %v13862 = vshrl.u32 %v13852, 26 (stack45)
        %v13863 = vor.u32 %v13862, %v13861 (stack46)
        %v13864 = vxor.u32 %v13863, %v13855 (stack47)
        %v13867 = vadd.s32 %v13864, %v10 (stack39)
        %v13871 = vadd.s32 5, %v13867 (stack39)
        %v13873 = vxor.u32 %v13871, %v13859 (stack47)
        %v13874 = vand.u32.u8 255, %v13873 (stack48)
        %v13875 = vand.u32 65535, %v13874 (stack49)
        %v13876 = vshrl.u32 %v13875, 1 (stack50)
        %v13877 = vor.u32 16256, %v13876 (stack46)
        %v13878 = vand.u32.u16 65535, %v13877 (stack51)
        %v119816 = vadd.low.f32.bf16 -1.0, %v13878 (stack52)
        %v13887 = vmul.f32 2.0, %v119816 (stack53)
        %v13891 = vadd.f32 -0.99609375, %v13887 (stack52)
        %v13895 = vmax.f32 %v13891, -0.99609375 (stack54)
        %v13897 = vand.u32 2147483647, %v13895 (stack55)
        %vm13900 = vcmp.eq.f32.partialorder %v13897, 1.0 (stack56)
        %v13905 = vmul.f32 inf, %v13895 (stack53)
        %v13907 = vxor.u32 2147483648, %v13895 (stack57)
        %v13910 = vmul.f32 %v13907, %v13895 (stack53)
        %v13912 = vadd.f32 1.0, %v13910 (stack58)
        %v13913 = vlog2.pop %v13912 (stack59)
        %v13914 = vmul.f32 0.6931472, %v13913 (stack60)
        %v13915 = vmul.f32 -0.5, %v13910 (stack61)
        %v13916 = vadd.f32 1.0, %v13915 (stack62)
        %v13917 = vmul.f32 %v13916, %v13910 (stack63)
        %v13918 = vand.u32 2147483647, %v13910 (stack64)
        %vm13919 = vcmp.lt.f32.partialorder %v13918, 0.0004427343 (stack65)
        %v13920 = vsel /*vm=*/%vm13919, /*on_true_vy=*/%v13917, /*on_false_vx=*/%v13914 (stack66)
        %v13921 = vxor.u32 2147483648, %v13920 (stack57)
        %vm13924 = vcmp.lt.f32.partialorder %v13921, 5.0 (stack56)
        %v13929 = vsel /*vm=*/%vm13924, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v13933 = vsel /*vm=*/%vm13924, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v13937 = vsel /*vm=*/%vm13924, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v13941 = vsel /*vm=*/%vm13924, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v13945 = vsel /*vm=*/%vm13924, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v13949 = vsel /*vm=*/%vm13924, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v13953 = vsel /*vm=*/%vm13924, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v13957 = vsel /*vm=*/%vm13924, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v13961 = vsel /*vm=*/%vm13924, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v13965 = vadd.f32 -2.5, %v13921 (stack52)
        %v13967 = vrsqrt.pop %v13921 (stack67)
        %v13968 = vmul.f32 %v13967, %v13921 (stack68)
        %vm13969 = vcmp.eq.f32.partialorder %v13921, inf (stack69)
        %v13970 = vsel /*vm=*/%vm13969, /*on_true_vy=*/%v13921, /*on_false_vx=*/%v13968 (stack70)
        %vm13971 = vcmp.eq.f32.partialorder %v13921, 0.0 (stack71)
        %v13972 = vand.u32 2147483648, %v13921 (stack72)
        %v13973 = vsel /*vm=*/%vm13971, /*on_true_vy=*/%v13972, /*on_false_vx=*/%v13970 (stack73)
        %v13976 = vadd.f32 -3.0, %v13973 (stack52)
        %v13980 = vsel /*vm=*/%vm13924, /*on_true_vy=*/%v13965, /*on_false_vx=*/%v13976 (stack43)
        %v13984 = vmul.f32 %v13980, %v13961 (stack53)
        %v13988 = vadd.f32 %v13984, %v13957 (stack52)
        %v13992 = vmul.f32 %v13988, %v13980 (stack53)
        %v13996 = vadd.f32 %v13992, %v13953 (stack52)
        %v14000 = vmul.f32 %v13996, %v13980 (stack53)
        %v14004 = vadd.f32 %v14000, %v13949 (stack52)
        %v14008 = vmul.f32 %v14004, %v13980 (stack53)
        %v14012 = vadd.f32 %v14008, %v13945 (stack52)
        %v14016 = vmul.f32 %v14012, %v13980 (stack53)
        %v14020 = vadd.f32 %v14016, %v13941 (stack52)
        %v14024 = vmul.f32 %v14020, %v13980 (stack53)
        %v14028 = vadd.f32 %v14024, %v13937 (stack52)
        %v14032 = vmul.f32 %v14028, %v13980 (stack53)
        %v14036 = vadd.f32 %v14032, %v13933 (stack52)
        %v14040 = vmul.f32 %v14036, %v13980 (stack53)
        %v14044 = vadd.f32 %v14040, %v13929 (stack52)
        %v14048 = vmul.f32 %v14044, %v13895 (stack53)
        %v14052 = vsel /*vm=*/%vm13900, /*on_true_vy=*/%v13905, /*on_false_vx=*/%v14048 (stack43)
        %v14056 = vmul.f32 1.4140625, %v14052 (stack53)
        %v14059 = vpack.c.bf16 0.0, %v14056 (stack74)
        %119817 = vst [vmem:[%s280 + $0x20c] sm:$0xf] /*vst_source=*/%v14059 (stack75)
        %v14063 = vadd.s32 %v11755, %v2842 (stack39)
        %v14073 = vadd.s32 %v14063, %v415 (stack39)
        %vm14077 = vcmp.lt.u32.totalorder %v14073, %v14063 (stack42)
        %vm14082 = vcmp.lt.u32.totalorder %v14063, %v2842 (stack42)
        %v14087 = vadd.s32 %v11738, %v2829 (stack39)
        %v14091 = vadd.s32 1, %v14087 (stack39)
        %v14095 = vsel /*vm=*/%vm14082, /*on_true_vy=*/%v14091, /*on_false_vx=*/%v14087 (stack43)
        %v14099 = vadd.s32 1, %v14095 (stack39)
        %v14103 = vsel /*vm=*/%vm14077, /*on_true_vy=*/%v14099, /*on_false_vx=*/%v14095 (stack43)
        %v14108 = vadd.s32 %v14103, %v10 (stack39)
        %v14112 = vadd.s32 %v14073, %v9 (stack39)
        %v14116 = vadd.s32 %v14112, %v14108 (stack39)
        %v14118 = vshll.u32 %v14112, 13 (stack44)
        %v14119 = vshrl.u32 %v14112, 19 (stack45)
        %v14120 = vor.u32 %v14119, %v14118 (stack46)
        %v14121 = vxor.u32 %v14120, %v14116 (stack47)
        %v14124 = vadd.s32 %v14121, %v14116 (stack39)
        %v14126 = vshll.u32 %v14121, 15 (stack44)
        %v14127 = vshrl.u32 %v14121, 17 (stack45)
        %v14128 = vor.u32 %v14127, %v14126 (stack46)
        %v14129 = vxor.u32 %v14128, %v14124 (stack47)
        %v14132 = vadd.s32 %v14129, %v14124 (stack39)
        %v14134 = vshll.u32 %v14129, 26 (stack44)
        %v14135 = vshrl.u32 %v14129, 6 (stack45)
        %v14136 = vor.u32 %v14135, %v14134 (stack46)
        %v14137 = vxor.u32 %v14136, %v14132 (stack47)
        %v14140 = vadd.s32 %v14137, %v14132 (stack39)
        %v14144 = vadd.s32 %v14140, %v9 (stack39)
        %v14146 = vshll.u32 %v14137, 6 (stack44)
        %v14147 = vshrl.u32 %v14137, 26 (stack45)
        %v14148 = vor.u32 %v14147, %v14146 (stack46)
        %v14149 = vxor.u32 %v14148, %v14140 (stack47)
        %v14152 = vadd.s32 %v14149, %v8 (stack39)
        %v14156 = vadd.s32 1, %v14152 (stack39)
        %v14160 = vadd.s32 %v14156, %v14144 (stack39)
        %v14162 = vshll.u32 %v14156, 17 (stack44)
        %v14163 = vshrl.u32 %v14156, 15 (stack45)
        %v14164 = vor.u32 %v14163, %v14162 (stack46)
        %v14165 = vxor.u32 %v14164, %v14160 (stack47)
        %v14168 = vadd.s32 %v14165, %v14160 (stack39)
        %v14170 = vshll.u32 %v14165, 29 (stack44)
        %v14171 = vshrl.u32 %v14165, 3 (stack45)
        %v14172 = vor.u32 %v14171, %v14170 (stack46)
        %v14173 = vxor.u32 %v14172, %v14168 (stack47)
        %v14176 = vadd.s32 %v14173, %v14168 (stack39)
        %v14178 = vshll.u32 %v14173, 16 (stack44)
        %v14179 = vshrl.u32 %v14173, 16 (stack45)
        %v14180 = vor.u32 %v14179, %v14178 (stack46)
        %v14181 = vxor.u32 %v14180, %v14176 (stack47)
        %v14184 = vadd.s32 %v14181, %v14176 (stack39)
        %v14188 = vadd.s32 %v14184, %v8 (stack39)
        %v14190 = vshll.u32 %v14181, 24 (stack44)
        %v14191 = vshrl.u32 %v14181, 8 (stack45)
        %v14192 = vor.u32 %v14191, %v14190 (stack46)
        %v14193 = vxor.u32 %v14192, %v14184 (stack47)
        %v14196 = vadd.s32 %v14193, %v10 (stack39)
        %v14200 = vadd.s32 2, %v14196 (stack39)
        %v14204 = vadd.s32 %v14200, %v14188 (stack39)
        %v14206 = vshll.u32 %v14200, 13 (stack44)
        %v14207 = vshrl.u32 %v14200, 19 (stack45)
        %v14208 = vor.u32 %v14207, %v14206 (stack46)
        %v14209 = vxor.u32 %v14208, %v14204 (stack47)
        %v14212 = vadd.s32 %v14209, %v14204 (stack39)
        %v14214 = vshll.u32 %v14209, 15 (stack44)
        %v14215 = vshrl.u32 %v14209, 17 (stack45)
        %v14216 = vor.u32 %v14215, %v14214 (stack46)
        %v14217 = vxor.u32 %v14216, %v14212 (stack47)
        %v14220 = vadd.s32 %v14217, %v14212 (stack39)
        %v14222 = vshll.u32 %v14217, 26 (stack44)
        %v14223 = vshrl.u32 %v14217, 6 (stack45)
        %v14224 = vor.u32 %v14223, %v14222 (stack46)
        %v14225 = vxor.u32 %v14224, %v14220 (stack47)
        %v14228 = vadd.s32 %v14225, %v14220 (stack39)
        %v14232 = vadd.s32 %v14228, %v10 (stack39)
        %v14234 = vshll.u32 %v14225, 6 (stack44)
        %v14235 = vshrl.u32 %v14225, 26 (stack45)
        %v14236 = vor.u32 %v14235, %v14234 (stack46)
        %v14237 = vxor.u32 %v14236, %v14228 (stack47)
        %v14240 = vadd.s32 %v14237, %v9 (stack39)
        %v14244 = vadd.s32 3, %v14240 (stack39)
        %v14248 = vadd.s32 %v14244, %v14232 (stack39)
        %v14250 = vshll.u32 %v14244, 17 (stack44)
        %v14251 = vshrl.u32 %v14244, 15 (stack45)
        %v14252 = vor.u32 %v14251, %v14250 (stack46)
        %v14253 = vxor.u32 %v14252, %v14248 (stack47)
        %v14256 = vadd.s32 %v14253, %v14248 (stack39)
        %v14258 = vshll.u32 %v14253, 29 (stack44)
        %v14259 = vshrl.u32 %v14253, 3 (stack45)
        %v14260 = vor.u32 %v14259, %v14258 (stack46)
        %v14261 = vxor.u32 %v14260, %v14256 (stack47)
        %v14264 = vadd.s32 %v14261, %v14256 (stack39)
        %v14266 = vshll.u32 %v14261, 16 (stack44)
        %v14267 = vshrl.u32 %v14261, 16 (stack45)
        %v14268 = vor.u32 %v14267, %v14266 (stack46)
        %v14269 = vxor.u32 %v14268, %v14264 (stack47)
        %v14272 = vadd.s32 %v14269, %v14264 (stack39)
        %v14276 = vadd.s32 %v14272, %v9 (stack39)
        %v14278 = vshll.u32 %v14269, 24 (stack44)
        %v14279 = vshrl.u32 %v14269, 8 (stack45)
        %v14280 = vor.u32 %v14279, %v14278 (stack46)
        %v14281 = vxor.u32 %v14280, %v14272 (stack47)
        %v14284 = vadd.s32 %v14281, %v8 (stack39)
        %v14288 = vadd.s32 4, %v14284 (stack39)
        %v14292 = vadd.s32 %v14288, %v14276 (stack39)
        %v14294 = vshll.u32 %v14288, 13 (stack44)
        %v14295 = vshrl.u32 %v14288, 19 (stack45)
        %v14296 = vor.u32 %v14295, %v14294 (stack46)
        %v14297 = vxor.u32 %v14296, %v14292 (stack47)
        %v14300 = vadd.s32 %v14297, %v14292 (stack39)
        %v14302 = vshll.u32 %v14297, 15 (stack44)
        %v14303 = vshrl.u32 %v14297, 17 (stack45)
        %v14304 = vor.u32 %v14303, %v14302 (stack46)
        %v14305 = vxor.u32 %v14304, %v14300 (stack47)
        %v14308 = vadd.s32 %v14305, %v14300 (stack39)
        %v14310 = vshll.u32 %v14305, 26 (stack44)
        %v14311 = vshrl.u32 %v14305, 6 (stack45)
        %v14312 = vor.u32 %v14311, %v14310 (stack46)
        %v14313 = vxor.u32 %v14312, %v14308 (stack47)
        %v14316 = vadd.s32 %v14313, %v14308 (stack39)
        %v14320 = vadd.s32 %v14316, %v8 (stack39)
        %v14322 = vshll.u32 %v14313, 6 (stack44)
        %v14323 = vshrl.u32 %v14313, 26 (stack45)
        %v14324 = vor.u32 %v14323, %v14322 (stack46)
        %v14325 = vxor.u32 %v14324, %v14316 (stack47)
        %v14328 = vadd.s32 %v14325, %v10 (stack39)
        %v14332 = vadd.s32 5, %v14328 (stack39)
        %v14334 = vxor.u32 %v14332, %v14320 (stack47)
        %v14335 = vand.u32.u8 255, %v14334 (stack48)
        %v14336 = vand.u32 65535, %v14335 (stack49)
        %v14337 = vshrl.u32 %v14336, 1 (stack50)
        %v14338 = vor.u32 16256, %v14337 (stack46)
        %v14339 = vand.u32.u16 65535, %v14338 (stack51)
        %v119818 = vadd.low.f32.bf16 -1.0, %v14339 (stack52)
        %v14348 = vmul.f32 2.0, %v119818 (stack53)
        %v14352 = vadd.f32 -0.99609375, %v14348 (stack52)
        %v14356 = vmax.f32 %v14352, -0.99609375 (stack54)
        %v14358 = vand.u32 2147483647, %v14356 (stack55)
        %vm14361 = vcmp.eq.f32.partialorder %v14358, 1.0 (stack56)
        %v14366 = vmul.f32 inf, %v14356 (stack53)
        %v14368 = vxor.u32 2147483648, %v14356 (stack57)
        %v14371 = vmul.f32 %v14368, %v14356 (stack53)
        %v14373 = vadd.f32 1.0, %v14371 (stack58)
        %v14374 = vlog2.pop %v14373 (stack59)
        %v14375 = vmul.f32 0.6931472, %v14374 (stack60)
        %v14376 = vmul.f32 -0.5, %v14371 (stack61)
        %v14377 = vadd.f32 1.0, %v14376 (stack62)
        %v14378 = vmul.f32 %v14377, %v14371 (stack63)
        %v14379 = vand.u32 2147483647, %v14371 (stack64)
        %vm14380 = vcmp.lt.f32.partialorder %v14379, 0.0004427343 (stack65)
        %v14381 = vsel /*vm=*/%vm14380, /*on_true_vy=*/%v14378, /*on_false_vx=*/%v14375 (stack66)
        %v14382 = vxor.u32 2147483648, %v14381 (stack57)
        %vm14385 = vcmp.lt.f32.partialorder %v14382, 5.0 (stack56)
        %v14390 = vsel /*vm=*/%vm14385, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v14394 = vsel /*vm=*/%vm14385, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v14398 = vsel /*vm=*/%vm14385, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v14402 = vsel /*vm=*/%vm14385, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v14406 = vsel /*vm=*/%vm14385, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v14410 = vsel /*vm=*/%vm14385, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v14414 = vsel /*vm=*/%vm14385, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v14418 = vsel /*vm=*/%vm14385, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v14422 = vsel /*vm=*/%vm14385, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v14426 = vadd.f32 -2.5, %v14382 (stack52)
        %v14428 = vrsqrt.pop %v14382 (stack67)
        %v14429 = vmul.f32 %v14428, %v14382 (stack68)
        %vm14430 = vcmp.eq.f32.partialorder %v14382, inf (stack69)
        %v14431 = vsel /*vm=*/%vm14430, /*on_true_vy=*/%v14382, /*on_false_vx=*/%v14429 (stack70)
        %vm14432 = vcmp.eq.f32.partialorder %v14382, 0.0 (stack71)
        %v14433 = vand.u32 2147483648, %v14382 (stack72)
        %v14434 = vsel /*vm=*/%vm14432, /*on_true_vy=*/%v14433, /*on_false_vx=*/%v14431 (stack73)
        %v14437 = vadd.f32 -3.0, %v14434 (stack52)
        %v14441 = vsel /*vm=*/%vm14385, /*on_true_vy=*/%v14426, /*on_false_vx=*/%v14437 (stack43)
        %v14445 = vmul.f32 %v14441, %v14422 (stack53)
        %v14449 = vadd.f32 %v14445, %v14418 (stack52)
        %v14453 = vmul.f32 %v14449, %v14441 (stack53)
        %v14457 = vadd.f32 %v14453, %v14414 (stack52)
        %v14461 = vmul.f32 %v14457, %v14441 (stack53)
        %v14465 = vadd.f32 %v14461, %v14410 (stack52)
        %v14469 = vmul.f32 %v14465, %v14441 (stack53)
        %v14473 = vadd.f32 %v14469, %v14406 (stack52)
        %v14477 = vmul.f32 %v14473, %v14441 (stack53)
        %v14481 = vadd.f32 %v14477, %v14402 (stack52)
        %v14485 = vmul.f32 %v14481, %v14441 (stack53)
        %v14489 = vadd.f32 %v14485, %v14398 (stack52)
        %v14493 = vmul.f32 %v14489, %v14441 (stack53)
        %v14497 = vadd.f32 %v14493, %v14394 (stack52)
        %v14501 = vmul.f32 %v14497, %v14441 (stack53)
        %v14505 = vadd.f32 %v14501, %v14390 (stack52)
        %v14509 = vmul.f32 %v14505, %v14356 (stack53)
        %v14513 = vsel /*vm=*/%vm14361, /*on_true_vy=*/%v14366, /*on_false_vx=*/%v14509 (stack43)
        %v14517 = vmul.f32 1.4140625, %v14513 (stack53)
        %v14520 = vpack.c.bf16 0.0, %v14517 (stack74)
        %119819 = vst [vmem:[%s280 + $0x28c] sm:$0xf] /*vst_source=*/%v14520 (stack75)
        %v14524 = vadd.s32 %v11755, %v3329 (stack39)
        %v14534 = vadd.s32 %v14524, %v415 (stack39)
        %vm14538 = vcmp.lt.u32.totalorder %v14534, %v14524 (stack42)
        %vm14543 = vcmp.lt.u32.totalorder %v14524, %v3329 (stack42)
        %v14548 = vadd.s32 %v11738, %v3316 (stack39)
        %v14552 = vadd.s32 1, %v14548 (stack39)
        %v14556 = vsel /*vm=*/%vm14543, /*on_true_vy=*/%v14552, /*on_false_vx=*/%v14548 (stack43)
        %v14560 = vadd.s32 1, %v14556 (stack39)
        %v14564 = vsel /*vm=*/%vm14538, /*on_true_vy=*/%v14560, /*on_false_vx=*/%v14556 (stack43)
        %v14569 = vadd.s32 %v14564, %v10 (stack39)
        %v14573 = vadd.s32 %v14534, %v9 (stack39)
        %v14577 = vadd.s32 %v14573, %v14569 (stack39)
        %v14579 = vshll.u32 %v14573, 13 (stack44)
        %v14580 = vshrl.u32 %v14573, 19 (stack45)
        %v14581 = vor.u32 %v14580, %v14579 (stack46)
        %v14582 = vxor.u32 %v14581, %v14577 (stack47)
        %v14585 = vadd.s32 %v14582, %v14577 (stack39)
        %v14587 = vshll.u32 %v14582, 15 (stack44)
        %v14588 = vshrl.u32 %v14582, 17 (stack45)
        %v14589 = vor.u32 %v14588, %v14587 (stack46)
        %v14590 = vxor.u32 %v14589, %v14585 (stack47)
        %v14593 = vadd.s32 %v14590, %v14585 (stack39)
        %v14595 = vshll.u32 %v14590, 26 (stack44)
        %v14596 = vshrl.u32 %v14590, 6 (stack45)
        %v14597 = vor.u32 %v14596, %v14595 (stack46)
        %v14598 = vxor.u32 %v14597, %v14593 (stack47)
        %v14601 = vadd.s32 %v14598, %v14593 (stack39)
        %v14605 = vadd.s32 %v14601, %v9 (stack39)
        %v14607 = vshll.u32 %v14598, 6 (stack44)
        %v14608 = vshrl.u32 %v14598, 26 (stack45)
        %v14609 = vor.u32 %v14608, %v14607 (stack46)
        %v14610 = vxor.u32 %v14609, %v14601 (stack47)
        %v14613 = vadd.s32 %v14610, %v8 (stack39)
        %v14617 = vadd.s32 1, %v14613 (stack39)
        %v14621 = vadd.s32 %v14617, %v14605 (stack39)
        %v14623 = vshll.u32 %v14617, 17 (stack44)
        %v14624 = vshrl.u32 %v14617, 15 (stack45)
        %v14625 = vor.u32 %v14624, %v14623 (stack46)
        %v14626 = vxor.u32 %v14625, %v14621 (stack47)
        %v14629 = vadd.s32 %v14626, %v14621 (stack39)
        %v14631 = vshll.u32 %v14626, 29 (stack44)
        %v14632 = vshrl.u32 %v14626, 3 (stack45)
        %v14633 = vor.u32 %v14632, %v14631 (stack46)
        %v14634 = vxor.u32 %v14633, %v14629 (stack47)
        %v14637 = vadd.s32 %v14634, %v14629 (stack39)
        %v14639 = vshll.u32 %v14634, 16 (stack44)
        %v14640 = vshrl.u32 %v14634, 16 (stack45)
        %v14641 = vor.u32 %v14640, %v14639 (stack46)
        %v14642 = vxor.u32 %v14641, %v14637 (stack47)
        %v14645 = vadd.s32 %v14642, %v14637 (stack39)
        %v14649 = vadd.s32 %v14645, %v8 (stack39)
        %v14651 = vshll.u32 %v14642, 24 (stack44)
        %v14652 = vshrl.u32 %v14642, 8 (stack45)
        %v14653 = vor.u32 %v14652, %v14651 (stack46)
        %v14654 = vxor.u32 %v14653, %v14645 (stack47)
        %v14657 = vadd.s32 %v14654, %v10 (stack39)
        %v14661 = vadd.s32 2, %v14657 (stack39)
        %v14665 = vadd.s32 %v14661, %v14649 (stack39)
        %v14667 = vshll.u32 %v14661, 13 (stack44)
        %v14668 = vshrl.u32 %v14661, 19 (stack45)
        %v14669 = vor.u32 %v14668, %v14667 (stack46)
        %v14670 = vxor.u32 %v14669, %v14665 (stack47)
        %v14673 = vadd.s32 %v14670, %v14665 (stack39)
        %v14675 = vshll.u32 %v14670, 15 (stack44)
        %v14676 = vshrl.u32 %v14670, 17 (stack45)
        %v14677 = vor.u32 %v14676, %v14675 (stack46)
        %v14678 = vxor.u32 %v14677, %v14673 (stack47)
        %v14681 = vadd.s32 %v14678, %v14673 (stack39)
        %v14683 = vshll.u32 %v14678, 26 (stack44)
        %v14684 = vshrl.u32 %v14678, 6 (stack45)
        %v14685 = vor.u32 %v14684, %v14683 (stack46)
        %v14686 = vxor.u32 %v14685, %v14681 (stack47)
        %v14689 = vadd.s32 %v14686, %v14681 (stack39)
        %v14693 = vadd.s32 %v14689, %v10 (stack39)
        %v14695 = vshll.u32 %v14686, 6 (stack44)
        %v14696 = vshrl.u32 %v14686, 26 (stack45)
        %v14697 = vor.u32 %v14696, %v14695 (stack46)
        %v14698 = vxor.u32 %v14697, %v14689 (stack47)
        %v14701 = vadd.s32 %v14698, %v9 (stack39)
        %v14705 = vadd.s32 3, %v14701 (stack39)
        %v14709 = vadd.s32 %v14705, %v14693 (stack39)
        %v14711 = vshll.u32 %v14705, 17 (stack44)
        %v14712 = vshrl.u32 %v14705, 15 (stack45)
        %v14713 = vor.u32 %v14712, %v14711 (stack46)
        %v14714 = vxor.u32 %v14713, %v14709 (stack47)
        %v14717 = vadd.s32 %v14714, %v14709 (stack39)
        %v14719 = vshll.u32 %v14714, 29 (stack44)
        %v14720 = vshrl.u32 %v14714, 3 (stack45)
        %v14721 = vor.u32 %v14720, %v14719 (stack46)
        %v14722 = vxor.u32 %v14721, %v14717 (stack47)
        %v14725 = vadd.s32 %v14722, %v14717 (stack39)
        %v14727 = vshll.u32 %v14722, 16 (stack44)
        %v14728 = vshrl.u32 %v14722, 16 (stack45)
        %v14729 = vor.u32 %v14728, %v14727 (stack46)
        %v14730 = vxor.u32 %v14729, %v14725 (stack47)
        %v14733 = vadd.s32 %v14730, %v14725 (stack39)
        %v14737 = vadd.s32 %v14733, %v9 (stack39)
        %v14739 = vshll.u32 %v14730, 24 (stack44)
        %v14740 = vshrl.u32 %v14730, 8 (stack45)
        %v14741 = vor.u32 %v14740, %v14739 (stack46)
        %v14742 = vxor.u32 %v14741, %v14733 (stack47)
        %v14745 = vadd.s32 %v14742, %v8 (stack39)
        %v14749 = vadd.s32 4, %v14745 (stack39)
        %v14753 = vadd.s32 %v14749, %v14737 (stack39)
        %v14755 = vshll.u32 %v14749, 13 (stack44)
        %v14756 = vshrl.u32 %v14749, 19 (stack45)
        %v14757 = vor.u32 %v14756, %v14755 (stack46)
        %v14758 = vxor.u32 %v14757, %v14753 (stack47)
        %v14761 = vadd.s32 %v14758, %v14753 (stack39)
        %v14763 = vshll.u32 %v14758, 15 (stack44)
        %v14764 = vshrl.u32 %v14758, 17 (stack45)
        %v14765 = vor.u32 %v14764, %v14763 (stack46)
        %v14766 = vxor.u32 %v14765, %v14761 (stack47)
        %v14769 = vadd.s32 %v14766, %v14761 (stack39)
        %v14771 = vshll.u32 %v14766, 26 (stack44)
        %v14772 = vshrl.u32 %v14766, 6 (stack45)
        %v14773 = vor.u32 %v14772, %v14771 (stack46)
        %v14774 = vxor.u32 %v14773, %v14769 (stack47)
        %v14777 = vadd.s32 %v14774, %v14769 (stack39)
        %v14781 = vadd.s32 %v14777, %v8 (stack39)
        %v14783 = vshll.u32 %v14774, 6 (stack44)
        %v14784 = vshrl.u32 %v14774, 26 (stack45)
        %v14785 = vor.u32 %v14784, %v14783 (stack46)
        %v14786 = vxor.u32 %v14785, %v14777 (stack47)
        %v14789 = vadd.s32 %v14786, %v10 (stack39)
        %v14793 = vadd.s32 5, %v14789 (stack39)
        %v14795 = vxor.u32 %v14793, %v14781 (stack47)
        %v14796 = vand.u32.u8 255, %v14795 (stack48)
        %v14797 = vand.u32 65535, %v14796 (stack49)
        %v14798 = vshrl.u32 %v14797, 1 (stack50)
        %v14799 = vor.u32 16256, %v14798 (stack46)
        %v14800 = vand.u32.u16 65535, %v14799 (stack51)
        %v119820 = vadd.low.f32.bf16 -1.0, %v14800 (stack52)
        %v14809 = vmul.f32 2.0, %v119820 (stack53)
        %v14813 = vadd.f32 -0.99609375, %v14809 (stack52)
        %v14817 = vmax.f32 %v14813, -0.99609375 (stack54)
        %v14819 = vand.u32 2147483647, %v14817 (stack55)
        %vm14822 = vcmp.eq.f32.partialorder %v14819, 1.0 (stack56)
        %v14827 = vmul.f32 inf, %v14817 (stack53)
        %v14829 = vxor.u32 2147483648, %v14817 (stack57)
        %v14832 = vmul.f32 %v14829, %v14817 (stack53)
        %v14834 = vadd.f32 1.0, %v14832 (stack58)
        %v14835 = vlog2.pop %v14834 (stack59)
        %v14836 = vmul.f32 0.6931472, %v14835 (stack60)
        %v14837 = vmul.f32 -0.5, %v14832 (stack61)
        %v14838 = vadd.f32 1.0, %v14837 (stack62)
        %v14839 = vmul.f32 %v14838, %v14832 (stack63)
        %v14840 = vand.u32 2147483647, %v14832 (stack64)
        %vm14841 = vcmp.lt.f32.partialorder %v14840, 0.0004427343 (stack65)
        %v14842 = vsel /*vm=*/%vm14841, /*on_true_vy=*/%v14839, /*on_false_vx=*/%v14836 (stack66)
        %v14843 = vxor.u32 2147483648, %v14842 (stack57)
        %vm14846 = vcmp.lt.f32.partialorder %v14843, 5.0 (stack56)
        %v14851 = vsel /*vm=*/%vm14846, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v14855 = vsel /*vm=*/%vm14846, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v14859 = vsel /*vm=*/%vm14846, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v14863 = vsel /*vm=*/%vm14846, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v14867 = vsel /*vm=*/%vm14846, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v14871 = vsel /*vm=*/%vm14846, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v14875 = vsel /*vm=*/%vm14846, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v14879 = vsel /*vm=*/%vm14846, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v14883 = vsel /*vm=*/%vm14846, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v14887 = vadd.f32 -2.5, %v14843 (stack52)
        %v14889 = vrsqrt.pop %v14843 (stack67)
        %v14890 = vmul.f32 %v14889, %v14843 (stack68)
        %vm14891 = vcmp.eq.f32.partialorder %v14843, inf (stack69)
        %v14892 = vsel /*vm=*/%vm14891, /*on_true_vy=*/%v14843, /*on_false_vx=*/%v14890 (stack70)
        %vm14893 = vcmp.eq.f32.partialorder %v14843, 0.0 (stack71)
        %v14894 = vand.u32 2147483648, %v14843 (stack72)
        %v14895 = vsel /*vm=*/%vm14893, /*on_true_vy=*/%v14894, /*on_false_vx=*/%v14892 (stack73)
        %v14898 = vadd.f32 -3.0, %v14895 (stack52)
        %v14902 = vsel /*vm=*/%vm14846, /*on_true_vy=*/%v14887, /*on_false_vx=*/%v14898 (stack43)
        %v14906 = vmul.f32 %v14902, %v14883 (stack53)
        %v14910 = vadd.f32 %v14906, %v14879 (stack52)
        %v14914 = vmul.f32 %v14910, %v14902 (stack53)
        %v14918 = vadd.f32 %v14914, %v14875 (stack52)
        %v14922 = vmul.f32 %v14918, %v14902 (stack53)
        %v14926 = vadd.f32 %v14922, %v14871 (stack52)
        %v14930 = vmul.f32 %v14926, %v14902 (stack53)
        %v14934 = vadd.f32 %v14930, %v14867 (stack52)
        %v14938 = vmul.f32 %v14934, %v14902 (stack53)
        %v14942 = vadd.f32 %v14938, %v14863 (stack52)
        %v14946 = vmul.f32 %v14942, %v14902 (stack53)
        %v14950 = vadd.f32 %v14946, %v14859 (stack52)
        %v14954 = vmul.f32 %v14950, %v14902 (stack53)
        %v14958 = vadd.f32 %v14954, %v14855 (stack52)
        %v14962 = vmul.f32 %v14958, %v14902 (stack53)
        %v14966 = vadd.f32 %v14962, %v14851 (stack52)
        %v14970 = vmul.f32 %v14966, %v14817 (stack53)
        %v14974 = vsel /*vm=*/%vm14822, /*on_true_vy=*/%v14827, /*on_false_vx=*/%v14970 (stack43)
        %v14978 = vmul.f32 1.4140625, %v14974 (stack53)
        %v14981 = vpack.c.bf16 0.0, %v14978 (stack74)
        %119821 = vst [vmem:[%s280 + $0x30c] sm:$0xf] /*vst_source=*/%v14981 (stack75)
        %v14985 = vadd.s32 %v11755, %v3816 (stack39)
        %v14995 = vadd.s32 %v14985, %v415 (stack39)
        %vm14999 = vcmp.lt.u32.totalorder %v14995, %v14985 (stack42)
        %vm15004 = vcmp.lt.u32.totalorder %v14985, %v3816 (stack42)
        %v15009 = vadd.s32 %v11738, %v3803 (stack39)
        %v15013 = vadd.s32 1, %v15009 (stack39)
        %v15017 = vsel /*vm=*/%vm15004, /*on_true_vy=*/%v15013, /*on_false_vx=*/%v15009 (stack43)
        %v15021 = vadd.s32 1, %v15017 (stack39)
        %v15025 = vsel /*vm=*/%vm14999, /*on_true_vy=*/%v15021, /*on_false_vx=*/%v15017 (stack43)
        %v15030 = vadd.s32 %v15025, %v10 (stack39)
        %v15034 = vadd.s32 %v14995, %v9 (stack39)
        %v15038 = vadd.s32 %v15034, %v15030 (stack39)
        %v15040 = vshll.u32 %v15034, 13 (stack44)
        %v15041 = vshrl.u32 %v15034, 19 (stack45)
        %v15042 = vor.u32 %v15041, %v15040 (stack46)
        %v15043 = vxor.u32 %v15042, %v15038 (stack47)
        %v15046 = vadd.s32 %v15043, %v15038 (stack39)
        %v15048 = vshll.u32 %v15043, 15 (stack44)
        %v15049 = vshrl.u32 %v15043, 17 (stack45)
        %v15050 = vor.u32 %v15049, %v15048 (stack46)
        %v15051 = vxor.u32 %v15050, %v15046 (stack47)
        %v15054 = vadd.s32 %v15051, %v15046 (stack39)
        %v15056 = vshll.u32 %v15051, 26 (stack44)
        %v15057 = vshrl.u32 %v15051, 6 (stack45)
        %v15058 = vor.u32 %v15057, %v15056 (stack46)
        %v15059 = vxor.u32 %v15058, %v15054 (stack47)
        %v15062 = vadd.s32 %v15059, %v15054 (stack39)
        %v15066 = vadd.s32 %v15062, %v9 (stack39)
        %v15068 = vshll.u32 %v15059, 6 (stack44)
        %v15069 = vshrl.u32 %v15059, 26 (stack45)
        %v15070 = vor.u32 %v15069, %v15068 (stack46)
        %v15071 = vxor.u32 %v15070, %v15062 (stack47)
        %v15074 = vadd.s32 %v15071, %v8 (stack39)
        %v15078 = vadd.s32 1, %v15074 (stack39)
        %v15082 = vadd.s32 %v15078, %v15066 (stack39)
        %v15084 = vshll.u32 %v15078, 17 (stack44)
        %v15085 = vshrl.u32 %v15078, 15 (stack45)
        %v15086 = vor.u32 %v15085, %v15084 (stack46)
        %v15087 = vxor.u32 %v15086, %v15082 (stack47)
        %v15090 = vadd.s32 %v15087, %v15082 (stack39)
        %v15092 = vshll.u32 %v15087, 29 (stack44)
        %v15093 = vshrl.u32 %v15087, 3 (stack45)
        %v15094 = vor.u32 %v15093, %v15092 (stack46)
        %v15095 = vxor.u32 %v15094, %v15090 (stack47)
        %v15098 = vadd.s32 %v15095, %v15090 (stack39)
        %v15100 = vshll.u32 %v15095, 16 (stack44)
        %v15101 = vshrl.u32 %v15095, 16 (stack45)
        %v15102 = vor.u32 %v15101, %v15100 (stack46)
        %v15103 = vxor.u32 %v15102, %v15098 (stack47)
        %v15106 = vadd.s32 %v15103, %v15098 (stack39)
        %v15110 = vadd.s32 %v15106, %v8 (stack39)
        %v15112 = vshll.u32 %v15103, 24 (stack44)
        %v15113 = vshrl.u32 %v15103, 8 (stack45)
        %v15114 = vor.u32 %v15113, %v15112 (stack46)
        %v15115 = vxor.u32 %v15114, %v15106 (stack47)
        %v15118 = vadd.s32 %v15115, %v10 (stack39)
        %v15122 = vadd.s32 2, %v15118 (stack39)
        %v15126 = vadd.s32 %v15122, %v15110 (stack39)
        %v15128 = vshll.u32 %v15122, 13 (stack44)
        %v15129 = vshrl.u32 %v15122, 19 (stack45)
        %v15130 = vor.u32 %v15129, %v15128 (stack46)
        %v15131 = vxor.u32 %v15130, %v15126 (stack47)
        %v15134 = vadd.s32 %v15131, %v15126 (stack39)
        %v15136 = vshll.u32 %v15131, 15 (stack44)
        %v15137 = vshrl.u32 %v15131, 17 (stack45)
        %v15138 = vor.u32 %v15137, %v15136 (stack46)
        %v15139 = vxor.u32 %v15138, %v15134 (stack47)
        %v15142 = vadd.s32 %v15139, %v15134 (stack39)
        %v15144 = vshll.u32 %v15139, 26 (stack44)
        %v15145 = vshrl.u32 %v15139, 6 (stack45)
        %v15146 = vor.u32 %v15145, %v15144 (stack46)
        %v15147 = vxor.u32 %v15146, %v15142 (stack47)
        %v15150 = vadd.s32 %v15147, %v15142 (stack39)
        %v15154 = vadd.s32 %v15150, %v10 (stack39)
        %v15156 = vshll.u32 %v15147, 6 (stack44)
        %v15157 = vshrl.u32 %v15147, 26 (stack45)
        %v15158 = vor.u32 %v15157, %v15156 (stack46)
        %v15159 = vxor.u32 %v15158, %v15150 (stack47)
        %v15162 = vadd.s32 %v15159, %v9 (stack39)
        %v15166 = vadd.s32 3, %v15162 (stack39)
        %v15170 = vadd.s32 %v15166, %v15154 (stack39)
        %v15172 = vshll.u32 %v15166, 17 (stack44)
        %v15173 = vshrl.u32 %v15166, 15 (stack45)
        %v15174 = vor.u32 %v15173, %v15172 (stack46)
        %v15175 = vxor.u32 %v15174, %v15170 (stack47)
        %v15178 = vadd.s32 %v15175, %v15170 (stack39)
        %v15180 = vshll.u32 %v15175, 29 (stack44)
        %v15181 = vshrl.u32 %v15175, 3 (stack45)
        %v15182 = vor.u32 %v15181, %v15180 (stack46)
        %v15183 = vxor.u32 %v15182, %v15178 (stack47)
        %v15186 = vadd.s32 %v15183, %v15178 (stack39)
        %v15188 = vshll.u32 %v15183, 16 (stack44)
        %v15189 = vshrl.u32 %v15183, 16 (stack45)
        %v15190 = vor.u32 %v15189, %v15188 (stack46)
        %v15191 = vxor.u32 %v15190, %v15186 (stack47)
        %v15194 = vadd.s32 %v15191, %v15186 (stack39)
        %v15198 = vadd.s32 %v15194, %v9 (stack39)
        %v15200 = vshll.u32 %v15191, 24 (stack44)
        %v15201 = vshrl.u32 %v15191, 8 (stack45)
        %v15202 = vor.u32 %v15201, %v15200 (stack46)
        %v15203 = vxor.u32 %v15202, %v15194 (stack47)
        %v15206 = vadd.s32 %v15203, %v8 (stack39)
        %v15210 = vadd.s32 4, %v15206 (stack39)
        %v15214 = vadd.s32 %v15210, %v15198 (stack39)
        %v15216 = vshll.u32 %v15210, 13 (stack44)
        %v15217 = vshrl.u32 %v15210, 19 (stack45)
        %v15218 = vor.u32 %v15217, %v15216 (stack46)
        %v15219 = vxor.u32 %v15218, %v15214 (stack47)
        %v15222 = vadd.s32 %v15219, %v15214 (stack39)
        %v15224 = vshll.u32 %v15219, 15 (stack44)
        %v15225 = vshrl.u32 %v15219, 17 (stack45)
        %v15226 = vor.u32 %v15225, %v15224 (stack46)
        %v15227 = vxor.u32 %v15226, %v15222 (stack47)
        %v15230 = vadd.s32 %v15227, %v15222 (stack39)
        %v15232 = vshll.u32 %v15227, 26 (stack44)
        %v15233 = vshrl.u32 %v15227, 6 (stack45)
        %v15234 = vor.u32 %v15233, %v15232 (stack46)
        %v15235 = vxor.u32 %v15234, %v15230 (stack47)
        %v15238 = vadd.s32 %v15235, %v15230 (stack39)
        %v15242 = vadd.s32 %v15238, %v8 (stack39)
        %v15244 = vshll.u32 %v15235, 6 (stack44)
        %v15245 = vshrl.u32 %v15235, 26 (stack45)
        %v15246 = vor.u32 %v15245, %v15244 (stack46)
        %v15247 = vxor.u32 %v15246, %v15238 (stack47)
        %v15250 = vadd.s32 %v15247, %v10 (stack39)
        %v15254 = vadd.s32 5, %v15250 (stack39)
        %v15256 = vxor.u32 %v15254, %v15242 (stack47)
        %v15257 = vand.u32.u8 255, %v15256 (stack48)
        %v15258 = vand.u32 65535, %v15257 (stack49)
        %v15259 = vshrl.u32 %v15258, 1 (stack50)
        %v15260 = vor.u32 16256, %v15259 (stack46)
        %v15261 = vand.u32.u16 65535, %v15260 (stack51)
        %v119822 = vadd.low.f32.bf16 -1.0, %v15261 (stack52)
        %v15270 = vmul.f32 2.0, %v119822 (stack53)
        %v15274 = vadd.f32 -0.99609375, %v15270 (stack52)
        %v15278 = vmax.f32 %v15274, -0.99609375 (stack54)
        %v15280 = vand.u32 2147483647, %v15278 (stack55)
        %vm15283 = vcmp.eq.f32.partialorder %v15280, 1.0 (stack56)
        %v15288 = vmul.f32 inf, %v15278 (stack53)
        %v15290 = vxor.u32 2147483648, %v15278 (stack57)
        %v15293 = vmul.f32 %v15290, %v15278 (stack53)
        %v15295 = vadd.f32 1.0, %v15293 (stack58)
        %v15296 = vlog2.pop %v15295 (stack59)
        %v15297 = vmul.f32 0.6931472, %v15296 (stack60)
        %v15298 = vmul.f32 -0.5, %v15293 (stack61)
        %v15299 = vadd.f32 1.0, %v15298 (stack62)
        %v15300 = vmul.f32 %v15299, %v15293 (stack63)
        %v15301 = vand.u32 2147483647, %v15293 (stack64)
        %vm15302 = vcmp.lt.f32.partialorder %v15301, 0.0004427343 (stack65)
        %v15303 = vsel /*vm=*/%vm15302, /*on_true_vy=*/%v15300, /*on_false_vx=*/%v15297 (stack66)
        %v15304 = vxor.u32 2147483648, %v15303 (stack57)
        %vm15307 = vcmp.lt.f32.partialorder %v15304, 5.0 (stack56)
        %v15312 = vsel /*vm=*/%vm15307, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v15316 = vsel /*vm=*/%vm15307, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v15320 = vsel /*vm=*/%vm15307, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v15324 = vsel /*vm=*/%vm15307, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v15328 = vsel /*vm=*/%vm15307, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v15332 = vsel /*vm=*/%vm15307, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v15336 = vsel /*vm=*/%vm15307, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v15340 = vsel /*vm=*/%vm15307, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v15344 = vsel /*vm=*/%vm15307, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v15348 = vadd.f32 -2.5, %v15304 (stack52)
        %v15350 = vrsqrt.pop %v15304 (stack67)
        %v15351 = vmul.f32 %v15350, %v15304 (stack68)
        %vm15352 = vcmp.eq.f32.partialorder %v15304, inf (stack69)
        %v15353 = vsel /*vm=*/%vm15352, /*on_true_vy=*/%v15304, /*on_false_vx=*/%v15351 (stack70)
        %vm15354 = vcmp.eq.f32.partialorder %v15304, 0.0 (stack71)
        %v15355 = vand.u32 2147483648, %v15304 (stack72)
        %v15356 = vsel /*vm=*/%vm15354, /*on_true_vy=*/%v15355, /*on_false_vx=*/%v15353 (stack73)
        %v15359 = vadd.f32 -3.0, %v15356 (stack52)
        %v15363 = vsel /*vm=*/%vm15307, /*on_true_vy=*/%v15348, /*on_false_vx=*/%v15359 (stack43)
        %v15367 = vmul.f32 %v15363, %v15344 (stack53)
        %v15371 = vadd.f32 %v15367, %v15340 (stack52)
        %v15375 = vmul.f32 %v15371, %v15363 (stack53)
        %v15379 = vadd.f32 %v15375, %v15336 (stack52)
        %v15383 = vmul.f32 %v15379, %v15363 (stack53)
        %v15387 = vadd.f32 %v15383, %v15332 (stack52)
        %v15391 = vmul.f32 %v15387, %v15363 (stack53)
        %v15395 = vadd.f32 %v15391, %v15328 (stack52)
        %v15399 = vmul.f32 %v15395, %v15363 (stack53)
        %v15403 = vadd.f32 %v15399, %v15324 (stack52)
        %v15407 = vmul.f32 %v15403, %v15363 (stack53)
        %v15411 = vadd.f32 %v15407, %v15320 (stack52)
        %v15415 = vmul.f32 %v15411, %v15363 (stack53)
        %v15419 = vadd.f32 %v15415, %v15316 (stack52)
        %v15423 = vmul.f32 %v15419, %v15363 (stack53)
        %v15427 = vadd.f32 %v15423, %v15312 (stack52)
        %v15431 = vmul.f32 %v15427, %v15278 (stack53)
        %v15435 = vsel /*vm=*/%vm15283, /*on_true_vy=*/%v15288, /*on_false_vx=*/%v15431 (stack43)
        %v15439 = vmul.f32 1.4140625, %v15435 (stack53)
        %v15442 = vpack.c.bf16 0.0, %v15439 (stack74)
        %119823 = vst [vmem:[%s280 + $0x38c] sm:$0xf] /*vst_source=*/%v15442 (stack75)
        %s15444 = sadd.s32 32, %s120390 (stack76)
        %s15445 = sshrl.u32 %s15444, 10 (stack23)
        %p119824 = scmp.gt.s32.totalorder %s15445, 1 (stack24)
        %s15447 = scalar_select /*predicate=*/%p119824, /*on_true=*/1, /*on_false=*/%s15445 (stack25)
        %s15448 = sand.u32 1023, %s15444 /* smod.u32 w/div 1024 */ (stack26)
        %s15449 = sshrl.u32 %s15448, 7 (stack27)
        %s15450 = sand.u32 127, %s15448 /* smod.u32 w/div 128 */ (stack28)
        %s119825 = sshll.u32 %s15447, 3 (stack29)
        %s15452 = scalar_lea.vmem %s3, %s119825 (stack30)
        %s15454 = scalar_lea.vmem %s15452, %s15449 (stack31)
        %v15455 = vld [vmem:[%s15454] ss:$0 sm:$0xff] (stack32)
        %s15456 = sand.u32 255, %s15450 (stack33)
        %s15458 = sor.u32 256, %s15456 (stack34)
        %15459 = vbcast.lane.b32.xlu0 %v15455, %s15458 (stack35)
        %v15460 = vpop.permute.xlu0 %15459 (stack36)
        %s15469 = scalar_lea.vmem %s5, %s119825 (stack30)
        %s15471 = scalar_lea.vmem %s15469, %s15449 (stack31)
        %v15472 = vld [vmem:[%s15471] ss:$0 sm:$0xff] (stack32)
        %15476 = vbcast.lane.b32.xlu0 %v15472, %s15458 (stack35)
        %v15477 = vpop.permute.xlu0 %15476 (stack36)
        %v15480 = vadd.s32 %v15477, %v408 (stack39)
        %v15490 = vadd.s32 %v15480, %v415 (stack39)
        %vm15494 = vcmp.lt.u32.totalorder %v15490, %v15480 (stack42)
        %vm15499 = vcmp.lt.u32.totalorder %v15480, %v408 (stack42)
        %v15504 = vadd.s32 %v15460, %v380 (stack39)
        %v15508 = vadd.s32 1, %v15504 (stack39)
        %v15512 = vsel /*vm=*/%vm15499, /*on_true_vy=*/%v15508, /*on_false_vx=*/%v15504 (stack43)
        %v15516 = vadd.s32 1, %v15512 (stack39)
        %v15520 = vsel /*vm=*/%vm15494, /*on_true_vy=*/%v15516, /*on_false_vx=*/%v15512 (stack43)
        %v15525 = vadd.s32 %v15520, %v10 (stack39)
        %v15529 = vadd.s32 %v15490, %v9 (stack39)
        %v15533 = vadd.s32 %v15529, %v15525 (stack39)
        %v15535 = vshll.u32 %v15529, 13 (stack44)
        %v15536 = vshrl.u32 %v15529, 19 (stack45)
        %v15537 = vor.u32 %v15536, %v15535 (stack46)
        %v15538 = vxor.u32 %v15537, %v15533 (stack47)
        %v15541 = vadd.s32 %v15538, %v15533 (stack39)
        %v15543 = vshll.u32 %v15538, 15 (stack44)
        %v15544 = vshrl.u32 %v15538, 17 (stack45)
        %v15545 = vor.u32 %v15544, %v15543 (stack46)
        %v15546 = vxor.u32 %v15545, %v15541 (stack47)
        %v15549 = vadd.s32 %v15546, %v15541 (stack39)
        %v15551 = vshll.u32 %v15546, 26 (stack44)
        %v15552 = vshrl.u32 %v15546, 6 (stack45)
        %v15553 = vor.u32 %v15552, %v15551 (stack46)
        %v15554 = vxor.u32 %v15553, %v15549 (stack47)
        %v15557 = vadd.s32 %v15554, %v15549 (stack39)
        %v15561 = vadd.s32 %v15557, %v9 (stack39)
        %v15563 = vshll.u32 %v15554, 6 (stack44)
        %v15564 = vshrl.u32 %v15554, 26 (stack45)
        %v15565 = vor.u32 %v15564, %v15563 (stack46)
        %v15566 = vxor.u32 %v15565, %v15557 (stack47)
        %v15569 = vadd.s32 %v15566, %v8 (stack39)
        %v15573 = vadd.s32 1, %v15569 (stack39)
        %v15577 = vadd.s32 %v15573, %v15561 (stack39)
        %v15579 = vshll.u32 %v15573, 17 (stack44)
        %v15580 = vshrl.u32 %v15573, 15 (stack45)
        %v15581 = vor.u32 %v15580, %v15579 (stack46)
        %v15582 = vxor.u32 %v15581, %v15577 (stack47)
        %v15585 = vadd.s32 %v15582, %v15577 (stack39)
        %v15587 = vshll.u32 %v15582, 29 (stack44)
        %v15588 = vshrl.u32 %v15582, 3 (stack45)
        %v15589 = vor.u32 %v15588, %v15587 (stack46)
        %v15590 = vxor.u32 %v15589, %v15585 (stack47)
        %v15593 = vadd.s32 %v15590, %v15585 (stack39)
        %v15595 = vshll.u32 %v15590, 16 (stack44)
        %v15596 = vshrl.u32 %v15590, 16 (stack45)
        %v15597 = vor.u32 %v15596, %v15595 (stack46)
        %v15598 = vxor.u32 %v15597, %v15593 (stack47)
        %v15601 = vadd.s32 %v15598, %v15593 (stack39)
        %v15605 = vadd.s32 %v15601, %v8 (stack39)
        %v15607 = vshll.u32 %v15598, 24 (stack44)
        %v15608 = vshrl.u32 %v15598, 8 (stack45)
        %v15609 = vor.u32 %v15608, %v15607 (stack46)
        %v15610 = vxor.u32 %v15609, %v15601 (stack47)
        %v15613 = vadd.s32 %v15610, %v10 (stack39)
        %v15617 = vadd.s32 2, %v15613 (stack39)
        %v15621 = vadd.s32 %v15617, %v15605 (stack39)
        %v15623 = vshll.u32 %v15617, 13 (stack44)
        %v15624 = vshrl.u32 %v15617, 19 (stack45)
        %v15625 = vor.u32 %v15624, %v15623 (stack46)
        %v15626 = vxor.u32 %v15625, %v15621 (stack47)
        %v15629 = vadd.s32 %v15626, %v15621 (stack39)
        %v15631 = vshll.u32 %v15626, 15 (stack44)
        %v15632 = vshrl.u32 %v15626, 17 (stack45)
        %v15633 = vor.u32 %v15632, %v15631 (stack46)
        %v15634 = vxor.u32 %v15633, %v15629 (stack47)
        %v15637 = vadd.s32 %v15634, %v15629 (stack39)
        %v15639 = vshll.u32 %v15634, 26 (stack44)
        %v15640 = vshrl.u32 %v15634, 6 (stack45)
        %v15641 = vor.u32 %v15640, %v15639 (stack46)
        %v15642 = vxor.u32 %v15641, %v15637 (stack47)
        %v15645 = vadd.s32 %v15642, %v15637 (stack39)
        %v15649 = vadd.s32 %v15645, %v10 (stack39)
        %v15651 = vshll.u32 %v15642, 6 (stack44)
        %v15652 = vshrl.u32 %v15642, 26 (stack45)
        %v15653 = vor.u32 %v15652, %v15651 (stack46)
        %v15654 = vxor.u32 %v15653, %v15645 (stack47)
        %v15657 = vadd.s32 %v15654, %v9 (stack39)
        %v15661 = vadd.s32 3, %v15657 (stack39)
        %v15665 = vadd.s32 %v15661, %v15649 (stack39)
        %v15667 = vshll.u32 %v15661, 17 (stack44)
        %v15668 = vshrl.u32 %v15661, 15 (stack45)
        %v15669 = vor.u32 %v15668, %v15667 (stack46)
        %v15670 = vxor.u32 %v15669, %v15665 (stack47)
        %v15673 = vadd.s32 %v15670, %v15665 (stack39)
        %v15675 = vshll.u32 %v15670, 29 (stack44)
        %v15676 = vshrl.u32 %v15670, 3 (stack45)
        %v15677 = vor.u32 %v15676, %v15675 (stack46)
        %v15678 = vxor.u32 %v15677, %v15673 (stack47)
        %v15681 = vadd.s32 %v15678, %v15673 (stack39)
        %v15683 = vshll.u32 %v15678, 16 (stack44)
        %v15684 = vshrl.u32 %v15678, 16 (stack45)
        %v15685 = vor.u32 %v15684, %v15683 (stack46)
        %v15686 = vxor.u32 %v15685, %v15681 (stack47)
        %v15689 = vadd.s32 %v15686, %v15681 (stack39)
        %v15693 = vadd.s32 %v15689, %v9 (stack39)
        %v15695 = vshll.u32 %v15686, 24 (stack44)
        %v15696 = vshrl.u32 %v15686, 8 (stack45)
        %v15697 = vor.u32 %v15696, %v15695 (stack46)
        %v15698 = vxor.u32 %v15697, %v15689 (stack47)
        %v15701 = vadd.s32 %v15698, %v8 (stack39)
        %v15705 = vadd.s32 4, %v15701 (stack39)
        %v15709 = vadd.s32 %v15705, %v15693 (stack39)
        %v15711 = vshll.u32 %v15705, 13 (stack44)
        %v15712 = vshrl.u32 %v15705, 19 (stack45)
        %v15713 = vor.u32 %v15712, %v15711 (stack46)
        %v15714 = vxor.u32 %v15713, %v15709 (stack47)
        %v15717 = vadd.s32 %v15714, %v15709 (stack39)
        %v15719 = vshll.u32 %v15714, 15 (stack44)
        %v15720 = vshrl.u32 %v15714, 17 (stack45)
        %v15721 = vor.u32 %v15720, %v15719 (stack46)
        %v15722 = vxor.u32 %v15721, %v15717 (stack47)
        %v15725 = vadd.s32 %v15722, %v15717 (stack39)
        %v15727 = vshll.u32 %v15722, 26 (stack44)
        %v15728 = vshrl.u32 %v15722, 6 (stack45)
        %v15729 = vor.u32 %v15728, %v15727 (stack46)
        %v15730 = vxor.u32 %v15729, %v15725 (stack47)
        %v15733 = vadd.s32 %v15730, %v15725 (stack39)
        %v15737 = vadd.s32 %v15733, %v8 (stack39)
        %v15739 = vshll.u32 %v15730, 6 (stack44)
        %v15740 = vshrl.u32 %v15730, 26 (stack45)
        %v15741 = vor.u32 %v15740, %v15739 (stack46)
        %v15742 = vxor.u32 %v15741, %v15733 (stack47)
        %v15745 = vadd.s32 %v15742, %v10 (stack39)
        %v15749 = vadd.s32 5, %v15745 (stack39)
        %v15751 = vxor.u32 %v15749, %v15737 (stack47)
        %v15752 = vand.u32.u8 255, %v15751 (stack48)
        %v15753 = vand.u32 65535, %v15752 (stack49)
        %v15754 = vshrl.u32 %v15753, 1 (stack50)
        %v15755 = vor.u32 16256, %v15754 (stack46)
        %v15756 = vand.u32.u16 65535, %v15755 (stack51)
        %v119828 = vadd.low.f32.bf16 -1.0, %v15756 (stack52)
        %v15765 = vmul.f32 2.0, %v119828 (stack53)
        %v15769 = vadd.f32 -0.99609375, %v15765 (stack52)
        %v15773 = vmax.f32 %v15769, -0.99609375 (stack54)
        %v15775 = vand.u32 2147483647, %v15773 (stack55)
        %vm15778 = vcmp.eq.f32.partialorder %v15775, 1.0 (stack56)
        %v15783 = vmul.f32 inf, %v15773 (stack53)
        %v15785 = vxor.u32 2147483648, %v15773 (stack57)
        %v15788 = vmul.f32 %v15785, %v15773 (stack53)
        %v15790 = vadd.f32 1.0, %v15788 (stack58)
        %v15791 = vlog2.pop %v15790 (stack59)
        %v15792 = vmul.f32 0.6931472, %v15791 (stack60)
        %v15793 = vmul.f32 -0.5, %v15788 (stack61)
        %v15794 = vadd.f32 1.0, %v15793 (stack62)
        %v15795 = vmul.f32 %v15794, %v15788 (stack63)
        %v15796 = vand.u32 2147483647, %v15788 (stack64)
        %vm15797 = vcmp.lt.f32.partialorder %v15796, 0.0004427343 (stack65)
        %v15798 = vsel /*vm=*/%vm15797, /*on_true_vy=*/%v15795, /*on_false_vx=*/%v15792 (stack66)
        %v15799 = vxor.u32 2147483648, %v15798 (stack57)
        %vm15802 = vcmp.lt.f32.partialorder %v15799, 5.0 (stack56)
        %v15807 = vsel /*vm=*/%vm15802, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v15811 = vsel /*vm=*/%vm15802, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v15815 = vsel /*vm=*/%vm15802, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v15819 = vsel /*vm=*/%vm15802, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v15823 = vsel /*vm=*/%vm15802, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v15827 = vsel /*vm=*/%vm15802, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v15831 = vsel /*vm=*/%vm15802, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v15835 = vsel /*vm=*/%vm15802, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v15839 = vsel /*vm=*/%vm15802, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v15843 = vadd.f32 -2.5, %v15799 (stack52)
        %v15845 = vrsqrt.pop %v15799 (stack67)
        %v15846 = vmul.f32 %v15845, %v15799 (stack68)
        %vm15847 = vcmp.eq.f32.partialorder %v15799, inf (stack69)
        %v15848 = vsel /*vm=*/%vm15847, /*on_true_vy=*/%v15799, /*on_false_vx=*/%v15846 (stack70)
        %vm15849 = vcmp.eq.f32.partialorder %v15799, 0.0 (stack71)
        %v15850 = vand.u32 2147483648, %v15799 (stack72)
        %v15851 = vsel /*vm=*/%vm15849, /*on_true_vy=*/%v15850, /*on_false_vx=*/%v15848 (stack73)
        %v15854 = vadd.f32 -3.0, %v15851 (stack52)
        %v15858 = vsel /*vm=*/%vm15802, /*on_true_vy=*/%v15843, /*on_false_vx=*/%v15854 (stack43)
        %v15862 = vmul.f32 %v15858, %v15839 (stack53)
        %v15866 = vadd.f32 %v15862, %v15835 (stack52)
        %v15870 = vmul.f32 %v15866, %v15858 (stack53)
        %v15874 = vadd.f32 %v15870, %v15831 (stack52)
        %v15878 = vmul.f32 %v15874, %v15858 (stack53)
        %v15882 = vadd.f32 %v15878, %v15827 (stack52)
        %v15886 = vmul.f32 %v15882, %v15858 (stack53)
        %v15890 = vadd.f32 %v15886, %v15823 (stack52)
        %v15894 = vmul.f32 %v15890, %v15858 (stack53)
        %v15898 = vadd.f32 %v15894, %v15819 (stack52)
        %v15902 = vmul.f32 %v15898, %v15858 (stack53)
        %v15906 = vadd.f32 %v15902, %v15815 (stack52)
        %v15910 = vmul.f32 %v15906, %v15858 (stack53)
        %v15914 = vadd.f32 %v15910, %v15811 (stack52)
        %v15918 = vmul.f32 %v15914, %v15858 (stack53)
        %v15922 = vadd.f32 %v15918, %v15807 (stack52)
        %v15926 = vmul.f32 %v15922, %v15773 (stack53)
        %v15930 = vsel /*vm=*/%vm15778, /*on_true_vy=*/%v15783, /*on_false_vx=*/%v15926 (stack43)
        %v15934 = vmul.f32 1.4140625, %v15930 (stack53)
        %v15937 = vpack.c.bf16 0.0, %v15934 (stack74)
        %119829 = vst [vmem:[%s280 + $0x10] sm:$0xf] /*vst_source=*/%v15937 (stack75)
        %v15941 = vadd.s32 %v15477, %v894 (stack39)
        %v15951 = vadd.s32 %v15941, %v415 (stack39)
        %vm15955 = vcmp.lt.u32.totalorder %v15951, %v15941 (stack42)
        %vm15960 = vcmp.lt.u32.totalorder %v15941, %v894 (stack42)
        %v15965 = vadd.s32 %v15460, %v881 (stack39)
        %v15969 = vadd.s32 1, %v15965 (stack39)
        %v15973 = vsel /*vm=*/%vm15960, /*on_true_vy=*/%v15969, /*on_false_vx=*/%v15965 (stack43)
        %v15977 = vadd.s32 1, %v15973 (stack39)
        %v15981 = vsel /*vm=*/%vm15955, /*on_true_vy=*/%v15977, /*on_false_vx=*/%v15973 (stack43)
        %v15986 = vadd.s32 %v15981, %v10 (stack39)
        %v15990 = vadd.s32 %v15951, %v9 (stack39)
        %v15994 = vadd.s32 %v15990, %v15986 (stack39)
        %v15996 = vshll.u32 %v15990, 13 (stack44)
        %v15997 = vshrl.u32 %v15990, 19 (stack45)
        %v15998 = vor.u32 %v15997, %v15996 (stack46)
        %v15999 = vxor.u32 %v15998, %v15994 (stack47)
        %v16002 = vadd.s32 %v15999, %v15994 (stack39)
        %v16004 = vshll.u32 %v15999, 15 (stack44)
        %v16005 = vshrl.u32 %v15999, 17 (stack45)
        %v16006 = vor.u32 %v16005, %v16004 (stack46)
        %v16007 = vxor.u32 %v16006, %v16002 (stack47)
        %v16010 = vadd.s32 %v16007, %v16002 (stack39)
        %v16012 = vshll.u32 %v16007, 26 (stack44)
        %v16013 = vshrl.u32 %v16007, 6 (stack45)
        %v16014 = vor.u32 %v16013, %v16012 (stack46)
        %v16015 = vxor.u32 %v16014, %v16010 (stack47)
        %v16018 = vadd.s32 %v16015, %v16010 (stack39)
        %v16022 = vadd.s32 %v16018, %v9 (stack39)
        %v16024 = vshll.u32 %v16015, 6 (stack44)
        %v16025 = vshrl.u32 %v16015, 26 (stack45)
        %v16026 = vor.u32 %v16025, %v16024 (stack46)
        %v16027 = vxor.u32 %v16026, %v16018 (stack47)
        %v16030 = vadd.s32 %v16027, %v8 (stack39)
        %v16034 = vadd.s32 1, %v16030 (stack39)
        %v16038 = vadd.s32 %v16034, %v16022 (stack39)
        %v16040 = vshll.u32 %v16034, 17 (stack44)
        %v16041 = vshrl.u32 %v16034, 15 (stack45)
        %v16042 = vor.u32 %v16041, %v16040 (stack46)
        %v16043 = vxor.u32 %v16042, %v16038 (stack47)
        %v16046 = vadd.s32 %v16043, %v16038 (stack39)
        %v16048 = vshll.u32 %v16043, 29 (stack44)
        %v16049 = vshrl.u32 %v16043, 3 (stack45)
        %v16050 = vor.u32 %v16049, %v16048 (stack46)
        %v16051 = vxor.u32 %v16050, %v16046 (stack47)
        %v16054 = vadd.s32 %v16051, %v16046 (stack39)
        %v16056 = vshll.u32 %v16051, 16 (stack44)
        %v16057 = vshrl.u32 %v16051, 16 (stack45)
        %v16058 = vor.u32 %v16057, %v16056 (stack46)
        %v16059 = vxor.u32 %v16058, %v16054 (stack47)
        %v16062 = vadd.s32 %v16059, %v16054 (stack39)
        %v16066 = vadd.s32 %v16062, %v8 (stack39)
        %v16068 = vshll.u32 %v16059, 24 (stack44)
        %v16069 = vshrl.u32 %v16059, 8 (stack45)
        %v16070 = vor.u32 %v16069, %v16068 (stack46)
        %v16071 = vxor.u32 %v16070, %v16062 (stack47)
        %v16074 = vadd.s32 %v16071, %v10 (stack39)
        %v16078 = vadd.s32 2, %v16074 (stack39)
        %v16082 = vadd.s32 %v16078, %v16066 (stack39)
        %v16084 = vshll.u32 %v16078, 13 (stack44)
        %v16085 = vshrl.u32 %v16078, 19 (stack45)
        %v16086 = vor.u32 %v16085, %v16084 (stack46)
        %v16087 = vxor.u32 %v16086, %v16082 (stack47)
        %v16090 = vadd.s32 %v16087, %v16082 (stack39)
        %v16092 = vshll.u32 %v16087, 15 (stack44)
        %v16093 = vshrl.u32 %v16087, 17 (stack45)
        %v16094 = vor.u32 %v16093, %v16092 (stack46)
        %v16095 = vxor.u32 %v16094, %v16090 (stack47)
        %v16098 = vadd.s32 %v16095, %v16090 (stack39)
        %v16100 = vshll.u32 %v16095, 26 (stack44)
        %v16101 = vshrl.u32 %v16095, 6 (stack45)
        %v16102 = vor.u32 %v16101, %v16100 (stack46)
        %v16103 = vxor.u32 %v16102, %v16098 (stack47)
        %v16106 = vadd.s32 %v16103, %v16098 (stack39)
        %v16110 = vadd.s32 %v16106, %v10 (stack39)
        %v16112 = vshll.u32 %v16103, 6 (stack44)
        %v16113 = vshrl.u32 %v16103, 26 (stack45)
        %v16114 = vor.u32 %v16113, %v16112 (stack46)
        %v16115 = vxor.u32 %v16114, %v16106 (stack47)
        %v16118 = vadd.s32 %v16115, %v9 (stack39)
        %v16122 = vadd.s32 3, %v16118 (stack39)
        %v16126 = vadd.s32 %v16122, %v16110 (stack39)
        %v16128 = vshll.u32 %v16122, 17 (stack44)
        %v16129 = vshrl.u32 %v16122, 15 (stack45)
        %v16130 = vor.u32 %v16129, %v16128 (stack46)
        %v16131 = vxor.u32 %v16130, %v16126 (stack47)
        %v16134 = vadd.s32 %v16131, %v16126 (stack39)
        %v16136 = vshll.u32 %v16131, 29 (stack44)
        %v16137 = vshrl.u32 %v16131, 3 (stack45)
        %v16138 = vor.u32 %v16137, %v16136 (stack46)
        %v16139 = vxor.u32 %v16138, %v16134 (stack47)
        %v16142 = vadd.s32 %v16139, %v16134 (stack39)
        %v16144 = vshll.u32 %v16139, 16 (stack44)
        %v16145 = vshrl.u32 %v16139, 16 (stack45)
        %v16146 = vor.u32 %v16145, %v16144 (stack46)
        %v16147 = vxor.u32 %v16146, %v16142 (stack47)
        %v16150 = vadd.s32 %v16147, %v16142 (stack39)
        %v16154 = vadd.s32 %v16150, %v9 (stack39)
        %v16156 = vshll.u32 %v16147, 24 (stack44)
        %v16157 = vshrl.u32 %v16147, 8 (stack45)
        %v16158 = vor.u32 %v16157, %v16156 (stack46)
        %v16159 = vxor.u32 %v16158, %v16150 (stack47)
        %v16162 = vadd.s32 %v16159, %v8 (stack39)
        %v16166 = vadd.s32 4, %v16162 (stack39)
        %v16170 = vadd.s32 %v16166, %v16154 (stack39)
        %v16172 = vshll.u32 %v16166, 13 (stack44)
        %v16173 = vshrl.u32 %v16166, 19 (stack45)
        %v16174 = vor.u32 %v16173, %v16172 (stack46)
        %v16175 = vxor.u32 %v16174, %v16170 (stack47)
        %v16178 = vadd.s32 %v16175, %v16170 (stack39)
        %v16180 = vshll.u32 %v16175, 15 (stack44)
        %v16181 = vshrl.u32 %v16175, 17 (stack45)
        %v16182 = vor.u32 %v16181, %v16180 (stack46)
        %v16183 = vxor.u32 %v16182, %v16178 (stack47)
        %v16186 = vadd.s32 %v16183, %v16178 (stack39)
        %v16188 = vshll.u32 %v16183, 26 (stack44)
        %v16189 = vshrl.u32 %v16183, 6 (stack45)
        %v16190 = vor.u32 %v16189, %v16188 (stack46)
        %v16191 = vxor.u32 %v16190, %v16186 (stack47)
        %v16194 = vadd.s32 %v16191, %v16186 (stack39)
        %v16198 = vadd.s32 %v16194, %v8 (stack39)
        %v16200 = vshll.u32 %v16191, 6 (stack44)
        %v16201 = vshrl.u32 %v16191, 26 (stack45)
        %v16202 = vor.u32 %v16201, %v16200 (stack46)
        %v16203 = vxor.u32 %v16202, %v16194 (stack47)
        %v16206 = vadd.s32 %v16203, %v10 (stack39)
        %v16210 = vadd.s32 5, %v16206 (stack39)
        %v16212 = vxor.u32 %v16210, %v16198 (stack47)
        %v16213 = vand.u32.u8 255, %v16212 (stack48)
        %v16214 = vand.u32 65535, %v16213 (stack49)
        %v16215 = vshrl.u32 %v16214, 1 (stack50)
        %v16216 = vor.u32 16256, %v16215 (stack46)
        %v16217 = vand.u32.u16 65535, %v16216 (stack51)
        %v119830 = vadd.low.f32.bf16 -1.0, %v16217 (stack52)
        %v16226 = vmul.f32 2.0, %v119830 (stack53)
        %v16230 = vadd.f32 -0.99609375, %v16226 (stack52)
        %v16234 = vmax.f32 %v16230, -0.99609375 (stack54)
        %v16236 = vand.u32 2147483647, %v16234 (stack55)
        %vm16239 = vcmp.eq.f32.partialorder %v16236, 1.0 (stack56)
        %v16244 = vmul.f32 inf, %v16234 (stack53)
        %v16246 = vxor.u32 2147483648, %v16234 (stack57)
        %v16249 = vmul.f32 %v16246, %v16234 (stack53)
        %v16251 = vadd.f32 1.0, %v16249 (stack58)
        %v16252 = vlog2.pop %v16251 (stack59)
        %v16253 = vmul.f32 0.6931472, %v16252 (stack60)
        %v16254 = vmul.f32 -0.5, %v16249 (stack61)
        %v16255 = vadd.f32 1.0, %v16254 (stack62)
        %v16256 = vmul.f32 %v16255, %v16249 (stack63)
        %v16257 = vand.u32 2147483647, %v16249 (stack64)
        %vm16258 = vcmp.lt.f32.partialorder %v16257, 0.0004427343 (stack65)
        %v16259 = vsel /*vm=*/%vm16258, /*on_true_vy=*/%v16256, /*on_false_vx=*/%v16253 (stack66)
        %v16260 = vxor.u32 2147483648, %v16259 (stack57)
        %vm16263 = vcmp.lt.f32.partialorder %v16260, 5.0 (stack56)
        %v16268 = vsel /*vm=*/%vm16263, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v16272 = vsel /*vm=*/%vm16263, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v16276 = vsel /*vm=*/%vm16263, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v16280 = vsel /*vm=*/%vm16263, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v16284 = vsel /*vm=*/%vm16263, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v16288 = vsel /*vm=*/%vm16263, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v16292 = vsel /*vm=*/%vm16263, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v16296 = vsel /*vm=*/%vm16263, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v16300 = vsel /*vm=*/%vm16263, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v16304 = vadd.f32 -2.5, %v16260 (stack52)
        %v16306 = vrsqrt.pop %v16260 (stack67)
        %v16307 = vmul.f32 %v16306, %v16260 (stack68)
        %vm16308 = vcmp.eq.f32.partialorder %v16260, inf (stack69)
        %v16309 = vsel /*vm=*/%vm16308, /*on_true_vy=*/%v16260, /*on_false_vx=*/%v16307 (stack70)
        %vm16310 = vcmp.eq.f32.partialorder %v16260, 0.0 (stack71)
        %v16311 = vand.u32 2147483648, %v16260 (stack72)
        %v16312 = vsel /*vm=*/%vm16310, /*on_true_vy=*/%v16311, /*on_false_vx=*/%v16309 (stack73)
        %v16315 = vadd.f32 -3.0, %v16312 (stack52)
        %v16319 = vsel /*vm=*/%vm16263, /*on_true_vy=*/%v16304, /*on_false_vx=*/%v16315 (stack43)
        %v16323 = vmul.f32 %v16319, %v16300 (stack53)
        %v16327 = vadd.f32 %v16323, %v16296 (stack52)
        %v16331 = vmul.f32 %v16327, %v16319 (stack53)
        %v16335 = vadd.f32 %v16331, %v16292 (stack52)
        %v16339 = vmul.f32 %v16335, %v16319 (stack53)
        %v16343 = vadd.f32 %v16339, %v16288 (stack52)
        %v16347 = vmul.f32 %v16343, %v16319 (stack53)
        %v16351 = vadd.f32 %v16347, %v16284 (stack52)
        %v16355 = vmul.f32 %v16351, %v16319 (stack53)
        %v16359 = vadd.f32 %v16355, %v16280 (stack52)
        %v16363 = vmul.f32 %v16359, %v16319 (stack53)
        %v16367 = vadd.f32 %v16363, %v16276 (stack52)
        %v16371 = vmul.f32 %v16367, %v16319 (stack53)
        %v16375 = vadd.f32 %v16371, %v16272 (stack52)
        %v16379 = vmul.f32 %v16375, %v16319 (stack53)
        %v16383 = vadd.f32 %v16379, %v16268 (stack52)
        %v16387 = vmul.f32 %v16383, %v16234 (stack53)
        %v16391 = vsel /*vm=*/%vm16239, /*on_true_vy=*/%v16244, /*on_false_vx=*/%v16387 (stack43)
        %v16395 = vmul.f32 1.4140625, %v16391 (stack53)
        %v16398 = vpack.c.bf16 0.0, %v16395 (stack74)
        %119831 = vst [vmem:[%s280 + $0x90] sm:$0xf] /*vst_source=*/%v16398 (stack75)
        %v16402 = vadd.s32 %v15477, %v1381 (stack39)
        %v16412 = vadd.s32 %v16402, %v415 (stack39)
        %vm16416 = vcmp.lt.u32.totalorder %v16412, %v16402 (stack42)
        %vm16421 = vcmp.lt.u32.totalorder %v16402, %v1381 (stack42)
        %v16426 = vadd.s32 %v15460, %v1368 (stack39)
        %v16430 = vadd.s32 1, %v16426 (stack39)
        %v16434 = vsel /*vm=*/%vm16421, /*on_true_vy=*/%v16430, /*on_false_vx=*/%v16426 (stack43)
        %v16438 = vadd.s32 1, %v16434 (stack39)
        %v16442 = vsel /*vm=*/%vm16416, /*on_true_vy=*/%v16438, /*on_false_vx=*/%v16434 (stack43)
        %v16447 = vadd.s32 %v16442, %v10 (stack39)
        %v16451 = vadd.s32 %v16412, %v9 (stack39)
        %v16455 = vadd.s32 %v16451, %v16447 (stack39)
        %v16457 = vshll.u32 %v16451, 13 (stack44)
        %v16458 = vshrl.u32 %v16451, 19 (stack45)
        %v16459 = vor.u32 %v16458, %v16457 (stack46)
        %v16460 = vxor.u32 %v16459, %v16455 (stack47)
        %v16463 = vadd.s32 %v16460, %v16455 (stack39)
        %v16465 = vshll.u32 %v16460, 15 (stack44)
        %v16466 = vshrl.u32 %v16460, 17 (stack45)
        %v16467 = vor.u32 %v16466, %v16465 (stack46)
        %v16468 = vxor.u32 %v16467, %v16463 (stack47)
        %v16471 = vadd.s32 %v16468, %v16463 (stack39)
        %v16473 = vshll.u32 %v16468, 26 (stack44)
        %v16474 = vshrl.u32 %v16468, 6 (stack45)
        %v16475 = vor.u32 %v16474, %v16473 (stack46)
        %v16476 = vxor.u32 %v16475, %v16471 (stack47)
        %v16479 = vadd.s32 %v16476, %v16471 (stack39)
        %v16483 = vadd.s32 %v16479, %v9 (stack39)
        %v16485 = vshll.u32 %v16476, 6 (stack44)
        %v16486 = vshrl.u32 %v16476, 26 (stack45)
        %v16487 = vor.u32 %v16486, %v16485 (stack46)
        %v16488 = vxor.u32 %v16487, %v16479 (stack47)
        %v16491 = vadd.s32 %v16488, %v8 (stack39)
        %v16495 = vadd.s32 1, %v16491 (stack39)
        %v16499 = vadd.s32 %v16495, %v16483 (stack39)
        %v16501 = vshll.u32 %v16495, 17 (stack44)
        %v16502 = vshrl.u32 %v16495, 15 (stack45)
        %v16503 = vor.u32 %v16502, %v16501 (stack46)
        %v16504 = vxor.u32 %v16503, %v16499 (stack47)
        %v16507 = vadd.s32 %v16504, %v16499 (stack39)
        %v16509 = vshll.u32 %v16504, 29 (stack44)
        %v16510 = vshrl.u32 %v16504, 3 (stack45)
        %v16511 = vor.u32 %v16510, %v16509 (stack46)
        %v16512 = vxor.u32 %v16511, %v16507 (stack47)
        %v16515 = vadd.s32 %v16512, %v16507 (stack39)
        %v16517 = vshll.u32 %v16512, 16 (stack44)
        %v16518 = vshrl.u32 %v16512, 16 (stack45)
        %v16519 = vor.u32 %v16518, %v16517 (stack46)
        %v16520 = vxor.u32 %v16519, %v16515 (stack47)
        %v16523 = vadd.s32 %v16520, %v16515 (stack39)
        %v16527 = vadd.s32 %v16523, %v8 (stack39)
        %v16529 = vshll.u32 %v16520, 24 (stack44)
        %v16530 = vshrl.u32 %v16520, 8 (stack45)
        %v16531 = vor.u32 %v16530, %v16529 (stack46)
        %v16532 = vxor.u32 %v16531, %v16523 (stack47)
        %v16535 = vadd.s32 %v16532, %v10 (stack39)
        %v16539 = vadd.s32 2, %v16535 (stack39)
        %v16543 = vadd.s32 %v16539, %v16527 (stack39)
        %v16545 = vshll.u32 %v16539, 13 (stack44)
        %v16546 = vshrl.u32 %v16539, 19 (stack45)
        %v16547 = vor.u32 %v16546, %v16545 (stack46)
        %v16548 = vxor.u32 %v16547, %v16543 (stack47)
        %v16551 = vadd.s32 %v16548, %v16543 (stack39)
        %v16553 = vshll.u32 %v16548, 15 (stack44)
        %v16554 = vshrl.u32 %v16548, 17 (stack45)
        %v16555 = vor.u32 %v16554, %v16553 (stack46)
        %v16556 = vxor.u32 %v16555, %v16551 (stack47)
        %v16559 = vadd.s32 %v16556, %v16551 (stack39)
        %v16561 = vshll.u32 %v16556, 26 (stack44)
        %v16562 = vshrl.u32 %v16556, 6 (stack45)
        %v16563 = vor.u32 %v16562, %v16561 (stack46)
        %v16564 = vxor.u32 %v16563, %v16559 (stack47)
        %v16567 = vadd.s32 %v16564, %v16559 (stack39)
        %v16571 = vadd.s32 %v16567, %v10 (stack39)
        %v16573 = vshll.u32 %v16564, 6 (stack44)
        %v16574 = vshrl.u32 %v16564, 26 (stack45)
        %v16575 = vor.u32 %v16574, %v16573 (stack46)
        %v16576 = vxor.u32 %v16575, %v16567 (stack47)
        %v16579 = vadd.s32 %v16576, %v9 (stack39)
        %v16583 = vadd.s32 3, %v16579 (stack39)
        %v16587 = vadd.s32 %v16583, %v16571 (stack39)
        %v16589 = vshll.u32 %v16583, 17 (stack44)
        %v16590 = vshrl.u32 %v16583, 15 (stack45)
        %v16591 = vor.u32 %v16590, %v16589 (stack46)
        %v16592 = vxor.u32 %v16591, %v16587 (stack47)
        %v16595 = vadd.s32 %v16592, %v16587 (stack39)
        %v16597 = vshll.u32 %v16592, 29 (stack44)
        %v16598 = vshrl.u32 %v16592, 3 (stack45)
        %v16599 = vor.u32 %v16598, %v16597 (stack46)
        %v16600 = vxor.u32 %v16599, %v16595 (stack47)
        %v16603 = vadd.s32 %v16600, %v16595 (stack39)
        %v16605 = vshll.u32 %v16600, 16 (stack44)
        %v16606 = vshrl.u32 %v16600, 16 (stack45)
        %v16607 = vor.u32 %v16606, %v16605 (stack46)
        %v16608 = vxor.u32 %v16607, %v16603 (stack47)
        %v16611 = vadd.s32 %v16608, %v16603 (stack39)
        %v16615 = vadd.s32 %v16611, %v9 (stack39)
        %v16617 = vshll.u32 %v16608, 24 (stack44)
        %v16618 = vshrl.u32 %v16608, 8 (stack45)
        %v16619 = vor.u32 %v16618, %v16617 (stack46)
        %v16620 = vxor.u32 %v16619, %v16611 (stack47)
        %v16623 = vadd.s32 %v16620, %v8 (stack39)
        %v16627 = vadd.s32 4, %v16623 (stack39)
        %v16631 = vadd.s32 %v16627, %v16615 (stack39)
        %v16633 = vshll.u32 %v16627, 13 (stack44)
        %v16634 = vshrl.u32 %v16627, 19 (stack45)
        %v16635 = vor.u32 %v16634, %v16633 (stack46)
        %v16636 = vxor.u32 %v16635, %v16631 (stack47)
        %v16639 = vadd.s32 %v16636, %v16631 (stack39)
        %v16641 = vshll.u32 %v16636, 15 (stack44)
        %v16642 = vshrl.u32 %v16636, 17 (stack45)
        %v16643 = vor.u32 %v16642, %v16641 (stack46)
        %v16644 = vxor.u32 %v16643, %v16639 (stack47)
        %v16647 = vadd.s32 %v16644, %v16639 (stack39)
        %v16649 = vshll.u32 %v16644, 26 (stack44)
        %v16650 = vshrl.u32 %v16644, 6 (stack45)
        %v16651 = vor.u32 %v16650, %v16649 (stack46)
        %v16652 = vxor.u32 %v16651, %v16647 (stack47)
        %v16655 = vadd.s32 %v16652, %v16647 (stack39)
        %v16659 = vadd.s32 %v16655, %v8 (stack39)
        %v16661 = vshll.u32 %v16652, 6 (stack44)
        %v16662 = vshrl.u32 %v16652, 26 (stack45)
        %v16663 = vor.u32 %v16662, %v16661 (stack46)
        %v16664 = vxor.u32 %v16663, %v16655 (stack47)
        %v16667 = vadd.s32 %v16664, %v10 (stack39)
        %v16671 = vadd.s32 5, %v16667 (stack39)
        %v16673 = vxor.u32 %v16671, %v16659 (stack47)
        %v16674 = vand.u32.u8 255, %v16673 (stack48)
        %v16675 = vand.u32 65535, %v16674 (stack49)
        %v16676 = vshrl.u32 %v16675, 1 (stack50)
        %v16677 = vor.u32 16256, %v16676 (stack46)
        %v16678 = vand.u32.u16 65535, %v16677 (stack51)
        %v119832 = vadd.low.f32.bf16 -1.0, %v16678 (stack52)
        %v16687 = vmul.f32 2.0, %v119832 (stack53)
        %v16691 = vadd.f32 -0.99609375, %v16687 (stack52)
        %v16695 = vmax.f32 %v16691, -0.99609375 (stack54)
        %v16697 = vand.u32 2147483647, %v16695 (stack55)
        %vm16700 = vcmp.eq.f32.partialorder %v16697, 1.0 (stack56)
        %v16705 = vmul.f32 inf, %v16695 (stack53)
        %v16707 = vxor.u32 2147483648, %v16695 (stack57)
        %v16710 = vmul.f32 %v16707, %v16695 (stack53)
        %v16712 = vadd.f32 1.0, %v16710 (stack58)
        %v16713 = vlog2.pop %v16712 (stack59)
        %v16714 = vmul.f32 0.6931472, %v16713 (stack60)
        %v16715 = vmul.f32 -0.5, %v16710 (stack61)
        %v16716 = vadd.f32 1.0, %v16715 (stack62)
        %v16717 = vmul.f32 %v16716, %v16710 (stack63)
        %v16718 = vand.u32 2147483647, %v16710 (stack64)
        %vm16719 = vcmp.lt.f32.partialorder %v16718, 0.0004427343 (stack65)
        %v16720 = vsel /*vm=*/%vm16719, /*on_true_vy=*/%v16717, /*on_false_vx=*/%v16714 (stack66)
        %v16721 = vxor.u32 2147483648, %v16720 (stack57)
        %vm16724 = vcmp.lt.f32.partialorder %v16721, 5.0 (stack56)
        %v16729 = vsel /*vm=*/%vm16724, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v16733 = vsel /*vm=*/%vm16724, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v16737 = vsel /*vm=*/%vm16724, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v16741 = vsel /*vm=*/%vm16724, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v16745 = vsel /*vm=*/%vm16724, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v16749 = vsel /*vm=*/%vm16724, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v16753 = vsel /*vm=*/%vm16724, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v16757 = vsel /*vm=*/%vm16724, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v16761 = vsel /*vm=*/%vm16724, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v16765 = vadd.f32 -2.5, %v16721 (stack52)
        %v16767 = vrsqrt.pop %v16721 (stack67)
        %v16768 = vmul.f32 %v16767, %v16721 (stack68)
        %vm16769 = vcmp.eq.f32.partialorder %v16721, inf (stack69)
        %v16770 = vsel /*vm=*/%vm16769, /*on_true_vy=*/%v16721, /*on_false_vx=*/%v16768 (stack70)
        %vm16771 = vcmp.eq.f32.partialorder %v16721, 0.0 (stack71)
        %v16772 = vand.u32 2147483648, %v16721 (stack72)
        %v16773 = vsel /*vm=*/%vm16771, /*on_true_vy=*/%v16772, /*on_false_vx=*/%v16770 (stack73)
        %v16776 = vadd.f32 -3.0, %v16773 (stack52)
        %v16780 = vsel /*vm=*/%vm16724, /*on_true_vy=*/%v16765, /*on_false_vx=*/%v16776 (stack43)
        %v16784 = vmul.f32 %v16780, %v16761 (stack53)
        %v16788 = vadd.f32 %v16784, %v16757 (stack52)
        %v16792 = vmul.f32 %v16788, %v16780 (stack53)
        %v16796 = vadd.f32 %v16792, %v16753 (stack52)
        %v16800 = vmul.f32 %v16796, %v16780 (stack53)
        %v16804 = vadd.f32 %v16800, %v16749 (stack52)
        %v16808 = vmul.f32 %v16804, %v16780 (stack53)
        %v16812 = vadd.f32 %v16808, %v16745 (stack52)
        %v16816 = vmul.f32 %v16812, %v16780 (stack53)
        %v16820 = vadd.f32 %v16816, %v16741 (stack52)
        %v16824 = vmul.f32 %v16820, %v16780 (stack53)
        %v16828 = vadd.f32 %v16824, %v16737 (stack52)
        %v16832 = vmul.f32 %v16828, %v16780 (stack53)
        %v16836 = vadd.f32 %v16832, %v16733 (stack52)
        %v16840 = vmul.f32 %v16836, %v16780 (stack53)
        %v16844 = vadd.f32 %v16840, %v16729 (stack52)
        %v16848 = vmul.f32 %v16844, %v16695 (stack53)
        %v16852 = vsel /*vm=*/%vm16700, /*on_true_vy=*/%v16705, /*on_false_vx=*/%v16848 (stack43)
        %v16856 = vmul.f32 1.4140625, %v16852 (stack53)
        %v16859 = vpack.c.bf16 0.0, %v16856 (stack74)
        %119833 = vst [vmem:[%s280 + $0x110] sm:$0xf] /*vst_source=*/%v16859 (stack75)
        %v16863 = vadd.s32 %v15477, %v1868 (stack39)
        %v16873 = vadd.s32 %v16863, %v415 (stack39)
        %vm16877 = vcmp.lt.u32.totalorder %v16873, %v16863 (stack42)
        %vm16882 = vcmp.lt.u32.totalorder %v16863, %v1868 (stack42)
        %v16887 = vadd.s32 %v15460, %v1855 (stack39)
        %v16891 = vadd.s32 1, %v16887 (stack39)
        %v16895 = vsel /*vm=*/%vm16882, /*on_true_vy=*/%v16891, /*on_false_vx=*/%v16887 (stack43)
        %v16899 = vadd.s32 1, %v16895 (stack39)
        %v16903 = vsel /*vm=*/%vm16877, /*on_true_vy=*/%v16899, /*on_false_vx=*/%v16895 (stack43)
        %v16908 = vadd.s32 %v16903, %v10 (stack39)
        %v16912 = vadd.s32 %v16873, %v9 (stack39)
        %v16916 = vadd.s32 %v16912, %v16908 (stack39)
        %v16918 = vshll.u32 %v16912, 13 (stack44)
        %v16919 = vshrl.u32 %v16912, 19 (stack45)
        %v16920 = vor.u32 %v16919, %v16918 (stack46)
        %v16921 = vxor.u32 %v16920, %v16916 (stack47)
        %v16924 = vadd.s32 %v16921, %v16916 (stack39)
        %v16926 = vshll.u32 %v16921, 15 (stack44)
        %v16927 = vshrl.u32 %v16921, 17 (stack45)
        %v16928 = vor.u32 %v16927, %v16926 (stack46)
        %v16929 = vxor.u32 %v16928, %v16924 (stack47)
        %v16932 = vadd.s32 %v16929, %v16924 (stack39)
        %v16934 = vshll.u32 %v16929, 26 (stack44)
        %v16935 = vshrl.u32 %v16929, 6 (stack45)
        %v16936 = vor.u32 %v16935, %v16934 (stack46)
        %v16937 = vxor.u32 %v16936, %v16932 (stack47)
        %v16940 = vadd.s32 %v16937, %v16932 (stack39)
        %v16944 = vadd.s32 %v16940, %v9 (stack39)
        %v16946 = vshll.u32 %v16937, 6 (stack44)
        %v16947 = vshrl.u32 %v16937, 26 (stack45)
        %v16948 = vor.u32 %v16947, %v16946 (stack46)
        %v16949 = vxor.u32 %v16948, %v16940 (stack47)
        %v16952 = vadd.s32 %v16949, %v8 (stack39)
        %v16956 = vadd.s32 1, %v16952 (stack39)
        %v16960 = vadd.s32 %v16956, %v16944 (stack39)
        %v16962 = vshll.u32 %v16956, 17 (stack44)
        %v16963 = vshrl.u32 %v16956, 15 (stack45)
        %v16964 = vor.u32 %v16963, %v16962 (stack46)
        %v16965 = vxor.u32 %v16964, %v16960 (stack47)
        %v16968 = vadd.s32 %v16965, %v16960 (stack39)
        %v16970 = vshll.u32 %v16965, 29 (stack44)
        %v16971 = vshrl.u32 %v16965, 3 (stack45)
        %v16972 = vor.u32 %v16971, %v16970 (stack46)
        %v16973 = vxor.u32 %v16972, %v16968 (stack47)
        %v16976 = vadd.s32 %v16973, %v16968 (stack39)
        %v16978 = vshll.u32 %v16973, 16 (stack44)
        %v16979 = vshrl.u32 %v16973, 16 (stack45)
        %v16980 = vor.u32 %v16979, %v16978 (stack46)
        %v16981 = vxor.u32 %v16980, %v16976 (stack47)
        %v16984 = vadd.s32 %v16981, %v16976 (stack39)
        %v16988 = vadd.s32 %v16984, %v8 (stack39)
        %v16990 = vshll.u32 %v16981, 24 (stack44)
        %v16991 = vshrl.u32 %v16981, 8 (stack45)
        %v16992 = vor.u32 %v16991, %v16990 (stack46)
        %v16993 = vxor.u32 %v16992, %v16984 (stack47)
        %v16996 = vadd.s32 %v16993, %v10 (stack39)
        %v17000 = vadd.s32 2, %v16996 (stack39)
        %v17004 = vadd.s32 %v17000, %v16988 (stack39)
        %v17006 = vshll.u32 %v17000, 13 (stack44)
        %v17007 = vshrl.u32 %v17000, 19 (stack45)
        %v17008 = vor.u32 %v17007, %v17006 (stack46)
        %v17009 = vxor.u32 %v17008, %v17004 (stack47)
        %v17012 = vadd.s32 %v17009, %v17004 (stack39)
        %v17014 = vshll.u32 %v17009, 15 (stack44)
        %v17015 = vshrl.u32 %v17009, 17 (stack45)
        %v17016 = vor.u32 %v17015, %v17014 (stack46)
        %v17017 = vxor.u32 %v17016, %v17012 (stack47)
        %v17020 = vadd.s32 %v17017, %v17012 (stack39)
        %v17022 = vshll.u32 %v17017, 26 (stack44)
        %v17023 = vshrl.u32 %v17017, 6 (stack45)
        %v17024 = vor.u32 %v17023, %v17022 (stack46)
        %v17025 = vxor.u32 %v17024, %v17020 (stack47)
        %v17028 = vadd.s32 %v17025, %v17020 (stack39)
        %v17032 = vadd.s32 %v17028, %v10 (stack39)
        %v17034 = vshll.u32 %v17025, 6 (stack44)
        %v17035 = vshrl.u32 %v17025, 26 (stack45)
        %v17036 = vor.u32 %v17035, %v17034 (stack46)
        %v17037 = vxor.u32 %v17036, %v17028 (stack47)
        %v17040 = vadd.s32 %v17037, %v9 (stack39)
        %v17044 = vadd.s32 3, %v17040 (stack39)
        %v17048 = vadd.s32 %v17044, %v17032 (stack39)
        %v17050 = vshll.u32 %v17044, 17 (stack44)
        %v17051 = vshrl.u32 %v17044, 15 (stack45)
        %v17052 = vor.u32 %v17051, %v17050 (stack46)
        %v17053 = vxor.u32 %v17052, %v17048 (stack47)
        %v17056 = vadd.s32 %v17053, %v17048 (stack39)
        %v17058 = vshll.u32 %v17053, 29 (stack44)
        %v17059 = vshrl.u32 %v17053, 3 (stack45)
        %v17060 = vor.u32 %v17059, %v17058 (stack46)
        %v17061 = vxor.u32 %v17060, %v17056 (stack47)
        %v17064 = vadd.s32 %v17061, %v17056 (stack39)
        %v17066 = vshll.u32 %v17061, 16 (stack44)
        %v17067 = vshrl.u32 %v17061, 16 (stack45)
        %v17068 = vor.u32 %v17067, %v17066 (stack46)
        %v17069 = vxor.u32 %v17068, %v17064 (stack47)
        %v17072 = vadd.s32 %v17069, %v17064 (stack39)
        %v17076 = vadd.s32 %v17072, %v9 (stack39)
        %v17078 = vshll.u32 %v17069, 24 (stack44)
        %v17079 = vshrl.u32 %v17069, 8 (stack45)
        %v17080 = vor.u32 %v17079, %v17078 (stack46)
        %v17081 = vxor.u32 %v17080, %v17072 (stack47)
        %v17084 = vadd.s32 %v17081, %v8 (stack39)
        %v17088 = vadd.s32 4, %v17084 (stack39)
        %v17092 = vadd.s32 %v17088, %v17076 (stack39)
        %v17094 = vshll.u32 %v17088, 13 (stack44)
        %v17095 = vshrl.u32 %v17088, 19 (stack45)
        %v17096 = vor.u32 %v17095, %v17094 (stack46)
        %v17097 = vxor.u32 %v17096, %v17092 (stack47)
        %v17100 = vadd.s32 %v17097, %v17092 (stack39)
        %v17102 = vshll.u32 %v17097, 15 (stack44)
        %v17103 = vshrl.u32 %v17097, 17 (stack45)
        %v17104 = vor.u32 %v17103, %v17102 (stack46)
        %v17105 = vxor.u32 %v17104, %v17100 (stack47)
        %v17108 = vadd.s32 %v17105, %v17100 (stack39)
        %v17110 = vshll.u32 %v17105, 26 (stack44)
        %v17111 = vshrl.u32 %v17105, 6 (stack45)
        %v17112 = vor.u32 %v17111, %v17110 (stack46)
        %v17113 = vxor.u32 %v17112, %v17108 (stack47)
        %v17116 = vadd.s32 %v17113, %v17108 (stack39)
        %v17120 = vadd.s32 %v17116, %v8 (stack39)
        %v17122 = vshll.u32 %v17113, 6 (stack44)
        %v17123 = vshrl.u32 %v17113, 26 (stack45)
        %v17124 = vor.u32 %v17123, %v17122 (stack46)
        %v17125 = vxor.u32 %v17124, %v17116 (stack47)
        %v17128 = vadd.s32 %v17125, %v10 (stack39)
        %v17132 = vadd.s32 5, %v17128 (stack39)
        %v17134 = vxor.u32 %v17132, %v17120 (stack47)
        %v17135 = vand.u32.u8 255, %v17134 (stack48)
        %v17136 = vand.u32 65535, %v17135 (stack49)
        %v17137 = vshrl.u32 %v17136, 1 (stack50)
        %v17138 = vor.u32 16256, %v17137 (stack46)
        %v17139 = vand.u32.u16 65535, %v17138 (stack51)
        %v119834 = vadd.low.f32.bf16 -1.0, %v17139 (stack52)
        %v17148 = vmul.f32 2.0, %v119834 (stack53)
        %v17152 = vadd.f32 -0.99609375, %v17148 (stack52)
        %v17156 = vmax.f32 %v17152, -0.99609375 (stack54)
        %v17158 = vand.u32 2147483647, %v17156 (stack55)
        %vm17161 = vcmp.eq.f32.partialorder %v17158, 1.0 (stack56)
        %v17166 = vmul.f32 inf, %v17156 (stack53)
        %v17168 = vxor.u32 2147483648, %v17156 (stack57)
        %v17171 = vmul.f32 %v17168, %v17156 (stack53)
        %v17173 = vadd.f32 1.0, %v17171 (stack58)
        %v17174 = vlog2.pop %v17173 (stack59)
        %v17175 = vmul.f32 0.6931472, %v17174 (stack60)
        %v17176 = vmul.f32 -0.5, %v17171 (stack61)
        %v17177 = vadd.f32 1.0, %v17176 (stack62)
        %v17178 = vmul.f32 %v17177, %v17171 (stack63)
        %v17179 = vand.u32 2147483647, %v17171 (stack64)
        %vm17180 = vcmp.lt.f32.partialorder %v17179, 0.0004427343 (stack65)
        %v17181 = vsel /*vm=*/%vm17180, /*on_true_vy=*/%v17178, /*on_false_vx=*/%v17175 (stack66)
        %v17182 = vxor.u32 2147483648, %v17181 (stack57)
        %vm17185 = vcmp.lt.f32.partialorder %v17182, 5.0 (stack56)
        %v17190 = vsel /*vm=*/%vm17185, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v17194 = vsel /*vm=*/%vm17185, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v17198 = vsel /*vm=*/%vm17185, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v17202 = vsel /*vm=*/%vm17185, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v17206 = vsel /*vm=*/%vm17185, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v17210 = vsel /*vm=*/%vm17185, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v17214 = vsel /*vm=*/%vm17185, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v17218 = vsel /*vm=*/%vm17185, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v17222 = vsel /*vm=*/%vm17185, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v17226 = vadd.f32 -2.5, %v17182 (stack52)
        %v17228 = vrsqrt.pop %v17182 (stack67)
        %v17229 = vmul.f32 %v17228, %v17182 (stack68)
        %vm17230 = vcmp.eq.f32.partialorder %v17182, inf (stack69)
        %v17231 = vsel /*vm=*/%vm17230, /*on_true_vy=*/%v17182, /*on_false_vx=*/%v17229 (stack70)
        %vm17232 = vcmp.eq.f32.partialorder %v17182, 0.0 (stack71)
        %v17233 = vand.u32 2147483648, %v17182 (stack72)
        %v17234 = vsel /*vm=*/%vm17232, /*on_true_vy=*/%v17233, /*on_false_vx=*/%v17231 (stack73)
        %v17237 = vadd.f32 -3.0, %v17234 (stack52)
        %v17241 = vsel /*vm=*/%vm17185, /*on_true_vy=*/%v17226, /*on_false_vx=*/%v17237 (stack43)
        %v17245 = vmul.f32 %v17241, %v17222 (stack53)
        %v17249 = vadd.f32 %v17245, %v17218 (stack52)
        %v17253 = vmul.f32 %v17249, %v17241 (stack53)
        %v17257 = vadd.f32 %v17253, %v17214 (stack52)
        %v17261 = vmul.f32 %v17257, %v17241 (stack53)
        %v17265 = vadd.f32 %v17261, %v17210 (stack52)
        %v17269 = vmul.f32 %v17265, %v17241 (stack53)
        %v17273 = vadd.f32 %v17269, %v17206 (stack52)
        %v17277 = vmul.f32 %v17273, %v17241 (stack53)
        %v17281 = vadd.f32 %v17277, %v17202 (stack52)
        %v17285 = vmul.f32 %v17281, %v17241 (stack53)
        %v17289 = vadd.f32 %v17285, %v17198 (stack52)
        %v17293 = vmul.f32 %v17289, %v17241 (stack53)
        %v17297 = vadd.f32 %v17293, %v17194 (stack52)
        %v17301 = vmul.f32 %v17297, %v17241 (stack53)
        %v17305 = vadd.f32 %v17301, %v17190 (stack52)
        %v17309 = vmul.f32 %v17305, %v17156 (stack53)
        %v17313 = vsel /*vm=*/%vm17161, /*on_true_vy=*/%v17166, /*on_false_vx=*/%v17309 (stack43)
        %v17317 = vmul.f32 1.4140625, %v17313 (stack53)
        %v17320 = vpack.c.bf16 0.0, %v17317 (stack74)
        %119835 = vst [vmem:[%s280 + $0x190] sm:$0xf] /*vst_source=*/%v17320 (stack75)
        %v17324 = vadd.s32 %v15477, %v2355 (stack39)
        %v17334 = vadd.s32 %v17324, %v415 (stack39)
        %vm17338 = vcmp.lt.u32.totalorder %v17334, %v17324 (stack42)
        %vm17343 = vcmp.lt.u32.totalorder %v17324, %v2355 (stack42)
        %v17348 = vadd.s32 %v15460, %v2342 (stack39)
        %v17352 = vadd.s32 1, %v17348 (stack39)
        %v17356 = vsel /*vm=*/%vm17343, /*on_true_vy=*/%v17352, /*on_false_vx=*/%v17348 (stack43)
        %v17360 = vadd.s32 1, %v17356 (stack39)
        %v17364 = vsel /*vm=*/%vm17338, /*on_true_vy=*/%v17360, /*on_false_vx=*/%v17356 (stack43)
        %v17369 = vadd.s32 %v17364, %v10 (stack39)
        %v17373 = vadd.s32 %v17334, %v9 (stack39)
        %v17377 = vadd.s32 %v17373, %v17369 (stack39)
        %v17379 = vshll.u32 %v17373, 13 (stack44)
        %v17380 = vshrl.u32 %v17373, 19 (stack45)
        %v17381 = vor.u32 %v17380, %v17379 (stack46)
        %v17382 = vxor.u32 %v17381, %v17377 (stack47)
        %v17385 = vadd.s32 %v17382, %v17377 (stack39)
        %v17387 = vshll.u32 %v17382, 15 (stack44)
        %v17388 = vshrl.u32 %v17382, 17 (stack45)
        %v17389 = vor.u32 %v17388, %v17387 (stack46)
        %v17390 = vxor.u32 %v17389, %v17385 (stack47)
        %v17393 = vadd.s32 %v17390, %v17385 (stack39)
        %v17395 = vshll.u32 %v17390, 26 (stack44)
        %v17396 = vshrl.u32 %v17390, 6 (stack45)
        %v17397 = vor.u32 %v17396, %v17395 (stack46)
        %v17398 = vxor.u32 %v17397, %v17393 (stack47)
        %v17401 = vadd.s32 %v17398, %v17393 (stack39)
        %v17405 = vadd.s32 %v17401, %v9 (stack39)
        %v17407 = vshll.u32 %v17398, 6 (stack44)
        %v17408 = vshrl.u32 %v17398, 26 (stack45)
        %v17409 = vor.u32 %v17408, %v17407 (stack46)
        %v17410 = vxor.u32 %v17409, %v17401 (stack47)
        %v17413 = vadd.s32 %v17410, %v8 (stack39)
        %v17417 = vadd.s32 1, %v17413 (stack39)
        %v17421 = vadd.s32 %v17417, %v17405 (stack39)
        %v17423 = vshll.u32 %v17417, 17 (stack44)
        %v17424 = vshrl.u32 %v17417, 15 (stack45)
        %v17425 = vor.u32 %v17424, %v17423 (stack46)
        %v17426 = vxor.u32 %v17425, %v17421 (stack47)
        %v17429 = vadd.s32 %v17426, %v17421 (stack39)
        %v17431 = vshll.u32 %v17426, 29 (stack44)
        %v17432 = vshrl.u32 %v17426, 3 (stack45)
        %v17433 = vor.u32 %v17432, %v17431 (stack46)
        %v17434 = vxor.u32 %v17433, %v17429 (stack47)
        %v17437 = vadd.s32 %v17434, %v17429 (stack39)
        %v17439 = vshll.u32 %v17434, 16 (stack44)
        %v17440 = vshrl.u32 %v17434, 16 (stack45)
        %v17441 = vor.u32 %v17440, %v17439 (stack46)
        %v17442 = vxor.u32 %v17441, %v17437 (stack47)
        %v17445 = vadd.s32 %v17442, %v17437 (stack39)
        %v17449 = vadd.s32 %v17445, %v8 (stack39)
        %v17451 = vshll.u32 %v17442, 24 (stack44)
        %v17452 = vshrl.u32 %v17442, 8 (stack45)
        %v17453 = vor.u32 %v17452, %v17451 (stack46)
        %v17454 = vxor.u32 %v17453, %v17445 (stack47)
        %v17457 = vadd.s32 %v17454, %v10 (stack39)
        %v17461 = vadd.s32 2, %v17457 (stack39)
        %v17465 = vadd.s32 %v17461, %v17449 (stack39)
        %v17467 = vshll.u32 %v17461, 13 (stack44)
        %v17468 = vshrl.u32 %v17461, 19 (stack45)
        %v17469 = vor.u32 %v17468, %v17467 (stack46)
        %v17470 = vxor.u32 %v17469, %v17465 (stack47)
        %v17473 = vadd.s32 %v17470, %v17465 (stack39)
        %v17475 = vshll.u32 %v17470, 15 (stack44)
        %v17476 = vshrl.u32 %v17470, 17 (stack45)
        %v17477 = vor.u32 %v17476, %v17475 (stack46)
        %v17478 = vxor.u32 %v17477, %v17473 (stack47)
        %v17481 = vadd.s32 %v17478, %v17473 (stack39)
        %v17483 = vshll.u32 %v17478, 26 (stack44)
        %v17484 = vshrl.u32 %v17478, 6 (stack45)
        %v17485 = vor.u32 %v17484, %v17483 (stack46)
        %v17486 = vxor.u32 %v17485, %v17481 (stack47)
        %v17489 = vadd.s32 %v17486, %v17481 (stack39)
        %v17493 = vadd.s32 %v17489, %v10 (stack39)
        %v17495 = vshll.u32 %v17486, 6 (stack44)
        %v17496 = vshrl.u32 %v17486, 26 (stack45)
        %v17497 = vor.u32 %v17496, %v17495 (stack46)
        %v17498 = vxor.u32 %v17497, %v17489 (stack47)
        %v17501 = vadd.s32 %v17498, %v9 (stack39)
        %v17505 = vadd.s32 3, %v17501 (stack39)
        %v17509 = vadd.s32 %v17505, %v17493 (stack39)
        %v17511 = vshll.u32 %v17505, 17 (stack44)
        %v17512 = vshrl.u32 %v17505, 15 (stack45)
        %v17513 = vor.u32 %v17512, %v17511 (stack46)
        %v17514 = vxor.u32 %v17513, %v17509 (stack47)
        %v17517 = vadd.s32 %v17514, %v17509 (stack39)
        %v17519 = vshll.u32 %v17514, 29 (stack44)
        %v17520 = vshrl.u32 %v17514, 3 (stack45)
        %v17521 = vor.u32 %v17520, %v17519 (stack46)
        %v17522 = vxor.u32 %v17521, %v17517 (stack47)
        %v17525 = vadd.s32 %v17522, %v17517 (stack39)
        %v17527 = vshll.u32 %v17522, 16 (stack44)
        %v17528 = vshrl.u32 %v17522, 16 (stack45)
        %v17529 = vor.u32 %v17528, %v17527 (stack46)
        %v17530 = vxor.u32 %v17529, %v17525 (stack47)
        %v17533 = vadd.s32 %v17530, %v17525 (stack39)
        %v17537 = vadd.s32 %v17533, %v9 (stack39)
        %v17539 = vshll.u32 %v17530, 24 (stack44)
        %v17540 = vshrl.u32 %v17530, 8 (stack45)
        %v17541 = vor.u32 %v17540, %v17539 (stack46)
        %v17542 = vxor.u32 %v17541, %v17533 (stack47)
        %v17545 = vadd.s32 %v17542, %v8 (stack39)
        %v17549 = vadd.s32 4, %v17545 (stack39)
        %v17553 = vadd.s32 %v17549, %v17537 (stack39)
        %v17555 = vshll.u32 %v17549, 13 (stack44)
        %v17556 = vshrl.u32 %v17549, 19 (stack45)
        %v17557 = vor.u32 %v17556, %v17555 (stack46)
        %v17558 = vxor.u32 %v17557, %v17553 (stack47)
        %v17561 = vadd.s32 %v17558, %v17553 (stack39)
        %v17563 = vshll.u32 %v17558, 15 (stack44)
        %v17564 = vshrl.u32 %v17558, 17 (stack45)
        %v17565 = vor.u32 %v17564, %v17563 (stack46)
        %v17566 = vxor.u32 %v17565, %v17561 (stack47)
        %v17569 = vadd.s32 %v17566, %v17561 (stack39)
        %v17571 = vshll.u32 %v17566, 26 (stack44)
        %v17572 = vshrl.u32 %v17566, 6 (stack45)
        %v17573 = vor.u32 %v17572, %v17571 (stack46)
        %v17574 = vxor.u32 %v17573, %v17569 (stack47)
        %v17577 = vadd.s32 %v17574, %v17569 (stack39)
        %v17581 = vadd.s32 %v17577, %v8 (stack39)
        %v17583 = vshll.u32 %v17574, 6 (stack44)
        %v17584 = vshrl.u32 %v17574, 26 (stack45)
        %v17585 = vor.u32 %v17584, %v17583 (stack46)
        %v17586 = vxor.u32 %v17585, %v17577 (stack47)
        %v17589 = vadd.s32 %v17586, %v10 (stack39)
        %v17593 = vadd.s32 5, %v17589 (stack39)
        %v17595 = vxor.u32 %v17593, %v17581 (stack47)
        %v17596 = vand.u32.u8 255, %v17595 (stack48)
        %v17597 = vand.u32 65535, %v17596 (stack49)
        %v17598 = vshrl.u32 %v17597, 1 (stack50)
        %v17599 = vor.u32 16256, %v17598 (stack46)
        %v17600 = vand.u32.u16 65535, %v17599 (stack51)
        %v119836 = vadd.low.f32.bf16 -1.0, %v17600 (stack52)
        %v17609 = vmul.f32 2.0, %v119836 (stack53)
        %v17613 = vadd.f32 -0.99609375, %v17609 (stack52)
        %v17617 = vmax.f32 %v17613, -0.99609375 (stack54)
        %v17619 = vand.u32 2147483647, %v17617 (stack55)
        %vm17622 = vcmp.eq.f32.partialorder %v17619, 1.0 (stack56)
        %v17627 = vmul.f32 inf, %v17617 (stack53)
        %v17629 = vxor.u32 2147483648, %v17617 (stack57)
        %v17632 = vmul.f32 %v17629, %v17617 (stack53)
        %v17634 = vadd.f32 1.0, %v17632 (stack58)
        %v17635 = vlog2.pop %v17634 (stack59)
        %v17636 = vmul.f32 0.6931472, %v17635 (stack60)
        %v17637 = vmul.f32 -0.5, %v17632 (stack61)
        %v17638 = vadd.f32 1.0, %v17637 (stack62)
        %v17639 = vmul.f32 %v17638, %v17632 (stack63)
        %v17640 = vand.u32 2147483647, %v17632 (stack64)
        %vm17641 = vcmp.lt.f32.partialorder %v17640, 0.0004427343 (stack65)
        %v17642 = vsel /*vm=*/%vm17641, /*on_true_vy=*/%v17639, /*on_false_vx=*/%v17636 (stack66)
        %v17643 = vxor.u32 2147483648, %v17642 (stack57)
        %vm17646 = vcmp.lt.f32.partialorder %v17643, 5.0 (stack56)
        %v17651 = vsel /*vm=*/%vm17646, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v17655 = vsel /*vm=*/%vm17646, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v17659 = vsel /*vm=*/%vm17646, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v17663 = vsel /*vm=*/%vm17646, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v17667 = vsel /*vm=*/%vm17646, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v17671 = vsel /*vm=*/%vm17646, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v17675 = vsel /*vm=*/%vm17646, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v17679 = vsel /*vm=*/%vm17646, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v17683 = vsel /*vm=*/%vm17646, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v17687 = vadd.f32 -2.5, %v17643 (stack52)
        %v17689 = vrsqrt.pop %v17643 (stack67)
        %v17690 = vmul.f32 %v17689, %v17643 (stack68)
        %vm17691 = vcmp.eq.f32.partialorder %v17643, inf (stack69)
        %v17692 = vsel /*vm=*/%vm17691, /*on_true_vy=*/%v17643, /*on_false_vx=*/%v17690 (stack70)
        %vm17693 = vcmp.eq.f32.partialorder %v17643, 0.0 (stack71)
        %v17694 = vand.u32 2147483648, %v17643 (stack72)
        %v17695 = vsel /*vm=*/%vm17693, /*on_true_vy=*/%v17694, /*on_false_vx=*/%v17692 (stack73)
        %v17698 = vadd.f32 -3.0, %v17695 (stack52)
        %v17702 = vsel /*vm=*/%vm17646, /*on_true_vy=*/%v17687, /*on_false_vx=*/%v17698 (stack43)
        %v17706 = vmul.f32 %v17702, %v17683 (stack53)
        %v17710 = vadd.f32 %v17706, %v17679 (stack52)
        %v17714 = vmul.f32 %v17710, %v17702 (stack53)
        %v17718 = vadd.f32 %v17714, %v17675 (stack52)
        %v17722 = vmul.f32 %v17718, %v17702 (stack53)
        %v17726 = vadd.f32 %v17722, %v17671 (stack52)
        %v17730 = vmul.f32 %v17726, %v17702 (stack53)
        %v17734 = vadd.f32 %v17730, %v17667 (stack52)
        %v17738 = vmul.f32 %v17734, %v17702 (stack53)
        %v17742 = vadd.f32 %v17738, %v17663 (stack52)
        %v17746 = vmul.f32 %v17742, %v17702 (stack53)
        %v17750 = vadd.f32 %v17746, %v17659 (stack52)
        %v17754 = vmul.f32 %v17750, %v17702 (stack53)
        %v17758 = vadd.f32 %v17754, %v17655 (stack52)
        %v17762 = vmul.f32 %v17758, %v17702 (stack53)
        %v17766 = vadd.f32 %v17762, %v17651 (stack52)
        %v17770 = vmul.f32 %v17766, %v17617 (stack53)
        %v17774 = vsel /*vm=*/%vm17622, /*on_true_vy=*/%v17627, /*on_false_vx=*/%v17770 (stack43)
        %v17778 = vmul.f32 1.4140625, %v17774 (stack53)
        %v17781 = vpack.c.bf16 0.0, %v17778 (stack74)
        %119837 = vst [vmem:[%s280 + $0x210] sm:$0xf] /*vst_source=*/%v17781 (stack75)
        %v17785 = vadd.s32 %v15477, %v2842 (stack39)
        %v17795 = vadd.s32 %v17785, %v415 (stack39)
        %vm17799 = vcmp.lt.u32.totalorder %v17795, %v17785 (stack42)
        %vm17804 = vcmp.lt.u32.totalorder %v17785, %v2842 (stack42)
        %v17809 = vadd.s32 %v15460, %v2829 (stack39)
        %v17813 = vadd.s32 1, %v17809 (stack39)
        %v17817 = vsel /*vm=*/%vm17804, /*on_true_vy=*/%v17813, /*on_false_vx=*/%v17809 (stack43)
        %v17821 = vadd.s32 1, %v17817 (stack39)
        %v17825 = vsel /*vm=*/%vm17799, /*on_true_vy=*/%v17821, /*on_false_vx=*/%v17817 (stack43)
        %v17830 = vadd.s32 %v17825, %v10 (stack39)
        %v17834 = vadd.s32 %v17795, %v9 (stack39)
        %v17838 = vadd.s32 %v17834, %v17830 (stack39)
        %v17840 = vshll.u32 %v17834, 13 (stack44)
        %v17841 = vshrl.u32 %v17834, 19 (stack45)
        %v17842 = vor.u32 %v17841, %v17840 (stack46)
        %v17843 = vxor.u32 %v17842, %v17838 (stack47)
        %v17846 = vadd.s32 %v17843, %v17838 (stack39)
        %v17848 = vshll.u32 %v17843, 15 (stack44)
        %v17849 = vshrl.u32 %v17843, 17 (stack45)
        %v17850 = vor.u32 %v17849, %v17848 (stack46)
        %v17851 = vxor.u32 %v17850, %v17846 (stack47)
        %v17854 = vadd.s32 %v17851, %v17846 (stack39)
        %v17856 = vshll.u32 %v17851, 26 (stack44)
        %v17857 = vshrl.u32 %v17851, 6 (stack45)
        %v17858 = vor.u32 %v17857, %v17856 (stack46)
        %v17859 = vxor.u32 %v17858, %v17854 (stack47)
        %v17862 = vadd.s32 %v17859, %v17854 (stack39)
        %v17866 = vadd.s32 %v17862, %v9 (stack39)
        %v17868 = vshll.u32 %v17859, 6 (stack44)
        %v17869 = vshrl.u32 %v17859, 26 (stack45)
        %v17870 = vor.u32 %v17869, %v17868 (stack46)
        %v17871 = vxor.u32 %v17870, %v17862 (stack47)
        %v17874 = vadd.s32 %v17871, %v8 (stack39)
        %v17878 = vadd.s32 1, %v17874 (stack39)
        %v17882 = vadd.s32 %v17878, %v17866 (stack39)
        %v17884 = vshll.u32 %v17878, 17 (stack44)
        %v17885 = vshrl.u32 %v17878, 15 (stack45)
        %v17886 = vor.u32 %v17885, %v17884 (stack46)
        %v17887 = vxor.u32 %v17886, %v17882 (stack47)
        %v17890 = vadd.s32 %v17887, %v17882 (stack39)
        %v17892 = vshll.u32 %v17887, 29 (stack44)
        %v17893 = vshrl.u32 %v17887, 3 (stack45)
        %v17894 = vor.u32 %v17893, %v17892 (stack46)
        %v17895 = vxor.u32 %v17894, %v17890 (stack47)
        %v17898 = vadd.s32 %v17895, %v17890 (stack39)
        %v17900 = vshll.u32 %v17895, 16 (stack44)
        %v17901 = vshrl.u32 %v17895, 16 (stack45)
        %v17902 = vor.u32 %v17901, %v17900 (stack46)
        %v17903 = vxor.u32 %v17902, %v17898 (stack47)
        %v17906 = vadd.s32 %v17903, %v17898 (stack39)
        %v17910 = vadd.s32 %v17906, %v8 (stack39)
        %v17912 = vshll.u32 %v17903, 24 (stack44)
        %v17913 = vshrl.u32 %v17903, 8 (stack45)
        %v17914 = vor.u32 %v17913, %v17912 (stack46)
        %v17915 = vxor.u32 %v17914, %v17906 (stack47)
        %v17918 = vadd.s32 %v17915, %v10 (stack39)
        %v17922 = vadd.s32 2, %v17918 (stack39)
        %v17926 = vadd.s32 %v17922, %v17910 (stack39)
        %v17928 = vshll.u32 %v17922, 13 (stack44)
        %v17929 = vshrl.u32 %v17922, 19 (stack45)
        %v17930 = vor.u32 %v17929, %v17928 (stack46)
        %v17931 = vxor.u32 %v17930, %v17926 (stack47)
        %v17934 = vadd.s32 %v17931, %v17926 (stack39)
        %v17936 = vshll.u32 %v17931, 15 (stack44)
        %v17937 = vshrl.u32 %v17931, 17 (stack45)
        %v17938 = vor.u32 %v17937, %v17936 (stack46)
        %v17939 = vxor.u32 %v17938, %v17934 (stack47)
        %v17942 = vadd.s32 %v17939, %v17934 (stack39)
        %v17944 = vshll.u32 %v17939, 26 (stack44)
        %v17945 = vshrl.u32 %v17939, 6 (stack45)
        %v17946 = vor.u32 %v17945, %v17944 (stack46)
        %v17947 = vxor.u32 %v17946, %v17942 (stack47)
        %v17950 = vadd.s32 %v17947, %v17942 (stack39)
        %v17954 = vadd.s32 %v17950, %v10 (stack39)
        %v17956 = vshll.u32 %v17947, 6 (stack44)
        %v17957 = vshrl.u32 %v17947, 26 (stack45)
        %v17958 = vor.u32 %v17957, %v17956 (stack46)
        %v17959 = vxor.u32 %v17958, %v17950 (stack47)
        %v17962 = vadd.s32 %v17959, %v9 (stack39)
        %v17966 = vadd.s32 3, %v17962 (stack39)
        %v17970 = vadd.s32 %v17966, %v17954 (stack39)
        %v17972 = vshll.u32 %v17966, 17 (stack44)
        %v17973 = vshrl.u32 %v17966, 15 (stack45)
        %v17974 = vor.u32 %v17973, %v17972 (stack46)
        %v17975 = vxor.u32 %v17974, %v17970 (stack47)
        %v17978 = vadd.s32 %v17975, %v17970 (stack39)
        %v17980 = vshll.u32 %v17975, 29 (stack44)
        %v17981 = vshrl.u32 %v17975, 3 (stack45)
        %v17982 = vor.u32 %v17981, %v17980 (stack46)
        %v17983 = vxor.u32 %v17982, %v17978 (stack47)
        %v17986 = vadd.s32 %v17983, %v17978 (stack39)
        %v17988 = vshll.u32 %v17983, 16 (stack44)
        %v17989 = vshrl.u32 %v17983, 16 (stack45)
        %v17990 = vor.u32 %v17989, %v17988 (stack46)
        %v17991 = vxor.u32 %v17990, %v17986 (stack47)
        %v17994 = vadd.s32 %v17991, %v17986 (stack39)
        %v17998 = vadd.s32 %v17994, %v9 (stack39)
        %v18000 = vshll.u32 %v17991, 24 (stack44)
        %v18001 = vshrl.u32 %v17991, 8 (stack45)
        %v18002 = vor.u32 %v18001, %v18000 (stack46)
        %v18003 = vxor.u32 %v18002, %v17994 (stack47)
        %v18006 = vadd.s32 %v18003, %v8 (stack39)
        %v18010 = vadd.s32 4, %v18006 (stack39)
        %v18014 = vadd.s32 %v18010, %v17998 (stack39)
        %v18016 = vshll.u32 %v18010, 13 (stack44)
        %v18017 = vshrl.u32 %v18010, 19 (stack45)
        %v18018 = vor.u32 %v18017, %v18016 (stack46)
        %v18019 = vxor.u32 %v18018, %v18014 (stack47)
        %v18022 = vadd.s32 %v18019, %v18014 (stack39)
        %v18024 = vshll.u32 %v18019, 15 (stack44)
        %v18025 = vshrl.u32 %v18019, 17 (stack45)
        %v18026 = vor.u32 %v18025, %v18024 (stack46)
        %v18027 = vxor.u32 %v18026, %v18022 (stack47)
        %v18030 = vadd.s32 %v18027, %v18022 (stack39)
        %v18032 = vshll.u32 %v18027, 26 (stack44)
        %v18033 = vshrl.u32 %v18027, 6 (stack45)
        %v18034 = vor.u32 %v18033, %v18032 (stack46)
        %v18035 = vxor.u32 %v18034, %v18030 (stack47)
        %v18038 = vadd.s32 %v18035, %v18030 (stack39)
        %v18042 = vadd.s32 %v18038, %v8 (stack39)
        %v18044 = vshll.u32 %v18035, 6 (stack44)
        %v18045 = vshrl.u32 %v18035, 26 (stack45)
        %v18046 = vor.u32 %v18045, %v18044 (stack46)
        %v18047 = vxor.u32 %v18046, %v18038 (stack47)
        %v18050 = vadd.s32 %v18047, %v10 (stack39)
        %v18054 = vadd.s32 5, %v18050 (stack39)
        %v18056 = vxor.u32 %v18054, %v18042 (stack47)
        %v18057 = vand.u32.u8 255, %v18056 (stack48)
        %v18058 = vand.u32 65535, %v18057 (stack49)
        %v18059 = vshrl.u32 %v18058, 1 (stack50)
        %v18060 = vor.u32 16256, %v18059 (stack46)
        %v18061 = vand.u32.u16 65535, %v18060 (stack51)
        %v119838 = vadd.low.f32.bf16 -1.0, %v18061 (stack52)
        %v18070 = vmul.f32 2.0, %v119838 (stack53)
        %v18074 = vadd.f32 -0.99609375, %v18070 (stack52)
        %v18078 = vmax.f32 %v18074, -0.99609375 (stack54)
        %v18080 = vand.u32 2147483647, %v18078 (stack55)
        %vm18083 = vcmp.eq.f32.partialorder %v18080, 1.0 (stack56)
        %v18088 = vmul.f32 inf, %v18078 (stack53)
        %v18090 = vxor.u32 2147483648, %v18078 (stack57)
        %v18093 = vmul.f32 %v18090, %v18078 (stack53)
        %v18095 = vadd.f32 1.0, %v18093 (stack58)
        %v18096 = vlog2.pop %v18095 (stack59)
        %v18097 = vmul.f32 0.6931472, %v18096 (stack60)
        %v18098 = vmul.f32 -0.5, %v18093 (stack61)
        %v18099 = vadd.f32 1.0, %v18098 (stack62)
        %v18100 = vmul.f32 %v18099, %v18093 (stack63)
        %v18101 = vand.u32 2147483647, %v18093 (stack64)
        %vm18102 = vcmp.lt.f32.partialorder %v18101, 0.0004427343 (stack65)
        %v18103 = vsel /*vm=*/%vm18102, /*on_true_vy=*/%v18100, /*on_false_vx=*/%v18097 (stack66)
        %v18104 = vxor.u32 2147483648, %v18103 (stack57)
        %vm18107 = vcmp.lt.f32.partialorder %v18104, 5.0 (stack56)
        %v18112 = vsel /*vm=*/%vm18107, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v18116 = vsel /*vm=*/%vm18107, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v18120 = vsel /*vm=*/%vm18107, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v18124 = vsel /*vm=*/%vm18107, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v18128 = vsel /*vm=*/%vm18107, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v18132 = vsel /*vm=*/%vm18107, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v18136 = vsel /*vm=*/%vm18107, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v18140 = vsel /*vm=*/%vm18107, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v18144 = vsel /*vm=*/%vm18107, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v18148 = vadd.f32 -2.5, %v18104 (stack52)
        %v18150 = vrsqrt.pop %v18104 (stack67)
        %v18151 = vmul.f32 %v18150, %v18104 (stack68)
        %vm18152 = vcmp.eq.f32.partialorder %v18104, inf (stack69)
        %v18153 = vsel /*vm=*/%vm18152, /*on_true_vy=*/%v18104, /*on_false_vx=*/%v18151 (stack70)
        %vm18154 = vcmp.eq.f32.partialorder %v18104, 0.0 (stack71)
        %v18155 = vand.u32 2147483648, %v18104 (stack72)
        %v18156 = vsel /*vm=*/%vm18154, /*on_true_vy=*/%v18155, /*on_false_vx=*/%v18153 (stack73)
        %v18159 = vadd.f32 -3.0, %v18156 (stack52)
        %v18163 = vsel /*vm=*/%vm18107, /*on_true_vy=*/%v18148, /*on_false_vx=*/%v18159 (stack43)
        %v18167 = vmul.f32 %v18163, %v18144 (stack53)
        %v18171 = vadd.f32 %v18167, %v18140 (stack52)
        %v18175 = vmul.f32 %v18171, %v18163 (stack53)
        %v18179 = vadd.f32 %v18175, %v18136 (stack52)
        %v18183 = vmul.f32 %v18179, %v18163 (stack53)
        %v18187 = vadd.f32 %v18183, %v18132 (stack52)
        %v18191 = vmul.f32 %v18187, %v18163 (stack53)
        %v18195 = vadd.f32 %v18191, %v18128 (stack52)
        %v18199 = vmul.f32 %v18195, %v18163 (stack53)
        %v18203 = vadd.f32 %v18199, %v18124 (stack52)
        %v18207 = vmul.f32 %v18203, %v18163 (stack53)
        %v18211 = vadd.f32 %v18207, %v18120 (stack52)
        %v18215 = vmul.f32 %v18211, %v18163 (stack53)
        %v18219 = vadd.f32 %v18215, %v18116 (stack52)
        %v18223 = vmul.f32 %v18219, %v18163 (stack53)
        %v18227 = vadd.f32 %v18223, %v18112 (stack52)
        %v18231 = vmul.f32 %v18227, %v18078 (stack53)
        %v18235 = vsel /*vm=*/%vm18083, /*on_true_vy=*/%v18088, /*on_false_vx=*/%v18231 (stack43)
        %v18239 = vmul.f32 1.4140625, %v18235 (stack53)
        %v18242 = vpack.c.bf16 0.0, %v18239 (stack74)
        %119839 = vst [vmem:[%s280 + $0x290] sm:$0xf] /*vst_source=*/%v18242 (stack75)
        %v18246 = vadd.s32 %v15477, %v3329 (stack39)
        %v18256 = vadd.s32 %v18246, %v415 (stack39)
        %vm18260 = vcmp.lt.u32.totalorder %v18256, %v18246 (stack42)
        %vm18265 = vcmp.lt.u32.totalorder %v18246, %v3329 (stack42)
        %v18270 = vadd.s32 %v15460, %v3316 (stack39)
        %v18274 = vadd.s32 1, %v18270 (stack39)
        %v18278 = vsel /*vm=*/%vm18265, /*on_true_vy=*/%v18274, /*on_false_vx=*/%v18270 (stack43)
        %v18282 = vadd.s32 1, %v18278 (stack39)
        %v18286 = vsel /*vm=*/%vm18260, /*on_true_vy=*/%v18282, /*on_false_vx=*/%v18278 (stack43)
        %v18291 = vadd.s32 %v18286, %v10 (stack39)
        %v18295 = vadd.s32 %v18256, %v9 (stack39)
        %v18299 = vadd.s32 %v18295, %v18291 (stack39)
        %v18301 = vshll.u32 %v18295, 13 (stack44)
        %v18302 = vshrl.u32 %v18295, 19 (stack45)
        %v18303 = vor.u32 %v18302, %v18301 (stack46)
        %v18304 = vxor.u32 %v18303, %v18299 (stack47)
        %v18307 = vadd.s32 %v18304, %v18299 (stack39)
        %v18309 = vshll.u32 %v18304, 15 (stack44)
        %v18310 = vshrl.u32 %v18304, 17 (stack45)
        %v18311 = vor.u32 %v18310, %v18309 (stack46)
        %v18312 = vxor.u32 %v18311, %v18307 (stack47)
        %v18315 = vadd.s32 %v18312, %v18307 (stack39)
        %v18317 = vshll.u32 %v18312, 26 (stack44)
        %v18318 = vshrl.u32 %v18312, 6 (stack45)
        %v18319 = vor.u32 %v18318, %v18317 (stack46)
        %v18320 = vxor.u32 %v18319, %v18315 (stack47)
        %v18323 = vadd.s32 %v18320, %v18315 (stack39)
        %v18327 = vadd.s32 %v18323, %v9 (stack39)
        %v18329 = vshll.u32 %v18320, 6 (stack44)
        %v18330 = vshrl.u32 %v18320, 26 (stack45)
        %v18331 = vor.u32 %v18330, %v18329 (stack46)
        %v18332 = vxor.u32 %v18331, %v18323 (stack47)
        %v18335 = vadd.s32 %v18332, %v8 (stack39)
        %v18339 = vadd.s32 1, %v18335 (stack39)
        %v18343 = vadd.s32 %v18339, %v18327 (stack39)
        %v18345 = vshll.u32 %v18339, 17 (stack44)
        %v18346 = vshrl.u32 %v18339, 15 (stack45)
        %v18347 = vor.u32 %v18346, %v18345 (stack46)
        %v18348 = vxor.u32 %v18347, %v18343 (stack47)
        %v18351 = vadd.s32 %v18348, %v18343 (stack39)
        %v18353 = vshll.u32 %v18348, 29 (stack44)
        %v18354 = vshrl.u32 %v18348, 3 (stack45)
        %v18355 = vor.u32 %v18354, %v18353 (stack46)
        %v18356 = vxor.u32 %v18355, %v18351 (stack47)
        %v18359 = vadd.s32 %v18356, %v18351 (stack39)
        %v18361 = vshll.u32 %v18356, 16 (stack44)
        %v18362 = vshrl.u32 %v18356, 16 (stack45)
        %v18363 = vor.u32 %v18362, %v18361 (stack46)
        %v18364 = vxor.u32 %v18363, %v18359 (stack47)
        %v18367 = vadd.s32 %v18364, %v18359 (stack39)
        %v18371 = vadd.s32 %v18367, %v8 (stack39)
        %v18373 = vshll.u32 %v18364, 24 (stack44)
        %v18374 = vshrl.u32 %v18364, 8 (stack45)
        %v18375 = vor.u32 %v18374, %v18373 (stack46)
        %v18376 = vxor.u32 %v18375, %v18367 (stack47)
        %v18379 = vadd.s32 %v18376, %v10 (stack39)
        %v18383 = vadd.s32 2, %v18379 (stack39)
        %v18387 = vadd.s32 %v18383, %v18371 (stack39)
        %v18389 = vshll.u32 %v18383, 13 (stack44)
        %v18390 = vshrl.u32 %v18383, 19 (stack45)
        %v18391 = vor.u32 %v18390, %v18389 (stack46)
        %v18392 = vxor.u32 %v18391, %v18387 (stack47)
        %v18395 = vadd.s32 %v18392, %v18387 (stack39)
        %v18397 = vshll.u32 %v18392, 15 (stack44)
        %v18398 = vshrl.u32 %v18392, 17 (stack45)
        %v18399 = vor.u32 %v18398, %v18397 (stack46)
        %v18400 = vxor.u32 %v18399, %v18395 (stack47)
        %v18403 = vadd.s32 %v18400, %v18395 (stack39)
        %v18405 = vshll.u32 %v18400, 26 (stack44)
        %v18406 = vshrl.u32 %v18400, 6 (stack45)
        %v18407 = vor.u32 %v18406, %v18405 (stack46)
        %v18408 = vxor.u32 %v18407, %v18403 (stack47)
        %v18411 = vadd.s32 %v18408, %v18403 (stack39)
        %v18415 = vadd.s32 %v18411, %v10 (stack39)
        %v18417 = vshll.u32 %v18408, 6 (stack44)
        %v18418 = vshrl.u32 %v18408, 26 (stack45)
        %v18419 = vor.u32 %v18418, %v18417 (stack46)
        %v18420 = vxor.u32 %v18419, %v18411 (stack47)
        %v18423 = vadd.s32 %v18420, %v9 (stack39)
        %v18427 = vadd.s32 3, %v18423 (stack39)
        %v18431 = vadd.s32 %v18427, %v18415 (stack39)
        %v18433 = vshll.u32 %v18427, 17 (stack44)
        %v18434 = vshrl.u32 %v18427, 15 (stack45)
        %v18435 = vor.u32 %v18434, %v18433 (stack46)
        %v18436 = vxor.u32 %v18435, %v18431 (stack47)
        %v18439 = vadd.s32 %v18436, %v18431 (stack39)
        %v18441 = vshll.u32 %v18436, 29 (stack44)
        %v18442 = vshrl.u32 %v18436, 3 (stack45)
        %v18443 = vor.u32 %v18442, %v18441 (stack46)
        %v18444 = vxor.u32 %v18443, %v18439 (stack47)
        %v18447 = vadd.s32 %v18444, %v18439 (stack39)
        %v18449 = vshll.u32 %v18444, 16 (stack44)
        %v18450 = vshrl.u32 %v18444, 16 (stack45)
        %v18451 = vor.u32 %v18450, %v18449 (stack46)
        %v18452 = vxor.u32 %v18451, %v18447 (stack47)
        %v18455 = vadd.s32 %v18452, %v18447 (stack39)
        %v18459 = vadd.s32 %v18455, %v9 (stack39)
        %v18461 = vshll.u32 %v18452, 24 (stack44)
        %v18462 = vshrl.u32 %v18452, 8 (stack45)
        %v18463 = vor.u32 %v18462, %v18461 (stack46)
        %v18464 = vxor.u32 %v18463, %v18455 (stack47)
        %v18467 = vadd.s32 %v18464, %v8 (stack39)
        %v18471 = vadd.s32 4, %v18467 (stack39)
        %v18475 = vadd.s32 %v18471, %v18459 (stack39)
        %v18477 = vshll.u32 %v18471, 13 (stack44)
        %v18478 = vshrl.u32 %v18471, 19 (stack45)
        %v18479 = vor.u32 %v18478, %v18477 (stack46)
        %v18480 = vxor.u32 %v18479, %v18475 (stack47)
        %v18483 = vadd.s32 %v18480, %v18475 (stack39)
        %v18485 = vshll.u32 %v18480, 15 (stack44)
        %v18486 = vshrl.u32 %v18480, 17 (stack45)
        %v18487 = vor.u32 %v18486, %v18485 (stack46)
        %v18488 = vxor.u32 %v18487, %v18483 (stack47)
        %v18491 = vadd.s32 %v18488, %v18483 (stack39)
        %v18493 = vshll.u32 %v18488, 26 (stack44)
        %v18494 = vshrl.u32 %v18488, 6 (stack45)
        %v18495 = vor.u32 %v18494, %v18493 (stack46)
        %v18496 = vxor.u32 %v18495, %v18491 (stack47)
        %v18499 = vadd.s32 %v18496, %v18491 (stack39)
        %v18503 = vadd.s32 %v18499, %v8 (stack39)
        %v18505 = vshll.u32 %v18496, 6 (stack44)
        %v18506 = vshrl.u32 %v18496, 26 (stack45)
        %v18507 = vor.u32 %v18506, %v18505 (stack46)
        %v18508 = vxor.u32 %v18507, %v18499 (stack47)
        %v18511 = vadd.s32 %v18508, %v10 (stack39)
        %v18515 = vadd.s32 5, %v18511 (stack39)
        %v18517 = vxor.u32 %v18515, %v18503 (stack47)
        %v18518 = vand.u32.u8 255, %v18517 (stack48)
        %v18519 = vand.u32 65535, %v18518 (stack49)
        %v18520 = vshrl.u32 %v18519, 1 (stack50)
        %v18521 = vor.u32 16256, %v18520 (stack46)
        %v18522 = vand.u32.u16 65535, %v18521 (stack51)
        %v119840 = vadd.low.f32.bf16 -1.0, %v18522 (stack52)
        %v18531 = vmul.f32 2.0, %v119840 (stack53)
        %v18535 = vadd.f32 -0.99609375, %v18531 (stack52)
        %v18539 = vmax.f32 %v18535, -0.99609375 (stack54)
        %v18541 = vand.u32 2147483647, %v18539 (stack55)
        %vm18544 = vcmp.eq.f32.partialorder %v18541, 1.0 (stack56)
        %v18549 = vmul.f32 inf, %v18539 (stack53)
        %v18551 = vxor.u32 2147483648, %v18539 (stack57)
        %v18554 = vmul.f32 %v18551, %v18539 (stack53)
        %v18556 = vadd.f32 1.0, %v18554 (stack58)
        %v18557 = vlog2.pop %v18556 (stack59)
        %v18558 = vmul.f32 0.6931472, %v18557 (stack60)
        %v18559 = vmul.f32 -0.5, %v18554 (stack61)
        %v18560 = vadd.f32 1.0, %v18559 (stack62)
        %v18561 = vmul.f32 %v18560, %v18554 (stack63)
        %v18562 = vand.u32 2147483647, %v18554 (stack64)
        %vm18563 = vcmp.lt.f32.partialorder %v18562, 0.0004427343 (stack65)
        %v18564 = vsel /*vm=*/%vm18563, /*on_true_vy=*/%v18561, /*on_false_vx=*/%v18558 (stack66)
        %v18565 = vxor.u32 2147483648, %v18564 (stack57)
        %vm18568 = vcmp.lt.f32.partialorder %v18565, 5.0 (stack56)
        %v18573 = vsel /*vm=*/%vm18568, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v18577 = vsel /*vm=*/%vm18568, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v18581 = vsel /*vm=*/%vm18568, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v18585 = vsel /*vm=*/%vm18568, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v18589 = vsel /*vm=*/%vm18568, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v18593 = vsel /*vm=*/%vm18568, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v18597 = vsel /*vm=*/%vm18568, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v18601 = vsel /*vm=*/%vm18568, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v18605 = vsel /*vm=*/%vm18568, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v18609 = vadd.f32 -2.5, %v18565 (stack52)
        %v18611 = vrsqrt.pop %v18565 (stack67)
        %v18612 = vmul.f32 %v18611, %v18565 (stack68)
        %vm18613 = vcmp.eq.f32.partialorder %v18565, inf (stack69)
        %v18614 = vsel /*vm=*/%vm18613, /*on_true_vy=*/%v18565, /*on_false_vx=*/%v18612 (stack70)
        %vm18615 = vcmp.eq.f32.partialorder %v18565, 0.0 (stack71)
        %v18616 = vand.u32 2147483648, %v18565 (stack72)
        %v18617 = vsel /*vm=*/%vm18615, /*on_true_vy=*/%v18616, /*on_false_vx=*/%v18614 (stack73)
        %v18620 = vadd.f32 -3.0, %v18617 (stack52)
        %v18624 = vsel /*vm=*/%vm18568, /*on_true_vy=*/%v18609, /*on_false_vx=*/%v18620 (stack43)
        %v18628 = vmul.f32 %v18624, %v18605 (stack53)
        %v18632 = vadd.f32 %v18628, %v18601 (stack52)
        %v18636 = vmul.f32 %v18632, %v18624 (stack53)
        %v18640 = vadd.f32 %v18636, %v18597 (stack52)
        %v18644 = vmul.f32 %v18640, %v18624 (stack53)
        %v18648 = vadd.f32 %v18644, %v18593 (stack52)
        %v18652 = vmul.f32 %v18648, %v18624 (stack53)
        %v18656 = vadd.f32 %v18652, %v18589 (stack52)
        %v18660 = vmul.f32 %v18656, %v18624 (stack53)
        %v18664 = vadd.f32 %v18660, %v18585 (stack52)
        %v18668 = vmul.f32 %v18664, %v18624 (stack53)
        %v18672 = vadd.f32 %v18668, %v18581 (stack52)
        %v18676 = vmul.f32 %v18672, %v18624 (stack53)
        %v18680 = vadd.f32 %v18676, %v18577 (stack52)
        %v18684 = vmul.f32 %v18680, %v18624 (stack53)
        %v18688 = vadd.f32 %v18684, %v18573 (stack52)
        %v18692 = vmul.f32 %v18688, %v18539 (stack53)
        %v18696 = vsel /*vm=*/%vm18544, /*on_true_vy=*/%v18549, /*on_false_vx=*/%v18692 (stack43)
        %v18700 = vmul.f32 1.4140625, %v18696 (stack53)
        %v18703 = vpack.c.bf16 0.0, %v18700 (stack74)
        %119841 = vst [vmem:[%s280 + $0x310] sm:$0xf] /*vst_source=*/%v18703 (stack75)
        %v18707 = vadd.s32 %v15477, %v3816 (stack39)
        %v18717 = vadd.s32 %v18707, %v415 (stack39)
        %vm18721 = vcmp.lt.u32.totalorder %v18717, %v18707 (stack42)
        %vm18726 = vcmp.lt.u32.totalorder %v18707, %v3816 (stack42)
        %v18731 = vadd.s32 %v15460, %v3803 (stack39)
        %v18735 = vadd.s32 1, %v18731 (stack39)
        %v18739 = vsel /*vm=*/%vm18726, /*on_true_vy=*/%v18735, /*on_false_vx=*/%v18731 (stack43)
        %v18743 = vadd.s32 1, %v18739 (stack39)
        %v18747 = vsel /*vm=*/%vm18721, /*on_true_vy=*/%v18743, /*on_false_vx=*/%v18739 (stack43)
        %v18752 = vadd.s32 %v18747, %v10 (stack39)
        %v18756 = vadd.s32 %v18717, %v9 (stack39)
        %v18760 = vadd.s32 %v18756, %v18752 (stack39)
        %v18762 = vshll.u32 %v18756, 13 (stack44)
        %v18763 = vshrl.u32 %v18756, 19 (stack45)
        %v18764 = vor.u32 %v18763, %v18762 (stack46)
        %v18765 = vxor.u32 %v18764, %v18760 (stack47)
        %v18768 = vadd.s32 %v18765, %v18760 (stack39)
        %v18770 = vshll.u32 %v18765, 15 (stack44)
        %v18771 = vshrl.u32 %v18765, 17 (stack45)
        %v18772 = vor.u32 %v18771, %v18770 (stack46)
        %v18773 = vxor.u32 %v18772, %v18768 (stack47)
        %v18776 = vadd.s32 %v18773, %v18768 (stack39)
        %v18778 = vshll.u32 %v18773, 26 (stack44)
        %v18779 = vshrl.u32 %v18773, 6 (stack45)
        %v18780 = vor.u32 %v18779, %v18778 (stack46)
        %v18781 = vxor.u32 %v18780, %v18776 (stack47)
        %v18784 = vadd.s32 %v18781, %v18776 (stack39)
        %v18788 = vadd.s32 %v18784, %v9 (stack39)
        %v18790 = vshll.u32 %v18781, 6 (stack44)
        %v18791 = vshrl.u32 %v18781, 26 (stack45)
        %v18792 = vor.u32 %v18791, %v18790 (stack46)
        %v18793 = vxor.u32 %v18792, %v18784 (stack47)
        %v18796 = vadd.s32 %v18793, %v8 (stack39)
        %v18800 = vadd.s32 1, %v18796 (stack39)
        %v18804 = vadd.s32 %v18800, %v18788 (stack39)
        %v18806 = vshll.u32 %v18800, 17 (stack44)
        %v18807 = vshrl.u32 %v18800, 15 (stack45)
        %v18808 = vor.u32 %v18807, %v18806 (stack46)
        %v18809 = vxor.u32 %v18808, %v18804 (stack47)
        %v18812 = vadd.s32 %v18809, %v18804 (stack39)
        %v18814 = vshll.u32 %v18809, 29 (stack44)
        %v18815 = vshrl.u32 %v18809, 3 (stack45)
        %v18816 = vor.u32 %v18815, %v18814 (stack46)
        %v18817 = vxor.u32 %v18816, %v18812 (stack47)
        %v18820 = vadd.s32 %v18817, %v18812 (stack39)
        %v18822 = vshll.u32 %v18817, 16 (stack44)
        %v18823 = vshrl.u32 %v18817, 16 (stack45)
        %v18824 = vor.u32 %v18823, %v18822 (stack46)
        %v18825 = vxor.u32 %v18824, %v18820 (stack47)
        %v18828 = vadd.s32 %v18825, %v18820 (stack39)
        %v18832 = vadd.s32 %v18828, %v8 (stack39)
        %v18834 = vshll.u32 %v18825, 24 (stack44)
        %v18835 = vshrl.u32 %v18825, 8 (stack45)
        %v18836 = vor.u32 %v18835, %v18834 (stack46)
        %v18837 = vxor.u32 %v18836, %v18828 (stack47)
        %v18840 = vadd.s32 %v18837, %v10 (stack39)
        %v18844 = vadd.s32 2, %v18840 (stack39)
        %v18848 = vadd.s32 %v18844, %v18832 (stack39)
        %v18850 = vshll.u32 %v18844, 13 (stack44)
        %v18851 = vshrl.u32 %v18844, 19 (stack45)
        %v18852 = vor.u32 %v18851, %v18850 (stack46)
        %v18853 = vxor.u32 %v18852, %v18848 (stack47)
        %v18856 = vadd.s32 %v18853, %v18848 (stack39)
        %v18858 = vshll.u32 %v18853, 15 (stack44)
        %v18859 = vshrl.u32 %v18853, 17 (stack45)
        %v18860 = vor.u32 %v18859, %v18858 (stack46)
        %v18861 = vxor.u32 %v18860, %v18856 (stack47)
        %v18864 = vadd.s32 %v18861, %v18856 (stack39)
        %v18866 = vshll.u32 %v18861, 26 (stack44)
        %v18867 = vshrl.u32 %v18861, 6 (stack45)
        %v18868 = vor.u32 %v18867, %v18866 (stack46)
        %v18869 = vxor.u32 %v18868, %v18864 (stack47)
        %v18872 = vadd.s32 %v18869, %v18864 (stack39)
        %v18876 = vadd.s32 %v18872, %v10 (stack39)
        %v18878 = vshll.u32 %v18869, 6 (stack44)
        %v18879 = vshrl.u32 %v18869, 26 (stack45)
        %v18880 = vor.u32 %v18879, %v18878 (stack46)
        %v18881 = vxor.u32 %v18880, %v18872 (stack47)
        %v18884 = vadd.s32 %v18881, %v9 (stack39)
        %v18888 = vadd.s32 3, %v18884 (stack39)
        %v18892 = vadd.s32 %v18888, %v18876 (stack39)
        %v18894 = vshll.u32 %v18888, 17 (stack44)
        %v18895 = vshrl.u32 %v18888, 15 (stack45)
        %v18896 = vor.u32 %v18895, %v18894 (stack46)
        %v18897 = vxor.u32 %v18896, %v18892 (stack47)
        %v18900 = vadd.s32 %v18897, %v18892 (stack39)
        %v18902 = vshll.u32 %v18897, 29 (stack44)
        %v18903 = vshrl.u32 %v18897, 3 (stack45)
        %v18904 = vor.u32 %v18903, %v18902 (stack46)
        %v18905 = vxor.u32 %v18904, %v18900 (stack47)
        %v18908 = vadd.s32 %v18905, %v18900 (stack39)
        %v18910 = vshll.u32 %v18905, 16 (stack44)
        %v18911 = vshrl.u32 %v18905, 16 (stack45)
        %v18912 = vor.u32 %v18911, %v18910 (stack46)
        %v18913 = vxor.u32 %v18912, %v18908 (stack47)
        %v18916 = vadd.s32 %v18913, %v18908 (stack39)
        %v18920 = vadd.s32 %v18916, %v9 (stack39)
        %v18922 = vshll.u32 %v18913, 24 (stack44)
        %v18923 = vshrl.u32 %v18913, 8 (stack45)
        %v18924 = vor.u32 %v18923, %v18922 (stack46)
        %v18925 = vxor.u32 %v18924, %v18916 (stack47)
        %v18928 = vadd.s32 %v18925, %v8 (stack39)
        %v18932 = vadd.s32 4, %v18928 (stack39)
        %v18936 = vadd.s32 %v18932, %v18920 (stack39)
        %v18938 = vshll.u32 %v18932, 13 (stack44)
        %v18939 = vshrl.u32 %v18932, 19 (stack45)
        %v18940 = vor.u32 %v18939, %v18938 (stack46)
        %v18941 = vxor.u32 %v18940, %v18936 (stack47)
        %v18944 = vadd.s32 %v18941, %v18936 (stack39)
        %v18946 = vshll.u32 %v18941, 15 (stack44)
        %v18947 = vshrl.u32 %v18941, 17 (stack45)
        %v18948 = vor.u32 %v18947, %v18946 (stack46)
        %v18949 = vxor.u32 %v18948, %v18944 (stack47)
        %v18952 = vadd.s32 %v18949, %v18944 (stack39)
        %v18954 = vshll.u32 %v18949, 26 (stack44)
        %v18955 = vshrl.u32 %v18949, 6 (stack45)
        %v18956 = vor.u32 %v18955, %v18954 (stack46)
        %v18957 = vxor.u32 %v18956, %v18952 (stack47)
        %v18960 = vadd.s32 %v18957, %v18952 (stack39)
        %v18964 = vadd.s32 %v18960, %v8 (stack39)
        %v18966 = vshll.u32 %v18957, 6 (stack44)
        %v18967 = vshrl.u32 %v18957, 26 (stack45)
        %v18968 = vor.u32 %v18967, %v18966 (stack46)
        %v18969 = vxor.u32 %v18968, %v18960 (stack47)
        %v18972 = vadd.s32 %v18969, %v10 (stack39)
        %v18976 = vadd.s32 5, %v18972 (stack39)
        %v18978 = vxor.u32 %v18976, %v18964 (stack47)
        %v18979 = vand.u32.u8 255, %v18978 (stack48)
        %v18980 = vand.u32 65535, %v18979 (stack49)
        %v18981 = vshrl.u32 %v18980, 1 (stack50)
        %v18982 = vor.u32 16256, %v18981 (stack46)
        %v18983 = vand.u32.u16 65535, %v18982 (stack51)
        %v119842 = vadd.low.f32.bf16 -1.0, %v18983 (stack52)
        %v18992 = vmul.f32 2.0, %v119842 (stack53)
        %v18996 = vadd.f32 -0.99609375, %v18992 (stack52)
        %v19000 = vmax.f32 %v18996, -0.99609375 (stack54)
        %v19002 = vand.u32 2147483647, %v19000 (stack55)
        %vm19005 = vcmp.eq.f32.partialorder %v19002, 1.0 (stack56)
        %v19010 = vmul.f32 inf, %v19000 (stack53)
        %v19012 = vxor.u32 2147483648, %v19000 (stack57)
        %v19015 = vmul.f32 %v19012, %v19000 (stack53)
        %v19017 = vadd.f32 1.0, %v19015 (stack58)
        %v19018 = vlog2.pop %v19017 (stack59)
        %v19019 = vmul.f32 0.6931472, %v19018 (stack60)
        %v19020 = vmul.f32 -0.5, %v19015 (stack61)
        %v19021 = vadd.f32 1.0, %v19020 (stack62)
        %v19022 = vmul.f32 %v19021, %v19015 (stack63)
        %v19023 = vand.u32 2147483647, %v19015 (stack64)
        %vm19024 = vcmp.lt.f32.partialorder %v19023, 0.0004427343 (stack65)
        %v19025 = vsel /*vm=*/%vm19024, /*on_true_vy=*/%v19022, /*on_false_vx=*/%v19019 (stack66)
        %v19026 = vxor.u32 2147483648, %v19025 (stack57)
        %vm19029 = vcmp.lt.f32.partialorder %v19026, 5.0 (stack56)
        %v19034 = vsel /*vm=*/%vm19029, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v19038 = vsel /*vm=*/%vm19029, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v19042 = vsel /*vm=*/%vm19029, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v19046 = vsel /*vm=*/%vm19029, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v19050 = vsel /*vm=*/%vm19029, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v19054 = vsel /*vm=*/%vm19029, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v19058 = vsel /*vm=*/%vm19029, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v19062 = vsel /*vm=*/%vm19029, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v19066 = vsel /*vm=*/%vm19029, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v19070 = vadd.f32 -2.5, %v19026 (stack52)
        %v19072 = vrsqrt.pop %v19026 (stack67)
        %v19073 = vmul.f32 %v19072, %v19026 (stack68)
        %vm19074 = vcmp.eq.f32.partialorder %v19026, inf (stack69)
        %v19075 = vsel /*vm=*/%vm19074, /*on_true_vy=*/%v19026, /*on_false_vx=*/%v19073 (stack70)
        %vm19076 = vcmp.eq.f32.partialorder %v19026, 0.0 (stack71)
        %v19077 = vand.u32 2147483648, %v19026 (stack72)
        %v19078 = vsel /*vm=*/%vm19076, /*on_true_vy=*/%v19077, /*on_false_vx=*/%v19075 (stack73)
        %v19081 = vadd.f32 -3.0, %v19078 (stack52)
        %v19085 = vsel /*vm=*/%vm19029, /*on_true_vy=*/%v19070, /*on_false_vx=*/%v19081 (stack43)
        %v19089 = vmul.f32 %v19085, %v19066 (stack53)
        %v19093 = vadd.f32 %v19089, %v19062 (stack52)
        %v19097 = vmul.f32 %v19093, %v19085 (stack53)
        %v19101 = vadd.f32 %v19097, %v19058 (stack52)
        %v19105 = vmul.f32 %v19101, %v19085 (stack53)
        %v19109 = vadd.f32 %v19105, %v19054 (stack52)
        %v19113 = vmul.f32 %v19109, %v19085 (stack53)
        %v19117 = vadd.f32 %v19113, %v19050 (stack52)
        %v19121 = vmul.f32 %v19117, %v19085 (stack53)
        %v19125 = vadd.f32 %v19121, %v19046 (stack52)
        %v19129 = vmul.f32 %v19125, %v19085 (stack53)
        %v19133 = vadd.f32 %v19129, %v19042 (stack52)
        %v19137 = vmul.f32 %v19133, %v19085 (stack53)
        %v19141 = vadd.f32 %v19137, %v19038 (stack52)
        %v19145 = vmul.f32 %v19141, %v19085 (stack53)
        %v19149 = vadd.f32 %v19145, %v19034 (stack52)
        %v19153 = vmul.f32 %v19149, %v19000 (stack53)
        %v19157 = vsel /*vm=*/%vm19005, /*on_true_vy=*/%v19010, /*on_false_vx=*/%v19153 (stack43)
        %v19161 = vmul.f32 1.4140625, %v19157 (stack53)
        %v19164 = vpack.c.bf16 0.0, %v19161 (stack74)
        %119843 = vst [vmem:[%s280 + $0x390] sm:$0xf] /*vst_source=*/%v19164 (stack75)
        %s19166 = sadd.s32 40, %s120390 (stack76)
        %s19167 = sshrl.u32 %s19166, 10 (stack23)
        %p119844 = scmp.gt.s32.totalorder %s19167, 1 (stack24)
        %s19169 = scalar_select /*predicate=*/%p119844, /*on_true=*/1, /*on_false=*/%s19167 (stack25)
        %s19170 = sand.u32 1023, %s19166 /* smod.u32 w/div 1024 */ (stack26)
        %s19171 = sshrl.u32 %s19170, 7 (stack27)
        %s19172 = sand.u32 127, %s19170 /* smod.u32 w/div 128 */ (stack28)
        %s119845 = sshll.u32 %s19169, 3 (stack29)
        %s19174 = scalar_lea.vmem %s3, %s119845 (stack30)
        %s19176 = scalar_lea.vmem %s19174, %s19171 (stack31)
        %v19177 = vld [vmem:[%s19176] ss:$0 sm:$0xff] (stack32)
        %s19178 = sand.u32 255, %s19172 (stack33)
        %s19180 = sor.u32 256, %s19178 (stack34)
        %19181 = vbcast.lane.b32.xlu0 %v19177, %s19180 (stack35)
        %v19182 = vpop.permute.xlu0 %19181 (stack36)
        %s19191 = scalar_lea.vmem %s5, %s119845 (stack30)
        %s19193 = scalar_lea.vmem %s19191, %s19171 (stack31)
        %v19194 = vld [vmem:[%s19193] ss:$0 sm:$0xff] (stack32)
        %19198 = vbcast.lane.b32.xlu0 %v19194, %s19180 (stack35)
        %v19199 = vpop.permute.xlu0 %19198 (stack36)
        %v19202 = vadd.s32 %v19199, %v408 (stack39)
        %v19212 = vadd.s32 %v19202, %v415 (stack39)
        %vm19216 = vcmp.lt.u32.totalorder %v19212, %v19202 (stack42)
        %vm19221 = vcmp.lt.u32.totalorder %v19202, %v408 (stack42)
        %v19226 = vadd.s32 %v19182, %v380 (stack39)
        %v19230 = vadd.s32 1, %v19226 (stack39)
        %v19234 = vsel /*vm=*/%vm19221, /*on_true_vy=*/%v19230, /*on_false_vx=*/%v19226 (stack43)
        %v19238 = vadd.s32 1, %v19234 (stack39)
        %v19242 = vsel /*vm=*/%vm19216, /*on_true_vy=*/%v19238, /*on_false_vx=*/%v19234 (stack43)
        %v19247 = vadd.s32 %v19242, %v10 (stack39)
        %v19251 = vadd.s32 %v19212, %v9 (stack39)
        %v19255 = vadd.s32 %v19251, %v19247 (stack39)
        %v19257 = vshll.u32 %v19251, 13 (stack44)
        %v19258 = vshrl.u32 %v19251, 19 (stack45)
        %v19259 = vor.u32 %v19258, %v19257 (stack46)
        %v19260 = vxor.u32 %v19259, %v19255 (stack47)
        %v19263 = vadd.s32 %v19260, %v19255 (stack39)
        %v19265 = vshll.u32 %v19260, 15 (stack44)
        %v19266 = vshrl.u32 %v19260, 17 (stack45)
        %v19267 = vor.u32 %v19266, %v19265 (stack46)
        %v19268 = vxor.u32 %v19267, %v19263 (stack47)
        %v19271 = vadd.s32 %v19268, %v19263 (stack39)
        %v19273 = vshll.u32 %v19268, 26 (stack44)
        %v19274 = vshrl.u32 %v19268, 6 (stack45)
        %v19275 = vor.u32 %v19274, %v19273 (stack46)
        %v19276 = vxor.u32 %v19275, %v19271 (stack47)
        %v19279 = vadd.s32 %v19276, %v19271 (stack39)
        %v19283 = vadd.s32 %v19279, %v9 (stack39)
        %v19285 = vshll.u32 %v19276, 6 (stack44)
        %v19286 = vshrl.u32 %v19276, 26 (stack45)
        %v19287 = vor.u32 %v19286, %v19285 (stack46)
        %v19288 = vxor.u32 %v19287, %v19279 (stack47)
        %v19291 = vadd.s32 %v19288, %v8 (stack39)
        %v19295 = vadd.s32 1, %v19291 (stack39)
        %v19299 = vadd.s32 %v19295, %v19283 (stack39)
        %v19301 = vshll.u32 %v19295, 17 (stack44)
        %v19302 = vshrl.u32 %v19295, 15 (stack45)
        %v19303 = vor.u32 %v19302, %v19301 (stack46)
        %v19304 = vxor.u32 %v19303, %v19299 (stack47)
        %v19307 = vadd.s32 %v19304, %v19299 (stack39)
        %v19309 = vshll.u32 %v19304, 29 (stack44)
        %v19310 = vshrl.u32 %v19304, 3 (stack45)
        %v19311 = vor.u32 %v19310, %v19309 (stack46)
        %v19312 = vxor.u32 %v19311, %v19307 (stack47)
        %v19315 = vadd.s32 %v19312, %v19307 (stack39)
        %v19317 = vshll.u32 %v19312, 16 (stack44)
        %v19318 = vshrl.u32 %v19312, 16 (stack45)
        %v19319 = vor.u32 %v19318, %v19317 (stack46)
        %v19320 = vxor.u32 %v19319, %v19315 (stack47)
        %v19323 = vadd.s32 %v19320, %v19315 (stack39)
        %v19327 = vadd.s32 %v19323, %v8 (stack39)
        %v19329 = vshll.u32 %v19320, 24 (stack44)
        %v19330 = vshrl.u32 %v19320, 8 (stack45)
        %v19331 = vor.u32 %v19330, %v19329 (stack46)
        %v19332 = vxor.u32 %v19331, %v19323 (stack47)
        %v19335 = vadd.s32 %v19332, %v10 (stack39)
        %v19339 = vadd.s32 2, %v19335 (stack39)
        %v19343 = vadd.s32 %v19339, %v19327 (stack39)
        %v19345 = vshll.u32 %v19339, 13 (stack44)
        %v19346 = vshrl.u32 %v19339, 19 (stack45)
        %v19347 = vor.u32 %v19346, %v19345 (stack46)
        %v19348 = vxor.u32 %v19347, %v19343 (stack47)
        %v19351 = vadd.s32 %v19348, %v19343 (stack39)
        %v19353 = vshll.u32 %v19348, 15 (stack44)
        %v19354 = vshrl.u32 %v19348, 17 (stack45)
        %v19355 = vor.u32 %v19354, %v19353 (stack46)
        %v19356 = vxor.u32 %v19355, %v19351 (stack47)
        %v19359 = vadd.s32 %v19356, %v19351 (stack39)
        %v19361 = vshll.u32 %v19356, 26 (stack44)
        %v19362 = vshrl.u32 %v19356, 6 (stack45)
        %v19363 = vor.u32 %v19362, %v19361 (stack46)
        %v19364 = vxor.u32 %v19363, %v19359 (stack47)
        %v19367 = vadd.s32 %v19364, %v19359 (stack39)
        %v19371 = vadd.s32 %v19367, %v10 (stack39)
        %v19373 = vshll.u32 %v19364, 6 (stack44)
        %v19374 = vshrl.u32 %v19364, 26 (stack45)
        %v19375 = vor.u32 %v19374, %v19373 (stack46)
        %v19376 = vxor.u32 %v19375, %v19367 (stack47)
        %v19379 = vadd.s32 %v19376, %v9 (stack39)
        %v19383 = vadd.s32 3, %v19379 (stack39)
        %v19387 = vadd.s32 %v19383, %v19371 (stack39)
        %v19389 = vshll.u32 %v19383, 17 (stack44)
        %v19390 = vshrl.u32 %v19383, 15 (stack45)
        %v19391 = vor.u32 %v19390, %v19389 (stack46)
        %v19392 = vxor.u32 %v19391, %v19387 (stack47)
        %v19395 = vadd.s32 %v19392, %v19387 (stack39)
        %v19397 = vshll.u32 %v19392, 29 (stack44)
        %v19398 = vshrl.u32 %v19392, 3 (stack45)
        %v19399 = vor.u32 %v19398, %v19397 (stack46)
        %v19400 = vxor.u32 %v19399, %v19395 (stack47)
        %v19403 = vadd.s32 %v19400, %v19395 (stack39)
        %v19405 = vshll.u32 %v19400, 16 (stack44)
        %v19406 = vshrl.u32 %v19400, 16 (stack45)
        %v19407 = vor.u32 %v19406, %v19405 (stack46)
        %v19408 = vxor.u32 %v19407, %v19403 (stack47)
        %v19411 = vadd.s32 %v19408, %v19403 (stack39)
        %v19415 = vadd.s32 %v19411, %v9 (stack39)
        %v19417 = vshll.u32 %v19408, 24 (stack44)
        %v19418 = vshrl.u32 %v19408, 8 (stack45)
        %v19419 = vor.u32 %v19418, %v19417 (stack46)
        %v19420 = vxor.u32 %v19419, %v19411 (stack47)
        %v19423 = vadd.s32 %v19420, %v8 (stack39)
        %v19427 = vadd.s32 4, %v19423 (stack39)
        %v19431 = vadd.s32 %v19427, %v19415 (stack39)
        %v19433 = vshll.u32 %v19427, 13 (stack44)
        %v19434 = vshrl.u32 %v19427, 19 (stack45)
        %v19435 = vor.u32 %v19434, %v19433 (stack46)
        %v19436 = vxor.u32 %v19435, %v19431 (stack47)
        %v19439 = vadd.s32 %v19436, %v19431 (stack39)
        %v19441 = vshll.u32 %v19436, 15 (stack44)
        %v19442 = vshrl.u32 %v19436, 17 (stack45)
        %v19443 = vor.u32 %v19442, %v19441 (stack46)
        %v19444 = vxor.u32 %v19443, %v19439 (stack47)
        %v19447 = vadd.s32 %v19444, %v19439 (stack39)
        %v19449 = vshll.u32 %v19444, 26 (stack44)
        %v19450 = vshrl.u32 %v19444, 6 (stack45)
        %v19451 = vor.u32 %v19450, %v19449 (stack46)
        %v19452 = vxor.u32 %v19451, %v19447 (stack47)
        %v19455 = vadd.s32 %v19452, %v19447 (stack39)
        %v19459 = vadd.s32 %v19455, %v8 (stack39)
        %v19461 = vshll.u32 %v19452, 6 (stack44)
        %v19462 = vshrl.u32 %v19452, 26 (stack45)
        %v19463 = vor.u32 %v19462, %v19461 (stack46)
        %v19464 = vxor.u32 %v19463, %v19455 (stack47)
        %v19467 = vadd.s32 %v19464, %v10 (stack39)
        %v19471 = vadd.s32 5, %v19467 (stack39)
        %v19473 = vxor.u32 %v19471, %v19459 (stack47)
        %v19474 = vand.u32.u8 255, %v19473 (stack48)
        %v19475 = vand.u32 65535, %v19474 (stack49)
        %v19476 = vshrl.u32 %v19475, 1 (stack50)
        %v19477 = vor.u32 16256, %v19476 (stack46)
        %v19478 = vand.u32.u16 65535, %v19477 (stack51)
        %v119848 = vadd.low.f32.bf16 -1.0, %v19478 (stack52)
        %v19487 = vmul.f32 2.0, %v119848 (stack53)
        %v19491 = vadd.f32 -0.99609375, %v19487 (stack52)
        %v19495 = vmax.f32 %v19491, -0.99609375 (stack54)
        %v19497 = vand.u32 2147483647, %v19495 (stack55)
        %vm19500 = vcmp.eq.f32.partialorder %v19497, 1.0 (stack56)
        %v19505 = vmul.f32 inf, %v19495 (stack53)
        %v19507 = vxor.u32 2147483648, %v19495 (stack57)
        %v19510 = vmul.f32 %v19507, %v19495 (stack53)
        %v19512 = vadd.f32 1.0, %v19510 (stack58)
        %v19513 = vlog2.pop %v19512 (stack59)
        %v19514 = vmul.f32 0.6931472, %v19513 (stack60)
        %v19515 = vmul.f32 -0.5, %v19510 (stack61)
        %v19516 = vadd.f32 1.0, %v19515 (stack62)
        %v19517 = vmul.f32 %v19516, %v19510 (stack63)
        %v19518 = vand.u32 2147483647, %v19510 (stack64)
        %vm19519 = vcmp.lt.f32.partialorder %v19518, 0.0004427343 (stack65)
        %v19520 = vsel /*vm=*/%vm19519, /*on_true_vy=*/%v19517, /*on_false_vx=*/%v19514 (stack66)
        %v19521 = vxor.u32 2147483648, %v19520 (stack57)
        %vm19524 = vcmp.lt.f32.partialorder %v19521, 5.0 (stack56)
        %v19529 = vsel /*vm=*/%vm19524, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v19533 = vsel /*vm=*/%vm19524, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v19537 = vsel /*vm=*/%vm19524, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v19541 = vsel /*vm=*/%vm19524, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v19545 = vsel /*vm=*/%vm19524, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v19549 = vsel /*vm=*/%vm19524, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v19553 = vsel /*vm=*/%vm19524, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v19557 = vsel /*vm=*/%vm19524, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v19561 = vsel /*vm=*/%vm19524, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v19565 = vadd.f32 -2.5, %v19521 (stack52)
        %v19567 = vrsqrt.pop %v19521 (stack67)
        %v19568 = vmul.f32 %v19567, %v19521 (stack68)
        %vm19569 = vcmp.eq.f32.partialorder %v19521, inf (stack69)
        %v19570 = vsel /*vm=*/%vm19569, /*on_true_vy=*/%v19521, /*on_false_vx=*/%v19568 (stack70)
        %vm19571 = vcmp.eq.f32.partialorder %v19521, 0.0 (stack71)
        %v19572 = vand.u32 2147483648, %v19521 (stack72)
        %v19573 = vsel /*vm=*/%vm19571, /*on_true_vy=*/%v19572, /*on_false_vx=*/%v19570 (stack73)
        %v19576 = vadd.f32 -3.0, %v19573 (stack52)
        %v19580 = vsel /*vm=*/%vm19524, /*on_true_vy=*/%v19565, /*on_false_vx=*/%v19576 (stack43)
        %v19584 = vmul.f32 %v19580, %v19561 (stack53)
        %v19588 = vadd.f32 %v19584, %v19557 (stack52)
        %v19592 = vmul.f32 %v19588, %v19580 (stack53)
        %v19596 = vadd.f32 %v19592, %v19553 (stack52)
        %v19600 = vmul.f32 %v19596, %v19580 (stack53)
        %v19604 = vadd.f32 %v19600, %v19549 (stack52)
        %v19608 = vmul.f32 %v19604, %v19580 (stack53)
        %v19612 = vadd.f32 %v19608, %v19545 (stack52)
        %v19616 = vmul.f32 %v19612, %v19580 (stack53)
        %v19620 = vadd.f32 %v19616, %v19541 (stack52)
        %v19624 = vmul.f32 %v19620, %v19580 (stack53)
        %v19628 = vadd.f32 %v19624, %v19537 (stack52)
        %v19632 = vmul.f32 %v19628, %v19580 (stack53)
        %v19636 = vadd.f32 %v19632, %v19533 (stack52)
        %v19640 = vmul.f32 %v19636, %v19580 (stack53)
        %v19644 = vadd.f32 %v19640, %v19529 (stack52)
        %v19648 = vmul.f32 %v19644, %v19495 (stack53)
        %v19652 = vsel /*vm=*/%vm19500, /*on_true_vy=*/%v19505, /*on_false_vx=*/%v19648 (stack43)
        %v19656 = vmul.f32 1.4140625, %v19652 (stack53)
        %v19659 = vpack.c.bf16 0.0, %v19656 (stack74)
        %119849 = vst [vmem:[%s280 + $0x14] sm:$0xf] /*vst_source=*/%v19659 (stack75)
        %v19663 = vadd.s32 %v19199, %v894 (stack39)
        %v19673 = vadd.s32 %v19663, %v415 (stack39)
        %vm19677 = vcmp.lt.u32.totalorder %v19673, %v19663 (stack42)
        %vm19682 = vcmp.lt.u32.totalorder %v19663, %v894 (stack42)
        %v19687 = vadd.s32 %v19182, %v881 (stack39)
        %v19691 = vadd.s32 1, %v19687 (stack39)
        %v19695 = vsel /*vm=*/%vm19682, /*on_true_vy=*/%v19691, /*on_false_vx=*/%v19687 (stack43)
        %v19699 = vadd.s32 1, %v19695 (stack39)
        %v19703 = vsel /*vm=*/%vm19677, /*on_true_vy=*/%v19699, /*on_false_vx=*/%v19695 (stack43)
        %v19708 = vadd.s32 %v19703, %v10 (stack39)
        %v19712 = vadd.s32 %v19673, %v9 (stack39)
        %v19716 = vadd.s32 %v19712, %v19708 (stack39)
        %v19718 = vshll.u32 %v19712, 13 (stack44)
        %v19719 = vshrl.u32 %v19712, 19 (stack45)
        %v19720 = vor.u32 %v19719, %v19718 (stack46)
        %v19721 = vxor.u32 %v19720, %v19716 (stack47)
        %v19724 = vadd.s32 %v19721, %v19716 (stack39)
        %v19726 = vshll.u32 %v19721, 15 (stack44)
        %v19727 = vshrl.u32 %v19721, 17 (stack45)
        %v19728 = vor.u32 %v19727, %v19726 (stack46)
        %v19729 = vxor.u32 %v19728, %v19724 (stack47)
        %v19732 = vadd.s32 %v19729, %v19724 (stack39)
        %v19734 = vshll.u32 %v19729, 26 (stack44)
        %v19735 = vshrl.u32 %v19729, 6 (stack45)
        %v19736 = vor.u32 %v19735, %v19734 (stack46)
        %v19737 = vxor.u32 %v19736, %v19732 (stack47)
        %v19740 = vadd.s32 %v19737, %v19732 (stack39)
        %v19744 = vadd.s32 %v19740, %v9 (stack39)
        %v19746 = vshll.u32 %v19737, 6 (stack44)
        %v19747 = vshrl.u32 %v19737, 26 (stack45)
        %v19748 = vor.u32 %v19747, %v19746 (stack46)
        %v19749 = vxor.u32 %v19748, %v19740 (stack47)
        %v19752 = vadd.s32 %v19749, %v8 (stack39)
        %v19756 = vadd.s32 1, %v19752 (stack39)
        %v19760 = vadd.s32 %v19756, %v19744 (stack39)
        %v19762 = vshll.u32 %v19756, 17 (stack44)
        %v19763 = vshrl.u32 %v19756, 15 (stack45)
        %v19764 = vor.u32 %v19763, %v19762 (stack46)
        %v19765 = vxor.u32 %v19764, %v19760 (stack47)
        %v19768 = vadd.s32 %v19765, %v19760 (stack39)
        %v19770 = vshll.u32 %v19765, 29 (stack44)
        %v19771 = vshrl.u32 %v19765, 3 (stack45)
        %v19772 = vor.u32 %v19771, %v19770 (stack46)
        %v19773 = vxor.u32 %v19772, %v19768 (stack47)
        %v19776 = vadd.s32 %v19773, %v19768 (stack39)
        %v19778 = vshll.u32 %v19773, 16 (stack44)
        %v19779 = vshrl.u32 %v19773, 16 (stack45)
        %v19780 = vor.u32 %v19779, %v19778 (stack46)
        %v19781 = vxor.u32 %v19780, %v19776 (stack47)
        %v19784 = vadd.s32 %v19781, %v19776 (stack39)
        %v19788 = vadd.s32 %v19784, %v8 (stack39)
        %v19790 = vshll.u32 %v19781, 24 (stack44)
        %v19791 = vshrl.u32 %v19781, 8 (stack45)
        %v19792 = vor.u32 %v19791, %v19790 (stack46)
        %v19793 = vxor.u32 %v19792, %v19784 (stack47)
        %v19796 = vadd.s32 %v19793, %v10 (stack39)
        %v19800 = vadd.s32 2, %v19796 (stack39)
        %v19804 = vadd.s32 %v19800, %v19788 (stack39)
        %v19806 = vshll.u32 %v19800, 13 (stack44)
        %v19807 = vshrl.u32 %v19800, 19 (stack45)
        %v19808 = vor.u32 %v19807, %v19806 (stack46)
        %v19809 = vxor.u32 %v19808, %v19804 (stack47)
        %v19812 = vadd.s32 %v19809, %v19804 (stack39)
        %v19814 = vshll.u32 %v19809, 15 (stack44)
        %v19815 = vshrl.u32 %v19809, 17 (stack45)
        %v19816 = vor.u32 %v19815, %v19814 (stack46)
        %v19817 = vxor.u32 %v19816, %v19812 (stack47)
        %v19820 = vadd.s32 %v19817, %v19812 (stack39)
        %v19822 = vshll.u32 %v19817, 26 (stack44)
        %v19823 = vshrl.u32 %v19817, 6 (stack45)
        %v19824 = vor.u32 %v19823, %v19822 (stack46)
        %v19825 = vxor.u32 %v19824, %v19820 (stack47)
        %v19828 = vadd.s32 %v19825, %v19820 (stack39)
        %v19832 = vadd.s32 %v19828, %v10 (stack39)
        %v19834 = vshll.u32 %v19825, 6 (stack44)
        %v19835 = vshrl.u32 %v19825, 26 (stack45)
        %v19836 = vor.u32 %v19835, %v19834 (stack46)
        %v19837 = vxor.u32 %v19836, %v19828 (stack47)
        %v19840 = vadd.s32 %v19837, %v9 (stack39)
        %v19844 = vadd.s32 3, %v19840 (stack39)
        %v19848 = vadd.s32 %v19844, %v19832 (stack39)
        %v19850 = vshll.u32 %v19844, 17 (stack44)
        %v19851 = vshrl.u32 %v19844, 15 (stack45)
        %v19852 = vor.u32 %v19851, %v19850 (stack46)
        %v19853 = vxor.u32 %v19852, %v19848 (stack47)
        %v19856 = vadd.s32 %v19853, %v19848 (stack39)
        %v19858 = vshll.u32 %v19853, 29 (stack44)
        %v19859 = vshrl.u32 %v19853, 3 (stack45)
        %v19860 = vor.u32 %v19859, %v19858 (stack46)
        %v19861 = vxor.u32 %v19860, %v19856 (stack47)
        %v19864 = vadd.s32 %v19861, %v19856 (stack39)
        %v19866 = vshll.u32 %v19861, 16 (stack44)
        %v19867 = vshrl.u32 %v19861, 16 (stack45)
        %v19868 = vor.u32 %v19867, %v19866 (stack46)
        %v19869 = vxor.u32 %v19868, %v19864 (stack47)
        %v19872 = vadd.s32 %v19869, %v19864 (stack39)
        %v19876 = vadd.s32 %v19872, %v9 (stack39)
        %v19878 = vshll.u32 %v19869, 24 (stack44)
        %v19879 = vshrl.u32 %v19869, 8 (stack45)
        %v19880 = vor.u32 %v19879, %v19878 (stack46)
        %v19881 = vxor.u32 %v19880, %v19872 (stack47)
        %v19884 = vadd.s32 %v19881, %v8 (stack39)
        %v19888 = vadd.s32 4, %v19884 (stack39)
        %v19892 = vadd.s32 %v19888, %v19876 (stack39)
        %v19894 = vshll.u32 %v19888, 13 (stack44)
        %v19895 = vshrl.u32 %v19888, 19 (stack45)
        %v19896 = vor.u32 %v19895, %v19894 (stack46)
        %v19897 = vxor.u32 %v19896, %v19892 (stack47)
        %v19900 = vadd.s32 %v19897, %v19892 (stack39)
        %v19902 = vshll.u32 %v19897, 15 (stack44)
        %v19903 = vshrl.u32 %v19897, 17 (stack45)
        %v19904 = vor.u32 %v19903, %v19902 (stack46)
        %v19905 = vxor.u32 %v19904, %v19900 (stack47)
        %v19908 = vadd.s32 %v19905, %v19900 (stack39)
        %v19910 = vshll.u32 %v19905, 26 (stack44)
        %v19911 = vshrl.u32 %v19905, 6 (stack45)
        %v19912 = vor.u32 %v19911, %v19910 (stack46)
        %v19913 = vxor.u32 %v19912, %v19908 (stack47)
        %v19916 = vadd.s32 %v19913, %v19908 (stack39)
        %v19920 = vadd.s32 %v19916, %v8 (stack39)
        %v19922 = vshll.u32 %v19913, 6 (stack44)
        %v19923 = vshrl.u32 %v19913, 26 (stack45)
        %v19924 = vor.u32 %v19923, %v19922 (stack46)
        %v19925 = vxor.u32 %v19924, %v19916 (stack47)
        %v19928 = vadd.s32 %v19925, %v10 (stack39)
        %v19932 = vadd.s32 5, %v19928 (stack39)
        %v19934 = vxor.u32 %v19932, %v19920 (stack47)
        %v19935 = vand.u32.u8 255, %v19934 (stack48)
        %v19936 = vand.u32 65535, %v19935 (stack49)
        %v19937 = vshrl.u32 %v19936, 1 (stack50)
        %v19938 = vor.u32 16256, %v19937 (stack46)
        %v19939 = vand.u32.u16 65535, %v19938 (stack51)
        %v119850 = vadd.low.f32.bf16 -1.0, %v19939 (stack52)
        %v19948 = vmul.f32 2.0, %v119850 (stack53)
        %v19952 = vadd.f32 -0.99609375, %v19948 (stack52)
        %v19956 = vmax.f32 %v19952, -0.99609375 (stack54)
        %v19958 = vand.u32 2147483647, %v19956 (stack55)
        %vm19961 = vcmp.eq.f32.partialorder %v19958, 1.0 (stack56)
        %v19966 = vmul.f32 inf, %v19956 (stack53)
        %v19968 = vxor.u32 2147483648, %v19956 (stack57)
        %v19971 = vmul.f32 %v19968, %v19956 (stack53)
        %v19973 = vadd.f32 1.0, %v19971 (stack58)
        %v19974 = vlog2.pop %v19973 (stack59)
        %v19975 = vmul.f32 0.6931472, %v19974 (stack60)
        %v19976 = vmul.f32 -0.5, %v19971 (stack61)
        %v19977 = vadd.f32 1.0, %v19976 (stack62)
        %v19978 = vmul.f32 %v19977, %v19971 (stack63)
        %v19979 = vand.u32 2147483647, %v19971 (stack64)
        %vm19980 = vcmp.lt.f32.partialorder %v19979, 0.0004427343 (stack65)
        %v19981 = vsel /*vm=*/%vm19980, /*on_true_vy=*/%v19978, /*on_false_vx=*/%v19975 (stack66)
        %v19982 = vxor.u32 2147483648, %v19981 (stack57)
        %vm19985 = vcmp.lt.f32.partialorder %v19982, 5.0 (stack56)
        %v19990 = vsel /*vm=*/%vm19985, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v19994 = vsel /*vm=*/%vm19985, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v19998 = vsel /*vm=*/%vm19985, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v20002 = vsel /*vm=*/%vm19985, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v20006 = vsel /*vm=*/%vm19985, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v20010 = vsel /*vm=*/%vm19985, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v20014 = vsel /*vm=*/%vm19985, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v20018 = vsel /*vm=*/%vm19985, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v20022 = vsel /*vm=*/%vm19985, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v20026 = vadd.f32 -2.5, %v19982 (stack52)
        %v20028 = vrsqrt.pop %v19982 (stack67)
        %v20029 = vmul.f32 %v20028, %v19982 (stack68)
        %vm20030 = vcmp.eq.f32.partialorder %v19982, inf (stack69)
        %v20031 = vsel /*vm=*/%vm20030, /*on_true_vy=*/%v19982, /*on_false_vx=*/%v20029 (stack70)
        %vm20032 = vcmp.eq.f32.partialorder %v19982, 0.0 (stack71)
        %v20033 = vand.u32 2147483648, %v19982 (stack72)
        %v20034 = vsel /*vm=*/%vm20032, /*on_true_vy=*/%v20033, /*on_false_vx=*/%v20031 (stack73)
        %v20037 = vadd.f32 -3.0, %v20034 (stack52)
        %v20041 = vsel /*vm=*/%vm19985, /*on_true_vy=*/%v20026, /*on_false_vx=*/%v20037 (stack43)
        %v20045 = vmul.f32 %v20041, %v20022 (stack53)
        %v20049 = vadd.f32 %v20045, %v20018 (stack52)
        %v20053 = vmul.f32 %v20049, %v20041 (stack53)
        %v20057 = vadd.f32 %v20053, %v20014 (stack52)
        %v20061 = vmul.f32 %v20057, %v20041 (stack53)
        %v20065 = vadd.f32 %v20061, %v20010 (stack52)
        %v20069 = vmul.f32 %v20065, %v20041 (stack53)
        %v20073 = vadd.f32 %v20069, %v20006 (stack52)
        %v20077 = vmul.f32 %v20073, %v20041 (stack53)
        %v20081 = vadd.f32 %v20077, %v20002 (stack52)
        %v20085 = vmul.f32 %v20081, %v20041 (stack53)
        %v20089 = vadd.f32 %v20085, %v19998 (stack52)
        %v20093 = vmul.f32 %v20089, %v20041 (stack53)
        %v20097 = vadd.f32 %v20093, %v19994 (stack52)
        %v20101 = vmul.f32 %v20097, %v20041 (stack53)
        %v20105 = vadd.f32 %v20101, %v19990 (stack52)
        %v20109 = vmul.f32 %v20105, %v19956 (stack53)
        %v20113 = vsel /*vm=*/%vm19961, /*on_true_vy=*/%v19966, /*on_false_vx=*/%v20109 (stack43)
        %v20117 = vmul.f32 1.4140625, %v20113 (stack53)
        %v20120 = vpack.c.bf16 0.0, %v20117 (stack74)
        %119851 = vst [vmem:[%s280 + $0x94] sm:$0xf] /*vst_source=*/%v20120 (stack75)
        %v20124 = vadd.s32 %v19199, %v1381 (stack39)
        %v20134 = vadd.s32 %v20124, %v415 (stack39)
        %vm20138 = vcmp.lt.u32.totalorder %v20134, %v20124 (stack42)
        %vm20143 = vcmp.lt.u32.totalorder %v20124, %v1381 (stack42)
        %v20148 = vadd.s32 %v19182, %v1368 (stack39)
        %v20152 = vadd.s32 1, %v20148 (stack39)
        %v20156 = vsel /*vm=*/%vm20143, /*on_true_vy=*/%v20152, /*on_false_vx=*/%v20148 (stack43)
        %v20160 = vadd.s32 1, %v20156 (stack39)
        %v20164 = vsel /*vm=*/%vm20138, /*on_true_vy=*/%v20160, /*on_false_vx=*/%v20156 (stack43)
        %v20169 = vadd.s32 %v20164, %v10 (stack39)
        %v20173 = vadd.s32 %v20134, %v9 (stack39)
        %v20177 = vadd.s32 %v20173, %v20169 (stack39)
        %v20179 = vshll.u32 %v20173, 13 (stack44)
        %v20180 = vshrl.u32 %v20173, 19 (stack45)
        %v20181 = vor.u32 %v20180, %v20179 (stack46)
        %v20182 = vxor.u32 %v20181, %v20177 (stack47)
        %v20185 = vadd.s32 %v20182, %v20177 (stack39)
        %v20187 = vshll.u32 %v20182, 15 (stack44)
        %v20188 = vshrl.u32 %v20182, 17 (stack45)
        %v20189 = vor.u32 %v20188, %v20187 (stack46)
        %v20190 = vxor.u32 %v20189, %v20185 (stack47)
        %v20193 = vadd.s32 %v20190, %v20185 (stack39)
        %v20195 = vshll.u32 %v20190, 26 (stack44)
        %v20196 = vshrl.u32 %v20190, 6 (stack45)
        %v20197 = vor.u32 %v20196, %v20195 (stack46)
        %v20198 = vxor.u32 %v20197, %v20193 (stack47)
        %v20201 = vadd.s32 %v20198, %v20193 (stack39)
        %v20205 = vadd.s32 %v20201, %v9 (stack39)
        %v20207 = vshll.u32 %v20198, 6 (stack44)
        %v20208 = vshrl.u32 %v20198, 26 (stack45)
        %v20209 = vor.u32 %v20208, %v20207 (stack46)
        %v20210 = vxor.u32 %v20209, %v20201 (stack47)
        %v20213 = vadd.s32 %v20210, %v8 (stack39)
        %v20217 = vadd.s32 1, %v20213 (stack39)
        %v20221 = vadd.s32 %v20217, %v20205 (stack39)
        %v20223 = vshll.u32 %v20217, 17 (stack44)
        %v20224 = vshrl.u32 %v20217, 15 (stack45)
        %v20225 = vor.u32 %v20224, %v20223 (stack46)
        %v20226 = vxor.u32 %v20225, %v20221 (stack47)
        %v20229 = vadd.s32 %v20226, %v20221 (stack39)
        %v20231 = vshll.u32 %v20226, 29 (stack44)
        %v20232 = vshrl.u32 %v20226, 3 (stack45)
        %v20233 = vor.u32 %v20232, %v20231 (stack46)
        %v20234 = vxor.u32 %v20233, %v20229 (stack47)
        %v20237 = vadd.s32 %v20234, %v20229 (stack39)
        %v20239 = vshll.u32 %v20234, 16 (stack44)
        %v20240 = vshrl.u32 %v20234, 16 (stack45)
        %v20241 = vor.u32 %v20240, %v20239 (stack46)
        %v20242 = vxor.u32 %v20241, %v20237 (stack47)
        %v20245 = vadd.s32 %v20242, %v20237 (stack39)
        %v20249 = vadd.s32 %v20245, %v8 (stack39)
        %v20251 = vshll.u32 %v20242, 24 (stack44)
        %v20252 = vshrl.u32 %v20242, 8 (stack45)
        %v20253 = vor.u32 %v20252, %v20251 (stack46)
        %v20254 = vxor.u32 %v20253, %v20245 (stack47)
        %v20257 = vadd.s32 %v20254, %v10 (stack39)
        %v20261 = vadd.s32 2, %v20257 (stack39)
        %v20265 = vadd.s32 %v20261, %v20249 (stack39)
        %v20267 = vshll.u32 %v20261, 13 (stack44)
        %v20268 = vshrl.u32 %v20261, 19 (stack45)
        %v20269 = vor.u32 %v20268, %v20267 (stack46)
        %v20270 = vxor.u32 %v20269, %v20265 (stack47)
        %v20273 = vadd.s32 %v20270, %v20265 (stack39)
        %v20275 = vshll.u32 %v20270, 15 (stack44)
        %v20276 = vshrl.u32 %v20270, 17 (stack45)
        %v20277 = vor.u32 %v20276, %v20275 (stack46)
        %v20278 = vxor.u32 %v20277, %v20273 (stack47)
        %v20281 = vadd.s32 %v20278, %v20273 (stack39)
        %v20283 = vshll.u32 %v20278, 26 (stack44)
        %v20284 = vshrl.u32 %v20278, 6 (stack45)
        %v20285 = vor.u32 %v20284, %v20283 (stack46)
        %v20286 = vxor.u32 %v20285, %v20281 (stack47)
        %v20289 = vadd.s32 %v20286, %v20281 (stack39)
        %v20293 = vadd.s32 %v20289, %v10 (stack39)
        %v20295 = vshll.u32 %v20286, 6 (stack44)
        %v20296 = vshrl.u32 %v20286, 26 (stack45)
        %v20297 = vor.u32 %v20296, %v20295 (stack46)
        %v20298 = vxor.u32 %v20297, %v20289 (stack47)
        %v20301 = vadd.s32 %v20298, %v9 (stack39)
        %v20305 = vadd.s32 3, %v20301 (stack39)
        %v20309 = vadd.s32 %v20305, %v20293 (stack39)
        %v20311 = vshll.u32 %v20305, 17 (stack44)
        %v20312 = vshrl.u32 %v20305, 15 (stack45)
        %v20313 = vor.u32 %v20312, %v20311 (stack46)
        %v20314 = vxor.u32 %v20313, %v20309 (stack47)
        %v20317 = vadd.s32 %v20314, %v20309 (stack39)
        %v20319 = vshll.u32 %v20314, 29 (stack44)
        %v20320 = vshrl.u32 %v20314, 3 (stack45)
        %v20321 = vor.u32 %v20320, %v20319 (stack46)
        %v20322 = vxor.u32 %v20321, %v20317 (stack47)
        %v20325 = vadd.s32 %v20322, %v20317 (stack39)
        %v20327 = vshll.u32 %v20322, 16 (stack44)
        %v20328 = vshrl.u32 %v20322, 16 (stack45)
        %v20329 = vor.u32 %v20328, %v20327 (stack46)
        %v20330 = vxor.u32 %v20329, %v20325 (stack47)
        %v20333 = vadd.s32 %v20330, %v20325 (stack39)
        %v20337 = vadd.s32 %v20333, %v9 (stack39)
        %v20339 = vshll.u32 %v20330, 24 (stack44)
        %v20340 = vshrl.u32 %v20330, 8 (stack45)
        %v20341 = vor.u32 %v20340, %v20339 (stack46)
        %v20342 = vxor.u32 %v20341, %v20333 (stack47)
        %v20345 = vadd.s32 %v20342, %v8 (stack39)
        %v20349 = vadd.s32 4, %v20345 (stack39)
        %v20353 = vadd.s32 %v20349, %v20337 (stack39)
        %v20355 = vshll.u32 %v20349, 13 (stack44)
        %v20356 = vshrl.u32 %v20349, 19 (stack45)
        %v20357 = vor.u32 %v20356, %v20355 (stack46)
        %v20358 = vxor.u32 %v20357, %v20353 (stack47)
        %v20361 = vadd.s32 %v20358, %v20353 (stack39)
        %v20363 = vshll.u32 %v20358, 15 (stack44)
        %v20364 = vshrl.u32 %v20358, 17 (stack45)
        %v20365 = vor.u32 %v20364, %v20363 (stack46)
        %v20366 = vxor.u32 %v20365, %v20361 (stack47)
        %v20369 = vadd.s32 %v20366, %v20361 (stack39)
        %v20371 = vshll.u32 %v20366, 26 (stack44)
        %v20372 = vshrl.u32 %v20366, 6 (stack45)
        %v20373 = vor.u32 %v20372, %v20371 (stack46)
        %v20374 = vxor.u32 %v20373, %v20369 (stack47)
        %v20377 = vadd.s32 %v20374, %v20369 (stack39)
        %v20381 = vadd.s32 %v20377, %v8 (stack39)
        %v20383 = vshll.u32 %v20374, 6 (stack44)
        %v20384 = vshrl.u32 %v20374, 26 (stack45)
        %v20385 = vor.u32 %v20384, %v20383 (stack46)
        %v20386 = vxor.u32 %v20385, %v20377 (stack47)
        %v20389 = vadd.s32 %v20386, %v10 (stack39)
        %v20393 = vadd.s32 5, %v20389 (stack39)
        %v20395 = vxor.u32 %v20393, %v20381 (stack47)
        %v20396 = vand.u32.u8 255, %v20395 (stack48)
        %v20397 = vand.u32 65535, %v20396 (stack49)
        %v20398 = vshrl.u32 %v20397, 1 (stack50)
        %v20399 = vor.u32 16256, %v20398 (stack46)
        %v20400 = vand.u32.u16 65535, %v20399 (stack51)
        %v119852 = vadd.low.f32.bf16 -1.0, %v20400 (stack52)
        %v20409 = vmul.f32 2.0, %v119852 (stack53)
        %v20413 = vadd.f32 -0.99609375, %v20409 (stack52)
        %v20417 = vmax.f32 %v20413, -0.99609375 (stack54)
        %v20419 = vand.u32 2147483647, %v20417 (stack55)
        %vm20422 = vcmp.eq.f32.partialorder %v20419, 1.0 (stack56)
        %v20427 = vmul.f32 inf, %v20417 (stack53)
        %v20429 = vxor.u32 2147483648, %v20417 (stack57)
        %v20432 = vmul.f32 %v20429, %v20417 (stack53)
        %v20434 = vadd.f32 1.0, %v20432 (stack58)
        %v20435 = vlog2.pop %v20434 (stack59)
        %v20436 = vmul.f32 0.6931472, %v20435 (stack60)
        %v20437 = vmul.f32 -0.5, %v20432 (stack61)
        %v20438 = vadd.f32 1.0, %v20437 (stack62)
        %v20439 = vmul.f32 %v20438, %v20432 (stack63)
        %v20440 = vand.u32 2147483647, %v20432 (stack64)
        %vm20441 = vcmp.lt.f32.partialorder %v20440, 0.0004427343 (stack65)
        %v20442 = vsel /*vm=*/%vm20441, /*on_true_vy=*/%v20439, /*on_false_vx=*/%v20436 (stack66)
        %v20443 = vxor.u32 2147483648, %v20442 (stack57)
        %vm20446 = vcmp.lt.f32.partialorder %v20443, 5.0 (stack56)
        %v20451 = vsel /*vm=*/%vm20446, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v20455 = vsel /*vm=*/%vm20446, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v20459 = vsel /*vm=*/%vm20446, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v20463 = vsel /*vm=*/%vm20446, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v20467 = vsel /*vm=*/%vm20446, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v20471 = vsel /*vm=*/%vm20446, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v20475 = vsel /*vm=*/%vm20446, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v20479 = vsel /*vm=*/%vm20446, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v20483 = vsel /*vm=*/%vm20446, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v20487 = vadd.f32 -2.5, %v20443 (stack52)
        %v20489 = vrsqrt.pop %v20443 (stack67)
        %v20490 = vmul.f32 %v20489, %v20443 (stack68)
        %vm20491 = vcmp.eq.f32.partialorder %v20443, inf (stack69)
        %v20492 = vsel /*vm=*/%vm20491, /*on_true_vy=*/%v20443, /*on_false_vx=*/%v20490 (stack70)
        %vm20493 = vcmp.eq.f32.partialorder %v20443, 0.0 (stack71)
        %v20494 = vand.u32 2147483648, %v20443 (stack72)
        %v20495 = vsel /*vm=*/%vm20493, /*on_true_vy=*/%v20494, /*on_false_vx=*/%v20492 (stack73)
        %v20498 = vadd.f32 -3.0, %v20495 (stack52)
        %v20502 = vsel /*vm=*/%vm20446, /*on_true_vy=*/%v20487, /*on_false_vx=*/%v20498 (stack43)
        %v20506 = vmul.f32 %v20502, %v20483 (stack53)
        %v20510 = vadd.f32 %v20506, %v20479 (stack52)
        %v20514 = vmul.f32 %v20510, %v20502 (stack53)
        %v20518 = vadd.f32 %v20514, %v20475 (stack52)
        %v20522 = vmul.f32 %v20518, %v20502 (stack53)
        %v20526 = vadd.f32 %v20522, %v20471 (stack52)
        %v20530 = vmul.f32 %v20526, %v20502 (stack53)
        %v20534 = vadd.f32 %v20530, %v20467 (stack52)
        %v20538 = vmul.f32 %v20534, %v20502 (stack53)
        %v20542 = vadd.f32 %v20538, %v20463 (stack52)
        %v20546 = vmul.f32 %v20542, %v20502 (stack53)
        %v20550 = vadd.f32 %v20546, %v20459 (stack52)
        %v20554 = vmul.f32 %v20550, %v20502 (stack53)
        %v20558 = vadd.f32 %v20554, %v20455 (stack52)
        %v20562 = vmul.f32 %v20558, %v20502 (stack53)
        %v20566 = vadd.f32 %v20562, %v20451 (stack52)
        %v20570 = vmul.f32 %v20566, %v20417 (stack53)
        %v20574 = vsel /*vm=*/%vm20422, /*on_true_vy=*/%v20427, /*on_false_vx=*/%v20570 (stack43)
        %v20578 = vmul.f32 1.4140625, %v20574 (stack53)
        %v20581 = vpack.c.bf16 0.0, %v20578 (stack74)
        %119853 = vst [vmem:[%s280 + $0x114] sm:$0xf] /*vst_source=*/%v20581 (stack75)
        %v20585 = vadd.s32 %v19199, %v1868 (stack39)
        %v20595 = vadd.s32 %v20585, %v415 (stack39)
        %vm20599 = vcmp.lt.u32.totalorder %v20595, %v20585 (stack42)
        %vm20604 = vcmp.lt.u32.totalorder %v20585, %v1868 (stack42)
        %v20609 = vadd.s32 %v19182, %v1855 (stack39)
        %v20613 = vadd.s32 1, %v20609 (stack39)
        %v20617 = vsel /*vm=*/%vm20604, /*on_true_vy=*/%v20613, /*on_false_vx=*/%v20609 (stack43)
        %v20621 = vadd.s32 1, %v20617 (stack39)
        %v20625 = vsel /*vm=*/%vm20599, /*on_true_vy=*/%v20621, /*on_false_vx=*/%v20617 (stack43)
        %v20630 = vadd.s32 %v20625, %v10 (stack39)
        %v20634 = vadd.s32 %v20595, %v9 (stack39)
        %v20638 = vadd.s32 %v20634, %v20630 (stack39)
        %v20640 = vshll.u32 %v20634, 13 (stack44)
        %v20641 = vshrl.u32 %v20634, 19 (stack45)
        %v20642 = vor.u32 %v20641, %v20640 (stack46)
        %v20643 = vxor.u32 %v20642, %v20638 (stack47)
        %v20646 = vadd.s32 %v20643, %v20638 (stack39)
        %v20648 = vshll.u32 %v20643, 15 (stack44)
        %v20649 = vshrl.u32 %v20643, 17 (stack45)
        %v20650 = vor.u32 %v20649, %v20648 (stack46)
        %v20651 = vxor.u32 %v20650, %v20646 (stack47)
        %v20654 = vadd.s32 %v20651, %v20646 (stack39)
        %v20656 = vshll.u32 %v20651, 26 (stack44)
        %v20657 = vshrl.u32 %v20651, 6 (stack45)
        %v20658 = vor.u32 %v20657, %v20656 (stack46)
        %v20659 = vxor.u32 %v20658, %v20654 (stack47)
        %v20662 = vadd.s32 %v20659, %v20654 (stack39)
        %v20666 = vadd.s32 %v20662, %v9 (stack39)
        %v20668 = vshll.u32 %v20659, 6 (stack44)
        %v20669 = vshrl.u32 %v20659, 26 (stack45)
        %v20670 = vor.u32 %v20669, %v20668 (stack46)
        %v20671 = vxor.u32 %v20670, %v20662 (stack47)
        %v20674 = vadd.s32 %v20671, %v8 (stack39)
        %v20678 = vadd.s32 1, %v20674 (stack39)
        %v20682 = vadd.s32 %v20678, %v20666 (stack39)
        %v20684 = vshll.u32 %v20678, 17 (stack44)
        %v20685 = vshrl.u32 %v20678, 15 (stack45)
        %v20686 = vor.u32 %v20685, %v20684 (stack46)
        %v20687 = vxor.u32 %v20686, %v20682 (stack47)
        %v20690 = vadd.s32 %v20687, %v20682 (stack39)
        %v20692 = vshll.u32 %v20687, 29 (stack44)
        %v20693 = vshrl.u32 %v20687, 3 (stack45)
        %v20694 = vor.u32 %v20693, %v20692 (stack46)
        %v20695 = vxor.u32 %v20694, %v20690 (stack47)
        %v20698 = vadd.s32 %v20695, %v20690 (stack39)
        %v20700 = vshll.u32 %v20695, 16 (stack44)
        %v20701 = vshrl.u32 %v20695, 16 (stack45)
        %v20702 = vor.u32 %v20701, %v20700 (stack46)
        %v20703 = vxor.u32 %v20702, %v20698 (stack47)
        %v20706 = vadd.s32 %v20703, %v20698 (stack39)
        %v20710 = vadd.s32 %v20706, %v8 (stack39)
        %v20712 = vshll.u32 %v20703, 24 (stack44)
        %v20713 = vshrl.u32 %v20703, 8 (stack45)
        %v20714 = vor.u32 %v20713, %v20712 (stack46)
        %v20715 = vxor.u32 %v20714, %v20706 (stack47)
        %v20718 = vadd.s32 %v20715, %v10 (stack39)
        %v20722 = vadd.s32 2, %v20718 (stack39)
        %v20726 = vadd.s32 %v20722, %v20710 (stack39)
        %v20728 = vshll.u32 %v20722, 13 (stack44)
        %v20729 = vshrl.u32 %v20722, 19 (stack45)
        %v20730 = vor.u32 %v20729, %v20728 (stack46)
        %v20731 = vxor.u32 %v20730, %v20726 (stack47)
        %v20734 = vadd.s32 %v20731, %v20726 (stack39)
        %v20736 = vshll.u32 %v20731, 15 (stack44)
        %v20737 = vshrl.u32 %v20731, 17 (stack45)
        %v20738 = vor.u32 %v20737, %v20736 (stack46)
        %v20739 = vxor.u32 %v20738, %v20734 (stack47)
        %v20742 = vadd.s32 %v20739, %v20734 (stack39)
        %v20744 = vshll.u32 %v20739, 26 (stack44)
        %v20745 = vshrl.u32 %v20739, 6 (stack45)
        %v20746 = vor.u32 %v20745, %v20744 (stack46)
        %v20747 = vxor.u32 %v20746, %v20742 (stack47)
        %v20750 = vadd.s32 %v20747, %v20742 (stack39)
        %v20754 = vadd.s32 %v20750, %v10 (stack39)
        %v20756 = vshll.u32 %v20747, 6 (stack44)
        %v20757 = vshrl.u32 %v20747, 26 (stack45)
        %v20758 = vor.u32 %v20757, %v20756 (stack46)
        %v20759 = vxor.u32 %v20758, %v20750 (stack47)
        %v20762 = vadd.s32 %v20759, %v9 (stack39)
        %v20766 = vadd.s32 3, %v20762 (stack39)
        %v20770 = vadd.s32 %v20766, %v20754 (stack39)
        %v20772 = vshll.u32 %v20766, 17 (stack44)
        %v20773 = vshrl.u32 %v20766, 15 (stack45)
        %v20774 = vor.u32 %v20773, %v20772 (stack46)
        %v20775 = vxor.u32 %v20774, %v20770 (stack47)
        %v20778 = vadd.s32 %v20775, %v20770 (stack39)
        %v20780 = vshll.u32 %v20775, 29 (stack44)
        %v20781 = vshrl.u32 %v20775, 3 (stack45)
        %v20782 = vor.u32 %v20781, %v20780 (stack46)
        %v20783 = vxor.u32 %v20782, %v20778 (stack47)
        %v20786 = vadd.s32 %v20783, %v20778 (stack39)
        %v20788 = vshll.u32 %v20783, 16 (stack44)
        %v20789 = vshrl.u32 %v20783, 16 (stack45)
        %v20790 = vor.u32 %v20789, %v20788 (stack46)
        %v20791 = vxor.u32 %v20790, %v20786 (stack47)
        %v20794 = vadd.s32 %v20791, %v20786 (stack39)
        %v20798 = vadd.s32 %v20794, %v9 (stack39)
        %v20800 = vshll.u32 %v20791, 24 (stack44)
        %v20801 = vshrl.u32 %v20791, 8 (stack45)
        %v20802 = vor.u32 %v20801, %v20800 (stack46)
        %v20803 = vxor.u32 %v20802, %v20794 (stack47)
        %v20806 = vadd.s32 %v20803, %v8 (stack39)
        %v20810 = vadd.s32 4, %v20806 (stack39)
        %v20814 = vadd.s32 %v20810, %v20798 (stack39)
        %v20816 = vshll.u32 %v20810, 13 (stack44)
        %v20817 = vshrl.u32 %v20810, 19 (stack45)
        %v20818 = vor.u32 %v20817, %v20816 (stack46)
        %v20819 = vxor.u32 %v20818, %v20814 (stack47)
        %v20822 = vadd.s32 %v20819, %v20814 (stack39)
        %v20824 = vshll.u32 %v20819, 15 (stack44)
        %v20825 = vshrl.u32 %v20819, 17 (stack45)
        %v20826 = vor.u32 %v20825, %v20824 (stack46)
        %v20827 = vxor.u32 %v20826, %v20822 (stack47)
        %v20830 = vadd.s32 %v20827, %v20822 (stack39)
        %v20832 = vshll.u32 %v20827, 26 (stack44)
        %v20833 = vshrl.u32 %v20827, 6 (stack45)
        %v20834 = vor.u32 %v20833, %v20832 (stack46)
        %v20835 = vxor.u32 %v20834, %v20830 (stack47)
        %v20838 = vadd.s32 %v20835, %v20830 (stack39)
        %v20842 = vadd.s32 %v20838, %v8 (stack39)
        %v20844 = vshll.u32 %v20835, 6 (stack44)
        %v20845 = vshrl.u32 %v20835, 26 (stack45)
        %v20846 = vor.u32 %v20845, %v20844 (stack46)
        %v20847 = vxor.u32 %v20846, %v20838 (stack47)
        %v20850 = vadd.s32 %v20847, %v10 (stack39)
        %v20854 = vadd.s32 5, %v20850 (stack39)
        %v20856 = vxor.u32 %v20854, %v20842 (stack47)
        %v20857 = vand.u32.u8 255, %v20856 (stack48)
        %v20858 = vand.u32 65535, %v20857 (stack49)
        %v20859 = vshrl.u32 %v20858, 1 (stack50)
        %v20860 = vor.u32 16256, %v20859 (stack46)
        %v20861 = vand.u32.u16 65535, %v20860 (stack51)
        %v119854 = vadd.low.f32.bf16 -1.0, %v20861 (stack52)
        %v20870 = vmul.f32 2.0, %v119854 (stack53)
        %v20874 = vadd.f32 -0.99609375, %v20870 (stack52)
        %v20878 = vmax.f32 %v20874, -0.99609375 (stack54)
        %v20880 = vand.u32 2147483647, %v20878 (stack55)
        %vm20883 = vcmp.eq.f32.partialorder %v20880, 1.0 (stack56)
        %v20888 = vmul.f32 inf, %v20878 (stack53)
        %v20890 = vxor.u32 2147483648, %v20878 (stack57)
        %v20893 = vmul.f32 %v20890, %v20878 (stack53)
        %v20895 = vadd.f32 1.0, %v20893 (stack58)
        %v20896 = vlog2.pop %v20895 (stack59)
        %v20897 = vmul.f32 0.6931472, %v20896 (stack60)
        %v20898 = vmul.f32 -0.5, %v20893 (stack61)
        %v20899 = vadd.f32 1.0, %v20898 (stack62)
        %v20900 = vmul.f32 %v20899, %v20893 (stack63)
        %v20901 = vand.u32 2147483647, %v20893 (stack64)
        %vm20902 = vcmp.lt.f32.partialorder %v20901, 0.0004427343 (stack65)
        %v20903 = vsel /*vm=*/%vm20902, /*on_true_vy=*/%v20900, /*on_false_vx=*/%v20897 (stack66)
        %v20904 = vxor.u32 2147483648, %v20903 (stack57)
        %vm20907 = vcmp.lt.f32.partialorder %v20904, 5.0 (stack56)
        %v20912 = vsel /*vm=*/%vm20907, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v20916 = vsel /*vm=*/%vm20907, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v20920 = vsel /*vm=*/%vm20907, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v20924 = vsel /*vm=*/%vm20907, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v20928 = vsel /*vm=*/%vm20907, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v20932 = vsel /*vm=*/%vm20907, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v20936 = vsel /*vm=*/%vm20907, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v20940 = vsel /*vm=*/%vm20907, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v20944 = vsel /*vm=*/%vm20907, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v20948 = vadd.f32 -2.5, %v20904 (stack52)
        %v20950 = vrsqrt.pop %v20904 (stack67)
        %v20951 = vmul.f32 %v20950, %v20904 (stack68)
        %vm20952 = vcmp.eq.f32.partialorder %v20904, inf (stack69)
        %v20953 = vsel /*vm=*/%vm20952, /*on_true_vy=*/%v20904, /*on_false_vx=*/%v20951 (stack70)
        %vm20954 = vcmp.eq.f32.partialorder %v20904, 0.0 (stack71)
        %v20955 = vand.u32 2147483648, %v20904 (stack72)
        %v20956 = vsel /*vm=*/%vm20954, /*on_true_vy=*/%v20955, /*on_false_vx=*/%v20953 (stack73)
        %v20959 = vadd.f32 -3.0, %v20956 (stack52)
        %v20963 = vsel /*vm=*/%vm20907, /*on_true_vy=*/%v20948, /*on_false_vx=*/%v20959 (stack43)
        %v20967 = vmul.f32 %v20963, %v20944 (stack53)
        %v20971 = vadd.f32 %v20967, %v20940 (stack52)
        %v20975 = vmul.f32 %v20971, %v20963 (stack53)
        %v20979 = vadd.f32 %v20975, %v20936 (stack52)
        %v20983 = vmul.f32 %v20979, %v20963 (stack53)
        %v20987 = vadd.f32 %v20983, %v20932 (stack52)
        %v20991 = vmul.f32 %v20987, %v20963 (stack53)
        %v20995 = vadd.f32 %v20991, %v20928 (stack52)
        %v20999 = vmul.f32 %v20995, %v20963 (stack53)
        %v21003 = vadd.f32 %v20999, %v20924 (stack52)
        %v21007 = vmul.f32 %v21003, %v20963 (stack53)
        %v21011 = vadd.f32 %v21007, %v20920 (stack52)
        %v21015 = vmul.f32 %v21011, %v20963 (stack53)
        %v21019 = vadd.f32 %v21015, %v20916 (stack52)
        %v21023 = vmul.f32 %v21019, %v20963 (stack53)
        %v21027 = vadd.f32 %v21023, %v20912 (stack52)
        %v21031 = vmul.f32 %v21027, %v20878 (stack53)
        %v21035 = vsel /*vm=*/%vm20883, /*on_true_vy=*/%v20888, /*on_false_vx=*/%v21031 (stack43)
        %v21039 = vmul.f32 1.4140625, %v21035 (stack53)
        %v21042 = vpack.c.bf16 0.0, %v21039 (stack74)
        %119855 = vst [vmem:[%s280 + $0x194] sm:$0xf] /*vst_source=*/%v21042 (stack75)
        %v21046 = vadd.s32 %v19199, %v2355 (stack39)
        %v21056 = vadd.s32 %v21046, %v415 (stack39)
        %vm21060 = vcmp.lt.u32.totalorder %v21056, %v21046 (stack42)
        %vm21065 = vcmp.lt.u32.totalorder %v21046, %v2355 (stack42)
        %v21070 = vadd.s32 %v19182, %v2342 (stack39)
        %v21074 = vadd.s32 1, %v21070 (stack39)
        %v21078 = vsel /*vm=*/%vm21065, /*on_true_vy=*/%v21074, /*on_false_vx=*/%v21070 (stack43)
        %v21082 = vadd.s32 1, %v21078 (stack39)
        %v21086 = vsel /*vm=*/%vm21060, /*on_true_vy=*/%v21082, /*on_false_vx=*/%v21078 (stack43)
        %v21091 = vadd.s32 %v21086, %v10 (stack39)
        %v21095 = vadd.s32 %v21056, %v9 (stack39)
        %v21099 = vadd.s32 %v21095, %v21091 (stack39)
        %v21101 = vshll.u32 %v21095, 13 (stack44)
        %v21102 = vshrl.u32 %v21095, 19 (stack45)
        %v21103 = vor.u32 %v21102, %v21101 (stack46)
        %v21104 = vxor.u32 %v21103, %v21099 (stack47)
        %v21107 = vadd.s32 %v21104, %v21099 (stack39)
        %v21109 = vshll.u32 %v21104, 15 (stack44)
        %v21110 = vshrl.u32 %v21104, 17 (stack45)
        %v21111 = vor.u32 %v21110, %v21109 (stack46)
        %v21112 = vxor.u32 %v21111, %v21107 (stack47)
        %v21115 = vadd.s32 %v21112, %v21107 (stack39)
        %v21117 = vshll.u32 %v21112, 26 (stack44)
        %v21118 = vshrl.u32 %v21112, 6 (stack45)
        %v21119 = vor.u32 %v21118, %v21117 (stack46)
        %v21120 = vxor.u32 %v21119, %v21115 (stack47)
        %v21123 = vadd.s32 %v21120, %v21115 (stack39)
        %v21127 = vadd.s32 %v21123, %v9 (stack39)
        %v21129 = vshll.u32 %v21120, 6 (stack44)
        %v21130 = vshrl.u32 %v21120, 26 (stack45)
        %v21131 = vor.u32 %v21130, %v21129 (stack46)
        %v21132 = vxor.u32 %v21131, %v21123 (stack47)
        %v21135 = vadd.s32 %v21132, %v8 (stack39)
        %v21139 = vadd.s32 1, %v21135 (stack39)
        %v21143 = vadd.s32 %v21139, %v21127 (stack39)
        %v21145 = vshll.u32 %v21139, 17 (stack44)
        %v21146 = vshrl.u32 %v21139, 15 (stack45)
        %v21147 = vor.u32 %v21146, %v21145 (stack46)
        %v21148 = vxor.u32 %v21147, %v21143 (stack47)
        %v21151 = vadd.s32 %v21148, %v21143 (stack39)
        %v21153 = vshll.u32 %v21148, 29 (stack44)
        %v21154 = vshrl.u32 %v21148, 3 (stack45)
        %v21155 = vor.u32 %v21154, %v21153 (stack46)
        %v21156 = vxor.u32 %v21155, %v21151 (stack47)
        %v21159 = vadd.s32 %v21156, %v21151 (stack39)
        %v21161 = vshll.u32 %v21156, 16 (stack44)
        %v21162 = vshrl.u32 %v21156, 16 (stack45)
        %v21163 = vor.u32 %v21162, %v21161 (stack46)
        %v21164 = vxor.u32 %v21163, %v21159 (stack47)
        %v21167 = vadd.s32 %v21164, %v21159 (stack39)
        %v21171 = vadd.s32 %v21167, %v8 (stack39)
        %v21173 = vshll.u32 %v21164, 24 (stack44)
        %v21174 = vshrl.u32 %v21164, 8 (stack45)
        %v21175 = vor.u32 %v21174, %v21173 (stack46)
        %v21176 = vxor.u32 %v21175, %v21167 (stack47)
        %v21179 = vadd.s32 %v21176, %v10 (stack39)
        %v21183 = vadd.s32 2, %v21179 (stack39)
        %v21187 = vadd.s32 %v21183, %v21171 (stack39)
        %v21189 = vshll.u32 %v21183, 13 (stack44)
        %v21190 = vshrl.u32 %v21183, 19 (stack45)
        %v21191 = vor.u32 %v21190, %v21189 (stack46)
        %v21192 = vxor.u32 %v21191, %v21187 (stack47)
        %v21195 = vadd.s32 %v21192, %v21187 (stack39)
        %v21197 = vshll.u32 %v21192, 15 (stack44)
        %v21198 = vshrl.u32 %v21192, 17 (stack45)
        %v21199 = vor.u32 %v21198, %v21197 (stack46)
        %v21200 = vxor.u32 %v21199, %v21195 (stack47)
        %v21203 = vadd.s32 %v21200, %v21195 (stack39)
        %v21205 = vshll.u32 %v21200, 26 (stack44)
        %v21206 = vshrl.u32 %v21200, 6 (stack45)
        %v21207 = vor.u32 %v21206, %v21205 (stack46)
        %v21208 = vxor.u32 %v21207, %v21203 (stack47)
        %v21211 = vadd.s32 %v21208, %v21203 (stack39)
        %v21215 = vadd.s32 %v21211, %v10 (stack39)
        %v21217 = vshll.u32 %v21208, 6 (stack44)
        %v21218 = vshrl.u32 %v21208, 26 (stack45)
        %v21219 = vor.u32 %v21218, %v21217 (stack46)
        %v21220 = vxor.u32 %v21219, %v21211 (stack47)
        %v21223 = vadd.s32 %v21220, %v9 (stack39)
        %v21227 = vadd.s32 3, %v21223 (stack39)
        %v21231 = vadd.s32 %v21227, %v21215 (stack39)
        %v21233 = vshll.u32 %v21227, 17 (stack44)
        %v21234 = vshrl.u32 %v21227, 15 (stack45)
        %v21235 = vor.u32 %v21234, %v21233 (stack46)
        %v21236 = vxor.u32 %v21235, %v21231 (stack47)
        %v21239 = vadd.s32 %v21236, %v21231 (stack39)
        %v21241 = vshll.u32 %v21236, 29 (stack44)
        %v21242 = vshrl.u32 %v21236, 3 (stack45)
        %v21243 = vor.u32 %v21242, %v21241 (stack46)
        %v21244 = vxor.u32 %v21243, %v21239 (stack47)
        %v21247 = vadd.s32 %v21244, %v21239 (stack39)
        %v21249 = vshll.u32 %v21244, 16 (stack44)
        %v21250 = vshrl.u32 %v21244, 16 (stack45)
        %v21251 = vor.u32 %v21250, %v21249 (stack46)
        %v21252 = vxor.u32 %v21251, %v21247 (stack47)
        %v21255 = vadd.s32 %v21252, %v21247 (stack39)
        %v21259 = vadd.s32 %v21255, %v9 (stack39)
        %v21261 = vshll.u32 %v21252, 24 (stack44)
        %v21262 = vshrl.u32 %v21252, 8 (stack45)
        %v21263 = vor.u32 %v21262, %v21261 (stack46)
        %v21264 = vxor.u32 %v21263, %v21255 (stack47)
        %v21267 = vadd.s32 %v21264, %v8 (stack39)
        %v21271 = vadd.s32 4, %v21267 (stack39)
        %v21275 = vadd.s32 %v21271, %v21259 (stack39)
        %v21277 = vshll.u32 %v21271, 13 (stack44)
        %v21278 = vshrl.u32 %v21271, 19 (stack45)
        %v21279 = vor.u32 %v21278, %v21277 (stack46)
        %v21280 = vxor.u32 %v21279, %v21275 (stack47)
        %v21283 = vadd.s32 %v21280, %v21275 (stack39)
        %v21285 = vshll.u32 %v21280, 15 (stack44)
        %v21286 = vshrl.u32 %v21280, 17 (stack45)
        %v21287 = vor.u32 %v21286, %v21285 (stack46)
        %v21288 = vxor.u32 %v21287, %v21283 (stack47)
        %v21291 = vadd.s32 %v21288, %v21283 (stack39)
        %v21293 = vshll.u32 %v21288, 26 (stack44)
        %v21294 = vshrl.u32 %v21288, 6 (stack45)
        %v21295 = vor.u32 %v21294, %v21293 (stack46)
        %v21296 = vxor.u32 %v21295, %v21291 (stack47)
        %v21299 = vadd.s32 %v21296, %v21291 (stack39)
        %v21303 = vadd.s32 %v21299, %v8 (stack39)
        %v21305 = vshll.u32 %v21296, 6 (stack44)
        %v21306 = vshrl.u32 %v21296, 26 (stack45)
        %v21307 = vor.u32 %v21306, %v21305 (stack46)
        %v21308 = vxor.u32 %v21307, %v21299 (stack47)
        %v21311 = vadd.s32 %v21308, %v10 (stack39)
        %v21315 = vadd.s32 5, %v21311 (stack39)
        %v21317 = vxor.u32 %v21315, %v21303 (stack47)
        %v21318 = vand.u32.u8 255, %v21317 (stack48)
        %v21319 = vand.u32 65535, %v21318 (stack49)
        %v21320 = vshrl.u32 %v21319, 1 (stack50)
        %v21321 = vor.u32 16256, %v21320 (stack46)
        %v21322 = vand.u32.u16 65535, %v21321 (stack51)
        %v119856 = vadd.low.f32.bf16 -1.0, %v21322 (stack52)
        %v21331 = vmul.f32 2.0, %v119856 (stack53)
        %v21335 = vadd.f32 -0.99609375, %v21331 (stack52)
        %v21339 = vmax.f32 %v21335, -0.99609375 (stack54)
        %v21341 = vand.u32 2147483647, %v21339 (stack55)
        %vm21344 = vcmp.eq.f32.partialorder %v21341, 1.0 (stack56)
        %v21349 = vmul.f32 inf, %v21339 (stack53)
        %v21351 = vxor.u32 2147483648, %v21339 (stack57)
        %v21354 = vmul.f32 %v21351, %v21339 (stack53)
        %v21356 = vadd.f32 1.0, %v21354 (stack58)
        %v21357 = vlog2.pop %v21356 (stack59)
        %v21358 = vmul.f32 0.6931472, %v21357 (stack60)
        %v21359 = vmul.f32 -0.5, %v21354 (stack61)
        %v21360 = vadd.f32 1.0, %v21359 (stack62)
        %v21361 = vmul.f32 %v21360, %v21354 (stack63)
        %v21362 = vand.u32 2147483647, %v21354 (stack64)
        %vm21363 = vcmp.lt.f32.partialorder %v21362, 0.0004427343 (stack65)
        %v21364 = vsel /*vm=*/%vm21363, /*on_true_vy=*/%v21361, /*on_false_vx=*/%v21358 (stack66)
        %v21365 = vxor.u32 2147483648, %v21364 (stack57)
        %vm21368 = vcmp.lt.f32.partialorder %v21365, 5.0 (stack56)
        %v21373 = vsel /*vm=*/%vm21368, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v21377 = vsel /*vm=*/%vm21368, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v21381 = vsel /*vm=*/%vm21368, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v21385 = vsel /*vm=*/%vm21368, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v21389 = vsel /*vm=*/%vm21368, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v21393 = vsel /*vm=*/%vm21368, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v21397 = vsel /*vm=*/%vm21368, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v21401 = vsel /*vm=*/%vm21368, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v21405 = vsel /*vm=*/%vm21368, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v21409 = vadd.f32 -2.5, %v21365 (stack52)
        %v21411 = vrsqrt.pop %v21365 (stack67)
        %v21412 = vmul.f32 %v21411, %v21365 (stack68)
        %vm21413 = vcmp.eq.f32.partialorder %v21365, inf (stack69)
        %v21414 = vsel /*vm=*/%vm21413, /*on_true_vy=*/%v21365, /*on_false_vx=*/%v21412 (stack70)
        %vm21415 = vcmp.eq.f32.partialorder %v21365, 0.0 (stack71)
        %v21416 = vand.u32 2147483648, %v21365 (stack72)
        %v21417 = vsel /*vm=*/%vm21415, /*on_true_vy=*/%v21416, /*on_false_vx=*/%v21414 (stack73)
        %v21420 = vadd.f32 -3.0, %v21417 (stack52)
        %v21424 = vsel /*vm=*/%vm21368, /*on_true_vy=*/%v21409, /*on_false_vx=*/%v21420 (stack43)
        %v21428 = vmul.f32 %v21424, %v21405 (stack53)
        %v21432 = vadd.f32 %v21428, %v21401 (stack52)
        %v21436 = vmul.f32 %v21432, %v21424 (stack53)
        %v21440 = vadd.f32 %v21436, %v21397 (stack52)
        %v21444 = vmul.f32 %v21440, %v21424 (stack53)
        %v21448 = vadd.f32 %v21444, %v21393 (stack52)
        %v21452 = vmul.f32 %v21448, %v21424 (stack53)
        %v21456 = vadd.f32 %v21452, %v21389 (stack52)
        %v21460 = vmul.f32 %v21456, %v21424 (stack53)
        %v21464 = vadd.f32 %v21460, %v21385 (stack52)
        %v21468 = vmul.f32 %v21464, %v21424 (stack53)
        %v21472 = vadd.f32 %v21468, %v21381 (stack52)
        %v21476 = vmul.f32 %v21472, %v21424 (stack53)
        %v21480 = vadd.f32 %v21476, %v21377 (stack52)
        %v21484 = vmul.f32 %v21480, %v21424 (stack53)
        %v21488 = vadd.f32 %v21484, %v21373 (stack52)
        %v21492 = vmul.f32 %v21488, %v21339 (stack53)
        %v21496 = vsel /*vm=*/%vm21344, /*on_true_vy=*/%v21349, /*on_false_vx=*/%v21492 (stack43)
        %v21500 = vmul.f32 1.4140625, %v21496 (stack53)
        %v21503 = vpack.c.bf16 0.0, %v21500 (stack74)
        %119857 = vst [vmem:[%s280 + $0x214] sm:$0xf] /*vst_source=*/%v21503 (stack75)
        %v21507 = vadd.s32 %v19199, %v2842 (stack39)
        %v21517 = vadd.s32 %v21507, %v415 (stack39)
        %vm21521 = vcmp.lt.u32.totalorder %v21517, %v21507 (stack42)
        %vm21526 = vcmp.lt.u32.totalorder %v21507, %v2842 (stack42)
        %v21531 = vadd.s32 %v19182, %v2829 (stack39)
        %v21535 = vadd.s32 1, %v21531 (stack39)
        %v21539 = vsel /*vm=*/%vm21526, /*on_true_vy=*/%v21535, /*on_false_vx=*/%v21531 (stack43)
        %v21543 = vadd.s32 1, %v21539 (stack39)
        %v21547 = vsel /*vm=*/%vm21521, /*on_true_vy=*/%v21543, /*on_false_vx=*/%v21539 (stack43)
        %v21552 = vadd.s32 %v21547, %v10 (stack39)
        %v21556 = vadd.s32 %v21517, %v9 (stack39)
        %v21560 = vadd.s32 %v21556, %v21552 (stack39)
        %v21562 = vshll.u32 %v21556, 13 (stack44)
        %v21563 = vshrl.u32 %v21556, 19 (stack45)
        %v21564 = vor.u32 %v21563, %v21562 (stack46)
        %v21565 = vxor.u32 %v21564, %v21560 (stack47)
        %v21568 = vadd.s32 %v21565, %v21560 (stack39)
        %v21570 = vshll.u32 %v21565, 15 (stack44)
        %v21571 = vshrl.u32 %v21565, 17 (stack45)
        %v21572 = vor.u32 %v21571, %v21570 (stack46)
        %v21573 = vxor.u32 %v21572, %v21568 (stack47)
        %v21576 = vadd.s32 %v21573, %v21568 (stack39)
        %v21578 = vshll.u32 %v21573, 26 (stack44)
        %v21579 = vshrl.u32 %v21573, 6 (stack45)
        %v21580 = vor.u32 %v21579, %v21578 (stack46)
        %v21581 = vxor.u32 %v21580, %v21576 (stack47)
        %v21584 = vadd.s32 %v21581, %v21576 (stack39)
        %v21588 = vadd.s32 %v21584, %v9 (stack39)
        %v21590 = vshll.u32 %v21581, 6 (stack44)
        %v21591 = vshrl.u32 %v21581, 26 (stack45)
        %v21592 = vor.u32 %v21591, %v21590 (stack46)
        %v21593 = vxor.u32 %v21592, %v21584 (stack47)
        %v21596 = vadd.s32 %v21593, %v8 (stack39)
        %v21600 = vadd.s32 1, %v21596 (stack39)
        %v21604 = vadd.s32 %v21600, %v21588 (stack39)
        %v21606 = vshll.u32 %v21600, 17 (stack44)
        %v21607 = vshrl.u32 %v21600, 15 (stack45)
        %v21608 = vor.u32 %v21607, %v21606 (stack46)
        %v21609 = vxor.u32 %v21608, %v21604 (stack47)
        %v21612 = vadd.s32 %v21609, %v21604 (stack39)
        %v21614 = vshll.u32 %v21609, 29 (stack44)
        %v21615 = vshrl.u32 %v21609, 3 (stack45)
        %v21616 = vor.u32 %v21615, %v21614 (stack46)
        %v21617 = vxor.u32 %v21616, %v21612 (stack47)
        %v21620 = vadd.s32 %v21617, %v21612 (stack39)
        %v21622 = vshll.u32 %v21617, 16 (stack44)
        %v21623 = vshrl.u32 %v21617, 16 (stack45)
        %v21624 = vor.u32 %v21623, %v21622 (stack46)
        %v21625 = vxor.u32 %v21624, %v21620 (stack47)
        %v21628 = vadd.s32 %v21625, %v21620 (stack39)
        %v21632 = vadd.s32 %v21628, %v8 (stack39)
        %v21634 = vshll.u32 %v21625, 24 (stack44)
        %v21635 = vshrl.u32 %v21625, 8 (stack45)
        %v21636 = vor.u32 %v21635, %v21634 (stack46)
        %v21637 = vxor.u32 %v21636, %v21628 (stack47)
        %v21640 = vadd.s32 %v21637, %v10 (stack39)
        %v21644 = vadd.s32 2, %v21640 (stack39)
        %v21648 = vadd.s32 %v21644, %v21632 (stack39)
        %v21650 = vshll.u32 %v21644, 13 (stack44)
        %v21651 = vshrl.u32 %v21644, 19 (stack45)
        %v21652 = vor.u32 %v21651, %v21650 (stack46)
        %v21653 = vxor.u32 %v21652, %v21648 (stack47)
        %v21656 = vadd.s32 %v21653, %v21648 (stack39)
        %v21658 = vshll.u32 %v21653, 15 (stack44)
        %v21659 = vshrl.u32 %v21653, 17 (stack45)
        %v21660 = vor.u32 %v21659, %v21658 (stack46)
        %v21661 = vxor.u32 %v21660, %v21656 (stack47)
        %v21664 = vadd.s32 %v21661, %v21656 (stack39)
        %v21666 = vshll.u32 %v21661, 26 (stack44)
        %v21667 = vshrl.u32 %v21661, 6 (stack45)
        %v21668 = vor.u32 %v21667, %v21666 (stack46)
        %v21669 = vxor.u32 %v21668, %v21664 (stack47)
        %v21672 = vadd.s32 %v21669, %v21664 (stack39)
        %v21676 = vadd.s32 %v21672, %v10 (stack39)
        %v21678 = vshll.u32 %v21669, 6 (stack44)
        %v21679 = vshrl.u32 %v21669, 26 (stack45)
        %v21680 = vor.u32 %v21679, %v21678 (stack46)
        %v21681 = vxor.u32 %v21680, %v21672 (stack47)
        %v21684 = vadd.s32 %v21681, %v9 (stack39)
        %v21688 = vadd.s32 3, %v21684 (stack39)
        %v21692 = vadd.s32 %v21688, %v21676 (stack39)
        %v21694 = vshll.u32 %v21688, 17 (stack44)
        %v21695 = vshrl.u32 %v21688, 15 (stack45)
        %v21696 = vor.u32 %v21695, %v21694 (stack46)
        %v21697 = vxor.u32 %v21696, %v21692 (stack47)
        %v21700 = vadd.s32 %v21697, %v21692 (stack39)
        %v21702 = vshll.u32 %v21697, 29 (stack44)
        %v21703 = vshrl.u32 %v21697, 3 (stack45)
        %v21704 = vor.u32 %v21703, %v21702 (stack46)
        %v21705 = vxor.u32 %v21704, %v21700 (stack47)
        %v21708 = vadd.s32 %v21705, %v21700 (stack39)
        %v21710 = vshll.u32 %v21705, 16 (stack44)
        %v21711 = vshrl.u32 %v21705, 16 (stack45)
        %v21712 = vor.u32 %v21711, %v21710 (stack46)
        %v21713 = vxor.u32 %v21712, %v21708 (stack47)
        %v21716 = vadd.s32 %v21713, %v21708 (stack39)
        %v21720 = vadd.s32 %v21716, %v9 (stack39)
        %v21722 = vshll.u32 %v21713, 24 (stack44)
        %v21723 = vshrl.u32 %v21713, 8 (stack45)
        %v21724 = vor.u32 %v21723, %v21722 (stack46)
        %v21725 = vxor.u32 %v21724, %v21716 (stack47)
        %v21728 = vadd.s32 %v21725, %v8 (stack39)
        %v21732 = vadd.s32 4, %v21728 (stack39)
        %v21736 = vadd.s32 %v21732, %v21720 (stack39)
        %v21738 = vshll.u32 %v21732, 13 (stack44)
        %v21739 = vshrl.u32 %v21732, 19 (stack45)
        %v21740 = vor.u32 %v21739, %v21738 (stack46)
        %v21741 = vxor.u32 %v21740, %v21736 (stack47)
        %v21744 = vadd.s32 %v21741, %v21736 (stack39)
        %v21746 = vshll.u32 %v21741, 15 (stack44)
        %v21747 = vshrl.u32 %v21741, 17 (stack45)
        %v21748 = vor.u32 %v21747, %v21746 (stack46)
        %v21749 = vxor.u32 %v21748, %v21744 (stack47)
        %v21752 = vadd.s32 %v21749, %v21744 (stack39)
        %v21754 = vshll.u32 %v21749, 26 (stack44)
        %v21755 = vshrl.u32 %v21749, 6 (stack45)
        %v21756 = vor.u32 %v21755, %v21754 (stack46)
        %v21757 = vxor.u32 %v21756, %v21752 (stack47)
        %v21760 = vadd.s32 %v21757, %v21752 (stack39)
        %v21764 = vadd.s32 %v21760, %v8 (stack39)
        %v21766 = vshll.u32 %v21757, 6 (stack44)
        %v21767 = vshrl.u32 %v21757, 26 (stack45)
        %v21768 = vor.u32 %v21767, %v21766 (stack46)
        %v21769 = vxor.u32 %v21768, %v21760 (stack47)
        %v21772 = vadd.s32 %v21769, %v10 (stack39)
        %v21776 = vadd.s32 5, %v21772 (stack39)
        %v21778 = vxor.u32 %v21776, %v21764 (stack47)
        %v21779 = vand.u32.u8 255, %v21778 (stack48)
        %v21780 = vand.u32 65535, %v21779 (stack49)
        %v21781 = vshrl.u32 %v21780, 1 (stack50)
        %v21782 = vor.u32 16256, %v21781 (stack46)
        %v21783 = vand.u32.u16 65535, %v21782 (stack51)
        %v119858 = vadd.low.f32.bf16 -1.0, %v21783 (stack52)
        %v21792 = vmul.f32 2.0, %v119858 (stack53)
        %v21796 = vadd.f32 -0.99609375, %v21792 (stack52)
        %v21800 = vmax.f32 %v21796, -0.99609375 (stack54)
        %v21802 = vand.u32 2147483647, %v21800 (stack55)
        %vm21805 = vcmp.eq.f32.partialorder %v21802, 1.0 (stack56)
        %v21810 = vmul.f32 inf, %v21800 (stack53)
        %v21812 = vxor.u32 2147483648, %v21800 (stack57)
        %v21815 = vmul.f32 %v21812, %v21800 (stack53)
        %v21817 = vadd.f32 1.0, %v21815 (stack58)
        %v21818 = vlog2.pop %v21817 (stack59)
        %v21819 = vmul.f32 0.6931472, %v21818 (stack60)
        %v21820 = vmul.f32 -0.5, %v21815 (stack61)
        %v21821 = vadd.f32 1.0, %v21820 (stack62)
        %v21822 = vmul.f32 %v21821, %v21815 (stack63)
        %v21823 = vand.u32 2147483647, %v21815 (stack64)
        %vm21824 = vcmp.lt.f32.partialorder %v21823, 0.0004427343 (stack65)
        %v21825 = vsel /*vm=*/%vm21824, /*on_true_vy=*/%v21822, /*on_false_vx=*/%v21819 (stack66)
        %v21826 = vxor.u32 2147483648, %v21825 (stack57)
        %vm21829 = vcmp.lt.f32.partialorder %v21826, 5.0 (stack56)
        %v21834 = vsel /*vm=*/%vm21829, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v21838 = vsel /*vm=*/%vm21829, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v21842 = vsel /*vm=*/%vm21829, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v21846 = vsel /*vm=*/%vm21829, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v21850 = vsel /*vm=*/%vm21829, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v21854 = vsel /*vm=*/%vm21829, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v21858 = vsel /*vm=*/%vm21829, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v21862 = vsel /*vm=*/%vm21829, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v21866 = vsel /*vm=*/%vm21829, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v21870 = vadd.f32 -2.5, %v21826 (stack52)
        %v21872 = vrsqrt.pop %v21826 (stack67)
        %v21873 = vmul.f32 %v21872, %v21826 (stack68)
        %vm21874 = vcmp.eq.f32.partialorder %v21826, inf (stack69)
        %v21875 = vsel /*vm=*/%vm21874, /*on_true_vy=*/%v21826, /*on_false_vx=*/%v21873 (stack70)
        %vm21876 = vcmp.eq.f32.partialorder %v21826, 0.0 (stack71)
        %v21877 = vand.u32 2147483648, %v21826 (stack72)
        %v21878 = vsel /*vm=*/%vm21876, /*on_true_vy=*/%v21877, /*on_false_vx=*/%v21875 (stack73)
        %v21881 = vadd.f32 -3.0, %v21878 (stack52)
        %v21885 = vsel /*vm=*/%vm21829, /*on_true_vy=*/%v21870, /*on_false_vx=*/%v21881 (stack43)
        %v21889 = vmul.f32 %v21885, %v21866 (stack53)
        %v21893 = vadd.f32 %v21889, %v21862 (stack52)
        %v21897 = vmul.f32 %v21893, %v21885 (stack53)
        %v21901 = vadd.f32 %v21897, %v21858 (stack52)
        %v21905 = vmul.f32 %v21901, %v21885 (stack53)
        %v21909 = vadd.f32 %v21905, %v21854 (stack52)
        %v21913 = vmul.f32 %v21909, %v21885 (stack53)
        %v21917 = vadd.f32 %v21913, %v21850 (stack52)
        %v21921 = vmul.f32 %v21917, %v21885 (stack53)
        %v21925 = vadd.f32 %v21921, %v21846 (stack52)
        %v21929 = vmul.f32 %v21925, %v21885 (stack53)
        %v21933 = vadd.f32 %v21929, %v21842 (stack52)
        %v21937 = vmul.f32 %v21933, %v21885 (stack53)
        %v21941 = vadd.f32 %v21937, %v21838 (stack52)
        %v21945 = vmul.f32 %v21941, %v21885 (stack53)
        %v21949 = vadd.f32 %v21945, %v21834 (stack52)
        %v21953 = vmul.f32 %v21949, %v21800 (stack53)
        %v21957 = vsel /*vm=*/%vm21805, /*on_true_vy=*/%v21810, /*on_false_vx=*/%v21953 (stack43)
        %v21961 = vmul.f32 1.4140625, %v21957 (stack53)
        %v21964 = vpack.c.bf16 0.0, %v21961 (stack74)
        %119859 = vst [vmem:[%s280 + $0x294] sm:$0xf] /*vst_source=*/%v21964 (stack75)
        %v21968 = vadd.s32 %v19199, %v3329 (stack39)
        %v21978 = vadd.s32 %v21968, %v415 (stack39)
        %vm21982 = vcmp.lt.u32.totalorder %v21978, %v21968 (stack42)
        %vm21987 = vcmp.lt.u32.totalorder %v21968, %v3329 (stack42)
        %v21992 = vadd.s32 %v19182, %v3316 (stack39)
        %v21996 = vadd.s32 1, %v21992 (stack39)
        %v22000 = vsel /*vm=*/%vm21987, /*on_true_vy=*/%v21996, /*on_false_vx=*/%v21992 (stack43)
        %v22004 = vadd.s32 1, %v22000 (stack39)
        %v22008 = vsel /*vm=*/%vm21982, /*on_true_vy=*/%v22004, /*on_false_vx=*/%v22000 (stack43)
        %v22013 = vadd.s32 %v22008, %v10 (stack39)
        %v22017 = vadd.s32 %v21978, %v9 (stack39)
        %v22021 = vadd.s32 %v22017, %v22013 (stack39)
        %v22023 = vshll.u32 %v22017, 13 (stack44)
        %v22024 = vshrl.u32 %v22017, 19 (stack45)
        %v22025 = vor.u32 %v22024, %v22023 (stack46)
        %v22026 = vxor.u32 %v22025, %v22021 (stack47)
        %v22029 = vadd.s32 %v22026, %v22021 (stack39)
        %v22031 = vshll.u32 %v22026, 15 (stack44)
        %v22032 = vshrl.u32 %v22026, 17 (stack45)
        %v22033 = vor.u32 %v22032, %v22031 (stack46)
        %v22034 = vxor.u32 %v22033, %v22029 (stack47)
        %v22037 = vadd.s32 %v22034, %v22029 (stack39)
        %v22039 = vshll.u32 %v22034, 26 (stack44)
        %v22040 = vshrl.u32 %v22034, 6 (stack45)
        %v22041 = vor.u32 %v22040, %v22039 (stack46)
        %v22042 = vxor.u32 %v22041, %v22037 (stack47)
        %v22045 = vadd.s32 %v22042, %v22037 (stack39)
        %v22049 = vadd.s32 %v22045, %v9 (stack39)
        %v22051 = vshll.u32 %v22042, 6 (stack44)
        %v22052 = vshrl.u32 %v22042, 26 (stack45)
        %v22053 = vor.u32 %v22052, %v22051 (stack46)
        %v22054 = vxor.u32 %v22053, %v22045 (stack47)
        %v22057 = vadd.s32 %v22054, %v8 (stack39)
        %v22061 = vadd.s32 1, %v22057 (stack39)
        %v22065 = vadd.s32 %v22061, %v22049 (stack39)
        %v22067 = vshll.u32 %v22061, 17 (stack44)
        %v22068 = vshrl.u32 %v22061, 15 (stack45)
        %v22069 = vor.u32 %v22068, %v22067 (stack46)
        %v22070 = vxor.u32 %v22069, %v22065 (stack47)
        %v22073 = vadd.s32 %v22070, %v22065 (stack39)
        %v22075 = vshll.u32 %v22070, 29 (stack44)
        %v22076 = vshrl.u32 %v22070, 3 (stack45)
        %v22077 = vor.u32 %v22076, %v22075 (stack46)
        %v22078 = vxor.u32 %v22077, %v22073 (stack47)
        %v22081 = vadd.s32 %v22078, %v22073 (stack39)
        %v22083 = vshll.u32 %v22078, 16 (stack44)
        %v22084 = vshrl.u32 %v22078, 16 (stack45)
        %v22085 = vor.u32 %v22084, %v22083 (stack46)
        %v22086 = vxor.u32 %v22085, %v22081 (stack47)
        %v22089 = vadd.s32 %v22086, %v22081 (stack39)
        %v22093 = vadd.s32 %v22089, %v8 (stack39)
        %v22095 = vshll.u32 %v22086, 24 (stack44)
        %v22096 = vshrl.u32 %v22086, 8 (stack45)
        %v22097 = vor.u32 %v22096, %v22095 (stack46)
        %v22098 = vxor.u32 %v22097, %v22089 (stack47)
        %v22101 = vadd.s32 %v22098, %v10 (stack39)
        %v22105 = vadd.s32 2, %v22101 (stack39)
        %v22109 = vadd.s32 %v22105, %v22093 (stack39)
        %v22111 = vshll.u32 %v22105, 13 (stack44)
        %v22112 = vshrl.u32 %v22105, 19 (stack45)
        %v22113 = vor.u32 %v22112, %v22111 (stack46)
        %v22114 = vxor.u32 %v22113, %v22109 (stack47)
        %v22117 = vadd.s32 %v22114, %v22109 (stack39)
        %v22119 = vshll.u32 %v22114, 15 (stack44)
        %v22120 = vshrl.u32 %v22114, 17 (stack45)
        %v22121 = vor.u32 %v22120, %v22119 (stack46)
        %v22122 = vxor.u32 %v22121, %v22117 (stack47)
        %v22125 = vadd.s32 %v22122, %v22117 (stack39)
        %v22127 = vshll.u32 %v22122, 26 (stack44)
        %v22128 = vshrl.u32 %v22122, 6 (stack45)
        %v22129 = vor.u32 %v22128, %v22127 (stack46)
        %v22130 = vxor.u32 %v22129, %v22125 (stack47)
        %v22133 = vadd.s32 %v22130, %v22125 (stack39)
        %v22137 = vadd.s32 %v22133, %v10 (stack39)
        %v22139 = vshll.u32 %v22130, 6 (stack44)
        %v22140 = vshrl.u32 %v22130, 26 (stack45)
        %v22141 = vor.u32 %v22140, %v22139 (stack46)
        %v22142 = vxor.u32 %v22141, %v22133 (stack47)
        %v22145 = vadd.s32 %v22142, %v9 (stack39)
        %v22149 = vadd.s32 3, %v22145 (stack39)
        %v22153 = vadd.s32 %v22149, %v22137 (stack39)
        %v22155 = vshll.u32 %v22149, 17 (stack44)
        %v22156 = vshrl.u32 %v22149, 15 (stack45)
        %v22157 = vor.u32 %v22156, %v22155 (stack46)
        %v22158 = vxor.u32 %v22157, %v22153 (stack47)
        %v22161 = vadd.s32 %v22158, %v22153 (stack39)
        %v22163 = vshll.u32 %v22158, 29 (stack44)
        %v22164 = vshrl.u32 %v22158, 3 (stack45)
        %v22165 = vor.u32 %v22164, %v22163 (stack46)
        %v22166 = vxor.u32 %v22165, %v22161 (stack47)
        %v22169 = vadd.s32 %v22166, %v22161 (stack39)
        %v22171 = vshll.u32 %v22166, 16 (stack44)
        %v22172 = vshrl.u32 %v22166, 16 (stack45)
        %v22173 = vor.u32 %v22172, %v22171 (stack46)
        %v22174 = vxor.u32 %v22173, %v22169 (stack47)
        %v22177 = vadd.s32 %v22174, %v22169 (stack39)
        %v22181 = vadd.s32 %v22177, %v9 (stack39)
        %v22183 = vshll.u32 %v22174, 24 (stack44)
        %v22184 = vshrl.u32 %v22174, 8 (stack45)
        %v22185 = vor.u32 %v22184, %v22183 (stack46)
        %v22186 = vxor.u32 %v22185, %v22177 (stack47)
        %v22189 = vadd.s32 %v22186, %v8 (stack39)
        %v22193 = vadd.s32 4, %v22189 (stack39)
        %v22197 = vadd.s32 %v22193, %v22181 (stack39)
        %v22199 = vshll.u32 %v22193, 13 (stack44)
        %v22200 = vshrl.u32 %v22193, 19 (stack45)
        %v22201 = vor.u32 %v22200, %v22199 (stack46)
        %v22202 = vxor.u32 %v22201, %v22197 (stack47)
        %v22205 = vadd.s32 %v22202, %v22197 (stack39)
        %v22207 = vshll.u32 %v22202, 15 (stack44)
        %v22208 = vshrl.u32 %v22202, 17 (stack45)
        %v22209 = vor.u32 %v22208, %v22207 (stack46)
        %v22210 = vxor.u32 %v22209, %v22205 (stack47)
        %v22213 = vadd.s32 %v22210, %v22205 (stack39)
        %v22215 = vshll.u32 %v22210, 26 (stack44)
        %v22216 = vshrl.u32 %v22210, 6 (stack45)
        %v22217 = vor.u32 %v22216, %v22215 (stack46)
        %v22218 = vxor.u32 %v22217, %v22213 (stack47)
        %v22221 = vadd.s32 %v22218, %v22213 (stack39)
        %v22225 = vadd.s32 %v22221, %v8 (stack39)
        %v22227 = vshll.u32 %v22218, 6 (stack44)
        %v22228 = vshrl.u32 %v22218, 26 (stack45)
        %v22229 = vor.u32 %v22228, %v22227 (stack46)
        %v22230 = vxor.u32 %v22229, %v22221 (stack47)
        %v22233 = vadd.s32 %v22230, %v10 (stack39)
        %v22237 = vadd.s32 5, %v22233 (stack39)
        %v22239 = vxor.u32 %v22237, %v22225 (stack47)
        %v22240 = vand.u32.u8 255, %v22239 (stack48)
        %v22241 = vand.u32 65535, %v22240 (stack49)
        %v22242 = vshrl.u32 %v22241, 1 (stack50)
        %v22243 = vor.u32 16256, %v22242 (stack46)
        %v22244 = vand.u32.u16 65535, %v22243 (stack51)
        %v119860 = vadd.low.f32.bf16 -1.0, %v22244 (stack52)
        %v22253 = vmul.f32 2.0, %v119860 (stack53)
        %v22257 = vadd.f32 -0.99609375, %v22253 (stack52)
        %v22261 = vmax.f32 %v22257, -0.99609375 (stack54)
        %v22263 = vand.u32 2147483647, %v22261 (stack55)
        %vm22266 = vcmp.eq.f32.partialorder %v22263, 1.0 (stack56)
        %v22271 = vmul.f32 inf, %v22261 (stack53)
        %v22273 = vxor.u32 2147483648, %v22261 (stack57)
        %v22276 = vmul.f32 %v22273, %v22261 (stack53)
        %v22278 = vadd.f32 1.0, %v22276 (stack58)
        %v22279 = vlog2.pop %v22278 (stack59)
        %v22280 = vmul.f32 0.6931472, %v22279 (stack60)
        %v22281 = vmul.f32 -0.5, %v22276 (stack61)
        %v22282 = vadd.f32 1.0, %v22281 (stack62)
        %v22283 = vmul.f32 %v22282, %v22276 (stack63)
        %v22284 = vand.u32 2147483647, %v22276 (stack64)
        %vm22285 = vcmp.lt.f32.partialorder %v22284, 0.0004427343 (stack65)
        %v22286 = vsel /*vm=*/%vm22285, /*on_true_vy=*/%v22283, /*on_false_vx=*/%v22280 (stack66)
        %v22287 = vxor.u32 2147483648, %v22286 (stack57)
        %vm22290 = vcmp.lt.f32.partialorder %v22287, 5.0 (stack56)
        %v22295 = vsel /*vm=*/%vm22290, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v22299 = vsel /*vm=*/%vm22290, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v22303 = vsel /*vm=*/%vm22290, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v22307 = vsel /*vm=*/%vm22290, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v22311 = vsel /*vm=*/%vm22290, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v22315 = vsel /*vm=*/%vm22290, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v22319 = vsel /*vm=*/%vm22290, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v22323 = vsel /*vm=*/%vm22290, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v22327 = vsel /*vm=*/%vm22290, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v22331 = vadd.f32 -2.5, %v22287 (stack52)
        %v22333 = vrsqrt.pop %v22287 (stack67)
        %v22334 = vmul.f32 %v22333, %v22287 (stack68)
        %vm22335 = vcmp.eq.f32.partialorder %v22287, inf (stack69)
        %v22336 = vsel /*vm=*/%vm22335, /*on_true_vy=*/%v22287, /*on_false_vx=*/%v22334 (stack70)
        %vm22337 = vcmp.eq.f32.partialorder %v22287, 0.0 (stack71)
        %v22338 = vand.u32 2147483648, %v22287 (stack72)
        %v22339 = vsel /*vm=*/%vm22337, /*on_true_vy=*/%v22338, /*on_false_vx=*/%v22336 (stack73)
        %v22342 = vadd.f32 -3.0, %v22339 (stack52)
        %v22346 = vsel /*vm=*/%vm22290, /*on_true_vy=*/%v22331, /*on_false_vx=*/%v22342 (stack43)
        %v22350 = vmul.f32 %v22346, %v22327 (stack53)
        %v22354 = vadd.f32 %v22350, %v22323 (stack52)
        %v22358 = vmul.f32 %v22354, %v22346 (stack53)
        %v22362 = vadd.f32 %v22358, %v22319 (stack52)
        %v22366 = vmul.f32 %v22362, %v22346 (stack53)
        %v22370 = vadd.f32 %v22366, %v22315 (stack52)
        %v22374 = vmul.f32 %v22370, %v22346 (stack53)
        %v22378 = vadd.f32 %v22374, %v22311 (stack52)
        %v22382 = vmul.f32 %v22378, %v22346 (stack53)
        %v22386 = vadd.f32 %v22382, %v22307 (stack52)
        %v22390 = vmul.f32 %v22386, %v22346 (stack53)
        %v22394 = vadd.f32 %v22390, %v22303 (stack52)
        %v22398 = vmul.f32 %v22394, %v22346 (stack53)
        %v22402 = vadd.f32 %v22398, %v22299 (stack52)
        %v22406 = vmul.f32 %v22402, %v22346 (stack53)
        %v22410 = vadd.f32 %v22406, %v22295 (stack52)
        %v22414 = vmul.f32 %v22410, %v22261 (stack53)
        %v22418 = vsel /*vm=*/%vm22266, /*on_true_vy=*/%v22271, /*on_false_vx=*/%v22414 (stack43)
        %v22422 = vmul.f32 1.4140625, %v22418 (stack53)
        %v22425 = vpack.c.bf16 0.0, %v22422 (stack74)
        %119861 = vst [vmem:[%s280 + $0x314] sm:$0xf] /*vst_source=*/%v22425 (stack75)
        %v22429 = vadd.s32 %v19199, %v3816 (stack39)
        %v22439 = vadd.s32 %v22429, %v415 (stack39)
        %vm22443 = vcmp.lt.u32.totalorder %v22439, %v22429 (stack42)
        %vm22448 = vcmp.lt.u32.totalorder %v22429, %v3816 (stack42)
        %v22453 = vadd.s32 %v19182, %v3803 (stack39)
        %v22457 = vadd.s32 1, %v22453 (stack39)
        %v22461 = vsel /*vm=*/%vm22448, /*on_true_vy=*/%v22457, /*on_false_vx=*/%v22453 (stack43)
        %v22465 = vadd.s32 1, %v22461 (stack39)
        %v22469 = vsel /*vm=*/%vm22443, /*on_true_vy=*/%v22465, /*on_false_vx=*/%v22461 (stack43)
        %v22474 = vadd.s32 %v22469, %v10 (stack39)
        %v22478 = vadd.s32 %v22439, %v9 (stack39)
        %v22482 = vadd.s32 %v22478, %v22474 (stack39)
        %v22484 = vshll.u32 %v22478, 13 (stack44)
        %v22485 = vshrl.u32 %v22478, 19 (stack45)
        %v22486 = vor.u32 %v22485, %v22484 (stack46)
        %v22487 = vxor.u32 %v22486, %v22482 (stack47)
        %v22490 = vadd.s32 %v22487, %v22482 (stack39)
        %v22492 = vshll.u32 %v22487, 15 (stack44)
        %v22493 = vshrl.u32 %v22487, 17 (stack45)
        %v22494 = vor.u32 %v22493, %v22492 (stack46)
        %v22495 = vxor.u32 %v22494, %v22490 (stack47)
        %v22498 = vadd.s32 %v22495, %v22490 (stack39)
        %v22500 = vshll.u32 %v22495, 26 (stack44)
        %v22501 = vshrl.u32 %v22495, 6 (stack45)
        %v22502 = vor.u32 %v22501, %v22500 (stack46)
        %v22503 = vxor.u32 %v22502, %v22498 (stack47)
        %v22506 = vadd.s32 %v22503, %v22498 (stack39)
        %v22510 = vadd.s32 %v22506, %v9 (stack39)
        %v22512 = vshll.u32 %v22503, 6 (stack44)
        %v22513 = vshrl.u32 %v22503, 26 (stack45)
        %v22514 = vor.u32 %v22513, %v22512 (stack46)
        %v22515 = vxor.u32 %v22514, %v22506 (stack47)
        %v22518 = vadd.s32 %v22515, %v8 (stack39)
        %v22522 = vadd.s32 1, %v22518 (stack39)
        %v22526 = vadd.s32 %v22522, %v22510 (stack39)
        %v22528 = vshll.u32 %v22522, 17 (stack44)
        %v22529 = vshrl.u32 %v22522, 15 (stack45)
        %v22530 = vor.u32 %v22529, %v22528 (stack46)
        %v22531 = vxor.u32 %v22530, %v22526 (stack47)
        %v22534 = vadd.s32 %v22531, %v22526 (stack39)
        %v22536 = vshll.u32 %v22531, 29 (stack44)
        %v22537 = vshrl.u32 %v22531, 3 (stack45)
        %v22538 = vor.u32 %v22537, %v22536 (stack46)
        %v22539 = vxor.u32 %v22538, %v22534 (stack47)
        %v22542 = vadd.s32 %v22539, %v22534 (stack39)
        %v22544 = vshll.u32 %v22539, 16 (stack44)
        %v22545 = vshrl.u32 %v22539, 16 (stack45)
        %v22546 = vor.u32 %v22545, %v22544 (stack46)
        %v22547 = vxor.u32 %v22546, %v22542 (stack47)
        %v22550 = vadd.s32 %v22547, %v22542 (stack39)
        %v22554 = vadd.s32 %v22550, %v8 (stack39)
        %v22556 = vshll.u32 %v22547, 24 (stack44)
        %v22557 = vshrl.u32 %v22547, 8 (stack45)
        %v22558 = vor.u32 %v22557, %v22556 (stack46)
        %v22559 = vxor.u32 %v22558, %v22550 (stack47)
        %v22562 = vadd.s32 %v22559, %v10 (stack39)
        %v22566 = vadd.s32 2, %v22562 (stack39)
        %v22570 = vadd.s32 %v22566, %v22554 (stack39)
        %v22572 = vshll.u32 %v22566, 13 (stack44)
        %v22573 = vshrl.u32 %v22566, 19 (stack45)
        %v22574 = vor.u32 %v22573, %v22572 (stack46)
        %v22575 = vxor.u32 %v22574, %v22570 (stack47)
        %v22578 = vadd.s32 %v22575, %v22570 (stack39)
        %v22580 = vshll.u32 %v22575, 15 (stack44)
        %v22581 = vshrl.u32 %v22575, 17 (stack45)
        %v22582 = vor.u32 %v22581, %v22580 (stack46)
        %v22583 = vxor.u32 %v22582, %v22578 (stack47)
        %v22586 = vadd.s32 %v22583, %v22578 (stack39)
        %v22588 = vshll.u32 %v22583, 26 (stack44)
        %v22589 = vshrl.u32 %v22583, 6 (stack45)
        %v22590 = vor.u32 %v22589, %v22588 (stack46)
        %v22591 = vxor.u32 %v22590, %v22586 (stack47)
        %v22594 = vadd.s32 %v22591, %v22586 (stack39)
        %v22598 = vadd.s32 %v22594, %v10 (stack39)
        %v22600 = vshll.u32 %v22591, 6 (stack44)
        %v22601 = vshrl.u32 %v22591, 26 (stack45)
        %v22602 = vor.u32 %v22601, %v22600 (stack46)
        %v22603 = vxor.u32 %v22602, %v22594 (stack47)
        %v22606 = vadd.s32 %v22603, %v9 (stack39)
        %v22610 = vadd.s32 3, %v22606 (stack39)
        %v22614 = vadd.s32 %v22610, %v22598 (stack39)
        %v22616 = vshll.u32 %v22610, 17 (stack44)
        %v22617 = vshrl.u32 %v22610, 15 (stack45)
        %v22618 = vor.u32 %v22617, %v22616 (stack46)
        %v22619 = vxor.u32 %v22618, %v22614 (stack47)
        %v22622 = vadd.s32 %v22619, %v22614 (stack39)
        %v22624 = vshll.u32 %v22619, 29 (stack44)
        %v22625 = vshrl.u32 %v22619, 3 (stack45)
        %v22626 = vor.u32 %v22625, %v22624 (stack46)
        %v22627 = vxor.u32 %v22626, %v22622 (stack47)
        %v22630 = vadd.s32 %v22627, %v22622 (stack39)
        %v22632 = vshll.u32 %v22627, 16 (stack44)
        %v22633 = vshrl.u32 %v22627, 16 (stack45)
        %v22634 = vor.u32 %v22633, %v22632 (stack46)
        %v22635 = vxor.u32 %v22634, %v22630 (stack47)
        %v22638 = vadd.s32 %v22635, %v22630 (stack39)
        %v22642 = vadd.s32 %v22638, %v9 (stack39)
        %v22644 = vshll.u32 %v22635, 24 (stack44)
        %v22645 = vshrl.u32 %v22635, 8 (stack45)
        %v22646 = vor.u32 %v22645, %v22644 (stack46)
        %v22647 = vxor.u32 %v22646, %v22638 (stack47)
        %v22650 = vadd.s32 %v22647, %v8 (stack39)
        %v22654 = vadd.s32 4, %v22650 (stack39)
        %v22658 = vadd.s32 %v22654, %v22642 (stack39)
        %v22660 = vshll.u32 %v22654, 13 (stack44)
        %v22661 = vshrl.u32 %v22654, 19 (stack45)
        %v22662 = vor.u32 %v22661, %v22660 (stack46)
        %v22663 = vxor.u32 %v22662, %v22658 (stack47)
        %v22666 = vadd.s32 %v22663, %v22658 (stack39)
        %v22668 = vshll.u32 %v22663, 15 (stack44)
        %v22669 = vshrl.u32 %v22663, 17 (stack45)
        %v22670 = vor.u32 %v22669, %v22668 (stack46)
        %v22671 = vxor.u32 %v22670, %v22666 (stack47)
        %v22674 = vadd.s32 %v22671, %v22666 (stack39)
        %v22676 = vshll.u32 %v22671, 26 (stack44)
        %v22677 = vshrl.u32 %v22671, 6 (stack45)
        %v22678 = vor.u32 %v22677, %v22676 (stack46)
        %v22679 = vxor.u32 %v22678, %v22674 (stack47)
        %v22682 = vadd.s32 %v22679, %v22674 (stack39)
        %v22686 = vadd.s32 %v22682, %v8 (stack39)
        %v22688 = vshll.u32 %v22679, 6 (stack44)
        %v22689 = vshrl.u32 %v22679, 26 (stack45)
        %v22690 = vor.u32 %v22689, %v22688 (stack46)
        %v22691 = vxor.u32 %v22690, %v22682 (stack47)
        %v22694 = vadd.s32 %v22691, %v10 (stack39)
        %v22698 = vadd.s32 5, %v22694 (stack39)
        %v22700 = vxor.u32 %v22698, %v22686 (stack47)
        %v22701 = vand.u32.u8 255, %v22700 (stack48)
        %v22702 = vand.u32 65535, %v22701 (stack49)
        %v22703 = vshrl.u32 %v22702, 1 (stack50)
        %v22704 = vor.u32 16256, %v22703 (stack46)
        %v22705 = vand.u32.u16 65535, %v22704 (stack51)
        %v119862 = vadd.low.f32.bf16 -1.0, %v22705 (stack52)
        %v22714 = vmul.f32 2.0, %v119862 (stack53)
        %v22718 = vadd.f32 -0.99609375, %v22714 (stack52)
        %v22722 = vmax.f32 %v22718, -0.99609375 (stack54)
        %v22724 = vand.u32 2147483647, %v22722 (stack55)
        %vm22727 = vcmp.eq.f32.partialorder %v22724, 1.0 (stack56)
        %v22732 = vmul.f32 inf, %v22722 (stack53)
        %v22734 = vxor.u32 2147483648, %v22722 (stack57)
        %v22737 = vmul.f32 %v22734, %v22722 (stack53)
        %v22739 = vadd.f32 1.0, %v22737 (stack58)
        %v22740 = vlog2.pop %v22739 (stack59)
        %v22741 = vmul.f32 0.6931472, %v22740 (stack60)
        %v22742 = vmul.f32 -0.5, %v22737 (stack61)
        %v22743 = vadd.f32 1.0, %v22742 (stack62)
        %v22744 = vmul.f32 %v22743, %v22737 (stack63)
        %v22745 = vand.u32 2147483647, %v22737 (stack64)
        %vm22746 = vcmp.lt.f32.partialorder %v22745, 0.0004427343 (stack65)
        %v22747 = vsel /*vm=*/%vm22746, /*on_true_vy=*/%v22744, /*on_false_vx=*/%v22741 (stack66)
        %v22748 = vxor.u32 2147483648, %v22747 (stack57)
        %vm22751 = vcmp.lt.f32.partialorder %v22748, 5.0 (stack56)
        %v22756 = vsel /*vm=*/%vm22751, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v22760 = vsel /*vm=*/%vm22751, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v22764 = vsel /*vm=*/%vm22751, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v22768 = vsel /*vm=*/%vm22751, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v22772 = vsel /*vm=*/%vm22751, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v22776 = vsel /*vm=*/%vm22751, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v22780 = vsel /*vm=*/%vm22751, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v22784 = vsel /*vm=*/%vm22751, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v22788 = vsel /*vm=*/%vm22751, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v22792 = vadd.f32 -2.5, %v22748 (stack52)
        %v22794 = vrsqrt.pop %v22748 (stack67)
        %v22795 = vmul.f32 %v22794, %v22748 (stack68)
        %vm22796 = vcmp.eq.f32.partialorder %v22748, inf (stack69)
        %v22797 = vsel /*vm=*/%vm22796, /*on_true_vy=*/%v22748, /*on_false_vx=*/%v22795 (stack70)
        %vm22798 = vcmp.eq.f32.partialorder %v22748, 0.0 (stack71)
        %v22799 = vand.u32 2147483648, %v22748 (stack72)
        %v22800 = vsel /*vm=*/%vm22798, /*on_true_vy=*/%v22799, /*on_false_vx=*/%v22797 (stack73)
        %v22803 = vadd.f32 -3.0, %v22800 (stack52)
        %v22807 = vsel /*vm=*/%vm22751, /*on_true_vy=*/%v22792, /*on_false_vx=*/%v22803 (stack43)
        %v22811 = vmul.f32 %v22807, %v22788 (stack53)
        %v22815 = vadd.f32 %v22811, %v22784 (stack52)
        %v22819 = vmul.f32 %v22815, %v22807 (stack53)
        %v22823 = vadd.f32 %v22819, %v22780 (stack52)
        %v22827 = vmul.f32 %v22823, %v22807 (stack53)
        %v22831 = vadd.f32 %v22827, %v22776 (stack52)
        %v22835 = vmul.f32 %v22831, %v22807 (stack53)
        %v22839 = vadd.f32 %v22835, %v22772 (stack52)
        %v22843 = vmul.f32 %v22839, %v22807 (stack53)
        %v22847 = vadd.f32 %v22843, %v22768 (stack52)
        %v22851 = vmul.f32 %v22847, %v22807 (stack53)
        %v22855 = vadd.f32 %v22851, %v22764 (stack52)
        %v22859 = vmul.f32 %v22855, %v22807 (stack53)
        %v22863 = vadd.f32 %v22859, %v22760 (stack52)
        %v22867 = vmul.f32 %v22863, %v22807 (stack53)
        %v22871 = vadd.f32 %v22867, %v22756 (stack52)
        %v22875 = vmul.f32 %v22871, %v22722 (stack53)
        %v22879 = vsel /*vm=*/%vm22727, /*on_true_vy=*/%v22732, /*on_false_vx=*/%v22875 (stack43)
        %v22883 = vmul.f32 1.4140625, %v22879 (stack53)
        %v22886 = vpack.c.bf16 0.0, %v22883 (stack74)
        %119863 = vst [vmem:[%s280 + $0x394] sm:$0xf] /*vst_source=*/%v22886 (stack75)
        %s22888 = sadd.s32 48, %s120390 (stack76)
        %s22889 = sshrl.u32 %s22888, 10 (stack23)
        %p119864 = scmp.gt.s32.totalorder %s22889, 1 (stack24)
        %s22891 = scalar_select /*predicate=*/%p119864, /*on_true=*/1, /*on_false=*/%s22889 (stack25)
        %s22892 = sand.u32 1023, %s22888 /* smod.u32 w/div 1024 */ (stack26)
        %s22893 = sshrl.u32 %s22892, 7 (stack27)
        %s22894 = sand.u32 127, %s22892 /* smod.u32 w/div 128 */ (stack28)
        %s119865 = sshll.u32 %s22891, 3 (stack29)
        %s22896 = scalar_lea.vmem %s3, %s119865 (stack30)
        %s22898 = scalar_lea.vmem %s22896, %s22893 (stack31)
        %v22899 = vld [vmem:[%s22898] ss:$0 sm:$0xff] (stack32)
        %s22900 = sand.u32 255, %s22894 (stack33)
        %s22902 = sor.u32 256, %s22900 (stack34)
        %22903 = vbcast.lane.b32.xlu0 %v22899, %s22902 (stack35)
        %v22904 = vpop.permute.xlu0 %22903 (stack36)
        %s22913 = scalar_lea.vmem %s5, %s119865 (stack30)
        %s22915 = scalar_lea.vmem %s22913, %s22893 (stack31)
        %v22916 = vld [vmem:[%s22915] ss:$0 sm:$0xff] (stack32)
        %22920 = vbcast.lane.b32.xlu0 %v22916, %s22902 (stack35)
        %v22921 = vpop.permute.xlu0 %22920 (stack36)
        %v22924 = vadd.s32 %v22921, %v408 (stack39)
        %v22934 = vadd.s32 %v22924, %v415 (stack39)
        %vm22938 = vcmp.lt.u32.totalorder %v22934, %v22924 (stack42)
        %vm22943 = vcmp.lt.u32.totalorder %v22924, %v408 (stack42)
        %v22948 = vadd.s32 %v22904, %v380 (stack39)
        %v22952 = vadd.s32 1, %v22948 (stack39)
        %v22956 = vsel /*vm=*/%vm22943, /*on_true_vy=*/%v22952, /*on_false_vx=*/%v22948 (stack43)
        %v22960 = vadd.s32 1, %v22956 (stack39)
        %v22964 = vsel /*vm=*/%vm22938, /*on_true_vy=*/%v22960, /*on_false_vx=*/%v22956 (stack43)
        %v22969 = vadd.s32 %v22964, %v10 (stack39)
        %v22973 = vadd.s32 %v22934, %v9 (stack39)
        %v22977 = vadd.s32 %v22973, %v22969 (stack39)
        %v22979 = vshll.u32 %v22973, 13 (stack44)
        %v22980 = vshrl.u32 %v22973, 19 (stack45)
        %v22981 = vor.u32 %v22980, %v22979 (stack46)
        %v22982 = vxor.u32 %v22981, %v22977 (stack47)
        %v22985 = vadd.s32 %v22982, %v22977 (stack39)
        %v22987 = vshll.u32 %v22982, 15 (stack44)
        %v22988 = vshrl.u32 %v22982, 17 (stack45)
        %v22989 = vor.u32 %v22988, %v22987 (stack46)
        %v22990 = vxor.u32 %v22989, %v22985 (stack47)
        %v22993 = vadd.s32 %v22990, %v22985 (stack39)
        %v22995 = vshll.u32 %v22990, 26 (stack44)
        %v22996 = vshrl.u32 %v22990, 6 (stack45)
        %v22997 = vor.u32 %v22996, %v22995 (stack46)
        %v22998 = vxor.u32 %v22997, %v22993 (stack47)
        %v23001 = vadd.s32 %v22998, %v22993 (stack39)
        %v23005 = vadd.s32 %v23001, %v9 (stack39)
        %v23007 = vshll.u32 %v22998, 6 (stack44)
        %v23008 = vshrl.u32 %v22998, 26 (stack45)
        %v23009 = vor.u32 %v23008, %v23007 (stack46)
        %v23010 = vxor.u32 %v23009, %v23001 (stack47)
        %v23013 = vadd.s32 %v23010, %v8 (stack39)
        %v23017 = vadd.s32 1, %v23013 (stack39)
        %v23021 = vadd.s32 %v23017, %v23005 (stack39)
        %v23023 = vshll.u32 %v23017, 17 (stack44)
        %v23024 = vshrl.u32 %v23017, 15 (stack45)
        %v23025 = vor.u32 %v23024, %v23023 (stack46)
        %v23026 = vxor.u32 %v23025, %v23021 (stack47)
        %v23029 = vadd.s32 %v23026, %v23021 (stack39)
        %v23031 = vshll.u32 %v23026, 29 (stack44)
        %v23032 = vshrl.u32 %v23026, 3 (stack45)
        %v23033 = vor.u32 %v23032, %v23031 (stack46)
        %v23034 = vxor.u32 %v23033, %v23029 (stack47)
        %v23037 = vadd.s32 %v23034, %v23029 (stack39)
        %v23039 = vshll.u32 %v23034, 16 (stack44)
        %v23040 = vshrl.u32 %v23034, 16 (stack45)
        %v23041 = vor.u32 %v23040, %v23039 (stack46)
        %v23042 = vxor.u32 %v23041, %v23037 (stack47)
        %v23045 = vadd.s32 %v23042, %v23037 (stack39)
        %v23049 = vadd.s32 %v23045, %v8 (stack39)
        %v23051 = vshll.u32 %v23042, 24 (stack44)
        %v23052 = vshrl.u32 %v23042, 8 (stack45)
        %v23053 = vor.u32 %v23052, %v23051 (stack46)
        %v23054 = vxor.u32 %v23053, %v23045 (stack47)
        %v23057 = vadd.s32 %v23054, %v10 (stack39)
        %v23061 = vadd.s32 2, %v23057 (stack39)
        %v23065 = vadd.s32 %v23061, %v23049 (stack39)
        %v23067 = vshll.u32 %v23061, 13 (stack44)
        %v23068 = vshrl.u32 %v23061, 19 (stack45)
        %v23069 = vor.u32 %v23068, %v23067 (stack46)
        %v23070 = vxor.u32 %v23069, %v23065 (stack47)
        %v23073 = vadd.s32 %v23070, %v23065 (stack39)
        %v23075 = vshll.u32 %v23070, 15 (stack44)
        %v23076 = vshrl.u32 %v23070, 17 (stack45)
        %v23077 = vor.u32 %v23076, %v23075 (stack46)
        %v23078 = vxor.u32 %v23077, %v23073 (stack47)
        %v23081 = vadd.s32 %v23078, %v23073 (stack39)
        %v23083 = vshll.u32 %v23078, 26 (stack44)
        %v23084 = vshrl.u32 %v23078, 6 (stack45)
        %v23085 = vor.u32 %v23084, %v23083 (stack46)
        %v23086 = vxor.u32 %v23085, %v23081 (stack47)
        %v23089 = vadd.s32 %v23086, %v23081 (stack39)
        %v23093 = vadd.s32 %v23089, %v10 (stack39)
        %v23095 = vshll.u32 %v23086, 6 (stack44)
        %v23096 = vshrl.u32 %v23086, 26 (stack45)
        %v23097 = vor.u32 %v23096, %v23095 (stack46)
        %v23098 = vxor.u32 %v23097, %v23089 (stack47)
        %v23101 = vadd.s32 %v23098, %v9 (stack39)
        %v23105 = vadd.s32 3, %v23101 (stack39)
        %v23109 = vadd.s32 %v23105, %v23093 (stack39)
        %v23111 = vshll.u32 %v23105, 17 (stack44)
        %v23112 = vshrl.u32 %v23105, 15 (stack45)
        %v23113 = vor.u32 %v23112, %v23111 (stack46)
        %v23114 = vxor.u32 %v23113, %v23109 (stack47)
        %v23117 = vadd.s32 %v23114, %v23109 (stack39)
        %v23119 = vshll.u32 %v23114, 29 (stack44)
        %v23120 = vshrl.u32 %v23114, 3 (stack45)
        %v23121 = vor.u32 %v23120, %v23119 (stack46)
        %v23122 = vxor.u32 %v23121, %v23117 (stack47)
        %v23125 = vadd.s32 %v23122, %v23117 (stack39)
        %v23127 = vshll.u32 %v23122, 16 (stack44)
        %v23128 = vshrl.u32 %v23122, 16 (stack45)
        %v23129 = vor.u32 %v23128, %v23127 (stack46)
        %v23130 = vxor.u32 %v23129, %v23125 (stack47)
        %v23133 = vadd.s32 %v23130, %v23125 (stack39)
        %v23137 = vadd.s32 %v23133, %v9 (stack39)
        %v23139 = vshll.u32 %v23130, 24 (stack44)
        %v23140 = vshrl.u32 %v23130, 8 (stack45)
        %v23141 = vor.u32 %v23140, %v23139 (stack46)
        %v23142 = vxor.u32 %v23141, %v23133 (stack47)
        %v23145 = vadd.s32 %v23142, %v8 (stack39)
        %v23149 = vadd.s32 4, %v23145 (stack39)
        %v23153 = vadd.s32 %v23149, %v23137 (stack39)
        %v23155 = vshll.u32 %v23149, 13 (stack44)
        %v23156 = vshrl.u32 %v23149, 19 (stack45)
        %v23157 = vor.u32 %v23156, %v23155 (stack46)
        %v23158 = vxor.u32 %v23157, %v23153 (stack47)
        %v23161 = vadd.s32 %v23158, %v23153 (stack39)
        %v23163 = vshll.u32 %v23158, 15 (stack44)
        %v23164 = vshrl.u32 %v23158, 17 (stack45)
        %v23165 = vor.u32 %v23164, %v23163 (stack46)
        %v23166 = vxor.u32 %v23165, %v23161 (stack47)
        %v23169 = vadd.s32 %v23166, %v23161 (stack39)
        %v23171 = vshll.u32 %v23166, 26 (stack44)
        %v23172 = vshrl.u32 %v23166, 6 (stack45)
        %v23173 = vor.u32 %v23172, %v23171 (stack46)
        %v23174 = vxor.u32 %v23173, %v23169 (stack47)
        %v23177 = vadd.s32 %v23174, %v23169 (stack39)
        %v23181 = vadd.s32 %v23177, %v8 (stack39)
        %v23183 = vshll.u32 %v23174, 6 (stack44)
        %v23184 = vshrl.u32 %v23174, 26 (stack45)
        %v23185 = vor.u32 %v23184, %v23183 (stack46)
        %v23186 = vxor.u32 %v23185, %v23177 (stack47)
        %v23189 = vadd.s32 %v23186, %v10 (stack39)
        %v23193 = vadd.s32 5, %v23189 (stack39)
        %v23195 = vxor.u32 %v23193, %v23181 (stack47)
        %v23196 = vand.u32.u8 255, %v23195 (stack48)
        %v23197 = vand.u32 65535, %v23196 (stack49)
        %v23198 = vshrl.u32 %v23197, 1 (stack50)
        %v23199 = vor.u32 16256, %v23198 (stack46)
        %v23200 = vand.u32.u16 65535, %v23199 (stack51)
        %v119868 = vadd.low.f32.bf16 -1.0, %v23200 (stack52)
        %v23209 = vmul.f32 2.0, %v119868 (stack53)
        %v23213 = vadd.f32 -0.99609375, %v23209 (stack52)
        %v23217 = vmax.f32 %v23213, -0.99609375 (stack54)
        %v23219 = vand.u32 2147483647, %v23217 (stack55)
        %vm23222 = vcmp.eq.f32.partialorder %v23219, 1.0 (stack56)
        %v23227 = vmul.f32 inf, %v23217 (stack53)
        %v23229 = vxor.u32 2147483648, %v23217 (stack57)
        %v23232 = vmul.f32 %v23229, %v23217 (stack53)
        %v23234 = vadd.f32 1.0, %v23232 (stack58)
        %v23235 = vlog2.pop %v23234 (stack59)
        %v23236 = vmul.f32 0.6931472, %v23235 (stack60)
        %v23237 = vmul.f32 -0.5, %v23232 (stack61)
        %v23238 = vadd.f32 1.0, %v23237 (stack62)
        %v23239 = vmul.f32 %v23238, %v23232 (stack63)
        %v23240 = vand.u32 2147483647, %v23232 (stack64)
        %vm23241 = vcmp.lt.f32.partialorder %v23240, 0.0004427343 (stack65)
        %v23242 = vsel /*vm=*/%vm23241, /*on_true_vy=*/%v23239, /*on_false_vx=*/%v23236 (stack66)
        %v23243 = vxor.u32 2147483648, %v23242 (stack57)
        %vm23246 = vcmp.lt.f32.partialorder %v23243, 5.0 (stack56)
        %v23251 = vsel /*vm=*/%vm23246, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v23255 = vsel /*vm=*/%vm23246, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v23259 = vsel /*vm=*/%vm23246, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v23263 = vsel /*vm=*/%vm23246, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v23267 = vsel /*vm=*/%vm23246, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v23271 = vsel /*vm=*/%vm23246, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v23275 = vsel /*vm=*/%vm23246, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v23279 = vsel /*vm=*/%vm23246, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v23283 = vsel /*vm=*/%vm23246, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v23287 = vadd.f32 -2.5, %v23243 (stack52)
        %v23289 = vrsqrt.pop %v23243 (stack67)
        %v23290 = vmul.f32 %v23289, %v23243 (stack68)
        %vm23291 = vcmp.eq.f32.partialorder %v23243, inf (stack69)
        %v23292 = vsel /*vm=*/%vm23291, /*on_true_vy=*/%v23243, /*on_false_vx=*/%v23290 (stack70)
        %vm23293 = vcmp.eq.f32.partialorder %v23243, 0.0 (stack71)
        %v23294 = vand.u32 2147483648, %v23243 (stack72)
        %v23295 = vsel /*vm=*/%vm23293, /*on_true_vy=*/%v23294, /*on_false_vx=*/%v23292 (stack73)
        %v23298 = vadd.f32 -3.0, %v23295 (stack52)
        %v23302 = vsel /*vm=*/%vm23246, /*on_true_vy=*/%v23287, /*on_false_vx=*/%v23298 (stack43)
        %v23306 = vmul.f32 %v23302, %v23283 (stack53)
        %v23310 = vadd.f32 %v23306, %v23279 (stack52)
        %v23314 = vmul.f32 %v23310, %v23302 (stack53)
        %v23318 = vadd.f32 %v23314, %v23275 (stack52)
        %v23322 = vmul.f32 %v23318, %v23302 (stack53)
        %v23326 = vadd.f32 %v23322, %v23271 (stack52)
        %v23330 = vmul.f32 %v23326, %v23302 (stack53)
        %v23334 = vadd.f32 %v23330, %v23267 (stack52)
        %v23338 = vmul.f32 %v23334, %v23302 (stack53)
        %v23342 = vadd.f32 %v23338, %v23263 (stack52)
        %v23346 = vmul.f32 %v23342, %v23302 (stack53)
        %v23350 = vadd.f32 %v23346, %v23259 (stack52)
        %v23354 = vmul.f32 %v23350, %v23302 (stack53)
        %v23358 = vadd.f32 %v23354, %v23255 (stack52)
        %v23362 = vmul.f32 %v23358, %v23302 (stack53)
        %v23366 = vadd.f32 %v23362, %v23251 (stack52)
        %v23370 = vmul.f32 %v23366, %v23217 (stack53)
        %v23374 = vsel /*vm=*/%vm23222, /*on_true_vy=*/%v23227, /*on_false_vx=*/%v23370 (stack43)
        %v23378 = vmul.f32 1.4140625, %v23374 (stack53)
        %v23381 = vpack.c.bf16 0.0, %v23378 (stack74)
        %119869 = vst [vmem:[%s280 + $0x18] sm:$0xf] /*vst_source=*/%v23381 (stack75)
        %v23385 = vadd.s32 %v22921, %v894 (stack39)
        %v23395 = vadd.s32 %v23385, %v415 (stack39)
        %vm23399 = vcmp.lt.u32.totalorder %v23395, %v23385 (stack42)
        %vm23404 = vcmp.lt.u32.totalorder %v23385, %v894 (stack42)
        %v23409 = vadd.s32 %v22904, %v881 (stack39)
        %v23413 = vadd.s32 1, %v23409 (stack39)
        %v23417 = vsel /*vm=*/%vm23404, /*on_true_vy=*/%v23413, /*on_false_vx=*/%v23409 (stack43)
        %v23421 = vadd.s32 1, %v23417 (stack39)
        %v23425 = vsel /*vm=*/%vm23399, /*on_true_vy=*/%v23421, /*on_false_vx=*/%v23417 (stack43)
        %v23430 = vadd.s32 %v23425, %v10 (stack39)
        %v23434 = vadd.s32 %v23395, %v9 (stack39)
        %v23438 = vadd.s32 %v23434, %v23430 (stack39)
        %v23440 = vshll.u32 %v23434, 13 (stack44)
        %v23441 = vshrl.u32 %v23434, 19 (stack45)
        %v23442 = vor.u32 %v23441, %v23440 (stack46)
        %v23443 = vxor.u32 %v23442, %v23438 (stack47)
        %v23446 = vadd.s32 %v23443, %v23438 (stack39)
        %v23448 = vshll.u32 %v23443, 15 (stack44)
        %v23449 = vshrl.u32 %v23443, 17 (stack45)
        %v23450 = vor.u32 %v23449, %v23448 (stack46)
        %v23451 = vxor.u32 %v23450, %v23446 (stack47)
        %v23454 = vadd.s32 %v23451, %v23446 (stack39)
        %v23456 = vshll.u32 %v23451, 26 (stack44)
        %v23457 = vshrl.u32 %v23451, 6 (stack45)
        %v23458 = vor.u32 %v23457, %v23456 (stack46)
        %v23459 = vxor.u32 %v23458, %v23454 (stack47)
        %v23462 = vadd.s32 %v23459, %v23454 (stack39)
        %v23466 = vadd.s32 %v23462, %v9 (stack39)
        %v23468 = vshll.u32 %v23459, 6 (stack44)
        %v23469 = vshrl.u32 %v23459, 26 (stack45)
        %v23470 = vor.u32 %v23469, %v23468 (stack46)
        %v23471 = vxor.u32 %v23470, %v23462 (stack47)
        %v23474 = vadd.s32 %v23471, %v8 (stack39)
        %v23478 = vadd.s32 1, %v23474 (stack39)
        %v23482 = vadd.s32 %v23478, %v23466 (stack39)
        %v23484 = vshll.u32 %v23478, 17 (stack44)
        %v23485 = vshrl.u32 %v23478, 15 (stack45)
        %v23486 = vor.u32 %v23485, %v23484 (stack46)
        %v23487 = vxor.u32 %v23486, %v23482 (stack47)
        %v23490 = vadd.s32 %v23487, %v23482 (stack39)
        %v23492 = vshll.u32 %v23487, 29 (stack44)
        %v23493 = vshrl.u32 %v23487, 3 (stack45)
        %v23494 = vor.u32 %v23493, %v23492 (stack46)
        %v23495 = vxor.u32 %v23494, %v23490 (stack47)
        %v23498 = vadd.s32 %v23495, %v23490 (stack39)
        %v23500 = vshll.u32 %v23495, 16 (stack44)
        %v23501 = vshrl.u32 %v23495, 16 (stack45)
        %v23502 = vor.u32 %v23501, %v23500 (stack46)
        %v23503 = vxor.u32 %v23502, %v23498 (stack47)
        %v23506 = vadd.s32 %v23503, %v23498 (stack39)
        %v23510 = vadd.s32 %v23506, %v8 (stack39)
        %v23512 = vshll.u32 %v23503, 24 (stack44)
        %v23513 = vshrl.u32 %v23503, 8 (stack45)
        %v23514 = vor.u32 %v23513, %v23512 (stack46)
        %v23515 = vxor.u32 %v23514, %v23506 (stack47)
        %v23518 = vadd.s32 %v23515, %v10 (stack39)
        %v23522 = vadd.s32 2, %v23518 (stack39)
        %v23526 = vadd.s32 %v23522, %v23510 (stack39)
        %v23528 = vshll.u32 %v23522, 13 (stack44)
        %v23529 = vshrl.u32 %v23522, 19 (stack45)
        %v23530 = vor.u32 %v23529, %v23528 (stack46)
        %v23531 = vxor.u32 %v23530, %v23526 (stack47)
        %v23534 = vadd.s32 %v23531, %v23526 (stack39)
        %v23536 = vshll.u32 %v23531, 15 (stack44)
        %v23537 = vshrl.u32 %v23531, 17 (stack45)
        %v23538 = vor.u32 %v23537, %v23536 (stack46)
        %v23539 = vxor.u32 %v23538, %v23534 (stack47)
        %v23542 = vadd.s32 %v23539, %v23534 (stack39)
        %v23544 = vshll.u32 %v23539, 26 (stack44)
        %v23545 = vshrl.u32 %v23539, 6 (stack45)
        %v23546 = vor.u32 %v23545, %v23544 (stack46)
        %v23547 = vxor.u32 %v23546, %v23542 (stack47)
        %v23550 = vadd.s32 %v23547, %v23542 (stack39)
        %v23554 = vadd.s32 %v23550, %v10 (stack39)
        %v23556 = vshll.u32 %v23547, 6 (stack44)
        %v23557 = vshrl.u32 %v23547, 26 (stack45)
        %v23558 = vor.u32 %v23557, %v23556 (stack46)
        %v23559 = vxor.u32 %v23558, %v23550 (stack47)
        %v23562 = vadd.s32 %v23559, %v9 (stack39)
        %v23566 = vadd.s32 3, %v23562 (stack39)
        %v23570 = vadd.s32 %v23566, %v23554 (stack39)
        %v23572 = vshll.u32 %v23566, 17 (stack44)
        %v23573 = vshrl.u32 %v23566, 15 (stack45)
        %v23574 = vor.u32 %v23573, %v23572 (stack46)
        %v23575 = vxor.u32 %v23574, %v23570 (stack47)
        %v23578 = vadd.s32 %v23575, %v23570 (stack39)
        %v23580 = vshll.u32 %v23575, 29 (stack44)
        %v23581 = vshrl.u32 %v23575, 3 (stack45)
        %v23582 = vor.u32 %v23581, %v23580 (stack46)
        %v23583 = vxor.u32 %v23582, %v23578 (stack47)
        %v23586 = vadd.s32 %v23583, %v23578 (stack39)
        %v23588 = vshll.u32 %v23583, 16 (stack44)
        %v23589 = vshrl.u32 %v23583, 16 (stack45)
        %v23590 = vor.u32 %v23589, %v23588 (stack46)
        %v23591 = vxor.u32 %v23590, %v23586 (stack47)
        %v23594 = vadd.s32 %v23591, %v23586 (stack39)
        %v23598 = vadd.s32 %v23594, %v9 (stack39)
        %v23600 = vshll.u32 %v23591, 24 (stack44)
        %v23601 = vshrl.u32 %v23591, 8 (stack45)
        %v23602 = vor.u32 %v23601, %v23600 (stack46)
        %v23603 = vxor.u32 %v23602, %v23594 (stack47)
        %v23606 = vadd.s32 %v23603, %v8 (stack39)
        %v23610 = vadd.s32 4, %v23606 (stack39)
        %v23614 = vadd.s32 %v23610, %v23598 (stack39)
        %v23616 = vshll.u32 %v23610, 13 (stack44)
        %v23617 = vshrl.u32 %v23610, 19 (stack45)
        %v23618 = vor.u32 %v23617, %v23616 (stack46)
        %v23619 = vxor.u32 %v23618, %v23614 (stack47)
        %v23622 = vadd.s32 %v23619, %v23614 (stack39)
        %v23624 = vshll.u32 %v23619, 15 (stack44)
        %v23625 = vshrl.u32 %v23619, 17 (stack45)
        %v23626 = vor.u32 %v23625, %v23624 (stack46)
        %v23627 = vxor.u32 %v23626, %v23622 (stack47)
        %v23630 = vadd.s32 %v23627, %v23622 (stack39)
        %v23632 = vshll.u32 %v23627, 26 (stack44)
        %v23633 = vshrl.u32 %v23627, 6 (stack45)
        %v23634 = vor.u32 %v23633, %v23632 (stack46)
        %v23635 = vxor.u32 %v23634, %v23630 (stack47)
        %v23638 = vadd.s32 %v23635, %v23630 (stack39)
        %v23642 = vadd.s32 %v23638, %v8 (stack39)
        %v23644 = vshll.u32 %v23635, 6 (stack44)
        %v23645 = vshrl.u32 %v23635, 26 (stack45)
        %v23646 = vor.u32 %v23645, %v23644 (stack46)
        %v23647 = vxor.u32 %v23646, %v23638 (stack47)
        %v23650 = vadd.s32 %v23647, %v10 (stack39)
        %v23654 = vadd.s32 5, %v23650 (stack39)
        %v23656 = vxor.u32 %v23654, %v23642 (stack47)
        %v23657 = vand.u32.u8 255, %v23656 (stack48)
        %v23658 = vand.u32 65535, %v23657 (stack49)
        %v23659 = vshrl.u32 %v23658, 1 (stack50)
        %v23660 = vor.u32 16256, %v23659 (stack46)
        %v23661 = vand.u32.u16 65535, %v23660 (stack51)
        %v119870 = vadd.low.f32.bf16 -1.0, %v23661 (stack52)
        %v23670 = vmul.f32 2.0, %v119870 (stack53)
        %v23674 = vadd.f32 -0.99609375, %v23670 (stack52)
        %v23678 = vmax.f32 %v23674, -0.99609375 (stack54)
        %v23680 = vand.u32 2147483647, %v23678 (stack55)
        %vm23683 = vcmp.eq.f32.partialorder %v23680, 1.0 (stack56)
        %v23688 = vmul.f32 inf, %v23678 (stack53)
        %v23690 = vxor.u32 2147483648, %v23678 (stack57)
        %v23693 = vmul.f32 %v23690, %v23678 (stack53)
        %v23695 = vadd.f32 1.0, %v23693 (stack58)
        %v23696 = vlog2.pop %v23695 (stack59)
        %v23697 = vmul.f32 0.6931472, %v23696 (stack60)
        %v23698 = vmul.f32 -0.5, %v23693 (stack61)
        %v23699 = vadd.f32 1.0, %v23698 (stack62)
        %v23700 = vmul.f32 %v23699, %v23693 (stack63)
        %v23701 = vand.u32 2147483647, %v23693 (stack64)
        %vm23702 = vcmp.lt.f32.partialorder %v23701, 0.0004427343 (stack65)
        %v23703 = vsel /*vm=*/%vm23702, /*on_true_vy=*/%v23700, /*on_false_vx=*/%v23697 (stack66)
        %v23704 = vxor.u32 2147483648, %v23703 (stack57)
        %vm23707 = vcmp.lt.f32.partialorder %v23704, 5.0 (stack56)
        %v23712 = vsel /*vm=*/%vm23707, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v23716 = vsel /*vm=*/%vm23707, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v23720 = vsel /*vm=*/%vm23707, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v23724 = vsel /*vm=*/%vm23707, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v23728 = vsel /*vm=*/%vm23707, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v23732 = vsel /*vm=*/%vm23707, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v23736 = vsel /*vm=*/%vm23707, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v23740 = vsel /*vm=*/%vm23707, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v23744 = vsel /*vm=*/%vm23707, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v23748 = vadd.f32 -2.5, %v23704 (stack52)
        %v23750 = vrsqrt.pop %v23704 (stack67)
        %v23751 = vmul.f32 %v23750, %v23704 (stack68)
        %vm23752 = vcmp.eq.f32.partialorder %v23704, inf (stack69)
        %v23753 = vsel /*vm=*/%vm23752, /*on_true_vy=*/%v23704, /*on_false_vx=*/%v23751 (stack70)
        %vm23754 = vcmp.eq.f32.partialorder %v23704, 0.0 (stack71)
        %v23755 = vand.u32 2147483648, %v23704 (stack72)
        %v23756 = vsel /*vm=*/%vm23754, /*on_true_vy=*/%v23755, /*on_false_vx=*/%v23753 (stack73)
        %v23759 = vadd.f32 -3.0, %v23756 (stack52)
        %v23763 = vsel /*vm=*/%vm23707, /*on_true_vy=*/%v23748, /*on_false_vx=*/%v23759 (stack43)
        %v23767 = vmul.f32 %v23763, %v23744 (stack53)
        %v23771 = vadd.f32 %v23767, %v23740 (stack52)
        %v23775 = vmul.f32 %v23771, %v23763 (stack53)
        %v23779 = vadd.f32 %v23775, %v23736 (stack52)
        %v23783 = vmul.f32 %v23779, %v23763 (stack53)
        %v23787 = vadd.f32 %v23783, %v23732 (stack52)
        %v23791 = vmul.f32 %v23787, %v23763 (stack53)
        %v23795 = vadd.f32 %v23791, %v23728 (stack52)
        %v23799 = vmul.f32 %v23795, %v23763 (stack53)
        %v23803 = vadd.f32 %v23799, %v23724 (stack52)
        %v23807 = vmul.f32 %v23803, %v23763 (stack53)
        %v23811 = vadd.f32 %v23807, %v23720 (stack52)
        %v23815 = vmul.f32 %v23811, %v23763 (stack53)
        %v23819 = vadd.f32 %v23815, %v23716 (stack52)
        %v23823 = vmul.f32 %v23819, %v23763 (stack53)
        %v23827 = vadd.f32 %v23823, %v23712 (stack52)
        %v23831 = vmul.f32 %v23827, %v23678 (stack53)
        %v23835 = vsel /*vm=*/%vm23683, /*on_true_vy=*/%v23688, /*on_false_vx=*/%v23831 (stack43)
        %v23839 = vmul.f32 1.4140625, %v23835 (stack53)
        %v23842 = vpack.c.bf16 0.0, %v23839 (stack74)
        %119871 = vst [vmem:[%s280 + $0x98] sm:$0xf] /*vst_source=*/%v23842 (stack75)
        %v23846 = vadd.s32 %v22921, %v1381 (stack39)
        %v23856 = vadd.s32 %v23846, %v415 (stack39)
        %vm23860 = vcmp.lt.u32.totalorder %v23856, %v23846 (stack42)
        %vm23865 = vcmp.lt.u32.totalorder %v23846, %v1381 (stack42)
        %v23870 = vadd.s32 %v22904, %v1368 (stack39)
        %v23874 = vadd.s32 1, %v23870 (stack39)
        %v23878 = vsel /*vm=*/%vm23865, /*on_true_vy=*/%v23874, /*on_false_vx=*/%v23870 (stack43)
        %v23882 = vadd.s32 1, %v23878 (stack39)
        %v23886 = vsel /*vm=*/%vm23860, /*on_true_vy=*/%v23882, /*on_false_vx=*/%v23878 (stack43)
        %v23891 = vadd.s32 %v23886, %v10 (stack39)
        %v23895 = vadd.s32 %v23856, %v9 (stack39)
        %v23899 = vadd.s32 %v23895, %v23891 (stack39)
        %v23901 = vshll.u32 %v23895, 13 (stack44)
        %v23902 = vshrl.u32 %v23895, 19 (stack45)
        %v23903 = vor.u32 %v23902, %v23901 (stack46)
        %v23904 = vxor.u32 %v23903, %v23899 (stack47)
        %v23907 = vadd.s32 %v23904, %v23899 (stack39)
        %v23909 = vshll.u32 %v23904, 15 (stack44)
        %v23910 = vshrl.u32 %v23904, 17 (stack45)
        %v23911 = vor.u32 %v23910, %v23909 (stack46)
        %v23912 = vxor.u32 %v23911, %v23907 (stack47)
        %v23915 = vadd.s32 %v23912, %v23907 (stack39)
        %v23917 = vshll.u32 %v23912, 26 (stack44)
        %v23918 = vshrl.u32 %v23912, 6 (stack45)
        %v23919 = vor.u32 %v23918, %v23917 (stack46)
        %v23920 = vxor.u32 %v23919, %v23915 (stack47)
        %v23923 = vadd.s32 %v23920, %v23915 (stack39)
        %v23927 = vadd.s32 %v23923, %v9 (stack39)
        %v23929 = vshll.u32 %v23920, 6 (stack44)
        %v23930 = vshrl.u32 %v23920, 26 (stack45)
        %v23931 = vor.u32 %v23930, %v23929 (stack46)
        %v23932 = vxor.u32 %v23931, %v23923 (stack47)
        %v23935 = vadd.s32 %v23932, %v8 (stack39)
        %v23939 = vadd.s32 1, %v23935 (stack39)
        %v23943 = vadd.s32 %v23939, %v23927 (stack39)
        %v23945 = vshll.u32 %v23939, 17 (stack44)
        %v23946 = vshrl.u32 %v23939, 15 (stack45)
        %v23947 = vor.u32 %v23946, %v23945 (stack46)
        %v23948 = vxor.u32 %v23947, %v23943 (stack47)
        %v23951 = vadd.s32 %v23948, %v23943 (stack39)
        %v23953 = vshll.u32 %v23948, 29 (stack44)
        %v23954 = vshrl.u32 %v23948, 3 (stack45)
        %v23955 = vor.u32 %v23954, %v23953 (stack46)
        %v23956 = vxor.u32 %v23955, %v23951 (stack47)
        %v23959 = vadd.s32 %v23956, %v23951 (stack39)
        %v23961 = vshll.u32 %v23956, 16 (stack44)
        %v23962 = vshrl.u32 %v23956, 16 (stack45)
        %v23963 = vor.u32 %v23962, %v23961 (stack46)
        %v23964 = vxor.u32 %v23963, %v23959 (stack47)
        %v23967 = vadd.s32 %v23964, %v23959 (stack39)
        %v23971 = vadd.s32 %v23967, %v8 (stack39)
        %v23973 = vshll.u32 %v23964, 24 (stack44)
        %v23974 = vshrl.u32 %v23964, 8 (stack45)
        %v23975 = vor.u32 %v23974, %v23973 (stack46)
        %v23976 = vxor.u32 %v23975, %v23967 (stack47)
        %v23979 = vadd.s32 %v23976, %v10 (stack39)
        %v23983 = vadd.s32 2, %v23979 (stack39)
        %v23987 = vadd.s32 %v23983, %v23971 (stack39)
        %v23989 = vshll.u32 %v23983, 13 (stack44)
        %v23990 = vshrl.u32 %v23983, 19 (stack45)
        %v23991 = vor.u32 %v23990, %v23989 (stack46)
        %v23992 = vxor.u32 %v23991, %v23987 (stack47)
        %v23995 = vadd.s32 %v23992, %v23987 (stack39)
        %v23997 = vshll.u32 %v23992, 15 (stack44)
        %v23998 = vshrl.u32 %v23992, 17 (stack45)
        %v23999 = vor.u32 %v23998, %v23997 (stack46)
        %v24000 = vxor.u32 %v23999, %v23995 (stack47)
        %v24003 = vadd.s32 %v24000, %v23995 (stack39)
        %v24005 = vshll.u32 %v24000, 26 (stack44)
        %v24006 = vshrl.u32 %v24000, 6 (stack45)
        %v24007 = vor.u32 %v24006, %v24005 (stack46)
        %v24008 = vxor.u32 %v24007, %v24003 (stack47)
        %v24011 = vadd.s32 %v24008, %v24003 (stack39)
        %v24015 = vadd.s32 %v24011, %v10 (stack39)
        %v24017 = vshll.u32 %v24008, 6 (stack44)
        %v24018 = vshrl.u32 %v24008, 26 (stack45)
        %v24019 = vor.u32 %v24018, %v24017 (stack46)
        %v24020 = vxor.u32 %v24019, %v24011 (stack47)
        %v24023 = vadd.s32 %v24020, %v9 (stack39)
        %v24027 = vadd.s32 3, %v24023 (stack39)
        %v24031 = vadd.s32 %v24027, %v24015 (stack39)
        %v24033 = vshll.u32 %v24027, 17 (stack44)
        %v24034 = vshrl.u32 %v24027, 15 (stack45)
        %v24035 = vor.u32 %v24034, %v24033 (stack46)
        %v24036 = vxor.u32 %v24035, %v24031 (stack47)
        %v24039 = vadd.s32 %v24036, %v24031 (stack39)
        %v24041 = vshll.u32 %v24036, 29 (stack44)
        %v24042 = vshrl.u32 %v24036, 3 (stack45)
        %v24043 = vor.u32 %v24042, %v24041 (stack46)
        %v24044 = vxor.u32 %v24043, %v24039 (stack47)
        %v24047 = vadd.s32 %v24044, %v24039 (stack39)
        %v24049 = vshll.u32 %v24044, 16 (stack44)
        %v24050 = vshrl.u32 %v24044, 16 (stack45)
        %v24051 = vor.u32 %v24050, %v24049 (stack46)
        %v24052 = vxor.u32 %v24051, %v24047 (stack47)
        %v24055 = vadd.s32 %v24052, %v24047 (stack39)
        %v24059 = vadd.s32 %v24055, %v9 (stack39)
        %v24061 = vshll.u32 %v24052, 24 (stack44)
        %v24062 = vshrl.u32 %v24052, 8 (stack45)
        %v24063 = vor.u32 %v24062, %v24061 (stack46)
        %v24064 = vxor.u32 %v24063, %v24055 (stack47)
        %v24067 = vadd.s32 %v24064, %v8 (stack39)
        %v24071 = vadd.s32 4, %v24067 (stack39)
        %v24075 = vadd.s32 %v24071, %v24059 (stack39)
        %v24077 = vshll.u32 %v24071, 13 (stack44)
        %v24078 = vshrl.u32 %v24071, 19 (stack45)
        %v24079 = vor.u32 %v24078, %v24077 (stack46)
        %v24080 = vxor.u32 %v24079, %v24075 (stack47)
        %v24083 = vadd.s32 %v24080, %v24075 (stack39)
        %v24085 = vshll.u32 %v24080, 15 (stack44)
        %v24086 = vshrl.u32 %v24080, 17 (stack45)
        %v24087 = vor.u32 %v24086, %v24085 (stack46)
        %v24088 = vxor.u32 %v24087, %v24083 (stack47)
        %v24091 = vadd.s32 %v24088, %v24083 (stack39)
        %v24093 = vshll.u32 %v24088, 26 (stack44)
        %v24094 = vshrl.u32 %v24088, 6 (stack45)
        %v24095 = vor.u32 %v24094, %v24093 (stack46)
        %v24096 = vxor.u32 %v24095, %v24091 (stack47)
        %v24099 = vadd.s32 %v24096, %v24091 (stack39)
        %v24103 = vadd.s32 %v24099, %v8 (stack39)
        %v24105 = vshll.u32 %v24096, 6 (stack44)
        %v24106 = vshrl.u32 %v24096, 26 (stack45)
        %v24107 = vor.u32 %v24106, %v24105 (stack46)
        %v24108 = vxor.u32 %v24107, %v24099 (stack47)
        %v24111 = vadd.s32 %v24108, %v10 (stack39)
        %v24115 = vadd.s32 5, %v24111 (stack39)
        %v24117 = vxor.u32 %v24115, %v24103 (stack47)
        %v24118 = vand.u32.u8 255, %v24117 (stack48)
        %v24119 = vand.u32 65535, %v24118 (stack49)
        %v24120 = vshrl.u32 %v24119, 1 (stack50)
        %v24121 = vor.u32 16256, %v24120 (stack46)
        %v24122 = vand.u32.u16 65535, %v24121 (stack51)
        %v119872 = vadd.low.f32.bf16 -1.0, %v24122 (stack52)
        %v24131 = vmul.f32 2.0, %v119872 (stack53)
        %v24135 = vadd.f32 -0.99609375, %v24131 (stack52)
        %v24139 = vmax.f32 %v24135, -0.99609375 (stack54)
        %v24141 = vand.u32 2147483647, %v24139 (stack55)
        %vm24144 = vcmp.eq.f32.partialorder %v24141, 1.0 (stack56)
        %v24149 = vmul.f32 inf, %v24139 (stack53)
        %v24151 = vxor.u32 2147483648, %v24139 (stack57)
        %v24154 = vmul.f32 %v24151, %v24139 (stack53)
        %v24156 = vadd.f32 1.0, %v24154 (stack58)
        %v24157 = vlog2.pop %v24156 (stack59)
        %v24158 = vmul.f32 0.6931472, %v24157 (stack60)
        %v24159 = vmul.f32 -0.5, %v24154 (stack61)
        %v24160 = vadd.f32 1.0, %v24159 (stack62)
        %v24161 = vmul.f32 %v24160, %v24154 (stack63)
        %v24162 = vand.u32 2147483647, %v24154 (stack64)
        %vm24163 = vcmp.lt.f32.partialorder %v24162, 0.0004427343 (stack65)
        %v24164 = vsel /*vm=*/%vm24163, /*on_true_vy=*/%v24161, /*on_false_vx=*/%v24158 (stack66)
        %v24165 = vxor.u32 2147483648, %v24164 (stack57)
        %vm24168 = vcmp.lt.f32.partialorder %v24165, 5.0 (stack56)
        %v24173 = vsel /*vm=*/%vm24168, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v24177 = vsel /*vm=*/%vm24168, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v24181 = vsel /*vm=*/%vm24168, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v24185 = vsel /*vm=*/%vm24168, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v24189 = vsel /*vm=*/%vm24168, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v24193 = vsel /*vm=*/%vm24168, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v24197 = vsel /*vm=*/%vm24168, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v24201 = vsel /*vm=*/%vm24168, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v24205 = vsel /*vm=*/%vm24168, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v24209 = vadd.f32 -2.5, %v24165 (stack52)
        %v24211 = vrsqrt.pop %v24165 (stack67)
        %v24212 = vmul.f32 %v24211, %v24165 (stack68)
        %vm24213 = vcmp.eq.f32.partialorder %v24165, inf (stack69)
        %v24214 = vsel /*vm=*/%vm24213, /*on_true_vy=*/%v24165, /*on_false_vx=*/%v24212 (stack70)
        %vm24215 = vcmp.eq.f32.partialorder %v24165, 0.0 (stack71)
        %v24216 = vand.u32 2147483648, %v24165 (stack72)
        %v24217 = vsel /*vm=*/%vm24215, /*on_true_vy=*/%v24216, /*on_false_vx=*/%v24214 (stack73)
        %v24220 = vadd.f32 -3.0, %v24217 (stack52)
        %v24224 = vsel /*vm=*/%vm24168, /*on_true_vy=*/%v24209, /*on_false_vx=*/%v24220 (stack43)
        %v24228 = vmul.f32 %v24224, %v24205 (stack53)
        %v24232 = vadd.f32 %v24228, %v24201 (stack52)
        %v24236 = vmul.f32 %v24232, %v24224 (stack53)
        %v24240 = vadd.f32 %v24236, %v24197 (stack52)
        %v24244 = vmul.f32 %v24240, %v24224 (stack53)
        %v24248 = vadd.f32 %v24244, %v24193 (stack52)
        %v24252 = vmul.f32 %v24248, %v24224 (stack53)
        %v24256 = vadd.f32 %v24252, %v24189 (stack52)
        %v24260 = vmul.f32 %v24256, %v24224 (stack53)
        %v24264 = vadd.f32 %v24260, %v24185 (stack52)
        %v24268 = vmul.f32 %v24264, %v24224 (stack53)
        %v24272 = vadd.f32 %v24268, %v24181 (stack52)
        %v24276 = vmul.f32 %v24272, %v24224 (stack53)
        %v24280 = vadd.f32 %v24276, %v24177 (stack52)
        %v24284 = vmul.f32 %v24280, %v24224 (stack53)
        %v24288 = vadd.f32 %v24284, %v24173 (stack52)
        %v24292 = vmul.f32 %v24288, %v24139 (stack53)
        %v24296 = vsel /*vm=*/%vm24144, /*on_true_vy=*/%v24149, /*on_false_vx=*/%v24292 (stack43)
        %v24300 = vmul.f32 1.4140625, %v24296 (stack53)
        %v24303 = vpack.c.bf16 0.0, %v24300 (stack74)
        %119873 = vst [vmem:[%s280 + $0x118] sm:$0xf] /*vst_source=*/%v24303 (stack75)
        %v24307 = vadd.s32 %v22921, %v1868 (stack39)
        %v24317 = vadd.s32 %v24307, %v415 (stack39)
        %vm24321 = vcmp.lt.u32.totalorder %v24317, %v24307 (stack42)
        %vm24326 = vcmp.lt.u32.totalorder %v24307, %v1868 (stack42)
        %v24331 = vadd.s32 %v22904, %v1855 (stack39)
        %v24335 = vadd.s32 1, %v24331 (stack39)
        %v24339 = vsel /*vm=*/%vm24326, /*on_true_vy=*/%v24335, /*on_false_vx=*/%v24331 (stack43)
        %v24343 = vadd.s32 1, %v24339 (stack39)
        %v24347 = vsel /*vm=*/%vm24321, /*on_true_vy=*/%v24343, /*on_false_vx=*/%v24339 (stack43)
        %v24352 = vadd.s32 %v24347, %v10 (stack39)
        %v24356 = vadd.s32 %v24317, %v9 (stack39)
        %v24360 = vadd.s32 %v24356, %v24352 (stack39)
        %v24362 = vshll.u32 %v24356, 13 (stack44)
        %v24363 = vshrl.u32 %v24356, 19 (stack45)
        %v24364 = vor.u32 %v24363, %v24362 (stack46)
        %v24365 = vxor.u32 %v24364, %v24360 (stack47)
        %v24368 = vadd.s32 %v24365, %v24360 (stack39)
        %v24370 = vshll.u32 %v24365, 15 (stack44)
        %v24371 = vshrl.u32 %v24365, 17 (stack45)
        %v24372 = vor.u32 %v24371, %v24370 (stack46)
        %v24373 = vxor.u32 %v24372, %v24368 (stack47)
        %v24376 = vadd.s32 %v24373, %v24368 (stack39)
        %v24378 = vshll.u32 %v24373, 26 (stack44)
        %v24379 = vshrl.u32 %v24373, 6 (stack45)
        %v24380 = vor.u32 %v24379, %v24378 (stack46)
        %v24381 = vxor.u32 %v24380, %v24376 (stack47)
        %v24384 = vadd.s32 %v24381, %v24376 (stack39)
        %v24388 = vadd.s32 %v24384, %v9 (stack39)
        %v24390 = vshll.u32 %v24381, 6 (stack44)
        %v24391 = vshrl.u32 %v24381, 26 (stack45)
        %v24392 = vor.u32 %v24391, %v24390 (stack46)
        %v24393 = vxor.u32 %v24392, %v24384 (stack47)
        %v24396 = vadd.s32 %v24393, %v8 (stack39)
        %v24400 = vadd.s32 1, %v24396 (stack39)
        %v24404 = vadd.s32 %v24400, %v24388 (stack39)
        %v24406 = vshll.u32 %v24400, 17 (stack44)
        %v24407 = vshrl.u32 %v24400, 15 (stack45)
        %v24408 = vor.u32 %v24407, %v24406 (stack46)
        %v24409 = vxor.u32 %v24408, %v24404 (stack47)
        %v24412 = vadd.s32 %v24409, %v24404 (stack39)
        %v24414 = vshll.u32 %v24409, 29 (stack44)
        %v24415 = vshrl.u32 %v24409, 3 (stack45)
        %v24416 = vor.u32 %v24415, %v24414 (stack46)
        %v24417 = vxor.u32 %v24416, %v24412 (stack47)
        %v24420 = vadd.s32 %v24417, %v24412 (stack39)
        %v24422 = vshll.u32 %v24417, 16 (stack44)
        %v24423 = vshrl.u32 %v24417, 16 (stack45)
        %v24424 = vor.u32 %v24423, %v24422 (stack46)
        %v24425 = vxor.u32 %v24424, %v24420 (stack47)
        %v24428 = vadd.s32 %v24425, %v24420 (stack39)
        %v24432 = vadd.s32 %v24428, %v8 (stack39)
        %v24434 = vshll.u32 %v24425, 24 (stack44)
        %v24435 = vshrl.u32 %v24425, 8 (stack45)
        %v24436 = vor.u32 %v24435, %v24434 (stack46)
        %v24437 = vxor.u32 %v24436, %v24428 (stack47)
        %v24440 = vadd.s32 %v24437, %v10 (stack39)
        %v24444 = vadd.s32 2, %v24440 (stack39)
        %v24448 = vadd.s32 %v24444, %v24432 (stack39)
        %v24450 = vshll.u32 %v24444, 13 (stack44)
        %v24451 = vshrl.u32 %v24444, 19 (stack45)
        %v24452 = vor.u32 %v24451, %v24450 (stack46)
        %v24453 = vxor.u32 %v24452, %v24448 (stack47)
        %v24456 = vadd.s32 %v24453, %v24448 (stack39)
        %v24458 = vshll.u32 %v24453, 15 (stack44)
        %v24459 = vshrl.u32 %v24453, 17 (stack45)
        %v24460 = vor.u32 %v24459, %v24458 (stack46)
        %v24461 = vxor.u32 %v24460, %v24456 (stack47)
        %v24464 = vadd.s32 %v24461, %v24456 (stack39)
        %v24466 = vshll.u32 %v24461, 26 (stack44)
        %v24467 = vshrl.u32 %v24461, 6 (stack45)
        %v24468 = vor.u32 %v24467, %v24466 (stack46)
        %v24469 = vxor.u32 %v24468, %v24464 (stack47)
        %v24472 = vadd.s32 %v24469, %v24464 (stack39)
        %v24476 = vadd.s32 %v24472, %v10 (stack39)
        %v24478 = vshll.u32 %v24469, 6 (stack44)
        %v24479 = vshrl.u32 %v24469, 26 (stack45)
        %v24480 = vor.u32 %v24479, %v24478 (stack46)
        %v24481 = vxor.u32 %v24480, %v24472 (stack47)
        %v24484 = vadd.s32 %v24481, %v9 (stack39)
        %v24488 = vadd.s32 3, %v24484 (stack39)
        %v24492 = vadd.s32 %v24488, %v24476 (stack39)
        %v24494 = vshll.u32 %v24488, 17 (stack44)
        %v24495 = vshrl.u32 %v24488, 15 (stack45)
        %v24496 = vor.u32 %v24495, %v24494 (stack46)
        %v24497 = vxor.u32 %v24496, %v24492 (stack47)
        %v24500 = vadd.s32 %v24497, %v24492 (stack39)
        %v24502 = vshll.u32 %v24497, 29 (stack44)
        %v24503 = vshrl.u32 %v24497, 3 (stack45)
        %v24504 = vor.u32 %v24503, %v24502 (stack46)
        %v24505 = vxor.u32 %v24504, %v24500 (stack47)
        %v24508 = vadd.s32 %v24505, %v24500 (stack39)
        %v24510 = vshll.u32 %v24505, 16 (stack44)
        %v24511 = vshrl.u32 %v24505, 16 (stack45)
        %v24512 = vor.u32 %v24511, %v24510 (stack46)
        %v24513 = vxor.u32 %v24512, %v24508 (stack47)
        %v24516 = vadd.s32 %v24513, %v24508 (stack39)
        %v24520 = vadd.s32 %v24516, %v9 (stack39)
        %v24522 = vshll.u32 %v24513, 24 (stack44)
        %v24523 = vshrl.u32 %v24513, 8 (stack45)
        %v24524 = vor.u32 %v24523, %v24522 (stack46)
        %v24525 = vxor.u32 %v24524, %v24516 (stack47)
        %v24528 = vadd.s32 %v24525, %v8 (stack39)
        %v24532 = vadd.s32 4, %v24528 (stack39)
        %v24536 = vadd.s32 %v24532, %v24520 (stack39)
        %v24538 = vshll.u32 %v24532, 13 (stack44)
        %v24539 = vshrl.u32 %v24532, 19 (stack45)
        %v24540 = vor.u32 %v24539, %v24538 (stack46)
        %v24541 = vxor.u32 %v24540, %v24536 (stack47)
        %v24544 = vadd.s32 %v24541, %v24536 (stack39)
        %v24546 = vshll.u32 %v24541, 15 (stack44)
        %v24547 = vshrl.u32 %v24541, 17 (stack45)
        %v24548 = vor.u32 %v24547, %v24546 (stack46)
        %v24549 = vxor.u32 %v24548, %v24544 (stack47)
        %v24552 = vadd.s32 %v24549, %v24544 (stack39)
        %v24554 = vshll.u32 %v24549, 26 (stack44)
        %v24555 = vshrl.u32 %v24549, 6 (stack45)
        %v24556 = vor.u32 %v24555, %v24554 (stack46)
        %v24557 = vxor.u32 %v24556, %v24552 (stack47)
        %v24560 = vadd.s32 %v24557, %v24552 (stack39)
        %v24564 = vadd.s32 %v24560, %v8 (stack39)
        %v24566 = vshll.u32 %v24557, 6 (stack44)
        %v24567 = vshrl.u32 %v24557, 26 (stack45)
        %v24568 = vor.u32 %v24567, %v24566 (stack46)
        %v24569 = vxor.u32 %v24568, %v24560 (stack47)
        %v24572 = vadd.s32 %v24569, %v10 (stack39)
        %v24576 = vadd.s32 5, %v24572 (stack39)
        %v24578 = vxor.u32 %v24576, %v24564 (stack47)
        %v24579 = vand.u32.u8 255, %v24578 (stack48)
        %v24580 = vand.u32 65535, %v24579 (stack49)
        %v24581 = vshrl.u32 %v24580, 1 (stack50)
        %v24582 = vor.u32 16256, %v24581 (stack46)
        %v24583 = vand.u32.u16 65535, %v24582 (stack51)
        %v119874 = vadd.low.f32.bf16 -1.0, %v24583 (stack52)
        %v24592 = vmul.f32 2.0, %v119874 (stack53)
        %v24596 = vadd.f32 -0.99609375, %v24592 (stack52)
        %v24600 = vmax.f32 %v24596, -0.99609375 (stack54)
        %v24602 = vand.u32 2147483647, %v24600 (stack55)
        %vm24605 = vcmp.eq.f32.partialorder %v24602, 1.0 (stack56)
        %v24610 = vmul.f32 inf, %v24600 (stack53)
        %v24612 = vxor.u32 2147483648, %v24600 (stack57)
        %v24615 = vmul.f32 %v24612, %v24600 (stack53)
        %v24617 = vadd.f32 1.0, %v24615 (stack58)
        %v24618 = vlog2.pop %v24617 (stack59)
        %v24619 = vmul.f32 0.6931472, %v24618 (stack60)
        %v24620 = vmul.f32 -0.5, %v24615 (stack61)
        %v24621 = vadd.f32 1.0, %v24620 (stack62)
        %v24622 = vmul.f32 %v24621, %v24615 (stack63)
        %v24623 = vand.u32 2147483647, %v24615 (stack64)
        %vm24624 = vcmp.lt.f32.partialorder %v24623, 0.0004427343 (stack65)
        %v24625 = vsel /*vm=*/%vm24624, /*on_true_vy=*/%v24622, /*on_false_vx=*/%v24619 (stack66)
        %v24626 = vxor.u32 2147483648, %v24625 (stack57)
        %vm24629 = vcmp.lt.f32.partialorder %v24626, 5.0 (stack56)
        %v24634 = vsel /*vm=*/%vm24629, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v24638 = vsel /*vm=*/%vm24629, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v24642 = vsel /*vm=*/%vm24629, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v24646 = vsel /*vm=*/%vm24629, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v24650 = vsel /*vm=*/%vm24629, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v24654 = vsel /*vm=*/%vm24629, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v24658 = vsel /*vm=*/%vm24629, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v24662 = vsel /*vm=*/%vm24629, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v24666 = vsel /*vm=*/%vm24629, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v24670 = vadd.f32 -2.5, %v24626 (stack52)
        %v24672 = vrsqrt.pop %v24626 (stack67)
        %v24673 = vmul.f32 %v24672, %v24626 (stack68)
        %vm24674 = vcmp.eq.f32.partialorder %v24626, inf (stack69)
        %v24675 = vsel /*vm=*/%vm24674, /*on_true_vy=*/%v24626, /*on_false_vx=*/%v24673 (stack70)
        %vm24676 = vcmp.eq.f32.partialorder %v24626, 0.0 (stack71)
        %v24677 = vand.u32 2147483648, %v24626 (stack72)
        %v24678 = vsel /*vm=*/%vm24676, /*on_true_vy=*/%v24677, /*on_false_vx=*/%v24675 (stack73)
        %v24681 = vadd.f32 -3.0, %v24678 (stack52)
        %v24685 = vsel /*vm=*/%vm24629, /*on_true_vy=*/%v24670, /*on_false_vx=*/%v24681 (stack43)
        %v24689 = vmul.f32 %v24685, %v24666 (stack53)
        %v24693 = vadd.f32 %v24689, %v24662 (stack52)
        %v24697 = vmul.f32 %v24693, %v24685 (stack53)
        %v24701 = vadd.f32 %v24697, %v24658 (stack52)
        %v24705 = vmul.f32 %v24701, %v24685 (stack53)
        %v24709 = vadd.f32 %v24705, %v24654 (stack52)
        %v24713 = vmul.f32 %v24709, %v24685 (stack53)
        %v24717 = vadd.f32 %v24713, %v24650 (stack52)
        %v24721 = vmul.f32 %v24717, %v24685 (stack53)
        %v24725 = vadd.f32 %v24721, %v24646 (stack52)
        %v24729 = vmul.f32 %v24725, %v24685 (stack53)
        %v24733 = vadd.f32 %v24729, %v24642 (stack52)
        %v24737 = vmul.f32 %v24733, %v24685 (stack53)
        %v24741 = vadd.f32 %v24737, %v24638 (stack52)
        %v24745 = vmul.f32 %v24741, %v24685 (stack53)
        %v24749 = vadd.f32 %v24745, %v24634 (stack52)
        %v24753 = vmul.f32 %v24749, %v24600 (stack53)
        %v24757 = vsel /*vm=*/%vm24605, /*on_true_vy=*/%v24610, /*on_false_vx=*/%v24753 (stack43)
        %v24761 = vmul.f32 1.4140625, %v24757 (stack53)
        %v24764 = vpack.c.bf16 0.0, %v24761 (stack74)
        %119875 = vst [vmem:[%s280 + $0x198] sm:$0xf] /*vst_source=*/%v24764 (stack75)
        %v24768 = vadd.s32 %v22921, %v2355 (stack39)
        %v24778 = vadd.s32 %v24768, %v415 (stack39)
        %vm24782 = vcmp.lt.u32.totalorder %v24778, %v24768 (stack42)
        %vm24787 = vcmp.lt.u32.totalorder %v24768, %v2355 (stack42)
        %v24792 = vadd.s32 %v22904, %v2342 (stack39)
        %v24796 = vadd.s32 1, %v24792 (stack39)
        %v24800 = vsel /*vm=*/%vm24787, /*on_true_vy=*/%v24796, /*on_false_vx=*/%v24792 (stack43)
        %v24804 = vadd.s32 1, %v24800 (stack39)
        %v24808 = vsel /*vm=*/%vm24782, /*on_true_vy=*/%v24804, /*on_false_vx=*/%v24800 (stack43)
        %v24813 = vadd.s32 %v24808, %v10 (stack39)
        %v24817 = vadd.s32 %v24778, %v9 (stack39)
        %v24821 = vadd.s32 %v24817, %v24813 (stack39)
        %v24823 = vshll.u32 %v24817, 13 (stack44)
        %v24824 = vshrl.u32 %v24817, 19 (stack45)
        %v24825 = vor.u32 %v24824, %v24823 (stack46)
        %v24826 = vxor.u32 %v24825, %v24821 (stack47)
        %v24829 = vadd.s32 %v24826, %v24821 (stack39)
        %v24831 = vshll.u32 %v24826, 15 (stack44)
        %v24832 = vshrl.u32 %v24826, 17 (stack45)
        %v24833 = vor.u32 %v24832, %v24831 (stack46)
        %v24834 = vxor.u32 %v24833, %v24829 (stack47)
        %v24837 = vadd.s32 %v24834, %v24829 (stack39)
        %v24839 = vshll.u32 %v24834, 26 (stack44)
        %v24840 = vshrl.u32 %v24834, 6 (stack45)
        %v24841 = vor.u32 %v24840, %v24839 (stack46)
        %v24842 = vxor.u32 %v24841, %v24837 (stack47)
        %v24845 = vadd.s32 %v24842, %v24837 (stack39)
        %v24849 = vadd.s32 %v24845, %v9 (stack39)
        %v24851 = vshll.u32 %v24842, 6 (stack44)
        %v24852 = vshrl.u32 %v24842, 26 (stack45)
        %v24853 = vor.u32 %v24852, %v24851 (stack46)
        %v24854 = vxor.u32 %v24853, %v24845 (stack47)
        %v24857 = vadd.s32 %v24854, %v8 (stack39)
        %v24861 = vadd.s32 1, %v24857 (stack39)
        %v24865 = vadd.s32 %v24861, %v24849 (stack39)
        %v24867 = vshll.u32 %v24861, 17 (stack44)
        %v24868 = vshrl.u32 %v24861, 15 (stack45)
        %v24869 = vor.u32 %v24868, %v24867 (stack46)
        %v24870 = vxor.u32 %v24869, %v24865 (stack47)
        %v24873 = vadd.s32 %v24870, %v24865 (stack39)
        %v24875 = vshll.u32 %v24870, 29 (stack44)
        %v24876 = vshrl.u32 %v24870, 3 (stack45)
        %v24877 = vor.u32 %v24876, %v24875 (stack46)
        %v24878 = vxor.u32 %v24877, %v24873 (stack47)
        %v24881 = vadd.s32 %v24878, %v24873 (stack39)
        %v24883 = vshll.u32 %v24878, 16 (stack44)
        %v24884 = vshrl.u32 %v24878, 16 (stack45)
        %v24885 = vor.u32 %v24884, %v24883 (stack46)
        %v24886 = vxor.u32 %v24885, %v24881 (stack47)
        %v24889 = vadd.s32 %v24886, %v24881 (stack39)
        %v24893 = vadd.s32 %v24889, %v8 (stack39)
        %v24895 = vshll.u32 %v24886, 24 (stack44)
        %v24896 = vshrl.u32 %v24886, 8 (stack45)
        %v24897 = vor.u32 %v24896, %v24895 (stack46)
        %v24898 = vxor.u32 %v24897, %v24889 (stack47)
        %v24901 = vadd.s32 %v24898, %v10 (stack39)
        %v24905 = vadd.s32 2, %v24901 (stack39)
        %v24909 = vadd.s32 %v24905, %v24893 (stack39)
        %v24911 = vshll.u32 %v24905, 13 (stack44)
        %v24912 = vshrl.u32 %v24905, 19 (stack45)
        %v24913 = vor.u32 %v24912, %v24911 (stack46)
        %v24914 = vxor.u32 %v24913, %v24909 (stack47)
        %v24917 = vadd.s32 %v24914, %v24909 (stack39)
        %v24919 = vshll.u32 %v24914, 15 (stack44)
        %v24920 = vshrl.u32 %v24914, 17 (stack45)
        %v24921 = vor.u32 %v24920, %v24919 (stack46)
        %v24922 = vxor.u32 %v24921, %v24917 (stack47)
        %v24925 = vadd.s32 %v24922, %v24917 (stack39)
        %v24927 = vshll.u32 %v24922, 26 (stack44)
        %v24928 = vshrl.u32 %v24922, 6 (stack45)
        %v24929 = vor.u32 %v24928, %v24927 (stack46)
        %v24930 = vxor.u32 %v24929, %v24925 (stack47)
        %v24933 = vadd.s32 %v24930, %v24925 (stack39)
        %v24937 = vadd.s32 %v24933, %v10 (stack39)
        %v24939 = vshll.u32 %v24930, 6 (stack44)
        %v24940 = vshrl.u32 %v24930, 26 (stack45)
        %v24941 = vor.u32 %v24940, %v24939 (stack46)
        %v24942 = vxor.u32 %v24941, %v24933 (stack47)
        %v24945 = vadd.s32 %v24942, %v9 (stack39)
        %v24949 = vadd.s32 3, %v24945 (stack39)
        %v24953 = vadd.s32 %v24949, %v24937 (stack39)
        %v24955 = vshll.u32 %v24949, 17 (stack44)
        %v24956 = vshrl.u32 %v24949, 15 (stack45)
        %v24957 = vor.u32 %v24956, %v24955 (stack46)
        %v24958 = vxor.u32 %v24957, %v24953 (stack47)
        %v24961 = vadd.s32 %v24958, %v24953 (stack39)
        %v24963 = vshll.u32 %v24958, 29 (stack44)
        %v24964 = vshrl.u32 %v24958, 3 (stack45)
        %v24965 = vor.u32 %v24964, %v24963 (stack46)
        %v24966 = vxor.u32 %v24965, %v24961 (stack47)
        %v24969 = vadd.s32 %v24966, %v24961 (stack39)
        %v24971 = vshll.u32 %v24966, 16 (stack44)
        %v24972 = vshrl.u32 %v24966, 16 (stack45)
        %v24973 = vor.u32 %v24972, %v24971 (stack46)
        %v24974 = vxor.u32 %v24973, %v24969 (stack47)
        %v24977 = vadd.s32 %v24974, %v24969 (stack39)
        %v24981 = vadd.s32 %v24977, %v9 (stack39)
        %v24983 = vshll.u32 %v24974, 24 (stack44)
        %v24984 = vshrl.u32 %v24974, 8 (stack45)
        %v24985 = vor.u32 %v24984, %v24983 (stack46)
        %v24986 = vxor.u32 %v24985, %v24977 (stack47)
        %v24989 = vadd.s32 %v24986, %v8 (stack39)
        %v24993 = vadd.s32 4, %v24989 (stack39)
        %v24997 = vadd.s32 %v24993, %v24981 (stack39)
        %v24999 = vshll.u32 %v24993, 13 (stack44)
        %v25000 = vshrl.u32 %v24993, 19 (stack45)
        %v25001 = vor.u32 %v25000, %v24999 (stack46)
        %v25002 = vxor.u32 %v25001, %v24997 (stack47)
        %v25005 = vadd.s32 %v25002, %v24997 (stack39)
        %v25007 = vshll.u32 %v25002, 15 (stack44)
        %v25008 = vshrl.u32 %v25002, 17 (stack45)
        %v25009 = vor.u32 %v25008, %v25007 (stack46)
        %v25010 = vxor.u32 %v25009, %v25005 (stack47)
        %v25013 = vadd.s32 %v25010, %v25005 (stack39)
        %v25015 = vshll.u32 %v25010, 26 (stack44)
        %v25016 = vshrl.u32 %v25010, 6 (stack45)
        %v25017 = vor.u32 %v25016, %v25015 (stack46)
        %v25018 = vxor.u32 %v25017, %v25013 (stack47)
        %v25021 = vadd.s32 %v25018, %v25013 (stack39)
        %v25025 = vadd.s32 %v25021, %v8 (stack39)
        %v25027 = vshll.u32 %v25018, 6 (stack44)
        %v25028 = vshrl.u32 %v25018, 26 (stack45)
        %v25029 = vor.u32 %v25028, %v25027 (stack46)
        %v25030 = vxor.u32 %v25029, %v25021 (stack47)
        %v25033 = vadd.s32 %v25030, %v10 (stack39)
        %v25037 = vadd.s32 5, %v25033 (stack39)
        %v25039 = vxor.u32 %v25037, %v25025 (stack47)
        %v25040 = vand.u32.u8 255, %v25039 (stack48)
        %v25041 = vand.u32 65535, %v25040 (stack49)
        %v25042 = vshrl.u32 %v25041, 1 (stack50)
        %v25043 = vor.u32 16256, %v25042 (stack46)
        %v25044 = vand.u32.u16 65535, %v25043 (stack51)
        %v119876 = vadd.low.f32.bf16 -1.0, %v25044 (stack52)
        %v25053 = vmul.f32 2.0, %v119876 (stack53)
        %v25057 = vadd.f32 -0.99609375, %v25053 (stack52)
        %v25061 = vmax.f32 %v25057, -0.99609375 (stack54)
        %v25063 = vand.u32 2147483647, %v25061 (stack55)
        %vm25066 = vcmp.eq.f32.partialorder %v25063, 1.0 (stack56)
        %v25071 = vmul.f32 inf, %v25061 (stack53)
        %v25073 = vxor.u32 2147483648, %v25061 (stack57)
        %v25076 = vmul.f32 %v25073, %v25061 (stack53)
        %v25078 = vadd.f32 1.0, %v25076 (stack58)
        %v25079 = vlog2.pop %v25078 (stack59)
        %v25080 = vmul.f32 0.6931472, %v25079 (stack60)
        %v25081 = vmul.f32 -0.5, %v25076 (stack61)
        %v25082 = vadd.f32 1.0, %v25081 (stack62)
        %v25083 = vmul.f32 %v25082, %v25076 (stack63)
        %v25084 = vand.u32 2147483647, %v25076 (stack64)
        %vm25085 = vcmp.lt.f32.partialorder %v25084, 0.0004427343 (stack65)
        %v25086 = vsel /*vm=*/%vm25085, /*on_true_vy=*/%v25083, /*on_false_vx=*/%v25080 (stack66)
        %v25087 = vxor.u32 2147483648, %v25086 (stack57)
        %vm25090 = vcmp.lt.f32.partialorder %v25087, 5.0 (stack56)
        %v25095 = vsel /*vm=*/%vm25090, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v25099 = vsel /*vm=*/%vm25090, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v25103 = vsel /*vm=*/%vm25090, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v25107 = vsel /*vm=*/%vm25090, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v25111 = vsel /*vm=*/%vm25090, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v25115 = vsel /*vm=*/%vm25090, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v25119 = vsel /*vm=*/%vm25090, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v25123 = vsel /*vm=*/%vm25090, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v25127 = vsel /*vm=*/%vm25090, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v25131 = vadd.f32 -2.5, %v25087 (stack52)
        %v25133 = vrsqrt.pop %v25087 (stack67)
        %v25134 = vmul.f32 %v25133, %v25087 (stack68)
        %vm25135 = vcmp.eq.f32.partialorder %v25087, inf (stack69)
        %v25136 = vsel /*vm=*/%vm25135, /*on_true_vy=*/%v25087, /*on_false_vx=*/%v25134 (stack70)
        %vm25137 = vcmp.eq.f32.partialorder %v25087, 0.0 (stack71)
        %v25138 = vand.u32 2147483648, %v25087 (stack72)
        %v25139 = vsel /*vm=*/%vm25137, /*on_true_vy=*/%v25138, /*on_false_vx=*/%v25136 (stack73)
        %v25142 = vadd.f32 -3.0, %v25139 (stack52)
        %v25146 = vsel /*vm=*/%vm25090, /*on_true_vy=*/%v25131, /*on_false_vx=*/%v25142 (stack43)
        %v25150 = vmul.f32 %v25146, %v25127 (stack53)
        %v25154 = vadd.f32 %v25150, %v25123 (stack52)
        %v25158 = vmul.f32 %v25154, %v25146 (stack53)
        %v25162 = vadd.f32 %v25158, %v25119 (stack52)
        %v25166 = vmul.f32 %v25162, %v25146 (stack53)
        %v25170 = vadd.f32 %v25166, %v25115 (stack52)
        %v25174 = vmul.f32 %v25170, %v25146 (stack53)
        %v25178 = vadd.f32 %v25174, %v25111 (stack52)
        %v25182 = vmul.f32 %v25178, %v25146 (stack53)
        %v25186 = vadd.f32 %v25182, %v25107 (stack52)
        %v25190 = vmul.f32 %v25186, %v25146 (stack53)
        %v25194 = vadd.f32 %v25190, %v25103 (stack52)
        %v25198 = vmul.f32 %v25194, %v25146 (stack53)
        %v25202 = vadd.f32 %v25198, %v25099 (stack52)
        %v25206 = vmul.f32 %v25202, %v25146 (stack53)
        %v25210 = vadd.f32 %v25206, %v25095 (stack52)
        %v25214 = vmul.f32 %v25210, %v25061 (stack53)
        %v25218 = vsel /*vm=*/%vm25066, /*on_true_vy=*/%v25071, /*on_false_vx=*/%v25214 (stack43)
        %v25222 = vmul.f32 1.4140625, %v25218 (stack53)
        %v25225 = vpack.c.bf16 0.0, %v25222 (stack74)
        %119877 = vst [vmem:[%s280 + $0x218] sm:$0xf] /*vst_source=*/%v25225 (stack75)
        %v25229 = vadd.s32 %v22921, %v2842 (stack39)
        %v25239 = vadd.s32 %v25229, %v415 (stack39)
        %vm25243 = vcmp.lt.u32.totalorder %v25239, %v25229 (stack42)
        %vm25248 = vcmp.lt.u32.totalorder %v25229, %v2842 (stack42)
        %v25253 = vadd.s32 %v22904, %v2829 (stack39)
        %v25257 = vadd.s32 1, %v25253 (stack39)
        %v25261 = vsel /*vm=*/%vm25248, /*on_true_vy=*/%v25257, /*on_false_vx=*/%v25253 (stack43)
        %v25265 = vadd.s32 1, %v25261 (stack39)
        %v25269 = vsel /*vm=*/%vm25243, /*on_true_vy=*/%v25265, /*on_false_vx=*/%v25261 (stack43)
        %v25274 = vadd.s32 %v25269, %v10 (stack39)
        %v25278 = vadd.s32 %v25239, %v9 (stack39)
        %v25282 = vadd.s32 %v25278, %v25274 (stack39)
        %v25284 = vshll.u32 %v25278, 13 (stack44)
        %v25285 = vshrl.u32 %v25278, 19 (stack45)
        %v25286 = vor.u32 %v25285, %v25284 (stack46)
        %v25287 = vxor.u32 %v25286, %v25282 (stack47)
        %v25290 = vadd.s32 %v25287, %v25282 (stack39)
        %v25292 = vshll.u32 %v25287, 15 (stack44)
        %v25293 = vshrl.u32 %v25287, 17 (stack45)
        %v25294 = vor.u32 %v25293, %v25292 (stack46)
        %v25295 = vxor.u32 %v25294, %v25290 (stack47)
        %v25298 = vadd.s32 %v25295, %v25290 (stack39)
        %v25300 = vshll.u32 %v25295, 26 (stack44)
        %v25301 = vshrl.u32 %v25295, 6 (stack45)
        %v25302 = vor.u32 %v25301, %v25300 (stack46)
        %v25303 = vxor.u32 %v25302, %v25298 (stack47)
        %v25306 = vadd.s32 %v25303, %v25298 (stack39)
        %v25310 = vadd.s32 %v25306, %v9 (stack39)
        %v25312 = vshll.u32 %v25303, 6 (stack44)
        %v25313 = vshrl.u32 %v25303, 26 (stack45)
        %v25314 = vor.u32 %v25313, %v25312 (stack46)
        %v25315 = vxor.u32 %v25314, %v25306 (stack47)
        %v25318 = vadd.s32 %v25315, %v8 (stack39)
        %v25322 = vadd.s32 1, %v25318 (stack39)
        %v25326 = vadd.s32 %v25322, %v25310 (stack39)
        %v25328 = vshll.u32 %v25322, 17 (stack44)
        %v25329 = vshrl.u32 %v25322, 15 (stack45)
        %v25330 = vor.u32 %v25329, %v25328 (stack46)
        %v25331 = vxor.u32 %v25330, %v25326 (stack47)
        %v25334 = vadd.s32 %v25331, %v25326 (stack39)
        %v25336 = vshll.u32 %v25331, 29 (stack44)
        %v25337 = vshrl.u32 %v25331, 3 (stack45)
        %v25338 = vor.u32 %v25337, %v25336 (stack46)
        %v25339 = vxor.u32 %v25338, %v25334 (stack47)
        %v25342 = vadd.s32 %v25339, %v25334 (stack39)
        %v25344 = vshll.u32 %v25339, 16 (stack44)
        %v25345 = vshrl.u32 %v25339, 16 (stack45)
        %v25346 = vor.u32 %v25345, %v25344 (stack46)
        %v25347 = vxor.u32 %v25346, %v25342 (stack47)
        %v25350 = vadd.s32 %v25347, %v25342 (stack39)
        %v25354 = vadd.s32 %v25350, %v8 (stack39)
        %v25356 = vshll.u32 %v25347, 24 (stack44)
        %v25357 = vshrl.u32 %v25347, 8 (stack45)
        %v25358 = vor.u32 %v25357, %v25356 (stack46)
        %v25359 = vxor.u32 %v25358, %v25350 (stack47)
        %v25362 = vadd.s32 %v25359, %v10 (stack39)
        %v25366 = vadd.s32 2, %v25362 (stack39)
        %v25370 = vadd.s32 %v25366, %v25354 (stack39)
        %v25372 = vshll.u32 %v25366, 13 (stack44)
        %v25373 = vshrl.u32 %v25366, 19 (stack45)
        %v25374 = vor.u32 %v25373, %v25372 (stack46)
        %v25375 = vxor.u32 %v25374, %v25370 (stack47)
        %v25378 = vadd.s32 %v25375, %v25370 (stack39)
        %v25380 = vshll.u32 %v25375, 15 (stack44)
        %v25381 = vshrl.u32 %v25375, 17 (stack45)
        %v25382 = vor.u32 %v25381, %v25380 (stack46)
        %v25383 = vxor.u32 %v25382, %v25378 (stack47)
        %v25386 = vadd.s32 %v25383, %v25378 (stack39)
        %v25388 = vshll.u32 %v25383, 26 (stack44)
        %v25389 = vshrl.u32 %v25383, 6 (stack45)
        %v25390 = vor.u32 %v25389, %v25388 (stack46)
        %v25391 = vxor.u32 %v25390, %v25386 (stack47)
        %v25394 = vadd.s32 %v25391, %v25386 (stack39)
        %v25398 = vadd.s32 %v25394, %v10 (stack39)
        %v25400 = vshll.u32 %v25391, 6 (stack44)
        %v25401 = vshrl.u32 %v25391, 26 (stack45)
        %v25402 = vor.u32 %v25401, %v25400 (stack46)
        %v25403 = vxor.u32 %v25402, %v25394 (stack47)
        %v25406 = vadd.s32 %v25403, %v9 (stack39)
        %v25410 = vadd.s32 3, %v25406 (stack39)
        %v25414 = vadd.s32 %v25410, %v25398 (stack39)
        %v25416 = vshll.u32 %v25410, 17 (stack44)
        %v25417 = vshrl.u32 %v25410, 15 (stack45)
        %v25418 = vor.u32 %v25417, %v25416 (stack46)
        %v25419 = vxor.u32 %v25418, %v25414 (stack47)
        %v25422 = vadd.s32 %v25419, %v25414 (stack39)
        %v25424 = vshll.u32 %v25419, 29 (stack44)
        %v25425 = vshrl.u32 %v25419, 3 (stack45)
        %v25426 = vor.u32 %v25425, %v25424 (stack46)
        %v25427 = vxor.u32 %v25426, %v25422 (stack47)
        %v25430 = vadd.s32 %v25427, %v25422 (stack39)
        %v25432 = vshll.u32 %v25427, 16 (stack44)
        %v25433 = vshrl.u32 %v25427, 16 (stack45)
        %v25434 = vor.u32 %v25433, %v25432 (stack46)
        %v25435 = vxor.u32 %v25434, %v25430 (stack47)
        %v25438 = vadd.s32 %v25435, %v25430 (stack39)
        %v25442 = vadd.s32 %v25438, %v9 (stack39)
        %v25444 = vshll.u32 %v25435, 24 (stack44)
        %v25445 = vshrl.u32 %v25435, 8 (stack45)
        %v25446 = vor.u32 %v25445, %v25444 (stack46)
        %v25447 = vxor.u32 %v25446, %v25438 (stack47)
        %v25450 = vadd.s32 %v25447, %v8 (stack39)
        %v25454 = vadd.s32 4, %v25450 (stack39)
        %v25458 = vadd.s32 %v25454, %v25442 (stack39)
        %v25460 = vshll.u32 %v25454, 13 (stack44)
        %v25461 = vshrl.u32 %v25454, 19 (stack45)
        %v25462 = vor.u32 %v25461, %v25460 (stack46)
        %v25463 = vxor.u32 %v25462, %v25458 (stack47)
        %v25466 = vadd.s32 %v25463, %v25458 (stack39)
        %v25468 = vshll.u32 %v25463, 15 (stack44)
        %v25469 = vshrl.u32 %v25463, 17 (stack45)
        %v25470 = vor.u32 %v25469, %v25468 (stack46)
        %v25471 = vxor.u32 %v25470, %v25466 (stack47)
        %v25474 = vadd.s32 %v25471, %v25466 (stack39)
        %v25476 = vshll.u32 %v25471, 26 (stack44)
        %v25477 = vshrl.u32 %v25471, 6 (stack45)
        %v25478 = vor.u32 %v25477, %v25476 (stack46)
        %v25479 = vxor.u32 %v25478, %v25474 (stack47)
        %v25482 = vadd.s32 %v25479, %v25474 (stack39)
        %v25486 = vadd.s32 %v25482, %v8 (stack39)
        %v25488 = vshll.u32 %v25479, 6 (stack44)
        %v25489 = vshrl.u32 %v25479, 26 (stack45)
        %v25490 = vor.u32 %v25489, %v25488 (stack46)
        %v25491 = vxor.u32 %v25490, %v25482 (stack47)
        %v25494 = vadd.s32 %v25491, %v10 (stack39)
        %v25498 = vadd.s32 5, %v25494 (stack39)
        %v25500 = vxor.u32 %v25498, %v25486 (stack47)
        %v25501 = vand.u32.u8 255, %v25500 (stack48)
        %v25502 = vand.u32 65535, %v25501 (stack49)
        %v25503 = vshrl.u32 %v25502, 1 (stack50)
        %v25504 = vor.u32 16256, %v25503 (stack46)
        %v25505 = vand.u32.u16 65535, %v25504 (stack51)
        %v119878 = vadd.low.f32.bf16 -1.0, %v25505 (stack52)
        %v25514 = vmul.f32 2.0, %v119878 (stack53)
        %v25518 = vadd.f32 -0.99609375, %v25514 (stack52)
        %v25522 = vmax.f32 %v25518, -0.99609375 (stack54)
        %v25524 = vand.u32 2147483647, %v25522 (stack55)
        %vm25527 = vcmp.eq.f32.partialorder %v25524, 1.0 (stack56)
        %v25532 = vmul.f32 inf, %v25522 (stack53)
        %v25534 = vxor.u32 2147483648, %v25522 (stack57)
        %v25537 = vmul.f32 %v25534, %v25522 (stack53)
        %v25539 = vadd.f32 1.0, %v25537 (stack58)
        %v25540 = vlog2.pop %v25539 (stack59)
        %v25541 = vmul.f32 0.6931472, %v25540 (stack60)
        %v25542 = vmul.f32 -0.5, %v25537 (stack61)
        %v25543 = vadd.f32 1.0, %v25542 (stack62)
        %v25544 = vmul.f32 %v25543, %v25537 (stack63)
        %v25545 = vand.u32 2147483647, %v25537 (stack64)
        %vm25546 = vcmp.lt.f32.partialorder %v25545, 0.0004427343 (stack65)
        %v25547 = vsel /*vm=*/%vm25546, /*on_true_vy=*/%v25544, /*on_false_vx=*/%v25541 (stack66)
        %v25548 = vxor.u32 2147483648, %v25547 (stack57)
        %vm25551 = vcmp.lt.f32.partialorder %v25548, 5.0 (stack56)
        %v25556 = vsel /*vm=*/%vm25551, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v25560 = vsel /*vm=*/%vm25551, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v25564 = vsel /*vm=*/%vm25551, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v25568 = vsel /*vm=*/%vm25551, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v25572 = vsel /*vm=*/%vm25551, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v25576 = vsel /*vm=*/%vm25551, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v25580 = vsel /*vm=*/%vm25551, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v25584 = vsel /*vm=*/%vm25551, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v25588 = vsel /*vm=*/%vm25551, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v25592 = vadd.f32 -2.5, %v25548 (stack52)
        %v25594 = vrsqrt.pop %v25548 (stack67)
        %v25595 = vmul.f32 %v25594, %v25548 (stack68)
        %vm25596 = vcmp.eq.f32.partialorder %v25548, inf (stack69)
        %v25597 = vsel /*vm=*/%vm25596, /*on_true_vy=*/%v25548, /*on_false_vx=*/%v25595 (stack70)
        %vm25598 = vcmp.eq.f32.partialorder %v25548, 0.0 (stack71)
        %v25599 = vand.u32 2147483648, %v25548 (stack72)
        %v25600 = vsel /*vm=*/%vm25598, /*on_true_vy=*/%v25599, /*on_false_vx=*/%v25597 (stack73)
        %v25603 = vadd.f32 -3.0, %v25600 (stack52)
        %v25607 = vsel /*vm=*/%vm25551, /*on_true_vy=*/%v25592, /*on_false_vx=*/%v25603 (stack43)
        %v25611 = vmul.f32 %v25607, %v25588 (stack53)
        %v25615 = vadd.f32 %v25611, %v25584 (stack52)
        %v25619 = vmul.f32 %v25615, %v25607 (stack53)
        %v25623 = vadd.f32 %v25619, %v25580 (stack52)
        %v25627 = vmul.f32 %v25623, %v25607 (stack53)
        %v25631 = vadd.f32 %v25627, %v25576 (stack52)
        %v25635 = vmul.f32 %v25631, %v25607 (stack53)
        %v25639 = vadd.f32 %v25635, %v25572 (stack52)
        %v25643 = vmul.f32 %v25639, %v25607 (stack53)
        %v25647 = vadd.f32 %v25643, %v25568 (stack52)
        %v25651 = vmul.f32 %v25647, %v25607 (stack53)
        %v25655 = vadd.f32 %v25651, %v25564 (stack52)
        %v25659 = vmul.f32 %v25655, %v25607 (stack53)
        %v25663 = vadd.f32 %v25659, %v25560 (stack52)
        %v25667 = vmul.f32 %v25663, %v25607 (stack53)
        %v25671 = vadd.f32 %v25667, %v25556 (stack52)
        %v25675 = vmul.f32 %v25671, %v25522 (stack53)
        %v25679 = vsel /*vm=*/%vm25527, /*on_true_vy=*/%v25532, /*on_false_vx=*/%v25675 (stack43)
        %v25683 = vmul.f32 1.4140625, %v25679 (stack53)
        %v25686 = vpack.c.bf16 0.0, %v25683 (stack74)
        %119879 = vst [vmem:[%s280 + $0x298] sm:$0xf] /*vst_source=*/%v25686 (stack75)
        %v25690 = vadd.s32 %v22921, %v3329 (stack39)
        %v25700 = vadd.s32 %v25690, %v415 (stack39)
        %vm25704 = vcmp.lt.u32.totalorder %v25700, %v25690 (stack42)
        %vm25709 = vcmp.lt.u32.totalorder %v25690, %v3329 (stack42)
        %v25714 = vadd.s32 %v22904, %v3316 (stack39)
        %v25718 = vadd.s32 1, %v25714 (stack39)
        %v25722 = vsel /*vm=*/%vm25709, /*on_true_vy=*/%v25718, /*on_false_vx=*/%v25714 (stack43)
        %v25726 = vadd.s32 1, %v25722 (stack39)
        %v25730 = vsel /*vm=*/%vm25704, /*on_true_vy=*/%v25726, /*on_false_vx=*/%v25722 (stack43)
        %v25735 = vadd.s32 %v25730, %v10 (stack39)
        %v25739 = vadd.s32 %v25700, %v9 (stack39)
        %v25743 = vadd.s32 %v25739, %v25735 (stack39)
        %v25745 = vshll.u32 %v25739, 13 (stack44)
        %v25746 = vshrl.u32 %v25739, 19 (stack45)
        %v25747 = vor.u32 %v25746, %v25745 (stack46)
        %v25748 = vxor.u32 %v25747, %v25743 (stack47)
        %v25751 = vadd.s32 %v25748, %v25743 (stack39)
        %v25753 = vshll.u32 %v25748, 15 (stack44)
        %v25754 = vshrl.u32 %v25748, 17 (stack45)
        %v25755 = vor.u32 %v25754, %v25753 (stack46)
        %v25756 = vxor.u32 %v25755, %v25751 (stack47)
        %v25759 = vadd.s32 %v25756, %v25751 (stack39)
        %v25761 = vshll.u32 %v25756, 26 (stack44)
        %v25762 = vshrl.u32 %v25756, 6 (stack45)
        %v25763 = vor.u32 %v25762, %v25761 (stack46)
        %v25764 = vxor.u32 %v25763, %v25759 (stack47)
        %v25767 = vadd.s32 %v25764, %v25759 (stack39)
        %v25771 = vadd.s32 %v25767, %v9 (stack39)
        %v25773 = vshll.u32 %v25764, 6 (stack44)
        %v25774 = vshrl.u32 %v25764, 26 (stack45)
        %v25775 = vor.u32 %v25774, %v25773 (stack46)
        %v25776 = vxor.u32 %v25775, %v25767 (stack47)
        %v25779 = vadd.s32 %v25776, %v8 (stack39)
        %v25783 = vadd.s32 1, %v25779 (stack39)
        %v25787 = vadd.s32 %v25783, %v25771 (stack39)
        %v25789 = vshll.u32 %v25783, 17 (stack44)
        %v25790 = vshrl.u32 %v25783, 15 (stack45)
        %v25791 = vor.u32 %v25790, %v25789 (stack46)
        %v25792 = vxor.u32 %v25791, %v25787 (stack47)
        %v25795 = vadd.s32 %v25792, %v25787 (stack39)
        %v25797 = vshll.u32 %v25792, 29 (stack44)
        %v25798 = vshrl.u32 %v25792, 3 (stack45)
        %v25799 = vor.u32 %v25798, %v25797 (stack46)
        %v25800 = vxor.u32 %v25799, %v25795 (stack47)
        %v25803 = vadd.s32 %v25800, %v25795 (stack39)
        %v25805 = vshll.u32 %v25800, 16 (stack44)
        %v25806 = vshrl.u32 %v25800, 16 (stack45)
        %v25807 = vor.u32 %v25806, %v25805 (stack46)
        %v25808 = vxor.u32 %v25807, %v25803 (stack47)
        %v25811 = vadd.s32 %v25808, %v25803 (stack39)
        %v25815 = vadd.s32 %v25811, %v8 (stack39)
        %v25817 = vshll.u32 %v25808, 24 (stack44)
        %v25818 = vshrl.u32 %v25808, 8 (stack45)
        %v25819 = vor.u32 %v25818, %v25817 (stack46)
        %v25820 = vxor.u32 %v25819, %v25811 (stack47)
        %v25823 = vadd.s32 %v25820, %v10 (stack39)
        %v25827 = vadd.s32 2, %v25823 (stack39)
        %v25831 = vadd.s32 %v25827, %v25815 (stack39)
        %v25833 = vshll.u32 %v25827, 13 (stack44)
        %v25834 = vshrl.u32 %v25827, 19 (stack45)
        %v25835 = vor.u32 %v25834, %v25833 (stack46)
        %v25836 = vxor.u32 %v25835, %v25831 (stack47)
        %v25839 = vadd.s32 %v25836, %v25831 (stack39)
        %v25841 = vshll.u32 %v25836, 15 (stack44)
        %v25842 = vshrl.u32 %v25836, 17 (stack45)
        %v25843 = vor.u32 %v25842, %v25841 (stack46)
        %v25844 = vxor.u32 %v25843, %v25839 (stack47)
        %v25847 = vadd.s32 %v25844, %v25839 (stack39)
        %v25849 = vshll.u32 %v25844, 26 (stack44)
        %v25850 = vshrl.u32 %v25844, 6 (stack45)
        %v25851 = vor.u32 %v25850, %v25849 (stack46)
        %v25852 = vxor.u32 %v25851, %v25847 (stack47)
        %v25855 = vadd.s32 %v25852, %v25847 (stack39)
        %v25859 = vadd.s32 %v25855, %v10 (stack39)
        %v25861 = vshll.u32 %v25852, 6 (stack44)
        %v25862 = vshrl.u32 %v25852, 26 (stack45)
        %v25863 = vor.u32 %v25862, %v25861 (stack46)
        %v25864 = vxor.u32 %v25863, %v25855 (stack47)
        %v25867 = vadd.s32 %v25864, %v9 (stack39)
        %v25871 = vadd.s32 3, %v25867 (stack39)
        %v25875 = vadd.s32 %v25871, %v25859 (stack39)
        %v25877 = vshll.u32 %v25871, 17 (stack44)
        %v25878 = vshrl.u32 %v25871, 15 (stack45)
        %v25879 = vor.u32 %v25878, %v25877 (stack46)
        %v25880 = vxor.u32 %v25879, %v25875 (stack47)
        %v25883 = vadd.s32 %v25880, %v25875 (stack39)
        %v25885 = vshll.u32 %v25880, 29 (stack44)
        %v25886 = vshrl.u32 %v25880, 3 (stack45)
        %v25887 = vor.u32 %v25886, %v25885 (stack46)
        %v25888 = vxor.u32 %v25887, %v25883 (stack47)
        %v25891 = vadd.s32 %v25888, %v25883 (stack39)
        %v25893 = vshll.u32 %v25888, 16 (stack44)
        %v25894 = vshrl.u32 %v25888, 16 (stack45)
        %v25895 = vor.u32 %v25894, %v25893 (stack46)
        %v25896 = vxor.u32 %v25895, %v25891 (stack47)
        %v25899 = vadd.s32 %v25896, %v25891 (stack39)
        %v25903 = vadd.s32 %v25899, %v9 (stack39)
        %v25905 = vshll.u32 %v25896, 24 (stack44)
        %v25906 = vshrl.u32 %v25896, 8 (stack45)
        %v25907 = vor.u32 %v25906, %v25905 (stack46)
        %v25908 = vxor.u32 %v25907, %v25899 (stack47)
        %v25911 = vadd.s32 %v25908, %v8 (stack39)
        %v25915 = vadd.s32 4, %v25911 (stack39)
        %v25919 = vadd.s32 %v25915, %v25903 (stack39)
        %v25921 = vshll.u32 %v25915, 13 (stack44)
        %v25922 = vshrl.u32 %v25915, 19 (stack45)
        %v25923 = vor.u32 %v25922, %v25921 (stack46)
        %v25924 = vxor.u32 %v25923, %v25919 (stack47)
        %v25927 = vadd.s32 %v25924, %v25919 (stack39)
        %v25929 = vshll.u32 %v25924, 15 (stack44)
        %v25930 = vshrl.u32 %v25924, 17 (stack45)
        %v25931 = vor.u32 %v25930, %v25929 (stack46)
        %v25932 = vxor.u32 %v25931, %v25927 (stack47)
        %v25935 = vadd.s32 %v25932, %v25927 (stack39)
        %v25937 = vshll.u32 %v25932, 26 (stack44)
        %v25938 = vshrl.u32 %v25932, 6 (stack45)
        %v25939 = vor.u32 %v25938, %v25937 (stack46)
        %v25940 = vxor.u32 %v25939, %v25935 (stack47)
        %v25943 = vadd.s32 %v25940, %v25935 (stack39)
        %v25947 = vadd.s32 %v25943, %v8 (stack39)
        %v25949 = vshll.u32 %v25940, 6 (stack44)
        %v25950 = vshrl.u32 %v25940, 26 (stack45)
        %v25951 = vor.u32 %v25950, %v25949 (stack46)
        %v25952 = vxor.u32 %v25951, %v25943 (stack47)
        %v25955 = vadd.s32 %v25952, %v10 (stack39)
        %v25959 = vadd.s32 5, %v25955 (stack39)
        %v25961 = vxor.u32 %v25959, %v25947 (stack47)
        %v25962 = vand.u32.u8 255, %v25961 (stack48)
        %v25963 = vand.u32 65535, %v25962 (stack49)
        %v25964 = vshrl.u32 %v25963, 1 (stack50)
        %v25965 = vor.u32 16256, %v25964 (stack46)
        %v25966 = vand.u32.u16 65535, %v25965 (stack51)
        %v119880 = vadd.low.f32.bf16 -1.0, %v25966 (stack52)
        %v25975 = vmul.f32 2.0, %v119880 (stack53)
        %v25979 = vadd.f32 -0.99609375, %v25975 (stack52)
        %v25983 = vmax.f32 %v25979, -0.99609375 (stack54)
        %v25985 = vand.u32 2147483647, %v25983 (stack55)
        %vm25988 = vcmp.eq.f32.partialorder %v25985, 1.0 (stack56)
        %v25993 = vmul.f32 inf, %v25983 (stack53)
        %v25995 = vxor.u32 2147483648, %v25983 (stack57)
        %v25998 = vmul.f32 %v25995, %v25983 (stack53)
        %v26000 = vadd.f32 1.0, %v25998 (stack58)
        %v26001 = vlog2.pop %v26000 (stack59)
        %v26002 = vmul.f32 0.6931472, %v26001 (stack60)
        %v26003 = vmul.f32 -0.5, %v25998 (stack61)
        %v26004 = vadd.f32 1.0, %v26003 (stack62)
        %v26005 = vmul.f32 %v26004, %v25998 (stack63)
        %v26006 = vand.u32 2147483647, %v25998 (stack64)
        %vm26007 = vcmp.lt.f32.partialorder %v26006, 0.0004427343 (stack65)
        %v26008 = vsel /*vm=*/%vm26007, /*on_true_vy=*/%v26005, /*on_false_vx=*/%v26002 (stack66)
        %v26009 = vxor.u32 2147483648, %v26008 (stack57)
        %vm26012 = vcmp.lt.f32.partialorder %v26009, 5.0 (stack56)
        %v26017 = vsel /*vm=*/%vm26012, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v26021 = vsel /*vm=*/%vm26012, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v26025 = vsel /*vm=*/%vm26012, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v26029 = vsel /*vm=*/%vm26012, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v26033 = vsel /*vm=*/%vm26012, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v26037 = vsel /*vm=*/%vm26012, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v26041 = vsel /*vm=*/%vm26012, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v26045 = vsel /*vm=*/%vm26012, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v26049 = vsel /*vm=*/%vm26012, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v26053 = vadd.f32 -2.5, %v26009 (stack52)
        %v26055 = vrsqrt.pop %v26009 (stack67)
        %v26056 = vmul.f32 %v26055, %v26009 (stack68)
        %vm26057 = vcmp.eq.f32.partialorder %v26009, inf (stack69)
        %v26058 = vsel /*vm=*/%vm26057, /*on_true_vy=*/%v26009, /*on_false_vx=*/%v26056 (stack70)
        %vm26059 = vcmp.eq.f32.partialorder %v26009, 0.0 (stack71)
        %v26060 = vand.u32 2147483648, %v26009 (stack72)
        %v26061 = vsel /*vm=*/%vm26059, /*on_true_vy=*/%v26060, /*on_false_vx=*/%v26058 (stack73)
        %v26064 = vadd.f32 -3.0, %v26061 (stack52)
        %v26068 = vsel /*vm=*/%vm26012, /*on_true_vy=*/%v26053, /*on_false_vx=*/%v26064 (stack43)
        %v26072 = vmul.f32 %v26068, %v26049 (stack53)
        %v26076 = vadd.f32 %v26072, %v26045 (stack52)
        %v26080 = vmul.f32 %v26076, %v26068 (stack53)
        %v26084 = vadd.f32 %v26080, %v26041 (stack52)
        %v26088 = vmul.f32 %v26084, %v26068 (stack53)
        %v26092 = vadd.f32 %v26088, %v26037 (stack52)
        %v26096 = vmul.f32 %v26092, %v26068 (stack53)
        %v26100 = vadd.f32 %v26096, %v26033 (stack52)
        %v26104 = vmul.f32 %v26100, %v26068 (stack53)
        %v26108 = vadd.f32 %v26104, %v26029 (stack52)
        %v26112 = vmul.f32 %v26108, %v26068 (stack53)
        %v26116 = vadd.f32 %v26112, %v26025 (stack52)
        %v26120 = vmul.f32 %v26116, %v26068 (stack53)
        %v26124 = vadd.f32 %v26120, %v26021 (stack52)
        %v26128 = vmul.f32 %v26124, %v26068 (stack53)
        %v26132 = vadd.f32 %v26128, %v26017 (stack52)
        %v26136 = vmul.f32 %v26132, %v25983 (stack53)
        %v26140 = vsel /*vm=*/%vm25988, /*on_true_vy=*/%v25993, /*on_false_vx=*/%v26136 (stack43)
        %v26144 = vmul.f32 1.4140625, %v26140 (stack53)
        %v26147 = vpack.c.bf16 0.0, %v26144 (stack74)
        %119881 = vst [vmem:[%s280 + $0x318] sm:$0xf] /*vst_source=*/%v26147 (stack75)
        %v26151 = vadd.s32 %v22921, %v3816 (stack39)
        %v26161 = vadd.s32 %v26151, %v415 (stack39)
        %vm26165 = vcmp.lt.u32.totalorder %v26161, %v26151 (stack42)
        %vm26170 = vcmp.lt.u32.totalorder %v26151, %v3816 (stack42)
        %v26175 = vadd.s32 %v22904, %v3803 (stack39)
        %v26179 = vadd.s32 1, %v26175 (stack39)
        %v26183 = vsel /*vm=*/%vm26170, /*on_true_vy=*/%v26179, /*on_false_vx=*/%v26175 (stack43)
        %v26187 = vadd.s32 1, %v26183 (stack39)
        %v26191 = vsel /*vm=*/%vm26165, /*on_true_vy=*/%v26187, /*on_false_vx=*/%v26183 (stack43)
        %v26196 = vadd.s32 %v26191, %v10 (stack39)
        %v26200 = vadd.s32 %v26161, %v9 (stack39)
        %v26204 = vadd.s32 %v26200, %v26196 (stack39)
        %v26206 = vshll.u32 %v26200, 13 (stack44)
        %v26207 = vshrl.u32 %v26200, 19 (stack45)
        %v26208 = vor.u32 %v26207, %v26206 (stack46)
        %v26209 = vxor.u32 %v26208, %v26204 (stack47)
        %v26212 = vadd.s32 %v26209, %v26204 (stack39)
        %v26214 = vshll.u32 %v26209, 15 (stack44)
        %v26215 = vshrl.u32 %v26209, 17 (stack45)
        %v26216 = vor.u32 %v26215, %v26214 (stack46)
        %v26217 = vxor.u32 %v26216, %v26212 (stack47)
        %v26220 = vadd.s32 %v26217, %v26212 (stack39)
        %v26222 = vshll.u32 %v26217, 26 (stack44)
        %v26223 = vshrl.u32 %v26217, 6 (stack45)
        %v26224 = vor.u32 %v26223, %v26222 (stack46)
        %v26225 = vxor.u32 %v26224, %v26220 (stack47)
        %v26228 = vadd.s32 %v26225, %v26220 (stack39)
        %v26232 = vadd.s32 %v26228, %v9 (stack39)
        %v26234 = vshll.u32 %v26225, 6 (stack44)
        %v26235 = vshrl.u32 %v26225, 26 (stack45)
        %v26236 = vor.u32 %v26235, %v26234 (stack46)
        %v26237 = vxor.u32 %v26236, %v26228 (stack47)
        %v26240 = vadd.s32 %v26237, %v8 (stack39)
        %v26244 = vadd.s32 1, %v26240 (stack39)
        %v26248 = vadd.s32 %v26244, %v26232 (stack39)
        %v26250 = vshll.u32 %v26244, 17 (stack44)
        %v26251 = vshrl.u32 %v26244, 15 (stack45)
        %v26252 = vor.u32 %v26251, %v26250 (stack46)
        %v26253 = vxor.u32 %v26252, %v26248 (stack47)
        %v26256 = vadd.s32 %v26253, %v26248 (stack39)
        %v26258 = vshll.u32 %v26253, 29 (stack44)
        %v26259 = vshrl.u32 %v26253, 3 (stack45)
        %v26260 = vor.u32 %v26259, %v26258 (stack46)
        %v26261 = vxor.u32 %v26260, %v26256 (stack47)
        %v26264 = vadd.s32 %v26261, %v26256 (stack39)
        %v26266 = vshll.u32 %v26261, 16 (stack44)
        %v26267 = vshrl.u32 %v26261, 16 (stack45)
        %v26268 = vor.u32 %v26267, %v26266 (stack46)
        %v26269 = vxor.u32 %v26268, %v26264 (stack47)
        %v26272 = vadd.s32 %v26269, %v26264 (stack39)
        %v26276 = vadd.s32 %v26272, %v8 (stack39)
        %v26278 = vshll.u32 %v26269, 24 (stack44)
        %v26279 = vshrl.u32 %v26269, 8 (stack45)
        %v26280 = vor.u32 %v26279, %v26278 (stack46)
        %v26281 = vxor.u32 %v26280, %v26272 (stack47)
        %v26284 = vadd.s32 %v26281, %v10 (stack39)
        %v26288 = vadd.s32 2, %v26284 (stack39)
        %v26292 = vadd.s32 %v26288, %v26276 (stack39)
        %v26294 = vshll.u32 %v26288, 13 (stack44)
        %v26295 = vshrl.u32 %v26288, 19 (stack45)
        %v26296 = vor.u32 %v26295, %v26294 (stack46)
        %v26297 = vxor.u32 %v26296, %v26292 (stack47)
        %v26300 = vadd.s32 %v26297, %v26292 (stack39)
        %v26302 = vshll.u32 %v26297, 15 (stack44)
        %v26303 = vshrl.u32 %v26297, 17 (stack45)
        %v26304 = vor.u32 %v26303, %v26302 (stack46)
        %v26305 = vxor.u32 %v26304, %v26300 (stack47)
        %v26308 = vadd.s32 %v26305, %v26300 (stack39)
        %v26310 = vshll.u32 %v26305, 26 (stack44)
        %v26311 = vshrl.u32 %v26305, 6 (stack45)
        %v26312 = vor.u32 %v26311, %v26310 (stack46)
        %v26313 = vxor.u32 %v26312, %v26308 (stack47)
        %v26316 = vadd.s32 %v26313, %v26308 (stack39)
        %v26320 = vadd.s32 %v26316, %v10 (stack39)
        %v26322 = vshll.u32 %v26313, 6 (stack44)
        %v26323 = vshrl.u32 %v26313, 26 (stack45)
        %v26324 = vor.u32 %v26323, %v26322 (stack46)
        %v26325 = vxor.u32 %v26324, %v26316 (stack47)
        %v26328 = vadd.s32 %v26325, %v9 (stack39)
        %v26332 = vadd.s32 3, %v26328 (stack39)
        %v26336 = vadd.s32 %v26332, %v26320 (stack39)
        %v26338 = vshll.u32 %v26332, 17 (stack44)
        %v26339 = vshrl.u32 %v26332, 15 (stack45)
        %v26340 = vor.u32 %v26339, %v26338 (stack46)
        %v26341 = vxor.u32 %v26340, %v26336 (stack47)
        %v26344 = vadd.s32 %v26341, %v26336 (stack39)
        %v26346 = vshll.u32 %v26341, 29 (stack44)
        %v26347 = vshrl.u32 %v26341, 3 (stack45)
        %v26348 = vor.u32 %v26347, %v26346 (stack46)
        %v26349 = vxor.u32 %v26348, %v26344 (stack47)
        %v26352 = vadd.s32 %v26349, %v26344 (stack39)
        %v26354 = vshll.u32 %v26349, 16 (stack44)
        %v26355 = vshrl.u32 %v26349, 16 (stack45)
        %v26356 = vor.u32 %v26355, %v26354 (stack46)
        %v26357 = vxor.u32 %v26356, %v26352 (stack47)
        %v26360 = vadd.s32 %v26357, %v26352 (stack39)
        %v26364 = vadd.s32 %v26360, %v9 (stack39)
        %v26366 = vshll.u32 %v26357, 24 (stack44)
        %v26367 = vshrl.u32 %v26357, 8 (stack45)
        %v26368 = vor.u32 %v26367, %v26366 (stack46)
        %v26369 = vxor.u32 %v26368, %v26360 (stack47)
        %v26372 = vadd.s32 %v26369, %v8 (stack39)
        %v26376 = vadd.s32 4, %v26372 (stack39)
        %v26380 = vadd.s32 %v26376, %v26364 (stack39)
        %v26382 = vshll.u32 %v26376, 13 (stack44)
        %v26383 = vshrl.u32 %v26376, 19 (stack45)
        %v26384 = vor.u32 %v26383, %v26382 (stack46)
        %v26385 = vxor.u32 %v26384, %v26380 (stack47)
        %v26388 = vadd.s32 %v26385, %v26380 (stack39)
        %v26390 = vshll.u32 %v26385, 15 (stack44)
        %v26391 = vshrl.u32 %v26385, 17 (stack45)
        %v26392 = vor.u32 %v26391, %v26390 (stack46)
        %v26393 = vxor.u32 %v26392, %v26388 (stack47)
        %v26396 = vadd.s32 %v26393, %v26388 (stack39)
        %v26398 = vshll.u32 %v26393, 26 (stack44)
        %v26399 = vshrl.u32 %v26393, 6 (stack45)
        %v26400 = vor.u32 %v26399, %v26398 (stack46)
        %v26401 = vxor.u32 %v26400, %v26396 (stack47)
        %v26404 = vadd.s32 %v26401, %v26396 (stack39)
        %v26408 = vadd.s32 %v26404, %v8 (stack39)
        %v26410 = vshll.u32 %v26401, 6 (stack44)
        %v26411 = vshrl.u32 %v26401, 26 (stack45)
        %v26412 = vor.u32 %v26411, %v26410 (stack46)
        %v26413 = vxor.u32 %v26412, %v26404 (stack47)
        %v26416 = vadd.s32 %v26413, %v10 (stack39)
        %v26420 = vadd.s32 5, %v26416 (stack39)
        %v26422 = vxor.u32 %v26420, %v26408 (stack47)
        %v26423 = vand.u32.u8 255, %v26422 (stack48)
        %v26424 = vand.u32 65535, %v26423 (stack49)
        %v26425 = vshrl.u32 %v26424, 1 (stack50)
        %v26426 = vor.u32 16256, %v26425 (stack46)
        %v26427 = vand.u32.u16 65535, %v26426 (stack51)
        %v119882 = vadd.low.f32.bf16 -1.0, %v26427 (stack52)
        %v26436 = vmul.f32 2.0, %v119882 (stack53)
        %v26440 = vadd.f32 -0.99609375, %v26436 (stack52)
        %v26444 = vmax.f32 %v26440, -0.99609375 (stack54)
        %v26446 = vand.u32 2147483647, %v26444 (stack55)
        %vm26449 = vcmp.eq.f32.partialorder %v26446, 1.0 (stack56)
        %v26454 = vmul.f32 inf, %v26444 (stack53)
        %v26456 = vxor.u32 2147483648, %v26444 (stack57)
        %v26459 = vmul.f32 %v26456, %v26444 (stack53)
        %v26461 = vadd.f32 1.0, %v26459 (stack58)
        %v26462 = vlog2.pop %v26461 (stack59)
        %v26463 = vmul.f32 0.6931472, %v26462 (stack60)
        %v26464 = vmul.f32 -0.5, %v26459 (stack61)
        %v26465 = vadd.f32 1.0, %v26464 (stack62)
        %v26466 = vmul.f32 %v26465, %v26459 (stack63)
        %v26467 = vand.u32 2147483647, %v26459 (stack64)
        %vm26468 = vcmp.lt.f32.partialorder %v26467, 0.0004427343 (stack65)
        %v26469 = vsel /*vm=*/%vm26468, /*on_true_vy=*/%v26466, /*on_false_vx=*/%v26463 (stack66)
        %v26470 = vxor.u32 2147483648, %v26469 (stack57)
        %vm26473 = vcmp.lt.f32.partialorder %v26470, 5.0 (stack56)
        %v26478 = vsel /*vm=*/%vm26473, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v26482 = vsel /*vm=*/%vm26473, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v26486 = vsel /*vm=*/%vm26473, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v26490 = vsel /*vm=*/%vm26473, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v26494 = vsel /*vm=*/%vm26473, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v26498 = vsel /*vm=*/%vm26473, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v26502 = vsel /*vm=*/%vm26473, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v26506 = vsel /*vm=*/%vm26473, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v26510 = vsel /*vm=*/%vm26473, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v26514 = vadd.f32 -2.5, %v26470 (stack52)
        %v26516 = vrsqrt.pop %v26470 (stack67)
        %v26517 = vmul.f32 %v26516, %v26470 (stack68)
        %vm26518 = vcmp.eq.f32.partialorder %v26470, inf (stack69)
        %v26519 = vsel /*vm=*/%vm26518, /*on_true_vy=*/%v26470, /*on_false_vx=*/%v26517 (stack70)
        %vm26520 = vcmp.eq.f32.partialorder %v26470, 0.0 (stack71)
        %v26521 = vand.u32 2147483648, %v26470 (stack72)
        %v26522 = vsel /*vm=*/%vm26520, /*on_true_vy=*/%v26521, /*on_false_vx=*/%v26519 (stack73)
        %v26525 = vadd.f32 -3.0, %v26522 (stack52)
        %v26529 = vsel /*vm=*/%vm26473, /*on_true_vy=*/%v26514, /*on_false_vx=*/%v26525 (stack43)
        %v26533 = vmul.f32 %v26529, %v26510 (stack53)
        %v26537 = vadd.f32 %v26533, %v26506 (stack52)
        %v26541 = vmul.f32 %v26537, %v26529 (stack53)
        %v26545 = vadd.f32 %v26541, %v26502 (stack52)
        %v26549 = vmul.f32 %v26545, %v26529 (stack53)
        %v26553 = vadd.f32 %v26549, %v26498 (stack52)
        %v26557 = vmul.f32 %v26553, %v26529 (stack53)
        %v26561 = vadd.f32 %v26557, %v26494 (stack52)
        %v26565 = vmul.f32 %v26561, %v26529 (stack53)
        %v26569 = vadd.f32 %v26565, %v26490 (stack52)
        %v26573 = vmul.f32 %v26569, %v26529 (stack53)
        %v26577 = vadd.f32 %v26573, %v26486 (stack52)
        %v26581 = vmul.f32 %v26577, %v26529 (stack53)
        %v26585 = vadd.f32 %v26581, %v26482 (stack52)
        %v26589 = vmul.f32 %v26585, %v26529 (stack53)
        %v26593 = vadd.f32 %v26589, %v26478 (stack52)
        %v26597 = vmul.f32 %v26593, %v26444 (stack53)
        %v26601 = vsel /*vm=*/%vm26449, /*on_true_vy=*/%v26454, /*on_false_vx=*/%v26597 (stack43)
        %v26605 = vmul.f32 1.4140625, %v26601 (stack53)
        %v26608 = vpack.c.bf16 0.0, %v26605 (stack74)
        %119883 = vst [vmem:[%s280 + $0x398] sm:$0xf] /*vst_source=*/%v26608 (stack75)
        %s26610 = sadd.s32 56, %s120390 (stack76)
        %s26611 = sshrl.u32 %s26610, 10 (stack23)
        %p119884 = scmp.gt.s32.totalorder %s26611, 1 (stack24)
        %s26613 = scalar_select /*predicate=*/%p119884, /*on_true=*/1, /*on_false=*/%s26611 (stack25)
        %s26614 = sand.u32 1023, %s26610 /* smod.u32 w/div 1024 */ (stack26)
        %s26615 = sshrl.u32 %s26614, 7 (stack27)
        %s26616 = sand.u32 127, %s26614 /* smod.u32 w/div 128 */ (stack28)
        %s119885 = sshll.u32 %s26613, 3 (stack29)
        %s26618 = scalar_lea.vmem %s3, %s119885 (stack30)
        %s26620 = scalar_lea.vmem %s26618, %s26615 (stack31)
        %v26621 = vld [vmem:[%s26620] ss:$0 sm:$0xff] (stack32)
        %s26622 = sand.u32 255, %s26616 (stack33)
        %s26624 = sor.u32 256, %s26622 (stack34)
        %26625 = vbcast.lane.b32.xlu0 %v26621, %s26624 (stack35)
        %v26626 = vpop.permute.xlu0 %26625 (stack36)
        %s26635 = scalar_lea.vmem %s5, %s119885 (stack30)
        %s26637 = scalar_lea.vmem %s26635, %s26615 (stack31)
        %v26638 = vld [vmem:[%s26637] ss:$0 sm:$0xff] (stack32)
        %26642 = vbcast.lane.b32.xlu0 %v26638, %s26624 (stack35)
        %v26643 = vpop.permute.xlu0 %26642 (stack36)
        %v26646 = vadd.s32 %v26643, %v408 (stack39)
        %v26656 = vadd.s32 %v26646, %v415 (stack39)
        %vm26660 = vcmp.lt.u32.totalorder %v26656, %v26646 (stack42)
        %vm26665 = vcmp.lt.u32.totalorder %v26646, %v408 (stack42)
        %v26670 = vadd.s32 %v26626, %v380 (stack39)
        %v26674 = vadd.s32 1, %v26670 (stack39)
        %v26678 = vsel /*vm=*/%vm26665, /*on_true_vy=*/%v26674, /*on_false_vx=*/%v26670 (stack43)
        %v26682 = vadd.s32 1, %v26678 (stack39)
        %v26686 = vsel /*vm=*/%vm26660, /*on_true_vy=*/%v26682, /*on_false_vx=*/%v26678 (stack43)
        %v26691 = vadd.s32 %v26686, %v10 (stack39)
        %v26695 = vadd.s32 %v26656, %v9 (stack39)
        %v26699 = vadd.s32 %v26695, %v26691 (stack39)
        %v26701 = vshll.u32 %v26695, 13 (stack44)
        %v26702 = vshrl.u32 %v26695, 19 (stack45)
        %v26703 = vor.u32 %v26702, %v26701 (stack46)
        %v26704 = vxor.u32 %v26703, %v26699 (stack47)
        %v26707 = vadd.s32 %v26704, %v26699 (stack39)
        %v26709 = vshll.u32 %v26704, 15 (stack44)
        %v26710 = vshrl.u32 %v26704, 17 (stack45)
        %v26711 = vor.u32 %v26710, %v26709 (stack46)
        %v26712 = vxor.u32 %v26711, %v26707 (stack47)
        %v26715 = vadd.s32 %v26712, %v26707 (stack39)
        %v26717 = vshll.u32 %v26712, 26 (stack44)
        %v26718 = vshrl.u32 %v26712, 6 (stack45)
        %v26719 = vor.u32 %v26718, %v26717 (stack46)
        %v26720 = vxor.u32 %v26719, %v26715 (stack47)
        %v26723 = vadd.s32 %v26720, %v26715 (stack39)
        %v26727 = vadd.s32 %v26723, %v9 (stack39)
        %v26729 = vshll.u32 %v26720, 6 (stack44)
        %v26730 = vshrl.u32 %v26720, 26 (stack45)
        %v26731 = vor.u32 %v26730, %v26729 (stack46)
        %v26732 = vxor.u32 %v26731, %v26723 (stack47)
        %v26735 = vadd.s32 %v26732, %v8 (stack39)
        %v26739 = vadd.s32 1, %v26735 (stack39)
        %v26743 = vadd.s32 %v26739, %v26727 (stack39)
        %v26745 = vshll.u32 %v26739, 17 (stack44)
        %v26746 = vshrl.u32 %v26739, 15 (stack45)
        %v26747 = vor.u32 %v26746, %v26745 (stack46)
        %v26748 = vxor.u32 %v26747, %v26743 (stack47)
        %v26751 = vadd.s32 %v26748, %v26743 (stack39)
        %v26753 = vshll.u32 %v26748, 29 (stack44)
        %v26754 = vshrl.u32 %v26748, 3 (stack45)
        %v26755 = vor.u32 %v26754, %v26753 (stack46)
        %v26756 = vxor.u32 %v26755, %v26751 (stack47)
        %v26759 = vadd.s32 %v26756, %v26751 (stack39)
        %v26761 = vshll.u32 %v26756, 16 (stack44)
        %v26762 = vshrl.u32 %v26756, 16 (stack45)
        %v26763 = vor.u32 %v26762, %v26761 (stack46)
        %v26764 = vxor.u32 %v26763, %v26759 (stack47)
        %v26767 = vadd.s32 %v26764, %v26759 (stack39)
        %v26771 = vadd.s32 %v26767, %v8 (stack39)
        %v26773 = vshll.u32 %v26764, 24 (stack44)
        %v26774 = vshrl.u32 %v26764, 8 (stack45)
        %v26775 = vor.u32 %v26774, %v26773 (stack46)
        %v26776 = vxor.u32 %v26775, %v26767 (stack47)
        %v26779 = vadd.s32 %v26776, %v10 (stack39)
        %v26783 = vadd.s32 2, %v26779 (stack39)
        %v26787 = vadd.s32 %v26783, %v26771 (stack39)
        %v26789 = vshll.u32 %v26783, 13 (stack44)
        %v26790 = vshrl.u32 %v26783, 19 (stack45)
        %v26791 = vor.u32 %v26790, %v26789 (stack46)
        %v26792 = vxor.u32 %v26791, %v26787 (stack47)
        %v26795 = vadd.s32 %v26792, %v26787 (stack39)
        %v26797 = vshll.u32 %v26792, 15 (stack44)
        %v26798 = vshrl.u32 %v26792, 17 (stack45)
        %v26799 = vor.u32 %v26798, %v26797 (stack46)
        %v26800 = vxor.u32 %v26799, %v26795 (stack47)
        %v26803 = vadd.s32 %v26800, %v26795 (stack39)
        %v26805 = vshll.u32 %v26800, 26 (stack44)
        %v26806 = vshrl.u32 %v26800, 6 (stack45)
        %v26807 = vor.u32 %v26806, %v26805 (stack46)
        %v26808 = vxor.u32 %v26807, %v26803 (stack47)
        %v26811 = vadd.s32 %v26808, %v26803 (stack39)
        %v26815 = vadd.s32 %v26811, %v10 (stack39)
        %v26817 = vshll.u32 %v26808, 6 (stack44)
        %v26818 = vshrl.u32 %v26808, 26 (stack45)
        %v26819 = vor.u32 %v26818, %v26817 (stack46)
        %v26820 = vxor.u32 %v26819, %v26811 (stack47)
        %v26823 = vadd.s32 %v26820, %v9 (stack39)
        %v26827 = vadd.s32 3, %v26823 (stack39)
        %v26831 = vadd.s32 %v26827, %v26815 (stack39)
        %v26833 = vshll.u32 %v26827, 17 (stack44)
        %v26834 = vshrl.u32 %v26827, 15 (stack45)
        %v26835 = vor.u32 %v26834, %v26833 (stack46)
        %v26836 = vxor.u32 %v26835, %v26831 (stack47)
        %v26839 = vadd.s32 %v26836, %v26831 (stack39)
        %v26841 = vshll.u32 %v26836, 29 (stack44)
        %v26842 = vshrl.u32 %v26836, 3 (stack45)
        %v26843 = vor.u32 %v26842, %v26841 (stack46)
        %v26844 = vxor.u32 %v26843, %v26839 (stack47)
        %v26847 = vadd.s32 %v26844, %v26839 (stack39)
        %v26849 = vshll.u32 %v26844, 16 (stack44)
        %v26850 = vshrl.u32 %v26844, 16 (stack45)
        %v26851 = vor.u32 %v26850, %v26849 (stack46)
        %v26852 = vxor.u32 %v26851, %v26847 (stack47)
        %v26855 = vadd.s32 %v26852, %v26847 (stack39)
        %v26859 = vadd.s32 %v26855, %v9 (stack39)
        %v26861 = vshll.u32 %v26852, 24 (stack44)
        %v26862 = vshrl.u32 %v26852, 8 (stack45)
        %v26863 = vor.u32 %v26862, %v26861 (stack46)
        %v26864 = vxor.u32 %v26863, %v26855 (stack47)
        %v26867 = vadd.s32 %v26864, %v8 (stack39)
        %v26871 = vadd.s32 4, %v26867 (stack39)
        %v26875 = vadd.s32 %v26871, %v26859 (stack39)
        %v26877 = vshll.u32 %v26871, 13 (stack44)
        %v26878 = vshrl.u32 %v26871, 19 (stack45)
        %v26879 = vor.u32 %v26878, %v26877 (stack46)
        %v26880 = vxor.u32 %v26879, %v26875 (stack47)
        %v26883 = vadd.s32 %v26880, %v26875 (stack39)
        %v26885 = vshll.u32 %v26880, 15 (stack44)
        %v26886 = vshrl.u32 %v26880, 17 (stack45)
        %v26887 = vor.u32 %v26886, %v26885 (stack46)
        %v26888 = vxor.u32 %v26887, %v26883 (stack47)
        %v26891 = vadd.s32 %v26888, %v26883 (stack39)
        %v26893 = vshll.u32 %v26888, 26 (stack44)
        %v26894 = vshrl.u32 %v26888, 6 (stack45)
        %v26895 = vor.u32 %v26894, %v26893 (stack46)
        %v26896 = vxor.u32 %v26895, %v26891 (stack47)
        %v26899 = vadd.s32 %v26896, %v26891 (stack39)
        %v26903 = vadd.s32 %v26899, %v8 (stack39)
        %v26905 = vshll.u32 %v26896, 6 (stack44)
        %v26906 = vshrl.u32 %v26896, 26 (stack45)
        %v26907 = vor.u32 %v26906, %v26905 (stack46)
        %v26908 = vxor.u32 %v26907, %v26899 (stack47)
        %v26911 = vadd.s32 %v26908, %v10 (stack39)
        %v26915 = vadd.s32 5, %v26911 (stack39)
        %v26917 = vxor.u32 %v26915, %v26903 (stack47)
        %v26918 = vand.u32.u8 255, %v26917 (stack48)
        %v26919 = vand.u32 65535, %v26918 (stack49)
        %v26920 = vshrl.u32 %v26919, 1 (stack50)
        %v26921 = vor.u32 16256, %v26920 (stack46)
        %v26922 = vand.u32.u16 65535, %v26921 (stack51)
        %v119888 = vadd.low.f32.bf16 -1.0, %v26922 (stack52)
        %v26931 = vmul.f32 2.0, %v119888 (stack53)
        %v26935 = vadd.f32 -0.99609375, %v26931 (stack52)
        %v26939 = vmax.f32 %v26935, -0.99609375 (stack54)
        %v26941 = vand.u32 2147483647, %v26939 (stack55)
        %vm26944 = vcmp.eq.f32.partialorder %v26941, 1.0 (stack56)
        %v26949 = vmul.f32 inf, %v26939 (stack53)
        %v26951 = vxor.u32 2147483648, %v26939 (stack57)
        %v26954 = vmul.f32 %v26951, %v26939 (stack53)
        %v26956 = vadd.f32 1.0, %v26954 (stack58)
        %v26957 = vlog2.pop %v26956 (stack59)
        %v26958 = vmul.f32 0.6931472, %v26957 (stack60)
        %v26959 = vmul.f32 -0.5, %v26954 (stack61)
        %v26960 = vadd.f32 1.0, %v26959 (stack62)
        %v26961 = vmul.f32 %v26960, %v26954 (stack63)
        %v26962 = vand.u32 2147483647, %v26954 (stack64)
        %vm26963 = vcmp.lt.f32.partialorder %v26962, 0.0004427343 (stack65)
        %v26964 = vsel /*vm=*/%vm26963, /*on_true_vy=*/%v26961, /*on_false_vx=*/%v26958 (stack66)
        %v26965 = vxor.u32 2147483648, %v26964 (stack57)
        %vm26968 = vcmp.lt.f32.partialorder %v26965, 5.0 (stack56)
        %v26973 = vsel /*vm=*/%vm26968, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v26977 = vsel /*vm=*/%vm26968, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v26981 = vsel /*vm=*/%vm26968, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v26985 = vsel /*vm=*/%vm26968, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v26989 = vsel /*vm=*/%vm26968, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v26993 = vsel /*vm=*/%vm26968, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v26997 = vsel /*vm=*/%vm26968, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v27001 = vsel /*vm=*/%vm26968, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v27005 = vsel /*vm=*/%vm26968, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v27009 = vadd.f32 -2.5, %v26965 (stack52)
        %v27011 = vrsqrt.pop %v26965 (stack67)
        %v27012 = vmul.f32 %v27011, %v26965 (stack68)
        %vm27013 = vcmp.eq.f32.partialorder %v26965, inf (stack69)
        %v27014 = vsel /*vm=*/%vm27013, /*on_true_vy=*/%v26965, /*on_false_vx=*/%v27012 (stack70)
        %vm27015 = vcmp.eq.f32.partialorder %v26965, 0.0 (stack71)
        %v27016 = vand.u32 2147483648, %v26965 (stack72)
        %v27017 = vsel /*vm=*/%vm27015, /*on_true_vy=*/%v27016, /*on_false_vx=*/%v27014 (stack73)
        %v27020 = vadd.f32 -3.0, %v27017 (stack52)
        %v27024 = vsel /*vm=*/%vm26968, /*on_true_vy=*/%v27009, /*on_false_vx=*/%v27020 (stack43)
        %v27028 = vmul.f32 %v27024, %v27005 (stack53)
        %v27032 = vadd.f32 %v27028, %v27001 (stack52)
        %v27036 = vmul.f32 %v27032, %v27024 (stack53)
        %v27040 = vadd.f32 %v27036, %v26997 (stack52)
        %v27044 = vmul.f32 %v27040, %v27024 (stack53)
        %v27048 = vadd.f32 %v27044, %v26993 (stack52)
        %v27052 = vmul.f32 %v27048, %v27024 (stack53)
        %v27056 = vadd.f32 %v27052, %v26989 (stack52)
        %v27060 = vmul.f32 %v27056, %v27024 (stack53)
        %v27064 = vadd.f32 %v27060, %v26985 (stack52)
        %v27068 = vmul.f32 %v27064, %v27024 (stack53)
        %v27072 = vadd.f32 %v27068, %v26981 (stack52)
        %v27076 = vmul.f32 %v27072, %v27024 (stack53)
        %v27080 = vadd.f32 %v27076, %v26977 (stack52)
        %v27084 = vmul.f32 %v27080, %v27024 (stack53)
        %v27088 = vadd.f32 %v27084, %v26973 (stack52)
        %v27092 = vmul.f32 %v27088, %v26939 (stack53)
        %v27096 = vsel /*vm=*/%vm26944, /*on_true_vy=*/%v26949, /*on_false_vx=*/%v27092 (stack43)
        %v27100 = vmul.f32 1.4140625, %v27096 (stack53)
        %v27103 = vpack.c.bf16 0.0, %v27100 (stack74)
        %119889 = vst [vmem:[%s280 + $0x1c] sm:$0xf] /*vst_source=*/%v27103 (stack75)
        %v27107 = vadd.s32 %v26643, %v894 (stack39)
        %v27117 = vadd.s32 %v27107, %v415 (stack39)
        %vm27121 = vcmp.lt.u32.totalorder %v27117, %v27107 (stack42)
        %vm27126 = vcmp.lt.u32.totalorder %v27107, %v894 (stack42)
        %v27131 = vadd.s32 %v26626, %v881 (stack39)
        %v27135 = vadd.s32 1, %v27131 (stack39)
        %v27139 = vsel /*vm=*/%vm27126, /*on_true_vy=*/%v27135, /*on_false_vx=*/%v27131 (stack43)
        %v27143 = vadd.s32 1, %v27139 (stack39)
        %v27147 = vsel /*vm=*/%vm27121, /*on_true_vy=*/%v27143, /*on_false_vx=*/%v27139 (stack43)
        %v27152 = vadd.s32 %v27147, %v10 (stack39)
        %v27156 = vadd.s32 %v27117, %v9 (stack39)
        %v27160 = vadd.s32 %v27156, %v27152 (stack39)
        %v27162 = vshll.u32 %v27156, 13 (stack44)
        %v27163 = vshrl.u32 %v27156, 19 (stack45)
        %v27164 = vor.u32 %v27163, %v27162 (stack46)
        %v27165 = vxor.u32 %v27164, %v27160 (stack47)
        %v27168 = vadd.s32 %v27165, %v27160 (stack39)
        %v27170 = vshll.u32 %v27165, 15 (stack44)
        %v27171 = vshrl.u32 %v27165, 17 (stack45)
        %v27172 = vor.u32 %v27171, %v27170 (stack46)
        %v27173 = vxor.u32 %v27172, %v27168 (stack47)
        %v27176 = vadd.s32 %v27173, %v27168 (stack39)
        %v27178 = vshll.u32 %v27173, 26 (stack44)
        %v27179 = vshrl.u32 %v27173, 6 (stack45)
        %v27180 = vor.u32 %v27179, %v27178 (stack46)
        %v27181 = vxor.u32 %v27180, %v27176 (stack47)
        %v27184 = vadd.s32 %v27181, %v27176 (stack39)
        %v27188 = vadd.s32 %v27184, %v9 (stack39)
        %v27190 = vshll.u32 %v27181, 6 (stack44)
        %v27191 = vshrl.u32 %v27181, 26 (stack45)
        %v27192 = vor.u32 %v27191, %v27190 (stack46)
        %v27193 = vxor.u32 %v27192, %v27184 (stack47)
        %v27196 = vadd.s32 %v27193, %v8 (stack39)
        %v27200 = vadd.s32 1, %v27196 (stack39)
        %v27204 = vadd.s32 %v27200, %v27188 (stack39)
        %v27206 = vshll.u32 %v27200, 17 (stack44)
        %v27207 = vshrl.u32 %v27200, 15 (stack45)
        %v27208 = vor.u32 %v27207, %v27206 (stack46)
        %v27209 = vxor.u32 %v27208, %v27204 (stack47)
        %v27212 = vadd.s32 %v27209, %v27204 (stack39)
        %v27214 = vshll.u32 %v27209, 29 (stack44)
        %v27215 = vshrl.u32 %v27209, 3 (stack45)
        %v27216 = vor.u32 %v27215, %v27214 (stack46)
        %v27217 = vxor.u32 %v27216, %v27212 (stack47)
        %v27220 = vadd.s32 %v27217, %v27212 (stack39)
        %v27222 = vshll.u32 %v27217, 16 (stack44)
        %v27223 = vshrl.u32 %v27217, 16 (stack45)
        %v27224 = vor.u32 %v27223, %v27222 (stack46)
        %v27225 = vxor.u32 %v27224, %v27220 (stack47)
        %v27228 = vadd.s32 %v27225, %v27220 (stack39)
        %v27232 = vadd.s32 %v27228, %v8 (stack39)
        %v27234 = vshll.u32 %v27225, 24 (stack44)
        %v27235 = vshrl.u32 %v27225, 8 (stack45)
        %v27236 = vor.u32 %v27235, %v27234 (stack46)
        %v27237 = vxor.u32 %v27236, %v27228 (stack47)
        %v27240 = vadd.s32 %v27237, %v10 (stack39)
        %v27244 = vadd.s32 2, %v27240 (stack39)
        %v27248 = vadd.s32 %v27244, %v27232 (stack39)
        %v27250 = vshll.u32 %v27244, 13 (stack44)
        %v27251 = vshrl.u32 %v27244, 19 (stack45)
        %v27252 = vor.u32 %v27251, %v27250 (stack46)
        %v27253 = vxor.u32 %v27252, %v27248 (stack47)
        %v27256 = vadd.s32 %v27253, %v27248 (stack39)
        %v27258 = vshll.u32 %v27253, 15 (stack44)
        %v27259 = vshrl.u32 %v27253, 17 (stack45)
        %v27260 = vor.u32 %v27259, %v27258 (stack46)
        %v27261 = vxor.u32 %v27260, %v27256 (stack47)
        %v27264 = vadd.s32 %v27261, %v27256 (stack39)
        %v27266 = vshll.u32 %v27261, 26 (stack44)
        %v27267 = vshrl.u32 %v27261, 6 (stack45)
        %v27268 = vor.u32 %v27267, %v27266 (stack46)
        %v27269 = vxor.u32 %v27268, %v27264 (stack47)
        %v27272 = vadd.s32 %v27269, %v27264 (stack39)
        %v27276 = vadd.s32 %v27272, %v10 (stack39)
        %v27278 = vshll.u32 %v27269, 6 (stack44)
        %v27279 = vshrl.u32 %v27269, 26 (stack45)
        %v27280 = vor.u32 %v27279, %v27278 (stack46)
        %v27281 = vxor.u32 %v27280, %v27272 (stack47)
        %v27284 = vadd.s32 %v27281, %v9 (stack39)
        %v27288 = vadd.s32 3, %v27284 (stack39)
        %v27292 = vadd.s32 %v27288, %v27276 (stack39)
        %v27294 = vshll.u32 %v27288, 17 (stack44)
        %v27295 = vshrl.u32 %v27288, 15 (stack45)
        %v27296 = vor.u32 %v27295, %v27294 (stack46)
        %v27297 = vxor.u32 %v27296, %v27292 (stack47)
        %v27300 = vadd.s32 %v27297, %v27292 (stack39)
        %v27302 = vshll.u32 %v27297, 29 (stack44)
        %v27303 = vshrl.u32 %v27297, 3 (stack45)
        %v27304 = vor.u32 %v27303, %v27302 (stack46)
        %v27305 = vxor.u32 %v27304, %v27300 (stack47)
        %v27308 = vadd.s32 %v27305, %v27300 (stack39)
        %v27310 = vshll.u32 %v27305, 16 (stack44)
        %v27311 = vshrl.u32 %v27305, 16 (stack45)
        %v27312 = vor.u32 %v27311, %v27310 (stack46)
        %v27313 = vxor.u32 %v27312, %v27308 (stack47)
        %v27316 = vadd.s32 %v27313, %v27308 (stack39)
        %v27320 = vadd.s32 %v27316, %v9 (stack39)
        %v27322 = vshll.u32 %v27313, 24 (stack44)
        %v27323 = vshrl.u32 %v27313, 8 (stack45)
        %v27324 = vor.u32 %v27323, %v27322 (stack46)
        %v27325 = vxor.u32 %v27324, %v27316 (stack47)
        %v27328 = vadd.s32 %v27325, %v8 (stack39)
        %v27332 = vadd.s32 4, %v27328 (stack39)
        %v27336 = vadd.s32 %v27332, %v27320 (stack39)
        %v27338 = vshll.u32 %v27332, 13 (stack44)
        %v27339 = vshrl.u32 %v27332, 19 (stack45)
        %v27340 = vor.u32 %v27339, %v27338 (stack46)
        %v27341 = vxor.u32 %v27340, %v27336 (stack47)
        %v27344 = vadd.s32 %v27341, %v27336 (stack39)
        %v27346 = vshll.u32 %v27341, 15 (stack44)
        %v27347 = vshrl.u32 %v27341, 17 (stack45)
        %v27348 = vor.u32 %v27347, %v27346 (stack46)
        %v27349 = vxor.u32 %v27348, %v27344 (stack47)
        %v27352 = vadd.s32 %v27349, %v27344 (stack39)
        %v27354 = vshll.u32 %v27349, 26 (stack44)
        %v27355 = vshrl.u32 %v27349, 6 (stack45)
        %v27356 = vor.u32 %v27355, %v27354 (stack46)
        %v27357 = vxor.u32 %v27356, %v27352 (stack47)
        %v27360 = vadd.s32 %v27357, %v27352 (stack39)
        %v27364 = vadd.s32 %v27360, %v8 (stack39)
        %v27366 = vshll.u32 %v27357, 6 (stack44)
        %v27367 = vshrl.u32 %v27357, 26 (stack45)
        %v27368 = vor.u32 %v27367, %v27366 (stack46)
        %v27369 = vxor.u32 %v27368, %v27360 (stack47)
        %v27372 = vadd.s32 %v27369, %v10 (stack39)
        %v27376 = vadd.s32 5, %v27372 (stack39)
        %v27378 = vxor.u32 %v27376, %v27364 (stack47)
        %v27379 = vand.u32.u8 255, %v27378 (stack48)
        %v27380 = vand.u32 65535, %v27379 (stack49)
        %v27381 = vshrl.u32 %v27380, 1 (stack50)
        %v27382 = vor.u32 16256, %v27381 (stack46)
        %v27383 = vand.u32.u16 65535, %v27382 (stack51)
        %v119890 = vadd.low.f32.bf16 -1.0, %v27383 (stack52)
        %v27392 = vmul.f32 2.0, %v119890 (stack53)
        %v27396 = vadd.f32 -0.99609375, %v27392 (stack52)
        %v27400 = vmax.f32 %v27396, -0.99609375 (stack54)
        %v27402 = vand.u32 2147483647, %v27400 (stack55)
        %vm27405 = vcmp.eq.f32.partialorder %v27402, 1.0 (stack56)
        %v27410 = vmul.f32 inf, %v27400 (stack53)
        %v27412 = vxor.u32 2147483648, %v27400 (stack57)
        %v27415 = vmul.f32 %v27412, %v27400 (stack53)
        %v27417 = vadd.f32 1.0, %v27415 (stack58)
        %v27418 = vlog2.pop %v27417 (stack59)
        %v27419 = vmul.f32 0.6931472, %v27418 (stack60)
        %v27420 = vmul.f32 -0.5, %v27415 (stack61)
        %v27421 = vadd.f32 1.0, %v27420 (stack62)
        %v27422 = vmul.f32 %v27421, %v27415 (stack63)
        %v27423 = vand.u32 2147483647, %v27415 (stack64)
        %vm27424 = vcmp.lt.f32.partialorder %v27423, 0.0004427343 (stack65)
        %v27425 = vsel /*vm=*/%vm27424, /*on_true_vy=*/%v27422, /*on_false_vx=*/%v27419 (stack66)
        %v27426 = vxor.u32 2147483648, %v27425 (stack57)
        %vm27429 = vcmp.lt.f32.partialorder %v27426, 5.0 (stack56)
        %v27434 = vsel /*vm=*/%vm27429, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v27438 = vsel /*vm=*/%vm27429, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v27442 = vsel /*vm=*/%vm27429, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v27446 = vsel /*vm=*/%vm27429, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v27450 = vsel /*vm=*/%vm27429, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v27454 = vsel /*vm=*/%vm27429, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v27458 = vsel /*vm=*/%vm27429, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v27462 = vsel /*vm=*/%vm27429, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v27466 = vsel /*vm=*/%vm27429, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v27470 = vadd.f32 -2.5, %v27426 (stack52)
        %v27472 = vrsqrt.pop %v27426 (stack67)
        %v27473 = vmul.f32 %v27472, %v27426 (stack68)
        %vm27474 = vcmp.eq.f32.partialorder %v27426, inf (stack69)
        %v27475 = vsel /*vm=*/%vm27474, /*on_true_vy=*/%v27426, /*on_false_vx=*/%v27473 (stack70)
        %vm27476 = vcmp.eq.f32.partialorder %v27426, 0.0 (stack71)
        %v27477 = vand.u32 2147483648, %v27426 (stack72)
        %v27478 = vsel /*vm=*/%vm27476, /*on_true_vy=*/%v27477, /*on_false_vx=*/%v27475 (stack73)
        %v27481 = vadd.f32 -3.0, %v27478 (stack52)
        %v27485 = vsel /*vm=*/%vm27429, /*on_true_vy=*/%v27470, /*on_false_vx=*/%v27481 (stack43)
        %v27489 = vmul.f32 %v27485, %v27466 (stack53)
        %v27493 = vadd.f32 %v27489, %v27462 (stack52)
        %v27497 = vmul.f32 %v27493, %v27485 (stack53)
        %v27501 = vadd.f32 %v27497, %v27458 (stack52)
        %v27505 = vmul.f32 %v27501, %v27485 (stack53)
        %v27509 = vadd.f32 %v27505, %v27454 (stack52)
        %v27513 = vmul.f32 %v27509, %v27485 (stack53)
        %v27517 = vadd.f32 %v27513, %v27450 (stack52)
        %v27521 = vmul.f32 %v27517, %v27485 (stack53)
        %v27525 = vadd.f32 %v27521, %v27446 (stack52)
        %v27529 = vmul.f32 %v27525, %v27485 (stack53)
        %v27533 = vadd.f32 %v27529, %v27442 (stack52)
        %v27537 = vmul.f32 %v27533, %v27485 (stack53)
        %v27541 = vadd.f32 %v27537, %v27438 (stack52)
        %v27545 = vmul.f32 %v27541, %v27485 (stack53)
        %v27549 = vadd.f32 %v27545, %v27434 (stack52)
        %v27553 = vmul.f32 %v27549, %v27400 (stack53)
        %v27557 = vsel /*vm=*/%vm27405, /*on_true_vy=*/%v27410, /*on_false_vx=*/%v27553 (stack43)
        %v27561 = vmul.f32 1.4140625, %v27557 (stack53)
        %v27564 = vpack.c.bf16 0.0, %v27561 (stack74)
        %119891 = vst [vmem:[%s280 + $0x9c] sm:$0xf] /*vst_source=*/%v27564 (stack75)
        %v27568 = vadd.s32 %v26643, %v1381 (stack39)
        %v27578 = vadd.s32 %v27568, %v415 (stack39)
        %vm27582 = vcmp.lt.u32.totalorder %v27578, %v27568 (stack42)
        %vm27587 = vcmp.lt.u32.totalorder %v27568, %v1381 (stack42)
        %v27592 = vadd.s32 %v26626, %v1368 (stack39)
        %v27596 = vadd.s32 1, %v27592 (stack39)
        %v27600 = vsel /*vm=*/%vm27587, /*on_true_vy=*/%v27596, /*on_false_vx=*/%v27592 (stack43)
        %v27604 = vadd.s32 1, %v27600 (stack39)
        %v27608 = vsel /*vm=*/%vm27582, /*on_true_vy=*/%v27604, /*on_false_vx=*/%v27600 (stack43)
        %v27613 = vadd.s32 %v27608, %v10 (stack39)
        %v27617 = vadd.s32 %v27578, %v9 (stack39)
        %v27621 = vadd.s32 %v27617, %v27613 (stack39)
        %v27623 = vshll.u32 %v27617, 13 (stack44)
        %v27624 = vshrl.u32 %v27617, 19 (stack45)
        %v27625 = vor.u32 %v27624, %v27623 (stack46)
        %v27626 = vxor.u32 %v27625, %v27621 (stack47)
        %v27629 = vadd.s32 %v27626, %v27621 (stack39)
        %v27631 = vshll.u32 %v27626, 15 (stack44)
        %v27632 = vshrl.u32 %v27626, 17 (stack45)
        %v27633 = vor.u32 %v27632, %v27631 (stack46)
        %v27634 = vxor.u32 %v27633, %v27629 (stack47)
        %v27637 = vadd.s32 %v27634, %v27629 (stack39)
        %v27639 = vshll.u32 %v27634, 26 (stack44)
        %v27640 = vshrl.u32 %v27634, 6 (stack45)
        %v27641 = vor.u32 %v27640, %v27639 (stack46)
        %v27642 = vxor.u32 %v27641, %v27637 (stack47)
        %v27645 = vadd.s32 %v27642, %v27637 (stack39)
        %v27649 = vadd.s32 %v27645, %v9 (stack39)
        %v27651 = vshll.u32 %v27642, 6 (stack44)
        %v27652 = vshrl.u32 %v27642, 26 (stack45)
        %v27653 = vor.u32 %v27652, %v27651 (stack46)
        %v27654 = vxor.u32 %v27653, %v27645 (stack47)
        %v27657 = vadd.s32 %v27654, %v8 (stack39)
        %v27661 = vadd.s32 1, %v27657 (stack39)
        %v27665 = vadd.s32 %v27661, %v27649 (stack39)
        %v27667 = vshll.u32 %v27661, 17 (stack44)
        %v27668 = vshrl.u32 %v27661, 15 (stack45)
        %v27669 = vor.u32 %v27668, %v27667 (stack46)
        %v27670 = vxor.u32 %v27669, %v27665 (stack47)
        %v27673 = vadd.s32 %v27670, %v27665 (stack39)
        %v27675 = vshll.u32 %v27670, 29 (stack44)
        %v27676 = vshrl.u32 %v27670, 3 (stack45)
        %v27677 = vor.u32 %v27676, %v27675 (stack46)
        %v27678 = vxor.u32 %v27677, %v27673 (stack47)
        %v27681 = vadd.s32 %v27678, %v27673 (stack39)
        %v27683 = vshll.u32 %v27678, 16 (stack44)
        %v27684 = vshrl.u32 %v27678, 16 (stack45)
        %v27685 = vor.u32 %v27684, %v27683 (stack46)
        %v27686 = vxor.u32 %v27685, %v27681 (stack47)
        %v27689 = vadd.s32 %v27686, %v27681 (stack39)
        %v27693 = vadd.s32 %v27689, %v8 (stack39)
        %v27695 = vshll.u32 %v27686, 24 (stack44)
        %v27696 = vshrl.u32 %v27686, 8 (stack45)
        %v27697 = vor.u32 %v27696, %v27695 (stack46)
        %v27698 = vxor.u32 %v27697, %v27689 (stack47)
        %v27701 = vadd.s32 %v27698, %v10 (stack39)
        %v27705 = vadd.s32 2, %v27701 (stack39)
        %v27709 = vadd.s32 %v27705, %v27693 (stack39)
        %v27711 = vshll.u32 %v27705, 13 (stack44)
        %v27712 = vshrl.u32 %v27705, 19 (stack45)
        %v27713 = vor.u32 %v27712, %v27711 (stack46)
        %v27714 = vxor.u32 %v27713, %v27709 (stack47)
        %v27717 = vadd.s32 %v27714, %v27709 (stack39)
        %v27719 = vshll.u32 %v27714, 15 (stack44)
        %v27720 = vshrl.u32 %v27714, 17 (stack45)
        %v27721 = vor.u32 %v27720, %v27719 (stack46)
        %v27722 = vxor.u32 %v27721, %v27717 (stack47)
        %v27725 = vadd.s32 %v27722, %v27717 (stack39)
        %v27727 = vshll.u32 %v27722, 26 (stack44)
        %v27728 = vshrl.u32 %v27722, 6 (stack45)
        %v27729 = vor.u32 %v27728, %v27727 (stack46)
        %v27730 = vxor.u32 %v27729, %v27725 (stack47)
        %v27733 = vadd.s32 %v27730, %v27725 (stack39)
        %v27737 = vadd.s32 %v27733, %v10 (stack39)
        %v27739 = vshll.u32 %v27730, 6 (stack44)
        %v27740 = vshrl.u32 %v27730, 26 (stack45)
        %v27741 = vor.u32 %v27740, %v27739 (stack46)
        %v27742 = vxor.u32 %v27741, %v27733 (stack47)
        %v27745 = vadd.s32 %v27742, %v9 (stack39)
        %v27749 = vadd.s32 3, %v27745 (stack39)
        %v27753 = vadd.s32 %v27749, %v27737 (stack39)
        %v27755 = vshll.u32 %v27749, 17 (stack44)
        %v27756 = vshrl.u32 %v27749, 15 (stack45)
        %v27757 = vor.u32 %v27756, %v27755 (stack46)
        %v27758 = vxor.u32 %v27757, %v27753 (stack47)
        %v27761 = vadd.s32 %v27758, %v27753 (stack39)
        %v27763 = vshll.u32 %v27758, 29 (stack44)
        %v27764 = vshrl.u32 %v27758, 3 (stack45)
        %v27765 = vor.u32 %v27764, %v27763 (stack46)
        %v27766 = vxor.u32 %v27765, %v27761 (stack47)
        %v27769 = vadd.s32 %v27766, %v27761 (stack39)
        %v27771 = vshll.u32 %v27766, 16 (stack44)
        %v27772 = vshrl.u32 %v27766, 16 (stack45)
        %v27773 = vor.u32 %v27772, %v27771 (stack46)
        %v27774 = vxor.u32 %v27773, %v27769 (stack47)
        %v27777 = vadd.s32 %v27774, %v27769 (stack39)
        %v27781 = vadd.s32 %v27777, %v9 (stack39)
        %v27783 = vshll.u32 %v27774, 24 (stack44)
        %v27784 = vshrl.u32 %v27774, 8 (stack45)
        %v27785 = vor.u32 %v27784, %v27783 (stack46)
        %v27786 = vxor.u32 %v27785, %v27777 (stack47)
        %v27789 = vadd.s32 %v27786, %v8 (stack39)
        %v27793 = vadd.s32 4, %v27789 (stack39)
        %v27797 = vadd.s32 %v27793, %v27781 (stack39)
        %v27799 = vshll.u32 %v27793, 13 (stack44)
        %v27800 = vshrl.u32 %v27793, 19 (stack45)
        %v27801 = vor.u32 %v27800, %v27799 (stack46)
        %v27802 = vxor.u32 %v27801, %v27797 (stack47)
        %v27805 = vadd.s32 %v27802, %v27797 (stack39)
        %v27807 = vshll.u32 %v27802, 15 (stack44)
        %v27808 = vshrl.u32 %v27802, 17 (stack45)
        %v27809 = vor.u32 %v27808, %v27807 (stack46)
        %v27810 = vxor.u32 %v27809, %v27805 (stack47)
        %v27813 = vadd.s32 %v27810, %v27805 (stack39)
        %v27815 = vshll.u32 %v27810, 26 (stack44)
        %v27816 = vshrl.u32 %v27810, 6 (stack45)
        %v27817 = vor.u32 %v27816, %v27815 (stack46)
        %v27818 = vxor.u32 %v27817, %v27813 (stack47)
        %v27821 = vadd.s32 %v27818, %v27813 (stack39)
        %v27825 = vadd.s32 %v27821, %v8 (stack39)
        %v27827 = vshll.u32 %v27818, 6 (stack44)
        %v27828 = vshrl.u32 %v27818, 26 (stack45)
        %v27829 = vor.u32 %v27828, %v27827 (stack46)
        %v27830 = vxor.u32 %v27829, %v27821 (stack47)
        %v27833 = vadd.s32 %v27830, %v10 (stack39)
        %v27837 = vadd.s32 5, %v27833 (stack39)
        %v27839 = vxor.u32 %v27837, %v27825 (stack47)
        %v27840 = vand.u32.u8 255, %v27839 (stack48)
        %v27841 = vand.u32 65535, %v27840 (stack49)
        %v27842 = vshrl.u32 %v27841, 1 (stack50)
        %v27843 = vor.u32 16256, %v27842 (stack46)
        %v27844 = vand.u32.u16 65535, %v27843 (stack51)
        %v119892 = vadd.low.f32.bf16 -1.0, %v27844 (stack52)
        %v27853 = vmul.f32 2.0, %v119892 (stack53)
        %v27857 = vadd.f32 -0.99609375, %v27853 (stack52)
        %v27861 = vmax.f32 %v27857, -0.99609375 (stack54)
        %v27863 = vand.u32 2147483647, %v27861 (stack55)
        %vm27866 = vcmp.eq.f32.partialorder %v27863, 1.0 (stack56)
        %v27871 = vmul.f32 inf, %v27861 (stack53)
        %v27873 = vxor.u32 2147483648, %v27861 (stack57)
        %v27876 = vmul.f32 %v27873, %v27861 (stack53)
        %v27878 = vadd.f32 1.0, %v27876 (stack58)
        %v27879 = vlog2.pop %v27878 (stack59)
        %v27880 = vmul.f32 0.6931472, %v27879 (stack60)
        %v27881 = vmul.f32 -0.5, %v27876 (stack61)
        %v27882 = vadd.f32 1.0, %v27881 (stack62)
        %v27883 = vmul.f32 %v27882, %v27876 (stack63)
        %v27884 = vand.u32 2147483647, %v27876 (stack64)
        %vm27885 = vcmp.lt.f32.partialorder %v27884, 0.0004427343 (stack65)
        %v27886 = vsel /*vm=*/%vm27885, /*on_true_vy=*/%v27883, /*on_false_vx=*/%v27880 (stack66)
        %v27887 = vxor.u32 2147483648, %v27886 (stack57)
        %vm27890 = vcmp.lt.f32.partialorder %v27887, 5.0 (stack56)
        %v27895 = vsel /*vm=*/%vm27890, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v27899 = vsel /*vm=*/%vm27890, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v27903 = vsel /*vm=*/%vm27890, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v27907 = vsel /*vm=*/%vm27890, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v27911 = vsel /*vm=*/%vm27890, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v27915 = vsel /*vm=*/%vm27890, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v27919 = vsel /*vm=*/%vm27890, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v27923 = vsel /*vm=*/%vm27890, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v27927 = vsel /*vm=*/%vm27890, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v27931 = vadd.f32 -2.5, %v27887 (stack52)
        %v27933 = vrsqrt.pop %v27887 (stack67)
        %v27934 = vmul.f32 %v27933, %v27887 (stack68)
        %vm27935 = vcmp.eq.f32.partialorder %v27887, inf (stack69)
        %v27936 = vsel /*vm=*/%vm27935, /*on_true_vy=*/%v27887, /*on_false_vx=*/%v27934 (stack70)
        %vm27937 = vcmp.eq.f32.partialorder %v27887, 0.0 (stack71)
        %v27938 = vand.u32 2147483648, %v27887 (stack72)
        %v27939 = vsel /*vm=*/%vm27937, /*on_true_vy=*/%v27938, /*on_false_vx=*/%v27936 (stack73)
        %v27942 = vadd.f32 -3.0, %v27939 (stack52)
        %v27946 = vsel /*vm=*/%vm27890, /*on_true_vy=*/%v27931, /*on_false_vx=*/%v27942 (stack43)
        %v27950 = vmul.f32 %v27946, %v27927 (stack53)
        %v27954 = vadd.f32 %v27950, %v27923 (stack52)
        %v27958 = vmul.f32 %v27954, %v27946 (stack53)
        %v27962 = vadd.f32 %v27958, %v27919 (stack52)
        %v27966 = vmul.f32 %v27962, %v27946 (stack53)
        %v27970 = vadd.f32 %v27966, %v27915 (stack52)
        %v27974 = vmul.f32 %v27970, %v27946 (stack53)
        %v27978 = vadd.f32 %v27974, %v27911 (stack52)
        %v27982 = vmul.f32 %v27978, %v27946 (stack53)
        %v27986 = vadd.f32 %v27982, %v27907 (stack52)
        %v27990 = vmul.f32 %v27986, %v27946 (stack53)
        %v27994 = vadd.f32 %v27990, %v27903 (stack52)
        %v27998 = vmul.f32 %v27994, %v27946 (stack53)
        %v28002 = vadd.f32 %v27998, %v27899 (stack52)
        %v28006 = vmul.f32 %v28002, %v27946 (stack53)
        %v28010 = vadd.f32 %v28006, %v27895 (stack52)
        %v28014 = vmul.f32 %v28010, %v27861 (stack53)
        %v28018 = vsel /*vm=*/%vm27866, /*on_true_vy=*/%v27871, /*on_false_vx=*/%v28014 (stack43)
        %v28022 = vmul.f32 1.4140625, %v28018 (stack53)
        %v28025 = vpack.c.bf16 0.0, %v28022 (stack74)
        %119893 = vst [vmem:[%s280 + $0x11c] sm:$0xf] /*vst_source=*/%v28025 (stack75)
        %v28029 = vadd.s32 %v26643, %v1868 (stack39)
        %v28039 = vadd.s32 %v28029, %v415 (stack39)
        %vm28043 = vcmp.lt.u32.totalorder %v28039, %v28029 (stack42)
        %vm28048 = vcmp.lt.u32.totalorder %v28029, %v1868 (stack42)
        %v28053 = vadd.s32 %v26626, %v1855 (stack39)
        %v28057 = vadd.s32 1, %v28053 (stack39)
        %v28061 = vsel /*vm=*/%vm28048, /*on_true_vy=*/%v28057, /*on_false_vx=*/%v28053 (stack43)
        %v28065 = vadd.s32 1, %v28061 (stack39)
        %v28069 = vsel /*vm=*/%vm28043, /*on_true_vy=*/%v28065, /*on_false_vx=*/%v28061 (stack43)
        %v28074 = vadd.s32 %v28069, %v10 (stack39)
        %v28078 = vadd.s32 %v28039, %v9 (stack39)
        %v28082 = vadd.s32 %v28078, %v28074 (stack39)
        %v28084 = vshll.u32 %v28078, 13 (stack44)
        %v28085 = vshrl.u32 %v28078, 19 (stack45)
        %v28086 = vor.u32 %v28085, %v28084 (stack46)
        %v28087 = vxor.u32 %v28086, %v28082 (stack47)
        %v28090 = vadd.s32 %v28087, %v28082 (stack39)
        %v28092 = vshll.u32 %v28087, 15 (stack44)
        %v28093 = vshrl.u32 %v28087, 17 (stack45)
        %v28094 = vor.u32 %v28093, %v28092 (stack46)
        %v28095 = vxor.u32 %v28094, %v28090 (stack47)
        %v28098 = vadd.s32 %v28095, %v28090 (stack39)
        %v28100 = vshll.u32 %v28095, 26 (stack44)
        %v28101 = vshrl.u32 %v28095, 6 (stack45)
        %v28102 = vor.u32 %v28101, %v28100 (stack46)
        %v28103 = vxor.u32 %v28102, %v28098 (stack47)
        %v28106 = vadd.s32 %v28103, %v28098 (stack39)
        %v28110 = vadd.s32 %v28106, %v9 (stack39)
        %v28112 = vshll.u32 %v28103, 6 (stack44)
        %v28113 = vshrl.u32 %v28103, 26 (stack45)
        %v28114 = vor.u32 %v28113, %v28112 (stack46)
        %v28115 = vxor.u32 %v28114, %v28106 (stack47)
        %v28118 = vadd.s32 %v28115, %v8 (stack39)
        %v28122 = vadd.s32 1, %v28118 (stack39)
        %v28126 = vadd.s32 %v28122, %v28110 (stack39)
        %v28128 = vshll.u32 %v28122, 17 (stack44)
        %v28129 = vshrl.u32 %v28122, 15 (stack45)
        %v28130 = vor.u32 %v28129, %v28128 (stack46)
        %v28131 = vxor.u32 %v28130, %v28126 (stack47)
        %v28134 = vadd.s32 %v28131, %v28126 (stack39)
        %v28136 = vshll.u32 %v28131, 29 (stack44)
        %v28137 = vshrl.u32 %v28131, 3 (stack45)
        %v28138 = vor.u32 %v28137, %v28136 (stack46)
        %v28139 = vxor.u32 %v28138, %v28134 (stack47)
        %v28142 = vadd.s32 %v28139, %v28134 (stack39)
        %v28144 = vshll.u32 %v28139, 16 (stack44)
        %v28145 = vshrl.u32 %v28139, 16 (stack45)
        %v28146 = vor.u32 %v28145, %v28144 (stack46)
        %v28147 = vxor.u32 %v28146, %v28142 (stack47)
        %v28150 = vadd.s32 %v28147, %v28142 (stack39)
        %v28154 = vadd.s32 %v28150, %v8 (stack39)
        %v28156 = vshll.u32 %v28147, 24 (stack44)
        %v28157 = vshrl.u32 %v28147, 8 (stack45)
        %v28158 = vor.u32 %v28157, %v28156 (stack46)
        %v28159 = vxor.u32 %v28158, %v28150 (stack47)
        %v28162 = vadd.s32 %v28159, %v10 (stack39)
        %v28166 = vadd.s32 2, %v28162 (stack39)
        %v28170 = vadd.s32 %v28166, %v28154 (stack39)
        %v28172 = vshll.u32 %v28166, 13 (stack44)
        %v28173 = vshrl.u32 %v28166, 19 (stack45)
        %v28174 = vor.u32 %v28173, %v28172 (stack46)
        %v28175 = vxor.u32 %v28174, %v28170 (stack47)
        %v28178 = vadd.s32 %v28175, %v28170 (stack39)
        %v28180 = vshll.u32 %v28175, 15 (stack44)
        %v28181 = vshrl.u32 %v28175, 17 (stack45)
        %v28182 = vor.u32 %v28181, %v28180 (stack46)
        %v28183 = vxor.u32 %v28182, %v28178 (stack47)
        %v28186 = vadd.s32 %v28183, %v28178 (stack39)
        %v28188 = vshll.u32 %v28183, 26 (stack44)
        %v28189 = vshrl.u32 %v28183, 6 (stack45)
        %v28190 = vor.u32 %v28189, %v28188 (stack46)
        %v28191 = vxor.u32 %v28190, %v28186 (stack47)
        %v28194 = vadd.s32 %v28191, %v28186 (stack39)
        %v28198 = vadd.s32 %v28194, %v10 (stack39)
        %v28200 = vshll.u32 %v28191, 6 (stack44)
        %v28201 = vshrl.u32 %v28191, 26 (stack45)
        %v28202 = vor.u32 %v28201, %v28200 (stack46)
        %v28203 = vxor.u32 %v28202, %v28194 (stack47)
        %v28206 = vadd.s32 %v28203, %v9 (stack39)
        %v28210 = vadd.s32 3, %v28206 (stack39)
        %v28214 = vadd.s32 %v28210, %v28198 (stack39)
        %v28216 = vshll.u32 %v28210, 17 (stack44)
        %v28217 = vshrl.u32 %v28210, 15 (stack45)
        %v28218 = vor.u32 %v28217, %v28216 (stack46)
        %v28219 = vxor.u32 %v28218, %v28214 (stack47)
        %v28222 = vadd.s32 %v28219, %v28214 (stack39)
        %v28224 = vshll.u32 %v28219, 29 (stack44)
        %v28225 = vshrl.u32 %v28219, 3 (stack45)
        %v28226 = vor.u32 %v28225, %v28224 (stack46)
        %v28227 = vxor.u32 %v28226, %v28222 (stack47)
        %v28230 = vadd.s32 %v28227, %v28222 (stack39)
        %v28232 = vshll.u32 %v28227, 16 (stack44)
        %v28233 = vshrl.u32 %v28227, 16 (stack45)
        %v28234 = vor.u32 %v28233, %v28232 (stack46)
        %v28235 = vxor.u32 %v28234, %v28230 (stack47)
        %v28238 = vadd.s32 %v28235, %v28230 (stack39)
        %v28242 = vadd.s32 %v28238, %v9 (stack39)
        %v28244 = vshll.u32 %v28235, 24 (stack44)
        %v28245 = vshrl.u32 %v28235, 8 (stack45)
        %v28246 = vor.u32 %v28245, %v28244 (stack46)
        %v28247 = vxor.u32 %v28246, %v28238 (stack47)
        %v28250 = vadd.s32 %v28247, %v8 (stack39)
        %v28254 = vadd.s32 4, %v28250 (stack39)
        %v28258 = vadd.s32 %v28254, %v28242 (stack39)
        %v28260 = vshll.u32 %v28254, 13 (stack44)
        %v28261 = vshrl.u32 %v28254, 19 (stack45)
        %v28262 = vor.u32 %v28261, %v28260 (stack46)
        %v28263 = vxor.u32 %v28262, %v28258 (stack47)
        %v28266 = vadd.s32 %v28263, %v28258 (stack39)
        %v28268 = vshll.u32 %v28263, 15 (stack44)
        %v28269 = vshrl.u32 %v28263, 17 (stack45)
        %v28270 = vor.u32 %v28269, %v28268 (stack46)
        %v28271 = vxor.u32 %v28270, %v28266 (stack47)
        %v28274 = vadd.s32 %v28271, %v28266 (stack39)
        %v28276 = vshll.u32 %v28271, 26 (stack44)
        %v28277 = vshrl.u32 %v28271, 6 (stack45)
        %v28278 = vor.u32 %v28277, %v28276 (stack46)
        %v28279 = vxor.u32 %v28278, %v28274 (stack47)
        %v28282 = vadd.s32 %v28279, %v28274 (stack39)
        %v28286 = vadd.s32 %v28282, %v8 (stack39)
        %v28288 = vshll.u32 %v28279, 6 (stack44)
        %v28289 = vshrl.u32 %v28279, 26 (stack45)
        %v28290 = vor.u32 %v28289, %v28288 (stack46)
        %v28291 = vxor.u32 %v28290, %v28282 (stack47)
        %v28294 = vadd.s32 %v28291, %v10 (stack39)
        %v28298 = vadd.s32 5, %v28294 (stack39)
        %v28300 = vxor.u32 %v28298, %v28286 (stack47)
        %v28301 = vand.u32.u8 255, %v28300 (stack48)
        %v28302 = vand.u32 65535, %v28301 (stack49)
        %v28303 = vshrl.u32 %v28302, 1 (stack50)
        %v28304 = vor.u32 16256, %v28303 (stack46)
        %v28305 = vand.u32.u16 65535, %v28304 (stack51)
        %v119894 = vadd.low.f32.bf16 -1.0, %v28305 (stack52)
        %v28314 = vmul.f32 2.0, %v119894 (stack53)
        %v28318 = vadd.f32 -0.99609375, %v28314 (stack52)
        %v28322 = vmax.f32 %v28318, -0.99609375 (stack54)
        %v28324 = vand.u32 2147483647, %v28322 (stack55)
        %vm28327 = vcmp.eq.f32.partialorder %v28324, 1.0 (stack56)
        %v28332 = vmul.f32 inf, %v28322 (stack53)
        %v28334 = vxor.u32 2147483648, %v28322 (stack57)
        %v28337 = vmul.f32 %v28334, %v28322 (stack53)
        %v28339 = vadd.f32 1.0, %v28337 (stack58)
        %v28340 = vlog2.pop %v28339 (stack59)
        %v28341 = vmul.f32 0.6931472, %v28340 (stack60)
        %v28342 = vmul.f32 -0.5, %v28337 (stack61)
        %v28343 = vadd.f32 1.0, %v28342 (stack62)
        %v28344 = vmul.f32 %v28343, %v28337 (stack63)
        %v28345 = vand.u32 2147483647, %v28337 (stack64)
        %vm28346 = vcmp.lt.f32.partialorder %v28345, 0.0004427343 (stack65)
        %v28347 = vsel /*vm=*/%vm28346, /*on_true_vy=*/%v28344, /*on_false_vx=*/%v28341 (stack66)
        %v28348 = vxor.u32 2147483648, %v28347 (stack57)
        %vm28351 = vcmp.lt.f32.partialorder %v28348, 5.0 (stack56)
        %v28356 = vsel /*vm=*/%vm28351, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v28360 = vsel /*vm=*/%vm28351, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v28364 = vsel /*vm=*/%vm28351, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v28368 = vsel /*vm=*/%vm28351, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v28372 = vsel /*vm=*/%vm28351, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v28376 = vsel /*vm=*/%vm28351, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v28380 = vsel /*vm=*/%vm28351, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v28384 = vsel /*vm=*/%vm28351, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v28388 = vsel /*vm=*/%vm28351, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v28392 = vadd.f32 -2.5, %v28348 (stack52)
        %v28394 = vrsqrt.pop %v28348 (stack67)
        %v28395 = vmul.f32 %v28394, %v28348 (stack68)
        %vm28396 = vcmp.eq.f32.partialorder %v28348, inf (stack69)
        %v28397 = vsel /*vm=*/%vm28396, /*on_true_vy=*/%v28348, /*on_false_vx=*/%v28395 (stack70)
        %vm28398 = vcmp.eq.f32.partialorder %v28348, 0.0 (stack71)
        %v28399 = vand.u32 2147483648, %v28348 (stack72)
        %v28400 = vsel /*vm=*/%vm28398, /*on_true_vy=*/%v28399, /*on_false_vx=*/%v28397 (stack73)
        %v28403 = vadd.f32 -3.0, %v28400 (stack52)
        %v28407 = vsel /*vm=*/%vm28351, /*on_true_vy=*/%v28392, /*on_false_vx=*/%v28403 (stack43)
        %v28411 = vmul.f32 %v28407, %v28388 (stack53)
        %v28415 = vadd.f32 %v28411, %v28384 (stack52)
        %v28419 = vmul.f32 %v28415, %v28407 (stack53)
        %v28423 = vadd.f32 %v28419, %v28380 (stack52)
        %v28427 = vmul.f32 %v28423, %v28407 (stack53)
        %v28431 = vadd.f32 %v28427, %v28376 (stack52)
        %v28435 = vmul.f32 %v28431, %v28407 (stack53)
        %v28439 = vadd.f32 %v28435, %v28372 (stack52)
        %v28443 = vmul.f32 %v28439, %v28407 (stack53)
        %v28447 = vadd.f32 %v28443, %v28368 (stack52)
        %v28451 = vmul.f32 %v28447, %v28407 (stack53)
        %v28455 = vadd.f32 %v28451, %v28364 (stack52)
        %v28459 = vmul.f32 %v28455, %v28407 (stack53)
        %v28463 = vadd.f32 %v28459, %v28360 (stack52)
        %v28467 = vmul.f32 %v28463, %v28407 (stack53)
        %v28471 = vadd.f32 %v28467, %v28356 (stack52)
        %v28475 = vmul.f32 %v28471, %v28322 (stack53)
        %v28479 = vsel /*vm=*/%vm28327, /*on_true_vy=*/%v28332, /*on_false_vx=*/%v28475 (stack43)
        %v28483 = vmul.f32 1.4140625, %v28479 (stack53)
        %v28486 = vpack.c.bf16 0.0, %v28483 (stack74)
        %119895 = vst [vmem:[%s280 + $0x19c] sm:$0xf] /*vst_source=*/%v28486 (stack75)
        %v28490 = vadd.s32 %v26643, %v2355 (stack39)
        %v28500 = vadd.s32 %v28490, %v415 (stack39)
        %vm28504 = vcmp.lt.u32.totalorder %v28500, %v28490 (stack42)
        %vm28509 = vcmp.lt.u32.totalorder %v28490, %v2355 (stack42)
        %v28514 = vadd.s32 %v26626, %v2342 (stack39)
        %v28518 = vadd.s32 1, %v28514 (stack39)
        %v28522 = vsel /*vm=*/%vm28509, /*on_true_vy=*/%v28518, /*on_false_vx=*/%v28514 (stack43)
        %v28526 = vadd.s32 1, %v28522 (stack39)
        %v28530 = vsel /*vm=*/%vm28504, /*on_true_vy=*/%v28526, /*on_false_vx=*/%v28522 (stack43)
        %v28535 = vadd.s32 %v28530, %v10 (stack39)
        %v28539 = vadd.s32 %v28500, %v9 (stack39)
        %v28543 = vadd.s32 %v28539, %v28535 (stack39)
        %v28545 = vshll.u32 %v28539, 13 (stack44)
        %v28546 = vshrl.u32 %v28539, 19 (stack45)
        %v28547 = vor.u32 %v28546, %v28545 (stack46)
        %v28548 = vxor.u32 %v28547, %v28543 (stack47)
        %v28551 = vadd.s32 %v28548, %v28543 (stack39)
        %v28553 = vshll.u32 %v28548, 15 (stack44)
        %v28554 = vshrl.u32 %v28548, 17 (stack45)
        %v28555 = vor.u32 %v28554, %v28553 (stack46)
        %v28556 = vxor.u32 %v28555, %v28551 (stack47)
        %v28559 = vadd.s32 %v28556, %v28551 (stack39)
        %v28561 = vshll.u32 %v28556, 26 (stack44)
        %v28562 = vshrl.u32 %v28556, 6 (stack45)
        %v28563 = vor.u32 %v28562, %v28561 (stack46)
        %v28564 = vxor.u32 %v28563, %v28559 (stack47)
        %v28567 = vadd.s32 %v28564, %v28559 (stack39)
        %v28571 = vadd.s32 %v28567, %v9 (stack39)
        %v28573 = vshll.u32 %v28564, 6 (stack44)
        %v28574 = vshrl.u32 %v28564, 26 (stack45)
        %v28575 = vor.u32 %v28574, %v28573 (stack46)
        %v28576 = vxor.u32 %v28575, %v28567 (stack47)
        %v28579 = vadd.s32 %v28576, %v8 (stack39)
        %v28583 = vadd.s32 1, %v28579 (stack39)
        %v28587 = vadd.s32 %v28583, %v28571 (stack39)
        %v28589 = vshll.u32 %v28583, 17 (stack44)
        %v28590 = vshrl.u32 %v28583, 15 (stack45)
        %v28591 = vor.u32 %v28590, %v28589 (stack46)
        %v28592 = vxor.u32 %v28591, %v28587 (stack47)
        %v28595 = vadd.s32 %v28592, %v28587 (stack39)
        %v28597 = vshll.u32 %v28592, 29 (stack44)
        %v28598 = vshrl.u32 %v28592, 3 (stack45)
        %v28599 = vor.u32 %v28598, %v28597 (stack46)
        %v28600 = vxor.u32 %v28599, %v28595 (stack47)
        %v28603 = vadd.s32 %v28600, %v28595 (stack39)
        %v28605 = vshll.u32 %v28600, 16 (stack44)
        %v28606 = vshrl.u32 %v28600, 16 (stack45)
        %v28607 = vor.u32 %v28606, %v28605 (stack46)
        %v28608 = vxor.u32 %v28607, %v28603 (stack47)
        %v28611 = vadd.s32 %v28608, %v28603 (stack39)
        %v28615 = vadd.s32 %v28611, %v8 (stack39)
        %v28617 = vshll.u32 %v28608, 24 (stack44)
        %v28618 = vshrl.u32 %v28608, 8 (stack45)
        %v28619 = vor.u32 %v28618, %v28617 (stack46)
        %v28620 = vxor.u32 %v28619, %v28611 (stack47)
        %v28623 = vadd.s32 %v28620, %v10 (stack39)
        %v28627 = vadd.s32 2, %v28623 (stack39)
        %v28631 = vadd.s32 %v28627, %v28615 (stack39)
        %v28633 = vshll.u32 %v28627, 13 (stack44)
        %v28634 = vshrl.u32 %v28627, 19 (stack45)
        %v28635 = vor.u32 %v28634, %v28633 (stack46)
        %v28636 = vxor.u32 %v28635, %v28631 (stack47)
        %v28639 = vadd.s32 %v28636, %v28631 (stack39)
        %v28641 = vshll.u32 %v28636, 15 (stack44)
        %v28642 = vshrl.u32 %v28636, 17 (stack45)
        %v28643 = vor.u32 %v28642, %v28641 (stack46)
        %v28644 = vxor.u32 %v28643, %v28639 (stack47)
        %v28647 = vadd.s32 %v28644, %v28639 (stack39)
        %v28649 = vshll.u32 %v28644, 26 (stack44)
        %v28650 = vshrl.u32 %v28644, 6 (stack45)
        %v28651 = vor.u32 %v28650, %v28649 (stack46)
        %v28652 = vxor.u32 %v28651, %v28647 (stack47)
        %v28655 = vadd.s32 %v28652, %v28647 (stack39)
        %v28659 = vadd.s32 %v28655, %v10 (stack39)
        %v28661 = vshll.u32 %v28652, 6 (stack44)
        %v28662 = vshrl.u32 %v28652, 26 (stack45)
        %v28663 = vor.u32 %v28662, %v28661 (stack46)
        %v28664 = vxor.u32 %v28663, %v28655 (stack47)
        %v28667 = vadd.s32 %v28664, %v9 (stack39)
        %v28671 = vadd.s32 3, %v28667 (stack39)
        %v28675 = vadd.s32 %v28671, %v28659 (stack39)
        %v28677 = vshll.u32 %v28671, 17 (stack44)
        %v28678 = vshrl.u32 %v28671, 15 (stack45)
        %v28679 = vor.u32 %v28678, %v28677 (stack46)
        %v28680 = vxor.u32 %v28679, %v28675 (stack47)
        %v28683 = vadd.s32 %v28680, %v28675 (stack39)
        %v28685 = vshll.u32 %v28680, 29 (stack44)
        %v28686 = vshrl.u32 %v28680, 3 (stack45)
        %v28687 = vor.u32 %v28686, %v28685 (stack46)
        %v28688 = vxor.u32 %v28687, %v28683 (stack47)
        %v28691 = vadd.s32 %v28688, %v28683 (stack39)
        %v28693 = vshll.u32 %v28688, 16 (stack44)
        %v28694 = vshrl.u32 %v28688, 16 (stack45)
        %v28695 = vor.u32 %v28694, %v28693 (stack46)
        %v28696 = vxor.u32 %v28695, %v28691 (stack47)
        %v28699 = vadd.s32 %v28696, %v28691 (stack39)
        %v28703 = vadd.s32 %v28699, %v9 (stack39)
        %v28705 = vshll.u32 %v28696, 24 (stack44)
        %v28706 = vshrl.u32 %v28696, 8 (stack45)
        %v28707 = vor.u32 %v28706, %v28705 (stack46)
        %v28708 = vxor.u32 %v28707, %v28699 (stack47)
        %v28711 = vadd.s32 %v28708, %v8 (stack39)
        %v28715 = vadd.s32 4, %v28711 (stack39)
        %v28719 = vadd.s32 %v28715, %v28703 (stack39)
        %v28721 = vshll.u32 %v28715, 13 (stack44)
        %v28722 = vshrl.u32 %v28715, 19 (stack45)
        %v28723 = vor.u32 %v28722, %v28721 (stack46)
        %v28724 = vxor.u32 %v28723, %v28719 (stack47)
        %v28727 = vadd.s32 %v28724, %v28719 (stack39)
        %v28729 = vshll.u32 %v28724, 15 (stack44)
        %v28730 = vshrl.u32 %v28724, 17 (stack45)
        %v28731 = vor.u32 %v28730, %v28729 (stack46)
        %v28732 = vxor.u32 %v28731, %v28727 (stack47)
        %v28735 = vadd.s32 %v28732, %v28727 (stack39)
        %v28737 = vshll.u32 %v28732, 26 (stack44)
        %v28738 = vshrl.u32 %v28732, 6 (stack45)
        %v28739 = vor.u32 %v28738, %v28737 (stack46)
        %v28740 = vxor.u32 %v28739, %v28735 (stack47)
        %v28743 = vadd.s32 %v28740, %v28735 (stack39)
        %v28747 = vadd.s32 %v28743, %v8 (stack39)
        %v28749 = vshll.u32 %v28740, 6 (stack44)
        %v28750 = vshrl.u32 %v28740, 26 (stack45)
        %v28751 = vor.u32 %v28750, %v28749 (stack46)
        %v28752 = vxor.u32 %v28751, %v28743 (stack47)
        %v28755 = vadd.s32 %v28752, %v10 (stack39)
        %v28759 = vadd.s32 5, %v28755 (stack39)
        %v28761 = vxor.u32 %v28759, %v28747 (stack47)
        %v28762 = vand.u32.u8 255, %v28761 (stack48)
        %v28763 = vand.u32 65535, %v28762 (stack49)
        %v28764 = vshrl.u32 %v28763, 1 (stack50)
        %v28765 = vor.u32 16256, %v28764 (stack46)
        %v28766 = vand.u32.u16 65535, %v28765 (stack51)
        %v119896 = vadd.low.f32.bf16 -1.0, %v28766 (stack52)
        %v28775 = vmul.f32 2.0, %v119896 (stack53)
        %v28779 = vadd.f32 -0.99609375, %v28775 (stack52)
        %v28783 = vmax.f32 %v28779, -0.99609375 (stack54)
        %v28785 = vand.u32 2147483647, %v28783 (stack55)
        %vm28788 = vcmp.eq.f32.partialorder %v28785, 1.0 (stack56)
        %v28793 = vmul.f32 inf, %v28783 (stack53)
        %v28795 = vxor.u32 2147483648, %v28783 (stack57)
        %v28798 = vmul.f32 %v28795, %v28783 (stack53)
        %v28800 = vadd.f32 1.0, %v28798 (stack58)
        %v28801 = vlog2.pop %v28800 (stack59)
        %v28802 = vmul.f32 0.6931472, %v28801 (stack60)
        %v28803 = vmul.f32 -0.5, %v28798 (stack61)
        %v28804 = vadd.f32 1.0, %v28803 (stack62)
        %v28805 = vmul.f32 %v28804, %v28798 (stack63)
        %v28806 = vand.u32 2147483647, %v28798 (stack64)
        %vm28807 = vcmp.lt.f32.partialorder %v28806, 0.0004427343 (stack65)
        %v28808 = vsel /*vm=*/%vm28807, /*on_true_vy=*/%v28805, /*on_false_vx=*/%v28802 (stack66)
        %v28809 = vxor.u32 2147483648, %v28808 (stack57)
        %vm28812 = vcmp.lt.f32.partialorder %v28809, 5.0 (stack56)
        %v28817 = vsel /*vm=*/%vm28812, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v28821 = vsel /*vm=*/%vm28812, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v28825 = vsel /*vm=*/%vm28812, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v28829 = vsel /*vm=*/%vm28812, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v28833 = vsel /*vm=*/%vm28812, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v28837 = vsel /*vm=*/%vm28812, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v28841 = vsel /*vm=*/%vm28812, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v28845 = vsel /*vm=*/%vm28812, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v28849 = vsel /*vm=*/%vm28812, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v28853 = vadd.f32 -2.5, %v28809 (stack52)
        %v28855 = vrsqrt.pop %v28809 (stack67)
        %v28856 = vmul.f32 %v28855, %v28809 (stack68)
        %vm28857 = vcmp.eq.f32.partialorder %v28809, inf (stack69)
        %v28858 = vsel /*vm=*/%vm28857, /*on_true_vy=*/%v28809, /*on_false_vx=*/%v28856 (stack70)
        %vm28859 = vcmp.eq.f32.partialorder %v28809, 0.0 (stack71)
        %v28860 = vand.u32 2147483648, %v28809 (stack72)
        %v28861 = vsel /*vm=*/%vm28859, /*on_true_vy=*/%v28860, /*on_false_vx=*/%v28858 (stack73)
        %v28864 = vadd.f32 -3.0, %v28861 (stack52)
        %v28868 = vsel /*vm=*/%vm28812, /*on_true_vy=*/%v28853, /*on_false_vx=*/%v28864 (stack43)
        %v28872 = vmul.f32 %v28868, %v28849 (stack53)
        %v28876 = vadd.f32 %v28872, %v28845 (stack52)
        %v28880 = vmul.f32 %v28876, %v28868 (stack53)
        %v28884 = vadd.f32 %v28880, %v28841 (stack52)
        %v28888 = vmul.f32 %v28884, %v28868 (stack53)
        %v28892 = vadd.f32 %v28888, %v28837 (stack52)
        %v28896 = vmul.f32 %v28892, %v28868 (stack53)
        %v28900 = vadd.f32 %v28896, %v28833 (stack52)
        %v28904 = vmul.f32 %v28900, %v28868 (stack53)
        %v28908 = vadd.f32 %v28904, %v28829 (stack52)
        %v28912 = vmul.f32 %v28908, %v28868 (stack53)
        %v28916 = vadd.f32 %v28912, %v28825 (stack52)
        %v28920 = vmul.f32 %v28916, %v28868 (stack53)
        %v28924 = vadd.f32 %v28920, %v28821 (stack52)
        %v28928 = vmul.f32 %v28924, %v28868 (stack53)
        %v28932 = vadd.f32 %v28928, %v28817 (stack52)
        %v28936 = vmul.f32 %v28932, %v28783 (stack53)
        %v28940 = vsel /*vm=*/%vm28788, /*on_true_vy=*/%v28793, /*on_false_vx=*/%v28936 (stack43)
        %v28944 = vmul.f32 1.4140625, %v28940 (stack53)
        %v28947 = vpack.c.bf16 0.0, %v28944 (stack74)
        %119897 = vst [vmem:[%s280 + $0x21c] sm:$0xf] /*vst_source=*/%v28947 (stack75)
        %v28951 = vadd.s32 %v26643, %v2842 (stack39)
        %v28961 = vadd.s32 %v28951, %v415 (stack39)
        %vm28965 = vcmp.lt.u32.totalorder %v28961, %v28951 (stack42)
        %vm28970 = vcmp.lt.u32.totalorder %v28951, %v2842 (stack42)
        %v28975 = vadd.s32 %v26626, %v2829 (stack39)
        %v28979 = vadd.s32 1, %v28975 (stack39)
        %v28983 = vsel /*vm=*/%vm28970, /*on_true_vy=*/%v28979, /*on_false_vx=*/%v28975 (stack43)
        %v28987 = vadd.s32 1, %v28983 (stack39)
        %v28991 = vsel /*vm=*/%vm28965, /*on_true_vy=*/%v28987, /*on_false_vx=*/%v28983 (stack43)
        %v28996 = vadd.s32 %v28991, %v10 (stack39)
        %v29000 = vadd.s32 %v28961, %v9 (stack39)
        %v29004 = vadd.s32 %v29000, %v28996 (stack39)
        %v29006 = vshll.u32 %v29000, 13 (stack44)
        %v29007 = vshrl.u32 %v29000, 19 (stack45)
        %v29008 = vor.u32 %v29007, %v29006 (stack46)
        %v29009 = vxor.u32 %v29008, %v29004 (stack47)
        %v29012 = vadd.s32 %v29009, %v29004 (stack39)
        %v29014 = vshll.u32 %v29009, 15 (stack44)
        %v29015 = vshrl.u32 %v29009, 17 (stack45)
        %v29016 = vor.u32 %v29015, %v29014 (stack46)
        %v29017 = vxor.u32 %v29016, %v29012 (stack47)
        %v29020 = vadd.s32 %v29017, %v29012 (stack39)
        %v29022 = vshll.u32 %v29017, 26 (stack44)
        %v29023 = vshrl.u32 %v29017, 6 (stack45)
        %v29024 = vor.u32 %v29023, %v29022 (stack46)
        %v29025 = vxor.u32 %v29024, %v29020 (stack47)
        %v29028 = vadd.s32 %v29025, %v29020 (stack39)
        %v29032 = vadd.s32 %v29028, %v9 (stack39)
        %v29034 = vshll.u32 %v29025, 6 (stack44)
        %v29035 = vshrl.u32 %v29025, 26 (stack45)
        %v29036 = vor.u32 %v29035, %v29034 (stack46)
        %v29037 = vxor.u32 %v29036, %v29028 (stack47)
        %v29040 = vadd.s32 %v29037, %v8 (stack39)
        %v29044 = vadd.s32 1, %v29040 (stack39)
        %v29048 = vadd.s32 %v29044, %v29032 (stack39)
        %v29050 = vshll.u32 %v29044, 17 (stack44)
        %v29051 = vshrl.u32 %v29044, 15 (stack45)
        %v29052 = vor.u32 %v29051, %v29050 (stack46)
        %v29053 = vxor.u32 %v29052, %v29048 (stack47)
        %v29056 = vadd.s32 %v29053, %v29048 (stack39)
        %v29058 = vshll.u32 %v29053, 29 (stack44)
        %v29059 = vshrl.u32 %v29053, 3 (stack45)
        %v29060 = vor.u32 %v29059, %v29058 (stack46)
        %v29061 = vxor.u32 %v29060, %v29056 (stack47)
        %v29064 = vadd.s32 %v29061, %v29056 (stack39)
        %v29066 = vshll.u32 %v29061, 16 (stack44)
        %v29067 = vshrl.u32 %v29061, 16 (stack45)
        %v29068 = vor.u32 %v29067, %v29066 (stack46)
        %v29069 = vxor.u32 %v29068, %v29064 (stack47)
        %v29072 = vadd.s32 %v29069, %v29064 (stack39)
        %v29076 = vadd.s32 %v29072, %v8 (stack39)
        %v29078 = vshll.u32 %v29069, 24 (stack44)
        %v29079 = vshrl.u32 %v29069, 8 (stack45)
        %v29080 = vor.u32 %v29079, %v29078 (stack46)
        %v29081 = vxor.u32 %v29080, %v29072 (stack47)
        %v29084 = vadd.s32 %v29081, %v10 (stack39)
        %v29088 = vadd.s32 2, %v29084 (stack39)
        %v29092 = vadd.s32 %v29088, %v29076 (stack39)
        %v29094 = vshll.u32 %v29088, 13 (stack44)
        %v29095 = vshrl.u32 %v29088, 19 (stack45)
        %v29096 = vor.u32 %v29095, %v29094 (stack46)
        %v29097 = vxor.u32 %v29096, %v29092 (stack47)
        %v29100 = vadd.s32 %v29097, %v29092 (stack39)
        %v29102 = vshll.u32 %v29097, 15 (stack44)
        %v29103 = vshrl.u32 %v29097, 17 (stack45)
        %v29104 = vor.u32 %v29103, %v29102 (stack46)
        %v29105 = vxor.u32 %v29104, %v29100 (stack47)
        %v29108 = vadd.s32 %v29105, %v29100 (stack39)
        %v29110 = vshll.u32 %v29105, 26 (stack44)
        %v29111 = vshrl.u32 %v29105, 6 (stack45)
        %v29112 = vor.u32 %v29111, %v29110 (stack46)
        %v29113 = vxor.u32 %v29112, %v29108 (stack47)
        %v29116 = vadd.s32 %v29113, %v29108 (stack39)
        %v29120 = vadd.s32 %v29116, %v10 (stack39)
        %v29122 = vshll.u32 %v29113, 6 (stack44)
        %v29123 = vshrl.u32 %v29113, 26 (stack45)
        %v29124 = vor.u32 %v29123, %v29122 (stack46)
        %v29125 = vxor.u32 %v29124, %v29116 (stack47)
        %v29128 = vadd.s32 %v29125, %v9 (stack39)
        %v29132 = vadd.s32 3, %v29128 (stack39)
        %v29136 = vadd.s32 %v29132, %v29120 (stack39)
        %v29138 = vshll.u32 %v29132, 17 (stack44)
        %v29139 = vshrl.u32 %v29132, 15 (stack45)
        %v29140 = vor.u32 %v29139, %v29138 (stack46)
        %v29141 = vxor.u32 %v29140, %v29136 (stack47)
        %v29144 = vadd.s32 %v29141, %v29136 (stack39)
        %v29146 = vshll.u32 %v29141, 29 (stack44)
        %v29147 = vshrl.u32 %v29141, 3 (stack45)
        %v29148 = vor.u32 %v29147, %v29146 (stack46)
        %v29149 = vxor.u32 %v29148, %v29144 (stack47)
        %v29152 = vadd.s32 %v29149, %v29144 (stack39)
        %v29154 = vshll.u32 %v29149, 16 (stack44)
        %v29155 = vshrl.u32 %v29149, 16 (stack45)
        %v29156 = vor.u32 %v29155, %v29154 (stack46)
        %v29157 = vxor.u32 %v29156, %v29152 (stack47)
        %v29160 = vadd.s32 %v29157, %v29152 (stack39)
        %v29164 = vadd.s32 %v29160, %v9 (stack39)
        %v29166 = vshll.u32 %v29157, 24 (stack44)
        %v29167 = vshrl.u32 %v29157, 8 (stack45)
        %v29168 = vor.u32 %v29167, %v29166 (stack46)
        %v29169 = vxor.u32 %v29168, %v29160 (stack47)
        %v29172 = vadd.s32 %v29169, %v8 (stack39)
        %v29176 = vadd.s32 4, %v29172 (stack39)
        %v29180 = vadd.s32 %v29176, %v29164 (stack39)
        %v29182 = vshll.u32 %v29176, 13 (stack44)
        %v29183 = vshrl.u32 %v29176, 19 (stack45)
        %v29184 = vor.u32 %v29183, %v29182 (stack46)
        %v29185 = vxor.u32 %v29184, %v29180 (stack47)
        %v29188 = vadd.s32 %v29185, %v29180 (stack39)
        %v29190 = vshll.u32 %v29185, 15 (stack44)
        %v29191 = vshrl.u32 %v29185, 17 (stack45)
        %v29192 = vor.u32 %v29191, %v29190 (stack46)
        %v29193 = vxor.u32 %v29192, %v29188 (stack47)
        %v29196 = vadd.s32 %v29193, %v29188 (stack39)
        %v29198 = vshll.u32 %v29193, 26 (stack44)
        %v29199 = vshrl.u32 %v29193, 6 (stack45)
        %v29200 = vor.u32 %v29199, %v29198 (stack46)
        %v29201 = vxor.u32 %v29200, %v29196 (stack47)
        %v29204 = vadd.s32 %v29201, %v29196 (stack39)
        %v29208 = vadd.s32 %v29204, %v8 (stack39)
        %v29210 = vshll.u32 %v29201, 6 (stack44)
        %v29211 = vshrl.u32 %v29201, 26 (stack45)
        %v29212 = vor.u32 %v29211, %v29210 (stack46)
        %v29213 = vxor.u32 %v29212, %v29204 (stack47)
        %v29216 = vadd.s32 %v29213, %v10 (stack39)
        %v29220 = vadd.s32 5, %v29216 (stack39)
        %v29222 = vxor.u32 %v29220, %v29208 (stack47)
        %v29223 = vand.u32.u8 255, %v29222 (stack48)
        %v29224 = vand.u32 65535, %v29223 (stack49)
        %v29225 = vshrl.u32 %v29224, 1 (stack50)
        %v29226 = vor.u32 16256, %v29225 (stack46)
        %v29227 = vand.u32.u16 65535, %v29226 (stack51)
        %v119898 = vadd.low.f32.bf16 -1.0, %v29227 (stack52)
        %v29236 = vmul.f32 2.0, %v119898 (stack53)
        %v29240 = vadd.f32 -0.99609375, %v29236 (stack52)
        %v29244 = vmax.f32 %v29240, -0.99609375 (stack54)
        %v29246 = vand.u32 2147483647, %v29244 (stack55)
        %vm29249 = vcmp.eq.f32.partialorder %v29246, 1.0 (stack56)
        %v29254 = vmul.f32 inf, %v29244 (stack53)
        %v29256 = vxor.u32 2147483648, %v29244 (stack57)
        %v29259 = vmul.f32 %v29256, %v29244 (stack53)
        %v29261 = vadd.f32 1.0, %v29259 (stack58)
        %v29262 = vlog2.pop %v29261 (stack59)
        %v29263 = vmul.f32 0.6931472, %v29262 (stack60)
        %v29264 = vmul.f32 -0.5, %v29259 (stack61)
        %v29265 = vadd.f32 1.0, %v29264 (stack62)
        %v29266 = vmul.f32 %v29265, %v29259 (stack63)
        %v29267 = vand.u32 2147483647, %v29259 (stack64)
        %vm29268 = vcmp.lt.f32.partialorder %v29267, 0.0004427343 (stack65)
        %v29269 = vsel /*vm=*/%vm29268, /*on_true_vy=*/%v29266, /*on_false_vx=*/%v29263 (stack66)
        %v29270 = vxor.u32 2147483648, %v29269 (stack57)
        %vm29273 = vcmp.lt.f32.partialorder %v29270, 5.0 (stack56)
        %v29278 = vsel /*vm=*/%vm29273, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v29282 = vsel /*vm=*/%vm29273, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v29286 = vsel /*vm=*/%vm29273, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v29290 = vsel /*vm=*/%vm29273, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v29294 = vsel /*vm=*/%vm29273, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v29298 = vsel /*vm=*/%vm29273, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v29302 = vsel /*vm=*/%vm29273, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v29306 = vsel /*vm=*/%vm29273, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v29310 = vsel /*vm=*/%vm29273, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v29314 = vadd.f32 -2.5, %v29270 (stack52)
        %v29316 = vrsqrt.pop %v29270 (stack67)
        %v29317 = vmul.f32 %v29316, %v29270 (stack68)
        %vm29318 = vcmp.eq.f32.partialorder %v29270, inf (stack69)
        %v29319 = vsel /*vm=*/%vm29318, /*on_true_vy=*/%v29270, /*on_false_vx=*/%v29317 (stack70)
        %vm29320 = vcmp.eq.f32.partialorder %v29270, 0.0 (stack71)
        %v29321 = vand.u32 2147483648, %v29270 (stack72)
        %v29322 = vsel /*vm=*/%vm29320, /*on_true_vy=*/%v29321, /*on_false_vx=*/%v29319 (stack73)
        %v29325 = vadd.f32 -3.0, %v29322 (stack52)
        %v29329 = vsel /*vm=*/%vm29273, /*on_true_vy=*/%v29314, /*on_false_vx=*/%v29325 (stack43)
        %v29333 = vmul.f32 %v29329, %v29310 (stack53)
        %v29337 = vadd.f32 %v29333, %v29306 (stack52)
        %v29341 = vmul.f32 %v29337, %v29329 (stack53)
        %v29345 = vadd.f32 %v29341, %v29302 (stack52)
        %v29349 = vmul.f32 %v29345, %v29329 (stack53)
        %v29353 = vadd.f32 %v29349, %v29298 (stack52)
        %v29357 = vmul.f32 %v29353, %v29329 (stack53)
        %v29361 = vadd.f32 %v29357, %v29294 (stack52)
        %v29365 = vmul.f32 %v29361, %v29329 (stack53)
        %v29369 = vadd.f32 %v29365, %v29290 (stack52)
        %v29373 = vmul.f32 %v29369, %v29329 (stack53)
        %v29377 = vadd.f32 %v29373, %v29286 (stack52)
        %v29381 = vmul.f32 %v29377, %v29329 (stack53)
        %v29385 = vadd.f32 %v29381, %v29282 (stack52)
        %v29389 = vmul.f32 %v29385, %v29329 (stack53)
        %v29393 = vadd.f32 %v29389, %v29278 (stack52)
        %v29397 = vmul.f32 %v29393, %v29244 (stack53)
        %v29401 = vsel /*vm=*/%vm29249, /*on_true_vy=*/%v29254, /*on_false_vx=*/%v29397 (stack43)
        %v29405 = vmul.f32 1.4140625, %v29401 (stack53)
        %v29408 = vpack.c.bf16 0.0, %v29405 (stack74)
        %119899 = vst [vmem:[%s280 + $0x29c] sm:$0xf] /*vst_source=*/%v29408 (stack75)
        %v29412 = vadd.s32 %v26643, %v3329 (stack39)
        %v29422 = vadd.s32 %v29412, %v415 (stack39)
        %vm29426 = vcmp.lt.u32.totalorder %v29422, %v29412 (stack42)
        %vm29431 = vcmp.lt.u32.totalorder %v29412, %v3329 (stack42)
        %v29436 = vadd.s32 %v26626, %v3316 (stack39)
        %v29440 = vadd.s32 1, %v29436 (stack39)
        %v29444 = vsel /*vm=*/%vm29431, /*on_true_vy=*/%v29440, /*on_false_vx=*/%v29436 (stack43)
        %v29448 = vadd.s32 1, %v29444 (stack39)
        %v29452 = vsel /*vm=*/%vm29426, /*on_true_vy=*/%v29448, /*on_false_vx=*/%v29444 (stack43)
        %v29457 = vadd.s32 %v29452, %v10 (stack39)
        %v29461 = vadd.s32 %v29422, %v9 (stack39)
        %v29465 = vadd.s32 %v29461, %v29457 (stack39)
        %v29467 = vshll.u32 %v29461, 13 (stack44)
        %v29468 = vshrl.u32 %v29461, 19 (stack45)
        %v29469 = vor.u32 %v29468, %v29467 (stack46)
        %v29470 = vxor.u32 %v29469, %v29465 (stack47)
        %v29473 = vadd.s32 %v29470, %v29465 (stack39)
        %v29475 = vshll.u32 %v29470, 15 (stack44)
        %v29476 = vshrl.u32 %v29470, 17 (stack45)
        %v29477 = vor.u32 %v29476, %v29475 (stack46)
        %v29478 = vxor.u32 %v29477, %v29473 (stack47)
        %v29481 = vadd.s32 %v29478, %v29473 (stack39)
        %v29483 = vshll.u32 %v29478, 26 (stack44)
        %v29484 = vshrl.u32 %v29478, 6 (stack45)
        %v29485 = vor.u32 %v29484, %v29483 (stack46)
        %v29486 = vxor.u32 %v29485, %v29481 (stack47)
        %v29489 = vadd.s32 %v29486, %v29481 (stack39)
        %v29493 = vadd.s32 %v29489, %v9 (stack39)
        %v29495 = vshll.u32 %v29486, 6 (stack44)
        %v29496 = vshrl.u32 %v29486, 26 (stack45)
        %v29497 = vor.u32 %v29496, %v29495 (stack46)
        %v29498 = vxor.u32 %v29497, %v29489 (stack47)
        %v29501 = vadd.s32 %v29498, %v8 (stack39)
        %v29505 = vadd.s32 1, %v29501 (stack39)
        %v29509 = vadd.s32 %v29505, %v29493 (stack39)
        %v29511 = vshll.u32 %v29505, 17 (stack44)
        %v29512 = vshrl.u32 %v29505, 15 (stack45)
        %v29513 = vor.u32 %v29512, %v29511 (stack46)
        %v29514 = vxor.u32 %v29513, %v29509 (stack47)
        %v29517 = vadd.s32 %v29514, %v29509 (stack39)
        %v29519 = vshll.u32 %v29514, 29 (stack44)
        %v29520 = vshrl.u32 %v29514, 3 (stack45)
        %v29521 = vor.u32 %v29520, %v29519 (stack46)
        %v29522 = vxor.u32 %v29521, %v29517 (stack47)
        %v29525 = vadd.s32 %v29522, %v29517 (stack39)
        %v29527 = vshll.u32 %v29522, 16 (stack44)
        %v29528 = vshrl.u32 %v29522, 16 (stack45)
        %v29529 = vor.u32 %v29528, %v29527 (stack46)
        %v29530 = vxor.u32 %v29529, %v29525 (stack47)
        %v29533 = vadd.s32 %v29530, %v29525 (stack39)
        %v29537 = vadd.s32 %v29533, %v8 (stack39)
        %v29539 = vshll.u32 %v29530, 24 (stack44)
        %v29540 = vshrl.u32 %v29530, 8 (stack45)
        %v29541 = vor.u32 %v29540, %v29539 (stack46)
        %v29542 = vxor.u32 %v29541, %v29533 (stack47)
        %v29545 = vadd.s32 %v29542, %v10 (stack39)
        %v29549 = vadd.s32 2, %v29545 (stack39)
        %v29553 = vadd.s32 %v29549, %v29537 (stack39)
        %v29555 = vshll.u32 %v29549, 13 (stack44)
        %v29556 = vshrl.u32 %v29549, 19 (stack45)
        %v29557 = vor.u32 %v29556, %v29555 (stack46)
        %v29558 = vxor.u32 %v29557, %v29553 (stack47)
        %v29561 = vadd.s32 %v29558, %v29553 (stack39)
        %v29563 = vshll.u32 %v29558, 15 (stack44)
        %v29564 = vshrl.u32 %v29558, 17 (stack45)
        %v29565 = vor.u32 %v29564, %v29563 (stack46)
        %v29566 = vxor.u32 %v29565, %v29561 (stack47)
        %v29569 = vadd.s32 %v29566, %v29561 (stack39)
        %v29571 = vshll.u32 %v29566, 26 (stack44)
        %v29572 = vshrl.u32 %v29566, 6 (stack45)
        %v29573 = vor.u32 %v29572, %v29571 (stack46)
        %v29574 = vxor.u32 %v29573, %v29569 (stack47)
        %v29577 = vadd.s32 %v29574, %v29569 (stack39)
        %v29581 = vadd.s32 %v29577, %v10 (stack39)
        %v29583 = vshll.u32 %v29574, 6 (stack44)
        %v29584 = vshrl.u32 %v29574, 26 (stack45)
        %v29585 = vor.u32 %v29584, %v29583 (stack46)
        %v29586 = vxor.u32 %v29585, %v29577 (stack47)
        %v29589 = vadd.s32 %v29586, %v9 (stack39)
        %v29593 = vadd.s32 3, %v29589 (stack39)
        %v29597 = vadd.s32 %v29593, %v29581 (stack39)
        %v29599 = vshll.u32 %v29593, 17 (stack44)
        %v29600 = vshrl.u32 %v29593, 15 (stack45)
        %v29601 = vor.u32 %v29600, %v29599 (stack46)
        %v29602 = vxor.u32 %v29601, %v29597 (stack47)
        %v29605 = vadd.s32 %v29602, %v29597 (stack39)
        %v29607 = vshll.u32 %v29602, 29 (stack44)
        %v29608 = vshrl.u32 %v29602, 3 (stack45)
        %v29609 = vor.u32 %v29608, %v29607 (stack46)
        %v29610 = vxor.u32 %v29609, %v29605 (stack47)
        %v29613 = vadd.s32 %v29610, %v29605 (stack39)
        %v29615 = vshll.u32 %v29610, 16 (stack44)
        %v29616 = vshrl.u32 %v29610, 16 (stack45)
        %v29617 = vor.u32 %v29616, %v29615 (stack46)
        %v29618 = vxor.u32 %v29617, %v29613 (stack47)
        %v29621 = vadd.s32 %v29618, %v29613 (stack39)
        %v29625 = vadd.s32 %v29621, %v9 (stack39)
        %v29627 = vshll.u32 %v29618, 24 (stack44)
        %v29628 = vshrl.u32 %v29618, 8 (stack45)
        %v29629 = vor.u32 %v29628, %v29627 (stack46)
        %v29630 = vxor.u32 %v29629, %v29621 (stack47)
        %v29633 = vadd.s32 %v29630, %v8 (stack39)
        %v29637 = vadd.s32 4, %v29633 (stack39)
        %v29641 = vadd.s32 %v29637, %v29625 (stack39)
        %v29643 = vshll.u32 %v29637, 13 (stack44)
        %v29644 = vshrl.u32 %v29637, 19 (stack45)
        %v29645 = vor.u32 %v29644, %v29643 (stack46)
        %v29646 = vxor.u32 %v29645, %v29641 (stack47)
        %v29649 = vadd.s32 %v29646, %v29641 (stack39)
        %v29651 = vshll.u32 %v29646, 15 (stack44)
        %v29652 = vshrl.u32 %v29646, 17 (stack45)
        %v29653 = vor.u32 %v29652, %v29651 (stack46)
        %v29654 = vxor.u32 %v29653, %v29649 (stack47)
        %v29657 = vadd.s32 %v29654, %v29649 (stack39)
        %v29659 = vshll.u32 %v29654, 26 (stack44)
        %v29660 = vshrl.u32 %v29654, 6 (stack45)
        %v29661 = vor.u32 %v29660, %v29659 (stack46)
        %v29662 = vxor.u32 %v29661, %v29657 (stack47)
        %v29665 = vadd.s32 %v29662, %v29657 (stack39)
        %v29669 = vadd.s32 %v29665, %v8 (stack39)
        %v29671 = vshll.u32 %v29662, 6 (stack44)
        %v29672 = vshrl.u32 %v29662, 26 (stack45)
        %v29673 = vor.u32 %v29672, %v29671 (stack46)
        %v29674 = vxor.u32 %v29673, %v29665 (stack47)
        %v29677 = vadd.s32 %v29674, %v10 (stack39)
        %v29681 = vadd.s32 5, %v29677 (stack39)
        %v29683 = vxor.u32 %v29681, %v29669 (stack47)
        %v29684 = vand.u32.u8 255, %v29683 (stack48)
        %v29685 = vand.u32 65535, %v29684 (stack49)
        %v29686 = vshrl.u32 %v29685, 1 (stack50)
        %v29687 = vor.u32 16256, %v29686 (stack46)
        %v29688 = vand.u32.u16 65535, %v29687 (stack51)
        %v119900 = vadd.low.f32.bf16 -1.0, %v29688 (stack52)
        %v29697 = vmul.f32 2.0, %v119900 (stack53)
        %v29701 = vadd.f32 -0.99609375, %v29697 (stack52)
        %v29705 = vmax.f32 %v29701, -0.99609375 (stack54)
        %v29707 = vand.u32 2147483647, %v29705 (stack55)
        %vm29710 = vcmp.eq.f32.partialorder %v29707, 1.0 (stack56)
        %v29715 = vmul.f32 inf, %v29705 (stack53)
        %v29717 = vxor.u32 2147483648, %v29705 (stack57)
        %v29720 = vmul.f32 %v29717, %v29705 (stack53)
        %v29722 = vadd.f32 1.0, %v29720 (stack58)
        %v29723 = vlog2.pop %v29722 (stack59)
        %v29724 = vmul.f32 0.6931472, %v29723 (stack60)
        %v29725 = vmul.f32 -0.5, %v29720 (stack61)
        %v29726 = vadd.f32 1.0, %v29725 (stack62)
        %v29727 = vmul.f32 %v29726, %v29720 (stack63)
        %v29728 = vand.u32 2147483647, %v29720 (stack64)
        %vm29729 = vcmp.lt.f32.partialorder %v29728, 0.0004427343 (stack65)
        %v29730 = vsel /*vm=*/%vm29729, /*on_true_vy=*/%v29727, /*on_false_vx=*/%v29724 (stack66)
        %v29731 = vxor.u32 2147483648, %v29730 (stack57)
        %vm29734 = vcmp.lt.f32.partialorder %v29731, 5.0 (stack56)
        %v29739 = vsel /*vm=*/%vm29734, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v29743 = vsel /*vm=*/%vm29734, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v29747 = vsel /*vm=*/%vm29734, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v29751 = vsel /*vm=*/%vm29734, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v29755 = vsel /*vm=*/%vm29734, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v29759 = vsel /*vm=*/%vm29734, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v29763 = vsel /*vm=*/%vm29734, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v29767 = vsel /*vm=*/%vm29734, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v29771 = vsel /*vm=*/%vm29734, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v29775 = vadd.f32 -2.5, %v29731 (stack52)
        %v29777 = vrsqrt.pop %v29731 (stack67)
        %v29778 = vmul.f32 %v29777, %v29731 (stack68)
        %vm29779 = vcmp.eq.f32.partialorder %v29731, inf (stack69)
        %v29780 = vsel /*vm=*/%vm29779, /*on_true_vy=*/%v29731, /*on_false_vx=*/%v29778 (stack70)
        %vm29781 = vcmp.eq.f32.partialorder %v29731, 0.0 (stack71)
        %v29782 = vand.u32 2147483648, %v29731 (stack72)
        %v29783 = vsel /*vm=*/%vm29781, /*on_true_vy=*/%v29782, /*on_false_vx=*/%v29780 (stack73)
        %v29786 = vadd.f32 -3.0, %v29783 (stack52)
        %v29790 = vsel /*vm=*/%vm29734, /*on_true_vy=*/%v29775, /*on_false_vx=*/%v29786 (stack43)
        %v29794 = vmul.f32 %v29790, %v29771 (stack53)
        %v29798 = vadd.f32 %v29794, %v29767 (stack52)
        %v29802 = vmul.f32 %v29798, %v29790 (stack53)
        %v29806 = vadd.f32 %v29802, %v29763 (stack52)
        %v29810 = vmul.f32 %v29806, %v29790 (stack53)
        %v29814 = vadd.f32 %v29810, %v29759 (stack52)
        %v29818 = vmul.f32 %v29814, %v29790 (stack53)
        %v29822 = vadd.f32 %v29818, %v29755 (stack52)
        %v29826 = vmul.f32 %v29822, %v29790 (stack53)
        %v29830 = vadd.f32 %v29826, %v29751 (stack52)
        %v29834 = vmul.f32 %v29830, %v29790 (stack53)
        %v29838 = vadd.f32 %v29834, %v29747 (stack52)
        %v29842 = vmul.f32 %v29838, %v29790 (stack53)
        %v29846 = vadd.f32 %v29842, %v29743 (stack52)
        %v29850 = vmul.f32 %v29846, %v29790 (stack53)
        %v29854 = vadd.f32 %v29850, %v29739 (stack52)
        %v29858 = vmul.f32 %v29854, %v29705 (stack53)
        %v29862 = vsel /*vm=*/%vm29710, /*on_true_vy=*/%v29715, /*on_false_vx=*/%v29858 (stack43)
        %v29866 = vmul.f32 1.4140625, %v29862 (stack53)
        %v29869 = vpack.c.bf16 0.0, %v29866 (stack74)
        %119901 = vst [vmem:[%s280 + $0x31c] sm:$0xf] /*vst_source=*/%v29869 (stack75)
        %v29873 = vadd.s32 %v26643, %v3816 (stack39)
        %v29883 = vadd.s32 %v29873, %v415 (stack39)
        %vm29887 = vcmp.lt.u32.totalorder %v29883, %v29873 (stack42)
        %vm29892 = vcmp.lt.u32.totalorder %v29873, %v3816 (stack42)
        %v29897 = vadd.s32 %v26626, %v3803 (stack39)
        %v29901 = vadd.s32 1, %v29897 (stack39)
        %v29905 = vsel /*vm=*/%vm29892, /*on_true_vy=*/%v29901, /*on_false_vx=*/%v29897 (stack43)
        %v29909 = vadd.s32 1, %v29905 (stack39)
        %v29913 = vsel /*vm=*/%vm29887, /*on_true_vy=*/%v29909, /*on_false_vx=*/%v29905 (stack43)
        %v29918 = vadd.s32 %v29913, %v10 (stack39)
        %v29922 = vadd.s32 %v29883, %v9 (stack39)
        %v29926 = vadd.s32 %v29922, %v29918 (stack39)
        %v29928 = vshll.u32 %v29922, 13 (stack44)
        %v29929 = vshrl.u32 %v29922, 19 (stack45)
        %v29930 = vor.u32 %v29929, %v29928 (stack46)
        %v29931 = vxor.u32 %v29930, %v29926 (stack47)
        %v29934 = vadd.s32 %v29931, %v29926 (stack39)
        %v29936 = vshll.u32 %v29931, 15 (stack44)
        %v29937 = vshrl.u32 %v29931, 17 (stack45)
        %v29938 = vor.u32 %v29937, %v29936 (stack46)
        %v29939 = vxor.u32 %v29938, %v29934 (stack47)
        %v29942 = vadd.s32 %v29939, %v29934 (stack39)
        %v29944 = vshll.u32 %v29939, 26 (stack44)
        %v29945 = vshrl.u32 %v29939, 6 (stack45)
        %v29946 = vor.u32 %v29945, %v29944 (stack46)
        %v29947 = vxor.u32 %v29946, %v29942 (stack47)
        %v29950 = vadd.s32 %v29947, %v29942 (stack39)
        %v29954 = vadd.s32 %v29950, %v9 (stack39)
        %v29956 = vshll.u32 %v29947, 6 (stack44)
        %v29957 = vshrl.u32 %v29947, 26 (stack45)
        %v29958 = vor.u32 %v29957, %v29956 (stack46)
        %v29959 = vxor.u32 %v29958, %v29950 (stack47)
        %v29962 = vadd.s32 %v29959, %v8 (stack39)
        %v29966 = vadd.s32 1, %v29962 (stack39)
        %v29970 = vadd.s32 %v29966, %v29954 (stack39)
        %v29972 = vshll.u32 %v29966, 17 (stack44)
        %v29973 = vshrl.u32 %v29966, 15 (stack45)
        %v29974 = vor.u32 %v29973, %v29972 (stack46)
        %v29975 = vxor.u32 %v29974, %v29970 (stack47)
        %v29978 = vadd.s32 %v29975, %v29970 (stack39)
        %v29980 = vshll.u32 %v29975, 29 (stack44)
        %v29981 = vshrl.u32 %v29975, 3 (stack45)
        %v29982 = vor.u32 %v29981, %v29980 (stack46)
        %v29983 = vxor.u32 %v29982, %v29978 (stack47)
        %v29986 = vadd.s32 %v29983, %v29978 (stack39)
        %v29988 = vshll.u32 %v29983, 16 (stack44)
        %v29989 = vshrl.u32 %v29983, 16 (stack45)
        %v29990 = vor.u32 %v29989, %v29988 (stack46)
        %v29991 = vxor.u32 %v29990, %v29986 (stack47)
        %v29994 = vadd.s32 %v29991, %v29986 (stack39)
        %v29998 = vadd.s32 %v29994, %v8 (stack39)
        %v30000 = vshll.u32 %v29991, 24 (stack44)
        %v30001 = vshrl.u32 %v29991, 8 (stack45)
        %v30002 = vor.u32 %v30001, %v30000 (stack46)
        %v30003 = vxor.u32 %v30002, %v29994 (stack47)
        %v30006 = vadd.s32 %v30003, %v10 (stack39)
        %v30010 = vadd.s32 2, %v30006 (stack39)
        %v30014 = vadd.s32 %v30010, %v29998 (stack39)
        %v30016 = vshll.u32 %v30010, 13 (stack44)
        %v30017 = vshrl.u32 %v30010, 19 (stack45)
        %v30018 = vor.u32 %v30017, %v30016 (stack46)
        %v30019 = vxor.u32 %v30018, %v30014 (stack47)
        %v30022 = vadd.s32 %v30019, %v30014 (stack39)
        %v30024 = vshll.u32 %v30019, 15 (stack44)
        %v30025 = vshrl.u32 %v30019, 17 (stack45)
        %v30026 = vor.u32 %v30025, %v30024 (stack46)
        %v30027 = vxor.u32 %v30026, %v30022 (stack47)
        %v30030 = vadd.s32 %v30027, %v30022 (stack39)
        %v30032 = vshll.u32 %v30027, 26 (stack44)
        %v30033 = vshrl.u32 %v30027, 6 (stack45)
        %v30034 = vor.u32 %v30033, %v30032 (stack46)
        %v30035 = vxor.u32 %v30034, %v30030 (stack47)
        %v30038 = vadd.s32 %v30035, %v30030 (stack39)
        %v30042 = vadd.s32 %v30038, %v10 (stack39)
        %v30044 = vshll.u32 %v30035, 6 (stack44)
        %v30045 = vshrl.u32 %v30035, 26 (stack45)
        %v30046 = vor.u32 %v30045, %v30044 (stack46)
        %v30047 = vxor.u32 %v30046, %v30038 (stack47)
        %v30050 = vadd.s32 %v30047, %v9 (stack39)
        %v30054 = vadd.s32 3, %v30050 (stack39)
        %v30058 = vadd.s32 %v30054, %v30042 (stack39)
        %v30060 = vshll.u32 %v30054, 17 (stack44)
        %v30061 = vshrl.u32 %v30054, 15 (stack45)
        %v30062 = vor.u32 %v30061, %v30060 (stack46)
        %v30063 = vxor.u32 %v30062, %v30058 (stack47)
        %v30066 = vadd.s32 %v30063, %v30058 (stack39)
        %v30068 = vshll.u32 %v30063, 29 (stack44)
        %v30069 = vshrl.u32 %v30063, 3 (stack45)
        %v30070 = vor.u32 %v30069, %v30068 (stack46)
        %v30071 = vxor.u32 %v30070, %v30066 (stack47)
        %v30074 = vadd.s32 %v30071, %v30066 (stack39)
        %v30076 = vshll.u32 %v30071, 16 (stack44)
        %v30077 = vshrl.u32 %v30071, 16 (stack45)
        %v30078 = vor.u32 %v30077, %v30076 (stack46)
        %v30079 = vxor.u32 %v30078, %v30074 (stack47)
        %v30082 = vadd.s32 %v30079, %v30074 (stack39)
        %v30086 = vadd.s32 %v30082, %v9 (stack39)
        %v30088 = vshll.u32 %v30079, 24 (stack44)
        %v30089 = vshrl.u32 %v30079, 8 (stack45)
        %v30090 = vor.u32 %v30089, %v30088 (stack46)
        %v30091 = vxor.u32 %v30090, %v30082 (stack47)
        %v30094 = vadd.s32 %v30091, %v8 (stack39)
        %v30098 = vadd.s32 4, %v30094 (stack39)
        %v30102 = vadd.s32 %v30098, %v30086 (stack39)
        %v30104 = vshll.u32 %v30098, 13 (stack44)
        %v30105 = vshrl.u32 %v30098, 19 (stack45)
        %v30106 = vor.u32 %v30105, %v30104 (stack46)
        %v30107 = vxor.u32 %v30106, %v30102 (stack47)
        %v30110 = vadd.s32 %v30107, %v30102 (stack39)
        %v30112 = vshll.u32 %v30107, 15 (stack44)
        %v30113 = vshrl.u32 %v30107, 17 (stack45)
        %v30114 = vor.u32 %v30113, %v30112 (stack46)
        %v30115 = vxor.u32 %v30114, %v30110 (stack47)
        %v30118 = vadd.s32 %v30115, %v30110 (stack39)
        %v30120 = vshll.u32 %v30115, 26 (stack44)
        %v30121 = vshrl.u32 %v30115, 6 (stack45)
        %v30122 = vor.u32 %v30121, %v30120 (stack46)
        %v30123 = vxor.u32 %v30122, %v30118 (stack47)
        %v30126 = vadd.s32 %v30123, %v30118 (stack39)
        %v30130 = vadd.s32 %v30126, %v8 (stack39)
        %v30132 = vshll.u32 %v30123, 6 (stack44)
        %v30133 = vshrl.u32 %v30123, 26 (stack45)
        %v30134 = vor.u32 %v30133, %v30132 (stack46)
        %v30135 = vxor.u32 %v30134, %v30126 (stack47)
        %v30138 = vadd.s32 %v30135, %v10 (stack39)
        %v30142 = vadd.s32 5, %v30138 (stack39)
        %v30144 = vxor.u32 %v30142, %v30130 (stack47)
        %v30145 = vand.u32.u8 255, %v30144 (stack48)
        %v30146 = vand.u32 65535, %v30145 (stack49)
        %v30147 = vshrl.u32 %v30146, 1 (stack50)
        %v30148 = vor.u32 16256, %v30147 (stack46)
        %v30149 = vand.u32.u16 65535, %v30148 (stack51)
        %v119902 = vadd.low.f32.bf16 -1.0, %v30149 (stack52)
        %v30158 = vmul.f32 2.0, %v119902 (stack53)
        %v30162 = vadd.f32 -0.99609375, %v30158 (stack52)
        %v30166 = vmax.f32 %v30162, -0.99609375 (stack54)
        %v30168 = vand.u32 2147483647, %v30166 (stack55)
        %vm30171 = vcmp.eq.f32.partialorder %v30168, 1.0 (stack56)
        %v30176 = vmul.f32 inf, %v30166 (stack53)
        %v30178 = vxor.u32 2147483648, %v30166 (stack57)
        %v30181 = vmul.f32 %v30178, %v30166 (stack53)
        %v30183 = vadd.f32 1.0, %v30181 (stack58)
        %v30184 = vlog2.pop %v30183 (stack59)
        %v30185 = vmul.f32 0.6931472, %v30184 (stack60)
        %v30186 = vmul.f32 -0.5, %v30181 (stack61)
        %v30187 = vadd.f32 1.0, %v30186 (stack62)
        %v30188 = vmul.f32 %v30187, %v30181 (stack63)
        %v30189 = vand.u32 2147483647, %v30181 (stack64)
        %vm30190 = vcmp.lt.f32.partialorder %v30189, 0.0004427343 (stack65)
        %v30191 = vsel /*vm=*/%vm30190, /*on_true_vy=*/%v30188, /*on_false_vx=*/%v30185 (stack66)
        %v30192 = vxor.u32 2147483648, %v30191 (stack57)
        %vm30195 = vcmp.lt.f32.partialorder %v30192, 5.0 (stack56)
        %v30200 = vsel /*vm=*/%vm30195, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v30204 = vsel /*vm=*/%vm30195, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v30208 = vsel /*vm=*/%vm30195, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v30212 = vsel /*vm=*/%vm30195, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v30216 = vsel /*vm=*/%vm30195, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v30220 = vsel /*vm=*/%vm30195, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v30224 = vsel /*vm=*/%vm30195, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v30228 = vsel /*vm=*/%vm30195, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v30232 = vsel /*vm=*/%vm30195, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v30236 = vadd.f32 -2.5, %v30192 (stack52)
        %v30238 = vrsqrt.pop %v30192 (stack67)
        %v30239 = vmul.f32 %v30238, %v30192 (stack68)
        %vm30240 = vcmp.eq.f32.partialorder %v30192, inf (stack69)
        %v30241 = vsel /*vm=*/%vm30240, /*on_true_vy=*/%v30192, /*on_false_vx=*/%v30239 (stack70)
        %vm30242 = vcmp.eq.f32.partialorder %v30192, 0.0 (stack71)
        %v30243 = vand.u32 2147483648, %v30192 (stack72)
        %v30244 = vsel /*vm=*/%vm30242, /*on_true_vy=*/%v30243, /*on_false_vx=*/%v30241 (stack73)
        %v30247 = vadd.f32 -3.0, %v30244 (stack52)
        %v30251 = vsel /*vm=*/%vm30195, /*on_true_vy=*/%v30236, /*on_false_vx=*/%v30247 (stack43)
        %v30255 = vmul.f32 %v30251, %v30232 (stack53)
        %v30259 = vadd.f32 %v30255, %v30228 (stack52)
        %v30263 = vmul.f32 %v30259, %v30251 (stack53)
        %v30267 = vadd.f32 %v30263, %v30224 (stack52)
        %v30271 = vmul.f32 %v30267, %v30251 (stack53)
        %v30275 = vadd.f32 %v30271, %v30220 (stack52)
        %v30279 = vmul.f32 %v30275, %v30251 (stack53)
        %v30283 = vadd.f32 %v30279, %v30216 (stack52)
        %v30287 = vmul.f32 %v30283, %v30251 (stack53)
        %v30291 = vadd.f32 %v30287, %v30212 (stack52)
        %v30295 = vmul.f32 %v30291, %v30251 (stack53)
        %v30299 = vadd.f32 %v30295, %v30208 (stack52)
        %v30303 = vmul.f32 %v30299, %v30251 (stack53)
        %v30307 = vadd.f32 %v30303, %v30204 (stack52)
        %v30311 = vmul.f32 %v30307, %v30251 (stack53)
        %v30315 = vadd.f32 %v30311, %v30200 (stack52)
        %v30319 = vmul.f32 %v30315, %v30166 (stack53)
        %v30323 = vsel /*vm=*/%vm30171, /*on_true_vy=*/%v30176, /*on_false_vx=*/%v30319 (stack43)
        %v30327 = vmul.f32 1.4140625, %v30323 (stack53)
        %v30330 = vpack.c.bf16 0.0, %v30327 (stack74)
        %119903 = vst [vmem:[%s280 + $0x39c] sm:$0xf] /*vst_source=*/%v30330 (stack75)
        %s30332 = sadd.s32 64, %s120390 (stack76)
        %s30333 = sshrl.u32 %s30332, 10 (stack23)
        %p119904 = scmp.gt.s32.totalorder %s30333, 1 (stack24)
        %s30335 = scalar_select /*predicate=*/%p119904, /*on_true=*/1, /*on_false=*/%s30333 (stack25)
        %s30336 = sand.u32 1023, %s30332 /* smod.u32 w/div 1024 */ (stack26)
        %s30337 = sshrl.u32 %s30336, 7 (stack27)
        %s30338 = sand.u32 127, %s30336 /* smod.u32 w/div 128 */ (stack28)
        %s119905 = sshll.u32 %s30335, 3 (stack29)
        %s30340 = scalar_lea.vmem %s3, %s119905 (stack30)
        %s30342 = scalar_lea.vmem %s30340, %s30337 (stack31)
        %v30343 = vld [vmem:[%s30342] ss:$0 sm:$0xff] (stack32)
        %s30344 = sand.u32 255, %s30338 (stack33)
        %s30346 = sor.u32 256, %s30344 (stack34)
        %30347 = vbcast.lane.b32.xlu0 %v30343, %s30346 (stack35)
        %v30348 = vpop.permute.xlu0 %30347 (stack36)
        %s30357 = scalar_lea.vmem %s5, %s119905 (stack30)
        %s30359 = scalar_lea.vmem %s30357, %s30337 (stack31)
        %v30360 = vld [vmem:[%s30359] ss:$0 sm:$0xff] (stack32)
        %30364 = vbcast.lane.b32.xlu0 %v30360, %s30346 (stack35)
        %v30365 = vpop.permute.xlu0 %30364 (stack36)
        %v30368 = vadd.s32 %v30365, %v408 (stack39)
        %v30378 = vadd.s32 %v30368, %v415 (stack39)
        %vm30382 = vcmp.lt.u32.totalorder %v30378, %v30368 (stack42)
        %vm30387 = vcmp.lt.u32.totalorder %v30368, %v408 (stack42)
        %v30392 = vadd.s32 %v30348, %v380 (stack39)
        %v30396 = vadd.s32 1, %v30392 (stack39)
        %v30400 = vsel /*vm=*/%vm30387, /*on_true_vy=*/%v30396, /*on_false_vx=*/%v30392 (stack43)
        %v30404 = vadd.s32 1, %v30400 (stack39)
        %v30408 = vsel /*vm=*/%vm30382, /*on_true_vy=*/%v30404, /*on_false_vx=*/%v30400 (stack43)
        %v30413 = vadd.s32 %v30408, %v10 (stack39)
        %v30417 = vadd.s32 %v30378, %v9 (stack39)
        %v30421 = vadd.s32 %v30417, %v30413 (stack39)
        %v30423 = vshll.u32 %v30417, 13 (stack44)
        %v30424 = vshrl.u32 %v30417, 19 (stack45)
        %v30425 = vor.u32 %v30424, %v30423 (stack46)
        %v30426 = vxor.u32 %v30425, %v30421 (stack47)
        %v30429 = vadd.s32 %v30426, %v30421 (stack39)
        %v30431 = vshll.u32 %v30426, 15 (stack44)
        %v30432 = vshrl.u32 %v30426, 17 (stack45)
        %v30433 = vor.u32 %v30432, %v30431 (stack46)
        %v30434 = vxor.u32 %v30433, %v30429 (stack47)
        %v30437 = vadd.s32 %v30434, %v30429 (stack39)
        %v30439 = vshll.u32 %v30434, 26 (stack44)
        %v30440 = vshrl.u32 %v30434, 6 (stack45)
        %v30441 = vor.u32 %v30440, %v30439 (stack46)
        %v30442 = vxor.u32 %v30441, %v30437 (stack47)
        %v30445 = vadd.s32 %v30442, %v30437 (stack39)
        %v30449 = vadd.s32 %v30445, %v9 (stack39)
        %v30451 = vshll.u32 %v30442, 6 (stack44)
        %v30452 = vshrl.u32 %v30442, 26 (stack45)
        %v30453 = vor.u32 %v30452, %v30451 (stack46)
        %v30454 = vxor.u32 %v30453, %v30445 (stack47)
        %v30457 = vadd.s32 %v30454, %v8 (stack39)
        %v30461 = vadd.s32 1, %v30457 (stack39)
        %v30465 = vadd.s32 %v30461, %v30449 (stack39)
        %v30467 = vshll.u32 %v30461, 17 (stack44)
        %v30468 = vshrl.u32 %v30461, 15 (stack45)
        %v30469 = vor.u32 %v30468, %v30467 (stack46)
        %v30470 = vxor.u32 %v30469, %v30465 (stack47)
        %v30473 = vadd.s32 %v30470, %v30465 (stack39)
        %v30475 = vshll.u32 %v30470, 29 (stack44)
        %v30476 = vshrl.u32 %v30470, 3 (stack45)
        %v30477 = vor.u32 %v30476, %v30475 (stack46)
        %v30478 = vxor.u32 %v30477, %v30473 (stack47)
        %v30481 = vadd.s32 %v30478, %v30473 (stack39)
        %v30483 = vshll.u32 %v30478, 16 (stack44)
        %v30484 = vshrl.u32 %v30478, 16 (stack45)
        %v30485 = vor.u32 %v30484, %v30483 (stack46)
        %v30486 = vxor.u32 %v30485, %v30481 (stack47)
        %v30489 = vadd.s32 %v30486, %v30481 (stack39)
        %v30493 = vadd.s32 %v30489, %v8 (stack39)
        %v30495 = vshll.u32 %v30486, 24 (stack44)
        %v30496 = vshrl.u32 %v30486, 8 (stack45)
        %v30497 = vor.u32 %v30496, %v30495 (stack46)
        %v30498 = vxor.u32 %v30497, %v30489 (stack47)
        %v30501 = vadd.s32 %v30498, %v10 (stack39)
        %v30505 = vadd.s32 2, %v30501 (stack39)
        %v30509 = vadd.s32 %v30505, %v30493 (stack39)
        %v30511 = vshll.u32 %v30505, 13 (stack44)
        %v30512 = vshrl.u32 %v30505, 19 (stack45)
        %v30513 = vor.u32 %v30512, %v30511 (stack46)
        %v30514 = vxor.u32 %v30513, %v30509 (stack47)
        %v30517 = vadd.s32 %v30514, %v30509 (stack39)
        %v30519 = vshll.u32 %v30514, 15 (stack44)
        %v30520 = vshrl.u32 %v30514, 17 (stack45)
        %v30521 = vor.u32 %v30520, %v30519 (stack46)
        %v30522 = vxor.u32 %v30521, %v30517 (stack47)
        %v30525 = vadd.s32 %v30522, %v30517 (stack39)
        %v30527 = vshll.u32 %v30522, 26 (stack44)
        %v30528 = vshrl.u32 %v30522, 6 (stack45)
        %v30529 = vor.u32 %v30528, %v30527 (stack46)
        %v30530 = vxor.u32 %v30529, %v30525 (stack47)
        %v30533 = vadd.s32 %v30530, %v30525 (stack39)
        %v30537 = vadd.s32 %v30533, %v10 (stack39)
        %v30539 = vshll.u32 %v30530, 6 (stack44)
        %v30540 = vshrl.u32 %v30530, 26 (stack45)
        %v30541 = vor.u32 %v30540, %v30539 (stack46)
        %v30542 = vxor.u32 %v30541, %v30533 (stack47)
        %v30545 = vadd.s32 %v30542, %v9 (stack39)
        %v30549 = vadd.s32 3, %v30545 (stack39)
        %v30553 = vadd.s32 %v30549, %v30537 (stack39)
        %v30555 = vshll.u32 %v30549, 17 (stack44)
        %v30556 = vshrl.u32 %v30549, 15 (stack45)
        %v30557 = vor.u32 %v30556, %v30555 (stack46)
        %v30558 = vxor.u32 %v30557, %v30553 (stack47)
        %v30561 = vadd.s32 %v30558, %v30553 (stack39)
        %v30563 = vshll.u32 %v30558, 29 (stack44)
        %v30564 = vshrl.u32 %v30558, 3 (stack45)
        %v30565 = vor.u32 %v30564, %v30563 (stack46)
        %v30566 = vxor.u32 %v30565, %v30561 (stack47)
        %v30569 = vadd.s32 %v30566, %v30561 (stack39)
        %v30571 = vshll.u32 %v30566, 16 (stack44)
        %v30572 = vshrl.u32 %v30566, 16 (stack45)
        %v30573 = vor.u32 %v30572, %v30571 (stack46)
        %v30574 = vxor.u32 %v30573, %v30569 (stack47)
        %v30577 = vadd.s32 %v30574, %v30569 (stack39)
        %v30581 = vadd.s32 %v30577, %v9 (stack39)
        %v30583 = vshll.u32 %v30574, 24 (stack44)
        %v30584 = vshrl.u32 %v30574, 8 (stack45)
        %v30585 = vor.u32 %v30584, %v30583 (stack46)
        %v30586 = vxor.u32 %v30585, %v30577 (stack47)
        %v30589 = vadd.s32 %v30586, %v8 (stack39)
        %v30593 = vadd.s32 4, %v30589 (stack39)
        %v30597 = vadd.s32 %v30593, %v30581 (stack39)
        %v30599 = vshll.u32 %v30593, 13 (stack44)
        %v30600 = vshrl.u32 %v30593, 19 (stack45)
        %v30601 = vor.u32 %v30600, %v30599 (stack46)
        %v30602 = vxor.u32 %v30601, %v30597 (stack47)
        %v30605 = vadd.s32 %v30602, %v30597 (stack39)
        %v30607 = vshll.u32 %v30602, 15 (stack44)
        %v30608 = vshrl.u32 %v30602, 17 (stack45)
        %v30609 = vor.u32 %v30608, %v30607 (stack46)
        %v30610 = vxor.u32 %v30609, %v30605 (stack47)
        %v30613 = vadd.s32 %v30610, %v30605 (stack39)
        %v30615 = vshll.u32 %v30610, 26 (stack44)
        %v30616 = vshrl.u32 %v30610, 6 (stack45)
        %v30617 = vor.u32 %v30616, %v30615 (stack46)
        %v30618 = vxor.u32 %v30617, %v30613 (stack47)
        %v30621 = vadd.s32 %v30618, %v30613 (stack39)
        %v30625 = vadd.s32 %v30621, %v8 (stack39)
        %v30627 = vshll.u32 %v30618, 6 (stack44)
        %v30628 = vshrl.u32 %v30618, 26 (stack45)
        %v30629 = vor.u32 %v30628, %v30627 (stack46)
        %v30630 = vxor.u32 %v30629, %v30621 (stack47)
        %v30633 = vadd.s32 %v30630, %v10 (stack39)
        %v30637 = vadd.s32 5, %v30633 (stack39)
        %v30639 = vxor.u32 %v30637, %v30625 (stack47)
        %v30640 = vand.u32.u8 255, %v30639 (stack48)
        %v30641 = vand.u32 65535, %v30640 (stack49)
        %v30642 = vshrl.u32 %v30641, 1 (stack50)
        %v30643 = vor.u32 16256, %v30642 (stack46)
        %v30644 = vand.u32.u16 65535, %v30643 (stack51)
        %v119908 = vadd.low.f32.bf16 -1.0, %v30644 (stack52)
        %v30653 = vmul.f32 2.0, %v119908 (stack53)
        %v30657 = vadd.f32 -0.99609375, %v30653 (stack52)
        %v30661 = vmax.f32 %v30657, -0.99609375 (stack54)
        %v30663 = vand.u32 2147483647, %v30661 (stack55)
        %vm30666 = vcmp.eq.f32.partialorder %v30663, 1.0 (stack56)
        %v30671 = vmul.f32 inf, %v30661 (stack53)
        %v30673 = vxor.u32 2147483648, %v30661 (stack57)
        %v30676 = vmul.f32 %v30673, %v30661 (stack53)
        %v30678 = vadd.f32 1.0, %v30676 (stack58)
        %v30679 = vlog2.pop %v30678 (stack59)
        %v30680 = vmul.f32 0.6931472, %v30679 (stack60)
        %v30681 = vmul.f32 -0.5, %v30676 (stack61)
        %v30682 = vadd.f32 1.0, %v30681 (stack62)
        %v30683 = vmul.f32 %v30682, %v30676 (stack63)
        %v30684 = vand.u32 2147483647, %v30676 (stack64)
        %vm30685 = vcmp.lt.f32.partialorder %v30684, 0.0004427343 (stack65)
        %v30686 = vsel /*vm=*/%vm30685, /*on_true_vy=*/%v30683, /*on_false_vx=*/%v30680 (stack66)
        %v30687 = vxor.u32 2147483648, %v30686 (stack57)
        %vm30690 = vcmp.lt.f32.partialorder %v30687, 5.0 (stack56)
        %v30695 = vsel /*vm=*/%vm30690, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v30699 = vsel /*vm=*/%vm30690, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v30703 = vsel /*vm=*/%vm30690, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v30707 = vsel /*vm=*/%vm30690, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v30711 = vsel /*vm=*/%vm30690, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v30715 = vsel /*vm=*/%vm30690, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v30719 = vsel /*vm=*/%vm30690, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v30723 = vsel /*vm=*/%vm30690, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v30727 = vsel /*vm=*/%vm30690, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v30731 = vadd.f32 -2.5, %v30687 (stack52)
        %v30733 = vrsqrt.pop %v30687 (stack67)
        %v30734 = vmul.f32 %v30733, %v30687 (stack68)
        %vm30735 = vcmp.eq.f32.partialorder %v30687, inf (stack69)
        %v30736 = vsel /*vm=*/%vm30735, /*on_true_vy=*/%v30687, /*on_false_vx=*/%v30734 (stack70)
        %vm30737 = vcmp.eq.f32.partialorder %v30687, 0.0 (stack71)
        %v30738 = vand.u32 2147483648, %v30687 (stack72)
        %v30739 = vsel /*vm=*/%vm30737, /*on_true_vy=*/%v30738, /*on_false_vx=*/%v30736 (stack73)
        %v30742 = vadd.f32 -3.0, %v30739 (stack52)
        %v30746 = vsel /*vm=*/%vm30690, /*on_true_vy=*/%v30731, /*on_false_vx=*/%v30742 (stack43)
        %v30750 = vmul.f32 %v30746, %v30727 (stack53)
        %v30754 = vadd.f32 %v30750, %v30723 (stack52)
        %v30758 = vmul.f32 %v30754, %v30746 (stack53)
        %v30762 = vadd.f32 %v30758, %v30719 (stack52)
        %v30766 = vmul.f32 %v30762, %v30746 (stack53)
        %v30770 = vadd.f32 %v30766, %v30715 (stack52)
        %v30774 = vmul.f32 %v30770, %v30746 (stack53)
        %v30778 = vadd.f32 %v30774, %v30711 (stack52)
        %v30782 = vmul.f32 %v30778, %v30746 (stack53)
        %v30786 = vadd.f32 %v30782, %v30707 (stack52)
        %v30790 = vmul.f32 %v30786, %v30746 (stack53)
        %v30794 = vadd.f32 %v30790, %v30703 (stack52)
        %v30798 = vmul.f32 %v30794, %v30746 (stack53)
        %v30802 = vadd.f32 %v30798, %v30699 (stack52)
        %v30806 = vmul.f32 %v30802, %v30746 (stack53)
        %v30810 = vadd.f32 %v30806, %v30695 (stack52)
        %v30814 = vmul.f32 %v30810, %v30661 (stack53)
        %v30818 = vsel /*vm=*/%vm30666, /*on_true_vy=*/%v30671, /*on_false_vx=*/%v30814 (stack43)
        %v30822 = vmul.f32 1.4140625, %v30818 (stack53)
        %v30825 = vpack.c.bf16 0.0, %v30822 (stack74)
        %119909 = vst [vmem:[%s280 + $0x20] sm:$0xf] /*vst_source=*/%v30825 (stack75)
        %v30829 = vadd.s32 %v30365, %v894 (stack39)
        %v30839 = vadd.s32 %v30829, %v415 (stack39)
        %vm30843 = vcmp.lt.u32.totalorder %v30839, %v30829 (stack42)
        %vm30848 = vcmp.lt.u32.totalorder %v30829, %v894 (stack42)
        %v30853 = vadd.s32 %v30348, %v881 (stack39)
        %v30857 = vadd.s32 1, %v30853 (stack39)
        %v30861 = vsel /*vm=*/%vm30848, /*on_true_vy=*/%v30857, /*on_false_vx=*/%v30853 (stack43)
        %v30865 = vadd.s32 1, %v30861 (stack39)
        %v30869 = vsel /*vm=*/%vm30843, /*on_true_vy=*/%v30865, /*on_false_vx=*/%v30861 (stack43)
        %v30874 = vadd.s32 %v30869, %v10 (stack39)
        %v30878 = vadd.s32 %v30839, %v9 (stack39)
        %v30882 = vadd.s32 %v30878, %v30874 (stack39)
        %v30884 = vshll.u32 %v30878, 13 (stack44)
        %v30885 = vshrl.u32 %v30878, 19 (stack45)
        %v30886 = vor.u32 %v30885, %v30884 (stack46)
        %v30887 = vxor.u32 %v30886, %v30882 (stack47)
        %v30890 = vadd.s32 %v30887, %v30882 (stack39)
        %v30892 = vshll.u32 %v30887, 15 (stack44)
        %v30893 = vshrl.u32 %v30887, 17 (stack45)
        %v30894 = vor.u32 %v30893, %v30892 (stack46)
        %v30895 = vxor.u32 %v30894, %v30890 (stack47)
        %v30898 = vadd.s32 %v30895, %v30890 (stack39)
        %v30900 = vshll.u32 %v30895, 26 (stack44)
        %v30901 = vshrl.u32 %v30895, 6 (stack45)
        %v30902 = vor.u32 %v30901, %v30900 (stack46)
        %v30903 = vxor.u32 %v30902, %v30898 (stack47)
        %v30906 = vadd.s32 %v30903, %v30898 (stack39)
        %v30910 = vadd.s32 %v30906, %v9 (stack39)
        %v30912 = vshll.u32 %v30903, 6 (stack44)
        %v30913 = vshrl.u32 %v30903, 26 (stack45)
        %v30914 = vor.u32 %v30913, %v30912 (stack46)
        %v30915 = vxor.u32 %v30914, %v30906 (stack47)
        %v30918 = vadd.s32 %v30915, %v8 (stack39)
        %v30922 = vadd.s32 1, %v30918 (stack39)
        %v30926 = vadd.s32 %v30922, %v30910 (stack39)
        %v30928 = vshll.u32 %v30922, 17 (stack44)
        %v30929 = vshrl.u32 %v30922, 15 (stack45)
        %v30930 = vor.u32 %v30929, %v30928 (stack46)
        %v30931 = vxor.u32 %v30930, %v30926 (stack47)
        %v30934 = vadd.s32 %v30931, %v30926 (stack39)
        %v30936 = vshll.u32 %v30931, 29 (stack44)
        %v30937 = vshrl.u32 %v30931, 3 (stack45)
        %v30938 = vor.u32 %v30937, %v30936 (stack46)
        %v30939 = vxor.u32 %v30938, %v30934 (stack47)
        %v30942 = vadd.s32 %v30939, %v30934 (stack39)
        %v30944 = vshll.u32 %v30939, 16 (stack44)
        %v30945 = vshrl.u32 %v30939, 16 (stack45)
        %v30946 = vor.u32 %v30945, %v30944 (stack46)
        %v30947 = vxor.u32 %v30946, %v30942 (stack47)
        %v30950 = vadd.s32 %v30947, %v30942 (stack39)
        %v30954 = vadd.s32 %v30950, %v8 (stack39)
        %v30956 = vshll.u32 %v30947, 24 (stack44)
        %v30957 = vshrl.u32 %v30947, 8 (stack45)
        %v30958 = vor.u32 %v30957, %v30956 (stack46)
        %v30959 = vxor.u32 %v30958, %v30950 (stack47)
        %v30962 = vadd.s32 %v30959, %v10 (stack39)
        %v30966 = vadd.s32 2, %v30962 (stack39)
        %v30970 = vadd.s32 %v30966, %v30954 (stack39)
        %v30972 = vshll.u32 %v30966, 13 (stack44)
        %v30973 = vshrl.u32 %v30966, 19 (stack45)
        %v30974 = vor.u32 %v30973, %v30972 (stack46)
        %v30975 = vxor.u32 %v30974, %v30970 (stack47)
        %v30978 = vadd.s32 %v30975, %v30970 (stack39)
        %v30980 = vshll.u32 %v30975, 15 (stack44)
        %v30981 = vshrl.u32 %v30975, 17 (stack45)
        %v30982 = vor.u32 %v30981, %v30980 (stack46)
        %v30983 = vxor.u32 %v30982, %v30978 (stack47)
        %v30986 = vadd.s32 %v30983, %v30978 (stack39)
        %v30988 = vshll.u32 %v30983, 26 (stack44)
        %v30989 = vshrl.u32 %v30983, 6 (stack45)
        %v30990 = vor.u32 %v30989, %v30988 (stack46)
        %v30991 = vxor.u32 %v30990, %v30986 (stack47)
        %v30994 = vadd.s32 %v30991, %v30986 (stack39)
        %v30998 = vadd.s32 %v30994, %v10 (stack39)
        %v31000 = vshll.u32 %v30991, 6 (stack44)
        %v31001 = vshrl.u32 %v30991, 26 (stack45)
        %v31002 = vor.u32 %v31001, %v31000 (stack46)
        %v31003 = vxor.u32 %v31002, %v30994 (stack47)
        %v31006 = vadd.s32 %v31003, %v9 (stack39)
        %v31010 = vadd.s32 3, %v31006 (stack39)
        %v31014 = vadd.s32 %v31010, %v30998 (stack39)
        %v31016 = vshll.u32 %v31010, 17 (stack44)
        %v31017 = vshrl.u32 %v31010, 15 (stack45)
        %v31018 = vor.u32 %v31017, %v31016 (stack46)
        %v31019 = vxor.u32 %v31018, %v31014 (stack47)
        %v31022 = vadd.s32 %v31019, %v31014 (stack39)
        %v31024 = vshll.u32 %v31019, 29 (stack44)
        %v31025 = vshrl.u32 %v31019, 3 (stack45)
        %v31026 = vor.u32 %v31025, %v31024 (stack46)
        %v31027 = vxor.u32 %v31026, %v31022 (stack47)
        %v31030 = vadd.s32 %v31027, %v31022 (stack39)
        %v31032 = vshll.u32 %v31027, 16 (stack44)
        %v31033 = vshrl.u32 %v31027, 16 (stack45)
        %v31034 = vor.u32 %v31033, %v31032 (stack46)
        %v31035 = vxor.u32 %v31034, %v31030 (stack47)
        %v31038 = vadd.s32 %v31035, %v31030 (stack39)
        %v31042 = vadd.s32 %v31038, %v9 (stack39)
        %v31044 = vshll.u32 %v31035, 24 (stack44)
        %v31045 = vshrl.u32 %v31035, 8 (stack45)
        %v31046 = vor.u32 %v31045, %v31044 (stack46)
        %v31047 = vxor.u32 %v31046, %v31038 (stack47)
        %v31050 = vadd.s32 %v31047, %v8 (stack39)
        %v31054 = vadd.s32 4, %v31050 (stack39)
        %v31058 = vadd.s32 %v31054, %v31042 (stack39)
        %v31060 = vshll.u32 %v31054, 13 (stack44)
        %v31061 = vshrl.u32 %v31054, 19 (stack45)
        %v31062 = vor.u32 %v31061, %v31060 (stack46)
        %v31063 = vxor.u32 %v31062, %v31058 (stack47)
        %v31066 = vadd.s32 %v31063, %v31058 (stack39)
        %v31068 = vshll.u32 %v31063, 15 (stack44)
        %v31069 = vshrl.u32 %v31063, 17 (stack45)
        %v31070 = vor.u32 %v31069, %v31068 (stack46)
        %v31071 = vxor.u32 %v31070, %v31066 (stack47)
        %v31074 = vadd.s32 %v31071, %v31066 (stack39)
        %v31076 = vshll.u32 %v31071, 26 (stack44)
        %v31077 = vshrl.u32 %v31071, 6 (stack45)
        %v31078 = vor.u32 %v31077, %v31076 (stack46)
        %v31079 = vxor.u32 %v31078, %v31074 (stack47)
        %v31082 = vadd.s32 %v31079, %v31074 (stack39)
        %v31086 = vadd.s32 %v31082, %v8 (stack39)
        %v31088 = vshll.u32 %v31079, 6 (stack44)
        %v31089 = vshrl.u32 %v31079, 26 (stack45)
        %v31090 = vor.u32 %v31089, %v31088 (stack46)
        %v31091 = vxor.u32 %v31090, %v31082 (stack47)
        %v31094 = vadd.s32 %v31091, %v10 (stack39)
        %v31098 = vadd.s32 5, %v31094 (stack39)
        %v31100 = vxor.u32 %v31098, %v31086 (stack47)
        %v31101 = vand.u32.u8 255, %v31100 (stack48)
        %v31102 = vand.u32 65535, %v31101 (stack49)
        %v31103 = vshrl.u32 %v31102, 1 (stack50)
        %v31104 = vor.u32 16256, %v31103 (stack46)
        %v31105 = vand.u32.u16 65535, %v31104 (stack51)
        %v119910 = vadd.low.f32.bf16 -1.0, %v31105 (stack52)
        %v31114 = vmul.f32 2.0, %v119910 (stack53)
        %v31118 = vadd.f32 -0.99609375, %v31114 (stack52)
        %v31122 = vmax.f32 %v31118, -0.99609375 (stack54)
        %v31124 = vand.u32 2147483647, %v31122 (stack55)
        %vm31127 = vcmp.eq.f32.partialorder %v31124, 1.0 (stack56)
        %v31132 = vmul.f32 inf, %v31122 (stack53)
        %v31134 = vxor.u32 2147483648, %v31122 (stack57)
        %v31137 = vmul.f32 %v31134, %v31122 (stack53)
        %v31139 = vadd.f32 1.0, %v31137 (stack58)
        %v31140 = vlog2.pop %v31139 (stack59)
        %v31141 = vmul.f32 0.6931472, %v31140 (stack60)
        %v31142 = vmul.f32 -0.5, %v31137 (stack61)
        %v31143 = vadd.f32 1.0, %v31142 (stack62)
        %v31144 = vmul.f32 %v31143, %v31137 (stack63)
        %v31145 = vand.u32 2147483647, %v31137 (stack64)
        %vm31146 = vcmp.lt.f32.partialorder %v31145, 0.0004427343 (stack65)
        %v31147 = vsel /*vm=*/%vm31146, /*on_true_vy=*/%v31144, /*on_false_vx=*/%v31141 (stack66)
        %v31148 = vxor.u32 2147483648, %v31147 (stack57)
        %vm31151 = vcmp.lt.f32.partialorder %v31148, 5.0 (stack56)
        %v31156 = vsel /*vm=*/%vm31151, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v31160 = vsel /*vm=*/%vm31151, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v31164 = vsel /*vm=*/%vm31151, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v31168 = vsel /*vm=*/%vm31151, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v31172 = vsel /*vm=*/%vm31151, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v31176 = vsel /*vm=*/%vm31151, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v31180 = vsel /*vm=*/%vm31151, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v31184 = vsel /*vm=*/%vm31151, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v31188 = vsel /*vm=*/%vm31151, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v31192 = vadd.f32 -2.5, %v31148 (stack52)
        %v31194 = vrsqrt.pop %v31148 (stack67)
        %v31195 = vmul.f32 %v31194, %v31148 (stack68)
        %vm31196 = vcmp.eq.f32.partialorder %v31148, inf (stack69)
        %v31197 = vsel /*vm=*/%vm31196, /*on_true_vy=*/%v31148, /*on_false_vx=*/%v31195 (stack70)
        %vm31198 = vcmp.eq.f32.partialorder %v31148, 0.0 (stack71)
        %v31199 = vand.u32 2147483648, %v31148 (stack72)
        %v31200 = vsel /*vm=*/%vm31198, /*on_true_vy=*/%v31199, /*on_false_vx=*/%v31197 (stack73)
        %v31203 = vadd.f32 -3.0, %v31200 (stack52)
        %v31207 = vsel /*vm=*/%vm31151, /*on_true_vy=*/%v31192, /*on_false_vx=*/%v31203 (stack43)
        %v31211 = vmul.f32 %v31207, %v31188 (stack53)
        %v31215 = vadd.f32 %v31211, %v31184 (stack52)
        %v31219 = vmul.f32 %v31215, %v31207 (stack53)
        %v31223 = vadd.f32 %v31219, %v31180 (stack52)
        %v31227 = vmul.f32 %v31223, %v31207 (stack53)
        %v31231 = vadd.f32 %v31227, %v31176 (stack52)
        %v31235 = vmul.f32 %v31231, %v31207 (stack53)
        %v31239 = vadd.f32 %v31235, %v31172 (stack52)
        %v31243 = vmul.f32 %v31239, %v31207 (stack53)
        %v31247 = vadd.f32 %v31243, %v31168 (stack52)
        %v31251 = vmul.f32 %v31247, %v31207 (stack53)
        %v31255 = vadd.f32 %v31251, %v31164 (stack52)
        %v31259 = vmul.f32 %v31255, %v31207 (stack53)
        %v31263 = vadd.f32 %v31259, %v31160 (stack52)
        %v31267 = vmul.f32 %v31263, %v31207 (stack53)
        %v31271 = vadd.f32 %v31267, %v31156 (stack52)
        %v31275 = vmul.f32 %v31271, %v31122 (stack53)
        %v31279 = vsel /*vm=*/%vm31127, /*on_true_vy=*/%v31132, /*on_false_vx=*/%v31275 (stack43)
        %v31283 = vmul.f32 1.4140625, %v31279 (stack53)
        %v31286 = vpack.c.bf16 0.0, %v31283 (stack74)
        %119911 = vst [vmem:[%s280 + $0xa0] sm:$0xf] /*vst_source=*/%v31286 (stack75)
        %v31290 = vadd.s32 %v30365, %v1381 (stack39)
        %v31300 = vadd.s32 %v31290, %v415 (stack39)
        %vm31304 = vcmp.lt.u32.totalorder %v31300, %v31290 (stack42)
        %vm31309 = vcmp.lt.u32.totalorder %v31290, %v1381 (stack42)
        %v31314 = vadd.s32 %v30348, %v1368 (stack39)
        %v31318 = vadd.s32 1, %v31314 (stack39)
        %v31322 = vsel /*vm=*/%vm31309, /*on_true_vy=*/%v31318, /*on_false_vx=*/%v31314 (stack43)
        %v31326 = vadd.s32 1, %v31322 (stack39)
        %v31330 = vsel /*vm=*/%vm31304, /*on_true_vy=*/%v31326, /*on_false_vx=*/%v31322 (stack43)
        %v31335 = vadd.s32 %v31330, %v10 (stack39)
        %v31339 = vadd.s32 %v31300, %v9 (stack39)
        %v31343 = vadd.s32 %v31339, %v31335 (stack39)
        %v31345 = vshll.u32 %v31339, 13 (stack44)
        %v31346 = vshrl.u32 %v31339, 19 (stack45)
        %v31347 = vor.u32 %v31346, %v31345 (stack46)
        %v31348 = vxor.u32 %v31347, %v31343 (stack47)
        %v31351 = vadd.s32 %v31348, %v31343 (stack39)
        %v31353 = vshll.u32 %v31348, 15 (stack44)
        %v31354 = vshrl.u32 %v31348, 17 (stack45)
        %v31355 = vor.u32 %v31354, %v31353 (stack46)
        %v31356 = vxor.u32 %v31355, %v31351 (stack47)
        %v31359 = vadd.s32 %v31356, %v31351 (stack39)
        %v31361 = vshll.u32 %v31356, 26 (stack44)
        %v31362 = vshrl.u32 %v31356, 6 (stack45)
        %v31363 = vor.u32 %v31362, %v31361 (stack46)
        %v31364 = vxor.u32 %v31363, %v31359 (stack47)
        %v31367 = vadd.s32 %v31364, %v31359 (stack39)
        %v31371 = vadd.s32 %v31367, %v9 (stack39)
        %v31373 = vshll.u32 %v31364, 6 (stack44)
        %v31374 = vshrl.u32 %v31364, 26 (stack45)
        %v31375 = vor.u32 %v31374, %v31373 (stack46)
        %v31376 = vxor.u32 %v31375, %v31367 (stack47)
        %v31379 = vadd.s32 %v31376, %v8 (stack39)
        %v31383 = vadd.s32 1, %v31379 (stack39)
        %v31387 = vadd.s32 %v31383, %v31371 (stack39)
        %v31389 = vshll.u32 %v31383, 17 (stack44)
        %v31390 = vshrl.u32 %v31383, 15 (stack45)
        %v31391 = vor.u32 %v31390, %v31389 (stack46)
        %v31392 = vxor.u32 %v31391, %v31387 (stack47)
        %v31395 = vadd.s32 %v31392, %v31387 (stack39)
        %v31397 = vshll.u32 %v31392, 29 (stack44)
        %v31398 = vshrl.u32 %v31392, 3 (stack45)
        %v31399 = vor.u32 %v31398, %v31397 (stack46)
        %v31400 = vxor.u32 %v31399, %v31395 (stack47)
        %v31403 = vadd.s32 %v31400, %v31395 (stack39)
        %v31405 = vshll.u32 %v31400, 16 (stack44)
        %v31406 = vshrl.u32 %v31400, 16 (stack45)
        %v31407 = vor.u32 %v31406, %v31405 (stack46)
        %v31408 = vxor.u32 %v31407, %v31403 (stack47)
        %v31411 = vadd.s32 %v31408, %v31403 (stack39)
        %v31415 = vadd.s32 %v31411, %v8 (stack39)
        %v31417 = vshll.u32 %v31408, 24 (stack44)
        %v31418 = vshrl.u32 %v31408, 8 (stack45)
        %v31419 = vor.u32 %v31418, %v31417 (stack46)
        %v31420 = vxor.u32 %v31419, %v31411 (stack47)
        %v31423 = vadd.s32 %v31420, %v10 (stack39)
        %v31427 = vadd.s32 2, %v31423 (stack39)
        %v31431 = vadd.s32 %v31427, %v31415 (stack39)
        %v31433 = vshll.u32 %v31427, 13 (stack44)
        %v31434 = vshrl.u32 %v31427, 19 (stack45)
        %v31435 = vor.u32 %v31434, %v31433 (stack46)
        %v31436 = vxor.u32 %v31435, %v31431 (stack47)
        %v31439 = vadd.s32 %v31436, %v31431 (stack39)
        %v31441 = vshll.u32 %v31436, 15 (stack44)
        %v31442 = vshrl.u32 %v31436, 17 (stack45)
        %v31443 = vor.u32 %v31442, %v31441 (stack46)
        %v31444 = vxor.u32 %v31443, %v31439 (stack47)
        %v31447 = vadd.s32 %v31444, %v31439 (stack39)
        %v31449 = vshll.u32 %v31444, 26 (stack44)
        %v31450 = vshrl.u32 %v31444, 6 (stack45)
        %v31451 = vor.u32 %v31450, %v31449 (stack46)
        %v31452 = vxor.u32 %v31451, %v31447 (stack47)
        %v31455 = vadd.s32 %v31452, %v31447 (stack39)
        %v31459 = vadd.s32 %v31455, %v10 (stack39)
        %v31461 = vshll.u32 %v31452, 6 (stack44)
        %v31462 = vshrl.u32 %v31452, 26 (stack45)
        %v31463 = vor.u32 %v31462, %v31461 (stack46)
        %v31464 = vxor.u32 %v31463, %v31455 (stack47)
        %v31467 = vadd.s32 %v31464, %v9 (stack39)
        %v31471 = vadd.s32 3, %v31467 (stack39)
        %v31475 = vadd.s32 %v31471, %v31459 (stack39)
        %v31477 = vshll.u32 %v31471, 17 (stack44)
        %v31478 = vshrl.u32 %v31471, 15 (stack45)
        %v31479 = vor.u32 %v31478, %v31477 (stack46)
        %v31480 = vxor.u32 %v31479, %v31475 (stack47)
        %v31483 = vadd.s32 %v31480, %v31475 (stack39)
        %v31485 = vshll.u32 %v31480, 29 (stack44)
        %v31486 = vshrl.u32 %v31480, 3 (stack45)
        %v31487 = vor.u32 %v31486, %v31485 (stack46)
        %v31488 = vxor.u32 %v31487, %v31483 (stack47)
        %v31491 = vadd.s32 %v31488, %v31483 (stack39)
        %v31493 = vshll.u32 %v31488, 16 (stack44)
        %v31494 = vshrl.u32 %v31488, 16 (stack45)
        %v31495 = vor.u32 %v31494, %v31493 (stack46)
        %v31496 = vxor.u32 %v31495, %v31491 (stack47)
        %v31499 = vadd.s32 %v31496, %v31491 (stack39)
        %v31503 = vadd.s32 %v31499, %v9 (stack39)
        %v31505 = vshll.u32 %v31496, 24 (stack44)
        %v31506 = vshrl.u32 %v31496, 8 (stack45)
        %v31507 = vor.u32 %v31506, %v31505 (stack46)
        %v31508 = vxor.u32 %v31507, %v31499 (stack47)
        %v31511 = vadd.s32 %v31508, %v8 (stack39)
        %v31515 = vadd.s32 4, %v31511 (stack39)
        %v31519 = vadd.s32 %v31515, %v31503 (stack39)
        %v31521 = vshll.u32 %v31515, 13 (stack44)
        %v31522 = vshrl.u32 %v31515, 19 (stack45)
        %v31523 = vor.u32 %v31522, %v31521 (stack46)
        %v31524 = vxor.u32 %v31523, %v31519 (stack47)
        %v31527 = vadd.s32 %v31524, %v31519 (stack39)
        %v31529 = vshll.u32 %v31524, 15 (stack44)
        %v31530 = vshrl.u32 %v31524, 17 (stack45)
        %v31531 = vor.u32 %v31530, %v31529 (stack46)
        %v31532 = vxor.u32 %v31531, %v31527 (stack47)
        %v31535 = vadd.s32 %v31532, %v31527 (stack39)
        %v31537 = vshll.u32 %v31532, 26 (stack44)
        %v31538 = vshrl.u32 %v31532, 6 (stack45)
        %v31539 = vor.u32 %v31538, %v31537 (stack46)
        %v31540 = vxor.u32 %v31539, %v31535 (stack47)
        %v31543 = vadd.s32 %v31540, %v31535 (stack39)
        %v31547 = vadd.s32 %v31543, %v8 (stack39)
        %v31549 = vshll.u32 %v31540, 6 (stack44)
        %v31550 = vshrl.u32 %v31540, 26 (stack45)
        %v31551 = vor.u32 %v31550, %v31549 (stack46)
        %v31552 = vxor.u32 %v31551, %v31543 (stack47)
        %v31555 = vadd.s32 %v31552, %v10 (stack39)
        %v31559 = vadd.s32 5, %v31555 (stack39)
        %v31561 = vxor.u32 %v31559, %v31547 (stack47)
        %v31562 = vand.u32.u8 255, %v31561 (stack48)
        %v31563 = vand.u32 65535, %v31562 (stack49)
        %v31564 = vshrl.u32 %v31563, 1 (stack50)
        %v31565 = vor.u32 16256, %v31564 (stack46)
        %v31566 = vand.u32.u16 65535, %v31565 (stack51)
        %v119912 = vadd.low.f32.bf16 -1.0, %v31566 (stack52)
        %v31575 = vmul.f32 2.0, %v119912 (stack53)
        %v31579 = vadd.f32 -0.99609375, %v31575 (stack52)
        %v31583 = vmax.f32 %v31579, -0.99609375 (stack54)
        %v31585 = vand.u32 2147483647, %v31583 (stack55)
        %vm31588 = vcmp.eq.f32.partialorder %v31585, 1.0 (stack56)
        %v31593 = vmul.f32 inf, %v31583 (stack53)
        %v31595 = vxor.u32 2147483648, %v31583 (stack57)
        %v31598 = vmul.f32 %v31595, %v31583 (stack53)
        %v31600 = vadd.f32 1.0, %v31598 (stack58)
        %v31601 = vlog2.pop %v31600 (stack59)
        %v31602 = vmul.f32 0.6931472, %v31601 (stack60)
        %v31603 = vmul.f32 -0.5, %v31598 (stack61)
        %v31604 = vadd.f32 1.0, %v31603 (stack62)
        %v31605 = vmul.f32 %v31604, %v31598 (stack63)
        %v31606 = vand.u32 2147483647, %v31598 (stack64)
        %vm31607 = vcmp.lt.f32.partialorder %v31606, 0.0004427343 (stack65)
        %v31608 = vsel /*vm=*/%vm31607, /*on_true_vy=*/%v31605, /*on_false_vx=*/%v31602 (stack66)
        %v31609 = vxor.u32 2147483648, %v31608 (stack57)
        %vm31612 = vcmp.lt.f32.partialorder %v31609, 5.0 (stack56)
        %v31617 = vsel /*vm=*/%vm31612, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v31621 = vsel /*vm=*/%vm31612, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v31625 = vsel /*vm=*/%vm31612, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v31629 = vsel /*vm=*/%vm31612, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v31633 = vsel /*vm=*/%vm31612, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v31637 = vsel /*vm=*/%vm31612, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v31641 = vsel /*vm=*/%vm31612, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v31645 = vsel /*vm=*/%vm31612, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v31649 = vsel /*vm=*/%vm31612, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v31653 = vadd.f32 -2.5, %v31609 (stack52)
        %v31655 = vrsqrt.pop %v31609 (stack67)
        %v31656 = vmul.f32 %v31655, %v31609 (stack68)
        %vm31657 = vcmp.eq.f32.partialorder %v31609, inf (stack69)
        %v31658 = vsel /*vm=*/%vm31657, /*on_true_vy=*/%v31609, /*on_false_vx=*/%v31656 (stack70)
        %vm31659 = vcmp.eq.f32.partialorder %v31609, 0.0 (stack71)
        %v31660 = vand.u32 2147483648, %v31609 (stack72)
        %v31661 = vsel /*vm=*/%vm31659, /*on_true_vy=*/%v31660, /*on_false_vx=*/%v31658 (stack73)
        %v31664 = vadd.f32 -3.0, %v31661 (stack52)
        %v31668 = vsel /*vm=*/%vm31612, /*on_true_vy=*/%v31653, /*on_false_vx=*/%v31664 (stack43)
        %v31672 = vmul.f32 %v31668, %v31649 (stack53)
        %v31676 = vadd.f32 %v31672, %v31645 (stack52)
        %v31680 = vmul.f32 %v31676, %v31668 (stack53)
        %v31684 = vadd.f32 %v31680, %v31641 (stack52)
        %v31688 = vmul.f32 %v31684, %v31668 (stack53)
        %v31692 = vadd.f32 %v31688, %v31637 (stack52)
        %v31696 = vmul.f32 %v31692, %v31668 (stack53)
        %v31700 = vadd.f32 %v31696, %v31633 (stack52)
        %v31704 = vmul.f32 %v31700, %v31668 (stack53)
        %v31708 = vadd.f32 %v31704, %v31629 (stack52)
        %v31712 = vmul.f32 %v31708, %v31668 (stack53)
        %v31716 = vadd.f32 %v31712, %v31625 (stack52)
        %v31720 = vmul.f32 %v31716, %v31668 (stack53)
        %v31724 = vadd.f32 %v31720, %v31621 (stack52)
        %v31728 = vmul.f32 %v31724, %v31668 (stack53)
        %v31732 = vadd.f32 %v31728, %v31617 (stack52)
        %v31736 = vmul.f32 %v31732, %v31583 (stack53)
        %v31740 = vsel /*vm=*/%vm31588, /*on_true_vy=*/%v31593, /*on_false_vx=*/%v31736 (stack43)
        %v31744 = vmul.f32 1.4140625, %v31740 (stack53)
        %v31747 = vpack.c.bf16 0.0, %v31744 (stack74)
        %119913 = vst [vmem:[%s280 + $0x120] sm:$0xf] /*vst_source=*/%v31747 (stack75)
        %v31751 = vadd.s32 %v30365, %v1868 (stack39)
        %v31761 = vadd.s32 %v31751, %v415 (stack39)
        %vm31765 = vcmp.lt.u32.totalorder %v31761, %v31751 (stack42)
        %vm31770 = vcmp.lt.u32.totalorder %v31751, %v1868 (stack42)
        %v31775 = vadd.s32 %v30348, %v1855 (stack39)
        %v31779 = vadd.s32 1, %v31775 (stack39)
        %v31783 = vsel /*vm=*/%vm31770, /*on_true_vy=*/%v31779, /*on_false_vx=*/%v31775 (stack43)
        %v31787 = vadd.s32 1, %v31783 (stack39)
        %v31791 = vsel /*vm=*/%vm31765, /*on_true_vy=*/%v31787, /*on_false_vx=*/%v31783 (stack43)
        %v31796 = vadd.s32 %v31791, %v10 (stack39)
        %v31800 = vadd.s32 %v31761, %v9 (stack39)
        %v31804 = vadd.s32 %v31800, %v31796 (stack39)
        %v31806 = vshll.u32 %v31800, 13 (stack44)
        %v31807 = vshrl.u32 %v31800, 19 (stack45)
        %v31808 = vor.u32 %v31807, %v31806 (stack46)
        %v31809 = vxor.u32 %v31808, %v31804 (stack47)
        %v31812 = vadd.s32 %v31809, %v31804 (stack39)
        %v31814 = vshll.u32 %v31809, 15 (stack44)
        %v31815 = vshrl.u32 %v31809, 17 (stack45)
        %v31816 = vor.u32 %v31815, %v31814 (stack46)
        %v31817 = vxor.u32 %v31816, %v31812 (stack47)
        %v31820 = vadd.s32 %v31817, %v31812 (stack39)
        %v31822 = vshll.u32 %v31817, 26 (stack44)
        %v31823 = vshrl.u32 %v31817, 6 (stack45)
        %v31824 = vor.u32 %v31823, %v31822 (stack46)
        %v31825 = vxor.u32 %v31824, %v31820 (stack47)
        %v31828 = vadd.s32 %v31825, %v31820 (stack39)
        %v31832 = vadd.s32 %v31828, %v9 (stack39)
        %v31834 = vshll.u32 %v31825, 6 (stack44)
        %v31835 = vshrl.u32 %v31825, 26 (stack45)
        %v31836 = vor.u32 %v31835, %v31834 (stack46)
        %v31837 = vxor.u32 %v31836, %v31828 (stack47)
        %v31840 = vadd.s32 %v31837, %v8 (stack39)
        %v31844 = vadd.s32 1, %v31840 (stack39)
        %v31848 = vadd.s32 %v31844, %v31832 (stack39)
        %v31850 = vshll.u32 %v31844, 17 (stack44)
        %v31851 = vshrl.u32 %v31844, 15 (stack45)
        %v31852 = vor.u32 %v31851, %v31850 (stack46)
        %v31853 = vxor.u32 %v31852, %v31848 (stack47)
        %v31856 = vadd.s32 %v31853, %v31848 (stack39)
        %v31858 = vshll.u32 %v31853, 29 (stack44)
        %v31859 = vshrl.u32 %v31853, 3 (stack45)
        %v31860 = vor.u32 %v31859, %v31858 (stack46)
        %v31861 = vxor.u32 %v31860, %v31856 (stack47)
        %v31864 = vadd.s32 %v31861, %v31856 (stack39)
        %v31866 = vshll.u32 %v31861, 16 (stack44)
        %v31867 = vshrl.u32 %v31861, 16 (stack45)
        %v31868 = vor.u32 %v31867, %v31866 (stack46)
        %v31869 = vxor.u32 %v31868, %v31864 (stack47)
        %v31872 = vadd.s32 %v31869, %v31864 (stack39)
        %v31876 = vadd.s32 %v31872, %v8 (stack39)
        %v31878 = vshll.u32 %v31869, 24 (stack44)
        %v31879 = vshrl.u32 %v31869, 8 (stack45)
        %v31880 = vor.u32 %v31879, %v31878 (stack46)
        %v31881 = vxor.u32 %v31880, %v31872 (stack47)
        %v31884 = vadd.s32 %v31881, %v10 (stack39)
        %v31888 = vadd.s32 2, %v31884 (stack39)
        %v31892 = vadd.s32 %v31888, %v31876 (stack39)
        %v31894 = vshll.u32 %v31888, 13 (stack44)
        %v31895 = vshrl.u32 %v31888, 19 (stack45)
        %v31896 = vor.u32 %v31895, %v31894 (stack46)
        %v31897 = vxor.u32 %v31896, %v31892 (stack47)
        %v31900 = vadd.s32 %v31897, %v31892 (stack39)
        %v31902 = vshll.u32 %v31897, 15 (stack44)
        %v31903 = vshrl.u32 %v31897, 17 (stack45)
        %v31904 = vor.u32 %v31903, %v31902 (stack46)
        %v31905 = vxor.u32 %v31904, %v31900 (stack47)
        %v31908 = vadd.s32 %v31905, %v31900 (stack39)
        %v31910 = vshll.u32 %v31905, 26 (stack44)
        %v31911 = vshrl.u32 %v31905, 6 (stack45)
        %v31912 = vor.u32 %v31911, %v31910 (stack46)
        %v31913 = vxor.u32 %v31912, %v31908 (stack47)
        %v31916 = vadd.s32 %v31913, %v31908 (stack39)
        %v31920 = vadd.s32 %v31916, %v10 (stack39)
        %v31922 = vshll.u32 %v31913, 6 (stack44)
        %v31923 = vshrl.u32 %v31913, 26 (stack45)
        %v31924 = vor.u32 %v31923, %v31922 (stack46)
        %v31925 = vxor.u32 %v31924, %v31916 (stack47)
        %v31928 = vadd.s32 %v31925, %v9 (stack39)
        %v31932 = vadd.s32 3, %v31928 (stack39)
        %v31936 = vadd.s32 %v31932, %v31920 (stack39)
        %v31938 = vshll.u32 %v31932, 17 (stack44)
        %v31939 = vshrl.u32 %v31932, 15 (stack45)
        %v31940 = vor.u32 %v31939, %v31938 (stack46)
        %v31941 = vxor.u32 %v31940, %v31936 (stack47)
        %v31944 = vadd.s32 %v31941, %v31936 (stack39)
        %v31946 = vshll.u32 %v31941, 29 (stack44)
        %v31947 = vshrl.u32 %v31941, 3 (stack45)
        %v31948 = vor.u32 %v31947, %v31946 (stack46)
        %v31949 = vxor.u32 %v31948, %v31944 (stack47)
        %v31952 = vadd.s32 %v31949, %v31944 (stack39)
        %v31954 = vshll.u32 %v31949, 16 (stack44)
        %v31955 = vshrl.u32 %v31949, 16 (stack45)
        %v31956 = vor.u32 %v31955, %v31954 (stack46)
        %v31957 = vxor.u32 %v31956, %v31952 (stack47)
        %v31960 = vadd.s32 %v31957, %v31952 (stack39)
        %v31964 = vadd.s32 %v31960, %v9 (stack39)
        %v31966 = vshll.u32 %v31957, 24 (stack44)
        %v31967 = vshrl.u32 %v31957, 8 (stack45)
        %v31968 = vor.u32 %v31967, %v31966 (stack46)
        %v31969 = vxor.u32 %v31968, %v31960 (stack47)
        %v31972 = vadd.s32 %v31969, %v8 (stack39)
        %v31976 = vadd.s32 4, %v31972 (stack39)
        %v31980 = vadd.s32 %v31976, %v31964 (stack39)
        %v31982 = vshll.u32 %v31976, 13 (stack44)
        %v31983 = vshrl.u32 %v31976, 19 (stack45)
        %v31984 = vor.u32 %v31983, %v31982 (stack46)
        %v31985 = vxor.u32 %v31984, %v31980 (stack47)
        %v31988 = vadd.s32 %v31985, %v31980 (stack39)
        %v31990 = vshll.u32 %v31985, 15 (stack44)
        %v31991 = vshrl.u32 %v31985, 17 (stack45)
        %v31992 = vor.u32 %v31991, %v31990 (stack46)
        %v31993 = vxor.u32 %v31992, %v31988 (stack47)
        %v31996 = vadd.s32 %v31993, %v31988 (stack39)
        %v31998 = vshll.u32 %v31993, 26 (stack44)
        %v31999 = vshrl.u32 %v31993, 6 (stack45)
        %v32000 = vor.u32 %v31999, %v31998 (stack46)
        %v32001 = vxor.u32 %v32000, %v31996 (stack47)
        %v32004 = vadd.s32 %v32001, %v31996 (stack39)
        %v32008 = vadd.s32 %v32004, %v8 (stack39)
        %v32010 = vshll.u32 %v32001, 6 (stack44)
        %v32011 = vshrl.u32 %v32001, 26 (stack45)
        %v32012 = vor.u32 %v32011, %v32010 (stack46)
        %v32013 = vxor.u32 %v32012, %v32004 (stack47)
        %v32016 = vadd.s32 %v32013, %v10 (stack39)
        %v32020 = vadd.s32 5, %v32016 (stack39)
        %v32022 = vxor.u32 %v32020, %v32008 (stack47)
        %v32023 = vand.u32.u8 255, %v32022 (stack48)
        %v32024 = vand.u32 65535, %v32023 (stack49)
        %v32025 = vshrl.u32 %v32024, 1 (stack50)
        %v32026 = vor.u32 16256, %v32025 (stack46)
        %v32027 = vand.u32.u16 65535, %v32026 (stack51)
        %v119914 = vadd.low.f32.bf16 -1.0, %v32027 (stack52)
        %v32036 = vmul.f32 2.0, %v119914 (stack53)
        %v32040 = vadd.f32 -0.99609375, %v32036 (stack52)
        %v32044 = vmax.f32 %v32040, -0.99609375 (stack54)
        %v32046 = vand.u32 2147483647, %v32044 (stack55)
        %vm32049 = vcmp.eq.f32.partialorder %v32046, 1.0 (stack56)
        %v32054 = vmul.f32 inf, %v32044 (stack53)
        %v32056 = vxor.u32 2147483648, %v32044 (stack57)
        %v32059 = vmul.f32 %v32056, %v32044 (stack53)
        %v32061 = vadd.f32 1.0, %v32059 (stack58)
        %v32062 = vlog2.pop %v32061 (stack59)
        %v32063 = vmul.f32 0.6931472, %v32062 (stack60)
        %v32064 = vmul.f32 -0.5, %v32059 (stack61)
        %v32065 = vadd.f32 1.0, %v32064 (stack62)
        %v32066 = vmul.f32 %v32065, %v32059 (stack63)
        %v32067 = vand.u32 2147483647, %v32059 (stack64)
        %vm32068 = vcmp.lt.f32.partialorder %v32067, 0.0004427343 (stack65)
        %v32069 = vsel /*vm=*/%vm32068, /*on_true_vy=*/%v32066, /*on_false_vx=*/%v32063 (stack66)
        %v32070 = vxor.u32 2147483648, %v32069 (stack57)
        %vm32073 = vcmp.lt.f32.partialorder %v32070, 5.0 (stack56)
        %v32078 = vsel /*vm=*/%vm32073, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v32082 = vsel /*vm=*/%vm32073, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v32086 = vsel /*vm=*/%vm32073, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v32090 = vsel /*vm=*/%vm32073, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v32094 = vsel /*vm=*/%vm32073, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v32098 = vsel /*vm=*/%vm32073, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v32102 = vsel /*vm=*/%vm32073, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v32106 = vsel /*vm=*/%vm32073, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v32110 = vsel /*vm=*/%vm32073, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v32114 = vadd.f32 -2.5, %v32070 (stack52)
        %v32116 = vrsqrt.pop %v32070 (stack67)
        %v32117 = vmul.f32 %v32116, %v32070 (stack68)
        %vm32118 = vcmp.eq.f32.partialorder %v32070, inf (stack69)
        %v32119 = vsel /*vm=*/%vm32118, /*on_true_vy=*/%v32070, /*on_false_vx=*/%v32117 (stack70)
        %vm32120 = vcmp.eq.f32.partialorder %v32070, 0.0 (stack71)
        %v32121 = vand.u32 2147483648, %v32070 (stack72)
        %v32122 = vsel /*vm=*/%vm32120, /*on_true_vy=*/%v32121, /*on_false_vx=*/%v32119 (stack73)
        %v32125 = vadd.f32 -3.0, %v32122 (stack52)
        %v32129 = vsel /*vm=*/%vm32073, /*on_true_vy=*/%v32114, /*on_false_vx=*/%v32125 (stack43)
        %v32133 = vmul.f32 %v32129, %v32110 (stack53)
        %v32137 = vadd.f32 %v32133, %v32106 (stack52)
        %v32141 = vmul.f32 %v32137, %v32129 (stack53)
        %v32145 = vadd.f32 %v32141, %v32102 (stack52)
        %v32149 = vmul.f32 %v32145, %v32129 (stack53)
        %v32153 = vadd.f32 %v32149, %v32098 (stack52)
        %v32157 = vmul.f32 %v32153, %v32129 (stack53)
        %v32161 = vadd.f32 %v32157, %v32094 (stack52)
        %v32165 = vmul.f32 %v32161, %v32129 (stack53)
        %v32169 = vadd.f32 %v32165, %v32090 (stack52)
        %v32173 = vmul.f32 %v32169, %v32129 (stack53)
        %v32177 = vadd.f32 %v32173, %v32086 (stack52)
        %v32181 = vmul.f32 %v32177, %v32129 (stack53)
        %v32185 = vadd.f32 %v32181, %v32082 (stack52)
        %v32189 = vmul.f32 %v32185, %v32129 (stack53)
        %v32193 = vadd.f32 %v32189, %v32078 (stack52)
        %v32197 = vmul.f32 %v32193, %v32044 (stack53)
        %v32201 = vsel /*vm=*/%vm32049, /*on_true_vy=*/%v32054, /*on_false_vx=*/%v32197 (stack43)
        %v32205 = vmul.f32 1.4140625, %v32201 (stack53)
        %v32208 = vpack.c.bf16 0.0, %v32205 (stack74)
        %119915 = vst [vmem:[%s280 + $0x1a0] sm:$0xf] /*vst_source=*/%v32208 (stack75)
        %v32212 = vadd.s32 %v30365, %v2355 (stack39)
        %v32222 = vadd.s32 %v32212, %v415 (stack39)
        %vm32226 = vcmp.lt.u32.totalorder %v32222, %v32212 (stack42)
        %vm32231 = vcmp.lt.u32.totalorder %v32212, %v2355 (stack42)
        %v32236 = vadd.s32 %v30348, %v2342 (stack39)
        %v32240 = vadd.s32 1, %v32236 (stack39)
        %v32244 = vsel /*vm=*/%vm32231, /*on_true_vy=*/%v32240, /*on_false_vx=*/%v32236 (stack43)
        %v32248 = vadd.s32 1, %v32244 (stack39)
        %v32252 = vsel /*vm=*/%vm32226, /*on_true_vy=*/%v32248, /*on_false_vx=*/%v32244 (stack43)
        %v32257 = vadd.s32 %v32252, %v10 (stack39)
        %v32261 = vadd.s32 %v32222, %v9 (stack39)
        %v32265 = vadd.s32 %v32261, %v32257 (stack39)
        %v32267 = vshll.u32 %v32261, 13 (stack44)
        %v32268 = vshrl.u32 %v32261, 19 (stack45)
        %v32269 = vor.u32 %v32268, %v32267 (stack46)
        %v32270 = vxor.u32 %v32269, %v32265 (stack47)
        %v32273 = vadd.s32 %v32270, %v32265 (stack39)
        %v32275 = vshll.u32 %v32270, 15 (stack44)
        %v32276 = vshrl.u32 %v32270, 17 (stack45)
        %v32277 = vor.u32 %v32276, %v32275 (stack46)
        %v32278 = vxor.u32 %v32277, %v32273 (stack47)
        %v32281 = vadd.s32 %v32278, %v32273 (stack39)
        %v32283 = vshll.u32 %v32278, 26 (stack44)
        %v32284 = vshrl.u32 %v32278, 6 (stack45)
        %v32285 = vor.u32 %v32284, %v32283 (stack46)
        %v32286 = vxor.u32 %v32285, %v32281 (stack47)
        %v32289 = vadd.s32 %v32286, %v32281 (stack39)
        %v32293 = vadd.s32 %v32289, %v9 (stack39)
        %v32295 = vshll.u32 %v32286, 6 (stack44)
        %v32296 = vshrl.u32 %v32286, 26 (stack45)
        %v32297 = vor.u32 %v32296, %v32295 (stack46)
        %v32298 = vxor.u32 %v32297, %v32289 (stack47)
        %v32301 = vadd.s32 %v32298, %v8 (stack39)
        %v32305 = vadd.s32 1, %v32301 (stack39)
        %v32309 = vadd.s32 %v32305, %v32293 (stack39)
        %v32311 = vshll.u32 %v32305, 17 (stack44)
        %v32312 = vshrl.u32 %v32305, 15 (stack45)
        %v32313 = vor.u32 %v32312, %v32311 (stack46)
        %v32314 = vxor.u32 %v32313, %v32309 (stack47)
        %v32317 = vadd.s32 %v32314, %v32309 (stack39)
        %v32319 = vshll.u32 %v32314, 29 (stack44)
        %v32320 = vshrl.u32 %v32314, 3 (stack45)
        %v32321 = vor.u32 %v32320, %v32319 (stack46)
        %v32322 = vxor.u32 %v32321, %v32317 (stack47)
        %v32325 = vadd.s32 %v32322, %v32317 (stack39)
        %v32327 = vshll.u32 %v32322, 16 (stack44)
        %v32328 = vshrl.u32 %v32322, 16 (stack45)
        %v32329 = vor.u32 %v32328, %v32327 (stack46)
        %v32330 = vxor.u32 %v32329, %v32325 (stack47)
        %v32333 = vadd.s32 %v32330, %v32325 (stack39)
        %v32337 = vadd.s32 %v32333, %v8 (stack39)
        %v32339 = vshll.u32 %v32330, 24 (stack44)
        %v32340 = vshrl.u32 %v32330, 8 (stack45)
        %v32341 = vor.u32 %v32340, %v32339 (stack46)
        %v32342 = vxor.u32 %v32341, %v32333 (stack47)
        %v32345 = vadd.s32 %v32342, %v10 (stack39)
        %v32349 = vadd.s32 2, %v32345 (stack39)
        %v32353 = vadd.s32 %v32349, %v32337 (stack39)
        %v32355 = vshll.u32 %v32349, 13 (stack44)
        %v32356 = vshrl.u32 %v32349, 19 (stack45)
        %v32357 = vor.u32 %v32356, %v32355 (stack46)
        %v32358 = vxor.u32 %v32357, %v32353 (stack47)
        %v32361 = vadd.s32 %v32358, %v32353 (stack39)
        %v32363 = vshll.u32 %v32358, 15 (stack44)
        %v32364 = vshrl.u32 %v32358, 17 (stack45)
        %v32365 = vor.u32 %v32364, %v32363 (stack46)
        %v32366 = vxor.u32 %v32365, %v32361 (stack47)
        %v32369 = vadd.s32 %v32366, %v32361 (stack39)
        %v32371 = vshll.u32 %v32366, 26 (stack44)
        %v32372 = vshrl.u32 %v32366, 6 (stack45)
        %v32373 = vor.u32 %v32372, %v32371 (stack46)
        %v32374 = vxor.u32 %v32373, %v32369 (stack47)
        %v32377 = vadd.s32 %v32374, %v32369 (stack39)
        %v32381 = vadd.s32 %v32377, %v10 (stack39)
        %v32383 = vshll.u32 %v32374, 6 (stack44)
        %v32384 = vshrl.u32 %v32374, 26 (stack45)
        %v32385 = vor.u32 %v32384, %v32383 (stack46)
        %v32386 = vxor.u32 %v32385, %v32377 (stack47)
        %v32389 = vadd.s32 %v32386, %v9 (stack39)
        %v32393 = vadd.s32 3, %v32389 (stack39)
        %v32397 = vadd.s32 %v32393, %v32381 (stack39)
        %v32399 = vshll.u32 %v32393, 17 (stack44)
        %v32400 = vshrl.u32 %v32393, 15 (stack45)
        %v32401 = vor.u32 %v32400, %v32399 (stack46)
        %v32402 = vxor.u32 %v32401, %v32397 (stack47)
        %v32405 = vadd.s32 %v32402, %v32397 (stack39)
        %v32407 = vshll.u32 %v32402, 29 (stack44)
        %v32408 = vshrl.u32 %v32402, 3 (stack45)
        %v32409 = vor.u32 %v32408, %v32407 (stack46)
        %v32410 = vxor.u32 %v32409, %v32405 (stack47)
        %v32413 = vadd.s32 %v32410, %v32405 (stack39)
        %v32415 = vshll.u32 %v32410, 16 (stack44)
        %v32416 = vshrl.u32 %v32410, 16 (stack45)
        %v32417 = vor.u32 %v32416, %v32415 (stack46)
        %v32418 = vxor.u32 %v32417, %v32413 (stack47)
        %v32421 = vadd.s32 %v32418, %v32413 (stack39)
        %v32425 = vadd.s32 %v32421, %v9 (stack39)
        %v32427 = vshll.u32 %v32418, 24 (stack44)
        %v32428 = vshrl.u32 %v32418, 8 (stack45)
        %v32429 = vor.u32 %v32428, %v32427 (stack46)
        %v32430 = vxor.u32 %v32429, %v32421 (stack47)
        %v32433 = vadd.s32 %v32430, %v8 (stack39)
        %v32437 = vadd.s32 4, %v32433 (stack39)
        %v32441 = vadd.s32 %v32437, %v32425 (stack39)
        %v32443 = vshll.u32 %v32437, 13 (stack44)
        %v32444 = vshrl.u32 %v32437, 19 (stack45)
        %v32445 = vor.u32 %v32444, %v32443 (stack46)
        %v32446 = vxor.u32 %v32445, %v32441 (stack47)
        %v32449 = vadd.s32 %v32446, %v32441 (stack39)
        %v32451 = vshll.u32 %v32446, 15 (stack44)
        %v32452 = vshrl.u32 %v32446, 17 (stack45)
        %v32453 = vor.u32 %v32452, %v32451 (stack46)
        %v32454 = vxor.u32 %v32453, %v32449 (stack47)
        %v32457 = vadd.s32 %v32454, %v32449 (stack39)
        %v32459 = vshll.u32 %v32454, 26 (stack44)
        %v32460 = vshrl.u32 %v32454, 6 (stack45)
        %v32461 = vor.u32 %v32460, %v32459 (stack46)
        %v32462 = vxor.u32 %v32461, %v32457 (stack47)
        %v32465 = vadd.s32 %v32462, %v32457 (stack39)
        %v32469 = vadd.s32 %v32465, %v8 (stack39)
        %v32471 = vshll.u32 %v32462, 6 (stack44)
        %v32472 = vshrl.u32 %v32462, 26 (stack45)
        %v32473 = vor.u32 %v32472, %v32471 (stack46)
        %v32474 = vxor.u32 %v32473, %v32465 (stack47)
        %v32477 = vadd.s32 %v32474, %v10 (stack39)
        %v32481 = vadd.s32 5, %v32477 (stack39)
        %v32483 = vxor.u32 %v32481, %v32469 (stack47)
        %v32484 = vand.u32.u8 255, %v32483 (stack48)
        %v32485 = vand.u32 65535, %v32484 (stack49)
        %v32486 = vshrl.u32 %v32485, 1 (stack50)
        %v32487 = vor.u32 16256, %v32486 (stack46)
        %v32488 = vand.u32.u16 65535, %v32487 (stack51)
        %v119916 = vadd.low.f32.bf16 -1.0, %v32488 (stack52)
        %v32497 = vmul.f32 2.0, %v119916 (stack53)
        %v32501 = vadd.f32 -0.99609375, %v32497 (stack52)
        %v32505 = vmax.f32 %v32501, -0.99609375 (stack54)
        %v32507 = vand.u32 2147483647, %v32505 (stack55)
        %vm32510 = vcmp.eq.f32.partialorder %v32507, 1.0 (stack56)
        %v32515 = vmul.f32 inf, %v32505 (stack53)
        %v32517 = vxor.u32 2147483648, %v32505 (stack57)
        %v32520 = vmul.f32 %v32517, %v32505 (stack53)
        %v32522 = vadd.f32 1.0, %v32520 (stack58)
        %v32523 = vlog2.pop %v32522 (stack59)
        %v32524 = vmul.f32 0.6931472, %v32523 (stack60)
        %v32525 = vmul.f32 -0.5, %v32520 (stack61)
        %v32526 = vadd.f32 1.0, %v32525 (stack62)
        %v32527 = vmul.f32 %v32526, %v32520 (stack63)
        %v32528 = vand.u32 2147483647, %v32520 (stack64)
        %vm32529 = vcmp.lt.f32.partialorder %v32528, 0.0004427343 (stack65)
        %v32530 = vsel /*vm=*/%vm32529, /*on_true_vy=*/%v32527, /*on_false_vx=*/%v32524 (stack66)
        %v32531 = vxor.u32 2147483648, %v32530 (stack57)
        %vm32534 = vcmp.lt.f32.partialorder %v32531, 5.0 (stack56)
        %v32539 = vsel /*vm=*/%vm32534, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v32543 = vsel /*vm=*/%vm32534, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v32547 = vsel /*vm=*/%vm32534, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v32551 = vsel /*vm=*/%vm32534, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v32555 = vsel /*vm=*/%vm32534, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v32559 = vsel /*vm=*/%vm32534, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v32563 = vsel /*vm=*/%vm32534, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v32567 = vsel /*vm=*/%vm32534, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v32571 = vsel /*vm=*/%vm32534, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v32575 = vadd.f32 -2.5, %v32531 (stack52)
        %v32577 = vrsqrt.pop %v32531 (stack67)
        %v32578 = vmul.f32 %v32577, %v32531 (stack68)
        %vm32579 = vcmp.eq.f32.partialorder %v32531, inf (stack69)
        %v32580 = vsel /*vm=*/%vm32579, /*on_true_vy=*/%v32531, /*on_false_vx=*/%v32578 (stack70)
        %vm32581 = vcmp.eq.f32.partialorder %v32531, 0.0 (stack71)
        %v32582 = vand.u32 2147483648, %v32531 (stack72)
        %v32583 = vsel /*vm=*/%vm32581, /*on_true_vy=*/%v32582, /*on_false_vx=*/%v32580 (stack73)
        %v32586 = vadd.f32 -3.0, %v32583 (stack52)
        %v32590 = vsel /*vm=*/%vm32534, /*on_true_vy=*/%v32575, /*on_false_vx=*/%v32586 (stack43)
        %v32594 = vmul.f32 %v32590, %v32571 (stack53)
        %v32598 = vadd.f32 %v32594, %v32567 (stack52)
        %v32602 = vmul.f32 %v32598, %v32590 (stack53)
        %v32606 = vadd.f32 %v32602, %v32563 (stack52)
        %v32610 = vmul.f32 %v32606, %v32590 (stack53)
        %v32614 = vadd.f32 %v32610, %v32559 (stack52)
        %v32618 = vmul.f32 %v32614, %v32590 (stack53)
        %v32622 = vadd.f32 %v32618, %v32555 (stack52)
        %v32626 = vmul.f32 %v32622, %v32590 (stack53)
        %v32630 = vadd.f32 %v32626, %v32551 (stack52)
        %v32634 = vmul.f32 %v32630, %v32590 (stack53)
        %v32638 = vadd.f32 %v32634, %v32547 (stack52)
        %v32642 = vmul.f32 %v32638, %v32590 (stack53)
        %v32646 = vadd.f32 %v32642, %v32543 (stack52)
        %v32650 = vmul.f32 %v32646, %v32590 (stack53)
        %v32654 = vadd.f32 %v32650, %v32539 (stack52)
        %v32658 = vmul.f32 %v32654, %v32505 (stack53)
        %v32662 = vsel /*vm=*/%vm32510, /*on_true_vy=*/%v32515, /*on_false_vx=*/%v32658 (stack43)
        %v32666 = vmul.f32 1.4140625, %v32662 (stack53)
        %v32669 = vpack.c.bf16 0.0, %v32666 (stack74)
        %119917 = vst [vmem:[%s280 + $0x220] sm:$0xf] /*vst_source=*/%v32669 (stack75)
        %v32673 = vadd.s32 %v30365, %v2842 (stack39)
        %v32683 = vadd.s32 %v32673, %v415 (stack39)
        %vm32687 = vcmp.lt.u32.totalorder %v32683, %v32673 (stack42)
        %vm32692 = vcmp.lt.u32.totalorder %v32673, %v2842 (stack42)
        %v32697 = vadd.s32 %v30348, %v2829 (stack39)
        %v32701 = vadd.s32 1, %v32697 (stack39)
        %v32705 = vsel /*vm=*/%vm32692, /*on_true_vy=*/%v32701, /*on_false_vx=*/%v32697 (stack43)
        %v32709 = vadd.s32 1, %v32705 (stack39)
        %v32713 = vsel /*vm=*/%vm32687, /*on_true_vy=*/%v32709, /*on_false_vx=*/%v32705 (stack43)
        %v32718 = vadd.s32 %v32713, %v10 (stack39)
        %v32722 = vadd.s32 %v32683, %v9 (stack39)
        %v32726 = vadd.s32 %v32722, %v32718 (stack39)
        %v32728 = vshll.u32 %v32722, 13 (stack44)
        %v32729 = vshrl.u32 %v32722, 19 (stack45)
        %v32730 = vor.u32 %v32729, %v32728 (stack46)
        %v32731 = vxor.u32 %v32730, %v32726 (stack47)
        %v32734 = vadd.s32 %v32731, %v32726 (stack39)
        %v32736 = vshll.u32 %v32731, 15 (stack44)
        %v32737 = vshrl.u32 %v32731, 17 (stack45)
        %v32738 = vor.u32 %v32737, %v32736 (stack46)
        %v32739 = vxor.u32 %v32738, %v32734 (stack47)
        %v32742 = vadd.s32 %v32739, %v32734 (stack39)
        %v32744 = vshll.u32 %v32739, 26 (stack44)
        %v32745 = vshrl.u32 %v32739, 6 (stack45)
        %v32746 = vor.u32 %v32745, %v32744 (stack46)
        %v32747 = vxor.u32 %v32746, %v32742 (stack47)
        %v32750 = vadd.s32 %v32747, %v32742 (stack39)
        %v32754 = vadd.s32 %v32750, %v9 (stack39)
        %v32756 = vshll.u32 %v32747, 6 (stack44)
        %v32757 = vshrl.u32 %v32747, 26 (stack45)
        %v32758 = vor.u32 %v32757, %v32756 (stack46)
        %v32759 = vxor.u32 %v32758, %v32750 (stack47)
        %v32762 = vadd.s32 %v32759, %v8 (stack39)
        %v32766 = vadd.s32 1, %v32762 (stack39)
        %v32770 = vadd.s32 %v32766, %v32754 (stack39)
        %v32772 = vshll.u32 %v32766, 17 (stack44)
        %v32773 = vshrl.u32 %v32766, 15 (stack45)
        %v32774 = vor.u32 %v32773, %v32772 (stack46)
        %v32775 = vxor.u32 %v32774, %v32770 (stack47)
        %v32778 = vadd.s32 %v32775, %v32770 (stack39)
        %v32780 = vshll.u32 %v32775, 29 (stack44)
        %v32781 = vshrl.u32 %v32775, 3 (stack45)
        %v32782 = vor.u32 %v32781, %v32780 (stack46)
        %v32783 = vxor.u32 %v32782, %v32778 (stack47)
        %v32786 = vadd.s32 %v32783, %v32778 (stack39)
        %v32788 = vshll.u32 %v32783, 16 (stack44)
        %v32789 = vshrl.u32 %v32783, 16 (stack45)
        %v32790 = vor.u32 %v32789, %v32788 (stack46)
        %v32791 = vxor.u32 %v32790, %v32786 (stack47)
        %v32794 = vadd.s32 %v32791, %v32786 (stack39)
        %v32798 = vadd.s32 %v32794, %v8 (stack39)
        %v32800 = vshll.u32 %v32791, 24 (stack44)
        %v32801 = vshrl.u32 %v32791, 8 (stack45)
        %v32802 = vor.u32 %v32801, %v32800 (stack46)
        %v32803 = vxor.u32 %v32802, %v32794 (stack47)
        %v32806 = vadd.s32 %v32803, %v10 (stack39)
        %v32810 = vadd.s32 2, %v32806 (stack39)
        %v32814 = vadd.s32 %v32810, %v32798 (stack39)
        %v32816 = vshll.u32 %v32810, 13 (stack44)
        %v32817 = vshrl.u32 %v32810, 19 (stack45)
        %v32818 = vor.u32 %v32817, %v32816 (stack46)
        %v32819 = vxor.u32 %v32818, %v32814 (stack47)
        %v32822 = vadd.s32 %v32819, %v32814 (stack39)
        %v32824 = vshll.u32 %v32819, 15 (stack44)
        %v32825 = vshrl.u32 %v32819, 17 (stack45)
        %v32826 = vor.u32 %v32825, %v32824 (stack46)
        %v32827 = vxor.u32 %v32826, %v32822 (stack47)
        %v32830 = vadd.s32 %v32827, %v32822 (stack39)
        %v32832 = vshll.u32 %v32827, 26 (stack44)
        %v32833 = vshrl.u32 %v32827, 6 (stack45)
        %v32834 = vor.u32 %v32833, %v32832 (stack46)
        %v32835 = vxor.u32 %v32834, %v32830 (stack47)
        %v32838 = vadd.s32 %v32835, %v32830 (stack39)
        %v32842 = vadd.s32 %v32838, %v10 (stack39)
        %v32844 = vshll.u32 %v32835, 6 (stack44)
        %v32845 = vshrl.u32 %v32835, 26 (stack45)
        %v32846 = vor.u32 %v32845, %v32844 (stack46)
        %v32847 = vxor.u32 %v32846, %v32838 (stack47)
        %v32850 = vadd.s32 %v32847, %v9 (stack39)
        %v32854 = vadd.s32 3, %v32850 (stack39)
        %v32858 = vadd.s32 %v32854, %v32842 (stack39)
        %v32860 = vshll.u32 %v32854, 17 (stack44)
        %v32861 = vshrl.u32 %v32854, 15 (stack45)
        %v32862 = vor.u32 %v32861, %v32860 (stack46)
        %v32863 = vxor.u32 %v32862, %v32858 (stack47)
        %v32866 = vadd.s32 %v32863, %v32858 (stack39)
        %v32868 = vshll.u32 %v32863, 29 (stack44)
        %v32869 = vshrl.u32 %v32863, 3 (stack45)
        %v32870 = vor.u32 %v32869, %v32868 (stack46)
        %v32871 = vxor.u32 %v32870, %v32866 (stack47)
        %v32874 = vadd.s32 %v32871, %v32866 (stack39)
        %v32876 = vshll.u32 %v32871, 16 (stack44)
        %v32877 = vshrl.u32 %v32871, 16 (stack45)
        %v32878 = vor.u32 %v32877, %v32876 (stack46)
        %v32879 = vxor.u32 %v32878, %v32874 (stack47)
        %v32882 = vadd.s32 %v32879, %v32874 (stack39)
        %v32886 = vadd.s32 %v32882, %v9 (stack39)
        %v32888 = vshll.u32 %v32879, 24 (stack44)
        %v32889 = vshrl.u32 %v32879, 8 (stack45)
        %v32890 = vor.u32 %v32889, %v32888 (stack46)
        %v32891 = vxor.u32 %v32890, %v32882 (stack47)
        %v32894 = vadd.s32 %v32891, %v8 (stack39)
        %v32898 = vadd.s32 4, %v32894 (stack39)
        %v32902 = vadd.s32 %v32898, %v32886 (stack39)
        %v32904 = vshll.u32 %v32898, 13 (stack44)
        %v32905 = vshrl.u32 %v32898, 19 (stack45)
        %v32906 = vor.u32 %v32905, %v32904 (stack46)
        %v32907 = vxor.u32 %v32906, %v32902 (stack47)
        %v32910 = vadd.s32 %v32907, %v32902 (stack39)
        %v32912 = vshll.u32 %v32907, 15 (stack44)
        %v32913 = vshrl.u32 %v32907, 17 (stack45)
        %v32914 = vor.u32 %v32913, %v32912 (stack46)
        %v32915 = vxor.u32 %v32914, %v32910 (stack47)
        %v32918 = vadd.s32 %v32915, %v32910 (stack39)
        %v32920 = vshll.u32 %v32915, 26 (stack44)
        %v32921 = vshrl.u32 %v32915, 6 (stack45)
        %v32922 = vor.u32 %v32921, %v32920 (stack46)
        %v32923 = vxor.u32 %v32922, %v32918 (stack47)
        %v32926 = vadd.s32 %v32923, %v32918 (stack39)
        %v32930 = vadd.s32 %v32926, %v8 (stack39)
        %v32932 = vshll.u32 %v32923, 6 (stack44)
        %v32933 = vshrl.u32 %v32923, 26 (stack45)
        %v32934 = vor.u32 %v32933, %v32932 (stack46)
        %v32935 = vxor.u32 %v32934, %v32926 (stack47)
        %v32938 = vadd.s32 %v32935, %v10 (stack39)
        %v32942 = vadd.s32 5, %v32938 (stack39)
        %v32944 = vxor.u32 %v32942, %v32930 (stack47)
        %v32945 = vand.u32.u8 255, %v32944 (stack48)
        %v32946 = vand.u32 65535, %v32945 (stack49)
        %v32947 = vshrl.u32 %v32946, 1 (stack50)
        %v32948 = vor.u32 16256, %v32947 (stack46)
        %v32949 = vand.u32.u16 65535, %v32948 (stack51)
        %v119918 = vadd.low.f32.bf16 -1.0, %v32949 (stack52)
        %v32958 = vmul.f32 2.0, %v119918 (stack53)
        %v32962 = vadd.f32 -0.99609375, %v32958 (stack52)
        %v32966 = vmax.f32 %v32962, -0.99609375 (stack54)
        %v32968 = vand.u32 2147483647, %v32966 (stack55)
        %vm32971 = vcmp.eq.f32.partialorder %v32968, 1.0 (stack56)
        %v32976 = vmul.f32 inf, %v32966 (stack53)
        %v32978 = vxor.u32 2147483648, %v32966 (stack57)
        %v32981 = vmul.f32 %v32978, %v32966 (stack53)
        %v32983 = vadd.f32 1.0, %v32981 (stack58)
        %v32984 = vlog2.pop %v32983 (stack59)
        %v32985 = vmul.f32 0.6931472, %v32984 (stack60)
        %v32986 = vmul.f32 -0.5, %v32981 (stack61)
        %v32987 = vadd.f32 1.0, %v32986 (stack62)
        %v32988 = vmul.f32 %v32987, %v32981 (stack63)
        %v32989 = vand.u32 2147483647, %v32981 (stack64)
        %vm32990 = vcmp.lt.f32.partialorder %v32989, 0.0004427343 (stack65)
        %v32991 = vsel /*vm=*/%vm32990, /*on_true_vy=*/%v32988, /*on_false_vx=*/%v32985 (stack66)
        %v32992 = vxor.u32 2147483648, %v32991 (stack57)
        %vm32995 = vcmp.lt.f32.partialorder %v32992, 5.0 (stack56)
        %v33000 = vsel /*vm=*/%vm32995, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v33004 = vsel /*vm=*/%vm32995, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v33008 = vsel /*vm=*/%vm32995, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v33012 = vsel /*vm=*/%vm32995, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v33016 = vsel /*vm=*/%vm32995, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v33020 = vsel /*vm=*/%vm32995, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v33024 = vsel /*vm=*/%vm32995, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v33028 = vsel /*vm=*/%vm32995, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v33032 = vsel /*vm=*/%vm32995, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v33036 = vadd.f32 -2.5, %v32992 (stack52)
        %v33038 = vrsqrt.pop %v32992 (stack67)
        %v33039 = vmul.f32 %v33038, %v32992 (stack68)
        %vm33040 = vcmp.eq.f32.partialorder %v32992, inf (stack69)
        %v33041 = vsel /*vm=*/%vm33040, /*on_true_vy=*/%v32992, /*on_false_vx=*/%v33039 (stack70)
        %vm33042 = vcmp.eq.f32.partialorder %v32992, 0.0 (stack71)
        %v33043 = vand.u32 2147483648, %v32992 (stack72)
        %v33044 = vsel /*vm=*/%vm33042, /*on_true_vy=*/%v33043, /*on_false_vx=*/%v33041 (stack73)
        %v33047 = vadd.f32 -3.0, %v33044 (stack52)
        %v33051 = vsel /*vm=*/%vm32995, /*on_true_vy=*/%v33036, /*on_false_vx=*/%v33047 (stack43)
        %v33055 = vmul.f32 %v33051, %v33032 (stack53)
        %v33059 = vadd.f32 %v33055, %v33028 (stack52)
        %v33063 = vmul.f32 %v33059, %v33051 (stack53)
        %v33067 = vadd.f32 %v33063, %v33024 (stack52)
        %v33071 = vmul.f32 %v33067, %v33051 (stack53)
        %v33075 = vadd.f32 %v33071, %v33020 (stack52)
        %v33079 = vmul.f32 %v33075, %v33051 (stack53)
        %v33083 = vadd.f32 %v33079, %v33016 (stack52)
        %v33087 = vmul.f32 %v33083, %v33051 (stack53)
        %v33091 = vadd.f32 %v33087, %v33012 (stack52)
        %v33095 = vmul.f32 %v33091, %v33051 (stack53)
        %v33099 = vadd.f32 %v33095, %v33008 (stack52)
        %v33103 = vmul.f32 %v33099, %v33051 (stack53)
        %v33107 = vadd.f32 %v33103, %v33004 (stack52)
        %v33111 = vmul.f32 %v33107, %v33051 (stack53)
        %v33115 = vadd.f32 %v33111, %v33000 (stack52)
        %v33119 = vmul.f32 %v33115, %v32966 (stack53)
        %v33123 = vsel /*vm=*/%vm32971, /*on_true_vy=*/%v32976, /*on_false_vx=*/%v33119 (stack43)
        %v33127 = vmul.f32 1.4140625, %v33123 (stack53)
        %v33130 = vpack.c.bf16 0.0, %v33127 (stack74)
        %119919 = vst [vmem:[%s280 + $0x2a0] sm:$0xf] /*vst_source=*/%v33130 (stack75)
        %v33134 = vadd.s32 %v30365, %v3329 (stack39)
        %v33144 = vadd.s32 %v33134, %v415 (stack39)
        %vm33148 = vcmp.lt.u32.totalorder %v33144, %v33134 (stack42)
        %vm33153 = vcmp.lt.u32.totalorder %v33134, %v3329 (stack42)
        %v33158 = vadd.s32 %v30348, %v3316 (stack39)
        %v33162 = vadd.s32 1, %v33158 (stack39)
        %v33166 = vsel /*vm=*/%vm33153, /*on_true_vy=*/%v33162, /*on_false_vx=*/%v33158 (stack43)
        %v33170 = vadd.s32 1, %v33166 (stack39)
        %v33174 = vsel /*vm=*/%vm33148, /*on_true_vy=*/%v33170, /*on_false_vx=*/%v33166 (stack43)
        %v33179 = vadd.s32 %v33174, %v10 (stack39)
        %v33183 = vadd.s32 %v33144, %v9 (stack39)
        %v33187 = vadd.s32 %v33183, %v33179 (stack39)
        %v33189 = vshll.u32 %v33183, 13 (stack44)
        %v33190 = vshrl.u32 %v33183, 19 (stack45)
        %v33191 = vor.u32 %v33190, %v33189 (stack46)
        %v33192 = vxor.u32 %v33191, %v33187 (stack47)
        %v33195 = vadd.s32 %v33192, %v33187 (stack39)
        %v33197 = vshll.u32 %v33192, 15 (stack44)
        %v33198 = vshrl.u32 %v33192, 17 (stack45)
        %v33199 = vor.u32 %v33198, %v33197 (stack46)
        %v33200 = vxor.u32 %v33199, %v33195 (stack47)
        %v33203 = vadd.s32 %v33200, %v33195 (stack39)
        %v33205 = vshll.u32 %v33200, 26 (stack44)
        %v33206 = vshrl.u32 %v33200, 6 (stack45)
        %v33207 = vor.u32 %v33206, %v33205 (stack46)
        %v33208 = vxor.u32 %v33207, %v33203 (stack47)
        %v33211 = vadd.s32 %v33208, %v33203 (stack39)
        %v33215 = vadd.s32 %v33211, %v9 (stack39)
        %v33217 = vshll.u32 %v33208, 6 (stack44)
        %v33218 = vshrl.u32 %v33208, 26 (stack45)
        %v33219 = vor.u32 %v33218, %v33217 (stack46)
        %v33220 = vxor.u32 %v33219, %v33211 (stack47)
        %v33223 = vadd.s32 %v33220, %v8 (stack39)
        %v33227 = vadd.s32 1, %v33223 (stack39)
        %v33231 = vadd.s32 %v33227, %v33215 (stack39)
        %v33233 = vshll.u32 %v33227, 17 (stack44)
        %v33234 = vshrl.u32 %v33227, 15 (stack45)
        %v33235 = vor.u32 %v33234, %v33233 (stack46)
        %v33236 = vxor.u32 %v33235, %v33231 (stack47)
        %v33239 = vadd.s32 %v33236, %v33231 (stack39)
        %v33241 = vshll.u32 %v33236, 29 (stack44)
        %v33242 = vshrl.u32 %v33236, 3 (stack45)
        %v33243 = vor.u32 %v33242, %v33241 (stack46)
        %v33244 = vxor.u32 %v33243, %v33239 (stack47)
        %v33247 = vadd.s32 %v33244, %v33239 (stack39)
        %v33249 = vshll.u32 %v33244, 16 (stack44)
        %v33250 = vshrl.u32 %v33244, 16 (stack45)
        %v33251 = vor.u32 %v33250, %v33249 (stack46)
        %v33252 = vxor.u32 %v33251, %v33247 (stack47)
        %v33255 = vadd.s32 %v33252, %v33247 (stack39)
        %v33259 = vadd.s32 %v33255, %v8 (stack39)
        %v33261 = vshll.u32 %v33252, 24 (stack44)
        %v33262 = vshrl.u32 %v33252, 8 (stack45)
        %v33263 = vor.u32 %v33262, %v33261 (stack46)
        %v33264 = vxor.u32 %v33263, %v33255 (stack47)
        %v33267 = vadd.s32 %v33264, %v10 (stack39)
        %v33271 = vadd.s32 2, %v33267 (stack39)
        %v33275 = vadd.s32 %v33271, %v33259 (stack39)
        %v33277 = vshll.u32 %v33271, 13 (stack44)
        %v33278 = vshrl.u32 %v33271, 19 (stack45)
        %v33279 = vor.u32 %v33278, %v33277 (stack46)
        %v33280 = vxor.u32 %v33279, %v33275 (stack47)
        %v33283 = vadd.s32 %v33280, %v33275 (stack39)
        %v33285 = vshll.u32 %v33280, 15 (stack44)
        %v33286 = vshrl.u32 %v33280, 17 (stack45)
        %v33287 = vor.u32 %v33286, %v33285 (stack46)
        %v33288 = vxor.u32 %v33287, %v33283 (stack47)
        %v33291 = vadd.s32 %v33288, %v33283 (stack39)
        %v33293 = vshll.u32 %v33288, 26 (stack44)
        %v33294 = vshrl.u32 %v33288, 6 (stack45)
        %v33295 = vor.u32 %v33294, %v33293 (stack46)
        %v33296 = vxor.u32 %v33295, %v33291 (stack47)
        %v33299 = vadd.s32 %v33296, %v33291 (stack39)
        %v33303 = vadd.s32 %v33299, %v10 (stack39)
        %v33305 = vshll.u32 %v33296, 6 (stack44)
        %v33306 = vshrl.u32 %v33296, 26 (stack45)
        %v33307 = vor.u32 %v33306, %v33305 (stack46)
        %v33308 = vxor.u32 %v33307, %v33299 (stack47)
        %v33311 = vadd.s32 %v33308, %v9 (stack39)
        %v33315 = vadd.s32 3, %v33311 (stack39)
        %v33319 = vadd.s32 %v33315, %v33303 (stack39)
        %v33321 = vshll.u32 %v33315, 17 (stack44)
        %v33322 = vshrl.u32 %v33315, 15 (stack45)
        %v33323 = vor.u32 %v33322, %v33321 (stack46)
        %v33324 = vxor.u32 %v33323, %v33319 (stack47)
        %v33327 = vadd.s32 %v33324, %v33319 (stack39)
        %v33329 = vshll.u32 %v33324, 29 (stack44)
        %v33330 = vshrl.u32 %v33324, 3 (stack45)
        %v33331 = vor.u32 %v33330, %v33329 (stack46)
        %v33332 = vxor.u32 %v33331, %v33327 (stack47)
        %v33335 = vadd.s32 %v33332, %v33327 (stack39)
        %v33337 = vshll.u32 %v33332, 16 (stack44)
        %v33338 = vshrl.u32 %v33332, 16 (stack45)
        %v33339 = vor.u32 %v33338, %v33337 (stack46)
        %v33340 = vxor.u32 %v33339, %v33335 (stack47)
        %v33343 = vadd.s32 %v33340, %v33335 (stack39)
        %v33347 = vadd.s32 %v33343, %v9 (stack39)
        %v33349 = vshll.u32 %v33340, 24 (stack44)
        %v33350 = vshrl.u32 %v33340, 8 (stack45)
        %v33351 = vor.u32 %v33350, %v33349 (stack46)
        %v33352 = vxor.u32 %v33351, %v33343 (stack47)
        %v33355 = vadd.s32 %v33352, %v8 (stack39)
        %v33359 = vadd.s32 4, %v33355 (stack39)
        %v33363 = vadd.s32 %v33359, %v33347 (stack39)
        %v33365 = vshll.u32 %v33359, 13 (stack44)
        %v33366 = vshrl.u32 %v33359, 19 (stack45)
        %v33367 = vor.u32 %v33366, %v33365 (stack46)
        %v33368 = vxor.u32 %v33367, %v33363 (stack47)
        %v33371 = vadd.s32 %v33368, %v33363 (stack39)
        %v33373 = vshll.u32 %v33368, 15 (stack44)
        %v33374 = vshrl.u32 %v33368, 17 (stack45)
        %v33375 = vor.u32 %v33374, %v33373 (stack46)
        %v33376 = vxor.u32 %v33375, %v33371 (stack47)
        %v33379 = vadd.s32 %v33376, %v33371 (stack39)
        %v33381 = vshll.u32 %v33376, 26 (stack44)
        %v33382 = vshrl.u32 %v33376, 6 (stack45)
        %v33383 = vor.u32 %v33382, %v33381 (stack46)
        %v33384 = vxor.u32 %v33383, %v33379 (stack47)
        %v33387 = vadd.s32 %v33384, %v33379 (stack39)
        %v33391 = vadd.s32 %v33387, %v8 (stack39)
        %v33393 = vshll.u32 %v33384, 6 (stack44)
        %v33394 = vshrl.u32 %v33384, 26 (stack45)
        %v33395 = vor.u32 %v33394, %v33393 (stack46)
        %v33396 = vxor.u32 %v33395, %v33387 (stack47)
        %v33399 = vadd.s32 %v33396, %v10 (stack39)
        %v33403 = vadd.s32 5, %v33399 (stack39)
        %v33405 = vxor.u32 %v33403, %v33391 (stack47)
        %v33406 = vand.u32.u8 255, %v33405 (stack48)
        %v33407 = vand.u32 65535, %v33406 (stack49)
        %v33408 = vshrl.u32 %v33407, 1 (stack50)
        %v33409 = vor.u32 16256, %v33408 (stack46)
        %v33410 = vand.u32.u16 65535, %v33409 (stack51)
        %v119920 = vadd.low.f32.bf16 -1.0, %v33410 (stack52)
        %v33419 = vmul.f32 2.0, %v119920 (stack53)
        %v33423 = vadd.f32 -0.99609375, %v33419 (stack52)
        %v33427 = vmax.f32 %v33423, -0.99609375 (stack54)
        %v33429 = vand.u32 2147483647, %v33427 (stack55)
        %vm33432 = vcmp.eq.f32.partialorder %v33429, 1.0 (stack56)
        %v33437 = vmul.f32 inf, %v33427 (stack53)
        %v33439 = vxor.u32 2147483648, %v33427 (stack57)
        %v33442 = vmul.f32 %v33439, %v33427 (stack53)
        %v33444 = vadd.f32 1.0, %v33442 (stack58)
        %v33445 = vlog2.pop %v33444 (stack59)
        %v33446 = vmul.f32 0.6931472, %v33445 (stack60)
        %v33447 = vmul.f32 -0.5, %v33442 (stack61)
        %v33448 = vadd.f32 1.0, %v33447 (stack62)
        %v33449 = vmul.f32 %v33448, %v33442 (stack63)
        %v33450 = vand.u32 2147483647, %v33442 (stack64)
        %vm33451 = vcmp.lt.f32.partialorder %v33450, 0.0004427343 (stack65)
        %v33452 = vsel /*vm=*/%vm33451, /*on_true_vy=*/%v33449, /*on_false_vx=*/%v33446 (stack66)
        %v33453 = vxor.u32 2147483648, %v33452 (stack57)
        %vm33456 = vcmp.lt.f32.partialorder %v33453, 5.0 (stack56)
        %v33461 = vsel /*vm=*/%vm33456, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v33465 = vsel /*vm=*/%vm33456, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v33469 = vsel /*vm=*/%vm33456, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v33473 = vsel /*vm=*/%vm33456, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v33477 = vsel /*vm=*/%vm33456, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v33481 = vsel /*vm=*/%vm33456, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v33485 = vsel /*vm=*/%vm33456, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v33489 = vsel /*vm=*/%vm33456, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v33493 = vsel /*vm=*/%vm33456, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v33497 = vadd.f32 -2.5, %v33453 (stack52)
        %v33499 = vrsqrt.pop %v33453 (stack67)
        %v33500 = vmul.f32 %v33499, %v33453 (stack68)
        %vm33501 = vcmp.eq.f32.partialorder %v33453, inf (stack69)
        %v33502 = vsel /*vm=*/%vm33501, /*on_true_vy=*/%v33453, /*on_false_vx=*/%v33500 (stack70)
        %vm33503 = vcmp.eq.f32.partialorder %v33453, 0.0 (stack71)
        %v33504 = vand.u32 2147483648, %v33453 (stack72)
        %v33505 = vsel /*vm=*/%vm33503, /*on_true_vy=*/%v33504, /*on_false_vx=*/%v33502 (stack73)
        %v33508 = vadd.f32 -3.0, %v33505 (stack52)
        %v33512 = vsel /*vm=*/%vm33456, /*on_true_vy=*/%v33497, /*on_false_vx=*/%v33508 (stack43)
        %v33516 = vmul.f32 %v33512, %v33493 (stack53)
        %v33520 = vadd.f32 %v33516, %v33489 (stack52)
        %v33524 = vmul.f32 %v33520, %v33512 (stack53)
        %v33528 = vadd.f32 %v33524, %v33485 (stack52)
        %v33532 = vmul.f32 %v33528, %v33512 (stack53)
        %v33536 = vadd.f32 %v33532, %v33481 (stack52)
        %v33540 = vmul.f32 %v33536, %v33512 (stack53)
        %v33544 = vadd.f32 %v33540, %v33477 (stack52)
        %v33548 = vmul.f32 %v33544, %v33512 (stack53)
        %v33552 = vadd.f32 %v33548, %v33473 (stack52)
        %v33556 = vmul.f32 %v33552, %v33512 (stack53)
        %v33560 = vadd.f32 %v33556, %v33469 (stack52)
        %v33564 = vmul.f32 %v33560, %v33512 (stack53)
        %v33568 = vadd.f32 %v33564, %v33465 (stack52)
        %v33572 = vmul.f32 %v33568, %v33512 (stack53)
        %v33576 = vadd.f32 %v33572, %v33461 (stack52)
        %v33580 = vmul.f32 %v33576, %v33427 (stack53)
        %v33584 = vsel /*vm=*/%vm33432, /*on_true_vy=*/%v33437, /*on_false_vx=*/%v33580 (stack43)
        %v33588 = vmul.f32 1.4140625, %v33584 (stack53)
        %v33591 = vpack.c.bf16 0.0, %v33588 (stack74)
        %119921 = vst [vmem:[%s280 + $0x320] sm:$0xf] /*vst_source=*/%v33591 (stack75)
        %v33595 = vadd.s32 %v30365, %v3816 (stack39)
        %v33605 = vadd.s32 %v33595, %v415 (stack39)
        %vm33609 = vcmp.lt.u32.totalorder %v33605, %v33595 (stack42)
        %vm33614 = vcmp.lt.u32.totalorder %v33595, %v3816 (stack42)
        %v33619 = vadd.s32 %v30348, %v3803 (stack39)
        %v33623 = vadd.s32 1, %v33619 (stack39)
        %v33627 = vsel /*vm=*/%vm33614, /*on_true_vy=*/%v33623, /*on_false_vx=*/%v33619 (stack43)
        %v33631 = vadd.s32 1, %v33627 (stack39)
        %v33635 = vsel /*vm=*/%vm33609, /*on_true_vy=*/%v33631, /*on_false_vx=*/%v33627 (stack43)
        %v33640 = vadd.s32 %v33635, %v10 (stack39)
        %v33644 = vadd.s32 %v33605, %v9 (stack39)
        %v33648 = vadd.s32 %v33644, %v33640 (stack39)
        %v33650 = vshll.u32 %v33644, 13 (stack44)
        %v33651 = vshrl.u32 %v33644, 19 (stack45)
        %v33652 = vor.u32 %v33651, %v33650 (stack46)
        %v33653 = vxor.u32 %v33652, %v33648 (stack47)
        %v33656 = vadd.s32 %v33653, %v33648 (stack39)
        %v33658 = vshll.u32 %v33653, 15 (stack44)
        %v33659 = vshrl.u32 %v33653, 17 (stack45)
        %v33660 = vor.u32 %v33659, %v33658 (stack46)
        %v33661 = vxor.u32 %v33660, %v33656 (stack47)
        %v33664 = vadd.s32 %v33661, %v33656 (stack39)
        %v33666 = vshll.u32 %v33661, 26 (stack44)
        %v33667 = vshrl.u32 %v33661, 6 (stack45)
        %v33668 = vor.u32 %v33667, %v33666 (stack46)
        %v33669 = vxor.u32 %v33668, %v33664 (stack47)
        %v33672 = vadd.s32 %v33669, %v33664 (stack39)
        %v33676 = vadd.s32 %v33672, %v9 (stack39)
        %v33678 = vshll.u32 %v33669, 6 (stack44)
        %v33679 = vshrl.u32 %v33669, 26 (stack45)
        %v33680 = vor.u32 %v33679, %v33678 (stack46)
        %v33681 = vxor.u32 %v33680, %v33672 (stack47)
        %v33684 = vadd.s32 %v33681, %v8 (stack39)
        %v33688 = vadd.s32 1, %v33684 (stack39)
        %v33692 = vadd.s32 %v33688, %v33676 (stack39)
        %v33694 = vshll.u32 %v33688, 17 (stack44)
        %v33695 = vshrl.u32 %v33688, 15 (stack45)
        %v33696 = vor.u32 %v33695, %v33694 (stack46)
        %v33697 = vxor.u32 %v33696, %v33692 (stack47)
        %v33700 = vadd.s32 %v33697, %v33692 (stack39)
        %v33702 = vshll.u32 %v33697, 29 (stack44)
        %v33703 = vshrl.u32 %v33697, 3 (stack45)
        %v33704 = vor.u32 %v33703, %v33702 (stack46)
        %v33705 = vxor.u32 %v33704, %v33700 (stack47)
        %v33708 = vadd.s32 %v33705, %v33700 (stack39)
        %v33710 = vshll.u32 %v33705, 16 (stack44)
        %v33711 = vshrl.u32 %v33705, 16 (stack45)
        %v33712 = vor.u32 %v33711, %v33710 (stack46)
        %v33713 = vxor.u32 %v33712, %v33708 (stack47)
        %v33716 = vadd.s32 %v33713, %v33708 (stack39)
        %v33720 = vadd.s32 %v33716, %v8 (stack39)
        %v33722 = vshll.u32 %v33713, 24 (stack44)
        %v33723 = vshrl.u32 %v33713, 8 (stack45)
        %v33724 = vor.u32 %v33723, %v33722 (stack46)
        %v33725 = vxor.u32 %v33724, %v33716 (stack47)
        %v33728 = vadd.s32 %v33725, %v10 (stack39)
        %v33732 = vadd.s32 2, %v33728 (stack39)
        %v33736 = vadd.s32 %v33732, %v33720 (stack39)
        %v33738 = vshll.u32 %v33732, 13 (stack44)
        %v33739 = vshrl.u32 %v33732, 19 (stack45)
        %v33740 = vor.u32 %v33739, %v33738 (stack46)
        %v33741 = vxor.u32 %v33740, %v33736 (stack47)
        %v33744 = vadd.s32 %v33741, %v33736 (stack39)
        %v33746 = vshll.u32 %v33741, 15 (stack44)
        %v33747 = vshrl.u32 %v33741, 17 (stack45)
        %v33748 = vor.u32 %v33747, %v33746 (stack46)
        %v33749 = vxor.u32 %v33748, %v33744 (stack47)
        %v33752 = vadd.s32 %v33749, %v33744 (stack39)
        %v33754 = vshll.u32 %v33749, 26 (stack44)
        %v33755 = vshrl.u32 %v33749, 6 (stack45)
        %v33756 = vor.u32 %v33755, %v33754 (stack46)
        %v33757 = vxor.u32 %v33756, %v33752 (stack47)
        %v33760 = vadd.s32 %v33757, %v33752 (stack39)
        %v33764 = vadd.s32 %v33760, %v10 (stack39)
        %v33766 = vshll.u32 %v33757, 6 (stack44)
        %v33767 = vshrl.u32 %v33757, 26 (stack45)
        %v33768 = vor.u32 %v33767, %v33766 (stack46)
        %v33769 = vxor.u32 %v33768, %v33760 (stack47)
        %v33772 = vadd.s32 %v33769, %v9 (stack39)
        %v33776 = vadd.s32 3, %v33772 (stack39)
        %v33780 = vadd.s32 %v33776, %v33764 (stack39)
        %v33782 = vshll.u32 %v33776, 17 (stack44)
        %v33783 = vshrl.u32 %v33776, 15 (stack45)
        %v33784 = vor.u32 %v33783, %v33782 (stack46)
        %v33785 = vxor.u32 %v33784, %v33780 (stack47)
        %v33788 = vadd.s32 %v33785, %v33780 (stack39)
        %v33790 = vshll.u32 %v33785, 29 (stack44)
        %v33791 = vshrl.u32 %v33785, 3 (stack45)
        %v33792 = vor.u32 %v33791, %v33790 (stack46)
        %v33793 = vxor.u32 %v33792, %v33788 (stack47)
        %v33796 = vadd.s32 %v33793, %v33788 (stack39)
        %v33798 = vshll.u32 %v33793, 16 (stack44)
        %v33799 = vshrl.u32 %v33793, 16 (stack45)
        %v33800 = vor.u32 %v33799, %v33798 (stack46)
        %v33801 = vxor.u32 %v33800, %v33796 (stack47)
        %v33804 = vadd.s32 %v33801, %v33796 (stack39)
        %v33808 = vadd.s32 %v33804, %v9 (stack39)
        %v33810 = vshll.u32 %v33801, 24 (stack44)
        %v33811 = vshrl.u32 %v33801, 8 (stack45)
        %v33812 = vor.u32 %v33811, %v33810 (stack46)
        %v33813 = vxor.u32 %v33812, %v33804 (stack47)
        %v33816 = vadd.s32 %v33813, %v8 (stack39)
        %v33820 = vadd.s32 4, %v33816 (stack39)
        %v33824 = vadd.s32 %v33820, %v33808 (stack39)
        %v33826 = vshll.u32 %v33820, 13 (stack44)
        %v33827 = vshrl.u32 %v33820, 19 (stack45)
        %v33828 = vor.u32 %v33827, %v33826 (stack46)
        %v33829 = vxor.u32 %v33828, %v33824 (stack47)
        %v33832 = vadd.s32 %v33829, %v33824 (stack39)
        %v33834 = vshll.u32 %v33829, 15 (stack44)
        %v33835 = vshrl.u32 %v33829, 17 (stack45)
        %v33836 = vor.u32 %v33835, %v33834 (stack46)
        %v33837 = vxor.u32 %v33836, %v33832 (stack47)
        %v33840 = vadd.s32 %v33837, %v33832 (stack39)
        %v33842 = vshll.u32 %v33837, 26 (stack44)
        %v33843 = vshrl.u32 %v33837, 6 (stack45)
        %v33844 = vor.u32 %v33843, %v33842 (stack46)
        %v33845 = vxor.u32 %v33844, %v33840 (stack47)
        %v33848 = vadd.s32 %v33845, %v33840 (stack39)
        %v33852 = vadd.s32 %v33848, %v8 (stack39)
        %v33854 = vshll.u32 %v33845, 6 (stack44)
        %v33855 = vshrl.u32 %v33845, 26 (stack45)
        %v33856 = vor.u32 %v33855, %v33854 (stack46)
        %v33857 = vxor.u32 %v33856, %v33848 (stack47)
        %v33860 = vadd.s32 %v33857, %v10 (stack39)
        %v33864 = vadd.s32 5, %v33860 (stack39)
        %v33866 = vxor.u32 %v33864, %v33852 (stack47)
        %v33867 = vand.u32.u8 255, %v33866 (stack48)
        %v33868 = vand.u32 65535, %v33867 (stack49)
        %v33869 = vshrl.u32 %v33868, 1 (stack50)
        %v33870 = vor.u32 16256, %v33869 (stack46)
        %v33871 = vand.u32.u16 65535, %v33870 (stack51)
        %v119922 = vadd.low.f32.bf16 -1.0, %v33871 (stack52)
        %v33880 = vmul.f32 2.0, %v119922 (stack53)
        %v33884 = vadd.f32 -0.99609375, %v33880 (stack52)
        %v33888 = vmax.f32 %v33884, -0.99609375 (stack54)
        %v33890 = vand.u32 2147483647, %v33888 (stack55)
        %vm33893 = vcmp.eq.f32.partialorder %v33890, 1.0 (stack56)
        %v33898 = vmul.f32 inf, %v33888 (stack53)
        %v33900 = vxor.u32 2147483648, %v33888 (stack57)
        %v33903 = vmul.f32 %v33900, %v33888 (stack53)
        %v33905 = vadd.f32 1.0, %v33903 (stack58)
        %v33906 = vlog2.pop %v33905 (stack59)
        %v33907 = vmul.f32 0.6931472, %v33906 (stack60)
        %v33908 = vmul.f32 -0.5, %v33903 (stack61)
        %v33909 = vadd.f32 1.0, %v33908 (stack62)
        %v33910 = vmul.f32 %v33909, %v33903 (stack63)
        %v33911 = vand.u32 2147483647, %v33903 (stack64)
        %vm33912 = vcmp.lt.f32.partialorder %v33911, 0.0004427343 (stack65)
        %v33913 = vsel /*vm=*/%vm33912, /*on_true_vy=*/%v33910, /*on_false_vx=*/%v33907 (stack66)
        %v33914 = vxor.u32 2147483648, %v33913 (stack57)
        %vm33917 = vcmp.lt.f32.partialorder %v33914, 5.0 (stack56)
        %v33922 = vsel /*vm=*/%vm33917, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v33926 = vsel /*vm=*/%vm33917, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v33930 = vsel /*vm=*/%vm33917, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v33934 = vsel /*vm=*/%vm33917, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v33938 = vsel /*vm=*/%vm33917, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v33942 = vsel /*vm=*/%vm33917, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v33946 = vsel /*vm=*/%vm33917, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v33950 = vsel /*vm=*/%vm33917, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v33954 = vsel /*vm=*/%vm33917, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v33958 = vadd.f32 -2.5, %v33914 (stack52)
        %v33960 = vrsqrt.pop %v33914 (stack67)
        %v33961 = vmul.f32 %v33960, %v33914 (stack68)
        %vm33962 = vcmp.eq.f32.partialorder %v33914, inf (stack69)
        %v33963 = vsel /*vm=*/%vm33962, /*on_true_vy=*/%v33914, /*on_false_vx=*/%v33961 (stack70)
        %vm33964 = vcmp.eq.f32.partialorder %v33914, 0.0 (stack71)
        %v33965 = vand.u32 2147483648, %v33914 (stack72)
        %v33966 = vsel /*vm=*/%vm33964, /*on_true_vy=*/%v33965, /*on_false_vx=*/%v33963 (stack73)
        %v33969 = vadd.f32 -3.0, %v33966 (stack52)
        %v33973 = vsel /*vm=*/%vm33917, /*on_true_vy=*/%v33958, /*on_false_vx=*/%v33969 (stack43)
        %v33977 = vmul.f32 %v33973, %v33954 (stack53)
        %v33981 = vadd.f32 %v33977, %v33950 (stack52)
        %v33985 = vmul.f32 %v33981, %v33973 (stack53)
        %v33989 = vadd.f32 %v33985, %v33946 (stack52)
        %v33993 = vmul.f32 %v33989, %v33973 (stack53)
        %v33997 = vadd.f32 %v33993, %v33942 (stack52)
        %v34001 = vmul.f32 %v33997, %v33973 (stack53)
        %v34005 = vadd.f32 %v34001, %v33938 (stack52)
        %v34009 = vmul.f32 %v34005, %v33973 (stack53)
        %v34013 = vadd.f32 %v34009, %v33934 (stack52)
        %v34017 = vmul.f32 %v34013, %v33973 (stack53)
        %v34021 = vadd.f32 %v34017, %v33930 (stack52)
        %v34025 = vmul.f32 %v34021, %v33973 (stack53)
        %v34029 = vadd.f32 %v34025, %v33926 (stack52)
        %v34033 = vmul.f32 %v34029, %v33973 (stack53)
        %v34037 = vadd.f32 %v34033, %v33922 (stack52)
        %v34041 = vmul.f32 %v34037, %v33888 (stack53)
        %v34045 = vsel /*vm=*/%vm33893, /*on_true_vy=*/%v33898, /*on_false_vx=*/%v34041 (stack43)
        %v34049 = vmul.f32 1.4140625, %v34045 (stack53)
        %v34052 = vpack.c.bf16 0.0, %v34049 (stack74)
        %119923 = vst [vmem:[%s280 + $0x3a0] sm:$0xf] /*vst_source=*/%v34052 (stack75)
        %s34054 = sadd.s32 72, %s120390 (stack76)
        %s34055 = sshrl.u32 %s34054, 10 (stack23)
        %p119924 = scmp.gt.s32.totalorder %s34055, 1 (stack24)
        %s34057 = scalar_select /*predicate=*/%p119924, /*on_true=*/1, /*on_false=*/%s34055 (stack25)
        %s34058 = sand.u32 1023, %s34054 /* smod.u32 w/div 1024 */ (stack26)
        %s34059 = sshrl.u32 %s34058, 7 (stack27)
        %s34060 = sand.u32 127, %s34058 /* smod.u32 w/div 128 */ (stack28)
        %s119925 = sshll.u32 %s34057, 3 (stack29)
        %s34062 = scalar_lea.vmem %s3, %s119925 (stack30)
        %s34064 = scalar_lea.vmem %s34062, %s34059 (stack31)
        %v34065 = vld [vmem:[%s34064] ss:$0 sm:$0xff] (stack32)
        %s34066 = sand.u32 255, %s34060 (stack33)
        %s34068 = sor.u32 256, %s34066 (stack34)
        %34069 = vbcast.lane.b32.xlu0 %v34065, %s34068 (stack35)
        %v34070 = vpop.permute.xlu0 %34069 (stack36)
        %s34079 = scalar_lea.vmem %s5, %s119925 (stack30)
        %s34081 = scalar_lea.vmem %s34079, %s34059 (stack31)
        %v34082 = vld [vmem:[%s34081] ss:$0 sm:$0xff] (stack32)
        %34086 = vbcast.lane.b32.xlu0 %v34082, %s34068 (stack35)
        %v34087 = vpop.permute.xlu0 %34086 (stack36)
        %v34090 = vadd.s32 %v34087, %v408 (stack39)
        %v34100 = vadd.s32 %v34090, %v415 (stack39)
        %vm34104 = vcmp.lt.u32.totalorder %v34100, %v34090 (stack42)
        %vm34109 = vcmp.lt.u32.totalorder %v34090, %v408 (stack42)
        %v34114 = vadd.s32 %v34070, %v380 (stack39)
        %v34118 = vadd.s32 1, %v34114 (stack39)
        %v34122 = vsel /*vm=*/%vm34109, /*on_true_vy=*/%v34118, /*on_false_vx=*/%v34114 (stack43)
        %v34126 = vadd.s32 1, %v34122 (stack39)
        %v34130 = vsel /*vm=*/%vm34104, /*on_true_vy=*/%v34126, /*on_false_vx=*/%v34122 (stack43)
        %v34135 = vadd.s32 %v34130, %v10 (stack39)
        %v34139 = vadd.s32 %v34100, %v9 (stack39)
        %v34143 = vadd.s32 %v34139, %v34135 (stack39)
        %v34145 = vshll.u32 %v34139, 13 (stack44)
        %v34146 = vshrl.u32 %v34139, 19 (stack45)
        %v34147 = vor.u32 %v34146, %v34145 (stack46)
        %v34148 = vxor.u32 %v34147, %v34143 (stack47)
        %v34151 = vadd.s32 %v34148, %v34143 (stack39)
        %v34153 = vshll.u32 %v34148, 15 (stack44)
        %v34154 = vshrl.u32 %v34148, 17 (stack45)
        %v34155 = vor.u32 %v34154, %v34153 (stack46)
        %v34156 = vxor.u32 %v34155, %v34151 (stack47)
        %v34159 = vadd.s32 %v34156, %v34151 (stack39)
        %v34161 = vshll.u32 %v34156, 26 (stack44)
        %v34162 = vshrl.u32 %v34156, 6 (stack45)
        %v34163 = vor.u32 %v34162, %v34161 (stack46)
        %v34164 = vxor.u32 %v34163, %v34159 (stack47)
        %v34167 = vadd.s32 %v34164, %v34159 (stack39)
        %v34171 = vadd.s32 %v34167, %v9 (stack39)
        %v34173 = vshll.u32 %v34164, 6 (stack44)
        %v34174 = vshrl.u32 %v34164, 26 (stack45)
        %v34175 = vor.u32 %v34174, %v34173 (stack46)
        %v34176 = vxor.u32 %v34175, %v34167 (stack47)
        %v34179 = vadd.s32 %v34176, %v8 (stack39)
        %v34183 = vadd.s32 1, %v34179 (stack39)
        %v34187 = vadd.s32 %v34183, %v34171 (stack39)
        %v34189 = vshll.u32 %v34183, 17 (stack44)
        %v34190 = vshrl.u32 %v34183, 15 (stack45)
        %v34191 = vor.u32 %v34190, %v34189 (stack46)
        %v34192 = vxor.u32 %v34191, %v34187 (stack47)
        %v34195 = vadd.s32 %v34192, %v34187 (stack39)
        %v34197 = vshll.u32 %v34192, 29 (stack44)
        %v34198 = vshrl.u32 %v34192, 3 (stack45)
        %v34199 = vor.u32 %v34198, %v34197 (stack46)
        %v34200 = vxor.u32 %v34199, %v34195 (stack47)
        %v34203 = vadd.s32 %v34200, %v34195 (stack39)
        %v34205 = vshll.u32 %v34200, 16 (stack44)
        %v34206 = vshrl.u32 %v34200, 16 (stack45)
        %v34207 = vor.u32 %v34206, %v34205 (stack46)
        %v34208 = vxor.u32 %v34207, %v34203 (stack47)
        %v34211 = vadd.s32 %v34208, %v34203 (stack39)
        %v34215 = vadd.s32 %v34211, %v8 (stack39)
        %v34217 = vshll.u32 %v34208, 24 (stack44)
        %v34218 = vshrl.u32 %v34208, 8 (stack45)
        %v34219 = vor.u32 %v34218, %v34217 (stack46)
        %v34220 = vxor.u32 %v34219, %v34211 (stack47)
        %v34223 = vadd.s32 %v34220, %v10 (stack39)
        %v34227 = vadd.s32 2, %v34223 (stack39)
        %v34231 = vadd.s32 %v34227, %v34215 (stack39)
        %v34233 = vshll.u32 %v34227, 13 (stack44)
        %v34234 = vshrl.u32 %v34227, 19 (stack45)
        %v34235 = vor.u32 %v34234, %v34233 (stack46)
        %v34236 = vxor.u32 %v34235, %v34231 (stack47)
        %v34239 = vadd.s32 %v34236, %v34231 (stack39)
        %v34241 = vshll.u32 %v34236, 15 (stack44)
        %v34242 = vshrl.u32 %v34236, 17 (stack45)
        %v34243 = vor.u32 %v34242, %v34241 (stack46)
        %v34244 = vxor.u32 %v34243, %v34239 (stack47)
        %v34247 = vadd.s32 %v34244, %v34239 (stack39)
        %v34249 = vshll.u32 %v34244, 26 (stack44)
        %v34250 = vshrl.u32 %v34244, 6 (stack45)
        %v34251 = vor.u32 %v34250, %v34249 (stack46)
        %v34252 = vxor.u32 %v34251, %v34247 (stack47)
        %v34255 = vadd.s32 %v34252, %v34247 (stack39)
        %v34259 = vadd.s32 %v34255, %v10 (stack39)
        %v34261 = vshll.u32 %v34252, 6 (stack44)
        %v34262 = vshrl.u32 %v34252, 26 (stack45)
        %v34263 = vor.u32 %v34262, %v34261 (stack46)
        %v34264 = vxor.u32 %v34263, %v34255 (stack47)
        %v34267 = vadd.s32 %v34264, %v9 (stack39)
        %v34271 = vadd.s32 3, %v34267 (stack39)
        %v34275 = vadd.s32 %v34271, %v34259 (stack39)
        %v34277 = vshll.u32 %v34271, 17 (stack44)
        %v34278 = vshrl.u32 %v34271, 15 (stack45)
        %v34279 = vor.u32 %v34278, %v34277 (stack46)
        %v34280 = vxor.u32 %v34279, %v34275 (stack47)
        %v34283 = vadd.s32 %v34280, %v34275 (stack39)
        %v34285 = vshll.u32 %v34280, 29 (stack44)
        %v34286 = vshrl.u32 %v34280, 3 (stack45)
        %v34287 = vor.u32 %v34286, %v34285 (stack46)
        %v34288 = vxor.u32 %v34287, %v34283 (stack47)
        %v34291 = vadd.s32 %v34288, %v34283 (stack39)
        %v34293 = vshll.u32 %v34288, 16 (stack44)
        %v34294 = vshrl.u32 %v34288, 16 (stack45)
        %v34295 = vor.u32 %v34294, %v34293 (stack46)
        %v34296 = vxor.u32 %v34295, %v34291 (stack47)
        %v34299 = vadd.s32 %v34296, %v34291 (stack39)
        %v34303 = vadd.s32 %v34299, %v9 (stack39)
        %v34305 = vshll.u32 %v34296, 24 (stack44)
        %v34306 = vshrl.u32 %v34296, 8 (stack45)
        %v34307 = vor.u32 %v34306, %v34305 (stack46)
        %v34308 = vxor.u32 %v34307, %v34299 (stack47)
        %v34311 = vadd.s32 %v34308, %v8 (stack39)
        %v34315 = vadd.s32 4, %v34311 (stack39)
        %v34319 = vadd.s32 %v34315, %v34303 (stack39)
        %v34321 = vshll.u32 %v34315, 13 (stack44)
        %v34322 = vshrl.u32 %v34315, 19 (stack45)
        %v34323 = vor.u32 %v34322, %v34321 (stack46)
        %v34324 = vxor.u32 %v34323, %v34319 (stack47)
        %v34327 = vadd.s32 %v34324, %v34319 (stack39)
        %v34329 = vshll.u32 %v34324, 15 (stack44)
        %v34330 = vshrl.u32 %v34324, 17 (stack45)
        %v34331 = vor.u32 %v34330, %v34329 (stack46)
        %v34332 = vxor.u32 %v34331, %v34327 (stack47)
        %v34335 = vadd.s32 %v34332, %v34327 (stack39)
        %v34337 = vshll.u32 %v34332, 26 (stack44)
        %v34338 = vshrl.u32 %v34332, 6 (stack45)
        %v34339 = vor.u32 %v34338, %v34337 (stack46)
        %v34340 = vxor.u32 %v34339, %v34335 (stack47)
        %v34343 = vadd.s32 %v34340, %v34335 (stack39)
        %v34347 = vadd.s32 %v34343, %v8 (stack39)
        %v34349 = vshll.u32 %v34340, 6 (stack44)
        %v34350 = vshrl.u32 %v34340, 26 (stack45)
        %v34351 = vor.u32 %v34350, %v34349 (stack46)
        %v34352 = vxor.u32 %v34351, %v34343 (stack47)
        %v34355 = vadd.s32 %v34352, %v10 (stack39)
        %v34359 = vadd.s32 5, %v34355 (stack39)
        %v34361 = vxor.u32 %v34359, %v34347 (stack47)
        %v34362 = vand.u32.u8 255, %v34361 (stack48)
        %v34363 = vand.u32 65535, %v34362 (stack49)
        %v34364 = vshrl.u32 %v34363, 1 (stack50)
        %v34365 = vor.u32 16256, %v34364 (stack46)
        %v34366 = vand.u32.u16 65535, %v34365 (stack51)
        %v119928 = vadd.low.f32.bf16 -1.0, %v34366 (stack52)
        %v34375 = vmul.f32 2.0, %v119928 (stack53)
        %v34379 = vadd.f32 -0.99609375, %v34375 (stack52)
        %v34383 = vmax.f32 %v34379, -0.99609375 (stack54)
        %v34385 = vand.u32 2147483647, %v34383 (stack55)
        %vm34388 = vcmp.eq.f32.partialorder %v34385, 1.0 (stack56)
        %v34393 = vmul.f32 inf, %v34383 (stack53)
        %v34395 = vxor.u32 2147483648, %v34383 (stack57)
        %v34398 = vmul.f32 %v34395, %v34383 (stack53)
        %v34400 = vadd.f32 1.0, %v34398 (stack58)
        %v34401 = vlog2.pop %v34400 (stack59)
        %v34402 = vmul.f32 0.6931472, %v34401 (stack60)
        %v34403 = vmul.f32 -0.5, %v34398 (stack61)
        %v34404 = vadd.f32 1.0, %v34403 (stack62)
        %v34405 = vmul.f32 %v34404, %v34398 (stack63)
        %v34406 = vand.u32 2147483647, %v34398 (stack64)
        %vm34407 = vcmp.lt.f32.partialorder %v34406, 0.0004427343 (stack65)
        %v34408 = vsel /*vm=*/%vm34407, /*on_true_vy=*/%v34405, /*on_false_vx=*/%v34402 (stack66)
        %v34409 = vxor.u32 2147483648, %v34408 (stack57)
        %vm34412 = vcmp.lt.f32.partialorder %v34409, 5.0 (stack56)
        %v34417 = vsel /*vm=*/%vm34412, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v34421 = vsel /*vm=*/%vm34412, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v34425 = vsel /*vm=*/%vm34412, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v34429 = vsel /*vm=*/%vm34412, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v34433 = vsel /*vm=*/%vm34412, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v34437 = vsel /*vm=*/%vm34412, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v34441 = vsel /*vm=*/%vm34412, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v34445 = vsel /*vm=*/%vm34412, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v34449 = vsel /*vm=*/%vm34412, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v34453 = vadd.f32 -2.5, %v34409 (stack52)
        %v34455 = vrsqrt.pop %v34409 (stack67)
        %v34456 = vmul.f32 %v34455, %v34409 (stack68)
        %vm34457 = vcmp.eq.f32.partialorder %v34409, inf (stack69)
        %v34458 = vsel /*vm=*/%vm34457, /*on_true_vy=*/%v34409, /*on_false_vx=*/%v34456 (stack70)
        %vm34459 = vcmp.eq.f32.partialorder %v34409, 0.0 (stack71)
        %v34460 = vand.u32 2147483648, %v34409 (stack72)
        %v34461 = vsel /*vm=*/%vm34459, /*on_true_vy=*/%v34460, /*on_false_vx=*/%v34458 (stack73)
        %v34464 = vadd.f32 -3.0, %v34461 (stack52)
        %v34468 = vsel /*vm=*/%vm34412, /*on_true_vy=*/%v34453, /*on_false_vx=*/%v34464 (stack43)
        %v34472 = vmul.f32 %v34468, %v34449 (stack53)
        %v34476 = vadd.f32 %v34472, %v34445 (stack52)
        %v34480 = vmul.f32 %v34476, %v34468 (stack53)
        %v34484 = vadd.f32 %v34480, %v34441 (stack52)
        %v34488 = vmul.f32 %v34484, %v34468 (stack53)
        %v34492 = vadd.f32 %v34488, %v34437 (stack52)
        %v34496 = vmul.f32 %v34492, %v34468 (stack53)
        %v34500 = vadd.f32 %v34496, %v34433 (stack52)
        %v34504 = vmul.f32 %v34500, %v34468 (stack53)
        %v34508 = vadd.f32 %v34504, %v34429 (stack52)
        %v34512 = vmul.f32 %v34508, %v34468 (stack53)
        %v34516 = vadd.f32 %v34512, %v34425 (stack52)
        %v34520 = vmul.f32 %v34516, %v34468 (stack53)
        %v34524 = vadd.f32 %v34520, %v34421 (stack52)
        %v34528 = vmul.f32 %v34524, %v34468 (stack53)
        %v34532 = vadd.f32 %v34528, %v34417 (stack52)
        %v34536 = vmul.f32 %v34532, %v34383 (stack53)
        %v34540 = vsel /*vm=*/%vm34388, /*on_true_vy=*/%v34393, /*on_false_vx=*/%v34536 (stack43)
        %v34544 = vmul.f32 1.4140625, %v34540 (stack53)
        %v34547 = vpack.c.bf16 0.0, %v34544 (stack74)
        %119929 = vst [vmem:[%s280 + $0x24] sm:$0xf] /*vst_source=*/%v34547 (stack75)
        %v34551 = vadd.s32 %v34087, %v894 (stack39)
        %v34561 = vadd.s32 %v34551, %v415 (stack39)
        %vm34565 = vcmp.lt.u32.totalorder %v34561, %v34551 (stack42)
        %vm34570 = vcmp.lt.u32.totalorder %v34551, %v894 (stack42)
        %v34575 = vadd.s32 %v34070, %v881 (stack39)
        %v34579 = vadd.s32 1, %v34575 (stack39)
        %v34583 = vsel /*vm=*/%vm34570, /*on_true_vy=*/%v34579, /*on_false_vx=*/%v34575 (stack43)
        %v34587 = vadd.s32 1, %v34583 (stack39)
        %v34591 = vsel /*vm=*/%vm34565, /*on_true_vy=*/%v34587, /*on_false_vx=*/%v34583 (stack43)
        %v34596 = vadd.s32 %v34591, %v10 (stack39)
        %v34600 = vadd.s32 %v34561, %v9 (stack39)
        %v34604 = vadd.s32 %v34600, %v34596 (stack39)
        %v34606 = vshll.u32 %v34600, 13 (stack44)
        %v34607 = vshrl.u32 %v34600, 19 (stack45)
        %v34608 = vor.u32 %v34607, %v34606 (stack46)
        %v34609 = vxor.u32 %v34608, %v34604 (stack47)
        %v34612 = vadd.s32 %v34609, %v34604 (stack39)
        %v34614 = vshll.u32 %v34609, 15 (stack44)
        %v34615 = vshrl.u32 %v34609, 17 (stack45)
        %v34616 = vor.u32 %v34615, %v34614 (stack46)
        %v34617 = vxor.u32 %v34616, %v34612 (stack47)
        %v34620 = vadd.s32 %v34617, %v34612 (stack39)
        %v34622 = vshll.u32 %v34617, 26 (stack44)
        %v34623 = vshrl.u32 %v34617, 6 (stack45)
        %v34624 = vor.u32 %v34623, %v34622 (stack46)
        %v34625 = vxor.u32 %v34624, %v34620 (stack47)
        %v34628 = vadd.s32 %v34625, %v34620 (stack39)
        %v34632 = vadd.s32 %v34628, %v9 (stack39)
        %v34634 = vshll.u32 %v34625, 6 (stack44)
        %v34635 = vshrl.u32 %v34625, 26 (stack45)
        %v34636 = vor.u32 %v34635, %v34634 (stack46)
        %v34637 = vxor.u32 %v34636, %v34628 (stack47)
        %v34640 = vadd.s32 %v34637, %v8 (stack39)
        %v34644 = vadd.s32 1, %v34640 (stack39)
        %v34648 = vadd.s32 %v34644, %v34632 (stack39)
        %v34650 = vshll.u32 %v34644, 17 (stack44)
        %v34651 = vshrl.u32 %v34644, 15 (stack45)
        %v34652 = vor.u32 %v34651, %v34650 (stack46)
        %v34653 = vxor.u32 %v34652, %v34648 (stack47)
        %v34656 = vadd.s32 %v34653, %v34648 (stack39)
        %v34658 = vshll.u32 %v34653, 29 (stack44)
        %v34659 = vshrl.u32 %v34653, 3 (stack45)
        %v34660 = vor.u32 %v34659, %v34658 (stack46)
        %v34661 = vxor.u32 %v34660, %v34656 (stack47)
        %v34664 = vadd.s32 %v34661, %v34656 (stack39)
        %v34666 = vshll.u32 %v34661, 16 (stack44)
        %v34667 = vshrl.u32 %v34661, 16 (stack45)
        %v34668 = vor.u32 %v34667, %v34666 (stack46)
        %v34669 = vxor.u32 %v34668, %v34664 (stack47)
        %v34672 = vadd.s32 %v34669, %v34664 (stack39)
        %v34676 = vadd.s32 %v34672, %v8 (stack39)
        %v34678 = vshll.u32 %v34669, 24 (stack44)
        %v34679 = vshrl.u32 %v34669, 8 (stack45)
        %v34680 = vor.u32 %v34679, %v34678 (stack46)
        %v34681 = vxor.u32 %v34680, %v34672 (stack47)
        %v34684 = vadd.s32 %v34681, %v10 (stack39)
        %v34688 = vadd.s32 2, %v34684 (stack39)
        %v34692 = vadd.s32 %v34688, %v34676 (stack39)
        %v34694 = vshll.u32 %v34688, 13 (stack44)
        %v34695 = vshrl.u32 %v34688, 19 (stack45)
        %v34696 = vor.u32 %v34695, %v34694 (stack46)
        %v34697 = vxor.u32 %v34696, %v34692 (stack47)
        %v34700 = vadd.s32 %v34697, %v34692 (stack39)
        %v34702 = vshll.u32 %v34697, 15 (stack44)
        %v34703 = vshrl.u32 %v34697, 17 (stack45)
        %v34704 = vor.u32 %v34703, %v34702 (stack46)
        %v34705 = vxor.u32 %v34704, %v34700 (stack47)
        %v34708 = vadd.s32 %v34705, %v34700 (stack39)
        %v34710 = vshll.u32 %v34705, 26 (stack44)
        %v34711 = vshrl.u32 %v34705, 6 (stack45)
        %v34712 = vor.u32 %v34711, %v34710 (stack46)
        %v34713 = vxor.u32 %v34712, %v34708 (stack47)
        %v34716 = vadd.s32 %v34713, %v34708 (stack39)
        %v34720 = vadd.s32 %v34716, %v10 (stack39)
        %v34722 = vshll.u32 %v34713, 6 (stack44)
        %v34723 = vshrl.u32 %v34713, 26 (stack45)
        %v34724 = vor.u32 %v34723, %v34722 (stack46)
        %v34725 = vxor.u32 %v34724, %v34716 (stack47)
        %v34728 = vadd.s32 %v34725, %v9 (stack39)
        %v34732 = vadd.s32 3, %v34728 (stack39)
        %v34736 = vadd.s32 %v34732, %v34720 (stack39)
        %v34738 = vshll.u32 %v34732, 17 (stack44)
        %v34739 = vshrl.u32 %v34732, 15 (stack45)
        %v34740 = vor.u32 %v34739, %v34738 (stack46)
        %v34741 = vxor.u32 %v34740, %v34736 (stack47)
        %v34744 = vadd.s32 %v34741, %v34736 (stack39)
        %v34746 = vshll.u32 %v34741, 29 (stack44)
        %v34747 = vshrl.u32 %v34741, 3 (stack45)
        %v34748 = vor.u32 %v34747, %v34746 (stack46)
        %v34749 = vxor.u32 %v34748, %v34744 (stack47)
        %v34752 = vadd.s32 %v34749, %v34744 (stack39)
        %v34754 = vshll.u32 %v34749, 16 (stack44)
        %v34755 = vshrl.u32 %v34749, 16 (stack45)
        %v34756 = vor.u32 %v34755, %v34754 (stack46)
        %v34757 = vxor.u32 %v34756, %v34752 (stack47)
        %v34760 = vadd.s32 %v34757, %v34752 (stack39)
        %v34764 = vadd.s32 %v34760, %v9 (stack39)
        %v34766 = vshll.u32 %v34757, 24 (stack44)
        %v34767 = vshrl.u32 %v34757, 8 (stack45)
        %v34768 = vor.u32 %v34767, %v34766 (stack46)
        %v34769 = vxor.u32 %v34768, %v34760 (stack47)
        %v34772 = vadd.s32 %v34769, %v8 (stack39)
        %v34776 = vadd.s32 4, %v34772 (stack39)
        %v34780 = vadd.s32 %v34776, %v34764 (stack39)
        %v34782 = vshll.u32 %v34776, 13 (stack44)
        %v34783 = vshrl.u32 %v34776, 19 (stack45)
        %v34784 = vor.u32 %v34783, %v34782 (stack46)
        %v34785 = vxor.u32 %v34784, %v34780 (stack47)
        %v34788 = vadd.s32 %v34785, %v34780 (stack39)
        %v34790 = vshll.u32 %v34785, 15 (stack44)
        %v34791 = vshrl.u32 %v34785, 17 (stack45)
        %v34792 = vor.u32 %v34791, %v34790 (stack46)
        %v34793 = vxor.u32 %v34792, %v34788 (stack47)
        %v34796 = vadd.s32 %v34793, %v34788 (stack39)
        %v34798 = vshll.u32 %v34793, 26 (stack44)
        %v34799 = vshrl.u32 %v34793, 6 (stack45)
        %v34800 = vor.u32 %v34799, %v34798 (stack46)
        %v34801 = vxor.u32 %v34800, %v34796 (stack47)
        %v34804 = vadd.s32 %v34801, %v34796 (stack39)
        %v34808 = vadd.s32 %v34804, %v8 (stack39)
        %v34810 = vshll.u32 %v34801, 6 (stack44)
        %v34811 = vshrl.u32 %v34801, 26 (stack45)
        %v34812 = vor.u32 %v34811, %v34810 (stack46)
        %v34813 = vxor.u32 %v34812, %v34804 (stack47)
        %v34816 = vadd.s32 %v34813, %v10 (stack39)
        %v34820 = vadd.s32 5, %v34816 (stack39)
        %v34822 = vxor.u32 %v34820, %v34808 (stack47)
        %v34823 = vand.u32.u8 255, %v34822 (stack48)
        %v34824 = vand.u32 65535, %v34823 (stack49)
        %v34825 = vshrl.u32 %v34824, 1 (stack50)
        %v34826 = vor.u32 16256, %v34825 (stack46)
        %v34827 = vand.u32.u16 65535, %v34826 (stack51)
        %v119930 = vadd.low.f32.bf16 -1.0, %v34827 (stack52)
        %v34836 = vmul.f32 2.0, %v119930 (stack53)
        %v34840 = vadd.f32 -0.99609375, %v34836 (stack52)
        %v34844 = vmax.f32 %v34840, -0.99609375 (stack54)
        %v34846 = vand.u32 2147483647, %v34844 (stack55)
        %vm34849 = vcmp.eq.f32.partialorder %v34846, 1.0 (stack56)
        %v34854 = vmul.f32 inf, %v34844 (stack53)
        %v34856 = vxor.u32 2147483648, %v34844 (stack57)
        %v34859 = vmul.f32 %v34856, %v34844 (stack53)
        %v34861 = vadd.f32 1.0, %v34859 (stack58)
        %v34862 = vlog2.pop %v34861 (stack59)
        %v34863 = vmul.f32 0.6931472, %v34862 (stack60)
        %v34864 = vmul.f32 -0.5, %v34859 (stack61)
        %v34865 = vadd.f32 1.0, %v34864 (stack62)
        %v34866 = vmul.f32 %v34865, %v34859 (stack63)
        %v34867 = vand.u32 2147483647, %v34859 (stack64)
        %vm34868 = vcmp.lt.f32.partialorder %v34867, 0.0004427343 (stack65)
        %v34869 = vsel /*vm=*/%vm34868, /*on_true_vy=*/%v34866, /*on_false_vx=*/%v34863 (stack66)
        %v34870 = vxor.u32 2147483648, %v34869 (stack57)
        %vm34873 = vcmp.lt.f32.partialorder %v34870, 5.0 (stack56)
        %v34878 = vsel /*vm=*/%vm34873, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v34882 = vsel /*vm=*/%vm34873, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v34886 = vsel /*vm=*/%vm34873, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v34890 = vsel /*vm=*/%vm34873, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v34894 = vsel /*vm=*/%vm34873, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v34898 = vsel /*vm=*/%vm34873, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v34902 = vsel /*vm=*/%vm34873, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v34906 = vsel /*vm=*/%vm34873, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v34910 = vsel /*vm=*/%vm34873, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v34914 = vadd.f32 -2.5, %v34870 (stack52)
        %v34916 = vrsqrt.pop %v34870 (stack67)
        %v34917 = vmul.f32 %v34916, %v34870 (stack68)
        %vm34918 = vcmp.eq.f32.partialorder %v34870, inf (stack69)
        %v34919 = vsel /*vm=*/%vm34918, /*on_true_vy=*/%v34870, /*on_false_vx=*/%v34917 (stack70)
        %vm34920 = vcmp.eq.f32.partialorder %v34870, 0.0 (stack71)
        %v34921 = vand.u32 2147483648, %v34870 (stack72)
        %v34922 = vsel /*vm=*/%vm34920, /*on_true_vy=*/%v34921, /*on_false_vx=*/%v34919 (stack73)
        %v34925 = vadd.f32 -3.0, %v34922 (stack52)
        %v34929 = vsel /*vm=*/%vm34873, /*on_true_vy=*/%v34914, /*on_false_vx=*/%v34925 (stack43)
        %v34933 = vmul.f32 %v34929, %v34910 (stack53)
        %v34937 = vadd.f32 %v34933, %v34906 (stack52)
        %v34941 = vmul.f32 %v34937, %v34929 (stack53)
        %v34945 = vadd.f32 %v34941, %v34902 (stack52)
        %v34949 = vmul.f32 %v34945, %v34929 (stack53)
        %v34953 = vadd.f32 %v34949, %v34898 (stack52)
        %v34957 = vmul.f32 %v34953, %v34929 (stack53)
        %v34961 = vadd.f32 %v34957, %v34894 (stack52)
        %v34965 = vmul.f32 %v34961, %v34929 (stack53)
        %v34969 = vadd.f32 %v34965, %v34890 (stack52)
        %v34973 = vmul.f32 %v34969, %v34929 (stack53)
        %v34977 = vadd.f32 %v34973, %v34886 (stack52)
        %v34981 = vmul.f32 %v34977, %v34929 (stack53)
        %v34985 = vadd.f32 %v34981, %v34882 (stack52)
        %v34989 = vmul.f32 %v34985, %v34929 (stack53)
        %v34993 = vadd.f32 %v34989, %v34878 (stack52)
        %v34997 = vmul.f32 %v34993, %v34844 (stack53)
        %v35001 = vsel /*vm=*/%vm34849, /*on_true_vy=*/%v34854, /*on_false_vx=*/%v34997 (stack43)
        %v35005 = vmul.f32 1.4140625, %v35001 (stack53)
        %v35008 = vpack.c.bf16 0.0, %v35005 (stack74)
        %119931 = vst [vmem:[%s280 + $0xa4] sm:$0xf] /*vst_source=*/%v35008 (stack75)
        %v35012 = vadd.s32 %v34087, %v1381 (stack39)
        %v35022 = vadd.s32 %v35012, %v415 (stack39)
        %vm35026 = vcmp.lt.u32.totalorder %v35022, %v35012 (stack42)
        %vm35031 = vcmp.lt.u32.totalorder %v35012, %v1381 (stack42)
        %v35036 = vadd.s32 %v34070, %v1368 (stack39)
        %v35040 = vadd.s32 1, %v35036 (stack39)
        %v35044 = vsel /*vm=*/%vm35031, /*on_true_vy=*/%v35040, /*on_false_vx=*/%v35036 (stack43)
        %v35048 = vadd.s32 1, %v35044 (stack39)
        %v35052 = vsel /*vm=*/%vm35026, /*on_true_vy=*/%v35048, /*on_false_vx=*/%v35044 (stack43)
        %v35057 = vadd.s32 %v35052, %v10 (stack39)
        %v35061 = vadd.s32 %v35022, %v9 (stack39)
        %v35065 = vadd.s32 %v35061, %v35057 (stack39)
        %v35067 = vshll.u32 %v35061, 13 (stack44)
        %v35068 = vshrl.u32 %v35061, 19 (stack45)
        %v35069 = vor.u32 %v35068, %v35067 (stack46)
        %v35070 = vxor.u32 %v35069, %v35065 (stack47)
        %v35073 = vadd.s32 %v35070, %v35065 (stack39)
        %v35075 = vshll.u32 %v35070, 15 (stack44)
        %v35076 = vshrl.u32 %v35070, 17 (stack45)
        %v35077 = vor.u32 %v35076, %v35075 (stack46)
        %v35078 = vxor.u32 %v35077, %v35073 (stack47)
        %v35081 = vadd.s32 %v35078, %v35073 (stack39)
        %v35083 = vshll.u32 %v35078, 26 (stack44)
        %v35084 = vshrl.u32 %v35078, 6 (stack45)
        %v35085 = vor.u32 %v35084, %v35083 (stack46)
        %v35086 = vxor.u32 %v35085, %v35081 (stack47)
        %v35089 = vadd.s32 %v35086, %v35081 (stack39)
        %v35093 = vadd.s32 %v35089, %v9 (stack39)
        %v35095 = vshll.u32 %v35086, 6 (stack44)
        %v35096 = vshrl.u32 %v35086, 26 (stack45)
        %v35097 = vor.u32 %v35096, %v35095 (stack46)
        %v35098 = vxor.u32 %v35097, %v35089 (stack47)
        %v35101 = vadd.s32 %v35098, %v8 (stack39)
        %v35105 = vadd.s32 1, %v35101 (stack39)
        %v35109 = vadd.s32 %v35105, %v35093 (stack39)
        %v35111 = vshll.u32 %v35105, 17 (stack44)
        %v35112 = vshrl.u32 %v35105, 15 (stack45)
        %v35113 = vor.u32 %v35112, %v35111 (stack46)
        %v35114 = vxor.u32 %v35113, %v35109 (stack47)
        %v35117 = vadd.s32 %v35114, %v35109 (stack39)
        %v35119 = vshll.u32 %v35114, 29 (stack44)
        %v35120 = vshrl.u32 %v35114, 3 (stack45)
        %v35121 = vor.u32 %v35120, %v35119 (stack46)
        %v35122 = vxor.u32 %v35121, %v35117 (stack47)
        %v35125 = vadd.s32 %v35122, %v35117 (stack39)
        %v35127 = vshll.u32 %v35122, 16 (stack44)
        %v35128 = vshrl.u32 %v35122, 16 (stack45)
        %v35129 = vor.u32 %v35128, %v35127 (stack46)
        %v35130 = vxor.u32 %v35129, %v35125 (stack47)
        %v35133 = vadd.s32 %v35130, %v35125 (stack39)
        %v35137 = vadd.s32 %v35133, %v8 (stack39)
        %v35139 = vshll.u32 %v35130, 24 (stack44)
        %v35140 = vshrl.u32 %v35130, 8 (stack45)
        %v35141 = vor.u32 %v35140, %v35139 (stack46)
        %v35142 = vxor.u32 %v35141, %v35133 (stack47)
        %v35145 = vadd.s32 %v35142, %v10 (stack39)
        %v35149 = vadd.s32 2, %v35145 (stack39)
        %v35153 = vadd.s32 %v35149, %v35137 (stack39)
        %v35155 = vshll.u32 %v35149, 13 (stack44)
        %v35156 = vshrl.u32 %v35149, 19 (stack45)
        %v35157 = vor.u32 %v35156, %v35155 (stack46)
        %v35158 = vxor.u32 %v35157, %v35153 (stack47)
        %v35161 = vadd.s32 %v35158, %v35153 (stack39)
        %v35163 = vshll.u32 %v35158, 15 (stack44)
        %v35164 = vshrl.u32 %v35158, 17 (stack45)
        %v35165 = vor.u32 %v35164, %v35163 (stack46)
        %v35166 = vxor.u32 %v35165, %v35161 (stack47)
        %v35169 = vadd.s32 %v35166, %v35161 (stack39)
        %v35171 = vshll.u32 %v35166, 26 (stack44)
        %v35172 = vshrl.u32 %v35166, 6 (stack45)
        %v35173 = vor.u32 %v35172, %v35171 (stack46)
        %v35174 = vxor.u32 %v35173, %v35169 (stack47)
        %v35177 = vadd.s32 %v35174, %v35169 (stack39)
        %v35181 = vadd.s32 %v35177, %v10 (stack39)
        %v35183 = vshll.u32 %v35174, 6 (stack44)
        %v35184 = vshrl.u32 %v35174, 26 (stack45)
        %v35185 = vor.u32 %v35184, %v35183 (stack46)
        %v35186 = vxor.u32 %v35185, %v35177 (stack47)
        %v35189 = vadd.s32 %v35186, %v9 (stack39)
        %v35193 = vadd.s32 3, %v35189 (stack39)
        %v35197 = vadd.s32 %v35193, %v35181 (stack39)
        %v35199 = vshll.u32 %v35193, 17 (stack44)
        %v35200 = vshrl.u32 %v35193, 15 (stack45)
        %v35201 = vor.u32 %v35200, %v35199 (stack46)
        %v35202 = vxor.u32 %v35201, %v35197 (stack47)
        %v35205 = vadd.s32 %v35202, %v35197 (stack39)
        %v35207 = vshll.u32 %v35202, 29 (stack44)
        %v35208 = vshrl.u32 %v35202, 3 (stack45)
        %v35209 = vor.u32 %v35208, %v35207 (stack46)
        %v35210 = vxor.u32 %v35209, %v35205 (stack47)
        %v35213 = vadd.s32 %v35210, %v35205 (stack39)
        %v35215 = vshll.u32 %v35210, 16 (stack44)
        %v35216 = vshrl.u32 %v35210, 16 (stack45)
        %v35217 = vor.u32 %v35216, %v35215 (stack46)
        %v35218 = vxor.u32 %v35217, %v35213 (stack47)
        %v35221 = vadd.s32 %v35218, %v35213 (stack39)
        %v35225 = vadd.s32 %v35221, %v9 (stack39)
        %v35227 = vshll.u32 %v35218, 24 (stack44)
        %v35228 = vshrl.u32 %v35218, 8 (stack45)
        %v35229 = vor.u32 %v35228, %v35227 (stack46)
        %v35230 = vxor.u32 %v35229, %v35221 (stack47)
        %v35233 = vadd.s32 %v35230, %v8 (stack39)
        %v35237 = vadd.s32 4, %v35233 (stack39)
        %v35241 = vadd.s32 %v35237, %v35225 (stack39)
        %v35243 = vshll.u32 %v35237, 13 (stack44)
        %v35244 = vshrl.u32 %v35237, 19 (stack45)
        %v35245 = vor.u32 %v35244, %v35243 (stack46)
        %v35246 = vxor.u32 %v35245, %v35241 (stack47)
        %v35249 = vadd.s32 %v35246, %v35241 (stack39)
        %v35251 = vshll.u32 %v35246, 15 (stack44)
        %v35252 = vshrl.u32 %v35246, 17 (stack45)
        %v35253 = vor.u32 %v35252, %v35251 (stack46)
        %v35254 = vxor.u32 %v35253, %v35249 (stack47)
        %v35257 = vadd.s32 %v35254, %v35249 (stack39)
        %v35259 = vshll.u32 %v35254, 26 (stack44)
        %v35260 = vshrl.u32 %v35254, 6 (stack45)
        %v35261 = vor.u32 %v35260, %v35259 (stack46)
        %v35262 = vxor.u32 %v35261, %v35257 (stack47)
        %v35265 = vadd.s32 %v35262, %v35257 (stack39)
        %v35269 = vadd.s32 %v35265, %v8 (stack39)
        %v35271 = vshll.u32 %v35262, 6 (stack44)
        %v35272 = vshrl.u32 %v35262, 26 (stack45)
        %v35273 = vor.u32 %v35272, %v35271 (stack46)
        %v35274 = vxor.u32 %v35273, %v35265 (stack47)
        %v35277 = vadd.s32 %v35274, %v10 (stack39)
        %v35281 = vadd.s32 5, %v35277 (stack39)
        %v35283 = vxor.u32 %v35281, %v35269 (stack47)
        %v35284 = vand.u32.u8 255, %v35283 (stack48)
        %v35285 = vand.u32 65535, %v35284 (stack49)
        %v35286 = vshrl.u32 %v35285, 1 (stack50)
        %v35287 = vor.u32 16256, %v35286 (stack46)
        %v35288 = vand.u32.u16 65535, %v35287 (stack51)
        %v119932 = vadd.low.f32.bf16 -1.0, %v35288 (stack52)
        %v35297 = vmul.f32 2.0, %v119932 (stack53)
        %v35301 = vadd.f32 -0.99609375, %v35297 (stack52)
        %v35305 = vmax.f32 %v35301, -0.99609375 (stack54)
        %v35307 = vand.u32 2147483647, %v35305 (stack55)
        %vm35310 = vcmp.eq.f32.partialorder %v35307, 1.0 (stack56)
        %v35315 = vmul.f32 inf, %v35305 (stack53)
        %v35317 = vxor.u32 2147483648, %v35305 (stack57)
        %v35320 = vmul.f32 %v35317, %v35305 (stack53)
        %v35322 = vadd.f32 1.0, %v35320 (stack58)
        %v35323 = vlog2.pop %v35322 (stack59)
        %v35324 = vmul.f32 0.6931472, %v35323 (stack60)
        %v35325 = vmul.f32 -0.5, %v35320 (stack61)
        %v35326 = vadd.f32 1.0, %v35325 (stack62)
        %v35327 = vmul.f32 %v35326, %v35320 (stack63)
        %v35328 = vand.u32 2147483647, %v35320 (stack64)
        %vm35329 = vcmp.lt.f32.partialorder %v35328, 0.0004427343 (stack65)
        %v35330 = vsel /*vm=*/%vm35329, /*on_true_vy=*/%v35327, /*on_false_vx=*/%v35324 (stack66)
        %v35331 = vxor.u32 2147483648, %v35330 (stack57)
        %vm35334 = vcmp.lt.f32.partialorder %v35331, 5.0 (stack56)
        %v35339 = vsel /*vm=*/%vm35334, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v35343 = vsel /*vm=*/%vm35334, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v35347 = vsel /*vm=*/%vm35334, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v35351 = vsel /*vm=*/%vm35334, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v35355 = vsel /*vm=*/%vm35334, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v35359 = vsel /*vm=*/%vm35334, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v35363 = vsel /*vm=*/%vm35334, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v35367 = vsel /*vm=*/%vm35334, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v35371 = vsel /*vm=*/%vm35334, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v35375 = vadd.f32 -2.5, %v35331 (stack52)
        %v35377 = vrsqrt.pop %v35331 (stack67)
        %v35378 = vmul.f32 %v35377, %v35331 (stack68)
        %vm35379 = vcmp.eq.f32.partialorder %v35331, inf (stack69)
        %v35380 = vsel /*vm=*/%vm35379, /*on_true_vy=*/%v35331, /*on_false_vx=*/%v35378 (stack70)
        %vm35381 = vcmp.eq.f32.partialorder %v35331, 0.0 (stack71)
        %v35382 = vand.u32 2147483648, %v35331 (stack72)
        %v35383 = vsel /*vm=*/%vm35381, /*on_true_vy=*/%v35382, /*on_false_vx=*/%v35380 (stack73)
        %v35386 = vadd.f32 -3.0, %v35383 (stack52)
        %v35390 = vsel /*vm=*/%vm35334, /*on_true_vy=*/%v35375, /*on_false_vx=*/%v35386 (stack43)
        %v35394 = vmul.f32 %v35390, %v35371 (stack53)
        %v35398 = vadd.f32 %v35394, %v35367 (stack52)
        %v35402 = vmul.f32 %v35398, %v35390 (stack53)
        %v35406 = vadd.f32 %v35402, %v35363 (stack52)
        %v35410 = vmul.f32 %v35406, %v35390 (stack53)
        %v35414 = vadd.f32 %v35410, %v35359 (stack52)
        %v35418 = vmul.f32 %v35414, %v35390 (stack53)
        %v35422 = vadd.f32 %v35418, %v35355 (stack52)
        %v35426 = vmul.f32 %v35422, %v35390 (stack53)
        %v35430 = vadd.f32 %v35426, %v35351 (stack52)
        %v35434 = vmul.f32 %v35430, %v35390 (stack53)
        %v35438 = vadd.f32 %v35434, %v35347 (stack52)
        %v35442 = vmul.f32 %v35438, %v35390 (stack53)
        %v35446 = vadd.f32 %v35442, %v35343 (stack52)
        %v35450 = vmul.f32 %v35446, %v35390 (stack53)
        %v35454 = vadd.f32 %v35450, %v35339 (stack52)
        %v35458 = vmul.f32 %v35454, %v35305 (stack53)
        %v35462 = vsel /*vm=*/%vm35310, /*on_true_vy=*/%v35315, /*on_false_vx=*/%v35458 (stack43)
        %v35466 = vmul.f32 1.4140625, %v35462 (stack53)
        %v35469 = vpack.c.bf16 0.0, %v35466 (stack74)
        %119933 = vst [vmem:[%s280 + $0x124] sm:$0xf] /*vst_source=*/%v35469 (stack75)
        %v35473 = vadd.s32 %v34087, %v1868 (stack39)
        %v35483 = vadd.s32 %v35473, %v415 (stack39)
        %vm35487 = vcmp.lt.u32.totalorder %v35483, %v35473 (stack42)
        %vm35492 = vcmp.lt.u32.totalorder %v35473, %v1868 (stack42)
        %v35497 = vadd.s32 %v34070, %v1855 (stack39)
        %v35501 = vadd.s32 1, %v35497 (stack39)
        %v35505 = vsel /*vm=*/%vm35492, /*on_true_vy=*/%v35501, /*on_false_vx=*/%v35497 (stack43)
        %v35509 = vadd.s32 1, %v35505 (stack39)
        %v35513 = vsel /*vm=*/%vm35487, /*on_true_vy=*/%v35509, /*on_false_vx=*/%v35505 (stack43)
        %v35518 = vadd.s32 %v35513, %v10 (stack39)
        %v35522 = vadd.s32 %v35483, %v9 (stack39)
        %v35526 = vadd.s32 %v35522, %v35518 (stack39)
        %v35528 = vshll.u32 %v35522, 13 (stack44)
        %v35529 = vshrl.u32 %v35522, 19 (stack45)
        %v35530 = vor.u32 %v35529, %v35528 (stack46)
        %v35531 = vxor.u32 %v35530, %v35526 (stack47)
        %v35534 = vadd.s32 %v35531, %v35526 (stack39)
        %v35536 = vshll.u32 %v35531, 15 (stack44)
        %v35537 = vshrl.u32 %v35531, 17 (stack45)
        %v35538 = vor.u32 %v35537, %v35536 (stack46)
        %v35539 = vxor.u32 %v35538, %v35534 (stack47)
        %v35542 = vadd.s32 %v35539, %v35534 (stack39)
        %v35544 = vshll.u32 %v35539, 26 (stack44)
        %v35545 = vshrl.u32 %v35539, 6 (stack45)
        %v35546 = vor.u32 %v35545, %v35544 (stack46)
        %v35547 = vxor.u32 %v35546, %v35542 (stack47)
        %v35550 = vadd.s32 %v35547, %v35542 (stack39)
        %v35554 = vadd.s32 %v35550, %v9 (stack39)
        %v35556 = vshll.u32 %v35547, 6 (stack44)
        %v35557 = vshrl.u32 %v35547, 26 (stack45)
        %v35558 = vor.u32 %v35557, %v35556 (stack46)
        %v35559 = vxor.u32 %v35558, %v35550 (stack47)
        %v35562 = vadd.s32 %v35559, %v8 (stack39)
        %v35566 = vadd.s32 1, %v35562 (stack39)
        %v35570 = vadd.s32 %v35566, %v35554 (stack39)
        %v35572 = vshll.u32 %v35566, 17 (stack44)
        %v35573 = vshrl.u32 %v35566, 15 (stack45)
        %v35574 = vor.u32 %v35573, %v35572 (stack46)
        %v35575 = vxor.u32 %v35574, %v35570 (stack47)
        %v35578 = vadd.s32 %v35575, %v35570 (stack39)
        %v35580 = vshll.u32 %v35575, 29 (stack44)
        %v35581 = vshrl.u32 %v35575, 3 (stack45)
        %v35582 = vor.u32 %v35581, %v35580 (stack46)
        %v35583 = vxor.u32 %v35582, %v35578 (stack47)
        %v35586 = vadd.s32 %v35583, %v35578 (stack39)
        %v35588 = vshll.u32 %v35583, 16 (stack44)
        %v35589 = vshrl.u32 %v35583, 16 (stack45)
        %v35590 = vor.u32 %v35589, %v35588 (stack46)
        %v35591 = vxor.u32 %v35590, %v35586 (stack47)
        %v35594 = vadd.s32 %v35591, %v35586 (stack39)
        %v35598 = vadd.s32 %v35594, %v8 (stack39)
        %v35600 = vshll.u32 %v35591, 24 (stack44)
        %v35601 = vshrl.u32 %v35591, 8 (stack45)
        %v35602 = vor.u32 %v35601, %v35600 (stack46)
        %v35603 = vxor.u32 %v35602, %v35594 (stack47)
        %v35606 = vadd.s32 %v35603, %v10 (stack39)
        %v35610 = vadd.s32 2, %v35606 (stack39)
        %v35614 = vadd.s32 %v35610, %v35598 (stack39)
        %v35616 = vshll.u32 %v35610, 13 (stack44)
        %v35617 = vshrl.u32 %v35610, 19 (stack45)
        %v35618 = vor.u32 %v35617, %v35616 (stack46)
        %v35619 = vxor.u32 %v35618, %v35614 (stack47)
        %v35622 = vadd.s32 %v35619, %v35614 (stack39)
        %v35624 = vshll.u32 %v35619, 15 (stack44)
        %v35625 = vshrl.u32 %v35619, 17 (stack45)
        %v35626 = vor.u32 %v35625, %v35624 (stack46)
        %v35627 = vxor.u32 %v35626, %v35622 (stack47)
        %v35630 = vadd.s32 %v35627, %v35622 (stack39)
        %v35632 = vshll.u32 %v35627, 26 (stack44)
        %v35633 = vshrl.u32 %v35627, 6 (stack45)
        %v35634 = vor.u32 %v35633, %v35632 (stack46)
        %v35635 = vxor.u32 %v35634, %v35630 (stack47)
        %v35638 = vadd.s32 %v35635, %v35630 (stack39)
        %v35642 = vadd.s32 %v35638, %v10 (stack39)
        %v35644 = vshll.u32 %v35635, 6 (stack44)
        %v35645 = vshrl.u32 %v35635, 26 (stack45)
        %v35646 = vor.u32 %v35645, %v35644 (stack46)
        %v35647 = vxor.u32 %v35646, %v35638 (stack47)
        %v35650 = vadd.s32 %v35647, %v9 (stack39)
        %v35654 = vadd.s32 3, %v35650 (stack39)
        %v35658 = vadd.s32 %v35654, %v35642 (stack39)
        %v35660 = vshll.u32 %v35654, 17 (stack44)
        %v35661 = vshrl.u32 %v35654, 15 (stack45)
        %v35662 = vor.u32 %v35661, %v35660 (stack46)
        %v35663 = vxor.u32 %v35662, %v35658 (stack47)
        %v35666 = vadd.s32 %v35663, %v35658 (stack39)
        %v35668 = vshll.u32 %v35663, 29 (stack44)
        %v35669 = vshrl.u32 %v35663, 3 (stack45)
        %v35670 = vor.u32 %v35669, %v35668 (stack46)
        %v35671 = vxor.u32 %v35670, %v35666 (stack47)
        %v35674 = vadd.s32 %v35671, %v35666 (stack39)
        %v35676 = vshll.u32 %v35671, 16 (stack44)
        %v35677 = vshrl.u32 %v35671, 16 (stack45)
        %v35678 = vor.u32 %v35677, %v35676 (stack46)
        %v35679 = vxor.u32 %v35678, %v35674 (stack47)
        %v35682 = vadd.s32 %v35679, %v35674 (stack39)
        %v35686 = vadd.s32 %v35682, %v9 (stack39)
        %v35688 = vshll.u32 %v35679, 24 (stack44)
        %v35689 = vshrl.u32 %v35679, 8 (stack45)
        %v35690 = vor.u32 %v35689, %v35688 (stack46)
        %v35691 = vxor.u32 %v35690, %v35682 (stack47)
        %v35694 = vadd.s32 %v35691, %v8 (stack39)
        %v35698 = vadd.s32 4, %v35694 (stack39)
        %v35702 = vadd.s32 %v35698, %v35686 (stack39)
        %v35704 = vshll.u32 %v35698, 13 (stack44)
        %v35705 = vshrl.u32 %v35698, 19 (stack45)
        %v35706 = vor.u32 %v35705, %v35704 (stack46)
        %v35707 = vxor.u32 %v35706, %v35702 (stack47)
        %v35710 = vadd.s32 %v35707, %v35702 (stack39)
        %v35712 = vshll.u32 %v35707, 15 (stack44)
        %v35713 = vshrl.u32 %v35707, 17 (stack45)
        %v35714 = vor.u32 %v35713, %v35712 (stack46)
        %v35715 = vxor.u32 %v35714, %v35710 (stack47)
        %v35718 = vadd.s32 %v35715, %v35710 (stack39)
        %v35720 = vshll.u32 %v35715, 26 (stack44)
        %v35721 = vshrl.u32 %v35715, 6 (stack45)
        %v35722 = vor.u32 %v35721, %v35720 (stack46)
        %v35723 = vxor.u32 %v35722, %v35718 (stack47)
        %v35726 = vadd.s32 %v35723, %v35718 (stack39)
        %v35730 = vadd.s32 %v35726, %v8 (stack39)
        %v35732 = vshll.u32 %v35723, 6 (stack44)
        %v35733 = vshrl.u32 %v35723, 26 (stack45)
        %v35734 = vor.u32 %v35733, %v35732 (stack46)
        %v35735 = vxor.u32 %v35734, %v35726 (stack47)
        %v35738 = vadd.s32 %v35735, %v10 (stack39)
        %v35742 = vadd.s32 5, %v35738 (stack39)
        %v35744 = vxor.u32 %v35742, %v35730 (stack47)
        %v35745 = vand.u32.u8 255, %v35744 (stack48)
        %v35746 = vand.u32 65535, %v35745 (stack49)
        %v35747 = vshrl.u32 %v35746, 1 (stack50)
        %v35748 = vor.u32 16256, %v35747 (stack46)
        %v35749 = vand.u32.u16 65535, %v35748 (stack51)
        %v119934 = vadd.low.f32.bf16 -1.0, %v35749 (stack52)
        %v35758 = vmul.f32 2.0, %v119934 (stack53)
        %v35762 = vadd.f32 -0.99609375, %v35758 (stack52)
        %v35766 = vmax.f32 %v35762, -0.99609375 (stack54)
        %v35768 = vand.u32 2147483647, %v35766 (stack55)
        %vm35771 = vcmp.eq.f32.partialorder %v35768, 1.0 (stack56)
        %v35776 = vmul.f32 inf, %v35766 (stack53)
        %v35778 = vxor.u32 2147483648, %v35766 (stack57)
        %v35781 = vmul.f32 %v35778, %v35766 (stack53)
        %v35783 = vadd.f32 1.0, %v35781 (stack58)
        %v35784 = vlog2.pop %v35783 (stack59)
        %v35785 = vmul.f32 0.6931472, %v35784 (stack60)
        %v35786 = vmul.f32 -0.5, %v35781 (stack61)
        %v35787 = vadd.f32 1.0, %v35786 (stack62)
        %v35788 = vmul.f32 %v35787, %v35781 (stack63)
        %v35789 = vand.u32 2147483647, %v35781 (stack64)
        %vm35790 = vcmp.lt.f32.partialorder %v35789, 0.0004427343 (stack65)
        %v35791 = vsel /*vm=*/%vm35790, /*on_true_vy=*/%v35788, /*on_false_vx=*/%v35785 (stack66)
        %v35792 = vxor.u32 2147483648, %v35791 (stack57)
        %vm35795 = vcmp.lt.f32.partialorder %v35792, 5.0 (stack56)
        %v35800 = vsel /*vm=*/%vm35795, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v35804 = vsel /*vm=*/%vm35795, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v35808 = vsel /*vm=*/%vm35795, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v35812 = vsel /*vm=*/%vm35795, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v35816 = vsel /*vm=*/%vm35795, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v35820 = vsel /*vm=*/%vm35795, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v35824 = vsel /*vm=*/%vm35795, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v35828 = vsel /*vm=*/%vm35795, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v35832 = vsel /*vm=*/%vm35795, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v35836 = vadd.f32 -2.5, %v35792 (stack52)
        %v35838 = vrsqrt.pop %v35792 (stack67)
        %v35839 = vmul.f32 %v35838, %v35792 (stack68)
        %vm35840 = vcmp.eq.f32.partialorder %v35792, inf (stack69)
        %v35841 = vsel /*vm=*/%vm35840, /*on_true_vy=*/%v35792, /*on_false_vx=*/%v35839 (stack70)
        %vm35842 = vcmp.eq.f32.partialorder %v35792, 0.0 (stack71)
        %v35843 = vand.u32 2147483648, %v35792 (stack72)
        %v35844 = vsel /*vm=*/%vm35842, /*on_true_vy=*/%v35843, /*on_false_vx=*/%v35841 (stack73)
        %v35847 = vadd.f32 -3.0, %v35844 (stack52)
        %v35851 = vsel /*vm=*/%vm35795, /*on_true_vy=*/%v35836, /*on_false_vx=*/%v35847 (stack43)
        %v35855 = vmul.f32 %v35851, %v35832 (stack53)
        %v35859 = vadd.f32 %v35855, %v35828 (stack52)
        %v35863 = vmul.f32 %v35859, %v35851 (stack53)
        %v35867 = vadd.f32 %v35863, %v35824 (stack52)
        %v35871 = vmul.f32 %v35867, %v35851 (stack53)
        %v35875 = vadd.f32 %v35871, %v35820 (stack52)
        %v35879 = vmul.f32 %v35875, %v35851 (stack53)
        %v35883 = vadd.f32 %v35879, %v35816 (stack52)
        %v35887 = vmul.f32 %v35883, %v35851 (stack53)
        %v35891 = vadd.f32 %v35887, %v35812 (stack52)
        %v35895 = vmul.f32 %v35891, %v35851 (stack53)
        %v35899 = vadd.f32 %v35895, %v35808 (stack52)
        %v35903 = vmul.f32 %v35899, %v35851 (stack53)
        %v35907 = vadd.f32 %v35903, %v35804 (stack52)
        %v35911 = vmul.f32 %v35907, %v35851 (stack53)
        %v35915 = vadd.f32 %v35911, %v35800 (stack52)
        %v35919 = vmul.f32 %v35915, %v35766 (stack53)
        %v35923 = vsel /*vm=*/%vm35771, /*on_true_vy=*/%v35776, /*on_false_vx=*/%v35919 (stack43)
        %v35927 = vmul.f32 1.4140625, %v35923 (stack53)
        %v35930 = vpack.c.bf16 0.0, %v35927 (stack74)
        %119935 = vst [vmem:[%s280 + $0x1a4] sm:$0xf] /*vst_source=*/%v35930 (stack75)
        %v35934 = vadd.s32 %v34087, %v2355 (stack39)
        %v35944 = vadd.s32 %v35934, %v415 (stack39)
        %vm35948 = vcmp.lt.u32.totalorder %v35944, %v35934 (stack42)
        %vm35953 = vcmp.lt.u32.totalorder %v35934, %v2355 (stack42)
        %v35958 = vadd.s32 %v34070, %v2342 (stack39)
        %v35962 = vadd.s32 1, %v35958 (stack39)
        %v35966 = vsel /*vm=*/%vm35953, /*on_true_vy=*/%v35962, /*on_false_vx=*/%v35958 (stack43)
        %v35970 = vadd.s32 1, %v35966 (stack39)
        %v35974 = vsel /*vm=*/%vm35948, /*on_true_vy=*/%v35970, /*on_false_vx=*/%v35966 (stack43)
        %v35979 = vadd.s32 %v35974, %v10 (stack39)
        %v35983 = vadd.s32 %v35944, %v9 (stack39)
        %v35987 = vadd.s32 %v35983, %v35979 (stack39)
        %v35989 = vshll.u32 %v35983, 13 (stack44)
        %v35990 = vshrl.u32 %v35983, 19 (stack45)
        %v35991 = vor.u32 %v35990, %v35989 (stack46)
        %v35992 = vxor.u32 %v35991, %v35987 (stack47)
        %v35995 = vadd.s32 %v35992, %v35987 (stack39)
        %v35997 = vshll.u32 %v35992, 15 (stack44)
        %v35998 = vshrl.u32 %v35992, 17 (stack45)
        %v35999 = vor.u32 %v35998, %v35997 (stack46)
        %v36000 = vxor.u32 %v35999, %v35995 (stack47)
        %v36003 = vadd.s32 %v36000, %v35995 (stack39)
        %v36005 = vshll.u32 %v36000, 26 (stack44)
        %v36006 = vshrl.u32 %v36000, 6 (stack45)
        %v36007 = vor.u32 %v36006, %v36005 (stack46)
        %v36008 = vxor.u32 %v36007, %v36003 (stack47)
        %v36011 = vadd.s32 %v36008, %v36003 (stack39)
        %v36015 = vadd.s32 %v36011, %v9 (stack39)
        %v36017 = vshll.u32 %v36008, 6 (stack44)
        %v36018 = vshrl.u32 %v36008, 26 (stack45)
        %v36019 = vor.u32 %v36018, %v36017 (stack46)
        %v36020 = vxor.u32 %v36019, %v36011 (stack47)
        %v36023 = vadd.s32 %v36020, %v8 (stack39)
        %v36027 = vadd.s32 1, %v36023 (stack39)
        %v36031 = vadd.s32 %v36027, %v36015 (stack39)
        %v36033 = vshll.u32 %v36027, 17 (stack44)
        %v36034 = vshrl.u32 %v36027, 15 (stack45)
        %v36035 = vor.u32 %v36034, %v36033 (stack46)
        %v36036 = vxor.u32 %v36035, %v36031 (stack47)
        %v36039 = vadd.s32 %v36036, %v36031 (stack39)
        %v36041 = vshll.u32 %v36036, 29 (stack44)
        %v36042 = vshrl.u32 %v36036, 3 (stack45)
        %v36043 = vor.u32 %v36042, %v36041 (stack46)
        %v36044 = vxor.u32 %v36043, %v36039 (stack47)
        %v36047 = vadd.s32 %v36044, %v36039 (stack39)
        %v36049 = vshll.u32 %v36044, 16 (stack44)
        %v36050 = vshrl.u32 %v36044, 16 (stack45)
        %v36051 = vor.u32 %v36050, %v36049 (stack46)
        %v36052 = vxor.u32 %v36051, %v36047 (stack47)
        %v36055 = vadd.s32 %v36052, %v36047 (stack39)
        %v36059 = vadd.s32 %v36055, %v8 (stack39)
        %v36061 = vshll.u32 %v36052, 24 (stack44)
        %v36062 = vshrl.u32 %v36052, 8 (stack45)
        %v36063 = vor.u32 %v36062, %v36061 (stack46)
        %v36064 = vxor.u32 %v36063, %v36055 (stack47)
        %v36067 = vadd.s32 %v36064, %v10 (stack39)
        %v36071 = vadd.s32 2, %v36067 (stack39)
        %v36075 = vadd.s32 %v36071, %v36059 (stack39)
        %v36077 = vshll.u32 %v36071, 13 (stack44)
        %v36078 = vshrl.u32 %v36071, 19 (stack45)
        %v36079 = vor.u32 %v36078, %v36077 (stack46)
        %v36080 = vxor.u32 %v36079, %v36075 (stack47)
        %v36083 = vadd.s32 %v36080, %v36075 (stack39)
        %v36085 = vshll.u32 %v36080, 15 (stack44)
        %v36086 = vshrl.u32 %v36080, 17 (stack45)
        %v36087 = vor.u32 %v36086, %v36085 (stack46)
        %v36088 = vxor.u32 %v36087, %v36083 (stack47)
        %v36091 = vadd.s32 %v36088, %v36083 (stack39)
        %v36093 = vshll.u32 %v36088, 26 (stack44)
        %v36094 = vshrl.u32 %v36088, 6 (stack45)
        %v36095 = vor.u32 %v36094, %v36093 (stack46)
        %v36096 = vxor.u32 %v36095, %v36091 (stack47)
        %v36099 = vadd.s32 %v36096, %v36091 (stack39)
        %v36103 = vadd.s32 %v36099, %v10 (stack39)
        %v36105 = vshll.u32 %v36096, 6 (stack44)
        %v36106 = vshrl.u32 %v36096, 26 (stack45)
        %v36107 = vor.u32 %v36106, %v36105 (stack46)
        %v36108 = vxor.u32 %v36107, %v36099 (stack47)
        %v36111 = vadd.s32 %v36108, %v9 (stack39)
        %v36115 = vadd.s32 3, %v36111 (stack39)
        %v36119 = vadd.s32 %v36115, %v36103 (stack39)
        %v36121 = vshll.u32 %v36115, 17 (stack44)
        %v36122 = vshrl.u32 %v36115, 15 (stack45)
        %v36123 = vor.u32 %v36122, %v36121 (stack46)
        %v36124 = vxor.u32 %v36123, %v36119 (stack47)
        %v36127 = vadd.s32 %v36124, %v36119 (stack39)
        %v36129 = vshll.u32 %v36124, 29 (stack44)
        %v36130 = vshrl.u32 %v36124, 3 (stack45)
        %v36131 = vor.u32 %v36130, %v36129 (stack46)
        %v36132 = vxor.u32 %v36131, %v36127 (stack47)
        %v36135 = vadd.s32 %v36132, %v36127 (stack39)
        %v36137 = vshll.u32 %v36132, 16 (stack44)
        %v36138 = vshrl.u32 %v36132, 16 (stack45)
        %v36139 = vor.u32 %v36138, %v36137 (stack46)
        %v36140 = vxor.u32 %v36139, %v36135 (stack47)
        %v36143 = vadd.s32 %v36140, %v36135 (stack39)
        %v36147 = vadd.s32 %v36143, %v9 (stack39)
        %v36149 = vshll.u32 %v36140, 24 (stack44)
        %v36150 = vshrl.u32 %v36140, 8 (stack45)
        %v36151 = vor.u32 %v36150, %v36149 (stack46)
        %v36152 = vxor.u32 %v36151, %v36143 (stack47)
        %v36155 = vadd.s32 %v36152, %v8 (stack39)
        %v36159 = vadd.s32 4, %v36155 (stack39)
        %v36163 = vadd.s32 %v36159, %v36147 (stack39)
        %v36165 = vshll.u32 %v36159, 13 (stack44)
        %v36166 = vshrl.u32 %v36159, 19 (stack45)
        %v36167 = vor.u32 %v36166, %v36165 (stack46)
        %v36168 = vxor.u32 %v36167, %v36163 (stack47)
        %v36171 = vadd.s32 %v36168, %v36163 (stack39)
        %v36173 = vshll.u32 %v36168, 15 (stack44)
        %v36174 = vshrl.u32 %v36168, 17 (stack45)
        %v36175 = vor.u32 %v36174, %v36173 (stack46)
        %v36176 = vxor.u32 %v36175, %v36171 (stack47)
        %v36179 = vadd.s32 %v36176, %v36171 (stack39)
        %v36181 = vshll.u32 %v36176, 26 (stack44)
        %v36182 = vshrl.u32 %v36176, 6 (stack45)
        %v36183 = vor.u32 %v36182, %v36181 (stack46)
        %v36184 = vxor.u32 %v36183, %v36179 (stack47)
        %v36187 = vadd.s32 %v36184, %v36179 (stack39)
        %v36191 = vadd.s32 %v36187, %v8 (stack39)
        %v36193 = vshll.u32 %v36184, 6 (stack44)
        %v36194 = vshrl.u32 %v36184, 26 (stack45)
        %v36195 = vor.u32 %v36194, %v36193 (stack46)
        %v36196 = vxor.u32 %v36195, %v36187 (stack47)
        %v36199 = vadd.s32 %v36196, %v10 (stack39)
        %v36203 = vadd.s32 5, %v36199 (stack39)
        %v36205 = vxor.u32 %v36203, %v36191 (stack47)
        %v36206 = vand.u32.u8 255, %v36205 (stack48)
        %v36207 = vand.u32 65535, %v36206 (stack49)
        %v36208 = vshrl.u32 %v36207, 1 (stack50)
        %v36209 = vor.u32 16256, %v36208 (stack46)
        %v36210 = vand.u32.u16 65535, %v36209 (stack51)
        %v119936 = vadd.low.f32.bf16 -1.0, %v36210 (stack52)
        %v36219 = vmul.f32 2.0, %v119936 (stack53)
        %v36223 = vadd.f32 -0.99609375, %v36219 (stack52)
        %v36227 = vmax.f32 %v36223, -0.99609375 (stack54)
        %v36229 = vand.u32 2147483647, %v36227 (stack55)
        %vm36232 = vcmp.eq.f32.partialorder %v36229, 1.0 (stack56)
        %v36237 = vmul.f32 inf, %v36227 (stack53)
        %v36239 = vxor.u32 2147483648, %v36227 (stack57)
        %v36242 = vmul.f32 %v36239, %v36227 (stack53)
        %v36244 = vadd.f32 1.0, %v36242 (stack58)
        %v36245 = vlog2.pop %v36244 (stack59)
        %v36246 = vmul.f32 0.6931472, %v36245 (stack60)
        %v36247 = vmul.f32 -0.5, %v36242 (stack61)
        %v36248 = vadd.f32 1.0, %v36247 (stack62)
        %v36249 = vmul.f32 %v36248, %v36242 (stack63)
        %v36250 = vand.u32 2147483647, %v36242 (stack64)
        %vm36251 = vcmp.lt.f32.partialorder %v36250, 0.0004427343 (stack65)
        %v36252 = vsel /*vm=*/%vm36251, /*on_true_vy=*/%v36249, /*on_false_vx=*/%v36246 (stack66)
        %v36253 = vxor.u32 2147483648, %v36252 (stack57)
        %vm36256 = vcmp.lt.f32.partialorder %v36253, 5.0 (stack56)
        %v36261 = vsel /*vm=*/%vm36256, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v36265 = vsel /*vm=*/%vm36256, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v36269 = vsel /*vm=*/%vm36256, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v36273 = vsel /*vm=*/%vm36256, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v36277 = vsel /*vm=*/%vm36256, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v36281 = vsel /*vm=*/%vm36256, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v36285 = vsel /*vm=*/%vm36256, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v36289 = vsel /*vm=*/%vm36256, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v36293 = vsel /*vm=*/%vm36256, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v36297 = vadd.f32 -2.5, %v36253 (stack52)
        %v36299 = vrsqrt.pop %v36253 (stack67)
        %v36300 = vmul.f32 %v36299, %v36253 (stack68)
        %vm36301 = vcmp.eq.f32.partialorder %v36253, inf (stack69)
        %v36302 = vsel /*vm=*/%vm36301, /*on_true_vy=*/%v36253, /*on_false_vx=*/%v36300 (stack70)
        %vm36303 = vcmp.eq.f32.partialorder %v36253, 0.0 (stack71)
        %v36304 = vand.u32 2147483648, %v36253 (stack72)
        %v36305 = vsel /*vm=*/%vm36303, /*on_true_vy=*/%v36304, /*on_false_vx=*/%v36302 (stack73)
        %v36308 = vadd.f32 -3.0, %v36305 (stack52)
        %v36312 = vsel /*vm=*/%vm36256, /*on_true_vy=*/%v36297, /*on_false_vx=*/%v36308 (stack43)
        %v36316 = vmul.f32 %v36312, %v36293 (stack53)
        %v36320 = vadd.f32 %v36316, %v36289 (stack52)
        %v36324 = vmul.f32 %v36320, %v36312 (stack53)
        %v36328 = vadd.f32 %v36324, %v36285 (stack52)
        %v36332 = vmul.f32 %v36328, %v36312 (stack53)
        %v36336 = vadd.f32 %v36332, %v36281 (stack52)
        %v36340 = vmul.f32 %v36336, %v36312 (stack53)
        %v36344 = vadd.f32 %v36340, %v36277 (stack52)
        %v36348 = vmul.f32 %v36344, %v36312 (stack53)
        %v36352 = vadd.f32 %v36348, %v36273 (stack52)
        %v36356 = vmul.f32 %v36352, %v36312 (stack53)
        %v36360 = vadd.f32 %v36356, %v36269 (stack52)
        %v36364 = vmul.f32 %v36360, %v36312 (stack53)
        %v36368 = vadd.f32 %v36364, %v36265 (stack52)
        %v36372 = vmul.f32 %v36368, %v36312 (stack53)
        %v36376 = vadd.f32 %v36372, %v36261 (stack52)
        %v36380 = vmul.f32 %v36376, %v36227 (stack53)
        %v36384 = vsel /*vm=*/%vm36232, /*on_true_vy=*/%v36237, /*on_false_vx=*/%v36380 (stack43)
        %v36388 = vmul.f32 1.4140625, %v36384 (stack53)
        %v36391 = vpack.c.bf16 0.0, %v36388 (stack74)
        %119937 = vst [vmem:[%s280 + $0x224] sm:$0xf] /*vst_source=*/%v36391 (stack75)
        %v36395 = vadd.s32 %v34087, %v2842 (stack39)
        %v36405 = vadd.s32 %v36395, %v415 (stack39)
        %vm36409 = vcmp.lt.u32.totalorder %v36405, %v36395 (stack42)
        %vm36414 = vcmp.lt.u32.totalorder %v36395, %v2842 (stack42)
        %v36419 = vadd.s32 %v34070, %v2829 (stack39)
        %v36423 = vadd.s32 1, %v36419 (stack39)
        %v36427 = vsel /*vm=*/%vm36414, /*on_true_vy=*/%v36423, /*on_false_vx=*/%v36419 (stack43)
        %v36431 = vadd.s32 1, %v36427 (stack39)
        %v36435 = vsel /*vm=*/%vm36409, /*on_true_vy=*/%v36431, /*on_false_vx=*/%v36427 (stack43)
        %v36440 = vadd.s32 %v36435, %v10 (stack39)
        %v36444 = vadd.s32 %v36405, %v9 (stack39)
        %v36448 = vadd.s32 %v36444, %v36440 (stack39)
        %v36450 = vshll.u32 %v36444, 13 (stack44)
        %v36451 = vshrl.u32 %v36444, 19 (stack45)
        %v36452 = vor.u32 %v36451, %v36450 (stack46)
        %v36453 = vxor.u32 %v36452, %v36448 (stack47)
        %v36456 = vadd.s32 %v36453, %v36448 (stack39)
        %v36458 = vshll.u32 %v36453, 15 (stack44)
        %v36459 = vshrl.u32 %v36453, 17 (stack45)
        %v36460 = vor.u32 %v36459, %v36458 (stack46)
        %v36461 = vxor.u32 %v36460, %v36456 (stack47)
        %v36464 = vadd.s32 %v36461, %v36456 (stack39)
        %v36466 = vshll.u32 %v36461, 26 (stack44)
        %v36467 = vshrl.u32 %v36461, 6 (stack45)
        %v36468 = vor.u32 %v36467, %v36466 (stack46)
        %v36469 = vxor.u32 %v36468, %v36464 (stack47)
        %v36472 = vadd.s32 %v36469, %v36464 (stack39)
        %v36476 = vadd.s32 %v36472, %v9 (stack39)
        %v36478 = vshll.u32 %v36469, 6 (stack44)
        %v36479 = vshrl.u32 %v36469, 26 (stack45)
        %v36480 = vor.u32 %v36479, %v36478 (stack46)
        %v36481 = vxor.u32 %v36480, %v36472 (stack47)
        %v36484 = vadd.s32 %v36481, %v8 (stack39)
        %v36488 = vadd.s32 1, %v36484 (stack39)
        %v36492 = vadd.s32 %v36488, %v36476 (stack39)
        %v36494 = vshll.u32 %v36488, 17 (stack44)
        %v36495 = vshrl.u32 %v36488, 15 (stack45)
        %v36496 = vor.u32 %v36495, %v36494 (stack46)
        %v36497 = vxor.u32 %v36496, %v36492 (stack47)
        %v36500 = vadd.s32 %v36497, %v36492 (stack39)
        %v36502 = vshll.u32 %v36497, 29 (stack44)
        %v36503 = vshrl.u32 %v36497, 3 (stack45)
        %v36504 = vor.u32 %v36503, %v36502 (stack46)
        %v36505 = vxor.u32 %v36504, %v36500 (stack47)
        %v36508 = vadd.s32 %v36505, %v36500 (stack39)
        %v36510 = vshll.u32 %v36505, 16 (stack44)
        %v36511 = vshrl.u32 %v36505, 16 (stack45)
        %v36512 = vor.u32 %v36511, %v36510 (stack46)
        %v36513 = vxor.u32 %v36512, %v36508 (stack47)
        %v36516 = vadd.s32 %v36513, %v36508 (stack39)
        %v36520 = vadd.s32 %v36516, %v8 (stack39)
        %v36522 = vshll.u32 %v36513, 24 (stack44)
        %v36523 = vshrl.u32 %v36513, 8 (stack45)
        %v36524 = vor.u32 %v36523, %v36522 (stack46)
        %v36525 = vxor.u32 %v36524, %v36516 (stack47)
        %v36528 = vadd.s32 %v36525, %v10 (stack39)
        %v36532 = vadd.s32 2, %v36528 (stack39)
        %v36536 = vadd.s32 %v36532, %v36520 (stack39)
        %v36538 = vshll.u32 %v36532, 13 (stack44)
        %v36539 = vshrl.u32 %v36532, 19 (stack45)
        %v36540 = vor.u32 %v36539, %v36538 (stack46)
        %v36541 = vxor.u32 %v36540, %v36536 (stack47)
        %v36544 = vadd.s32 %v36541, %v36536 (stack39)
        %v36546 = vshll.u32 %v36541, 15 (stack44)
        %v36547 = vshrl.u32 %v36541, 17 (stack45)
        %v36548 = vor.u32 %v36547, %v36546 (stack46)
        %v36549 = vxor.u32 %v36548, %v36544 (stack47)
        %v36552 = vadd.s32 %v36549, %v36544 (stack39)
        %v36554 = vshll.u32 %v36549, 26 (stack44)
        %v36555 = vshrl.u32 %v36549, 6 (stack45)
        %v36556 = vor.u32 %v36555, %v36554 (stack46)
        %v36557 = vxor.u32 %v36556, %v36552 (stack47)
        %v36560 = vadd.s32 %v36557, %v36552 (stack39)
        %v36564 = vadd.s32 %v36560, %v10 (stack39)
        %v36566 = vshll.u32 %v36557, 6 (stack44)
        %v36567 = vshrl.u32 %v36557, 26 (stack45)
        %v36568 = vor.u32 %v36567, %v36566 (stack46)
        %v36569 = vxor.u32 %v36568, %v36560 (stack47)
        %v36572 = vadd.s32 %v36569, %v9 (stack39)
        %v36576 = vadd.s32 3, %v36572 (stack39)
        %v36580 = vadd.s32 %v36576, %v36564 (stack39)
        %v36582 = vshll.u32 %v36576, 17 (stack44)
        %v36583 = vshrl.u32 %v36576, 15 (stack45)
        %v36584 = vor.u32 %v36583, %v36582 (stack46)
        %v36585 = vxor.u32 %v36584, %v36580 (stack47)
        %v36588 = vadd.s32 %v36585, %v36580 (stack39)
        %v36590 = vshll.u32 %v36585, 29 (stack44)
        %v36591 = vshrl.u32 %v36585, 3 (stack45)
        %v36592 = vor.u32 %v36591, %v36590 (stack46)
        %v36593 = vxor.u32 %v36592, %v36588 (stack47)
        %v36596 = vadd.s32 %v36593, %v36588 (stack39)
        %v36598 = vshll.u32 %v36593, 16 (stack44)
        %v36599 = vshrl.u32 %v36593, 16 (stack45)
        %v36600 = vor.u32 %v36599, %v36598 (stack46)
        %v36601 = vxor.u32 %v36600, %v36596 (stack47)
        %v36604 = vadd.s32 %v36601, %v36596 (stack39)
        %v36608 = vadd.s32 %v36604, %v9 (stack39)
        %v36610 = vshll.u32 %v36601, 24 (stack44)
        %v36611 = vshrl.u32 %v36601, 8 (stack45)
        %v36612 = vor.u32 %v36611, %v36610 (stack46)
        %v36613 = vxor.u32 %v36612, %v36604 (stack47)
        %v36616 = vadd.s32 %v36613, %v8 (stack39)
        %v36620 = vadd.s32 4, %v36616 (stack39)
        %v36624 = vadd.s32 %v36620, %v36608 (stack39)
        %v36626 = vshll.u32 %v36620, 13 (stack44)
        %v36627 = vshrl.u32 %v36620, 19 (stack45)
        %v36628 = vor.u32 %v36627, %v36626 (stack46)
        %v36629 = vxor.u32 %v36628, %v36624 (stack47)
        %v36632 = vadd.s32 %v36629, %v36624 (stack39)
        %v36634 = vshll.u32 %v36629, 15 (stack44)
        %v36635 = vshrl.u32 %v36629, 17 (stack45)
        %v36636 = vor.u32 %v36635, %v36634 (stack46)
        %v36637 = vxor.u32 %v36636, %v36632 (stack47)
        %v36640 = vadd.s32 %v36637, %v36632 (stack39)
        %v36642 = vshll.u32 %v36637, 26 (stack44)
        %v36643 = vshrl.u32 %v36637, 6 (stack45)
        %v36644 = vor.u32 %v36643, %v36642 (stack46)
        %v36645 = vxor.u32 %v36644, %v36640 (stack47)
        %v36648 = vadd.s32 %v36645, %v36640 (stack39)
        %v36652 = vadd.s32 %v36648, %v8 (stack39)
        %v36654 = vshll.u32 %v36645, 6 (stack44)
        %v36655 = vshrl.u32 %v36645, 26 (stack45)
        %v36656 = vor.u32 %v36655, %v36654 (stack46)
        %v36657 = vxor.u32 %v36656, %v36648 (stack47)
        %v36660 = vadd.s32 %v36657, %v10 (stack39)
        %v36664 = vadd.s32 5, %v36660 (stack39)
        %v36666 = vxor.u32 %v36664, %v36652 (stack47)
        %v36667 = vand.u32.u8 255, %v36666 (stack48)
        %v36668 = vand.u32 65535, %v36667 (stack49)
        %v36669 = vshrl.u32 %v36668, 1 (stack50)
        %v36670 = vor.u32 16256, %v36669 (stack46)
        %v36671 = vand.u32.u16 65535, %v36670 (stack51)
        %v119938 = vadd.low.f32.bf16 -1.0, %v36671 (stack52)
        %v36680 = vmul.f32 2.0, %v119938 (stack53)
        %v36684 = vadd.f32 -0.99609375, %v36680 (stack52)
        %v36688 = vmax.f32 %v36684, -0.99609375 (stack54)
        %v36690 = vand.u32 2147483647, %v36688 (stack55)
        %vm36693 = vcmp.eq.f32.partialorder %v36690, 1.0 (stack56)
        %v36698 = vmul.f32 inf, %v36688 (stack53)
        %v36700 = vxor.u32 2147483648, %v36688 (stack57)
        %v36703 = vmul.f32 %v36700, %v36688 (stack53)
        %v36705 = vadd.f32 1.0, %v36703 (stack58)
        %v36706 = vlog2.pop %v36705 (stack59)
        %v36707 = vmul.f32 0.6931472, %v36706 (stack60)
        %v36708 = vmul.f32 -0.5, %v36703 (stack61)
        %v36709 = vadd.f32 1.0, %v36708 (stack62)
        %v36710 = vmul.f32 %v36709, %v36703 (stack63)
        %v36711 = vand.u32 2147483647, %v36703 (stack64)
        %vm36712 = vcmp.lt.f32.partialorder %v36711, 0.0004427343 (stack65)
        %v36713 = vsel /*vm=*/%vm36712, /*on_true_vy=*/%v36710, /*on_false_vx=*/%v36707 (stack66)
        %v36714 = vxor.u32 2147483648, %v36713 (stack57)
        %vm36717 = vcmp.lt.f32.partialorder %v36714, 5.0 (stack56)
        %v36722 = vsel /*vm=*/%vm36717, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v36726 = vsel /*vm=*/%vm36717, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v36730 = vsel /*vm=*/%vm36717, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v36734 = vsel /*vm=*/%vm36717, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v36738 = vsel /*vm=*/%vm36717, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v36742 = vsel /*vm=*/%vm36717, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v36746 = vsel /*vm=*/%vm36717, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v36750 = vsel /*vm=*/%vm36717, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v36754 = vsel /*vm=*/%vm36717, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v36758 = vadd.f32 -2.5, %v36714 (stack52)
        %v36760 = vrsqrt.pop %v36714 (stack67)
        %v36761 = vmul.f32 %v36760, %v36714 (stack68)
        %vm36762 = vcmp.eq.f32.partialorder %v36714, inf (stack69)
        %v36763 = vsel /*vm=*/%vm36762, /*on_true_vy=*/%v36714, /*on_false_vx=*/%v36761 (stack70)
        %vm36764 = vcmp.eq.f32.partialorder %v36714, 0.0 (stack71)
        %v36765 = vand.u32 2147483648, %v36714 (stack72)
        %v36766 = vsel /*vm=*/%vm36764, /*on_true_vy=*/%v36765, /*on_false_vx=*/%v36763 (stack73)
        %v36769 = vadd.f32 -3.0, %v36766 (stack52)
        %v36773 = vsel /*vm=*/%vm36717, /*on_true_vy=*/%v36758, /*on_false_vx=*/%v36769 (stack43)
        %v36777 = vmul.f32 %v36773, %v36754 (stack53)
        %v36781 = vadd.f32 %v36777, %v36750 (stack52)
        %v36785 = vmul.f32 %v36781, %v36773 (stack53)
        %v36789 = vadd.f32 %v36785, %v36746 (stack52)
        %v36793 = vmul.f32 %v36789, %v36773 (stack53)
        %v36797 = vadd.f32 %v36793, %v36742 (stack52)
        %v36801 = vmul.f32 %v36797, %v36773 (stack53)
        %v36805 = vadd.f32 %v36801, %v36738 (stack52)
        %v36809 = vmul.f32 %v36805, %v36773 (stack53)
        %v36813 = vadd.f32 %v36809, %v36734 (stack52)
        %v36817 = vmul.f32 %v36813, %v36773 (stack53)
        %v36821 = vadd.f32 %v36817, %v36730 (stack52)
        %v36825 = vmul.f32 %v36821, %v36773 (stack53)
        %v36829 = vadd.f32 %v36825, %v36726 (stack52)
        %v36833 = vmul.f32 %v36829, %v36773 (stack53)
        %v36837 = vadd.f32 %v36833, %v36722 (stack52)
        %v36841 = vmul.f32 %v36837, %v36688 (stack53)
        %v36845 = vsel /*vm=*/%vm36693, /*on_true_vy=*/%v36698, /*on_false_vx=*/%v36841 (stack43)
        %v36849 = vmul.f32 1.4140625, %v36845 (stack53)
        %v36852 = vpack.c.bf16 0.0, %v36849 (stack74)
        %119939 = vst [vmem:[%s280 + $0x2a4] sm:$0xf] /*vst_source=*/%v36852 (stack75)
        %v36856 = vadd.s32 %v34087, %v3329 (stack39)
        %v36866 = vadd.s32 %v36856, %v415 (stack39)
        %vm36870 = vcmp.lt.u32.totalorder %v36866, %v36856 (stack42)
        %vm36875 = vcmp.lt.u32.totalorder %v36856, %v3329 (stack42)
        %v36880 = vadd.s32 %v34070, %v3316 (stack39)
        %v36884 = vadd.s32 1, %v36880 (stack39)
        %v36888 = vsel /*vm=*/%vm36875, /*on_true_vy=*/%v36884, /*on_false_vx=*/%v36880 (stack43)
        %v36892 = vadd.s32 1, %v36888 (stack39)
        %v36896 = vsel /*vm=*/%vm36870, /*on_true_vy=*/%v36892, /*on_false_vx=*/%v36888 (stack43)
        %v36901 = vadd.s32 %v36896, %v10 (stack39)
        %v36905 = vadd.s32 %v36866, %v9 (stack39)
        %v36909 = vadd.s32 %v36905, %v36901 (stack39)
        %v36911 = vshll.u32 %v36905, 13 (stack44)
        %v36912 = vshrl.u32 %v36905, 19 (stack45)
        %v36913 = vor.u32 %v36912, %v36911 (stack46)
        %v36914 = vxor.u32 %v36913, %v36909 (stack47)
        %v36917 = vadd.s32 %v36914, %v36909 (stack39)
        %v36919 = vshll.u32 %v36914, 15 (stack44)
        %v36920 = vshrl.u32 %v36914, 17 (stack45)
        %v36921 = vor.u32 %v36920, %v36919 (stack46)
        %v36922 = vxor.u32 %v36921, %v36917 (stack47)
        %v36925 = vadd.s32 %v36922, %v36917 (stack39)
        %v36927 = vshll.u32 %v36922, 26 (stack44)
        %v36928 = vshrl.u32 %v36922, 6 (stack45)
        %v36929 = vor.u32 %v36928, %v36927 (stack46)
        %v36930 = vxor.u32 %v36929, %v36925 (stack47)
        %v36933 = vadd.s32 %v36930, %v36925 (stack39)
        %v36937 = vadd.s32 %v36933, %v9 (stack39)
        %v36939 = vshll.u32 %v36930, 6 (stack44)
        %v36940 = vshrl.u32 %v36930, 26 (stack45)
        %v36941 = vor.u32 %v36940, %v36939 (stack46)
        %v36942 = vxor.u32 %v36941, %v36933 (stack47)
        %v36945 = vadd.s32 %v36942, %v8 (stack39)
        %v36949 = vadd.s32 1, %v36945 (stack39)
        %v36953 = vadd.s32 %v36949, %v36937 (stack39)
        %v36955 = vshll.u32 %v36949, 17 (stack44)
        %v36956 = vshrl.u32 %v36949, 15 (stack45)
        %v36957 = vor.u32 %v36956, %v36955 (stack46)
        %v36958 = vxor.u32 %v36957, %v36953 (stack47)
        %v36961 = vadd.s32 %v36958, %v36953 (stack39)
        %v36963 = vshll.u32 %v36958, 29 (stack44)
        %v36964 = vshrl.u32 %v36958, 3 (stack45)
        %v36965 = vor.u32 %v36964, %v36963 (stack46)
        %v36966 = vxor.u32 %v36965, %v36961 (stack47)
        %v36969 = vadd.s32 %v36966, %v36961 (stack39)
        %v36971 = vshll.u32 %v36966, 16 (stack44)
        %v36972 = vshrl.u32 %v36966, 16 (stack45)
        %v36973 = vor.u32 %v36972, %v36971 (stack46)
        %v36974 = vxor.u32 %v36973, %v36969 (stack47)
        %v36977 = vadd.s32 %v36974, %v36969 (stack39)
        %v36981 = vadd.s32 %v36977, %v8 (stack39)
        %v36983 = vshll.u32 %v36974, 24 (stack44)
        %v36984 = vshrl.u32 %v36974, 8 (stack45)
        %v36985 = vor.u32 %v36984, %v36983 (stack46)
        %v36986 = vxor.u32 %v36985, %v36977 (stack47)
        %v36989 = vadd.s32 %v36986, %v10 (stack39)
        %v36993 = vadd.s32 2, %v36989 (stack39)
        %v36997 = vadd.s32 %v36993, %v36981 (stack39)
        %v36999 = vshll.u32 %v36993, 13 (stack44)
        %v37000 = vshrl.u32 %v36993, 19 (stack45)
        %v37001 = vor.u32 %v37000, %v36999 (stack46)
        %v37002 = vxor.u32 %v37001, %v36997 (stack47)
        %v37005 = vadd.s32 %v37002, %v36997 (stack39)
        %v37007 = vshll.u32 %v37002, 15 (stack44)
        %v37008 = vshrl.u32 %v37002, 17 (stack45)
        %v37009 = vor.u32 %v37008, %v37007 (stack46)
        %v37010 = vxor.u32 %v37009, %v37005 (stack47)
        %v37013 = vadd.s32 %v37010, %v37005 (stack39)
        %v37015 = vshll.u32 %v37010, 26 (stack44)
        %v37016 = vshrl.u32 %v37010, 6 (stack45)
        %v37017 = vor.u32 %v37016, %v37015 (stack46)
        %v37018 = vxor.u32 %v37017, %v37013 (stack47)
        %v37021 = vadd.s32 %v37018, %v37013 (stack39)
        %v37025 = vadd.s32 %v37021, %v10 (stack39)
        %v37027 = vshll.u32 %v37018, 6 (stack44)
        %v37028 = vshrl.u32 %v37018, 26 (stack45)
        %v37029 = vor.u32 %v37028, %v37027 (stack46)
        %v37030 = vxor.u32 %v37029, %v37021 (stack47)
        %v37033 = vadd.s32 %v37030, %v9 (stack39)
        %v37037 = vadd.s32 3, %v37033 (stack39)
        %v37041 = vadd.s32 %v37037, %v37025 (stack39)
        %v37043 = vshll.u32 %v37037, 17 (stack44)
        %v37044 = vshrl.u32 %v37037, 15 (stack45)
        %v37045 = vor.u32 %v37044, %v37043 (stack46)
        %v37046 = vxor.u32 %v37045, %v37041 (stack47)
        %v37049 = vadd.s32 %v37046, %v37041 (stack39)
        %v37051 = vshll.u32 %v37046, 29 (stack44)
        %v37052 = vshrl.u32 %v37046, 3 (stack45)
        %v37053 = vor.u32 %v37052, %v37051 (stack46)
        %v37054 = vxor.u32 %v37053, %v37049 (stack47)
        %v37057 = vadd.s32 %v37054, %v37049 (stack39)
        %v37059 = vshll.u32 %v37054, 16 (stack44)
        %v37060 = vshrl.u32 %v37054, 16 (stack45)
        %v37061 = vor.u32 %v37060, %v37059 (stack46)
        %v37062 = vxor.u32 %v37061, %v37057 (stack47)
        %v37065 = vadd.s32 %v37062, %v37057 (stack39)
        %v37069 = vadd.s32 %v37065, %v9 (stack39)
        %v37071 = vshll.u32 %v37062, 24 (stack44)
        %v37072 = vshrl.u32 %v37062, 8 (stack45)
        %v37073 = vor.u32 %v37072, %v37071 (stack46)
        %v37074 = vxor.u32 %v37073, %v37065 (stack47)
        %v37077 = vadd.s32 %v37074, %v8 (stack39)
        %v37081 = vadd.s32 4, %v37077 (stack39)
        %v37085 = vadd.s32 %v37081, %v37069 (stack39)
        %v37087 = vshll.u32 %v37081, 13 (stack44)
        %v37088 = vshrl.u32 %v37081, 19 (stack45)
        %v37089 = vor.u32 %v37088, %v37087 (stack46)
        %v37090 = vxor.u32 %v37089, %v37085 (stack47)
        %v37093 = vadd.s32 %v37090, %v37085 (stack39)
        %v37095 = vshll.u32 %v37090, 15 (stack44)
        %v37096 = vshrl.u32 %v37090, 17 (stack45)
        %v37097 = vor.u32 %v37096, %v37095 (stack46)
        %v37098 = vxor.u32 %v37097, %v37093 (stack47)
        %v37101 = vadd.s32 %v37098, %v37093 (stack39)
        %v37103 = vshll.u32 %v37098, 26 (stack44)
        %v37104 = vshrl.u32 %v37098, 6 (stack45)
        %v37105 = vor.u32 %v37104, %v37103 (stack46)
        %v37106 = vxor.u32 %v37105, %v37101 (stack47)
        %v37109 = vadd.s32 %v37106, %v37101 (stack39)
        %v37113 = vadd.s32 %v37109, %v8 (stack39)
        %v37115 = vshll.u32 %v37106, 6 (stack44)
        %v37116 = vshrl.u32 %v37106, 26 (stack45)
        %v37117 = vor.u32 %v37116, %v37115 (stack46)
        %v37118 = vxor.u32 %v37117, %v37109 (stack47)
        %v37121 = vadd.s32 %v37118, %v10 (stack39)
        %v37125 = vadd.s32 5, %v37121 (stack39)
        %v37127 = vxor.u32 %v37125, %v37113 (stack47)
        %v37128 = vand.u32.u8 255, %v37127 (stack48)
        %v37129 = vand.u32 65535, %v37128 (stack49)
        %v37130 = vshrl.u32 %v37129, 1 (stack50)
        %v37131 = vor.u32 16256, %v37130 (stack46)
        %v37132 = vand.u32.u16 65535, %v37131 (stack51)
        %v119940 = vadd.low.f32.bf16 -1.0, %v37132 (stack52)
        %v37141 = vmul.f32 2.0, %v119940 (stack53)
        %v37145 = vadd.f32 -0.99609375, %v37141 (stack52)
        %v37149 = vmax.f32 %v37145, -0.99609375 (stack54)
        %v37151 = vand.u32 2147483647, %v37149 (stack55)
        %vm37154 = vcmp.eq.f32.partialorder %v37151, 1.0 (stack56)
        %v37159 = vmul.f32 inf, %v37149 (stack53)
        %v37161 = vxor.u32 2147483648, %v37149 (stack57)
        %v37164 = vmul.f32 %v37161, %v37149 (stack53)
        %v37166 = vadd.f32 1.0, %v37164 (stack58)
        %v37167 = vlog2.pop %v37166 (stack59)
        %v37168 = vmul.f32 0.6931472, %v37167 (stack60)
        %v37169 = vmul.f32 -0.5, %v37164 (stack61)
        %v37170 = vadd.f32 1.0, %v37169 (stack62)
        %v37171 = vmul.f32 %v37170, %v37164 (stack63)
        %v37172 = vand.u32 2147483647, %v37164 (stack64)
        %vm37173 = vcmp.lt.f32.partialorder %v37172, 0.0004427343 (stack65)
        %v37174 = vsel /*vm=*/%vm37173, /*on_true_vy=*/%v37171, /*on_false_vx=*/%v37168 (stack66)
        %v37175 = vxor.u32 2147483648, %v37174 (stack57)
        %vm37178 = vcmp.lt.f32.partialorder %v37175, 5.0 (stack56)
        %v37183 = vsel /*vm=*/%vm37178, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v37187 = vsel /*vm=*/%vm37178, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v37191 = vsel /*vm=*/%vm37178, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v37195 = vsel /*vm=*/%vm37178, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v37199 = vsel /*vm=*/%vm37178, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v37203 = vsel /*vm=*/%vm37178, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v37207 = vsel /*vm=*/%vm37178, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v37211 = vsel /*vm=*/%vm37178, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v37215 = vsel /*vm=*/%vm37178, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v37219 = vadd.f32 -2.5, %v37175 (stack52)
        %v37221 = vrsqrt.pop %v37175 (stack67)
        %v37222 = vmul.f32 %v37221, %v37175 (stack68)
        %vm37223 = vcmp.eq.f32.partialorder %v37175, inf (stack69)
        %v37224 = vsel /*vm=*/%vm37223, /*on_true_vy=*/%v37175, /*on_false_vx=*/%v37222 (stack70)
        %vm37225 = vcmp.eq.f32.partialorder %v37175, 0.0 (stack71)
        %v37226 = vand.u32 2147483648, %v37175 (stack72)
        %v37227 = vsel /*vm=*/%vm37225, /*on_true_vy=*/%v37226, /*on_false_vx=*/%v37224 (stack73)
        %v37230 = vadd.f32 -3.0, %v37227 (stack52)
        %v37234 = vsel /*vm=*/%vm37178, /*on_true_vy=*/%v37219, /*on_false_vx=*/%v37230 (stack43)
        %v37238 = vmul.f32 %v37234, %v37215 (stack53)
        %v37242 = vadd.f32 %v37238, %v37211 (stack52)
        %v37246 = vmul.f32 %v37242, %v37234 (stack53)
        %v37250 = vadd.f32 %v37246, %v37207 (stack52)
        %v37254 = vmul.f32 %v37250, %v37234 (stack53)
        %v37258 = vadd.f32 %v37254, %v37203 (stack52)
        %v37262 = vmul.f32 %v37258, %v37234 (stack53)
        %v37266 = vadd.f32 %v37262, %v37199 (stack52)
        %v37270 = vmul.f32 %v37266, %v37234 (stack53)
        %v37274 = vadd.f32 %v37270, %v37195 (stack52)
        %v37278 = vmul.f32 %v37274, %v37234 (stack53)
        %v37282 = vadd.f32 %v37278, %v37191 (stack52)
        %v37286 = vmul.f32 %v37282, %v37234 (stack53)
        %v37290 = vadd.f32 %v37286, %v37187 (stack52)
        %v37294 = vmul.f32 %v37290, %v37234 (stack53)
        %v37298 = vadd.f32 %v37294, %v37183 (stack52)
        %v37302 = vmul.f32 %v37298, %v37149 (stack53)
        %v37306 = vsel /*vm=*/%vm37154, /*on_true_vy=*/%v37159, /*on_false_vx=*/%v37302 (stack43)
        %v37310 = vmul.f32 1.4140625, %v37306 (stack53)
        %v37313 = vpack.c.bf16 0.0, %v37310 (stack74)
        %119941 = vst [vmem:[%s280 + $0x324] sm:$0xf] /*vst_source=*/%v37313 (stack75)
        %v37317 = vadd.s32 %v34087, %v3816 (stack39)
        %v37327 = vadd.s32 %v37317, %v415 (stack39)
        %vm37331 = vcmp.lt.u32.totalorder %v37327, %v37317 (stack42)
        %vm37336 = vcmp.lt.u32.totalorder %v37317, %v3816 (stack42)
        %v37341 = vadd.s32 %v34070, %v3803 (stack39)
        %v37345 = vadd.s32 1, %v37341 (stack39)
        %v37349 = vsel /*vm=*/%vm37336, /*on_true_vy=*/%v37345, /*on_false_vx=*/%v37341 (stack43)
        %v37353 = vadd.s32 1, %v37349 (stack39)
        %v37357 = vsel /*vm=*/%vm37331, /*on_true_vy=*/%v37353, /*on_false_vx=*/%v37349 (stack43)
        %v37362 = vadd.s32 %v37357, %v10 (stack39)
        %v37366 = vadd.s32 %v37327, %v9 (stack39)
        %v37370 = vadd.s32 %v37366, %v37362 (stack39)
        %v37372 = vshll.u32 %v37366, 13 (stack44)
        %v37373 = vshrl.u32 %v37366, 19 (stack45)
        %v37374 = vor.u32 %v37373, %v37372 (stack46)
        %v37375 = vxor.u32 %v37374, %v37370 (stack47)
        %v37378 = vadd.s32 %v37375, %v37370 (stack39)
        %v37380 = vshll.u32 %v37375, 15 (stack44)
        %v37381 = vshrl.u32 %v37375, 17 (stack45)
        %v37382 = vor.u32 %v37381, %v37380 (stack46)
        %v37383 = vxor.u32 %v37382, %v37378 (stack47)
        %v37386 = vadd.s32 %v37383, %v37378 (stack39)
        %v37388 = vshll.u32 %v37383, 26 (stack44)
        %v37389 = vshrl.u32 %v37383, 6 (stack45)
        %v37390 = vor.u32 %v37389, %v37388 (stack46)
        %v37391 = vxor.u32 %v37390, %v37386 (stack47)
        %v37394 = vadd.s32 %v37391, %v37386 (stack39)
        %v37398 = vadd.s32 %v37394, %v9 (stack39)
        %v37400 = vshll.u32 %v37391, 6 (stack44)
        %v37401 = vshrl.u32 %v37391, 26 (stack45)
        %v37402 = vor.u32 %v37401, %v37400 (stack46)
        %v37403 = vxor.u32 %v37402, %v37394 (stack47)
        %v37406 = vadd.s32 %v37403, %v8 (stack39)
        %v37410 = vadd.s32 1, %v37406 (stack39)
        %v37414 = vadd.s32 %v37410, %v37398 (stack39)
        %v37416 = vshll.u32 %v37410, 17 (stack44)
        %v37417 = vshrl.u32 %v37410, 15 (stack45)
        %v37418 = vor.u32 %v37417, %v37416 (stack46)
        %v37419 = vxor.u32 %v37418, %v37414 (stack47)
        %v37422 = vadd.s32 %v37419, %v37414 (stack39)
        %v37424 = vshll.u32 %v37419, 29 (stack44)
        %v37425 = vshrl.u32 %v37419, 3 (stack45)
        %v37426 = vor.u32 %v37425, %v37424 (stack46)
        %v37427 = vxor.u32 %v37426, %v37422 (stack47)
        %v37430 = vadd.s32 %v37427, %v37422 (stack39)
        %v37432 = vshll.u32 %v37427, 16 (stack44)
        %v37433 = vshrl.u32 %v37427, 16 (stack45)
        %v37434 = vor.u32 %v37433, %v37432 (stack46)
        %v37435 = vxor.u32 %v37434, %v37430 (stack47)
        %v37438 = vadd.s32 %v37435, %v37430 (stack39)
        %v37442 = vadd.s32 %v37438, %v8 (stack39)
        %v37444 = vshll.u32 %v37435, 24 (stack44)
        %v37445 = vshrl.u32 %v37435, 8 (stack45)
        %v37446 = vor.u32 %v37445, %v37444 (stack46)
        %v37447 = vxor.u32 %v37446, %v37438 (stack47)
        %v37450 = vadd.s32 %v37447, %v10 (stack39)
        %v37454 = vadd.s32 2, %v37450 (stack39)
        %v37458 = vadd.s32 %v37454, %v37442 (stack39)
        %v37460 = vshll.u32 %v37454, 13 (stack44)
        %v37461 = vshrl.u32 %v37454, 19 (stack45)
        %v37462 = vor.u32 %v37461, %v37460 (stack46)
        %v37463 = vxor.u32 %v37462, %v37458 (stack47)
        %v37466 = vadd.s32 %v37463, %v37458 (stack39)
        %v37468 = vshll.u32 %v37463, 15 (stack44)
        %v37469 = vshrl.u32 %v37463, 17 (stack45)
        %v37470 = vor.u32 %v37469, %v37468 (stack46)
        %v37471 = vxor.u32 %v37470, %v37466 (stack47)
        %v37474 = vadd.s32 %v37471, %v37466 (stack39)
        %v37476 = vshll.u32 %v37471, 26 (stack44)
        %v37477 = vshrl.u32 %v37471, 6 (stack45)
        %v37478 = vor.u32 %v37477, %v37476 (stack46)
        %v37479 = vxor.u32 %v37478, %v37474 (stack47)
        %v37482 = vadd.s32 %v37479, %v37474 (stack39)
        %v37486 = vadd.s32 %v37482, %v10 (stack39)
        %v37488 = vshll.u32 %v37479, 6 (stack44)
        %v37489 = vshrl.u32 %v37479, 26 (stack45)
        %v37490 = vor.u32 %v37489, %v37488 (stack46)
        %v37491 = vxor.u32 %v37490, %v37482 (stack47)
        %v37494 = vadd.s32 %v37491, %v9 (stack39)
        %v37498 = vadd.s32 3, %v37494 (stack39)
        %v37502 = vadd.s32 %v37498, %v37486 (stack39)
        %v37504 = vshll.u32 %v37498, 17 (stack44)
        %v37505 = vshrl.u32 %v37498, 15 (stack45)
        %v37506 = vor.u32 %v37505, %v37504 (stack46)
        %v37507 = vxor.u32 %v37506, %v37502 (stack47)
        %v37510 = vadd.s32 %v37507, %v37502 (stack39)
        %v37512 = vshll.u32 %v37507, 29 (stack44)
        %v37513 = vshrl.u32 %v37507, 3 (stack45)
        %v37514 = vor.u32 %v37513, %v37512 (stack46)
        %v37515 = vxor.u32 %v37514, %v37510 (stack47)
        %v37518 = vadd.s32 %v37515, %v37510 (stack39)
        %v37520 = vshll.u32 %v37515, 16 (stack44)
        %v37521 = vshrl.u32 %v37515, 16 (stack45)
        %v37522 = vor.u32 %v37521, %v37520 (stack46)
        %v37523 = vxor.u32 %v37522, %v37518 (stack47)
        %v37526 = vadd.s32 %v37523, %v37518 (stack39)
        %v37530 = vadd.s32 %v37526, %v9 (stack39)
        %v37532 = vshll.u32 %v37523, 24 (stack44)
        %v37533 = vshrl.u32 %v37523, 8 (stack45)
        %v37534 = vor.u32 %v37533, %v37532 (stack46)
        %v37535 = vxor.u32 %v37534, %v37526 (stack47)
        %v37538 = vadd.s32 %v37535, %v8 (stack39)
        %v37542 = vadd.s32 4, %v37538 (stack39)
        %v37546 = vadd.s32 %v37542, %v37530 (stack39)
        %v37548 = vshll.u32 %v37542, 13 (stack44)
        %v37549 = vshrl.u32 %v37542, 19 (stack45)
        %v37550 = vor.u32 %v37549, %v37548 (stack46)
        %v37551 = vxor.u32 %v37550, %v37546 (stack47)
        %v37554 = vadd.s32 %v37551, %v37546 (stack39)
        %v37556 = vshll.u32 %v37551, 15 (stack44)
        %v37557 = vshrl.u32 %v37551, 17 (stack45)
        %v37558 = vor.u32 %v37557, %v37556 (stack46)
        %v37559 = vxor.u32 %v37558, %v37554 (stack47)
        %v37562 = vadd.s32 %v37559, %v37554 (stack39)
        %v37564 = vshll.u32 %v37559, 26 (stack44)
        %v37565 = vshrl.u32 %v37559, 6 (stack45)
        %v37566 = vor.u32 %v37565, %v37564 (stack46)
        %v37567 = vxor.u32 %v37566, %v37562 (stack47)
        %v37570 = vadd.s32 %v37567, %v37562 (stack39)
        %v37574 = vadd.s32 %v37570, %v8 (stack39)
        %v37576 = vshll.u32 %v37567, 6 (stack44)
        %v37577 = vshrl.u32 %v37567, 26 (stack45)
        %v37578 = vor.u32 %v37577, %v37576 (stack46)
        %v37579 = vxor.u32 %v37578, %v37570 (stack47)
        %v37582 = vadd.s32 %v37579, %v10 (stack39)
        %v37586 = vadd.s32 5, %v37582 (stack39)
        %v37588 = vxor.u32 %v37586, %v37574 (stack47)
        %v37589 = vand.u32.u8 255, %v37588 (stack48)
        %v37590 = vand.u32 65535, %v37589 (stack49)
        %v37591 = vshrl.u32 %v37590, 1 (stack50)
        %v37592 = vor.u32 16256, %v37591 (stack46)
        %v37593 = vand.u32.u16 65535, %v37592 (stack51)
        %v119942 = vadd.low.f32.bf16 -1.0, %v37593 (stack52)
        %v37602 = vmul.f32 2.0, %v119942 (stack53)
        %v37606 = vadd.f32 -0.99609375, %v37602 (stack52)
        %v37610 = vmax.f32 %v37606, -0.99609375 (stack54)
        %v37612 = vand.u32 2147483647, %v37610 (stack55)
        %vm37615 = vcmp.eq.f32.partialorder %v37612, 1.0 (stack56)
        %v37620 = vmul.f32 inf, %v37610 (stack53)
        %v37622 = vxor.u32 2147483648, %v37610 (stack57)
        %v37625 = vmul.f32 %v37622, %v37610 (stack53)
        %v37627 = vadd.f32 1.0, %v37625 (stack58)
        %v37628 = vlog2.pop %v37627 (stack59)
        %v37629 = vmul.f32 0.6931472, %v37628 (stack60)
        %v37630 = vmul.f32 -0.5, %v37625 (stack61)
        %v37631 = vadd.f32 1.0, %v37630 (stack62)
        %v37632 = vmul.f32 %v37631, %v37625 (stack63)
        %v37633 = vand.u32 2147483647, %v37625 (stack64)
        %vm37634 = vcmp.lt.f32.partialorder %v37633, 0.0004427343 (stack65)
        %v37635 = vsel /*vm=*/%vm37634, /*on_true_vy=*/%v37632, /*on_false_vx=*/%v37629 (stack66)
        %v37636 = vxor.u32 2147483648, %v37635 (stack57)
        %vm37639 = vcmp.lt.f32.partialorder %v37636, 5.0 (stack56)
        %v37644 = vsel /*vm=*/%vm37639, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v37648 = vsel /*vm=*/%vm37639, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v37652 = vsel /*vm=*/%vm37639, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v37656 = vsel /*vm=*/%vm37639, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v37660 = vsel /*vm=*/%vm37639, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v37664 = vsel /*vm=*/%vm37639, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v37668 = vsel /*vm=*/%vm37639, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v37672 = vsel /*vm=*/%vm37639, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v37676 = vsel /*vm=*/%vm37639, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v37680 = vadd.f32 -2.5, %v37636 (stack52)
        %v37682 = vrsqrt.pop %v37636 (stack67)
        %v37683 = vmul.f32 %v37682, %v37636 (stack68)
        %vm37684 = vcmp.eq.f32.partialorder %v37636, inf (stack69)
        %v37685 = vsel /*vm=*/%vm37684, /*on_true_vy=*/%v37636, /*on_false_vx=*/%v37683 (stack70)
        %vm37686 = vcmp.eq.f32.partialorder %v37636, 0.0 (stack71)
        %v37687 = vand.u32 2147483648, %v37636 (stack72)
        %v37688 = vsel /*vm=*/%vm37686, /*on_true_vy=*/%v37687, /*on_false_vx=*/%v37685 (stack73)
        %v37691 = vadd.f32 -3.0, %v37688 (stack52)
        %v37695 = vsel /*vm=*/%vm37639, /*on_true_vy=*/%v37680, /*on_false_vx=*/%v37691 (stack43)
        %v37699 = vmul.f32 %v37695, %v37676 (stack53)
        %v37703 = vadd.f32 %v37699, %v37672 (stack52)
        %v37707 = vmul.f32 %v37703, %v37695 (stack53)
        %v37711 = vadd.f32 %v37707, %v37668 (stack52)
        %v37715 = vmul.f32 %v37711, %v37695 (stack53)
        %v37719 = vadd.f32 %v37715, %v37664 (stack52)
        %v37723 = vmul.f32 %v37719, %v37695 (stack53)
        %v37727 = vadd.f32 %v37723, %v37660 (stack52)
        %v37731 = vmul.f32 %v37727, %v37695 (stack53)
        %v37735 = vadd.f32 %v37731, %v37656 (stack52)
        %v37739 = vmul.f32 %v37735, %v37695 (stack53)
        %v37743 = vadd.f32 %v37739, %v37652 (stack52)
        %v37747 = vmul.f32 %v37743, %v37695 (stack53)
        %v37751 = vadd.f32 %v37747, %v37648 (stack52)
        %v37755 = vmul.f32 %v37751, %v37695 (stack53)
        %v37759 = vadd.f32 %v37755, %v37644 (stack52)
        %v37763 = vmul.f32 %v37759, %v37610 (stack53)
        %v37767 = vsel /*vm=*/%vm37615, /*on_true_vy=*/%v37620, /*on_false_vx=*/%v37763 (stack43)
        %v37771 = vmul.f32 1.4140625, %v37767 (stack53)
        %v37774 = vpack.c.bf16 0.0, %v37771 (stack74)
        %119943 = vst [vmem:[%s280 + $0x3a4] sm:$0xf] /*vst_source=*/%v37774 (stack75)
        %s37776 = sadd.s32 80, %s120390 (stack76)
        %s37777 = sshrl.u32 %s37776, 10 (stack23)
        %p119944 = scmp.gt.s32.totalorder %s37777, 1 (stack24)
        %s37779 = scalar_select /*predicate=*/%p119944, /*on_true=*/1, /*on_false=*/%s37777 (stack25)
        %s37780 = sand.u32 1023, %s37776 /* smod.u32 w/div 1024 */ (stack26)
        %s37781 = sshrl.u32 %s37780, 7 (stack27)
        %s37782 = sand.u32 127, %s37780 /* smod.u32 w/div 128 */ (stack28)
        %s119945 = sshll.u32 %s37779, 3 (stack29)
        %s37784 = scalar_lea.vmem %s3, %s119945 (stack30)
        %s37786 = scalar_lea.vmem %s37784, %s37781 (stack31)
        %v37787 = vld [vmem:[%s37786] ss:$0 sm:$0xff] (stack32)
        %s37788 = sand.u32 255, %s37782 (stack33)
        %s37790 = sor.u32 256, %s37788 (stack34)
        %37791 = vbcast.lane.b32.xlu0 %v37787, %s37790 (stack35)
        %v37792 = vpop.permute.xlu0 %37791 (stack36)
        %s37801 = scalar_lea.vmem %s5, %s119945 (stack30)
        %s37803 = scalar_lea.vmem %s37801, %s37781 (stack31)
        %v37804 = vld [vmem:[%s37803] ss:$0 sm:$0xff] (stack32)
        %37808 = vbcast.lane.b32.xlu0 %v37804, %s37790 (stack35)
        %v37809 = vpop.permute.xlu0 %37808 (stack36)
        %v37812 = vadd.s32 %v37809, %v408 (stack39)
        %v37822 = vadd.s32 %v37812, %v415 (stack39)
        %vm37826 = vcmp.lt.u32.totalorder %v37822, %v37812 (stack42)
        %vm37831 = vcmp.lt.u32.totalorder %v37812, %v408 (stack42)
        %v37836 = vadd.s32 %v37792, %v380 (stack39)
        %v37840 = vadd.s32 1, %v37836 (stack39)
        %v37844 = vsel /*vm=*/%vm37831, /*on_true_vy=*/%v37840, /*on_false_vx=*/%v37836 (stack43)
        %v37848 = vadd.s32 1, %v37844 (stack39)
        %v37852 = vsel /*vm=*/%vm37826, /*on_true_vy=*/%v37848, /*on_false_vx=*/%v37844 (stack43)
        %v37857 = vadd.s32 %v37852, %v10 (stack39)
        %v37861 = vadd.s32 %v37822, %v9 (stack39)
        %v37865 = vadd.s32 %v37861, %v37857 (stack39)
        %v37867 = vshll.u32 %v37861, 13 (stack44)
        %v37868 = vshrl.u32 %v37861, 19 (stack45)
        %v37869 = vor.u32 %v37868, %v37867 (stack46)
        %v37870 = vxor.u32 %v37869, %v37865 (stack47)
        %v37873 = vadd.s32 %v37870, %v37865 (stack39)
        %v37875 = vshll.u32 %v37870, 15 (stack44)
        %v37876 = vshrl.u32 %v37870, 17 (stack45)
        %v37877 = vor.u32 %v37876, %v37875 (stack46)
        %v37878 = vxor.u32 %v37877, %v37873 (stack47)
        %v37881 = vadd.s32 %v37878, %v37873 (stack39)
        %v37883 = vshll.u32 %v37878, 26 (stack44)
        %v37884 = vshrl.u32 %v37878, 6 (stack45)
        %v37885 = vor.u32 %v37884, %v37883 (stack46)
        %v37886 = vxor.u32 %v37885, %v37881 (stack47)
        %v37889 = vadd.s32 %v37886, %v37881 (stack39)
        %v37893 = vadd.s32 %v37889, %v9 (stack39)
        %v37895 = vshll.u32 %v37886, 6 (stack44)
        %v37896 = vshrl.u32 %v37886, 26 (stack45)
        %v37897 = vor.u32 %v37896, %v37895 (stack46)
        %v37898 = vxor.u32 %v37897, %v37889 (stack47)
        %v37901 = vadd.s32 %v37898, %v8 (stack39)
        %v37905 = vadd.s32 1, %v37901 (stack39)
        %v37909 = vadd.s32 %v37905, %v37893 (stack39)
        %v37911 = vshll.u32 %v37905, 17 (stack44)
        %v37912 = vshrl.u32 %v37905, 15 (stack45)
        %v37913 = vor.u32 %v37912, %v37911 (stack46)
        %v37914 = vxor.u32 %v37913, %v37909 (stack47)
        %v37917 = vadd.s32 %v37914, %v37909 (stack39)
        %v37919 = vshll.u32 %v37914, 29 (stack44)
        %v37920 = vshrl.u32 %v37914, 3 (stack45)
        %v37921 = vor.u32 %v37920, %v37919 (stack46)
        %v37922 = vxor.u32 %v37921, %v37917 (stack47)
        %v37925 = vadd.s32 %v37922, %v37917 (stack39)
        %v37927 = vshll.u32 %v37922, 16 (stack44)
        %v37928 = vshrl.u32 %v37922, 16 (stack45)
        %v37929 = vor.u32 %v37928, %v37927 (stack46)
        %v37930 = vxor.u32 %v37929, %v37925 (stack47)
        %v37933 = vadd.s32 %v37930, %v37925 (stack39)
        %v37937 = vadd.s32 %v37933, %v8 (stack39)
        %v37939 = vshll.u32 %v37930, 24 (stack44)
        %v37940 = vshrl.u32 %v37930, 8 (stack45)
        %v37941 = vor.u32 %v37940, %v37939 (stack46)
        %v37942 = vxor.u32 %v37941, %v37933 (stack47)
        %v37945 = vadd.s32 %v37942, %v10 (stack39)
        %v37949 = vadd.s32 2, %v37945 (stack39)
        %v37953 = vadd.s32 %v37949, %v37937 (stack39)
        %v37955 = vshll.u32 %v37949, 13 (stack44)
        %v37956 = vshrl.u32 %v37949, 19 (stack45)
        %v37957 = vor.u32 %v37956, %v37955 (stack46)
        %v37958 = vxor.u32 %v37957, %v37953 (stack47)
        %v37961 = vadd.s32 %v37958, %v37953 (stack39)
        %v37963 = vshll.u32 %v37958, 15 (stack44)
        %v37964 = vshrl.u32 %v37958, 17 (stack45)
        %v37965 = vor.u32 %v37964, %v37963 (stack46)
        %v37966 = vxor.u32 %v37965, %v37961 (stack47)
        %v37969 = vadd.s32 %v37966, %v37961 (stack39)
        %v37971 = vshll.u32 %v37966, 26 (stack44)
        %v37972 = vshrl.u32 %v37966, 6 (stack45)
        %v37973 = vor.u32 %v37972, %v37971 (stack46)
        %v37974 = vxor.u32 %v37973, %v37969 (stack47)
        %v37977 = vadd.s32 %v37974, %v37969 (stack39)
        %v37981 = vadd.s32 %v37977, %v10 (stack39)
        %v37983 = vshll.u32 %v37974, 6 (stack44)
        %v37984 = vshrl.u32 %v37974, 26 (stack45)
        %v37985 = vor.u32 %v37984, %v37983 (stack46)
        %v37986 = vxor.u32 %v37985, %v37977 (stack47)
        %v37989 = vadd.s32 %v37986, %v9 (stack39)
        %v37993 = vadd.s32 3, %v37989 (stack39)
        %v37997 = vadd.s32 %v37993, %v37981 (stack39)
        %v37999 = vshll.u32 %v37993, 17 (stack44)
        %v38000 = vshrl.u32 %v37993, 15 (stack45)
        %v38001 = vor.u32 %v38000, %v37999 (stack46)
        %v38002 = vxor.u32 %v38001, %v37997 (stack47)
        %v38005 = vadd.s32 %v38002, %v37997 (stack39)
        %v38007 = vshll.u32 %v38002, 29 (stack44)
        %v38008 = vshrl.u32 %v38002, 3 (stack45)
        %v38009 = vor.u32 %v38008, %v38007 (stack46)
        %v38010 = vxor.u32 %v38009, %v38005 (stack47)
        %v38013 = vadd.s32 %v38010, %v38005 (stack39)
        %v38015 = vshll.u32 %v38010, 16 (stack44)
        %v38016 = vshrl.u32 %v38010, 16 (stack45)
        %v38017 = vor.u32 %v38016, %v38015 (stack46)
        %v38018 = vxor.u32 %v38017, %v38013 (stack47)
        %v38021 = vadd.s32 %v38018, %v38013 (stack39)
        %v38025 = vadd.s32 %v38021, %v9 (stack39)
        %v38027 = vshll.u32 %v38018, 24 (stack44)
        %v38028 = vshrl.u32 %v38018, 8 (stack45)
        %v38029 = vor.u32 %v38028, %v38027 (stack46)
        %v38030 = vxor.u32 %v38029, %v38021 (stack47)
        %v38033 = vadd.s32 %v38030, %v8 (stack39)
        %v38037 = vadd.s32 4, %v38033 (stack39)
        %v38041 = vadd.s32 %v38037, %v38025 (stack39)
        %v38043 = vshll.u32 %v38037, 13 (stack44)
        %v38044 = vshrl.u32 %v38037, 19 (stack45)
        %v38045 = vor.u32 %v38044, %v38043 (stack46)
        %v38046 = vxor.u32 %v38045, %v38041 (stack47)
        %v38049 = vadd.s32 %v38046, %v38041 (stack39)
        %v38051 = vshll.u32 %v38046, 15 (stack44)
        %v38052 = vshrl.u32 %v38046, 17 (stack45)
        %v38053 = vor.u32 %v38052, %v38051 (stack46)
        %v38054 = vxor.u32 %v38053, %v38049 (stack47)
        %v38057 = vadd.s32 %v38054, %v38049 (stack39)
        %v38059 = vshll.u32 %v38054, 26 (stack44)
        %v38060 = vshrl.u32 %v38054, 6 (stack45)
        %v38061 = vor.u32 %v38060, %v38059 (stack46)
        %v38062 = vxor.u32 %v38061, %v38057 (stack47)
        %v38065 = vadd.s32 %v38062, %v38057 (stack39)
        %v38069 = vadd.s32 %v38065, %v8 (stack39)
        %v38071 = vshll.u32 %v38062, 6 (stack44)
        %v38072 = vshrl.u32 %v38062, 26 (stack45)
        %v38073 = vor.u32 %v38072, %v38071 (stack46)
        %v38074 = vxor.u32 %v38073, %v38065 (stack47)
        %v38077 = vadd.s32 %v38074, %v10 (stack39)
        %v38081 = vadd.s32 5, %v38077 (stack39)
        %v38083 = vxor.u32 %v38081, %v38069 (stack47)
        %v38084 = vand.u32.u8 255, %v38083 (stack48)
        %v38085 = vand.u32 65535, %v38084 (stack49)
        %v38086 = vshrl.u32 %v38085, 1 (stack50)
        %v38087 = vor.u32 16256, %v38086 (stack46)
        %v38088 = vand.u32.u16 65535, %v38087 (stack51)
        %v119948 = vadd.low.f32.bf16 -1.0, %v38088 (stack52)
        %v38097 = vmul.f32 2.0, %v119948 (stack53)
        %v38101 = vadd.f32 -0.99609375, %v38097 (stack52)
        %v38105 = vmax.f32 %v38101, -0.99609375 (stack54)
        %v38107 = vand.u32 2147483647, %v38105 (stack55)
        %vm38110 = vcmp.eq.f32.partialorder %v38107, 1.0 (stack56)
        %v38115 = vmul.f32 inf, %v38105 (stack53)
        %v38117 = vxor.u32 2147483648, %v38105 (stack57)
        %v38120 = vmul.f32 %v38117, %v38105 (stack53)
        %v38122 = vadd.f32 1.0, %v38120 (stack58)
        %v38123 = vlog2.pop %v38122 (stack59)
        %v38124 = vmul.f32 0.6931472, %v38123 (stack60)
        %v38125 = vmul.f32 -0.5, %v38120 (stack61)
        %v38126 = vadd.f32 1.0, %v38125 (stack62)
        %v38127 = vmul.f32 %v38126, %v38120 (stack63)
        %v38128 = vand.u32 2147483647, %v38120 (stack64)
        %vm38129 = vcmp.lt.f32.partialorder %v38128, 0.0004427343 (stack65)
        %v38130 = vsel /*vm=*/%vm38129, /*on_true_vy=*/%v38127, /*on_false_vx=*/%v38124 (stack66)
        %v38131 = vxor.u32 2147483648, %v38130 (stack57)
        %vm38134 = vcmp.lt.f32.partialorder %v38131, 5.0 (stack56)
        %v38139 = vsel /*vm=*/%vm38134, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v38143 = vsel /*vm=*/%vm38134, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v38147 = vsel /*vm=*/%vm38134, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v38151 = vsel /*vm=*/%vm38134, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v38155 = vsel /*vm=*/%vm38134, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v38159 = vsel /*vm=*/%vm38134, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v38163 = vsel /*vm=*/%vm38134, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v38167 = vsel /*vm=*/%vm38134, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v38171 = vsel /*vm=*/%vm38134, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v38175 = vadd.f32 -2.5, %v38131 (stack52)
        %v38177 = vrsqrt.pop %v38131 (stack67)
        %v38178 = vmul.f32 %v38177, %v38131 (stack68)
        %vm38179 = vcmp.eq.f32.partialorder %v38131, inf (stack69)
        %v38180 = vsel /*vm=*/%vm38179, /*on_true_vy=*/%v38131, /*on_false_vx=*/%v38178 (stack70)
        %vm38181 = vcmp.eq.f32.partialorder %v38131, 0.0 (stack71)
        %v38182 = vand.u32 2147483648, %v38131 (stack72)
        %v38183 = vsel /*vm=*/%vm38181, /*on_true_vy=*/%v38182, /*on_false_vx=*/%v38180 (stack73)
        %v38186 = vadd.f32 -3.0, %v38183 (stack52)
        %v38190 = vsel /*vm=*/%vm38134, /*on_true_vy=*/%v38175, /*on_false_vx=*/%v38186 (stack43)
        %v38194 = vmul.f32 %v38190, %v38171 (stack53)
        %v38198 = vadd.f32 %v38194, %v38167 (stack52)
        %v38202 = vmul.f32 %v38198, %v38190 (stack53)
        %v38206 = vadd.f32 %v38202, %v38163 (stack52)
        %v38210 = vmul.f32 %v38206, %v38190 (stack53)
        %v38214 = vadd.f32 %v38210, %v38159 (stack52)
        %v38218 = vmul.f32 %v38214, %v38190 (stack53)
        %v38222 = vadd.f32 %v38218, %v38155 (stack52)
        %v38226 = vmul.f32 %v38222, %v38190 (stack53)
        %v38230 = vadd.f32 %v38226, %v38151 (stack52)
        %v38234 = vmul.f32 %v38230, %v38190 (stack53)
        %v38238 = vadd.f32 %v38234, %v38147 (stack52)
        %v38242 = vmul.f32 %v38238, %v38190 (stack53)
        %v38246 = vadd.f32 %v38242, %v38143 (stack52)
        %v38250 = vmul.f32 %v38246, %v38190 (stack53)
        %v38254 = vadd.f32 %v38250, %v38139 (stack52)
        %v38258 = vmul.f32 %v38254, %v38105 (stack53)
        %v38262 = vsel /*vm=*/%vm38110, /*on_true_vy=*/%v38115, /*on_false_vx=*/%v38258 (stack43)
        %v38266 = vmul.f32 1.4140625, %v38262 (stack53)
        %v38269 = vpack.c.bf16 0.0, %v38266 (stack74)
        %119949 = vst [vmem:[%s280 + $0x28] sm:$0xf] /*vst_source=*/%v38269 (stack75)
        %v38273 = vadd.s32 %v37809, %v894 (stack39)
        %v38283 = vadd.s32 %v38273, %v415 (stack39)
        %vm38287 = vcmp.lt.u32.totalorder %v38283, %v38273 (stack42)
        %vm38292 = vcmp.lt.u32.totalorder %v38273, %v894 (stack42)
        %v38297 = vadd.s32 %v37792, %v881 (stack39)
        %v38301 = vadd.s32 1, %v38297 (stack39)
        %v38305 = vsel /*vm=*/%vm38292, /*on_true_vy=*/%v38301, /*on_false_vx=*/%v38297 (stack43)
        %v38309 = vadd.s32 1, %v38305 (stack39)
        %v38313 = vsel /*vm=*/%vm38287, /*on_true_vy=*/%v38309, /*on_false_vx=*/%v38305 (stack43)
        %v38318 = vadd.s32 %v38313, %v10 (stack39)
        %v38322 = vadd.s32 %v38283, %v9 (stack39)
        %v38326 = vadd.s32 %v38322, %v38318 (stack39)
        %v38328 = vshll.u32 %v38322, 13 (stack44)
        %v38329 = vshrl.u32 %v38322, 19 (stack45)
        %v38330 = vor.u32 %v38329, %v38328 (stack46)
        %v38331 = vxor.u32 %v38330, %v38326 (stack47)
        %v38334 = vadd.s32 %v38331, %v38326 (stack39)
        %v38336 = vshll.u32 %v38331, 15 (stack44)
        %v38337 = vshrl.u32 %v38331, 17 (stack45)
        %v38338 = vor.u32 %v38337, %v38336 (stack46)
        %v38339 = vxor.u32 %v38338, %v38334 (stack47)
        %v38342 = vadd.s32 %v38339, %v38334 (stack39)
        %v38344 = vshll.u32 %v38339, 26 (stack44)
        %v38345 = vshrl.u32 %v38339, 6 (stack45)
        %v38346 = vor.u32 %v38345, %v38344 (stack46)
        %v38347 = vxor.u32 %v38346, %v38342 (stack47)
        %v38350 = vadd.s32 %v38347, %v38342 (stack39)
        %v38354 = vadd.s32 %v38350, %v9 (stack39)
        %v38356 = vshll.u32 %v38347, 6 (stack44)
        %v38357 = vshrl.u32 %v38347, 26 (stack45)
        %v38358 = vor.u32 %v38357, %v38356 (stack46)
        %v38359 = vxor.u32 %v38358, %v38350 (stack47)
        %v38362 = vadd.s32 %v38359, %v8 (stack39)
        %v38366 = vadd.s32 1, %v38362 (stack39)
        %v38370 = vadd.s32 %v38366, %v38354 (stack39)
        %v38372 = vshll.u32 %v38366, 17 (stack44)
        %v38373 = vshrl.u32 %v38366, 15 (stack45)
        %v38374 = vor.u32 %v38373, %v38372 (stack46)
        %v38375 = vxor.u32 %v38374, %v38370 (stack47)
        %v38378 = vadd.s32 %v38375, %v38370 (stack39)
        %v38380 = vshll.u32 %v38375, 29 (stack44)
        %v38381 = vshrl.u32 %v38375, 3 (stack45)
        %v38382 = vor.u32 %v38381, %v38380 (stack46)
        %v38383 = vxor.u32 %v38382, %v38378 (stack47)
        %v38386 = vadd.s32 %v38383, %v38378 (stack39)
        %v38388 = vshll.u32 %v38383, 16 (stack44)
        %v38389 = vshrl.u32 %v38383, 16 (stack45)
        %v38390 = vor.u32 %v38389, %v38388 (stack46)
        %v38391 = vxor.u32 %v38390, %v38386 (stack47)
        %v38394 = vadd.s32 %v38391, %v38386 (stack39)
        %v38398 = vadd.s32 %v38394, %v8 (stack39)
        %v38400 = vshll.u32 %v38391, 24 (stack44)
        %v38401 = vshrl.u32 %v38391, 8 (stack45)
        %v38402 = vor.u32 %v38401, %v38400 (stack46)
        %v38403 = vxor.u32 %v38402, %v38394 (stack47)
        %v38406 = vadd.s32 %v38403, %v10 (stack39)
        %v38410 = vadd.s32 2, %v38406 (stack39)
        %v38414 = vadd.s32 %v38410, %v38398 (stack39)
        %v38416 = vshll.u32 %v38410, 13 (stack44)
        %v38417 = vshrl.u32 %v38410, 19 (stack45)
        %v38418 = vor.u32 %v38417, %v38416 (stack46)
        %v38419 = vxor.u32 %v38418, %v38414 (stack47)
        %v38422 = vadd.s32 %v38419, %v38414 (stack39)
        %v38424 = vshll.u32 %v38419, 15 (stack44)
        %v38425 = vshrl.u32 %v38419, 17 (stack45)
        %v38426 = vor.u32 %v38425, %v38424 (stack46)
        %v38427 = vxor.u32 %v38426, %v38422 (stack47)
        %v38430 = vadd.s32 %v38427, %v38422 (stack39)
        %v38432 = vshll.u32 %v38427, 26 (stack44)
        %v38433 = vshrl.u32 %v38427, 6 (stack45)
        %v38434 = vor.u32 %v38433, %v38432 (stack46)
        %v38435 = vxor.u32 %v38434, %v38430 (stack47)
        %v38438 = vadd.s32 %v38435, %v38430 (stack39)
        %v38442 = vadd.s32 %v38438, %v10 (stack39)
        %v38444 = vshll.u32 %v38435, 6 (stack44)
        %v38445 = vshrl.u32 %v38435, 26 (stack45)
        %v38446 = vor.u32 %v38445, %v38444 (stack46)
        %v38447 = vxor.u32 %v38446, %v38438 (stack47)
        %v38450 = vadd.s32 %v38447, %v9 (stack39)
        %v38454 = vadd.s32 3, %v38450 (stack39)
        %v38458 = vadd.s32 %v38454, %v38442 (stack39)
        %v38460 = vshll.u32 %v38454, 17 (stack44)
        %v38461 = vshrl.u32 %v38454, 15 (stack45)
        %v38462 = vor.u32 %v38461, %v38460 (stack46)
        %v38463 = vxor.u32 %v38462, %v38458 (stack47)
        %v38466 = vadd.s32 %v38463, %v38458 (stack39)
        %v38468 = vshll.u32 %v38463, 29 (stack44)
        %v38469 = vshrl.u32 %v38463, 3 (stack45)
        %v38470 = vor.u32 %v38469, %v38468 (stack46)
        %v38471 = vxor.u32 %v38470, %v38466 (stack47)
        %v38474 = vadd.s32 %v38471, %v38466 (stack39)
        %v38476 = vshll.u32 %v38471, 16 (stack44)
        %v38477 = vshrl.u32 %v38471, 16 (stack45)
        %v38478 = vor.u32 %v38477, %v38476 (stack46)
        %v38479 = vxor.u32 %v38478, %v38474 (stack47)
        %v38482 = vadd.s32 %v38479, %v38474 (stack39)
        %v38486 = vadd.s32 %v38482, %v9 (stack39)
        %v38488 = vshll.u32 %v38479, 24 (stack44)
        %v38489 = vshrl.u32 %v38479, 8 (stack45)
        %v38490 = vor.u32 %v38489, %v38488 (stack46)
        %v38491 = vxor.u32 %v38490, %v38482 (stack47)
        %v38494 = vadd.s32 %v38491, %v8 (stack39)
        %v38498 = vadd.s32 4, %v38494 (stack39)
        %v38502 = vadd.s32 %v38498, %v38486 (stack39)
        %v38504 = vshll.u32 %v38498, 13 (stack44)
        %v38505 = vshrl.u32 %v38498, 19 (stack45)
        %v38506 = vor.u32 %v38505, %v38504 (stack46)
        %v38507 = vxor.u32 %v38506, %v38502 (stack47)
        %v38510 = vadd.s32 %v38507, %v38502 (stack39)
        %v38512 = vshll.u32 %v38507, 15 (stack44)
        %v38513 = vshrl.u32 %v38507, 17 (stack45)
        %v38514 = vor.u32 %v38513, %v38512 (stack46)
        %v38515 = vxor.u32 %v38514, %v38510 (stack47)
        %v38518 = vadd.s32 %v38515, %v38510 (stack39)
        %v38520 = vshll.u32 %v38515, 26 (stack44)
        %v38521 = vshrl.u32 %v38515, 6 (stack45)
        %v38522 = vor.u32 %v38521, %v38520 (stack46)
        %v38523 = vxor.u32 %v38522, %v38518 (stack47)
        %v38526 = vadd.s32 %v38523, %v38518 (stack39)
        %v38530 = vadd.s32 %v38526, %v8 (stack39)
        %v38532 = vshll.u32 %v38523, 6 (stack44)
        %v38533 = vshrl.u32 %v38523, 26 (stack45)
        %v38534 = vor.u32 %v38533, %v38532 (stack46)
        %v38535 = vxor.u32 %v38534, %v38526 (stack47)
        %v38538 = vadd.s32 %v38535, %v10 (stack39)
        %v38542 = vadd.s32 5, %v38538 (stack39)
        %v38544 = vxor.u32 %v38542, %v38530 (stack47)
        %v38545 = vand.u32.u8 255, %v38544 (stack48)
        %v38546 = vand.u32 65535, %v38545 (stack49)
        %v38547 = vshrl.u32 %v38546, 1 (stack50)
        %v38548 = vor.u32 16256, %v38547 (stack46)
        %v38549 = vand.u32.u16 65535, %v38548 (stack51)
        %v119950 = vadd.low.f32.bf16 -1.0, %v38549 (stack52)
        %v38558 = vmul.f32 2.0, %v119950 (stack53)
        %v38562 = vadd.f32 -0.99609375, %v38558 (stack52)
        %v38566 = vmax.f32 %v38562, -0.99609375 (stack54)
        %v38568 = vand.u32 2147483647, %v38566 (stack55)
        %vm38571 = vcmp.eq.f32.partialorder %v38568, 1.0 (stack56)
        %v38576 = vmul.f32 inf, %v38566 (stack53)
        %v38578 = vxor.u32 2147483648, %v38566 (stack57)
        %v38581 = vmul.f32 %v38578, %v38566 (stack53)
        %v38583 = vadd.f32 1.0, %v38581 (stack58)
        %v38584 = vlog2.pop %v38583 (stack59)
        %v38585 = vmul.f32 0.6931472, %v38584 (stack60)
        %v38586 = vmul.f32 -0.5, %v38581 (stack61)
        %v38587 = vadd.f32 1.0, %v38586 (stack62)
        %v38588 = vmul.f32 %v38587, %v38581 (stack63)
        %v38589 = vand.u32 2147483647, %v38581 (stack64)
        %vm38590 = vcmp.lt.f32.partialorder %v38589, 0.0004427343 (stack65)
        %v38591 = vsel /*vm=*/%vm38590, /*on_true_vy=*/%v38588, /*on_false_vx=*/%v38585 (stack66)
        %v38592 = vxor.u32 2147483648, %v38591 (stack57)
        %vm38595 = vcmp.lt.f32.partialorder %v38592, 5.0 (stack56)
        %v38600 = vsel /*vm=*/%vm38595, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v38604 = vsel /*vm=*/%vm38595, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v38608 = vsel /*vm=*/%vm38595, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v38612 = vsel /*vm=*/%vm38595, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v38616 = vsel /*vm=*/%vm38595, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v38620 = vsel /*vm=*/%vm38595, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v38624 = vsel /*vm=*/%vm38595, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v38628 = vsel /*vm=*/%vm38595, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v38632 = vsel /*vm=*/%vm38595, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v38636 = vadd.f32 -2.5, %v38592 (stack52)
        %v38638 = vrsqrt.pop %v38592 (stack67)
        %v38639 = vmul.f32 %v38638, %v38592 (stack68)
        %vm38640 = vcmp.eq.f32.partialorder %v38592, inf (stack69)
        %v38641 = vsel /*vm=*/%vm38640, /*on_true_vy=*/%v38592, /*on_false_vx=*/%v38639 (stack70)
        %vm38642 = vcmp.eq.f32.partialorder %v38592, 0.0 (stack71)
        %v38643 = vand.u32 2147483648, %v38592 (stack72)
        %v38644 = vsel /*vm=*/%vm38642, /*on_true_vy=*/%v38643, /*on_false_vx=*/%v38641 (stack73)
        %v38647 = vadd.f32 -3.0, %v38644 (stack52)
        %v38651 = vsel /*vm=*/%vm38595, /*on_true_vy=*/%v38636, /*on_false_vx=*/%v38647 (stack43)
        %v38655 = vmul.f32 %v38651, %v38632 (stack53)
        %v38659 = vadd.f32 %v38655, %v38628 (stack52)
        %v38663 = vmul.f32 %v38659, %v38651 (stack53)
        %v38667 = vadd.f32 %v38663, %v38624 (stack52)
        %v38671 = vmul.f32 %v38667, %v38651 (stack53)
        %v38675 = vadd.f32 %v38671, %v38620 (stack52)
        %v38679 = vmul.f32 %v38675, %v38651 (stack53)
        %v38683 = vadd.f32 %v38679, %v38616 (stack52)
        %v38687 = vmul.f32 %v38683, %v38651 (stack53)
        %v38691 = vadd.f32 %v38687, %v38612 (stack52)
        %v38695 = vmul.f32 %v38691, %v38651 (stack53)
        %v38699 = vadd.f32 %v38695, %v38608 (stack52)
        %v38703 = vmul.f32 %v38699, %v38651 (stack53)
        %v38707 = vadd.f32 %v38703, %v38604 (stack52)
        %v38711 = vmul.f32 %v38707, %v38651 (stack53)
        %v38715 = vadd.f32 %v38711, %v38600 (stack52)
        %v38719 = vmul.f32 %v38715, %v38566 (stack53)
        %v38723 = vsel /*vm=*/%vm38571, /*on_true_vy=*/%v38576, /*on_false_vx=*/%v38719 (stack43)
        %v38727 = vmul.f32 1.4140625, %v38723 (stack53)
        %v38730 = vpack.c.bf16 0.0, %v38727 (stack74)
        %119951 = vst [vmem:[%s280 + $0xa8] sm:$0xf] /*vst_source=*/%v38730 (stack75)
        %v38734 = vadd.s32 %v37809, %v1381 (stack39)
        %v38744 = vadd.s32 %v38734, %v415 (stack39)
        %vm38748 = vcmp.lt.u32.totalorder %v38744, %v38734 (stack42)
        %vm38753 = vcmp.lt.u32.totalorder %v38734, %v1381 (stack42)
        %v38758 = vadd.s32 %v37792, %v1368 (stack39)
        %v38762 = vadd.s32 1, %v38758 (stack39)
        %v38766 = vsel /*vm=*/%vm38753, /*on_true_vy=*/%v38762, /*on_false_vx=*/%v38758 (stack43)
        %v38770 = vadd.s32 1, %v38766 (stack39)
        %v38774 = vsel /*vm=*/%vm38748, /*on_true_vy=*/%v38770, /*on_false_vx=*/%v38766 (stack43)
        %v38779 = vadd.s32 %v38774, %v10 (stack39)
        %v38783 = vadd.s32 %v38744, %v9 (stack39)
        %v38787 = vadd.s32 %v38783, %v38779 (stack39)
        %v38789 = vshll.u32 %v38783, 13 (stack44)
        %v38790 = vshrl.u32 %v38783, 19 (stack45)
        %v38791 = vor.u32 %v38790, %v38789 (stack46)
        %v38792 = vxor.u32 %v38791, %v38787 (stack47)
        %v38795 = vadd.s32 %v38792, %v38787 (stack39)
        %v38797 = vshll.u32 %v38792, 15 (stack44)
        %v38798 = vshrl.u32 %v38792, 17 (stack45)
        %v38799 = vor.u32 %v38798, %v38797 (stack46)
        %v38800 = vxor.u32 %v38799, %v38795 (stack47)
        %v38803 = vadd.s32 %v38800, %v38795 (stack39)
        %v38805 = vshll.u32 %v38800, 26 (stack44)
        %v38806 = vshrl.u32 %v38800, 6 (stack45)
        %v38807 = vor.u32 %v38806, %v38805 (stack46)
        %v38808 = vxor.u32 %v38807, %v38803 (stack47)
        %v38811 = vadd.s32 %v38808, %v38803 (stack39)
        %v38815 = vadd.s32 %v38811, %v9 (stack39)
        %v38817 = vshll.u32 %v38808, 6 (stack44)
        %v38818 = vshrl.u32 %v38808, 26 (stack45)
        %v38819 = vor.u32 %v38818, %v38817 (stack46)
        %v38820 = vxor.u32 %v38819, %v38811 (stack47)
        %v38823 = vadd.s32 %v38820, %v8 (stack39)
        %v38827 = vadd.s32 1, %v38823 (stack39)
        %v38831 = vadd.s32 %v38827, %v38815 (stack39)
        %v38833 = vshll.u32 %v38827, 17 (stack44)
        %v38834 = vshrl.u32 %v38827, 15 (stack45)
        %v38835 = vor.u32 %v38834, %v38833 (stack46)
        %v38836 = vxor.u32 %v38835, %v38831 (stack47)
        %v38839 = vadd.s32 %v38836, %v38831 (stack39)
        %v38841 = vshll.u32 %v38836, 29 (stack44)
        %v38842 = vshrl.u32 %v38836, 3 (stack45)
        %v38843 = vor.u32 %v38842, %v38841 (stack46)
        %v38844 = vxor.u32 %v38843, %v38839 (stack47)
        %v38847 = vadd.s32 %v38844, %v38839 (stack39)
        %v38849 = vshll.u32 %v38844, 16 (stack44)
        %v38850 = vshrl.u32 %v38844, 16 (stack45)
        %v38851 = vor.u32 %v38850, %v38849 (stack46)
        %v38852 = vxor.u32 %v38851, %v38847 (stack47)
        %v38855 = vadd.s32 %v38852, %v38847 (stack39)
        %v38859 = vadd.s32 %v38855, %v8 (stack39)
        %v38861 = vshll.u32 %v38852, 24 (stack44)
        %v38862 = vshrl.u32 %v38852, 8 (stack45)
        %v38863 = vor.u32 %v38862, %v38861 (stack46)
        %v38864 = vxor.u32 %v38863, %v38855 (stack47)
        %v38867 = vadd.s32 %v38864, %v10 (stack39)
        %v38871 = vadd.s32 2, %v38867 (stack39)
        %v38875 = vadd.s32 %v38871, %v38859 (stack39)
        %v38877 = vshll.u32 %v38871, 13 (stack44)
        %v38878 = vshrl.u32 %v38871, 19 (stack45)
        %v38879 = vor.u32 %v38878, %v38877 (stack46)
        %v38880 = vxor.u32 %v38879, %v38875 (stack47)
        %v38883 = vadd.s32 %v38880, %v38875 (stack39)
        %v38885 = vshll.u32 %v38880, 15 (stack44)
        %v38886 = vshrl.u32 %v38880, 17 (stack45)
        %v38887 = vor.u32 %v38886, %v38885 (stack46)
        %v38888 = vxor.u32 %v38887, %v38883 (stack47)
        %v38891 = vadd.s32 %v38888, %v38883 (stack39)
        %v38893 = vshll.u32 %v38888, 26 (stack44)
        %v38894 = vshrl.u32 %v38888, 6 (stack45)
        %v38895 = vor.u32 %v38894, %v38893 (stack46)
        %v38896 = vxor.u32 %v38895, %v38891 (stack47)
        %v38899 = vadd.s32 %v38896, %v38891 (stack39)
        %v38903 = vadd.s32 %v38899, %v10 (stack39)
        %v38905 = vshll.u32 %v38896, 6 (stack44)
        %v38906 = vshrl.u32 %v38896, 26 (stack45)
        %v38907 = vor.u32 %v38906, %v38905 (stack46)
        %v38908 = vxor.u32 %v38907, %v38899 (stack47)
        %v38911 = vadd.s32 %v38908, %v9 (stack39)
        %v38915 = vadd.s32 3, %v38911 (stack39)
        %v38919 = vadd.s32 %v38915, %v38903 (stack39)
        %v38921 = vshll.u32 %v38915, 17 (stack44)
        %v38922 = vshrl.u32 %v38915, 15 (stack45)
        %v38923 = vor.u32 %v38922, %v38921 (stack46)
        %v38924 = vxor.u32 %v38923, %v38919 (stack47)
        %v38927 = vadd.s32 %v38924, %v38919 (stack39)
        %v38929 = vshll.u32 %v38924, 29 (stack44)
        %v38930 = vshrl.u32 %v38924, 3 (stack45)
        %v38931 = vor.u32 %v38930, %v38929 (stack46)
        %v38932 = vxor.u32 %v38931, %v38927 (stack47)
        %v38935 = vadd.s32 %v38932, %v38927 (stack39)
        %v38937 = vshll.u32 %v38932, 16 (stack44)
        %v38938 = vshrl.u32 %v38932, 16 (stack45)
        %v38939 = vor.u32 %v38938, %v38937 (stack46)
        %v38940 = vxor.u32 %v38939, %v38935 (stack47)
        %v38943 = vadd.s32 %v38940, %v38935 (stack39)
        %v38947 = vadd.s32 %v38943, %v9 (stack39)
        %v38949 = vshll.u32 %v38940, 24 (stack44)
        %v38950 = vshrl.u32 %v38940, 8 (stack45)
        %v38951 = vor.u32 %v38950, %v38949 (stack46)
        %v38952 = vxor.u32 %v38951, %v38943 (stack47)
        %v38955 = vadd.s32 %v38952, %v8 (stack39)
        %v38959 = vadd.s32 4, %v38955 (stack39)
        %v38963 = vadd.s32 %v38959, %v38947 (stack39)
        %v38965 = vshll.u32 %v38959, 13 (stack44)
        %v38966 = vshrl.u32 %v38959, 19 (stack45)
        %v38967 = vor.u32 %v38966, %v38965 (stack46)
        %v38968 = vxor.u32 %v38967, %v38963 (stack47)
        %v38971 = vadd.s32 %v38968, %v38963 (stack39)
        %v38973 = vshll.u32 %v38968, 15 (stack44)
        %v38974 = vshrl.u32 %v38968, 17 (stack45)
        %v38975 = vor.u32 %v38974, %v38973 (stack46)
        %v38976 = vxor.u32 %v38975, %v38971 (stack47)
        %v38979 = vadd.s32 %v38976, %v38971 (stack39)
        %v38981 = vshll.u32 %v38976, 26 (stack44)
        %v38982 = vshrl.u32 %v38976, 6 (stack45)
        %v38983 = vor.u32 %v38982, %v38981 (stack46)
        %v38984 = vxor.u32 %v38983, %v38979 (stack47)
        %v38987 = vadd.s32 %v38984, %v38979 (stack39)
        %v38991 = vadd.s32 %v38987, %v8 (stack39)
        %v38993 = vshll.u32 %v38984, 6 (stack44)
        %v38994 = vshrl.u32 %v38984, 26 (stack45)
        %v38995 = vor.u32 %v38994, %v38993 (stack46)
        %v38996 = vxor.u32 %v38995, %v38987 (stack47)
        %v38999 = vadd.s32 %v38996, %v10 (stack39)
        %v39003 = vadd.s32 5, %v38999 (stack39)
        %v39005 = vxor.u32 %v39003, %v38991 (stack47)
        %v39006 = vand.u32.u8 255, %v39005 (stack48)
        %v39007 = vand.u32 65535, %v39006 (stack49)
        %v39008 = vshrl.u32 %v39007, 1 (stack50)
        %v39009 = vor.u32 16256, %v39008 (stack46)
        %v39010 = vand.u32.u16 65535, %v39009 (stack51)
        %v119952 = vadd.low.f32.bf16 -1.0, %v39010 (stack52)
        %v39019 = vmul.f32 2.0, %v119952 (stack53)
        %v39023 = vadd.f32 -0.99609375, %v39019 (stack52)
        %v39027 = vmax.f32 %v39023, -0.99609375 (stack54)
        %v39029 = vand.u32 2147483647, %v39027 (stack55)
        %vm39032 = vcmp.eq.f32.partialorder %v39029, 1.0 (stack56)
        %v39037 = vmul.f32 inf, %v39027 (stack53)
        %v39039 = vxor.u32 2147483648, %v39027 (stack57)
        %v39042 = vmul.f32 %v39039, %v39027 (stack53)
        %v39044 = vadd.f32 1.0, %v39042 (stack58)
        %v39045 = vlog2.pop %v39044 (stack59)
        %v39046 = vmul.f32 0.6931472, %v39045 (stack60)
        %v39047 = vmul.f32 -0.5, %v39042 (stack61)
        %v39048 = vadd.f32 1.0, %v39047 (stack62)
        %v39049 = vmul.f32 %v39048, %v39042 (stack63)
        %v39050 = vand.u32 2147483647, %v39042 (stack64)
        %vm39051 = vcmp.lt.f32.partialorder %v39050, 0.0004427343 (stack65)
        %v39052 = vsel /*vm=*/%vm39051, /*on_true_vy=*/%v39049, /*on_false_vx=*/%v39046 (stack66)
        %v39053 = vxor.u32 2147483648, %v39052 (stack57)
        %vm39056 = vcmp.lt.f32.partialorder %v39053, 5.0 (stack56)
        %v39061 = vsel /*vm=*/%vm39056, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v39065 = vsel /*vm=*/%vm39056, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v39069 = vsel /*vm=*/%vm39056, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v39073 = vsel /*vm=*/%vm39056, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v39077 = vsel /*vm=*/%vm39056, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v39081 = vsel /*vm=*/%vm39056, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v39085 = vsel /*vm=*/%vm39056, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v39089 = vsel /*vm=*/%vm39056, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v39093 = vsel /*vm=*/%vm39056, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v39097 = vadd.f32 -2.5, %v39053 (stack52)
        %v39099 = vrsqrt.pop %v39053 (stack67)
        %v39100 = vmul.f32 %v39099, %v39053 (stack68)
        %vm39101 = vcmp.eq.f32.partialorder %v39053, inf (stack69)
        %v39102 = vsel /*vm=*/%vm39101, /*on_true_vy=*/%v39053, /*on_false_vx=*/%v39100 (stack70)
        %vm39103 = vcmp.eq.f32.partialorder %v39053, 0.0 (stack71)
        %v39104 = vand.u32 2147483648, %v39053 (stack72)
        %v39105 = vsel /*vm=*/%vm39103, /*on_true_vy=*/%v39104, /*on_false_vx=*/%v39102 (stack73)
        %v39108 = vadd.f32 -3.0, %v39105 (stack52)
        %v39112 = vsel /*vm=*/%vm39056, /*on_true_vy=*/%v39097, /*on_false_vx=*/%v39108 (stack43)
        %v39116 = vmul.f32 %v39112, %v39093 (stack53)
        %v39120 = vadd.f32 %v39116, %v39089 (stack52)
        %v39124 = vmul.f32 %v39120, %v39112 (stack53)
        %v39128 = vadd.f32 %v39124, %v39085 (stack52)
        %v39132 = vmul.f32 %v39128, %v39112 (stack53)
        %v39136 = vadd.f32 %v39132, %v39081 (stack52)
        %v39140 = vmul.f32 %v39136, %v39112 (stack53)
        %v39144 = vadd.f32 %v39140, %v39077 (stack52)
        %v39148 = vmul.f32 %v39144, %v39112 (stack53)
        %v39152 = vadd.f32 %v39148, %v39073 (stack52)
        %v39156 = vmul.f32 %v39152, %v39112 (stack53)
        %v39160 = vadd.f32 %v39156, %v39069 (stack52)
        %v39164 = vmul.f32 %v39160, %v39112 (stack53)
        %v39168 = vadd.f32 %v39164, %v39065 (stack52)
        %v39172 = vmul.f32 %v39168, %v39112 (stack53)
        %v39176 = vadd.f32 %v39172, %v39061 (stack52)
        %v39180 = vmul.f32 %v39176, %v39027 (stack53)
        %v39184 = vsel /*vm=*/%vm39032, /*on_true_vy=*/%v39037, /*on_false_vx=*/%v39180 (stack43)
        %v39188 = vmul.f32 1.4140625, %v39184 (stack53)
        %v39191 = vpack.c.bf16 0.0, %v39188 (stack74)
        %119953 = vst [vmem:[%s280 + $0x128] sm:$0xf] /*vst_source=*/%v39191 (stack75)
        %v39195 = vadd.s32 %v37809, %v1868 (stack39)
        %v39205 = vadd.s32 %v39195, %v415 (stack39)
        %vm39209 = vcmp.lt.u32.totalorder %v39205, %v39195 (stack42)
        %vm39214 = vcmp.lt.u32.totalorder %v39195, %v1868 (stack42)
        %v39219 = vadd.s32 %v37792, %v1855 (stack39)
        %v39223 = vadd.s32 1, %v39219 (stack39)
        %v39227 = vsel /*vm=*/%vm39214, /*on_true_vy=*/%v39223, /*on_false_vx=*/%v39219 (stack43)
        %v39231 = vadd.s32 1, %v39227 (stack39)
        %v39235 = vsel /*vm=*/%vm39209, /*on_true_vy=*/%v39231, /*on_false_vx=*/%v39227 (stack43)
        %v39240 = vadd.s32 %v39235, %v10 (stack39)
        %v39244 = vadd.s32 %v39205, %v9 (stack39)
        %v39248 = vadd.s32 %v39244, %v39240 (stack39)
        %v39250 = vshll.u32 %v39244, 13 (stack44)
        %v39251 = vshrl.u32 %v39244, 19 (stack45)
        %v39252 = vor.u32 %v39251, %v39250 (stack46)
        %v39253 = vxor.u32 %v39252, %v39248 (stack47)
        %v39256 = vadd.s32 %v39253, %v39248 (stack39)
        %v39258 = vshll.u32 %v39253, 15 (stack44)
        %v39259 = vshrl.u32 %v39253, 17 (stack45)
        %v39260 = vor.u32 %v39259, %v39258 (stack46)
        %v39261 = vxor.u32 %v39260, %v39256 (stack47)
        %v39264 = vadd.s32 %v39261, %v39256 (stack39)
        %v39266 = vshll.u32 %v39261, 26 (stack44)
        %v39267 = vshrl.u32 %v39261, 6 (stack45)
        %v39268 = vor.u32 %v39267, %v39266 (stack46)
        %v39269 = vxor.u32 %v39268, %v39264 (stack47)
        %v39272 = vadd.s32 %v39269, %v39264 (stack39)
        %v39276 = vadd.s32 %v39272, %v9 (stack39)
        %v39278 = vshll.u32 %v39269, 6 (stack44)
        %v39279 = vshrl.u32 %v39269, 26 (stack45)
        %v39280 = vor.u32 %v39279, %v39278 (stack46)
        %v39281 = vxor.u32 %v39280, %v39272 (stack47)
        %v39284 = vadd.s32 %v39281, %v8 (stack39)
        %v39288 = vadd.s32 1, %v39284 (stack39)
        %v39292 = vadd.s32 %v39288, %v39276 (stack39)
        %v39294 = vshll.u32 %v39288, 17 (stack44)
        %v39295 = vshrl.u32 %v39288, 15 (stack45)
        %v39296 = vor.u32 %v39295, %v39294 (stack46)
        %v39297 = vxor.u32 %v39296, %v39292 (stack47)
        %v39300 = vadd.s32 %v39297, %v39292 (stack39)
        %v39302 = vshll.u32 %v39297, 29 (stack44)
        %v39303 = vshrl.u32 %v39297, 3 (stack45)
        %v39304 = vor.u32 %v39303, %v39302 (stack46)
        %v39305 = vxor.u32 %v39304, %v39300 (stack47)
        %v39308 = vadd.s32 %v39305, %v39300 (stack39)
        %v39310 = vshll.u32 %v39305, 16 (stack44)
        %v39311 = vshrl.u32 %v39305, 16 (stack45)
        %v39312 = vor.u32 %v39311, %v39310 (stack46)
        %v39313 = vxor.u32 %v39312, %v39308 (stack47)
        %v39316 = vadd.s32 %v39313, %v39308 (stack39)
        %v39320 = vadd.s32 %v39316, %v8 (stack39)
        %v39322 = vshll.u32 %v39313, 24 (stack44)
        %v39323 = vshrl.u32 %v39313, 8 (stack45)
        %v39324 = vor.u32 %v39323, %v39322 (stack46)
        %v39325 = vxor.u32 %v39324, %v39316 (stack47)
        %v39328 = vadd.s32 %v39325, %v10 (stack39)
        %v39332 = vadd.s32 2, %v39328 (stack39)
        %v39336 = vadd.s32 %v39332, %v39320 (stack39)
        %v39338 = vshll.u32 %v39332, 13 (stack44)
        %v39339 = vshrl.u32 %v39332, 19 (stack45)
        %v39340 = vor.u32 %v39339, %v39338 (stack46)
        %v39341 = vxor.u32 %v39340, %v39336 (stack47)
        %v39344 = vadd.s32 %v39341, %v39336 (stack39)
        %v39346 = vshll.u32 %v39341, 15 (stack44)
        %v39347 = vshrl.u32 %v39341, 17 (stack45)
        %v39348 = vor.u32 %v39347, %v39346 (stack46)
        %v39349 = vxor.u32 %v39348, %v39344 (stack47)
        %v39352 = vadd.s32 %v39349, %v39344 (stack39)
        %v39354 = vshll.u32 %v39349, 26 (stack44)
        %v39355 = vshrl.u32 %v39349, 6 (stack45)
        %v39356 = vor.u32 %v39355, %v39354 (stack46)
        %v39357 = vxor.u32 %v39356, %v39352 (stack47)
        %v39360 = vadd.s32 %v39357, %v39352 (stack39)
        %v39364 = vadd.s32 %v39360, %v10 (stack39)
        %v39366 = vshll.u32 %v39357, 6 (stack44)
        %v39367 = vshrl.u32 %v39357, 26 (stack45)
        %v39368 = vor.u32 %v39367, %v39366 (stack46)
        %v39369 = vxor.u32 %v39368, %v39360 (stack47)
        %v39372 = vadd.s32 %v39369, %v9 (stack39)
        %v39376 = vadd.s32 3, %v39372 (stack39)
        %v39380 = vadd.s32 %v39376, %v39364 (stack39)
        %v39382 = vshll.u32 %v39376, 17 (stack44)
        %v39383 = vshrl.u32 %v39376, 15 (stack45)
        %v39384 = vor.u32 %v39383, %v39382 (stack46)
        %v39385 = vxor.u32 %v39384, %v39380 (stack47)
        %v39388 = vadd.s32 %v39385, %v39380 (stack39)
        %v39390 = vshll.u32 %v39385, 29 (stack44)
        %v39391 = vshrl.u32 %v39385, 3 (stack45)
        %v39392 = vor.u32 %v39391, %v39390 (stack46)
        %v39393 = vxor.u32 %v39392, %v39388 (stack47)
        %v39396 = vadd.s32 %v39393, %v39388 (stack39)
        %v39398 = vshll.u32 %v39393, 16 (stack44)
        %v39399 = vshrl.u32 %v39393, 16 (stack45)
        %v39400 = vor.u32 %v39399, %v39398 (stack46)
        %v39401 = vxor.u32 %v39400, %v39396 (stack47)
        %v39404 = vadd.s32 %v39401, %v39396 (stack39)
        %v39408 = vadd.s32 %v39404, %v9 (stack39)
        %v39410 = vshll.u32 %v39401, 24 (stack44)
        %v39411 = vshrl.u32 %v39401, 8 (stack45)
        %v39412 = vor.u32 %v39411, %v39410 (stack46)
        %v39413 = vxor.u32 %v39412, %v39404 (stack47)
        %v39416 = vadd.s32 %v39413, %v8 (stack39)
        %v39420 = vadd.s32 4, %v39416 (stack39)
        %v39424 = vadd.s32 %v39420, %v39408 (stack39)
        %v39426 = vshll.u32 %v39420, 13 (stack44)
        %v39427 = vshrl.u32 %v39420, 19 (stack45)
        %v39428 = vor.u32 %v39427, %v39426 (stack46)
        %v39429 = vxor.u32 %v39428, %v39424 (stack47)
        %v39432 = vadd.s32 %v39429, %v39424 (stack39)
        %v39434 = vshll.u32 %v39429, 15 (stack44)
        %v39435 = vshrl.u32 %v39429, 17 (stack45)
        %v39436 = vor.u32 %v39435, %v39434 (stack46)
        %v39437 = vxor.u32 %v39436, %v39432 (stack47)
        %v39440 = vadd.s32 %v39437, %v39432 (stack39)
        %v39442 = vshll.u32 %v39437, 26 (stack44)
        %v39443 = vshrl.u32 %v39437, 6 (stack45)
        %v39444 = vor.u32 %v39443, %v39442 (stack46)
        %v39445 = vxor.u32 %v39444, %v39440 (stack47)
        %v39448 = vadd.s32 %v39445, %v39440 (stack39)
        %v39452 = vadd.s32 %v39448, %v8 (stack39)
        %v39454 = vshll.u32 %v39445, 6 (stack44)
        %v39455 = vshrl.u32 %v39445, 26 (stack45)
        %v39456 = vor.u32 %v39455, %v39454 (stack46)
        %v39457 = vxor.u32 %v39456, %v39448 (stack47)
        %v39460 = vadd.s32 %v39457, %v10 (stack39)
        %v39464 = vadd.s32 5, %v39460 (stack39)
        %v39466 = vxor.u32 %v39464, %v39452 (stack47)
        %v39467 = vand.u32.u8 255, %v39466 (stack48)
        %v39468 = vand.u32 65535, %v39467 (stack49)
        %v39469 = vshrl.u32 %v39468, 1 (stack50)
        %v39470 = vor.u32 16256, %v39469 (stack46)
        %v39471 = vand.u32.u16 65535, %v39470 (stack51)
        %v119954 = vadd.low.f32.bf16 -1.0, %v39471 (stack52)
        %v39480 = vmul.f32 2.0, %v119954 (stack53)
        %v39484 = vadd.f32 -0.99609375, %v39480 (stack52)
        %v39488 = vmax.f32 %v39484, -0.99609375 (stack54)
        %v39490 = vand.u32 2147483647, %v39488 (stack55)
        %vm39493 = vcmp.eq.f32.partialorder %v39490, 1.0 (stack56)
        %v39498 = vmul.f32 inf, %v39488 (stack53)
        %v39500 = vxor.u32 2147483648, %v39488 (stack57)
        %v39503 = vmul.f32 %v39500, %v39488 (stack53)
        %v39505 = vadd.f32 1.0, %v39503 (stack58)
        %v39506 = vlog2.pop %v39505 (stack59)
        %v39507 = vmul.f32 0.6931472, %v39506 (stack60)
        %v39508 = vmul.f32 -0.5, %v39503 (stack61)
        %v39509 = vadd.f32 1.0, %v39508 (stack62)
        %v39510 = vmul.f32 %v39509, %v39503 (stack63)
        %v39511 = vand.u32 2147483647, %v39503 (stack64)
        %vm39512 = vcmp.lt.f32.partialorder %v39511, 0.0004427343 (stack65)
        %v39513 = vsel /*vm=*/%vm39512, /*on_true_vy=*/%v39510, /*on_false_vx=*/%v39507 (stack66)
        %v39514 = vxor.u32 2147483648, %v39513 (stack57)
        %vm39517 = vcmp.lt.f32.partialorder %v39514, 5.0 (stack56)
        %v39522 = vsel /*vm=*/%vm39517, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v39526 = vsel /*vm=*/%vm39517, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v39530 = vsel /*vm=*/%vm39517, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v39534 = vsel /*vm=*/%vm39517, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v39538 = vsel /*vm=*/%vm39517, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v39542 = vsel /*vm=*/%vm39517, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v39546 = vsel /*vm=*/%vm39517, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v39550 = vsel /*vm=*/%vm39517, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v39554 = vsel /*vm=*/%vm39517, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v39558 = vadd.f32 -2.5, %v39514 (stack52)
        %v39560 = vrsqrt.pop %v39514 (stack67)
        %v39561 = vmul.f32 %v39560, %v39514 (stack68)
        %vm39562 = vcmp.eq.f32.partialorder %v39514, inf (stack69)
        %v39563 = vsel /*vm=*/%vm39562, /*on_true_vy=*/%v39514, /*on_false_vx=*/%v39561 (stack70)
        %vm39564 = vcmp.eq.f32.partialorder %v39514, 0.0 (stack71)
        %v39565 = vand.u32 2147483648, %v39514 (stack72)
        %v39566 = vsel /*vm=*/%vm39564, /*on_true_vy=*/%v39565, /*on_false_vx=*/%v39563 (stack73)
        %v39569 = vadd.f32 -3.0, %v39566 (stack52)
        %v39573 = vsel /*vm=*/%vm39517, /*on_true_vy=*/%v39558, /*on_false_vx=*/%v39569 (stack43)
        %v39577 = vmul.f32 %v39573, %v39554 (stack53)
        %v39581 = vadd.f32 %v39577, %v39550 (stack52)
        %v39585 = vmul.f32 %v39581, %v39573 (stack53)
        %v39589 = vadd.f32 %v39585, %v39546 (stack52)
        %v39593 = vmul.f32 %v39589, %v39573 (stack53)
        %v39597 = vadd.f32 %v39593, %v39542 (stack52)
        %v39601 = vmul.f32 %v39597, %v39573 (stack53)
        %v39605 = vadd.f32 %v39601, %v39538 (stack52)
        %v39609 = vmul.f32 %v39605, %v39573 (stack53)
        %v39613 = vadd.f32 %v39609, %v39534 (stack52)
        %v39617 = vmul.f32 %v39613, %v39573 (stack53)
        %v39621 = vadd.f32 %v39617, %v39530 (stack52)
        %v39625 = vmul.f32 %v39621, %v39573 (stack53)
        %v39629 = vadd.f32 %v39625, %v39526 (stack52)
        %v39633 = vmul.f32 %v39629, %v39573 (stack53)
        %v39637 = vadd.f32 %v39633, %v39522 (stack52)
        %v39641 = vmul.f32 %v39637, %v39488 (stack53)
        %v39645 = vsel /*vm=*/%vm39493, /*on_true_vy=*/%v39498, /*on_false_vx=*/%v39641 (stack43)
        %v39649 = vmul.f32 1.4140625, %v39645 (stack53)
        %v39652 = vpack.c.bf16 0.0, %v39649 (stack74)
        %119955 = vst [vmem:[%s280 + $0x1a8] sm:$0xf] /*vst_source=*/%v39652 (stack75)
        %v39656 = vadd.s32 %v37809, %v2355 (stack39)
        %v39666 = vadd.s32 %v39656, %v415 (stack39)
        %vm39670 = vcmp.lt.u32.totalorder %v39666, %v39656 (stack42)
        %vm39675 = vcmp.lt.u32.totalorder %v39656, %v2355 (stack42)
        %v39680 = vadd.s32 %v37792, %v2342 (stack39)
        %v39684 = vadd.s32 1, %v39680 (stack39)
        %v39688 = vsel /*vm=*/%vm39675, /*on_true_vy=*/%v39684, /*on_false_vx=*/%v39680 (stack43)
        %v39692 = vadd.s32 1, %v39688 (stack39)
        %v39696 = vsel /*vm=*/%vm39670, /*on_true_vy=*/%v39692, /*on_false_vx=*/%v39688 (stack43)
        %v39701 = vadd.s32 %v39696, %v10 (stack39)
        %v39705 = vadd.s32 %v39666, %v9 (stack39)
        %v39709 = vadd.s32 %v39705, %v39701 (stack39)
        %v39711 = vshll.u32 %v39705, 13 (stack44)
        %v39712 = vshrl.u32 %v39705, 19 (stack45)
        %v39713 = vor.u32 %v39712, %v39711 (stack46)
        %v39714 = vxor.u32 %v39713, %v39709 (stack47)
        %v39717 = vadd.s32 %v39714, %v39709 (stack39)
        %v39719 = vshll.u32 %v39714, 15 (stack44)
        %v39720 = vshrl.u32 %v39714, 17 (stack45)
        %v39721 = vor.u32 %v39720, %v39719 (stack46)
        %v39722 = vxor.u32 %v39721, %v39717 (stack47)
        %v39725 = vadd.s32 %v39722, %v39717 (stack39)
        %v39727 = vshll.u32 %v39722, 26 (stack44)
        %v39728 = vshrl.u32 %v39722, 6 (stack45)
        %v39729 = vor.u32 %v39728, %v39727 (stack46)
        %v39730 = vxor.u32 %v39729, %v39725 (stack47)
        %v39733 = vadd.s32 %v39730, %v39725 (stack39)
        %v39737 = vadd.s32 %v39733, %v9 (stack39)
        %v39739 = vshll.u32 %v39730, 6 (stack44)
        %v39740 = vshrl.u32 %v39730, 26 (stack45)
        %v39741 = vor.u32 %v39740, %v39739 (stack46)
        %v39742 = vxor.u32 %v39741, %v39733 (stack47)
        %v39745 = vadd.s32 %v39742, %v8 (stack39)
        %v39749 = vadd.s32 1, %v39745 (stack39)
        %v39753 = vadd.s32 %v39749, %v39737 (stack39)
        %v39755 = vshll.u32 %v39749, 17 (stack44)
        %v39756 = vshrl.u32 %v39749, 15 (stack45)
        %v39757 = vor.u32 %v39756, %v39755 (stack46)
        %v39758 = vxor.u32 %v39757, %v39753 (stack47)
        %v39761 = vadd.s32 %v39758, %v39753 (stack39)
        %v39763 = vshll.u32 %v39758, 29 (stack44)
        %v39764 = vshrl.u32 %v39758, 3 (stack45)
        %v39765 = vor.u32 %v39764, %v39763 (stack46)
        %v39766 = vxor.u32 %v39765, %v39761 (stack47)
        %v39769 = vadd.s32 %v39766, %v39761 (stack39)
        %v39771 = vshll.u32 %v39766, 16 (stack44)
        %v39772 = vshrl.u32 %v39766, 16 (stack45)
        %v39773 = vor.u32 %v39772, %v39771 (stack46)
        %v39774 = vxor.u32 %v39773, %v39769 (stack47)
        %v39777 = vadd.s32 %v39774, %v39769 (stack39)
        %v39781 = vadd.s32 %v39777, %v8 (stack39)
        %v39783 = vshll.u32 %v39774, 24 (stack44)
        %v39784 = vshrl.u32 %v39774, 8 (stack45)
        %v39785 = vor.u32 %v39784, %v39783 (stack46)
        %v39786 = vxor.u32 %v39785, %v39777 (stack47)
        %v39789 = vadd.s32 %v39786, %v10 (stack39)
        %v39793 = vadd.s32 2, %v39789 (stack39)
        %v39797 = vadd.s32 %v39793, %v39781 (stack39)
        %v39799 = vshll.u32 %v39793, 13 (stack44)
        %v39800 = vshrl.u32 %v39793, 19 (stack45)
        %v39801 = vor.u32 %v39800, %v39799 (stack46)
        %v39802 = vxor.u32 %v39801, %v39797 (stack47)
        %v39805 = vadd.s32 %v39802, %v39797 (stack39)
        %v39807 = vshll.u32 %v39802, 15 (stack44)
        %v39808 = vshrl.u32 %v39802, 17 (stack45)
        %v39809 = vor.u32 %v39808, %v39807 (stack46)
        %v39810 = vxor.u32 %v39809, %v39805 (stack47)
        %v39813 = vadd.s32 %v39810, %v39805 (stack39)
        %v39815 = vshll.u32 %v39810, 26 (stack44)
        %v39816 = vshrl.u32 %v39810, 6 (stack45)
        %v39817 = vor.u32 %v39816, %v39815 (stack46)
        %v39818 = vxor.u32 %v39817, %v39813 (stack47)
        %v39821 = vadd.s32 %v39818, %v39813 (stack39)
        %v39825 = vadd.s32 %v39821, %v10 (stack39)
        %v39827 = vshll.u32 %v39818, 6 (stack44)
        %v39828 = vshrl.u32 %v39818, 26 (stack45)
        %v39829 = vor.u32 %v39828, %v39827 (stack46)
        %v39830 = vxor.u32 %v39829, %v39821 (stack47)
        %v39833 = vadd.s32 %v39830, %v9 (stack39)
        %v39837 = vadd.s32 3, %v39833 (stack39)
        %v39841 = vadd.s32 %v39837, %v39825 (stack39)
        %v39843 = vshll.u32 %v39837, 17 (stack44)
        %v39844 = vshrl.u32 %v39837, 15 (stack45)
        %v39845 = vor.u32 %v39844, %v39843 (stack46)
        %v39846 = vxor.u32 %v39845, %v39841 (stack47)
        %v39849 = vadd.s32 %v39846, %v39841 (stack39)
        %v39851 = vshll.u32 %v39846, 29 (stack44)
        %v39852 = vshrl.u32 %v39846, 3 (stack45)
        %v39853 = vor.u32 %v39852, %v39851 (stack46)
        %v39854 = vxor.u32 %v39853, %v39849 (stack47)
        %v39857 = vadd.s32 %v39854, %v39849 (stack39)
        %v39859 = vshll.u32 %v39854, 16 (stack44)
        %v39860 = vshrl.u32 %v39854, 16 (stack45)
        %v39861 = vor.u32 %v39860, %v39859 (stack46)
        %v39862 = vxor.u32 %v39861, %v39857 (stack47)
        %v39865 = vadd.s32 %v39862, %v39857 (stack39)
        %v39869 = vadd.s32 %v39865, %v9 (stack39)
        %v39871 = vshll.u32 %v39862, 24 (stack44)
        %v39872 = vshrl.u32 %v39862, 8 (stack45)
        %v39873 = vor.u32 %v39872, %v39871 (stack46)
        %v39874 = vxor.u32 %v39873, %v39865 (stack47)
        %v39877 = vadd.s32 %v39874, %v8 (stack39)
        %v39881 = vadd.s32 4, %v39877 (stack39)
        %v39885 = vadd.s32 %v39881, %v39869 (stack39)
        %v39887 = vshll.u32 %v39881, 13 (stack44)
        %v39888 = vshrl.u32 %v39881, 19 (stack45)
        %v39889 = vor.u32 %v39888, %v39887 (stack46)
        %v39890 = vxor.u32 %v39889, %v39885 (stack47)
        %v39893 = vadd.s32 %v39890, %v39885 (stack39)
        %v39895 = vshll.u32 %v39890, 15 (stack44)
        %v39896 = vshrl.u32 %v39890, 17 (stack45)
        %v39897 = vor.u32 %v39896, %v39895 (stack46)
        %v39898 = vxor.u32 %v39897, %v39893 (stack47)
        %v39901 = vadd.s32 %v39898, %v39893 (stack39)
        %v39903 = vshll.u32 %v39898, 26 (stack44)
        %v39904 = vshrl.u32 %v39898, 6 (stack45)
        %v39905 = vor.u32 %v39904, %v39903 (stack46)
        %v39906 = vxor.u32 %v39905, %v39901 (stack47)
        %v39909 = vadd.s32 %v39906, %v39901 (stack39)
        %v39913 = vadd.s32 %v39909, %v8 (stack39)
        %v39915 = vshll.u32 %v39906, 6 (stack44)
        %v39916 = vshrl.u32 %v39906, 26 (stack45)
        %v39917 = vor.u32 %v39916, %v39915 (stack46)
        %v39918 = vxor.u32 %v39917, %v39909 (stack47)
        %v39921 = vadd.s32 %v39918, %v10 (stack39)
        %v39925 = vadd.s32 5, %v39921 (stack39)
        %v39927 = vxor.u32 %v39925, %v39913 (stack47)
        %v39928 = vand.u32.u8 255, %v39927 (stack48)
        %v39929 = vand.u32 65535, %v39928 (stack49)
        %v39930 = vshrl.u32 %v39929, 1 (stack50)
        %v39931 = vor.u32 16256, %v39930 (stack46)
        %v39932 = vand.u32.u16 65535, %v39931 (stack51)
        %v119956 = vadd.low.f32.bf16 -1.0, %v39932 (stack52)
        %v39941 = vmul.f32 2.0, %v119956 (stack53)
        %v39945 = vadd.f32 -0.99609375, %v39941 (stack52)
        %v39949 = vmax.f32 %v39945, -0.99609375 (stack54)
        %v39951 = vand.u32 2147483647, %v39949 (stack55)
        %vm39954 = vcmp.eq.f32.partialorder %v39951, 1.0 (stack56)
        %v39959 = vmul.f32 inf, %v39949 (stack53)
        %v39961 = vxor.u32 2147483648, %v39949 (stack57)
        %v39964 = vmul.f32 %v39961, %v39949 (stack53)
        %v39966 = vadd.f32 1.0, %v39964 (stack58)
        %v39967 = vlog2.pop %v39966 (stack59)
        %v39968 = vmul.f32 0.6931472, %v39967 (stack60)
        %v39969 = vmul.f32 -0.5, %v39964 (stack61)
        %v39970 = vadd.f32 1.0, %v39969 (stack62)
        %v39971 = vmul.f32 %v39970, %v39964 (stack63)
        %v39972 = vand.u32 2147483647, %v39964 (stack64)
        %vm39973 = vcmp.lt.f32.partialorder %v39972, 0.0004427343 (stack65)
        %v39974 = vsel /*vm=*/%vm39973, /*on_true_vy=*/%v39971, /*on_false_vx=*/%v39968 (stack66)
        %v39975 = vxor.u32 2147483648, %v39974 (stack57)
        %vm39978 = vcmp.lt.f32.partialorder %v39975, 5.0 (stack56)
        %v39983 = vsel /*vm=*/%vm39978, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v39987 = vsel /*vm=*/%vm39978, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v39991 = vsel /*vm=*/%vm39978, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v39995 = vsel /*vm=*/%vm39978, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v39999 = vsel /*vm=*/%vm39978, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v40003 = vsel /*vm=*/%vm39978, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v40007 = vsel /*vm=*/%vm39978, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v40011 = vsel /*vm=*/%vm39978, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v40015 = vsel /*vm=*/%vm39978, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v40019 = vadd.f32 -2.5, %v39975 (stack52)
        %v40021 = vrsqrt.pop %v39975 (stack67)
        %v40022 = vmul.f32 %v40021, %v39975 (stack68)
        %vm40023 = vcmp.eq.f32.partialorder %v39975, inf (stack69)
        %v40024 = vsel /*vm=*/%vm40023, /*on_true_vy=*/%v39975, /*on_false_vx=*/%v40022 (stack70)
        %vm40025 = vcmp.eq.f32.partialorder %v39975, 0.0 (stack71)
        %v40026 = vand.u32 2147483648, %v39975 (stack72)
        %v40027 = vsel /*vm=*/%vm40025, /*on_true_vy=*/%v40026, /*on_false_vx=*/%v40024 (stack73)
        %v40030 = vadd.f32 -3.0, %v40027 (stack52)
        %v40034 = vsel /*vm=*/%vm39978, /*on_true_vy=*/%v40019, /*on_false_vx=*/%v40030 (stack43)
        %v40038 = vmul.f32 %v40034, %v40015 (stack53)
        %v40042 = vadd.f32 %v40038, %v40011 (stack52)
        %v40046 = vmul.f32 %v40042, %v40034 (stack53)
        %v40050 = vadd.f32 %v40046, %v40007 (stack52)
        %v40054 = vmul.f32 %v40050, %v40034 (stack53)
        %v40058 = vadd.f32 %v40054, %v40003 (stack52)
        %v40062 = vmul.f32 %v40058, %v40034 (stack53)
        %v40066 = vadd.f32 %v40062, %v39999 (stack52)
        %v40070 = vmul.f32 %v40066, %v40034 (stack53)
        %v40074 = vadd.f32 %v40070, %v39995 (stack52)
        %v40078 = vmul.f32 %v40074, %v40034 (stack53)
        %v40082 = vadd.f32 %v40078, %v39991 (stack52)
        %v40086 = vmul.f32 %v40082, %v40034 (stack53)
        %v40090 = vadd.f32 %v40086, %v39987 (stack52)
        %v40094 = vmul.f32 %v40090, %v40034 (stack53)
        %v40098 = vadd.f32 %v40094, %v39983 (stack52)
        %v40102 = vmul.f32 %v40098, %v39949 (stack53)
        %v40106 = vsel /*vm=*/%vm39954, /*on_true_vy=*/%v39959, /*on_false_vx=*/%v40102 (stack43)
        %v40110 = vmul.f32 1.4140625, %v40106 (stack53)
        %v40113 = vpack.c.bf16 0.0, %v40110 (stack74)
        %119957 = vst [vmem:[%s280 + $0x228] sm:$0xf] /*vst_source=*/%v40113 (stack75)
        %v40117 = vadd.s32 %v37809, %v2842 (stack39)
        %v40127 = vadd.s32 %v40117, %v415 (stack39)
        %vm40131 = vcmp.lt.u32.totalorder %v40127, %v40117 (stack42)
        %vm40136 = vcmp.lt.u32.totalorder %v40117, %v2842 (stack42)
        %v40141 = vadd.s32 %v37792, %v2829 (stack39)
        %v40145 = vadd.s32 1, %v40141 (stack39)
        %v40149 = vsel /*vm=*/%vm40136, /*on_true_vy=*/%v40145, /*on_false_vx=*/%v40141 (stack43)
        %v40153 = vadd.s32 1, %v40149 (stack39)
        %v40157 = vsel /*vm=*/%vm40131, /*on_true_vy=*/%v40153, /*on_false_vx=*/%v40149 (stack43)
        %v40162 = vadd.s32 %v40157, %v10 (stack39)
        %v40166 = vadd.s32 %v40127, %v9 (stack39)
        %v40170 = vadd.s32 %v40166, %v40162 (stack39)
        %v40172 = vshll.u32 %v40166, 13 (stack44)
        %v40173 = vshrl.u32 %v40166, 19 (stack45)
        %v40174 = vor.u32 %v40173, %v40172 (stack46)
        %v40175 = vxor.u32 %v40174, %v40170 (stack47)
        %v40178 = vadd.s32 %v40175, %v40170 (stack39)
        %v40180 = vshll.u32 %v40175, 15 (stack44)
        %v40181 = vshrl.u32 %v40175, 17 (stack45)
        %v40182 = vor.u32 %v40181, %v40180 (stack46)
        %v40183 = vxor.u32 %v40182, %v40178 (stack47)
        %v40186 = vadd.s32 %v40183, %v40178 (stack39)
        %v40188 = vshll.u32 %v40183, 26 (stack44)
        %v40189 = vshrl.u32 %v40183, 6 (stack45)
        %v40190 = vor.u32 %v40189, %v40188 (stack46)
        %v40191 = vxor.u32 %v40190, %v40186 (stack47)
        %v40194 = vadd.s32 %v40191, %v40186 (stack39)
        %v40198 = vadd.s32 %v40194, %v9 (stack39)
        %v40200 = vshll.u32 %v40191, 6 (stack44)
        %v40201 = vshrl.u32 %v40191, 26 (stack45)
        %v40202 = vor.u32 %v40201, %v40200 (stack46)
        %v40203 = vxor.u32 %v40202, %v40194 (stack47)
        %v40206 = vadd.s32 %v40203, %v8 (stack39)
        %v40210 = vadd.s32 1, %v40206 (stack39)
        %v40214 = vadd.s32 %v40210, %v40198 (stack39)
        %v40216 = vshll.u32 %v40210, 17 (stack44)
        %v40217 = vshrl.u32 %v40210, 15 (stack45)
        %v40218 = vor.u32 %v40217, %v40216 (stack46)
        %v40219 = vxor.u32 %v40218, %v40214 (stack47)
        %v40222 = vadd.s32 %v40219, %v40214 (stack39)
        %v40224 = vshll.u32 %v40219, 29 (stack44)
        %v40225 = vshrl.u32 %v40219, 3 (stack45)
        %v40226 = vor.u32 %v40225, %v40224 (stack46)
        %v40227 = vxor.u32 %v40226, %v40222 (stack47)
        %v40230 = vadd.s32 %v40227, %v40222 (stack39)
        %v40232 = vshll.u32 %v40227, 16 (stack44)
        %v40233 = vshrl.u32 %v40227, 16 (stack45)
        %v40234 = vor.u32 %v40233, %v40232 (stack46)
        %v40235 = vxor.u32 %v40234, %v40230 (stack47)
        %v40238 = vadd.s32 %v40235, %v40230 (stack39)
        %v40242 = vadd.s32 %v40238, %v8 (stack39)
        %v40244 = vshll.u32 %v40235, 24 (stack44)
        %v40245 = vshrl.u32 %v40235, 8 (stack45)
        %v40246 = vor.u32 %v40245, %v40244 (stack46)
        %v40247 = vxor.u32 %v40246, %v40238 (stack47)
        %v40250 = vadd.s32 %v40247, %v10 (stack39)
        %v40254 = vadd.s32 2, %v40250 (stack39)
        %v40258 = vadd.s32 %v40254, %v40242 (stack39)
        %v40260 = vshll.u32 %v40254, 13 (stack44)
        %v40261 = vshrl.u32 %v40254, 19 (stack45)
        %v40262 = vor.u32 %v40261, %v40260 (stack46)
        %v40263 = vxor.u32 %v40262, %v40258 (stack47)
        %v40266 = vadd.s32 %v40263, %v40258 (stack39)
        %v40268 = vshll.u32 %v40263, 15 (stack44)
        %v40269 = vshrl.u32 %v40263, 17 (stack45)
        %v40270 = vor.u32 %v40269, %v40268 (stack46)
        %v40271 = vxor.u32 %v40270, %v40266 (stack47)
        %v40274 = vadd.s32 %v40271, %v40266 (stack39)
        %v40276 = vshll.u32 %v40271, 26 (stack44)
        %v40277 = vshrl.u32 %v40271, 6 (stack45)
        %v40278 = vor.u32 %v40277, %v40276 (stack46)
        %v40279 = vxor.u32 %v40278, %v40274 (stack47)
        %v40282 = vadd.s32 %v40279, %v40274 (stack39)
        %v40286 = vadd.s32 %v40282, %v10 (stack39)
        %v40288 = vshll.u32 %v40279, 6 (stack44)
        %v40289 = vshrl.u32 %v40279, 26 (stack45)
        %v40290 = vor.u32 %v40289, %v40288 (stack46)
        %v40291 = vxor.u32 %v40290, %v40282 (stack47)
        %v40294 = vadd.s32 %v40291, %v9 (stack39)
        %v40298 = vadd.s32 3, %v40294 (stack39)
        %v40302 = vadd.s32 %v40298, %v40286 (stack39)
        %v40304 = vshll.u32 %v40298, 17 (stack44)
        %v40305 = vshrl.u32 %v40298, 15 (stack45)
        %v40306 = vor.u32 %v40305, %v40304 (stack46)
        %v40307 = vxor.u32 %v40306, %v40302 (stack47)
        %v40310 = vadd.s32 %v40307, %v40302 (stack39)
        %v40312 = vshll.u32 %v40307, 29 (stack44)
        %v40313 = vshrl.u32 %v40307, 3 (stack45)
        %v40314 = vor.u32 %v40313, %v40312 (stack46)
        %v40315 = vxor.u32 %v40314, %v40310 (stack47)
        %v40318 = vadd.s32 %v40315, %v40310 (stack39)
        %v40320 = vshll.u32 %v40315, 16 (stack44)
        %v40321 = vshrl.u32 %v40315, 16 (stack45)
        %v40322 = vor.u32 %v40321, %v40320 (stack46)
        %v40323 = vxor.u32 %v40322, %v40318 (stack47)
        %v40326 = vadd.s32 %v40323, %v40318 (stack39)
        %v40330 = vadd.s32 %v40326, %v9 (stack39)
        %v40332 = vshll.u32 %v40323, 24 (stack44)
        %v40333 = vshrl.u32 %v40323, 8 (stack45)
        %v40334 = vor.u32 %v40333, %v40332 (stack46)
        %v40335 = vxor.u32 %v40334, %v40326 (stack47)
        %v40338 = vadd.s32 %v40335, %v8 (stack39)
        %v40342 = vadd.s32 4, %v40338 (stack39)
        %v40346 = vadd.s32 %v40342, %v40330 (stack39)
        %v40348 = vshll.u32 %v40342, 13 (stack44)
        %v40349 = vshrl.u32 %v40342, 19 (stack45)
        %v40350 = vor.u32 %v40349, %v40348 (stack46)
        %v40351 = vxor.u32 %v40350, %v40346 (stack47)
        %v40354 = vadd.s32 %v40351, %v40346 (stack39)
        %v40356 = vshll.u32 %v40351, 15 (stack44)
        %v40357 = vshrl.u32 %v40351, 17 (stack45)
        %v40358 = vor.u32 %v40357, %v40356 (stack46)
        %v40359 = vxor.u32 %v40358, %v40354 (stack47)
        %v40362 = vadd.s32 %v40359, %v40354 (stack39)
        %v40364 = vshll.u32 %v40359, 26 (stack44)
        %v40365 = vshrl.u32 %v40359, 6 (stack45)
        %v40366 = vor.u32 %v40365, %v40364 (stack46)
        %v40367 = vxor.u32 %v40366, %v40362 (stack47)
        %v40370 = vadd.s32 %v40367, %v40362 (stack39)
        %v40374 = vadd.s32 %v40370, %v8 (stack39)
        %v40376 = vshll.u32 %v40367, 6 (stack44)
        %v40377 = vshrl.u32 %v40367, 26 (stack45)
        %v40378 = vor.u32 %v40377, %v40376 (stack46)
        %v40379 = vxor.u32 %v40378, %v40370 (stack47)
        %v40382 = vadd.s32 %v40379, %v10 (stack39)
        %v40386 = vadd.s32 5, %v40382 (stack39)
        %v40388 = vxor.u32 %v40386, %v40374 (stack47)
        %v40389 = vand.u32.u8 255, %v40388 (stack48)
        %v40390 = vand.u32 65535, %v40389 (stack49)
        %v40391 = vshrl.u32 %v40390, 1 (stack50)
        %v40392 = vor.u32 16256, %v40391 (stack46)
        %v40393 = vand.u32.u16 65535, %v40392 (stack51)
        %v119958 = vadd.low.f32.bf16 -1.0, %v40393 (stack52)
        %v40402 = vmul.f32 2.0, %v119958 (stack53)
        %v40406 = vadd.f32 -0.99609375, %v40402 (stack52)
        %v40410 = vmax.f32 %v40406, -0.99609375 (stack54)
        %v40412 = vand.u32 2147483647, %v40410 (stack55)
        %vm40415 = vcmp.eq.f32.partialorder %v40412, 1.0 (stack56)
        %v40420 = vmul.f32 inf, %v40410 (stack53)
        %v40422 = vxor.u32 2147483648, %v40410 (stack57)
        %v40425 = vmul.f32 %v40422, %v40410 (stack53)
        %v40427 = vadd.f32 1.0, %v40425 (stack58)
        %v40428 = vlog2.pop %v40427 (stack59)
        %v40429 = vmul.f32 0.6931472, %v40428 (stack60)
        %v40430 = vmul.f32 -0.5, %v40425 (stack61)
        %v40431 = vadd.f32 1.0, %v40430 (stack62)
        %v40432 = vmul.f32 %v40431, %v40425 (stack63)
        %v40433 = vand.u32 2147483647, %v40425 (stack64)
        %vm40434 = vcmp.lt.f32.partialorder %v40433, 0.0004427343 (stack65)
        %v40435 = vsel /*vm=*/%vm40434, /*on_true_vy=*/%v40432, /*on_false_vx=*/%v40429 (stack66)
        %v40436 = vxor.u32 2147483648, %v40435 (stack57)
        %vm40439 = vcmp.lt.f32.partialorder %v40436, 5.0 (stack56)
        %v40444 = vsel /*vm=*/%vm40439, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v40448 = vsel /*vm=*/%vm40439, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v40452 = vsel /*vm=*/%vm40439, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v40456 = vsel /*vm=*/%vm40439, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v40460 = vsel /*vm=*/%vm40439, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v40464 = vsel /*vm=*/%vm40439, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v40468 = vsel /*vm=*/%vm40439, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v40472 = vsel /*vm=*/%vm40439, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v40476 = vsel /*vm=*/%vm40439, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v40480 = vadd.f32 -2.5, %v40436 (stack52)
        %v40482 = vrsqrt.pop %v40436 (stack67)
        %v40483 = vmul.f32 %v40482, %v40436 (stack68)
        %vm40484 = vcmp.eq.f32.partialorder %v40436, inf (stack69)
        %v40485 = vsel /*vm=*/%vm40484, /*on_true_vy=*/%v40436, /*on_false_vx=*/%v40483 (stack70)
        %vm40486 = vcmp.eq.f32.partialorder %v40436, 0.0 (stack71)
        %v40487 = vand.u32 2147483648, %v40436 (stack72)
        %v40488 = vsel /*vm=*/%vm40486, /*on_true_vy=*/%v40487, /*on_false_vx=*/%v40485 (stack73)
        %v40491 = vadd.f32 -3.0, %v40488 (stack52)
        %v40495 = vsel /*vm=*/%vm40439, /*on_true_vy=*/%v40480, /*on_false_vx=*/%v40491 (stack43)
        %v40499 = vmul.f32 %v40495, %v40476 (stack53)
        %v40503 = vadd.f32 %v40499, %v40472 (stack52)
        %v40507 = vmul.f32 %v40503, %v40495 (stack53)
        %v40511 = vadd.f32 %v40507, %v40468 (stack52)
        %v40515 = vmul.f32 %v40511, %v40495 (stack53)
        %v40519 = vadd.f32 %v40515, %v40464 (stack52)
        %v40523 = vmul.f32 %v40519, %v40495 (stack53)
        %v40527 = vadd.f32 %v40523, %v40460 (stack52)
        %v40531 = vmul.f32 %v40527, %v40495 (stack53)
        %v40535 = vadd.f32 %v40531, %v40456 (stack52)
        %v40539 = vmul.f32 %v40535, %v40495 (stack53)
        %v40543 = vadd.f32 %v40539, %v40452 (stack52)
        %v40547 = vmul.f32 %v40543, %v40495 (stack53)
        %v40551 = vadd.f32 %v40547, %v40448 (stack52)
        %v40555 = vmul.f32 %v40551, %v40495 (stack53)
        %v40559 = vadd.f32 %v40555, %v40444 (stack52)
        %v40563 = vmul.f32 %v40559, %v40410 (stack53)
        %v40567 = vsel /*vm=*/%vm40415, /*on_true_vy=*/%v40420, /*on_false_vx=*/%v40563 (stack43)
        %v40571 = vmul.f32 1.4140625, %v40567 (stack53)
        %v40574 = vpack.c.bf16 0.0, %v40571 (stack74)
        %119959 = vst [vmem:[%s280 + $0x2a8] sm:$0xf] /*vst_source=*/%v40574 (stack75)
        %v40578 = vadd.s32 %v37809, %v3329 (stack39)
        %v40588 = vadd.s32 %v40578, %v415 (stack39)
        %vm40592 = vcmp.lt.u32.totalorder %v40588, %v40578 (stack42)
        %vm40597 = vcmp.lt.u32.totalorder %v40578, %v3329 (stack42)
        %v40602 = vadd.s32 %v37792, %v3316 (stack39)
        %v40606 = vadd.s32 1, %v40602 (stack39)
        %v40610 = vsel /*vm=*/%vm40597, /*on_true_vy=*/%v40606, /*on_false_vx=*/%v40602 (stack43)
        %v40614 = vadd.s32 1, %v40610 (stack39)
        %v40618 = vsel /*vm=*/%vm40592, /*on_true_vy=*/%v40614, /*on_false_vx=*/%v40610 (stack43)
        %v40623 = vadd.s32 %v40618, %v10 (stack39)
        %v40627 = vadd.s32 %v40588, %v9 (stack39)
        %v40631 = vadd.s32 %v40627, %v40623 (stack39)
        %v40633 = vshll.u32 %v40627, 13 (stack44)
        %v40634 = vshrl.u32 %v40627, 19 (stack45)
        %v40635 = vor.u32 %v40634, %v40633 (stack46)
        %v40636 = vxor.u32 %v40635, %v40631 (stack47)
        %v40639 = vadd.s32 %v40636, %v40631 (stack39)
        %v40641 = vshll.u32 %v40636, 15 (stack44)
        %v40642 = vshrl.u32 %v40636, 17 (stack45)
        %v40643 = vor.u32 %v40642, %v40641 (stack46)
        %v40644 = vxor.u32 %v40643, %v40639 (stack47)
        %v40647 = vadd.s32 %v40644, %v40639 (stack39)
        %v40649 = vshll.u32 %v40644, 26 (stack44)
        %v40650 = vshrl.u32 %v40644, 6 (stack45)
        %v40651 = vor.u32 %v40650, %v40649 (stack46)
        %v40652 = vxor.u32 %v40651, %v40647 (stack47)
        %v40655 = vadd.s32 %v40652, %v40647 (stack39)
        %v40659 = vadd.s32 %v40655, %v9 (stack39)
        %v40661 = vshll.u32 %v40652, 6 (stack44)
        %v40662 = vshrl.u32 %v40652, 26 (stack45)
        %v40663 = vor.u32 %v40662, %v40661 (stack46)
        %v40664 = vxor.u32 %v40663, %v40655 (stack47)
        %v40667 = vadd.s32 %v40664, %v8 (stack39)
        %v40671 = vadd.s32 1, %v40667 (stack39)
        %v40675 = vadd.s32 %v40671, %v40659 (stack39)
        %v40677 = vshll.u32 %v40671, 17 (stack44)
        %v40678 = vshrl.u32 %v40671, 15 (stack45)
        %v40679 = vor.u32 %v40678, %v40677 (stack46)
        %v40680 = vxor.u32 %v40679, %v40675 (stack47)
        %v40683 = vadd.s32 %v40680, %v40675 (stack39)
        %v40685 = vshll.u32 %v40680, 29 (stack44)
        %v40686 = vshrl.u32 %v40680, 3 (stack45)
        %v40687 = vor.u32 %v40686, %v40685 (stack46)
        %v40688 = vxor.u32 %v40687, %v40683 (stack47)
        %v40691 = vadd.s32 %v40688, %v40683 (stack39)
        %v40693 = vshll.u32 %v40688, 16 (stack44)
        %v40694 = vshrl.u32 %v40688, 16 (stack45)
        %v40695 = vor.u32 %v40694, %v40693 (stack46)
        %v40696 = vxor.u32 %v40695, %v40691 (stack47)
        %v40699 = vadd.s32 %v40696, %v40691 (stack39)
        %v40703 = vadd.s32 %v40699, %v8 (stack39)
        %v40705 = vshll.u32 %v40696, 24 (stack44)
        %v40706 = vshrl.u32 %v40696, 8 (stack45)
        %v40707 = vor.u32 %v40706, %v40705 (stack46)
        %v40708 = vxor.u32 %v40707, %v40699 (stack47)
        %v40711 = vadd.s32 %v40708, %v10 (stack39)
        %v40715 = vadd.s32 2, %v40711 (stack39)
        %v40719 = vadd.s32 %v40715, %v40703 (stack39)
        %v40721 = vshll.u32 %v40715, 13 (stack44)
        %v40722 = vshrl.u32 %v40715, 19 (stack45)
        %v40723 = vor.u32 %v40722, %v40721 (stack46)
        %v40724 = vxor.u32 %v40723, %v40719 (stack47)
        %v40727 = vadd.s32 %v40724, %v40719 (stack39)
        %v40729 = vshll.u32 %v40724, 15 (stack44)
        %v40730 = vshrl.u32 %v40724, 17 (stack45)
        %v40731 = vor.u32 %v40730, %v40729 (stack46)
        %v40732 = vxor.u32 %v40731, %v40727 (stack47)
        %v40735 = vadd.s32 %v40732, %v40727 (stack39)
        %v40737 = vshll.u32 %v40732, 26 (stack44)
        %v40738 = vshrl.u32 %v40732, 6 (stack45)
        %v40739 = vor.u32 %v40738, %v40737 (stack46)
        %v40740 = vxor.u32 %v40739, %v40735 (stack47)
        %v40743 = vadd.s32 %v40740, %v40735 (stack39)
        %v40747 = vadd.s32 %v40743, %v10 (stack39)
        %v40749 = vshll.u32 %v40740, 6 (stack44)
        %v40750 = vshrl.u32 %v40740, 26 (stack45)
        %v40751 = vor.u32 %v40750, %v40749 (stack46)
        %v40752 = vxor.u32 %v40751, %v40743 (stack47)
        %v40755 = vadd.s32 %v40752, %v9 (stack39)
        %v40759 = vadd.s32 3, %v40755 (stack39)
        %v40763 = vadd.s32 %v40759, %v40747 (stack39)
        %v40765 = vshll.u32 %v40759, 17 (stack44)
        %v40766 = vshrl.u32 %v40759, 15 (stack45)
        %v40767 = vor.u32 %v40766, %v40765 (stack46)
        %v40768 = vxor.u32 %v40767, %v40763 (stack47)
        %v40771 = vadd.s32 %v40768, %v40763 (stack39)
        %v40773 = vshll.u32 %v40768, 29 (stack44)
        %v40774 = vshrl.u32 %v40768, 3 (stack45)
        %v40775 = vor.u32 %v40774, %v40773 (stack46)
        %v40776 = vxor.u32 %v40775, %v40771 (stack47)
        %v40779 = vadd.s32 %v40776, %v40771 (stack39)
        %v40781 = vshll.u32 %v40776, 16 (stack44)
        %v40782 = vshrl.u32 %v40776, 16 (stack45)
        %v40783 = vor.u32 %v40782, %v40781 (stack46)
        %v40784 = vxor.u32 %v40783, %v40779 (stack47)
        %v40787 = vadd.s32 %v40784, %v40779 (stack39)
        %v40791 = vadd.s32 %v40787, %v9 (stack39)
        %v40793 = vshll.u32 %v40784, 24 (stack44)
        %v40794 = vshrl.u32 %v40784, 8 (stack45)
        %v40795 = vor.u32 %v40794, %v40793 (stack46)
        %v40796 = vxor.u32 %v40795, %v40787 (stack47)
        %v40799 = vadd.s32 %v40796, %v8 (stack39)
        %v40803 = vadd.s32 4, %v40799 (stack39)
        %v40807 = vadd.s32 %v40803, %v40791 (stack39)
        %v40809 = vshll.u32 %v40803, 13 (stack44)
        %v40810 = vshrl.u32 %v40803, 19 (stack45)
        %v40811 = vor.u32 %v40810, %v40809 (stack46)
        %v40812 = vxor.u32 %v40811, %v40807 (stack47)
        %v40815 = vadd.s32 %v40812, %v40807 (stack39)
        %v40817 = vshll.u32 %v40812, 15 (stack44)
        %v40818 = vshrl.u32 %v40812, 17 (stack45)
        %v40819 = vor.u32 %v40818, %v40817 (stack46)
        %v40820 = vxor.u32 %v40819, %v40815 (stack47)
        %v40823 = vadd.s32 %v40820, %v40815 (stack39)
        %v40825 = vshll.u32 %v40820, 26 (stack44)
        %v40826 = vshrl.u32 %v40820, 6 (stack45)
        %v40827 = vor.u32 %v40826, %v40825 (stack46)
        %v40828 = vxor.u32 %v40827, %v40823 (stack47)
        %v40831 = vadd.s32 %v40828, %v40823 (stack39)
        %v40835 = vadd.s32 %v40831, %v8 (stack39)
        %v40837 = vshll.u32 %v40828, 6 (stack44)
        %v40838 = vshrl.u32 %v40828, 26 (stack45)
        %v40839 = vor.u32 %v40838, %v40837 (stack46)
        %v40840 = vxor.u32 %v40839, %v40831 (stack47)
        %v40843 = vadd.s32 %v40840, %v10 (stack39)
        %v40847 = vadd.s32 5, %v40843 (stack39)
        %v40849 = vxor.u32 %v40847, %v40835 (stack47)
        %v40850 = vand.u32.u8 255, %v40849 (stack48)
        %v40851 = vand.u32 65535, %v40850 (stack49)
        %v40852 = vshrl.u32 %v40851, 1 (stack50)
        %v40853 = vor.u32 16256, %v40852 (stack46)
        %v40854 = vand.u32.u16 65535, %v40853 (stack51)
        %v119960 = vadd.low.f32.bf16 -1.0, %v40854 (stack52)
        %v40863 = vmul.f32 2.0, %v119960 (stack53)
        %v40867 = vadd.f32 -0.99609375, %v40863 (stack52)
        %v40871 = vmax.f32 %v40867, -0.99609375 (stack54)
        %v40873 = vand.u32 2147483647, %v40871 (stack55)
        %vm40876 = vcmp.eq.f32.partialorder %v40873, 1.0 (stack56)
        %v40881 = vmul.f32 inf, %v40871 (stack53)
        %v40883 = vxor.u32 2147483648, %v40871 (stack57)
        %v40886 = vmul.f32 %v40883, %v40871 (stack53)
        %v40888 = vadd.f32 1.0, %v40886 (stack58)
        %v40889 = vlog2.pop %v40888 (stack59)
        %v40890 = vmul.f32 0.6931472, %v40889 (stack60)
        %v40891 = vmul.f32 -0.5, %v40886 (stack61)
        %v40892 = vadd.f32 1.0, %v40891 (stack62)
        %v40893 = vmul.f32 %v40892, %v40886 (stack63)
        %v40894 = vand.u32 2147483647, %v40886 (stack64)
        %vm40895 = vcmp.lt.f32.partialorder %v40894, 0.0004427343 (stack65)
        %v40896 = vsel /*vm=*/%vm40895, /*on_true_vy=*/%v40893, /*on_false_vx=*/%v40890 (stack66)
        %v40897 = vxor.u32 2147483648, %v40896 (stack57)
        %vm40900 = vcmp.lt.f32.partialorder %v40897, 5.0 (stack56)
        %v40905 = vsel /*vm=*/%vm40900, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v40909 = vsel /*vm=*/%vm40900, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v40913 = vsel /*vm=*/%vm40900, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v40917 = vsel /*vm=*/%vm40900, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v40921 = vsel /*vm=*/%vm40900, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v40925 = vsel /*vm=*/%vm40900, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v40929 = vsel /*vm=*/%vm40900, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v40933 = vsel /*vm=*/%vm40900, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v40937 = vsel /*vm=*/%vm40900, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v40941 = vadd.f32 -2.5, %v40897 (stack52)
        %v40943 = vrsqrt.pop %v40897 (stack67)
        %v40944 = vmul.f32 %v40943, %v40897 (stack68)
        %vm40945 = vcmp.eq.f32.partialorder %v40897, inf (stack69)
        %v40946 = vsel /*vm=*/%vm40945, /*on_true_vy=*/%v40897, /*on_false_vx=*/%v40944 (stack70)
        %vm40947 = vcmp.eq.f32.partialorder %v40897, 0.0 (stack71)
        %v40948 = vand.u32 2147483648, %v40897 (stack72)
        %v40949 = vsel /*vm=*/%vm40947, /*on_true_vy=*/%v40948, /*on_false_vx=*/%v40946 (stack73)
        %v40952 = vadd.f32 -3.0, %v40949 (stack52)
        %v40956 = vsel /*vm=*/%vm40900, /*on_true_vy=*/%v40941, /*on_false_vx=*/%v40952 (stack43)
        %v40960 = vmul.f32 %v40956, %v40937 (stack53)
        %v40964 = vadd.f32 %v40960, %v40933 (stack52)
        %v40968 = vmul.f32 %v40964, %v40956 (stack53)
        %v40972 = vadd.f32 %v40968, %v40929 (stack52)
        %v40976 = vmul.f32 %v40972, %v40956 (stack53)
        %v40980 = vadd.f32 %v40976, %v40925 (stack52)
        %v40984 = vmul.f32 %v40980, %v40956 (stack53)
        %v40988 = vadd.f32 %v40984, %v40921 (stack52)
        %v40992 = vmul.f32 %v40988, %v40956 (stack53)
        %v40996 = vadd.f32 %v40992, %v40917 (stack52)
        %v41000 = vmul.f32 %v40996, %v40956 (stack53)
        %v41004 = vadd.f32 %v41000, %v40913 (stack52)
        %v41008 = vmul.f32 %v41004, %v40956 (stack53)
        %v41012 = vadd.f32 %v41008, %v40909 (stack52)
        %v41016 = vmul.f32 %v41012, %v40956 (stack53)
        %v41020 = vadd.f32 %v41016, %v40905 (stack52)
        %v41024 = vmul.f32 %v41020, %v40871 (stack53)
        %v41028 = vsel /*vm=*/%vm40876, /*on_true_vy=*/%v40881, /*on_false_vx=*/%v41024 (stack43)
        %v41032 = vmul.f32 1.4140625, %v41028 (stack53)
        %v41035 = vpack.c.bf16 0.0, %v41032 (stack74)
        %119961 = vst [vmem:[%s280 + $0x328] sm:$0xf] /*vst_source=*/%v41035 (stack75)
        %v41039 = vadd.s32 %v37809, %v3816 (stack39)
        %v41049 = vadd.s32 %v41039, %v415 (stack39)
        %vm41053 = vcmp.lt.u32.totalorder %v41049, %v41039 (stack42)
        %vm41058 = vcmp.lt.u32.totalorder %v41039, %v3816 (stack42)
        %v41063 = vadd.s32 %v37792, %v3803 (stack39)
        %v41067 = vadd.s32 1, %v41063 (stack39)
        %v41071 = vsel /*vm=*/%vm41058, /*on_true_vy=*/%v41067, /*on_false_vx=*/%v41063 (stack43)
        %v41075 = vadd.s32 1, %v41071 (stack39)
        %v41079 = vsel /*vm=*/%vm41053, /*on_true_vy=*/%v41075, /*on_false_vx=*/%v41071 (stack43)
        %v41084 = vadd.s32 %v41079, %v10 (stack39)
        %v41088 = vadd.s32 %v41049, %v9 (stack39)
        %v41092 = vadd.s32 %v41088, %v41084 (stack39)
        %v41094 = vshll.u32 %v41088, 13 (stack44)
        %v41095 = vshrl.u32 %v41088, 19 (stack45)
        %v41096 = vor.u32 %v41095, %v41094 (stack46)
        %v41097 = vxor.u32 %v41096, %v41092 (stack47)
        %v41100 = vadd.s32 %v41097, %v41092 (stack39)
        %v41102 = vshll.u32 %v41097, 15 (stack44)
        %v41103 = vshrl.u32 %v41097, 17 (stack45)
        %v41104 = vor.u32 %v41103, %v41102 (stack46)
        %v41105 = vxor.u32 %v41104, %v41100 (stack47)
        %v41108 = vadd.s32 %v41105, %v41100 (stack39)
        %v41110 = vshll.u32 %v41105, 26 (stack44)
        %v41111 = vshrl.u32 %v41105, 6 (stack45)
        %v41112 = vor.u32 %v41111, %v41110 (stack46)
        %v41113 = vxor.u32 %v41112, %v41108 (stack47)
        %v41116 = vadd.s32 %v41113, %v41108 (stack39)
        %v41120 = vadd.s32 %v41116, %v9 (stack39)
        %v41122 = vshll.u32 %v41113, 6 (stack44)
        %v41123 = vshrl.u32 %v41113, 26 (stack45)
        %v41124 = vor.u32 %v41123, %v41122 (stack46)
        %v41125 = vxor.u32 %v41124, %v41116 (stack47)
        %v41128 = vadd.s32 %v41125, %v8 (stack39)
        %v41132 = vadd.s32 1, %v41128 (stack39)
        %v41136 = vadd.s32 %v41132, %v41120 (stack39)
        %v41138 = vshll.u32 %v41132, 17 (stack44)
        %v41139 = vshrl.u32 %v41132, 15 (stack45)
        %v41140 = vor.u32 %v41139, %v41138 (stack46)
        %v41141 = vxor.u32 %v41140, %v41136 (stack47)
        %v41144 = vadd.s32 %v41141, %v41136 (stack39)
        %v41146 = vshll.u32 %v41141, 29 (stack44)
        %v41147 = vshrl.u32 %v41141, 3 (stack45)
        %v41148 = vor.u32 %v41147, %v41146 (stack46)
        %v41149 = vxor.u32 %v41148, %v41144 (stack47)
        %v41152 = vadd.s32 %v41149, %v41144 (stack39)
        %v41154 = vshll.u32 %v41149, 16 (stack44)
        %v41155 = vshrl.u32 %v41149, 16 (stack45)
        %v41156 = vor.u32 %v41155, %v41154 (stack46)
        %v41157 = vxor.u32 %v41156, %v41152 (stack47)
        %v41160 = vadd.s32 %v41157, %v41152 (stack39)
        %v41164 = vadd.s32 %v41160, %v8 (stack39)
        %v41166 = vshll.u32 %v41157, 24 (stack44)
        %v41167 = vshrl.u32 %v41157, 8 (stack45)
        %v41168 = vor.u32 %v41167, %v41166 (stack46)
        %v41169 = vxor.u32 %v41168, %v41160 (stack47)
        %v41172 = vadd.s32 %v41169, %v10 (stack39)
        %v41176 = vadd.s32 2, %v41172 (stack39)
        %v41180 = vadd.s32 %v41176, %v41164 (stack39)
        %v41182 = vshll.u32 %v41176, 13 (stack44)
        %v41183 = vshrl.u32 %v41176, 19 (stack45)
        %v41184 = vor.u32 %v41183, %v41182 (stack46)
        %v41185 = vxor.u32 %v41184, %v41180 (stack47)
        %v41188 = vadd.s32 %v41185, %v41180 (stack39)
        %v41190 = vshll.u32 %v41185, 15 (stack44)
        %v41191 = vshrl.u32 %v41185, 17 (stack45)
        %v41192 = vor.u32 %v41191, %v41190 (stack46)
        %v41193 = vxor.u32 %v41192, %v41188 (stack47)
        %v41196 = vadd.s32 %v41193, %v41188 (stack39)
        %v41198 = vshll.u32 %v41193, 26 (stack44)
        %v41199 = vshrl.u32 %v41193, 6 (stack45)
        %v41200 = vor.u32 %v41199, %v41198 (stack46)
        %v41201 = vxor.u32 %v41200, %v41196 (stack47)
        %v41204 = vadd.s32 %v41201, %v41196 (stack39)
        %v41208 = vadd.s32 %v41204, %v10 (stack39)
        %v41210 = vshll.u32 %v41201, 6 (stack44)
        %v41211 = vshrl.u32 %v41201, 26 (stack45)
        %v41212 = vor.u32 %v41211, %v41210 (stack46)
        %v41213 = vxor.u32 %v41212, %v41204 (stack47)
        %v41216 = vadd.s32 %v41213, %v9 (stack39)
        %v41220 = vadd.s32 3, %v41216 (stack39)
        %v41224 = vadd.s32 %v41220, %v41208 (stack39)
        %v41226 = vshll.u32 %v41220, 17 (stack44)
        %v41227 = vshrl.u32 %v41220, 15 (stack45)
        %v41228 = vor.u32 %v41227, %v41226 (stack46)
        %v41229 = vxor.u32 %v41228, %v41224 (stack47)
        %v41232 = vadd.s32 %v41229, %v41224 (stack39)
        %v41234 = vshll.u32 %v41229, 29 (stack44)
        %v41235 = vshrl.u32 %v41229, 3 (stack45)
        %v41236 = vor.u32 %v41235, %v41234 (stack46)
        %v41237 = vxor.u32 %v41236, %v41232 (stack47)
        %v41240 = vadd.s32 %v41237, %v41232 (stack39)
        %v41242 = vshll.u32 %v41237, 16 (stack44)
        %v41243 = vshrl.u32 %v41237, 16 (stack45)
        %v41244 = vor.u32 %v41243, %v41242 (stack46)
        %v41245 = vxor.u32 %v41244, %v41240 (stack47)
        %v41248 = vadd.s32 %v41245, %v41240 (stack39)
        %v41252 = vadd.s32 %v41248, %v9 (stack39)
        %v41254 = vshll.u32 %v41245, 24 (stack44)
        %v41255 = vshrl.u32 %v41245, 8 (stack45)
        %v41256 = vor.u32 %v41255, %v41254 (stack46)
        %v41257 = vxor.u32 %v41256, %v41248 (stack47)
        %v41260 = vadd.s32 %v41257, %v8 (stack39)
        %v41264 = vadd.s32 4, %v41260 (stack39)
        %v41268 = vadd.s32 %v41264, %v41252 (stack39)
        %v41270 = vshll.u32 %v41264, 13 (stack44)
        %v41271 = vshrl.u32 %v41264, 19 (stack45)
        %v41272 = vor.u32 %v41271, %v41270 (stack46)
        %v41273 = vxor.u32 %v41272, %v41268 (stack47)
        %v41276 = vadd.s32 %v41273, %v41268 (stack39)
        %v41278 = vshll.u32 %v41273, 15 (stack44)
        %v41279 = vshrl.u32 %v41273, 17 (stack45)
        %v41280 = vor.u32 %v41279, %v41278 (stack46)
        %v41281 = vxor.u32 %v41280, %v41276 (stack47)
        %v41284 = vadd.s32 %v41281, %v41276 (stack39)
        %v41286 = vshll.u32 %v41281, 26 (stack44)
        %v41287 = vshrl.u32 %v41281, 6 (stack45)
        %v41288 = vor.u32 %v41287, %v41286 (stack46)
        %v41289 = vxor.u32 %v41288, %v41284 (stack47)
        %v41292 = vadd.s32 %v41289, %v41284 (stack39)
        %v41296 = vadd.s32 %v41292, %v8 (stack39)
        %v41298 = vshll.u32 %v41289, 6 (stack44)
        %v41299 = vshrl.u32 %v41289, 26 (stack45)
        %v41300 = vor.u32 %v41299, %v41298 (stack46)
        %v41301 = vxor.u32 %v41300, %v41292 (stack47)
        %v41304 = vadd.s32 %v41301, %v10 (stack39)
        %v41308 = vadd.s32 5, %v41304 (stack39)
        %v41310 = vxor.u32 %v41308, %v41296 (stack47)
        %v41311 = vand.u32.u8 255, %v41310 (stack48)
        %v41312 = vand.u32 65535, %v41311 (stack49)
        %v41313 = vshrl.u32 %v41312, 1 (stack50)
        %v41314 = vor.u32 16256, %v41313 (stack46)
        %v41315 = vand.u32.u16 65535, %v41314 (stack51)
        %v119962 = vadd.low.f32.bf16 -1.0, %v41315 (stack52)
        %v41324 = vmul.f32 2.0, %v119962 (stack53)
        %v41328 = vadd.f32 -0.99609375, %v41324 (stack52)
        %v41332 = vmax.f32 %v41328, -0.99609375 (stack54)
        %v41334 = vand.u32 2147483647, %v41332 (stack55)
        %vm41337 = vcmp.eq.f32.partialorder %v41334, 1.0 (stack56)
        %v41342 = vmul.f32 inf, %v41332 (stack53)
        %v41344 = vxor.u32 2147483648, %v41332 (stack57)
        %v41347 = vmul.f32 %v41344, %v41332 (stack53)
        %v41349 = vadd.f32 1.0, %v41347 (stack58)
        %v41350 = vlog2.pop %v41349 (stack59)
        %v41351 = vmul.f32 0.6931472, %v41350 (stack60)
        %v41352 = vmul.f32 -0.5, %v41347 (stack61)
        %v41353 = vadd.f32 1.0, %v41352 (stack62)
        %v41354 = vmul.f32 %v41353, %v41347 (stack63)
        %v41355 = vand.u32 2147483647, %v41347 (stack64)
        %vm41356 = vcmp.lt.f32.partialorder %v41355, 0.0004427343 (stack65)
        %v41357 = vsel /*vm=*/%vm41356, /*on_true_vy=*/%v41354, /*on_false_vx=*/%v41351 (stack66)
        %v41358 = vxor.u32 2147483648, %v41357 (stack57)
        %vm41361 = vcmp.lt.f32.partialorder %v41358, 5.0 (stack56)
        %v41366 = vsel /*vm=*/%vm41361, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v41370 = vsel /*vm=*/%vm41361, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v41374 = vsel /*vm=*/%vm41361, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v41378 = vsel /*vm=*/%vm41361, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v41382 = vsel /*vm=*/%vm41361, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v41386 = vsel /*vm=*/%vm41361, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v41390 = vsel /*vm=*/%vm41361, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v41394 = vsel /*vm=*/%vm41361, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v41398 = vsel /*vm=*/%vm41361, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v41402 = vadd.f32 -2.5, %v41358 (stack52)
        %v41404 = vrsqrt.pop %v41358 (stack67)
        %v41405 = vmul.f32 %v41404, %v41358 (stack68)
        %vm41406 = vcmp.eq.f32.partialorder %v41358, inf (stack69)
        %v41407 = vsel /*vm=*/%vm41406, /*on_true_vy=*/%v41358, /*on_false_vx=*/%v41405 (stack70)
        %vm41408 = vcmp.eq.f32.partialorder %v41358, 0.0 (stack71)
        %v41409 = vand.u32 2147483648, %v41358 (stack72)
        %v41410 = vsel /*vm=*/%vm41408, /*on_true_vy=*/%v41409, /*on_false_vx=*/%v41407 (stack73)
        %v41413 = vadd.f32 -3.0, %v41410 (stack52)
        %v41417 = vsel /*vm=*/%vm41361, /*on_true_vy=*/%v41402, /*on_false_vx=*/%v41413 (stack43)
        %v41421 = vmul.f32 %v41417, %v41398 (stack53)
        %v41425 = vadd.f32 %v41421, %v41394 (stack52)
        %v41429 = vmul.f32 %v41425, %v41417 (stack53)
        %v41433 = vadd.f32 %v41429, %v41390 (stack52)
        %v41437 = vmul.f32 %v41433, %v41417 (stack53)
        %v41441 = vadd.f32 %v41437, %v41386 (stack52)
        %v41445 = vmul.f32 %v41441, %v41417 (stack53)
        %v41449 = vadd.f32 %v41445, %v41382 (stack52)
        %v41453 = vmul.f32 %v41449, %v41417 (stack53)
        %v41457 = vadd.f32 %v41453, %v41378 (stack52)
        %v41461 = vmul.f32 %v41457, %v41417 (stack53)
        %v41465 = vadd.f32 %v41461, %v41374 (stack52)
        %v41469 = vmul.f32 %v41465, %v41417 (stack53)
        %v41473 = vadd.f32 %v41469, %v41370 (stack52)
        %v41477 = vmul.f32 %v41473, %v41417 (stack53)
        %v41481 = vadd.f32 %v41477, %v41366 (stack52)
        %v41485 = vmul.f32 %v41481, %v41332 (stack53)
        %v41489 = vsel /*vm=*/%vm41337, /*on_true_vy=*/%v41342, /*on_false_vx=*/%v41485 (stack43)
        %v41493 = vmul.f32 1.4140625, %v41489 (stack53)
        %v41496 = vpack.c.bf16 0.0, %v41493 (stack74)
        %119963 = vst [vmem:[%s280 + $0x3a8] sm:$0xf] /*vst_source=*/%v41496 (stack75)
        %s41498 = sadd.s32 88, %s120390 (stack76)
        %s41499 = sshrl.u32 %s41498, 10 (stack23)
        %p119964 = scmp.gt.s32.totalorder %s41499, 1 (stack24)
        %s41501 = scalar_select /*predicate=*/%p119964, /*on_true=*/1, /*on_false=*/%s41499 (stack25)
        %s41502 = sand.u32 1023, %s41498 /* smod.u32 w/div 1024 */ (stack26)
        %s41503 = sshrl.u32 %s41502, 7 (stack27)
        %s41504 = sand.u32 127, %s41502 /* smod.u32 w/div 128 */ (stack28)
        %s119965 = sshll.u32 %s41501, 3 (stack29)
        %s41506 = scalar_lea.vmem %s3, %s119965 (stack30)
        %s41508 = scalar_lea.vmem %s41506, %s41503 (stack31)
        %v41509 = vld [vmem:[%s41508] ss:$0 sm:$0xff] (stack32)
        %s41510 = sand.u32 255, %s41504 (stack33)
        %s41512 = sor.u32 256, %s41510 (stack34)
        %41513 = vbcast.lane.b32.xlu0 %v41509, %s41512 (stack35)
        %v41514 = vpop.permute.xlu0 %41513 (stack36)
        %s41523 = scalar_lea.vmem %s5, %s119965 (stack30)
        %s41525 = scalar_lea.vmem %s41523, %s41503 (stack31)
        %v41526 = vld [vmem:[%s41525] ss:$0 sm:$0xff] (stack32)
        %41530 = vbcast.lane.b32.xlu0 %v41526, %s41512 (stack35)
        %v41531 = vpop.permute.xlu0 %41530 (stack36)
        %v41534 = vadd.s32 %v41531, %v408 (stack39)
        %v41544 = vadd.s32 %v41534, %v415 (stack39)
        %vm41548 = vcmp.lt.u32.totalorder %v41544, %v41534 (stack42)
        %vm41553 = vcmp.lt.u32.totalorder %v41534, %v408 (stack42)
        %v41558 = vadd.s32 %v41514, %v380 (stack39)
        %v41562 = vadd.s32 1, %v41558 (stack39)
        %v41566 = vsel /*vm=*/%vm41553, /*on_true_vy=*/%v41562, /*on_false_vx=*/%v41558 (stack43)
        %v41570 = vadd.s32 1, %v41566 (stack39)
        %v41574 = vsel /*vm=*/%vm41548, /*on_true_vy=*/%v41570, /*on_false_vx=*/%v41566 (stack43)
        %v41579 = vadd.s32 %v41574, %v10 (stack39)
        %v41583 = vadd.s32 %v41544, %v9 (stack39)
        %v41587 = vadd.s32 %v41583, %v41579 (stack39)
        %v41589 = vshll.u32 %v41583, 13 (stack44)
        %v41590 = vshrl.u32 %v41583, 19 (stack45)
        %v41591 = vor.u32 %v41590, %v41589 (stack46)
        %v41592 = vxor.u32 %v41591, %v41587 (stack47)
        %v41595 = vadd.s32 %v41592, %v41587 (stack39)
        %v41597 = vshll.u32 %v41592, 15 (stack44)
        %v41598 = vshrl.u32 %v41592, 17 (stack45)
        %v41599 = vor.u32 %v41598, %v41597 (stack46)
        %v41600 = vxor.u32 %v41599, %v41595 (stack47)
        %v41603 = vadd.s32 %v41600, %v41595 (stack39)
        %v41605 = vshll.u32 %v41600, 26 (stack44)
        %v41606 = vshrl.u32 %v41600, 6 (stack45)
        %v41607 = vor.u32 %v41606, %v41605 (stack46)
        %v41608 = vxor.u32 %v41607, %v41603 (stack47)
        %v41611 = vadd.s32 %v41608, %v41603 (stack39)
        %v41615 = vadd.s32 %v41611, %v9 (stack39)
        %v41617 = vshll.u32 %v41608, 6 (stack44)
        %v41618 = vshrl.u32 %v41608, 26 (stack45)
        %v41619 = vor.u32 %v41618, %v41617 (stack46)
        %v41620 = vxor.u32 %v41619, %v41611 (stack47)
        %v41623 = vadd.s32 %v41620, %v8 (stack39)
        %v41627 = vadd.s32 1, %v41623 (stack39)
        %v41631 = vadd.s32 %v41627, %v41615 (stack39)
        %v41633 = vshll.u32 %v41627, 17 (stack44)
        %v41634 = vshrl.u32 %v41627, 15 (stack45)
        %v41635 = vor.u32 %v41634, %v41633 (stack46)
        %v41636 = vxor.u32 %v41635, %v41631 (stack47)
        %v41639 = vadd.s32 %v41636, %v41631 (stack39)
        %v41641 = vshll.u32 %v41636, 29 (stack44)
        %v41642 = vshrl.u32 %v41636, 3 (stack45)
        %v41643 = vor.u32 %v41642, %v41641 (stack46)
        %v41644 = vxor.u32 %v41643, %v41639 (stack47)
        %v41647 = vadd.s32 %v41644, %v41639 (stack39)
        %v41649 = vshll.u32 %v41644, 16 (stack44)
        %v41650 = vshrl.u32 %v41644, 16 (stack45)
        %v41651 = vor.u32 %v41650, %v41649 (stack46)
        %v41652 = vxor.u32 %v41651, %v41647 (stack47)
        %v41655 = vadd.s32 %v41652, %v41647 (stack39)
        %v41659 = vadd.s32 %v41655, %v8 (stack39)
        %v41661 = vshll.u32 %v41652, 24 (stack44)
        %v41662 = vshrl.u32 %v41652, 8 (stack45)
        %v41663 = vor.u32 %v41662, %v41661 (stack46)
        %v41664 = vxor.u32 %v41663, %v41655 (stack47)
        %v41667 = vadd.s32 %v41664, %v10 (stack39)
        %v41671 = vadd.s32 2, %v41667 (stack39)
        %v41675 = vadd.s32 %v41671, %v41659 (stack39)
        %v41677 = vshll.u32 %v41671, 13 (stack44)
        %v41678 = vshrl.u32 %v41671, 19 (stack45)
        %v41679 = vor.u32 %v41678, %v41677 (stack46)
        %v41680 = vxor.u32 %v41679, %v41675 (stack47)
        %v41683 = vadd.s32 %v41680, %v41675 (stack39)
        %v41685 = vshll.u32 %v41680, 15 (stack44)
        %v41686 = vshrl.u32 %v41680, 17 (stack45)
        %v41687 = vor.u32 %v41686, %v41685 (stack46)
        %v41688 = vxor.u32 %v41687, %v41683 (stack47)
        %v41691 = vadd.s32 %v41688, %v41683 (stack39)
        %v41693 = vshll.u32 %v41688, 26 (stack44)
        %v41694 = vshrl.u32 %v41688, 6 (stack45)
        %v41695 = vor.u32 %v41694, %v41693 (stack46)
        %v41696 = vxor.u32 %v41695, %v41691 (stack47)
        %v41699 = vadd.s32 %v41696, %v41691 (stack39)
        %v41703 = vadd.s32 %v41699, %v10 (stack39)
        %v41705 = vshll.u32 %v41696, 6 (stack44)
        %v41706 = vshrl.u32 %v41696, 26 (stack45)
        %v41707 = vor.u32 %v41706, %v41705 (stack46)
        %v41708 = vxor.u32 %v41707, %v41699 (stack47)
        %v41711 = vadd.s32 %v41708, %v9 (stack39)
        %v41715 = vadd.s32 3, %v41711 (stack39)
        %v41719 = vadd.s32 %v41715, %v41703 (stack39)
        %v41721 = vshll.u32 %v41715, 17 (stack44)
        %v41722 = vshrl.u32 %v41715, 15 (stack45)
        %v41723 = vor.u32 %v41722, %v41721 (stack46)
        %v41724 = vxor.u32 %v41723, %v41719 (stack47)
        %v41727 = vadd.s32 %v41724, %v41719 (stack39)
        %v41729 = vshll.u32 %v41724, 29 (stack44)
        %v41730 = vshrl.u32 %v41724, 3 (stack45)
        %v41731 = vor.u32 %v41730, %v41729 (stack46)
        %v41732 = vxor.u32 %v41731, %v41727 (stack47)
        %v41735 = vadd.s32 %v41732, %v41727 (stack39)
        %v41737 = vshll.u32 %v41732, 16 (stack44)
        %v41738 = vshrl.u32 %v41732, 16 (stack45)
        %v41739 = vor.u32 %v41738, %v41737 (stack46)
        %v41740 = vxor.u32 %v41739, %v41735 (stack47)
        %v41743 = vadd.s32 %v41740, %v41735 (stack39)
        %v41747 = vadd.s32 %v41743, %v9 (stack39)
        %v41749 = vshll.u32 %v41740, 24 (stack44)
        %v41750 = vshrl.u32 %v41740, 8 (stack45)
        %v41751 = vor.u32 %v41750, %v41749 (stack46)
        %v41752 = vxor.u32 %v41751, %v41743 (stack47)
        %v41755 = vadd.s32 %v41752, %v8 (stack39)
        %v41759 = vadd.s32 4, %v41755 (stack39)
        %v41763 = vadd.s32 %v41759, %v41747 (stack39)
        %v41765 = vshll.u32 %v41759, 13 (stack44)
        %v41766 = vshrl.u32 %v41759, 19 (stack45)
        %v41767 = vor.u32 %v41766, %v41765 (stack46)
        %v41768 = vxor.u32 %v41767, %v41763 (stack47)
        %v41771 = vadd.s32 %v41768, %v41763 (stack39)
        %v41773 = vshll.u32 %v41768, 15 (stack44)
        %v41774 = vshrl.u32 %v41768, 17 (stack45)
        %v41775 = vor.u32 %v41774, %v41773 (stack46)
        %v41776 = vxor.u32 %v41775, %v41771 (stack47)
        %v41779 = vadd.s32 %v41776, %v41771 (stack39)
        %v41781 = vshll.u32 %v41776, 26 (stack44)
        %v41782 = vshrl.u32 %v41776, 6 (stack45)
        %v41783 = vor.u32 %v41782, %v41781 (stack46)
        %v41784 = vxor.u32 %v41783, %v41779 (stack47)
        %v41787 = vadd.s32 %v41784, %v41779 (stack39)
        %v41791 = vadd.s32 %v41787, %v8 (stack39)
        %v41793 = vshll.u32 %v41784, 6 (stack44)
        %v41794 = vshrl.u32 %v41784, 26 (stack45)
        %v41795 = vor.u32 %v41794, %v41793 (stack46)
        %v41796 = vxor.u32 %v41795, %v41787 (stack47)
        %v41799 = vadd.s32 %v41796, %v10 (stack39)
        %v41803 = vadd.s32 5, %v41799 (stack39)
        %v41805 = vxor.u32 %v41803, %v41791 (stack47)
        %v41806 = vand.u32.u8 255, %v41805 (stack48)
        %v41807 = vand.u32 65535, %v41806 (stack49)
        %v41808 = vshrl.u32 %v41807, 1 (stack50)
        %v41809 = vor.u32 16256, %v41808 (stack46)
        %v41810 = vand.u32.u16 65535, %v41809 (stack51)
        %v119968 = vadd.low.f32.bf16 -1.0, %v41810 (stack52)
        %v41819 = vmul.f32 2.0, %v119968 (stack53)
        %v41823 = vadd.f32 -0.99609375, %v41819 (stack52)
        %v41827 = vmax.f32 %v41823, -0.99609375 (stack54)
        %v41829 = vand.u32 2147483647, %v41827 (stack55)
        %vm41832 = vcmp.eq.f32.partialorder %v41829, 1.0 (stack56)
        %v41837 = vmul.f32 inf, %v41827 (stack53)
        %v41839 = vxor.u32 2147483648, %v41827 (stack57)
        %v41842 = vmul.f32 %v41839, %v41827 (stack53)
        %v41844 = vadd.f32 1.0, %v41842 (stack58)
        %v41845 = vlog2.pop %v41844 (stack59)
        %v41846 = vmul.f32 0.6931472, %v41845 (stack60)
        %v41847 = vmul.f32 -0.5, %v41842 (stack61)
        %v41848 = vadd.f32 1.0, %v41847 (stack62)
        %v41849 = vmul.f32 %v41848, %v41842 (stack63)
        %v41850 = vand.u32 2147483647, %v41842 (stack64)
        %vm41851 = vcmp.lt.f32.partialorder %v41850, 0.0004427343 (stack65)
        %v41852 = vsel /*vm=*/%vm41851, /*on_true_vy=*/%v41849, /*on_false_vx=*/%v41846 (stack66)
        %v41853 = vxor.u32 2147483648, %v41852 (stack57)
        %vm41856 = vcmp.lt.f32.partialorder %v41853, 5.0 (stack56)
        %v41861 = vsel /*vm=*/%vm41856, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v41865 = vsel /*vm=*/%vm41856, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v41869 = vsel /*vm=*/%vm41856, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v41873 = vsel /*vm=*/%vm41856, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v41877 = vsel /*vm=*/%vm41856, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v41881 = vsel /*vm=*/%vm41856, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v41885 = vsel /*vm=*/%vm41856, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v41889 = vsel /*vm=*/%vm41856, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v41893 = vsel /*vm=*/%vm41856, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v41897 = vadd.f32 -2.5, %v41853 (stack52)
        %v41899 = vrsqrt.pop %v41853 (stack67)
        %v41900 = vmul.f32 %v41899, %v41853 (stack68)
        %vm41901 = vcmp.eq.f32.partialorder %v41853, inf (stack69)
        %v41902 = vsel /*vm=*/%vm41901, /*on_true_vy=*/%v41853, /*on_false_vx=*/%v41900 (stack70)
        %vm41903 = vcmp.eq.f32.partialorder %v41853, 0.0 (stack71)
        %v41904 = vand.u32 2147483648, %v41853 (stack72)
        %v41905 = vsel /*vm=*/%vm41903, /*on_true_vy=*/%v41904, /*on_false_vx=*/%v41902 (stack73)
        %v41908 = vadd.f32 -3.0, %v41905 (stack52)
        %v41912 = vsel /*vm=*/%vm41856, /*on_true_vy=*/%v41897, /*on_false_vx=*/%v41908 (stack43)
        %v41916 = vmul.f32 %v41912, %v41893 (stack53)
        %v41920 = vadd.f32 %v41916, %v41889 (stack52)
        %v41924 = vmul.f32 %v41920, %v41912 (stack53)
        %v41928 = vadd.f32 %v41924, %v41885 (stack52)
        %v41932 = vmul.f32 %v41928, %v41912 (stack53)
        %v41936 = vadd.f32 %v41932, %v41881 (stack52)
        %v41940 = vmul.f32 %v41936, %v41912 (stack53)
        %v41944 = vadd.f32 %v41940, %v41877 (stack52)
        %v41948 = vmul.f32 %v41944, %v41912 (stack53)
        %v41952 = vadd.f32 %v41948, %v41873 (stack52)
        %v41956 = vmul.f32 %v41952, %v41912 (stack53)
        %v41960 = vadd.f32 %v41956, %v41869 (stack52)
        %v41964 = vmul.f32 %v41960, %v41912 (stack53)
        %v41968 = vadd.f32 %v41964, %v41865 (stack52)
        %v41972 = vmul.f32 %v41968, %v41912 (stack53)
        %v41976 = vadd.f32 %v41972, %v41861 (stack52)
        %v41980 = vmul.f32 %v41976, %v41827 (stack53)
        %v41984 = vsel /*vm=*/%vm41832, /*on_true_vy=*/%v41837, /*on_false_vx=*/%v41980 (stack43)
        %v41988 = vmul.f32 1.4140625, %v41984 (stack53)
        %v41991 = vpack.c.bf16 0.0, %v41988 (stack74)
        %119969 = vst [vmem:[%s280 + $0x2c] sm:$0xf] /*vst_source=*/%v41991 (stack75)
        %v41995 = vadd.s32 %v41531, %v894 (stack39)
        %v42005 = vadd.s32 %v41995, %v415 (stack39)
        %vm42009 = vcmp.lt.u32.totalorder %v42005, %v41995 (stack42)
        %vm42014 = vcmp.lt.u32.totalorder %v41995, %v894 (stack42)
        %v42019 = vadd.s32 %v41514, %v881 (stack39)
        %v42023 = vadd.s32 1, %v42019 (stack39)
        %v42027 = vsel /*vm=*/%vm42014, /*on_true_vy=*/%v42023, /*on_false_vx=*/%v42019 (stack43)
        %v42031 = vadd.s32 1, %v42027 (stack39)
        %v42035 = vsel /*vm=*/%vm42009, /*on_true_vy=*/%v42031, /*on_false_vx=*/%v42027 (stack43)
        %v42040 = vadd.s32 %v42035, %v10 (stack39)
        %v42044 = vadd.s32 %v42005, %v9 (stack39)
        %v42048 = vadd.s32 %v42044, %v42040 (stack39)
        %v42050 = vshll.u32 %v42044, 13 (stack44)
        %v42051 = vshrl.u32 %v42044, 19 (stack45)
        %v42052 = vor.u32 %v42051, %v42050 (stack46)
        %v42053 = vxor.u32 %v42052, %v42048 (stack47)
        %v42056 = vadd.s32 %v42053, %v42048 (stack39)
        %v42058 = vshll.u32 %v42053, 15 (stack44)
        %v42059 = vshrl.u32 %v42053, 17 (stack45)
        %v42060 = vor.u32 %v42059, %v42058 (stack46)
        %v42061 = vxor.u32 %v42060, %v42056 (stack47)
        %v42064 = vadd.s32 %v42061, %v42056 (stack39)
        %v42066 = vshll.u32 %v42061, 26 (stack44)
        %v42067 = vshrl.u32 %v42061, 6 (stack45)
        %v42068 = vor.u32 %v42067, %v42066 (stack46)
        %v42069 = vxor.u32 %v42068, %v42064 (stack47)
        %v42072 = vadd.s32 %v42069, %v42064 (stack39)
        %v42076 = vadd.s32 %v42072, %v9 (stack39)
        %v42078 = vshll.u32 %v42069, 6 (stack44)
        %v42079 = vshrl.u32 %v42069, 26 (stack45)
        %v42080 = vor.u32 %v42079, %v42078 (stack46)
        %v42081 = vxor.u32 %v42080, %v42072 (stack47)
        %v42084 = vadd.s32 %v42081, %v8 (stack39)
        %v42088 = vadd.s32 1, %v42084 (stack39)
        %v42092 = vadd.s32 %v42088, %v42076 (stack39)
        %v42094 = vshll.u32 %v42088, 17 (stack44)
        %v42095 = vshrl.u32 %v42088, 15 (stack45)
        %v42096 = vor.u32 %v42095, %v42094 (stack46)
        %v42097 = vxor.u32 %v42096, %v42092 (stack47)
        %v42100 = vadd.s32 %v42097, %v42092 (stack39)
        %v42102 = vshll.u32 %v42097, 29 (stack44)
        %v42103 = vshrl.u32 %v42097, 3 (stack45)
        %v42104 = vor.u32 %v42103, %v42102 (stack46)
        %v42105 = vxor.u32 %v42104, %v42100 (stack47)
        %v42108 = vadd.s32 %v42105, %v42100 (stack39)
        %v42110 = vshll.u32 %v42105, 16 (stack44)
        %v42111 = vshrl.u32 %v42105, 16 (stack45)
        %v42112 = vor.u32 %v42111, %v42110 (stack46)
        %v42113 = vxor.u32 %v42112, %v42108 (stack47)
        %v42116 = vadd.s32 %v42113, %v42108 (stack39)
        %v42120 = vadd.s32 %v42116, %v8 (stack39)
        %v42122 = vshll.u32 %v42113, 24 (stack44)
        %v42123 = vshrl.u32 %v42113, 8 (stack45)
        %v42124 = vor.u32 %v42123, %v42122 (stack46)
        %v42125 = vxor.u32 %v42124, %v42116 (stack47)
        %v42128 = vadd.s32 %v42125, %v10 (stack39)
        %v42132 = vadd.s32 2, %v42128 (stack39)
        %v42136 = vadd.s32 %v42132, %v42120 (stack39)
        %v42138 = vshll.u32 %v42132, 13 (stack44)
        %v42139 = vshrl.u32 %v42132, 19 (stack45)
        %v42140 = vor.u32 %v42139, %v42138 (stack46)
        %v42141 = vxor.u32 %v42140, %v42136 (stack47)
        %v42144 = vadd.s32 %v42141, %v42136 (stack39)
        %v42146 = vshll.u32 %v42141, 15 (stack44)
        %v42147 = vshrl.u32 %v42141, 17 (stack45)
        %v42148 = vor.u32 %v42147, %v42146 (stack46)
        %v42149 = vxor.u32 %v42148, %v42144 (stack47)
        %v42152 = vadd.s32 %v42149, %v42144 (stack39)
        %v42154 = vshll.u32 %v42149, 26 (stack44)
        %v42155 = vshrl.u32 %v42149, 6 (stack45)
        %v42156 = vor.u32 %v42155, %v42154 (stack46)
        %v42157 = vxor.u32 %v42156, %v42152 (stack47)
        %v42160 = vadd.s32 %v42157, %v42152 (stack39)
        %v42164 = vadd.s32 %v42160, %v10 (stack39)
        %v42166 = vshll.u32 %v42157, 6 (stack44)
        %v42167 = vshrl.u32 %v42157, 26 (stack45)
        %v42168 = vor.u32 %v42167, %v42166 (stack46)
        %v42169 = vxor.u32 %v42168, %v42160 (stack47)
        %v42172 = vadd.s32 %v42169, %v9 (stack39)
        %v42176 = vadd.s32 3, %v42172 (stack39)
        %v42180 = vadd.s32 %v42176, %v42164 (stack39)
        %v42182 = vshll.u32 %v42176, 17 (stack44)
        %v42183 = vshrl.u32 %v42176, 15 (stack45)
        %v42184 = vor.u32 %v42183, %v42182 (stack46)
        %v42185 = vxor.u32 %v42184, %v42180 (stack47)
        %v42188 = vadd.s32 %v42185, %v42180 (stack39)
        %v42190 = vshll.u32 %v42185, 29 (stack44)
        %v42191 = vshrl.u32 %v42185, 3 (stack45)
        %v42192 = vor.u32 %v42191, %v42190 (stack46)
        %v42193 = vxor.u32 %v42192, %v42188 (stack47)
        %v42196 = vadd.s32 %v42193, %v42188 (stack39)
        %v42198 = vshll.u32 %v42193, 16 (stack44)
        %v42199 = vshrl.u32 %v42193, 16 (stack45)
        %v42200 = vor.u32 %v42199, %v42198 (stack46)
        %v42201 = vxor.u32 %v42200, %v42196 (stack47)
        %v42204 = vadd.s32 %v42201, %v42196 (stack39)
        %v42208 = vadd.s32 %v42204, %v9 (stack39)
        %v42210 = vshll.u32 %v42201, 24 (stack44)
        %v42211 = vshrl.u32 %v42201, 8 (stack45)
        %v42212 = vor.u32 %v42211, %v42210 (stack46)
        %v42213 = vxor.u32 %v42212, %v42204 (stack47)
        %v42216 = vadd.s32 %v42213, %v8 (stack39)
        %v42220 = vadd.s32 4, %v42216 (stack39)
        %v42224 = vadd.s32 %v42220, %v42208 (stack39)
        %v42226 = vshll.u32 %v42220, 13 (stack44)
        %v42227 = vshrl.u32 %v42220, 19 (stack45)
        %v42228 = vor.u32 %v42227, %v42226 (stack46)
        %v42229 = vxor.u32 %v42228, %v42224 (stack47)
        %v42232 = vadd.s32 %v42229, %v42224 (stack39)
        %v42234 = vshll.u32 %v42229, 15 (stack44)
        %v42235 = vshrl.u32 %v42229, 17 (stack45)
        %v42236 = vor.u32 %v42235, %v42234 (stack46)
        %v42237 = vxor.u32 %v42236, %v42232 (stack47)
        %v42240 = vadd.s32 %v42237, %v42232 (stack39)
        %v42242 = vshll.u32 %v42237, 26 (stack44)
        %v42243 = vshrl.u32 %v42237, 6 (stack45)
        %v42244 = vor.u32 %v42243, %v42242 (stack46)
        %v42245 = vxor.u32 %v42244, %v42240 (stack47)
        %v42248 = vadd.s32 %v42245, %v42240 (stack39)
        %v42252 = vadd.s32 %v42248, %v8 (stack39)
        %v42254 = vshll.u32 %v42245, 6 (stack44)
        %v42255 = vshrl.u32 %v42245, 26 (stack45)
        %v42256 = vor.u32 %v42255, %v42254 (stack46)
        %v42257 = vxor.u32 %v42256, %v42248 (stack47)
        %v42260 = vadd.s32 %v42257, %v10 (stack39)
        %v42264 = vadd.s32 5, %v42260 (stack39)
        %v42266 = vxor.u32 %v42264, %v42252 (stack47)
        %v42267 = vand.u32.u8 255, %v42266 (stack48)
        %v42268 = vand.u32 65535, %v42267 (stack49)
        %v42269 = vshrl.u32 %v42268, 1 (stack50)
        %v42270 = vor.u32 16256, %v42269 (stack46)
        %v42271 = vand.u32.u16 65535, %v42270 (stack51)
        %v119970 = vadd.low.f32.bf16 -1.0, %v42271 (stack52)
        %v42280 = vmul.f32 2.0, %v119970 (stack53)
        %v42284 = vadd.f32 -0.99609375, %v42280 (stack52)
        %v42288 = vmax.f32 %v42284, -0.99609375 (stack54)
        %v42290 = vand.u32 2147483647, %v42288 (stack55)
        %vm42293 = vcmp.eq.f32.partialorder %v42290, 1.0 (stack56)
        %v42298 = vmul.f32 inf, %v42288 (stack53)
        %v42300 = vxor.u32 2147483648, %v42288 (stack57)
        %v42303 = vmul.f32 %v42300, %v42288 (stack53)
        %v42305 = vadd.f32 1.0, %v42303 (stack58)
        %v42306 = vlog2.pop %v42305 (stack59)
        %v42307 = vmul.f32 0.6931472, %v42306 (stack60)
        %v42308 = vmul.f32 -0.5, %v42303 (stack61)
        %v42309 = vadd.f32 1.0, %v42308 (stack62)
        %v42310 = vmul.f32 %v42309, %v42303 (stack63)
        %v42311 = vand.u32 2147483647, %v42303 (stack64)
        %vm42312 = vcmp.lt.f32.partialorder %v42311, 0.0004427343 (stack65)
        %v42313 = vsel /*vm=*/%vm42312, /*on_true_vy=*/%v42310, /*on_false_vx=*/%v42307 (stack66)
        %v42314 = vxor.u32 2147483648, %v42313 (stack57)
        %vm42317 = vcmp.lt.f32.partialorder %v42314, 5.0 (stack56)
        %v42322 = vsel /*vm=*/%vm42317, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v42326 = vsel /*vm=*/%vm42317, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v42330 = vsel /*vm=*/%vm42317, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v42334 = vsel /*vm=*/%vm42317, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v42338 = vsel /*vm=*/%vm42317, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v42342 = vsel /*vm=*/%vm42317, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v42346 = vsel /*vm=*/%vm42317, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v42350 = vsel /*vm=*/%vm42317, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v42354 = vsel /*vm=*/%vm42317, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v42358 = vadd.f32 -2.5, %v42314 (stack52)
        %v42360 = vrsqrt.pop %v42314 (stack67)
        %v42361 = vmul.f32 %v42360, %v42314 (stack68)
        %vm42362 = vcmp.eq.f32.partialorder %v42314, inf (stack69)
        %v42363 = vsel /*vm=*/%vm42362, /*on_true_vy=*/%v42314, /*on_false_vx=*/%v42361 (stack70)
        %vm42364 = vcmp.eq.f32.partialorder %v42314, 0.0 (stack71)
        %v42365 = vand.u32 2147483648, %v42314 (stack72)
        %v42366 = vsel /*vm=*/%vm42364, /*on_true_vy=*/%v42365, /*on_false_vx=*/%v42363 (stack73)
        %v42369 = vadd.f32 -3.0, %v42366 (stack52)
        %v42373 = vsel /*vm=*/%vm42317, /*on_true_vy=*/%v42358, /*on_false_vx=*/%v42369 (stack43)
        %v42377 = vmul.f32 %v42373, %v42354 (stack53)
        %v42381 = vadd.f32 %v42377, %v42350 (stack52)
        %v42385 = vmul.f32 %v42381, %v42373 (stack53)
        %v42389 = vadd.f32 %v42385, %v42346 (stack52)
        %v42393 = vmul.f32 %v42389, %v42373 (stack53)
        %v42397 = vadd.f32 %v42393, %v42342 (stack52)
        %v42401 = vmul.f32 %v42397, %v42373 (stack53)
        %v42405 = vadd.f32 %v42401, %v42338 (stack52)
        %v42409 = vmul.f32 %v42405, %v42373 (stack53)
        %v42413 = vadd.f32 %v42409, %v42334 (stack52)
        %v42417 = vmul.f32 %v42413, %v42373 (stack53)
        %v42421 = vadd.f32 %v42417, %v42330 (stack52)
        %v42425 = vmul.f32 %v42421, %v42373 (stack53)
        %v42429 = vadd.f32 %v42425, %v42326 (stack52)
        %v42433 = vmul.f32 %v42429, %v42373 (stack53)
        %v42437 = vadd.f32 %v42433, %v42322 (stack52)
        %v42441 = vmul.f32 %v42437, %v42288 (stack53)
        %v42445 = vsel /*vm=*/%vm42293, /*on_true_vy=*/%v42298, /*on_false_vx=*/%v42441 (stack43)
        %v42449 = vmul.f32 1.4140625, %v42445 (stack53)
        %v42452 = vpack.c.bf16 0.0, %v42449 (stack74)
        %119971 = vst [vmem:[%s280 + $0xac] sm:$0xf] /*vst_source=*/%v42452 (stack75)
        %v42456 = vadd.s32 %v41531, %v1381 (stack39)
        %v42466 = vadd.s32 %v42456, %v415 (stack39)
        %vm42470 = vcmp.lt.u32.totalorder %v42466, %v42456 (stack42)
        %vm42475 = vcmp.lt.u32.totalorder %v42456, %v1381 (stack42)
        %v42480 = vadd.s32 %v41514, %v1368 (stack39)
        %v42484 = vadd.s32 1, %v42480 (stack39)
        %v42488 = vsel /*vm=*/%vm42475, /*on_true_vy=*/%v42484, /*on_false_vx=*/%v42480 (stack43)
        %v42492 = vadd.s32 1, %v42488 (stack39)
        %v42496 = vsel /*vm=*/%vm42470, /*on_true_vy=*/%v42492, /*on_false_vx=*/%v42488 (stack43)
        %v42501 = vadd.s32 %v42496, %v10 (stack39)
        %v42505 = vadd.s32 %v42466, %v9 (stack39)
        %v42509 = vadd.s32 %v42505, %v42501 (stack39)
        %v42511 = vshll.u32 %v42505, 13 (stack44)
        %v42512 = vshrl.u32 %v42505, 19 (stack45)
        %v42513 = vor.u32 %v42512, %v42511 (stack46)
        %v42514 = vxor.u32 %v42513, %v42509 (stack47)
        %v42517 = vadd.s32 %v42514, %v42509 (stack39)
        %v42519 = vshll.u32 %v42514, 15 (stack44)
        %v42520 = vshrl.u32 %v42514, 17 (stack45)
        %v42521 = vor.u32 %v42520, %v42519 (stack46)
        %v42522 = vxor.u32 %v42521, %v42517 (stack47)
        %v42525 = vadd.s32 %v42522, %v42517 (stack39)
        %v42527 = vshll.u32 %v42522, 26 (stack44)
        %v42528 = vshrl.u32 %v42522, 6 (stack45)
        %v42529 = vor.u32 %v42528, %v42527 (stack46)
        %v42530 = vxor.u32 %v42529, %v42525 (stack47)
        %v42533 = vadd.s32 %v42530, %v42525 (stack39)
        %v42537 = vadd.s32 %v42533, %v9 (stack39)
        %v42539 = vshll.u32 %v42530, 6 (stack44)
        %v42540 = vshrl.u32 %v42530, 26 (stack45)
        %v42541 = vor.u32 %v42540, %v42539 (stack46)
        %v42542 = vxor.u32 %v42541, %v42533 (stack47)
        %v42545 = vadd.s32 %v42542, %v8 (stack39)
        %v42549 = vadd.s32 1, %v42545 (stack39)
        %v42553 = vadd.s32 %v42549, %v42537 (stack39)
        %v42555 = vshll.u32 %v42549, 17 (stack44)
        %v42556 = vshrl.u32 %v42549, 15 (stack45)
        %v42557 = vor.u32 %v42556, %v42555 (stack46)
        %v42558 = vxor.u32 %v42557, %v42553 (stack47)
        %v42561 = vadd.s32 %v42558, %v42553 (stack39)
        %v42563 = vshll.u32 %v42558, 29 (stack44)
        %v42564 = vshrl.u32 %v42558, 3 (stack45)
        %v42565 = vor.u32 %v42564, %v42563 (stack46)
        %v42566 = vxor.u32 %v42565, %v42561 (stack47)
        %v42569 = vadd.s32 %v42566, %v42561 (stack39)
        %v42571 = vshll.u32 %v42566, 16 (stack44)
        %v42572 = vshrl.u32 %v42566, 16 (stack45)
        %v42573 = vor.u32 %v42572, %v42571 (stack46)
        %v42574 = vxor.u32 %v42573, %v42569 (stack47)
        %v42577 = vadd.s32 %v42574, %v42569 (stack39)
        %v42581 = vadd.s32 %v42577, %v8 (stack39)
        %v42583 = vshll.u32 %v42574, 24 (stack44)
        %v42584 = vshrl.u32 %v42574, 8 (stack45)
        %v42585 = vor.u32 %v42584, %v42583 (stack46)
        %v42586 = vxor.u32 %v42585, %v42577 (stack47)
        %v42589 = vadd.s32 %v42586, %v10 (stack39)
        %v42593 = vadd.s32 2, %v42589 (stack39)
        %v42597 = vadd.s32 %v42593, %v42581 (stack39)
        %v42599 = vshll.u32 %v42593, 13 (stack44)
        %v42600 = vshrl.u32 %v42593, 19 (stack45)
        %v42601 = vor.u32 %v42600, %v42599 (stack46)
        %v42602 = vxor.u32 %v42601, %v42597 (stack47)
        %v42605 = vadd.s32 %v42602, %v42597 (stack39)
        %v42607 = vshll.u32 %v42602, 15 (stack44)
        %v42608 = vshrl.u32 %v42602, 17 (stack45)
        %v42609 = vor.u32 %v42608, %v42607 (stack46)
        %v42610 = vxor.u32 %v42609, %v42605 (stack47)
        %v42613 = vadd.s32 %v42610, %v42605 (stack39)
        %v42615 = vshll.u32 %v42610, 26 (stack44)
        %v42616 = vshrl.u32 %v42610, 6 (stack45)
        %v42617 = vor.u32 %v42616, %v42615 (stack46)
        %v42618 = vxor.u32 %v42617, %v42613 (stack47)
        %v42621 = vadd.s32 %v42618, %v42613 (stack39)
        %v42625 = vadd.s32 %v42621, %v10 (stack39)
        %v42627 = vshll.u32 %v42618, 6 (stack44)
        %v42628 = vshrl.u32 %v42618, 26 (stack45)
        %v42629 = vor.u32 %v42628, %v42627 (stack46)
        %v42630 = vxor.u32 %v42629, %v42621 (stack47)
        %v42633 = vadd.s32 %v42630, %v9 (stack39)
        %v42637 = vadd.s32 3, %v42633 (stack39)
        %v42641 = vadd.s32 %v42637, %v42625 (stack39)
        %v42643 = vshll.u32 %v42637, 17 (stack44)
        %v42644 = vshrl.u32 %v42637, 15 (stack45)
        %v42645 = vor.u32 %v42644, %v42643 (stack46)
        %v42646 = vxor.u32 %v42645, %v42641 (stack47)
        %v42649 = vadd.s32 %v42646, %v42641 (stack39)
        %v42651 = vshll.u32 %v42646, 29 (stack44)
        %v42652 = vshrl.u32 %v42646, 3 (stack45)
        %v42653 = vor.u32 %v42652, %v42651 (stack46)
        %v42654 = vxor.u32 %v42653, %v42649 (stack47)
        %v42657 = vadd.s32 %v42654, %v42649 (stack39)
        %v42659 = vshll.u32 %v42654, 16 (stack44)
        %v42660 = vshrl.u32 %v42654, 16 (stack45)
        %v42661 = vor.u32 %v42660, %v42659 (stack46)
        %v42662 = vxor.u32 %v42661, %v42657 (stack47)
        %v42665 = vadd.s32 %v42662, %v42657 (stack39)
        %v42669 = vadd.s32 %v42665, %v9 (stack39)
        %v42671 = vshll.u32 %v42662, 24 (stack44)
        %v42672 = vshrl.u32 %v42662, 8 (stack45)
        %v42673 = vor.u32 %v42672, %v42671 (stack46)
        %v42674 = vxor.u32 %v42673, %v42665 (stack47)
        %v42677 = vadd.s32 %v42674, %v8 (stack39)
        %v42681 = vadd.s32 4, %v42677 (stack39)
        %v42685 = vadd.s32 %v42681, %v42669 (stack39)
        %v42687 = vshll.u32 %v42681, 13 (stack44)
        %v42688 = vshrl.u32 %v42681, 19 (stack45)
        %v42689 = vor.u32 %v42688, %v42687 (stack46)
        %v42690 = vxor.u32 %v42689, %v42685 (stack47)
        %v42693 = vadd.s32 %v42690, %v42685 (stack39)
        %v42695 = vshll.u32 %v42690, 15 (stack44)
        %v42696 = vshrl.u32 %v42690, 17 (stack45)
        %v42697 = vor.u32 %v42696, %v42695 (stack46)
        %v42698 = vxor.u32 %v42697, %v42693 (stack47)
        %v42701 = vadd.s32 %v42698, %v42693 (stack39)
        %v42703 = vshll.u32 %v42698, 26 (stack44)
        %v42704 = vshrl.u32 %v42698, 6 (stack45)
        %v42705 = vor.u32 %v42704, %v42703 (stack46)
        %v42706 = vxor.u32 %v42705, %v42701 (stack47)
        %v42709 = vadd.s32 %v42706, %v42701 (stack39)
        %v42713 = vadd.s32 %v42709, %v8 (stack39)
        %v42715 = vshll.u32 %v42706, 6 (stack44)
        %v42716 = vshrl.u32 %v42706, 26 (stack45)
        %v42717 = vor.u32 %v42716, %v42715 (stack46)
        %v42718 = vxor.u32 %v42717, %v42709 (stack47)
        %v42721 = vadd.s32 %v42718, %v10 (stack39)
        %v42725 = vadd.s32 5, %v42721 (stack39)
        %v42727 = vxor.u32 %v42725, %v42713 (stack47)
        %v42728 = vand.u32.u8 255, %v42727 (stack48)
        %v42729 = vand.u32 65535, %v42728 (stack49)
        %v42730 = vshrl.u32 %v42729, 1 (stack50)
        %v42731 = vor.u32 16256, %v42730 (stack46)
        %v42732 = vand.u32.u16 65535, %v42731 (stack51)
        %v119972 = vadd.low.f32.bf16 -1.0, %v42732 (stack52)
        %v42741 = vmul.f32 2.0, %v119972 (stack53)
        %v42745 = vadd.f32 -0.99609375, %v42741 (stack52)
        %v42749 = vmax.f32 %v42745, -0.99609375 (stack54)
        %v42751 = vand.u32 2147483647, %v42749 (stack55)
        %vm42754 = vcmp.eq.f32.partialorder %v42751, 1.0 (stack56)
        %v42759 = vmul.f32 inf, %v42749 (stack53)
        %v42761 = vxor.u32 2147483648, %v42749 (stack57)
        %v42764 = vmul.f32 %v42761, %v42749 (stack53)
        %v42766 = vadd.f32 1.0, %v42764 (stack58)
        %v42767 = vlog2.pop %v42766 (stack59)
        %v42768 = vmul.f32 0.6931472, %v42767 (stack60)
        %v42769 = vmul.f32 -0.5, %v42764 (stack61)
        %v42770 = vadd.f32 1.0, %v42769 (stack62)
        %v42771 = vmul.f32 %v42770, %v42764 (stack63)
        %v42772 = vand.u32 2147483647, %v42764 (stack64)
        %vm42773 = vcmp.lt.f32.partialorder %v42772, 0.0004427343 (stack65)
        %v42774 = vsel /*vm=*/%vm42773, /*on_true_vy=*/%v42771, /*on_false_vx=*/%v42768 (stack66)
        %v42775 = vxor.u32 2147483648, %v42774 (stack57)
        %vm42778 = vcmp.lt.f32.partialorder %v42775, 5.0 (stack56)
        %v42783 = vsel /*vm=*/%vm42778, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v42787 = vsel /*vm=*/%vm42778, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v42791 = vsel /*vm=*/%vm42778, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v42795 = vsel /*vm=*/%vm42778, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v42799 = vsel /*vm=*/%vm42778, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v42803 = vsel /*vm=*/%vm42778, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v42807 = vsel /*vm=*/%vm42778, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v42811 = vsel /*vm=*/%vm42778, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v42815 = vsel /*vm=*/%vm42778, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v42819 = vadd.f32 -2.5, %v42775 (stack52)
        %v42821 = vrsqrt.pop %v42775 (stack67)
        %v42822 = vmul.f32 %v42821, %v42775 (stack68)
        %vm42823 = vcmp.eq.f32.partialorder %v42775, inf (stack69)
        %v42824 = vsel /*vm=*/%vm42823, /*on_true_vy=*/%v42775, /*on_false_vx=*/%v42822 (stack70)
        %vm42825 = vcmp.eq.f32.partialorder %v42775, 0.0 (stack71)
        %v42826 = vand.u32 2147483648, %v42775 (stack72)
        %v42827 = vsel /*vm=*/%vm42825, /*on_true_vy=*/%v42826, /*on_false_vx=*/%v42824 (stack73)
        %v42830 = vadd.f32 -3.0, %v42827 (stack52)
        %v42834 = vsel /*vm=*/%vm42778, /*on_true_vy=*/%v42819, /*on_false_vx=*/%v42830 (stack43)
        %v42838 = vmul.f32 %v42834, %v42815 (stack53)
        %v42842 = vadd.f32 %v42838, %v42811 (stack52)
        %v42846 = vmul.f32 %v42842, %v42834 (stack53)
        %v42850 = vadd.f32 %v42846, %v42807 (stack52)
        %v42854 = vmul.f32 %v42850, %v42834 (stack53)
        %v42858 = vadd.f32 %v42854, %v42803 (stack52)
        %v42862 = vmul.f32 %v42858, %v42834 (stack53)
        %v42866 = vadd.f32 %v42862, %v42799 (stack52)
        %v42870 = vmul.f32 %v42866, %v42834 (stack53)
        %v42874 = vadd.f32 %v42870, %v42795 (stack52)
        %v42878 = vmul.f32 %v42874, %v42834 (stack53)
        %v42882 = vadd.f32 %v42878, %v42791 (stack52)
        %v42886 = vmul.f32 %v42882, %v42834 (stack53)
        %v42890 = vadd.f32 %v42886, %v42787 (stack52)
        %v42894 = vmul.f32 %v42890, %v42834 (stack53)
        %v42898 = vadd.f32 %v42894, %v42783 (stack52)
        %v42902 = vmul.f32 %v42898, %v42749 (stack53)
        %v42906 = vsel /*vm=*/%vm42754, /*on_true_vy=*/%v42759, /*on_false_vx=*/%v42902 (stack43)
        %v42910 = vmul.f32 1.4140625, %v42906 (stack53)
        %v42913 = vpack.c.bf16 0.0, %v42910 (stack74)
        %119973 = vst [vmem:[%s280 + $0x12c] sm:$0xf] /*vst_source=*/%v42913 (stack75)
        %v42917 = vadd.s32 %v41531, %v1868 (stack39)
        %v42927 = vadd.s32 %v42917, %v415 (stack39)
        %vm42931 = vcmp.lt.u32.totalorder %v42927, %v42917 (stack42)
        %vm42936 = vcmp.lt.u32.totalorder %v42917, %v1868 (stack42)
        %v42941 = vadd.s32 %v41514, %v1855 (stack39)
        %v42945 = vadd.s32 1, %v42941 (stack39)
        %v42949 = vsel /*vm=*/%vm42936, /*on_true_vy=*/%v42945, /*on_false_vx=*/%v42941 (stack43)
        %v42953 = vadd.s32 1, %v42949 (stack39)
        %v42957 = vsel /*vm=*/%vm42931, /*on_true_vy=*/%v42953, /*on_false_vx=*/%v42949 (stack43)
        %v42962 = vadd.s32 %v42957, %v10 (stack39)
        %v42966 = vadd.s32 %v42927, %v9 (stack39)
        %v42970 = vadd.s32 %v42966, %v42962 (stack39)
        %v42972 = vshll.u32 %v42966, 13 (stack44)
        %v42973 = vshrl.u32 %v42966, 19 (stack45)
        %v42974 = vor.u32 %v42973, %v42972 (stack46)
        %v42975 = vxor.u32 %v42974, %v42970 (stack47)
        %v42978 = vadd.s32 %v42975, %v42970 (stack39)
        %v42980 = vshll.u32 %v42975, 15 (stack44)
        %v42981 = vshrl.u32 %v42975, 17 (stack45)
        %v42982 = vor.u32 %v42981, %v42980 (stack46)
        %v42983 = vxor.u32 %v42982, %v42978 (stack47)
        %v42986 = vadd.s32 %v42983, %v42978 (stack39)
        %v42988 = vshll.u32 %v42983, 26 (stack44)
        %v42989 = vshrl.u32 %v42983, 6 (stack45)
        %v42990 = vor.u32 %v42989, %v42988 (stack46)
        %v42991 = vxor.u32 %v42990, %v42986 (stack47)
        %v42994 = vadd.s32 %v42991, %v42986 (stack39)
        %v42998 = vadd.s32 %v42994, %v9 (stack39)
        %v43000 = vshll.u32 %v42991, 6 (stack44)
        %v43001 = vshrl.u32 %v42991, 26 (stack45)
        %v43002 = vor.u32 %v43001, %v43000 (stack46)
        %v43003 = vxor.u32 %v43002, %v42994 (stack47)
        %v43006 = vadd.s32 %v43003, %v8 (stack39)
        %v43010 = vadd.s32 1, %v43006 (stack39)
        %v43014 = vadd.s32 %v43010, %v42998 (stack39)
        %v43016 = vshll.u32 %v43010, 17 (stack44)
        %v43017 = vshrl.u32 %v43010, 15 (stack45)
        %v43018 = vor.u32 %v43017, %v43016 (stack46)
        %v43019 = vxor.u32 %v43018, %v43014 (stack47)
        %v43022 = vadd.s32 %v43019, %v43014 (stack39)
        %v43024 = vshll.u32 %v43019, 29 (stack44)
        %v43025 = vshrl.u32 %v43019, 3 (stack45)
        %v43026 = vor.u32 %v43025, %v43024 (stack46)
        %v43027 = vxor.u32 %v43026, %v43022 (stack47)
        %v43030 = vadd.s32 %v43027, %v43022 (stack39)
        %v43032 = vshll.u32 %v43027, 16 (stack44)
        %v43033 = vshrl.u32 %v43027, 16 (stack45)
        %v43034 = vor.u32 %v43033, %v43032 (stack46)
        %v43035 = vxor.u32 %v43034, %v43030 (stack47)
        %v43038 = vadd.s32 %v43035, %v43030 (stack39)
        %v43042 = vadd.s32 %v43038, %v8 (stack39)
        %v43044 = vshll.u32 %v43035, 24 (stack44)
        %v43045 = vshrl.u32 %v43035, 8 (stack45)
        %v43046 = vor.u32 %v43045, %v43044 (stack46)
        %v43047 = vxor.u32 %v43046, %v43038 (stack47)
        %v43050 = vadd.s32 %v43047, %v10 (stack39)
        %v43054 = vadd.s32 2, %v43050 (stack39)
        %v43058 = vadd.s32 %v43054, %v43042 (stack39)
        %v43060 = vshll.u32 %v43054, 13 (stack44)
        %v43061 = vshrl.u32 %v43054, 19 (stack45)
        %v43062 = vor.u32 %v43061, %v43060 (stack46)
        %v43063 = vxor.u32 %v43062, %v43058 (stack47)
        %v43066 = vadd.s32 %v43063, %v43058 (stack39)
        %v43068 = vshll.u32 %v43063, 15 (stack44)
        %v43069 = vshrl.u32 %v43063, 17 (stack45)
        %v43070 = vor.u32 %v43069, %v43068 (stack46)
        %v43071 = vxor.u32 %v43070, %v43066 (stack47)
        %v43074 = vadd.s32 %v43071, %v43066 (stack39)
        %v43076 = vshll.u32 %v43071, 26 (stack44)
        %v43077 = vshrl.u32 %v43071, 6 (stack45)
        %v43078 = vor.u32 %v43077, %v43076 (stack46)
        %v43079 = vxor.u32 %v43078, %v43074 (stack47)
        %v43082 = vadd.s32 %v43079, %v43074 (stack39)
        %v43086 = vadd.s32 %v43082, %v10 (stack39)
        %v43088 = vshll.u32 %v43079, 6 (stack44)
        %v43089 = vshrl.u32 %v43079, 26 (stack45)
        %v43090 = vor.u32 %v43089, %v43088 (stack46)
        %v43091 = vxor.u32 %v43090, %v43082 (stack47)
        %v43094 = vadd.s32 %v43091, %v9 (stack39)
        %v43098 = vadd.s32 3, %v43094 (stack39)
        %v43102 = vadd.s32 %v43098, %v43086 (stack39)
        %v43104 = vshll.u32 %v43098, 17 (stack44)
        %v43105 = vshrl.u32 %v43098, 15 (stack45)
        %v43106 = vor.u32 %v43105, %v43104 (stack46)
        %v43107 = vxor.u32 %v43106, %v43102 (stack47)
        %v43110 = vadd.s32 %v43107, %v43102 (stack39)
        %v43112 = vshll.u32 %v43107, 29 (stack44)
        %v43113 = vshrl.u32 %v43107, 3 (stack45)
        %v43114 = vor.u32 %v43113, %v43112 (stack46)
        %v43115 = vxor.u32 %v43114, %v43110 (stack47)
        %v43118 = vadd.s32 %v43115, %v43110 (stack39)
        %v43120 = vshll.u32 %v43115, 16 (stack44)
        %v43121 = vshrl.u32 %v43115, 16 (stack45)
        %v43122 = vor.u32 %v43121, %v43120 (stack46)
        %v43123 = vxor.u32 %v43122, %v43118 (stack47)
        %v43126 = vadd.s32 %v43123, %v43118 (stack39)
        %v43130 = vadd.s32 %v43126, %v9 (stack39)
        %v43132 = vshll.u32 %v43123, 24 (stack44)
        %v43133 = vshrl.u32 %v43123, 8 (stack45)
        %v43134 = vor.u32 %v43133, %v43132 (stack46)
        %v43135 = vxor.u32 %v43134, %v43126 (stack47)
        %v43138 = vadd.s32 %v43135, %v8 (stack39)
        %v43142 = vadd.s32 4, %v43138 (stack39)
        %v43146 = vadd.s32 %v43142, %v43130 (stack39)
        %v43148 = vshll.u32 %v43142, 13 (stack44)
        %v43149 = vshrl.u32 %v43142, 19 (stack45)
        %v43150 = vor.u32 %v43149, %v43148 (stack46)
        %v43151 = vxor.u32 %v43150, %v43146 (stack47)
        %v43154 = vadd.s32 %v43151, %v43146 (stack39)
        %v43156 = vshll.u32 %v43151, 15 (stack44)
        %v43157 = vshrl.u32 %v43151, 17 (stack45)
        %v43158 = vor.u32 %v43157, %v43156 (stack46)
        %v43159 = vxor.u32 %v43158, %v43154 (stack47)
        %v43162 = vadd.s32 %v43159, %v43154 (stack39)
        %v43164 = vshll.u32 %v43159, 26 (stack44)
        %v43165 = vshrl.u32 %v43159, 6 (stack45)
        %v43166 = vor.u32 %v43165, %v43164 (stack46)
        %v43167 = vxor.u32 %v43166, %v43162 (stack47)
        %v43170 = vadd.s32 %v43167, %v43162 (stack39)
        %v43174 = vadd.s32 %v43170, %v8 (stack39)
        %v43176 = vshll.u32 %v43167, 6 (stack44)
        %v43177 = vshrl.u32 %v43167, 26 (stack45)
        %v43178 = vor.u32 %v43177, %v43176 (stack46)
        %v43179 = vxor.u32 %v43178, %v43170 (stack47)
        %v43182 = vadd.s32 %v43179, %v10 (stack39)
        %v43186 = vadd.s32 5, %v43182 (stack39)
        %v43188 = vxor.u32 %v43186, %v43174 (stack47)
        %v43189 = vand.u32.u8 255, %v43188 (stack48)
        %v43190 = vand.u32 65535, %v43189 (stack49)
        %v43191 = vshrl.u32 %v43190, 1 (stack50)
        %v43192 = vor.u32 16256, %v43191 (stack46)
        %v43193 = vand.u32.u16 65535, %v43192 (stack51)
        %v119974 = vadd.low.f32.bf16 -1.0, %v43193 (stack52)
        %v43202 = vmul.f32 2.0, %v119974 (stack53)
        %v43206 = vadd.f32 -0.99609375, %v43202 (stack52)
        %v43210 = vmax.f32 %v43206, -0.99609375 (stack54)
        %v43212 = vand.u32 2147483647, %v43210 (stack55)
        %vm43215 = vcmp.eq.f32.partialorder %v43212, 1.0 (stack56)
        %v43220 = vmul.f32 inf, %v43210 (stack53)
        %v43222 = vxor.u32 2147483648, %v43210 (stack57)
        %v43225 = vmul.f32 %v43222, %v43210 (stack53)
        %v43227 = vadd.f32 1.0, %v43225 (stack58)
        %v43228 = vlog2.pop %v43227 (stack59)
        %v43229 = vmul.f32 0.6931472, %v43228 (stack60)
        %v43230 = vmul.f32 -0.5, %v43225 (stack61)
        %v43231 = vadd.f32 1.0, %v43230 (stack62)
        %v43232 = vmul.f32 %v43231, %v43225 (stack63)
        %v43233 = vand.u32 2147483647, %v43225 (stack64)
        %vm43234 = vcmp.lt.f32.partialorder %v43233, 0.0004427343 (stack65)
        %v43235 = vsel /*vm=*/%vm43234, /*on_true_vy=*/%v43232, /*on_false_vx=*/%v43229 (stack66)
        %v43236 = vxor.u32 2147483648, %v43235 (stack57)
        %vm43239 = vcmp.lt.f32.partialorder %v43236, 5.0 (stack56)
        %v43244 = vsel /*vm=*/%vm43239, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v43248 = vsel /*vm=*/%vm43239, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v43252 = vsel /*vm=*/%vm43239, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v43256 = vsel /*vm=*/%vm43239, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v43260 = vsel /*vm=*/%vm43239, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v43264 = vsel /*vm=*/%vm43239, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v43268 = vsel /*vm=*/%vm43239, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v43272 = vsel /*vm=*/%vm43239, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v43276 = vsel /*vm=*/%vm43239, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v43280 = vadd.f32 -2.5, %v43236 (stack52)
        %v43282 = vrsqrt.pop %v43236 (stack67)
        %v43283 = vmul.f32 %v43282, %v43236 (stack68)
        %vm43284 = vcmp.eq.f32.partialorder %v43236, inf (stack69)
        %v43285 = vsel /*vm=*/%vm43284, /*on_true_vy=*/%v43236, /*on_false_vx=*/%v43283 (stack70)
        %vm43286 = vcmp.eq.f32.partialorder %v43236, 0.0 (stack71)
        %v43287 = vand.u32 2147483648, %v43236 (stack72)
        %v43288 = vsel /*vm=*/%vm43286, /*on_true_vy=*/%v43287, /*on_false_vx=*/%v43285 (stack73)
        %v43291 = vadd.f32 -3.0, %v43288 (stack52)
        %v43295 = vsel /*vm=*/%vm43239, /*on_true_vy=*/%v43280, /*on_false_vx=*/%v43291 (stack43)
        %v43299 = vmul.f32 %v43295, %v43276 (stack53)
        %v43303 = vadd.f32 %v43299, %v43272 (stack52)
        %v43307 = vmul.f32 %v43303, %v43295 (stack53)
        %v43311 = vadd.f32 %v43307, %v43268 (stack52)
        %v43315 = vmul.f32 %v43311, %v43295 (stack53)
        %v43319 = vadd.f32 %v43315, %v43264 (stack52)
        %v43323 = vmul.f32 %v43319, %v43295 (stack53)
        %v43327 = vadd.f32 %v43323, %v43260 (stack52)
        %v43331 = vmul.f32 %v43327, %v43295 (stack53)
        %v43335 = vadd.f32 %v43331, %v43256 (stack52)
        %v43339 = vmul.f32 %v43335, %v43295 (stack53)
        %v43343 = vadd.f32 %v43339, %v43252 (stack52)
        %v43347 = vmul.f32 %v43343, %v43295 (stack53)
        %v43351 = vadd.f32 %v43347, %v43248 (stack52)
        %v43355 = vmul.f32 %v43351, %v43295 (stack53)
        %v43359 = vadd.f32 %v43355, %v43244 (stack52)
        %v43363 = vmul.f32 %v43359, %v43210 (stack53)
        %v43367 = vsel /*vm=*/%vm43215, /*on_true_vy=*/%v43220, /*on_false_vx=*/%v43363 (stack43)
        %v43371 = vmul.f32 1.4140625, %v43367 (stack53)
        %v43374 = vpack.c.bf16 0.0, %v43371 (stack74)
        %119975 = vst [vmem:[%s280 + $0x1ac] sm:$0xf] /*vst_source=*/%v43374 (stack75)
        %v43378 = vadd.s32 %v41531, %v2355 (stack39)
        %v43388 = vadd.s32 %v43378, %v415 (stack39)
        %vm43392 = vcmp.lt.u32.totalorder %v43388, %v43378 (stack42)
        %vm43397 = vcmp.lt.u32.totalorder %v43378, %v2355 (stack42)
        %v43402 = vadd.s32 %v41514, %v2342 (stack39)
        %v43406 = vadd.s32 1, %v43402 (stack39)
        %v43410 = vsel /*vm=*/%vm43397, /*on_true_vy=*/%v43406, /*on_false_vx=*/%v43402 (stack43)
        %v43414 = vadd.s32 1, %v43410 (stack39)
        %v43418 = vsel /*vm=*/%vm43392, /*on_true_vy=*/%v43414, /*on_false_vx=*/%v43410 (stack43)
        %v43423 = vadd.s32 %v43418, %v10 (stack39)
        %v43427 = vadd.s32 %v43388, %v9 (stack39)
        %v43431 = vadd.s32 %v43427, %v43423 (stack39)
        %v43433 = vshll.u32 %v43427, 13 (stack44)
        %v43434 = vshrl.u32 %v43427, 19 (stack45)
        %v43435 = vor.u32 %v43434, %v43433 (stack46)
        %v43436 = vxor.u32 %v43435, %v43431 (stack47)
        %v43439 = vadd.s32 %v43436, %v43431 (stack39)
        %v43441 = vshll.u32 %v43436, 15 (stack44)
        %v43442 = vshrl.u32 %v43436, 17 (stack45)
        %v43443 = vor.u32 %v43442, %v43441 (stack46)
        %v43444 = vxor.u32 %v43443, %v43439 (stack47)
        %v43447 = vadd.s32 %v43444, %v43439 (stack39)
        %v43449 = vshll.u32 %v43444, 26 (stack44)
        %v43450 = vshrl.u32 %v43444, 6 (stack45)
        %v43451 = vor.u32 %v43450, %v43449 (stack46)
        %v43452 = vxor.u32 %v43451, %v43447 (stack47)
        %v43455 = vadd.s32 %v43452, %v43447 (stack39)
        %v43459 = vadd.s32 %v43455, %v9 (stack39)
        %v43461 = vshll.u32 %v43452, 6 (stack44)
        %v43462 = vshrl.u32 %v43452, 26 (stack45)
        %v43463 = vor.u32 %v43462, %v43461 (stack46)
        %v43464 = vxor.u32 %v43463, %v43455 (stack47)
        %v43467 = vadd.s32 %v43464, %v8 (stack39)
        %v43471 = vadd.s32 1, %v43467 (stack39)
        %v43475 = vadd.s32 %v43471, %v43459 (stack39)
        %v43477 = vshll.u32 %v43471, 17 (stack44)
        %v43478 = vshrl.u32 %v43471, 15 (stack45)
        %v43479 = vor.u32 %v43478, %v43477 (stack46)
        %v43480 = vxor.u32 %v43479, %v43475 (stack47)
        %v43483 = vadd.s32 %v43480, %v43475 (stack39)
        %v43485 = vshll.u32 %v43480, 29 (stack44)
        %v43486 = vshrl.u32 %v43480, 3 (stack45)
        %v43487 = vor.u32 %v43486, %v43485 (stack46)
        %v43488 = vxor.u32 %v43487, %v43483 (stack47)
        %v43491 = vadd.s32 %v43488, %v43483 (stack39)
        %v43493 = vshll.u32 %v43488, 16 (stack44)
        %v43494 = vshrl.u32 %v43488, 16 (stack45)
        %v43495 = vor.u32 %v43494, %v43493 (stack46)
        %v43496 = vxor.u32 %v43495, %v43491 (stack47)
        %v43499 = vadd.s32 %v43496, %v43491 (stack39)
        %v43503 = vadd.s32 %v43499, %v8 (stack39)
        %v43505 = vshll.u32 %v43496, 24 (stack44)
        %v43506 = vshrl.u32 %v43496, 8 (stack45)
        %v43507 = vor.u32 %v43506, %v43505 (stack46)
        %v43508 = vxor.u32 %v43507, %v43499 (stack47)
        %v43511 = vadd.s32 %v43508, %v10 (stack39)
        %v43515 = vadd.s32 2, %v43511 (stack39)
        %v43519 = vadd.s32 %v43515, %v43503 (stack39)
        %v43521 = vshll.u32 %v43515, 13 (stack44)
        %v43522 = vshrl.u32 %v43515, 19 (stack45)
        %v43523 = vor.u32 %v43522, %v43521 (stack46)
        %v43524 = vxor.u32 %v43523, %v43519 (stack47)
        %v43527 = vadd.s32 %v43524, %v43519 (stack39)
        %v43529 = vshll.u32 %v43524, 15 (stack44)
        %v43530 = vshrl.u32 %v43524, 17 (stack45)
        %v43531 = vor.u32 %v43530, %v43529 (stack46)
        %v43532 = vxor.u32 %v43531, %v43527 (stack47)
        %v43535 = vadd.s32 %v43532, %v43527 (stack39)
        %v43537 = vshll.u32 %v43532, 26 (stack44)
        %v43538 = vshrl.u32 %v43532, 6 (stack45)
        %v43539 = vor.u32 %v43538, %v43537 (stack46)
        %v43540 = vxor.u32 %v43539, %v43535 (stack47)
        %v43543 = vadd.s32 %v43540, %v43535 (stack39)
        %v43547 = vadd.s32 %v43543, %v10 (stack39)
        %v43549 = vshll.u32 %v43540, 6 (stack44)
        %v43550 = vshrl.u32 %v43540, 26 (stack45)
        %v43551 = vor.u32 %v43550, %v43549 (stack46)
        %v43552 = vxor.u32 %v43551, %v43543 (stack47)
        %v43555 = vadd.s32 %v43552, %v9 (stack39)
        %v43559 = vadd.s32 3, %v43555 (stack39)
        %v43563 = vadd.s32 %v43559, %v43547 (stack39)
        %v43565 = vshll.u32 %v43559, 17 (stack44)
        %v43566 = vshrl.u32 %v43559, 15 (stack45)
        %v43567 = vor.u32 %v43566, %v43565 (stack46)
        %v43568 = vxor.u32 %v43567, %v43563 (stack47)
        %v43571 = vadd.s32 %v43568, %v43563 (stack39)
        %v43573 = vshll.u32 %v43568, 29 (stack44)
        %v43574 = vshrl.u32 %v43568, 3 (stack45)
        %v43575 = vor.u32 %v43574, %v43573 (stack46)
        %v43576 = vxor.u32 %v43575, %v43571 (stack47)
        %v43579 = vadd.s32 %v43576, %v43571 (stack39)
        %v43581 = vshll.u32 %v43576, 16 (stack44)
        %v43582 = vshrl.u32 %v43576, 16 (stack45)
        %v43583 = vor.u32 %v43582, %v43581 (stack46)
        %v43584 = vxor.u32 %v43583, %v43579 (stack47)
        %v43587 = vadd.s32 %v43584, %v43579 (stack39)
        %v43591 = vadd.s32 %v43587, %v9 (stack39)
        %v43593 = vshll.u32 %v43584, 24 (stack44)
        %v43594 = vshrl.u32 %v43584, 8 (stack45)
        %v43595 = vor.u32 %v43594, %v43593 (stack46)
        %v43596 = vxor.u32 %v43595, %v43587 (stack47)
        %v43599 = vadd.s32 %v43596, %v8 (stack39)
        %v43603 = vadd.s32 4, %v43599 (stack39)
        %v43607 = vadd.s32 %v43603, %v43591 (stack39)
        %v43609 = vshll.u32 %v43603, 13 (stack44)
        %v43610 = vshrl.u32 %v43603, 19 (stack45)
        %v43611 = vor.u32 %v43610, %v43609 (stack46)
        %v43612 = vxor.u32 %v43611, %v43607 (stack47)
        %v43615 = vadd.s32 %v43612, %v43607 (stack39)
        %v43617 = vshll.u32 %v43612, 15 (stack44)
        %v43618 = vshrl.u32 %v43612, 17 (stack45)
        %v43619 = vor.u32 %v43618, %v43617 (stack46)
        %v43620 = vxor.u32 %v43619, %v43615 (stack47)
        %v43623 = vadd.s32 %v43620, %v43615 (stack39)
        %v43625 = vshll.u32 %v43620, 26 (stack44)
        %v43626 = vshrl.u32 %v43620, 6 (stack45)
        %v43627 = vor.u32 %v43626, %v43625 (stack46)
        %v43628 = vxor.u32 %v43627, %v43623 (stack47)
        %v43631 = vadd.s32 %v43628, %v43623 (stack39)
        %v43635 = vadd.s32 %v43631, %v8 (stack39)
        %v43637 = vshll.u32 %v43628, 6 (stack44)
        %v43638 = vshrl.u32 %v43628, 26 (stack45)
        %v43639 = vor.u32 %v43638, %v43637 (stack46)
        %v43640 = vxor.u32 %v43639, %v43631 (stack47)
        %v43643 = vadd.s32 %v43640, %v10 (stack39)
        %v43647 = vadd.s32 5, %v43643 (stack39)
        %v43649 = vxor.u32 %v43647, %v43635 (stack47)
        %v43650 = vand.u32.u8 255, %v43649 (stack48)
        %v43651 = vand.u32 65535, %v43650 (stack49)
        %v43652 = vshrl.u32 %v43651, 1 (stack50)
        %v43653 = vor.u32 16256, %v43652 (stack46)
        %v43654 = vand.u32.u16 65535, %v43653 (stack51)
        %v119976 = vadd.low.f32.bf16 -1.0, %v43654 (stack52)
        %v43663 = vmul.f32 2.0, %v119976 (stack53)
        %v43667 = vadd.f32 -0.99609375, %v43663 (stack52)
        %v43671 = vmax.f32 %v43667, -0.99609375 (stack54)
        %v43673 = vand.u32 2147483647, %v43671 (stack55)
        %vm43676 = vcmp.eq.f32.partialorder %v43673, 1.0 (stack56)
        %v43681 = vmul.f32 inf, %v43671 (stack53)
        %v43683 = vxor.u32 2147483648, %v43671 (stack57)
        %v43686 = vmul.f32 %v43683, %v43671 (stack53)
        %v43688 = vadd.f32 1.0, %v43686 (stack58)
        %v43689 = vlog2.pop %v43688 (stack59)
        %v43690 = vmul.f32 0.6931472, %v43689 (stack60)
        %v43691 = vmul.f32 -0.5, %v43686 (stack61)
        %v43692 = vadd.f32 1.0, %v43691 (stack62)
        %v43693 = vmul.f32 %v43692, %v43686 (stack63)
        %v43694 = vand.u32 2147483647, %v43686 (stack64)
        %vm43695 = vcmp.lt.f32.partialorder %v43694, 0.0004427343 (stack65)
        %v43696 = vsel /*vm=*/%vm43695, /*on_true_vy=*/%v43693, /*on_false_vx=*/%v43690 (stack66)
        %v43697 = vxor.u32 2147483648, %v43696 (stack57)
        %vm43700 = vcmp.lt.f32.partialorder %v43697, 5.0 (stack56)
        %v43705 = vsel /*vm=*/%vm43700, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v43709 = vsel /*vm=*/%vm43700, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v43713 = vsel /*vm=*/%vm43700, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v43717 = vsel /*vm=*/%vm43700, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v43721 = vsel /*vm=*/%vm43700, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v43725 = vsel /*vm=*/%vm43700, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v43729 = vsel /*vm=*/%vm43700, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v43733 = vsel /*vm=*/%vm43700, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v43737 = vsel /*vm=*/%vm43700, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v43741 = vadd.f32 -2.5, %v43697 (stack52)
        %v43743 = vrsqrt.pop %v43697 (stack67)
        %v43744 = vmul.f32 %v43743, %v43697 (stack68)
        %vm43745 = vcmp.eq.f32.partialorder %v43697, inf (stack69)
        %v43746 = vsel /*vm=*/%vm43745, /*on_true_vy=*/%v43697, /*on_false_vx=*/%v43744 (stack70)
        %vm43747 = vcmp.eq.f32.partialorder %v43697, 0.0 (stack71)
        %v43748 = vand.u32 2147483648, %v43697 (stack72)
        %v43749 = vsel /*vm=*/%vm43747, /*on_true_vy=*/%v43748, /*on_false_vx=*/%v43746 (stack73)
        %v43752 = vadd.f32 -3.0, %v43749 (stack52)
        %v43756 = vsel /*vm=*/%vm43700, /*on_true_vy=*/%v43741, /*on_false_vx=*/%v43752 (stack43)
        %v43760 = vmul.f32 %v43756, %v43737 (stack53)
        %v43764 = vadd.f32 %v43760, %v43733 (stack52)
        %v43768 = vmul.f32 %v43764, %v43756 (stack53)
        %v43772 = vadd.f32 %v43768, %v43729 (stack52)
        %v43776 = vmul.f32 %v43772, %v43756 (stack53)
        %v43780 = vadd.f32 %v43776, %v43725 (stack52)
        %v43784 = vmul.f32 %v43780, %v43756 (stack53)
        %v43788 = vadd.f32 %v43784, %v43721 (stack52)
        %v43792 = vmul.f32 %v43788, %v43756 (stack53)
        %v43796 = vadd.f32 %v43792, %v43717 (stack52)
        %v43800 = vmul.f32 %v43796, %v43756 (stack53)
        %v43804 = vadd.f32 %v43800, %v43713 (stack52)
        %v43808 = vmul.f32 %v43804, %v43756 (stack53)
        %v43812 = vadd.f32 %v43808, %v43709 (stack52)
        %v43816 = vmul.f32 %v43812, %v43756 (stack53)
        %v43820 = vadd.f32 %v43816, %v43705 (stack52)
        %v43824 = vmul.f32 %v43820, %v43671 (stack53)
        %v43828 = vsel /*vm=*/%vm43676, /*on_true_vy=*/%v43681, /*on_false_vx=*/%v43824 (stack43)
        %v43832 = vmul.f32 1.4140625, %v43828 (stack53)
        %v43835 = vpack.c.bf16 0.0, %v43832 (stack74)
        %119977 = vst [vmem:[%s280 + $0x22c] sm:$0xf] /*vst_source=*/%v43835 (stack75)
        %v43839 = vadd.s32 %v41531, %v2842 (stack39)
        %v43849 = vadd.s32 %v43839, %v415 (stack39)
        %vm43853 = vcmp.lt.u32.totalorder %v43849, %v43839 (stack42)
        %vm43858 = vcmp.lt.u32.totalorder %v43839, %v2842 (stack42)
        %v43863 = vadd.s32 %v41514, %v2829 (stack39)
        %v43867 = vadd.s32 1, %v43863 (stack39)
        %v43871 = vsel /*vm=*/%vm43858, /*on_true_vy=*/%v43867, /*on_false_vx=*/%v43863 (stack43)
        %v43875 = vadd.s32 1, %v43871 (stack39)
        %v43879 = vsel /*vm=*/%vm43853, /*on_true_vy=*/%v43875, /*on_false_vx=*/%v43871 (stack43)
        %v43884 = vadd.s32 %v43879, %v10 (stack39)
        %v43888 = vadd.s32 %v43849, %v9 (stack39)
        %v43892 = vadd.s32 %v43888, %v43884 (stack39)
        %v43894 = vshll.u32 %v43888, 13 (stack44)
        %v43895 = vshrl.u32 %v43888, 19 (stack45)
        %v43896 = vor.u32 %v43895, %v43894 (stack46)
        %v43897 = vxor.u32 %v43896, %v43892 (stack47)
        %v43900 = vadd.s32 %v43897, %v43892 (stack39)
        %v43902 = vshll.u32 %v43897, 15 (stack44)
        %v43903 = vshrl.u32 %v43897, 17 (stack45)
        %v43904 = vor.u32 %v43903, %v43902 (stack46)
        %v43905 = vxor.u32 %v43904, %v43900 (stack47)
        %v43908 = vadd.s32 %v43905, %v43900 (stack39)
        %v43910 = vshll.u32 %v43905, 26 (stack44)
        %v43911 = vshrl.u32 %v43905, 6 (stack45)
        %v43912 = vor.u32 %v43911, %v43910 (stack46)
        %v43913 = vxor.u32 %v43912, %v43908 (stack47)
        %v43916 = vadd.s32 %v43913, %v43908 (stack39)
        %v43920 = vadd.s32 %v43916, %v9 (stack39)
        %v43922 = vshll.u32 %v43913, 6 (stack44)
        %v43923 = vshrl.u32 %v43913, 26 (stack45)
        %v43924 = vor.u32 %v43923, %v43922 (stack46)
        %v43925 = vxor.u32 %v43924, %v43916 (stack47)
        %v43928 = vadd.s32 %v43925, %v8 (stack39)
        %v43932 = vadd.s32 1, %v43928 (stack39)
        %v43936 = vadd.s32 %v43932, %v43920 (stack39)
        %v43938 = vshll.u32 %v43932, 17 (stack44)
        %v43939 = vshrl.u32 %v43932, 15 (stack45)
        %v43940 = vor.u32 %v43939, %v43938 (stack46)
        %v43941 = vxor.u32 %v43940, %v43936 (stack47)
        %v43944 = vadd.s32 %v43941, %v43936 (stack39)
        %v43946 = vshll.u32 %v43941, 29 (stack44)
        %v43947 = vshrl.u32 %v43941, 3 (stack45)
        %v43948 = vor.u32 %v43947, %v43946 (stack46)
        %v43949 = vxor.u32 %v43948, %v43944 (stack47)
        %v43952 = vadd.s32 %v43949, %v43944 (stack39)
        %v43954 = vshll.u32 %v43949, 16 (stack44)
        %v43955 = vshrl.u32 %v43949, 16 (stack45)
        %v43956 = vor.u32 %v43955, %v43954 (stack46)
        %v43957 = vxor.u32 %v43956, %v43952 (stack47)
        %v43960 = vadd.s32 %v43957, %v43952 (stack39)
        %v43964 = vadd.s32 %v43960, %v8 (stack39)
        %v43966 = vshll.u32 %v43957, 24 (stack44)
        %v43967 = vshrl.u32 %v43957, 8 (stack45)
        %v43968 = vor.u32 %v43967, %v43966 (stack46)
        %v43969 = vxor.u32 %v43968, %v43960 (stack47)
        %v43972 = vadd.s32 %v43969, %v10 (stack39)
        %v43976 = vadd.s32 2, %v43972 (stack39)
        %v43980 = vadd.s32 %v43976, %v43964 (stack39)
        %v43982 = vshll.u32 %v43976, 13 (stack44)
        %v43983 = vshrl.u32 %v43976, 19 (stack45)
        %v43984 = vor.u32 %v43983, %v43982 (stack46)
        %v43985 = vxor.u32 %v43984, %v43980 (stack47)
        %v43988 = vadd.s32 %v43985, %v43980 (stack39)
        %v43990 = vshll.u32 %v43985, 15 (stack44)
        %v43991 = vshrl.u32 %v43985, 17 (stack45)
        %v43992 = vor.u32 %v43991, %v43990 (stack46)
        %v43993 = vxor.u32 %v43992, %v43988 (stack47)
        %v43996 = vadd.s32 %v43993, %v43988 (stack39)
        %v43998 = vshll.u32 %v43993, 26 (stack44)
        %v43999 = vshrl.u32 %v43993, 6 (stack45)
        %v44000 = vor.u32 %v43999, %v43998 (stack46)
        %v44001 = vxor.u32 %v44000, %v43996 (stack47)
        %v44004 = vadd.s32 %v44001, %v43996 (stack39)
        %v44008 = vadd.s32 %v44004, %v10 (stack39)
        %v44010 = vshll.u32 %v44001, 6 (stack44)
        %v44011 = vshrl.u32 %v44001, 26 (stack45)
        %v44012 = vor.u32 %v44011, %v44010 (stack46)
        %v44013 = vxor.u32 %v44012, %v44004 (stack47)
        %v44016 = vadd.s32 %v44013, %v9 (stack39)
        %v44020 = vadd.s32 3, %v44016 (stack39)
        %v44024 = vadd.s32 %v44020, %v44008 (stack39)
        %v44026 = vshll.u32 %v44020, 17 (stack44)
        %v44027 = vshrl.u32 %v44020, 15 (stack45)
        %v44028 = vor.u32 %v44027, %v44026 (stack46)
        %v44029 = vxor.u32 %v44028, %v44024 (stack47)
        %v44032 = vadd.s32 %v44029, %v44024 (stack39)
        %v44034 = vshll.u32 %v44029, 29 (stack44)
        %v44035 = vshrl.u32 %v44029, 3 (stack45)
        %v44036 = vor.u32 %v44035, %v44034 (stack46)
        %v44037 = vxor.u32 %v44036, %v44032 (stack47)
        %v44040 = vadd.s32 %v44037, %v44032 (stack39)
        %v44042 = vshll.u32 %v44037, 16 (stack44)
        %v44043 = vshrl.u32 %v44037, 16 (stack45)
        %v44044 = vor.u32 %v44043, %v44042 (stack46)
        %v44045 = vxor.u32 %v44044, %v44040 (stack47)
        %v44048 = vadd.s32 %v44045, %v44040 (stack39)
        %v44052 = vadd.s32 %v44048, %v9 (stack39)
        %v44054 = vshll.u32 %v44045, 24 (stack44)
        %v44055 = vshrl.u32 %v44045, 8 (stack45)
        %v44056 = vor.u32 %v44055, %v44054 (stack46)
        %v44057 = vxor.u32 %v44056, %v44048 (stack47)
        %v44060 = vadd.s32 %v44057, %v8 (stack39)
        %v44064 = vadd.s32 4, %v44060 (stack39)
        %v44068 = vadd.s32 %v44064, %v44052 (stack39)
        %v44070 = vshll.u32 %v44064, 13 (stack44)
        %v44071 = vshrl.u32 %v44064, 19 (stack45)
        %v44072 = vor.u32 %v44071, %v44070 (stack46)
        %v44073 = vxor.u32 %v44072, %v44068 (stack47)
        %v44076 = vadd.s32 %v44073, %v44068 (stack39)
        %v44078 = vshll.u32 %v44073, 15 (stack44)
        %v44079 = vshrl.u32 %v44073, 17 (stack45)
        %v44080 = vor.u32 %v44079, %v44078 (stack46)
        %v44081 = vxor.u32 %v44080, %v44076 (stack47)
        %v44084 = vadd.s32 %v44081, %v44076 (stack39)
        %v44086 = vshll.u32 %v44081, 26 (stack44)
        %v44087 = vshrl.u32 %v44081, 6 (stack45)
        %v44088 = vor.u32 %v44087, %v44086 (stack46)
        %v44089 = vxor.u32 %v44088, %v44084 (stack47)
        %v44092 = vadd.s32 %v44089, %v44084 (stack39)
        %v44096 = vadd.s32 %v44092, %v8 (stack39)
        %v44098 = vshll.u32 %v44089, 6 (stack44)
        %v44099 = vshrl.u32 %v44089, 26 (stack45)
        %v44100 = vor.u32 %v44099, %v44098 (stack46)
        %v44101 = vxor.u32 %v44100, %v44092 (stack47)
        %v44104 = vadd.s32 %v44101, %v10 (stack39)
        %v44108 = vadd.s32 5, %v44104 (stack39)
        %v44110 = vxor.u32 %v44108, %v44096 (stack47)
        %v44111 = vand.u32.u8 255, %v44110 (stack48)
        %v44112 = vand.u32 65535, %v44111 (stack49)
        %v44113 = vshrl.u32 %v44112, 1 (stack50)
        %v44114 = vor.u32 16256, %v44113 (stack46)
        %v44115 = vand.u32.u16 65535, %v44114 (stack51)
        %v119978 = vadd.low.f32.bf16 -1.0, %v44115 (stack52)
        %v44124 = vmul.f32 2.0, %v119978 (stack53)
        %v44128 = vadd.f32 -0.99609375, %v44124 (stack52)
        %v44132 = vmax.f32 %v44128, -0.99609375 (stack54)
        %v44134 = vand.u32 2147483647, %v44132 (stack55)
        %vm44137 = vcmp.eq.f32.partialorder %v44134, 1.0 (stack56)
        %v44142 = vmul.f32 inf, %v44132 (stack53)
        %v44144 = vxor.u32 2147483648, %v44132 (stack57)
        %v44147 = vmul.f32 %v44144, %v44132 (stack53)
        %v44149 = vadd.f32 1.0, %v44147 (stack58)
        %v44150 = vlog2.pop %v44149 (stack59)
        %v44151 = vmul.f32 0.6931472, %v44150 (stack60)
        %v44152 = vmul.f32 -0.5, %v44147 (stack61)
        %v44153 = vadd.f32 1.0, %v44152 (stack62)
        %v44154 = vmul.f32 %v44153, %v44147 (stack63)
        %v44155 = vand.u32 2147483647, %v44147 (stack64)
        %vm44156 = vcmp.lt.f32.partialorder %v44155, 0.0004427343 (stack65)
        %v44157 = vsel /*vm=*/%vm44156, /*on_true_vy=*/%v44154, /*on_false_vx=*/%v44151 (stack66)
        %v44158 = vxor.u32 2147483648, %v44157 (stack57)
        %vm44161 = vcmp.lt.f32.partialorder %v44158, 5.0 (stack56)
        %v44166 = vsel /*vm=*/%vm44161, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v44170 = vsel /*vm=*/%vm44161, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v44174 = vsel /*vm=*/%vm44161, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v44178 = vsel /*vm=*/%vm44161, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v44182 = vsel /*vm=*/%vm44161, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v44186 = vsel /*vm=*/%vm44161, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v44190 = vsel /*vm=*/%vm44161, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v44194 = vsel /*vm=*/%vm44161, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v44198 = vsel /*vm=*/%vm44161, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v44202 = vadd.f32 -2.5, %v44158 (stack52)
        %v44204 = vrsqrt.pop %v44158 (stack67)
        %v44205 = vmul.f32 %v44204, %v44158 (stack68)
        %vm44206 = vcmp.eq.f32.partialorder %v44158, inf (stack69)
        %v44207 = vsel /*vm=*/%vm44206, /*on_true_vy=*/%v44158, /*on_false_vx=*/%v44205 (stack70)
        %vm44208 = vcmp.eq.f32.partialorder %v44158, 0.0 (stack71)
        %v44209 = vand.u32 2147483648, %v44158 (stack72)
        %v44210 = vsel /*vm=*/%vm44208, /*on_true_vy=*/%v44209, /*on_false_vx=*/%v44207 (stack73)
        %v44213 = vadd.f32 -3.0, %v44210 (stack52)
        %v44217 = vsel /*vm=*/%vm44161, /*on_true_vy=*/%v44202, /*on_false_vx=*/%v44213 (stack43)
        %v44221 = vmul.f32 %v44217, %v44198 (stack53)
        %v44225 = vadd.f32 %v44221, %v44194 (stack52)
        %v44229 = vmul.f32 %v44225, %v44217 (stack53)
        %v44233 = vadd.f32 %v44229, %v44190 (stack52)
        %v44237 = vmul.f32 %v44233, %v44217 (stack53)
        %v44241 = vadd.f32 %v44237, %v44186 (stack52)
        %v44245 = vmul.f32 %v44241, %v44217 (stack53)
        %v44249 = vadd.f32 %v44245, %v44182 (stack52)
        %v44253 = vmul.f32 %v44249, %v44217 (stack53)
        %v44257 = vadd.f32 %v44253, %v44178 (stack52)
        %v44261 = vmul.f32 %v44257, %v44217 (stack53)
        %v44265 = vadd.f32 %v44261, %v44174 (stack52)
        %v44269 = vmul.f32 %v44265, %v44217 (stack53)
        %v44273 = vadd.f32 %v44269, %v44170 (stack52)
        %v44277 = vmul.f32 %v44273, %v44217 (stack53)
        %v44281 = vadd.f32 %v44277, %v44166 (stack52)
        %v44285 = vmul.f32 %v44281, %v44132 (stack53)
        %v44289 = vsel /*vm=*/%vm44137, /*on_true_vy=*/%v44142, /*on_false_vx=*/%v44285 (stack43)
        %v44293 = vmul.f32 1.4140625, %v44289 (stack53)
        %v44296 = vpack.c.bf16 0.0, %v44293 (stack74)
        %119979 = vst [vmem:[%s280 + $0x2ac] sm:$0xf] /*vst_source=*/%v44296 (stack75)
        %v44300 = vadd.s32 %v41531, %v3329 (stack39)
        %v44310 = vadd.s32 %v44300, %v415 (stack39)
        %vm44314 = vcmp.lt.u32.totalorder %v44310, %v44300 (stack42)
        %vm44319 = vcmp.lt.u32.totalorder %v44300, %v3329 (stack42)
        %v44324 = vadd.s32 %v41514, %v3316 (stack39)
        %v44328 = vadd.s32 1, %v44324 (stack39)
        %v44332 = vsel /*vm=*/%vm44319, /*on_true_vy=*/%v44328, /*on_false_vx=*/%v44324 (stack43)
        %v44336 = vadd.s32 1, %v44332 (stack39)
        %v44340 = vsel /*vm=*/%vm44314, /*on_true_vy=*/%v44336, /*on_false_vx=*/%v44332 (stack43)
        %v44345 = vadd.s32 %v44340, %v10 (stack39)
        %v44349 = vadd.s32 %v44310, %v9 (stack39)
        %v44353 = vadd.s32 %v44349, %v44345 (stack39)
        %v44355 = vshll.u32 %v44349, 13 (stack44)
        %v44356 = vshrl.u32 %v44349, 19 (stack45)
        %v44357 = vor.u32 %v44356, %v44355 (stack46)
        %v44358 = vxor.u32 %v44357, %v44353 (stack47)
        %v44361 = vadd.s32 %v44358, %v44353 (stack39)
        %v44363 = vshll.u32 %v44358, 15 (stack44)
        %v44364 = vshrl.u32 %v44358, 17 (stack45)
        %v44365 = vor.u32 %v44364, %v44363 (stack46)
        %v44366 = vxor.u32 %v44365, %v44361 (stack47)
        %v44369 = vadd.s32 %v44366, %v44361 (stack39)
        %v44371 = vshll.u32 %v44366, 26 (stack44)
        %v44372 = vshrl.u32 %v44366, 6 (stack45)
        %v44373 = vor.u32 %v44372, %v44371 (stack46)
        %v44374 = vxor.u32 %v44373, %v44369 (stack47)
        %v44377 = vadd.s32 %v44374, %v44369 (stack39)
        %v44381 = vadd.s32 %v44377, %v9 (stack39)
        %v44383 = vshll.u32 %v44374, 6 (stack44)
        %v44384 = vshrl.u32 %v44374, 26 (stack45)
        %v44385 = vor.u32 %v44384, %v44383 (stack46)
        %v44386 = vxor.u32 %v44385, %v44377 (stack47)
        %v44389 = vadd.s32 %v44386, %v8 (stack39)
        %v44393 = vadd.s32 1, %v44389 (stack39)
        %v44397 = vadd.s32 %v44393, %v44381 (stack39)
        %v44399 = vshll.u32 %v44393, 17 (stack44)
        %v44400 = vshrl.u32 %v44393, 15 (stack45)
        %v44401 = vor.u32 %v44400, %v44399 (stack46)
        %v44402 = vxor.u32 %v44401, %v44397 (stack47)
        %v44405 = vadd.s32 %v44402, %v44397 (stack39)
        %v44407 = vshll.u32 %v44402, 29 (stack44)
        %v44408 = vshrl.u32 %v44402, 3 (stack45)
        %v44409 = vor.u32 %v44408, %v44407 (stack46)
        %v44410 = vxor.u32 %v44409, %v44405 (stack47)
        %v44413 = vadd.s32 %v44410, %v44405 (stack39)
        %v44415 = vshll.u32 %v44410, 16 (stack44)
        %v44416 = vshrl.u32 %v44410, 16 (stack45)
        %v44417 = vor.u32 %v44416, %v44415 (stack46)
        %v44418 = vxor.u32 %v44417, %v44413 (stack47)
        %v44421 = vadd.s32 %v44418, %v44413 (stack39)
        %v44425 = vadd.s32 %v44421, %v8 (stack39)
        %v44427 = vshll.u32 %v44418, 24 (stack44)
        %v44428 = vshrl.u32 %v44418, 8 (stack45)
        %v44429 = vor.u32 %v44428, %v44427 (stack46)
        %v44430 = vxor.u32 %v44429, %v44421 (stack47)
        %v44433 = vadd.s32 %v44430, %v10 (stack39)
        %v44437 = vadd.s32 2, %v44433 (stack39)
        %v44441 = vadd.s32 %v44437, %v44425 (stack39)
        %v44443 = vshll.u32 %v44437, 13 (stack44)
        %v44444 = vshrl.u32 %v44437, 19 (stack45)
        %v44445 = vor.u32 %v44444, %v44443 (stack46)
        %v44446 = vxor.u32 %v44445, %v44441 (stack47)
        %v44449 = vadd.s32 %v44446, %v44441 (stack39)
        %v44451 = vshll.u32 %v44446, 15 (stack44)
        %v44452 = vshrl.u32 %v44446, 17 (stack45)
        %v44453 = vor.u32 %v44452, %v44451 (stack46)
        %v44454 = vxor.u32 %v44453, %v44449 (stack47)
        %v44457 = vadd.s32 %v44454, %v44449 (stack39)
        %v44459 = vshll.u32 %v44454, 26 (stack44)
        %v44460 = vshrl.u32 %v44454, 6 (stack45)
        %v44461 = vor.u32 %v44460, %v44459 (stack46)
        %v44462 = vxor.u32 %v44461, %v44457 (stack47)
        %v44465 = vadd.s32 %v44462, %v44457 (stack39)
        %v44469 = vadd.s32 %v44465, %v10 (stack39)
        %v44471 = vshll.u32 %v44462, 6 (stack44)
        %v44472 = vshrl.u32 %v44462, 26 (stack45)
        %v44473 = vor.u32 %v44472, %v44471 (stack46)
        %v44474 = vxor.u32 %v44473, %v44465 (stack47)
        %v44477 = vadd.s32 %v44474, %v9 (stack39)
        %v44481 = vadd.s32 3, %v44477 (stack39)
        %v44485 = vadd.s32 %v44481, %v44469 (stack39)
        %v44487 = vshll.u32 %v44481, 17 (stack44)
        %v44488 = vshrl.u32 %v44481, 15 (stack45)
        %v44489 = vor.u32 %v44488, %v44487 (stack46)
        %v44490 = vxor.u32 %v44489, %v44485 (stack47)
        %v44493 = vadd.s32 %v44490, %v44485 (stack39)
        %v44495 = vshll.u32 %v44490, 29 (stack44)
        %v44496 = vshrl.u32 %v44490, 3 (stack45)
        %v44497 = vor.u32 %v44496, %v44495 (stack46)
        %v44498 = vxor.u32 %v44497, %v44493 (stack47)
        %v44501 = vadd.s32 %v44498, %v44493 (stack39)
        %v44503 = vshll.u32 %v44498, 16 (stack44)
        %v44504 = vshrl.u32 %v44498, 16 (stack45)
        %v44505 = vor.u32 %v44504, %v44503 (stack46)
        %v44506 = vxor.u32 %v44505, %v44501 (stack47)
        %v44509 = vadd.s32 %v44506, %v44501 (stack39)
        %v44513 = vadd.s32 %v44509, %v9 (stack39)
        %v44515 = vshll.u32 %v44506, 24 (stack44)
        %v44516 = vshrl.u32 %v44506, 8 (stack45)
        %v44517 = vor.u32 %v44516, %v44515 (stack46)
        %v44518 = vxor.u32 %v44517, %v44509 (stack47)
        %v44521 = vadd.s32 %v44518, %v8 (stack39)
        %v44525 = vadd.s32 4, %v44521 (stack39)
        %v44529 = vadd.s32 %v44525, %v44513 (stack39)
        %v44531 = vshll.u32 %v44525, 13 (stack44)
        %v44532 = vshrl.u32 %v44525, 19 (stack45)
        %v44533 = vor.u32 %v44532, %v44531 (stack46)
        %v44534 = vxor.u32 %v44533, %v44529 (stack47)
        %v44537 = vadd.s32 %v44534, %v44529 (stack39)
        %v44539 = vshll.u32 %v44534, 15 (stack44)
        %v44540 = vshrl.u32 %v44534, 17 (stack45)
        %v44541 = vor.u32 %v44540, %v44539 (stack46)
        %v44542 = vxor.u32 %v44541, %v44537 (stack47)
        %v44545 = vadd.s32 %v44542, %v44537 (stack39)
        %v44547 = vshll.u32 %v44542, 26 (stack44)
        %v44548 = vshrl.u32 %v44542, 6 (stack45)
        %v44549 = vor.u32 %v44548, %v44547 (stack46)
        %v44550 = vxor.u32 %v44549, %v44545 (stack47)
        %v44553 = vadd.s32 %v44550, %v44545 (stack39)
        %v44557 = vadd.s32 %v44553, %v8 (stack39)
        %v44559 = vshll.u32 %v44550, 6 (stack44)
        %v44560 = vshrl.u32 %v44550, 26 (stack45)
        %v44561 = vor.u32 %v44560, %v44559 (stack46)
        %v44562 = vxor.u32 %v44561, %v44553 (stack47)
        %v44565 = vadd.s32 %v44562, %v10 (stack39)
        %v44569 = vadd.s32 5, %v44565 (stack39)
        %v44571 = vxor.u32 %v44569, %v44557 (stack47)
        %v44572 = vand.u32.u8 255, %v44571 (stack48)
        %v44573 = vand.u32 65535, %v44572 (stack49)
        %v44574 = vshrl.u32 %v44573, 1 (stack50)
        %v44575 = vor.u32 16256, %v44574 (stack46)
        %v44576 = vand.u32.u16 65535, %v44575 (stack51)
        %v119980 = vadd.low.f32.bf16 -1.0, %v44576 (stack52)
        %v44585 = vmul.f32 2.0, %v119980 (stack53)
        %v44589 = vadd.f32 -0.99609375, %v44585 (stack52)
        %v44593 = vmax.f32 %v44589, -0.99609375 (stack54)
        %v44595 = vand.u32 2147483647, %v44593 (stack55)
        %vm44598 = vcmp.eq.f32.partialorder %v44595, 1.0 (stack56)
        %v44603 = vmul.f32 inf, %v44593 (stack53)
        %v44605 = vxor.u32 2147483648, %v44593 (stack57)
        %v44608 = vmul.f32 %v44605, %v44593 (stack53)
        %v44610 = vadd.f32 1.0, %v44608 (stack58)
        %v44611 = vlog2.pop %v44610 (stack59)
        %v44612 = vmul.f32 0.6931472, %v44611 (stack60)
        %v44613 = vmul.f32 -0.5, %v44608 (stack61)
        %v44614 = vadd.f32 1.0, %v44613 (stack62)
        %v44615 = vmul.f32 %v44614, %v44608 (stack63)
        %v44616 = vand.u32 2147483647, %v44608 (stack64)
        %vm44617 = vcmp.lt.f32.partialorder %v44616, 0.0004427343 (stack65)
        %v44618 = vsel /*vm=*/%vm44617, /*on_true_vy=*/%v44615, /*on_false_vx=*/%v44612 (stack66)
        %v44619 = vxor.u32 2147483648, %v44618 (stack57)
        %vm44622 = vcmp.lt.f32.partialorder %v44619, 5.0 (stack56)
        %v44627 = vsel /*vm=*/%vm44622, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v44631 = vsel /*vm=*/%vm44622, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v44635 = vsel /*vm=*/%vm44622, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v44639 = vsel /*vm=*/%vm44622, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v44643 = vsel /*vm=*/%vm44622, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v44647 = vsel /*vm=*/%vm44622, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v44651 = vsel /*vm=*/%vm44622, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v44655 = vsel /*vm=*/%vm44622, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v44659 = vsel /*vm=*/%vm44622, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v44663 = vadd.f32 -2.5, %v44619 (stack52)
        %v44665 = vrsqrt.pop %v44619 (stack67)
        %v44666 = vmul.f32 %v44665, %v44619 (stack68)
        %vm44667 = vcmp.eq.f32.partialorder %v44619, inf (stack69)
        %v44668 = vsel /*vm=*/%vm44667, /*on_true_vy=*/%v44619, /*on_false_vx=*/%v44666 (stack70)
        %vm44669 = vcmp.eq.f32.partialorder %v44619, 0.0 (stack71)
        %v44670 = vand.u32 2147483648, %v44619 (stack72)
        %v44671 = vsel /*vm=*/%vm44669, /*on_true_vy=*/%v44670, /*on_false_vx=*/%v44668 (stack73)
        %v44674 = vadd.f32 -3.0, %v44671 (stack52)
        %v44678 = vsel /*vm=*/%vm44622, /*on_true_vy=*/%v44663, /*on_false_vx=*/%v44674 (stack43)
        %v44682 = vmul.f32 %v44678, %v44659 (stack53)
        %v44686 = vadd.f32 %v44682, %v44655 (stack52)
        %v44690 = vmul.f32 %v44686, %v44678 (stack53)
        %v44694 = vadd.f32 %v44690, %v44651 (stack52)
        %v44698 = vmul.f32 %v44694, %v44678 (stack53)
        %v44702 = vadd.f32 %v44698, %v44647 (stack52)
        %v44706 = vmul.f32 %v44702, %v44678 (stack53)
        %v44710 = vadd.f32 %v44706, %v44643 (stack52)
        %v44714 = vmul.f32 %v44710, %v44678 (stack53)
        %v44718 = vadd.f32 %v44714, %v44639 (stack52)
        %v44722 = vmul.f32 %v44718, %v44678 (stack53)
        %v44726 = vadd.f32 %v44722, %v44635 (stack52)
        %v44730 = vmul.f32 %v44726, %v44678 (stack53)
        %v44734 = vadd.f32 %v44730, %v44631 (stack52)
        %v44738 = vmul.f32 %v44734, %v44678 (stack53)
        %v44742 = vadd.f32 %v44738, %v44627 (stack52)
        %v44746 = vmul.f32 %v44742, %v44593 (stack53)
        %v44750 = vsel /*vm=*/%vm44598, /*on_true_vy=*/%v44603, /*on_false_vx=*/%v44746 (stack43)
        %v44754 = vmul.f32 1.4140625, %v44750 (stack53)
        %v44757 = vpack.c.bf16 0.0, %v44754 (stack74)
        %119981 = vst [vmem:[%s280 + $0x32c] sm:$0xf] /*vst_source=*/%v44757 (stack75)
        %v44761 = vadd.s32 %v41531, %v3816 (stack39)
        %v44771 = vadd.s32 %v44761, %v415 (stack39)
        %vm44775 = vcmp.lt.u32.totalorder %v44771, %v44761 (stack42)
        %vm44780 = vcmp.lt.u32.totalorder %v44761, %v3816 (stack42)
        %v44785 = vadd.s32 %v41514, %v3803 (stack39)
        %v44789 = vadd.s32 1, %v44785 (stack39)
        %v44793 = vsel /*vm=*/%vm44780, /*on_true_vy=*/%v44789, /*on_false_vx=*/%v44785 (stack43)
        %v44797 = vadd.s32 1, %v44793 (stack39)
        %v44801 = vsel /*vm=*/%vm44775, /*on_true_vy=*/%v44797, /*on_false_vx=*/%v44793 (stack43)
        %v44806 = vadd.s32 %v44801, %v10 (stack39)
        %v44810 = vadd.s32 %v44771, %v9 (stack39)
        %v44814 = vadd.s32 %v44810, %v44806 (stack39)
        %v44816 = vshll.u32 %v44810, 13 (stack44)
        %v44817 = vshrl.u32 %v44810, 19 (stack45)
        %v44818 = vor.u32 %v44817, %v44816 (stack46)
        %v44819 = vxor.u32 %v44818, %v44814 (stack47)
        %v44822 = vadd.s32 %v44819, %v44814 (stack39)
        %v44824 = vshll.u32 %v44819, 15 (stack44)
        %v44825 = vshrl.u32 %v44819, 17 (stack45)
        %v44826 = vor.u32 %v44825, %v44824 (stack46)
        %v44827 = vxor.u32 %v44826, %v44822 (stack47)
        %v44830 = vadd.s32 %v44827, %v44822 (stack39)
        %v44832 = vshll.u32 %v44827, 26 (stack44)
        %v44833 = vshrl.u32 %v44827, 6 (stack45)
        %v44834 = vor.u32 %v44833, %v44832 (stack46)
        %v44835 = vxor.u32 %v44834, %v44830 (stack47)
        %v44838 = vadd.s32 %v44835, %v44830 (stack39)
        %v44842 = vadd.s32 %v44838, %v9 (stack39)
        %v44844 = vshll.u32 %v44835, 6 (stack44)
        %v44845 = vshrl.u32 %v44835, 26 (stack45)
        %v44846 = vor.u32 %v44845, %v44844 (stack46)
        %v44847 = vxor.u32 %v44846, %v44838 (stack47)
        %v44850 = vadd.s32 %v44847, %v8 (stack39)
        %v44854 = vadd.s32 1, %v44850 (stack39)
        %v44858 = vadd.s32 %v44854, %v44842 (stack39)
        %v44860 = vshll.u32 %v44854, 17 (stack44)
        %v44861 = vshrl.u32 %v44854, 15 (stack45)
        %v44862 = vor.u32 %v44861, %v44860 (stack46)
        %v44863 = vxor.u32 %v44862, %v44858 (stack47)
        %v44866 = vadd.s32 %v44863, %v44858 (stack39)
        %v44868 = vshll.u32 %v44863, 29 (stack44)
        %v44869 = vshrl.u32 %v44863, 3 (stack45)
        %v44870 = vor.u32 %v44869, %v44868 (stack46)
        %v44871 = vxor.u32 %v44870, %v44866 (stack47)
        %v44874 = vadd.s32 %v44871, %v44866 (stack39)
        %v44876 = vshll.u32 %v44871, 16 (stack44)
        %v44877 = vshrl.u32 %v44871, 16 (stack45)
        %v44878 = vor.u32 %v44877, %v44876 (stack46)
        %v44879 = vxor.u32 %v44878, %v44874 (stack47)
        %v44882 = vadd.s32 %v44879, %v44874 (stack39)
        %v44886 = vadd.s32 %v44882, %v8 (stack39)
        %v44888 = vshll.u32 %v44879, 24 (stack44)
        %v44889 = vshrl.u32 %v44879, 8 (stack45)
        %v44890 = vor.u32 %v44889, %v44888 (stack46)
        %v44891 = vxor.u32 %v44890, %v44882 (stack47)
        %v44894 = vadd.s32 %v44891, %v10 (stack39)
        %v44898 = vadd.s32 2, %v44894 (stack39)
        %v44902 = vadd.s32 %v44898, %v44886 (stack39)
        %v44904 = vshll.u32 %v44898, 13 (stack44)
        %v44905 = vshrl.u32 %v44898, 19 (stack45)
        %v44906 = vor.u32 %v44905, %v44904 (stack46)
        %v44907 = vxor.u32 %v44906, %v44902 (stack47)
        %v44910 = vadd.s32 %v44907, %v44902 (stack39)
        %v44912 = vshll.u32 %v44907, 15 (stack44)
        %v44913 = vshrl.u32 %v44907, 17 (stack45)
        %v44914 = vor.u32 %v44913, %v44912 (stack46)
        %v44915 = vxor.u32 %v44914, %v44910 (stack47)
        %v44918 = vadd.s32 %v44915, %v44910 (stack39)
        %v44920 = vshll.u32 %v44915, 26 (stack44)
        %v44921 = vshrl.u32 %v44915, 6 (stack45)
        %v44922 = vor.u32 %v44921, %v44920 (stack46)
        %v44923 = vxor.u32 %v44922, %v44918 (stack47)
        %v44926 = vadd.s32 %v44923, %v44918 (stack39)
        %v44930 = vadd.s32 %v44926, %v10 (stack39)
        %v44932 = vshll.u32 %v44923, 6 (stack44)
        %v44933 = vshrl.u32 %v44923, 26 (stack45)
        %v44934 = vor.u32 %v44933, %v44932 (stack46)
        %v44935 = vxor.u32 %v44934, %v44926 (stack47)
        %v44938 = vadd.s32 %v44935, %v9 (stack39)
        %v44942 = vadd.s32 3, %v44938 (stack39)
        %v44946 = vadd.s32 %v44942, %v44930 (stack39)
        %v44948 = vshll.u32 %v44942, 17 (stack44)
        %v44949 = vshrl.u32 %v44942, 15 (stack45)
        %v44950 = vor.u32 %v44949, %v44948 (stack46)
        %v44951 = vxor.u32 %v44950, %v44946 (stack47)
        %v44954 = vadd.s32 %v44951, %v44946 (stack39)
        %v44956 = vshll.u32 %v44951, 29 (stack44)
        %v44957 = vshrl.u32 %v44951, 3 (stack45)
        %v44958 = vor.u32 %v44957, %v44956 (stack46)
        %v44959 = vxor.u32 %v44958, %v44954 (stack47)
        %v44962 = vadd.s32 %v44959, %v44954 (stack39)
        %v44964 = vshll.u32 %v44959, 16 (stack44)
        %v44965 = vshrl.u32 %v44959, 16 (stack45)
        %v44966 = vor.u32 %v44965, %v44964 (stack46)
        %v44967 = vxor.u32 %v44966, %v44962 (stack47)
        %v44970 = vadd.s32 %v44967, %v44962 (stack39)
        %v44974 = vadd.s32 %v44970, %v9 (stack39)
        %v44976 = vshll.u32 %v44967, 24 (stack44)
        %v44977 = vshrl.u32 %v44967, 8 (stack45)
        %v44978 = vor.u32 %v44977, %v44976 (stack46)
        %v44979 = vxor.u32 %v44978, %v44970 (stack47)
        %v44982 = vadd.s32 %v44979, %v8 (stack39)
        %v44986 = vadd.s32 4, %v44982 (stack39)
        %v44990 = vadd.s32 %v44986, %v44974 (stack39)
        %v44992 = vshll.u32 %v44986, 13 (stack44)
        %v44993 = vshrl.u32 %v44986, 19 (stack45)
        %v44994 = vor.u32 %v44993, %v44992 (stack46)
        %v44995 = vxor.u32 %v44994, %v44990 (stack47)
        %v44998 = vadd.s32 %v44995, %v44990 (stack39)
        %v45000 = vshll.u32 %v44995, 15 (stack44)
        %v45001 = vshrl.u32 %v44995, 17 (stack45)
        %v45002 = vor.u32 %v45001, %v45000 (stack46)
        %v45003 = vxor.u32 %v45002, %v44998 (stack47)
        %v45006 = vadd.s32 %v45003, %v44998 (stack39)
        %v45008 = vshll.u32 %v45003, 26 (stack44)
        %v45009 = vshrl.u32 %v45003, 6 (stack45)
        %v45010 = vor.u32 %v45009, %v45008 (stack46)
        %v45011 = vxor.u32 %v45010, %v45006 (stack47)
        %v45014 = vadd.s32 %v45011, %v45006 (stack39)
        %v45018 = vadd.s32 %v45014, %v8 (stack39)
        %v45020 = vshll.u32 %v45011, 6 (stack44)
        %v45021 = vshrl.u32 %v45011, 26 (stack45)
        %v45022 = vor.u32 %v45021, %v45020 (stack46)
        %v45023 = vxor.u32 %v45022, %v45014 (stack47)
        %v45026 = vadd.s32 %v45023, %v10 (stack39)
        %v45030 = vadd.s32 5, %v45026 (stack39)
        %v45032 = vxor.u32 %v45030, %v45018 (stack47)
        %v45033 = vand.u32.u8 255, %v45032 (stack48)
        %v45034 = vand.u32 65535, %v45033 (stack49)
        %v45035 = vshrl.u32 %v45034, 1 (stack50)
        %v45036 = vor.u32 16256, %v45035 (stack46)
        %v45037 = vand.u32.u16 65535, %v45036 (stack51)
        %v119982 = vadd.low.f32.bf16 -1.0, %v45037 (stack52)
        %v45046 = vmul.f32 2.0, %v119982 (stack53)
        %v45050 = vadd.f32 -0.99609375, %v45046 (stack52)
        %v45054 = vmax.f32 %v45050, -0.99609375 (stack54)
        %v45056 = vand.u32 2147483647, %v45054 (stack55)
        %vm45059 = vcmp.eq.f32.partialorder %v45056, 1.0 (stack56)
        %v45064 = vmul.f32 inf, %v45054 (stack53)
        %v45066 = vxor.u32 2147483648, %v45054 (stack57)
        %v45069 = vmul.f32 %v45066, %v45054 (stack53)
        %v45071 = vadd.f32 1.0, %v45069 (stack58)
        %v45072 = vlog2.pop %v45071 (stack59)
        %v45073 = vmul.f32 0.6931472, %v45072 (stack60)
        %v45074 = vmul.f32 -0.5, %v45069 (stack61)
        %v45075 = vadd.f32 1.0, %v45074 (stack62)
        %v45076 = vmul.f32 %v45075, %v45069 (stack63)
        %v45077 = vand.u32 2147483647, %v45069 (stack64)
        %vm45078 = vcmp.lt.f32.partialorder %v45077, 0.0004427343 (stack65)
        %v45079 = vsel /*vm=*/%vm45078, /*on_true_vy=*/%v45076, /*on_false_vx=*/%v45073 (stack66)
        %v45080 = vxor.u32 2147483648, %v45079 (stack57)
        %vm45083 = vcmp.lt.f32.partialorder %v45080, 5.0 (stack56)
        %v45088 = vsel /*vm=*/%vm45083, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v45092 = vsel /*vm=*/%vm45083, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v45096 = vsel /*vm=*/%vm45083, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v45100 = vsel /*vm=*/%vm45083, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v45104 = vsel /*vm=*/%vm45083, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v45108 = vsel /*vm=*/%vm45083, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v45112 = vsel /*vm=*/%vm45083, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v45116 = vsel /*vm=*/%vm45083, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v45120 = vsel /*vm=*/%vm45083, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v45124 = vadd.f32 -2.5, %v45080 (stack52)
        %v45126 = vrsqrt.pop %v45080 (stack67)
        %v45127 = vmul.f32 %v45126, %v45080 (stack68)
        %vm45128 = vcmp.eq.f32.partialorder %v45080, inf (stack69)
        %v45129 = vsel /*vm=*/%vm45128, /*on_true_vy=*/%v45080, /*on_false_vx=*/%v45127 (stack70)
        %vm45130 = vcmp.eq.f32.partialorder %v45080, 0.0 (stack71)
        %v45131 = vand.u32 2147483648, %v45080 (stack72)
        %v45132 = vsel /*vm=*/%vm45130, /*on_true_vy=*/%v45131, /*on_false_vx=*/%v45129 (stack73)
        %v45135 = vadd.f32 -3.0, %v45132 (stack52)
        %v45139 = vsel /*vm=*/%vm45083, /*on_true_vy=*/%v45124, /*on_false_vx=*/%v45135 (stack43)
        %v45143 = vmul.f32 %v45139, %v45120 (stack53)
        %v45147 = vadd.f32 %v45143, %v45116 (stack52)
        %v45151 = vmul.f32 %v45147, %v45139 (stack53)
        %v45155 = vadd.f32 %v45151, %v45112 (stack52)
        %v45159 = vmul.f32 %v45155, %v45139 (stack53)
        %v45163 = vadd.f32 %v45159, %v45108 (stack52)
        %v45167 = vmul.f32 %v45163, %v45139 (stack53)
        %v45171 = vadd.f32 %v45167, %v45104 (stack52)
        %v45175 = vmul.f32 %v45171, %v45139 (stack53)
        %v45179 = vadd.f32 %v45175, %v45100 (stack52)
        %v45183 = vmul.f32 %v45179, %v45139 (stack53)
        %v45187 = vadd.f32 %v45183, %v45096 (stack52)
        %v45191 = vmul.f32 %v45187, %v45139 (stack53)
        %v45195 = vadd.f32 %v45191, %v45092 (stack52)
        %v45199 = vmul.f32 %v45195, %v45139 (stack53)
        %v45203 = vadd.f32 %v45199, %v45088 (stack52)
        %v45207 = vmul.f32 %v45203, %v45054 (stack53)
        %v45211 = vsel /*vm=*/%vm45059, /*on_true_vy=*/%v45064, /*on_false_vx=*/%v45207 (stack43)
        %v45215 = vmul.f32 1.4140625, %v45211 (stack53)
        %v45218 = vpack.c.bf16 0.0, %v45215 (stack74)
        %119983 = vst [vmem:[%s280 + $0x3ac] sm:$0xf] /*vst_source=*/%v45218 (stack75)
        %s45220 = sadd.s32 96, %s120390 (stack76)
        %s45221 = sshrl.u32 %s45220, 10 (stack23)
        %p119984 = scmp.gt.s32.totalorder %s45221, 1 (stack24)
        %s45223 = scalar_select /*predicate=*/%p119984, /*on_true=*/1, /*on_false=*/%s45221 (stack25)
        %s45224 = sand.u32 1023, %s45220 /* smod.u32 w/div 1024 */ (stack26)
        %s45225 = sshrl.u32 %s45224, 7 (stack27)
        %s45226 = sand.u32 127, %s45224 /* smod.u32 w/div 128 */ (stack28)
        %s119985 = sshll.u32 %s45223, 3 (stack29)
        %s45228 = scalar_lea.vmem %s3, %s119985 (stack30)
        %s45230 = scalar_lea.vmem %s45228, %s45225 (stack31)
        %v45231 = vld [vmem:[%s45230] ss:$0 sm:$0xff] (stack32)
        %s45232 = sand.u32 255, %s45226 (stack33)
        %s45234 = sor.u32 256, %s45232 (stack34)
        %45235 = vbcast.lane.b32.xlu0 %v45231, %s45234 (stack35)
        %v45236 = vpop.permute.xlu0 %45235 (stack36)
        %s45245 = scalar_lea.vmem %s5, %s119985 (stack30)
        %s45247 = scalar_lea.vmem %s45245, %s45225 (stack31)
        %v45248 = vld [vmem:[%s45247] ss:$0 sm:$0xff] (stack32)
        %45252 = vbcast.lane.b32.xlu0 %v45248, %s45234 (stack35)
        %v45253 = vpop.permute.xlu0 %45252 (stack36)
        %v45256 = vadd.s32 %v45253, %v408 (stack39)
        %v45266 = vadd.s32 %v45256, %v415 (stack39)
        %vm45270 = vcmp.lt.u32.totalorder %v45266, %v45256 (stack42)
        %vm45275 = vcmp.lt.u32.totalorder %v45256, %v408 (stack42)
        %v45280 = vadd.s32 %v45236, %v380 (stack39)
        %v45284 = vadd.s32 1, %v45280 (stack39)
        %v45288 = vsel /*vm=*/%vm45275, /*on_true_vy=*/%v45284, /*on_false_vx=*/%v45280 (stack43)
        %v45292 = vadd.s32 1, %v45288 (stack39)
        %v45296 = vsel /*vm=*/%vm45270, /*on_true_vy=*/%v45292, /*on_false_vx=*/%v45288 (stack43)
        %v45301 = vadd.s32 %v45296, %v10 (stack39)
        %v45305 = vadd.s32 %v45266, %v9 (stack39)
        %v45309 = vadd.s32 %v45305, %v45301 (stack39)
        %v45311 = vshll.u32 %v45305, 13 (stack44)
        %v45312 = vshrl.u32 %v45305, 19 (stack45)
        %v45313 = vor.u32 %v45312, %v45311 (stack46)
        %v45314 = vxor.u32 %v45313, %v45309 (stack47)
        %v45317 = vadd.s32 %v45314, %v45309 (stack39)
        %v45319 = vshll.u32 %v45314, 15 (stack44)
        %v45320 = vshrl.u32 %v45314, 17 (stack45)
        %v45321 = vor.u32 %v45320, %v45319 (stack46)
        %v45322 = vxor.u32 %v45321, %v45317 (stack47)
        %v45325 = vadd.s32 %v45322, %v45317 (stack39)
        %v45327 = vshll.u32 %v45322, 26 (stack44)
        %v45328 = vshrl.u32 %v45322, 6 (stack45)
        %v45329 = vor.u32 %v45328, %v45327 (stack46)
        %v45330 = vxor.u32 %v45329, %v45325 (stack47)
        %v45333 = vadd.s32 %v45330, %v45325 (stack39)
        %v45337 = vadd.s32 %v45333, %v9 (stack39)
        %v45339 = vshll.u32 %v45330, 6 (stack44)
        %v45340 = vshrl.u32 %v45330, 26 (stack45)
        %v45341 = vor.u32 %v45340, %v45339 (stack46)
        %v45342 = vxor.u32 %v45341, %v45333 (stack47)
        %v45345 = vadd.s32 %v45342, %v8 (stack39)
        %v45349 = vadd.s32 1, %v45345 (stack39)
        %v45353 = vadd.s32 %v45349, %v45337 (stack39)
        %v45355 = vshll.u32 %v45349, 17 (stack44)
        %v45356 = vshrl.u32 %v45349, 15 (stack45)
        %v45357 = vor.u32 %v45356, %v45355 (stack46)
        %v45358 = vxor.u32 %v45357, %v45353 (stack47)
        %v45361 = vadd.s32 %v45358, %v45353 (stack39)
        %v45363 = vshll.u32 %v45358, 29 (stack44)
        %v45364 = vshrl.u32 %v45358, 3 (stack45)
        %v45365 = vor.u32 %v45364, %v45363 (stack46)
        %v45366 = vxor.u32 %v45365, %v45361 (stack47)
        %v45369 = vadd.s32 %v45366, %v45361 (stack39)
        %v45371 = vshll.u32 %v45366, 16 (stack44)
        %v45372 = vshrl.u32 %v45366, 16 (stack45)
        %v45373 = vor.u32 %v45372, %v45371 (stack46)
        %v45374 = vxor.u32 %v45373, %v45369 (stack47)
        %v45377 = vadd.s32 %v45374, %v45369 (stack39)
        %v45381 = vadd.s32 %v45377, %v8 (stack39)
        %v45383 = vshll.u32 %v45374, 24 (stack44)
        %v45384 = vshrl.u32 %v45374, 8 (stack45)
        %v45385 = vor.u32 %v45384, %v45383 (stack46)
        %v45386 = vxor.u32 %v45385, %v45377 (stack47)
        %v45389 = vadd.s32 %v45386, %v10 (stack39)
        %v45393 = vadd.s32 2, %v45389 (stack39)
        %v45397 = vadd.s32 %v45393, %v45381 (stack39)
        %v45399 = vshll.u32 %v45393, 13 (stack44)
        %v45400 = vshrl.u32 %v45393, 19 (stack45)
        %v45401 = vor.u32 %v45400, %v45399 (stack46)
        %v45402 = vxor.u32 %v45401, %v45397 (stack47)
        %v45405 = vadd.s32 %v45402, %v45397 (stack39)
        %v45407 = vshll.u32 %v45402, 15 (stack44)
        %v45408 = vshrl.u32 %v45402, 17 (stack45)
        %v45409 = vor.u32 %v45408, %v45407 (stack46)
        %v45410 = vxor.u32 %v45409, %v45405 (stack47)
        %v45413 = vadd.s32 %v45410, %v45405 (stack39)
        %v45415 = vshll.u32 %v45410, 26 (stack44)
        %v45416 = vshrl.u32 %v45410, 6 (stack45)
        %v45417 = vor.u32 %v45416, %v45415 (stack46)
        %v45418 = vxor.u32 %v45417, %v45413 (stack47)
        %v45421 = vadd.s32 %v45418, %v45413 (stack39)
        %v45425 = vadd.s32 %v45421, %v10 (stack39)
        %v45427 = vshll.u32 %v45418, 6 (stack44)
        %v45428 = vshrl.u32 %v45418, 26 (stack45)
        %v45429 = vor.u32 %v45428, %v45427 (stack46)
        %v45430 = vxor.u32 %v45429, %v45421 (stack47)
        %v45433 = vadd.s32 %v45430, %v9 (stack39)
        %v45437 = vadd.s32 3, %v45433 (stack39)
        %v45441 = vadd.s32 %v45437, %v45425 (stack39)
        %v45443 = vshll.u32 %v45437, 17 (stack44)
        %v45444 = vshrl.u32 %v45437, 15 (stack45)
        %v45445 = vor.u32 %v45444, %v45443 (stack46)
        %v45446 = vxor.u32 %v45445, %v45441 (stack47)
        %v45449 = vadd.s32 %v45446, %v45441 (stack39)
        %v45451 = vshll.u32 %v45446, 29 (stack44)
        %v45452 = vshrl.u32 %v45446, 3 (stack45)
        %v45453 = vor.u32 %v45452, %v45451 (stack46)
        %v45454 = vxor.u32 %v45453, %v45449 (stack47)
        %v45457 = vadd.s32 %v45454, %v45449 (stack39)
        %v45459 = vshll.u32 %v45454, 16 (stack44)
        %v45460 = vshrl.u32 %v45454, 16 (stack45)
        %v45461 = vor.u32 %v45460, %v45459 (stack46)
        %v45462 = vxor.u32 %v45461, %v45457 (stack47)
        %v45465 = vadd.s32 %v45462, %v45457 (stack39)
        %v45469 = vadd.s32 %v45465, %v9 (stack39)
        %v45471 = vshll.u32 %v45462, 24 (stack44)
        %v45472 = vshrl.u32 %v45462, 8 (stack45)
        %v45473 = vor.u32 %v45472, %v45471 (stack46)
        %v45474 = vxor.u32 %v45473, %v45465 (stack47)
        %v45477 = vadd.s32 %v45474, %v8 (stack39)
        %v45481 = vadd.s32 4, %v45477 (stack39)
        %v45485 = vadd.s32 %v45481, %v45469 (stack39)
        %v45487 = vshll.u32 %v45481, 13 (stack44)
        %v45488 = vshrl.u32 %v45481, 19 (stack45)
        %v45489 = vor.u32 %v45488, %v45487 (stack46)
        %v45490 = vxor.u32 %v45489, %v45485 (stack47)
        %v45493 = vadd.s32 %v45490, %v45485 (stack39)
        %v45495 = vshll.u32 %v45490, 15 (stack44)
        %v45496 = vshrl.u32 %v45490, 17 (stack45)
        %v45497 = vor.u32 %v45496, %v45495 (stack46)
        %v45498 = vxor.u32 %v45497, %v45493 (stack47)
        %v45501 = vadd.s32 %v45498, %v45493 (stack39)
        %v45503 = vshll.u32 %v45498, 26 (stack44)
        %v45504 = vshrl.u32 %v45498, 6 (stack45)
        %v45505 = vor.u32 %v45504, %v45503 (stack46)
        %v45506 = vxor.u32 %v45505, %v45501 (stack47)
        %v45509 = vadd.s32 %v45506, %v45501 (stack39)
        %v45513 = vadd.s32 %v45509, %v8 (stack39)
        %v45515 = vshll.u32 %v45506, 6 (stack44)
        %v45516 = vshrl.u32 %v45506, 26 (stack45)
        %v45517 = vor.u32 %v45516, %v45515 (stack46)
        %v45518 = vxor.u32 %v45517, %v45509 (stack47)
        %v45521 = vadd.s32 %v45518, %v10 (stack39)
        %v45525 = vadd.s32 5, %v45521 (stack39)
        %v45527 = vxor.u32 %v45525, %v45513 (stack47)
        %v45528 = vand.u32.u8 255, %v45527 (stack48)
        %v45529 = vand.u32 65535, %v45528 (stack49)
        %v45530 = vshrl.u32 %v45529, 1 (stack50)
        %v45531 = vor.u32 16256, %v45530 (stack46)
        %v45532 = vand.u32.u16 65535, %v45531 (stack51)
        %v119988 = vadd.low.f32.bf16 -1.0, %v45532 (stack52)
        %v45541 = vmul.f32 2.0, %v119988 (stack53)
        %v45545 = vadd.f32 -0.99609375, %v45541 (stack52)
        %v45549 = vmax.f32 %v45545, -0.99609375 (stack54)
        %v45551 = vand.u32 2147483647, %v45549 (stack55)
        %vm45554 = vcmp.eq.f32.partialorder %v45551, 1.0 (stack56)
        %v45559 = vmul.f32 inf, %v45549 (stack53)
        %v45561 = vxor.u32 2147483648, %v45549 (stack57)
        %v45564 = vmul.f32 %v45561, %v45549 (stack53)
        %v45566 = vadd.f32 1.0, %v45564 (stack58)
        %v45567 = vlog2.pop %v45566 (stack59)
        %v45568 = vmul.f32 0.6931472, %v45567 (stack60)
        %v45569 = vmul.f32 -0.5, %v45564 (stack61)
        %v45570 = vadd.f32 1.0, %v45569 (stack62)
        %v45571 = vmul.f32 %v45570, %v45564 (stack63)
        %v45572 = vand.u32 2147483647, %v45564 (stack64)
        %vm45573 = vcmp.lt.f32.partialorder %v45572, 0.0004427343 (stack65)
        %v45574 = vsel /*vm=*/%vm45573, /*on_true_vy=*/%v45571, /*on_false_vx=*/%v45568 (stack66)
        %v45575 = vxor.u32 2147483648, %v45574 (stack57)
        %vm45578 = vcmp.lt.f32.partialorder %v45575, 5.0 (stack56)
        %v45583 = vsel /*vm=*/%vm45578, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v45587 = vsel /*vm=*/%vm45578, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v45591 = vsel /*vm=*/%vm45578, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v45595 = vsel /*vm=*/%vm45578, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v45599 = vsel /*vm=*/%vm45578, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v45603 = vsel /*vm=*/%vm45578, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v45607 = vsel /*vm=*/%vm45578, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v45611 = vsel /*vm=*/%vm45578, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v45615 = vsel /*vm=*/%vm45578, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v45619 = vadd.f32 -2.5, %v45575 (stack52)
        %v45621 = vrsqrt.pop %v45575 (stack67)
        %v45622 = vmul.f32 %v45621, %v45575 (stack68)
        %vm45623 = vcmp.eq.f32.partialorder %v45575, inf (stack69)
        %v45624 = vsel /*vm=*/%vm45623, /*on_true_vy=*/%v45575, /*on_false_vx=*/%v45622 (stack70)
        %vm45625 = vcmp.eq.f32.partialorder %v45575, 0.0 (stack71)
        %v45626 = vand.u32 2147483648, %v45575 (stack72)
        %v45627 = vsel /*vm=*/%vm45625, /*on_true_vy=*/%v45626, /*on_false_vx=*/%v45624 (stack73)
        %v45630 = vadd.f32 -3.0, %v45627 (stack52)
        %v45634 = vsel /*vm=*/%vm45578, /*on_true_vy=*/%v45619, /*on_false_vx=*/%v45630 (stack43)
        %v45638 = vmul.f32 %v45634, %v45615 (stack53)
        %v45642 = vadd.f32 %v45638, %v45611 (stack52)
        %v45646 = vmul.f32 %v45642, %v45634 (stack53)
        %v45650 = vadd.f32 %v45646, %v45607 (stack52)
        %v45654 = vmul.f32 %v45650, %v45634 (stack53)
        %v45658 = vadd.f32 %v45654, %v45603 (stack52)
        %v45662 = vmul.f32 %v45658, %v45634 (stack53)
        %v45666 = vadd.f32 %v45662, %v45599 (stack52)
        %v45670 = vmul.f32 %v45666, %v45634 (stack53)
        %v45674 = vadd.f32 %v45670, %v45595 (stack52)
        %v45678 = vmul.f32 %v45674, %v45634 (stack53)
        %v45682 = vadd.f32 %v45678, %v45591 (stack52)
        %v45686 = vmul.f32 %v45682, %v45634 (stack53)
        %v45690 = vadd.f32 %v45686, %v45587 (stack52)
        %v45694 = vmul.f32 %v45690, %v45634 (stack53)
        %v45698 = vadd.f32 %v45694, %v45583 (stack52)
        %v45702 = vmul.f32 %v45698, %v45549 (stack53)
        %v45706 = vsel /*vm=*/%vm45554, /*on_true_vy=*/%v45559, /*on_false_vx=*/%v45702 (stack43)
        %v45710 = vmul.f32 1.4140625, %v45706 (stack53)
        %v45713 = vpack.c.bf16 0.0, %v45710 (stack74)
        %119989 = vst [vmem:[%s280 + $0x30] sm:$0xf] /*vst_source=*/%v45713 (stack75)
        %v45717 = vadd.s32 %v45253, %v894 (stack39)
        %v45727 = vadd.s32 %v45717, %v415 (stack39)
        %vm45731 = vcmp.lt.u32.totalorder %v45727, %v45717 (stack42)
        %vm45736 = vcmp.lt.u32.totalorder %v45717, %v894 (stack42)
        %v45741 = vadd.s32 %v45236, %v881 (stack39)
        %v45745 = vadd.s32 1, %v45741 (stack39)
        %v45749 = vsel /*vm=*/%vm45736, /*on_true_vy=*/%v45745, /*on_false_vx=*/%v45741 (stack43)
        %v45753 = vadd.s32 1, %v45749 (stack39)
        %v45757 = vsel /*vm=*/%vm45731, /*on_true_vy=*/%v45753, /*on_false_vx=*/%v45749 (stack43)
        %v45762 = vadd.s32 %v45757, %v10 (stack39)
        %v45766 = vadd.s32 %v45727, %v9 (stack39)
        %v45770 = vadd.s32 %v45766, %v45762 (stack39)
        %v45772 = vshll.u32 %v45766, 13 (stack44)
        %v45773 = vshrl.u32 %v45766, 19 (stack45)
        %v45774 = vor.u32 %v45773, %v45772 (stack46)
        %v45775 = vxor.u32 %v45774, %v45770 (stack47)
        %v45778 = vadd.s32 %v45775, %v45770 (stack39)
        %v45780 = vshll.u32 %v45775, 15 (stack44)
        %v45781 = vshrl.u32 %v45775, 17 (stack45)
        %v45782 = vor.u32 %v45781, %v45780 (stack46)
        %v45783 = vxor.u32 %v45782, %v45778 (stack47)
        %v45786 = vadd.s32 %v45783, %v45778 (stack39)
        %v45788 = vshll.u32 %v45783, 26 (stack44)
        %v45789 = vshrl.u32 %v45783, 6 (stack45)
        %v45790 = vor.u32 %v45789, %v45788 (stack46)
        %v45791 = vxor.u32 %v45790, %v45786 (stack47)
        %v45794 = vadd.s32 %v45791, %v45786 (stack39)
        %v45798 = vadd.s32 %v45794, %v9 (stack39)
        %v45800 = vshll.u32 %v45791, 6 (stack44)
        %v45801 = vshrl.u32 %v45791, 26 (stack45)
        %v45802 = vor.u32 %v45801, %v45800 (stack46)
        %v45803 = vxor.u32 %v45802, %v45794 (stack47)
        %v45806 = vadd.s32 %v45803, %v8 (stack39)
        %v45810 = vadd.s32 1, %v45806 (stack39)
        %v45814 = vadd.s32 %v45810, %v45798 (stack39)
        %v45816 = vshll.u32 %v45810, 17 (stack44)
        %v45817 = vshrl.u32 %v45810, 15 (stack45)
        %v45818 = vor.u32 %v45817, %v45816 (stack46)
        %v45819 = vxor.u32 %v45818, %v45814 (stack47)
        %v45822 = vadd.s32 %v45819, %v45814 (stack39)
        %v45824 = vshll.u32 %v45819, 29 (stack44)
        %v45825 = vshrl.u32 %v45819, 3 (stack45)
        %v45826 = vor.u32 %v45825, %v45824 (stack46)
        %v45827 = vxor.u32 %v45826, %v45822 (stack47)
        %v45830 = vadd.s32 %v45827, %v45822 (stack39)
        %v45832 = vshll.u32 %v45827, 16 (stack44)
        %v45833 = vshrl.u32 %v45827, 16 (stack45)
        %v45834 = vor.u32 %v45833, %v45832 (stack46)
        %v45835 = vxor.u32 %v45834, %v45830 (stack47)
        %v45838 = vadd.s32 %v45835, %v45830 (stack39)
        %v45842 = vadd.s32 %v45838, %v8 (stack39)
        %v45844 = vshll.u32 %v45835, 24 (stack44)
        %v45845 = vshrl.u32 %v45835, 8 (stack45)
        %v45846 = vor.u32 %v45845, %v45844 (stack46)
        %v45847 = vxor.u32 %v45846, %v45838 (stack47)
        %v45850 = vadd.s32 %v45847, %v10 (stack39)
        %v45854 = vadd.s32 2, %v45850 (stack39)
        %v45858 = vadd.s32 %v45854, %v45842 (stack39)
        %v45860 = vshll.u32 %v45854, 13 (stack44)
        %v45861 = vshrl.u32 %v45854, 19 (stack45)
        %v45862 = vor.u32 %v45861, %v45860 (stack46)
        %v45863 = vxor.u32 %v45862, %v45858 (stack47)
        %v45866 = vadd.s32 %v45863, %v45858 (stack39)
        %v45868 = vshll.u32 %v45863, 15 (stack44)
        %v45869 = vshrl.u32 %v45863, 17 (stack45)
        %v45870 = vor.u32 %v45869, %v45868 (stack46)
        %v45871 = vxor.u32 %v45870, %v45866 (stack47)
        %v45874 = vadd.s32 %v45871, %v45866 (stack39)
        %v45876 = vshll.u32 %v45871, 26 (stack44)
        %v45877 = vshrl.u32 %v45871, 6 (stack45)
        %v45878 = vor.u32 %v45877, %v45876 (stack46)
        %v45879 = vxor.u32 %v45878, %v45874 (stack47)
        %v45882 = vadd.s32 %v45879, %v45874 (stack39)
        %v45886 = vadd.s32 %v45882, %v10 (stack39)
        %v45888 = vshll.u32 %v45879, 6 (stack44)
        %v45889 = vshrl.u32 %v45879, 26 (stack45)
        %v45890 = vor.u32 %v45889, %v45888 (stack46)
        %v45891 = vxor.u32 %v45890, %v45882 (stack47)
        %v45894 = vadd.s32 %v45891, %v9 (stack39)
        %v45898 = vadd.s32 3, %v45894 (stack39)
        %v45902 = vadd.s32 %v45898, %v45886 (stack39)
        %v45904 = vshll.u32 %v45898, 17 (stack44)
        %v45905 = vshrl.u32 %v45898, 15 (stack45)
        %v45906 = vor.u32 %v45905, %v45904 (stack46)
        %v45907 = vxor.u32 %v45906, %v45902 (stack47)
        %v45910 = vadd.s32 %v45907, %v45902 (stack39)
        %v45912 = vshll.u32 %v45907, 29 (stack44)
        %v45913 = vshrl.u32 %v45907, 3 (stack45)
        %v45914 = vor.u32 %v45913, %v45912 (stack46)
        %v45915 = vxor.u32 %v45914, %v45910 (stack47)
        %v45918 = vadd.s32 %v45915, %v45910 (stack39)
        %v45920 = vshll.u32 %v45915, 16 (stack44)
        %v45921 = vshrl.u32 %v45915, 16 (stack45)
        %v45922 = vor.u32 %v45921, %v45920 (stack46)
        %v45923 = vxor.u32 %v45922, %v45918 (stack47)
        %v45926 = vadd.s32 %v45923, %v45918 (stack39)
        %v45930 = vadd.s32 %v45926, %v9 (stack39)
        %v45932 = vshll.u32 %v45923, 24 (stack44)
        %v45933 = vshrl.u32 %v45923, 8 (stack45)
        %v45934 = vor.u32 %v45933, %v45932 (stack46)
        %v45935 = vxor.u32 %v45934, %v45926 (stack47)
        %v45938 = vadd.s32 %v45935, %v8 (stack39)
        %v45942 = vadd.s32 4, %v45938 (stack39)
        %v45946 = vadd.s32 %v45942, %v45930 (stack39)
        %v45948 = vshll.u32 %v45942, 13 (stack44)
        %v45949 = vshrl.u32 %v45942, 19 (stack45)
        %v45950 = vor.u32 %v45949, %v45948 (stack46)
        %v45951 = vxor.u32 %v45950, %v45946 (stack47)
        %v45954 = vadd.s32 %v45951, %v45946 (stack39)
        %v45956 = vshll.u32 %v45951, 15 (stack44)
        %v45957 = vshrl.u32 %v45951, 17 (stack45)
        %v45958 = vor.u32 %v45957, %v45956 (stack46)
        %v45959 = vxor.u32 %v45958, %v45954 (stack47)
        %v45962 = vadd.s32 %v45959, %v45954 (stack39)
        %v45964 = vshll.u32 %v45959, 26 (stack44)
        %v45965 = vshrl.u32 %v45959, 6 (stack45)
        %v45966 = vor.u32 %v45965, %v45964 (stack46)
        %v45967 = vxor.u32 %v45966, %v45962 (stack47)
        %v45970 = vadd.s32 %v45967, %v45962 (stack39)
        %v45974 = vadd.s32 %v45970, %v8 (stack39)
        %v45976 = vshll.u32 %v45967, 6 (stack44)
        %v45977 = vshrl.u32 %v45967, 26 (stack45)
        %v45978 = vor.u32 %v45977, %v45976 (stack46)
        %v45979 = vxor.u32 %v45978, %v45970 (stack47)
        %v45982 = vadd.s32 %v45979, %v10 (stack39)
        %v45986 = vadd.s32 5, %v45982 (stack39)
        %v45988 = vxor.u32 %v45986, %v45974 (stack47)
        %v45989 = vand.u32.u8 255, %v45988 (stack48)
        %v45990 = vand.u32 65535, %v45989 (stack49)
        %v45991 = vshrl.u32 %v45990, 1 (stack50)
        %v45992 = vor.u32 16256, %v45991 (stack46)
        %v45993 = vand.u32.u16 65535, %v45992 (stack51)
        %v119990 = vadd.low.f32.bf16 -1.0, %v45993 (stack52)
        %v46002 = vmul.f32 2.0, %v119990 (stack53)
        %v46006 = vadd.f32 -0.99609375, %v46002 (stack52)
        %v46010 = vmax.f32 %v46006, -0.99609375 (stack54)
        %v46012 = vand.u32 2147483647, %v46010 (stack55)
        %vm46015 = vcmp.eq.f32.partialorder %v46012, 1.0 (stack56)
        %v46020 = vmul.f32 inf, %v46010 (stack53)
        %v46022 = vxor.u32 2147483648, %v46010 (stack57)
        %v46025 = vmul.f32 %v46022, %v46010 (stack53)
        %v46027 = vadd.f32 1.0, %v46025 (stack58)
        %v46028 = vlog2.pop %v46027 (stack59)
        %v46029 = vmul.f32 0.6931472, %v46028 (stack60)
        %v46030 = vmul.f32 -0.5, %v46025 (stack61)
        %v46031 = vadd.f32 1.0, %v46030 (stack62)
        %v46032 = vmul.f32 %v46031, %v46025 (stack63)
        %v46033 = vand.u32 2147483647, %v46025 (stack64)
        %vm46034 = vcmp.lt.f32.partialorder %v46033, 0.0004427343 (stack65)
        %v46035 = vsel /*vm=*/%vm46034, /*on_true_vy=*/%v46032, /*on_false_vx=*/%v46029 (stack66)
        %v46036 = vxor.u32 2147483648, %v46035 (stack57)
        %vm46039 = vcmp.lt.f32.partialorder %v46036, 5.0 (stack56)
        %v46044 = vsel /*vm=*/%vm46039, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v46048 = vsel /*vm=*/%vm46039, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v46052 = vsel /*vm=*/%vm46039, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v46056 = vsel /*vm=*/%vm46039, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v46060 = vsel /*vm=*/%vm46039, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v46064 = vsel /*vm=*/%vm46039, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v46068 = vsel /*vm=*/%vm46039, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v46072 = vsel /*vm=*/%vm46039, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v46076 = vsel /*vm=*/%vm46039, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v46080 = vadd.f32 -2.5, %v46036 (stack52)
        %v46082 = vrsqrt.pop %v46036 (stack67)
        %v46083 = vmul.f32 %v46082, %v46036 (stack68)
        %vm46084 = vcmp.eq.f32.partialorder %v46036, inf (stack69)
        %v46085 = vsel /*vm=*/%vm46084, /*on_true_vy=*/%v46036, /*on_false_vx=*/%v46083 (stack70)
        %vm46086 = vcmp.eq.f32.partialorder %v46036, 0.0 (stack71)
        %v46087 = vand.u32 2147483648, %v46036 (stack72)
        %v46088 = vsel /*vm=*/%vm46086, /*on_true_vy=*/%v46087, /*on_false_vx=*/%v46085 (stack73)
        %v46091 = vadd.f32 -3.0, %v46088 (stack52)
        %v46095 = vsel /*vm=*/%vm46039, /*on_true_vy=*/%v46080, /*on_false_vx=*/%v46091 (stack43)
        %v46099 = vmul.f32 %v46095, %v46076 (stack53)
        %v46103 = vadd.f32 %v46099, %v46072 (stack52)
        %v46107 = vmul.f32 %v46103, %v46095 (stack53)
        %v46111 = vadd.f32 %v46107, %v46068 (stack52)
        %v46115 = vmul.f32 %v46111, %v46095 (stack53)
        %v46119 = vadd.f32 %v46115, %v46064 (stack52)
        %v46123 = vmul.f32 %v46119, %v46095 (stack53)
        %v46127 = vadd.f32 %v46123, %v46060 (stack52)
        %v46131 = vmul.f32 %v46127, %v46095 (stack53)
        %v46135 = vadd.f32 %v46131, %v46056 (stack52)
        %v46139 = vmul.f32 %v46135, %v46095 (stack53)
        %v46143 = vadd.f32 %v46139, %v46052 (stack52)
        %v46147 = vmul.f32 %v46143, %v46095 (stack53)
        %v46151 = vadd.f32 %v46147, %v46048 (stack52)
        %v46155 = vmul.f32 %v46151, %v46095 (stack53)
        %v46159 = vadd.f32 %v46155, %v46044 (stack52)
        %v46163 = vmul.f32 %v46159, %v46010 (stack53)
        %v46167 = vsel /*vm=*/%vm46015, /*on_true_vy=*/%v46020, /*on_false_vx=*/%v46163 (stack43)
        %v46171 = vmul.f32 1.4140625, %v46167 (stack53)
        %v46174 = vpack.c.bf16 0.0, %v46171 (stack74)
        %119991 = vst [vmem:[%s280 + $0xb0] sm:$0xf] /*vst_source=*/%v46174 (stack75)
        %v46178 = vadd.s32 %v45253, %v1381 (stack39)
        %v46188 = vadd.s32 %v46178, %v415 (stack39)
        %vm46192 = vcmp.lt.u32.totalorder %v46188, %v46178 (stack42)
        %vm46197 = vcmp.lt.u32.totalorder %v46178, %v1381 (stack42)
        %v46202 = vadd.s32 %v45236, %v1368 (stack39)
        %v46206 = vadd.s32 1, %v46202 (stack39)
        %v46210 = vsel /*vm=*/%vm46197, /*on_true_vy=*/%v46206, /*on_false_vx=*/%v46202 (stack43)
        %v46214 = vadd.s32 1, %v46210 (stack39)
        %v46218 = vsel /*vm=*/%vm46192, /*on_true_vy=*/%v46214, /*on_false_vx=*/%v46210 (stack43)
        %v46223 = vadd.s32 %v46218, %v10 (stack39)
        %v46227 = vadd.s32 %v46188, %v9 (stack39)
        %v46231 = vadd.s32 %v46227, %v46223 (stack39)
        %v46233 = vshll.u32 %v46227, 13 (stack44)
        %v46234 = vshrl.u32 %v46227, 19 (stack45)
        %v46235 = vor.u32 %v46234, %v46233 (stack46)
        %v46236 = vxor.u32 %v46235, %v46231 (stack47)
        %v46239 = vadd.s32 %v46236, %v46231 (stack39)
        %v46241 = vshll.u32 %v46236, 15 (stack44)
        %v46242 = vshrl.u32 %v46236, 17 (stack45)
        %v46243 = vor.u32 %v46242, %v46241 (stack46)
        %v46244 = vxor.u32 %v46243, %v46239 (stack47)
        %v46247 = vadd.s32 %v46244, %v46239 (stack39)
        %v46249 = vshll.u32 %v46244, 26 (stack44)
        %v46250 = vshrl.u32 %v46244, 6 (stack45)
        %v46251 = vor.u32 %v46250, %v46249 (stack46)
        %v46252 = vxor.u32 %v46251, %v46247 (stack47)
        %v46255 = vadd.s32 %v46252, %v46247 (stack39)
        %v46259 = vadd.s32 %v46255, %v9 (stack39)
        %v46261 = vshll.u32 %v46252, 6 (stack44)
        %v46262 = vshrl.u32 %v46252, 26 (stack45)
        %v46263 = vor.u32 %v46262, %v46261 (stack46)
        %v46264 = vxor.u32 %v46263, %v46255 (stack47)
        %v46267 = vadd.s32 %v46264, %v8 (stack39)
        %v46271 = vadd.s32 1, %v46267 (stack39)
        %v46275 = vadd.s32 %v46271, %v46259 (stack39)
        %v46277 = vshll.u32 %v46271, 17 (stack44)
        %v46278 = vshrl.u32 %v46271, 15 (stack45)
        %v46279 = vor.u32 %v46278, %v46277 (stack46)
        %v46280 = vxor.u32 %v46279, %v46275 (stack47)
        %v46283 = vadd.s32 %v46280, %v46275 (stack39)
        %v46285 = vshll.u32 %v46280, 29 (stack44)
        %v46286 = vshrl.u32 %v46280, 3 (stack45)
        %v46287 = vor.u32 %v46286, %v46285 (stack46)
        %v46288 = vxor.u32 %v46287, %v46283 (stack47)
        %v46291 = vadd.s32 %v46288, %v46283 (stack39)
        %v46293 = vshll.u32 %v46288, 16 (stack44)
        %v46294 = vshrl.u32 %v46288, 16 (stack45)
        %v46295 = vor.u32 %v46294, %v46293 (stack46)
        %v46296 = vxor.u32 %v46295, %v46291 (stack47)
        %v46299 = vadd.s32 %v46296, %v46291 (stack39)
        %v46303 = vadd.s32 %v46299, %v8 (stack39)
        %v46305 = vshll.u32 %v46296, 24 (stack44)
        %v46306 = vshrl.u32 %v46296, 8 (stack45)
        %v46307 = vor.u32 %v46306, %v46305 (stack46)
        %v46308 = vxor.u32 %v46307, %v46299 (stack47)
        %v46311 = vadd.s32 %v46308, %v10 (stack39)
        %v46315 = vadd.s32 2, %v46311 (stack39)
        %v46319 = vadd.s32 %v46315, %v46303 (stack39)
        %v46321 = vshll.u32 %v46315, 13 (stack44)
        %v46322 = vshrl.u32 %v46315, 19 (stack45)
        %v46323 = vor.u32 %v46322, %v46321 (stack46)
        %v46324 = vxor.u32 %v46323, %v46319 (stack47)
        %v46327 = vadd.s32 %v46324, %v46319 (stack39)
        %v46329 = vshll.u32 %v46324, 15 (stack44)
        %v46330 = vshrl.u32 %v46324, 17 (stack45)
        %v46331 = vor.u32 %v46330, %v46329 (stack46)
        %v46332 = vxor.u32 %v46331, %v46327 (stack47)
        %v46335 = vadd.s32 %v46332, %v46327 (stack39)
        %v46337 = vshll.u32 %v46332, 26 (stack44)
        %v46338 = vshrl.u32 %v46332, 6 (stack45)
        %v46339 = vor.u32 %v46338, %v46337 (stack46)
        %v46340 = vxor.u32 %v46339, %v46335 (stack47)
        %v46343 = vadd.s32 %v46340, %v46335 (stack39)
        %v46347 = vadd.s32 %v46343, %v10 (stack39)
        %v46349 = vshll.u32 %v46340, 6 (stack44)
        %v46350 = vshrl.u32 %v46340, 26 (stack45)
        %v46351 = vor.u32 %v46350, %v46349 (stack46)
        %v46352 = vxor.u32 %v46351, %v46343 (stack47)
        %v46355 = vadd.s32 %v46352, %v9 (stack39)
        %v46359 = vadd.s32 3, %v46355 (stack39)
        %v46363 = vadd.s32 %v46359, %v46347 (stack39)
        %v46365 = vshll.u32 %v46359, 17 (stack44)
        %v46366 = vshrl.u32 %v46359, 15 (stack45)
        %v46367 = vor.u32 %v46366, %v46365 (stack46)
        %v46368 = vxor.u32 %v46367, %v46363 (stack47)
        %v46371 = vadd.s32 %v46368, %v46363 (stack39)
        %v46373 = vshll.u32 %v46368, 29 (stack44)
        %v46374 = vshrl.u32 %v46368, 3 (stack45)
        %v46375 = vor.u32 %v46374, %v46373 (stack46)
        %v46376 = vxor.u32 %v46375, %v46371 (stack47)
        %v46379 = vadd.s32 %v46376, %v46371 (stack39)
        %v46381 = vshll.u32 %v46376, 16 (stack44)
        %v46382 = vshrl.u32 %v46376, 16 (stack45)
        %v46383 = vor.u32 %v46382, %v46381 (stack46)
        %v46384 = vxor.u32 %v46383, %v46379 (stack47)
        %v46387 = vadd.s32 %v46384, %v46379 (stack39)
        %v46391 = vadd.s32 %v46387, %v9 (stack39)
        %v46393 = vshll.u32 %v46384, 24 (stack44)
        %v46394 = vshrl.u32 %v46384, 8 (stack45)
        %v46395 = vor.u32 %v46394, %v46393 (stack46)
        %v46396 = vxor.u32 %v46395, %v46387 (stack47)
        %v46399 = vadd.s32 %v46396, %v8 (stack39)
        %v46403 = vadd.s32 4, %v46399 (stack39)
        %v46407 = vadd.s32 %v46403, %v46391 (stack39)
        %v46409 = vshll.u32 %v46403, 13 (stack44)
        %v46410 = vshrl.u32 %v46403, 19 (stack45)
        %v46411 = vor.u32 %v46410, %v46409 (stack46)
        %v46412 = vxor.u32 %v46411, %v46407 (stack47)
        %v46415 = vadd.s32 %v46412, %v46407 (stack39)
        %v46417 = vshll.u32 %v46412, 15 (stack44)
        %v46418 = vshrl.u32 %v46412, 17 (stack45)
        %v46419 = vor.u32 %v46418, %v46417 (stack46)
        %v46420 = vxor.u32 %v46419, %v46415 (stack47)
        %v46423 = vadd.s32 %v46420, %v46415 (stack39)
        %v46425 = vshll.u32 %v46420, 26 (stack44)
        %v46426 = vshrl.u32 %v46420, 6 (stack45)
        %v46427 = vor.u32 %v46426, %v46425 (stack46)
        %v46428 = vxor.u32 %v46427, %v46423 (stack47)
        %v46431 = vadd.s32 %v46428, %v46423 (stack39)
        %v46435 = vadd.s32 %v46431, %v8 (stack39)
        %v46437 = vshll.u32 %v46428, 6 (stack44)
        %v46438 = vshrl.u32 %v46428, 26 (stack45)
        %v46439 = vor.u32 %v46438, %v46437 (stack46)
        %v46440 = vxor.u32 %v46439, %v46431 (stack47)
        %v46443 = vadd.s32 %v46440, %v10 (stack39)
        %v46447 = vadd.s32 5, %v46443 (stack39)
        %v46449 = vxor.u32 %v46447, %v46435 (stack47)
        %v46450 = vand.u32.u8 255, %v46449 (stack48)
        %v46451 = vand.u32 65535, %v46450 (stack49)
        %v46452 = vshrl.u32 %v46451, 1 (stack50)
        %v46453 = vor.u32 16256, %v46452 (stack46)
        %v46454 = vand.u32.u16 65535, %v46453 (stack51)
        %v119992 = vadd.low.f32.bf16 -1.0, %v46454 (stack52)
        %v46463 = vmul.f32 2.0, %v119992 (stack53)
        %v46467 = vadd.f32 -0.99609375, %v46463 (stack52)
        %v46471 = vmax.f32 %v46467, -0.99609375 (stack54)
        %v46473 = vand.u32 2147483647, %v46471 (stack55)
        %vm46476 = vcmp.eq.f32.partialorder %v46473, 1.0 (stack56)
        %v46481 = vmul.f32 inf, %v46471 (stack53)
        %v46483 = vxor.u32 2147483648, %v46471 (stack57)
        %v46486 = vmul.f32 %v46483, %v46471 (stack53)
        %v46488 = vadd.f32 1.0, %v46486 (stack58)
        %v46489 = vlog2.pop %v46488 (stack59)
        %v46490 = vmul.f32 0.6931472, %v46489 (stack60)
        %v46491 = vmul.f32 -0.5, %v46486 (stack61)
        %v46492 = vadd.f32 1.0, %v46491 (stack62)
        %v46493 = vmul.f32 %v46492, %v46486 (stack63)
        %v46494 = vand.u32 2147483647, %v46486 (stack64)
        %vm46495 = vcmp.lt.f32.partialorder %v46494, 0.0004427343 (stack65)
        %v46496 = vsel /*vm=*/%vm46495, /*on_true_vy=*/%v46493, /*on_false_vx=*/%v46490 (stack66)
        %v46497 = vxor.u32 2147483648, %v46496 (stack57)
        %vm46500 = vcmp.lt.f32.partialorder %v46497, 5.0 (stack56)
        %v46505 = vsel /*vm=*/%vm46500, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v46509 = vsel /*vm=*/%vm46500, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v46513 = vsel /*vm=*/%vm46500, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v46517 = vsel /*vm=*/%vm46500, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v46521 = vsel /*vm=*/%vm46500, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v46525 = vsel /*vm=*/%vm46500, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v46529 = vsel /*vm=*/%vm46500, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v46533 = vsel /*vm=*/%vm46500, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v46537 = vsel /*vm=*/%vm46500, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v46541 = vadd.f32 -2.5, %v46497 (stack52)
        %v46543 = vrsqrt.pop %v46497 (stack67)
        %v46544 = vmul.f32 %v46543, %v46497 (stack68)
        %vm46545 = vcmp.eq.f32.partialorder %v46497, inf (stack69)
        %v46546 = vsel /*vm=*/%vm46545, /*on_true_vy=*/%v46497, /*on_false_vx=*/%v46544 (stack70)
        %vm46547 = vcmp.eq.f32.partialorder %v46497, 0.0 (stack71)
        %v46548 = vand.u32 2147483648, %v46497 (stack72)
        %v46549 = vsel /*vm=*/%vm46547, /*on_true_vy=*/%v46548, /*on_false_vx=*/%v46546 (stack73)
        %v46552 = vadd.f32 -3.0, %v46549 (stack52)
        %v46556 = vsel /*vm=*/%vm46500, /*on_true_vy=*/%v46541, /*on_false_vx=*/%v46552 (stack43)
        %v46560 = vmul.f32 %v46556, %v46537 (stack53)
        %v46564 = vadd.f32 %v46560, %v46533 (stack52)
        %v46568 = vmul.f32 %v46564, %v46556 (stack53)
        %v46572 = vadd.f32 %v46568, %v46529 (stack52)
        %v46576 = vmul.f32 %v46572, %v46556 (stack53)
        %v46580 = vadd.f32 %v46576, %v46525 (stack52)
        %v46584 = vmul.f32 %v46580, %v46556 (stack53)
        %v46588 = vadd.f32 %v46584, %v46521 (stack52)
        %v46592 = vmul.f32 %v46588, %v46556 (stack53)
        %v46596 = vadd.f32 %v46592, %v46517 (stack52)
        %v46600 = vmul.f32 %v46596, %v46556 (stack53)
        %v46604 = vadd.f32 %v46600, %v46513 (stack52)
        %v46608 = vmul.f32 %v46604, %v46556 (stack53)
        %v46612 = vadd.f32 %v46608, %v46509 (stack52)
        %v46616 = vmul.f32 %v46612, %v46556 (stack53)
        %v46620 = vadd.f32 %v46616, %v46505 (stack52)
        %v46624 = vmul.f32 %v46620, %v46471 (stack53)
        %v46628 = vsel /*vm=*/%vm46476, /*on_true_vy=*/%v46481, /*on_false_vx=*/%v46624 (stack43)
        %v46632 = vmul.f32 1.4140625, %v46628 (stack53)
        %v46635 = vpack.c.bf16 0.0, %v46632 (stack74)
        %119993 = vst [vmem:[%s280 + $0x130] sm:$0xf] /*vst_source=*/%v46635 (stack75)
        %v46639 = vadd.s32 %v45253, %v1868 (stack39)
        %v46649 = vadd.s32 %v46639, %v415 (stack39)
        %vm46653 = vcmp.lt.u32.totalorder %v46649, %v46639 (stack42)
        %vm46658 = vcmp.lt.u32.totalorder %v46639, %v1868 (stack42)
        %v46663 = vadd.s32 %v45236, %v1855 (stack39)
        %v46667 = vadd.s32 1, %v46663 (stack39)
        %v46671 = vsel /*vm=*/%vm46658, /*on_true_vy=*/%v46667, /*on_false_vx=*/%v46663 (stack43)
        %v46675 = vadd.s32 1, %v46671 (stack39)
        %v46679 = vsel /*vm=*/%vm46653, /*on_true_vy=*/%v46675, /*on_false_vx=*/%v46671 (stack43)
        %v46684 = vadd.s32 %v46679, %v10 (stack39)
        %v46688 = vadd.s32 %v46649, %v9 (stack39)
        %v46692 = vadd.s32 %v46688, %v46684 (stack39)
        %v46694 = vshll.u32 %v46688, 13 (stack44)
        %v46695 = vshrl.u32 %v46688, 19 (stack45)
        %v46696 = vor.u32 %v46695, %v46694 (stack46)
        %v46697 = vxor.u32 %v46696, %v46692 (stack47)
        %v46700 = vadd.s32 %v46697, %v46692 (stack39)
        %v46702 = vshll.u32 %v46697, 15 (stack44)
        %v46703 = vshrl.u32 %v46697, 17 (stack45)
        %v46704 = vor.u32 %v46703, %v46702 (stack46)
        %v46705 = vxor.u32 %v46704, %v46700 (stack47)
        %v46708 = vadd.s32 %v46705, %v46700 (stack39)
        %v46710 = vshll.u32 %v46705, 26 (stack44)
        %v46711 = vshrl.u32 %v46705, 6 (stack45)
        %v46712 = vor.u32 %v46711, %v46710 (stack46)
        %v46713 = vxor.u32 %v46712, %v46708 (stack47)
        %v46716 = vadd.s32 %v46713, %v46708 (stack39)
        %v46720 = vadd.s32 %v46716, %v9 (stack39)
        %v46722 = vshll.u32 %v46713, 6 (stack44)
        %v46723 = vshrl.u32 %v46713, 26 (stack45)
        %v46724 = vor.u32 %v46723, %v46722 (stack46)
        %v46725 = vxor.u32 %v46724, %v46716 (stack47)
        %v46728 = vadd.s32 %v46725, %v8 (stack39)
        %v46732 = vadd.s32 1, %v46728 (stack39)
        %v46736 = vadd.s32 %v46732, %v46720 (stack39)
        %v46738 = vshll.u32 %v46732, 17 (stack44)
        %v46739 = vshrl.u32 %v46732, 15 (stack45)
        %v46740 = vor.u32 %v46739, %v46738 (stack46)
        %v46741 = vxor.u32 %v46740, %v46736 (stack47)
        %v46744 = vadd.s32 %v46741, %v46736 (stack39)
        %v46746 = vshll.u32 %v46741, 29 (stack44)
        %v46747 = vshrl.u32 %v46741, 3 (stack45)
        %v46748 = vor.u32 %v46747, %v46746 (stack46)
        %v46749 = vxor.u32 %v46748, %v46744 (stack47)
        %v46752 = vadd.s32 %v46749, %v46744 (stack39)
        %v46754 = vshll.u32 %v46749, 16 (stack44)
        %v46755 = vshrl.u32 %v46749, 16 (stack45)
        %v46756 = vor.u32 %v46755, %v46754 (stack46)
        %v46757 = vxor.u32 %v46756, %v46752 (stack47)
        %v46760 = vadd.s32 %v46757, %v46752 (stack39)
        %v46764 = vadd.s32 %v46760, %v8 (stack39)
        %v46766 = vshll.u32 %v46757, 24 (stack44)
        %v46767 = vshrl.u32 %v46757, 8 (stack45)
        %v46768 = vor.u32 %v46767, %v46766 (stack46)
        %v46769 = vxor.u32 %v46768, %v46760 (stack47)
        %v46772 = vadd.s32 %v46769, %v10 (stack39)
        %v46776 = vadd.s32 2, %v46772 (stack39)
        %v46780 = vadd.s32 %v46776, %v46764 (stack39)
        %v46782 = vshll.u32 %v46776, 13 (stack44)
        %v46783 = vshrl.u32 %v46776, 19 (stack45)
        %v46784 = vor.u32 %v46783, %v46782 (stack46)
        %v46785 = vxor.u32 %v46784, %v46780 (stack47)
        %v46788 = vadd.s32 %v46785, %v46780 (stack39)
        %v46790 = vshll.u32 %v46785, 15 (stack44)
        %v46791 = vshrl.u32 %v46785, 17 (stack45)
        %v46792 = vor.u32 %v46791, %v46790 (stack46)
        %v46793 = vxor.u32 %v46792, %v46788 (stack47)
        %v46796 = vadd.s32 %v46793, %v46788 (stack39)
        %v46798 = vshll.u32 %v46793, 26 (stack44)
        %v46799 = vshrl.u32 %v46793, 6 (stack45)
        %v46800 = vor.u32 %v46799, %v46798 (stack46)
        %v46801 = vxor.u32 %v46800, %v46796 (stack47)
        %v46804 = vadd.s32 %v46801, %v46796 (stack39)
        %v46808 = vadd.s32 %v46804, %v10 (stack39)
        %v46810 = vshll.u32 %v46801, 6 (stack44)
        %v46811 = vshrl.u32 %v46801, 26 (stack45)
        %v46812 = vor.u32 %v46811, %v46810 (stack46)
        %v46813 = vxor.u32 %v46812, %v46804 (stack47)
        %v46816 = vadd.s32 %v46813, %v9 (stack39)
        %v46820 = vadd.s32 3, %v46816 (stack39)
        %v46824 = vadd.s32 %v46820, %v46808 (stack39)
        %v46826 = vshll.u32 %v46820, 17 (stack44)
        %v46827 = vshrl.u32 %v46820, 15 (stack45)
        %v46828 = vor.u32 %v46827, %v46826 (stack46)
        %v46829 = vxor.u32 %v46828, %v46824 (stack47)
        %v46832 = vadd.s32 %v46829, %v46824 (stack39)
        %v46834 = vshll.u32 %v46829, 29 (stack44)
        %v46835 = vshrl.u32 %v46829, 3 (stack45)
        %v46836 = vor.u32 %v46835, %v46834 (stack46)
        %v46837 = vxor.u32 %v46836, %v46832 (stack47)
        %v46840 = vadd.s32 %v46837, %v46832 (stack39)
        %v46842 = vshll.u32 %v46837, 16 (stack44)
        %v46843 = vshrl.u32 %v46837, 16 (stack45)
        %v46844 = vor.u32 %v46843, %v46842 (stack46)
        %v46845 = vxor.u32 %v46844, %v46840 (stack47)
        %v46848 = vadd.s32 %v46845, %v46840 (stack39)
        %v46852 = vadd.s32 %v46848, %v9 (stack39)
        %v46854 = vshll.u32 %v46845, 24 (stack44)
        %v46855 = vshrl.u32 %v46845, 8 (stack45)
        %v46856 = vor.u32 %v46855, %v46854 (stack46)
        %v46857 = vxor.u32 %v46856, %v46848 (stack47)
        %v46860 = vadd.s32 %v46857, %v8 (stack39)
        %v46864 = vadd.s32 4, %v46860 (stack39)
        %v46868 = vadd.s32 %v46864, %v46852 (stack39)
        %v46870 = vshll.u32 %v46864, 13 (stack44)
        %v46871 = vshrl.u32 %v46864, 19 (stack45)
        %v46872 = vor.u32 %v46871, %v46870 (stack46)
        %v46873 = vxor.u32 %v46872, %v46868 (stack47)
        %v46876 = vadd.s32 %v46873, %v46868 (stack39)
        %v46878 = vshll.u32 %v46873, 15 (stack44)
        %v46879 = vshrl.u32 %v46873, 17 (stack45)
        %v46880 = vor.u32 %v46879, %v46878 (stack46)
        %v46881 = vxor.u32 %v46880, %v46876 (stack47)
        %v46884 = vadd.s32 %v46881, %v46876 (stack39)
        %v46886 = vshll.u32 %v46881, 26 (stack44)
        %v46887 = vshrl.u32 %v46881, 6 (stack45)
        %v46888 = vor.u32 %v46887, %v46886 (stack46)
        %v46889 = vxor.u32 %v46888, %v46884 (stack47)
        %v46892 = vadd.s32 %v46889, %v46884 (stack39)
        %v46896 = vadd.s32 %v46892, %v8 (stack39)
        %v46898 = vshll.u32 %v46889, 6 (stack44)
        %v46899 = vshrl.u32 %v46889, 26 (stack45)
        %v46900 = vor.u32 %v46899, %v46898 (stack46)
        %v46901 = vxor.u32 %v46900, %v46892 (stack47)
        %v46904 = vadd.s32 %v46901, %v10 (stack39)
        %v46908 = vadd.s32 5, %v46904 (stack39)
        %v46910 = vxor.u32 %v46908, %v46896 (stack47)
        %v46911 = vand.u32.u8 255, %v46910 (stack48)
        %v46912 = vand.u32 65535, %v46911 (stack49)
        %v46913 = vshrl.u32 %v46912, 1 (stack50)
        %v46914 = vor.u32 16256, %v46913 (stack46)
        %v46915 = vand.u32.u16 65535, %v46914 (stack51)
        %v119994 = vadd.low.f32.bf16 -1.0, %v46915 (stack52)
        %v46924 = vmul.f32 2.0, %v119994 (stack53)
        %v46928 = vadd.f32 -0.99609375, %v46924 (stack52)
        %v46932 = vmax.f32 %v46928, -0.99609375 (stack54)
        %v46934 = vand.u32 2147483647, %v46932 (stack55)
        %vm46937 = vcmp.eq.f32.partialorder %v46934, 1.0 (stack56)
        %v46942 = vmul.f32 inf, %v46932 (stack53)
        %v46944 = vxor.u32 2147483648, %v46932 (stack57)
        %v46947 = vmul.f32 %v46944, %v46932 (stack53)
        %v46949 = vadd.f32 1.0, %v46947 (stack58)
        %v46950 = vlog2.pop %v46949 (stack59)
        %v46951 = vmul.f32 0.6931472, %v46950 (stack60)
        %v46952 = vmul.f32 -0.5, %v46947 (stack61)
        %v46953 = vadd.f32 1.0, %v46952 (stack62)
        %v46954 = vmul.f32 %v46953, %v46947 (stack63)
        %v46955 = vand.u32 2147483647, %v46947 (stack64)
        %vm46956 = vcmp.lt.f32.partialorder %v46955, 0.0004427343 (stack65)
        %v46957 = vsel /*vm=*/%vm46956, /*on_true_vy=*/%v46954, /*on_false_vx=*/%v46951 (stack66)
        %v46958 = vxor.u32 2147483648, %v46957 (stack57)
        %vm46961 = vcmp.lt.f32.partialorder %v46958, 5.0 (stack56)
        %v46966 = vsel /*vm=*/%vm46961, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v46970 = vsel /*vm=*/%vm46961, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v46974 = vsel /*vm=*/%vm46961, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v46978 = vsel /*vm=*/%vm46961, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v46982 = vsel /*vm=*/%vm46961, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v46986 = vsel /*vm=*/%vm46961, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v46990 = vsel /*vm=*/%vm46961, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v46994 = vsel /*vm=*/%vm46961, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v46998 = vsel /*vm=*/%vm46961, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v47002 = vadd.f32 -2.5, %v46958 (stack52)
        %v47004 = vrsqrt.pop %v46958 (stack67)
        %v47005 = vmul.f32 %v47004, %v46958 (stack68)
        %vm47006 = vcmp.eq.f32.partialorder %v46958, inf (stack69)
        %v47007 = vsel /*vm=*/%vm47006, /*on_true_vy=*/%v46958, /*on_false_vx=*/%v47005 (stack70)
        %vm47008 = vcmp.eq.f32.partialorder %v46958, 0.0 (stack71)
        %v47009 = vand.u32 2147483648, %v46958 (stack72)
        %v47010 = vsel /*vm=*/%vm47008, /*on_true_vy=*/%v47009, /*on_false_vx=*/%v47007 (stack73)
        %v47013 = vadd.f32 -3.0, %v47010 (stack52)
        %v47017 = vsel /*vm=*/%vm46961, /*on_true_vy=*/%v47002, /*on_false_vx=*/%v47013 (stack43)
        %v47021 = vmul.f32 %v47017, %v46998 (stack53)
        %v47025 = vadd.f32 %v47021, %v46994 (stack52)
        %v47029 = vmul.f32 %v47025, %v47017 (stack53)
        %v47033 = vadd.f32 %v47029, %v46990 (stack52)
        %v47037 = vmul.f32 %v47033, %v47017 (stack53)
        %v47041 = vadd.f32 %v47037, %v46986 (stack52)
        %v47045 = vmul.f32 %v47041, %v47017 (stack53)
        %v47049 = vadd.f32 %v47045, %v46982 (stack52)
        %v47053 = vmul.f32 %v47049, %v47017 (stack53)
        %v47057 = vadd.f32 %v47053, %v46978 (stack52)
        %v47061 = vmul.f32 %v47057, %v47017 (stack53)
        %v47065 = vadd.f32 %v47061, %v46974 (stack52)
        %v47069 = vmul.f32 %v47065, %v47017 (stack53)
        %v47073 = vadd.f32 %v47069, %v46970 (stack52)
        %v47077 = vmul.f32 %v47073, %v47017 (stack53)
        %v47081 = vadd.f32 %v47077, %v46966 (stack52)
        %v47085 = vmul.f32 %v47081, %v46932 (stack53)
        %v47089 = vsel /*vm=*/%vm46937, /*on_true_vy=*/%v46942, /*on_false_vx=*/%v47085 (stack43)
        %v47093 = vmul.f32 1.4140625, %v47089 (stack53)
        %v47096 = vpack.c.bf16 0.0, %v47093 (stack74)
        %119995 = vst [vmem:[%s280 + $0x1b0] sm:$0xf] /*vst_source=*/%v47096 (stack75)
        %v47100 = vadd.s32 %v45253, %v2355 (stack39)
        %v47110 = vadd.s32 %v47100, %v415 (stack39)
        %vm47114 = vcmp.lt.u32.totalorder %v47110, %v47100 (stack42)
        %vm47119 = vcmp.lt.u32.totalorder %v47100, %v2355 (stack42)
        %v47124 = vadd.s32 %v45236, %v2342 (stack39)
        %v47128 = vadd.s32 1, %v47124 (stack39)
        %v47132 = vsel /*vm=*/%vm47119, /*on_true_vy=*/%v47128, /*on_false_vx=*/%v47124 (stack43)
        %v47136 = vadd.s32 1, %v47132 (stack39)
        %v47140 = vsel /*vm=*/%vm47114, /*on_true_vy=*/%v47136, /*on_false_vx=*/%v47132 (stack43)
        %v47145 = vadd.s32 %v47140, %v10 (stack39)
        %v47149 = vadd.s32 %v47110, %v9 (stack39)
        %v47153 = vadd.s32 %v47149, %v47145 (stack39)
        %v47155 = vshll.u32 %v47149, 13 (stack44)
        %v47156 = vshrl.u32 %v47149, 19 (stack45)
        %v47157 = vor.u32 %v47156, %v47155 (stack46)
        %v47158 = vxor.u32 %v47157, %v47153 (stack47)
        %v47161 = vadd.s32 %v47158, %v47153 (stack39)
        %v47163 = vshll.u32 %v47158, 15 (stack44)
        %v47164 = vshrl.u32 %v47158, 17 (stack45)
        %v47165 = vor.u32 %v47164, %v47163 (stack46)
        %v47166 = vxor.u32 %v47165, %v47161 (stack47)
        %v47169 = vadd.s32 %v47166, %v47161 (stack39)
        %v47171 = vshll.u32 %v47166, 26 (stack44)
        %v47172 = vshrl.u32 %v47166, 6 (stack45)
        %v47173 = vor.u32 %v47172, %v47171 (stack46)
        %v47174 = vxor.u32 %v47173, %v47169 (stack47)
        %v47177 = vadd.s32 %v47174, %v47169 (stack39)
        %v47181 = vadd.s32 %v47177, %v9 (stack39)
        %v47183 = vshll.u32 %v47174, 6 (stack44)
        %v47184 = vshrl.u32 %v47174, 26 (stack45)
        %v47185 = vor.u32 %v47184, %v47183 (stack46)
        %v47186 = vxor.u32 %v47185, %v47177 (stack47)
        %v47189 = vadd.s32 %v47186, %v8 (stack39)
        %v47193 = vadd.s32 1, %v47189 (stack39)
        %v47197 = vadd.s32 %v47193, %v47181 (stack39)
        %v47199 = vshll.u32 %v47193, 17 (stack44)
        %v47200 = vshrl.u32 %v47193, 15 (stack45)
        %v47201 = vor.u32 %v47200, %v47199 (stack46)
        %v47202 = vxor.u32 %v47201, %v47197 (stack47)
        %v47205 = vadd.s32 %v47202, %v47197 (stack39)
        %v47207 = vshll.u32 %v47202, 29 (stack44)
        %v47208 = vshrl.u32 %v47202, 3 (stack45)
        %v47209 = vor.u32 %v47208, %v47207 (stack46)
        %v47210 = vxor.u32 %v47209, %v47205 (stack47)
        %v47213 = vadd.s32 %v47210, %v47205 (stack39)
        %v47215 = vshll.u32 %v47210, 16 (stack44)
        %v47216 = vshrl.u32 %v47210, 16 (stack45)
        %v47217 = vor.u32 %v47216, %v47215 (stack46)
        %v47218 = vxor.u32 %v47217, %v47213 (stack47)
        %v47221 = vadd.s32 %v47218, %v47213 (stack39)
        %v47225 = vadd.s32 %v47221, %v8 (stack39)
        %v47227 = vshll.u32 %v47218, 24 (stack44)
        %v47228 = vshrl.u32 %v47218, 8 (stack45)
        %v47229 = vor.u32 %v47228, %v47227 (stack46)
        %v47230 = vxor.u32 %v47229, %v47221 (stack47)
        %v47233 = vadd.s32 %v47230, %v10 (stack39)
        %v47237 = vadd.s32 2, %v47233 (stack39)
        %v47241 = vadd.s32 %v47237, %v47225 (stack39)
        %v47243 = vshll.u32 %v47237, 13 (stack44)
        %v47244 = vshrl.u32 %v47237, 19 (stack45)
        %v47245 = vor.u32 %v47244, %v47243 (stack46)
        %v47246 = vxor.u32 %v47245, %v47241 (stack47)
        %v47249 = vadd.s32 %v47246, %v47241 (stack39)
        %v47251 = vshll.u32 %v47246, 15 (stack44)
        %v47252 = vshrl.u32 %v47246, 17 (stack45)
        %v47253 = vor.u32 %v47252, %v47251 (stack46)
        %v47254 = vxor.u32 %v47253, %v47249 (stack47)
        %v47257 = vadd.s32 %v47254, %v47249 (stack39)
        %v47259 = vshll.u32 %v47254, 26 (stack44)
        %v47260 = vshrl.u32 %v47254, 6 (stack45)
        %v47261 = vor.u32 %v47260, %v47259 (stack46)
        %v47262 = vxor.u32 %v47261, %v47257 (stack47)
        %v47265 = vadd.s32 %v47262, %v47257 (stack39)
        %v47269 = vadd.s32 %v47265, %v10 (stack39)
        %v47271 = vshll.u32 %v47262, 6 (stack44)
        %v47272 = vshrl.u32 %v47262, 26 (stack45)
        %v47273 = vor.u32 %v47272, %v47271 (stack46)
        %v47274 = vxor.u32 %v47273, %v47265 (stack47)
        %v47277 = vadd.s32 %v47274, %v9 (stack39)
        %v47281 = vadd.s32 3, %v47277 (stack39)
        %v47285 = vadd.s32 %v47281, %v47269 (stack39)
        %v47287 = vshll.u32 %v47281, 17 (stack44)
        %v47288 = vshrl.u32 %v47281, 15 (stack45)
        %v47289 = vor.u32 %v47288, %v47287 (stack46)
        %v47290 = vxor.u32 %v47289, %v47285 (stack47)
        %v47293 = vadd.s32 %v47290, %v47285 (stack39)
        %v47295 = vshll.u32 %v47290, 29 (stack44)
        %v47296 = vshrl.u32 %v47290, 3 (stack45)
        %v47297 = vor.u32 %v47296, %v47295 (stack46)
        %v47298 = vxor.u32 %v47297, %v47293 (stack47)
        %v47301 = vadd.s32 %v47298, %v47293 (stack39)
        %v47303 = vshll.u32 %v47298, 16 (stack44)
        %v47304 = vshrl.u32 %v47298, 16 (stack45)
        %v47305 = vor.u32 %v47304, %v47303 (stack46)
        %v47306 = vxor.u32 %v47305, %v47301 (stack47)
        %v47309 = vadd.s32 %v47306, %v47301 (stack39)
        %v47313 = vadd.s32 %v47309, %v9 (stack39)
        %v47315 = vshll.u32 %v47306, 24 (stack44)
        %v47316 = vshrl.u32 %v47306, 8 (stack45)
        %v47317 = vor.u32 %v47316, %v47315 (stack46)
        %v47318 = vxor.u32 %v47317, %v47309 (stack47)
        %v47321 = vadd.s32 %v47318, %v8 (stack39)
        %v47325 = vadd.s32 4, %v47321 (stack39)
        %v47329 = vadd.s32 %v47325, %v47313 (stack39)
        %v47331 = vshll.u32 %v47325, 13 (stack44)
        %v47332 = vshrl.u32 %v47325, 19 (stack45)
        %v47333 = vor.u32 %v47332, %v47331 (stack46)
        %v47334 = vxor.u32 %v47333, %v47329 (stack47)
        %v47337 = vadd.s32 %v47334, %v47329 (stack39)
        %v47339 = vshll.u32 %v47334, 15 (stack44)
        %v47340 = vshrl.u32 %v47334, 17 (stack45)
        %v47341 = vor.u32 %v47340, %v47339 (stack46)
        %v47342 = vxor.u32 %v47341, %v47337 (stack47)
        %v47345 = vadd.s32 %v47342, %v47337 (stack39)
        %v47347 = vshll.u32 %v47342, 26 (stack44)
        %v47348 = vshrl.u32 %v47342, 6 (stack45)
        %v47349 = vor.u32 %v47348, %v47347 (stack46)
        %v47350 = vxor.u32 %v47349, %v47345 (stack47)
        %v47353 = vadd.s32 %v47350, %v47345 (stack39)
        %v47357 = vadd.s32 %v47353, %v8 (stack39)
        %v47359 = vshll.u32 %v47350, 6 (stack44)
        %v47360 = vshrl.u32 %v47350, 26 (stack45)
        %v47361 = vor.u32 %v47360, %v47359 (stack46)
        %v47362 = vxor.u32 %v47361, %v47353 (stack47)
        %v47365 = vadd.s32 %v47362, %v10 (stack39)
        %v47369 = vadd.s32 5, %v47365 (stack39)
        %v47371 = vxor.u32 %v47369, %v47357 (stack47)
        %v47372 = vand.u32.u8 255, %v47371 (stack48)
        %v47373 = vand.u32 65535, %v47372 (stack49)
        %v47374 = vshrl.u32 %v47373, 1 (stack50)
        %v47375 = vor.u32 16256, %v47374 (stack46)
        %v47376 = vand.u32.u16 65535, %v47375 (stack51)
        %v119996 = vadd.low.f32.bf16 -1.0, %v47376 (stack52)
        %v47385 = vmul.f32 2.0, %v119996 (stack53)
        %v47389 = vadd.f32 -0.99609375, %v47385 (stack52)
        %v47393 = vmax.f32 %v47389, -0.99609375 (stack54)
        %v47395 = vand.u32 2147483647, %v47393 (stack55)
        %vm47398 = vcmp.eq.f32.partialorder %v47395, 1.0 (stack56)
        %v47403 = vmul.f32 inf, %v47393 (stack53)
        %v47405 = vxor.u32 2147483648, %v47393 (stack57)
        %v47408 = vmul.f32 %v47405, %v47393 (stack53)
        %v47410 = vadd.f32 1.0, %v47408 (stack58)
        %v47411 = vlog2.pop %v47410 (stack59)
        %v47412 = vmul.f32 0.6931472, %v47411 (stack60)
        %v47413 = vmul.f32 -0.5, %v47408 (stack61)
        %v47414 = vadd.f32 1.0, %v47413 (stack62)
        %v47415 = vmul.f32 %v47414, %v47408 (stack63)
        %v47416 = vand.u32 2147483647, %v47408 (stack64)
        %vm47417 = vcmp.lt.f32.partialorder %v47416, 0.0004427343 (stack65)
        %v47418 = vsel /*vm=*/%vm47417, /*on_true_vy=*/%v47415, /*on_false_vx=*/%v47412 (stack66)
        %v47419 = vxor.u32 2147483648, %v47418 (stack57)
        %vm47422 = vcmp.lt.f32.partialorder %v47419, 5.0 (stack56)
        %v47427 = vsel /*vm=*/%vm47422, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v47431 = vsel /*vm=*/%vm47422, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v47435 = vsel /*vm=*/%vm47422, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v47439 = vsel /*vm=*/%vm47422, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v47443 = vsel /*vm=*/%vm47422, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v47447 = vsel /*vm=*/%vm47422, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v47451 = vsel /*vm=*/%vm47422, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v47455 = vsel /*vm=*/%vm47422, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v47459 = vsel /*vm=*/%vm47422, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v47463 = vadd.f32 -2.5, %v47419 (stack52)
        %v47465 = vrsqrt.pop %v47419 (stack67)
        %v47466 = vmul.f32 %v47465, %v47419 (stack68)
        %vm47467 = vcmp.eq.f32.partialorder %v47419, inf (stack69)
        %v47468 = vsel /*vm=*/%vm47467, /*on_true_vy=*/%v47419, /*on_false_vx=*/%v47466 (stack70)
        %vm47469 = vcmp.eq.f32.partialorder %v47419, 0.0 (stack71)
        %v47470 = vand.u32 2147483648, %v47419 (stack72)
        %v47471 = vsel /*vm=*/%vm47469, /*on_true_vy=*/%v47470, /*on_false_vx=*/%v47468 (stack73)
        %v47474 = vadd.f32 -3.0, %v47471 (stack52)
        %v47478 = vsel /*vm=*/%vm47422, /*on_true_vy=*/%v47463, /*on_false_vx=*/%v47474 (stack43)
        %v47482 = vmul.f32 %v47478, %v47459 (stack53)
        %v47486 = vadd.f32 %v47482, %v47455 (stack52)
        %v47490 = vmul.f32 %v47486, %v47478 (stack53)
        %v47494 = vadd.f32 %v47490, %v47451 (stack52)
        %v47498 = vmul.f32 %v47494, %v47478 (stack53)
        %v47502 = vadd.f32 %v47498, %v47447 (stack52)
        %v47506 = vmul.f32 %v47502, %v47478 (stack53)
        %v47510 = vadd.f32 %v47506, %v47443 (stack52)
        %v47514 = vmul.f32 %v47510, %v47478 (stack53)
        %v47518 = vadd.f32 %v47514, %v47439 (stack52)
        %v47522 = vmul.f32 %v47518, %v47478 (stack53)
        %v47526 = vadd.f32 %v47522, %v47435 (stack52)
        %v47530 = vmul.f32 %v47526, %v47478 (stack53)
        %v47534 = vadd.f32 %v47530, %v47431 (stack52)
        %v47538 = vmul.f32 %v47534, %v47478 (stack53)
        %v47542 = vadd.f32 %v47538, %v47427 (stack52)
        %v47546 = vmul.f32 %v47542, %v47393 (stack53)
        %v47550 = vsel /*vm=*/%vm47398, /*on_true_vy=*/%v47403, /*on_false_vx=*/%v47546 (stack43)
        %v47554 = vmul.f32 1.4140625, %v47550 (stack53)
        %v47557 = vpack.c.bf16 0.0, %v47554 (stack74)
        %119997 = vst [vmem:[%s280 + $0x230] sm:$0xf] /*vst_source=*/%v47557 (stack75)
        %v47561 = vadd.s32 %v45253, %v2842 (stack39)
        %v47571 = vadd.s32 %v47561, %v415 (stack39)
        %vm47575 = vcmp.lt.u32.totalorder %v47571, %v47561 (stack42)
        %vm47580 = vcmp.lt.u32.totalorder %v47561, %v2842 (stack42)
        %v47585 = vadd.s32 %v45236, %v2829 (stack39)
        %v47589 = vadd.s32 1, %v47585 (stack39)
        %v47593 = vsel /*vm=*/%vm47580, /*on_true_vy=*/%v47589, /*on_false_vx=*/%v47585 (stack43)
        %v47597 = vadd.s32 1, %v47593 (stack39)
        %v47601 = vsel /*vm=*/%vm47575, /*on_true_vy=*/%v47597, /*on_false_vx=*/%v47593 (stack43)
        %v47606 = vadd.s32 %v47601, %v10 (stack39)
        %v47610 = vadd.s32 %v47571, %v9 (stack39)
        %v47614 = vadd.s32 %v47610, %v47606 (stack39)
        %v47616 = vshll.u32 %v47610, 13 (stack44)
        %v47617 = vshrl.u32 %v47610, 19 (stack45)
        %v47618 = vor.u32 %v47617, %v47616 (stack46)
        %v47619 = vxor.u32 %v47618, %v47614 (stack47)
        %v47622 = vadd.s32 %v47619, %v47614 (stack39)
        %v47624 = vshll.u32 %v47619, 15 (stack44)
        %v47625 = vshrl.u32 %v47619, 17 (stack45)
        %v47626 = vor.u32 %v47625, %v47624 (stack46)
        %v47627 = vxor.u32 %v47626, %v47622 (stack47)
        %v47630 = vadd.s32 %v47627, %v47622 (stack39)
        %v47632 = vshll.u32 %v47627, 26 (stack44)
        %v47633 = vshrl.u32 %v47627, 6 (stack45)
        %v47634 = vor.u32 %v47633, %v47632 (stack46)
        %v47635 = vxor.u32 %v47634, %v47630 (stack47)
        %v47638 = vadd.s32 %v47635, %v47630 (stack39)
        %v47642 = vadd.s32 %v47638, %v9 (stack39)
        %v47644 = vshll.u32 %v47635, 6 (stack44)
        %v47645 = vshrl.u32 %v47635, 26 (stack45)
        %v47646 = vor.u32 %v47645, %v47644 (stack46)
        %v47647 = vxor.u32 %v47646, %v47638 (stack47)
        %v47650 = vadd.s32 %v47647, %v8 (stack39)
        %v47654 = vadd.s32 1, %v47650 (stack39)
        %v47658 = vadd.s32 %v47654, %v47642 (stack39)
        %v47660 = vshll.u32 %v47654, 17 (stack44)
        %v47661 = vshrl.u32 %v47654, 15 (stack45)
        %v47662 = vor.u32 %v47661, %v47660 (stack46)
        %v47663 = vxor.u32 %v47662, %v47658 (stack47)
        %v47666 = vadd.s32 %v47663, %v47658 (stack39)
        %v47668 = vshll.u32 %v47663, 29 (stack44)
        %v47669 = vshrl.u32 %v47663, 3 (stack45)
        %v47670 = vor.u32 %v47669, %v47668 (stack46)
        %v47671 = vxor.u32 %v47670, %v47666 (stack47)
        %v47674 = vadd.s32 %v47671, %v47666 (stack39)
        %v47676 = vshll.u32 %v47671, 16 (stack44)
        %v47677 = vshrl.u32 %v47671, 16 (stack45)
        %v47678 = vor.u32 %v47677, %v47676 (stack46)
        %v47679 = vxor.u32 %v47678, %v47674 (stack47)
        %v47682 = vadd.s32 %v47679, %v47674 (stack39)
        %v47686 = vadd.s32 %v47682, %v8 (stack39)
        %v47688 = vshll.u32 %v47679, 24 (stack44)
        %v47689 = vshrl.u32 %v47679, 8 (stack45)
        %v47690 = vor.u32 %v47689, %v47688 (stack46)
        %v47691 = vxor.u32 %v47690, %v47682 (stack47)
        %v47694 = vadd.s32 %v47691, %v10 (stack39)
        %v47698 = vadd.s32 2, %v47694 (stack39)
        %v47702 = vadd.s32 %v47698, %v47686 (stack39)
        %v47704 = vshll.u32 %v47698, 13 (stack44)
        %v47705 = vshrl.u32 %v47698, 19 (stack45)
        %v47706 = vor.u32 %v47705, %v47704 (stack46)
        %v47707 = vxor.u32 %v47706, %v47702 (stack47)
        %v47710 = vadd.s32 %v47707, %v47702 (stack39)
        %v47712 = vshll.u32 %v47707, 15 (stack44)
        %v47713 = vshrl.u32 %v47707, 17 (stack45)
        %v47714 = vor.u32 %v47713, %v47712 (stack46)
        %v47715 = vxor.u32 %v47714, %v47710 (stack47)
        %v47718 = vadd.s32 %v47715, %v47710 (stack39)
        %v47720 = vshll.u32 %v47715, 26 (stack44)
        %v47721 = vshrl.u32 %v47715, 6 (stack45)
        %v47722 = vor.u32 %v47721, %v47720 (stack46)
        %v47723 = vxor.u32 %v47722, %v47718 (stack47)
        %v47726 = vadd.s32 %v47723, %v47718 (stack39)
        %v47730 = vadd.s32 %v47726, %v10 (stack39)
        %v47732 = vshll.u32 %v47723, 6 (stack44)
        %v47733 = vshrl.u32 %v47723, 26 (stack45)
        %v47734 = vor.u32 %v47733, %v47732 (stack46)
        %v47735 = vxor.u32 %v47734, %v47726 (stack47)
        %v47738 = vadd.s32 %v47735, %v9 (stack39)
        %v47742 = vadd.s32 3, %v47738 (stack39)
        %v47746 = vadd.s32 %v47742, %v47730 (stack39)
        %v47748 = vshll.u32 %v47742, 17 (stack44)
        %v47749 = vshrl.u32 %v47742, 15 (stack45)
        %v47750 = vor.u32 %v47749, %v47748 (stack46)
        %v47751 = vxor.u32 %v47750, %v47746 (stack47)
        %v47754 = vadd.s32 %v47751, %v47746 (stack39)
        %v47756 = vshll.u32 %v47751, 29 (stack44)
        %v47757 = vshrl.u32 %v47751, 3 (stack45)
        %v47758 = vor.u32 %v47757, %v47756 (stack46)
        %v47759 = vxor.u32 %v47758, %v47754 (stack47)
        %v47762 = vadd.s32 %v47759, %v47754 (stack39)
        %v47764 = vshll.u32 %v47759, 16 (stack44)
        %v47765 = vshrl.u32 %v47759, 16 (stack45)
        %v47766 = vor.u32 %v47765, %v47764 (stack46)
        %v47767 = vxor.u32 %v47766, %v47762 (stack47)
        %v47770 = vadd.s32 %v47767, %v47762 (stack39)
        %v47774 = vadd.s32 %v47770, %v9 (stack39)
        %v47776 = vshll.u32 %v47767, 24 (stack44)
        %v47777 = vshrl.u32 %v47767, 8 (stack45)
        %v47778 = vor.u32 %v47777, %v47776 (stack46)
        %v47779 = vxor.u32 %v47778, %v47770 (stack47)
        %v47782 = vadd.s32 %v47779, %v8 (stack39)
        %v47786 = vadd.s32 4, %v47782 (stack39)
        %v47790 = vadd.s32 %v47786, %v47774 (stack39)
        %v47792 = vshll.u32 %v47786, 13 (stack44)
        %v47793 = vshrl.u32 %v47786, 19 (stack45)
        %v47794 = vor.u32 %v47793, %v47792 (stack46)
        %v47795 = vxor.u32 %v47794, %v47790 (stack47)
        %v47798 = vadd.s32 %v47795, %v47790 (stack39)
        %v47800 = vshll.u32 %v47795, 15 (stack44)
        %v47801 = vshrl.u32 %v47795, 17 (stack45)
        %v47802 = vor.u32 %v47801, %v47800 (stack46)
        %v47803 = vxor.u32 %v47802, %v47798 (stack47)
        %v47806 = vadd.s32 %v47803, %v47798 (stack39)
        %v47808 = vshll.u32 %v47803, 26 (stack44)
        %v47809 = vshrl.u32 %v47803, 6 (stack45)
        %v47810 = vor.u32 %v47809, %v47808 (stack46)
        %v47811 = vxor.u32 %v47810, %v47806 (stack47)
        %v47814 = vadd.s32 %v47811, %v47806 (stack39)
        %v47818 = vadd.s32 %v47814, %v8 (stack39)
        %v47820 = vshll.u32 %v47811, 6 (stack44)
        %v47821 = vshrl.u32 %v47811, 26 (stack45)
        %v47822 = vor.u32 %v47821, %v47820 (stack46)
        %v47823 = vxor.u32 %v47822, %v47814 (stack47)
        %v47826 = vadd.s32 %v47823, %v10 (stack39)
        %v47830 = vadd.s32 5, %v47826 (stack39)
        %v47832 = vxor.u32 %v47830, %v47818 (stack47)
        %v47833 = vand.u32.u8 255, %v47832 (stack48)
        %v47834 = vand.u32 65535, %v47833 (stack49)
        %v47835 = vshrl.u32 %v47834, 1 (stack50)
        %v47836 = vor.u32 16256, %v47835 (stack46)
        %v47837 = vand.u32.u16 65535, %v47836 (stack51)
        %v119998 = vadd.low.f32.bf16 -1.0, %v47837 (stack52)
        %v47846 = vmul.f32 2.0, %v119998 (stack53)
        %v47850 = vadd.f32 -0.99609375, %v47846 (stack52)
        %v47854 = vmax.f32 %v47850, -0.99609375 (stack54)
        %v47856 = vand.u32 2147483647, %v47854 (stack55)
        %vm47859 = vcmp.eq.f32.partialorder %v47856, 1.0 (stack56)
        %v47864 = vmul.f32 inf, %v47854 (stack53)
        %v47866 = vxor.u32 2147483648, %v47854 (stack57)
        %v47869 = vmul.f32 %v47866, %v47854 (stack53)
        %v47871 = vadd.f32 1.0, %v47869 (stack58)
        %v47872 = vlog2.pop %v47871 (stack59)
        %v47873 = vmul.f32 0.6931472, %v47872 (stack60)
        %v47874 = vmul.f32 -0.5, %v47869 (stack61)
        %v47875 = vadd.f32 1.0, %v47874 (stack62)
        %v47876 = vmul.f32 %v47875, %v47869 (stack63)
        %v47877 = vand.u32 2147483647, %v47869 (stack64)
        %vm47878 = vcmp.lt.f32.partialorder %v47877, 0.0004427343 (stack65)
        %v47879 = vsel /*vm=*/%vm47878, /*on_true_vy=*/%v47876, /*on_false_vx=*/%v47873 (stack66)
        %v47880 = vxor.u32 2147483648, %v47879 (stack57)
        %vm47883 = vcmp.lt.f32.partialorder %v47880, 5.0 (stack56)
        %v47888 = vsel /*vm=*/%vm47883, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v47892 = vsel /*vm=*/%vm47883, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v47896 = vsel /*vm=*/%vm47883, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v47900 = vsel /*vm=*/%vm47883, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v47904 = vsel /*vm=*/%vm47883, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v47908 = vsel /*vm=*/%vm47883, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v47912 = vsel /*vm=*/%vm47883, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v47916 = vsel /*vm=*/%vm47883, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v47920 = vsel /*vm=*/%vm47883, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v47924 = vadd.f32 -2.5, %v47880 (stack52)
        %v47926 = vrsqrt.pop %v47880 (stack67)
        %v47927 = vmul.f32 %v47926, %v47880 (stack68)
        %vm47928 = vcmp.eq.f32.partialorder %v47880, inf (stack69)
        %v47929 = vsel /*vm=*/%vm47928, /*on_true_vy=*/%v47880, /*on_false_vx=*/%v47927 (stack70)
        %vm47930 = vcmp.eq.f32.partialorder %v47880, 0.0 (stack71)
        %v47931 = vand.u32 2147483648, %v47880 (stack72)
        %v47932 = vsel /*vm=*/%vm47930, /*on_true_vy=*/%v47931, /*on_false_vx=*/%v47929 (stack73)
        %v47935 = vadd.f32 -3.0, %v47932 (stack52)
        %v47939 = vsel /*vm=*/%vm47883, /*on_true_vy=*/%v47924, /*on_false_vx=*/%v47935 (stack43)
        %v47943 = vmul.f32 %v47939, %v47920 (stack53)
        %v47947 = vadd.f32 %v47943, %v47916 (stack52)
        %v47951 = vmul.f32 %v47947, %v47939 (stack53)
        %v47955 = vadd.f32 %v47951, %v47912 (stack52)
        %v47959 = vmul.f32 %v47955, %v47939 (stack53)
        %v47963 = vadd.f32 %v47959, %v47908 (stack52)
        %v47967 = vmul.f32 %v47963, %v47939 (stack53)
        %v47971 = vadd.f32 %v47967, %v47904 (stack52)
        %v47975 = vmul.f32 %v47971, %v47939 (stack53)
        %v47979 = vadd.f32 %v47975, %v47900 (stack52)
        %v47983 = vmul.f32 %v47979, %v47939 (stack53)
        %v47987 = vadd.f32 %v47983, %v47896 (stack52)
        %v47991 = vmul.f32 %v47987, %v47939 (stack53)
        %v47995 = vadd.f32 %v47991, %v47892 (stack52)
        %v47999 = vmul.f32 %v47995, %v47939 (stack53)
        %v48003 = vadd.f32 %v47999, %v47888 (stack52)
        %v48007 = vmul.f32 %v48003, %v47854 (stack53)
        %v48011 = vsel /*vm=*/%vm47859, /*on_true_vy=*/%v47864, /*on_false_vx=*/%v48007 (stack43)
        %v48015 = vmul.f32 1.4140625, %v48011 (stack53)
        %v48018 = vpack.c.bf16 0.0, %v48015 (stack74)
        %119999 = vst [vmem:[%s280 + $0x2b0] sm:$0xf] /*vst_source=*/%v48018 (stack75)
        %v48022 = vadd.s32 %v45253, %v3329 (stack39)
        %v48032 = vadd.s32 %v48022, %v415 (stack39)
        %vm48036 = vcmp.lt.u32.totalorder %v48032, %v48022 (stack42)
        %vm48041 = vcmp.lt.u32.totalorder %v48022, %v3329 (stack42)
        %v48046 = vadd.s32 %v45236, %v3316 (stack39)
        %v48050 = vadd.s32 1, %v48046 (stack39)
        %v48054 = vsel /*vm=*/%vm48041, /*on_true_vy=*/%v48050, /*on_false_vx=*/%v48046 (stack43)
        %v48058 = vadd.s32 1, %v48054 (stack39)
        %v48062 = vsel /*vm=*/%vm48036, /*on_true_vy=*/%v48058, /*on_false_vx=*/%v48054 (stack43)
        %v48067 = vadd.s32 %v48062, %v10 (stack39)
        %v48071 = vadd.s32 %v48032, %v9 (stack39)
        %v48075 = vadd.s32 %v48071, %v48067 (stack39)
        %v48077 = vshll.u32 %v48071, 13 (stack44)
        %v48078 = vshrl.u32 %v48071, 19 (stack45)
        %v48079 = vor.u32 %v48078, %v48077 (stack46)
        %v48080 = vxor.u32 %v48079, %v48075 (stack47)
        %v48083 = vadd.s32 %v48080, %v48075 (stack39)
        %v48085 = vshll.u32 %v48080, 15 (stack44)
        %v48086 = vshrl.u32 %v48080, 17 (stack45)
        %v48087 = vor.u32 %v48086, %v48085 (stack46)
        %v48088 = vxor.u32 %v48087, %v48083 (stack47)
        %v48091 = vadd.s32 %v48088, %v48083 (stack39)
        %v48093 = vshll.u32 %v48088, 26 (stack44)
        %v48094 = vshrl.u32 %v48088, 6 (stack45)
        %v48095 = vor.u32 %v48094, %v48093 (stack46)
        %v48096 = vxor.u32 %v48095, %v48091 (stack47)
        %v48099 = vadd.s32 %v48096, %v48091 (stack39)
        %v48103 = vadd.s32 %v48099, %v9 (stack39)
        %v48105 = vshll.u32 %v48096, 6 (stack44)
        %v48106 = vshrl.u32 %v48096, 26 (stack45)
        %v48107 = vor.u32 %v48106, %v48105 (stack46)
        %v48108 = vxor.u32 %v48107, %v48099 (stack47)
        %v48111 = vadd.s32 %v48108, %v8 (stack39)
        %v48115 = vadd.s32 1, %v48111 (stack39)
        %v48119 = vadd.s32 %v48115, %v48103 (stack39)
        %v48121 = vshll.u32 %v48115, 17 (stack44)
        %v48122 = vshrl.u32 %v48115, 15 (stack45)
        %v48123 = vor.u32 %v48122, %v48121 (stack46)
        %v48124 = vxor.u32 %v48123, %v48119 (stack47)
        %v48127 = vadd.s32 %v48124, %v48119 (stack39)
        %v48129 = vshll.u32 %v48124, 29 (stack44)
        %v48130 = vshrl.u32 %v48124, 3 (stack45)
        %v48131 = vor.u32 %v48130, %v48129 (stack46)
        %v48132 = vxor.u32 %v48131, %v48127 (stack47)
        %v48135 = vadd.s32 %v48132, %v48127 (stack39)
        %v48137 = vshll.u32 %v48132, 16 (stack44)
        %v48138 = vshrl.u32 %v48132, 16 (stack45)
        %v48139 = vor.u32 %v48138, %v48137 (stack46)
        %v48140 = vxor.u32 %v48139, %v48135 (stack47)
        %v48143 = vadd.s32 %v48140, %v48135 (stack39)
        %v48147 = vadd.s32 %v48143, %v8 (stack39)
        %v48149 = vshll.u32 %v48140, 24 (stack44)
        %v48150 = vshrl.u32 %v48140, 8 (stack45)
        %v48151 = vor.u32 %v48150, %v48149 (stack46)
        %v48152 = vxor.u32 %v48151, %v48143 (stack47)
        %v48155 = vadd.s32 %v48152, %v10 (stack39)
        %v48159 = vadd.s32 2, %v48155 (stack39)
        %v48163 = vadd.s32 %v48159, %v48147 (stack39)
        %v48165 = vshll.u32 %v48159, 13 (stack44)
        %v48166 = vshrl.u32 %v48159, 19 (stack45)
        %v48167 = vor.u32 %v48166, %v48165 (stack46)
        %v48168 = vxor.u32 %v48167, %v48163 (stack47)
        %v48171 = vadd.s32 %v48168, %v48163 (stack39)
        %v48173 = vshll.u32 %v48168, 15 (stack44)
        %v48174 = vshrl.u32 %v48168, 17 (stack45)
        %v48175 = vor.u32 %v48174, %v48173 (stack46)
        %v48176 = vxor.u32 %v48175, %v48171 (stack47)
        %v48179 = vadd.s32 %v48176, %v48171 (stack39)
        %v48181 = vshll.u32 %v48176, 26 (stack44)
        %v48182 = vshrl.u32 %v48176, 6 (stack45)
        %v48183 = vor.u32 %v48182, %v48181 (stack46)
        %v48184 = vxor.u32 %v48183, %v48179 (stack47)
        %v48187 = vadd.s32 %v48184, %v48179 (stack39)
        %v48191 = vadd.s32 %v48187, %v10 (stack39)
        %v48193 = vshll.u32 %v48184, 6 (stack44)
        %v48194 = vshrl.u32 %v48184, 26 (stack45)
        %v48195 = vor.u32 %v48194, %v48193 (stack46)
        %v48196 = vxor.u32 %v48195, %v48187 (stack47)
        %v48199 = vadd.s32 %v48196, %v9 (stack39)
        %v48203 = vadd.s32 3, %v48199 (stack39)
        %v48207 = vadd.s32 %v48203, %v48191 (stack39)
        %v48209 = vshll.u32 %v48203, 17 (stack44)
        %v48210 = vshrl.u32 %v48203, 15 (stack45)
        %v48211 = vor.u32 %v48210, %v48209 (stack46)
        %v48212 = vxor.u32 %v48211, %v48207 (stack47)
        %v48215 = vadd.s32 %v48212, %v48207 (stack39)
        %v48217 = vshll.u32 %v48212, 29 (stack44)
        %v48218 = vshrl.u32 %v48212, 3 (stack45)
        %v48219 = vor.u32 %v48218, %v48217 (stack46)
        %v48220 = vxor.u32 %v48219, %v48215 (stack47)
        %v48223 = vadd.s32 %v48220, %v48215 (stack39)
        %v48225 = vshll.u32 %v48220, 16 (stack44)
        %v48226 = vshrl.u32 %v48220, 16 (stack45)
        %v48227 = vor.u32 %v48226, %v48225 (stack46)
        %v48228 = vxor.u32 %v48227, %v48223 (stack47)
        %v48231 = vadd.s32 %v48228, %v48223 (stack39)
        %v48235 = vadd.s32 %v48231, %v9 (stack39)
        %v48237 = vshll.u32 %v48228, 24 (stack44)
        %v48238 = vshrl.u32 %v48228, 8 (stack45)
        %v48239 = vor.u32 %v48238, %v48237 (stack46)
        %v48240 = vxor.u32 %v48239, %v48231 (stack47)
        %v48243 = vadd.s32 %v48240, %v8 (stack39)
        %v48247 = vadd.s32 4, %v48243 (stack39)
        %v48251 = vadd.s32 %v48247, %v48235 (stack39)
        %v48253 = vshll.u32 %v48247, 13 (stack44)
        %v48254 = vshrl.u32 %v48247, 19 (stack45)
        %v48255 = vor.u32 %v48254, %v48253 (stack46)
        %v48256 = vxor.u32 %v48255, %v48251 (stack47)
        %v48259 = vadd.s32 %v48256, %v48251 (stack39)
        %v48261 = vshll.u32 %v48256, 15 (stack44)
        %v48262 = vshrl.u32 %v48256, 17 (stack45)
        %v48263 = vor.u32 %v48262, %v48261 (stack46)
        %v48264 = vxor.u32 %v48263, %v48259 (stack47)
        %v48267 = vadd.s32 %v48264, %v48259 (stack39)
        %v48269 = vshll.u32 %v48264, 26 (stack44)
        %v48270 = vshrl.u32 %v48264, 6 (stack45)
        %v48271 = vor.u32 %v48270, %v48269 (stack46)
        %v48272 = vxor.u32 %v48271, %v48267 (stack47)
        %v48275 = vadd.s32 %v48272, %v48267 (stack39)
        %v48279 = vadd.s32 %v48275, %v8 (stack39)
        %v48281 = vshll.u32 %v48272, 6 (stack44)
        %v48282 = vshrl.u32 %v48272, 26 (stack45)
        %v48283 = vor.u32 %v48282, %v48281 (stack46)
        %v48284 = vxor.u32 %v48283, %v48275 (stack47)
        %v48287 = vadd.s32 %v48284, %v10 (stack39)
        %v48291 = vadd.s32 5, %v48287 (stack39)
        %v48293 = vxor.u32 %v48291, %v48279 (stack47)
        %v48294 = vand.u32.u8 255, %v48293 (stack48)
        %v48295 = vand.u32 65535, %v48294 (stack49)
        %v48296 = vshrl.u32 %v48295, 1 (stack50)
        %v48297 = vor.u32 16256, %v48296 (stack46)
        %v48298 = vand.u32.u16 65535, %v48297 (stack51)
        %v120000 = vadd.low.f32.bf16 -1.0, %v48298 (stack52)
        %v48307 = vmul.f32 2.0, %v120000 (stack53)
        %v48311 = vadd.f32 -0.99609375, %v48307 (stack52)
        %v48315 = vmax.f32 %v48311, -0.99609375 (stack54)
        %v48317 = vand.u32 2147483647, %v48315 (stack55)
        %vm48320 = vcmp.eq.f32.partialorder %v48317, 1.0 (stack56)
        %v48325 = vmul.f32 inf, %v48315 (stack53)
        %v48327 = vxor.u32 2147483648, %v48315 (stack57)
        %v48330 = vmul.f32 %v48327, %v48315 (stack53)
        %v48332 = vadd.f32 1.0, %v48330 (stack58)
        %v48333 = vlog2.pop %v48332 (stack59)
        %v48334 = vmul.f32 0.6931472, %v48333 (stack60)
        %v48335 = vmul.f32 -0.5, %v48330 (stack61)
        %v48336 = vadd.f32 1.0, %v48335 (stack62)
        %v48337 = vmul.f32 %v48336, %v48330 (stack63)
        %v48338 = vand.u32 2147483647, %v48330 (stack64)
        %vm48339 = vcmp.lt.f32.partialorder %v48338, 0.0004427343 (stack65)
        %v48340 = vsel /*vm=*/%vm48339, /*on_true_vy=*/%v48337, /*on_false_vx=*/%v48334 (stack66)
        %v48341 = vxor.u32 2147483648, %v48340 (stack57)
        %vm48344 = vcmp.lt.f32.partialorder %v48341, 5.0 (stack56)
        %v48349 = vsel /*vm=*/%vm48344, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v48353 = vsel /*vm=*/%vm48344, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v48357 = vsel /*vm=*/%vm48344, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v48361 = vsel /*vm=*/%vm48344, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v48365 = vsel /*vm=*/%vm48344, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v48369 = vsel /*vm=*/%vm48344, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v48373 = vsel /*vm=*/%vm48344, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v48377 = vsel /*vm=*/%vm48344, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v48381 = vsel /*vm=*/%vm48344, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v48385 = vadd.f32 -2.5, %v48341 (stack52)
        %v48387 = vrsqrt.pop %v48341 (stack67)
        %v48388 = vmul.f32 %v48387, %v48341 (stack68)
        %vm48389 = vcmp.eq.f32.partialorder %v48341, inf (stack69)
        %v48390 = vsel /*vm=*/%vm48389, /*on_true_vy=*/%v48341, /*on_false_vx=*/%v48388 (stack70)
        %vm48391 = vcmp.eq.f32.partialorder %v48341, 0.0 (stack71)
        %v48392 = vand.u32 2147483648, %v48341 (stack72)
        %v48393 = vsel /*vm=*/%vm48391, /*on_true_vy=*/%v48392, /*on_false_vx=*/%v48390 (stack73)
        %v48396 = vadd.f32 -3.0, %v48393 (stack52)
        %v48400 = vsel /*vm=*/%vm48344, /*on_true_vy=*/%v48385, /*on_false_vx=*/%v48396 (stack43)
        %v48404 = vmul.f32 %v48400, %v48381 (stack53)
        %v48408 = vadd.f32 %v48404, %v48377 (stack52)
        %v48412 = vmul.f32 %v48408, %v48400 (stack53)
        %v48416 = vadd.f32 %v48412, %v48373 (stack52)
        %v48420 = vmul.f32 %v48416, %v48400 (stack53)
        %v48424 = vadd.f32 %v48420, %v48369 (stack52)
        %v48428 = vmul.f32 %v48424, %v48400 (stack53)
        %v48432 = vadd.f32 %v48428, %v48365 (stack52)
        %v48436 = vmul.f32 %v48432, %v48400 (stack53)
        %v48440 = vadd.f32 %v48436, %v48361 (stack52)
        %v48444 = vmul.f32 %v48440, %v48400 (stack53)
        %v48448 = vadd.f32 %v48444, %v48357 (stack52)
        %v48452 = vmul.f32 %v48448, %v48400 (stack53)
        %v48456 = vadd.f32 %v48452, %v48353 (stack52)
        %v48460 = vmul.f32 %v48456, %v48400 (stack53)
        %v48464 = vadd.f32 %v48460, %v48349 (stack52)
        %v48468 = vmul.f32 %v48464, %v48315 (stack53)
        %v48472 = vsel /*vm=*/%vm48320, /*on_true_vy=*/%v48325, /*on_false_vx=*/%v48468 (stack43)
        %v48476 = vmul.f32 1.4140625, %v48472 (stack53)
        %v48479 = vpack.c.bf16 0.0, %v48476 (stack74)
        %120001 = vst [vmem:[%s280 + $0x330] sm:$0xf] /*vst_source=*/%v48479 (stack75)
        %v48483 = vadd.s32 %v45253, %v3816 (stack39)
        %v48493 = vadd.s32 %v48483, %v415 (stack39)
        %vm48497 = vcmp.lt.u32.totalorder %v48493, %v48483 (stack42)
        %vm48502 = vcmp.lt.u32.totalorder %v48483, %v3816 (stack42)
        %v48507 = vadd.s32 %v45236, %v3803 (stack39)
        %v48511 = vadd.s32 1, %v48507 (stack39)
        %v48515 = vsel /*vm=*/%vm48502, /*on_true_vy=*/%v48511, /*on_false_vx=*/%v48507 (stack43)
        %v48519 = vadd.s32 1, %v48515 (stack39)
        %v48523 = vsel /*vm=*/%vm48497, /*on_true_vy=*/%v48519, /*on_false_vx=*/%v48515 (stack43)
        %v48528 = vadd.s32 %v48523, %v10 (stack39)
        %v48532 = vadd.s32 %v48493, %v9 (stack39)
        %v48536 = vadd.s32 %v48532, %v48528 (stack39)
        %v48538 = vshll.u32 %v48532, 13 (stack44)
        %v48539 = vshrl.u32 %v48532, 19 (stack45)
        %v48540 = vor.u32 %v48539, %v48538 (stack46)
        %v48541 = vxor.u32 %v48540, %v48536 (stack47)
        %v48544 = vadd.s32 %v48541, %v48536 (stack39)
        %v48546 = vshll.u32 %v48541, 15 (stack44)
        %v48547 = vshrl.u32 %v48541, 17 (stack45)
        %v48548 = vor.u32 %v48547, %v48546 (stack46)
        %v48549 = vxor.u32 %v48548, %v48544 (stack47)
        %v48552 = vadd.s32 %v48549, %v48544 (stack39)
        %v48554 = vshll.u32 %v48549, 26 (stack44)
        %v48555 = vshrl.u32 %v48549, 6 (stack45)
        %v48556 = vor.u32 %v48555, %v48554 (stack46)
        %v48557 = vxor.u32 %v48556, %v48552 (stack47)
        %v48560 = vadd.s32 %v48557, %v48552 (stack39)
        %v48564 = vadd.s32 %v48560, %v9 (stack39)
        %v48566 = vshll.u32 %v48557, 6 (stack44)
        %v48567 = vshrl.u32 %v48557, 26 (stack45)
        %v48568 = vor.u32 %v48567, %v48566 (stack46)
        %v48569 = vxor.u32 %v48568, %v48560 (stack47)
        %v48572 = vadd.s32 %v48569, %v8 (stack39)
        %v48576 = vadd.s32 1, %v48572 (stack39)
        %v48580 = vadd.s32 %v48576, %v48564 (stack39)
        %v48582 = vshll.u32 %v48576, 17 (stack44)
        %v48583 = vshrl.u32 %v48576, 15 (stack45)
        %v48584 = vor.u32 %v48583, %v48582 (stack46)
        %v48585 = vxor.u32 %v48584, %v48580 (stack47)
        %v48588 = vadd.s32 %v48585, %v48580 (stack39)
        %v48590 = vshll.u32 %v48585, 29 (stack44)
        %v48591 = vshrl.u32 %v48585, 3 (stack45)
        %v48592 = vor.u32 %v48591, %v48590 (stack46)
        %v48593 = vxor.u32 %v48592, %v48588 (stack47)
        %v48596 = vadd.s32 %v48593, %v48588 (stack39)
        %v48598 = vshll.u32 %v48593, 16 (stack44)
        %v48599 = vshrl.u32 %v48593, 16 (stack45)
        %v48600 = vor.u32 %v48599, %v48598 (stack46)
        %v48601 = vxor.u32 %v48600, %v48596 (stack47)
        %v48604 = vadd.s32 %v48601, %v48596 (stack39)
        %v48608 = vadd.s32 %v48604, %v8 (stack39)
        %v48610 = vshll.u32 %v48601, 24 (stack44)
        %v48611 = vshrl.u32 %v48601, 8 (stack45)
        %v48612 = vor.u32 %v48611, %v48610 (stack46)
        %v48613 = vxor.u32 %v48612, %v48604 (stack47)
        %v48616 = vadd.s32 %v48613, %v10 (stack39)
        %v48620 = vadd.s32 2, %v48616 (stack39)
        %v48624 = vadd.s32 %v48620, %v48608 (stack39)
        %v48626 = vshll.u32 %v48620, 13 (stack44)
        %v48627 = vshrl.u32 %v48620, 19 (stack45)
        %v48628 = vor.u32 %v48627, %v48626 (stack46)
        %v48629 = vxor.u32 %v48628, %v48624 (stack47)
        %v48632 = vadd.s32 %v48629, %v48624 (stack39)
        %v48634 = vshll.u32 %v48629, 15 (stack44)
        %v48635 = vshrl.u32 %v48629, 17 (stack45)
        %v48636 = vor.u32 %v48635, %v48634 (stack46)
        %v48637 = vxor.u32 %v48636, %v48632 (stack47)
        %v48640 = vadd.s32 %v48637, %v48632 (stack39)
        %v48642 = vshll.u32 %v48637, 26 (stack44)
        %v48643 = vshrl.u32 %v48637, 6 (stack45)
        %v48644 = vor.u32 %v48643, %v48642 (stack46)
        %v48645 = vxor.u32 %v48644, %v48640 (stack47)
        %v48648 = vadd.s32 %v48645, %v48640 (stack39)
        %v48652 = vadd.s32 %v48648, %v10 (stack39)
        %v48654 = vshll.u32 %v48645, 6 (stack44)
        %v48655 = vshrl.u32 %v48645, 26 (stack45)
        %v48656 = vor.u32 %v48655, %v48654 (stack46)
        %v48657 = vxor.u32 %v48656, %v48648 (stack47)
        %v48660 = vadd.s32 %v48657, %v9 (stack39)
        %v48664 = vadd.s32 3, %v48660 (stack39)
        %v48668 = vadd.s32 %v48664, %v48652 (stack39)
        %v48670 = vshll.u32 %v48664, 17 (stack44)
        %v48671 = vshrl.u32 %v48664, 15 (stack45)
        %v48672 = vor.u32 %v48671, %v48670 (stack46)
        %v48673 = vxor.u32 %v48672, %v48668 (stack47)
        %v48676 = vadd.s32 %v48673, %v48668 (stack39)
        %v48678 = vshll.u32 %v48673, 29 (stack44)
        %v48679 = vshrl.u32 %v48673, 3 (stack45)
        %v48680 = vor.u32 %v48679, %v48678 (stack46)
        %v48681 = vxor.u32 %v48680, %v48676 (stack47)
        %v48684 = vadd.s32 %v48681, %v48676 (stack39)
        %v48686 = vshll.u32 %v48681, 16 (stack44)
        %v48687 = vshrl.u32 %v48681, 16 (stack45)
        %v48688 = vor.u32 %v48687, %v48686 (stack46)
        %v48689 = vxor.u32 %v48688, %v48684 (stack47)
        %v48692 = vadd.s32 %v48689, %v48684 (stack39)
        %v48696 = vadd.s32 %v48692, %v9 (stack39)
        %v48698 = vshll.u32 %v48689, 24 (stack44)
        %v48699 = vshrl.u32 %v48689, 8 (stack45)
        %v48700 = vor.u32 %v48699, %v48698 (stack46)
        %v48701 = vxor.u32 %v48700, %v48692 (stack47)
        %v48704 = vadd.s32 %v48701, %v8 (stack39)
        %v48708 = vadd.s32 4, %v48704 (stack39)
        %v48712 = vadd.s32 %v48708, %v48696 (stack39)
        %v48714 = vshll.u32 %v48708, 13 (stack44)
        %v48715 = vshrl.u32 %v48708, 19 (stack45)
        %v48716 = vor.u32 %v48715, %v48714 (stack46)
        %v48717 = vxor.u32 %v48716, %v48712 (stack47)
        %v48720 = vadd.s32 %v48717, %v48712 (stack39)
        %v48722 = vshll.u32 %v48717, 15 (stack44)
        %v48723 = vshrl.u32 %v48717, 17 (stack45)
        %v48724 = vor.u32 %v48723, %v48722 (stack46)
        %v48725 = vxor.u32 %v48724, %v48720 (stack47)
        %v48728 = vadd.s32 %v48725, %v48720 (stack39)
        %v48730 = vshll.u32 %v48725, 26 (stack44)
        %v48731 = vshrl.u32 %v48725, 6 (stack45)
        %v48732 = vor.u32 %v48731, %v48730 (stack46)
        %v48733 = vxor.u32 %v48732, %v48728 (stack47)
        %v48736 = vadd.s32 %v48733, %v48728 (stack39)
        %v48740 = vadd.s32 %v48736, %v8 (stack39)
        %v48742 = vshll.u32 %v48733, 6 (stack44)
        %v48743 = vshrl.u32 %v48733, 26 (stack45)
        %v48744 = vor.u32 %v48743, %v48742 (stack46)
        %v48745 = vxor.u32 %v48744, %v48736 (stack47)
        %v48748 = vadd.s32 %v48745, %v10 (stack39)
        %v48752 = vadd.s32 5, %v48748 (stack39)
        %v48754 = vxor.u32 %v48752, %v48740 (stack47)
        %v48755 = vand.u32.u8 255, %v48754 (stack48)
        %v48756 = vand.u32 65535, %v48755 (stack49)
        %v48757 = vshrl.u32 %v48756, 1 (stack50)
        %v48758 = vor.u32 16256, %v48757 (stack46)
        %v48759 = vand.u32.u16 65535, %v48758 (stack51)
        %v120002 = vadd.low.f32.bf16 -1.0, %v48759 (stack52)
        %v48768 = vmul.f32 2.0, %v120002 (stack53)
        %v48772 = vadd.f32 -0.99609375, %v48768 (stack52)
        %v48776 = vmax.f32 %v48772, -0.99609375 (stack54)
        %v48778 = vand.u32 2147483647, %v48776 (stack55)
        %vm48781 = vcmp.eq.f32.partialorder %v48778, 1.0 (stack56)
        %v48786 = vmul.f32 inf, %v48776 (stack53)
        %v48788 = vxor.u32 2147483648, %v48776 (stack57)
        %v48791 = vmul.f32 %v48788, %v48776 (stack53)
        %v48793 = vadd.f32 1.0, %v48791 (stack58)
        %v48794 = vlog2.pop %v48793 (stack59)
        %v48795 = vmul.f32 0.6931472, %v48794 (stack60)
        %v48796 = vmul.f32 -0.5, %v48791 (stack61)
        %v48797 = vadd.f32 1.0, %v48796 (stack62)
        %v48798 = vmul.f32 %v48797, %v48791 (stack63)
        %v48799 = vand.u32 2147483647, %v48791 (stack64)
        %vm48800 = vcmp.lt.f32.partialorder %v48799, 0.0004427343 (stack65)
        %v48801 = vsel /*vm=*/%vm48800, /*on_true_vy=*/%v48798, /*on_false_vx=*/%v48795 (stack66)
        %v48802 = vxor.u32 2147483648, %v48801 (stack57)
        %vm48805 = vcmp.lt.f32.partialorder %v48802, 5.0 (stack56)
        %v48810 = vsel /*vm=*/%vm48805, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v48814 = vsel /*vm=*/%vm48805, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v48818 = vsel /*vm=*/%vm48805, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v48822 = vsel /*vm=*/%vm48805, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v48826 = vsel /*vm=*/%vm48805, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v48830 = vsel /*vm=*/%vm48805, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v48834 = vsel /*vm=*/%vm48805, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v48838 = vsel /*vm=*/%vm48805, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v48842 = vsel /*vm=*/%vm48805, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v48846 = vadd.f32 -2.5, %v48802 (stack52)
        %v48848 = vrsqrt.pop %v48802 (stack67)
        %v48849 = vmul.f32 %v48848, %v48802 (stack68)
        %vm48850 = vcmp.eq.f32.partialorder %v48802, inf (stack69)
        %v48851 = vsel /*vm=*/%vm48850, /*on_true_vy=*/%v48802, /*on_false_vx=*/%v48849 (stack70)
        %vm48852 = vcmp.eq.f32.partialorder %v48802, 0.0 (stack71)
        %v48853 = vand.u32 2147483648, %v48802 (stack72)
        %v48854 = vsel /*vm=*/%vm48852, /*on_true_vy=*/%v48853, /*on_false_vx=*/%v48851 (stack73)
        %v48857 = vadd.f32 -3.0, %v48854 (stack52)
        %v48861 = vsel /*vm=*/%vm48805, /*on_true_vy=*/%v48846, /*on_false_vx=*/%v48857 (stack43)
        %v48865 = vmul.f32 %v48861, %v48842 (stack53)
        %v48869 = vadd.f32 %v48865, %v48838 (stack52)
        %v48873 = vmul.f32 %v48869, %v48861 (stack53)
        %v48877 = vadd.f32 %v48873, %v48834 (stack52)
        %v48881 = vmul.f32 %v48877, %v48861 (stack53)
        %v48885 = vadd.f32 %v48881, %v48830 (stack52)
        %v48889 = vmul.f32 %v48885, %v48861 (stack53)
        %v48893 = vadd.f32 %v48889, %v48826 (stack52)
        %v48897 = vmul.f32 %v48893, %v48861 (stack53)
        %v48901 = vadd.f32 %v48897, %v48822 (stack52)
        %v48905 = vmul.f32 %v48901, %v48861 (stack53)
        %v48909 = vadd.f32 %v48905, %v48818 (stack52)
        %v48913 = vmul.f32 %v48909, %v48861 (stack53)
        %v48917 = vadd.f32 %v48913, %v48814 (stack52)
        %v48921 = vmul.f32 %v48917, %v48861 (stack53)
        %v48925 = vadd.f32 %v48921, %v48810 (stack52)
        %v48929 = vmul.f32 %v48925, %v48776 (stack53)
        %v48933 = vsel /*vm=*/%vm48781, /*on_true_vy=*/%v48786, /*on_false_vx=*/%v48929 (stack43)
        %v48937 = vmul.f32 1.4140625, %v48933 (stack53)
        %v48940 = vpack.c.bf16 0.0, %v48937 (stack74)
        %120003 = vst [vmem:[%s280 + $0x3b0] sm:$0xf] /*vst_source=*/%v48940 (stack75)
        %s48942 = sadd.s32 104, %s120390 (stack76)
        %s48943 = sshrl.u32 %s48942, 10 (stack23)
        %p120004 = scmp.gt.s32.totalorder %s48943, 1 (stack24)
        %s48945 = scalar_select /*predicate=*/%p120004, /*on_true=*/1, /*on_false=*/%s48943 (stack25)
        %s48946 = sand.u32 1023, %s48942 /* smod.u32 w/div 1024 */ (stack26)
        %s48947 = sshrl.u32 %s48946, 7 (stack27)
        %s48948 = sand.u32 127, %s48946 /* smod.u32 w/div 128 */ (stack28)
        %s120005 = sshll.u32 %s48945, 3 (stack29)
        %s48950 = scalar_lea.vmem %s3, %s120005 (stack30)
        %s48952 = scalar_lea.vmem %s48950, %s48947 (stack31)
        %v48953 = vld [vmem:[%s48952] ss:$0 sm:$0xff] (stack32)
        %s48954 = sand.u32 255, %s48948 (stack33)
        %s48956 = sor.u32 256, %s48954 (stack34)
        %48957 = vbcast.lane.b32.xlu0 %v48953, %s48956 (stack35)
        %v48958 = vpop.permute.xlu0 %48957 (stack36)
        %s48967 = scalar_lea.vmem %s5, %s120005 (stack30)
        %s48969 = scalar_lea.vmem %s48967, %s48947 (stack31)
        %v48970 = vld [vmem:[%s48969] ss:$0 sm:$0xff] (stack32)
        %48974 = vbcast.lane.b32.xlu0 %v48970, %s48956 (stack35)
        %v48975 = vpop.permute.xlu0 %48974 (stack36)
        %v48978 = vadd.s32 %v48975, %v408 (stack39)
        %v48988 = vadd.s32 %v48978, %v415 (stack39)
        %vm48992 = vcmp.lt.u32.totalorder %v48988, %v48978 (stack42)
        %vm48997 = vcmp.lt.u32.totalorder %v48978, %v408 (stack42)
        %v49002 = vadd.s32 %v48958, %v380 (stack39)
        %v49006 = vadd.s32 1, %v49002 (stack39)
        %v49010 = vsel /*vm=*/%vm48997, /*on_true_vy=*/%v49006, /*on_false_vx=*/%v49002 (stack43)
        %v49014 = vadd.s32 1, %v49010 (stack39)
        %v49018 = vsel /*vm=*/%vm48992, /*on_true_vy=*/%v49014, /*on_false_vx=*/%v49010 (stack43)
        %v49023 = vadd.s32 %v49018, %v10 (stack39)
        %v49027 = vadd.s32 %v48988, %v9 (stack39)
        %v49031 = vadd.s32 %v49027, %v49023 (stack39)
        %v49033 = vshll.u32 %v49027, 13 (stack44)
        %v49034 = vshrl.u32 %v49027, 19 (stack45)
        %v49035 = vor.u32 %v49034, %v49033 (stack46)
        %v49036 = vxor.u32 %v49035, %v49031 (stack47)
        %v49039 = vadd.s32 %v49036, %v49031 (stack39)
        %v49041 = vshll.u32 %v49036, 15 (stack44)
        %v49042 = vshrl.u32 %v49036, 17 (stack45)
        %v49043 = vor.u32 %v49042, %v49041 (stack46)
        %v49044 = vxor.u32 %v49043, %v49039 (stack47)
        %v49047 = vadd.s32 %v49044, %v49039 (stack39)
        %v49049 = vshll.u32 %v49044, 26 (stack44)
        %v49050 = vshrl.u32 %v49044, 6 (stack45)
        %v49051 = vor.u32 %v49050, %v49049 (stack46)
        %v49052 = vxor.u32 %v49051, %v49047 (stack47)
        %v49055 = vadd.s32 %v49052, %v49047 (stack39)
        %v49059 = vadd.s32 %v49055, %v9 (stack39)
        %v49061 = vshll.u32 %v49052, 6 (stack44)
        %v49062 = vshrl.u32 %v49052, 26 (stack45)
        %v49063 = vor.u32 %v49062, %v49061 (stack46)
        %v49064 = vxor.u32 %v49063, %v49055 (stack47)
        %v49067 = vadd.s32 %v49064, %v8 (stack39)
        %v49071 = vadd.s32 1, %v49067 (stack39)
        %v49075 = vadd.s32 %v49071, %v49059 (stack39)
        %v49077 = vshll.u32 %v49071, 17 (stack44)
        %v49078 = vshrl.u32 %v49071, 15 (stack45)
        %v49079 = vor.u32 %v49078, %v49077 (stack46)
        %v49080 = vxor.u32 %v49079, %v49075 (stack47)
        %v49083 = vadd.s32 %v49080, %v49075 (stack39)
        %v49085 = vshll.u32 %v49080, 29 (stack44)
        %v49086 = vshrl.u32 %v49080, 3 (stack45)
        %v49087 = vor.u32 %v49086, %v49085 (stack46)
        %v49088 = vxor.u32 %v49087, %v49083 (stack47)
        %v49091 = vadd.s32 %v49088, %v49083 (stack39)
        %v49093 = vshll.u32 %v49088, 16 (stack44)
        %v49094 = vshrl.u32 %v49088, 16 (stack45)
        %v49095 = vor.u32 %v49094, %v49093 (stack46)
        %v49096 = vxor.u32 %v49095, %v49091 (stack47)
        %v49099 = vadd.s32 %v49096, %v49091 (stack39)
        %v49103 = vadd.s32 %v49099, %v8 (stack39)
        %v49105 = vshll.u32 %v49096, 24 (stack44)
        %v49106 = vshrl.u32 %v49096, 8 (stack45)
        %v49107 = vor.u32 %v49106, %v49105 (stack46)
        %v49108 = vxor.u32 %v49107, %v49099 (stack47)
        %v49111 = vadd.s32 %v49108, %v10 (stack39)
        %v49115 = vadd.s32 2, %v49111 (stack39)
        %v49119 = vadd.s32 %v49115, %v49103 (stack39)
        %v49121 = vshll.u32 %v49115, 13 (stack44)
        %v49122 = vshrl.u32 %v49115, 19 (stack45)
        %v49123 = vor.u32 %v49122, %v49121 (stack46)
        %v49124 = vxor.u32 %v49123, %v49119 (stack47)
        %v49127 = vadd.s32 %v49124, %v49119 (stack39)
        %v49129 = vshll.u32 %v49124, 15 (stack44)
        %v49130 = vshrl.u32 %v49124, 17 (stack45)
        %v49131 = vor.u32 %v49130, %v49129 (stack46)
        %v49132 = vxor.u32 %v49131, %v49127 (stack47)
        %v49135 = vadd.s32 %v49132, %v49127 (stack39)
        %v49137 = vshll.u32 %v49132, 26 (stack44)
        %v49138 = vshrl.u32 %v49132, 6 (stack45)
        %v49139 = vor.u32 %v49138, %v49137 (stack46)
        %v49140 = vxor.u32 %v49139, %v49135 (stack47)
        %v49143 = vadd.s32 %v49140, %v49135 (stack39)
        %v49147 = vadd.s32 %v49143, %v10 (stack39)
        %v49149 = vshll.u32 %v49140, 6 (stack44)
        %v49150 = vshrl.u32 %v49140, 26 (stack45)
        %v49151 = vor.u32 %v49150, %v49149 (stack46)
        %v49152 = vxor.u32 %v49151, %v49143 (stack47)
        %v49155 = vadd.s32 %v49152, %v9 (stack39)
        %v49159 = vadd.s32 3, %v49155 (stack39)
        %v49163 = vadd.s32 %v49159, %v49147 (stack39)
        %v49165 = vshll.u32 %v49159, 17 (stack44)
        %v49166 = vshrl.u32 %v49159, 15 (stack45)
        %v49167 = vor.u32 %v49166, %v49165 (stack46)
        %v49168 = vxor.u32 %v49167, %v49163 (stack47)
        %v49171 = vadd.s32 %v49168, %v49163 (stack39)
        %v49173 = vshll.u32 %v49168, 29 (stack44)
        %v49174 = vshrl.u32 %v49168, 3 (stack45)
        %v49175 = vor.u32 %v49174, %v49173 (stack46)
        %v49176 = vxor.u32 %v49175, %v49171 (stack47)
        %v49179 = vadd.s32 %v49176, %v49171 (stack39)
        %v49181 = vshll.u32 %v49176, 16 (stack44)
        %v49182 = vshrl.u32 %v49176, 16 (stack45)
        %v49183 = vor.u32 %v49182, %v49181 (stack46)
        %v49184 = vxor.u32 %v49183, %v49179 (stack47)
        %v49187 = vadd.s32 %v49184, %v49179 (stack39)
        %v49191 = vadd.s32 %v49187, %v9 (stack39)
        %v49193 = vshll.u32 %v49184, 24 (stack44)
        %v49194 = vshrl.u32 %v49184, 8 (stack45)
        %v49195 = vor.u32 %v49194, %v49193 (stack46)
        %v49196 = vxor.u32 %v49195, %v49187 (stack47)
        %v49199 = vadd.s32 %v49196, %v8 (stack39)
        %v49203 = vadd.s32 4, %v49199 (stack39)
        %v49207 = vadd.s32 %v49203, %v49191 (stack39)
        %v49209 = vshll.u32 %v49203, 13 (stack44)
        %v49210 = vshrl.u32 %v49203, 19 (stack45)
        %v49211 = vor.u32 %v49210, %v49209 (stack46)
        %v49212 = vxor.u32 %v49211, %v49207 (stack47)
        %v49215 = vadd.s32 %v49212, %v49207 (stack39)
        %v49217 = vshll.u32 %v49212, 15 (stack44)
        %v49218 = vshrl.u32 %v49212, 17 (stack45)
        %v49219 = vor.u32 %v49218, %v49217 (stack46)
        %v49220 = vxor.u32 %v49219, %v49215 (stack47)
        %v49223 = vadd.s32 %v49220, %v49215 (stack39)
        %v49225 = vshll.u32 %v49220, 26 (stack44)
        %v49226 = vshrl.u32 %v49220, 6 (stack45)
        %v49227 = vor.u32 %v49226, %v49225 (stack46)
        %v49228 = vxor.u32 %v49227, %v49223 (stack47)
        %v49231 = vadd.s32 %v49228, %v49223 (stack39)
        %v49235 = vadd.s32 %v49231, %v8 (stack39)
        %v49237 = vshll.u32 %v49228, 6 (stack44)
        %v49238 = vshrl.u32 %v49228, 26 (stack45)
        %v49239 = vor.u32 %v49238, %v49237 (stack46)
        %v49240 = vxor.u32 %v49239, %v49231 (stack47)
        %v49243 = vadd.s32 %v49240, %v10 (stack39)
        %v49247 = vadd.s32 5, %v49243 (stack39)
        %v49249 = vxor.u32 %v49247, %v49235 (stack47)
        %v49250 = vand.u32.u8 255, %v49249 (stack48)
        %v49251 = vand.u32 65535, %v49250 (stack49)
        %v49252 = vshrl.u32 %v49251, 1 (stack50)
        %v49253 = vor.u32 16256, %v49252 (stack46)
        %v49254 = vand.u32.u16 65535, %v49253 (stack51)
        %v120008 = vadd.low.f32.bf16 -1.0, %v49254 (stack52)
        %v49263 = vmul.f32 2.0, %v120008 (stack53)
        %v49267 = vadd.f32 -0.99609375, %v49263 (stack52)
        %v49271 = vmax.f32 %v49267, -0.99609375 (stack54)
        %v49273 = vand.u32 2147483647, %v49271 (stack55)
        %vm49276 = vcmp.eq.f32.partialorder %v49273, 1.0 (stack56)
        %v49281 = vmul.f32 inf, %v49271 (stack53)
        %v49283 = vxor.u32 2147483648, %v49271 (stack57)
        %v49286 = vmul.f32 %v49283, %v49271 (stack53)
        %v49288 = vadd.f32 1.0, %v49286 (stack58)
        %v49289 = vlog2.pop %v49288 (stack59)
        %v49290 = vmul.f32 0.6931472, %v49289 (stack60)
        %v49291 = vmul.f32 -0.5, %v49286 (stack61)
        %v49292 = vadd.f32 1.0, %v49291 (stack62)
        %v49293 = vmul.f32 %v49292, %v49286 (stack63)
        %v49294 = vand.u32 2147483647, %v49286 (stack64)
        %vm49295 = vcmp.lt.f32.partialorder %v49294, 0.0004427343 (stack65)
        %v49296 = vsel /*vm=*/%vm49295, /*on_true_vy=*/%v49293, /*on_false_vx=*/%v49290 (stack66)
        %v49297 = vxor.u32 2147483648, %v49296 (stack57)
        %vm49300 = vcmp.lt.f32.partialorder %v49297, 5.0 (stack56)
        %v49305 = vsel /*vm=*/%vm49300, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v49309 = vsel /*vm=*/%vm49300, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v49313 = vsel /*vm=*/%vm49300, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v49317 = vsel /*vm=*/%vm49300, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v49321 = vsel /*vm=*/%vm49300, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v49325 = vsel /*vm=*/%vm49300, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v49329 = vsel /*vm=*/%vm49300, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v49333 = vsel /*vm=*/%vm49300, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v49337 = vsel /*vm=*/%vm49300, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v49341 = vadd.f32 -2.5, %v49297 (stack52)
        %v49343 = vrsqrt.pop %v49297 (stack67)
        %v49344 = vmul.f32 %v49343, %v49297 (stack68)
        %vm49345 = vcmp.eq.f32.partialorder %v49297, inf (stack69)
        %v49346 = vsel /*vm=*/%vm49345, /*on_true_vy=*/%v49297, /*on_false_vx=*/%v49344 (stack70)
        %vm49347 = vcmp.eq.f32.partialorder %v49297, 0.0 (stack71)
        %v49348 = vand.u32 2147483648, %v49297 (stack72)
        %v49349 = vsel /*vm=*/%vm49347, /*on_true_vy=*/%v49348, /*on_false_vx=*/%v49346 (stack73)
        %v49352 = vadd.f32 -3.0, %v49349 (stack52)
        %v49356 = vsel /*vm=*/%vm49300, /*on_true_vy=*/%v49341, /*on_false_vx=*/%v49352 (stack43)
        %v49360 = vmul.f32 %v49356, %v49337 (stack53)
        %v49364 = vadd.f32 %v49360, %v49333 (stack52)
        %v49368 = vmul.f32 %v49364, %v49356 (stack53)
        %v49372 = vadd.f32 %v49368, %v49329 (stack52)
        %v49376 = vmul.f32 %v49372, %v49356 (stack53)
        %v49380 = vadd.f32 %v49376, %v49325 (stack52)
        %v49384 = vmul.f32 %v49380, %v49356 (stack53)
        %v49388 = vadd.f32 %v49384, %v49321 (stack52)
        %v49392 = vmul.f32 %v49388, %v49356 (stack53)
        %v49396 = vadd.f32 %v49392, %v49317 (stack52)
        %v49400 = vmul.f32 %v49396, %v49356 (stack53)
        %v49404 = vadd.f32 %v49400, %v49313 (stack52)
        %v49408 = vmul.f32 %v49404, %v49356 (stack53)
        %v49412 = vadd.f32 %v49408, %v49309 (stack52)
        %v49416 = vmul.f32 %v49412, %v49356 (stack53)
        %v49420 = vadd.f32 %v49416, %v49305 (stack52)
        %v49424 = vmul.f32 %v49420, %v49271 (stack53)
        %v49428 = vsel /*vm=*/%vm49276, /*on_true_vy=*/%v49281, /*on_false_vx=*/%v49424 (stack43)
        %v49432 = vmul.f32 1.4140625, %v49428 (stack53)
        %v49435 = vpack.c.bf16 0.0, %v49432 (stack74)
        %120009 = vst [vmem:[%s280 + $0x34] sm:$0xf] /*vst_source=*/%v49435 (stack75)
        %v49439 = vadd.s32 %v48975, %v894 (stack39)
        %v49449 = vadd.s32 %v49439, %v415 (stack39)
        %vm49453 = vcmp.lt.u32.totalorder %v49449, %v49439 (stack42)
        %vm49458 = vcmp.lt.u32.totalorder %v49439, %v894 (stack42)
        %v49463 = vadd.s32 %v48958, %v881 (stack39)
        %v49467 = vadd.s32 1, %v49463 (stack39)
        %v49471 = vsel /*vm=*/%vm49458, /*on_true_vy=*/%v49467, /*on_false_vx=*/%v49463 (stack43)
        %v49475 = vadd.s32 1, %v49471 (stack39)
        %v49479 = vsel /*vm=*/%vm49453, /*on_true_vy=*/%v49475, /*on_false_vx=*/%v49471 (stack43)
        %v49484 = vadd.s32 %v49479, %v10 (stack39)
        %v49488 = vadd.s32 %v49449, %v9 (stack39)
        %v49492 = vadd.s32 %v49488, %v49484 (stack39)
        %v49494 = vshll.u32 %v49488, 13 (stack44)
        %v49495 = vshrl.u32 %v49488, 19 (stack45)
        %v49496 = vor.u32 %v49495, %v49494 (stack46)
        %v49497 = vxor.u32 %v49496, %v49492 (stack47)
        %v49500 = vadd.s32 %v49497, %v49492 (stack39)
        %v49502 = vshll.u32 %v49497, 15 (stack44)
        %v49503 = vshrl.u32 %v49497, 17 (stack45)
        %v49504 = vor.u32 %v49503, %v49502 (stack46)
        %v49505 = vxor.u32 %v49504, %v49500 (stack47)
        %v49508 = vadd.s32 %v49505, %v49500 (stack39)
        %v49510 = vshll.u32 %v49505, 26 (stack44)
        %v49511 = vshrl.u32 %v49505, 6 (stack45)
        %v49512 = vor.u32 %v49511, %v49510 (stack46)
        %v49513 = vxor.u32 %v49512, %v49508 (stack47)
        %v49516 = vadd.s32 %v49513, %v49508 (stack39)
        %v49520 = vadd.s32 %v49516, %v9 (stack39)
        %v49522 = vshll.u32 %v49513, 6 (stack44)
        %v49523 = vshrl.u32 %v49513, 26 (stack45)
        %v49524 = vor.u32 %v49523, %v49522 (stack46)
        %v49525 = vxor.u32 %v49524, %v49516 (stack47)
        %v49528 = vadd.s32 %v49525, %v8 (stack39)
        %v49532 = vadd.s32 1, %v49528 (stack39)
        %v49536 = vadd.s32 %v49532, %v49520 (stack39)
        %v49538 = vshll.u32 %v49532, 17 (stack44)
        %v49539 = vshrl.u32 %v49532, 15 (stack45)
        %v49540 = vor.u32 %v49539, %v49538 (stack46)
        %v49541 = vxor.u32 %v49540, %v49536 (stack47)
        %v49544 = vadd.s32 %v49541, %v49536 (stack39)
        %v49546 = vshll.u32 %v49541, 29 (stack44)
        %v49547 = vshrl.u32 %v49541, 3 (stack45)
        %v49548 = vor.u32 %v49547, %v49546 (stack46)
        %v49549 = vxor.u32 %v49548, %v49544 (stack47)
        %v49552 = vadd.s32 %v49549, %v49544 (stack39)
        %v49554 = vshll.u32 %v49549, 16 (stack44)
        %v49555 = vshrl.u32 %v49549, 16 (stack45)
        %v49556 = vor.u32 %v49555, %v49554 (stack46)
        %v49557 = vxor.u32 %v49556, %v49552 (stack47)
        %v49560 = vadd.s32 %v49557, %v49552 (stack39)
        %v49564 = vadd.s32 %v49560, %v8 (stack39)
        %v49566 = vshll.u32 %v49557, 24 (stack44)
        %v49567 = vshrl.u32 %v49557, 8 (stack45)
        %v49568 = vor.u32 %v49567, %v49566 (stack46)
        %v49569 = vxor.u32 %v49568, %v49560 (stack47)
        %v49572 = vadd.s32 %v49569, %v10 (stack39)
        %v49576 = vadd.s32 2, %v49572 (stack39)
        %v49580 = vadd.s32 %v49576, %v49564 (stack39)
        %v49582 = vshll.u32 %v49576, 13 (stack44)
        %v49583 = vshrl.u32 %v49576, 19 (stack45)
        %v49584 = vor.u32 %v49583, %v49582 (stack46)
        %v49585 = vxor.u32 %v49584, %v49580 (stack47)
        %v49588 = vadd.s32 %v49585, %v49580 (stack39)
        %v49590 = vshll.u32 %v49585, 15 (stack44)
        %v49591 = vshrl.u32 %v49585, 17 (stack45)
        %v49592 = vor.u32 %v49591, %v49590 (stack46)
        %v49593 = vxor.u32 %v49592, %v49588 (stack47)
        %v49596 = vadd.s32 %v49593, %v49588 (stack39)
        %v49598 = vshll.u32 %v49593, 26 (stack44)
        %v49599 = vshrl.u32 %v49593, 6 (stack45)
        %v49600 = vor.u32 %v49599, %v49598 (stack46)
        %v49601 = vxor.u32 %v49600, %v49596 (stack47)
        %v49604 = vadd.s32 %v49601, %v49596 (stack39)
        %v49608 = vadd.s32 %v49604, %v10 (stack39)
        %v49610 = vshll.u32 %v49601, 6 (stack44)
        %v49611 = vshrl.u32 %v49601, 26 (stack45)
        %v49612 = vor.u32 %v49611, %v49610 (stack46)
        %v49613 = vxor.u32 %v49612, %v49604 (stack47)
        %v49616 = vadd.s32 %v49613, %v9 (stack39)
        %v49620 = vadd.s32 3, %v49616 (stack39)
        %v49624 = vadd.s32 %v49620, %v49608 (stack39)
        %v49626 = vshll.u32 %v49620, 17 (stack44)
        %v49627 = vshrl.u32 %v49620, 15 (stack45)
        %v49628 = vor.u32 %v49627, %v49626 (stack46)
        %v49629 = vxor.u32 %v49628, %v49624 (stack47)
        %v49632 = vadd.s32 %v49629, %v49624 (stack39)
        %v49634 = vshll.u32 %v49629, 29 (stack44)
        %v49635 = vshrl.u32 %v49629, 3 (stack45)
        %v49636 = vor.u32 %v49635, %v49634 (stack46)
        %v49637 = vxor.u32 %v49636, %v49632 (stack47)
        %v49640 = vadd.s32 %v49637, %v49632 (stack39)
        %v49642 = vshll.u32 %v49637, 16 (stack44)
        %v49643 = vshrl.u32 %v49637, 16 (stack45)
        %v49644 = vor.u32 %v49643, %v49642 (stack46)
        %v49645 = vxor.u32 %v49644, %v49640 (stack47)
        %v49648 = vadd.s32 %v49645, %v49640 (stack39)
        %v49652 = vadd.s32 %v49648, %v9 (stack39)
        %v49654 = vshll.u32 %v49645, 24 (stack44)
        %v49655 = vshrl.u32 %v49645, 8 (stack45)
        %v49656 = vor.u32 %v49655, %v49654 (stack46)
        %v49657 = vxor.u32 %v49656, %v49648 (stack47)
        %v49660 = vadd.s32 %v49657, %v8 (stack39)
        %v49664 = vadd.s32 4, %v49660 (stack39)
        %v49668 = vadd.s32 %v49664, %v49652 (stack39)
        %v49670 = vshll.u32 %v49664, 13 (stack44)
        %v49671 = vshrl.u32 %v49664, 19 (stack45)
        %v49672 = vor.u32 %v49671, %v49670 (stack46)
        %v49673 = vxor.u32 %v49672, %v49668 (stack47)
        %v49676 = vadd.s32 %v49673, %v49668 (stack39)
        %v49678 = vshll.u32 %v49673, 15 (stack44)
        %v49679 = vshrl.u32 %v49673, 17 (stack45)
        %v49680 = vor.u32 %v49679, %v49678 (stack46)
        %v49681 = vxor.u32 %v49680, %v49676 (stack47)
        %v49684 = vadd.s32 %v49681, %v49676 (stack39)
        %v49686 = vshll.u32 %v49681, 26 (stack44)
        %v49687 = vshrl.u32 %v49681, 6 (stack45)
        %v49688 = vor.u32 %v49687, %v49686 (stack46)
        %v49689 = vxor.u32 %v49688, %v49684 (stack47)
        %v49692 = vadd.s32 %v49689, %v49684 (stack39)
        %v49696 = vadd.s32 %v49692, %v8 (stack39)
        %v49698 = vshll.u32 %v49689, 6 (stack44)
        %v49699 = vshrl.u32 %v49689, 26 (stack45)
        %v49700 = vor.u32 %v49699, %v49698 (stack46)
        %v49701 = vxor.u32 %v49700, %v49692 (stack47)
        %v49704 = vadd.s32 %v49701, %v10 (stack39)
        %v49708 = vadd.s32 5, %v49704 (stack39)
        %v49710 = vxor.u32 %v49708, %v49696 (stack47)
        %v49711 = vand.u32.u8 255, %v49710 (stack48)
        %v49712 = vand.u32 65535, %v49711 (stack49)
        %v49713 = vshrl.u32 %v49712, 1 (stack50)
        %v49714 = vor.u32 16256, %v49713 (stack46)
        %v49715 = vand.u32.u16 65535, %v49714 (stack51)
        %v120010 = vadd.low.f32.bf16 -1.0, %v49715 (stack52)
        %v49724 = vmul.f32 2.0, %v120010 (stack53)
        %v49728 = vadd.f32 -0.99609375, %v49724 (stack52)
        %v49732 = vmax.f32 %v49728, -0.99609375 (stack54)
        %v49734 = vand.u32 2147483647, %v49732 (stack55)
        %vm49737 = vcmp.eq.f32.partialorder %v49734, 1.0 (stack56)
        %v49742 = vmul.f32 inf, %v49732 (stack53)
        %v49744 = vxor.u32 2147483648, %v49732 (stack57)
        %v49747 = vmul.f32 %v49744, %v49732 (stack53)
        %v49749 = vadd.f32 1.0, %v49747 (stack58)
        %v49750 = vlog2.pop %v49749 (stack59)
        %v49751 = vmul.f32 0.6931472, %v49750 (stack60)
        %v49752 = vmul.f32 -0.5, %v49747 (stack61)
        %v49753 = vadd.f32 1.0, %v49752 (stack62)
        %v49754 = vmul.f32 %v49753, %v49747 (stack63)
        %v49755 = vand.u32 2147483647, %v49747 (stack64)
        %vm49756 = vcmp.lt.f32.partialorder %v49755, 0.0004427343 (stack65)
        %v49757 = vsel /*vm=*/%vm49756, /*on_true_vy=*/%v49754, /*on_false_vx=*/%v49751 (stack66)
        %v49758 = vxor.u32 2147483648, %v49757 (stack57)
        %vm49761 = vcmp.lt.f32.partialorder %v49758, 5.0 (stack56)
        %v49766 = vsel /*vm=*/%vm49761, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v49770 = vsel /*vm=*/%vm49761, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v49774 = vsel /*vm=*/%vm49761, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v49778 = vsel /*vm=*/%vm49761, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v49782 = vsel /*vm=*/%vm49761, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v49786 = vsel /*vm=*/%vm49761, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v49790 = vsel /*vm=*/%vm49761, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v49794 = vsel /*vm=*/%vm49761, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v49798 = vsel /*vm=*/%vm49761, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v49802 = vadd.f32 -2.5, %v49758 (stack52)
        %v49804 = vrsqrt.pop %v49758 (stack67)
        %v49805 = vmul.f32 %v49804, %v49758 (stack68)
        %vm49806 = vcmp.eq.f32.partialorder %v49758, inf (stack69)
        %v49807 = vsel /*vm=*/%vm49806, /*on_true_vy=*/%v49758, /*on_false_vx=*/%v49805 (stack70)
        %vm49808 = vcmp.eq.f32.partialorder %v49758, 0.0 (stack71)
        %v49809 = vand.u32 2147483648, %v49758 (stack72)
        %v49810 = vsel /*vm=*/%vm49808, /*on_true_vy=*/%v49809, /*on_false_vx=*/%v49807 (stack73)
        %v49813 = vadd.f32 -3.0, %v49810 (stack52)
        %v49817 = vsel /*vm=*/%vm49761, /*on_true_vy=*/%v49802, /*on_false_vx=*/%v49813 (stack43)
        %v49821 = vmul.f32 %v49817, %v49798 (stack53)
        %v49825 = vadd.f32 %v49821, %v49794 (stack52)
        %v49829 = vmul.f32 %v49825, %v49817 (stack53)
        %v49833 = vadd.f32 %v49829, %v49790 (stack52)
        %v49837 = vmul.f32 %v49833, %v49817 (stack53)
        %v49841 = vadd.f32 %v49837, %v49786 (stack52)
        %v49845 = vmul.f32 %v49841, %v49817 (stack53)
        %v49849 = vadd.f32 %v49845, %v49782 (stack52)
        %v49853 = vmul.f32 %v49849, %v49817 (stack53)
        %v49857 = vadd.f32 %v49853, %v49778 (stack52)
        %v49861 = vmul.f32 %v49857, %v49817 (stack53)
        %v49865 = vadd.f32 %v49861, %v49774 (stack52)
        %v49869 = vmul.f32 %v49865, %v49817 (stack53)
        %v49873 = vadd.f32 %v49869, %v49770 (stack52)
        %v49877 = vmul.f32 %v49873, %v49817 (stack53)
        %v49881 = vadd.f32 %v49877, %v49766 (stack52)
        %v49885 = vmul.f32 %v49881, %v49732 (stack53)
        %v49889 = vsel /*vm=*/%vm49737, /*on_true_vy=*/%v49742, /*on_false_vx=*/%v49885 (stack43)
        %v49893 = vmul.f32 1.4140625, %v49889 (stack53)
        %v49896 = vpack.c.bf16 0.0, %v49893 (stack74)
        %120011 = vst [vmem:[%s280 + $0xb4] sm:$0xf] /*vst_source=*/%v49896 (stack75)
        %v49900 = vadd.s32 %v48975, %v1381 (stack39)
        %v49910 = vadd.s32 %v49900, %v415 (stack39)
        %vm49914 = vcmp.lt.u32.totalorder %v49910, %v49900 (stack42)
        %vm49919 = vcmp.lt.u32.totalorder %v49900, %v1381 (stack42)
        %v49924 = vadd.s32 %v48958, %v1368 (stack39)
        %v49928 = vadd.s32 1, %v49924 (stack39)
        %v49932 = vsel /*vm=*/%vm49919, /*on_true_vy=*/%v49928, /*on_false_vx=*/%v49924 (stack43)
        %v49936 = vadd.s32 1, %v49932 (stack39)
        %v49940 = vsel /*vm=*/%vm49914, /*on_true_vy=*/%v49936, /*on_false_vx=*/%v49932 (stack43)
        %v49945 = vadd.s32 %v49940, %v10 (stack39)
        %v49949 = vadd.s32 %v49910, %v9 (stack39)
        %v49953 = vadd.s32 %v49949, %v49945 (stack39)
        %v49955 = vshll.u32 %v49949, 13 (stack44)
        %v49956 = vshrl.u32 %v49949, 19 (stack45)
        %v49957 = vor.u32 %v49956, %v49955 (stack46)
        %v49958 = vxor.u32 %v49957, %v49953 (stack47)
        %v49961 = vadd.s32 %v49958, %v49953 (stack39)
        %v49963 = vshll.u32 %v49958, 15 (stack44)
        %v49964 = vshrl.u32 %v49958, 17 (stack45)
        %v49965 = vor.u32 %v49964, %v49963 (stack46)
        %v49966 = vxor.u32 %v49965, %v49961 (stack47)
        %v49969 = vadd.s32 %v49966, %v49961 (stack39)
        %v49971 = vshll.u32 %v49966, 26 (stack44)
        %v49972 = vshrl.u32 %v49966, 6 (stack45)
        %v49973 = vor.u32 %v49972, %v49971 (stack46)
        %v49974 = vxor.u32 %v49973, %v49969 (stack47)
        %v49977 = vadd.s32 %v49974, %v49969 (stack39)
        %v49981 = vadd.s32 %v49977, %v9 (stack39)
        %v49983 = vshll.u32 %v49974, 6 (stack44)
        %v49984 = vshrl.u32 %v49974, 26 (stack45)
        %v49985 = vor.u32 %v49984, %v49983 (stack46)
        %v49986 = vxor.u32 %v49985, %v49977 (stack47)
        %v49989 = vadd.s32 %v49986, %v8 (stack39)
        %v49993 = vadd.s32 1, %v49989 (stack39)
        %v49997 = vadd.s32 %v49993, %v49981 (stack39)
        %v49999 = vshll.u32 %v49993, 17 (stack44)
        %v50000 = vshrl.u32 %v49993, 15 (stack45)
        %v50001 = vor.u32 %v50000, %v49999 (stack46)
        %v50002 = vxor.u32 %v50001, %v49997 (stack47)
        %v50005 = vadd.s32 %v50002, %v49997 (stack39)
        %v50007 = vshll.u32 %v50002, 29 (stack44)
        %v50008 = vshrl.u32 %v50002, 3 (stack45)
        %v50009 = vor.u32 %v50008, %v50007 (stack46)
        %v50010 = vxor.u32 %v50009, %v50005 (stack47)
        %v50013 = vadd.s32 %v50010, %v50005 (stack39)
        %v50015 = vshll.u32 %v50010, 16 (stack44)
        %v50016 = vshrl.u32 %v50010, 16 (stack45)
        %v50017 = vor.u32 %v50016, %v50015 (stack46)
        %v50018 = vxor.u32 %v50017, %v50013 (stack47)
        %v50021 = vadd.s32 %v50018, %v50013 (stack39)
        %v50025 = vadd.s32 %v50021, %v8 (stack39)
        %v50027 = vshll.u32 %v50018, 24 (stack44)
        %v50028 = vshrl.u32 %v50018, 8 (stack45)
        %v50029 = vor.u32 %v50028, %v50027 (stack46)
        %v50030 = vxor.u32 %v50029, %v50021 (stack47)
        %v50033 = vadd.s32 %v50030, %v10 (stack39)
        %v50037 = vadd.s32 2, %v50033 (stack39)
        %v50041 = vadd.s32 %v50037, %v50025 (stack39)
        %v50043 = vshll.u32 %v50037, 13 (stack44)
        %v50044 = vshrl.u32 %v50037, 19 (stack45)
        %v50045 = vor.u32 %v50044, %v50043 (stack46)
        %v50046 = vxor.u32 %v50045, %v50041 (stack47)
        %v50049 = vadd.s32 %v50046, %v50041 (stack39)
        %v50051 = vshll.u32 %v50046, 15 (stack44)
        %v50052 = vshrl.u32 %v50046, 17 (stack45)
        %v50053 = vor.u32 %v50052, %v50051 (stack46)
        %v50054 = vxor.u32 %v50053, %v50049 (stack47)
        %v50057 = vadd.s32 %v50054, %v50049 (stack39)
        %v50059 = vshll.u32 %v50054, 26 (stack44)
        %v50060 = vshrl.u32 %v50054, 6 (stack45)
        %v50061 = vor.u32 %v50060, %v50059 (stack46)
        %v50062 = vxor.u32 %v50061, %v50057 (stack47)
        %v50065 = vadd.s32 %v50062, %v50057 (stack39)
        %v50069 = vadd.s32 %v50065, %v10 (stack39)
        %v50071 = vshll.u32 %v50062, 6 (stack44)
        %v50072 = vshrl.u32 %v50062, 26 (stack45)
        %v50073 = vor.u32 %v50072, %v50071 (stack46)
        %v50074 = vxor.u32 %v50073, %v50065 (stack47)
        %v50077 = vadd.s32 %v50074, %v9 (stack39)
        %v50081 = vadd.s32 3, %v50077 (stack39)
        %v50085 = vadd.s32 %v50081, %v50069 (stack39)
        %v50087 = vshll.u32 %v50081, 17 (stack44)
        %v50088 = vshrl.u32 %v50081, 15 (stack45)
        %v50089 = vor.u32 %v50088, %v50087 (stack46)
        %v50090 = vxor.u32 %v50089, %v50085 (stack47)
        %v50093 = vadd.s32 %v50090, %v50085 (stack39)
        %v50095 = vshll.u32 %v50090, 29 (stack44)
        %v50096 = vshrl.u32 %v50090, 3 (stack45)
        %v50097 = vor.u32 %v50096, %v50095 (stack46)
        %v50098 = vxor.u32 %v50097, %v50093 (stack47)
        %v50101 = vadd.s32 %v50098, %v50093 (stack39)
        %v50103 = vshll.u32 %v50098, 16 (stack44)
        %v50104 = vshrl.u32 %v50098, 16 (stack45)
        %v50105 = vor.u32 %v50104, %v50103 (stack46)
        %v50106 = vxor.u32 %v50105, %v50101 (stack47)
        %v50109 = vadd.s32 %v50106, %v50101 (stack39)
        %v50113 = vadd.s32 %v50109, %v9 (stack39)
        %v50115 = vshll.u32 %v50106, 24 (stack44)
        %v50116 = vshrl.u32 %v50106, 8 (stack45)
        %v50117 = vor.u32 %v50116, %v50115 (stack46)
        %v50118 = vxor.u32 %v50117, %v50109 (stack47)
        %v50121 = vadd.s32 %v50118, %v8 (stack39)
        %v50125 = vadd.s32 4, %v50121 (stack39)
        %v50129 = vadd.s32 %v50125, %v50113 (stack39)
        %v50131 = vshll.u32 %v50125, 13 (stack44)
        %v50132 = vshrl.u32 %v50125, 19 (stack45)
        %v50133 = vor.u32 %v50132, %v50131 (stack46)
        %v50134 = vxor.u32 %v50133, %v50129 (stack47)
        %v50137 = vadd.s32 %v50134, %v50129 (stack39)
        %v50139 = vshll.u32 %v50134, 15 (stack44)
        %v50140 = vshrl.u32 %v50134, 17 (stack45)
        %v50141 = vor.u32 %v50140, %v50139 (stack46)
        %v50142 = vxor.u32 %v50141, %v50137 (stack47)
        %v50145 = vadd.s32 %v50142, %v50137 (stack39)
        %v50147 = vshll.u32 %v50142, 26 (stack44)
        %v50148 = vshrl.u32 %v50142, 6 (stack45)
        %v50149 = vor.u32 %v50148, %v50147 (stack46)
        %v50150 = vxor.u32 %v50149, %v50145 (stack47)
        %v50153 = vadd.s32 %v50150, %v50145 (stack39)
        %v50157 = vadd.s32 %v50153, %v8 (stack39)
        %v50159 = vshll.u32 %v50150, 6 (stack44)
        %v50160 = vshrl.u32 %v50150, 26 (stack45)
        %v50161 = vor.u32 %v50160, %v50159 (stack46)
        %v50162 = vxor.u32 %v50161, %v50153 (stack47)
        %v50165 = vadd.s32 %v50162, %v10 (stack39)
        %v50169 = vadd.s32 5, %v50165 (stack39)
        %v50171 = vxor.u32 %v50169, %v50157 (stack47)
        %v50172 = vand.u32.u8 255, %v50171 (stack48)
        %v50173 = vand.u32 65535, %v50172 (stack49)
        %v50174 = vshrl.u32 %v50173, 1 (stack50)
        %v50175 = vor.u32 16256, %v50174 (stack46)
        %v50176 = vand.u32.u16 65535, %v50175 (stack51)
        %v120012 = vadd.low.f32.bf16 -1.0, %v50176 (stack52)
        %v50185 = vmul.f32 2.0, %v120012 (stack53)
        %v50189 = vadd.f32 -0.99609375, %v50185 (stack52)
        %v50193 = vmax.f32 %v50189, -0.99609375 (stack54)
        %v50195 = vand.u32 2147483647, %v50193 (stack55)
        %vm50198 = vcmp.eq.f32.partialorder %v50195, 1.0 (stack56)
        %v50203 = vmul.f32 inf, %v50193 (stack53)
        %v50205 = vxor.u32 2147483648, %v50193 (stack57)
        %v50208 = vmul.f32 %v50205, %v50193 (stack53)
        %v50210 = vadd.f32 1.0, %v50208 (stack58)
        %v50211 = vlog2.pop %v50210 (stack59)
        %v50212 = vmul.f32 0.6931472, %v50211 (stack60)
        %v50213 = vmul.f32 -0.5, %v50208 (stack61)
        %v50214 = vadd.f32 1.0, %v50213 (stack62)
        %v50215 = vmul.f32 %v50214, %v50208 (stack63)
        %v50216 = vand.u32 2147483647, %v50208 (stack64)
        %vm50217 = vcmp.lt.f32.partialorder %v50216, 0.0004427343 (stack65)
        %v50218 = vsel /*vm=*/%vm50217, /*on_true_vy=*/%v50215, /*on_false_vx=*/%v50212 (stack66)
        %v50219 = vxor.u32 2147483648, %v50218 (stack57)
        %vm50222 = vcmp.lt.f32.partialorder %v50219, 5.0 (stack56)
        %v50227 = vsel /*vm=*/%vm50222, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v50231 = vsel /*vm=*/%vm50222, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v50235 = vsel /*vm=*/%vm50222, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v50239 = vsel /*vm=*/%vm50222, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v50243 = vsel /*vm=*/%vm50222, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v50247 = vsel /*vm=*/%vm50222, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v50251 = vsel /*vm=*/%vm50222, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v50255 = vsel /*vm=*/%vm50222, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v50259 = vsel /*vm=*/%vm50222, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v50263 = vadd.f32 -2.5, %v50219 (stack52)
        %v50265 = vrsqrt.pop %v50219 (stack67)
        %v50266 = vmul.f32 %v50265, %v50219 (stack68)
        %vm50267 = vcmp.eq.f32.partialorder %v50219, inf (stack69)
        %v50268 = vsel /*vm=*/%vm50267, /*on_true_vy=*/%v50219, /*on_false_vx=*/%v50266 (stack70)
        %vm50269 = vcmp.eq.f32.partialorder %v50219, 0.0 (stack71)
        %v50270 = vand.u32 2147483648, %v50219 (stack72)
        %v50271 = vsel /*vm=*/%vm50269, /*on_true_vy=*/%v50270, /*on_false_vx=*/%v50268 (stack73)
        %v50274 = vadd.f32 -3.0, %v50271 (stack52)
        %v50278 = vsel /*vm=*/%vm50222, /*on_true_vy=*/%v50263, /*on_false_vx=*/%v50274 (stack43)
        %v50282 = vmul.f32 %v50278, %v50259 (stack53)
        %v50286 = vadd.f32 %v50282, %v50255 (stack52)
        %v50290 = vmul.f32 %v50286, %v50278 (stack53)
        %v50294 = vadd.f32 %v50290, %v50251 (stack52)
        %v50298 = vmul.f32 %v50294, %v50278 (stack53)
        %v50302 = vadd.f32 %v50298, %v50247 (stack52)
        %v50306 = vmul.f32 %v50302, %v50278 (stack53)
        %v50310 = vadd.f32 %v50306, %v50243 (stack52)
        %v50314 = vmul.f32 %v50310, %v50278 (stack53)
        %v50318 = vadd.f32 %v50314, %v50239 (stack52)
        %v50322 = vmul.f32 %v50318, %v50278 (stack53)
        %v50326 = vadd.f32 %v50322, %v50235 (stack52)
        %v50330 = vmul.f32 %v50326, %v50278 (stack53)
        %v50334 = vadd.f32 %v50330, %v50231 (stack52)
        %v50338 = vmul.f32 %v50334, %v50278 (stack53)
        %v50342 = vadd.f32 %v50338, %v50227 (stack52)
        %v50346 = vmul.f32 %v50342, %v50193 (stack53)
        %v50350 = vsel /*vm=*/%vm50198, /*on_true_vy=*/%v50203, /*on_false_vx=*/%v50346 (stack43)
        %v50354 = vmul.f32 1.4140625, %v50350 (stack53)
        %v50357 = vpack.c.bf16 0.0, %v50354 (stack74)
        %120013 = vst [vmem:[%s280 + $0x134] sm:$0xf] /*vst_source=*/%v50357 (stack75)
        %v50361 = vadd.s32 %v48975, %v1868 (stack39)
        %v50371 = vadd.s32 %v50361, %v415 (stack39)
        %vm50375 = vcmp.lt.u32.totalorder %v50371, %v50361 (stack42)
        %vm50380 = vcmp.lt.u32.totalorder %v50361, %v1868 (stack42)
        %v50385 = vadd.s32 %v48958, %v1855 (stack39)
        %v50389 = vadd.s32 1, %v50385 (stack39)
        %v50393 = vsel /*vm=*/%vm50380, /*on_true_vy=*/%v50389, /*on_false_vx=*/%v50385 (stack43)
        %v50397 = vadd.s32 1, %v50393 (stack39)
        %v50401 = vsel /*vm=*/%vm50375, /*on_true_vy=*/%v50397, /*on_false_vx=*/%v50393 (stack43)
        %v50406 = vadd.s32 %v50401, %v10 (stack39)
        %v50410 = vadd.s32 %v50371, %v9 (stack39)
        %v50414 = vadd.s32 %v50410, %v50406 (stack39)
        %v50416 = vshll.u32 %v50410, 13 (stack44)
        %v50417 = vshrl.u32 %v50410, 19 (stack45)
        %v50418 = vor.u32 %v50417, %v50416 (stack46)
        %v50419 = vxor.u32 %v50418, %v50414 (stack47)
        %v50422 = vadd.s32 %v50419, %v50414 (stack39)
        %v50424 = vshll.u32 %v50419, 15 (stack44)
        %v50425 = vshrl.u32 %v50419, 17 (stack45)
        %v50426 = vor.u32 %v50425, %v50424 (stack46)
        %v50427 = vxor.u32 %v50426, %v50422 (stack47)
        %v50430 = vadd.s32 %v50427, %v50422 (stack39)
        %v50432 = vshll.u32 %v50427, 26 (stack44)
        %v50433 = vshrl.u32 %v50427, 6 (stack45)
        %v50434 = vor.u32 %v50433, %v50432 (stack46)
        %v50435 = vxor.u32 %v50434, %v50430 (stack47)
        %v50438 = vadd.s32 %v50435, %v50430 (stack39)
        %v50442 = vadd.s32 %v50438, %v9 (stack39)
        %v50444 = vshll.u32 %v50435, 6 (stack44)
        %v50445 = vshrl.u32 %v50435, 26 (stack45)
        %v50446 = vor.u32 %v50445, %v50444 (stack46)
        %v50447 = vxor.u32 %v50446, %v50438 (stack47)
        %v50450 = vadd.s32 %v50447, %v8 (stack39)
        %v50454 = vadd.s32 1, %v50450 (stack39)
        %v50458 = vadd.s32 %v50454, %v50442 (stack39)
        %v50460 = vshll.u32 %v50454, 17 (stack44)
        %v50461 = vshrl.u32 %v50454, 15 (stack45)
        %v50462 = vor.u32 %v50461, %v50460 (stack46)
        %v50463 = vxor.u32 %v50462, %v50458 (stack47)
        %v50466 = vadd.s32 %v50463, %v50458 (stack39)
        %v50468 = vshll.u32 %v50463, 29 (stack44)
        %v50469 = vshrl.u32 %v50463, 3 (stack45)
        %v50470 = vor.u32 %v50469, %v50468 (stack46)
        %v50471 = vxor.u32 %v50470, %v50466 (stack47)
        %v50474 = vadd.s32 %v50471, %v50466 (stack39)
        %v50476 = vshll.u32 %v50471, 16 (stack44)
        %v50477 = vshrl.u32 %v50471, 16 (stack45)
        %v50478 = vor.u32 %v50477, %v50476 (stack46)
        %v50479 = vxor.u32 %v50478, %v50474 (stack47)
        %v50482 = vadd.s32 %v50479, %v50474 (stack39)
        %v50486 = vadd.s32 %v50482, %v8 (stack39)
        %v50488 = vshll.u32 %v50479, 24 (stack44)
        %v50489 = vshrl.u32 %v50479, 8 (stack45)
        %v50490 = vor.u32 %v50489, %v50488 (stack46)
        %v50491 = vxor.u32 %v50490, %v50482 (stack47)
        %v50494 = vadd.s32 %v50491, %v10 (stack39)
        %v50498 = vadd.s32 2, %v50494 (stack39)
        %v50502 = vadd.s32 %v50498, %v50486 (stack39)
        %v50504 = vshll.u32 %v50498, 13 (stack44)
        %v50505 = vshrl.u32 %v50498, 19 (stack45)
        %v50506 = vor.u32 %v50505, %v50504 (stack46)
        %v50507 = vxor.u32 %v50506, %v50502 (stack47)
        %v50510 = vadd.s32 %v50507, %v50502 (stack39)
        %v50512 = vshll.u32 %v50507, 15 (stack44)
        %v50513 = vshrl.u32 %v50507, 17 (stack45)
        %v50514 = vor.u32 %v50513, %v50512 (stack46)
        %v50515 = vxor.u32 %v50514, %v50510 (stack47)
        %v50518 = vadd.s32 %v50515, %v50510 (stack39)
        %v50520 = vshll.u32 %v50515, 26 (stack44)
        %v50521 = vshrl.u32 %v50515, 6 (stack45)
        %v50522 = vor.u32 %v50521, %v50520 (stack46)
        %v50523 = vxor.u32 %v50522, %v50518 (stack47)
        %v50526 = vadd.s32 %v50523, %v50518 (stack39)
        %v50530 = vadd.s32 %v50526, %v10 (stack39)
        %v50532 = vshll.u32 %v50523, 6 (stack44)
        %v50533 = vshrl.u32 %v50523, 26 (stack45)
        %v50534 = vor.u32 %v50533, %v50532 (stack46)
        %v50535 = vxor.u32 %v50534, %v50526 (stack47)
        %v50538 = vadd.s32 %v50535, %v9 (stack39)
        %v50542 = vadd.s32 3, %v50538 (stack39)
        %v50546 = vadd.s32 %v50542, %v50530 (stack39)
        %v50548 = vshll.u32 %v50542, 17 (stack44)
        %v50549 = vshrl.u32 %v50542, 15 (stack45)
        %v50550 = vor.u32 %v50549, %v50548 (stack46)
        %v50551 = vxor.u32 %v50550, %v50546 (stack47)
        %v50554 = vadd.s32 %v50551, %v50546 (stack39)
        %v50556 = vshll.u32 %v50551, 29 (stack44)
        %v50557 = vshrl.u32 %v50551, 3 (stack45)
        %v50558 = vor.u32 %v50557, %v50556 (stack46)
        %v50559 = vxor.u32 %v50558, %v50554 (stack47)
        %v50562 = vadd.s32 %v50559, %v50554 (stack39)
        %v50564 = vshll.u32 %v50559, 16 (stack44)
        %v50565 = vshrl.u32 %v50559, 16 (stack45)
        %v50566 = vor.u32 %v50565, %v50564 (stack46)
        %v50567 = vxor.u32 %v50566, %v50562 (stack47)
        %v50570 = vadd.s32 %v50567, %v50562 (stack39)
        %v50574 = vadd.s32 %v50570, %v9 (stack39)
        %v50576 = vshll.u32 %v50567, 24 (stack44)
        %v50577 = vshrl.u32 %v50567, 8 (stack45)
        %v50578 = vor.u32 %v50577, %v50576 (stack46)
        %v50579 = vxor.u32 %v50578, %v50570 (stack47)
        %v50582 = vadd.s32 %v50579, %v8 (stack39)
        %v50586 = vadd.s32 4, %v50582 (stack39)
        %v50590 = vadd.s32 %v50586, %v50574 (stack39)
        %v50592 = vshll.u32 %v50586, 13 (stack44)
        %v50593 = vshrl.u32 %v50586, 19 (stack45)
        %v50594 = vor.u32 %v50593, %v50592 (stack46)
        %v50595 = vxor.u32 %v50594, %v50590 (stack47)
        %v50598 = vadd.s32 %v50595, %v50590 (stack39)
        %v50600 = vshll.u32 %v50595, 15 (stack44)
        %v50601 = vshrl.u32 %v50595, 17 (stack45)
        %v50602 = vor.u32 %v50601, %v50600 (stack46)
        %v50603 = vxor.u32 %v50602, %v50598 (stack47)
        %v50606 = vadd.s32 %v50603, %v50598 (stack39)
        %v50608 = vshll.u32 %v50603, 26 (stack44)
        %v50609 = vshrl.u32 %v50603, 6 (stack45)
        %v50610 = vor.u32 %v50609, %v50608 (stack46)
        %v50611 = vxor.u32 %v50610, %v50606 (stack47)
        %v50614 = vadd.s32 %v50611, %v50606 (stack39)
        %v50618 = vadd.s32 %v50614, %v8 (stack39)
        %v50620 = vshll.u32 %v50611, 6 (stack44)
        %v50621 = vshrl.u32 %v50611, 26 (stack45)
        %v50622 = vor.u32 %v50621, %v50620 (stack46)
        %v50623 = vxor.u32 %v50622, %v50614 (stack47)
        %v50626 = vadd.s32 %v50623, %v10 (stack39)
        %v50630 = vadd.s32 5, %v50626 (stack39)
        %v50632 = vxor.u32 %v50630, %v50618 (stack47)
        %v50633 = vand.u32.u8 255, %v50632 (stack48)
        %v50634 = vand.u32 65535, %v50633 (stack49)
        %v50635 = vshrl.u32 %v50634, 1 (stack50)
        %v50636 = vor.u32 16256, %v50635 (stack46)
        %v50637 = vand.u32.u16 65535, %v50636 (stack51)
        %v120014 = vadd.low.f32.bf16 -1.0, %v50637 (stack52)
        %v50646 = vmul.f32 2.0, %v120014 (stack53)
        %v50650 = vadd.f32 -0.99609375, %v50646 (stack52)
        %v50654 = vmax.f32 %v50650, -0.99609375 (stack54)
        %v50656 = vand.u32 2147483647, %v50654 (stack55)
        %vm50659 = vcmp.eq.f32.partialorder %v50656, 1.0 (stack56)
        %v50664 = vmul.f32 inf, %v50654 (stack53)
        %v50666 = vxor.u32 2147483648, %v50654 (stack57)
        %v50669 = vmul.f32 %v50666, %v50654 (stack53)
        %v50671 = vadd.f32 1.0, %v50669 (stack58)
        %v50672 = vlog2.pop %v50671 (stack59)
        %v50673 = vmul.f32 0.6931472, %v50672 (stack60)
        %v50674 = vmul.f32 -0.5, %v50669 (stack61)
        %v50675 = vadd.f32 1.0, %v50674 (stack62)
        %v50676 = vmul.f32 %v50675, %v50669 (stack63)
        %v50677 = vand.u32 2147483647, %v50669 (stack64)
        %vm50678 = vcmp.lt.f32.partialorder %v50677, 0.0004427343 (stack65)
        %v50679 = vsel /*vm=*/%vm50678, /*on_true_vy=*/%v50676, /*on_false_vx=*/%v50673 (stack66)
        %v50680 = vxor.u32 2147483648, %v50679 (stack57)
        %vm50683 = vcmp.lt.f32.partialorder %v50680, 5.0 (stack56)
        %v50688 = vsel /*vm=*/%vm50683, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v50692 = vsel /*vm=*/%vm50683, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v50696 = vsel /*vm=*/%vm50683, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v50700 = vsel /*vm=*/%vm50683, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v50704 = vsel /*vm=*/%vm50683, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v50708 = vsel /*vm=*/%vm50683, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v50712 = vsel /*vm=*/%vm50683, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v50716 = vsel /*vm=*/%vm50683, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v50720 = vsel /*vm=*/%vm50683, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v50724 = vadd.f32 -2.5, %v50680 (stack52)
        %v50726 = vrsqrt.pop %v50680 (stack67)
        %v50727 = vmul.f32 %v50726, %v50680 (stack68)
        %vm50728 = vcmp.eq.f32.partialorder %v50680, inf (stack69)
        %v50729 = vsel /*vm=*/%vm50728, /*on_true_vy=*/%v50680, /*on_false_vx=*/%v50727 (stack70)
        %vm50730 = vcmp.eq.f32.partialorder %v50680, 0.0 (stack71)
        %v50731 = vand.u32 2147483648, %v50680 (stack72)
        %v50732 = vsel /*vm=*/%vm50730, /*on_true_vy=*/%v50731, /*on_false_vx=*/%v50729 (stack73)
        %v50735 = vadd.f32 -3.0, %v50732 (stack52)
        %v50739 = vsel /*vm=*/%vm50683, /*on_true_vy=*/%v50724, /*on_false_vx=*/%v50735 (stack43)
        %v50743 = vmul.f32 %v50739, %v50720 (stack53)
        %v50747 = vadd.f32 %v50743, %v50716 (stack52)
        %v50751 = vmul.f32 %v50747, %v50739 (stack53)
        %v50755 = vadd.f32 %v50751, %v50712 (stack52)
        %v50759 = vmul.f32 %v50755, %v50739 (stack53)
        %v50763 = vadd.f32 %v50759, %v50708 (stack52)
        %v50767 = vmul.f32 %v50763, %v50739 (stack53)
        %v50771 = vadd.f32 %v50767, %v50704 (stack52)
        %v50775 = vmul.f32 %v50771, %v50739 (stack53)
        %v50779 = vadd.f32 %v50775, %v50700 (stack52)
        %v50783 = vmul.f32 %v50779, %v50739 (stack53)
        %v50787 = vadd.f32 %v50783, %v50696 (stack52)
        %v50791 = vmul.f32 %v50787, %v50739 (stack53)
        %v50795 = vadd.f32 %v50791, %v50692 (stack52)
        %v50799 = vmul.f32 %v50795, %v50739 (stack53)
        %v50803 = vadd.f32 %v50799, %v50688 (stack52)
        %v50807 = vmul.f32 %v50803, %v50654 (stack53)
        %v50811 = vsel /*vm=*/%vm50659, /*on_true_vy=*/%v50664, /*on_false_vx=*/%v50807 (stack43)
        %v50815 = vmul.f32 1.4140625, %v50811 (stack53)
        %v50818 = vpack.c.bf16 0.0, %v50815 (stack74)
        %120015 = vst [vmem:[%s280 + $0x1b4] sm:$0xf] /*vst_source=*/%v50818 (stack75)
        %v50822 = vadd.s32 %v48975, %v2355 (stack39)
        %v50832 = vadd.s32 %v50822, %v415 (stack39)
        %vm50836 = vcmp.lt.u32.totalorder %v50832, %v50822 (stack42)
        %vm50841 = vcmp.lt.u32.totalorder %v50822, %v2355 (stack42)
        %v50846 = vadd.s32 %v48958, %v2342 (stack39)
        %v50850 = vadd.s32 1, %v50846 (stack39)
        %v50854 = vsel /*vm=*/%vm50841, /*on_true_vy=*/%v50850, /*on_false_vx=*/%v50846 (stack43)
        %v50858 = vadd.s32 1, %v50854 (stack39)
        %v50862 = vsel /*vm=*/%vm50836, /*on_true_vy=*/%v50858, /*on_false_vx=*/%v50854 (stack43)
        %v50867 = vadd.s32 %v50862, %v10 (stack39)
        %v50871 = vadd.s32 %v50832, %v9 (stack39)
        %v50875 = vadd.s32 %v50871, %v50867 (stack39)
        %v50877 = vshll.u32 %v50871, 13 (stack44)
        %v50878 = vshrl.u32 %v50871, 19 (stack45)
        %v50879 = vor.u32 %v50878, %v50877 (stack46)
        %v50880 = vxor.u32 %v50879, %v50875 (stack47)
        %v50883 = vadd.s32 %v50880, %v50875 (stack39)
        %v50885 = vshll.u32 %v50880, 15 (stack44)
        %v50886 = vshrl.u32 %v50880, 17 (stack45)
        %v50887 = vor.u32 %v50886, %v50885 (stack46)
        %v50888 = vxor.u32 %v50887, %v50883 (stack47)
        %v50891 = vadd.s32 %v50888, %v50883 (stack39)
        %v50893 = vshll.u32 %v50888, 26 (stack44)
        %v50894 = vshrl.u32 %v50888, 6 (stack45)
        %v50895 = vor.u32 %v50894, %v50893 (stack46)
        %v50896 = vxor.u32 %v50895, %v50891 (stack47)
        %v50899 = vadd.s32 %v50896, %v50891 (stack39)
        %v50903 = vadd.s32 %v50899, %v9 (stack39)
        %v50905 = vshll.u32 %v50896, 6 (stack44)
        %v50906 = vshrl.u32 %v50896, 26 (stack45)
        %v50907 = vor.u32 %v50906, %v50905 (stack46)
        %v50908 = vxor.u32 %v50907, %v50899 (stack47)
        %v50911 = vadd.s32 %v50908, %v8 (stack39)
        %v50915 = vadd.s32 1, %v50911 (stack39)
        %v50919 = vadd.s32 %v50915, %v50903 (stack39)
        %v50921 = vshll.u32 %v50915, 17 (stack44)
        %v50922 = vshrl.u32 %v50915, 15 (stack45)
        %v50923 = vor.u32 %v50922, %v50921 (stack46)
        %v50924 = vxor.u32 %v50923, %v50919 (stack47)
        %v50927 = vadd.s32 %v50924, %v50919 (stack39)
        %v50929 = vshll.u32 %v50924, 29 (stack44)
        %v50930 = vshrl.u32 %v50924, 3 (stack45)
        %v50931 = vor.u32 %v50930, %v50929 (stack46)
        %v50932 = vxor.u32 %v50931, %v50927 (stack47)
        %v50935 = vadd.s32 %v50932, %v50927 (stack39)
        %v50937 = vshll.u32 %v50932, 16 (stack44)
        %v50938 = vshrl.u32 %v50932, 16 (stack45)
        %v50939 = vor.u32 %v50938, %v50937 (stack46)
        %v50940 = vxor.u32 %v50939, %v50935 (stack47)
        %v50943 = vadd.s32 %v50940, %v50935 (stack39)
        %v50947 = vadd.s32 %v50943, %v8 (stack39)
        %v50949 = vshll.u32 %v50940, 24 (stack44)
        %v50950 = vshrl.u32 %v50940, 8 (stack45)
        %v50951 = vor.u32 %v50950, %v50949 (stack46)
        %v50952 = vxor.u32 %v50951, %v50943 (stack47)
        %v50955 = vadd.s32 %v50952, %v10 (stack39)
        %v50959 = vadd.s32 2, %v50955 (stack39)
        %v50963 = vadd.s32 %v50959, %v50947 (stack39)
        %v50965 = vshll.u32 %v50959, 13 (stack44)
        %v50966 = vshrl.u32 %v50959, 19 (stack45)
        %v50967 = vor.u32 %v50966, %v50965 (stack46)
        %v50968 = vxor.u32 %v50967, %v50963 (stack47)
        %v50971 = vadd.s32 %v50968, %v50963 (stack39)
        %v50973 = vshll.u32 %v50968, 15 (stack44)
        %v50974 = vshrl.u32 %v50968, 17 (stack45)
        %v50975 = vor.u32 %v50974, %v50973 (stack46)
        %v50976 = vxor.u32 %v50975, %v50971 (stack47)
        %v50979 = vadd.s32 %v50976, %v50971 (stack39)
        %v50981 = vshll.u32 %v50976, 26 (stack44)
        %v50982 = vshrl.u32 %v50976, 6 (stack45)
        %v50983 = vor.u32 %v50982, %v50981 (stack46)
        %v50984 = vxor.u32 %v50983, %v50979 (stack47)
        %v50987 = vadd.s32 %v50984, %v50979 (stack39)
        %v50991 = vadd.s32 %v50987, %v10 (stack39)
        %v50993 = vshll.u32 %v50984, 6 (stack44)
        %v50994 = vshrl.u32 %v50984, 26 (stack45)
        %v50995 = vor.u32 %v50994, %v50993 (stack46)
        %v50996 = vxor.u32 %v50995, %v50987 (stack47)
        %v50999 = vadd.s32 %v50996, %v9 (stack39)
        %v51003 = vadd.s32 3, %v50999 (stack39)
        %v51007 = vadd.s32 %v51003, %v50991 (stack39)
        %v51009 = vshll.u32 %v51003, 17 (stack44)
        %v51010 = vshrl.u32 %v51003, 15 (stack45)
        %v51011 = vor.u32 %v51010, %v51009 (stack46)
        %v51012 = vxor.u32 %v51011, %v51007 (stack47)
        %v51015 = vadd.s32 %v51012, %v51007 (stack39)
        %v51017 = vshll.u32 %v51012, 29 (stack44)
        %v51018 = vshrl.u32 %v51012, 3 (stack45)
        %v51019 = vor.u32 %v51018, %v51017 (stack46)
        %v51020 = vxor.u32 %v51019, %v51015 (stack47)
        %v51023 = vadd.s32 %v51020, %v51015 (stack39)
        %v51025 = vshll.u32 %v51020, 16 (stack44)
        %v51026 = vshrl.u32 %v51020, 16 (stack45)
        %v51027 = vor.u32 %v51026, %v51025 (stack46)
        %v51028 = vxor.u32 %v51027, %v51023 (stack47)
        %v51031 = vadd.s32 %v51028, %v51023 (stack39)
        %v51035 = vadd.s32 %v51031, %v9 (stack39)
        %v51037 = vshll.u32 %v51028, 24 (stack44)
        %v51038 = vshrl.u32 %v51028, 8 (stack45)
        %v51039 = vor.u32 %v51038, %v51037 (stack46)
        %v51040 = vxor.u32 %v51039, %v51031 (stack47)
        %v51043 = vadd.s32 %v51040, %v8 (stack39)
        %v51047 = vadd.s32 4, %v51043 (stack39)
        %v51051 = vadd.s32 %v51047, %v51035 (stack39)
        %v51053 = vshll.u32 %v51047, 13 (stack44)
        %v51054 = vshrl.u32 %v51047, 19 (stack45)
        %v51055 = vor.u32 %v51054, %v51053 (stack46)
        %v51056 = vxor.u32 %v51055, %v51051 (stack47)
        %v51059 = vadd.s32 %v51056, %v51051 (stack39)
        %v51061 = vshll.u32 %v51056, 15 (stack44)
        %v51062 = vshrl.u32 %v51056, 17 (stack45)
        %v51063 = vor.u32 %v51062, %v51061 (stack46)
        %v51064 = vxor.u32 %v51063, %v51059 (stack47)
        %v51067 = vadd.s32 %v51064, %v51059 (stack39)
        %v51069 = vshll.u32 %v51064, 26 (stack44)
        %v51070 = vshrl.u32 %v51064, 6 (stack45)
        %v51071 = vor.u32 %v51070, %v51069 (stack46)
        %v51072 = vxor.u32 %v51071, %v51067 (stack47)
        %v51075 = vadd.s32 %v51072, %v51067 (stack39)
        %v51079 = vadd.s32 %v51075, %v8 (stack39)
        %v51081 = vshll.u32 %v51072, 6 (stack44)
        %v51082 = vshrl.u32 %v51072, 26 (stack45)
        %v51083 = vor.u32 %v51082, %v51081 (stack46)
        %v51084 = vxor.u32 %v51083, %v51075 (stack47)
        %v51087 = vadd.s32 %v51084, %v10 (stack39)
        %v51091 = vadd.s32 5, %v51087 (stack39)
        %v51093 = vxor.u32 %v51091, %v51079 (stack47)
        %v51094 = vand.u32.u8 255, %v51093 (stack48)
        %v51095 = vand.u32 65535, %v51094 (stack49)
        %v51096 = vshrl.u32 %v51095, 1 (stack50)
        %v51097 = vor.u32 16256, %v51096 (stack46)
        %v51098 = vand.u32.u16 65535, %v51097 (stack51)
        %v120016 = vadd.low.f32.bf16 -1.0, %v51098 (stack52)
        %v51107 = vmul.f32 2.0, %v120016 (stack53)
        %v51111 = vadd.f32 -0.99609375, %v51107 (stack52)
        %v51115 = vmax.f32 %v51111, -0.99609375 (stack54)
        %v51117 = vand.u32 2147483647, %v51115 (stack55)
        %vm51120 = vcmp.eq.f32.partialorder %v51117, 1.0 (stack56)
        %v51125 = vmul.f32 inf, %v51115 (stack53)
        %v51127 = vxor.u32 2147483648, %v51115 (stack57)
        %v51130 = vmul.f32 %v51127, %v51115 (stack53)
        %v51132 = vadd.f32 1.0, %v51130 (stack58)
        %v51133 = vlog2.pop %v51132 (stack59)
        %v51134 = vmul.f32 0.6931472, %v51133 (stack60)
        %v51135 = vmul.f32 -0.5, %v51130 (stack61)
        %v51136 = vadd.f32 1.0, %v51135 (stack62)
        %v51137 = vmul.f32 %v51136, %v51130 (stack63)
        %v51138 = vand.u32 2147483647, %v51130 (stack64)
        %vm51139 = vcmp.lt.f32.partialorder %v51138, 0.0004427343 (stack65)
        %v51140 = vsel /*vm=*/%vm51139, /*on_true_vy=*/%v51137, /*on_false_vx=*/%v51134 (stack66)
        %v51141 = vxor.u32 2147483648, %v51140 (stack57)
        %vm51144 = vcmp.lt.f32.partialorder %v51141, 5.0 (stack56)
        %v51149 = vsel /*vm=*/%vm51144, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v51153 = vsel /*vm=*/%vm51144, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v51157 = vsel /*vm=*/%vm51144, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v51161 = vsel /*vm=*/%vm51144, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v51165 = vsel /*vm=*/%vm51144, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v51169 = vsel /*vm=*/%vm51144, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v51173 = vsel /*vm=*/%vm51144, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v51177 = vsel /*vm=*/%vm51144, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v51181 = vsel /*vm=*/%vm51144, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v51185 = vadd.f32 -2.5, %v51141 (stack52)
        %v51187 = vrsqrt.pop %v51141 (stack67)
        %v51188 = vmul.f32 %v51187, %v51141 (stack68)
        %vm51189 = vcmp.eq.f32.partialorder %v51141, inf (stack69)
        %v51190 = vsel /*vm=*/%vm51189, /*on_true_vy=*/%v51141, /*on_false_vx=*/%v51188 (stack70)
        %vm51191 = vcmp.eq.f32.partialorder %v51141, 0.0 (stack71)
        %v51192 = vand.u32 2147483648, %v51141 (stack72)
        %v51193 = vsel /*vm=*/%vm51191, /*on_true_vy=*/%v51192, /*on_false_vx=*/%v51190 (stack73)
        %v51196 = vadd.f32 -3.0, %v51193 (stack52)
        %v51200 = vsel /*vm=*/%vm51144, /*on_true_vy=*/%v51185, /*on_false_vx=*/%v51196 (stack43)
        %v51204 = vmul.f32 %v51200, %v51181 (stack53)
        %v51208 = vadd.f32 %v51204, %v51177 (stack52)
        %v51212 = vmul.f32 %v51208, %v51200 (stack53)
        %v51216 = vadd.f32 %v51212, %v51173 (stack52)
        %v51220 = vmul.f32 %v51216, %v51200 (stack53)
        %v51224 = vadd.f32 %v51220, %v51169 (stack52)
        %v51228 = vmul.f32 %v51224, %v51200 (stack53)
        %v51232 = vadd.f32 %v51228, %v51165 (stack52)
        %v51236 = vmul.f32 %v51232, %v51200 (stack53)
        %v51240 = vadd.f32 %v51236, %v51161 (stack52)
        %v51244 = vmul.f32 %v51240, %v51200 (stack53)
        %v51248 = vadd.f32 %v51244, %v51157 (stack52)
        %v51252 = vmul.f32 %v51248, %v51200 (stack53)
        %v51256 = vadd.f32 %v51252, %v51153 (stack52)
        %v51260 = vmul.f32 %v51256, %v51200 (stack53)
        %v51264 = vadd.f32 %v51260, %v51149 (stack52)
        %v51268 = vmul.f32 %v51264, %v51115 (stack53)
        %v51272 = vsel /*vm=*/%vm51120, /*on_true_vy=*/%v51125, /*on_false_vx=*/%v51268 (stack43)
        %v51276 = vmul.f32 1.4140625, %v51272 (stack53)
        %v51279 = vpack.c.bf16 0.0, %v51276 (stack74)
        %120017 = vst [vmem:[%s280 + $0x234] sm:$0xf] /*vst_source=*/%v51279 (stack75)
        %v51283 = vadd.s32 %v48975, %v2842 (stack39)
        %v51293 = vadd.s32 %v51283, %v415 (stack39)
        %vm51297 = vcmp.lt.u32.totalorder %v51293, %v51283 (stack42)
        %vm51302 = vcmp.lt.u32.totalorder %v51283, %v2842 (stack42)
        %v51307 = vadd.s32 %v48958, %v2829 (stack39)
        %v51311 = vadd.s32 1, %v51307 (stack39)
        %v51315 = vsel /*vm=*/%vm51302, /*on_true_vy=*/%v51311, /*on_false_vx=*/%v51307 (stack43)
        %v51319 = vadd.s32 1, %v51315 (stack39)
        %v51323 = vsel /*vm=*/%vm51297, /*on_true_vy=*/%v51319, /*on_false_vx=*/%v51315 (stack43)
        %v51328 = vadd.s32 %v51323, %v10 (stack39)
        %v51332 = vadd.s32 %v51293, %v9 (stack39)
        %v51336 = vadd.s32 %v51332, %v51328 (stack39)
        %v51338 = vshll.u32 %v51332, 13 (stack44)
        %v51339 = vshrl.u32 %v51332, 19 (stack45)
        %v51340 = vor.u32 %v51339, %v51338 (stack46)
        %v51341 = vxor.u32 %v51340, %v51336 (stack47)
        %v51344 = vadd.s32 %v51341, %v51336 (stack39)
        %v51346 = vshll.u32 %v51341, 15 (stack44)
        %v51347 = vshrl.u32 %v51341, 17 (stack45)
        %v51348 = vor.u32 %v51347, %v51346 (stack46)
        %v51349 = vxor.u32 %v51348, %v51344 (stack47)
        %v51352 = vadd.s32 %v51349, %v51344 (stack39)
        %v51354 = vshll.u32 %v51349, 26 (stack44)
        %v51355 = vshrl.u32 %v51349, 6 (stack45)
        %v51356 = vor.u32 %v51355, %v51354 (stack46)
        %v51357 = vxor.u32 %v51356, %v51352 (stack47)
        %v51360 = vadd.s32 %v51357, %v51352 (stack39)
        %v51364 = vadd.s32 %v51360, %v9 (stack39)
        %v51366 = vshll.u32 %v51357, 6 (stack44)
        %v51367 = vshrl.u32 %v51357, 26 (stack45)
        %v51368 = vor.u32 %v51367, %v51366 (stack46)
        %v51369 = vxor.u32 %v51368, %v51360 (stack47)
        %v51372 = vadd.s32 %v51369, %v8 (stack39)
        %v51376 = vadd.s32 1, %v51372 (stack39)
        %v51380 = vadd.s32 %v51376, %v51364 (stack39)
        %v51382 = vshll.u32 %v51376, 17 (stack44)
        %v51383 = vshrl.u32 %v51376, 15 (stack45)
        %v51384 = vor.u32 %v51383, %v51382 (stack46)
        %v51385 = vxor.u32 %v51384, %v51380 (stack47)
        %v51388 = vadd.s32 %v51385, %v51380 (stack39)
        %v51390 = vshll.u32 %v51385, 29 (stack44)
        %v51391 = vshrl.u32 %v51385, 3 (stack45)
        %v51392 = vor.u32 %v51391, %v51390 (stack46)
        %v51393 = vxor.u32 %v51392, %v51388 (stack47)
        %v51396 = vadd.s32 %v51393, %v51388 (stack39)
        %v51398 = vshll.u32 %v51393, 16 (stack44)
        %v51399 = vshrl.u32 %v51393, 16 (stack45)
        %v51400 = vor.u32 %v51399, %v51398 (stack46)
        %v51401 = vxor.u32 %v51400, %v51396 (stack47)
        %v51404 = vadd.s32 %v51401, %v51396 (stack39)
        %v51408 = vadd.s32 %v51404, %v8 (stack39)
        %v51410 = vshll.u32 %v51401, 24 (stack44)
        %v51411 = vshrl.u32 %v51401, 8 (stack45)
        %v51412 = vor.u32 %v51411, %v51410 (stack46)
        %v51413 = vxor.u32 %v51412, %v51404 (stack47)
        %v51416 = vadd.s32 %v51413, %v10 (stack39)
        %v51420 = vadd.s32 2, %v51416 (stack39)
        %v51424 = vadd.s32 %v51420, %v51408 (stack39)
        %v51426 = vshll.u32 %v51420, 13 (stack44)
        %v51427 = vshrl.u32 %v51420, 19 (stack45)
        %v51428 = vor.u32 %v51427, %v51426 (stack46)
        %v51429 = vxor.u32 %v51428, %v51424 (stack47)
        %v51432 = vadd.s32 %v51429, %v51424 (stack39)
        %v51434 = vshll.u32 %v51429, 15 (stack44)
        %v51435 = vshrl.u32 %v51429, 17 (stack45)
        %v51436 = vor.u32 %v51435, %v51434 (stack46)
        %v51437 = vxor.u32 %v51436, %v51432 (stack47)
        %v51440 = vadd.s32 %v51437, %v51432 (stack39)
        %v51442 = vshll.u32 %v51437, 26 (stack44)
        %v51443 = vshrl.u32 %v51437, 6 (stack45)
        %v51444 = vor.u32 %v51443, %v51442 (stack46)
        %v51445 = vxor.u32 %v51444, %v51440 (stack47)
        %v51448 = vadd.s32 %v51445, %v51440 (stack39)
        %v51452 = vadd.s32 %v51448, %v10 (stack39)
        %v51454 = vshll.u32 %v51445, 6 (stack44)
        %v51455 = vshrl.u32 %v51445, 26 (stack45)
        %v51456 = vor.u32 %v51455, %v51454 (stack46)
        %v51457 = vxor.u32 %v51456, %v51448 (stack47)
        %v51460 = vadd.s32 %v51457, %v9 (stack39)
        %v51464 = vadd.s32 3, %v51460 (stack39)
        %v51468 = vadd.s32 %v51464, %v51452 (stack39)
        %v51470 = vshll.u32 %v51464, 17 (stack44)
        %v51471 = vshrl.u32 %v51464, 15 (stack45)
        %v51472 = vor.u32 %v51471, %v51470 (stack46)
        %v51473 = vxor.u32 %v51472, %v51468 (stack47)
        %v51476 = vadd.s32 %v51473, %v51468 (stack39)
        %v51478 = vshll.u32 %v51473, 29 (stack44)
        %v51479 = vshrl.u32 %v51473, 3 (stack45)
        %v51480 = vor.u32 %v51479, %v51478 (stack46)
        %v51481 = vxor.u32 %v51480, %v51476 (stack47)
        %v51484 = vadd.s32 %v51481, %v51476 (stack39)
        %v51486 = vshll.u32 %v51481, 16 (stack44)
        %v51487 = vshrl.u32 %v51481, 16 (stack45)
        %v51488 = vor.u32 %v51487, %v51486 (stack46)
        %v51489 = vxor.u32 %v51488, %v51484 (stack47)
        %v51492 = vadd.s32 %v51489, %v51484 (stack39)
        %v51496 = vadd.s32 %v51492, %v9 (stack39)
        %v51498 = vshll.u32 %v51489, 24 (stack44)
        %v51499 = vshrl.u32 %v51489, 8 (stack45)
        %v51500 = vor.u32 %v51499, %v51498 (stack46)
        %v51501 = vxor.u32 %v51500, %v51492 (stack47)
        %v51504 = vadd.s32 %v51501, %v8 (stack39)
        %v51508 = vadd.s32 4, %v51504 (stack39)
        %v51512 = vadd.s32 %v51508, %v51496 (stack39)
        %v51514 = vshll.u32 %v51508, 13 (stack44)
        %v51515 = vshrl.u32 %v51508, 19 (stack45)
        %v51516 = vor.u32 %v51515, %v51514 (stack46)
        %v51517 = vxor.u32 %v51516, %v51512 (stack47)
        %v51520 = vadd.s32 %v51517, %v51512 (stack39)
        %v51522 = vshll.u32 %v51517, 15 (stack44)
        %v51523 = vshrl.u32 %v51517, 17 (stack45)
        %v51524 = vor.u32 %v51523, %v51522 (stack46)
        %v51525 = vxor.u32 %v51524, %v51520 (stack47)
        %v51528 = vadd.s32 %v51525, %v51520 (stack39)
        %v51530 = vshll.u32 %v51525, 26 (stack44)
        %v51531 = vshrl.u32 %v51525, 6 (stack45)
        %v51532 = vor.u32 %v51531, %v51530 (stack46)
        %v51533 = vxor.u32 %v51532, %v51528 (stack47)
        %v51536 = vadd.s32 %v51533, %v51528 (stack39)
        %v51540 = vadd.s32 %v51536, %v8 (stack39)
        %v51542 = vshll.u32 %v51533, 6 (stack44)
        %v51543 = vshrl.u32 %v51533, 26 (stack45)
        %v51544 = vor.u32 %v51543, %v51542 (stack46)
        %v51545 = vxor.u32 %v51544, %v51536 (stack47)
        %v51548 = vadd.s32 %v51545, %v10 (stack39)
        %v51552 = vadd.s32 5, %v51548 (stack39)
        %v51554 = vxor.u32 %v51552, %v51540 (stack47)
        %v51555 = vand.u32.u8 255, %v51554 (stack48)
        %v51556 = vand.u32 65535, %v51555 (stack49)
        %v51557 = vshrl.u32 %v51556, 1 (stack50)
        %v51558 = vor.u32 16256, %v51557 (stack46)
        %v51559 = vand.u32.u16 65535, %v51558 (stack51)
        %v120018 = vadd.low.f32.bf16 -1.0, %v51559 (stack52)
        %v51568 = vmul.f32 2.0, %v120018 (stack53)
        %v51572 = vadd.f32 -0.99609375, %v51568 (stack52)
        %v51576 = vmax.f32 %v51572, -0.99609375 (stack54)
        %v51578 = vand.u32 2147483647, %v51576 (stack55)
        %vm51581 = vcmp.eq.f32.partialorder %v51578, 1.0 (stack56)
        %v51586 = vmul.f32 inf, %v51576 (stack53)
        %v51588 = vxor.u32 2147483648, %v51576 (stack57)
        %v51591 = vmul.f32 %v51588, %v51576 (stack53)
        %v51593 = vadd.f32 1.0, %v51591 (stack58)
        %v51594 = vlog2.pop %v51593 (stack59)
        %v51595 = vmul.f32 0.6931472, %v51594 (stack60)
        %v51596 = vmul.f32 -0.5, %v51591 (stack61)
        %v51597 = vadd.f32 1.0, %v51596 (stack62)
        %v51598 = vmul.f32 %v51597, %v51591 (stack63)
        %v51599 = vand.u32 2147483647, %v51591 (stack64)
        %vm51600 = vcmp.lt.f32.partialorder %v51599, 0.0004427343 (stack65)
        %v51601 = vsel /*vm=*/%vm51600, /*on_true_vy=*/%v51598, /*on_false_vx=*/%v51595 (stack66)
        %v51602 = vxor.u32 2147483648, %v51601 (stack57)
        %vm51605 = vcmp.lt.f32.partialorder %v51602, 5.0 (stack56)
        %v51610 = vsel /*vm=*/%vm51605, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v51614 = vsel /*vm=*/%vm51605, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v51618 = vsel /*vm=*/%vm51605, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v51622 = vsel /*vm=*/%vm51605, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v51626 = vsel /*vm=*/%vm51605, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v51630 = vsel /*vm=*/%vm51605, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v51634 = vsel /*vm=*/%vm51605, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v51638 = vsel /*vm=*/%vm51605, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v51642 = vsel /*vm=*/%vm51605, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v51646 = vadd.f32 -2.5, %v51602 (stack52)
        %v51648 = vrsqrt.pop %v51602 (stack67)
        %v51649 = vmul.f32 %v51648, %v51602 (stack68)
        %vm51650 = vcmp.eq.f32.partialorder %v51602, inf (stack69)
        %v51651 = vsel /*vm=*/%vm51650, /*on_true_vy=*/%v51602, /*on_false_vx=*/%v51649 (stack70)
        %vm51652 = vcmp.eq.f32.partialorder %v51602, 0.0 (stack71)
        %v51653 = vand.u32 2147483648, %v51602 (stack72)
        %v51654 = vsel /*vm=*/%vm51652, /*on_true_vy=*/%v51653, /*on_false_vx=*/%v51651 (stack73)
        %v51657 = vadd.f32 -3.0, %v51654 (stack52)
        %v51661 = vsel /*vm=*/%vm51605, /*on_true_vy=*/%v51646, /*on_false_vx=*/%v51657 (stack43)
        %v51665 = vmul.f32 %v51661, %v51642 (stack53)
        %v51669 = vadd.f32 %v51665, %v51638 (stack52)
        %v51673 = vmul.f32 %v51669, %v51661 (stack53)
        %v51677 = vadd.f32 %v51673, %v51634 (stack52)
        %v51681 = vmul.f32 %v51677, %v51661 (stack53)
        %v51685 = vadd.f32 %v51681, %v51630 (stack52)
        %v51689 = vmul.f32 %v51685, %v51661 (stack53)
        %v51693 = vadd.f32 %v51689, %v51626 (stack52)
        %v51697 = vmul.f32 %v51693, %v51661 (stack53)
        %v51701 = vadd.f32 %v51697, %v51622 (stack52)
        %v51705 = vmul.f32 %v51701, %v51661 (stack53)
        %v51709 = vadd.f32 %v51705, %v51618 (stack52)
        %v51713 = vmul.f32 %v51709, %v51661 (stack53)
        %v51717 = vadd.f32 %v51713, %v51614 (stack52)
        %v51721 = vmul.f32 %v51717, %v51661 (stack53)
        %v51725 = vadd.f32 %v51721, %v51610 (stack52)
        %v51729 = vmul.f32 %v51725, %v51576 (stack53)
        %v51733 = vsel /*vm=*/%vm51581, /*on_true_vy=*/%v51586, /*on_false_vx=*/%v51729 (stack43)
        %v51737 = vmul.f32 1.4140625, %v51733 (stack53)
        %v51740 = vpack.c.bf16 0.0, %v51737 (stack74)
        %120019 = vst [vmem:[%s280 + $0x2b4] sm:$0xf] /*vst_source=*/%v51740 (stack75)
        %v51744 = vadd.s32 %v48975, %v3329 (stack39)
        %v51754 = vadd.s32 %v51744, %v415 (stack39)
        %vm51758 = vcmp.lt.u32.totalorder %v51754, %v51744 (stack42)
        %vm51763 = vcmp.lt.u32.totalorder %v51744, %v3329 (stack42)
        %v51768 = vadd.s32 %v48958, %v3316 (stack39)
        %v51772 = vadd.s32 1, %v51768 (stack39)
        %v51776 = vsel /*vm=*/%vm51763, /*on_true_vy=*/%v51772, /*on_false_vx=*/%v51768 (stack43)
        %v51780 = vadd.s32 1, %v51776 (stack39)
        %v51784 = vsel /*vm=*/%vm51758, /*on_true_vy=*/%v51780, /*on_false_vx=*/%v51776 (stack43)
        %v51789 = vadd.s32 %v51784, %v10 (stack39)
        %v51793 = vadd.s32 %v51754, %v9 (stack39)
        %v51797 = vadd.s32 %v51793, %v51789 (stack39)
        %v51799 = vshll.u32 %v51793, 13 (stack44)
        %v51800 = vshrl.u32 %v51793, 19 (stack45)
        %v51801 = vor.u32 %v51800, %v51799 (stack46)
        %v51802 = vxor.u32 %v51801, %v51797 (stack47)
        %v51805 = vadd.s32 %v51802, %v51797 (stack39)
        %v51807 = vshll.u32 %v51802, 15 (stack44)
        %v51808 = vshrl.u32 %v51802, 17 (stack45)
        %v51809 = vor.u32 %v51808, %v51807 (stack46)
        %v51810 = vxor.u32 %v51809, %v51805 (stack47)
        %v51813 = vadd.s32 %v51810, %v51805 (stack39)
        %v51815 = vshll.u32 %v51810, 26 (stack44)
        %v51816 = vshrl.u32 %v51810, 6 (stack45)
        %v51817 = vor.u32 %v51816, %v51815 (stack46)
        %v51818 = vxor.u32 %v51817, %v51813 (stack47)
        %v51821 = vadd.s32 %v51818, %v51813 (stack39)
        %v51825 = vadd.s32 %v51821, %v9 (stack39)
        %v51827 = vshll.u32 %v51818, 6 (stack44)
        %v51828 = vshrl.u32 %v51818, 26 (stack45)
        %v51829 = vor.u32 %v51828, %v51827 (stack46)
        %v51830 = vxor.u32 %v51829, %v51821 (stack47)
        %v51833 = vadd.s32 %v51830, %v8 (stack39)
        %v51837 = vadd.s32 1, %v51833 (stack39)
        %v51841 = vadd.s32 %v51837, %v51825 (stack39)
        %v51843 = vshll.u32 %v51837, 17 (stack44)
        %v51844 = vshrl.u32 %v51837, 15 (stack45)
        %v51845 = vor.u32 %v51844, %v51843 (stack46)
        %v51846 = vxor.u32 %v51845, %v51841 (stack47)
        %v51849 = vadd.s32 %v51846, %v51841 (stack39)
        %v51851 = vshll.u32 %v51846, 29 (stack44)
        %v51852 = vshrl.u32 %v51846, 3 (stack45)
        %v51853 = vor.u32 %v51852, %v51851 (stack46)
        %v51854 = vxor.u32 %v51853, %v51849 (stack47)
        %v51857 = vadd.s32 %v51854, %v51849 (stack39)
        %v51859 = vshll.u32 %v51854, 16 (stack44)
        %v51860 = vshrl.u32 %v51854, 16 (stack45)
        %v51861 = vor.u32 %v51860, %v51859 (stack46)
        %v51862 = vxor.u32 %v51861, %v51857 (stack47)
        %v51865 = vadd.s32 %v51862, %v51857 (stack39)
        %v51869 = vadd.s32 %v51865, %v8 (stack39)
        %v51871 = vshll.u32 %v51862, 24 (stack44)
        %v51872 = vshrl.u32 %v51862, 8 (stack45)
        %v51873 = vor.u32 %v51872, %v51871 (stack46)
        %v51874 = vxor.u32 %v51873, %v51865 (stack47)
        %v51877 = vadd.s32 %v51874, %v10 (stack39)
        %v51881 = vadd.s32 2, %v51877 (stack39)
        %v51885 = vadd.s32 %v51881, %v51869 (stack39)
        %v51887 = vshll.u32 %v51881, 13 (stack44)
        %v51888 = vshrl.u32 %v51881, 19 (stack45)
        %v51889 = vor.u32 %v51888, %v51887 (stack46)
        %v51890 = vxor.u32 %v51889, %v51885 (stack47)
        %v51893 = vadd.s32 %v51890, %v51885 (stack39)
        %v51895 = vshll.u32 %v51890, 15 (stack44)
        %v51896 = vshrl.u32 %v51890, 17 (stack45)
        %v51897 = vor.u32 %v51896, %v51895 (stack46)
        %v51898 = vxor.u32 %v51897, %v51893 (stack47)
        %v51901 = vadd.s32 %v51898, %v51893 (stack39)
        %v51903 = vshll.u32 %v51898, 26 (stack44)
        %v51904 = vshrl.u32 %v51898, 6 (stack45)
        %v51905 = vor.u32 %v51904, %v51903 (stack46)
        %v51906 = vxor.u32 %v51905, %v51901 (stack47)
        %v51909 = vadd.s32 %v51906, %v51901 (stack39)
        %v51913 = vadd.s32 %v51909, %v10 (stack39)
        %v51915 = vshll.u32 %v51906, 6 (stack44)
        %v51916 = vshrl.u32 %v51906, 26 (stack45)
        %v51917 = vor.u32 %v51916, %v51915 (stack46)
        %v51918 = vxor.u32 %v51917, %v51909 (stack47)
        %v51921 = vadd.s32 %v51918, %v9 (stack39)
        %v51925 = vadd.s32 3, %v51921 (stack39)
        %v51929 = vadd.s32 %v51925, %v51913 (stack39)
        %v51931 = vshll.u32 %v51925, 17 (stack44)
        %v51932 = vshrl.u32 %v51925, 15 (stack45)
        %v51933 = vor.u32 %v51932, %v51931 (stack46)
        %v51934 = vxor.u32 %v51933, %v51929 (stack47)
        %v51937 = vadd.s32 %v51934, %v51929 (stack39)
        %v51939 = vshll.u32 %v51934, 29 (stack44)
        %v51940 = vshrl.u32 %v51934, 3 (stack45)
        %v51941 = vor.u32 %v51940, %v51939 (stack46)
        %v51942 = vxor.u32 %v51941, %v51937 (stack47)
        %v51945 = vadd.s32 %v51942, %v51937 (stack39)
        %v51947 = vshll.u32 %v51942, 16 (stack44)
        %v51948 = vshrl.u32 %v51942, 16 (stack45)
        %v51949 = vor.u32 %v51948, %v51947 (stack46)
        %v51950 = vxor.u32 %v51949, %v51945 (stack47)
        %v51953 = vadd.s32 %v51950, %v51945 (stack39)
        %v51957 = vadd.s32 %v51953, %v9 (stack39)
        %v51959 = vshll.u32 %v51950, 24 (stack44)
        %v51960 = vshrl.u32 %v51950, 8 (stack45)
        %v51961 = vor.u32 %v51960, %v51959 (stack46)
        %v51962 = vxor.u32 %v51961, %v51953 (stack47)
        %v51965 = vadd.s32 %v51962, %v8 (stack39)
        %v51969 = vadd.s32 4, %v51965 (stack39)
        %v51973 = vadd.s32 %v51969, %v51957 (stack39)
        %v51975 = vshll.u32 %v51969, 13 (stack44)
        %v51976 = vshrl.u32 %v51969, 19 (stack45)
        %v51977 = vor.u32 %v51976, %v51975 (stack46)
        %v51978 = vxor.u32 %v51977, %v51973 (stack47)
        %v51981 = vadd.s32 %v51978, %v51973 (stack39)
        %v51983 = vshll.u32 %v51978, 15 (stack44)
        %v51984 = vshrl.u32 %v51978, 17 (stack45)
        %v51985 = vor.u32 %v51984, %v51983 (stack46)
        %v51986 = vxor.u32 %v51985, %v51981 (stack47)
        %v51989 = vadd.s32 %v51986, %v51981 (stack39)
        %v51991 = vshll.u32 %v51986, 26 (stack44)
        %v51992 = vshrl.u32 %v51986, 6 (stack45)
        %v51993 = vor.u32 %v51992, %v51991 (stack46)
        %v51994 = vxor.u32 %v51993, %v51989 (stack47)
        %v51997 = vadd.s32 %v51994, %v51989 (stack39)
        %v52001 = vadd.s32 %v51997, %v8 (stack39)
        %v52003 = vshll.u32 %v51994, 6 (stack44)
        %v52004 = vshrl.u32 %v51994, 26 (stack45)
        %v52005 = vor.u32 %v52004, %v52003 (stack46)
        %v52006 = vxor.u32 %v52005, %v51997 (stack47)
        %v52009 = vadd.s32 %v52006, %v10 (stack39)
        %v52013 = vadd.s32 5, %v52009 (stack39)
        %v52015 = vxor.u32 %v52013, %v52001 (stack47)
        %v52016 = vand.u32.u8 255, %v52015 (stack48)
        %v52017 = vand.u32 65535, %v52016 (stack49)
        %v52018 = vshrl.u32 %v52017, 1 (stack50)
        %v52019 = vor.u32 16256, %v52018 (stack46)
        %v52020 = vand.u32.u16 65535, %v52019 (stack51)
        %v120020 = vadd.low.f32.bf16 -1.0, %v52020 (stack52)
        %v52029 = vmul.f32 2.0, %v120020 (stack53)
        %v52033 = vadd.f32 -0.99609375, %v52029 (stack52)
        %v52037 = vmax.f32 %v52033, -0.99609375 (stack54)
        %v52039 = vand.u32 2147483647, %v52037 (stack55)
        %vm52042 = vcmp.eq.f32.partialorder %v52039, 1.0 (stack56)
        %v52047 = vmul.f32 inf, %v52037 (stack53)
        %v52049 = vxor.u32 2147483648, %v52037 (stack57)
        %v52052 = vmul.f32 %v52049, %v52037 (stack53)
        %v52054 = vadd.f32 1.0, %v52052 (stack58)
        %v52055 = vlog2.pop %v52054 (stack59)
        %v52056 = vmul.f32 0.6931472, %v52055 (stack60)
        %v52057 = vmul.f32 -0.5, %v52052 (stack61)
        %v52058 = vadd.f32 1.0, %v52057 (stack62)
        %v52059 = vmul.f32 %v52058, %v52052 (stack63)
        %v52060 = vand.u32 2147483647, %v52052 (stack64)
        %vm52061 = vcmp.lt.f32.partialorder %v52060, 0.0004427343 (stack65)
        %v52062 = vsel /*vm=*/%vm52061, /*on_true_vy=*/%v52059, /*on_false_vx=*/%v52056 (stack66)
        %v52063 = vxor.u32 2147483648, %v52062 (stack57)
        %vm52066 = vcmp.lt.f32.partialorder %v52063, 5.0 (stack56)
        %v52071 = vsel /*vm=*/%vm52066, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v52075 = vsel /*vm=*/%vm52066, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v52079 = vsel /*vm=*/%vm52066, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v52083 = vsel /*vm=*/%vm52066, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v52087 = vsel /*vm=*/%vm52066, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v52091 = vsel /*vm=*/%vm52066, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v52095 = vsel /*vm=*/%vm52066, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v52099 = vsel /*vm=*/%vm52066, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v52103 = vsel /*vm=*/%vm52066, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v52107 = vadd.f32 -2.5, %v52063 (stack52)
        %v52109 = vrsqrt.pop %v52063 (stack67)
        %v52110 = vmul.f32 %v52109, %v52063 (stack68)
        %vm52111 = vcmp.eq.f32.partialorder %v52063, inf (stack69)
        %v52112 = vsel /*vm=*/%vm52111, /*on_true_vy=*/%v52063, /*on_false_vx=*/%v52110 (stack70)
        %vm52113 = vcmp.eq.f32.partialorder %v52063, 0.0 (stack71)
        %v52114 = vand.u32 2147483648, %v52063 (stack72)
        %v52115 = vsel /*vm=*/%vm52113, /*on_true_vy=*/%v52114, /*on_false_vx=*/%v52112 (stack73)
        %v52118 = vadd.f32 -3.0, %v52115 (stack52)
        %v52122 = vsel /*vm=*/%vm52066, /*on_true_vy=*/%v52107, /*on_false_vx=*/%v52118 (stack43)
        %v52126 = vmul.f32 %v52122, %v52103 (stack53)
        %v52130 = vadd.f32 %v52126, %v52099 (stack52)
        %v52134 = vmul.f32 %v52130, %v52122 (stack53)
        %v52138 = vadd.f32 %v52134, %v52095 (stack52)
        %v52142 = vmul.f32 %v52138, %v52122 (stack53)
        %v52146 = vadd.f32 %v52142, %v52091 (stack52)
        %v52150 = vmul.f32 %v52146, %v52122 (stack53)
        %v52154 = vadd.f32 %v52150, %v52087 (stack52)
        %v52158 = vmul.f32 %v52154, %v52122 (stack53)
        %v52162 = vadd.f32 %v52158, %v52083 (stack52)
        %v52166 = vmul.f32 %v52162, %v52122 (stack53)
        %v52170 = vadd.f32 %v52166, %v52079 (stack52)
        %v52174 = vmul.f32 %v52170, %v52122 (stack53)
        %v52178 = vadd.f32 %v52174, %v52075 (stack52)
        %v52182 = vmul.f32 %v52178, %v52122 (stack53)
        %v52186 = vadd.f32 %v52182, %v52071 (stack52)
        %v52190 = vmul.f32 %v52186, %v52037 (stack53)
        %v52194 = vsel /*vm=*/%vm52042, /*on_true_vy=*/%v52047, /*on_false_vx=*/%v52190 (stack43)
        %v52198 = vmul.f32 1.4140625, %v52194 (stack53)
        %v52201 = vpack.c.bf16 0.0, %v52198 (stack74)
        %120021 = vst [vmem:[%s280 + $0x334] sm:$0xf] /*vst_source=*/%v52201 (stack75)
        %v52205 = vadd.s32 %v48975, %v3816 (stack39)
        %v52215 = vadd.s32 %v52205, %v415 (stack39)
        %vm52219 = vcmp.lt.u32.totalorder %v52215, %v52205 (stack42)
        %vm52224 = vcmp.lt.u32.totalorder %v52205, %v3816 (stack42)
        %v52229 = vadd.s32 %v48958, %v3803 (stack39)
        %v52233 = vadd.s32 1, %v52229 (stack39)
        %v52237 = vsel /*vm=*/%vm52224, /*on_true_vy=*/%v52233, /*on_false_vx=*/%v52229 (stack43)
        %v52241 = vadd.s32 1, %v52237 (stack39)
        %v52245 = vsel /*vm=*/%vm52219, /*on_true_vy=*/%v52241, /*on_false_vx=*/%v52237 (stack43)
        %v52250 = vadd.s32 %v52245, %v10 (stack39)
        %v52254 = vadd.s32 %v52215, %v9 (stack39)
        %v52258 = vadd.s32 %v52254, %v52250 (stack39)
        %v52260 = vshll.u32 %v52254, 13 (stack44)
        %v52261 = vshrl.u32 %v52254, 19 (stack45)
        %v52262 = vor.u32 %v52261, %v52260 (stack46)
        %v52263 = vxor.u32 %v52262, %v52258 (stack47)
        %v52266 = vadd.s32 %v52263, %v52258 (stack39)
        %v52268 = vshll.u32 %v52263, 15 (stack44)
        %v52269 = vshrl.u32 %v52263, 17 (stack45)
        %v52270 = vor.u32 %v52269, %v52268 (stack46)
        %v52271 = vxor.u32 %v52270, %v52266 (stack47)
        %v52274 = vadd.s32 %v52271, %v52266 (stack39)
        %v52276 = vshll.u32 %v52271, 26 (stack44)
        %v52277 = vshrl.u32 %v52271, 6 (stack45)
        %v52278 = vor.u32 %v52277, %v52276 (stack46)
        %v52279 = vxor.u32 %v52278, %v52274 (stack47)
        %v52282 = vadd.s32 %v52279, %v52274 (stack39)
        %v52286 = vadd.s32 %v52282, %v9 (stack39)
        %v52288 = vshll.u32 %v52279, 6 (stack44)
        %v52289 = vshrl.u32 %v52279, 26 (stack45)
        %v52290 = vor.u32 %v52289, %v52288 (stack46)
        %v52291 = vxor.u32 %v52290, %v52282 (stack47)
        %v52294 = vadd.s32 %v52291, %v8 (stack39)
        %v52298 = vadd.s32 1, %v52294 (stack39)
        %v52302 = vadd.s32 %v52298, %v52286 (stack39)
        %v52304 = vshll.u32 %v52298, 17 (stack44)
        %v52305 = vshrl.u32 %v52298, 15 (stack45)
        %v52306 = vor.u32 %v52305, %v52304 (stack46)
        %v52307 = vxor.u32 %v52306, %v52302 (stack47)
        %v52310 = vadd.s32 %v52307, %v52302 (stack39)
        %v52312 = vshll.u32 %v52307, 29 (stack44)
        %v52313 = vshrl.u32 %v52307, 3 (stack45)
        %v52314 = vor.u32 %v52313, %v52312 (stack46)
        %v52315 = vxor.u32 %v52314, %v52310 (stack47)
        %v52318 = vadd.s32 %v52315, %v52310 (stack39)
        %v52320 = vshll.u32 %v52315, 16 (stack44)
        %v52321 = vshrl.u32 %v52315, 16 (stack45)
        %v52322 = vor.u32 %v52321, %v52320 (stack46)
        %v52323 = vxor.u32 %v52322, %v52318 (stack47)
        %v52326 = vadd.s32 %v52323, %v52318 (stack39)
        %v52330 = vadd.s32 %v52326, %v8 (stack39)
        %v52332 = vshll.u32 %v52323, 24 (stack44)
        %v52333 = vshrl.u32 %v52323, 8 (stack45)
        %v52334 = vor.u32 %v52333, %v52332 (stack46)
        %v52335 = vxor.u32 %v52334, %v52326 (stack47)
        %v52338 = vadd.s32 %v52335, %v10 (stack39)
        %v52342 = vadd.s32 2, %v52338 (stack39)
        %v52346 = vadd.s32 %v52342, %v52330 (stack39)
        %v52348 = vshll.u32 %v52342, 13 (stack44)
        %v52349 = vshrl.u32 %v52342, 19 (stack45)
        %v52350 = vor.u32 %v52349, %v52348 (stack46)
        %v52351 = vxor.u32 %v52350, %v52346 (stack47)
        %v52354 = vadd.s32 %v52351, %v52346 (stack39)
        %v52356 = vshll.u32 %v52351, 15 (stack44)
        %v52357 = vshrl.u32 %v52351, 17 (stack45)
        %v52358 = vor.u32 %v52357, %v52356 (stack46)
        %v52359 = vxor.u32 %v52358, %v52354 (stack47)
        %v52362 = vadd.s32 %v52359, %v52354 (stack39)
        %v52364 = vshll.u32 %v52359, 26 (stack44)
        %v52365 = vshrl.u32 %v52359, 6 (stack45)
        %v52366 = vor.u32 %v52365, %v52364 (stack46)
        %v52367 = vxor.u32 %v52366, %v52362 (stack47)
        %v52370 = vadd.s32 %v52367, %v52362 (stack39)
        %v52374 = vadd.s32 %v52370, %v10 (stack39)
        %v52376 = vshll.u32 %v52367, 6 (stack44)
        %v52377 = vshrl.u32 %v52367, 26 (stack45)
        %v52378 = vor.u32 %v52377, %v52376 (stack46)
        %v52379 = vxor.u32 %v52378, %v52370 (stack47)
        %v52382 = vadd.s32 %v52379, %v9 (stack39)
        %v52386 = vadd.s32 3, %v52382 (stack39)
        %v52390 = vadd.s32 %v52386, %v52374 (stack39)
        %v52392 = vshll.u32 %v52386, 17 (stack44)
        %v52393 = vshrl.u32 %v52386, 15 (stack45)
        %v52394 = vor.u32 %v52393, %v52392 (stack46)
        %v52395 = vxor.u32 %v52394, %v52390 (stack47)
        %v52398 = vadd.s32 %v52395, %v52390 (stack39)
        %v52400 = vshll.u32 %v52395, 29 (stack44)
        %v52401 = vshrl.u32 %v52395, 3 (stack45)
        %v52402 = vor.u32 %v52401, %v52400 (stack46)
        %v52403 = vxor.u32 %v52402, %v52398 (stack47)
        %v52406 = vadd.s32 %v52403, %v52398 (stack39)
        %v52408 = vshll.u32 %v52403, 16 (stack44)
        %v52409 = vshrl.u32 %v52403, 16 (stack45)
        %v52410 = vor.u32 %v52409, %v52408 (stack46)
        %v52411 = vxor.u32 %v52410, %v52406 (stack47)
        %v52414 = vadd.s32 %v52411, %v52406 (stack39)
        %v52418 = vadd.s32 %v52414, %v9 (stack39)
        %v52420 = vshll.u32 %v52411, 24 (stack44)
        %v52421 = vshrl.u32 %v52411, 8 (stack45)
        %v52422 = vor.u32 %v52421, %v52420 (stack46)
        %v52423 = vxor.u32 %v52422, %v52414 (stack47)
        %v52426 = vadd.s32 %v52423, %v8 (stack39)
        %v52430 = vadd.s32 4, %v52426 (stack39)
        %v52434 = vadd.s32 %v52430, %v52418 (stack39)
        %v52436 = vshll.u32 %v52430, 13 (stack44)
        %v52437 = vshrl.u32 %v52430, 19 (stack45)
        %v52438 = vor.u32 %v52437, %v52436 (stack46)
        %v52439 = vxor.u32 %v52438, %v52434 (stack47)
        %v52442 = vadd.s32 %v52439, %v52434 (stack39)
        %v52444 = vshll.u32 %v52439, 15 (stack44)
        %v52445 = vshrl.u32 %v52439, 17 (stack45)
        %v52446 = vor.u32 %v52445, %v52444 (stack46)
        %v52447 = vxor.u32 %v52446, %v52442 (stack47)
        %v52450 = vadd.s32 %v52447, %v52442 (stack39)
        %v52452 = vshll.u32 %v52447, 26 (stack44)
        %v52453 = vshrl.u32 %v52447, 6 (stack45)
        %v52454 = vor.u32 %v52453, %v52452 (stack46)
        %v52455 = vxor.u32 %v52454, %v52450 (stack47)
        %v52458 = vadd.s32 %v52455, %v52450 (stack39)
        %v52462 = vadd.s32 %v52458, %v8 (stack39)
        %v52464 = vshll.u32 %v52455, 6 (stack44)
        %v52465 = vshrl.u32 %v52455, 26 (stack45)
        %v52466 = vor.u32 %v52465, %v52464 (stack46)
        %v52467 = vxor.u32 %v52466, %v52458 (stack47)
        %v52470 = vadd.s32 %v52467, %v10 (stack39)
        %v52474 = vadd.s32 5, %v52470 (stack39)
        %v52476 = vxor.u32 %v52474, %v52462 (stack47)
        %v52477 = vand.u32.u8 255, %v52476 (stack48)
        %v52478 = vand.u32 65535, %v52477 (stack49)
        %v52479 = vshrl.u32 %v52478, 1 (stack50)
        %v52480 = vor.u32 16256, %v52479 (stack46)
        %v52481 = vand.u32.u16 65535, %v52480 (stack51)
        %v120022 = vadd.low.f32.bf16 -1.0, %v52481 (stack52)
        %v52490 = vmul.f32 2.0, %v120022 (stack53)
        %v52494 = vadd.f32 -0.99609375, %v52490 (stack52)
        %v52498 = vmax.f32 %v52494, -0.99609375 (stack54)
        %v52500 = vand.u32 2147483647, %v52498 (stack55)
        %vm52503 = vcmp.eq.f32.partialorder %v52500, 1.0 (stack56)
        %v52508 = vmul.f32 inf, %v52498 (stack53)
        %v52510 = vxor.u32 2147483648, %v52498 (stack57)
        %v52513 = vmul.f32 %v52510, %v52498 (stack53)
        %v52515 = vadd.f32 1.0, %v52513 (stack58)
        %v52516 = vlog2.pop %v52515 (stack59)
        %v52517 = vmul.f32 0.6931472, %v52516 (stack60)
        %v52518 = vmul.f32 -0.5, %v52513 (stack61)
        %v52519 = vadd.f32 1.0, %v52518 (stack62)
        %v52520 = vmul.f32 %v52519, %v52513 (stack63)
        %v52521 = vand.u32 2147483647, %v52513 (stack64)
        %vm52522 = vcmp.lt.f32.partialorder %v52521, 0.0004427343 (stack65)
        %v52523 = vsel /*vm=*/%vm52522, /*on_true_vy=*/%v52520, /*on_false_vx=*/%v52517 (stack66)
        %v52524 = vxor.u32 2147483648, %v52523 (stack57)
        %vm52527 = vcmp.lt.f32.partialorder %v52524, 5.0 (stack56)
        %v52532 = vsel /*vm=*/%vm52527, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v52536 = vsel /*vm=*/%vm52527, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v52540 = vsel /*vm=*/%vm52527, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v52544 = vsel /*vm=*/%vm52527, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v52548 = vsel /*vm=*/%vm52527, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v52552 = vsel /*vm=*/%vm52527, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v52556 = vsel /*vm=*/%vm52527, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v52560 = vsel /*vm=*/%vm52527, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v52564 = vsel /*vm=*/%vm52527, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v52568 = vadd.f32 -2.5, %v52524 (stack52)
        %v52570 = vrsqrt.pop %v52524 (stack67)
        %v52571 = vmul.f32 %v52570, %v52524 (stack68)
        %vm52572 = vcmp.eq.f32.partialorder %v52524, inf (stack69)
        %v52573 = vsel /*vm=*/%vm52572, /*on_true_vy=*/%v52524, /*on_false_vx=*/%v52571 (stack70)
        %vm52574 = vcmp.eq.f32.partialorder %v52524, 0.0 (stack71)
        %v52575 = vand.u32 2147483648, %v52524 (stack72)
        %v52576 = vsel /*vm=*/%vm52574, /*on_true_vy=*/%v52575, /*on_false_vx=*/%v52573 (stack73)
        %v52579 = vadd.f32 -3.0, %v52576 (stack52)
        %v52583 = vsel /*vm=*/%vm52527, /*on_true_vy=*/%v52568, /*on_false_vx=*/%v52579 (stack43)
        %v52587 = vmul.f32 %v52583, %v52564 (stack53)
        %v52591 = vadd.f32 %v52587, %v52560 (stack52)
        %v52595 = vmul.f32 %v52591, %v52583 (stack53)
        %v52599 = vadd.f32 %v52595, %v52556 (stack52)
        %v52603 = vmul.f32 %v52599, %v52583 (stack53)
        %v52607 = vadd.f32 %v52603, %v52552 (stack52)
        %v52611 = vmul.f32 %v52607, %v52583 (stack53)
        %v52615 = vadd.f32 %v52611, %v52548 (stack52)
        %v52619 = vmul.f32 %v52615, %v52583 (stack53)
        %v52623 = vadd.f32 %v52619, %v52544 (stack52)
        %v52627 = vmul.f32 %v52623, %v52583 (stack53)
        %v52631 = vadd.f32 %v52627, %v52540 (stack52)
        %v52635 = vmul.f32 %v52631, %v52583 (stack53)
        %v52639 = vadd.f32 %v52635, %v52536 (stack52)
        %v52643 = vmul.f32 %v52639, %v52583 (stack53)
        %v52647 = vadd.f32 %v52643, %v52532 (stack52)
        %v52651 = vmul.f32 %v52647, %v52498 (stack53)
        %v52655 = vsel /*vm=*/%vm52503, /*on_true_vy=*/%v52508, /*on_false_vx=*/%v52651 (stack43)
        %v52659 = vmul.f32 1.4140625, %v52655 (stack53)
        %v52662 = vpack.c.bf16 0.0, %v52659 (stack74)
        %120023 = vst [vmem:[%s280 + $0x3b4] sm:$0xf] /*vst_source=*/%v52662 (stack75)
        %s52664 = sadd.s32 112, %s120390 (stack76)
        %s52665 = sshrl.u32 %s52664, 10 (stack23)
        %p120024 = scmp.gt.s32.totalorder %s52665, 1 (stack24)
        %s52667 = scalar_select /*predicate=*/%p120024, /*on_true=*/1, /*on_false=*/%s52665 (stack25)
        %s52668 = sand.u32 1023, %s52664 /* smod.u32 w/div 1024 */ (stack26)
        %s52669 = sshrl.u32 %s52668, 7 (stack27)
        %s52670 = sand.u32 127, %s52668 /* smod.u32 w/div 128 */ (stack28)
        %s120025 = sshll.u32 %s52667, 3 (stack29)
        %s52672 = scalar_lea.vmem %s3, %s120025 (stack30)
        %s52674 = scalar_lea.vmem %s52672, %s52669 (stack31)
        %v52675 = vld [vmem:[%s52674] ss:$0 sm:$0xff] (stack32)
        %s52676 = sand.u32 255, %s52670 (stack33)
        %s52678 = sor.u32 256, %s52676 (stack34)
        %52679 = vbcast.lane.b32.xlu0 %v52675, %s52678 (stack35)
        %v52680 = vpop.permute.xlu0 %52679 (stack36)
        %s52689 = scalar_lea.vmem %s5, %s120025 (stack30)
        %s52691 = scalar_lea.vmem %s52689, %s52669 (stack31)
        %v52692 = vld [vmem:[%s52691] ss:$0 sm:$0xff] (stack32)
        %52696 = vbcast.lane.b32.xlu0 %v52692, %s52678 (stack35)
        %v52697 = vpop.permute.xlu0 %52696 (stack36)
        %v52700 = vadd.s32 %v52697, %v408 (stack39)
        %v52710 = vadd.s32 %v52700, %v415 (stack39)
        %vm52714 = vcmp.lt.u32.totalorder %v52710, %v52700 (stack42)
        %vm52719 = vcmp.lt.u32.totalorder %v52700, %v408 (stack42)
        %v52724 = vadd.s32 %v52680, %v380 (stack39)
        %v52728 = vadd.s32 1, %v52724 (stack39)
        %v52732 = vsel /*vm=*/%vm52719, /*on_true_vy=*/%v52728, /*on_false_vx=*/%v52724 (stack43)
        %v52736 = vadd.s32 1, %v52732 (stack39)
        %v52740 = vsel /*vm=*/%vm52714, /*on_true_vy=*/%v52736, /*on_false_vx=*/%v52732 (stack43)
        %v52745 = vadd.s32 %v52740, %v10 (stack39)
        %v52749 = vadd.s32 %v52710, %v9 (stack39)
        %v52753 = vadd.s32 %v52749, %v52745 (stack39)
        %v52755 = vshll.u32 %v52749, 13 (stack44)
        %v52756 = vshrl.u32 %v52749, 19 (stack45)
        %v52757 = vor.u32 %v52756, %v52755 (stack46)
        %v52758 = vxor.u32 %v52757, %v52753 (stack47)
        %v52761 = vadd.s32 %v52758, %v52753 (stack39)
        %v52763 = vshll.u32 %v52758, 15 (stack44)
        %v52764 = vshrl.u32 %v52758, 17 (stack45)
        %v52765 = vor.u32 %v52764, %v52763 (stack46)
        %v52766 = vxor.u32 %v52765, %v52761 (stack47)
        %v52769 = vadd.s32 %v52766, %v52761 (stack39)
        %v52771 = vshll.u32 %v52766, 26 (stack44)
        %v52772 = vshrl.u32 %v52766, 6 (stack45)
        %v52773 = vor.u32 %v52772, %v52771 (stack46)
        %v52774 = vxor.u32 %v52773, %v52769 (stack47)
        %v52777 = vadd.s32 %v52774, %v52769 (stack39)
        %v52781 = vadd.s32 %v52777, %v9 (stack39)
        %v52783 = vshll.u32 %v52774, 6 (stack44)
        %v52784 = vshrl.u32 %v52774, 26 (stack45)
        %v52785 = vor.u32 %v52784, %v52783 (stack46)
        %v52786 = vxor.u32 %v52785, %v52777 (stack47)
        %v52789 = vadd.s32 %v52786, %v8 (stack39)
        %v52793 = vadd.s32 1, %v52789 (stack39)
        %v52797 = vadd.s32 %v52793, %v52781 (stack39)
        %v52799 = vshll.u32 %v52793, 17 (stack44)
        %v52800 = vshrl.u32 %v52793, 15 (stack45)
        %v52801 = vor.u32 %v52800, %v52799 (stack46)
        %v52802 = vxor.u32 %v52801, %v52797 (stack47)
        %v52805 = vadd.s32 %v52802, %v52797 (stack39)
        %v52807 = vshll.u32 %v52802, 29 (stack44)
        %v52808 = vshrl.u32 %v52802, 3 (stack45)
        %v52809 = vor.u32 %v52808, %v52807 (stack46)
        %v52810 = vxor.u32 %v52809, %v52805 (stack47)
        %v52813 = vadd.s32 %v52810, %v52805 (stack39)
        %v52815 = vshll.u32 %v52810, 16 (stack44)
        %v52816 = vshrl.u32 %v52810, 16 (stack45)
        %v52817 = vor.u32 %v52816, %v52815 (stack46)
        %v52818 = vxor.u32 %v52817, %v52813 (stack47)
        %v52821 = vadd.s32 %v52818, %v52813 (stack39)
        %v52825 = vadd.s32 %v52821, %v8 (stack39)
        %v52827 = vshll.u32 %v52818, 24 (stack44)
        %v52828 = vshrl.u32 %v52818, 8 (stack45)
        %v52829 = vor.u32 %v52828, %v52827 (stack46)
        %v52830 = vxor.u32 %v52829, %v52821 (stack47)
        %v52833 = vadd.s32 %v52830, %v10 (stack39)
        %v52837 = vadd.s32 2, %v52833 (stack39)
        %v52841 = vadd.s32 %v52837, %v52825 (stack39)
        %v52843 = vshll.u32 %v52837, 13 (stack44)
        %v52844 = vshrl.u32 %v52837, 19 (stack45)
        %v52845 = vor.u32 %v52844, %v52843 (stack46)
        %v52846 = vxor.u32 %v52845, %v52841 (stack47)
        %v52849 = vadd.s32 %v52846, %v52841 (stack39)
        %v52851 = vshll.u32 %v52846, 15 (stack44)
        %v52852 = vshrl.u32 %v52846, 17 (stack45)
        %v52853 = vor.u32 %v52852, %v52851 (stack46)
        %v52854 = vxor.u32 %v52853, %v52849 (stack47)
        %v52857 = vadd.s32 %v52854, %v52849 (stack39)
        %v52859 = vshll.u32 %v52854, 26 (stack44)
        %v52860 = vshrl.u32 %v52854, 6 (stack45)
        %v52861 = vor.u32 %v52860, %v52859 (stack46)
        %v52862 = vxor.u32 %v52861, %v52857 (stack47)
        %v52865 = vadd.s32 %v52862, %v52857 (stack39)
        %v52869 = vadd.s32 %v52865, %v10 (stack39)
        %v52871 = vshll.u32 %v52862, 6 (stack44)
        %v52872 = vshrl.u32 %v52862, 26 (stack45)
        %v52873 = vor.u32 %v52872, %v52871 (stack46)
        %v52874 = vxor.u32 %v52873, %v52865 (stack47)
        %v52877 = vadd.s32 %v52874, %v9 (stack39)
        %v52881 = vadd.s32 3, %v52877 (stack39)
        %v52885 = vadd.s32 %v52881, %v52869 (stack39)
        %v52887 = vshll.u32 %v52881, 17 (stack44)
        %v52888 = vshrl.u32 %v52881, 15 (stack45)
        %v52889 = vor.u32 %v52888, %v52887 (stack46)
        %v52890 = vxor.u32 %v52889, %v52885 (stack47)
        %v52893 = vadd.s32 %v52890, %v52885 (stack39)
        %v52895 = vshll.u32 %v52890, 29 (stack44)
        %v52896 = vshrl.u32 %v52890, 3 (stack45)
        %v52897 = vor.u32 %v52896, %v52895 (stack46)
        %v52898 = vxor.u32 %v52897, %v52893 (stack47)
        %v52901 = vadd.s32 %v52898, %v52893 (stack39)
        %v52903 = vshll.u32 %v52898, 16 (stack44)
        %v52904 = vshrl.u32 %v52898, 16 (stack45)
        %v52905 = vor.u32 %v52904, %v52903 (stack46)
        %v52906 = vxor.u32 %v52905, %v52901 (stack47)
        %v52909 = vadd.s32 %v52906, %v52901 (stack39)
        %v52913 = vadd.s32 %v52909, %v9 (stack39)
        %v52915 = vshll.u32 %v52906, 24 (stack44)
        %v52916 = vshrl.u32 %v52906, 8 (stack45)
        %v52917 = vor.u32 %v52916, %v52915 (stack46)
        %v52918 = vxor.u32 %v52917, %v52909 (stack47)
        %v52921 = vadd.s32 %v52918, %v8 (stack39)
        %v52925 = vadd.s32 4, %v52921 (stack39)
        %v52929 = vadd.s32 %v52925, %v52913 (stack39)
        %v52931 = vshll.u32 %v52925, 13 (stack44)
        %v52932 = vshrl.u32 %v52925, 19 (stack45)
        %v52933 = vor.u32 %v52932, %v52931 (stack46)
        %v52934 = vxor.u32 %v52933, %v52929 (stack47)
        %v52937 = vadd.s32 %v52934, %v52929 (stack39)
        %v52939 = vshll.u32 %v52934, 15 (stack44)
        %v52940 = vshrl.u32 %v52934, 17 (stack45)
        %v52941 = vor.u32 %v52940, %v52939 (stack46)
        %v52942 = vxor.u32 %v52941, %v52937 (stack47)
        %v52945 = vadd.s32 %v52942, %v52937 (stack39)
        %v52947 = vshll.u32 %v52942, 26 (stack44)
        %v52948 = vshrl.u32 %v52942, 6 (stack45)
        %v52949 = vor.u32 %v52948, %v52947 (stack46)
        %v52950 = vxor.u32 %v52949, %v52945 (stack47)
        %v52953 = vadd.s32 %v52950, %v52945 (stack39)
        %v52957 = vadd.s32 %v52953, %v8 (stack39)
        %v52959 = vshll.u32 %v52950, 6 (stack44)
        %v52960 = vshrl.u32 %v52950, 26 (stack45)
        %v52961 = vor.u32 %v52960, %v52959 (stack46)
        %v52962 = vxor.u32 %v52961, %v52953 (stack47)
        %v52965 = vadd.s32 %v52962, %v10 (stack39)
        %v52969 = vadd.s32 5, %v52965 (stack39)
        %v52971 = vxor.u32 %v52969, %v52957 (stack47)
        %v52972 = vand.u32.u8 255, %v52971 (stack48)
        %v52973 = vand.u32 65535, %v52972 (stack49)
        %v52974 = vshrl.u32 %v52973, 1 (stack50)
        %v52975 = vor.u32 16256, %v52974 (stack46)
        %v52976 = vand.u32.u16 65535, %v52975 (stack51)
        %v120028 = vadd.low.f32.bf16 -1.0, %v52976 (stack52)
        %v52985 = vmul.f32 2.0, %v120028 (stack53)
        %v52989 = vadd.f32 -0.99609375, %v52985 (stack52)
        %v52993 = vmax.f32 %v52989, -0.99609375 (stack54)
        %v52995 = vand.u32 2147483647, %v52993 (stack55)
        %vm52998 = vcmp.eq.f32.partialorder %v52995, 1.0 (stack56)
        %v53003 = vmul.f32 inf, %v52993 (stack53)
        %v53005 = vxor.u32 2147483648, %v52993 (stack57)
        %v53008 = vmul.f32 %v53005, %v52993 (stack53)
        %v53010 = vadd.f32 1.0, %v53008 (stack58)
        %v53011 = vlog2.pop %v53010 (stack59)
        %v53012 = vmul.f32 0.6931472, %v53011 (stack60)
        %v53013 = vmul.f32 -0.5, %v53008 (stack61)
        %v53014 = vadd.f32 1.0, %v53013 (stack62)
        %v53015 = vmul.f32 %v53014, %v53008 (stack63)
        %v53016 = vand.u32 2147483647, %v53008 (stack64)
        %vm53017 = vcmp.lt.f32.partialorder %v53016, 0.0004427343 (stack65)
        %v53018 = vsel /*vm=*/%vm53017, /*on_true_vy=*/%v53015, /*on_false_vx=*/%v53012 (stack66)
        %v53019 = vxor.u32 2147483648, %v53018 (stack57)
        %vm53022 = vcmp.lt.f32.partialorder %v53019, 5.0 (stack56)
        %v53027 = vsel /*vm=*/%vm53022, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v53031 = vsel /*vm=*/%vm53022, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v53035 = vsel /*vm=*/%vm53022, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v53039 = vsel /*vm=*/%vm53022, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v53043 = vsel /*vm=*/%vm53022, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v53047 = vsel /*vm=*/%vm53022, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v53051 = vsel /*vm=*/%vm53022, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v53055 = vsel /*vm=*/%vm53022, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v53059 = vsel /*vm=*/%vm53022, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v53063 = vadd.f32 -2.5, %v53019 (stack52)
        %v53065 = vrsqrt.pop %v53019 (stack67)
        %v53066 = vmul.f32 %v53065, %v53019 (stack68)
        %vm53067 = vcmp.eq.f32.partialorder %v53019, inf (stack69)
        %v53068 = vsel /*vm=*/%vm53067, /*on_true_vy=*/%v53019, /*on_false_vx=*/%v53066 (stack70)
        %vm53069 = vcmp.eq.f32.partialorder %v53019, 0.0 (stack71)
        %v53070 = vand.u32 2147483648, %v53019 (stack72)
        %v53071 = vsel /*vm=*/%vm53069, /*on_true_vy=*/%v53070, /*on_false_vx=*/%v53068 (stack73)
        %v53074 = vadd.f32 -3.0, %v53071 (stack52)
        %v53078 = vsel /*vm=*/%vm53022, /*on_true_vy=*/%v53063, /*on_false_vx=*/%v53074 (stack43)
        %v53082 = vmul.f32 %v53078, %v53059 (stack53)
        %v53086 = vadd.f32 %v53082, %v53055 (stack52)
        %v53090 = vmul.f32 %v53086, %v53078 (stack53)
        %v53094 = vadd.f32 %v53090, %v53051 (stack52)
        %v53098 = vmul.f32 %v53094, %v53078 (stack53)
        %v53102 = vadd.f32 %v53098, %v53047 (stack52)
        %v53106 = vmul.f32 %v53102, %v53078 (stack53)
        %v53110 = vadd.f32 %v53106, %v53043 (stack52)
        %v53114 = vmul.f32 %v53110, %v53078 (stack53)
        %v53118 = vadd.f32 %v53114, %v53039 (stack52)
        %v53122 = vmul.f32 %v53118, %v53078 (stack53)
        %v53126 = vadd.f32 %v53122, %v53035 (stack52)
        %v53130 = vmul.f32 %v53126, %v53078 (stack53)
        %v53134 = vadd.f32 %v53130, %v53031 (stack52)
        %v53138 = vmul.f32 %v53134, %v53078 (stack53)
        %v53142 = vadd.f32 %v53138, %v53027 (stack52)
        %v53146 = vmul.f32 %v53142, %v52993 (stack53)
        %v53150 = vsel /*vm=*/%vm52998, /*on_true_vy=*/%v53003, /*on_false_vx=*/%v53146 (stack43)
        %v53154 = vmul.f32 1.4140625, %v53150 (stack53)
        %v53157 = vpack.c.bf16 0.0, %v53154 (stack74)
        %120029 = vst [vmem:[%s280 + $0x38] sm:$0xf] /*vst_source=*/%v53157 (stack75)
        %v53161 = vadd.s32 %v52697, %v894 (stack39)
        %v53171 = vadd.s32 %v53161, %v415 (stack39)
        %vm53175 = vcmp.lt.u32.totalorder %v53171, %v53161 (stack42)
        %vm53180 = vcmp.lt.u32.totalorder %v53161, %v894 (stack42)
        %v53185 = vadd.s32 %v52680, %v881 (stack39)
        %v53189 = vadd.s32 1, %v53185 (stack39)
        %v53193 = vsel /*vm=*/%vm53180, /*on_true_vy=*/%v53189, /*on_false_vx=*/%v53185 (stack43)
        %v53197 = vadd.s32 1, %v53193 (stack39)
        %v53201 = vsel /*vm=*/%vm53175, /*on_true_vy=*/%v53197, /*on_false_vx=*/%v53193 (stack43)
        %v53206 = vadd.s32 %v53201, %v10 (stack39)
        %v53210 = vadd.s32 %v53171, %v9 (stack39)
        %v53214 = vadd.s32 %v53210, %v53206 (stack39)
        %v53216 = vshll.u32 %v53210, 13 (stack44)
        %v53217 = vshrl.u32 %v53210, 19 (stack45)
        %v53218 = vor.u32 %v53217, %v53216 (stack46)
        %v53219 = vxor.u32 %v53218, %v53214 (stack47)
        %v53222 = vadd.s32 %v53219, %v53214 (stack39)
        %v53224 = vshll.u32 %v53219, 15 (stack44)
        %v53225 = vshrl.u32 %v53219, 17 (stack45)
        %v53226 = vor.u32 %v53225, %v53224 (stack46)
        %v53227 = vxor.u32 %v53226, %v53222 (stack47)
        %v53230 = vadd.s32 %v53227, %v53222 (stack39)
        %v53232 = vshll.u32 %v53227, 26 (stack44)
        %v53233 = vshrl.u32 %v53227, 6 (stack45)
        %v53234 = vor.u32 %v53233, %v53232 (stack46)
        %v53235 = vxor.u32 %v53234, %v53230 (stack47)
        %v53238 = vadd.s32 %v53235, %v53230 (stack39)
        %v53242 = vadd.s32 %v53238, %v9 (stack39)
        %v53244 = vshll.u32 %v53235, 6 (stack44)
        %v53245 = vshrl.u32 %v53235, 26 (stack45)
        %v53246 = vor.u32 %v53245, %v53244 (stack46)
        %v53247 = vxor.u32 %v53246, %v53238 (stack47)
        %v53250 = vadd.s32 %v53247, %v8 (stack39)
        %v53254 = vadd.s32 1, %v53250 (stack39)
        %v53258 = vadd.s32 %v53254, %v53242 (stack39)
        %v53260 = vshll.u32 %v53254, 17 (stack44)
        %v53261 = vshrl.u32 %v53254, 15 (stack45)
        %v53262 = vor.u32 %v53261, %v53260 (stack46)
        %v53263 = vxor.u32 %v53262, %v53258 (stack47)
        %v53266 = vadd.s32 %v53263, %v53258 (stack39)
        %v53268 = vshll.u32 %v53263, 29 (stack44)
        %v53269 = vshrl.u32 %v53263, 3 (stack45)
        %v53270 = vor.u32 %v53269, %v53268 (stack46)
        %v53271 = vxor.u32 %v53270, %v53266 (stack47)
        %v53274 = vadd.s32 %v53271, %v53266 (stack39)
        %v53276 = vshll.u32 %v53271, 16 (stack44)
        %v53277 = vshrl.u32 %v53271, 16 (stack45)
        %v53278 = vor.u32 %v53277, %v53276 (stack46)
        %v53279 = vxor.u32 %v53278, %v53274 (stack47)
        %v53282 = vadd.s32 %v53279, %v53274 (stack39)
        %v53286 = vadd.s32 %v53282, %v8 (stack39)
        %v53288 = vshll.u32 %v53279, 24 (stack44)
        %v53289 = vshrl.u32 %v53279, 8 (stack45)
        %v53290 = vor.u32 %v53289, %v53288 (stack46)
        %v53291 = vxor.u32 %v53290, %v53282 (stack47)
        %v53294 = vadd.s32 %v53291, %v10 (stack39)
        %v53298 = vadd.s32 2, %v53294 (stack39)
        %v53302 = vadd.s32 %v53298, %v53286 (stack39)
        %v53304 = vshll.u32 %v53298, 13 (stack44)
        %v53305 = vshrl.u32 %v53298, 19 (stack45)
        %v53306 = vor.u32 %v53305, %v53304 (stack46)
        %v53307 = vxor.u32 %v53306, %v53302 (stack47)
        %v53310 = vadd.s32 %v53307, %v53302 (stack39)
        %v53312 = vshll.u32 %v53307, 15 (stack44)
        %v53313 = vshrl.u32 %v53307, 17 (stack45)
        %v53314 = vor.u32 %v53313, %v53312 (stack46)
        %v53315 = vxor.u32 %v53314, %v53310 (stack47)
        %v53318 = vadd.s32 %v53315, %v53310 (stack39)
        %v53320 = vshll.u32 %v53315, 26 (stack44)
        %v53321 = vshrl.u32 %v53315, 6 (stack45)
        %v53322 = vor.u32 %v53321, %v53320 (stack46)
        %v53323 = vxor.u32 %v53322, %v53318 (stack47)
        %v53326 = vadd.s32 %v53323, %v53318 (stack39)
        %v53330 = vadd.s32 %v53326, %v10 (stack39)
        %v53332 = vshll.u32 %v53323, 6 (stack44)
        %v53333 = vshrl.u32 %v53323, 26 (stack45)
        %v53334 = vor.u32 %v53333, %v53332 (stack46)
        %v53335 = vxor.u32 %v53334, %v53326 (stack47)
        %v53338 = vadd.s32 %v53335, %v9 (stack39)
        %v53342 = vadd.s32 3, %v53338 (stack39)
        %v53346 = vadd.s32 %v53342, %v53330 (stack39)
        %v53348 = vshll.u32 %v53342, 17 (stack44)
        %v53349 = vshrl.u32 %v53342, 15 (stack45)
        %v53350 = vor.u32 %v53349, %v53348 (stack46)
        %v53351 = vxor.u32 %v53350, %v53346 (stack47)
        %v53354 = vadd.s32 %v53351, %v53346 (stack39)
        %v53356 = vshll.u32 %v53351, 29 (stack44)
        %v53357 = vshrl.u32 %v53351, 3 (stack45)
        %v53358 = vor.u32 %v53357, %v53356 (stack46)
        %v53359 = vxor.u32 %v53358, %v53354 (stack47)
        %v53362 = vadd.s32 %v53359, %v53354 (stack39)
        %v53364 = vshll.u32 %v53359, 16 (stack44)
        %v53365 = vshrl.u32 %v53359, 16 (stack45)
        %v53366 = vor.u32 %v53365, %v53364 (stack46)
        %v53367 = vxor.u32 %v53366, %v53362 (stack47)
        %v53370 = vadd.s32 %v53367, %v53362 (stack39)
        %v53374 = vadd.s32 %v53370, %v9 (stack39)
        %v53376 = vshll.u32 %v53367, 24 (stack44)
        %v53377 = vshrl.u32 %v53367, 8 (stack45)
        %v53378 = vor.u32 %v53377, %v53376 (stack46)
        %v53379 = vxor.u32 %v53378, %v53370 (stack47)
        %v53382 = vadd.s32 %v53379, %v8 (stack39)
        %v53386 = vadd.s32 4, %v53382 (stack39)
        %v53390 = vadd.s32 %v53386, %v53374 (stack39)
        %v53392 = vshll.u32 %v53386, 13 (stack44)
        %v53393 = vshrl.u32 %v53386, 19 (stack45)
        %v53394 = vor.u32 %v53393, %v53392 (stack46)
        %v53395 = vxor.u32 %v53394, %v53390 (stack47)
        %v53398 = vadd.s32 %v53395, %v53390 (stack39)
        %v53400 = vshll.u32 %v53395, 15 (stack44)
        %v53401 = vshrl.u32 %v53395, 17 (stack45)
        %v53402 = vor.u32 %v53401, %v53400 (stack46)
        %v53403 = vxor.u32 %v53402, %v53398 (stack47)
        %v53406 = vadd.s32 %v53403, %v53398 (stack39)
        %v53408 = vshll.u32 %v53403, 26 (stack44)
        %v53409 = vshrl.u32 %v53403, 6 (stack45)
        %v53410 = vor.u32 %v53409, %v53408 (stack46)
        %v53411 = vxor.u32 %v53410, %v53406 (stack47)
        %v53414 = vadd.s32 %v53411, %v53406 (stack39)
        %v53418 = vadd.s32 %v53414, %v8 (stack39)
        %v53420 = vshll.u32 %v53411, 6 (stack44)
        %v53421 = vshrl.u32 %v53411, 26 (stack45)
        %v53422 = vor.u32 %v53421, %v53420 (stack46)
        %v53423 = vxor.u32 %v53422, %v53414 (stack47)
        %v53426 = vadd.s32 %v53423, %v10 (stack39)
        %v53430 = vadd.s32 5, %v53426 (stack39)
        %v53432 = vxor.u32 %v53430, %v53418 (stack47)
        %v53433 = vand.u32.u8 255, %v53432 (stack48)
        %v53434 = vand.u32 65535, %v53433 (stack49)
        %v53435 = vshrl.u32 %v53434, 1 (stack50)
        %v53436 = vor.u32 16256, %v53435 (stack46)
        %v53437 = vand.u32.u16 65535, %v53436 (stack51)
        %v120030 = vadd.low.f32.bf16 -1.0, %v53437 (stack52)
        %v53446 = vmul.f32 2.0, %v120030 (stack53)
        %v53450 = vadd.f32 -0.99609375, %v53446 (stack52)
        %v53454 = vmax.f32 %v53450, -0.99609375 (stack54)
        %v53456 = vand.u32 2147483647, %v53454 (stack55)
        %vm53459 = vcmp.eq.f32.partialorder %v53456, 1.0 (stack56)
        %v53464 = vmul.f32 inf, %v53454 (stack53)
        %v53466 = vxor.u32 2147483648, %v53454 (stack57)
        %v53469 = vmul.f32 %v53466, %v53454 (stack53)
        %v53471 = vadd.f32 1.0, %v53469 (stack58)
        %v53472 = vlog2.pop %v53471 (stack59)
        %v53473 = vmul.f32 0.6931472, %v53472 (stack60)
        %v53474 = vmul.f32 -0.5, %v53469 (stack61)
        %v53475 = vadd.f32 1.0, %v53474 (stack62)
        %v53476 = vmul.f32 %v53475, %v53469 (stack63)
        %v53477 = vand.u32 2147483647, %v53469 (stack64)
        %vm53478 = vcmp.lt.f32.partialorder %v53477, 0.0004427343 (stack65)
        %v53479 = vsel /*vm=*/%vm53478, /*on_true_vy=*/%v53476, /*on_false_vx=*/%v53473 (stack66)
        %v53480 = vxor.u32 2147483648, %v53479 (stack57)
        %vm53483 = vcmp.lt.f32.partialorder %v53480, 5.0 (stack56)
        %v53488 = vsel /*vm=*/%vm53483, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v53492 = vsel /*vm=*/%vm53483, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v53496 = vsel /*vm=*/%vm53483, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v53500 = vsel /*vm=*/%vm53483, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v53504 = vsel /*vm=*/%vm53483, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v53508 = vsel /*vm=*/%vm53483, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v53512 = vsel /*vm=*/%vm53483, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v53516 = vsel /*vm=*/%vm53483, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v53520 = vsel /*vm=*/%vm53483, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v53524 = vadd.f32 -2.5, %v53480 (stack52)
        %v53526 = vrsqrt.pop %v53480 (stack67)
        %v53527 = vmul.f32 %v53526, %v53480 (stack68)
        %vm53528 = vcmp.eq.f32.partialorder %v53480, inf (stack69)
        %v53529 = vsel /*vm=*/%vm53528, /*on_true_vy=*/%v53480, /*on_false_vx=*/%v53527 (stack70)
        %vm53530 = vcmp.eq.f32.partialorder %v53480, 0.0 (stack71)
        %v53531 = vand.u32 2147483648, %v53480 (stack72)
        %v53532 = vsel /*vm=*/%vm53530, /*on_true_vy=*/%v53531, /*on_false_vx=*/%v53529 (stack73)
        %v53535 = vadd.f32 -3.0, %v53532 (stack52)
        %v53539 = vsel /*vm=*/%vm53483, /*on_true_vy=*/%v53524, /*on_false_vx=*/%v53535 (stack43)
        %v53543 = vmul.f32 %v53539, %v53520 (stack53)
        %v53547 = vadd.f32 %v53543, %v53516 (stack52)
        %v53551 = vmul.f32 %v53547, %v53539 (stack53)
        %v53555 = vadd.f32 %v53551, %v53512 (stack52)
        %v53559 = vmul.f32 %v53555, %v53539 (stack53)
        %v53563 = vadd.f32 %v53559, %v53508 (stack52)
        %v53567 = vmul.f32 %v53563, %v53539 (stack53)
        %v53571 = vadd.f32 %v53567, %v53504 (stack52)
        %v53575 = vmul.f32 %v53571, %v53539 (stack53)
        %v53579 = vadd.f32 %v53575, %v53500 (stack52)
        %v53583 = vmul.f32 %v53579, %v53539 (stack53)
        %v53587 = vadd.f32 %v53583, %v53496 (stack52)
        %v53591 = vmul.f32 %v53587, %v53539 (stack53)
        %v53595 = vadd.f32 %v53591, %v53492 (stack52)
        %v53599 = vmul.f32 %v53595, %v53539 (stack53)
        %v53603 = vadd.f32 %v53599, %v53488 (stack52)
        %v53607 = vmul.f32 %v53603, %v53454 (stack53)
        %v53611 = vsel /*vm=*/%vm53459, /*on_true_vy=*/%v53464, /*on_false_vx=*/%v53607 (stack43)
        %v53615 = vmul.f32 1.4140625, %v53611 (stack53)
        %v53618 = vpack.c.bf16 0.0, %v53615 (stack74)
        %120031 = vst [vmem:[%s280 + $0xb8] sm:$0xf] /*vst_source=*/%v53618 (stack75)
        %v53622 = vadd.s32 %v52697, %v1381 (stack39)
        %v53632 = vadd.s32 %v53622, %v415 (stack39)
        %vm53636 = vcmp.lt.u32.totalorder %v53632, %v53622 (stack42)
        %vm53641 = vcmp.lt.u32.totalorder %v53622, %v1381 (stack42)
        %v53646 = vadd.s32 %v52680, %v1368 (stack39)
        %v53650 = vadd.s32 1, %v53646 (stack39)
        %v53654 = vsel /*vm=*/%vm53641, /*on_true_vy=*/%v53650, /*on_false_vx=*/%v53646 (stack43)
        %v53658 = vadd.s32 1, %v53654 (stack39)
        %v53662 = vsel /*vm=*/%vm53636, /*on_true_vy=*/%v53658, /*on_false_vx=*/%v53654 (stack43)
        %v53667 = vadd.s32 %v53662, %v10 (stack39)
        %v53671 = vadd.s32 %v53632, %v9 (stack39)
        %v53675 = vadd.s32 %v53671, %v53667 (stack39)
        %v53677 = vshll.u32 %v53671, 13 (stack44)
        %v53678 = vshrl.u32 %v53671, 19 (stack45)
        %v53679 = vor.u32 %v53678, %v53677 (stack46)
        %v53680 = vxor.u32 %v53679, %v53675 (stack47)
        %v53683 = vadd.s32 %v53680, %v53675 (stack39)
        %v53685 = vshll.u32 %v53680, 15 (stack44)
        %v53686 = vshrl.u32 %v53680, 17 (stack45)
        %v53687 = vor.u32 %v53686, %v53685 (stack46)
        %v53688 = vxor.u32 %v53687, %v53683 (stack47)
        %v53691 = vadd.s32 %v53688, %v53683 (stack39)
        %v53693 = vshll.u32 %v53688, 26 (stack44)
        %v53694 = vshrl.u32 %v53688, 6 (stack45)
        %v53695 = vor.u32 %v53694, %v53693 (stack46)
        %v53696 = vxor.u32 %v53695, %v53691 (stack47)
        %v53699 = vadd.s32 %v53696, %v53691 (stack39)
        %v53703 = vadd.s32 %v53699, %v9 (stack39)
        %v53705 = vshll.u32 %v53696, 6 (stack44)
        %v53706 = vshrl.u32 %v53696, 26 (stack45)
        %v53707 = vor.u32 %v53706, %v53705 (stack46)
        %v53708 = vxor.u32 %v53707, %v53699 (stack47)
        %v53711 = vadd.s32 %v53708, %v8 (stack39)
        %v53715 = vadd.s32 1, %v53711 (stack39)
        %v53719 = vadd.s32 %v53715, %v53703 (stack39)
        %v53721 = vshll.u32 %v53715, 17 (stack44)
        %v53722 = vshrl.u32 %v53715, 15 (stack45)
        %v53723 = vor.u32 %v53722, %v53721 (stack46)
        %v53724 = vxor.u32 %v53723, %v53719 (stack47)
        %v53727 = vadd.s32 %v53724, %v53719 (stack39)
        %v53729 = vshll.u32 %v53724, 29 (stack44)
        %v53730 = vshrl.u32 %v53724, 3 (stack45)
        %v53731 = vor.u32 %v53730, %v53729 (stack46)
        %v53732 = vxor.u32 %v53731, %v53727 (stack47)
        %v53735 = vadd.s32 %v53732, %v53727 (stack39)
        %v53737 = vshll.u32 %v53732, 16 (stack44)
        %v53738 = vshrl.u32 %v53732, 16 (stack45)
        %v53739 = vor.u32 %v53738, %v53737 (stack46)
        %v53740 = vxor.u32 %v53739, %v53735 (stack47)
        %v53743 = vadd.s32 %v53740, %v53735 (stack39)
        %v53747 = vadd.s32 %v53743, %v8 (stack39)
        %v53749 = vshll.u32 %v53740, 24 (stack44)
        %v53750 = vshrl.u32 %v53740, 8 (stack45)
        %v53751 = vor.u32 %v53750, %v53749 (stack46)
        %v53752 = vxor.u32 %v53751, %v53743 (stack47)
        %v53755 = vadd.s32 %v53752, %v10 (stack39)
        %v53759 = vadd.s32 2, %v53755 (stack39)
        %v53763 = vadd.s32 %v53759, %v53747 (stack39)
        %v53765 = vshll.u32 %v53759, 13 (stack44)
        %v53766 = vshrl.u32 %v53759, 19 (stack45)
        %v53767 = vor.u32 %v53766, %v53765 (stack46)
        %v53768 = vxor.u32 %v53767, %v53763 (stack47)
        %v53771 = vadd.s32 %v53768, %v53763 (stack39)
        %v53773 = vshll.u32 %v53768, 15 (stack44)
        %v53774 = vshrl.u32 %v53768, 17 (stack45)
        %v53775 = vor.u32 %v53774, %v53773 (stack46)
        %v53776 = vxor.u32 %v53775, %v53771 (stack47)
        %v53779 = vadd.s32 %v53776, %v53771 (stack39)
        %v53781 = vshll.u32 %v53776, 26 (stack44)
        %v53782 = vshrl.u32 %v53776, 6 (stack45)
        %v53783 = vor.u32 %v53782, %v53781 (stack46)
        %v53784 = vxor.u32 %v53783, %v53779 (stack47)
        %v53787 = vadd.s32 %v53784, %v53779 (stack39)
        %v53791 = vadd.s32 %v53787, %v10 (stack39)
        %v53793 = vshll.u32 %v53784, 6 (stack44)
        %v53794 = vshrl.u32 %v53784, 26 (stack45)
        %v53795 = vor.u32 %v53794, %v53793 (stack46)
        %v53796 = vxor.u32 %v53795, %v53787 (stack47)
        %v53799 = vadd.s32 %v53796, %v9 (stack39)
        %v53803 = vadd.s32 3, %v53799 (stack39)
        %v53807 = vadd.s32 %v53803, %v53791 (stack39)
        %v53809 = vshll.u32 %v53803, 17 (stack44)
        %v53810 = vshrl.u32 %v53803, 15 (stack45)
        %v53811 = vor.u32 %v53810, %v53809 (stack46)
        %v53812 = vxor.u32 %v53811, %v53807 (stack47)
        %v53815 = vadd.s32 %v53812, %v53807 (stack39)
        %v53817 = vshll.u32 %v53812, 29 (stack44)
        %v53818 = vshrl.u32 %v53812, 3 (stack45)
        %v53819 = vor.u32 %v53818, %v53817 (stack46)
        %v53820 = vxor.u32 %v53819, %v53815 (stack47)
        %v53823 = vadd.s32 %v53820, %v53815 (stack39)
        %v53825 = vshll.u32 %v53820, 16 (stack44)
        %v53826 = vshrl.u32 %v53820, 16 (stack45)
        %v53827 = vor.u32 %v53826, %v53825 (stack46)
        %v53828 = vxor.u32 %v53827, %v53823 (stack47)
        %v53831 = vadd.s32 %v53828, %v53823 (stack39)
        %v53835 = vadd.s32 %v53831, %v9 (stack39)
        %v53837 = vshll.u32 %v53828, 24 (stack44)
        %v53838 = vshrl.u32 %v53828, 8 (stack45)
        %v53839 = vor.u32 %v53838, %v53837 (stack46)
        %v53840 = vxor.u32 %v53839, %v53831 (stack47)
        %v53843 = vadd.s32 %v53840, %v8 (stack39)
        %v53847 = vadd.s32 4, %v53843 (stack39)
        %v53851 = vadd.s32 %v53847, %v53835 (stack39)
        %v53853 = vshll.u32 %v53847, 13 (stack44)
        %v53854 = vshrl.u32 %v53847, 19 (stack45)
        %v53855 = vor.u32 %v53854, %v53853 (stack46)
        %v53856 = vxor.u32 %v53855, %v53851 (stack47)
        %v53859 = vadd.s32 %v53856, %v53851 (stack39)
        %v53861 = vshll.u32 %v53856, 15 (stack44)
        %v53862 = vshrl.u32 %v53856, 17 (stack45)
        %v53863 = vor.u32 %v53862, %v53861 (stack46)
        %v53864 = vxor.u32 %v53863, %v53859 (stack47)
        %v53867 = vadd.s32 %v53864, %v53859 (stack39)
        %v53869 = vshll.u32 %v53864, 26 (stack44)
        %v53870 = vshrl.u32 %v53864, 6 (stack45)
        %v53871 = vor.u32 %v53870, %v53869 (stack46)
        %v53872 = vxor.u32 %v53871, %v53867 (stack47)
        %v53875 = vadd.s32 %v53872, %v53867 (stack39)
        %v53879 = vadd.s32 %v53875, %v8 (stack39)
        %v53881 = vshll.u32 %v53872, 6 (stack44)
        %v53882 = vshrl.u32 %v53872, 26 (stack45)
        %v53883 = vor.u32 %v53882, %v53881 (stack46)
        %v53884 = vxor.u32 %v53883, %v53875 (stack47)
        %v53887 = vadd.s32 %v53884, %v10 (stack39)
        %v53891 = vadd.s32 5, %v53887 (stack39)
        %v53893 = vxor.u32 %v53891, %v53879 (stack47)
        %v53894 = vand.u32.u8 255, %v53893 (stack48)
        %v53895 = vand.u32 65535, %v53894 (stack49)
        %v53896 = vshrl.u32 %v53895, 1 (stack50)
        %v53897 = vor.u32 16256, %v53896 (stack46)
        %v53898 = vand.u32.u16 65535, %v53897 (stack51)
        %v120032 = vadd.low.f32.bf16 -1.0, %v53898 (stack52)
        %v53907 = vmul.f32 2.0, %v120032 (stack53)
        %v53911 = vadd.f32 -0.99609375, %v53907 (stack52)
        %v53915 = vmax.f32 %v53911, -0.99609375 (stack54)
        %v53917 = vand.u32 2147483647, %v53915 (stack55)
        %vm53920 = vcmp.eq.f32.partialorder %v53917, 1.0 (stack56)
        %v53925 = vmul.f32 inf, %v53915 (stack53)
        %v53927 = vxor.u32 2147483648, %v53915 (stack57)
        %v53930 = vmul.f32 %v53927, %v53915 (stack53)
        %v53932 = vadd.f32 1.0, %v53930 (stack58)
        %v53933 = vlog2.pop %v53932 (stack59)
        %v53934 = vmul.f32 0.6931472, %v53933 (stack60)
        %v53935 = vmul.f32 -0.5, %v53930 (stack61)
        %v53936 = vadd.f32 1.0, %v53935 (stack62)
        %v53937 = vmul.f32 %v53936, %v53930 (stack63)
        %v53938 = vand.u32 2147483647, %v53930 (stack64)
        %vm53939 = vcmp.lt.f32.partialorder %v53938, 0.0004427343 (stack65)
        %v53940 = vsel /*vm=*/%vm53939, /*on_true_vy=*/%v53937, /*on_false_vx=*/%v53934 (stack66)
        %v53941 = vxor.u32 2147483648, %v53940 (stack57)
        %vm53944 = vcmp.lt.f32.partialorder %v53941, 5.0 (stack56)
        %v53949 = vsel /*vm=*/%vm53944, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v53953 = vsel /*vm=*/%vm53944, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v53957 = vsel /*vm=*/%vm53944, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v53961 = vsel /*vm=*/%vm53944, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v53965 = vsel /*vm=*/%vm53944, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v53969 = vsel /*vm=*/%vm53944, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v53973 = vsel /*vm=*/%vm53944, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v53977 = vsel /*vm=*/%vm53944, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v53981 = vsel /*vm=*/%vm53944, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v53985 = vadd.f32 -2.5, %v53941 (stack52)
        %v53987 = vrsqrt.pop %v53941 (stack67)
        %v53988 = vmul.f32 %v53987, %v53941 (stack68)
        %vm53989 = vcmp.eq.f32.partialorder %v53941, inf (stack69)
        %v53990 = vsel /*vm=*/%vm53989, /*on_true_vy=*/%v53941, /*on_false_vx=*/%v53988 (stack70)
        %vm53991 = vcmp.eq.f32.partialorder %v53941, 0.0 (stack71)
        %v53992 = vand.u32 2147483648, %v53941 (stack72)
        %v53993 = vsel /*vm=*/%vm53991, /*on_true_vy=*/%v53992, /*on_false_vx=*/%v53990 (stack73)
        %v53996 = vadd.f32 -3.0, %v53993 (stack52)
        %v54000 = vsel /*vm=*/%vm53944, /*on_true_vy=*/%v53985, /*on_false_vx=*/%v53996 (stack43)
        %v54004 = vmul.f32 %v54000, %v53981 (stack53)
        %v54008 = vadd.f32 %v54004, %v53977 (stack52)
        %v54012 = vmul.f32 %v54008, %v54000 (stack53)
        %v54016 = vadd.f32 %v54012, %v53973 (stack52)
        %v54020 = vmul.f32 %v54016, %v54000 (stack53)
        %v54024 = vadd.f32 %v54020, %v53969 (stack52)
        %v54028 = vmul.f32 %v54024, %v54000 (stack53)
        %v54032 = vadd.f32 %v54028, %v53965 (stack52)
        %v54036 = vmul.f32 %v54032, %v54000 (stack53)
        %v54040 = vadd.f32 %v54036, %v53961 (stack52)
        %v54044 = vmul.f32 %v54040, %v54000 (stack53)
        %v54048 = vadd.f32 %v54044, %v53957 (stack52)
        %v54052 = vmul.f32 %v54048, %v54000 (stack53)
        %v54056 = vadd.f32 %v54052, %v53953 (stack52)
        %v54060 = vmul.f32 %v54056, %v54000 (stack53)
        %v54064 = vadd.f32 %v54060, %v53949 (stack52)
        %v54068 = vmul.f32 %v54064, %v53915 (stack53)
        %v54072 = vsel /*vm=*/%vm53920, /*on_true_vy=*/%v53925, /*on_false_vx=*/%v54068 (stack43)
        %v54076 = vmul.f32 1.4140625, %v54072 (stack53)
        %v54079 = vpack.c.bf16 0.0, %v54076 (stack74)
        %120033 = vst [vmem:[%s280 + $0x138] sm:$0xf] /*vst_source=*/%v54079 (stack75)
        %v54083 = vadd.s32 %v52697, %v1868 (stack39)
        %v54093 = vadd.s32 %v54083, %v415 (stack39)
        %vm54097 = vcmp.lt.u32.totalorder %v54093, %v54083 (stack42)
        %vm54102 = vcmp.lt.u32.totalorder %v54083, %v1868 (stack42)
        %v54107 = vadd.s32 %v52680, %v1855 (stack39)
        %v54111 = vadd.s32 1, %v54107 (stack39)
        %v54115 = vsel /*vm=*/%vm54102, /*on_true_vy=*/%v54111, /*on_false_vx=*/%v54107 (stack43)
        %v54119 = vadd.s32 1, %v54115 (stack39)
        %v54123 = vsel /*vm=*/%vm54097, /*on_true_vy=*/%v54119, /*on_false_vx=*/%v54115 (stack43)
        %v54128 = vadd.s32 %v54123, %v10 (stack39)
        %v54132 = vadd.s32 %v54093, %v9 (stack39)
        %v54136 = vadd.s32 %v54132, %v54128 (stack39)
        %v54138 = vshll.u32 %v54132, 13 (stack44)
        %v54139 = vshrl.u32 %v54132, 19 (stack45)
        %v54140 = vor.u32 %v54139, %v54138 (stack46)
        %v54141 = vxor.u32 %v54140, %v54136 (stack47)
        %v54144 = vadd.s32 %v54141, %v54136 (stack39)
        %v54146 = vshll.u32 %v54141, 15 (stack44)
        %v54147 = vshrl.u32 %v54141, 17 (stack45)
        %v54148 = vor.u32 %v54147, %v54146 (stack46)
        %v54149 = vxor.u32 %v54148, %v54144 (stack47)
        %v54152 = vadd.s32 %v54149, %v54144 (stack39)
        %v54154 = vshll.u32 %v54149, 26 (stack44)
        %v54155 = vshrl.u32 %v54149, 6 (stack45)
        %v54156 = vor.u32 %v54155, %v54154 (stack46)
        %v54157 = vxor.u32 %v54156, %v54152 (stack47)
        %v54160 = vadd.s32 %v54157, %v54152 (stack39)
        %v54164 = vadd.s32 %v54160, %v9 (stack39)
        %v54166 = vshll.u32 %v54157, 6 (stack44)
        %v54167 = vshrl.u32 %v54157, 26 (stack45)
        %v54168 = vor.u32 %v54167, %v54166 (stack46)
        %v54169 = vxor.u32 %v54168, %v54160 (stack47)
        %v54172 = vadd.s32 %v54169, %v8 (stack39)
        %v54176 = vadd.s32 1, %v54172 (stack39)
        %v54180 = vadd.s32 %v54176, %v54164 (stack39)
        %v54182 = vshll.u32 %v54176, 17 (stack44)
        %v54183 = vshrl.u32 %v54176, 15 (stack45)
        %v54184 = vor.u32 %v54183, %v54182 (stack46)
        %v54185 = vxor.u32 %v54184, %v54180 (stack47)
        %v54188 = vadd.s32 %v54185, %v54180 (stack39)
        %v54190 = vshll.u32 %v54185, 29 (stack44)
        %v54191 = vshrl.u32 %v54185, 3 (stack45)
        %v54192 = vor.u32 %v54191, %v54190 (stack46)
        %v54193 = vxor.u32 %v54192, %v54188 (stack47)
        %v54196 = vadd.s32 %v54193, %v54188 (stack39)
        %v54198 = vshll.u32 %v54193, 16 (stack44)
        %v54199 = vshrl.u32 %v54193, 16 (stack45)
        %v54200 = vor.u32 %v54199, %v54198 (stack46)
        %v54201 = vxor.u32 %v54200, %v54196 (stack47)
        %v54204 = vadd.s32 %v54201, %v54196 (stack39)
        %v54208 = vadd.s32 %v54204, %v8 (stack39)
        %v54210 = vshll.u32 %v54201, 24 (stack44)
        %v54211 = vshrl.u32 %v54201, 8 (stack45)
        %v54212 = vor.u32 %v54211, %v54210 (stack46)
        %v54213 = vxor.u32 %v54212, %v54204 (stack47)
        %v54216 = vadd.s32 %v54213, %v10 (stack39)
        %v54220 = vadd.s32 2, %v54216 (stack39)
        %v54224 = vadd.s32 %v54220, %v54208 (stack39)
        %v54226 = vshll.u32 %v54220, 13 (stack44)
        %v54227 = vshrl.u32 %v54220, 19 (stack45)
        %v54228 = vor.u32 %v54227, %v54226 (stack46)
        %v54229 = vxor.u32 %v54228, %v54224 (stack47)
        %v54232 = vadd.s32 %v54229, %v54224 (stack39)
        %v54234 = vshll.u32 %v54229, 15 (stack44)
        %v54235 = vshrl.u32 %v54229, 17 (stack45)
        %v54236 = vor.u32 %v54235, %v54234 (stack46)
        %v54237 = vxor.u32 %v54236, %v54232 (stack47)
        %v54240 = vadd.s32 %v54237, %v54232 (stack39)
        %v54242 = vshll.u32 %v54237, 26 (stack44)
        %v54243 = vshrl.u32 %v54237, 6 (stack45)
        %v54244 = vor.u32 %v54243, %v54242 (stack46)
        %v54245 = vxor.u32 %v54244, %v54240 (stack47)
        %v54248 = vadd.s32 %v54245, %v54240 (stack39)
        %v54252 = vadd.s32 %v54248, %v10 (stack39)
        %v54254 = vshll.u32 %v54245, 6 (stack44)
        %v54255 = vshrl.u32 %v54245, 26 (stack45)
        %v54256 = vor.u32 %v54255, %v54254 (stack46)
        %v54257 = vxor.u32 %v54256, %v54248 (stack47)
        %v54260 = vadd.s32 %v54257, %v9 (stack39)
        %v54264 = vadd.s32 3, %v54260 (stack39)
        %v54268 = vadd.s32 %v54264, %v54252 (stack39)
        %v54270 = vshll.u32 %v54264, 17 (stack44)
        %v54271 = vshrl.u32 %v54264, 15 (stack45)
        %v54272 = vor.u32 %v54271, %v54270 (stack46)
        %v54273 = vxor.u32 %v54272, %v54268 (stack47)
        %v54276 = vadd.s32 %v54273, %v54268 (stack39)
        %v54278 = vshll.u32 %v54273, 29 (stack44)
        %v54279 = vshrl.u32 %v54273, 3 (stack45)
        %v54280 = vor.u32 %v54279, %v54278 (stack46)
        %v54281 = vxor.u32 %v54280, %v54276 (stack47)
        %v54284 = vadd.s32 %v54281, %v54276 (stack39)
        %v54286 = vshll.u32 %v54281, 16 (stack44)
        %v54287 = vshrl.u32 %v54281, 16 (stack45)
        %v54288 = vor.u32 %v54287, %v54286 (stack46)
        %v54289 = vxor.u32 %v54288, %v54284 (stack47)
        %v54292 = vadd.s32 %v54289, %v54284 (stack39)
        %v54296 = vadd.s32 %v54292, %v9 (stack39)
        %v54298 = vshll.u32 %v54289, 24 (stack44)
        %v54299 = vshrl.u32 %v54289, 8 (stack45)
        %v54300 = vor.u32 %v54299, %v54298 (stack46)
        %v54301 = vxor.u32 %v54300, %v54292 (stack47)
        %v54304 = vadd.s32 %v54301, %v8 (stack39)
        %v54308 = vadd.s32 4, %v54304 (stack39)
        %v54312 = vadd.s32 %v54308, %v54296 (stack39)
        %v54314 = vshll.u32 %v54308, 13 (stack44)
        %v54315 = vshrl.u32 %v54308, 19 (stack45)
        %v54316 = vor.u32 %v54315, %v54314 (stack46)
        %v54317 = vxor.u32 %v54316, %v54312 (stack47)
        %v54320 = vadd.s32 %v54317, %v54312 (stack39)
        %v54322 = vshll.u32 %v54317, 15 (stack44)
        %v54323 = vshrl.u32 %v54317, 17 (stack45)
        %v54324 = vor.u32 %v54323, %v54322 (stack46)
        %v54325 = vxor.u32 %v54324, %v54320 (stack47)
        %v54328 = vadd.s32 %v54325, %v54320 (stack39)
        %v54330 = vshll.u32 %v54325, 26 (stack44)
        %v54331 = vshrl.u32 %v54325, 6 (stack45)
        %v54332 = vor.u32 %v54331, %v54330 (stack46)
        %v54333 = vxor.u32 %v54332, %v54328 (stack47)
        %v54336 = vadd.s32 %v54333, %v54328 (stack39)
        %v54340 = vadd.s32 %v54336, %v8 (stack39)
        %v54342 = vshll.u32 %v54333, 6 (stack44)
        %v54343 = vshrl.u32 %v54333, 26 (stack45)
        %v54344 = vor.u32 %v54343, %v54342 (stack46)
        %v54345 = vxor.u32 %v54344, %v54336 (stack47)
        %v54348 = vadd.s32 %v54345, %v10 (stack39)
        %v54352 = vadd.s32 5, %v54348 (stack39)
        %v54354 = vxor.u32 %v54352, %v54340 (stack47)
        %v54355 = vand.u32.u8 255, %v54354 (stack48)
        %v54356 = vand.u32 65535, %v54355 (stack49)
        %v54357 = vshrl.u32 %v54356, 1 (stack50)
        %v54358 = vor.u32 16256, %v54357 (stack46)
        %v54359 = vand.u32.u16 65535, %v54358 (stack51)
        %v120034 = vadd.low.f32.bf16 -1.0, %v54359 (stack52)
        %v54368 = vmul.f32 2.0, %v120034 (stack53)
        %v54372 = vadd.f32 -0.99609375, %v54368 (stack52)
        %v54376 = vmax.f32 %v54372, -0.99609375 (stack54)
        %v54378 = vand.u32 2147483647, %v54376 (stack55)
        %vm54381 = vcmp.eq.f32.partialorder %v54378, 1.0 (stack56)
        %v54386 = vmul.f32 inf, %v54376 (stack53)
        %v54388 = vxor.u32 2147483648, %v54376 (stack57)
        %v54391 = vmul.f32 %v54388, %v54376 (stack53)
        %v54393 = vadd.f32 1.0, %v54391 (stack58)
        %v54394 = vlog2.pop %v54393 (stack59)
        %v54395 = vmul.f32 0.6931472, %v54394 (stack60)
        %v54396 = vmul.f32 -0.5, %v54391 (stack61)
        %v54397 = vadd.f32 1.0, %v54396 (stack62)
        %v54398 = vmul.f32 %v54397, %v54391 (stack63)
        %v54399 = vand.u32 2147483647, %v54391 (stack64)
        %vm54400 = vcmp.lt.f32.partialorder %v54399, 0.0004427343 (stack65)
        %v54401 = vsel /*vm=*/%vm54400, /*on_true_vy=*/%v54398, /*on_false_vx=*/%v54395 (stack66)
        %v54402 = vxor.u32 2147483648, %v54401 (stack57)
        %vm54405 = vcmp.lt.f32.partialorder %v54402, 5.0 (stack56)
        %v54410 = vsel /*vm=*/%vm54405, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v54414 = vsel /*vm=*/%vm54405, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v54418 = vsel /*vm=*/%vm54405, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v54422 = vsel /*vm=*/%vm54405, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v54426 = vsel /*vm=*/%vm54405, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v54430 = vsel /*vm=*/%vm54405, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v54434 = vsel /*vm=*/%vm54405, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v54438 = vsel /*vm=*/%vm54405, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v54442 = vsel /*vm=*/%vm54405, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v54446 = vadd.f32 -2.5, %v54402 (stack52)
        %v54448 = vrsqrt.pop %v54402 (stack67)
        %v54449 = vmul.f32 %v54448, %v54402 (stack68)
        %vm54450 = vcmp.eq.f32.partialorder %v54402, inf (stack69)
        %v54451 = vsel /*vm=*/%vm54450, /*on_true_vy=*/%v54402, /*on_false_vx=*/%v54449 (stack70)
        %vm54452 = vcmp.eq.f32.partialorder %v54402, 0.0 (stack71)
        %v54453 = vand.u32 2147483648, %v54402 (stack72)
        %v54454 = vsel /*vm=*/%vm54452, /*on_true_vy=*/%v54453, /*on_false_vx=*/%v54451 (stack73)
        %v54457 = vadd.f32 -3.0, %v54454 (stack52)
        %v54461 = vsel /*vm=*/%vm54405, /*on_true_vy=*/%v54446, /*on_false_vx=*/%v54457 (stack43)
        %v54465 = vmul.f32 %v54461, %v54442 (stack53)
        %v54469 = vadd.f32 %v54465, %v54438 (stack52)
        %v54473 = vmul.f32 %v54469, %v54461 (stack53)
        %v54477 = vadd.f32 %v54473, %v54434 (stack52)
        %v54481 = vmul.f32 %v54477, %v54461 (stack53)
        %v54485 = vadd.f32 %v54481, %v54430 (stack52)
        %v54489 = vmul.f32 %v54485, %v54461 (stack53)
        %v54493 = vadd.f32 %v54489, %v54426 (stack52)
        %v54497 = vmul.f32 %v54493, %v54461 (stack53)
        %v54501 = vadd.f32 %v54497, %v54422 (stack52)
        %v54505 = vmul.f32 %v54501, %v54461 (stack53)
        %v54509 = vadd.f32 %v54505, %v54418 (stack52)
        %v54513 = vmul.f32 %v54509, %v54461 (stack53)
        %v54517 = vadd.f32 %v54513, %v54414 (stack52)
        %v54521 = vmul.f32 %v54517, %v54461 (stack53)
        %v54525 = vadd.f32 %v54521, %v54410 (stack52)
        %v54529 = vmul.f32 %v54525, %v54376 (stack53)
        %v54533 = vsel /*vm=*/%vm54381, /*on_true_vy=*/%v54386, /*on_false_vx=*/%v54529 (stack43)
        %v54537 = vmul.f32 1.4140625, %v54533 (stack53)
        %v54540 = vpack.c.bf16 0.0, %v54537 (stack74)
        %120035 = vst [vmem:[%s280 + $0x1b8] sm:$0xf] /*vst_source=*/%v54540 (stack75)
        %v54544 = vadd.s32 %v52697, %v2355 (stack39)
        %v54554 = vadd.s32 %v54544, %v415 (stack39)
        %vm54558 = vcmp.lt.u32.totalorder %v54554, %v54544 (stack42)
        %vm54563 = vcmp.lt.u32.totalorder %v54544, %v2355 (stack42)
        %v54568 = vadd.s32 %v52680, %v2342 (stack39)
        %v54572 = vadd.s32 1, %v54568 (stack39)
        %v54576 = vsel /*vm=*/%vm54563, /*on_true_vy=*/%v54572, /*on_false_vx=*/%v54568 (stack43)
        %v54580 = vadd.s32 1, %v54576 (stack39)
        %v54584 = vsel /*vm=*/%vm54558, /*on_true_vy=*/%v54580, /*on_false_vx=*/%v54576 (stack43)
        %v54589 = vadd.s32 %v54584, %v10 (stack39)
        %v54593 = vadd.s32 %v54554, %v9 (stack39)
        %v54597 = vadd.s32 %v54593, %v54589 (stack39)
        %v54599 = vshll.u32 %v54593, 13 (stack44)
        %v54600 = vshrl.u32 %v54593, 19 (stack45)
        %v54601 = vor.u32 %v54600, %v54599 (stack46)
        %v54602 = vxor.u32 %v54601, %v54597 (stack47)
        %v54605 = vadd.s32 %v54602, %v54597 (stack39)
        %v54607 = vshll.u32 %v54602, 15 (stack44)
        %v54608 = vshrl.u32 %v54602, 17 (stack45)
        %v54609 = vor.u32 %v54608, %v54607 (stack46)
        %v54610 = vxor.u32 %v54609, %v54605 (stack47)
        %v54613 = vadd.s32 %v54610, %v54605 (stack39)
        %v54615 = vshll.u32 %v54610, 26 (stack44)
        %v54616 = vshrl.u32 %v54610, 6 (stack45)
        %v54617 = vor.u32 %v54616, %v54615 (stack46)
        %v54618 = vxor.u32 %v54617, %v54613 (stack47)
        %v54621 = vadd.s32 %v54618, %v54613 (stack39)
        %v54625 = vadd.s32 %v54621, %v9 (stack39)
        %v54627 = vshll.u32 %v54618, 6 (stack44)
        %v54628 = vshrl.u32 %v54618, 26 (stack45)
        %v54629 = vor.u32 %v54628, %v54627 (stack46)
        %v54630 = vxor.u32 %v54629, %v54621 (stack47)
        %v54633 = vadd.s32 %v54630, %v8 (stack39)
        %v54637 = vadd.s32 1, %v54633 (stack39)
        %v54641 = vadd.s32 %v54637, %v54625 (stack39)
        %v54643 = vshll.u32 %v54637, 17 (stack44)
        %v54644 = vshrl.u32 %v54637, 15 (stack45)
        %v54645 = vor.u32 %v54644, %v54643 (stack46)
        %v54646 = vxor.u32 %v54645, %v54641 (stack47)
        %v54649 = vadd.s32 %v54646, %v54641 (stack39)
        %v54651 = vshll.u32 %v54646, 29 (stack44)
        %v54652 = vshrl.u32 %v54646, 3 (stack45)
        %v54653 = vor.u32 %v54652, %v54651 (stack46)
        %v54654 = vxor.u32 %v54653, %v54649 (stack47)
        %v54657 = vadd.s32 %v54654, %v54649 (stack39)
        %v54659 = vshll.u32 %v54654, 16 (stack44)
        %v54660 = vshrl.u32 %v54654, 16 (stack45)
        %v54661 = vor.u32 %v54660, %v54659 (stack46)
        %v54662 = vxor.u32 %v54661, %v54657 (stack47)
        %v54665 = vadd.s32 %v54662, %v54657 (stack39)
        %v54669 = vadd.s32 %v54665, %v8 (stack39)
        %v54671 = vshll.u32 %v54662, 24 (stack44)
        %v54672 = vshrl.u32 %v54662, 8 (stack45)
        %v54673 = vor.u32 %v54672, %v54671 (stack46)
        %v54674 = vxor.u32 %v54673, %v54665 (stack47)
        %v54677 = vadd.s32 %v54674, %v10 (stack39)
        %v54681 = vadd.s32 2, %v54677 (stack39)
        %v54685 = vadd.s32 %v54681, %v54669 (stack39)
        %v54687 = vshll.u32 %v54681, 13 (stack44)
        %v54688 = vshrl.u32 %v54681, 19 (stack45)
        %v54689 = vor.u32 %v54688, %v54687 (stack46)
        %v54690 = vxor.u32 %v54689, %v54685 (stack47)
        %v54693 = vadd.s32 %v54690, %v54685 (stack39)
        %v54695 = vshll.u32 %v54690, 15 (stack44)
        %v54696 = vshrl.u32 %v54690, 17 (stack45)
        %v54697 = vor.u32 %v54696, %v54695 (stack46)
        %v54698 = vxor.u32 %v54697, %v54693 (stack47)
        %v54701 = vadd.s32 %v54698, %v54693 (stack39)
        %v54703 = vshll.u32 %v54698, 26 (stack44)
        %v54704 = vshrl.u32 %v54698, 6 (stack45)
        %v54705 = vor.u32 %v54704, %v54703 (stack46)
        %v54706 = vxor.u32 %v54705, %v54701 (stack47)
        %v54709 = vadd.s32 %v54706, %v54701 (stack39)
        %v54713 = vadd.s32 %v54709, %v10 (stack39)
        %v54715 = vshll.u32 %v54706, 6 (stack44)
        %v54716 = vshrl.u32 %v54706, 26 (stack45)
        %v54717 = vor.u32 %v54716, %v54715 (stack46)
        %v54718 = vxor.u32 %v54717, %v54709 (stack47)
        %v54721 = vadd.s32 %v54718, %v9 (stack39)
        %v54725 = vadd.s32 3, %v54721 (stack39)
        %v54729 = vadd.s32 %v54725, %v54713 (stack39)
        %v54731 = vshll.u32 %v54725, 17 (stack44)
        %v54732 = vshrl.u32 %v54725, 15 (stack45)
        %v54733 = vor.u32 %v54732, %v54731 (stack46)
        %v54734 = vxor.u32 %v54733, %v54729 (stack47)
        %v54737 = vadd.s32 %v54734, %v54729 (stack39)
        %v54739 = vshll.u32 %v54734, 29 (stack44)
        %v54740 = vshrl.u32 %v54734, 3 (stack45)
        %v54741 = vor.u32 %v54740, %v54739 (stack46)
        %v54742 = vxor.u32 %v54741, %v54737 (stack47)
        %v54745 = vadd.s32 %v54742, %v54737 (stack39)
        %v54747 = vshll.u32 %v54742, 16 (stack44)
        %v54748 = vshrl.u32 %v54742, 16 (stack45)
        %v54749 = vor.u32 %v54748, %v54747 (stack46)
        %v54750 = vxor.u32 %v54749, %v54745 (stack47)
        %v54753 = vadd.s32 %v54750, %v54745 (stack39)
        %v54757 = vadd.s32 %v54753, %v9 (stack39)
        %v54759 = vshll.u32 %v54750, 24 (stack44)
        %v54760 = vshrl.u32 %v54750, 8 (stack45)
        %v54761 = vor.u32 %v54760, %v54759 (stack46)
        %v54762 = vxor.u32 %v54761, %v54753 (stack47)
        %v54765 = vadd.s32 %v54762, %v8 (stack39)
        %v54769 = vadd.s32 4, %v54765 (stack39)
        %v54773 = vadd.s32 %v54769, %v54757 (stack39)
        %v54775 = vshll.u32 %v54769, 13 (stack44)
        %v54776 = vshrl.u32 %v54769, 19 (stack45)
        %v54777 = vor.u32 %v54776, %v54775 (stack46)
        %v54778 = vxor.u32 %v54777, %v54773 (stack47)
        %v54781 = vadd.s32 %v54778, %v54773 (stack39)
        %v54783 = vshll.u32 %v54778, 15 (stack44)
        %v54784 = vshrl.u32 %v54778, 17 (stack45)
        %v54785 = vor.u32 %v54784, %v54783 (stack46)
        %v54786 = vxor.u32 %v54785, %v54781 (stack47)
        %v54789 = vadd.s32 %v54786, %v54781 (stack39)
        %v54791 = vshll.u32 %v54786, 26 (stack44)
        %v54792 = vshrl.u32 %v54786, 6 (stack45)
        %v54793 = vor.u32 %v54792, %v54791 (stack46)
        %v54794 = vxor.u32 %v54793, %v54789 (stack47)
        %v54797 = vadd.s32 %v54794, %v54789 (stack39)
        %v54801 = vadd.s32 %v54797, %v8 (stack39)
        %v54803 = vshll.u32 %v54794, 6 (stack44)
        %v54804 = vshrl.u32 %v54794, 26 (stack45)
        %v54805 = vor.u32 %v54804, %v54803 (stack46)
        %v54806 = vxor.u32 %v54805, %v54797 (stack47)
        %v54809 = vadd.s32 %v54806, %v10 (stack39)
        %v54813 = vadd.s32 5, %v54809 (stack39)
        %v54815 = vxor.u32 %v54813, %v54801 (stack47)
        %v54816 = vand.u32.u8 255, %v54815 (stack48)
        %v54817 = vand.u32 65535, %v54816 (stack49)
        %v54818 = vshrl.u32 %v54817, 1 (stack50)
        %v54819 = vor.u32 16256, %v54818 (stack46)
        %v54820 = vand.u32.u16 65535, %v54819 (stack51)
        %v120036 = vadd.low.f32.bf16 -1.0, %v54820 (stack52)
        %v54829 = vmul.f32 2.0, %v120036 (stack53)
        %v54833 = vadd.f32 -0.99609375, %v54829 (stack52)
        %v54837 = vmax.f32 %v54833, -0.99609375 (stack54)
        %v54839 = vand.u32 2147483647, %v54837 (stack55)
        %vm54842 = vcmp.eq.f32.partialorder %v54839, 1.0 (stack56)
        %v54847 = vmul.f32 inf, %v54837 (stack53)
        %v54849 = vxor.u32 2147483648, %v54837 (stack57)
        %v54852 = vmul.f32 %v54849, %v54837 (stack53)
        %v54854 = vadd.f32 1.0, %v54852 (stack58)
        %v54855 = vlog2.pop %v54854 (stack59)
        %v54856 = vmul.f32 0.6931472, %v54855 (stack60)
        %v54857 = vmul.f32 -0.5, %v54852 (stack61)
        %v54858 = vadd.f32 1.0, %v54857 (stack62)
        %v54859 = vmul.f32 %v54858, %v54852 (stack63)
        %v54860 = vand.u32 2147483647, %v54852 (stack64)
        %vm54861 = vcmp.lt.f32.partialorder %v54860, 0.0004427343 (stack65)
        %v54862 = vsel /*vm=*/%vm54861, /*on_true_vy=*/%v54859, /*on_false_vx=*/%v54856 (stack66)
        %v54863 = vxor.u32 2147483648, %v54862 (stack57)
        %vm54866 = vcmp.lt.f32.partialorder %v54863, 5.0 (stack56)
        %v54871 = vsel /*vm=*/%vm54866, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v54875 = vsel /*vm=*/%vm54866, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v54879 = vsel /*vm=*/%vm54866, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v54883 = vsel /*vm=*/%vm54866, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v54887 = vsel /*vm=*/%vm54866, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v54891 = vsel /*vm=*/%vm54866, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v54895 = vsel /*vm=*/%vm54866, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v54899 = vsel /*vm=*/%vm54866, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v54903 = vsel /*vm=*/%vm54866, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v54907 = vadd.f32 -2.5, %v54863 (stack52)
        %v54909 = vrsqrt.pop %v54863 (stack67)
        %v54910 = vmul.f32 %v54909, %v54863 (stack68)
        %vm54911 = vcmp.eq.f32.partialorder %v54863, inf (stack69)
        %v54912 = vsel /*vm=*/%vm54911, /*on_true_vy=*/%v54863, /*on_false_vx=*/%v54910 (stack70)
        %vm54913 = vcmp.eq.f32.partialorder %v54863, 0.0 (stack71)
        %v54914 = vand.u32 2147483648, %v54863 (stack72)
        %v54915 = vsel /*vm=*/%vm54913, /*on_true_vy=*/%v54914, /*on_false_vx=*/%v54912 (stack73)
        %v54918 = vadd.f32 -3.0, %v54915 (stack52)
        %v54922 = vsel /*vm=*/%vm54866, /*on_true_vy=*/%v54907, /*on_false_vx=*/%v54918 (stack43)
        %v54926 = vmul.f32 %v54922, %v54903 (stack53)
        %v54930 = vadd.f32 %v54926, %v54899 (stack52)
        %v54934 = vmul.f32 %v54930, %v54922 (stack53)
        %v54938 = vadd.f32 %v54934, %v54895 (stack52)
        %v54942 = vmul.f32 %v54938, %v54922 (stack53)
        %v54946 = vadd.f32 %v54942, %v54891 (stack52)
        %v54950 = vmul.f32 %v54946, %v54922 (stack53)
        %v54954 = vadd.f32 %v54950, %v54887 (stack52)
        %v54958 = vmul.f32 %v54954, %v54922 (stack53)
        %v54962 = vadd.f32 %v54958, %v54883 (stack52)
        %v54966 = vmul.f32 %v54962, %v54922 (stack53)
        %v54970 = vadd.f32 %v54966, %v54879 (stack52)
        %v54974 = vmul.f32 %v54970, %v54922 (stack53)
        %v54978 = vadd.f32 %v54974, %v54875 (stack52)
        %v54982 = vmul.f32 %v54978, %v54922 (stack53)
        %v54986 = vadd.f32 %v54982, %v54871 (stack52)
        %v54990 = vmul.f32 %v54986, %v54837 (stack53)
        %v54994 = vsel /*vm=*/%vm54842, /*on_true_vy=*/%v54847, /*on_false_vx=*/%v54990 (stack43)
        %v54998 = vmul.f32 1.4140625, %v54994 (stack53)
        %v55001 = vpack.c.bf16 0.0, %v54998 (stack74)
        %120037 = vst [vmem:[%s280 + $0x238] sm:$0xf] /*vst_source=*/%v55001 (stack75)
        %v55005 = vadd.s32 %v52697, %v2842 (stack39)
        %v55015 = vadd.s32 %v55005, %v415 (stack39)
        %vm55019 = vcmp.lt.u32.totalorder %v55015, %v55005 (stack42)
        %vm55024 = vcmp.lt.u32.totalorder %v55005, %v2842 (stack42)
        %v55029 = vadd.s32 %v52680, %v2829 (stack39)
        %v55033 = vadd.s32 1, %v55029 (stack39)
        %v55037 = vsel /*vm=*/%vm55024, /*on_true_vy=*/%v55033, /*on_false_vx=*/%v55029 (stack43)
        %v55041 = vadd.s32 1, %v55037 (stack39)
        %v55045 = vsel /*vm=*/%vm55019, /*on_true_vy=*/%v55041, /*on_false_vx=*/%v55037 (stack43)
        %v55050 = vadd.s32 %v55045, %v10 (stack39)
        %v55054 = vadd.s32 %v55015, %v9 (stack39)
        %v55058 = vadd.s32 %v55054, %v55050 (stack39)
        %v55060 = vshll.u32 %v55054, 13 (stack44)
        %v55061 = vshrl.u32 %v55054, 19 (stack45)
        %v55062 = vor.u32 %v55061, %v55060 (stack46)
        %v55063 = vxor.u32 %v55062, %v55058 (stack47)
        %v55066 = vadd.s32 %v55063, %v55058 (stack39)
        %v55068 = vshll.u32 %v55063, 15 (stack44)
        %v55069 = vshrl.u32 %v55063, 17 (stack45)
        %v55070 = vor.u32 %v55069, %v55068 (stack46)
        %v55071 = vxor.u32 %v55070, %v55066 (stack47)
        %v55074 = vadd.s32 %v55071, %v55066 (stack39)
        %v55076 = vshll.u32 %v55071, 26 (stack44)
        %v55077 = vshrl.u32 %v55071, 6 (stack45)
        %v55078 = vor.u32 %v55077, %v55076 (stack46)
        %v55079 = vxor.u32 %v55078, %v55074 (stack47)
        %v55082 = vadd.s32 %v55079, %v55074 (stack39)
        %v55086 = vadd.s32 %v55082, %v9 (stack39)
        %v55088 = vshll.u32 %v55079, 6 (stack44)
        %v55089 = vshrl.u32 %v55079, 26 (stack45)
        %v55090 = vor.u32 %v55089, %v55088 (stack46)
        %v55091 = vxor.u32 %v55090, %v55082 (stack47)
        %v55094 = vadd.s32 %v55091, %v8 (stack39)
        %v55098 = vadd.s32 1, %v55094 (stack39)
        %v55102 = vadd.s32 %v55098, %v55086 (stack39)
        %v55104 = vshll.u32 %v55098, 17 (stack44)
        %v55105 = vshrl.u32 %v55098, 15 (stack45)
        %v55106 = vor.u32 %v55105, %v55104 (stack46)
        %v55107 = vxor.u32 %v55106, %v55102 (stack47)
        %v55110 = vadd.s32 %v55107, %v55102 (stack39)
        %v55112 = vshll.u32 %v55107, 29 (stack44)
        %v55113 = vshrl.u32 %v55107, 3 (stack45)
        %v55114 = vor.u32 %v55113, %v55112 (stack46)
        %v55115 = vxor.u32 %v55114, %v55110 (stack47)
        %v55118 = vadd.s32 %v55115, %v55110 (stack39)
        %v55120 = vshll.u32 %v55115, 16 (stack44)
        %v55121 = vshrl.u32 %v55115, 16 (stack45)
        %v55122 = vor.u32 %v55121, %v55120 (stack46)
        %v55123 = vxor.u32 %v55122, %v55118 (stack47)
        %v55126 = vadd.s32 %v55123, %v55118 (stack39)
        %v55130 = vadd.s32 %v55126, %v8 (stack39)
        %v55132 = vshll.u32 %v55123, 24 (stack44)
        %v55133 = vshrl.u32 %v55123, 8 (stack45)
        %v55134 = vor.u32 %v55133, %v55132 (stack46)
        %v55135 = vxor.u32 %v55134, %v55126 (stack47)
        %v55138 = vadd.s32 %v55135, %v10 (stack39)
        %v55142 = vadd.s32 2, %v55138 (stack39)
        %v55146 = vadd.s32 %v55142, %v55130 (stack39)
        %v55148 = vshll.u32 %v55142, 13 (stack44)
        %v55149 = vshrl.u32 %v55142, 19 (stack45)
        %v55150 = vor.u32 %v55149, %v55148 (stack46)
        %v55151 = vxor.u32 %v55150, %v55146 (stack47)
        %v55154 = vadd.s32 %v55151, %v55146 (stack39)
        %v55156 = vshll.u32 %v55151, 15 (stack44)
        %v55157 = vshrl.u32 %v55151, 17 (stack45)
        %v55158 = vor.u32 %v55157, %v55156 (stack46)
        %v55159 = vxor.u32 %v55158, %v55154 (stack47)
        %v55162 = vadd.s32 %v55159, %v55154 (stack39)
        %v55164 = vshll.u32 %v55159, 26 (stack44)
        %v55165 = vshrl.u32 %v55159, 6 (stack45)
        %v55166 = vor.u32 %v55165, %v55164 (stack46)
        %v55167 = vxor.u32 %v55166, %v55162 (stack47)
        %v55170 = vadd.s32 %v55167, %v55162 (stack39)
        %v55174 = vadd.s32 %v55170, %v10 (stack39)
        %v55176 = vshll.u32 %v55167, 6 (stack44)
        %v55177 = vshrl.u32 %v55167, 26 (stack45)
        %v55178 = vor.u32 %v55177, %v55176 (stack46)
        %v55179 = vxor.u32 %v55178, %v55170 (stack47)
        %v55182 = vadd.s32 %v55179, %v9 (stack39)
        %v55186 = vadd.s32 3, %v55182 (stack39)
        %v55190 = vadd.s32 %v55186, %v55174 (stack39)
        %v55192 = vshll.u32 %v55186, 17 (stack44)
        %v55193 = vshrl.u32 %v55186, 15 (stack45)
        %v55194 = vor.u32 %v55193, %v55192 (stack46)
        %v55195 = vxor.u32 %v55194, %v55190 (stack47)
        %v55198 = vadd.s32 %v55195, %v55190 (stack39)
        %v55200 = vshll.u32 %v55195, 29 (stack44)
        %v55201 = vshrl.u32 %v55195, 3 (stack45)
        %v55202 = vor.u32 %v55201, %v55200 (stack46)
        %v55203 = vxor.u32 %v55202, %v55198 (stack47)
        %v55206 = vadd.s32 %v55203, %v55198 (stack39)
        %v55208 = vshll.u32 %v55203, 16 (stack44)
        %v55209 = vshrl.u32 %v55203, 16 (stack45)
        %v55210 = vor.u32 %v55209, %v55208 (stack46)
        %v55211 = vxor.u32 %v55210, %v55206 (stack47)
        %v55214 = vadd.s32 %v55211, %v55206 (stack39)
        %v55218 = vadd.s32 %v55214, %v9 (stack39)
        %v55220 = vshll.u32 %v55211, 24 (stack44)
        %v55221 = vshrl.u32 %v55211, 8 (stack45)
        %v55222 = vor.u32 %v55221, %v55220 (stack46)
        %v55223 = vxor.u32 %v55222, %v55214 (stack47)
        %v55226 = vadd.s32 %v55223, %v8 (stack39)
        %v55230 = vadd.s32 4, %v55226 (stack39)
        %v55234 = vadd.s32 %v55230, %v55218 (stack39)
        %v55236 = vshll.u32 %v55230, 13 (stack44)
        %v55237 = vshrl.u32 %v55230, 19 (stack45)
        %v55238 = vor.u32 %v55237, %v55236 (stack46)
        %v55239 = vxor.u32 %v55238, %v55234 (stack47)
        %v55242 = vadd.s32 %v55239, %v55234 (stack39)
        %v55244 = vshll.u32 %v55239, 15 (stack44)
        %v55245 = vshrl.u32 %v55239, 17 (stack45)
        %v55246 = vor.u32 %v55245, %v55244 (stack46)
        %v55247 = vxor.u32 %v55246, %v55242 (stack47)
        %v55250 = vadd.s32 %v55247, %v55242 (stack39)
        %v55252 = vshll.u32 %v55247, 26 (stack44)
        %v55253 = vshrl.u32 %v55247, 6 (stack45)
        %v55254 = vor.u32 %v55253, %v55252 (stack46)
        %v55255 = vxor.u32 %v55254, %v55250 (stack47)
        %v55258 = vadd.s32 %v55255, %v55250 (stack39)
        %v55262 = vadd.s32 %v55258, %v8 (stack39)
        %v55264 = vshll.u32 %v55255, 6 (stack44)
        %v55265 = vshrl.u32 %v55255, 26 (stack45)
        %v55266 = vor.u32 %v55265, %v55264 (stack46)
        %v55267 = vxor.u32 %v55266, %v55258 (stack47)
        %v55270 = vadd.s32 %v55267, %v10 (stack39)
        %v55274 = vadd.s32 5, %v55270 (stack39)
        %v55276 = vxor.u32 %v55274, %v55262 (stack47)
        %v55277 = vand.u32.u8 255, %v55276 (stack48)
        %v55278 = vand.u32 65535, %v55277 (stack49)
        %v55279 = vshrl.u32 %v55278, 1 (stack50)
        %v55280 = vor.u32 16256, %v55279 (stack46)
        %v55281 = vand.u32.u16 65535, %v55280 (stack51)
        %v120038 = vadd.low.f32.bf16 -1.0, %v55281 (stack52)
        %v55290 = vmul.f32 2.0, %v120038 (stack53)
        %v55294 = vadd.f32 -0.99609375, %v55290 (stack52)
        %v55298 = vmax.f32 %v55294, -0.99609375 (stack54)
        %v55300 = vand.u32 2147483647, %v55298 (stack55)
        %vm55303 = vcmp.eq.f32.partialorder %v55300, 1.0 (stack56)
        %v55308 = vmul.f32 inf, %v55298 (stack53)
        %v55310 = vxor.u32 2147483648, %v55298 (stack57)
        %v55313 = vmul.f32 %v55310, %v55298 (stack53)
        %v55315 = vadd.f32 1.0, %v55313 (stack58)
        %v55316 = vlog2.pop %v55315 (stack59)
        %v55317 = vmul.f32 0.6931472, %v55316 (stack60)
        %v55318 = vmul.f32 -0.5, %v55313 (stack61)
        %v55319 = vadd.f32 1.0, %v55318 (stack62)
        %v55320 = vmul.f32 %v55319, %v55313 (stack63)
        %v55321 = vand.u32 2147483647, %v55313 (stack64)
        %vm55322 = vcmp.lt.f32.partialorder %v55321, 0.0004427343 (stack65)
        %v55323 = vsel /*vm=*/%vm55322, /*on_true_vy=*/%v55320, /*on_false_vx=*/%v55317 (stack66)
        %v55324 = vxor.u32 2147483648, %v55323 (stack57)
        %vm55327 = vcmp.lt.f32.partialorder %v55324, 5.0 (stack56)
        %v55332 = vsel /*vm=*/%vm55327, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v55336 = vsel /*vm=*/%vm55327, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v55340 = vsel /*vm=*/%vm55327, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v55344 = vsel /*vm=*/%vm55327, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v55348 = vsel /*vm=*/%vm55327, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v55352 = vsel /*vm=*/%vm55327, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v55356 = vsel /*vm=*/%vm55327, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v55360 = vsel /*vm=*/%vm55327, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v55364 = vsel /*vm=*/%vm55327, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v55368 = vadd.f32 -2.5, %v55324 (stack52)
        %v55370 = vrsqrt.pop %v55324 (stack67)
        %v55371 = vmul.f32 %v55370, %v55324 (stack68)
        %vm55372 = vcmp.eq.f32.partialorder %v55324, inf (stack69)
        %v55373 = vsel /*vm=*/%vm55372, /*on_true_vy=*/%v55324, /*on_false_vx=*/%v55371 (stack70)
        %vm55374 = vcmp.eq.f32.partialorder %v55324, 0.0 (stack71)
        %v55375 = vand.u32 2147483648, %v55324 (stack72)
        %v55376 = vsel /*vm=*/%vm55374, /*on_true_vy=*/%v55375, /*on_false_vx=*/%v55373 (stack73)
        %v55379 = vadd.f32 -3.0, %v55376 (stack52)
        %v55383 = vsel /*vm=*/%vm55327, /*on_true_vy=*/%v55368, /*on_false_vx=*/%v55379 (stack43)
        %v55387 = vmul.f32 %v55383, %v55364 (stack53)
        %v55391 = vadd.f32 %v55387, %v55360 (stack52)
        %v55395 = vmul.f32 %v55391, %v55383 (stack53)
        %v55399 = vadd.f32 %v55395, %v55356 (stack52)
        %v55403 = vmul.f32 %v55399, %v55383 (stack53)
        %v55407 = vadd.f32 %v55403, %v55352 (stack52)
        %v55411 = vmul.f32 %v55407, %v55383 (stack53)
        %v55415 = vadd.f32 %v55411, %v55348 (stack52)
        %v55419 = vmul.f32 %v55415, %v55383 (stack53)
        %v55423 = vadd.f32 %v55419, %v55344 (stack52)
        %v55427 = vmul.f32 %v55423, %v55383 (stack53)
        %v55431 = vadd.f32 %v55427, %v55340 (stack52)
        %v55435 = vmul.f32 %v55431, %v55383 (stack53)
        %v55439 = vadd.f32 %v55435, %v55336 (stack52)
        %v55443 = vmul.f32 %v55439, %v55383 (stack53)
        %v55447 = vadd.f32 %v55443, %v55332 (stack52)
        %v55451 = vmul.f32 %v55447, %v55298 (stack53)
        %v55455 = vsel /*vm=*/%vm55303, /*on_true_vy=*/%v55308, /*on_false_vx=*/%v55451 (stack43)
        %v55459 = vmul.f32 1.4140625, %v55455 (stack53)
        %v55462 = vpack.c.bf16 0.0, %v55459 (stack74)
        %120039 = vst [vmem:[%s280 + $0x2b8] sm:$0xf] /*vst_source=*/%v55462 (stack75)
        %v55466 = vadd.s32 %v52697, %v3329 (stack39)
        %v55476 = vadd.s32 %v55466, %v415 (stack39)
        %vm55480 = vcmp.lt.u32.totalorder %v55476, %v55466 (stack42)
        %vm55485 = vcmp.lt.u32.totalorder %v55466, %v3329 (stack42)
        %v55490 = vadd.s32 %v52680, %v3316 (stack39)
        %v55494 = vadd.s32 1, %v55490 (stack39)
        %v55498 = vsel /*vm=*/%vm55485, /*on_true_vy=*/%v55494, /*on_false_vx=*/%v55490 (stack43)
        %v55502 = vadd.s32 1, %v55498 (stack39)
        %v55506 = vsel /*vm=*/%vm55480, /*on_true_vy=*/%v55502, /*on_false_vx=*/%v55498 (stack43)
        %v55511 = vadd.s32 %v55506, %v10 (stack39)
        %v55515 = vadd.s32 %v55476, %v9 (stack39)
        %v55519 = vadd.s32 %v55515, %v55511 (stack39)
        %v55521 = vshll.u32 %v55515, 13 (stack44)
        %v55522 = vshrl.u32 %v55515, 19 (stack45)
        %v55523 = vor.u32 %v55522, %v55521 (stack46)
        %v55524 = vxor.u32 %v55523, %v55519 (stack47)
        %v55527 = vadd.s32 %v55524, %v55519 (stack39)
        %v55529 = vshll.u32 %v55524, 15 (stack44)
        %v55530 = vshrl.u32 %v55524, 17 (stack45)
        %v55531 = vor.u32 %v55530, %v55529 (stack46)
        %v55532 = vxor.u32 %v55531, %v55527 (stack47)
        %v55535 = vadd.s32 %v55532, %v55527 (stack39)
        %v55537 = vshll.u32 %v55532, 26 (stack44)
        %v55538 = vshrl.u32 %v55532, 6 (stack45)
        %v55539 = vor.u32 %v55538, %v55537 (stack46)
        %v55540 = vxor.u32 %v55539, %v55535 (stack47)
        %v55543 = vadd.s32 %v55540, %v55535 (stack39)
        %v55547 = vadd.s32 %v55543, %v9 (stack39)
        %v55549 = vshll.u32 %v55540, 6 (stack44)
        %v55550 = vshrl.u32 %v55540, 26 (stack45)
        %v55551 = vor.u32 %v55550, %v55549 (stack46)
        %v55552 = vxor.u32 %v55551, %v55543 (stack47)
        %v55555 = vadd.s32 %v55552, %v8 (stack39)
        %v55559 = vadd.s32 1, %v55555 (stack39)
        %v55563 = vadd.s32 %v55559, %v55547 (stack39)
        %v55565 = vshll.u32 %v55559, 17 (stack44)
        %v55566 = vshrl.u32 %v55559, 15 (stack45)
        %v55567 = vor.u32 %v55566, %v55565 (stack46)
        %v55568 = vxor.u32 %v55567, %v55563 (stack47)
        %v55571 = vadd.s32 %v55568, %v55563 (stack39)
        %v55573 = vshll.u32 %v55568, 29 (stack44)
        %v55574 = vshrl.u32 %v55568, 3 (stack45)
        %v55575 = vor.u32 %v55574, %v55573 (stack46)
        %v55576 = vxor.u32 %v55575, %v55571 (stack47)
        %v55579 = vadd.s32 %v55576, %v55571 (stack39)
        %v55581 = vshll.u32 %v55576, 16 (stack44)
        %v55582 = vshrl.u32 %v55576, 16 (stack45)
        %v55583 = vor.u32 %v55582, %v55581 (stack46)
        %v55584 = vxor.u32 %v55583, %v55579 (stack47)
        %v55587 = vadd.s32 %v55584, %v55579 (stack39)
        %v55591 = vadd.s32 %v55587, %v8 (stack39)
        %v55593 = vshll.u32 %v55584, 24 (stack44)
        %v55594 = vshrl.u32 %v55584, 8 (stack45)
        %v55595 = vor.u32 %v55594, %v55593 (stack46)
        %v55596 = vxor.u32 %v55595, %v55587 (stack47)
        %v55599 = vadd.s32 %v55596, %v10 (stack39)
        %v55603 = vadd.s32 2, %v55599 (stack39)
        %v55607 = vadd.s32 %v55603, %v55591 (stack39)
        %v55609 = vshll.u32 %v55603, 13 (stack44)
        %v55610 = vshrl.u32 %v55603, 19 (stack45)
        %v55611 = vor.u32 %v55610, %v55609 (stack46)
        %v55612 = vxor.u32 %v55611, %v55607 (stack47)
        %v55615 = vadd.s32 %v55612, %v55607 (stack39)
        %v55617 = vshll.u32 %v55612, 15 (stack44)
        %v55618 = vshrl.u32 %v55612, 17 (stack45)
        %v55619 = vor.u32 %v55618, %v55617 (stack46)
        %v55620 = vxor.u32 %v55619, %v55615 (stack47)
        %v55623 = vadd.s32 %v55620, %v55615 (stack39)
        %v55625 = vshll.u32 %v55620, 26 (stack44)
        %v55626 = vshrl.u32 %v55620, 6 (stack45)
        %v55627 = vor.u32 %v55626, %v55625 (stack46)
        %v55628 = vxor.u32 %v55627, %v55623 (stack47)
        %v55631 = vadd.s32 %v55628, %v55623 (stack39)
        %v55635 = vadd.s32 %v55631, %v10 (stack39)
        %v55637 = vshll.u32 %v55628, 6 (stack44)
        %v55638 = vshrl.u32 %v55628, 26 (stack45)
        %v55639 = vor.u32 %v55638, %v55637 (stack46)
        %v55640 = vxor.u32 %v55639, %v55631 (stack47)
        %v55643 = vadd.s32 %v55640, %v9 (stack39)
        %v55647 = vadd.s32 3, %v55643 (stack39)
        %v55651 = vadd.s32 %v55647, %v55635 (stack39)
        %v55653 = vshll.u32 %v55647, 17 (stack44)
        %v55654 = vshrl.u32 %v55647, 15 (stack45)
        %v55655 = vor.u32 %v55654, %v55653 (stack46)
        %v55656 = vxor.u32 %v55655, %v55651 (stack47)
        %v55659 = vadd.s32 %v55656, %v55651 (stack39)
        %v55661 = vshll.u32 %v55656, 29 (stack44)
        %v55662 = vshrl.u32 %v55656, 3 (stack45)
        %v55663 = vor.u32 %v55662, %v55661 (stack46)
        %v55664 = vxor.u32 %v55663, %v55659 (stack47)
        %v55667 = vadd.s32 %v55664, %v55659 (stack39)
        %v55669 = vshll.u32 %v55664, 16 (stack44)
        %v55670 = vshrl.u32 %v55664, 16 (stack45)
        %v55671 = vor.u32 %v55670, %v55669 (stack46)
        %v55672 = vxor.u32 %v55671, %v55667 (stack47)
        %v55675 = vadd.s32 %v55672, %v55667 (stack39)
        %v55679 = vadd.s32 %v55675, %v9 (stack39)
        %v55681 = vshll.u32 %v55672, 24 (stack44)
        %v55682 = vshrl.u32 %v55672, 8 (stack45)
        %v55683 = vor.u32 %v55682, %v55681 (stack46)
        %v55684 = vxor.u32 %v55683, %v55675 (stack47)
        %v55687 = vadd.s32 %v55684, %v8 (stack39)
        %v55691 = vadd.s32 4, %v55687 (stack39)
        %v55695 = vadd.s32 %v55691, %v55679 (stack39)
        %v55697 = vshll.u32 %v55691, 13 (stack44)
        %v55698 = vshrl.u32 %v55691, 19 (stack45)
        %v55699 = vor.u32 %v55698, %v55697 (stack46)
        %v55700 = vxor.u32 %v55699, %v55695 (stack47)
        %v55703 = vadd.s32 %v55700, %v55695 (stack39)
        %v55705 = vshll.u32 %v55700, 15 (stack44)
        %v55706 = vshrl.u32 %v55700, 17 (stack45)
        %v55707 = vor.u32 %v55706, %v55705 (stack46)
        %v55708 = vxor.u32 %v55707, %v55703 (stack47)
        %v55711 = vadd.s32 %v55708, %v55703 (stack39)
        %v55713 = vshll.u32 %v55708, 26 (stack44)
        %v55714 = vshrl.u32 %v55708, 6 (stack45)
        %v55715 = vor.u32 %v55714, %v55713 (stack46)
        %v55716 = vxor.u32 %v55715, %v55711 (stack47)
        %v55719 = vadd.s32 %v55716, %v55711 (stack39)
        %v55723 = vadd.s32 %v55719, %v8 (stack39)
        %v55725 = vshll.u32 %v55716, 6 (stack44)
        %v55726 = vshrl.u32 %v55716, 26 (stack45)
        %v55727 = vor.u32 %v55726, %v55725 (stack46)
        %v55728 = vxor.u32 %v55727, %v55719 (stack47)
        %v55731 = vadd.s32 %v55728, %v10 (stack39)
        %v55735 = vadd.s32 5, %v55731 (stack39)
        %v55737 = vxor.u32 %v55735, %v55723 (stack47)
        %v55738 = vand.u32.u8 255, %v55737 (stack48)
        %v55739 = vand.u32 65535, %v55738 (stack49)
        %v55740 = vshrl.u32 %v55739, 1 (stack50)
        %v55741 = vor.u32 16256, %v55740 (stack46)
        %v55742 = vand.u32.u16 65535, %v55741 (stack51)
        %v120040 = vadd.low.f32.bf16 -1.0, %v55742 (stack52)
        %v55751 = vmul.f32 2.0, %v120040 (stack53)
        %v55755 = vadd.f32 -0.99609375, %v55751 (stack52)
        %v55759 = vmax.f32 %v55755, -0.99609375 (stack54)
        %v55761 = vand.u32 2147483647, %v55759 (stack55)
        %vm55764 = vcmp.eq.f32.partialorder %v55761, 1.0 (stack56)
        %v55769 = vmul.f32 inf, %v55759 (stack53)
        %v55771 = vxor.u32 2147483648, %v55759 (stack57)
        %v55774 = vmul.f32 %v55771, %v55759 (stack53)
        %v55776 = vadd.f32 1.0, %v55774 (stack58)
        %v55777 = vlog2.pop %v55776 (stack59)
        %v55778 = vmul.f32 0.6931472, %v55777 (stack60)
        %v55779 = vmul.f32 -0.5, %v55774 (stack61)
        %v55780 = vadd.f32 1.0, %v55779 (stack62)
        %v55781 = vmul.f32 %v55780, %v55774 (stack63)
        %v55782 = vand.u32 2147483647, %v55774 (stack64)
        %vm55783 = vcmp.lt.f32.partialorder %v55782, 0.0004427343 (stack65)
        %v55784 = vsel /*vm=*/%vm55783, /*on_true_vy=*/%v55781, /*on_false_vx=*/%v55778 (stack66)
        %v55785 = vxor.u32 2147483648, %v55784 (stack57)
        %vm55788 = vcmp.lt.f32.partialorder %v55785, 5.0 (stack56)
        %v55793 = vsel /*vm=*/%vm55788, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v55797 = vsel /*vm=*/%vm55788, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v55801 = vsel /*vm=*/%vm55788, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v55805 = vsel /*vm=*/%vm55788, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v55809 = vsel /*vm=*/%vm55788, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v55813 = vsel /*vm=*/%vm55788, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v55817 = vsel /*vm=*/%vm55788, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v55821 = vsel /*vm=*/%vm55788, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v55825 = vsel /*vm=*/%vm55788, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v55829 = vadd.f32 -2.5, %v55785 (stack52)
        %v55831 = vrsqrt.pop %v55785 (stack67)
        %v55832 = vmul.f32 %v55831, %v55785 (stack68)
        %vm55833 = vcmp.eq.f32.partialorder %v55785, inf (stack69)
        %v55834 = vsel /*vm=*/%vm55833, /*on_true_vy=*/%v55785, /*on_false_vx=*/%v55832 (stack70)
        %vm55835 = vcmp.eq.f32.partialorder %v55785, 0.0 (stack71)
        %v55836 = vand.u32 2147483648, %v55785 (stack72)
        %v55837 = vsel /*vm=*/%vm55835, /*on_true_vy=*/%v55836, /*on_false_vx=*/%v55834 (stack73)
        %v55840 = vadd.f32 -3.0, %v55837 (stack52)
        %v55844 = vsel /*vm=*/%vm55788, /*on_true_vy=*/%v55829, /*on_false_vx=*/%v55840 (stack43)
        %v55848 = vmul.f32 %v55844, %v55825 (stack53)
        %v55852 = vadd.f32 %v55848, %v55821 (stack52)
        %v55856 = vmul.f32 %v55852, %v55844 (stack53)
        %v55860 = vadd.f32 %v55856, %v55817 (stack52)
        %v55864 = vmul.f32 %v55860, %v55844 (stack53)
        %v55868 = vadd.f32 %v55864, %v55813 (stack52)
        %v55872 = vmul.f32 %v55868, %v55844 (stack53)
        %v55876 = vadd.f32 %v55872, %v55809 (stack52)
        %v55880 = vmul.f32 %v55876, %v55844 (stack53)
        %v55884 = vadd.f32 %v55880, %v55805 (stack52)
        %v55888 = vmul.f32 %v55884, %v55844 (stack53)
        %v55892 = vadd.f32 %v55888, %v55801 (stack52)
        %v55896 = vmul.f32 %v55892, %v55844 (stack53)
        %v55900 = vadd.f32 %v55896, %v55797 (stack52)
        %v55904 = vmul.f32 %v55900, %v55844 (stack53)
        %v55908 = vadd.f32 %v55904, %v55793 (stack52)
        %v55912 = vmul.f32 %v55908, %v55759 (stack53)
        %v55916 = vsel /*vm=*/%vm55764, /*on_true_vy=*/%v55769, /*on_false_vx=*/%v55912 (stack43)
        %v55920 = vmul.f32 1.4140625, %v55916 (stack53)
        %v55923 = vpack.c.bf16 0.0, %v55920 (stack74)
        %120041 = vst [vmem:[%s280 + $0x338] sm:$0xf] /*vst_source=*/%v55923 (stack75)
        %v55927 = vadd.s32 %v52697, %v3816 (stack39)
        %v55937 = vadd.s32 %v55927, %v415 (stack39)
        %vm55941 = vcmp.lt.u32.totalorder %v55937, %v55927 (stack42)
        %vm55946 = vcmp.lt.u32.totalorder %v55927, %v3816 (stack42)
        %v55951 = vadd.s32 %v52680, %v3803 (stack39)
        %v55955 = vadd.s32 1, %v55951 (stack39)
        %v55959 = vsel /*vm=*/%vm55946, /*on_true_vy=*/%v55955, /*on_false_vx=*/%v55951 (stack43)
        %v55963 = vadd.s32 1, %v55959 (stack39)
        %v55967 = vsel /*vm=*/%vm55941, /*on_true_vy=*/%v55963, /*on_false_vx=*/%v55959 (stack43)
        %v55972 = vadd.s32 %v55967, %v10 (stack39)
        %v55976 = vadd.s32 %v55937, %v9 (stack39)
        %v55980 = vadd.s32 %v55976, %v55972 (stack39)
        %v55982 = vshll.u32 %v55976, 13 (stack44)
        %v55983 = vshrl.u32 %v55976, 19 (stack45)
        %v55984 = vor.u32 %v55983, %v55982 (stack46)
        %v55985 = vxor.u32 %v55984, %v55980 (stack47)
        %v55988 = vadd.s32 %v55985, %v55980 (stack39)
        %v55990 = vshll.u32 %v55985, 15 (stack44)
        %v55991 = vshrl.u32 %v55985, 17 (stack45)
        %v55992 = vor.u32 %v55991, %v55990 (stack46)
        %v55993 = vxor.u32 %v55992, %v55988 (stack47)
        %v55996 = vadd.s32 %v55993, %v55988 (stack39)
        %v55998 = vshll.u32 %v55993, 26 (stack44)
        %v55999 = vshrl.u32 %v55993, 6 (stack45)
        %v56000 = vor.u32 %v55999, %v55998 (stack46)
        %v56001 = vxor.u32 %v56000, %v55996 (stack47)
        %v56004 = vadd.s32 %v56001, %v55996 (stack39)
        %v56008 = vadd.s32 %v56004, %v9 (stack39)
        %v56010 = vshll.u32 %v56001, 6 (stack44)
        %v56011 = vshrl.u32 %v56001, 26 (stack45)
        %v56012 = vor.u32 %v56011, %v56010 (stack46)
        %v56013 = vxor.u32 %v56012, %v56004 (stack47)
        %v56016 = vadd.s32 %v56013, %v8 (stack39)
        %v56020 = vadd.s32 1, %v56016 (stack39)
        %v56024 = vadd.s32 %v56020, %v56008 (stack39)
        %v56026 = vshll.u32 %v56020, 17 (stack44)
        %v56027 = vshrl.u32 %v56020, 15 (stack45)
        %v56028 = vor.u32 %v56027, %v56026 (stack46)
        %v56029 = vxor.u32 %v56028, %v56024 (stack47)
        %v56032 = vadd.s32 %v56029, %v56024 (stack39)
        %v56034 = vshll.u32 %v56029, 29 (stack44)
        %v56035 = vshrl.u32 %v56029, 3 (stack45)
        %v56036 = vor.u32 %v56035, %v56034 (stack46)
        %v56037 = vxor.u32 %v56036, %v56032 (stack47)
        %v56040 = vadd.s32 %v56037, %v56032 (stack39)
        %v56042 = vshll.u32 %v56037, 16 (stack44)
        %v56043 = vshrl.u32 %v56037, 16 (stack45)
        %v56044 = vor.u32 %v56043, %v56042 (stack46)
        %v56045 = vxor.u32 %v56044, %v56040 (stack47)
        %v56048 = vadd.s32 %v56045, %v56040 (stack39)
        %v56052 = vadd.s32 %v56048, %v8 (stack39)
        %v56054 = vshll.u32 %v56045, 24 (stack44)
        %v56055 = vshrl.u32 %v56045, 8 (stack45)
        %v56056 = vor.u32 %v56055, %v56054 (stack46)
        %v56057 = vxor.u32 %v56056, %v56048 (stack47)
        %v56060 = vadd.s32 %v56057, %v10 (stack39)
        %v56064 = vadd.s32 2, %v56060 (stack39)
        %v56068 = vadd.s32 %v56064, %v56052 (stack39)
        %v56070 = vshll.u32 %v56064, 13 (stack44)
        %v56071 = vshrl.u32 %v56064, 19 (stack45)
        %v56072 = vor.u32 %v56071, %v56070 (stack46)
        %v56073 = vxor.u32 %v56072, %v56068 (stack47)
        %v56076 = vadd.s32 %v56073, %v56068 (stack39)
        %v56078 = vshll.u32 %v56073, 15 (stack44)
        %v56079 = vshrl.u32 %v56073, 17 (stack45)
        %v56080 = vor.u32 %v56079, %v56078 (stack46)
        %v56081 = vxor.u32 %v56080, %v56076 (stack47)
        %v56084 = vadd.s32 %v56081, %v56076 (stack39)
        %v56086 = vshll.u32 %v56081, 26 (stack44)
        %v56087 = vshrl.u32 %v56081, 6 (stack45)
        %v56088 = vor.u32 %v56087, %v56086 (stack46)
        %v56089 = vxor.u32 %v56088, %v56084 (stack47)
        %v56092 = vadd.s32 %v56089, %v56084 (stack39)
        %v56096 = vadd.s32 %v56092, %v10 (stack39)
        %v56098 = vshll.u32 %v56089, 6 (stack44)
        %v56099 = vshrl.u32 %v56089, 26 (stack45)
        %v56100 = vor.u32 %v56099, %v56098 (stack46)
        %v56101 = vxor.u32 %v56100, %v56092 (stack47)
        %v56104 = vadd.s32 %v56101, %v9 (stack39)
        %v56108 = vadd.s32 3, %v56104 (stack39)
        %v56112 = vadd.s32 %v56108, %v56096 (stack39)
        %v56114 = vshll.u32 %v56108, 17 (stack44)
        %v56115 = vshrl.u32 %v56108, 15 (stack45)
        %v56116 = vor.u32 %v56115, %v56114 (stack46)
        %v56117 = vxor.u32 %v56116, %v56112 (stack47)
        %v56120 = vadd.s32 %v56117, %v56112 (stack39)
        %v56122 = vshll.u32 %v56117, 29 (stack44)
        %v56123 = vshrl.u32 %v56117, 3 (stack45)
        %v56124 = vor.u32 %v56123, %v56122 (stack46)
        %v56125 = vxor.u32 %v56124, %v56120 (stack47)
        %v56128 = vadd.s32 %v56125, %v56120 (stack39)
        %v56130 = vshll.u32 %v56125, 16 (stack44)
        %v56131 = vshrl.u32 %v56125, 16 (stack45)
        %v56132 = vor.u32 %v56131, %v56130 (stack46)
        %v56133 = vxor.u32 %v56132, %v56128 (stack47)
        %v56136 = vadd.s32 %v56133, %v56128 (stack39)
        %v56140 = vadd.s32 %v56136, %v9 (stack39)
        %v56142 = vshll.u32 %v56133, 24 (stack44)
        %v56143 = vshrl.u32 %v56133, 8 (stack45)
        %v56144 = vor.u32 %v56143, %v56142 (stack46)
        %v56145 = vxor.u32 %v56144, %v56136 (stack47)
        %v56148 = vadd.s32 %v56145, %v8 (stack39)
        %v56152 = vadd.s32 4, %v56148 (stack39)
        %v56156 = vadd.s32 %v56152, %v56140 (stack39)
        %v56158 = vshll.u32 %v56152, 13 (stack44)
        %v56159 = vshrl.u32 %v56152, 19 (stack45)
        %v56160 = vor.u32 %v56159, %v56158 (stack46)
        %v56161 = vxor.u32 %v56160, %v56156 (stack47)
        %v56164 = vadd.s32 %v56161, %v56156 (stack39)
        %v56166 = vshll.u32 %v56161, 15 (stack44)
        %v56167 = vshrl.u32 %v56161, 17 (stack45)
        %v56168 = vor.u32 %v56167, %v56166 (stack46)
        %v56169 = vxor.u32 %v56168, %v56164 (stack47)
        %v56172 = vadd.s32 %v56169, %v56164 (stack39)
        %v56174 = vshll.u32 %v56169, 26 (stack44)
        %v56175 = vshrl.u32 %v56169, 6 (stack45)
        %v56176 = vor.u32 %v56175, %v56174 (stack46)
        %v56177 = vxor.u32 %v56176, %v56172 (stack47)
        %v56180 = vadd.s32 %v56177, %v56172 (stack39)
        %v56184 = vadd.s32 %v56180, %v8 (stack39)
        %v56186 = vshll.u32 %v56177, 6 (stack44)
        %v56187 = vshrl.u32 %v56177, 26 (stack45)
        %v56188 = vor.u32 %v56187, %v56186 (stack46)
        %v56189 = vxor.u32 %v56188, %v56180 (stack47)
        %v56192 = vadd.s32 %v56189, %v10 (stack39)
        %v56196 = vadd.s32 5, %v56192 (stack39)
        %v56198 = vxor.u32 %v56196, %v56184 (stack47)
        %v56199 = vand.u32.u8 255, %v56198 (stack48)
        %v56200 = vand.u32 65535, %v56199 (stack49)
        %v56201 = vshrl.u32 %v56200, 1 (stack50)
        %v56202 = vor.u32 16256, %v56201 (stack46)
        %v56203 = vand.u32.u16 65535, %v56202 (stack51)
        %v120042 = vadd.low.f32.bf16 -1.0, %v56203 (stack52)
        %v56212 = vmul.f32 2.0, %v120042 (stack53)
        %v56216 = vadd.f32 -0.99609375, %v56212 (stack52)
        %v56220 = vmax.f32 %v56216, -0.99609375 (stack54)
        %v56222 = vand.u32 2147483647, %v56220 (stack55)
        %vm56225 = vcmp.eq.f32.partialorder %v56222, 1.0 (stack56)
        %v56230 = vmul.f32 inf, %v56220 (stack53)
        %v56232 = vxor.u32 2147483648, %v56220 (stack57)
        %v56235 = vmul.f32 %v56232, %v56220 (stack53)
        %v56237 = vadd.f32 1.0, %v56235 (stack58)
        %v56238 = vlog2.pop %v56237 (stack59)
        %v56239 = vmul.f32 0.6931472, %v56238 (stack60)
        %v56240 = vmul.f32 -0.5, %v56235 (stack61)
        %v56241 = vadd.f32 1.0, %v56240 (stack62)
        %v56242 = vmul.f32 %v56241, %v56235 (stack63)
        %v56243 = vand.u32 2147483647, %v56235 (stack64)
        %vm56244 = vcmp.lt.f32.partialorder %v56243, 0.0004427343 (stack65)
        %v56245 = vsel /*vm=*/%vm56244, /*on_true_vy=*/%v56242, /*on_false_vx=*/%v56239 (stack66)
        %v56246 = vxor.u32 2147483648, %v56245 (stack57)
        %vm56249 = vcmp.lt.f32.partialorder %v56246, 5.0 (stack56)
        %v56254 = vsel /*vm=*/%vm56249, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v56258 = vsel /*vm=*/%vm56249, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v56262 = vsel /*vm=*/%vm56249, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v56266 = vsel /*vm=*/%vm56249, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v56270 = vsel /*vm=*/%vm56249, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v56274 = vsel /*vm=*/%vm56249, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v56278 = vsel /*vm=*/%vm56249, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v56282 = vsel /*vm=*/%vm56249, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v56286 = vsel /*vm=*/%vm56249, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v56290 = vadd.f32 -2.5, %v56246 (stack52)
        %v56292 = vrsqrt.pop %v56246 (stack67)
        %v56293 = vmul.f32 %v56292, %v56246 (stack68)
        %vm56294 = vcmp.eq.f32.partialorder %v56246, inf (stack69)
        %v56295 = vsel /*vm=*/%vm56294, /*on_true_vy=*/%v56246, /*on_false_vx=*/%v56293 (stack70)
        %vm56296 = vcmp.eq.f32.partialorder %v56246, 0.0 (stack71)
        %v56297 = vand.u32 2147483648, %v56246 (stack72)
        %v56298 = vsel /*vm=*/%vm56296, /*on_true_vy=*/%v56297, /*on_false_vx=*/%v56295 (stack73)
        %v56301 = vadd.f32 -3.0, %v56298 (stack52)
        %v56305 = vsel /*vm=*/%vm56249, /*on_true_vy=*/%v56290, /*on_false_vx=*/%v56301 (stack43)
        %v56309 = vmul.f32 %v56305, %v56286 (stack53)
        %v56313 = vadd.f32 %v56309, %v56282 (stack52)
        %v56317 = vmul.f32 %v56313, %v56305 (stack53)
        %v56321 = vadd.f32 %v56317, %v56278 (stack52)
        %v56325 = vmul.f32 %v56321, %v56305 (stack53)
        %v56329 = vadd.f32 %v56325, %v56274 (stack52)
        %v56333 = vmul.f32 %v56329, %v56305 (stack53)
        %v56337 = vadd.f32 %v56333, %v56270 (stack52)
        %v56341 = vmul.f32 %v56337, %v56305 (stack53)
        %v56345 = vadd.f32 %v56341, %v56266 (stack52)
        %v56349 = vmul.f32 %v56345, %v56305 (stack53)
        %v56353 = vadd.f32 %v56349, %v56262 (stack52)
        %v56357 = vmul.f32 %v56353, %v56305 (stack53)
        %v56361 = vadd.f32 %v56357, %v56258 (stack52)
        %v56365 = vmul.f32 %v56361, %v56305 (stack53)
        %v56369 = vadd.f32 %v56365, %v56254 (stack52)
        %v56373 = vmul.f32 %v56369, %v56220 (stack53)
        %v56377 = vsel /*vm=*/%vm56225, /*on_true_vy=*/%v56230, /*on_false_vx=*/%v56373 (stack43)
        %v56381 = vmul.f32 1.4140625, %v56377 (stack53)
        %v56384 = vpack.c.bf16 0.0, %v56381 (stack74)
        %120043 = vst [vmem:[%s280 + $0x3b8] sm:$0xf] /*vst_source=*/%v56384 (stack75)
        %s56386 = sadd.s32 120, %s120390 (stack76)
        %s56387 = sshrl.u32 %s56386, 10 (stack23)
        %p120044 = scmp.gt.s32.totalorder %s56387, 1 (stack24)
        %s56389 = scalar_select /*predicate=*/%p120044, /*on_true=*/1, /*on_false=*/%s56387 (stack25)
        %s56390 = sand.u32 1023, %s56386 /* smod.u32 w/div 1024 */ (stack26)
        %s56391 = sshrl.u32 %s56390, 7 (stack27)
        %s56392 = sand.u32 127, %s56390 /* smod.u32 w/div 128 */ (stack28)
        %s120045 = sshll.u32 %s56389, 3 (stack29)
        %s56394 = scalar_lea.vmem %s3, %s120045 (stack30)
        %s56396 = scalar_lea.vmem %s56394, %s56391 (stack31)
        %v56397 = vld [vmem:[%s56396] ss:$0 sm:$0xff] (stack32)
        %s56398 = sand.u32 255, %s56392 (stack33)
        %s56400 = sor.u32 256, %s56398 (stack34)
        %56401 = vbcast.lane.b32.xlu0 %v56397, %s56400 (stack35)
        %v56402 = vpop.permute.xlu0 %56401 (stack36)
        %s56411 = scalar_lea.vmem %s5, %s120045 (stack30)
        %s56413 = scalar_lea.vmem %s56411, %s56391 (stack31)
        %v56414 = vld [vmem:[%s56413] ss:$0 sm:$0xff] (stack32)
        %56418 = vbcast.lane.b32.xlu0 %v56414, %s56400 (stack35)
        %v56419 = vpop.permute.xlu0 %56418 (stack36)
        %v56422 = vadd.s32 %v56419, %v408 (stack39)
        %v56432 = vadd.s32 %v56422, %v415 (stack39)
        %vm56436 = vcmp.lt.u32.totalorder %v56432, %v56422 (stack42)
        %vm56441 = vcmp.lt.u32.totalorder %v56422, %v408 (stack42)
        %v56446 = vadd.s32 %v56402, %v380 (stack39)
        %v56450 = vadd.s32 1, %v56446 (stack39)
        %v56454 = vsel /*vm=*/%vm56441, /*on_true_vy=*/%v56450, /*on_false_vx=*/%v56446 (stack43)
        %v56458 = vadd.s32 1, %v56454 (stack39)
        %v56462 = vsel /*vm=*/%vm56436, /*on_true_vy=*/%v56458, /*on_false_vx=*/%v56454 (stack43)
        %v56467 = vadd.s32 %v56462, %v10 (stack39)
        %v56471 = vadd.s32 %v56432, %v9 (stack39)
        %v56475 = vadd.s32 %v56471, %v56467 (stack39)
        %v56477 = vshll.u32 %v56471, 13 (stack44)
        %v56478 = vshrl.u32 %v56471, 19 (stack45)
        %v56479 = vor.u32 %v56478, %v56477 (stack46)
        %v56480 = vxor.u32 %v56479, %v56475 (stack47)
        %v56483 = vadd.s32 %v56480, %v56475 (stack39)
        %v56485 = vshll.u32 %v56480, 15 (stack44)
        %v56486 = vshrl.u32 %v56480, 17 (stack45)
        %v56487 = vor.u32 %v56486, %v56485 (stack46)
        %v56488 = vxor.u32 %v56487, %v56483 (stack47)
        %v56491 = vadd.s32 %v56488, %v56483 (stack39)
        %v56493 = vshll.u32 %v56488, 26 (stack44)
        %v56494 = vshrl.u32 %v56488, 6 (stack45)
        %v56495 = vor.u32 %v56494, %v56493 (stack46)
        %v56496 = vxor.u32 %v56495, %v56491 (stack47)
        %v56499 = vadd.s32 %v56496, %v56491 (stack39)
        %v56503 = vadd.s32 %v56499, %v9 (stack39)
        %v56505 = vshll.u32 %v56496, 6 (stack44)
        %v56506 = vshrl.u32 %v56496, 26 (stack45)
        %v56507 = vor.u32 %v56506, %v56505 (stack46)
        %v56508 = vxor.u32 %v56507, %v56499 (stack47)
        %v56511 = vadd.s32 %v56508, %v8 (stack39)
        %v56515 = vadd.s32 1, %v56511 (stack39)
        %v56519 = vadd.s32 %v56515, %v56503 (stack39)
        %v56521 = vshll.u32 %v56515, 17 (stack44)
        %v56522 = vshrl.u32 %v56515, 15 (stack45)
        %v56523 = vor.u32 %v56522, %v56521 (stack46)
        %v56524 = vxor.u32 %v56523, %v56519 (stack47)
        %v56527 = vadd.s32 %v56524, %v56519 (stack39)
        %v56529 = vshll.u32 %v56524, 29 (stack44)
        %v56530 = vshrl.u32 %v56524, 3 (stack45)
        %v56531 = vor.u32 %v56530, %v56529 (stack46)
        %v56532 = vxor.u32 %v56531, %v56527 (stack47)
        %v56535 = vadd.s32 %v56532, %v56527 (stack39)
        %v56537 = vshll.u32 %v56532, 16 (stack44)
        %v56538 = vshrl.u32 %v56532, 16 (stack45)
        %v56539 = vor.u32 %v56538, %v56537 (stack46)
        %v56540 = vxor.u32 %v56539, %v56535 (stack47)
        %v56543 = vadd.s32 %v56540, %v56535 (stack39)
        %v56547 = vadd.s32 %v56543, %v8 (stack39)
        %v56549 = vshll.u32 %v56540, 24 (stack44)
        %v56550 = vshrl.u32 %v56540, 8 (stack45)
        %v56551 = vor.u32 %v56550, %v56549 (stack46)
        %v56552 = vxor.u32 %v56551, %v56543 (stack47)
        %v56555 = vadd.s32 %v56552, %v10 (stack39)
        %v56559 = vadd.s32 2, %v56555 (stack39)
        %v56563 = vadd.s32 %v56559, %v56547 (stack39)
        %v56565 = vshll.u32 %v56559, 13 (stack44)
        %v56566 = vshrl.u32 %v56559, 19 (stack45)
        %v56567 = vor.u32 %v56566, %v56565 (stack46)
        %v56568 = vxor.u32 %v56567, %v56563 (stack47)
        %v56571 = vadd.s32 %v56568, %v56563 (stack39)
        %v56573 = vshll.u32 %v56568, 15 (stack44)
        %v56574 = vshrl.u32 %v56568, 17 (stack45)
        %v56575 = vor.u32 %v56574, %v56573 (stack46)
        %v56576 = vxor.u32 %v56575, %v56571 (stack47)
        %v56579 = vadd.s32 %v56576, %v56571 (stack39)
        %v56581 = vshll.u32 %v56576, 26 (stack44)
        %v56582 = vshrl.u32 %v56576, 6 (stack45)
        %v56583 = vor.u32 %v56582, %v56581 (stack46)
        %v56584 = vxor.u32 %v56583, %v56579 (stack47)
        %v56587 = vadd.s32 %v56584, %v56579 (stack39)
        %v56591 = vadd.s32 %v56587, %v10 (stack39)
        %v56593 = vshll.u32 %v56584, 6 (stack44)
        %v56594 = vshrl.u32 %v56584, 26 (stack45)
        %v56595 = vor.u32 %v56594, %v56593 (stack46)
        %v56596 = vxor.u32 %v56595, %v56587 (stack47)
        %v56599 = vadd.s32 %v56596, %v9 (stack39)
        %v56603 = vadd.s32 3, %v56599 (stack39)
        %v56607 = vadd.s32 %v56603, %v56591 (stack39)
        %v56609 = vshll.u32 %v56603, 17 (stack44)
        %v56610 = vshrl.u32 %v56603, 15 (stack45)
        %v56611 = vor.u32 %v56610, %v56609 (stack46)
        %v56612 = vxor.u32 %v56611, %v56607 (stack47)
        %v56615 = vadd.s32 %v56612, %v56607 (stack39)
        %v56617 = vshll.u32 %v56612, 29 (stack44)
        %v56618 = vshrl.u32 %v56612, 3 (stack45)
        %v56619 = vor.u32 %v56618, %v56617 (stack46)
        %v56620 = vxor.u32 %v56619, %v56615 (stack47)
        %v56623 = vadd.s32 %v56620, %v56615 (stack39)
        %v56625 = vshll.u32 %v56620, 16 (stack44)
        %v56626 = vshrl.u32 %v56620, 16 (stack45)
        %v56627 = vor.u32 %v56626, %v56625 (stack46)
        %v56628 = vxor.u32 %v56627, %v56623 (stack47)
        %v56631 = vadd.s32 %v56628, %v56623 (stack39)
        %v56635 = vadd.s32 %v56631, %v9 (stack39)
        %v56637 = vshll.u32 %v56628, 24 (stack44)
        %v56638 = vshrl.u32 %v56628, 8 (stack45)
        %v56639 = vor.u32 %v56638, %v56637 (stack46)
        %v56640 = vxor.u32 %v56639, %v56631 (stack47)
        %v56643 = vadd.s32 %v56640, %v8 (stack39)
        %v56647 = vadd.s32 4, %v56643 (stack39)
        %v56651 = vadd.s32 %v56647, %v56635 (stack39)
        %v56653 = vshll.u32 %v56647, 13 (stack44)
        %v56654 = vshrl.u32 %v56647, 19 (stack45)
        %v56655 = vor.u32 %v56654, %v56653 (stack46)
        %v56656 = vxor.u32 %v56655, %v56651 (stack47)
        %v56659 = vadd.s32 %v56656, %v56651 (stack39)
        %v56661 = vshll.u32 %v56656, 15 (stack44)
        %v56662 = vshrl.u32 %v56656, 17 (stack45)
        %v56663 = vor.u32 %v56662, %v56661 (stack46)
        %v56664 = vxor.u32 %v56663, %v56659 (stack47)
        %v56667 = vadd.s32 %v56664, %v56659 (stack39)
        %v56669 = vshll.u32 %v56664, 26 (stack44)
        %v56670 = vshrl.u32 %v56664, 6 (stack45)
        %v56671 = vor.u32 %v56670, %v56669 (stack46)
        %v56672 = vxor.u32 %v56671, %v56667 (stack47)
        %v56675 = vadd.s32 %v56672, %v56667 (stack39)
        %v56679 = vadd.s32 %v56675, %v8 (stack39)
        %v56681 = vshll.u32 %v56672, 6 (stack44)
        %v56682 = vshrl.u32 %v56672, 26 (stack45)
        %v56683 = vor.u32 %v56682, %v56681 (stack46)
        %v56684 = vxor.u32 %v56683, %v56675 (stack47)
        %v56687 = vadd.s32 %v56684, %v10 (stack39)
        %v56691 = vadd.s32 5, %v56687 (stack39)
        %v56693 = vxor.u32 %v56691, %v56679 (stack47)
        %v56694 = vand.u32.u8 255, %v56693 (stack48)
        %v56695 = vand.u32 65535, %v56694 (stack49)
        %v56696 = vshrl.u32 %v56695, 1 (stack50)
        %v56697 = vor.u32 16256, %v56696 (stack46)
        %v56698 = vand.u32.u16 65535, %v56697 (stack51)
        %v120048 = vadd.low.f32.bf16 -1.0, %v56698 (stack52)
        %v56707 = vmul.f32 2.0, %v120048 (stack53)
        %v56711 = vadd.f32 -0.99609375, %v56707 (stack52)
        %v56715 = vmax.f32 %v56711, -0.99609375 (stack54)
        %v56717 = vand.u32 2147483647, %v56715 (stack55)
        %vm56720 = vcmp.eq.f32.partialorder %v56717, 1.0 (stack56)
        %v56725 = vmul.f32 inf, %v56715 (stack53)
        %v56727 = vxor.u32 2147483648, %v56715 (stack57)
        %v56730 = vmul.f32 %v56727, %v56715 (stack53)
        %v56732 = vadd.f32 1.0, %v56730 (stack58)
        %v56733 = vlog2.pop %v56732 (stack59)
        %v56734 = vmul.f32 0.6931472, %v56733 (stack60)
        %v56735 = vmul.f32 -0.5, %v56730 (stack61)
        %v56736 = vadd.f32 1.0, %v56735 (stack62)
        %v56737 = vmul.f32 %v56736, %v56730 (stack63)
        %v56738 = vand.u32 2147483647, %v56730 (stack64)
        %vm56739 = vcmp.lt.f32.partialorder %v56738, 0.0004427343 (stack65)
        %v56740 = vsel /*vm=*/%vm56739, /*on_true_vy=*/%v56737, /*on_false_vx=*/%v56734 (stack66)
        %v56741 = vxor.u32 2147483648, %v56740 (stack57)
        %vm56744 = vcmp.lt.f32.partialorder %v56741, 5.0 (stack56)
        %v56749 = vsel /*vm=*/%vm56744, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v56753 = vsel /*vm=*/%vm56744, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v56757 = vsel /*vm=*/%vm56744, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v56761 = vsel /*vm=*/%vm56744, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v56765 = vsel /*vm=*/%vm56744, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v56769 = vsel /*vm=*/%vm56744, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v56773 = vsel /*vm=*/%vm56744, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v56777 = vsel /*vm=*/%vm56744, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v56781 = vsel /*vm=*/%vm56744, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v56785 = vadd.f32 -2.5, %v56741 (stack52)
        %v56787 = vrsqrt.pop %v56741 (stack67)
        %v56788 = vmul.f32 %v56787, %v56741 (stack68)
        %vm56789 = vcmp.eq.f32.partialorder %v56741, inf (stack69)
        %v56790 = vsel /*vm=*/%vm56789, /*on_true_vy=*/%v56741, /*on_false_vx=*/%v56788 (stack70)
        %vm56791 = vcmp.eq.f32.partialorder %v56741, 0.0 (stack71)
        %v56792 = vand.u32 2147483648, %v56741 (stack72)
        %v56793 = vsel /*vm=*/%vm56791, /*on_true_vy=*/%v56792, /*on_false_vx=*/%v56790 (stack73)
        %v56796 = vadd.f32 -3.0, %v56793 (stack52)
        %v56800 = vsel /*vm=*/%vm56744, /*on_true_vy=*/%v56785, /*on_false_vx=*/%v56796 (stack43)
        %v56804 = vmul.f32 %v56800, %v56781 (stack53)
        %v56808 = vadd.f32 %v56804, %v56777 (stack52)
        %v56812 = vmul.f32 %v56808, %v56800 (stack53)
        %v56816 = vadd.f32 %v56812, %v56773 (stack52)
        %v56820 = vmul.f32 %v56816, %v56800 (stack53)
        %v56824 = vadd.f32 %v56820, %v56769 (stack52)
        %v56828 = vmul.f32 %v56824, %v56800 (stack53)
        %v56832 = vadd.f32 %v56828, %v56765 (stack52)
        %v56836 = vmul.f32 %v56832, %v56800 (stack53)
        %v56840 = vadd.f32 %v56836, %v56761 (stack52)
        %v56844 = vmul.f32 %v56840, %v56800 (stack53)
        %v56848 = vadd.f32 %v56844, %v56757 (stack52)
        %v56852 = vmul.f32 %v56848, %v56800 (stack53)
        %v56856 = vadd.f32 %v56852, %v56753 (stack52)
        %v56860 = vmul.f32 %v56856, %v56800 (stack53)
        %v56864 = vadd.f32 %v56860, %v56749 (stack52)
        %v56868 = vmul.f32 %v56864, %v56715 (stack53)
        %v56872 = vsel /*vm=*/%vm56720, /*on_true_vy=*/%v56725, /*on_false_vx=*/%v56868 (stack43)
        %v56876 = vmul.f32 1.4140625, %v56872 (stack53)
        %v56879 = vpack.c.bf16 0.0, %v56876 (stack74)
        %120049 = vst [vmem:[%s280 + $0x3c] sm:$0xf] /*vst_source=*/%v56879 (stack75)
        %v56883 = vadd.s32 %v56419, %v894 (stack39)
        %v56893 = vadd.s32 %v56883, %v415 (stack39)
        %vm56897 = vcmp.lt.u32.totalorder %v56893, %v56883 (stack42)
        %vm56902 = vcmp.lt.u32.totalorder %v56883, %v894 (stack42)
        %v56907 = vadd.s32 %v56402, %v881 (stack39)
        %v56911 = vadd.s32 1, %v56907 (stack39)
        %v56915 = vsel /*vm=*/%vm56902, /*on_true_vy=*/%v56911, /*on_false_vx=*/%v56907 (stack43)
        %v56919 = vadd.s32 1, %v56915 (stack39)
        %v56923 = vsel /*vm=*/%vm56897, /*on_true_vy=*/%v56919, /*on_false_vx=*/%v56915 (stack43)
        %v56928 = vadd.s32 %v56923, %v10 (stack39)
        %v56932 = vadd.s32 %v56893, %v9 (stack39)
        %v56936 = vadd.s32 %v56932, %v56928 (stack39)
        %v56938 = vshll.u32 %v56932, 13 (stack44)
        %v56939 = vshrl.u32 %v56932, 19 (stack45)
        %v56940 = vor.u32 %v56939, %v56938 (stack46)
        %v56941 = vxor.u32 %v56940, %v56936 (stack47)
        %v56944 = vadd.s32 %v56941, %v56936 (stack39)
        %v56946 = vshll.u32 %v56941, 15 (stack44)
        %v56947 = vshrl.u32 %v56941, 17 (stack45)
        %v56948 = vor.u32 %v56947, %v56946 (stack46)
        %v56949 = vxor.u32 %v56948, %v56944 (stack47)
        %v56952 = vadd.s32 %v56949, %v56944 (stack39)
        %v56954 = vshll.u32 %v56949, 26 (stack44)
        %v56955 = vshrl.u32 %v56949, 6 (stack45)
        %v56956 = vor.u32 %v56955, %v56954 (stack46)
        %v56957 = vxor.u32 %v56956, %v56952 (stack47)
        %v56960 = vadd.s32 %v56957, %v56952 (stack39)
        %v56964 = vadd.s32 %v56960, %v9 (stack39)
        %v56966 = vshll.u32 %v56957, 6 (stack44)
        %v56967 = vshrl.u32 %v56957, 26 (stack45)
        %v56968 = vor.u32 %v56967, %v56966 (stack46)
        %v56969 = vxor.u32 %v56968, %v56960 (stack47)
        %v56972 = vadd.s32 %v56969, %v8 (stack39)
        %v56976 = vadd.s32 1, %v56972 (stack39)
        %v56980 = vadd.s32 %v56976, %v56964 (stack39)
        %v56982 = vshll.u32 %v56976, 17 (stack44)
        %v56983 = vshrl.u32 %v56976, 15 (stack45)
        %v56984 = vor.u32 %v56983, %v56982 (stack46)
        %v56985 = vxor.u32 %v56984, %v56980 (stack47)
        %v56988 = vadd.s32 %v56985, %v56980 (stack39)
        %v56990 = vshll.u32 %v56985, 29 (stack44)
        %v56991 = vshrl.u32 %v56985, 3 (stack45)
        %v56992 = vor.u32 %v56991, %v56990 (stack46)
        %v56993 = vxor.u32 %v56992, %v56988 (stack47)
        %v56996 = vadd.s32 %v56993, %v56988 (stack39)
        %v56998 = vshll.u32 %v56993, 16 (stack44)
        %v56999 = vshrl.u32 %v56993, 16 (stack45)
        %v57000 = vor.u32 %v56999, %v56998 (stack46)
        %v57001 = vxor.u32 %v57000, %v56996 (stack47)
        %v57004 = vadd.s32 %v57001, %v56996 (stack39)
        %v57008 = vadd.s32 %v57004, %v8 (stack39)
        %v57010 = vshll.u32 %v57001, 24 (stack44)
        %v57011 = vshrl.u32 %v57001, 8 (stack45)
        %v57012 = vor.u32 %v57011, %v57010 (stack46)
        %v57013 = vxor.u32 %v57012, %v57004 (stack47)
        %v57016 = vadd.s32 %v57013, %v10 (stack39)
        %v57020 = vadd.s32 2, %v57016 (stack39)
        %v57024 = vadd.s32 %v57020, %v57008 (stack39)
        %v57026 = vshll.u32 %v57020, 13 (stack44)
        %v57027 = vshrl.u32 %v57020, 19 (stack45)
        %v57028 = vor.u32 %v57027, %v57026 (stack46)
        %v57029 = vxor.u32 %v57028, %v57024 (stack47)
        %v57032 = vadd.s32 %v57029, %v57024 (stack39)
        %v57034 = vshll.u32 %v57029, 15 (stack44)
        %v57035 = vshrl.u32 %v57029, 17 (stack45)
        %v57036 = vor.u32 %v57035, %v57034 (stack46)
        %v57037 = vxor.u32 %v57036, %v57032 (stack47)
        %v57040 = vadd.s32 %v57037, %v57032 (stack39)
        %v57042 = vshll.u32 %v57037, 26 (stack44)
        %v57043 = vshrl.u32 %v57037, 6 (stack45)
        %v57044 = vor.u32 %v57043, %v57042 (stack46)
        %v57045 = vxor.u32 %v57044, %v57040 (stack47)
        %v57048 = vadd.s32 %v57045, %v57040 (stack39)
        %v57052 = vadd.s32 %v57048, %v10 (stack39)
        %v57054 = vshll.u32 %v57045, 6 (stack44)
        %v57055 = vshrl.u32 %v57045, 26 (stack45)
        %v57056 = vor.u32 %v57055, %v57054 (stack46)
        %v57057 = vxor.u32 %v57056, %v57048 (stack47)
        %v57060 = vadd.s32 %v57057, %v9 (stack39)
        %v57064 = vadd.s32 3, %v57060 (stack39)
        %v57068 = vadd.s32 %v57064, %v57052 (stack39)
        %v57070 = vshll.u32 %v57064, 17 (stack44)
        %v57071 = vshrl.u32 %v57064, 15 (stack45)
        %v57072 = vor.u32 %v57071, %v57070 (stack46)
        %v57073 = vxor.u32 %v57072, %v57068 (stack47)
        %v57076 = vadd.s32 %v57073, %v57068 (stack39)
        %v57078 = vshll.u32 %v57073, 29 (stack44)
        %v57079 = vshrl.u32 %v57073, 3 (stack45)
        %v57080 = vor.u32 %v57079, %v57078 (stack46)
        %v57081 = vxor.u32 %v57080, %v57076 (stack47)
        %v57084 = vadd.s32 %v57081, %v57076 (stack39)
        %v57086 = vshll.u32 %v57081, 16 (stack44)
        %v57087 = vshrl.u32 %v57081, 16 (stack45)
        %v57088 = vor.u32 %v57087, %v57086 (stack46)
        %v57089 = vxor.u32 %v57088, %v57084 (stack47)
        %v57092 = vadd.s32 %v57089, %v57084 (stack39)
        %v57096 = vadd.s32 %v57092, %v9 (stack39)
        %v57098 = vshll.u32 %v57089, 24 (stack44)
        %v57099 = vshrl.u32 %v57089, 8 (stack45)
        %v57100 = vor.u32 %v57099, %v57098 (stack46)
        %v57101 = vxor.u32 %v57100, %v57092 (stack47)
        %v57104 = vadd.s32 %v57101, %v8 (stack39)
        %v57108 = vadd.s32 4, %v57104 (stack39)
        %v57112 = vadd.s32 %v57108, %v57096 (stack39)
        %v57114 = vshll.u32 %v57108, 13 (stack44)
        %v57115 = vshrl.u32 %v57108, 19 (stack45)
        %v57116 = vor.u32 %v57115, %v57114 (stack46)
        %v57117 = vxor.u32 %v57116, %v57112 (stack47)
        %v57120 = vadd.s32 %v57117, %v57112 (stack39)
        %v57122 = vshll.u32 %v57117, 15 (stack44)
        %v57123 = vshrl.u32 %v57117, 17 (stack45)
        %v57124 = vor.u32 %v57123, %v57122 (stack46)
        %v57125 = vxor.u32 %v57124, %v57120 (stack47)
        %v57128 = vadd.s32 %v57125, %v57120 (stack39)
        %v57130 = vshll.u32 %v57125, 26 (stack44)
        %v57131 = vshrl.u32 %v57125, 6 (stack45)
        %v57132 = vor.u32 %v57131, %v57130 (stack46)
        %v57133 = vxor.u32 %v57132, %v57128 (stack47)
        %v57136 = vadd.s32 %v57133, %v57128 (stack39)
        %v57140 = vadd.s32 %v57136, %v8 (stack39)
        %v57142 = vshll.u32 %v57133, 6 (stack44)
        %v57143 = vshrl.u32 %v57133, 26 (stack45)
        %v57144 = vor.u32 %v57143, %v57142 (stack46)
        %v57145 = vxor.u32 %v57144, %v57136 (stack47)
        %v57148 = vadd.s32 %v57145, %v10 (stack39)
        %v57152 = vadd.s32 5, %v57148 (stack39)
        %v57154 = vxor.u32 %v57152, %v57140 (stack47)
        %v57155 = vand.u32.u8 255, %v57154 (stack48)
        %v57156 = vand.u32 65535, %v57155 (stack49)
        %v57157 = vshrl.u32 %v57156, 1 (stack50)
        %v57158 = vor.u32 16256, %v57157 (stack46)
        %v57159 = vand.u32.u16 65535, %v57158 (stack51)
        %v120050 = vadd.low.f32.bf16 -1.0, %v57159 (stack52)
        %v57168 = vmul.f32 2.0, %v120050 (stack53)
        %v57172 = vadd.f32 -0.99609375, %v57168 (stack52)
        %v57176 = vmax.f32 %v57172, -0.99609375 (stack54)
        %v57178 = vand.u32 2147483647, %v57176 (stack55)
        %vm57181 = vcmp.eq.f32.partialorder %v57178, 1.0 (stack56)
        %v57186 = vmul.f32 inf, %v57176 (stack53)
        %v57188 = vxor.u32 2147483648, %v57176 (stack57)
        %v57191 = vmul.f32 %v57188, %v57176 (stack53)
        %v57193 = vadd.f32 1.0, %v57191 (stack58)
        %v57194 = vlog2.pop %v57193 (stack59)
        %v57195 = vmul.f32 0.6931472, %v57194 (stack60)
        %v57196 = vmul.f32 -0.5, %v57191 (stack61)
        %v57197 = vadd.f32 1.0, %v57196 (stack62)
        %v57198 = vmul.f32 %v57197, %v57191 (stack63)
        %v57199 = vand.u32 2147483647, %v57191 (stack64)
        %vm57200 = vcmp.lt.f32.partialorder %v57199, 0.0004427343 (stack65)
        %v57201 = vsel /*vm=*/%vm57200, /*on_true_vy=*/%v57198, /*on_false_vx=*/%v57195 (stack66)
        %v57202 = vxor.u32 2147483648, %v57201 (stack57)
        %vm57205 = vcmp.lt.f32.partialorder %v57202, 5.0 (stack56)
        %v57210 = vsel /*vm=*/%vm57205, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v57214 = vsel /*vm=*/%vm57205, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v57218 = vsel /*vm=*/%vm57205, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v57222 = vsel /*vm=*/%vm57205, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v57226 = vsel /*vm=*/%vm57205, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v57230 = vsel /*vm=*/%vm57205, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v57234 = vsel /*vm=*/%vm57205, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v57238 = vsel /*vm=*/%vm57205, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v57242 = vsel /*vm=*/%vm57205, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v57246 = vadd.f32 -2.5, %v57202 (stack52)
        %v57248 = vrsqrt.pop %v57202 (stack67)
        %v57249 = vmul.f32 %v57248, %v57202 (stack68)
        %vm57250 = vcmp.eq.f32.partialorder %v57202, inf (stack69)
        %v57251 = vsel /*vm=*/%vm57250, /*on_true_vy=*/%v57202, /*on_false_vx=*/%v57249 (stack70)
        %vm57252 = vcmp.eq.f32.partialorder %v57202, 0.0 (stack71)
        %v57253 = vand.u32 2147483648, %v57202 (stack72)
        %v57254 = vsel /*vm=*/%vm57252, /*on_true_vy=*/%v57253, /*on_false_vx=*/%v57251 (stack73)
        %v57257 = vadd.f32 -3.0, %v57254 (stack52)
        %v57261 = vsel /*vm=*/%vm57205, /*on_true_vy=*/%v57246, /*on_false_vx=*/%v57257 (stack43)
        %v57265 = vmul.f32 %v57261, %v57242 (stack53)
        %v57269 = vadd.f32 %v57265, %v57238 (stack52)
        %v57273 = vmul.f32 %v57269, %v57261 (stack53)
        %v57277 = vadd.f32 %v57273, %v57234 (stack52)
        %v57281 = vmul.f32 %v57277, %v57261 (stack53)
        %v57285 = vadd.f32 %v57281, %v57230 (stack52)
        %v57289 = vmul.f32 %v57285, %v57261 (stack53)
        %v57293 = vadd.f32 %v57289, %v57226 (stack52)
        %v57297 = vmul.f32 %v57293, %v57261 (stack53)
        %v57301 = vadd.f32 %v57297, %v57222 (stack52)
        %v57305 = vmul.f32 %v57301, %v57261 (stack53)
        %v57309 = vadd.f32 %v57305, %v57218 (stack52)
        %v57313 = vmul.f32 %v57309, %v57261 (stack53)
        %v57317 = vadd.f32 %v57313, %v57214 (stack52)
        %v57321 = vmul.f32 %v57317, %v57261 (stack53)
        %v57325 = vadd.f32 %v57321, %v57210 (stack52)
        %v57329 = vmul.f32 %v57325, %v57176 (stack53)
        %v57333 = vsel /*vm=*/%vm57181, /*on_true_vy=*/%v57186, /*on_false_vx=*/%v57329 (stack43)
        %v57337 = vmul.f32 1.4140625, %v57333 (stack53)
        %v57340 = vpack.c.bf16 0.0, %v57337 (stack74)
        %120051 = vst [vmem:[%s280 + $0xbc] sm:$0xf] /*vst_source=*/%v57340 (stack75)
        %v57344 = vadd.s32 %v56419, %v1381 (stack39)
        %v57354 = vadd.s32 %v57344, %v415 (stack39)
        %vm57358 = vcmp.lt.u32.totalorder %v57354, %v57344 (stack42)
        %vm57363 = vcmp.lt.u32.totalorder %v57344, %v1381 (stack42)
        %v57368 = vadd.s32 %v56402, %v1368 (stack39)
        %v57372 = vadd.s32 1, %v57368 (stack39)
        %v57376 = vsel /*vm=*/%vm57363, /*on_true_vy=*/%v57372, /*on_false_vx=*/%v57368 (stack43)
        %v57380 = vadd.s32 1, %v57376 (stack39)
        %v57384 = vsel /*vm=*/%vm57358, /*on_true_vy=*/%v57380, /*on_false_vx=*/%v57376 (stack43)
        %v57389 = vadd.s32 %v57384, %v10 (stack39)
        %v57393 = vadd.s32 %v57354, %v9 (stack39)
        %v57397 = vadd.s32 %v57393, %v57389 (stack39)
        %v57399 = vshll.u32 %v57393, 13 (stack44)
        %v57400 = vshrl.u32 %v57393, 19 (stack45)
        %v57401 = vor.u32 %v57400, %v57399 (stack46)
        %v57402 = vxor.u32 %v57401, %v57397 (stack47)
        %v57405 = vadd.s32 %v57402, %v57397 (stack39)
        %v57407 = vshll.u32 %v57402, 15 (stack44)
        %v57408 = vshrl.u32 %v57402, 17 (stack45)
        %v57409 = vor.u32 %v57408, %v57407 (stack46)
        %v57410 = vxor.u32 %v57409, %v57405 (stack47)
        %v57413 = vadd.s32 %v57410, %v57405 (stack39)
        %v57415 = vshll.u32 %v57410, 26 (stack44)
        %v57416 = vshrl.u32 %v57410, 6 (stack45)
        %v57417 = vor.u32 %v57416, %v57415 (stack46)
        %v57418 = vxor.u32 %v57417, %v57413 (stack47)
        %v57421 = vadd.s32 %v57418, %v57413 (stack39)
        %v57425 = vadd.s32 %v57421, %v9 (stack39)
        %v57427 = vshll.u32 %v57418, 6 (stack44)
        %v57428 = vshrl.u32 %v57418, 26 (stack45)
        %v57429 = vor.u32 %v57428, %v57427 (stack46)
        %v57430 = vxor.u32 %v57429, %v57421 (stack47)
        %v57433 = vadd.s32 %v57430, %v8 (stack39)
        %v57437 = vadd.s32 1, %v57433 (stack39)
        %v57441 = vadd.s32 %v57437, %v57425 (stack39)
        %v57443 = vshll.u32 %v57437, 17 (stack44)
        %v57444 = vshrl.u32 %v57437, 15 (stack45)
        %v57445 = vor.u32 %v57444, %v57443 (stack46)
        %v57446 = vxor.u32 %v57445, %v57441 (stack47)
        %v57449 = vadd.s32 %v57446, %v57441 (stack39)
        %v57451 = vshll.u32 %v57446, 29 (stack44)
        %v57452 = vshrl.u32 %v57446, 3 (stack45)
        %v57453 = vor.u32 %v57452, %v57451 (stack46)
        %v57454 = vxor.u32 %v57453, %v57449 (stack47)
        %v57457 = vadd.s32 %v57454, %v57449 (stack39)
        %v57459 = vshll.u32 %v57454, 16 (stack44)
        %v57460 = vshrl.u32 %v57454, 16 (stack45)
        %v57461 = vor.u32 %v57460, %v57459 (stack46)
        %v57462 = vxor.u32 %v57461, %v57457 (stack47)
        %v57465 = vadd.s32 %v57462, %v57457 (stack39)
        %v57469 = vadd.s32 %v57465, %v8 (stack39)
        %v57471 = vshll.u32 %v57462, 24 (stack44)
        %v57472 = vshrl.u32 %v57462, 8 (stack45)
        %v57473 = vor.u32 %v57472, %v57471 (stack46)
        %v57474 = vxor.u32 %v57473, %v57465 (stack47)
        %v57477 = vadd.s32 %v57474, %v10 (stack39)
        %v57481 = vadd.s32 2, %v57477 (stack39)
        %v57485 = vadd.s32 %v57481, %v57469 (stack39)
        %v57487 = vshll.u32 %v57481, 13 (stack44)
        %v57488 = vshrl.u32 %v57481, 19 (stack45)
        %v57489 = vor.u32 %v57488, %v57487 (stack46)
        %v57490 = vxor.u32 %v57489, %v57485 (stack47)
        %v57493 = vadd.s32 %v57490, %v57485 (stack39)
        %v57495 = vshll.u32 %v57490, 15 (stack44)
        %v57496 = vshrl.u32 %v57490, 17 (stack45)
        %v57497 = vor.u32 %v57496, %v57495 (stack46)
        %v57498 = vxor.u32 %v57497, %v57493 (stack47)
        %v57501 = vadd.s32 %v57498, %v57493 (stack39)
        %v57503 = vshll.u32 %v57498, 26 (stack44)
        %v57504 = vshrl.u32 %v57498, 6 (stack45)
        %v57505 = vor.u32 %v57504, %v57503 (stack46)
        %v57506 = vxor.u32 %v57505, %v57501 (stack47)
        %v57509 = vadd.s32 %v57506, %v57501 (stack39)
        %v57513 = vadd.s32 %v57509, %v10 (stack39)
        %v57515 = vshll.u32 %v57506, 6 (stack44)
        %v57516 = vshrl.u32 %v57506, 26 (stack45)
        %v57517 = vor.u32 %v57516, %v57515 (stack46)
        %v57518 = vxor.u32 %v57517, %v57509 (stack47)
        %v57521 = vadd.s32 %v57518, %v9 (stack39)
        %v57525 = vadd.s32 3, %v57521 (stack39)
        %v57529 = vadd.s32 %v57525, %v57513 (stack39)
        %v57531 = vshll.u32 %v57525, 17 (stack44)
        %v57532 = vshrl.u32 %v57525, 15 (stack45)
        %v57533 = vor.u32 %v57532, %v57531 (stack46)
        %v57534 = vxor.u32 %v57533, %v57529 (stack47)
        %v57537 = vadd.s32 %v57534, %v57529 (stack39)
        %v57539 = vshll.u32 %v57534, 29 (stack44)
        %v57540 = vshrl.u32 %v57534, 3 (stack45)
        %v57541 = vor.u32 %v57540, %v57539 (stack46)
        %v57542 = vxor.u32 %v57541, %v57537 (stack47)
        %v57545 = vadd.s32 %v57542, %v57537 (stack39)
        %v57547 = vshll.u32 %v57542, 16 (stack44)
        %v57548 = vshrl.u32 %v57542, 16 (stack45)
        %v57549 = vor.u32 %v57548, %v57547 (stack46)
        %v57550 = vxor.u32 %v57549, %v57545 (stack47)
        %v57553 = vadd.s32 %v57550, %v57545 (stack39)
        %v57557 = vadd.s32 %v57553, %v9 (stack39)
        %v57559 = vshll.u32 %v57550, 24 (stack44)
        %v57560 = vshrl.u32 %v57550, 8 (stack45)
        %v57561 = vor.u32 %v57560, %v57559 (stack46)
        %v57562 = vxor.u32 %v57561, %v57553 (stack47)
        %v57565 = vadd.s32 %v57562, %v8 (stack39)
        %v57569 = vadd.s32 4, %v57565 (stack39)
        %v57573 = vadd.s32 %v57569, %v57557 (stack39)
        %v57575 = vshll.u32 %v57569, 13 (stack44)
        %v57576 = vshrl.u32 %v57569, 19 (stack45)
        %v57577 = vor.u32 %v57576, %v57575 (stack46)
        %v57578 = vxor.u32 %v57577, %v57573 (stack47)
        %v57581 = vadd.s32 %v57578, %v57573 (stack39)
        %v57583 = vshll.u32 %v57578, 15 (stack44)
        %v57584 = vshrl.u32 %v57578, 17 (stack45)
        %v57585 = vor.u32 %v57584, %v57583 (stack46)
        %v57586 = vxor.u32 %v57585, %v57581 (stack47)
        %v57589 = vadd.s32 %v57586, %v57581 (stack39)
        %v57591 = vshll.u32 %v57586, 26 (stack44)
        %v57592 = vshrl.u32 %v57586, 6 (stack45)
        %v57593 = vor.u32 %v57592, %v57591 (stack46)
        %v57594 = vxor.u32 %v57593, %v57589 (stack47)
        %v57597 = vadd.s32 %v57594, %v57589 (stack39)
        %v57601 = vadd.s32 %v57597, %v8 (stack39)
        %v57603 = vshll.u32 %v57594, 6 (stack44)
        %v57604 = vshrl.u32 %v57594, 26 (stack45)
        %v57605 = vor.u32 %v57604, %v57603 (stack46)
        %v57606 = vxor.u32 %v57605, %v57597 (stack47)
        %v57609 = vadd.s32 %v57606, %v10 (stack39)
        %v57613 = vadd.s32 5, %v57609 (stack39)
        %v57615 = vxor.u32 %v57613, %v57601 (stack47)
        %v57616 = vand.u32.u8 255, %v57615 (stack48)
        %v57617 = vand.u32 65535, %v57616 (stack49)
        %v57618 = vshrl.u32 %v57617, 1 (stack50)
        %v57619 = vor.u32 16256, %v57618 (stack46)
        %v57620 = vand.u32.u16 65535, %v57619 (stack51)
        %v120052 = vadd.low.f32.bf16 -1.0, %v57620 (stack52)
        %v57629 = vmul.f32 2.0, %v120052 (stack53)
        %v57633 = vadd.f32 -0.99609375, %v57629 (stack52)
        %v57637 = vmax.f32 %v57633, -0.99609375 (stack54)
        %v57639 = vand.u32 2147483647, %v57637 (stack55)
        %vm57642 = vcmp.eq.f32.partialorder %v57639, 1.0 (stack56)
        %v57647 = vmul.f32 inf, %v57637 (stack53)
        %v57649 = vxor.u32 2147483648, %v57637 (stack57)
        %v57652 = vmul.f32 %v57649, %v57637 (stack53)
        %v57654 = vadd.f32 1.0, %v57652 (stack58)
        %v57655 = vlog2.pop %v57654 (stack59)
        %v57656 = vmul.f32 0.6931472, %v57655 (stack60)
        %v57657 = vmul.f32 -0.5, %v57652 (stack61)
        %v57658 = vadd.f32 1.0, %v57657 (stack62)
        %v57659 = vmul.f32 %v57658, %v57652 (stack63)
        %v57660 = vand.u32 2147483647, %v57652 (stack64)
        %vm57661 = vcmp.lt.f32.partialorder %v57660, 0.0004427343 (stack65)
        %v57662 = vsel /*vm=*/%vm57661, /*on_true_vy=*/%v57659, /*on_false_vx=*/%v57656 (stack66)
        %v57663 = vxor.u32 2147483648, %v57662 (stack57)
        %vm57666 = vcmp.lt.f32.partialorder %v57663, 5.0 (stack56)
        %v57671 = vsel /*vm=*/%vm57666, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v57675 = vsel /*vm=*/%vm57666, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v57679 = vsel /*vm=*/%vm57666, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v57683 = vsel /*vm=*/%vm57666, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v57687 = vsel /*vm=*/%vm57666, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v57691 = vsel /*vm=*/%vm57666, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v57695 = vsel /*vm=*/%vm57666, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v57699 = vsel /*vm=*/%vm57666, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v57703 = vsel /*vm=*/%vm57666, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v57707 = vadd.f32 -2.5, %v57663 (stack52)
        %v57709 = vrsqrt.pop %v57663 (stack67)
        %v57710 = vmul.f32 %v57709, %v57663 (stack68)
        %vm57711 = vcmp.eq.f32.partialorder %v57663, inf (stack69)
        %v57712 = vsel /*vm=*/%vm57711, /*on_true_vy=*/%v57663, /*on_false_vx=*/%v57710 (stack70)
        %vm57713 = vcmp.eq.f32.partialorder %v57663, 0.0 (stack71)
        %v57714 = vand.u32 2147483648, %v57663 (stack72)
        %v57715 = vsel /*vm=*/%vm57713, /*on_true_vy=*/%v57714, /*on_false_vx=*/%v57712 (stack73)
        %v57718 = vadd.f32 -3.0, %v57715 (stack52)
        %v57722 = vsel /*vm=*/%vm57666, /*on_true_vy=*/%v57707, /*on_false_vx=*/%v57718 (stack43)
        %v57726 = vmul.f32 %v57722, %v57703 (stack53)
        %v57730 = vadd.f32 %v57726, %v57699 (stack52)
        %v57734 = vmul.f32 %v57730, %v57722 (stack53)
        %v57738 = vadd.f32 %v57734, %v57695 (stack52)
        %v57742 = vmul.f32 %v57738, %v57722 (stack53)
        %v57746 = vadd.f32 %v57742, %v57691 (stack52)
        %v57750 = vmul.f32 %v57746, %v57722 (stack53)
        %v57754 = vadd.f32 %v57750, %v57687 (stack52)
        %v57758 = vmul.f32 %v57754, %v57722 (stack53)
        %v57762 = vadd.f32 %v57758, %v57683 (stack52)
        %v57766 = vmul.f32 %v57762, %v57722 (stack53)
        %v57770 = vadd.f32 %v57766, %v57679 (stack52)
        %v57774 = vmul.f32 %v57770, %v57722 (stack53)
        %v57778 = vadd.f32 %v57774, %v57675 (stack52)
        %v57782 = vmul.f32 %v57778, %v57722 (stack53)
        %v57786 = vadd.f32 %v57782, %v57671 (stack52)
        %v57790 = vmul.f32 %v57786, %v57637 (stack53)
        %v57794 = vsel /*vm=*/%vm57642, /*on_true_vy=*/%v57647, /*on_false_vx=*/%v57790 (stack43)
        %v57798 = vmul.f32 1.4140625, %v57794 (stack53)
        %v57801 = vpack.c.bf16 0.0, %v57798 (stack74)
        %120053 = vst [vmem:[%s280 + $0x13c] sm:$0xf] /*vst_source=*/%v57801 (stack75)
        %v57805 = vadd.s32 %v56419, %v1868 (stack39)
        %v57815 = vadd.s32 %v57805, %v415 (stack39)
        %vm57819 = vcmp.lt.u32.totalorder %v57815, %v57805 (stack42)
        %vm57824 = vcmp.lt.u32.totalorder %v57805, %v1868 (stack42)
        %v57829 = vadd.s32 %v56402, %v1855 (stack39)
        %v57833 = vadd.s32 1, %v57829 (stack39)
        %v57837 = vsel /*vm=*/%vm57824, /*on_true_vy=*/%v57833, /*on_false_vx=*/%v57829 (stack43)
        %v57841 = vadd.s32 1, %v57837 (stack39)
        %v57845 = vsel /*vm=*/%vm57819, /*on_true_vy=*/%v57841, /*on_false_vx=*/%v57837 (stack43)
        %v57850 = vadd.s32 %v57845, %v10 (stack39)
        %v57854 = vadd.s32 %v57815, %v9 (stack39)
        %v57858 = vadd.s32 %v57854, %v57850 (stack39)
        %v57860 = vshll.u32 %v57854, 13 (stack44)
        %v57861 = vshrl.u32 %v57854, 19 (stack45)
        %v57862 = vor.u32 %v57861, %v57860 (stack46)
        %v57863 = vxor.u32 %v57862, %v57858 (stack47)
        %v57866 = vadd.s32 %v57863, %v57858 (stack39)
        %v57868 = vshll.u32 %v57863, 15 (stack44)
        %v57869 = vshrl.u32 %v57863, 17 (stack45)
        %v57870 = vor.u32 %v57869, %v57868 (stack46)
        %v57871 = vxor.u32 %v57870, %v57866 (stack47)
        %v57874 = vadd.s32 %v57871, %v57866 (stack39)
        %v57876 = vshll.u32 %v57871, 26 (stack44)
        %v57877 = vshrl.u32 %v57871, 6 (stack45)
        %v57878 = vor.u32 %v57877, %v57876 (stack46)
        %v57879 = vxor.u32 %v57878, %v57874 (stack47)
        %v57882 = vadd.s32 %v57879, %v57874 (stack39)
        %v57886 = vadd.s32 %v57882, %v9 (stack39)
        %v57888 = vshll.u32 %v57879, 6 (stack44)
        %v57889 = vshrl.u32 %v57879, 26 (stack45)
        %v57890 = vor.u32 %v57889, %v57888 (stack46)
        %v57891 = vxor.u32 %v57890, %v57882 (stack47)
        %v57894 = vadd.s32 %v57891, %v8 (stack39)
        %v57898 = vadd.s32 1, %v57894 (stack39)
        %v57902 = vadd.s32 %v57898, %v57886 (stack39)
        %v57904 = vshll.u32 %v57898, 17 (stack44)
        %v57905 = vshrl.u32 %v57898, 15 (stack45)
        %v57906 = vor.u32 %v57905, %v57904 (stack46)
        %v57907 = vxor.u32 %v57906, %v57902 (stack47)
        %v57910 = vadd.s32 %v57907, %v57902 (stack39)
        %v57912 = vshll.u32 %v57907, 29 (stack44)
        %v57913 = vshrl.u32 %v57907, 3 (stack45)
        %v57914 = vor.u32 %v57913, %v57912 (stack46)
        %v57915 = vxor.u32 %v57914, %v57910 (stack47)
        %v57918 = vadd.s32 %v57915, %v57910 (stack39)
        %v57920 = vshll.u32 %v57915, 16 (stack44)
        %v57921 = vshrl.u32 %v57915, 16 (stack45)
        %v57922 = vor.u32 %v57921, %v57920 (stack46)
        %v57923 = vxor.u32 %v57922, %v57918 (stack47)
        %v57926 = vadd.s32 %v57923, %v57918 (stack39)
        %v57930 = vadd.s32 %v57926, %v8 (stack39)
        %v57932 = vshll.u32 %v57923, 24 (stack44)
        %v57933 = vshrl.u32 %v57923, 8 (stack45)
        %v57934 = vor.u32 %v57933, %v57932 (stack46)
        %v57935 = vxor.u32 %v57934, %v57926 (stack47)
        %v57938 = vadd.s32 %v57935, %v10 (stack39)
        %v57942 = vadd.s32 2, %v57938 (stack39)
        %v57946 = vadd.s32 %v57942, %v57930 (stack39)
        %v57948 = vshll.u32 %v57942, 13 (stack44)
        %v57949 = vshrl.u32 %v57942, 19 (stack45)
        %v57950 = vor.u32 %v57949, %v57948 (stack46)
        %v57951 = vxor.u32 %v57950, %v57946 (stack47)
        %v57954 = vadd.s32 %v57951, %v57946 (stack39)
        %v57956 = vshll.u32 %v57951, 15 (stack44)
        %v57957 = vshrl.u32 %v57951, 17 (stack45)
        %v57958 = vor.u32 %v57957, %v57956 (stack46)
        %v57959 = vxor.u32 %v57958, %v57954 (stack47)
        %v57962 = vadd.s32 %v57959, %v57954 (stack39)
        %v57964 = vshll.u32 %v57959, 26 (stack44)
        %v57965 = vshrl.u32 %v57959, 6 (stack45)
        %v57966 = vor.u32 %v57965, %v57964 (stack46)
        %v57967 = vxor.u32 %v57966, %v57962 (stack47)
        %v57970 = vadd.s32 %v57967, %v57962 (stack39)
        %v57974 = vadd.s32 %v57970, %v10 (stack39)
        %v57976 = vshll.u32 %v57967, 6 (stack44)
        %v57977 = vshrl.u32 %v57967, 26 (stack45)
        %v57978 = vor.u32 %v57977, %v57976 (stack46)
        %v57979 = vxor.u32 %v57978, %v57970 (stack47)
        %v57982 = vadd.s32 %v57979, %v9 (stack39)
        %v57986 = vadd.s32 3, %v57982 (stack39)
        %v57990 = vadd.s32 %v57986, %v57974 (stack39)
        %v57992 = vshll.u32 %v57986, 17 (stack44)
        %v57993 = vshrl.u32 %v57986, 15 (stack45)
        %v57994 = vor.u32 %v57993, %v57992 (stack46)
        %v57995 = vxor.u32 %v57994, %v57990 (stack47)
        %v57998 = vadd.s32 %v57995, %v57990 (stack39)
        %v58000 = vshll.u32 %v57995, 29 (stack44)
        %v58001 = vshrl.u32 %v57995, 3 (stack45)
        %v58002 = vor.u32 %v58001, %v58000 (stack46)
        %v58003 = vxor.u32 %v58002, %v57998 (stack47)
        %v58006 = vadd.s32 %v58003, %v57998 (stack39)
        %v58008 = vshll.u32 %v58003, 16 (stack44)
        %v58009 = vshrl.u32 %v58003, 16 (stack45)
        %v58010 = vor.u32 %v58009, %v58008 (stack46)
        %v58011 = vxor.u32 %v58010, %v58006 (stack47)
        %v58014 = vadd.s32 %v58011, %v58006 (stack39)
        %v58018 = vadd.s32 %v58014, %v9 (stack39)
        %v58020 = vshll.u32 %v58011, 24 (stack44)
        %v58021 = vshrl.u32 %v58011, 8 (stack45)
        %v58022 = vor.u32 %v58021, %v58020 (stack46)
        %v58023 = vxor.u32 %v58022, %v58014 (stack47)
        %v58026 = vadd.s32 %v58023, %v8 (stack39)
        %v58030 = vadd.s32 4, %v58026 (stack39)
        %v58034 = vadd.s32 %v58030, %v58018 (stack39)
        %v58036 = vshll.u32 %v58030, 13 (stack44)
        %v58037 = vshrl.u32 %v58030, 19 (stack45)
        %v58038 = vor.u32 %v58037, %v58036 (stack46)
        %v58039 = vxor.u32 %v58038, %v58034 (stack47)
        %v58042 = vadd.s32 %v58039, %v58034 (stack39)
        %v58044 = vshll.u32 %v58039, 15 (stack44)
        %v58045 = vshrl.u32 %v58039, 17 (stack45)
        %v58046 = vor.u32 %v58045, %v58044 (stack46)
        %v58047 = vxor.u32 %v58046, %v58042 (stack47)
        %v58050 = vadd.s32 %v58047, %v58042 (stack39)
        %v58052 = vshll.u32 %v58047, 26 (stack44)
        %v58053 = vshrl.u32 %v58047, 6 (stack45)
        %v58054 = vor.u32 %v58053, %v58052 (stack46)
        %v58055 = vxor.u32 %v58054, %v58050 (stack47)
        %v58058 = vadd.s32 %v58055, %v58050 (stack39)
        %v58062 = vadd.s32 %v58058, %v8 (stack39)
        %v58064 = vshll.u32 %v58055, 6 (stack44)
        %v58065 = vshrl.u32 %v58055, 26 (stack45)
        %v58066 = vor.u32 %v58065, %v58064 (stack46)
        %v58067 = vxor.u32 %v58066, %v58058 (stack47)
        %v58070 = vadd.s32 %v58067, %v10 (stack39)
        %v58074 = vadd.s32 5, %v58070 (stack39)
        %v58076 = vxor.u32 %v58074, %v58062 (stack47)
        %v58077 = vand.u32.u8 255, %v58076 (stack48)
        %v58078 = vand.u32 65535, %v58077 (stack49)
        %v58079 = vshrl.u32 %v58078, 1 (stack50)
        %v58080 = vor.u32 16256, %v58079 (stack46)
        %v58081 = vand.u32.u16 65535, %v58080 (stack51)
        %v120054 = vadd.low.f32.bf16 -1.0, %v58081 (stack52)
        %v58090 = vmul.f32 2.0, %v120054 (stack53)
        %v58094 = vadd.f32 -0.99609375, %v58090 (stack52)
        %v58098 = vmax.f32 %v58094, -0.99609375 (stack54)
        %v58100 = vand.u32 2147483647, %v58098 (stack55)
        %vm58103 = vcmp.eq.f32.partialorder %v58100, 1.0 (stack56)
        %v58108 = vmul.f32 inf, %v58098 (stack53)
        %v58110 = vxor.u32 2147483648, %v58098 (stack57)
        %v58113 = vmul.f32 %v58110, %v58098 (stack53)
        %v58115 = vadd.f32 1.0, %v58113 (stack58)
        %v58116 = vlog2.pop %v58115 (stack59)
        %v58117 = vmul.f32 0.6931472, %v58116 (stack60)
        %v58118 = vmul.f32 -0.5, %v58113 (stack61)
        %v58119 = vadd.f32 1.0, %v58118 (stack62)
        %v58120 = vmul.f32 %v58119, %v58113 (stack63)
        %v58121 = vand.u32 2147483647, %v58113 (stack64)
        %vm58122 = vcmp.lt.f32.partialorder %v58121, 0.0004427343 (stack65)
        %v58123 = vsel /*vm=*/%vm58122, /*on_true_vy=*/%v58120, /*on_false_vx=*/%v58117 (stack66)
        %v58124 = vxor.u32 2147483648, %v58123 (stack57)
        %vm58127 = vcmp.lt.f32.partialorder %v58124, 5.0 (stack56)
        %v58132 = vsel /*vm=*/%vm58127, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v58136 = vsel /*vm=*/%vm58127, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v58140 = vsel /*vm=*/%vm58127, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v58144 = vsel /*vm=*/%vm58127, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v58148 = vsel /*vm=*/%vm58127, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v58152 = vsel /*vm=*/%vm58127, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v58156 = vsel /*vm=*/%vm58127, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v58160 = vsel /*vm=*/%vm58127, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v58164 = vsel /*vm=*/%vm58127, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v58168 = vadd.f32 -2.5, %v58124 (stack52)
        %v58170 = vrsqrt.pop %v58124 (stack67)
        %v58171 = vmul.f32 %v58170, %v58124 (stack68)
        %vm58172 = vcmp.eq.f32.partialorder %v58124, inf (stack69)
        %v58173 = vsel /*vm=*/%vm58172, /*on_true_vy=*/%v58124, /*on_false_vx=*/%v58171 (stack70)
        %vm58174 = vcmp.eq.f32.partialorder %v58124, 0.0 (stack71)
        %v58175 = vand.u32 2147483648, %v58124 (stack72)
        %v58176 = vsel /*vm=*/%vm58174, /*on_true_vy=*/%v58175, /*on_false_vx=*/%v58173 (stack73)
        %v58179 = vadd.f32 -3.0, %v58176 (stack52)
        %v58183 = vsel /*vm=*/%vm58127, /*on_true_vy=*/%v58168, /*on_false_vx=*/%v58179 (stack43)
        %v58187 = vmul.f32 %v58183, %v58164 (stack53)
        %v58191 = vadd.f32 %v58187, %v58160 (stack52)
        %v58195 = vmul.f32 %v58191, %v58183 (stack53)
        %v58199 = vadd.f32 %v58195, %v58156 (stack52)
        %v58203 = vmul.f32 %v58199, %v58183 (stack53)
        %v58207 = vadd.f32 %v58203, %v58152 (stack52)
        %v58211 = vmul.f32 %v58207, %v58183 (stack53)
        %v58215 = vadd.f32 %v58211, %v58148 (stack52)
        %v58219 = vmul.f32 %v58215, %v58183 (stack53)
        %v58223 = vadd.f32 %v58219, %v58144 (stack52)
        %v58227 = vmul.f32 %v58223, %v58183 (stack53)
        %v58231 = vadd.f32 %v58227, %v58140 (stack52)
        %v58235 = vmul.f32 %v58231, %v58183 (stack53)
        %v58239 = vadd.f32 %v58235, %v58136 (stack52)
        %v58243 = vmul.f32 %v58239, %v58183 (stack53)
        %v58247 = vadd.f32 %v58243, %v58132 (stack52)
        %v58251 = vmul.f32 %v58247, %v58098 (stack53)
        %v58255 = vsel /*vm=*/%vm58103, /*on_true_vy=*/%v58108, /*on_false_vx=*/%v58251 (stack43)
        %v58259 = vmul.f32 1.4140625, %v58255 (stack53)
        %v58262 = vpack.c.bf16 0.0, %v58259 (stack74)
        %120055 = vst [vmem:[%s280 + $0x1bc] sm:$0xf] /*vst_source=*/%v58262 (stack75)
        %v58266 = vadd.s32 %v56419, %v2355 (stack39)
        %v58276 = vadd.s32 %v58266, %v415 (stack39)
        %vm58280 = vcmp.lt.u32.totalorder %v58276, %v58266 (stack42)
        %vm58285 = vcmp.lt.u32.totalorder %v58266, %v2355 (stack42)
        %v58290 = vadd.s32 %v56402, %v2342 (stack39)
        %v58294 = vadd.s32 1, %v58290 (stack39)
        %v58298 = vsel /*vm=*/%vm58285, /*on_true_vy=*/%v58294, /*on_false_vx=*/%v58290 (stack43)
        %v58302 = vadd.s32 1, %v58298 (stack39)
        %v58306 = vsel /*vm=*/%vm58280, /*on_true_vy=*/%v58302, /*on_false_vx=*/%v58298 (stack43)
        %v58311 = vadd.s32 %v58306, %v10 (stack39)
        %v58315 = vadd.s32 %v58276, %v9 (stack39)
        %v58319 = vadd.s32 %v58315, %v58311 (stack39)
        %v58321 = vshll.u32 %v58315, 13 (stack44)
        %v58322 = vshrl.u32 %v58315, 19 (stack45)
        %v58323 = vor.u32 %v58322, %v58321 (stack46)
        %v58324 = vxor.u32 %v58323, %v58319 (stack47)
        %v58327 = vadd.s32 %v58324, %v58319 (stack39)
        %v58329 = vshll.u32 %v58324, 15 (stack44)
        %v58330 = vshrl.u32 %v58324, 17 (stack45)
        %v58331 = vor.u32 %v58330, %v58329 (stack46)
        %v58332 = vxor.u32 %v58331, %v58327 (stack47)
        %v58335 = vadd.s32 %v58332, %v58327 (stack39)
        %v58337 = vshll.u32 %v58332, 26 (stack44)
        %v58338 = vshrl.u32 %v58332, 6 (stack45)
        %v58339 = vor.u32 %v58338, %v58337 (stack46)
        %v58340 = vxor.u32 %v58339, %v58335 (stack47)
        %v58343 = vadd.s32 %v58340, %v58335 (stack39)
        %v58347 = vadd.s32 %v58343, %v9 (stack39)
        %v58349 = vshll.u32 %v58340, 6 (stack44)
        %v58350 = vshrl.u32 %v58340, 26 (stack45)
        %v58351 = vor.u32 %v58350, %v58349 (stack46)
        %v58352 = vxor.u32 %v58351, %v58343 (stack47)
        %v58355 = vadd.s32 %v58352, %v8 (stack39)
        %v58359 = vadd.s32 1, %v58355 (stack39)
        %v58363 = vadd.s32 %v58359, %v58347 (stack39)
        %v58365 = vshll.u32 %v58359, 17 (stack44)
        %v58366 = vshrl.u32 %v58359, 15 (stack45)
        %v58367 = vor.u32 %v58366, %v58365 (stack46)
        %v58368 = vxor.u32 %v58367, %v58363 (stack47)
        %v58371 = vadd.s32 %v58368, %v58363 (stack39)
        %v58373 = vshll.u32 %v58368, 29 (stack44)
        %v58374 = vshrl.u32 %v58368, 3 (stack45)
        %v58375 = vor.u32 %v58374, %v58373 (stack46)
        %v58376 = vxor.u32 %v58375, %v58371 (stack47)
        %v58379 = vadd.s32 %v58376, %v58371 (stack39)
        %v58381 = vshll.u32 %v58376, 16 (stack44)
        %v58382 = vshrl.u32 %v58376, 16 (stack45)
        %v58383 = vor.u32 %v58382, %v58381 (stack46)
        %v58384 = vxor.u32 %v58383, %v58379 (stack47)
        %v58387 = vadd.s32 %v58384, %v58379 (stack39)
        %v58391 = vadd.s32 %v58387, %v8 (stack39)
        %v58393 = vshll.u32 %v58384, 24 (stack44)
        %v58394 = vshrl.u32 %v58384, 8 (stack45)
        %v58395 = vor.u32 %v58394, %v58393 (stack46)
        %v58396 = vxor.u32 %v58395, %v58387 (stack47)
        %v58399 = vadd.s32 %v58396, %v10 (stack39)
        %v58403 = vadd.s32 2, %v58399 (stack39)
        %v58407 = vadd.s32 %v58403, %v58391 (stack39)
        %v58409 = vshll.u32 %v58403, 13 (stack44)
        %v58410 = vshrl.u32 %v58403, 19 (stack45)
        %v58411 = vor.u32 %v58410, %v58409 (stack46)
        %v58412 = vxor.u32 %v58411, %v58407 (stack47)
        %v58415 = vadd.s32 %v58412, %v58407 (stack39)
        %v58417 = vshll.u32 %v58412, 15 (stack44)
        %v58418 = vshrl.u32 %v58412, 17 (stack45)
        %v58419 = vor.u32 %v58418, %v58417 (stack46)
        %v58420 = vxor.u32 %v58419, %v58415 (stack47)
        %v58423 = vadd.s32 %v58420, %v58415 (stack39)
        %v58425 = vshll.u32 %v58420, 26 (stack44)
        %v58426 = vshrl.u32 %v58420, 6 (stack45)
        %v58427 = vor.u32 %v58426, %v58425 (stack46)
        %v58428 = vxor.u32 %v58427, %v58423 (stack47)
        %v58431 = vadd.s32 %v58428, %v58423 (stack39)
        %v58435 = vadd.s32 %v58431, %v10 (stack39)
        %v58437 = vshll.u32 %v58428, 6 (stack44)
        %v58438 = vshrl.u32 %v58428, 26 (stack45)
        %v58439 = vor.u32 %v58438, %v58437 (stack46)
        %v58440 = vxor.u32 %v58439, %v58431 (stack47)
        %v58443 = vadd.s32 %v58440, %v9 (stack39)
        %v58447 = vadd.s32 3, %v58443 (stack39)
        %v58451 = vadd.s32 %v58447, %v58435 (stack39)
        %v58453 = vshll.u32 %v58447, 17 (stack44)
        %v58454 = vshrl.u32 %v58447, 15 (stack45)
        %v58455 = vor.u32 %v58454, %v58453 (stack46)
        %v58456 = vxor.u32 %v58455, %v58451 (stack47)
        %v58459 = vadd.s32 %v58456, %v58451 (stack39)
        %v58461 = vshll.u32 %v58456, 29 (stack44)
        %v58462 = vshrl.u32 %v58456, 3 (stack45)
        %v58463 = vor.u32 %v58462, %v58461 (stack46)
        %v58464 = vxor.u32 %v58463, %v58459 (stack47)
        %v58467 = vadd.s32 %v58464, %v58459 (stack39)
        %v58469 = vshll.u32 %v58464, 16 (stack44)
        %v58470 = vshrl.u32 %v58464, 16 (stack45)
        %v58471 = vor.u32 %v58470, %v58469 (stack46)
        %v58472 = vxor.u32 %v58471, %v58467 (stack47)
        %v58475 = vadd.s32 %v58472, %v58467 (stack39)
        %v58479 = vadd.s32 %v58475, %v9 (stack39)
        %v58481 = vshll.u32 %v58472, 24 (stack44)
        %v58482 = vshrl.u32 %v58472, 8 (stack45)
        %v58483 = vor.u32 %v58482, %v58481 (stack46)
        %v58484 = vxor.u32 %v58483, %v58475 (stack47)
        %v58487 = vadd.s32 %v58484, %v8 (stack39)
        %v58491 = vadd.s32 4, %v58487 (stack39)
        %v58495 = vadd.s32 %v58491, %v58479 (stack39)
        %v58497 = vshll.u32 %v58491, 13 (stack44)
        %v58498 = vshrl.u32 %v58491, 19 (stack45)
        %v58499 = vor.u32 %v58498, %v58497 (stack46)
        %v58500 = vxor.u32 %v58499, %v58495 (stack47)
        %v58503 = vadd.s32 %v58500, %v58495 (stack39)
        %v58505 = vshll.u32 %v58500, 15 (stack44)
        %v58506 = vshrl.u32 %v58500, 17 (stack45)
        %v58507 = vor.u32 %v58506, %v58505 (stack46)
        %v58508 = vxor.u32 %v58507, %v58503 (stack47)
        %v58511 = vadd.s32 %v58508, %v58503 (stack39)
        %v58513 = vshll.u32 %v58508, 26 (stack44)
        %v58514 = vshrl.u32 %v58508, 6 (stack45)
        %v58515 = vor.u32 %v58514, %v58513 (stack46)
        %v58516 = vxor.u32 %v58515, %v58511 (stack47)
        %v58519 = vadd.s32 %v58516, %v58511 (stack39)
        %v58523 = vadd.s32 %v58519, %v8 (stack39)
        %v58525 = vshll.u32 %v58516, 6 (stack44)
        %v58526 = vshrl.u32 %v58516, 26 (stack45)
        %v58527 = vor.u32 %v58526, %v58525 (stack46)
        %v58528 = vxor.u32 %v58527, %v58519 (stack47)
        %v58531 = vadd.s32 %v58528, %v10 (stack39)
        %v58535 = vadd.s32 5, %v58531 (stack39)
        %v58537 = vxor.u32 %v58535, %v58523 (stack47)
        %v58538 = vand.u32.u8 255, %v58537 (stack48)
        %v58539 = vand.u32 65535, %v58538 (stack49)
        %v58540 = vshrl.u32 %v58539, 1 (stack50)
        %v58541 = vor.u32 16256, %v58540 (stack46)
        %v58542 = vand.u32.u16 65535, %v58541 (stack51)
        %v120056 = vadd.low.f32.bf16 -1.0, %v58542 (stack52)
        %v58551 = vmul.f32 2.0, %v120056 (stack53)
        %v58555 = vadd.f32 -0.99609375, %v58551 (stack52)
        %v58559 = vmax.f32 %v58555, -0.99609375 (stack54)
        %v58561 = vand.u32 2147483647, %v58559 (stack55)
        %vm58564 = vcmp.eq.f32.partialorder %v58561, 1.0 (stack56)
        %v58569 = vmul.f32 inf, %v58559 (stack53)
        %v58571 = vxor.u32 2147483648, %v58559 (stack57)
        %v58574 = vmul.f32 %v58571, %v58559 (stack53)
        %v58576 = vadd.f32 1.0, %v58574 (stack58)
        %v58577 = vlog2.pop %v58576 (stack59)
        %v58578 = vmul.f32 0.6931472, %v58577 (stack60)
        %v58579 = vmul.f32 -0.5, %v58574 (stack61)
        %v58580 = vadd.f32 1.0, %v58579 (stack62)
        %v58581 = vmul.f32 %v58580, %v58574 (stack63)
        %v58582 = vand.u32 2147483647, %v58574 (stack64)
        %vm58583 = vcmp.lt.f32.partialorder %v58582, 0.0004427343 (stack65)
        %v58584 = vsel /*vm=*/%vm58583, /*on_true_vy=*/%v58581, /*on_false_vx=*/%v58578 (stack66)
        %v58585 = vxor.u32 2147483648, %v58584 (stack57)
        %vm58588 = vcmp.lt.f32.partialorder %v58585, 5.0 (stack56)
        %v58593 = vsel /*vm=*/%vm58588, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v58597 = vsel /*vm=*/%vm58588, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v58601 = vsel /*vm=*/%vm58588, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v58605 = vsel /*vm=*/%vm58588, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v58609 = vsel /*vm=*/%vm58588, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v58613 = vsel /*vm=*/%vm58588, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v58617 = vsel /*vm=*/%vm58588, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v58621 = vsel /*vm=*/%vm58588, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v58625 = vsel /*vm=*/%vm58588, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v58629 = vadd.f32 -2.5, %v58585 (stack52)
        %v58631 = vrsqrt.pop %v58585 (stack67)
        %v58632 = vmul.f32 %v58631, %v58585 (stack68)
        %vm58633 = vcmp.eq.f32.partialorder %v58585, inf (stack69)
        %v58634 = vsel /*vm=*/%vm58633, /*on_true_vy=*/%v58585, /*on_false_vx=*/%v58632 (stack70)
        %vm58635 = vcmp.eq.f32.partialorder %v58585, 0.0 (stack71)
        %v58636 = vand.u32 2147483648, %v58585 (stack72)
        %v58637 = vsel /*vm=*/%vm58635, /*on_true_vy=*/%v58636, /*on_false_vx=*/%v58634 (stack73)
        %v58640 = vadd.f32 -3.0, %v58637 (stack52)
        %v58644 = vsel /*vm=*/%vm58588, /*on_true_vy=*/%v58629, /*on_false_vx=*/%v58640 (stack43)
        %v58648 = vmul.f32 %v58644, %v58625 (stack53)
        %v58652 = vadd.f32 %v58648, %v58621 (stack52)
        %v58656 = vmul.f32 %v58652, %v58644 (stack53)
        %v58660 = vadd.f32 %v58656, %v58617 (stack52)
        %v58664 = vmul.f32 %v58660, %v58644 (stack53)
        %v58668 = vadd.f32 %v58664, %v58613 (stack52)
        %v58672 = vmul.f32 %v58668, %v58644 (stack53)
        %v58676 = vadd.f32 %v58672, %v58609 (stack52)
        %v58680 = vmul.f32 %v58676, %v58644 (stack53)
        %v58684 = vadd.f32 %v58680, %v58605 (stack52)
        %v58688 = vmul.f32 %v58684, %v58644 (stack53)
        %v58692 = vadd.f32 %v58688, %v58601 (stack52)
        %v58696 = vmul.f32 %v58692, %v58644 (stack53)
        %v58700 = vadd.f32 %v58696, %v58597 (stack52)
        %v58704 = vmul.f32 %v58700, %v58644 (stack53)
        %v58708 = vadd.f32 %v58704, %v58593 (stack52)
        %v58712 = vmul.f32 %v58708, %v58559 (stack53)
        %v58716 = vsel /*vm=*/%vm58564, /*on_true_vy=*/%v58569, /*on_false_vx=*/%v58712 (stack43)
        %v58720 = vmul.f32 1.4140625, %v58716 (stack53)
        %v58723 = vpack.c.bf16 0.0, %v58720 (stack74)
        %120057 = vst [vmem:[%s280 + $0x23c] sm:$0xf] /*vst_source=*/%v58723 (stack75)
        %v58727 = vadd.s32 %v56419, %v2842 (stack39)
        %v58737 = vadd.s32 %v58727, %v415 (stack39)
        %vm58741 = vcmp.lt.u32.totalorder %v58737, %v58727 (stack42)
        %vm58746 = vcmp.lt.u32.totalorder %v58727, %v2842 (stack42)
        %v58751 = vadd.s32 %v56402, %v2829 (stack39)
        %v58755 = vadd.s32 1, %v58751 (stack39)
        %v58759 = vsel /*vm=*/%vm58746, /*on_true_vy=*/%v58755, /*on_false_vx=*/%v58751 (stack43)
        %v58763 = vadd.s32 1, %v58759 (stack39)
        %v58767 = vsel /*vm=*/%vm58741, /*on_true_vy=*/%v58763, /*on_false_vx=*/%v58759 (stack43)
        %v58772 = vadd.s32 %v58767, %v10 (stack39)
        %v58776 = vadd.s32 %v58737, %v9 (stack39)
        %v58780 = vadd.s32 %v58776, %v58772 (stack39)
        %v58782 = vshll.u32 %v58776, 13 (stack44)
        %v58783 = vshrl.u32 %v58776, 19 (stack45)
        %v58784 = vor.u32 %v58783, %v58782 (stack46)
        %v58785 = vxor.u32 %v58784, %v58780 (stack47)
        %v58788 = vadd.s32 %v58785, %v58780 (stack39)
        %v58790 = vshll.u32 %v58785, 15 (stack44)
        %v58791 = vshrl.u32 %v58785, 17 (stack45)
        %v58792 = vor.u32 %v58791, %v58790 (stack46)
        %v58793 = vxor.u32 %v58792, %v58788 (stack47)
        %v58796 = vadd.s32 %v58793, %v58788 (stack39)
        %v58798 = vshll.u32 %v58793, 26 (stack44)
        %v58799 = vshrl.u32 %v58793, 6 (stack45)
        %v58800 = vor.u32 %v58799, %v58798 (stack46)
        %v58801 = vxor.u32 %v58800, %v58796 (stack47)
        %v58804 = vadd.s32 %v58801, %v58796 (stack39)
        %v58808 = vadd.s32 %v58804, %v9 (stack39)
        %v58810 = vshll.u32 %v58801, 6 (stack44)
        %v58811 = vshrl.u32 %v58801, 26 (stack45)
        %v58812 = vor.u32 %v58811, %v58810 (stack46)
        %v58813 = vxor.u32 %v58812, %v58804 (stack47)
        %v58816 = vadd.s32 %v58813, %v8 (stack39)
        %v58820 = vadd.s32 1, %v58816 (stack39)
        %v58824 = vadd.s32 %v58820, %v58808 (stack39)
        %v58826 = vshll.u32 %v58820, 17 (stack44)
        %v58827 = vshrl.u32 %v58820, 15 (stack45)
        %v58828 = vor.u32 %v58827, %v58826 (stack46)
        %v58829 = vxor.u32 %v58828, %v58824 (stack47)
        %v58832 = vadd.s32 %v58829, %v58824 (stack39)
        %v58834 = vshll.u32 %v58829, 29 (stack44)
        %v58835 = vshrl.u32 %v58829, 3 (stack45)
        %v58836 = vor.u32 %v58835, %v58834 (stack46)
        %v58837 = vxor.u32 %v58836, %v58832 (stack47)
        %v58840 = vadd.s32 %v58837, %v58832 (stack39)
        %v58842 = vshll.u32 %v58837, 16 (stack44)
        %v58843 = vshrl.u32 %v58837, 16 (stack45)
        %v58844 = vor.u32 %v58843, %v58842 (stack46)
        %v58845 = vxor.u32 %v58844, %v58840 (stack47)
        %v58848 = vadd.s32 %v58845, %v58840 (stack39)
        %v58852 = vadd.s32 %v58848, %v8 (stack39)
        %v58854 = vshll.u32 %v58845, 24 (stack44)
        %v58855 = vshrl.u32 %v58845, 8 (stack45)
        %v58856 = vor.u32 %v58855, %v58854 (stack46)
        %v58857 = vxor.u32 %v58856, %v58848 (stack47)
        %v58860 = vadd.s32 %v58857, %v10 (stack39)
        %v58864 = vadd.s32 2, %v58860 (stack39)
        %v58868 = vadd.s32 %v58864, %v58852 (stack39)
        %v58870 = vshll.u32 %v58864, 13 (stack44)
        %v58871 = vshrl.u32 %v58864, 19 (stack45)
        %v58872 = vor.u32 %v58871, %v58870 (stack46)
        %v58873 = vxor.u32 %v58872, %v58868 (stack47)
        %v58876 = vadd.s32 %v58873, %v58868 (stack39)
        %v58878 = vshll.u32 %v58873, 15 (stack44)
        %v58879 = vshrl.u32 %v58873, 17 (stack45)
        %v58880 = vor.u32 %v58879, %v58878 (stack46)
        %v58881 = vxor.u32 %v58880, %v58876 (stack47)
        %v58884 = vadd.s32 %v58881, %v58876 (stack39)
        %v58886 = vshll.u32 %v58881, 26 (stack44)
        %v58887 = vshrl.u32 %v58881, 6 (stack45)
        %v58888 = vor.u32 %v58887, %v58886 (stack46)
        %v58889 = vxor.u32 %v58888, %v58884 (stack47)
        %v58892 = vadd.s32 %v58889, %v58884 (stack39)
        %v58896 = vadd.s32 %v58892, %v10 (stack39)
        %v58898 = vshll.u32 %v58889, 6 (stack44)
        %v58899 = vshrl.u32 %v58889, 26 (stack45)
        %v58900 = vor.u32 %v58899, %v58898 (stack46)
        %v58901 = vxor.u32 %v58900, %v58892 (stack47)
        %v58904 = vadd.s32 %v58901, %v9 (stack39)
        %v58908 = vadd.s32 3, %v58904 (stack39)
        %v58912 = vadd.s32 %v58908, %v58896 (stack39)
        %v58914 = vshll.u32 %v58908, 17 (stack44)
        %v58915 = vshrl.u32 %v58908, 15 (stack45)
        %v58916 = vor.u32 %v58915, %v58914 (stack46)
        %v58917 = vxor.u32 %v58916, %v58912 (stack47)
        %v58920 = vadd.s32 %v58917, %v58912 (stack39)
        %v58922 = vshll.u32 %v58917, 29 (stack44)
        %v58923 = vshrl.u32 %v58917, 3 (stack45)
        %v58924 = vor.u32 %v58923, %v58922 (stack46)
        %v58925 = vxor.u32 %v58924, %v58920 (stack47)
        %v58928 = vadd.s32 %v58925, %v58920 (stack39)
        %v58930 = vshll.u32 %v58925, 16 (stack44)
        %v58931 = vshrl.u32 %v58925, 16 (stack45)
        %v58932 = vor.u32 %v58931, %v58930 (stack46)
        %v58933 = vxor.u32 %v58932, %v58928 (stack47)
        %v58936 = vadd.s32 %v58933, %v58928 (stack39)
        %v58940 = vadd.s32 %v58936, %v9 (stack39)
        %v58942 = vshll.u32 %v58933, 24 (stack44)
        %v58943 = vshrl.u32 %v58933, 8 (stack45)
        %v58944 = vor.u32 %v58943, %v58942 (stack46)
        %v58945 = vxor.u32 %v58944, %v58936 (stack47)
        %v58948 = vadd.s32 %v58945, %v8 (stack39)
        %v58952 = vadd.s32 4, %v58948 (stack39)
        %v58956 = vadd.s32 %v58952, %v58940 (stack39)
        %v58958 = vshll.u32 %v58952, 13 (stack44)
        %v58959 = vshrl.u32 %v58952, 19 (stack45)
        %v58960 = vor.u32 %v58959, %v58958 (stack46)
        %v58961 = vxor.u32 %v58960, %v58956 (stack47)
        %v58964 = vadd.s32 %v58961, %v58956 (stack39)
        %v58966 = vshll.u32 %v58961, 15 (stack44)
        %v58967 = vshrl.u32 %v58961, 17 (stack45)
        %v58968 = vor.u32 %v58967, %v58966 (stack46)
        %v58969 = vxor.u32 %v58968, %v58964 (stack47)
        %v58972 = vadd.s32 %v58969, %v58964 (stack39)
        %v58974 = vshll.u32 %v58969, 26 (stack44)
        %v58975 = vshrl.u32 %v58969, 6 (stack45)
        %v58976 = vor.u32 %v58975, %v58974 (stack46)
        %v58977 = vxor.u32 %v58976, %v58972 (stack47)
        %v58980 = vadd.s32 %v58977, %v58972 (stack39)
        %v58984 = vadd.s32 %v58980, %v8 (stack39)
        %v58986 = vshll.u32 %v58977, 6 (stack44)
        %v58987 = vshrl.u32 %v58977, 26 (stack45)
        %v58988 = vor.u32 %v58987, %v58986 (stack46)
        %v58989 = vxor.u32 %v58988, %v58980 (stack47)
        %v58992 = vadd.s32 %v58989, %v10 (stack39)
        %v58996 = vadd.s32 5, %v58992 (stack39)
        %v58998 = vxor.u32 %v58996, %v58984 (stack47)
        %v58999 = vand.u32.u8 255, %v58998 (stack48)
        %v59000 = vand.u32 65535, %v58999 (stack49)
        %v59001 = vshrl.u32 %v59000, 1 (stack50)
        %v59002 = vor.u32 16256, %v59001 (stack46)
        %v59003 = vand.u32.u16 65535, %v59002 (stack51)
        %v120058 = vadd.low.f32.bf16 -1.0, %v59003 (stack52)
        %v59012 = vmul.f32 2.0, %v120058 (stack53)
        %v59016 = vadd.f32 -0.99609375, %v59012 (stack52)
        %v59020 = vmax.f32 %v59016, -0.99609375 (stack54)
        %v59022 = vand.u32 2147483647, %v59020 (stack55)
        %vm59025 = vcmp.eq.f32.partialorder %v59022, 1.0 (stack56)
        %v59030 = vmul.f32 inf, %v59020 (stack53)
        %v59032 = vxor.u32 2147483648, %v59020 (stack57)
        %v59035 = vmul.f32 %v59032, %v59020 (stack53)
        %v59037 = vadd.f32 1.0, %v59035 (stack58)
        %v59038 = vlog2.pop %v59037 (stack59)
        %v59039 = vmul.f32 0.6931472, %v59038 (stack60)
        %v59040 = vmul.f32 -0.5, %v59035 (stack61)
        %v59041 = vadd.f32 1.0, %v59040 (stack62)
        %v59042 = vmul.f32 %v59041, %v59035 (stack63)
        %v59043 = vand.u32 2147483647, %v59035 (stack64)
        %vm59044 = vcmp.lt.f32.partialorder %v59043, 0.0004427343 (stack65)
        %v59045 = vsel /*vm=*/%vm59044, /*on_true_vy=*/%v59042, /*on_false_vx=*/%v59039 (stack66)
        %v59046 = vxor.u32 2147483648, %v59045 (stack57)
        %vm59049 = vcmp.lt.f32.partialorder %v59046, 5.0 (stack56)
        %v59054 = vsel /*vm=*/%vm59049, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v59058 = vsel /*vm=*/%vm59049, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v59062 = vsel /*vm=*/%vm59049, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v59066 = vsel /*vm=*/%vm59049, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v59070 = vsel /*vm=*/%vm59049, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v59074 = vsel /*vm=*/%vm59049, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v59078 = vsel /*vm=*/%vm59049, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v59082 = vsel /*vm=*/%vm59049, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v59086 = vsel /*vm=*/%vm59049, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v59090 = vadd.f32 -2.5, %v59046 (stack52)
        %v59092 = vrsqrt.pop %v59046 (stack67)
        %v59093 = vmul.f32 %v59092, %v59046 (stack68)
        %vm59094 = vcmp.eq.f32.partialorder %v59046, inf (stack69)
        %v59095 = vsel /*vm=*/%vm59094, /*on_true_vy=*/%v59046, /*on_false_vx=*/%v59093 (stack70)
        %vm59096 = vcmp.eq.f32.partialorder %v59046, 0.0 (stack71)
        %v59097 = vand.u32 2147483648, %v59046 (stack72)
        %v59098 = vsel /*vm=*/%vm59096, /*on_true_vy=*/%v59097, /*on_false_vx=*/%v59095 (stack73)
        %v59101 = vadd.f32 -3.0, %v59098 (stack52)
        %v59105 = vsel /*vm=*/%vm59049, /*on_true_vy=*/%v59090, /*on_false_vx=*/%v59101 (stack43)
        %v59109 = vmul.f32 %v59105, %v59086 (stack53)
        %v59113 = vadd.f32 %v59109, %v59082 (stack52)
        %v59117 = vmul.f32 %v59113, %v59105 (stack53)
        %v59121 = vadd.f32 %v59117, %v59078 (stack52)
        %v59125 = vmul.f32 %v59121, %v59105 (stack53)
        %v59129 = vadd.f32 %v59125, %v59074 (stack52)
        %v59133 = vmul.f32 %v59129, %v59105 (stack53)
        %v59137 = vadd.f32 %v59133, %v59070 (stack52)
        %v59141 = vmul.f32 %v59137, %v59105 (stack53)
        %v59145 = vadd.f32 %v59141, %v59066 (stack52)
        %v59149 = vmul.f32 %v59145, %v59105 (stack53)
        %v59153 = vadd.f32 %v59149, %v59062 (stack52)
        %v59157 = vmul.f32 %v59153, %v59105 (stack53)
        %v59161 = vadd.f32 %v59157, %v59058 (stack52)
        %v59165 = vmul.f32 %v59161, %v59105 (stack53)
        %v59169 = vadd.f32 %v59165, %v59054 (stack52)
        %v59173 = vmul.f32 %v59169, %v59020 (stack53)
        %v59177 = vsel /*vm=*/%vm59025, /*on_true_vy=*/%v59030, /*on_false_vx=*/%v59173 (stack43)
        %v59181 = vmul.f32 1.4140625, %v59177 (stack53)
        %v59184 = vpack.c.bf16 0.0, %v59181 (stack74)
        %120059 = vst [vmem:[%s280 + $0x2bc] sm:$0xf] /*vst_source=*/%v59184 (stack75)
        %v59188 = vadd.s32 %v56419, %v3329 (stack39)
        %v59198 = vadd.s32 %v59188, %v415 (stack39)
        %vm59202 = vcmp.lt.u32.totalorder %v59198, %v59188 (stack42)
        %vm59207 = vcmp.lt.u32.totalorder %v59188, %v3329 (stack42)
        %v59212 = vadd.s32 %v56402, %v3316 (stack39)
        %v59216 = vadd.s32 1, %v59212 (stack39)
        %v59220 = vsel /*vm=*/%vm59207, /*on_true_vy=*/%v59216, /*on_false_vx=*/%v59212 (stack43)
        %v59224 = vadd.s32 1, %v59220 (stack39)
        %v59228 = vsel /*vm=*/%vm59202, /*on_true_vy=*/%v59224, /*on_false_vx=*/%v59220 (stack43)
        %v59233 = vadd.s32 %v59228, %v10 (stack39)
        %v59237 = vadd.s32 %v59198, %v9 (stack39)
        %v59241 = vadd.s32 %v59237, %v59233 (stack39)
        %v59243 = vshll.u32 %v59237, 13 (stack44)
        %v59244 = vshrl.u32 %v59237, 19 (stack45)
        %v59245 = vor.u32 %v59244, %v59243 (stack46)
        %v59246 = vxor.u32 %v59245, %v59241 (stack47)
        %v59249 = vadd.s32 %v59246, %v59241 (stack39)
        %v59251 = vshll.u32 %v59246, 15 (stack44)
        %v59252 = vshrl.u32 %v59246, 17 (stack45)
        %v59253 = vor.u32 %v59252, %v59251 (stack46)
        %v59254 = vxor.u32 %v59253, %v59249 (stack47)
        %v59257 = vadd.s32 %v59254, %v59249 (stack39)
        %v59259 = vshll.u32 %v59254, 26 (stack44)
        %v59260 = vshrl.u32 %v59254, 6 (stack45)
        %v59261 = vor.u32 %v59260, %v59259 (stack46)
        %v59262 = vxor.u32 %v59261, %v59257 (stack47)
        %v59265 = vadd.s32 %v59262, %v59257 (stack39)
        %v59269 = vadd.s32 %v59265, %v9 (stack39)
        %v59271 = vshll.u32 %v59262, 6 (stack44)
        %v59272 = vshrl.u32 %v59262, 26 (stack45)
        %v59273 = vor.u32 %v59272, %v59271 (stack46)
        %v59274 = vxor.u32 %v59273, %v59265 (stack47)
        %v59277 = vadd.s32 %v59274, %v8 (stack39)
        %v59281 = vadd.s32 1, %v59277 (stack39)
        %v59285 = vadd.s32 %v59281, %v59269 (stack39)
        %v59287 = vshll.u32 %v59281, 17 (stack44)
        %v59288 = vshrl.u32 %v59281, 15 (stack45)
        %v59289 = vor.u32 %v59288, %v59287 (stack46)
        %v59290 = vxor.u32 %v59289, %v59285 (stack47)
        %v59293 = vadd.s32 %v59290, %v59285 (stack39)
        %v59295 = vshll.u32 %v59290, 29 (stack44)
        %v59296 = vshrl.u32 %v59290, 3 (stack45)
        %v59297 = vor.u32 %v59296, %v59295 (stack46)
        %v59298 = vxor.u32 %v59297, %v59293 (stack47)
        %v59301 = vadd.s32 %v59298, %v59293 (stack39)
        %v59303 = vshll.u32 %v59298, 16 (stack44)
        %v59304 = vshrl.u32 %v59298, 16 (stack45)
        %v59305 = vor.u32 %v59304, %v59303 (stack46)
        %v59306 = vxor.u32 %v59305, %v59301 (stack47)
        %v59309 = vadd.s32 %v59306, %v59301 (stack39)
        %v59313 = vadd.s32 %v59309, %v8 (stack39)
        %v59315 = vshll.u32 %v59306, 24 (stack44)
        %v59316 = vshrl.u32 %v59306, 8 (stack45)
        %v59317 = vor.u32 %v59316, %v59315 (stack46)
        %v59318 = vxor.u32 %v59317, %v59309 (stack47)
        %v59321 = vadd.s32 %v59318, %v10 (stack39)
        %v59325 = vadd.s32 2, %v59321 (stack39)
        %v59329 = vadd.s32 %v59325, %v59313 (stack39)
        %v59331 = vshll.u32 %v59325, 13 (stack44)
        %v59332 = vshrl.u32 %v59325, 19 (stack45)
        %v59333 = vor.u32 %v59332, %v59331 (stack46)
        %v59334 = vxor.u32 %v59333, %v59329 (stack47)
        %v59337 = vadd.s32 %v59334, %v59329 (stack39)
        %v59339 = vshll.u32 %v59334, 15 (stack44)
        %v59340 = vshrl.u32 %v59334, 17 (stack45)
        %v59341 = vor.u32 %v59340, %v59339 (stack46)
        %v59342 = vxor.u32 %v59341, %v59337 (stack47)
        %v59345 = vadd.s32 %v59342, %v59337 (stack39)
        %v59347 = vshll.u32 %v59342, 26 (stack44)
        %v59348 = vshrl.u32 %v59342, 6 (stack45)
        %v59349 = vor.u32 %v59348, %v59347 (stack46)
        %v59350 = vxor.u32 %v59349, %v59345 (stack47)
        %v59353 = vadd.s32 %v59350, %v59345 (stack39)
        %v59357 = vadd.s32 %v59353, %v10 (stack39)
        %v59359 = vshll.u32 %v59350, 6 (stack44)
        %v59360 = vshrl.u32 %v59350, 26 (stack45)
        %v59361 = vor.u32 %v59360, %v59359 (stack46)
        %v59362 = vxor.u32 %v59361, %v59353 (stack47)
        %v59365 = vadd.s32 %v59362, %v9 (stack39)
        %v59369 = vadd.s32 3, %v59365 (stack39)
        %v59373 = vadd.s32 %v59369, %v59357 (stack39)
        %v59375 = vshll.u32 %v59369, 17 (stack44)
        %v59376 = vshrl.u32 %v59369, 15 (stack45)
        %v59377 = vor.u32 %v59376, %v59375 (stack46)
        %v59378 = vxor.u32 %v59377, %v59373 (stack47)
        %v59381 = vadd.s32 %v59378, %v59373 (stack39)
        %v59383 = vshll.u32 %v59378, 29 (stack44)
        %v59384 = vshrl.u32 %v59378, 3 (stack45)
        %v59385 = vor.u32 %v59384, %v59383 (stack46)
        %v59386 = vxor.u32 %v59385, %v59381 (stack47)
        %v59389 = vadd.s32 %v59386, %v59381 (stack39)
        %v59391 = vshll.u32 %v59386, 16 (stack44)
        %v59392 = vshrl.u32 %v59386, 16 (stack45)
        %v59393 = vor.u32 %v59392, %v59391 (stack46)
        %v59394 = vxor.u32 %v59393, %v59389 (stack47)
        %v59397 = vadd.s32 %v59394, %v59389 (stack39)
        %v59401 = vadd.s32 %v59397, %v9 (stack39)
        %v59403 = vshll.u32 %v59394, 24 (stack44)
        %v59404 = vshrl.u32 %v59394, 8 (stack45)
        %v59405 = vor.u32 %v59404, %v59403 (stack46)
        %v59406 = vxor.u32 %v59405, %v59397 (stack47)
        %v59409 = vadd.s32 %v59406, %v8 (stack39)
        %v59413 = vadd.s32 4, %v59409 (stack39)
        %v59417 = vadd.s32 %v59413, %v59401 (stack39)
        %v59419 = vshll.u32 %v59413, 13 (stack44)
        %v59420 = vshrl.u32 %v59413, 19 (stack45)
        %v59421 = vor.u32 %v59420, %v59419 (stack46)
        %v59422 = vxor.u32 %v59421, %v59417 (stack47)
        %v59425 = vadd.s32 %v59422, %v59417 (stack39)
        %v59427 = vshll.u32 %v59422, 15 (stack44)
        %v59428 = vshrl.u32 %v59422, 17 (stack45)
        %v59429 = vor.u32 %v59428, %v59427 (stack46)
        %v59430 = vxor.u32 %v59429, %v59425 (stack47)
        %v59433 = vadd.s32 %v59430, %v59425 (stack39)
        %v59435 = vshll.u32 %v59430, 26 (stack44)
        %v59436 = vshrl.u32 %v59430, 6 (stack45)
        %v59437 = vor.u32 %v59436, %v59435 (stack46)
        %v59438 = vxor.u32 %v59437, %v59433 (stack47)
        %v59441 = vadd.s32 %v59438, %v59433 (stack39)
        %v59445 = vadd.s32 %v59441, %v8 (stack39)
        %v59447 = vshll.u32 %v59438, 6 (stack44)
        %v59448 = vshrl.u32 %v59438, 26 (stack45)
        %v59449 = vor.u32 %v59448, %v59447 (stack46)
        %v59450 = vxor.u32 %v59449, %v59441 (stack47)
        %v59453 = vadd.s32 %v59450, %v10 (stack39)
        %v59457 = vadd.s32 5, %v59453 (stack39)
        %v59459 = vxor.u32 %v59457, %v59445 (stack47)
        %v59460 = vand.u32.u8 255, %v59459 (stack48)
        %v59461 = vand.u32 65535, %v59460 (stack49)
        %v59462 = vshrl.u32 %v59461, 1 (stack50)
        %v59463 = vor.u32 16256, %v59462 (stack46)
        %v59464 = vand.u32.u16 65535, %v59463 (stack51)
        %v120060 = vadd.low.f32.bf16 -1.0, %v59464 (stack52)
        %v59473 = vmul.f32 2.0, %v120060 (stack53)
        %v59477 = vadd.f32 -0.99609375, %v59473 (stack52)
        %v59481 = vmax.f32 %v59477, -0.99609375 (stack54)
        %v59483 = vand.u32 2147483647, %v59481 (stack55)
        %vm59486 = vcmp.eq.f32.partialorder %v59483, 1.0 (stack56)
        %v59491 = vmul.f32 inf, %v59481 (stack53)
        %v59493 = vxor.u32 2147483648, %v59481 (stack57)
        %v59496 = vmul.f32 %v59493, %v59481 (stack53)
        %v59498 = vadd.f32 1.0, %v59496 (stack58)
        %v59499 = vlog2.pop %v59498 (stack59)
        %v59500 = vmul.f32 0.6931472, %v59499 (stack60)
        %v59501 = vmul.f32 -0.5, %v59496 (stack61)
        %v59502 = vadd.f32 1.0, %v59501 (stack62)
        %v59503 = vmul.f32 %v59502, %v59496 (stack63)
        %v59504 = vand.u32 2147483647, %v59496 (stack64)
        %vm59505 = vcmp.lt.f32.partialorder %v59504, 0.0004427343 (stack65)
        %v59506 = vsel /*vm=*/%vm59505, /*on_true_vy=*/%v59503, /*on_false_vx=*/%v59500 (stack66)
        %v59507 = vxor.u32 2147483648, %v59506 (stack57)
        %vm59510 = vcmp.lt.f32.partialorder %v59507, 5.0 (stack56)
        %v59515 = vsel /*vm=*/%vm59510, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v59519 = vsel /*vm=*/%vm59510, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v59523 = vsel /*vm=*/%vm59510, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v59527 = vsel /*vm=*/%vm59510, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v59531 = vsel /*vm=*/%vm59510, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v59535 = vsel /*vm=*/%vm59510, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v59539 = vsel /*vm=*/%vm59510, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v59543 = vsel /*vm=*/%vm59510, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v59547 = vsel /*vm=*/%vm59510, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v59551 = vadd.f32 -2.5, %v59507 (stack52)
        %v59553 = vrsqrt.pop %v59507 (stack67)
        %v59554 = vmul.f32 %v59553, %v59507 (stack68)
        %vm59555 = vcmp.eq.f32.partialorder %v59507, inf (stack69)
        %v59556 = vsel /*vm=*/%vm59555, /*on_true_vy=*/%v59507, /*on_false_vx=*/%v59554 (stack70)
        %vm59557 = vcmp.eq.f32.partialorder %v59507, 0.0 (stack71)
        %v59558 = vand.u32 2147483648, %v59507 (stack72)
        %v59559 = vsel /*vm=*/%vm59557, /*on_true_vy=*/%v59558, /*on_false_vx=*/%v59556 (stack73)
        %v59562 = vadd.f32 -3.0, %v59559 (stack52)
        %v59566 = vsel /*vm=*/%vm59510, /*on_true_vy=*/%v59551, /*on_false_vx=*/%v59562 (stack43)
        %v59570 = vmul.f32 %v59566, %v59547 (stack53)
        %v59574 = vadd.f32 %v59570, %v59543 (stack52)
        %v59578 = vmul.f32 %v59574, %v59566 (stack53)
        %v59582 = vadd.f32 %v59578, %v59539 (stack52)
        %v59586 = vmul.f32 %v59582, %v59566 (stack53)
        %v59590 = vadd.f32 %v59586, %v59535 (stack52)
        %v59594 = vmul.f32 %v59590, %v59566 (stack53)
        %v59598 = vadd.f32 %v59594, %v59531 (stack52)
        %v59602 = vmul.f32 %v59598, %v59566 (stack53)
        %v59606 = vadd.f32 %v59602, %v59527 (stack52)
        %v59610 = vmul.f32 %v59606, %v59566 (stack53)
        %v59614 = vadd.f32 %v59610, %v59523 (stack52)
        %v59618 = vmul.f32 %v59614, %v59566 (stack53)
        %v59622 = vadd.f32 %v59618, %v59519 (stack52)
        %v59626 = vmul.f32 %v59622, %v59566 (stack53)
        %v59630 = vadd.f32 %v59626, %v59515 (stack52)
        %v59634 = vmul.f32 %v59630, %v59481 (stack53)
        %v59638 = vsel /*vm=*/%vm59486, /*on_true_vy=*/%v59491, /*on_false_vx=*/%v59634 (stack43)
        %v59642 = vmul.f32 1.4140625, %v59638 (stack53)
        %v59645 = vpack.c.bf16 0.0, %v59642 (stack74)
        %120061 = vst [vmem:[%s280 + $0x33c] sm:$0xf] /*vst_source=*/%v59645 (stack75)
        %v59649 = vadd.s32 %v56419, %v3816 (stack39)
        %v59659 = vadd.s32 %v59649, %v415 (stack39)
        %vm59663 = vcmp.lt.u32.totalorder %v59659, %v59649 (stack42)
        %vm59668 = vcmp.lt.u32.totalorder %v59649, %v3816 (stack42)
        %v59673 = vadd.s32 %v56402, %v3803 (stack39)
        %v59677 = vadd.s32 1, %v59673 (stack39)
        %v59681 = vsel /*vm=*/%vm59668, /*on_true_vy=*/%v59677, /*on_false_vx=*/%v59673 (stack43)
        %v59685 = vadd.s32 1, %v59681 (stack39)
        %v59689 = vsel /*vm=*/%vm59663, /*on_true_vy=*/%v59685, /*on_false_vx=*/%v59681 (stack43)
        %v59694 = vadd.s32 %v59689, %v10 (stack39)
        %v59698 = vadd.s32 %v59659, %v9 (stack39)
        %v59702 = vadd.s32 %v59698, %v59694 (stack39)
        %v59704 = vshll.u32 %v59698, 13 (stack44)
        %v59705 = vshrl.u32 %v59698, 19 (stack45)
        %v59706 = vor.u32 %v59705, %v59704 (stack46)
        %v59707 = vxor.u32 %v59706, %v59702 (stack47)
        %v59710 = vadd.s32 %v59707, %v59702 (stack39)
        %v59712 = vshll.u32 %v59707, 15 (stack44)
        %v59713 = vshrl.u32 %v59707, 17 (stack45)
        %v59714 = vor.u32 %v59713, %v59712 (stack46)
        %v59715 = vxor.u32 %v59714, %v59710 (stack47)
        %v59718 = vadd.s32 %v59715, %v59710 (stack39)
        %v59720 = vshll.u32 %v59715, 26 (stack44)
        %v59721 = vshrl.u32 %v59715, 6 (stack45)
        %v59722 = vor.u32 %v59721, %v59720 (stack46)
        %v59723 = vxor.u32 %v59722, %v59718 (stack47)
        %v59726 = vadd.s32 %v59723, %v59718 (stack39)
        %v59730 = vadd.s32 %v59726, %v9 (stack39)
        %v59732 = vshll.u32 %v59723, 6 (stack44)
        %v59733 = vshrl.u32 %v59723, 26 (stack45)
        %v59734 = vor.u32 %v59733, %v59732 (stack46)
        %v59735 = vxor.u32 %v59734, %v59726 (stack47)
        %v59738 = vadd.s32 %v59735, %v8 (stack39)
        %v59742 = vadd.s32 1, %v59738 (stack39)
        %v59746 = vadd.s32 %v59742, %v59730 (stack39)
        %v59748 = vshll.u32 %v59742, 17 (stack44)
        %v59749 = vshrl.u32 %v59742, 15 (stack45)
        %v59750 = vor.u32 %v59749, %v59748 (stack46)
        %v59751 = vxor.u32 %v59750, %v59746 (stack47)
        %v59754 = vadd.s32 %v59751, %v59746 (stack39)
        %v59756 = vshll.u32 %v59751, 29 (stack44)
        %v59757 = vshrl.u32 %v59751, 3 (stack45)
        %v59758 = vor.u32 %v59757, %v59756 (stack46)
        %v59759 = vxor.u32 %v59758, %v59754 (stack47)
        %v59762 = vadd.s32 %v59759, %v59754 (stack39)
        %v59764 = vshll.u32 %v59759, 16 (stack44)
        %v59765 = vshrl.u32 %v59759, 16 (stack45)
        %v59766 = vor.u32 %v59765, %v59764 (stack46)
        %v59767 = vxor.u32 %v59766, %v59762 (stack47)
        %v59770 = vadd.s32 %v59767, %v59762 (stack39)
        %v59774 = vadd.s32 %v59770, %v8 (stack39)
        %v59776 = vshll.u32 %v59767, 24 (stack44)
        %v59777 = vshrl.u32 %v59767, 8 (stack45)
        %v59778 = vor.u32 %v59777, %v59776 (stack46)
        %v59779 = vxor.u32 %v59778, %v59770 (stack47)
        %v59782 = vadd.s32 %v59779, %v10 (stack39)
        %v59786 = vadd.s32 2, %v59782 (stack39)
        %v59790 = vadd.s32 %v59786, %v59774 (stack39)
        %v59792 = vshll.u32 %v59786, 13 (stack44)
        %v59793 = vshrl.u32 %v59786, 19 (stack45)
        %v59794 = vor.u32 %v59793, %v59792 (stack46)
        %v59795 = vxor.u32 %v59794, %v59790 (stack47)
        %v59798 = vadd.s32 %v59795, %v59790 (stack39)
        %v59800 = vshll.u32 %v59795, 15 (stack44)
        %v59801 = vshrl.u32 %v59795, 17 (stack45)
        %v59802 = vor.u32 %v59801, %v59800 (stack46)
        %v59803 = vxor.u32 %v59802, %v59798 (stack47)
        %v59806 = vadd.s32 %v59803, %v59798 (stack39)
        %v59808 = vshll.u32 %v59803, 26 (stack44)
        %v59809 = vshrl.u32 %v59803, 6 (stack45)
        %v59810 = vor.u32 %v59809, %v59808 (stack46)
        %v59811 = vxor.u32 %v59810, %v59806 (stack47)
        %v59814 = vadd.s32 %v59811, %v59806 (stack39)
        %v59818 = vadd.s32 %v59814, %v10 (stack39)
        %v59820 = vshll.u32 %v59811, 6 (stack44)
        %v59821 = vshrl.u32 %v59811, 26 (stack45)
        %v59822 = vor.u32 %v59821, %v59820 (stack46)
        %v59823 = vxor.u32 %v59822, %v59814 (stack47)
        %v59826 = vadd.s32 %v59823, %v9 (stack39)
        %v59830 = vadd.s32 3, %v59826 (stack39)
        %v59834 = vadd.s32 %v59830, %v59818 (stack39)
        %v59836 = vshll.u32 %v59830, 17 (stack44)
        %v59837 = vshrl.u32 %v59830, 15 (stack45)
        %v59838 = vor.u32 %v59837, %v59836 (stack46)
        %v59839 = vxor.u32 %v59838, %v59834 (stack47)
        %v59842 = vadd.s32 %v59839, %v59834 (stack39)
        %v59844 = vshll.u32 %v59839, 29 (stack44)
        %v59845 = vshrl.u32 %v59839, 3 (stack45)
        %v59846 = vor.u32 %v59845, %v59844 (stack46)
        %v59847 = vxor.u32 %v59846, %v59842 (stack47)
        %v59850 = vadd.s32 %v59847, %v59842 (stack39)
        %v59852 = vshll.u32 %v59847, 16 (stack44)
        %v59853 = vshrl.u32 %v59847, 16 (stack45)
        %v59854 = vor.u32 %v59853, %v59852 (stack46)
        %v59855 = vxor.u32 %v59854, %v59850 (stack47)
        %v59858 = vadd.s32 %v59855, %v59850 (stack39)
        %v59862 = vadd.s32 %v59858, %v9 (stack39)
        %v59864 = vshll.u32 %v59855, 24 (stack44)
        %v59865 = vshrl.u32 %v59855, 8 (stack45)
        %v59866 = vor.u32 %v59865, %v59864 (stack46)
        %v59867 = vxor.u32 %v59866, %v59858 (stack47)
        %v59870 = vadd.s32 %v59867, %v8 (stack39)
        %v59874 = vadd.s32 4, %v59870 (stack39)
        %v59878 = vadd.s32 %v59874, %v59862 (stack39)
        %v59880 = vshll.u32 %v59874, 13 (stack44)
        %v59881 = vshrl.u32 %v59874, 19 (stack45)
        %v59882 = vor.u32 %v59881, %v59880 (stack46)
        %v59883 = vxor.u32 %v59882, %v59878 (stack47)
        %v59886 = vadd.s32 %v59883, %v59878 (stack39)
        %v59888 = vshll.u32 %v59883, 15 (stack44)
        %v59889 = vshrl.u32 %v59883, 17 (stack45)
        %v59890 = vor.u32 %v59889, %v59888 (stack46)
        %v59891 = vxor.u32 %v59890, %v59886 (stack47)
        %v59894 = vadd.s32 %v59891, %v59886 (stack39)
        %v59896 = vshll.u32 %v59891, 26 (stack44)
        %v59897 = vshrl.u32 %v59891, 6 (stack45)
        %v59898 = vor.u32 %v59897, %v59896 (stack46)
        %v59899 = vxor.u32 %v59898, %v59894 (stack47)
        %v59902 = vadd.s32 %v59899, %v59894 (stack39)
        %v59906 = vadd.s32 %v59902, %v8 (stack39)
        %v59908 = vshll.u32 %v59899, 6 (stack44)
        %v59909 = vshrl.u32 %v59899, 26 (stack45)
        %v59910 = vor.u32 %v59909, %v59908 (stack46)
        %v59911 = vxor.u32 %v59910, %v59902 (stack47)
        %v59914 = vadd.s32 %v59911, %v10 (stack39)
        %v59918 = vadd.s32 5, %v59914 (stack39)
        %v59920 = vxor.u32 %v59918, %v59906 (stack47)
        %v59921 = vand.u32.u8 255, %v59920 (stack48)
        %v59922 = vand.u32 65535, %v59921 (stack49)
        %v59923 = vshrl.u32 %v59922, 1 (stack50)
        %v59924 = vor.u32 16256, %v59923 (stack46)
        %v59925 = vand.u32.u16 65535, %v59924 (stack51)
        %v120062 = vadd.low.f32.bf16 -1.0, %v59925 (stack52)
        %v59934 = vmul.f32 2.0, %v120062 (stack53)
        %v59938 = vadd.f32 -0.99609375, %v59934 (stack52)
        %v59942 = vmax.f32 %v59938, -0.99609375 (stack54)
        %v59944 = vand.u32 2147483647, %v59942 (stack55)
        %vm59947 = vcmp.eq.f32.partialorder %v59944, 1.0 (stack56)
        %v59952 = vmul.f32 inf, %v59942 (stack53)
        %v59954 = vxor.u32 2147483648, %v59942 (stack57)
        %v59957 = vmul.f32 %v59954, %v59942 (stack53)
        %v59959 = vadd.f32 1.0, %v59957 (stack58)
        %v59960 = vlog2.pop %v59959 (stack59)
        %v59961 = vmul.f32 0.6931472, %v59960 (stack60)
        %v59962 = vmul.f32 -0.5, %v59957 (stack61)
        %v59963 = vadd.f32 1.0, %v59962 (stack62)
        %v59964 = vmul.f32 %v59963, %v59957 (stack63)
        %v59965 = vand.u32 2147483647, %v59957 (stack64)
        %vm59966 = vcmp.lt.f32.partialorder %v59965, 0.0004427343 (stack65)
        %v59967 = vsel /*vm=*/%vm59966, /*on_true_vy=*/%v59964, /*on_false_vx=*/%v59961 (stack66)
        %v59968 = vxor.u32 2147483648, %v59967 (stack57)
        %vm59971 = vcmp.lt.f32.partialorder %v59968, 5.0 (stack56)
        %v59976 = vsel /*vm=*/%vm59971, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v59980 = vsel /*vm=*/%vm59971, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v59984 = vsel /*vm=*/%vm59971, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v59988 = vsel /*vm=*/%vm59971, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v59992 = vsel /*vm=*/%vm59971, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v59996 = vsel /*vm=*/%vm59971, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v60000 = vsel /*vm=*/%vm59971, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v60004 = vsel /*vm=*/%vm59971, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v60008 = vsel /*vm=*/%vm59971, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v60012 = vadd.f32 -2.5, %v59968 (stack52)
        %v60014 = vrsqrt.pop %v59968 (stack67)
        %v60015 = vmul.f32 %v60014, %v59968 (stack68)
        %vm60016 = vcmp.eq.f32.partialorder %v59968, inf (stack69)
        %v60017 = vsel /*vm=*/%vm60016, /*on_true_vy=*/%v59968, /*on_false_vx=*/%v60015 (stack70)
        %vm60018 = vcmp.eq.f32.partialorder %v59968, 0.0 (stack71)
        %v60019 = vand.u32 2147483648, %v59968 (stack72)
        %v60020 = vsel /*vm=*/%vm60018, /*on_true_vy=*/%v60019, /*on_false_vx=*/%v60017 (stack73)
        %v60023 = vadd.f32 -3.0, %v60020 (stack52)
        %v60027 = vsel /*vm=*/%vm59971, /*on_true_vy=*/%v60012, /*on_false_vx=*/%v60023 (stack43)
        %v60031 = vmul.f32 %v60027, %v60008 (stack53)
        %v60035 = vadd.f32 %v60031, %v60004 (stack52)
        %v60039 = vmul.f32 %v60035, %v60027 (stack53)
        %v60043 = vadd.f32 %v60039, %v60000 (stack52)
        %v60047 = vmul.f32 %v60043, %v60027 (stack53)
        %v60051 = vadd.f32 %v60047, %v59996 (stack52)
        %v60055 = vmul.f32 %v60051, %v60027 (stack53)
        %v60059 = vadd.f32 %v60055, %v59992 (stack52)
        %v60063 = vmul.f32 %v60059, %v60027 (stack53)
        %v60067 = vadd.f32 %v60063, %v59988 (stack52)
        %v60071 = vmul.f32 %v60067, %v60027 (stack53)
        %v60075 = vadd.f32 %v60071, %v59984 (stack52)
        %v60079 = vmul.f32 %v60075, %v60027 (stack53)
        %v60083 = vadd.f32 %v60079, %v59980 (stack52)
        %v60087 = vmul.f32 %v60083, %v60027 (stack53)
        %v60091 = vadd.f32 %v60087, %v59976 (stack52)
        %v60095 = vmul.f32 %v60091, %v59942 (stack53)
        %v60099 = vsel /*vm=*/%vm59947, /*on_true_vy=*/%v59952, /*on_false_vx=*/%v60095 (stack43)
        %v60103 = vmul.f32 1.4140625, %v60099 (stack53)
        %v60106 = vpack.c.bf16 0.0, %v60103 (stack74)
        %120063 = vst [vmem:[%s280 + $0x3bc] sm:$0xf] /*vst_source=*/%v60106 (stack75)
        %s60108 = sadd.s32 128, %s120390 (stack76)
        %s60109 = sshrl.u32 %s60108, 10 (stack23)
        %p120064 = scmp.gt.s32.totalorder %s60109, 1 (stack24)
        %s60111 = scalar_select /*predicate=*/%p120064, /*on_true=*/1, /*on_false=*/%s60109 (stack25)
        %s60112 = sand.u32 1023, %s60108 /* smod.u32 w/div 1024 */ (stack26)
        %s60113 = sshrl.u32 %s60112, 7 (stack27)
        %s60114 = sand.u32 127, %s60112 /* smod.u32 w/div 128 */ (stack28)
        %s120065 = sshll.u32 %s60111, 3 (stack29)
        %s60116 = scalar_lea.vmem %s3, %s120065 (stack30)
        %s60118 = scalar_lea.vmem %s60116, %s60113 (stack31)
        %v60119 = vld [vmem:[%s60118] ss:$0 sm:$0xff] (stack32)
        %s60120 = sand.u32 255, %s60114 (stack33)
        %s60122 = sor.u32 256, %s60120 (stack34)
        %60123 = vbcast.lane.b32.xlu0 %v60119, %s60122 (stack35)
        %v60124 = vpop.permute.xlu0 %60123 (stack36)
        %s60133 = scalar_lea.vmem %s5, %s120065 (stack30)
        %s60135 = scalar_lea.vmem %s60133, %s60113 (stack31)
        %v60136 = vld [vmem:[%s60135] ss:$0 sm:$0xff] (stack32)
        %60140 = vbcast.lane.b32.xlu0 %v60136, %s60122 (stack35)
        %v60141 = vpop.permute.xlu0 %60140 (stack36)
        %v60144 = vadd.s32 %v60141, %v408 (stack39)
        %v60154 = vadd.s32 %v60144, %v415 (stack39)
        %vm60158 = vcmp.lt.u32.totalorder %v60154, %v60144 (stack42)
        %vm60163 = vcmp.lt.u32.totalorder %v60144, %v408 (stack42)
        %v60168 = vadd.s32 %v60124, %v380 (stack39)
        %v60172 = vadd.s32 1, %v60168 (stack39)
        %v60176 = vsel /*vm=*/%vm60163, /*on_true_vy=*/%v60172, /*on_false_vx=*/%v60168 (stack43)
        %v60180 = vadd.s32 1, %v60176 (stack39)
        %v60184 = vsel /*vm=*/%vm60158, /*on_true_vy=*/%v60180, /*on_false_vx=*/%v60176 (stack43)
        %v60189 = vadd.s32 %v60184, %v10 (stack39)
        %v60193 = vadd.s32 %v60154, %v9 (stack39)
        %v60197 = vadd.s32 %v60193, %v60189 (stack39)
        %v60199 = vshll.u32 %v60193, 13 (stack44)
        %v60200 = vshrl.u32 %v60193, 19 (stack45)
        %v60201 = vor.u32 %v60200, %v60199 (stack46)
        %v60202 = vxor.u32 %v60201, %v60197 (stack47)
        %v60205 = vadd.s32 %v60202, %v60197 (stack39)
        %v60207 = vshll.u32 %v60202, 15 (stack44)
        %v60208 = vshrl.u32 %v60202, 17 (stack45)
        %v60209 = vor.u32 %v60208, %v60207 (stack46)
        %v60210 = vxor.u32 %v60209, %v60205 (stack47)
        %v60213 = vadd.s32 %v60210, %v60205 (stack39)
        %v60215 = vshll.u32 %v60210, 26 (stack44)
        %v60216 = vshrl.u32 %v60210, 6 (stack45)
        %v60217 = vor.u32 %v60216, %v60215 (stack46)
        %v60218 = vxor.u32 %v60217, %v60213 (stack47)
        %v60221 = vadd.s32 %v60218, %v60213 (stack39)
        %v60225 = vadd.s32 %v60221, %v9 (stack39)
        %v60227 = vshll.u32 %v60218, 6 (stack44)
        %v60228 = vshrl.u32 %v60218, 26 (stack45)
        %v60229 = vor.u32 %v60228, %v60227 (stack46)
        %v60230 = vxor.u32 %v60229, %v60221 (stack47)
        %v60233 = vadd.s32 %v60230, %v8 (stack39)
        %v60237 = vadd.s32 1, %v60233 (stack39)
        %v60241 = vadd.s32 %v60237, %v60225 (stack39)
        %v60243 = vshll.u32 %v60237, 17 (stack44)
        %v60244 = vshrl.u32 %v60237, 15 (stack45)
        %v60245 = vor.u32 %v60244, %v60243 (stack46)
        %v60246 = vxor.u32 %v60245, %v60241 (stack47)
        %v60249 = vadd.s32 %v60246, %v60241 (stack39)
        %v60251 = vshll.u32 %v60246, 29 (stack44)
        %v60252 = vshrl.u32 %v60246, 3 (stack45)
        %v60253 = vor.u32 %v60252, %v60251 (stack46)
        %v60254 = vxor.u32 %v60253, %v60249 (stack47)
        %v60257 = vadd.s32 %v60254, %v60249 (stack39)
        %v60259 = vshll.u32 %v60254, 16 (stack44)
        %v60260 = vshrl.u32 %v60254, 16 (stack45)
        %v60261 = vor.u32 %v60260, %v60259 (stack46)
        %v60262 = vxor.u32 %v60261, %v60257 (stack47)
        %v60265 = vadd.s32 %v60262, %v60257 (stack39)
        %v60269 = vadd.s32 %v60265, %v8 (stack39)
        %v60271 = vshll.u32 %v60262, 24 (stack44)
        %v60272 = vshrl.u32 %v60262, 8 (stack45)
        %v60273 = vor.u32 %v60272, %v60271 (stack46)
        %v60274 = vxor.u32 %v60273, %v60265 (stack47)
        %v60277 = vadd.s32 %v60274, %v10 (stack39)
        %v60281 = vadd.s32 2, %v60277 (stack39)
        %v60285 = vadd.s32 %v60281, %v60269 (stack39)
        %v60287 = vshll.u32 %v60281, 13 (stack44)
        %v60288 = vshrl.u32 %v60281, 19 (stack45)
        %v60289 = vor.u32 %v60288, %v60287 (stack46)
        %v60290 = vxor.u32 %v60289, %v60285 (stack47)
        %v60293 = vadd.s32 %v60290, %v60285 (stack39)
        %v60295 = vshll.u32 %v60290, 15 (stack44)
        %v60296 = vshrl.u32 %v60290, 17 (stack45)
        %v60297 = vor.u32 %v60296, %v60295 (stack46)
        %v60298 = vxor.u32 %v60297, %v60293 (stack47)
        %v60301 = vadd.s32 %v60298, %v60293 (stack39)
        %v60303 = vshll.u32 %v60298, 26 (stack44)
        %v60304 = vshrl.u32 %v60298, 6 (stack45)
        %v60305 = vor.u32 %v60304, %v60303 (stack46)
        %v60306 = vxor.u32 %v60305, %v60301 (stack47)
        %v60309 = vadd.s32 %v60306, %v60301 (stack39)
        %v60313 = vadd.s32 %v60309, %v10 (stack39)
        %v60315 = vshll.u32 %v60306, 6 (stack44)
        %v60316 = vshrl.u32 %v60306, 26 (stack45)
        %v60317 = vor.u32 %v60316, %v60315 (stack46)
        %v60318 = vxor.u32 %v60317, %v60309 (stack47)
        %v60321 = vadd.s32 %v60318, %v9 (stack39)
        %v60325 = vadd.s32 3, %v60321 (stack39)
        %v60329 = vadd.s32 %v60325, %v60313 (stack39)
        %v60331 = vshll.u32 %v60325, 17 (stack44)
        %v60332 = vshrl.u32 %v60325, 15 (stack45)
        %v60333 = vor.u32 %v60332, %v60331 (stack46)
        %v60334 = vxor.u32 %v60333, %v60329 (stack47)
        %v60337 = vadd.s32 %v60334, %v60329 (stack39)
        %v60339 = vshll.u32 %v60334, 29 (stack44)
        %v60340 = vshrl.u32 %v60334, 3 (stack45)
        %v60341 = vor.u32 %v60340, %v60339 (stack46)
        %v60342 = vxor.u32 %v60341, %v60337 (stack47)
        %v60345 = vadd.s32 %v60342, %v60337 (stack39)
        %v60347 = vshll.u32 %v60342, 16 (stack44)
        %v60348 = vshrl.u32 %v60342, 16 (stack45)
        %v60349 = vor.u32 %v60348, %v60347 (stack46)
        %v60350 = vxor.u32 %v60349, %v60345 (stack47)
        %v60353 = vadd.s32 %v60350, %v60345 (stack39)
        %v60357 = vadd.s32 %v60353, %v9 (stack39)
        %v60359 = vshll.u32 %v60350, 24 (stack44)
        %v60360 = vshrl.u32 %v60350, 8 (stack45)
        %v60361 = vor.u32 %v60360, %v60359 (stack46)
        %v60362 = vxor.u32 %v60361, %v60353 (stack47)
        %v60365 = vadd.s32 %v60362, %v8 (stack39)
        %v60369 = vadd.s32 4, %v60365 (stack39)
        %v60373 = vadd.s32 %v60369, %v60357 (stack39)
        %v60375 = vshll.u32 %v60369, 13 (stack44)
        %v60376 = vshrl.u32 %v60369, 19 (stack45)
        %v60377 = vor.u32 %v60376, %v60375 (stack46)
        %v60378 = vxor.u32 %v60377, %v60373 (stack47)
        %v60381 = vadd.s32 %v60378, %v60373 (stack39)
        %v60383 = vshll.u32 %v60378, 15 (stack44)
        %v60384 = vshrl.u32 %v60378, 17 (stack45)
        %v60385 = vor.u32 %v60384, %v60383 (stack46)
        %v60386 = vxor.u32 %v60385, %v60381 (stack47)
        %v60389 = vadd.s32 %v60386, %v60381 (stack39)
        %v60391 = vshll.u32 %v60386, 26 (stack44)
        %v60392 = vshrl.u32 %v60386, 6 (stack45)
        %v60393 = vor.u32 %v60392, %v60391 (stack46)
        %v60394 = vxor.u32 %v60393, %v60389 (stack47)
        %v60397 = vadd.s32 %v60394, %v60389 (stack39)
        %v60401 = vadd.s32 %v60397, %v8 (stack39)
        %v60403 = vshll.u32 %v60394, 6 (stack44)
        %v60404 = vshrl.u32 %v60394, 26 (stack45)
        %v60405 = vor.u32 %v60404, %v60403 (stack46)
        %v60406 = vxor.u32 %v60405, %v60397 (stack47)
        %v60409 = vadd.s32 %v60406, %v10 (stack39)
        %v60413 = vadd.s32 5, %v60409 (stack39)
        %v60415 = vxor.u32 %v60413, %v60401 (stack47)
        %v60416 = vand.u32.u8 255, %v60415 (stack48)
        %v60417 = vand.u32 65535, %v60416 (stack49)
        %v60418 = vshrl.u32 %v60417, 1 (stack50)
        %v60419 = vor.u32 16256, %v60418 (stack46)
        %v60420 = vand.u32.u16 65535, %v60419 (stack51)
        %v120068 = vadd.low.f32.bf16 -1.0, %v60420 (stack52)
        %v60429 = vmul.f32 2.0, %v120068 (stack53)
        %v60433 = vadd.f32 -0.99609375, %v60429 (stack52)
        %v60437 = vmax.f32 %v60433, -0.99609375 (stack54)
        %v60439 = vand.u32 2147483647, %v60437 (stack55)
        %vm60442 = vcmp.eq.f32.partialorder %v60439, 1.0 (stack56)
        %v60447 = vmul.f32 inf, %v60437 (stack53)
        %v60449 = vxor.u32 2147483648, %v60437 (stack57)
        %v60452 = vmul.f32 %v60449, %v60437 (stack53)
        %v60454 = vadd.f32 1.0, %v60452 (stack58)
        %v60455 = vlog2.pop %v60454 (stack59)
        %v60456 = vmul.f32 0.6931472, %v60455 (stack60)
        %v60457 = vmul.f32 -0.5, %v60452 (stack61)
        %v60458 = vadd.f32 1.0, %v60457 (stack62)
        %v60459 = vmul.f32 %v60458, %v60452 (stack63)
        %v60460 = vand.u32 2147483647, %v60452 (stack64)
        %vm60461 = vcmp.lt.f32.partialorder %v60460, 0.0004427343 (stack65)
        %v60462 = vsel /*vm=*/%vm60461, /*on_true_vy=*/%v60459, /*on_false_vx=*/%v60456 (stack66)
        %v60463 = vxor.u32 2147483648, %v60462 (stack57)
        %vm60466 = vcmp.lt.f32.partialorder %v60463, 5.0 (stack56)
        %v60471 = vsel /*vm=*/%vm60466, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v60475 = vsel /*vm=*/%vm60466, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v60479 = vsel /*vm=*/%vm60466, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v60483 = vsel /*vm=*/%vm60466, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v60487 = vsel /*vm=*/%vm60466, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v60491 = vsel /*vm=*/%vm60466, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v60495 = vsel /*vm=*/%vm60466, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v60499 = vsel /*vm=*/%vm60466, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v60503 = vsel /*vm=*/%vm60466, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v60507 = vadd.f32 -2.5, %v60463 (stack52)
        %v60509 = vrsqrt.pop %v60463 (stack67)
        %v60510 = vmul.f32 %v60509, %v60463 (stack68)
        %vm60511 = vcmp.eq.f32.partialorder %v60463, inf (stack69)
        %v60512 = vsel /*vm=*/%vm60511, /*on_true_vy=*/%v60463, /*on_false_vx=*/%v60510 (stack70)
        %vm60513 = vcmp.eq.f32.partialorder %v60463, 0.0 (stack71)
        %v60514 = vand.u32 2147483648, %v60463 (stack72)
        %v60515 = vsel /*vm=*/%vm60513, /*on_true_vy=*/%v60514, /*on_false_vx=*/%v60512 (stack73)
        %v60518 = vadd.f32 -3.0, %v60515 (stack52)
        %v60522 = vsel /*vm=*/%vm60466, /*on_true_vy=*/%v60507, /*on_false_vx=*/%v60518 (stack43)
        %v60526 = vmul.f32 %v60522, %v60503 (stack53)
        %v60530 = vadd.f32 %v60526, %v60499 (stack52)
        %v60534 = vmul.f32 %v60530, %v60522 (stack53)
        %v60538 = vadd.f32 %v60534, %v60495 (stack52)
        %v60542 = vmul.f32 %v60538, %v60522 (stack53)
        %v60546 = vadd.f32 %v60542, %v60491 (stack52)
        %v60550 = vmul.f32 %v60546, %v60522 (stack53)
        %v60554 = vadd.f32 %v60550, %v60487 (stack52)
        %v60558 = vmul.f32 %v60554, %v60522 (stack53)
        %v60562 = vadd.f32 %v60558, %v60483 (stack52)
        %v60566 = vmul.f32 %v60562, %v60522 (stack53)
        %v60570 = vadd.f32 %v60566, %v60479 (stack52)
        %v60574 = vmul.f32 %v60570, %v60522 (stack53)
        %v60578 = vadd.f32 %v60574, %v60475 (stack52)
        %v60582 = vmul.f32 %v60578, %v60522 (stack53)
        %v60586 = vadd.f32 %v60582, %v60471 (stack52)
        %v60590 = vmul.f32 %v60586, %v60437 (stack53)
        %v60594 = vsel /*vm=*/%vm60442, /*on_true_vy=*/%v60447, /*on_false_vx=*/%v60590 (stack43)
        %v60598 = vmul.f32 1.4140625, %v60594 (stack53)
        %v60601 = vpack.c.bf16 0.0, %v60598 (stack74)
        %120069 = vst [vmem:[%s280 + $0x40] sm:$0xf] /*vst_source=*/%v60601 (stack75)
        %v60605 = vadd.s32 %v60141, %v894 (stack39)
        %v60615 = vadd.s32 %v60605, %v415 (stack39)
        %vm60619 = vcmp.lt.u32.totalorder %v60615, %v60605 (stack42)
        %vm60624 = vcmp.lt.u32.totalorder %v60605, %v894 (stack42)
        %v60629 = vadd.s32 %v60124, %v881 (stack39)
        %v60633 = vadd.s32 1, %v60629 (stack39)
        %v60637 = vsel /*vm=*/%vm60624, /*on_true_vy=*/%v60633, /*on_false_vx=*/%v60629 (stack43)
        %v60641 = vadd.s32 1, %v60637 (stack39)
        %v60645 = vsel /*vm=*/%vm60619, /*on_true_vy=*/%v60641, /*on_false_vx=*/%v60637 (stack43)
        %v60650 = vadd.s32 %v60645, %v10 (stack39)
        %v60654 = vadd.s32 %v60615, %v9 (stack39)
        %v60658 = vadd.s32 %v60654, %v60650 (stack39)
        %v60660 = vshll.u32 %v60654, 13 (stack44)
        %v60661 = vshrl.u32 %v60654, 19 (stack45)
        %v60662 = vor.u32 %v60661, %v60660 (stack46)
        %v60663 = vxor.u32 %v60662, %v60658 (stack47)
        %v60666 = vadd.s32 %v60663, %v60658 (stack39)
        %v60668 = vshll.u32 %v60663, 15 (stack44)
        %v60669 = vshrl.u32 %v60663, 17 (stack45)
        %v60670 = vor.u32 %v60669, %v60668 (stack46)
        %v60671 = vxor.u32 %v60670, %v60666 (stack47)
        %v60674 = vadd.s32 %v60671, %v60666 (stack39)
        %v60676 = vshll.u32 %v60671, 26 (stack44)
        %v60677 = vshrl.u32 %v60671, 6 (stack45)
        %v60678 = vor.u32 %v60677, %v60676 (stack46)
        %v60679 = vxor.u32 %v60678, %v60674 (stack47)
        %v60682 = vadd.s32 %v60679, %v60674 (stack39)
        %v60686 = vadd.s32 %v60682, %v9 (stack39)
        %v60688 = vshll.u32 %v60679, 6 (stack44)
        %v60689 = vshrl.u32 %v60679, 26 (stack45)
        %v60690 = vor.u32 %v60689, %v60688 (stack46)
        %v60691 = vxor.u32 %v60690, %v60682 (stack47)
        %v60694 = vadd.s32 %v60691, %v8 (stack39)
        %v60698 = vadd.s32 1, %v60694 (stack39)
        %v60702 = vadd.s32 %v60698, %v60686 (stack39)
        %v60704 = vshll.u32 %v60698, 17 (stack44)
        %v60705 = vshrl.u32 %v60698, 15 (stack45)
        %v60706 = vor.u32 %v60705, %v60704 (stack46)
        %v60707 = vxor.u32 %v60706, %v60702 (stack47)
        %v60710 = vadd.s32 %v60707, %v60702 (stack39)
        %v60712 = vshll.u32 %v60707, 29 (stack44)
        %v60713 = vshrl.u32 %v60707, 3 (stack45)
        %v60714 = vor.u32 %v60713, %v60712 (stack46)
        %v60715 = vxor.u32 %v60714, %v60710 (stack47)
        %v60718 = vadd.s32 %v60715, %v60710 (stack39)
        %v60720 = vshll.u32 %v60715, 16 (stack44)
        %v60721 = vshrl.u32 %v60715, 16 (stack45)
        %v60722 = vor.u32 %v60721, %v60720 (stack46)
        %v60723 = vxor.u32 %v60722, %v60718 (stack47)
        %v60726 = vadd.s32 %v60723, %v60718 (stack39)
        %v60730 = vadd.s32 %v60726, %v8 (stack39)
        %v60732 = vshll.u32 %v60723, 24 (stack44)
        %v60733 = vshrl.u32 %v60723, 8 (stack45)
        %v60734 = vor.u32 %v60733, %v60732 (stack46)
        %v60735 = vxor.u32 %v60734, %v60726 (stack47)
        %v60738 = vadd.s32 %v60735, %v10 (stack39)
        %v60742 = vadd.s32 2, %v60738 (stack39)
        %v60746 = vadd.s32 %v60742, %v60730 (stack39)
        %v60748 = vshll.u32 %v60742, 13 (stack44)
        %v60749 = vshrl.u32 %v60742, 19 (stack45)
        %v60750 = vor.u32 %v60749, %v60748 (stack46)
        %v60751 = vxor.u32 %v60750, %v60746 (stack47)
        %v60754 = vadd.s32 %v60751, %v60746 (stack39)
        %v60756 = vshll.u32 %v60751, 15 (stack44)
        %v60757 = vshrl.u32 %v60751, 17 (stack45)
        %v60758 = vor.u32 %v60757, %v60756 (stack46)
        %v60759 = vxor.u32 %v60758, %v60754 (stack47)
        %v60762 = vadd.s32 %v60759, %v60754 (stack39)
        %v60764 = vshll.u32 %v60759, 26 (stack44)
        %v60765 = vshrl.u32 %v60759, 6 (stack45)
        %v60766 = vor.u32 %v60765, %v60764 (stack46)
        %v60767 = vxor.u32 %v60766, %v60762 (stack47)
        %v60770 = vadd.s32 %v60767, %v60762 (stack39)
        %v60774 = vadd.s32 %v60770, %v10 (stack39)
        %v60776 = vshll.u32 %v60767, 6 (stack44)
        %v60777 = vshrl.u32 %v60767, 26 (stack45)
        %v60778 = vor.u32 %v60777, %v60776 (stack46)
        %v60779 = vxor.u32 %v60778, %v60770 (stack47)
        %v60782 = vadd.s32 %v60779, %v9 (stack39)
        %v60786 = vadd.s32 3, %v60782 (stack39)
        %v60790 = vadd.s32 %v60786, %v60774 (stack39)
        %v60792 = vshll.u32 %v60786, 17 (stack44)
        %v60793 = vshrl.u32 %v60786, 15 (stack45)
        %v60794 = vor.u32 %v60793, %v60792 (stack46)
        %v60795 = vxor.u32 %v60794, %v60790 (stack47)
        %v60798 = vadd.s32 %v60795, %v60790 (stack39)
        %v60800 = vshll.u32 %v60795, 29 (stack44)
        %v60801 = vshrl.u32 %v60795, 3 (stack45)
        %v60802 = vor.u32 %v60801, %v60800 (stack46)
        %v60803 = vxor.u32 %v60802, %v60798 (stack47)
        %v60806 = vadd.s32 %v60803, %v60798 (stack39)
        %v60808 = vshll.u32 %v60803, 16 (stack44)
        %v60809 = vshrl.u32 %v60803, 16 (stack45)
        %v60810 = vor.u32 %v60809, %v60808 (stack46)
        %v60811 = vxor.u32 %v60810, %v60806 (stack47)
        %v60814 = vadd.s32 %v60811, %v60806 (stack39)
        %v60818 = vadd.s32 %v60814, %v9 (stack39)
        %v60820 = vshll.u32 %v60811, 24 (stack44)
        %v60821 = vshrl.u32 %v60811, 8 (stack45)
        %v60822 = vor.u32 %v60821, %v60820 (stack46)
        %v60823 = vxor.u32 %v60822, %v60814 (stack47)
        %v60826 = vadd.s32 %v60823, %v8 (stack39)
        %v60830 = vadd.s32 4, %v60826 (stack39)
        %v60834 = vadd.s32 %v60830, %v60818 (stack39)
        %v60836 = vshll.u32 %v60830, 13 (stack44)
        %v60837 = vshrl.u32 %v60830, 19 (stack45)
        %v60838 = vor.u32 %v60837, %v60836 (stack46)
        %v60839 = vxor.u32 %v60838, %v60834 (stack47)
        %v60842 = vadd.s32 %v60839, %v60834 (stack39)
        %v60844 = vshll.u32 %v60839, 15 (stack44)
        %v60845 = vshrl.u32 %v60839, 17 (stack45)
        %v60846 = vor.u32 %v60845, %v60844 (stack46)
        %v60847 = vxor.u32 %v60846, %v60842 (stack47)
        %v60850 = vadd.s32 %v60847, %v60842 (stack39)
        %v60852 = vshll.u32 %v60847, 26 (stack44)
        %v60853 = vshrl.u32 %v60847, 6 (stack45)
        %v60854 = vor.u32 %v60853, %v60852 (stack46)
        %v60855 = vxor.u32 %v60854, %v60850 (stack47)
        %v60858 = vadd.s32 %v60855, %v60850 (stack39)
        %v60862 = vadd.s32 %v60858, %v8 (stack39)
        %v60864 = vshll.u32 %v60855, 6 (stack44)
        %v60865 = vshrl.u32 %v60855, 26 (stack45)
        %v60866 = vor.u32 %v60865, %v60864 (stack46)
        %v60867 = vxor.u32 %v60866, %v60858 (stack47)
        %v60870 = vadd.s32 %v60867, %v10 (stack39)
        %v60874 = vadd.s32 5, %v60870 (stack39)
        %v60876 = vxor.u32 %v60874, %v60862 (stack47)
        %v60877 = vand.u32.u8 255, %v60876 (stack48)
        %v60878 = vand.u32 65535, %v60877 (stack49)
        %v60879 = vshrl.u32 %v60878, 1 (stack50)
        %v60880 = vor.u32 16256, %v60879 (stack46)
        %v60881 = vand.u32.u16 65535, %v60880 (stack51)
        %v120070 = vadd.low.f32.bf16 -1.0, %v60881 (stack52)
        %v60890 = vmul.f32 2.0, %v120070 (stack53)
        %v60894 = vadd.f32 -0.99609375, %v60890 (stack52)
        %v60898 = vmax.f32 %v60894, -0.99609375 (stack54)
        %v60900 = vand.u32 2147483647, %v60898 (stack55)
        %vm60903 = vcmp.eq.f32.partialorder %v60900, 1.0 (stack56)
        %v60908 = vmul.f32 inf, %v60898 (stack53)
        %v60910 = vxor.u32 2147483648, %v60898 (stack57)
        %v60913 = vmul.f32 %v60910, %v60898 (stack53)
        %v60915 = vadd.f32 1.0, %v60913 (stack58)
        %v60916 = vlog2.pop %v60915 (stack59)
        %v60917 = vmul.f32 0.6931472, %v60916 (stack60)
        %v60918 = vmul.f32 -0.5, %v60913 (stack61)
        %v60919 = vadd.f32 1.0, %v60918 (stack62)
        %v60920 = vmul.f32 %v60919, %v60913 (stack63)
        %v60921 = vand.u32 2147483647, %v60913 (stack64)
        %vm60922 = vcmp.lt.f32.partialorder %v60921, 0.0004427343 (stack65)
        %v60923 = vsel /*vm=*/%vm60922, /*on_true_vy=*/%v60920, /*on_false_vx=*/%v60917 (stack66)
        %v60924 = vxor.u32 2147483648, %v60923 (stack57)
        %vm60927 = vcmp.lt.f32.partialorder %v60924, 5.0 (stack56)
        %v60932 = vsel /*vm=*/%vm60927, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v60936 = vsel /*vm=*/%vm60927, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v60940 = vsel /*vm=*/%vm60927, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v60944 = vsel /*vm=*/%vm60927, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v60948 = vsel /*vm=*/%vm60927, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v60952 = vsel /*vm=*/%vm60927, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v60956 = vsel /*vm=*/%vm60927, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v60960 = vsel /*vm=*/%vm60927, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v60964 = vsel /*vm=*/%vm60927, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v60968 = vadd.f32 -2.5, %v60924 (stack52)
        %v60970 = vrsqrt.pop %v60924 (stack67)
        %v60971 = vmul.f32 %v60970, %v60924 (stack68)
        %vm60972 = vcmp.eq.f32.partialorder %v60924, inf (stack69)
        %v60973 = vsel /*vm=*/%vm60972, /*on_true_vy=*/%v60924, /*on_false_vx=*/%v60971 (stack70)
        %vm60974 = vcmp.eq.f32.partialorder %v60924, 0.0 (stack71)
        %v60975 = vand.u32 2147483648, %v60924 (stack72)
        %v60976 = vsel /*vm=*/%vm60974, /*on_true_vy=*/%v60975, /*on_false_vx=*/%v60973 (stack73)
        %v60979 = vadd.f32 -3.0, %v60976 (stack52)
        %v60983 = vsel /*vm=*/%vm60927, /*on_true_vy=*/%v60968, /*on_false_vx=*/%v60979 (stack43)
        %v60987 = vmul.f32 %v60983, %v60964 (stack53)
        %v60991 = vadd.f32 %v60987, %v60960 (stack52)
        %v60995 = vmul.f32 %v60991, %v60983 (stack53)
        %v60999 = vadd.f32 %v60995, %v60956 (stack52)
        %v61003 = vmul.f32 %v60999, %v60983 (stack53)
        %v61007 = vadd.f32 %v61003, %v60952 (stack52)
        %v61011 = vmul.f32 %v61007, %v60983 (stack53)
        %v61015 = vadd.f32 %v61011, %v60948 (stack52)
        %v61019 = vmul.f32 %v61015, %v60983 (stack53)
        %v61023 = vadd.f32 %v61019, %v60944 (stack52)
        %v61027 = vmul.f32 %v61023, %v60983 (stack53)
        %v61031 = vadd.f32 %v61027, %v60940 (stack52)
        %v61035 = vmul.f32 %v61031, %v60983 (stack53)
        %v61039 = vadd.f32 %v61035, %v60936 (stack52)
        %v61043 = vmul.f32 %v61039, %v60983 (stack53)
        %v61047 = vadd.f32 %v61043, %v60932 (stack52)
        %v61051 = vmul.f32 %v61047, %v60898 (stack53)
        %v61055 = vsel /*vm=*/%vm60903, /*on_true_vy=*/%v60908, /*on_false_vx=*/%v61051 (stack43)
        %v61059 = vmul.f32 1.4140625, %v61055 (stack53)
        %v61062 = vpack.c.bf16 0.0, %v61059 (stack74)
        %120071 = vst [vmem:[%s280 + $0xc0] sm:$0xf] /*vst_source=*/%v61062 (stack75)
        %v61066 = vadd.s32 %v60141, %v1381 (stack39)
        %v61076 = vadd.s32 %v61066, %v415 (stack39)
        %vm61080 = vcmp.lt.u32.totalorder %v61076, %v61066 (stack42)
        %vm61085 = vcmp.lt.u32.totalorder %v61066, %v1381 (stack42)
        %v61090 = vadd.s32 %v60124, %v1368 (stack39)
        %v61094 = vadd.s32 1, %v61090 (stack39)
        %v61098 = vsel /*vm=*/%vm61085, /*on_true_vy=*/%v61094, /*on_false_vx=*/%v61090 (stack43)
        %v61102 = vadd.s32 1, %v61098 (stack39)
        %v61106 = vsel /*vm=*/%vm61080, /*on_true_vy=*/%v61102, /*on_false_vx=*/%v61098 (stack43)
        %v61111 = vadd.s32 %v61106, %v10 (stack39)
        %v61115 = vadd.s32 %v61076, %v9 (stack39)
        %v61119 = vadd.s32 %v61115, %v61111 (stack39)
        %v61121 = vshll.u32 %v61115, 13 (stack44)
        %v61122 = vshrl.u32 %v61115, 19 (stack45)
        %v61123 = vor.u32 %v61122, %v61121 (stack46)
        %v61124 = vxor.u32 %v61123, %v61119 (stack47)
        %v61127 = vadd.s32 %v61124, %v61119 (stack39)
        %v61129 = vshll.u32 %v61124, 15 (stack44)
        %v61130 = vshrl.u32 %v61124, 17 (stack45)
        %v61131 = vor.u32 %v61130, %v61129 (stack46)
        %v61132 = vxor.u32 %v61131, %v61127 (stack47)
        %v61135 = vadd.s32 %v61132, %v61127 (stack39)
        %v61137 = vshll.u32 %v61132, 26 (stack44)
        %v61138 = vshrl.u32 %v61132, 6 (stack45)
        %v61139 = vor.u32 %v61138, %v61137 (stack46)
        %v61140 = vxor.u32 %v61139, %v61135 (stack47)
        %v61143 = vadd.s32 %v61140, %v61135 (stack39)
        %v61147 = vadd.s32 %v61143, %v9 (stack39)
        %v61149 = vshll.u32 %v61140, 6 (stack44)
        %v61150 = vshrl.u32 %v61140, 26 (stack45)
        %v61151 = vor.u32 %v61150, %v61149 (stack46)
        %v61152 = vxor.u32 %v61151, %v61143 (stack47)
        %v61155 = vadd.s32 %v61152, %v8 (stack39)
        %v61159 = vadd.s32 1, %v61155 (stack39)
        %v61163 = vadd.s32 %v61159, %v61147 (stack39)
        %v61165 = vshll.u32 %v61159, 17 (stack44)
        %v61166 = vshrl.u32 %v61159, 15 (stack45)
        %v61167 = vor.u32 %v61166, %v61165 (stack46)
        %v61168 = vxor.u32 %v61167, %v61163 (stack47)
        %v61171 = vadd.s32 %v61168, %v61163 (stack39)
        %v61173 = vshll.u32 %v61168, 29 (stack44)
        %v61174 = vshrl.u32 %v61168, 3 (stack45)
        %v61175 = vor.u32 %v61174, %v61173 (stack46)
        %v61176 = vxor.u32 %v61175, %v61171 (stack47)
        %v61179 = vadd.s32 %v61176, %v61171 (stack39)
        %v61181 = vshll.u32 %v61176, 16 (stack44)
        %v61182 = vshrl.u32 %v61176, 16 (stack45)
        %v61183 = vor.u32 %v61182, %v61181 (stack46)
        %v61184 = vxor.u32 %v61183, %v61179 (stack47)
        %v61187 = vadd.s32 %v61184, %v61179 (stack39)
        %v61191 = vadd.s32 %v61187, %v8 (stack39)
        %v61193 = vshll.u32 %v61184, 24 (stack44)
        %v61194 = vshrl.u32 %v61184, 8 (stack45)
        %v61195 = vor.u32 %v61194, %v61193 (stack46)
        %v61196 = vxor.u32 %v61195, %v61187 (stack47)
        %v61199 = vadd.s32 %v61196, %v10 (stack39)
        %v61203 = vadd.s32 2, %v61199 (stack39)
        %v61207 = vadd.s32 %v61203, %v61191 (stack39)
        %v61209 = vshll.u32 %v61203, 13 (stack44)
        %v61210 = vshrl.u32 %v61203, 19 (stack45)
        %v61211 = vor.u32 %v61210, %v61209 (stack46)
        %v61212 = vxor.u32 %v61211, %v61207 (stack47)
        %v61215 = vadd.s32 %v61212, %v61207 (stack39)
        %v61217 = vshll.u32 %v61212, 15 (stack44)
        %v61218 = vshrl.u32 %v61212, 17 (stack45)
        %v61219 = vor.u32 %v61218, %v61217 (stack46)
        %v61220 = vxor.u32 %v61219, %v61215 (stack47)
        %v61223 = vadd.s32 %v61220, %v61215 (stack39)
        %v61225 = vshll.u32 %v61220, 26 (stack44)
        %v61226 = vshrl.u32 %v61220, 6 (stack45)
        %v61227 = vor.u32 %v61226, %v61225 (stack46)
        %v61228 = vxor.u32 %v61227, %v61223 (stack47)
        %v61231 = vadd.s32 %v61228, %v61223 (stack39)
        %v61235 = vadd.s32 %v61231, %v10 (stack39)
        %v61237 = vshll.u32 %v61228, 6 (stack44)
        %v61238 = vshrl.u32 %v61228, 26 (stack45)
        %v61239 = vor.u32 %v61238, %v61237 (stack46)
        %v61240 = vxor.u32 %v61239, %v61231 (stack47)
        %v61243 = vadd.s32 %v61240, %v9 (stack39)
        %v61247 = vadd.s32 3, %v61243 (stack39)
        %v61251 = vadd.s32 %v61247, %v61235 (stack39)
        %v61253 = vshll.u32 %v61247, 17 (stack44)
        %v61254 = vshrl.u32 %v61247, 15 (stack45)
        %v61255 = vor.u32 %v61254, %v61253 (stack46)
        %v61256 = vxor.u32 %v61255, %v61251 (stack47)
        %v61259 = vadd.s32 %v61256, %v61251 (stack39)
        %v61261 = vshll.u32 %v61256, 29 (stack44)
        %v61262 = vshrl.u32 %v61256, 3 (stack45)
        %v61263 = vor.u32 %v61262, %v61261 (stack46)
        %v61264 = vxor.u32 %v61263, %v61259 (stack47)
        %v61267 = vadd.s32 %v61264, %v61259 (stack39)
        %v61269 = vshll.u32 %v61264, 16 (stack44)
        %v61270 = vshrl.u32 %v61264, 16 (stack45)
        %v61271 = vor.u32 %v61270, %v61269 (stack46)
        %v61272 = vxor.u32 %v61271, %v61267 (stack47)
        %v61275 = vadd.s32 %v61272, %v61267 (stack39)
        %v61279 = vadd.s32 %v61275, %v9 (stack39)
        %v61281 = vshll.u32 %v61272, 24 (stack44)
        %v61282 = vshrl.u32 %v61272, 8 (stack45)
        %v61283 = vor.u32 %v61282, %v61281 (stack46)
        %v61284 = vxor.u32 %v61283, %v61275 (stack47)
        %v61287 = vadd.s32 %v61284, %v8 (stack39)
        %v61291 = vadd.s32 4, %v61287 (stack39)
        %v61295 = vadd.s32 %v61291, %v61279 (stack39)
        %v61297 = vshll.u32 %v61291, 13 (stack44)
        %v61298 = vshrl.u32 %v61291, 19 (stack45)
        %v61299 = vor.u32 %v61298, %v61297 (stack46)
        %v61300 = vxor.u32 %v61299, %v61295 (stack47)
        %v61303 = vadd.s32 %v61300, %v61295 (stack39)
        %v61305 = vshll.u32 %v61300, 15 (stack44)
        %v61306 = vshrl.u32 %v61300, 17 (stack45)
        %v61307 = vor.u32 %v61306, %v61305 (stack46)
        %v61308 = vxor.u32 %v61307, %v61303 (stack47)
        %v61311 = vadd.s32 %v61308, %v61303 (stack39)
        %v61313 = vshll.u32 %v61308, 26 (stack44)
        %v61314 = vshrl.u32 %v61308, 6 (stack45)
        %v61315 = vor.u32 %v61314, %v61313 (stack46)
        %v61316 = vxor.u32 %v61315, %v61311 (stack47)
        %v61319 = vadd.s32 %v61316, %v61311 (stack39)
        %v61323 = vadd.s32 %v61319, %v8 (stack39)
        %v61325 = vshll.u32 %v61316, 6 (stack44)
        %v61326 = vshrl.u32 %v61316, 26 (stack45)
        %v61327 = vor.u32 %v61326, %v61325 (stack46)
        %v61328 = vxor.u32 %v61327, %v61319 (stack47)
        %v61331 = vadd.s32 %v61328, %v10 (stack39)
        %v61335 = vadd.s32 5, %v61331 (stack39)
        %v61337 = vxor.u32 %v61335, %v61323 (stack47)
        %v61338 = vand.u32.u8 255, %v61337 (stack48)
        %v61339 = vand.u32 65535, %v61338 (stack49)
        %v61340 = vshrl.u32 %v61339, 1 (stack50)
        %v61341 = vor.u32 16256, %v61340 (stack46)
        %v61342 = vand.u32.u16 65535, %v61341 (stack51)
        %v120072 = vadd.low.f32.bf16 -1.0, %v61342 (stack52)
        %v61351 = vmul.f32 2.0, %v120072 (stack53)
        %v61355 = vadd.f32 -0.99609375, %v61351 (stack52)
        %v61359 = vmax.f32 %v61355, -0.99609375 (stack54)
        %v61361 = vand.u32 2147483647, %v61359 (stack55)
        %vm61364 = vcmp.eq.f32.partialorder %v61361, 1.0 (stack56)
        %v61369 = vmul.f32 inf, %v61359 (stack53)
        %v61371 = vxor.u32 2147483648, %v61359 (stack57)
        %v61374 = vmul.f32 %v61371, %v61359 (stack53)
        %v61376 = vadd.f32 1.0, %v61374 (stack58)
        %v61377 = vlog2.pop %v61376 (stack59)
        %v61378 = vmul.f32 0.6931472, %v61377 (stack60)
        %v61379 = vmul.f32 -0.5, %v61374 (stack61)
        %v61380 = vadd.f32 1.0, %v61379 (stack62)
        %v61381 = vmul.f32 %v61380, %v61374 (stack63)
        %v61382 = vand.u32 2147483647, %v61374 (stack64)
        %vm61383 = vcmp.lt.f32.partialorder %v61382, 0.0004427343 (stack65)
        %v61384 = vsel /*vm=*/%vm61383, /*on_true_vy=*/%v61381, /*on_false_vx=*/%v61378 (stack66)
        %v61385 = vxor.u32 2147483648, %v61384 (stack57)
        %vm61388 = vcmp.lt.f32.partialorder %v61385, 5.0 (stack56)
        %v61393 = vsel /*vm=*/%vm61388, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v61397 = vsel /*vm=*/%vm61388, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v61401 = vsel /*vm=*/%vm61388, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v61405 = vsel /*vm=*/%vm61388, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v61409 = vsel /*vm=*/%vm61388, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v61413 = vsel /*vm=*/%vm61388, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v61417 = vsel /*vm=*/%vm61388, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v61421 = vsel /*vm=*/%vm61388, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v61425 = vsel /*vm=*/%vm61388, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v61429 = vadd.f32 -2.5, %v61385 (stack52)
        %v61431 = vrsqrt.pop %v61385 (stack67)
        %v61432 = vmul.f32 %v61431, %v61385 (stack68)
        %vm61433 = vcmp.eq.f32.partialorder %v61385, inf (stack69)
        %v61434 = vsel /*vm=*/%vm61433, /*on_true_vy=*/%v61385, /*on_false_vx=*/%v61432 (stack70)
        %vm61435 = vcmp.eq.f32.partialorder %v61385, 0.0 (stack71)
        %v61436 = vand.u32 2147483648, %v61385 (stack72)
        %v61437 = vsel /*vm=*/%vm61435, /*on_true_vy=*/%v61436, /*on_false_vx=*/%v61434 (stack73)
        %v61440 = vadd.f32 -3.0, %v61437 (stack52)
        %v61444 = vsel /*vm=*/%vm61388, /*on_true_vy=*/%v61429, /*on_false_vx=*/%v61440 (stack43)
        %v61448 = vmul.f32 %v61444, %v61425 (stack53)
        %v61452 = vadd.f32 %v61448, %v61421 (stack52)
        %v61456 = vmul.f32 %v61452, %v61444 (stack53)
        %v61460 = vadd.f32 %v61456, %v61417 (stack52)
        %v61464 = vmul.f32 %v61460, %v61444 (stack53)
        %v61468 = vadd.f32 %v61464, %v61413 (stack52)
        %v61472 = vmul.f32 %v61468, %v61444 (stack53)
        %v61476 = vadd.f32 %v61472, %v61409 (stack52)
        %v61480 = vmul.f32 %v61476, %v61444 (stack53)
        %v61484 = vadd.f32 %v61480, %v61405 (stack52)
        %v61488 = vmul.f32 %v61484, %v61444 (stack53)
        %v61492 = vadd.f32 %v61488, %v61401 (stack52)
        %v61496 = vmul.f32 %v61492, %v61444 (stack53)
        %v61500 = vadd.f32 %v61496, %v61397 (stack52)
        %v61504 = vmul.f32 %v61500, %v61444 (stack53)
        %v61508 = vadd.f32 %v61504, %v61393 (stack52)
        %v61512 = vmul.f32 %v61508, %v61359 (stack53)
        %v61516 = vsel /*vm=*/%vm61364, /*on_true_vy=*/%v61369, /*on_false_vx=*/%v61512 (stack43)
        %v61520 = vmul.f32 1.4140625, %v61516 (stack53)
        %v61523 = vpack.c.bf16 0.0, %v61520 (stack74)
        %120073 = vst [vmem:[%s280 + $0x140] sm:$0xf] /*vst_source=*/%v61523 (stack75)
        %v61527 = vadd.s32 %v60141, %v1868 (stack39)
        %v61537 = vadd.s32 %v61527, %v415 (stack39)
        %vm61541 = vcmp.lt.u32.totalorder %v61537, %v61527 (stack42)
        %vm61546 = vcmp.lt.u32.totalorder %v61527, %v1868 (stack42)
        %v61551 = vadd.s32 %v60124, %v1855 (stack39)
        %v61555 = vadd.s32 1, %v61551 (stack39)
        %v61559 = vsel /*vm=*/%vm61546, /*on_true_vy=*/%v61555, /*on_false_vx=*/%v61551 (stack43)
        %v61563 = vadd.s32 1, %v61559 (stack39)
        %v61567 = vsel /*vm=*/%vm61541, /*on_true_vy=*/%v61563, /*on_false_vx=*/%v61559 (stack43)
        %v61572 = vadd.s32 %v61567, %v10 (stack39)
        %v61576 = vadd.s32 %v61537, %v9 (stack39)
        %v61580 = vadd.s32 %v61576, %v61572 (stack39)
        %v61582 = vshll.u32 %v61576, 13 (stack44)
        %v61583 = vshrl.u32 %v61576, 19 (stack45)
        %v61584 = vor.u32 %v61583, %v61582 (stack46)
        %v61585 = vxor.u32 %v61584, %v61580 (stack47)
        %v61588 = vadd.s32 %v61585, %v61580 (stack39)
        %v61590 = vshll.u32 %v61585, 15 (stack44)
        %v61591 = vshrl.u32 %v61585, 17 (stack45)
        %v61592 = vor.u32 %v61591, %v61590 (stack46)
        %v61593 = vxor.u32 %v61592, %v61588 (stack47)
        %v61596 = vadd.s32 %v61593, %v61588 (stack39)
        %v61598 = vshll.u32 %v61593, 26 (stack44)
        %v61599 = vshrl.u32 %v61593, 6 (stack45)
        %v61600 = vor.u32 %v61599, %v61598 (stack46)
        %v61601 = vxor.u32 %v61600, %v61596 (stack47)
        %v61604 = vadd.s32 %v61601, %v61596 (stack39)
        %v61608 = vadd.s32 %v61604, %v9 (stack39)
        %v61610 = vshll.u32 %v61601, 6 (stack44)
        %v61611 = vshrl.u32 %v61601, 26 (stack45)
        %v61612 = vor.u32 %v61611, %v61610 (stack46)
        %v61613 = vxor.u32 %v61612, %v61604 (stack47)
        %v61616 = vadd.s32 %v61613, %v8 (stack39)
        %v61620 = vadd.s32 1, %v61616 (stack39)
        %v61624 = vadd.s32 %v61620, %v61608 (stack39)
        %v61626 = vshll.u32 %v61620, 17 (stack44)
        %v61627 = vshrl.u32 %v61620, 15 (stack45)
        %v61628 = vor.u32 %v61627, %v61626 (stack46)
        %v61629 = vxor.u32 %v61628, %v61624 (stack47)
        %v61632 = vadd.s32 %v61629, %v61624 (stack39)
        %v61634 = vshll.u32 %v61629, 29 (stack44)
        %v61635 = vshrl.u32 %v61629, 3 (stack45)
        %v61636 = vor.u32 %v61635, %v61634 (stack46)
        %v61637 = vxor.u32 %v61636, %v61632 (stack47)
        %v61640 = vadd.s32 %v61637, %v61632 (stack39)
        %v61642 = vshll.u32 %v61637, 16 (stack44)
        %v61643 = vshrl.u32 %v61637, 16 (stack45)
        %v61644 = vor.u32 %v61643, %v61642 (stack46)
        %v61645 = vxor.u32 %v61644, %v61640 (stack47)
        %v61648 = vadd.s32 %v61645, %v61640 (stack39)
        %v61652 = vadd.s32 %v61648, %v8 (stack39)
        %v61654 = vshll.u32 %v61645, 24 (stack44)
        %v61655 = vshrl.u32 %v61645, 8 (stack45)
        %v61656 = vor.u32 %v61655, %v61654 (stack46)
        %v61657 = vxor.u32 %v61656, %v61648 (stack47)
        %v61660 = vadd.s32 %v61657, %v10 (stack39)
        %v61664 = vadd.s32 2, %v61660 (stack39)
        %v61668 = vadd.s32 %v61664, %v61652 (stack39)
        %v61670 = vshll.u32 %v61664, 13 (stack44)
        %v61671 = vshrl.u32 %v61664, 19 (stack45)
        %v61672 = vor.u32 %v61671, %v61670 (stack46)
        %v61673 = vxor.u32 %v61672, %v61668 (stack47)
        %v61676 = vadd.s32 %v61673, %v61668 (stack39)
        %v61678 = vshll.u32 %v61673, 15 (stack44)
        %v61679 = vshrl.u32 %v61673, 17 (stack45)
        %v61680 = vor.u32 %v61679, %v61678 (stack46)
        %v61681 = vxor.u32 %v61680, %v61676 (stack47)
        %v61684 = vadd.s32 %v61681, %v61676 (stack39)
        %v61686 = vshll.u32 %v61681, 26 (stack44)
        %v61687 = vshrl.u32 %v61681, 6 (stack45)
        %v61688 = vor.u32 %v61687, %v61686 (stack46)
        %v61689 = vxor.u32 %v61688, %v61684 (stack47)
        %v61692 = vadd.s32 %v61689, %v61684 (stack39)
        %v61696 = vadd.s32 %v61692, %v10 (stack39)
        %v61698 = vshll.u32 %v61689, 6 (stack44)
        %v61699 = vshrl.u32 %v61689, 26 (stack45)
        %v61700 = vor.u32 %v61699, %v61698 (stack46)
        %v61701 = vxor.u32 %v61700, %v61692 (stack47)
        %v61704 = vadd.s32 %v61701, %v9 (stack39)
        %v61708 = vadd.s32 3, %v61704 (stack39)
        %v61712 = vadd.s32 %v61708, %v61696 (stack39)
        %v61714 = vshll.u32 %v61708, 17 (stack44)
        %v61715 = vshrl.u32 %v61708, 15 (stack45)
        %v61716 = vor.u32 %v61715, %v61714 (stack46)
        %v61717 = vxor.u32 %v61716, %v61712 (stack47)
        %v61720 = vadd.s32 %v61717, %v61712 (stack39)
        %v61722 = vshll.u32 %v61717, 29 (stack44)
        %v61723 = vshrl.u32 %v61717, 3 (stack45)
        %v61724 = vor.u32 %v61723, %v61722 (stack46)
        %v61725 = vxor.u32 %v61724, %v61720 (stack47)
        %v61728 = vadd.s32 %v61725, %v61720 (stack39)
        %v61730 = vshll.u32 %v61725, 16 (stack44)
        %v61731 = vshrl.u32 %v61725, 16 (stack45)
        %v61732 = vor.u32 %v61731, %v61730 (stack46)
        %v61733 = vxor.u32 %v61732, %v61728 (stack47)
        %v61736 = vadd.s32 %v61733, %v61728 (stack39)
        %v61740 = vadd.s32 %v61736, %v9 (stack39)
        %v61742 = vshll.u32 %v61733, 24 (stack44)
        %v61743 = vshrl.u32 %v61733, 8 (stack45)
        %v61744 = vor.u32 %v61743, %v61742 (stack46)
        %v61745 = vxor.u32 %v61744, %v61736 (stack47)
        %v61748 = vadd.s32 %v61745, %v8 (stack39)
        %v61752 = vadd.s32 4, %v61748 (stack39)
        %v61756 = vadd.s32 %v61752, %v61740 (stack39)
        %v61758 = vshll.u32 %v61752, 13 (stack44)
        %v61759 = vshrl.u32 %v61752, 19 (stack45)
        %v61760 = vor.u32 %v61759, %v61758 (stack46)
        %v61761 = vxor.u32 %v61760, %v61756 (stack47)
        %v61764 = vadd.s32 %v61761, %v61756 (stack39)
        %v61766 = vshll.u32 %v61761, 15 (stack44)
        %v61767 = vshrl.u32 %v61761, 17 (stack45)
        %v61768 = vor.u32 %v61767, %v61766 (stack46)
        %v61769 = vxor.u32 %v61768, %v61764 (stack47)
        %v61772 = vadd.s32 %v61769, %v61764 (stack39)
        %v61774 = vshll.u32 %v61769, 26 (stack44)
        %v61775 = vshrl.u32 %v61769, 6 (stack45)
        %v61776 = vor.u32 %v61775, %v61774 (stack46)
        %v61777 = vxor.u32 %v61776, %v61772 (stack47)
        %v61780 = vadd.s32 %v61777, %v61772 (stack39)
        %v61784 = vadd.s32 %v61780, %v8 (stack39)
        %v61786 = vshll.u32 %v61777, 6 (stack44)
        %v61787 = vshrl.u32 %v61777, 26 (stack45)
        %v61788 = vor.u32 %v61787, %v61786 (stack46)
        %v61789 = vxor.u32 %v61788, %v61780 (stack47)
        %v61792 = vadd.s32 %v61789, %v10 (stack39)
        %v61796 = vadd.s32 5, %v61792 (stack39)
        %v61798 = vxor.u32 %v61796, %v61784 (stack47)
        %v61799 = vand.u32.u8 255, %v61798 (stack48)
        %v61800 = vand.u32 65535, %v61799 (stack49)
        %v61801 = vshrl.u32 %v61800, 1 (stack50)
        %v61802 = vor.u32 16256, %v61801 (stack46)
        %v61803 = vand.u32.u16 65535, %v61802 (stack51)
        %v120074 = vadd.low.f32.bf16 -1.0, %v61803 (stack52)
        %v61812 = vmul.f32 2.0, %v120074 (stack53)
        %v61816 = vadd.f32 -0.99609375, %v61812 (stack52)
        %v61820 = vmax.f32 %v61816, -0.99609375 (stack54)
        %v61822 = vand.u32 2147483647, %v61820 (stack55)
        %vm61825 = vcmp.eq.f32.partialorder %v61822, 1.0 (stack56)
        %v61830 = vmul.f32 inf, %v61820 (stack53)
        %v61832 = vxor.u32 2147483648, %v61820 (stack57)
        %v61835 = vmul.f32 %v61832, %v61820 (stack53)
        %v61837 = vadd.f32 1.0, %v61835 (stack58)
        %v61838 = vlog2.pop %v61837 (stack59)
        %v61839 = vmul.f32 0.6931472, %v61838 (stack60)
        %v61840 = vmul.f32 -0.5, %v61835 (stack61)
        %v61841 = vadd.f32 1.0, %v61840 (stack62)
        %v61842 = vmul.f32 %v61841, %v61835 (stack63)
        %v61843 = vand.u32 2147483647, %v61835 (stack64)
        %vm61844 = vcmp.lt.f32.partialorder %v61843, 0.0004427343 (stack65)
        %v61845 = vsel /*vm=*/%vm61844, /*on_true_vy=*/%v61842, /*on_false_vx=*/%v61839 (stack66)
        %v61846 = vxor.u32 2147483648, %v61845 (stack57)
        %vm61849 = vcmp.lt.f32.partialorder %v61846, 5.0 (stack56)
        %v61854 = vsel /*vm=*/%vm61849, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v61858 = vsel /*vm=*/%vm61849, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v61862 = vsel /*vm=*/%vm61849, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v61866 = vsel /*vm=*/%vm61849, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v61870 = vsel /*vm=*/%vm61849, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v61874 = vsel /*vm=*/%vm61849, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v61878 = vsel /*vm=*/%vm61849, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v61882 = vsel /*vm=*/%vm61849, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v61886 = vsel /*vm=*/%vm61849, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v61890 = vadd.f32 -2.5, %v61846 (stack52)
        %v61892 = vrsqrt.pop %v61846 (stack67)
        %v61893 = vmul.f32 %v61892, %v61846 (stack68)
        %vm61894 = vcmp.eq.f32.partialorder %v61846, inf (stack69)
        %v61895 = vsel /*vm=*/%vm61894, /*on_true_vy=*/%v61846, /*on_false_vx=*/%v61893 (stack70)
        %vm61896 = vcmp.eq.f32.partialorder %v61846, 0.0 (stack71)
        %v61897 = vand.u32 2147483648, %v61846 (stack72)
        %v61898 = vsel /*vm=*/%vm61896, /*on_true_vy=*/%v61897, /*on_false_vx=*/%v61895 (stack73)
        %v61901 = vadd.f32 -3.0, %v61898 (stack52)
        %v61905 = vsel /*vm=*/%vm61849, /*on_true_vy=*/%v61890, /*on_false_vx=*/%v61901 (stack43)
        %v61909 = vmul.f32 %v61905, %v61886 (stack53)
        %v61913 = vadd.f32 %v61909, %v61882 (stack52)
        %v61917 = vmul.f32 %v61913, %v61905 (stack53)
        %v61921 = vadd.f32 %v61917, %v61878 (stack52)
        %v61925 = vmul.f32 %v61921, %v61905 (stack53)
        %v61929 = vadd.f32 %v61925, %v61874 (stack52)
        %v61933 = vmul.f32 %v61929, %v61905 (stack53)
        %v61937 = vadd.f32 %v61933, %v61870 (stack52)
        %v61941 = vmul.f32 %v61937, %v61905 (stack53)
        %v61945 = vadd.f32 %v61941, %v61866 (stack52)
        %v61949 = vmul.f32 %v61945, %v61905 (stack53)
        %v61953 = vadd.f32 %v61949, %v61862 (stack52)
        %v61957 = vmul.f32 %v61953, %v61905 (stack53)
        %v61961 = vadd.f32 %v61957, %v61858 (stack52)
        %v61965 = vmul.f32 %v61961, %v61905 (stack53)
        %v61969 = vadd.f32 %v61965, %v61854 (stack52)
        %v61973 = vmul.f32 %v61969, %v61820 (stack53)
        %v61977 = vsel /*vm=*/%vm61825, /*on_true_vy=*/%v61830, /*on_false_vx=*/%v61973 (stack43)
        %v61981 = vmul.f32 1.4140625, %v61977 (stack53)
        %v61984 = vpack.c.bf16 0.0, %v61981 (stack74)
        %120075 = vst [vmem:[%s280 + $0x1c0] sm:$0xf] /*vst_source=*/%v61984 (stack75)
        %v61988 = vadd.s32 %v60141, %v2355 (stack39)
        %v61998 = vadd.s32 %v61988, %v415 (stack39)
        %vm62002 = vcmp.lt.u32.totalorder %v61998, %v61988 (stack42)
        %vm62007 = vcmp.lt.u32.totalorder %v61988, %v2355 (stack42)
        %v62012 = vadd.s32 %v60124, %v2342 (stack39)
        %v62016 = vadd.s32 1, %v62012 (stack39)
        %v62020 = vsel /*vm=*/%vm62007, /*on_true_vy=*/%v62016, /*on_false_vx=*/%v62012 (stack43)
        %v62024 = vadd.s32 1, %v62020 (stack39)
        %v62028 = vsel /*vm=*/%vm62002, /*on_true_vy=*/%v62024, /*on_false_vx=*/%v62020 (stack43)
        %v62033 = vadd.s32 %v62028, %v10 (stack39)
        %v62037 = vadd.s32 %v61998, %v9 (stack39)
        %v62041 = vadd.s32 %v62037, %v62033 (stack39)
        %v62043 = vshll.u32 %v62037, 13 (stack44)
        %v62044 = vshrl.u32 %v62037, 19 (stack45)
        %v62045 = vor.u32 %v62044, %v62043 (stack46)
        %v62046 = vxor.u32 %v62045, %v62041 (stack47)
        %v62049 = vadd.s32 %v62046, %v62041 (stack39)
        %v62051 = vshll.u32 %v62046, 15 (stack44)
        %v62052 = vshrl.u32 %v62046, 17 (stack45)
        %v62053 = vor.u32 %v62052, %v62051 (stack46)
        %v62054 = vxor.u32 %v62053, %v62049 (stack47)
        %v62057 = vadd.s32 %v62054, %v62049 (stack39)
        %v62059 = vshll.u32 %v62054, 26 (stack44)
        %v62060 = vshrl.u32 %v62054, 6 (stack45)
        %v62061 = vor.u32 %v62060, %v62059 (stack46)
        %v62062 = vxor.u32 %v62061, %v62057 (stack47)
        %v62065 = vadd.s32 %v62062, %v62057 (stack39)
        %v62069 = vadd.s32 %v62065, %v9 (stack39)
        %v62071 = vshll.u32 %v62062, 6 (stack44)
        %v62072 = vshrl.u32 %v62062, 26 (stack45)
        %v62073 = vor.u32 %v62072, %v62071 (stack46)
        %v62074 = vxor.u32 %v62073, %v62065 (stack47)
        %v62077 = vadd.s32 %v62074, %v8 (stack39)
        %v62081 = vadd.s32 1, %v62077 (stack39)
        %v62085 = vadd.s32 %v62081, %v62069 (stack39)
        %v62087 = vshll.u32 %v62081, 17 (stack44)
        %v62088 = vshrl.u32 %v62081, 15 (stack45)
        %v62089 = vor.u32 %v62088, %v62087 (stack46)
        %v62090 = vxor.u32 %v62089, %v62085 (stack47)
        %v62093 = vadd.s32 %v62090, %v62085 (stack39)
        %v62095 = vshll.u32 %v62090, 29 (stack44)
        %v62096 = vshrl.u32 %v62090, 3 (stack45)
        %v62097 = vor.u32 %v62096, %v62095 (stack46)
        %v62098 = vxor.u32 %v62097, %v62093 (stack47)
        %v62101 = vadd.s32 %v62098, %v62093 (stack39)
        %v62103 = vshll.u32 %v62098, 16 (stack44)
        %v62104 = vshrl.u32 %v62098, 16 (stack45)
        %v62105 = vor.u32 %v62104, %v62103 (stack46)
        %v62106 = vxor.u32 %v62105, %v62101 (stack47)
        %v62109 = vadd.s32 %v62106, %v62101 (stack39)
        %v62113 = vadd.s32 %v62109, %v8 (stack39)
        %v62115 = vshll.u32 %v62106, 24 (stack44)
        %v62116 = vshrl.u32 %v62106, 8 (stack45)
        %v62117 = vor.u32 %v62116, %v62115 (stack46)
        %v62118 = vxor.u32 %v62117, %v62109 (stack47)
        %v62121 = vadd.s32 %v62118, %v10 (stack39)
        %v62125 = vadd.s32 2, %v62121 (stack39)
        %v62129 = vadd.s32 %v62125, %v62113 (stack39)
        %v62131 = vshll.u32 %v62125, 13 (stack44)
        %v62132 = vshrl.u32 %v62125, 19 (stack45)
        %v62133 = vor.u32 %v62132, %v62131 (stack46)
        %v62134 = vxor.u32 %v62133, %v62129 (stack47)
        %v62137 = vadd.s32 %v62134, %v62129 (stack39)
        %v62139 = vshll.u32 %v62134, 15 (stack44)
        %v62140 = vshrl.u32 %v62134, 17 (stack45)
        %v62141 = vor.u32 %v62140, %v62139 (stack46)
        %v62142 = vxor.u32 %v62141, %v62137 (stack47)
        %v62145 = vadd.s32 %v62142, %v62137 (stack39)
        %v62147 = vshll.u32 %v62142, 26 (stack44)
        %v62148 = vshrl.u32 %v62142, 6 (stack45)
        %v62149 = vor.u32 %v62148, %v62147 (stack46)
        %v62150 = vxor.u32 %v62149, %v62145 (stack47)
        %v62153 = vadd.s32 %v62150, %v62145 (stack39)
        %v62157 = vadd.s32 %v62153, %v10 (stack39)
        %v62159 = vshll.u32 %v62150, 6 (stack44)
        %v62160 = vshrl.u32 %v62150, 26 (stack45)
        %v62161 = vor.u32 %v62160, %v62159 (stack46)
        %v62162 = vxor.u32 %v62161, %v62153 (stack47)
        %v62165 = vadd.s32 %v62162, %v9 (stack39)
        %v62169 = vadd.s32 3, %v62165 (stack39)
        %v62173 = vadd.s32 %v62169, %v62157 (stack39)
        %v62175 = vshll.u32 %v62169, 17 (stack44)
        %v62176 = vshrl.u32 %v62169, 15 (stack45)
        %v62177 = vor.u32 %v62176, %v62175 (stack46)
        %v62178 = vxor.u32 %v62177, %v62173 (stack47)
        %v62181 = vadd.s32 %v62178, %v62173 (stack39)
        %v62183 = vshll.u32 %v62178, 29 (stack44)
        %v62184 = vshrl.u32 %v62178, 3 (stack45)
        %v62185 = vor.u32 %v62184, %v62183 (stack46)
        %v62186 = vxor.u32 %v62185, %v62181 (stack47)
        %v62189 = vadd.s32 %v62186, %v62181 (stack39)
        %v62191 = vshll.u32 %v62186, 16 (stack44)
        %v62192 = vshrl.u32 %v62186, 16 (stack45)
        %v62193 = vor.u32 %v62192, %v62191 (stack46)
        %v62194 = vxor.u32 %v62193, %v62189 (stack47)
        %v62197 = vadd.s32 %v62194, %v62189 (stack39)
        %v62201 = vadd.s32 %v62197, %v9 (stack39)
        %v62203 = vshll.u32 %v62194, 24 (stack44)
        %v62204 = vshrl.u32 %v62194, 8 (stack45)
        %v62205 = vor.u32 %v62204, %v62203 (stack46)
        %v62206 = vxor.u32 %v62205, %v62197 (stack47)
        %v62209 = vadd.s32 %v62206, %v8 (stack39)
        %v62213 = vadd.s32 4, %v62209 (stack39)
        %v62217 = vadd.s32 %v62213, %v62201 (stack39)
        %v62219 = vshll.u32 %v62213, 13 (stack44)
        %v62220 = vshrl.u32 %v62213, 19 (stack45)
        %v62221 = vor.u32 %v62220, %v62219 (stack46)
        %v62222 = vxor.u32 %v62221, %v62217 (stack47)
        %v62225 = vadd.s32 %v62222, %v62217 (stack39)
        %v62227 = vshll.u32 %v62222, 15 (stack44)
        %v62228 = vshrl.u32 %v62222, 17 (stack45)
        %v62229 = vor.u32 %v62228, %v62227 (stack46)
        %v62230 = vxor.u32 %v62229, %v62225 (stack47)
        %v62233 = vadd.s32 %v62230, %v62225 (stack39)
        %v62235 = vshll.u32 %v62230, 26 (stack44)
        %v62236 = vshrl.u32 %v62230, 6 (stack45)
        %v62237 = vor.u32 %v62236, %v62235 (stack46)
        %v62238 = vxor.u32 %v62237, %v62233 (stack47)
        %v62241 = vadd.s32 %v62238, %v62233 (stack39)
        %v62245 = vadd.s32 %v62241, %v8 (stack39)
        %v62247 = vshll.u32 %v62238, 6 (stack44)
        %v62248 = vshrl.u32 %v62238, 26 (stack45)
        %v62249 = vor.u32 %v62248, %v62247 (stack46)
        %v62250 = vxor.u32 %v62249, %v62241 (stack47)
        %v62253 = vadd.s32 %v62250, %v10 (stack39)
        %v62257 = vadd.s32 5, %v62253 (stack39)
        %v62259 = vxor.u32 %v62257, %v62245 (stack47)
        %v62260 = vand.u32.u8 255, %v62259 (stack48)
        %v62261 = vand.u32 65535, %v62260 (stack49)
        %v62262 = vshrl.u32 %v62261, 1 (stack50)
        %v62263 = vor.u32 16256, %v62262 (stack46)
        %v62264 = vand.u32.u16 65535, %v62263 (stack51)
        %v120076 = vadd.low.f32.bf16 -1.0, %v62264 (stack52)
        %v62273 = vmul.f32 2.0, %v120076 (stack53)
        %v62277 = vadd.f32 -0.99609375, %v62273 (stack52)
        %v62281 = vmax.f32 %v62277, -0.99609375 (stack54)
        %v62283 = vand.u32 2147483647, %v62281 (stack55)
        %vm62286 = vcmp.eq.f32.partialorder %v62283, 1.0 (stack56)
        %v62291 = vmul.f32 inf, %v62281 (stack53)
        %v62293 = vxor.u32 2147483648, %v62281 (stack57)
        %v62296 = vmul.f32 %v62293, %v62281 (stack53)
        %v62298 = vadd.f32 1.0, %v62296 (stack58)
        %v62299 = vlog2.pop %v62298 (stack59)
        %v62300 = vmul.f32 0.6931472, %v62299 (stack60)
        %v62301 = vmul.f32 -0.5, %v62296 (stack61)
        %v62302 = vadd.f32 1.0, %v62301 (stack62)
        %v62303 = vmul.f32 %v62302, %v62296 (stack63)
        %v62304 = vand.u32 2147483647, %v62296 (stack64)
        %vm62305 = vcmp.lt.f32.partialorder %v62304, 0.0004427343 (stack65)
        %v62306 = vsel /*vm=*/%vm62305, /*on_true_vy=*/%v62303, /*on_false_vx=*/%v62300 (stack66)
        %v62307 = vxor.u32 2147483648, %v62306 (stack57)
        %vm62310 = vcmp.lt.f32.partialorder %v62307, 5.0 (stack56)
        %v62315 = vsel /*vm=*/%vm62310, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v62319 = vsel /*vm=*/%vm62310, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v62323 = vsel /*vm=*/%vm62310, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v62327 = vsel /*vm=*/%vm62310, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v62331 = vsel /*vm=*/%vm62310, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v62335 = vsel /*vm=*/%vm62310, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v62339 = vsel /*vm=*/%vm62310, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v62343 = vsel /*vm=*/%vm62310, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v62347 = vsel /*vm=*/%vm62310, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v62351 = vadd.f32 -2.5, %v62307 (stack52)
        %v62353 = vrsqrt.pop %v62307 (stack67)
        %v62354 = vmul.f32 %v62353, %v62307 (stack68)
        %vm62355 = vcmp.eq.f32.partialorder %v62307, inf (stack69)
        %v62356 = vsel /*vm=*/%vm62355, /*on_true_vy=*/%v62307, /*on_false_vx=*/%v62354 (stack70)
        %vm62357 = vcmp.eq.f32.partialorder %v62307, 0.0 (stack71)
        %v62358 = vand.u32 2147483648, %v62307 (stack72)
        %v62359 = vsel /*vm=*/%vm62357, /*on_true_vy=*/%v62358, /*on_false_vx=*/%v62356 (stack73)
        %v62362 = vadd.f32 -3.0, %v62359 (stack52)
        %v62366 = vsel /*vm=*/%vm62310, /*on_true_vy=*/%v62351, /*on_false_vx=*/%v62362 (stack43)
        %v62370 = vmul.f32 %v62366, %v62347 (stack53)
        %v62374 = vadd.f32 %v62370, %v62343 (stack52)
        %v62378 = vmul.f32 %v62374, %v62366 (stack53)
        %v62382 = vadd.f32 %v62378, %v62339 (stack52)
        %v62386 = vmul.f32 %v62382, %v62366 (stack53)
        %v62390 = vadd.f32 %v62386, %v62335 (stack52)
        %v62394 = vmul.f32 %v62390, %v62366 (stack53)
        %v62398 = vadd.f32 %v62394, %v62331 (stack52)
        %v62402 = vmul.f32 %v62398, %v62366 (stack53)
        %v62406 = vadd.f32 %v62402, %v62327 (stack52)
        %v62410 = vmul.f32 %v62406, %v62366 (stack53)
        %v62414 = vadd.f32 %v62410, %v62323 (stack52)
        %v62418 = vmul.f32 %v62414, %v62366 (stack53)
        %v62422 = vadd.f32 %v62418, %v62319 (stack52)
        %v62426 = vmul.f32 %v62422, %v62366 (stack53)
        %v62430 = vadd.f32 %v62426, %v62315 (stack52)
        %v62434 = vmul.f32 %v62430, %v62281 (stack53)
        %v62438 = vsel /*vm=*/%vm62286, /*on_true_vy=*/%v62291, /*on_false_vx=*/%v62434 (stack43)
        %v62442 = vmul.f32 1.4140625, %v62438 (stack53)
        %v62445 = vpack.c.bf16 0.0, %v62442 (stack74)
        %120077 = vst [vmem:[%s280 + $0x240] sm:$0xf] /*vst_source=*/%v62445 (stack75)
        %v62449 = vadd.s32 %v60141, %v2842 (stack39)
        %v62459 = vadd.s32 %v62449, %v415 (stack39)
        %vm62463 = vcmp.lt.u32.totalorder %v62459, %v62449 (stack42)
        %vm62468 = vcmp.lt.u32.totalorder %v62449, %v2842 (stack42)
        %v62473 = vadd.s32 %v60124, %v2829 (stack39)
        %v62477 = vadd.s32 1, %v62473 (stack39)
        %v62481 = vsel /*vm=*/%vm62468, /*on_true_vy=*/%v62477, /*on_false_vx=*/%v62473 (stack43)
        %v62485 = vadd.s32 1, %v62481 (stack39)
        %v62489 = vsel /*vm=*/%vm62463, /*on_true_vy=*/%v62485, /*on_false_vx=*/%v62481 (stack43)
        %v62494 = vadd.s32 %v62489, %v10 (stack39)
        %v62498 = vadd.s32 %v62459, %v9 (stack39)
        %v62502 = vadd.s32 %v62498, %v62494 (stack39)
        %v62504 = vshll.u32 %v62498, 13 (stack44)
        %v62505 = vshrl.u32 %v62498, 19 (stack45)
        %v62506 = vor.u32 %v62505, %v62504 (stack46)
        %v62507 = vxor.u32 %v62506, %v62502 (stack47)
        %v62510 = vadd.s32 %v62507, %v62502 (stack39)
        %v62512 = vshll.u32 %v62507, 15 (stack44)
        %v62513 = vshrl.u32 %v62507, 17 (stack45)
        %v62514 = vor.u32 %v62513, %v62512 (stack46)
        %v62515 = vxor.u32 %v62514, %v62510 (stack47)
        %v62518 = vadd.s32 %v62515, %v62510 (stack39)
        %v62520 = vshll.u32 %v62515, 26 (stack44)
        %v62521 = vshrl.u32 %v62515, 6 (stack45)
        %v62522 = vor.u32 %v62521, %v62520 (stack46)
        %v62523 = vxor.u32 %v62522, %v62518 (stack47)
        %v62526 = vadd.s32 %v62523, %v62518 (stack39)
        %v62530 = vadd.s32 %v62526, %v9 (stack39)
        %v62532 = vshll.u32 %v62523, 6 (stack44)
        %v62533 = vshrl.u32 %v62523, 26 (stack45)
        %v62534 = vor.u32 %v62533, %v62532 (stack46)
        %v62535 = vxor.u32 %v62534, %v62526 (stack47)
        %v62538 = vadd.s32 %v62535, %v8 (stack39)
        %v62542 = vadd.s32 1, %v62538 (stack39)
        %v62546 = vadd.s32 %v62542, %v62530 (stack39)
        %v62548 = vshll.u32 %v62542, 17 (stack44)
        %v62549 = vshrl.u32 %v62542, 15 (stack45)
        %v62550 = vor.u32 %v62549, %v62548 (stack46)
        %v62551 = vxor.u32 %v62550, %v62546 (stack47)
        %v62554 = vadd.s32 %v62551, %v62546 (stack39)
        %v62556 = vshll.u32 %v62551, 29 (stack44)
        %v62557 = vshrl.u32 %v62551, 3 (stack45)
        %v62558 = vor.u32 %v62557, %v62556 (stack46)
        %v62559 = vxor.u32 %v62558, %v62554 (stack47)
        %v62562 = vadd.s32 %v62559, %v62554 (stack39)
        %v62564 = vshll.u32 %v62559, 16 (stack44)
        %v62565 = vshrl.u32 %v62559, 16 (stack45)
        %v62566 = vor.u32 %v62565, %v62564 (stack46)
        %v62567 = vxor.u32 %v62566, %v62562 (stack47)
        %v62570 = vadd.s32 %v62567, %v62562 (stack39)
        %v62574 = vadd.s32 %v62570, %v8 (stack39)
        %v62576 = vshll.u32 %v62567, 24 (stack44)
        %v62577 = vshrl.u32 %v62567, 8 (stack45)
        %v62578 = vor.u32 %v62577, %v62576 (stack46)
        %v62579 = vxor.u32 %v62578, %v62570 (stack47)
        %v62582 = vadd.s32 %v62579, %v10 (stack39)
        %v62586 = vadd.s32 2, %v62582 (stack39)
        %v62590 = vadd.s32 %v62586, %v62574 (stack39)
        %v62592 = vshll.u32 %v62586, 13 (stack44)
        %v62593 = vshrl.u32 %v62586, 19 (stack45)
        %v62594 = vor.u32 %v62593, %v62592 (stack46)
        %v62595 = vxor.u32 %v62594, %v62590 (stack47)
        %v62598 = vadd.s32 %v62595, %v62590 (stack39)
        %v62600 = vshll.u32 %v62595, 15 (stack44)
        %v62601 = vshrl.u32 %v62595, 17 (stack45)
        %v62602 = vor.u32 %v62601, %v62600 (stack46)
        %v62603 = vxor.u32 %v62602, %v62598 (stack47)
        %v62606 = vadd.s32 %v62603, %v62598 (stack39)
        %v62608 = vshll.u32 %v62603, 26 (stack44)
        %v62609 = vshrl.u32 %v62603, 6 (stack45)
        %v62610 = vor.u32 %v62609, %v62608 (stack46)
        %v62611 = vxor.u32 %v62610, %v62606 (stack47)
        %v62614 = vadd.s32 %v62611, %v62606 (stack39)
        %v62618 = vadd.s32 %v62614, %v10 (stack39)
        %v62620 = vshll.u32 %v62611, 6 (stack44)
        %v62621 = vshrl.u32 %v62611, 26 (stack45)
        %v62622 = vor.u32 %v62621, %v62620 (stack46)
        %v62623 = vxor.u32 %v62622, %v62614 (stack47)
        %v62626 = vadd.s32 %v62623, %v9 (stack39)
        %v62630 = vadd.s32 3, %v62626 (stack39)
        %v62634 = vadd.s32 %v62630, %v62618 (stack39)
        %v62636 = vshll.u32 %v62630, 17 (stack44)
        %v62637 = vshrl.u32 %v62630, 15 (stack45)
        %v62638 = vor.u32 %v62637, %v62636 (stack46)
        %v62639 = vxor.u32 %v62638, %v62634 (stack47)
        %v62642 = vadd.s32 %v62639, %v62634 (stack39)
        %v62644 = vshll.u32 %v62639, 29 (stack44)
        %v62645 = vshrl.u32 %v62639, 3 (stack45)
        %v62646 = vor.u32 %v62645, %v62644 (stack46)
        %v62647 = vxor.u32 %v62646, %v62642 (stack47)
        %v62650 = vadd.s32 %v62647, %v62642 (stack39)
        %v62652 = vshll.u32 %v62647, 16 (stack44)
        %v62653 = vshrl.u32 %v62647, 16 (stack45)
        %v62654 = vor.u32 %v62653, %v62652 (stack46)
        %v62655 = vxor.u32 %v62654, %v62650 (stack47)
        %v62658 = vadd.s32 %v62655, %v62650 (stack39)
        %v62662 = vadd.s32 %v62658, %v9 (stack39)
        %v62664 = vshll.u32 %v62655, 24 (stack44)
        %v62665 = vshrl.u32 %v62655, 8 (stack45)
        %v62666 = vor.u32 %v62665, %v62664 (stack46)
        %v62667 = vxor.u32 %v62666, %v62658 (stack47)
        %v62670 = vadd.s32 %v62667, %v8 (stack39)
        %v62674 = vadd.s32 4, %v62670 (stack39)
        %v62678 = vadd.s32 %v62674, %v62662 (stack39)
        %v62680 = vshll.u32 %v62674, 13 (stack44)
        %v62681 = vshrl.u32 %v62674, 19 (stack45)
        %v62682 = vor.u32 %v62681, %v62680 (stack46)
        %v62683 = vxor.u32 %v62682, %v62678 (stack47)
        %v62686 = vadd.s32 %v62683, %v62678 (stack39)
        %v62688 = vshll.u32 %v62683, 15 (stack44)
        %v62689 = vshrl.u32 %v62683, 17 (stack45)
        %v62690 = vor.u32 %v62689, %v62688 (stack46)
        %v62691 = vxor.u32 %v62690, %v62686 (stack47)
        %v62694 = vadd.s32 %v62691, %v62686 (stack39)
        %v62696 = vshll.u32 %v62691, 26 (stack44)
        %v62697 = vshrl.u32 %v62691, 6 (stack45)
        %v62698 = vor.u32 %v62697, %v62696 (stack46)
        %v62699 = vxor.u32 %v62698, %v62694 (stack47)
        %v62702 = vadd.s32 %v62699, %v62694 (stack39)
        %v62706 = vadd.s32 %v62702, %v8 (stack39)
        %v62708 = vshll.u32 %v62699, 6 (stack44)
        %v62709 = vshrl.u32 %v62699, 26 (stack45)
        %v62710 = vor.u32 %v62709, %v62708 (stack46)
        %v62711 = vxor.u32 %v62710, %v62702 (stack47)
        %v62714 = vadd.s32 %v62711, %v10 (stack39)
        %v62718 = vadd.s32 5, %v62714 (stack39)
        %v62720 = vxor.u32 %v62718, %v62706 (stack47)
        %v62721 = vand.u32.u8 255, %v62720 (stack48)
        %v62722 = vand.u32 65535, %v62721 (stack49)
        %v62723 = vshrl.u32 %v62722, 1 (stack50)
        %v62724 = vor.u32 16256, %v62723 (stack46)
        %v62725 = vand.u32.u16 65535, %v62724 (stack51)
        %v120078 = vadd.low.f32.bf16 -1.0, %v62725 (stack52)
        %v62734 = vmul.f32 2.0, %v120078 (stack53)
        %v62738 = vadd.f32 -0.99609375, %v62734 (stack52)
        %v62742 = vmax.f32 %v62738, -0.99609375 (stack54)
        %v62744 = vand.u32 2147483647, %v62742 (stack55)
        %vm62747 = vcmp.eq.f32.partialorder %v62744, 1.0 (stack56)
        %v62752 = vmul.f32 inf, %v62742 (stack53)
        %v62754 = vxor.u32 2147483648, %v62742 (stack57)
        %v62757 = vmul.f32 %v62754, %v62742 (stack53)
        %v62759 = vadd.f32 1.0, %v62757 (stack58)
        %v62760 = vlog2.pop %v62759 (stack59)
        %v62761 = vmul.f32 0.6931472, %v62760 (stack60)
        %v62762 = vmul.f32 -0.5, %v62757 (stack61)
        %v62763 = vadd.f32 1.0, %v62762 (stack62)
        %v62764 = vmul.f32 %v62763, %v62757 (stack63)
        %v62765 = vand.u32 2147483647, %v62757 (stack64)
        %vm62766 = vcmp.lt.f32.partialorder %v62765, 0.0004427343 (stack65)
        %v62767 = vsel /*vm=*/%vm62766, /*on_true_vy=*/%v62764, /*on_false_vx=*/%v62761 (stack66)
        %v62768 = vxor.u32 2147483648, %v62767 (stack57)
        %vm62771 = vcmp.lt.f32.partialorder %v62768, 5.0 (stack56)
        %v62776 = vsel /*vm=*/%vm62771, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v62780 = vsel /*vm=*/%vm62771, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v62784 = vsel /*vm=*/%vm62771, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v62788 = vsel /*vm=*/%vm62771, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v62792 = vsel /*vm=*/%vm62771, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v62796 = vsel /*vm=*/%vm62771, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v62800 = vsel /*vm=*/%vm62771, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v62804 = vsel /*vm=*/%vm62771, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v62808 = vsel /*vm=*/%vm62771, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v62812 = vadd.f32 -2.5, %v62768 (stack52)
        %v62814 = vrsqrt.pop %v62768 (stack67)
        %v62815 = vmul.f32 %v62814, %v62768 (stack68)
        %vm62816 = vcmp.eq.f32.partialorder %v62768, inf (stack69)
        %v62817 = vsel /*vm=*/%vm62816, /*on_true_vy=*/%v62768, /*on_false_vx=*/%v62815 (stack70)
        %vm62818 = vcmp.eq.f32.partialorder %v62768, 0.0 (stack71)
        %v62819 = vand.u32 2147483648, %v62768 (stack72)
        %v62820 = vsel /*vm=*/%vm62818, /*on_true_vy=*/%v62819, /*on_false_vx=*/%v62817 (stack73)
        %v62823 = vadd.f32 -3.0, %v62820 (stack52)
        %v62827 = vsel /*vm=*/%vm62771, /*on_true_vy=*/%v62812, /*on_false_vx=*/%v62823 (stack43)
        %v62831 = vmul.f32 %v62827, %v62808 (stack53)
        %v62835 = vadd.f32 %v62831, %v62804 (stack52)
        %v62839 = vmul.f32 %v62835, %v62827 (stack53)
        %v62843 = vadd.f32 %v62839, %v62800 (stack52)
        %v62847 = vmul.f32 %v62843, %v62827 (stack53)
        %v62851 = vadd.f32 %v62847, %v62796 (stack52)
        %v62855 = vmul.f32 %v62851, %v62827 (stack53)
        %v62859 = vadd.f32 %v62855, %v62792 (stack52)
        %v62863 = vmul.f32 %v62859, %v62827 (stack53)
        %v62867 = vadd.f32 %v62863, %v62788 (stack52)
        %v62871 = vmul.f32 %v62867, %v62827 (stack53)
        %v62875 = vadd.f32 %v62871, %v62784 (stack52)
        %v62879 = vmul.f32 %v62875, %v62827 (stack53)
        %v62883 = vadd.f32 %v62879, %v62780 (stack52)
        %v62887 = vmul.f32 %v62883, %v62827 (stack53)
        %v62891 = vadd.f32 %v62887, %v62776 (stack52)
        %v62895 = vmul.f32 %v62891, %v62742 (stack53)
        %v62899 = vsel /*vm=*/%vm62747, /*on_true_vy=*/%v62752, /*on_false_vx=*/%v62895 (stack43)
        %v62903 = vmul.f32 1.4140625, %v62899 (stack53)
        %v62906 = vpack.c.bf16 0.0, %v62903 (stack74)
        %120079 = vst [vmem:[%s280 + $0x2c0] sm:$0xf] /*vst_source=*/%v62906 (stack75)
        %v62910 = vadd.s32 %v60141, %v3329 (stack39)
        %v62920 = vadd.s32 %v62910, %v415 (stack39)
        %vm62924 = vcmp.lt.u32.totalorder %v62920, %v62910 (stack42)
        %vm62929 = vcmp.lt.u32.totalorder %v62910, %v3329 (stack42)
        %v62934 = vadd.s32 %v60124, %v3316 (stack39)
        %v62938 = vadd.s32 1, %v62934 (stack39)
        %v62942 = vsel /*vm=*/%vm62929, /*on_true_vy=*/%v62938, /*on_false_vx=*/%v62934 (stack43)
        %v62946 = vadd.s32 1, %v62942 (stack39)
        %v62950 = vsel /*vm=*/%vm62924, /*on_true_vy=*/%v62946, /*on_false_vx=*/%v62942 (stack43)
        %v62955 = vadd.s32 %v62950, %v10 (stack39)
        %v62959 = vadd.s32 %v62920, %v9 (stack39)
        %v62963 = vadd.s32 %v62959, %v62955 (stack39)
        %v62965 = vshll.u32 %v62959, 13 (stack44)
        %v62966 = vshrl.u32 %v62959, 19 (stack45)
        %v62967 = vor.u32 %v62966, %v62965 (stack46)
        %v62968 = vxor.u32 %v62967, %v62963 (stack47)
        %v62971 = vadd.s32 %v62968, %v62963 (stack39)
        %v62973 = vshll.u32 %v62968, 15 (stack44)
        %v62974 = vshrl.u32 %v62968, 17 (stack45)
        %v62975 = vor.u32 %v62974, %v62973 (stack46)
        %v62976 = vxor.u32 %v62975, %v62971 (stack47)
        %v62979 = vadd.s32 %v62976, %v62971 (stack39)
        %v62981 = vshll.u32 %v62976, 26 (stack44)
        %v62982 = vshrl.u32 %v62976, 6 (stack45)
        %v62983 = vor.u32 %v62982, %v62981 (stack46)
        %v62984 = vxor.u32 %v62983, %v62979 (stack47)
        %v62987 = vadd.s32 %v62984, %v62979 (stack39)
        %v62991 = vadd.s32 %v62987, %v9 (stack39)
        %v62993 = vshll.u32 %v62984, 6 (stack44)
        %v62994 = vshrl.u32 %v62984, 26 (stack45)
        %v62995 = vor.u32 %v62994, %v62993 (stack46)
        %v62996 = vxor.u32 %v62995, %v62987 (stack47)
        %v62999 = vadd.s32 %v62996, %v8 (stack39)
        %v63003 = vadd.s32 1, %v62999 (stack39)
        %v63007 = vadd.s32 %v63003, %v62991 (stack39)
        %v63009 = vshll.u32 %v63003, 17 (stack44)
        %v63010 = vshrl.u32 %v63003, 15 (stack45)
        %v63011 = vor.u32 %v63010, %v63009 (stack46)
        %v63012 = vxor.u32 %v63011, %v63007 (stack47)
        %v63015 = vadd.s32 %v63012, %v63007 (stack39)
        %v63017 = vshll.u32 %v63012, 29 (stack44)
        %v63018 = vshrl.u32 %v63012, 3 (stack45)
        %v63019 = vor.u32 %v63018, %v63017 (stack46)
        %v63020 = vxor.u32 %v63019, %v63015 (stack47)
        %v63023 = vadd.s32 %v63020, %v63015 (stack39)
        %v63025 = vshll.u32 %v63020, 16 (stack44)
        %v63026 = vshrl.u32 %v63020, 16 (stack45)
        %v63027 = vor.u32 %v63026, %v63025 (stack46)
        %v63028 = vxor.u32 %v63027, %v63023 (stack47)
        %v63031 = vadd.s32 %v63028, %v63023 (stack39)
        %v63035 = vadd.s32 %v63031, %v8 (stack39)
        %v63037 = vshll.u32 %v63028, 24 (stack44)
        %v63038 = vshrl.u32 %v63028, 8 (stack45)
        %v63039 = vor.u32 %v63038, %v63037 (stack46)
        %v63040 = vxor.u32 %v63039, %v63031 (stack47)
        %v63043 = vadd.s32 %v63040, %v10 (stack39)
        %v63047 = vadd.s32 2, %v63043 (stack39)
        %v63051 = vadd.s32 %v63047, %v63035 (stack39)
        %v63053 = vshll.u32 %v63047, 13 (stack44)
        %v63054 = vshrl.u32 %v63047, 19 (stack45)
        %v63055 = vor.u32 %v63054, %v63053 (stack46)
        %v63056 = vxor.u32 %v63055, %v63051 (stack47)
        %v63059 = vadd.s32 %v63056, %v63051 (stack39)
        %v63061 = vshll.u32 %v63056, 15 (stack44)
        %v63062 = vshrl.u32 %v63056, 17 (stack45)
        %v63063 = vor.u32 %v63062, %v63061 (stack46)
        %v63064 = vxor.u32 %v63063, %v63059 (stack47)
        %v63067 = vadd.s32 %v63064, %v63059 (stack39)
        %v63069 = vshll.u32 %v63064, 26 (stack44)
        %v63070 = vshrl.u32 %v63064, 6 (stack45)
        %v63071 = vor.u32 %v63070, %v63069 (stack46)
        %v63072 = vxor.u32 %v63071, %v63067 (stack47)
        %v63075 = vadd.s32 %v63072, %v63067 (stack39)
        %v63079 = vadd.s32 %v63075, %v10 (stack39)
        %v63081 = vshll.u32 %v63072, 6 (stack44)
        %v63082 = vshrl.u32 %v63072, 26 (stack45)
        %v63083 = vor.u32 %v63082, %v63081 (stack46)
        %v63084 = vxor.u32 %v63083, %v63075 (stack47)
        %v63087 = vadd.s32 %v63084, %v9 (stack39)
        %v63091 = vadd.s32 3, %v63087 (stack39)
        %v63095 = vadd.s32 %v63091, %v63079 (stack39)
        %v63097 = vshll.u32 %v63091, 17 (stack44)
        %v63098 = vshrl.u32 %v63091, 15 (stack45)
        %v63099 = vor.u32 %v63098, %v63097 (stack46)
        %v63100 = vxor.u32 %v63099, %v63095 (stack47)
        %v63103 = vadd.s32 %v63100, %v63095 (stack39)
        %v63105 = vshll.u32 %v63100, 29 (stack44)
        %v63106 = vshrl.u32 %v63100, 3 (stack45)
        %v63107 = vor.u32 %v63106, %v63105 (stack46)
        %v63108 = vxor.u32 %v63107, %v63103 (stack47)
        %v63111 = vadd.s32 %v63108, %v63103 (stack39)
        %v63113 = vshll.u32 %v63108, 16 (stack44)
        %v63114 = vshrl.u32 %v63108, 16 (stack45)
        %v63115 = vor.u32 %v63114, %v63113 (stack46)
        %v63116 = vxor.u32 %v63115, %v63111 (stack47)
        %v63119 = vadd.s32 %v63116, %v63111 (stack39)
        %v63123 = vadd.s32 %v63119, %v9 (stack39)
        %v63125 = vshll.u32 %v63116, 24 (stack44)
        %v63126 = vshrl.u32 %v63116, 8 (stack45)
        %v63127 = vor.u32 %v63126, %v63125 (stack46)
        %v63128 = vxor.u32 %v63127, %v63119 (stack47)
        %v63131 = vadd.s32 %v63128, %v8 (stack39)
        %v63135 = vadd.s32 4, %v63131 (stack39)
        %v63139 = vadd.s32 %v63135, %v63123 (stack39)
        %v63141 = vshll.u32 %v63135, 13 (stack44)
        %v63142 = vshrl.u32 %v63135, 19 (stack45)
        %v63143 = vor.u32 %v63142, %v63141 (stack46)
        %v63144 = vxor.u32 %v63143, %v63139 (stack47)
        %v63147 = vadd.s32 %v63144, %v63139 (stack39)
        %v63149 = vshll.u32 %v63144, 15 (stack44)
        %v63150 = vshrl.u32 %v63144, 17 (stack45)
        %v63151 = vor.u32 %v63150, %v63149 (stack46)
        %v63152 = vxor.u32 %v63151, %v63147 (stack47)
        %v63155 = vadd.s32 %v63152, %v63147 (stack39)
        %v63157 = vshll.u32 %v63152, 26 (stack44)
        %v63158 = vshrl.u32 %v63152, 6 (stack45)
        %v63159 = vor.u32 %v63158, %v63157 (stack46)
        %v63160 = vxor.u32 %v63159, %v63155 (stack47)
        %v63163 = vadd.s32 %v63160, %v63155 (stack39)
        %v63167 = vadd.s32 %v63163, %v8 (stack39)
        %v63169 = vshll.u32 %v63160, 6 (stack44)
        %v63170 = vshrl.u32 %v63160, 26 (stack45)
        %v63171 = vor.u32 %v63170, %v63169 (stack46)
        %v63172 = vxor.u32 %v63171, %v63163 (stack47)
        %v63175 = vadd.s32 %v63172, %v10 (stack39)
        %v63179 = vadd.s32 5, %v63175 (stack39)
        %v63181 = vxor.u32 %v63179, %v63167 (stack47)
        %v63182 = vand.u32.u8 255, %v63181 (stack48)
        %v63183 = vand.u32 65535, %v63182 (stack49)
        %v63184 = vshrl.u32 %v63183, 1 (stack50)
        %v63185 = vor.u32 16256, %v63184 (stack46)
        %v63186 = vand.u32.u16 65535, %v63185 (stack51)
        %v120080 = vadd.low.f32.bf16 -1.0, %v63186 (stack52)
        %v63195 = vmul.f32 2.0, %v120080 (stack53)
        %v63199 = vadd.f32 -0.99609375, %v63195 (stack52)
        %v63203 = vmax.f32 %v63199, -0.99609375 (stack54)
        %v63205 = vand.u32 2147483647, %v63203 (stack55)
        %vm63208 = vcmp.eq.f32.partialorder %v63205, 1.0 (stack56)
        %v63213 = vmul.f32 inf, %v63203 (stack53)
        %v63215 = vxor.u32 2147483648, %v63203 (stack57)
        %v63218 = vmul.f32 %v63215, %v63203 (stack53)
        %v63220 = vadd.f32 1.0, %v63218 (stack58)
        %v63221 = vlog2.pop %v63220 (stack59)
        %v63222 = vmul.f32 0.6931472, %v63221 (stack60)
        %v63223 = vmul.f32 -0.5, %v63218 (stack61)
        %v63224 = vadd.f32 1.0, %v63223 (stack62)
        %v63225 = vmul.f32 %v63224, %v63218 (stack63)
        %v63226 = vand.u32 2147483647, %v63218 (stack64)
        %vm63227 = vcmp.lt.f32.partialorder %v63226, 0.0004427343 (stack65)
        %v63228 = vsel /*vm=*/%vm63227, /*on_true_vy=*/%v63225, /*on_false_vx=*/%v63222 (stack66)
        %v63229 = vxor.u32 2147483648, %v63228 (stack57)
        %vm63232 = vcmp.lt.f32.partialorder %v63229, 5.0 (stack56)
        %v63237 = vsel /*vm=*/%vm63232, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v63241 = vsel /*vm=*/%vm63232, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v63245 = vsel /*vm=*/%vm63232, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v63249 = vsel /*vm=*/%vm63232, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v63253 = vsel /*vm=*/%vm63232, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v63257 = vsel /*vm=*/%vm63232, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v63261 = vsel /*vm=*/%vm63232, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v63265 = vsel /*vm=*/%vm63232, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v63269 = vsel /*vm=*/%vm63232, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v63273 = vadd.f32 -2.5, %v63229 (stack52)
        %v63275 = vrsqrt.pop %v63229 (stack67)
        %v63276 = vmul.f32 %v63275, %v63229 (stack68)
        %vm63277 = vcmp.eq.f32.partialorder %v63229, inf (stack69)
        %v63278 = vsel /*vm=*/%vm63277, /*on_true_vy=*/%v63229, /*on_false_vx=*/%v63276 (stack70)
        %vm63279 = vcmp.eq.f32.partialorder %v63229, 0.0 (stack71)
        %v63280 = vand.u32 2147483648, %v63229 (stack72)
        %v63281 = vsel /*vm=*/%vm63279, /*on_true_vy=*/%v63280, /*on_false_vx=*/%v63278 (stack73)
        %v63284 = vadd.f32 -3.0, %v63281 (stack52)
        %v63288 = vsel /*vm=*/%vm63232, /*on_true_vy=*/%v63273, /*on_false_vx=*/%v63284 (stack43)
        %v63292 = vmul.f32 %v63288, %v63269 (stack53)
        %v63296 = vadd.f32 %v63292, %v63265 (stack52)
        %v63300 = vmul.f32 %v63296, %v63288 (stack53)
        %v63304 = vadd.f32 %v63300, %v63261 (stack52)
        %v63308 = vmul.f32 %v63304, %v63288 (stack53)
        %v63312 = vadd.f32 %v63308, %v63257 (stack52)
        %v63316 = vmul.f32 %v63312, %v63288 (stack53)
        %v63320 = vadd.f32 %v63316, %v63253 (stack52)
        %v63324 = vmul.f32 %v63320, %v63288 (stack53)
        %v63328 = vadd.f32 %v63324, %v63249 (stack52)
        %v63332 = vmul.f32 %v63328, %v63288 (stack53)
        %v63336 = vadd.f32 %v63332, %v63245 (stack52)
        %v63340 = vmul.f32 %v63336, %v63288 (stack53)
        %v63344 = vadd.f32 %v63340, %v63241 (stack52)
        %v63348 = vmul.f32 %v63344, %v63288 (stack53)
        %v63352 = vadd.f32 %v63348, %v63237 (stack52)
        %v63356 = vmul.f32 %v63352, %v63203 (stack53)
        %v63360 = vsel /*vm=*/%vm63208, /*on_true_vy=*/%v63213, /*on_false_vx=*/%v63356 (stack43)
        %v63364 = vmul.f32 1.4140625, %v63360 (stack53)
        %v63367 = vpack.c.bf16 0.0, %v63364 (stack74)
        %120081 = vst [vmem:[%s280 + $0x340] sm:$0xf] /*vst_source=*/%v63367 (stack75)
        %v63371 = vadd.s32 %v60141, %v3816 (stack39)
        %v63381 = vadd.s32 %v63371, %v415 (stack39)
        %vm63385 = vcmp.lt.u32.totalorder %v63381, %v63371 (stack42)
        %vm63390 = vcmp.lt.u32.totalorder %v63371, %v3816 (stack42)
        %v63395 = vadd.s32 %v60124, %v3803 (stack39)
        %v63399 = vadd.s32 1, %v63395 (stack39)
        %v63403 = vsel /*vm=*/%vm63390, /*on_true_vy=*/%v63399, /*on_false_vx=*/%v63395 (stack43)
        %v63407 = vadd.s32 1, %v63403 (stack39)
        %v63411 = vsel /*vm=*/%vm63385, /*on_true_vy=*/%v63407, /*on_false_vx=*/%v63403 (stack43)
        %v63416 = vadd.s32 %v63411, %v10 (stack39)
        %v63420 = vadd.s32 %v63381, %v9 (stack39)
        %v63424 = vadd.s32 %v63420, %v63416 (stack39)
        %v63426 = vshll.u32 %v63420, 13 (stack44)
        %v63427 = vshrl.u32 %v63420, 19 (stack45)
        %v63428 = vor.u32 %v63427, %v63426 (stack46)
        %v63429 = vxor.u32 %v63428, %v63424 (stack47)
        %v63432 = vadd.s32 %v63429, %v63424 (stack39)
        %v63434 = vshll.u32 %v63429, 15 (stack44)
        %v63435 = vshrl.u32 %v63429, 17 (stack45)
        %v63436 = vor.u32 %v63435, %v63434 (stack46)
        %v63437 = vxor.u32 %v63436, %v63432 (stack47)
        %v63440 = vadd.s32 %v63437, %v63432 (stack39)
        %v63442 = vshll.u32 %v63437, 26 (stack44)
        %v63443 = vshrl.u32 %v63437, 6 (stack45)
        %v63444 = vor.u32 %v63443, %v63442 (stack46)
        %v63445 = vxor.u32 %v63444, %v63440 (stack47)
        %v63448 = vadd.s32 %v63445, %v63440 (stack39)
        %v63452 = vadd.s32 %v63448, %v9 (stack39)
        %v63454 = vshll.u32 %v63445, 6 (stack44)
        %v63455 = vshrl.u32 %v63445, 26 (stack45)
        %v63456 = vor.u32 %v63455, %v63454 (stack46)
        %v63457 = vxor.u32 %v63456, %v63448 (stack47)
        %v63460 = vadd.s32 %v63457, %v8 (stack39)
        %v63464 = vadd.s32 1, %v63460 (stack39)
        %v63468 = vadd.s32 %v63464, %v63452 (stack39)
        %v63470 = vshll.u32 %v63464, 17 (stack44)
        %v63471 = vshrl.u32 %v63464, 15 (stack45)
        %v63472 = vor.u32 %v63471, %v63470 (stack46)
        %v63473 = vxor.u32 %v63472, %v63468 (stack47)
        %v63476 = vadd.s32 %v63473, %v63468 (stack39)
        %v63478 = vshll.u32 %v63473, 29 (stack44)
        %v63479 = vshrl.u32 %v63473, 3 (stack45)
        %v63480 = vor.u32 %v63479, %v63478 (stack46)
        %v63481 = vxor.u32 %v63480, %v63476 (stack47)
        %v63484 = vadd.s32 %v63481, %v63476 (stack39)
        %v63486 = vshll.u32 %v63481, 16 (stack44)
        %v63487 = vshrl.u32 %v63481, 16 (stack45)
        %v63488 = vor.u32 %v63487, %v63486 (stack46)
        %v63489 = vxor.u32 %v63488, %v63484 (stack47)
        %v63492 = vadd.s32 %v63489, %v63484 (stack39)
        %v63496 = vadd.s32 %v63492, %v8 (stack39)
        %v63498 = vshll.u32 %v63489, 24 (stack44)
        %v63499 = vshrl.u32 %v63489, 8 (stack45)
        %v63500 = vor.u32 %v63499, %v63498 (stack46)
        %v63501 = vxor.u32 %v63500, %v63492 (stack47)
        %v63504 = vadd.s32 %v63501, %v10 (stack39)
        %v63508 = vadd.s32 2, %v63504 (stack39)
        %v63512 = vadd.s32 %v63508, %v63496 (stack39)
        %v63514 = vshll.u32 %v63508, 13 (stack44)
        %v63515 = vshrl.u32 %v63508, 19 (stack45)
        %v63516 = vor.u32 %v63515, %v63514 (stack46)
        %v63517 = vxor.u32 %v63516, %v63512 (stack47)
        %v63520 = vadd.s32 %v63517, %v63512 (stack39)
        %v63522 = vshll.u32 %v63517, 15 (stack44)
        %v63523 = vshrl.u32 %v63517, 17 (stack45)
        %v63524 = vor.u32 %v63523, %v63522 (stack46)
        %v63525 = vxor.u32 %v63524, %v63520 (stack47)
        %v63528 = vadd.s32 %v63525, %v63520 (stack39)
        %v63530 = vshll.u32 %v63525, 26 (stack44)
        %v63531 = vshrl.u32 %v63525, 6 (stack45)
        %v63532 = vor.u32 %v63531, %v63530 (stack46)
        %v63533 = vxor.u32 %v63532, %v63528 (stack47)
        %v63536 = vadd.s32 %v63533, %v63528 (stack39)
        %v63540 = vadd.s32 %v63536, %v10 (stack39)
        %v63542 = vshll.u32 %v63533, 6 (stack44)
        %v63543 = vshrl.u32 %v63533, 26 (stack45)
        %v63544 = vor.u32 %v63543, %v63542 (stack46)
        %v63545 = vxor.u32 %v63544, %v63536 (stack47)
        %v63548 = vadd.s32 %v63545, %v9 (stack39)
        %v63552 = vadd.s32 3, %v63548 (stack39)
        %v63556 = vadd.s32 %v63552, %v63540 (stack39)
        %v63558 = vshll.u32 %v63552, 17 (stack44)
        %v63559 = vshrl.u32 %v63552, 15 (stack45)
        %v63560 = vor.u32 %v63559, %v63558 (stack46)
        %v63561 = vxor.u32 %v63560, %v63556 (stack47)
        %v63564 = vadd.s32 %v63561, %v63556 (stack39)
        %v63566 = vshll.u32 %v63561, 29 (stack44)
        %v63567 = vshrl.u32 %v63561, 3 (stack45)
        %v63568 = vor.u32 %v63567, %v63566 (stack46)
        %v63569 = vxor.u32 %v63568, %v63564 (stack47)
        %v63572 = vadd.s32 %v63569, %v63564 (stack39)
        %v63574 = vshll.u32 %v63569, 16 (stack44)
        %v63575 = vshrl.u32 %v63569, 16 (stack45)
        %v63576 = vor.u32 %v63575, %v63574 (stack46)
        %v63577 = vxor.u32 %v63576, %v63572 (stack47)
        %v63580 = vadd.s32 %v63577, %v63572 (stack39)
        %v63584 = vadd.s32 %v63580, %v9 (stack39)
        %v63586 = vshll.u32 %v63577, 24 (stack44)
        %v63587 = vshrl.u32 %v63577, 8 (stack45)
        %v63588 = vor.u32 %v63587, %v63586 (stack46)
        %v63589 = vxor.u32 %v63588, %v63580 (stack47)
        %v63592 = vadd.s32 %v63589, %v8 (stack39)
        %v63596 = vadd.s32 4, %v63592 (stack39)
        %v63600 = vadd.s32 %v63596, %v63584 (stack39)
        %v63602 = vshll.u32 %v63596, 13 (stack44)
        %v63603 = vshrl.u32 %v63596, 19 (stack45)
        %v63604 = vor.u32 %v63603, %v63602 (stack46)
        %v63605 = vxor.u32 %v63604, %v63600 (stack47)
        %v63608 = vadd.s32 %v63605, %v63600 (stack39)
        %v63610 = vshll.u32 %v63605, 15 (stack44)
        %v63611 = vshrl.u32 %v63605, 17 (stack45)
        %v63612 = vor.u32 %v63611, %v63610 (stack46)
        %v63613 = vxor.u32 %v63612, %v63608 (stack47)
        %v63616 = vadd.s32 %v63613, %v63608 (stack39)
        %v63618 = vshll.u32 %v63613, 26 (stack44)
        %v63619 = vshrl.u32 %v63613, 6 (stack45)
        %v63620 = vor.u32 %v63619, %v63618 (stack46)
        %v63621 = vxor.u32 %v63620, %v63616 (stack47)
        %v63624 = vadd.s32 %v63621, %v63616 (stack39)
        %v63628 = vadd.s32 %v63624, %v8 (stack39)
        %v63630 = vshll.u32 %v63621, 6 (stack44)
        %v63631 = vshrl.u32 %v63621, 26 (stack45)
        %v63632 = vor.u32 %v63631, %v63630 (stack46)
        %v63633 = vxor.u32 %v63632, %v63624 (stack47)
        %v63636 = vadd.s32 %v63633, %v10 (stack39)
        %v63640 = vadd.s32 5, %v63636 (stack39)
        %v63642 = vxor.u32 %v63640, %v63628 (stack47)
        %v63643 = vand.u32.u8 255, %v63642 (stack48)
        %v63644 = vand.u32 65535, %v63643 (stack49)
        %v63645 = vshrl.u32 %v63644, 1 (stack50)
        %v63646 = vor.u32 16256, %v63645 (stack46)
        %v63647 = vand.u32.u16 65535, %v63646 (stack51)
        %v120082 = vadd.low.f32.bf16 -1.0, %v63647 (stack52)
        %v63656 = vmul.f32 2.0, %v120082 (stack53)
        %v63660 = vadd.f32 -0.99609375, %v63656 (stack52)
        %v63664 = vmax.f32 %v63660, -0.99609375 (stack54)
        %v63666 = vand.u32 2147483647, %v63664 (stack55)
        %vm63669 = vcmp.eq.f32.partialorder %v63666, 1.0 (stack56)
        %v63674 = vmul.f32 inf, %v63664 (stack53)
        %v63676 = vxor.u32 2147483648, %v63664 (stack57)
        %v63679 = vmul.f32 %v63676, %v63664 (stack53)
        %v63681 = vadd.f32 1.0, %v63679 (stack58)
        %v63682 = vlog2.pop %v63681 (stack59)
        %v63683 = vmul.f32 0.6931472, %v63682 (stack60)
        %v63684 = vmul.f32 -0.5, %v63679 (stack61)
        %v63685 = vadd.f32 1.0, %v63684 (stack62)
        %v63686 = vmul.f32 %v63685, %v63679 (stack63)
        %v63687 = vand.u32 2147483647, %v63679 (stack64)
        %vm63688 = vcmp.lt.f32.partialorder %v63687, 0.0004427343 (stack65)
        %v63689 = vsel /*vm=*/%vm63688, /*on_true_vy=*/%v63686, /*on_false_vx=*/%v63683 (stack66)
        %v63690 = vxor.u32 2147483648, %v63689 (stack57)
        %vm63693 = vcmp.lt.f32.partialorder %v63690, 5.0 (stack56)
        %v63698 = vsel /*vm=*/%vm63693, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v63702 = vsel /*vm=*/%vm63693, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v63706 = vsel /*vm=*/%vm63693, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v63710 = vsel /*vm=*/%vm63693, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v63714 = vsel /*vm=*/%vm63693, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v63718 = vsel /*vm=*/%vm63693, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v63722 = vsel /*vm=*/%vm63693, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v63726 = vsel /*vm=*/%vm63693, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v63730 = vsel /*vm=*/%vm63693, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v63734 = vadd.f32 -2.5, %v63690 (stack52)
        %v63736 = vrsqrt.pop %v63690 (stack67)
        %v63737 = vmul.f32 %v63736, %v63690 (stack68)
        %vm63738 = vcmp.eq.f32.partialorder %v63690, inf (stack69)
        %v63739 = vsel /*vm=*/%vm63738, /*on_true_vy=*/%v63690, /*on_false_vx=*/%v63737 (stack70)
        %vm63740 = vcmp.eq.f32.partialorder %v63690, 0.0 (stack71)
        %v63741 = vand.u32 2147483648, %v63690 (stack72)
        %v63742 = vsel /*vm=*/%vm63740, /*on_true_vy=*/%v63741, /*on_false_vx=*/%v63739 (stack73)
        %v63745 = vadd.f32 -3.0, %v63742 (stack52)
        %v63749 = vsel /*vm=*/%vm63693, /*on_true_vy=*/%v63734, /*on_false_vx=*/%v63745 (stack43)
        %v63753 = vmul.f32 %v63749, %v63730 (stack53)
        %v63757 = vadd.f32 %v63753, %v63726 (stack52)
        %v63761 = vmul.f32 %v63757, %v63749 (stack53)
        %v63765 = vadd.f32 %v63761, %v63722 (stack52)
        %v63769 = vmul.f32 %v63765, %v63749 (stack53)
        %v63773 = vadd.f32 %v63769, %v63718 (stack52)
        %v63777 = vmul.f32 %v63773, %v63749 (stack53)
        %v63781 = vadd.f32 %v63777, %v63714 (stack52)
        %v63785 = vmul.f32 %v63781, %v63749 (stack53)
        %v63789 = vadd.f32 %v63785, %v63710 (stack52)
        %v63793 = vmul.f32 %v63789, %v63749 (stack53)
        %v63797 = vadd.f32 %v63793, %v63706 (stack52)
        %v63801 = vmul.f32 %v63797, %v63749 (stack53)
        %v63805 = vadd.f32 %v63801, %v63702 (stack52)
        %v63809 = vmul.f32 %v63805, %v63749 (stack53)
        %v63813 = vadd.f32 %v63809, %v63698 (stack52)
        %v63817 = vmul.f32 %v63813, %v63664 (stack53)
        %v63821 = vsel /*vm=*/%vm63669, /*on_true_vy=*/%v63674, /*on_false_vx=*/%v63817 (stack43)
        %v63825 = vmul.f32 1.4140625, %v63821 (stack53)
        %v63828 = vpack.c.bf16 0.0, %v63825 (stack74)
        %120083 = vst [vmem:[%s280 + $0x3c0] sm:$0xf] /*vst_source=*/%v63828 (stack75)
        %s63830 = sadd.s32 136, %s120390 (stack76)
        %s63831 = sshrl.u32 %s63830, 10 (stack23)
        %p120084 = scmp.gt.s32.totalorder %s63831, 1 (stack24)
        %s63833 = scalar_select /*predicate=*/%p120084, /*on_true=*/1, /*on_false=*/%s63831 (stack25)
        %s63834 = sand.u32 1023, %s63830 /* smod.u32 w/div 1024 */ (stack26)
        %s63835 = sshrl.u32 %s63834, 7 (stack27)
        %s63836 = sand.u32 127, %s63834 /* smod.u32 w/div 128 */ (stack28)
        %s120085 = sshll.u32 %s63833, 3 (stack29)
        %s63838 = scalar_lea.vmem %s3, %s120085 (stack30)
        %s63840 = scalar_lea.vmem %s63838, %s63835 (stack31)
        %v63841 = vld [vmem:[%s63840] ss:$0 sm:$0xff] (stack32)
        %s63842 = sand.u32 255, %s63836 (stack33)
        %s63844 = sor.u32 256, %s63842 (stack34)
        %63845 = vbcast.lane.b32.xlu0 %v63841, %s63844 (stack35)
        %v63846 = vpop.permute.xlu0 %63845 (stack36)
        %s63855 = scalar_lea.vmem %s5, %s120085 (stack30)
        %s63857 = scalar_lea.vmem %s63855, %s63835 (stack31)
        %v63858 = vld [vmem:[%s63857] ss:$0 sm:$0xff] (stack32)
        %63862 = vbcast.lane.b32.xlu0 %v63858, %s63844 (stack35)
        %v63863 = vpop.permute.xlu0 %63862 (stack36)
        %v63866 = vadd.s32 %v63863, %v408 (stack39)
        %v63876 = vadd.s32 %v63866, %v415 (stack39)
        %vm63880 = vcmp.lt.u32.totalorder %v63876, %v63866 (stack42)
        %vm63885 = vcmp.lt.u32.totalorder %v63866, %v408 (stack42)
        %v63890 = vadd.s32 %v63846, %v380 (stack39)
        %v63894 = vadd.s32 1, %v63890 (stack39)
        %v63898 = vsel /*vm=*/%vm63885, /*on_true_vy=*/%v63894, /*on_false_vx=*/%v63890 (stack43)
        %v63902 = vadd.s32 1, %v63898 (stack39)
        %v63906 = vsel /*vm=*/%vm63880, /*on_true_vy=*/%v63902, /*on_false_vx=*/%v63898 (stack43)
        %v63911 = vadd.s32 %v63906, %v10 (stack39)
        %v63915 = vadd.s32 %v63876, %v9 (stack39)
        %v63919 = vadd.s32 %v63915, %v63911 (stack39)
        %v63921 = vshll.u32 %v63915, 13 (stack44)
        %v63922 = vshrl.u32 %v63915, 19 (stack45)
        %v63923 = vor.u32 %v63922, %v63921 (stack46)
        %v63924 = vxor.u32 %v63923, %v63919 (stack47)
        %v63927 = vadd.s32 %v63924, %v63919 (stack39)
        %v63929 = vshll.u32 %v63924, 15 (stack44)
        %v63930 = vshrl.u32 %v63924, 17 (stack45)
        %v63931 = vor.u32 %v63930, %v63929 (stack46)
        %v63932 = vxor.u32 %v63931, %v63927 (stack47)
        %v63935 = vadd.s32 %v63932, %v63927 (stack39)
        %v63937 = vshll.u32 %v63932, 26 (stack44)
        %v63938 = vshrl.u32 %v63932, 6 (stack45)
        %v63939 = vor.u32 %v63938, %v63937 (stack46)
        %v63940 = vxor.u32 %v63939, %v63935 (stack47)
        %v63943 = vadd.s32 %v63940, %v63935 (stack39)
        %v63947 = vadd.s32 %v63943, %v9 (stack39)
        %v63949 = vshll.u32 %v63940, 6 (stack44)
        %v63950 = vshrl.u32 %v63940, 26 (stack45)
        %v63951 = vor.u32 %v63950, %v63949 (stack46)
        %v63952 = vxor.u32 %v63951, %v63943 (stack47)
        %v63955 = vadd.s32 %v63952, %v8 (stack39)
        %v63959 = vadd.s32 1, %v63955 (stack39)
        %v63963 = vadd.s32 %v63959, %v63947 (stack39)
        %v63965 = vshll.u32 %v63959, 17 (stack44)
        %v63966 = vshrl.u32 %v63959, 15 (stack45)
        %v63967 = vor.u32 %v63966, %v63965 (stack46)
        %v63968 = vxor.u32 %v63967, %v63963 (stack47)
        %v63971 = vadd.s32 %v63968, %v63963 (stack39)
        %v63973 = vshll.u32 %v63968, 29 (stack44)
        %v63974 = vshrl.u32 %v63968, 3 (stack45)
        %v63975 = vor.u32 %v63974, %v63973 (stack46)
        %v63976 = vxor.u32 %v63975, %v63971 (stack47)
        %v63979 = vadd.s32 %v63976, %v63971 (stack39)
        %v63981 = vshll.u32 %v63976, 16 (stack44)
        %v63982 = vshrl.u32 %v63976, 16 (stack45)
        %v63983 = vor.u32 %v63982, %v63981 (stack46)
        %v63984 = vxor.u32 %v63983, %v63979 (stack47)
        %v63987 = vadd.s32 %v63984, %v63979 (stack39)
        %v63991 = vadd.s32 %v63987, %v8 (stack39)
        %v63993 = vshll.u32 %v63984, 24 (stack44)
        %v63994 = vshrl.u32 %v63984, 8 (stack45)
        %v63995 = vor.u32 %v63994, %v63993 (stack46)
        %v63996 = vxor.u32 %v63995, %v63987 (stack47)
        %v63999 = vadd.s32 %v63996, %v10 (stack39)
        %v64003 = vadd.s32 2, %v63999 (stack39)
        %v64007 = vadd.s32 %v64003, %v63991 (stack39)
        %v64009 = vshll.u32 %v64003, 13 (stack44)
        %v64010 = vshrl.u32 %v64003, 19 (stack45)
        %v64011 = vor.u32 %v64010, %v64009 (stack46)
        %v64012 = vxor.u32 %v64011, %v64007 (stack47)
        %v64015 = vadd.s32 %v64012, %v64007 (stack39)
        %v64017 = vshll.u32 %v64012, 15 (stack44)
        %v64018 = vshrl.u32 %v64012, 17 (stack45)
        %v64019 = vor.u32 %v64018, %v64017 (stack46)
        %v64020 = vxor.u32 %v64019, %v64015 (stack47)
        %v64023 = vadd.s32 %v64020, %v64015 (stack39)
        %v64025 = vshll.u32 %v64020, 26 (stack44)
        %v64026 = vshrl.u32 %v64020, 6 (stack45)
        %v64027 = vor.u32 %v64026, %v64025 (stack46)
        %v64028 = vxor.u32 %v64027, %v64023 (stack47)
        %v64031 = vadd.s32 %v64028, %v64023 (stack39)
        %v64035 = vadd.s32 %v64031, %v10 (stack39)
        %v64037 = vshll.u32 %v64028, 6 (stack44)
        %v64038 = vshrl.u32 %v64028, 26 (stack45)
        %v64039 = vor.u32 %v64038, %v64037 (stack46)
        %v64040 = vxor.u32 %v64039, %v64031 (stack47)
        %v64043 = vadd.s32 %v64040, %v9 (stack39)
        %v64047 = vadd.s32 3, %v64043 (stack39)
        %v64051 = vadd.s32 %v64047, %v64035 (stack39)
        %v64053 = vshll.u32 %v64047, 17 (stack44)
        %v64054 = vshrl.u32 %v64047, 15 (stack45)
        %v64055 = vor.u32 %v64054, %v64053 (stack46)
        %v64056 = vxor.u32 %v64055, %v64051 (stack47)
        %v64059 = vadd.s32 %v64056, %v64051 (stack39)
        %v64061 = vshll.u32 %v64056, 29 (stack44)
        %v64062 = vshrl.u32 %v64056, 3 (stack45)
        %v64063 = vor.u32 %v64062, %v64061 (stack46)
        %v64064 = vxor.u32 %v64063, %v64059 (stack47)
        %v64067 = vadd.s32 %v64064, %v64059 (stack39)
        %v64069 = vshll.u32 %v64064, 16 (stack44)
        %v64070 = vshrl.u32 %v64064, 16 (stack45)
        %v64071 = vor.u32 %v64070, %v64069 (stack46)
        %v64072 = vxor.u32 %v64071, %v64067 (stack47)
        %v64075 = vadd.s32 %v64072, %v64067 (stack39)
        %v64079 = vadd.s32 %v64075, %v9 (stack39)
        %v64081 = vshll.u32 %v64072, 24 (stack44)
        %v64082 = vshrl.u32 %v64072, 8 (stack45)
        %v64083 = vor.u32 %v64082, %v64081 (stack46)
        %v64084 = vxor.u32 %v64083, %v64075 (stack47)
        %v64087 = vadd.s32 %v64084, %v8 (stack39)
        %v64091 = vadd.s32 4, %v64087 (stack39)
        %v64095 = vadd.s32 %v64091, %v64079 (stack39)
        %v64097 = vshll.u32 %v64091, 13 (stack44)
        %v64098 = vshrl.u32 %v64091, 19 (stack45)
        %v64099 = vor.u32 %v64098, %v64097 (stack46)
        %v64100 = vxor.u32 %v64099, %v64095 (stack47)
        %v64103 = vadd.s32 %v64100, %v64095 (stack39)
        %v64105 = vshll.u32 %v64100, 15 (stack44)
        %v64106 = vshrl.u32 %v64100, 17 (stack45)
        %v64107 = vor.u32 %v64106, %v64105 (stack46)
        %v64108 = vxor.u32 %v64107, %v64103 (stack47)
        %v64111 = vadd.s32 %v64108, %v64103 (stack39)
        %v64113 = vshll.u32 %v64108, 26 (stack44)
        %v64114 = vshrl.u32 %v64108, 6 (stack45)
        %v64115 = vor.u32 %v64114, %v64113 (stack46)
        %v64116 = vxor.u32 %v64115, %v64111 (stack47)
        %v64119 = vadd.s32 %v64116, %v64111 (stack39)
        %v64123 = vadd.s32 %v64119, %v8 (stack39)
        %v64125 = vshll.u32 %v64116, 6 (stack44)
        %v64126 = vshrl.u32 %v64116, 26 (stack45)
        %v64127 = vor.u32 %v64126, %v64125 (stack46)
        %v64128 = vxor.u32 %v64127, %v64119 (stack47)
        %v64131 = vadd.s32 %v64128, %v10 (stack39)
        %v64135 = vadd.s32 5, %v64131 (stack39)
        %v64137 = vxor.u32 %v64135, %v64123 (stack47)
        %v64138 = vand.u32.u8 255, %v64137 (stack48)
        %v64139 = vand.u32 65535, %v64138 (stack49)
        %v64140 = vshrl.u32 %v64139, 1 (stack50)
        %v64141 = vor.u32 16256, %v64140 (stack46)
        %v64142 = vand.u32.u16 65535, %v64141 (stack51)
        %v120088 = vadd.low.f32.bf16 -1.0, %v64142 (stack52)
        %v64151 = vmul.f32 2.0, %v120088 (stack53)
        %v64155 = vadd.f32 -0.99609375, %v64151 (stack52)
        %v64159 = vmax.f32 %v64155, -0.99609375 (stack54)
        %v64161 = vand.u32 2147483647, %v64159 (stack55)
        %vm64164 = vcmp.eq.f32.partialorder %v64161, 1.0 (stack56)
        %v64169 = vmul.f32 inf, %v64159 (stack53)
        %v64171 = vxor.u32 2147483648, %v64159 (stack57)
        %v64174 = vmul.f32 %v64171, %v64159 (stack53)
        %v64176 = vadd.f32 1.0, %v64174 (stack58)
        %v64177 = vlog2.pop %v64176 (stack59)
        %v64178 = vmul.f32 0.6931472, %v64177 (stack60)
        %v64179 = vmul.f32 -0.5, %v64174 (stack61)
        %v64180 = vadd.f32 1.0, %v64179 (stack62)
        %v64181 = vmul.f32 %v64180, %v64174 (stack63)
        %v64182 = vand.u32 2147483647, %v64174 (stack64)
        %vm64183 = vcmp.lt.f32.partialorder %v64182, 0.0004427343 (stack65)
        %v64184 = vsel /*vm=*/%vm64183, /*on_true_vy=*/%v64181, /*on_false_vx=*/%v64178 (stack66)
        %v64185 = vxor.u32 2147483648, %v64184 (stack57)
        %vm64188 = vcmp.lt.f32.partialorder %v64185, 5.0 (stack56)
        %v64193 = vsel /*vm=*/%vm64188, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v64197 = vsel /*vm=*/%vm64188, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v64201 = vsel /*vm=*/%vm64188, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v64205 = vsel /*vm=*/%vm64188, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v64209 = vsel /*vm=*/%vm64188, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v64213 = vsel /*vm=*/%vm64188, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v64217 = vsel /*vm=*/%vm64188, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v64221 = vsel /*vm=*/%vm64188, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v64225 = vsel /*vm=*/%vm64188, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v64229 = vadd.f32 -2.5, %v64185 (stack52)
        %v64231 = vrsqrt.pop %v64185 (stack67)
        %v64232 = vmul.f32 %v64231, %v64185 (stack68)
        %vm64233 = vcmp.eq.f32.partialorder %v64185, inf (stack69)
        %v64234 = vsel /*vm=*/%vm64233, /*on_true_vy=*/%v64185, /*on_false_vx=*/%v64232 (stack70)
        %vm64235 = vcmp.eq.f32.partialorder %v64185, 0.0 (stack71)
        %v64236 = vand.u32 2147483648, %v64185 (stack72)
        %v64237 = vsel /*vm=*/%vm64235, /*on_true_vy=*/%v64236, /*on_false_vx=*/%v64234 (stack73)
        %v64240 = vadd.f32 -3.0, %v64237 (stack52)
        %v64244 = vsel /*vm=*/%vm64188, /*on_true_vy=*/%v64229, /*on_false_vx=*/%v64240 (stack43)
        %v64248 = vmul.f32 %v64244, %v64225 (stack53)
        %v64252 = vadd.f32 %v64248, %v64221 (stack52)
        %v64256 = vmul.f32 %v64252, %v64244 (stack53)
        %v64260 = vadd.f32 %v64256, %v64217 (stack52)
        %v64264 = vmul.f32 %v64260, %v64244 (stack53)
        %v64268 = vadd.f32 %v64264, %v64213 (stack52)
        %v64272 = vmul.f32 %v64268, %v64244 (stack53)
        %v64276 = vadd.f32 %v64272, %v64209 (stack52)
        %v64280 = vmul.f32 %v64276, %v64244 (stack53)
        %v64284 = vadd.f32 %v64280, %v64205 (stack52)
        %v64288 = vmul.f32 %v64284, %v64244 (stack53)
        %v64292 = vadd.f32 %v64288, %v64201 (stack52)
        %v64296 = vmul.f32 %v64292, %v64244 (stack53)
        %v64300 = vadd.f32 %v64296, %v64197 (stack52)
        %v64304 = vmul.f32 %v64300, %v64244 (stack53)
        %v64308 = vadd.f32 %v64304, %v64193 (stack52)
        %v64312 = vmul.f32 %v64308, %v64159 (stack53)
        %v64316 = vsel /*vm=*/%vm64164, /*on_true_vy=*/%v64169, /*on_false_vx=*/%v64312 (stack43)
        %v64320 = vmul.f32 1.4140625, %v64316 (stack53)
        %v64323 = vpack.c.bf16 0.0, %v64320 (stack74)
        %120089 = vst [vmem:[%s280 + $0x44] sm:$0xf] /*vst_source=*/%v64323 (stack75)
        %v64327 = vadd.s32 %v63863, %v894 (stack39)
        %v64337 = vadd.s32 %v64327, %v415 (stack39)
        %vm64341 = vcmp.lt.u32.totalorder %v64337, %v64327 (stack42)
        %vm64346 = vcmp.lt.u32.totalorder %v64327, %v894 (stack42)
        %v64351 = vadd.s32 %v63846, %v881 (stack39)
        %v64355 = vadd.s32 1, %v64351 (stack39)
        %v64359 = vsel /*vm=*/%vm64346, /*on_true_vy=*/%v64355, /*on_false_vx=*/%v64351 (stack43)
        %v64363 = vadd.s32 1, %v64359 (stack39)
        %v64367 = vsel /*vm=*/%vm64341, /*on_true_vy=*/%v64363, /*on_false_vx=*/%v64359 (stack43)
        %v64372 = vadd.s32 %v64367, %v10 (stack39)
        %v64376 = vadd.s32 %v64337, %v9 (stack39)
        %v64380 = vadd.s32 %v64376, %v64372 (stack39)
        %v64382 = vshll.u32 %v64376, 13 (stack44)
        %v64383 = vshrl.u32 %v64376, 19 (stack45)
        %v64384 = vor.u32 %v64383, %v64382 (stack46)
        %v64385 = vxor.u32 %v64384, %v64380 (stack47)
        %v64388 = vadd.s32 %v64385, %v64380 (stack39)
        %v64390 = vshll.u32 %v64385, 15 (stack44)
        %v64391 = vshrl.u32 %v64385, 17 (stack45)
        %v64392 = vor.u32 %v64391, %v64390 (stack46)
        %v64393 = vxor.u32 %v64392, %v64388 (stack47)
        %v64396 = vadd.s32 %v64393, %v64388 (stack39)
        %v64398 = vshll.u32 %v64393, 26 (stack44)
        %v64399 = vshrl.u32 %v64393, 6 (stack45)
        %v64400 = vor.u32 %v64399, %v64398 (stack46)
        %v64401 = vxor.u32 %v64400, %v64396 (stack47)
        %v64404 = vadd.s32 %v64401, %v64396 (stack39)
        %v64408 = vadd.s32 %v64404, %v9 (stack39)
        %v64410 = vshll.u32 %v64401, 6 (stack44)
        %v64411 = vshrl.u32 %v64401, 26 (stack45)
        %v64412 = vor.u32 %v64411, %v64410 (stack46)
        %v64413 = vxor.u32 %v64412, %v64404 (stack47)
        %v64416 = vadd.s32 %v64413, %v8 (stack39)
        %v64420 = vadd.s32 1, %v64416 (stack39)
        %v64424 = vadd.s32 %v64420, %v64408 (stack39)
        %v64426 = vshll.u32 %v64420, 17 (stack44)
        %v64427 = vshrl.u32 %v64420, 15 (stack45)
        %v64428 = vor.u32 %v64427, %v64426 (stack46)
        %v64429 = vxor.u32 %v64428, %v64424 (stack47)
        %v64432 = vadd.s32 %v64429, %v64424 (stack39)
        %v64434 = vshll.u32 %v64429, 29 (stack44)
        %v64435 = vshrl.u32 %v64429, 3 (stack45)
        %v64436 = vor.u32 %v64435, %v64434 (stack46)
        %v64437 = vxor.u32 %v64436, %v64432 (stack47)
        %v64440 = vadd.s32 %v64437, %v64432 (stack39)
        %v64442 = vshll.u32 %v64437, 16 (stack44)
        %v64443 = vshrl.u32 %v64437, 16 (stack45)
        %v64444 = vor.u32 %v64443, %v64442 (stack46)
        %v64445 = vxor.u32 %v64444, %v64440 (stack47)
        %v64448 = vadd.s32 %v64445, %v64440 (stack39)
        %v64452 = vadd.s32 %v64448, %v8 (stack39)
        %v64454 = vshll.u32 %v64445, 24 (stack44)
        %v64455 = vshrl.u32 %v64445, 8 (stack45)
        %v64456 = vor.u32 %v64455, %v64454 (stack46)
        %v64457 = vxor.u32 %v64456, %v64448 (stack47)
        %v64460 = vadd.s32 %v64457, %v10 (stack39)
        %v64464 = vadd.s32 2, %v64460 (stack39)
        %v64468 = vadd.s32 %v64464, %v64452 (stack39)
        %v64470 = vshll.u32 %v64464, 13 (stack44)
        %v64471 = vshrl.u32 %v64464, 19 (stack45)
        %v64472 = vor.u32 %v64471, %v64470 (stack46)
        %v64473 = vxor.u32 %v64472, %v64468 (stack47)
        %v64476 = vadd.s32 %v64473, %v64468 (stack39)
        %v64478 = vshll.u32 %v64473, 15 (stack44)
        %v64479 = vshrl.u32 %v64473, 17 (stack45)
        %v64480 = vor.u32 %v64479, %v64478 (stack46)
        %v64481 = vxor.u32 %v64480, %v64476 (stack47)
        %v64484 = vadd.s32 %v64481, %v64476 (stack39)
        %v64486 = vshll.u32 %v64481, 26 (stack44)
        %v64487 = vshrl.u32 %v64481, 6 (stack45)
        %v64488 = vor.u32 %v64487, %v64486 (stack46)
        %v64489 = vxor.u32 %v64488, %v64484 (stack47)
        %v64492 = vadd.s32 %v64489, %v64484 (stack39)
        %v64496 = vadd.s32 %v64492, %v10 (stack39)
        %v64498 = vshll.u32 %v64489, 6 (stack44)
        %v64499 = vshrl.u32 %v64489, 26 (stack45)
        %v64500 = vor.u32 %v64499, %v64498 (stack46)
        %v64501 = vxor.u32 %v64500, %v64492 (stack47)
        %v64504 = vadd.s32 %v64501, %v9 (stack39)
        %v64508 = vadd.s32 3, %v64504 (stack39)
        %v64512 = vadd.s32 %v64508, %v64496 (stack39)
        %v64514 = vshll.u32 %v64508, 17 (stack44)
        %v64515 = vshrl.u32 %v64508, 15 (stack45)
        %v64516 = vor.u32 %v64515, %v64514 (stack46)
        %v64517 = vxor.u32 %v64516, %v64512 (stack47)
        %v64520 = vadd.s32 %v64517, %v64512 (stack39)
        %v64522 = vshll.u32 %v64517, 29 (stack44)
        %v64523 = vshrl.u32 %v64517, 3 (stack45)
        %v64524 = vor.u32 %v64523, %v64522 (stack46)
        %v64525 = vxor.u32 %v64524, %v64520 (stack47)
        %v64528 = vadd.s32 %v64525, %v64520 (stack39)
        %v64530 = vshll.u32 %v64525, 16 (stack44)
        %v64531 = vshrl.u32 %v64525, 16 (stack45)
        %v64532 = vor.u32 %v64531, %v64530 (stack46)
        %v64533 = vxor.u32 %v64532, %v64528 (stack47)
        %v64536 = vadd.s32 %v64533, %v64528 (stack39)
        %v64540 = vadd.s32 %v64536, %v9 (stack39)
        %v64542 = vshll.u32 %v64533, 24 (stack44)
        %v64543 = vshrl.u32 %v64533, 8 (stack45)
        %v64544 = vor.u32 %v64543, %v64542 (stack46)
        %v64545 = vxor.u32 %v64544, %v64536 (stack47)
        %v64548 = vadd.s32 %v64545, %v8 (stack39)
        %v64552 = vadd.s32 4, %v64548 (stack39)
        %v64556 = vadd.s32 %v64552, %v64540 (stack39)
        %v64558 = vshll.u32 %v64552, 13 (stack44)
        %v64559 = vshrl.u32 %v64552, 19 (stack45)
        %v64560 = vor.u32 %v64559, %v64558 (stack46)
        %v64561 = vxor.u32 %v64560, %v64556 (stack47)
        %v64564 = vadd.s32 %v64561, %v64556 (stack39)
        %v64566 = vshll.u32 %v64561, 15 (stack44)
        %v64567 = vshrl.u32 %v64561, 17 (stack45)
        %v64568 = vor.u32 %v64567, %v64566 (stack46)
        %v64569 = vxor.u32 %v64568, %v64564 (stack47)
        %v64572 = vadd.s32 %v64569, %v64564 (stack39)
        %v64574 = vshll.u32 %v64569, 26 (stack44)
        %v64575 = vshrl.u32 %v64569, 6 (stack45)
        %v64576 = vor.u32 %v64575, %v64574 (stack46)
        %v64577 = vxor.u32 %v64576, %v64572 (stack47)
        %v64580 = vadd.s32 %v64577, %v64572 (stack39)
        %v64584 = vadd.s32 %v64580, %v8 (stack39)
        %v64586 = vshll.u32 %v64577, 6 (stack44)
        %v64587 = vshrl.u32 %v64577, 26 (stack45)
        %v64588 = vor.u32 %v64587, %v64586 (stack46)
        %v64589 = vxor.u32 %v64588, %v64580 (stack47)
        %v64592 = vadd.s32 %v64589, %v10 (stack39)
        %v64596 = vadd.s32 5, %v64592 (stack39)
        %v64598 = vxor.u32 %v64596, %v64584 (stack47)
        %v64599 = vand.u32.u8 255, %v64598 (stack48)
        %v64600 = vand.u32 65535, %v64599 (stack49)
        %v64601 = vshrl.u32 %v64600, 1 (stack50)
        %v64602 = vor.u32 16256, %v64601 (stack46)
        %v64603 = vand.u32.u16 65535, %v64602 (stack51)
        %v120090 = vadd.low.f32.bf16 -1.0, %v64603 (stack52)
        %v64612 = vmul.f32 2.0, %v120090 (stack53)
        %v64616 = vadd.f32 -0.99609375, %v64612 (stack52)
        %v64620 = vmax.f32 %v64616, -0.99609375 (stack54)
        %v64622 = vand.u32 2147483647, %v64620 (stack55)
        %vm64625 = vcmp.eq.f32.partialorder %v64622, 1.0 (stack56)
        %v64630 = vmul.f32 inf, %v64620 (stack53)
        %v64632 = vxor.u32 2147483648, %v64620 (stack57)
        %v64635 = vmul.f32 %v64632, %v64620 (stack53)
        %v64637 = vadd.f32 1.0, %v64635 (stack58)
        %v64638 = vlog2.pop %v64637 (stack59)
        %v64639 = vmul.f32 0.6931472, %v64638 (stack60)
        %v64640 = vmul.f32 -0.5, %v64635 (stack61)
        %v64641 = vadd.f32 1.0, %v64640 (stack62)
        %v64642 = vmul.f32 %v64641, %v64635 (stack63)
        %v64643 = vand.u32 2147483647, %v64635 (stack64)
        %vm64644 = vcmp.lt.f32.partialorder %v64643, 0.0004427343 (stack65)
        %v64645 = vsel /*vm=*/%vm64644, /*on_true_vy=*/%v64642, /*on_false_vx=*/%v64639 (stack66)
        %v64646 = vxor.u32 2147483648, %v64645 (stack57)
        %vm64649 = vcmp.lt.f32.partialorder %v64646, 5.0 (stack56)
        %v64654 = vsel /*vm=*/%vm64649, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v64658 = vsel /*vm=*/%vm64649, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v64662 = vsel /*vm=*/%vm64649, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v64666 = vsel /*vm=*/%vm64649, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v64670 = vsel /*vm=*/%vm64649, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v64674 = vsel /*vm=*/%vm64649, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v64678 = vsel /*vm=*/%vm64649, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v64682 = vsel /*vm=*/%vm64649, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v64686 = vsel /*vm=*/%vm64649, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v64690 = vadd.f32 -2.5, %v64646 (stack52)
        %v64692 = vrsqrt.pop %v64646 (stack67)
        %v64693 = vmul.f32 %v64692, %v64646 (stack68)
        %vm64694 = vcmp.eq.f32.partialorder %v64646, inf (stack69)
        %v64695 = vsel /*vm=*/%vm64694, /*on_true_vy=*/%v64646, /*on_false_vx=*/%v64693 (stack70)
        %vm64696 = vcmp.eq.f32.partialorder %v64646, 0.0 (stack71)
        %v64697 = vand.u32 2147483648, %v64646 (stack72)
        %v64698 = vsel /*vm=*/%vm64696, /*on_true_vy=*/%v64697, /*on_false_vx=*/%v64695 (stack73)
        %v64701 = vadd.f32 -3.0, %v64698 (stack52)
        %v64705 = vsel /*vm=*/%vm64649, /*on_true_vy=*/%v64690, /*on_false_vx=*/%v64701 (stack43)
        %v64709 = vmul.f32 %v64705, %v64686 (stack53)
        %v64713 = vadd.f32 %v64709, %v64682 (stack52)
        %v64717 = vmul.f32 %v64713, %v64705 (stack53)
        %v64721 = vadd.f32 %v64717, %v64678 (stack52)
        %v64725 = vmul.f32 %v64721, %v64705 (stack53)
        %v64729 = vadd.f32 %v64725, %v64674 (stack52)
        %v64733 = vmul.f32 %v64729, %v64705 (stack53)
        %v64737 = vadd.f32 %v64733, %v64670 (stack52)
        %v64741 = vmul.f32 %v64737, %v64705 (stack53)
        %v64745 = vadd.f32 %v64741, %v64666 (stack52)
        %v64749 = vmul.f32 %v64745, %v64705 (stack53)
        %v64753 = vadd.f32 %v64749, %v64662 (stack52)
        %v64757 = vmul.f32 %v64753, %v64705 (stack53)
        %v64761 = vadd.f32 %v64757, %v64658 (stack52)
        %v64765 = vmul.f32 %v64761, %v64705 (stack53)
        %v64769 = vadd.f32 %v64765, %v64654 (stack52)
        %v64773 = vmul.f32 %v64769, %v64620 (stack53)
        %v64777 = vsel /*vm=*/%vm64625, /*on_true_vy=*/%v64630, /*on_false_vx=*/%v64773 (stack43)
        %v64781 = vmul.f32 1.4140625, %v64777 (stack53)
        %v64784 = vpack.c.bf16 0.0, %v64781 (stack74)
        %120091 = vst [vmem:[%s280 + $0xc4] sm:$0xf] /*vst_source=*/%v64784 (stack75)
        %v64788 = vadd.s32 %v63863, %v1381 (stack39)
        %v64798 = vadd.s32 %v64788, %v415 (stack39)
        %vm64802 = vcmp.lt.u32.totalorder %v64798, %v64788 (stack42)
        %vm64807 = vcmp.lt.u32.totalorder %v64788, %v1381 (stack42)
        %v64812 = vadd.s32 %v63846, %v1368 (stack39)
        %v64816 = vadd.s32 1, %v64812 (stack39)
        %v64820 = vsel /*vm=*/%vm64807, /*on_true_vy=*/%v64816, /*on_false_vx=*/%v64812 (stack43)
        %v64824 = vadd.s32 1, %v64820 (stack39)
        %v64828 = vsel /*vm=*/%vm64802, /*on_true_vy=*/%v64824, /*on_false_vx=*/%v64820 (stack43)
        %v64833 = vadd.s32 %v64828, %v10 (stack39)
        %v64837 = vadd.s32 %v64798, %v9 (stack39)
        %v64841 = vadd.s32 %v64837, %v64833 (stack39)
        %v64843 = vshll.u32 %v64837, 13 (stack44)
        %v64844 = vshrl.u32 %v64837, 19 (stack45)
        %v64845 = vor.u32 %v64844, %v64843 (stack46)
        %v64846 = vxor.u32 %v64845, %v64841 (stack47)
        %v64849 = vadd.s32 %v64846, %v64841 (stack39)
        %v64851 = vshll.u32 %v64846, 15 (stack44)
        %v64852 = vshrl.u32 %v64846, 17 (stack45)
        %v64853 = vor.u32 %v64852, %v64851 (stack46)
        %v64854 = vxor.u32 %v64853, %v64849 (stack47)
        %v64857 = vadd.s32 %v64854, %v64849 (stack39)
        %v64859 = vshll.u32 %v64854, 26 (stack44)
        %v64860 = vshrl.u32 %v64854, 6 (stack45)
        %v64861 = vor.u32 %v64860, %v64859 (stack46)
        %v64862 = vxor.u32 %v64861, %v64857 (stack47)
        %v64865 = vadd.s32 %v64862, %v64857 (stack39)
        %v64869 = vadd.s32 %v64865, %v9 (stack39)
        %v64871 = vshll.u32 %v64862, 6 (stack44)
        %v64872 = vshrl.u32 %v64862, 26 (stack45)
        %v64873 = vor.u32 %v64872, %v64871 (stack46)
        %v64874 = vxor.u32 %v64873, %v64865 (stack47)
        %v64877 = vadd.s32 %v64874, %v8 (stack39)
        %v64881 = vadd.s32 1, %v64877 (stack39)
        %v64885 = vadd.s32 %v64881, %v64869 (stack39)
        %v64887 = vshll.u32 %v64881, 17 (stack44)
        %v64888 = vshrl.u32 %v64881, 15 (stack45)
        %v64889 = vor.u32 %v64888, %v64887 (stack46)
        %v64890 = vxor.u32 %v64889, %v64885 (stack47)
        %v64893 = vadd.s32 %v64890, %v64885 (stack39)
        %v64895 = vshll.u32 %v64890, 29 (stack44)
        %v64896 = vshrl.u32 %v64890, 3 (stack45)
        %v64897 = vor.u32 %v64896, %v64895 (stack46)
        %v64898 = vxor.u32 %v64897, %v64893 (stack47)
        %v64901 = vadd.s32 %v64898, %v64893 (stack39)
        %v64903 = vshll.u32 %v64898, 16 (stack44)
        %v64904 = vshrl.u32 %v64898, 16 (stack45)
        %v64905 = vor.u32 %v64904, %v64903 (stack46)
        %v64906 = vxor.u32 %v64905, %v64901 (stack47)
        %v64909 = vadd.s32 %v64906, %v64901 (stack39)
        %v64913 = vadd.s32 %v64909, %v8 (stack39)
        %v64915 = vshll.u32 %v64906, 24 (stack44)
        %v64916 = vshrl.u32 %v64906, 8 (stack45)
        %v64917 = vor.u32 %v64916, %v64915 (stack46)
        %v64918 = vxor.u32 %v64917, %v64909 (stack47)
        %v64921 = vadd.s32 %v64918, %v10 (stack39)
        %v64925 = vadd.s32 2, %v64921 (stack39)
        %v64929 = vadd.s32 %v64925, %v64913 (stack39)
        %v64931 = vshll.u32 %v64925, 13 (stack44)
        %v64932 = vshrl.u32 %v64925, 19 (stack45)
        %v64933 = vor.u32 %v64932, %v64931 (stack46)
        %v64934 = vxor.u32 %v64933, %v64929 (stack47)
        %v64937 = vadd.s32 %v64934, %v64929 (stack39)
        %v64939 = vshll.u32 %v64934, 15 (stack44)
        %v64940 = vshrl.u32 %v64934, 17 (stack45)
        %v64941 = vor.u32 %v64940, %v64939 (stack46)
        %v64942 = vxor.u32 %v64941, %v64937 (stack47)
        %v64945 = vadd.s32 %v64942, %v64937 (stack39)
        %v64947 = vshll.u32 %v64942, 26 (stack44)
        %v64948 = vshrl.u32 %v64942, 6 (stack45)
        %v64949 = vor.u32 %v64948, %v64947 (stack46)
        %v64950 = vxor.u32 %v64949, %v64945 (stack47)
        %v64953 = vadd.s32 %v64950, %v64945 (stack39)
        %v64957 = vadd.s32 %v64953, %v10 (stack39)
        %v64959 = vshll.u32 %v64950, 6 (stack44)
        %v64960 = vshrl.u32 %v64950, 26 (stack45)
        %v64961 = vor.u32 %v64960, %v64959 (stack46)
        %v64962 = vxor.u32 %v64961, %v64953 (stack47)
        %v64965 = vadd.s32 %v64962, %v9 (stack39)
        %v64969 = vadd.s32 3, %v64965 (stack39)
        %v64973 = vadd.s32 %v64969, %v64957 (stack39)
        %v64975 = vshll.u32 %v64969, 17 (stack44)
        %v64976 = vshrl.u32 %v64969, 15 (stack45)
        %v64977 = vor.u32 %v64976, %v64975 (stack46)
        %v64978 = vxor.u32 %v64977, %v64973 (stack47)
        %v64981 = vadd.s32 %v64978, %v64973 (stack39)
        %v64983 = vshll.u32 %v64978, 29 (stack44)
        %v64984 = vshrl.u32 %v64978, 3 (stack45)
        %v64985 = vor.u32 %v64984, %v64983 (stack46)
        %v64986 = vxor.u32 %v64985, %v64981 (stack47)
        %v64989 = vadd.s32 %v64986, %v64981 (stack39)
        %v64991 = vshll.u32 %v64986, 16 (stack44)
        %v64992 = vshrl.u32 %v64986, 16 (stack45)
        %v64993 = vor.u32 %v64992, %v64991 (stack46)
        %v64994 = vxor.u32 %v64993, %v64989 (stack47)
        %v64997 = vadd.s32 %v64994, %v64989 (stack39)
        %v65001 = vadd.s32 %v64997, %v9 (stack39)
        %v65003 = vshll.u32 %v64994, 24 (stack44)
        %v65004 = vshrl.u32 %v64994, 8 (stack45)
        %v65005 = vor.u32 %v65004, %v65003 (stack46)
        %v65006 = vxor.u32 %v65005, %v64997 (stack47)
        %v65009 = vadd.s32 %v65006, %v8 (stack39)
        %v65013 = vadd.s32 4, %v65009 (stack39)
        %v65017 = vadd.s32 %v65013, %v65001 (stack39)
        %v65019 = vshll.u32 %v65013, 13 (stack44)
        %v65020 = vshrl.u32 %v65013, 19 (stack45)
        %v65021 = vor.u32 %v65020, %v65019 (stack46)
        %v65022 = vxor.u32 %v65021, %v65017 (stack47)
        %v65025 = vadd.s32 %v65022, %v65017 (stack39)
        %v65027 = vshll.u32 %v65022, 15 (stack44)
        %v65028 = vshrl.u32 %v65022, 17 (stack45)
        %v65029 = vor.u32 %v65028, %v65027 (stack46)
        %v65030 = vxor.u32 %v65029, %v65025 (stack47)
        %v65033 = vadd.s32 %v65030, %v65025 (stack39)
        %v65035 = vshll.u32 %v65030, 26 (stack44)
        %v65036 = vshrl.u32 %v65030, 6 (stack45)
        %v65037 = vor.u32 %v65036, %v65035 (stack46)
        %v65038 = vxor.u32 %v65037, %v65033 (stack47)
        %v65041 = vadd.s32 %v65038, %v65033 (stack39)
        %v65045 = vadd.s32 %v65041, %v8 (stack39)
        %v65047 = vshll.u32 %v65038, 6 (stack44)
        %v65048 = vshrl.u32 %v65038, 26 (stack45)
        %v65049 = vor.u32 %v65048, %v65047 (stack46)
        %v65050 = vxor.u32 %v65049, %v65041 (stack47)
        %v65053 = vadd.s32 %v65050, %v10 (stack39)
        %v65057 = vadd.s32 5, %v65053 (stack39)
        %v65059 = vxor.u32 %v65057, %v65045 (stack47)
        %v65060 = vand.u32.u8 255, %v65059 (stack48)
        %v65061 = vand.u32 65535, %v65060 (stack49)
        %v65062 = vshrl.u32 %v65061, 1 (stack50)
        %v65063 = vor.u32 16256, %v65062 (stack46)
        %v65064 = vand.u32.u16 65535, %v65063 (stack51)
        %v120092 = vadd.low.f32.bf16 -1.0, %v65064 (stack52)
        %v65073 = vmul.f32 2.0, %v120092 (stack53)
        %v65077 = vadd.f32 -0.99609375, %v65073 (stack52)
        %v65081 = vmax.f32 %v65077, -0.99609375 (stack54)
        %v65083 = vand.u32 2147483647, %v65081 (stack55)
        %vm65086 = vcmp.eq.f32.partialorder %v65083, 1.0 (stack56)
        %v65091 = vmul.f32 inf, %v65081 (stack53)
        %v65093 = vxor.u32 2147483648, %v65081 (stack57)
        %v65096 = vmul.f32 %v65093, %v65081 (stack53)
        %v65098 = vadd.f32 1.0, %v65096 (stack58)
        %v65099 = vlog2.pop %v65098 (stack59)
        %v65100 = vmul.f32 0.6931472, %v65099 (stack60)
        %v65101 = vmul.f32 -0.5, %v65096 (stack61)
        %v65102 = vadd.f32 1.0, %v65101 (stack62)
        %v65103 = vmul.f32 %v65102, %v65096 (stack63)
        %v65104 = vand.u32 2147483647, %v65096 (stack64)
        %vm65105 = vcmp.lt.f32.partialorder %v65104, 0.0004427343 (stack65)
        %v65106 = vsel /*vm=*/%vm65105, /*on_true_vy=*/%v65103, /*on_false_vx=*/%v65100 (stack66)
        %v65107 = vxor.u32 2147483648, %v65106 (stack57)
        %vm65110 = vcmp.lt.f32.partialorder %v65107, 5.0 (stack56)
        %v65115 = vsel /*vm=*/%vm65110, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v65119 = vsel /*vm=*/%vm65110, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v65123 = vsel /*vm=*/%vm65110, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v65127 = vsel /*vm=*/%vm65110, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v65131 = vsel /*vm=*/%vm65110, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v65135 = vsel /*vm=*/%vm65110, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v65139 = vsel /*vm=*/%vm65110, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v65143 = vsel /*vm=*/%vm65110, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v65147 = vsel /*vm=*/%vm65110, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v65151 = vadd.f32 -2.5, %v65107 (stack52)
        %v65153 = vrsqrt.pop %v65107 (stack67)
        %v65154 = vmul.f32 %v65153, %v65107 (stack68)
        %vm65155 = vcmp.eq.f32.partialorder %v65107, inf (stack69)
        %v65156 = vsel /*vm=*/%vm65155, /*on_true_vy=*/%v65107, /*on_false_vx=*/%v65154 (stack70)
        %vm65157 = vcmp.eq.f32.partialorder %v65107, 0.0 (stack71)
        %v65158 = vand.u32 2147483648, %v65107 (stack72)
        %v65159 = vsel /*vm=*/%vm65157, /*on_true_vy=*/%v65158, /*on_false_vx=*/%v65156 (stack73)
        %v65162 = vadd.f32 -3.0, %v65159 (stack52)
        %v65166 = vsel /*vm=*/%vm65110, /*on_true_vy=*/%v65151, /*on_false_vx=*/%v65162 (stack43)
        %v65170 = vmul.f32 %v65166, %v65147 (stack53)
        %v65174 = vadd.f32 %v65170, %v65143 (stack52)
        %v65178 = vmul.f32 %v65174, %v65166 (stack53)
        %v65182 = vadd.f32 %v65178, %v65139 (stack52)
        %v65186 = vmul.f32 %v65182, %v65166 (stack53)
        %v65190 = vadd.f32 %v65186, %v65135 (stack52)
        %v65194 = vmul.f32 %v65190, %v65166 (stack53)
        %v65198 = vadd.f32 %v65194, %v65131 (stack52)
        %v65202 = vmul.f32 %v65198, %v65166 (stack53)
        %v65206 = vadd.f32 %v65202, %v65127 (stack52)
        %v65210 = vmul.f32 %v65206, %v65166 (stack53)
        %v65214 = vadd.f32 %v65210, %v65123 (stack52)
        %v65218 = vmul.f32 %v65214, %v65166 (stack53)
        %v65222 = vadd.f32 %v65218, %v65119 (stack52)
        %v65226 = vmul.f32 %v65222, %v65166 (stack53)
        %v65230 = vadd.f32 %v65226, %v65115 (stack52)
        %v65234 = vmul.f32 %v65230, %v65081 (stack53)
        %v65238 = vsel /*vm=*/%vm65086, /*on_true_vy=*/%v65091, /*on_false_vx=*/%v65234 (stack43)
        %v65242 = vmul.f32 1.4140625, %v65238 (stack53)
        %v65245 = vpack.c.bf16 0.0, %v65242 (stack74)
        %120093 = vst [vmem:[%s280 + $0x144] sm:$0xf] /*vst_source=*/%v65245 (stack75)
        %v65249 = vadd.s32 %v63863, %v1868 (stack39)
        %v65259 = vadd.s32 %v65249, %v415 (stack39)
        %vm65263 = vcmp.lt.u32.totalorder %v65259, %v65249 (stack42)
        %vm65268 = vcmp.lt.u32.totalorder %v65249, %v1868 (stack42)
        %v65273 = vadd.s32 %v63846, %v1855 (stack39)
        %v65277 = vadd.s32 1, %v65273 (stack39)
        %v65281 = vsel /*vm=*/%vm65268, /*on_true_vy=*/%v65277, /*on_false_vx=*/%v65273 (stack43)
        %v65285 = vadd.s32 1, %v65281 (stack39)
        %v65289 = vsel /*vm=*/%vm65263, /*on_true_vy=*/%v65285, /*on_false_vx=*/%v65281 (stack43)
        %v65294 = vadd.s32 %v65289, %v10 (stack39)
        %v65298 = vadd.s32 %v65259, %v9 (stack39)
        %v65302 = vadd.s32 %v65298, %v65294 (stack39)
        %v65304 = vshll.u32 %v65298, 13 (stack44)
        %v65305 = vshrl.u32 %v65298, 19 (stack45)
        %v65306 = vor.u32 %v65305, %v65304 (stack46)
        %v65307 = vxor.u32 %v65306, %v65302 (stack47)
        %v65310 = vadd.s32 %v65307, %v65302 (stack39)
        %v65312 = vshll.u32 %v65307, 15 (stack44)
        %v65313 = vshrl.u32 %v65307, 17 (stack45)
        %v65314 = vor.u32 %v65313, %v65312 (stack46)
        %v65315 = vxor.u32 %v65314, %v65310 (stack47)
        %v65318 = vadd.s32 %v65315, %v65310 (stack39)
        %v65320 = vshll.u32 %v65315, 26 (stack44)
        %v65321 = vshrl.u32 %v65315, 6 (stack45)
        %v65322 = vor.u32 %v65321, %v65320 (stack46)
        %v65323 = vxor.u32 %v65322, %v65318 (stack47)
        %v65326 = vadd.s32 %v65323, %v65318 (stack39)
        %v65330 = vadd.s32 %v65326, %v9 (stack39)
        %v65332 = vshll.u32 %v65323, 6 (stack44)
        %v65333 = vshrl.u32 %v65323, 26 (stack45)
        %v65334 = vor.u32 %v65333, %v65332 (stack46)
        %v65335 = vxor.u32 %v65334, %v65326 (stack47)
        %v65338 = vadd.s32 %v65335, %v8 (stack39)
        %v65342 = vadd.s32 1, %v65338 (stack39)
        %v65346 = vadd.s32 %v65342, %v65330 (stack39)
        %v65348 = vshll.u32 %v65342, 17 (stack44)
        %v65349 = vshrl.u32 %v65342, 15 (stack45)
        %v65350 = vor.u32 %v65349, %v65348 (stack46)
        %v65351 = vxor.u32 %v65350, %v65346 (stack47)
        %v65354 = vadd.s32 %v65351, %v65346 (stack39)
        %v65356 = vshll.u32 %v65351, 29 (stack44)
        %v65357 = vshrl.u32 %v65351, 3 (stack45)
        %v65358 = vor.u32 %v65357, %v65356 (stack46)
        %v65359 = vxor.u32 %v65358, %v65354 (stack47)
        %v65362 = vadd.s32 %v65359, %v65354 (stack39)
        %v65364 = vshll.u32 %v65359, 16 (stack44)
        %v65365 = vshrl.u32 %v65359, 16 (stack45)
        %v65366 = vor.u32 %v65365, %v65364 (stack46)
        %v65367 = vxor.u32 %v65366, %v65362 (stack47)
        %v65370 = vadd.s32 %v65367, %v65362 (stack39)
        %v65374 = vadd.s32 %v65370, %v8 (stack39)
        %v65376 = vshll.u32 %v65367, 24 (stack44)
        %v65377 = vshrl.u32 %v65367, 8 (stack45)
        %v65378 = vor.u32 %v65377, %v65376 (stack46)
        %v65379 = vxor.u32 %v65378, %v65370 (stack47)
        %v65382 = vadd.s32 %v65379, %v10 (stack39)
        %v65386 = vadd.s32 2, %v65382 (stack39)
        %v65390 = vadd.s32 %v65386, %v65374 (stack39)
        %v65392 = vshll.u32 %v65386, 13 (stack44)
        %v65393 = vshrl.u32 %v65386, 19 (stack45)
        %v65394 = vor.u32 %v65393, %v65392 (stack46)
        %v65395 = vxor.u32 %v65394, %v65390 (stack47)
        %v65398 = vadd.s32 %v65395, %v65390 (stack39)
        %v65400 = vshll.u32 %v65395, 15 (stack44)
        %v65401 = vshrl.u32 %v65395, 17 (stack45)
        %v65402 = vor.u32 %v65401, %v65400 (stack46)
        %v65403 = vxor.u32 %v65402, %v65398 (stack47)
        %v65406 = vadd.s32 %v65403, %v65398 (stack39)
        %v65408 = vshll.u32 %v65403, 26 (stack44)
        %v65409 = vshrl.u32 %v65403, 6 (stack45)
        %v65410 = vor.u32 %v65409, %v65408 (stack46)
        %v65411 = vxor.u32 %v65410, %v65406 (stack47)
        %v65414 = vadd.s32 %v65411, %v65406 (stack39)
        %v65418 = vadd.s32 %v65414, %v10 (stack39)
        %v65420 = vshll.u32 %v65411, 6 (stack44)
        %v65421 = vshrl.u32 %v65411, 26 (stack45)
        %v65422 = vor.u32 %v65421, %v65420 (stack46)
        %v65423 = vxor.u32 %v65422, %v65414 (stack47)
        %v65426 = vadd.s32 %v65423, %v9 (stack39)
        %v65430 = vadd.s32 3, %v65426 (stack39)
        %v65434 = vadd.s32 %v65430, %v65418 (stack39)
        %v65436 = vshll.u32 %v65430, 17 (stack44)
        %v65437 = vshrl.u32 %v65430, 15 (stack45)
        %v65438 = vor.u32 %v65437, %v65436 (stack46)
        %v65439 = vxor.u32 %v65438, %v65434 (stack47)
        %v65442 = vadd.s32 %v65439, %v65434 (stack39)
        %v65444 = vshll.u32 %v65439, 29 (stack44)
        %v65445 = vshrl.u32 %v65439, 3 (stack45)
        %v65446 = vor.u32 %v65445, %v65444 (stack46)
        %v65447 = vxor.u32 %v65446, %v65442 (stack47)
        %v65450 = vadd.s32 %v65447, %v65442 (stack39)
        %v65452 = vshll.u32 %v65447, 16 (stack44)
        %v65453 = vshrl.u32 %v65447, 16 (stack45)
        %v65454 = vor.u32 %v65453, %v65452 (stack46)
        %v65455 = vxor.u32 %v65454, %v65450 (stack47)
        %v65458 = vadd.s32 %v65455, %v65450 (stack39)
        %v65462 = vadd.s32 %v65458, %v9 (stack39)
        %v65464 = vshll.u32 %v65455, 24 (stack44)
        %v65465 = vshrl.u32 %v65455, 8 (stack45)
        %v65466 = vor.u32 %v65465, %v65464 (stack46)
        %v65467 = vxor.u32 %v65466, %v65458 (stack47)
        %v65470 = vadd.s32 %v65467, %v8 (stack39)
        %v65474 = vadd.s32 4, %v65470 (stack39)
        %v65478 = vadd.s32 %v65474, %v65462 (stack39)
        %v65480 = vshll.u32 %v65474, 13 (stack44)
        %v65481 = vshrl.u32 %v65474, 19 (stack45)
        %v65482 = vor.u32 %v65481, %v65480 (stack46)
        %v65483 = vxor.u32 %v65482, %v65478 (stack47)
        %v65486 = vadd.s32 %v65483, %v65478 (stack39)
        %v65488 = vshll.u32 %v65483, 15 (stack44)
        %v65489 = vshrl.u32 %v65483, 17 (stack45)
        %v65490 = vor.u32 %v65489, %v65488 (stack46)
        %v65491 = vxor.u32 %v65490, %v65486 (stack47)
        %v65494 = vadd.s32 %v65491, %v65486 (stack39)
        %v65496 = vshll.u32 %v65491, 26 (stack44)
        %v65497 = vshrl.u32 %v65491, 6 (stack45)
        %v65498 = vor.u32 %v65497, %v65496 (stack46)
        %v65499 = vxor.u32 %v65498, %v65494 (stack47)
        %v65502 = vadd.s32 %v65499, %v65494 (stack39)
        %v65506 = vadd.s32 %v65502, %v8 (stack39)
        %v65508 = vshll.u32 %v65499, 6 (stack44)
        %v65509 = vshrl.u32 %v65499, 26 (stack45)
        %v65510 = vor.u32 %v65509, %v65508 (stack46)
        %v65511 = vxor.u32 %v65510, %v65502 (stack47)
        %v65514 = vadd.s32 %v65511, %v10 (stack39)
        %v65518 = vadd.s32 5, %v65514 (stack39)
        %v65520 = vxor.u32 %v65518, %v65506 (stack47)
        %v65521 = vand.u32.u8 255, %v65520 (stack48)
        %v65522 = vand.u32 65535, %v65521 (stack49)
        %v65523 = vshrl.u32 %v65522, 1 (stack50)
        %v65524 = vor.u32 16256, %v65523 (stack46)
        %v65525 = vand.u32.u16 65535, %v65524 (stack51)
        %v120094 = vadd.low.f32.bf16 -1.0, %v65525 (stack52)
        %v65534 = vmul.f32 2.0, %v120094 (stack53)
        %v65538 = vadd.f32 -0.99609375, %v65534 (stack52)
        %v65542 = vmax.f32 %v65538, -0.99609375 (stack54)
        %v65544 = vand.u32 2147483647, %v65542 (stack55)
        %vm65547 = vcmp.eq.f32.partialorder %v65544, 1.0 (stack56)
        %v65552 = vmul.f32 inf, %v65542 (stack53)
        %v65554 = vxor.u32 2147483648, %v65542 (stack57)
        %v65557 = vmul.f32 %v65554, %v65542 (stack53)
        %v65559 = vadd.f32 1.0, %v65557 (stack58)
        %v65560 = vlog2.pop %v65559 (stack59)
        %v65561 = vmul.f32 0.6931472, %v65560 (stack60)
        %v65562 = vmul.f32 -0.5, %v65557 (stack61)
        %v65563 = vadd.f32 1.0, %v65562 (stack62)
        %v65564 = vmul.f32 %v65563, %v65557 (stack63)
        %v65565 = vand.u32 2147483647, %v65557 (stack64)
        %vm65566 = vcmp.lt.f32.partialorder %v65565, 0.0004427343 (stack65)
        %v65567 = vsel /*vm=*/%vm65566, /*on_true_vy=*/%v65564, /*on_false_vx=*/%v65561 (stack66)
        %v65568 = vxor.u32 2147483648, %v65567 (stack57)
        %vm65571 = vcmp.lt.f32.partialorder %v65568, 5.0 (stack56)
        %v65576 = vsel /*vm=*/%vm65571, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v65580 = vsel /*vm=*/%vm65571, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v65584 = vsel /*vm=*/%vm65571, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v65588 = vsel /*vm=*/%vm65571, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v65592 = vsel /*vm=*/%vm65571, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v65596 = vsel /*vm=*/%vm65571, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v65600 = vsel /*vm=*/%vm65571, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v65604 = vsel /*vm=*/%vm65571, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v65608 = vsel /*vm=*/%vm65571, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v65612 = vadd.f32 -2.5, %v65568 (stack52)
        %v65614 = vrsqrt.pop %v65568 (stack67)
        %v65615 = vmul.f32 %v65614, %v65568 (stack68)
        %vm65616 = vcmp.eq.f32.partialorder %v65568, inf (stack69)
        %v65617 = vsel /*vm=*/%vm65616, /*on_true_vy=*/%v65568, /*on_false_vx=*/%v65615 (stack70)
        %vm65618 = vcmp.eq.f32.partialorder %v65568, 0.0 (stack71)
        %v65619 = vand.u32 2147483648, %v65568 (stack72)
        %v65620 = vsel /*vm=*/%vm65618, /*on_true_vy=*/%v65619, /*on_false_vx=*/%v65617 (stack73)
        %v65623 = vadd.f32 -3.0, %v65620 (stack52)
        %v65627 = vsel /*vm=*/%vm65571, /*on_true_vy=*/%v65612, /*on_false_vx=*/%v65623 (stack43)
        %v65631 = vmul.f32 %v65627, %v65608 (stack53)
        %v65635 = vadd.f32 %v65631, %v65604 (stack52)
        %v65639 = vmul.f32 %v65635, %v65627 (stack53)
        %v65643 = vadd.f32 %v65639, %v65600 (stack52)
        %v65647 = vmul.f32 %v65643, %v65627 (stack53)
        %v65651 = vadd.f32 %v65647, %v65596 (stack52)
        %v65655 = vmul.f32 %v65651, %v65627 (stack53)
        %v65659 = vadd.f32 %v65655, %v65592 (stack52)
        %v65663 = vmul.f32 %v65659, %v65627 (stack53)
        %v65667 = vadd.f32 %v65663, %v65588 (stack52)
        %v65671 = vmul.f32 %v65667, %v65627 (stack53)
        %v65675 = vadd.f32 %v65671, %v65584 (stack52)
        %v65679 = vmul.f32 %v65675, %v65627 (stack53)
        %v65683 = vadd.f32 %v65679, %v65580 (stack52)
        %v65687 = vmul.f32 %v65683, %v65627 (stack53)
        %v65691 = vadd.f32 %v65687, %v65576 (stack52)
        %v65695 = vmul.f32 %v65691, %v65542 (stack53)
        %v65699 = vsel /*vm=*/%vm65547, /*on_true_vy=*/%v65552, /*on_false_vx=*/%v65695 (stack43)
        %v65703 = vmul.f32 1.4140625, %v65699 (stack53)
        %v65706 = vpack.c.bf16 0.0, %v65703 (stack74)
        %120095 = vst [vmem:[%s280 + $0x1c4] sm:$0xf] /*vst_source=*/%v65706 (stack75)
        %v65710 = vadd.s32 %v63863, %v2355 (stack39)
        %v65720 = vadd.s32 %v65710, %v415 (stack39)
        %vm65724 = vcmp.lt.u32.totalorder %v65720, %v65710 (stack42)
        %vm65729 = vcmp.lt.u32.totalorder %v65710, %v2355 (stack42)
        %v65734 = vadd.s32 %v63846, %v2342 (stack39)
        %v65738 = vadd.s32 1, %v65734 (stack39)
        %v65742 = vsel /*vm=*/%vm65729, /*on_true_vy=*/%v65738, /*on_false_vx=*/%v65734 (stack43)
        %v65746 = vadd.s32 1, %v65742 (stack39)
        %v65750 = vsel /*vm=*/%vm65724, /*on_true_vy=*/%v65746, /*on_false_vx=*/%v65742 (stack43)
        %v65755 = vadd.s32 %v65750, %v10 (stack39)
        %v65759 = vadd.s32 %v65720, %v9 (stack39)
        %v65763 = vadd.s32 %v65759, %v65755 (stack39)
        %v65765 = vshll.u32 %v65759, 13 (stack44)
        %v65766 = vshrl.u32 %v65759, 19 (stack45)
        %v65767 = vor.u32 %v65766, %v65765 (stack46)
        %v65768 = vxor.u32 %v65767, %v65763 (stack47)
        %v65771 = vadd.s32 %v65768, %v65763 (stack39)
        %v65773 = vshll.u32 %v65768, 15 (stack44)
        %v65774 = vshrl.u32 %v65768, 17 (stack45)
        %v65775 = vor.u32 %v65774, %v65773 (stack46)
        %v65776 = vxor.u32 %v65775, %v65771 (stack47)
        %v65779 = vadd.s32 %v65776, %v65771 (stack39)
        %v65781 = vshll.u32 %v65776, 26 (stack44)
        %v65782 = vshrl.u32 %v65776, 6 (stack45)
        %v65783 = vor.u32 %v65782, %v65781 (stack46)
        %v65784 = vxor.u32 %v65783, %v65779 (stack47)
        %v65787 = vadd.s32 %v65784, %v65779 (stack39)
        %v65791 = vadd.s32 %v65787, %v9 (stack39)
        %v65793 = vshll.u32 %v65784, 6 (stack44)
        %v65794 = vshrl.u32 %v65784, 26 (stack45)
        %v65795 = vor.u32 %v65794, %v65793 (stack46)
        %v65796 = vxor.u32 %v65795, %v65787 (stack47)
        %v65799 = vadd.s32 %v65796, %v8 (stack39)
        %v65803 = vadd.s32 1, %v65799 (stack39)
        %v65807 = vadd.s32 %v65803, %v65791 (stack39)
        %v65809 = vshll.u32 %v65803, 17 (stack44)
        %v65810 = vshrl.u32 %v65803, 15 (stack45)
        %v65811 = vor.u32 %v65810, %v65809 (stack46)
        %v65812 = vxor.u32 %v65811, %v65807 (stack47)
        %v65815 = vadd.s32 %v65812, %v65807 (stack39)
        %v65817 = vshll.u32 %v65812, 29 (stack44)
        %v65818 = vshrl.u32 %v65812, 3 (stack45)
        %v65819 = vor.u32 %v65818, %v65817 (stack46)
        %v65820 = vxor.u32 %v65819, %v65815 (stack47)
        %v65823 = vadd.s32 %v65820, %v65815 (stack39)
        %v65825 = vshll.u32 %v65820, 16 (stack44)
        %v65826 = vshrl.u32 %v65820, 16 (stack45)
        %v65827 = vor.u32 %v65826, %v65825 (stack46)
        %v65828 = vxor.u32 %v65827, %v65823 (stack47)
        %v65831 = vadd.s32 %v65828, %v65823 (stack39)
        %v65835 = vadd.s32 %v65831, %v8 (stack39)
        %v65837 = vshll.u32 %v65828, 24 (stack44)
        %v65838 = vshrl.u32 %v65828, 8 (stack45)
        %v65839 = vor.u32 %v65838, %v65837 (stack46)
        %v65840 = vxor.u32 %v65839, %v65831 (stack47)
        %v65843 = vadd.s32 %v65840, %v10 (stack39)
        %v65847 = vadd.s32 2, %v65843 (stack39)
        %v65851 = vadd.s32 %v65847, %v65835 (stack39)
        %v65853 = vshll.u32 %v65847, 13 (stack44)
        %v65854 = vshrl.u32 %v65847, 19 (stack45)
        %v65855 = vor.u32 %v65854, %v65853 (stack46)
        %v65856 = vxor.u32 %v65855, %v65851 (stack47)
        %v65859 = vadd.s32 %v65856, %v65851 (stack39)
        %v65861 = vshll.u32 %v65856, 15 (stack44)
        %v65862 = vshrl.u32 %v65856, 17 (stack45)
        %v65863 = vor.u32 %v65862, %v65861 (stack46)
        %v65864 = vxor.u32 %v65863, %v65859 (stack47)
        %v65867 = vadd.s32 %v65864, %v65859 (stack39)
        %v65869 = vshll.u32 %v65864, 26 (stack44)
        %v65870 = vshrl.u32 %v65864, 6 (stack45)
        %v65871 = vor.u32 %v65870, %v65869 (stack46)
        %v65872 = vxor.u32 %v65871, %v65867 (stack47)
        %v65875 = vadd.s32 %v65872, %v65867 (stack39)
        %v65879 = vadd.s32 %v65875, %v10 (stack39)
        %v65881 = vshll.u32 %v65872, 6 (stack44)
        %v65882 = vshrl.u32 %v65872, 26 (stack45)
        %v65883 = vor.u32 %v65882, %v65881 (stack46)
        %v65884 = vxor.u32 %v65883, %v65875 (stack47)
        %v65887 = vadd.s32 %v65884, %v9 (stack39)
        %v65891 = vadd.s32 3, %v65887 (stack39)
        %v65895 = vadd.s32 %v65891, %v65879 (stack39)
        %v65897 = vshll.u32 %v65891, 17 (stack44)
        %v65898 = vshrl.u32 %v65891, 15 (stack45)
        %v65899 = vor.u32 %v65898, %v65897 (stack46)
        %v65900 = vxor.u32 %v65899, %v65895 (stack47)
        %v65903 = vadd.s32 %v65900, %v65895 (stack39)
        %v65905 = vshll.u32 %v65900, 29 (stack44)
        %v65906 = vshrl.u32 %v65900, 3 (stack45)
        %v65907 = vor.u32 %v65906, %v65905 (stack46)
        %v65908 = vxor.u32 %v65907, %v65903 (stack47)
        %v65911 = vadd.s32 %v65908, %v65903 (stack39)
        %v65913 = vshll.u32 %v65908, 16 (stack44)
        %v65914 = vshrl.u32 %v65908, 16 (stack45)
        %v65915 = vor.u32 %v65914, %v65913 (stack46)
        %v65916 = vxor.u32 %v65915, %v65911 (stack47)
        %v65919 = vadd.s32 %v65916, %v65911 (stack39)
        %v65923 = vadd.s32 %v65919, %v9 (stack39)
        %v65925 = vshll.u32 %v65916, 24 (stack44)
        %v65926 = vshrl.u32 %v65916, 8 (stack45)
        %v65927 = vor.u32 %v65926, %v65925 (stack46)
        %v65928 = vxor.u32 %v65927, %v65919 (stack47)
        %v65931 = vadd.s32 %v65928, %v8 (stack39)
        %v65935 = vadd.s32 4, %v65931 (stack39)
        %v65939 = vadd.s32 %v65935, %v65923 (stack39)
        %v65941 = vshll.u32 %v65935, 13 (stack44)
        %v65942 = vshrl.u32 %v65935, 19 (stack45)
        %v65943 = vor.u32 %v65942, %v65941 (stack46)
        %v65944 = vxor.u32 %v65943, %v65939 (stack47)
        %v65947 = vadd.s32 %v65944, %v65939 (stack39)
        %v65949 = vshll.u32 %v65944, 15 (stack44)
        %v65950 = vshrl.u32 %v65944, 17 (stack45)
        %v65951 = vor.u32 %v65950, %v65949 (stack46)
        %v65952 = vxor.u32 %v65951, %v65947 (stack47)
        %v65955 = vadd.s32 %v65952, %v65947 (stack39)
        %v65957 = vshll.u32 %v65952, 26 (stack44)
        %v65958 = vshrl.u32 %v65952, 6 (stack45)
        %v65959 = vor.u32 %v65958, %v65957 (stack46)
        %v65960 = vxor.u32 %v65959, %v65955 (stack47)
        %v65963 = vadd.s32 %v65960, %v65955 (stack39)
        %v65967 = vadd.s32 %v65963, %v8 (stack39)
        %v65969 = vshll.u32 %v65960, 6 (stack44)
        %v65970 = vshrl.u32 %v65960, 26 (stack45)
        %v65971 = vor.u32 %v65970, %v65969 (stack46)
        %v65972 = vxor.u32 %v65971, %v65963 (stack47)
        %v65975 = vadd.s32 %v65972, %v10 (stack39)
        %v65979 = vadd.s32 5, %v65975 (stack39)
        %v65981 = vxor.u32 %v65979, %v65967 (stack47)
        %v65982 = vand.u32.u8 255, %v65981 (stack48)
        %v65983 = vand.u32 65535, %v65982 (stack49)
        %v65984 = vshrl.u32 %v65983, 1 (stack50)
        %v65985 = vor.u32 16256, %v65984 (stack46)
        %v65986 = vand.u32.u16 65535, %v65985 (stack51)
        %v120096 = vadd.low.f32.bf16 -1.0, %v65986 (stack52)
        %v65995 = vmul.f32 2.0, %v120096 (stack53)
        %v65999 = vadd.f32 -0.99609375, %v65995 (stack52)
        %v66003 = vmax.f32 %v65999, -0.99609375 (stack54)
        %v66005 = vand.u32 2147483647, %v66003 (stack55)
        %vm66008 = vcmp.eq.f32.partialorder %v66005, 1.0 (stack56)
        %v66013 = vmul.f32 inf, %v66003 (stack53)
        %v66015 = vxor.u32 2147483648, %v66003 (stack57)
        %v66018 = vmul.f32 %v66015, %v66003 (stack53)
        %v66020 = vadd.f32 1.0, %v66018 (stack58)
        %v66021 = vlog2.pop %v66020 (stack59)
        %v66022 = vmul.f32 0.6931472, %v66021 (stack60)
        %v66023 = vmul.f32 -0.5, %v66018 (stack61)
        %v66024 = vadd.f32 1.0, %v66023 (stack62)
        %v66025 = vmul.f32 %v66024, %v66018 (stack63)
        %v66026 = vand.u32 2147483647, %v66018 (stack64)
        %vm66027 = vcmp.lt.f32.partialorder %v66026, 0.0004427343 (stack65)
        %v66028 = vsel /*vm=*/%vm66027, /*on_true_vy=*/%v66025, /*on_false_vx=*/%v66022 (stack66)
        %v66029 = vxor.u32 2147483648, %v66028 (stack57)
        %vm66032 = vcmp.lt.f32.partialorder %v66029, 5.0 (stack56)
        %v66037 = vsel /*vm=*/%vm66032, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v66041 = vsel /*vm=*/%vm66032, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v66045 = vsel /*vm=*/%vm66032, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v66049 = vsel /*vm=*/%vm66032, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v66053 = vsel /*vm=*/%vm66032, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v66057 = vsel /*vm=*/%vm66032, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v66061 = vsel /*vm=*/%vm66032, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v66065 = vsel /*vm=*/%vm66032, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v66069 = vsel /*vm=*/%vm66032, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v66073 = vadd.f32 -2.5, %v66029 (stack52)
        %v66075 = vrsqrt.pop %v66029 (stack67)
        %v66076 = vmul.f32 %v66075, %v66029 (stack68)
        %vm66077 = vcmp.eq.f32.partialorder %v66029, inf (stack69)
        %v66078 = vsel /*vm=*/%vm66077, /*on_true_vy=*/%v66029, /*on_false_vx=*/%v66076 (stack70)
        %vm66079 = vcmp.eq.f32.partialorder %v66029, 0.0 (stack71)
        %v66080 = vand.u32 2147483648, %v66029 (stack72)
        %v66081 = vsel /*vm=*/%vm66079, /*on_true_vy=*/%v66080, /*on_false_vx=*/%v66078 (stack73)
        %v66084 = vadd.f32 -3.0, %v66081 (stack52)
        %v66088 = vsel /*vm=*/%vm66032, /*on_true_vy=*/%v66073, /*on_false_vx=*/%v66084 (stack43)
        %v66092 = vmul.f32 %v66088, %v66069 (stack53)
        %v66096 = vadd.f32 %v66092, %v66065 (stack52)
        %v66100 = vmul.f32 %v66096, %v66088 (stack53)
        %v66104 = vadd.f32 %v66100, %v66061 (stack52)
        %v66108 = vmul.f32 %v66104, %v66088 (stack53)
        %v66112 = vadd.f32 %v66108, %v66057 (stack52)
        %v66116 = vmul.f32 %v66112, %v66088 (stack53)
        %v66120 = vadd.f32 %v66116, %v66053 (stack52)
        %v66124 = vmul.f32 %v66120, %v66088 (stack53)
        %v66128 = vadd.f32 %v66124, %v66049 (stack52)
        %v66132 = vmul.f32 %v66128, %v66088 (stack53)
        %v66136 = vadd.f32 %v66132, %v66045 (stack52)
        %v66140 = vmul.f32 %v66136, %v66088 (stack53)
        %v66144 = vadd.f32 %v66140, %v66041 (stack52)
        %v66148 = vmul.f32 %v66144, %v66088 (stack53)
        %v66152 = vadd.f32 %v66148, %v66037 (stack52)
        %v66156 = vmul.f32 %v66152, %v66003 (stack53)
        %v66160 = vsel /*vm=*/%vm66008, /*on_true_vy=*/%v66013, /*on_false_vx=*/%v66156 (stack43)
        %v66164 = vmul.f32 1.4140625, %v66160 (stack53)
        %v66167 = vpack.c.bf16 0.0, %v66164 (stack74)
        %120097 = vst [vmem:[%s280 + $0x244] sm:$0xf] /*vst_source=*/%v66167 (stack75)
        %v66171 = vadd.s32 %v63863, %v2842 (stack39)
        %v66181 = vadd.s32 %v66171, %v415 (stack39)
        %vm66185 = vcmp.lt.u32.totalorder %v66181, %v66171 (stack42)
        %vm66190 = vcmp.lt.u32.totalorder %v66171, %v2842 (stack42)
        %v66195 = vadd.s32 %v63846, %v2829 (stack39)
        %v66199 = vadd.s32 1, %v66195 (stack39)
        %v66203 = vsel /*vm=*/%vm66190, /*on_true_vy=*/%v66199, /*on_false_vx=*/%v66195 (stack43)
        %v66207 = vadd.s32 1, %v66203 (stack39)
        %v66211 = vsel /*vm=*/%vm66185, /*on_true_vy=*/%v66207, /*on_false_vx=*/%v66203 (stack43)
        %v66216 = vadd.s32 %v66211, %v10 (stack39)
        %v66220 = vadd.s32 %v66181, %v9 (stack39)
        %v66224 = vadd.s32 %v66220, %v66216 (stack39)
        %v66226 = vshll.u32 %v66220, 13 (stack44)
        %v66227 = vshrl.u32 %v66220, 19 (stack45)
        %v66228 = vor.u32 %v66227, %v66226 (stack46)
        %v66229 = vxor.u32 %v66228, %v66224 (stack47)
        %v66232 = vadd.s32 %v66229, %v66224 (stack39)
        %v66234 = vshll.u32 %v66229, 15 (stack44)
        %v66235 = vshrl.u32 %v66229, 17 (stack45)
        %v66236 = vor.u32 %v66235, %v66234 (stack46)
        %v66237 = vxor.u32 %v66236, %v66232 (stack47)
        %v66240 = vadd.s32 %v66237, %v66232 (stack39)
        %v66242 = vshll.u32 %v66237, 26 (stack44)
        %v66243 = vshrl.u32 %v66237, 6 (stack45)
        %v66244 = vor.u32 %v66243, %v66242 (stack46)
        %v66245 = vxor.u32 %v66244, %v66240 (stack47)
        %v66248 = vadd.s32 %v66245, %v66240 (stack39)
        %v66252 = vadd.s32 %v66248, %v9 (stack39)
        %v66254 = vshll.u32 %v66245, 6 (stack44)
        %v66255 = vshrl.u32 %v66245, 26 (stack45)
        %v66256 = vor.u32 %v66255, %v66254 (stack46)
        %v66257 = vxor.u32 %v66256, %v66248 (stack47)
        %v66260 = vadd.s32 %v66257, %v8 (stack39)
        %v66264 = vadd.s32 1, %v66260 (stack39)
        %v66268 = vadd.s32 %v66264, %v66252 (stack39)
        %v66270 = vshll.u32 %v66264, 17 (stack44)
        %v66271 = vshrl.u32 %v66264, 15 (stack45)
        %v66272 = vor.u32 %v66271, %v66270 (stack46)
        %v66273 = vxor.u32 %v66272, %v66268 (stack47)
        %v66276 = vadd.s32 %v66273, %v66268 (stack39)
        %v66278 = vshll.u32 %v66273, 29 (stack44)
        %v66279 = vshrl.u32 %v66273, 3 (stack45)
        %v66280 = vor.u32 %v66279, %v66278 (stack46)
        %v66281 = vxor.u32 %v66280, %v66276 (stack47)
        %v66284 = vadd.s32 %v66281, %v66276 (stack39)
        %v66286 = vshll.u32 %v66281, 16 (stack44)
        %v66287 = vshrl.u32 %v66281, 16 (stack45)
        %v66288 = vor.u32 %v66287, %v66286 (stack46)
        %v66289 = vxor.u32 %v66288, %v66284 (stack47)
        %v66292 = vadd.s32 %v66289, %v66284 (stack39)
        %v66296 = vadd.s32 %v66292, %v8 (stack39)
        %v66298 = vshll.u32 %v66289, 24 (stack44)
        %v66299 = vshrl.u32 %v66289, 8 (stack45)
        %v66300 = vor.u32 %v66299, %v66298 (stack46)
        %v66301 = vxor.u32 %v66300, %v66292 (stack47)
        %v66304 = vadd.s32 %v66301, %v10 (stack39)
        %v66308 = vadd.s32 2, %v66304 (stack39)
        %v66312 = vadd.s32 %v66308, %v66296 (stack39)
        %v66314 = vshll.u32 %v66308, 13 (stack44)
        %v66315 = vshrl.u32 %v66308, 19 (stack45)
        %v66316 = vor.u32 %v66315, %v66314 (stack46)
        %v66317 = vxor.u32 %v66316, %v66312 (stack47)
        %v66320 = vadd.s32 %v66317, %v66312 (stack39)
        %v66322 = vshll.u32 %v66317, 15 (stack44)
        %v66323 = vshrl.u32 %v66317, 17 (stack45)
        %v66324 = vor.u32 %v66323, %v66322 (stack46)
        %v66325 = vxor.u32 %v66324, %v66320 (stack47)
        %v66328 = vadd.s32 %v66325, %v66320 (stack39)
        %v66330 = vshll.u32 %v66325, 26 (stack44)
        %v66331 = vshrl.u32 %v66325, 6 (stack45)
        %v66332 = vor.u32 %v66331, %v66330 (stack46)
        %v66333 = vxor.u32 %v66332, %v66328 (stack47)
        %v66336 = vadd.s32 %v66333, %v66328 (stack39)
        %v66340 = vadd.s32 %v66336, %v10 (stack39)
        %v66342 = vshll.u32 %v66333, 6 (stack44)
        %v66343 = vshrl.u32 %v66333, 26 (stack45)
        %v66344 = vor.u32 %v66343, %v66342 (stack46)
        %v66345 = vxor.u32 %v66344, %v66336 (stack47)
        %v66348 = vadd.s32 %v66345, %v9 (stack39)
        %v66352 = vadd.s32 3, %v66348 (stack39)
        %v66356 = vadd.s32 %v66352, %v66340 (stack39)
        %v66358 = vshll.u32 %v66352, 17 (stack44)
        %v66359 = vshrl.u32 %v66352, 15 (stack45)
        %v66360 = vor.u32 %v66359, %v66358 (stack46)
        %v66361 = vxor.u32 %v66360, %v66356 (stack47)
        %v66364 = vadd.s32 %v66361, %v66356 (stack39)
        %v66366 = vshll.u32 %v66361, 29 (stack44)
        %v66367 = vshrl.u32 %v66361, 3 (stack45)
        %v66368 = vor.u32 %v66367, %v66366 (stack46)
        %v66369 = vxor.u32 %v66368, %v66364 (stack47)
        %v66372 = vadd.s32 %v66369, %v66364 (stack39)
        %v66374 = vshll.u32 %v66369, 16 (stack44)
        %v66375 = vshrl.u32 %v66369, 16 (stack45)
        %v66376 = vor.u32 %v66375, %v66374 (stack46)
        %v66377 = vxor.u32 %v66376, %v66372 (stack47)
        %v66380 = vadd.s32 %v66377, %v66372 (stack39)
        %v66384 = vadd.s32 %v66380, %v9 (stack39)
        %v66386 = vshll.u32 %v66377, 24 (stack44)
        %v66387 = vshrl.u32 %v66377, 8 (stack45)
        %v66388 = vor.u32 %v66387, %v66386 (stack46)
        %v66389 = vxor.u32 %v66388, %v66380 (stack47)
        %v66392 = vadd.s32 %v66389, %v8 (stack39)
        %v66396 = vadd.s32 4, %v66392 (stack39)
        %v66400 = vadd.s32 %v66396, %v66384 (stack39)
        %v66402 = vshll.u32 %v66396, 13 (stack44)
        %v66403 = vshrl.u32 %v66396, 19 (stack45)
        %v66404 = vor.u32 %v66403, %v66402 (stack46)
        %v66405 = vxor.u32 %v66404, %v66400 (stack47)
        %v66408 = vadd.s32 %v66405, %v66400 (stack39)
        %v66410 = vshll.u32 %v66405, 15 (stack44)
        %v66411 = vshrl.u32 %v66405, 17 (stack45)
        %v66412 = vor.u32 %v66411, %v66410 (stack46)
        %v66413 = vxor.u32 %v66412, %v66408 (stack47)
        %v66416 = vadd.s32 %v66413, %v66408 (stack39)
        %v66418 = vshll.u32 %v66413, 26 (stack44)
        %v66419 = vshrl.u32 %v66413, 6 (stack45)
        %v66420 = vor.u32 %v66419, %v66418 (stack46)
        %v66421 = vxor.u32 %v66420, %v66416 (stack47)
        %v66424 = vadd.s32 %v66421, %v66416 (stack39)
        %v66428 = vadd.s32 %v66424, %v8 (stack39)
        %v66430 = vshll.u32 %v66421, 6 (stack44)
        %v66431 = vshrl.u32 %v66421, 26 (stack45)
        %v66432 = vor.u32 %v66431, %v66430 (stack46)
        %v66433 = vxor.u32 %v66432, %v66424 (stack47)
        %v66436 = vadd.s32 %v66433, %v10 (stack39)
        %v66440 = vadd.s32 5, %v66436 (stack39)
        %v66442 = vxor.u32 %v66440, %v66428 (stack47)
        %v66443 = vand.u32.u8 255, %v66442 (stack48)
        %v66444 = vand.u32 65535, %v66443 (stack49)
        %v66445 = vshrl.u32 %v66444, 1 (stack50)
        %v66446 = vor.u32 16256, %v66445 (stack46)
        %v66447 = vand.u32.u16 65535, %v66446 (stack51)
        %v120098 = vadd.low.f32.bf16 -1.0, %v66447 (stack52)
        %v66456 = vmul.f32 2.0, %v120098 (stack53)
        %v66460 = vadd.f32 -0.99609375, %v66456 (stack52)
        %v66464 = vmax.f32 %v66460, -0.99609375 (stack54)
        %v66466 = vand.u32 2147483647, %v66464 (stack55)
        %vm66469 = vcmp.eq.f32.partialorder %v66466, 1.0 (stack56)
        %v66474 = vmul.f32 inf, %v66464 (stack53)
        %v66476 = vxor.u32 2147483648, %v66464 (stack57)
        %v66479 = vmul.f32 %v66476, %v66464 (stack53)
        %v66481 = vadd.f32 1.0, %v66479 (stack58)
        %v66482 = vlog2.pop %v66481 (stack59)
        %v66483 = vmul.f32 0.6931472, %v66482 (stack60)
        %v66484 = vmul.f32 -0.5, %v66479 (stack61)
        %v66485 = vadd.f32 1.0, %v66484 (stack62)
        %v66486 = vmul.f32 %v66485, %v66479 (stack63)
        %v66487 = vand.u32 2147483647, %v66479 (stack64)
        %vm66488 = vcmp.lt.f32.partialorder %v66487, 0.0004427343 (stack65)
        %v66489 = vsel /*vm=*/%vm66488, /*on_true_vy=*/%v66486, /*on_false_vx=*/%v66483 (stack66)
        %v66490 = vxor.u32 2147483648, %v66489 (stack57)
        %vm66493 = vcmp.lt.f32.partialorder %v66490, 5.0 (stack56)
        %v66498 = vsel /*vm=*/%vm66493, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v66502 = vsel /*vm=*/%vm66493, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v66506 = vsel /*vm=*/%vm66493, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v66510 = vsel /*vm=*/%vm66493, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v66514 = vsel /*vm=*/%vm66493, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v66518 = vsel /*vm=*/%vm66493, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v66522 = vsel /*vm=*/%vm66493, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v66526 = vsel /*vm=*/%vm66493, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v66530 = vsel /*vm=*/%vm66493, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v66534 = vadd.f32 -2.5, %v66490 (stack52)
        %v66536 = vrsqrt.pop %v66490 (stack67)
        %v66537 = vmul.f32 %v66536, %v66490 (stack68)
        %vm66538 = vcmp.eq.f32.partialorder %v66490, inf (stack69)
        %v66539 = vsel /*vm=*/%vm66538, /*on_true_vy=*/%v66490, /*on_false_vx=*/%v66537 (stack70)
        %vm66540 = vcmp.eq.f32.partialorder %v66490, 0.0 (stack71)
        %v66541 = vand.u32 2147483648, %v66490 (stack72)
        %v66542 = vsel /*vm=*/%vm66540, /*on_true_vy=*/%v66541, /*on_false_vx=*/%v66539 (stack73)
        %v66545 = vadd.f32 -3.0, %v66542 (stack52)
        %v66549 = vsel /*vm=*/%vm66493, /*on_true_vy=*/%v66534, /*on_false_vx=*/%v66545 (stack43)
        %v66553 = vmul.f32 %v66549, %v66530 (stack53)
        %v66557 = vadd.f32 %v66553, %v66526 (stack52)
        %v66561 = vmul.f32 %v66557, %v66549 (stack53)
        %v66565 = vadd.f32 %v66561, %v66522 (stack52)
        %v66569 = vmul.f32 %v66565, %v66549 (stack53)
        %v66573 = vadd.f32 %v66569, %v66518 (stack52)
        %v66577 = vmul.f32 %v66573, %v66549 (stack53)
        %v66581 = vadd.f32 %v66577, %v66514 (stack52)
        %v66585 = vmul.f32 %v66581, %v66549 (stack53)
        %v66589 = vadd.f32 %v66585, %v66510 (stack52)
        %v66593 = vmul.f32 %v66589, %v66549 (stack53)
        %v66597 = vadd.f32 %v66593, %v66506 (stack52)
        %v66601 = vmul.f32 %v66597, %v66549 (stack53)
        %v66605 = vadd.f32 %v66601, %v66502 (stack52)
        %v66609 = vmul.f32 %v66605, %v66549 (stack53)
        %v66613 = vadd.f32 %v66609, %v66498 (stack52)
        %v66617 = vmul.f32 %v66613, %v66464 (stack53)
        %v66621 = vsel /*vm=*/%vm66469, /*on_true_vy=*/%v66474, /*on_false_vx=*/%v66617 (stack43)
        %v66625 = vmul.f32 1.4140625, %v66621 (stack53)
        %v66628 = vpack.c.bf16 0.0, %v66625 (stack74)
        %120099 = vst [vmem:[%s280 + $0x2c4] sm:$0xf] /*vst_source=*/%v66628 (stack75)
        %v66632 = vadd.s32 %v63863, %v3329 (stack39)
        %v66642 = vadd.s32 %v66632, %v415 (stack39)
        %vm66646 = vcmp.lt.u32.totalorder %v66642, %v66632 (stack42)
        %vm66651 = vcmp.lt.u32.totalorder %v66632, %v3329 (stack42)
        %v66656 = vadd.s32 %v63846, %v3316 (stack39)
        %v66660 = vadd.s32 1, %v66656 (stack39)
        %v66664 = vsel /*vm=*/%vm66651, /*on_true_vy=*/%v66660, /*on_false_vx=*/%v66656 (stack43)
        %v66668 = vadd.s32 1, %v66664 (stack39)
        %v66672 = vsel /*vm=*/%vm66646, /*on_true_vy=*/%v66668, /*on_false_vx=*/%v66664 (stack43)
        %v66677 = vadd.s32 %v66672, %v10 (stack39)
        %v66681 = vadd.s32 %v66642, %v9 (stack39)
        %v66685 = vadd.s32 %v66681, %v66677 (stack39)
        %v66687 = vshll.u32 %v66681, 13 (stack44)
        %v66688 = vshrl.u32 %v66681, 19 (stack45)
        %v66689 = vor.u32 %v66688, %v66687 (stack46)
        %v66690 = vxor.u32 %v66689, %v66685 (stack47)
        %v66693 = vadd.s32 %v66690, %v66685 (stack39)
        %v66695 = vshll.u32 %v66690, 15 (stack44)
        %v66696 = vshrl.u32 %v66690, 17 (stack45)
        %v66697 = vor.u32 %v66696, %v66695 (stack46)
        %v66698 = vxor.u32 %v66697, %v66693 (stack47)
        %v66701 = vadd.s32 %v66698, %v66693 (stack39)
        %v66703 = vshll.u32 %v66698, 26 (stack44)
        %v66704 = vshrl.u32 %v66698, 6 (stack45)
        %v66705 = vor.u32 %v66704, %v66703 (stack46)
        %v66706 = vxor.u32 %v66705, %v66701 (stack47)
        %v66709 = vadd.s32 %v66706, %v66701 (stack39)
        %v66713 = vadd.s32 %v66709, %v9 (stack39)
        %v66715 = vshll.u32 %v66706, 6 (stack44)
        %v66716 = vshrl.u32 %v66706, 26 (stack45)
        %v66717 = vor.u32 %v66716, %v66715 (stack46)
        %v66718 = vxor.u32 %v66717, %v66709 (stack47)
        %v66721 = vadd.s32 %v66718, %v8 (stack39)
        %v66725 = vadd.s32 1, %v66721 (stack39)
        %v66729 = vadd.s32 %v66725, %v66713 (stack39)
        %v66731 = vshll.u32 %v66725, 17 (stack44)
        %v66732 = vshrl.u32 %v66725, 15 (stack45)
        %v66733 = vor.u32 %v66732, %v66731 (stack46)
        %v66734 = vxor.u32 %v66733, %v66729 (stack47)
        %v66737 = vadd.s32 %v66734, %v66729 (stack39)
        %v66739 = vshll.u32 %v66734, 29 (stack44)
        %v66740 = vshrl.u32 %v66734, 3 (stack45)
        %v66741 = vor.u32 %v66740, %v66739 (stack46)
        %v66742 = vxor.u32 %v66741, %v66737 (stack47)
        %v66745 = vadd.s32 %v66742, %v66737 (stack39)
        %v66747 = vshll.u32 %v66742, 16 (stack44)
        %v66748 = vshrl.u32 %v66742, 16 (stack45)
        %v66749 = vor.u32 %v66748, %v66747 (stack46)
        %v66750 = vxor.u32 %v66749, %v66745 (stack47)
        %v66753 = vadd.s32 %v66750, %v66745 (stack39)
        %v66757 = vadd.s32 %v66753, %v8 (stack39)
        %v66759 = vshll.u32 %v66750, 24 (stack44)
        %v66760 = vshrl.u32 %v66750, 8 (stack45)
        %v66761 = vor.u32 %v66760, %v66759 (stack46)
        %v66762 = vxor.u32 %v66761, %v66753 (stack47)
        %v66765 = vadd.s32 %v66762, %v10 (stack39)
        %v66769 = vadd.s32 2, %v66765 (stack39)
        %v66773 = vadd.s32 %v66769, %v66757 (stack39)
        %v66775 = vshll.u32 %v66769, 13 (stack44)
        %v66776 = vshrl.u32 %v66769, 19 (stack45)
        %v66777 = vor.u32 %v66776, %v66775 (stack46)
        %v66778 = vxor.u32 %v66777, %v66773 (stack47)
        %v66781 = vadd.s32 %v66778, %v66773 (stack39)
        %v66783 = vshll.u32 %v66778, 15 (stack44)
        %v66784 = vshrl.u32 %v66778, 17 (stack45)
        %v66785 = vor.u32 %v66784, %v66783 (stack46)
        %v66786 = vxor.u32 %v66785, %v66781 (stack47)
        %v66789 = vadd.s32 %v66786, %v66781 (stack39)
        %v66791 = vshll.u32 %v66786, 26 (stack44)
        %v66792 = vshrl.u32 %v66786, 6 (stack45)
        %v66793 = vor.u32 %v66792, %v66791 (stack46)
        %v66794 = vxor.u32 %v66793, %v66789 (stack47)
        %v66797 = vadd.s32 %v66794, %v66789 (stack39)
        %v66801 = vadd.s32 %v66797, %v10 (stack39)
        %v66803 = vshll.u32 %v66794, 6 (stack44)
        %v66804 = vshrl.u32 %v66794, 26 (stack45)
        %v66805 = vor.u32 %v66804, %v66803 (stack46)
        %v66806 = vxor.u32 %v66805, %v66797 (stack47)
        %v66809 = vadd.s32 %v66806, %v9 (stack39)
        %v66813 = vadd.s32 3, %v66809 (stack39)
        %v66817 = vadd.s32 %v66813, %v66801 (stack39)
        %v66819 = vshll.u32 %v66813, 17 (stack44)
        %v66820 = vshrl.u32 %v66813, 15 (stack45)
        %v66821 = vor.u32 %v66820, %v66819 (stack46)
        %v66822 = vxor.u32 %v66821, %v66817 (stack47)
        %v66825 = vadd.s32 %v66822, %v66817 (stack39)
        %v66827 = vshll.u32 %v66822, 29 (stack44)
        %v66828 = vshrl.u32 %v66822, 3 (stack45)
        %v66829 = vor.u32 %v66828, %v66827 (stack46)
        %v66830 = vxor.u32 %v66829, %v66825 (stack47)
        %v66833 = vadd.s32 %v66830, %v66825 (stack39)
        %v66835 = vshll.u32 %v66830, 16 (stack44)
        %v66836 = vshrl.u32 %v66830, 16 (stack45)
        %v66837 = vor.u32 %v66836, %v66835 (stack46)
        %v66838 = vxor.u32 %v66837, %v66833 (stack47)
        %v66841 = vadd.s32 %v66838, %v66833 (stack39)
        %v66845 = vadd.s32 %v66841, %v9 (stack39)
        %v66847 = vshll.u32 %v66838, 24 (stack44)
        %v66848 = vshrl.u32 %v66838, 8 (stack45)
        %v66849 = vor.u32 %v66848, %v66847 (stack46)
        %v66850 = vxor.u32 %v66849, %v66841 (stack47)
        %v66853 = vadd.s32 %v66850, %v8 (stack39)
        %v66857 = vadd.s32 4, %v66853 (stack39)
        %v66861 = vadd.s32 %v66857, %v66845 (stack39)
        %v66863 = vshll.u32 %v66857, 13 (stack44)
        %v66864 = vshrl.u32 %v66857, 19 (stack45)
        %v66865 = vor.u32 %v66864, %v66863 (stack46)
        %v66866 = vxor.u32 %v66865, %v66861 (stack47)
        %v66869 = vadd.s32 %v66866, %v66861 (stack39)
        %v66871 = vshll.u32 %v66866, 15 (stack44)
        %v66872 = vshrl.u32 %v66866, 17 (stack45)
        %v66873 = vor.u32 %v66872, %v66871 (stack46)
        %v66874 = vxor.u32 %v66873, %v66869 (stack47)
        %v66877 = vadd.s32 %v66874, %v66869 (stack39)
        %v66879 = vshll.u32 %v66874, 26 (stack44)
        %v66880 = vshrl.u32 %v66874, 6 (stack45)
        %v66881 = vor.u32 %v66880, %v66879 (stack46)
        %v66882 = vxor.u32 %v66881, %v66877 (stack47)
        %v66885 = vadd.s32 %v66882, %v66877 (stack39)
        %v66889 = vadd.s32 %v66885, %v8 (stack39)
        %v66891 = vshll.u32 %v66882, 6 (stack44)
        %v66892 = vshrl.u32 %v66882, 26 (stack45)
        %v66893 = vor.u32 %v66892, %v66891 (stack46)
        %v66894 = vxor.u32 %v66893, %v66885 (stack47)
        %v66897 = vadd.s32 %v66894, %v10 (stack39)
        %v66901 = vadd.s32 5, %v66897 (stack39)
        %v66903 = vxor.u32 %v66901, %v66889 (stack47)
        %v66904 = vand.u32.u8 255, %v66903 (stack48)
        %v66905 = vand.u32 65535, %v66904 (stack49)
        %v66906 = vshrl.u32 %v66905, 1 (stack50)
        %v66907 = vor.u32 16256, %v66906 (stack46)
        %v66908 = vand.u32.u16 65535, %v66907 (stack51)
        %v120100 = vadd.low.f32.bf16 -1.0, %v66908 (stack52)
        %v66917 = vmul.f32 2.0, %v120100 (stack53)
        %v66921 = vadd.f32 -0.99609375, %v66917 (stack52)
        %v66925 = vmax.f32 %v66921, -0.99609375 (stack54)
        %v66927 = vand.u32 2147483647, %v66925 (stack55)
        %vm66930 = vcmp.eq.f32.partialorder %v66927, 1.0 (stack56)
        %v66935 = vmul.f32 inf, %v66925 (stack53)
        %v66937 = vxor.u32 2147483648, %v66925 (stack57)
        %v66940 = vmul.f32 %v66937, %v66925 (stack53)
        %v66942 = vadd.f32 1.0, %v66940 (stack58)
        %v66943 = vlog2.pop %v66942 (stack59)
        %v66944 = vmul.f32 0.6931472, %v66943 (stack60)
        %v66945 = vmul.f32 -0.5, %v66940 (stack61)
        %v66946 = vadd.f32 1.0, %v66945 (stack62)
        %v66947 = vmul.f32 %v66946, %v66940 (stack63)
        %v66948 = vand.u32 2147483647, %v66940 (stack64)
        %vm66949 = vcmp.lt.f32.partialorder %v66948, 0.0004427343 (stack65)
        %v66950 = vsel /*vm=*/%vm66949, /*on_true_vy=*/%v66947, /*on_false_vx=*/%v66944 (stack66)
        %v66951 = vxor.u32 2147483648, %v66950 (stack57)
        %vm66954 = vcmp.lt.f32.partialorder %v66951, 5.0 (stack56)
        %v66959 = vsel /*vm=*/%vm66954, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v66963 = vsel /*vm=*/%vm66954, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v66967 = vsel /*vm=*/%vm66954, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v66971 = vsel /*vm=*/%vm66954, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v66975 = vsel /*vm=*/%vm66954, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v66979 = vsel /*vm=*/%vm66954, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v66983 = vsel /*vm=*/%vm66954, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v66987 = vsel /*vm=*/%vm66954, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v66991 = vsel /*vm=*/%vm66954, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v66995 = vadd.f32 -2.5, %v66951 (stack52)
        %v66997 = vrsqrt.pop %v66951 (stack67)
        %v66998 = vmul.f32 %v66997, %v66951 (stack68)
        %vm66999 = vcmp.eq.f32.partialorder %v66951, inf (stack69)
        %v67000 = vsel /*vm=*/%vm66999, /*on_true_vy=*/%v66951, /*on_false_vx=*/%v66998 (stack70)
        %vm67001 = vcmp.eq.f32.partialorder %v66951, 0.0 (stack71)
        %v67002 = vand.u32 2147483648, %v66951 (stack72)
        %v67003 = vsel /*vm=*/%vm67001, /*on_true_vy=*/%v67002, /*on_false_vx=*/%v67000 (stack73)
        %v67006 = vadd.f32 -3.0, %v67003 (stack52)
        %v67010 = vsel /*vm=*/%vm66954, /*on_true_vy=*/%v66995, /*on_false_vx=*/%v67006 (stack43)
        %v67014 = vmul.f32 %v67010, %v66991 (stack53)
        %v67018 = vadd.f32 %v67014, %v66987 (stack52)
        %v67022 = vmul.f32 %v67018, %v67010 (stack53)
        %v67026 = vadd.f32 %v67022, %v66983 (stack52)
        %v67030 = vmul.f32 %v67026, %v67010 (stack53)
        %v67034 = vadd.f32 %v67030, %v66979 (stack52)
        %v67038 = vmul.f32 %v67034, %v67010 (stack53)
        %v67042 = vadd.f32 %v67038, %v66975 (stack52)
        %v67046 = vmul.f32 %v67042, %v67010 (stack53)
        %v67050 = vadd.f32 %v67046, %v66971 (stack52)
        %v67054 = vmul.f32 %v67050, %v67010 (stack53)
        %v67058 = vadd.f32 %v67054, %v66967 (stack52)
        %v67062 = vmul.f32 %v67058, %v67010 (stack53)
        %v67066 = vadd.f32 %v67062, %v66963 (stack52)
        %v67070 = vmul.f32 %v67066, %v67010 (stack53)
        %v67074 = vadd.f32 %v67070, %v66959 (stack52)
        %v67078 = vmul.f32 %v67074, %v66925 (stack53)
        %v67082 = vsel /*vm=*/%vm66930, /*on_true_vy=*/%v66935, /*on_false_vx=*/%v67078 (stack43)
        %v67086 = vmul.f32 1.4140625, %v67082 (stack53)
        %v67089 = vpack.c.bf16 0.0, %v67086 (stack74)
        %120101 = vst [vmem:[%s280 + $0x344] sm:$0xf] /*vst_source=*/%v67089 (stack75)
        %v67093 = vadd.s32 %v63863, %v3816 (stack39)
        %v67103 = vadd.s32 %v67093, %v415 (stack39)
        %vm67107 = vcmp.lt.u32.totalorder %v67103, %v67093 (stack42)
        %vm67112 = vcmp.lt.u32.totalorder %v67093, %v3816 (stack42)
        %v67117 = vadd.s32 %v63846, %v3803 (stack39)
        %v67121 = vadd.s32 1, %v67117 (stack39)
        %v67125 = vsel /*vm=*/%vm67112, /*on_true_vy=*/%v67121, /*on_false_vx=*/%v67117 (stack43)
        %v67129 = vadd.s32 1, %v67125 (stack39)
        %v67133 = vsel /*vm=*/%vm67107, /*on_true_vy=*/%v67129, /*on_false_vx=*/%v67125 (stack43)
        %v67138 = vadd.s32 %v67133, %v10 (stack39)
        %v67142 = vadd.s32 %v67103, %v9 (stack39)
        %v67146 = vadd.s32 %v67142, %v67138 (stack39)
        %v67148 = vshll.u32 %v67142, 13 (stack44)
        %v67149 = vshrl.u32 %v67142, 19 (stack45)
        %v67150 = vor.u32 %v67149, %v67148 (stack46)
        %v67151 = vxor.u32 %v67150, %v67146 (stack47)
        %v67154 = vadd.s32 %v67151, %v67146 (stack39)
        %v67156 = vshll.u32 %v67151, 15 (stack44)
        %v67157 = vshrl.u32 %v67151, 17 (stack45)
        %v67158 = vor.u32 %v67157, %v67156 (stack46)
        %v67159 = vxor.u32 %v67158, %v67154 (stack47)
        %v67162 = vadd.s32 %v67159, %v67154 (stack39)
        %v67164 = vshll.u32 %v67159, 26 (stack44)
        %v67165 = vshrl.u32 %v67159, 6 (stack45)
        %v67166 = vor.u32 %v67165, %v67164 (stack46)
        %v67167 = vxor.u32 %v67166, %v67162 (stack47)
        %v67170 = vadd.s32 %v67167, %v67162 (stack39)
        %v67174 = vadd.s32 %v67170, %v9 (stack39)
        %v67176 = vshll.u32 %v67167, 6 (stack44)
        %v67177 = vshrl.u32 %v67167, 26 (stack45)
        %v67178 = vor.u32 %v67177, %v67176 (stack46)
        %v67179 = vxor.u32 %v67178, %v67170 (stack47)
        %v67182 = vadd.s32 %v67179, %v8 (stack39)
        %v67186 = vadd.s32 1, %v67182 (stack39)
        %v67190 = vadd.s32 %v67186, %v67174 (stack39)
        %v67192 = vshll.u32 %v67186, 17 (stack44)
        %v67193 = vshrl.u32 %v67186, 15 (stack45)
        %v67194 = vor.u32 %v67193, %v67192 (stack46)
        %v67195 = vxor.u32 %v67194, %v67190 (stack47)
        %v67198 = vadd.s32 %v67195, %v67190 (stack39)
        %v67200 = vshll.u32 %v67195, 29 (stack44)
        %v67201 = vshrl.u32 %v67195, 3 (stack45)
        %v67202 = vor.u32 %v67201, %v67200 (stack46)
        %v67203 = vxor.u32 %v67202, %v67198 (stack47)
        %v67206 = vadd.s32 %v67203, %v67198 (stack39)
        %v67208 = vshll.u32 %v67203, 16 (stack44)
        %v67209 = vshrl.u32 %v67203, 16 (stack45)
        %v67210 = vor.u32 %v67209, %v67208 (stack46)
        %v67211 = vxor.u32 %v67210, %v67206 (stack47)
        %v67214 = vadd.s32 %v67211, %v67206 (stack39)
        %v67218 = vadd.s32 %v67214, %v8 (stack39)
        %v67220 = vshll.u32 %v67211, 24 (stack44)
        %v67221 = vshrl.u32 %v67211, 8 (stack45)
        %v67222 = vor.u32 %v67221, %v67220 (stack46)
        %v67223 = vxor.u32 %v67222, %v67214 (stack47)
        %v67226 = vadd.s32 %v67223, %v10 (stack39)
        %v67230 = vadd.s32 2, %v67226 (stack39)
        %v67234 = vadd.s32 %v67230, %v67218 (stack39)
        %v67236 = vshll.u32 %v67230, 13 (stack44)
        %v67237 = vshrl.u32 %v67230, 19 (stack45)
        %v67238 = vor.u32 %v67237, %v67236 (stack46)
        %v67239 = vxor.u32 %v67238, %v67234 (stack47)
        %v67242 = vadd.s32 %v67239, %v67234 (stack39)
        %v67244 = vshll.u32 %v67239, 15 (stack44)
        %v67245 = vshrl.u32 %v67239, 17 (stack45)
        %v67246 = vor.u32 %v67245, %v67244 (stack46)
        %v67247 = vxor.u32 %v67246, %v67242 (stack47)
        %v67250 = vadd.s32 %v67247, %v67242 (stack39)
        %v67252 = vshll.u32 %v67247, 26 (stack44)
        %v67253 = vshrl.u32 %v67247, 6 (stack45)
        %v67254 = vor.u32 %v67253, %v67252 (stack46)
        %v67255 = vxor.u32 %v67254, %v67250 (stack47)
        %v67258 = vadd.s32 %v67255, %v67250 (stack39)
        %v67262 = vadd.s32 %v67258, %v10 (stack39)
        %v67264 = vshll.u32 %v67255, 6 (stack44)
        %v67265 = vshrl.u32 %v67255, 26 (stack45)
        %v67266 = vor.u32 %v67265, %v67264 (stack46)
        %v67267 = vxor.u32 %v67266, %v67258 (stack47)
        %v67270 = vadd.s32 %v67267, %v9 (stack39)
        %v67274 = vadd.s32 3, %v67270 (stack39)
        %v67278 = vadd.s32 %v67274, %v67262 (stack39)
        %v67280 = vshll.u32 %v67274, 17 (stack44)
        %v67281 = vshrl.u32 %v67274, 15 (stack45)
        %v67282 = vor.u32 %v67281, %v67280 (stack46)
        %v67283 = vxor.u32 %v67282, %v67278 (stack47)
        %v67286 = vadd.s32 %v67283, %v67278 (stack39)
        %v67288 = vshll.u32 %v67283, 29 (stack44)
        %v67289 = vshrl.u32 %v67283, 3 (stack45)
        %v67290 = vor.u32 %v67289, %v67288 (stack46)
        %v67291 = vxor.u32 %v67290, %v67286 (stack47)
        %v67294 = vadd.s32 %v67291, %v67286 (stack39)
        %v67296 = vshll.u32 %v67291, 16 (stack44)
        %v67297 = vshrl.u32 %v67291, 16 (stack45)
        %v67298 = vor.u32 %v67297, %v67296 (stack46)
        %v67299 = vxor.u32 %v67298, %v67294 (stack47)
        %v67302 = vadd.s32 %v67299, %v67294 (stack39)
        %v67306 = vadd.s32 %v67302, %v9 (stack39)
        %v67308 = vshll.u32 %v67299, 24 (stack44)
        %v67309 = vshrl.u32 %v67299, 8 (stack45)
        %v67310 = vor.u32 %v67309, %v67308 (stack46)
        %v67311 = vxor.u32 %v67310, %v67302 (stack47)
        %v67314 = vadd.s32 %v67311, %v8 (stack39)
        %v67318 = vadd.s32 4, %v67314 (stack39)
        %v67322 = vadd.s32 %v67318, %v67306 (stack39)
        %v67324 = vshll.u32 %v67318, 13 (stack44)
        %v67325 = vshrl.u32 %v67318, 19 (stack45)
        %v67326 = vor.u32 %v67325, %v67324 (stack46)
        %v67327 = vxor.u32 %v67326, %v67322 (stack47)
        %v67330 = vadd.s32 %v67327, %v67322 (stack39)
        %v67332 = vshll.u32 %v67327, 15 (stack44)
        %v67333 = vshrl.u32 %v67327, 17 (stack45)
        %v67334 = vor.u32 %v67333, %v67332 (stack46)
        %v67335 = vxor.u32 %v67334, %v67330 (stack47)
        %v67338 = vadd.s32 %v67335, %v67330 (stack39)
        %v67340 = vshll.u32 %v67335, 26 (stack44)
        %v67341 = vshrl.u32 %v67335, 6 (stack45)
        %v67342 = vor.u32 %v67341, %v67340 (stack46)
        %v67343 = vxor.u32 %v67342, %v67338 (stack47)
        %v67346 = vadd.s32 %v67343, %v67338 (stack39)
        %v67350 = vadd.s32 %v67346, %v8 (stack39)
        %v67352 = vshll.u32 %v67343, 6 (stack44)
        %v67353 = vshrl.u32 %v67343, 26 (stack45)
        %v67354 = vor.u32 %v67353, %v67352 (stack46)
        %v67355 = vxor.u32 %v67354, %v67346 (stack47)
        %v67358 = vadd.s32 %v67355, %v10 (stack39)
        %v67362 = vadd.s32 5, %v67358 (stack39)
        %v67364 = vxor.u32 %v67362, %v67350 (stack47)
        %v67365 = vand.u32.u8 255, %v67364 (stack48)
        %v67366 = vand.u32 65535, %v67365 (stack49)
        %v67367 = vshrl.u32 %v67366, 1 (stack50)
        %v67368 = vor.u32 16256, %v67367 (stack46)
        %v67369 = vand.u32.u16 65535, %v67368 (stack51)
        %v120102 = vadd.low.f32.bf16 -1.0, %v67369 (stack52)
        %v67378 = vmul.f32 2.0, %v120102 (stack53)
        %v67382 = vadd.f32 -0.99609375, %v67378 (stack52)
        %v67386 = vmax.f32 %v67382, -0.99609375 (stack54)
        %v67388 = vand.u32 2147483647, %v67386 (stack55)
        %vm67391 = vcmp.eq.f32.partialorder %v67388, 1.0 (stack56)
        %v67396 = vmul.f32 inf, %v67386 (stack53)
        %v67398 = vxor.u32 2147483648, %v67386 (stack57)
        %v67401 = vmul.f32 %v67398, %v67386 (stack53)
        %v67403 = vadd.f32 1.0, %v67401 (stack58)
        %v67404 = vlog2.pop %v67403 (stack59)
        %v67405 = vmul.f32 0.6931472, %v67404 (stack60)
        %v67406 = vmul.f32 -0.5, %v67401 (stack61)
        %v67407 = vadd.f32 1.0, %v67406 (stack62)
        %v67408 = vmul.f32 %v67407, %v67401 (stack63)
        %v67409 = vand.u32 2147483647, %v67401 (stack64)
        %vm67410 = vcmp.lt.f32.partialorder %v67409, 0.0004427343 (stack65)
        %v67411 = vsel /*vm=*/%vm67410, /*on_true_vy=*/%v67408, /*on_false_vx=*/%v67405 (stack66)
        %v67412 = vxor.u32 2147483648, %v67411 (stack57)
        %vm67415 = vcmp.lt.f32.partialorder %v67412, 5.0 (stack56)
        %v67420 = vsel /*vm=*/%vm67415, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v67424 = vsel /*vm=*/%vm67415, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v67428 = vsel /*vm=*/%vm67415, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v67432 = vsel /*vm=*/%vm67415, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v67436 = vsel /*vm=*/%vm67415, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v67440 = vsel /*vm=*/%vm67415, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v67444 = vsel /*vm=*/%vm67415, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v67448 = vsel /*vm=*/%vm67415, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v67452 = vsel /*vm=*/%vm67415, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v67456 = vadd.f32 -2.5, %v67412 (stack52)
        %v67458 = vrsqrt.pop %v67412 (stack67)
        %v67459 = vmul.f32 %v67458, %v67412 (stack68)
        %vm67460 = vcmp.eq.f32.partialorder %v67412, inf (stack69)
        %v67461 = vsel /*vm=*/%vm67460, /*on_true_vy=*/%v67412, /*on_false_vx=*/%v67459 (stack70)
        %vm67462 = vcmp.eq.f32.partialorder %v67412, 0.0 (stack71)
        %v67463 = vand.u32 2147483648, %v67412 (stack72)
        %v67464 = vsel /*vm=*/%vm67462, /*on_true_vy=*/%v67463, /*on_false_vx=*/%v67461 (stack73)
        %v67467 = vadd.f32 -3.0, %v67464 (stack52)
        %v67471 = vsel /*vm=*/%vm67415, /*on_true_vy=*/%v67456, /*on_false_vx=*/%v67467 (stack43)
        %v67475 = vmul.f32 %v67471, %v67452 (stack53)
        %v67479 = vadd.f32 %v67475, %v67448 (stack52)
        %v67483 = vmul.f32 %v67479, %v67471 (stack53)
        %v67487 = vadd.f32 %v67483, %v67444 (stack52)
        %v67491 = vmul.f32 %v67487, %v67471 (stack53)
        %v67495 = vadd.f32 %v67491, %v67440 (stack52)
        %v67499 = vmul.f32 %v67495, %v67471 (stack53)
        %v67503 = vadd.f32 %v67499, %v67436 (stack52)
        %v67507 = vmul.f32 %v67503, %v67471 (stack53)
        %v67511 = vadd.f32 %v67507, %v67432 (stack52)
        %v67515 = vmul.f32 %v67511, %v67471 (stack53)
        %v67519 = vadd.f32 %v67515, %v67428 (stack52)
        %v67523 = vmul.f32 %v67519, %v67471 (stack53)
        %v67527 = vadd.f32 %v67523, %v67424 (stack52)
        %v67531 = vmul.f32 %v67527, %v67471 (stack53)
        %v67535 = vadd.f32 %v67531, %v67420 (stack52)
        %v67539 = vmul.f32 %v67535, %v67386 (stack53)
        %v67543 = vsel /*vm=*/%vm67391, /*on_true_vy=*/%v67396, /*on_false_vx=*/%v67539 (stack43)
        %v67547 = vmul.f32 1.4140625, %v67543 (stack53)
        %v67550 = vpack.c.bf16 0.0, %v67547 (stack74)
        %120103 = vst [vmem:[%s280 + $0x3c4] sm:$0xf] /*vst_source=*/%v67550 (stack75)
        %s67552 = sadd.s32 144, %s120390 (stack76)
        %s67553 = sshrl.u32 %s67552, 10 (stack23)
        %p120104 = scmp.gt.s32.totalorder %s67553, 1 (stack24)
        %s67555 = scalar_select /*predicate=*/%p120104, /*on_true=*/1, /*on_false=*/%s67553 (stack25)
        %s67556 = sand.u32 1023, %s67552 /* smod.u32 w/div 1024 */ (stack26)
        %s67557 = sshrl.u32 %s67556, 7 (stack27)
        %s67558 = sand.u32 127, %s67556 /* smod.u32 w/div 128 */ (stack28)
        %s120105 = sshll.u32 %s67555, 3 (stack29)
        %s67560 = scalar_lea.vmem %s3, %s120105 (stack30)
        %s67562 = scalar_lea.vmem %s67560, %s67557 (stack31)
        %v67563 = vld [vmem:[%s67562] ss:$0 sm:$0xff] (stack32)
        %s67564 = sand.u32 255, %s67558 (stack33)
        %s67566 = sor.u32 256, %s67564 (stack34)
        %67567 = vbcast.lane.b32.xlu0 %v67563, %s67566 (stack35)
        %v67568 = vpop.permute.xlu0 %67567 (stack36)
        %s67577 = scalar_lea.vmem %s5, %s120105 (stack30)
        %s67579 = scalar_lea.vmem %s67577, %s67557 (stack31)
        %v67580 = vld [vmem:[%s67579] ss:$0 sm:$0xff] (stack32)
        %67584 = vbcast.lane.b32.xlu0 %v67580, %s67566 (stack35)
        %v67585 = vpop.permute.xlu0 %67584 (stack36)
        %v67588 = vadd.s32 %v67585, %v408 (stack39)
        %v67598 = vadd.s32 %v67588, %v415 (stack39)
        %vm67602 = vcmp.lt.u32.totalorder %v67598, %v67588 (stack42)
        %vm67607 = vcmp.lt.u32.totalorder %v67588, %v408 (stack42)
        %v67612 = vadd.s32 %v67568, %v380 (stack39)
        %v67616 = vadd.s32 1, %v67612 (stack39)
        %v67620 = vsel /*vm=*/%vm67607, /*on_true_vy=*/%v67616, /*on_false_vx=*/%v67612 (stack43)
        %v67624 = vadd.s32 1, %v67620 (stack39)
        %v67628 = vsel /*vm=*/%vm67602, /*on_true_vy=*/%v67624, /*on_false_vx=*/%v67620 (stack43)
        %v67633 = vadd.s32 %v67628, %v10 (stack39)
        %v67637 = vadd.s32 %v67598, %v9 (stack39)
        %v67641 = vadd.s32 %v67637, %v67633 (stack39)
        %v67643 = vshll.u32 %v67637, 13 (stack44)
        %v67644 = vshrl.u32 %v67637, 19 (stack45)
        %v67645 = vor.u32 %v67644, %v67643 (stack46)
        %v67646 = vxor.u32 %v67645, %v67641 (stack47)
        %v67649 = vadd.s32 %v67646, %v67641 (stack39)
        %v67651 = vshll.u32 %v67646, 15 (stack44)
        %v67652 = vshrl.u32 %v67646, 17 (stack45)
        %v67653 = vor.u32 %v67652, %v67651 (stack46)
        %v67654 = vxor.u32 %v67653, %v67649 (stack47)
        %v67657 = vadd.s32 %v67654, %v67649 (stack39)
        %v67659 = vshll.u32 %v67654, 26 (stack44)
        %v67660 = vshrl.u32 %v67654, 6 (stack45)
        %v67661 = vor.u32 %v67660, %v67659 (stack46)
        %v67662 = vxor.u32 %v67661, %v67657 (stack47)
        %v67665 = vadd.s32 %v67662, %v67657 (stack39)
        %v67669 = vadd.s32 %v67665, %v9 (stack39)
        %v67671 = vshll.u32 %v67662, 6 (stack44)
        %v67672 = vshrl.u32 %v67662, 26 (stack45)
        %v67673 = vor.u32 %v67672, %v67671 (stack46)
        %v67674 = vxor.u32 %v67673, %v67665 (stack47)
        %v67677 = vadd.s32 %v67674, %v8 (stack39)
        %v67681 = vadd.s32 1, %v67677 (stack39)
        %v67685 = vadd.s32 %v67681, %v67669 (stack39)
        %v67687 = vshll.u32 %v67681, 17 (stack44)
        %v67688 = vshrl.u32 %v67681, 15 (stack45)
        %v67689 = vor.u32 %v67688, %v67687 (stack46)
        %v67690 = vxor.u32 %v67689, %v67685 (stack47)
        %v67693 = vadd.s32 %v67690, %v67685 (stack39)
        %v67695 = vshll.u32 %v67690, 29 (stack44)
        %v67696 = vshrl.u32 %v67690, 3 (stack45)
        %v67697 = vor.u32 %v67696, %v67695 (stack46)
        %v67698 = vxor.u32 %v67697, %v67693 (stack47)
        %v67701 = vadd.s32 %v67698, %v67693 (stack39)
        %v67703 = vshll.u32 %v67698, 16 (stack44)
        %v67704 = vshrl.u32 %v67698, 16 (stack45)
        %v67705 = vor.u32 %v67704, %v67703 (stack46)
        %v67706 = vxor.u32 %v67705, %v67701 (stack47)
        %v67709 = vadd.s32 %v67706, %v67701 (stack39)
        %v67713 = vadd.s32 %v67709, %v8 (stack39)
        %v67715 = vshll.u32 %v67706, 24 (stack44)
        %v67716 = vshrl.u32 %v67706, 8 (stack45)
        %v67717 = vor.u32 %v67716, %v67715 (stack46)
        %v67718 = vxor.u32 %v67717, %v67709 (stack47)
        %v67721 = vadd.s32 %v67718, %v10 (stack39)
        %v67725 = vadd.s32 2, %v67721 (stack39)
        %v67729 = vadd.s32 %v67725, %v67713 (stack39)
        %v67731 = vshll.u32 %v67725, 13 (stack44)
        %v67732 = vshrl.u32 %v67725, 19 (stack45)
        %v67733 = vor.u32 %v67732, %v67731 (stack46)
        %v67734 = vxor.u32 %v67733, %v67729 (stack47)
        %v67737 = vadd.s32 %v67734, %v67729 (stack39)
        %v67739 = vshll.u32 %v67734, 15 (stack44)
        %v67740 = vshrl.u32 %v67734, 17 (stack45)
        %v67741 = vor.u32 %v67740, %v67739 (stack46)
        %v67742 = vxor.u32 %v67741, %v67737 (stack47)
        %v67745 = vadd.s32 %v67742, %v67737 (stack39)
        %v67747 = vshll.u32 %v67742, 26 (stack44)
        %v67748 = vshrl.u32 %v67742, 6 (stack45)
        %v67749 = vor.u32 %v67748, %v67747 (stack46)
        %v67750 = vxor.u32 %v67749, %v67745 (stack47)
        %v67753 = vadd.s32 %v67750, %v67745 (stack39)
        %v67757 = vadd.s32 %v67753, %v10 (stack39)
        %v67759 = vshll.u32 %v67750, 6 (stack44)
        %v67760 = vshrl.u32 %v67750, 26 (stack45)
        %v67761 = vor.u32 %v67760, %v67759 (stack46)
        %v67762 = vxor.u32 %v67761, %v67753 (stack47)
        %v67765 = vadd.s32 %v67762, %v9 (stack39)
        %v67769 = vadd.s32 3, %v67765 (stack39)
        %v67773 = vadd.s32 %v67769, %v67757 (stack39)
        %v67775 = vshll.u32 %v67769, 17 (stack44)
        %v67776 = vshrl.u32 %v67769, 15 (stack45)
        %v67777 = vor.u32 %v67776, %v67775 (stack46)
        %v67778 = vxor.u32 %v67777, %v67773 (stack47)
        %v67781 = vadd.s32 %v67778, %v67773 (stack39)
        %v67783 = vshll.u32 %v67778, 29 (stack44)
        %v67784 = vshrl.u32 %v67778, 3 (stack45)
        %v67785 = vor.u32 %v67784, %v67783 (stack46)
        %v67786 = vxor.u32 %v67785, %v67781 (stack47)
        %v67789 = vadd.s32 %v67786, %v67781 (stack39)
        %v67791 = vshll.u32 %v67786, 16 (stack44)
        %v67792 = vshrl.u32 %v67786, 16 (stack45)
        %v67793 = vor.u32 %v67792, %v67791 (stack46)
        %v67794 = vxor.u32 %v67793, %v67789 (stack47)
        %v67797 = vadd.s32 %v67794, %v67789 (stack39)
        %v67801 = vadd.s32 %v67797, %v9 (stack39)
        %v67803 = vshll.u32 %v67794, 24 (stack44)
        %v67804 = vshrl.u32 %v67794, 8 (stack45)
        %v67805 = vor.u32 %v67804, %v67803 (stack46)
        %v67806 = vxor.u32 %v67805, %v67797 (stack47)
        %v67809 = vadd.s32 %v67806, %v8 (stack39)
        %v67813 = vadd.s32 4, %v67809 (stack39)
        %v67817 = vadd.s32 %v67813, %v67801 (stack39)
        %v67819 = vshll.u32 %v67813, 13 (stack44)
        %v67820 = vshrl.u32 %v67813, 19 (stack45)
        %v67821 = vor.u32 %v67820, %v67819 (stack46)
        %v67822 = vxor.u32 %v67821, %v67817 (stack47)
        %v67825 = vadd.s32 %v67822, %v67817 (stack39)
        %v67827 = vshll.u32 %v67822, 15 (stack44)
        %v67828 = vshrl.u32 %v67822, 17 (stack45)
        %v67829 = vor.u32 %v67828, %v67827 (stack46)
        %v67830 = vxor.u32 %v67829, %v67825 (stack47)
        %v67833 = vadd.s32 %v67830, %v67825 (stack39)
        %v67835 = vshll.u32 %v67830, 26 (stack44)
        %v67836 = vshrl.u32 %v67830, 6 (stack45)
        %v67837 = vor.u32 %v67836, %v67835 (stack46)
        %v67838 = vxor.u32 %v67837, %v67833 (stack47)
        %v67841 = vadd.s32 %v67838, %v67833 (stack39)
        %v67845 = vadd.s32 %v67841, %v8 (stack39)
        %v67847 = vshll.u32 %v67838, 6 (stack44)
        %v67848 = vshrl.u32 %v67838, 26 (stack45)
        %v67849 = vor.u32 %v67848, %v67847 (stack46)
        %v67850 = vxor.u32 %v67849, %v67841 (stack47)
        %v67853 = vadd.s32 %v67850, %v10 (stack39)
        %v67857 = vadd.s32 5, %v67853 (stack39)
        %v67859 = vxor.u32 %v67857, %v67845 (stack47)
        %v67860 = vand.u32.u8 255, %v67859 (stack48)
        %v67861 = vand.u32 65535, %v67860 (stack49)
        %v67862 = vshrl.u32 %v67861, 1 (stack50)
        %v67863 = vor.u32 16256, %v67862 (stack46)
        %v67864 = vand.u32.u16 65535, %v67863 (stack51)
        %v120108 = vadd.low.f32.bf16 -1.0, %v67864 (stack52)
        %v67873 = vmul.f32 2.0, %v120108 (stack53)
        %v67877 = vadd.f32 -0.99609375, %v67873 (stack52)
        %v67881 = vmax.f32 %v67877, -0.99609375 (stack54)
        %v67883 = vand.u32 2147483647, %v67881 (stack55)
        %vm67886 = vcmp.eq.f32.partialorder %v67883, 1.0 (stack56)
        %v67891 = vmul.f32 inf, %v67881 (stack53)
        %v67893 = vxor.u32 2147483648, %v67881 (stack57)
        %v67896 = vmul.f32 %v67893, %v67881 (stack53)
        %v67898 = vadd.f32 1.0, %v67896 (stack58)
        %v67899 = vlog2.pop %v67898 (stack59)
        %v67900 = vmul.f32 0.6931472, %v67899 (stack60)
        %v67901 = vmul.f32 -0.5, %v67896 (stack61)
        %v67902 = vadd.f32 1.0, %v67901 (stack62)
        %v67903 = vmul.f32 %v67902, %v67896 (stack63)
        %v67904 = vand.u32 2147483647, %v67896 (stack64)
        %vm67905 = vcmp.lt.f32.partialorder %v67904, 0.0004427343 (stack65)
        %v67906 = vsel /*vm=*/%vm67905, /*on_true_vy=*/%v67903, /*on_false_vx=*/%v67900 (stack66)
        %v67907 = vxor.u32 2147483648, %v67906 (stack57)
        %vm67910 = vcmp.lt.f32.partialorder %v67907, 5.0 (stack56)
        %v67915 = vsel /*vm=*/%vm67910, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v67919 = vsel /*vm=*/%vm67910, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v67923 = vsel /*vm=*/%vm67910, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v67927 = vsel /*vm=*/%vm67910, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v67931 = vsel /*vm=*/%vm67910, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v67935 = vsel /*vm=*/%vm67910, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v67939 = vsel /*vm=*/%vm67910, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v67943 = vsel /*vm=*/%vm67910, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v67947 = vsel /*vm=*/%vm67910, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v67951 = vadd.f32 -2.5, %v67907 (stack52)
        %v67953 = vrsqrt.pop %v67907 (stack67)
        %v67954 = vmul.f32 %v67953, %v67907 (stack68)
        %vm67955 = vcmp.eq.f32.partialorder %v67907, inf (stack69)
        %v67956 = vsel /*vm=*/%vm67955, /*on_true_vy=*/%v67907, /*on_false_vx=*/%v67954 (stack70)
        %vm67957 = vcmp.eq.f32.partialorder %v67907, 0.0 (stack71)
        %v67958 = vand.u32 2147483648, %v67907 (stack72)
        %v67959 = vsel /*vm=*/%vm67957, /*on_true_vy=*/%v67958, /*on_false_vx=*/%v67956 (stack73)
        %v67962 = vadd.f32 -3.0, %v67959 (stack52)
        %v67966 = vsel /*vm=*/%vm67910, /*on_true_vy=*/%v67951, /*on_false_vx=*/%v67962 (stack43)
        %v67970 = vmul.f32 %v67966, %v67947 (stack53)
        %v67974 = vadd.f32 %v67970, %v67943 (stack52)
        %v67978 = vmul.f32 %v67974, %v67966 (stack53)
        %v67982 = vadd.f32 %v67978, %v67939 (stack52)
        %v67986 = vmul.f32 %v67982, %v67966 (stack53)
        %v67990 = vadd.f32 %v67986, %v67935 (stack52)
        %v67994 = vmul.f32 %v67990, %v67966 (stack53)
        %v67998 = vadd.f32 %v67994, %v67931 (stack52)
        %v68002 = vmul.f32 %v67998, %v67966 (stack53)
        %v68006 = vadd.f32 %v68002, %v67927 (stack52)
        %v68010 = vmul.f32 %v68006, %v67966 (stack53)
        %v68014 = vadd.f32 %v68010, %v67923 (stack52)
        %v68018 = vmul.f32 %v68014, %v67966 (stack53)
        %v68022 = vadd.f32 %v68018, %v67919 (stack52)
        %v68026 = vmul.f32 %v68022, %v67966 (stack53)
        %v68030 = vadd.f32 %v68026, %v67915 (stack52)
        %v68034 = vmul.f32 %v68030, %v67881 (stack53)
        %v68038 = vsel /*vm=*/%vm67886, /*on_true_vy=*/%v67891, /*on_false_vx=*/%v68034 (stack43)
        %v68042 = vmul.f32 1.4140625, %v68038 (stack53)
        %v68045 = vpack.c.bf16 0.0, %v68042 (stack74)
        %120109 = vst [vmem:[%s280 + $0x48] sm:$0xf] /*vst_source=*/%v68045 (stack75)
        %v68049 = vadd.s32 %v67585, %v894 (stack39)
        %v68059 = vadd.s32 %v68049, %v415 (stack39)
        %vm68063 = vcmp.lt.u32.totalorder %v68059, %v68049 (stack42)
        %vm68068 = vcmp.lt.u32.totalorder %v68049, %v894 (stack42)
        %v68073 = vadd.s32 %v67568, %v881 (stack39)
        %v68077 = vadd.s32 1, %v68073 (stack39)
        %v68081 = vsel /*vm=*/%vm68068, /*on_true_vy=*/%v68077, /*on_false_vx=*/%v68073 (stack43)
        %v68085 = vadd.s32 1, %v68081 (stack39)
        %v68089 = vsel /*vm=*/%vm68063, /*on_true_vy=*/%v68085, /*on_false_vx=*/%v68081 (stack43)
        %v68094 = vadd.s32 %v68089, %v10 (stack39)
        %v68098 = vadd.s32 %v68059, %v9 (stack39)
        %v68102 = vadd.s32 %v68098, %v68094 (stack39)
        %v68104 = vshll.u32 %v68098, 13 (stack44)
        %v68105 = vshrl.u32 %v68098, 19 (stack45)
        %v68106 = vor.u32 %v68105, %v68104 (stack46)
        %v68107 = vxor.u32 %v68106, %v68102 (stack47)
        %v68110 = vadd.s32 %v68107, %v68102 (stack39)
        %v68112 = vshll.u32 %v68107, 15 (stack44)
        %v68113 = vshrl.u32 %v68107, 17 (stack45)
        %v68114 = vor.u32 %v68113, %v68112 (stack46)
        %v68115 = vxor.u32 %v68114, %v68110 (stack47)
        %v68118 = vadd.s32 %v68115, %v68110 (stack39)
        %v68120 = vshll.u32 %v68115, 26 (stack44)
        %v68121 = vshrl.u32 %v68115, 6 (stack45)
        %v68122 = vor.u32 %v68121, %v68120 (stack46)
        %v68123 = vxor.u32 %v68122, %v68118 (stack47)
        %v68126 = vadd.s32 %v68123, %v68118 (stack39)
        %v68130 = vadd.s32 %v68126, %v9 (stack39)
        %v68132 = vshll.u32 %v68123, 6 (stack44)
        %v68133 = vshrl.u32 %v68123, 26 (stack45)
        %v68134 = vor.u32 %v68133, %v68132 (stack46)
        %v68135 = vxor.u32 %v68134, %v68126 (stack47)
        %v68138 = vadd.s32 %v68135, %v8 (stack39)
        %v68142 = vadd.s32 1, %v68138 (stack39)
        %v68146 = vadd.s32 %v68142, %v68130 (stack39)
        %v68148 = vshll.u32 %v68142, 17 (stack44)
        %v68149 = vshrl.u32 %v68142, 15 (stack45)
        %v68150 = vor.u32 %v68149, %v68148 (stack46)
        %v68151 = vxor.u32 %v68150, %v68146 (stack47)
        %v68154 = vadd.s32 %v68151, %v68146 (stack39)
        %v68156 = vshll.u32 %v68151, 29 (stack44)
        %v68157 = vshrl.u32 %v68151, 3 (stack45)
        %v68158 = vor.u32 %v68157, %v68156 (stack46)
        %v68159 = vxor.u32 %v68158, %v68154 (stack47)
        %v68162 = vadd.s32 %v68159, %v68154 (stack39)
        %v68164 = vshll.u32 %v68159, 16 (stack44)
        %v68165 = vshrl.u32 %v68159, 16 (stack45)
        %v68166 = vor.u32 %v68165, %v68164 (stack46)
        %v68167 = vxor.u32 %v68166, %v68162 (stack47)
        %v68170 = vadd.s32 %v68167, %v68162 (stack39)
        %v68174 = vadd.s32 %v68170, %v8 (stack39)
        %v68176 = vshll.u32 %v68167, 24 (stack44)
        %v68177 = vshrl.u32 %v68167, 8 (stack45)
        %v68178 = vor.u32 %v68177, %v68176 (stack46)
        %v68179 = vxor.u32 %v68178, %v68170 (stack47)
        %v68182 = vadd.s32 %v68179, %v10 (stack39)
        %v68186 = vadd.s32 2, %v68182 (stack39)
        %v68190 = vadd.s32 %v68186, %v68174 (stack39)
        %v68192 = vshll.u32 %v68186, 13 (stack44)
        %v68193 = vshrl.u32 %v68186, 19 (stack45)
        %v68194 = vor.u32 %v68193, %v68192 (stack46)
        %v68195 = vxor.u32 %v68194, %v68190 (stack47)
        %v68198 = vadd.s32 %v68195, %v68190 (stack39)
        %v68200 = vshll.u32 %v68195, 15 (stack44)
        %v68201 = vshrl.u32 %v68195, 17 (stack45)
        %v68202 = vor.u32 %v68201, %v68200 (stack46)
        %v68203 = vxor.u32 %v68202, %v68198 (stack47)
        %v68206 = vadd.s32 %v68203, %v68198 (stack39)
        %v68208 = vshll.u32 %v68203, 26 (stack44)
        %v68209 = vshrl.u32 %v68203, 6 (stack45)
        %v68210 = vor.u32 %v68209, %v68208 (stack46)
        %v68211 = vxor.u32 %v68210, %v68206 (stack47)
        %v68214 = vadd.s32 %v68211, %v68206 (stack39)
        %v68218 = vadd.s32 %v68214, %v10 (stack39)
        %v68220 = vshll.u32 %v68211, 6 (stack44)
        %v68221 = vshrl.u32 %v68211, 26 (stack45)
        %v68222 = vor.u32 %v68221, %v68220 (stack46)
        %v68223 = vxor.u32 %v68222, %v68214 (stack47)
        %v68226 = vadd.s32 %v68223, %v9 (stack39)
        %v68230 = vadd.s32 3, %v68226 (stack39)
        %v68234 = vadd.s32 %v68230, %v68218 (stack39)
        %v68236 = vshll.u32 %v68230, 17 (stack44)
        %v68237 = vshrl.u32 %v68230, 15 (stack45)
        %v68238 = vor.u32 %v68237, %v68236 (stack46)
        %v68239 = vxor.u32 %v68238, %v68234 (stack47)
        %v68242 = vadd.s32 %v68239, %v68234 (stack39)
        %v68244 = vshll.u32 %v68239, 29 (stack44)
        %v68245 = vshrl.u32 %v68239, 3 (stack45)
        %v68246 = vor.u32 %v68245, %v68244 (stack46)
        %v68247 = vxor.u32 %v68246, %v68242 (stack47)
        %v68250 = vadd.s32 %v68247, %v68242 (stack39)
        %v68252 = vshll.u32 %v68247, 16 (stack44)
        %v68253 = vshrl.u32 %v68247, 16 (stack45)
        %v68254 = vor.u32 %v68253, %v68252 (stack46)
        %v68255 = vxor.u32 %v68254, %v68250 (stack47)
        %v68258 = vadd.s32 %v68255, %v68250 (stack39)
        %v68262 = vadd.s32 %v68258, %v9 (stack39)
        %v68264 = vshll.u32 %v68255, 24 (stack44)
        %v68265 = vshrl.u32 %v68255, 8 (stack45)
        %v68266 = vor.u32 %v68265, %v68264 (stack46)
        %v68267 = vxor.u32 %v68266, %v68258 (stack47)
        %v68270 = vadd.s32 %v68267, %v8 (stack39)
        %v68274 = vadd.s32 4, %v68270 (stack39)
        %v68278 = vadd.s32 %v68274, %v68262 (stack39)
        %v68280 = vshll.u32 %v68274, 13 (stack44)
        %v68281 = vshrl.u32 %v68274, 19 (stack45)
        %v68282 = vor.u32 %v68281, %v68280 (stack46)
        %v68283 = vxor.u32 %v68282, %v68278 (stack47)
        %v68286 = vadd.s32 %v68283, %v68278 (stack39)
        %v68288 = vshll.u32 %v68283, 15 (stack44)
        %v68289 = vshrl.u32 %v68283, 17 (stack45)
        %v68290 = vor.u32 %v68289, %v68288 (stack46)
        %v68291 = vxor.u32 %v68290, %v68286 (stack47)
        %v68294 = vadd.s32 %v68291, %v68286 (stack39)
        %v68296 = vshll.u32 %v68291, 26 (stack44)
        %v68297 = vshrl.u32 %v68291, 6 (stack45)
        %v68298 = vor.u32 %v68297, %v68296 (stack46)
        %v68299 = vxor.u32 %v68298, %v68294 (stack47)
        %v68302 = vadd.s32 %v68299, %v68294 (stack39)
        %v68306 = vadd.s32 %v68302, %v8 (stack39)
        %v68308 = vshll.u32 %v68299, 6 (stack44)
        %v68309 = vshrl.u32 %v68299, 26 (stack45)
        %v68310 = vor.u32 %v68309, %v68308 (stack46)
        %v68311 = vxor.u32 %v68310, %v68302 (stack47)
        %v68314 = vadd.s32 %v68311, %v10 (stack39)
        %v68318 = vadd.s32 5, %v68314 (stack39)
        %v68320 = vxor.u32 %v68318, %v68306 (stack47)
        %v68321 = vand.u32.u8 255, %v68320 (stack48)
        %v68322 = vand.u32 65535, %v68321 (stack49)
        %v68323 = vshrl.u32 %v68322, 1 (stack50)
        %v68324 = vor.u32 16256, %v68323 (stack46)
        %v68325 = vand.u32.u16 65535, %v68324 (stack51)
        %v120110 = vadd.low.f32.bf16 -1.0, %v68325 (stack52)
        %v68334 = vmul.f32 2.0, %v120110 (stack53)
        %v68338 = vadd.f32 -0.99609375, %v68334 (stack52)
        %v68342 = vmax.f32 %v68338, -0.99609375 (stack54)
        %v68344 = vand.u32 2147483647, %v68342 (stack55)
        %vm68347 = vcmp.eq.f32.partialorder %v68344, 1.0 (stack56)
        %v68352 = vmul.f32 inf, %v68342 (stack53)
        %v68354 = vxor.u32 2147483648, %v68342 (stack57)
        %v68357 = vmul.f32 %v68354, %v68342 (stack53)
        %v68359 = vadd.f32 1.0, %v68357 (stack58)
        %v68360 = vlog2.pop %v68359 (stack59)
        %v68361 = vmul.f32 0.6931472, %v68360 (stack60)
        %v68362 = vmul.f32 -0.5, %v68357 (stack61)
        %v68363 = vadd.f32 1.0, %v68362 (stack62)
        %v68364 = vmul.f32 %v68363, %v68357 (stack63)
        %v68365 = vand.u32 2147483647, %v68357 (stack64)
        %vm68366 = vcmp.lt.f32.partialorder %v68365, 0.0004427343 (stack65)
        %v68367 = vsel /*vm=*/%vm68366, /*on_true_vy=*/%v68364, /*on_false_vx=*/%v68361 (stack66)
        %v68368 = vxor.u32 2147483648, %v68367 (stack57)
        %vm68371 = vcmp.lt.f32.partialorder %v68368, 5.0 (stack56)
        %v68376 = vsel /*vm=*/%vm68371, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v68380 = vsel /*vm=*/%vm68371, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v68384 = vsel /*vm=*/%vm68371, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v68388 = vsel /*vm=*/%vm68371, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v68392 = vsel /*vm=*/%vm68371, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v68396 = vsel /*vm=*/%vm68371, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v68400 = vsel /*vm=*/%vm68371, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v68404 = vsel /*vm=*/%vm68371, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v68408 = vsel /*vm=*/%vm68371, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v68412 = vadd.f32 -2.5, %v68368 (stack52)
        %v68414 = vrsqrt.pop %v68368 (stack67)
        %v68415 = vmul.f32 %v68414, %v68368 (stack68)
        %vm68416 = vcmp.eq.f32.partialorder %v68368, inf (stack69)
        %v68417 = vsel /*vm=*/%vm68416, /*on_true_vy=*/%v68368, /*on_false_vx=*/%v68415 (stack70)
        %vm68418 = vcmp.eq.f32.partialorder %v68368, 0.0 (stack71)
        %v68419 = vand.u32 2147483648, %v68368 (stack72)
        %v68420 = vsel /*vm=*/%vm68418, /*on_true_vy=*/%v68419, /*on_false_vx=*/%v68417 (stack73)
        %v68423 = vadd.f32 -3.0, %v68420 (stack52)
        %v68427 = vsel /*vm=*/%vm68371, /*on_true_vy=*/%v68412, /*on_false_vx=*/%v68423 (stack43)
        %v68431 = vmul.f32 %v68427, %v68408 (stack53)
        %v68435 = vadd.f32 %v68431, %v68404 (stack52)
        %v68439 = vmul.f32 %v68435, %v68427 (stack53)
        %v68443 = vadd.f32 %v68439, %v68400 (stack52)
        %v68447 = vmul.f32 %v68443, %v68427 (stack53)
        %v68451 = vadd.f32 %v68447, %v68396 (stack52)
        %v68455 = vmul.f32 %v68451, %v68427 (stack53)
        %v68459 = vadd.f32 %v68455, %v68392 (stack52)
        %v68463 = vmul.f32 %v68459, %v68427 (stack53)
        %v68467 = vadd.f32 %v68463, %v68388 (stack52)
        %v68471 = vmul.f32 %v68467, %v68427 (stack53)
        %v68475 = vadd.f32 %v68471, %v68384 (stack52)
        %v68479 = vmul.f32 %v68475, %v68427 (stack53)
        %v68483 = vadd.f32 %v68479, %v68380 (stack52)
        %v68487 = vmul.f32 %v68483, %v68427 (stack53)
        %v68491 = vadd.f32 %v68487, %v68376 (stack52)
        %v68495 = vmul.f32 %v68491, %v68342 (stack53)
        %v68499 = vsel /*vm=*/%vm68347, /*on_true_vy=*/%v68352, /*on_false_vx=*/%v68495 (stack43)
        %v68503 = vmul.f32 1.4140625, %v68499 (stack53)
        %v68506 = vpack.c.bf16 0.0, %v68503 (stack74)
        %120111 = vst [vmem:[%s280 + $0xc8] sm:$0xf] /*vst_source=*/%v68506 (stack75)
        %v68510 = vadd.s32 %v67585, %v1381 (stack39)
        %v68520 = vadd.s32 %v68510, %v415 (stack39)
        %vm68524 = vcmp.lt.u32.totalorder %v68520, %v68510 (stack42)
        %vm68529 = vcmp.lt.u32.totalorder %v68510, %v1381 (stack42)
        %v68534 = vadd.s32 %v67568, %v1368 (stack39)
        %v68538 = vadd.s32 1, %v68534 (stack39)
        %v68542 = vsel /*vm=*/%vm68529, /*on_true_vy=*/%v68538, /*on_false_vx=*/%v68534 (stack43)
        %v68546 = vadd.s32 1, %v68542 (stack39)
        %v68550 = vsel /*vm=*/%vm68524, /*on_true_vy=*/%v68546, /*on_false_vx=*/%v68542 (stack43)
        %v68555 = vadd.s32 %v68550, %v10 (stack39)
        %v68559 = vadd.s32 %v68520, %v9 (stack39)
        %v68563 = vadd.s32 %v68559, %v68555 (stack39)
        %v68565 = vshll.u32 %v68559, 13 (stack44)
        %v68566 = vshrl.u32 %v68559, 19 (stack45)
        %v68567 = vor.u32 %v68566, %v68565 (stack46)
        %v68568 = vxor.u32 %v68567, %v68563 (stack47)
        %v68571 = vadd.s32 %v68568, %v68563 (stack39)
        %v68573 = vshll.u32 %v68568, 15 (stack44)
        %v68574 = vshrl.u32 %v68568, 17 (stack45)
        %v68575 = vor.u32 %v68574, %v68573 (stack46)
        %v68576 = vxor.u32 %v68575, %v68571 (stack47)
        %v68579 = vadd.s32 %v68576, %v68571 (stack39)
        %v68581 = vshll.u32 %v68576, 26 (stack44)
        %v68582 = vshrl.u32 %v68576, 6 (stack45)
        %v68583 = vor.u32 %v68582, %v68581 (stack46)
        %v68584 = vxor.u32 %v68583, %v68579 (stack47)
        %v68587 = vadd.s32 %v68584, %v68579 (stack39)
        %v68591 = vadd.s32 %v68587, %v9 (stack39)
        %v68593 = vshll.u32 %v68584, 6 (stack44)
        %v68594 = vshrl.u32 %v68584, 26 (stack45)
        %v68595 = vor.u32 %v68594, %v68593 (stack46)
        %v68596 = vxor.u32 %v68595, %v68587 (stack47)
        %v68599 = vadd.s32 %v68596, %v8 (stack39)
        %v68603 = vadd.s32 1, %v68599 (stack39)
        %v68607 = vadd.s32 %v68603, %v68591 (stack39)
        %v68609 = vshll.u32 %v68603, 17 (stack44)
        %v68610 = vshrl.u32 %v68603, 15 (stack45)
        %v68611 = vor.u32 %v68610, %v68609 (stack46)
        %v68612 = vxor.u32 %v68611, %v68607 (stack47)
        %v68615 = vadd.s32 %v68612, %v68607 (stack39)
        %v68617 = vshll.u32 %v68612, 29 (stack44)
        %v68618 = vshrl.u32 %v68612, 3 (stack45)
        %v68619 = vor.u32 %v68618, %v68617 (stack46)
        %v68620 = vxor.u32 %v68619, %v68615 (stack47)
        %v68623 = vadd.s32 %v68620, %v68615 (stack39)
        %v68625 = vshll.u32 %v68620, 16 (stack44)
        %v68626 = vshrl.u32 %v68620, 16 (stack45)
        %v68627 = vor.u32 %v68626, %v68625 (stack46)
        %v68628 = vxor.u32 %v68627, %v68623 (stack47)
        %v68631 = vadd.s32 %v68628, %v68623 (stack39)
        %v68635 = vadd.s32 %v68631, %v8 (stack39)
        %v68637 = vshll.u32 %v68628, 24 (stack44)
        %v68638 = vshrl.u32 %v68628, 8 (stack45)
        %v68639 = vor.u32 %v68638, %v68637 (stack46)
        %v68640 = vxor.u32 %v68639, %v68631 (stack47)
        %v68643 = vadd.s32 %v68640, %v10 (stack39)
        %v68647 = vadd.s32 2, %v68643 (stack39)
        %v68651 = vadd.s32 %v68647, %v68635 (stack39)
        %v68653 = vshll.u32 %v68647, 13 (stack44)
        %v68654 = vshrl.u32 %v68647, 19 (stack45)
        %v68655 = vor.u32 %v68654, %v68653 (stack46)
        %v68656 = vxor.u32 %v68655, %v68651 (stack47)
        %v68659 = vadd.s32 %v68656, %v68651 (stack39)
        %v68661 = vshll.u32 %v68656, 15 (stack44)
        %v68662 = vshrl.u32 %v68656, 17 (stack45)
        %v68663 = vor.u32 %v68662, %v68661 (stack46)
        %v68664 = vxor.u32 %v68663, %v68659 (stack47)
        %v68667 = vadd.s32 %v68664, %v68659 (stack39)
        %v68669 = vshll.u32 %v68664, 26 (stack44)
        %v68670 = vshrl.u32 %v68664, 6 (stack45)
        %v68671 = vor.u32 %v68670, %v68669 (stack46)
        %v68672 = vxor.u32 %v68671, %v68667 (stack47)
        %v68675 = vadd.s32 %v68672, %v68667 (stack39)
        %v68679 = vadd.s32 %v68675, %v10 (stack39)
        %v68681 = vshll.u32 %v68672, 6 (stack44)
        %v68682 = vshrl.u32 %v68672, 26 (stack45)
        %v68683 = vor.u32 %v68682, %v68681 (stack46)
        %v68684 = vxor.u32 %v68683, %v68675 (stack47)
        %v68687 = vadd.s32 %v68684, %v9 (stack39)
        %v68691 = vadd.s32 3, %v68687 (stack39)
        %v68695 = vadd.s32 %v68691, %v68679 (stack39)
        %v68697 = vshll.u32 %v68691, 17 (stack44)
        %v68698 = vshrl.u32 %v68691, 15 (stack45)
        %v68699 = vor.u32 %v68698, %v68697 (stack46)
        %v68700 = vxor.u32 %v68699, %v68695 (stack47)
        %v68703 = vadd.s32 %v68700, %v68695 (stack39)
        %v68705 = vshll.u32 %v68700, 29 (stack44)
        %v68706 = vshrl.u32 %v68700, 3 (stack45)
        %v68707 = vor.u32 %v68706, %v68705 (stack46)
        %v68708 = vxor.u32 %v68707, %v68703 (stack47)
        %v68711 = vadd.s32 %v68708, %v68703 (stack39)
        %v68713 = vshll.u32 %v68708, 16 (stack44)
        %v68714 = vshrl.u32 %v68708, 16 (stack45)
        %v68715 = vor.u32 %v68714, %v68713 (stack46)
        %v68716 = vxor.u32 %v68715, %v68711 (stack47)
        %v68719 = vadd.s32 %v68716, %v68711 (stack39)
        %v68723 = vadd.s32 %v68719, %v9 (stack39)
        %v68725 = vshll.u32 %v68716, 24 (stack44)
        %v68726 = vshrl.u32 %v68716, 8 (stack45)
        %v68727 = vor.u32 %v68726, %v68725 (stack46)
        %v68728 = vxor.u32 %v68727, %v68719 (stack47)
        %v68731 = vadd.s32 %v68728, %v8 (stack39)
        %v68735 = vadd.s32 4, %v68731 (stack39)
        %v68739 = vadd.s32 %v68735, %v68723 (stack39)
        %v68741 = vshll.u32 %v68735, 13 (stack44)
        %v68742 = vshrl.u32 %v68735, 19 (stack45)
        %v68743 = vor.u32 %v68742, %v68741 (stack46)
        %v68744 = vxor.u32 %v68743, %v68739 (stack47)
        %v68747 = vadd.s32 %v68744, %v68739 (stack39)
        %v68749 = vshll.u32 %v68744, 15 (stack44)
        %v68750 = vshrl.u32 %v68744, 17 (stack45)
        %v68751 = vor.u32 %v68750, %v68749 (stack46)
        %v68752 = vxor.u32 %v68751, %v68747 (stack47)
        %v68755 = vadd.s32 %v68752, %v68747 (stack39)
        %v68757 = vshll.u32 %v68752, 26 (stack44)
        %v68758 = vshrl.u32 %v68752, 6 (stack45)
        %v68759 = vor.u32 %v68758, %v68757 (stack46)
        %v68760 = vxor.u32 %v68759, %v68755 (stack47)
        %v68763 = vadd.s32 %v68760, %v68755 (stack39)
        %v68767 = vadd.s32 %v68763, %v8 (stack39)
        %v68769 = vshll.u32 %v68760, 6 (stack44)
        %v68770 = vshrl.u32 %v68760, 26 (stack45)
        %v68771 = vor.u32 %v68770, %v68769 (stack46)
        %v68772 = vxor.u32 %v68771, %v68763 (stack47)
        %v68775 = vadd.s32 %v68772, %v10 (stack39)
        %v68779 = vadd.s32 5, %v68775 (stack39)
        %v68781 = vxor.u32 %v68779, %v68767 (stack47)
        %v68782 = vand.u32.u8 255, %v68781 (stack48)
        %v68783 = vand.u32 65535, %v68782 (stack49)
        %v68784 = vshrl.u32 %v68783, 1 (stack50)
        %v68785 = vor.u32 16256, %v68784 (stack46)
        %v68786 = vand.u32.u16 65535, %v68785 (stack51)
        %v120112 = vadd.low.f32.bf16 -1.0, %v68786 (stack52)
        %v68795 = vmul.f32 2.0, %v120112 (stack53)
        %v68799 = vadd.f32 -0.99609375, %v68795 (stack52)
        %v68803 = vmax.f32 %v68799, -0.99609375 (stack54)
        %v68805 = vand.u32 2147483647, %v68803 (stack55)
        %vm68808 = vcmp.eq.f32.partialorder %v68805, 1.0 (stack56)
        %v68813 = vmul.f32 inf, %v68803 (stack53)
        %v68815 = vxor.u32 2147483648, %v68803 (stack57)
        %v68818 = vmul.f32 %v68815, %v68803 (stack53)
        %v68820 = vadd.f32 1.0, %v68818 (stack58)
        %v68821 = vlog2.pop %v68820 (stack59)
        %v68822 = vmul.f32 0.6931472, %v68821 (stack60)
        %v68823 = vmul.f32 -0.5, %v68818 (stack61)
        %v68824 = vadd.f32 1.0, %v68823 (stack62)
        %v68825 = vmul.f32 %v68824, %v68818 (stack63)
        %v68826 = vand.u32 2147483647, %v68818 (stack64)
        %vm68827 = vcmp.lt.f32.partialorder %v68826, 0.0004427343 (stack65)
        %v68828 = vsel /*vm=*/%vm68827, /*on_true_vy=*/%v68825, /*on_false_vx=*/%v68822 (stack66)
        %v68829 = vxor.u32 2147483648, %v68828 (stack57)
        %vm68832 = vcmp.lt.f32.partialorder %v68829, 5.0 (stack56)
        %v68837 = vsel /*vm=*/%vm68832, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v68841 = vsel /*vm=*/%vm68832, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v68845 = vsel /*vm=*/%vm68832, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v68849 = vsel /*vm=*/%vm68832, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v68853 = vsel /*vm=*/%vm68832, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v68857 = vsel /*vm=*/%vm68832, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v68861 = vsel /*vm=*/%vm68832, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v68865 = vsel /*vm=*/%vm68832, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v68869 = vsel /*vm=*/%vm68832, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v68873 = vadd.f32 -2.5, %v68829 (stack52)
        %v68875 = vrsqrt.pop %v68829 (stack67)
        %v68876 = vmul.f32 %v68875, %v68829 (stack68)
        %vm68877 = vcmp.eq.f32.partialorder %v68829, inf (stack69)
        %v68878 = vsel /*vm=*/%vm68877, /*on_true_vy=*/%v68829, /*on_false_vx=*/%v68876 (stack70)
        %vm68879 = vcmp.eq.f32.partialorder %v68829, 0.0 (stack71)
        %v68880 = vand.u32 2147483648, %v68829 (stack72)
        %v68881 = vsel /*vm=*/%vm68879, /*on_true_vy=*/%v68880, /*on_false_vx=*/%v68878 (stack73)
        %v68884 = vadd.f32 -3.0, %v68881 (stack52)
        %v68888 = vsel /*vm=*/%vm68832, /*on_true_vy=*/%v68873, /*on_false_vx=*/%v68884 (stack43)
        %v68892 = vmul.f32 %v68888, %v68869 (stack53)
        %v68896 = vadd.f32 %v68892, %v68865 (stack52)
        %v68900 = vmul.f32 %v68896, %v68888 (stack53)
        %v68904 = vadd.f32 %v68900, %v68861 (stack52)
        %v68908 = vmul.f32 %v68904, %v68888 (stack53)
        %v68912 = vadd.f32 %v68908, %v68857 (stack52)
        %v68916 = vmul.f32 %v68912, %v68888 (stack53)
        %v68920 = vadd.f32 %v68916, %v68853 (stack52)
        %v68924 = vmul.f32 %v68920, %v68888 (stack53)
        %v68928 = vadd.f32 %v68924, %v68849 (stack52)
        %v68932 = vmul.f32 %v68928, %v68888 (stack53)
        %v68936 = vadd.f32 %v68932, %v68845 (stack52)
        %v68940 = vmul.f32 %v68936, %v68888 (stack53)
        %v68944 = vadd.f32 %v68940, %v68841 (stack52)
        %v68948 = vmul.f32 %v68944, %v68888 (stack53)
        %v68952 = vadd.f32 %v68948, %v68837 (stack52)
        %v68956 = vmul.f32 %v68952, %v68803 (stack53)
        %v68960 = vsel /*vm=*/%vm68808, /*on_true_vy=*/%v68813, /*on_false_vx=*/%v68956 (stack43)
        %v68964 = vmul.f32 1.4140625, %v68960 (stack53)
        %v68967 = vpack.c.bf16 0.0, %v68964 (stack74)
        %120113 = vst [vmem:[%s280 + $0x148] sm:$0xf] /*vst_source=*/%v68967 (stack75)
        %v68971 = vadd.s32 %v67585, %v1868 (stack39)
        %v68981 = vadd.s32 %v68971, %v415 (stack39)
        %vm68985 = vcmp.lt.u32.totalorder %v68981, %v68971 (stack42)
        %vm68990 = vcmp.lt.u32.totalorder %v68971, %v1868 (stack42)
        %v68995 = vadd.s32 %v67568, %v1855 (stack39)
        %v68999 = vadd.s32 1, %v68995 (stack39)
        %v69003 = vsel /*vm=*/%vm68990, /*on_true_vy=*/%v68999, /*on_false_vx=*/%v68995 (stack43)
        %v69007 = vadd.s32 1, %v69003 (stack39)
        %v69011 = vsel /*vm=*/%vm68985, /*on_true_vy=*/%v69007, /*on_false_vx=*/%v69003 (stack43)
        %v69016 = vadd.s32 %v69011, %v10 (stack39)
        %v69020 = vadd.s32 %v68981, %v9 (stack39)
        %v69024 = vadd.s32 %v69020, %v69016 (stack39)
        %v69026 = vshll.u32 %v69020, 13 (stack44)
        %v69027 = vshrl.u32 %v69020, 19 (stack45)
        %v69028 = vor.u32 %v69027, %v69026 (stack46)
        %v69029 = vxor.u32 %v69028, %v69024 (stack47)
        %v69032 = vadd.s32 %v69029, %v69024 (stack39)
        %v69034 = vshll.u32 %v69029, 15 (stack44)
        %v69035 = vshrl.u32 %v69029, 17 (stack45)
        %v69036 = vor.u32 %v69035, %v69034 (stack46)
        %v69037 = vxor.u32 %v69036, %v69032 (stack47)
        %v69040 = vadd.s32 %v69037, %v69032 (stack39)
        %v69042 = vshll.u32 %v69037, 26 (stack44)
        %v69043 = vshrl.u32 %v69037, 6 (stack45)
        %v69044 = vor.u32 %v69043, %v69042 (stack46)
        %v69045 = vxor.u32 %v69044, %v69040 (stack47)
        %v69048 = vadd.s32 %v69045, %v69040 (stack39)
        %v69052 = vadd.s32 %v69048, %v9 (stack39)
        %v69054 = vshll.u32 %v69045, 6 (stack44)
        %v69055 = vshrl.u32 %v69045, 26 (stack45)
        %v69056 = vor.u32 %v69055, %v69054 (stack46)
        %v69057 = vxor.u32 %v69056, %v69048 (stack47)
        %v69060 = vadd.s32 %v69057, %v8 (stack39)
        %v69064 = vadd.s32 1, %v69060 (stack39)
        %v69068 = vadd.s32 %v69064, %v69052 (stack39)
        %v69070 = vshll.u32 %v69064, 17 (stack44)
        %v69071 = vshrl.u32 %v69064, 15 (stack45)
        %v69072 = vor.u32 %v69071, %v69070 (stack46)
        %v69073 = vxor.u32 %v69072, %v69068 (stack47)
        %v69076 = vadd.s32 %v69073, %v69068 (stack39)
        %v69078 = vshll.u32 %v69073, 29 (stack44)
        %v69079 = vshrl.u32 %v69073, 3 (stack45)
        %v69080 = vor.u32 %v69079, %v69078 (stack46)
        %v69081 = vxor.u32 %v69080, %v69076 (stack47)
        %v69084 = vadd.s32 %v69081, %v69076 (stack39)
        %v69086 = vshll.u32 %v69081, 16 (stack44)
        %v69087 = vshrl.u32 %v69081, 16 (stack45)
        %v69088 = vor.u32 %v69087, %v69086 (stack46)
        %v69089 = vxor.u32 %v69088, %v69084 (stack47)
        %v69092 = vadd.s32 %v69089, %v69084 (stack39)
        %v69096 = vadd.s32 %v69092, %v8 (stack39)
        %v69098 = vshll.u32 %v69089, 24 (stack44)
        %v69099 = vshrl.u32 %v69089, 8 (stack45)
        %v69100 = vor.u32 %v69099, %v69098 (stack46)
        %v69101 = vxor.u32 %v69100, %v69092 (stack47)
        %v69104 = vadd.s32 %v69101, %v10 (stack39)
        %v69108 = vadd.s32 2, %v69104 (stack39)
        %v69112 = vadd.s32 %v69108, %v69096 (stack39)
        %v69114 = vshll.u32 %v69108, 13 (stack44)
        %v69115 = vshrl.u32 %v69108, 19 (stack45)
        %v69116 = vor.u32 %v69115, %v69114 (stack46)
        %v69117 = vxor.u32 %v69116, %v69112 (stack47)
        %v69120 = vadd.s32 %v69117, %v69112 (stack39)
        %v69122 = vshll.u32 %v69117, 15 (stack44)
        %v69123 = vshrl.u32 %v69117, 17 (stack45)
        %v69124 = vor.u32 %v69123, %v69122 (stack46)
        %v69125 = vxor.u32 %v69124, %v69120 (stack47)
        %v69128 = vadd.s32 %v69125, %v69120 (stack39)
        %v69130 = vshll.u32 %v69125, 26 (stack44)
        %v69131 = vshrl.u32 %v69125, 6 (stack45)
        %v69132 = vor.u32 %v69131, %v69130 (stack46)
        %v69133 = vxor.u32 %v69132, %v69128 (stack47)
        %v69136 = vadd.s32 %v69133, %v69128 (stack39)
        %v69140 = vadd.s32 %v69136, %v10 (stack39)
        %v69142 = vshll.u32 %v69133, 6 (stack44)
        %v69143 = vshrl.u32 %v69133, 26 (stack45)
        %v69144 = vor.u32 %v69143, %v69142 (stack46)
        %v69145 = vxor.u32 %v69144, %v69136 (stack47)
        %v69148 = vadd.s32 %v69145, %v9 (stack39)
        %v69152 = vadd.s32 3, %v69148 (stack39)
        %v69156 = vadd.s32 %v69152, %v69140 (stack39)
        %v69158 = vshll.u32 %v69152, 17 (stack44)
        %v69159 = vshrl.u32 %v69152, 15 (stack45)
        %v69160 = vor.u32 %v69159, %v69158 (stack46)
        %v69161 = vxor.u32 %v69160, %v69156 (stack47)
        %v69164 = vadd.s32 %v69161, %v69156 (stack39)
        %v69166 = vshll.u32 %v69161, 29 (stack44)
        %v69167 = vshrl.u32 %v69161, 3 (stack45)
        %v69168 = vor.u32 %v69167, %v69166 (stack46)
        %v69169 = vxor.u32 %v69168, %v69164 (stack47)
        %v69172 = vadd.s32 %v69169, %v69164 (stack39)
        %v69174 = vshll.u32 %v69169, 16 (stack44)
        %v69175 = vshrl.u32 %v69169, 16 (stack45)
        %v69176 = vor.u32 %v69175, %v69174 (stack46)
        %v69177 = vxor.u32 %v69176, %v69172 (stack47)
        %v69180 = vadd.s32 %v69177, %v69172 (stack39)
        %v69184 = vadd.s32 %v69180, %v9 (stack39)
        %v69186 = vshll.u32 %v69177, 24 (stack44)
        %v69187 = vshrl.u32 %v69177, 8 (stack45)
        %v69188 = vor.u32 %v69187, %v69186 (stack46)
        %v69189 = vxor.u32 %v69188, %v69180 (stack47)
        %v69192 = vadd.s32 %v69189, %v8 (stack39)
        %v69196 = vadd.s32 4, %v69192 (stack39)
        %v69200 = vadd.s32 %v69196, %v69184 (stack39)
        %v69202 = vshll.u32 %v69196, 13 (stack44)
        %v69203 = vshrl.u32 %v69196, 19 (stack45)
        %v69204 = vor.u32 %v69203, %v69202 (stack46)
        %v69205 = vxor.u32 %v69204, %v69200 (stack47)
        %v69208 = vadd.s32 %v69205, %v69200 (stack39)
        %v69210 = vshll.u32 %v69205, 15 (stack44)
        %v69211 = vshrl.u32 %v69205, 17 (stack45)
        %v69212 = vor.u32 %v69211, %v69210 (stack46)
        %v69213 = vxor.u32 %v69212, %v69208 (stack47)
        %v69216 = vadd.s32 %v69213, %v69208 (stack39)
        %v69218 = vshll.u32 %v69213, 26 (stack44)
        %v69219 = vshrl.u32 %v69213, 6 (stack45)
        %v69220 = vor.u32 %v69219, %v69218 (stack46)
        %v69221 = vxor.u32 %v69220, %v69216 (stack47)
        %v69224 = vadd.s32 %v69221, %v69216 (stack39)
        %v69228 = vadd.s32 %v69224, %v8 (stack39)
        %v69230 = vshll.u32 %v69221, 6 (stack44)
        %v69231 = vshrl.u32 %v69221, 26 (stack45)
        %v69232 = vor.u32 %v69231, %v69230 (stack46)
        %v69233 = vxor.u32 %v69232, %v69224 (stack47)
        %v69236 = vadd.s32 %v69233, %v10 (stack39)
        %v69240 = vadd.s32 5, %v69236 (stack39)
        %v69242 = vxor.u32 %v69240, %v69228 (stack47)
        %v69243 = vand.u32.u8 255, %v69242 (stack48)
        %v69244 = vand.u32 65535, %v69243 (stack49)
        %v69245 = vshrl.u32 %v69244, 1 (stack50)
        %v69246 = vor.u32 16256, %v69245 (stack46)
        %v69247 = vand.u32.u16 65535, %v69246 (stack51)
        %v120114 = vadd.low.f32.bf16 -1.0, %v69247 (stack52)
        %v69256 = vmul.f32 2.0, %v120114 (stack53)
        %v69260 = vadd.f32 -0.99609375, %v69256 (stack52)
        %v69264 = vmax.f32 %v69260, -0.99609375 (stack54)
        %v69266 = vand.u32 2147483647, %v69264 (stack55)
        %vm69269 = vcmp.eq.f32.partialorder %v69266, 1.0 (stack56)
        %v69274 = vmul.f32 inf, %v69264 (stack53)
        %v69276 = vxor.u32 2147483648, %v69264 (stack57)
        %v69279 = vmul.f32 %v69276, %v69264 (stack53)
        %v69281 = vadd.f32 1.0, %v69279 (stack58)
        %v69282 = vlog2.pop %v69281 (stack59)
        %v69283 = vmul.f32 0.6931472, %v69282 (stack60)
        %v69284 = vmul.f32 -0.5, %v69279 (stack61)
        %v69285 = vadd.f32 1.0, %v69284 (stack62)
        %v69286 = vmul.f32 %v69285, %v69279 (stack63)
        %v69287 = vand.u32 2147483647, %v69279 (stack64)
        %vm69288 = vcmp.lt.f32.partialorder %v69287, 0.0004427343 (stack65)
        %v69289 = vsel /*vm=*/%vm69288, /*on_true_vy=*/%v69286, /*on_false_vx=*/%v69283 (stack66)
        %v69290 = vxor.u32 2147483648, %v69289 (stack57)
        %vm69293 = vcmp.lt.f32.partialorder %v69290, 5.0 (stack56)
        %v69298 = vsel /*vm=*/%vm69293, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v69302 = vsel /*vm=*/%vm69293, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v69306 = vsel /*vm=*/%vm69293, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v69310 = vsel /*vm=*/%vm69293, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v69314 = vsel /*vm=*/%vm69293, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v69318 = vsel /*vm=*/%vm69293, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v69322 = vsel /*vm=*/%vm69293, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v69326 = vsel /*vm=*/%vm69293, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v69330 = vsel /*vm=*/%vm69293, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v69334 = vadd.f32 -2.5, %v69290 (stack52)
        %v69336 = vrsqrt.pop %v69290 (stack67)
        %v69337 = vmul.f32 %v69336, %v69290 (stack68)
        %vm69338 = vcmp.eq.f32.partialorder %v69290, inf (stack69)
        %v69339 = vsel /*vm=*/%vm69338, /*on_true_vy=*/%v69290, /*on_false_vx=*/%v69337 (stack70)
        %vm69340 = vcmp.eq.f32.partialorder %v69290, 0.0 (stack71)
        %v69341 = vand.u32 2147483648, %v69290 (stack72)
        %v69342 = vsel /*vm=*/%vm69340, /*on_true_vy=*/%v69341, /*on_false_vx=*/%v69339 (stack73)
        %v69345 = vadd.f32 -3.0, %v69342 (stack52)
        %v69349 = vsel /*vm=*/%vm69293, /*on_true_vy=*/%v69334, /*on_false_vx=*/%v69345 (stack43)
        %v69353 = vmul.f32 %v69349, %v69330 (stack53)
        %v69357 = vadd.f32 %v69353, %v69326 (stack52)
        %v69361 = vmul.f32 %v69357, %v69349 (stack53)
        %v69365 = vadd.f32 %v69361, %v69322 (stack52)
        %v69369 = vmul.f32 %v69365, %v69349 (stack53)
        %v69373 = vadd.f32 %v69369, %v69318 (stack52)
        %v69377 = vmul.f32 %v69373, %v69349 (stack53)
        %v69381 = vadd.f32 %v69377, %v69314 (stack52)
        %v69385 = vmul.f32 %v69381, %v69349 (stack53)
        %v69389 = vadd.f32 %v69385, %v69310 (stack52)
        %v69393 = vmul.f32 %v69389, %v69349 (stack53)
        %v69397 = vadd.f32 %v69393, %v69306 (stack52)
        %v69401 = vmul.f32 %v69397, %v69349 (stack53)
        %v69405 = vadd.f32 %v69401, %v69302 (stack52)
        %v69409 = vmul.f32 %v69405, %v69349 (stack53)
        %v69413 = vadd.f32 %v69409, %v69298 (stack52)
        %v69417 = vmul.f32 %v69413, %v69264 (stack53)
        %v69421 = vsel /*vm=*/%vm69269, /*on_true_vy=*/%v69274, /*on_false_vx=*/%v69417 (stack43)
        %v69425 = vmul.f32 1.4140625, %v69421 (stack53)
        %v69428 = vpack.c.bf16 0.0, %v69425 (stack74)
        %120115 = vst [vmem:[%s280 + $0x1c8] sm:$0xf] /*vst_source=*/%v69428 (stack75)
        %v69432 = vadd.s32 %v67585, %v2355 (stack39)
        %v69442 = vadd.s32 %v69432, %v415 (stack39)
        %vm69446 = vcmp.lt.u32.totalorder %v69442, %v69432 (stack42)
        %vm69451 = vcmp.lt.u32.totalorder %v69432, %v2355 (stack42)
        %v69456 = vadd.s32 %v67568, %v2342 (stack39)
        %v69460 = vadd.s32 1, %v69456 (stack39)
        %v69464 = vsel /*vm=*/%vm69451, /*on_true_vy=*/%v69460, /*on_false_vx=*/%v69456 (stack43)
        %v69468 = vadd.s32 1, %v69464 (stack39)
        %v69472 = vsel /*vm=*/%vm69446, /*on_true_vy=*/%v69468, /*on_false_vx=*/%v69464 (stack43)
        %v69477 = vadd.s32 %v69472, %v10 (stack39)
        %v69481 = vadd.s32 %v69442, %v9 (stack39)
        %v69485 = vadd.s32 %v69481, %v69477 (stack39)
        %v69487 = vshll.u32 %v69481, 13 (stack44)
        %v69488 = vshrl.u32 %v69481, 19 (stack45)
        %v69489 = vor.u32 %v69488, %v69487 (stack46)
        %v69490 = vxor.u32 %v69489, %v69485 (stack47)
        %v69493 = vadd.s32 %v69490, %v69485 (stack39)
        %v69495 = vshll.u32 %v69490, 15 (stack44)
        %v69496 = vshrl.u32 %v69490, 17 (stack45)
        %v69497 = vor.u32 %v69496, %v69495 (stack46)
        %v69498 = vxor.u32 %v69497, %v69493 (stack47)
        %v69501 = vadd.s32 %v69498, %v69493 (stack39)
        %v69503 = vshll.u32 %v69498, 26 (stack44)
        %v69504 = vshrl.u32 %v69498, 6 (stack45)
        %v69505 = vor.u32 %v69504, %v69503 (stack46)
        %v69506 = vxor.u32 %v69505, %v69501 (stack47)
        %v69509 = vadd.s32 %v69506, %v69501 (stack39)
        %v69513 = vadd.s32 %v69509, %v9 (stack39)
        %v69515 = vshll.u32 %v69506, 6 (stack44)
        %v69516 = vshrl.u32 %v69506, 26 (stack45)
        %v69517 = vor.u32 %v69516, %v69515 (stack46)
        %v69518 = vxor.u32 %v69517, %v69509 (stack47)
        %v69521 = vadd.s32 %v69518, %v8 (stack39)
        %v69525 = vadd.s32 1, %v69521 (stack39)
        %v69529 = vadd.s32 %v69525, %v69513 (stack39)
        %v69531 = vshll.u32 %v69525, 17 (stack44)
        %v69532 = vshrl.u32 %v69525, 15 (stack45)
        %v69533 = vor.u32 %v69532, %v69531 (stack46)
        %v69534 = vxor.u32 %v69533, %v69529 (stack47)
        %v69537 = vadd.s32 %v69534, %v69529 (stack39)
        %v69539 = vshll.u32 %v69534, 29 (stack44)
        %v69540 = vshrl.u32 %v69534, 3 (stack45)
        %v69541 = vor.u32 %v69540, %v69539 (stack46)
        %v69542 = vxor.u32 %v69541, %v69537 (stack47)
        %v69545 = vadd.s32 %v69542, %v69537 (stack39)
        %v69547 = vshll.u32 %v69542, 16 (stack44)
        %v69548 = vshrl.u32 %v69542, 16 (stack45)
        %v69549 = vor.u32 %v69548, %v69547 (stack46)
        %v69550 = vxor.u32 %v69549, %v69545 (stack47)
        %v69553 = vadd.s32 %v69550, %v69545 (stack39)
        %v69557 = vadd.s32 %v69553, %v8 (stack39)
        %v69559 = vshll.u32 %v69550, 24 (stack44)
        %v69560 = vshrl.u32 %v69550, 8 (stack45)
        %v69561 = vor.u32 %v69560, %v69559 (stack46)
        %v69562 = vxor.u32 %v69561, %v69553 (stack47)
        %v69565 = vadd.s32 %v69562, %v10 (stack39)
        %v69569 = vadd.s32 2, %v69565 (stack39)
        %v69573 = vadd.s32 %v69569, %v69557 (stack39)
        %v69575 = vshll.u32 %v69569, 13 (stack44)
        %v69576 = vshrl.u32 %v69569, 19 (stack45)
        %v69577 = vor.u32 %v69576, %v69575 (stack46)
        %v69578 = vxor.u32 %v69577, %v69573 (stack47)
        %v69581 = vadd.s32 %v69578, %v69573 (stack39)
        %v69583 = vshll.u32 %v69578, 15 (stack44)
        %v69584 = vshrl.u32 %v69578, 17 (stack45)
        %v69585 = vor.u32 %v69584, %v69583 (stack46)
        %v69586 = vxor.u32 %v69585, %v69581 (stack47)
        %v69589 = vadd.s32 %v69586, %v69581 (stack39)
        %v69591 = vshll.u32 %v69586, 26 (stack44)
        %v69592 = vshrl.u32 %v69586, 6 (stack45)
        %v69593 = vor.u32 %v69592, %v69591 (stack46)
        %v69594 = vxor.u32 %v69593, %v69589 (stack47)
        %v69597 = vadd.s32 %v69594, %v69589 (stack39)
        %v69601 = vadd.s32 %v69597, %v10 (stack39)
        %v69603 = vshll.u32 %v69594, 6 (stack44)
        %v69604 = vshrl.u32 %v69594, 26 (stack45)
        %v69605 = vor.u32 %v69604, %v69603 (stack46)
        %v69606 = vxor.u32 %v69605, %v69597 (stack47)
        %v69609 = vadd.s32 %v69606, %v9 (stack39)
        %v69613 = vadd.s32 3, %v69609 (stack39)
        %v69617 = vadd.s32 %v69613, %v69601 (stack39)
        %v69619 = vshll.u32 %v69613, 17 (stack44)
        %v69620 = vshrl.u32 %v69613, 15 (stack45)
        %v69621 = vor.u32 %v69620, %v69619 (stack46)
        %v69622 = vxor.u32 %v69621, %v69617 (stack47)
        %v69625 = vadd.s32 %v69622, %v69617 (stack39)
        %v69627 = vshll.u32 %v69622, 29 (stack44)
        %v69628 = vshrl.u32 %v69622, 3 (stack45)
        %v69629 = vor.u32 %v69628, %v69627 (stack46)
        %v69630 = vxor.u32 %v69629, %v69625 (stack47)
        %v69633 = vadd.s32 %v69630, %v69625 (stack39)
        %v69635 = vshll.u32 %v69630, 16 (stack44)
        %v69636 = vshrl.u32 %v69630, 16 (stack45)
        %v69637 = vor.u32 %v69636, %v69635 (stack46)
        %v69638 = vxor.u32 %v69637, %v69633 (stack47)
        %v69641 = vadd.s32 %v69638, %v69633 (stack39)
        %v69645 = vadd.s32 %v69641, %v9 (stack39)
        %v69647 = vshll.u32 %v69638, 24 (stack44)
        %v69648 = vshrl.u32 %v69638, 8 (stack45)
        %v69649 = vor.u32 %v69648, %v69647 (stack46)
        %v69650 = vxor.u32 %v69649, %v69641 (stack47)
        %v69653 = vadd.s32 %v69650, %v8 (stack39)
        %v69657 = vadd.s32 4, %v69653 (stack39)
        %v69661 = vadd.s32 %v69657, %v69645 (stack39)
        %v69663 = vshll.u32 %v69657, 13 (stack44)
        %v69664 = vshrl.u32 %v69657, 19 (stack45)
        %v69665 = vor.u32 %v69664, %v69663 (stack46)
        %v69666 = vxor.u32 %v69665, %v69661 (stack47)
        %v69669 = vadd.s32 %v69666, %v69661 (stack39)
        %v69671 = vshll.u32 %v69666, 15 (stack44)
        %v69672 = vshrl.u32 %v69666, 17 (stack45)
        %v69673 = vor.u32 %v69672, %v69671 (stack46)
        %v69674 = vxor.u32 %v69673, %v69669 (stack47)
        %v69677 = vadd.s32 %v69674, %v69669 (stack39)
        %v69679 = vshll.u32 %v69674, 26 (stack44)
        %v69680 = vshrl.u32 %v69674, 6 (stack45)
        %v69681 = vor.u32 %v69680, %v69679 (stack46)
        %v69682 = vxor.u32 %v69681, %v69677 (stack47)
        %v69685 = vadd.s32 %v69682, %v69677 (stack39)
        %v69689 = vadd.s32 %v69685, %v8 (stack39)
        %v69691 = vshll.u32 %v69682, 6 (stack44)
        %v69692 = vshrl.u32 %v69682, 26 (stack45)
        %v69693 = vor.u32 %v69692, %v69691 (stack46)
        %v69694 = vxor.u32 %v69693, %v69685 (stack47)
        %v69697 = vadd.s32 %v69694, %v10 (stack39)
        %v69701 = vadd.s32 5, %v69697 (stack39)
        %v69703 = vxor.u32 %v69701, %v69689 (stack47)
        %v69704 = vand.u32.u8 255, %v69703 (stack48)
        %v69705 = vand.u32 65535, %v69704 (stack49)
        %v69706 = vshrl.u32 %v69705, 1 (stack50)
        %v69707 = vor.u32 16256, %v69706 (stack46)
        %v69708 = vand.u32.u16 65535, %v69707 (stack51)
        %v120116 = vadd.low.f32.bf16 -1.0, %v69708 (stack52)
        %v69717 = vmul.f32 2.0, %v120116 (stack53)
        %v69721 = vadd.f32 -0.99609375, %v69717 (stack52)
        %v69725 = vmax.f32 %v69721, -0.99609375 (stack54)
        %v69727 = vand.u32 2147483647, %v69725 (stack55)
        %vm69730 = vcmp.eq.f32.partialorder %v69727, 1.0 (stack56)
        %v69735 = vmul.f32 inf, %v69725 (stack53)
        %v69737 = vxor.u32 2147483648, %v69725 (stack57)
        %v69740 = vmul.f32 %v69737, %v69725 (stack53)
        %v69742 = vadd.f32 1.0, %v69740 (stack58)
        %v69743 = vlog2.pop %v69742 (stack59)
        %v69744 = vmul.f32 0.6931472, %v69743 (stack60)
        %v69745 = vmul.f32 -0.5, %v69740 (stack61)
        %v69746 = vadd.f32 1.0, %v69745 (stack62)
        %v69747 = vmul.f32 %v69746, %v69740 (stack63)
        %v69748 = vand.u32 2147483647, %v69740 (stack64)
        %vm69749 = vcmp.lt.f32.partialorder %v69748, 0.0004427343 (stack65)
        %v69750 = vsel /*vm=*/%vm69749, /*on_true_vy=*/%v69747, /*on_false_vx=*/%v69744 (stack66)
        %v69751 = vxor.u32 2147483648, %v69750 (stack57)
        %vm69754 = vcmp.lt.f32.partialorder %v69751, 5.0 (stack56)
        %v69759 = vsel /*vm=*/%vm69754, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v69763 = vsel /*vm=*/%vm69754, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v69767 = vsel /*vm=*/%vm69754, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v69771 = vsel /*vm=*/%vm69754, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v69775 = vsel /*vm=*/%vm69754, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v69779 = vsel /*vm=*/%vm69754, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v69783 = vsel /*vm=*/%vm69754, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v69787 = vsel /*vm=*/%vm69754, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v69791 = vsel /*vm=*/%vm69754, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v69795 = vadd.f32 -2.5, %v69751 (stack52)
        %v69797 = vrsqrt.pop %v69751 (stack67)
        %v69798 = vmul.f32 %v69797, %v69751 (stack68)
        %vm69799 = vcmp.eq.f32.partialorder %v69751, inf (stack69)
        %v69800 = vsel /*vm=*/%vm69799, /*on_true_vy=*/%v69751, /*on_false_vx=*/%v69798 (stack70)
        %vm69801 = vcmp.eq.f32.partialorder %v69751, 0.0 (stack71)
        %v69802 = vand.u32 2147483648, %v69751 (stack72)
        %v69803 = vsel /*vm=*/%vm69801, /*on_true_vy=*/%v69802, /*on_false_vx=*/%v69800 (stack73)
        %v69806 = vadd.f32 -3.0, %v69803 (stack52)
        %v69810 = vsel /*vm=*/%vm69754, /*on_true_vy=*/%v69795, /*on_false_vx=*/%v69806 (stack43)
        %v69814 = vmul.f32 %v69810, %v69791 (stack53)
        %v69818 = vadd.f32 %v69814, %v69787 (stack52)
        %v69822 = vmul.f32 %v69818, %v69810 (stack53)
        %v69826 = vadd.f32 %v69822, %v69783 (stack52)
        %v69830 = vmul.f32 %v69826, %v69810 (stack53)
        %v69834 = vadd.f32 %v69830, %v69779 (stack52)
        %v69838 = vmul.f32 %v69834, %v69810 (stack53)
        %v69842 = vadd.f32 %v69838, %v69775 (stack52)
        %v69846 = vmul.f32 %v69842, %v69810 (stack53)
        %v69850 = vadd.f32 %v69846, %v69771 (stack52)
        %v69854 = vmul.f32 %v69850, %v69810 (stack53)
        %v69858 = vadd.f32 %v69854, %v69767 (stack52)
        %v69862 = vmul.f32 %v69858, %v69810 (stack53)
        %v69866 = vadd.f32 %v69862, %v69763 (stack52)
        %v69870 = vmul.f32 %v69866, %v69810 (stack53)
        %v69874 = vadd.f32 %v69870, %v69759 (stack52)
        %v69878 = vmul.f32 %v69874, %v69725 (stack53)
        %v69882 = vsel /*vm=*/%vm69730, /*on_true_vy=*/%v69735, /*on_false_vx=*/%v69878 (stack43)
        %v69886 = vmul.f32 1.4140625, %v69882 (stack53)
        %v69889 = vpack.c.bf16 0.0, %v69886 (stack74)
        %120117 = vst [vmem:[%s280 + $0x248] sm:$0xf] /*vst_source=*/%v69889 (stack75)
        %v69893 = vadd.s32 %v67585, %v2842 (stack39)
        %v69903 = vadd.s32 %v69893, %v415 (stack39)
        %vm69907 = vcmp.lt.u32.totalorder %v69903, %v69893 (stack42)
        %vm69912 = vcmp.lt.u32.totalorder %v69893, %v2842 (stack42)
        %v69917 = vadd.s32 %v67568, %v2829 (stack39)
        %v69921 = vadd.s32 1, %v69917 (stack39)
        %v69925 = vsel /*vm=*/%vm69912, /*on_true_vy=*/%v69921, /*on_false_vx=*/%v69917 (stack43)
        %v69929 = vadd.s32 1, %v69925 (stack39)
        %v69933 = vsel /*vm=*/%vm69907, /*on_true_vy=*/%v69929, /*on_false_vx=*/%v69925 (stack43)
        %v69938 = vadd.s32 %v69933, %v10 (stack39)
        %v69942 = vadd.s32 %v69903, %v9 (stack39)
        %v69946 = vadd.s32 %v69942, %v69938 (stack39)
        %v69948 = vshll.u32 %v69942, 13 (stack44)
        %v69949 = vshrl.u32 %v69942, 19 (stack45)
        %v69950 = vor.u32 %v69949, %v69948 (stack46)
        %v69951 = vxor.u32 %v69950, %v69946 (stack47)
        %v69954 = vadd.s32 %v69951, %v69946 (stack39)
        %v69956 = vshll.u32 %v69951, 15 (stack44)
        %v69957 = vshrl.u32 %v69951, 17 (stack45)
        %v69958 = vor.u32 %v69957, %v69956 (stack46)
        %v69959 = vxor.u32 %v69958, %v69954 (stack47)
        %v69962 = vadd.s32 %v69959, %v69954 (stack39)
        %v69964 = vshll.u32 %v69959, 26 (stack44)
        %v69965 = vshrl.u32 %v69959, 6 (stack45)
        %v69966 = vor.u32 %v69965, %v69964 (stack46)
        %v69967 = vxor.u32 %v69966, %v69962 (stack47)
        %v69970 = vadd.s32 %v69967, %v69962 (stack39)
        %v69974 = vadd.s32 %v69970, %v9 (stack39)
        %v69976 = vshll.u32 %v69967, 6 (stack44)
        %v69977 = vshrl.u32 %v69967, 26 (stack45)
        %v69978 = vor.u32 %v69977, %v69976 (stack46)
        %v69979 = vxor.u32 %v69978, %v69970 (stack47)
        %v69982 = vadd.s32 %v69979, %v8 (stack39)
        %v69986 = vadd.s32 1, %v69982 (stack39)
        %v69990 = vadd.s32 %v69986, %v69974 (stack39)
        %v69992 = vshll.u32 %v69986, 17 (stack44)
        %v69993 = vshrl.u32 %v69986, 15 (stack45)
        %v69994 = vor.u32 %v69993, %v69992 (stack46)
        %v69995 = vxor.u32 %v69994, %v69990 (stack47)
        %v69998 = vadd.s32 %v69995, %v69990 (stack39)
        %v70000 = vshll.u32 %v69995, 29 (stack44)
        %v70001 = vshrl.u32 %v69995, 3 (stack45)
        %v70002 = vor.u32 %v70001, %v70000 (stack46)
        %v70003 = vxor.u32 %v70002, %v69998 (stack47)
        %v70006 = vadd.s32 %v70003, %v69998 (stack39)
        %v70008 = vshll.u32 %v70003, 16 (stack44)
        %v70009 = vshrl.u32 %v70003, 16 (stack45)
        %v70010 = vor.u32 %v70009, %v70008 (stack46)
        %v70011 = vxor.u32 %v70010, %v70006 (stack47)
        %v70014 = vadd.s32 %v70011, %v70006 (stack39)
        %v70018 = vadd.s32 %v70014, %v8 (stack39)
        %v70020 = vshll.u32 %v70011, 24 (stack44)
        %v70021 = vshrl.u32 %v70011, 8 (stack45)
        %v70022 = vor.u32 %v70021, %v70020 (stack46)
        %v70023 = vxor.u32 %v70022, %v70014 (stack47)
        %v70026 = vadd.s32 %v70023, %v10 (stack39)
        %v70030 = vadd.s32 2, %v70026 (stack39)
        %v70034 = vadd.s32 %v70030, %v70018 (stack39)
        %v70036 = vshll.u32 %v70030, 13 (stack44)
        %v70037 = vshrl.u32 %v70030, 19 (stack45)
        %v70038 = vor.u32 %v70037, %v70036 (stack46)
        %v70039 = vxor.u32 %v70038, %v70034 (stack47)
        %v70042 = vadd.s32 %v70039, %v70034 (stack39)
        %v70044 = vshll.u32 %v70039, 15 (stack44)
        %v70045 = vshrl.u32 %v70039, 17 (stack45)
        %v70046 = vor.u32 %v70045, %v70044 (stack46)
        %v70047 = vxor.u32 %v70046, %v70042 (stack47)
        %v70050 = vadd.s32 %v70047, %v70042 (stack39)
        %v70052 = vshll.u32 %v70047, 26 (stack44)
        %v70053 = vshrl.u32 %v70047, 6 (stack45)
        %v70054 = vor.u32 %v70053, %v70052 (stack46)
        %v70055 = vxor.u32 %v70054, %v70050 (stack47)
        %v70058 = vadd.s32 %v70055, %v70050 (stack39)
        %v70062 = vadd.s32 %v70058, %v10 (stack39)
        %v70064 = vshll.u32 %v70055, 6 (stack44)
        %v70065 = vshrl.u32 %v70055, 26 (stack45)
        %v70066 = vor.u32 %v70065, %v70064 (stack46)
        %v70067 = vxor.u32 %v70066, %v70058 (stack47)
        %v70070 = vadd.s32 %v70067, %v9 (stack39)
        %v70074 = vadd.s32 3, %v70070 (stack39)
        %v70078 = vadd.s32 %v70074, %v70062 (stack39)
        %v70080 = vshll.u32 %v70074, 17 (stack44)
        %v70081 = vshrl.u32 %v70074, 15 (stack45)
        %v70082 = vor.u32 %v70081, %v70080 (stack46)
        %v70083 = vxor.u32 %v70082, %v70078 (stack47)
        %v70086 = vadd.s32 %v70083, %v70078 (stack39)
        %v70088 = vshll.u32 %v70083, 29 (stack44)
        %v70089 = vshrl.u32 %v70083, 3 (stack45)
        %v70090 = vor.u32 %v70089, %v70088 (stack46)
        %v70091 = vxor.u32 %v70090, %v70086 (stack47)
        %v70094 = vadd.s32 %v70091, %v70086 (stack39)
        %v70096 = vshll.u32 %v70091, 16 (stack44)
        %v70097 = vshrl.u32 %v70091, 16 (stack45)
        %v70098 = vor.u32 %v70097, %v70096 (stack46)
        %v70099 = vxor.u32 %v70098, %v70094 (stack47)
        %v70102 = vadd.s32 %v70099, %v70094 (stack39)
        %v70106 = vadd.s32 %v70102, %v9 (stack39)
        %v70108 = vshll.u32 %v70099, 24 (stack44)
        %v70109 = vshrl.u32 %v70099, 8 (stack45)
        %v70110 = vor.u32 %v70109, %v70108 (stack46)
        %v70111 = vxor.u32 %v70110, %v70102 (stack47)
        %v70114 = vadd.s32 %v70111, %v8 (stack39)
        %v70118 = vadd.s32 4, %v70114 (stack39)
        %v70122 = vadd.s32 %v70118, %v70106 (stack39)
        %v70124 = vshll.u32 %v70118, 13 (stack44)
        %v70125 = vshrl.u32 %v70118, 19 (stack45)
        %v70126 = vor.u32 %v70125, %v70124 (stack46)
        %v70127 = vxor.u32 %v70126, %v70122 (stack47)
        %v70130 = vadd.s32 %v70127, %v70122 (stack39)
        %v70132 = vshll.u32 %v70127, 15 (stack44)
        %v70133 = vshrl.u32 %v70127, 17 (stack45)
        %v70134 = vor.u32 %v70133, %v70132 (stack46)
        %v70135 = vxor.u32 %v70134, %v70130 (stack47)
        %v70138 = vadd.s32 %v70135, %v70130 (stack39)
        %v70140 = vshll.u32 %v70135, 26 (stack44)
        %v70141 = vshrl.u32 %v70135, 6 (stack45)
        %v70142 = vor.u32 %v70141, %v70140 (stack46)
        %v70143 = vxor.u32 %v70142, %v70138 (stack47)
        %v70146 = vadd.s32 %v70143, %v70138 (stack39)
        %v70150 = vadd.s32 %v70146, %v8 (stack39)
        %v70152 = vshll.u32 %v70143, 6 (stack44)
        %v70153 = vshrl.u32 %v70143, 26 (stack45)
        %v70154 = vor.u32 %v70153, %v70152 (stack46)
        %v70155 = vxor.u32 %v70154, %v70146 (stack47)
        %v70158 = vadd.s32 %v70155, %v10 (stack39)
        %v70162 = vadd.s32 5, %v70158 (stack39)
        %v70164 = vxor.u32 %v70162, %v70150 (stack47)
        %v70165 = vand.u32.u8 255, %v70164 (stack48)
        %v70166 = vand.u32 65535, %v70165 (stack49)
        %v70167 = vshrl.u32 %v70166, 1 (stack50)
        %v70168 = vor.u32 16256, %v70167 (stack46)
        %v70169 = vand.u32.u16 65535, %v70168 (stack51)
        %v120118 = vadd.low.f32.bf16 -1.0, %v70169 (stack52)
        %v70178 = vmul.f32 2.0, %v120118 (stack53)
        %v70182 = vadd.f32 -0.99609375, %v70178 (stack52)
        %v70186 = vmax.f32 %v70182, -0.99609375 (stack54)
        %v70188 = vand.u32 2147483647, %v70186 (stack55)
        %vm70191 = vcmp.eq.f32.partialorder %v70188, 1.0 (stack56)
        %v70196 = vmul.f32 inf, %v70186 (stack53)
        %v70198 = vxor.u32 2147483648, %v70186 (stack57)
        %v70201 = vmul.f32 %v70198, %v70186 (stack53)
        %v70203 = vadd.f32 1.0, %v70201 (stack58)
        %v70204 = vlog2.pop %v70203 (stack59)
        %v70205 = vmul.f32 0.6931472, %v70204 (stack60)
        %v70206 = vmul.f32 -0.5, %v70201 (stack61)
        %v70207 = vadd.f32 1.0, %v70206 (stack62)
        %v70208 = vmul.f32 %v70207, %v70201 (stack63)
        %v70209 = vand.u32 2147483647, %v70201 (stack64)
        %vm70210 = vcmp.lt.f32.partialorder %v70209, 0.0004427343 (stack65)
        %v70211 = vsel /*vm=*/%vm70210, /*on_true_vy=*/%v70208, /*on_false_vx=*/%v70205 (stack66)
        %v70212 = vxor.u32 2147483648, %v70211 (stack57)
        %vm70215 = vcmp.lt.f32.partialorder %v70212, 5.0 (stack56)
        %v70220 = vsel /*vm=*/%vm70215, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v70224 = vsel /*vm=*/%vm70215, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v70228 = vsel /*vm=*/%vm70215, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v70232 = vsel /*vm=*/%vm70215, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v70236 = vsel /*vm=*/%vm70215, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v70240 = vsel /*vm=*/%vm70215, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v70244 = vsel /*vm=*/%vm70215, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v70248 = vsel /*vm=*/%vm70215, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v70252 = vsel /*vm=*/%vm70215, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v70256 = vadd.f32 -2.5, %v70212 (stack52)
        %v70258 = vrsqrt.pop %v70212 (stack67)
        %v70259 = vmul.f32 %v70258, %v70212 (stack68)
        %vm70260 = vcmp.eq.f32.partialorder %v70212, inf (stack69)
        %v70261 = vsel /*vm=*/%vm70260, /*on_true_vy=*/%v70212, /*on_false_vx=*/%v70259 (stack70)
        %vm70262 = vcmp.eq.f32.partialorder %v70212, 0.0 (stack71)
        %v70263 = vand.u32 2147483648, %v70212 (stack72)
        %v70264 = vsel /*vm=*/%vm70262, /*on_true_vy=*/%v70263, /*on_false_vx=*/%v70261 (stack73)
        %v70267 = vadd.f32 -3.0, %v70264 (stack52)
        %v70271 = vsel /*vm=*/%vm70215, /*on_true_vy=*/%v70256, /*on_false_vx=*/%v70267 (stack43)
        %v70275 = vmul.f32 %v70271, %v70252 (stack53)
        %v70279 = vadd.f32 %v70275, %v70248 (stack52)
        %v70283 = vmul.f32 %v70279, %v70271 (stack53)
        %v70287 = vadd.f32 %v70283, %v70244 (stack52)
        %v70291 = vmul.f32 %v70287, %v70271 (stack53)
        %v70295 = vadd.f32 %v70291, %v70240 (stack52)
        %v70299 = vmul.f32 %v70295, %v70271 (stack53)
        %v70303 = vadd.f32 %v70299, %v70236 (stack52)
        %v70307 = vmul.f32 %v70303, %v70271 (stack53)
        %v70311 = vadd.f32 %v70307, %v70232 (stack52)
        %v70315 = vmul.f32 %v70311, %v70271 (stack53)
        %v70319 = vadd.f32 %v70315, %v70228 (stack52)
        %v70323 = vmul.f32 %v70319, %v70271 (stack53)
        %v70327 = vadd.f32 %v70323, %v70224 (stack52)
        %v70331 = vmul.f32 %v70327, %v70271 (stack53)
        %v70335 = vadd.f32 %v70331, %v70220 (stack52)
        %v70339 = vmul.f32 %v70335, %v70186 (stack53)
        %v70343 = vsel /*vm=*/%vm70191, /*on_true_vy=*/%v70196, /*on_false_vx=*/%v70339 (stack43)
        %v70347 = vmul.f32 1.4140625, %v70343 (stack53)
        %v70350 = vpack.c.bf16 0.0, %v70347 (stack74)
        %120119 = vst [vmem:[%s280 + $0x2c8] sm:$0xf] /*vst_source=*/%v70350 (stack75)
        %v70354 = vadd.s32 %v67585, %v3329 (stack39)
        %v70364 = vadd.s32 %v70354, %v415 (stack39)
        %vm70368 = vcmp.lt.u32.totalorder %v70364, %v70354 (stack42)
        %vm70373 = vcmp.lt.u32.totalorder %v70354, %v3329 (stack42)
        %v70378 = vadd.s32 %v67568, %v3316 (stack39)
        %v70382 = vadd.s32 1, %v70378 (stack39)
        %v70386 = vsel /*vm=*/%vm70373, /*on_true_vy=*/%v70382, /*on_false_vx=*/%v70378 (stack43)
        %v70390 = vadd.s32 1, %v70386 (stack39)
        %v70394 = vsel /*vm=*/%vm70368, /*on_true_vy=*/%v70390, /*on_false_vx=*/%v70386 (stack43)
        %v70399 = vadd.s32 %v70394, %v10 (stack39)
        %v70403 = vadd.s32 %v70364, %v9 (stack39)
        %v70407 = vadd.s32 %v70403, %v70399 (stack39)
        %v70409 = vshll.u32 %v70403, 13 (stack44)
        %v70410 = vshrl.u32 %v70403, 19 (stack45)
        %v70411 = vor.u32 %v70410, %v70409 (stack46)
        %v70412 = vxor.u32 %v70411, %v70407 (stack47)
        %v70415 = vadd.s32 %v70412, %v70407 (stack39)
        %v70417 = vshll.u32 %v70412, 15 (stack44)
        %v70418 = vshrl.u32 %v70412, 17 (stack45)
        %v70419 = vor.u32 %v70418, %v70417 (stack46)
        %v70420 = vxor.u32 %v70419, %v70415 (stack47)
        %v70423 = vadd.s32 %v70420, %v70415 (stack39)
        %v70425 = vshll.u32 %v70420, 26 (stack44)
        %v70426 = vshrl.u32 %v70420, 6 (stack45)
        %v70427 = vor.u32 %v70426, %v70425 (stack46)
        %v70428 = vxor.u32 %v70427, %v70423 (stack47)
        %v70431 = vadd.s32 %v70428, %v70423 (stack39)
        %v70435 = vadd.s32 %v70431, %v9 (stack39)
        %v70437 = vshll.u32 %v70428, 6 (stack44)
        %v70438 = vshrl.u32 %v70428, 26 (stack45)
        %v70439 = vor.u32 %v70438, %v70437 (stack46)
        %v70440 = vxor.u32 %v70439, %v70431 (stack47)
        %v70443 = vadd.s32 %v70440, %v8 (stack39)
        %v70447 = vadd.s32 1, %v70443 (stack39)
        %v70451 = vadd.s32 %v70447, %v70435 (stack39)
        %v70453 = vshll.u32 %v70447, 17 (stack44)
        %v70454 = vshrl.u32 %v70447, 15 (stack45)
        %v70455 = vor.u32 %v70454, %v70453 (stack46)
        %v70456 = vxor.u32 %v70455, %v70451 (stack47)
        %v70459 = vadd.s32 %v70456, %v70451 (stack39)
        %v70461 = vshll.u32 %v70456, 29 (stack44)
        %v70462 = vshrl.u32 %v70456, 3 (stack45)
        %v70463 = vor.u32 %v70462, %v70461 (stack46)
        %v70464 = vxor.u32 %v70463, %v70459 (stack47)
        %v70467 = vadd.s32 %v70464, %v70459 (stack39)
        %v70469 = vshll.u32 %v70464, 16 (stack44)
        %v70470 = vshrl.u32 %v70464, 16 (stack45)
        %v70471 = vor.u32 %v70470, %v70469 (stack46)
        %v70472 = vxor.u32 %v70471, %v70467 (stack47)
        %v70475 = vadd.s32 %v70472, %v70467 (stack39)
        %v70479 = vadd.s32 %v70475, %v8 (stack39)
        %v70481 = vshll.u32 %v70472, 24 (stack44)
        %v70482 = vshrl.u32 %v70472, 8 (stack45)
        %v70483 = vor.u32 %v70482, %v70481 (stack46)
        %v70484 = vxor.u32 %v70483, %v70475 (stack47)
        %v70487 = vadd.s32 %v70484, %v10 (stack39)
        %v70491 = vadd.s32 2, %v70487 (stack39)
        %v70495 = vadd.s32 %v70491, %v70479 (stack39)
        %v70497 = vshll.u32 %v70491, 13 (stack44)
        %v70498 = vshrl.u32 %v70491, 19 (stack45)
        %v70499 = vor.u32 %v70498, %v70497 (stack46)
        %v70500 = vxor.u32 %v70499, %v70495 (stack47)
        %v70503 = vadd.s32 %v70500, %v70495 (stack39)
        %v70505 = vshll.u32 %v70500, 15 (stack44)
        %v70506 = vshrl.u32 %v70500, 17 (stack45)
        %v70507 = vor.u32 %v70506, %v70505 (stack46)
        %v70508 = vxor.u32 %v70507, %v70503 (stack47)
        %v70511 = vadd.s32 %v70508, %v70503 (stack39)
        %v70513 = vshll.u32 %v70508, 26 (stack44)
        %v70514 = vshrl.u32 %v70508, 6 (stack45)
        %v70515 = vor.u32 %v70514, %v70513 (stack46)
        %v70516 = vxor.u32 %v70515, %v70511 (stack47)
        %v70519 = vadd.s32 %v70516, %v70511 (stack39)
        %v70523 = vadd.s32 %v70519, %v10 (stack39)
        %v70525 = vshll.u32 %v70516, 6 (stack44)
        %v70526 = vshrl.u32 %v70516, 26 (stack45)
        %v70527 = vor.u32 %v70526, %v70525 (stack46)
        %v70528 = vxor.u32 %v70527, %v70519 (stack47)
        %v70531 = vadd.s32 %v70528, %v9 (stack39)
        %v70535 = vadd.s32 3, %v70531 (stack39)
        %v70539 = vadd.s32 %v70535, %v70523 (stack39)
        %v70541 = vshll.u32 %v70535, 17 (stack44)
        %v70542 = vshrl.u32 %v70535, 15 (stack45)
        %v70543 = vor.u32 %v70542, %v70541 (stack46)
        %v70544 = vxor.u32 %v70543, %v70539 (stack47)
        %v70547 = vadd.s32 %v70544, %v70539 (stack39)
        %v70549 = vshll.u32 %v70544, 29 (stack44)
        %v70550 = vshrl.u32 %v70544, 3 (stack45)
        %v70551 = vor.u32 %v70550, %v70549 (stack46)
        %v70552 = vxor.u32 %v70551, %v70547 (stack47)
        %v70555 = vadd.s32 %v70552, %v70547 (stack39)
        %v70557 = vshll.u32 %v70552, 16 (stack44)
        %v70558 = vshrl.u32 %v70552, 16 (stack45)
        %v70559 = vor.u32 %v70558, %v70557 (stack46)
        %v70560 = vxor.u32 %v70559, %v70555 (stack47)
        %v70563 = vadd.s32 %v70560, %v70555 (stack39)
        %v70567 = vadd.s32 %v70563, %v9 (stack39)
        %v70569 = vshll.u32 %v70560, 24 (stack44)
        %v70570 = vshrl.u32 %v70560, 8 (stack45)
        %v70571 = vor.u32 %v70570, %v70569 (stack46)
        %v70572 = vxor.u32 %v70571, %v70563 (stack47)
        %v70575 = vadd.s32 %v70572, %v8 (stack39)
        %v70579 = vadd.s32 4, %v70575 (stack39)
        %v70583 = vadd.s32 %v70579, %v70567 (stack39)
        %v70585 = vshll.u32 %v70579, 13 (stack44)
        %v70586 = vshrl.u32 %v70579, 19 (stack45)
        %v70587 = vor.u32 %v70586, %v70585 (stack46)
        %v70588 = vxor.u32 %v70587, %v70583 (stack47)
        %v70591 = vadd.s32 %v70588, %v70583 (stack39)
        %v70593 = vshll.u32 %v70588, 15 (stack44)
        %v70594 = vshrl.u32 %v70588, 17 (stack45)
        %v70595 = vor.u32 %v70594, %v70593 (stack46)
        %v70596 = vxor.u32 %v70595, %v70591 (stack47)
        %v70599 = vadd.s32 %v70596, %v70591 (stack39)
        %v70601 = vshll.u32 %v70596, 26 (stack44)
        %v70602 = vshrl.u32 %v70596, 6 (stack45)
        %v70603 = vor.u32 %v70602, %v70601 (stack46)
        %v70604 = vxor.u32 %v70603, %v70599 (stack47)
        %v70607 = vadd.s32 %v70604, %v70599 (stack39)
        %v70611 = vadd.s32 %v70607, %v8 (stack39)
        %v70613 = vshll.u32 %v70604, 6 (stack44)
        %v70614 = vshrl.u32 %v70604, 26 (stack45)
        %v70615 = vor.u32 %v70614, %v70613 (stack46)
        %v70616 = vxor.u32 %v70615, %v70607 (stack47)
        %v70619 = vadd.s32 %v70616, %v10 (stack39)
        %v70623 = vadd.s32 5, %v70619 (stack39)
        %v70625 = vxor.u32 %v70623, %v70611 (stack47)
        %v70626 = vand.u32.u8 255, %v70625 (stack48)
        %v70627 = vand.u32 65535, %v70626 (stack49)
        %v70628 = vshrl.u32 %v70627, 1 (stack50)
        %v70629 = vor.u32 16256, %v70628 (stack46)
        %v70630 = vand.u32.u16 65535, %v70629 (stack51)
        %v120120 = vadd.low.f32.bf16 -1.0, %v70630 (stack52)
        %v70639 = vmul.f32 2.0, %v120120 (stack53)
        %v70643 = vadd.f32 -0.99609375, %v70639 (stack52)
        %v70647 = vmax.f32 %v70643, -0.99609375 (stack54)
        %v70649 = vand.u32 2147483647, %v70647 (stack55)
        %vm70652 = vcmp.eq.f32.partialorder %v70649, 1.0 (stack56)
        %v70657 = vmul.f32 inf, %v70647 (stack53)
        %v70659 = vxor.u32 2147483648, %v70647 (stack57)
        %v70662 = vmul.f32 %v70659, %v70647 (stack53)
        %v70664 = vadd.f32 1.0, %v70662 (stack58)
        %v70665 = vlog2.pop %v70664 (stack59)
        %v70666 = vmul.f32 0.6931472, %v70665 (stack60)
        %v70667 = vmul.f32 -0.5, %v70662 (stack61)
        %v70668 = vadd.f32 1.0, %v70667 (stack62)
        %v70669 = vmul.f32 %v70668, %v70662 (stack63)
        %v70670 = vand.u32 2147483647, %v70662 (stack64)
        %vm70671 = vcmp.lt.f32.partialorder %v70670, 0.0004427343 (stack65)
        %v70672 = vsel /*vm=*/%vm70671, /*on_true_vy=*/%v70669, /*on_false_vx=*/%v70666 (stack66)
        %v70673 = vxor.u32 2147483648, %v70672 (stack57)
        %vm70676 = vcmp.lt.f32.partialorder %v70673, 5.0 (stack56)
        %v70681 = vsel /*vm=*/%vm70676, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v70685 = vsel /*vm=*/%vm70676, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v70689 = vsel /*vm=*/%vm70676, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v70693 = vsel /*vm=*/%vm70676, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v70697 = vsel /*vm=*/%vm70676, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v70701 = vsel /*vm=*/%vm70676, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v70705 = vsel /*vm=*/%vm70676, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v70709 = vsel /*vm=*/%vm70676, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v70713 = vsel /*vm=*/%vm70676, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v70717 = vadd.f32 -2.5, %v70673 (stack52)
        %v70719 = vrsqrt.pop %v70673 (stack67)
        %v70720 = vmul.f32 %v70719, %v70673 (stack68)
        %vm70721 = vcmp.eq.f32.partialorder %v70673, inf (stack69)
        %v70722 = vsel /*vm=*/%vm70721, /*on_true_vy=*/%v70673, /*on_false_vx=*/%v70720 (stack70)
        %vm70723 = vcmp.eq.f32.partialorder %v70673, 0.0 (stack71)
        %v70724 = vand.u32 2147483648, %v70673 (stack72)
        %v70725 = vsel /*vm=*/%vm70723, /*on_true_vy=*/%v70724, /*on_false_vx=*/%v70722 (stack73)
        %v70728 = vadd.f32 -3.0, %v70725 (stack52)
        %v70732 = vsel /*vm=*/%vm70676, /*on_true_vy=*/%v70717, /*on_false_vx=*/%v70728 (stack43)
        %v70736 = vmul.f32 %v70732, %v70713 (stack53)
        %v70740 = vadd.f32 %v70736, %v70709 (stack52)
        %v70744 = vmul.f32 %v70740, %v70732 (stack53)
        %v70748 = vadd.f32 %v70744, %v70705 (stack52)
        %v70752 = vmul.f32 %v70748, %v70732 (stack53)
        %v70756 = vadd.f32 %v70752, %v70701 (stack52)
        %v70760 = vmul.f32 %v70756, %v70732 (stack53)
        %v70764 = vadd.f32 %v70760, %v70697 (stack52)
        %v70768 = vmul.f32 %v70764, %v70732 (stack53)
        %v70772 = vadd.f32 %v70768, %v70693 (stack52)
        %v70776 = vmul.f32 %v70772, %v70732 (stack53)
        %v70780 = vadd.f32 %v70776, %v70689 (stack52)
        %v70784 = vmul.f32 %v70780, %v70732 (stack53)
        %v70788 = vadd.f32 %v70784, %v70685 (stack52)
        %v70792 = vmul.f32 %v70788, %v70732 (stack53)
        %v70796 = vadd.f32 %v70792, %v70681 (stack52)
        %v70800 = vmul.f32 %v70796, %v70647 (stack53)
        %v70804 = vsel /*vm=*/%vm70652, /*on_true_vy=*/%v70657, /*on_false_vx=*/%v70800 (stack43)
        %v70808 = vmul.f32 1.4140625, %v70804 (stack53)
        %v70811 = vpack.c.bf16 0.0, %v70808 (stack74)
        %120121 = vst [vmem:[%s280 + $0x348] sm:$0xf] /*vst_source=*/%v70811 (stack75)
        %v70815 = vadd.s32 %v67585, %v3816 (stack39)
        %v70825 = vadd.s32 %v70815, %v415 (stack39)
        %vm70829 = vcmp.lt.u32.totalorder %v70825, %v70815 (stack42)
        %vm70834 = vcmp.lt.u32.totalorder %v70815, %v3816 (stack42)
        %v70839 = vadd.s32 %v67568, %v3803 (stack39)
        %v70843 = vadd.s32 1, %v70839 (stack39)
        %v70847 = vsel /*vm=*/%vm70834, /*on_true_vy=*/%v70843, /*on_false_vx=*/%v70839 (stack43)
        %v70851 = vadd.s32 1, %v70847 (stack39)
        %v70855 = vsel /*vm=*/%vm70829, /*on_true_vy=*/%v70851, /*on_false_vx=*/%v70847 (stack43)
        %v70860 = vadd.s32 %v70855, %v10 (stack39)
        %v70864 = vadd.s32 %v70825, %v9 (stack39)
        %v70868 = vadd.s32 %v70864, %v70860 (stack39)
        %v70870 = vshll.u32 %v70864, 13 (stack44)
        %v70871 = vshrl.u32 %v70864, 19 (stack45)
        %v70872 = vor.u32 %v70871, %v70870 (stack46)
        %v70873 = vxor.u32 %v70872, %v70868 (stack47)
        %v70876 = vadd.s32 %v70873, %v70868 (stack39)
        %v70878 = vshll.u32 %v70873, 15 (stack44)
        %v70879 = vshrl.u32 %v70873, 17 (stack45)
        %v70880 = vor.u32 %v70879, %v70878 (stack46)
        %v70881 = vxor.u32 %v70880, %v70876 (stack47)
        %v70884 = vadd.s32 %v70881, %v70876 (stack39)
        %v70886 = vshll.u32 %v70881, 26 (stack44)
        %v70887 = vshrl.u32 %v70881, 6 (stack45)
        %v70888 = vor.u32 %v70887, %v70886 (stack46)
        %v70889 = vxor.u32 %v70888, %v70884 (stack47)
        %v70892 = vadd.s32 %v70889, %v70884 (stack39)
        %v70896 = vadd.s32 %v70892, %v9 (stack39)
        %v70898 = vshll.u32 %v70889, 6 (stack44)
        %v70899 = vshrl.u32 %v70889, 26 (stack45)
        %v70900 = vor.u32 %v70899, %v70898 (stack46)
        %v70901 = vxor.u32 %v70900, %v70892 (stack47)
        %v70904 = vadd.s32 %v70901, %v8 (stack39)
        %v70908 = vadd.s32 1, %v70904 (stack39)
        %v70912 = vadd.s32 %v70908, %v70896 (stack39)
        %v70914 = vshll.u32 %v70908, 17 (stack44)
        %v70915 = vshrl.u32 %v70908, 15 (stack45)
        %v70916 = vor.u32 %v70915, %v70914 (stack46)
        %v70917 = vxor.u32 %v70916, %v70912 (stack47)
        %v70920 = vadd.s32 %v70917, %v70912 (stack39)
        %v70922 = vshll.u32 %v70917, 29 (stack44)
        %v70923 = vshrl.u32 %v70917, 3 (stack45)
        %v70924 = vor.u32 %v70923, %v70922 (stack46)
        %v70925 = vxor.u32 %v70924, %v70920 (stack47)
        %v70928 = vadd.s32 %v70925, %v70920 (stack39)
        %v70930 = vshll.u32 %v70925, 16 (stack44)
        %v70931 = vshrl.u32 %v70925, 16 (stack45)
        %v70932 = vor.u32 %v70931, %v70930 (stack46)
        %v70933 = vxor.u32 %v70932, %v70928 (stack47)
        %v70936 = vadd.s32 %v70933, %v70928 (stack39)
        %v70940 = vadd.s32 %v70936, %v8 (stack39)
        %v70942 = vshll.u32 %v70933, 24 (stack44)
        %v70943 = vshrl.u32 %v70933, 8 (stack45)
        %v70944 = vor.u32 %v70943, %v70942 (stack46)
        %v70945 = vxor.u32 %v70944, %v70936 (stack47)
        %v70948 = vadd.s32 %v70945, %v10 (stack39)
        %v70952 = vadd.s32 2, %v70948 (stack39)
        %v70956 = vadd.s32 %v70952, %v70940 (stack39)
        %v70958 = vshll.u32 %v70952, 13 (stack44)
        %v70959 = vshrl.u32 %v70952, 19 (stack45)
        %v70960 = vor.u32 %v70959, %v70958 (stack46)
        %v70961 = vxor.u32 %v70960, %v70956 (stack47)
        %v70964 = vadd.s32 %v70961, %v70956 (stack39)
        %v70966 = vshll.u32 %v70961, 15 (stack44)
        %v70967 = vshrl.u32 %v70961, 17 (stack45)
        %v70968 = vor.u32 %v70967, %v70966 (stack46)
        %v70969 = vxor.u32 %v70968, %v70964 (stack47)
        %v70972 = vadd.s32 %v70969, %v70964 (stack39)
        %v70974 = vshll.u32 %v70969, 26 (stack44)
        %v70975 = vshrl.u32 %v70969, 6 (stack45)
        %v70976 = vor.u32 %v70975, %v70974 (stack46)
        %v70977 = vxor.u32 %v70976, %v70972 (stack47)
        %v70980 = vadd.s32 %v70977, %v70972 (stack39)
        %v70984 = vadd.s32 %v70980, %v10 (stack39)
        %v70986 = vshll.u32 %v70977, 6 (stack44)
        %v70987 = vshrl.u32 %v70977, 26 (stack45)
        %v70988 = vor.u32 %v70987, %v70986 (stack46)
        %v70989 = vxor.u32 %v70988, %v70980 (stack47)
        %v70992 = vadd.s32 %v70989, %v9 (stack39)
        %v70996 = vadd.s32 3, %v70992 (stack39)
        %v71000 = vadd.s32 %v70996, %v70984 (stack39)
        %v71002 = vshll.u32 %v70996, 17 (stack44)
        %v71003 = vshrl.u32 %v70996, 15 (stack45)
        %v71004 = vor.u32 %v71003, %v71002 (stack46)
        %v71005 = vxor.u32 %v71004, %v71000 (stack47)
        %v71008 = vadd.s32 %v71005, %v71000 (stack39)
        %v71010 = vshll.u32 %v71005, 29 (stack44)
        %v71011 = vshrl.u32 %v71005, 3 (stack45)
        %v71012 = vor.u32 %v71011, %v71010 (stack46)
        %v71013 = vxor.u32 %v71012, %v71008 (stack47)
        %v71016 = vadd.s32 %v71013, %v71008 (stack39)
        %v71018 = vshll.u32 %v71013, 16 (stack44)
        %v71019 = vshrl.u32 %v71013, 16 (stack45)
        %v71020 = vor.u32 %v71019, %v71018 (stack46)
        %v71021 = vxor.u32 %v71020, %v71016 (stack47)
        %v71024 = vadd.s32 %v71021, %v71016 (stack39)
        %v71028 = vadd.s32 %v71024, %v9 (stack39)
        %v71030 = vshll.u32 %v71021, 24 (stack44)
        %v71031 = vshrl.u32 %v71021, 8 (stack45)
        %v71032 = vor.u32 %v71031, %v71030 (stack46)
        %v71033 = vxor.u32 %v71032, %v71024 (stack47)
        %v71036 = vadd.s32 %v71033, %v8 (stack39)
        %v71040 = vadd.s32 4, %v71036 (stack39)
        %v71044 = vadd.s32 %v71040, %v71028 (stack39)
        %v71046 = vshll.u32 %v71040, 13 (stack44)
        %v71047 = vshrl.u32 %v71040, 19 (stack45)
        %v71048 = vor.u32 %v71047, %v71046 (stack46)
        %v71049 = vxor.u32 %v71048, %v71044 (stack47)
        %v71052 = vadd.s32 %v71049, %v71044 (stack39)
        %v71054 = vshll.u32 %v71049, 15 (stack44)
        %v71055 = vshrl.u32 %v71049, 17 (stack45)
        %v71056 = vor.u32 %v71055, %v71054 (stack46)
        %v71057 = vxor.u32 %v71056, %v71052 (stack47)
        %v71060 = vadd.s32 %v71057, %v71052 (stack39)
        %v71062 = vshll.u32 %v71057, 26 (stack44)
        %v71063 = vshrl.u32 %v71057, 6 (stack45)
        %v71064 = vor.u32 %v71063, %v71062 (stack46)
        %v71065 = vxor.u32 %v71064, %v71060 (stack47)
        %v71068 = vadd.s32 %v71065, %v71060 (stack39)
        %v71072 = vadd.s32 %v71068, %v8 (stack39)
        %v71074 = vshll.u32 %v71065, 6 (stack44)
        %v71075 = vshrl.u32 %v71065, 26 (stack45)
        %v71076 = vor.u32 %v71075, %v71074 (stack46)
        %v71077 = vxor.u32 %v71076, %v71068 (stack47)
        %v71080 = vadd.s32 %v71077, %v10 (stack39)
        %v71084 = vadd.s32 5, %v71080 (stack39)
        %v71086 = vxor.u32 %v71084, %v71072 (stack47)
        %v71087 = vand.u32.u8 255, %v71086 (stack48)
        %v71088 = vand.u32 65535, %v71087 (stack49)
        %v71089 = vshrl.u32 %v71088, 1 (stack50)
        %v71090 = vor.u32 16256, %v71089 (stack46)
        %v71091 = vand.u32.u16 65535, %v71090 (stack51)
        %v120122 = vadd.low.f32.bf16 -1.0, %v71091 (stack52)
        %v71100 = vmul.f32 2.0, %v120122 (stack53)
        %v71104 = vadd.f32 -0.99609375, %v71100 (stack52)
        %v71108 = vmax.f32 %v71104, -0.99609375 (stack54)
        %v71110 = vand.u32 2147483647, %v71108 (stack55)
        %vm71113 = vcmp.eq.f32.partialorder %v71110, 1.0 (stack56)
        %v71118 = vmul.f32 inf, %v71108 (stack53)
        %v71120 = vxor.u32 2147483648, %v71108 (stack57)
        %v71123 = vmul.f32 %v71120, %v71108 (stack53)
        %v71125 = vadd.f32 1.0, %v71123 (stack58)
        %v71126 = vlog2.pop %v71125 (stack59)
        %v71127 = vmul.f32 0.6931472, %v71126 (stack60)
        %v71128 = vmul.f32 -0.5, %v71123 (stack61)
        %v71129 = vadd.f32 1.0, %v71128 (stack62)
        %v71130 = vmul.f32 %v71129, %v71123 (stack63)
        %v71131 = vand.u32 2147483647, %v71123 (stack64)
        %vm71132 = vcmp.lt.f32.partialorder %v71131, 0.0004427343 (stack65)
        %v71133 = vsel /*vm=*/%vm71132, /*on_true_vy=*/%v71130, /*on_false_vx=*/%v71127 (stack66)
        %v71134 = vxor.u32 2147483648, %v71133 (stack57)
        %vm71137 = vcmp.lt.f32.partialorder %v71134, 5.0 (stack56)
        %v71142 = vsel /*vm=*/%vm71137, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v71146 = vsel /*vm=*/%vm71137, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v71150 = vsel /*vm=*/%vm71137, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v71154 = vsel /*vm=*/%vm71137, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v71158 = vsel /*vm=*/%vm71137, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v71162 = vsel /*vm=*/%vm71137, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v71166 = vsel /*vm=*/%vm71137, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v71170 = vsel /*vm=*/%vm71137, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v71174 = vsel /*vm=*/%vm71137, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v71178 = vadd.f32 -2.5, %v71134 (stack52)
        %v71180 = vrsqrt.pop %v71134 (stack67)
        %v71181 = vmul.f32 %v71180, %v71134 (stack68)
        %vm71182 = vcmp.eq.f32.partialorder %v71134, inf (stack69)
        %v71183 = vsel /*vm=*/%vm71182, /*on_true_vy=*/%v71134, /*on_false_vx=*/%v71181 (stack70)
        %vm71184 = vcmp.eq.f32.partialorder %v71134, 0.0 (stack71)
        %v71185 = vand.u32 2147483648, %v71134 (stack72)
        %v71186 = vsel /*vm=*/%vm71184, /*on_true_vy=*/%v71185, /*on_false_vx=*/%v71183 (stack73)
        %v71189 = vadd.f32 -3.0, %v71186 (stack52)
        %v71193 = vsel /*vm=*/%vm71137, /*on_true_vy=*/%v71178, /*on_false_vx=*/%v71189 (stack43)
        %v71197 = vmul.f32 %v71193, %v71174 (stack53)
        %v71201 = vadd.f32 %v71197, %v71170 (stack52)
        %v71205 = vmul.f32 %v71201, %v71193 (stack53)
        %v71209 = vadd.f32 %v71205, %v71166 (stack52)
        %v71213 = vmul.f32 %v71209, %v71193 (stack53)
        %v71217 = vadd.f32 %v71213, %v71162 (stack52)
        %v71221 = vmul.f32 %v71217, %v71193 (stack53)
        %v71225 = vadd.f32 %v71221, %v71158 (stack52)
        %v71229 = vmul.f32 %v71225, %v71193 (stack53)
        %v71233 = vadd.f32 %v71229, %v71154 (stack52)
        %v71237 = vmul.f32 %v71233, %v71193 (stack53)
        %v71241 = vadd.f32 %v71237, %v71150 (stack52)
        %v71245 = vmul.f32 %v71241, %v71193 (stack53)
        %v71249 = vadd.f32 %v71245, %v71146 (stack52)
        %v71253 = vmul.f32 %v71249, %v71193 (stack53)
        %v71257 = vadd.f32 %v71253, %v71142 (stack52)
        %v71261 = vmul.f32 %v71257, %v71108 (stack53)
        %v71265 = vsel /*vm=*/%vm71113, /*on_true_vy=*/%v71118, /*on_false_vx=*/%v71261 (stack43)
        %v71269 = vmul.f32 1.4140625, %v71265 (stack53)
        %v71272 = vpack.c.bf16 0.0, %v71269 (stack74)
        %120123 = vst [vmem:[%s280 + $0x3c8] sm:$0xf] /*vst_source=*/%v71272 (stack75)
        %s71274 = sadd.s32 152, %s120390 (stack76)
        %s71275 = sshrl.u32 %s71274, 10 (stack23)
        %p120124 = scmp.gt.s32.totalorder %s71275, 1 (stack24)
        %s71277 = scalar_select /*predicate=*/%p120124, /*on_true=*/1, /*on_false=*/%s71275 (stack25)
        %s71278 = sand.u32 1023, %s71274 /* smod.u32 w/div 1024 */ (stack26)
        %s71279 = sshrl.u32 %s71278, 7 (stack27)
        %s71280 = sand.u32 127, %s71278 /* smod.u32 w/div 128 */ (stack28)
        %s120125 = sshll.u32 %s71277, 3 (stack29)
        %s71282 = scalar_lea.vmem %s3, %s120125 (stack30)
        %s71284 = scalar_lea.vmem %s71282, %s71279 (stack31)
        %v71285 = vld [vmem:[%s71284] ss:$0 sm:$0xff] (stack32)
        %s71286 = sand.u32 255, %s71280 (stack33)
        %s71288 = sor.u32 256, %s71286 (stack34)
        %71289 = vbcast.lane.b32.xlu0 %v71285, %s71288 (stack35)
        %v71290 = vpop.permute.xlu0 %71289 (stack36)
        %s71299 = scalar_lea.vmem %s5, %s120125 (stack30)
        %s71301 = scalar_lea.vmem %s71299, %s71279 (stack31)
        %v71302 = vld [vmem:[%s71301] ss:$0 sm:$0xff] (stack32)
        %71306 = vbcast.lane.b32.xlu0 %v71302, %s71288 (stack35)
        %v71307 = vpop.permute.xlu0 %71306 (stack36)
        %v71310 = vadd.s32 %v71307, %v408 (stack39)
        %v71320 = vadd.s32 %v71310, %v415 (stack39)
        %vm71324 = vcmp.lt.u32.totalorder %v71320, %v71310 (stack42)
        %vm71329 = vcmp.lt.u32.totalorder %v71310, %v408 (stack42)
        %v71334 = vadd.s32 %v71290, %v380 (stack39)
        %v71338 = vadd.s32 1, %v71334 (stack39)
        %v71342 = vsel /*vm=*/%vm71329, /*on_true_vy=*/%v71338, /*on_false_vx=*/%v71334 (stack43)
        %v71346 = vadd.s32 1, %v71342 (stack39)
        %v71350 = vsel /*vm=*/%vm71324, /*on_true_vy=*/%v71346, /*on_false_vx=*/%v71342 (stack43)
        %v71355 = vadd.s32 %v71350, %v10 (stack39)
        %v71359 = vadd.s32 %v71320, %v9 (stack39)
        %v71363 = vadd.s32 %v71359, %v71355 (stack39)
        %v71365 = vshll.u32 %v71359, 13 (stack44)
        %v71366 = vshrl.u32 %v71359, 19 (stack45)
        %v71367 = vor.u32 %v71366, %v71365 (stack46)
        %v71368 = vxor.u32 %v71367, %v71363 (stack47)
        %v71371 = vadd.s32 %v71368, %v71363 (stack39)
        %v71373 = vshll.u32 %v71368, 15 (stack44)
        %v71374 = vshrl.u32 %v71368, 17 (stack45)
        %v71375 = vor.u32 %v71374, %v71373 (stack46)
        %v71376 = vxor.u32 %v71375, %v71371 (stack47)
        %v71379 = vadd.s32 %v71376, %v71371 (stack39)
        %v71381 = vshll.u32 %v71376, 26 (stack44)
        %v71382 = vshrl.u32 %v71376, 6 (stack45)
        %v71383 = vor.u32 %v71382, %v71381 (stack46)
        %v71384 = vxor.u32 %v71383, %v71379 (stack47)
        %v71387 = vadd.s32 %v71384, %v71379 (stack39)
        %v71391 = vadd.s32 %v71387, %v9 (stack39)
        %v71393 = vshll.u32 %v71384, 6 (stack44)
        %v71394 = vshrl.u32 %v71384, 26 (stack45)
        %v71395 = vor.u32 %v71394, %v71393 (stack46)
        %v71396 = vxor.u32 %v71395, %v71387 (stack47)
        %v71399 = vadd.s32 %v71396, %v8 (stack39)
        %v71403 = vadd.s32 1, %v71399 (stack39)
        %v71407 = vadd.s32 %v71403, %v71391 (stack39)
        %v71409 = vshll.u32 %v71403, 17 (stack44)
        %v71410 = vshrl.u32 %v71403, 15 (stack45)
        %v71411 = vor.u32 %v71410, %v71409 (stack46)
        %v71412 = vxor.u32 %v71411, %v71407 (stack47)
        %v71415 = vadd.s32 %v71412, %v71407 (stack39)
        %v71417 = vshll.u32 %v71412, 29 (stack44)
        %v71418 = vshrl.u32 %v71412, 3 (stack45)
        %v71419 = vor.u32 %v71418, %v71417 (stack46)
        %v71420 = vxor.u32 %v71419, %v71415 (stack47)
        %v71423 = vadd.s32 %v71420, %v71415 (stack39)
        %v71425 = vshll.u32 %v71420, 16 (stack44)
        %v71426 = vshrl.u32 %v71420, 16 (stack45)
        %v71427 = vor.u32 %v71426, %v71425 (stack46)
        %v71428 = vxor.u32 %v71427, %v71423 (stack47)
        %v71431 = vadd.s32 %v71428, %v71423 (stack39)
        %v71435 = vadd.s32 %v71431, %v8 (stack39)
        %v71437 = vshll.u32 %v71428, 24 (stack44)
        %v71438 = vshrl.u32 %v71428, 8 (stack45)
        %v71439 = vor.u32 %v71438, %v71437 (stack46)
        %v71440 = vxor.u32 %v71439, %v71431 (stack47)
        %v71443 = vadd.s32 %v71440, %v10 (stack39)
        %v71447 = vadd.s32 2, %v71443 (stack39)
        %v71451 = vadd.s32 %v71447, %v71435 (stack39)
        %v71453 = vshll.u32 %v71447, 13 (stack44)
        %v71454 = vshrl.u32 %v71447, 19 (stack45)
        %v71455 = vor.u32 %v71454, %v71453 (stack46)
        %v71456 = vxor.u32 %v71455, %v71451 (stack47)
        %v71459 = vadd.s32 %v71456, %v71451 (stack39)
        %v71461 = vshll.u32 %v71456, 15 (stack44)
        %v71462 = vshrl.u32 %v71456, 17 (stack45)
        %v71463 = vor.u32 %v71462, %v71461 (stack46)
        %v71464 = vxor.u32 %v71463, %v71459 (stack47)
        %v71467 = vadd.s32 %v71464, %v71459 (stack39)
        %v71469 = vshll.u32 %v71464, 26 (stack44)
        %v71470 = vshrl.u32 %v71464, 6 (stack45)
        %v71471 = vor.u32 %v71470, %v71469 (stack46)
        %v71472 = vxor.u32 %v71471, %v71467 (stack47)
        %v71475 = vadd.s32 %v71472, %v71467 (stack39)
        %v71479 = vadd.s32 %v71475, %v10 (stack39)
        %v71481 = vshll.u32 %v71472, 6 (stack44)
        %v71482 = vshrl.u32 %v71472, 26 (stack45)
        %v71483 = vor.u32 %v71482, %v71481 (stack46)
        %v71484 = vxor.u32 %v71483, %v71475 (stack47)
        %v71487 = vadd.s32 %v71484, %v9 (stack39)
        %v71491 = vadd.s32 3, %v71487 (stack39)
        %v71495 = vadd.s32 %v71491, %v71479 (stack39)
        %v71497 = vshll.u32 %v71491, 17 (stack44)
        %v71498 = vshrl.u32 %v71491, 15 (stack45)
        %v71499 = vor.u32 %v71498, %v71497 (stack46)
        %v71500 = vxor.u32 %v71499, %v71495 (stack47)
        %v71503 = vadd.s32 %v71500, %v71495 (stack39)
        %v71505 = vshll.u32 %v71500, 29 (stack44)
        %v71506 = vshrl.u32 %v71500, 3 (stack45)
        %v71507 = vor.u32 %v71506, %v71505 (stack46)
        %v71508 = vxor.u32 %v71507, %v71503 (stack47)
        %v71511 = vadd.s32 %v71508, %v71503 (stack39)
        %v71513 = vshll.u32 %v71508, 16 (stack44)
        %v71514 = vshrl.u32 %v71508, 16 (stack45)
        %v71515 = vor.u32 %v71514, %v71513 (stack46)
        %v71516 = vxor.u32 %v71515, %v71511 (stack47)
        %v71519 = vadd.s32 %v71516, %v71511 (stack39)
        %v71523 = vadd.s32 %v71519, %v9 (stack39)
        %v71525 = vshll.u32 %v71516, 24 (stack44)
        %v71526 = vshrl.u32 %v71516, 8 (stack45)
        %v71527 = vor.u32 %v71526, %v71525 (stack46)
        %v71528 = vxor.u32 %v71527, %v71519 (stack47)
        %v71531 = vadd.s32 %v71528, %v8 (stack39)
        %v71535 = vadd.s32 4, %v71531 (stack39)
        %v71539 = vadd.s32 %v71535, %v71523 (stack39)
        %v71541 = vshll.u32 %v71535, 13 (stack44)
        %v71542 = vshrl.u32 %v71535, 19 (stack45)
        %v71543 = vor.u32 %v71542, %v71541 (stack46)
        %v71544 = vxor.u32 %v71543, %v71539 (stack47)
        %v71547 = vadd.s32 %v71544, %v71539 (stack39)
        %v71549 = vshll.u32 %v71544, 15 (stack44)
        %v71550 = vshrl.u32 %v71544, 17 (stack45)
        %v71551 = vor.u32 %v71550, %v71549 (stack46)
        %v71552 = vxor.u32 %v71551, %v71547 (stack47)
        %v71555 = vadd.s32 %v71552, %v71547 (stack39)
        %v71557 = vshll.u32 %v71552, 26 (stack44)
        %v71558 = vshrl.u32 %v71552, 6 (stack45)
        %v71559 = vor.u32 %v71558, %v71557 (stack46)
        %v71560 = vxor.u32 %v71559, %v71555 (stack47)
        %v71563 = vadd.s32 %v71560, %v71555 (stack39)
        %v71567 = vadd.s32 %v71563, %v8 (stack39)
        %v71569 = vshll.u32 %v71560, 6 (stack44)
        %v71570 = vshrl.u32 %v71560, 26 (stack45)
        %v71571 = vor.u32 %v71570, %v71569 (stack46)
        %v71572 = vxor.u32 %v71571, %v71563 (stack47)
        %v71575 = vadd.s32 %v71572, %v10 (stack39)
        %v71579 = vadd.s32 5, %v71575 (stack39)
        %v71581 = vxor.u32 %v71579, %v71567 (stack47)
        %v71582 = vand.u32.u8 255, %v71581 (stack48)
        %v71583 = vand.u32 65535, %v71582 (stack49)
        %v71584 = vshrl.u32 %v71583, 1 (stack50)
        %v71585 = vor.u32 16256, %v71584 (stack46)
        %v71586 = vand.u32.u16 65535, %v71585 (stack51)
        %v120128 = vadd.low.f32.bf16 -1.0, %v71586 (stack52)
        %v71595 = vmul.f32 2.0, %v120128 (stack53)
        %v71599 = vadd.f32 -0.99609375, %v71595 (stack52)
        %v71603 = vmax.f32 %v71599, -0.99609375 (stack54)
        %v71605 = vand.u32 2147483647, %v71603 (stack55)
        %vm71608 = vcmp.eq.f32.partialorder %v71605, 1.0 (stack56)
        %v71613 = vmul.f32 inf, %v71603 (stack53)
        %v71615 = vxor.u32 2147483648, %v71603 (stack57)
        %v71618 = vmul.f32 %v71615, %v71603 (stack53)
        %v71620 = vadd.f32 1.0, %v71618 (stack58)
        %v71621 = vlog2.pop %v71620 (stack59)
        %v71622 = vmul.f32 0.6931472, %v71621 (stack60)
        %v71623 = vmul.f32 -0.5, %v71618 (stack61)
        %v71624 = vadd.f32 1.0, %v71623 (stack62)
        %v71625 = vmul.f32 %v71624, %v71618 (stack63)
        %v71626 = vand.u32 2147483647, %v71618 (stack64)
        %vm71627 = vcmp.lt.f32.partialorder %v71626, 0.0004427343 (stack65)
        %v71628 = vsel /*vm=*/%vm71627, /*on_true_vy=*/%v71625, /*on_false_vx=*/%v71622 (stack66)
        %v71629 = vxor.u32 2147483648, %v71628 (stack57)
        %vm71632 = vcmp.lt.f32.partialorder %v71629, 5.0 (stack56)
        %v71637 = vsel /*vm=*/%vm71632, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v71641 = vsel /*vm=*/%vm71632, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v71645 = vsel /*vm=*/%vm71632, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v71649 = vsel /*vm=*/%vm71632, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v71653 = vsel /*vm=*/%vm71632, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v71657 = vsel /*vm=*/%vm71632, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v71661 = vsel /*vm=*/%vm71632, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v71665 = vsel /*vm=*/%vm71632, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v71669 = vsel /*vm=*/%vm71632, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v71673 = vadd.f32 -2.5, %v71629 (stack52)
        %v71675 = vrsqrt.pop %v71629 (stack67)
        %v71676 = vmul.f32 %v71675, %v71629 (stack68)
        %vm71677 = vcmp.eq.f32.partialorder %v71629, inf (stack69)
        %v71678 = vsel /*vm=*/%vm71677, /*on_true_vy=*/%v71629, /*on_false_vx=*/%v71676 (stack70)
        %vm71679 = vcmp.eq.f32.partialorder %v71629, 0.0 (stack71)
        %v71680 = vand.u32 2147483648, %v71629 (stack72)
        %v71681 = vsel /*vm=*/%vm71679, /*on_true_vy=*/%v71680, /*on_false_vx=*/%v71678 (stack73)
        %v71684 = vadd.f32 -3.0, %v71681 (stack52)
        %v71688 = vsel /*vm=*/%vm71632, /*on_true_vy=*/%v71673, /*on_false_vx=*/%v71684 (stack43)
        %v71692 = vmul.f32 %v71688, %v71669 (stack53)
        %v71696 = vadd.f32 %v71692, %v71665 (stack52)
        %v71700 = vmul.f32 %v71696, %v71688 (stack53)
        %v71704 = vadd.f32 %v71700, %v71661 (stack52)
        %v71708 = vmul.f32 %v71704, %v71688 (stack53)
        %v71712 = vadd.f32 %v71708, %v71657 (stack52)
        %v71716 = vmul.f32 %v71712, %v71688 (stack53)
        %v71720 = vadd.f32 %v71716, %v71653 (stack52)
        %v71724 = vmul.f32 %v71720, %v71688 (stack53)
        %v71728 = vadd.f32 %v71724, %v71649 (stack52)
        %v71732 = vmul.f32 %v71728, %v71688 (stack53)
        %v71736 = vadd.f32 %v71732, %v71645 (stack52)
        %v71740 = vmul.f32 %v71736, %v71688 (stack53)
        %v71744 = vadd.f32 %v71740, %v71641 (stack52)
        %v71748 = vmul.f32 %v71744, %v71688 (stack53)
        %v71752 = vadd.f32 %v71748, %v71637 (stack52)
        %v71756 = vmul.f32 %v71752, %v71603 (stack53)
        %v71760 = vsel /*vm=*/%vm71608, /*on_true_vy=*/%v71613, /*on_false_vx=*/%v71756 (stack43)
        %v71764 = vmul.f32 1.4140625, %v71760 (stack53)
        %v71767 = vpack.c.bf16 0.0, %v71764 (stack74)
        %120129 = vst [vmem:[%s280 + $0x4c] sm:$0xf] /*vst_source=*/%v71767 (stack75)
        %v71771 = vadd.s32 %v71307, %v894 (stack39)
        %v71781 = vadd.s32 %v71771, %v415 (stack39)
        %vm71785 = vcmp.lt.u32.totalorder %v71781, %v71771 (stack42)
        %vm71790 = vcmp.lt.u32.totalorder %v71771, %v894 (stack42)
        %v71795 = vadd.s32 %v71290, %v881 (stack39)
        %v71799 = vadd.s32 1, %v71795 (stack39)
        %v71803 = vsel /*vm=*/%vm71790, /*on_true_vy=*/%v71799, /*on_false_vx=*/%v71795 (stack43)
        %v71807 = vadd.s32 1, %v71803 (stack39)
        %v71811 = vsel /*vm=*/%vm71785, /*on_true_vy=*/%v71807, /*on_false_vx=*/%v71803 (stack43)
        %v71816 = vadd.s32 %v71811, %v10 (stack39)
        %v71820 = vadd.s32 %v71781, %v9 (stack39)
        %v71824 = vadd.s32 %v71820, %v71816 (stack39)
        %v71826 = vshll.u32 %v71820, 13 (stack44)
        %v71827 = vshrl.u32 %v71820, 19 (stack45)
        %v71828 = vor.u32 %v71827, %v71826 (stack46)
        %v71829 = vxor.u32 %v71828, %v71824 (stack47)
        %v71832 = vadd.s32 %v71829, %v71824 (stack39)
        %v71834 = vshll.u32 %v71829, 15 (stack44)
        %v71835 = vshrl.u32 %v71829, 17 (stack45)
        %v71836 = vor.u32 %v71835, %v71834 (stack46)
        %v71837 = vxor.u32 %v71836, %v71832 (stack47)
        %v71840 = vadd.s32 %v71837, %v71832 (stack39)
        %v71842 = vshll.u32 %v71837, 26 (stack44)
        %v71843 = vshrl.u32 %v71837, 6 (stack45)
        %v71844 = vor.u32 %v71843, %v71842 (stack46)
        %v71845 = vxor.u32 %v71844, %v71840 (stack47)
        %v71848 = vadd.s32 %v71845, %v71840 (stack39)
        %v71852 = vadd.s32 %v71848, %v9 (stack39)
        %v71854 = vshll.u32 %v71845, 6 (stack44)
        %v71855 = vshrl.u32 %v71845, 26 (stack45)
        %v71856 = vor.u32 %v71855, %v71854 (stack46)
        %v71857 = vxor.u32 %v71856, %v71848 (stack47)
        %v71860 = vadd.s32 %v71857, %v8 (stack39)
        %v71864 = vadd.s32 1, %v71860 (stack39)
        %v71868 = vadd.s32 %v71864, %v71852 (stack39)
        %v71870 = vshll.u32 %v71864, 17 (stack44)
        %v71871 = vshrl.u32 %v71864, 15 (stack45)
        %v71872 = vor.u32 %v71871, %v71870 (stack46)
        %v71873 = vxor.u32 %v71872, %v71868 (stack47)
        %v71876 = vadd.s32 %v71873, %v71868 (stack39)
        %v71878 = vshll.u32 %v71873, 29 (stack44)
        %v71879 = vshrl.u32 %v71873, 3 (stack45)
        %v71880 = vor.u32 %v71879, %v71878 (stack46)
        %v71881 = vxor.u32 %v71880, %v71876 (stack47)
        %v71884 = vadd.s32 %v71881, %v71876 (stack39)
        %v71886 = vshll.u32 %v71881, 16 (stack44)
        %v71887 = vshrl.u32 %v71881, 16 (stack45)
        %v71888 = vor.u32 %v71887, %v71886 (stack46)
        %v71889 = vxor.u32 %v71888, %v71884 (stack47)
        %v71892 = vadd.s32 %v71889, %v71884 (stack39)
        %v71896 = vadd.s32 %v71892, %v8 (stack39)
        %v71898 = vshll.u32 %v71889, 24 (stack44)
        %v71899 = vshrl.u32 %v71889, 8 (stack45)
        %v71900 = vor.u32 %v71899, %v71898 (stack46)
        %v71901 = vxor.u32 %v71900, %v71892 (stack47)
        %v71904 = vadd.s32 %v71901, %v10 (stack39)
        %v71908 = vadd.s32 2, %v71904 (stack39)
        %v71912 = vadd.s32 %v71908, %v71896 (stack39)
        %v71914 = vshll.u32 %v71908, 13 (stack44)
        %v71915 = vshrl.u32 %v71908, 19 (stack45)
        %v71916 = vor.u32 %v71915, %v71914 (stack46)
        %v71917 = vxor.u32 %v71916, %v71912 (stack47)
        %v71920 = vadd.s32 %v71917, %v71912 (stack39)
        %v71922 = vshll.u32 %v71917, 15 (stack44)
        %v71923 = vshrl.u32 %v71917, 17 (stack45)
        %v71924 = vor.u32 %v71923, %v71922 (stack46)
        %v71925 = vxor.u32 %v71924, %v71920 (stack47)
        %v71928 = vadd.s32 %v71925, %v71920 (stack39)
        %v71930 = vshll.u32 %v71925, 26 (stack44)
        %v71931 = vshrl.u32 %v71925, 6 (stack45)
        %v71932 = vor.u32 %v71931, %v71930 (stack46)
        %v71933 = vxor.u32 %v71932, %v71928 (stack47)
        %v71936 = vadd.s32 %v71933, %v71928 (stack39)
        %v71940 = vadd.s32 %v71936, %v10 (stack39)
        %v71942 = vshll.u32 %v71933, 6 (stack44)
        %v71943 = vshrl.u32 %v71933, 26 (stack45)
        %v71944 = vor.u32 %v71943, %v71942 (stack46)
        %v71945 = vxor.u32 %v71944, %v71936 (stack47)
        %v71948 = vadd.s32 %v71945, %v9 (stack39)
        %v71952 = vadd.s32 3, %v71948 (stack39)
        %v71956 = vadd.s32 %v71952, %v71940 (stack39)
        %v71958 = vshll.u32 %v71952, 17 (stack44)
        %v71959 = vshrl.u32 %v71952, 15 (stack45)
        %v71960 = vor.u32 %v71959, %v71958 (stack46)
        %v71961 = vxor.u32 %v71960, %v71956 (stack47)
        %v71964 = vadd.s32 %v71961, %v71956 (stack39)
        %v71966 = vshll.u32 %v71961, 29 (stack44)
        %v71967 = vshrl.u32 %v71961, 3 (stack45)
        %v71968 = vor.u32 %v71967, %v71966 (stack46)
        %v71969 = vxor.u32 %v71968, %v71964 (stack47)
        %v71972 = vadd.s32 %v71969, %v71964 (stack39)
        %v71974 = vshll.u32 %v71969, 16 (stack44)
        %v71975 = vshrl.u32 %v71969, 16 (stack45)
        %v71976 = vor.u32 %v71975, %v71974 (stack46)
        %v71977 = vxor.u32 %v71976, %v71972 (stack47)
        %v71980 = vadd.s32 %v71977, %v71972 (stack39)
        %v71984 = vadd.s32 %v71980, %v9 (stack39)
        %v71986 = vshll.u32 %v71977, 24 (stack44)
        %v71987 = vshrl.u32 %v71977, 8 (stack45)
        %v71988 = vor.u32 %v71987, %v71986 (stack46)
        %v71989 = vxor.u32 %v71988, %v71980 (stack47)
        %v71992 = vadd.s32 %v71989, %v8 (stack39)
        %v71996 = vadd.s32 4, %v71992 (stack39)
        %v72000 = vadd.s32 %v71996, %v71984 (stack39)
        %v72002 = vshll.u32 %v71996, 13 (stack44)
        %v72003 = vshrl.u32 %v71996, 19 (stack45)
        %v72004 = vor.u32 %v72003, %v72002 (stack46)
        %v72005 = vxor.u32 %v72004, %v72000 (stack47)
        %v72008 = vadd.s32 %v72005, %v72000 (stack39)
        %v72010 = vshll.u32 %v72005, 15 (stack44)
        %v72011 = vshrl.u32 %v72005, 17 (stack45)
        %v72012 = vor.u32 %v72011, %v72010 (stack46)
        %v72013 = vxor.u32 %v72012, %v72008 (stack47)
        %v72016 = vadd.s32 %v72013, %v72008 (stack39)
        %v72018 = vshll.u32 %v72013, 26 (stack44)
        %v72019 = vshrl.u32 %v72013, 6 (stack45)
        %v72020 = vor.u32 %v72019, %v72018 (stack46)
        %v72021 = vxor.u32 %v72020, %v72016 (stack47)
        %v72024 = vadd.s32 %v72021, %v72016 (stack39)
        %v72028 = vadd.s32 %v72024, %v8 (stack39)
        %v72030 = vshll.u32 %v72021, 6 (stack44)
        %v72031 = vshrl.u32 %v72021, 26 (stack45)
        %v72032 = vor.u32 %v72031, %v72030 (stack46)
        %v72033 = vxor.u32 %v72032, %v72024 (stack47)
        %v72036 = vadd.s32 %v72033, %v10 (stack39)
        %v72040 = vadd.s32 5, %v72036 (stack39)
        %v72042 = vxor.u32 %v72040, %v72028 (stack47)
        %v72043 = vand.u32.u8 255, %v72042 (stack48)
        %v72044 = vand.u32 65535, %v72043 (stack49)
        %v72045 = vshrl.u32 %v72044, 1 (stack50)
        %v72046 = vor.u32 16256, %v72045 (stack46)
        %v72047 = vand.u32.u16 65535, %v72046 (stack51)
        %v120130 = vadd.low.f32.bf16 -1.0, %v72047 (stack52)
        %v72056 = vmul.f32 2.0, %v120130 (stack53)
        %v72060 = vadd.f32 -0.99609375, %v72056 (stack52)
        %v72064 = vmax.f32 %v72060, -0.99609375 (stack54)
        %v72066 = vand.u32 2147483647, %v72064 (stack55)
        %vm72069 = vcmp.eq.f32.partialorder %v72066, 1.0 (stack56)
        %v72074 = vmul.f32 inf, %v72064 (stack53)
        %v72076 = vxor.u32 2147483648, %v72064 (stack57)
        %v72079 = vmul.f32 %v72076, %v72064 (stack53)
        %v72081 = vadd.f32 1.0, %v72079 (stack58)
        %v72082 = vlog2.pop %v72081 (stack59)
        %v72083 = vmul.f32 0.6931472, %v72082 (stack60)
        %v72084 = vmul.f32 -0.5, %v72079 (stack61)
        %v72085 = vadd.f32 1.0, %v72084 (stack62)
        %v72086 = vmul.f32 %v72085, %v72079 (stack63)
        %v72087 = vand.u32 2147483647, %v72079 (stack64)
        %vm72088 = vcmp.lt.f32.partialorder %v72087, 0.0004427343 (stack65)
        %v72089 = vsel /*vm=*/%vm72088, /*on_true_vy=*/%v72086, /*on_false_vx=*/%v72083 (stack66)
        %v72090 = vxor.u32 2147483648, %v72089 (stack57)
        %vm72093 = vcmp.lt.f32.partialorder %v72090, 5.0 (stack56)
        %v72098 = vsel /*vm=*/%vm72093, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v72102 = vsel /*vm=*/%vm72093, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v72106 = vsel /*vm=*/%vm72093, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v72110 = vsel /*vm=*/%vm72093, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v72114 = vsel /*vm=*/%vm72093, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v72118 = vsel /*vm=*/%vm72093, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v72122 = vsel /*vm=*/%vm72093, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v72126 = vsel /*vm=*/%vm72093, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v72130 = vsel /*vm=*/%vm72093, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v72134 = vadd.f32 -2.5, %v72090 (stack52)
        %v72136 = vrsqrt.pop %v72090 (stack67)
        %v72137 = vmul.f32 %v72136, %v72090 (stack68)
        %vm72138 = vcmp.eq.f32.partialorder %v72090, inf (stack69)
        %v72139 = vsel /*vm=*/%vm72138, /*on_true_vy=*/%v72090, /*on_false_vx=*/%v72137 (stack70)
        %vm72140 = vcmp.eq.f32.partialorder %v72090, 0.0 (stack71)
        %v72141 = vand.u32 2147483648, %v72090 (stack72)
        %v72142 = vsel /*vm=*/%vm72140, /*on_true_vy=*/%v72141, /*on_false_vx=*/%v72139 (stack73)
        %v72145 = vadd.f32 -3.0, %v72142 (stack52)
        %v72149 = vsel /*vm=*/%vm72093, /*on_true_vy=*/%v72134, /*on_false_vx=*/%v72145 (stack43)
        %v72153 = vmul.f32 %v72149, %v72130 (stack53)
        %v72157 = vadd.f32 %v72153, %v72126 (stack52)
        %v72161 = vmul.f32 %v72157, %v72149 (stack53)
        %v72165 = vadd.f32 %v72161, %v72122 (stack52)
        %v72169 = vmul.f32 %v72165, %v72149 (stack53)
        %v72173 = vadd.f32 %v72169, %v72118 (stack52)
        %v72177 = vmul.f32 %v72173, %v72149 (stack53)
        %v72181 = vadd.f32 %v72177, %v72114 (stack52)
        %v72185 = vmul.f32 %v72181, %v72149 (stack53)
        %v72189 = vadd.f32 %v72185, %v72110 (stack52)
        %v72193 = vmul.f32 %v72189, %v72149 (stack53)
        %v72197 = vadd.f32 %v72193, %v72106 (stack52)
        %v72201 = vmul.f32 %v72197, %v72149 (stack53)
        %v72205 = vadd.f32 %v72201, %v72102 (stack52)
        %v72209 = vmul.f32 %v72205, %v72149 (stack53)
        %v72213 = vadd.f32 %v72209, %v72098 (stack52)
        %v72217 = vmul.f32 %v72213, %v72064 (stack53)
        %v72221 = vsel /*vm=*/%vm72069, /*on_true_vy=*/%v72074, /*on_false_vx=*/%v72217 (stack43)
        %v72225 = vmul.f32 1.4140625, %v72221 (stack53)
        %v72228 = vpack.c.bf16 0.0, %v72225 (stack74)
        %120131 = vst [vmem:[%s280 + $0xcc] sm:$0xf] /*vst_source=*/%v72228 (stack75)
        %v72232 = vadd.s32 %v71307, %v1381 (stack39)
        %v72242 = vadd.s32 %v72232, %v415 (stack39)
        %vm72246 = vcmp.lt.u32.totalorder %v72242, %v72232 (stack42)
        %vm72251 = vcmp.lt.u32.totalorder %v72232, %v1381 (stack42)
        %v72256 = vadd.s32 %v71290, %v1368 (stack39)
        %v72260 = vadd.s32 1, %v72256 (stack39)
        %v72264 = vsel /*vm=*/%vm72251, /*on_true_vy=*/%v72260, /*on_false_vx=*/%v72256 (stack43)
        %v72268 = vadd.s32 1, %v72264 (stack39)
        %v72272 = vsel /*vm=*/%vm72246, /*on_true_vy=*/%v72268, /*on_false_vx=*/%v72264 (stack43)
        %v72277 = vadd.s32 %v72272, %v10 (stack39)
        %v72281 = vadd.s32 %v72242, %v9 (stack39)
        %v72285 = vadd.s32 %v72281, %v72277 (stack39)
        %v72287 = vshll.u32 %v72281, 13 (stack44)
        %v72288 = vshrl.u32 %v72281, 19 (stack45)
        %v72289 = vor.u32 %v72288, %v72287 (stack46)
        %v72290 = vxor.u32 %v72289, %v72285 (stack47)
        %v72293 = vadd.s32 %v72290, %v72285 (stack39)
        %v72295 = vshll.u32 %v72290, 15 (stack44)
        %v72296 = vshrl.u32 %v72290, 17 (stack45)
        %v72297 = vor.u32 %v72296, %v72295 (stack46)
        %v72298 = vxor.u32 %v72297, %v72293 (stack47)
        %v72301 = vadd.s32 %v72298, %v72293 (stack39)
        %v72303 = vshll.u32 %v72298, 26 (stack44)
        %v72304 = vshrl.u32 %v72298, 6 (stack45)
        %v72305 = vor.u32 %v72304, %v72303 (stack46)
        %v72306 = vxor.u32 %v72305, %v72301 (stack47)
        %v72309 = vadd.s32 %v72306, %v72301 (stack39)
        %v72313 = vadd.s32 %v72309, %v9 (stack39)
        %v72315 = vshll.u32 %v72306, 6 (stack44)
        %v72316 = vshrl.u32 %v72306, 26 (stack45)
        %v72317 = vor.u32 %v72316, %v72315 (stack46)
        %v72318 = vxor.u32 %v72317, %v72309 (stack47)
        %v72321 = vadd.s32 %v72318, %v8 (stack39)
        %v72325 = vadd.s32 1, %v72321 (stack39)
        %v72329 = vadd.s32 %v72325, %v72313 (stack39)
        %v72331 = vshll.u32 %v72325, 17 (stack44)
        %v72332 = vshrl.u32 %v72325, 15 (stack45)
        %v72333 = vor.u32 %v72332, %v72331 (stack46)
        %v72334 = vxor.u32 %v72333, %v72329 (stack47)
        %v72337 = vadd.s32 %v72334, %v72329 (stack39)
        %v72339 = vshll.u32 %v72334, 29 (stack44)
        %v72340 = vshrl.u32 %v72334, 3 (stack45)
        %v72341 = vor.u32 %v72340, %v72339 (stack46)
        %v72342 = vxor.u32 %v72341, %v72337 (stack47)
        %v72345 = vadd.s32 %v72342, %v72337 (stack39)
        %v72347 = vshll.u32 %v72342, 16 (stack44)
        %v72348 = vshrl.u32 %v72342, 16 (stack45)
        %v72349 = vor.u32 %v72348, %v72347 (stack46)
        %v72350 = vxor.u32 %v72349, %v72345 (stack47)
        %v72353 = vadd.s32 %v72350, %v72345 (stack39)
        %v72357 = vadd.s32 %v72353, %v8 (stack39)
        %v72359 = vshll.u32 %v72350, 24 (stack44)
        %v72360 = vshrl.u32 %v72350, 8 (stack45)
        %v72361 = vor.u32 %v72360, %v72359 (stack46)
        %v72362 = vxor.u32 %v72361, %v72353 (stack47)
        %v72365 = vadd.s32 %v72362, %v10 (stack39)
        %v72369 = vadd.s32 2, %v72365 (stack39)
        %v72373 = vadd.s32 %v72369, %v72357 (stack39)
        %v72375 = vshll.u32 %v72369, 13 (stack44)
        %v72376 = vshrl.u32 %v72369, 19 (stack45)
        %v72377 = vor.u32 %v72376, %v72375 (stack46)
        %v72378 = vxor.u32 %v72377, %v72373 (stack47)
        %v72381 = vadd.s32 %v72378, %v72373 (stack39)
        %v72383 = vshll.u32 %v72378, 15 (stack44)
        %v72384 = vshrl.u32 %v72378, 17 (stack45)
        %v72385 = vor.u32 %v72384, %v72383 (stack46)
        %v72386 = vxor.u32 %v72385, %v72381 (stack47)
        %v72389 = vadd.s32 %v72386, %v72381 (stack39)
        %v72391 = vshll.u32 %v72386, 26 (stack44)
        %v72392 = vshrl.u32 %v72386, 6 (stack45)
        %v72393 = vor.u32 %v72392, %v72391 (stack46)
        %v72394 = vxor.u32 %v72393, %v72389 (stack47)
        %v72397 = vadd.s32 %v72394, %v72389 (stack39)
        %v72401 = vadd.s32 %v72397, %v10 (stack39)
        %v72403 = vshll.u32 %v72394, 6 (stack44)
        %v72404 = vshrl.u32 %v72394, 26 (stack45)
        %v72405 = vor.u32 %v72404, %v72403 (stack46)
        %v72406 = vxor.u32 %v72405, %v72397 (stack47)
        %v72409 = vadd.s32 %v72406, %v9 (stack39)
        %v72413 = vadd.s32 3, %v72409 (stack39)
        %v72417 = vadd.s32 %v72413, %v72401 (stack39)
        %v72419 = vshll.u32 %v72413, 17 (stack44)
        %v72420 = vshrl.u32 %v72413, 15 (stack45)
        %v72421 = vor.u32 %v72420, %v72419 (stack46)
        %v72422 = vxor.u32 %v72421, %v72417 (stack47)
        %v72425 = vadd.s32 %v72422, %v72417 (stack39)
        %v72427 = vshll.u32 %v72422, 29 (stack44)
        %v72428 = vshrl.u32 %v72422, 3 (stack45)
        %v72429 = vor.u32 %v72428, %v72427 (stack46)
        %v72430 = vxor.u32 %v72429, %v72425 (stack47)
        %v72433 = vadd.s32 %v72430, %v72425 (stack39)
        %v72435 = vshll.u32 %v72430, 16 (stack44)
        %v72436 = vshrl.u32 %v72430, 16 (stack45)
        %v72437 = vor.u32 %v72436, %v72435 (stack46)
        %v72438 = vxor.u32 %v72437, %v72433 (stack47)
        %v72441 = vadd.s32 %v72438, %v72433 (stack39)
        %v72445 = vadd.s32 %v72441, %v9 (stack39)
        %v72447 = vshll.u32 %v72438, 24 (stack44)
        %v72448 = vshrl.u32 %v72438, 8 (stack45)
        %v72449 = vor.u32 %v72448, %v72447 (stack46)
        %v72450 = vxor.u32 %v72449, %v72441 (stack47)
        %v72453 = vadd.s32 %v72450, %v8 (stack39)
        %v72457 = vadd.s32 4, %v72453 (stack39)
        %v72461 = vadd.s32 %v72457, %v72445 (stack39)
        %v72463 = vshll.u32 %v72457, 13 (stack44)
        %v72464 = vshrl.u32 %v72457, 19 (stack45)
        %v72465 = vor.u32 %v72464, %v72463 (stack46)
        %v72466 = vxor.u32 %v72465, %v72461 (stack47)
        %v72469 = vadd.s32 %v72466, %v72461 (stack39)
        %v72471 = vshll.u32 %v72466, 15 (stack44)
        %v72472 = vshrl.u32 %v72466, 17 (stack45)
        %v72473 = vor.u32 %v72472, %v72471 (stack46)
        %v72474 = vxor.u32 %v72473, %v72469 (stack47)
        %v72477 = vadd.s32 %v72474, %v72469 (stack39)
        %v72479 = vshll.u32 %v72474, 26 (stack44)
        %v72480 = vshrl.u32 %v72474, 6 (stack45)
        %v72481 = vor.u32 %v72480, %v72479 (stack46)
        %v72482 = vxor.u32 %v72481, %v72477 (stack47)
        %v72485 = vadd.s32 %v72482, %v72477 (stack39)
        %v72489 = vadd.s32 %v72485, %v8 (stack39)
        %v72491 = vshll.u32 %v72482, 6 (stack44)
        %v72492 = vshrl.u32 %v72482, 26 (stack45)
        %v72493 = vor.u32 %v72492, %v72491 (stack46)
        %v72494 = vxor.u32 %v72493, %v72485 (stack47)
        %v72497 = vadd.s32 %v72494, %v10 (stack39)
        %v72501 = vadd.s32 5, %v72497 (stack39)
        %v72503 = vxor.u32 %v72501, %v72489 (stack47)
        %v72504 = vand.u32.u8 255, %v72503 (stack48)
        %v72505 = vand.u32 65535, %v72504 (stack49)
        %v72506 = vshrl.u32 %v72505, 1 (stack50)
        %v72507 = vor.u32 16256, %v72506 (stack46)
        %v72508 = vand.u32.u16 65535, %v72507 (stack51)
        %v120132 = vadd.low.f32.bf16 -1.0, %v72508 (stack52)
        %v72517 = vmul.f32 2.0, %v120132 (stack53)
        %v72521 = vadd.f32 -0.99609375, %v72517 (stack52)
        %v72525 = vmax.f32 %v72521, -0.99609375 (stack54)
        %v72527 = vand.u32 2147483647, %v72525 (stack55)
        %vm72530 = vcmp.eq.f32.partialorder %v72527, 1.0 (stack56)
        %v72535 = vmul.f32 inf, %v72525 (stack53)
        %v72537 = vxor.u32 2147483648, %v72525 (stack57)
        %v72540 = vmul.f32 %v72537, %v72525 (stack53)
        %v72542 = vadd.f32 1.0, %v72540 (stack58)
        %v72543 = vlog2.pop %v72542 (stack59)
        %v72544 = vmul.f32 0.6931472, %v72543 (stack60)
        %v72545 = vmul.f32 -0.5, %v72540 (stack61)
        %v72546 = vadd.f32 1.0, %v72545 (stack62)
        %v72547 = vmul.f32 %v72546, %v72540 (stack63)
        %v72548 = vand.u32 2147483647, %v72540 (stack64)
        %vm72549 = vcmp.lt.f32.partialorder %v72548, 0.0004427343 (stack65)
        %v72550 = vsel /*vm=*/%vm72549, /*on_true_vy=*/%v72547, /*on_false_vx=*/%v72544 (stack66)
        %v72551 = vxor.u32 2147483648, %v72550 (stack57)
        %vm72554 = vcmp.lt.f32.partialorder %v72551, 5.0 (stack56)
        %v72559 = vsel /*vm=*/%vm72554, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v72563 = vsel /*vm=*/%vm72554, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v72567 = vsel /*vm=*/%vm72554, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v72571 = vsel /*vm=*/%vm72554, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v72575 = vsel /*vm=*/%vm72554, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v72579 = vsel /*vm=*/%vm72554, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v72583 = vsel /*vm=*/%vm72554, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v72587 = vsel /*vm=*/%vm72554, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v72591 = vsel /*vm=*/%vm72554, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v72595 = vadd.f32 -2.5, %v72551 (stack52)
        %v72597 = vrsqrt.pop %v72551 (stack67)
        %v72598 = vmul.f32 %v72597, %v72551 (stack68)
        %vm72599 = vcmp.eq.f32.partialorder %v72551, inf (stack69)
        %v72600 = vsel /*vm=*/%vm72599, /*on_true_vy=*/%v72551, /*on_false_vx=*/%v72598 (stack70)
        %vm72601 = vcmp.eq.f32.partialorder %v72551, 0.0 (stack71)
        %v72602 = vand.u32 2147483648, %v72551 (stack72)
        %v72603 = vsel /*vm=*/%vm72601, /*on_true_vy=*/%v72602, /*on_false_vx=*/%v72600 (stack73)
        %v72606 = vadd.f32 -3.0, %v72603 (stack52)
        %v72610 = vsel /*vm=*/%vm72554, /*on_true_vy=*/%v72595, /*on_false_vx=*/%v72606 (stack43)
        %v72614 = vmul.f32 %v72610, %v72591 (stack53)
        %v72618 = vadd.f32 %v72614, %v72587 (stack52)
        %v72622 = vmul.f32 %v72618, %v72610 (stack53)
        %v72626 = vadd.f32 %v72622, %v72583 (stack52)
        %v72630 = vmul.f32 %v72626, %v72610 (stack53)
        %v72634 = vadd.f32 %v72630, %v72579 (stack52)
        %v72638 = vmul.f32 %v72634, %v72610 (stack53)
        %v72642 = vadd.f32 %v72638, %v72575 (stack52)
        %v72646 = vmul.f32 %v72642, %v72610 (stack53)
        %v72650 = vadd.f32 %v72646, %v72571 (stack52)
        %v72654 = vmul.f32 %v72650, %v72610 (stack53)
        %v72658 = vadd.f32 %v72654, %v72567 (stack52)
        %v72662 = vmul.f32 %v72658, %v72610 (stack53)
        %v72666 = vadd.f32 %v72662, %v72563 (stack52)
        %v72670 = vmul.f32 %v72666, %v72610 (stack53)
        %v72674 = vadd.f32 %v72670, %v72559 (stack52)
        %v72678 = vmul.f32 %v72674, %v72525 (stack53)
        %v72682 = vsel /*vm=*/%vm72530, /*on_true_vy=*/%v72535, /*on_false_vx=*/%v72678 (stack43)
        %v72686 = vmul.f32 1.4140625, %v72682 (stack53)
        %v72689 = vpack.c.bf16 0.0, %v72686 (stack74)
        %120133 = vst [vmem:[%s280 + $0x14c] sm:$0xf] /*vst_source=*/%v72689 (stack75)
        %v72693 = vadd.s32 %v71307, %v1868 (stack39)
        %v72703 = vadd.s32 %v72693, %v415 (stack39)
        %vm72707 = vcmp.lt.u32.totalorder %v72703, %v72693 (stack42)
        %vm72712 = vcmp.lt.u32.totalorder %v72693, %v1868 (stack42)
        %v72717 = vadd.s32 %v71290, %v1855 (stack39)
        %v72721 = vadd.s32 1, %v72717 (stack39)
        %v72725 = vsel /*vm=*/%vm72712, /*on_true_vy=*/%v72721, /*on_false_vx=*/%v72717 (stack43)
        %v72729 = vadd.s32 1, %v72725 (stack39)
        %v72733 = vsel /*vm=*/%vm72707, /*on_true_vy=*/%v72729, /*on_false_vx=*/%v72725 (stack43)
        %v72738 = vadd.s32 %v72733, %v10 (stack39)
        %v72742 = vadd.s32 %v72703, %v9 (stack39)
        %v72746 = vadd.s32 %v72742, %v72738 (stack39)
        %v72748 = vshll.u32 %v72742, 13 (stack44)
        %v72749 = vshrl.u32 %v72742, 19 (stack45)
        %v72750 = vor.u32 %v72749, %v72748 (stack46)
        %v72751 = vxor.u32 %v72750, %v72746 (stack47)
        %v72754 = vadd.s32 %v72751, %v72746 (stack39)
        %v72756 = vshll.u32 %v72751, 15 (stack44)
        %v72757 = vshrl.u32 %v72751, 17 (stack45)
        %v72758 = vor.u32 %v72757, %v72756 (stack46)
        %v72759 = vxor.u32 %v72758, %v72754 (stack47)
        %v72762 = vadd.s32 %v72759, %v72754 (stack39)
        %v72764 = vshll.u32 %v72759, 26 (stack44)
        %v72765 = vshrl.u32 %v72759, 6 (stack45)
        %v72766 = vor.u32 %v72765, %v72764 (stack46)
        %v72767 = vxor.u32 %v72766, %v72762 (stack47)
        %v72770 = vadd.s32 %v72767, %v72762 (stack39)
        %v72774 = vadd.s32 %v72770, %v9 (stack39)
        %v72776 = vshll.u32 %v72767, 6 (stack44)
        %v72777 = vshrl.u32 %v72767, 26 (stack45)
        %v72778 = vor.u32 %v72777, %v72776 (stack46)
        %v72779 = vxor.u32 %v72778, %v72770 (stack47)
        %v72782 = vadd.s32 %v72779, %v8 (stack39)
        %v72786 = vadd.s32 1, %v72782 (stack39)
        %v72790 = vadd.s32 %v72786, %v72774 (stack39)
        %v72792 = vshll.u32 %v72786, 17 (stack44)
        %v72793 = vshrl.u32 %v72786, 15 (stack45)
        %v72794 = vor.u32 %v72793, %v72792 (stack46)
        %v72795 = vxor.u32 %v72794, %v72790 (stack47)
        %v72798 = vadd.s32 %v72795, %v72790 (stack39)
        %v72800 = vshll.u32 %v72795, 29 (stack44)
        %v72801 = vshrl.u32 %v72795, 3 (stack45)
        %v72802 = vor.u32 %v72801, %v72800 (stack46)
        %v72803 = vxor.u32 %v72802, %v72798 (stack47)
        %v72806 = vadd.s32 %v72803, %v72798 (stack39)
        %v72808 = vshll.u32 %v72803, 16 (stack44)
        %v72809 = vshrl.u32 %v72803, 16 (stack45)
        %v72810 = vor.u32 %v72809, %v72808 (stack46)
        %v72811 = vxor.u32 %v72810, %v72806 (stack47)
        %v72814 = vadd.s32 %v72811, %v72806 (stack39)
        %v72818 = vadd.s32 %v72814, %v8 (stack39)
        %v72820 = vshll.u32 %v72811, 24 (stack44)
        %v72821 = vshrl.u32 %v72811, 8 (stack45)
        %v72822 = vor.u32 %v72821, %v72820 (stack46)
        %v72823 = vxor.u32 %v72822, %v72814 (stack47)
        %v72826 = vadd.s32 %v72823, %v10 (stack39)
        %v72830 = vadd.s32 2, %v72826 (stack39)
        %v72834 = vadd.s32 %v72830, %v72818 (stack39)
        %v72836 = vshll.u32 %v72830, 13 (stack44)
        %v72837 = vshrl.u32 %v72830, 19 (stack45)
        %v72838 = vor.u32 %v72837, %v72836 (stack46)
        %v72839 = vxor.u32 %v72838, %v72834 (stack47)
        %v72842 = vadd.s32 %v72839, %v72834 (stack39)
        %v72844 = vshll.u32 %v72839, 15 (stack44)
        %v72845 = vshrl.u32 %v72839, 17 (stack45)
        %v72846 = vor.u32 %v72845, %v72844 (stack46)
        %v72847 = vxor.u32 %v72846, %v72842 (stack47)
        %v72850 = vadd.s32 %v72847, %v72842 (stack39)
        %v72852 = vshll.u32 %v72847, 26 (stack44)
        %v72853 = vshrl.u32 %v72847, 6 (stack45)
        %v72854 = vor.u32 %v72853, %v72852 (stack46)
        %v72855 = vxor.u32 %v72854, %v72850 (stack47)
        %v72858 = vadd.s32 %v72855, %v72850 (stack39)
        %v72862 = vadd.s32 %v72858, %v10 (stack39)
        %v72864 = vshll.u32 %v72855, 6 (stack44)
        %v72865 = vshrl.u32 %v72855, 26 (stack45)
        %v72866 = vor.u32 %v72865, %v72864 (stack46)
        %v72867 = vxor.u32 %v72866, %v72858 (stack47)
        %v72870 = vadd.s32 %v72867, %v9 (stack39)
        %v72874 = vadd.s32 3, %v72870 (stack39)
        %v72878 = vadd.s32 %v72874, %v72862 (stack39)
        %v72880 = vshll.u32 %v72874, 17 (stack44)
        %v72881 = vshrl.u32 %v72874, 15 (stack45)
        %v72882 = vor.u32 %v72881, %v72880 (stack46)
        %v72883 = vxor.u32 %v72882, %v72878 (stack47)
        %v72886 = vadd.s32 %v72883, %v72878 (stack39)
        %v72888 = vshll.u32 %v72883, 29 (stack44)
        %v72889 = vshrl.u32 %v72883, 3 (stack45)
        %v72890 = vor.u32 %v72889, %v72888 (stack46)
        %v72891 = vxor.u32 %v72890, %v72886 (stack47)
        %v72894 = vadd.s32 %v72891, %v72886 (stack39)
        %v72896 = vshll.u32 %v72891, 16 (stack44)
        %v72897 = vshrl.u32 %v72891, 16 (stack45)
        %v72898 = vor.u32 %v72897, %v72896 (stack46)
        %v72899 = vxor.u32 %v72898, %v72894 (stack47)
        %v72902 = vadd.s32 %v72899, %v72894 (stack39)
        %v72906 = vadd.s32 %v72902, %v9 (stack39)
        %v72908 = vshll.u32 %v72899, 24 (stack44)
        %v72909 = vshrl.u32 %v72899, 8 (stack45)
        %v72910 = vor.u32 %v72909, %v72908 (stack46)
        %v72911 = vxor.u32 %v72910, %v72902 (stack47)
        %v72914 = vadd.s32 %v72911, %v8 (stack39)
        %v72918 = vadd.s32 4, %v72914 (stack39)
        %v72922 = vadd.s32 %v72918, %v72906 (stack39)
        %v72924 = vshll.u32 %v72918, 13 (stack44)
        %v72925 = vshrl.u32 %v72918, 19 (stack45)
        %v72926 = vor.u32 %v72925, %v72924 (stack46)
        %v72927 = vxor.u32 %v72926, %v72922 (stack47)
        %v72930 = vadd.s32 %v72927, %v72922 (stack39)
        %v72932 = vshll.u32 %v72927, 15 (stack44)
        %v72933 = vshrl.u32 %v72927, 17 (stack45)
        %v72934 = vor.u32 %v72933, %v72932 (stack46)
        %v72935 = vxor.u32 %v72934, %v72930 (stack47)
        %v72938 = vadd.s32 %v72935, %v72930 (stack39)
        %v72940 = vshll.u32 %v72935, 26 (stack44)
        %v72941 = vshrl.u32 %v72935, 6 (stack45)
        %v72942 = vor.u32 %v72941, %v72940 (stack46)
        %v72943 = vxor.u32 %v72942, %v72938 (stack47)
        %v72946 = vadd.s32 %v72943, %v72938 (stack39)
        %v72950 = vadd.s32 %v72946, %v8 (stack39)
        %v72952 = vshll.u32 %v72943, 6 (stack44)
        %v72953 = vshrl.u32 %v72943, 26 (stack45)
        %v72954 = vor.u32 %v72953, %v72952 (stack46)
        %v72955 = vxor.u32 %v72954, %v72946 (stack47)
        %v72958 = vadd.s32 %v72955, %v10 (stack39)
        %v72962 = vadd.s32 5, %v72958 (stack39)
        %v72964 = vxor.u32 %v72962, %v72950 (stack47)
        %v72965 = vand.u32.u8 255, %v72964 (stack48)
        %v72966 = vand.u32 65535, %v72965 (stack49)
        %v72967 = vshrl.u32 %v72966, 1 (stack50)
        %v72968 = vor.u32 16256, %v72967 (stack46)
        %v72969 = vand.u32.u16 65535, %v72968 (stack51)
        %v120134 = vadd.low.f32.bf16 -1.0, %v72969 (stack52)
        %v72978 = vmul.f32 2.0, %v120134 (stack53)
        %v72982 = vadd.f32 -0.99609375, %v72978 (stack52)
        %v72986 = vmax.f32 %v72982, -0.99609375 (stack54)
        %v72988 = vand.u32 2147483647, %v72986 (stack55)
        %vm72991 = vcmp.eq.f32.partialorder %v72988, 1.0 (stack56)
        %v72996 = vmul.f32 inf, %v72986 (stack53)
        %v72998 = vxor.u32 2147483648, %v72986 (stack57)
        %v73001 = vmul.f32 %v72998, %v72986 (stack53)
        %v73003 = vadd.f32 1.0, %v73001 (stack58)
        %v73004 = vlog2.pop %v73003 (stack59)
        %v73005 = vmul.f32 0.6931472, %v73004 (stack60)
        %v73006 = vmul.f32 -0.5, %v73001 (stack61)
        %v73007 = vadd.f32 1.0, %v73006 (stack62)
        %v73008 = vmul.f32 %v73007, %v73001 (stack63)
        %v73009 = vand.u32 2147483647, %v73001 (stack64)
        %vm73010 = vcmp.lt.f32.partialorder %v73009, 0.0004427343 (stack65)
        %v73011 = vsel /*vm=*/%vm73010, /*on_true_vy=*/%v73008, /*on_false_vx=*/%v73005 (stack66)
        %v73012 = vxor.u32 2147483648, %v73011 (stack57)
        %vm73015 = vcmp.lt.f32.partialorder %v73012, 5.0 (stack56)
        %v73020 = vsel /*vm=*/%vm73015, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v73024 = vsel /*vm=*/%vm73015, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v73028 = vsel /*vm=*/%vm73015, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v73032 = vsel /*vm=*/%vm73015, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v73036 = vsel /*vm=*/%vm73015, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v73040 = vsel /*vm=*/%vm73015, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v73044 = vsel /*vm=*/%vm73015, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v73048 = vsel /*vm=*/%vm73015, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v73052 = vsel /*vm=*/%vm73015, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v73056 = vadd.f32 -2.5, %v73012 (stack52)
        %v73058 = vrsqrt.pop %v73012 (stack67)
        %v73059 = vmul.f32 %v73058, %v73012 (stack68)
        %vm73060 = vcmp.eq.f32.partialorder %v73012, inf (stack69)
        %v73061 = vsel /*vm=*/%vm73060, /*on_true_vy=*/%v73012, /*on_false_vx=*/%v73059 (stack70)
        %vm73062 = vcmp.eq.f32.partialorder %v73012, 0.0 (stack71)
        %v73063 = vand.u32 2147483648, %v73012 (stack72)
        %v73064 = vsel /*vm=*/%vm73062, /*on_true_vy=*/%v73063, /*on_false_vx=*/%v73061 (stack73)
        %v73067 = vadd.f32 -3.0, %v73064 (stack52)
        %v73071 = vsel /*vm=*/%vm73015, /*on_true_vy=*/%v73056, /*on_false_vx=*/%v73067 (stack43)
        %v73075 = vmul.f32 %v73071, %v73052 (stack53)
        %v73079 = vadd.f32 %v73075, %v73048 (stack52)
        %v73083 = vmul.f32 %v73079, %v73071 (stack53)
        %v73087 = vadd.f32 %v73083, %v73044 (stack52)
        %v73091 = vmul.f32 %v73087, %v73071 (stack53)
        %v73095 = vadd.f32 %v73091, %v73040 (stack52)
        %v73099 = vmul.f32 %v73095, %v73071 (stack53)
        %v73103 = vadd.f32 %v73099, %v73036 (stack52)
        %v73107 = vmul.f32 %v73103, %v73071 (stack53)
        %v73111 = vadd.f32 %v73107, %v73032 (stack52)
        %v73115 = vmul.f32 %v73111, %v73071 (stack53)
        %v73119 = vadd.f32 %v73115, %v73028 (stack52)
        %v73123 = vmul.f32 %v73119, %v73071 (stack53)
        %v73127 = vadd.f32 %v73123, %v73024 (stack52)
        %v73131 = vmul.f32 %v73127, %v73071 (stack53)
        %v73135 = vadd.f32 %v73131, %v73020 (stack52)
        %v73139 = vmul.f32 %v73135, %v72986 (stack53)
        %v73143 = vsel /*vm=*/%vm72991, /*on_true_vy=*/%v72996, /*on_false_vx=*/%v73139 (stack43)
        %v73147 = vmul.f32 1.4140625, %v73143 (stack53)
        %v73150 = vpack.c.bf16 0.0, %v73147 (stack74)
        %120135 = vst [vmem:[%s280 + $0x1cc] sm:$0xf] /*vst_source=*/%v73150 (stack75)
        %v73154 = vadd.s32 %v71307, %v2355 (stack39)
        %v73164 = vadd.s32 %v73154, %v415 (stack39)
        %vm73168 = vcmp.lt.u32.totalorder %v73164, %v73154 (stack42)
        %vm73173 = vcmp.lt.u32.totalorder %v73154, %v2355 (stack42)
        %v73178 = vadd.s32 %v71290, %v2342 (stack39)
        %v73182 = vadd.s32 1, %v73178 (stack39)
        %v73186 = vsel /*vm=*/%vm73173, /*on_true_vy=*/%v73182, /*on_false_vx=*/%v73178 (stack43)
        %v73190 = vadd.s32 1, %v73186 (stack39)
        %v73194 = vsel /*vm=*/%vm73168, /*on_true_vy=*/%v73190, /*on_false_vx=*/%v73186 (stack43)
        %v73199 = vadd.s32 %v73194, %v10 (stack39)
        %v73203 = vadd.s32 %v73164, %v9 (stack39)
        %v73207 = vadd.s32 %v73203, %v73199 (stack39)
        %v73209 = vshll.u32 %v73203, 13 (stack44)
        %v73210 = vshrl.u32 %v73203, 19 (stack45)
        %v73211 = vor.u32 %v73210, %v73209 (stack46)
        %v73212 = vxor.u32 %v73211, %v73207 (stack47)
        %v73215 = vadd.s32 %v73212, %v73207 (stack39)
        %v73217 = vshll.u32 %v73212, 15 (stack44)
        %v73218 = vshrl.u32 %v73212, 17 (stack45)
        %v73219 = vor.u32 %v73218, %v73217 (stack46)
        %v73220 = vxor.u32 %v73219, %v73215 (stack47)
        %v73223 = vadd.s32 %v73220, %v73215 (stack39)
        %v73225 = vshll.u32 %v73220, 26 (stack44)
        %v73226 = vshrl.u32 %v73220, 6 (stack45)
        %v73227 = vor.u32 %v73226, %v73225 (stack46)
        %v73228 = vxor.u32 %v73227, %v73223 (stack47)
        %v73231 = vadd.s32 %v73228, %v73223 (stack39)
        %v73235 = vadd.s32 %v73231, %v9 (stack39)
        %v73237 = vshll.u32 %v73228, 6 (stack44)
        %v73238 = vshrl.u32 %v73228, 26 (stack45)
        %v73239 = vor.u32 %v73238, %v73237 (stack46)
        %v73240 = vxor.u32 %v73239, %v73231 (stack47)
        %v73243 = vadd.s32 %v73240, %v8 (stack39)
        %v73247 = vadd.s32 1, %v73243 (stack39)
        %v73251 = vadd.s32 %v73247, %v73235 (stack39)
        %v73253 = vshll.u32 %v73247, 17 (stack44)
        %v73254 = vshrl.u32 %v73247, 15 (stack45)
        %v73255 = vor.u32 %v73254, %v73253 (stack46)
        %v73256 = vxor.u32 %v73255, %v73251 (stack47)
        %v73259 = vadd.s32 %v73256, %v73251 (stack39)
        %v73261 = vshll.u32 %v73256, 29 (stack44)
        %v73262 = vshrl.u32 %v73256, 3 (stack45)
        %v73263 = vor.u32 %v73262, %v73261 (stack46)
        %v73264 = vxor.u32 %v73263, %v73259 (stack47)
        %v73267 = vadd.s32 %v73264, %v73259 (stack39)
        %v73269 = vshll.u32 %v73264, 16 (stack44)
        %v73270 = vshrl.u32 %v73264, 16 (stack45)
        %v73271 = vor.u32 %v73270, %v73269 (stack46)
        %v73272 = vxor.u32 %v73271, %v73267 (stack47)
        %v73275 = vadd.s32 %v73272, %v73267 (stack39)
        %v73279 = vadd.s32 %v73275, %v8 (stack39)
        %v73281 = vshll.u32 %v73272, 24 (stack44)
        %v73282 = vshrl.u32 %v73272, 8 (stack45)
        %v73283 = vor.u32 %v73282, %v73281 (stack46)
        %v73284 = vxor.u32 %v73283, %v73275 (stack47)
        %v73287 = vadd.s32 %v73284, %v10 (stack39)
        %v73291 = vadd.s32 2, %v73287 (stack39)
        %v73295 = vadd.s32 %v73291, %v73279 (stack39)
        %v73297 = vshll.u32 %v73291, 13 (stack44)
        %v73298 = vshrl.u32 %v73291, 19 (stack45)
        %v73299 = vor.u32 %v73298, %v73297 (stack46)
        %v73300 = vxor.u32 %v73299, %v73295 (stack47)
        %v73303 = vadd.s32 %v73300, %v73295 (stack39)
        %v73305 = vshll.u32 %v73300, 15 (stack44)
        %v73306 = vshrl.u32 %v73300, 17 (stack45)
        %v73307 = vor.u32 %v73306, %v73305 (stack46)
        %v73308 = vxor.u32 %v73307, %v73303 (stack47)
        %v73311 = vadd.s32 %v73308, %v73303 (stack39)
        %v73313 = vshll.u32 %v73308, 26 (stack44)
        %v73314 = vshrl.u32 %v73308, 6 (stack45)
        %v73315 = vor.u32 %v73314, %v73313 (stack46)
        %v73316 = vxor.u32 %v73315, %v73311 (stack47)
        %v73319 = vadd.s32 %v73316, %v73311 (stack39)
        %v73323 = vadd.s32 %v73319, %v10 (stack39)
        %v73325 = vshll.u32 %v73316, 6 (stack44)
        %v73326 = vshrl.u32 %v73316, 26 (stack45)
        %v73327 = vor.u32 %v73326, %v73325 (stack46)
        %v73328 = vxor.u32 %v73327, %v73319 (stack47)
        %v73331 = vadd.s32 %v73328, %v9 (stack39)
        %v73335 = vadd.s32 3, %v73331 (stack39)
        %v73339 = vadd.s32 %v73335, %v73323 (stack39)
        %v73341 = vshll.u32 %v73335, 17 (stack44)
        %v73342 = vshrl.u32 %v73335, 15 (stack45)
        %v73343 = vor.u32 %v73342, %v73341 (stack46)
        %v73344 = vxor.u32 %v73343, %v73339 (stack47)
        %v73347 = vadd.s32 %v73344, %v73339 (stack39)
        %v73349 = vshll.u32 %v73344, 29 (stack44)
        %v73350 = vshrl.u32 %v73344, 3 (stack45)
        %v73351 = vor.u32 %v73350, %v73349 (stack46)
        %v73352 = vxor.u32 %v73351, %v73347 (stack47)
        %v73355 = vadd.s32 %v73352, %v73347 (stack39)
        %v73357 = vshll.u32 %v73352, 16 (stack44)
        %v73358 = vshrl.u32 %v73352, 16 (stack45)
        %v73359 = vor.u32 %v73358, %v73357 (stack46)
        %v73360 = vxor.u32 %v73359, %v73355 (stack47)
        %v73363 = vadd.s32 %v73360, %v73355 (stack39)
        %v73367 = vadd.s32 %v73363, %v9 (stack39)
        %v73369 = vshll.u32 %v73360, 24 (stack44)
        %v73370 = vshrl.u32 %v73360, 8 (stack45)
        %v73371 = vor.u32 %v73370, %v73369 (stack46)
        %v73372 = vxor.u32 %v73371, %v73363 (stack47)
        %v73375 = vadd.s32 %v73372, %v8 (stack39)
        %v73379 = vadd.s32 4, %v73375 (stack39)
        %v73383 = vadd.s32 %v73379, %v73367 (stack39)
        %v73385 = vshll.u32 %v73379, 13 (stack44)
        %v73386 = vshrl.u32 %v73379, 19 (stack45)
        %v73387 = vor.u32 %v73386, %v73385 (stack46)
        %v73388 = vxor.u32 %v73387, %v73383 (stack47)
        %v73391 = vadd.s32 %v73388, %v73383 (stack39)
        %v73393 = vshll.u32 %v73388, 15 (stack44)
        %v73394 = vshrl.u32 %v73388, 17 (stack45)
        %v73395 = vor.u32 %v73394, %v73393 (stack46)
        %v73396 = vxor.u32 %v73395, %v73391 (stack47)
        %v73399 = vadd.s32 %v73396, %v73391 (stack39)
        %v73401 = vshll.u32 %v73396, 26 (stack44)
        %v73402 = vshrl.u32 %v73396, 6 (stack45)
        %v73403 = vor.u32 %v73402, %v73401 (stack46)
        %v73404 = vxor.u32 %v73403, %v73399 (stack47)
        %v73407 = vadd.s32 %v73404, %v73399 (stack39)
        %v73411 = vadd.s32 %v73407, %v8 (stack39)
        %v73413 = vshll.u32 %v73404, 6 (stack44)
        %v73414 = vshrl.u32 %v73404, 26 (stack45)
        %v73415 = vor.u32 %v73414, %v73413 (stack46)
        %v73416 = vxor.u32 %v73415, %v73407 (stack47)
        %v73419 = vadd.s32 %v73416, %v10 (stack39)
        %v73423 = vadd.s32 5, %v73419 (stack39)
        %v73425 = vxor.u32 %v73423, %v73411 (stack47)
        %v73426 = vand.u32.u8 255, %v73425 (stack48)
        %v73427 = vand.u32 65535, %v73426 (stack49)
        %v73428 = vshrl.u32 %v73427, 1 (stack50)
        %v73429 = vor.u32 16256, %v73428 (stack46)
        %v73430 = vand.u32.u16 65535, %v73429 (stack51)
        %v120136 = vadd.low.f32.bf16 -1.0, %v73430 (stack52)
        %v73439 = vmul.f32 2.0, %v120136 (stack53)
        %v73443 = vadd.f32 -0.99609375, %v73439 (stack52)
        %v73447 = vmax.f32 %v73443, -0.99609375 (stack54)
        %v73449 = vand.u32 2147483647, %v73447 (stack55)
        %vm73452 = vcmp.eq.f32.partialorder %v73449, 1.0 (stack56)
        %v73457 = vmul.f32 inf, %v73447 (stack53)
        %v73459 = vxor.u32 2147483648, %v73447 (stack57)
        %v73462 = vmul.f32 %v73459, %v73447 (stack53)
        %v73464 = vadd.f32 1.0, %v73462 (stack58)
        %v73465 = vlog2.pop %v73464 (stack59)
        %v73466 = vmul.f32 0.6931472, %v73465 (stack60)
        %v73467 = vmul.f32 -0.5, %v73462 (stack61)
        %v73468 = vadd.f32 1.0, %v73467 (stack62)
        %v73469 = vmul.f32 %v73468, %v73462 (stack63)
        %v73470 = vand.u32 2147483647, %v73462 (stack64)
        %vm73471 = vcmp.lt.f32.partialorder %v73470, 0.0004427343 (stack65)
        %v73472 = vsel /*vm=*/%vm73471, /*on_true_vy=*/%v73469, /*on_false_vx=*/%v73466 (stack66)
        %v73473 = vxor.u32 2147483648, %v73472 (stack57)
        %vm73476 = vcmp.lt.f32.partialorder %v73473, 5.0 (stack56)
        %v73481 = vsel /*vm=*/%vm73476, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v73485 = vsel /*vm=*/%vm73476, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v73489 = vsel /*vm=*/%vm73476, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v73493 = vsel /*vm=*/%vm73476, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v73497 = vsel /*vm=*/%vm73476, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v73501 = vsel /*vm=*/%vm73476, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v73505 = vsel /*vm=*/%vm73476, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v73509 = vsel /*vm=*/%vm73476, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v73513 = vsel /*vm=*/%vm73476, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v73517 = vadd.f32 -2.5, %v73473 (stack52)
        %v73519 = vrsqrt.pop %v73473 (stack67)
        %v73520 = vmul.f32 %v73519, %v73473 (stack68)
        %vm73521 = vcmp.eq.f32.partialorder %v73473, inf (stack69)
        %v73522 = vsel /*vm=*/%vm73521, /*on_true_vy=*/%v73473, /*on_false_vx=*/%v73520 (stack70)
        %vm73523 = vcmp.eq.f32.partialorder %v73473, 0.0 (stack71)
        %v73524 = vand.u32 2147483648, %v73473 (stack72)
        %v73525 = vsel /*vm=*/%vm73523, /*on_true_vy=*/%v73524, /*on_false_vx=*/%v73522 (stack73)
        %v73528 = vadd.f32 -3.0, %v73525 (stack52)
        %v73532 = vsel /*vm=*/%vm73476, /*on_true_vy=*/%v73517, /*on_false_vx=*/%v73528 (stack43)
        %v73536 = vmul.f32 %v73532, %v73513 (stack53)
        %v73540 = vadd.f32 %v73536, %v73509 (stack52)
        %v73544 = vmul.f32 %v73540, %v73532 (stack53)
        %v73548 = vadd.f32 %v73544, %v73505 (stack52)
        %v73552 = vmul.f32 %v73548, %v73532 (stack53)
        %v73556 = vadd.f32 %v73552, %v73501 (stack52)
        %v73560 = vmul.f32 %v73556, %v73532 (stack53)
        %v73564 = vadd.f32 %v73560, %v73497 (stack52)
        %v73568 = vmul.f32 %v73564, %v73532 (stack53)
        %v73572 = vadd.f32 %v73568, %v73493 (stack52)
        %v73576 = vmul.f32 %v73572, %v73532 (stack53)
        %v73580 = vadd.f32 %v73576, %v73489 (stack52)
        %v73584 = vmul.f32 %v73580, %v73532 (stack53)
        %v73588 = vadd.f32 %v73584, %v73485 (stack52)
        %v73592 = vmul.f32 %v73588, %v73532 (stack53)
        %v73596 = vadd.f32 %v73592, %v73481 (stack52)
        %v73600 = vmul.f32 %v73596, %v73447 (stack53)
        %v73604 = vsel /*vm=*/%vm73452, /*on_true_vy=*/%v73457, /*on_false_vx=*/%v73600 (stack43)
        %v73608 = vmul.f32 1.4140625, %v73604 (stack53)
        %v73611 = vpack.c.bf16 0.0, %v73608 (stack74)
        %120137 = vst [vmem:[%s280 + $0x24c] sm:$0xf] /*vst_source=*/%v73611 (stack75)
        %v73615 = vadd.s32 %v71307, %v2842 (stack39)
        %v73625 = vadd.s32 %v73615, %v415 (stack39)
        %vm73629 = vcmp.lt.u32.totalorder %v73625, %v73615 (stack42)
        %vm73634 = vcmp.lt.u32.totalorder %v73615, %v2842 (stack42)
        %v73639 = vadd.s32 %v71290, %v2829 (stack39)
        %v73643 = vadd.s32 1, %v73639 (stack39)
        %v73647 = vsel /*vm=*/%vm73634, /*on_true_vy=*/%v73643, /*on_false_vx=*/%v73639 (stack43)
        %v73651 = vadd.s32 1, %v73647 (stack39)
        %v73655 = vsel /*vm=*/%vm73629, /*on_true_vy=*/%v73651, /*on_false_vx=*/%v73647 (stack43)
        %v73660 = vadd.s32 %v73655, %v10 (stack39)
        %v73664 = vadd.s32 %v73625, %v9 (stack39)
        %v73668 = vadd.s32 %v73664, %v73660 (stack39)
        %v73670 = vshll.u32 %v73664, 13 (stack44)
        %v73671 = vshrl.u32 %v73664, 19 (stack45)
        %v73672 = vor.u32 %v73671, %v73670 (stack46)
        %v73673 = vxor.u32 %v73672, %v73668 (stack47)
        %v73676 = vadd.s32 %v73673, %v73668 (stack39)
        %v73678 = vshll.u32 %v73673, 15 (stack44)
        %v73679 = vshrl.u32 %v73673, 17 (stack45)
        %v73680 = vor.u32 %v73679, %v73678 (stack46)
        %v73681 = vxor.u32 %v73680, %v73676 (stack47)
        %v73684 = vadd.s32 %v73681, %v73676 (stack39)
        %v73686 = vshll.u32 %v73681, 26 (stack44)
        %v73687 = vshrl.u32 %v73681, 6 (stack45)
        %v73688 = vor.u32 %v73687, %v73686 (stack46)
        %v73689 = vxor.u32 %v73688, %v73684 (stack47)
        %v73692 = vadd.s32 %v73689, %v73684 (stack39)
        %v73696 = vadd.s32 %v73692, %v9 (stack39)
        %v73698 = vshll.u32 %v73689, 6 (stack44)
        %v73699 = vshrl.u32 %v73689, 26 (stack45)
        %v73700 = vor.u32 %v73699, %v73698 (stack46)
        %v73701 = vxor.u32 %v73700, %v73692 (stack47)
        %v73704 = vadd.s32 %v73701, %v8 (stack39)
        %v73708 = vadd.s32 1, %v73704 (stack39)
        %v73712 = vadd.s32 %v73708, %v73696 (stack39)
        %v73714 = vshll.u32 %v73708, 17 (stack44)
        %v73715 = vshrl.u32 %v73708, 15 (stack45)
        %v73716 = vor.u32 %v73715, %v73714 (stack46)
        %v73717 = vxor.u32 %v73716, %v73712 (stack47)
        %v73720 = vadd.s32 %v73717, %v73712 (stack39)
        %v73722 = vshll.u32 %v73717, 29 (stack44)
        %v73723 = vshrl.u32 %v73717, 3 (stack45)
        %v73724 = vor.u32 %v73723, %v73722 (stack46)
        %v73725 = vxor.u32 %v73724, %v73720 (stack47)
        %v73728 = vadd.s32 %v73725, %v73720 (stack39)
        %v73730 = vshll.u32 %v73725, 16 (stack44)
        %v73731 = vshrl.u32 %v73725, 16 (stack45)
        %v73732 = vor.u32 %v73731, %v73730 (stack46)
        %v73733 = vxor.u32 %v73732, %v73728 (stack47)
        %v73736 = vadd.s32 %v73733, %v73728 (stack39)
        %v73740 = vadd.s32 %v73736, %v8 (stack39)
        %v73742 = vshll.u32 %v73733, 24 (stack44)
        %v73743 = vshrl.u32 %v73733, 8 (stack45)
        %v73744 = vor.u32 %v73743, %v73742 (stack46)
        %v73745 = vxor.u32 %v73744, %v73736 (stack47)
        %v73748 = vadd.s32 %v73745, %v10 (stack39)
        %v73752 = vadd.s32 2, %v73748 (stack39)
        %v73756 = vadd.s32 %v73752, %v73740 (stack39)
        %v73758 = vshll.u32 %v73752, 13 (stack44)
        %v73759 = vshrl.u32 %v73752, 19 (stack45)
        %v73760 = vor.u32 %v73759, %v73758 (stack46)
        %v73761 = vxor.u32 %v73760, %v73756 (stack47)
        %v73764 = vadd.s32 %v73761, %v73756 (stack39)
        %v73766 = vshll.u32 %v73761, 15 (stack44)
        %v73767 = vshrl.u32 %v73761, 17 (stack45)
        %v73768 = vor.u32 %v73767, %v73766 (stack46)
        %v73769 = vxor.u32 %v73768, %v73764 (stack47)
        %v73772 = vadd.s32 %v73769, %v73764 (stack39)
        %v73774 = vshll.u32 %v73769, 26 (stack44)
        %v73775 = vshrl.u32 %v73769, 6 (stack45)
        %v73776 = vor.u32 %v73775, %v73774 (stack46)
        %v73777 = vxor.u32 %v73776, %v73772 (stack47)
        %v73780 = vadd.s32 %v73777, %v73772 (stack39)
        %v73784 = vadd.s32 %v73780, %v10 (stack39)
        %v73786 = vshll.u32 %v73777, 6 (stack44)
        %v73787 = vshrl.u32 %v73777, 26 (stack45)
        %v73788 = vor.u32 %v73787, %v73786 (stack46)
        %v73789 = vxor.u32 %v73788, %v73780 (stack47)
        %v73792 = vadd.s32 %v73789, %v9 (stack39)
        %v73796 = vadd.s32 3, %v73792 (stack39)
        %v73800 = vadd.s32 %v73796, %v73784 (stack39)
        %v73802 = vshll.u32 %v73796, 17 (stack44)
        %v73803 = vshrl.u32 %v73796, 15 (stack45)
        %v73804 = vor.u32 %v73803, %v73802 (stack46)
        %v73805 = vxor.u32 %v73804, %v73800 (stack47)
        %v73808 = vadd.s32 %v73805, %v73800 (stack39)
        %v73810 = vshll.u32 %v73805, 29 (stack44)
        %v73811 = vshrl.u32 %v73805, 3 (stack45)
        %v73812 = vor.u32 %v73811, %v73810 (stack46)
        %v73813 = vxor.u32 %v73812, %v73808 (stack47)
        %v73816 = vadd.s32 %v73813, %v73808 (stack39)
        %v73818 = vshll.u32 %v73813, 16 (stack44)
        %v73819 = vshrl.u32 %v73813, 16 (stack45)
        %v73820 = vor.u32 %v73819, %v73818 (stack46)
        %v73821 = vxor.u32 %v73820, %v73816 (stack47)
        %v73824 = vadd.s32 %v73821, %v73816 (stack39)
        %v73828 = vadd.s32 %v73824, %v9 (stack39)
        %v73830 = vshll.u32 %v73821, 24 (stack44)
        %v73831 = vshrl.u32 %v73821, 8 (stack45)
        %v73832 = vor.u32 %v73831, %v73830 (stack46)
        %v73833 = vxor.u32 %v73832, %v73824 (stack47)
        %v73836 = vadd.s32 %v73833, %v8 (stack39)
        %v73840 = vadd.s32 4, %v73836 (stack39)
        %v73844 = vadd.s32 %v73840, %v73828 (stack39)
        %v73846 = vshll.u32 %v73840, 13 (stack44)
        %v73847 = vshrl.u32 %v73840, 19 (stack45)
        %v73848 = vor.u32 %v73847, %v73846 (stack46)
        %v73849 = vxor.u32 %v73848, %v73844 (stack47)
        %v73852 = vadd.s32 %v73849, %v73844 (stack39)
        %v73854 = vshll.u32 %v73849, 15 (stack44)
        %v73855 = vshrl.u32 %v73849, 17 (stack45)
        %v73856 = vor.u32 %v73855, %v73854 (stack46)
        %v73857 = vxor.u32 %v73856, %v73852 (stack47)
        %v73860 = vadd.s32 %v73857, %v73852 (stack39)
        %v73862 = vshll.u32 %v73857, 26 (stack44)
        %v73863 = vshrl.u32 %v73857, 6 (stack45)
        %v73864 = vor.u32 %v73863, %v73862 (stack46)
        %v73865 = vxor.u32 %v73864, %v73860 (stack47)
        %v73868 = vadd.s32 %v73865, %v73860 (stack39)
        %v73872 = vadd.s32 %v73868, %v8 (stack39)
        %v73874 = vshll.u32 %v73865, 6 (stack44)
        %v73875 = vshrl.u32 %v73865, 26 (stack45)
        %v73876 = vor.u32 %v73875, %v73874 (stack46)
        %v73877 = vxor.u32 %v73876, %v73868 (stack47)
        %v73880 = vadd.s32 %v73877, %v10 (stack39)
        %v73884 = vadd.s32 5, %v73880 (stack39)
        %v73886 = vxor.u32 %v73884, %v73872 (stack47)
        %v73887 = vand.u32.u8 255, %v73886 (stack48)
        %v73888 = vand.u32 65535, %v73887 (stack49)
        %v73889 = vshrl.u32 %v73888, 1 (stack50)
        %v73890 = vor.u32 16256, %v73889 (stack46)
        %v73891 = vand.u32.u16 65535, %v73890 (stack51)
        %v120138 = vadd.low.f32.bf16 -1.0, %v73891 (stack52)
        %v73900 = vmul.f32 2.0, %v120138 (stack53)
        %v73904 = vadd.f32 -0.99609375, %v73900 (stack52)
        %v73908 = vmax.f32 %v73904, -0.99609375 (stack54)
        %v73910 = vand.u32 2147483647, %v73908 (stack55)
        %vm73913 = vcmp.eq.f32.partialorder %v73910, 1.0 (stack56)
        %v73918 = vmul.f32 inf, %v73908 (stack53)
        %v73920 = vxor.u32 2147483648, %v73908 (stack57)
        %v73923 = vmul.f32 %v73920, %v73908 (stack53)
        %v73925 = vadd.f32 1.0, %v73923 (stack58)
        %v73926 = vlog2.pop %v73925 (stack59)
        %v73927 = vmul.f32 0.6931472, %v73926 (stack60)
        %v73928 = vmul.f32 -0.5, %v73923 (stack61)
        %v73929 = vadd.f32 1.0, %v73928 (stack62)
        %v73930 = vmul.f32 %v73929, %v73923 (stack63)
        %v73931 = vand.u32 2147483647, %v73923 (stack64)
        %vm73932 = vcmp.lt.f32.partialorder %v73931, 0.0004427343 (stack65)
        %v73933 = vsel /*vm=*/%vm73932, /*on_true_vy=*/%v73930, /*on_false_vx=*/%v73927 (stack66)
        %v73934 = vxor.u32 2147483648, %v73933 (stack57)
        %vm73937 = vcmp.lt.f32.partialorder %v73934, 5.0 (stack56)
        %v73942 = vsel /*vm=*/%vm73937, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v73946 = vsel /*vm=*/%vm73937, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v73950 = vsel /*vm=*/%vm73937, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v73954 = vsel /*vm=*/%vm73937, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v73958 = vsel /*vm=*/%vm73937, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v73962 = vsel /*vm=*/%vm73937, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v73966 = vsel /*vm=*/%vm73937, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v73970 = vsel /*vm=*/%vm73937, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v73974 = vsel /*vm=*/%vm73937, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v73978 = vadd.f32 -2.5, %v73934 (stack52)
        %v73980 = vrsqrt.pop %v73934 (stack67)
        %v73981 = vmul.f32 %v73980, %v73934 (stack68)
        %vm73982 = vcmp.eq.f32.partialorder %v73934, inf (stack69)
        %v73983 = vsel /*vm=*/%vm73982, /*on_true_vy=*/%v73934, /*on_false_vx=*/%v73981 (stack70)
        %vm73984 = vcmp.eq.f32.partialorder %v73934, 0.0 (stack71)
        %v73985 = vand.u32 2147483648, %v73934 (stack72)
        %v73986 = vsel /*vm=*/%vm73984, /*on_true_vy=*/%v73985, /*on_false_vx=*/%v73983 (stack73)
        %v73989 = vadd.f32 -3.0, %v73986 (stack52)
        %v73993 = vsel /*vm=*/%vm73937, /*on_true_vy=*/%v73978, /*on_false_vx=*/%v73989 (stack43)
        %v73997 = vmul.f32 %v73993, %v73974 (stack53)
        %v74001 = vadd.f32 %v73997, %v73970 (stack52)
        %v74005 = vmul.f32 %v74001, %v73993 (stack53)
        %v74009 = vadd.f32 %v74005, %v73966 (stack52)
        %v74013 = vmul.f32 %v74009, %v73993 (stack53)
        %v74017 = vadd.f32 %v74013, %v73962 (stack52)
        %v74021 = vmul.f32 %v74017, %v73993 (stack53)
        %v74025 = vadd.f32 %v74021, %v73958 (stack52)
        %v74029 = vmul.f32 %v74025, %v73993 (stack53)
        %v74033 = vadd.f32 %v74029, %v73954 (stack52)
        %v74037 = vmul.f32 %v74033, %v73993 (stack53)
        %v74041 = vadd.f32 %v74037, %v73950 (stack52)
        %v74045 = vmul.f32 %v74041, %v73993 (stack53)
        %v74049 = vadd.f32 %v74045, %v73946 (stack52)
        %v74053 = vmul.f32 %v74049, %v73993 (stack53)
        %v74057 = vadd.f32 %v74053, %v73942 (stack52)
        %v74061 = vmul.f32 %v74057, %v73908 (stack53)
        %v74065 = vsel /*vm=*/%vm73913, /*on_true_vy=*/%v73918, /*on_false_vx=*/%v74061 (stack43)
        %v74069 = vmul.f32 1.4140625, %v74065 (stack53)
        %v74072 = vpack.c.bf16 0.0, %v74069 (stack74)
        %120139 = vst [vmem:[%s280 + $0x2cc] sm:$0xf] /*vst_source=*/%v74072 (stack75)
        %v74076 = vadd.s32 %v71307, %v3329 (stack39)
        %v74086 = vadd.s32 %v74076, %v415 (stack39)
        %vm74090 = vcmp.lt.u32.totalorder %v74086, %v74076 (stack42)
        %vm74095 = vcmp.lt.u32.totalorder %v74076, %v3329 (stack42)
        %v74100 = vadd.s32 %v71290, %v3316 (stack39)
        %v74104 = vadd.s32 1, %v74100 (stack39)
        %v74108 = vsel /*vm=*/%vm74095, /*on_true_vy=*/%v74104, /*on_false_vx=*/%v74100 (stack43)
        %v74112 = vadd.s32 1, %v74108 (stack39)
        %v74116 = vsel /*vm=*/%vm74090, /*on_true_vy=*/%v74112, /*on_false_vx=*/%v74108 (stack43)
        %v74121 = vadd.s32 %v74116, %v10 (stack39)
        %v74125 = vadd.s32 %v74086, %v9 (stack39)
        %v74129 = vadd.s32 %v74125, %v74121 (stack39)
        %v74131 = vshll.u32 %v74125, 13 (stack44)
        %v74132 = vshrl.u32 %v74125, 19 (stack45)
        %v74133 = vor.u32 %v74132, %v74131 (stack46)
        %v74134 = vxor.u32 %v74133, %v74129 (stack47)
        %v74137 = vadd.s32 %v74134, %v74129 (stack39)
        %v74139 = vshll.u32 %v74134, 15 (stack44)
        %v74140 = vshrl.u32 %v74134, 17 (stack45)
        %v74141 = vor.u32 %v74140, %v74139 (stack46)
        %v74142 = vxor.u32 %v74141, %v74137 (stack47)
        %v74145 = vadd.s32 %v74142, %v74137 (stack39)
        %v74147 = vshll.u32 %v74142, 26 (stack44)
        %v74148 = vshrl.u32 %v74142, 6 (stack45)
        %v74149 = vor.u32 %v74148, %v74147 (stack46)
        %v74150 = vxor.u32 %v74149, %v74145 (stack47)
        %v74153 = vadd.s32 %v74150, %v74145 (stack39)
        %v74157 = vadd.s32 %v74153, %v9 (stack39)
        %v74159 = vshll.u32 %v74150, 6 (stack44)
        %v74160 = vshrl.u32 %v74150, 26 (stack45)
        %v74161 = vor.u32 %v74160, %v74159 (stack46)
        %v74162 = vxor.u32 %v74161, %v74153 (stack47)
        %v74165 = vadd.s32 %v74162, %v8 (stack39)
        %v74169 = vadd.s32 1, %v74165 (stack39)
        %v74173 = vadd.s32 %v74169, %v74157 (stack39)
        %v74175 = vshll.u32 %v74169, 17 (stack44)
        %v74176 = vshrl.u32 %v74169, 15 (stack45)
        %v74177 = vor.u32 %v74176, %v74175 (stack46)
        %v74178 = vxor.u32 %v74177, %v74173 (stack47)
        %v74181 = vadd.s32 %v74178, %v74173 (stack39)
        %v74183 = vshll.u32 %v74178, 29 (stack44)
        %v74184 = vshrl.u32 %v74178, 3 (stack45)
        %v74185 = vor.u32 %v74184, %v74183 (stack46)
        %v74186 = vxor.u32 %v74185, %v74181 (stack47)
        %v74189 = vadd.s32 %v74186, %v74181 (stack39)
        %v74191 = vshll.u32 %v74186, 16 (stack44)
        %v74192 = vshrl.u32 %v74186, 16 (stack45)
        %v74193 = vor.u32 %v74192, %v74191 (stack46)
        %v74194 = vxor.u32 %v74193, %v74189 (stack47)
        %v74197 = vadd.s32 %v74194, %v74189 (stack39)
        %v74201 = vadd.s32 %v74197, %v8 (stack39)
        %v74203 = vshll.u32 %v74194, 24 (stack44)
        %v74204 = vshrl.u32 %v74194, 8 (stack45)
        %v74205 = vor.u32 %v74204, %v74203 (stack46)
        %v74206 = vxor.u32 %v74205, %v74197 (stack47)
        %v74209 = vadd.s32 %v74206, %v10 (stack39)
        %v74213 = vadd.s32 2, %v74209 (stack39)
        %v74217 = vadd.s32 %v74213, %v74201 (stack39)
        %v74219 = vshll.u32 %v74213, 13 (stack44)
        %v74220 = vshrl.u32 %v74213, 19 (stack45)
        %v74221 = vor.u32 %v74220, %v74219 (stack46)
        %v74222 = vxor.u32 %v74221, %v74217 (stack47)
        %v74225 = vadd.s32 %v74222, %v74217 (stack39)
        %v74227 = vshll.u32 %v74222, 15 (stack44)
        %v74228 = vshrl.u32 %v74222, 17 (stack45)
        %v74229 = vor.u32 %v74228, %v74227 (stack46)
        %v74230 = vxor.u32 %v74229, %v74225 (stack47)
        %v74233 = vadd.s32 %v74230, %v74225 (stack39)
        %v74235 = vshll.u32 %v74230, 26 (stack44)
        %v74236 = vshrl.u32 %v74230, 6 (stack45)
        %v74237 = vor.u32 %v74236, %v74235 (stack46)
        %v74238 = vxor.u32 %v74237, %v74233 (stack47)
        %v74241 = vadd.s32 %v74238, %v74233 (stack39)
        %v74245 = vadd.s32 %v74241, %v10 (stack39)
        %v74247 = vshll.u32 %v74238, 6 (stack44)
        %v74248 = vshrl.u32 %v74238, 26 (stack45)
        %v74249 = vor.u32 %v74248, %v74247 (stack46)
        %v74250 = vxor.u32 %v74249, %v74241 (stack47)
        %v74253 = vadd.s32 %v74250, %v9 (stack39)
        %v74257 = vadd.s32 3, %v74253 (stack39)
        %v74261 = vadd.s32 %v74257, %v74245 (stack39)
        %v74263 = vshll.u32 %v74257, 17 (stack44)
        %v74264 = vshrl.u32 %v74257, 15 (stack45)
        %v74265 = vor.u32 %v74264, %v74263 (stack46)
        %v74266 = vxor.u32 %v74265, %v74261 (stack47)
        %v74269 = vadd.s32 %v74266, %v74261 (stack39)
        %v74271 = vshll.u32 %v74266, 29 (stack44)
        %v74272 = vshrl.u32 %v74266, 3 (stack45)
        %v74273 = vor.u32 %v74272, %v74271 (stack46)
        %v74274 = vxor.u32 %v74273, %v74269 (stack47)
        %v74277 = vadd.s32 %v74274, %v74269 (stack39)
        %v74279 = vshll.u32 %v74274, 16 (stack44)
        %v74280 = vshrl.u32 %v74274, 16 (stack45)
        %v74281 = vor.u32 %v74280, %v74279 (stack46)
        %v74282 = vxor.u32 %v74281, %v74277 (stack47)
        %v74285 = vadd.s32 %v74282, %v74277 (stack39)
        %v74289 = vadd.s32 %v74285, %v9 (stack39)
        %v74291 = vshll.u32 %v74282, 24 (stack44)
        %v74292 = vshrl.u32 %v74282, 8 (stack45)
        %v74293 = vor.u32 %v74292, %v74291 (stack46)
        %v74294 = vxor.u32 %v74293, %v74285 (stack47)
        %v74297 = vadd.s32 %v74294, %v8 (stack39)
        %v74301 = vadd.s32 4, %v74297 (stack39)
        %v74305 = vadd.s32 %v74301, %v74289 (stack39)
        %v74307 = vshll.u32 %v74301, 13 (stack44)
        %v74308 = vshrl.u32 %v74301, 19 (stack45)
        %v74309 = vor.u32 %v74308, %v74307 (stack46)
        %v74310 = vxor.u32 %v74309, %v74305 (stack47)
        %v74313 = vadd.s32 %v74310, %v74305 (stack39)
        %v74315 = vshll.u32 %v74310, 15 (stack44)
        %v74316 = vshrl.u32 %v74310, 17 (stack45)
        %v74317 = vor.u32 %v74316, %v74315 (stack46)
        %v74318 = vxor.u32 %v74317, %v74313 (stack47)
        %v74321 = vadd.s32 %v74318, %v74313 (stack39)
        %v74323 = vshll.u32 %v74318, 26 (stack44)
        %v74324 = vshrl.u32 %v74318, 6 (stack45)
        %v74325 = vor.u32 %v74324, %v74323 (stack46)
        %v74326 = vxor.u32 %v74325, %v74321 (stack47)
        %v74329 = vadd.s32 %v74326, %v74321 (stack39)
        %v74333 = vadd.s32 %v74329, %v8 (stack39)
        %v74335 = vshll.u32 %v74326, 6 (stack44)
        %v74336 = vshrl.u32 %v74326, 26 (stack45)
        %v74337 = vor.u32 %v74336, %v74335 (stack46)
        %v74338 = vxor.u32 %v74337, %v74329 (stack47)
        %v74341 = vadd.s32 %v74338, %v10 (stack39)
        %v74345 = vadd.s32 5, %v74341 (stack39)
        %v74347 = vxor.u32 %v74345, %v74333 (stack47)
        %v74348 = vand.u32.u8 255, %v74347 (stack48)
        %v74349 = vand.u32 65535, %v74348 (stack49)
        %v74350 = vshrl.u32 %v74349, 1 (stack50)
        %v74351 = vor.u32 16256, %v74350 (stack46)
        %v74352 = vand.u32.u16 65535, %v74351 (stack51)
        %v120140 = vadd.low.f32.bf16 -1.0, %v74352 (stack52)
        %v74361 = vmul.f32 2.0, %v120140 (stack53)
        %v74365 = vadd.f32 -0.99609375, %v74361 (stack52)
        %v74369 = vmax.f32 %v74365, -0.99609375 (stack54)
        %v74371 = vand.u32 2147483647, %v74369 (stack55)
        %vm74374 = vcmp.eq.f32.partialorder %v74371, 1.0 (stack56)
        %v74379 = vmul.f32 inf, %v74369 (stack53)
        %v74381 = vxor.u32 2147483648, %v74369 (stack57)
        %v74384 = vmul.f32 %v74381, %v74369 (stack53)
        %v74386 = vadd.f32 1.0, %v74384 (stack58)
        %v74387 = vlog2.pop %v74386 (stack59)
        %v74388 = vmul.f32 0.6931472, %v74387 (stack60)
        %v74389 = vmul.f32 -0.5, %v74384 (stack61)
        %v74390 = vadd.f32 1.0, %v74389 (stack62)
        %v74391 = vmul.f32 %v74390, %v74384 (stack63)
        %v74392 = vand.u32 2147483647, %v74384 (stack64)
        %vm74393 = vcmp.lt.f32.partialorder %v74392, 0.0004427343 (stack65)
        %v74394 = vsel /*vm=*/%vm74393, /*on_true_vy=*/%v74391, /*on_false_vx=*/%v74388 (stack66)
        %v74395 = vxor.u32 2147483648, %v74394 (stack57)
        %vm74398 = vcmp.lt.f32.partialorder %v74395, 5.0 (stack56)
        %v74403 = vsel /*vm=*/%vm74398, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v74407 = vsel /*vm=*/%vm74398, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v74411 = vsel /*vm=*/%vm74398, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v74415 = vsel /*vm=*/%vm74398, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v74419 = vsel /*vm=*/%vm74398, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v74423 = vsel /*vm=*/%vm74398, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v74427 = vsel /*vm=*/%vm74398, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v74431 = vsel /*vm=*/%vm74398, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v74435 = vsel /*vm=*/%vm74398, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v74439 = vadd.f32 -2.5, %v74395 (stack52)
        %v74441 = vrsqrt.pop %v74395 (stack67)
        %v74442 = vmul.f32 %v74441, %v74395 (stack68)
        %vm74443 = vcmp.eq.f32.partialorder %v74395, inf (stack69)
        %v74444 = vsel /*vm=*/%vm74443, /*on_true_vy=*/%v74395, /*on_false_vx=*/%v74442 (stack70)
        %vm74445 = vcmp.eq.f32.partialorder %v74395, 0.0 (stack71)
        %v74446 = vand.u32 2147483648, %v74395 (stack72)
        %v74447 = vsel /*vm=*/%vm74445, /*on_true_vy=*/%v74446, /*on_false_vx=*/%v74444 (stack73)
        %v74450 = vadd.f32 -3.0, %v74447 (stack52)
        %v74454 = vsel /*vm=*/%vm74398, /*on_true_vy=*/%v74439, /*on_false_vx=*/%v74450 (stack43)
        %v74458 = vmul.f32 %v74454, %v74435 (stack53)
        %v74462 = vadd.f32 %v74458, %v74431 (stack52)
        %v74466 = vmul.f32 %v74462, %v74454 (stack53)
        %v74470 = vadd.f32 %v74466, %v74427 (stack52)
        %v74474 = vmul.f32 %v74470, %v74454 (stack53)
        %v74478 = vadd.f32 %v74474, %v74423 (stack52)
        %v74482 = vmul.f32 %v74478, %v74454 (stack53)
        %v74486 = vadd.f32 %v74482, %v74419 (stack52)
        %v74490 = vmul.f32 %v74486, %v74454 (stack53)
        %v74494 = vadd.f32 %v74490, %v74415 (stack52)
        %v74498 = vmul.f32 %v74494, %v74454 (stack53)
        %v74502 = vadd.f32 %v74498, %v74411 (stack52)
        %v74506 = vmul.f32 %v74502, %v74454 (stack53)
        %v74510 = vadd.f32 %v74506, %v74407 (stack52)
        %v74514 = vmul.f32 %v74510, %v74454 (stack53)
        %v74518 = vadd.f32 %v74514, %v74403 (stack52)
        %v74522 = vmul.f32 %v74518, %v74369 (stack53)
        %v74526 = vsel /*vm=*/%vm74374, /*on_true_vy=*/%v74379, /*on_false_vx=*/%v74522 (stack43)
        %v74530 = vmul.f32 1.4140625, %v74526 (stack53)
        %v74533 = vpack.c.bf16 0.0, %v74530 (stack74)
        %120141 = vst [vmem:[%s280 + $0x34c] sm:$0xf] /*vst_source=*/%v74533 (stack75)
        %v74537 = vadd.s32 %v71307, %v3816 (stack39)
        %v74547 = vadd.s32 %v74537, %v415 (stack39)
        %vm74551 = vcmp.lt.u32.totalorder %v74547, %v74537 (stack42)
        %vm74556 = vcmp.lt.u32.totalorder %v74537, %v3816 (stack42)
        %v74561 = vadd.s32 %v71290, %v3803 (stack39)
        %v74565 = vadd.s32 1, %v74561 (stack39)
        %v74569 = vsel /*vm=*/%vm74556, /*on_true_vy=*/%v74565, /*on_false_vx=*/%v74561 (stack43)
        %v74573 = vadd.s32 1, %v74569 (stack39)
        %v74577 = vsel /*vm=*/%vm74551, /*on_true_vy=*/%v74573, /*on_false_vx=*/%v74569 (stack43)
        %v74582 = vadd.s32 %v74577, %v10 (stack39)
        %v74586 = vadd.s32 %v74547, %v9 (stack39)
        %v74590 = vadd.s32 %v74586, %v74582 (stack39)
        %v74592 = vshll.u32 %v74586, 13 (stack44)
        %v74593 = vshrl.u32 %v74586, 19 (stack45)
        %v74594 = vor.u32 %v74593, %v74592 (stack46)
        %v74595 = vxor.u32 %v74594, %v74590 (stack47)
        %v74598 = vadd.s32 %v74595, %v74590 (stack39)
        %v74600 = vshll.u32 %v74595, 15 (stack44)
        %v74601 = vshrl.u32 %v74595, 17 (stack45)
        %v74602 = vor.u32 %v74601, %v74600 (stack46)
        %v74603 = vxor.u32 %v74602, %v74598 (stack47)
        %v74606 = vadd.s32 %v74603, %v74598 (stack39)
        %v74608 = vshll.u32 %v74603, 26 (stack44)
        %v74609 = vshrl.u32 %v74603, 6 (stack45)
        %v74610 = vor.u32 %v74609, %v74608 (stack46)
        %v74611 = vxor.u32 %v74610, %v74606 (stack47)
        %v74614 = vadd.s32 %v74611, %v74606 (stack39)
        %v74618 = vadd.s32 %v74614, %v9 (stack39)
        %v74620 = vshll.u32 %v74611, 6 (stack44)
        %v74621 = vshrl.u32 %v74611, 26 (stack45)
        %v74622 = vor.u32 %v74621, %v74620 (stack46)
        %v74623 = vxor.u32 %v74622, %v74614 (stack47)
        %v74626 = vadd.s32 %v74623, %v8 (stack39)
        %v74630 = vadd.s32 1, %v74626 (stack39)
        %v74634 = vadd.s32 %v74630, %v74618 (stack39)
        %v74636 = vshll.u32 %v74630, 17 (stack44)
        %v74637 = vshrl.u32 %v74630, 15 (stack45)
        %v74638 = vor.u32 %v74637, %v74636 (stack46)
        %v74639 = vxor.u32 %v74638, %v74634 (stack47)
        %v74642 = vadd.s32 %v74639, %v74634 (stack39)
        %v74644 = vshll.u32 %v74639, 29 (stack44)
        %v74645 = vshrl.u32 %v74639, 3 (stack45)
        %v74646 = vor.u32 %v74645, %v74644 (stack46)
        %v74647 = vxor.u32 %v74646, %v74642 (stack47)
        %v74650 = vadd.s32 %v74647, %v74642 (stack39)
        %v74652 = vshll.u32 %v74647, 16 (stack44)
        %v74653 = vshrl.u32 %v74647, 16 (stack45)
        %v74654 = vor.u32 %v74653, %v74652 (stack46)
        %v74655 = vxor.u32 %v74654, %v74650 (stack47)
        %v74658 = vadd.s32 %v74655, %v74650 (stack39)
        %v74662 = vadd.s32 %v74658, %v8 (stack39)
        %v74664 = vshll.u32 %v74655, 24 (stack44)
        %v74665 = vshrl.u32 %v74655, 8 (stack45)
        %v74666 = vor.u32 %v74665, %v74664 (stack46)
        %v74667 = vxor.u32 %v74666, %v74658 (stack47)
        %v74670 = vadd.s32 %v74667, %v10 (stack39)
        %v74674 = vadd.s32 2, %v74670 (stack39)
        %v74678 = vadd.s32 %v74674, %v74662 (stack39)
        %v74680 = vshll.u32 %v74674, 13 (stack44)
        %v74681 = vshrl.u32 %v74674, 19 (stack45)
        %v74682 = vor.u32 %v74681, %v74680 (stack46)
        %v74683 = vxor.u32 %v74682, %v74678 (stack47)
        %v74686 = vadd.s32 %v74683, %v74678 (stack39)
        %v74688 = vshll.u32 %v74683, 15 (stack44)
        %v74689 = vshrl.u32 %v74683, 17 (stack45)
        %v74690 = vor.u32 %v74689, %v74688 (stack46)
        %v74691 = vxor.u32 %v74690, %v74686 (stack47)
        %v74694 = vadd.s32 %v74691, %v74686 (stack39)
        %v74696 = vshll.u32 %v74691, 26 (stack44)
        %v74697 = vshrl.u32 %v74691, 6 (stack45)
        %v74698 = vor.u32 %v74697, %v74696 (stack46)
        %v74699 = vxor.u32 %v74698, %v74694 (stack47)
        %v74702 = vadd.s32 %v74699, %v74694 (stack39)
        %v74706 = vadd.s32 %v74702, %v10 (stack39)
        %v74708 = vshll.u32 %v74699, 6 (stack44)
        %v74709 = vshrl.u32 %v74699, 26 (stack45)
        %v74710 = vor.u32 %v74709, %v74708 (stack46)
        %v74711 = vxor.u32 %v74710, %v74702 (stack47)
        %v74714 = vadd.s32 %v74711, %v9 (stack39)
        %v74718 = vadd.s32 3, %v74714 (stack39)
        %v74722 = vadd.s32 %v74718, %v74706 (stack39)
        %v74724 = vshll.u32 %v74718, 17 (stack44)
        %v74725 = vshrl.u32 %v74718, 15 (stack45)
        %v74726 = vor.u32 %v74725, %v74724 (stack46)
        %v74727 = vxor.u32 %v74726, %v74722 (stack47)
        %v74730 = vadd.s32 %v74727, %v74722 (stack39)
        %v74732 = vshll.u32 %v74727, 29 (stack44)
        %v74733 = vshrl.u32 %v74727, 3 (stack45)
        %v74734 = vor.u32 %v74733, %v74732 (stack46)
        %v74735 = vxor.u32 %v74734, %v74730 (stack47)
        %v74738 = vadd.s32 %v74735, %v74730 (stack39)
        %v74740 = vshll.u32 %v74735, 16 (stack44)
        %v74741 = vshrl.u32 %v74735, 16 (stack45)
        %v74742 = vor.u32 %v74741, %v74740 (stack46)
        %v74743 = vxor.u32 %v74742, %v74738 (stack47)
        %v74746 = vadd.s32 %v74743, %v74738 (stack39)
        %v74750 = vadd.s32 %v74746, %v9 (stack39)
        %v74752 = vshll.u32 %v74743, 24 (stack44)
        %v74753 = vshrl.u32 %v74743, 8 (stack45)
        %v74754 = vor.u32 %v74753, %v74752 (stack46)
        %v74755 = vxor.u32 %v74754, %v74746 (stack47)
        %v74758 = vadd.s32 %v74755, %v8 (stack39)
        %v74762 = vadd.s32 4, %v74758 (stack39)
        %v74766 = vadd.s32 %v74762, %v74750 (stack39)
        %v74768 = vshll.u32 %v74762, 13 (stack44)
        %v74769 = vshrl.u32 %v74762, 19 (stack45)
        %v74770 = vor.u32 %v74769, %v74768 (stack46)
        %v74771 = vxor.u32 %v74770, %v74766 (stack47)
        %v74774 = vadd.s32 %v74771, %v74766 (stack39)
        %v74776 = vshll.u32 %v74771, 15 (stack44)
        %v74777 = vshrl.u32 %v74771, 17 (stack45)
        %v74778 = vor.u32 %v74777, %v74776 (stack46)
        %v74779 = vxor.u32 %v74778, %v74774 (stack47)
        %v74782 = vadd.s32 %v74779, %v74774 (stack39)
        %v74784 = vshll.u32 %v74779, 26 (stack44)
        %v74785 = vshrl.u32 %v74779, 6 (stack45)
        %v74786 = vor.u32 %v74785, %v74784 (stack46)
        %v74787 = vxor.u32 %v74786, %v74782 (stack47)
        %v74790 = vadd.s32 %v74787, %v74782 (stack39)
        %v74794 = vadd.s32 %v74790, %v8 (stack39)
        %v74796 = vshll.u32 %v74787, 6 (stack44)
        %v74797 = vshrl.u32 %v74787, 26 (stack45)
        %v74798 = vor.u32 %v74797, %v74796 (stack46)
        %v74799 = vxor.u32 %v74798, %v74790 (stack47)
        %v74802 = vadd.s32 %v74799, %v10 (stack39)
        %v74806 = vadd.s32 5, %v74802 (stack39)
        %v74808 = vxor.u32 %v74806, %v74794 (stack47)
        %v74809 = vand.u32.u8 255, %v74808 (stack48)
        %v74810 = vand.u32 65535, %v74809 (stack49)
        %v74811 = vshrl.u32 %v74810, 1 (stack50)
        %v74812 = vor.u32 16256, %v74811 (stack46)
        %v74813 = vand.u32.u16 65535, %v74812 (stack51)
        %v120142 = vadd.low.f32.bf16 -1.0, %v74813 (stack52)
        %v74822 = vmul.f32 2.0, %v120142 (stack53)
        %v74826 = vadd.f32 -0.99609375, %v74822 (stack52)
        %v74830 = vmax.f32 %v74826, -0.99609375 (stack54)
        %v74832 = vand.u32 2147483647, %v74830 (stack55)
        %vm74835 = vcmp.eq.f32.partialorder %v74832, 1.0 (stack56)
        %v74840 = vmul.f32 inf, %v74830 (stack53)
        %v74842 = vxor.u32 2147483648, %v74830 (stack57)
        %v74845 = vmul.f32 %v74842, %v74830 (stack53)
        %v74847 = vadd.f32 1.0, %v74845 (stack58)
        %v74848 = vlog2.pop %v74847 (stack59)
        %v74849 = vmul.f32 0.6931472, %v74848 (stack60)
        %v74850 = vmul.f32 -0.5, %v74845 (stack61)
        %v74851 = vadd.f32 1.0, %v74850 (stack62)
        %v74852 = vmul.f32 %v74851, %v74845 (stack63)
        %v74853 = vand.u32 2147483647, %v74845 (stack64)
        %vm74854 = vcmp.lt.f32.partialorder %v74853, 0.0004427343 (stack65)
        %v74855 = vsel /*vm=*/%vm74854, /*on_true_vy=*/%v74852, /*on_false_vx=*/%v74849 (stack66)
        %v74856 = vxor.u32 2147483648, %v74855 (stack57)
        %vm74859 = vcmp.lt.f32.partialorder %v74856, 5.0 (stack56)
        %v74864 = vsel /*vm=*/%vm74859, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v74868 = vsel /*vm=*/%vm74859, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v74872 = vsel /*vm=*/%vm74859, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v74876 = vsel /*vm=*/%vm74859, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v74880 = vsel /*vm=*/%vm74859, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v74884 = vsel /*vm=*/%vm74859, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v74888 = vsel /*vm=*/%vm74859, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v74892 = vsel /*vm=*/%vm74859, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v74896 = vsel /*vm=*/%vm74859, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v74900 = vadd.f32 -2.5, %v74856 (stack52)
        %v74902 = vrsqrt.pop %v74856 (stack67)
        %v74903 = vmul.f32 %v74902, %v74856 (stack68)
        %vm74904 = vcmp.eq.f32.partialorder %v74856, inf (stack69)
        %v74905 = vsel /*vm=*/%vm74904, /*on_true_vy=*/%v74856, /*on_false_vx=*/%v74903 (stack70)
        %vm74906 = vcmp.eq.f32.partialorder %v74856, 0.0 (stack71)
        %v74907 = vand.u32 2147483648, %v74856 (stack72)
        %v74908 = vsel /*vm=*/%vm74906, /*on_true_vy=*/%v74907, /*on_false_vx=*/%v74905 (stack73)
        %v74911 = vadd.f32 -3.0, %v74908 (stack52)
        %v74915 = vsel /*vm=*/%vm74859, /*on_true_vy=*/%v74900, /*on_false_vx=*/%v74911 (stack43)
        %v74919 = vmul.f32 %v74915, %v74896 (stack53)
        %v74923 = vadd.f32 %v74919, %v74892 (stack52)
        %v74927 = vmul.f32 %v74923, %v74915 (stack53)
        %v74931 = vadd.f32 %v74927, %v74888 (stack52)
        %v74935 = vmul.f32 %v74931, %v74915 (stack53)
        %v74939 = vadd.f32 %v74935, %v74884 (stack52)
        %v74943 = vmul.f32 %v74939, %v74915 (stack53)
        %v74947 = vadd.f32 %v74943, %v74880 (stack52)
        %v74951 = vmul.f32 %v74947, %v74915 (stack53)
        %v74955 = vadd.f32 %v74951, %v74876 (stack52)
        %v74959 = vmul.f32 %v74955, %v74915 (stack53)
        %v74963 = vadd.f32 %v74959, %v74872 (stack52)
        %v74967 = vmul.f32 %v74963, %v74915 (stack53)
        %v74971 = vadd.f32 %v74967, %v74868 (stack52)
        %v74975 = vmul.f32 %v74971, %v74915 (stack53)
        %v74979 = vadd.f32 %v74975, %v74864 (stack52)
        %v74983 = vmul.f32 %v74979, %v74830 (stack53)
        %v74987 = vsel /*vm=*/%vm74835, /*on_true_vy=*/%v74840, /*on_false_vx=*/%v74983 (stack43)
        %v74991 = vmul.f32 1.4140625, %v74987 (stack53)
        %v74994 = vpack.c.bf16 0.0, %v74991 (stack74)
        %120143 = vst [vmem:[%s280 + $0x3cc] sm:$0xf] /*vst_source=*/%v74994 (stack75)
        %s74996 = sadd.s32 160, %s120390 (stack76)
        %s74997 = sshrl.u32 %s74996, 10 (stack23)
        %p120144 = scmp.gt.s32.totalorder %s74997, 1 (stack24)
        %s74999 = scalar_select /*predicate=*/%p120144, /*on_true=*/1, /*on_false=*/%s74997 (stack25)
        %s75000 = sand.u32 1023, %s74996 /* smod.u32 w/div 1024 */ (stack26)
        %s75001 = sshrl.u32 %s75000, 7 (stack27)
        %s75002 = sand.u32 127, %s75000 /* smod.u32 w/div 128 */ (stack28)
        %s120145 = sshll.u32 %s74999, 3 (stack29)
        %s75004 = scalar_lea.vmem %s3, %s120145 (stack30)
        %s75006 = scalar_lea.vmem %s75004, %s75001 (stack31)
        %v75007 = vld [vmem:[%s75006] ss:$0 sm:$0xff] (stack32)
        %s75008 = sand.u32 255, %s75002 (stack33)
        %s75010 = sor.u32 256, %s75008 (stack34)
        %75011 = vbcast.lane.b32.xlu0 %v75007, %s75010 (stack35)
        %v75012 = vpop.permute.xlu0 %75011 (stack36)
        %s75021 = scalar_lea.vmem %s5, %s120145 (stack30)
        %s75023 = scalar_lea.vmem %s75021, %s75001 (stack31)
        %v75024 = vld [vmem:[%s75023] ss:$0 sm:$0xff] (stack32)
        %75028 = vbcast.lane.b32.xlu0 %v75024, %s75010 (stack35)
        %v75029 = vpop.permute.xlu0 %75028 (stack36)
        %v75032 = vadd.s32 %v75029, %v408 (stack39)
        %v75042 = vadd.s32 %v75032, %v415 (stack39)
        %vm75046 = vcmp.lt.u32.totalorder %v75042, %v75032 (stack42)
        %vm75051 = vcmp.lt.u32.totalorder %v75032, %v408 (stack42)
        %v75056 = vadd.s32 %v75012, %v380 (stack39)
        %v75060 = vadd.s32 1, %v75056 (stack39)
        %v75064 = vsel /*vm=*/%vm75051, /*on_true_vy=*/%v75060, /*on_false_vx=*/%v75056 (stack43)
        %v75068 = vadd.s32 1, %v75064 (stack39)
        %v75072 = vsel /*vm=*/%vm75046, /*on_true_vy=*/%v75068, /*on_false_vx=*/%v75064 (stack43)
        %v75077 = vadd.s32 %v75072, %v10 (stack39)
        %v75081 = vadd.s32 %v75042, %v9 (stack39)
        %v75085 = vadd.s32 %v75081, %v75077 (stack39)
        %v75087 = vshll.u32 %v75081, 13 (stack44)
        %v75088 = vshrl.u32 %v75081, 19 (stack45)
        %v75089 = vor.u32 %v75088, %v75087 (stack46)
        %v75090 = vxor.u32 %v75089, %v75085 (stack47)
        %v75093 = vadd.s32 %v75090, %v75085 (stack39)
        %v75095 = vshll.u32 %v75090, 15 (stack44)
        %v75096 = vshrl.u32 %v75090, 17 (stack45)
        %v75097 = vor.u32 %v75096, %v75095 (stack46)
        %v75098 = vxor.u32 %v75097, %v75093 (stack47)
        %v75101 = vadd.s32 %v75098, %v75093 (stack39)
        %v75103 = vshll.u32 %v75098, 26 (stack44)
        %v75104 = vshrl.u32 %v75098, 6 (stack45)
        %v75105 = vor.u32 %v75104, %v75103 (stack46)
        %v75106 = vxor.u32 %v75105, %v75101 (stack47)
        %v75109 = vadd.s32 %v75106, %v75101 (stack39)
        %v75113 = vadd.s32 %v75109, %v9 (stack39)
        %v75115 = vshll.u32 %v75106, 6 (stack44)
        %v75116 = vshrl.u32 %v75106, 26 (stack45)
        %v75117 = vor.u32 %v75116, %v75115 (stack46)
        %v75118 = vxor.u32 %v75117, %v75109 (stack47)
        %v75121 = vadd.s32 %v75118, %v8 (stack39)
        %v75125 = vadd.s32 1, %v75121 (stack39)
        %v75129 = vadd.s32 %v75125, %v75113 (stack39)
        %v75131 = vshll.u32 %v75125, 17 (stack44)
        %v75132 = vshrl.u32 %v75125, 15 (stack45)
        %v75133 = vor.u32 %v75132, %v75131 (stack46)
        %v75134 = vxor.u32 %v75133, %v75129 (stack47)
        %v75137 = vadd.s32 %v75134, %v75129 (stack39)
        %v75139 = vshll.u32 %v75134, 29 (stack44)
        %v75140 = vshrl.u32 %v75134, 3 (stack45)
        %v75141 = vor.u32 %v75140, %v75139 (stack46)
        %v75142 = vxor.u32 %v75141, %v75137 (stack47)
        %v75145 = vadd.s32 %v75142, %v75137 (stack39)
        %v75147 = vshll.u32 %v75142, 16 (stack44)
        %v75148 = vshrl.u32 %v75142, 16 (stack45)
        %v75149 = vor.u32 %v75148, %v75147 (stack46)
        %v75150 = vxor.u32 %v75149, %v75145 (stack47)
        %v75153 = vadd.s32 %v75150, %v75145 (stack39)
        %v75157 = vadd.s32 %v75153, %v8 (stack39)
        %v75159 = vshll.u32 %v75150, 24 (stack44)
        %v75160 = vshrl.u32 %v75150, 8 (stack45)
        %v75161 = vor.u32 %v75160, %v75159 (stack46)
        %v75162 = vxor.u32 %v75161, %v75153 (stack47)
        %v75165 = vadd.s32 %v75162, %v10 (stack39)
        %v75169 = vadd.s32 2, %v75165 (stack39)
        %v75173 = vadd.s32 %v75169, %v75157 (stack39)
        %v75175 = vshll.u32 %v75169, 13 (stack44)
        %v75176 = vshrl.u32 %v75169, 19 (stack45)
        %v75177 = vor.u32 %v75176, %v75175 (stack46)
        %v75178 = vxor.u32 %v75177, %v75173 (stack47)
        %v75181 = vadd.s32 %v75178, %v75173 (stack39)
        %v75183 = vshll.u32 %v75178, 15 (stack44)
        %v75184 = vshrl.u32 %v75178, 17 (stack45)
        %v75185 = vor.u32 %v75184, %v75183 (stack46)
        %v75186 = vxor.u32 %v75185, %v75181 (stack47)
        %v75189 = vadd.s32 %v75186, %v75181 (stack39)
        %v75191 = vshll.u32 %v75186, 26 (stack44)
        %v75192 = vshrl.u32 %v75186, 6 (stack45)
        %v75193 = vor.u32 %v75192, %v75191 (stack46)
        %v75194 = vxor.u32 %v75193, %v75189 (stack47)
        %v75197 = vadd.s32 %v75194, %v75189 (stack39)
        %v75201 = vadd.s32 %v75197, %v10 (stack39)
        %v75203 = vshll.u32 %v75194, 6 (stack44)
        %v75204 = vshrl.u32 %v75194, 26 (stack45)
        %v75205 = vor.u32 %v75204, %v75203 (stack46)
        %v75206 = vxor.u32 %v75205, %v75197 (stack47)
        %v75209 = vadd.s32 %v75206, %v9 (stack39)
        %v75213 = vadd.s32 3, %v75209 (stack39)
        %v75217 = vadd.s32 %v75213, %v75201 (stack39)
        %v75219 = vshll.u32 %v75213, 17 (stack44)
        %v75220 = vshrl.u32 %v75213, 15 (stack45)
        %v75221 = vor.u32 %v75220, %v75219 (stack46)
        %v75222 = vxor.u32 %v75221, %v75217 (stack47)
        %v75225 = vadd.s32 %v75222, %v75217 (stack39)
        %v75227 = vshll.u32 %v75222, 29 (stack44)
        %v75228 = vshrl.u32 %v75222, 3 (stack45)
        %v75229 = vor.u32 %v75228, %v75227 (stack46)
        %v75230 = vxor.u32 %v75229, %v75225 (stack47)
        %v75233 = vadd.s32 %v75230, %v75225 (stack39)
        %v75235 = vshll.u32 %v75230, 16 (stack44)
        %v75236 = vshrl.u32 %v75230, 16 (stack45)
        %v75237 = vor.u32 %v75236, %v75235 (stack46)
        %v75238 = vxor.u32 %v75237, %v75233 (stack47)
        %v75241 = vadd.s32 %v75238, %v75233 (stack39)
        %v75245 = vadd.s32 %v75241, %v9 (stack39)
        %v75247 = vshll.u32 %v75238, 24 (stack44)
        %v75248 = vshrl.u32 %v75238, 8 (stack45)
        %v75249 = vor.u32 %v75248, %v75247 (stack46)
        %v75250 = vxor.u32 %v75249, %v75241 (stack47)
        %v75253 = vadd.s32 %v75250, %v8 (stack39)
        %v75257 = vadd.s32 4, %v75253 (stack39)
        %v75261 = vadd.s32 %v75257, %v75245 (stack39)
        %v75263 = vshll.u32 %v75257, 13 (stack44)
        %v75264 = vshrl.u32 %v75257, 19 (stack45)
        %v75265 = vor.u32 %v75264, %v75263 (stack46)
        %v75266 = vxor.u32 %v75265, %v75261 (stack47)
        %v75269 = vadd.s32 %v75266, %v75261 (stack39)
        %v75271 = vshll.u32 %v75266, 15 (stack44)
        %v75272 = vshrl.u32 %v75266, 17 (stack45)
        %v75273 = vor.u32 %v75272, %v75271 (stack46)
        %v75274 = vxor.u32 %v75273, %v75269 (stack47)
        %v75277 = vadd.s32 %v75274, %v75269 (stack39)
        %v75279 = vshll.u32 %v75274, 26 (stack44)
        %v75280 = vshrl.u32 %v75274, 6 (stack45)
        %v75281 = vor.u32 %v75280, %v75279 (stack46)
        %v75282 = vxor.u32 %v75281, %v75277 (stack47)
        %v75285 = vadd.s32 %v75282, %v75277 (stack39)
        %v75289 = vadd.s32 %v75285, %v8 (stack39)
        %v75291 = vshll.u32 %v75282, 6 (stack44)
        %v75292 = vshrl.u32 %v75282, 26 (stack45)
        %v75293 = vor.u32 %v75292, %v75291 (stack46)
        %v75294 = vxor.u32 %v75293, %v75285 (stack47)
        %v75297 = vadd.s32 %v75294, %v10 (stack39)
        %v75301 = vadd.s32 5, %v75297 (stack39)
        %v75303 = vxor.u32 %v75301, %v75289 (stack47)
        %v75304 = vand.u32.u8 255, %v75303 (stack48)
        %v75305 = vand.u32 65535, %v75304 (stack49)
        %v75306 = vshrl.u32 %v75305, 1 (stack50)
        %v75307 = vor.u32 16256, %v75306 (stack46)
        %v75308 = vand.u32.u16 65535, %v75307 (stack51)
        %v120148 = vadd.low.f32.bf16 -1.0, %v75308 (stack52)
        %v75317 = vmul.f32 2.0, %v120148 (stack53)
        %v75321 = vadd.f32 -0.99609375, %v75317 (stack52)
        %v75325 = vmax.f32 %v75321, -0.99609375 (stack54)
        %v75327 = vand.u32 2147483647, %v75325 (stack55)
        %vm75330 = vcmp.eq.f32.partialorder %v75327, 1.0 (stack56)
        %v75335 = vmul.f32 inf, %v75325 (stack53)
        %v75337 = vxor.u32 2147483648, %v75325 (stack57)
        %v75340 = vmul.f32 %v75337, %v75325 (stack53)
        %v75342 = vadd.f32 1.0, %v75340 (stack58)
        %v75343 = vlog2.pop %v75342 (stack59)
        %v75344 = vmul.f32 0.6931472, %v75343 (stack60)
        %v75345 = vmul.f32 -0.5, %v75340 (stack61)
        %v75346 = vadd.f32 1.0, %v75345 (stack62)
        %v75347 = vmul.f32 %v75346, %v75340 (stack63)
        %v75348 = vand.u32 2147483647, %v75340 (stack64)
        %vm75349 = vcmp.lt.f32.partialorder %v75348, 0.0004427343 (stack65)
        %v75350 = vsel /*vm=*/%vm75349, /*on_true_vy=*/%v75347, /*on_false_vx=*/%v75344 (stack66)
        %v75351 = vxor.u32 2147483648, %v75350 (stack57)
        %vm75354 = vcmp.lt.f32.partialorder %v75351, 5.0 (stack56)
        %v75359 = vsel /*vm=*/%vm75354, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v75363 = vsel /*vm=*/%vm75354, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v75367 = vsel /*vm=*/%vm75354, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v75371 = vsel /*vm=*/%vm75354, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v75375 = vsel /*vm=*/%vm75354, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v75379 = vsel /*vm=*/%vm75354, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v75383 = vsel /*vm=*/%vm75354, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v75387 = vsel /*vm=*/%vm75354, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v75391 = vsel /*vm=*/%vm75354, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v75395 = vadd.f32 -2.5, %v75351 (stack52)
        %v75397 = vrsqrt.pop %v75351 (stack67)
        %v75398 = vmul.f32 %v75397, %v75351 (stack68)
        %vm75399 = vcmp.eq.f32.partialorder %v75351, inf (stack69)
        %v75400 = vsel /*vm=*/%vm75399, /*on_true_vy=*/%v75351, /*on_false_vx=*/%v75398 (stack70)
        %vm75401 = vcmp.eq.f32.partialorder %v75351, 0.0 (stack71)
        %v75402 = vand.u32 2147483648, %v75351 (stack72)
        %v75403 = vsel /*vm=*/%vm75401, /*on_true_vy=*/%v75402, /*on_false_vx=*/%v75400 (stack73)
        %v75406 = vadd.f32 -3.0, %v75403 (stack52)
        %v75410 = vsel /*vm=*/%vm75354, /*on_true_vy=*/%v75395, /*on_false_vx=*/%v75406 (stack43)
        %v75414 = vmul.f32 %v75410, %v75391 (stack53)
        %v75418 = vadd.f32 %v75414, %v75387 (stack52)
        %v75422 = vmul.f32 %v75418, %v75410 (stack53)
        %v75426 = vadd.f32 %v75422, %v75383 (stack52)
        %v75430 = vmul.f32 %v75426, %v75410 (stack53)
        %v75434 = vadd.f32 %v75430, %v75379 (stack52)
        %v75438 = vmul.f32 %v75434, %v75410 (stack53)
        %v75442 = vadd.f32 %v75438, %v75375 (stack52)
        %v75446 = vmul.f32 %v75442, %v75410 (stack53)
        %v75450 = vadd.f32 %v75446, %v75371 (stack52)
        %v75454 = vmul.f32 %v75450, %v75410 (stack53)
        %v75458 = vadd.f32 %v75454, %v75367 (stack52)
        %v75462 = vmul.f32 %v75458, %v75410 (stack53)
        %v75466 = vadd.f32 %v75462, %v75363 (stack52)
        %v75470 = vmul.f32 %v75466, %v75410 (stack53)
        %v75474 = vadd.f32 %v75470, %v75359 (stack52)
        %v75478 = vmul.f32 %v75474, %v75325 (stack53)
        %v75482 = vsel /*vm=*/%vm75330, /*on_true_vy=*/%v75335, /*on_false_vx=*/%v75478 (stack43)
        %v75486 = vmul.f32 1.4140625, %v75482 (stack53)
        %v75489 = vpack.c.bf16 0.0, %v75486 (stack74)
        %120149 = vst [vmem:[%s280 + $0x50] sm:$0xf] /*vst_source=*/%v75489 (stack75)
        %v75493 = vadd.s32 %v75029, %v894 (stack39)
        %v75503 = vadd.s32 %v75493, %v415 (stack39)
        %vm75507 = vcmp.lt.u32.totalorder %v75503, %v75493 (stack42)
        %vm75512 = vcmp.lt.u32.totalorder %v75493, %v894 (stack42)
        %v75517 = vadd.s32 %v75012, %v881 (stack39)
        %v75521 = vadd.s32 1, %v75517 (stack39)
        %v75525 = vsel /*vm=*/%vm75512, /*on_true_vy=*/%v75521, /*on_false_vx=*/%v75517 (stack43)
        %v75529 = vadd.s32 1, %v75525 (stack39)
        %v75533 = vsel /*vm=*/%vm75507, /*on_true_vy=*/%v75529, /*on_false_vx=*/%v75525 (stack43)
        %v75538 = vadd.s32 %v75533, %v10 (stack39)
        %v75542 = vadd.s32 %v75503, %v9 (stack39)
        %v75546 = vadd.s32 %v75542, %v75538 (stack39)
        %v75548 = vshll.u32 %v75542, 13 (stack44)
        %v75549 = vshrl.u32 %v75542, 19 (stack45)
        %v75550 = vor.u32 %v75549, %v75548 (stack46)
        %v75551 = vxor.u32 %v75550, %v75546 (stack47)
        %v75554 = vadd.s32 %v75551, %v75546 (stack39)
        %v75556 = vshll.u32 %v75551, 15 (stack44)
        %v75557 = vshrl.u32 %v75551, 17 (stack45)
        %v75558 = vor.u32 %v75557, %v75556 (stack46)
        %v75559 = vxor.u32 %v75558, %v75554 (stack47)
        %v75562 = vadd.s32 %v75559, %v75554 (stack39)
        %v75564 = vshll.u32 %v75559, 26 (stack44)
        %v75565 = vshrl.u32 %v75559, 6 (stack45)
        %v75566 = vor.u32 %v75565, %v75564 (stack46)
        %v75567 = vxor.u32 %v75566, %v75562 (stack47)
        %v75570 = vadd.s32 %v75567, %v75562 (stack39)
        %v75574 = vadd.s32 %v75570, %v9 (stack39)
        %v75576 = vshll.u32 %v75567, 6 (stack44)
        %v75577 = vshrl.u32 %v75567, 26 (stack45)
        %v75578 = vor.u32 %v75577, %v75576 (stack46)
        %v75579 = vxor.u32 %v75578, %v75570 (stack47)
        %v75582 = vadd.s32 %v75579, %v8 (stack39)
        %v75586 = vadd.s32 1, %v75582 (stack39)
        %v75590 = vadd.s32 %v75586, %v75574 (stack39)
        %v75592 = vshll.u32 %v75586, 17 (stack44)
        %v75593 = vshrl.u32 %v75586, 15 (stack45)
        %v75594 = vor.u32 %v75593, %v75592 (stack46)
        %v75595 = vxor.u32 %v75594, %v75590 (stack47)
        %v75598 = vadd.s32 %v75595, %v75590 (stack39)
        %v75600 = vshll.u32 %v75595, 29 (stack44)
        %v75601 = vshrl.u32 %v75595, 3 (stack45)
        %v75602 = vor.u32 %v75601, %v75600 (stack46)
        %v75603 = vxor.u32 %v75602, %v75598 (stack47)
        %v75606 = vadd.s32 %v75603, %v75598 (stack39)
        %v75608 = vshll.u32 %v75603, 16 (stack44)
        %v75609 = vshrl.u32 %v75603, 16 (stack45)
        %v75610 = vor.u32 %v75609, %v75608 (stack46)
        %v75611 = vxor.u32 %v75610, %v75606 (stack47)
        %v75614 = vadd.s32 %v75611, %v75606 (stack39)
        %v75618 = vadd.s32 %v75614, %v8 (stack39)
        %v75620 = vshll.u32 %v75611, 24 (stack44)
        %v75621 = vshrl.u32 %v75611, 8 (stack45)
        %v75622 = vor.u32 %v75621, %v75620 (stack46)
        %v75623 = vxor.u32 %v75622, %v75614 (stack47)
        %v75626 = vadd.s32 %v75623, %v10 (stack39)
        %v75630 = vadd.s32 2, %v75626 (stack39)
        %v75634 = vadd.s32 %v75630, %v75618 (stack39)
        %v75636 = vshll.u32 %v75630, 13 (stack44)
        %v75637 = vshrl.u32 %v75630, 19 (stack45)
        %v75638 = vor.u32 %v75637, %v75636 (stack46)
        %v75639 = vxor.u32 %v75638, %v75634 (stack47)
        %v75642 = vadd.s32 %v75639, %v75634 (stack39)
        %v75644 = vshll.u32 %v75639, 15 (stack44)
        %v75645 = vshrl.u32 %v75639, 17 (stack45)
        %v75646 = vor.u32 %v75645, %v75644 (stack46)
        %v75647 = vxor.u32 %v75646, %v75642 (stack47)
        %v75650 = vadd.s32 %v75647, %v75642 (stack39)
        %v75652 = vshll.u32 %v75647, 26 (stack44)
        %v75653 = vshrl.u32 %v75647, 6 (stack45)
        %v75654 = vor.u32 %v75653, %v75652 (stack46)
        %v75655 = vxor.u32 %v75654, %v75650 (stack47)
        %v75658 = vadd.s32 %v75655, %v75650 (stack39)
        %v75662 = vadd.s32 %v75658, %v10 (stack39)
        %v75664 = vshll.u32 %v75655, 6 (stack44)
        %v75665 = vshrl.u32 %v75655, 26 (stack45)
        %v75666 = vor.u32 %v75665, %v75664 (stack46)
        %v75667 = vxor.u32 %v75666, %v75658 (stack47)
        %v75670 = vadd.s32 %v75667, %v9 (stack39)
        %v75674 = vadd.s32 3, %v75670 (stack39)
        %v75678 = vadd.s32 %v75674, %v75662 (stack39)
        %v75680 = vshll.u32 %v75674, 17 (stack44)
        %v75681 = vshrl.u32 %v75674, 15 (stack45)
        %v75682 = vor.u32 %v75681, %v75680 (stack46)
        %v75683 = vxor.u32 %v75682, %v75678 (stack47)
        %v75686 = vadd.s32 %v75683, %v75678 (stack39)
        %v75688 = vshll.u32 %v75683, 29 (stack44)
        %v75689 = vshrl.u32 %v75683, 3 (stack45)
        %v75690 = vor.u32 %v75689, %v75688 (stack46)
        %v75691 = vxor.u32 %v75690, %v75686 (stack47)
        %v75694 = vadd.s32 %v75691, %v75686 (stack39)
        %v75696 = vshll.u32 %v75691, 16 (stack44)
        %v75697 = vshrl.u32 %v75691, 16 (stack45)
        %v75698 = vor.u32 %v75697, %v75696 (stack46)
        %v75699 = vxor.u32 %v75698, %v75694 (stack47)
        %v75702 = vadd.s32 %v75699, %v75694 (stack39)
        %v75706 = vadd.s32 %v75702, %v9 (stack39)
        %v75708 = vshll.u32 %v75699, 24 (stack44)
        %v75709 = vshrl.u32 %v75699, 8 (stack45)
        %v75710 = vor.u32 %v75709, %v75708 (stack46)
        %v75711 = vxor.u32 %v75710, %v75702 (stack47)
        %v75714 = vadd.s32 %v75711, %v8 (stack39)
        %v75718 = vadd.s32 4, %v75714 (stack39)
        %v75722 = vadd.s32 %v75718, %v75706 (stack39)
        %v75724 = vshll.u32 %v75718, 13 (stack44)
        %v75725 = vshrl.u32 %v75718, 19 (stack45)
        %v75726 = vor.u32 %v75725, %v75724 (stack46)
        %v75727 = vxor.u32 %v75726, %v75722 (stack47)
        %v75730 = vadd.s32 %v75727, %v75722 (stack39)
        %v75732 = vshll.u32 %v75727, 15 (stack44)
        %v75733 = vshrl.u32 %v75727, 17 (stack45)
        %v75734 = vor.u32 %v75733, %v75732 (stack46)
        %v75735 = vxor.u32 %v75734, %v75730 (stack47)
        %v75738 = vadd.s32 %v75735, %v75730 (stack39)
        %v75740 = vshll.u32 %v75735, 26 (stack44)
        %v75741 = vshrl.u32 %v75735, 6 (stack45)
        %v75742 = vor.u32 %v75741, %v75740 (stack46)
        %v75743 = vxor.u32 %v75742, %v75738 (stack47)
        %v75746 = vadd.s32 %v75743, %v75738 (stack39)
        %v75750 = vadd.s32 %v75746, %v8 (stack39)
        %v75752 = vshll.u32 %v75743, 6 (stack44)
        %v75753 = vshrl.u32 %v75743, 26 (stack45)
        %v75754 = vor.u32 %v75753, %v75752 (stack46)
        %v75755 = vxor.u32 %v75754, %v75746 (stack47)
        %v75758 = vadd.s32 %v75755, %v10 (stack39)
        %v75762 = vadd.s32 5, %v75758 (stack39)
        %v75764 = vxor.u32 %v75762, %v75750 (stack47)
        %v75765 = vand.u32.u8 255, %v75764 (stack48)
        %v75766 = vand.u32 65535, %v75765 (stack49)
        %v75767 = vshrl.u32 %v75766, 1 (stack50)
        %v75768 = vor.u32 16256, %v75767 (stack46)
        %v75769 = vand.u32.u16 65535, %v75768 (stack51)
        %v120150 = vadd.low.f32.bf16 -1.0, %v75769 (stack52)
        %v75778 = vmul.f32 2.0, %v120150 (stack53)
        %v75782 = vadd.f32 -0.99609375, %v75778 (stack52)
        %v75786 = vmax.f32 %v75782, -0.99609375 (stack54)
        %v75788 = vand.u32 2147483647, %v75786 (stack55)
        %vm75791 = vcmp.eq.f32.partialorder %v75788, 1.0 (stack56)
        %v75796 = vmul.f32 inf, %v75786 (stack53)
        %v75798 = vxor.u32 2147483648, %v75786 (stack57)
        %v75801 = vmul.f32 %v75798, %v75786 (stack53)
        %v75803 = vadd.f32 1.0, %v75801 (stack58)
        %v75804 = vlog2.pop %v75803 (stack59)
        %v75805 = vmul.f32 0.6931472, %v75804 (stack60)
        %v75806 = vmul.f32 -0.5, %v75801 (stack61)
        %v75807 = vadd.f32 1.0, %v75806 (stack62)
        %v75808 = vmul.f32 %v75807, %v75801 (stack63)
        %v75809 = vand.u32 2147483647, %v75801 (stack64)
        %vm75810 = vcmp.lt.f32.partialorder %v75809, 0.0004427343 (stack65)
        %v75811 = vsel /*vm=*/%vm75810, /*on_true_vy=*/%v75808, /*on_false_vx=*/%v75805 (stack66)
        %v75812 = vxor.u32 2147483648, %v75811 (stack57)
        %vm75815 = vcmp.lt.f32.partialorder %v75812, 5.0 (stack56)
        %v75820 = vsel /*vm=*/%vm75815, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v75824 = vsel /*vm=*/%vm75815, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v75828 = vsel /*vm=*/%vm75815, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v75832 = vsel /*vm=*/%vm75815, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v75836 = vsel /*vm=*/%vm75815, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v75840 = vsel /*vm=*/%vm75815, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v75844 = vsel /*vm=*/%vm75815, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v75848 = vsel /*vm=*/%vm75815, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v75852 = vsel /*vm=*/%vm75815, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v75856 = vadd.f32 -2.5, %v75812 (stack52)
        %v75858 = vrsqrt.pop %v75812 (stack67)
        %v75859 = vmul.f32 %v75858, %v75812 (stack68)
        %vm75860 = vcmp.eq.f32.partialorder %v75812, inf (stack69)
        %v75861 = vsel /*vm=*/%vm75860, /*on_true_vy=*/%v75812, /*on_false_vx=*/%v75859 (stack70)
        %vm75862 = vcmp.eq.f32.partialorder %v75812, 0.0 (stack71)
        %v75863 = vand.u32 2147483648, %v75812 (stack72)
        %v75864 = vsel /*vm=*/%vm75862, /*on_true_vy=*/%v75863, /*on_false_vx=*/%v75861 (stack73)
        %v75867 = vadd.f32 -3.0, %v75864 (stack52)
        %v75871 = vsel /*vm=*/%vm75815, /*on_true_vy=*/%v75856, /*on_false_vx=*/%v75867 (stack43)
        %v75875 = vmul.f32 %v75871, %v75852 (stack53)
        %v75879 = vadd.f32 %v75875, %v75848 (stack52)
        %v75883 = vmul.f32 %v75879, %v75871 (stack53)
        %v75887 = vadd.f32 %v75883, %v75844 (stack52)
        %v75891 = vmul.f32 %v75887, %v75871 (stack53)
        %v75895 = vadd.f32 %v75891, %v75840 (stack52)
        %v75899 = vmul.f32 %v75895, %v75871 (stack53)
        %v75903 = vadd.f32 %v75899, %v75836 (stack52)
        %v75907 = vmul.f32 %v75903, %v75871 (stack53)
        %v75911 = vadd.f32 %v75907, %v75832 (stack52)
        %v75915 = vmul.f32 %v75911, %v75871 (stack53)
        %v75919 = vadd.f32 %v75915, %v75828 (stack52)
        %v75923 = vmul.f32 %v75919, %v75871 (stack53)
        %v75927 = vadd.f32 %v75923, %v75824 (stack52)
        %v75931 = vmul.f32 %v75927, %v75871 (stack53)
        %v75935 = vadd.f32 %v75931, %v75820 (stack52)
        %v75939 = vmul.f32 %v75935, %v75786 (stack53)
        %v75943 = vsel /*vm=*/%vm75791, /*on_true_vy=*/%v75796, /*on_false_vx=*/%v75939 (stack43)
        %v75947 = vmul.f32 1.4140625, %v75943 (stack53)
        %v75950 = vpack.c.bf16 0.0, %v75947 (stack74)
        %120151 = vst [vmem:[%s280 + $0xd0] sm:$0xf] /*vst_source=*/%v75950 (stack75)
        %v75954 = vadd.s32 %v75029, %v1381 (stack39)
        %v75964 = vadd.s32 %v75954, %v415 (stack39)
        %vm75968 = vcmp.lt.u32.totalorder %v75964, %v75954 (stack42)
        %vm75973 = vcmp.lt.u32.totalorder %v75954, %v1381 (stack42)
        %v75978 = vadd.s32 %v75012, %v1368 (stack39)
        %v75982 = vadd.s32 1, %v75978 (stack39)
        %v75986 = vsel /*vm=*/%vm75973, /*on_true_vy=*/%v75982, /*on_false_vx=*/%v75978 (stack43)
        %v75990 = vadd.s32 1, %v75986 (stack39)
        %v75994 = vsel /*vm=*/%vm75968, /*on_true_vy=*/%v75990, /*on_false_vx=*/%v75986 (stack43)
        %v75999 = vadd.s32 %v75994, %v10 (stack39)
        %v76003 = vadd.s32 %v75964, %v9 (stack39)
        %v76007 = vadd.s32 %v76003, %v75999 (stack39)
        %v76009 = vshll.u32 %v76003, 13 (stack44)
        %v76010 = vshrl.u32 %v76003, 19 (stack45)
        %v76011 = vor.u32 %v76010, %v76009 (stack46)
        %v76012 = vxor.u32 %v76011, %v76007 (stack47)
        %v76015 = vadd.s32 %v76012, %v76007 (stack39)
        %v76017 = vshll.u32 %v76012, 15 (stack44)
        %v76018 = vshrl.u32 %v76012, 17 (stack45)
        %v76019 = vor.u32 %v76018, %v76017 (stack46)
        %v76020 = vxor.u32 %v76019, %v76015 (stack47)
        %v76023 = vadd.s32 %v76020, %v76015 (stack39)
        %v76025 = vshll.u32 %v76020, 26 (stack44)
        %v76026 = vshrl.u32 %v76020, 6 (stack45)
        %v76027 = vor.u32 %v76026, %v76025 (stack46)
        %v76028 = vxor.u32 %v76027, %v76023 (stack47)
        %v76031 = vadd.s32 %v76028, %v76023 (stack39)
        %v76035 = vadd.s32 %v76031, %v9 (stack39)
        %v76037 = vshll.u32 %v76028, 6 (stack44)
        %v76038 = vshrl.u32 %v76028, 26 (stack45)
        %v76039 = vor.u32 %v76038, %v76037 (stack46)
        %v76040 = vxor.u32 %v76039, %v76031 (stack47)
        %v76043 = vadd.s32 %v76040, %v8 (stack39)
        %v76047 = vadd.s32 1, %v76043 (stack39)
        %v76051 = vadd.s32 %v76047, %v76035 (stack39)
        %v76053 = vshll.u32 %v76047, 17 (stack44)
        %v76054 = vshrl.u32 %v76047, 15 (stack45)
        %v76055 = vor.u32 %v76054, %v76053 (stack46)
        %v76056 = vxor.u32 %v76055, %v76051 (stack47)
        %v76059 = vadd.s32 %v76056, %v76051 (stack39)
        %v76061 = vshll.u32 %v76056, 29 (stack44)
        %v76062 = vshrl.u32 %v76056, 3 (stack45)
        %v76063 = vor.u32 %v76062, %v76061 (stack46)
        %v76064 = vxor.u32 %v76063, %v76059 (stack47)
        %v76067 = vadd.s32 %v76064, %v76059 (stack39)
        %v76069 = vshll.u32 %v76064, 16 (stack44)
        %v76070 = vshrl.u32 %v76064, 16 (stack45)
        %v76071 = vor.u32 %v76070, %v76069 (stack46)
        %v76072 = vxor.u32 %v76071, %v76067 (stack47)
        %v76075 = vadd.s32 %v76072, %v76067 (stack39)
        %v76079 = vadd.s32 %v76075, %v8 (stack39)
        %v76081 = vshll.u32 %v76072, 24 (stack44)
        %v76082 = vshrl.u32 %v76072, 8 (stack45)
        %v76083 = vor.u32 %v76082, %v76081 (stack46)
        %v76084 = vxor.u32 %v76083, %v76075 (stack47)
        %v76087 = vadd.s32 %v76084, %v10 (stack39)
        %v76091 = vadd.s32 2, %v76087 (stack39)
        %v76095 = vadd.s32 %v76091, %v76079 (stack39)
        %v76097 = vshll.u32 %v76091, 13 (stack44)
        %v76098 = vshrl.u32 %v76091, 19 (stack45)
        %v76099 = vor.u32 %v76098, %v76097 (stack46)
        %v76100 = vxor.u32 %v76099, %v76095 (stack47)
        %v76103 = vadd.s32 %v76100, %v76095 (stack39)
        %v76105 = vshll.u32 %v76100, 15 (stack44)
        %v76106 = vshrl.u32 %v76100, 17 (stack45)
        %v76107 = vor.u32 %v76106, %v76105 (stack46)
        %v76108 = vxor.u32 %v76107, %v76103 (stack47)
        %v76111 = vadd.s32 %v76108, %v76103 (stack39)
        %v76113 = vshll.u32 %v76108, 26 (stack44)
        %v76114 = vshrl.u32 %v76108, 6 (stack45)
        %v76115 = vor.u32 %v76114, %v76113 (stack46)
        %v76116 = vxor.u32 %v76115, %v76111 (stack47)
        %v76119 = vadd.s32 %v76116, %v76111 (stack39)
        %v76123 = vadd.s32 %v76119, %v10 (stack39)
        %v76125 = vshll.u32 %v76116, 6 (stack44)
        %v76126 = vshrl.u32 %v76116, 26 (stack45)
        %v76127 = vor.u32 %v76126, %v76125 (stack46)
        %v76128 = vxor.u32 %v76127, %v76119 (stack47)
        %v76131 = vadd.s32 %v76128, %v9 (stack39)
        %v76135 = vadd.s32 3, %v76131 (stack39)
        %v76139 = vadd.s32 %v76135, %v76123 (stack39)
        %v76141 = vshll.u32 %v76135, 17 (stack44)
        %v76142 = vshrl.u32 %v76135, 15 (stack45)
        %v76143 = vor.u32 %v76142, %v76141 (stack46)
        %v76144 = vxor.u32 %v76143, %v76139 (stack47)
        %v76147 = vadd.s32 %v76144, %v76139 (stack39)
        %v76149 = vshll.u32 %v76144, 29 (stack44)
        %v76150 = vshrl.u32 %v76144, 3 (stack45)
        %v76151 = vor.u32 %v76150, %v76149 (stack46)
        %v76152 = vxor.u32 %v76151, %v76147 (stack47)
        %v76155 = vadd.s32 %v76152, %v76147 (stack39)
        %v76157 = vshll.u32 %v76152, 16 (stack44)
        %v76158 = vshrl.u32 %v76152, 16 (stack45)
        %v76159 = vor.u32 %v76158, %v76157 (stack46)
        %v76160 = vxor.u32 %v76159, %v76155 (stack47)
        %v76163 = vadd.s32 %v76160, %v76155 (stack39)
        %v76167 = vadd.s32 %v76163, %v9 (stack39)
        %v76169 = vshll.u32 %v76160, 24 (stack44)
        %v76170 = vshrl.u32 %v76160, 8 (stack45)
        %v76171 = vor.u32 %v76170, %v76169 (stack46)
        %v76172 = vxor.u32 %v76171, %v76163 (stack47)
        %v76175 = vadd.s32 %v76172, %v8 (stack39)
        %v76179 = vadd.s32 4, %v76175 (stack39)
        %v76183 = vadd.s32 %v76179, %v76167 (stack39)
        %v76185 = vshll.u32 %v76179, 13 (stack44)
        %v76186 = vshrl.u32 %v76179, 19 (stack45)
        %v76187 = vor.u32 %v76186, %v76185 (stack46)
        %v76188 = vxor.u32 %v76187, %v76183 (stack47)
        %v76191 = vadd.s32 %v76188, %v76183 (stack39)
        %v76193 = vshll.u32 %v76188, 15 (stack44)
        %v76194 = vshrl.u32 %v76188, 17 (stack45)
        %v76195 = vor.u32 %v76194, %v76193 (stack46)
        %v76196 = vxor.u32 %v76195, %v76191 (stack47)
        %v76199 = vadd.s32 %v76196, %v76191 (stack39)
        %v76201 = vshll.u32 %v76196, 26 (stack44)
        %v76202 = vshrl.u32 %v76196, 6 (stack45)
        %v76203 = vor.u32 %v76202, %v76201 (stack46)
        %v76204 = vxor.u32 %v76203, %v76199 (stack47)
        %v76207 = vadd.s32 %v76204, %v76199 (stack39)
        %v76211 = vadd.s32 %v76207, %v8 (stack39)
        %v76213 = vshll.u32 %v76204, 6 (stack44)
        %v76214 = vshrl.u32 %v76204, 26 (stack45)
        %v76215 = vor.u32 %v76214, %v76213 (stack46)
        %v76216 = vxor.u32 %v76215, %v76207 (stack47)
        %v76219 = vadd.s32 %v76216, %v10 (stack39)
        %v76223 = vadd.s32 5, %v76219 (stack39)
        %v76225 = vxor.u32 %v76223, %v76211 (stack47)
        %v76226 = vand.u32.u8 255, %v76225 (stack48)
        %v76227 = vand.u32 65535, %v76226 (stack49)
        %v76228 = vshrl.u32 %v76227, 1 (stack50)
        %v76229 = vor.u32 16256, %v76228 (stack46)
        %v76230 = vand.u32.u16 65535, %v76229 (stack51)
        %v120152 = vadd.low.f32.bf16 -1.0, %v76230 (stack52)
        %v76239 = vmul.f32 2.0, %v120152 (stack53)
        %v76243 = vadd.f32 -0.99609375, %v76239 (stack52)
        %v76247 = vmax.f32 %v76243, -0.99609375 (stack54)
        %v76249 = vand.u32 2147483647, %v76247 (stack55)
        %vm76252 = vcmp.eq.f32.partialorder %v76249, 1.0 (stack56)
        %v76257 = vmul.f32 inf, %v76247 (stack53)
        %v76259 = vxor.u32 2147483648, %v76247 (stack57)
        %v76262 = vmul.f32 %v76259, %v76247 (stack53)
        %v76264 = vadd.f32 1.0, %v76262 (stack58)
        %v76265 = vlog2.pop %v76264 (stack59)
        %v76266 = vmul.f32 0.6931472, %v76265 (stack60)
        %v76267 = vmul.f32 -0.5, %v76262 (stack61)
        %v76268 = vadd.f32 1.0, %v76267 (stack62)
        %v76269 = vmul.f32 %v76268, %v76262 (stack63)
        %v76270 = vand.u32 2147483647, %v76262 (stack64)
        %vm76271 = vcmp.lt.f32.partialorder %v76270, 0.0004427343 (stack65)
        %v76272 = vsel /*vm=*/%vm76271, /*on_true_vy=*/%v76269, /*on_false_vx=*/%v76266 (stack66)
        %v76273 = vxor.u32 2147483648, %v76272 (stack57)
        %vm76276 = vcmp.lt.f32.partialorder %v76273, 5.0 (stack56)
        %v76281 = vsel /*vm=*/%vm76276, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v76285 = vsel /*vm=*/%vm76276, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v76289 = vsel /*vm=*/%vm76276, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v76293 = vsel /*vm=*/%vm76276, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v76297 = vsel /*vm=*/%vm76276, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v76301 = vsel /*vm=*/%vm76276, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v76305 = vsel /*vm=*/%vm76276, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v76309 = vsel /*vm=*/%vm76276, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v76313 = vsel /*vm=*/%vm76276, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v76317 = vadd.f32 -2.5, %v76273 (stack52)
        %v76319 = vrsqrt.pop %v76273 (stack67)
        %v76320 = vmul.f32 %v76319, %v76273 (stack68)
        %vm76321 = vcmp.eq.f32.partialorder %v76273, inf (stack69)
        %v76322 = vsel /*vm=*/%vm76321, /*on_true_vy=*/%v76273, /*on_false_vx=*/%v76320 (stack70)
        %vm76323 = vcmp.eq.f32.partialorder %v76273, 0.0 (stack71)
        %v76324 = vand.u32 2147483648, %v76273 (stack72)
        %v76325 = vsel /*vm=*/%vm76323, /*on_true_vy=*/%v76324, /*on_false_vx=*/%v76322 (stack73)
        %v76328 = vadd.f32 -3.0, %v76325 (stack52)
        %v76332 = vsel /*vm=*/%vm76276, /*on_true_vy=*/%v76317, /*on_false_vx=*/%v76328 (stack43)
        %v76336 = vmul.f32 %v76332, %v76313 (stack53)
        %v76340 = vadd.f32 %v76336, %v76309 (stack52)
        %v76344 = vmul.f32 %v76340, %v76332 (stack53)
        %v76348 = vadd.f32 %v76344, %v76305 (stack52)
        %v76352 = vmul.f32 %v76348, %v76332 (stack53)
        %v76356 = vadd.f32 %v76352, %v76301 (stack52)
        %v76360 = vmul.f32 %v76356, %v76332 (stack53)
        %v76364 = vadd.f32 %v76360, %v76297 (stack52)
        %v76368 = vmul.f32 %v76364, %v76332 (stack53)
        %v76372 = vadd.f32 %v76368, %v76293 (stack52)
        %v76376 = vmul.f32 %v76372, %v76332 (stack53)
        %v76380 = vadd.f32 %v76376, %v76289 (stack52)
        %v76384 = vmul.f32 %v76380, %v76332 (stack53)
        %v76388 = vadd.f32 %v76384, %v76285 (stack52)
        %v76392 = vmul.f32 %v76388, %v76332 (stack53)
        %v76396 = vadd.f32 %v76392, %v76281 (stack52)
        %v76400 = vmul.f32 %v76396, %v76247 (stack53)
        %v76404 = vsel /*vm=*/%vm76252, /*on_true_vy=*/%v76257, /*on_false_vx=*/%v76400 (stack43)
        %v76408 = vmul.f32 1.4140625, %v76404 (stack53)
        %v76411 = vpack.c.bf16 0.0, %v76408 (stack74)
        %120153 = vst [vmem:[%s280 + $0x150] sm:$0xf] /*vst_source=*/%v76411 (stack75)
        %v76415 = vadd.s32 %v75029, %v1868 (stack39)
        %v76425 = vadd.s32 %v76415, %v415 (stack39)
        %vm76429 = vcmp.lt.u32.totalorder %v76425, %v76415 (stack42)
        %vm76434 = vcmp.lt.u32.totalorder %v76415, %v1868 (stack42)
        %v76439 = vadd.s32 %v75012, %v1855 (stack39)
        %v76443 = vadd.s32 1, %v76439 (stack39)
        %v76447 = vsel /*vm=*/%vm76434, /*on_true_vy=*/%v76443, /*on_false_vx=*/%v76439 (stack43)
        %v76451 = vadd.s32 1, %v76447 (stack39)
        %v76455 = vsel /*vm=*/%vm76429, /*on_true_vy=*/%v76451, /*on_false_vx=*/%v76447 (stack43)
        %v76460 = vadd.s32 %v76455, %v10 (stack39)
        %v76464 = vadd.s32 %v76425, %v9 (stack39)
        %v76468 = vadd.s32 %v76464, %v76460 (stack39)
        %v76470 = vshll.u32 %v76464, 13 (stack44)
        %v76471 = vshrl.u32 %v76464, 19 (stack45)
        %v76472 = vor.u32 %v76471, %v76470 (stack46)
        %v76473 = vxor.u32 %v76472, %v76468 (stack47)
        %v76476 = vadd.s32 %v76473, %v76468 (stack39)
        %v76478 = vshll.u32 %v76473, 15 (stack44)
        %v76479 = vshrl.u32 %v76473, 17 (stack45)
        %v76480 = vor.u32 %v76479, %v76478 (stack46)
        %v76481 = vxor.u32 %v76480, %v76476 (stack47)
        %v76484 = vadd.s32 %v76481, %v76476 (stack39)
        %v76486 = vshll.u32 %v76481, 26 (stack44)
        %v76487 = vshrl.u32 %v76481, 6 (stack45)
        %v76488 = vor.u32 %v76487, %v76486 (stack46)
        %v76489 = vxor.u32 %v76488, %v76484 (stack47)
        %v76492 = vadd.s32 %v76489, %v76484 (stack39)
        %v76496 = vadd.s32 %v76492, %v9 (stack39)
        %v76498 = vshll.u32 %v76489, 6 (stack44)
        %v76499 = vshrl.u32 %v76489, 26 (stack45)
        %v76500 = vor.u32 %v76499, %v76498 (stack46)
        %v76501 = vxor.u32 %v76500, %v76492 (stack47)
        %v76504 = vadd.s32 %v76501, %v8 (stack39)
        %v76508 = vadd.s32 1, %v76504 (stack39)
        %v76512 = vadd.s32 %v76508, %v76496 (stack39)
        %v76514 = vshll.u32 %v76508, 17 (stack44)
        %v76515 = vshrl.u32 %v76508, 15 (stack45)
        %v76516 = vor.u32 %v76515, %v76514 (stack46)
        %v76517 = vxor.u32 %v76516, %v76512 (stack47)
        %v76520 = vadd.s32 %v76517, %v76512 (stack39)
        %v76522 = vshll.u32 %v76517, 29 (stack44)
        %v76523 = vshrl.u32 %v76517, 3 (stack45)
        %v76524 = vor.u32 %v76523, %v76522 (stack46)
        %v76525 = vxor.u32 %v76524, %v76520 (stack47)
        %v76528 = vadd.s32 %v76525, %v76520 (stack39)
        %v76530 = vshll.u32 %v76525, 16 (stack44)
        %v76531 = vshrl.u32 %v76525, 16 (stack45)
        %v76532 = vor.u32 %v76531, %v76530 (stack46)
        %v76533 = vxor.u32 %v76532, %v76528 (stack47)
        %v76536 = vadd.s32 %v76533, %v76528 (stack39)
        %v76540 = vadd.s32 %v76536, %v8 (stack39)
        %v76542 = vshll.u32 %v76533, 24 (stack44)
        %v76543 = vshrl.u32 %v76533, 8 (stack45)
        %v76544 = vor.u32 %v76543, %v76542 (stack46)
        %v76545 = vxor.u32 %v76544, %v76536 (stack47)
        %v76548 = vadd.s32 %v76545, %v10 (stack39)
        %v76552 = vadd.s32 2, %v76548 (stack39)
        %v76556 = vadd.s32 %v76552, %v76540 (stack39)
        %v76558 = vshll.u32 %v76552, 13 (stack44)
        %v76559 = vshrl.u32 %v76552, 19 (stack45)
        %v76560 = vor.u32 %v76559, %v76558 (stack46)
        %v76561 = vxor.u32 %v76560, %v76556 (stack47)
        %v76564 = vadd.s32 %v76561, %v76556 (stack39)
        %v76566 = vshll.u32 %v76561, 15 (stack44)
        %v76567 = vshrl.u32 %v76561, 17 (stack45)
        %v76568 = vor.u32 %v76567, %v76566 (stack46)
        %v76569 = vxor.u32 %v76568, %v76564 (stack47)
        %v76572 = vadd.s32 %v76569, %v76564 (stack39)
        %v76574 = vshll.u32 %v76569, 26 (stack44)
        %v76575 = vshrl.u32 %v76569, 6 (stack45)
        %v76576 = vor.u32 %v76575, %v76574 (stack46)
        %v76577 = vxor.u32 %v76576, %v76572 (stack47)
        %v76580 = vadd.s32 %v76577, %v76572 (stack39)
        %v76584 = vadd.s32 %v76580, %v10 (stack39)
        %v76586 = vshll.u32 %v76577, 6 (stack44)
        %v76587 = vshrl.u32 %v76577, 26 (stack45)
        %v76588 = vor.u32 %v76587, %v76586 (stack46)
        %v76589 = vxor.u32 %v76588, %v76580 (stack47)
        %v76592 = vadd.s32 %v76589, %v9 (stack39)
        %v76596 = vadd.s32 3, %v76592 (stack39)
        %v76600 = vadd.s32 %v76596, %v76584 (stack39)
        %v76602 = vshll.u32 %v76596, 17 (stack44)
        %v76603 = vshrl.u32 %v76596, 15 (stack45)
        %v76604 = vor.u32 %v76603, %v76602 (stack46)
        %v76605 = vxor.u32 %v76604, %v76600 (stack47)
        %v76608 = vadd.s32 %v76605, %v76600 (stack39)
        %v76610 = vshll.u32 %v76605, 29 (stack44)
        %v76611 = vshrl.u32 %v76605, 3 (stack45)
        %v76612 = vor.u32 %v76611, %v76610 (stack46)
        %v76613 = vxor.u32 %v76612, %v76608 (stack47)
        %v76616 = vadd.s32 %v76613, %v76608 (stack39)
        %v76618 = vshll.u32 %v76613, 16 (stack44)
        %v76619 = vshrl.u32 %v76613, 16 (stack45)
        %v76620 = vor.u32 %v76619, %v76618 (stack46)
        %v76621 = vxor.u32 %v76620, %v76616 (stack47)
        %v76624 = vadd.s32 %v76621, %v76616 (stack39)
        %v76628 = vadd.s32 %v76624, %v9 (stack39)
        %v76630 = vshll.u32 %v76621, 24 (stack44)
        %v76631 = vshrl.u32 %v76621, 8 (stack45)
        %v76632 = vor.u32 %v76631, %v76630 (stack46)
        %v76633 = vxor.u32 %v76632, %v76624 (stack47)
        %v76636 = vadd.s32 %v76633, %v8 (stack39)
        %v76640 = vadd.s32 4, %v76636 (stack39)
        %v76644 = vadd.s32 %v76640, %v76628 (stack39)
        %v76646 = vshll.u32 %v76640, 13 (stack44)
        %v76647 = vshrl.u32 %v76640, 19 (stack45)
        %v76648 = vor.u32 %v76647, %v76646 (stack46)
        %v76649 = vxor.u32 %v76648, %v76644 (stack47)
        %v76652 = vadd.s32 %v76649, %v76644 (stack39)
        %v76654 = vshll.u32 %v76649, 15 (stack44)
        %v76655 = vshrl.u32 %v76649, 17 (stack45)
        %v76656 = vor.u32 %v76655, %v76654 (stack46)
        %v76657 = vxor.u32 %v76656, %v76652 (stack47)
        %v76660 = vadd.s32 %v76657, %v76652 (stack39)
        %v76662 = vshll.u32 %v76657, 26 (stack44)
        %v76663 = vshrl.u32 %v76657, 6 (stack45)
        %v76664 = vor.u32 %v76663, %v76662 (stack46)
        %v76665 = vxor.u32 %v76664, %v76660 (stack47)
        %v76668 = vadd.s32 %v76665, %v76660 (stack39)
        %v76672 = vadd.s32 %v76668, %v8 (stack39)
        %v76674 = vshll.u32 %v76665, 6 (stack44)
        %v76675 = vshrl.u32 %v76665, 26 (stack45)
        %v76676 = vor.u32 %v76675, %v76674 (stack46)
        %v76677 = vxor.u32 %v76676, %v76668 (stack47)
        %v76680 = vadd.s32 %v76677, %v10 (stack39)
        %v76684 = vadd.s32 5, %v76680 (stack39)
        %v76686 = vxor.u32 %v76684, %v76672 (stack47)
        %v76687 = vand.u32.u8 255, %v76686 (stack48)
        %v76688 = vand.u32 65535, %v76687 (stack49)
        %v76689 = vshrl.u32 %v76688, 1 (stack50)
        %v76690 = vor.u32 16256, %v76689 (stack46)
        %v76691 = vand.u32.u16 65535, %v76690 (stack51)
        %v120154 = vadd.low.f32.bf16 -1.0, %v76691 (stack52)
        %v76700 = vmul.f32 2.0, %v120154 (stack53)
        %v76704 = vadd.f32 -0.99609375, %v76700 (stack52)
        %v76708 = vmax.f32 %v76704, -0.99609375 (stack54)
        %v76710 = vand.u32 2147483647, %v76708 (stack55)
        %vm76713 = vcmp.eq.f32.partialorder %v76710, 1.0 (stack56)
        %v76718 = vmul.f32 inf, %v76708 (stack53)
        %v76720 = vxor.u32 2147483648, %v76708 (stack57)
        %v76723 = vmul.f32 %v76720, %v76708 (stack53)
        %v76725 = vadd.f32 1.0, %v76723 (stack58)
        %v76726 = vlog2.pop %v76725 (stack59)
        %v76727 = vmul.f32 0.6931472, %v76726 (stack60)
        %v76728 = vmul.f32 -0.5, %v76723 (stack61)
        %v76729 = vadd.f32 1.0, %v76728 (stack62)
        %v76730 = vmul.f32 %v76729, %v76723 (stack63)
        %v76731 = vand.u32 2147483647, %v76723 (stack64)
        %vm76732 = vcmp.lt.f32.partialorder %v76731, 0.0004427343 (stack65)
        %v76733 = vsel /*vm=*/%vm76732, /*on_true_vy=*/%v76730, /*on_false_vx=*/%v76727 (stack66)
        %v76734 = vxor.u32 2147483648, %v76733 (stack57)
        %vm76737 = vcmp.lt.f32.partialorder %v76734, 5.0 (stack56)
        %v76742 = vsel /*vm=*/%vm76737, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v76746 = vsel /*vm=*/%vm76737, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v76750 = vsel /*vm=*/%vm76737, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v76754 = vsel /*vm=*/%vm76737, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v76758 = vsel /*vm=*/%vm76737, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v76762 = vsel /*vm=*/%vm76737, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v76766 = vsel /*vm=*/%vm76737, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v76770 = vsel /*vm=*/%vm76737, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v76774 = vsel /*vm=*/%vm76737, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v76778 = vadd.f32 -2.5, %v76734 (stack52)
        %v76780 = vrsqrt.pop %v76734 (stack67)
        %v76781 = vmul.f32 %v76780, %v76734 (stack68)
        %vm76782 = vcmp.eq.f32.partialorder %v76734, inf (stack69)
        %v76783 = vsel /*vm=*/%vm76782, /*on_true_vy=*/%v76734, /*on_false_vx=*/%v76781 (stack70)
        %vm76784 = vcmp.eq.f32.partialorder %v76734, 0.0 (stack71)
        %v76785 = vand.u32 2147483648, %v76734 (stack72)
        %v76786 = vsel /*vm=*/%vm76784, /*on_true_vy=*/%v76785, /*on_false_vx=*/%v76783 (stack73)
        %v76789 = vadd.f32 -3.0, %v76786 (stack52)
        %v76793 = vsel /*vm=*/%vm76737, /*on_true_vy=*/%v76778, /*on_false_vx=*/%v76789 (stack43)
        %v76797 = vmul.f32 %v76793, %v76774 (stack53)
        %v76801 = vadd.f32 %v76797, %v76770 (stack52)
        %v76805 = vmul.f32 %v76801, %v76793 (stack53)
        %v76809 = vadd.f32 %v76805, %v76766 (stack52)
        %v76813 = vmul.f32 %v76809, %v76793 (stack53)
        %v76817 = vadd.f32 %v76813, %v76762 (stack52)
        %v76821 = vmul.f32 %v76817, %v76793 (stack53)
        %v76825 = vadd.f32 %v76821, %v76758 (stack52)
        %v76829 = vmul.f32 %v76825, %v76793 (stack53)
        %v76833 = vadd.f32 %v76829, %v76754 (stack52)
        %v76837 = vmul.f32 %v76833, %v76793 (stack53)
        %v76841 = vadd.f32 %v76837, %v76750 (stack52)
        %v76845 = vmul.f32 %v76841, %v76793 (stack53)
        %v76849 = vadd.f32 %v76845, %v76746 (stack52)
        %v76853 = vmul.f32 %v76849, %v76793 (stack53)
        %v76857 = vadd.f32 %v76853, %v76742 (stack52)
        %v76861 = vmul.f32 %v76857, %v76708 (stack53)
        %v76865 = vsel /*vm=*/%vm76713, /*on_true_vy=*/%v76718, /*on_false_vx=*/%v76861 (stack43)
        %v76869 = vmul.f32 1.4140625, %v76865 (stack53)
        %v76872 = vpack.c.bf16 0.0, %v76869 (stack74)
        %120155 = vst [vmem:[%s280 + $0x1d0] sm:$0xf] /*vst_source=*/%v76872 (stack75)
        %v76876 = vadd.s32 %v75029, %v2355 (stack39)
        %v76886 = vadd.s32 %v76876, %v415 (stack39)
        %vm76890 = vcmp.lt.u32.totalorder %v76886, %v76876 (stack42)
        %vm76895 = vcmp.lt.u32.totalorder %v76876, %v2355 (stack42)
        %v76900 = vadd.s32 %v75012, %v2342 (stack39)
        %v76904 = vadd.s32 1, %v76900 (stack39)
        %v76908 = vsel /*vm=*/%vm76895, /*on_true_vy=*/%v76904, /*on_false_vx=*/%v76900 (stack43)
        %v76912 = vadd.s32 1, %v76908 (stack39)
        %v76916 = vsel /*vm=*/%vm76890, /*on_true_vy=*/%v76912, /*on_false_vx=*/%v76908 (stack43)
        %v76921 = vadd.s32 %v76916, %v10 (stack39)
        %v76925 = vadd.s32 %v76886, %v9 (stack39)
        %v76929 = vadd.s32 %v76925, %v76921 (stack39)
        %v76931 = vshll.u32 %v76925, 13 (stack44)
        %v76932 = vshrl.u32 %v76925, 19 (stack45)
        %v76933 = vor.u32 %v76932, %v76931 (stack46)
        %v76934 = vxor.u32 %v76933, %v76929 (stack47)
        %v76937 = vadd.s32 %v76934, %v76929 (stack39)
        %v76939 = vshll.u32 %v76934, 15 (stack44)
        %v76940 = vshrl.u32 %v76934, 17 (stack45)
        %v76941 = vor.u32 %v76940, %v76939 (stack46)
        %v76942 = vxor.u32 %v76941, %v76937 (stack47)
        %v76945 = vadd.s32 %v76942, %v76937 (stack39)
        %v76947 = vshll.u32 %v76942, 26 (stack44)
        %v76948 = vshrl.u32 %v76942, 6 (stack45)
        %v76949 = vor.u32 %v76948, %v76947 (stack46)
        %v76950 = vxor.u32 %v76949, %v76945 (stack47)
        %v76953 = vadd.s32 %v76950, %v76945 (stack39)
        %v76957 = vadd.s32 %v76953, %v9 (stack39)
        %v76959 = vshll.u32 %v76950, 6 (stack44)
        %v76960 = vshrl.u32 %v76950, 26 (stack45)
        %v76961 = vor.u32 %v76960, %v76959 (stack46)
        %v76962 = vxor.u32 %v76961, %v76953 (stack47)
        %v76965 = vadd.s32 %v76962, %v8 (stack39)
        %v76969 = vadd.s32 1, %v76965 (stack39)
        %v76973 = vadd.s32 %v76969, %v76957 (stack39)
        %v76975 = vshll.u32 %v76969, 17 (stack44)
        %v76976 = vshrl.u32 %v76969, 15 (stack45)
        %v76977 = vor.u32 %v76976, %v76975 (stack46)
        %v76978 = vxor.u32 %v76977, %v76973 (stack47)
        %v76981 = vadd.s32 %v76978, %v76973 (stack39)
        %v76983 = vshll.u32 %v76978, 29 (stack44)
        %v76984 = vshrl.u32 %v76978, 3 (stack45)
        %v76985 = vor.u32 %v76984, %v76983 (stack46)
        %v76986 = vxor.u32 %v76985, %v76981 (stack47)
        %v76989 = vadd.s32 %v76986, %v76981 (stack39)
        %v76991 = vshll.u32 %v76986, 16 (stack44)
        %v76992 = vshrl.u32 %v76986, 16 (stack45)
        %v76993 = vor.u32 %v76992, %v76991 (stack46)
        %v76994 = vxor.u32 %v76993, %v76989 (stack47)
        %v76997 = vadd.s32 %v76994, %v76989 (stack39)
        %v77001 = vadd.s32 %v76997, %v8 (stack39)
        %v77003 = vshll.u32 %v76994, 24 (stack44)
        %v77004 = vshrl.u32 %v76994, 8 (stack45)
        %v77005 = vor.u32 %v77004, %v77003 (stack46)
        %v77006 = vxor.u32 %v77005, %v76997 (stack47)
        %v77009 = vadd.s32 %v77006, %v10 (stack39)
        %v77013 = vadd.s32 2, %v77009 (stack39)
        %v77017 = vadd.s32 %v77013, %v77001 (stack39)
        %v77019 = vshll.u32 %v77013, 13 (stack44)
        %v77020 = vshrl.u32 %v77013, 19 (stack45)
        %v77021 = vor.u32 %v77020, %v77019 (stack46)
        %v77022 = vxor.u32 %v77021, %v77017 (stack47)
        %v77025 = vadd.s32 %v77022, %v77017 (stack39)
        %v77027 = vshll.u32 %v77022, 15 (stack44)
        %v77028 = vshrl.u32 %v77022, 17 (stack45)
        %v77029 = vor.u32 %v77028, %v77027 (stack46)
        %v77030 = vxor.u32 %v77029, %v77025 (stack47)
        %v77033 = vadd.s32 %v77030, %v77025 (stack39)
        %v77035 = vshll.u32 %v77030, 26 (stack44)
        %v77036 = vshrl.u32 %v77030, 6 (stack45)
        %v77037 = vor.u32 %v77036, %v77035 (stack46)
        %v77038 = vxor.u32 %v77037, %v77033 (stack47)
        %v77041 = vadd.s32 %v77038, %v77033 (stack39)
        %v77045 = vadd.s32 %v77041, %v10 (stack39)
        %v77047 = vshll.u32 %v77038, 6 (stack44)
        %v77048 = vshrl.u32 %v77038, 26 (stack45)
        %v77049 = vor.u32 %v77048, %v77047 (stack46)
        %v77050 = vxor.u32 %v77049, %v77041 (stack47)
        %v77053 = vadd.s32 %v77050, %v9 (stack39)
        %v77057 = vadd.s32 3, %v77053 (stack39)
        %v77061 = vadd.s32 %v77057, %v77045 (stack39)
        %v77063 = vshll.u32 %v77057, 17 (stack44)
        %v77064 = vshrl.u32 %v77057, 15 (stack45)
        %v77065 = vor.u32 %v77064, %v77063 (stack46)
        %v77066 = vxor.u32 %v77065, %v77061 (stack47)
        %v77069 = vadd.s32 %v77066, %v77061 (stack39)
        %v77071 = vshll.u32 %v77066, 29 (stack44)
        %v77072 = vshrl.u32 %v77066, 3 (stack45)
        %v77073 = vor.u32 %v77072, %v77071 (stack46)
        %v77074 = vxor.u32 %v77073, %v77069 (stack47)
        %v77077 = vadd.s32 %v77074, %v77069 (stack39)
        %v77079 = vshll.u32 %v77074, 16 (stack44)
        %v77080 = vshrl.u32 %v77074, 16 (stack45)
        %v77081 = vor.u32 %v77080, %v77079 (stack46)
        %v77082 = vxor.u32 %v77081, %v77077 (stack47)
        %v77085 = vadd.s32 %v77082, %v77077 (stack39)
        %v77089 = vadd.s32 %v77085, %v9 (stack39)
        %v77091 = vshll.u32 %v77082, 24 (stack44)
        %v77092 = vshrl.u32 %v77082, 8 (stack45)
        %v77093 = vor.u32 %v77092, %v77091 (stack46)
        %v77094 = vxor.u32 %v77093, %v77085 (stack47)
        %v77097 = vadd.s32 %v77094, %v8 (stack39)
        %v77101 = vadd.s32 4, %v77097 (stack39)
        %v77105 = vadd.s32 %v77101, %v77089 (stack39)
        %v77107 = vshll.u32 %v77101, 13 (stack44)
        %v77108 = vshrl.u32 %v77101, 19 (stack45)
        %v77109 = vor.u32 %v77108, %v77107 (stack46)
        %v77110 = vxor.u32 %v77109, %v77105 (stack47)
        %v77113 = vadd.s32 %v77110, %v77105 (stack39)
        %v77115 = vshll.u32 %v77110, 15 (stack44)
        %v77116 = vshrl.u32 %v77110, 17 (stack45)
        %v77117 = vor.u32 %v77116, %v77115 (stack46)
        %v77118 = vxor.u32 %v77117, %v77113 (stack47)
        %v77121 = vadd.s32 %v77118, %v77113 (stack39)
        %v77123 = vshll.u32 %v77118, 26 (stack44)
        %v77124 = vshrl.u32 %v77118, 6 (stack45)
        %v77125 = vor.u32 %v77124, %v77123 (stack46)
        %v77126 = vxor.u32 %v77125, %v77121 (stack47)
        %v77129 = vadd.s32 %v77126, %v77121 (stack39)
        %v77133 = vadd.s32 %v77129, %v8 (stack39)
        %v77135 = vshll.u32 %v77126, 6 (stack44)
        %v77136 = vshrl.u32 %v77126, 26 (stack45)
        %v77137 = vor.u32 %v77136, %v77135 (stack46)
        %v77138 = vxor.u32 %v77137, %v77129 (stack47)
        %v77141 = vadd.s32 %v77138, %v10 (stack39)
        %v77145 = vadd.s32 5, %v77141 (stack39)
        %v77147 = vxor.u32 %v77145, %v77133 (stack47)
        %v77148 = vand.u32.u8 255, %v77147 (stack48)
        %v77149 = vand.u32 65535, %v77148 (stack49)
        %v77150 = vshrl.u32 %v77149, 1 (stack50)
        %v77151 = vor.u32 16256, %v77150 (stack46)
        %v77152 = vand.u32.u16 65535, %v77151 (stack51)
        %v120156 = vadd.low.f32.bf16 -1.0, %v77152 (stack52)
        %v77161 = vmul.f32 2.0, %v120156 (stack53)
        %v77165 = vadd.f32 -0.99609375, %v77161 (stack52)
        %v77169 = vmax.f32 %v77165, -0.99609375 (stack54)
        %v77171 = vand.u32 2147483647, %v77169 (stack55)
        %vm77174 = vcmp.eq.f32.partialorder %v77171, 1.0 (stack56)
        %v77179 = vmul.f32 inf, %v77169 (stack53)
        %v77181 = vxor.u32 2147483648, %v77169 (stack57)
        %v77184 = vmul.f32 %v77181, %v77169 (stack53)
        %v77186 = vadd.f32 1.0, %v77184 (stack58)
        %v77187 = vlog2.pop %v77186 (stack59)
        %v77188 = vmul.f32 0.6931472, %v77187 (stack60)
        %v77189 = vmul.f32 -0.5, %v77184 (stack61)
        %v77190 = vadd.f32 1.0, %v77189 (stack62)
        %v77191 = vmul.f32 %v77190, %v77184 (stack63)
        %v77192 = vand.u32 2147483647, %v77184 (stack64)
        %vm77193 = vcmp.lt.f32.partialorder %v77192, 0.0004427343 (stack65)
        %v77194 = vsel /*vm=*/%vm77193, /*on_true_vy=*/%v77191, /*on_false_vx=*/%v77188 (stack66)
        %v77195 = vxor.u32 2147483648, %v77194 (stack57)
        %vm77198 = vcmp.lt.f32.partialorder %v77195, 5.0 (stack56)
        %v77203 = vsel /*vm=*/%vm77198, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v77207 = vsel /*vm=*/%vm77198, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v77211 = vsel /*vm=*/%vm77198, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v77215 = vsel /*vm=*/%vm77198, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v77219 = vsel /*vm=*/%vm77198, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v77223 = vsel /*vm=*/%vm77198, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v77227 = vsel /*vm=*/%vm77198, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v77231 = vsel /*vm=*/%vm77198, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v77235 = vsel /*vm=*/%vm77198, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v77239 = vadd.f32 -2.5, %v77195 (stack52)
        %v77241 = vrsqrt.pop %v77195 (stack67)
        %v77242 = vmul.f32 %v77241, %v77195 (stack68)
        %vm77243 = vcmp.eq.f32.partialorder %v77195, inf (stack69)
        %v77244 = vsel /*vm=*/%vm77243, /*on_true_vy=*/%v77195, /*on_false_vx=*/%v77242 (stack70)
        %vm77245 = vcmp.eq.f32.partialorder %v77195, 0.0 (stack71)
        %v77246 = vand.u32 2147483648, %v77195 (stack72)
        %v77247 = vsel /*vm=*/%vm77245, /*on_true_vy=*/%v77246, /*on_false_vx=*/%v77244 (stack73)
        %v77250 = vadd.f32 -3.0, %v77247 (stack52)
        %v77254 = vsel /*vm=*/%vm77198, /*on_true_vy=*/%v77239, /*on_false_vx=*/%v77250 (stack43)
        %v77258 = vmul.f32 %v77254, %v77235 (stack53)
        %v77262 = vadd.f32 %v77258, %v77231 (stack52)
        %v77266 = vmul.f32 %v77262, %v77254 (stack53)
        %v77270 = vadd.f32 %v77266, %v77227 (stack52)
        %v77274 = vmul.f32 %v77270, %v77254 (stack53)
        %v77278 = vadd.f32 %v77274, %v77223 (stack52)
        %v77282 = vmul.f32 %v77278, %v77254 (stack53)
        %v77286 = vadd.f32 %v77282, %v77219 (stack52)
        %v77290 = vmul.f32 %v77286, %v77254 (stack53)
        %v77294 = vadd.f32 %v77290, %v77215 (stack52)
        %v77298 = vmul.f32 %v77294, %v77254 (stack53)
        %v77302 = vadd.f32 %v77298, %v77211 (stack52)
        %v77306 = vmul.f32 %v77302, %v77254 (stack53)
        %v77310 = vadd.f32 %v77306, %v77207 (stack52)
        %v77314 = vmul.f32 %v77310, %v77254 (stack53)
        %v77318 = vadd.f32 %v77314, %v77203 (stack52)
        %v77322 = vmul.f32 %v77318, %v77169 (stack53)
        %v77326 = vsel /*vm=*/%vm77174, /*on_true_vy=*/%v77179, /*on_false_vx=*/%v77322 (stack43)
        %v77330 = vmul.f32 1.4140625, %v77326 (stack53)
        %v77333 = vpack.c.bf16 0.0, %v77330 (stack74)
        %120157 = vst [vmem:[%s280 + $0x250] sm:$0xf] /*vst_source=*/%v77333 (stack75)
        %v77337 = vadd.s32 %v75029, %v2842 (stack39)
        %v77347 = vadd.s32 %v77337, %v415 (stack39)
        %vm77351 = vcmp.lt.u32.totalorder %v77347, %v77337 (stack42)
        %vm77356 = vcmp.lt.u32.totalorder %v77337, %v2842 (stack42)
        %v77361 = vadd.s32 %v75012, %v2829 (stack39)
        %v77365 = vadd.s32 1, %v77361 (stack39)
        %v77369 = vsel /*vm=*/%vm77356, /*on_true_vy=*/%v77365, /*on_false_vx=*/%v77361 (stack43)
        %v77373 = vadd.s32 1, %v77369 (stack39)
        %v77377 = vsel /*vm=*/%vm77351, /*on_true_vy=*/%v77373, /*on_false_vx=*/%v77369 (stack43)
        %v77382 = vadd.s32 %v77377, %v10 (stack39)
        %v77386 = vadd.s32 %v77347, %v9 (stack39)
        %v77390 = vadd.s32 %v77386, %v77382 (stack39)
        %v77392 = vshll.u32 %v77386, 13 (stack44)
        %v77393 = vshrl.u32 %v77386, 19 (stack45)
        %v77394 = vor.u32 %v77393, %v77392 (stack46)
        %v77395 = vxor.u32 %v77394, %v77390 (stack47)
        %v77398 = vadd.s32 %v77395, %v77390 (stack39)
        %v77400 = vshll.u32 %v77395, 15 (stack44)
        %v77401 = vshrl.u32 %v77395, 17 (stack45)
        %v77402 = vor.u32 %v77401, %v77400 (stack46)
        %v77403 = vxor.u32 %v77402, %v77398 (stack47)
        %v77406 = vadd.s32 %v77403, %v77398 (stack39)
        %v77408 = vshll.u32 %v77403, 26 (stack44)
        %v77409 = vshrl.u32 %v77403, 6 (stack45)
        %v77410 = vor.u32 %v77409, %v77408 (stack46)
        %v77411 = vxor.u32 %v77410, %v77406 (stack47)
        %v77414 = vadd.s32 %v77411, %v77406 (stack39)
        %v77418 = vadd.s32 %v77414, %v9 (stack39)
        %v77420 = vshll.u32 %v77411, 6 (stack44)
        %v77421 = vshrl.u32 %v77411, 26 (stack45)
        %v77422 = vor.u32 %v77421, %v77420 (stack46)
        %v77423 = vxor.u32 %v77422, %v77414 (stack47)
        %v77426 = vadd.s32 %v77423, %v8 (stack39)
        %v77430 = vadd.s32 1, %v77426 (stack39)
        %v77434 = vadd.s32 %v77430, %v77418 (stack39)
        %v77436 = vshll.u32 %v77430, 17 (stack44)
        %v77437 = vshrl.u32 %v77430, 15 (stack45)
        %v77438 = vor.u32 %v77437, %v77436 (stack46)
        %v77439 = vxor.u32 %v77438, %v77434 (stack47)
        %v77442 = vadd.s32 %v77439, %v77434 (stack39)
        %v77444 = vshll.u32 %v77439, 29 (stack44)
        %v77445 = vshrl.u32 %v77439, 3 (stack45)
        %v77446 = vor.u32 %v77445, %v77444 (stack46)
        %v77447 = vxor.u32 %v77446, %v77442 (stack47)
        %v77450 = vadd.s32 %v77447, %v77442 (stack39)
        %v77452 = vshll.u32 %v77447, 16 (stack44)
        %v77453 = vshrl.u32 %v77447, 16 (stack45)
        %v77454 = vor.u32 %v77453, %v77452 (stack46)
        %v77455 = vxor.u32 %v77454, %v77450 (stack47)
        %v77458 = vadd.s32 %v77455, %v77450 (stack39)
        %v77462 = vadd.s32 %v77458, %v8 (stack39)
        %v77464 = vshll.u32 %v77455, 24 (stack44)
        %v77465 = vshrl.u32 %v77455, 8 (stack45)
        %v77466 = vor.u32 %v77465, %v77464 (stack46)
        %v77467 = vxor.u32 %v77466, %v77458 (stack47)
        %v77470 = vadd.s32 %v77467, %v10 (stack39)
        %v77474 = vadd.s32 2, %v77470 (stack39)
        %v77478 = vadd.s32 %v77474, %v77462 (stack39)
        %v77480 = vshll.u32 %v77474, 13 (stack44)
        %v77481 = vshrl.u32 %v77474, 19 (stack45)
        %v77482 = vor.u32 %v77481, %v77480 (stack46)
        %v77483 = vxor.u32 %v77482, %v77478 (stack47)
        %v77486 = vadd.s32 %v77483, %v77478 (stack39)
        %v77488 = vshll.u32 %v77483, 15 (stack44)
        %v77489 = vshrl.u32 %v77483, 17 (stack45)
        %v77490 = vor.u32 %v77489, %v77488 (stack46)
        %v77491 = vxor.u32 %v77490, %v77486 (stack47)
        %v77494 = vadd.s32 %v77491, %v77486 (stack39)
        %v77496 = vshll.u32 %v77491, 26 (stack44)
        %v77497 = vshrl.u32 %v77491, 6 (stack45)
        %v77498 = vor.u32 %v77497, %v77496 (stack46)
        %v77499 = vxor.u32 %v77498, %v77494 (stack47)
        %v77502 = vadd.s32 %v77499, %v77494 (stack39)
        %v77506 = vadd.s32 %v77502, %v10 (stack39)
        %v77508 = vshll.u32 %v77499, 6 (stack44)
        %v77509 = vshrl.u32 %v77499, 26 (stack45)
        %v77510 = vor.u32 %v77509, %v77508 (stack46)
        %v77511 = vxor.u32 %v77510, %v77502 (stack47)
        %v77514 = vadd.s32 %v77511, %v9 (stack39)
        %v77518 = vadd.s32 3, %v77514 (stack39)
        %v77522 = vadd.s32 %v77518, %v77506 (stack39)
        %v77524 = vshll.u32 %v77518, 17 (stack44)
        %v77525 = vshrl.u32 %v77518, 15 (stack45)
        %v77526 = vor.u32 %v77525, %v77524 (stack46)
        %v77527 = vxor.u32 %v77526, %v77522 (stack47)
        %v77530 = vadd.s32 %v77527, %v77522 (stack39)
        %v77532 = vshll.u32 %v77527, 29 (stack44)
        %v77533 = vshrl.u32 %v77527, 3 (stack45)
        %v77534 = vor.u32 %v77533, %v77532 (stack46)
        %v77535 = vxor.u32 %v77534, %v77530 (stack47)
        %v77538 = vadd.s32 %v77535, %v77530 (stack39)
        %v77540 = vshll.u32 %v77535, 16 (stack44)
        %v77541 = vshrl.u32 %v77535, 16 (stack45)
        %v77542 = vor.u32 %v77541, %v77540 (stack46)
        %v77543 = vxor.u32 %v77542, %v77538 (stack47)
        %v77546 = vadd.s32 %v77543, %v77538 (stack39)
        %v77550 = vadd.s32 %v77546, %v9 (stack39)
        %v77552 = vshll.u32 %v77543, 24 (stack44)
        %v77553 = vshrl.u32 %v77543, 8 (stack45)
        %v77554 = vor.u32 %v77553, %v77552 (stack46)
        %v77555 = vxor.u32 %v77554, %v77546 (stack47)
        %v77558 = vadd.s32 %v77555, %v8 (stack39)
        %v77562 = vadd.s32 4, %v77558 (stack39)
        %v77566 = vadd.s32 %v77562, %v77550 (stack39)
        %v77568 = vshll.u32 %v77562, 13 (stack44)
        %v77569 = vshrl.u32 %v77562, 19 (stack45)
        %v77570 = vor.u32 %v77569, %v77568 (stack46)
        %v77571 = vxor.u32 %v77570, %v77566 (stack47)
        %v77574 = vadd.s32 %v77571, %v77566 (stack39)
        %v77576 = vshll.u32 %v77571, 15 (stack44)
        %v77577 = vshrl.u32 %v77571, 17 (stack45)
        %v77578 = vor.u32 %v77577, %v77576 (stack46)
        %v77579 = vxor.u32 %v77578, %v77574 (stack47)
        %v77582 = vadd.s32 %v77579, %v77574 (stack39)
        %v77584 = vshll.u32 %v77579, 26 (stack44)
        %v77585 = vshrl.u32 %v77579, 6 (stack45)
        %v77586 = vor.u32 %v77585, %v77584 (stack46)
        %v77587 = vxor.u32 %v77586, %v77582 (stack47)
        %v77590 = vadd.s32 %v77587, %v77582 (stack39)
        %v77594 = vadd.s32 %v77590, %v8 (stack39)
        %v77596 = vshll.u32 %v77587, 6 (stack44)
        %v77597 = vshrl.u32 %v77587, 26 (stack45)
        %v77598 = vor.u32 %v77597, %v77596 (stack46)
        %v77599 = vxor.u32 %v77598, %v77590 (stack47)
        %v77602 = vadd.s32 %v77599, %v10 (stack39)
        %v77606 = vadd.s32 5, %v77602 (stack39)
        %v77608 = vxor.u32 %v77606, %v77594 (stack47)
        %v77609 = vand.u32.u8 255, %v77608 (stack48)
        %v77610 = vand.u32 65535, %v77609 (stack49)
        %v77611 = vshrl.u32 %v77610, 1 (stack50)
        %v77612 = vor.u32 16256, %v77611 (stack46)
        %v77613 = vand.u32.u16 65535, %v77612 (stack51)
        %v120158 = vadd.low.f32.bf16 -1.0, %v77613 (stack52)
        %v77622 = vmul.f32 2.0, %v120158 (stack53)
        %v77626 = vadd.f32 -0.99609375, %v77622 (stack52)
        %v77630 = vmax.f32 %v77626, -0.99609375 (stack54)
        %v77632 = vand.u32 2147483647, %v77630 (stack55)
        %vm77635 = vcmp.eq.f32.partialorder %v77632, 1.0 (stack56)
        %v77640 = vmul.f32 inf, %v77630 (stack53)
        %v77642 = vxor.u32 2147483648, %v77630 (stack57)
        %v77645 = vmul.f32 %v77642, %v77630 (stack53)
        %v77647 = vadd.f32 1.0, %v77645 (stack58)
        %v77648 = vlog2.pop %v77647 (stack59)
        %v77649 = vmul.f32 0.6931472, %v77648 (stack60)
        %v77650 = vmul.f32 -0.5, %v77645 (stack61)
        %v77651 = vadd.f32 1.0, %v77650 (stack62)
        %v77652 = vmul.f32 %v77651, %v77645 (stack63)
        %v77653 = vand.u32 2147483647, %v77645 (stack64)
        %vm77654 = vcmp.lt.f32.partialorder %v77653, 0.0004427343 (stack65)
        %v77655 = vsel /*vm=*/%vm77654, /*on_true_vy=*/%v77652, /*on_false_vx=*/%v77649 (stack66)
        %v77656 = vxor.u32 2147483648, %v77655 (stack57)
        %vm77659 = vcmp.lt.f32.partialorder %v77656, 5.0 (stack56)
        %v77664 = vsel /*vm=*/%vm77659, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v77668 = vsel /*vm=*/%vm77659, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v77672 = vsel /*vm=*/%vm77659, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v77676 = vsel /*vm=*/%vm77659, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v77680 = vsel /*vm=*/%vm77659, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v77684 = vsel /*vm=*/%vm77659, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v77688 = vsel /*vm=*/%vm77659, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v77692 = vsel /*vm=*/%vm77659, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v77696 = vsel /*vm=*/%vm77659, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v77700 = vadd.f32 -2.5, %v77656 (stack52)
        %v77702 = vrsqrt.pop %v77656 (stack67)
        %v77703 = vmul.f32 %v77702, %v77656 (stack68)
        %vm77704 = vcmp.eq.f32.partialorder %v77656, inf (stack69)
        %v77705 = vsel /*vm=*/%vm77704, /*on_true_vy=*/%v77656, /*on_false_vx=*/%v77703 (stack70)
        %vm77706 = vcmp.eq.f32.partialorder %v77656, 0.0 (stack71)
        %v77707 = vand.u32 2147483648, %v77656 (stack72)
        %v77708 = vsel /*vm=*/%vm77706, /*on_true_vy=*/%v77707, /*on_false_vx=*/%v77705 (stack73)
        %v77711 = vadd.f32 -3.0, %v77708 (stack52)
        %v77715 = vsel /*vm=*/%vm77659, /*on_true_vy=*/%v77700, /*on_false_vx=*/%v77711 (stack43)
        %v77719 = vmul.f32 %v77715, %v77696 (stack53)
        %v77723 = vadd.f32 %v77719, %v77692 (stack52)
        %v77727 = vmul.f32 %v77723, %v77715 (stack53)
        %v77731 = vadd.f32 %v77727, %v77688 (stack52)
        %v77735 = vmul.f32 %v77731, %v77715 (stack53)
        %v77739 = vadd.f32 %v77735, %v77684 (stack52)
        %v77743 = vmul.f32 %v77739, %v77715 (stack53)
        %v77747 = vadd.f32 %v77743, %v77680 (stack52)
        %v77751 = vmul.f32 %v77747, %v77715 (stack53)
        %v77755 = vadd.f32 %v77751, %v77676 (stack52)
        %v77759 = vmul.f32 %v77755, %v77715 (stack53)
        %v77763 = vadd.f32 %v77759, %v77672 (stack52)
        %v77767 = vmul.f32 %v77763, %v77715 (stack53)
        %v77771 = vadd.f32 %v77767, %v77668 (stack52)
        %v77775 = vmul.f32 %v77771, %v77715 (stack53)
        %v77779 = vadd.f32 %v77775, %v77664 (stack52)
        %v77783 = vmul.f32 %v77779, %v77630 (stack53)
        %v77787 = vsel /*vm=*/%vm77635, /*on_true_vy=*/%v77640, /*on_false_vx=*/%v77783 (stack43)
        %v77791 = vmul.f32 1.4140625, %v77787 (stack53)
        %v77794 = vpack.c.bf16 0.0, %v77791 (stack74)
        %120159 = vst [vmem:[%s280 + $0x2d0] sm:$0xf] /*vst_source=*/%v77794 (stack75)
        %v77798 = vadd.s32 %v75029, %v3329 (stack39)
        %v77808 = vadd.s32 %v77798, %v415 (stack39)
        %vm77812 = vcmp.lt.u32.totalorder %v77808, %v77798 (stack42)
        %vm77817 = vcmp.lt.u32.totalorder %v77798, %v3329 (stack42)
        %v77822 = vadd.s32 %v75012, %v3316 (stack39)
        %v77826 = vadd.s32 1, %v77822 (stack39)
        %v77830 = vsel /*vm=*/%vm77817, /*on_true_vy=*/%v77826, /*on_false_vx=*/%v77822 (stack43)
        %v77834 = vadd.s32 1, %v77830 (stack39)
        %v77838 = vsel /*vm=*/%vm77812, /*on_true_vy=*/%v77834, /*on_false_vx=*/%v77830 (stack43)
        %v77843 = vadd.s32 %v77838, %v10 (stack39)
        %v77847 = vadd.s32 %v77808, %v9 (stack39)
        %v77851 = vadd.s32 %v77847, %v77843 (stack39)
        %v77853 = vshll.u32 %v77847, 13 (stack44)
        %v77854 = vshrl.u32 %v77847, 19 (stack45)
        %v77855 = vor.u32 %v77854, %v77853 (stack46)
        %v77856 = vxor.u32 %v77855, %v77851 (stack47)
        %v77859 = vadd.s32 %v77856, %v77851 (stack39)
        %v77861 = vshll.u32 %v77856, 15 (stack44)
        %v77862 = vshrl.u32 %v77856, 17 (stack45)
        %v77863 = vor.u32 %v77862, %v77861 (stack46)
        %v77864 = vxor.u32 %v77863, %v77859 (stack47)
        %v77867 = vadd.s32 %v77864, %v77859 (stack39)
        %v77869 = vshll.u32 %v77864, 26 (stack44)
        %v77870 = vshrl.u32 %v77864, 6 (stack45)
        %v77871 = vor.u32 %v77870, %v77869 (stack46)
        %v77872 = vxor.u32 %v77871, %v77867 (stack47)
        %v77875 = vadd.s32 %v77872, %v77867 (stack39)
        %v77879 = vadd.s32 %v77875, %v9 (stack39)
        %v77881 = vshll.u32 %v77872, 6 (stack44)
        %v77882 = vshrl.u32 %v77872, 26 (stack45)
        %v77883 = vor.u32 %v77882, %v77881 (stack46)
        %v77884 = vxor.u32 %v77883, %v77875 (stack47)
        %v77887 = vadd.s32 %v77884, %v8 (stack39)
        %v77891 = vadd.s32 1, %v77887 (stack39)
        %v77895 = vadd.s32 %v77891, %v77879 (stack39)
        %v77897 = vshll.u32 %v77891, 17 (stack44)
        %v77898 = vshrl.u32 %v77891, 15 (stack45)
        %v77899 = vor.u32 %v77898, %v77897 (stack46)
        %v77900 = vxor.u32 %v77899, %v77895 (stack47)
        %v77903 = vadd.s32 %v77900, %v77895 (stack39)
        %v77905 = vshll.u32 %v77900, 29 (stack44)
        %v77906 = vshrl.u32 %v77900, 3 (stack45)
        %v77907 = vor.u32 %v77906, %v77905 (stack46)
        %v77908 = vxor.u32 %v77907, %v77903 (stack47)
        %v77911 = vadd.s32 %v77908, %v77903 (stack39)
        %v77913 = vshll.u32 %v77908, 16 (stack44)
        %v77914 = vshrl.u32 %v77908, 16 (stack45)
        %v77915 = vor.u32 %v77914, %v77913 (stack46)
        %v77916 = vxor.u32 %v77915, %v77911 (stack47)
        %v77919 = vadd.s32 %v77916, %v77911 (stack39)
        %v77923 = vadd.s32 %v77919, %v8 (stack39)
        %v77925 = vshll.u32 %v77916, 24 (stack44)
        %v77926 = vshrl.u32 %v77916, 8 (stack45)
        %v77927 = vor.u32 %v77926, %v77925 (stack46)
        %v77928 = vxor.u32 %v77927, %v77919 (stack47)
        %v77931 = vadd.s32 %v77928, %v10 (stack39)
        %v77935 = vadd.s32 2, %v77931 (stack39)
        %v77939 = vadd.s32 %v77935, %v77923 (stack39)
        %v77941 = vshll.u32 %v77935, 13 (stack44)
        %v77942 = vshrl.u32 %v77935, 19 (stack45)
        %v77943 = vor.u32 %v77942, %v77941 (stack46)
        %v77944 = vxor.u32 %v77943, %v77939 (stack47)
        %v77947 = vadd.s32 %v77944, %v77939 (stack39)
        %v77949 = vshll.u32 %v77944, 15 (stack44)
        %v77950 = vshrl.u32 %v77944, 17 (stack45)
        %v77951 = vor.u32 %v77950, %v77949 (stack46)
        %v77952 = vxor.u32 %v77951, %v77947 (stack47)
        %v77955 = vadd.s32 %v77952, %v77947 (stack39)
        %v77957 = vshll.u32 %v77952, 26 (stack44)
        %v77958 = vshrl.u32 %v77952, 6 (stack45)
        %v77959 = vor.u32 %v77958, %v77957 (stack46)
        %v77960 = vxor.u32 %v77959, %v77955 (stack47)
        %v77963 = vadd.s32 %v77960, %v77955 (stack39)
        %v77967 = vadd.s32 %v77963, %v10 (stack39)
        %v77969 = vshll.u32 %v77960, 6 (stack44)
        %v77970 = vshrl.u32 %v77960, 26 (stack45)
        %v77971 = vor.u32 %v77970, %v77969 (stack46)
        %v77972 = vxor.u32 %v77971, %v77963 (stack47)
        %v77975 = vadd.s32 %v77972, %v9 (stack39)
        %v77979 = vadd.s32 3, %v77975 (stack39)
        %v77983 = vadd.s32 %v77979, %v77967 (stack39)
        %v77985 = vshll.u32 %v77979, 17 (stack44)
        %v77986 = vshrl.u32 %v77979, 15 (stack45)
        %v77987 = vor.u32 %v77986, %v77985 (stack46)
        %v77988 = vxor.u32 %v77987, %v77983 (stack47)
        %v77991 = vadd.s32 %v77988, %v77983 (stack39)
        %v77993 = vshll.u32 %v77988, 29 (stack44)
        %v77994 = vshrl.u32 %v77988, 3 (stack45)
        %v77995 = vor.u32 %v77994, %v77993 (stack46)
        %v77996 = vxor.u32 %v77995, %v77991 (stack47)
        %v77999 = vadd.s32 %v77996, %v77991 (stack39)
        %v78001 = vshll.u32 %v77996, 16 (stack44)
        %v78002 = vshrl.u32 %v77996, 16 (stack45)
        %v78003 = vor.u32 %v78002, %v78001 (stack46)
        %v78004 = vxor.u32 %v78003, %v77999 (stack47)
        %v78007 = vadd.s32 %v78004, %v77999 (stack39)
        %v78011 = vadd.s32 %v78007, %v9 (stack39)
        %v78013 = vshll.u32 %v78004, 24 (stack44)
        %v78014 = vshrl.u32 %v78004, 8 (stack45)
        %v78015 = vor.u32 %v78014, %v78013 (stack46)
        %v78016 = vxor.u32 %v78015, %v78007 (stack47)
        %v78019 = vadd.s32 %v78016, %v8 (stack39)
        %v78023 = vadd.s32 4, %v78019 (stack39)
        %v78027 = vadd.s32 %v78023, %v78011 (stack39)
        %v78029 = vshll.u32 %v78023, 13 (stack44)
        %v78030 = vshrl.u32 %v78023, 19 (stack45)
        %v78031 = vor.u32 %v78030, %v78029 (stack46)
        %v78032 = vxor.u32 %v78031, %v78027 (stack47)
        %v78035 = vadd.s32 %v78032, %v78027 (stack39)
        %v78037 = vshll.u32 %v78032, 15 (stack44)
        %v78038 = vshrl.u32 %v78032, 17 (stack45)
        %v78039 = vor.u32 %v78038, %v78037 (stack46)
        %v78040 = vxor.u32 %v78039, %v78035 (stack47)
        %v78043 = vadd.s32 %v78040, %v78035 (stack39)
        %v78045 = vshll.u32 %v78040, 26 (stack44)
        %v78046 = vshrl.u32 %v78040, 6 (stack45)
        %v78047 = vor.u32 %v78046, %v78045 (stack46)
        %v78048 = vxor.u32 %v78047, %v78043 (stack47)
        %v78051 = vadd.s32 %v78048, %v78043 (stack39)
        %v78055 = vadd.s32 %v78051, %v8 (stack39)
        %v78057 = vshll.u32 %v78048, 6 (stack44)
        %v78058 = vshrl.u32 %v78048, 26 (stack45)
        %v78059 = vor.u32 %v78058, %v78057 (stack46)
        %v78060 = vxor.u32 %v78059, %v78051 (stack47)
        %v78063 = vadd.s32 %v78060, %v10 (stack39)
        %v78067 = vadd.s32 5, %v78063 (stack39)
        %v78069 = vxor.u32 %v78067, %v78055 (stack47)
        %v78070 = vand.u32.u8 255, %v78069 (stack48)
        %v78071 = vand.u32 65535, %v78070 (stack49)
        %v78072 = vshrl.u32 %v78071, 1 (stack50)
        %v78073 = vor.u32 16256, %v78072 (stack46)
        %v78074 = vand.u32.u16 65535, %v78073 (stack51)
        %v120160 = vadd.low.f32.bf16 -1.0, %v78074 (stack52)
        %v78083 = vmul.f32 2.0, %v120160 (stack53)
        %v78087 = vadd.f32 -0.99609375, %v78083 (stack52)
        %v78091 = vmax.f32 %v78087, -0.99609375 (stack54)
        %v78093 = vand.u32 2147483647, %v78091 (stack55)
        %vm78096 = vcmp.eq.f32.partialorder %v78093, 1.0 (stack56)
        %v78101 = vmul.f32 inf, %v78091 (stack53)
        %v78103 = vxor.u32 2147483648, %v78091 (stack57)
        %v78106 = vmul.f32 %v78103, %v78091 (stack53)
        %v78108 = vadd.f32 1.0, %v78106 (stack58)
        %v78109 = vlog2.pop %v78108 (stack59)
        %v78110 = vmul.f32 0.6931472, %v78109 (stack60)
        %v78111 = vmul.f32 -0.5, %v78106 (stack61)
        %v78112 = vadd.f32 1.0, %v78111 (stack62)
        %v78113 = vmul.f32 %v78112, %v78106 (stack63)
        %v78114 = vand.u32 2147483647, %v78106 (stack64)
        %vm78115 = vcmp.lt.f32.partialorder %v78114, 0.0004427343 (stack65)
        %v78116 = vsel /*vm=*/%vm78115, /*on_true_vy=*/%v78113, /*on_false_vx=*/%v78110 (stack66)
        %v78117 = vxor.u32 2147483648, %v78116 (stack57)
        %vm78120 = vcmp.lt.f32.partialorder %v78117, 5.0 (stack56)
        %v78125 = vsel /*vm=*/%vm78120, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v78129 = vsel /*vm=*/%vm78120, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v78133 = vsel /*vm=*/%vm78120, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v78137 = vsel /*vm=*/%vm78120, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v78141 = vsel /*vm=*/%vm78120, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v78145 = vsel /*vm=*/%vm78120, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v78149 = vsel /*vm=*/%vm78120, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v78153 = vsel /*vm=*/%vm78120, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v78157 = vsel /*vm=*/%vm78120, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v78161 = vadd.f32 -2.5, %v78117 (stack52)
        %v78163 = vrsqrt.pop %v78117 (stack67)
        %v78164 = vmul.f32 %v78163, %v78117 (stack68)
        %vm78165 = vcmp.eq.f32.partialorder %v78117, inf (stack69)
        %v78166 = vsel /*vm=*/%vm78165, /*on_true_vy=*/%v78117, /*on_false_vx=*/%v78164 (stack70)
        %vm78167 = vcmp.eq.f32.partialorder %v78117, 0.0 (stack71)
        %v78168 = vand.u32 2147483648, %v78117 (stack72)
        %v78169 = vsel /*vm=*/%vm78167, /*on_true_vy=*/%v78168, /*on_false_vx=*/%v78166 (stack73)
        %v78172 = vadd.f32 -3.0, %v78169 (stack52)
        %v78176 = vsel /*vm=*/%vm78120, /*on_true_vy=*/%v78161, /*on_false_vx=*/%v78172 (stack43)
        %v78180 = vmul.f32 %v78176, %v78157 (stack53)
        %v78184 = vadd.f32 %v78180, %v78153 (stack52)
        %v78188 = vmul.f32 %v78184, %v78176 (stack53)
        %v78192 = vadd.f32 %v78188, %v78149 (stack52)
        %v78196 = vmul.f32 %v78192, %v78176 (stack53)
        %v78200 = vadd.f32 %v78196, %v78145 (stack52)
        %v78204 = vmul.f32 %v78200, %v78176 (stack53)
        %v78208 = vadd.f32 %v78204, %v78141 (stack52)
        %v78212 = vmul.f32 %v78208, %v78176 (stack53)
        %v78216 = vadd.f32 %v78212, %v78137 (stack52)
        %v78220 = vmul.f32 %v78216, %v78176 (stack53)
        %v78224 = vadd.f32 %v78220, %v78133 (stack52)
        %v78228 = vmul.f32 %v78224, %v78176 (stack53)
        %v78232 = vadd.f32 %v78228, %v78129 (stack52)
        %v78236 = vmul.f32 %v78232, %v78176 (stack53)
        %v78240 = vadd.f32 %v78236, %v78125 (stack52)
        %v78244 = vmul.f32 %v78240, %v78091 (stack53)
        %v78248 = vsel /*vm=*/%vm78096, /*on_true_vy=*/%v78101, /*on_false_vx=*/%v78244 (stack43)
        %v78252 = vmul.f32 1.4140625, %v78248 (stack53)
        %v78255 = vpack.c.bf16 0.0, %v78252 (stack74)
        %120161 = vst [vmem:[%s280 + $0x350] sm:$0xf] /*vst_source=*/%v78255 (stack75)
        %v78259 = vadd.s32 %v75029, %v3816 (stack39)
        %v78269 = vadd.s32 %v78259, %v415 (stack39)
        %vm78273 = vcmp.lt.u32.totalorder %v78269, %v78259 (stack42)
        %vm78278 = vcmp.lt.u32.totalorder %v78259, %v3816 (stack42)
        %v78283 = vadd.s32 %v75012, %v3803 (stack39)
        %v78287 = vadd.s32 1, %v78283 (stack39)
        %v78291 = vsel /*vm=*/%vm78278, /*on_true_vy=*/%v78287, /*on_false_vx=*/%v78283 (stack43)
        %v78295 = vadd.s32 1, %v78291 (stack39)
        %v78299 = vsel /*vm=*/%vm78273, /*on_true_vy=*/%v78295, /*on_false_vx=*/%v78291 (stack43)
        %v78304 = vadd.s32 %v78299, %v10 (stack39)
        %v78308 = vadd.s32 %v78269, %v9 (stack39)
        %v78312 = vadd.s32 %v78308, %v78304 (stack39)
        %v78314 = vshll.u32 %v78308, 13 (stack44)
        %v78315 = vshrl.u32 %v78308, 19 (stack45)
        %v78316 = vor.u32 %v78315, %v78314 (stack46)
        %v78317 = vxor.u32 %v78316, %v78312 (stack47)
        %v78320 = vadd.s32 %v78317, %v78312 (stack39)
        %v78322 = vshll.u32 %v78317, 15 (stack44)
        %v78323 = vshrl.u32 %v78317, 17 (stack45)
        %v78324 = vor.u32 %v78323, %v78322 (stack46)
        %v78325 = vxor.u32 %v78324, %v78320 (stack47)
        %v78328 = vadd.s32 %v78325, %v78320 (stack39)
        %v78330 = vshll.u32 %v78325, 26 (stack44)
        %v78331 = vshrl.u32 %v78325, 6 (stack45)
        %v78332 = vor.u32 %v78331, %v78330 (stack46)
        %v78333 = vxor.u32 %v78332, %v78328 (stack47)
        %v78336 = vadd.s32 %v78333, %v78328 (stack39)
        %v78340 = vadd.s32 %v78336, %v9 (stack39)
        %v78342 = vshll.u32 %v78333, 6 (stack44)
        %v78343 = vshrl.u32 %v78333, 26 (stack45)
        %v78344 = vor.u32 %v78343, %v78342 (stack46)
        %v78345 = vxor.u32 %v78344, %v78336 (stack47)
        %v78348 = vadd.s32 %v78345, %v8 (stack39)
        %v78352 = vadd.s32 1, %v78348 (stack39)
        %v78356 = vadd.s32 %v78352, %v78340 (stack39)
        %v78358 = vshll.u32 %v78352, 17 (stack44)
        %v78359 = vshrl.u32 %v78352, 15 (stack45)
        %v78360 = vor.u32 %v78359, %v78358 (stack46)
        %v78361 = vxor.u32 %v78360, %v78356 (stack47)
        %v78364 = vadd.s32 %v78361, %v78356 (stack39)
        %v78366 = vshll.u32 %v78361, 29 (stack44)
        %v78367 = vshrl.u32 %v78361, 3 (stack45)
        %v78368 = vor.u32 %v78367, %v78366 (stack46)
        %v78369 = vxor.u32 %v78368, %v78364 (stack47)
        %v78372 = vadd.s32 %v78369, %v78364 (stack39)
        %v78374 = vshll.u32 %v78369, 16 (stack44)
        %v78375 = vshrl.u32 %v78369, 16 (stack45)
        %v78376 = vor.u32 %v78375, %v78374 (stack46)
        %v78377 = vxor.u32 %v78376, %v78372 (stack47)
        %v78380 = vadd.s32 %v78377, %v78372 (stack39)
        %v78384 = vadd.s32 %v78380, %v8 (stack39)
        %v78386 = vshll.u32 %v78377, 24 (stack44)
        %v78387 = vshrl.u32 %v78377, 8 (stack45)
        %v78388 = vor.u32 %v78387, %v78386 (stack46)
        %v78389 = vxor.u32 %v78388, %v78380 (stack47)
        %v78392 = vadd.s32 %v78389, %v10 (stack39)
        %v78396 = vadd.s32 2, %v78392 (stack39)
        %v78400 = vadd.s32 %v78396, %v78384 (stack39)
        %v78402 = vshll.u32 %v78396, 13 (stack44)
        %v78403 = vshrl.u32 %v78396, 19 (stack45)
        %v78404 = vor.u32 %v78403, %v78402 (stack46)
        %v78405 = vxor.u32 %v78404, %v78400 (stack47)
        %v78408 = vadd.s32 %v78405, %v78400 (stack39)
        %v78410 = vshll.u32 %v78405, 15 (stack44)
        %v78411 = vshrl.u32 %v78405, 17 (stack45)
        %v78412 = vor.u32 %v78411, %v78410 (stack46)
        %v78413 = vxor.u32 %v78412, %v78408 (stack47)
        %v78416 = vadd.s32 %v78413, %v78408 (stack39)
        %v78418 = vshll.u32 %v78413, 26 (stack44)
        %v78419 = vshrl.u32 %v78413, 6 (stack45)
        %v78420 = vor.u32 %v78419, %v78418 (stack46)
        %v78421 = vxor.u32 %v78420, %v78416 (stack47)
        %v78424 = vadd.s32 %v78421, %v78416 (stack39)
        %v78428 = vadd.s32 %v78424, %v10 (stack39)
        %v78430 = vshll.u32 %v78421, 6 (stack44)
        %v78431 = vshrl.u32 %v78421, 26 (stack45)
        %v78432 = vor.u32 %v78431, %v78430 (stack46)
        %v78433 = vxor.u32 %v78432, %v78424 (stack47)
        %v78436 = vadd.s32 %v78433, %v9 (stack39)
        %v78440 = vadd.s32 3, %v78436 (stack39)
        %v78444 = vadd.s32 %v78440, %v78428 (stack39)
        %v78446 = vshll.u32 %v78440, 17 (stack44)
        %v78447 = vshrl.u32 %v78440, 15 (stack45)
        %v78448 = vor.u32 %v78447, %v78446 (stack46)
        %v78449 = vxor.u32 %v78448, %v78444 (stack47)
        %v78452 = vadd.s32 %v78449, %v78444 (stack39)
        %v78454 = vshll.u32 %v78449, 29 (stack44)
        %v78455 = vshrl.u32 %v78449, 3 (stack45)
        %v78456 = vor.u32 %v78455, %v78454 (stack46)
        %v78457 = vxor.u32 %v78456, %v78452 (stack47)
        %v78460 = vadd.s32 %v78457, %v78452 (stack39)
        %v78462 = vshll.u32 %v78457, 16 (stack44)
        %v78463 = vshrl.u32 %v78457, 16 (stack45)
        %v78464 = vor.u32 %v78463, %v78462 (stack46)
        %v78465 = vxor.u32 %v78464, %v78460 (stack47)
        %v78468 = vadd.s32 %v78465, %v78460 (stack39)
        %v78472 = vadd.s32 %v78468, %v9 (stack39)
        %v78474 = vshll.u32 %v78465, 24 (stack44)
        %v78475 = vshrl.u32 %v78465, 8 (stack45)
        %v78476 = vor.u32 %v78475, %v78474 (stack46)
        %v78477 = vxor.u32 %v78476, %v78468 (stack47)
        %v78480 = vadd.s32 %v78477, %v8 (stack39)
        %v78484 = vadd.s32 4, %v78480 (stack39)
        %v78488 = vadd.s32 %v78484, %v78472 (stack39)
        %v78490 = vshll.u32 %v78484, 13 (stack44)
        %v78491 = vshrl.u32 %v78484, 19 (stack45)
        %v78492 = vor.u32 %v78491, %v78490 (stack46)
        %v78493 = vxor.u32 %v78492, %v78488 (stack47)
        %v78496 = vadd.s32 %v78493, %v78488 (stack39)
        %v78498 = vshll.u32 %v78493, 15 (stack44)
        %v78499 = vshrl.u32 %v78493, 17 (stack45)
        %v78500 = vor.u32 %v78499, %v78498 (stack46)
        %v78501 = vxor.u32 %v78500, %v78496 (stack47)
        %v78504 = vadd.s32 %v78501, %v78496 (stack39)
        %v78506 = vshll.u32 %v78501, 26 (stack44)
        %v78507 = vshrl.u32 %v78501, 6 (stack45)
        %v78508 = vor.u32 %v78507, %v78506 (stack46)
        %v78509 = vxor.u32 %v78508, %v78504 (stack47)
        %v78512 = vadd.s32 %v78509, %v78504 (stack39)
        %v78516 = vadd.s32 %v78512, %v8 (stack39)
        %v78518 = vshll.u32 %v78509, 6 (stack44)
        %v78519 = vshrl.u32 %v78509, 26 (stack45)
        %v78520 = vor.u32 %v78519, %v78518 (stack46)
        %v78521 = vxor.u32 %v78520, %v78512 (stack47)
        %v78524 = vadd.s32 %v78521, %v10 (stack39)
        %v78528 = vadd.s32 5, %v78524 (stack39)
        %v78530 = vxor.u32 %v78528, %v78516 (stack47)
        %v78531 = vand.u32.u8 255, %v78530 (stack48)
        %v78532 = vand.u32 65535, %v78531 (stack49)
        %v78533 = vshrl.u32 %v78532, 1 (stack50)
        %v78534 = vor.u32 16256, %v78533 (stack46)
        %v78535 = vand.u32.u16 65535, %v78534 (stack51)
        %v120162 = vadd.low.f32.bf16 -1.0, %v78535 (stack52)
        %v78544 = vmul.f32 2.0, %v120162 (stack53)
        %v78548 = vadd.f32 -0.99609375, %v78544 (stack52)
        %v78552 = vmax.f32 %v78548, -0.99609375 (stack54)
        %v78554 = vand.u32 2147483647, %v78552 (stack55)
        %vm78557 = vcmp.eq.f32.partialorder %v78554, 1.0 (stack56)
        %v78562 = vmul.f32 inf, %v78552 (stack53)
        %v78564 = vxor.u32 2147483648, %v78552 (stack57)
        %v78567 = vmul.f32 %v78564, %v78552 (stack53)
        %v78569 = vadd.f32 1.0, %v78567 (stack58)
        %v78570 = vlog2.pop %v78569 (stack59)
        %v78571 = vmul.f32 0.6931472, %v78570 (stack60)
        %v78572 = vmul.f32 -0.5, %v78567 (stack61)
        %v78573 = vadd.f32 1.0, %v78572 (stack62)
        %v78574 = vmul.f32 %v78573, %v78567 (stack63)
        %v78575 = vand.u32 2147483647, %v78567 (stack64)
        %vm78576 = vcmp.lt.f32.partialorder %v78575, 0.0004427343 (stack65)
        %v78577 = vsel /*vm=*/%vm78576, /*on_true_vy=*/%v78574, /*on_false_vx=*/%v78571 (stack66)
        %v78578 = vxor.u32 2147483648, %v78577 (stack57)
        %vm78581 = vcmp.lt.f32.partialorder %v78578, 5.0 (stack56)
        %v78586 = vsel /*vm=*/%vm78581, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v78590 = vsel /*vm=*/%vm78581, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v78594 = vsel /*vm=*/%vm78581, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v78598 = vsel /*vm=*/%vm78581, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v78602 = vsel /*vm=*/%vm78581, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v78606 = vsel /*vm=*/%vm78581, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v78610 = vsel /*vm=*/%vm78581, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v78614 = vsel /*vm=*/%vm78581, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v78618 = vsel /*vm=*/%vm78581, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v78622 = vadd.f32 -2.5, %v78578 (stack52)
        %v78624 = vrsqrt.pop %v78578 (stack67)
        %v78625 = vmul.f32 %v78624, %v78578 (stack68)
        %vm78626 = vcmp.eq.f32.partialorder %v78578, inf (stack69)
        %v78627 = vsel /*vm=*/%vm78626, /*on_true_vy=*/%v78578, /*on_false_vx=*/%v78625 (stack70)
        %vm78628 = vcmp.eq.f32.partialorder %v78578, 0.0 (stack71)
        %v78629 = vand.u32 2147483648, %v78578 (stack72)
        %v78630 = vsel /*vm=*/%vm78628, /*on_true_vy=*/%v78629, /*on_false_vx=*/%v78627 (stack73)
        %v78633 = vadd.f32 -3.0, %v78630 (stack52)
        %v78637 = vsel /*vm=*/%vm78581, /*on_true_vy=*/%v78622, /*on_false_vx=*/%v78633 (stack43)
        %v78641 = vmul.f32 %v78637, %v78618 (stack53)
        %v78645 = vadd.f32 %v78641, %v78614 (stack52)
        %v78649 = vmul.f32 %v78645, %v78637 (stack53)
        %v78653 = vadd.f32 %v78649, %v78610 (stack52)
        %v78657 = vmul.f32 %v78653, %v78637 (stack53)
        %v78661 = vadd.f32 %v78657, %v78606 (stack52)
        %v78665 = vmul.f32 %v78661, %v78637 (stack53)
        %v78669 = vadd.f32 %v78665, %v78602 (stack52)
        %v78673 = vmul.f32 %v78669, %v78637 (stack53)
        %v78677 = vadd.f32 %v78673, %v78598 (stack52)
        %v78681 = vmul.f32 %v78677, %v78637 (stack53)
        %v78685 = vadd.f32 %v78681, %v78594 (stack52)
        %v78689 = vmul.f32 %v78685, %v78637 (stack53)
        %v78693 = vadd.f32 %v78689, %v78590 (stack52)
        %v78697 = vmul.f32 %v78693, %v78637 (stack53)
        %v78701 = vadd.f32 %v78697, %v78586 (stack52)
        %v78705 = vmul.f32 %v78701, %v78552 (stack53)
        %v78709 = vsel /*vm=*/%vm78557, /*on_true_vy=*/%v78562, /*on_false_vx=*/%v78705 (stack43)
        %v78713 = vmul.f32 1.4140625, %v78709 (stack53)
        %v78716 = vpack.c.bf16 0.0, %v78713 (stack74)
        %120163 = vst [vmem:[%s280 + $0x3d0] sm:$0xf] /*vst_source=*/%v78716 (stack75)
        %s78718 = sadd.s32 168, %s120390 (stack76)
        %s78719 = sshrl.u32 %s78718, 10 (stack23)
        %p120164 = scmp.gt.s32.totalorder %s78719, 1 (stack24)
        %s78721 = scalar_select /*predicate=*/%p120164, /*on_true=*/1, /*on_false=*/%s78719 (stack25)
        %s78722 = sand.u32 1023, %s78718 /* smod.u32 w/div 1024 */ (stack26)
        %s78723 = sshrl.u32 %s78722, 7 (stack27)
        %s78724 = sand.u32 127, %s78722 /* smod.u32 w/div 128 */ (stack28)
        %s120165 = sshll.u32 %s78721, 3 (stack29)
        %s78726 = scalar_lea.vmem %s3, %s120165 (stack30)
        %s78728 = scalar_lea.vmem %s78726, %s78723 (stack31)
        %v78729 = vld [vmem:[%s78728] ss:$0 sm:$0xff] (stack32)
        %s78730 = sand.u32 255, %s78724 (stack33)
        %s78732 = sor.u32 256, %s78730 (stack34)
        %78733 = vbcast.lane.b32.xlu0 %v78729, %s78732 (stack35)
        %v78734 = vpop.permute.xlu0 %78733 (stack36)
        %s78743 = scalar_lea.vmem %s5, %s120165 (stack30)
        %s78745 = scalar_lea.vmem %s78743, %s78723 (stack31)
        %v78746 = vld [vmem:[%s78745] ss:$0 sm:$0xff] (stack32)
        %78750 = vbcast.lane.b32.xlu0 %v78746, %s78732 (stack35)
        %v78751 = vpop.permute.xlu0 %78750 (stack36)
        %v78754 = vadd.s32 %v78751, %v408 (stack39)
        %v78764 = vadd.s32 %v78754, %v415 (stack39)
        %vm78768 = vcmp.lt.u32.totalorder %v78764, %v78754 (stack42)
        %vm78773 = vcmp.lt.u32.totalorder %v78754, %v408 (stack42)
        %v78778 = vadd.s32 %v78734, %v380 (stack39)
        %v78782 = vadd.s32 1, %v78778 (stack39)
        %v78786 = vsel /*vm=*/%vm78773, /*on_true_vy=*/%v78782, /*on_false_vx=*/%v78778 (stack43)
        %v78790 = vadd.s32 1, %v78786 (stack39)
        %v78794 = vsel /*vm=*/%vm78768, /*on_true_vy=*/%v78790, /*on_false_vx=*/%v78786 (stack43)
        %v78799 = vadd.s32 %v78794, %v10 (stack39)
        %v78803 = vadd.s32 %v78764, %v9 (stack39)
        %v78807 = vadd.s32 %v78803, %v78799 (stack39)
        %v78809 = vshll.u32 %v78803, 13 (stack44)
        %v78810 = vshrl.u32 %v78803, 19 (stack45)
        %v78811 = vor.u32 %v78810, %v78809 (stack46)
        %v78812 = vxor.u32 %v78811, %v78807 (stack47)
        %v78815 = vadd.s32 %v78812, %v78807 (stack39)
        %v78817 = vshll.u32 %v78812, 15 (stack44)
        %v78818 = vshrl.u32 %v78812, 17 (stack45)
        %v78819 = vor.u32 %v78818, %v78817 (stack46)
        %v78820 = vxor.u32 %v78819, %v78815 (stack47)
        %v78823 = vadd.s32 %v78820, %v78815 (stack39)
        %v78825 = vshll.u32 %v78820, 26 (stack44)
        %v78826 = vshrl.u32 %v78820, 6 (stack45)
        %v78827 = vor.u32 %v78826, %v78825 (stack46)
        %v78828 = vxor.u32 %v78827, %v78823 (stack47)
        %v78831 = vadd.s32 %v78828, %v78823 (stack39)
        %v78835 = vadd.s32 %v78831, %v9 (stack39)
        %v78837 = vshll.u32 %v78828, 6 (stack44)
        %v78838 = vshrl.u32 %v78828, 26 (stack45)
        %v78839 = vor.u32 %v78838, %v78837 (stack46)
        %v78840 = vxor.u32 %v78839, %v78831 (stack47)
        %v78843 = vadd.s32 %v78840, %v8 (stack39)
        %v78847 = vadd.s32 1, %v78843 (stack39)
        %v78851 = vadd.s32 %v78847, %v78835 (stack39)
        %v78853 = vshll.u32 %v78847, 17 (stack44)
        %v78854 = vshrl.u32 %v78847, 15 (stack45)
        %v78855 = vor.u32 %v78854, %v78853 (stack46)
        %v78856 = vxor.u32 %v78855, %v78851 (stack47)
        %v78859 = vadd.s32 %v78856, %v78851 (stack39)
        %v78861 = vshll.u32 %v78856, 29 (stack44)
        %v78862 = vshrl.u32 %v78856, 3 (stack45)
        %v78863 = vor.u32 %v78862, %v78861 (stack46)
        %v78864 = vxor.u32 %v78863, %v78859 (stack47)
        %v78867 = vadd.s32 %v78864, %v78859 (stack39)
        %v78869 = vshll.u32 %v78864, 16 (stack44)
        %v78870 = vshrl.u32 %v78864, 16 (stack45)
        %v78871 = vor.u32 %v78870, %v78869 (stack46)
        %v78872 = vxor.u32 %v78871, %v78867 (stack47)
        %v78875 = vadd.s32 %v78872, %v78867 (stack39)
        %v78879 = vadd.s32 %v78875, %v8 (stack39)
        %v78881 = vshll.u32 %v78872, 24 (stack44)
        %v78882 = vshrl.u32 %v78872, 8 (stack45)
        %v78883 = vor.u32 %v78882, %v78881 (stack46)
        %v78884 = vxor.u32 %v78883, %v78875 (stack47)
        %v78887 = vadd.s32 %v78884, %v10 (stack39)
        %v78891 = vadd.s32 2, %v78887 (stack39)
        %v78895 = vadd.s32 %v78891, %v78879 (stack39)
        %v78897 = vshll.u32 %v78891, 13 (stack44)
        %v78898 = vshrl.u32 %v78891, 19 (stack45)
        %v78899 = vor.u32 %v78898, %v78897 (stack46)
        %v78900 = vxor.u32 %v78899, %v78895 (stack47)
        %v78903 = vadd.s32 %v78900, %v78895 (stack39)
        %v78905 = vshll.u32 %v78900, 15 (stack44)
        %v78906 = vshrl.u32 %v78900, 17 (stack45)
        %v78907 = vor.u32 %v78906, %v78905 (stack46)
        %v78908 = vxor.u32 %v78907, %v78903 (stack47)
        %v78911 = vadd.s32 %v78908, %v78903 (stack39)
        %v78913 = vshll.u32 %v78908, 26 (stack44)
        %v78914 = vshrl.u32 %v78908, 6 (stack45)
        %v78915 = vor.u32 %v78914, %v78913 (stack46)
        %v78916 = vxor.u32 %v78915, %v78911 (stack47)
        %v78919 = vadd.s32 %v78916, %v78911 (stack39)
        %v78923 = vadd.s32 %v78919, %v10 (stack39)
        %v78925 = vshll.u32 %v78916, 6 (stack44)
        %v78926 = vshrl.u32 %v78916, 26 (stack45)
        %v78927 = vor.u32 %v78926, %v78925 (stack46)
        %v78928 = vxor.u32 %v78927, %v78919 (stack47)
        %v78931 = vadd.s32 %v78928, %v9 (stack39)
        %v78935 = vadd.s32 3, %v78931 (stack39)
        %v78939 = vadd.s32 %v78935, %v78923 (stack39)
        %v78941 = vshll.u32 %v78935, 17 (stack44)
        %v78942 = vshrl.u32 %v78935, 15 (stack45)
        %v78943 = vor.u32 %v78942, %v78941 (stack46)
        %v78944 = vxor.u32 %v78943, %v78939 (stack47)
        %v78947 = vadd.s32 %v78944, %v78939 (stack39)
        %v78949 = vshll.u32 %v78944, 29 (stack44)
        %v78950 = vshrl.u32 %v78944, 3 (stack45)
        %v78951 = vor.u32 %v78950, %v78949 (stack46)
        %v78952 = vxor.u32 %v78951, %v78947 (stack47)
        %v78955 = vadd.s32 %v78952, %v78947 (stack39)
        %v78957 = vshll.u32 %v78952, 16 (stack44)
        %v78958 = vshrl.u32 %v78952, 16 (stack45)
        %v78959 = vor.u32 %v78958, %v78957 (stack46)
        %v78960 = vxor.u32 %v78959, %v78955 (stack47)
        %v78963 = vadd.s32 %v78960, %v78955 (stack39)
        %v78967 = vadd.s32 %v78963, %v9 (stack39)
        %v78969 = vshll.u32 %v78960, 24 (stack44)
        %v78970 = vshrl.u32 %v78960, 8 (stack45)
        %v78971 = vor.u32 %v78970, %v78969 (stack46)
        %v78972 = vxor.u32 %v78971, %v78963 (stack47)
        %v78975 = vadd.s32 %v78972, %v8 (stack39)
        %v78979 = vadd.s32 4, %v78975 (stack39)
        %v78983 = vadd.s32 %v78979, %v78967 (stack39)
        %v78985 = vshll.u32 %v78979, 13 (stack44)
        %v78986 = vshrl.u32 %v78979, 19 (stack45)
        %v78987 = vor.u32 %v78986, %v78985 (stack46)
        %v78988 = vxor.u32 %v78987, %v78983 (stack47)
        %v78991 = vadd.s32 %v78988, %v78983 (stack39)
        %v78993 = vshll.u32 %v78988, 15 (stack44)
        %v78994 = vshrl.u32 %v78988, 17 (stack45)
        %v78995 = vor.u32 %v78994, %v78993 (stack46)
        %v78996 = vxor.u32 %v78995, %v78991 (stack47)
        %v78999 = vadd.s32 %v78996, %v78991 (stack39)
        %v79001 = vshll.u32 %v78996, 26 (stack44)
        %v79002 = vshrl.u32 %v78996, 6 (stack45)
        %v79003 = vor.u32 %v79002, %v79001 (stack46)
        %v79004 = vxor.u32 %v79003, %v78999 (stack47)
        %v79007 = vadd.s32 %v79004, %v78999 (stack39)
        %v79011 = vadd.s32 %v79007, %v8 (stack39)
        %v79013 = vshll.u32 %v79004, 6 (stack44)
        %v79014 = vshrl.u32 %v79004, 26 (stack45)
        %v79015 = vor.u32 %v79014, %v79013 (stack46)
        %v79016 = vxor.u32 %v79015, %v79007 (stack47)
        %v79019 = vadd.s32 %v79016, %v10 (stack39)
        %v79023 = vadd.s32 5, %v79019 (stack39)
        %v79025 = vxor.u32 %v79023, %v79011 (stack47)
        %v79026 = vand.u32.u8 255, %v79025 (stack48)
        %v79027 = vand.u32 65535, %v79026 (stack49)
        %v79028 = vshrl.u32 %v79027, 1 (stack50)
        %v79029 = vor.u32 16256, %v79028 (stack46)
        %v79030 = vand.u32.u16 65535, %v79029 (stack51)
        %v120168 = vadd.low.f32.bf16 -1.0, %v79030 (stack52)
        %v79039 = vmul.f32 2.0, %v120168 (stack53)
        %v79043 = vadd.f32 -0.99609375, %v79039 (stack52)
        %v79047 = vmax.f32 %v79043, -0.99609375 (stack54)
        %v79049 = vand.u32 2147483647, %v79047 (stack55)
        %vm79052 = vcmp.eq.f32.partialorder %v79049, 1.0 (stack56)
        %v79057 = vmul.f32 inf, %v79047 (stack53)
        %v79059 = vxor.u32 2147483648, %v79047 (stack57)
        %v79062 = vmul.f32 %v79059, %v79047 (stack53)
        %v79064 = vadd.f32 1.0, %v79062 (stack58)
        %v79065 = vlog2.pop %v79064 (stack59)
        %v79066 = vmul.f32 0.6931472, %v79065 (stack60)
        %v79067 = vmul.f32 -0.5, %v79062 (stack61)
        %v79068 = vadd.f32 1.0, %v79067 (stack62)
        %v79069 = vmul.f32 %v79068, %v79062 (stack63)
        %v79070 = vand.u32 2147483647, %v79062 (stack64)
        %vm79071 = vcmp.lt.f32.partialorder %v79070, 0.0004427343 (stack65)
        %v79072 = vsel /*vm=*/%vm79071, /*on_true_vy=*/%v79069, /*on_false_vx=*/%v79066 (stack66)
        %v79073 = vxor.u32 2147483648, %v79072 (stack57)
        %vm79076 = vcmp.lt.f32.partialorder %v79073, 5.0 (stack56)
        %v79081 = vsel /*vm=*/%vm79076, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v79085 = vsel /*vm=*/%vm79076, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v79089 = vsel /*vm=*/%vm79076, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v79093 = vsel /*vm=*/%vm79076, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v79097 = vsel /*vm=*/%vm79076, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v79101 = vsel /*vm=*/%vm79076, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v79105 = vsel /*vm=*/%vm79076, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v79109 = vsel /*vm=*/%vm79076, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v79113 = vsel /*vm=*/%vm79076, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v79117 = vadd.f32 -2.5, %v79073 (stack52)
        %v79119 = vrsqrt.pop %v79073 (stack67)
        %v79120 = vmul.f32 %v79119, %v79073 (stack68)
        %vm79121 = vcmp.eq.f32.partialorder %v79073, inf (stack69)
        %v79122 = vsel /*vm=*/%vm79121, /*on_true_vy=*/%v79073, /*on_false_vx=*/%v79120 (stack70)
        %vm79123 = vcmp.eq.f32.partialorder %v79073, 0.0 (stack71)
        %v79124 = vand.u32 2147483648, %v79073 (stack72)
        %v79125 = vsel /*vm=*/%vm79123, /*on_true_vy=*/%v79124, /*on_false_vx=*/%v79122 (stack73)
        %v79128 = vadd.f32 -3.0, %v79125 (stack52)
        %v79132 = vsel /*vm=*/%vm79076, /*on_true_vy=*/%v79117, /*on_false_vx=*/%v79128 (stack43)
        %v79136 = vmul.f32 %v79132, %v79113 (stack53)
        %v79140 = vadd.f32 %v79136, %v79109 (stack52)
        %v79144 = vmul.f32 %v79140, %v79132 (stack53)
        %v79148 = vadd.f32 %v79144, %v79105 (stack52)
        %v79152 = vmul.f32 %v79148, %v79132 (stack53)
        %v79156 = vadd.f32 %v79152, %v79101 (stack52)
        %v79160 = vmul.f32 %v79156, %v79132 (stack53)
        %v79164 = vadd.f32 %v79160, %v79097 (stack52)
        %v79168 = vmul.f32 %v79164, %v79132 (stack53)
        %v79172 = vadd.f32 %v79168, %v79093 (stack52)
        %v79176 = vmul.f32 %v79172, %v79132 (stack53)
        %v79180 = vadd.f32 %v79176, %v79089 (stack52)
        %v79184 = vmul.f32 %v79180, %v79132 (stack53)
        %v79188 = vadd.f32 %v79184, %v79085 (stack52)
        %v79192 = vmul.f32 %v79188, %v79132 (stack53)
        %v79196 = vadd.f32 %v79192, %v79081 (stack52)
        %v79200 = vmul.f32 %v79196, %v79047 (stack53)
        %v79204 = vsel /*vm=*/%vm79052, /*on_true_vy=*/%v79057, /*on_false_vx=*/%v79200 (stack43)
        %v79208 = vmul.f32 1.4140625, %v79204 (stack53)
        %v79211 = vpack.c.bf16 0.0, %v79208 (stack74)
        %120169 = vst [vmem:[%s280 + $0x54] sm:$0xf] /*vst_source=*/%v79211 (stack75)
        %v79215 = vadd.s32 %v78751, %v894 (stack39)
        %v79225 = vadd.s32 %v79215, %v415 (stack39)
        %vm79229 = vcmp.lt.u32.totalorder %v79225, %v79215 (stack42)
        %vm79234 = vcmp.lt.u32.totalorder %v79215, %v894 (stack42)
        %v79239 = vadd.s32 %v78734, %v881 (stack39)
        %v79243 = vadd.s32 1, %v79239 (stack39)
        %v79247 = vsel /*vm=*/%vm79234, /*on_true_vy=*/%v79243, /*on_false_vx=*/%v79239 (stack43)
        %v79251 = vadd.s32 1, %v79247 (stack39)
        %v79255 = vsel /*vm=*/%vm79229, /*on_true_vy=*/%v79251, /*on_false_vx=*/%v79247 (stack43)
        %v79260 = vadd.s32 %v79255, %v10 (stack39)
        %v79264 = vadd.s32 %v79225, %v9 (stack39)
        %v79268 = vadd.s32 %v79264, %v79260 (stack39)
        %v79270 = vshll.u32 %v79264, 13 (stack44)
        %v79271 = vshrl.u32 %v79264, 19 (stack45)
        %v79272 = vor.u32 %v79271, %v79270 (stack46)
        %v79273 = vxor.u32 %v79272, %v79268 (stack47)
        %v79276 = vadd.s32 %v79273, %v79268 (stack39)
        %v79278 = vshll.u32 %v79273, 15 (stack44)
        %v79279 = vshrl.u32 %v79273, 17 (stack45)
        %v79280 = vor.u32 %v79279, %v79278 (stack46)
        %v79281 = vxor.u32 %v79280, %v79276 (stack47)
        %v79284 = vadd.s32 %v79281, %v79276 (stack39)
        %v79286 = vshll.u32 %v79281, 26 (stack44)
        %v79287 = vshrl.u32 %v79281, 6 (stack45)
        %v79288 = vor.u32 %v79287, %v79286 (stack46)
        %v79289 = vxor.u32 %v79288, %v79284 (stack47)
        %v79292 = vadd.s32 %v79289, %v79284 (stack39)
        %v79296 = vadd.s32 %v79292, %v9 (stack39)
        %v79298 = vshll.u32 %v79289, 6 (stack44)
        %v79299 = vshrl.u32 %v79289, 26 (stack45)
        %v79300 = vor.u32 %v79299, %v79298 (stack46)
        %v79301 = vxor.u32 %v79300, %v79292 (stack47)
        %v79304 = vadd.s32 %v79301, %v8 (stack39)
        %v79308 = vadd.s32 1, %v79304 (stack39)
        %v79312 = vadd.s32 %v79308, %v79296 (stack39)
        %v79314 = vshll.u32 %v79308, 17 (stack44)
        %v79315 = vshrl.u32 %v79308, 15 (stack45)
        %v79316 = vor.u32 %v79315, %v79314 (stack46)
        %v79317 = vxor.u32 %v79316, %v79312 (stack47)
        %v79320 = vadd.s32 %v79317, %v79312 (stack39)
        %v79322 = vshll.u32 %v79317, 29 (stack44)
        %v79323 = vshrl.u32 %v79317, 3 (stack45)
        %v79324 = vor.u32 %v79323, %v79322 (stack46)
        %v79325 = vxor.u32 %v79324, %v79320 (stack47)
        %v79328 = vadd.s32 %v79325, %v79320 (stack39)
        %v79330 = vshll.u32 %v79325, 16 (stack44)
        %v79331 = vshrl.u32 %v79325, 16 (stack45)
        %v79332 = vor.u32 %v79331, %v79330 (stack46)
        %v79333 = vxor.u32 %v79332, %v79328 (stack47)
        %v79336 = vadd.s32 %v79333, %v79328 (stack39)
        %v79340 = vadd.s32 %v79336, %v8 (stack39)
        %v79342 = vshll.u32 %v79333, 24 (stack44)
        %v79343 = vshrl.u32 %v79333, 8 (stack45)
        %v79344 = vor.u32 %v79343, %v79342 (stack46)
        %v79345 = vxor.u32 %v79344, %v79336 (stack47)
        %v79348 = vadd.s32 %v79345, %v10 (stack39)
        %v79352 = vadd.s32 2, %v79348 (stack39)
        %v79356 = vadd.s32 %v79352, %v79340 (stack39)
        %v79358 = vshll.u32 %v79352, 13 (stack44)
        %v79359 = vshrl.u32 %v79352, 19 (stack45)
        %v79360 = vor.u32 %v79359, %v79358 (stack46)
        %v79361 = vxor.u32 %v79360, %v79356 (stack47)
        %v79364 = vadd.s32 %v79361, %v79356 (stack39)
        %v79366 = vshll.u32 %v79361, 15 (stack44)
        %v79367 = vshrl.u32 %v79361, 17 (stack45)
        %v79368 = vor.u32 %v79367, %v79366 (stack46)
        %v79369 = vxor.u32 %v79368, %v79364 (stack47)
        %v79372 = vadd.s32 %v79369, %v79364 (stack39)
        %v79374 = vshll.u32 %v79369, 26 (stack44)
        %v79375 = vshrl.u32 %v79369, 6 (stack45)
        %v79376 = vor.u32 %v79375, %v79374 (stack46)
        %v79377 = vxor.u32 %v79376, %v79372 (stack47)
        %v79380 = vadd.s32 %v79377, %v79372 (stack39)
        %v79384 = vadd.s32 %v79380, %v10 (stack39)
        %v79386 = vshll.u32 %v79377, 6 (stack44)
        %v79387 = vshrl.u32 %v79377, 26 (stack45)
        %v79388 = vor.u32 %v79387, %v79386 (stack46)
        %v79389 = vxor.u32 %v79388, %v79380 (stack47)
        %v79392 = vadd.s32 %v79389, %v9 (stack39)
        %v79396 = vadd.s32 3, %v79392 (stack39)
        %v79400 = vadd.s32 %v79396, %v79384 (stack39)
        %v79402 = vshll.u32 %v79396, 17 (stack44)
        %v79403 = vshrl.u32 %v79396, 15 (stack45)
        %v79404 = vor.u32 %v79403, %v79402 (stack46)
        %v79405 = vxor.u32 %v79404, %v79400 (stack47)
        %v79408 = vadd.s32 %v79405, %v79400 (stack39)
        %v79410 = vshll.u32 %v79405, 29 (stack44)
        %v79411 = vshrl.u32 %v79405, 3 (stack45)
        %v79412 = vor.u32 %v79411, %v79410 (stack46)
        %v79413 = vxor.u32 %v79412, %v79408 (stack47)
        %v79416 = vadd.s32 %v79413, %v79408 (stack39)
        %v79418 = vshll.u32 %v79413, 16 (stack44)
        %v79419 = vshrl.u32 %v79413, 16 (stack45)
        %v79420 = vor.u32 %v79419, %v79418 (stack46)
        %v79421 = vxor.u32 %v79420, %v79416 (stack47)
        %v79424 = vadd.s32 %v79421, %v79416 (stack39)
        %v79428 = vadd.s32 %v79424, %v9 (stack39)
        %v79430 = vshll.u32 %v79421, 24 (stack44)
        %v79431 = vshrl.u32 %v79421, 8 (stack45)
        %v79432 = vor.u32 %v79431, %v79430 (stack46)
        %v79433 = vxor.u32 %v79432, %v79424 (stack47)
        %v79436 = vadd.s32 %v79433, %v8 (stack39)
        %v79440 = vadd.s32 4, %v79436 (stack39)
        %v79444 = vadd.s32 %v79440, %v79428 (stack39)
        %v79446 = vshll.u32 %v79440, 13 (stack44)
        %v79447 = vshrl.u32 %v79440, 19 (stack45)
        %v79448 = vor.u32 %v79447, %v79446 (stack46)
        %v79449 = vxor.u32 %v79448, %v79444 (stack47)
        %v79452 = vadd.s32 %v79449, %v79444 (stack39)
        %v79454 = vshll.u32 %v79449, 15 (stack44)
        %v79455 = vshrl.u32 %v79449, 17 (stack45)
        %v79456 = vor.u32 %v79455, %v79454 (stack46)
        %v79457 = vxor.u32 %v79456, %v79452 (stack47)
        %v79460 = vadd.s32 %v79457, %v79452 (stack39)
        %v79462 = vshll.u32 %v79457, 26 (stack44)
        %v79463 = vshrl.u32 %v79457, 6 (stack45)
        %v79464 = vor.u32 %v79463, %v79462 (stack46)
        %v79465 = vxor.u32 %v79464, %v79460 (stack47)
        %v79468 = vadd.s32 %v79465, %v79460 (stack39)
        %v79472 = vadd.s32 %v79468, %v8 (stack39)
        %v79474 = vshll.u32 %v79465, 6 (stack44)
        %v79475 = vshrl.u32 %v79465, 26 (stack45)
        %v79476 = vor.u32 %v79475, %v79474 (stack46)
        %v79477 = vxor.u32 %v79476, %v79468 (stack47)
        %v79480 = vadd.s32 %v79477, %v10 (stack39)
        %v79484 = vadd.s32 5, %v79480 (stack39)
        %v79486 = vxor.u32 %v79484, %v79472 (stack47)
        %v79487 = vand.u32.u8 255, %v79486 (stack48)
        %v79488 = vand.u32 65535, %v79487 (stack49)
        %v79489 = vshrl.u32 %v79488, 1 (stack50)
        %v79490 = vor.u32 16256, %v79489 (stack46)
        %v79491 = vand.u32.u16 65535, %v79490 (stack51)
        %v120170 = vadd.low.f32.bf16 -1.0, %v79491 (stack52)
        %v79500 = vmul.f32 2.0, %v120170 (stack53)
        %v79504 = vadd.f32 -0.99609375, %v79500 (stack52)
        %v79508 = vmax.f32 %v79504, -0.99609375 (stack54)
        %v79510 = vand.u32 2147483647, %v79508 (stack55)
        %vm79513 = vcmp.eq.f32.partialorder %v79510, 1.0 (stack56)
        %v79518 = vmul.f32 inf, %v79508 (stack53)
        %v79520 = vxor.u32 2147483648, %v79508 (stack57)
        %v79523 = vmul.f32 %v79520, %v79508 (stack53)
        %v79525 = vadd.f32 1.0, %v79523 (stack58)
        %v79526 = vlog2.pop %v79525 (stack59)
        %v79527 = vmul.f32 0.6931472, %v79526 (stack60)
        %v79528 = vmul.f32 -0.5, %v79523 (stack61)
        %v79529 = vadd.f32 1.0, %v79528 (stack62)
        %v79530 = vmul.f32 %v79529, %v79523 (stack63)
        %v79531 = vand.u32 2147483647, %v79523 (stack64)
        %vm79532 = vcmp.lt.f32.partialorder %v79531, 0.0004427343 (stack65)
        %v79533 = vsel /*vm=*/%vm79532, /*on_true_vy=*/%v79530, /*on_false_vx=*/%v79527 (stack66)
        %v79534 = vxor.u32 2147483648, %v79533 (stack57)
        %vm79537 = vcmp.lt.f32.partialorder %v79534, 5.0 (stack56)
        %v79542 = vsel /*vm=*/%vm79537, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v79546 = vsel /*vm=*/%vm79537, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v79550 = vsel /*vm=*/%vm79537, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v79554 = vsel /*vm=*/%vm79537, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v79558 = vsel /*vm=*/%vm79537, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v79562 = vsel /*vm=*/%vm79537, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v79566 = vsel /*vm=*/%vm79537, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v79570 = vsel /*vm=*/%vm79537, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v79574 = vsel /*vm=*/%vm79537, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v79578 = vadd.f32 -2.5, %v79534 (stack52)
        %v79580 = vrsqrt.pop %v79534 (stack67)
        %v79581 = vmul.f32 %v79580, %v79534 (stack68)
        %vm79582 = vcmp.eq.f32.partialorder %v79534, inf (stack69)
        %v79583 = vsel /*vm=*/%vm79582, /*on_true_vy=*/%v79534, /*on_false_vx=*/%v79581 (stack70)
        %vm79584 = vcmp.eq.f32.partialorder %v79534, 0.0 (stack71)
        %v79585 = vand.u32 2147483648, %v79534 (stack72)
        %v79586 = vsel /*vm=*/%vm79584, /*on_true_vy=*/%v79585, /*on_false_vx=*/%v79583 (stack73)
        %v79589 = vadd.f32 -3.0, %v79586 (stack52)
        %v79593 = vsel /*vm=*/%vm79537, /*on_true_vy=*/%v79578, /*on_false_vx=*/%v79589 (stack43)
        %v79597 = vmul.f32 %v79593, %v79574 (stack53)
        %v79601 = vadd.f32 %v79597, %v79570 (stack52)
        %v79605 = vmul.f32 %v79601, %v79593 (stack53)
        %v79609 = vadd.f32 %v79605, %v79566 (stack52)
        %v79613 = vmul.f32 %v79609, %v79593 (stack53)
        %v79617 = vadd.f32 %v79613, %v79562 (stack52)
        %v79621 = vmul.f32 %v79617, %v79593 (stack53)
        %v79625 = vadd.f32 %v79621, %v79558 (stack52)
        %v79629 = vmul.f32 %v79625, %v79593 (stack53)
        %v79633 = vadd.f32 %v79629, %v79554 (stack52)
        %v79637 = vmul.f32 %v79633, %v79593 (stack53)
        %v79641 = vadd.f32 %v79637, %v79550 (stack52)
        %v79645 = vmul.f32 %v79641, %v79593 (stack53)
        %v79649 = vadd.f32 %v79645, %v79546 (stack52)
        %v79653 = vmul.f32 %v79649, %v79593 (stack53)
        %v79657 = vadd.f32 %v79653, %v79542 (stack52)
        %v79661 = vmul.f32 %v79657, %v79508 (stack53)
        %v79665 = vsel /*vm=*/%vm79513, /*on_true_vy=*/%v79518, /*on_false_vx=*/%v79661 (stack43)
        %v79669 = vmul.f32 1.4140625, %v79665 (stack53)
        %v79672 = vpack.c.bf16 0.0, %v79669 (stack74)
        %120171 = vst [vmem:[%s280 + $0xd4] sm:$0xf] /*vst_source=*/%v79672 (stack75)
        %v79676 = vadd.s32 %v78751, %v1381 (stack39)
        %v79686 = vadd.s32 %v79676, %v415 (stack39)
        %vm79690 = vcmp.lt.u32.totalorder %v79686, %v79676 (stack42)
        %vm79695 = vcmp.lt.u32.totalorder %v79676, %v1381 (stack42)
        %v79700 = vadd.s32 %v78734, %v1368 (stack39)
        %v79704 = vadd.s32 1, %v79700 (stack39)
        %v79708 = vsel /*vm=*/%vm79695, /*on_true_vy=*/%v79704, /*on_false_vx=*/%v79700 (stack43)
        %v79712 = vadd.s32 1, %v79708 (stack39)
        %v79716 = vsel /*vm=*/%vm79690, /*on_true_vy=*/%v79712, /*on_false_vx=*/%v79708 (stack43)
        %v79721 = vadd.s32 %v79716, %v10 (stack39)
        %v79725 = vadd.s32 %v79686, %v9 (stack39)
        %v79729 = vadd.s32 %v79725, %v79721 (stack39)
        %v79731 = vshll.u32 %v79725, 13 (stack44)
        %v79732 = vshrl.u32 %v79725, 19 (stack45)
        %v79733 = vor.u32 %v79732, %v79731 (stack46)
        %v79734 = vxor.u32 %v79733, %v79729 (stack47)
        %v79737 = vadd.s32 %v79734, %v79729 (stack39)
        %v79739 = vshll.u32 %v79734, 15 (stack44)
        %v79740 = vshrl.u32 %v79734, 17 (stack45)
        %v79741 = vor.u32 %v79740, %v79739 (stack46)
        %v79742 = vxor.u32 %v79741, %v79737 (stack47)
        %v79745 = vadd.s32 %v79742, %v79737 (stack39)
        %v79747 = vshll.u32 %v79742, 26 (stack44)
        %v79748 = vshrl.u32 %v79742, 6 (stack45)
        %v79749 = vor.u32 %v79748, %v79747 (stack46)
        %v79750 = vxor.u32 %v79749, %v79745 (stack47)
        %v79753 = vadd.s32 %v79750, %v79745 (stack39)
        %v79757 = vadd.s32 %v79753, %v9 (stack39)
        %v79759 = vshll.u32 %v79750, 6 (stack44)
        %v79760 = vshrl.u32 %v79750, 26 (stack45)
        %v79761 = vor.u32 %v79760, %v79759 (stack46)
        %v79762 = vxor.u32 %v79761, %v79753 (stack47)
        %v79765 = vadd.s32 %v79762, %v8 (stack39)
        %v79769 = vadd.s32 1, %v79765 (stack39)
        %v79773 = vadd.s32 %v79769, %v79757 (stack39)
        %v79775 = vshll.u32 %v79769, 17 (stack44)
        %v79776 = vshrl.u32 %v79769, 15 (stack45)
        %v79777 = vor.u32 %v79776, %v79775 (stack46)
        %v79778 = vxor.u32 %v79777, %v79773 (stack47)
        %v79781 = vadd.s32 %v79778, %v79773 (stack39)
        %v79783 = vshll.u32 %v79778, 29 (stack44)
        %v79784 = vshrl.u32 %v79778, 3 (stack45)
        %v79785 = vor.u32 %v79784, %v79783 (stack46)
        %v79786 = vxor.u32 %v79785, %v79781 (stack47)
        %v79789 = vadd.s32 %v79786, %v79781 (stack39)
        %v79791 = vshll.u32 %v79786, 16 (stack44)
        %v79792 = vshrl.u32 %v79786, 16 (stack45)
        %v79793 = vor.u32 %v79792, %v79791 (stack46)
        %v79794 = vxor.u32 %v79793, %v79789 (stack47)
        %v79797 = vadd.s32 %v79794, %v79789 (stack39)
        %v79801 = vadd.s32 %v79797, %v8 (stack39)
        %v79803 = vshll.u32 %v79794, 24 (stack44)
        %v79804 = vshrl.u32 %v79794, 8 (stack45)
        %v79805 = vor.u32 %v79804, %v79803 (stack46)
        %v79806 = vxor.u32 %v79805, %v79797 (stack47)
        %v79809 = vadd.s32 %v79806, %v10 (stack39)
        %v79813 = vadd.s32 2, %v79809 (stack39)
        %v79817 = vadd.s32 %v79813, %v79801 (stack39)
        %v79819 = vshll.u32 %v79813, 13 (stack44)
        %v79820 = vshrl.u32 %v79813, 19 (stack45)
        %v79821 = vor.u32 %v79820, %v79819 (stack46)
        %v79822 = vxor.u32 %v79821, %v79817 (stack47)
        %v79825 = vadd.s32 %v79822, %v79817 (stack39)
        %v79827 = vshll.u32 %v79822, 15 (stack44)
        %v79828 = vshrl.u32 %v79822, 17 (stack45)
        %v79829 = vor.u32 %v79828, %v79827 (stack46)
        %v79830 = vxor.u32 %v79829, %v79825 (stack47)
        %v79833 = vadd.s32 %v79830, %v79825 (stack39)
        %v79835 = vshll.u32 %v79830, 26 (stack44)
        %v79836 = vshrl.u32 %v79830, 6 (stack45)
        %v79837 = vor.u32 %v79836, %v79835 (stack46)
        %v79838 = vxor.u32 %v79837, %v79833 (stack47)
        %v79841 = vadd.s32 %v79838, %v79833 (stack39)
        %v79845 = vadd.s32 %v79841, %v10 (stack39)
        %v79847 = vshll.u32 %v79838, 6 (stack44)
        %v79848 = vshrl.u32 %v79838, 26 (stack45)
        %v79849 = vor.u32 %v79848, %v79847 (stack46)
        %v79850 = vxor.u32 %v79849, %v79841 (stack47)
        %v79853 = vadd.s32 %v79850, %v9 (stack39)
        %v79857 = vadd.s32 3, %v79853 (stack39)
        %v79861 = vadd.s32 %v79857, %v79845 (stack39)
        %v79863 = vshll.u32 %v79857, 17 (stack44)
        %v79864 = vshrl.u32 %v79857, 15 (stack45)
        %v79865 = vor.u32 %v79864, %v79863 (stack46)
        %v79866 = vxor.u32 %v79865, %v79861 (stack47)
        %v79869 = vadd.s32 %v79866, %v79861 (stack39)
        %v79871 = vshll.u32 %v79866, 29 (stack44)
        %v79872 = vshrl.u32 %v79866, 3 (stack45)
        %v79873 = vor.u32 %v79872, %v79871 (stack46)
        %v79874 = vxor.u32 %v79873, %v79869 (stack47)
        %v79877 = vadd.s32 %v79874, %v79869 (stack39)
        %v79879 = vshll.u32 %v79874, 16 (stack44)
        %v79880 = vshrl.u32 %v79874, 16 (stack45)
        %v79881 = vor.u32 %v79880, %v79879 (stack46)
        %v79882 = vxor.u32 %v79881, %v79877 (stack47)
        %v79885 = vadd.s32 %v79882, %v79877 (stack39)
        %v79889 = vadd.s32 %v79885, %v9 (stack39)
        %v79891 = vshll.u32 %v79882, 24 (stack44)
        %v79892 = vshrl.u32 %v79882, 8 (stack45)
        %v79893 = vor.u32 %v79892, %v79891 (stack46)
        %v79894 = vxor.u32 %v79893, %v79885 (stack47)
        %v79897 = vadd.s32 %v79894, %v8 (stack39)
        %v79901 = vadd.s32 4, %v79897 (stack39)
        %v79905 = vadd.s32 %v79901, %v79889 (stack39)
        %v79907 = vshll.u32 %v79901, 13 (stack44)
        %v79908 = vshrl.u32 %v79901, 19 (stack45)
        %v79909 = vor.u32 %v79908, %v79907 (stack46)
        %v79910 = vxor.u32 %v79909, %v79905 (stack47)
        %v79913 = vadd.s32 %v79910, %v79905 (stack39)
        %v79915 = vshll.u32 %v79910, 15 (stack44)
        %v79916 = vshrl.u32 %v79910, 17 (stack45)
        %v79917 = vor.u32 %v79916, %v79915 (stack46)
        %v79918 = vxor.u32 %v79917, %v79913 (stack47)
        %v79921 = vadd.s32 %v79918, %v79913 (stack39)
        %v79923 = vshll.u32 %v79918, 26 (stack44)
        %v79924 = vshrl.u32 %v79918, 6 (stack45)
        %v79925 = vor.u32 %v79924, %v79923 (stack46)
        %v79926 = vxor.u32 %v79925, %v79921 (stack47)
        %v79929 = vadd.s32 %v79926, %v79921 (stack39)
        %v79933 = vadd.s32 %v79929, %v8 (stack39)
        %v79935 = vshll.u32 %v79926, 6 (stack44)
        %v79936 = vshrl.u32 %v79926, 26 (stack45)
        %v79937 = vor.u32 %v79936, %v79935 (stack46)
        %v79938 = vxor.u32 %v79937, %v79929 (stack47)
        %v79941 = vadd.s32 %v79938, %v10 (stack39)
        %v79945 = vadd.s32 5, %v79941 (stack39)
        %v79947 = vxor.u32 %v79945, %v79933 (stack47)
        %v79948 = vand.u32.u8 255, %v79947 (stack48)
        %v79949 = vand.u32 65535, %v79948 (stack49)
        %v79950 = vshrl.u32 %v79949, 1 (stack50)
        %v79951 = vor.u32 16256, %v79950 (stack46)
        %v79952 = vand.u32.u16 65535, %v79951 (stack51)
        %v120172 = vadd.low.f32.bf16 -1.0, %v79952 (stack52)
        %v79961 = vmul.f32 2.0, %v120172 (stack53)
        %v79965 = vadd.f32 -0.99609375, %v79961 (stack52)
        %v79969 = vmax.f32 %v79965, -0.99609375 (stack54)
        %v79971 = vand.u32 2147483647, %v79969 (stack55)
        %vm79974 = vcmp.eq.f32.partialorder %v79971, 1.0 (stack56)
        %v79979 = vmul.f32 inf, %v79969 (stack53)
        %v79981 = vxor.u32 2147483648, %v79969 (stack57)
        %v79984 = vmul.f32 %v79981, %v79969 (stack53)
        %v79986 = vadd.f32 1.0, %v79984 (stack58)
        %v79987 = vlog2.pop %v79986 (stack59)
        %v79988 = vmul.f32 0.6931472, %v79987 (stack60)
        %v79989 = vmul.f32 -0.5, %v79984 (stack61)
        %v79990 = vadd.f32 1.0, %v79989 (stack62)
        %v79991 = vmul.f32 %v79990, %v79984 (stack63)
        %v79992 = vand.u32 2147483647, %v79984 (stack64)
        %vm79993 = vcmp.lt.f32.partialorder %v79992, 0.0004427343 (stack65)
        %v79994 = vsel /*vm=*/%vm79993, /*on_true_vy=*/%v79991, /*on_false_vx=*/%v79988 (stack66)
        %v79995 = vxor.u32 2147483648, %v79994 (stack57)
        %vm79998 = vcmp.lt.f32.partialorder %v79995, 5.0 (stack56)
        %v80003 = vsel /*vm=*/%vm79998, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v80007 = vsel /*vm=*/%vm79998, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v80011 = vsel /*vm=*/%vm79998, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v80015 = vsel /*vm=*/%vm79998, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v80019 = vsel /*vm=*/%vm79998, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v80023 = vsel /*vm=*/%vm79998, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v80027 = vsel /*vm=*/%vm79998, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v80031 = vsel /*vm=*/%vm79998, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v80035 = vsel /*vm=*/%vm79998, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v80039 = vadd.f32 -2.5, %v79995 (stack52)
        %v80041 = vrsqrt.pop %v79995 (stack67)
        %v80042 = vmul.f32 %v80041, %v79995 (stack68)
        %vm80043 = vcmp.eq.f32.partialorder %v79995, inf (stack69)
        %v80044 = vsel /*vm=*/%vm80043, /*on_true_vy=*/%v79995, /*on_false_vx=*/%v80042 (stack70)
        %vm80045 = vcmp.eq.f32.partialorder %v79995, 0.0 (stack71)
        %v80046 = vand.u32 2147483648, %v79995 (stack72)
        %v80047 = vsel /*vm=*/%vm80045, /*on_true_vy=*/%v80046, /*on_false_vx=*/%v80044 (stack73)
        %v80050 = vadd.f32 -3.0, %v80047 (stack52)
        %v80054 = vsel /*vm=*/%vm79998, /*on_true_vy=*/%v80039, /*on_false_vx=*/%v80050 (stack43)
        %v80058 = vmul.f32 %v80054, %v80035 (stack53)
        %v80062 = vadd.f32 %v80058, %v80031 (stack52)
        %v80066 = vmul.f32 %v80062, %v80054 (stack53)
        %v80070 = vadd.f32 %v80066, %v80027 (stack52)
        %v80074 = vmul.f32 %v80070, %v80054 (stack53)
        %v80078 = vadd.f32 %v80074, %v80023 (stack52)
        %v80082 = vmul.f32 %v80078, %v80054 (stack53)
        %v80086 = vadd.f32 %v80082, %v80019 (stack52)
        %v80090 = vmul.f32 %v80086, %v80054 (stack53)
        %v80094 = vadd.f32 %v80090, %v80015 (stack52)
        %v80098 = vmul.f32 %v80094, %v80054 (stack53)
        %v80102 = vadd.f32 %v80098, %v80011 (stack52)
        %v80106 = vmul.f32 %v80102, %v80054 (stack53)
        %v80110 = vadd.f32 %v80106, %v80007 (stack52)
        %v80114 = vmul.f32 %v80110, %v80054 (stack53)
        %v80118 = vadd.f32 %v80114, %v80003 (stack52)
        %v80122 = vmul.f32 %v80118, %v79969 (stack53)
        %v80126 = vsel /*vm=*/%vm79974, /*on_true_vy=*/%v79979, /*on_false_vx=*/%v80122 (stack43)
        %v80130 = vmul.f32 1.4140625, %v80126 (stack53)
        %v80133 = vpack.c.bf16 0.0, %v80130 (stack74)
        %120173 = vst [vmem:[%s280 + $0x154] sm:$0xf] /*vst_source=*/%v80133 (stack75)
        %v80137 = vadd.s32 %v78751, %v1868 (stack39)
        %v80147 = vadd.s32 %v80137, %v415 (stack39)
        %vm80151 = vcmp.lt.u32.totalorder %v80147, %v80137 (stack42)
        %vm80156 = vcmp.lt.u32.totalorder %v80137, %v1868 (stack42)
        %v80161 = vadd.s32 %v78734, %v1855 (stack39)
        %v80165 = vadd.s32 1, %v80161 (stack39)
        %v80169 = vsel /*vm=*/%vm80156, /*on_true_vy=*/%v80165, /*on_false_vx=*/%v80161 (stack43)
        %v80173 = vadd.s32 1, %v80169 (stack39)
        %v80177 = vsel /*vm=*/%vm80151, /*on_true_vy=*/%v80173, /*on_false_vx=*/%v80169 (stack43)
        %v80182 = vadd.s32 %v80177, %v10 (stack39)
        %v80186 = vadd.s32 %v80147, %v9 (stack39)
        %v80190 = vadd.s32 %v80186, %v80182 (stack39)
        %v80192 = vshll.u32 %v80186, 13 (stack44)
        %v80193 = vshrl.u32 %v80186, 19 (stack45)
        %v80194 = vor.u32 %v80193, %v80192 (stack46)
        %v80195 = vxor.u32 %v80194, %v80190 (stack47)
        %v80198 = vadd.s32 %v80195, %v80190 (stack39)
        %v80200 = vshll.u32 %v80195, 15 (stack44)
        %v80201 = vshrl.u32 %v80195, 17 (stack45)
        %v80202 = vor.u32 %v80201, %v80200 (stack46)
        %v80203 = vxor.u32 %v80202, %v80198 (stack47)
        %v80206 = vadd.s32 %v80203, %v80198 (stack39)
        %v80208 = vshll.u32 %v80203, 26 (stack44)
        %v80209 = vshrl.u32 %v80203, 6 (stack45)
        %v80210 = vor.u32 %v80209, %v80208 (stack46)
        %v80211 = vxor.u32 %v80210, %v80206 (stack47)
        %v80214 = vadd.s32 %v80211, %v80206 (stack39)
        %v80218 = vadd.s32 %v80214, %v9 (stack39)
        %v80220 = vshll.u32 %v80211, 6 (stack44)
        %v80221 = vshrl.u32 %v80211, 26 (stack45)
        %v80222 = vor.u32 %v80221, %v80220 (stack46)
        %v80223 = vxor.u32 %v80222, %v80214 (stack47)
        %v80226 = vadd.s32 %v80223, %v8 (stack39)
        %v80230 = vadd.s32 1, %v80226 (stack39)
        %v80234 = vadd.s32 %v80230, %v80218 (stack39)
        %v80236 = vshll.u32 %v80230, 17 (stack44)
        %v80237 = vshrl.u32 %v80230, 15 (stack45)
        %v80238 = vor.u32 %v80237, %v80236 (stack46)
        %v80239 = vxor.u32 %v80238, %v80234 (stack47)
        %v80242 = vadd.s32 %v80239, %v80234 (stack39)
        %v80244 = vshll.u32 %v80239, 29 (stack44)
        %v80245 = vshrl.u32 %v80239, 3 (stack45)
        %v80246 = vor.u32 %v80245, %v80244 (stack46)
        %v80247 = vxor.u32 %v80246, %v80242 (stack47)
        %v80250 = vadd.s32 %v80247, %v80242 (stack39)
        %v80252 = vshll.u32 %v80247, 16 (stack44)
        %v80253 = vshrl.u32 %v80247, 16 (stack45)
        %v80254 = vor.u32 %v80253, %v80252 (stack46)
        %v80255 = vxor.u32 %v80254, %v80250 (stack47)
        %v80258 = vadd.s32 %v80255, %v80250 (stack39)
        %v80262 = vadd.s32 %v80258, %v8 (stack39)
        %v80264 = vshll.u32 %v80255, 24 (stack44)
        %v80265 = vshrl.u32 %v80255, 8 (stack45)
        %v80266 = vor.u32 %v80265, %v80264 (stack46)
        %v80267 = vxor.u32 %v80266, %v80258 (stack47)
        %v80270 = vadd.s32 %v80267, %v10 (stack39)
        %v80274 = vadd.s32 2, %v80270 (stack39)
        %v80278 = vadd.s32 %v80274, %v80262 (stack39)
        %v80280 = vshll.u32 %v80274, 13 (stack44)
        %v80281 = vshrl.u32 %v80274, 19 (stack45)
        %v80282 = vor.u32 %v80281, %v80280 (stack46)
        %v80283 = vxor.u32 %v80282, %v80278 (stack47)
        %v80286 = vadd.s32 %v80283, %v80278 (stack39)
        %v80288 = vshll.u32 %v80283, 15 (stack44)
        %v80289 = vshrl.u32 %v80283, 17 (stack45)
        %v80290 = vor.u32 %v80289, %v80288 (stack46)
        %v80291 = vxor.u32 %v80290, %v80286 (stack47)
        %v80294 = vadd.s32 %v80291, %v80286 (stack39)
        %v80296 = vshll.u32 %v80291, 26 (stack44)
        %v80297 = vshrl.u32 %v80291, 6 (stack45)
        %v80298 = vor.u32 %v80297, %v80296 (stack46)
        %v80299 = vxor.u32 %v80298, %v80294 (stack47)
        %v80302 = vadd.s32 %v80299, %v80294 (stack39)
        %v80306 = vadd.s32 %v80302, %v10 (stack39)
        %v80308 = vshll.u32 %v80299, 6 (stack44)
        %v80309 = vshrl.u32 %v80299, 26 (stack45)
        %v80310 = vor.u32 %v80309, %v80308 (stack46)
        %v80311 = vxor.u32 %v80310, %v80302 (stack47)
        %v80314 = vadd.s32 %v80311, %v9 (stack39)
        %v80318 = vadd.s32 3, %v80314 (stack39)
        %v80322 = vadd.s32 %v80318, %v80306 (stack39)
        %v80324 = vshll.u32 %v80318, 17 (stack44)
        %v80325 = vshrl.u32 %v80318, 15 (stack45)
        %v80326 = vor.u32 %v80325, %v80324 (stack46)
        %v80327 = vxor.u32 %v80326, %v80322 (stack47)
        %v80330 = vadd.s32 %v80327, %v80322 (stack39)
        %v80332 = vshll.u32 %v80327, 29 (stack44)
        %v80333 = vshrl.u32 %v80327, 3 (stack45)
        %v80334 = vor.u32 %v80333, %v80332 (stack46)
        %v80335 = vxor.u32 %v80334, %v80330 (stack47)
        %v80338 = vadd.s32 %v80335, %v80330 (stack39)
        %v80340 = vshll.u32 %v80335, 16 (stack44)
        %v80341 = vshrl.u32 %v80335, 16 (stack45)
        %v80342 = vor.u32 %v80341, %v80340 (stack46)
        %v80343 = vxor.u32 %v80342, %v80338 (stack47)
        %v80346 = vadd.s32 %v80343, %v80338 (stack39)
        %v80350 = vadd.s32 %v80346, %v9 (stack39)
        %v80352 = vshll.u32 %v80343, 24 (stack44)
        %v80353 = vshrl.u32 %v80343, 8 (stack45)
        %v80354 = vor.u32 %v80353, %v80352 (stack46)
        %v80355 = vxor.u32 %v80354, %v80346 (stack47)
        %v80358 = vadd.s32 %v80355, %v8 (stack39)
        %v80362 = vadd.s32 4, %v80358 (stack39)
        %v80366 = vadd.s32 %v80362, %v80350 (stack39)
        %v80368 = vshll.u32 %v80362, 13 (stack44)
        %v80369 = vshrl.u32 %v80362, 19 (stack45)
        %v80370 = vor.u32 %v80369, %v80368 (stack46)
        %v80371 = vxor.u32 %v80370, %v80366 (stack47)
        %v80374 = vadd.s32 %v80371, %v80366 (stack39)
        %v80376 = vshll.u32 %v80371, 15 (stack44)
        %v80377 = vshrl.u32 %v80371, 17 (stack45)
        %v80378 = vor.u32 %v80377, %v80376 (stack46)
        %v80379 = vxor.u32 %v80378, %v80374 (stack47)
        %v80382 = vadd.s32 %v80379, %v80374 (stack39)
        %v80384 = vshll.u32 %v80379, 26 (stack44)
        %v80385 = vshrl.u32 %v80379, 6 (stack45)
        %v80386 = vor.u32 %v80385, %v80384 (stack46)
        %v80387 = vxor.u32 %v80386, %v80382 (stack47)
        %v80390 = vadd.s32 %v80387, %v80382 (stack39)
        %v80394 = vadd.s32 %v80390, %v8 (stack39)
        %v80396 = vshll.u32 %v80387, 6 (stack44)
        %v80397 = vshrl.u32 %v80387, 26 (stack45)
        %v80398 = vor.u32 %v80397, %v80396 (stack46)
        %v80399 = vxor.u32 %v80398, %v80390 (stack47)
        %v80402 = vadd.s32 %v80399, %v10 (stack39)
        %v80406 = vadd.s32 5, %v80402 (stack39)
        %v80408 = vxor.u32 %v80406, %v80394 (stack47)
        %v80409 = vand.u32.u8 255, %v80408 (stack48)
        %v80410 = vand.u32 65535, %v80409 (stack49)
        %v80411 = vshrl.u32 %v80410, 1 (stack50)
        %v80412 = vor.u32 16256, %v80411 (stack46)
        %v80413 = vand.u32.u16 65535, %v80412 (stack51)
        %v120174 = vadd.low.f32.bf16 -1.0, %v80413 (stack52)
        %v80422 = vmul.f32 2.0, %v120174 (stack53)
        %v80426 = vadd.f32 -0.99609375, %v80422 (stack52)
        %v80430 = vmax.f32 %v80426, -0.99609375 (stack54)
        %v80432 = vand.u32 2147483647, %v80430 (stack55)
        %vm80435 = vcmp.eq.f32.partialorder %v80432, 1.0 (stack56)
        %v80440 = vmul.f32 inf, %v80430 (stack53)
        %v80442 = vxor.u32 2147483648, %v80430 (stack57)
        %v80445 = vmul.f32 %v80442, %v80430 (stack53)
        %v80447 = vadd.f32 1.0, %v80445 (stack58)
        %v80448 = vlog2.pop %v80447 (stack59)
        %v80449 = vmul.f32 0.6931472, %v80448 (stack60)
        %v80450 = vmul.f32 -0.5, %v80445 (stack61)
        %v80451 = vadd.f32 1.0, %v80450 (stack62)
        %v80452 = vmul.f32 %v80451, %v80445 (stack63)
        %v80453 = vand.u32 2147483647, %v80445 (stack64)
        %vm80454 = vcmp.lt.f32.partialorder %v80453, 0.0004427343 (stack65)
        %v80455 = vsel /*vm=*/%vm80454, /*on_true_vy=*/%v80452, /*on_false_vx=*/%v80449 (stack66)
        %v80456 = vxor.u32 2147483648, %v80455 (stack57)
        %vm80459 = vcmp.lt.f32.partialorder %v80456, 5.0 (stack56)
        %v80464 = vsel /*vm=*/%vm80459, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v80468 = vsel /*vm=*/%vm80459, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v80472 = vsel /*vm=*/%vm80459, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v80476 = vsel /*vm=*/%vm80459, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v80480 = vsel /*vm=*/%vm80459, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v80484 = vsel /*vm=*/%vm80459, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v80488 = vsel /*vm=*/%vm80459, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v80492 = vsel /*vm=*/%vm80459, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v80496 = vsel /*vm=*/%vm80459, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v80500 = vadd.f32 -2.5, %v80456 (stack52)
        %v80502 = vrsqrt.pop %v80456 (stack67)
        %v80503 = vmul.f32 %v80502, %v80456 (stack68)
        %vm80504 = vcmp.eq.f32.partialorder %v80456, inf (stack69)
        %v80505 = vsel /*vm=*/%vm80504, /*on_true_vy=*/%v80456, /*on_false_vx=*/%v80503 (stack70)
        %vm80506 = vcmp.eq.f32.partialorder %v80456, 0.0 (stack71)
        %v80507 = vand.u32 2147483648, %v80456 (stack72)
        %v80508 = vsel /*vm=*/%vm80506, /*on_true_vy=*/%v80507, /*on_false_vx=*/%v80505 (stack73)
        %v80511 = vadd.f32 -3.0, %v80508 (stack52)
        %v80515 = vsel /*vm=*/%vm80459, /*on_true_vy=*/%v80500, /*on_false_vx=*/%v80511 (stack43)
        %v80519 = vmul.f32 %v80515, %v80496 (stack53)
        %v80523 = vadd.f32 %v80519, %v80492 (stack52)
        %v80527 = vmul.f32 %v80523, %v80515 (stack53)
        %v80531 = vadd.f32 %v80527, %v80488 (stack52)
        %v80535 = vmul.f32 %v80531, %v80515 (stack53)
        %v80539 = vadd.f32 %v80535, %v80484 (stack52)
        %v80543 = vmul.f32 %v80539, %v80515 (stack53)
        %v80547 = vadd.f32 %v80543, %v80480 (stack52)
        %v80551 = vmul.f32 %v80547, %v80515 (stack53)
        %v80555 = vadd.f32 %v80551, %v80476 (stack52)
        %v80559 = vmul.f32 %v80555, %v80515 (stack53)
        %v80563 = vadd.f32 %v80559, %v80472 (stack52)
        %v80567 = vmul.f32 %v80563, %v80515 (stack53)
        %v80571 = vadd.f32 %v80567, %v80468 (stack52)
        %v80575 = vmul.f32 %v80571, %v80515 (stack53)
        %v80579 = vadd.f32 %v80575, %v80464 (stack52)
        %v80583 = vmul.f32 %v80579, %v80430 (stack53)
        %v80587 = vsel /*vm=*/%vm80435, /*on_true_vy=*/%v80440, /*on_false_vx=*/%v80583 (stack43)
        %v80591 = vmul.f32 1.4140625, %v80587 (stack53)
        %v80594 = vpack.c.bf16 0.0, %v80591 (stack74)
        %120175 = vst [vmem:[%s280 + $0x1d4] sm:$0xf] /*vst_source=*/%v80594 (stack75)
        %v80598 = vadd.s32 %v78751, %v2355 (stack39)
        %v80608 = vadd.s32 %v80598, %v415 (stack39)
        %vm80612 = vcmp.lt.u32.totalorder %v80608, %v80598 (stack42)
        %vm80617 = vcmp.lt.u32.totalorder %v80598, %v2355 (stack42)
        %v80622 = vadd.s32 %v78734, %v2342 (stack39)
        %v80626 = vadd.s32 1, %v80622 (stack39)
        %v80630 = vsel /*vm=*/%vm80617, /*on_true_vy=*/%v80626, /*on_false_vx=*/%v80622 (stack43)
        %v80634 = vadd.s32 1, %v80630 (stack39)
        %v80638 = vsel /*vm=*/%vm80612, /*on_true_vy=*/%v80634, /*on_false_vx=*/%v80630 (stack43)
        %v80643 = vadd.s32 %v80638, %v10 (stack39)
        %v80647 = vadd.s32 %v80608, %v9 (stack39)
        %v80651 = vadd.s32 %v80647, %v80643 (stack39)
        %v80653 = vshll.u32 %v80647, 13 (stack44)
        %v80654 = vshrl.u32 %v80647, 19 (stack45)
        %v80655 = vor.u32 %v80654, %v80653 (stack46)
        %v80656 = vxor.u32 %v80655, %v80651 (stack47)
        %v80659 = vadd.s32 %v80656, %v80651 (stack39)
        %v80661 = vshll.u32 %v80656, 15 (stack44)
        %v80662 = vshrl.u32 %v80656, 17 (stack45)
        %v80663 = vor.u32 %v80662, %v80661 (stack46)
        %v80664 = vxor.u32 %v80663, %v80659 (stack47)
        %v80667 = vadd.s32 %v80664, %v80659 (stack39)
        %v80669 = vshll.u32 %v80664, 26 (stack44)
        %v80670 = vshrl.u32 %v80664, 6 (stack45)
        %v80671 = vor.u32 %v80670, %v80669 (stack46)
        %v80672 = vxor.u32 %v80671, %v80667 (stack47)
        %v80675 = vadd.s32 %v80672, %v80667 (stack39)
        %v80679 = vadd.s32 %v80675, %v9 (stack39)
        %v80681 = vshll.u32 %v80672, 6 (stack44)
        %v80682 = vshrl.u32 %v80672, 26 (stack45)
        %v80683 = vor.u32 %v80682, %v80681 (stack46)
        %v80684 = vxor.u32 %v80683, %v80675 (stack47)
        %v80687 = vadd.s32 %v80684, %v8 (stack39)
        %v80691 = vadd.s32 1, %v80687 (stack39)
        %v80695 = vadd.s32 %v80691, %v80679 (stack39)
        %v80697 = vshll.u32 %v80691, 17 (stack44)
        %v80698 = vshrl.u32 %v80691, 15 (stack45)
        %v80699 = vor.u32 %v80698, %v80697 (stack46)
        %v80700 = vxor.u32 %v80699, %v80695 (stack47)
        %v80703 = vadd.s32 %v80700, %v80695 (stack39)
        %v80705 = vshll.u32 %v80700, 29 (stack44)
        %v80706 = vshrl.u32 %v80700, 3 (stack45)
        %v80707 = vor.u32 %v80706, %v80705 (stack46)
        %v80708 = vxor.u32 %v80707, %v80703 (stack47)
        %v80711 = vadd.s32 %v80708, %v80703 (stack39)
        %v80713 = vshll.u32 %v80708, 16 (stack44)
        %v80714 = vshrl.u32 %v80708, 16 (stack45)
        %v80715 = vor.u32 %v80714, %v80713 (stack46)
        %v80716 = vxor.u32 %v80715, %v80711 (stack47)
        %v80719 = vadd.s32 %v80716, %v80711 (stack39)
        %v80723 = vadd.s32 %v80719, %v8 (stack39)
        %v80725 = vshll.u32 %v80716, 24 (stack44)
        %v80726 = vshrl.u32 %v80716, 8 (stack45)
        %v80727 = vor.u32 %v80726, %v80725 (stack46)
        %v80728 = vxor.u32 %v80727, %v80719 (stack47)
        %v80731 = vadd.s32 %v80728, %v10 (stack39)
        %v80735 = vadd.s32 2, %v80731 (stack39)
        %v80739 = vadd.s32 %v80735, %v80723 (stack39)
        %v80741 = vshll.u32 %v80735, 13 (stack44)
        %v80742 = vshrl.u32 %v80735, 19 (stack45)
        %v80743 = vor.u32 %v80742, %v80741 (stack46)
        %v80744 = vxor.u32 %v80743, %v80739 (stack47)
        %v80747 = vadd.s32 %v80744, %v80739 (stack39)
        %v80749 = vshll.u32 %v80744, 15 (stack44)
        %v80750 = vshrl.u32 %v80744, 17 (stack45)
        %v80751 = vor.u32 %v80750, %v80749 (stack46)
        %v80752 = vxor.u32 %v80751, %v80747 (stack47)
        %v80755 = vadd.s32 %v80752, %v80747 (stack39)
        %v80757 = vshll.u32 %v80752, 26 (stack44)
        %v80758 = vshrl.u32 %v80752, 6 (stack45)
        %v80759 = vor.u32 %v80758, %v80757 (stack46)
        %v80760 = vxor.u32 %v80759, %v80755 (stack47)
        %v80763 = vadd.s32 %v80760, %v80755 (stack39)
        %v80767 = vadd.s32 %v80763, %v10 (stack39)
        %v80769 = vshll.u32 %v80760, 6 (stack44)
        %v80770 = vshrl.u32 %v80760, 26 (stack45)
        %v80771 = vor.u32 %v80770, %v80769 (stack46)
        %v80772 = vxor.u32 %v80771, %v80763 (stack47)
        %v80775 = vadd.s32 %v80772, %v9 (stack39)
        %v80779 = vadd.s32 3, %v80775 (stack39)
        %v80783 = vadd.s32 %v80779, %v80767 (stack39)
        %v80785 = vshll.u32 %v80779, 17 (stack44)
        %v80786 = vshrl.u32 %v80779, 15 (stack45)
        %v80787 = vor.u32 %v80786, %v80785 (stack46)
        %v80788 = vxor.u32 %v80787, %v80783 (stack47)
        %v80791 = vadd.s32 %v80788, %v80783 (stack39)
        %v80793 = vshll.u32 %v80788, 29 (stack44)
        %v80794 = vshrl.u32 %v80788, 3 (stack45)
        %v80795 = vor.u32 %v80794, %v80793 (stack46)
        %v80796 = vxor.u32 %v80795, %v80791 (stack47)
        %v80799 = vadd.s32 %v80796, %v80791 (stack39)
        %v80801 = vshll.u32 %v80796, 16 (stack44)
        %v80802 = vshrl.u32 %v80796, 16 (stack45)
        %v80803 = vor.u32 %v80802, %v80801 (stack46)
        %v80804 = vxor.u32 %v80803, %v80799 (stack47)
        %v80807 = vadd.s32 %v80804, %v80799 (stack39)
        %v80811 = vadd.s32 %v80807, %v9 (stack39)
        %v80813 = vshll.u32 %v80804, 24 (stack44)
        %v80814 = vshrl.u32 %v80804, 8 (stack45)
        %v80815 = vor.u32 %v80814, %v80813 (stack46)
        %v80816 = vxor.u32 %v80815, %v80807 (stack47)
        %v80819 = vadd.s32 %v80816, %v8 (stack39)
        %v80823 = vadd.s32 4, %v80819 (stack39)
        %v80827 = vadd.s32 %v80823, %v80811 (stack39)
        %v80829 = vshll.u32 %v80823, 13 (stack44)
        %v80830 = vshrl.u32 %v80823, 19 (stack45)
        %v80831 = vor.u32 %v80830, %v80829 (stack46)
        %v80832 = vxor.u32 %v80831, %v80827 (stack47)
        %v80835 = vadd.s32 %v80832, %v80827 (stack39)
        %v80837 = vshll.u32 %v80832, 15 (stack44)
        %v80838 = vshrl.u32 %v80832, 17 (stack45)
        %v80839 = vor.u32 %v80838, %v80837 (stack46)
        %v80840 = vxor.u32 %v80839, %v80835 (stack47)
        %v80843 = vadd.s32 %v80840, %v80835 (stack39)
        %v80845 = vshll.u32 %v80840, 26 (stack44)
        %v80846 = vshrl.u32 %v80840, 6 (stack45)
        %v80847 = vor.u32 %v80846, %v80845 (stack46)
        %v80848 = vxor.u32 %v80847, %v80843 (stack47)
        %v80851 = vadd.s32 %v80848, %v80843 (stack39)
        %v80855 = vadd.s32 %v80851, %v8 (stack39)
        %v80857 = vshll.u32 %v80848, 6 (stack44)
        %v80858 = vshrl.u32 %v80848, 26 (stack45)
        %v80859 = vor.u32 %v80858, %v80857 (stack46)
        %v80860 = vxor.u32 %v80859, %v80851 (stack47)
        %v80863 = vadd.s32 %v80860, %v10 (stack39)
        %v80867 = vadd.s32 5, %v80863 (stack39)
        %v80869 = vxor.u32 %v80867, %v80855 (stack47)
        %v80870 = vand.u32.u8 255, %v80869 (stack48)
        %v80871 = vand.u32 65535, %v80870 (stack49)
        %v80872 = vshrl.u32 %v80871, 1 (stack50)
        %v80873 = vor.u32 16256, %v80872 (stack46)
        %v80874 = vand.u32.u16 65535, %v80873 (stack51)
        %v120176 = vadd.low.f32.bf16 -1.0, %v80874 (stack52)
        %v80883 = vmul.f32 2.0, %v120176 (stack53)
        %v80887 = vadd.f32 -0.99609375, %v80883 (stack52)
        %v80891 = vmax.f32 %v80887, -0.99609375 (stack54)
        %v80893 = vand.u32 2147483647, %v80891 (stack55)
        %vm80896 = vcmp.eq.f32.partialorder %v80893, 1.0 (stack56)
        %v80901 = vmul.f32 inf, %v80891 (stack53)
        %v80903 = vxor.u32 2147483648, %v80891 (stack57)
        %v80906 = vmul.f32 %v80903, %v80891 (stack53)
        %v80908 = vadd.f32 1.0, %v80906 (stack58)
        %v80909 = vlog2.pop %v80908 (stack59)
        %v80910 = vmul.f32 0.6931472, %v80909 (stack60)
        %v80911 = vmul.f32 -0.5, %v80906 (stack61)
        %v80912 = vadd.f32 1.0, %v80911 (stack62)
        %v80913 = vmul.f32 %v80912, %v80906 (stack63)
        %v80914 = vand.u32 2147483647, %v80906 (stack64)
        %vm80915 = vcmp.lt.f32.partialorder %v80914, 0.0004427343 (stack65)
        %v80916 = vsel /*vm=*/%vm80915, /*on_true_vy=*/%v80913, /*on_false_vx=*/%v80910 (stack66)
        %v80917 = vxor.u32 2147483648, %v80916 (stack57)
        %vm80920 = vcmp.lt.f32.partialorder %v80917, 5.0 (stack56)
        %v80925 = vsel /*vm=*/%vm80920, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v80929 = vsel /*vm=*/%vm80920, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v80933 = vsel /*vm=*/%vm80920, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v80937 = vsel /*vm=*/%vm80920, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v80941 = vsel /*vm=*/%vm80920, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v80945 = vsel /*vm=*/%vm80920, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v80949 = vsel /*vm=*/%vm80920, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v80953 = vsel /*vm=*/%vm80920, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v80957 = vsel /*vm=*/%vm80920, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v80961 = vadd.f32 -2.5, %v80917 (stack52)
        %v80963 = vrsqrt.pop %v80917 (stack67)
        %v80964 = vmul.f32 %v80963, %v80917 (stack68)
        %vm80965 = vcmp.eq.f32.partialorder %v80917, inf (stack69)
        %v80966 = vsel /*vm=*/%vm80965, /*on_true_vy=*/%v80917, /*on_false_vx=*/%v80964 (stack70)
        %vm80967 = vcmp.eq.f32.partialorder %v80917, 0.0 (stack71)
        %v80968 = vand.u32 2147483648, %v80917 (stack72)
        %v80969 = vsel /*vm=*/%vm80967, /*on_true_vy=*/%v80968, /*on_false_vx=*/%v80966 (stack73)
        %v80972 = vadd.f32 -3.0, %v80969 (stack52)
        %v80976 = vsel /*vm=*/%vm80920, /*on_true_vy=*/%v80961, /*on_false_vx=*/%v80972 (stack43)
        %v80980 = vmul.f32 %v80976, %v80957 (stack53)
        %v80984 = vadd.f32 %v80980, %v80953 (stack52)
        %v80988 = vmul.f32 %v80984, %v80976 (stack53)
        %v80992 = vadd.f32 %v80988, %v80949 (stack52)
        %v80996 = vmul.f32 %v80992, %v80976 (stack53)
        %v81000 = vadd.f32 %v80996, %v80945 (stack52)
        %v81004 = vmul.f32 %v81000, %v80976 (stack53)
        %v81008 = vadd.f32 %v81004, %v80941 (stack52)
        %v81012 = vmul.f32 %v81008, %v80976 (stack53)
        %v81016 = vadd.f32 %v81012, %v80937 (stack52)
        %v81020 = vmul.f32 %v81016, %v80976 (stack53)
        %v81024 = vadd.f32 %v81020, %v80933 (stack52)
        %v81028 = vmul.f32 %v81024, %v80976 (stack53)
        %v81032 = vadd.f32 %v81028, %v80929 (stack52)
        %v81036 = vmul.f32 %v81032, %v80976 (stack53)
        %v81040 = vadd.f32 %v81036, %v80925 (stack52)
        %v81044 = vmul.f32 %v81040, %v80891 (stack53)
        %v81048 = vsel /*vm=*/%vm80896, /*on_true_vy=*/%v80901, /*on_false_vx=*/%v81044 (stack43)
        %v81052 = vmul.f32 1.4140625, %v81048 (stack53)
        %v81055 = vpack.c.bf16 0.0, %v81052 (stack74)
        %120177 = vst [vmem:[%s280 + $0x254] sm:$0xf] /*vst_source=*/%v81055 (stack75)
        %v81059 = vadd.s32 %v78751, %v2842 (stack39)
        %v81069 = vadd.s32 %v81059, %v415 (stack39)
        %vm81073 = vcmp.lt.u32.totalorder %v81069, %v81059 (stack42)
        %vm81078 = vcmp.lt.u32.totalorder %v81059, %v2842 (stack42)
        %v81083 = vadd.s32 %v78734, %v2829 (stack39)
        %v81087 = vadd.s32 1, %v81083 (stack39)
        %v81091 = vsel /*vm=*/%vm81078, /*on_true_vy=*/%v81087, /*on_false_vx=*/%v81083 (stack43)
        %v81095 = vadd.s32 1, %v81091 (stack39)
        %v81099 = vsel /*vm=*/%vm81073, /*on_true_vy=*/%v81095, /*on_false_vx=*/%v81091 (stack43)
        %v81104 = vadd.s32 %v81099, %v10 (stack39)
        %v81108 = vadd.s32 %v81069, %v9 (stack39)
        %v81112 = vadd.s32 %v81108, %v81104 (stack39)
        %v81114 = vshll.u32 %v81108, 13 (stack44)
        %v81115 = vshrl.u32 %v81108, 19 (stack45)
        %v81116 = vor.u32 %v81115, %v81114 (stack46)
        %v81117 = vxor.u32 %v81116, %v81112 (stack47)
        %v81120 = vadd.s32 %v81117, %v81112 (stack39)
        %v81122 = vshll.u32 %v81117, 15 (stack44)
        %v81123 = vshrl.u32 %v81117, 17 (stack45)
        %v81124 = vor.u32 %v81123, %v81122 (stack46)
        %v81125 = vxor.u32 %v81124, %v81120 (stack47)
        %v81128 = vadd.s32 %v81125, %v81120 (stack39)
        %v81130 = vshll.u32 %v81125, 26 (stack44)
        %v81131 = vshrl.u32 %v81125, 6 (stack45)
        %v81132 = vor.u32 %v81131, %v81130 (stack46)
        %v81133 = vxor.u32 %v81132, %v81128 (stack47)
        %v81136 = vadd.s32 %v81133, %v81128 (stack39)
        %v81140 = vadd.s32 %v81136, %v9 (stack39)
        %v81142 = vshll.u32 %v81133, 6 (stack44)
        %v81143 = vshrl.u32 %v81133, 26 (stack45)
        %v81144 = vor.u32 %v81143, %v81142 (stack46)
        %v81145 = vxor.u32 %v81144, %v81136 (stack47)
        %v81148 = vadd.s32 %v81145, %v8 (stack39)
        %v81152 = vadd.s32 1, %v81148 (stack39)
        %v81156 = vadd.s32 %v81152, %v81140 (stack39)
        %v81158 = vshll.u32 %v81152, 17 (stack44)
        %v81159 = vshrl.u32 %v81152, 15 (stack45)
        %v81160 = vor.u32 %v81159, %v81158 (stack46)
        %v81161 = vxor.u32 %v81160, %v81156 (stack47)
        %v81164 = vadd.s32 %v81161, %v81156 (stack39)
        %v81166 = vshll.u32 %v81161, 29 (stack44)
        %v81167 = vshrl.u32 %v81161, 3 (stack45)
        %v81168 = vor.u32 %v81167, %v81166 (stack46)
        %v81169 = vxor.u32 %v81168, %v81164 (stack47)
        %v81172 = vadd.s32 %v81169, %v81164 (stack39)
        %v81174 = vshll.u32 %v81169, 16 (stack44)
        %v81175 = vshrl.u32 %v81169, 16 (stack45)
        %v81176 = vor.u32 %v81175, %v81174 (stack46)
        %v81177 = vxor.u32 %v81176, %v81172 (stack47)
        %v81180 = vadd.s32 %v81177, %v81172 (stack39)
        %v81184 = vadd.s32 %v81180, %v8 (stack39)
        %v81186 = vshll.u32 %v81177, 24 (stack44)
        %v81187 = vshrl.u32 %v81177, 8 (stack45)
        %v81188 = vor.u32 %v81187, %v81186 (stack46)
        %v81189 = vxor.u32 %v81188, %v81180 (stack47)
        %v81192 = vadd.s32 %v81189, %v10 (stack39)
        %v81196 = vadd.s32 2, %v81192 (stack39)
        %v81200 = vadd.s32 %v81196, %v81184 (stack39)
        %v81202 = vshll.u32 %v81196, 13 (stack44)
        %v81203 = vshrl.u32 %v81196, 19 (stack45)
        %v81204 = vor.u32 %v81203, %v81202 (stack46)
        %v81205 = vxor.u32 %v81204, %v81200 (stack47)
        %v81208 = vadd.s32 %v81205, %v81200 (stack39)
        %v81210 = vshll.u32 %v81205, 15 (stack44)
        %v81211 = vshrl.u32 %v81205, 17 (stack45)
        %v81212 = vor.u32 %v81211, %v81210 (stack46)
        %v81213 = vxor.u32 %v81212, %v81208 (stack47)
        %v81216 = vadd.s32 %v81213, %v81208 (stack39)
        %v81218 = vshll.u32 %v81213, 26 (stack44)
        %v81219 = vshrl.u32 %v81213, 6 (stack45)
        %v81220 = vor.u32 %v81219, %v81218 (stack46)
        %v81221 = vxor.u32 %v81220, %v81216 (stack47)
        %v81224 = vadd.s32 %v81221, %v81216 (stack39)
        %v81228 = vadd.s32 %v81224, %v10 (stack39)
        %v81230 = vshll.u32 %v81221, 6 (stack44)
        %v81231 = vshrl.u32 %v81221, 26 (stack45)
        %v81232 = vor.u32 %v81231, %v81230 (stack46)
        %v81233 = vxor.u32 %v81232, %v81224 (stack47)
        %v81236 = vadd.s32 %v81233, %v9 (stack39)
        %v81240 = vadd.s32 3, %v81236 (stack39)
        %v81244 = vadd.s32 %v81240, %v81228 (stack39)
        %v81246 = vshll.u32 %v81240, 17 (stack44)
        %v81247 = vshrl.u32 %v81240, 15 (stack45)
        %v81248 = vor.u32 %v81247, %v81246 (stack46)
        %v81249 = vxor.u32 %v81248, %v81244 (stack47)
        %v81252 = vadd.s32 %v81249, %v81244 (stack39)
        %v81254 = vshll.u32 %v81249, 29 (stack44)
        %v81255 = vshrl.u32 %v81249, 3 (stack45)
        %v81256 = vor.u32 %v81255, %v81254 (stack46)
        %v81257 = vxor.u32 %v81256, %v81252 (stack47)
        %v81260 = vadd.s32 %v81257, %v81252 (stack39)
        %v81262 = vshll.u32 %v81257, 16 (stack44)
        %v81263 = vshrl.u32 %v81257, 16 (stack45)
        %v81264 = vor.u32 %v81263, %v81262 (stack46)
        %v81265 = vxor.u32 %v81264, %v81260 (stack47)
        %v81268 = vadd.s32 %v81265, %v81260 (stack39)
        %v81272 = vadd.s32 %v81268, %v9 (stack39)
        %v81274 = vshll.u32 %v81265, 24 (stack44)
        %v81275 = vshrl.u32 %v81265, 8 (stack45)
        %v81276 = vor.u32 %v81275, %v81274 (stack46)
        %v81277 = vxor.u32 %v81276, %v81268 (stack47)
        %v81280 = vadd.s32 %v81277, %v8 (stack39)
        %v81284 = vadd.s32 4, %v81280 (stack39)
        %v81288 = vadd.s32 %v81284, %v81272 (stack39)
        %v81290 = vshll.u32 %v81284, 13 (stack44)
        %v81291 = vshrl.u32 %v81284, 19 (stack45)
        %v81292 = vor.u32 %v81291, %v81290 (stack46)
        %v81293 = vxor.u32 %v81292, %v81288 (stack47)
        %v81296 = vadd.s32 %v81293, %v81288 (stack39)
        %v81298 = vshll.u32 %v81293, 15 (stack44)
        %v81299 = vshrl.u32 %v81293, 17 (stack45)
        %v81300 = vor.u32 %v81299, %v81298 (stack46)
        %v81301 = vxor.u32 %v81300, %v81296 (stack47)
        %v81304 = vadd.s32 %v81301, %v81296 (stack39)
        %v81306 = vshll.u32 %v81301, 26 (stack44)
        %v81307 = vshrl.u32 %v81301, 6 (stack45)
        %v81308 = vor.u32 %v81307, %v81306 (stack46)
        %v81309 = vxor.u32 %v81308, %v81304 (stack47)
        %v81312 = vadd.s32 %v81309, %v81304 (stack39)
        %v81316 = vadd.s32 %v81312, %v8 (stack39)
        %v81318 = vshll.u32 %v81309, 6 (stack44)
        %v81319 = vshrl.u32 %v81309, 26 (stack45)
        %v81320 = vor.u32 %v81319, %v81318 (stack46)
        %v81321 = vxor.u32 %v81320, %v81312 (stack47)
        %v81324 = vadd.s32 %v81321, %v10 (stack39)
        %v81328 = vadd.s32 5, %v81324 (stack39)
        %v81330 = vxor.u32 %v81328, %v81316 (stack47)
        %v81331 = vand.u32.u8 255, %v81330 (stack48)
        %v81332 = vand.u32 65535, %v81331 (stack49)
        %v81333 = vshrl.u32 %v81332, 1 (stack50)
        %v81334 = vor.u32 16256, %v81333 (stack46)
        %v81335 = vand.u32.u16 65535, %v81334 (stack51)
        %v120178 = vadd.low.f32.bf16 -1.0, %v81335 (stack52)
        %v81344 = vmul.f32 2.0, %v120178 (stack53)
        %v81348 = vadd.f32 -0.99609375, %v81344 (stack52)
        %v81352 = vmax.f32 %v81348, -0.99609375 (stack54)
        %v81354 = vand.u32 2147483647, %v81352 (stack55)
        %vm81357 = vcmp.eq.f32.partialorder %v81354, 1.0 (stack56)
        %v81362 = vmul.f32 inf, %v81352 (stack53)
        %v81364 = vxor.u32 2147483648, %v81352 (stack57)
        %v81367 = vmul.f32 %v81364, %v81352 (stack53)
        %v81369 = vadd.f32 1.0, %v81367 (stack58)
        %v81370 = vlog2.pop %v81369 (stack59)
        %v81371 = vmul.f32 0.6931472, %v81370 (stack60)
        %v81372 = vmul.f32 -0.5, %v81367 (stack61)
        %v81373 = vadd.f32 1.0, %v81372 (stack62)
        %v81374 = vmul.f32 %v81373, %v81367 (stack63)
        %v81375 = vand.u32 2147483647, %v81367 (stack64)
        %vm81376 = vcmp.lt.f32.partialorder %v81375, 0.0004427343 (stack65)
        %v81377 = vsel /*vm=*/%vm81376, /*on_true_vy=*/%v81374, /*on_false_vx=*/%v81371 (stack66)
        %v81378 = vxor.u32 2147483648, %v81377 (stack57)
        %vm81381 = vcmp.lt.f32.partialorder %v81378, 5.0 (stack56)
        %v81386 = vsel /*vm=*/%vm81381, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v81390 = vsel /*vm=*/%vm81381, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v81394 = vsel /*vm=*/%vm81381, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v81398 = vsel /*vm=*/%vm81381, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v81402 = vsel /*vm=*/%vm81381, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v81406 = vsel /*vm=*/%vm81381, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v81410 = vsel /*vm=*/%vm81381, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v81414 = vsel /*vm=*/%vm81381, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v81418 = vsel /*vm=*/%vm81381, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v81422 = vadd.f32 -2.5, %v81378 (stack52)
        %v81424 = vrsqrt.pop %v81378 (stack67)
        %v81425 = vmul.f32 %v81424, %v81378 (stack68)
        %vm81426 = vcmp.eq.f32.partialorder %v81378, inf (stack69)
        %v81427 = vsel /*vm=*/%vm81426, /*on_true_vy=*/%v81378, /*on_false_vx=*/%v81425 (stack70)
        %vm81428 = vcmp.eq.f32.partialorder %v81378, 0.0 (stack71)
        %v81429 = vand.u32 2147483648, %v81378 (stack72)
        %v81430 = vsel /*vm=*/%vm81428, /*on_true_vy=*/%v81429, /*on_false_vx=*/%v81427 (stack73)
        %v81433 = vadd.f32 -3.0, %v81430 (stack52)
        %v81437 = vsel /*vm=*/%vm81381, /*on_true_vy=*/%v81422, /*on_false_vx=*/%v81433 (stack43)
        %v81441 = vmul.f32 %v81437, %v81418 (stack53)
        %v81445 = vadd.f32 %v81441, %v81414 (stack52)
        %v81449 = vmul.f32 %v81445, %v81437 (stack53)
        %v81453 = vadd.f32 %v81449, %v81410 (stack52)
        %v81457 = vmul.f32 %v81453, %v81437 (stack53)
        %v81461 = vadd.f32 %v81457, %v81406 (stack52)
        %v81465 = vmul.f32 %v81461, %v81437 (stack53)
        %v81469 = vadd.f32 %v81465, %v81402 (stack52)
        %v81473 = vmul.f32 %v81469, %v81437 (stack53)
        %v81477 = vadd.f32 %v81473, %v81398 (stack52)
        %v81481 = vmul.f32 %v81477, %v81437 (stack53)
        %v81485 = vadd.f32 %v81481, %v81394 (stack52)
        %v81489 = vmul.f32 %v81485, %v81437 (stack53)
        %v81493 = vadd.f32 %v81489, %v81390 (stack52)
        %v81497 = vmul.f32 %v81493, %v81437 (stack53)
        %v81501 = vadd.f32 %v81497, %v81386 (stack52)
        %v81505 = vmul.f32 %v81501, %v81352 (stack53)
        %v81509 = vsel /*vm=*/%vm81357, /*on_true_vy=*/%v81362, /*on_false_vx=*/%v81505 (stack43)
        %v81513 = vmul.f32 1.4140625, %v81509 (stack53)
        %v81516 = vpack.c.bf16 0.0, %v81513 (stack74)
        %120179 = vst [vmem:[%s280 + $0x2d4] sm:$0xf] /*vst_source=*/%v81516 (stack75)
        %v81520 = vadd.s32 %v78751, %v3329 (stack39)
        %v81530 = vadd.s32 %v81520, %v415 (stack39)
        %vm81534 = vcmp.lt.u32.totalorder %v81530, %v81520 (stack42)
        %vm81539 = vcmp.lt.u32.totalorder %v81520, %v3329 (stack42)
        %v81544 = vadd.s32 %v78734, %v3316 (stack39)
        %v81548 = vadd.s32 1, %v81544 (stack39)
        %v81552 = vsel /*vm=*/%vm81539, /*on_true_vy=*/%v81548, /*on_false_vx=*/%v81544 (stack43)
        %v81556 = vadd.s32 1, %v81552 (stack39)
        %v81560 = vsel /*vm=*/%vm81534, /*on_true_vy=*/%v81556, /*on_false_vx=*/%v81552 (stack43)
        %v81565 = vadd.s32 %v81560, %v10 (stack39)
        %v81569 = vadd.s32 %v81530, %v9 (stack39)
        %v81573 = vadd.s32 %v81569, %v81565 (stack39)
        %v81575 = vshll.u32 %v81569, 13 (stack44)
        %v81576 = vshrl.u32 %v81569, 19 (stack45)
        %v81577 = vor.u32 %v81576, %v81575 (stack46)
        %v81578 = vxor.u32 %v81577, %v81573 (stack47)
        %v81581 = vadd.s32 %v81578, %v81573 (stack39)
        %v81583 = vshll.u32 %v81578, 15 (stack44)
        %v81584 = vshrl.u32 %v81578, 17 (stack45)
        %v81585 = vor.u32 %v81584, %v81583 (stack46)
        %v81586 = vxor.u32 %v81585, %v81581 (stack47)
        %v81589 = vadd.s32 %v81586, %v81581 (stack39)
        %v81591 = vshll.u32 %v81586, 26 (stack44)
        %v81592 = vshrl.u32 %v81586, 6 (stack45)
        %v81593 = vor.u32 %v81592, %v81591 (stack46)
        %v81594 = vxor.u32 %v81593, %v81589 (stack47)
        %v81597 = vadd.s32 %v81594, %v81589 (stack39)
        %v81601 = vadd.s32 %v81597, %v9 (stack39)
        %v81603 = vshll.u32 %v81594, 6 (stack44)
        %v81604 = vshrl.u32 %v81594, 26 (stack45)
        %v81605 = vor.u32 %v81604, %v81603 (stack46)
        %v81606 = vxor.u32 %v81605, %v81597 (stack47)
        %v81609 = vadd.s32 %v81606, %v8 (stack39)
        %v81613 = vadd.s32 1, %v81609 (stack39)
        %v81617 = vadd.s32 %v81613, %v81601 (stack39)
        %v81619 = vshll.u32 %v81613, 17 (stack44)
        %v81620 = vshrl.u32 %v81613, 15 (stack45)
        %v81621 = vor.u32 %v81620, %v81619 (stack46)
        %v81622 = vxor.u32 %v81621, %v81617 (stack47)
        %v81625 = vadd.s32 %v81622, %v81617 (stack39)
        %v81627 = vshll.u32 %v81622, 29 (stack44)
        %v81628 = vshrl.u32 %v81622, 3 (stack45)
        %v81629 = vor.u32 %v81628, %v81627 (stack46)
        %v81630 = vxor.u32 %v81629, %v81625 (stack47)
        %v81633 = vadd.s32 %v81630, %v81625 (stack39)
        %v81635 = vshll.u32 %v81630, 16 (stack44)
        %v81636 = vshrl.u32 %v81630, 16 (stack45)
        %v81637 = vor.u32 %v81636, %v81635 (stack46)
        %v81638 = vxor.u32 %v81637, %v81633 (stack47)
        %v81641 = vadd.s32 %v81638, %v81633 (stack39)
        %v81645 = vadd.s32 %v81641, %v8 (stack39)
        %v81647 = vshll.u32 %v81638, 24 (stack44)
        %v81648 = vshrl.u32 %v81638, 8 (stack45)
        %v81649 = vor.u32 %v81648, %v81647 (stack46)
        %v81650 = vxor.u32 %v81649, %v81641 (stack47)
        %v81653 = vadd.s32 %v81650, %v10 (stack39)
        %v81657 = vadd.s32 2, %v81653 (stack39)
        %v81661 = vadd.s32 %v81657, %v81645 (stack39)
        %v81663 = vshll.u32 %v81657, 13 (stack44)
        %v81664 = vshrl.u32 %v81657, 19 (stack45)
        %v81665 = vor.u32 %v81664, %v81663 (stack46)
        %v81666 = vxor.u32 %v81665, %v81661 (stack47)
        %v81669 = vadd.s32 %v81666, %v81661 (stack39)
        %v81671 = vshll.u32 %v81666, 15 (stack44)
        %v81672 = vshrl.u32 %v81666, 17 (stack45)
        %v81673 = vor.u32 %v81672, %v81671 (stack46)
        %v81674 = vxor.u32 %v81673, %v81669 (stack47)
        %v81677 = vadd.s32 %v81674, %v81669 (stack39)
        %v81679 = vshll.u32 %v81674, 26 (stack44)
        %v81680 = vshrl.u32 %v81674, 6 (stack45)
        %v81681 = vor.u32 %v81680, %v81679 (stack46)
        %v81682 = vxor.u32 %v81681, %v81677 (stack47)
        %v81685 = vadd.s32 %v81682, %v81677 (stack39)
        %v81689 = vadd.s32 %v81685, %v10 (stack39)
        %v81691 = vshll.u32 %v81682, 6 (stack44)
        %v81692 = vshrl.u32 %v81682, 26 (stack45)
        %v81693 = vor.u32 %v81692, %v81691 (stack46)
        %v81694 = vxor.u32 %v81693, %v81685 (stack47)
        %v81697 = vadd.s32 %v81694, %v9 (stack39)
        %v81701 = vadd.s32 3, %v81697 (stack39)
        %v81705 = vadd.s32 %v81701, %v81689 (stack39)
        %v81707 = vshll.u32 %v81701, 17 (stack44)
        %v81708 = vshrl.u32 %v81701, 15 (stack45)
        %v81709 = vor.u32 %v81708, %v81707 (stack46)
        %v81710 = vxor.u32 %v81709, %v81705 (stack47)
        %v81713 = vadd.s32 %v81710, %v81705 (stack39)
        %v81715 = vshll.u32 %v81710, 29 (stack44)
        %v81716 = vshrl.u32 %v81710, 3 (stack45)
        %v81717 = vor.u32 %v81716, %v81715 (stack46)
        %v81718 = vxor.u32 %v81717, %v81713 (stack47)
        %v81721 = vadd.s32 %v81718, %v81713 (stack39)
        %v81723 = vshll.u32 %v81718, 16 (stack44)
        %v81724 = vshrl.u32 %v81718, 16 (stack45)
        %v81725 = vor.u32 %v81724, %v81723 (stack46)
        %v81726 = vxor.u32 %v81725, %v81721 (stack47)
        %v81729 = vadd.s32 %v81726, %v81721 (stack39)
        %v81733 = vadd.s32 %v81729, %v9 (stack39)
        %v81735 = vshll.u32 %v81726, 24 (stack44)
        %v81736 = vshrl.u32 %v81726, 8 (stack45)
        %v81737 = vor.u32 %v81736, %v81735 (stack46)
        %v81738 = vxor.u32 %v81737, %v81729 (stack47)
        %v81741 = vadd.s32 %v81738, %v8 (stack39)
        %v81745 = vadd.s32 4, %v81741 (stack39)
        %v81749 = vadd.s32 %v81745, %v81733 (stack39)
        %v81751 = vshll.u32 %v81745, 13 (stack44)
        %v81752 = vshrl.u32 %v81745, 19 (stack45)
        %v81753 = vor.u32 %v81752, %v81751 (stack46)
        %v81754 = vxor.u32 %v81753, %v81749 (stack47)
        %v81757 = vadd.s32 %v81754, %v81749 (stack39)
        %v81759 = vshll.u32 %v81754, 15 (stack44)
        %v81760 = vshrl.u32 %v81754, 17 (stack45)
        %v81761 = vor.u32 %v81760, %v81759 (stack46)
        %v81762 = vxor.u32 %v81761, %v81757 (stack47)
        %v81765 = vadd.s32 %v81762, %v81757 (stack39)
        %v81767 = vshll.u32 %v81762, 26 (stack44)
        %v81768 = vshrl.u32 %v81762, 6 (stack45)
        %v81769 = vor.u32 %v81768, %v81767 (stack46)
        %v81770 = vxor.u32 %v81769, %v81765 (stack47)
        %v81773 = vadd.s32 %v81770, %v81765 (stack39)
        %v81777 = vadd.s32 %v81773, %v8 (stack39)
        %v81779 = vshll.u32 %v81770, 6 (stack44)
        %v81780 = vshrl.u32 %v81770, 26 (stack45)
        %v81781 = vor.u32 %v81780, %v81779 (stack46)
        %v81782 = vxor.u32 %v81781, %v81773 (stack47)
        %v81785 = vadd.s32 %v81782, %v10 (stack39)
        %v81789 = vadd.s32 5, %v81785 (stack39)
        %v81791 = vxor.u32 %v81789, %v81777 (stack47)
        %v81792 = vand.u32.u8 255, %v81791 (stack48)
        %v81793 = vand.u32 65535, %v81792 (stack49)
        %v81794 = vshrl.u32 %v81793, 1 (stack50)
        %v81795 = vor.u32 16256, %v81794 (stack46)
        %v81796 = vand.u32.u16 65535, %v81795 (stack51)
        %v120180 = vadd.low.f32.bf16 -1.0, %v81796 (stack52)
        %v81805 = vmul.f32 2.0, %v120180 (stack53)
        %v81809 = vadd.f32 -0.99609375, %v81805 (stack52)
        %v81813 = vmax.f32 %v81809, -0.99609375 (stack54)
        %v81815 = vand.u32 2147483647, %v81813 (stack55)
        %vm81818 = vcmp.eq.f32.partialorder %v81815, 1.0 (stack56)
        %v81823 = vmul.f32 inf, %v81813 (stack53)
        %v81825 = vxor.u32 2147483648, %v81813 (stack57)
        %v81828 = vmul.f32 %v81825, %v81813 (stack53)
        %v81830 = vadd.f32 1.0, %v81828 (stack58)
        %v81831 = vlog2.pop %v81830 (stack59)
        %v81832 = vmul.f32 0.6931472, %v81831 (stack60)
        %v81833 = vmul.f32 -0.5, %v81828 (stack61)
        %v81834 = vadd.f32 1.0, %v81833 (stack62)
        %v81835 = vmul.f32 %v81834, %v81828 (stack63)
        %v81836 = vand.u32 2147483647, %v81828 (stack64)
        %vm81837 = vcmp.lt.f32.partialorder %v81836, 0.0004427343 (stack65)
        %v81838 = vsel /*vm=*/%vm81837, /*on_true_vy=*/%v81835, /*on_false_vx=*/%v81832 (stack66)
        %v81839 = vxor.u32 2147483648, %v81838 (stack57)
        %vm81842 = vcmp.lt.f32.partialorder %v81839, 5.0 (stack56)
        %v81847 = vsel /*vm=*/%vm81842, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v81851 = vsel /*vm=*/%vm81842, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v81855 = vsel /*vm=*/%vm81842, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v81859 = vsel /*vm=*/%vm81842, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v81863 = vsel /*vm=*/%vm81842, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v81867 = vsel /*vm=*/%vm81842, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v81871 = vsel /*vm=*/%vm81842, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v81875 = vsel /*vm=*/%vm81842, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v81879 = vsel /*vm=*/%vm81842, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v81883 = vadd.f32 -2.5, %v81839 (stack52)
        %v81885 = vrsqrt.pop %v81839 (stack67)
        %v81886 = vmul.f32 %v81885, %v81839 (stack68)
        %vm81887 = vcmp.eq.f32.partialorder %v81839, inf (stack69)
        %v81888 = vsel /*vm=*/%vm81887, /*on_true_vy=*/%v81839, /*on_false_vx=*/%v81886 (stack70)
        %vm81889 = vcmp.eq.f32.partialorder %v81839, 0.0 (stack71)
        %v81890 = vand.u32 2147483648, %v81839 (stack72)
        %v81891 = vsel /*vm=*/%vm81889, /*on_true_vy=*/%v81890, /*on_false_vx=*/%v81888 (stack73)
        %v81894 = vadd.f32 -3.0, %v81891 (stack52)
        %v81898 = vsel /*vm=*/%vm81842, /*on_true_vy=*/%v81883, /*on_false_vx=*/%v81894 (stack43)
        %v81902 = vmul.f32 %v81898, %v81879 (stack53)
        %v81906 = vadd.f32 %v81902, %v81875 (stack52)
        %v81910 = vmul.f32 %v81906, %v81898 (stack53)
        %v81914 = vadd.f32 %v81910, %v81871 (stack52)
        %v81918 = vmul.f32 %v81914, %v81898 (stack53)
        %v81922 = vadd.f32 %v81918, %v81867 (stack52)
        %v81926 = vmul.f32 %v81922, %v81898 (stack53)
        %v81930 = vadd.f32 %v81926, %v81863 (stack52)
        %v81934 = vmul.f32 %v81930, %v81898 (stack53)
        %v81938 = vadd.f32 %v81934, %v81859 (stack52)
        %v81942 = vmul.f32 %v81938, %v81898 (stack53)
        %v81946 = vadd.f32 %v81942, %v81855 (stack52)
        %v81950 = vmul.f32 %v81946, %v81898 (stack53)
        %v81954 = vadd.f32 %v81950, %v81851 (stack52)
        %v81958 = vmul.f32 %v81954, %v81898 (stack53)
        %v81962 = vadd.f32 %v81958, %v81847 (stack52)
        %v81966 = vmul.f32 %v81962, %v81813 (stack53)
        %v81970 = vsel /*vm=*/%vm81818, /*on_true_vy=*/%v81823, /*on_false_vx=*/%v81966 (stack43)
        %v81974 = vmul.f32 1.4140625, %v81970 (stack53)
        %v81977 = vpack.c.bf16 0.0, %v81974 (stack74)
        %120181 = vst [vmem:[%s280 + $0x354] sm:$0xf] /*vst_source=*/%v81977 (stack75)
        %v81981 = vadd.s32 %v78751, %v3816 (stack39)
        %v81991 = vadd.s32 %v81981, %v415 (stack39)
        %vm81995 = vcmp.lt.u32.totalorder %v81991, %v81981 (stack42)
        %vm82000 = vcmp.lt.u32.totalorder %v81981, %v3816 (stack42)
        %v82005 = vadd.s32 %v78734, %v3803 (stack39)
        %v82009 = vadd.s32 1, %v82005 (stack39)
        %v82013 = vsel /*vm=*/%vm82000, /*on_true_vy=*/%v82009, /*on_false_vx=*/%v82005 (stack43)
        %v82017 = vadd.s32 1, %v82013 (stack39)
        %v82021 = vsel /*vm=*/%vm81995, /*on_true_vy=*/%v82017, /*on_false_vx=*/%v82013 (stack43)
        %v82026 = vadd.s32 %v82021, %v10 (stack39)
        %v82030 = vadd.s32 %v81991, %v9 (stack39)
        %v82034 = vadd.s32 %v82030, %v82026 (stack39)
        %v82036 = vshll.u32 %v82030, 13 (stack44)
        %v82037 = vshrl.u32 %v82030, 19 (stack45)
        %v82038 = vor.u32 %v82037, %v82036 (stack46)
        %v82039 = vxor.u32 %v82038, %v82034 (stack47)
        %v82042 = vadd.s32 %v82039, %v82034 (stack39)
        %v82044 = vshll.u32 %v82039, 15 (stack44)
        %v82045 = vshrl.u32 %v82039, 17 (stack45)
        %v82046 = vor.u32 %v82045, %v82044 (stack46)
        %v82047 = vxor.u32 %v82046, %v82042 (stack47)
        %v82050 = vadd.s32 %v82047, %v82042 (stack39)
        %v82052 = vshll.u32 %v82047, 26 (stack44)
        %v82053 = vshrl.u32 %v82047, 6 (stack45)
        %v82054 = vor.u32 %v82053, %v82052 (stack46)
        %v82055 = vxor.u32 %v82054, %v82050 (stack47)
        %v82058 = vadd.s32 %v82055, %v82050 (stack39)
        %v82062 = vadd.s32 %v82058, %v9 (stack39)
        %v82064 = vshll.u32 %v82055, 6 (stack44)
        %v82065 = vshrl.u32 %v82055, 26 (stack45)
        %v82066 = vor.u32 %v82065, %v82064 (stack46)
        %v82067 = vxor.u32 %v82066, %v82058 (stack47)
        %v82070 = vadd.s32 %v82067, %v8 (stack39)
        %v82074 = vadd.s32 1, %v82070 (stack39)
        %v82078 = vadd.s32 %v82074, %v82062 (stack39)
        %v82080 = vshll.u32 %v82074, 17 (stack44)
        %v82081 = vshrl.u32 %v82074, 15 (stack45)
        %v82082 = vor.u32 %v82081, %v82080 (stack46)
        %v82083 = vxor.u32 %v82082, %v82078 (stack47)
        %v82086 = vadd.s32 %v82083, %v82078 (stack39)
        %v82088 = vshll.u32 %v82083, 29 (stack44)
        %v82089 = vshrl.u32 %v82083, 3 (stack45)
        %v82090 = vor.u32 %v82089, %v82088 (stack46)
        %v82091 = vxor.u32 %v82090, %v82086 (stack47)
        %v82094 = vadd.s32 %v82091, %v82086 (stack39)
        %v82096 = vshll.u32 %v82091, 16 (stack44)
        %v82097 = vshrl.u32 %v82091, 16 (stack45)
        %v82098 = vor.u32 %v82097, %v82096 (stack46)
        %v82099 = vxor.u32 %v82098, %v82094 (stack47)
        %v82102 = vadd.s32 %v82099, %v82094 (stack39)
        %v82106 = vadd.s32 %v82102, %v8 (stack39)
        %v82108 = vshll.u32 %v82099, 24 (stack44)
        %v82109 = vshrl.u32 %v82099, 8 (stack45)
        %v82110 = vor.u32 %v82109, %v82108 (stack46)
        %v82111 = vxor.u32 %v82110, %v82102 (stack47)
        %v82114 = vadd.s32 %v82111, %v10 (stack39)
        %v82118 = vadd.s32 2, %v82114 (stack39)
        %v82122 = vadd.s32 %v82118, %v82106 (stack39)
        %v82124 = vshll.u32 %v82118, 13 (stack44)
        %v82125 = vshrl.u32 %v82118, 19 (stack45)
        %v82126 = vor.u32 %v82125, %v82124 (stack46)
        %v82127 = vxor.u32 %v82126, %v82122 (stack47)
        %v82130 = vadd.s32 %v82127, %v82122 (stack39)
        %v82132 = vshll.u32 %v82127, 15 (stack44)
        %v82133 = vshrl.u32 %v82127, 17 (stack45)
        %v82134 = vor.u32 %v82133, %v82132 (stack46)
        %v82135 = vxor.u32 %v82134, %v82130 (stack47)
        %v82138 = vadd.s32 %v82135, %v82130 (stack39)
        %v82140 = vshll.u32 %v82135, 26 (stack44)
        %v82141 = vshrl.u32 %v82135, 6 (stack45)
        %v82142 = vor.u32 %v82141, %v82140 (stack46)
        %v82143 = vxor.u32 %v82142, %v82138 (stack47)
        %v82146 = vadd.s32 %v82143, %v82138 (stack39)
        %v82150 = vadd.s32 %v82146, %v10 (stack39)
        %v82152 = vshll.u32 %v82143, 6 (stack44)
        %v82153 = vshrl.u32 %v82143, 26 (stack45)
        %v82154 = vor.u32 %v82153, %v82152 (stack46)
        %v82155 = vxor.u32 %v82154, %v82146 (stack47)
        %v82158 = vadd.s32 %v82155, %v9 (stack39)
        %v82162 = vadd.s32 3, %v82158 (stack39)
        %v82166 = vadd.s32 %v82162, %v82150 (stack39)
        %v82168 = vshll.u32 %v82162, 17 (stack44)
        %v82169 = vshrl.u32 %v82162, 15 (stack45)
        %v82170 = vor.u32 %v82169, %v82168 (stack46)
        %v82171 = vxor.u32 %v82170, %v82166 (stack47)
        %v82174 = vadd.s32 %v82171, %v82166 (stack39)
        %v82176 = vshll.u32 %v82171, 29 (stack44)
        %v82177 = vshrl.u32 %v82171, 3 (stack45)
        %v82178 = vor.u32 %v82177, %v82176 (stack46)
        %v82179 = vxor.u32 %v82178, %v82174 (stack47)
        %v82182 = vadd.s32 %v82179, %v82174 (stack39)
        %v82184 = vshll.u32 %v82179, 16 (stack44)
        %v82185 = vshrl.u32 %v82179, 16 (stack45)
        %v82186 = vor.u32 %v82185, %v82184 (stack46)
        %v82187 = vxor.u32 %v82186, %v82182 (stack47)
        %v82190 = vadd.s32 %v82187, %v82182 (stack39)
        %v82194 = vadd.s32 %v82190, %v9 (stack39)
        %v82196 = vshll.u32 %v82187, 24 (stack44)
        %v82197 = vshrl.u32 %v82187, 8 (stack45)
        %v82198 = vor.u32 %v82197, %v82196 (stack46)
        %v82199 = vxor.u32 %v82198, %v82190 (stack47)
        %v82202 = vadd.s32 %v82199, %v8 (stack39)
        %v82206 = vadd.s32 4, %v82202 (stack39)
        %v82210 = vadd.s32 %v82206, %v82194 (stack39)
        %v82212 = vshll.u32 %v82206, 13 (stack44)
        %v82213 = vshrl.u32 %v82206, 19 (stack45)
        %v82214 = vor.u32 %v82213, %v82212 (stack46)
        %v82215 = vxor.u32 %v82214, %v82210 (stack47)
        %v82218 = vadd.s32 %v82215, %v82210 (stack39)
        %v82220 = vshll.u32 %v82215, 15 (stack44)
        %v82221 = vshrl.u32 %v82215, 17 (stack45)
        %v82222 = vor.u32 %v82221, %v82220 (stack46)
        %v82223 = vxor.u32 %v82222, %v82218 (stack47)
        %v82226 = vadd.s32 %v82223, %v82218 (stack39)
        %v82228 = vshll.u32 %v82223, 26 (stack44)
        %v82229 = vshrl.u32 %v82223, 6 (stack45)
        %v82230 = vor.u32 %v82229, %v82228 (stack46)
        %v82231 = vxor.u32 %v82230, %v82226 (stack47)
        %v82234 = vadd.s32 %v82231, %v82226 (stack39)
        %v82238 = vadd.s32 %v82234, %v8 (stack39)
        %v82240 = vshll.u32 %v82231, 6 (stack44)
        %v82241 = vshrl.u32 %v82231, 26 (stack45)
        %v82242 = vor.u32 %v82241, %v82240 (stack46)
        %v82243 = vxor.u32 %v82242, %v82234 (stack47)
        %v82246 = vadd.s32 %v82243, %v10 (stack39)
        %v82250 = vadd.s32 5, %v82246 (stack39)
        %v82252 = vxor.u32 %v82250, %v82238 (stack47)
        %v82253 = vand.u32.u8 255, %v82252 (stack48)
        %v82254 = vand.u32 65535, %v82253 (stack49)
        %v82255 = vshrl.u32 %v82254, 1 (stack50)
        %v82256 = vor.u32 16256, %v82255 (stack46)
        %v82257 = vand.u32.u16 65535, %v82256 (stack51)
        %v120182 = vadd.low.f32.bf16 -1.0, %v82257 (stack52)
        %v82266 = vmul.f32 2.0, %v120182 (stack53)
        %v82270 = vadd.f32 -0.99609375, %v82266 (stack52)
        %v82274 = vmax.f32 %v82270, -0.99609375 (stack54)
        %v82276 = vand.u32 2147483647, %v82274 (stack55)
        %vm82279 = vcmp.eq.f32.partialorder %v82276, 1.0 (stack56)
        %v82284 = vmul.f32 inf, %v82274 (stack53)
        %v82286 = vxor.u32 2147483648, %v82274 (stack57)
        %v82289 = vmul.f32 %v82286, %v82274 (stack53)
        %v82291 = vadd.f32 1.0, %v82289 (stack58)
        %v82292 = vlog2.pop %v82291 (stack59)
        %v82293 = vmul.f32 0.6931472, %v82292 (stack60)
        %v82294 = vmul.f32 -0.5, %v82289 (stack61)
        %v82295 = vadd.f32 1.0, %v82294 (stack62)
        %v82296 = vmul.f32 %v82295, %v82289 (stack63)
        %v82297 = vand.u32 2147483647, %v82289 (stack64)
        %vm82298 = vcmp.lt.f32.partialorder %v82297, 0.0004427343 (stack65)
        %v82299 = vsel /*vm=*/%vm82298, /*on_true_vy=*/%v82296, /*on_false_vx=*/%v82293 (stack66)
        %v82300 = vxor.u32 2147483648, %v82299 (stack57)
        %vm82303 = vcmp.lt.f32.partialorder %v82300, 5.0 (stack56)
        %v82308 = vsel /*vm=*/%vm82303, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v82312 = vsel /*vm=*/%vm82303, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v82316 = vsel /*vm=*/%vm82303, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v82320 = vsel /*vm=*/%vm82303, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v82324 = vsel /*vm=*/%vm82303, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v82328 = vsel /*vm=*/%vm82303, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v82332 = vsel /*vm=*/%vm82303, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v82336 = vsel /*vm=*/%vm82303, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v82340 = vsel /*vm=*/%vm82303, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v82344 = vadd.f32 -2.5, %v82300 (stack52)
        %v82346 = vrsqrt.pop %v82300 (stack67)
        %v82347 = vmul.f32 %v82346, %v82300 (stack68)
        %vm82348 = vcmp.eq.f32.partialorder %v82300, inf (stack69)
        %v82349 = vsel /*vm=*/%vm82348, /*on_true_vy=*/%v82300, /*on_false_vx=*/%v82347 (stack70)
        %vm82350 = vcmp.eq.f32.partialorder %v82300, 0.0 (stack71)
        %v82351 = vand.u32 2147483648, %v82300 (stack72)
        %v82352 = vsel /*vm=*/%vm82350, /*on_true_vy=*/%v82351, /*on_false_vx=*/%v82349 (stack73)
        %v82355 = vadd.f32 -3.0, %v82352 (stack52)
        %v82359 = vsel /*vm=*/%vm82303, /*on_true_vy=*/%v82344, /*on_false_vx=*/%v82355 (stack43)
        %v82363 = vmul.f32 %v82359, %v82340 (stack53)
        %v82367 = vadd.f32 %v82363, %v82336 (stack52)
        %v82371 = vmul.f32 %v82367, %v82359 (stack53)
        %v82375 = vadd.f32 %v82371, %v82332 (stack52)
        %v82379 = vmul.f32 %v82375, %v82359 (stack53)
        %v82383 = vadd.f32 %v82379, %v82328 (stack52)
        %v82387 = vmul.f32 %v82383, %v82359 (stack53)
        %v82391 = vadd.f32 %v82387, %v82324 (stack52)
        %v82395 = vmul.f32 %v82391, %v82359 (stack53)
        %v82399 = vadd.f32 %v82395, %v82320 (stack52)
        %v82403 = vmul.f32 %v82399, %v82359 (stack53)
        %v82407 = vadd.f32 %v82403, %v82316 (stack52)
        %v82411 = vmul.f32 %v82407, %v82359 (stack53)
        %v82415 = vadd.f32 %v82411, %v82312 (stack52)
        %v82419 = vmul.f32 %v82415, %v82359 (stack53)
        %v82423 = vadd.f32 %v82419, %v82308 (stack52)
        %v82427 = vmul.f32 %v82423, %v82274 (stack53)
        %v82431 = vsel /*vm=*/%vm82279, /*on_true_vy=*/%v82284, /*on_false_vx=*/%v82427 (stack43)
        %v82435 = vmul.f32 1.4140625, %v82431 (stack53)
        %v82438 = vpack.c.bf16 0.0, %v82435 (stack74)
        %120183 = vst [vmem:[%s280 + $0x3d4] sm:$0xf] /*vst_source=*/%v82438 (stack75)
        %s82440 = sadd.s32 176, %s120390 (stack76)
        %s82441 = sshrl.u32 %s82440, 10 (stack23)
        %p120184 = scmp.gt.s32.totalorder %s82441, 1 (stack24)
        %s82443 = scalar_select /*predicate=*/%p120184, /*on_true=*/1, /*on_false=*/%s82441 (stack25)
        %s82444 = sand.u32 1023, %s82440 /* smod.u32 w/div 1024 */ (stack26)
        %s82445 = sshrl.u32 %s82444, 7 (stack27)
        %s82446 = sand.u32 127, %s82444 /* smod.u32 w/div 128 */ (stack28)
        %s120185 = sshll.u32 %s82443, 3 (stack29)
        %s82448 = scalar_lea.vmem %s3, %s120185 (stack30)
        %s82450 = scalar_lea.vmem %s82448, %s82445 (stack31)
        %v82451 = vld [vmem:[%s82450] ss:$0 sm:$0xff] (stack32)
        %s82452 = sand.u32 255, %s82446 (stack33)
        %s82454 = sor.u32 256, %s82452 (stack34)
        %82455 = vbcast.lane.b32.xlu0 %v82451, %s82454 (stack35)
        %v82456 = vpop.permute.xlu0 %82455 (stack36)
        %s82465 = scalar_lea.vmem %s5, %s120185 (stack30)
        %s82467 = scalar_lea.vmem %s82465, %s82445 (stack31)
        %v82468 = vld [vmem:[%s82467] ss:$0 sm:$0xff] (stack32)
        %82472 = vbcast.lane.b32.xlu0 %v82468, %s82454 (stack35)
        %v82473 = vpop.permute.xlu0 %82472 (stack36)
        %v82476 = vadd.s32 %v82473, %v408 (stack39)
        %v82486 = vadd.s32 %v82476, %v415 (stack39)
        %vm82490 = vcmp.lt.u32.totalorder %v82486, %v82476 (stack42)
        %vm82495 = vcmp.lt.u32.totalorder %v82476, %v408 (stack42)
        %v82500 = vadd.s32 %v82456, %v380 (stack39)
        %v82504 = vadd.s32 1, %v82500 (stack39)
        %v82508 = vsel /*vm=*/%vm82495, /*on_true_vy=*/%v82504, /*on_false_vx=*/%v82500 (stack43)
        %v82512 = vadd.s32 1, %v82508 (stack39)
        %v82516 = vsel /*vm=*/%vm82490, /*on_true_vy=*/%v82512, /*on_false_vx=*/%v82508 (stack43)
        %v82521 = vadd.s32 %v82516, %v10 (stack39)
        %v82525 = vadd.s32 %v82486, %v9 (stack39)
        %v82529 = vadd.s32 %v82525, %v82521 (stack39)
        %v82531 = vshll.u32 %v82525, 13 (stack44)
        %v82532 = vshrl.u32 %v82525, 19 (stack45)
        %v82533 = vor.u32 %v82532, %v82531 (stack46)
        %v82534 = vxor.u32 %v82533, %v82529 (stack47)
        %v82537 = vadd.s32 %v82534, %v82529 (stack39)
        %v82539 = vshll.u32 %v82534, 15 (stack44)
        %v82540 = vshrl.u32 %v82534, 17 (stack45)
        %v82541 = vor.u32 %v82540, %v82539 (stack46)
        %v82542 = vxor.u32 %v82541, %v82537 (stack47)
        %v82545 = vadd.s32 %v82542, %v82537 (stack39)
        %v82547 = vshll.u32 %v82542, 26 (stack44)
        %v82548 = vshrl.u32 %v82542, 6 (stack45)
        %v82549 = vor.u32 %v82548, %v82547 (stack46)
        %v82550 = vxor.u32 %v82549, %v82545 (stack47)
        %v82553 = vadd.s32 %v82550, %v82545 (stack39)
        %v82557 = vadd.s32 %v82553, %v9 (stack39)
        %v82559 = vshll.u32 %v82550, 6 (stack44)
        %v82560 = vshrl.u32 %v82550, 26 (stack45)
        %v82561 = vor.u32 %v82560, %v82559 (stack46)
        %v82562 = vxor.u32 %v82561, %v82553 (stack47)
        %v82565 = vadd.s32 %v82562, %v8 (stack39)
        %v82569 = vadd.s32 1, %v82565 (stack39)
        %v82573 = vadd.s32 %v82569, %v82557 (stack39)
        %v82575 = vshll.u32 %v82569, 17 (stack44)
        %v82576 = vshrl.u32 %v82569, 15 (stack45)
        %v82577 = vor.u32 %v82576, %v82575 (stack46)
        %v82578 = vxor.u32 %v82577, %v82573 (stack47)
        %v82581 = vadd.s32 %v82578, %v82573 (stack39)
        %v82583 = vshll.u32 %v82578, 29 (stack44)
        %v82584 = vshrl.u32 %v82578, 3 (stack45)
        %v82585 = vor.u32 %v82584, %v82583 (stack46)
        %v82586 = vxor.u32 %v82585, %v82581 (stack47)
        %v82589 = vadd.s32 %v82586, %v82581 (stack39)
        %v82591 = vshll.u32 %v82586, 16 (stack44)
        %v82592 = vshrl.u32 %v82586, 16 (stack45)
        %v82593 = vor.u32 %v82592, %v82591 (stack46)
        %v82594 = vxor.u32 %v82593, %v82589 (stack47)
        %v82597 = vadd.s32 %v82594, %v82589 (stack39)
        %v82601 = vadd.s32 %v82597, %v8 (stack39)
        %v82603 = vshll.u32 %v82594, 24 (stack44)
        %v82604 = vshrl.u32 %v82594, 8 (stack45)
        %v82605 = vor.u32 %v82604, %v82603 (stack46)
        %v82606 = vxor.u32 %v82605, %v82597 (stack47)
        %v82609 = vadd.s32 %v82606, %v10 (stack39)
        %v82613 = vadd.s32 2, %v82609 (stack39)
        %v82617 = vadd.s32 %v82613, %v82601 (stack39)
        %v82619 = vshll.u32 %v82613, 13 (stack44)
        %v82620 = vshrl.u32 %v82613, 19 (stack45)
        %v82621 = vor.u32 %v82620, %v82619 (stack46)
        %v82622 = vxor.u32 %v82621, %v82617 (stack47)
        %v82625 = vadd.s32 %v82622, %v82617 (stack39)
        %v82627 = vshll.u32 %v82622, 15 (stack44)
        %v82628 = vshrl.u32 %v82622, 17 (stack45)
        %v82629 = vor.u32 %v82628, %v82627 (stack46)
        %v82630 = vxor.u32 %v82629, %v82625 (stack47)
        %v82633 = vadd.s32 %v82630, %v82625 (stack39)
        %v82635 = vshll.u32 %v82630, 26 (stack44)
        %v82636 = vshrl.u32 %v82630, 6 (stack45)
        %v82637 = vor.u32 %v82636, %v82635 (stack46)
        %v82638 = vxor.u32 %v82637, %v82633 (stack47)
        %v82641 = vadd.s32 %v82638, %v82633 (stack39)
        %v82645 = vadd.s32 %v82641, %v10 (stack39)
        %v82647 = vshll.u32 %v82638, 6 (stack44)
        %v82648 = vshrl.u32 %v82638, 26 (stack45)
        %v82649 = vor.u32 %v82648, %v82647 (stack46)
        %v82650 = vxor.u32 %v82649, %v82641 (stack47)
        %v82653 = vadd.s32 %v82650, %v9 (stack39)
        %v82657 = vadd.s32 3, %v82653 (stack39)
        %v82661 = vadd.s32 %v82657, %v82645 (stack39)
        %v82663 = vshll.u32 %v82657, 17 (stack44)
        %v82664 = vshrl.u32 %v82657, 15 (stack45)
        %v82665 = vor.u32 %v82664, %v82663 (stack46)
        %v82666 = vxor.u32 %v82665, %v82661 (stack47)
        %v82669 = vadd.s32 %v82666, %v82661 (stack39)
        %v82671 = vshll.u32 %v82666, 29 (stack44)
        %v82672 = vshrl.u32 %v82666, 3 (stack45)
        %v82673 = vor.u32 %v82672, %v82671 (stack46)
        %v82674 = vxor.u32 %v82673, %v82669 (stack47)
        %v82677 = vadd.s32 %v82674, %v82669 (stack39)
        %v82679 = vshll.u32 %v82674, 16 (stack44)
        %v82680 = vshrl.u32 %v82674, 16 (stack45)
        %v82681 = vor.u32 %v82680, %v82679 (stack46)
        %v82682 = vxor.u32 %v82681, %v82677 (stack47)
        %v82685 = vadd.s32 %v82682, %v82677 (stack39)
        %v82689 = vadd.s32 %v82685, %v9 (stack39)
        %v82691 = vshll.u32 %v82682, 24 (stack44)
        %v82692 = vshrl.u32 %v82682, 8 (stack45)
        %v82693 = vor.u32 %v82692, %v82691 (stack46)
        %v82694 = vxor.u32 %v82693, %v82685 (stack47)
        %v82697 = vadd.s32 %v82694, %v8 (stack39)
        %v82701 = vadd.s32 4, %v82697 (stack39)
        %v82705 = vadd.s32 %v82701, %v82689 (stack39)
        %v82707 = vshll.u32 %v82701, 13 (stack44)
        %v82708 = vshrl.u32 %v82701, 19 (stack45)
        %v82709 = vor.u32 %v82708, %v82707 (stack46)
        %v82710 = vxor.u32 %v82709, %v82705 (stack47)
        %v82713 = vadd.s32 %v82710, %v82705 (stack39)
        %v82715 = vshll.u32 %v82710, 15 (stack44)
        %v82716 = vshrl.u32 %v82710, 17 (stack45)
        %v82717 = vor.u32 %v82716, %v82715 (stack46)
        %v82718 = vxor.u32 %v82717, %v82713 (stack47)
        %v82721 = vadd.s32 %v82718, %v82713 (stack39)
        %v82723 = vshll.u32 %v82718, 26 (stack44)
        %v82724 = vshrl.u32 %v82718, 6 (stack45)
        %v82725 = vor.u32 %v82724, %v82723 (stack46)
        %v82726 = vxor.u32 %v82725, %v82721 (stack47)
        %v82729 = vadd.s32 %v82726, %v82721 (stack39)
        %v82733 = vadd.s32 %v82729, %v8 (stack39)
        %v82735 = vshll.u32 %v82726, 6 (stack44)
        %v82736 = vshrl.u32 %v82726, 26 (stack45)
        %v82737 = vor.u32 %v82736, %v82735 (stack46)
        %v82738 = vxor.u32 %v82737, %v82729 (stack47)
        %v82741 = vadd.s32 %v82738, %v10 (stack39)
        %v82745 = vadd.s32 5, %v82741 (stack39)
        %v82747 = vxor.u32 %v82745, %v82733 (stack47)
        %v82748 = vand.u32.u8 255, %v82747 (stack48)
        %v82749 = vand.u32 65535, %v82748 (stack49)
        %v82750 = vshrl.u32 %v82749, 1 (stack50)
        %v82751 = vor.u32 16256, %v82750 (stack46)
        %v82752 = vand.u32.u16 65535, %v82751 (stack51)
        %v120188 = vadd.low.f32.bf16 -1.0, %v82752 (stack52)
        %v82761 = vmul.f32 2.0, %v120188 (stack53)
        %v82765 = vadd.f32 -0.99609375, %v82761 (stack52)
        %v82769 = vmax.f32 %v82765, -0.99609375 (stack54)
        %v82771 = vand.u32 2147483647, %v82769 (stack55)
        %vm82774 = vcmp.eq.f32.partialorder %v82771, 1.0 (stack56)
        %v82779 = vmul.f32 inf, %v82769 (stack53)
        %v82781 = vxor.u32 2147483648, %v82769 (stack57)
        %v82784 = vmul.f32 %v82781, %v82769 (stack53)
        %v82786 = vadd.f32 1.0, %v82784 (stack58)
        %v82787 = vlog2.pop %v82786 (stack59)
        %v82788 = vmul.f32 0.6931472, %v82787 (stack60)
        %v82789 = vmul.f32 -0.5, %v82784 (stack61)
        %v82790 = vadd.f32 1.0, %v82789 (stack62)
        %v82791 = vmul.f32 %v82790, %v82784 (stack63)
        %v82792 = vand.u32 2147483647, %v82784 (stack64)
        %vm82793 = vcmp.lt.f32.partialorder %v82792, 0.0004427343 (stack65)
        %v82794 = vsel /*vm=*/%vm82793, /*on_true_vy=*/%v82791, /*on_false_vx=*/%v82788 (stack66)
        %v82795 = vxor.u32 2147483648, %v82794 (stack57)
        %vm82798 = vcmp.lt.f32.partialorder %v82795, 5.0 (stack56)
        %v82803 = vsel /*vm=*/%vm82798, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v82807 = vsel /*vm=*/%vm82798, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v82811 = vsel /*vm=*/%vm82798, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v82815 = vsel /*vm=*/%vm82798, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v82819 = vsel /*vm=*/%vm82798, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v82823 = vsel /*vm=*/%vm82798, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v82827 = vsel /*vm=*/%vm82798, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v82831 = vsel /*vm=*/%vm82798, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v82835 = vsel /*vm=*/%vm82798, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v82839 = vadd.f32 -2.5, %v82795 (stack52)
        %v82841 = vrsqrt.pop %v82795 (stack67)
        %v82842 = vmul.f32 %v82841, %v82795 (stack68)
        %vm82843 = vcmp.eq.f32.partialorder %v82795, inf (stack69)
        %v82844 = vsel /*vm=*/%vm82843, /*on_true_vy=*/%v82795, /*on_false_vx=*/%v82842 (stack70)
        %vm82845 = vcmp.eq.f32.partialorder %v82795, 0.0 (stack71)
        %v82846 = vand.u32 2147483648, %v82795 (stack72)
        %v82847 = vsel /*vm=*/%vm82845, /*on_true_vy=*/%v82846, /*on_false_vx=*/%v82844 (stack73)
        %v82850 = vadd.f32 -3.0, %v82847 (stack52)
        %v82854 = vsel /*vm=*/%vm82798, /*on_true_vy=*/%v82839, /*on_false_vx=*/%v82850 (stack43)
        %v82858 = vmul.f32 %v82854, %v82835 (stack53)
        %v82862 = vadd.f32 %v82858, %v82831 (stack52)
        %v82866 = vmul.f32 %v82862, %v82854 (stack53)
        %v82870 = vadd.f32 %v82866, %v82827 (stack52)
        %v82874 = vmul.f32 %v82870, %v82854 (stack53)
        %v82878 = vadd.f32 %v82874, %v82823 (stack52)
        %v82882 = vmul.f32 %v82878, %v82854 (stack53)
        %v82886 = vadd.f32 %v82882, %v82819 (stack52)
        %v82890 = vmul.f32 %v82886, %v82854 (stack53)
        %v82894 = vadd.f32 %v82890, %v82815 (stack52)
        %v82898 = vmul.f32 %v82894, %v82854 (stack53)
        %v82902 = vadd.f32 %v82898, %v82811 (stack52)
        %v82906 = vmul.f32 %v82902, %v82854 (stack53)
        %v82910 = vadd.f32 %v82906, %v82807 (stack52)
        %v82914 = vmul.f32 %v82910, %v82854 (stack53)
        %v82918 = vadd.f32 %v82914, %v82803 (stack52)
        %v82922 = vmul.f32 %v82918, %v82769 (stack53)
        %v82926 = vsel /*vm=*/%vm82774, /*on_true_vy=*/%v82779, /*on_false_vx=*/%v82922 (stack43)
        %v82930 = vmul.f32 1.4140625, %v82926 (stack53)
        %v82933 = vpack.c.bf16 0.0, %v82930 (stack74)
        %120189 = vst [vmem:[%s280 + $0x58] sm:$0xf] /*vst_source=*/%v82933 (stack75)
        %v82937 = vadd.s32 %v82473, %v894 (stack39)
        %v82947 = vadd.s32 %v82937, %v415 (stack39)
        %vm82951 = vcmp.lt.u32.totalorder %v82947, %v82937 (stack42)
        %vm82956 = vcmp.lt.u32.totalorder %v82937, %v894 (stack42)
        %v82961 = vadd.s32 %v82456, %v881 (stack39)
        %v82965 = vadd.s32 1, %v82961 (stack39)
        %v82969 = vsel /*vm=*/%vm82956, /*on_true_vy=*/%v82965, /*on_false_vx=*/%v82961 (stack43)
        %v82973 = vadd.s32 1, %v82969 (stack39)
        %v82977 = vsel /*vm=*/%vm82951, /*on_true_vy=*/%v82973, /*on_false_vx=*/%v82969 (stack43)
        %v82982 = vadd.s32 %v82977, %v10 (stack39)
        %v82986 = vadd.s32 %v82947, %v9 (stack39)
        %v82990 = vadd.s32 %v82986, %v82982 (stack39)
        %v82992 = vshll.u32 %v82986, 13 (stack44)
        %v82993 = vshrl.u32 %v82986, 19 (stack45)
        %v82994 = vor.u32 %v82993, %v82992 (stack46)
        %v82995 = vxor.u32 %v82994, %v82990 (stack47)
        %v82998 = vadd.s32 %v82995, %v82990 (stack39)
        %v83000 = vshll.u32 %v82995, 15 (stack44)
        %v83001 = vshrl.u32 %v82995, 17 (stack45)
        %v83002 = vor.u32 %v83001, %v83000 (stack46)
        %v83003 = vxor.u32 %v83002, %v82998 (stack47)
        %v83006 = vadd.s32 %v83003, %v82998 (stack39)
        %v83008 = vshll.u32 %v83003, 26 (stack44)
        %v83009 = vshrl.u32 %v83003, 6 (stack45)
        %v83010 = vor.u32 %v83009, %v83008 (stack46)
        %v83011 = vxor.u32 %v83010, %v83006 (stack47)
        %v83014 = vadd.s32 %v83011, %v83006 (stack39)
        %v83018 = vadd.s32 %v83014, %v9 (stack39)
        %v83020 = vshll.u32 %v83011, 6 (stack44)
        %v83021 = vshrl.u32 %v83011, 26 (stack45)
        %v83022 = vor.u32 %v83021, %v83020 (stack46)
        %v83023 = vxor.u32 %v83022, %v83014 (stack47)
        %v83026 = vadd.s32 %v83023, %v8 (stack39)
        %v83030 = vadd.s32 1, %v83026 (stack39)
        %v83034 = vadd.s32 %v83030, %v83018 (stack39)
        %v83036 = vshll.u32 %v83030, 17 (stack44)
        %v83037 = vshrl.u32 %v83030, 15 (stack45)
        %v83038 = vor.u32 %v83037, %v83036 (stack46)
        %v83039 = vxor.u32 %v83038, %v83034 (stack47)
        %v83042 = vadd.s32 %v83039, %v83034 (stack39)
        %v83044 = vshll.u32 %v83039, 29 (stack44)
        %v83045 = vshrl.u32 %v83039, 3 (stack45)
        %v83046 = vor.u32 %v83045, %v83044 (stack46)
        %v83047 = vxor.u32 %v83046, %v83042 (stack47)
        %v83050 = vadd.s32 %v83047, %v83042 (stack39)
        %v83052 = vshll.u32 %v83047, 16 (stack44)
        %v83053 = vshrl.u32 %v83047, 16 (stack45)
        %v83054 = vor.u32 %v83053, %v83052 (stack46)
        %v83055 = vxor.u32 %v83054, %v83050 (stack47)
        %v83058 = vadd.s32 %v83055, %v83050 (stack39)
        %v83062 = vadd.s32 %v83058, %v8 (stack39)
        %v83064 = vshll.u32 %v83055, 24 (stack44)
        %v83065 = vshrl.u32 %v83055, 8 (stack45)
        %v83066 = vor.u32 %v83065, %v83064 (stack46)
        %v83067 = vxor.u32 %v83066, %v83058 (stack47)
        %v83070 = vadd.s32 %v83067, %v10 (stack39)
        %v83074 = vadd.s32 2, %v83070 (stack39)
        %v83078 = vadd.s32 %v83074, %v83062 (stack39)
        %v83080 = vshll.u32 %v83074, 13 (stack44)
        %v83081 = vshrl.u32 %v83074, 19 (stack45)
        %v83082 = vor.u32 %v83081, %v83080 (stack46)
        %v83083 = vxor.u32 %v83082, %v83078 (stack47)
        %v83086 = vadd.s32 %v83083, %v83078 (stack39)
        %v83088 = vshll.u32 %v83083, 15 (stack44)
        %v83089 = vshrl.u32 %v83083, 17 (stack45)
        %v83090 = vor.u32 %v83089, %v83088 (stack46)
        %v83091 = vxor.u32 %v83090, %v83086 (stack47)
        %v83094 = vadd.s32 %v83091, %v83086 (stack39)
        %v83096 = vshll.u32 %v83091, 26 (stack44)
        %v83097 = vshrl.u32 %v83091, 6 (stack45)
        %v83098 = vor.u32 %v83097, %v83096 (stack46)
        %v83099 = vxor.u32 %v83098, %v83094 (stack47)
        %v83102 = vadd.s32 %v83099, %v83094 (stack39)
        %v83106 = vadd.s32 %v83102, %v10 (stack39)
        %v83108 = vshll.u32 %v83099, 6 (stack44)
        %v83109 = vshrl.u32 %v83099, 26 (stack45)
        %v83110 = vor.u32 %v83109, %v83108 (stack46)
        %v83111 = vxor.u32 %v83110, %v83102 (stack47)
        %v83114 = vadd.s32 %v83111, %v9 (stack39)
        %v83118 = vadd.s32 3, %v83114 (stack39)
        %v83122 = vadd.s32 %v83118, %v83106 (stack39)
        %v83124 = vshll.u32 %v83118, 17 (stack44)
        %v83125 = vshrl.u32 %v83118, 15 (stack45)
        %v83126 = vor.u32 %v83125, %v83124 (stack46)
        %v83127 = vxor.u32 %v83126, %v83122 (stack47)
        %v83130 = vadd.s32 %v83127, %v83122 (stack39)
        %v83132 = vshll.u32 %v83127, 29 (stack44)
        %v83133 = vshrl.u32 %v83127, 3 (stack45)
        %v83134 = vor.u32 %v83133, %v83132 (stack46)
        %v83135 = vxor.u32 %v83134, %v83130 (stack47)
        %v83138 = vadd.s32 %v83135, %v83130 (stack39)
        %v83140 = vshll.u32 %v83135, 16 (stack44)
        %v83141 = vshrl.u32 %v83135, 16 (stack45)
        %v83142 = vor.u32 %v83141, %v83140 (stack46)
        %v83143 = vxor.u32 %v83142, %v83138 (stack47)
        %v83146 = vadd.s32 %v83143, %v83138 (stack39)
        %v83150 = vadd.s32 %v83146, %v9 (stack39)
        %v83152 = vshll.u32 %v83143, 24 (stack44)
        %v83153 = vshrl.u32 %v83143, 8 (stack45)
        %v83154 = vor.u32 %v83153, %v83152 (stack46)
        %v83155 = vxor.u32 %v83154, %v83146 (stack47)
        %v83158 = vadd.s32 %v83155, %v8 (stack39)
        %v83162 = vadd.s32 4, %v83158 (stack39)
        %v83166 = vadd.s32 %v83162, %v83150 (stack39)
        %v83168 = vshll.u32 %v83162, 13 (stack44)
        %v83169 = vshrl.u32 %v83162, 19 (stack45)
        %v83170 = vor.u32 %v83169, %v83168 (stack46)
        %v83171 = vxor.u32 %v83170, %v83166 (stack47)
        %v83174 = vadd.s32 %v83171, %v83166 (stack39)
        %v83176 = vshll.u32 %v83171, 15 (stack44)
        %v83177 = vshrl.u32 %v83171, 17 (stack45)
        %v83178 = vor.u32 %v83177, %v83176 (stack46)
        %v83179 = vxor.u32 %v83178, %v83174 (stack47)
        %v83182 = vadd.s32 %v83179, %v83174 (stack39)
        %v83184 = vshll.u32 %v83179, 26 (stack44)
        %v83185 = vshrl.u32 %v83179, 6 (stack45)
        %v83186 = vor.u32 %v83185, %v83184 (stack46)
        %v83187 = vxor.u32 %v83186, %v83182 (stack47)
        %v83190 = vadd.s32 %v83187, %v83182 (stack39)
        %v83194 = vadd.s32 %v83190, %v8 (stack39)
        %v83196 = vshll.u32 %v83187, 6 (stack44)
        %v83197 = vshrl.u32 %v83187, 26 (stack45)
        %v83198 = vor.u32 %v83197, %v83196 (stack46)
        %v83199 = vxor.u32 %v83198, %v83190 (stack47)
        %v83202 = vadd.s32 %v83199, %v10 (stack39)
        %v83206 = vadd.s32 5, %v83202 (stack39)
        %v83208 = vxor.u32 %v83206, %v83194 (stack47)
        %v83209 = vand.u32.u8 255, %v83208 (stack48)
        %v83210 = vand.u32 65535, %v83209 (stack49)
        %v83211 = vshrl.u32 %v83210, 1 (stack50)
        %v83212 = vor.u32 16256, %v83211 (stack46)
        %v83213 = vand.u32.u16 65535, %v83212 (stack51)
        %v120190 = vadd.low.f32.bf16 -1.0, %v83213 (stack52)
        %v83222 = vmul.f32 2.0, %v120190 (stack53)
        %v83226 = vadd.f32 -0.99609375, %v83222 (stack52)
        %v83230 = vmax.f32 %v83226, -0.99609375 (stack54)
        %v83232 = vand.u32 2147483647, %v83230 (stack55)
        %vm83235 = vcmp.eq.f32.partialorder %v83232, 1.0 (stack56)
        %v83240 = vmul.f32 inf, %v83230 (stack53)
        %v83242 = vxor.u32 2147483648, %v83230 (stack57)
        %v83245 = vmul.f32 %v83242, %v83230 (stack53)
        %v83247 = vadd.f32 1.0, %v83245 (stack58)
        %v83248 = vlog2.pop %v83247 (stack59)
        %v83249 = vmul.f32 0.6931472, %v83248 (stack60)
        %v83250 = vmul.f32 -0.5, %v83245 (stack61)
        %v83251 = vadd.f32 1.0, %v83250 (stack62)
        %v83252 = vmul.f32 %v83251, %v83245 (stack63)
        %v83253 = vand.u32 2147483647, %v83245 (stack64)
        %vm83254 = vcmp.lt.f32.partialorder %v83253, 0.0004427343 (stack65)
        %v83255 = vsel /*vm=*/%vm83254, /*on_true_vy=*/%v83252, /*on_false_vx=*/%v83249 (stack66)
        %v83256 = vxor.u32 2147483648, %v83255 (stack57)
        %vm83259 = vcmp.lt.f32.partialorder %v83256, 5.0 (stack56)
        %v83264 = vsel /*vm=*/%vm83259, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v83268 = vsel /*vm=*/%vm83259, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v83272 = vsel /*vm=*/%vm83259, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v83276 = vsel /*vm=*/%vm83259, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v83280 = vsel /*vm=*/%vm83259, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v83284 = vsel /*vm=*/%vm83259, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v83288 = vsel /*vm=*/%vm83259, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v83292 = vsel /*vm=*/%vm83259, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v83296 = vsel /*vm=*/%vm83259, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v83300 = vadd.f32 -2.5, %v83256 (stack52)
        %v83302 = vrsqrt.pop %v83256 (stack67)
        %v83303 = vmul.f32 %v83302, %v83256 (stack68)
        %vm83304 = vcmp.eq.f32.partialorder %v83256, inf (stack69)
        %v83305 = vsel /*vm=*/%vm83304, /*on_true_vy=*/%v83256, /*on_false_vx=*/%v83303 (stack70)
        %vm83306 = vcmp.eq.f32.partialorder %v83256, 0.0 (stack71)
        %v83307 = vand.u32 2147483648, %v83256 (stack72)
        %v83308 = vsel /*vm=*/%vm83306, /*on_true_vy=*/%v83307, /*on_false_vx=*/%v83305 (stack73)
        %v83311 = vadd.f32 -3.0, %v83308 (stack52)
        %v83315 = vsel /*vm=*/%vm83259, /*on_true_vy=*/%v83300, /*on_false_vx=*/%v83311 (stack43)
        %v83319 = vmul.f32 %v83315, %v83296 (stack53)
        %v83323 = vadd.f32 %v83319, %v83292 (stack52)
        %v83327 = vmul.f32 %v83323, %v83315 (stack53)
        %v83331 = vadd.f32 %v83327, %v83288 (stack52)
        %v83335 = vmul.f32 %v83331, %v83315 (stack53)
        %v83339 = vadd.f32 %v83335, %v83284 (stack52)
        %v83343 = vmul.f32 %v83339, %v83315 (stack53)
        %v83347 = vadd.f32 %v83343, %v83280 (stack52)
        %v83351 = vmul.f32 %v83347, %v83315 (stack53)
        %v83355 = vadd.f32 %v83351, %v83276 (stack52)
        %v83359 = vmul.f32 %v83355, %v83315 (stack53)
        %v83363 = vadd.f32 %v83359, %v83272 (stack52)
        %v83367 = vmul.f32 %v83363, %v83315 (stack53)
        %v83371 = vadd.f32 %v83367, %v83268 (stack52)
        %v83375 = vmul.f32 %v83371, %v83315 (stack53)
        %v83379 = vadd.f32 %v83375, %v83264 (stack52)
        %v83383 = vmul.f32 %v83379, %v83230 (stack53)
        %v83387 = vsel /*vm=*/%vm83235, /*on_true_vy=*/%v83240, /*on_false_vx=*/%v83383 (stack43)
        %v83391 = vmul.f32 1.4140625, %v83387 (stack53)
        %v83394 = vpack.c.bf16 0.0, %v83391 (stack74)
        %120191 = vst [vmem:[%s280 + $0xd8] sm:$0xf] /*vst_source=*/%v83394 (stack75)
        %v83398 = vadd.s32 %v82473, %v1381 (stack39)
        %v83408 = vadd.s32 %v83398, %v415 (stack39)
        %vm83412 = vcmp.lt.u32.totalorder %v83408, %v83398 (stack42)
        %vm83417 = vcmp.lt.u32.totalorder %v83398, %v1381 (stack42)
        %v83422 = vadd.s32 %v82456, %v1368 (stack39)
        %v83426 = vadd.s32 1, %v83422 (stack39)
        %v83430 = vsel /*vm=*/%vm83417, /*on_true_vy=*/%v83426, /*on_false_vx=*/%v83422 (stack43)
        %v83434 = vadd.s32 1, %v83430 (stack39)
        %v83438 = vsel /*vm=*/%vm83412, /*on_true_vy=*/%v83434, /*on_false_vx=*/%v83430 (stack43)
        %v83443 = vadd.s32 %v83438, %v10 (stack39)
        %v83447 = vadd.s32 %v83408, %v9 (stack39)
        %v83451 = vadd.s32 %v83447, %v83443 (stack39)
        %v83453 = vshll.u32 %v83447, 13 (stack44)
        %v83454 = vshrl.u32 %v83447, 19 (stack45)
        %v83455 = vor.u32 %v83454, %v83453 (stack46)
        %v83456 = vxor.u32 %v83455, %v83451 (stack47)
        %v83459 = vadd.s32 %v83456, %v83451 (stack39)
        %v83461 = vshll.u32 %v83456, 15 (stack44)
        %v83462 = vshrl.u32 %v83456, 17 (stack45)
        %v83463 = vor.u32 %v83462, %v83461 (stack46)
        %v83464 = vxor.u32 %v83463, %v83459 (stack47)
        %v83467 = vadd.s32 %v83464, %v83459 (stack39)
        %v83469 = vshll.u32 %v83464, 26 (stack44)
        %v83470 = vshrl.u32 %v83464, 6 (stack45)
        %v83471 = vor.u32 %v83470, %v83469 (stack46)
        %v83472 = vxor.u32 %v83471, %v83467 (stack47)
        %v83475 = vadd.s32 %v83472, %v83467 (stack39)
        %v83479 = vadd.s32 %v83475, %v9 (stack39)
        %v83481 = vshll.u32 %v83472, 6 (stack44)
        %v83482 = vshrl.u32 %v83472, 26 (stack45)
        %v83483 = vor.u32 %v83482, %v83481 (stack46)
        %v83484 = vxor.u32 %v83483, %v83475 (stack47)
        %v83487 = vadd.s32 %v83484, %v8 (stack39)
        %v83491 = vadd.s32 1, %v83487 (stack39)
        %v83495 = vadd.s32 %v83491, %v83479 (stack39)
        %v83497 = vshll.u32 %v83491, 17 (stack44)
        %v83498 = vshrl.u32 %v83491, 15 (stack45)
        %v83499 = vor.u32 %v83498, %v83497 (stack46)
        %v83500 = vxor.u32 %v83499, %v83495 (stack47)
        %v83503 = vadd.s32 %v83500, %v83495 (stack39)
        %v83505 = vshll.u32 %v83500, 29 (stack44)
        %v83506 = vshrl.u32 %v83500, 3 (stack45)
        %v83507 = vor.u32 %v83506, %v83505 (stack46)
        %v83508 = vxor.u32 %v83507, %v83503 (stack47)
        %v83511 = vadd.s32 %v83508, %v83503 (stack39)
        %v83513 = vshll.u32 %v83508, 16 (stack44)
        %v83514 = vshrl.u32 %v83508, 16 (stack45)
        %v83515 = vor.u32 %v83514, %v83513 (stack46)
        %v83516 = vxor.u32 %v83515, %v83511 (stack47)
        %v83519 = vadd.s32 %v83516, %v83511 (stack39)
        %v83523 = vadd.s32 %v83519, %v8 (stack39)
        %v83525 = vshll.u32 %v83516, 24 (stack44)
        %v83526 = vshrl.u32 %v83516, 8 (stack45)
        %v83527 = vor.u32 %v83526, %v83525 (stack46)
        %v83528 = vxor.u32 %v83527, %v83519 (stack47)
        %v83531 = vadd.s32 %v83528, %v10 (stack39)
        %v83535 = vadd.s32 2, %v83531 (stack39)
        %v83539 = vadd.s32 %v83535, %v83523 (stack39)
        %v83541 = vshll.u32 %v83535, 13 (stack44)
        %v83542 = vshrl.u32 %v83535, 19 (stack45)
        %v83543 = vor.u32 %v83542, %v83541 (stack46)
        %v83544 = vxor.u32 %v83543, %v83539 (stack47)
        %v83547 = vadd.s32 %v83544, %v83539 (stack39)
        %v83549 = vshll.u32 %v83544, 15 (stack44)
        %v83550 = vshrl.u32 %v83544, 17 (stack45)
        %v83551 = vor.u32 %v83550, %v83549 (stack46)
        %v83552 = vxor.u32 %v83551, %v83547 (stack47)
        %v83555 = vadd.s32 %v83552, %v83547 (stack39)
        %v83557 = vshll.u32 %v83552, 26 (stack44)
        %v83558 = vshrl.u32 %v83552, 6 (stack45)
        %v83559 = vor.u32 %v83558, %v83557 (stack46)
        %v83560 = vxor.u32 %v83559, %v83555 (stack47)
        %v83563 = vadd.s32 %v83560, %v83555 (stack39)
        %v83567 = vadd.s32 %v83563, %v10 (stack39)
        %v83569 = vshll.u32 %v83560, 6 (stack44)
        %v83570 = vshrl.u32 %v83560, 26 (stack45)
        %v83571 = vor.u32 %v83570, %v83569 (stack46)
        %v83572 = vxor.u32 %v83571, %v83563 (stack47)
        %v83575 = vadd.s32 %v83572, %v9 (stack39)
        %v83579 = vadd.s32 3, %v83575 (stack39)
        %v83583 = vadd.s32 %v83579, %v83567 (stack39)
        %v83585 = vshll.u32 %v83579, 17 (stack44)
        %v83586 = vshrl.u32 %v83579, 15 (stack45)
        %v83587 = vor.u32 %v83586, %v83585 (stack46)
        %v83588 = vxor.u32 %v83587, %v83583 (stack47)
        %v83591 = vadd.s32 %v83588, %v83583 (stack39)
        %v83593 = vshll.u32 %v83588, 29 (stack44)
        %v83594 = vshrl.u32 %v83588, 3 (stack45)
        %v83595 = vor.u32 %v83594, %v83593 (stack46)
        %v83596 = vxor.u32 %v83595, %v83591 (stack47)
        %v83599 = vadd.s32 %v83596, %v83591 (stack39)
        %v83601 = vshll.u32 %v83596, 16 (stack44)
        %v83602 = vshrl.u32 %v83596, 16 (stack45)
        %v83603 = vor.u32 %v83602, %v83601 (stack46)
        %v83604 = vxor.u32 %v83603, %v83599 (stack47)
        %v83607 = vadd.s32 %v83604, %v83599 (stack39)
        %v83611 = vadd.s32 %v83607, %v9 (stack39)
        %v83613 = vshll.u32 %v83604, 24 (stack44)
        %v83614 = vshrl.u32 %v83604, 8 (stack45)
        %v83615 = vor.u32 %v83614, %v83613 (stack46)
        %v83616 = vxor.u32 %v83615, %v83607 (stack47)
        %v83619 = vadd.s32 %v83616, %v8 (stack39)
        %v83623 = vadd.s32 4, %v83619 (stack39)
        %v83627 = vadd.s32 %v83623, %v83611 (stack39)
        %v83629 = vshll.u32 %v83623, 13 (stack44)
        %v83630 = vshrl.u32 %v83623, 19 (stack45)
        %v83631 = vor.u32 %v83630, %v83629 (stack46)
        %v83632 = vxor.u32 %v83631, %v83627 (stack47)
        %v83635 = vadd.s32 %v83632, %v83627 (stack39)
        %v83637 = vshll.u32 %v83632, 15 (stack44)
        %v83638 = vshrl.u32 %v83632, 17 (stack45)
        %v83639 = vor.u32 %v83638, %v83637 (stack46)
        %v83640 = vxor.u32 %v83639, %v83635 (stack47)
        %v83643 = vadd.s32 %v83640, %v83635 (stack39)
        %v83645 = vshll.u32 %v83640, 26 (stack44)
        %v83646 = vshrl.u32 %v83640, 6 (stack45)
        %v83647 = vor.u32 %v83646, %v83645 (stack46)
        %v83648 = vxor.u32 %v83647, %v83643 (stack47)
        %v83651 = vadd.s32 %v83648, %v83643 (stack39)
        %v83655 = vadd.s32 %v83651, %v8 (stack39)
        %v83657 = vshll.u32 %v83648, 6 (stack44)
        %v83658 = vshrl.u32 %v83648, 26 (stack45)
        %v83659 = vor.u32 %v83658, %v83657 (stack46)
        %v83660 = vxor.u32 %v83659, %v83651 (stack47)
        %v83663 = vadd.s32 %v83660, %v10 (stack39)
        %v83667 = vadd.s32 5, %v83663 (stack39)
        %v83669 = vxor.u32 %v83667, %v83655 (stack47)
        %v83670 = vand.u32.u8 255, %v83669 (stack48)
        %v83671 = vand.u32 65535, %v83670 (stack49)
        %v83672 = vshrl.u32 %v83671, 1 (stack50)
        %v83673 = vor.u32 16256, %v83672 (stack46)
        %v83674 = vand.u32.u16 65535, %v83673 (stack51)
        %v120192 = vadd.low.f32.bf16 -1.0, %v83674 (stack52)
        %v83683 = vmul.f32 2.0, %v120192 (stack53)
        %v83687 = vadd.f32 -0.99609375, %v83683 (stack52)
        %v83691 = vmax.f32 %v83687, -0.99609375 (stack54)
        %v83693 = vand.u32 2147483647, %v83691 (stack55)
        %vm83696 = vcmp.eq.f32.partialorder %v83693, 1.0 (stack56)
        %v83701 = vmul.f32 inf, %v83691 (stack53)
        %v83703 = vxor.u32 2147483648, %v83691 (stack57)
        %v83706 = vmul.f32 %v83703, %v83691 (stack53)
        %v83708 = vadd.f32 1.0, %v83706 (stack58)
        %v83709 = vlog2.pop %v83708 (stack59)
        %v83710 = vmul.f32 0.6931472, %v83709 (stack60)
        %v83711 = vmul.f32 -0.5, %v83706 (stack61)
        %v83712 = vadd.f32 1.0, %v83711 (stack62)
        %v83713 = vmul.f32 %v83712, %v83706 (stack63)
        %v83714 = vand.u32 2147483647, %v83706 (stack64)
        %vm83715 = vcmp.lt.f32.partialorder %v83714, 0.0004427343 (stack65)
        %v83716 = vsel /*vm=*/%vm83715, /*on_true_vy=*/%v83713, /*on_false_vx=*/%v83710 (stack66)
        %v83717 = vxor.u32 2147483648, %v83716 (stack57)
        %vm83720 = vcmp.lt.f32.partialorder %v83717, 5.0 (stack56)
        %v83725 = vsel /*vm=*/%vm83720, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v83729 = vsel /*vm=*/%vm83720, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v83733 = vsel /*vm=*/%vm83720, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v83737 = vsel /*vm=*/%vm83720, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v83741 = vsel /*vm=*/%vm83720, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v83745 = vsel /*vm=*/%vm83720, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v83749 = vsel /*vm=*/%vm83720, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v83753 = vsel /*vm=*/%vm83720, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v83757 = vsel /*vm=*/%vm83720, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v83761 = vadd.f32 -2.5, %v83717 (stack52)
        %v83763 = vrsqrt.pop %v83717 (stack67)
        %v83764 = vmul.f32 %v83763, %v83717 (stack68)
        %vm83765 = vcmp.eq.f32.partialorder %v83717, inf (stack69)
        %v83766 = vsel /*vm=*/%vm83765, /*on_true_vy=*/%v83717, /*on_false_vx=*/%v83764 (stack70)
        %vm83767 = vcmp.eq.f32.partialorder %v83717, 0.0 (stack71)
        %v83768 = vand.u32 2147483648, %v83717 (stack72)
        %v83769 = vsel /*vm=*/%vm83767, /*on_true_vy=*/%v83768, /*on_false_vx=*/%v83766 (stack73)
        %v83772 = vadd.f32 -3.0, %v83769 (stack52)
        %v83776 = vsel /*vm=*/%vm83720, /*on_true_vy=*/%v83761, /*on_false_vx=*/%v83772 (stack43)
        %v83780 = vmul.f32 %v83776, %v83757 (stack53)
        %v83784 = vadd.f32 %v83780, %v83753 (stack52)
        %v83788 = vmul.f32 %v83784, %v83776 (stack53)
        %v83792 = vadd.f32 %v83788, %v83749 (stack52)
        %v83796 = vmul.f32 %v83792, %v83776 (stack53)
        %v83800 = vadd.f32 %v83796, %v83745 (stack52)
        %v83804 = vmul.f32 %v83800, %v83776 (stack53)
        %v83808 = vadd.f32 %v83804, %v83741 (stack52)
        %v83812 = vmul.f32 %v83808, %v83776 (stack53)
        %v83816 = vadd.f32 %v83812, %v83737 (stack52)
        %v83820 = vmul.f32 %v83816, %v83776 (stack53)
        %v83824 = vadd.f32 %v83820, %v83733 (stack52)
        %v83828 = vmul.f32 %v83824, %v83776 (stack53)
        %v83832 = vadd.f32 %v83828, %v83729 (stack52)
        %v83836 = vmul.f32 %v83832, %v83776 (stack53)
        %v83840 = vadd.f32 %v83836, %v83725 (stack52)
        %v83844 = vmul.f32 %v83840, %v83691 (stack53)
        %v83848 = vsel /*vm=*/%vm83696, /*on_true_vy=*/%v83701, /*on_false_vx=*/%v83844 (stack43)
        %v83852 = vmul.f32 1.4140625, %v83848 (stack53)
        %v83855 = vpack.c.bf16 0.0, %v83852 (stack74)
        %120193 = vst [vmem:[%s280 + $0x158] sm:$0xf] /*vst_source=*/%v83855 (stack75)
        %v83859 = vadd.s32 %v82473, %v1868 (stack39)
        %v83869 = vadd.s32 %v83859, %v415 (stack39)
        %vm83873 = vcmp.lt.u32.totalorder %v83869, %v83859 (stack42)
        %vm83878 = vcmp.lt.u32.totalorder %v83859, %v1868 (stack42)
        %v83883 = vadd.s32 %v82456, %v1855 (stack39)
        %v83887 = vadd.s32 1, %v83883 (stack39)
        %v83891 = vsel /*vm=*/%vm83878, /*on_true_vy=*/%v83887, /*on_false_vx=*/%v83883 (stack43)
        %v83895 = vadd.s32 1, %v83891 (stack39)
        %v83899 = vsel /*vm=*/%vm83873, /*on_true_vy=*/%v83895, /*on_false_vx=*/%v83891 (stack43)
        %v83904 = vadd.s32 %v83899, %v10 (stack39)
        %v83908 = vadd.s32 %v83869, %v9 (stack39)
        %v83912 = vadd.s32 %v83908, %v83904 (stack39)
        %v83914 = vshll.u32 %v83908, 13 (stack44)
        %v83915 = vshrl.u32 %v83908, 19 (stack45)
        %v83916 = vor.u32 %v83915, %v83914 (stack46)
        %v83917 = vxor.u32 %v83916, %v83912 (stack47)
        %v83920 = vadd.s32 %v83917, %v83912 (stack39)
        %v83922 = vshll.u32 %v83917, 15 (stack44)
        %v83923 = vshrl.u32 %v83917, 17 (stack45)
        %v83924 = vor.u32 %v83923, %v83922 (stack46)
        %v83925 = vxor.u32 %v83924, %v83920 (stack47)
        %v83928 = vadd.s32 %v83925, %v83920 (stack39)
        %v83930 = vshll.u32 %v83925, 26 (stack44)
        %v83931 = vshrl.u32 %v83925, 6 (stack45)
        %v83932 = vor.u32 %v83931, %v83930 (stack46)
        %v83933 = vxor.u32 %v83932, %v83928 (stack47)
        %v83936 = vadd.s32 %v83933, %v83928 (stack39)
        %v83940 = vadd.s32 %v83936, %v9 (stack39)
        %v83942 = vshll.u32 %v83933, 6 (stack44)
        %v83943 = vshrl.u32 %v83933, 26 (stack45)
        %v83944 = vor.u32 %v83943, %v83942 (stack46)
        %v83945 = vxor.u32 %v83944, %v83936 (stack47)
        %v83948 = vadd.s32 %v83945, %v8 (stack39)
        %v83952 = vadd.s32 1, %v83948 (stack39)
        %v83956 = vadd.s32 %v83952, %v83940 (stack39)
        %v83958 = vshll.u32 %v83952, 17 (stack44)
        %v83959 = vshrl.u32 %v83952, 15 (stack45)
        %v83960 = vor.u32 %v83959, %v83958 (stack46)
        %v83961 = vxor.u32 %v83960, %v83956 (stack47)
        %v83964 = vadd.s32 %v83961, %v83956 (stack39)
        %v83966 = vshll.u32 %v83961, 29 (stack44)
        %v83967 = vshrl.u32 %v83961, 3 (stack45)
        %v83968 = vor.u32 %v83967, %v83966 (stack46)
        %v83969 = vxor.u32 %v83968, %v83964 (stack47)
        %v83972 = vadd.s32 %v83969, %v83964 (stack39)
        %v83974 = vshll.u32 %v83969, 16 (stack44)
        %v83975 = vshrl.u32 %v83969, 16 (stack45)
        %v83976 = vor.u32 %v83975, %v83974 (stack46)
        %v83977 = vxor.u32 %v83976, %v83972 (stack47)
        %v83980 = vadd.s32 %v83977, %v83972 (stack39)
        %v83984 = vadd.s32 %v83980, %v8 (stack39)
        %v83986 = vshll.u32 %v83977, 24 (stack44)
        %v83987 = vshrl.u32 %v83977, 8 (stack45)
        %v83988 = vor.u32 %v83987, %v83986 (stack46)
        %v83989 = vxor.u32 %v83988, %v83980 (stack47)
        %v83992 = vadd.s32 %v83989, %v10 (stack39)
        %v83996 = vadd.s32 2, %v83992 (stack39)
        %v84000 = vadd.s32 %v83996, %v83984 (stack39)
        %v84002 = vshll.u32 %v83996, 13 (stack44)
        %v84003 = vshrl.u32 %v83996, 19 (stack45)
        %v84004 = vor.u32 %v84003, %v84002 (stack46)
        %v84005 = vxor.u32 %v84004, %v84000 (stack47)
        %v84008 = vadd.s32 %v84005, %v84000 (stack39)
        %v84010 = vshll.u32 %v84005, 15 (stack44)
        %v84011 = vshrl.u32 %v84005, 17 (stack45)
        %v84012 = vor.u32 %v84011, %v84010 (stack46)
        %v84013 = vxor.u32 %v84012, %v84008 (stack47)
        %v84016 = vadd.s32 %v84013, %v84008 (stack39)
        %v84018 = vshll.u32 %v84013, 26 (stack44)
        %v84019 = vshrl.u32 %v84013, 6 (stack45)
        %v84020 = vor.u32 %v84019, %v84018 (stack46)
        %v84021 = vxor.u32 %v84020, %v84016 (stack47)
        %v84024 = vadd.s32 %v84021, %v84016 (stack39)
        %v84028 = vadd.s32 %v84024, %v10 (stack39)
        %v84030 = vshll.u32 %v84021, 6 (stack44)
        %v84031 = vshrl.u32 %v84021, 26 (stack45)
        %v84032 = vor.u32 %v84031, %v84030 (stack46)
        %v84033 = vxor.u32 %v84032, %v84024 (stack47)
        %v84036 = vadd.s32 %v84033, %v9 (stack39)
        %v84040 = vadd.s32 3, %v84036 (stack39)
        %v84044 = vadd.s32 %v84040, %v84028 (stack39)
        %v84046 = vshll.u32 %v84040, 17 (stack44)
        %v84047 = vshrl.u32 %v84040, 15 (stack45)
        %v84048 = vor.u32 %v84047, %v84046 (stack46)
        %v84049 = vxor.u32 %v84048, %v84044 (stack47)
        %v84052 = vadd.s32 %v84049, %v84044 (stack39)
        %v84054 = vshll.u32 %v84049, 29 (stack44)
        %v84055 = vshrl.u32 %v84049, 3 (stack45)
        %v84056 = vor.u32 %v84055, %v84054 (stack46)
        %v84057 = vxor.u32 %v84056, %v84052 (stack47)
        %v84060 = vadd.s32 %v84057, %v84052 (stack39)
        %v84062 = vshll.u32 %v84057, 16 (stack44)
        %v84063 = vshrl.u32 %v84057, 16 (stack45)
        %v84064 = vor.u32 %v84063, %v84062 (stack46)
        %v84065 = vxor.u32 %v84064, %v84060 (stack47)
        %v84068 = vadd.s32 %v84065, %v84060 (stack39)
        %v84072 = vadd.s32 %v84068, %v9 (stack39)
        %v84074 = vshll.u32 %v84065, 24 (stack44)
        %v84075 = vshrl.u32 %v84065, 8 (stack45)
        %v84076 = vor.u32 %v84075, %v84074 (stack46)
        %v84077 = vxor.u32 %v84076, %v84068 (stack47)
        %v84080 = vadd.s32 %v84077, %v8 (stack39)
        %v84084 = vadd.s32 4, %v84080 (stack39)
        %v84088 = vadd.s32 %v84084, %v84072 (stack39)
        %v84090 = vshll.u32 %v84084, 13 (stack44)
        %v84091 = vshrl.u32 %v84084, 19 (stack45)
        %v84092 = vor.u32 %v84091, %v84090 (stack46)
        %v84093 = vxor.u32 %v84092, %v84088 (stack47)
        %v84096 = vadd.s32 %v84093, %v84088 (stack39)
        %v84098 = vshll.u32 %v84093, 15 (stack44)
        %v84099 = vshrl.u32 %v84093, 17 (stack45)
        %v84100 = vor.u32 %v84099, %v84098 (stack46)
        %v84101 = vxor.u32 %v84100, %v84096 (stack47)
        %v84104 = vadd.s32 %v84101, %v84096 (stack39)
        %v84106 = vshll.u32 %v84101, 26 (stack44)
        %v84107 = vshrl.u32 %v84101, 6 (stack45)
        %v84108 = vor.u32 %v84107, %v84106 (stack46)
        %v84109 = vxor.u32 %v84108, %v84104 (stack47)
        %v84112 = vadd.s32 %v84109, %v84104 (stack39)
        %v84116 = vadd.s32 %v84112, %v8 (stack39)
        %v84118 = vshll.u32 %v84109, 6 (stack44)
        %v84119 = vshrl.u32 %v84109, 26 (stack45)
        %v84120 = vor.u32 %v84119, %v84118 (stack46)
        %v84121 = vxor.u32 %v84120, %v84112 (stack47)
        %v84124 = vadd.s32 %v84121, %v10 (stack39)
        %v84128 = vadd.s32 5, %v84124 (stack39)
        %v84130 = vxor.u32 %v84128, %v84116 (stack47)
        %v84131 = vand.u32.u8 255, %v84130 (stack48)
        %v84132 = vand.u32 65535, %v84131 (stack49)
        %v84133 = vshrl.u32 %v84132, 1 (stack50)
        %v84134 = vor.u32 16256, %v84133 (stack46)
        %v84135 = vand.u32.u16 65535, %v84134 (stack51)
        %v120194 = vadd.low.f32.bf16 -1.0, %v84135 (stack52)
        %v84144 = vmul.f32 2.0, %v120194 (stack53)
        %v84148 = vadd.f32 -0.99609375, %v84144 (stack52)
        %v84152 = vmax.f32 %v84148, -0.99609375 (stack54)
        %v84154 = vand.u32 2147483647, %v84152 (stack55)
        %vm84157 = vcmp.eq.f32.partialorder %v84154, 1.0 (stack56)
        %v84162 = vmul.f32 inf, %v84152 (stack53)
        %v84164 = vxor.u32 2147483648, %v84152 (stack57)
        %v84167 = vmul.f32 %v84164, %v84152 (stack53)
        %v84169 = vadd.f32 1.0, %v84167 (stack58)
        %v84170 = vlog2.pop %v84169 (stack59)
        %v84171 = vmul.f32 0.6931472, %v84170 (stack60)
        %v84172 = vmul.f32 -0.5, %v84167 (stack61)
        %v84173 = vadd.f32 1.0, %v84172 (stack62)
        %v84174 = vmul.f32 %v84173, %v84167 (stack63)
        %v84175 = vand.u32 2147483647, %v84167 (stack64)
        %vm84176 = vcmp.lt.f32.partialorder %v84175, 0.0004427343 (stack65)
        %v84177 = vsel /*vm=*/%vm84176, /*on_true_vy=*/%v84174, /*on_false_vx=*/%v84171 (stack66)
        %v84178 = vxor.u32 2147483648, %v84177 (stack57)
        %vm84181 = vcmp.lt.f32.partialorder %v84178, 5.0 (stack56)
        %v84186 = vsel /*vm=*/%vm84181, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v84190 = vsel /*vm=*/%vm84181, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v84194 = vsel /*vm=*/%vm84181, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v84198 = vsel /*vm=*/%vm84181, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v84202 = vsel /*vm=*/%vm84181, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v84206 = vsel /*vm=*/%vm84181, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v84210 = vsel /*vm=*/%vm84181, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v84214 = vsel /*vm=*/%vm84181, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v84218 = vsel /*vm=*/%vm84181, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v84222 = vadd.f32 -2.5, %v84178 (stack52)
        %v84224 = vrsqrt.pop %v84178 (stack67)
        %v84225 = vmul.f32 %v84224, %v84178 (stack68)
        %vm84226 = vcmp.eq.f32.partialorder %v84178, inf (stack69)
        %v84227 = vsel /*vm=*/%vm84226, /*on_true_vy=*/%v84178, /*on_false_vx=*/%v84225 (stack70)
        %vm84228 = vcmp.eq.f32.partialorder %v84178, 0.0 (stack71)
        %v84229 = vand.u32 2147483648, %v84178 (stack72)
        %v84230 = vsel /*vm=*/%vm84228, /*on_true_vy=*/%v84229, /*on_false_vx=*/%v84227 (stack73)
        %v84233 = vadd.f32 -3.0, %v84230 (stack52)
        %v84237 = vsel /*vm=*/%vm84181, /*on_true_vy=*/%v84222, /*on_false_vx=*/%v84233 (stack43)
        %v84241 = vmul.f32 %v84237, %v84218 (stack53)
        %v84245 = vadd.f32 %v84241, %v84214 (stack52)
        %v84249 = vmul.f32 %v84245, %v84237 (stack53)
        %v84253 = vadd.f32 %v84249, %v84210 (stack52)
        %v84257 = vmul.f32 %v84253, %v84237 (stack53)
        %v84261 = vadd.f32 %v84257, %v84206 (stack52)
        %v84265 = vmul.f32 %v84261, %v84237 (stack53)
        %v84269 = vadd.f32 %v84265, %v84202 (stack52)
        %v84273 = vmul.f32 %v84269, %v84237 (stack53)
        %v84277 = vadd.f32 %v84273, %v84198 (stack52)
        %v84281 = vmul.f32 %v84277, %v84237 (stack53)
        %v84285 = vadd.f32 %v84281, %v84194 (stack52)
        %v84289 = vmul.f32 %v84285, %v84237 (stack53)
        %v84293 = vadd.f32 %v84289, %v84190 (stack52)
        %v84297 = vmul.f32 %v84293, %v84237 (stack53)
        %v84301 = vadd.f32 %v84297, %v84186 (stack52)
        %v84305 = vmul.f32 %v84301, %v84152 (stack53)
        %v84309 = vsel /*vm=*/%vm84157, /*on_true_vy=*/%v84162, /*on_false_vx=*/%v84305 (stack43)
        %v84313 = vmul.f32 1.4140625, %v84309 (stack53)
        %v84316 = vpack.c.bf16 0.0, %v84313 (stack74)
        %120195 = vst [vmem:[%s280 + $0x1d8] sm:$0xf] /*vst_source=*/%v84316 (stack75)
        %v84320 = vadd.s32 %v82473, %v2355 (stack39)
        %v84330 = vadd.s32 %v84320, %v415 (stack39)
        %vm84334 = vcmp.lt.u32.totalorder %v84330, %v84320 (stack42)
        %vm84339 = vcmp.lt.u32.totalorder %v84320, %v2355 (stack42)
        %v84344 = vadd.s32 %v82456, %v2342 (stack39)
        %v84348 = vadd.s32 1, %v84344 (stack39)
        %v84352 = vsel /*vm=*/%vm84339, /*on_true_vy=*/%v84348, /*on_false_vx=*/%v84344 (stack43)
        %v84356 = vadd.s32 1, %v84352 (stack39)
        %v84360 = vsel /*vm=*/%vm84334, /*on_true_vy=*/%v84356, /*on_false_vx=*/%v84352 (stack43)
        %v84365 = vadd.s32 %v84360, %v10 (stack39)
        %v84369 = vadd.s32 %v84330, %v9 (stack39)
        %v84373 = vadd.s32 %v84369, %v84365 (stack39)
        %v84375 = vshll.u32 %v84369, 13 (stack44)
        %v84376 = vshrl.u32 %v84369, 19 (stack45)
        %v84377 = vor.u32 %v84376, %v84375 (stack46)
        %v84378 = vxor.u32 %v84377, %v84373 (stack47)
        %v84381 = vadd.s32 %v84378, %v84373 (stack39)
        %v84383 = vshll.u32 %v84378, 15 (stack44)
        %v84384 = vshrl.u32 %v84378, 17 (stack45)
        %v84385 = vor.u32 %v84384, %v84383 (stack46)
        %v84386 = vxor.u32 %v84385, %v84381 (stack47)
        %v84389 = vadd.s32 %v84386, %v84381 (stack39)
        %v84391 = vshll.u32 %v84386, 26 (stack44)
        %v84392 = vshrl.u32 %v84386, 6 (stack45)
        %v84393 = vor.u32 %v84392, %v84391 (stack46)
        %v84394 = vxor.u32 %v84393, %v84389 (stack47)
        %v84397 = vadd.s32 %v84394, %v84389 (stack39)
        %v84401 = vadd.s32 %v84397, %v9 (stack39)
        %v84403 = vshll.u32 %v84394, 6 (stack44)
        %v84404 = vshrl.u32 %v84394, 26 (stack45)
        %v84405 = vor.u32 %v84404, %v84403 (stack46)
        %v84406 = vxor.u32 %v84405, %v84397 (stack47)
        %v84409 = vadd.s32 %v84406, %v8 (stack39)
        %v84413 = vadd.s32 1, %v84409 (stack39)
        %v84417 = vadd.s32 %v84413, %v84401 (stack39)
        %v84419 = vshll.u32 %v84413, 17 (stack44)
        %v84420 = vshrl.u32 %v84413, 15 (stack45)
        %v84421 = vor.u32 %v84420, %v84419 (stack46)
        %v84422 = vxor.u32 %v84421, %v84417 (stack47)
        %v84425 = vadd.s32 %v84422, %v84417 (stack39)
        %v84427 = vshll.u32 %v84422, 29 (stack44)
        %v84428 = vshrl.u32 %v84422, 3 (stack45)
        %v84429 = vor.u32 %v84428, %v84427 (stack46)
        %v84430 = vxor.u32 %v84429, %v84425 (stack47)
        %v84433 = vadd.s32 %v84430, %v84425 (stack39)
        %v84435 = vshll.u32 %v84430, 16 (stack44)
        %v84436 = vshrl.u32 %v84430, 16 (stack45)
        %v84437 = vor.u32 %v84436, %v84435 (stack46)
        %v84438 = vxor.u32 %v84437, %v84433 (stack47)
        %v84441 = vadd.s32 %v84438, %v84433 (stack39)
        %v84445 = vadd.s32 %v84441, %v8 (stack39)
        %v84447 = vshll.u32 %v84438, 24 (stack44)
        %v84448 = vshrl.u32 %v84438, 8 (stack45)
        %v84449 = vor.u32 %v84448, %v84447 (stack46)
        %v84450 = vxor.u32 %v84449, %v84441 (stack47)
        %v84453 = vadd.s32 %v84450, %v10 (stack39)
        %v84457 = vadd.s32 2, %v84453 (stack39)
        %v84461 = vadd.s32 %v84457, %v84445 (stack39)
        %v84463 = vshll.u32 %v84457, 13 (stack44)
        %v84464 = vshrl.u32 %v84457, 19 (stack45)
        %v84465 = vor.u32 %v84464, %v84463 (stack46)
        %v84466 = vxor.u32 %v84465, %v84461 (stack47)
        %v84469 = vadd.s32 %v84466, %v84461 (stack39)
        %v84471 = vshll.u32 %v84466, 15 (stack44)
        %v84472 = vshrl.u32 %v84466, 17 (stack45)
        %v84473 = vor.u32 %v84472, %v84471 (stack46)
        %v84474 = vxor.u32 %v84473, %v84469 (stack47)
        %v84477 = vadd.s32 %v84474, %v84469 (stack39)
        %v84479 = vshll.u32 %v84474, 26 (stack44)
        %v84480 = vshrl.u32 %v84474, 6 (stack45)
        %v84481 = vor.u32 %v84480, %v84479 (stack46)
        %v84482 = vxor.u32 %v84481, %v84477 (stack47)
        %v84485 = vadd.s32 %v84482, %v84477 (stack39)
        %v84489 = vadd.s32 %v84485, %v10 (stack39)
        %v84491 = vshll.u32 %v84482, 6 (stack44)
        %v84492 = vshrl.u32 %v84482, 26 (stack45)
        %v84493 = vor.u32 %v84492, %v84491 (stack46)
        %v84494 = vxor.u32 %v84493, %v84485 (stack47)
        %v84497 = vadd.s32 %v84494, %v9 (stack39)
        %v84501 = vadd.s32 3, %v84497 (stack39)
        %v84505 = vadd.s32 %v84501, %v84489 (stack39)
        %v84507 = vshll.u32 %v84501, 17 (stack44)
        %v84508 = vshrl.u32 %v84501, 15 (stack45)
        %v84509 = vor.u32 %v84508, %v84507 (stack46)
        %v84510 = vxor.u32 %v84509, %v84505 (stack47)
        %v84513 = vadd.s32 %v84510, %v84505 (stack39)
        %v84515 = vshll.u32 %v84510, 29 (stack44)
        %v84516 = vshrl.u32 %v84510, 3 (stack45)
        %v84517 = vor.u32 %v84516, %v84515 (stack46)
        %v84518 = vxor.u32 %v84517, %v84513 (stack47)
        %v84521 = vadd.s32 %v84518, %v84513 (stack39)
        %v84523 = vshll.u32 %v84518, 16 (stack44)
        %v84524 = vshrl.u32 %v84518, 16 (stack45)
        %v84525 = vor.u32 %v84524, %v84523 (stack46)
        %v84526 = vxor.u32 %v84525, %v84521 (stack47)
        %v84529 = vadd.s32 %v84526, %v84521 (stack39)
        %v84533 = vadd.s32 %v84529, %v9 (stack39)
        %v84535 = vshll.u32 %v84526, 24 (stack44)
        %v84536 = vshrl.u32 %v84526, 8 (stack45)
        %v84537 = vor.u32 %v84536, %v84535 (stack46)
        %v84538 = vxor.u32 %v84537, %v84529 (stack47)
        %v84541 = vadd.s32 %v84538, %v8 (stack39)
        %v84545 = vadd.s32 4, %v84541 (stack39)
        %v84549 = vadd.s32 %v84545, %v84533 (stack39)
        %v84551 = vshll.u32 %v84545, 13 (stack44)
        %v84552 = vshrl.u32 %v84545, 19 (stack45)
        %v84553 = vor.u32 %v84552, %v84551 (stack46)
        %v84554 = vxor.u32 %v84553, %v84549 (stack47)
        %v84557 = vadd.s32 %v84554, %v84549 (stack39)
        %v84559 = vshll.u32 %v84554, 15 (stack44)
        %v84560 = vshrl.u32 %v84554, 17 (stack45)
        %v84561 = vor.u32 %v84560, %v84559 (stack46)
        %v84562 = vxor.u32 %v84561, %v84557 (stack47)
        %v84565 = vadd.s32 %v84562, %v84557 (stack39)
        %v84567 = vshll.u32 %v84562, 26 (stack44)
        %v84568 = vshrl.u32 %v84562, 6 (stack45)
        %v84569 = vor.u32 %v84568, %v84567 (stack46)
        %v84570 = vxor.u32 %v84569, %v84565 (stack47)
        %v84573 = vadd.s32 %v84570, %v84565 (stack39)
        %v84577 = vadd.s32 %v84573, %v8 (stack39)
        %v84579 = vshll.u32 %v84570, 6 (stack44)
        %v84580 = vshrl.u32 %v84570, 26 (stack45)
        %v84581 = vor.u32 %v84580, %v84579 (stack46)
        %v84582 = vxor.u32 %v84581, %v84573 (stack47)
        %v84585 = vadd.s32 %v84582, %v10 (stack39)
        %v84589 = vadd.s32 5, %v84585 (stack39)
        %v84591 = vxor.u32 %v84589, %v84577 (stack47)
        %v84592 = vand.u32.u8 255, %v84591 (stack48)
        %v84593 = vand.u32 65535, %v84592 (stack49)
        %v84594 = vshrl.u32 %v84593, 1 (stack50)
        %v84595 = vor.u32 16256, %v84594 (stack46)
        %v84596 = vand.u32.u16 65535, %v84595 (stack51)
        %v120196 = vadd.low.f32.bf16 -1.0, %v84596 (stack52)
        %v84605 = vmul.f32 2.0, %v120196 (stack53)
        %v84609 = vadd.f32 -0.99609375, %v84605 (stack52)
        %v84613 = vmax.f32 %v84609, -0.99609375 (stack54)
        %v84615 = vand.u32 2147483647, %v84613 (stack55)
        %vm84618 = vcmp.eq.f32.partialorder %v84615, 1.0 (stack56)
        %v84623 = vmul.f32 inf, %v84613 (stack53)
        %v84625 = vxor.u32 2147483648, %v84613 (stack57)
        %v84628 = vmul.f32 %v84625, %v84613 (stack53)
        %v84630 = vadd.f32 1.0, %v84628 (stack58)
        %v84631 = vlog2.pop %v84630 (stack59)
        %v84632 = vmul.f32 0.6931472, %v84631 (stack60)
        %v84633 = vmul.f32 -0.5, %v84628 (stack61)
        %v84634 = vadd.f32 1.0, %v84633 (stack62)
        %v84635 = vmul.f32 %v84634, %v84628 (stack63)
        %v84636 = vand.u32 2147483647, %v84628 (stack64)
        %vm84637 = vcmp.lt.f32.partialorder %v84636, 0.0004427343 (stack65)
        %v84638 = vsel /*vm=*/%vm84637, /*on_true_vy=*/%v84635, /*on_false_vx=*/%v84632 (stack66)
        %v84639 = vxor.u32 2147483648, %v84638 (stack57)
        %vm84642 = vcmp.lt.f32.partialorder %v84639, 5.0 (stack56)
        %v84647 = vsel /*vm=*/%vm84642, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v84651 = vsel /*vm=*/%vm84642, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v84655 = vsel /*vm=*/%vm84642, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v84659 = vsel /*vm=*/%vm84642, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v84663 = vsel /*vm=*/%vm84642, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v84667 = vsel /*vm=*/%vm84642, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v84671 = vsel /*vm=*/%vm84642, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v84675 = vsel /*vm=*/%vm84642, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v84679 = vsel /*vm=*/%vm84642, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v84683 = vadd.f32 -2.5, %v84639 (stack52)
        %v84685 = vrsqrt.pop %v84639 (stack67)
        %v84686 = vmul.f32 %v84685, %v84639 (stack68)
        %vm84687 = vcmp.eq.f32.partialorder %v84639, inf (stack69)
        %v84688 = vsel /*vm=*/%vm84687, /*on_true_vy=*/%v84639, /*on_false_vx=*/%v84686 (stack70)
        %vm84689 = vcmp.eq.f32.partialorder %v84639, 0.0 (stack71)
        %v84690 = vand.u32 2147483648, %v84639 (stack72)
        %v84691 = vsel /*vm=*/%vm84689, /*on_true_vy=*/%v84690, /*on_false_vx=*/%v84688 (stack73)
        %v84694 = vadd.f32 -3.0, %v84691 (stack52)
        %v84698 = vsel /*vm=*/%vm84642, /*on_true_vy=*/%v84683, /*on_false_vx=*/%v84694 (stack43)
        %v84702 = vmul.f32 %v84698, %v84679 (stack53)
        %v84706 = vadd.f32 %v84702, %v84675 (stack52)
        %v84710 = vmul.f32 %v84706, %v84698 (stack53)
        %v84714 = vadd.f32 %v84710, %v84671 (stack52)
        %v84718 = vmul.f32 %v84714, %v84698 (stack53)
        %v84722 = vadd.f32 %v84718, %v84667 (stack52)
        %v84726 = vmul.f32 %v84722, %v84698 (stack53)
        %v84730 = vadd.f32 %v84726, %v84663 (stack52)
        %v84734 = vmul.f32 %v84730, %v84698 (stack53)
        %v84738 = vadd.f32 %v84734, %v84659 (stack52)
        %v84742 = vmul.f32 %v84738, %v84698 (stack53)
        %v84746 = vadd.f32 %v84742, %v84655 (stack52)
        %v84750 = vmul.f32 %v84746, %v84698 (stack53)
        %v84754 = vadd.f32 %v84750, %v84651 (stack52)
        %v84758 = vmul.f32 %v84754, %v84698 (stack53)
        %v84762 = vadd.f32 %v84758, %v84647 (stack52)
        %v84766 = vmul.f32 %v84762, %v84613 (stack53)
        %v84770 = vsel /*vm=*/%vm84618, /*on_true_vy=*/%v84623, /*on_false_vx=*/%v84766 (stack43)
        %v84774 = vmul.f32 1.4140625, %v84770 (stack53)
        %v84777 = vpack.c.bf16 0.0, %v84774 (stack74)
        %120197 = vst [vmem:[%s280 + $0x258] sm:$0xf] /*vst_source=*/%v84777 (stack75)
        %v84781 = vadd.s32 %v82473, %v2842 (stack39)
        %v84791 = vadd.s32 %v84781, %v415 (stack39)
        %vm84795 = vcmp.lt.u32.totalorder %v84791, %v84781 (stack42)
        %vm84800 = vcmp.lt.u32.totalorder %v84781, %v2842 (stack42)
        %v84805 = vadd.s32 %v82456, %v2829 (stack39)
        %v84809 = vadd.s32 1, %v84805 (stack39)
        %v84813 = vsel /*vm=*/%vm84800, /*on_true_vy=*/%v84809, /*on_false_vx=*/%v84805 (stack43)
        %v84817 = vadd.s32 1, %v84813 (stack39)
        %v84821 = vsel /*vm=*/%vm84795, /*on_true_vy=*/%v84817, /*on_false_vx=*/%v84813 (stack43)
        %v84826 = vadd.s32 %v84821, %v10 (stack39)
        %v84830 = vadd.s32 %v84791, %v9 (stack39)
        %v84834 = vadd.s32 %v84830, %v84826 (stack39)
        %v84836 = vshll.u32 %v84830, 13 (stack44)
        %v84837 = vshrl.u32 %v84830, 19 (stack45)
        %v84838 = vor.u32 %v84837, %v84836 (stack46)
        %v84839 = vxor.u32 %v84838, %v84834 (stack47)
        %v84842 = vadd.s32 %v84839, %v84834 (stack39)
        %v84844 = vshll.u32 %v84839, 15 (stack44)
        %v84845 = vshrl.u32 %v84839, 17 (stack45)
        %v84846 = vor.u32 %v84845, %v84844 (stack46)
        %v84847 = vxor.u32 %v84846, %v84842 (stack47)
        %v84850 = vadd.s32 %v84847, %v84842 (stack39)
        %v84852 = vshll.u32 %v84847, 26 (stack44)
        %v84853 = vshrl.u32 %v84847, 6 (stack45)
        %v84854 = vor.u32 %v84853, %v84852 (stack46)
        %v84855 = vxor.u32 %v84854, %v84850 (stack47)
        %v84858 = vadd.s32 %v84855, %v84850 (stack39)
        %v84862 = vadd.s32 %v84858, %v9 (stack39)
        %v84864 = vshll.u32 %v84855, 6 (stack44)
        %v84865 = vshrl.u32 %v84855, 26 (stack45)
        %v84866 = vor.u32 %v84865, %v84864 (stack46)
        %v84867 = vxor.u32 %v84866, %v84858 (stack47)
        %v84870 = vadd.s32 %v84867, %v8 (stack39)
        %v84874 = vadd.s32 1, %v84870 (stack39)
        %v84878 = vadd.s32 %v84874, %v84862 (stack39)
        %v84880 = vshll.u32 %v84874, 17 (stack44)
        %v84881 = vshrl.u32 %v84874, 15 (stack45)
        %v84882 = vor.u32 %v84881, %v84880 (stack46)
        %v84883 = vxor.u32 %v84882, %v84878 (stack47)
        %v84886 = vadd.s32 %v84883, %v84878 (stack39)
        %v84888 = vshll.u32 %v84883, 29 (stack44)
        %v84889 = vshrl.u32 %v84883, 3 (stack45)
        %v84890 = vor.u32 %v84889, %v84888 (stack46)
        %v84891 = vxor.u32 %v84890, %v84886 (stack47)
        %v84894 = vadd.s32 %v84891, %v84886 (stack39)
        %v84896 = vshll.u32 %v84891, 16 (stack44)
        %v84897 = vshrl.u32 %v84891, 16 (stack45)
        %v84898 = vor.u32 %v84897, %v84896 (stack46)
        %v84899 = vxor.u32 %v84898, %v84894 (stack47)
        %v84902 = vadd.s32 %v84899, %v84894 (stack39)
        %v84906 = vadd.s32 %v84902, %v8 (stack39)
        %v84908 = vshll.u32 %v84899, 24 (stack44)
        %v84909 = vshrl.u32 %v84899, 8 (stack45)
        %v84910 = vor.u32 %v84909, %v84908 (stack46)
        %v84911 = vxor.u32 %v84910, %v84902 (stack47)
        %v84914 = vadd.s32 %v84911, %v10 (stack39)
        %v84918 = vadd.s32 2, %v84914 (stack39)
        %v84922 = vadd.s32 %v84918, %v84906 (stack39)
        %v84924 = vshll.u32 %v84918, 13 (stack44)
        %v84925 = vshrl.u32 %v84918, 19 (stack45)
        %v84926 = vor.u32 %v84925, %v84924 (stack46)
        %v84927 = vxor.u32 %v84926, %v84922 (stack47)
        %v84930 = vadd.s32 %v84927, %v84922 (stack39)
        %v84932 = vshll.u32 %v84927, 15 (stack44)
        %v84933 = vshrl.u32 %v84927, 17 (stack45)
        %v84934 = vor.u32 %v84933, %v84932 (stack46)
        %v84935 = vxor.u32 %v84934, %v84930 (stack47)
        %v84938 = vadd.s32 %v84935, %v84930 (stack39)
        %v84940 = vshll.u32 %v84935, 26 (stack44)
        %v84941 = vshrl.u32 %v84935, 6 (stack45)
        %v84942 = vor.u32 %v84941, %v84940 (stack46)
        %v84943 = vxor.u32 %v84942, %v84938 (stack47)
        %v84946 = vadd.s32 %v84943, %v84938 (stack39)
        %v84950 = vadd.s32 %v84946, %v10 (stack39)
        %v84952 = vshll.u32 %v84943, 6 (stack44)
        %v84953 = vshrl.u32 %v84943, 26 (stack45)
        %v84954 = vor.u32 %v84953, %v84952 (stack46)
        %v84955 = vxor.u32 %v84954, %v84946 (stack47)
        %v84958 = vadd.s32 %v84955, %v9 (stack39)
        %v84962 = vadd.s32 3, %v84958 (stack39)
        %v84966 = vadd.s32 %v84962, %v84950 (stack39)
        %v84968 = vshll.u32 %v84962, 17 (stack44)
        %v84969 = vshrl.u32 %v84962, 15 (stack45)
        %v84970 = vor.u32 %v84969, %v84968 (stack46)
        %v84971 = vxor.u32 %v84970, %v84966 (stack47)
        %v84974 = vadd.s32 %v84971, %v84966 (stack39)
        %v84976 = vshll.u32 %v84971, 29 (stack44)
        %v84977 = vshrl.u32 %v84971, 3 (stack45)
        %v84978 = vor.u32 %v84977, %v84976 (stack46)
        %v84979 = vxor.u32 %v84978, %v84974 (stack47)
        %v84982 = vadd.s32 %v84979, %v84974 (stack39)
        %v84984 = vshll.u32 %v84979, 16 (stack44)
        %v84985 = vshrl.u32 %v84979, 16 (stack45)
        %v84986 = vor.u32 %v84985, %v84984 (stack46)
        %v84987 = vxor.u32 %v84986, %v84982 (stack47)
        %v84990 = vadd.s32 %v84987, %v84982 (stack39)
        %v84994 = vadd.s32 %v84990, %v9 (stack39)
        %v84996 = vshll.u32 %v84987, 24 (stack44)
        %v84997 = vshrl.u32 %v84987, 8 (stack45)
        %v84998 = vor.u32 %v84997, %v84996 (stack46)
        %v84999 = vxor.u32 %v84998, %v84990 (stack47)
        %v85002 = vadd.s32 %v84999, %v8 (stack39)
        %v85006 = vadd.s32 4, %v85002 (stack39)
        %v85010 = vadd.s32 %v85006, %v84994 (stack39)
        %v85012 = vshll.u32 %v85006, 13 (stack44)
        %v85013 = vshrl.u32 %v85006, 19 (stack45)
        %v85014 = vor.u32 %v85013, %v85012 (stack46)
        %v85015 = vxor.u32 %v85014, %v85010 (stack47)
        %v85018 = vadd.s32 %v85015, %v85010 (stack39)
        %v85020 = vshll.u32 %v85015, 15 (stack44)
        %v85021 = vshrl.u32 %v85015, 17 (stack45)
        %v85022 = vor.u32 %v85021, %v85020 (stack46)
        %v85023 = vxor.u32 %v85022, %v85018 (stack47)
        %v85026 = vadd.s32 %v85023, %v85018 (stack39)
        %v85028 = vshll.u32 %v85023, 26 (stack44)
        %v85029 = vshrl.u32 %v85023, 6 (stack45)
        %v85030 = vor.u32 %v85029, %v85028 (stack46)
        %v85031 = vxor.u32 %v85030, %v85026 (stack47)
        %v85034 = vadd.s32 %v85031, %v85026 (stack39)
        %v85038 = vadd.s32 %v85034, %v8 (stack39)
        %v85040 = vshll.u32 %v85031, 6 (stack44)
        %v85041 = vshrl.u32 %v85031, 26 (stack45)
        %v85042 = vor.u32 %v85041, %v85040 (stack46)
        %v85043 = vxor.u32 %v85042, %v85034 (stack47)
        %v85046 = vadd.s32 %v85043, %v10 (stack39)
        %v85050 = vadd.s32 5, %v85046 (stack39)
        %v85052 = vxor.u32 %v85050, %v85038 (stack47)
        %v85053 = vand.u32.u8 255, %v85052 (stack48)
        %v85054 = vand.u32 65535, %v85053 (stack49)
        %v85055 = vshrl.u32 %v85054, 1 (stack50)
        %v85056 = vor.u32 16256, %v85055 (stack46)
        %v85057 = vand.u32.u16 65535, %v85056 (stack51)
        %v120198 = vadd.low.f32.bf16 -1.0, %v85057 (stack52)
        %v85066 = vmul.f32 2.0, %v120198 (stack53)
        %v85070 = vadd.f32 -0.99609375, %v85066 (stack52)
        %v85074 = vmax.f32 %v85070, -0.99609375 (stack54)
        %v85076 = vand.u32 2147483647, %v85074 (stack55)
        %vm85079 = vcmp.eq.f32.partialorder %v85076, 1.0 (stack56)
        %v85084 = vmul.f32 inf, %v85074 (stack53)
        %v85086 = vxor.u32 2147483648, %v85074 (stack57)
        %v85089 = vmul.f32 %v85086, %v85074 (stack53)
        %v85091 = vadd.f32 1.0, %v85089 (stack58)
        %v85092 = vlog2.pop %v85091 (stack59)
        %v85093 = vmul.f32 0.6931472, %v85092 (stack60)
        %v85094 = vmul.f32 -0.5, %v85089 (stack61)
        %v85095 = vadd.f32 1.0, %v85094 (stack62)
        %v85096 = vmul.f32 %v85095, %v85089 (stack63)
        %v85097 = vand.u32 2147483647, %v85089 (stack64)
        %vm85098 = vcmp.lt.f32.partialorder %v85097, 0.0004427343 (stack65)
        %v85099 = vsel /*vm=*/%vm85098, /*on_true_vy=*/%v85096, /*on_false_vx=*/%v85093 (stack66)
        %v85100 = vxor.u32 2147483648, %v85099 (stack57)
        %vm85103 = vcmp.lt.f32.partialorder %v85100, 5.0 (stack56)
        %v85108 = vsel /*vm=*/%vm85103, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v85112 = vsel /*vm=*/%vm85103, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v85116 = vsel /*vm=*/%vm85103, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v85120 = vsel /*vm=*/%vm85103, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v85124 = vsel /*vm=*/%vm85103, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v85128 = vsel /*vm=*/%vm85103, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v85132 = vsel /*vm=*/%vm85103, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v85136 = vsel /*vm=*/%vm85103, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v85140 = vsel /*vm=*/%vm85103, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v85144 = vadd.f32 -2.5, %v85100 (stack52)
        %v85146 = vrsqrt.pop %v85100 (stack67)
        %v85147 = vmul.f32 %v85146, %v85100 (stack68)
        %vm85148 = vcmp.eq.f32.partialorder %v85100, inf (stack69)
        %v85149 = vsel /*vm=*/%vm85148, /*on_true_vy=*/%v85100, /*on_false_vx=*/%v85147 (stack70)
        %vm85150 = vcmp.eq.f32.partialorder %v85100, 0.0 (stack71)
        %v85151 = vand.u32 2147483648, %v85100 (stack72)
        %v85152 = vsel /*vm=*/%vm85150, /*on_true_vy=*/%v85151, /*on_false_vx=*/%v85149 (stack73)
        %v85155 = vadd.f32 -3.0, %v85152 (stack52)
        %v85159 = vsel /*vm=*/%vm85103, /*on_true_vy=*/%v85144, /*on_false_vx=*/%v85155 (stack43)
        %v85163 = vmul.f32 %v85159, %v85140 (stack53)
        %v85167 = vadd.f32 %v85163, %v85136 (stack52)
        %v85171 = vmul.f32 %v85167, %v85159 (stack53)
        %v85175 = vadd.f32 %v85171, %v85132 (stack52)
        %v85179 = vmul.f32 %v85175, %v85159 (stack53)
        %v85183 = vadd.f32 %v85179, %v85128 (stack52)
        %v85187 = vmul.f32 %v85183, %v85159 (stack53)
        %v85191 = vadd.f32 %v85187, %v85124 (stack52)
        %v85195 = vmul.f32 %v85191, %v85159 (stack53)
        %v85199 = vadd.f32 %v85195, %v85120 (stack52)
        %v85203 = vmul.f32 %v85199, %v85159 (stack53)
        %v85207 = vadd.f32 %v85203, %v85116 (stack52)
        %v85211 = vmul.f32 %v85207, %v85159 (stack53)
        %v85215 = vadd.f32 %v85211, %v85112 (stack52)
        %v85219 = vmul.f32 %v85215, %v85159 (stack53)
        %v85223 = vadd.f32 %v85219, %v85108 (stack52)
        %v85227 = vmul.f32 %v85223, %v85074 (stack53)
        %v85231 = vsel /*vm=*/%vm85079, /*on_true_vy=*/%v85084, /*on_false_vx=*/%v85227 (stack43)
        %v85235 = vmul.f32 1.4140625, %v85231 (stack53)
        %v85238 = vpack.c.bf16 0.0, %v85235 (stack74)
        %120199 = vst [vmem:[%s280 + $0x2d8] sm:$0xf] /*vst_source=*/%v85238 (stack75)
        %v85242 = vadd.s32 %v82473, %v3329 (stack39)
        %v85252 = vadd.s32 %v85242, %v415 (stack39)
        %vm85256 = vcmp.lt.u32.totalorder %v85252, %v85242 (stack42)
        %vm85261 = vcmp.lt.u32.totalorder %v85242, %v3329 (stack42)
        %v85266 = vadd.s32 %v82456, %v3316 (stack39)
        %v85270 = vadd.s32 1, %v85266 (stack39)
        %v85274 = vsel /*vm=*/%vm85261, /*on_true_vy=*/%v85270, /*on_false_vx=*/%v85266 (stack43)
        %v85278 = vadd.s32 1, %v85274 (stack39)
        %v85282 = vsel /*vm=*/%vm85256, /*on_true_vy=*/%v85278, /*on_false_vx=*/%v85274 (stack43)
        %v85287 = vadd.s32 %v85282, %v10 (stack39)
        %v85291 = vadd.s32 %v85252, %v9 (stack39)
        %v85295 = vadd.s32 %v85291, %v85287 (stack39)
        %v85297 = vshll.u32 %v85291, 13 (stack44)
        %v85298 = vshrl.u32 %v85291, 19 (stack45)
        %v85299 = vor.u32 %v85298, %v85297 (stack46)
        %v85300 = vxor.u32 %v85299, %v85295 (stack47)
        %v85303 = vadd.s32 %v85300, %v85295 (stack39)
        %v85305 = vshll.u32 %v85300, 15 (stack44)
        %v85306 = vshrl.u32 %v85300, 17 (stack45)
        %v85307 = vor.u32 %v85306, %v85305 (stack46)
        %v85308 = vxor.u32 %v85307, %v85303 (stack47)
        %v85311 = vadd.s32 %v85308, %v85303 (stack39)
        %v85313 = vshll.u32 %v85308, 26 (stack44)
        %v85314 = vshrl.u32 %v85308, 6 (stack45)
        %v85315 = vor.u32 %v85314, %v85313 (stack46)
        %v85316 = vxor.u32 %v85315, %v85311 (stack47)
        %v85319 = vadd.s32 %v85316, %v85311 (stack39)
        %v85323 = vadd.s32 %v85319, %v9 (stack39)
        %v85325 = vshll.u32 %v85316, 6 (stack44)
        %v85326 = vshrl.u32 %v85316, 26 (stack45)
        %v85327 = vor.u32 %v85326, %v85325 (stack46)
        %v85328 = vxor.u32 %v85327, %v85319 (stack47)
        %v85331 = vadd.s32 %v85328, %v8 (stack39)
        %v85335 = vadd.s32 1, %v85331 (stack39)
        %v85339 = vadd.s32 %v85335, %v85323 (stack39)
        %v85341 = vshll.u32 %v85335, 17 (stack44)
        %v85342 = vshrl.u32 %v85335, 15 (stack45)
        %v85343 = vor.u32 %v85342, %v85341 (stack46)
        %v85344 = vxor.u32 %v85343, %v85339 (stack47)
        %v85347 = vadd.s32 %v85344, %v85339 (stack39)
        %v85349 = vshll.u32 %v85344, 29 (stack44)
        %v85350 = vshrl.u32 %v85344, 3 (stack45)
        %v85351 = vor.u32 %v85350, %v85349 (stack46)
        %v85352 = vxor.u32 %v85351, %v85347 (stack47)
        %v85355 = vadd.s32 %v85352, %v85347 (stack39)
        %v85357 = vshll.u32 %v85352, 16 (stack44)
        %v85358 = vshrl.u32 %v85352, 16 (stack45)
        %v85359 = vor.u32 %v85358, %v85357 (stack46)
        %v85360 = vxor.u32 %v85359, %v85355 (stack47)
        %v85363 = vadd.s32 %v85360, %v85355 (stack39)
        %v85367 = vadd.s32 %v85363, %v8 (stack39)
        %v85369 = vshll.u32 %v85360, 24 (stack44)
        %v85370 = vshrl.u32 %v85360, 8 (stack45)
        %v85371 = vor.u32 %v85370, %v85369 (stack46)
        %v85372 = vxor.u32 %v85371, %v85363 (stack47)
        %v85375 = vadd.s32 %v85372, %v10 (stack39)
        %v85379 = vadd.s32 2, %v85375 (stack39)
        %v85383 = vadd.s32 %v85379, %v85367 (stack39)
        %v85385 = vshll.u32 %v85379, 13 (stack44)
        %v85386 = vshrl.u32 %v85379, 19 (stack45)
        %v85387 = vor.u32 %v85386, %v85385 (stack46)
        %v85388 = vxor.u32 %v85387, %v85383 (stack47)
        %v85391 = vadd.s32 %v85388, %v85383 (stack39)
        %v85393 = vshll.u32 %v85388, 15 (stack44)
        %v85394 = vshrl.u32 %v85388, 17 (stack45)
        %v85395 = vor.u32 %v85394, %v85393 (stack46)
        %v85396 = vxor.u32 %v85395, %v85391 (stack47)
        %v85399 = vadd.s32 %v85396, %v85391 (stack39)
        %v85401 = vshll.u32 %v85396, 26 (stack44)
        %v85402 = vshrl.u32 %v85396, 6 (stack45)
        %v85403 = vor.u32 %v85402, %v85401 (stack46)
        %v85404 = vxor.u32 %v85403, %v85399 (stack47)
        %v85407 = vadd.s32 %v85404, %v85399 (stack39)
        %v85411 = vadd.s32 %v85407, %v10 (stack39)
        %v85413 = vshll.u32 %v85404, 6 (stack44)
        %v85414 = vshrl.u32 %v85404, 26 (stack45)
        %v85415 = vor.u32 %v85414, %v85413 (stack46)
        %v85416 = vxor.u32 %v85415, %v85407 (stack47)
        %v85419 = vadd.s32 %v85416, %v9 (stack39)
        %v85423 = vadd.s32 3, %v85419 (stack39)
        %v85427 = vadd.s32 %v85423, %v85411 (stack39)
        %v85429 = vshll.u32 %v85423, 17 (stack44)
        %v85430 = vshrl.u32 %v85423, 15 (stack45)
        %v85431 = vor.u32 %v85430, %v85429 (stack46)
        %v85432 = vxor.u32 %v85431, %v85427 (stack47)
        %v85435 = vadd.s32 %v85432, %v85427 (stack39)
        %v85437 = vshll.u32 %v85432, 29 (stack44)
        %v85438 = vshrl.u32 %v85432, 3 (stack45)
        %v85439 = vor.u32 %v85438, %v85437 (stack46)
        %v85440 = vxor.u32 %v85439, %v85435 (stack47)
        %v85443 = vadd.s32 %v85440, %v85435 (stack39)
        %v85445 = vshll.u32 %v85440, 16 (stack44)
        %v85446 = vshrl.u32 %v85440, 16 (stack45)
        %v85447 = vor.u32 %v85446, %v85445 (stack46)
        %v85448 = vxor.u32 %v85447, %v85443 (stack47)
        %v85451 = vadd.s32 %v85448, %v85443 (stack39)
        %v85455 = vadd.s32 %v85451, %v9 (stack39)
        %v85457 = vshll.u32 %v85448, 24 (stack44)
        %v85458 = vshrl.u32 %v85448, 8 (stack45)
        %v85459 = vor.u32 %v85458, %v85457 (stack46)
        %v85460 = vxor.u32 %v85459, %v85451 (stack47)
        %v85463 = vadd.s32 %v85460, %v8 (stack39)
        %v85467 = vadd.s32 4, %v85463 (stack39)
        %v85471 = vadd.s32 %v85467, %v85455 (stack39)
        %v85473 = vshll.u32 %v85467, 13 (stack44)
        %v85474 = vshrl.u32 %v85467, 19 (stack45)
        %v85475 = vor.u32 %v85474, %v85473 (stack46)
        %v85476 = vxor.u32 %v85475, %v85471 (stack47)
        %v85479 = vadd.s32 %v85476, %v85471 (stack39)
        %v85481 = vshll.u32 %v85476, 15 (stack44)
        %v85482 = vshrl.u32 %v85476, 17 (stack45)
        %v85483 = vor.u32 %v85482, %v85481 (stack46)
        %v85484 = vxor.u32 %v85483, %v85479 (stack47)
        %v85487 = vadd.s32 %v85484, %v85479 (stack39)
        %v85489 = vshll.u32 %v85484, 26 (stack44)
        %v85490 = vshrl.u32 %v85484, 6 (stack45)
        %v85491 = vor.u32 %v85490, %v85489 (stack46)
        %v85492 = vxor.u32 %v85491, %v85487 (stack47)
        %v85495 = vadd.s32 %v85492, %v85487 (stack39)
        %v85499 = vadd.s32 %v85495, %v8 (stack39)
        %v85501 = vshll.u32 %v85492, 6 (stack44)
        %v85502 = vshrl.u32 %v85492, 26 (stack45)
        %v85503 = vor.u32 %v85502, %v85501 (stack46)
        %v85504 = vxor.u32 %v85503, %v85495 (stack47)
        %v85507 = vadd.s32 %v85504, %v10 (stack39)
        %v85511 = vadd.s32 5, %v85507 (stack39)
        %v85513 = vxor.u32 %v85511, %v85499 (stack47)
        %v85514 = vand.u32.u8 255, %v85513 (stack48)
        %v85515 = vand.u32 65535, %v85514 (stack49)
        %v85516 = vshrl.u32 %v85515, 1 (stack50)
        %v85517 = vor.u32 16256, %v85516 (stack46)
        %v85518 = vand.u32.u16 65535, %v85517 (stack51)
        %v120200 = vadd.low.f32.bf16 -1.0, %v85518 (stack52)
        %v85527 = vmul.f32 2.0, %v120200 (stack53)
        %v85531 = vadd.f32 -0.99609375, %v85527 (stack52)
        %v85535 = vmax.f32 %v85531, -0.99609375 (stack54)
        %v85537 = vand.u32 2147483647, %v85535 (stack55)
        %vm85540 = vcmp.eq.f32.partialorder %v85537, 1.0 (stack56)
        %v85545 = vmul.f32 inf, %v85535 (stack53)
        %v85547 = vxor.u32 2147483648, %v85535 (stack57)
        %v85550 = vmul.f32 %v85547, %v85535 (stack53)
        %v85552 = vadd.f32 1.0, %v85550 (stack58)
        %v85553 = vlog2.pop %v85552 (stack59)
        %v85554 = vmul.f32 0.6931472, %v85553 (stack60)
        %v85555 = vmul.f32 -0.5, %v85550 (stack61)
        %v85556 = vadd.f32 1.0, %v85555 (stack62)
        %v85557 = vmul.f32 %v85556, %v85550 (stack63)
        %v85558 = vand.u32 2147483647, %v85550 (stack64)
        %vm85559 = vcmp.lt.f32.partialorder %v85558, 0.0004427343 (stack65)
        %v85560 = vsel /*vm=*/%vm85559, /*on_true_vy=*/%v85557, /*on_false_vx=*/%v85554 (stack66)
        %v85561 = vxor.u32 2147483648, %v85560 (stack57)
        %vm85564 = vcmp.lt.f32.partialorder %v85561, 5.0 (stack56)
        %v85569 = vsel /*vm=*/%vm85564, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v85573 = vsel /*vm=*/%vm85564, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v85577 = vsel /*vm=*/%vm85564, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v85581 = vsel /*vm=*/%vm85564, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v85585 = vsel /*vm=*/%vm85564, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v85589 = vsel /*vm=*/%vm85564, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v85593 = vsel /*vm=*/%vm85564, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v85597 = vsel /*vm=*/%vm85564, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v85601 = vsel /*vm=*/%vm85564, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v85605 = vadd.f32 -2.5, %v85561 (stack52)
        %v85607 = vrsqrt.pop %v85561 (stack67)
        %v85608 = vmul.f32 %v85607, %v85561 (stack68)
        %vm85609 = vcmp.eq.f32.partialorder %v85561, inf (stack69)
        %v85610 = vsel /*vm=*/%vm85609, /*on_true_vy=*/%v85561, /*on_false_vx=*/%v85608 (stack70)
        %vm85611 = vcmp.eq.f32.partialorder %v85561, 0.0 (stack71)
        %v85612 = vand.u32 2147483648, %v85561 (stack72)
        %v85613 = vsel /*vm=*/%vm85611, /*on_true_vy=*/%v85612, /*on_false_vx=*/%v85610 (stack73)
        %v85616 = vadd.f32 -3.0, %v85613 (stack52)
        %v85620 = vsel /*vm=*/%vm85564, /*on_true_vy=*/%v85605, /*on_false_vx=*/%v85616 (stack43)
        %v85624 = vmul.f32 %v85620, %v85601 (stack53)
        %v85628 = vadd.f32 %v85624, %v85597 (stack52)
        %v85632 = vmul.f32 %v85628, %v85620 (stack53)
        %v85636 = vadd.f32 %v85632, %v85593 (stack52)
        %v85640 = vmul.f32 %v85636, %v85620 (stack53)
        %v85644 = vadd.f32 %v85640, %v85589 (stack52)
        %v85648 = vmul.f32 %v85644, %v85620 (stack53)
        %v85652 = vadd.f32 %v85648, %v85585 (stack52)
        %v85656 = vmul.f32 %v85652, %v85620 (stack53)
        %v85660 = vadd.f32 %v85656, %v85581 (stack52)
        %v85664 = vmul.f32 %v85660, %v85620 (stack53)
        %v85668 = vadd.f32 %v85664, %v85577 (stack52)
        %v85672 = vmul.f32 %v85668, %v85620 (stack53)
        %v85676 = vadd.f32 %v85672, %v85573 (stack52)
        %v85680 = vmul.f32 %v85676, %v85620 (stack53)
        %v85684 = vadd.f32 %v85680, %v85569 (stack52)
        %v85688 = vmul.f32 %v85684, %v85535 (stack53)
        %v85692 = vsel /*vm=*/%vm85540, /*on_true_vy=*/%v85545, /*on_false_vx=*/%v85688 (stack43)
        %v85696 = vmul.f32 1.4140625, %v85692 (stack53)
        %v85699 = vpack.c.bf16 0.0, %v85696 (stack74)
        %120201 = vst [vmem:[%s280 + $0x358] sm:$0xf] /*vst_source=*/%v85699 (stack75)
        %v85703 = vadd.s32 %v82473, %v3816 (stack39)
        %v85713 = vadd.s32 %v85703, %v415 (stack39)
        %vm85717 = vcmp.lt.u32.totalorder %v85713, %v85703 (stack42)
        %vm85722 = vcmp.lt.u32.totalorder %v85703, %v3816 (stack42)
        %v85727 = vadd.s32 %v82456, %v3803 (stack39)
        %v85731 = vadd.s32 1, %v85727 (stack39)
        %v85735 = vsel /*vm=*/%vm85722, /*on_true_vy=*/%v85731, /*on_false_vx=*/%v85727 (stack43)
        %v85739 = vadd.s32 1, %v85735 (stack39)
        %v85743 = vsel /*vm=*/%vm85717, /*on_true_vy=*/%v85739, /*on_false_vx=*/%v85735 (stack43)
        %v85748 = vadd.s32 %v85743, %v10 (stack39)
        %v85752 = vadd.s32 %v85713, %v9 (stack39)
        %v85756 = vadd.s32 %v85752, %v85748 (stack39)
        %v85758 = vshll.u32 %v85752, 13 (stack44)
        %v85759 = vshrl.u32 %v85752, 19 (stack45)
        %v85760 = vor.u32 %v85759, %v85758 (stack46)
        %v85761 = vxor.u32 %v85760, %v85756 (stack47)
        %v85764 = vadd.s32 %v85761, %v85756 (stack39)
        %v85766 = vshll.u32 %v85761, 15 (stack44)
        %v85767 = vshrl.u32 %v85761, 17 (stack45)
        %v85768 = vor.u32 %v85767, %v85766 (stack46)
        %v85769 = vxor.u32 %v85768, %v85764 (stack47)
        %v85772 = vadd.s32 %v85769, %v85764 (stack39)
        %v85774 = vshll.u32 %v85769, 26 (stack44)
        %v85775 = vshrl.u32 %v85769, 6 (stack45)
        %v85776 = vor.u32 %v85775, %v85774 (stack46)
        %v85777 = vxor.u32 %v85776, %v85772 (stack47)
        %v85780 = vadd.s32 %v85777, %v85772 (stack39)
        %v85784 = vadd.s32 %v85780, %v9 (stack39)
        %v85786 = vshll.u32 %v85777, 6 (stack44)
        %v85787 = vshrl.u32 %v85777, 26 (stack45)
        %v85788 = vor.u32 %v85787, %v85786 (stack46)
        %v85789 = vxor.u32 %v85788, %v85780 (stack47)
        %v85792 = vadd.s32 %v85789, %v8 (stack39)
        %v85796 = vadd.s32 1, %v85792 (stack39)
        %v85800 = vadd.s32 %v85796, %v85784 (stack39)
        %v85802 = vshll.u32 %v85796, 17 (stack44)
        %v85803 = vshrl.u32 %v85796, 15 (stack45)
        %v85804 = vor.u32 %v85803, %v85802 (stack46)
        %v85805 = vxor.u32 %v85804, %v85800 (stack47)
        %v85808 = vadd.s32 %v85805, %v85800 (stack39)
        %v85810 = vshll.u32 %v85805, 29 (stack44)
        %v85811 = vshrl.u32 %v85805, 3 (stack45)
        %v85812 = vor.u32 %v85811, %v85810 (stack46)
        %v85813 = vxor.u32 %v85812, %v85808 (stack47)
        %v85816 = vadd.s32 %v85813, %v85808 (stack39)
        %v85818 = vshll.u32 %v85813, 16 (stack44)
        %v85819 = vshrl.u32 %v85813, 16 (stack45)
        %v85820 = vor.u32 %v85819, %v85818 (stack46)
        %v85821 = vxor.u32 %v85820, %v85816 (stack47)
        %v85824 = vadd.s32 %v85821, %v85816 (stack39)
        %v85828 = vadd.s32 %v85824, %v8 (stack39)
        %v85830 = vshll.u32 %v85821, 24 (stack44)
        %v85831 = vshrl.u32 %v85821, 8 (stack45)
        %v85832 = vor.u32 %v85831, %v85830 (stack46)
        %v85833 = vxor.u32 %v85832, %v85824 (stack47)
        %v85836 = vadd.s32 %v85833, %v10 (stack39)
        %v85840 = vadd.s32 2, %v85836 (stack39)
        %v85844 = vadd.s32 %v85840, %v85828 (stack39)
        %v85846 = vshll.u32 %v85840, 13 (stack44)
        %v85847 = vshrl.u32 %v85840, 19 (stack45)
        %v85848 = vor.u32 %v85847, %v85846 (stack46)
        %v85849 = vxor.u32 %v85848, %v85844 (stack47)
        %v85852 = vadd.s32 %v85849, %v85844 (stack39)
        %v85854 = vshll.u32 %v85849, 15 (stack44)
        %v85855 = vshrl.u32 %v85849, 17 (stack45)
        %v85856 = vor.u32 %v85855, %v85854 (stack46)
        %v85857 = vxor.u32 %v85856, %v85852 (stack47)
        %v85860 = vadd.s32 %v85857, %v85852 (stack39)
        %v85862 = vshll.u32 %v85857, 26 (stack44)
        %v85863 = vshrl.u32 %v85857, 6 (stack45)
        %v85864 = vor.u32 %v85863, %v85862 (stack46)
        %v85865 = vxor.u32 %v85864, %v85860 (stack47)
        %v85868 = vadd.s32 %v85865, %v85860 (stack39)
        %v85872 = vadd.s32 %v85868, %v10 (stack39)
        %v85874 = vshll.u32 %v85865, 6 (stack44)
        %v85875 = vshrl.u32 %v85865, 26 (stack45)
        %v85876 = vor.u32 %v85875, %v85874 (stack46)
        %v85877 = vxor.u32 %v85876, %v85868 (stack47)
        %v85880 = vadd.s32 %v85877, %v9 (stack39)
        %v85884 = vadd.s32 3, %v85880 (stack39)
        %v85888 = vadd.s32 %v85884, %v85872 (stack39)
        %v85890 = vshll.u32 %v85884, 17 (stack44)
        %v85891 = vshrl.u32 %v85884, 15 (stack45)
        %v85892 = vor.u32 %v85891, %v85890 (stack46)
        %v85893 = vxor.u32 %v85892, %v85888 (stack47)
        %v85896 = vadd.s32 %v85893, %v85888 (stack39)
        %v85898 = vshll.u32 %v85893, 29 (stack44)
        %v85899 = vshrl.u32 %v85893, 3 (stack45)
        %v85900 = vor.u32 %v85899, %v85898 (stack46)
        %v85901 = vxor.u32 %v85900, %v85896 (stack47)
        %v85904 = vadd.s32 %v85901, %v85896 (stack39)
        %v85906 = vshll.u32 %v85901, 16 (stack44)
        %v85907 = vshrl.u32 %v85901, 16 (stack45)
        %v85908 = vor.u32 %v85907, %v85906 (stack46)
        %v85909 = vxor.u32 %v85908, %v85904 (stack47)
        %v85912 = vadd.s32 %v85909, %v85904 (stack39)
        %v85916 = vadd.s32 %v85912, %v9 (stack39)
        %v85918 = vshll.u32 %v85909, 24 (stack44)
        %v85919 = vshrl.u32 %v85909, 8 (stack45)
        %v85920 = vor.u32 %v85919, %v85918 (stack46)
        %v85921 = vxor.u32 %v85920, %v85912 (stack47)
        %v85924 = vadd.s32 %v85921, %v8 (stack39)
        %v85928 = vadd.s32 4, %v85924 (stack39)
        %v85932 = vadd.s32 %v85928, %v85916 (stack39)
        %v85934 = vshll.u32 %v85928, 13 (stack44)
        %v85935 = vshrl.u32 %v85928, 19 (stack45)
        %v85936 = vor.u32 %v85935, %v85934 (stack46)
        %v85937 = vxor.u32 %v85936, %v85932 (stack47)
        %v85940 = vadd.s32 %v85937, %v85932 (stack39)
        %v85942 = vshll.u32 %v85937, 15 (stack44)
        %v85943 = vshrl.u32 %v85937, 17 (stack45)
        %v85944 = vor.u32 %v85943, %v85942 (stack46)
        %v85945 = vxor.u32 %v85944, %v85940 (stack47)
        %v85948 = vadd.s32 %v85945, %v85940 (stack39)
        %v85950 = vshll.u32 %v85945, 26 (stack44)
        %v85951 = vshrl.u32 %v85945, 6 (stack45)
        %v85952 = vor.u32 %v85951, %v85950 (stack46)
        %v85953 = vxor.u32 %v85952, %v85948 (stack47)
        %v85956 = vadd.s32 %v85953, %v85948 (stack39)
        %v85960 = vadd.s32 %v85956, %v8 (stack39)
        %v85962 = vshll.u32 %v85953, 6 (stack44)
        %v85963 = vshrl.u32 %v85953, 26 (stack45)
        %v85964 = vor.u32 %v85963, %v85962 (stack46)
        %v85965 = vxor.u32 %v85964, %v85956 (stack47)
        %v85968 = vadd.s32 %v85965, %v10 (stack39)
        %v85972 = vadd.s32 5, %v85968 (stack39)
        %v85974 = vxor.u32 %v85972, %v85960 (stack47)
        %v85975 = vand.u32.u8 255, %v85974 (stack48)
        %v85976 = vand.u32 65535, %v85975 (stack49)
        %v85977 = vshrl.u32 %v85976, 1 (stack50)
        %v85978 = vor.u32 16256, %v85977 (stack46)
        %v85979 = vand.u32.u16 65535, %v85978 (stack51)
        %v120202 = vadd.low.f32.bf16 -1.0, %v85979 (stack52)
        %v85988 = vmul.f32 2.0, %v120202 (stack53)
        %v85992 = vadd.f32 -0.99609375, %v85988 (stack52)
        %v85996 = vmax.f32 %v85992, -0.99609375 (stack54)
        %v85998 = vand.u32 2147483647, %v85996 (stack55)
        %vm86001 = vcmp.eq.f32.partialorder %v85998, 1.0 (stack56)
        %v86006 = vmul.f32 inf, %v85996 (stack53)
        %v86008 = vxor.u32 2147483648, %v85996 (stack57)
        %v86011 = vmul.f32 %v86008, %v85996 (stack53)
        %v86013 = vadd.f32 1.0, %v86011 (stack58)
        %v86014 = vlog2.pop %v86013 (stack59)
        %v86015 = vmul.f32 0.6931472, %v86014 (stack60)
        %v86016 = vmul.f32 -0.5, %v86011 (stack61)
        %v86017 = vadd.f32 1.0, %v86016 (stack62)
        %v86018 = vmul.f32 %v86017, %v86011 (stack63)
        %v86019 = vand.u32 2147483647, %v86011 (stack64)
        %vm86020 = vcmp.lt.f32.partialorder %v86019, 0.0004427343 (stack65)
        %v86021 = vsel /*vm=*/%vm86020, /*on_true_vy=*/%v86018, /*on_false_vx=*/%v86015 (stack66)
        %v86022 = vxor.u32 2147483648, %v86021 (stack57)
        %vm86025 = vcmp.lt.f32.partialorder %v86022, 5.0 (stack56)
        %v86030 = vsel /*vm=*/%vm86025, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v86034 = vsel /*vm=*/%vm86025, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v86038 = vsel /*vm=*/%vm86025, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v86042 = vsel /*vm=*/%vm86025, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v86046 = vsel /*vm=*/%vm86025, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v86050 = vsel /*vm=*/%vm86025, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v86054 = vsel /*vm=*/%vm86025, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v86058 = vsel /*vm=*/%vm86025, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v86062 = vsel /*vm=*/%vm86025, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v86066 = vadd.f32 -2.5, %v86022 (stack52)
        %v86068 = vrsqrt.pop %v86022 (stack67)
        %v86069 = vmul.f32 %v86068, %v86022 (stack68)
        %vm86070 = vcmp.eq.f32.partialorder %v86022, inf (stack69)
        %v86071 = vsel /*vm=*/%vm86070, /*on_true_vy=*/%v86022, /*on_false_vx=*/%v86069 (stack70)
        %vm86072 = vcmp.eq.f32.partialorder %v86022, 0.0 (stack71)
        %v86073 = vand.u32 2147483648, %v86022 (stack72)
        %v86074 = vsel /*vm=*/%vm86072, /*on_true_vy=*/%v86073, /*on_false_vx=*/%v86071 (stack73)
        %v86077 = vadd.f32 -3.0, %v86074 (stack52)
        %v86081 = vsel /*vm=*/%vm86025, /*on_true_vy=*/%v86066, /*on_false_vx=*/%v86077 (stack43)
        %v86085 = vmul.f32 %v86081, %v86062 (stack53)
        %v86089 = vadd.f32 %v86085, %v86058 (stack52)
        %v86093 = vmul.f32 %v86089, %v86081 (stack53)
        %v86097 = vadd.f32 %v86093, %v86054 (stack52)
        %v86101 = vmul.f32 %v86097, %v86081 (stack53)
        %v86105 = vadd.f32 %v86101, %v86050 (stack52)
        %v86109 = vmul.f32 %v86105, %v86081 (stack53)
        %v86113 = vadd.f32 %v86109, %v86046 (stack52)
        %v86117 = vmul.f32 %v86113, %v86081 (stack53)
        %v86121 = vadd.f32 %v86117, %v86042 (stack52)
        %v86125 = vmul.f32 %v86121, %v86081 (stack53)
        %v86129 = vadd.f32 %v86125, %v86038 (stack52)
        %v86133 = vmul.f32 %v86129, %v86081 (stack53)
        %v86137 = vadd.f32 %v86133, %v86034 (stack52)
        %v86141 = vmul.f32 %v86137, %v86081 (stack53)
        %v86145 = vadd.f32 %v86141, %v86030 (stack52)
        %v86149 = vmul.f32 %v86145, %v85996 (stack53)
        %v86153 = vsel /*vm=*/%vm86001, /*on_true_vy=*/%v86006, /*on_false_vx=*/%v86149 (stack43)
        %v86157 = vmul.f32 1.4140625, %v86153 (stack53)
        %v86160 = vpack.c.bf16 0.0, %v86157 (stack74)
        %120203 = vst [vmem:[%s280 + $0x3d8] sm:$0xf] /*vst_source=*/%v86160 (stack75)
        %s86162 = sadd.s32 184, %s120390 (stack76)
        %s86163 = sshrl.u32 %s86162, 10 (stack23)
        %p120204 = scmp.gt.s32.totalorder %s86163, 1 (stack24)
        %s86165 = scalar_select /*predicate=*/%p120204, /*on_true=*/1, /*on_false=*/%s86163 (stack25)
        %s86166 = sand.u32 1023, %s86162 /* smod.u32 w/div 1024 */ (stack26)
        %s86167 = sshrl.u32 %s86166, 7 (stack27)
        %s86168 = sand.u32 127, %s86166 /* smod.u32 w/div 128 */ (stack28)
        %s120205 = sshll.u32 %s86165, 3 (stack29)
        %s86170 = scalar_lea.vmem %s3, %s120205 (stack30)
        %s86172 = scalar_lea.vmem %s86170, %s86167 (stack31)
        %v86173 = vld [vmem:[%s86172] ss:$0 sm:$0xff] (stack32)
        %s86174 = sand.u32 255, %s86168 (stack33)
        %s86176 = sor.u32 256, %s86174 (stack34)
        %86177 = vbcast.lane.b32.xlu0 %v86173, %s86176 (stack35)
        %v86178 = vpop.permute.xlu0 %86177 (stack36)
        %s86187 = scalar_lea.vmem %s5, %s120205 (stack30)
        %s86189 = scalar_lea.vmem %s86187, %s86167 (stack31)
        %v86190 = vld [vmem:[%s86189] ss:$0 sm:$0xff] (stack32)
        %86194 = vbcast.lane.b32.xlu0 %v86190, %s86176 (stack35)
        %v86195 = vpop.permute.xlu0 %86194 (stack36)
        %v86198 = vadd.s32 %v86195, %v408 (stack39)
        %v86208 = vadd.s32 %v86198, %v415 (stack39)
        %vm86212 = vcmp.lt.u32.totalorder %v86208, %v86198 (stack42)
        %vm86217 = vcmp.lt.u32.totalorder %v86198, %v408 (stack42)
        %v86222 = vadd.s32 %v86178, %v380 (stack39)
        %v86226 = vadd.s32 1, %v86222 (stack39)
        %v86230 = vsel /*vm=*/%vm86217, /*on_true_vy=*/%v86226, /*on_false_vx=*/%v86222 (stack43)
        %v86234 = vadd.s32 1, %v86230 (stack39)
        %v86238 = vsel /*vm=*/%vm86212, /*on_true_vy=*/%v86234, /*on_false_vx=*/%v86230 (stack43)
        %v86243 = vadd.s32 %v86238, %v10 (stack39)
        %v86247 = vadd.s32 %v86208, %v9 (stack39)
        %v86251 = vadd.s32 %v86247, %v86243 (stack39)
        %v86253 = vshll.u32 %v86247, 13 (stack44)
        %v86254 = vshrl.u32 %v86247, 19 (stack45)
        %v86255 = vor.u32 %v86254, %v86253 (stack46)
        %v86256 = vxor.u32 %v86255, %v86251 (stack47)
        %v86259 = vadd.s32 %v86256, %v86251 (stack39)
        %v86261 = vshll.u32 %v86256, 15 (stack44)
        %v86262 = vshrl.u32 %v86256, 17 (stack45)
        %v86263 = vor.u32 %v86262, %v86261 (stack46)
        %v86264 = vxor.u32 %v86263, %v86259 (stack47)
        %v86267 = vadd.s32 %v86264, %v86259 (stack39)
        %v86269 = vshll.u32 %v86264, 26 (stack44)
        %v86270 = vshrl.u32 %v86264, 6 (stack45)
        %v86271 = vor.u32 %v86270, %v86269 (stack46)
        %v86272 = vxor.u32 %v86271, %v86267 (stack47)
        %v86275 = vadd.s32 %v86272, %v86267 (stack39)
        %v86279 = vadd.s32 %v86275, %v9 (stack39)
        %v86281 = vshll.u32 %v86272, 6 (stack44)
        %v86282 = vshrl.u32 %v86272, 26 (stack45)
        %v86283 = vor.u32 %v86282, %v86281 (stack46)
        %v86284 = vxor.u32 %v86283, %v86275 (stack47)
        %v86287 = vadd.s32 %v86284, %v8 (stack39)
        %v86291 = vadd.s32 1, %v86287 (stack39)
        %v86295 = vadd.s32 %v86291, %v86279 (stack39)
        %v86297 = vshll.u32 %v86291, 17 (stack44)
        %v86298 = vshrl.u32 %v86291, 15 (stack45)
        %v86299 = vor.u32 %v86298, %v86297 (stack46)
        %v86300 = vxor.u32 %v86299, %v86295 (stack47)
        %v86303 = vadd.s32 %v86300, %v86295 (stack39)
        %v86305 = vshll.u32 %v86300, 29 (stack44)
        %v86306 = vshrl.u32 %v86300, 3 (stack45)
        %v86307 = vor.u32 %v86306, %v86305 (stack46)
        %v86308 = vxor.u32 %v86307, %v86303 (stack47)
        %v86311 = vadd.s32 %v86308, %v86303 (stack39)
        %v86313 = vshll.u32 %v86308, 16 (stack44)
        %v86314 = vshrl.u32 %v86308, 16 (stack45)
        %v86315 = vor.u32 %v86314, %v86313 (stack46)
        %v86316 = vxor.u32 %v86315, %v86311 (stack47)
        %v86319 = vadd.s32 %v86316, %v86311 (stack39)
        %v86323 = vadd.s32 %v86319, %v8 (stack39)
        %v86325 = vshll.u32 %v86316, 24 (stack44)
        %v86326 = vshrl.u32 %v86316, 8 (stack45)
        %v86327 = vor.u32 %v86326, %v86325 (stack46)
        %v86328 = vxor.u32 %v86327, %v86319 (stack47)
        %v86331 = vadd.s32 %v86328, %v10 (stack39)
        %v86335 = vadd.s32 2, %v86331 (stack39)
        %v86339 = vadd.s32 %v86335, %v86323 (stack39)
        %v86341 = vshll.u32 %v86335, 13 (stack44)
        %v86342 = vshrl.u32 %v86335, 19 (stack45)
        %v86343 = vor.u32 %v86342, %v86341 (stack46)
        %v86344 = vxor.u32 %v86343, %v86339 (stack47)
        %v86347 = vadd.s32 %v86344, %v86339 (stack39)
        %v86349 = vshll.u32 %v86344, 15 (stack44)
        %v86350 = vshrl.u32 %v86344, 17 (stack45)
        %v86351 = vor.u32 %v86350, %v86349 (stack46)
        %v86352 = vxor.u32 %v86351, %v86347 (stack47)
        %v86355 = vadd.s32 %v86352, %v86347 (stack39)
        %v86357 = vshll.u32 %v86352, 26 (stack44)
        %v86358 = vshrl.u32 %v86352, 6 (stack45)
        %v86359 = vor.u32 %v86358, %v86357 (stack46)
        %v86360 = vxor.u32 %v86359, %v86355 (stack47)
        %v86363 = vadd.s32 %v86360, %v86355 (stack39)
        %v86367 = vadd.s32 %v86363, %v10 (stack39)
        %v86369 = vshll.u32 %v86360, 6 (stack44)
        %v86370 = vshrl.u32 %v86360, 26 (stack45)
        %v86371 = vor.u32 %v86370, %v86369 (stack46)
        %v86372 = vxor.u32 %v86371, %v86363 (stack47)
        %v86375 = vadd.s32 %v86372, %v9 (stack39)
        %v86379 = vadd.s32 3, %v86375 (stack39)
        %v86383 = vadd.s32 %v86379, %v86367 (stack39)
        %v86385 = vshll.u32 %v86379, 17 (stack44)
        %v86386 = vshrl.u32 %v86379, 15 (stack45)
        %v86387 = vor.u32 %v86386, %v86385 (stack46)
        %v86388 = vxor.u32 %v86387, %v86383 (stack47)
        %v86391 = vadd.s32 %v86388, %v86383 (stack39)
        %v86393 = vshll.u32 %v86388, 29 (stack44)
        %v86394 = vshrl.u32 %v86388, 3 (stack45)
        %v86395 = vor.u32 %v86394, %v86393 (stack46)
        %v86396 = vxor.u32 %v86395, %v86391 (stack47)
        %v86399 = vadd.s32 %v86396, %v86391 (stack39)
        %v86401 = vshll.u32 %v86396, 16 (stack44)
        %v86402 = vshrl.u32 %v86396, 16 (stack45)
        %v86403 = vor.u32 %v86402, %v86401 (stack46)
        %v86404 = vxor.u32 %v86403, %v86399 (stack47)
        %v86407 = vadd.s32 %v86404, %v86399 (stack39)
        %v86411 = vadd.s32 %v86407, %v9 (stack39)
        %v86413 = vshll.u32 %v86404, 24 (stack44)
        %v86414 = vshrl.u32 %v86404, 8 (stack45)
        %v86415 = vor.u32 %v86414, %v86413 (stack46)
        %v86416 = vxor.u32 %v86415, %v86407 (stack47)
        %v86419 = vadd.s32 %v86416, %v8 (stack39)
        %v86423 = vadd.s32 4, %v86419 (stack39)
        %v86427 = vadd.s32 %v86423, %v86411 (stack39)
        %v86429 = vshll.u32 %v86423, 13 (stack44)
        %v86430 = vshrl.u32 %v86423, 19 (stack45)
        %v86431 = vor.u32 %v86430, %v86429 (stack46)
        %v86432 = vxor.u32 %v86431, %v86427 (stack47)
        %v86435 = vadd.s32 %v86432, %v86427 (stack39)
        %v86437 = vshll.u32 %v86432, 15 (stack44)
        %v86438 = vshrl.u32 %v86432, 17 (stack45)
        %v86439 = vor.u32 %v86438, %v86437 (stack46)
        %v86440 = vxor.u32 %v86439, %v86435 (stack47)
        %v86443 = vadd.s32 %v86440, %v86435 (stack39)
        %v86445 = vshll.u32 %v86440, 26 (stack44)
        %v86446 = vshrl.u32 %v86440, 6 (stack45)
        %v86447 = vor.u32 %v86446, %v86445 (stack46)
        %v86448 = vxor.u32 %v86447, %v86443 (stack47)
        %v86451 = vadd.s32 %v86448, %v86443 (stack39)
        %v86455 = vadd.s32 %v86451, %v8 (stack39)
        %v86457 = vshll.u32 %v86448, 6 (stack44)
        %v86458 = vshrl.u32 %v86448, 26 (stack45)
        %v86459 = vor.u32 %v86458, %v86457 (stack46)
        %v86460 = vxor.u32 %v86459, %v86451 (stack47)
        %v86463 = vadd.s32 %v86460, %v10 (stack39)
        %v86467 = vadd.s32 5, %v86463 (stack39)
        %v86469 = vxor.u32 %v86467, %v86455 (stack47)
        %v86470 = vand.u32.u8 255, %v86469 (stack48)
        %v86471 = vand.u32 65535, %v86470 (stack49)
        %v86472 = vshrl.u32 %v86471, 1 (stack50)
        %v86473 = vor.u32 16256, %v86472 (stack46)
        %v86474 = vand.u32.u16 65535, %v86473 (stack51)
        %v120208 = vadd.low.f32.bf16 -1.0, %v86474 (stack52)
        %v86483 = vmul.f32 2.0, %v120208 (stack53)
        %v86487 = vadd.f32 -0.99609375, %v86483 (stack52)
        %v86491 = vmax.f32 %v86487, -0.99609375 (stack54)
        %v86493 = vand.u32 2147483647, %v86491 (stack55)
        %vm86496 = vcmp.eq.f32.partialorder %v86493, 1.0 (stack56)
        %v86501 = vmul.f32 inf, %v86491 (stack53)
        %v86503 = vxor.u32 2147483648, %v86491 (stack57)
        %v86506 = vmul.f32 %v86503, %v86491 (stack53)
        %v86508 = vadd.f32 1.0, %v86506 (stack58)
        %v86509 = vlog2.pop %v86508 (stack59)
        %v86510 = vmul.f32 0.6931472, %v86509 (stack60)
        %v86511 = vmul.f32 -0.5, %v86506 (stack61)
        %v86512 = vadd.f32 1.0, %v86511 (stack62)
        %v86513 = vmul.f32 %v86512, %v86506 (stack63)
        %v86514 = vand.u32 2147483647, %v86506 (stack64)
        %vm86515 = vcmp.lt.f32.partialorder %v86514, 0.0004427343 (stack65)
        %v86516 = vsel /*vm=*/%vm86515, /*on_true_vy=*/%v86513, /*on_false_vx=*/%v86510 (stack66)
        %v86517 = vxor.u32 2147483648, %v86516 (stack57)
        %vm86520 = vcmp.lt.f32.partialorder %v86517, 5.0 (stack56)
        %v86525 = vsel /*vm=*/%vm86520, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v86529 = vsel /*vm=*/%vm86520, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v86533 = vsel /*vm=*/%vm86520, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v86537 = vsel /*vm=*/%vm86520, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v86541 = vsel /*vm=*/%vm86520, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v86545 = vsel /*vm=*/%vm86520, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v86549 = vsel /*vm=*/%vm86520, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v86553 = vsel /*vm=*/%vm86520, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v86557 = vsel /*vm=*/%vm86520, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v86561 = vadd.f32 -2.5, %v86517 (stack52)
        %v86563 = vrsqrt.pop %v86517 (stack67)
        %v86564 = vmul.f32 %v86563, %v86517 (stack68)
        %vm86565 = vcmp.eq.f32.partialorder %v86517, inf (stack69)
        %v86566 = vsel /*vm=*/%vm86565, /*on_true_vy=*/%v86517, /*on_false_vx=*/%v86564 (stack70)
        %vm86567 = vcmp.eq.f32.partialorder %v86517, 0.0 (stack71)
        %v86568 = vand.u32 2147483648, %v86517 (stack72)
        %v86569 = vsel /*vm=*/%vm86567, /*on_true_vy=*/%v86568, /*on_false_vx=*/%v86566 (stack73)
        %v86572 = vadd.f32 -3.0, %v86569 (stack52)
        %v86576 = vsel /*vm=*/%vm86520, /*on_true_vy=*/%v86561, /*on_false_vx=*/%v86572 (stack43)
        %v86580 = vmul.f32 %v86576, %v86557 (stack53)
        %v86584 = vadd.f32 %v86580, %v86553 (stack52)
        %v86588 = vmul.f32 %v86584, %v86576 (stack53)
        %v86592 = vadd.f32 %v86588, %v86549 (stack52)
        %v86596 = vmul.f32 %v86592, %v86576 (stack53)
        %v86600 = vadd.f32 %v86596, %v86545 (stack52)
        %v86604 = vmul.f32 %v86600, %v86576 (stack53)
        %v86608 = vadd.f32 %v86604, %v86541 (stack52)
        %v86612 = vmul.f32 %v86608, %v86576 (stack53)
        %v86616 = vadd.f32 %v86612, %v86537 (stack52)
        %v86620 = vmul.f32 %v86616, %v86576 (stack53)
        %v86624 = vadd.f32 %v86620, %v86533 (stack52)
        %v86628 = vmul.f32 %v86624, %v86576 (stack53)
        %v86632 = vadd.f32 %v86628, %v86529 (stack52)
        %v86636 = vmul.f32 %v86632, %v86576 (stack53)
        %v86640 = vadd.f32 %v86636, %v86525 (stack52)
        %v86644 = vmul.f32 %v86640, %v86491 (stack53)
        %v86648 = vsel /*vm=*/%vm86496, /*on_true_vy=*/%v86501, /*on_false_vx=*/%v86644 (stack43)
        %v86652 = vmul.f32 1.4140625, %v86648 (stack53)
        %v86655 = vpack.c.bf16 0.0, %v86652 (stack74)
        %120209 = vst [vmem:[%s280 + $0x5c] sm:$0xf] /*vst_source=*/%v86655 (stack75)
        %v86659 = vadd.s32 %v86195, %v894 (stack39)
        %v86669 = vadd.s32 %v86659, %v415 (stack39)
        %vm86673 = vcmp.lt.u32.totalorder %v86669, %v86659 (stack42)
        %vm86678 = vcmp.lt.u32.totalorder %v86659, %v894 (stack42)
        %v86683 = vadd.s32 %v86178, %v881 (stack39)
        %v86687 = vadd.s32 1, %v86683 (stack39)
        %v86691 = vsel /*vm=*/%vm86678, /*on_true_vy=*/%v86687, /*on_false_vx=*/%v86683 (stack43)
        %v86695 = vadd.s32 1, %v86691 (stack39)
        %v86699 = vsel /*vm=*/%vm86673, /*on_true_vy=*/%v86695, /*on_false_vx=*/%v86691 (stack43)
        %v86704 = vadd.s32 %v86699, %v10 (stack39)
        %v86708 = vadd.s32 %v86669, %v9 (stack39)
        %v86712 = vadd.s32 %v86708, %v86704 (stack39)
        %v86714 = vshll.u32 %v86708, 13 (stack44)
        %v86715 = vshrl.u32 %v86708, 19 (stack45)
        %v86716 = vor.u32 %v86715, %v86714 (stack46)
        %v86717 = vxor.u32 %v86716, %v86712 (stack47)
        %v86720 = vadd.s32 %v86717, %v86712 (stack39)
        %v86722 = vshll.u32 %v86717, 15 (stack44)
        %v86723 = vshrl.u32 %v86717, 17 (stack45)
        %v86724 = vor.u32 %v86723, %v86722 (stack46)
        %v86725 = vxor.u32 %v86724, %v86720 (stack47)
        %v86728 = vadd.s32 %v86725, %v86720 (stack39)
        %v86730 = vshll.u32 %v86725, 26 (stack44)
        %v86731 = vshrl.u32 %v86725, 6 (stack45)
        %v86732 = vor.u32 %v86731, %v86730 (stack46)
        %v86733 = vxor.u32 %v86732, %v86728 (stack47)
        %v86736 = vadd.s32 %v86733, %v86728 (stack39)
        %v86740 = vadd.s32 %v86736, %v9 (stack39)
        %v86742 = vshll.u32 %v86733, 6 (stack44)
        %v86743 = vshrl.u32 %v86733, 26 (stack45)
        %v86744 = vor.u32 %v86743, %v86742 (stack46)
        %v86745 = vxor.u32 %v86744, %v86736 (stack47)
        %v86748 = vadd.s32 %v86745, %v8 (stack39)
        %v86752 = vadd.s32 1, %v86748 (stack39)
        %v86756 = vadd.s32 %v86752, %v86740 (stack39)
        %v86758 = vshll.u32 %v86752, 17 (stack44)
        %v86759 = vshrl.u32 %v86752, 15 (stack45)
        %v86760 = vor.u32 %v86759, %v86758 (stack46)
        %v86761 = vxor.u32 %v86760, %v86756 (stack47)
        %v86764 = vadd.s32 %v86761, %v86756 (stack39)
        %v86766 = vshll.u32 %v86761, 29 (stack44)
        %v86767 = vshrl.u32 %v86761, 3 (stack45)
        %v86768 = vor.u32 %v86767, %v86766 (stack46)
        %v86769 = vxor.u32 %v86768, %v86764 (stack47)
        %v86772 = vadd.s32 %v86769, %v86764 (stack39)
        %v86774 = vshll.u32 %v86769, 16 (stack44)
        %v86775 = vshrl.u32 %v86769, 16 (stack45)
        %v86776 = vor.u32 %v86775, %v86774 (stack46)
        %v86777 = vxor.u32 %v86776, %v86772 (stack47)
        %v86780 = vadd.s32 %v86777, %v86772 (stack39)
        %v86784 = vadd.s32 %v86780, %v8 (stack39)
        %v86786 = vshll.u32 %v86777, 24 (stack44)
        %v86787 = vshrl.u32 %v86777, 8 (stack45)
        %v86788 = vor.u32 %v86787, %v86786 (stack46)
        %v86789 = vxor.u32 %v86788, %v86780 (stack47)
        %v86792 = vadd.s32 %v86789, %v10 (stack39)
        %v86796 = vadd.s32 2, %v86792 (stack39)
        %v86800 = vadd.s32 %v86796, %v86784 (stack39)
        %v86802 = vshll.u32 %v86796, 13 (stack44)
        %v86803 = vshrl.u32 %v86796, 19 (stack45)
        %v86804 = vor.u32 %v86803, %v86802 (stack46)
        %v86805 = vxor.u32 %v86804, %v86800 (stack47)
        %v86808 = vadd.s32 %v86805, %v86800 (stack39)
        %v86810 = vshll.u32 %v86805, 15 (stack44)
        %v86811 = vshrl.u32 %v86805, 17 (stack45)
        %v86812 = vor.u32 %v86811, %v86810 (stack46)
        %v86813 = vxor.u32 %v86812, %v86808 (stack47)
        %v86816 = vadd.s32 %v86813, %v86808 (stack39)
        %v86818 = vshll.u32 %v86813, 26 (stack44)
        %v86819 = vshrl.u32 %v86813, 6 (stack45)
        %v86820 = vor.u32 %v86819, %v86818 (stack46)
        %v86821 = vxor.u32 %v86820, %v86816 (stack47)
        %v86824 = vadd.s32 %v86821, %v86816 (stack39)
        %v86828 = vadd.s32 %v86824, %v10 (stack39)
        %v86830 = vshll.u32 %v86821, 6 (stack44)
        %v86831 = vshrl.u32 %v86821, 26 (stack45)
        %v86832 = vor.u32 %v86831, %v86830 (stack46)
        %v86833 = vxor.u32 %v86832, %v86824 (stack47)
        %v86836 = vadd.s32 %v86833, %v9 (stack39)
        %v86840 = vadd.s32 3, %v86836 (stack39)
        %v86844 = vadd.s32 %v86840, %v86828 (stack39)
        %v86846 = vshll.u32 %v86840, 17 (stack44)
        %v86847 = vshrl.u32 %v86840, 15 (stack45)
        %v86848 = vor.u32 %v86847, %v86846 (stack46)
        %v86849 = vxor.u32 %v86848, %v86844 (stack47)
        %v86852 = vadd.s32 %v86849, %v86844 (stack39)
        %v86854 = vshll.u32 %v86849, 29 (stack44)
        %v86855 = vshrl.u32 %v86849, 3 (stack45)
        %v86856 = vor.u32 %v86855, %v86854 (stack46)
        %v86857 = vxor.u32 %v86856, %v86852 (stack47)
        %v86860 = vadd.s32 %v86857, %v86852 (stack39)
        %v86862 = vshll.u32 %v86857, 16 (stack44)
        %v86863 = vshrl.u32 %v86857, 16 (stack45)
        %v86864 = vor.u32 %v86863, %v86862 (stack46)
        %v86865 = vxor.u32 %v86864, %v86860 (stack47)
        %v86868 = vadd.s32 %v86865, %v86860 (stack39)
        %v86872 = vadd.s32 %v86868, %v9 (stack39)
        %v86874 = vshll.u32 %v86865, 24 (stack44)
        %v86875 = vshrl.u32 %v86865, 8 (stack45)
        %v86876 = vor.u32 %v86875, %v86874 (stack46)
        %v86877 = vxor.u32 %v86876, %v86868 (stack47)
        %v86880 = vadd.s32 %v86877, %v8 (stack39)
        %v86884 = vadd.s32 4, %v86880 (stack39)
        %v86888 = vadd.s32 %v86884, %v86872 (stack39)
        %v86890 = vshll.u32 %v86884, 13 (stack44)
        %v86891 = vshrl.u32 %v86884, 19 (stack45)
        %v86892 = vor.u32 %v86891, %v86890 (stack46)
        %v86893 = vxor.u32 %v86892, %v86888 (stack47)
        %v86896 = vadd.s32 %v86893, %v86888 (stack39)
        %v86898 = vshll.u32 %v86893, 15 (stack44)
        %v86899 = vshrl.u32 %v86893, 17 (stack45)
        %v86900 = vor.u32 %v86899, %v86898 (stack46)
        %v86901 = vxor.u32 %v86900, %v86896 (stack47)
        %v86904 = vadd.s32 %v86901, %v86896 (stack39)
        %v86906 = vshll.u32 %v86901, 26 (stack44)
        %v86907 = vshrl.u32 %v86901, 6 (stack45)
        %v86908 = vor.u32 %v86907, %v86906 (stack46)
        %v86909 = vxor.u32 %v86908, %v86904 (stack47)
        %v86912 = vadd.s32 %v86909, %v86904 (stack39)
        %v86916 = vadd.s32 %v86912, %v8 (stack39)
        %v86918 = vshll.u32 %v86909, 6 (stack44)
        %v86919 = vshrl.u32 %v86909, 26 (stack45)
        %v86920 = vor.u32 %v86919, %v86918 (stack46)
        %v86921 = vxor.u32 %v86920, %v86912 (stack47)
        %v86924 = vadd.s32 %v86921, %v10 (stack39)
        %v86928 = vadd.s32 5, %v86924 (stack39)
        %v86930 = vxor.u32 %v86928, %v86916 (stack47)
        %v86931 = vand.u32.u8 255, %v86930 (stack48)
        %v86932 = vand.u32 65535, %v86931 (stack49)
        %v86933 = vshrl.u32 %v86932, 1 (stack50)
        %v86934 = vor.u32 16256, %v86933 (stack46)
        %v86935 = vand.u32.u16 65535, %v86934 (stack51)
        %v120210 = vadd.low.f32.bf16 -1.0, %v86935 (stack52)
        %v86944 = vmul.f32 2.0, %v120210 (stack53)
        %v86948 = vadd.f32 -0.99609375, %v86944 (stack52)
        %v86952 = vmax.f32 %v86948, -0.99609375 (stack54)
        %v86954 = vand.u32 2147483647, %v86952 (stack55)
        %vm86957 = vcmp.eq.f32.partialorder %v86954, 1.0 (stack56)
        %v86962 = vmul.f32 inf, %v86952 (stack53)
        %v86964 = vxor.u32 2147483648, %v86952 (stack57)
        %v86967 = vmul.f32 %v86964, %v86952 (stack53)
        %v86969 = vadd.f32 1.0, %v86967 (stack58)
        %v86970 = vlog2.pop %v86969 (stack59)
        %v86971 = vmul.f32 0.6931472, %v86970 (stack60)
        %v86972 = vmul.f32 -0.5, %v86967 (stack61)
        %v86973 = vadd.f32 1.0, %v86972 (stack62)
        %v86974 = vmul.f32 %v86973, %v86967 (stack63)
        %v86975 = vand.u32 2147483647, %v86967 (stack64)
        %vm86976 = vcmp.lt.f32.partialorder %v86975, 0.0004427343 (stack65)
        %v86977 = vsel /*vm=*/%vm86976, /*on_true_vy=*/%v86974, /*on_false_vx=*/%v86971 (stack66)
        %v86978 = vxor.u32 2147483648, %v86977 (stack57)
        %vm86981 = vcmp.lt.f32.partialorder %v86978, 5.0 (stack56)
        %v86986 = vsel /*vm=*/%vm86981, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v86990 = vsel /*vm=*/%vm86981, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v86994 = vsel /*vm=*/%vm86981, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v86998 = vsel /*vm=*/%vm86981, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v87002 = vsel /*vm=*/%vm86981, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v87006 = vsel /*vm=*/%vm86981, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v87010 = vsel /*vm=*/%vm86981, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v87014 = vsel /*vm=*/%vm86981, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v87018 = vsel /*vm=*/%vm86981, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v87022 = vadd.f32 -2.5, %v86978 (stack52)
        %v87024 = vrsqrt.pop %v86978 (stack67)
        %v87025 = vmul.f32 %v87024, %v86978 (stack68)
        %vm87026 = vcmp.eq.f32.partialorder %v86978, inf (stack69)
        %v87027 = vsel /*vm=*/%vm87026, /*on_true_vy=*/%v86978, /*on_false_vx=*/%v87025 (stack70)
        %vm87028 = vcmp.eq.f32.partialorder %v86978, 0.0 (stack71)
        %v87029 = vand.u32 2147483648, %v86978 (stack72)
        %v87030 = vsel /*vm=*/%vm87028, /*on_true_vy=*/%v87029, /*on_false_vx=*/%v87027 (stack73)
        %v87033 = vadd.f32 -3.0, %v87030 (stack52)
        %v87037 = vsel /*vm=*/%vm86981, /*on_true_vy=*/%v87022, /*on_false_vx=*/%v87033 (stack43)
        %v87041 = vmul.f32 %v87037, %v87018 (stack53)
        %v87045 = vadd.f32 %v87041, %v87014 (stack52)
        %v87049 = vmul.f32 %v87045, %v87037 (stack53)
        %v87053 = vadd.f32 %v87049, %v87010 (stack52)
        %v87057 = vmul.f32 %v87053, %v87037 (stack53)
        %v87061 = vadd.f32 %v87057, %v87006 (stack52)
        %v87065 = vmul.f32 %v87061, %v87037 (stack53)
        %v87069 = vadd.f32 %v87065, %v87002 (stack52)
        %v87073 = vmul.f32 %v87069, %v87037 (stack53)
        %v87077 = vadd.f32 %v87073, %v86998 (stack52)
        %v87081 = vmul.f32 %v87077, %v87037 (stack53)
        %v87085 = vadd.f32 %v87081, %v86994 (stack52)
        %v87089 = vmul.f32 %v87085, %v87037 (stack53)
        %v87093 = vadd.f32 %v87089, %v86990 (stack52)
        %v87097 = vmul.f32 %v87093, %v87037 (stack53)
        %v87101 = vadd.f32 %v87097, %v86986 (stack52)
        %v87105 = vmul.f32 %v87101, %v86952 (stack53)
        %v87109 = vsel /*vm=*/%vm86957, /*on_true_vy=*/%v86962, /*on_false_vx=*/%v87105 (stack43)
        %v87113 = vmul.f32 1.4140625, %v87109 (stack53)
        %v87116 = vpack.c.bf16 0.0, %v87113 (stack74)
        %120211 = vst [vmem:[%s280 + $0xdc] sm:$0xf] /*vst_source=*/%v87116 (stack75)
        %v87120 = vadd.s32 %v86195, %v1381 (stack39)
        %v87130 = vadd.s32 %v87120, %v415 (stack39)
        %vm87134 = vcmp.lt.u32.totalorder %v87130, %v87120 (stack42)
        %vm87139 = vcmp.lt.u32.totalorder %v87120, %v1381 (stack42)
        %v87144 = vadd.s32 %v86178, %v1368 (stack39)
        %v87148 = vadd.s32 1, %v87144 (stack39)
        %v87152 = vsel /*vm=*/%vm87139, /*on_true_vy=*/%v87148, /*on_false_vx=*/%v87144 (stack43)
        %v87156 = vadd.s32 1, %v87152 (stack39)
        %v87160 = vsel /*vm=*/%vm87134, /*on_true_vy=*/%v87156, /*on_false_vx=*/%v87152 (stack43)
        %v87165 = vadd.s32 %v87160, %v10 (stack39)
        %v87169 = vadd.s32 %v87130, %v9 (stack39)
        %v87173 = vadd.s32 %v87169, %v87165 (stack39)
        %v87175 = vshll.u32 %v87169, 13 (stack44)
        %v87176 = vshrl.u32 %v87169, 19 (stack45)
        %v87177 = vor.u32 %v87176, %v87175 (stack46)
        %v87178 = vxor.u32 %v87177, %v87173 (stack47)
        %v87181 = vadd.s32 %v87178, %v87173 (stack39)
        %v87183 = vshll.u32 %v87178, 15 (stack44)
        %v87184 = vshrl.u32 %v87178, 17 (stack45)
        %v87185 = vor.u32 %v87184, %v87183 (stack46)
        %v87186 = vxor.u32 %v87185, %v87181 (stack47)
        %v87189 = vadd.s32 %v87186, %v87181 (stack39)
        %v87191 = vshll.u32 %v87186, 26 (stack44)
        %v87192 = vshrl.u32 %v87186, 6 (stack45)
        %v87193 = vor.u32 %v87192, %v87191 (stack46)
        %v87194 = vxor.u32 %v87193, %v87189 (stack47)
        %v87197 = vadd.s32 %v87194, %v87189 (stack39)
        %v87201 = vadd.s32 %v87197, %v9 (stack39)
        %v87203 = vshll.u32 %v87194, 6 (stack44)
        %v87204 = vshrl.u32 %v87194, 26 (stack45)
        %v87205 = vor.u32 %v87204, %v87203 (stack46)
        %v87206 = vxor.u32 %v87205, %v87197 (stack47)
        %v87209 = vadd.s32 %v87206, %v8 (stack39)
        %v87213 = vadd.s32 1, %v87209 (stack39)
        %v87217 = vadd.s32 %v87213, %v87201 (stack39)
        %v87219 = vshll.u32 %v87213, 17 (stack44)
        %v87220 = vshrl.u32 %v87213, 15 (stack45)
        %v87221 = vor.u32 %v87220, %v87219 (stack46)
        %v87222 = vxor.u32 %v87221, %v87217 (stack47)
        %v87225 = vadd.s32 %v87222, %v87217 (stack39)
        %v87227 = vshll.u32 %v87222, 29 (stack44)
        %v87228 = vshrl.u32 %v87222, 3 (stack45)
        %v87229 = vor.u32 %v87228, %v87227 (stack46)
        %v87230 = vxor.u32 %v87229, %v87225 (stack47)
        %v87233 = vadd.s32 %v87230, %v87225 (stack39)
        %v87235 = vshll.u32 %v87230, 16 (stack44)
        %v87236 = vshrl.u32 %v87230, 16 (stack45)
        %v87237 = vor.u32 %v87236, %v87235 (stack46)
        %v87238 = vxor.u32 %v87237, %v87233 (stack47)
        %v87241 = vadd.s32 %v87238, %v87233 (stack39)
        %v87245 = vadd.s32 %v87241, %v8 (stack39)
        %v87247 = vshll.u32 %v87238, 24 (stack44)
        %v87248 = vshrl.u32 %v87238, 8 (stack45)
        %v87249 = vor.u32 %v87248, %v87247 (stack46)
        %v87250 = vxor.u32 %v87249, %v87241 (stack47)
        %v87253 = vadd.s32 %v87250, %v10 (stack39)
        %v87257 = vadd.s32 2, %v87253 (stack39)
        %v87261 = vadd.s32 %v87257, %v87245 (stack39)
        %v87263 = vshll.u32 %v87257, 13 (stack44)
        %v87264 = vshrl.u32 %v87257, 19 (stack45)
        %v87265 = vor.u32 %v87264, %v87263 (stack46)
        %v87266 = vxor.u32 %v87265, %v87261 (stack47)
        %v87269 = vadd.s32 %v87266, %v87261 (stack39)
        %v87271 = vshll.u32 %v87266, 15 (stack44)
        %v87272 = vshrl.u32 %v87266, 17 (stack45)
        %v87273 = vor.u32 %v87272, %v87271 (stack46)
        %v87274 = vxor.u32 %v87273, %v87269 (stack47)
        %v87277 = vadd.s32 %v87274, %v87269 (stack39)
        %v87279 = vshll.u32 %v87274, 26 (stack44)
        %v87280 = vshrl.u32 %v87274, 6 (stack45)
        %v87281 = vor.u32 %v87280, %v87279 (stack46)
        %v87282 = vxor.u32 %v87281, %v87277 (stack47)
        %v87285 = vadd.s32 %v87282, %v87277 (stack39)
        %v87289 = vadd.s32 %v87285, %v10 (stack39)
        %v87291 = vshll.u32 %v87282, 6 (stack44)
        %v87292 = vshrl.u32 %v87282, 26 (stack45)
        %v87293 = vor.u32 %v87292, %v87291 (stack46)
        %v87294 = vxor.u32 %v87293, %v87285 (stack47)
        %v87297 = vadd.s32 %v87294, %v9 (stack39)
        %v87301 = vadd.s32 3, %v87297 (stack39)
        %v87305 = vadd.s32 %v87301, %v87289 (stack39)
        %v87307 = vshll.u32 %v87301, 17 (stack44)
        %v87308 = vshrl.u32 %v87301, 15 (stack45)
        %v87309 = vor.u32 %v87308, %v87307 (stack46)
        %v87310 = vxor.u32 %v87309, %v87305 (stack47)
        %v87313 = vadd.s32 %v87310, %v87305 (stack39)
        %v87315 = vshll.u32 %v87310, 29 (stack44)
        %v87316 = vshrl.u32 %v87310, 3 (stack45)
        %v87317 = vor.u32 %v87316, %v87315 (stack46)
        %v87318 = vxor.u32 %v87317, %v87313 (stack47)
        %v87321 = vadd.s32 %v87318, %v87313 (stack39)
        %v87323 = vshll.u32 %v87318, 16 (stack44)
        %v87324 = vshrl.u32 %v87318, 16 (stack45)
        %v87325 = vor.u32 %v87324, %v87323 (stack46)
        %v87326 = vxor.u32 %v87325, %v87321 (stack47)
        %v87329 = vadd.s32 %v87326, %v87321 (stack39)
        %v87333 = vadd.s32 %v87329, %v9 (stack39)
        %v87335 = vshll.u32 %v87326, 24 (stack44)
        %v87336 = vshrl.u32 %v87326, 8 (stack45)
        %v87337 = vor.u32 %v87336, %v87335 (stack46)
        %v87338 = vxor.u32 %v87337, %v87329 (stack47)
        %v87341 = vadd.s32 %v87338, %v8 (stack39)
        %v87345 = vadd.s32 4, %v87341 (stack39)
        %v87349 = vadd.s32 %v87345, %v87333 (stack39)
        %v87351 = vshll.u32 %v87345, 13 (stack44)
        %v87352 = vshrl.u32 %v87345, 19 (stack45)
        %v87353 = vor.u32 %v87352, %v87351 (stack46)
        %v87354 = vxor.u32 %v87353, %v87349 (stack47)
        %v87357 = vadd.s32 %v87354, %v87349 (stack39)
        %v87359 = vshll.u32 %v87354, 15 (stack44)
        %v87360 = vshrl.u32 %v87354, 17 (stack45)
        %v87361 = vor.u32 %v87360, %v87359 (stack46)
        %v87362 = vxor.u32 %v87361, %v87357 (stack47)
        %v87365 = vadd.s32 %v87362, %v87357 (stack39)
        %v87367 = vshll.u32 %v87362, 26 (stack44)
        %v87368 = vshrl.u32 %v87362, 6 (stack45)
        %v87369 = vor.u32 %v87368, %v87367 (stack46)
        %v87370 = vxor.u32 %v87369, %v87365 (stack47)
        %v87373 = vadd.s32 %v87370, %v87365 (stack39)
        %v87377 = vadd.s32 %v87373, %v8 (stack39)
        %v87379 = vshll.u32 %v87370, 6 (stack44)
        %v87380 = vshrl.u32 %v87370, 26 (stack45)
        %v87381 = vor.u32 %v87380, %v87379 (stack46)
        %v87382 = vxor.u32 %v87381, %v87373 (stack47)
        %v87385 = vadd.s32 %v87382, %v10 (stack39)
        %v87389 = vadd.s32 5, %v87385 (stack39)
        %v87391 = vxor.u32 %v87389, %v87377 (stack47)
        %v87392 = vand.u32.u8 255, %v87391 (stack48)
        %v87393 = vand.u32 65535, %v87392 (stack49)
        %v87394 = vshrl.u32 %v87393, 1 (stack50)
        %v87395 = vor.u32 16256, %v87394 (stack46)
        %v87396 = vand.u32.u16 65535, %v87395 (stack51)
        %v120212 = vadd.low.f32.bf16 -1.0, %v87396 (stack52)
        %v87405 = vmul.f32 2.0, %v120212 (stack53)
        %v87409 = vadd.f32 -0.99609375, %v87405 (stack52)
        %v87413 = vmax.f32 %v87409, -0.99609375 (stack54)
        %v87415 = vand.u32 2147483647, %v87413 (stack55)
        %vm87418 = vcmp.eq.f32.partialorder %v87415, 1.0 (stack56)
        %v87423 = vmul.f32 inf, %v87413 (stack53)
        %v87425 = vxor.u32 2147483648, %v87413 (stack57)
        %v87428 = vmul.f32 %v87425, %v87413 (stack53)
        %v87430 = vadd.f32 1.0, %v87428 (stack58)
        %v87431 = vlog2.pop %v87430 (stack59)
        %v87432 = vmul.f32 0.6931472, %v87431 (stack60)
        %v87433 = vmul.f32 -0.5, %v87428 (stack61)
        %v87434 = vadd.f32 1.0, %v87433 (stack62)
        %v87435 = vmul.f32 %v87434, %v87428 (stack63)
        %v87436 = vand.u32 2147483647, %v87428 (stack64)
        %vm87437 = vcmp.lt.f32.partialorder %v87436, 0.0004427343 (stack65)
        %v87438 = vsel /*vm=*/%vm87437, /*on_true_vy=*/%v87435, /*on_false_vx=*/%v87432 (stack66)
        %v87439 = vxor.u32 2147483648, %v87438 (stack57)
        %vm87442 = vcmp.lt.f32.partialorder %v87439, 5.0 (stack56)
        %v87447 = vsel /*vm=*/%vm87442, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v87451 = vsel /*vm=*/%vm87442, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v87455 = vsel /*vm=*/%vm87442, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v87459 = vsel /*vm=*/%vm87442, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v87463 = vsel /*vm=*/%vm87442, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v87467 = vsel /*vm=*/%vm87442, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v87471 = vsel /*vm=*/%vm87442, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v87475 = vsel /*vm=*/%vm87442, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v87479 = vsel /*vm=*/%vm87442, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v87483 = vadd.f32 -2.5, %v87439 (stack52)
        %v87485 = vrsqrt.pop %v87439 (stack67)
        %v87486 = vmul.f32 %v87485, %v87439 (stack68)
        %vm87487 = vcmp.eq.f32.partialorder %v87439, inf (stack69)
        %v87488 = vsel /*vm=*/%vm87487, /*on_true_vy=*/%v87439, /*on_false_vx=*/%v87486 (stack70)
        %vm87489 = vcmp.eq.f32.partialorder %v87439, 0.0 (stack71)
        %v87490 = vand.u32 2147483648, %v87439 (stack72)
        %v87491 = vsel /*vm=*/%vm87489, /*on_true_vy=*/%v87490, /*on_false_vx=*/%v87488 (stack73)
        %v87494 = vadd.f32 -3.0, %v87491 (stack52)
        %v87498 = vsel /*vm=*/%vm87442, /*on_true_vy=*/%v87483, /*on_false_vx=*/%v87494 (stack43)
        %v87502 = vmul.f32 %v87498, %v87479 (stack53)
        %v87506 = vadd.f32 %v87502, %v87475 (stack52)
        %v87510 = vmul.f32 %v87506, %v87498 (stack53)
        %v87514 = vadd.f32 %v87510, %v87471 (stack52)
        %v87518 = vmul.f32 %v87514, %v87498 (stack53)
        %v87522 = vadd.f32 %v87518, %v87467 (stack52)
        %v87526 = vmul.f32 %v87522, %v87498 (stack53)
        %v87530 = vadd.f32 %v87526, %v87463 (stack52)
        %v87534 = vmul.f32 %v87530, %v87498 (stack53)
        %v87538 = vadd.f32 %v87534, %v87459 (stack52)
        %v87542 = vmul.f32 %v87538, %v87498 (stack53)
        %v87546 = vadd.f32 %v87542, %v87455 (stack52)
        %v87550 = vmul.f32 %v87546, %v87498 (stack53)
        %v87554 = vadd.f32 %v87550, %v87451 (stack52)
        %v87558 = vmul.f32 %v87554, %v87498 (stack53)
        %v87562 = vadd.f32 %v87558, %v87447 (stack52)
        %v87566 = vmul.f32 %v87562, %v87413 (stack53)
        %v87570 = vsel /*vm=*/%vm87418, /*on_true_vy=*/%v87423, /*on_false_vx=*/%v87566 (stack43)
        %v87574 = vmul.f32 1.4140625, %v87570 (stack53)
        %v87577 = vpack.c.bf16 0.0, %v87574 (stack74)
        %120213 = vst [vmem:[%s280 + $0x15c] sm:$0xf] /*vst_source=*/%v87577 (stack75)
        %v87581 = vadd.s32 %v86195, %v1868 (stack39)
        %v87591 = vadd.s32 %v87581, %v415 (stack39)
        %vm87595 = vcmp.lt.u32.totalorder %v87591, %v87581 (stack42)
        %vm87600 = vcmp.lt.u32.totalorder %v87581, %v1868 (stack42)
        %v87605 = vadd.s32 %v86178, %v1855 (stack39)
        %v87609 = vadd.s32 1, %v87605 (stack39)
        %v87613 = vsel /*vm=*/%vm87600, /*on_true_vy=*/%v87609, /*on_false_vx=*/%v87605 (stack43)
        %v87617 = vadd.s32 1, %v87613 (stack39)
        %v87621 = vsel /*vm=*/%vm87595, /*on_true_vy=*/%v87617, /*on_false_vx=*/%v87613 (stack43)
        %v87626 = vadd.s32 %v87621, %v10 (stack39)
        %v87630 = vadd.s32 %v87591, %v9 (stack39)
        %v87634 = vadd.s32 %v87630, %v87626 (stack39)
        %v87636 = vshll.u32 %v87630, 13 (stack44)
        %v87637 = vshrl.u32 %v87630, 19 (stack45)
        %v87638 = vor.u32 %v87637, %v87636 (stack46)
        %v87639 = vxor.u32 %v87638, %v87634 (stack47)
        %v87642 = vadd.s32 %v87639, %v87634 (stack39)
        %v87644 = vshll.u32 %v87639, 15 (stack44)
        %v87645 = vshrl.u32 %v87639, 17 (stack45)
        %v87646 = vor.u32 %v87645, %v87644 (stack46)
        %v87647 = vxor.u32 %v87646, %v87642 (stack47)
        %v87650 = vadd.s32 %v87647, %v87642 (stack39)
        %v87652 = vshll.u32 %v87647, 26 (stack44)
        %v87653 = vshrl.u32 %v87647, 6 (stack45)
        %v87654 = vor.u32 %v87653, %v87652 (stack46)
        %v87655 = vxor.u32 %v87654, %v87650 (stack47)
        %v87658 = vadd.s32 %v87655, %v87650 (stack39)
        %v87662 = vadd.s32 %v87658, %v9 (stack39)
        %v87664 = vshll.u32 %v87655, 6 (stack44)
        %v87665 = vshrl.u32 %v87655, 26 (stack45)
        %v87666 = vor.u32 %v87665, %v87664 (stack46)
        %v87667 = vxor.u32 %v87666, %v87658 (stack47)
        %v87670 = vadd.s32 %v87667, %v8 (stack39)
        %v87674 = vadd.s32 1, %v87670 (stack39)
        %v87678 = vadd.s32 %v87674, %v87662 (stack39)
        %v87680 = vshll.u32 %v87674, 17 (stack44)
        %v87681 = vshrl.u32 %v87674, 15 (stack45)
        %v87682 = vor.u32 %v87681, %v87680 (stack46)
        %v87683 = vxor.u32 %v87682, %v87678 (stack47)
        %v87686 = vadd.s32 %v87683, %v87678 (stack39)
        %v87688 = vshll.u32 %v87683, 29 (stack44)
        %v87689 = vshrl.u32 %v87683, 3 (stack45)
        %v87690 = vor.u32 %v87689, %v87688 (stack46)
        %v87691 = vxor.u32 %v87690, %v87686 (stack47)
        %v87694 = vadd.s32 %v87691, %v87686 (stack39)
        %v87696 = vshll.u32 %v87691, 16 (stack44)
        %v87697 = vshrl.u32 %v87691, 16 (stack45)
        %v87698 = vor.u32 %v87697, %v87696 (stack46)
        %v87699 = vxor.u32 %v87698, %v87694 (stack47)
        %v87702 = vadd.s32 %v87699, %v87694 (stack39)
        %v87706 = vadd.s32 %v87702, %v8 (stack39)
        %v87708 = vshll.u32 %v87699, 24 (stack44)
        %v87709 = vshrl.u32 %v87699, 8 (stack45)
        %v87710 = vor.u32 %v87709, %v87708 (stack46)
        %v87711 = vxor.u32 %v87710, %v87702 (stack47)
        %v87714 = vadd.s32 %v87711, %v10 (stack39)
        %v87718 = vadd.s32 2, %v87714 (stack39)
        %v87722 = vadd.s32 %v87718, %v87706 (stack39)
        %v87724 = vshll.u32 %v87718, 13 (stack44)
        %v87725 = vshrl.u32 %v87718, 19 (stack45)
        %v87726 = vor.u32 %v87725, %v87724 (stack46)
        %v87727 = vxor.u32 %v87726, %v87722 (stack47)
        %v87730 = vadd.s32 %v87727, %v87722 (stack39)
        %v87732 = vshll.u32 %v87727, 15 (stack44)
        %v87733 = vshrl.u32 %v87727, 17 (stack45)
        %v87734 = vor.u32 %v87733, %v87732 (stack46)
        %v87735 = vxor.u32 %v87734, %v87730 (stack47)
        %v87738 = vadd.s32 %v87735, %v87730 (stack39)
        %v87740 = vshll.u32 %v87735, 26 (stack44)
        %v87741 = vshrl.u32 %v87735, 6 (stack45)
        %v87742 = vor.u32 %v87741, %v87740 (stack46)
        %v87743 = vxor.u32 %v87742, %v87738 (stack47)
        %v87746 = vadd.s32 %v87743, %v87738 (stack39)
        %v87750 = vadd.s32 %v87746, %v10 (stack39)
        %v87752 = vshll.u32 %v87743, 6 (stack44)
        %v87753 = vshrl.u32 %v87743, 26 (stack45)
        %v87754 = vor.u32 %v87753, %v87752 (stack46)
        %v87755 = vxor.u32 %v87754, %v87746 (stack47)
        %v87758 = vadd.s32 %v87755, %v9 (stack39)
        %v87762 = vadd.s32 3, %v87758 (stack39)
        %v87766 = vadd.s32 %v87762, %v87750 (stack39)
        %v87768 = vshll.u32 %v87762, 17 (stack44)
        %v87769 = vshrl.u32 %v87762, 15 (stack45)
        %v87770 = vor.u32 %v87769, %v87768 (stack46)
        %v87771 = vxor.u32 %v87770, %v87766 (stack47)
        %v87774 = vadd.s32 %v87771, %v87766 (stack39)
        %v87776 = vshll.u32 %v87771, 29 (stack44)
        %v87777 = vshrl.u32 %v87771, 3 (stack45)
        %v87778 = vor.u32 %v87777, %v87776 (stack46)
        %v87779 = vxor.u32 %v87778, %v87774 (stack47)
        %v87782 = vadd.s32 %v87779, %v87774 (stack39)
        %v87784 = vshll.u32 %v87779, 16 (stack44)
        %v87785 = vshrl.u32 %v87779, 16 (stack45)
        %v87786 = vor.u32 %v87785, %v87784 (stack46)
        %v87787 = vxor.u32 %v87786, %v87782 (stack47)
        %v87790 = vadd.s32 %v87787, %v87782 (stack39)
        %v87794 = vadd.s32 %v87790, %v9 (stack39)
        %v87796 = vshll.u32 %v87787, 24 (stack44)
        %v87797 = vshrl.u32 %v87787, 8 (stack45)
        %v87798 = vor.u32 %v87797, %v87796 (stack46)
        %v87799 = vxor.u32 %v87798, %v87790 (stack47)
        %v87802 = vadd.s32 %v87799, %v8 (stack39)
        %v87806 = vadd.s32 4, %v87802 (stack39)
        %v87810 = vadd.s32 %v87806, %v87794 (stack39)
        %v87812 = vshll.u32 %v87806, 13 (stack44)
        %v87813 = vshrl.u32 %v87806, 19 (stack45)
        %v87814 = vor.u32 %v87813, %v87812 (stack46)
        %v87815 = vxor.u32 %v87814, %v87810 (stack47)
        %v87818 = vadd.s32 %v87815, %v87810 (stack39)
        %v87820 = vshll.u32 %v87815, 15 (stack44)
        %v87821 = vshrl.u32 %v87815, 17 (stack45)
        %v87822 = vor.u32 %v87821, %v87820 (stack46)
        %v87823 = vxor.u32 %v87822, %v87818 (stack47)
        %v87826 = vadd.s32 %v87823, %v87818 (stack39)
        %v87828 = vshll.u32 %v87823, 26 (stack44)
        %v87829 = vshrl.u32 %v87823, 6 (stack45)
        %v87830 = vor.u32 %v87829, %v87828 (stack46)
        %v87831 = vxor.u32 %v87830, %v87826 (stack47)
        %v87834 = vadd.s32 %v87831, %v87826 (stack39)
        %v87838 = vadd.s32 %v87834, %v8 (stack39)
        %v87840 = vshll.u32 %v87831, 6 (stack44)
        %v87841 = vshrl.u32 %v87831, 26 (stack45)
        %v87842 = vor.u32 %v87841, %v87840 (stack46)
        %v87843 = vxor.u32 %v87842, %v87834 (stack47)
        %v87846 = vadd.s32 %v87843, %v10 (stack39)
        %v87850 = vadd.s32 5, %v87846 (stack39)
        %v87852 = vxor.u32 %v87850, %v87838 (stack47)
        %v87853 = vand.u32.u8 255, %v87852 (stack48)
        %v87854 = vand.u32 65535, %v87853 (stack49)
        %v87855 = vshrl.u32 %v87854, 1 (stack50)
        %v87856 = vor.u32 16256, %v87855 (stack46)
        %v87857 = vand.u32.u16 65535, %v87856 (stack51)
        %v120214 = vadd.low.f32.bf16 -1.0, %v87857 (stack52)
        %v87866 = vmul.f32 2.0, %v120214 (stack53)
        %v87870 = vadd.f32 -0.99609375, %v87866 (stack52)
        %v87874 = vmax.f32 %v87870, -0.99609375 (stack54)
        %v87876 = vand.u32 2147483647, %v87874 (stack55)
        %vm87879 = vcmp.eq.f32.partialorder %v87876, 1.0 (stack56)
        %v87884 = vmul.f32 inf, %v87874 (stack53)
        %v87886 = vxor.u32 2147483648, %v87874 (stack57)
        %v87889 = vmul.f32 %v87886, %v87874 (stack53)
        %v87891 = vadd.f32 1.0, %v87889 (stack58)
        %v87892 = vlog2.pop %v87891 (stack59)
        %v87893 = vmul.f32 0.6931472, %v87892 (stack60)
        %v87894 = vmul.f32 -0.5, %v87889 (stack61)
        %v87895 = vadd.f32 1.0, %v87894 (stack62)
        %v87896 = vmul.f32 %v87895, %v87889 (stack63)
        %v87897 = vand.u32 2147483647, %v87889 (stack64)
        %vm87898 = vcmp.lt.f32.partialorder %v87897, 0.0004427343 (stack65)
        %v87899 = vsel /*vm=*/%vm87898, /*on_true_vy=*/%v87896, /*on_false_vx=*/%v87893 (stack66)
        %v87900 = vxor.u32 2147483648, %v87899 (stack57)
        %vm87903 = vcmp.lt.f32.partialorder %v87900, 5.0 (stack56)
        %v87908 = vsel /*vm=*/%vm87903, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v87912 = vsel /*vm=*/%vm87903, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v87916 = vsel /*vm=*/%vm87903, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v87920 = vsel /*vm=*/%vm87903, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v87924 = vsel /*vm=*/%vm87903, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v87928 = vsel /*vm=*/%vm87903, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v87932 = vsel /*vm=*/%vm87903, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v87936 = vsel /*vm=*/%vm87903, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v87940 = vsel /*vm=*/%vm87903, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v87944 = vadd.f32 -2.5, %v87900 (stack52)
        %v87946 = vrsqrt.pop %v87900 (stack67)
        %v87947 = vmul.f32 %v87946, %v87900 (stack68)
        %vm87948 = vcmp.eq.f32.partialorder %v87900, inf (stack69)
        %v87949 = vsel /*vm=*/%vm87948, /*on_true_vy=*/%v87900, /*on_false_vx=*/%v87947 (stack70)
        %vm87950 = vcmp.eq.f32.partialorder %v87900, 0.0 (stack71)
        %v87951 = vand.u32 2147483648, %v87900 (stack72)
        %v87952 = vsel /*vm=*/%vm87950, /*on_true_vy=*/%v87951, /*on_false_vx=*/%v87949 (stack73)
        %v87955 = vadd.f32 -3.0, %v87952 (stack52)
        %v87959 = vsel /*vm=*/%vm87903, /*on_true_vy=*/%v87944, /*on_false_vx=*/%v87955 (stack43)
        %v87963 = vmul.f32 %v87959, %v87940 (stack53)
        %v87967 = vadd.f32 %v87963, %v87936 (stack52)
        %v87971 = vmul.f32 %v87967, %v87959 (stack53)
        %v87975 = vadd.f32 %v87971, %v87932 (stack52)
        %v87979 = vmul.f32 %v87975, %v87959 (stack53)
        %v87983 = vadd.f32 %v87979, %v87928 (stack52)
        %v87987 = vmul.f32 %v87983, %v87959 (stack53)
        %v87991 = vadd.f32 %v87987, %v87924 (stack52)
        %v87995 = vmul.f32 %v87991, %v87959 (stack53)
        %v87999 = vadd.f32 %v87995, %v87920 (stack52)
        %v88003 = vmul.f32 %v87999, %v87959 (stack53)
        %v88007 = vadd.f32 %v88003, %v87916 (stack52)
        %v88011 = vmul.f32 %v88007, %v87959 (stack53)
        %v88015 = vadd.f32 %v88011, %v87912 (stack52)
        %v88019 = vmul.f32 %v88015, %v87959 (stack53)
        %v88023 = vadd.f32 %v88019, %v87908 (stack52)
        %v88027 = vmul.f32 %v88023, %v87874 (stack53)
        %v88031 = vsel /*vm=*/%vm87879, /*on_true_vy=*/%v87884, /*on_false_vx=*/%v88027 (stack43)
        %v88035 = vmul.f32 1.4140625, %v88031 (stack53)
        %v88038 = vpack.c.bf16 0.0, %v88035 (stack74)
        %120215 = vst [vmem:[%s280 + $0x1dc] sm:$0xf] /*vst_source=*/%v88038 (stack75)
        %v88042 = vadd.s32 %v86195, %v2355 (stack39)
        %v88052 = vadd.s32 %v88042, %v415 (stack39)
        %vm88056 = vcmp.lt.u32.totalorder %v88052, %v88042 (stack42)
        %vm88061 = vcmp.lt.u32.totalorder %v88042, %v2355 (stack42)
        %v88066 = vadd.s32 %v86178, %v2342 (stack39)
        %v88070 = vadd.s32 1, %v88066 (stack39)
        %v88074 = vsel /*vm=*/%vm88061, /*on_true_vy=*/%v88070, /*on_false_vx=*/%v88066 (stack43)
        %v88078 = vadd.s32 1, %v88074 (stack39)
        %v88082 = vsel /*vm=*/%vm88056, /*on_true_vy=*/%v88078, /*on_false_vx=*/%v88074 (stack43)
        %v88087 = vadd.s32 %v88082, %v10 (stack39)
        %v88091 = vadd.s32 %v88052, %v9 (stack39)
        %v88095 = vadd.s32 %v88091, %v88087 (stack39)
        %v88097 = vshll.u32 %v88091, 13 (stack44)
        %v88098 = vshrl.u32 %v88091, 19 (stack45)
        %v88099 = vor.u32 %v88098, %v88097 (stack46)
        %v88100 = vxor.u32 %v88099, %v88095 (stack47)
        %v88103 = vadd.s32 %v88100, %v88095 (stack39)
        %v88105 = vshll.u32 %v88100, 15 (stack44)
        %v88106 = vshrl.u32 %v88100, 17 (stack45)
        %v88107 = vor.u32 %v88106, %v88105 (stack46)
        %v88108 = vxor.u32 %v88107, %v88103 (stack47)
        %v88111 = vadd.s32 %v88108, %v88103 (stack39)
        %v88113 = vshll.u32 %v88108, 26 (stack44)
        %v88114 = vshrl.u32 %v88108, 6 (stack45)
        %v88115 = vor.u32 %v88114, %v88113 (stack46)
        %v88116 = vxor.u32 %v88115, %v88111 (stack47)
        %v88119 = vadd.s32 %v88116, %v88111 (stack39)
        %v88123 = vadd.s32 %v88119, %v9 (stack39)
        %v88125 = vshll.u32 %v88116, 6 (stack44)
        %v88126 = vshrl.u32 %v88116, 26 (stack45)
        %v88127 = vor.u32 %v88126, %v88125 (stack46)
        %v88128 = vxor.u32 %v88127, %v88119 (stack47)
        %v88131 = vadd.s32 %v88128, %v8 (stack39)
        %v88135 = vadd.s32 1, %v88131 (stack39)
        %v88139 = vadd.s32 %v88135, %v88123 (stack39)
        %v88141 = vshll.u32 %v88135, 17 (stack44)
        %v88142 = vshrl.u32 %v88135, 15 (stack45)
        %v88143 = vor.u32 %v88142, %v88141 (stack46)
        %v88144 = vxor.u32 %v88143, %v88139 (stack47)
        %v88147 = vadd.s32 %v88144, %v88139 (stack39)
        %v88149 = vshll.u32 %v88144, 29 (stack44)
        %v88150 = vshrl.u32 %v88144, 3 (stack45)
        %v88151 = vor.u32 %v88150, %v88149 (stack46)
        %v88152 = vxor.u32 %v88151, %v88147 (stack47)
        %v88155 = vadd.s32 %v88152, %v88147 (stack39)
        %v88157 = vshll.u32 %v88152, 16 (stack44)
        %v88158 = vshrl.u32 %v88152, 16 (stack45)
        %v88159 = vor.u32 %v88158, %v88157 (stack46)
        %v88160 = vxor.u32 %v88159, %v88155 (stack47)
        %v88163 = vadd.s32 %v88160, %v88155 (stack39)
        %v88167 = vadd.s32 %v88163, %v8 (stack39)
        %v88169 = vshll.u32 %v88160, 24 (stack44)
        %v88170 = vshrl.u32 %v88160, 8 (stack45)
        %v88171 = vor.u32 %v88170, %v88169 (stack46)
        %v88172 = vxor.u32 %v88171, %v88163 (stack47)
        %v88175 = vadd.s32 %v88172, %v10 (stack39)
        %v88179 = vadd.s32 2, %v88175 (stack39)
        %v88183 = vadd.s32 %v88179, %v88167 (stack39)
        %v88185 = vshll.u32 %v88179, 13 (stack44)
        %v88186 = vshrl.u32 %v88179, 19 (stack45)
        %v88187 = vor.u32 %v88186, %v88185 (stack46)
        %v88188 = vxor.u32 %v88187, %v88183 (stack47)
        %v88191 = vadd.s32 %v88188, %v88183 (stack39)
        %v88193 = vshll.u32 %v88188, 15 (stack44)
        %v88194 = vshrl.u32 %v88188, 17 (stack45)
        %v88195 = vor.u32 %v88194, %v88193 (stack46)
        %v88196 = vxor.u32 %v88195, %v88191 (stack47)
        %v88199 = vadd.s32 %v88196, %v88191 (stack39)
        %v88201 = vshll.u32 %v88196, 26 (stack44)
        %v88202 = vshrl.u32 %v88196, 6 (stack45)
        %v88203 = vor.u32 %v88202, %v88201 (stack46)
        %v88204 = vxor.u32 %v88203, %v88199 (stack47)
        %v88207 = vadd.s32 %v88204, %v88199 (stack39)
        %v88211 = vadd.s32 %v88207, %v10 (stack39)
        %v88213 = vshll.u32 %v88204, 6 (stack44)
        %v88214 = vshrl.u32 %v88204, 26 (stack45)
        %v88215 = vor.u32 %v88214, %v88213 (stack46)
        %v88216 = vxor.u32 %v88215, %v88207 (stack47)
        %v88219 = vadd.s32 %v88216, %v9 (stack39)
        %v88223 = vadd.s32 3, %v88219 (stack39)
        %v88227 = vadd.s32 %v88223, %v88211 (stack39)
        %v88229 = vshll.u32 %v88223, 17 (stack44)
        %v88230 = vshrl.u32 %v88223, 15 (stack45)
        %v88231 = vor.u32 %v88230, %v88229 (stack46)
        %v88232 = vxor.u32 %v88231, %v88227 (stack47)
        %v88235 = vadd.s32 %v88232, %v88227 (stack39)
        %v88237 = vshll.u32 %v88232, 29 (stack44)
        %v88238 = vshrl.u32 %v88232, 3 (stack45)
        %v88239 = vor.u32 %v88238, %v88237 (stack46)
        %v88240 = vxor.u32 %v88239, %v88235 (stack47)
        %v88243 = vadd.s32 %v88240, %v88235 (stack39)
        %v88245 = vshll.u32 %v88240, 16 (stack44)
        %v88246 = vshrl.u32 %v88240, 16 (stack45)
        %v88247 = vor.u32 %v88246, %v88245 (stack46)
        %v88248 = vxor.u32 %v88247, %v88243 (stack47)
        %v88251 = vadd.s32 %v88248, %v88243 (stack39)
        %v88255 = vadd.s32 %v88251, %v9 (stack39)
        %v88257 = vshll.u32 %v88248, 24 (stack44)
        %v88258 = vshrl.u32 %v88248, 8 (stack45)
        %v88259 = vor.u32 %v88258, %v88257 (stack46)
        %v88260 = vxor.u32 %v88259, %v88251 (stack47)
        %v88263 = vadd.s32 %v88260, %v8 (stack39)
        %v88267 = vadd.s32 4, %v88263 (stack39)
        %v88271 = vadd.s32 %v88267, %v88255 (stack39)
        %v88273 = vshll.u32 %v88267, 13 (stack44)
        %v88274 = vshrl.u32 %v88267, 19 (stack45)
        %v88275 = vor.u32 %v88274, %v88273 (stack46)
        %v88276 = vxor.u32 %v88275, %v88271 (stack47)
        %v88279 = vadd.s32 %v88276, %v88271 (stack39)
        %v88281 = vshll.u32 %v88276, 15 (stack44)
        %v88282 = vshrl.u32 %v88276, 17 (stack45)
        %v88283 = vor.u32 %v88282, %v88281 (stack46)
        %v88284 = vxor.u32 %v88283, %v88279 (stack47)
        %v88287 = vadd.s32 %v88284, %v88279 (stack39)
        %v88289 = vshll.u32 %v88284, 26 (stack44)
        %v88290 = vshrl.u32 %v88284, 6 (stack45)
        %v88291 = vor.u32 %v88290, %v88289 (stack46)
        %v88292 = vxor.u32 %v88291, %v88287 (stack47)
        %v88295 = vadd.s32 %v88292, %v88287 (stack39)
        %v88299 = vadd.s32 %v88295, %v8 (stack39)
        %v88301 = vshll.u32 %v88292, 6 (stack44)
        %v88302 = vshrl.u32 %v88292, 26 (stack45)
        %v88303 = vor.u32 %v88302, %v88301 (stack46)
        %v88304 = vxor.u32 %v88303, %v88295 (stack47)
        %v88307 = vadd.s32 %v88304, %v10 (stack39)
        %v88311 = vadd.s32 5, %v88307 (stack39)
        %v88313 = vxor.u32 %v88311, %v88299 (stack47)
        %v88314 = vand.u32.u8 255, %v88313 (stack48)
        %v88315 = vand.u32 65535, %v88314 (stack49)
        %v88316 = vshrl.u32 %v88315, 1 (stack50)
        %v88317 = vor.u32 16256, %v88316 (stack46)
        %v88318 = vand.u32.u16 65535, %v88317 (stack51)
        %v120216 = vadd.low.f32.bf16 -1.0, %v88318 (stack52)
        %v88327 = vmul.f32 2.0, %v120216 (stack53)
        %v88331 = vadd.f32 -0.99609375, %v88327 (stack52)
        %v88335 = vmax.f32 %v88331, -0.99609375 (stack54)
        %v88337 = vand.u32 2147483647, %v88335 (stack55)
        %vm88340 = vcmp.eq.f32.partialorder %v88337, 1.0 (stack56)
        %v88345 = vmul.f32 inf, %v88335 (stack53)
        %v88347 = vxor.u32 2147483648, %v88335 (stack57)
        %v88350 = vmul.f32 %v88347, %v88335 (stack53)
        %v88352 = vadd.f32 1.0, %v88350 (stack58)
        %v88353 = vlog2.pop %v88352 (stack59)
        %v88354 = vmul.f32 0.6931472, %v88353 (stack60)
        %v88355 = vmul.f32 -0.5, %v88350 (stack61)
        %v88356 = vadd.f32 1.0, %v88355 (stack62)
        %v88357 = vmul.f32 %v88356, %v88350 (stack63)
        %v88358 = vand.u32 2147483647, %v88350 (stack64)
        %vm88359 = vcmp.lt.f32.partialorder %v88358, 0.0004427343 (stack65)
        %v88360 = vsel /*vm=*/%vm88359, /*on_true_vy=*/%v88357, /*on_false_vx=*/%v88354 (stack66)
        %v88361 = vxor.u32 2147483648, %v88360 (stack57)
        %vm88364 = vcmp.lt.f32.partialorder %v88361, 5.0 (stack56)
        %v88369 = vsel /*vm=*/%vm88364, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v88373 = vsel /*vm=*/%vm88364, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v88377 = vsel /*vm=*/%vm88364, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v88381 = vsel /*vm=*/%vm88364, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v88385 = vsel /*vm=*/%vm88364, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v88389 = vsel /*vm=*/%vm88364, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v88393 = vsel /*vm=*/%vm88364, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v88397 = vsel /*vm=*/%vm88364, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v88401 = vsel /*vm=*/%vm88364, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v88405 = vadd.f32 -2.5, %v88361 (stack52)
        %v88407 = vrsqrt.pop %v88361 (stack67)
        %v88408 = vmul.f32 %v88407, %v88361 (stack68)
        %vm88409 = vcmp.eq.f32.partialorder %v88361, inf (stack69)
        %v88410 = vsel /*vm=*/%vm88409, /*on_true_vy=*/%v88361, /*on_false_vx=*/%v88408 (stack70)
        %vm88411 = vcmp.eq.f32.partialorder %v88361, 0.0 (stack71)
        %v88412 = vand.u32 2147483648, %v88361 (stack72)
        %v88413 = vsel /*vm=*/%vm88411, /*on_true_vy=*/%v88412, /*on_false_vx=*/%v88410 (stack73)
        %v88416 = vadd.f32 -3.0, %v88413 (stack52)
        %v88420 = vsel /*vm=*/%vm88364, /*on_true_vy=*/%v88405, /*on_false_vx=*/%v88416 (stack43)
        %v88424 = vmul.f32 %v88420, %v88401 (stack53)
        %v88428 = vadd.f32 %v88424, %v88397 (stack52)
        %v88432 = vmul.f32 %v88428, %v88420 (stack53)
        %v88436 = vadd.f32 %v88432, %v88393 (stack52)
        %v88440 = vmul.f32 %v88436, %v88420 (stack53)
        %v88444 = vadd.f32 %v88440, %v88389 (stack52)
        %v88448 = vmul.f32 %v88444, %v88420 (stack53)
        %v88452 = vadd.f32 %v88448, %v88385 (stack52)
        %v88456 = vmul.f32 %v88452, %v88420 (stack53)
        %v88460 = vadd.f32 %v88456, %v88381 (stack52)
        %v88464 = vmul.f32 %v88460, %v88420 (stack53)
        %v88468 = vadd.f32 %v88464, %v88377 (stack52)
        %v88472 = vmul.f32 %v88468, %v88420 (stack53)
        %v88476 = vadd.f32 %v88472, %v88373 (stack52)
        %v88480 = vmul.f32 %v88476, %v88420 (stack53)
        %v88484 = vadd.f32 %v88480, %v88369 (stack52)
        %v88488 = vmul.f32 %v88484, %v88335 (stack53)
        %v88492 = vsel /*vm=*/%vm88340, /*on_true_vy=*/%v88345, /*on_false_vx=*/%v88488 (stack43)
        %v88496 = vmul.f32 1.4140625, %v88492 (stack53)
        %v88499 = vpack.c.bf16 0.0, %v88496 (stack74)
        %120217 = vst [vmem:[%s280 + $0x25c] sm:$0xf] /*vst_source=*/%v88499 (stack75)
        %v88503 = vadd.s32 %v86195, %v2842 (stack39)
        %v88513 = vadd.s32 %v88503, %v415 (stack39)
        %vm88517 = vcmp.lt.u32.totalorder %v88513, %v88503 (stack42)
        %vm88522 = vcmp.lt.u32.totalorder %v88503, %v2842 (stack42)
        %v88527 = vadd.s32 %v86178, %v2829 (stack39)
        %v88531 = vadd.s32 1, %v88527 (stack39)
        %v88535 = vsel /*vm=*/%vm88522, /*on_true_vy=*/%v88531, /*on_false_vx=*/%v88527 (stack43)
        %v88539 = vadd.s32 1, %v88535 (stack39)
        %v88543 = vsel /*vm=*/%vm88517, /*on_true_vy=*/%v88539, /*on_false_vx=*/%v88535 (stack43)
        %v88548 = vadd.s32 %v88543, %v10 (stack39)
        %v88552 = vadd.s32 %v88513, %v9 (stack39)
        %v88556 = vadd.s32 %v88552, %v88548 (stack39)
        %v88558 = vshll.u32 %v88552, 13 (stack44)
        %v88559 = vshrl.u32 %v88552, 19 (stack45)
        %v88560 = vor.u32 %v88559, %v88558 (stack46)
        %v88561 = vxor.u32 %v88560, %v88556 (stack47)
        %v88564 = vadd.s32 %v88561, %v88556 (stack39)
        %v88566 = vshll.u32 %v88561, 15 (stack44)
        %v88567 = vshrl.u32 %v88561, 17 (stack45)
        %v88568 = vor.u32 %v88567, %v88566 (stack46)
        %v88569 = vxor.u32 %v88568, %v88564 (stack47)
        %v88572 = vadd.s32 %v88569, %v88564 (stack39)
        %v88574 = vshll.u32 %v88569, 26 (stack44)
        %v88575 = vshrl.u32 %v88569, 6 (stack45)
        %v88576 = vor.u32 %v88575, %v88574 (stack46)
        %v88577 = vxor.u32 %v88576, %v88572 (stack47)
        %v88580 = vadd.s32 %v88577, %v88572 (stack39)
        %v88584 = vadd.s32 %v88580, %v9 (stack39)
        %v88586 = vshll.u32 %v88577, 6 (stack44)
        %v88587 = vshrl.u32 %v88577, 26 (stack45)
        %v88588 = vor.u32 %v88587, %v88586 (stack46)
        %v88589 = vxor.u32 %v88588, %v88580 (stack47)
        %v88592 = vadd.s32 %v88589, %v8 (stack39)
        %v88596 = vadd.s32 1, %v88592 (stack39)
        %v88600 = vadd.s32 %v88596, %v88584 (stack39)
        %v88602 = vshll.u32 %v88596, 17 (stack44)
        %v88603 = vshrl.u32 %v88596, 15 (stack45)
        %v88604 = vor.u32 %v88603, %v88602 (stack46)
        %v88605 = vxor.u32 %v88604, %v88600 (stack47)
        %v88608 = vadd.s32 %v88605, %v88600 (stack39)
        %v88610 = vshll.u32 %v88605, 29 (stack44)
        %v88611 = vshrl.u32 %v88605, 3 (stack45)
        %v88612 = vor.u32 %v88611, %v88610 (stack46)
        %v88613 = vxor.u32 %v88612, %v88608 (stack47)
        %v88616 = vadd.s32 %v88613, %v88608 (stack39)
        %v88618 = vshll.u32 %v88613, 16 (stack44)
        %v88619 = vshrl.u32 %v88613, 16 (stack45)
        %v88620 = vor.u32 %v88619, %v88618 (stack46)
        %v88621 = vxor.u32 %v88620, %v88616 (stack47)
        %v88624 = vadd.s32 %v88621, %v88616 (stack39)
        %v88628 = vadd.s32 %v88624, %v8 (stack39)
        %v88630 = vshll.u32 %v88621, 24 (stack44)
        %v88631 = vshrl.u32 %v88621, 8 (stack45)
        %v88632 = vor.u32 %v88631, %v88630 (stack46)
        %v88633 = vxor.u32 %v88632, %v88624 (stack47)
        %v88636 = vadd.s32 %v88633, %v10 (stack39)
        %v88640 = vadd.s32 2, %v88636 (stack39)
        %v88644 = vadd.s32 %v88640, %v88628 (stack39)
        %v88646 = vshll.u32 %v88640, 13 (stack44)
        %v88647 = vshrl.u32 %v88640, 19 (stack45)
        %v88648 = vor.u32 %v88647, %v88646 (stack46)
        %v88649 = vxor.u32 %v88648, %v88644 (stack47)
        %v88652 = vadd.s32 %v88649, %v88644 (stack39)
        %v88654 = vshll.u32 %v88649, 15 (stack44)
        %v88655 = vshrl.u32 %v88649, 17 (stack45)
        %v88656 = vor.u32 %v88655, %v88654 (stack46)
        %v88657 = vxor.u32 %v88656, %v88652 (stack47)
        %v88660 = vadd.s32 %v88657, %v88652 (stack39)
        %v88662 = vshll.u32 %v88657, 26 (stack44)
        %v88663 = vshrl.u32 %v88657, 6 (stack45)
        %v88664 = vor.u32 %v88663, %v88662 (stack46)
        %v88665 = vxor.u32 %v88664, %v88660 (stack47)
        %v88668 = vadd.s32 %v88665, %v88660 (stack39)
        %v88672 = vadd.s32 %v88668, %v10 (stack39)
        %v88674 = vshll.u32 %v88665, 6 (stack44)
        %v88675 = vshrl.u32 %v88665, 26 (stack45)
        %v88676 = vor.u32 %v88675, %v88674 (stack46)
        %v88677 = vxor.u32 %v88676, %v88668 (stack47)
        %v88680 = vadd.s32 %v88677, %v9 (stack39)
        %v88684 = vadd.s32 3, %v88680 (stack39)
        %v88688 = vadd.s32 %v88684, %v88672 (stack39)
        %v88690 = vshll.u32 %v88684, 17 (stack44)
        %v88691 = vshrl.u32 %v88684, 15 (stack45)
        %v88692 = vor.u32 %v88691, %v88690 (stack46)
        %v88693 = vxor.u32 %v88692, %v88688 (stack47)
        %v88696 = vadd.s32 %v88693, %v88688 (stack39)
        %v88698 = vshll.u32 %v88693, 29 (stack44)
        %v88699 = vshrl.u32 %v88693, 3 (stack45)
        %v88700 = vor.u32 %v88699, %v88698 (stack46)
        %v88701 = vxor.u32 %v88700, %v88696 (stack47)
        %v88704 = vadd.s32 %v88701, %v88696 (stack39)
        %v88706 = vshll.u32 %v88701, 16 (stack44)
        %v88707 = vshrl.u32 %v88701, 16 (stack45)
        %v88708 = vor.u32 %v88707, %v88706 (stack46)
        %v88709 = vxor.u32 %v88708, %v88704 (stack47)
        %v88712 = vadd.s32 %v88709, %v88704 (stack39)
        %v88716 = vadd.s32 %v88712, %v9 (stack39)
        %v88718 = vshll.u32 %v88709, 24 (stack44)
        %v88719 = vshrl.u32 %v88709, 8 (stack45)
        %v88720 = vor.u32 %v88719, %v88718 (stack46)
        %v88721 = vxor.u32 %v88720, %v88712 (stack47)
        %v88724 = vadd.s32 %v88721, %v8 (stack39)
        %v88728 = vadd.s32 4, %v88724 (stack39)
        %v88732 = vadd.s32 %v88728, %v88716 (stack39)
        %v88734 = vshll.u32 %v88728, 13 (stack44)
        %v88735 = vshrl.u32 %v88728, 19 (stack45)
        %v88736 = vor.u32 %v88735, %v88734 (stack46)
        %v88737 = vxor.u32 %v88736, %v88732 (stack47)
        %v88740 = vadd.s32 %v88737, %v88732 (stack39)
        %v88742 = vshll.u32 %v88737, 15 (stack44)
        %v88743 = vshrl.u32 %v88737, 17 (stack45)
        %v88744 = vor.u32 %v88743, %v88742 (stack46)
        %v88745 = vxor.u32 %v88744, %v88740 (stack47)
        %v88748 = vadd.s32 %v88745, %v88740 (stack39)
        %v88750 = vshll.u32 %v88745, 26 (stack44)
        %v88751 = vshrl.u32 %v88745, 6 (stack45)
        %v88752 = vor.u32 %v88751, %v88750 (stack46)
        %v88753 = vxor.u32 %v88752, %v88748 (stack47)
        %v88756 = vadd.s32 %v88753, %v88748 (stack39)
        %v88760 = vadd.s32 %v88756, %v8 (stack39)
        %v88762 = vshll.u32 %v88753, 6 (stack44)
        %v88763 = vshrl.u32 %v88753, 26 (stack45)
        %v88764 = vor.u32 %v88763, %v88762 (stack46)
        %v88765 = vxor.u32 %v88764, %v88756 (stack47)
        %v88768 = vadd.s32 %v88765, %v10 (stack39)
        %v88772 = vadd.s32 5, %v88768 (stack39)
        %v88774 = vxor.u32 %v88772, %v88760 (stack47)
        %v88775 = vand.u32.u8 255, %v88774 (stack48)
        %v88776 = vand.u32 65535, %v88775 (stack49)
        %v88777 = vshrl.u32 %v88776, 1 (stack50)
        %v88778 = vor.u32 16256, %v88777 (stack46)
        %v88779 = vand.u32.u16 65535, %v88778 (stack51)
        %v120218 = vadd.low.f32.bf16 -1.0, %v88779 (stack52)
        %v88788 = vmul.f32 2.0, %v120218 (stack53)
        %v88792 = vadd.f32 -0.99609375, %v88788 (stack52)
        %v88796 = vmax.f32 %v88792, -0.99609375 (stack54)
        %v88798 = vand.u32 2147483647, %v88796 (stack55)
        %vm88801 = vcmp.eq.f32.partialorder %v88798, 1.0 (stack56)
        %v88806 = vmul.f32 inf, %v88796 (stack53)
        %v88808 = vxor.u32 2147483648, %v88796 (stack57)
        %v88811 = vmul.f32 %v88808, %v88796 (stack53)
        %v88813 = vadd.f32 1.0, %v88811 (stack58)
        %v88814 = vlog2.pop %v88813 (stack59)
        %v88815 = vmul.f32 0.6931472, %v88814 (stack60)
        %v88816 = vmul.f32 -0.5, %v88811 (stack61)
        %v88817 = vadd.f32 1.0, %v88816 (stack62)
        %v88818 = vmul.f32 %v88817, %v88811 (stack63)
        %v88819 = vand.u32 2147483647, %v88811 (stack64)
        %vm88820 = vcmp.lt.f32.partialorder %v88819, 0.0004427343 (stack65)
        %v88821 = vsel /*vm=*/%vm88820, /*on_true_vy=*/%v88818, /*on_false_vx=*/%v88815 (stack66)
        %v88822 = vxor.u32 2147483648, %v88821 (stack57)
        %vm88825 = vcmp.lt.f32.partialorder %v88822, 5.0 (stack56)
        %v88830 = vsel /*vm=*/%vm88825, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v88834 = vsel /*vm=*/%vm88825, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v88838 = vsel /*vm=*/%vm88825, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v88842 = vsel /*vm=*/%vm88825, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v88846 = vsel /*vm=*/%vm88825, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v88850 = vsel /*vm=*/%vm88825, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v88854 = vsel /*vm=*/%vm88825, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v88858 = vsel /*vm=*/%vm88825, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v88862 = vsel /*vm=*/%vm88825, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v88866 = vadd.f32 -2.5, %v88822 (stack52)
        %v88868 = vrsqrt.pop %v88822 (stack67)
        %v88869 = vmul.f32 %v88868, %v88822 (stack68)
        %vm88870 = vcmp.eq.f32.partialorder %v88822, inf (stack69)
        %v88871 = vsel /*vm=*/%vm88870, /*on_true_vy=*/%v88822, /*on_false_vx=*/%v88869 (stack70)
        %vm88872 = vcmp.eq.f32.partialorder %v88822, 0.0 (stack71)
        %v88873 = vand.u32 2147483648, %v88822 (stack72)
        %v88874 = vsel /*vm=*/%vm88872, /*on_true_vy=*/%v88873, /*on_false_vx=*/%v88871 (stack73)
        %v88877 = vadd.f32 -3.0, %v88874 (stack52)
        %v88881 = vsel /*vm=*/%vm88825, /*on_true_vy=*/%v88866, /*on_false_vx=*/%v88877 (stack43)
        %v88885 = vmul.f32 %v88881, %v88862 (stack53)
        %v88889 = vadd.f32 %v88885, %v88858 (stack52)
        %v88893 = vmul.f32 %v88889, %v88881 (stack53)
        %v88897 = vadd.f32 %v88893, %v88854 (stack52)
        %v88901 = vmul.f32 %v88897, %v88881 (stack53)
        %v88905 = vadd.f32 %v88901, %v88850 (stack52)
        %v88909 = vmul.f32 %v88905, %v88881 (stack53)
        %v88913 = vadd.f32 %v88909, %v88846 (stack52)
        %v88917 = vmul.f32 %v88913, %v88881 (stack53)
        %v88921 = vadd.f32 %v88917, %v88842 (stack52)
        %v88925 = vmul.f32 %v88921, %v88881 (stack53)
        %v88929 = vadd.f32 %v88925, %v88838 (stack52)
        %v88933 = vmul.f32 %v88929, %v88881 (stack53)
        %v88937 = vadd.f32 %v88933, %v88834 (stack52)
        %v88941 = vmul.f32 %v88937, %v88881 (stack53)
        %v88945 = vadd.f32 %v88941, %v88830 (stack52)
        %v88949 = vmul.f32 %v88945, %v88796 (stack53)
        %v88953 = vsel /*vm=*/%vm88801, /*on_true_vy=*/%v88806, /*on_false_vx=*/%v88949 (stack43)
        %v88957 = vmul.f32 1.4140625, %v88953 (stack53)
        %v88960 = vpack.c.bf16 0.0, %v88957 (stack74)
        %120219 = vst [vmem:[%s280 + $0x2dc] sm:$0xf] /*vst_source=*/%v88960 (stack75)
        %v88964 = vadd.s32 %v86195, %v3329 (stack39)
        %v88974 = vadd.s32 %v88964, %v415 (stack39)
        %vm88978 = vcmp.lt.u32.totalorder %v88974, %v88964 (stack42)
        %vm88983 = vcmp.lt.u32.totalorder %v88964, %v3329 (stack42)
        %v88988 = vadd.s32 %v86178, %v3316 (stack39)
        %v88992 = vadd.s32 1, %v88988 (stack39)
        %v88996 = vsel /*vm=*/%vm88983, /*on_true_vy=*/%v88992, /*on_false_vx=*/%v88988 (stack43)
        %v89000 = vadd.s32 1, %v88996 (stack39)
        %v89004 = vsel /*vm=*/%vm88978, /*on_true_vy=*/%v89000, /*on_false_vx=*/%v88996 (stack43)
        %v89009 = vadd.s32 %v89004, %v10 (stack39)
        %v89013 = vadd.s32 %v88974, %v9 (stack39)
        %v89017 = vadd.s32 %v89013, %v89009 (stack39)
        %v89019 = vshll.u32 %v89013, 13 (stack44)
        %v89020 = vshrl.u32 %v89013, 19 (stack45)
        %v89021 = vor.u32 %v89020, %v89019 (stack46)
        %v89022 = vxor.u32 %v89021, %v89017 (stack47)
        %v89025 = vadd.s32 %v89022, %v89017 (stack39)
        %v89027 = vshll.u32 %v89022, 15 (stack44)
        %v89028 = vshrl.u32 %v89022, 17 (stack45)
        %v89029 = vor.u32 %v89028, %v89027 (stack46)
        %v89030 = vxor.u32 %v89029, %v89025 (stack47)
        %v89033 = vadd.s32 %v89030, %v89025 (stack39)
        %v89035 = vshll.u32 %v89030, 26 (stack44)
        %v89036 = vshrl.u32 %v89030, 6 (stack45)
        %v89037 = vor.u32 %v89036, %v89035 (stack46)
        %v89038 = vxor.u32 %v89037, %v89033 (stack47)
        %v89041 = vadd.s32 %v89038, %v89033 (stack39)
        %v89045 = vadd.s32 %v89041, %v9 (stack39)
        %v89047 = vshll.u32 %v89038, 6 (stack44)
        %v89048 = vshrl.u32 %v89038, 26 (stack45)
        %v89049 = vor.u32 %v89048, %v89047 (stack46)
        %v89050 = vxor.u32 %v89049, %v89041 (stack47)
        %v89053 = vadd.s32 %v89050, %v8 (stack39)
        %v89057 = vadd.s32 1, %v89053 (stack39)
        %v89061 = vadd.s32 %v89057, %v89045 (stack39)
        %v89063 = vshll.u32 %v89057, 17 (stack44)
        %v89064 = vshrl.u32 %v89057, 15 (stack45)
        %v89065 = vor.u32 %v89064, %v89063 (stack46)
        %v89066 = vxor.u32 %v89065, %v89061 (stack47)
        %v89069 = vadd.s32 %v89066, %v89061 (stack39)
        %v89071 = vshll.u32 %v89066, 29 (stack44)
        %v89072 = vshrl.u32 %v89066, 3 (stack45)
        %v89073 = vor.u32 %v89072, %v89071 (stack46)
        %v89074 = vxor.u32 %v89073, %v89069 (stack47)
        %v89077 = vadd.s32 %v89074, %v89069 (stack39)
        %v89079 = vshll.u32 %v89074, 16 (stack44)
        %v89080 = vshrl.u32 %v89074, 16 (stack45)
        %v89081 = vor.u32 %v89080, %v89079 (stack46)
        %v89082 = vxor.u32 %v89081, %v89077 (stack47)
        %v89085 = vadd.s32 %v89082, %v89077 (stack39)
        %v89089 = vadd.s32 %v89085, %v8 (stack39)
        %v89091 = vshll.u32 %v89082, 24 (stack44)
        %v89092 = vshrl.u32 %v89082, 8 (stack45)
        %v89093 = vor.u32 %v89092, %v89091 (stack46)
        %v89094 = vxor.u32 %v89093, %v89085 (stack47)
        %v89097 = vadd.s32 %v89094, %v10 (stack39)
        %v89101 = vadd.s32 2, %v89097 (stack39)
        %v89105 = vadd.s32 %v89101, %v89089 (stack39)
        %v89107 = vshll.u32 %v89101, 13 (stack44)
        %v89108 = vshrl.u32 %v89101, 19 (stack45)
        %v89109 = vor.u32 %v89108, %v89107 (stack46)
        %v89110 = vxor.u32 %v89109, %v89105 (stack47)
        %v89113 = vadd.s32 %v89110, %v89105 (stack39)
        %v89115 = vshll.u32 %v89110, 15 (stack44)
        %v89116 = vshrl.u32 %v89110, 17 (stack45)
        %v89117 = vor.u32 %v89116, %v89115 (stack46)
        %v89118 = vxor.u32 %v89117, %v89113 (stack47)
        %v89121 = vadd.s32 %v89118, %v89113 (stack39)
        %v89123 = vshll.u32 %v89118, 26 (stack44)
        %v89124 = vshrl.u32 %v89118, 6 (stack45)
        %v89125 = vor.u32 %v89124, %v89123 (stack46)
        %v89126 = vxor.u32 %v89125, %v89121 (stack47)
        %v89129 = vadd.s32 %v89126, %v89121 (stack39)
        %v89133 = vadd.s32 %v89129, %v10 (stack39)
        %v89135 = vshll.u32 %v89126, 6 (stack44)
        %v89136 = vshrl.u32 %v89126, 26 (stack45)
        %v89137 = vor.u32 %v89136, %v89135 (stack46)
        %v89138 = vxor.u32 %v89137, %v89129 (stack47)
        %v89141 = vadd.s32 %v89138, %v9 (stack39)
        %v89145 = vadd.s32 3, %v89141 (stack39)
        %v89149 = vadd.s32 %v89145, %v89133 (stack39)
        %v89151 = vshll.u32 %v89145, 17 (stack44)
        %v89152 = vshrl.u32 %v89145, 15 (stack45)
        %v89153 = vor.u32 %v89152, %v89151 (stack46)
        %v89154 = vxor.u32 %v89153, %v89149 (stack47)
        %v89157 = vadd.s32 %v89154, %v89149 (stack39)
        %v89159 = vshll.u32 %v89154, 29 (stack44)
        %v89160 = vshrl.u32 %v89154, 3 (stack45)
        %v89161 = vor.u32 %v89160, %v89159 (stack46)
        %v89162 = vxor.u32 %v89161, %v89157 (stack47)
        %v89165 = vadd.s32 %v89162, %v89157 (stack39)
        %v89167 = vshll.u32 %v89162, 16 (stack44)
        %v89168 = vshrl.u32 %v89162, 16 (stack45)
        %v89169 = vor.u32 %v89168, %v89167 (stack46)
        %v89170 = vxor.u32 %v89169, %v89165 (stack47)
        %v89173 = vadd.s32 %v89170, %v89165 (stack39)
        %v89177 = vadd.s32 %v89173, %v9 (stack39)
        %v89179 = vshll.u32 %v89170, 24 (stack44)
        %v89180 = vshrl.u32 %v89170, 8 (stack45)
        %v89181 = vor.u32 %v89180, %v89179 (stack46)
        %v89182 = vxor.u32 %v89181, %v89173 (stack47)
        %v89185 = vadd.s32 %v89182, %v8 (stack39)
        %v89189 = vadd.s32 4, %v89185 (stack39)
        %v89193 = vadd.s32 %v89189, %v89177 (stack39)
        %v89195 = vshll.u32 %v89189, 13 (stack44)
        %v89196 = vshrl.u32 %v89189, 19 (stack45)
        %v89197 = vor.u32 %v89196, %v89195 (stack46)
        %v89198 = vxor.u32 %v89197, %v89193 (stack47)
        %v89201 = vadd.s32 %v89198, %v89193 (stack39)
        %v89203 = vshll.u32 %v89198, 15 (stack44)
        %v89204 = vshrl.u32 %v89198, 17 (stack45)
        %v89205 = vor.u32 %v89204, %v89203 (stack46)
        %v89206 = vxor.u32 %v89205, %v89201 (stack47)
        %v89209 = vadd.s32 %v89206, %v89201 (stack39)
        %v89211 = vshll.u32 %v89206, 26 (stack44)
        %v89212 = vshrl.u32 %v89206, 6 (stack45)
        %v89213 = vor.u32 %v89212, %v89211 (stack46)
        %v89214 = vxor.u32 %v89213, %v89209 (stack47)
        %v89217 = vadd.s32 %v89214, %v89209 (stack39)
        %v89221 = vadd.s32 %v89217, %v8 (stack39)
        %v89223 = vshll.u32 %v89214, 6 (stack44)
        %v89224 = vshrl.u32 %v89214, 26 (stack45)
        %v89225 = vor.u32 %v89224, %v89223 (stack46)
        %v89226 = vxor.u32 %v89225, %v89217 (stack47)
        %v89229 = vadd.s32 %v89226, %v10 (stack39)
        %v89233 = vadd.s32 5, %v89229 (stack39)
        %v89235 = vxor.u32 %v89233, %v89221 (stack47)
        %v89236 = vand.u32.u8 255, %v89235 (stack48)
        %v89237 = vand.u32 65535, %v89236 (stack49)
        %v89238 = vshrl.u32 %v89237, 1 (stack50)
        %v89239 = vor.u32 16256, %v89238 (stack46)
        %v89240 = vand.u32.u16 65535, %v89239 (stack51)
        %v120220 = vadd.low.f32.bf16 -1.0, %v89240 (stack52)
        %v89249 = vmul.f32 2.0, %v120220 (stack53)
        %v89253 = vadd.f32 -0.99609375, %v89249 (stack52)
        %v89257 = vmax.f32 %v89253, -0.99609375 (stack54)
        %v89259 = vand.u32 2147483647, %v89257 (stack55)
        %vm89262 = vcmp.eq.f32.partialorder %v89259, 1.0 (stack56)
        %v89267 = vmul.f32 inf, %v89257 (stack53)
        %v89269 = vxor.u32 2147483648, %v89257 (stack57)
        %v89272 = vmul.f32 %v89269, %v89257 (stack53)
        %v89274 = vadd.f32 1.0, %v89272 (stack58)
        %v89275 = vlog2.pop %v89274 (stack59)
        %v89276 = vmul.f32 0.6931472, %v89275 (stack60)
        %v89277 = vmul.f32 -0.5, %v89272 (stack61)
        %v89278 = vadd.f32 1.0, %v89277 (stack62)
        %v89279 = vmul.f32 %v89278, %v89272 (stack63)
        %v89280 = vand.u32 2147483647, %v89272 (stack64)
        %vm89281 = vcmp.lt.f32.partialorder %v89280, 0.0004427343 (stack65)
        %v89282 = vsel /*vm=*/%vm89281, /*on_true_vy=*/%v89279, /*on_false_vx=*/%v89276 (stack66)
        %v89283 = vxor.u32 2147483648, %v89282 (stack57)
        %vm89286 = vcmp.lt.f32.partialorder %v89283, 5.0 (stack56)
        %v89291 = vsel /*vm=*/%vm89286, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v89295 = vsel /*vm=*/%vm89286, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v89299 = vsel /*vm=*/%vm89286, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v89303 = vsel /*vm=*/%vm89286, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v89307 = vsel /*vm=*/%vm89286, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v89311 = vsel /*vm=*/%vm89286, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v89315 = vsel /*vm=*/%vm89286, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v89319 = vsel /*vm=*/%vm89286, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v89323 = vsel /*vm=*/%vm89286, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v89327 = vadd.f32 -2.5, %v89283 (stack52)
        %v89329 = vrsqrt.pop %v89283 (stack67)
        %v89330 = vmul.f32 %v89329, %v89283 (stack68)
        %vm89331 = vcmp.eq.f32.partialorder %v89283, inf (stack69)
        %v89332 = vsel /*vm=*/%vm89331, /*on_true_vy=*/%v89283, /*on_false_vx=*/%v89330 (stack70)
        %vm89333 = vcmp.eq.f32.partialorder %v89283, 0.0 (stack71)
        %v89334 = vand.u32 2147483648, %v89283 (stack72)
        %v89335 = vsel /*vm=*/%vm89333, /*on_true_vy=*/%v89334, /*on_false_vx=*/%v89332 (stack73)
        %v89338 = vadd.f32 -3.0, %v89335 (stack52)
        %v89342 = vsel /*vm=*/%vm89286, /*on_true_vy=*/%v89327, /*on_false_vx=*/%v89338 (stack43)
        %v89346 = vmul.f32 %v89342, %v89323 (stack53)
        %v89350 = vadd.f32 %v89346, %v89319 (stack52)
        %v89354 = vmul.f32 %v89350, %v89342 (stack53)
        %v89358 = vadd.f32 %v89354, %v89315 (stack52)
        %v89362 = vmul.f32 %v89358, %v89342 (stack53)
        %v89366 = vadd.f32 %v89362, %v89311 (stack52)
        %v89370 = vmul.f32 %v89366, %v89342 (stack53)
        %v89374 = vadd.f32 %v89370, %v89307 (stack52)
        %v89378 = vmul.f32 %v89374, %v89342 (stack53)
        %v89382 = vadd.f32 %v89378, %v89303 (stack52)
        %v89386 = vmul.f32 %v89382, %v89342 (stack53)
        %v89390 = vadd.f32 %v89386, %v89299 (stack52)
        %v89394 = vmul.f32 %v89390, %v89342 (stack53)
        %v89398 = vadd.f32 %v89394, %v89295 (stack52)
        %v89402 = vmul.f32 %v89398, %v89342 (stack53)
        %v89406 = vadd.f32 %v89402, %v89291 (stack52)
        %v89410 = vmul.f32 %v89406, %v89257 (stack53)
        %v89414 = vsel /*vm=*/%vm89262, /*on_true_vy=*/%v89267, /*on_false_vx=*/%v89410 (stack43)
        %v89418 = vmul.f32 1.4140625, %v89414 (stack53)
        %v89421 = vpack.c.bf16 0.0, %v89418 (stack74)
        %120221 = vst [vmem:[%s280 + $0x35c] sm:$0xf] /*vst_source=*/%v89421 (stack75)
        %v89425 = vadd.s32 %v86195, %v3816 (stack39)
        %v89435 = vadd.s32 %v89425, %v415 (stack39)
        %vm89439 = vcmp.lt.u32.totalorder %v89435, %v89425 (stack42)
        %vm89444 = vcmp.lt.u32.totalorder %v89425, %v3816 (stack42)
        %v89449 = vadd.s32 %v86178, %v3803 (stack39)
        %v89453 = vadd.s32 1, %v89449 (stack39)
        %v89457 = vsel /*vm=*/%vm89444, /*on_true_vy=*/%v89453, /*on_false_vx=*/%v89449 (stack43)
        %v89461 = vadd.s32 1, %v89457 (stack39)
        %v89465 = vsel /*vm=*/%vm89439, /*on_true_vy=*/%v89461, /*on_false_vx=*/%v89457 (stack43)
        %v89470 = vadd.s32 %v89465, %v10 (stack39)
        %v89474 = vadd.s32 %v89435, %v9 (stack39)
        %v89478 = vadd.s32 %v89474, %v89470 (stack39)
        %v89480 = vshll.u32 %v89474, 13 (stack44)
        %v89481 = vshrl.u32 %v89474, 19 (stack45)
        %v89482 = vor.u32 %v89481, %v89480 (stack46)
        %v89483 = vxor.u32 %v89482, %v89478 (stack47)
        %v89486 = vadd.s32 %v89483, %v89478 (stack39)
        %v89488 = vshll.u32 %v89483, 15 (stack44)
        %v89489 = vshrl.u32 %v89483, 17 (stack45)
        %v89490 = vor.u32 %v89489, %v89488 (stack46)
        %v89491 = vxor.u32 %v89490, %v89486 (stack47)
        %v89494 = vadd.s32 %v89491, %v89486 (stack39)
        %v89496 = vshll.u32 %v89491, 26 (stack44)
        %v89497 = vshrl.u32 %v89491, 6 (stack45)
        %v89498 = vor.u32 %v89497, %v89496 (stack46)
        %v89499 = vxor.u32 %v89498, %v89494 (stack47)
        %v89502 = vadd.s32 %v89499, %v89494 (stack39)
        %v89506 = vadd.s32 %v89502, %v9 (stack39)
        %v89508 = vshll.u32 %v89499, 6 (stack44)
        %v89509 = vshrl.u32 %v89499, 26 (stack45)
        %v89510 = vor.u32 %v89509, %v89508 (stack46)
        %v89511 = vxor.u32 %v89510, %v89502 (stack47)
        %v89514 = vadd.s32 %v89511, %v8 (stack39)
        %v89518 = vadd.s32 1, %v89514 (stack39)
        %v89522 = vadd.s32 %v89518, %v89506 (stack39)
        %v89524 = vshll.u32 %v89518, 17 (stack44)
        %v89525 = vshrl.u32 %v89518, 15 (stack45)
        %v89526 = vor.u32 %v89525, %v89524 (stack46)
        %v89527 = vxor.u32 %v89526, %v89522 (stack47)
        %v89530 = vadd.s32 %v89527, %v89522 (stack39)
        %v89532 = vshll.u32 %v89527, 29 (stack44)
        %v89533 = vshrl.u32 %v89527, 3 (stack45)
        %v89534 = vor.u32 %v89533, %v89532 (stack46)
        %v89535 = vxor.u32 %v89534, %v89530 (stack47)
        %v89538 = vadd.s32 %v89535, %v89530 (stack39)
        %v89540 = vshll.u32 %v89535, 16 (stack44)
        %v89541 = vshrl.u32 %v89535, 16 (stack45)
        %v89542 = vor.u32 %v89541, %v89540 (stack46)
        %v89543 = vxor.u32 %v89542, %v89538 (stack47)
        %v89546 = vadd.s32 %v89543, %v89538 (stack39)
        %v89550 = vadd.s32 %v89546, %v8 (stack39)
        %v89552 = vshll.u32 %v89543, 24 (stack44)
        %v89553 = vshrl.u32 %v89543, 8 (stack45)
        %v89554 = vor.u32 %v89553, %v89552 (stack46)
        %v89555 = vxor.u32 %v89554, %v89546 (stack47)
        %v89558 = vadd.s32 %v89555, %v10 (stack39)
        %v89562 = vadd.s32 2, %v89558 (stack39)
        %v89566 = vadd.s32 %v89562, %v89550 (stack39)
        %v89568 = vshll.u32 %v89562, 13 (stack44)
        %v89569 = vshrl.u32 %v89562, 19 (stack45)
        %v89570 = vor.u32 %v89569, %v89568 (stack46)
        %v89571 = vxor.u32 %v89570, %v89566 (stack47)
        %v89574 = vadd.s32 %v89571, %v89566 (stack39)
        %v89576 = vshll.u32 %v89571, 15 (stack44)
        %v89577 = vshrl.u32 %v89571, 17 (stack45)
        %v89578 = vor.u32 %v89577, %v89576 (stack46)
        %v89579 = vxor.u32 %v89578, %v89574 (stack47)
        %v89582 = vadd.s32 %v89579, %v89574 (stack39)
        %v89584 = vshll.u32 %v89579, 26 (stack44)
        %v89585 = vshrl.u32 %v89579, 6 (stack45)
        %v89586 = vor.u32 %v89585, %v89584 (stack46)
        %v89587 = vxor.u32 %v89586, %v89582 (stack47)
        %v89590 = vadd.s32 %v89587, %v89582 (stack39)
        %v89594 = vadd.s32 %v89590, %v10 (stack39)
        %v89596 = vshll.u32 %v89587, 6 (stack44)
        %v89597 = vshrl.u32 %v89587, 26 (stack45)
        %v89598 = vor.u32 %v89597, %v89596 (stack46)
        %v89599 = vxor.u32 %v89598, %v89590 (stack47)
        %v89602 = vadd.s32 %v89599, %v9 (stack39)
        %v89606 = vadd.s32 3, %v89602 (stack39)
        %v89610 = vadd.s32 %v89606, %v89594 (stack39)
        %v89612 = vshll.u32 %v89606, 17 (stack44)
        %v89613 = vshrl.u32 %v89606, 15 (stack45)
        %v89614 = vor.u32 %v89613, %v89612 (stack46)
        %v89615 = vxor.u32 %v89614, %v89610 (stack47)
        %v89618 = vadd.s32 %v89615, %v89610 (stack39)
        %v89620 = vshll.u32 %v89615, 29 (stack44)
        %v89621 = vshrl.u32 %v89615, 3 (stack45)
        %v89622 = vor.u32 %v89621, %v89620 (stack46)
        %v89623 = vxor.u32 %v89622, %v89618 (stack47)
        %v89626 = vadd.s32 %v89623, %v89618 (stack39)
        %v89628 = vshll.u32 %v89623, 16 (stack44)
        %v89629 = vshrl.u32 %v89623, 16 (stack45)
        %v89630 = vor.u32 %v89629, %v89628 (stack46)
        %v89631 = vxor.u32 %v89630, %v89626 (stack47)
        %v89634 = vadd.s32 %v89631, %v89626 (stack39)
        %v89638 = vadd.s32 %v89634, %v9 (stack39)
        %v89640 = vshll.u32 %v89631, 24 (stack44)
        %v89641 = vshrl.u32 %v89631, 8 (stack45)
        %v89642 = vor.u32 %v89641, %v89640 (stack46)
        %v89643 = vxor.u32 %v89642, %v89634 (stack47)
        %v89646 = vadd.s32 %v89643, %v8 (stack39)
        %v89650 = vadd.s32 4, %v89646 (stack39)
        %v89654 = vadd.s32 %v89650, %v89638 (stack39)
        %v89656 = vshll.u32 %v89650, 13 (stack44)
        %v89657 = vshrl.u32 %v89650, 19 (stack45)
        %v89658 = vor.u32 %v89657, %v89656 (stack46)
        %v89659 = vxor.u32 %v89658, %v89654 (stack47)
        %v89662 = vadd.s32 %v89659, %v89654 (stack39)
        %v89664 = vshll.u32 %v89659, 15 (stack44)
        %v89665 = vshrl.u32 %v89659, 17 (stack45)
        %v89666 = vor.u32 %v89665, %v89664 (stack46)
        %v89667 = vxor.u32 %v89666, %v89662 (stack47)
        %v89670 = vadd.s32 %v89667, %v89662 (stack39)
        %v89672 = vshll.u32 %v89667, 26 (stack44)
        %v89673 = vshrl.u32 %v89667, 6 (stack45)
        %v89674 = vor.u32 %v89673, %v89672 (stack46)
        %v89675 = vxor.u32 %v89674, %v89670 (stack47)
        %v89678 = vadd.s32 %v89675, %v89670 (stack39)
        %v89682 = vadd.s32 %v89678, %v8 (stack39)
        %v89684 = vshll.u32 %v89675, 6 (stack44)
        %v89685 = vshrl.u32 %v89675, 26 (stack45)
        %v89686 = vor.u32 %v89685, %v89684 (stack46)
        %v89687 = vxor.u32 %v89686, %v89678 (stack47)
        %v89690 = vadd.s32 %v89687, %v10 (stack39)
        %v89694 = vadd.s32 5, %v89690 (stack39)
        %v89696 = vxor.u32 %v89694, %v89682 (stack47)
        %v89697 = vand.u32.u8 255, %v89696 (stack48)
        %v89698 = vand.u32 65535, %v89697 (stack49)
        %v89699 = vshrl.u32 %v89698, 1 (stack50)
        %v89700 = vor.u32 16256, %v89699 (stack46)
        %v89701 = vand.u32.u16 65535, %v89700 (stack51)
        %v120222 = vadd.low.f32.bf16 -1.0, %v89701 (stack52)
        %v89710 = vmul.f32 2.0, %v120222 (stack53)
        %v89714 = vadd.f32 -0.99609375, %v89710 (stack52)
        %v89718 = vmax.f32 %v89714, -0.99609375 (stack54)
        %v89720 = vand.u32 2147483647, %v89718 (stack55)
        %vm89723 = vcmp.eq.f32.partialorder %v89720, 1.0 (stack56)
        %v89728 = vmul.f32 inf, %v89718 (stack53)
        %v89730 = vxor.u32 2147483648, %v89718 (stack57)
        %v89733 = vmul.f32 %v89730, %v89718 (stack53)
        %v89735 = vadd.f32 1.0, %v89733 (stack58)
        %v89736 = vlog2.pop %v89735 (stack59)
        %v89737 = vmul.f32 0.6931472, %v89736 (stack60)
        %v89738 = vmul.f32 -0.5, %v89733 (stack61)
        %v89739 = vadd.f32 1.0, %v89738 (stack62)
        %v89740 = vmul.f32 %v89739, %v89733 (stack63)
        %v89741 = vand.u32 2147483647, %v89733 (stack64)
        %vm89742 = vcmp.lt.f32.partialorder %v89741, 0.0004427343 (stack65)
        %v89743 = vsel /*vm=*/%vm89742, /*on_true_vy=*/%v89740, /*on_false_vx=*/%v89737 (stack66)
        %v89744 = vxor.u32 2147483648, %v89743 (stack57)
        %vm89747 = vcmp.lt.f32.partialorder %v89744, 5.0 (stack56)
        %v89752 = vsel /*vm=*/%vm89747, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v89756 = vsel /*vm=*/%vm89747, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v89760 = vsel /*vm=*/%vm89747, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v89764 = vsel /*vm=*/%vm89747, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v89768 = vsel /*vm=*/%vm89747, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v89772 = vsel /*vm=*/%vm89747, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v89776 = vsel /*vm=*/%vm89747, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v89780 = vsel /*vm=*/%vm89747, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v89784 = vsel /*vm=*/%vm89747, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v89788 = vadd.f32 -2.5, %v89744 (stack52)
        %v89790 = vrsqrt.pop %v89744 (stack67)
        %v89791 = vmul.f32 %v89790, %v89744 (stack68)
        %vm89792 = vcmp.eq.f32.partialorder %v89744, inf (stack69)
        %v89793 = vsel /*vm=*/%vm89792, /*on_true_vy=*/%v89744, /*on_false_vx=*/%v89791 (stack70)
        %vm89794 = vcmp.eq.f32.partialorder %v89744, 0.0 (stack71)
        %v89795 = vand.u32 2147483648, %v89744 (stack72)
        %v89796 = vsel /*vm=*/%vm89794, /*on_true_vy=*/%v89795, /*on_false_vx=*/%v89793 (stack73)
        %v89799 = vadd.f32 -3.0, %v89796 (stack52)
        %v89803 = vsel /*vm=*/%vm89747, /*on_true_vy=*/%v89788, /*on_false_vx=*/%v89799 (stack43)
        %v89807 = vmul.f32 %v89803, %v89784 (stack53)
        %v89811 = vadd.f32 %v89807, %v89780 (stack52)
        %v89815 = vmul.f32 %v89811, %v89803 (stack53)
        %v89819 = vadd.f32 %v89815, %v89776 (stack52)
        %v89823 = vmul.f32 %v89819, %v89803 (stack53)
        %v89827 = vadd.f32 %v89823, %v89772 (stack52)
        %v89831 = vmul.f32 %v89827, %v89803 (stack53)
        %v89835 = vadd.f32 %v89831, %v89768 (stack52)
        %v89839 = vmul.f32 %v89835, %v89803 (stack53)
        %v89843 = vadd.f32 %v89839, %v89764 (stack52)
        %v89847 = vmul.f32 %v89843, %v89803 (stack53)
        %v89851 = vadd.f32 %v89847, %v89760 (stack52)
        %v89855 = vmul.f32 %v89851, %v89803 (stack53)
        %v89859 = vadd.f32 %v89855, %v89756 (stack52)
        %v89863 = vmul.f32 %v89859, %v89803 (stack53)
        %v89867 = vadd.f32 %v89863, %v89752 (stack52)
        %v89871 = vmul.f32 %v89867, %v89718 (stack53)
        %v89875 = vsel /*vm=*/%vm89723, /*on_true_vy=*/%v89728, /*on_false_vx=*/%v89871 (stack43)
        %v89879 = vmul.f32 1.4140625, %v89875 (stack53)
        %v89882 = vpack.c.bf16 0.0, %v89879 (stack74)
        %120223 = vst [vmem:[%s280 + $0x3dc] sm:$0xf] /*vst_source=*/%v89882 (stack75)
        %s89884 = sadd.s32 192, %s120390 (stack76)
        %s89885 = sshrl.u32 %s89884, 10 (stack23)
        %p120224 = scmp.gt.s32.totalorder %s89885, 1 (stack24)
        %s89887 = scalar_select /*predicate=*/%p120224, /*on_true=*/1, /*on_false=*/%s89885 (stack25)
        %s89888 = sand.u32 1023, %s89884 /* smod.u32 w/div 1024 */ (stack26)
        %s89889 = sshrl.u32 %s89888, 7 (stack27)
        %s89890 = sand.u32 127, %s89888 /* smod.u32 w/div 128 */ (stack28)
        %s120225 = sshll.u32 %s89887, 3 (stack29)
        %s89892 = scalar_lea.vmem %s3, %s120225 (stack30)
        %s89894 = scalar_lea.vmem %s89892, %s89889 (stack31)
        %v89895 = vld [vmem:[%s89894] ss:$0 sm:$0xff] (stack32)
        %s89896 = sand.u32 255, %s89890 (stack33)
        %s89898 = sor.u32 256, %s89896 (stack34)
        %89899 = vbcast.lane.b32.xlu0 %v89895, %s89898 (stack35)
        %v89900 = vpop.permute.xlu0 %89899 (stack36)
        %s89909 = scalar_lea.vmem %s5, %s120225 (stack30)
        %s89911 = scalar_lea.vmem %s89909, %s89889 (stack31)
        %v89912 = vld [vmem:[%s89911] ss:$0 sm:$0xff] (stack32)
        %89916 = vbcast.lane.b32.xlu0 %v89912, %s89898 (stack35)
        %v89917 = vpop.permute.xlu0 %89916 (stack36)
        %v89920 = vadd.s32 %v89917, %v408 (stack39)
        %v89930 = vadd.s32 %v89920, %v415 (stack39)
        %vm89934 = vcmp.lt.u32.totalorder %v89930, %v89920 (stack42)
        %vm89939 = vcmp.lt.u32.totalorder %v89920, %v408 (stack42)
        %v89944 = vadd.s32 %v89900, %v380 (stack39)
        %v89948 = vadd.s32 1, %v89944 (stack39)
        %v89952 = vsel /*vm=*/%vm89939, /*on_true_vy=*/%v89948, /*on_false_vx=*/%v89944 (stack43)
        %v89956 = vadd.s32 1, %v89952 (stack39)
        %v89960 = vsel /*vm=*/%vm89934, /*on_true_vy=*/%v89956, /*on_false_vx=*/%v89952 (stack43)
        %v89965 = vadd.s32 %v89960, %v10 (stack39)
        %v89969 = vadd.s32 %v89930, %v9 (stack39)
        %v89973 = vadd.s32 %v89969, %v89965 (stack39)
        %v89975 = vshll.u32 %v89969, 13 (stack44)
        %v89976 = vshrl.u32 %v89969, 19 (stack45)
        %v89977 = vor.u32 %v89976, %v89975 (stack46)
        %v89978 = vxor.u32 %v89977, %v89973 (stack47)
        %v89981 = vadd.s32 %v89978, %v89973 (stack39)
        %v89983 = vshll.u32 %v89978, 15 (stack44)
        %v89984 = vshrl.u32 %v89978, 17 (stack45)
        %v89985 = vor.u32 %v89984, %v89983 (stack46)
        %v89986 = vxor.u32 %v89985, %v89981 (stack47)
        %v89989 = vadd.s32 %v89986, %v89981 (stack39)
        %v89991 = vshll.u32 %v89986, 26 (stack44)
        %v89992 = vshrl.u32 %v89986, 6 (stack45)
        %v89993 = vor.u32 %v89992, %v89991 (stack46)
        %v89994 = vxor.u32 %v89993, %v89989 (stack47)
        %v89997 = vadd.s32 %v89994, %v89989 (stack39)
        %v90001 = vadd.s32 %v89997, %v9 (stack39)
        %v90003 = vshll.u32 %v89994, 6 (stack44)
        %v90004 = vshrl.u32 %v89994, 26 (stack45)
        %v90005 = vor.u32 %v90004, %v90003 (stack46)
        %v90006 = vxor.u32 %v90005, %v89997 (stack47)
        %v90009 = vadd.s32 %v90006, %v8 (stack39)
        %v90013 = vadd.s32 1, %v90009 (stack39)
        %v90017 = vadd.s32 %v90013, %v90001 (stack39)
        %v90019 = vshll.u32 %v90013, 17 (stack44)
        %v90020 = vshrl.u32 %v90013, 15 (stack45)
        %v90021 = vor.u32 %v90020, %v90019 (stack46)
        %v90022 = vxor.u32 %v90021, %v90017 (stack47)
        %v90025 = vadd.s32 %v90022, %v90017 (stack39)
        %v90027 = vshll.u32 %v90022, 29 (stack44)
        %v90028 = vshrl.u32 %v90022, 3 (stack45)
        %v90029 = vor.u32 %v90028, %v90027 (stack46)
        %v90030 = vxor.u32 %v90029, %v90025 (stack47)
        %v90033 = vadd.s32 %v90030, %v90025 (stack39)
        %v90035 = vshll.u32 %v90030, 16 (stack44)
        %v90036 = vshrl.u32 %v90030, 16 (stack45)
        %v90037 = vor.u32 %v90036, %v90035 (stack46)
        %v90038 = vxor.u32 %v90037, %v90033 (stack47)
        %v90041 = vadd.s32 %v90038, %v90033 (stack39)
        %v90045 = vadd.s32 %v90041, %v8 (stack39)
        %v90047 = vshll.u32 %v90038, 24 (stack44)
        %v90048 = vshrl.u32 %v90038, 8 (stack45)
        %v90049 = vor.u32 %v90048, %v90047 (stack46)
        %v90050 = vxor.u32 %v90049, %v90041 (stack47)
        %v90053 = vadd.s32 %v90050, %v10 (stack39)
        %v90057 = vadd.s32 2, %v90053 (stack39)
        %v90061 = vadd.s32 %v90057, %v90045 (stack39)
        %v90063 = vshll.u32 %v90057, 13 (stack44)
        %v90064 = vshrl.u32 %v90057, 19 (stack45)
        %v90065 = vor.u32 %v90064, %v90063 (stack46)
        %v90066 = vxor.u32 %v90065, %v90061 (stack47)
        %v90069 = vadd.s32 %v90066, %v90061 (stack39)
        %v90071 = vshll.u32 %v90066, 15 (stack44)
        %v90072 = vshrl.u32 %v90066, 17 (stack45)
        %v90073 = vor.u32 %v90072, %v90071 (stack46)
        %v90074 = vxor.u32 %v90073, %v90069 (stack47)
        %v90077 = vadd.s32 %v90074, %v90069 (stack39)
        %v90079 = vshll.u32 %v90074, 26 (stack44)
        %v90080 = vshrl.u32 %v90074, 6 (stack45)
        %v90081 = vor.u32 %v90080, %v90079 (stack46)
        %v90082 = vxor.u32 %v90081, %v90077 (stack47)
        %v90085 = vadd.s32 %v90082, %v90077 (stack39)
        %v90089 = vadd.s32 %v90085, %v10 (stack39)
        %v90091 = vshll.u32 %v90082, 6 (stack44)
        %v90092 = vshrl.u32 %v90082, 26 (stack45)
        %v90093 = vor.u32 %v90092, %v90091 (stack46)
        %v90094 = vxor.u32 %v90093, %v90085 (stack47)
        %v90097 = vadd.s32 %v90094, %v9 (stack39)
        %v90101 = vadd.s32 3, %v90097 (stack39)
        %v90105 = vadd.s32 %v90101, %v90089 (stack39)
        %v90107 = vshll.u32 %v90101, 17 (stack44)
        %v90108 = vshrl.u32 %v90101, 15 (stack45)
        %v90109 = vor.u32 %v90108, %v90107 (stack46)
        %v90110 = vxor.u32 %v90109, %v90105 (stack47)
        %v90113 = vadd.s32 %v90110, %v90105 (stack39)
        %v90115 = vshll.u32 %v90110, 29 (stack44)
        %v90116 = vshrl.u32 %v90110, 3 (stack45)
        %v90117 = vor.u32 %v90116, %v90115 (stack46)
        %v90118 = vxor.u32 %v90117, %v90113 (stack47)
        %v90121 = vadd.s32 %v90118, %v90113 (stack39)
        %v90123 = vshll.u32 %v90118, 16 (stack44)
        %v90124 = vshrl.u32 %v90118, 16 (stack45)
        %v90125 = vor.u32 %v90124, %v90123 (stack46)
        %v90126 = vxor.u32 %v90125, %v90121 (stack47)
        %v90129 = vadd.s32 %v90126, %v90121 (stack39)
        %v90133 = vadd.s32 %v90129, %v9 (stack39)
        %v90135 = vshll.u32 %v90126, 24 (stack44)
        %v90136 = vshrl.u32 %v90126, 8 (stack45)
        %v90137 = vor.u32 %v90136, %v90135 (stack46)
        %v90138 = vxor.u32 %v90137, %v90129 (stack47)
        %v90141 = vadd.s32 %v90138, %v8 (stack39)
        %v90145 = vadd.s32 4, %v90141 (stack39)
        %v90149 = vadd.s32 %v90145, %v90133 (stack39)
        %v90151 = vshll.u32 %v90145, 13 (stack44)
        %v90152 = vshrl.u32 %v90145, 19 (stack45)
        %v90153 = vor.u32 %v90152, %v90151 (stack46)
        %v90154 = vxor.u32 %v90153, %v90149 (stack47)
        %v90157 = vadd.s32 %v90154, %v90149 (stack39)
        %v90159 = vshll.u32 %v90154, 15 (stack44)
        %v90160 = vshrl.u32 %v90154, 17 (stack45)
        %v90161 = vor.u32 %v90160, %v90159 (stack46)
        %v90162 = vxor.u32 %v90161, %v90157 (stack47)
        %v90165 = vadd.s32 %v90162, %v90157 (stack39)
        %v90167 = vshll.u32 %v90162, 26 (stack44)
        %v90168 = vshrl.u32 %v90162, 6 (stack45)
        %v90169 = vor.u32 %v90168, %v90167 (stack46)
        %v90170 = vxor.u32 %v90169, %v90165 (stack47)
        %v90173 = vadd.s32 %v90170, %v90165 (stack39)
        %v90177 = vadd.s32 %v90173, %v8 (stack39)
        %v90179 = vshll.u32 %v90170, 6 (stack44)
        %v90180 = vshrl.u32 %v90170, 26 (stack45)
        %v90181 = vor.u32 %v90180, %v90179 (stack46)
        %v90182 = vxor.u32 %v90181, %v90173 (stack47)
        %v90185 = vadd.s32 %v90182, %v10 (stack39)
        %v90189 = vadd.s32 5, %v90185 (stack39)
        %v90191 = vxor.u32 %v90189, %v90177 (stack47)
        %v90192 = vand.u32.u8 255, %v90191 (stack48)
        %v90193 = vand.u32 65535, %v90192 (stack49)
        %v90194 = vshrl.u32 %v90193, 1 (stack50)
        %v90195 = vor.u32 16256, %v90194 (stack46)
        %v90196 = vand.u32.u16 65535, %v90195 (stack51)
        %v120228 = vadd.low.f32.bf16 -1.0, %v90196 (stack52)
        %v90205 = vmul.f32 2.0, %v120228 (stack53)
        %v90209 = vadd.f32 -0.99609375, %v90205 (stack52)
        %v90213 = vmax.f32 %v90209, -0.99609375 (stack54)
        %v90215 = vand.u32 2147483647, %v90213 (stack55)
        %vm90218 = vcmp.eq.f32.partialorder %v90215, 1.0 (stack56)
        %v90223 = vmul.f32 inf, %v90213 (stack53)
        %v90225 = vxor.u32 2147483648, %v90213 (stack57)
        %v90228 = vmul.f32 %v90225, %v90213 (stack53)
        %v90230 = vadd.f32 1.0, %v90228 (stack58)
        %v90231 = vlog2.pop %v90230 (stack59)
        %v90232 = vmul.f32 0.6931472, %v90231 (stack60)
        %v90233 = vmul.f32 -0.5, %v90228 (stack61)
        %v90234 = vadd.f32 1.0, %v90233 (stack62)
        %v90235 = vmul.f32 %v90234, %v90228 (stack63)
        %v90236 = vand.u32 2147483647, %v90228 (stack64)
        %vm90237 = vcmp.lt.f32.partialorder %v90236, 0.0004427343 (stack65)
        %v90238 = vsel /*vm=*/%vm90237, /*on_true_vy=*/%v90235, /*on_false_vx=*/%v90232 (stack66)
        %v90239 = vxor.u32 2147483648, %v90238 (stack57)
        %vm90242 = vcmp.lt.f32.partialorder %v90239, 5.0 (stack56)
        %v90247 = vsel /*vm=*/%vm90242, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v90251 = vsel /*vm=*/%vm90242, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v90255 = vsel /*vm=*/%vm90242, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v90259 = vsel /*vm=*/%vm90242, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v90263 = vsel /*vm=*/%vm90242, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v90267 = vsel /*vm=*/%vm90242, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v90271 = vsel /*vm=*/%vm90242, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v90275 = vsel /*vm=*/%vm90242, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v90279 = vsel /*vm=*/%vm90242, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v90283 = vadd.f32 -2.5, %v90239 (stack52)
        %v90285 = vrsqrt.pop %v90239 (stack67)
        %v90286 = vmul.f32 %v90285, %v90239 (stack68)
        %vm90287 = vcmp.eq.f32.partialorder %v90239, inf (stack69)
        %v90288 = vsel /*vm=*/%vm90287, /*on_true_vy=*/%v90239, /*on_false_vx=*/%v90286 (stack70)
        %vm90289 = vcmp.eq.f32.partialorder %v90239, 0.0 (stack71)
        %v90290 = vand.u32 2147483648, %v90239 (stack72)
        %v90291 = vsel /*vm=*/%vm90289, /*on_true_vy=*/%v90290, /*on_false_vx=*/%v90288 (stack73)
        %v90294 = vadd.f32 -3.0, %v90291 (stack52)
        %v90298 = vsel /*vm=*/%vm90242, /*on_true_vy=*/%v90283, /*on_false_vx=*/%v90294 (stack43)
        %v90302 = vmul.f32 %v90298, %v90279 (stack53)
        %v90306 = vadd.f32 %v90302, %v90275 (stack52)
        %v90310 = vmul.f32 %v90306, %v90298 (stack53)
        %v90314 = vadd.f32 %v90310, %v90271 (stack52)
        %v90318 = vmul.f32 %v90314, %v90298 (stack53)
        %v90322 = vadd.f32 %v90318, %v90267 (stack52)
        %v90326 = vmul.f32 %v90322, %v90298 (stack53)
        %v90330 = vadd.f32 %v90326, %v90263 (stack52)
        %v90334 = vmul.f32 %v90330, %v90298 (stack53)
        %v90338 = vadd.f32 %v90334, %v90259 (stack52)
        %v90342 = vmul.f32 %v90338, %v90298 (stack53)
        %v90346 = vadd.f32 %v90342, %v90255 (stack52)
        %v90350 = vmul.f32 %v90346, %v90298 (stack53)
        %v90354 = vadd.f32 %v90350, %v90251 (stack52)
        %v90358 = vmul.f32 %v90354, %v90298 (stack53)
        %v90362 = vadd.f32 %v90358, %v90247 (stack52)
        %v90366 = vmul.f32 %v90362, %v90213 (stack53)
        %v90370 = vsel /*vm=*/%vm90218, /*on_true_vy=*/%v90223, /*on_false_vx=*/%v90366 (stack43)
        %v90374 = vmul.f32 1.4140625, %v90370 (stack53)
        %v90377 = vpack.c.bf16 0.0, %v90374 (stack74)
        %120229 = vst [vmem:[%s280 + $0x60] sm:$0xf] /*vst_source=*/%v90377 (stack75)
        %v90381 = vadd.s32 %v89917, %v894 (stack39)
        %v90391 = vadd.s32 %v90381, %v415 (stack39)
        %vm90395 = vcmp.lt.u32.totalorder %v90391, %v90381 (stack42)
        %vm90400 = vcmp.lt.u32.totalorder %v90381, %v894 (stack42)
        %v90405 = vadd.s32 %v89900, %v881 (stack39)
        %v90409 = vadd.s32 1, %v90405 (stack39)
        %v90413 = vsel /*vm=*/%vm90400, /*on_true_vy=*/%v90409, /*on_false_vx=*/%v90405 (stack43)
        %v90417 = vadd.s32 1, %v90413 (stack39)
        %v90421 = vsel /*vm=*/%vm90395, /*on_true_vy=*/%v90417, /*on_false_vx=*/%v90413 (stack43)
        %v90426 = vadd.s32 %v90421, %v10 (stack39)
        %v90430 = vadd.s32 %v90391, %v9 (stack39)
        %v90434 = vadd.s32 %v90430, %v90426 (stack39)
        %v90436 = vshll.u32 %v90430, 13 (stack44)
        %v90437 = vshrl.u32 %v90430, 19 (stack45)
        %v90438 = vor.u32 %v90437, %v90436 (stack46)
        %v90439 = vxor.u32 %v90438, %v90434 (stack47)
        %v90442 = vadd.s32 %v90439, %v90434 (stack39)
        %v90444 = vshll.u32 %v90439, 15 (stack44)
        %v90445 = vshrl.u32 %v90439, 17 (stack45)
        %v90446 = vor.u32 %v90445, %v90444 (stack46)
        %v90447 = vxor.u32 %v90446, %v90442 (stack47)
        %v90450 = vadd.s32 %v90447, %v90442 (stack39)
        %v90452 = vshll.u32 %v90447, 26 (stack44)
        %v90453 = vshrl.u32 %v90447, 6 (stack45)
        %v90454 = vor.u32 %v90453, %v90452 (stack46)
        %v90455 = vxor.u32 %v90454, %v90450 (stack47)
        %v90458 = vadd.s32 %v90455, %v90450 (stack39)
        %v90462 = vadd.s32 %v90458, %v9 (stack39)
        %v90464 = vshll.u32 %v90455, 6 (stack44)
        %v90465 = vshrl.u32 %v90455, 26 (stack45)
        %v90466 = vor.u32 %v90465, %v90464 (stack46)
        %v90467 = vxor.u32 %v90466, %v90458 (stack47)
        %v90470 = vadd.s32 %v90467, %v8 (stack39)
        %v90474 = vadd.s32 1, %v90470 (stack39)
        %v90478 = vadd.s32 %v90474, %v90462 (stack39)
        %v90480 = vshll.u32 %v90474, 17 (stack44)
        %v90481 = vshrl.u32 %v90474, 15 (stack45)
        %v90482 = vor.u32 %v90481, %v90480 (stack46)
        %v90483 = vxor.u32 %v90482, %v90478 (stack47)
        %v90486 = vadd.s32 %v90483, %v90478 (stack39)
        %v90488 = vshll.u32 %v90483, 29 (stack44)
        %v90489 = vshrl.u32 %v90483, 3 (stack45)
        %v90490 = vor.u32 %v90489, %v90488 (stack46)
        %v90491 = vxor.u32 %v90490, %v90486 (stack47)
        %v90494 = vadd.s32 %v90491, %v90486 (stack39)
        %v90496 = vshll.u32 %v90491, 16 (stack44)
        %v90497 = vshrl.u32 %v90491, 16 (stack45)
        %v90498 = vor.u32 %v90497, %v90496 (stack46)
        %v90499 = vxor.u32 %v90498, %v90494 (stack47)
        %v90502 = vadd.s32 %v90499, %v90494 (stack39)
        %v90506 = vadd.s32 %v90502, %v8 (stack39)
        %v90508 = vshll.u32 %v90499, 24 (stack44)
        %v90509 = vshrl.u32 %v90499, 8 (stack45)
        %v90510 = vor.u32 %v90509, %v90508 (stack46)
        %v90511 = vxor.u32 %v90510, %v90502 (stack47)
        %v90514 = vadd.s32 %v90511, %v10 (stack39)
        %v90518 = vadd.s32 2, %v90514 (stack39)
        %v90522 = vadd.s32 %v90518, %v90506 (stack39)
        %v90524 = vshll.u32 %v90518, 13 (stack44)
        %v90525 = vshrl.u32 %v90518, 19 (stack45)
        %v90526 = vor.u32 %v90525, %v90524 (stack46)
        %v90527 = vxor.u32 %v90526, %v90522 (stack47)
        %v90530 = vadd.s32 %v90527, %v90522 (stack39)
        %v90532 = vshll.u32 %v90527, 15 (stack44)
        %v90533 = vshrl.u32 %v90527, 17 (stack45)
        %v90534 = vor.u32 %v90533, %v90532 (stack46)
        %v90535 = vxor.u32 %v90534, %v90530 (stack47)
        %v90538 = vadd.s32 %v90535, %v90530 (stack39)
        %v90540 = vshll.u32 %v90535, 26 (stack44)
        %v90541 = vshrl.u32 %v90535, 6 (stack45)
        %v90542 = vor.u32 %v90541, %v90540 (stack46)
        %v90543 = vxor.u32 %v90542, %v90538 (stack47)
        %v90546 = vadd.s32 %v90543, %v90538 (stack39)
        %v90550 = vadd.s32 %v90546, %v10 (stack39)
        %v90552 = vshll.u32 %v90543, 6 (stack44)
        %v90553 = vshrl.u32 %v90543, 26 (stack45)
        %v90554 = vor.u32 %v90553, %v90552 (stack46)
        %v90555 = vxor.u32 %v90554, %v90546 (stack47)
        %v90558 = vadd.s32 %v90555, %v9 (stack39)
        %v90562 = vadd.s32 3, %v90558 (stack39)
        %v90566 = vadd.s32 %v90562, %v90550 (stack39)
        %v90568 = vshll.u32 %v90562, 17 (stack44)
        %v90569 = vshrl.u32 %v90562, 15 (stack45)
        %v90570 = vor.u32 %v90569, %v90568 (stack46)
        %v90571 = vxor.u32 %v90570, %v90566 (stack47)
        %v90574 = vadd.s32 %v90571, %v90566 (stack39)
        %v90576 = vshll.u32 %v90571, 29 (stack44)
        %v90577 = vshrl.u32 %v90571, 3 (stack45)
        %v90578 = vor.u32 %v90577, %v90576 (stack46)
        %v90579 = vxor.u32 %v90578, %v90574 (stack47)
        %v90582 = vadd.s32 %v90579, %v90574 (stack39)
        %v90584 = vshll.u32 %v90579, 16 (stack44)
        %v90585 = vshrl.u32 %v90579, 16 (stack45)
        %v90586 = vor.u32 %v90585, %v90584 (stack46)
        %v90587 = vxor.u32 %v90586, %v90582 (stack47)
        %v90590 = vadd.s32 %v90587, %v90582 (stack39)
        %v90594 = vadd.s32 %v90590, %v9 (stack39)
        %v90596 = vshll.u32 %v90587, 24 (stack44)
        %v90597 = vshrl.u32 %v90587, 8 (stack45)
        %v90598 = vor.u32 %v90597, %v90596 (stack46)
        %v90599 = vxor.u32 %v90598, %v90590 (stack47)
        %v90602 = vadd.s32 %v90599, %v8 (stack39)
        %v90606 = vadd.s32 4, %v90602 (stack39)
        %v90610 = vadd.s32 %v90606, %v90594 (stack39)
        %v90612 = vshll.u32 %v90606, 13 (stack44)
        %v90613 = vshrl.u32 %v90606, 19 (stack45)
        %v90614 = vor.u32 %v90613, %v90612 (stack46)
        %v90615 = vxor.u32 %v90614, %v90610 (stack47)
        %v90618 = vadd.s32 %v90615, %v90610 (stack39)
        %v90620 = vshll.u32 %v90615, 15 (stack44)
        %v90621 = vshrl.u32 %v90615, 17 (stack45)
        %v90622 = vor.u32 %v90621, %v90620 (stack46)
        %v90623 = vxor.u32 %v90622, %v90618 (stack47)
        %v90626 = vadd.s32 %v90623, %v90618 (stack39)
        %v90628 = vshll.u32 %v90623, 26 (stack44)
        %v90629 = vshrl.u32 %v90623, 6 (stack45)
        %v90630 = vor.u32 %v90629, %v90628 (stack46)
        %v90631 = vxor.u32 %v90630, %v90626 (stack47)
        %v90634 = vadd.s32 %v90631, %v90626 (stack39)
        %v90638 = vadd.s32 %v90634, %v8 (stack39)
        %v90640 = vshll.u32 %v90631, 6 (stack44)
        %v90641 = vshrl.u32 %v90631, 26 (stack45)
        %v90642 = vor.u32 %v90641, %v90640 (stack46)
        %v90643 = vxor.u32 %v90642, %v90634 (stack47)
        %v90646 = vadd.s32 %v90643, %v10 (stack39)
        %v90650 = vadd.s32 5, %v90646 (stack39)
        %v90652 = vxor.u32 %v90650, %v90638 (stack47)
        %v90653 = vand.u32.u8 255, %v90652 (stack48)
        %v90654 = vand.u32 65535, %v90653 (stack49)
        %v90655 = vshrl.u32 %v90654, 1 (stack50)
        %v90656 = vor.u32 16256, %v90655 (stack46)
        %v90657 = vand.u32.u16 65535, %v90656 (stack51)
        %v120230 = vadd.low.f32.bf16 -1.0, %v90657 (stack52)
        %v90666 = vmul.f32 2.0, %v120230 (stack53)
        %v90670 = vadd.f32 -0.99609375, %v90666 (stack52)
        %v90674 = vmax.f32 %v90670, -0.99609375 (stack54)
        %v90676 = vand.u32 2147483647, %v90674 (stack55)
        %vm90679 = vcmp.eq.f32.partialorder %v90676, 1.0 (stack56)
        %v90684 = vmul.f32 inf, %v90674 (stack53)
        %v90686 = vxor.u32 2147483648, %v90674 (stack57)
        %v90689 = vmul.f32 %v90686, %v90674 (stack53)
        %v90691 = vadd.f32 1.0, %v90689 (stack58)
        %v90692 = vlog2.pop %v90691 (stack59)
        %v90693 = vmul.f32 0.6931472, %v90692 (stack60)
        %v90694 = vmul.f32 -0.5, %v90689 (stack61)
        %v90695 = vadd.f32 1.0, %v90694 (stack62)
        %v90696 = vmul.f32 %v90695, %v90689 (stack63)
        %v90697 = vand.u32 2147483647, %v90689 (stack64)
        %vm90698 = vcmp.lt.f32.partialorder %v90697, 0.0004427343 (stack65)
        %v90699 = vsel /*vm=*/%vm90698, /*on_true_vy=*/%v90696, /*on_false_vx=*/%v90693 (stack66)
        %v90700 = vxor.u32 2147483648, %v90699 (stack57)
        %vm90703 = vcmp.lt.f32.partialorder %v90700, 5.0 (stack56)
        %v90708 = vsel /*vm=*/%vm90703, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v90712 = vsel /*vm=*/%vm90703, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v90716 = vsel /*vm=*/%vm90703, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v90720 = vsel /*vm=*/%vm90703, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v90724 = vsel /*vm=*/%vm90703, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v90728 = vsel /*vm=*/%vm90703, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v90732 = vsel /*vm=*/%vm90703, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v90736 = vsel /*vm=*/%vm90703, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v90740 = vsel /*vm=*/%vm90703, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v90744 = vadd.f32 -2.5, %v90700 (stack52)
        %v90746 = vrsqrt.pop %v90700 (stack67)
        %v90747 = vmul.f32 %v90746, %v90700 (stack68)
        %vm90748 = vcmp.eq.f32.partialorder %v90700, inf (stack69)
        %v90749 = vsel /*vm=*/%vm90748, /*on_true_vy=*/%v90700, /*on_false_vx=*/%v90747 (stack70)
        %vm90750 = vcmp.eq.f32.partialorder %v90700, 0.0 (stack71)
        %v90751 = vand.u32 2147483648, %v90700 (stack72)
        %v90752 = vsel /*vm=*/%vm90750, /*on_true_vy=*/%v90751, /*on_false_vx=*/%v90749 (stack73)
        %v90755 = vadd.f32 -3.0, %v90752 (stack52)
        %v90759 = vsel /*vm=*/%vm90703, /*on_true_vy=*/%v90744, /*on_false_vx=*/%v90755 (stack43)
        %v90763 = vmul.f32 %v90759, %v90740 (stack53)
        %v90767 = vadd.f32 %v90763, %v90736 (stack52)
        %v90771 = vmul.f32 %v90767, %v90759 (stack53)
        %v90775 = vadd.f32 %v90771, %v90732 (stack52)
        %v90779 = vmul.f32 %v90775, %v90759 (stack53)
        %v90783 = vadd.f32 %v90779, %v90728 (stack52)
        %v90787 = vmul.f32 %v90783, %v90759 (stack53)
        %v90791 = vadd.f32 %v90787, %v90724 (stack52)
        %v90795 = vmul.f32 %v90791, %v90759 (stack53)
        %v90799 = vadd.f32 %v90795, %v90720 (stack52)
        %v90803 = vmul.f32 %v90799, %v90759 (stack53)
        %v90807 = vadd.f32 %v90803, %v90716 (stack52)
        %v90811 = vmul.f32 %v90807, %v90759 (stack53)
        %v90815 = vadd.f32 %v90811, %v90712 (stack52)
        %v90819 = vmul.f32 %v90815, %v90759 (stack53)
        %v90823 = vadd.f32 %v90819, %v90708 (stack52)
        %v90827 = vmul.f32 %v90823, %v90674 (stack53)
        %v90831 = vsel /*vm=*/%vm90679, /*on_true_vy=*/%v90684, /*on_false_vx=*/%v90827 (stack43)
        %v90835 = vmul.f32 1.4140625, %v90831 (stack53)
        %v90838 = vpack.c.bf16 0.0, %v90835 (stack74)
        %120231 = vst [vmem:[%s280 + $0xe0] sm:$0xf] /*vst_source=*/%v90838 (stack75)
        %v90842 = vadd.s32 %v89917, %v1381 (stack39)
        %v90852 = vadd.s32 %v90842, %v415 (stack39)
        %vm90856 = vcmp.lt.u32.totalorder %v90852, %v90842 (stack42)
        %vm90861 = vcmp.lt.u32.totalorder %v90842, %v1381 (stack42)
        %v90866 = vadd.s32 %v89900, %v1368 (stack39)
        %v90870 = vadd.s32 1, %v90866 (stack39)
        %v90874 = vsel /*vm=*/%vm90861, /*on_true_vy=*/%v90870, /*on_false_vx=*/%v90866 (stack43)
        %v90878 = vadd.s32 1, %v90874 (stack39)
        %v90882 = vsel /*vm=*/%vm90856, /*on_true_vy=*/%v90878, /*on_false_vx=*/%v90874 (stack43)
        %v90887 = vadd.s32 %v90882, %v10 (stack39)
        %v90891 = vadd.s32 %v90852, %v9 (stack39)
        %v90895 = vadd.s32 %v90891, %v90887 (stack39)
        %v90897 = vshll.u32 %v90891, 13 (stack44)
        %v90898 = vshrl.u32 %v90891, 19 (stack45)
        %v90899 = vor.u32 %v90898, %v90897 (stack46)
        %v90900 = vxor.u32 %v90899, %v90895 (stack47)
        %v90903 = vadd.s32 %v90900, %v90895 (stack39)
        %v90905 = vshll.u32 %v90900, 15 (stack44)
        %v90906 = vshrl.u32 %v90900, 17 (stack45)
        %v90907 = vor.u32 %v90906, %v90905 (stack46)
        %v90908 = vxor.u32 %v90907, %v90903 (stack47)
        %v90911 = vadd.s32 %v90908, %v90903 (stack39)
        %v90913 = vshll.u32 %v90908, 26 (stack44)
        %v90914 = vshrl.u32 %v90908, 6 (stack45)
        %v90915 = vor.u32 %v90914, %v90913 (stack46)
        %v90916 = vxor.u32 %v90915, %v90911 (stack47)
        %v90919 = vadd.s32 %v90916, %v90911 (stack39)
        %v90923 = vadd.s32 %v90919, %v9 (stack39)
        %v90925 = vshll.u32 %v90916, 6 (stack44)
        %v90926 = vshrl.u32 %v90916, 26 (stack45)
        %v90927 = vor.u32 %v90926, %v90925 (stack46)
        %v90928 = vxor.u32 %v90927, %v90919 (stack47)
        %v90931 = vadd.s32 %v90928, %v8 (stack39)
        %v90935 = vadd.s32 1, %v90931 (stack39)
        %v90939 = vadd.s32 %v90935, %v90923 (stack39)
        %v90941 = vshll.u32 %v90935, 17 (stack44)
        %v90942 = vshrl.u32 %v90935, 15 (stack45)
        %v90943 = vor.u32 %v90942, %v90941 (stack46)
        %v90944 = vxor.u32 %v90943, %v90939 (stack47)
        %v90947 = vadd.s32 %v90944, %v90939 (stack39)
        %v90949 = vshll.u32 %v90944, 29 (stack44)
        %v90950 = vshrl.u32 %v90944, 3 (stack45)
        %v90951 = vor.u32 %v90950, %v90949 (stack46)
        %v90952 = vxor.u32 %v90951, %v90947 (stack47)
        %v90955 = vadd.s32 %v90952, %v90947 (stack39)
        %v90957 = vshll.u32 %v90952, 16 (stack44)
        %v90958 = vshrl.u32 %v90952, 16 (stack45)
        %v90959 = vor.u32 %v90958, %v90957 (stack46)
        %v90960 = vxor.u32 %v90959, %v90955 (stack47)
        %v90963 = vadd.s32 %v90960, %v90955 (stack39)
        %v90967 = vadd.s32 %v90963, %v8 (stack39)
        %v90969 = vshll.u32 %v90960, 24 (stack44)
        %v90970 = vshrl.u32 %v90960, 8 (stack45)
        %v90971 = vor.u32 %v90970, %v90969 (stack46)
        %v90972 = vxor.u32 %v90971, %v90963 (stack47)
        %v90975 = vadd.s32 %v90972, %v10 (stack39)
        %v90979 = vadd.s32 2, %v90975 (stack39)
        %v90983 = vadd.s32 %v90979, %v90967 (stack39)
        %v90985 = vshll.u32 %v90979, 13 (stack44)
        %v90986 = vshrl.u32 %v90979, 19 (stack45)
        %v90987 = vor.u32 %v90986, %v90985 (stack46)
        %v90988 = vxor.u32 %v90987, %v90983 (stack47)
        %v90991 = vadd.s32 %v90988, %v90983 (stack39)
        %v90993 = vshll.u32 %v90988, 15 (stack44)
        %v90994 = vshrl.u32 %v90988, 17 (stack45)
        %v90995 = vor.u32 %v90994, %v90993 (stack46)
        %v90996 = vxor.u32 %v90995, %v90991 (stack47)
        %v90999 = vadd.s32 %v90996, %v90991 (stack39)
        %v91001 = vshll.u32 %v90996, 26 (stack44)
        %v91002 = vshrl.u32 %v90996, 6 (stack45)
        %v91003 = vor.u32 %v91002, %v91001 (stack46)
        %v91004 = vxor.u32 %v91003, %v90999 (stack47)
        %v91007 = vadd.s32 %v91004, %v90999 (stack39)
        %v91011 = vadd.s32 %v91007, %v10 (stack39)
        %v91013 = vshll.u32 %v91004, 6 (stack44)
        %v91014 = vshrl.u32 %v91004, 26 (stack45)
        %v91015 = vor.u32 %v91014, %v91013 (stack46)
        %v91016 = vxor.u32 %v91015, %v91007 (stack47)
        %v91019 = vadd.s32 %v91016, %v9 (stack39)
        %v91023 = vadd.s32 3, %v91019 (stack39)
        %v91027 = vadd.s32 %v91023, %v91011 (stack39)
        %v91029 = vshll.u32 %v91023, 17 (stack44)
        %v91030 = vshrl.u32 %v91023, 15 (stack45)
        %v91031 = vor.u32 %v91030, %v91029 (stack46)
        %v91032 = vxor.u32 %v91031, %v91027 (stack47)
        %v91035 = vadd.s32 %v91032, %v91027 (stack39)
        %v91037 = vshll.u32 %v91032, 29 (stack44)
        %v91038 = vshrl.u32 %v91032, 3 (stack45)
        %v91039 = vor.u32 %v91038, %v91037 (stack46)
        %v91040 = vxor.u32 %v91039, %v91035 (stack47)
        %v91043 = vadd.s32 %v91040, %v91035 (stack39)
        %v91045 = vshll.u32 %v91040, 16 (stack44)
        %v91046 = vshrl.u32 %v91040, 16 (stack45)
        %v91047 = vor.u32 %v91046, %v91045 (stack46)
        %v91048 = vxor.u32 %v91047, %v91043 (stack47)
        %v91051 = vadd.s32 %v91048, %v91043 (stack39)
        %v91055 = vadd.s32 %v91051, %v9 (stack39)
        %v91057 = vshll.u32 %v91048, 24 (stack44)
        %v91058 = vshrl.u32 %v91048, 8 (stack45)
        %v91059 = vor.u32 %v91058, %v91057 (stack46)
        %v91060 = vxor.u32 %v91059, %v91051 (stack47)
        %v91063 = vadd.s32 %v91060, %v8 (stack39)
        %v91067 = vadd.s32 4, %v91063 (stack39)
        %v91071 = vadd.s32 %v91067, %v91055 (stack39)
        %v91073 = vshll.u32 %v91067, 13 (stack44)
        %v91074 = vshrl.u32 %v91067, 19 (stack45)
        %v91075 = vor.u32 %v91074, %v91073 (stack46)
        %v91076 = vxor.u32 %v91075, %v91071 (stack47)
        %v91079 = vadd.s32 %v91076, %v91071 (stack39)
        %v91081 = vshll.u32 %v91076, 15 (stack44)
        %v91082 = vshrl.u32 %v91076, 17 (stack45)
        %v91083 = vor.u32 %v91082, %v91081 (stack46)
        %v91084 = vxor.u32 %v91083, %v91079 (stack47)
        %v91087 = vadd.s32 %v91084, %v91079 (stack39)
        %v91089 = vshll.u32 %v91084, 26 (stack44)
        %v91090 = vshrl.u32 %v91084, 6 (stack45)
        %v91091 = vor.u32 %v91090, %v91089 (stack46)
        %v91092 = vxor.u32 %v91091, %v91087 (stack47)
        %v91095 = vadd.s32 %v91092, %v91087 (stack39)
        %v91099 = vadd.s32 %v91095, %v8 (stack39)
        %v91101 = vshll.u32 %v91092, 6 (stack44)
        %v91102 = vshrl.u32 %v91092, 26 (stack45)
        %v91103 = vor.u32 %v91102, %v91101 (stack46)
        %v91104 = vxor.u32 %v91103, %v91095 (stack47)
        %v91107 = vadd.s32 %v91104, %v10 (stack39)
        %v91111 = vadd.s32 5, %v91107 (stack39)
        %v91113 = vxor.u32 %v91111, %v91099 (stack47)
        %v91114 = vand.u32.u8 255, %v91113 (stack48)
        %v91115 = vand.u32 65535, %v91114 (stack49)
        %v91116 = vshrl.u32 %v91115, 1 (stack50)
        %v91117 = vor.u32 16256, %v91116 (stack46)
        %v91118 = vand.u32.u16 65535, %v91117 (stack51)
        %v120232 = vadd.low.f32.bf16 -1.0, %v91118 (stack52)
        %v91127 = vmul.f32 2.0, %v120232 (stack53)
        %v91131 = vadd.f32 -0.99609375, %v91127 (stack52)
        %v91135 = vmax.f32 %v91131, -0.99609375 (stack54)
        %v91137 = vand.u32 2147483647, %v91135 (stack55)
        %vm91140 = vcmp.eq.f32.partialorder %v91137, 1.0 (stack56)
        %v91145 = vmul.f32 inf, %v91135 (stack53)
        %v91147 = vxor.u32 2147483648, %v91135 (stack57)
        %v91150 = vmul.f32 %v91147, %v91135 (stack53)
        %v91152 = vadd.f32 1.0, %v91150 (stack58)
        %v91153 = vlog2.pop %v91152 (stack59)
        %v91154 = vmul.f32 0.6931472, %v91153 (stack60)
        %v91155 = vmul.f32 -0.5, %v91150 (stack61)
        %v91156 = vadd.f32 1.0, %v91155 (stack62)
        %v91157 = vmul.f32 %v91156, %v91150 (stack63)
        %v91158 = vand.u32 2147483647, %v91150 (stack64)
        %vm91159 = vcmp.lt.f32.partialorder %v91158, 0.0004427343 (stack65)
        %v91160 = vsel /*vm=*/%vm91159, /*on_true_vy=*/%v91157, /*on_false_vx=*/%v91154 (stack66)
        %v91161 = vxor.u32 2147483648, %v91160 (stack57)
        %vm91164 = vcmp.lt.f32.partialorder %v91161, 5.0 (stack56)
        %v91169 = vsel /*vm=*/%vm91164, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v91173 = vsel /*vm=*/%vm91164, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v91177 = vsel /*vm=*/%vm91164, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v91181 = vsel /*vm=*/%vm91164, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v91185 = vsel /*vm=*/%vm91164, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v91189 = vsel /*vm=*/%vm91164, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v91193 = vsel /*vm=*/%vm91164, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v91197 = vsel /*vm=*/%vm91164, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v91201 = vsel /*vm=*/%vm91164, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v91205 = vadd.f32 -2.5, %v91161 (stack52)
        %v91207 = vrsqrt.pop %v91161 (stack67)
        %v91208 = vmul.f32 %v91207, %v91161 (stack68)
        %vm91209 = vcmp.eq.f32.partialorder %v91161, inf (stack69)
        %v91210 = vsel /*vm=*/%vm91209, /*on_true_vy=*/%v91161, /*on_false_vx=*/%v91208 (stack70)
        %vm91211 = vcmp.eq.f32.partialorder %v91161, 0.0 (stack71)
        %v91212 = vand.u32 2147483648, %v91161 (stack72)
        %v91213 = vsel /*vm=*/%vm91211, /*on_true_vy=*/%v91212, /*on_false_vx=*/%v91210 (stack73)
        %v91216 = vadd.f32 -3.0, %v91213 (stack52)
        %v91220 = vsel /*vm=*/%vm91164, /*on_true_vy=*/%v91205, /*on_false_vx=*/%v91216 (stack43)
        %v91224 = vmul.f32 %v91220, %v91201 (stack53)
        %v91228 = vadd.f32 %v91224, %v91197 (stack52)
        %v91232 = vmul.f32 %v91228, %v91220 (stack53)
        %v91236 = vadd.f32 %v91232, %v91193 (stack52)
        %v91240 = vmul.f32 %v91236, %v91220 (stack53)
        %v91244 = vadd.f32 %v91240, %v91189 (stack52)
        %v91248 = vmul.f32 %v91244, %v91220 (stack53)
        %v91252 = vadd.f32 %v91248, %v91185 (stack52)
        %v91256 = vmul.f32 %v91252, %v91220 (stack53)
        %v91260 = vadd.f32 %v91256, %v91181 (stack52)
        %v91264 = vmul.f32 %v91260, %v91220 (stack53)
        %v91268 = vadd.f32 %v91264, %v91177 (stack52)
        %v91272 = vmul.f32 %v91268, %v91220 (stack53)
        %v91276 = vadd.f32 %v91272, %v91173 (stack52)
        %v91280 = vmul.f32 %v91276, %v91220 (stack53)
        %v91284 = vadd.f32 %v91280, %v91169 (stack52)
        %v91288 = vmul.f32 %v91284, %v91135 (stack53)
        %v91292 = vsel /*vm=*/%vm91140, /*on_true_vy=*/%v91145, /*on_false_vx=*/%v91288 (stack43)
        %v91296 = vmul.f32 1.4140625, %v91292 (stack53)
        %v91299 = vpack.c.bf16 0.0, %v91296 (stack74)
        %120233 = vst [vmem:[%s280 + $0x160] sm:$0xf] /*vst_source=*/%v91299 (stack75)
        %v91303 = vadd.s32 %v89917, %v1868 (stack39)
        %v91313 = vadd.s32 %v91303, %v415 (stack39)
        %vm91317 = vcmp.lt.u32.totalorder %v91313, %v91303 (stack42)
        %vm91322 = vcmp.lt.u32.totalorder %v91303, %v1868 (stack42)
        %v91327 = vadd.s32 %v89900, %v1855 (stack39)
        %v91331 = vadd.s32 1, %v91327 (stack39)
        %v91335 = vsel /*vm=*/%vm91322, /*on_true_vy=*/%v91331, /*on_false_vx=*/%v91327 (stack43)
        %v91339 = vadd.s32 1, %v91335 (stack39)
        %v91343 = vsel /*vm=*/%vm91317, /*on_true_vy=*/%v91339, /*on_false_vx=*/%v91335 (stack43)
        %v91348 = vadd.s32 %v91343, %v10 (stack39)
        %v91352 = vadd.s32 %v91313, %v9 (stack39)
        %v91356 = vadd.s32 %v91352, %v91348 (stack39)
        %v91358 = vshll.u32 %v91352, 13 (stack44)
        %v91359 = vshrl.u32 %v91352, 19 (stack45)
        %v91360 = vor.u32 %v91359, %v91358 (stack46)
        %v91361 = vxor.u32 %v91360, %v91356 (stack47)
        %v91364 = vadd.s32 %v91361, %v91356 (stack39)
        %v91366 = vshll.u32 %v91361, 15 (stack44)
        %v91367 = vshrl.u32 %v91361, 17 (stack45)
        %v91368 = vor.u32 %v91367, %v91366 (stack46)
        %v91369 = vxor.u32 %v91368, %v91364 (stack47)
        %v91372 = vadd.s32 %v91369, %v91364 (stack39)
        %v91374 = vshll.u32 %v91369, 26 (stack44)
        %v91375 = vshrl.u32 %v91369, 6 (stack45)
        %v91376 = vor.u32 %v91375, %v91374 (stack46)
        %v91377 = vxor.u32 %v91376, %v91372 (stack47)
        %v91380 = vadd.s32 %v91377, %v91372 (stack39)
        %v91384 = vadd.s32 %v91380, %v9 (stack39)
        %v91386 = vshll.u32 %v91377, 6 (stack44)
        %v91387 = vshrl.u32 %v91377, 26 (stack45)
        %v91388 = vor.u32 %v91387, %v91386 (stack46)
        %v91389 = vxor.u32 %v91388, %v91380 (stack47)
        %v91392 = vadd.s32 %v91389, %v8 (stack39)
        %v91396 = vadd.s32 1, %v91392 (stack39)
        %v91400 = vadd.s32 %v91396, %v91384 (stack39)
        %v91402 = vshll.u32 %v91396, 17 (stack44)
        %v91403 = vshrl.u32 %v91396, 15 (stack45)
        %v91404 = vor.u32 %v91403, %v91402 (stack46)
        %v91405 = vxor.u32 %v91404, %v91400 (stack47)
        %v91408 = vadd.s32 %v91405, %v91400 (stack39)
        %v91410 = vshll.u32 %v91405, 29 (stack44)
        %v91411 = vshrl.u32 %v91405, 3 (stack45)
        %v91412 = vor.u32 %v91411, %v91410 (stack46)
        %v91413 = vxor.u32 %v91412, %v91408 (stack47)
        %v91416 = vadd.s32 %v91413, %v91408 (stack39)
        %v91418 = vshll.u32 %v91413, 16 (stack44)
        %v91419 = vshrl.u32 %v91413, 16 (stack45)
        %v91420 = vor.u32 %v91419, %v91418 (stack46)
        %v91421 = vxor.u32 %v91420, %v91416 (stack47)
        %v91424 = vadd.s32 %v91421, %v91416 (stack39)
        %v91428 = vadd.s32 %v91424, %v8 (stack39)
        %v91430 = vshll.u32 %v91421, 24 (stack44)
        %v91431 = vshrl.u32 %v91421, 8 (stack45)
        %v91432 = vor.u32 %v91431, %v91430 (stack46)
        %v91433 = vxor.u32 %v91432, %v91424 (stack47)
        %v91436 = vadd.s32 %v91433, %v10 (stack39)
        %v91440 = vadd.s32 2, %v91436 (stack39)
        %v91444 = vadd.s32 %v91440, %v91428 (stack39)
        %v91446 = vshll.u32 %v91440, 13 (stack44)
        %v91447 = vshrl.u32 %v91440, 19 (stack45)
        %v91448 = vor.u32 %v91447, %v91446 (stack46)
        %v91449 = vxor.u32 %v91448, %v91444 (stack47)
        %v91452 = vadd.s32 %v91449, %v91444 (stack39)
        %v91454 = vshll.u32 %v91449, 15 (stack44)
        %v91455 = vshrl.u32 %v91449, 17 (stack45)
        %v91456 = vor.u32 %v91455, %v91454 (stack46)
        %v91457 = vxor.u32 %v91456, %v91452 (stack47)
        %v91460 = vadd.s32 %v91457, %v91452 (stack39)
        %v91462 = vshll.u32 %v91457, 26 (stack44)
        %v91463 = vshrl.u32 %v91457, 6 (stack45)
        %v91464 = vor.u32 %v91463, %v91462 (stack46)
        %v91465 = vxor.u32 %v91464, %v91460 (stack47)
        %v91468 = vadd.s32 %v91465, %v91460 (stack39)
        %v91472 = vadd.s32 %v91468, %v10 (stack39)
        %v91474 = vshll.u32 %v91465, 6 (stack44)
        %v91475 = vshrl.u32 %v91465, 26 (stack45)
        %v91476 = vor.u32 %v91475, %v91474 (stack46)
        %v91477 = vxor.u32 %v91476, %v91468 (stack47)
        %v91480 = vadd.s32 %v91477, %v9 (stack39)
        %v91484 = vadd.s32 3, %v91480 (stack39)
        %v91488 = vadd.s32 %v91484, %v91472 (stack39)
        %v91490 = vshll.u32 %v91484, 17 (stack44)
        %v91491 = vshrl.u32 %v91484, 15 (stack45)
        %v91492 = vor.u32 %v91491, %v91490 (stack46)
        %v91493 = vxor.u32 %v91492, %v91488 (stack47)
        %v91496 = vadd.s32 %v91493, %v91488 (stack39)
        %v91498 = vshll.u32 %v91493, 29 (stack44)
        %v91499 = vshrl.u32 %v91493, 3 (stack45)
        %v91500 = vor.u32 %v91499, %v91498 (stack46)
        %v91501 = vxor.u32 %v91500, %v91496 (stack47)
        %v91504 = vadd.s32 %v91501, %v91496 (stack39)
        %v91506 = vshll.u32 %v91501, 16 (stack44)
        %v91507 = vshrl.u32 %v91501, 16 (stack45)
        %v91508 = vor.u32 %v91507, %v91506 (stack46)
        %v91509 = vxor.u32 %v91508, %v91504 (stack47)
        %v91512 = vadd.s32 %v91509, %v91504 (stack39)
        %v91516 = vadd.s32 %v91512, %v9 (stack39)
        %v91518 = vshll.u32 %v91509, 24 (stack44)
        %v91519 = vshrl.u32 %v91509, 8 (stack45)
        %v91520 = vor.u32 %v91519, %v91518 (stack46)
        %v91521 = vxor.u32 %v91520, %v91512 (stack47)
        %v91524 = vadd.s32 %v91521, %v8 (stack39)
        %v91528 = vadd.s32 4, %v91524 (stack39)
        %v91532 = vadd.s32 %v91528, %v91516 (stack39)
        %v91534 = vshll.u32 %v91528, 13 (stack44)
        %v91535 = vshrl.u32 %v91528, 19 (stack45)
        %v91536 = vor.u32 %v91535, %v91534 (stack46)
        %v91537 = vxor.u32 %v91536, %v91532 (stack47)
        %v91540 = vadd.s32 %v91537, %v91532 (stack39)
        %v91542 = vshll.u32 %v91537, 15 (stack44)
        %v91543 = vshrl.u32 %v91537, 17 (stack45)
        %v91544 = vor.u32 %v91543, %v91542 (stack46)
        %v91545 = vxor.u32 %v91544, %v91540 (stack47)
        %v91548 = vadd.s32 %v91545, %v91540 (stack39)
        %v91550 = vshll.u32 %v91545, 26 (stack44)
        %v91551 = vshrl.u32 %v91545, 6 (stack45)
        %v91552 = vor.u32 %v91551, %v91550 (stack46)
        %v91553 = vxor.u32 %v91552, %v91548 (stack47)
        %v91556 = vadd.s32 %v91553, %v91548 (stack39)
        %v91560 = vadd.s32 %v91556, %v8 (stack39)
        %v91562 = vshll.u32 %v91553, 6 (stack44)
        %v91563 = vshrl.u32 %v91553, 26 (stack45)
        %v91564 = vor.u32 %v91563, %v91562 (stack46)
        %v91565 = vxor.u32 %v91564, %v91556 (stack47)
        %v91568 = vadd.s32 %v91565, %v10 (stack39)
        %v91572 = vadd.s32 5, %v91568 (stack39)
        %v91574 = vxor.u32 %v91572, %v91560 (stack47)
        %v91575 = vand.u32.u8 255, %v91574 (stack48)
        %v91576 = vand.u32 65535, %v91575 (stack49)
        %v91577 = vshrl.u32 %v91576, 1 (stack50)
        %v91578 = vor.u32 16256, %v91577 (stack46)
        %v91579 = vand.u32.u16 65535, %v91578 (stack51)
        %v120234 = vadd.low.f32.bf16 -1.0, %v91579 (stack52)
        %v91588 = vmul.f32 2.0, %v120234 (stack53)
        %v91592 = vadd.f32 -0.99609375, %v91588 (stack52)
        %v91596 = vmax.f32 %v91592, -0.99609375 (stack54)
        %v91598 = vand.u32 2147483647, %v91596 (stack55)
        %vm91601 = vcmp.eq.f32.partialorder %v91598, 1.0 (stack56)
        %v91606 = vmul.f32 inf, %v91596 (stack53)
        %v91608 = vxor.u32 2147483648, %v91596 (stack57)
        %v91611 = vmul.f32 %v91608, %v91596 (stack53)
        %v91613 = vadd.f32 1.0, %v91611 (stack58)
        %v91614 = vlog2.pop %v91613 (stack59)
        %v91615 = vmul.f32 0.6931472, %v91614 (stack60)
        %v91616 = vmul.f32 -0.5, %v91611 (stack61)
        %v91617 = vadd.f32 1.0, %v91616 (stack62)
        %v91618 = vmul.f32 %v91617, %v91611 (stack63)
        %v91619 = vand.u32 2147483647, %v91611 (stack64)
        %vm91620 = vcmp.lt.f32.partialorder %v91619, 0.0004427343 (stack65)
        %v91621 = vsel /*vm=*/%vm91620, /*on_true_vy=*/%v91618, /*on_false_vx=*/%v91615 (stack66)
        %v91622 = vxor.u32 2147483648, %v91621 (stack57)
        %vm91625 = vcmp.lt.f32.partialorder %v91622, 5.0 (stack56)
        %v91630 = vsel /*vm=*/%vm91625, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v91634 = vsel /*vm=*/%vm91625, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v91638 = vsel /*vm=*/%vm91625, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v91642 = vsel /*vm=*/%vm91625, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v91646 = vsel /*vm=*/%vm91625, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v91650 = vsel /*vm=*/%vm91625, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v91654 = vsel /*vm=*/%vm91625, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v91658 = vsel /*vm=*/%vm91625, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v91662 = vsel /*vm=*/%vm91625, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v91666 = vadd.f32 -2.5, %v91622 (stack52)
        %v91668 = vrsqrt.pop %v91622 (stack67)
        %v91669 = vmul.f32 %v91668, %v91622 (stack68)
        %vm91670 = vcmp.eq.f32.partialorder %v91622, inf (stack69)
        %v91671 = vsel /*vm=*/%vm91670, /*on_true_vy=*/%v91622, /*on_false_vx=*/%v91669 (stack70)
        %vm91672 = vcmp.eq.f32.partialorder %v91622, 0.0 (stack71)
        %v91673 = vand.u32 2147483648, %v91622 (stack72)
        %v91674 = vsel /*vm=*/%vm91672, /*on_true_vy=*/%v91673, /*on_false_vx=*/%v91671 (stack73)
        %v91677 = vadd.f32 -3.0, %v91674 (stack52)
        %v91681 = vsel /*vm=*/%vm91625, /*on_true_vy=*/%v91666, /*on_false_vx=*/%v91677 (stack43)
        %v91685 = vmul.f32 %v91681, %v91662 (stack53)
        %v91689 = vadd.f32 %v91685, %v91658 (stack52)
        %v91693 = vmul.f32 %v91689, %v91681 (stack53)
        %v91697 = vadd.f32 %v91693, %v91654 (stack52)
        %v91701 = vmul.f32 %v91697, %v91681 (stack53)
        %v91705 = vadd.f32 %v91701, %v91650 (stack52)
        %v91709 = vmul.f32 %v91705, %v91681 (stack53)
        %v91713 = vadd.f32 %v91709, %v91646 (stack52)
        %v91717 = vmul.f32 %v91713, %v91681 (stack53)
        %v91721 = vadd.f32 %v91717, %v91642 (stack52)
        %v91725 = vmul.f32 %v91721, %v91681 (stack53)
        %v91729 = vadd.f32 %v91725, %v91638 (stack52)
        %v91733 = vmul.f32 %v91729, %v91681 (stack53)
        %v91737 = vadd.f32 %v91733, %v91634 (stack52)
        %v91741 = vmul.f32 %v91737, %v91681 (stack53)
        %v91745 = vadd.f32 %v91741, %v91630 (stack52)
        %v91749 = vmul.f32 %v91745, %v91596 (stack53)
        %v91753 = vsel /*vm=*/%vm91601, /*on_true_vy=*/%v91606, /*on_false_vx=*/%v91749 (stack43)
        %v91757 = vmul.f32 1.4140625, %v91753 (stack53)
        %v91760 = vpack.c.bf16 0.0, %v91757 (stack74)
        %120235 = vst [vmem:[%s280 + $0x1e0] sm:$0xf] /*vst_source=*/%v91760 (stack75)
        %v91764 = vadd.s32 %v89917, %v2355 (stack39)
        %v91774 = vadd.s32 %v91764, %v415 (stack39)
        %vm91778 = vcmp.lt.u32.totalorder %v91774, %v91764 (stack42)
        %vm91783 = vcmp.lt.u32.totalorder %v91764, %v2355 (stack42)
        %v91788 = vadd.s32 %v89900, %v2342 (stack39)
        %v91792 = vadd.s32 1, %v91788 (stack39)
        %v91796 = vsel /*vm=*/%vm91783, /*on_true_vy=*/%v91792, /*on_false_vx=*/%v91788 (stack43)
        %v91800 = vadd.s32 1, %v91796 (stack39)
        %v91804 = vsel /*vm=*/%vm91778, /*on_true_vy=*/%v91800, /*on_false_vx=*/%v91796 (stack43)
        %v91809 = vadd.s32 %v91804, %v10 (stack39)
        %v91813 = vadd.s32 %v91774, %v9 (stack39)
        %v91817 = vadd.s32 %v91813, %v91809 (stack39)
        %v91819 = vshll.u32 %v91813, 13 (stack44)
        %v91820 = vshrl.u32 %v91813, 19 (stack45)
        %v91821 = vor.u32 %v91820, %v91819 (stack46)
        %v91822 = vxor.u32 %v91821, %v91817 (stack47)
        %v91825 = vadd.s32 %v91822, %v91817 (stack39)
        %v91827 = vshll.u32 %v91822, 15 (stack44)
        %v91828 = vshrl.u32 %v91822, 17 (stack45)
        %v91829 = vor.u32 %v91828, %v91827 (stack46)
        %v91830 = vxor.u32 %v91829, %v91825 (stack47)
        %v91833 = vadd.s32 %v91830, %v91825 (stack39)
        %v91835 = vshll.u32 %v91830, 26 (stack44)
        %v91836 = vshrl.u32 %v91830, 6 (stack45)
        %v91837 = vor.u32 %v91836, %v91835 (stack46)
        %v91838 = vxor.u32 %v91837, %v91833 (stack47)
        %v91841 = vadd.s32 %v91838, %v91833 (stack39)
        %v91845 = vadd.s32 %v91841, %v9 (stack39)
        %v91847 = vshll.u32 %v91838, 6 (stack44)
        %v91848 = vshrl.u32 %v91838, 26 (stack45)
        %v91849 = vor.u32 %v91848, %v91847 (stack46)
        %v91850 = vxor.u32 %v91849, %v91841 (stack47)
        %v91853 = vadd.s32 %v91850, %v8 (stack39)
        %v91857 = vadd.s32 1, %v91853 (stack39)
        %v91861 = vadd.s32 %v91857, %v91845 (stack39)
        %v91863 = vshll.u32 %v91857, 17 (stack44)
        %v91864 = vshrl.u32 %v91857, 15 (stack45)
        %v91865 = vor.u32 %v91864, %v91863 (stack46)
        %v91866 = vxor.u32 %v91865, %v91861 (stack47)
        %v91869 = vadd.s32 %v91866, %v91861 (stack39)
        %v91871 = vshll.u32 %v91866, 29 (stack44)
        %v91872 = vshrl.u32 %v91866, 3 (stack45)
        %v91873 = vor.u32 %v91872, %v91871 (stack46)
        %v91874 = vxor.u32 %v91873, %v91869 (stack47)
        %v91877 = vadd.s32 %v91874, %v91869 (stack39)
        %v91879 = vshll.u32 %v91874, 16 (stack44)
        %v91880 = vshrl.u32 %v91874, 16 (stack45)
        %v91881 = vor.u32 %v91880, %v91879 (stack46)
        %v91882 = vxor.u32 %v91881, %v91877 (stack47)
        %v91885 = vadd.s32 %v91882, %v91877 (stack39)
        %v91889 = vadd.s32 %v91885, %v8 (stack39)
        %v91891 = vshll.u32 %v91882, 24 (stack44)
        %v91892 = vshrl.u32 %v91882, 8 (stack45)
        %v91893 = vor.u32 %v91892, %v91891 (stack46)
        %v91894 = vxor.u32 %v91893, %v91885 (stack47)
        %v91897 = vadd.s32 %v91894, %v10 (stack39)
        %v91901 = vadd.s32 2, %v91897 (stack39)
        %v91905 = vadd.s32 %v91901, %v91889 (stack39)
        %v91907 = vshll.u32 %v91901, 13 (stack44)
        %v91908 = vshrl.u32 %v91901, 19 (stack45)
        %v91909 = vor.u32 %v91908, %v91907 (stack46)
        %v91910 = vxor.u32 %v91909, %v91905 (stack47)
        %v91913 = vadd.s32 %v91910, %v91905 (stack39)
        %v91915 = vshll.u32 %v91910, 15 (stack44)
        %v91916 = vshrl.u32 %v91910, 17 (stack45)
        %v91917 = vor.u32 %v91916, %v91915 (stack46)
        %v91918 = vxor.u32 %v91917, %v91913 (stack47)
        %v91921 = vadd.s32 %v91918, %v91913 (stack39)
        %v91923 = vshll.u32 %v91918, 26 (stack44)
        %v91924 = vshrl.u32 %v91918, 6 (stack45)
        %v91925 = vor.u32 %v91924, %v91923 (stack46)
        %v91926 = vxor.u32 %v91925, %v91921 (stack47)
        %v91929 = vadd.s32 %v91926, %v91921 (stack39)
        %v91933 = vadd.s32 %v91929, %v10 (stack39)
        %v91935 = vshll.u32 %v91926, 6 (stack44)
        %v91936 = vshrl.u32 %v91926, 26 (stack45)
        %v91937 = vor.u32 %v91936, %v91935 (stack46)
        %v91938 = vxor.u32 %v91937, %v91929 (stack47)
        %v91941 = vadd.s32 %v91938, %v9 (stack39)
        %v91945 = vadd.s32 3, %v91941 (stack39)
        %v91949 = vadd.s32 %v91945, %v91933 (stack39)
        %v91951 = vshll.u32 %v91945, 17 (stack44)
        %v91952 = vshrl.u32 %v91945, 15 (stack45)
        %v91953 = vor.u32 %v91952, %v91951 (stack46)
        %v91954 = vxor.u32 %v91953, %v91949 (stack47)
        %v91957 = vadd.s32 %v91954, %v91949 (stack39)
        %v91959 = vshll.u32 %v91954, 29 (stack44)
        %v91960 = vshrl.u32 %v91954, 3 (stack45)
        %v91961 = vor.u32 %v91960, %v91959 (stack46)
        %v91962 = vxor.u32 %v91961, %v91957 (stack47)
        %v91965 = vadd.s32 %v91962, %v91957 (stack39)
        %v91967 = vshll.u32 %v91962, 16 (stack44)
        %v91968 = vshrl.u32 %v91962, 16 (stack45)
        %v91969 = vor.u32 %v91968, %v91967 (stack46)
        %v91970 = vxor.u32 %v91969, %v91965 (stack47)
        %v91973 = vadd.s32 %v91970, %v91965 (stack39)
        %v91977 = vadd.s32 %v91973, %v9 (stack39)
        %v91979 = vshll.u32 %v91970, 24 (stack44)
        %v91980 = vshrl.u32 %v91970, 8 (stack45)
        %v91981 = vor.u32 %v91980, %v91979 (stack46)
        %v91982 = vxor.u32 %v91981, %v91973 (stack47)
        %v91985 = vadd.s32 %v91982, %v8 (stack39)
        %v91989 = vadd.s32 4, %v91985 (stack39)
        %v91993 = vadd.s32 %v91989, %v91977 (stack39)
        %v91995 = vshll.u32 %v91989, 13 (stack44)
        %v91996 = vshrl.u32 %v91989, 19 (stack45)
        %v91997 = vor.u32 %v91996, %v91995 (stack46)
        %v91998 = vxor.u32 %v91997, %v91993 (stack47)
        %v92001 = vadd.s32 %v91998, %v91993 (stack39)
        %v92003 = vshll.u32 %v91998, 15 (stack44)
        %v92004 = vshrl.u32 %v91998, 17 (stack45)
        %v92005 = vor.u32 %v92004, %v92003 (stack46)
        %v92006 = vxor.u32 %v92005, %v92001 (stack47)
        %v92009 = vadd.s32 %v92006, %v92001 (stack39)
        %v92011 = vshll.u32 %v92006, 26 (stack44)
        %v92012 = vshrl.u32 %v92006, 6 (stack45)
        %v92013 = vor.u32 %v92012, %v92011 (stack46)
        %v92014 = vxor.u32 %v92013, %v92009 (stack47)
        %v92017 = vadd.s32 %v92014, %v92009 (stack39)
        %v92021 = vadd.s32 %v92017, %v8 (stack39)
        %v92023 = vshll.u32 %v92014, 6 (stack44)
        %v92024 = vshrl.u32 %v92014, 26 (stack45)
        %v92025 = vor.u32 %v92024, %v92023 (stack46)
        %v92026 = vxor.u32 %v92025, %v92017 (stack47)
        %v92029 = vadd.s32 %v92026, %v10 (stack39)
        %v92033 = vadd.s32 5, %v92029 (stack39)
        %v92035 = vxor.u32 %v92033, %v92021 (stack47)
        %v92036 = vand.u32.u8 255, %v92035 (stack48)
        %v92037 = vand.u32 65535, %v92036 (stack49)
        %v92038 = vshrl.u32 %v92037, 1 (stack50)
        %v92039 = vor.u32 16256, %v92038 (stack46)
        %v92040 = vand.u32.u16 65535, %v92039 (stack51)
        %v120236 = vadd.low.f32.bf16 -1.0, %v92040 (stack52)
        %v92049 = vmul.f32 2.0, %v120236 (stack53)
        %v92053 = vadd.f32 -0.99609375, %v92049 (stack52)
        %v92057 = vmax.f32 %v92053, -0.99609375 (stack54)
        %v92059 = vand.u32 2147483647, %v92057 (stack55)
        %vm92062 = vcmp.eq.f32.partialorder %v92059, 1.0 (stack56)
        %v92067 = vmul.f32 inf, %v92057 (stack53)
        %v92069 = vxor.u32 2147483648, %v92057 (stack57)
        %v92072 = vmul.f32 %v92069, %v92057 (stack53)
        %v92074 = vadd.f32 1.0, %v92072 (stack58)
        %v92075 = vlog2.pop %v92074 (stack59)
        %v92076 = vmul.f32 0.6931472, %v92075 (stack60)
        %v92077 = vmul.f32 -0.5, %v92072 (stack61)
        %v92078 = vadd.f32 1.0, %v92077 (stack62)
        %v92079 = vmul.f32 %v92078, %v92072 (stack63)
        %v92080 = vand.u32 2147483647, %v92072 (stack64)
        %vm92081 = vcmp.lt.f32.partialorder %v92080, 0.0004427343 (stack65)
        %v92082 = vsel /*vm=*/%vm92081, /*on_true_vy=*/%v92079, /*on_false_vx=*/%v92076 (stack66)
        %v92083 = vxor.u32 2147483648, %v92082 (stack57)
        %vm92086 = vcmp.lt.f32.partialorder %v92083, 5.0 (stack56)
        %v92091 = vsel /*vm=*/%vm92086, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v92095 = vsel /*vm=*/%vm92086, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v92099 = vsel /*vm=*/%vm92086, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v92103 = vsel /*vm=*/%vm92086, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v92107 = vsel /*vm=*/%vm92086, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v92111 = vsel /*vm=*/%vm92086, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v92115 = vsel /*vm=*/%vm92086, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v92119 = vsel /*vm=*/%vm92086, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v92123 = vsel /*vm=*/%vm92086, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v92127 = vadd.f32 -2.5, %v92083 (stack52)
        %v92129 = vrsqrt.pop %v92083 (stack67)
        %v92130 = vmul.f32 %v92129, %v92083 (stack68)
        %vm92131 = vcmp.eq.f32.partialorder %v92083, inf (stack69)
        %v92132 = vsel /*vm=*/%vm92131, /*on_true_vy=*/%v92083, /*on_false_vx=*/%v92130 (stack70)
        %vm92133 = vcmp.eq.f32.partialorder %v92083, 0.0 (stack71)
        %v92134 = vand.u32 2147483648, %v92083 (stack72)
        %v92135 = vsel /*vm=*/%vm92133, /*on_true_vy=*/%v92134, /*on_false_vx=*/%v92132 (stack73)
        %v92138 = vadd.f32 -3.0, %v92135 (stack52)
        %v92142 = vsel /*vm=*/%vm92086, /*on_true_vy=*/%v92127, /*on_false_vx=*/%v92138 (stack43)
        %v92146 = vmul.f32 %v92142, %v92123 (stack53)
        %v92150 = vadd.f32 %v92146, %v92119 (stack52)
        %v92154 = vmul.f32 %v92150, %v92142 (stack53)
        %v92158 = vadd.f32 %v92154, %v92115 (stack52)
        %v92162 = vmul.f32 %v92158, %v92142 (stack53)
        %v92166 = vadd.f32 %v92162, %v92111 (stack52)
        %v92170 = vmul.f32 %v92166, %v92142 (stack53)
        %v92174 = vadd.f32 %v92170, %v92107 (stack52)
        %v92178 = vmul.f32 %v92174, %v92142 (stack53)
        %v92182 = vadd.f32 %v92178, %v92103 (stack52)
        %v92186 = vmul.f32 %v92182, %v92142 (stack53)
        %v92190 = vadd.f32 %v92186, %v92099 (stack52)
        %v92194 = vmul.f32 %v92190, %v92142 (stack53)
        %v92198 = vadd.f32 %v92194, %v92095 (stack52)
        %v92202 = vmul.f32 %v92198, %v92142 (stack53)
        %v92206 = vadd.f32 %v92202, %v92091 (stack52)
        %v92210 = vmul.f32 %v92206, %v92057 (stack53)
        %v92214 = vsel /*vm=*/%vm92062, /*on_true_vy=*/%v92067, /*on_false_vx=*/%v92210 (stack43)
        %v92218 = vmul.f32 1.4140625, %v92214 (stack53)
        %v92221 = vpack.c.bf16 0.0, %v92218 (stack74)
        %120237 = vst [vmem:[%s280 + $0x260] sm:$0xf] /*vst_source=*/%v92221 (stack75)
        %v92225 = vadd.s32 %v89917, %v2842 (stack39)
        %v92235 = vadd.s32 %v92225, %v415 (stack39)
        %vm92239 = vcmp.lt.u32.totalorder %v92235, %v92225 (stack42)
        %vm92244 = vcmp.lt.u32.totalorder %v92225, %v2842 (stack42)
        %v92249 = vadd.s32 %v89900, %v2829 (stack39)
        %v92253 = vadd.s32 1, %v92249 (stack39)
        %v92257 = vsel /*vm=*/%vm92244, /*on_true_vy=*/%v92253, /*on_false_vx=*/%v92249 (stack43)
        %v92261 = vadd.s32 1, %v92257 (stack39)
        %v92265 = vsel /*vm=*/%vm92239, /*on_true_vy=*/%v92261, /*on_false_vx=*/%v92257 (stack43)
        %v92270 = vadd.s32 %v92265, %v10 (stack39)
        %v92274 = vadd.s32 %v92235, %v9 (stack39)
        %v92278 = vadd.s32 %v92274, %v92270 (stack39)
        %v92280 = vshll.u32 %v92274, 13 (stack44)
        %v92281 = vshrl.u32 %v92274, 19 (stack45)
        %v92282 = vor.u32 %v92281, %v92280 (stack46)
        %v92283 = vxor.u32 %v92282, %v92278 (stack47)
        %v92286 = vadd.s32 %v92283, %v92278 (stack39)
        %v92288 = vshll.u32 %v92283, 15 (stack44)
        %v92289 = vshrl.u32 %v92283, 17 (stack45)
        %v92290 = vor.u32 %v92289, %v92288 (stack46)
        %v92291 = vxor.u32 %v92290, %v92286 (stack47)
        %v92294 = vadd.s32 %v92291, %v92286 (stack39)
        %v92296 = vshll.u32 %v92291, 26 (stack44)
        %v92297 = vshrl.u32 %v92291, 6 (stack45)
        %v92298 = vor.u32 %v92297, %v92296 (stack46)
        %v92299 = vxor.u32 %v92298, %v92294 (stack47)
        %v92302 = vadd.s32 %v92299, %v92294 (stack39)
        %v92306 = vadd.s32 %v92302, %v9 (stack39)
        %v92308 = vshll.u32 %v92299, 6 (stack44)
        %v92309 = vshrl.u32 %v92299, 26 (stack45)
        %v92310 = vor.u32 %v92309, %v92308 (stack46)
        %v92311 = vxor.u32 %v92310, %v92302 (stack47)
        %v92314 = vadd.s32 %v92311, %v8 (stack39)
        %v92318 = vadd.s32 1, %v92314 (stack39)
        %v92322 = vadd.s32 %v92318, %v92306 (stack39)
        %v92324 = vshll.u32 %v92318, 17 (stack44)
        %v92325 = vshrl.u32 %v92318, 15 (stack45)
        %v92326 = vor.u32 %v92325, %v92324 (stack46)
        %v92327 = vxor.u32 %v92326, %v92322 (stack47)
        %v92330 = vadd.s32 %v92327, %v92322 (stack39)
        %v92332 = vshll.u32 %v92327, 29 (stack44)
        %v92333 = vshrl.u32 %v92327, 3 (stack45)
        %v92334 = vor.u32 %v92333, %v92332 (stack46)
        %v92335 = vxor.u32 %v92334, %v92330 (stack47)
        %v92338 = vadd.s32 %v92335, %v92330 (stack39)
        %v92340 = vshll.u32 %v92335, 16 (stack44)
        %v92341 = vshrl.u32 %v92335, 16 (stack45)
        %v92342 = vor.u32 %v92341, %v92340 (stack46)
        %v92343 = vxor.u32 %v92342, %v92338 (stack47)
        %v92346 = vadd.s32 %v92343, %v92338 (stack39)
        %v92350 = vadd.s32 %v92346, %v8 (stack39)
        %v92352 = vshll.u32 %v92343, 24 (stack44)
        %v92353 = vshrl.u32 %v92343, 8 (stack45)
        %v92354 = vor.u32 %v92353, %v92352 (stack46)
        %v92355 = vxor.u32 %v92354, %v92346 (stack47)
        %v92358 = vadd.s32 %v92355, %v10 (stack39)
        %v92362 = vadd.s32 2, %v92358 (stack39)
        %v92366 = vadd.s32 %v92362, %v92350 (stack39)
        %v92368 = vshll.u32 %v92362, 13 (stack44)
        %v92369 = vshrl.u32 %v92362, 19 (stack45)
        %v92370 = vor.u32 %v92369, %v92368 (stack46)
        %v92371 = vxor.u32 %v92370, %v92366 (stack47)
        %v92374 = vadd.s32 %v92371, %v92366 (stack39)
        %v92376 = vshll.u32 %v92371, 15 (stack44)
        %v92377 = vshrl.u32 %v92371, 17 (stack45)
        %v92378 = vor.u32 %v92377, %v92376 (stack46)
        %v92379 = vxor.u32 %v92378, %v92374 (stack47)
        %v92382 = vadd.s32 %v92379, %v92374 (stack39)
        %v92384 = vshll.u32 %v92379, 26 (stack44)
        %v92385 = vshrl.u32 %v92379, 6 (stack45)
        %v92386 = vor.u32 %v92385, %v92384 (stack46)
        %v92387 = vxor.u32 %v92386, %v92382 (stack47)
        %v92390 = vadd.s32 %v92387, %v92382 (stack39)
        %v92394 = vadd.s32 %v92390, %v10 (stack39)
        %v92396 = vshll.u32 %v92387, 6 (stack44)
        %v92397 = vshrl.u32 %v92387, 26 (stack45)
        %v92398 = vor.u32 %v92397, %v92396 (stack46)
        %v92399 = vxor.u32 %v92398, %v92390 (stack47)
        %v92402 = vadd.s32 %v92399, %v9 (stack39)
        %v92406 = vadd.s32 3, %v92402 (stack39)
        %v92410 = vadd.s32 %v92406, %v92394 (stack39)
        %v92412 = vshll.u32 %v92406, 17 (stack44)
        %v92413 = vshrl.u32 %v92406, 15 (stack45)
        %v92414 = vor.u32 %v92413, %v92412 (stack46)
        %v92415 = vxor.u32 %v92414, %v92410 (stack47)
        %v92418 = vadd.s32 %v92415, %v92410 (stack39)
        %v92420 = vshll.u32 %v92415, 29 (stack44)
        %v92421 = vshrl.u32 %v92415, 3 (stack45)
        %v92422 = vor.u32 %v92421, %v92420 (stack46)
        %v92423 = vxor.u32 %v92422, %v92418 (stack47)
        %v92426 = vadd.s32 %v92423, %v92418 (stack39)
        %v92428 = vshll.u32 %v92423, 16 (stack44)
        %v92429 = vshrl.u32 %v92423, 16 (stack45)
        %v92430 = vor.u32 %v92429, %v92428 (stack46)
        %v92431 = vxor.u32 %v92430, %v92426 (stack47)
        %v92434 = vadd.s32 %v92431, %v92426 (stack39)
        %v92438 = vadd.s32 %v92434, %v9 (stack39)
        %v92440 = vshll.u32 %v92431, 24 (stack44)
        %v92441 = vshrl.u32 %v92431, 8 (stack45)
        %v92442 = vor.u32 %v92441, %v92440 (stack46)
        %v92443 = vxor.u32 %v92442, %v92434 (stack47)
        %v92446 = vadd.s32 %v92443, %v8 (stack39)
        %v92450 = vadd.s32 4, %v92446 (stack39)
        %v92454 = vadd.s32 %v92450, %v92438 (stack39)
        %v92456 = vshll.u32 %v92450, 13 (stack44)
        %v92457 = vshrl.u32 %v92450, 19 (stack45)
        %v92458 = vor.u32 %v92457, %v92456 (stack46)
        %v92459 = vxor.u32 %v92458, %v92454 (stack47)
        %v92462 = vadd.s32 %v92459, %v92454 (stack39)
        %v92464 = vshll.u32 %v92459, 15 (stack44)
        %v92465 = vshrl.u32 %v92459, 17 (stack45)
        %v92466 = vor.u32 %v92465, %v92464 (stack46)
        %v92467 = vxor.u32 %v92466, %v92462 (stack47)
        %v92470 = vadd.s32 %v92467, %v92462 (stack39)
        %v92472 = vshll.u32 %v92467, 26 (stack44)
        %v92473 = vshrl.u32 %v92467, 6 (stack45)
        %v92474 = vor.u32 %v92473, %v92472 (stack46)
        %v92475 = vxor.u32 %v92474, %v92470 (stack47)
        %v92478 = vadd.s32 %v92475, %v92470 (stack39)
        %v92482 = vadd.s32 %v92478, %v8 (stack39)
        %v92484 = vshll.u32 %v92475, 6 (stack44)
        %v92485 = vshrl.u32 %v92475, 26 (stack45)
        %v92486 = vor.u32 %v92485, %v92484 (stack46)
        %v92487 = vxor.u32 %v92486, %v92478 (stack47)
        %v92490 = vadd.s32 %v92487, %v10 (stack39)
        %v92494 = vadd.s32 5, %v92490 (stack39)
        %v92496 = vxor.u32 %v92494, %v92482 (stack47)
        %v92497 = vand.u32.u8 255, %v92496 (stack48)
        %v92498 = vand.u32 65535, %v92497 (stack49)
        %v92499 = vshrl.u32 %v92498, 1 (stack50)
        %v92500 = vor.u32 16256, %v92499 (stack46)
        %v92501 = vand.u32.u16 65535, %v92500 (stack51)
        %v120238 = vadd.low.f32.bf16 -1.0, %v92501 (stack52)
        %v92510 = vmul.f32 2.0, %v120238 (stack53)
        %v92514 = vadd.f32 -0.99609375, %v92510 (stack52)
        %v92518 = vmax.f32 %v92514, -0.99609375 (stack54)
        %v92520 = vand.u32 2147483647, %v92518 (stack55)
        %vm92523 = vcmp.eq.f32.partialorder %v92520, 1.0 (stack56)
        %v92528 = vmul.f32 inf, %v92518 (stack53)
        %v92530 = vxor.u32 2147483648, %v92518 (stack57)
        %v92533 = vmul.f32 %v92530, %v92518 (stack53)
        %v92535 = vadd.f32 1.0, %v92533 (stack58)
        %v92536 = vlog2.pop %v92535 (stack59)
        %v92537 = vmul.f32 0.6931472, %v92536 (stack60)
        %v92538 = vmul.f32 -0.5, %v92533 (stack61)
        %v92539 = vadd.f32 1.0, %v92538 (stack62)
        %v92540 = vmul.f32 %v92539, %v92533 (stack63)
        %v92541 = vand.u32 2147483647, %v92533 (stack64)
        %vm92542 = vcmp.lt.f32.partialorder %v92541, 0.0004427343 (stack65)
        %v92543 = vsel /*vm=*/%vm92542, /*on_true_vy=*/%v92540, /*on_false_vx=*/%v92537 (stack66)
        %v92544 = vxor.u32 2147483648, %v92543 (stack57)
        %vm92547 = vcmp.lt.f32.partialorder %v92544, 5.0 (stack56)
        %v92552 = vsel /*vm=*/%vm92547, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v92556 = vsel /*vm=*/%vm92547, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v92560 = vsel /*vm=*/%vm92547, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v92564 = vsel /*vm=*/%vm92547, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v92568 = vsel /*vm=*/%vm92547, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v92572 = vsel /*vm=*/%vm92547, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v92576 = vsel /*vm=*/%vm92547, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v92580 = vsel /*vm=*/%vm92547, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v92584 = vsel /*vm=*/%vm92547, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v92588 = vadd.f32 -2.5, %v92544 (stack52)
        %v92590 = vrsqrt.pop %v92544 (stack67)
        %v92591 = vmul.f32 %v92590, %v92544 (stack68)
        %vm92592 = vcmp.eq.f32.partialorder %v92544, inf (stack69)
        %v92593 = vsel /*vm=*/%vm92592, /*on_true_vy=*/%v92544, /*on_false_vx=*/%v92591 (stack70)
        %vm92594 = vcmp.eq.f32.partialorder %v92544, 0.0 (stack71)
        %v92595 = vand.u32 2147483648, %v92544 (stack72)
        %v92596 = vsel /*vm=*/%vm92594, /*on_true_vy=*/%v92595, /*on_false_vx=*/%v92593 (stack73)
        %v92599 = vadd.f32 -3.0, %v92596 (stack52)
        %v92603 = vsel /*vm=*/%vm92547, /*on_true_vy=*/%v92588, /*on_false_vx=*/%v92599 (stack43)
        %v92607 = vmul.f32 %v92603, %v92584 (stack53)
        %v92611 = vadd.f32 %v92607, %v92580 (stack52)
        %v92615 = vmul.f32 %v92611, %v92603 (stack53)
        %v92619 = vadd.f32 %v92615, %v92576 (stack52)
        %v92623 = vmul.f32 %v92619, %v92603 (stack53)
        %v92627 = vadd.f32 %v92623, %v92572 (stack52)
        %v92631 = vmul.f32 %v92627, %v92603 (stack53)
        %v92635 = vadd.f32 %v92631, %v92568 (stack52)
        %v92639 = vmul.f32 %v92635, %v92603 (stack53)
        %v92643 = vadd.f32 %v92639, %v92564 (stack52)
        %v92647 = vmul.f32 %v92643, %v92603 (stack53)
        %v92651 = vadd.f32 %v92647, %v92560 (stack52)
        %v92655 = vmul.f32 %v92651, %v92603 (stack53)
        %v92659 = vadd.f32 %v92655, %v92556 (stack52)
        %v92663 = vmul.f32 %v92659, %v92603 (stack53)
        %v92667 = vadd.f32 %v92663, %v92552 (stack52)
        %v92671 = vmul.f32 %v92667, %v92518 (stack53)
        %v92675 = vsel /*vm=*/%vm92523, /*on_true_vy=*/%v92528, /*on_false_vx=*/%v92671 (stack43)
        %v92679 = vmul.f32 1.4140625, %v92675 (stack53)
        %v92682 = vpack.c.bf16 0.0, %v92679 (stack74)
        %120239 = vst [vmem:[%s280 + $0x2e0] sm:$0xf] /*vst_source=*/%v92682 (stack75)
        %v92686 = vadd.s32 %v89917, %v3329 (stack39)
        %v92696 = vadd.s32 %v92686, %v415 (stack39)
        %vm92700 = vcmp.lt.u32.totalorder %v92696, %v92686 (stack42)
        %vm92705 = vcmp.lt.u32.totalorder %v92686, %v3329 (stack42)
        %v92710 = vadd.s32 %v89900, %v3316 (stack39)
        %v92714 = vadd.s32 1, %v92710 (stack39)
        %v92718 = vsel /*vm=*/%vm92705, /*on_true_vy=*/%v92714, /*on_false_vx=*/%v92710 (stack43)
        %v92722 = vadd.s32 1, %v92718 (stack39)
        %v92726 = vsel /*vm=*/%vm92700, /*on_true_vy=*/%v92722, /*on_false_vx=*/%v92718 (stack43)
        %v92731 = vadd.s32 %v92726, %v10 (stack39)
        %v92735 = vadd.s32 %v92696, %v9 (stack39)
        %v92739 = vadd.s32 %v92735, %v92731 (stack39)
        %v92741 = vshll.u32 %v92735, 13 (stack44)
        %v92742 = vshrl.u32 %v92735, 19 (stack45)
        %v92743 = vor.u32 %v92742, %v92741 (stack46)
        %v92744 = vxor.u32 %v92743, %v92739 (stack47)
        %v92747 = vadd.s32 %v92744, %v92739 (stack39)
        %v92749 = vshll.u32 %v92744, 15 (stack44)
        %v92750 = vshrl.u32 %v92744, 17 (stack45)
        %v92751 = vor.u32 %v92750, %v92749 (stack46)
        %v92752 = vxor.u32 %v92751, %v92747 (stack47)
        %v92755 = vadd.s32 %v92752, %v92747 (stack39)
        %v92757 = vshll.u32 %v92752, 26 (stack44)
        %v92758 = vshrl.u32 %v92752, 6 (stack45)
        %v92759 = vor.u32 %v92758, %v92757 (stack46)
        %v92760 = vxor.u32 %v92759, %v92755 (stack47)
        %v92763 = vadd.s32 %v92760, %v92755 (stack39)
        %v92767 = vadd.s32 %v92763, %v9 (stack39)
        %v92769 = vshll.u32 %v92760, 6 (stack44)
        %v92770 = vshrl.u32 %v92760, 26 (stack45)
        %v92771 = vor.u32 %v92770, %v92769 (stack46)
        %v92772 = vxor.u32 %v92771, %v92763 (stack47)
        %v92775 = vadd.s32 %v92772, %v8 (stack39)
        %v92779 = vadd.s32 1, %v92775 (stack39)
        %v92783 = vadd.s32 %v92779, %v92767 (stack39)
        %v92785 = vshll.u32 %v92779, 17 (stack44)
        %v92786 = vshrl.u32 %v92779, 15 (stack45)
        %v92787 = vor.u32 %v92786, %v92785 (stack46)
        %v92788 = vxor.u32 %v92787, %v92783 (stack47)
        %v92791 = vadd.s32 %v92788, %v92783 (stack39)
        %v92793 = vshll.u32 %v92788, 29 (stack44)
        %v92794 = vshrl.u32 %v92788, 3 (stack45)
        %v92795 = vor.u32 %v92794, %v92793 (stack46)
        %v92796 = vxor.u32 %v92795, %v92791 (stack47)
        %v92799 = vadd.s32 %v92796, %v92791 (stack39)
        %v92801 = vshll.u32 %v92796, 16 (stack44)
        %v92802 = vshrl.u32 %v92796, 16 (stack45)
        %v92803 = vor.u32 %v92802, %v92801 (stack46)
        %v92804 = vxor.u32 %v92803, %v92799 (stack47)
        %v92807 = vadd.s32 %v92804, %v92799 (stack39)
        %v92811 = vadd.s32 %v92807, %v8 (stack39)
        %v92813 = vshll.u32 %v92804, 24 (stack44)
        %v92814 = vshrl.u32 %v92804, 8 (stack45)
        %v92815 = vor.u32 %v92814, %v92813 (stack46)
        %v92816 = vxor.u32 %v92815, %v92807 (stack47)
        %v92819 = vadd.s32 %v92816, %v10 (stack39)
        %v92823 = vadd.s32 2, %v92819 (stack39)
        %v92827 = vadd.s32 %v92823, %v92811 (stack39)
        %v92829 = vshll.u32 %v92823, 13 (stack44)
        %v92830 = vshrl.u32 %v92823, 19 (stack45)
        %v92831 = vor.u32 %v92830, %v92829 (stack46)
        %v92832 = vxor.u32 %v92831, %v92827 (stack47)
        %v92835 = vadd.s32 %v92832, %v92827 (stack39)
        %v92837 = vshll.u32 %v92832, 15 (stack44)
        %v92838 = vshrl.u32 %v92832, 17 (stack45)
        %v92839 = vor.u32 %v92838, %v92837 (stack46)
        %v92840 = vxor.u32 %v92839, %v92835 (stack47)
        %v92843 = vadd.s32 %v92840, %v92835 (stack39)
        %v92845 = vshll.u32 %v92840, 26 (stack44)
        %v92846 = vshrl.u32 %v92840, 6 (stack45)
        %v92847 = vor.u32 %v92846, %v92845 (stack46)
        %v92848 = vxor.u32 %v92847, %v92843 (stack47)
        %v92851 = vadd.s32 %v92848, %v92843 (stack39)
        %v92855 = vadd.s32 %v92851, %v10 (stack39)
        %v92857 = vshll.u32 %v92848, 6 (stack44)
        %v92858 = vshrl.u32 %v92848, 26 (stack45)
        %v92859 = vor.u32 %v92858, %v92857 (stack46)
        %v92860 = vxor.u32 %v92859, %v92851 (stack47)
        %v92863 = vadd.s32 %v92860, %v9 (stack39)
        %v92867 = vadd.s32 3, %v92863 (stack39)
        %v92871 = vadd.s32 %v92867, %v92855 (stack39)
        %v92873 = vshll.u32 %v92867, 17 (stack44)
        %v92874 = vshrl.u32 %v92867, 15 (stack45)
        %v92875 = vor.u32 %v92874, %v92873 (stack46)
        %v92876 = vxor.u32 %v92875, %v92871 (stack47)
        %v92879 = vadd.s32 %v92876, %v92871 (stack39)
        %v92881 = vshll.u32 %v92876, 29 (stack44)
        %v92882 = vshrl.u32 %v92876, 3 (stack45)
        %v92883 = vor.u32 %v92882, %v92881 (stack46)
        %v92884 = vxor.u32 %v92883, %v92879 (stack47)
        %v92887 = vadd.s32 %v92884, %v92879 (stack39)
        %v92889 = vshll.u32 %v92884, 16 (stack44)
        %v92890 = vshrl.u32 %v92884, 16 (stack45)
        %v92891 = vor.u32 %v92890, %v92889 (stack46)
        %v92892 = vxor.u32 %v92891, %v92887 (stack47)
        %v92895 = vadd.s32 %v92892, %v92887 (stack39)
        %v92899 = vadd.s32 %v92895, %v9 (stack39)
        %v92901 = vshll.u32 %v92892, 24 (stack44)
        %v92902 = vshrl.u32 %v92892, 8 (stack45)
        %v92903 = vor.u32 %v92902, %v92901 (stack46)
        %v92904 = vxor.u32 %v92903, %v92895 (stack47)
        %v92907 = vadd.s32 %v92904, %v8 (stack39)
        %v92911 = vadd.s32 4, %v92907 (stack39)
        %v92915 = vadd.s32 %v92911, %v92899 (stack39)
        %v92917 = vshll.u32 %v92911, 13 (stack44)
        %v92918 = vshrl.u32 %v92911, 19 (stack45)
        %v92919 = vor.u32 %v92918, %v92917 (stack46)
        %v92920 = vxor.u32 %v92919, %v92915 (stack47)
        %v92923 = vadd.s32 %v92920, %v92915 (stack39)
        %v92925 = vshll.u32 %v92920, 15 (stack44)
        %v92926 = vshrl.u32 %v92920, 17 (stack45)
        %v92927 = vor.u32 %v92926, %v92925 (stack46)
        %v92928 = vxor.u32 %v92927, %v92923 (stack47)
        %v92931 = vadd.s32 %v92928, %v92923 (stack39)
        %v92933 = vshll.u32 %v92928, 26 (stack44)
        %v92934 = vshrl.u32 %v92928, 6 (stack45)
        %v92935 = vor.u32 %v92934, %v92933 (stack46)
        %v92936 = vxor.u32 %v92935, %v92931 (stack47)
        %v92939 = vadd.s32 %v92936, %v92931 (stack39)
        %v92943 = vadd.s32 %v92939, %v8 (stack39)
        %v92945 = vshll.u32 %v92936, 6 (stack44)
        %v92946 = vshrl.u32 %v92936, 26 (stack45)
        %v92947 = vor.u32 %v92946, %v92945 (stack46)
        %v92948 = vxor.u32 %v92947, %v92939 (stack47)
        %v92951 = vadd.s32 %v92948, %v10 (stack39)
        %v92955 = vadd.s32 5, %v92951 (stack39)
        %v92957 = vxor.u32 %v92955, %v92943 (stack47)
        %v92958 = vand.u32.u8 255, %v92957 (stack48)
        %v92959 = vand.u32 65535, %v92958 (stack49)
        %v92960 = vshrl.u32 %v92959, 1 (stack50)
        %v92961 = vor.u32 16256, %v92960 (stack46)
        %v92962 = vand.u32.u16 65535, %v92961 (stack51)
        %v120240 = vadd.low.f32.bf16 -1.0, %v92962 (stack52)
        %v92971 = vmul.f32 2.0, %v120240 (stack53)
        %v92975 = vadd.f32 -0.99609375, %v92971 (stack52)
        %v92979 = vmax.f32 %v92975, -0.99609375 (stack54)
        %v92981 = vand.u32 2147483647, %v92979 (stack55)
        %vm92984 = vcmp.eq.f32.partialorder %v92981, 1.0 (stack56)
        %v92989 = vmul.f32 inf, %v92979 (stack53)
        %v92991 = vxor.u32 2147483648, %v92979 (stack57)
        %v92994 = vmul.f32 %v92991, %v92979 (stack53)
        %v92996 = vadd.f32 1.0, %v92994 (stack58)
        %v92997 = vlog2.pop %v92996 (stack59)
        %v92998 = vmul.f32 0.6931472, %v92997 (stack60)
        %v92999 = vmul.f32 -0.5, %v92994 (stack61)
        %v93000 = vadd.f32 1.0, %v92999 (stack62)
        %v93001 = vmul.f32 %v93000, %v92994 (stack63)
        %v93002 = vand.u32 2147483647, %v92994 (stack64)
        %vm93003 = vcmp.lt.f32.partialorder %v93002, 0.0004427343 (stack65)
        %v93004 = vsel /*vm=*/%vm93003, /*on_true_vy=*/%v93001, /*on_false_vx=*/%v92998 (stack66)
        %v93005 = vxor.u32 2147483648, %v93004 (stack57)
        %vm93008 = vcmp.lt.f32.partialorder %v93005, 5.0 (stack56)
        %v93013 = vsel /*vm=*/%vm93008, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v93017 = vsel /*vm=*/%vm93008, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v93021 = vsel /*vm=*/%vm93008, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v93025 = vsel /*vm=*/%vm93008, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v93029 = vsel /*vm=*/%vm93008, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v93033 = vsel /*vm=*/%vm93008, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v93037 = vsel /*vm=*/%vm93008, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v93041 = vsel /*vm=*/%vm93008, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v93045 = vsel /*vm=*/%vm93008, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v93049 = vadd.f32 -2.5, %v93005 (stack52)
        %v93051 = vrsqrt.pop %v93005 (stack67)
        %v93052 = vmul.f32 %v93051, %v93005 (stack68)
        %vm93053 = vcmp.eq.f32.partialorder %v93005, inf (stack69)
        %v93054 = vsel /*vm=*/%vm93053, /*on_true_vy=*/%v93005, /*on_false_vx=*/%v93052 (stack70)
        %vm93055 = vcmp.eq.f32.partialorder %v93005, 0.0 (stack71)
        %v93056 = vand.u32 2147483648, %v93005 (stack72)
        %v93057 = vsel /*vm=*/%vm93055, /*on_true_vy=*/%v93056, /*on_false_vx=*/%v93054 (stack73)
        %v93060 = vadd.f32 -3.0, %v93057 (stack52)
        %v93064 = vsel /*vm=*/%vm93008, /*on_true_vy=*/%v93049, /*on_false_vx=*/%v93060 (stack43)
        %v93068 = vmul.f32 %v93064, %v93045 (stack53)
        %v93072 = vadd.f32 %v93068, %v93041 (stack52)
        %v93076 = vmul.f32 %v93072, %v93064 (stack53)
        %v93080 = vadd.f32 %v93076, %v93037 (stack52)
        %v93084 = vmul.f32 %v93080, %v93064 (stack53)
        %v93088 = vadd.f32 %v93084, %v93033 (stack52)
        %v93092 = vmul.f32 %v93088, %v93064 (stack53)
        %v93096 = vadd.f32 %v93092, %v93029 (stack52)
        %v93100 = vmul.f32 %v93096, %v93064 (stack53)
        %v93104 = vadd.f32 %v93100, %v93025 (stack52)
        %v93108 = vmul.f32 %v93104, %v93064 (stack53)
        %v93112 = vadd.f32 %v93108, %v93021 (stack52)
        %v93116 = vmul.f32 %v93112, %v93064 (stack53)
        %v93120 = vadd.f32 %v93116, %v93017 (stack52)
        %v93124 = vmul.f32 %v93120, %v93064 (stack53)
        %v93128 = vadd.f32 %v93124, %v93013 (stack52)
        %v93132 = vmul.f32 %v93128, %v92979 (stack53)
        %v93136 = vsel /*vm=*/%vm92984, /*on_true_vy=*/%v92989, /*on_false_vx=*/%v93132 (stack43)
        %v93140 = vmul.f32 1.4140625, %v93136 (stack53)
        %v93143 = vpack.c.bf16 0.0, %v93140 (stack74)
        %120241 = vst [vmem:[%s280 + $0x360] sm:$0xf] /*vst_source=*/%v93143 (stack75)
        %v93147 = vadd.s32 %v89917, %v3816 (stack39)
        %v93157 = vadd.s32 %v93147, %v415 (stack39)
        %vm93161 = vcmp.lt.u32.totalorder %v93157, %v93147 (stack42)
        %vm93166 = vcmp.lt.u32.totalorder %v93147, %v3816 (stack42)
        %v93171 = vadd.s32 %v89900, %v3803 (stack39)
        %v93175 = vadd.s32 1, %v93171 (stack39)
        %v93179 = vsel /*vm=*/%vm93166, /*on_true_vy=*/%v93175, /*on_false_vx=*/%v93171 (stack43)
        %v93183 = vadd.s32 1, %v93179 (stack39)
        %v93187 = vsel /*vm=*/%vm93161, /*on_true_vy=*/%v93183, /*on_false_vx=*/%v93179 (stack43)
        %v93192 = vadd.s32 %v93187, %v10 (stack39)
        %v93196 = vadd.s32 %v93157, %v9 (stack39)
        %v93200 = vadd.s32 %v93196, %v93192 (stack39)
        %v93202 = vshll.u32 %v93196, 13 (stack44)
        %v93203 = vshrl.u32 %v93196, 19 (stack45)
        %v93204 = vor.u32 %v93203, %v93202 (stack46)
        %v93205 = vxor.u32 %v93204, %v93200 (stack47)
        %v93208 = vadd.s32 %v93205, %v93200 (stack39)
        %v93210 = vshll.u32 %v93205, 15 (stack44)
        %v93211 = vshrl.u32 %v93205, 17 (stack45)
        %v93212 = vor.u32 %v93211, %v93210 (stack46)
        %v93213 = vxor.u32 %v93212, %v93208 (stack47)
        %v93216 = vadd.s32 %v93213, %v93208 (stack39)
        %v93218 = vshll.u32 %v93213, 26 (stack44)
        %v93219 = vshrl.u32 %v93213, 6 (stack45)
        %v93220 = vor.u32 %v93219, %v93218 (stack46)
        %v93221 = vxor.u32 %v93220, %v93216 (stack47)
        %v93224 = vadd.s32 %v93221, %v93216 (stack39)
        %v93228 = vadd.s32 %v93224, %v9 (stack39)
        %v93230 = vshll.u32 %v93221, 6 (stack44)
        %v93231 = vshrl.u32 %v93221, 26 (stack45)
        %v93232 = vor.u32 %v93231, %v93230 (stack46)
        %v93233 = vxor.u32 %v93232, %v93224 (stack47)
        %v93236 = vadd.s32 %v93233, %v8 (stack39)
        %v93240 = vadd.s32 1, %v93236 (stack39)
        %v93244 = vadd.s32 %v93240, %v93228 (stack39)
        %v93246 = vshll.u32 %v93240, 17 (stack44)
        %v93247 = vshrl.u32 %v93240, 15 (stack45)
        %v93248 = vor.u32 %v93247, %v93246 (stack46)
        %v93249 = vxor.u32 %v93248, %v93244 (stack47)
        %v93252 = vadd.s32 %v93249, %v93244 (stack39)
        %v93254 = vshll.u32 %v93249, 29 (stack44)
        %v93255 = vshrl.u32 %v93249, 3 (stack45)
        %v93256 = vor.u32 %v93255, %v93254 (stack46)
        %v93257 = vxor.u32 %v93256, %v93252 (stack47)
        %v93260 = vadd.s32 %v93257, %v93252 (stack39)
        %v93262 = vshll.u32 %v93257, 16 (stack44)
        %v93263 = vshrl.u32 %v93257, 16 (stack45)
        %v93264 = vor.u32 %v93263, %v93262 (stack46)
        %v93265 = vxor.u32 %v93264, %v93260 (stack47)
        %v93268 = vadd.s32 %v93265, %v93260 (stack39)
        %v93272 = vadd.s32 %v93268, %v8 (stack39)
        %v93274 = vshll.u32 %v93265, 24 (stack44)
        %v93275 = vshrl.u32 %v93265, 8 (stack45)
        %v93276 = vor.u32 %v93275, %v93274 (stack46)
        %v93277 = vxor.u32 %v93276, %v93268 (stack47)
        %v93280 = vadd.s32 %v93277, %v10 (stack39)
        %v93284 = vadd.s32 2, %v93280 (stack39)
        %v93288 = vadd.s32 %v93284, %v93272 (stack39)
        %v93290 = vshll.u32 %v93284, 13 (stack44)
        %v93291 = vshrl.u32 %v93284, 19 (stack45)
        %v93292 = vor.u32 %v93291, %v93290 (stack46)
        %v93293 = vxor.u32 %v93292, %v93288 (stack47)
        %v93296 = vadd.s32 %v93293, %v93288 (stack39)
        %v93298 = vshll.u32 %v93293, 15 (stack44)
        %v93299 = vshrl.u32 %v93293, 17 (stack45)
        %v93300 = vor.u32 %v93299, %v93298 (stack46)
        %v93301 = vxor.u32 %v93300, %v93296 (stack47)
        %v93304 = vadd.s32 %v93301, %v93296 (stack39)
        %v93306 = vshll.u32 %v93301, 26 (stack44)
        %v93307 = vshrl.u32 %v93301, 6 (stack45)
        %v93308 = vor.u32 %v93307, %v93306 (stack46)
        %v93309 = vxor.u32 %v93308, %v93304 (stack47)
        %v93312 = vadd.s32 %v93309, %v93304 (stack39)
        %v93316 = vadd.s32 %v93312, %v10 (stack39)
        %v93318 = vshll.u32 %v93309, 6 (stack44)
        %v93319 = vshrl.u32 %v93309, 26 (stack45)
        %v93320 = vor.u32 %v93319, %v93318 (stack46)
        %v93321 = vxor.u32 %v93320, %v93312 (stack47)
        %v93324 = vadd.s32 %v93321, %v9 (stack39)
        %v93328 = vadd.s32 3, %v93324 (stack39)
        %v93332 = vadd.s32 %v93328, %v93316 (stack39)
        %v93334 = vshll.u32 %v93328, 17 (stack44)
        %v93335 = vshrl.u32 %v93328, 15 (stack45)
        %v93336 = vor.u32 %v93335, %v93334 (stack46)
        %v93337 = vxor.u32 %v93336, %v93332 (stack47)
        %v93340 = vadd.s32 %v93337, %v93332 (stack39)
        %v93342 = vshll.u32 %v93337, 29 (stack44)
        %v93343 = vshrl.u32 %v93337, 3 (stack45)
        %v93344 = vor.u32 %v93343, %v93342 (stack46)
        %v93345 = vxor.u32 %v93344, %v93340 (stack47)
        %v93348 = vadd.s32 %v93345, %v93340 (stack39)
        %v93350 = vshll.u32 %v93345, 16 (stack44)
        %v93351 = vshrl.u32 %v93345, 16 (stack45)
        %v93352 = vor.u32 %v93351, %v93350 (stack46)
        %v93353 = vxor.u32 %v93352, %v93348 (stack47)
        %v93356 = vadd.s32 %v93353, %v93348 (stack39)
        %v93360 = vadd.s32 %v93356, %v9 (stack39)
        %v93362 = vshll.u32 %v93353, 24 (stack44)
        %v93363 = vshrl.u32 %v93353, 8 (stack45)
        %v93364 = vor.u32 %v93363, %v93362 (stack46)
        %v93365 = vxor.u32 %v93364, %v93356 (stack47)
        %v93368 = vadd.s32 %v93365, %v8 (stack39)
        %v93372 = vadd.s32 4, %v93368 (stack39)
        %v93376 = vadd.s32 %v93372, %v93360 (stack39)
        %v93378 = vshll.u32 %v93372, 13 (stack44)
        %v93379 = vshrl.u32 %v93372, 19 (stack45)
        %v93380 = vor.u32 %v93379, %v93378 (stack46)
        %v93381 = vxor.u32 %v93380, %v93376 (stack47)
        %v93384 = vadd.s32 %v93381, %v93376 (stack39)
        %v93386 = vshll.u32 %v93381, 15 (stack44)
        %v93387 = vshrl.u32 %v93381, 17 (stack45)
        %v93388 = vor.u32 %v93387, %v93386 (stack46)
        %v93389 = vxor.u32 %v93388, %v93384 (stack47)
        %v93392 = vadd.s32 %v93389, %v93384 (stack39)
        %v93394 = vshll.u32 %v93389, 26 (stack44)
        %v93395 = vshrl.u32 %v93389, 6 (stack45)
        %v93396 = vor.u32 %v93395, %v93394 (stack46)
        %v93397 = vxor.u32 %v93396, %v93392 (stack47)
        %v93400 = vadd.s32 %v93397, %v93392 (stack39)
        %v93404 = vadd.s32 %v93400, %v8 (stack39)
        %v93406 = vshll.u32 %v93397, 6 (stack44)
        %v93407 = vshrl.u32 %v93397, 26 (stack45)
        %v93408 = vor.u32 %v93407, %v93406 (stack46)
        %v93409 = vxor.u32 %v93408, %v93400 (stack47)
        %v93412 = vadd.s32 %v93409, %v10 (stack39)
        %v93416 = vadd.s32 5, %v93412 (stack39)
        %v93418 = vxor.u32 %v93416, %v93404 (stack47)
        %v93419 = vand.u32.u8 255, %v93418 (stack48)
        %v93420 = vand.u32 65535, %v93419 (stack49)
        %v93421 = vshrl.u32 %v93420, 1 (stack50)
        %v93422 = vor.u32 16256, %v93421 (stack46)
        %v93423 = vand.u32.u16 65535, %v93422 (stack51)
        %v120242 = vadd.low.f32.bf16 -1.0, %v93423 (stack52)
        %v93432 = vmul.f32 2.0, %v120242 (stack53)
        %v93436 = vadd.f32 -0.99609375, %v93432 (stack52)
        %v93440 = vmax.f32 %v93436, -0.99609375 (stack54)
        %v93442 = vand.u32 2147483647, %v93440 (stack55)
        %vm93445 = vcmp.eq.f32.partialorder %v93442, 1.0 (stack56)
        %v93450 = vmul.f32 inf, %v93440 (stack53)
        %v93452 = vxor.u32 2147483648, %v93440 (stack57)
        %v93455 = vmul.f32 %v93452, %v93440 (stack53)
        %v93457 = vadd.f32 1.0, %v93455 (stack58)
        %v93458 = vlog2.pop %v93457 (stack59)
        %v93459 = vmul.f32 0.6931472, %v93458 (stack60)
        %v93460 = vmul.f32 -0.5, %v93455 (stack61)
        %v93461 = vadd.f32 1.0, %v93460 (stack62)
        %v93462 = vmul.f32 %v93461, %v93455 (stack63)
        %v93463 = vand.u32 2147483647, %v93455 (stack64)
        %vm93464 = vcmp.lt.f32.partialorder %v93463, 0.0004427343 (stack65)
        %v93465 = vsel /*vm=*/%vm93464, /*on_true_vy=*/%v93462, /*on_false_vx=*/%v93459 (stack66)
        %v93466 = vxor.u32 2147483648, %v93465 (stack57)
        %vm93469 = vcmp.lt.f32.partialorder %v93466, 5.0 (stack56)
        %v93474 = vsel /*vm=*/%vm93469, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v93478 = vsel /*vm=*/%vm93469, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v93482 = vsel /*vm=*/%vm93469, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v93486 = vsel /*vm=*/%vm93469, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v93490 = vsel /*vm=*/%vm93469, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v93494 = vsel /*vm=*/%vm93469, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v93498 = vsel /*vm=*/%vm93469, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v93502 = vsel /*vm=*/%vm93469, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v93506 = vsel /*vm=*/%vm93469, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v93510 = vadd.f32 -2.5, %v93466 (stack52)
        %v93512 = vrsqrt.pop %v93466 (stack67)
        %v93513 = vmul.f32 %v93512, %v93466 (stack68)
        %vm93514 = vcmp.eq.f32.partialorder %v93466, inf (stack69)
        %v93515 = vsel /*vm=*/%vm93514, /*on_true_vy=*/%v93466, /*on_false_vx=*/%v93513 (stack70)
        %vm93516 = vcmp.eq.f32.partialorder %v93466, 0.0 (stack71)
        %v93517 = vand.u32 2147483648, %v93466 (stack72)
        %v93518 = vsel /*vm=*/%vm93516, /*on_true_vy=*/%v93517, /*on_false_vx=*/%v93515 (stack73)
        %v93521 = vadd.f32 -3.0, %v93518 (stack52)
        %v93525 = vsel /*vm=*/%vm93469, /*on_true_vy=*/%v93510, /*on_false_vx=*/%v93521 (stack43)
        %v93529 = vmul.f32 %v93525, %v93506 (stack53)
        %v93533 = vadd.f32 %v93529, %v93502 (stack52)
        %v93537 = vmul.f32 %v93533, %v93525 (stack53)
        %v93541 = vadd.f32 %v93537, %v93498 (stack52)
        %v93545 = vmul.f32 %v93541, %v93525 (stack53)
        %v93549 = vadd.f32 %v93545, %v93494 (stack52)
        %v93553 = vmul.f32 %v93549, %v93525 (stack53)
        %v93557 = vadd.f32 %v93553, %v93490 (stack52)
        %v93561 = vmul.f32 %v93557, %v93525 (stack53)
        %v93565 = vadd.f32 %v93561, %v93486 (stack52)
        %v93569 = vmul.f32 %v93565, %v93525 (stack53)
        %v93573 = vadd.f32 %v93569, %v93482 (stack52)
        %v93577 = vmul.f32 %v93573, %v93525 (stack53)
        %v93581 = vadd.f32 %v93577, %v93478 (stack52)
        %v93585 = vmul.f32 %v93581, %v93525 (stack53)
        %v93589 = vadd.f32 %v93585, %v93474 (stack52)
        %v93593 = vmul.f32 %v93589, %v93440 (stack53)
        %v93597 = vsel /*vm=*/%vm93445, /*on_true_vy=*/%v93450, /*on_false_vx=*/%v93593 (stack43)
        %v93601 = vmul.f32 1.4140625, %v93597 (stack53)
        %v93604 = vpack.c.bf16 0.0, %v93601 (stack74)
        %120243 = vst [vmem:[%s280 + $0x3e0] sm:$0xf] /*vst_source=*/%v93604 (stack75)
        %s93606 = sadd.s32 200, %s120390 (stack76)
        %s93607 = sshrl.u32 %s93606, 10 (stack23)
        %p120244 = scmp.gt.s32.totalorder %s93607, 1 (stack24)
        %s93609 = scalar_select /*predicate=*/%p120244, /*on_true=*/1, /*on_false=*/%s93607 (stack25)
        %s93610 = sand.u32 1023, %s93606 /* smod.u32 w/div 1024 */ (stack26)
        %s93611 = sshrl.u32 %s93610, 7 (stack27)
        %s93612 = sand.u32 127, %s93610 /* smod.u32 w/div 128 */ (stack28)
        %s120245 = sshll.u32 %s93609, 3 (stack29)
        %s93614 = scalar_lea.vmem %s3, %s120245 (stack30)
        %s93616 = scalar_lea.vmem %s93614, %s93611 (stack31)
        %v93617 = vld [vmem:[%s93616] ss:$0 sm:$0xff] (stack32)
        %s93618 = sand.u32 255, %s93612 (stack33)
        %s93620 = sor.u32 256, %s93618 (stack34)
        %93621 = vbcast.lane.b32.xlu0 %v93617, %s93620 (stack35)
        %v93622 = vpop.permute.xlu0 %93621 (stack36)
        %s93631 = scalar_lea.vmem %s5, %s120245 (stack30)
        %s93633 = scalar_lea.vmem %s93631, %s93611 (stack31)
        %v93634 = vld [vmem:[%s93633] ss:$0 sm:$0xff] (stack32)
        %93638 = vbcast.lane.b32.xlu0 %v93634, %s93620 (stack35)
        %v93639 = vpop.permute.xlu0 %93638 (stack36)
        %v93642 = vadd.s32 %v93639, %v408 (stack39)
        %v93652 = vadd.s32 %v93642, %v415 (stack39)
        %vm93656 = vcmp.lt.u32.totalorder %v93652, %v93642 (stack42)
        %vm93661 = vcmp.lt.u32.totalorder %v93642, %v408 (stack42)
        %v93666 = vadd.s32 %v93622, %v380 (stack39)
        %v93670 = vadd.s32 1, %v93666 (stack39)
        %v93674 = vsel /*vm=*/%vm93661, /*on_true_vy=*/%v93670, /*on_false_vx=*/%v93666 (stack43)
        %v93678 = vadd.s32 1, %v93674 (stack39)
        %v93682 = vsel /*vm=*/%vm93656, /*on_true_vy=*/%v93678, /*on_false_vx=*/%v93674 (stack43)
        %v93687 = vadd.s32 %v93682, %v10 (stack39)
        %v93691 = vadd.s32 %v93652, %v9 (stack39)
        %v93695 = vadd.s32 %v93691, %v93687 (stack39)
        %v93697 = vshll.u32 %v93691, 13 (stack44)
        %v93698 = vshrl.u32 %v93691, 19 (stack45)
        %v93699 = vor.u32 %v93698, %v93697 (stack46)
        %v93700 = vxor.u32 %v93699, %v93695 (stack47)
        %v93703 = vadd.s32 %v93700, %v93695 (stack39)
        %v93705 = vshll.u32 %v93700, 15 (stack44)
        %v93706 = vshrl.u32 %v93700, 17 (stack45)
        %v93707 = vor.u32 %v93706, %v93705 (stack46)
        %v93708 = vxor.u32 %v93707, %v93703 (stack47)
        %v93711 = vadd.s32 %v93708, %v93703 (stack39)
        %v93713 = vshll.u32 %v93708, 26 (stack44)
        %v93714 = vshrl.u32 %v93708, 6 (stack45)
        %v93715 = vor.u32 %v93714, %v93713 (stack46)
        %v93716 = vxor.u32 %v93715, %v93711 (stack47)
        %v93719 = vadd.s32 %v93716, %v93711 (stack39)
        %v93723 = vadd.s32 %v93719, %v9 (stack39)
        %v93725 = vshll.u32 %v93716, 6 (stack44)
        %v93726 = vshrl.u32 %v93716, 26 (stack45)
        %v93727 = vor.u32 %v93726, %v93725 (stack46)
        %v93728 = vxor.u32 %v93727, %v93719 (stack47)
        %v93731 = vadd.s32 %v93728, %v8 (stack39)
        %v93735 = vadd.s32 1, %v93731 (stack39)
        %v93739 = vadd.s32 %v93735, %v93723 (stack39)
        %v93741 = vshll.u32 %v93735, 17 (stack44)
        %v93742 = vshrl.u32 %v93735, 15 (stack45)
        %v93743 = vor.u32 %v93742, %v93741 (stack46)
        %v93744 = vxor.u32 %v93743, %v93739 (stack47)
        %v93747 = vadd.s32 %v93744, %v93739 (stack39)
        %v93749 = vshll.u32 %v93744, 29 (stack44)
        %v93750 = vshrl.u32 %v93744, 3 (stack45)
        %v93751 = vor.u32 %v93750, %v93749 (stack46)
        %v93752 = vxor.u32 %v93751, %v93747 (stack47)
        %v93755 = vadd.s32 %v93752, %v93747 (stack39)
        %v93757 = vshll.u32 %v93752, 16 (stack44)
        %v93758 = vshrl.u32 %v93752, 16 (stack45)
        %v93759 = vor.u32 %v93758, %v93757 (stack46)
        %v93760 = vxor.u32 %v93759, %v93755 (stack47)
        %v93763 = vadd.s32 %v93760, %v93755 (stack39)
        %v93767 = vadd.s32 %v93763, %v8 (stack39)
        %v93769 = vshll.u32 %v93760, 24 (stack44)
        %v93770 = vshrl.u32 %v93760, 8 (stack45)
        %v93771 = vor.u32 %v93770, %v93769 (stack46)
        %v93772 = vxor.u32 %v93771, %v93763 (stack47)
        %v93775 = vadd.s32 %v93772, %v10 (stack39)
        %v93779 = vadd.s32 2, %v93775 (stack39)
        %v93783 = vadd.s32 %v93779, %v93767 (stack39)
        %v93785 = vshll.u32 %v93779, 13 (stack44)
        %v93786 = vshrl.u32 %v93779, 19 (stack45)
        %v93787 = vor.u32 %v93786, %v93785 (stack46)
        %v93788 = vxor.u32 %v93787, %v93783 (stack47)
        %v93791 = vadd.s32 %v93788, %v93783 (stack39)
        %v93793 = vshll.u32 %v93788, 15 (stack44)
        %v93794 = vshrl.u32 %v93788, 17 (stack45)
        %v93795 = vor.u32 %v93794, %v93793 (stack46)
        %v93796 = vxor.u32 %v93795, %v93791 (stack47)
        %v93799 = vadd.s32 %v93796, %v93791 (stack39)
        %v93801 = vshll.u32 %v93796, 26 (stack44)
        %v93802 = vshrl.u32 %v93796, 6 (stack45)
        %v93803 = vor.u32 %v93802, %v93801 (stack46)
        %v93804 = vxor.u32 %v93803, %v93799 (stack47)
        %v93807 = vadd.s32 %v93804, %v93799 (stack39)
        %v93811 = vadd.s32 %v93807, %v10 (stack39)
        %v93813 = vshll.u32 %v93804, 6 (stack44)
        %v93814 = vshrl.u32 %v93804, 26 (stack45)
        %v93815 = vor.u32 %v93814, %v93813 (stack46)
        %v93816 = vxor.u32 %v93815, %v93807 (stack47)
        %v93819 = vadd.s32 %v93816, %v9 (stack39)
        %v93823 = vadd.s32 3, %v93819 (stack39)
        %v93827 = vadd.s32 %v93823, %v93811 (stack39)
        %v93829 = vshll.u32 %v93823, 17 (stack44)
        %v93830 = vshrl.u32 %v93823, 15 (stack45)
        %v93831 = vor.u32 %v93830, %v93829 (stack46)
        %v93832 = vxor.u32 %v93831, %v93827 (stack47)
        %v93835 = vadd.s32 %v93832, %v93827 (stack39)
        %v93837 = vshll.u32 %v93832, 29 (stack44)
        %v93838 = vshrl.u32 %v93832, 3 (stack45)
        %v93839 = vor.u32 %v93838, %v93837 (stack46)
        %v93840 = vxor.u32 %v93839, %v93835 (stack47)
        %v93843 = vadd.s32 %v93840, %v93835 (stack39)
        %v93845 = vshll.u32 %v93840, 16 (stack44)
        %v93846 = vshrl.u32 %v93840, 16 (stack45)
        %v93847 = vor.u32 %v93846, %v93845 (stack46)
        %v93848 = vxor.u32 %v93847, %v93843 (stack47)
        %v93851 = vadd.s32 %v93848, %v93843 (stack39)
        %v93855 = vadd.s32 %v93851, %v9 (stack39)
        %v93857 = vshll.u32 %v93848, 24 (stack44)
        %v93858 = vshrl.u32 %v93848, 8 (stack45)
        %v93859 = vor.u32 %v93858, %v93857 (stack46)
        %v93860 = vxor.u32 %v93859, %v93851 (stack47)
        %v93863 = vadd.s32 %v93860, %v8 (stack39)
        %v93867 = vadd.s32 4, %v93863 (stack39)
        %v93871 = vadd.s32 %v93867, %v93855 (stack39)
        %v93873 = vshll.u32 %v93867, 13 (stack44)
        %v93874 = vshrl.u32 %v93867, 19 (stack45)
        %v93875 = vor.u32 %v93874, %v93873 (stack46)
        %v93876 = vxor.u32 %v93875, %v93871 (stack47)
        %v93879 = vadd.s32 %v93876, %v93871 (stack39)
        %v93881 = vshll.u32 %v93876, 15 (stack44)
        %v93882 = vshrl.u32 %v93876, 17 (stack45)
        %v93883 = vor.u32 %v93882, %v93881 (stack46)
        %v93884 = vxor.u32 %v93883, %v93879 (stack47)
        %v93887 = vadd.s32 %v93884, %v93879 (stack39)
        %v93889 = vshll.u32 %v93884, 26 (stack44)
        %v93890 = vshrl.u32 %v93884, 6 (stack45)
        %v93891 = vor.u32 %v93890, %v93889 (stack46)
        %v93892 = vxor.u32 %v93891, %v93887 (stack47)
        %v93895 = vadd.s32 %v93892, %v93887 (stack39)
        %v93899 = vadd.s32 %v93895, %v8 (stack39)
        %v93901 = vshll.u32 %v93892, 6 (stack44)
        %v93902 = vshrl.u32 %v93892, 26 (stack45)
        %v93903 = vor.u32 %v93902, %v93901 (stack46)
        %v93904 = vxor.u32 %v93903, %v93895 (stack47)
        %v93907 = vadd.s32 %v93904, %v10 (stack39)
        %v93911 = vadd.s32 5, %v93907 (stack39)
        %v93913 = vxor.u32 %v93911, %v93899 (stack47)
        %v93914 = vand.u32.u8 255, %v93913 (stack48)
        %v93915 = vand.u32 65535, %v93914 (stack49)
        %v93916 = vshrl.u32 %v93915, 1 (stack50)
        %v93917 = vor.u32 16256, %v93916 (stack46)
        %v93918 = vand.u32.u16 65535, %v93917 (stack51)
        %v120248 = vadd.low.f32.bf16 -1.0, %v93918 (stack52)
        %v93927 = vmul.f32 2.0, %v120248 (stack53)
        %v93931 = vadd.f32 -0.99609375, %v93927 (stack52)
        %v93935 = vmax.f32 %v93931, -0.99609375 (stack54)
        %v93937 = vand.u32 2147483647, %v93935 (stack55)
        %vm93940 = vcmp.eq.f32.partialorder %v93937, 1.0 (stack56)
        %v93945 = vmul.f32 inf, %v93935 (stack53)
        %v93947 = vxor.u32 2147483648, %v93935 (stack57)
        %v93950 = vmul.f32 %v93947, %v93935 (stack53)
        %v93952 = vadd.f32 1.0, %v93950 (stack58)
        %v93953 = vlog2.pop %v93952 (stack59)
        %v93954 = vmul.f32 0.6931472, %v93953 (stack60)
        %v93955 = vmul.f32 -0.5, %v93950 (stack61)
        %v93956 = vadd.f32 1.0, %v93955 (stack62)
        %v93957 = vmul.f32 %v93956, %v93950 (stack63)
        %v93958 = vand.u32 2147483647, %v93950 (stack64)
        %vm93959 = vcmp.lt.f32.partialorder %v93958, 0.0004427343 (stack65)
        %v93960 = vsel /*vm=*/%vm93959, /*on_true_vy=*/%v93957, /*on_false_vx=*/%v93954 (stack66)
        %v93961 = vxor.u32 2147483648, %v93960 (stack57)
        %vm93964 = vcmp.lt.f32.partialorder %v93961, 5.0 (stack56)
        %v93969 = vsel /*vm=*/%vm93964, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v93973 = vsel /*vm=*/%vm93964, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v93977 = vsel /*vm=*/%vm93964, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v93981 = vsel /*vm=*/%vm93964, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v93985 = vsel /*vm=*/%vm93964, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v93989 = vsel /*vm=*/%vm93964, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v93993 = vsel /*vm=*/%vm93964, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v93997 = vsel /*vm=*/%vm93964, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v94001 = vsel /*vm=*/%vm93964, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v94005 = vadd.f32 -2.5, %v93961 (stack52)
        %v94007 = vrsqrt.pop %v93961 (stack67)
        %v94008 = vmul.f32 %v94007, %v93961 (stack68)
        %vm94009 = vcmp.eq.f32.partialorder %v93961, inf (stack69)
        %v94010 = vsel /*vm=*/%vm94009, /*on_true_vy=*/%v93961, /*on_false_vx=*/%v94008 (stack70)
        %vm94011 = vcmp.eq.f32.partialorder %v93961, 0.0 (stack71)
        %v94012 = vand.u32 2147483648, %v93961 (stack72)
        %v94013 = vsel /*vm=*/%vm94011, /*on_true_vy=*/%v94012, /*on_false_vx=*/%v94010 (stack73)
        %v94016 = vadd.f32 -3.0, %v94013 (stack52)
        %v94020 = vsel /*vm=*/%vm93964, /*on_true_vy=*/%v94005, /*on_false_vx=*/%v94016 (stack43)
        %v94024 = vmul.f32 %v94020, %v94001 (stack53)
        %v94028 = vadd.f32 %v94024, %v93997 (stack52)
        %v94032 = vmul.f32 %v94028, %v94020 (stack53)
        %v94036 = vadd.f32 %v94032, %v93993 (stack52)
        %v94040 = vmul.f32 %v94036, %v94020 (stack53)
        %v94044 = vadd.f32 %v94040, %v93989 (stack52)
        %v94048 = vmul.f32 %v94044, %v94020 (stack53)
        %v94052 = vadd.f32 %v94048, %v93985 (stack52)
        %v94056 = vmul.f32 %v94052, %v94020 (stack53)
        %v94060 = vadd.f32 %v94056, %v93981 (stack52)
        %v94064 = vmul.f32 %v94060, %v94020 (stack53)
        %v94068 = vadd.f32 %v94064, %v93977 (stack52)
        %v94072 = vmul.f32 %v94068, %v94020 (stack53)
        %v94076 = vadd.f32 %v94072, %v93973 (stack52)
        %v94080 = vmul.f32 %v94076, %v94020 (stack53)
        %v94084 = vadd.f32 %v94080, %v93969 (stack52)
        %v94088 = vmul.f32 %v94084, %v93935 (stack53)
        %v94092 = vsel /*vm=*/%vm93940, /*on_true_vy=*/%v93945, /*on_false_vx=*/%v94088 (stack43)
        %v94096 = vmul.f32 1.4140625, %v94092 (stack53)
        %v94099 = vpack.c.bf16 0.0, %v94096 (stack74)
        %120249 = vst [vmem:[%s280 + $0x64] sm:$0xf] /*vst_source=*/%v94099 (stack75)
        %v94103 = vadd.s32 %v93639, %v894 (stack39)
        %v94113 = vadd.s32 %v94103, %v415 (stack39)
        %vm94117 = vcmp.lt.u32.totalorder %v94113, %v94103 (stack42)
        %vm94122 = vcmp.lt.u32.totalorder %v94103, %v894 (stack42)
        %v94127 = vadd.s32 %v93622, %v881 (stack39)
        %v94131 = vadd.s32 1, %v94127 (stack39)
        %v94135 = vsel /*vm=*/%vm94122, /*on_true_vy=*/%v94131, /*on_false_vx=*/%v94127 (stack43)
        %v94139 = vadd.s32 1, %v94135 (stack39)
        %v94143 = vsel /*vm=*/%vm94117, /*on_true_vy=*/%v94139, /*on_false_vx=*/%v94135 (stack43)
        %v94148 = vadd.s32 %v94143, %v10 (stack39)
        %v94152 = vadd.s32 %v94113, %v9 (stack39)
        %v94156 = vadd.s32 %v94152, %v94148 (stack39)
        %v94158 = vshll.u32 %v94152, 13 (stack44)
        %v94159 = vshrl.u32 %v94152, 19 (stack45)
        %v94160 = vor.u32 %v94159, %v94158 (stack46)
        %v94161 = vxor.u32 %v94160, %v94156 (stack47)
        %v94164 = vadd.s32 %v94161, %v94156 (stack39)
        %v94166 = vshll.u32 %v94161, 15 (stack44)
        %v94167 = vshrl.u32 %v94161, 17 (stack45)
        %v94168 = vor.u32 %v94167, %v94166 (stack46)
        %v94169 = vxor.u32 %v94168, %v94164 (stack47)
        %v94172 = vadd.s32 %v94169, %v94164 (stack39)
        %v94174 = vshll.u32 %v94169, 26 (stack44)
        %v94175 = vshrl.u32 %v94169, 6 (stack45)
        %v94176 = vor.u32 %v94175, %v94174 (stack46)
        %v94177 = vxor.u32 %v94176, %v94172 (stack47)
        %v94180 = vadd.s32 %v94177, %v94172 (stack39)
        %v94184 = vadd.s32 %v94180, %v9 (stack39)
        %v94186 = vshll.u32 %v94177, 6 (stack44)
        %v94187 = vshrl.u32 %v94177, 26 (stack45)
        %v94188 = vor.u32 %v94187, %v94186 (stack46)
        %v94189 = vxor.u32 %v94188, %v94180 (stack47)
        %v94192 = vadd.s32 %v94189, %v8 (stack39)
        %v94196 = vadd.s32 1, %v94192 (stack39)
        %v94200 = vadd.s32 %v94196, %v94184 (stack39)
        %v94202 = vshll.u32 %v94196, 17 (stack44)
        %v94203 = vshrl.u32 %v94196, 15 (stack45)
        %v94204 = vor.u32 %v94203, %v94202 (stack46)
        %v94205 = vxor.u32 %v94204, %v94200 (stack47)
        %v94208 = vadd.s32 %v94205, %v94200 (stack39)
        %v94210 = vshll.u32 %v94205, 29 (stack44)
        %v94211 = vshrl.u32 %v94205, 3 (stack45)
        %v94212 = vor.u32 %v94211, %v94210 (stack46)
        %v94213 = vxor.u32 %v94212, %v94208 (stack47)
        %v94216 = vadd.s32 %v94213, %v94208 (stack39)
        %v94218 = vshll.u32 %v94213, 16 (stack44)
        %v94219 = vshrl.u32 %v94213, 16 (stack45)
        %v94220 = vor.u32 %v94219, %v94218 (stack46)
        %v94221 = vxor.u32 %v94220, %v94216 (stack47)
        %v94224 = vadd.s32 %v94221, %v94216 (stack39)
        %v94228 = vadd.s32 %v94224, %v8 (stack39)
        %v94230 = vshll.u32 %v94221, 24 (stack44)
        %v94231 = vshrl.u32 %v94221, 8 (stack45)
        %v94232 = vor.u32 %v94231, %v94230 (stack46)
        %v94233 = vxor.u32 %v94232, %v94224 (stack47)
        %v94236 = vadd.s32 %v94233, %v10 (stack39)
        %v94240 = vadd.s32 2, %v94236 (stack39)
        %v94244 = vadd.s32 %v94240, %v94228 (stack39)
        %v94246 = vshll.u32 %v94240, 13 (stack44)
        %v94247 = vshrl.u32 %v94240, 19 (stack45)
        %v94248 = vor.u32 %v94247, %v94246 (stack46)
        %v94249 = vxor.u32 %v94248, %v94244 (stack47)
        %v94252 = vadd.s32 %v94249, %v94244 (stack39)
        %v94254 = vshll.u32 %v94249, 15 (stack44)
        %v94255 = vshrl.u32 %v94249, 17 (stack45)
        %v94256 = vor.u32 %v94255, %v94254 (stack46)
        %v94257 = vxor.u32 %v94256, %v94252 (stack47)
        %v94260 = vadd.s32 %v94257, %v94252 (stack39)
        %v94262 = vshll.u32 %v94257, 26 (stack44)
        %v94263 = vshrl.u32 %v94257, 6 (stack45)
        %v94264 = vor.u32 %v94263, %v94262 (stack46)
        %v94265 = vxor.u32 %v94264, %v94260 (stack47)
        %v94268 = vadd.s32 %v94265, %v94260 (stack39)
        %v94272 = vadd.s32 %v94268, %v10 (stack39)
        %v94274 = vshll.u32 %v94265, 6 (stack44)
        %v94275 = vshrl.u32 %v94265, 26 (stack45)
        %v94276 = vor.u32 %v94275, %v94274 (stack46)
        %v94277 = vxor.u32 %v94276, %v94268 (stack47)
        %v94280 = vadd.s32 %v94277, %v9 (stack39)
        %v94284 = vadd.s32 3, %v94280 (stack39)
        %v94288 = vadd.s32 %v94284, %v94272 (stack39)
        %v94290 = vshll.u32 %v94284, 17 (stack44)
        %v94291 = vshrl.u32 %v94284, 15 (stack45)
        %v94292 = vor.u32 %v94291, %v94290 (stack46)
        %v94293 = vxor.u32 %v94292, %v94288 (stack47)
        %v94296 = vadd.s32 %v94293, %v94288 (stack39)
        %v94298 = vshll.u32 %v94293, 29 (stack44)
        %v94299 = vshrl.u32 %v94293, 3 (stack45)
        %v94300 = vor.u32 %v94299, %v94298 (stack46)
        %v94301 = vxor.u32 %v94300, %v94296 (stack47)
        %v94304 = vadd.s32 %v94301, %v94296 (stack39)
        %v94306 = vshll.u32 %v94301, 16 (stack44)
        %v94307 = vshrl.u32 %v94301, 16 (stack45)
        %v94308 = vor.u32 %v94307, %v94306 (stack46)
        %v94309 = vxor.u32 %v94308, %v94304 (stack47)
        %v94312 = vadd.s32 %v94309, %v94304 (stack39)
        %v94316 = vadd.s32 %v94312, %v9 (stack39)
        %v94318 = vshll.u32 %v94309, 24 (stack44)
        %v94319 = vshrl.u32 %v94309, 8 (stack45)
        %v94320 = vor.u32 %v94319, %v94318 (stack46)
        %v94321 = vxor.u32 %v94320, %v94312 (stack47)
        %v94324 = vadd.s32 %v94321, %v8 (stack39)
        %v94328 = vadd.s32 4, %v94324 (stack39)
        %v94332 = vadd.s32 %v94328, %v94316 (stack39)
        %v94334 = vshll.u32 %v94328, 13 (stack44)
        %v94335 = vshrl.u32 %v94328, 19 (stack45)
        %v94336 = vor.u32 %v94335, %v94334 (stack46)
        %v94337 = vxor.u32 %v94336, %v94332 (stack47)
        %v94340 = vadd.s32 %v94337, %v94332 (stack39)
        %v94342 = vshll.u32 %v94337, 15 (stack44)
        %v94343 = vshrl.u32 %v94337, 17 (stack45)
        %v94344 = vor.u32 %v94343, %v94342 (stack46)
        %v94345 = vxor.u32 %v94344, %v94340 (stack47)
        %v94348 = vadd.s32 %v94345, %v94340 (stack39)
        %v94350 = vshll.u32 %v94345, 26 (stack44)
        %v94351 = vshrl.u32 %v94345, 6 (stack45)
        %v94352 = vor.u32 %v94351, %v94350 (stack46)
        %v94353 = vxor.u32 %v94352, %v94348 (stack47)
        %v94356 = vadd.s32 %v94353, %v94348 (stack39)
        %v94360 = vadd.s32 %v94356, %v8 (stack39)
        %v94362 = vshll.u32 %v94353, 6 (stack44)
        %v94363 = vshrl.u32 %v94353, 26 (stack45)
        %v94364 = vor.u32 %v94363, %v94362 (stack46)
        %v94365 = vxor.u32 %v94364, %v94356 (stack47)
        %v94368 = vadd.s32 %v94365, %v10 (stack39)
        %v94372 = vadd.s32 5, %v94368 (stack39)
        %v94374 = vxor.u32 %v94372, %v94360 (stack47)
        %v94375 = vand.u32.u8 255, %v94374 (stack48)
        %v94376 = vand.u32 65535, %v94375 (stack49)
        %v94377 = vshrl.u32 %v94376, 1 (stack50)
        %v94378 = vor.u32 16256, %v94377 (stack46)
        %v94379 = vand.u32.u16 65535, %v94378 (stack51)
        %v120250 = vadd.low.f32.bf16 -1.0, %v94379 (stack52)
        %v94388 = vmul.f32 2.0, %v120250 (stack53)
        %v94392 = vadd.f32 -0.99609375, %v94388 (stack52)
        %v94396 = vmax.f32 %v94392, -0.99609375 (stack54)
        %v94398 = vand.u32 2147483647, %v94396 (stack55)
        %vm94401 = vcmp.eq.f32.partialorder %v94398, 1.0 (stack56)
        %v94406 = vmul.f32 inf, %v94396 (stack53)
        %v94408 = vxor.u32 2147483648, %v94396 (stack57)
        %v94411 = vmul.f32 %v94408, %v94396 (stack53)
        %v94413 = vadd.f32 1.0, %v94411 (stack58)
        %v94414 = vlog2.pop %v94413 (stack59)
        %v94415 = vmul.f32 0.6931472, %v94414 (stack60)
        %v94416 = vmul.f32 -0.5, %v94411 (stack61)
        %v94417 = vadd.f32 1.0, %v94416 (stack62)
        %v94418 = vmul.f32 %v94417, %v94411 (stack63)
        %v94419 = vand.u32 2147483647, %v94411 (stack64)
        %vm94420 = vcmp.lt.f32.partialorder %v94419, 0.0004427343 (stack65)
        %v94421 = vsel /*vm=*/%vm94420, /*on_true_vy=*/%v94418, /*on_false_vx=*/%v94415 (stack66)
        %v94422 = vxor.u32 2147483648, %v94421 (stack57)
        %vm94425 = vcmp.lt.f32.partialorder %v94422, 5.0 (stack56)
        %v94430 = vsel /*vm=*/%vm94425, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v94434 = vsel /*vm=*/%vm94425, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v94438 = vsel /*vm=*/%vm94425, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v94442 = vsel /*vm=*/%vm94425, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v94446 = vsel /*vm=*/%vm94425, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v94450 = vsel /*vm=*/%vm94425, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v94454 = vsel /*vm=*/%vm94425, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v94458 = vsel /*vm=*/%vm94425, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v94462 = vsel /*vm=*/%vm94425, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v94466 = vadd.f32 -2.5, %v94422 (stack52)
        %v94468 = vrsqrt.pop %v94422 (stack67)
        %v94469 = vmul.f32 %v94468, %v94422 (stack68)
        %vm94470 = vcmp.eq.f32.partialorder %v94422, inf (stack69)
        %v94471 = vsel /*vm=*/%vm94470, /*on_true_vy=*/%v94422, /*on_false_vx=*/%v94469 (stack70)
        %vm94472 = vcmp.eq.f32.partialorder %v94422, 0.0 (stack71)
        %v94473 = vand.u32 2147483648, %v94422 (stack72)
        %v94474 = vsel /*vm=*/%vm94472, /*on_true_vy=*/%v94473, /*on_false_vx=*/%v94471 (stack73)
        %v94477 = vadd.f32 -3.0, %v94474 (stack52)
        %v94481 = vsel /*vm=*/%vm94425, /*on_true_vy=*/%v94466, /*on_false_vx=*/%v94477 (stack43)
        %v94485 = vmul.f32 %v94481, %v94462 (stack53)
        %v94489 = vadd.f32 %v94485, %v94458 (stack52)
        %v94493 = vmul.f32 %v94489, %v94481 (stack53)
        %v94497 = vadd.f32 %v94493, %v94454 (stack52)
        %v94501 = vmul.f32 %v94497, %v94481 (stack53)
        %v94505 = vadd.f32 %v94501, %v94450 (stack52)
        %v94509 = vmul.f32 %v94505, %v94481 (stack53)
        %v94513 = vadd.f32 %v94509, %v94446 (stack52)
        %v94517 = vmul.f32 %v94513, %v94481 (stack53)
        %v94521 = vadd.f32 %v94517, %v94442 (stack52)
        %v94525 = vmul.f32 %v94521, %v94481 (stack53)
        %v94529 = vadd.f32 %v94525, %v94438 (stack52)
        %v94533 = vmul.f32 %v94529, %v94481 (stack53)
        %v94537 = vadd.f32 %v94533, %v94434 (stack52)
        %v94541 = vmul.f32 %v94537, %v94481 (stack53)
        %v94545 = vadd.f32 %v94541, %v94430 (stack52)
        %v94549 = vmul.f32 %v94545, %v94396 (stack53)
        %v94553 = vsel /*vm=*/%vm94401, /*on_true_vy=*/%v94406, /*on_false_vx=*/%v94549 (stack43)
        %v94557 = vmul.f32 1.4140625, %v94553 (stack53)
        %v94560 = vpack.c.bf16 0.0, %v94557 (stack74)
        %120251 = vst [vmem:[%s280 + $0xe4] sm:$0xf] /*vst_source=*/%v94560 (stack75)
        %v94564 = vadd.s32 %v93639, %v1381 (stack39)
        %v94574 = vadd.s32 %v94564, %v415 (stack39)
        %vm94578 = vcmp.lt.u32.totalorder %v94574, %v94564 (stack42)
        %vm94583 = vcmp.lt.u32.totalorder %v94564, %v1381 (stack42)
        %v94588 = vadd.s32 %v93622, %v1368 (stack39)
        %v94592 = vadd.s32 1, %v94588 (stack39)
        %v94596 = vsel /*vm=*/%vm94583, /*on_true_vy=*/%v94592, /*on_false_vx=*/%v94588 (stack43)
        %v94600 = vadd.s32 1, %v94596 (stack39)
        %v94604 = vsel /*vm=*/%vm94578, /*on_true_vy=*/%v94600, /*on_false_vx=*/%v94596 (stack43)
        %v94609 = vadd.s32 %v94604, %v10 (stack39)
        %v94613 = vadd.s32 %v94574, %v9 (stack39)
        %v94617 = vadd.s32 %v94613, %v94609 (stack39)
        %v94619 = vshll.u32 %v94613, 13 (stack44)
        %v94620 = vshrl.u32 %v94613, 19 (stack45)
        %v94621 = vor.u32 %v94620, %v94619 (stack46)
        %v94622 = vxor.u32 %v94621, %v94617 (stack47)
        %v94625 = vadd.s32 %v94622, %v94617 (stack39)
        %v94627 = vshll.u32 %v94622, 15 (stack44)
        %v94628 = vshrl.u32 %v94622, 17 (stack45)
        %v94629 = vor.u32 %v94628, %v94627 (stack46)
        %v94630 = vxor.u32 %v94629, %v94625 (stack47)
        %v94633 = vadd.s32 %v94630, %v94625 (stack39)
        %v94635 = vshll.u32 %v94630, 26 (stack44)
        %v94636 = vshrl.u32 %v94630, 6 (stack45)
        %v94637 = vor.u32 %v94636, %v94635 (stack46)
        %v94638 = vxor.u32 %v94637, %v94633 (stack47)
        %v94641 = vadd.s32 %v94638, %v94633 (stack39)
        %v94645 = vadd.s32 %v94641, %v9 (stack39)
        %v94647 = vshll.u32 %v94638, 6 (stack44)
        %v94648 = vshrl.u32 %v94638, 26 (stack45)
        %v94649 = vor.u32 %v94648, %v94647 (stack46)
        %v94650 = vxor.u32 %v94649, %v94641 (stack47)
        %v94653 = vadd.s32 %v94650, %v8 (stack39)
        %v94657 = vadd.s32 1, %v94653 (stack39)
        %v94661 = vadd.s32 %v94657, %v94645 (stack39)
        %v94663 = vshll.u32 %v94657, 17 (stack44)
        %v94664 = vshrl.u32 %v94657, 15 (stack45)
        %v94665 = vor.u32 %v94664, %v94663 (stack46)
        %v94666 = vxor.u32 %v94665, %v94661 (stack47)
        %v94669 = vadd.s32 %v94666, %v94661 (stack39)
        %v94671 = vshll.u32 %v94666, 29 (stack44)
        %v94672 = vshrl.u32 %v94666, 3 (stack45)
        %v94673 = vor.u32 %v94672, %v94671 (stack46)
        %v94674 = vxor.u32 %v94673, %v94669 (stack47)
        %v94677 = vadd.s32 %v94674, %v94669 (stack39)
        %v94679 = vshll.u32 %v94674, 16 (stack44)
        %v94680 = vshrl.u32 %v94674, 16 (stack45)
        %v94681 = vor.u32 %v94680, %v94679 (stack46)
        %v94682 = vxor.u32 %v94681, %v94677 (stack47)
        %v94685 = vadd.s32 %v94682, %v94677 (stack39)
        %v94689 = vadd.s32 %v94685, %v8 (stack39)
        %v94691 = vshll.u32 %v94682, 24 (stack44)
        %v94692 = vshrl.u32 %v94682, 8 (stack45)
        %v94693 = vor.u32 %v94692, %v94691 (stack46)
        %v94694 = vxor.u32 %v94693, %v94685 (stack47)
        %v94697 = vadd.s32 %v94694, %v10 (stack39)
        %v94701 = vadd.s32 2, %v94697 (stack39)
        %v94705 = vadd.s32 %v94701, %v94689 (stack39)
        %v94707 = vshll.u32 %v94701, 13 (stack44)
        %v94708 = vshrl.u32 %v94701, 19 (stack45)
        %v94709 = vor.u32 %v94708, %v94707 (stack46)
        %v94710 = vxor.u32 %v94709, %v94705 (stack47)
        %v94713 = vadd.s32 %v94710, %v94705 (stack39)
        %v94715 = vshll.u32 %v94710, 15 (stack44)
        %v94716 = vshrl.u32 %v94710, 17 (stack45)
        %v94717 = vor.u32 %v94716, %v94715 (stack46)
        %v94718 = vxor.u32 %v94717, %v94713 (stack47)
        %v94721 = vadd.s32 %v94718, %v94713 (stack39)
        %v94723 = vshll.u32 %v94718, 26 (stack44)
        %v94724 = vshrl.u32 %v94718, 6 (stack45)
        %v94725 = vor.u32 %v94724, %v94723 (stack46)
        %v94726 = vxor.u32 %v94725, %v94721 (stack47)
        %v94729 = vadd.s32 %v94726, %v94721 (stack39)
        %v94733 = vadd.s32 %v94729, %v10 (stack39)
        %v94735 = vshll.u32 %v94726, 6 (stack44)
        %v94736 = vshrl.u32 %v94726, 26 (stack45)
        %v94737 = vor.u32 %v94736, %v94735 (stack46)
        %v94738 = vxor.u32 %v94737, %v94729 (stack47)
        %v94741 = vadd.s32 %v94738, %v9 (stack39)
        %v94745 = vadd.s32 3, %v94741 (stack39)
        %v94749 = vadd.s32 %v94745, %v94733 (stack39)
        %v94751 = vshll.u32 %v94745, 17 (stack44)
        %v94752 = vshrl.u32 %v94745, 15 (stack45)
        %v94753 = vor.u32 %v94752, %v94751 (stack46)
        %v94754 = vxor.u32 %v94753, %v94749 (stack47)
        %v94757 = vadd.s32 %v94754, %v94749 (stack39)
        %v94759 = vshll.u32 %v94754, 29 (stack44)
        %v94760 = vshrl.u32 %v94754, 3 (stack45)
        %v94761 = vor.u32 %v94760, %v94759 (stack46)
        %v94762 = vxor.u32 %v94761, %v94757 (stack47)
        %v94765 = vadd.s32 %v94762, %v94757 (stack39)
        %v94767 = vshll.u32 %v94762, 16 (stack44)
        %v94768 = vshrl.u32 %v94762, 16 (stack45)
        %v94769 = vor.u32 %v94768, %v94767 (stack46)
        %v94770 = vxor.u32 %v94769, %v94765 (stack47)
        %v94773 = vadd.s32 %v94770, %v94765 (stack39)
        %v94777 = vadd.s32 %v94773, %v9 (stack39)
        %v94779 = vshll.u32 %v94770, 24 (stack44)
        %v94780 = vshrl.u32 %v94770, 8 (stack45)
        %v94781 = vor.u32 %v94780, %v94779 (stack46)
        %v94782 = vxor.u32 %v94781, %v94773 (stack47)
        %v94785 = vadd.s32 %v94782, %v8 (stack39)
        %v94789 = vadd.s32 4, %v94785 (stack39)
        %v94793 = vadd.s32 %v94789, %v94777 (stack39)
        %v94795 = vshll.u32 %v94789, 13 (stack44)
        %v94796 = vshrl.u32 %v94789, 19 (stack45)
        %v94797 = vor.u32 %v94796, %v94795 (stack46)
        %v94798 = vxor.u32 %v94797, %v94793 (stack47)
        %v94801 = vadd.s32 %v94798, %v94793 (stack39)
        %v94803 = vshll.u32 %v94798, 15 (stack44)
        %v94804 = vshrl.u32 %v94798, 17 (stack45)
        %v94805 = vor.u32 %v94804, %v94803 (stack46)
        %v94806 = vxor.u32 %v94805, %v94801 (stack47)
        %v94809 = vadd.s32 %v94806, %v94801 (stack39)
        %v94811 = vshll.u32 %v94806, 26 (stack44)
        %v94812 = vshrl.u32 %v94806, 6 (stack45)
        %v94813 = vor.u32 %v94812, %v94811 (stack46)
        %v94814 = vxor.u32 %v94813, %v94809 (stack47)
        %v94817 = vadd.s32 %v94814, %v94809 (stack39)
        %v94821 = vadd.s32 %v94817, %v8 (stack39)
        %v94823 = vshll.u32 %v94814, 6 (stack44)
        %v94824 = vshrl.u32 %v94814, 26 (stack45)
        %v94825 = vor.u32 %v94824, %v94823 (stack46)
        %v94826 = vxor.u32 %v94825, %v94817 (stack47)
        %v94829 = vadd.s32 %v94826, %v10 (stack39)
        %v94833 = vadd.s32 5, %v94829 (stack39)
        %v94835 = vxor.u32 %v94833, %v94821 (stack47)
        %v94836 = vand.u32.u8 255, %v94835 (stack48)
        %v94837 = vand.u32 65535, %v94836 (stack49)
        %v94838 = vshrl.u32 %v94837, 1 (stack50)
        %v94839 = vor.u32 16256, %v94838 (stack46)
        %v94840 = vand.u32.u16 65535, %v94839 (stack51)
        %v120252 = vadd.low.f32.bf16 -1.0, %v94840 (stack52)
        %v94849 = vmul.f32 2.0, %v120252 (stack53)
        %v94853 = vadd.f32 -0.99609375, %v94849 (stack52)
        %v94857 = vmax.f32 %v94853, -0.99609375 (stack54)
        %v94859 = vand.u32 2147483647, %v94857 (stack55)
        %vm94862 = vcmp.eq.f32.partialorder %v94859, 1.0 (stack56)
        %v94867 = vmul.f32 inf, %v94857 (stack53)
        %v94869 = vxor.u32 2147483648, %v94857 (stack57)
        %v94872 = vmul.f32 %v94869, %v94857 (stack53)
        %v94874 = vadd.f32 1.0, %v94872 (stack58)
        %v94875 = vlog2.pop %v94874 (stack59)
        %v94876 = vmul.f32 0.6931472, %v94875 (stack60)
        %v94877 = vmul.f32 -0.5, %v94872 (stack61)
        %v94878 = vadd.f32 1.0, %v94877 (stack62)
        %v94879 = vmul.f32 %v94878, %v94872 (stack63)
        %v94880 = vand.u32 2147483647, %v94872 (stack64)
        %vm94881 = vcmp.lt.f32.partialorder %v94880, 0.0004427343 (stack65)
        %v94882 = vsel /*vm=*/%vm94881, /*on_true_vy=*/%v94879, /*on_false_vx=*/%v94876 (stack66)
        %v94883 = vxor.u32 2147483648, %v94882 (stack57)
        %vm94886 = vcmp.lt.f32.partialorder %v94883, 5.0 (stack56)
        %v94891 = vsel /*vm=*/%vm94886, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v94895 = vsel /*vm=*/%vm94886, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v94899 = vsel /*vm=*/%vm94886, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v94903 = vsel /*vm=*/%vm94886, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v94907 = vsel /*vm=*/%vm94886, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v94911 = vsel /*vm=*/%vm94886, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v94915 = vsel /*vm=*/%vm94886, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v94919 = vsel /*vm=*/%vm94886, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v94923 = vsel /*vm=*/%vm94886, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v94927 = vadd.f32 -2.5, %v94883 (stack52)
        %v94929 = vrsqrt.pop %v94883 (stack67)
        %v94930 = vmul.f32 %v94929, %v94883 (stack68)
        %vm94931 = vcmp.eq.f32.partialorder %v94883, inf (stack69)
        %v94932 = vsel /*vm=*/%vm94931, /*on_true_vy=*/%v94883, /*on_false_vx=*/%v94930 (stack70)
        %vm94933 = vcmp.eq.f32.partialorder %v94883, 0.0 (stack71)
        %v94934 = vand.u32 2147483648, %v94883 (stack72)
        %v94935 = vsel /*vm=*/%vm94933, /*on_true_vy=*/%v94934, /*on_false_vx=*/%v94932 (stack73)
        %v94938 = vadd.f32 -3.0, %v94935 (stack52)
        %v94942 = vsel /*vm=*/%vm94886, /*on_true_vy=*/%v94927, /*on_false_vx=*/%v94938 (stack43)
        %v94946 = vmul.f32 %v94942, %v94923 (stack53)
        %v94950 = vadd.f32 %v94946, %v94919 (stack52)
        %v94954 = vmul.f32 %v94950, %v94942 (stack53)
        %v94958 = vadd.f32 %v94954, %v94915 (stack52)
        %v94962 = vmul.f32 %v94958, %v94942 (stack53)
        %v94966 = vadd.f32 %v94962, %v94911 (stack52)
        %v94970 = vmul.f32 %v94966, %v94942 (stack53)
        %v94974 = vadd.f32 %v94970, %v94907 (stack52)
        %v94978 = vmul.f32 %v94974, %v94942 (stack53)
        %v94982 = vadd.f32 %v94978, %v94903 (stack52)
        %v94986 = vmul.f32 %v94982, %v94942 (stack53)
        %v94990 = vadd.f32 %v94986, %v94899 (stack52)
        %v94994 = vmul.f32 %v94990, %v94942 (stack53)
        %v94998 = vadd.f32 %v94994, %v94895 (stack52)
        %v95002 = vmul.f32 %v94998, %v94942 (stack53)
        %v95006 = vadd.f32 %v95002, %v94891 (stack52)
        %v95010 = vmul.f32 %v95006, %v94857 (stack53)
        %v95014 = vsel /*vm=*/%vm94862, /*on_true_vy=*/%v94867, /*on_false_vx=*/%v95010 (stack43)
        %v95018 = vmul.f32 1.4140625, %v95014 (stack53)
        %v95021 = vpack.c.bf16 0.0, %v95018 (stack74)
        %120253 = vst [vmem:[%s280 + $0x164] sm:$0xf] /*vst_source=*/%v95021 (stack75)
        %v95025 = vadd.s32 %v93639, %v1868 (stack39)
        %v95035 = vadd.s32 %v95025, %v415 (stack39)
        %vm95039 = vcmp.lt.u32.totalorder %v95035, %v95025 (stack42)
        %vm95044 = vcmp.lt.u32.totalorder %v95025, %v1868 (stack42)
        %v95049 = vadd.s32 %v93622, %v1855 (stack39)
        %v95053 = vadd.s32 1, %v95049 (stack39)
        %v95057 = vsel /*vm=*/%vm95044, /*on_true_vy=*/%v95053, /*on_false_vx=*/%v95049 (stack43)
        %v95061 = vadd.s32 1, %v95057 (stack39)
        %v95065 = vsel /*vm=*/%vm95039, /*on_true_vy=*/%v95061, /*on_false_vx=*/%v95057 (stack43)
        %v95070 = vadd.s32 %v95065, %v10 (stack39)
        %v95074 = vadd.s32 %v95035, %v9 (stack39)
        %v95078 = vadd.s32 %v95074, %v95070 (stack39)
        %v95080 = vshll.u32 %v95074, 13 (stack44)
        %v95081 = vshrl.u32 %v95074, 19 (stack45)
        %v95082 = vor.u32 %v95081, %v95080 (stack46)
        %v95083 = vxor.u32 %v95082, %v95078 (stack47)
        %v95086 = vadd.s32 %v95083, %v95078 (stack39)
        %v95088 = vshll.u32 %v95083, 15 (stack44)
        %v95089 = vshrl.u32 %v95083, 17 (stack45)
        %v95090 = vor.u32 %v95089, %v95088 (stack46)
        %v95091 = vxor.u32 %v95090, %v95086 (stack47)
        %v95094 = vadd.s32 %v95091, %v95086 (stack39)
        %v95096 = vshll.u32 %v95091, 26 (stack44)
        %v95097 = vshrl.u32 %v95091, 6 (stack45)
        %v95098 = vor.u32 %v95097, %v95096 (stack46)
        %v95099 = vxor.u32 %v95098, %v95094 (stack47)
        %v95102 = vadd.s32 %v95099, %v95094 (stack39)
        %v95106 = vadd.s32 %v95102, %v9 (stack39)
        %v95108 = vshll.u32 %v95099, 6 (stack44)
        %v95109 = vshrl.u32 %v95099, 26 (stack45)
        %v95110 = vor.u32 %v95109, %v95108 (stack46)
        %v95111 = vxor.u32 %v95110, %v95102 (stack47)
        %v95114 = vadd.s32 %v95111, %v8 (stack39)
        %v95118 = vadd.s32 1, %v95114 (stack39)
        %v95122 = vadd.s32 %v95118, %v95106 (stack39)
        %v95124 = vshll.u32 %v95118, 17 (stack44)
        %v95125 = vshrl.u32 %v95118, 15 (stack45)
        %v95126 = vor.u32 %v95125, %v95124 (stack46)
        %v95127 = vxor.u32 %v95126, %v95122 (stack47)
        %v95130 = vadd.s32 %v95127, %v95122 (stack39)
        %v95132 = vshll.u32 %v95127, 29 (stack44)
        %v95133 = vshrl.u32 %v95127, 3 (stack45)
        %v95134 = vor.u32 %v95133, %v95132 (stack46)
        %v95135 = vxor.u32 %v95134, %v95130 (stack47)
        %v95138 = vadd.s32 %v95135, %v95130 (stack39)
        %v95140 = vshll.u32 %v95135, 16 (stack44)
        %v95141 = vshrl.u32 %v95135, 16 (stack45)
        %v95142 = vor.u32 %v95141, %v95140 (stack46)
        %v95143 = vxor.u32 %v95142, %v95138 (stack47)
        %v95146 = vadd.s32 %v95143, %v95138 (stack39)
        %v95150 = vadd.s32 %v95146, %v8 (stack39)
        %v95152 = vshll.u32 %v95143, 24 (stack44)
        %v95153 = vshrl.u32 %v95143, 8 (stack45)
        %v95154 = vor.u32 %v95153, %v95152 (stack46)
        %v95155 = vxor.u32 %v95154, %v95146 (stack47)
        %v95158 = vadd.s32 %v95155, %v10 (stack39)
        %v95162 = vadd.s32 2, %v95158 (stack39)
        %v95166 = vadd.s32 %v95162, %v95150 (stack39)
        %v95168 = vshll.u32 %v95162, 13 (stack44)
        %v95169 = vshrl.u32 %v95162, 19 (stack45)
        %v95170 = vor.u32 %v95169, %v95168 (stack46)
        %v95171 = vxor.u32 %v95170, %v95166 (stack47)
        %v95174 = vadd.s32 %v95171, %v95166 (stack39)
        %v95176 = vshll.u32 %v95171, 15 (stack44)
        %v95177 = vshrl.u32 %v95171, 17 (stack45)
        %v95178 = vor.u32 %v95177, %v95176 (stack46)
        %v95179 = vxor.u32 %v95178, %v95174 (stack47)
        %v95182 = vadd.s32 %v95179, %v95174 (stack39)
        %v95184 = vshll.u32 %v95179, 26 (stack44)
        %v95185 = vshrl.u32 %v95179, 6 (stack45)
        %v95186 = vor.u32 %v95185, %v95184 (stack46)
        %v95187 = vxor.u32 %v95186, %v95182 (stack47)
        %v95190 = vadd.s32 %v95187, %v95182 (stack39)
        %v95194 = vadd.s32 %v95190, %v10 (stack39)
        %v95196 = vshll.u32 %v95187, 6 (stack44)
        %v95197 = vshrl.u32 %v95187, 26 (stack45)
        %v95198 = vor.u32 %v95197, %v95196 (stack46)
        %v95199 = vxor.u32 %v95198, %v95190 (stack47)
        %v95202 = vadd.s32 %v95199, %v9 (stack39)
        %v95206 = vadd.s32 3, %v95202 (stack39)
        %v95210 = vadd.s32 %v95206, %v95194 (stack39)
        %v95212 = vshll.u32 %v95206, 17 (stack44)
        %v95213 = vshrl.u32 %v95206, 15 (stack45)
        %v95214 = vor.u32 %v95213, %v95212 (stack46)
        %v95215 = vxor.u32 %v95214, %v95210 (stack47)
        %v95218 = vadd.s32 %v95215, %v95210 (stack39)
        %v95220 = vshll.u32 %v95215, 29 (stack44)
        %v95221 = vshrl.u32 %v95215, 3 (stack45)
        %v95222 = vor.u32 %v95221, %v95220 (stack46)
        %v95223 = vxor.u32 %v95222, %v95218 (stack47)
        %v95226 = vadd.s32 %v95223, %v95218 (stack39)
        %v95228 = vshll.u32 %v95223, 16 (stack44)
        %v95229 = vshrl.u32 %v95223, 16 (stack45)
        %v95230 = vor.u32 %v95229, %v95228 (stack46)
        %v95231 = vxor.u32 %v95230, %v95226 (stack47)
        %v95234 = vadd.s32 %v95231, %v95226 (stack39)
        %v95238 = vadd.s32 %v95234, %v9 (stack39)
        %v95240 = vshll.u32 %v95231, 24 (stack44)
        %v95241 = vshrl.u32 %v95231, 8 (stack45)
        %v95242 = vor.u32 %v95241, %v95240 (stack46)
        %v95243 = vxor.u32 %v95242, %v95234 (stack47)
        %v95246 = vadd.s32 %v95243, %v8 (stack39)
        %v95250 = vadd.s32 4, %v95246 (stack39)
        %v95254 = vadd.s32 %v95250, %v95238 (stack39)
        %v95256 = vshll.u32 %v95250, 13 (stack44)
        %v95257 = vshrl.u32 %v95250, 19 (stack45)
        %v95258 = vor.u32 %v95257, %v95256 (stack46)
        %v95259 = vxor.u32 %v95258, %v95254 (stack47)
        %v95262 = vadd.s32 %v95259, %v95254 (stack39)
        %v95264 = vshll.u32 %v95259, 15 (stack44)
        %v95265 = vshrl.u32 %v95259, 17 (stack45)
        %v95266 = vor.u32 %v95265, %v95264 (stack46)
        %v95267 = vxor.u32 %v95266, %v95262 (stack47)
        %v95270 = vadd.s32 %v95267, %v95262 (stack39)
        %v95272 = vshll.u32 %v95267, 26 (stack44)
        %v95273 = vshrl.u32 %v95267, 6 (stack45)
        %v95274 = vor.u32 %v95273, %v95272 (stack46)
        %v95275 = vxor.u32 %v95274, %v95270 (stack47)
        %v95278 = vadd.s32 %v95275, %v95270 (stack39)
        %v95282 = vadd.s32 %v95278, %v8 (stack39)
        %v95284 = vshll.u32 %v95275, 6 (stack44)
        %v95285 = vshrl.u32 %v95275, 26 (stack45)
        %v95286 = vor.u32 %v95285, %v95284 (stack46)
        %v95287 = vxor.u32 %v95286, %v95278 (stack47)
        %v95290 = vadd.s32 %v95287, %v10 (stack39)
        %v95294 = vadd.s32 5, %v95290 (stack39)
        %v95296 = vxor.u32 %v95294, %v95282 (stack47)
        %v95297 = vand.u32.u8 255, %v95296 (stack48)
        %v95298 = vand.u32 65535, %v95297 (stack49)
        %v95299 = vshrl.u32 %v95298, 1 (stack50)
        %v95300 = vor.u32 16256, %v95299 (stack46)
        %v95301 = vand.u32.u16 65535, %v95300 (stack51)
        %v120254 = vadd.low.f32.bf16 -1.0, %v95301 (stack52)
        %v95310 = vmul.f32 2.0, %v120254 (stack53)
        %v95314 = vadd.f32 -0.99609375, %v95310 (stack52)
        %v95318 = vmax.f32 %v95314, -0.99609375 (stack54)
        %v95320 = vand.u32 2147483647, %v95318 (stack55)
        %vm95323 = vcmp.eq.f32.partialorder %v95320, 1.0 (stack56)
        %v95328 = vmul.f32 inf, %v95318 (stack53)
        %v95330 = vxor.u32 2147483648, %v95318 (stack57)
        %v95333 = vmul.f32 %v95330, %v95318 (stack53)
        %v95335 = vadd.f32 1.0, %v95333 (stack58)
        %v95336 = vlog2.pop %v95335 (stack59)
        %v95337 = vmul.f32 0.6931472, %v95336 (stack60)
        %v95338 = vmul.f32 -0.5, %v95333 (stack61)
        %v95339 = vadd.f32 1.0, %v95338 (stack62)
        %v95340 = vmul.f32 %v95339, %v95333 (stack63)
        %v95341 = vand.u32 2147483647, %v95333 (stack64)
        %vm95342 = vcmp.lt.f32.partialorder %v95341, 0.0004427343 (stack65)
        %v95343 = vsel /*vm=*/%vm95342, /*on_true_vy=*/%v95340, /*on_false_vx=*/%v95337 (stack66)
        %v95344 = vxor.u32 2147483648, %v95343 (stack57)
        %vm95347 = vcmp.lt.f32.partialorder %v95344, 5.0 (stack56)
        %v95352 = vsel /*vm=*/%vm95347, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v95356 = vsel /*vm=*/%vm95347, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v95360 = vsel /*vm=*/%vm95347, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v95364 = vsel /*vm=*/%vm95347, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v95368 = vsel /*vm=*/%vm95347, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v95372 = vsel /*vm=*/%vm95347, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v95376 = vsel /*vm=*/%vm95347, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v95380 = vsel /*vm=*/%vm95347, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v95384 = vsel /*vm=*/%vm95347, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v95388 = vadd.f32 -2.5, %v95344 (stack52)
        %v95390 = vrsqrt.pop %v95344 (stack67)
        %v95391 = vmul.f32 %v95390, %v95344 (stack68)
        %vm95392 = vcmp.eq.f32.partialorder %v95344, inf (stack69)
        %v95393 = vsel /*vm=*/%vm95392, /*on_true_vy=*/%v95344, /*on_false_vx=*/%v95391 (stack70)
        %vm95394 = vcmp.eq.f32.partialorder %v95344, 0.0 (stack71)
        %v95395 = vand.u32 2147483648, %v95344 (stack72)
        %v95396 = vsel /*vm=*/%vm95394, /*on_true_vy=*/%v95395, /*on_false_vx=*/%v95393 (stack73)
        %v95399 = vadd.f32 -3.0, %v95396 (stack52)
        %v95403 = vsel /*vm=*/%vm95347, /*on_true_vy=*/%v95388, /*on_false_vx=*/%v95399 (stack43)
        %v95407 = vmul.f32 %v95403, %v95384 (stack53)
        %v95411 = vadd.f32 %v95407, %v95380 (stack52)
        %v95415 = vmul.f32 %v95411, %v95403 (stack53)
        %v95419 = vadd.f32 %v95415, %v95376 (stack52)
        %v95423 = vmul.f32 %v95419, %v95403 (stack53)
        %v95427 = vadd.f32 %v95423, %v95372 (stack52)
        %v95431 = vmul.f32 %v95427, %v95403 (stack53)
        %v95435 = vadd.f32 %v95431, %v95368 (stack52)
        %v95439 = vmul.f32 %v95435, %v95403 (stack53)
        %v95443 = vadd.f32 %v95439, %v95364 (stack52)
        %v95447 = vmul.f32 %v95443, %v95403 (stack53)
        %v95451 = vadd.f32 %v95447, %v95360 (stack52)
        %v95455 = vmul.f32 %v95451, %v95403 (stack53)
        %v95459 = vadd.f32 %v95455, %v95356 (stack52)
        %v95463 = vmul.f32 %v95459, %v95403 (stack53)
        %v95467 = vadd.f32 %v95463, %v95352 (stack52)
        %v95471 = vmul.f32 %v95467, %v95318 (stack53)
        %v95475 = vsel /*vm=*/%vm95323, /*on_true_vy=*/%v95328, /*on_false_vx=*/%v95471 (stack43)
        %v95479 = vmul.f32 1.4140625, %v95475 (stack53)
        %v95482 = vpack.c.bf16 0.0, %v95479 (stack74)
        %120255 = vst [vmem:[%s280 + $0x1e4] sm:$0xf] /*vst_source=*/%v95482 (stack75)
        %v95486 = vadd.s32 %v93639, %v2355 (stack39)
        %v95496 = vadd.s32 %v95486, %v415 (stack39)
        %vm95500 = vcmp.lt.u32.totalorder %v95496, %v95486 (stack42)
        %vm95505 = vcmp.lt.u32.totalorder %v95486, %v2355 (stack42)
        %v95510 = vadd.s32 %v93622, %v2342 (stack39)
        %v95514 = vadd.s32 1, %v95510 (stack39)
        %v95518 = vsel /*vm=*/%vm95505, /*on_true_vy=*/%v95514, /*on_false_vx=*/%v95510 (stack43)
        %v95522 = vadd.s32 1, %v95518 (stack39)
        %v95526 = vsel /*vm=*/%vm95500, /*on_true_vy=*/%v95522, /*on_false_vx=*/%v95518 (stack43)
        %v95531 = vadd.s32 %v95526, %v10 (stack39)
        %v95535 = vadd.s32 %v95496, %v9 (stack39)
        %v95539 = vadd.s32 %v95535, %v95531 (stack39)
        %v95541 = vshll.u32 %v95535, 13 (stack44)
        %v95542 = vshrl.u32 %v95535, 19 (stack45)
        %v95543 = vor.u32 %v95542, %v95541 (stack46)
        %v95544 = vxor.u32 %v95543, %v95539 (stack47)
        %v95547 = vadd.s32 %v95544, %v95539 (stack39)
        %v95549 = vshll.u32 %v95544, 15 (stack44)
        %v95550 = vshrl.u32 %v95544, 17 (stack45)
        %v95551 = vor.u32 %v95550, %v95549 (stack46)
        %v95552 = vxor.u32 %v95551, %v95547 (stack47)
        %v95555 = vadd.s32 %v95552, %v95547 (stack39)
        %v95557 = vshll.u32 %v95552, 26 (stack44)
        %v95558 = vshrl.u32 %v95552, 6 (stack45)
        %v95559 = vor.u32 %v95558, %v95557 (stack46)
        %v95560 = vxor.u32 %v95559, %v95555 (stack47)
        %v95563 = vadd.s32 %v95560, %v95555 (stack39)
        %v95567 = vadd.s32 %v95563, %v9 (stack39)
        %v95569 = vshll.u32 %v95560, 6 (stack44)
        %v95570 = vshrl.u32 %v95560, 26 (stack45)
        %v95571 = vor.u32 %v95570, %v95569 (stack46)
        %v95572 = vxor.u32 %v95571, %v95563 (stack47)
        %v95575 = vadd.s32 %v95572, %v8 (stack39)
        %v95579 = vadd.s32 1, %v95575 (stack39)
        %v95583 = vadd.s32 %v95579, %v95567 (stack39)
        %v95585 = vshll.u32 %v95579, 17 (stack44)
        %v95586 = vshrl.u32 %v95579, 15 (stack45)
        %v95587 = vor.u32 %v95586, %v95585 (stack46)
        %v95588 = vxor.u32 %v95587, %v95583 (stack47)
        %v95591 = vadd.s32 %v95588, %v95583 (stack39)
        %v95593 = vshll.u32 %v95588, 29 (stack44)
        %v95594 = vshrl.u32 %v95588, 3 (stack45)
        %v95595 = vor.u32 %v95594, %v95593 (stack46)
        %v95596 = vxor.u32 %v95595, %v95591 (stack47)
        %v95599 = vadd.s32 %v95596, %v95591 (stack39)
        %v95601 = vshll.u32 %v95596, 16 (stack44)
        %v95602 = vshrl.u32 %v95596, 16 (stack45)
        %v95603 = vor.u32 %v95602, %v95601 (stack46)
        %v95604 = vxor.u32 %v95603, %v95599 (stack47)
        %v95607 = vadd.s32 %v95604, %v95599 (stack39)
        %v95611 = vadd.s32 %v95607, %v8 (stack39)
        %v95613 = vshll.u32 %v95604, 24 (stack44)
        %v95614 = vshrl.u32 %v95604, 8 (stack45)
        %v95615 = vor.u32 %v95614, %v95613 (stack46)
        %v95616 = vxor.u32 %v95615, %v95607 (stack47)
        %v95619 = vadd.s32 %v95616, %v10 (stack39)
        %v95623 = vadd.s32 2, %v95619 (stack39)
        %v95627 = vadd.s32 %v95623, %v95611 (stack39)
        %v95629 = vshll.u32 %v95623, 13 (stack44)
        %v95630 = vshrl.u32 %v95623, 19 (stack45)
        %v95631 = vor.u32 %v95630, %v95629 (stack46)
        %v95632 = vxor.u32 %v95631, %v95627 (stack47)
        %v95635 = vadd.s32 %v95632, %v95627 (stack39)
        %v95637 = vshll.u32 %v95632, 15 (stack44)
        %v95638 = vshrl.u32 %v95632, 17 (stack45)
        %v95639 = vor.u32 %v95638, %v95637 (stack46)
        %v95640 = vxor.u32 %v95639, %v95635 (stack47)
        %v95643 = vadd.s32 %v95640, %v95635 (stack39)
        %v95645 = vshll.u32 %v95640, 26 (stack44)
        %v95646 = vshrl.u32 %v95640, 6 (stack45)
        %v95647 = vor.u32 %v95646, %v95645 (stack46)
        %v95648 = vxor.u32 %v95647, %v95643 (stack47)
        %v95651 = vadd.s32 %v95648, %v95643 (stack39)
        %v95655 = vadd.s32 %v95651, %v10 (stack39)
        %v95657 = vshll.u32 %v95648, 6 (stack44)
        %v95658 = vshrl.u32 %v95648, 26 (stack45)
        %v95659 = vor.u32 %v95658, %v95657 (stack46)
        %v95660 = vxor.u32 %v95659, %v95651 (stack47)
        %v95663 = vadd.s32 %v95660, %v9 (stack39)
        %v95667 = vadd.s32 3, %v95663 (stack39)
        %v95671 = vadd.s32 %v95667, %v95655 (stack39)
        %v95673 = vshll.u32 %v95667, 17 (stack44)
        %v95674 = vshrl.u32 %v95667, 15 (stack45)
        %v95675 = vor.u32 %v95674, %v95673 (stack46)
        %v95676 = vxor.u32 %v95675, %v95671 (stack47)
        %v95679 = vadd.s32 %v95676, %v95671 (stack39)
        %v95681 = vshll.u32 %v95676, 29 (stack44)
        %v95682 = vshrl.u32 %v95676, 3 (stack45)
        %v95683 = vor.u32 %v95682, %v95681 (stack46)
        %v95684 = vxor.u32 %v95683, %v95679 (stack47)
        %v95687 = vadd.s32 %v95684, %v95679 (stack39)
        %v95689 = vshll.u32 %v95684, 16 (stack44)
        %v95690 = vshrl.u32 %v95684, 16 (stack45)
        %v95691 = vor.u32 %v95690, %v95689 (stack46)
        %v95692 = vxor.u32 %v95691, %v95687 (stack47)
        %v95695 = vadd.s32 %v95692, %v95687 (stack39)
        %v95699 = vadd.s32 %v95695, %v9 (stack39)
        %v95701 = vshll.u32 %v95692, 24 (stack44)
        %v95702 = vshrl.u32 %v95692, 8 (stack45)
        %v95703 = vor.u32 %v95702, %v95701 (stack46)
        %v95704 = vxor.u32 %v95703, %v95695 (stack47)
        %v95707 = vadd.s32 %v95704, %v8 (stack39)
        %v95711 = vadd.s32 4, %v95707 (stack39)
        %v95715 = vadd.s32 %v95711, %v95699 (stack39)
        %v95717 = vshll.u32 %v95711, 13 (stack44)
        %v95718 = vshrl.u32 %v95711, 19 (stack45)
        %v95719 = vor.u32 %v95718, %v95717 (stack46)
        %v95720 = vxor.u32 %v95719, %v95715 (stack47)
        %v95723 = vadd.s32 %v95720, %v95715 (stack39)
        %v95725 = vshll.u32 %v95720, 15 (stack44)
        %v95726 = vshrl.u32 %v95720, 17 (stack45)
        %v95727 = vor.u32 %v95726, %v95725 (stack46)
        %v95728 = vxor.u32 %v95727, %v95723 (stack47)
        %v95731 = vadd.s32 %v95728, %v95723 (stack39)
        %v95733 = vshll.u32 %v95728, 26 (stack44)
        %v95734 = vshrl.u32 %v95728, 6 (stack45)
        %v95735 = vor.u32 %v95734, %v95733 (stack46)
        %v95736 = vxor.u32 %v95735, %v95731 (stack47)
        %v95739 = vadd.s32 %v95736, %v95731 (stack39)
        %v95743 = vadd.s32 %v95739, %v8 (stack39)
        %v95745 = vshll.u32 %v95736, 6 (stack44)
        %v95746 = vshrl.u32 %v95736, 26 (stack45)
        %v95747 = vor.u32 %v95746, %v95745 (stack46)
        %v95748 = vxor.u32 %v95747, %v95739 (stack47)
        %v95751 = vadd.s32 %v95748, %v10 (stack39)
        %v95755 = vadd.s32 5, %v95751 (stack39)
        %v95757 = vxor.u32 %v95755, %v95743 (stack47)
        %v95758 = vand.u32.u8 255, %v95757 (stack48)
        %v95759 = vand.u32 65535, %v95758 (stack49)
        %v95760 = vshrl.u32 %v95759, 1 (stack50)
        %v95761 = vor.u32 16256, %v95760 (stack46)
        %v95762 = vand.u32.u16 65535, %v95761 (stack51)
        %v120256 = vadd.low.f32.bf16 -1.0, %v95762 (stack52)
        %v95771 = vmul.f32 2.0, %v120256 (stack53)
        %v95775 = vadd.f32 -0.99609375, %v95771 (stack52)
        %v95779 = vmax.f32 %v95775, -0.99609375 (stack54)
        %v95781 = vand.u32 2147483647, %v95779 (stack55)
        %vm95784 = vcmp.eq.f32.partialorder %v95781, 1.0 (stack56)
        %v95789 = vmul.f32 inf, %v95779 (stack53)
        %v95791 = vxor.u32 2147483648, %v95779 (stack57)
        %v95794 = vmul.f32 %v95791, %v95779 (stack53)
        %v95796 = vadd.f32 1.0, %v95794 (stack58)
        %v95797 = vlog2.pop %v95796 (stack59)
        %v95798 = vmul.f32 0.6931472, %v95797 (stack60)
        %v95799 = vmul.f32 -0.5, %v95794 (stack61)
        %v95800 = vadd.f32 1.0, %v95799 (stack62)
        %v95801 = vmul.f32 %v95800, %v95794 (stack63)
        %v95802 = vand.u32 2147483647, %v95794 (stack64)
        %vm95803 = vcmp.lt.f32.partialorder %v95802, 0.0004427343 (stack65)
        %v95804 = vsel /*vm=*/%vm95803, /*on_true_vy=*/%v95801, /*on_false_vx=*/%v95798 (stack66)
        %v95805 = vxor.u32 2147483648, %v95804 (stack57)
        %vm95808 = vcmp.lt.f32.partialorder %v95805, 5.0 (stack56)
        %v95813 = vsel /*vm=*/%vm95808, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v95817 = vsel /*vm=*/%vm95808, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v95821 = vsel /*vm=*/%vm95808, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v95825 = vsel /*vm=*/%vm95808, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v95829 = vsel /*vm=*/%vm95808, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v95833 = vsel /*vm=*/%vm95808, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v95837 = vsel /*vm=*/%vm95808, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v95841 = vsel /*vm=*/%vm95808, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v95845 = vsel /*vm=*/%vm95808, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v95849 = vadd.f32 -2.5, %v95805 (stack52)
        %v95851 = vrsqrt.pop %v95805 (stack67)
        %v95852 = vmul.f32 %v95851, %v95805 (stack68)
        %vm95853 = vcmp.eq.f32.partialorder %v95805, inf (stack69)
        %v95854 = vsel /*vm=*/%vm95853, /*on_true_vy=*/%v95805, /*on_false_vx=*/%v95852 (stack70)
        %vm95855 = vcmp.eq.f32.partialorder %v95805, 0.0 (stack71)
        %v95856 = vand.u32 2147483648, %v95805 (stack72)
        %v95857 = vsel /*vm=*/%vm95855, /*on_true_vy=*/%v95856, /*on_false_vx=*/%v95854 (stack73)
        %v95860 = vadd.f32 -3.0, %v95857 (stack52)
        %v95864 = vsel /*vm=*/%vm95808, /*on_true_vy=*/%v95849, /*on_false_vx=*/%v95860 (stack43)
        %v95868 = vmul.f32 %v95864, %v95845 (stack53)
        %v95872 = vadd.f32 %v95868, %v95841 (stack52)
        %v95876 = vmul.f32 %v95872, %v95864 (stack53)
        %v95880 = vadd.f32 %v95876, %v95837 (stack52)
        %v95884 = vmul.f32 %v95880, %v95864 (stack53)
        %v95888 = vadd.f32 %v95884, %v95833 (stack52)
        %v95892 = vmul.f32 %v95888, %v95864 (stack53)
        %v95896 = vadd.f32 %v95892, %v95829 (stack52)
        %v95900 = vmul.f32 %v95896, %v95864 (stack53)
        %v95904 = vadd.f32 %v95900, %v95825 (stack52)
        %v95908 = vmul.f32 %v95904, %v95864 (stack53)
        %v95912 = vadd.f32 %v95908, %v95821 (stack52)
        %v95916 = vmul.f32 %v95912, %v95864 (stack53)
        %v95920 = vadd.f32 %v95916, %v95817 (stack52)
        %v95924 = vmul.f32 %v95920, %v95864 (stack53)
        %v95928 = vadd.f32 %v95924, %v95813 (stack52)
        %v95932 = vmul.f32 %v95928, %v95779 (stack53)
        %v95936 = vsel /*vm=*/%vm95784, /*on_true_vy=*/%v95789, /*on_false_vx=*/%v95932 (stack43)
        %v95940 = vmul.f32 1.4140625, %v95936 (stack53)
        %v95943 = vpack.c.bf16 0.0, %v95940 (stack74)
        %120257 = vst [vmem:[%s280 + $0x264] sm:$0xf] /*vst_source=*/%v95943 (stack75)
        %v95947 = vadd.s32 %v93639, %v2842 (stack39)
        %v95957 = vadd.s32 %v95947, %v415 (stack39)
        %vm95961 = vcmp.lt.u32.totalorder %v95957, %v95947 (stack42)
        %vm95966 = vcmp.lt.u32.totalorder %v95947, %v2842 (stack42)
        %v95971 = vadd.s32 %v93622, %v2829 (stack39)
        %v95975 = vadd.s32 1, %v95971 (stack39)
        %v95979 = vsel /*vm=*/%vm95966, /*on_true_vy=*/%v95975, /*on_false_vx=*/%v95971 (stack43)
        %v95983 = vadd.s32 1, %v95979 (stack39)
        %v95987 = vsel /*vm=*/%vm95961, /*on_true_vy=*/%v95983, /*on_false_vx=*/%v95979 (stack43)
        %v95992 = vadd.s32 %v95987, %v10 (stack39)
        %v95996 = vadd.s32 %v95957, %v9 (stack39)
        %v96000 = vadd.s32 %v95996, %v95992 (stack39)
        %v96002 = vshll.u32 %v95996, 13 (stack44)
        %v96003 = vshrl.u32 %v95996, 19 (stack45)
        %v96004 = vor.u32 %v96003, %v96002 (stack46)
        %v96005 = vxor.u32 %v96004, %v96000 (stack47)
        %v96008 = vadd.s32 %v96005, %v96000 (stack39)
        %v96010 = vshll.u32 %v96005, 15 (stack44)
        %v96011 = vshrl.u32 %v96005, 17 (stack45)
        %v96012 = vor.u32 %v96011, %v96010 (stack46)
        %v96013 = vxor.u32 %v96012, %v96008 (stack47)
        %v96016 = vadd.s32 %v96013, %v96008 (stack39)
        %v96018 = vshll.u32 %v96013, 26 (stack44)
        %v96019 = vshrl.u32 %v96013, 6 (stack45)
        %v96020 = vor.u32 %v96019, %v96018 (stack46)
        %v96021 = vxor.u32 %v96020, %v96016 (stack47)
        %v96024 = vadd.s32 %v96021, %v96016 (stack39)
        %v96028 = vadd.s32 %v96024, %v9 (stack39)
        %v96030 = vshll.u32 %v96021, 6 (stack44)
        %v96031 = vshrl.u32 %v96021, 26 (stack45)
        %v96032 = vor.u32 %v96031, %v96030 (stack46)
        %v96033 = vxor.u32 %v96032, %v96024 (stack47)
        %v96036 = vadd.s32 %v96033, %v8 (stack39)
        %v96040 = vadd.s32 1, %v96036 (stack39)
        %v96044 = vadd.s32 %v96040, %v96028 (stack39)
        %v96046 = vshll.u32 %v96040, 17 (stack44)
        %v96047 = vshrl.u32 %v96040, 15 (stack45)
        %v96048 = vor.u32 %v96047, %v96046 (stack46)
        %v96049 = vxor.u32 %v96048, %v96044 (stack47)
        %v96052 = vadd.s32 %v96049, %v96044 (stack39)
        %v96054 = vshll.u32 %v96049, 29 (stack44)
        %v96055 = vshrl.u32 %v96049, 3 (stack45)
        %v96056 = vor.u32 %v96055, %v96054 (stack46)
        %v96057 = vxor.u32 %v96056, %v96052 (stack47)
        %v96060 = vadd.s32 %v96057, %v96052 (stack39)
        %v96062 = vshll.u32 %v96057, 16 (stack44)
        %v96063 = vshrl.u32 %v96057, 16 (stack45)
        %v96064 = vor.u32 %v96063, %v96062 (stack46)
        %v96065 = vxor.u32 %v96064, %v96060 (stack47)
        %v96068 = vadd.s32 %v96065, %v96060 (stack39)
        %v96072 = vadd.s32 %v96068, %v8 (stack39)
        %v96074 = vshll.u32 %v96065, 24 (stack44)
        %v96075 = vshrl.u32 %v96065, 8 (stack45)
        %v96076 = vor.u32 %v96075, %v96074 (stack46)
        %v96077 = vxor.u32 %v96076, %v96068 (stack47)
        %v96080 = vadd.s32 %v96077, %v10 (stack39)
        %v96084 = vadd.s32 2, %v96080 (stack39)
        %v96088 = vadd.s32 %v96084, %v96072 (stack39)
        %v96090 = vshll.u32 %v96084, 13 (stack44)
        %v96091 = vshrl.u32 %v96084, 19 (stack45)
        %v96092 = vor.u32 %v96091, %v96090 (stack46)
        %v96093 = vxor.u32 %v96092, %v96088 (stack47)
        %v96096 = vadd.s32 %v96093, %v96088 (stack39)
        %v96098 = vshll.u32 %v96093, 15 (stack44)
        %v96099 = vshrl.u32 %v96093, 17 (stack45)
        %v96100 = vor.u32 %v96099, %v96098 (stack46)
        %v96101 = vxor.u32 %v96100, %v96096 (stack47)
        %v96104 = vadd.s32 %v96101, %v96096 (stack39)
        %v96106 = vshll.u32 %v96101, 26 (stack44)
        %v96107 = vshrl.u32 %v96101, 6 (stack45)
        %v96108 = vor.u32 %v96107, %v96106 (stack46)
        %v96109 = vxor.u32 %v96108, %v96104 (stack47)
        %v96112 = vadd.s32 %v96109, %v96104 (stack39)
        %v96116 = vadd.s32 %v96112, %v10 (stack39)
        %v96118 = vshll.u32 %v96109, 6 (stack44)
        %v96119 = vshrl.u32 %v96109, 26 (stack45)
        %v96120 = vor.u32 %v96119, %v96118 (stack46)
        %v96121 = vxor.u32 %v96120, %v96112 (stack47)
        %v96124 = vadd.s32 %v96121, %v9 (stack39)
        %v96128 = vadd.s32 3, %v96124 (stack39)
        %v96132 = vadd.s32 %v96128, %v96116 (stack39)
        %v96134 = vshll.u32 %v96128, 17 (stack44)
        %v96135 = vshrl.u32 %v96128, 15 (stack45)
        %v96136 = vor.u32 %v96135, %v96134 (stack46)
        %v96137 = vxor.u32 %v96136, %v96132 (stack47)
        %v96140 = vadd.s32 %v96137, %v96132 (stack39)
        %v96142 = vshll.u32 %v96137, 29 (stack44)
        %v96143 = vshrl.u32 %v96137, 3 (stack45)
        %v96144 = vor.u32 %v96143, %v96142 (stack46)
        %v96145 = vxor.u32 %v96144, %v96140 (stack47)
        %v96148 = vadd.s32 %v96145, %v96140 (stack39)
        %v96150 = vshll.u32 %v96145, 16 (stack44)
        %v96151 = vshrl.u32 %v96145, 16 (stack45)
        %v96152 = vor.u32 %v96151, %v96150 (stack46)
        %v96153 = vxor.u32 %v96152, %v96148 (stack47)
        %v96156 = vadd.s32 %v96153, %v96148 (stack39)
        %v96160 = vadd.s32 %v96156, %v9 (stack39)
        %v96162 = vshll.u32 %v96153, 24 (stack44)
        %v96163 = vshrl.u32 %v96153, 8 (stack45)
        %v96164 = vor.u32 %v96163, %v96162 (stack46)
        %v96165 = vxor.u32 %v96164, %v96156 (stack47)
        %v96168 = vadd.s32 %v96165, %v8 (stack39)
        %v96172 = vadd.s32 4, %v96168 (stack39)
        %v96176 = vadd.s32 %v96172, %v96160 (stack39)
        %v96178 = vshll.u32 %v96172, 13 (stack44)
        %v96179 = vshrl.u32 %v96172, 19 (stack45)
        %v96180 = vor.u32 %v96179, %v96178 (stack46)
        %v96181 = vxor.u32 %v96180, %v96176 (stack47)
        %v96184 = vadd.s32 %v96181, %v96176 (stack39)
        %v96186 = vshll.u32 %v96181, 15 (stack44)
        %v96187 = vshrl.u32 %v96181, 17 (stack45)
        %v96188 = vor.u32 %v96187, %v96186 (stack46)
        %v96189 = vxor.u32 %v96188, %v96184 (stack47)
        %v96192 = vadd.s32 %v96189, %v96184 (stack39)
        %v96194 = vshll.u32 %v96189, 26 (stack44)
        %v96195 = vshrl.u32 %v96189, 6 (stack45)
        %v96196 = vor.u32 %v96195, %v96194 (stack46)
        %v96197 = vxor.u32 %v96196, %v96192 (stack47)
        %v96200 = vadd.s32 %v96197, %v96192 (stack39)
        %v96204 = vadd.s32 %v96200, %v8 (stack39)
        %v96206 = vshll.u32 %v96197, 6 (stack44)
        %v96207 = vshrl.u32 %v96197, 26 (stack45)
        %v96208 = vor.u32 %v96207, %v96206 (stack46)
        %v96209 = vxor.u32 %v96208, %v96200 (stack47)
        %v96212 = vadd.s32 %v96209, %v10 (stack39)
        %v96216 = vadd.s32 5, %v96212 (stack39)
        %v96218 = vxor.u32 %v96216, %v96204 (stack47)
        %v96219 = vand.u32.u8 255, %v96218 (stack48)
        %v96220 = vand.u32 65535, %v96219 (stack49)
        %v96221 = vshrl.u32 %v96220, 1 (stack50)
        %v96222 = vor.u32 16256, %v96221 (stack46)
        %v96223 = vand.u32.u16 65535, %v96222 (stack51)
        %v120258 = vadd.low.f32.bf16 -1.0, %v96223 (stack52)
        %v96232 = vmul.f32 2.0, %v120258 (stack53)
        %v96236 = vadd.f32 -0.99609375, %v96232 (stack52)
        %v96240 = vmax.f32 %v96236, -0.99609375 (stack54)
        %v96242 = vand.u32 2147483647, %v96240 (stack55)
        %vm96245 = vcmp.eq.f32.partialorder %v96242, 1.0 (stack56)
        %v96250 = vmul.f32 inf, %v96240 (stack53)
        %v96252 = vxor.u32 2147483648, %v96240 (stack57)
        %v96255 = vmul.f32 %v96252, %v96240 (stack53)
        %v96257 = vadd.f32 1.0, %v96255 (stack58)
        %v96258 = vlog2.pop %v96257 (stack59)
        %v96259 = vmul.f32 0.6931472, %v96258 (stack60)
        %v96260 = vmul.f32 -0.5, %v96255 (stack61)
        %v96261 = vadd.f32 1.0, %v96260 (stack62)
        %v96262 = vmul.f32 %v96261, %v96255 (stack63)
        %v96263 = vand.u32 2147483647, %v96255 (stack64)
        %vm96264 = vcmp.lt.f32.partialorder %v96263, 0.0004427343 (stack65)
        %v96265 = vsel /*vm=*/%vm96264, /*on_true_vy=*/%v96262, /*on_false_vx=*/%v96259 (stack66)
        %v96266 = vxor.u32 2147483648, %v96265 (stack57)
        %vm96269 = vcmp.lt.f32.partialorder %v96266, 5.0 (stack56)
        %v96274 = vsel /*vm=*/%vm96269, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v96278 = vsel /*vm=*/%vm96269, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v96282 = vsel /*vm=*/%vm96269, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v96286 = vsel /*vm=*/%vm96269, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v96290 = vsel /*vm=*/%vm96269, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v96294 = vsel /*vm=*/%vm96269, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v96298 = vsel /*vm=*/%vm96269, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v96302 = vsel /*vm=*/%vm96269, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v96306 = vsel /*vm=*/%vm96269, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v96310 = vadd.f32 -2.5, %v96266 (stack52)
        %v96312 = vrsqrt.pop %v96266 (stack67)
        %v96313 = vmul.f32 %v96312, %v96266 (stack68)
        %vm96314 = vcmp.eq.f32.partialorder %v96266, inf (stack69)
        %v96315 = vsel /*vm=*/%vm96314, /*on_true_vy=*/%v96266, /*on_false_vx=*/%v96313 (stack70)
        %vm96316 = vcmp.eq.f32.partialorder %v96266, 0.0 (stack71)
        %v96317 = vand.u32 2147483648, %v96266 (stack72)
        %v96318 = vsel /*vm=*/%vm96316, /*on_true_vy=*/%v96317, /*on_false_vx=*/%v96315 (stack73)
        %v96321 = vadd.f32 -3.0, %v96318 (stack52)
        %v96325 = vsel /*vm=*/%vm96269, /*on_true_vy=*/%v96310, /*on_false_vx=*/%v96321 (stack43)
        %v96329 = vmul.f32 %v96325, %v96306 (stack53)
        %v96333 = vadd.f32 %v96329, %v96302 (stack52)
        %v96337 = vmul.f32 %v96333, %v96325 (stack53)
        %v96341 = vadd.f32 %v96337, %v96298 (stack52)
        %v96345 = vmul.f32 %v96341, %v96325 (stack53)
        %v96349 = vadd.f32 %v96345, %v96294 (stack52)
        %v96353 = vmul.f32 %v96349, %v96325 (stack53)
        %v96357 = vadd.f32 %v96353, %v96290 (stack52)
        %v96361 = vmul.f32 %v96357, %v96325 (stack53)
        %v96365 = vadd.f32 %v96361, %v96286 (stack52)
        %v96369 = vmul.f32 %v96365, %v96325 (stack53)
        %v96373 = vadd.f32 %v96369, %v96282 (stack52)
        %v96377 = vmul.f32 %v96373, %v96325 (stack53)
        %v96381 = vadd.f32 %v96377, %v96278 (stack52)
        %v96385 = vmul.f32 %v96381, %v96325 (stack53)
        %v96389 = vadd.f32 %v96385, %v96274 (stack52)
        %v96393 = vmul.f32 %v96389, %v96240 (stack53)
        %v96397 = vsel /*vm=*/%vm96245, /*on_true_vy=*/%v96250, /*on_false_vx=*/%v96393 (stack43)
        %v96401 = vmul.f32 1.4140625, %v96397 (stack53)
        %v96404 = vpack.c.bf16 0.0, %v96401 (stack74)
        %120259 = vst [vmem:[%s280 + $0x2e4] sm:$0xf] /*vst_source=*/%v96404 (stack75)
        %v96408 = vadd.s32 %v93639, %v3329 (stack39)
        %v96418 = vadd.s32 %v96408, %v415 (stack39)
        %vm96422 = vcmp.lt.u32.totalorder %v96418, %v96408 (stack42)
        %vm96427 = vcmp.lt.u32.totalorder %v96408, %v3329 (stack42)
        %v96432 = vadd.s32 %v93622, %v3316 (stack39)
        %v96436 = vadd.s32 1, %v96432 (stack39)
        %v96440 = vsel /*vm=*/%vm96427, /*on_true_vy=*/%v96436, /*on_false_vx=*/%v96432 (stack43)
        %v96444 = vadd.s32 1, %v96440 (stack39)
        %v96448 = vsel /*vm=*/%vm96422, /*on_true_vy=*/%v96444, /*on_false_vx=*/%v96440 (stack43)
        %v96453 = vadd.s32 %v96448, %v10 (stack39)
        %v96457 = vadd.s32 %v96418, %v9 (stack39)
        %v96461 = vadd.s32 %v96457, %v96453 (stack39)
        %v96463 = vshll.u32 %v96457, 13 (stack44)
        %v96464 = vshrl.u32 %v96457, 19 (stack45)
        %v96465 = vor.u32 %v96464, %v96463 (stack46)
        %v96466 = vxor.u32 %v96465, %v96461 (stack47)
        %v96469 = vadd.s32 %v96466, %v96461 (stack39)
        %v96471 = vshll.u32 %v96466, 15 (stack44)
        %v96472 = vshrl.u32 %v96466, 17 (stack45)
        %v96473 = vor.u32 %v96472, %v96471 (stack46)
        %v96474 = vxor.u32 %v96473, %v96469 (stack47)
        %v96477 = vadd.s32 %v96474, %v96469 (stack39)
        %v96479 = vshll.u32 %v96474, 26 (stack44)
        %v96480 = vshrl.u32 %v96474, 6 (stack45)
        %v96481 = vor.u32 %v96480, %v96479 (stack46)
        %v96482 = vxor.u32 %v96481, %v96477 (stack47)
        %v96485 = vadd.s32 %v96482, %v96477 (stack39)
        %v96489 = vadd.s32 %v96485, %v9 (stack39)
        %v96491 = vshll.u32 %v96482, 6 (stack44)
        %v96492 = vshrl.u32 %v96482, 26 (stack45)
        %v96493 = vor.u32 %v96492, %v96491 (stack46)
        %v96494 = vxor.u32 %v96493, %v96485 (stack47)
        %v96497 = vadd.s32 %v96494, %v8 (stack39)
        %v96501 = vadd.s32 1, %v96497 (stack39)
        %v96505 = vadd.s32 %v96501, %v96489 (stack39)
        %v96507 = vshll.u32 %v96501, 17 (stack44)
        %v96508 = vshrl.u32 %v96501, 15 (stack45)
        %v96509 = vor.u32 %v96508, %v96507 (stack46)
        %v96510 = vxor.u32 %v96509, %v96505 (stack47)
        %v96513 = vadd.s32 %v96510, %v96505 (stack39)
        %v96515 = vshll.u32 %v96510, 29 (stack44)
        %v96516 = vshrl.u32 %v96510, 3 (stack45)
        %v96517 = vor.u32 %v96516, %v96515 (stack46)
        %v96518 = vxor.u32 %v96517, %v96513 (stack47)
        %v96521 = vadd.s32 %v96518, %v96513 (stack39)
        %v96523 = vshll.u32 %v96518, 16 (stack44)
        %v96524 = vshrl.u32 %v96518, 16 (stack45)
        %v96525 = vor.u32 %v96524, %v96523 (stack46)
        %v96526 = vxor.u32 %v96525, %v96521 (stack47)
        %v96529 = vadd.s32 %v96526, %v96521 (stack39)
        %v96533 = vadd.s32 %v96529, %v8 (stack39)
        %v96535 = vshll.u32 %v96526, 24 (stack44)
        %v96536 = vshrl.u32 %v96526, 8 (stack45)
        %v96537 = vor.u32 %v96536, %v96535 (stack46)
        %v96538 = vxor.u32 %v96537, %v96529 (stack47)
        %v96541 = vadd.s32 %v96538, %v10 (stack39)
        %v96545 = vadd.s32 2, %v96541 (stack39)
        %v96549 = vadd.s32 %v96545, %v96533 (stack39)
        %v96551 = vshll.u32 %v96545, 13 (stack44)
        %v96552 = vshrl.u32 %v96545, 19 (stack45)
        %v96553 = vor.u32 %v96552, %v96551 (stack46)
        %v96554 = vxor.u32 %v96553, %v96549 (stack47)
        %v96557 = vadd.s32 %v96554, %v96549 (stack39)
        %v96559 = vshll.u32 %v96554, 15 (stack44)
        %v96560 = vshrl.u32 %v96554, 17 (stack45)
        %v96561 = vor.u32 %v96560, %v96559 (stack46)
        %v96562 = vxor.u32 %v96561, %v96557 (stack47)
        %v96565 = vadd.s32 %v96562, %v96557 (stack39)
        %v96567 = vshll.u32 %v96562, 26 (stack44)
        %v96568 = vshrl.u32 %v96562, 6 (stack45)
        %v96569 = vor.u32 %v96568, %v96567 (stack46)
        %v96570 = vxor.u32 %v96569, %v96565 (stack47)
        %v96573 = vadd.s32 %v96570, %v96565 (stack39)
        %v96577 = vadd.s32 %v96573, %v10 (stack39)
        %v96579 = vshll.u32 %v96570, 6 (stack44)
        %v96580 = vshrl.u32 %v96570, 26 (stack45)
        %v96581 = vor.u32 %v96580, %v96579 (stack46)
        %v96582 = vxor.u32 %v96581, %v96573 (stack47)
        %v96585 = vadd.s32 %v96582, %v9 (stack39)
        %v96589 = vadd.s32 3, %v96585 (stack39)
        %v96593 = vadd.s32 %v96589, %v96577 (stack39)
        %v96595 = vshll.u32 %v96589, 17 (stack44)
        %v96596 = vshrl.u32 %v96589, 15 (stack45)
        %v96597 = vor.u32 %v96596, %v96595 (stack46)
        %v96598 = vxor.u32 %v96597, %v96593 (stack47)
        %v96601 = vadd.s32 %v96598, %v96593 (stack39)
        %v96603 = vshll.u32 %v96598, 29 (stack44)
        %v96604 = vshrl.u32 %v96598, 3 (stack45)
        %v96605 = vor.u32 %v96604, %v96603 (stack46)
        %v96606 = vxor.u32 %v96605, %v96601 (stack47)
        %v96609 = vadd.s32 %v96606, %v96601 (stack39)
        %v96611 = vshll.u32 %v96606, 16 (stack44)
        %v96612 = vshrl.u32 %v96606, 16 (stack45)
        %v96613 = vor.u32 %v96612, %v96611 (stack46)
        %v96614 = vxor.u32 %v96613, %v96609 (stack47)
        %v96617 = vadd.s32 %v96614, %v96609 (stack39)
        %v96621 = vadd.s32 %v96617, %v9 (stack39)
        %v96623 = vshll.u32 %v96614, 24 (stack44)
        %v96624 = vshrl.u32 %v96614, 8 (stack45)
        %v96625 = vor.u32 %v96624, %v96623 (stack46)
        %v96626 = vxor.u32 %v96625, %v96617 (stack47)
        %v96629 = vadd.s32 %v96626, %v8 (stack39)
        %v96633 = vadd.s32 4, %v96629 (stack39)
        %v96637 = vadd.s32 %v96633, %v96621 (stack39)
        %v96639 = vshll.u32 %v96633, 13 (stack44)
        %v96640 = vshrl.u32 %v96633, 19 (stack45)
        %v96641 = vor.u32 %v96640, %v96639 (stack46)
        %v96642 = vxor.u32 %v96641, %v96637 (stack47)
        %v96645 = vadd.s32 %v96642, %v96637 (stack39)
        %v96647 = vshll.u32 %v96642, 15 (stack44)
        %v96648 = vshrl.u32 %v96642, 17 (stack45)
        %v96649 = vor.u32 %v96648, %v96647 (stack46)
        %v96650 = vxor.u32 %v96649, %v96645 (stack47)
        %v96653 = vadd.s32 %v96650, %v96645 (stack39)
        %v96655 = vshll.u32 %v96650, 26 (stack44)
        %v96656 = vshrl.u32 %v96650, 6 (stack45)
        %v96657 = vor.u32 %v96656, %v96655 (stack46)
        %v96658 = vxor.u32 %v96657, %v96653 (stack47)
        %v96661 = vadd.s32 %v96658, %v96653 (stack39)
        %v96665 = vadd.s32 %v96661, %v8 (stack39)
        %v96667 = vshll.u32 %v96658, 6 (stack44)
        %v96668 = vshrl.u32 %v96658, 26 (stack45)
        %v96669 = vor.u32 %v96668, %v96667 (stack46)
        %v96670 = vxor.u32 %v96669, %v96661 (stack47)
        %v96673 = vadd.s32 %v96670, %v10 (stack39)
        %v96677 = vadd.s32 5, %v96673 (stack39)
        %v96679 = vxor.u32 %v96677, %v96665 (stack47)
        %v96680 = vand.u32.u8 255, %v96679 (stack48)
        %v96681 = vand.u32 65535, %v96680 (stack49)
        %v96682 = vshrl.u32 %v96681, 1 (stack50)
        %v96683 = vor.u32 16256, %v96682 (stack46)
        %v96684 = vand.u32.u16 65535, %v96683 (stack51)
        %v120260 = vadd.low.f32.bf16 -1.0, %v96684 (stack52)
        %v96693 = vmul.f32 2.0, %v120260 (stack53)
        %v96697 = vadd.f32 -0.99609375, %v96693 (stack52)
        %v96701 = vmax.f32 %v96697, -0.99609375 (stack54)
        %v96703 = vand.u32 2147483647, %v96701 (stack55)
        %vm96706 = vcmp.eq.f32.partialorder %v96703, 1.0 (stack56)
        %v96711 = vmul.f32 inf, %v96701 (stack53)
        %v96713 = vxor.u32 2147483648, %v96701 (stack57)
        %v96716 = vmul.f32 %v96713, %v96701 (stack53)
        %v96718 = vadd.f32 1.0, %v96716 (stack58)
        %v96719 = vlog2.pop %v96718 (stack59)
        %v96720 = vmul.f32 0.6931472, %v96719 (stack60)
        %v96721 = vmul.f32 -0.5, %v96716 (stack61)
        %v96722 = vadd.f32 1.0, %v96721 (stack62)
        %v96723 = vmul.f32 %v96722, %v96716 (stack63)
        %v96724 = vand.u32 2147483647, %v96716 (stack64)
        %vm96725 = vcmp.lt.f32.partialorder %v96724, 0.0004427343 (stack65)
        %v96726 = vsel /*vm=*/%vm96725, /*on_true_vy=*/%v96723, /*on_false_vx=*/%v96720 (stack66)
        %v96727 = vxor.u32 2147483648, %v96726 (stack57)
        %vm96730 = vcmp.lt.f32.partialorder %v96727, 5.0 (stack56)
        %v96735 = vsel /*vm=*/%vm96730, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v96739 = vsel /*vm=*/%vm96730, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v96743 = vsel /*vm=*/%vm96730, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v96747 = vsel /*vm=*/%vm96730, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v96751 = vsel /*vm=*/%vm96730, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v96755 = vsel /*vm=*/%vm96730, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v96759 = vsel /*vm=*/%vm96730, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v96763 = vsel /*vm=*/%vm96730, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v96767 = vsel /*vm=*/%vm96730, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v96771 = vadd.f32 -2.5, %v96727 (stack52)
        %v96773 = vrsqrt.pop %v96727 (stack67)
        %v96774 = vmul.f32 %v96773, %v96727 (stack68)
        %vm96775 = vcmp.eq.f32.partialorder %v96727, inf (stack69)
        %v96776 = vsel /*vm=*/%vm96775, /*on_true_vy=*/%v96727, /*on_false_vx=*/%v96774 (stack70)
        %vm96777 = vcmp.eq.f32.partialorder %v96727, 0.0 (stack71)
        %v96778 = vand.u32 2147483648, %v96727 (stack72)
        %v96779 = vsel /*vm=*/%vm96777, /*on_true_vy=*/%v96778, /*on_false_vx=*/%v96776 (stack73)
        %v96782 = vadd.f32 -3.0, %v96779 (stack52)
        %v96786 = vsel /*vm=*/%vm96730, /*on_true_vy=*/%v96771, /*on_false_vx=*/%v96782 (stack43)
        %v96790 = vmul.f32 %v96786, %v96767 (stack53)
        %v96794 = vadd.f32 %v96790, %v96763 (stack52)
        %v96798 = vmul.f32 %v96794, %v96786 (stack53)
        %v96802 = vadd.f32 %v96798, %v96759 (stack52)
        %v96806 = vmul.f32 %v96802, %v96786 (stack53)
        %v96810 = vadd.f32 %v96806, %v96755 (stack52)
        %v96814 = vmul.f32 %v96810, %v96786 (stack53)
        %v96818 = vadd.f32 %v96814, %v96751 (stack52)
        %v96822 = vmul.f32 %v96818, %v96786 (stack53)
        %v96826 = vadd.f32 %v96822, %v96747 (stack52)
        %v96830 = vmul.f32 %v96826, %v96786 (stack53)
        %v96834 = vadd.f32 %v96830, %v96743 (stack52)
        %v96838 = vmul.f32 %v96834, %v96786 (stack53)
        %v96842 = vadd.f32 %v96838, %v96739 (stack52)
        %v96846 = vmul.f32 %v96842, %v96786 (stack53)
        %v96850 = vadd.f32 %v96846, %v96735 (stack52)
        %v96854 = vmul.f32 %v96850, %v96701 (stack53)
        %v96858 = vsel /*vm=*/%vm96706, /*on_true_vy=*/%v96711, /*on_false_vx=*/%v96854 (stack43)
        %v96862 = vmul.f32 1.4140625, %v96858 (stack53)
        %v96865 = vpack.c.bf16 0.0, %v96862 (stack74)
        %120261 = vst [vmem:[%s280 + $0x364] sm:$0xf] /*vst_source=*/%v96865 (stack75)
        %v96869 = vadd.s32 %v93639, %v3816 (stack39)
        %v96879 = vadd.s32 %v96869, %v415 (stack39)
        %vm96883 = vcmp.lt.u32.totalorder %v96879, %v96869 (stack42)
        %vm96888 = vcmp.lt.u32.totalorder %v96869, %v3816 (stack42)
        %v96893 = vadd.s32 %v93622, %v3803 (stack39)
        %v96897 = vadd.s32 1, %v96893 (stack39)
        %v96901 = vsel /*vm=*/%vm96888, /*on_true_vy=*/%v96897, /*on_false_vx=*/%v96893 (stack43)
        %v96905 = vadd.s32 1, %v96901 (stack39)
        %v96909 = vsel /*vm=*/%vm96883, /*on_true_vy=*/%v96905, /*on_false_vx=*/%v96901 (stack43)
        %v96914 = vadd.s32 %v96909, %v10 (stack39)
        %v96918 = vadd.s32 %v96879, %v9 (stack39)
        %v96922 = vadd.s32 %v96918, %v96914 (stack39)
        %v96924 = vshll.u32 %v96918, 13 (stack44)
        %v96925 = vshrl.u32 %v96918, 19 (stack45)
        %v96926 = vor.u32 %v96925, %v96924 (stack46)
        %v96927 = vxor.u32 %v96926, %v96922 (stack47)
        %v96930 = vadd.s32 %v96927, %v96922 (stack39)
        %v96932 = vshll.u32 %v96927, 15 (stack44)
        %v96933 = vshrl.u32 %v96927, 17 (stack45)
        %v96934 = vor.u32 %v96933, %v96932 (stack46)
        %v96935 = vxor.u32 %v96934, %v96930 (stack47)
        %v96938 = vadd.s32 %v96935, %v96930 (stack39)
        %v96940 = vshll.u32 %v96935, 26 (stack44)
        %v96941 = vshrl.u32 %v96935, 6 (stack45)
        %v96942 = vor.u32 %v96941, %v96940 (stack46)
        %v96943 = vxor.u32 %v96942, %v96938 (stack47)
        %v96946 = vadd.s32 %v96943, %v96938 (stack39)
        %v96950 = vadd.s32 %v96946, %v9 (stack39)
        %v96952 = vshll.u32 %v96943, 6 (stack44)
        %v96953 = vshrl.u32 %v96943, 26 (stack45)
        %v96954 = vor.u32 %v96953, %v96952 (stack46)
        %v96955 = vxor.u32 %v96954, %v96946 (stack47)
        %v96958 = vadd.s32 %v96955, %v8 (stack39)
        %v96962 = vadd.s32 1, %v96958 (stack39)
        %v96966 = vadd.s32 %v96962, %v96950 (stack39)
        %v96968 = vshll.u32 %v96962, 17 (stack44)
        %v96969 = vshrl.u32 %v96962, 15 (stack45)
        %v96970 = vor.u32 %v96969, %v96968 (stack46)
        %v96971 = vxor.u32 %v96970, %v96966 (stack47)
        %v96974 = vadd.s32 %v96971, %v96966 (stack39)
        %v96976 = vshll.u32 %v96971, 29 (stack44)
        %v96977 = vshrl.u32 %v96971, 3 (stack45)
        %v96978 = vor.u32 %v96977, %v96976 (stack46)
        %v96979 = vxor.u32 %v96978, %v96974 (stack47)
        %v96982 = vadd.s32 %v96979, %v96974 (stack39)
        %v96984 = vshll.u32 %v96979, 16 (stack44)
        %v96985 = vshrl.u32 %v96979, 16 (stack45)
        %v96986 = vor.u32 %v96985, %v96984 (stack46)
        %v96987 = vxor.u32 %v96986, %v96982 (stack47)
        %v96990 = vadd.s32 %v96987, %v96982 (stack39)
        %v96994 = vadd.s32 %v96990, %v8 (stack39)
        %v96996 = vshll.u32 %v96987, 24 (stack44)
        %v96997 = vshrl.u32 %v96987, 8 (stack45)
        %v96998 = vor.u32 %v96997, %v96996 (stack46)
        %v96999 = vxor.u32 %v96998, %v96990 (stack47)
        %v97002 = vadd.s32 %v96999, %v10 (stack39)
        %v97006 = vadd.s32 2, %v97002 (stack39)
        %v97010 = vadd.s32 %v97006, %v96994 (stack39)
        %v97012 = vshll.u32 %v97006, 13 (stack44)
        %v97013 = vshrl.u32 %v97006, 19 (stack45)
        %v97014 = vor.u32 %v97013, %v97012 (stack46)
        %v97015 = vxor.u32 %v97014, %v97010 (stack47)
        %v97018 = vadd.s32 %v97015, %v97010 (stack39)
        %v97020 = vshll.u32 %v97015, 15 (stack44)
        %v97021 = vshrl.u32 %v97015, 17 (stack45)
        %v97022 = vor.u32 %v97021, %v97020 (stack46)
        %v97023 = vxor.u32 %v97022, %v97018 (stack47)
        %v97026 = vadd.s32 %v97023, %v97018 (stack39)
        %v97028 = vshll.u32 %v97023, 26 (stack44)
        %v97029 = vshrl.u32 %v97023, 6 (stack45)
        %v97030 = vor.u32 %v97029, %v97028 (stack46)
        %v97031 = vxor.u32 %v97030, %v97026 (stack47)
        %v97034 = vadd.s32 %v97031, %v97026 (stack39)
        %v97038 = vadd.s32 %v97034, %v10 (stack39)
        %v97040 = vshll.u32 %v97031, 6 (stack44)
        %v97041 = vshrl.u32 %v97031, 26 (stack45)
        %v97042 = vor.u32 %v97041, %v97040 (stack46)
        %v97043 = vxor.u32 %v97042, %v97034 (stack47)
        %v97046 = vadd.s32 %v97043, %v9 (stack39)
        %v97050 = vadd.s32 3, %v97046 (stack39)
        %v97054 = vadd.s32 %v97050, %v97038 (stack39)
        %v97056 = vshll.u32 %v97050, 17 (stack44)
        %v97057 = vshrl.u32 %v97050, 15 (stack45)
        %v97058 = vor.u32 %v97057, %v97056 (stack46)
        %v97059 = vxor.u32 %v97058, %v97054 (stack47)
        %v97062 = vadd.s32 %v97059, %v97054 (stack39)
        %v97064 = vshll.u32 %v97059, 29 (stack44)
        %v97065 = vshrl.u32 %v97059, 3 (stack45)
        %v97066 = vor.u32 %v97065, %v97064 (stack46)
        %v97067 = vxor.u32 %v97066, %v97062 (stack47)
        %v97070 = vadd.s32 %v97067, %v97062 (stack39)
        %v97072 = vshll.u32 %v97067, 16 (stack44)
        %v97073 = vshrl.u32 %v97067, 16 (stack45)
        %v97074 = vor.u32 %v97073, %v97072 (stack46)
        %v97075 = vxor.u32 %v97074, %v97070 (stack47)
        %v97078 = vadd.s32 %v97075, %v97070 (stack39)
        %v97082 = vadd.s32 %v97078, %v9 (stack39)
        %v97084 = vshll.u32 %v97075, 24 (stack44)
        %v97085 = vshrl.u32 %v97075, 8 (stack45)
        %v97086 = vor.u32 %v97085, %v97084 (stack46)
        %v97087 = vxor.u32 %v97086, %v97078 (stack47)
        %v97090 = vadd.s32 %v97087, %v8 (stack39)
        %v97094 = vadd.s32 4, %v97090 (stack39)
        %v97098 = vadd.s32 %v97094, %v97082 (stack39)
        %v97100 = vshll.u32 %v97094, 13 (stack44)
        %v97101 = vshrl.u32 %v97094, 19 (stack45)
        %v97102 = vor.u32 %v97101, %v97100 (stack46)
        %v97103 = vxor.u32 %v97102, %v97098 (stack47)
        %v97106 = vadd.s32 %v97103, %v97098 (stack39)
        %v97108 = vshll.u32 %v97103, 15 (stack44)
        %v97109 = vshrl.u32 %v97103, 17 (stack45)
        %v97110 = vor.u32 %v97109, %v97108 (stack46)
        %v97111 = vxor.u32 %v97110, %v97106 (stack47)
        %v97114 = vadd.s32 %v97111, %v97106 (stack39)
        %v97116 = vshll.u32 %v97111, 26 (stack44)
        %v97117 = vshrl.u32 %v97111, 6 (stack45)
        %v97118 = vor.u32 %v97117, %v97116 (stack46)
        %v97119 = vxor.u32 %v97118, %v97114 (stack47)
        %v97122 = vadd.s32 %v97119, %v97114 (stack39)
        %v97126 = vadd.s32 %v97122, %v8 (stack39)
        %v97128 = vshll.u32 %v97119, 6 (stack44)
        %v97129 = vshrl.u32 %v97119, 26 (stack45)
        %v97130 = vor.u32 %v97129, %v97128 (stack46)
        %v97131 = vxor.u32 %v97130, %v97122 (stack47)
        %v97134 = vadd.s32 %v97131, %v10 (stack39)
        %v97138 = vadd.s32 5, %v97134 (stack39)
        %v97140 = vxor.u32 %v97138, %v97126 (stack47)
        %v97141 = vand.u32.u8 255, %v97140 (stack48)
        %v97142 = vand.u32 65535, %v97141 (stack49)
        %v97143 = vshrl.u32 %v97142, 1 (stack50)
        %v97144 = vor.u32 16256, %v97143 (stack46)
        %v97145 = vand.u32.u16 65535, %v97144 (stack51)
        %v120262 = vadd.low.f32.bf16 -1.0, %v97145 (stack52)
        %v97154 = vmul.f32 2.0, %v120262 (stack53)
        %v97158 = vadd.f32 -0.99609375, %v97154 (stack52)
        %v97162 = vmax.f32 %v97158, -0.99609375 (stack54)
        %v97164 = vand.u32 2147483647, %v97162 (stack55)
        %vm97167 = vcmp.eq.f32.partialorder %v97164, 1.0 (stack56)
        %v97172 = vmul.f32 inf, %v97162 (stack53)
        %v97174 = vxor.u32 2147483648, %v97162 (stack57)
        %v97177 = vmul.f32 %v97174, %v97162 (stack53)
        %v97179 = vadd.f32 1.0, %v97177 (stack58)
        %v97180 = vlog2.pop %v97179 (stack59)
        %v97181 = vmul.f32 0.6931472, %v97180 (stack60)
        %v97182 = vmul.f32 -0.5, %v97177 (stack61)
        %v97183 = vadd.f32 1.0, %v97182 (stack62)
        %v97184 = vmul.f32 %v97183, %v97177 (stack63)
        %v97185 = vand.u32 2147483647, %v97177 (stack64)
        %vm97186 = vcmp.lt.f32.partialorder %v97185, 0.0004427343 (stack65)
        %v97187 = vsel /*vm=*/%vm97186, /*on_true_vy=*/%v97184, /*on_false_vx=*/%v97181 (stack66)
        %v97188 = vxor.u32 2147483648, %v97187 (stack57)
        %vm97191 = vcmp.lt.f32.partialorder %v97188, 5.0 (stack56)
        %v97196 = vsel /*vm=*/%vm97191, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v97200 = vsel /*vm=*/%vm97191, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v97204 = vsel /*vm=*/%vm97191, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v97208 = vsel /*vm=*/%vm97191, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v97212 = vsel /*vm=*/%vm97191, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v97216 = vsel /*vm=*/%vm97191, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v97220 = vsel /*vm=*/%vm97191, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v97224 = vsel /*vm=*/%vm97191, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v97228 = vsel /*vm=*/%vm97191, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v97232 = vadd.f32 -2.5, %v97188 (stack52)
        %v97234 = vrsqrt.pop %v97188 (stack67)
        %v97235 = vmul.f32 %v97234, %v97188 (stack68)
        %vm97236 = vcmp.eq.f32.partialorder %v97188, inf (stack69)
        %v97237 = vsel /*vm=*/%vm97236, /*on_true_vy=*/%v97188, /*on_false_vx=*/%v97235 (stack70)
        %vm97238 = vcmp.eq.f32.partialorder %v97188, 0.0 (stack71)
        %v97239 = vand.u32 2147483648, %v97188 (stack72)
        %v97240 = vsel /*vm=*/%vm97238, /*on_true_vy=*/%v97239, /*on_false_vx=*/%v97237 (stack73)
        %v97243 = vadd.f32 -3.0, %v97240 (stack52)
        %v97247 = vsel /*vm=*/%vm97191, /*on_true_vy=*/%v97232, /*on_false_vx=*/%v97243 (stack43)
        %v97251 = vmul.f32 %v97247, %v97228 (stack53)
        %v97255 = vadd.f32 %v97251, %v97224 (stack52)
        %v97259 = vmul.f32 %v97255, %v97247 (stack53)
        %v97263 = vadd.f32 %v97259, %v97220 (stack52)
        %v97267 = vmul.f32 %v97263, %v97247 (stack53)
        %v97271 = vadd.f32 %v97267, %v97216 (stack52)
        %v97275 = vmul.f32 %v97271, %v97247 (stack53)
        %v97279 = vadd.f32 %v97275, %v97212 (stack52)
        %v97283 = vmul.f32 %v97279, %v97247 (stack53)
        %v97287 = vadd.f32 %v97283, %v97208 (stack52)
        %v97291 = vmul.f32 %v97287, %v97247 (stack53)
        %v97295 = vadd.f32 %v97291, %v97204 (stack52)
        %v97299 = vmul.f32 %v97295, %v97247 (stack53)
        %v97303 = vadd.f32 %v97299, %v97200 (stack52)
        %v97307 = vmul.f32 %v97303, %v97247 (stack53)
        %v97311 = vadd.f32 %v97307, %v97196 (stack52)
        %v97315 = vmul.f32 %v97311, %v97162 (stack53)
        %v97319 = vsel /*vm=*/%vm97167, /*on_true_vy=*/%v97172, /*on_false_vx=*/%v97315 (stack43)
        %v97323 = vmul.f32 1.4140625, %v97319 (stack53)
        %v97326 = vpack.c.bf16 0.0, %v97323 (stack74)
        %120263 = vst [vmem:[%s280 + $0x3e4] sm:$0xf] /*vst_source=*/%v97326 (stack75)
        %s97328 = sadd.s32 208, %s120390 (stack76)
        %s97329 = sshrl.u32 %s97328, 10 (stack23)
        %p120264 = scmp.gt.s32.totalorder %s97329, 1 (stack24)
        %s97331 = scalar_select /*predicate=*/%p120264, /*on_true=*/1, /*on_false=*/%s97329 (stack25)
        %s97332 = sand.u32 1023, %s97328 /* smod.u32 w/div 1024 */ (stack26)
        %s97333 = sshrl.u32 %s97332, 7 (stack27)
        %s97334 = sand.u32 127, %s97332 /* smod.u32 w/div 128 */ (stack28)
        %s120265 = sshll.u32 %s97331, 3 (stack29)
        %s97336 = scalar_lea.vmem %s3, %s120265 (stack30)
        %s97338 = scalar_lea.vmem %s97336, %s97333 (stack31)
        %v97339 = vld [vmem:[%s97338] ss:$0 sm:$0xff] (stack32)
        %s97340 = sand.u32 255, %s97334 (stack33)
        %s97342 = sor.u32 256, %s97340 (stack34)
        %97343 = vbcast.lane.b32.xlu0 %v97339, %s97342 (stack35)
        %v97344 = vpop.permute.xlu0 %97343 (stack36)
        %s97353 = scalar_lea.vmem %s5, %s120265 (stack30)
        %s97355 = scalar_lea.vmem %s97353, %s97333 (stack31)
        %v97356 = vld [vmem:[%s97355] ss:$0 sm:$0xff] (stack32)
        %97360 = vbcast.lane.b32.xlu0 %v97356, %s97342 (stack35)
        %v97361 = vpop.permute.xlu0 %97360 (stack36)
        %v97364 = vadd.s32 %v97361, %v408 (stack39)
        %v97374 = vadd.s32 %v97364, %v415 (stack39)
        %vm97378 = vcmp.lt.u32.totalorder %v97374, %v97364 (stack42)
        %vm97383 = vcmp.lt.u32.totalorder %v97364, %v408 (stack42)
        %v97388 = vadd.s32 %v97344, %v380 (stack39)
        %v97392 = vadd.s32 1, %v97388 (stack39)
        %v97396 = vsel /*vm=*/%vm97383, /*on_true_vy=*/%v97392, /*on_false_vx=*/%v97388 (stack43)
        %v97400 = vadd.s32 1, %v97396 (stack39)
        %v97404 = vsel /*vm=*/%vm97378, /*on_true_vy=*/%v97400, /*on_false_vx=*/%v97396 (stack43)
        %v97409 = vadd.s32 %v97404, %v10 (stack39)
        %v97413 = vadd.s32 %v97374, %v9 (stack39)
        %v97417 = vadd.s32 %v97413, %v97409 (stack39)
        %v97419 = vshll.u32 %v97413, 13 (stack44)
        %v97420 = vshrl.u32 %v97413, 19 (stack45)
        %v97421 = vor.u32 %v97420, %v97419 (stack46)
        %v97422 = vxor.u32 %v97421, %v97417 (stack47)
        %v97425 = vadd.s32 %v97422, %v97417 (stack39)
        %v97427 = vshll.u32 %v97422, 15 (stack44)
        %v97428 = vshrl.u32 %v97422, 17 (stack45)
        %v97429 = vor.u32 %v97428, %v97427 (stack46)
        %v97430 = vxor.u32 %v97429, %v97425 (stack47)
        %v97433 = vadd.s32 %v97430, %v97425 (stack39)
        %v97435 = vshll.u32 %v97430, 26 (stack44)
        %v97436 = vshrl.u32 %v97430, 6 (stack45)
        %v97437 = vor.u32 %v97436, %v97435 (stack46)
        %v97438 = vxor.u32 %v97437, %v97433 (stack47)
        %v97441 = vadd.s32 %v97438, %v97433 (stack39)
        %v97445 = vadd.s32 %v97441, %v9 (stack39)
        %v97447 = vshll.u32 %v97438, 6 (stack44)
        %v97448 = vshrl.u32 %v97438, 26 (stack45)
        %v97449 = vor.u32 %v97448, %v97447 (stack46)
        %v97450 = vxor.u32 %v97449, %v97441 (stack47)
        %v97453 = vadd.s32 %v97450, %v8 (stack39)
        %v97457 = vadd.s32 1, %v97453 (stack39)
        %v97461 = vadd.s32 %v97457, %v97445 (stack39)
        %v97463 = vshll.u32 %v97457, 17 (stack44)
        %v97464 = vshrl.u32 %v97457, 15 (stack45)
        %v97465 = vor.u32 %v97464, %v97463 (stack46)
        %v97466 = vxor.u32 %v97465, %v97461 (stack47)
        %v97469 = vadd.s32 %v97466, %v97461 (stack39)
        %v97471 = vshll.u32 %v97466, 29 (stack44)
        %v97472 = vshrl.u32 %v97466, 3 (stack45)
        %v97473 = vor.u32 %v97472, %v97471 (stack46)
        %v97474 = vxor.u32 %v97473, %v97469 (stack47)
        %v97477 = vadd.s32 %v97474, %v97469 (stack39)
        %v97479 = vshll.u32 %v97474, 16 (stack44)
        %v97480 = vshrl.u32 %v97474, 16 (stack45)
        %v97481 = vor.u32 %v97480, %v97479 (stack46)
        %v97482 = vxor.u32 %v97481, %v97477 (stack47)
        %v97485 = vadd.s32 %v97482, %v97477 (stack39)
        %v97489 = vadd.s32 %v97485, %v8 (stack39)
        %v97491 = vshll.u32 %v97482, 24 (stack44)
        %v97492 = vshrl.u32 %v97482, 8 (stack45)
        %v97493 = vor.u32 %v97492, %v97491 (stack46)
        %v97494 = vxor.u32 %v97493, %v97485 (stack47)
        %v97497 = vadd.s32 %v97494, %v10 (stack39)
        %v97501 = vadd.s32 2, %v97497 (stack39)
        %v97505 = vadd.s32 %v97501, %v97489 (stack39)
        %v97507 = vshll.u32 %v97501, 13 (stack44)
        %v97508 = vshrl.u32 %v97501, 19 (stack45)
        %v97509 = vor.u32 %v97508, %v97507 (stack46)
        %v97510 = vxor.u32 %v97509, %v97505 (stack47)
        %v97513 = vadd.s32 %v97510, %v97505 (stack39)
        %v97515 = vshll.u32 %v97510, 15 (stack44)
        %v97516 = vshrl.u32 %v97510, 17 (stack45)
        %v97517 = vor.u32 %v97516, %v97515 (stack46)
        %v97518 = vxor.u32 %v97517, %v97513 (stack47)
        %v97521 = vadd.s32 %v97518, %v97513 (stack39)
        %v97523 = vshll.u32 %v97518, 26 (stack44)
        %v97524 = vshrl.u32 %v97518, 6 (stack45)
        %v97525 = vor.u32 %v97524, %v97523 (stack46)
        %v97526 = vxor.u32 %v97525, %v97521 (stack47)
        %v97529 = vadd.s32 %v97526, %v97521 (stack39)
        %v97533 = vadd.s32 %v97529, %v10 (stack39)
        %v97535 = vshll.u32 %v97526, 6 (stack44)
        %v97536 = vshrl.u32 %v97526, 26 (stack45)
        %v97537 = vor.u32 %v97536, %v97535 (stack46)
        %v97538 = vxor.u32 %v97537, %v97529 (stack47)
        %v97541 = vadd.s32 %v97538, %v9 (stack39)
        %v97545 = vadd.s32 3, %v97541 (stack39)
        %v97549 = vadd.s32 %v97545, %v97533 (stack39)
        %v97551 = vshll.u32 %v97545, 17 (stack44)
        %v97552 = vshrl.u32 %v97545, 15 (stack45)
        %v97553 = vor.u32 %v97552, %v97551 (stack46)
        %v97554 = vxor.u32 %v97553, %v97549 (stack47)
        %v97557 = vadd.s32 %v97554, %v97549 (stack39)
        %v97559 = vshll.u32 %v97554, 29 (stack44)
        %v97560 = vshrl.u32 %v97554, 3 (stack45)
        %v97561 = vor.u32 %v97560, %v97559 (stack46)
        %v97562 = vxor.u32 %v97561, %v97557 (stack47)
        %v97565 = vadd.s32 %v97562, %v97557 (stack39)
        %v97567 = vshll.u32 %v97562, 16 (stack44)
        %v97568 = vshrl.u32 %v97562, 16 (stack45)
        %v97569 = vor.u32 %v97568, %v97567 (stack46)
        %v97570 = vxor.u32 %v97569, %v97565 (stack47)
        %v97573 = vadd.s32 %v97570, %v97565 (stack39)
        %v97577 = vadd.s32 %v97573, %v9 (stack39)
        %v97579 = vshll.u32 %v97570, 24 (stack44)
        %v97580 = vshrl.u32 %v97570, 8 (stack45)
        %v97581 = vor.u32 %v97580, %v97579 (stack46)
        %v97582 = vxor.u32 %v97581, %v97573 (stack47)
        %v97585 = vadd.s32 %v97582, %v8 (stack39)
        %v97589 = vadd.s32 4, %v97585 (stack39)
        %v97593 = vadd.s32 %v97589, %v97577 (stack39)
        %v97595 = vshll.u32 %v97589, 13 (stack44)
        %v97596 = vshrl.u32 %v97589, 19 (stack45)
        %v97597 = vor.u32 %v97596, %v97595 (stack46)
        %v97598 = vxor.u32 %v97597, %v97593 (stack47)
        %v97601 = vadd.s32 %v97598, %v97593 (stack39)
        %v97603 = vshll.u32 %v97598, 15 (stack44)
        %v97604 = vshrl.u32 %v97598, 17 (stack45)
        %v97605 = vor.u32 %v97604, %v97603 (stack46)
        %v97606 = vxor.u32 %v97605, %v97601 (stack47)
        %v97609 = vadd.s32 %v97606, %v97601 (stack39)
        %v97611 = vshll.u32 %v97606, 26 (stack44)
        %v97612 = vshrl.u32 %v97606, 6 (stack45)
        %v97613 = vor.u32 %v97612, %v97611 (stack46)
        %v97614 = vxor.u32 %v97613, %v97609 (stack47)
        %v97617 = vadd.s32 %v97614, %v97609 (stack39)
        %v97621 = vadd.s32 %v97617, %v8 (stack39)
        %v97623 = vshll.u32 %v97614, 6 (stack44)
        %v97624 = vshrl.u32 %v97614, 26 (stack45)
        %v97625 = vor.u32 %v97624, %v97623 (stack46)
        %v97626 = vxor.u32 %v97625, %v97617 (stack47)
        %v97629 = vadd.s32 %v97626, %v10 (stack39)
        %v97633 = vadd.s32 5, %v97629 (stack39)
        %v97635 = vxor.u32 %v97633, %v97621 (stack47)
        %v97636 = vand.u32.u8 255, %v97635 (stack48)
        %v97637 = vand.u32 65535, %v97636 (stack49)
        %v97638 = vshrl.u32 %v97637, 1 (stack50)
        %v97639 = vor.u32 16256, %v97638 (stack46)
        %v97640 = vand.u32.u16 65535, %v97639 (stack51)
        %v120268 = vadd.low.f32.bf16 -1.0, %v97640 (stack52)
        %v97649 = vmul.f32 2.0, %v120268 (stack53)
        %v97653 = vadd.f32 -0.99609375, %v97649 (stack52)
        %v97657 = vmax.f32 %v97653, -0.99609375 (stack54)
        %v97659 = vand.u32 2147483647, %v97657 (stack55)
        %vm97662 = vcmp.eq.f32.partialorder %v97659, 1.0 (stack56)
        %v97667 = vmul.f32 inf, %v97657 (stack53)
        %v97669 = vxor.u32 2147483648, %v97657 (stack57)
        %v97672 = vmul.f32 %v97669, %v97657 (stack53)
        %v97674 = vadd.f32 1.0, %v97672 (stack58)
        %v97675 = vlog2.pop %v97674 (stack59)
        %v97676 = vmul.f32 0.6931472, %v97675 (stack60)
        %v97677 = vmul.f32 -0.5, %v97672 (stack61)
        %v97678 = vadd.f32 1.0, %v97677 (stack62)
        %v97679 = vmul.f32 %v97678, %v97672 (stack63)
        %v97680 = vand.u32 2147483647, %v97672 (stack64)
        %vm97681 = vcmp.lt.f32.partialorder %v97680, 0.0004427343 (stack65)
        %v97682 = vsel /*vm=*/%vm97681, /*on_true_vy=*/%v97679, /*on_false_vx=*/%v97676 (stack66)
        %v97683 = vxor.u32 2147483648, %v97682 (stack57)
        %vm97686 = vcmp.lt.f32.partialorder %v97683, 5.0 (stack56)
        %v97691 = vsel /*vm=*/%vm97686, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v97695 = vsel /*vm=*/%vm97686, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v97699 = vsel /*vm=*/%vm97686, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v97703 = vsel /*vm=*/%vm97686, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v97707 = vsel /*vm=*/%vm97686, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v97711 = vsel /*vm=*/%vm97686, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v97715 = vsel /*vm=*/%vm97686, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v97719 = vsel /*vm=*/%vm97686, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v97723 = vsel /*vm=*/%vm97686, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v97727 = vadd.f32 -2.5, %v97683 (stack52)
        %v97729 = vrsqrt.pop %v97683 (stack67)
        %v97730 = vmul.f32 %v97729, %v97683 (stack68)
        %vm97731 = vcmp.eq.f32.partialorder %v97683, inf (stack69)
        %v97732 = vsel /*vm=*/%vm97731, /*on_true_vy=*/%v97683, /*on_false_vx=*/%v97730 (stack70)
        %vm97733 = vcmp.eq.f32.partialorder %v97683, 0.0 (stack71)
        %v97734 = vand.u32 2147483648, %v97683 (stack72)
        %v97735 = vsel /*vm=*/%vm97733, /*on_true_vy=*/%v97734, /*on_false_vx=*/%v97732 (stack73)
        %v97738 = vadd.f32 -3.0, %v97735 (stack52)
        %v97742 = vsel /*vm=*/%vm97686, /*on_true_vy=*/%v97727, /*on_false_vx=*/%v97738 (stack43)
        %v97746 = vmul.f32 %v97742, %v97723 (stack53)
        %v97750 = vadd.f32 %v97746, %v97719 (stack52)
        %v97754 = vmul.f32 %v97750, %v97742 (stack53)
        %v97758 = vadd.f32 %v97754, %v97715 (stack52)
        %v97762 = vmul.f32 %v97758, %v97742 (stack53)
        %v97766 = vadd.f32 %v97762, %v97711 (stack52)
        %v97770 = vmul.f32 %v97766, %v97742 (stack53)
        %v97774 = vadd.f32 %v97770, %v97707 (stack52)
        %v97778 = vmul.f32 %v97774, %v97742 (stack53)
        %v97782 = vadd.f32 %v97778, %v97703 (stack52)
        %v97786 = vmul.f32 %v97782, %v97742 (stack53)
        %v97790 = vadd.f32 %v97786, %v97699 (stack52)
        %v97794 = vmul.f32 %v97790, %v97742 (stack53)
        %v97798 = vadd.f32 %v97794, %v97695 (stack52)
        %v97802 = vmul.f32 %v97798, %v97742 (stack53)
        %v97806 = vadd.f32 %v97802, %v97691 (stack52)
        %v97810 = vmul.f32 %v97806, %v97657 (stack53)
        %v97814 = vsel /*vm=*/%vm97662, /*on_true_vy=*/%v97667, /*on_false_vx=*/%v97810 (stack43)
        %v97818 = vmul.f32 1.4140625, %v97814 (stack53)
        %v97821 = vpack.c.bf16 0.0, %v97818 (stack74)
        %120269 = vst [vmem:[%s280 + $0x68] sm:$0xf] /*vst_source=*/%v97821 (stack75)
        %v97825 = vadd.s32 %v97361, %v894 (stack39)
        %v97835 = vadd.s32 %v97825, %v415 (stack39)
        %vm97839 = vcmp.lt.u32.totalorder %v97835, %v97825 (stack42)
        %vm97844 = vcmp.lt.u32.totalorder %v97825, %v894 (stack42)
        %v97849 = vadd.s32 %v97344, %v881 (stack39)
        %v97853 = vadd.s32 1, %v97849 (stack39)
        %v97857 = vsel /*vm=*/%vm97844, /*on_true_vy=*/%v97853, /*on_false_vx=*/%v97849 (stack43)
        %v97861 = vadd.s32 1, %v97857 (stack39)
        %v97865 = vsel /*vm=*/%vm97839, /*on_true_vy=*/%v97861, /*on_false_vx=*/%v97857 (stack43)
        %v97870 = vadd.s32 %v97865, %v10 (stack39)
        %v97874 = vadd.s32 %v97835, %v9 (stack39)
        %v97878 = vadd.s32 %v97874, %v97870 (stack39)
        %v97880 = vshll.u32 %v97874, 13 (stack44)
        %v97881 = vshrl.u32 %v97874, 19 (stack45)
        %v97882 = vor.u32 %v97881, %v97880 (stack46)
        %v97883 = vxor.u32 %v97882, %v97878 (stack47)
        %v97886 = vadd.s32 %v97883, %v97878 (stack39)
        %v97888 = vshll.u32 %v97883, 15 (stack44)
        %v97889 = vshrl.u32 %v97883, 17 (stack45)
        %v97890 = vor.u32 %v97889, %v97888 (stack46)
        %v97891 = vxor.u32 %v97890, %v97886 (stack47)
        %v97894 = vadd.s32 %v97891, %v97886 (stack39)
        %v97896 = vshll.u32 %v97891, 26 (stack44)
        %v97897 = vshrl.u32 %v97891, 6 (stack45)
        %v97898 = vor.u32 %v97897, %v97896 (stack46)
        %v97899 = vxor.u32 %v97898, %v97894 (stack47)
        %v97902 = vadd.s32 %v97899, %v97894 (stack39)
        %v97906 = vadd.s32 %v97902, %v9 (stack39)
        %v97908 = vshll.u32 %v97899, 6 (stack44)
        %v97909 = vshrl.u32 %v97899, 26 (stack45)
        %v97910 = vor.u32 %v97909, %v97908 (stack46)
        %v97911 = vxor.u32 %v97910, %v97902 (stack47)
        %v97914 = vadd.s32 %v97911, %v8 (stack39)
        %v97918 = vadd.s32 1, %v97914 (stack39)
        %v97922 = vadd.s32 %v97918, %v97906 (stack39)
        %v97924 = vshll.u32 %v97918, 17 (stack44)
        %v97925 = vshrl.u32 %v97918, 15 (stack45)
        %v97926 = vor.u32 %v97925, %v97924 (stack46)
        %v97927 = vxor.u32 %v97926, %v97922 (stack47)
        %v97930 = vadd.s32 %v97927, %v97922 (stack39)
        %v97932 = vshll.u32 %v97927, 29 (stack44)
        %v97933 = vshrl.u32 %v97927, 3 (stack45)
        %v97934 = vor.u32 %v97933, %v97932 (stack46)
        %v97935 = vxor.u32 %v97934, %v97930 (stack47)
        %v97938 = vadd.s32 %v97935, %v97930 (stack39)
        %v97940 = vshll.u32 %v97935, 16 (stack44)
        %v97941 = vshrl.u32 %v97935, 16 (stack45)
        %v97942 = vor.u32 %v97941, %v97940 (stack46)
        %v97943 = vxor.u32 %v97942, %v97938 (stack47)
        %v97946 = vadd.s32 %v97943, %v97938 (stack39)
        %v97950 = vadd.s32 %v97946, %v8 (stack39)
        %v97952 = vshll.u32 %v97943, 24 (stack44)
        %v97953 = vshrl.u32 %v97943, 8 (stack45)
        %v97954 = vor.u32 %v97953, %v97952 (stack46)
        %v97955 = vxor.u32 %v97954, %v97946 (stack47)
        %v97958 = vadd.s32 %v97955, %v10 (stack39)
        %v97962 = vadd.s32 2, %v97958 (stack39)
        %v97966 = vadd.s32 %v97962, %v97950 (stack39)
        %v97968 = vshll.u32 %v97962, 13 (stack44)
        %v97969 = vshrl.u32 %v97962, 19 (stack45)
        %v97970 = vor.u32 %v97969, %v97968 (stack46)
        %v97971 = vxor.u32 %v97970, %v97966 (stack47)
        %v97974 = vadd.s32 %v97971, %v97966 (stack39)
        %v97976 = vshll.u32 %v97971, 15 (stack44)
        %v97977 = vshrl.u32 %v97971, 17 (stack45)
        %v97978 = vor.u32 %v97977, %v97976 (stack46)
        %v97979 = vxor.u32 %v97978, %v97974 (stack47)
        %v97982 = vadd.s32 %v97979, %v97974 (stack39)
        %v97984 = vshll.u32 %v97979, 26 (stack44)
        %v97985 = vshrl.u32 %v97979, 6 (stack45)
        %v97986 = vor.u32 %v97985, %v97984 (stack46)
        %v97987 = vxor.u32 %v97986, %v97982 (stack47)
        %v97990 = vadd.s32 %v97987, %v97982 (stack39)
        %v97994 = vadd.s32 %v97990, %v10 (stack39)
        %v97996 = vshll.u32 %v97987, 6 (stack44)
        %v97997 = vshrl.u32 %v97987, 26 (stack45)
        %v97998 = vor.u32 %v97997, %v97996 (stack46)
        %v97999 = vxor.u32 %v97998, %v97990 (stack47)
        %v98002 = vadd.s32 %v97999, %v9 (stack39)
        %v98006 = vadd.s32 3, %v98002 (stack39)
        %v98010 = vadd.s32 %v98006, %v97994 (stack39)
        %v98012 = vshll.u32 %v98006, 17 (stack44)
        %v98013 = vshrl.u32 %v98006, 15 (stack45)
        %v98014 = vor.u32 %v98013, %v98012 (stack46)
        %v98015 = vxor.u32 %v98014, %v98010 (stack47)
        %v98018 = vadd.s32 %v98015, %v98010 (stack39)
        %v98020 = vshll.u32 %v98015, 29 (stack44)
        %v98021 = vshrl.u32 %v98015, 3 (stack45)
        %v98022 = vor.u32 %v98021, %v98020 (stack46)
        %v98023 = vxor.u32 %v98022, %v98018 (stack47)
        %v98026 = vadd.s32 %v98023, %v98018 (stack39)
        %v98028 = vshll.u32 %v98023, 16 (stack44)
        %v98029 = vshrl.u32 %v98023, 16 (stack45)
        %v98030 = vor.u32 %v98029, %v98028 (stack46)
        %v98031 = vxor.u32 %v98030, %v98026 (stack47)
        %v98034 = vadd.s32 %v98031, %v98026 (stack39)
        %v98038 = vadd.s32 %v98034, %v9 (stack39)
        %v98040 = vshll.u32 %v98031, 24 (stack44)
        %v98041 = vshrl.u32 %v98031, 8 (stack45)
        %v98042 = vor.u32 %v98041, %v98040 (stack46)
        %v98043 = vxor.u32 %v98042, %v98034 (stack47)
        %v98046 = vadd.s32 %v98043, %v8 (stack39)
        %v98050 = vadd.s32 4, %v98046 (stack39)
        %v98054 = vadd.s32 %v98050, %v98038 (stack39)
        %v98056 = vshll.u32 %v98050, 13 (stack44)
        %v98057 = vshrl.u32 %v98050, 19 (stack45)
        %v98058 = vor.u32 %v98057, %v98056 (stack46)
        %v98059 = vxor.u32 %v98058, %v98054 (stack47)
        %v98062 = vadd.s32 %v98059, %v98054 (stack39)
        %v98064 = vshll.u32 %v98059, 15 (stack44)
        %v98065 = vshrl.u32 %v98059, 17 (stack45)
        %v98066 = vor.u32 %v98065, %v98064 (stack46)
        %v98067 = vxor.u32 %v98066, %v98062 (stack47)
        %v98070 = vadd.s32 %v98067, %v98062 (stack39)
        %v98072 = vshll.u32 %v98067, 26 (stack44)
        %v98073 = vshrl.u32 %v98067, 6 (stack45)
        %v98074 = vor.u32 %v98073, %v98072 (stack46)
        %v98075 = vxor.u32 %v98074, %v98070 (stack47)
        %v98078 = vadd.s32 %v98075, %v98070 (stack39)
        %v98082 = vadd.s32 %v98078, %v8 (stack39)
        %v98084 = vshll.u32 %v98075, 6 (stack44)
        %v98085 = vshrl.u32 %v98075, 26 (stack45)
        %v98086 = vor.u32 %v98085, %v98084 (stack46)
        %v98087 = vxor.u32 %v98086, %v98078 (stack47)
        %v98090 = vadd.s32 %v98087, %v10 (stack39)
        %v98094 = vadd.s32 5, %v98090 (stack39)
        %v98096 = vxor.u32 %v98094, %v98082 (stack47)
        %v98097 = vand.u32.u8 255, %v98096 (stack48)
        %v98098 = vand.u32 65535, %v98097 (stack49)
        %v98099 = vshrl.u32 %v98098, 1 (stack50)
        %v98100 = vor.u32 16256, %v98099 (stack46)
        %v98101 = vand.u32.u16 65535, %v98100 (stack51)
        %v120270 = vadd.low.f32.bf16 -1.0, %v98101 (stack52)
        %v98110 = vmul.f32 2.0, %v120270 (stack53)
        %v98114 = vadd.f32 -0.99609375, %v98110 (stack52)
        %v98118 = vmax.f32 %v98114, -0.99609375 (stack54)
        %v98120 = vand.u32 2147483647, %v98118 (stack55)
        %vm98123 = vcmp.eq.f32.partialorder %v98120, 1.0 (stack56)
        %v98128 = vmul.f32 inf, %v98118 (stack53)
        %v98130 = vxor.u32 2147483648, %v98118 (stack57)
        %v98133 = vmul.f32 %v98130, %v98118 (stack53)
        %v98135 = vadd.f32 1.0, %v98133 (stack58)
        %v98136 = vlog2.pop %v98135 (stack59)
        %v98137 = vmul.f32 0.6931472, %v98136 (stack60)
        %v98138 = vmul.f32 -0.5, %v98133 (stack61)
        %v98139 = vadd.f32 1.0, %v98138 (stack62)
        %v98140 = vmul.f32 %v98139, %v98133 (stack63)
        %v98141 = vand.u32 2147483647, %v98133 (stack64)
        %vm98142 = vcmp.lt.f32.partialorder %v98141, 0.0004427343 (stack65)
        %v98143 = vsel /*vm=*/%vm98142, /*on_true_vy=*/%v98140, /*on_false_vx=*/%v98137 (stack66)
        %v98144 = vxor.u32 2147483648, %v98143 (stack57)
        %vm98147 = vcmp.lt.f32.partialorder %v98144, 5.0 (stack56)
        %v98152 = vsel /*vm=*/%vm98147, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v98156 = vsel /*vm=*/%vm98147, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v98160 = vsel /*vm=*/%vm98147, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v98164 = vsel /*vm=*/%vm98147, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v98168 = vsel /*vm=*/%vm98147, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v98172 = vsel /*vm=*/%vm98147, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v98176 = vsel /*vm=*/%vm98147, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v98180 = vsel /*vm=*/%vm98147, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v98184 = vsel /*vm=*/%vm98147, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v98188 = vadd.f32 -2.5, %v98144 (stack52)
        %v98190 = vrsqrt.pop %v98144 (stack67)
        %v98191 = vmul.f32 %v98190, %v98144 (stack68)
        %vm98192 = vcmp.eq.f32.partialorder %v98144, inf (stack69)
        %v98193 = vsel /*vm=*/%vm98192, /*on_true_vy=*/%v98144, /*on_false_vx=*/%v98191 (stack70)
        %vm98194 = vcmp.eq.f32.partialorder %v98144, 0.0 (stack71)
        %v98195 = vand.u32 2147483648, %v98144 (stack72)
        %v98196 = vsel /*vm=*/%vm98194, /*on_true_vy=*/%v98195, /*on_false_vx=*/%v98193 (stack73)
        %v98199 = vadd.f32 -3.0, %v98196 (stack52)
        %v98203 = vsel /*vm=*/%vm98147, /*on_true_vy=*/%v98188, /*on_false_vx=*/%v98199 (stack43)
        %v98207 = vmul.f32 %v98203, %v98184 (stack53)
        %v98211 = vadd.f32 %v98207, %v98180 (stack52)
        %v98215 = vmul.f32 %v98211, %v98203 (stack53)
        %v98219 = vadd.f32 %v98215, %v98176 (stack52)
        %v98223 = vmul.f32 %v98219, %v98203 (stack53)
        %v98227 = vadd.f32 %v98223, %v98172 (stack52)
        %v98231 = vmul.f32 %v98227, %v98203 (stack53)
        %v98235 = vadd.f32 %v98231, %v98168 (stack52)
        %v98239 = vmul.f32 %v98235, %v98203 (stack53)
        %v98243 = vadd.f32 %v98239, %v98164 (stack52)
        %v98247 = vmul.f32 %v98243, %v98203 (stack53)
        %v98251 = vadd.f32 %v98247, %v98160 (stack52)
        %v98255 = vmul.f32 %v98251, %v98203 (stack53)
        %v98259 = vadd.f32 %v98255, %v98156 (stack52)
        %v98263 = vmul.f32 %v98259, %v98203 (stack53)
        %v98267 = vadd.f32 %v98263, %v98152 (stack52)
        %v98271 = vmul.f32 %v98267, %v98118 (stack53)
        %v98275 = vsel /*vm=*/%vm98123, /*on_true_vy=*/%v98128, /*on_false_vx=*/%v98271 (stack43)
        %v98279 = vmul.f32 1.4140625, %v98275 (stack53)
        %v98282 = vpack.c.bf16 0.0, %v98279 (stack74)
        %120271 = vst [vmem:[%s280 + $0xe8] sm:$0xf] /*vst_source=*/%v98282 (stack75)
        %v98286 = vadd.s32 %v97361, %v1381 (stack39)
        %v98296 = vadd.s32 %v98286, %v415 (stack39)
        %vm98300 = vcmp.lt.u32.totalorder %v98296, %v98286 (stack42)
        %vm98305 = vcmp.lt.u32.totalorder %v98286, %v1381 (stack42)
        %v98310 = vadd.s32 %v97344, %v1368 (stack39)
        %v98314 = vadd.s32 1, %v98310 (stack39)
        %v98318 = vsel /*vm=*/%vm98305, /*on_true_vy=*/%v98314, /*on_false_vx=*/%v98310 (stack43)
        %v98322 = vadd.s32 1, %v98318 (stack39)
        %v98326 = vsel /*vm=*/%vm98300, /*on_true_vy=*/%v98322, /*on_false_vx=*/%v98318 (stack43)
        %v98331 = vadd.s32 %v98326, %v10 (stack39)
        %v98335 = vadd.s32 %v98296, %v9 (stack39)
        %v98339 = vadd.s32 %v98335, %v98331 (stack39)
        %v98341 = vshll.u32 %v98335, 13 (stack44)
        %v98342 = vshrl.u32 %v98335, 19 (stack45)
        %v98343 = vor.u32 %v98342, %v98341 (stack46)
        %v98344 = vxor.u32 %v98343, %v98339 (stack47)
        %v98347 = vadd.s32 %v98344, %v98339 (stack39)
        %v98349 = vshll.u32 %v98344, 15 (stack44)
        %v98350 = vshrl.u32 %v98344, 17 (stack45)
        %v98351 = vor.u32 %v98350, %v98349 (stack46)
        %v98352 = vxor.u32 %v98351, %v98347 (stack47)
        %v98355 = vadd.s32 %v98352, %v98347 (stack39)
        %v98357 = vshll.u32 %v98352, 26 (stack44)
        %v98358 = vshrl.u32 %v98352, 6 (stack45)
        %v98359 = vor.u32 %v98358, %v98357 (stack46)
        %v98360 = vxor.u32 %v98359, %v98355 (stack47)
        %v98363 = vadd.s32 %v98360, %v98355 (stack39)
        %v98367 = vadd.s32 %v98363, %v9 (stack39)
        %v98369 = vshll.u32 %v98360, 6 (stack44)
        %v98370 = vshrl.u32 %v98360, 26 (stack45)
        %v98371 = vor.u32 %v98370, %v98369 (stack46)
        %v98372 = vxor.u32 %v98371, %v98363 (stack47)
        %v98375 = vadd.s32 %v98372, %v8 (stack39)
        %v98379 = vadd.s32 1, %v98375 (stack39)
        %v98383 = vadd.s32 %v98379, %v98367 (stack39)
        %v98385 = vshll.u32 %v98379, 17 (stack44)
        %v98386 = vshrl.u32 %v98379, 15 (stack45)
        %v98387 = vor.u32 %v98386, %v98385 (stack46)
        %v98388 = vxor.u32 %v98387, %v98383 (stack47)
        %v98391 = vadd.s32 %v98388, %v98383 (stack39)
        %v98393 = vshll.u32 %v98388, 29 (stack44)
        %v98394 = vshrl.u32 %v98388, 3 (stack45)
        %v98395 = vor.u32 %v98394, %v98393 (stack46)
        %v98396 = vxor.u32 %v98395, %v98391 (stack47)
        %v98399 = vadd.s32 %v98396, %v98391 (stack39)
        %v98401 = vshll.u32 %v98396, 16 (stack44)
        %v98402 = vshrl.u32 %v98396, 16 (stack45)
        %v98403 = vor.u32 %v98402, %v98401 (stack46)
        %v98404 = vxor.u32 %v98403, %v98399 (stack47)
        %v98407 = vadd.s32 %v98404, %v98399 (stack39)
        %v98411 = vadd.s32 %v98407, %v8 (stack39)
        %v98413 = vshll.u32 %v98404, 24 (stack44)
        %v98414 = vshrl.u32 %v98404, 8 (stack45)
        %v98415 = vor.u32 %v98414, %v98413 (stack46)
        %v98416 = vxor.u32 %v98415, %v98407 (stack47)
        %v98419 = vadd.s32 %v98416, %v10 (stack39)
        %v98423 = vadd.s32 2, %v98419 (stack39)
        %v98427 = vadd.s32 %v98423, %v98411 (stack39)
        %v98429 = vshll.u32 %v98423, 13 (stack44)
        %v98430 = vshrl.u32 %v98423, 19 (stack45)
        %v98431 = vor.u32 %v98430, %v98429 (stack46)
        %v98432 = vxor.u32 %v98431, %v98427 (stack47)
        %v98435 = vadd.s32 %v98432, %v98427 (stack39)
        %v98437 = vshll.u32 %v98432, 15 (stack44)
        %v98438 = vshrl.u32 %v98432, 17 (stack45)
        %v98439 = vor.u32 %v98438, %v98437 (stack46)
        %v98440 = vxor.u32 %v98439, %v98435 (stack47)
        %v98443 = vadd.s32 %v98440, %v98435 (stack39)
        %v98445 = vshll.u32 %v98440, 26 (stack44)
        %v98446 = vshrl.u32 %v98440, 6 (stack45)
        %v98447 = vor.u32 %v98446, %v98445 (stack46)
        %v98448 = vxor.u32 %v98447, %v98443 (stack47)
        %v98451 = vadd.s32 %v98448, %v98443 (stack39)
        %v98455 = vadd.s32 %v98451, %v10 (stack39)
        %v98457 = vshll.u32 %v98448, 6 (stack44)
        %v98458 = vshrl.u32 %v98448, 26 (stack45)
        %v98459 = vor.u32 %v98458, %v98457 (stack46)
        %v98460 = vxor.u32 %v98459, %v98451 (stack47)
        %v98463 = vadd.s32 %v98460, %v9 (stack39)
        %v98467 = vadd.s32 3, %v98463 (stack39)
        %v98471 = vadd.s32 %v98467, %v98455 (stack39)
        %v98473 = vshll.u32 %v98467, 17 (stack44)
        %v98474 = vshrl.u32 %v98467, 15 (stack45)
        %v98475 = vor.u32 %v98474, %v98473 (stack46)
        %v98476 = vxor.u32 %v98475, %v98471 (stack47)
        %v98479 = vadd.s32 %v98476, %v98471 (stack39)
        %v98481 = vshll.u32 %v98476, 29 (stack44)
        %v98482 = vshrl.u32 %v98476, 3 (stack45)
        %v98483 = vor.u32 %v98482, %v98481 (stack46)
        %v98484 = vxor.u32 %v98483, %v98479 (stack47)
        %v98487 = vadd.s32 %v98484, %v98479 (stack39)
        %v98489 = vshll.u32 %v98484, 16 (stack44)
        %v98490 = vshrl.u32 %v98484, 16 (stack45)
        %v98491 = vor.u32 %v98490, %v98489 (stack46)
        %v98492 = vxor.u32 %v98491, %v98487 (stack47)
        %v98495 = vadd.s32 %v98492, %v98487 (stack39)
        %v98499 = vadd.s32 %v98495, %v9 (stack39)
        %v98501 = vshll.u32 %v98492, 24 (stack44)
        %v98502 = vshrl.u32 %v98492, 8 (stack45)
        %v98503 = vor.u32 %v98502, %v98501 (stack46)
        %v98504 = vxor.u32 %v98503, %v98495 (stack47)
        %v98507 = vadd.s32 %v98504, %v8 (stack39)
        %v98511 = vadd.s32 4, %v98507 (stack39)
        %v98515 = vadd.s32 %v98511, %v98499 (stack39)
        %v98517 = vshll.u32 %v98511, 13 (stack44)
        %v98518 = vshrl.u32 %v98511, 19 (stack45)
        %v98519 = vor.u32 %v98518, %v98517 (stack46)
        %v98520 = vxor.u32 %v98519, %v98515 (stack47)
        %v98523 = vadd.s32 %v98520, %v98515 (stack39)
        %v98525 = vshll.u32 %v98520, 15 (stack44)
        %v98526 = vshrl.u32 %v98520, 17 (stack45)
        %v98527 = vor.u32 %v98526, %v98525 (stack46)
        %v98528 = vxor.u32 %v98527, %v98523 (stack47)
        %v98531 = vadd.s32 %v98528, %v98523 (stack39)
        %v98533 = vshll.u32 %v98528, 26 (stack44)
        %v98534 = vshrl.u32 %v98528, 6 (stack45)
        %v98535 = vor.u32 %v98534, %v98533 (stack46)
        %v98536 = vxor.u32 %v98535, %v98531 (stack47)
        %v98539 = vadd.s32 %v98536, %v98531 (stack39)
        %v98543 = vadd.s32 %v98539, %v8 (stack39)
        %v98545 = vshll.u32 %v98536, 6 (stack44)
        %v98546 = vshrl.u32 %v98536, 26 (stack45)
        %v98547 = vor.u32 %v98546, %v98545 (stack46)
        %v98548 = vxor.u32 %v98547, %v98539 (stack47)
        %v98551 = vadd.s32 %v98548, %v10 (stack39)
        %v98555 = vadd.s32 5, %v98551 (stack39)
        %v98557 = vxor.u32 %v98555, %v98543 (stack47)
        %v98558 = vand.u32.u8 255, %v98557 (stack48)
        %v98559 = vand.u32 65535, %v98558 (stack49)
        %v98560 = vshrl.u32 %v98559, 1 (stack50)
        %v98561 = vor.u32 16256, %v98560 (stack46)
        %v98562 = vand.u32.u16 65535, %v98561 (stack51)
        %v120272 = vadd.low.f32.bf16 -1.0, %v98562 (stack52)
        %v98571 = vmul.f32 2.0, %v120272 (stack53)
        %v98575 = vadd.f32 -0.99609375, %v98571 (stack52)
        %v98579 = vmax.f32 %v98575, -0.99609375 (stack54)
        %v98581 = vand.u32 2147483647, %v98579 (stack55)
        %vm98584 = vcmp.eq.f32.partialorder %v98581, 1.0 (stack56)
        %v98589 = vmul.f32 inf, %v98579 (stack53)
        %v98591 = vxor.u32 2147483648, %v98579 (stack57)
        %v98594 = vmul.f32 %v98591, %v98579 (stack53)
        %v98596 = vadd.f32 1.0, %v98594 (stack58)
        %v98597 = vlog2.pop %v98596 (stack59)
        %v98598 = vmul.f32 0.6931472, %v98597 (stack60)
        %v98599 = vmul.f32 -0.5, %v98594 (stack61)
        %v98600 = vadd.f32 1.0, %v98599 (stack62)
        %v98601 = vmul.f32 %v98600, %v98594 (stack63)
        %v98602 = vand.u32 2147483647, %v98594 (stack64)
        %vm98603 = vcmp.lt.f32.partialorder %v98602, 0.0004427343 (stack65)
        %v98604 = vsel /*vm=*/%vm98603, /*on_true_vy=*/%v98601, /*on_false_vx=*/%v98598 (stack66)
        %v98605 = vxor.u32 2147483648, %v98604 (stack57)
        %vm98608 = vcmp.lt.f32.partialorder %v98605, 5.0 (stack56)
        %v98613 = vsel /*vm=*/%vm98608, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v98617 = vsel /*vm=*/%vm98608, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v98621 = vsel /*vm=*/%vm98608, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v98625 = vsel /*vm=*/%vm98608, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v98629 = vsel /*vm=*/%vm98608, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v98633 = vsel /*vm=*/%vm98608, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v98637 = vsel /*vm=*/%vm98608, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v98641 = vsel /*vm=*/%vm98608, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v98645 = vsel /*vm=*/%vm98608, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v98649 = vadd.f32 -2.5, %v98605 (stack52)
        %v98651 = vrsqrt.pop %v98605 (stack67)
        %v98652 = vmul.f32 %v98651, %v98605 (stack68)
        %vm98653 = vcmp.eq.f32.partialorder %v98605, inf (stack69)
        %v98654 = vsel /*vm=*/%vm98653, /*on_true_vy=*/%v98605, /*on_false_vx=*/%v98652 (stack70)
        %vm98655 = vcmp.eq.f32.partialorder %v98605, 0.0 (stack71)
        %v98656 = vand.u32 2147483648, %v98605 (stack72)
        %v98657 = vsel /*vm=*/%vm98655, /*on_true_vy=*/%v98656, /*on_false_vx=*/%v98654 (stack73)
        %v98660 = vadd.f32 -3.0, %v98657 (stack52)
        %v98664 = vsel /*vm=*/%vm98608, /*on_true_vy=*/%v98649, /*on_false_vx=*/%v98660 (stack43)
        %v98668 = vmul.f32 %v98664, %v98645 (stack53)
        %v98672 = vadd.f32 %v98668, %v98641 (stack52)
        %v98676 = vmul.f32 %v98672, %v98664 (stack53)
        %v98680 = vadd.f32 %v98676, %v98637 (stack52)
        %v98684 = vmul.f32 %v98680, %v98664 (stack53)
        %v98688 = vadd.f32 %v98684, %v98633 (stack52)
        %v98692 = vmul.f32 %v98688, %v98664 (stack53)
        %v98696 = vadd.f32 %v98692, %v98629 (stack52)
        %v98700 = vmul.f32 %v98696, %v98664 (stack53)
        %v98704 = vadd.f32 %v98700, %v98625 (stack52)
        %v98708 = vmul.f32 %v98704, %v98664 (stack53)
        %v98712 = vadd.f32 %v98708, %v98621 (stack52)
        %v98716 = vmul.f32 %v98712, %v98664 (stack53)
        %v98720 = vadd.f32 %v98716, %v98617 (stack52)
        %v98724 = vmul.f32 %v98720, %v98664 (stack53)
        %v98728 = vadd.f32 %v98724, %v98613 (stack52)
        %v98732 = vmul.f32 %v98728, %v98579 (stack53)
        %v98736 = vsel /*vm=*/%vm98584, /*on_true_vy=*/%v98589, /*on_false_vx=*/%v98732 (stack43)
        %v98740 = vmul.f32 1.4140625, %v98736 (stack53)
        %v98743 = vpack.c.bf16 0.0, %v98740 (stack74)
        %120273 = vst [vmem:[%s280 + $0x168] sm:$0xf] /*vst_source=*/%v98743 (stack75)
        %v98747 = vadd.s32 %v97361, %v1868 (stack39)
        %v98757 = vadd.s32 %v98747, %v415 (stack39)
        %vm98761 = vcmp.lt.u32.totalorder %v98757, %v98747 (stack42)
        %vm98766 = vcmp.lt.u32.totalorder %v98747, %v1868 (stack42)
        %v98771 = vadd.s32 %v97344, %v1855 (stack39)
        %v98775 = vadd.s32 1, %v98771 (stack39)
        %v98779 = vsel /*vm=*/%vm98766, /*on_true_vy=*/%v98775, /*on_false_vx=*/%v98771 (stack43)
        %v98783 = vadd.s32 1, %v98779 (stack39)
        %v98787 = vsel /*vm=*/%vm98761, /*on_true_vy=*/%v98783, /*on_false_vx=*/%v98779 (stack43)
        %v98792 = vadd.s32 %v98787, %v10 (stack39)
        %v98796 = vadd.s32 %v98757, %v9 (stack39)
        %v98800 = vadd.s32 %v98796, %v98792 (stack39)
        %v98802 = vshll.u32 %v98796, 13 (stack44)
        %v98803 = vshrl.u32 %v98796, 19 (stack45)
        %v98804 = vor.u32 %v98803, %v98802 (stack46)
        %v98805 = vxor.u32 %v98804, %v98800 (stack47)
        %v98808 = vadd.s32 %v98805, %v98800 (stack39)
        %v98810 = vshll.u32 %v98805, 15 (stack44)
        %v98811 = vshrl.u32 %v98805, 17 (stack45)
        %v98812 = vor.u32 %v98811, %v98810 (stack46)
        %v98813 = vxor.u32 %v98812, %v98808 (stack47)
        %v98816 = vadd.s32 %v98813, %v98808 (stack39)
        %v98818 = vshll.u32 %v98813, 26 (stack44)
        %v98819 = vshrl.u32 %v98813, 6 (stack45)
        %v98820 = vor.u32 %v98819, %v98818 (stack46)
        %v98821 = vxor.u32 %v98820, %v98816 (stack47)
        %v98824 = vadd.s32 %v98821, %v98816 (stack39)
        %v98828 = vadd.s32 %v98824, %v9 (stack39)
        %v98830 = vshll.u32 %v98821, 6 (stack44)
        %v98831 = vshrl.u32 %v98821, 26 (stack45)
        %v98832 = vor.u32 %v98831, %v98830 (stack46)
        %v98833 = vxor.u32 %v98832, %v98824 (stack47)
        %v98836 = vadd.s32 %v98833, %v8 (stack39)
        %v98840 = vadd.s32 1, %v98836 (stack39)
        %v98844 = vadd.s32 %v98840, %v98828 (stack39)
        %v98846 = vshll.u32 %v98840, 17 (stack44)
        %v98847 = vshrl.u32 %v98840, 15 (stack45)
        %v98848 = vor.u32 %v98847, %v98846 (stack46)
        %v98849 = vxor.u32 %v98848, %v98844 (stack47)
        %v98852 = vadd.s32 %v98849, %v98844 (stack39)
        %v98854 = vshll.u32 %v98849, 29 (stack44)
        %v98855 = vshrl.u32 %v98849, 3 (stack45)
        %v98856 = vor.u32 %v98855, %v98854 (stack46)
        %v98857 = vxor.u32 %v98856, %v98852 (stack47)
        %v98860 = vadd.s32 %v98857, %v98852 (stack39)
        %v98862 = vshll.u32 %v98857, 16 (stack44)
        %v98863 = vshrl.u32 %v98857, 16 (stack45)
        %v98864 = vor.u32 %v98863, %v98862 (stack46)
        %v98865 = vxor.u32 %v98864, %v98860 (stack47)
        %v98868 = vadd.s32 %v98865, %v98860 (stack39)
        %v98872 = vadd.s32 %v98868, %v8 (stack39)
        %v98874 = vshll.u32 %v98865, 24 (stack44)
        %v98875 = vshrl.u32 %v98865, 8 (stack45)
        %v98876 = vor.u32 %v98875, %v98874 (stack46)
        %v98877 = vxor.u32 %v98876, %v98868 (stack47)
        %v98880 = vadd.s32 %v98877, %v10 (stack39)
        %v98884 = vadd.s32 2, %v98880 (stack39)
        %v98888 = vadd.s32 %v98884, %v98872 (stack39)
        %v98890 = vshll.u32 %v98884, 13 (stack44)
        %v98891 = vshrl.u32 %v98884, 19 (stack45)
        %v98892 = vor.u32 %v98891, %v98890 (stack46)
        %v98893 = vxor.u32 %v98892, %v98888 (stack47)
        %v98896 = vadd.s32 %v98893, %v98888 (stack39)
        %v98898 = vshll.u32 %v98893, 15 (stack44)
        %v98899 = vshrl.u32 %v98893, 17 (stack45)
        %v98900 = vor.u32 %v98899, %v98898 (stack46)
        %v98901 = vxor.u32 %v98900, %v98896 (stack47)
        %v98904 = vadd.s32 %v98901, %v98896 (stack39)
        %v98906 = vshll.u32 %v98901, 26 (stack44)
        %v98907 = vshrl.u32 %v98901, 6 (stack45)
        %v98908 = vor.u32 %v98907, %v98906 (stack46)
        %v98909 = vxor.u32 %v98908, %v98904 (stack47)
        %v98912 = vadd.s32 %v98909, %v98904 (stack39)
        %v98916 = vadd.s32 %v98912, %v10 (stack39)
        %v98918 = vshll.u32 %v98909, 6 (stack44)
        %v98919 = vshrl.u32 %v98909, 26 (stack45)
        %v98920 = vor.u32 %v98919, %v98918 (stack46)
        %v98921 = vxor.u32 %v98920, %v98912 (stack47)
        %v98924 = vadd.s32 %v98921, %v9 (stack39)
        %v98928 = vadd.s32 3, %v98924 (stack39)
        %v98932 = vadd.s32 %v98928, %v98916 (stack39)
        %v98934 = vshll.u32 %v98928, 17 (stack44)
        %v98935 = vshrl.u32 %v98928, 15 (stack45)
        %v98936 = vor.u32 %v98935, %v98934 (stack46)
        %v98937 = vxor.u32 %v98936, %v98932 (stack47)
        %v98940 = vadd.s32 %v98937, %v98932 (stack39)
        %v98942 = vshll.u32 %v98937, 29 (stack44)
        %v98943 = vshrl.u32 %v98937, 3 (stack45)
        %v98944 = vor.u32 %v98943, %v98942 (stack46)
        %v98945 = vxor.u32 %v98944, %v98940 (stack47)
        %v98948 = vadd.s32 %v98945, %v98940 (stack39)
        %v98950 = vshll.u32 %v98945, 16 (stack44)
        %v98951 = vshrl.u32 %v98945, 16 (stack45)
        %v98952 = vor.u32 %v98951, %v98950 (stack46)
        %v98953 = vxor.u32 %v98952, %v98948 (stack47)
        %v98956 = vadd.s32 %v98953, %v98948 (stack39)
        %v98960 = vadd.s32 %v98956, %v9 (stack39)
        %v98962 = vshll.u32 %v98953, 24 (stack44)
        %v98963 = vshrl.u32 %v98953, 8 (stack45)
        %v98964 = vor.u32 %v98963, %v98962 (stack46)
        %v98965 = vxor.u32 %v98964, %v98956 (stack47)
        %v98968 = vadd.s32 %v98965, %v8 (stack39)
        %v98972 = vadd.s32 4, %v98968 (stack39)
        %v98976 = vadd.s32 %v98972, %v98960 (stack39)
        %v98978 = vshll.u32 %v98972, 13 (stack44)
        %v98979 = vshrl.u32 %v98972, 19 (stack45)
        %v98980 = vor.u32 %v98979, %v98978 (stack46)
        %v98981 = vxor.u32 %v98980, %v98976 (stack47)
        %v98984 = vadd.s32 %v98981, %v98976 (stack39)
        %v98986 = vshll.u32 %v98981, 15 (stack44)
        %v98987 = vshrl.u32 %v98981, 17 (stack45)
        %v98988 = vor.u32 %v98987, %v98986 (stack46)
        %v98989 = vxor.u32 %v98988, %v98984 (stack47)
        %v98992 = vadd.s32 %v98989, %v98984 (stack39)
        %v98994 = vshll.u32 %v98989, 26 (stack44)
        %v98995 = vshrl.u32 %v98989, 6 (stack45)
        %v98996 = vor.u32 %v98995, %v98994 (stack46)
        %v98997 = vxor.u32 %v98996, %v98992 (stack47)
        %v99000 = vadd.s32 %v98997, %v98992 (stack39)
        %v99004 = vadd.s32 %v99000, %v8 (stack39)
        %v99006 = vshll.u32 %v98997, 6 (stack44)
        %v99007 = vshrl.u32 %v98997, 26 (stack45)
        %v99008 = vor.u32 %v99007, %v99006 (stack46)
        %v99009 = vxor.u32 %v99008, %v99000 (stack47)
        %v99012 = vadd.s32 %v99009, %v10 (stack39)
        %v99016 = vadd.s32 5, %v99012 (stack39)
        %v99018 = vxor.u32 %v99016, %v99004 (stack47)
        %v99019 = vand.u32.u8 255, %v99018 (stack48)
        %v99020 = vand.u32 65535, %v99019 (stack49)
        %v99021 = vshrl.u32 %v99020, 1 (stack50)
        %v99022 = vor.u32 16256, %v99021 (stack46)
        %v99023 = vand.u32.u16 65535, %v99022 (stack51)
        %v120274 = vadd.low.f32.bf16 -1.0, %v99023 (stack52)
        %v99032 = vmul.f32 2.0, %v120274 (stack53)
        %v99036 = vadd.f32 -0.99609375, %v99032 (stack52)
        %v99040 = vmax.f32 %v99036, -0.99609375 (stack54)
        %v99042 = vand.u32 2147483647, %v99040 (stack55)
        %vm99045 = vcmp.eq.f32.partialorder %v99042, 1.0 (stack56)
        %v99050 = vmul.f32 inf, %v99040 (stack53)
        %v99052 = vxor.u32 2147483648, %v99040 (stack57)
        %v99055 = vmul.f32 %v99052, %v99040 (stack53)
        %v99057 = vadd.f32 1.0, %v99055 (stack58)
        %v99058 = vlog2.pop %v99057 (stack59)
        %v99059 = vmul.f32 0.6931472, %v99058 (stack60)
        %v99060 = vmul.f32 -0.5, %v99055 (stack61)
        %v99061 = vadd.f32 1.0, %v99060 (stack62)
        %v99062 = vmul.f32 %v99061, %v99055 (stack63)
        %v99063 = vand.u32 2147483647, %v99055 (stack64)
        %vm99064 = vcmp.lt.f32.partialorder %v99063, 0.0004427343 (stack65)
        %v99065 = vsel /*vm=*/%vm99064, /*on_true_vy=*/%v99062, /*on_false_vx=*/%v99059 (stack66)
        %v99066 = vxor.u32 2147483648, %v99065 (stack57)
        %vm99069 = vcmp.lt.f32.partialorder %v99066, 5.0 (stack56)
        %v99074 = vsel /*vm=*/%vm99069, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v99078 = vsel /*vm=*/%vm99069, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v99082 = vsel /*vm=*/%vm99069, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v99086 = vsel /*vm=*/%vm99069, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v99090 = vsel /*vm=*/%vm99069, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v99094 = vsel /*vm=*/%vm99069, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v99098 = vsel /*vm=*/%vm99069, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v99102 = vsel /*vm=*/%vm99069, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v99106 = vsel /*vm=*/%vm99069, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v99110 = vadd.f32 -2.5, %v99066 (stack52)
        %v99112 = vrsqrt.pop %v99066 (stack67)
        %v99113 = vmul.f32 %v99112, %v99066 (stack68)
        %vm99114 = vcmp.eq.f32.partialorder %v99066, inf (stack69)
        %v99115 = vsel /*vm=*/%vm99114, /*on_true_vy=*/%v99066, /*on_false_vx=*/%v99113 (stack70)
        %vm99116 = vcmp.eq.f32.partialorder %v99066, 0.0 (stack71)
        %v99117 = vand.u32 2147483648, %v99066 (stack72)
        %v99118 = vsel /*vm=*/%vm99116, /*on_true_vy=*/%v99117, /*on_false_vx=*/%v99115 (stack73)
        %v99121 = vadd.f32 -3.0, %v99118 (stack52)
        %v99125 = vsel /*vm=*/%vm99069, /*on_true_vy=*/%v99110, /*on_false_vx=*/%v99121 (stack43)
        %v99129 = vmul.f32 %v99125, %v99106 (stack53)
        %v99133 = vadd.f32 %v99129, %v99102 (stack52)
        %v99137 = vmul.f32 %v99133, %v99125 (stack53)
        %v99141 = vadd.f32 %v99137, %v99098 (stack52)
        %v99145 = vmul.f32 %v99141, %v99125 (stack53)
        %v99149 = vadd.f32 %v99145, %v99094 (stack52)
        %v99153 = vmul.f32 %v99149, %v99125 (stack53)
        %v99157 = vadd.f32 %v99153, %v99090 (stack52)
        %v99161 = vmul.f32 %v99157, %v99125 (stack53)
        %v99165 = vadd.f32 %v99161, %v99086 (stack52)
        %v99169 = vmul.f32 %v99165, %v99125 (stack53)
        %v99173 = vadd.f32 %v99169, %v99082 (stack52)
        %v99177 = vmul.f32 %v99173, %v99125 (stack53)
        %v99181 = vadd.f32 %v99177, %v99078 (stack52)
        %v99185 = vmul.f32 %v99181, %v99125 (stack53)
        %v99189 = vadd.f32 %v99185, %v99074 (stack52)
        %v99193 = vmul.f32 %v99189, %v99040 (stack53)
        %v99197 = vsel /*vm=*/%vm99045, /*on_true_vy=*/%v99050, /*on_false_vx=*/%v99193 (stack43)
        %v99201 = vmul.f32 1.4140625, %v99197 (stack53)
        %v99204 = vpack.c.bf16 0.0, %v99201 (stack74)
        %120275 = vst [vmem:[%s280 + $0x1e8] sm:$0xf] /*vst_source=*/%v99204 (stack75)
        %v99208 = vadd.s32 %v97361, %v2355 (stack39)
        %v99218 = vadd.s32 %v99208, %v415 (stack39)
        %vm99222 = vcmp.lt.u32.totalorder %v99218, %v99208 (stack42)
        %vm99227 = vcmp.lt.u32.totalorder %v99208, %v2355 (stack42)
        %v99232 = vadd.s32 %v97344, %v2342 (stack39)
        %v99236 = vadd.s32 1, %v99232 (stack39)
        %v99240 = vsel /*vm=*/%vm99227, /*on_true_vy=*/%v99236, /*on_false_vx=*/%v99232 (stack43)
        %v99244 = vadd.s32 1, %v99240 (stack39)
        %v99248 = vsel /*vm=*/%vm99222, /*on_true_vy=*/%v99244, /*on_false_vx=*/%v99240 (stack43)
        %v99253 = vadd.s32 %v99248, %v10 (stack39)
        %v99257 = vadd.s32 %v99218, %v9 (stack39)
        %v99261 = vadd.s32 %v99257, %v99253 (stack39)
        %v99263 = vshll.u32 %v99257, 13 (stack44)
        %v99264 = vshrl.u32 %v99257, 19 (stack45)
        %v99265 = vor.u32 %v99264, %v99263 (stack46)
        %v99266 = vxor.u32 %v99265, %v99261 (stack47)
        %v99269 = vadd.s32 %v99266, %v99261 (stack39)
        %v99271 = vshll.u32 %v99266, 15 (stack44)
        %v99272 = vshrl.u32 %v99266, 17 (stack45)
        %v99273 = vor.u32 %v99272, %v99271 (stack46)
        %v99274 = vxor.u32 %v99273, %v99269 (stack47)
        %v99277 = vadd.s32 %v99274, %v99269 (stack39)
        %v99279 = vshll.u32 %v99274, 26 (stack44)
        %v99280 = vshrl.u32 %v99274, 6 (stack45)
        %v99281 = vor.u32 %v99280, %v99279 (stack46)
        %v99282 = vxor.u32 %v99281, %v99277 (stack47)
        %v99285 = vadd.s32 %v99282, %v99277 (stack39)
        %v99289 = vadd.s32 %v99285, %v9 (stack39)
        %v99291 = vshll.u32 %v99282, 6 (stack44)
        %v99292 = vshrl.u32 %v99282, 26 (stack45)
        %v99293 = vor.u32 %v99292, %v99291 (stack46)
        %v99294 = vxor.u32 %v99293, %v99285 (stack47)
        %v99297 = vadd.s32 %v99294, %v8 (stack39)
        %v99301 = vadd.s32 1, %v99297 (stack39)
        %v99305 = vadd.s32 %v99301, %v99289 (stack39)
        %v99307 = vshll.u32 %v99301, 17 (stack44)
        %v99308 = vshrl.u32 %v99301, 15 (stack45)
        %v99309 = vor.u32 %v99308, %v99307 (stack46)
        %v99310 = vxor.u32 %v99309, %v99305 (stack47)
        %v99313 = vadd.s32 %v99310, %v99305 (stack39)
        %v99315 = vshll.u32 %v99310, 29 (stack44)
        %v99316 = vshrl.u32 %v99310, 3 (stack45)
        %v99317 = vor.u32 %v99316, %v99315 (stack46)
        %v99318 = vxor.u32 %v99317, %v99313 (stack47)
        %v99321 = vadd.s32 %v99318, %v99313 (stack39)
        %v99323 = vshll.u32 %v99318, 16 (stack44)
        %v99324 = vshrl.u32 %v99318, 16 (stack45)
        %v99325 = vor.u32 %v99324, %v99323 (stack46)
        %v99326 = vxor.u32 %v99325, %v99321 (stack47)
        %v99329 = vadd.s32 %v99326, %v99321 (stack39)
        %v99333 = vadd.s32 %v99329, %v8 (stack39)
        %v99335 = vshll.u32 %v99326, 24 (stack44)
        %v99336 = vshrl.u32 %v99326, 8 (stack45)
        %v99337 = vor.u32 %v99336, %v99335 (stack46)
        %v99338 = vxor.u32 %v99337, %v99329 (stack47)
        %v99341 = vadd.s32 %v99338, %v10 (stack39)
        %v99345 = vadd.s32 2, %v99341 (stack39)
        %v99349 = vadd.s32 %v99345, %v99333 (stack39)
        %v99351 = vshll.u32 %v99345, 13 (stack44)
        %v99352 = vshrl.u32 %v99345, 19 (stack45)
        %v99353 = vor.u32 %v99352, %v99351 (stack46)
        %v99354 = vxor.u32 %v99353, %v99349 (stack47)
        %v99357 = vadd.s32 %v99354, %v99349 (stack39)
        %v99359 = vshll.u32 %v99354, 15 (stack44)
        %v99360 = vshrl.u32 %v99354, 17 (stack45)
        %v99361 = vor.u32 %v99360, %v99359 (stack46)
        %v99362 = vxor.u32 %v99361, %v99357 (stack47)
        %v99365 = vadd.s32 %v99362, %v99357 (stack39)
        %v99367 = vshll.u32 %v99362, 26 (stack44)
        %v99368 = vshrl.u32 %v99362, 6 (stack45)
        %v99369 = vor.u32 %v99368, %v99367 (stack46)
        %v99370 = vxor.u32 %v99369, %v99365 (stack47)
        %v99373 = vadd.s32 %v99370, %v99365 (stack39)
        %v99377 = vadd.s32 %v99373, %v10 (stack39)
        %v99379 = vshll.u32 %v99370, 6 (stack44)
        %v99380 = vshrl.u32 %v99370, 26 (stack45)
        %v99381 = vor.u32 %v99380, %v99379 (stack46)
        %v99382 = vxor.u32 %v99381, %v99373 (stack47)
        %v99385 = vadd.s32 %v99382, %v9 (stack39)
        %v99389 = vadd.s32 3, %v99385 (stack39)
        %v99393 = vadd.s32 %v99389, %v99377 (stack39)
        %v99395 = vshll.u32 %v99389, 17 (stack44)
        %v99396 = vshrl.u32 %v99389, 15 (stack45)
        %v99397 = vor.u32 %v99396, %v99395 (stack46)
        %v99398 = vxor.u32 %v99397, %v99393 (stack47)
        %v99401 = vadd.s32 %v99398, %v99393 (stack39)
        %v99403 = vshll.u32 %v99398, 29 (stack44)
        %v99404 = vshrl.u32 %v99398, 3 (stack45)
        %v99405 = vor.u32 %v99404, %v99403 (stack46)
        %v99406 = vxor.u32 %v99405, %v99401 (stack47)
        %v99409 = vadd.s32 %v99406, %v99401 (stack39)
        %v99411 = vshll.u32 %v99406, 16 (stack44)
        %v99412 = vshrl.u32 %v99406, 16 (stack45)
        %v99413 = vor.u32 %v99412, %v99411 (stack46)
        %v99414 = vxor.u32 %v99413, %v99409 (stack47)
        %v99417 = vadd.s32 %v99414, %v99409 (stack39)
        %v99421 = vadd.s32 %v99417, %v9 (stack39)
        %v99423 = vshll.u32 %v99414, 24 (stack44)
        %v99424 = vshrl.u32 %v99414, 8 (stack45)
        %v99425 = vor.u32 %v99424, %v99423 (stack46)
        %v99426 = vxor.u32 %v99425, %v99417 (stack47)
        %v99429 = vadd.s32 %v99426, %v8 (stack39)
        %v99433 = vadd.s32 4, %v99429 (stack39)
        %v99437 = vadd.s32 %v99433, %v99421 (stack39)
        %v99439 = vshll.u32 %v99433, 13 (stack44)
        %v99440 = vshrl.u32 %v99433, 19 (stack45)
        %v99441 = vor.u32 %v99440, %v99439 (stack46)
        %v99442 = vxor.u32 %v99441, %v99437 (stack47)
        %v99445 = vadd.s32 %v99442, %v99437 (stack39)
        %v99447 = vshll.u32 %v99442, 15 (stack44)
        %v99448 = vshrl.u32 %v99442, 17 (stack45)
        %v99449 = vor.u32 %v99448, %v99447 (stack46)
        %v99450 = vxor.u32 %v99449, %v99445 (stack47)
        %v99453 = vadd.s32 %v99450, %v99445 (stack39)
        %v99455 = vshll.u32 %v99450, 26 (stack44)
        %v99456 = vshrl.u32 %v99450, 6 (stack45)
        %v99457 = vor.u32 %v99456, %v99455 (stack46)
        %v99458 = vxor.u32 %v99457, %v99453 (stack47)
        %v99461 = vadd.s32 %v99458, %v99453 (stack39)
        %v99465 = vadd.s32 %v99461, %v8 (stack39)
        %v99467 = vshll.u32 %v99458, 6 (stack44)
        %v99468 = vshrl.u32 %v99458, 26 (stack45)
        %v99469 = vor.u32 %v99468, %v99467 (stack46)
        %v99470 = vxor.u32 %v99469, %v99461 (stack47)
        %v99473 = vadd.s32 %v99470, %v10 (stack39)
        %v99477 = vadd.s32 5, %v99473 (stack39)
        %v99479 = vxor.u32 %v99477, %v99465 (stack47)
        %v99480 = vand.u32.u8 255, %v99479 (stack48)
        %v99481 = vand.u32 65535, %v99480 (stack49)
        %v99482 = vshrl.u32 %v99481, 1 (stack50)
        %v99483 = vor.u32 16256, %v99482 (stack46)
        %v99484 = vand.u32.u16 65535, %v99483 (stack51)
        %v120276 = vadd.low.f32.bf16 -1.0, %v99484 (stack52)
        %v99493 = vmul.f32 2.0, %v120276 (stack53)
        %v99497 = vadd.f32 -0.99609375, %v99493 (stack52)
        %v99501 = vmax.f32 %v99497, -0.99609375 (stack54)
        %v99503 = vand.u32 2147483647, %v99501 (stack55)
        %vm99506 = vcmp.eq.f32.partialorder %v99503, 1.0 (stack56)
        %v99511 = vmul.f32 inf, %v99501 (stack53)
        %v99513 = vxor.u32 2147483648, %v99501 (stack57)
        %v99516 = vmul.f32 %v99513, %v99501 (stack53)
        %v99518 = vadd.f32 1.0, %v99516 (stack58)
        %v99519 = vlog2.pop %v99518 (stack59)
        %v99520 = vmul.f32 0.6931472, %v99519 (stack60)
        %v99521 = vmul.f32 -0.5, %v99516 (stack61)
        %v99522 = vadd.f32 1.0, %v99521 (stack62)
        %v99523 = vmul.f32 %v99522, %v99516 (stack63)
        %v99524 = vand.u32 2147483647, %v99516 (stack64)
        %vm99525 = vcmp.lt.f32.partialorder %v99524, 0.0004427343 (stack65)
        %v99526 = vsel /*vm=*/%vm99525, /*on_true_vy=*/%v99523, /*on_false_vx=*/%v99520 (stack66)
        %v99527 = vxor.u32 2147483648, %v99526 (stack57)
        %vm99530 = vcmp.lt.f32.partialorder %v99527, 5.0 (stack56)
        %v99535 = vsel /*vm=*/%vm99530, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v99539 = vsel /*vm=*/%vm99530, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v99543 = vsel /*vm=*/%vm99530, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v99547 = vsel /*vm=*/%vm99530, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v99551 = vsel /*vm=*/%vm99530, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v99555 = vsel /*vm=*/%vm99530, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v99559 = vsel /*vm=*/%vm99530, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v99563 = vsel /*vm=*/%vm99530, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v99567 = vsel /*vm=*/%vm99530, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v99571 = vadd.f32 -2.5, %v99527 (stack52)
        %v99573 = vrsqrt.pop %v99527 (stack67)
        %v99574 = vmul.f32 %v99573, %v99527 (stack68)
        %vm99575 = vcmp.eq.f32.partialorder %v99527, inf (stack69)
        %v99576 = vsel /*vm=*/%vm99575, /*on_true_vy=*/%v99527, /*on_false_vx=*/%v99574 (stack70)
        %vm99577 = vcmp.eq.f32.partialorder %v99527, 0.0 (stack71)
        %v99578 = vand.u32 2147483648, %v99527 (stack72)
        %v99579 = vsel /*vm=*/%vm99577, /*on_true_vy=*/%v99578, /*on_false_vx=*/%v99576 (stack73)
        %v99582 = vadd.f32 -3.0, %v99579 (stack52)
        %v99586 = vsel /*vm=*/%vm99530, /*on_true_vy=*/%v99571, /*on_false_vx=*/%v99582 (stack43)
        %v99590 = vmul.f32 %v99586, %v99567 (stack53)
        %v99594 = vadd.f32 %v99590, %v99563 (stack52)
        %v99598 = vmul.f32 %v99594, %v99586 (stack53)
        %v99602 = vadd.f32 %v99598, %v99559 (stack52)
        %v99606 = vmul.f32 %v99602, %v99586 (stack53)
        %v99610 = vadd.f32 %v99606, %v99555 (stack52)
        %v99614 = vmul.f32 %v99610, %v99586 (stack53)
        %v99618 = vadd.f32 %v99614, %v99551 (stack52)
        %v99622 = vmul.f32 %v99618, %v99586 (stack53)
        %v99626 = vadd.f32 %v99622, %v99547 (stack52)
        %v99630 = vmul.f32 %v99626, %v99586 (stack53)
        %v99634 = vadd.f32 %v99630, %v99543 (stack52)
        %v99638 = vmul.f32 %v99634, %v99586 (stack53)
        %v99642 = vadd.f32 %v99638, %v99539 (stack52)
        %v99646 = vmul.f32 %v99642, %v99586 (stack53)
        %v99650 = vadd.f32 %v99646, %v99535 (stack52)
        %v99654 = vmul.f32 %v99650, %v99501 (stack53)
        %v99658 = vsel /*vm=*/%vm99506, /*on_true_vy=*/%v99511, /*on_false_vx=*/%v99654 (stack43)
        %v99662 = vmul.f32 1.4140625, %v99658 (stack53)
        %v99665 = vpack.c.bf16 0.0, %v99662 (stack74)
        %120277 = vst [vmem:[%s280 + $0x268] sm:$0xf] /*vst_source=*/%v99665 (stack75)
        %v99669 = vadd.s32 %v97361, %v2842 (stack39)
        %v99679 = vadd.s32 %v99669, %v415 (stack39)
        %vm99683 = vcmp.lt.u32.totalorder %v99679, %v99669 (stack42)
        %vm99688 = vcmp.lt.u32.totalorder %v99669, %v2842 (stack42)
        %v99693 = vadd.s32 %v97344, %v2829 (stack39)
        %v99697 = vadd.s32 1, %v99693 (stack39)
        %v99701 = vsel /*vm=*/%vm99688, /*on_true_vy=*/%v99697, /*on_false_vx=*/%v99693 (stack43)
        %v99705 = vadd.s32 1, %v99701 (stack39)
        %v99709 = vsel /*vm=*/%vm99683, /*on_true_vy=*/%v99705, /*on_false_vx=*/%v99701 (stack43)
        %v99714 = vadd.s32 %v99709, %v10 (stack39)
        %v99718 = vadd.s32 %v99679, %v9 (stack39)
        %v99722 = vadd.s32 %v99718, %v99714 (stack39)
        %v99724 = vshll.u32 %v99718, 13 (stack44)
        %v99725 = vshrl.u32 %v99718, 19 (stack45)
        %v99726 = vor.u32 %v99725, %v99724 (stack46)
        %v99727 = vxor.u32 %v99726, %v99722 (stack47)
        %v99730 = vadd.s32 %v99727, %v99722 (stack39)
        %v99732 = vshll.u32 %v99727, 15 (stack44)
        %v99733 = vshrl.u32 %v99727, 17 (stack45)
        %v99734 = vor.u32 %v99733, %v99732 (stack46)
        %v99735 = vxor.u32 %v99734, %v99730 (stack47)
        %v99738 = vadd.s32 %v99735, %v99730 (stack39)
        %v99740 = vshll.u32 %v99735, 26 (stack44)
        %v99741 = vshrl.u32 %v99735, 6 (stack45)
        %v99742 = vor.u32 %v99741, %v99740 (stack46)
        %v99743 = vxor.u32 %v99742, %v99738 (stack47)
        %v99746 = vadd.s32 %v99743, %v99738 (stack39)
        %v99750 = vadd.s32 %v99746, %v9 (stack39)
        %v99752 = vshll.u32 %v99743, 6 (stack44)
        %v99753 = vshrl.u32 %v99743, 26 (stack45)
        %v99754 = vor.u32 %v99753, %v99752 (stack46)
        %v99755 = vxor.u32 %v99754, %v99746 (stack47)
        %v99758 = vadd.s32 %v99755, %v8 (stack39)
        %v99762 = vadd.s32 1, %v99758 (stack39)
        %v99766 = vadd.s32 %v99762, %v99750 (stack39)
        %v99768 = vshll.u32 %v99762, 17 (stack44)
        %v99769 = vshrl.u32 %v99762, 15 (stack45)
        %v99770 = vor.u32 %v99769, %v99768 (stack46)
        %v99771 = vxor.u32 %v99770, %v99766 (stack47)
        %v99774 = vadd.s32 %v99771, %v99766 (stack39)
        %v99776 = vshll.u32 %v99771, 29 (stack44)
        %v99777 = vshrl.u32 %v99771, 3 (stack45)
        %v99778 = vor.u32 %v99777, %v99776 (stack46)
        %v99779 = vxor.u32 %v99778, %v99774 (stack47)
        %v99782 = vadd.s32 %v99779, %v99774 (stack39)
        %v99784 = vshll.u32 %v99779, 16 (stack44)
        %v99785 = vshrl.u32 %v99779, 16 (stack45)
        %v99786 = vor.u32 %v99785, %v99784 (stack46)
        %v99787 = vxor.u32 %v99786, %v99782 (stack47)
        %v99790 = vadd.s32 %v99787, %v99782 (stack39)
        %v99794 = vadd.s32 %v99790, %v8 (stack39)
        %v99796 = vshll.u32 %v99787, 24 (stack44)
        %v99797 = vshrl.u32 %v99787, 8 (stack45)
        %v99798 = vor.u32 %v99797, %v99796 (stack46)
        %v99799 = vxor.u32 %v99798, %v99790 (stack47)
        %v99802 = vadd.s32 %v99799, %v10 (stack39)
        %v99806 = vadd.s32 2, %v99802 (stack39)
        %v99810 = vadd.s32 %v99806, %v99794 (stack39)
        %v99812 = vshll.u32 %v99806, 13 (stack44)
        %v99813 = vshrl.u32 %v99806, 19 (stack45)
        %v99814 = vor.u32 %v99813, %v99812 (stack46)
        %v99815 = vxor.u32 %v99814, %v99810 (stack47)
        %v99818 = vadd.s32 %v99815, %v99810 (stack39)
        %v99820 = vshll.u32 %v99815, 15 (stack44)
        %v99821 = vshrl.u32 %v99815, 17 (stack45)
        %v99822 = vor.u32 %v99821, %v99820 (stack46)
        %v99823 = vxor.u32 %v99822, %v99818 (stack47)
        %v99826 = vadd.s32 %v99823, %v99818 (stack39)
        %v99828 = vshll.u32 %v99823, 26 (stack44)
        %v99829 = vshrl.u32 %v99823, 6 (stack45)
        %v99830 = vor.u32 %v99829, %v99828 (stack46)
        %v99831 = vxor.u32 %v99830, %v99826 (stack47)
        %v99834 = vadd.s32 %v99831, %v99826 (stack39)
        %v99838 = vadd.s32 %v99834, %v10 (stack39)
        %v99840 = vshll.u32 %v99831, 6 (stack44)
        %v99841 = vshrl.u32 %v99831, 26 (stack45)
        %v99842 = vor.u32 %v99841, %v99840 (stack46)
        %v99843 = vxor.u32 %v99842, %v99834 (stack47)
        %v99846 = vadd.s32 %v99843, %v9 (stack39)
        %v99850 = vadd.s32 3, %v99846 (stack39)
        %v99854 = vadd.s32 %v99850, %v99838 (stack39)
        %v99856 = vshll.u32 %v99850, 17 (stack44)
        %v99857 = vshrl.u32 %v99850, 15 (stack45)
        %v99858 = vor.u32 %v99857, %v99856 (stack46)
        %v99859 = vxor.u32 %v99858, %v99854 (stack47)
        %v99862 = vadd.s32 %v99859, %v99854 (stack39)
        %v99864 = vshll.u32 %v99859, 29 (stack44)
        %v99865 = vshrl.u32 %v99859, 3 (stack45)
        %v99866 = vor.u32 %v99865, %v99864 (stack46)
        %v99867 = vxor.u32 %v99866, %v99862 (stack47)
        %v99870 = vadd.s32 %v99867, %v99862 (stack39)
        %v99872 = vshll.u32 %v99867, 16 (stack44)
        %v99873 = vshrl.u32 %v99867, 16 (stack45)
        %v99874 = vor.u32 %v99873, %v99872 (stack46)
        %v99875 = vxor.u32 %v99874, %v99870 (stack47)
        %v99878 = vadd.s32 %v99875, %v99870 (stack39)
        %v99882 = vadd.s32 %v99878, %v9 (stack39)
        %v99884 = vshll.u32 %v99875, 24 (stack44)
        %v99885 = vshrl.u32 %v99875, 8 (stack45)
        %v99886 = vor.u32 %v99885, %v99884 (stack46)
        %v99887 = vxor.u32 %v99886, %v99878 (stack47)
        %v99890 = vadd.s32 %v99887, %v8 (stack39)
        %v99894 = vadd.s32 4, %v99890 (stack39)
        %v99898 = vadd.s32 %v99894, %v99882 (stack39)
        %v99900 = vshll.u32 %v99894, 13 (stack44)
        %v99901 = vshrl.u32 %v99894, 19 (stack45)
        %v99902 = vor.u32 %v99901, %v99900 (stack46)
        %v99903 = vxor.u32 %v99902, %v99898 (stack47)
        %v99906 = vadd.s32 %v99903, %v99898 (stack39)
        %v99908 = vshll.u32 %v99903, 15 (stack44)
        %v99909 = vshrl.u32 %v99903, 17 (stack45)
        %v99910 = vor.u32 %v99909, %v99908 (stack46)
        %v99911 = vxor.u32 %v99910, %v99906 (stack47)
        %v99914 = vadd.s32 %v99911, %v99906 (stack39)
        %v99916 = vshll.u32 %v99911, 26 (stack44)
        %v99917 = vshrl.u32 %v99911, 6 (stack45)
        %v99918 = vor.u32 %v99917, %v99916 (stack46)
        %v99919 = vxor.u32 %v99918, %v99914 (stack47)
        %v99922 = vadd.s32 %v99919, %v99914 (stack39)
        %v99926 = vadd.s32 %v99922, %v8 (stack39)
        %v99928 = vshll.u32 %v99919, 6 (stack44)
        %v99929 = vshrl.u32 %v99919, 26 (stack45)
        %v99930 = vor.u32 %v99929, %v99928 (stack46)
        %v99931 = vxor.u32 %v99930, %v99922 (stack47)
        %v99934 = vadd.s32 %v99931, %v10 (stack39)
        %v99938 = vadd.s32 5, %v99934 (stack39)
        %v99940 = vxor.u32 %v99938, %v99926 (stack47)
        %v99941 = vand.u32.u8 255, %v99940 (stack48)
        %v99942 = vand.u32 65535, %v99941 (stack49)
        %v99943 = vshrl.u32 %v99942, 1 (stack50)
        %v99944 = vor.u32 16256, %v99943 (stack46)
        %v99945 = vand.u32.u16 65535, %v99944 (stack51)
        %v120278 = vadd.low.f32.bf16 -1.0, %v99945 (stack52)
        %v99954 = vmul.f32 2.0, %v120278 (stack53)
        %v99958 = vadd.f32 -0.99609375, %v99954 (stack52)
        %v99962 = vmax.f32 %v99958, -0.99609375 (stack54)
        %v99964 = vand.u32 2147483647, %v99962 (stack55)
        %vm99967 = vcmp.eq.f32.partialorder %v99964, 1.0 (stack56)
        %v99972 = vmul.f32 inf, %v99962 (stack53)
        %v99974 = vxor.u32 2147483648, %v99962 (stack57)
        %v99977 = vmul.f32 %v99974, %v99962 (stack53)
        %v99979 = vadd.f32 1.0, %v99977 (stack58)
        %v99980 = vlog2.pop %v99979 (stack59)
        %v99981 = vmul.f32 0.6931472, %v99980 (stack60)
        %v99982 = vmul.f32 -0.5, %v99977 (stack61)
        %v99983 = vadd.f32 1.0, %v99982 (stack62)
        %v99984 = vmul.f32 %v99983, %v99977 (stack63)
        %v99985 = vand.u32 2147483647, %v99977 (stack64)
        %vm99986 = vcmp.lt.f32.partialorder %v99985, 0.0004427343 (stack65)
        %v99987 = vsel /*vm=*/%vm99986, /*on_true_vy=*/%v99984, /*on_false_vx=*/%v99981 (stack66)
        %v99988 = vxor.u32 2147483648, %v99987 (stack57)
        %vm99991 = vcmp.lt.f32.partialorder %v99988, 5.0 (stack56)
        %v99996 = vsel /*vm=*/%vm99991, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v100000 = vsel /*vm=*/%vm99991, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v100004 = vsel /*vm=*/%vm99991, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v100008 = vsel /*vm=*/%vm99991, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v100012 = vsel /*vm=*/%vm99991, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v100016 = vsel /*vm=*/%vm99991, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v100020 = vsel /*vm=*/%vm99991, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v100024 = vsel /*vm=*/%vm99991, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v100028 = vsel /*vm=*/%vm99991, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v100032 = vadd.f32 -2.5, %v99988 (stack52)
        %v100034 = vrsqrt.pop %v99988 (stack67)
        %v100035 = vmul.f32 %v100034, %v99988 (stack68)
        %vm100036 = vcmp.eq.f32.partialorder %v99988, inf (stack69)
        %v100037 = vsel /*vm=*/%vm100036, /*on_true_vy=*/%v99988, /*on_false_vx=*/%v100035 (stack70)
        %vm100038 = vcmp.eq.f32.partialorder %v99988, 0.0 (stack71)
        %v100039 = vand.u32 2147483648, %v99988 (stack72)
        %v100040 = vsel /*vm=*/%vm100038, /*on_true_vy=*/%v100039, /*on_false_vx=*/%v100037 (stack73)
        %v100043 = vadd.f32 -3.0, %v100040 (stack52)
        %v100047 = vsel /*vm=*/%vm99991, /*on_true_vy=*/%v100032, /*on_false_vx=*/%v100043 (stack43)
        %v100051 = vmul.f32 %v100047, %v100028 (stack53)
        %v100055 = vadd.f32 %v100051, %v100024 (stack52)
        %v100059 = vmul.f32 %v100055, %v100047 (stack53)
        %v100063 = vadd.f32 %v100059, %v100020 (stack52)
        %v100067 = vmul.f32 %v100063, %v100047 (stack53)
        %v100071 = vadd.f32 %v100067, %v100016 (stack52)
        %v100075 = vmul.f32 %v100071, %v100047 (stack53)
        %v100079 = vadd.f32 %v100075, %v100012 (stack52)
        %v100083 = vmul.f32 %v100079, %v100047 (stack53)
        %v100087 = vadd.f32 %v100083, %v100008 (stack52)
        %v100091 = vmul.f32 %v100087, %v100047 (stack53)
        %v100095 = vadd.f32 %v100091, %v100004 (stack52)
        %v100099 = vmul.f32 %v100095, %v100047 (stack53)
        %v100103 = vadd.f32 %v100099, %v100000 (stack52)
        %v100107 = vmul.f32 %v100103, %v100047 (stack53)
        %v100111 = vadd.f32 %v100107, %v99996 (stack52)
        %v100115 = vmul.f32 %v100111, %v99962 (stack53)
        %v100119 = vsel /*vm=*/%vm99967, /*on_true_vy=*/%v99972, /*on_false_vx=*/%v100115 (stack43)
        %v100123 = vmul.f32 1.4140625, %v100119 (stack53)
        %v100126 = vpack.c.bf16 0.0, %v100123 (stack74)
        %120279 = vst [vmem:[%s280 + $0x2e8] sm:$0xf] /*vst_source=*/%v100126 (stack75)
        %v100130 = vadd.s32 %v97361, %v3329 (stack39)
        %v100140 = vadd.s32 %v100130, %v415 (stack39)
        %vm100144 = vcmp.lt.u32.totalorder %v100140, %v100130 (stack42)
        %vm100149 = vcmp.lt.u32.totalorder %v100130, %v3329 (stack42)
        %v100154 = vadd.s32 %v97344, %v3316 (stack39)
        %v100158 = vadd.s32 1, %v100154 (stack39)
        %v100162 = vsel /*vm=*/%vm100149, /*on_true_vy=*/%v100158, /*on_false_vx=*/%v100154 (stack43)
        %v100166 = vadd.s32 1, %v100162 (stack39)
        %v100170 = vsel /*vm=*/%vm100144, /*on_true_vy=*/%v100166, /*on_false_vx=*/%v100162 (stack43)
        %v100175 = vadd.s32 %v100170, %v10 (stack39)
        %v100179 = vadd.s32 %v100140, %v9 (stack39)
        %v100183 = vadd.s32 %v100179, %v100175 (stack39)
        %v100185 = vshll.u32 %v100179, 13 (stack44)
        %v100186 = vshrl.u32 %v100179, 19 (stack45)
        %v100187 = vor.u32 %v100186, %v100185 (stack46)
        %v100188 = vxor.u32 %v100187, %v100183 (stack47)
        %v100191 = vadd.s32 %v100188, %v100183 (stack39)
        %v100193 = vshll.u32 %v100188, 15 (stack44)
        %v100194 = vshrl.u32 %v100188, 17 (stack45)
        %v100195 = vor.u32 %v100194, %v100193 (stack46)
        %v100196 = vxor.u32 %v100195, %v100191 (stack47)
        %v100199 = vadd.s32 %v100196, %v100191 (stack39)
        %v100201 = vshll.u32 %v100196, 26 (stack44)
        %v100202 = vshrl.u32 %v100196, 6 (stack45)
        %v100203 = vor.u32 %v100202, %v100201 (stack46)
        %v100204 = vxor.u32 %v100203, %v100199 (stack47)
        %v100207 = vadd.s32 %v100204, %v100199 (stack39)
        %v100211 = vadd.s32 %v100207, %v9 (stack39)
        %v100213 = vshll.u32 %v100204, 6 (stack44)
        %v100214 = vshrl.u32 %v100204, 26 (stack45)
        %v100215 = vor.u32 %v100214, %v100213 (stack46)
        %v100216 = vxor.u32 %v100215, %v100207 (stack47)
        %v100219 = vadd.s32 %v100216, %v8 (stack39)
        %v100223 = vadd.s32 1, %v100219 (stack39)
        %v100227 = vadd.s32 %v100223, %v100211 (stack39)
        %v100229 = vshll.u32 %v100223, 17 (stack44)
        %v100230 = vshrl.u32 %v100223, 15 (stack45)
        %v100231 = vor.u32 %v100230, %v100229 (stack46)
        %v100232 = vxor.u32 %v100231, %v100227 (stack47)
        %v100235 = vadd.s32 %v100232, %v100227 (stack39)
        %v100237 = vshll.u32 %v100232, 29 (stack44)
        %v100238 = vshrl.u32 %v100232, 3 (stack45)
        %v100239 = vor.u32 %v100238, %v100237 (stack46)
        %v100240 = vxor.u32 %v100239, %v100235 (stack47)
        %v100243 = vadd.s32 %v100240, %v100235 (stack39)
        %v100245 = vshll.u32 %v100240, 16 (stack44)
        %v100246 = vshrl.u32 %v100240, 16 (stack45)
        %v100247 = vor.u32 %v100246, %v100245 (stack46)
        %v100248 = vxor.u32 %v100247, %v100243 (stack47)
        %v100251 = vadd.s32 %v100248, %v100243 (stack39)
        %v100255 = vadd.s32 %v100251, %v8 (stack39)
        %v100257 = vshll.u32 %v100248, 24 (stack44)
        %v100258 = vshrl.u32 %v100248, 8 (stack45)
        %v100259 = vor.u32 %v100258, %v100257 (stack46)
        %v100260 = vxor.u32 %v100259, %v100251 (stack47)
        %v100263 = vadd.s32 %v100260, %v10 (stack39)
        %v100267 = vadd.s32 2, %v100263 (stack39)
        %v100271 = vadd.s32 %v100267, %v100255 (stack39)
        %v100273 = vshll.u32 %v100267, 13 (stack44)
        %v100274 = vshrl.u32 %v100267, 19 (stack45)
        %v100275 = vor.u32 %v100274, %v100273 (stack46)
        %v100276 = vxor.u32 %v100275, %v100271 (stack47)
        %v100279 = vadd.s32 %v100276, %v100271 (stack39)
        %v100281 = vshll.u32 %v100276, 15 (stack44)
        %v100282 = vshrl.u32 %v100276, 17 (stack45)
        %v100283 = vor.u32 %v100282, %v100281 (stack46)
        %v100284 = vxor.u32 %v100283, %v100279 (stack47)
        %v100287 = vadd.s32 %v100284, %v100279 (stack39)
        %v100289 = vshll.u32 %v100284, 26 (stack44)
        %v100290 = vshrl.u32 %v100284, 6 (stack45)
        %v100291 = vor.u32 %v100290, %v100289 (stack46)
        %v100292 = vxor.u32 %v100291, %v100287 (stack47)
        %v100295 = vadd.s32 %v100292, %v100287 (stack39)
        %v100299 = vadd.s32 %v100295, %v10 (stack39)
        %v100301 = vshll.u32 %v100292, 6 (stack44)
        %v100302 = vshrl.u32 %v100292, 26 (stack45)
        %v100303 = vor.u32 %v100302, %v100301 (stack46)
        %v100304 = vxor.u32 %v100303, %v100295 (stack47)
        %v100307 = vadd.s32 %v100304, %v9 (stack39)
        %v100311 = vadd.s32 3, %v100307 (stack39)
        %v100315 = vadd.s32 %v100311, %v100299 (stack39)
        %v100317 = vshll.u32 %v100311, 17 (stack44)
        %v100318 = vshrl.u32 %v100311, 15 (stack45)
        %v100319 = vor.u32 %v100318, %v100317 (stack46)
        %v100320 = vxor.u32 %v100319, %v100315 (stack47)
        %v100323 = vadd.s32 %v100320, %v100315 (stack39)
        %v100325 = vshll.u32 %v100320, 29 (stack44)
        %v100326 = vshrl.u32 %v100320, 3 (stack45)
        %v100327 = vor.u32 %v100326, %v100325 (stack46)
        %v100328 = vxor.u32 %v100327, %v100323 (stack47)
        %v100331 = vadd.s32 %v100328, %v100323 (stack39)
        %v100333 = vshll.u32 %v100328, 16 (stack44)
        %v100334 = vshrl.u32 %v100328, 16 (stack45)
        %v100335 = vor.u32 %v100334, %v100333 (stack46)
        %v100336 = vxor.u32 %v100335, %v100331 (stack47)
        %v100339 = vadd.s32 %v100336, %v100331 (stack39)
        %v100343 = vadd.s32 %v100339, %v9 (stack39)
        %v100345 = vshll.u32 %v100336, 24 (stack44)
        %v100346 = vshrl.u32 %v100336, 8 (stack45)
        %v100347 = vor.u32 %v100346, %v100345 (stack46)
        %v100348 = vxor.u32 %v100347, %v100339 (stack47)
        %v100351 = vadd.s32 %v100348, %v8 (stack39)
        %v100355 = vadd.s32 4, %v100351 (stack39)
        %v100359 = vadd.s32 %v100355, %v100343 (stack39)
        %v100361 = vshll.u32 %v100355, 13 (stack44)
        %v100362 = vshrl.u32 %v100355, 19 (stack45)
        %v100363 = vor.u32 %v100362, %v100361 (stack46)
        %v100364 = vxor.u32 %v100363, %v100359 (stack47)
        %v100367 = vadd.s32 %v100364, %v100359 (stack39)
        %v100369 = vshll.u32 %v100364, 15 (stack44)
        %v100370 = vshrl.u32 %v100364, 17 (stack45)
        %v100371 = vor.u32 %v100370, %v100369 (stack46)
        %v100372 = vxor.u32 %v100371, %v100367 (stack47)
        %v100375 = vadd.s32 %v100372, %v100367 (stack39)
        %v100377 = vshll.u32 %v100372, 26 (stack44)
        %v100378 = vshrl.u32 %v100372, 6 (stack45)
        %v100379 = vor.u32 %v100378, %v100377 (stack46)
        %v100380 = vxor.u32 %v100379, %v100375 (stack47)
        %v100383 = vadd.s32 %v100380, %v100375 (stack39)
        %v100387 = vadd.s32 %v100383, %v8 (stack39)
        %v100389 = vshll.u32 %v100380, 6 (stack44)
        %v100390 = vshrl.u32 %v100380, 26 (stack45)
        %v100391 = vor.u32 %v100390, %v100389 (stack46)
        %v100392 = vxor.u32 %v100391, %v100383 (stack47)
        %v100395 = vadd.s32 %v100392, %v10 (stack39)
        %v100399 = vadd.s32 5, %v100395 (stack39)
        %v100401 = vxor.u32 %v100399, %v100387 (stack47)
        %v100402 = vand.u32.u8 255, %v100401 (stack48)
        %v100403 = vand.u32 65535, %v100402 (stack49)
        %v100404 = vshrl.u32 %v100403, 1 (stack50)
        %v100405 = vor.u32 16256, %v100404 (stack46)
        %v100406 = vand.u32.u16 65535, %v100405 (stack51)
        %v120280 = vadd.low.f32.bf16 -1.0, %v100406 (stack52)
        %v100415 = vmul.f32 2.0, %v120280 (stack53)
        %v100419 = vadd.f32 -0.99609375, %v100415 (stack52)
        %v100423 = vmax.f32 %v100419, -0.99609375 (stack54)
        %v100425 = vand.u32 2147483647, %v100423 (stack55)
        %vm100428 = vcmp.eq.f32.partialorder %v100425, 1.0 (stack56)
        %v100433 = vmul.f32 inf, %v100423 (stack53)
        %v100435 = vxor.u32 2147483648, %v100423 (stack57)
        %v100438 = vmul.f32 %v100435, %v100423 (stack53)
        %v100440 = vadd.f32 1.0, %v100438 (stack58)
        %v100441 = vlog2.pop %v100440 (stack59)
        %v100442 = vmul.f32 0.6931472, %v100441 (stack60)
        %v100443 = vmul.f32 -0.5, %v100438 (stack61)
        %v100444 = vadd.f32 1.0, %v100443 (stack62)
        %v100445 = vmul.f32 %v100444, %v100438 (stack63)
        %v100446 = vand.u32 2147483647, %v100438 (stack64)
        %vm100447 = vcmp.lt.f32.partialorder %v100446, 0.0004427343 (stack65)
        %v100448 = vsel /*vm=*/%vm100447, /*on_true_vy=*/%v100445, /*on_false_vx=*/%v100442 (stack66)
        %v100449 = vxor.u32 2147483648, %v100448 (stack57)
        %vm100452 = vcmp.lt.f32.partialorder %v100449, 5.0 (stack56)
        %v100457 = vsel /*vm=*/%vm100452, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v100461 = vsel /*vm=*/%vm100452, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v100465 = vsel /*vm=*/%vm100452, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v100469 = vsel /*vm=*/%vm100452, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v100473 = vsel /*vm=*/%vm100452, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v100477 = vsel /*vm=*/%vm100452, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v100481 = vsel /*vm=*/%vm100452, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v100485 = vsel /*vm=*/%vm100452, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v100489 = vsel /*vm=*/%vm100452, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v100493 = vadd.f32 -2.5, %v100449 (stack52)
        %v100495 = vrsqrt.pop %v100449 (stack67)
        %v100496 = vmul.f32 %v100495, %v100449 (stack68)
        %vm100497 = vcmp.eq.f32.partialorder %v100449, inf (stack69)
        %v100498 = vsel /*vm=*/%vm100497, /*on_true_vy=*/%v100449, /*on_false_vx=*/%v100496 (stack70)
        %vm100499 = vcmp.eq.f32.partialorder %v100449, 0.0 (stack71)
        %v100500 = vand.u32 2147483648, %v100449 (stack72)
        %v100501 = vsel /*vm=*/%vm100499, /*on_true_vy=*/%v100500, /*on_false_vx=*/%v100498 (stack73)
        %v100504 = vadd.f32 -3.0, %v100501 (stack52)
        %v100508 = vsel /*vm=*/%vm100452, /*on_true_vy=*/%v100493, /*on_false_vx=*/%v100504 (stack43)
        %v100512 = vmul.f32 %v100508, %v100489 (stack53)
        %v100516 = vadd.f32 %v100512, %v100485 (stack52)
        %v100520 = vmul.f32 %v100516, %v100508 (stack53)
        %v100524 = vadd.f32 %v100520, %v100481 (stack52)
        %v100528 = vmul.f32 %v100524, %v100508 (stack53)
        %v100532 = vadd.f32 %v100528, %v100477 (stack52)
        %v100536 = vmul.f32 %v100532, %v100508 (stack53)
        %v100540 = vadd.f32 %v100536, %v100473 (stack52)
        %v100544 = vmul.f32 %v100540, %v100508 (stack53)
        %v100548 = vadd.f32 %v100544, %v100469 (stack52)
        %v100552 = vmul.f32 %v100548, %v100508 (stack53)
        %v100556 = vadd.f32 %v100552, %v100465 (stack52)
        %v100560 = vmul.f32 %v100556, %v100508 (stack53)
        %v100564 = vadd.f32 %v100560, %v100461 (stack52)
        %v100568 = vmul.f32 %v100564, %v100508 (stack53)
        %v100572 = vadd.f32 %v100568, %v100457 (stack52)
        %v100576 = vmul.f32 %v100572, %v100423 (stack53)
        %v100580 = vsel /*vm=*/%vm100428, /*on_true_vy=*/%v100433, /*on_false_vx=*/%v100576 (stack43)
        %v100584 = vmul.f32 1.4140625, %v100580 (stack53)
        %v100587 = vpack.c.bf16 0.0, %v100584 (stack74)
        %120281 = vst [vmem:[%s280 + $0x368] sm:$0xf] /*vst_source=*/%v100587 (stack75)
        %v100591 = vadd.s32 %v97361, %v3816 (stack39)
        %v100601 = vadd.s32 %v100591, %v415 (stack39)
        %vm100605 = vcmp.lt.u32.totalorder %v100601, %v100591 (stack42)
        %vm100610 = vcmp.lt.u32.totalorder %v100591, %v3816 (stack42)
        %v100615 = vadd.s32 %v97344, %v3803 (stack39)
        %v100619 = vadd.s32 1, %v100615 (stack39)
        %v100623 = vsel /*vm=*/%vm100610, /*on_true_vy=*/%v100619, /*on_false_vx=*/%v100615 (stack43)
        %v100627 = vadd.s32 1, %v100623 (stack39)
        %v100631 = vsel /*vm=*/%vm100605, /*on_true_vy=*/%v100627, /*on_false_vx=*/%v100623 (stack43)
        %v100636 = vadd.s32 %v100631, %v10 (stack39)
        %v100640 = vadd.s32 %v100601, %v9 (stack39)
        %v100644 = vadd.s32 %v100640, %v100636 (stack39)
        %v100646 = vshll.u32 %v100640, 13 (stack44)
        %v100647 = vshrl.u32 %v100640, 19 (stack45)
        %v100648 = vor.u32 %v100647, %v100646 (stack46)
        %v100649 = vxor.u32 %v100648, %v100644 (stack47)
        %v100652 = vadd.s32 %v100649, %v100644 (stack39)
        %v100654 = vshll.u32 %v100649, 15 (stack44)
        %v100655 = vshrl.u32 %v100649, 17 (stack45)
        %v100656 = vor.u32 %v100655, %v100654 (stack46)
        %v100657 = vxor.u32 %v100656, %v100652 (stack47)
        %v100660 = vadd.s32 %v100657, %v100652 (stack39)
        %v100662 = vshll.u32 %v100657, 26 (stack44)
        %v100663 = vshrl.u32 %v100657, 6 (stack45)
        %v100664 = vor.u32 %v100663, %v100662 (stack46)
        %v100665 = vxor.u32 %v100664, %v100660 (stack47)
        %v100668 = vadd.s32 %v100665, %v100660 (stack39)
        %v100672 = vadd.s32 %v100668, %v9 (stack39)
        %v100674 = vshll.u32 %v100665, 6 (stack44)
        %v100675 = vshrl.u32 %v100665, 26 (stack45)
        %v100676 = vor.u32 %v100675, %v100674 (stack46)
        %v100677 = vxor.u32 %v100676, %v100668 (stack47)
        %v100680 = vadd.s32 %v100677, %v8 (stack39)
        %v100684 = vadd.s32 1, %v100680 (stack39)
        %v100688 = vadd.s32 %v100684, %v100672 (stack39)
        %v100690 = vshll.u32 %v100684, 17 (stack44)
        %v100691 = vshrl.u32 %v100684, 15 (stack45)
        %v100692 = vor.u32 %v100691, %v100690 (stack46)
        %v100693 = vxor.u32 %v100692, %v100688 (stack47)
        %v100696 = vadd.s32 %v100693, %v100688 (stack39)
        %v100698 = vshll.u32 %v100693, 29 (stack44)
        %v100699 = vshrl.u32 %v100693, 3 (stack45)
        %v100700 = vor.u32 %v100699, %v100698 (stack46)
        %v100701 = vxor.u32 %v100700, %v100696 (stack47)
        %v100704 = vadd.s32 %v100701, %v100696 (stack39)
        %v100706 = vshll.u32 %v100701, 16 (stack44)
        %v100707 = vshrl.u32 %v100701, 16 (stack45)
        %v100708 = vor.u32 %v100707, %v100706 (stack46)
        %v100709 = vxor.u32 %v100708, %v100704 (stack47)
        %v100712 = vadd.s32 %v100709, %v100704 (stack39)
        %v100716 = vadd.s32 %v100712, %v8 (stack39)
        %v100718 = vshll.u32 %v100709, 24 (stack44)
        %v100719 = vshrl.u32 %v100709, 8 (stack45)
        %v100720 = vor.u32 %v100719, %v100718 (stack46)
        %v100721 = vxor.u32 %v100720, %v100712 (stack47)
        %v100724 = vadd.s32 %v100721, %v10 (stack39)
        %v100728 = vadd.s32 2, %v100724 (stack39)
        %v100732 = vadd.s32 %v100728, %v100716 (stack39)
        %v100734 = vshll.u32 %v100728, 13 (stack44)
        %v100735 = vshrl.u32 %v100728, 19 (stack45)
        %v100736 = vor.u32 %v100735, %v100734 (stack46)
        %v100737 = vxor.u32 %v100736, %v100732 (stack47)
        %v100740 = vadd.s32 %v100737, %v100732 (stack39)
        %v100742 = vshll.u32 %v100737, 15 (stack44)
        %v100743 = vshrl.u32 %v100737, 17 (stack45)
        %v100744 = vor.u32 %v100743, %v100742 (stack46)
        %v100745 = vxor.u32 %v100744, %v100740 (stack47)
        %v100748 = vadd.s32 %v100745, %v100740 (stack39)
        %v100750 = vshll.u32 %v100745, 26 (stack44)
        %v100751 = vshrl.u32 %v100745, 6 (stack45)
        %v100752 = vor.u32 %v100751, %v100750 (stack46)
        %v100753 = vxor.u32 %v100752, %v100748 (stack47)
        %v100756 = vadd.s32 %v100753, %v100748 (stack39)
        %v100760 = vadd.s32 %v100756, %v10 (stack39)
        %v100762 = vshll.u32 %v100753, 6 (stack44)
        %v100763 = vshrl.u32 %v100753, 26 (stack45)
        %v100764 = vor.u32 %v100763, %v100762 (stack46)
        %v100765 = vxor.u32 %v100764, %v100756 (stack47)
        %v100768 = vadd.s32 %v100765, %v9 (stack39)
        %v100772 = vadd.s32 3, %v100768 (stack39)
        %v100776 = vadd.s32 %v100772, %v100760 (stack39)
        %v100778 = vshll.u32 %v100772, 17 (stack44)
        %v100779 = vshrl.u32 %v100772, 15 (stack45)
        %v100780 = vor.u32 %v100779, %v100778 (stack46)
        %v100781 = vxor.u32 %v100780, %v100776 (stack47)
        %v100784 = vadd.s32 %v100781, %v100776 (stack39)
        %v100786 = vshll.u32 %v100781, 29 (stack44)
        %v100787 = vshrl.u32 %v100781, 3 (stack45)
        %v100788 = vor.u32 %v100787, %v100786 (stack46)
        %v100789 = vxor.u32 %v100788, %v100784 (stack47)
        %v100792 = vadd.s32 %v100789, %v100784 (stack39)
        %v100794 = vshll.u32 %v100789, 16 (stack44)
        %v100795 = vshrl.u32 %v100789, 16 (stack45)
        %v100796 = vor.u32 %v100795, %v100794 (stack46)
        %v100797 = vxor.u32 %v100796, %v100792 (stack47)
        %v100800 = vadd.s32 %v100797, %v100792 (stack39)
        %v100804 = vadd.s32 %v100800, %v9 (stack39)
        %v100806 = vshll.u32 %v100797, 24 (stack44)
        %v100807 = vshrl.u32 %v100797, 8 (stack45)
        %v100808 = vor.u32 %v100807, %v100806 (stack46)
        %v100809 = vxor.u32 %v100808, %v100800 (stack47)
        %v100812 = vadd.s32 %v100809, %v8 (stack39)
        %v100816 = vadd.s32 4, %v100812 (stack39)
        %v100820 = vadd.s32 %v100816, %v100804 (stack39)
        %v100822 = vshll.u32 %v100816, 13 (stack44)
        %v100823 = vshrl.u32 %v100816, 19 (stack45)
        %v100824 = vor.u32 %v100823, %v100822 (stack46)
        %v100825 = vxor.u32 %v100824, %v100820 (stack47)
        %v100828 = vadd.s32 %v100825, %v100820 (stack39)
        %v100830 = vshll.u32 %v100825, 15 (stack44)
        %v100831 = vshrl.u32 %v100825, 17 (stack45)
        %v100832 = vor.u32 %v100831, %v100830 (stack46)
        %v100833 = vxor.u32 %v100832, %v100828 (stack47)
        %v100836 = vadd.s32 %v100833, %v100828 (stack39)
        %v100838 = vshll.u32 %v100833, 26 (stack44)
        %v100839 = vshrl.u32 %v100833, 6 (stack45)
        %v100840 = vor.u32 %v100839, %v100838 (stack46)
        %v100841 = vxor.u32 %v100840, %v100836 (stack47)
        %v100844 = vadd.s32 %v100841, %v100836 (stack39)
        %v100848 = vadd.s32 %v100844, %v8 (stack39)
        %v100850 = vshll.u32 %v100841, 6 (stack44)
        %v100851 = vshrl.u32 %v100841, 26 (stack45)
        %v100852 = vor.u32 %v100851, %v100850 (stack46)
        %v100853 = vxor.u32 %v100852, %v100844 (stack47)
        %v100856 = vadd.s32 %v100853, %v10 (stack39)
        %v100860 = vadd.s32 5, %v100856 (stack39)
        %v100862 = vxor.u32 %v100860, %v100848 (stack47)
        %v100863 = vand.u32.u8 255, %v100862 (stack48)
        %v100864 = vand.u32 65535, %v100863 (stack49)
        %v100865 = vshrl.u32 %v100864, 1 (stack50)
        %v100866 = vor.u32 16256, %v100865 (stack46)
        %v100867 = vand.u32.u16 65535, %v100866 (stack51)
        %v120282 = vadd.low.f32.bf16 -1.0, %v100867 (stack52)
        %v100876 = vmul.f32 2.0, %v120282 (stack53)
        %v100880 = vadd.f32 -0.99609375, %v100876 (stack52)
        %v100884 = vmax.f32 %v100880, -0.99609375 (stack54)
        %v100886 = vand.u32 2147483647, %v100884 (stack55)
        %vm100889 = vcmp.eq.f32.partialorder %v100886, 1.0 (stack56)
        %v100894 = vmul.f32 inf, %v100884 (stack53)
        %v100896 = vxor.u32 2147483648, %v100884 (stack57)
        %v100899 = vmul.f32 %v100896, %v100884 (stack53)
        %v100901 = vadd.f32 1.0, %v100899 (stack58)
        %v100902 = vlog2.pop %v100901 (stack59)
        %v100903 = vmul.f32 0.6931472, %v100902 (stack60)
        %v100904 = vmul.f32 -0.5, %v100899 (stack61)
        %v100905 = vadd.f32 1.0, %v100904 (stack62)
        %v100906 = vmul.f32 %v100905, %v100899 (stack63)
        %v100907 = vand.u32 2147483647, %v100899 (stack64)
        %vm100908 = vcmp.lt.f32.partialorder %v100907, 0.0004427343 (stack65)
        %v100909 = vsel /*vm=*/%vm100908, /*on_true_vy=*/%v100906, /*on_false_vx=*/%v100903 (stack66)
        %v100910 = vxor.u32 2147483648, %v100909 (stack57)
        %vm100913 = vcmp.lt.f32.partialorder %v100910, 5.0 (stack56)
        %v100918 = vsel /*vm=*/%vm100913, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v100922 = vsel /*vm=*/%vm100913, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v100926 = vsel /*vm=*/%vm100913, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v100930 = vsel /*vm=*/%vm100913, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v100934 = vsel /*vm=*/%vm100913, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v100938 = vsel /*vm=*/%vm100913, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v100942 = vsel /*vm=*/%vm100913, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v100946 = vsel /*vm=*/%vm100913, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v100950 = vsel /*vm=*/%vm100913, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v100954 = vadd.f32 -2.5, %v100910 (stack52)
        %v100956 = vrsqrt.pop %v100910 (stack67)
        %v100957 = vmul.f32 %v100956, %v100910 (stack68)
        %vm100958 = vcmp.eq.f32.partialorder %v100910, inf (stack69)
        %v100959 = vsel /*vm=*/%vm100958, /*on_true_vy=*/%v100910, /*on_false_vx=*/%v100957 (stack70)
        %vm100960 = vcmp.eq.f32.partialorder %v100910, 0.0 (stack71)
        %v100961 = vand.u32 2147483648, %v100910 (stack72)
        %v100962 = vsel /*vm=*/%vm100960, /*on_true_vy=*/%v100961, /*on_false_vx=*/%v100959 (stack73)
        %v100965 = vadd.f32 -3.0, %v100962 (stack52)
        %v100969 = vsel /*vm=*/%vm100913, /*on_true_vy=*/%v100954, /*on_false_vx=*/%v100965 (stack43)
        %v100973 = vmul.f32 %v100969, %v100950 (stack53)
        %v100977 = vadd.f32 %v100973, %v100946 (stack52)
        %v100981 = vmul.f32 %v100977, %v100969 (stack53)
        %v100985 = vadd.f32 %v100981, %v100942 (stack52)
        %v100989 = vmul.f32 %v100985, %v100969 (stack53)
        %v100993 = vadd.f32 %v100989, %v100938 (stack52)
        %v100997 = vmul.f32 %v100993, %v100969 (stack53)
        %v101001 = vadd.f32 %v100997, %v100934 (stack52)
        %v101005 = vmul.f32 %v101001, %v100969 (stack53)
        %v101009 = vadd.f32 %v101005, %v100930 (stack52)
        %v101013 = vmul.f32 %v101009, %v100969 (stack53)
        %v101017 = vadd.f32 %v101013, %v100926 (stack52)
        %v101021 = vmul.f32 %v101017, %v100969 (stack53)
        %v101025 = vadd.f32 %v101021, %v100922 (stack52)
        %v101029 = vmul.f32 %v101025, %v100969 (stack53)
        %v101033 = vadd.f32 %v101029, %v100918 (stack52)
        %v101037 = vmul.f32 %v101033, %v100884 (stack53)
        %v101041 = vsel /*vm=*/%vm100889, /*on_true_vy=*/%v100894, /*on_false_vx=*/%v101037 (stack43)
        %v101045 = vmul.f32 1.4140625, %v101041 (stack53)
        %v101048 = vpack.c.bf16 0.0, %v101045 (stack74)
        %120283 = vst [vmem:[%s280 + $0x3e8] sm:$0xf] /*vst_source=*/%v101048 (stack75)
        %s101050 = sadd.s32 216, %s120390 (stack76)
        %s101051 = sshrl.u32 %s101050, 10 (stack23)
        %p120284 = scmp.gt.s32.totalorder %s101051, 1 (stack24)
        %s101053 = scalar_select /*predicate=*/%p120284, /*on_true=*/1, /*on_false=*/%s101051 (stack25)
        %s101054 = sand.u32 1023, %s101050 /* smod.u32 w/div 1024 */ (stack26)
        %s101055 = sshrl.u32 %s101054, 7 (stack27)
        %s101056 = sand.u32 127, %s101054 /* smod.u32 w/div 128 */ (stack28)
        %s120285 = sshll.u32 %s101053, 3 (stack29)
        %s101058 = scalar_lea.vmem %s3, %s120285 (stack30)
        %s101060 = scalar_lea.vmem %s101058, %s101055 (stack31)
        %v101061 = vld [vmem:[%s101060] ss:$0 sm:$0xff] (stack32)
        %s101062 = sand.u32 255, %s101056 (stack33)
        %s101064 = sor.u32 256, %s101062 (stack34)
        %101065 = vbcast.lane.b32.xlu0 %v101061, %s101064 (stack35)
        %v101066 = vpop.permute.xlu0 %101065 (stack36)
        %s101075 = scalar_lea.vmem %s5, %s120285 (stack30)
        %s101077 = scalar_lea.vmem %s101075, %s101055 (stack31)
        %v101078 = vld [vmem:[%s101077] ss:$0 sm:$0xff] (stack32)
        %101082 = vbcast.lane.b32.xlu0 %v101078, %s101064 (stack35)
        %v101083 = vpop.permute.xlu0 %101082 (stack36)
        %v101086 = vadd.s32 %v101083, %v408 (stack39)
        %v101096 = vadd.s32 %v101086, %v415 (stack39)
        %vm101100 = vcmp.lt.u32.totalorder %v101096, %v101086 (stack42)
        %vm101105 = vcmp.lt.u32.totalorder %v101086, %v408 (stack42)
        %v101110 = vadd.s32 %v101066, %v380 (stack39)
        %v101114 = vadd.s32 1, %v101110 (stack39)
        %v101118 = vsel /*vm=*/%vm101105, /*on_true_vy=*/%v101114, /*on_false_vx=*/%v101110 (stack43)
        %v101122 = vadd.s32 1, %v101118 (stack39)
        %v101126 = vsel /*vm=*/%vm101100, /*on_true_vy=*/%v101122, /*on_false_vx=*/%v101118 (stack43)
        %v101131 = vadd.s32 %v101126, %v10 (stack39)
        %v101135 = vadd.s32 %v101096, %v9 (stack39)
        %v101139 = vadd.s32 %v101135, %v101131 (stack39)
        %v101141 = vshll.u32 %v101135, 13 (stack44)
        %v101142 = vshrl.u32 %v101135, 19 (stack45)
        %v101143 = vor.u32 %v101142, %v101141 (stack46)
        %v101144 = vxor.u32 %v101143, %v101139 (stack47)
        %v101147 = vadd.s32 %v101144, %v101139 (stack39)
        %v101149 = vshll.u32 %v101144, 15 (stack44)
        %v101150 = vshrl.u32 %v101144, 17 (stack45)
        %v101151 = vor.u32 %v101150, %v101149 (stack46)
        %v101152 = vxor.u32 %v101151, %v101147 (stack47)
        %v101155 = vadd.s32 %v101152, %v101147 (stack39)
        %v101157 = vshll.u32 %v101152, 26 (stack44)
        %v101158 = vshrl.u32 %v101152, 6 (stack45)
        %v101159 = vor.u32 %v101158, %v101157 (stack46)
        %v101160 = vxor.u32 %v101159, %v101155 (stack47)
        %v101163 = vadd.s32 %v101160, %v101155 (stack39)
        %v101167 = vadd.s32 %v101163, %v9 (stack39)
        %v101169 = vshll.u32 %v101160, 6 (stack44)
        %v101170 = vshrl.u32 %v101160, 26 (stack45)
        %v101171 = vor.u32 %v101170, %v101169 (stack46)
        %v101172 = vxor.u32 %v101171, %v101163 (stack47)
        %v101175 = vadd.s32 %v101172, %v8 (stack39)
        %v101179 = vadd.s32 1, %v101175 (stack39)
        %v101183 = vadd.s32 %v101179, %v101167 (stack39)
        %v101185 = vshll.u32 %v101179, 17 (stack44)
        %v101186 = vshrl.u32 %v101179, 15 (stack45)
        %v101187 = vor.u32 %v101186, %v101185 (stack46)
        %v101188 = vxor.u32 %v101187, %v101183 (stack47)
        %v101191 = vadd.s32 %v101188, %v101183 (stack39)
        %v101193 = vshll.u32 %v101188, 29 (stack44)
        %v101194 = vshrl.u32 %v101188, 3 (stack45)
        %v101195 = vor.u32 %v101194, %v101193 (stack46)
        %v101196 = vxor.u32 %v101195, %v101191 (stack47)
        %v101199 = vadd.s32 %v101196, %v101191 (stack39)
        %v101201 = vshll.u32 %v101196, 16 (stack44)
        %v101202 = vshrl.u32 %v101196, 16 (stack45)
        %v101203 = vor.u32 %v101202, %v101201 (stack46)
        %v101204 = vxor.u32 %v101203, %v101199 (stack47)
        %v101207 = vadd.s32 %v101204, %v101199 (stack39)
        %v101211 = vadd.s32 %v101207, %v8 (stack39)
        %v101213 = vshll.u32 %v101204, 24 (stack44)
        %v101214 = vshrl.u32 %v101204, 8 (stack45)
        %v101215 = vor.u32 %v101214, %v101213 (stack46)
        %v101216 = vxor.u32 %v101215, %v101207 (stack47)
        %v101219 = vadd.s32 %v101216, %v10 (stack39)
        %v101223 = vadd.s32 2, %v101219 (stack39)
        %v101227 = vadd.s32 %v101223, %v101211 (stack39)
        %v101229 = vshll.u32 %v101223, 13 (stack44)
        %v101230 = vshrl.u32 %v101223, 19 (stack45)
        %v101231 = vor.u32 %v101230, %v101229 (stack46)
        %v101232 = vxor.u32 %v101231, %v101227 (stack47)
        %v101235 = vadd.s32 %v101232, %v101227 (stack39)
        %v101237 = vshll.u32 %v101232, 15 (stack44)
        %v101238 = vshrl.u32 %v101232, 17 (stack45)
        %v101239 = vor.u32 %v101238, %v101237 (stack46)
        %v101240 = vxor.u32 %v101239, %v101235 (stack47)
        %v101243 = vadd.s32 %v101240, %v101235 (stack39)
        %v101245 = vshll.u32 %v101240, 26 (stack44)
        %v101246 = vshrl.u32 %v101240, 6 (stack45)
        %v101247 = vor.u32 %v101246, %v101245 (stack46)
        %v101248 = vxor.u32 %v101247, %v101243 (stack47)
        %v101251 = vadd.s32 %v101248, %v101243 (stack39)
        %v101255 = vadd.s32 %v101251, %v10 (stack39)
        %v101257 = vshll.u32 %v101248, 6 (stack44)
        %v101258 = vshrl.u32 %v101248, 26 (stack45)
        %v101259 = vor.u32 %v101258, %v101257 (stack46)
        %v101260 = vxor.u32 %v101259, %v101251 (stack47)
        %v101263 = vadd.s32 %v101260, %v9 (stack39)
        %v101267 = vadd.s32 3, %v101263 (stack39)
        %v101271 = vadd.s32 %v101267, %v101255 (stack39)
        %v101273 = vshll.u32 %v101267, 17 (stack44)
        %v101274 = vshrl.u32 %v101267, 15 (stack45)
        %v101275 = vor.u32 %v101274, %v101273 (stack46)
        %v101276 = vxor.u32 %v101275, %v101271 (stack47)
        %v101279 = vadd.s32 %v101276, %v101271 (stack39)
        %v101281 = vshll.u32 %v101276, 29 (stack44)
        %v101282 = vshrl.u32 %v101276, 3 (stack45)
        %v101283 = vor.u32 %v101282, %v101281 (stack46)
        %v101284 = vxor.u32 %v101283, %v101279 (stack47)
        %v101287 = vadd.s32 %v101284, %v101279 (stack39)
        %v101289 = vshll.u32 %v101284, 16 (stack44)
        %v101290 = vshrl.u32 %v101284, 16 (stack45)
        %v101291 = vor.u32 %v101290, %v101289 (stack46)
        %v101292 = vxor.u32 %v101291, %v101287 (stack47)
        %v101295 = vadd.s32 %v101292, %v101287 (stack39)
        %v101299 = vadd.s32 %v101295, %v9 (stack39)
        %v101301 = vshll.u32 %v101292, 24 (stack44)
        %v101302 = vshrl.u32 %v101292, 8 (stack45)
        %v101303 = vor.u32 %v101302, %v101301 (stack46)
        %v101304 = vxor.u32 %v101303, %v101295 (stack47)
        %v101307 = vadd.s32 %v101304, %v8 (stack39)
        %v101311 = vadd.s32 4, %v101307 (stack39)
        %v101315 = vadd.s32 %v101311, %v101299 (stack39)
        %v101317 = vshll.u32 %v101311, 13 (stack44)
        %v101318 = vshrl.u32 %v101311, 19 (stack45)
        %v101319 = vor.u32 %v101318, %v101317 (stack46)
        %v101320 = vxor.u32 %v101319, %v101315 (stack47)
        %v101323 = vadd.s32 %v101320, %v101315 (stack39)
        %v101325 = vshll.u32 %v101320, 15 (stack44)
        %v101326 = vshrl.u32 %v101320, 17 (stack45)
        %v101327 = vor.u32 %v101326, %v101325 (stack46)
        %v101328 = vxor.u32 %v101327, %v101323 (stack47)
        %v101331 = vadd.s32 %v101328, %v101323 (stack39)
        %v101333 = vshll.u32 %v101328, 26 (stack44)
        %v101334 = vshrl.u32 %v101328, 6 (stack45)
        %v101335 = vor.u32 %v101334, %v101333 (stack46)
        %v101336 = vxor.u32 %v101335, %v101331 (stack47)
        %v101339 = vadd.s32 %v101336, %v101331 (stack39)
        %v101343 = vadd.s32 %v101339, %v8 (stack39)
        %v101345 = vshll.u32 %v101336, 6 (stack44)
        %v101346 = vshrl.u32 %v101336, 26 (stack45)
        %v101347 = vor.u32 %v101346, %v101345 (stack46)
        %v101348 = vxor.u32 %v101347, %v101339 (stack47)
        %v101351 = vadd.s32 %v101348, %v10 (stack39)
        %v101355 = vadd.s32 5, %v101351 (stack39)
        %v101357 = vxor.u32 %v101355, %v101343 (stack47)
        %v101358 = vand.u32.u8 255, %v101357 (stack48)
        %v101359 = vand.u32 65535, %v101358 (stack49)
        %v101360 = vshrl.u32 %v101359, 1 (stack50)
        %v101361 = vor.u32 16256, %v101360 (stack46)
        %v101362 = vand.u32.u16 65535, %v101361 (stack51)
        %v120288 = vadd.low.f32.bf16 -1.0, %v101362 (stack52)
        %v101371 = vmul.f32 2.0, %v120288 (stack53)
        %v101375 = vadd.f32 -0.99609375, %v101371 (stack52)
        %v101379 = vmax.f32 %v101375, -0.99609375 (stack54)
        %v101381 = vand.u32 2147483647, %v101379 (stack55)
        %vm101384 = vcmp.eq.f32.partialorder %v101381, 1.0 (stack56)
        %v101389 = vmul.f32 inf, %v101379 (stack53)
        %v101391 = vxor.u32 2147483648, %v101379 (stack57)
        %v101394 = vmul.f32 %v101391, %v101379 (stack53)
        %v101396 = vadd.f32 1.0, %v101394 (stack58)
        %v101397 = vlog2.pop %v101396 (stack59)
        %v101398 = vmul.f32 0.6931472, %v101397 (stack60)
        %v101399 = vmul.f32 -0.5, %v101394 (stack61)
        %v101400 = vadd.f32 1.0, %v101399 (stack62)
        %v101401 = vmul.f32 %v101400, %v101394 (stack63)
        %v101402 = vand.u32 2147483647, %v101394 (stack64)
        %vm101403 = vcmp.lt.f32.partialorder %v101402, 0.0004427343 (stack65)
        %v101404 = vsel /*vm=*/%vm101403, /*on_true_vy=*/%v101401, /*on_false_vx=*/%v101398 (stack66)
        %v101405 = vxor.u32 2147483648, %v101404 (stack57)
        %vm101408 = vcmp.lt.f32.partialorder %v101405, 5.0 (stack56)
        %v101413 = vsel /*vm=*/%vm101408, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v101417 = vsel /*vm=*/%vm101408, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v101421 = vsel /*vm=*/%vm101408, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v101425 = vsel /*vm=*/%vm101408, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v101429 = vsel /*vm=*/%vm101408, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v101433 = vsel /*vm=*/%vm101408, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v101437 = vsel /*vm=*/%vm101408, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v101441 = vsel /*vm=*/%vm101408, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v101445 = vsel /*vm=*/%vm101408, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v101449 = vadd.f32 -2.5, %v101405 (stack52)
        %v101451 = vrsqrt.pop %v101405 (stack67)
        %v101452 = vmul.f32 %v101451, %v101405 (stack68)
        %vm101453 = vcmp.eq.f32.partialorder %v101405, inf (stack69)
        %v101454 = vsel /*vm=*/%vm101453, /*on_true_vy=*/%v101405, /*on_false_vx=*/%v101452 (stack70)
        %vm101455 = vcmp.eq.f32.partialorder %v101405, 0.0 (stack71)
        %v101456 = vand.u32 2147483648, %v101405 (stack72)
        %v101457 = vsel /*vm=*/%vm101455, /*on_true_vy=*/%v101456, /*on_false_vx=*/%v101454 (stack73)
        %v101460 = vadd.f32 -3.0, %v101457 (stack52)
        %v101464 = vsel /*vm=*/%vm101408, /*on_true_vy=*/%v101449, /*on_false_vx=*/%v101460 (stack43)
        %v101468 = vmul.f32 %v101464, %v101445 (stack53)
        %v101472 = vadd.f32 %v101468, %v101441 (stack52)
        %v101476 = vmul.f32 %v101472, %v101464 (stack53)
        %v101480 = vadd.f32 %v101476, %v101437 (stack52)
        %v101484 = vmul.f32 %v101480, %v101464 (stack53)
        %v101488 = vadd.f32 %v101484, %v101433 (stack52)
        %v101492 = vmul.f32 %v101488, %v101464 (stack53)
        %v101496 = vadd.f32 %v101492, %v101429 (stack52)
        %v101500 = vmul.f32 %v101496, %v101464 (stack53)
        %v101504 = vadd.f32 %v101500, %v101425 (stack52)
        %v101508 = vmul.f32 %v101504, %v101464 (stack53)
        %v101512 = vadd.f32 %v101508, %v101421 (stack52)
        %v101516 = vmul.f32 %v101512, %v101464 (stack53)
        %v101520 = vadd.f32 %v101516, %v101417 (stack52)
        %v101524 = vmul.f32 %v101520, %v101464 (stack53)
        %v101528 = vadd.f32 %v101524, %v101413 (stack52)
        %v101532 = vmul.f32 %v101528, %v101379 (stack53)
        %v101536 = vsel /*vm=*/%vm101384, /*on_true_vy=*/%v101389, /*on_false_vx=*/%v101532 (stack43)
        %v101540 = vmul.f32 1.4140625, %v101536 (stack53)
        %v101543 = vpack.c.bf16 0.0, %v101540 (stack74)
        %120289 = vst [vmem:[%s280 + $0x6c] sm:$0xf] /*vst_source=*/%v101543 (stack75)
        %v101547 = vadd.s32 %v101083, %v894 (stack39)
        %v101557 = vadd.s32 %v101547, %v415 (stack39)
        %vm101561 = vcmp.lt.u32.totalorder %v101557, %v101547 (stack42)
        %vm101566 = vcmp.lt.u32.totalorder %v101547, %v894 (stack42)
        %v101571 = vadd.s32 %v101066, %v881 (stack39)
        %v101575 = vadd.s32 1, %v101571 (stack39)
        %v101579 = vsel /*vm=*/%vm101566, /*on_true_vy=*/%v101575, /*on_false_vx=*/%v101571 (stack43)
        %v101583 = vadd.s32 1, %v101579 (stack39)
        %v101587 = vsel /*vm=*/%vm101561, /*on_true_vy=*/%v101583, /*on_false_vx=*/%v101579 (stack43)
        %v101592 = vadd.s32 %v101587, %v10 (stack39)
        %v101596 = vadd.s32 %v101557, %v9 (stack39)
        %v101600 = vadd.s32 %v101596, %v101592 (stack39)
        %v101602 = vshll.u32 %v101596, 13 (stack44)
        %v101603 = vshrl.u32 %v101596, 19 (stack45)
        %v101604 = vor.u32 %v101603, %v101602 (stack46)
        %v101605 = vxor.u32 %v101604, %v101600 (stack47)
        %v101608 = vadd.s32 %v101605, %v101600 (stack39)
        %v101610 = vshll.u32 %v101605, 15 (stack44)
        %v101611 = vshrl.u32 %v101605, 17 (stack45)
        %v101612 = vor.u32 %v101611, %v101610 (stack46)
        %v101613 = vxor.u32 %v101612, %v101608 (stack47)
        %v101616 = vadd.s32 %v101613, %v101608 (stack39)
        %v101618 = vshll.u32 %v101613, 26 (stack44)
        %v101619 = vshrl.u32 %v101613, 6 (stack45)
        %v101620 = vor.u32 %v101619, %v101618 (stack46)
        %v101621 = vxor.u32 %v101620, %v101616 (stack47)
        %v101624 = vadd.s32 %v101621, %v101616 (stack39)
        %v101628 = vadd.s32 %v101624, %v9 (stack39)
        %v101630 = vshll.u32 %v101621, 6 (stack44)
        %v101631 = vshrl.u32 %v101621, 26 (stack45)
        %v101632 = vor.u32 %v101631, %v101630 (stack46)
        %v101633 = vxor.u32 %v101632, %v101624 (stack47)
        %v101636 = vadd.s32 %v101633, %v8 (stack39)
        %v101640 = vadd.s32 1, %v101636 (stack39)
        %v101644 = vadd.s32 %v101640, %v101628 (stack39)
        %v101646 = vshll.u32 %v101640, 17 (stack44)
        %v101647 = vshrl.u32 %v101640, 15 (stack45)
        %v101648 = vor.u32 %v101647, %v101646 (stack46)
        %v101649 = vxor.u32 %v101648, %v101644 (stack47)
        %v101652 = vadd.s32 %v101649, %v101644 (stack39)
        %v101654 = vshll.u32 %v101649, 29 (stack44)
        %v101655 = vshrl.u32 %v101649, 3 (stack45)
        %v101656 = vor.u32 %v101655, %v101654 (stack46)
        %v101657 = vxor.u32 %v101656, %v101652 (stack47)
        %v101660 = vadd.s32 %v101657, %v101652 (stack39)
        %v101662 = vshll.u32 %v101657, 16 (stack44)
        %v101663 = vshrl.u32 %v101657, 16 (stack45)
        %v101664 = vor.u32 %v101663, %v101662 (stack46)
        %v101665 = vxor.u32 %v101664, %v101660 (stack47)
        %v101668 = vadd.s32 %v101665, %v101660 (stack39)
        %v101672 = vadd.s32 %v101668, %v8 (stack39)
        %v101674 = vshll.u32 %v101665, 24 (stack44)
        %v101675 = vshrl.u32 %v101665, 8 (stack45)
        %v101676 = vor.u32 %v101675, %v101674 (stack46)
        %v101677 = vxor.u32 %v101676, %v101668 (stack47)
        %v101680 = vadd.s32 %v101677, %v10 (stack39)
        %v101684 = vadd.s32 2, %v101680 (stack39)
        %v101688 = vadd.s32 %v101684, %v101672 (stack39)
        %v101690 = vshll.u32 %v101684, 13 (stack44)
        %v101691 = vshrl.u32 %v101684, 19 (stack45)
        %v101692 = vor.u32 %v101691, %v101690 (stack46)
        %v101693 = vxor.u32 %v101692, %v101688 (stack47)
        %v101696 = vadd.s32 %v101693, %v101688 (stack39)
        %v101698 = vshll.u32 %v101693, 15 (stack44)
        %v101699 = vshrl.u32 %v101693, 17 (stack45)
        %v101700 = vor.u32 %v101699, %v101698 (stack46)
        %v101701 = vxor.u32 %v101700, %v101696 (stack47)
        %v101704 = vadd.s32 %v101701, %v101696 (stack39)
        %v101706 = vshll.u32 %v101701, 26 (stack44)
        %v101707 = vshrl.u32 %v101701, 6 (stack45)
        %v101708 = vor.u32 %v101707, %v101706 (stack46)
        %v101709 = vxor.u32 %v101708, %v101704 (stack47)
        %v101712 = vadd.s32 %v101709, %v101704 (stack39)
        %v101716 = vadd.s32 %v101712, %v10 (stack39)
        %v101718 = vshll.u32 %v101709, 6 (stack44)
        %v101719 = vshrl.u32 %v101709, 26 (stack45)
        %v101720 = vor.u32 %v101719, %v101718 (stack46)
        %v101721 = vxor.u32 %v101720, %v101712 (stack47)
        %v101724 = vadd.s32 %v101721, %v9 (stack39)
        %v101728 = vadd.s32 3, %v101724 (stack39)
        %v101732 = vadd.s32 %v101728, %v101716 (stack39)
        %v101734 = vshll.u32 %v101728, 17 (stack44)
        %v101735 = vshrl.u32 %v101728, 15 (stack45)
        %v101736 = vor.u32 %v101735, %v101734 (stack46)
        %v101737 = vxor.u32 %v101736, %v101732 (stack47)
        %v101740 = vadd.s32 %v101737, %v101732 (stack39)
        %v101742 = vshll.u32 %v101737, 29 (stack44)
        %v101743 = vshrl.u32 %v101737, 3 (stack45)
        %v101744 = vor.u32 %v101743, %v101742 (stack46)
        %v101745 = vxor.u32 %v101744, %v101740 (stack47)
        %v101748 = vadd.s32 %v101745, %v101740 (stack39)
        %v101750 = vshll.u32 %v101745, 16 (stack44)
        %v101751 = vshrl.u32 %v101745, 16 (stack45)
        %v101752 = vor.u32 %v101751, %v101750 (stack46)
        %v101753 = vxor.u32 %v101752, %v101748 (stack47)
        %v101756 = vadd.s32 %v101753, %v101748 (stack39)
        %v101760 = vadd.s32 %v101756, %v9 (stack39)
        %v101762 = vshll.u32 %v101753, 24 (stack44)
        %v101763 = vshrl.u32 %v101753, 8 (stack45)
        %v101764 = vor.u32 %v101763, %v101762 (stack46)
        %v101765 = vxor.u32 %v101764, %v101756 (stack47)
        %v101768 = vadd.s32 %v101765, %v8 (stack39)
        %v101772 = vadd.s32 4, %v101768 (stack39)
        %v101776 = vadd.s32 %v101772, %v101760 (stack39)
        %v101778 = vshll.u32 %v101772, 13 (stack44)
        %v101779 = vshrl.u32 %v101772, 19 (stack45)
        %v101780 = vor.u32 %v101779, %v101778 (stack46)
        %v101781 = vxor.u32 %v101780, %v101776 (stack47)
        %v101784 = vadd.s32 %v101781, %v101776 (stack39)
        %v101786 = vshll.u32 %v101781, 15 (stack44)
        %v101787 = vshrl.u32 %v101781, 17 (stack45)
        %v101788 = vor.u32 %v101787, %v101786 (stack46)
        %v101789 = vxor.u32 %v101788, %v101784 (stack47)
        %v101792 = vadd.s32 %v101789, %v101784 (stack39)
        %v101794 = vshll.u32 %v101789, 26 (stack44)
        %v101795 = vshrl.u32 %v101789, 6 (stack45)
        %v101796 = vor.u32 %v101795, %v101794 (stack46)
        %v101797 = vxor.u32 %v101796, %v101792 (stack47)
        %v101800 = vadd.s32 %v101797, %v101792 (stack39)
        %v101804 = vadd.s32 %v101800, %v8 (stack39)
        %v101806 = vshll.u32 %v101797, 6 (stack44)
        %v101807 = vshrl.u32 %v101797, 26 (stack45)
        %v101808 = vor.u32 %v101807, %v101806 (stack46)
        %v101809 = vxor.u32 %v101808, %v101800 (stack47)
        %v101812 = vadd.s32 %v101809, %v10 (stack39)
        %v101816 = vadd.s32 5, %v101812 (stack39)
        %v101818 = vxor.u32 %v101816, %v101804 (stack47)
        %v101819 = vand.u32.u8 255, %v101818 (stack48)
        %v101820 = vand.u32 65535, %v101819 (stack49)
        %v101821 = vshrl.u32 %v101820, 1 (stack50)
        %v101822 = vor.u32 16256, %v101821 (stack46)
        %v101823 = vand.u32.u16 65535, %v101822 (stack51)
        %v120290 = vadd.low.f32.bf16 -1.0, %v101823 (stack52)
        %v101832 = vmul.f32 2.0, %v120290 (stack53)
        %v101836 = vadd.f32 -0.99609375, %v101832 (stack52)
        %v101840 = vmax.f32 %v101836, -0.99609375 (stack54)
        %v101842 = vand.u32 2147483647, %v101840 (stack55)
        %vm101845 = vcmp.eq.f32.partialorder %v101842, 1.0 (stack56)
        %v101850 = vmul.f32 inf, %v101840 (stack53)
        %v101852 = vxor.u32 2147483648, %v101840 (stack57)
        %v101855 = vmul.f32 %v101852, %v101840 (stack53)
        %v101857 = vadd.f32 1.0, %v101855 (stack58)
        %v101858 = vlog2.pop %v101857 (stack59)
        %v101859 = vmul.f32 0.6931472, %v101858 (stack60)
        %v101860 = vmul.f32 -0.5, %v101855 (stack61)
        %v101861 = vadd.f32 1.0, %v101860 (stack62)
        %v101862 = vmul.f32 %v101861, %v101855 (stack63)
        %v101863 = vand.u32 2147483647, %v101855 (stack64)
        %vm101864 = vcmp.lt.f32.partialorder %v101863, 0.0004427343 (stack65)
        %v101865 = vsel /*vm=*/%vm101864, /*on_true_vy=*/%v101862, /*on_false_vx=*/%v101859 (stack66)
        %v101866 = vxor.u32 2147483648, %v101865 (stack57)
        %vm101869 = vcmp.lt.f32.partialorder %v101866, 5.0 (stack56)
        %v101874 = vsel /*vm=*/%vm101869, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v101878 = vsel /*vm=*/%vm101869, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v101882 = vsel /*vm=*/%vm101869, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v101886 = vsel /*vm=*/%vm101869, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v101890 = vsel /*vm=*/%vm101869, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v101894 = vsel /*vm=*/%vm101869, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v101898 = vsel /*vm=*/%vm101869, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v101902 = vsel /*vm=*/%vm101869, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v101906 = vsel /*vm=*/%vm101869, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v101910 = vadd.f32 -2.5, %v101866 (stack52)
        %v101912 = vrsqrt.pop %v101866 (stack67)
        %v101913 = vmul.f32 %v101912, %v101866 (stack68)
        %vm101914 = vcmp.eq.f32.partialorder %v101866, inf (stack69)
        %v101915 = vsel /*vm=*/%vm101914, /*on_true_vy=*/%v101866, /*on_false_vx=*/%v101913 (stack70)
        %vm101916 = vcmp.eq.f32.partialorder %v101866, 0.0 (stack71)
        %v101917 = vand.u32 2147483648, %v101866 (stack72)
        %v101918 = vsel /*vm=*/%vm101916, /*on_true_vy=*/%v101917, /*on_false_vx=*/%v101915 (stack73)
        %v101921 = vadd.f32 -3.0, %v101918 (stack52)
        %v101925 = vsel /*vm=*/%vm101869, /*on_true_vy=*/%v101910, /*on_false_vx=*/%v101921 (stack43)
        %v101929 = vmul.f32 %v101925, %v101906 (stack53)
        %v101933 = vadd.f32 %v101929, %v101902 (stack52)
        %v101937 = vmul.f32 %v101933, %v101925 (stack53)
        %v101941 = vadd.f32 %v101937, %v101898 (stack52)
        %v101945 = vmul.f32 %v101941, %v101925 (stack53)
        %v101949 = vadd.f32 %v101945, %v101894 (stack52)
        %v101953 = vmul.f32 %v101949, %v101925 (stack53)
        %v101957 = vadd.f32 %v101953, %v101890 (stack52)
        %v101961 = vmul.f32 %v101957, %v101925 (stack53)
        %v101965 = vadd.f32 %v101961, %v101886 (stack52)
        %v101969 = vmul.f32 %v101965, %v101925 (stack53)
        %v101973 = vadd.f32 %v101969, %v101882 (stack52)
        %v101977 = vmul.f32 %v101973, %v101925 (stack53)
        %v101981 = vadd.f32 %v101977, %v101878 (stack52)
        %v101985 = vmul.f32 %v101981, %v101925 (stack53)
        %v101989 = vadd.f32 %v101985, %v101874 (stack52)
        %v101993 = vmul.f32 %v101989, %v101840 (stack53)
        %v101997 = vsel /*vm=*/%vm101845, /*on_true_vy=*/%v101850, /*on_false_vx=*/%v101993 (stack43)
        %v102001 = vmul.f32 1.4140625, %v101997 (stack53)
        %v102004 = vpack.c.bf16 0.0, %v102001 (stack74)
        %120291 = vst [vmem:[%s280 + $0xec] sm:$0xf] /*vst_source=*/%v102004 (stack75)
        %v102008 = vadd.s32 %v101083, %v1381 (stack39)
        %v102018 = vadd.s32 %v102008, %v415 (stack39)
        %vm102022 = vcmp.lt.u32.totalorder %v102018, %v102008 (stack42)
        %vm102027 = vcmp.lt.u32.totalorder %v102008, %v1381 (stack42)
        %v102032 = vadd.s32 %v101066, %v1368 (stack39)
        %v102036 = vadd.s32 1, %v102032 (stack39)
        %v102040 = vsel /*vm=*/%vm102027, /*on_true_vy=*/%v102036, /*on_false_vx=*/%v102032 (stack43)
        %v102044 = vadd.s32 1, %v102040 (stack39)
        %v102048 = vsel /*vm=*/%vm102022, /*on_true_vy=*/%v102044, /*on_false_vx=*/%v102040 (stack43)
        %v102053 = vadd.s32 %v102048, %v10 (stack39)
        %v102057 = vadd.s32 %v102018, %v9 (stack39)
        %v102061 = vadd.s32 %v102057, %v102053 (stack39)
        %v102063 = vshll.u32 %v102057, 13 (stack44)
        %v102064 = vshrl.u32 %v102057, 19 (stack45)
        %v102065 = vor.u32 %v102064, %v102063 (stack46)
        %v102066 = vxor.u32 %v102065, %v102061 (stack47)
        %v102069 = vadd.s32 %v102066, %v102061 (stack39)
        %v102071 = vshll.u32 %v102066, 15 (stack44)
        %v102072 = vshrl.u32 %v102066, 17 (stack45)
        %v102073 = vor.u32 %v102072, %v102071 (stack46)
        %v102074 = vxor.u32 %v102073, %v102069 (stack47)
        %v102077 = vadd.s32 %v102074, %v102069 (stack39)
        %v102079 = vshll.u32 %v102074, 26 (stack44)
        %v102080 = vshrl.u32 %v102074, 6 (stack45)
        %v102081 = vor.u32 %v102080, %v102079 (stack46)
        %v102082 = vxor.u32 %v102081, %v102077 (stack47)
        %v102085 = vadd.s32 %v102082, %v102077 (stack39)
        %v102089 = vadd.s32 %v102085, %v9 (stack39)
        %v102091 = vshll.u32 %v102082, 6 (stack44)
        %v102092 = vshrl.u32 %v102082, 26 (stack45)
        %v102093 = vor.u32 %v102092, %v102091 (stack46)
        %v102094 = vxor.u32 %v102093, %v102085 (stack47)
        %v102097 = vadd.s32 %v102094, %v8 (stack39)
        %v102101 = vadd.s32 1, %v102097 (stack39)
        %v102105 = vadd.s32 %v102101, %v102089 (stack39)
        %v102107 = vshll.u32 %v102101, 17 (stack44)
        %v102108 = vshrl.u32 %v102101, 15 (stack45)
        %v102109 = vor.u32 %v102108, %v102107 (stack46)
        %v102110 = vxor.u32 %v102109, %v102105 (stack47)
        %v102113 = vadd.s32 %v102110, %v102105 (stack39)
        %v102115 = vshll.u32 %v102110, 29 (stack44)
        %v102116 = vshrl.u32 %v102110, 3 (stack45)
        %v102117 = vor.u32 %v102116, %v102115 (stack46)
        %v102118 = vxor.u32 %v102117, %v102113 (stack47)
        %v102121 = vadd.s32 %v102118, %v102113 (stack39)
        %v102123 = vshll.u32 %v102118, 16 (stack44)
        %v102124 = vshrl.u32 %v102118, 16 (stack45)
        %v102125 = vor.u32 %v102124, %v102123 (stack46)
        %v102126 = vxor.u32 %v102125, %v102121 (stack47)
        %v102129 = vadd.s32 %v102126, %v102121 (stack39)
        %v102133 = vadd.s32 %v102129, %v8 (stack39)
        %v102135 = vshll.u32 %v102126, 24 (stack44)
        %v102136 = vshrl.u32 %v102126, 8 (stack45)
        %v102137 = vor.u32 %v102136, %v102135 (stack46)
        %v102138 = vxor.u32 %v102137, %v102129 (stack47)
        %v102141 = vadd.s32 %v102138, %v10 (stack39)
        %v102145 = vadd.s32 2, %v102141 (stack39)
        %v102149 = vadd.s32 %v102145, %v102133 (stack39)
        %v102151 = vshll.u32 %v102145, 13 (stack44)
        %v102152 = vshrl.u32 %v102145, 19 (stack45)
        %v102153 = vor.u32 %v102152, %v102151 (stack46)
        %v102154 = vxor.u32 %v102153, %v102149 (stack47)
        %v102157 = vadd.s32 %v102154, %v102149 (stack39)
        %v102159 = vshll.u32 %v102154, 15 (stack44)
        %v102160 = vshrl.u32 %v102154, 17 (stack45)
        %v102161 = vor.u32 %v102160, %v102159 (stack46)
        %v102162 = vxor.u32 %v102161, %v102157 (stack47)
        %v102165 = vadd.s32 %v102162, %v102157 (stack39)
        %v102167 = vshll.u32 %v102162, 26 (stack44)
        %v102168 = vshrl.u32 %v102162, 6 (stack45)
        %v102169 = vor.u32 %v102168, %v102167 (stack46)
        %v102170 = vxor.u32 %v102169, %v102165 (stack47)
        %v102173 = vadd.s32 %v102170, %v102165 (stack39)
        %v102177 = vadd.s32 %v102173, %v10 (stack39)
        %v102179 = vshll.u32 %v102170, 6 (stack44)
        %v102180 = vshrl.u32 %v102170, 26 (stack45)
        %v102181 = vor.u32 %v102180, %v102179 (stack46)
        %v102182 = vxor.u32 %v102181, %v102173 (stack47)
        %v102185 = vadd.s32 %v102182, %v9 (stack39)
        %v102189 = vadd.s32 3, %v102185 (stack39)
        %v102193 = vadd.s32 %v102189, %v102177 (stack39)
        %v102195 = vshll.u32 %v102189, 17 (stack44)
        %v102196 = vshrl.u32 %v102189, 15 (stack45)
        %v102197 = vor.u32 %v102196, %v102195 (stack46)
        %v102198 = vxor.u32 %v102197, %v102193 (stack47)
        %v102201 = vadd.s32 %v102198, %v102193 (stack39)
        %v102203 = vshll.u32 %v102198, 29 (stack44)
        %v102204 = vshrl.u32 %v102198, 3 (stack45)
        %v102205 = vor.u32 %v102204, %v102203 (stack46)
        %v102206 = vxor.u32 %v102205, %v102201 (stack47)
        %v102209 = vadd.s32 %v102206, %v102201 (stack39)
        %v102211 = vshll.u32 %v102206, 16 (stack44)
        %v102212 = vshrl.u32 %v102206, 16 (stack45)
        %v102213 = vor.u32 %v102212, %v102211 (stack46)
        %v102214 = vxor.u32 %v102213, %v102209 (stack47)
        %v102217 = vadd.s32 %v102214, %v102209 (stack39)
        %v102221 = vadd.s32 %v102217, %v9 (stack39)
        %v102223 = vshll.u32 %v102214, 24 (stack44)
        %v102224 = vshrl.u32 %v102214, 8 (stack45)
        %v102225 = vor.u32 %v102224, %v102223 (stack46)
        %v102226 = vxor.u32 %v102225, %v102217 (stack47)
        %v102229 = vadd.s32 %v102226, %v8 (stack39)
        %v102233 = vadd.s32 4, %v102229 (stack39)
        %v102237 = vadd.s32 %v102233, %v102221 (stack39)
        %v102239 = vshll.u32 %v102233, 13 (stack44)
        %v102240 = vshrl.u32 %v102233, 19 (stack45)
        %v102241 = vor.u32 %v102240, %v102239 (stack46)
        %v102242 = vxor.u32 %v102241, %v102237 (stack47)
        %v102245 = vadd.s32 %v102242, %v102237 (stack39)
        %v102247 = vshll.u32 %v102242, 15 (stack44)
        %v102248 = vshrl.u32 %v102242, 17 (stack45)
        %v102249 = vor.u32 %v102248, %v102247 (stack46)
        %v102250 = vxor.u32 %v102249, %v102245 (stack47)
        %v102253 = vadd.s32 %v102250, %v102245 (stack39)
        %v102255 = vshll.u32 %v102250, 26 (stack44)
        %v102256 = vshrl.u32 %v102250, 6 (stack45)
        %v102257 = vor.u32 %v102256, %v102255 (stack46)
        %v102258 = vxor.u32 %v102257, %v102253 (stack47)
        %v102261 = vadd.s32 %v102258, %v102253 (stack39)
        %v102265 = vadd.s32 %v102261, %v8 (stack39)
        %v102267 = vshll.u32 %v102258, 6 (stack44)
        %v102268 = vshrl.u32 %v102258, 26 (stack45)
        %v102269 = vor.u32 %v102268, %v102267 (stack46)
        %v102270 = vxor.u32 %v102269, %v102261 (stack47)
        %v102273 = vadd.s32 %v102270, %v10 (stack39)
        %v102277 = vadd.s32 5, %v102273 (stack39)
        %v102279 = vxor.u32 %v102277, %v102265 (stack47)
        %v102280 = vand.u32.u8 255, %v102279 (stack48)
        %v102281 = vand.u32 65535, %v102280 (stack49)
        %v102282 = vshrl.u32 %v102281, 1 (stack50)
        %v102283 = vor.u32 16256, %v102282 (stack46)
        %v102284 = vand.u32.u16 65535, %v102283 (stack51)
        %v120292 = vadd.low.f32.bf16 -1.0, %v102284 (stack52)
        %v102293 = vmul.f32 2.0, %v120292 (stack53)
        %v102297 = vadd.f32 -0.99609375, %v102293 (stack52)
        %v102301 = vmax.f32 %v102297, -0.99609375 (stack54)
        %v102303 = vand.u32 2147483647, %v102301 (stack55)
        %vm102306 = vcmp.eq.f32.partialorder %v102303, 1.0 (stack56)
        %v102311 = vmul.f32 inf, %v102301 (stack53)
        %v102313 = vxor.u32 2147483648, %v102301 (stack57)
        %v102316 = vmul.f32 %v102313, %v102301 (stack53)
        %v102318 = vadd.f32 1.0, %v102316 (stack58)
        %v102319 = vlog2.pop %v102318 (stack59)
        %v102320 = vmul.f32 0.6931472, %v102319 (stack60)
        %v102321 = vmul.f32 -0.5, %v102316 (stack61)
        %v102322 = vadd.f32 1.0, %v102321 (stack62)
        %v102323 = vmul.f32 %v102322, %v102316 (stack63)
        %v102324 = vand.u32 2147483647, %v102316 (stack64)
        %vm102325 = vcmp.lt.f32.partialorder %v102324, 0.0004427343 (stack65)
        %v102326 = vsel /*vm=*/%vm102325, /*on_true_vy=*/%v102323, /*on_false_vx=*/%v102320 (stack66)
        %v102327 = vxor.u32 2147483648, %v102326 (stack57)
        %vm102330 = vcmp.lt.f32.partialorder %v102327, 5.0 (stack56)
        %v102335 = vsel /*vm=*/%vm102330, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v102339 = vsel /*vm=*/%vm102330, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v102343 = vsel /*vm=*/%vm102330, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v102347 = vsel /*vm=*/%vm102330, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v102351 = vsel /*vm=*/%vm102330, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v102355 = vsel /*vm=*/%vm102330, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v102359 = vsel /*vm=*/%vm102330, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v102363 = vsel /*vm=*/%vm102330, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v102367 = vsel /*vm=*/%vm102330, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v102371 = vadd.f32 -2.5, %v102327 (stack52)
        %v102373 = vrsqrt.pop %v102327 (stack67)
        %v102374 = vmul.f32 %v102373, %v102327 (stack68)
        %vm102375 = vcmp.eq.f32.partialorder %v102327, inf (stack69)
        %v102376 = vsel /*vm=*/%vm102375, /*on_true_vy=*/%v102327, /*on_false_vx=*/%v102374 (stack70)
        %vm102377 = vcmp.eq.f32.partialorder %v102327, 0.0 (stack71)
        %v102378 = vand.u32 2147483648, %v102327 (stack72)
        %v102379 = vsel /*vm=*/%vm102377, /*on_true_vy=*/%v102378, /*on_false_vx=*/%v102376 (stack73)
        %v102382 = vadd.f32 -3.0, %v102379 (stack52)
        %v102386 = vsel /*vm=*/%vm102330, /*on_true_vy=*/%v102371, /*on_false_vx=*/%v102382 (stack43)
        %v102390 = vmul.f32 %v102386, %v102367 (stack53)
        %v102394 = vadd.f32 %v102390, %v102363 (stack52)
        %v102398 = vmul.f32 %v102394, %v102386 (stack53)
        %v102402 = vadd.f32 %v102398, %v102359 (stack52)
        %v102406 = vmul.f32 %v102402, %v102386 (stack53)
        %v102410 = vadd.f32 %v102406, %v102355 (stack52)
        %v102414 = vmul.f32 %v102410, %v102386 (stack53)
        %v102418 = vadd.f32 %v102414, %v102351 (stack52)
        %v102422 = vmul.f32 %v102418, %v102386 (stack53)
        %v102426 = vadd.f32 %v102422, %v102347 (stack52)
        %v102430 = vmul.f32 %v102426, %v102386 (stack53)
        %v102434 = vadd.f32 %v102430, %v102343 (stack52)
        %v102438 = vmul.f32 %v102434, %v102386 (stack53)
        %v102442 = vadd.f32 %v102438, %v102339 (stack52)
        %v102446 = vmul.f32 %v102442, %v102386 (stack53)
        %v102450 = vadd.f32 %v102446, %v102335 (stack52)
        %v102454 = vmul.f32 %v102450, %v102301 (stack53)
        %v102458 = vsel /*vm=*/%vm102306, /*on_true_vy=*/%v102311, /*on_false_vx=*/%v102454 (stack43)
        %v102462 = vmul.f32 1.4140625, %v102458 (stack53)
        %v102465 = vpack.c.bf16 0.0, %v102462 (stack74)
        %120293 = vst [vmem:[%s280 + $0x16c] sm:$0xf] /*vst_source=*/%v102465 (stack75)
        %v102469 = vadd.s32 %v101083, %v1868 (stack39)
        %v102479 = vadd.s32 %v102469, %v415 (stack39)
        %vm102483 = vcmp.lt.u32.totalorder %v102479, %v102469 (stack42)
        %vm102488 = vcmp.lt.u32.totalorder %v102469, %v1868 (stack42)
        %v102493 = vadd.s32 %v101066, %v1855 (stack39)
        %v102497 = vadd.s32 1, %v102493 (stack39)
        %v102501 = vsel /*vm=*/%vm102488, /*on_true_vy=*/%v102497, /*on_false_vx=*/%v102493 (stack43)
        %v102505 = vadd.s32 1, %v102501 (stack39)
        %v102509 = vsel /*vm=*/%vm102483, /*on_true_vy=*/%v102505, /*on_false_vx=*/%v102501 (stack43)
        %v102514 = vadd.s32 %v102509, %v10 (stack39)
        %v102518 = vadd.s32 %v102479, %v9 (stack39)
        %v102522 = vadd.s32 %v102518, %v102514 (stack39)
        %v102524 = vshll.u32 %v102518, 13 (stack44)
        %v102525 = vshrl.u32 %v102518, 19 (stack45)
        %v102526 = vor.u32 %v102525, %v102524 (stack46)
        %v102527 = vxor.u32 %v102526, %v102522 (stack47)
        %v102530 = vadd.s32 %v102527, %v102522 (stack39)
        %v102532 = vshll.u32 %v102527, 15 (stack44)
        %v102533 = vshrl.u32 %v102527, 17 (stack45)
        %v102534 = vor.u32 %v102533, %v102532 (stack46)
        %v102535 = vxor.u32 %v102534, %v102530 (stack47)
        %v102538 = vadd.s32 %v102535, %v102530 (stack39)
        %v102540 = vshll.u32 %v102535, 26 (stack44)
        %v102541 = vshrl.u32 %v102535, 6 (stack45)
        %v102542 = vor.u32 %v102541, %v102540 (stack46)
        %v102543 = vxor.u32 %v102542, %v102538 (stack47)
        %v102546 = vadd.s32 %v102543, %v102538 (stack39)
        %v102550 = vadd.s32 %v102546, %v9 (stack39)
        %v102552 = vshll.u32 %v102543, 6 (stack44)
        %v102553 = vshrl.u32 %v102543, 26 (stack45)
        %v102554 = vor.u32 %v102553, %v102552 (stack46)
        %v102555 = vxor.u32 %v102554, %v102546 (stack47)
        %v102558 = vadd.s32 %v102555, %v8 (stack39)
        %v102562 = vadd.s32 1, %v102558 (stack39)
        %v102566 = vadd.s32 %v102562, %v102550 (stack39)
        %v102568 = vshll.u32 %v102562, 17 (stack44)
        %v102569 = vshrl.u32 %v102562, 15 (stack45)
        %v102570 = vor.u32 %v102569, %v102568 (stack46)
        %v102571 = vxor.u32 %v102570, %v102566 (stack47)
        %v102574 = vadd.s32 %v102571, %v102566 (stack39)
        %v102576 = vshll.u32 %v102571, 29 (stack44)
        %v102577 = vshrl.u32 %v102571, 3 (stack45)
        %v102578 = vor.u32 %v102577, %v102576 (stack46)
        %v102579 = vxor.u32 %v102578, %v102574 (stack47)
        %v102582 = vadd.s32 %v102579, %v102574 (stack39)
        %v102584 = vshll.u32 %v102579, 16 (stack44)
        %v102585 = vshrl.u32 %v102579, 16 (stack45)
        %v102586 = vor.u32 %v102585, %v102584 (stack46)
        %v102587 = vxor.u32 %v102586, %v102582 (stack47)
        %v102590 = vadd.s32 %v102587, %v102582 (stack39)
        %v102594 = vadd.s32 %v102590, %v8 (stack39)
        %v102596 = vshll.u32 %v102587, 24 (stack44)
        %v102597 = vshrl.u32 %v102587, 8 (stack45)
        %v102598 = vor.u32 %v102597, %v102596 (stack46)
        %v102599 = vxor.u32 %v102598, %v102590 (stack47)
        %v102602 = vadd.s32 %v102599, %v10 (stack39)
        %v102606 = vadd.s32 2, %v102602 (stack39)
        %v102610 = vadd.s32 %v102606, %v102594 (stack39)
        %v102612 = vshll.u32 %v102606, 13 (stack44)
        %v102613 = vshrl.u32 %v102606, 19 (stack45)
        %v102614 = vor.u32 %v102613, %v102612 (stack46)
        %v102615 = vxor.u32 %v102614, %v102610 (stack47)
        %v102618 = vadd.s32 %v102615, %v102610 (stack39)
        %v102620 = vshll.u32 %v102615, 15 (stack44)
        %v102621 = vshrl.u32 %v102615, 17 (stack45)
        %v102622 = vor.u32 %v102621, %v102620 (stack46)
        %v102623 = vxor.u32 %v102622, %v102618 (stack47)
        %v102626 = vadd.s32 %v102623, %v102618 (stack39)
        %v102628 = vshll.u32 %v102623, 26 (stack44)
        %v102629 = vshrl.u32 %v102623, 6 (stack45)
        %v102630 = vor.u32 %v102629, %v102628 (stack46)
        %v102631 = vxor.u32 %v102630, %v102626 (stack47)
        %v102634 = vadd.s32 %v102631, %v102626 (stack39)
        %v102638 = vadd.s32 %v102634, %v10 (stack39)
        %v102640 = vshll.u32 %v102631, 6 (stack44)
        %v102641 = vshrl.u32 %v102631, 26 (stack45)
        %v102642 = vor.u32 %v102641, %v102640 (stack46)
        %v102643 = vxor.u32 %v102642, %v102634 (stack47)
        %v102646 = vadd.s32 %v102643, %v9 (stack39)
        %v102650 = vadd.s32 3, %v102646 (stack39)
        %v102654 = vadd.s32 %v102650, %v102638 (stack39)
        %v102656 = vshll.u32 %v102650, 17 (stack44)
        %v102657 = vshrl.u32 %v102650, 15 (stack45)
        %v102658 = vor.u32 %v102657, %v102656 (stack46)
        %v102659 = vxor.u32 %v102658, %v102654 (stack47)
        %v102662 = vadd.s32 %v102659, %v102654 (stack39)
        %v102664 = vshll.u32 %v102659, 29 (stack44)
        %v102665 = vshrl.u32 %v102659, 3 (stack45)
        %v102666 = vor.u32 %v102665, %v102664 (stack46)
        %v102667 = vxor.u32 %v102666, %v102662 (stack47)
        %v102670 = vadd.s32 %v102667, %v102662 (stack39)
        %v102672 = vshll.u32 %v102667, 16 (stack44)
        %v102673 = vshrl.u32 %v102667, 16 (stack45)
        %v102674 = vor.u32 %v102673, %v102672 (stack46)
        %v102675 = vxor.u32 %v102674, %v102670 (stack47)
        %v102678 = vadd.s32 %v102675, %v102670 (stack39)
        %v102682 = vadd.s32 %v102678, %v9 (stack39)
        %v102684 = vshll.u32 %v102675, 24 (stack44)
        %v102685 = vshrl.u32 %v102675, 8 (stack45)
        %v102686 = vor.u32 %v102685, %v102684 (stack46)
        %v102687 = vxor.u32 %v102686, %v102678 (stack47)
        %v102690 = vadd.s32 %v102687, %v8 (stack39)
        %v102694 = vadd.s32 4, %v102690 (stack39)
        %v102698 = vadd.s32 %v102694, %v102682 (stack39)
        %v102700 = vshll.u32 %v102694, 13 (stack44)
        %v102701 = vshrl.u32 %v102694, 19 (stack45)
        %v102702 = vor.u32 %v102701, %v102700 (stack46)
        %v102703 = vxor.u32 %v102702, %v102698 (stack47)
        %v102706 = vadd.s32 %v102703, %v102698 (stack39)
        %v102708 = vshll.u32 %v102703, 15 (stack44)
        %v102709 = vshrl.u32 %v102703, 17 (stack45)
        %v102710 = vor.u32 %v102709, %v102708 (stack46)
        %v102711 = vxor.u32 %v102710, %v102706 (stack47)
        %v102714 = vadd.s32 %v102711, %v102706 (stack39)
        %v102716 = vshll.u32 %v102711, 26 (stack44)
        %v102717 = vshrl.u32 %v102711, 6 (stack45)
        %v102718 = vor.u32 %v102717, %v102716 (stack46)
        %v102719 = vxor.u32 %v102718, %v102714 (stack47)
        %v102722 = vadd.s32 %v102719, %v102714 (stack39)
        %v102726 = vadd.s32 %v102722, %v8 (stack39)
        %v102728 = vshll.u32 %v102719, 6 (stack44)
        %v102729 = vshrl.u32 %v102719, 26 (stack45)
        %v102730 = vor.u32 %v102729, %v102728 (stack46)
        %v102731 = vxor.u32 %v102730, %v102722 (stack47)
        %v102734 = vadd.s32 %v102731, %v10 (stack39)
        %v102738 = vadd.s32 5, %v102734 (stack39)
        %v102740 = vxor.u32 %v102738, %v102726 (stack47)
        %v102741 = vand.u32.u8 255, %v102740 (stack48)
        %v102742 = vand.u32 65535, %v102741 (stack49)
        %v102743 = vshrl.u32 %v102742, 1 (stack50)
        %v102744 = vor.u32 16256, %v102743 (stack46)
        %v102745 = vand.u32.u16 65535, %v102744 (stack51)
        %v120294 = vadd.low.f32.bf16 -1.0, %v102745 (stack52)
        %v102754 = vmul.f32 2.0, %v120294 (stack53)
        %v102758 = vadd.f32 -0.99609375, %v102754 (stack52)
        %v102762 = vmax.f32 %v102758, -0.99609375 (stack54)
        %v102764 = vand.u32 2147483647, %v102762 (stack55)
        %vm102767 = vcmp.eq.f32.partialorder %v102764, 1.0 (stack56)
        %v102772 = vmul.f32 inf, %v102762 (stack53)
        %v102774 = vxor.u32 2147483648, %v102762 (stack57)
        %v102777 = vmul.f32 %v102774, %v102762 (stack53)
        %v102779 = vadd.f32 1.0, %v102777 (stack58)
        %v102780 = vlog2.pop %v102779 (stack59)
        %v102781 = vmul.f32 0.6931472, %v102780 (stack60)
        %v102782 = vmul.f32 -0.5, %v102777 (stack61)
        %v102783 = vadd.f32 1.0, %v102782 (stack62)
        %v102784 = vmul.f32 %v102783, %v102777 (stack63)
        %v102785 = vand.u32 2147483647, %v102777 (stack64)
        %vm102786 = vcmp.lt.f32.partialorder %v102785, 0.0004427343 (stack65)
        %v102787 = vsel /*vm=*/%vm102786, /*on_true_vy=*/%v102784, /*on_false_vx=*/%v102781 (stack66)
        %v102788 = vxor.u32 2147483648, %v102787 (stack57)
        %vm102791 = vcmp.lt.f32.partialorder %v102788, 5.0 (stack56)
        %v102796 = vsel /*vm=*/%vm102791, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v102800 = vsel /*vm=*/%vm102791, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v102804 = vsel /*vm=*/%vm102791, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v102808 = vsel /*vm=*/%vm102791, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v102812 = vsel /*vm=*/%vm102791, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v102816 = vsel /*vm=*/%vm102791, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v102820 = vsel /*vm=*/%vm102791, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v102824 = vsel /*vm=*/%vm102791, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v102828 = vsel /*vm=*/%vm102791, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v102832 = vadd.f32 -2.5, %v102788 (stack52)
        %v102834 = vrsqrt.pop %v102788 (stack67)
        %v102835 = vmul.f32 %v102834, %v102788 (stack68)
        %vm102836 = vcmp.eq.f32.partialorder %v102788, inf (stack69)
        %v102837 = vsel /*vm=*/%vm102836, /*on_true_vy=*/%v102788, /*on_false_vx=*/%v102835 (stack70)
        %vm102838 = vcmp.eq.f32.partialorder %v102788, 0.0 (stack71)
        %v102839 = vand.u32 2147483648, %v102788 (stack72)
        %v102840 = vsel /*vm=*/%vm102838, /*on_true_vy=*/%v102839, /*on_false_vx=*/%v102837 (stack73)
        %v102843 = vadd.f32 -3.0, %v102840 (stack52)
        %v102847 = vsel /*vm=*/%vm102791, /*on_true_vy=*/%v102832, /*on_false_vx=*/%v102843 (stack43)
        %v102851 = vmul.f32 %v102847, %v102828 (stack53)
        %v102855 = vadd.f32 %v102851, %v102824 (stack52)
        %v102859 = vmul.f32 %v102855, %v102847 (stack53)
        %v102863 = vadd.f32 %v102859, %v102820 (stack52)
        %v102867 = vmul.f32 %v102863, %v102847 (stack53)
        %v102871 = vadd.f32 %v102867, %v102816 (stack52)
        %v102875 = vmul.f32 %v102871, %v102847 (stack53)
        %v102879 = vadd.f32 %v102875, %v102812 (stack52)
        %v102883 = vmul.f32 %v102879, %v102847 (stack53)
        %v102887 = vadd.f32 %v102883, %v102808 (stack52)
        %v102891 = vmul.f32 %v102887, %v102847 (stack53)
        %v102895 = vadd.f32 %v102891, %v102804 (stack52)
        %v102899 = vmul.f32 %v102895, %v102847 (stack53)
        %v102903 = vadd.f32 %v102899, %v102800 (stack52)
        %v102907 = vmul.f32 %v102903, %v102847 (stack53)
        %v102911 = vadd.f32 %v102907, %v102796 (stack52)
        %v102915 = vmul.f32 %v102911, %v102762 (stack53)
        %v102919 = vsel /*vm=*/%vm102767, /*on_true_vy=*/%v102772, /*on_false_vx=*/%v102915 (stack43)
        %v102923 = vmul.f32 1.4140625, %v102919 (stack53)
        %v102926 = vpack.c.bf16 0.0, %v102923 (stack74)
        %120295 = vst [vmem:[%s280 + $0x1ec] sm:$0xf] /*vst_source=*/%v102926 (stack75)
        %v102930 = vadd.s32 %v101083, %v2355 (stack39)
        %v102940 = vadd.s32 %v102930, %v415 (stack39)
        %vm102944 = vcmp.lt.u32.totalorder %v102940, %v102930 (stack42)
        %vm102949 = vcmp.lt.u32.totalorder %v102930, %v2355 (stack42)
        %v102954 = vadd.s32 %v101066, %v2342 (stack39)
        %v102958 = vadd.s32 1, %v102954 (stack39)
        %v102962 = vsel /*vm=*/%vm102949, /*on_true_vy=*/%v102958, /*on_false_vx=*/%v102954 (stack43)
        %v102966 = vadd.s32 1, %v102962 (stack39)
        %v102970 = vsel /*vm=*/%vm102944, /*on_true_vy=*/%v102966, /*on_false_vx=*/%v102962 (stack43)
        %v102975 = vadd.s32 %v102970, %v10 (stack39)
        %v102979 = vadd.s32 %v102940, %v9 (stack39)
        %v102983 = vadd.s32 %v102979, %v102975 (stack39)
        %v102985 = vshll.u32 %v102979, 13 (stack44)
        %v102986 = vshrl.u32 %v102979, 19 (stack45)
        %v102987 = vor.u32 %v102986, %v102985 (stack46)
        %v102988 = vxor.u32 %v102987, %v102983 (stack47)
        %v102991 = vadd.s32 %v102988, %v102983 (stack39)
        %v102993 = vshll.u32 %v102988, 15 (stack44)
        %v102994 = vshrl.u32 %v102988, 17 (stack45)
        %v102995 = vor.u32 %v102994, %v102993 (stack46)
        %v102996 = vxor.u32 %v102995, %v102991 (stack47)
        %v102999 = vadd.s32 %v102996, %v102991 (stack39)
        %v103001 = vshll.u32 %v102996, 26 (stack44)
        %v103002 = vshrl.u32 %v102996, 6 (stack45)
        %v103003 = vor.u32 %v103002, %v103001 (stack46)
        %v103004 = vxor.u32 %v103003, %v102999 (stack47)
        %v103007 = vadd.s32 %v103004, %v102999 (stack39)
        %v103011 = vadd.s32 %v103007, %v9 (stack39)
        %v103013 = vshll.u32 %v103004, 6 (stack44)
        %v103014 = vshrl.u32 %v103004, 26 (stack45)
        %v103015 = vor.u32 %v103014, %v103013 (stack46)
        %v103016 = vxor.u32 %v103015, %v103007 (stack47)
        %v103019 = vadd.s32 %v103016, %v8 (stack39)
        %v103023 = vadd.s32 1, %v103019 (stack39)
        %v103027 = vadd.s32 %v103023, %v103011 (stack39)
        %v103029 = vshll.u32 %v103023, 17 (stack44)
        %v103030 = vshrl.u32 %v103023, 15 (stack45)
        %v103031 = vor.u32 %v103030, %v103029 (stack46)
        %v103032 = vxor.u32 %v103031, %v103027 (stack47)
        %v103035 = vadd.s32 %v103032, %v103027 (stack39)
        %v103037 = vshll.u32 %v103032, 29 (stack44)
        %v103038 = vshrl.u32 %v103032, 3 (stack45)
        %v103039 = vor.u32 %v103038, %v103037 (stack46)
        %v103040 = vxor.u32 %v103039, %v103035 (stack47)
        %v103043 = vadd.s32 %v103040, %v103035 (stack39)
        %v103045 = vshll.u32 %v103040, 16 (stack44)
        %v103046 = vshrl.u32 %v103040, 16 (stack45)
        %v103047 = vor.u32 %v103046, %v103045 (stack46)
        %v103048 = vxor.u32 %v103047, %v103043 (stack47)
        %v103051 = vadd.s32 %v103048, %v103043 (stack39)
        %v103055 = vadd.s32 %v103051, %v8 (stack39)
        %v103057 = vshll.u32 %v103048, 24 (stack44)
        %v103058 = vshrl.u32 %v103048, 8 (stack45)
        %v103059 = vor.u32 %v103058, %v103057 (stack46)
        %v103060 = vxor.u32 %v103059, %v103051 (stack47)
        %v103063 = vadd.s32 %v103060, %v10 (stack39)
        %v103067 = vadd.s32 2, %v103063 (stack39)
        %v103071 = vadd.s32 %v103067, %v103055 (stack39)
        %v103073 = vshll.u32 %v103067, 13 (stack44)
        %v103074 = vshrl.u32 %v103067, 19 (stack45)
        %v103075 = vor.u32 %v103074, %v103073 (stack46)
        %v103076 = vxor.u32 %v103075, %v103071 (stack47)
        %v103079 = vadd.s32 %v103076, %v103071 (stack39)
        %v103081 = vshll.u32 %v103076, 15 (stack44)
        %v103082 = vshrl.u32 %v103076, 17 (stack45)
        %v103083 = vor.u32 %v103082, %v103081 (stack46)
        %v103084 = vxor.u32 %v103083, %v103079 (stack47)
        %v103087 = vadd.s32 %v103084, %v103079 (stack39)
        %v103089 = vshll.u32 %v103084, 26 (stack44)
        %v103090 = vshrl.u32 %v103084, 6 (stack45)
        %v103091 = vor.u32 %v103090, %v103089 (stack46)
        %v103092 = vxor.u32 %v103091, %v103087 (stack47)
        %v103095 = vadd.s32 %v103092, %v103087 (stack39)
        %v103099 = vadd.s32 %v103095, %v10 (stack39)
        %v103101 = vshll.u32 %v103092, 6 (stack44)
        %v103102 = vshrl.u32 %v103092, 26 (stack45)
        %v103103 = vor.u32 %v103102, %v103101 (stack46)
        %v103104 = vxor.u32 %v103103, %v103095 (stack47)
        %v103107 = vadd.s32 %v103104, %v9 (stack39)
        %v103111 = vadd.s32 3, %v103107 (stack39)
        %v103115 = vadd.s32 %v103111, %v103099 (stack39)
        %v103117 = vshll.u32 %v103111, 17 (stack44)
        %v103118 = vshrl.u32 %v103111, 15 (stack45)
        %v103119 = vor.u32 %v103118, %v103117 (stack46)
        %v103120 = vxor.u32 %v103119, %v103115 (stack47)
        %v103123 = vadd.s32 %v103120, %v103115 (stack39)
        %v103125 = vshll.u32 %v103120, 29 (stack44)
        %v103126 = vshrl.u32 %v103120, 3 (stack45)
        %v103127 = vor.u32 %v103126, %v103125 (stack46)
        %v103128 = vxor.u32 %v103127, %v103123 (stack47)
        %v103131 = vadd.s32 %v103128, %v103123 (stack39)
        %v103133 = vshll.u32 %v103128, 16 (stack44)
        %v103134 = vshrl.u32 %v103128, 16 (stack45)
        %v103135 = vor.u32 %v103134, %v103133 (stack46)
        %v103136 = vxor.u32 %v103135, %v103131 (stack47)
        %v103139 = vadd.s32 %v103136, %v103131 (stack39)
        %v103143 = vadd.s32 %v103139, %v9 (stack39)
        %v103145 = vshll.u32 %v103136, 24 (stack44)
        %v103146 = vshrl.u32 %v103136, 8 (stack45)
        %v103147 = vor.u32 %v103146, %v103145 (stack46)
        %v103148 = vxor.u32 %v103147, %v103139 (stack47)
        %v103151 = vadd.s32 %v103148, %v8 (stack39)
        %v103155 = vadd.s32 4, %v103151 (stack39)
        %v103159 = vadd.s32 %v103155, %v103143 (stack39)
        %v103161 = vshll.u32 %v103155, 13 (stack44)
        %v103162 = vshrl.u32 %v103155, 19 (stack45)
        %v103163 = vor.u32 %v103162, %v103161 (stack46)
        %v103164 = vxor.u32 %v103163, %v103159 (stack47)
        %v103167 = vadd.s32 %v103164, %v103159 (stack39)
        %v103169 = vshll.u32 %v103164, 15 (stack44)
        %v103170 = vshrl.u32 %v103164, 17 (stack45)
        %v103171 = vor.u32 %v103170, %v103169 (stack46)
        %v103172 = vxor.u32 %v103171, %v103167 (stack47)
        %v103175 = vadd.s32 %v103172, %v103167 (stack39)
        %v103177 = vshll.u32 %v103172, 26 (stack44)
        %v103178 = vshrl.u32 %v103172, 6 (stack45)
        %v103179 = vor.u32 %v103178, %v103177 (stack46)
        %v103180 = vxor.u32 %v103179, %v103175 (stack47)
        %v103183 = vadd.s32 %v103180, %v103175 (stack39)
        %v103187 = vadd.s32 %v103183, %v8 (stack39)
        %v103189 = vshll.u32 %v103180, 6 (stack44)
        %v103190 = vshrl.u32 %v103180, 26 (stack45)
        %v103191 = vor.u32 %v103190, %v103189 (stack46)
        %v103192 = vxor.u32 %v103191, %v103183 (stack47)
        %v103195 = vadd.s32 %v103192, %v10 (stack39)
        %v103199 = vadd.s32 5, %v103195 (stack39)
        %v103201 = vxor.u32 %v103199, %v103187 (stack47)
        %v103202 = vand.u32.u8 255, %v103201 (stack48)
        %v103203 = vand.u32 65535, %v103202 (stack49)
        %v103204 = vshrl.u32 %v103203, 1 (stack50)
        %v103205 = vor.u32 16256, %v103204 (stack46)
        %v103206 = vand.u32.u16 65535, %v103205 (stack51)
        %v120296 = vadd.low.f32.bf16 -1.0, %v103206 (stack52)
        %v103215 = vmul.f32 2.0, %v120296 (stack53)
        %v103219 = vadd.f32 -0.99609375, %v103215 (stack52)
        %v103223 = vmax.f32 %v103219, -0.99609375 (stack54)
        %v103225 = vand.u32 2147483647, %v103223 (stack55)
        %vm103228 = vcmp.eq.f32.partialorder %v103225, 1.0 (stack56)
        %v103233 = vmul.f32 inf, %v103223 (stack53)
        %v103235 = vxor.u32 2147483648, %v103223 (stack57)
        %v103238 = vmul.f32 %v103235, %v103223 (stack53)
        %v103240 = vadd.f32 1.0, %v103238 (stack58)
        %v103241 = vlog2.pop %v103240 (stack59)
        %v103242 = vmul.f32 0.6931472, %v103241 (stack60)
        %v103243 = vmul.f32 -0.5, %v103238 (stack61)
        %v103244 = vadd.f32 1.0, %v103243 (stack62)
        %v103245 = vmul.f32 %v103244, %v103238 (stack63)
        %v103246 = vand.u32 2147483647, %v103238 (stack64)
        %vm103247 = vcmp.lt.f32.partialorder %v103246, 0.0004427343 (stack65)
        %v103248 = vsel /*vm=*/%vm103247, /*on_true_vy=*/%v103245, /*on_false_vx=*/%v103242 (stack66)
        %v103249 = vxor.u32 2147483648, %v103248 (stack57)
        %vm103252 = vcmp.lt.f32.partialorder %v103249, 5.0 (stack56)
        %v103257 = vsel /*vm=*/%vm103252, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v103261 = vsel /*vm=*/%vm103252, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v103265 = vsel /*vm=*/%vm103252, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v103269 = vsel /*vm=*/%vm103252, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v103273 = vsel /*vm=*/%vm103252, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v103277 = vsel /*vm=*/%vm103252, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v103281 = vsel /*vm=*/%vm103252, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v103285 = vsel /*vm=*/%vm103252, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v103289 = vsel /*vm=*/%vm103252, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v103293 = vadd.f32 -2.5, %v103249 (stack52)
        %v103295 = vrsqrt.pop %v103249 (stack67)
        %v103296 = vmul.f32 %v103295, %v103249 (stack68)
        %vm103297 = vcmp.eq.f32.partialorder %v103249, inf (stack69)
        %v103298 = vsel /*vm=*/%vm103297, /*on_true_vy=*/%v103249, /*on_false_vx=*/%v103296 (stack70)
        %vm103299 = vcmp.eq.f32.partialorder %v103249, 0.0 (stack71)
        %v103300 = vand.u32 2147483648, %v103249 (stack72)
        %v103301 = vsel /*vm=*/%vm103299, /*on_true_vy=*/%v103300, /*on_false_vx=*/%v103298 (stack73)
        %v103304 = vadd.f32 -3.0, %v103301 (stack52)
        %v103308 = vsel /*vm=*/%vm103252, /*on_true_vy=*/%v103293, /*on_false_vx=*/%v103304 (stack43)
        %v103312 = vmul.f32 %v103308, %v103289 (stack53)
        %v103316 = vadd.f32 %v103312, %v103285 (stack52)
        %v103320 = vmul.f32 %v103316, %v103308 (stack53)
        %v103324 = vadd.f32 %v103320, %v103281 (stack52)
        %v103328 = vmul.f32 %v103324, %v103308 (stack53)
        %v103332 = vadd.f32 %v103328, %v103277 (stack52)
        %v103336 = vmul.f32 %v103332, %v103308 (stack53)
        %v103340 = vadd.f32 %v103336, %v103273 (stack52)
        %v103344 = vmul.f32 %v103340, %v103308 (stack53)
        %v103348 = vadd.f32 %v103344, %v103269 (stack52)
        %v103352 = vmul.f32 %v103348, %v103308 (stack53)
        %v103356 = vadd.f32 %v103352, %v103265 (stack52)
        %v103360 = vmul.f32 %v103356, %v103308 (stack53)
        %v103364 = vadd.f32 %v103360, %v103261 (stack52)
        %v103368 = vmul.f32 %v103364, %v103308 (stack53)
        %v103372 = vadd.f32 %v103368, %v103257 (stack52)
        %v103376 = vmul.f32 %v103372, %v103223 (stack53)
        %v103380 = vsel /*vm=*/%vm103228, /*on_true_vy=*/%v103233, /*on_false_vx=*/%v103376 (stack43)
        %v103384 = vmul.f32 1.4140625, %v103380 (stack53)
        %v103387 = vpack.c.bf16 0.0, %v103384 (stack74)
        %120297 = vst [vmem:[%s280 + $0x26c] sm:$0xf] /*vst_source=*/%v103387 (stack75)
        %v103391 = vadd.s32 %v101083, %v2842 (stack39)
        %v103401 = vadd.s32 %v103391, %v415 (stack39)
        %vm103405 = vcmp.lt.u32.totalorder %v103401, %v103391 (stack42)
        %vm103410 = vcmp.lt.u32.totalorder %v103391, %v2842 (stack42)
        %v103415 = vadd.s32 %v101066, %v2829 (stack39)
        %v103419 = vadd.s32 1, %v103415 (stack39)
        %v103423 = vsel /*vm=*/%vm103410, /*on_true_vy=*/%v103419, /*on_false_vx=*/%v103415 (stack43)
        %v103427 = vadd.s32 1, %v103423 (stack39)
        %v103431 = vsel /*vm=*/%vm103405, /*on_true_vy=*/%v103427, /*on_false_vx=*/%v103423 (stack43)
        %v103436 = vadd.s32 %v103431, %v10 (stack39)
        %v103440 = vadd.s32 %v103401, %v9 (stack39)
        %v103444 = vadd.s32 %v103440, %v103436 (stack39)
        %v103446 = vshll.u32 %v103440, 13 (stack44)
        %v103447 = vshrl.u32 %v103440, 19 (stack45)
        %v103448 = vor.u32 %v103447, %v103446 (stack46)
        %v103449 = vxor.u32 %v103448, %v103444 (stack47)
        %v103452 = vadd.s32 %v103449, %v103444 (stack39)
        %v103454 = vshll.u32 %v103449, 15 (stack44)
        %v103455 = vshrl.u32 %v103449, 17 (stack45)
        %v103456 = vor.u32 %v103455, %v103454 (stack46)
        %v103457 = vxor.u32 %v103456, %v103452 (stack47)
        %v103460 = vadd.s32 %v103457, %v103452 (stack39)
        %v103462 = vshll.u32 %v103457, 26 (stack44)
        %v103463 = vshrl.u32 %v103457, 6 (stack45)
        %v103464 = vor.u32 %v103463, %v103462 (stack46)
        %v103465 = vxor.u32 %v103464, %v103460 (stack47)
        %v103468 = vadd.s32 %v103465, %v103460 (stack39)
        %v103472 = vadd.s32 %v103468, %v9 (stack39)
        %v103474 = vshll.u32 %v103465, 6 (stack44)
        %v103475 = vshrl.u32 %v103465, 26 (stack45)
        %v103476 = vor.u32 %v103475, %v103474 (stack46)
        %v103477 = vxor.u32 %v103476, %v103468 (stack47)
        %v103480 = vadd.s32 %v103477, %v8 (stack39)
        %v103484 = vadd.s32 1, %v103480 (stack39)
        %v103488 = vadd.s32 %v103484, %v103472 (stack39)
        %v103490 = vshll.u32 %v103484, 17 (stack44)
        %v103491 = vshrl.u32 %v103484, 15 (stack45)
        %v103492 = vor.u32 %v103491, %v103490 (stack46)
        %v103493 = vxor.u32 %v103492, %v103488 (stack47)
        %v103496 = vadd.s32 %v103493, %v103488 (stack39)
        %v103498 = vshll.u32 %v103493, 29 (stack44)
        %v103499 = vshrl.u32 %v103493, 3 (stack45)
        %v103500 = vor.u32 %v103499, %v103498 (stack46)
        %v103501 = vxor.u32 %v103500, %v103496 (stack47)
        %v103504 = vadd.s32 %v103501, %v103496 (stack39)
        %v103506 = vshll.u32 %v103501, 16 (stack44)
        %v103507 = vshrl.u32 %v103501, 16 (stack45)
        %v103508 = vor.u32 %v103507, %v103506 (stack46)
        %v103509 = vxor.u32 %v103508, %v103504 (stack47)
        %v103512 = vadd.s32 %v103509, %v103504 (stack39)
        %v103516 = vadd.s32 %v103512, %v8 (stack39)
        %v103518 = vshll.u32 %v103509, 24 (stack44)
        %v103519 = vshrl.u32 %v103509, 8 (stack45)
        %v103520 = vor.u32 %v103519, %v103518 (stack46)
        %v103521 = vxor.u32 %v103520, %v103512 (stack47)
        %v103524 = vadd.s32 %v103521, %v10 (stack39)
        %v103528 = vadd.s32 2, %v103524 (stack39)
        %v103532 = vadd.s32 %v103528, %v103516 (stack39)
        %v103534 = vshll.u32 %v103528, 13 (stack44)
        %v103535 = vshrl.u32 %v103528, 19 (stack45)
        %v103536 = vor.u32 %v103535, %v103534 (stack46)
        %v103537 = vxor.u32 %v103536, %v103532 (stack47)
        %v103540 = vadd.s32 %v103537, %v103532 (stack39)
        %v103542 = vshll.u32 %v103537, 15 (stack44)
        %v103543 = vshrl.u32 %v103537, 17 (stack45)
        %v103544 = vor.u32 %v103543, %v103542 (stack46)
        %v103545 = vxor.u32 %v103544, %v103540 (stack47)
        %v103548 = vadd.s32 %v103545, %v103540 (stack39)
        %v103550 = vshll.u32 %v103545, 26 (stack44)
        %v103551 = vshrl.u32 %v103545, 6 (stack45)
        %v103552 = vor.u32 %v103551, %v103550 (stack46)
        %v103553 = vxor.u32 %v103552, %v103548 (stack47)
        %v103556 = vadd.s32 %v103553, %v103548 (stack39)
        %v103560 = vadd.s32 %v103556, %v10 (stack39)
        %v103562 = vshll.u32 %v103553, 6 (stack44)
        %v103563 = vshrl.u32 %v103553, 26 (stack45)
        %v103564 = vor.u32 %v103563, %v103562 (stack46)
        %v103565 = vxor.u32 %v103564, %v103556 (stack47)
        %v103568 = vadd.s32 %v103565, %v9 (stack39)
        %v103572 = vadd.s32 3, %v103568 (stack39)
        %v103576 = vadd.s32 %v103572, %v103560 (stack39)
        %v103578 = vshll.u32 %v103572, 17 (stack44)
        %v103579 = vshrl.u32 %v103572, 15 (stack45)
        %v103580 = vor.u32 %v103579, %v103578 (stack46)
        %v103581 = vxor.u32 %v103580, %v103576 (stack47)
        %v103584 = vadd.s32 %v103581, %v103576 (stack39)
        %v103586 = vshll.u32 %v103581, 29 (stack44)
        %v103587 = vshrl.u32 %v103581, 3 (stack45)
        %v103588 = vor.u32 %v103587, %v103586 (stack46)
        %v103589 = vxor.u32 %v103588, %v103584 (stack47)
        %v103592 = vadd.s32 %v103589, %v103584 (stack39)
        %v103594 = vshll.u32 %v103589, 16 (stack44)
        %v103595 = vshrl.u32 %v103589, 16 (stack45)
        %v103596 = vor.u32 %v103595, %v103594 (stack46)
        %v103597 = vxor.u32 %v103596, %v103592 (stack47)
        %v103600 = vadd.s32 %v103597, %v103592 (stack39)
        %v103604 = vadd.s32 %v103600, %v9 (stack39)
        %v103606 = vshll.u32 %v103597, 24 (stack44)
        %v103607 = vshrl.u32 %v103597, 8 (stack45)
        %v103608 = vor.u32 %v103607, %v103606 (stack46)
        %v103609 = vxor.u32 %v103608, %v103600 (stack47)
        %v103612 = vadd.s32 %v103609, %v8 (stack39)
        %v103616 = vadd.s32 4, %v103612 (stack39)
        %v103620 = vadd.s32 %v103616, %v103604 (stack39)
        %v103622 = vshll.u32 %v103616, 13 (stack44)
        %v103623 = vshrl.u32 %v103616, 19 (stack45)
        %v103624 = vor.u32 %v103623, %v103622 (stack46)
        %v103625 = vxor.u32 %v103624, %v103620 (stack47)
        %v103628 = vadd.s32 %v103625, %v103620 (stack39)
        %v103630 = vshll.u32 %v103625, 15 (stack44)
        %v103631 = vshrl.u32 %v103625, 17 (stack45)
        %v103632 = vor.u32 %v103631, %v103630 (stack46)
        %v103633 = vxor.u32 %v103632, %v103628 (stack47)
        %v103636 = vadd.s32 %v103633, %v103628 (stack39)
        %v103638 = vshll.u32 %v103633, 26 (stack44)
        %v103639 = vshrl.u32 %v103633, 6 (stack45)
        %v103640 = vor.u32 %v103639, %v103638 (stack46)
        %v103641 = vxor.u32 %v103640, %v103636 (stack47)
        %v103644 = vadd.s32 %v103641, %v103636 (stack39)
        %v103648 = vadd.s32 %v103644, %v8 (stack39)
        %v103650 = vshll.u32 %v103641, 6 (stack44)
        %v103651 = vshrl.u32 %v103641, 26 (stack45)
        %v103652 = vor.u32 %v103651, %v103650 (stack46)
        %v103653 = vxor.u32 %v103652, %v103644 (stack47)
        %v103656 = vadd.s32 %v103653, %v10 (stack39)
        %v103660 = vadd.s32 5, %v103656 (stack39)
        %v103662 = vxor.u32 %v103660, %v103648 (stack47)
        %v103663 = vand.u32.u8 255, %v103662 (stack48)
        %v103664 = vand.u32 65535, %v103663 (stack49)
        %v103665 = vshrl.u32 %v103664, 1 (stack50)
        %v103666 = vor.u32 16256, %v103665 (stack46)
        %v103667 = vand.u32.u16 65535, %v103666 (stack51)
        %v120298 = vadd.low.f32.bf16 -1.0, %v103667 (stack52)
        %v103676 = vmul.f32 2.0, %v120298 (stack53)
        %v103680 = vadd.f32 -0.99609375, %v103676 (stack52)
        %v103684 = vmax.f32 %v103680, -0.99609375 (stack54)
        %v103686 = vand.u32 2147483647, %v103684 (stack55)
        %vm103689 = vcmp.eq.f32.partialorder %v103686, 1.0 (stack56)
        %v103694 = vmul.f32 inf, %v103684 (stack53)
        %v103696 = vxor.u32 2147483648, %v103684 (stack57)
        %v103699 = vmul.f32 %v103696, %v103684 (stack53)
        %v103701 = vadd.f32 1.0, %v103699 (stack58)
        %v103702 = vlog2.pop %v103701 (stack59)
        %v103703 = vmul.f32 0.6931472, %v103702 (stack60)
        %v103704 = vmul.f32 -0.5, %v103699 (stack61)
        %v103705 = vadd.f32 1.0, %v103704 (stack62)
        %v103706 = vmul.f32 %v103705, %v103699 (stack63)
        %v103707 = vand.u32 2147483647, %v103699 (stack64)
        %vm103708 = vcmp.lt.f32.partialorder %v103707, 0.0004427343 (stack65)
        %v103709 = vsel /*vm=*/%vm103708, /*on_true_vy=*/%v103706, /*on_false_vx=*/%v103703 (stack66)
        %v103710 = vxor.u32 2147483648, %v103709 (stack57)
        %vm103713 = vcmp.lt.f32.partialorder %v103710, 5.0 (stack56)
        %v103718 = vsel /*vm=*/%vm103713, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v103722 = vsel /*vm=*/%vm103713, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v103726 = vsel /*vm=*/%vm103713, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v103730 = vsel /*vm=*/%vm103713, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v103734 = vsel /*vm=*/%vm103713, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v103738 = vsel /*vm=*/%vm103713, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v103742 = vsel /*vm=*/%vm103713, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v103746 = vsel /*vm=*/%vm103713, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v103750 = vsel /*vm=*/%vm103713, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v103754 = vadd.f32 -2.5, %v103710 (stack52)
        %v103756 = vrsqrt.pop %v103710 (stack67)
        %v103757 = vmul.f32 %v103756, %v103710 (stack68)
        %vm103758 = vcmp.eq.f32.partialorder %v103710, inf (stack69)
        %v103759 = vsel /*vm=*/%vm103758, /*on_true_vy=*/%v103710, /*on_false_vx=*/%v103757 (stack70)
        %vm103760 = vcmp.eq.f32.partialorder %v103710, 0.0 (stack71)
        %v103761 = vand.u32 2147483648, %v103710 (stack72)
        %v103762 = vsel /*vm=*/%vm103760, /*on_true_vy=*/%v103761, /*on_false_vx=*/%v103759 (stack73)
        %v103765 = vadd.f32 -3.0, %v103762 (stack52)
        %v103769 = vsel /*vm=*/%vm103713, /*on_true_vy=*/%v103754, /*on_false_vx=*/%v103765 (stack43)
        %v103773 = vmul.f32 %v103769, %v103750 (stack53)
        %v103777 = vadd.f32 %v103773, %v103746 (stack52)
        %v103781 = vmul.f32 %v103777, %v103769 (stack53)
        %v103785 = vadd.f32 %v103781, %v103742 (stack52)
        %v103789 = vmul.f32 %v103785, %v103769 (stack53)
        %v103793 = vadd.f32 %v103789, %v103738 (stack52)
        %v103797 = vmul.f32 %v103793, %v103769 (stack53)
        %v103801 = vadd.f32 %v103797, %v103734 (stack52)
        %v103805 = vmul.f32 %v103801, %v103769 (stack53)
        %v103809 = vadd.f32 %v103805, %v103730 (stack52)
        %v103813 = vmul.f32 %v103809, %v103769 (stack53)
        %v103817 = vadd.f32 %v103813, %v103726 (stack52)
        %v103821 = vmul.f32 %v103817, %v103769 (stack53)
        %v103825 = vadd.f32 %v103821, %v103722 (stack52)
        %v103829 = vmul.f32 %v103825, %v103769 (stack53)
        %v103833 = vadd.f32 %v103829, %v103718 (stack52)
        %v103837 = vmul.f32 %v103833, %v103684 (stack53)
        %v103841 = vsel /*vm=*/%vm103689, /*on_true_vy=*/%v103694, /*on_false_vx=*/%v103837 (stack43)
        %v103845 = vmul.f32 1.4140625, %v103841 (stack53)
        %v103848 = vpack.c.bf16 0.0, %v103845 (stack74)
        %120299 = vst [vmem:[%s280 + $0x2ec] sm:$0xf] /*vst_source=*/%v103848 (stack75)
        %v103852 = vadd.s32 %v101083, %v3329 (stack39)
        %v103862 = vadd.s32 %v103852, %v415 (stack39)
        %vm103866 = vcmp.lt.u32.totalorder %v103862, %v103852 (stack42)
        %vm103871 = vcmp.lt.u32.totalorder %v103852, %v3329 (stack42)
        %v103876 = vadd.s32 %v101066, %v3316 (stack39)
        %v103880 = vadd.s32 1, %v103876 (stack39)
        %v103884 = vsel /*vm=*/%vm103871, /*on_true_vy=*/%v103880, /*on_false_vx=*/%v103876 (stack43)
        %v103888 = vadd.s32 1, %v103884 (stack39)
        %v103892 = vsel /*vm=*/%vm103866, /*on_true_vy=*/%v103888, /*on_false_vx=*/%v103884 (stack43)
        %v103897 = vadd.s32 %v103892, %v10 (stack39)
        %v103901 = vadd.s32 %v103862, %v9 (stack39)
        %v103905 = vadd.s32 %v103901, %v103897 (stack39)
        %v103907 = vshll.u32 %v103901, 13 (stack44)
        %v103908 = vshrl.u32 %v103901, 19 (stack45)
        %v103909 = vor.u32 %v103908, %v103907 (stack46)
        %v103910 = vxor.u32 %v103909, %v103905 (stack47)
        %v103913 = vadd.s32 %v103910, %v103905 (stack39)
        %v103915 = vshll.u32 %v103910, 15 (stack44)
        %v103916 = vshrl.u32 %v103910, 17 (stack45)
        %v103917 = vor.u32 %v103916, %v103915 (stack46)
        %v103918 = vxor.u32 %v103917, %v103913 (stack47)
        %v103921 = vadd.s32 %v103918, %v103913 (stack39)
        %v103923 = vshll.u32 %v103918, 26 (stack44)
        %v103924 = vshrl.u32 %v103918, 6 (stack45)
        %v103925 = vor.u32 %v103924, %v103923 (stack46)
        %v103926 = vxor.u32 %v103925, %v103921 (stack47)
        %v103929 = vadd.s32 %v103926, %v103921 (stack39)
        %v103933 = vadd.s32 %v103929, %v9 (stack39)
        %v103935 = vshll.u32 %v103926, 6 (stack44)
        %v103936 = vshrl.u32 %v103926, 26 (stack45)
        %v103937 = vor.u32 %v103936, %v103935 (stack46)
        %v103938 = vxor.u32 %v103937, %v103929 (stack47)
        %v103941 = vadd.s32 %v103938, %v8 (stack39)
        %v103945 = vadd.s32 1, %v103941 (stack39)
        %v103949 = vadd.s32 %v103945, %v103933 (stack39)
        %v103951 = vshll.u32 %v103945, 17 (stack44)
        %v103952 = vshrl.u32 %v103945, 15 (stack45)
        %v103953 = vor.u32 %v103952, %v103951 (stack46)
        %v103954 = vxor.u32 %v103953, %v103949 (stack47)
        %v103957 = vadd.s32 %v103954, %v103949 (stack39)
        %v103959 = vshll.u32 %v103954, 29 (stack44)
        %v103960 = vshrl.u32 %v103954, 3 (stack45)
        %v103961 = vor.u32 %v103960, %v103959 (stack46)
        %v103962 = vxor.u32 %v103961, %v103957 (stack47)
        %v103965 = vadd.s32 %v103962, %v103957 (stack39)
        %v103967 = vshll.u32 %v103962, 16 (stack44)
        %v103968 = vshrl.u32 %v103962, 16 (stack45)
        %v103969 = vor.u32 %v103968, %v103967 (stack46)
        %v103970 = vxor.u32 %v103969, %v103965 (stack47)
        %v103973 = vadd.s32 %v103970, %v103965 (stack39)
        %v103977 = vadd.s32 %v103973, %v8 (stack39)
        %v103979 = vshll.u32 %v103970, 24 (stack44)
        %v103980 = vshrl.u32 %v103970, 8 (stack45)
        %v103981 = vor.u32 %v103980, %v103979 (stack46)
        %v103982 = vxor.u32 %v103981, %v103973 (stack47)
        %v103985 = vadd.s32 %v103982, %v10 (stack39)
        %v103989 = vadd.s32 2, %v103985 (stack39)
        %v103993 = vadd.s32 %v103989, %v103977 (stack39)
        %v103995 = vshll.u32 %v103989, 13 (stack44)
        %v103996 = vshrl.u32 %v103989, 19 (stack45)
        %v103997 = vor.u32 %v103996, %v103995 (stack46)
        %v103998 = vxor.u32 %v103997, %v103993 (stack47)
        %v104001 = vadd.s32 %v103998, %v103993 (stack39)
        %v104003 = vshll.u32 %v103998, 15 (stack44)
        %v104004 = vshrl.u32 %v103998, 17 (stack45)
        %v104005 = vor.u32 %v104004, %v104003 (stack46)
        %v104006 = vxor.u32 %v104005, %v104001 (stack47)
        %v104009 = vadd.s32 %v104006, %v104001 (stack39)
        %v104011 = vshll.u32 %v104006, 26 (stack44)
        %v104012 = vshrl.u32 %v104006, 6 (stack45)
        %v104013 = vor.u32 %v104012, %v104011 (stack46)
        %v104014 = vxor.u32 %v104013, %v104009 (stack47)
        %v104017 = vadd.s32 %v104014, %v104009 (stack39)
        %v104021 = vadd.s32 %v104017, %v10 (stack39)
        %v104023 = vshll.u32 %v104014, 6 (stack44)
        %v104024 = vshrl.u32 %v104014, 26 (stack45)
        %v104025 = vor.u32 %v104024, %v104023 (stack46)
        %v104026 = vxor.u32 %v104025, %v104017 (stack47)
        %v104029 = vadd.s32 %v104026, %v9 (stack39)
        %v104033 = vadd.s32 3, %v104029 (stack39)
        %v104037 = vadd.s32 %v104033, %v104021 (stack39)
        %v104039 = vshll.u32 %v104033, 17 (stack44)
        %v104040 = vshrl.u32 %v104033, 15 (stack45)
        %v104041 = vor.u32 %v104040, %v104039 (stack46)
        %v104042 = vxor.u32 %v104041, %v104037 (stack47)
        %v104045 = vadd.s32 %v104042, %v104037 (stack39)
        %v104047 = vshll.u32 %v104042, 29 (stack44)
        %v104048 = vshrl.u32 %v104042, 3 (stack45)
        %v104049 = vor.u32 %v104048, %v104047 (stack46)
        %v104050 = vxor.u32 %v104049, %v104045 (stack47)
        %v104053 = vadd.s32 %v104050, %v104045 (stack39)
        %v104055 = vshll.u32 %v104050, 16 (stack44)
        %v104056 = vshrl.u32 %v104050, 16 (stack45)
        %v104057 = vor.u32 %v104056, %v104055 (stack46)
        %v104058 = vxor.u32 %v104057, %v104053 (stack47)
        %v104061 = vadd.s32 %v104058, %v104053 (stack39)
        %v104065 = vadd.s32 %v104061, %v9 (stack39)
        %v104067 = vshll.u32 %v104058, 24 (stack44)
        %v104068 = vshrl.u32 %v104058, 8 (stack45)
        %v104069 = vor.u32 %v104068, %v104067 (stack46)
        %v104070 = vxor.u32 %v104069, %v104061 (stack47)
        %v104073 = vadd.s32 %v104070, %v8 (stack39)
        %v104077 = vadd.s32 4, %v104073 (stack39)
        %v104081 = vadd.s32 %v104077, %v104065 (stack39)
        %v104083 = vshll.u32 %v104077, 13 (stack44)
        %v104084 = vshrl.u32 %v104077, 19 (stack45)
        %v104085 = vor.u32 %v104084, %v104083 (stack46)
        %v104086 = vxor.u32 %v104085, %v104081 (stack47)
        %v104089 = vadd.s32 %v104086, %v104081 (stack39)
        %v104091 = vshll.u32 %v104086, 15 (stack44)
        %v104092 = vshrl.u32 %v104086, 17 (stack45)
        %v104093 = vor.u32 %v104092, %v104091 (stack46)
        %v104094 = vxor.u32 %v104093, %v104089 (stack47)
        %v104097 = vadd.s32 %v104094, %v104089 (stack39)
        %v104099 = vshll.u32 %v104094, 26 (stack44)
        %v104100 = vshrl.u32 %v104094, 6 (stack45)
        %v104101 = vor.u32 %v104100, %v104099 (stack46)
        %v104102 = vxor.u32 %v104101, %v104097 (stack47)
        %v104105 = vadd.s32 %v104102, %v104097 (stack39)
        %v104109 = vadd.s32 %v104105, %v8 (stack39)
        %v104111 = vshll.u32 %v104102, 6 (stack44)
        %v104112 = vshrl.u32 %v104102, 26 (stack45)
        %v104113 = vor.u32 %v104112, %v104111 (stack46)
        %v104114 = vxor.u32 %v104113, %v104105 (stack47)
        %v104117 = vadd.s32 %v104114, %v10 (stack39)
        %v104121 = vadd.s32 5, %v104117 (stack39)
        %v104123 = vxor.u32 %v104121, %v104109 (stack47)
        %v104124 = vand.u32.u8 255, %v104123 (stack48)
        %v104125 = vand.u32 65535, %v104124 (stack49)
        %v104126 = vshrl.u32 %v104125, 1 (stack50)
        %v104127 = vor.u32 16256, %v104126 (stack46)
        %v104128 = vand.u32.u16 65535, %v104127 (stack51)
        %v120300 = vadd.low.f32.bf16 -1.0, %v104128 (stack52)
        %v104137 = vmul.f32 2.0, %v120300 (stack53)
        %v104141 = vadd.f32 -0.99609375, %v104137 (stack52)
        %v104145 = vmax.f32 %v104141, -0.99609375 (stack54)
        %v104147 = vand.u32 2147483647, %v104145 (stack55)
        %vm104150 = vcmp.eq.f32.partialorder %v104147, 1.0 (stack56)
        %v104155 = vmul.f32 inf, %v104145 (stack53)
        %v104157 = vxor.u32 2147483648, %v104145 (stack57)
        %v104160 = vmul.f32 %v104157, %v104145 (stack53)
        %v104162 = vadd.f32 1.0, %v104160 (stack58)
        %v104163 = vlog2.pop %v104162 (stack59)
        %v104164 = vmul.f32 0.6931472, %v104163 (stack60)
        %v104165 = vmul.f32 -0.5, %v104160 (stack61)
        %v104166 = vadd.f32 1.0, %v104165 (stack62)
        %v104167 = vmul.f32 %v104166, %v104160 (stack63)
        %v104168 = vand.u32 2147483647, %v104160 (stack64)
        %vm104169 = vcmp.lt.f32.partialorder %v104168, 0.0004427343 (stack65)
        %v104170 = vsel /*vm=*/%vm104169, /*on_true_vy=*/%v104167, /*on_false_vx=*/%v104164 (stack66)
        %v104171 = vxor.u32 2147483648, %v104170 (stack57)
        %vm104174 = vcmp.lt.f32.partialorder %v104171, 5.0 (stack56)
        %v104179 = vsel /*vm=*/%vm104174, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v104183 = vsel /*vm=*/%vm104174, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v104187 = vsel /*vm=*/%vm104174, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v104191 = vsel /*vm=*/%vm104174, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v104195 = vsel /*vm=*/%vm104174, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v104199 = vsel /*vm=*/%vm104174, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v104203 = vsel /*vm=*/%vm104174, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v104207 = vsel /*vm=*/%vm104174, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v104211 = vsel /*vm=*/%vm104174, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v104215 = vadd.f32 -2.5, %v104171 (stack52)
        %v104217 = vrsqrt.pop %v104171 (stack67)
        %v104218 = vmul.f32 %v104217, %v104171 (stack68)
        %vm104219 = vcmp.eq.f32.partialorder %v104171, inf (stack69)
        %v104220 = vsel /*vm=*/%vm104219, /*on_true_vy=*/%v104171, /*on_false_vx=*/%v104218 (stack70)
        %vm104221 = vcmp.eq.f32.partialorder %v104171, 0.0 (stack71)
        %v104222 = vand.u32 2147483648, %v104171 (stack72)
        %v104223 = vsel /*vm=*/%vm104221, /*on_true_vy=*/%v104222, /*on_false_vx=*/%v104220 (stack73)
        %v104226 = vadd.f32 -3.0, %v104223 (stack52)
        %v104230 = vsel /*vm=*/%vm104174, /*on_true_vy=*/%v104215, /*on_false_vx=*/%v104226 (stack43)
        %v104234 = vmul.f32 %v104230, %v104211 (stack53)
        %v104238 = vadd.f32 %v104234, %v104207 (stack52)
        %v104242 = vmul.f32 %v104238, %v104230 (stack53)
        %v104246 = vadd.f32 %v104242, %v104203 (stack52)
        %v104250 = vmul.f32 %v104246, %v104230 (stack53)
        %v104254 = vadd.f32 %v104250, %v104199 (stack52)
        %v104258 = vmul.f32 %v104254, %v104230 (stack53)
        %v104262 = vadd.f32 %v104258, %v104195 (stack52)
        %v104266 = vmul.f32 %v104262, %v104230 (stack53)
        %v104270 = vadd.f32 %v104266, %v104191 (stack52)
        %v104274 = vmul.f32 %v104270, %v104230 (stack53)
        %v104278 = vadd.f32 %v104274, %v104187 (stack52)
        %v104282 = vmul.f32 %v104278, %v104230 (stack53)
        %v104286 = vadd.f32 %v104282, %v104183 (stack52)
        %v104290 = vmul.f32 %v104286, %v104230 (stack53)
        %v104294 = vadd.f32 %v104290, %v104179 (stack52)
        %v104298 = vmul.f32 %v104294, %v104145 (stack53)
        %v104302 = vsel /*vm=*/%vm104150, /*on_true_vy=*/%v104155, /*on_false_vx=*/%v104298 (stack43)
        %v104306 = vmul.f32 1.4140625, %v104302 (stack53)
        %v104309 = vpack.c.bf16 0.0, %v104306 (stack74)
        %120301 = vst [vmem:[%s280 + $0x36c] sm:$0xf] /*vst_source=*/%v104309 (stack75)
        %v104313 = vadd.s32 %v101083, %v3816 (stack39)
        %v104323 = vadd.s32 %v104313, %v415 (stack39)
        %vm104327 = vcmp.lt.u32.totalorder %v104323, %v104313 (stack42)
        %vm104332 = vcmp.lt.u32.totalorder %v104313, %v3816 (stack42)
        %v104337 = vadd.s32 %v101066, %v3803 (stack39)
        %v104341 = vadd.s32 1, %v104337 (stack39)
        %v104345 = vsel /*vm=*/%vm104332, /*on_true_vy=*/%v104341, /*on_false_vx=*/%v104337 (stack43)
        %v104349 = vadd.s32 1, %v104345 (stack39)
        %v104353 = vsel /*vm=*/%vm104327, /*on_true_vy=*/%v104349, /*on_false_vx=*/%v104345 (stack43)
        %v104358 = vadd.s32 %v104353, %v10 (stack39)
        %v104362 = vadd.s32 %v104323, %v9 (stack39)
        %v104366 = vadd.s32 %v104362, %v104358 (stack39)
        %v104368 = vshll.u32 %v104362, 13 (stack44)
        %v104369 = vshrl.u32 %v104362, 19 (stack45)
        %v104370 = vor.u32 %v104369, %v104368 (stack46)
        %v104371 = vxor.u32 %v104370, %v104366 (stack47)
        %v104374 = vadd.s32 %v104371, %v104366 (stack39)
        %v104376 = vshll.u32 %v104371, 15 (stack44)
        %v104377 = vshrl.u32 %v104371, 17 (stack45)
        %v104378 = vor.u32 %v104377, %v104376 (stack46)
        %v104379 = vxor.u32 %v104378, %v104374 (stack47)
        %v104382 = vadd.s32 %v104379, %v104374 (stack39)
        %v104384 = vshll.u32 %v104379, 26 (stack44)
        %v104385 = vshrl.u32 %v104379, 6 (stack45)
        %v104386 = vor.u32 %v104385, %v104384 (stack46)
        %v104387 = vxor.u32 %v104386, %v104382 (stack47)
        %v104390 = vadd.s32 %v104387, %v104382 (stack39)
        %v104394 = vadd.s32 %v104390, %v9 (stack39)
        %v104396 = vshll.u32 %v104387, 6 (stack44)
        %v104397 = vshrl.u32 %v104387, 26 (stack45)
        %v104398 = vor.u32 %v104397, %v104396 (stack46)
        %v104399 = vxor.u32 %v104398, %v104390 (stack47)
        %v104402 = vadd.s32 %v104399, %v8 (stack39)
        %v104406 = vadd.s32 1, %v104402 (stack39)
        %v104410 = vadd.s32 %v104406, %v104394 (stack39)
        %v104412 = vshll.u32 %v104406, 17 (stack44)
        %v104413 = vshrl.u32 %v104406, 15 (stack45)
        %v104414 = vor.u32 %v104413, %v104412 (stack46)
        %v104415 = vxor.u32 %v104414, %v104410 (stack47)
        %v104418 = vadd.s32 %v104415, %v104410 (stack39)
        %v104420 = vshll.u32 %v104415, 29 (stack44)
        %v104421 = vshrl.u32 %v104415, 3 (stack45)
        %v104422 = vor.u32 %v104421, %v104420 (stack46)
        %v104423 = vxor.u32 %v104422, %v104418 (stack47)
        %v104426 = vadd.s32 %v104423, %v104418 (stack39)
        %v104428 = vshll.u32 %v104423, 16 (stack44)
        %v104429 = vshrl.u32 %v104423, 16 (stack45)
        %v104430 = vor.u32 %v104429, %v104428 (stack46)
        %v104431 = vxor.u32 %v104430, %v104426 (stack47)
        %v104434 = vadd.s32 %v104431, %v104426 (stack39)
        %v104438 = vadd.s32 %v104434, %v8 (stack39)
        %v104440 = vshll.u32 %v104431, 24 (stack44)
        %v104441 = vshrl.u32 %v104431, 8 (stack45)
        %v104442 = vor.u32 %v104441, %v104440 (stack46)
        %v104443 = vxor.u32 %v104442, %v104434 (stack47)
        %v104446 = vadd.s32 %v104443, %v10 (stack39)
        %v104450 = vadd.s32 2, %v104446 (stack39)
        %v104454 = vadd.s32 %v104450, %v104438 (stack39)
        %v104456 = vshll.u32 %v104450, 13 (stack44)
        %v104457 = vshrl.u32 %v104450, 19 (stack45)
        %v104458 = vor.u32 %v104457, %v104456 (stack46)
        %v104459 = vxor.u32 %v104458, %v104454 (stack47)
        %v104462 = vadd.s32 %v104459, %v104454 (stack39)
        %v104464 = vshll.u32 %v104459, 15 (stack44)
        %v104465 = vshrl.u32 %v104459, 17 (stack45)
        %v104466 = vor.u32 %v104465, %v104464 (stack46)
        %v104467 = vxor.u32 %v104466, %v104462 (stack47)
        %v104470 = vadd.s32 %v104467, %v104462 (stack39)
        %v104472 = vshll.u32 %v104467, 26 (stack44)
        %v104473 = vshrl.u32 %v104467, 6 (stack45)
        %v104474 = vor.u32 %v104473, %v104472 (stack46)
        %v104475 = vxor.u32 %v104474, %v104470 (stack47)
        %v104478 = vadd.s32 %v104475, %v104470 (stack39)
        %v104482 = vadd.s32 %v104478, %v10 (stack39)
        %v104484 = vshll.u32 %v104475, 6 (stack44)
        %v104485 = vshrl.u32 %v104475, 26 (stack45)
        %v104486 = vor.u32 %v104485, %v104484 (stack46)
        %v104487 = vxor.u32 %v104486, %v104478 (stack47)
        %v104490 = vadd.s32 %v104487, %v9 (stack39)
        %v104494 = vadd.s32 3, %v104490 (stack39)
        %v104498 = vadd.s32 %v104494, %v104482 (stack39)
        %v104500 = vshll.u32 %v104494, 17 (stack44)
        %v104501 = vshrl.u32 %v104494, 15 (stack45)
        %v104502 = vor.u32 %v104501, %v104500 (stack46)
        %v104503 = vxor.u32 %v104502, %v104498 (stack47)
        %v104506 = vadd.s32 %v104503, %v104498 (stack39)
        %v104508 = vshll.u32 %v104503, 29 (stack44)
        %v104509 = vshrl.u32 %v104503, 3 (stack45)
        %v104510 = vor.u32 %v104509, %v104508 (stack46)
        %v104511 = vxor.u32 %v104510, %v104506 (stack47)
        %v104514 = vadd.s32 %v104511, %v104506 (stack39)
        %v104516 = vshll.u32 %v104511, 16 (stack44)
        %v104517 = vshrl.u32 %v104511, 16 (stack45)
        %v104518 = vor.u32 %v104517, %v104516 (stack46)
        %v104519 = vxor.u32 %v104518, %v104514 (stack47)
        %v104522 = vadd.s32 %v104519, %v104514 (stack39)
        %v104526 = vadd.s32 %v104522, %v9 (stack39)
        %v104528 = vshll.u32 %v104519, 24 (stack44)
        %v104529 = vshrl.u32 %v104519, 8 (stack45)
        %v104530 = vor.u32 %v104529, %v104528 (stack46)
        %v104531 = vxor.u32 %v104530, %v104522 (stack47)
        %v104534 = vadd.s32 %v104531, %v8 (stack39)
        %v104538 = vadd.s32 4, %v104534 (stack39)
        %v104542 = vadd.s32 %v104538, %v104526 (stack39)
        %v104544 = vshll.u32 %v104538, 13 (stack44)
        %v104545 = vshrl.u32 %v104538, 19 (stack45)
        %v104546 = vor.u32 %v104545, %v104544 (stack46)
        %v104547 = vxor.u32 %v104546, %v104542 (stack47)
        %v104550 = vadd.s32 %v104547, %v104542 (stack39)
        %v104552 = vshll.u32 %v104547, 15 (stack44)
        %v104553 = vshrl.u32 %v104547, 17 (stack45)
        %v104554 = vor.u32 %v104553, %v104552 (stack46)
        %v104555 = vxor.u32 %v104554, %v104550 (stack47)
        %v104558 = vadd.s32 %v104555, %v104550 (stack39)
        %v104560 = vshll.u32 %v104555, 26 (stack44)
        %v104561 = vshrl.u32 %v104555, 6 (stack45)
        %v104562 = vor.u32 %v104561, %v104560 (stack46)
        %v104563 = vxor.u32 %v104562, %v104558 (stack47)
        %v104566 = vadd.s32 %v104563, %v104558 (stack39)
        %v104570 = vadd.s32 %v104566, %v8 (stack39)
        %v104572 = vshll.u32 %v104563, 6 (stack44)
        %v104573 = vshrl.u32 %v104563, 26 (stack45)
        %v104574 = vor.u32 %v104573, %v104572 (stack46)
        %v104575 = vxor.u32 %v104574, %v104566 (stack47)
        %v104578 = vadd.s32 %v104575, %v10 (stack39)
        %v104582 = vadd.s32 5, %v104578 (stack39)
        %v104584 = vxor.u32 %v104582, %v104570 (stack47)
        %v104585 = vand.u32.u8 255, %v104584 (stack48)
        %v104586 = vand.u32 65535, %v104585 (stack49)
        %v104587 = vshrl.u32 %v104586, 1 (stack50)
        %v104588 = vor.u32 16256, %v104587 (stack46)
        %v104589 = vand.u32.u16 65535, %v104588 (stack51)
        %v120302 = vadd.low.f32.bf16 -1.0, %v104589 (stack52)
        %v104598 = vmul.f32 2.0, %v120302 (stack53)
        %v104602 = vadd.f32 -0.99609375, %v104598 (stack52)
        %v104606 = vmax.f32 %v104602, -0.99609375 (stack54)
        %v104608 = vand.u32 2147483647, %v104606 (stack55)
        %vm104611 = vcmp.eq.f32.partialorder %v104608, 1.0 (stack56)
        %v104616 = vmul.f32 inf, %v104606 (stack53)
        %v104618 = vxor.u32 2147483648, %v104606 (stack57)
        %v104621 = vmul.f32 %v104618, %v104606 (stack53)
        %v104623 = vadd.f32 1.0, %v104621 (stack58)
        %v104624 = vlog2.pop %v104623 (stack59)
        %v104625 = vmul.f32 0.6931472, %v104624 (stack60)
        %v104626 = vmul.f32 -0.5, %v104621 (stack61)
        %v104627 = vadd.f32 1.0, %v104626 (stack62)
        %v104628 = vmul.f32 %v104627, %v104621 (stack63)
        %v104629 = vand.u32 2147483647, %v104621 (stack64)
        %vm104630 = vcmp.lt.f32.partialorder %v104629, 0.0004427343 (stack65)
        %v104631 = vsel /*vm=*/%vm104630, /*on_true_vy=*/%v104628, /*on_false_vx=*/%v104625 (stack66)
        %v104632 = vxor.u32 2147483648, %v104631 (stack57)
        %vm104635 = vcmp.lt.f32.partialorder %v104632, 5.0 (stack56)
        %v104640 = vsel /*vm=*/%vm104635, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v104644 = vsel /*vm=*/%vm104635, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v104648 = vsel /*vm=*/%vm104635, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v104652 = vsel /*vm=*/%vm104635, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v104656 = vsel /*vm=*/%vm104635, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v104660 = vsel /*vm=*/%vm104635, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v104664 = vsel /*vm=*/%vm104635, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v104668 = vsel /*vm=*/%vm104635, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v104672 = vsel /*vm=*/%vm104635, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v104676 = vadd.f32 -2.5, %v104632 (stack52)
        %v104678 = vrsqrt.pop %v104632 (stack67)
        %v104679 = vmul.f32 %v104678, %v104632 (stack68)
        %vm104680 = vcmp.eq.f32.partialorder %v104632, inf (stack69)
        %v104681 = vsel /*vm=*/%vm104680, /*on_true_vy=*/%v104632, /*on_false_vx=*/%v104679 (stack70)
        %vm104682 = vcmp.eq.f32.partialorder %v104632, 0.0 (stack71)
        %v104683 = vand.u32 2147483648, %v104632 (stack72)
        %v104684 = vsel /*vm=*/%vm104682, /*on_true_vy=*/%v104683, /*on_false_vx=*/%v104681 (stack73)
        %v104687 = vadd.f32 -3.0, %v104684 (stack52)
        %v104691 = vsel /*vm=*/%vm104635, /*on_true_vy=*/%v104676, /*on_false_vx=*/%v104687 (stack43)
        %v104695 = vmul.f32 %v104691, %v104672 (stack53)
        %v104699 = vadd.f32 %v104695, %v104668 (stack52)
        %v104703 = vmul.f32 %v104699, %v104691 (stack53)
        %v104707 = vadd.f32 %v104703, %v104664 (stack52)
        %v104711 = vmul.f32 %v104707, %v104691 (stack53)
        %v104715 = vadd.f32 %v104711, %v104660 (stack52)
        %v104719 = vmul.f32 %v104715, %v104691 (stack53)
        %v104723 = vadd.f32 %v104719, %v104656 (stack52)
        %v104727 = vmul.f32 %v104723, %v104691 (stack53)
        %v104731 = vadd.f32 %v104727, %v104652 (stack52)
        %v104735 = vmul.f32 %v104731, %v104691 (stack53)
        %v104739 = vadd.f32 %v104735, %v104648 (stack52)
        %v104743 = vmul.f32 %v104739, %v104691 (stack53)
        %v104747 = vadd.f32 %v104743, %v104644 (stack52)
        %v104751 = vmul.f32 %v104747, %v104691 (stack53)
        %v104755 = vadd.f32 %v104751, %v104640 (stack52)
        %v104759 = vmul.f32 %v104755, %v104606 (stack53)
        %v104763 = vsel /*vm=*/%vm104611, /*on_true_vy=*/%v104616, /*on_false_vx=*/%v104759 (stack43)
        %v104767 = vmul.f32 1.4140625, %v104763 (stack53)
        %v104770 = vpack.c.bf16 0.0, %v104767 (stack74)
        %120303 = vst [vmem:[%s280 + $0x3ec] sm:$0xf] /*vst_source=*/%v104770 (stack75)
        %s104772 = sadd.s32 224, %s120390 (stack76)
        %s104773 = sshrl.u32 %s104772, 10 (stack23)
        %p120304 = scmp.gt.s32.totalorder %s104773, 1 (stack24)
        %s104775 = scalar_select /*predicate=*/%p120304, /*on_true=*/1, /*on_false=*/%s104773 (stack25)
        %s104776 = sand.u32 1023, %s104772 /* smod.u32 w/div 1024 */ (stack26)
        %s104777 = sshrl.u32 %s104776, 7 (stack27)
        %s104778 = sand.u32 127, %s104776 /* smod.u32 w/div 128 */ (stack28)
        %s120305 = sshll.u32 %s104775, 3 (stack29)
        %s104780 = scalar_lea.vmem %s3, %s120305 (stack30)
        %s104782 = scalar_lea.vmem %s104780, %s104777 (stack31)
        %v104783 = vld [vmem:[%s104782] ss:$0 sm:$0xff] (stack32)
        %s104784 = sand.u32 255, %s104778 (stack33)
        %s104786 = sor.u32 256, %s104784 (stack34)
        %104787 = vbcast.lane.b32.xlu0 %v104783, %s104786 (stack35)
        %v104788 = vpop.permute.xlu0 %104787 (stack36)
        %s104797 = scalar_lea.vmem %s5, %s120305 (stack30)
        %s104799 = scalar_lea.vmem %s104797, %s104777 (stack31)
        %v104800 = vld [vmem:[%s104799] ss:$0 sm:$0xff] (stack32)
        %104804 = vbcast.lane.b32.xlu0 %v104800, %s104786 (stack35)
        %v104805 = vpop.permute.xlu0 %104804 (stack36)
        %v104808 = vadd.s32 %v104805, %v408 (stack39)
        %v104818 = vadd.s32 %v104808, %v415 (stack39)
        %vm104822 = vcmp.lt.u32.totalorder %v104818, %v104808 (stack42)
        %vm104827 = vcmp.lt.u32.totalorder %v104808, %v408 (stack42)
        %v104832 = vadd.s32 %v104788, %v380 (stack39)
        %v104836 = vadd.s32 1, %v104832 (stack39)
        %v104840 = vsel /*vm=*/%vm104827, /*on_true_vy=*/%v104836, /*on_false_vx=*/%v104832 (stack43)
        %v104844 = vadd.s32 1, %v104840 (stack39)
        %v104848 = vsel /*vm=*/%vm104822, /*on_true_vy=*/%v104844, /*on_false_vx=*/%v104840 (stack43)
        %v104853 = vadd.s32 %v104848, %v10 (stack39)
        %v104857 = vadd.s32 %v104818, %v9 (stack39)
        %v104861 = vadd.s32 %v104857, %v104853 (stack39)
        %v104863 = vshll.u32 %v104857, 13 (stack44)
        %v104864 = vshrl.u32 %v104857, 19 (stack45)
        %v104865 = vor.u32 %v104864, %v104863 (stack46)
        %v104866 = vxor.u32 %v104865, %v104861 (stack47)
        %v104869 = vadd.s32 %v104866, %v104861 (stack39)
        %v104871 = vshll.u32 %v104866, 15 (stack44)
        %v104872 = vshrl.u32 %v104866, 17 (stack45)
        %v104873 = vor.u32 %v104872, %v104871 (stack46)
        %v104874 = vxor.u32 %v104873, %v104869 (stack47)
        %v104877 = vadd.s32 %v104874, %v104869 (stack39)
        %v104879 = vshll.u32 %v104874, 26 (stack44)
        %v104880 = vshrl.u32 %v104874, 6 (stack45)
        %v104881 = vor.u32 %v104880, %v104879 (stack46)
        %v104882 = vxor.u32 %v104881, %v104877 (stack47)
        %v104885 = vadd.s32 %v104882, %v104877 (stack39)
        %v104889 = vadd.s32 %v104885, %v9 (stack39)
        %v104891 = vshll.u32 %v104882, 6 (stack44)
        %v104892 = vshrl.u32 %v104882, 26 (stack45)
        %v104893 = vor.u32 %v104892, %v104891 (stack46)
        %v104894 = vxor.u32 %v104893, %v104885 (stack47)
        %v104897 = vadd.s32 %v104894, %v8 (stack39)
        %v104901 = vadd.s32 1, %v104897 (stack39)
        %v104905 = vadd.s32 %v104901, %v104889 (stack39)
        %v104907 = vshll.u32 %v104901, 17 (stack44)
        %v104908 = vshrl.u32 %v104901, 15 (stack45)
        %v104909 = vor.u32 %v104908, %v104907 (stack46)
        %v104910 = vxor.u32 %v104909, %v104905 (stack47)
        %v104913 = vadd.s32 %v104910, %v104905 (stack39)
        %v104915 = vshll.u32 %v104910, 29 (stack44)
        %v104916 = vshrl.u32 %v104910, 3 (stack45)
        %v104917 = vor.u32 %v104916, %v104915 (stack46)
        %v104918 = vxor.u32 %v104917, %v104913 (stack47)
        %v104921 = vadd.s32 %v104918, %v104913 (stack39)
        %v104923 = vshll.u32 %v104918, 16 (stack44)
        %v104924 = vshrl.u32 %v104918, 16 (stack45)
        %v104925 = vor.u32 %v104924, %v104923 (stack46)
        %v104926 = vxor.u32 %v104925, %v104921 (stack47)
        %v104929 = vadd.s32 %v104926, %v104921 (stack39)
        %v104933 = vadd.s32 %v104929, %v8 (stack39)
        %v104935 = vshll.u32 %v104926, 24 (stack44)
        %v104936 = vshrl.u32 %v104926, 8 (stack45)
        %v104937 = vor.u32 %v104936, %v104935 (stack46)
        %v104938 = vxor.u32 %v104937, %v104929 (stack47)
        %v104941 = vadd.s32 %v104938, %v10 (stack39)
        %v104945 = vadd.s32 2, %v104941 (stack39)
        %v104949 = vadd.s32 %v104945, %v104933 (stack39)
        %v104951 = vshll.u32 %v104945, 13 (stack44)
        %v104952 = vshrl.u32 %v104945, 19 (stack45)
        %v104953 = vor.u32 %v104952, %v104951 (stack46)
        %v104954 = vxor.u32 %v104953, %v104949 (stack47)
        %v104957 = vadd.s32 %v104954, %v104949 (stack39)
        %v104959 = vshll.u32 %v104954, 15 (stack44)
        %v104960 = vshrl.u32 %v104954, 17 (stack45)
        %v104961 = vor.u32 %v104960, %v104959 (stack46)
        %v104962 = vxor.u32 %v104961, %v104957 (stack47)
        %v104965 = vadd.s32 %v104962, %v104957 (stack39)
        %v104967 = vshll.u32 %v104962, 26 (stack44)
        %v104968 = vshrl.u32 %v104962, 6 (stack45)
        %v104969 = vor.u32 %v104968, %v104967 (stack46)
        %v104970 = vxor.u32 %v104969, %v104965 (stack47)
        %v104973 = vadd.s32 %v104970, %v104965 (stack39)
        %v104977 = vadd.s32 %v104973, %v10 (stack39)
        %v104979 = vshll.u32 %v104970, 6 (stack44)
        %v104980 = vshrl.u32 %v104970, 26 (stack45)
        %v104981 = vor.u32 %v104980, %v104979 (stack46)
        %v104982 = vxor.u32 %v104981, %v104973 (stack47)
        %v104985 = vadd.s32 %v104982, %v9 (stack39)
        %v104989 = vadd.s32 3, %v104985 (stack39)
        %v104993 = vadd.s32 %v104989, %v104977 (stack39)
        %v104995 = vshll.u32 %v104989, 17 (stack44)
        %v104996 = vshrl.u32 %v104989, 15 (stack45)
        %v104997 = vor.u32 %v104996, %v104995 (stack46)
        %v104998 = vxor.u32 %v104997, %v104993 (stack47)
        %v105001 = vadd.s32 %v104998, %v104993 (stack39)
        %v105003 = vshll.u32 %v104998, 29 (stack44)
        %v105004 = vshrl.u32 %v104998, 3 (stack45)
        %v105005 = vor.u32 %v105004, %v105003 (stack46)
        %v105006 = vxor.u32 %v105005, %v105001 (stack47)
        %v105009 = vadd.s32 %v105006, %v105001 (stack39)
        %v105011 = vshll.u32 %v105006, 16 (stack44)
        %v105012 = vshrl.u32 %v105006, 16 (stack45)
        %v105013 = vor.u32 %v105012, %v105011 (stack46)
        %v105014 = vxor.u32 %v105013, %v105009 (stack47)
        %v105017 = vadd.s32 %v105014, %v105009 (stack39)
        %v105021 = vadd.s32 %v105017, %v9 (stack39)
        %v105023 = vshll.u32 %v105014, 24 (stack44)
        %v105024 = vshrl.u32 %v105014, 8 (stack45)
        %v105025 = vor.u32 %v105024, %v105023 (stack46)
        %v105026 = vxor.u32 %v105025, %v105017 (stack47)
        %v105029 = vadd.s32 %v105026, %v8 (stack39)
        %v105033 = vadd.s32 4, %v105029 (stack39)
        %v105037 = vadd.s32 %v105033, %v105021 (stack39)
        %v105039 = vshll.u32 %v105033, 13 (stack44)
        %v105040 = vshrl.u32 %v105033, 19 (stack45)
        %v105041 = vor.u32 %v105040, %v105039 (stack46)
        %v105042 = vxor.u32 %v105041, %v105037 (stack47)
        %v105045 = vadd.s32 %v105042, %v105037 (stack39)
        %v105047 = vshll.u32 %v105042, 15 (stack44)
        %v105048 = vshrl.u32 %v105042, 17 (stack45)
        %v105049 = vor.u32 %v105048, %v105047 (stack46)
        %v105050 = vxor.u32 %v105049, %v105045 (stack47)
        %v105053 = vadd.s32 %v105050, %v105045 (stack39)
        %v105055 = vshll.u32 %v105050, 26 (stack44)
        %v105056 = vshrl.u32 %v105050, 6 (stack45)
        %v105057 = vor.u32 %v105056, %v105055 (stack46)
        %v105058 = vxor.u32 %v105057, %v105053 (stack47)
        %v105061 = vadd.s32 %v105058, %v105053 (stack39)
        %v105065 = vadd.s32 %v105061, %v8 (stack39)
        %v105067 = vshll.u32 %v105058, 6 (stack44)
        %v105068 = vshrl.u32 %v105058, 26 (stack45)
        %v105069 = vor.u32 %v105068, %v105067 (stack46)
        %v105070 = vxor.u32 %v105069, %v105061 (stack47)
        %v105073 = vadd.s32 %v105070, %v10 (stack39)
        %v105077 = vadd.s32 5, %v105073 (stack39)
        %v105079 = vxor.u32 %v105077, %v105065 (stack47)
        %v105080 = vand.u32.u8 255, %v105079 (stack48)
        %v105081 = vand.u32 65535, %v105080 (stack49)
        %v105082 = vshrl.u32 %v105081, 1 (stack50)
        %v105083 = vor.u32 16256, %v105082 (stack46)
        %v105084 = vand.u32.u16 65535, %v105083 (stack51)
        %v120308 = vadd.low.f32.bf16 -1.0, %v105084 (stack52)
        %v105093 = vmul.f32 2.0, %v120308 (stack53)
        %v105097 = vadd.f32 -0.99609375, %v105093 (stack52)
        %v105101 = vmax.f32 %v105097, -0.99609375 (stack54)
        %v105103 = vand.u32 2147483647, %v105101 (stack55)
        %vm105106 = vcmp.eq.f32.partialorder %v105103, 1.0 (stack56)
        %v105111 = vmul.f32 inf, %v105101 (stack53)
        %v105113 = vxor.u32 2147483648, %v105101 (stack57)
        %v105116 = vmul.f32 %v105113, %v105101 (stack53)
        %v105118 = vadd.f32 1.0, %v105116 (stack58)
        %v105119 = vlog2.pop %v105118 (stack59)
        %v105120 = vmul.f32 0.6931472, %v105119 (stack60)
        %v105121 = vmul.f32 -0.5, %v105116 (stack61)
        %v105122 = vadd.f32 1.0, %v105121 (stack62)
        %v105123 = vmul.f32 %v105122, %v105116 (stack63)
        %v105124 = vand.u32 2147483647, %v105116 (stack64)
        %vm105125 = vcmp.lt.f32.partialorder %v105124, 0.0004427343 (stack65)
        %v105126 = vsel /*vm=*/%vm105125, /*on_true_vy=*/%v105123, /*on_false_vx=*/%v105120 (stack66)
        %v105127 = vxor.u32 2147483648, %v105126 (stack57)
        %vm105130 = vcmp.lt.f32.partialorder %v105127, 5.0 (stack56)
        %v105135 = vsel /*vm=*/%vm105130, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v105139 = vsel /*vm=*/%vm105130, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v105143 = vsel /*vm=*/%vm105130, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v105147 = vsel /*vm=*/%vm105130, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v105151 = vsel /*vm=*/%vm105130, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v105155 = vsel /*vm=*/%vm105130, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v105159 = vsel /*vm=*/%vm105130, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v105163 = vsel /*vm=*/%vm105130, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v105167 = vsel /*vm=*/%vm105130, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v105171 = vadd.f32 -2.5, %v105127 (stack52)
        %v105173 = vrsqrt.pop %v105127 (stack67)
        %v105174 = vmul.f32 %v105173, %v105127 (stack68)
        %vm105175 = vcmp.eq.f32.partialorder %v105127, inf (stack69)
        %v105176 = vsel /*vm=*/%vm105175, /*on_true_vy=*/%v105127, /*on_false_vx=*/%v105174 (stack70)
        %vm105177 = vcmp.eq.f32.partialorder %v105127, 0.0 (stack71)
        %v105178 = vand.u32 2147483648, %v105127 (stack72)
        %v105179 = vsel /*vm=*/%vm105177, /*on_true_vy=*/%v105178, /*on_false_vx=*/%v105176 (stack73)
        %v105182 = vadd.f32 -3.0, %v105179 (stack52)
        %v105186 = vsel /*vm=*/%vm105130, /*on_true_vy=*/%v105171, /*on_false_vx=*/%v105182 (stack43)
        %v105190 = vmul.f32 %v105186, %v105167 (stack53)
        %v105194 = vadd.f32 %v105190, %v105163 (stack52)
        %v105198 = vmul.f32 %v105194, %v105186 (stack53)
        %v105202 = vadd.f32 %v105198, %v105159 (stack52)
        %v105206 = vmul.f32 %v105202, %v105186 (stack53)
        %v105210 = vadd.f32 %v105206, %v105155 (stack52)
        %v105214 = vmul.f32 %v105210, %v105186 (stack53)
        %v105218 = vadd.f32 %v105214, %v105151 (stack52)
        %v105222 = vmul.f32 %v105218, %v105186 (stack53)
        %v105226 = vadd.f32 %v105222, %v105147 (stack52)
        %v105230 = vmul.f32 %v105226, %v105186 (stack53)
        %v105234 = vadd.f32 %v105230, %v105143 (stack52)
        %v105238 = vmul.f32 %v105234, %v105186 (stack53)
        %v105242 = vadd.f32 %v105238, %v105139 (stack52)
        %v105246 = vmul.f32 %v105242, %v105186 (stack53)
        %v105250 = vadd.f32 %v105246, %v105135 (stack52)
        %v105254 = vmul.f32 %v105250, %v105101 (stack53)
        %v105258 = vsel /*vm=*/%vm105106, /*on_true_vy=*/%v105111, /*on_false_vx=*/%v105254 (stack43)
        %v105262 = vmul.f32 1.4140625, %v105258 (stack53)
        %v105265 = vpack.c.bf16 0.0, %v105262 (stack74)
        %120309 = vst [vmem:[%s280 + $0x70] sm:$0xf] /*vst_source=*/%v105265 (stack75)
        %v105269 = vadd.s32 %v104805, %v894 (stack39)
        %v105279 = vadd.s32 %v105269, %v415 (stack39)
        %vm105283 = vcmp.lt.u32.totalorder %v105279, %v105269 (stack42)
        %vm105288 = vcmp.lt.u32.totalorder %v105269, %v894 (stack42)
        %v105293 = vadd.s32 %v104788, %v881 (stack39)
        %v105297 = vadd.s32 1, %v105293 (stack39)
        %v105301 = vsel /*vm=*/%vm105288, /*on_true_vy=*/%v105297, /*on_false_vx=*/%v105293 (stack43)
        %v105305 = vadd.s32 1, %v105301 (stack39)
        %v105309 = vsel /*vm=*/%vm105283, /*on_true_vy=*/%v105305, /*on_false_vx=*/%v105301 (stack43)
        %v105314 = vadd.s32 %v105309, %v10 (stack39)
        %v105318 = vadd.s32 %v105279, %v9 (stack39)
        %v105322 = vadd.s32 %v105318, %v105314 (stack39)
        %v105324 = vshll.u32 %v105318, 13 (stack44)
        %v105325 = vshrl.u32 %v105318, 19 (stack45)
        %v105326 = vor.u32 %v105325, %v105324 (stack46)
        %v105327 = vxor.u32 %v105326, %v105322 (stack47)
        %v105330 = vadd.s32 %v105327, %v105322 (stack39)
        %v105332 = vshll.u32 %v105327, 15 (stack44)
        %v105333 = vshrl.u32 %v105327, 17 (stack45)
        %v105334 = vor.u32 %v105333, %v105332 (stack46)
        %v105335 = vxor.u32 %v105334, %v105330 (stack47)
        %v105338 = vadd.s32 %v105335, %v105330 (stack39)
        %v105340 = vshll.u32 %v105335, 26 (stack44)
        %v105341 = vshrl.u32 %v105335, 6 (stack45)
        %v105342 = vor.u32 %v105341, %v105340 (stack46)
        %v105343 = vxor.u32 %v105342, %v105338 (stack47)
        %v105346 = vadd.s32 %v105343, %v105338 (stack39)
        %v105350 = vadd.s32 %v105346, %v9 (stack39)
        %v105352 = vshll.u32 %v105343, 6 (stack44)
        %v105353 = vshrl.u32 %v105343, 26 (stack45)
        %v105354 = vor.u32 %v105353, %v105352 (stack46)
        %v105355 = vxor.u32 %v105354, %v105346 (stack47)
        %v105358 = vadd.s32 %v105355, %v8 (stack39)
        %v105362 = vadd.s32 1, %v105358 (stack39)
        %v105366 = vadd.s32 %v105362, %v105350 (stack39)
        %v105368 = vshll.u32 %v105362, 17 (stack44)
        %v105369 = vshrl.u32 %v105362, 15 (stack45)
        %v105370 = vor.u32 %v105369, %v105368 (stack46)
        %v105371 = vxor.u32 %v105370, %v105366 (stack47)
        %v105374 = vadd.s32 %v105371, %v105366 (stack39)
        %v105376 = vshll.u32 %v105371, 29 (stack44)
        %v105377 = vshrl.u32 %v105371, 3 (stack45)
        %v105378 = vor.u32 %v105377, %v105376 (stack46)
        %v105379 = vxor.u32 %v105378, %v105374 (stack47)
        %v105382 = vadd.s32 %v105379, %v105374 (stack39)
        %v105384 = vshll.u32 %v105379, 16 (stack44)
        %v105385 = vshrl.u32 %v105379, 16 (stack45)
        %v105386 = vor.u32 %v105385, %v105384 (stack46)
        %v105387 = vxor.u32 %v105386, %v105382 (stack47)
        %v105390 = vadd.s32 %v105387, %v105382 (stack39)
        %v105394 = vadd.s32 %v105390, %v8 (stack39)
        %v105396 = vshll.u32 %v105387, 24 (stack44)
        %v105397 = vshrl.u32 %v105387, 8 (stack45)
        %v105398 = vor.u32 %v105397, %v105396 (stack46)
        %v105399 = vxor.u32 %v105398, %v105390 (stack47)
        %v105402 = vadd.s32 %v105399, %v10 (stack39)
        %v105406 = vadd.s32 2, %v105402 (stack39)
        %v105410 = vadd.s32 %v105406, %v105394 (stack39)
        %v105412 = vshll.u32 %v105406, 13 (stack44)
        %v105413 = vshrl.u32 %v105406, 19 (stack45)
        %v105414 = vor.u32 %v105413, %v105412 (stack46)
        %v105415 = vxor.u32 %v105414, %v105410 (stack47)
        %v105418 = vadd.s32 %v105415, %v105410 (stack39)
        %v105420 = vshll.u32 %v105415, 15 (stack44)
        %v105421 = vshrl.u32 %v105415, 17 (stack45)
        %v105422 = vor.u32 %v105421, %v105420 (stack46)
        %v105423 = vxor.u32 %v105422, %v105418 (stack47)
        %v105426 = vadd.s32 %v105423, %v105418 (stack39)
        %v105428 = vshll.u32 %v105423, 26 (stack44)
        %v105429 = vshrl.u32 %v105423, 6 (stack45)
        %v105430 = vor.u32 %v105429, %v105428 (stack46)
        %v105431 = vxor.u32 %v105430, %v105426 (stack47)
        %v105434 = vadd.s32 %v105431, %v105426 (stack39)
        %v105438 = vadd.s32 %v105434, %v10 (stack39)
        %v105440 = vshll.u32 %v105431, 6 (stack44)
        %v105441 = vshrl.u32 %v105431, 26 (stack45)
        %v105442 = vor.u32 %v105441, %v105440 (stack46)
        %v105443 = vxor.u32 %v105442, %v105434 (stack47)
        %v105446 = vadd.s32 %v105443, %v9 (stack39)
        %v105450 = vadd.s32 3, %v105446 (stack39)
        %v105454 = vadd.s32 %v105450, %v105438 (stack39)
        %v105456 = vshll.u32 %v105450, 17 (stack44)
        %v105457 = vshrl.u32 %v105450, 15 (stack45)
        %v105458 = vor.u32 %v105457, %v105456 (stack46)
        %v105459 = vxor.u32 %v105458, %v105454 (stack47)
        %v105462 = vadd.s32 %v105459, %v105454 (stack39)
        %v105464 = vshll.u32 %v105459, 29 (stack44)
        %v105465 = vshrl.u32 %v105459, 3 (stack45)
        %v105466 = vor.u32 %v105465, %v105464 (stack46)
        %v105467 = vxor.u32 %v105466, %v105462 (stack47)
        %v105470 = vadd.s32 %v105467, %v105462 (stack39)
        %v105472 = vshll.u32 %v105467, 16 (stack44)
        %v105473 = vshrl.u32 %v105467, 16 (stack45)
        %v105474 = vor.u32 %v105473, %v105472 (stack46)
        %v105475 = vxor.u32 %v105474, %v105470 (stack47)
        %v105478 = vadd.s32 %v105475, %v105470 (stack39)
        %v105482 = vadd.s32 %v105478, %v9 (stack39)
        %v105484 = vshll.u32 %v105475, 24 (stack44)
        %v105485 = vshrl.u32 %v105475, 8 (stack45)
        %v105486 = vor.u32 %v105485, %v105484 (stack46)
        %v105487 = vxor.u32 %v105486, %v105478 (stack47)
        %v105490 = vadd.s32 %v105487, %v8 (stack39)
        %v105494 = vadd.s32 4, %v105490 (stack39)
        %v105498 = vadd.s32 %v105494, %v105482 (stack39)
        %v105500 = vshll.u32 %v105494, 13 (stack44)
        %v105501 = vshrl.u32 %v105494, 19 (stack45)
        %v105502 = vor.u32 %v105501, %v105500 (stack46)
        %v105503 = vxor.u32 %v105502, %v105498 (stack47)
        %v105506 = vadd.s32 %v105503, %v105498 (stack39)
        %v105508 = vshll.u32 %v105503, 15 (stack44)
        %v105509 = vshrl.u32 %v105503, 17 (stack45)
        %v105510 = vor.u32 %v105509, %v105508 (stack46)
        %v105511 = vxor.u32 %v105510, %v105506 (stack47)
        %v105514 = vadd.s32 %v105511, %v105506 (stack39)
        %v105516 = vshll.u32 %v105511, 26 (stack44)
        %v105517 = vshrl.u32 %v105511, 6 (stack45)
        %v105518 = vor.u32 %v105517, %v105516 (stack46)
        %v105519 = vxor.u32 %v105518, %v105514 (stack47)
        %v105522 = vadd.s32 %v105519, %v105514 (stack39)
        %v105526 = vadd.s32 %v105522, %v8 (stack39)
        %v105528 = vshll.u32 %v105519, 6 (stack44)
        %v105529 = vshrl.u32 %v105519, 26 (stack45)
        %v105530 = vor.u32 %v105529, %v105528 (stack46)
        %v105531 = vxor.u32 %v105530, %v105522 (stack47)
        %v105534 = vadd.s32 %v105531, %v10 (stack39)
        %v105538 = vadd.s32 5, %v105534 (stack39)
        %v105540 = vxor.u32 %v105538, %v105526 (stack47)
        %v105541 = vand.u32.u8 255, %v105540 (stack48)
        %v105542 = vand.u32 65535, %v105541 (stack49)
        %v105543 = vshrl.u32 %v105542, 1 (stack50)
        %v105544 = vor.u32 16256, %v105543 (stack46)
        %v105545 = vand.u32.u16 65535, %v105544 (stack51)
        %v120310 = vadd.low.f32.bf16 -1.0, %v105545 (stack52)
        %v105554 = vmul.f32 2.0, %v120310 (stack53)
        %v105558 = vadd.f32 -0.99609375, %v105554 (stack52)
        %v105562 = vmax.f32 %v105558, -0.99609375 (stack54)
        %v105564 = vand.u32 2147483647, %v105562 (stack55)
        %vm105567 = vcmp.eq.f32.partialorder %v105564, 1.0 (stack56)
        %v105572 = vmul.f32 inf, %v105562 (stack53)
        %v105574 = vxor.u32 2147483648, %v105562 (stack57)
        %v105577 = vmul.f32 %v105574, %v105562 (stack53)
        %v105579 = vadd.f32 1.0, %v105577 (stack58)
        %v105580 = vlog2.pop %v105579 (stack59)
        %v105581 = vmul.f32 0.6931472, %v105580 (stack60)
        %v105582 = vmul.f32 -0.5, %v105577 (stack61)
        %v105583 = vadd.f32 1.0, %v105582 (stack62)
        %v105584 = vmul.f32 %v105583, %v105577 (stack63)
        %v105585 = vand.u32 2147483647, %v105577 (stack64)
        %vm105586 = vcmp.lt.f32.partialorder %v105585, 0.0004427343 (stack65)
        %v105587 = vsel /*vm=*/%vm105586, /*on_true_vy=*/%v105584, /*on_false_vx=*/%v105581 (stack66)
        %v105588 = vxor.u32 2147483648, %v105587 (stack57)
        %vm105591 = vcmp.lt.f32.partialorder %v105588, 5.0 (stack56)
        %v105596 = vsel /*vm=*/%vm105591, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v105600 = vsel /*vm=*/%vm105591, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v105604 = vsel /*vm=*/%vm105591, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v105608 = vsel /*vm=*/%vm105591, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v105612 = vsel /*vm=*/%vm105591, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v105616 = vsel /*vm=*/%vm105591, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v105620 = vsel /*vm=*/%vm105591, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v105624 = vsel /*vm=*/%vm105591, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v105628 = vsel /*vm=*/%vm105591, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v105632 = vadd.f32 -2.5, %v105588 (stack52)
        %v105634 = vrsqrt.pop %v105588 (stack67)
        %v105635 = vmul.f32 %v105634, %v105588 (stack68)
        %vm105636 = vcmp.eq.f32.partialorder %v105588, inf (stack69)
        %v105637 = vsel /*vm=*/%vm105636, /*on_true_vy=*/%v105588, /*on_false_vx=*/%v105635 (stack70)
        %vm105638 = vcmp.eq.f32.partialorder %v105588, 0.0 (stack71)
        %v105639 = vand.u32 2147483648, %v105588 (stack72)
        %v105640 = vsel /*vm=*/%vm105638, /*on_true_vy=*/%v105639, /*on_false_vx=*/%v105637 (stack73)
        %v105643 = vadd.f32 -3.0, %v105640 (stack52)
        %v105647 = vsel /*vm=*/%vm105591, /*on_true_vy=*/%v105632, /*on_false_vx=*/%v105643 (stack43)
        %v105651 = vmul.f32 %v105647, %v105628 (stack53)
        %v105655 = vadd.f32 %v105651, %v105624 (stack52)
        %v105659 = vmul.f32 %v105655, %v105647 (stack53)
        %v105663 = vadd.f32 %v105659, %v105620 (stack52)
        %v105667 = vmul.f32 %v105663, %v105647 (stack53)
        %v105671 = vadd.f32 %v105667, %v105616 (stack52)
        %v105675 = vmul.f32 %v105671, %v105647 (stack53)
        %v105679 = vadd.f32 %v105675, %v105612 (stack52)
        %v105683 = vmul.f32 %v105679, %v105647 (stack53)
        %v105687 = vadd.f32 %v105683, %v105608 (stack52)
        %v105691 = vmul.f32 %v105687, %v105647 (stack53)
        %v105695 = vadd.f32 %v105691, %v105604 (stack52)
        %v105699 = vmul.f32 %v105695, %v105647 (stack53)
        %v105703 = vadd.f32 %v105699, %v105600 (stack52)
        %v105707 = vmul.f32 %v105703, %v105647 (stack53)
        %v105711 = vadd.f32 %v105707, %v105596 (stack52)
        %v105715 = vmul.f32 %v105711, %v105562 (stack53)
        %v105719 = vsel /*vm=*/%vm105567, /*on_true_vy=*/%v105572, /*on_false_vx=*/%v105715 (stack43)
        %v105723 = vmul.f32 1.4140625, %v105719 (stack53)
        %v105726 = vpack.c.bf16 0.0, %v105723 (stack74)
        %120311 = vst [vmem:[%s280 + $0xf0] sm:$0xf] /*vst_source=*/%v105726 (stack75)
        %v105730 = vadd.s32 %v104805, %v1381 (stack39)
        %v105740 = vadd.s32 %v105730, %v415 (stack39)
        %vm105744 = vcmp.lt.u32.totalorder %v105740, %v105730 (stack42)
        %vm105749 = vcmp.lt.u32.totalorder %v105730, %v1381 (stack42)
        %v105754 = vadd.s32 %v104788, %v1368 (stack39)
        %v105758 = vadd.s32 1, %v105754 (stack39)
        %v105762 = vsel /*vm=*/%vm105749, /*on_true_vy=*/%v105758, /*on_false_vx=*/%v105754 (stack43)
        %v105766 = vadd.s32 1, %v105762 (stack39)
        %v105770 = vsel /*vm=*/%vm105744, /*on_true_vy=*/%v105766, /*on_false_vx=*/%v105762 (stack43)
        %v105775 = vadd.s32 %v105770, %v10 (stack39)
        %v105779 = vadd.s32 %v105740, %v9 (stack39)
        %v105783 = vadd.s32 %v105779, %v105775 (stack39)
        %v105785 = vshll.u32 %v105779, 13 (stack44)
        %v105786 = vshrl.u32 %v105779, 19 (stack45)
        %v105787 = vor.u32 %v105786, %v105785 (stack46)
        %v105788 = vxor.u32 %v105787, %v105783 (stack47)
        %v105791 = vadd.s32 %v105788, %v105783 (stack39)
        %v105793 = vshll.u32 %v105788, 15 (stack44)
        %v105794 = vshrl.u32 %v105788, 17 (stack45)
        %v105795 = vor.u32 %v105794, %v105793 (stack46)
        %v105796 = vxor.u32 %v105795, %v105791 (stack47)
        %v105799 = vadd.s32 %v105796, %v105791 (stack39)
        %v105801 = vshll.u32 %v105796, 26 (stack44)
        %v105802 = vshrl.u32 %v105796, 6 (stack45)
        %v105803 = vor.u32 %v105802, %v105801 (stack46)
        %v105804 = vxor.u32 %v105803, %v105799 (stack47)
        %v105807 = vadd.s32 %v105804, %v105799 (stack39)
        %v105811 = vadd.s32 %v105807, %v9 (stack39)
        %v105813 = vshll.u32 %v105804, 6 (stack44)
        %v105814 = vshrl.u32 %v105804, 26 (stack45)
        %v105815 = vor.u32 %v105814, %v105813 (stack46)
        %v105816 = vxor.u32 %v105815, %v105807 (stack47)
        %v105819 = vadd.s32 %v105816, %v8 (stack39)
        %v105823 = vadd.s32 1, %v105819 (stack39)
        %v105827 = vadd.s32 %v105823, %v105811 (stack39)
        %v105829 = vshll.u32 %v105823, 17 (stack44)
        %v105830 = vshrl.u32 %v105823, 15 (stack45)
        %v105831 = vor.u32 %v105830, %v105829 (stack46)
        %v105832 = vxor.u32 %v105831, %v105827 (stack47)
        %v105835 = vadd.s32 %v105832, %v105827 (stack39)
        %v105837 = vshll.u32 %v105832, 29 (stack44)
        %v105838 = vshrl.u32 %v105832, 3 (stack45)
        %v105839 = vor.u32 %v105838, %v105837 (stack46)
        %v105840 = vxor.u32 %v105839, %v105835 (stack47)
        %v105843 = vadd.s32 %v105840, %v105835 (stack39)
        %v105845 = vshll.u32 %v105840, 16 (stack44)
        %v105846 = vshrl.u32 %v105840, 16 (stack45)
        %v105847 = vor.u32 %v105846, %v105845 (stack46)
        %v105848 = vxor.u32 %v105847, %v105843 (stack47)
        %v105851 = vadd.s32 %v105848, %v105843 (stack39)
        %v105855 = vadd.s32 %v105851, %v8 (stack39)
        %v105857 = vshll.u32 %v105848, 24 (stack44)
        %v105858 = vshrl.u32 %v105848, 8 (stack45)
        %v105859 = vor.u32 %v105858, %v105857 (stack46)
        %v105860 = vxor.u32 %v105859, %v105851 (stack47)
        %v105863 = vadd.s32 %v105860, %v10 (stack39)
        %v105867 = vadd.s32 2, %v105863 (stack39)
        %v105871 = vadd.s32 %v105867, %v105855 (stack39)
        %v105873 = vshll.u32 %v105867, 13 (stack44)
        %v105874 = vshrl.u32 %v105867, 19 (stack45)
        %v105875 = vor.u32 %v105874, %v105873 (stack46)
        %v105876 = vxor.u32 %v105875, %v105871 (stack47)
        %v105879 = vadd.s32 %v105876, %v105871 (stack39)
        %v105881 = vshll.u32 %v105876, 15 (stack44)
        %v105882 = vshrl.u32 %v105876, 17 (stack45)
        %v105883 = vor.u32 %v105882, %v105881 (stack46)
        %v105884 = vxor.u32 %v105883, %v105879 (stack47)
        %v105887 = vadd.s32 %v105884, %v105879 (stack39)
        %v105889 = vshll.u32 %v105884, 26 (stack44)
        %v105890 = vshrl.u32 %v105884, 6 (stack45)
        %v105891 = vor.u32 %v105890, %v105889 (stack46)
        %v105892 = vxor.u32 %v105891, %v105887 (stack47)
        %v105895 = vadd.s32 %v105892, %v105887 (stack39)
        %v105899 = vadd.s32 %v105895, %v10 (stack39)
        %v105901 = vshll.u32 %v105892, 6 (stack44)
        %v105902 = vshrl.u32 %v105892, 26 (stack45)
        %v105903 = vor.u32 %v105902, %v105901 (stack46)
        %v105904 = vxor.u32 %v105903, %v105895 (stack47)
        %v105907 = vadd.s32 %v105904, %v9 (stack39)
        %v105911 = vadd.s32 3, %v105907 (stack39)
        %v105915 = vadd.s32 %v105911, %v105899 (stack39)
        %v105917 = vshll.u32 %v105911, 17 (stack44)
        %v105918 = vshrl.u32 %v105911, 15 (stack45)
        %v105919 = vor.u32 %v105918, %v105917 (stack46)
        %v105920 = vxor.u32 %v105919, %v105915 (stack47)
        %v105923 = vadd.s32 %v105920, %v105915 (stack39)
        %v105925 = vshll.u32 %v105920, 29 (stack44)
        %v105926 = vshrl.u32 %v105920, 3 (stack45)
        %v105927 = vor.u32 %v105926, %v105925 (stack46)
        %v105928 = vxor.u32 %v105927, %v105923 (stack47)
        %v105931 = vadd.s32 %v105928, %v105923 (stack39)
        %v105933 = vshll.u32 %v105928, 16 (stack44)
        %v105934 = vshrl.u32 %v105928, 16 (stack45)
        %v105935 = vor.u32 %v105934, %v105933 (stack46)
        %v105936 = vxor.u32 %v105935, %v105931 (stack47)
        %v105939 = vadd.s32 %v105936, %v105931 (stack39)
        %v105943 = vadd.s32 %v105939, %v9 (stack39)
        %v105945 = vshll.u32 %v105936, 24 (stack44)
        %v105946 = vshrl.u32 %v105936, 8 (stack45)
        %v105947 = vor.u32 %v105946, %v105945 (stack46)
        %v105948 = vxor.u32 %v105947, %v105939 (stack47)
        %v105951 = vadd.s32 %v105948, %v8 (stack39)
        %v105955 = vadd.s32 4, %v105951 (stack39)
        %v105959 = vadd.s32 %v105955, %v105943 (stack39)
        %v105961 = vshll.u32 %v105955, 13 (stack44)
        %v105962 = vshrl.u32 %v105955, 19 (stack45)
        %v105963 = vor.u32 %v105962, %v105961 (stack46)
        %v105964 = vxor.u32 %v105963, %v105959 (stack47)
        %v105967 = vadd.s32 %v105964, %v105959 (stack39)
        %v105969 = vshll.u32 %v105964, 15 (stack44)
        %v105970 = vshrl.u32 %v105964, 17 (stack45)
        %v105971 = vor.u32 %v105970, %v105969 (stack46)
        %v105972 = vxor.u32 %v105971, %v105967 (stack47)
        %v105975 = vadd.s32 %v105972, %v105967 (stack39)
        %v105977 = vshll.u32 %v105972, 26 (stack44)
        %v105978 = vshrl.u32 %v105972, 6 (stack45)
        %v105979 = vor.u32 %v105978, %v105977 (stack46)
        %v105980 = vxor.u32 %v105979, %v105975 (stack47)
        %v105983 = vadd.s32 %v105980, %v105975 (stack39)
        %v105987 = vadd.s32 %v105983, %v8 (stack39)
        %v105989 = vshll.u32 %v105980, 6 (stack44)
        %v105990 = vshrl.u32 %v105980, 26 (stack45)
        %v105991 = vor.u32 %v105990, %v105989 (stack46)
        %v105992 = vxor.u32 %v105991, %v105983 (stack47)
        %v105995 = vadd.s32 %v105992, %v10 (stack39)
        %v105999 = vadd.s32 5, %v105995 (stack39)
        %v106001 = vxor.u32 %v105999, %v105987 (stack47)
        %v106002 = vand.u32.u8 255, %v106001 (stack48)
        %v106003 = vand.u32 65535, %v106002 (stack49)
        %v106004 = vshrl.u32 %v106003, 1 (stack50)
        %v106005 = vor.u32 16256, %v106004 (stack46)
        %v106006 = vand.u32.u16 65535, %v106005 (stack51)
        %v120312 = vadd.low.f32.bf16 -1.0, %v106006 (stack52)
        %v106015 = vmul.f32 2.0, %v120312 (stack53)
        %v106019 = vadd.f32 -0.99609375, %v106015 (stack52)
        %v106023 = vmax.f32 %v106019, -0.99609375 (stack54)
        %v106025 = vand.u32 2147483647, %v106023 (stack55)
        %vm106028 = vcmp.eq.f32.partialorder %v106025, 1.0 (stack56)
        %v106033 = vmul.f32 inf, %v106023 (stack53)
        %v106035 = vxor.u32 2147483648, %v106023 (stack57)
        %v106038 = vmul.f32 %v106035, %v106023 (stack53)
        %v106040 = vadd.f32 1.0, %v106038 (stack58)
        %v106041 = vlog2.pop %v106040 (stack59)
        %v106042 = vmul.f32 0.6931472, %v106041 (stack60)
        %v106043 = vmul.f32 -0.5, %v106038 (stack61)
        %v106044 = vadd.f32 1.0, %v106043 (stack62)
        %v106045 = vmul.f32 %v106044, %v106038 (stack63)
        %v106046 = vand.u32 2147483647, %v106038 (stack64)
        %vm106047 = vcmp.lt.f32.partialorder %v106046, 0.0004427343 (stack65)
        %v106048 = vsel /*vm=*/%vm106047, /*on_true_vy=*/%v106045, /*on_false_vx=*/%v106042 (stack66)
        %v106049 = vxor.u32 2147483648, %v106048 (stack57)
        %vm106052 = vcmp.lt.f32.partialorder %v106049, 5.0 (stack56)
        %v106057 = vsel /*vm=*/%vm106052, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v106061 = vsel /*vm=*/%vm106052, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v106065 = vsel /*vm=*/%vm106052, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v106069 = vsel /*vm=*/%vm106052, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v106073 = vsel /*vm=*/%vm106052, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v106077 = vsel /*vm=*/%vm106052, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v106081 = vsel /*vm=*/%vm106052, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v106085 = vsel /*vm=*/%vm106052, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v106089 = vsel /*vm=*/%vm106052, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v106093 = vadd.f32 -2.5, %v106049 (stack52)
        %v106095 = vrsqrt.pop %v106049 (stack67)
        %v106096 = vmul.f32 %v106095, %v106049 (stack68)
        %vm106097 = vcmp.eq.f32.partialorder %v106049, inf (stack69)
        %v106098 = vsel /*vm=*/%vm106097, /*on_true_vy=*/%v106049, /*on_false_vx=*/%v106096 (stack70)
        %vm106099 = vcmp.eq.f32.partialorder %v106049, 0.0 (stack71)
        %v106100 = vand.u32 2147483648, %v106049 (stack72)
        %v106101 = vsel /*vm=*/%vm106099, /*on_true_vy=*/%v106100, /*on_false_vx=*/%v106098 (stack73)
        %v106104 = vadd.f32 -3.0, %v106101 (stack52)
        %v106108 = vsel /*vm=*/%vm106052, /*on_true_vy=*/%v106093, /*on_false_vx=*/%v106104 (stack43)
        %v106112 = vmul.f32 %v106108, %v106089 (stack53)
        %v106116 = vadd.f32 %v106112, %v106085 (stack52)
        %v106120 = vmul.f32 %v106116, %v106108 (stack53)
        %v106124 = vadd.f32 %v106120, %v106081 (stack52)
        %v106128 = vmul.f32 %v106124, %v106108 (stack53)
        %v106132 = vadd.f32 %v106128, %v106077 (stack52)
        %v106136 = vmul.f32 %v106132, %v106108 (stack53)
        %v106140 = vadd.f32 %v106136, %v106073 (stack52)
        %v106144 = vmul.f32 %v106140, %v106108 (stack53)
        %v106148 = vadd.f32 %v106144, %v106069 (stack52)
        %v106152 = vmul.f32 %v106148, %v106108 (stack53)
        %v106156 = vadd.f32 %v106152, %v106065 (stack52)
        %v106160 = vmul.f32 %v106156, %v106108 (stack53)
        %v106164 = vadd.f32 %v106160, %v106061 (stack52)
        %v106168 = vmul.f32 %v106164, %v106108 (stack53)
        %v106172 = vadd.f32 %v106168, %v106057 (stack52)
        %v106176 = vmul.f32 %v106172, %v106023 (stack53)
        %v106180 = vsel /*vm=*/%vm106028, /*on_true_vy=*/%v106033, /*on_false_vx=*/%v106176 (stack43)
        %v106184 = vmul.f32 1.4140625, %v106180 (stack53)
        %v106187 = vpack.c.bf16 0.0, %v106184 (stack74)
        %120313 = vst [vmem:[%s280 + $0x170] sm:$0xf] /*vst_source=*/%v106187 (stack75)
        %v106191 = vadd.s32 %v104805, %v1868 (stack39)
        %v106201 = vadd.s32 %v106191, %v415 (stack39)
        %vm106205 = vcmp.lt.u32.totalorder %v106201, %v106191 (stack42)
        %vm106210 = vcmp.lt.u32.totalorder %v106191, %v1868 (stack42)
        %v106215 = vadd.s32 %v104788, %v1855 (stack39)
        %v106219 = vadd.s32 1, %v106215 (stack39)
        %v106223 = vsel /*vm=*/%vm106210, /*on_true_vy=*/%v106219, /*on_false_vx=*/%v106215 (stack43)
        %v106227 = vadd.s32 1, %v106223 (stack39)
        %v106231 = vsel /*vm=*/%vm106205, /*on_true_vy=*/%v106227, /*on_false_vx=*/%v106223 (stack43)
        %v106236 = vadd.s32 %v106231, %v10 (stack39)
        %v106240 = vadd.s32 %v106201, %v9 (stack39)
        %v106244 = vadd.s32 %v106240, %v106236 (stack39)
        %v106246 = vshll.u32 %v106240, 13 (stack44)
        %v106247 = vshrl.u32 %v106240, 19 (stack45)
        %v106248 = vor.u32 %v106247, %v106246 (stack46)
        %v106249 = vxor.u32 %v106248, %v106244 (stack47)
        %v106252 = vadd.s32 %v106249, %v106244 (stack39)
        %v106254 = vshll.u32 %v106249, 15 (stack44)
        %v106255 = vshrl.u32 %v106249, 17 (stack45)
        %v106256 = vor.u32 %v106255, %v106254 (stack46)
        %v106257 = vxor.u32 %v106256, %v106252 (stack47)
        %v106260 = vadd.s32 %v106257, %v106252 (stack39)
        %v106262 = vshll.u32 %v106257, 26 (stack44)
        %v106263 = vshrl.u32 %v106257, 6 (stack45)
        %v106264 = vor.u32 %v106263, %v106262 (stack46)
        %v106265 = vxor.u32 %v106264, %v106260 (stack47)
        %v106268 = vadd.s32 %v106265, %v106260 (stack39)
        %v106272 = vadd.s32 %v106268, %v9 (stack39)
        %v106274 = vshll.u32 %v106265, 6 (stack44)
        %v106275 = vshrl.u32 %v106265, 26 (stack45)
        %v106276 = vor.u32 %v106275, %v106274 (stack46)
        %v106277 = vxor.u32 %v106276, %v106268 (stack47)
        %v106280 = vadd.s32 %v106277, %v8 (stack39)
        %v106284 = vadd.s32 1, %v106280 (stack39)
        %v106288 = vadd.s32 %v106284, %v106272 (stack39)
        %v106290 = vshll.u32 %v106284, 17 (stack44)
        %v106291 = vshrl.u32 %v106284, 15 (stack45)
        %v106292 = vor.u32 %v106291, %v106290 (stack46)
        %v106293 = vxor.u32 %v106292, %v106288 (stack47)
        %v106296 = vadd.s32 %v106293, %v106288 (stack39)
        %v106298 = vshll.u32 %v106293, 29 (stack44)
        %v106299 = vshrl.u32 %v106293, 3 (stack45)
        %v106300 = vor.u32 %v106299, %v106298 (stack46)
        %v106301 = vxor.u32 %v106300, %v106296 (stack47)
        %v106304 = vadd.s32 %v106301, %v106296 (stack39)
        %v106306 = vshll.u32 %v106301, 16 (stack44)
        %v106307 = vshrl.u32 %v106301, 16 (stack45)
        %v106308 = vor.u32 %v106307, %v106306 (stack46)
        %v106309 = vxor.u32 %v106308, %v106304 (stack47)
        %v106312 = vadd.s32 %v106309, %v106304 (stack39)
        %v106316 = vadd.s32 %v106312, %v8 (stack39)
        %v106318 = vshll.u32 %v106309, 24 (stack44)
        %v106319 = vshrl.u32 %v106309, 8 (stack45)
        %v106320 = vor.u32 %v106319, %v106318 (stack46)
        %v106321 = vxor.u32 %v106320, %v106312 (stack47)
        %v106324 = vadd.s32 %v106321, %v10 (stack39)
        %v106328 = vadd.s32 2, %v106324 (stack39)
        %v106332 = vadd.s32 %v106328, %v106316 (stack39)
        %v106334 = vshll.u32 %v106328, 13 (stack44)
        %v106335 = vshrl.u32 %v106328, 19 (stack45)
        %v106336 = vor.u32 %v106335, %v106334 (stack46)
        %v106337 = vxor.u32 %v106336, %v106332 (stack47)
        %v106340 = vadd.s32 %v106337, %v106332 (stack39)
        %v106342 = vshll.u32 %v106337, 15 (stack44)
        %v106343 = vshrl.u32 %v106337, 17 (stack45)
        %v106344 = vor.u32 %v106343, %v106342 (stack46)
        %v106345 = vxor.u32 %v106344, %v106340 (stack47)
        %v106348 = vadd.s32 %v106345, %v106340 (stack39)
        %v106350 = vshll.u32 %v106345, 26 (stack44)
        %v106351 = vshrl.u32 %v106345, 6 (stack45)
        %v106352 = vor.u32 %v106351, %v106350 (stack46)
        %v106353 = vxor.u32 %v106352, %v106348 (stack47)
        %v106356 = vadd.s32 %v106353, %v106348 (stack39)
        %v106360 = vadd.s32 %v106356, %v10 (stack39)
        %v106362 = vshll.u32 %v106353, 6 (stack44)
        %v106363 = vshrl.u32 %v106353, 26 (stack45)
        %v106364 = vor.u32 %v106363, %v106362 (stack46)
        %v106365 = vxor.u32 %v106364, %v106356 (stack47)
        %v106368 = vadd.s32 %v106365, %v9 (stack39)
        %v106372 = vadd.s32 3, %v106368 (stack39)
        %v106376 = vadd.s32 %v106372, %v106360 (stack39)
        %v106378 = vshll.u32 %v106372, 17 (stack44)
        %v106379 = vshrl.u32 %v106372, 15 (stack45)
        %v106380 = vor.u32 %v106379, %v106378 (stack46)
        %v106381 = vxor.u32 %v106380, %v106376 (stack47)
        %v106384 = vadd.s32 %v106381, %v106376 (stack39)
        %v106386 = vshll.u32 %v106381, 29 (stack44)
        %v106387 = vshrl.u32 %v106381, 3 (stack45)
        %v106388 = vor.u32 %v106387, %v106386 (stack46)
        %v106389 = vxor.u32 %v106388, %v106384 (stack47)
        %v106392 = vadd.s32 %v106389, %v106384 (stack39)
        %v106394 = vshll.u32 %v106389, 16 (stack44)
        %v106395 = vshrl.u32 %v106389, 16 (stack45)
        %v106396 = vor.u32 %v106395, %v106394 (stack46)
        %v106397 = vxor.u32 %v106396, %v106392 (stack47)
        %v106400 = vadd.s32 %v106397, %v106392 (stack39)
        %v106404 = vadd.s32 %v106400, %v9 (stack39)
        %v106406 = vshll.u32 %v106397, 24 (stack44)
        %v106407 = vshrl.u32 %v106397, 8 (stack45)
        %v106408 = vor.u32 %v106407, %v106406 (stack46)
        %v106409 = vxor.u32 %v106408, %v106400 (stack47)
        %v106412 = vadd.s32 %v106409, %v8 (stack39)
        %v106416 = vadd.s32 4, %v106412 (stack39)
        %v106420 = vadd.s32 %v106416, %v106404 (stack39)
        %v106422 = vshll.u32 %v106416, 13 (stack44)
        %v106423 = vshrl.u32 %v106416, 19 (stack45)
        %v106424 = vor.u32 %v106423, %v106422 (stack46)
        %v106425 = vxor.u32 %v106424, %v106420 (stack47)
        %v106428 = vadd.s32 %v106425, %v106420 (stack39)
        %v106430 = vshll.u32 %v106425, 15 (stack44)
        %v106431 = vshrl.u32 %v106425, 17 (stack45)
        %v106432 = vor.u32 %v106431, %v106430 (stack46)
        %v106433 = vxor.u32 %v106432, %v106428 (stack47)
        %v106436 = vadd.s32 %v106433, %v106428 (stack39)
        %v106438 = vshll.u32 %v106433, 26 (stack44)
        %v106439 = vshrl.u32 %v106433, 6 (stack45)
        %v106440 = vor.u32 %v106439, %v106438 (stack46)
        %v106441 = vxor.u32 %v106440, %v106436 (stack47)
        %v106444 = vadd.s32 %v106441, %v106436 (stack39)
        %v106448 = vadd.s32 %v106444, %v8 (stack39)
        %v106450 = vshll.u32 %v106441, 6 (stack44)
        %v106451 = vshrl.u32 %v106441, 26 (stack45)
        %v106452 = vor.u32 %v106451, %v106450 (stack46)
        %v106453 = vxor.u32 %v106452, %v106444 (stack47)
        %v106456 = vadd.s32 %v106453, %v10 (stack39)
        %v106460 = vadd.s32 5, %v106456 (stack39)
        %v106462 = vxor.u32 %v106460, %v106448 (stack47)
        %v106463 = vand.u32.u8 255, %v106462 (stack48)
        %v106464 = vand.u32 65535, %v106463 (stack49)
        %v106465 = vshrl.u32 %v106464, 1 (stack50)
        %v106466 = vor.u32 16256, %v106465 (stack46)
        %v106467 = vand.u32.u16 65535, %v106466 (stack51)
        %v120314 = vadd.low.f32.bf16 -1.0, %v106467 (stack52)
        %v106476 = vmul.f32 2.0, %v120314 (stack53)
        %v106480 = vadd.f32 -0.99609375, %v106476 (stack52)
        %v106484 = vmax.f32 %v106480, -0.99609375 (stack54)
        %v106486 = vand.u32 2147483647, %v106484 (stack55)
        %vm106489 = vcmp.eq.f32.partialorder %v106486, 1.0 (stack56)
        %v106494 = vmul.f32 inf, %v106484 (stack53)
        %v106496 = vxor.u32 2147483648, %v106484 (stack57)
        %v106499 = vmul.f32 %v106496, %v106484 (stack53)
        %v106501 = vadd.f32 1.0, %v106499 (stack58)
        %v106502 = vlog2.pop %v106501 (stack59)
        %v106503 = vmul.f32 0.6931472, %v106502 (stack60)
        %v106504 = vmul.f32 -0.5, %v106499 (stack61)
        %v106505 = vadd.f32 1.0, %v106504 (stack62)
        %v106506 = vmul.f32 %v106505, %v106499 (stack63)
        %v106507 = vand.u32 2147483647, %v106499 (stack64)
        %vm106508 = vcmp.lt.f32.partialorder %v106507, 0.0004427343 (stack65)
        %v106509 = vsel /*vm=*/%vm106508, /*on_true_vy=*/%v106506, /*on_false_vx=*/%v106503 (stack66)
        %v106510 = vxor.u32 2147483648, %v106509 (stack57)
        %vm106513 = vcmp.lt.f32.partialorder %v106510, 5.0 (stack56)
        %v106518 = vsel /*vm=*/%vm106513, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v106522 = vsel /*vm=*/%vm106513, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v106526 = vsel /*vm=*/%vm106513, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v106530 = vsel /*vm=*/%vm106513, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v106534 = vsel /*vm=*/%vm106513, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v106538 = vsel /*vm=*/%vm106513, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v106542 = vsel /*vm=*/%vm106513, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v106546 = vsel /*vm=*/%vm106513, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v106550 = vsel /*vm=*/%vm106513, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v106554 = vadd.f32 -2.5, %v106510 (stack52)
        %v106556 = vrsqrt.pop %v106510 (stack67)
        %v106557 = vmul.f32 %v106556, %v106510 (stack68)
        %vm106558 = vcmp.eq.f32.partialorder %v106510, inf (stack69)
        %v106559 = vsel /*vm=*/%vm106558, /*on_true_vy=*/%v106510, /*on_false_vx=*/%v106557 (stack70)
        %vm106560 = vcmp.eq.f32.partialorder %v106510, 0.0 (stack71)
        %v106561 = vand.u32 2147483648, %v106510 (stack72)
        %v106562 = vsel /*vm=*/%vm106560, /*on_true_vy=*/%v106561, /*on_false_vx=*/%v106559 (stack73)
        %v106565 = vadd.f32 -3.0, %v106562 (stack52)
        %v106569 = vsel /*vm=*/%vm106513, /*on_true_vy=*/%v106554, /*on_false_vx=*/%v106565 (stack43)
        %v106573 = vmul.f32 %v106569, %v106550 (stack53)
        %v106577 = vadd.f32 %v106573, %v106546 (stack52)
        %v106581 = vmul.f32 %v106577, %v106569 (stack53)
        %v106585 = vadd.f32 %v106581, %v106542 (stack52)
        %v106589 = vmul.f32 %v106585, %v106569 (stack53)
        %v106593 = vadd.f32 %v106589, %v106538 (stack52)
        %v106597 = vmul.f32 %v106593, %v106569 (stack53)
        %v106601 = vadd.f32 %v106597, %v106534 (stack52)
        %v106605 = vmul.f32 %v106601, %v106569 (stack53)
        %v106609 = vadd.f32 %v106605, %v106530 (stack52)
        %v106613 = vmul.f32 %v106609, %v106569 (stack53)
        %v106617 = vadd.f32 %v106613, %v106526 (stack52)
        %v106621 = vmul.f32 %v106617, %v106569 (stack53)
        %v106625 = vadd.f32 %v106621, %v106522 (stack52)
        %v106629 = vmul.f32 %v106625, %v106569 (stack53)
        %v106633 = vadd.f32 %v106629, %v106518 (stack52)
        %v106637 = vmul.f32 %v106633, %v106484 (stack53)
        %v106641 = vsel /*vm=*/%vm106489, /*on_true_vy=*/%v106494, /*on_false_vx=*/%v106637 (stack43)
        %v106645 = vmul.f32 1.4140625, %v106641 (stack53)
        %v106648 = vpack.c.bf16 0.0, %v106645 (stack74)
        %120315 = vst [vmem:[%s280 + $0x1f0] sm:$0xf] /*vst_source=*/%v106648 (stack75)
        %v106652 = vadd.s32 %v104805, %v2355 (stack39)
        %v106662 = vadd.s32 %v106652, %v415 (stack39)
        %vm106666 = vcmp.lt.u32.totalorder %v106662, %v106652 (stack42)
        %vm106671 = vcmp.lt.u32.totalorder %v106652, %v2355 (stack42)
        %v106676 = vadd.s32 %v104788, %v2342 (stack39)
        %v106680 = vadd.s32 1, %v106676 (stack39)
        %v106684 = vsel /*vm=*/%vm106671, /*on_true_vy=*/%v106680, /*on_false_vx=*/%v106676 (stack43)
        %v106688 = vadd.s32 1, %v106684 (stack39)
        %v106692 = vsel /*vm=*/%vm106666, /*on_true_vy=*/%v106688, /*on_false_vx=*/%v106684 (stack43)
        %v106697 = vadd.s32 %v106692, %v10 (stack39)
        %v106701 = vadd.s32 %v106662, %v9 (stack39)
        %v106705 = vadd.s32 %v106701, %v106697 (stack39)
        %v106707 = vshll.u32 %v106701, 13 (stack44)
        %v106708 = vshrl.u32 %v106701, 19 (stack45)
        %v106709 = vor.u32 %v106708, %v106707 (stack46)
        %v106710 = vxor.u32 %v106709, %v106705 (stack47)
        %v106713 = vadd.s32 %v106710, %v106705 (stack39)
        %v106715 = vshll.u32 %v106710, 15 (stack44)
        %v106716 = vshrl.u32 %v106710, 17 (stack45)
        %v106717 = vor.u32 %v106716, %v106715 (stack46)
        %v106718 = vxor.u32 %v106717, %v106713 (stack47)
        %v106721 = vadd.s32 %v106718, %v106713 (stack39)
        %v106723 = vshll.u32 %v106718, 26 (stack44)
        %v106724 = vshrl.u32 %v106718, 6 (stack45)
        %v106725 = vor.u32 %v106724, %v106723 (stack46)
        %v106726 = vxor.u32 %v106725, %v106721 (stack47)
        %v106729 = vadd.s32 %v106726, %v106721 (stack39)
        %v106733 = vadd.s32 %v106729, %v9 (stack39)
        %v106735 = vshll.u32 %v106726, 6 (stack44)
        %v106736 = vshrl.u32 %v106726, 26 (stack45)
        %v106737 = vor.u32 %v106736, %v106735 (stack46)
        %v106738 = vxor.u32 %v106737, %v106729 (stack47)
        %v106741 = vadd.s32 %v106738, %v8 (stack39)
        %v106745 = vadd.s32 1, %v106741 (stack39)
        %v106749 = vadd.s32 %v106745, %v106733 (stack39)
        %v106751 = vshll.u32 %v106745, 17 (stack44)
        %v106752 = vshrl.u32 %v106745, 15 (stack45)
        %v106753 = vor.u32 %v106752, %v106751 (stack46)
        %v106754 = vxor.u32 %v106753, %v106749 (stack47)
        %v106757 = vadd.s32 %v106754, %v106749 (stack39)
        %v106759 = vshll.u32 %v106754, 29 (stack44)
        %v106760 = vshrl.u32 %v106754, 3 (stack45)
        %v106761 = vor.u32 %v106760, %v106759 (stack46)
        %v106762 = vxor.u32 %v106761, %v106757 (stack47)
        %v106765 = vadd.s32 %v106762, %v106757 (stack39)
        %v106767 = vshll.u32 %v106762, 16 (stack44)
        %v106768 = vshrl.u32 %v106762, 16 (stack45)
        %v106769 = vor.u32 %v106768, %v106767 (stack46)
        %v106770 = vxor.u32 %v106769, %v106765 (stack47)
        %v106773 = vadd.s32 %v106770, %v106765 (stack39)
        %v106777 = vadd.s32 %v106773, %v8 (stack39)
        %v106779 = vshll.u32 %v106770, 24 (stack44)
        %v106780 = vshrl.u32 %v106770, 8 (stack45)
        %v106781 = vor.u32 %v106780, %v106779 (stack46)
        %v106782 = vxor.u32 %v106781, %v106773 (stack47)
        %v106785 = vadd.s32 %v106782, %v10 (stack39)
        %v106789 = vadd.s32 2, %v106785 (stack39)
        %v106793 = vadd.s32 %v106789, %v106777 (stack39)
        %v106795 = vshll.u32 %v106789, 13 (stack44)
        %v106796 = vshrl.u32 %v106789, 19 (stack45)
        %v106797 = vor.u32 %v106796, %v106795 (stack46)
        %v106798 = vxor.u32 %v106797, %v106793 (stack47)
        %v106801 = vadd.s32 %v106798, %v106793 (stack39)
        %v106803 = vshll.u32 %v106798, 15 (stack44)
        %v106804 = vshrl.u32 %v106798, 17 (stack45)
        %v106805 = vor.u32 %v106804, %v106803 (stack46)
        %v106806 = vxor.u32 %v106805, %v106801 (stack47)
        %v106809 = vadd.s32 %v106806, %v106801 (stack39)
        %v106811 = vshll.u32 %v106806, 26 (stack44)
        %v106812 = vshrl.u32 %v106806, 6 (stack45)
        %v106813 = vor.u32 %v106812, %v106811 (stack46)
        %v106814 = vxor.u32 %v106813, %v106809 (stack47)
        %v106817 = vadd.s32 %v106814, %v106809 (stack39)
        %v106821 = vadd.s32 %v106817, %v10 (stack39)
        %v106823 = vshll.u32 %v106814, 6 (stack44)
        %v106824 = vshrl.u32 %v106814, 26 (stack45)
        %v106825 = vor.u32 %v106824, %v106823 (stack46)
        %v106826 = vxor.u32 %v106825, %v106817 (stack47)
        %v106829 = vadd.s32 %v106826, %v9 (stack39)
        %v106833 = vadd.s32 3, %v106829 (stack39)
        %v106837 = vadd.s32 %v106833, %v106821 (stack39)
        %v106839 = vshll.u32 %v106833, 17 (stack44)
        %v106840 = vshrl.u32 %v106833, 15 (stack45)
        %v106841 = vor.u32 %v106840, %v106839 (stack46)
        %v106842 = vxor.u32 %v106841, %v106837 (stack47)
        %v106845 = vadd.s32 %v106842, %v106837 (stack39)
        %v106847 = vshll.u32 %v106842, 29 (stack44)
        %v106848 = vshrl.u32 %v106842, 3 (stack45)
        %v106849 = vor.u32 %v106848, %v106847 (stack46)
        %v106850 = vxor.u32 %v106849, %v106845 (stack47)
        %v106853 = vadd.s32 %v106850, %v106845 (stack39)
        %v106855 = vshll.u32 %v106850, 16 (stack44)
        %v106856 = vshrl.u32 %v106850, 16 (stack45)
        %v106857 = vor.u32 %v106856, %v106855 (stack46)
        %v106858 = vxor.u32 %v106857, %v106853 (stack47)
        %v106861 = vadd.s32 %v106858, %v106853 (stack39)
        %v106865 = vadd.s32 %v106861, %v9 (stack39)
        %v106867 = vshll.u32 %v106858, 24 (stack44)
        %v106868 = vshrl.u32 %v106858, 8 (stack45)
        %v106869 = vor.u32 %v106868, %v106867 (stack46)
        %v106870 = vxor.u32 %v106869, %v106861 (stack47)
        %v106873 = vadd.s32 %v106870, %v8 (stack39)
        %v106877 = vadd.s32 4, %v106873 (stack39)
        %v106881 = vadd.s32 %v106877, %v106865 (stack39)
        %v106883 = vshll.u32 %v106877, 13 (stack44)
        %v106884 = vshrl.u32 %v106877, 19 (stack45)
        %v106885 = vor.u32 %v106884, %v106883 (stack46)
        %v106886 = vxor.u32 %v106885, %v106881 (stack47)
        %v106889 = vadd.s32 %v106886, %v106881 (stack39)
        %v106891 = vshll.u32 %v106886, 15 (stack44)
        %v106892 = vshrl.u32 %v106886, 17 (stack45)
        %v106893 = vor.u32 %v106892, %v106891 (stack46)
        %v106894 = vxor.u32 %v106893, %v106889 (stack47)
        %v106897 = vadd.s32 %v106894, %v106889 (stack39)
        %v106899 = vshll.u32 %v106894, 26 (stack44)
        %v106900 = vshrl.u32 %v106894, 6 (stack45)
        %v106901 = vor.u32 %v106900, %v106899 (stack46)
        %v106902 = vxor.u32 %v106901, %v106897 (stack47)
        %v106905 = vadd.s32 %v106902, %v106897 (stack39)
        %v106909 = vadd.s32 %v106905, %v8 (stack39)
        %v106911 = vshll.u32 %v106902, 6 (stack44)
        %v106912 = vshrl.u32 %v106902, 26 (stack45)
        %v106913 = vor.u32 %v106912, %v106911 (stack46)
        %v106914 = vxor.u32 %v106913, %v106905 (stack47)
        %v106917 = vadd.s32 %v106914, %v10 (stack39)
        %v106921 = vadd.s32 5, %v106917 (stack39)
        %v106923 = vxor.u32 %v106921, %v106909 (stack47)
        %v106924 = vand.u32.u8 255, %v106923 (stack48)
        %v106925 = vand.u32 65535, %v106924 (stack49)
        %v106926 = vshrl.u32 %v106925, 1 (stack50)
        %v106927 = vor.u32 16256, %v106926 (stack46)
        %v106928 = vand.u32.u16 65535, %v106927 (stack51)
        %v120316 = vadd.low.f32.bf16 -1.0, %v106928 (stack52)
        %v106937 = vmul.f32 2.0, %v120316 (stack53)
        %v106941 = vadd.f32 -0.99609375, %v106937 (stack52)
        %v106945 = vmax.f32 %v106941, -0.99609375 (stack54)
        %v106947 = vand.u32 2147483647, %v106945 (stack55)
        %vm106950 = vcmp.eq.f32.partialorder %v106947, 1.0 (stack56)
        %v106955 = vmul.f32 inf, %v106945 (stack53)
        %v106957 = vxor.u32 2147483648, %v106945 (stack57)
        %v106960 = vmul.f32 %v106957, %v106945 (stack53)
        %v106962 = vadd.f32 1.0, %v106960 (stack58)
        %v106963 = vlog2.pop %v106962 (stack59)
        %v106964 = vmul.f32 0.6931472, %v106963 (stack60)
        %v106965 = vmul.f32 -0.5, %v106960 (stack61)
        %v106966 = vadd.f32 1.0, %v106965 (stack62)
        %v106967 = vmul.f32 %v106966, %v106960 (stack63)
        %v106968 = vand.u32 2147483647, %v106960 (stack64)
        %vm106969 = vcmp.lt.f32.partialorder %v106968, 0.0004427343 (stack65)
        %v106970 = vsel /*vm=*/%vm106969, /*on_true_vy=*/%v106967, /*on_false_vx=*/%v106964 (stack66)
        %v106971 = vxor.u32 2147483648, %v106970 (stack57)
        %vm106974 = vcmp.lt.f32.partialorder %v106971, 5.0 (stack56)
        %v106979 = vsel /*vm=*/%vm106974, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v106983 = vsel /*vm=*/%vm106974, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v106987 = vsel /*vm=*/%vm106974, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v106991 = vsel /*vm=*/%vm106974, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v106995 = vsel /*vm=*/%vm106974, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v106999 = vsel /*vm=*/%vm106974, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v107003 = vsel /*vm=*/%vm106974, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v107007 = vsel /*vm=*/%vm106974, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v107011 = vsel /*vm=*/%vm106974, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v107015 = vadd.f32 -2.5, %v106971 (stack52)
        %v107017 = vrsqrt.pop %v106971 (stack67)
        %v107018 = vmul.f32 %v107017, %v106971 (stack68)
        %vm107019 = vcmp.eq.f32.partialorder %v106971, inf (stack69)
        %v107020 = vsel /*vm=*/%vm107019, /*on_true_vy=*/%v106971, /*on_false_vx=*/%v107018 (stack70)
        %vm107021 = vcmp.eq.f32.partialorder %v106971, 0.0 (stack71)
        %v107022 = vand.u32 2147483648, %v106971 (stack72)
        %v107023 = vsel /*vm=*/%vm107021, /*on_true_vy=*/%v107022, /*on_false_vx=*/%v107020 (stack73)
        %v107026 = vadd.f32 -3.0, %v107023 (stack52)
        %v107030 = vsel /*vm=*/%vm106974, /*on_true_vy=*/%v107015, /*on_false_vx=*/%v107026 (stack43)
        %v107034 = vmul.f32 %v107030, %v107011 (stack53)
        %v107038 = vadd.f32 %v107034, %v107007 (stack52)
        %v107042 = vmul.f32 %v107038, %v107030 (stack53)
        %v107046 = vadd.f32 %v107042, %v107003 (stack52)
        %v107050 = vmul.f32 %v107046, %v107030 (stack53)
        %v107054 = vadd.f32 %v107050, %v106999 (stack52)
        %v107058 = vmul.f32 %v107054, %v107030 (stack53)
        %v107062 = vadd.f32 %v107058, %v106995 (stack52)
        %v107066 = vmul.f32 %v107062, %v107030 (stack53)
        %v107070 = vadd.f32 %v107066, %v106991 (stack52)
        %v107074 = vmul.f32 %v107070, %v107030 (stack53)
        %v107078 = vadd.f32 %v107074, %v106987 (stack52)
        %v107082 = vmul.f32 %v107078, %v107030 (stack53)
        %v107086 = vadd.f32 %v107082, %v106983 (stack52)
        %v107090 = vmul.f32 %v107086, %v107030 (stack53)
        %v107094 = vadd.f32 %v107090, %v106979 (stack52)
        %v107098 = vmul.f32 %v107094, %v106945 (stack53)
        %v107102 = vsel /*vm=*/%vm106950, /*on_true_vy=*/%v106955, /*on_false_vx=*/%v107098 (stack43)
        %v107106 = vmul.f32 1.4140625, %v107102 (stack53)
        %v107109 = vpack.c.bf16 0.0, %v107106 (stack74)
        %120317 = vst [vmem:[%s280 + $0x270] sm:$0xf] /*vst_source=*/%v107109 (stack75)
        %v107113 = vadd.s32 %v104805, %v2842 (stack39)
        %v107123 = vadd.s32 %v107113, %v415 (stack39)
        %vm107127 = vcmp.lt.u32.totalorder %v107123, %v107113 (stack42)
        %vm107132 = vcmp.lt.u32.totalorder %v107113, %v2842 (stack42)
        %v107137 = vadd.s32 %v104788, %v2829 (stack39)
        %v107141 = vadd.s32 1, %v107137 (stack39)
        %v107145 = vsel /*vm=*/%vm107132, /*on_true_vy=*/%v107141, /*on_false_vx=*/%v107137 (stack43)
        %v107149 = vadd.s32 1, %v107145 (stack39)
        %v107153 = vsel /*vm=*/%vm107127, /*on_true_vy=*/%v107149, /*on_false_vx=*/%v107145 (stack43)
        %v107158 = vadd.s32 %v107153, %v10 (stack39)
        %v107162 = vadd.s32 %v107123, %v9 (stack39)
        %v107166 = vadd.s32 %v107162, %v107158 (stack39)
        %v107168 = vshll.u32 %v107162, 13 (stack44)
        %v107169 = vshrl.u32 %v107162, 19 (stack45)
        %v107170 = vor.u32 %v107169, %v107168 (stack46)
        %v107171 = vxor.u32 %v107170, %v107166 (stack47)
        %v107174 = vadd.s32 %v107171, %v107166 (stack39)
        %v107176 = vshll.u32 %v107171, 15 (stack44)
        %v107177 = vshrl.u32 %v107171, 17 (stack45)
        %v107178 = vor.u32 %v107177, %v107176 (stack46)
        %v107179 = vxor.u32 %v107178, %v107174 (stack47)
        %v107182 = vadd.s32 %v107179, %v107174 (stack39)
        %v107184 = vshll.u32 %v107179, 26 (stack44)
        %v107185 = vshrl.u32 %v107179, 6 (stack45)
        %v107186 = vor.u32 %v107185, %v107184 (stack46)
        %v107187 = vxor.u32 %v107186, %v107182 (stack47)
        %v107190 = vadd.s32 %v107187, %v107182 (stack39)
        %v107194 = vadd.s32 %v107190, %v9 (stack39)
        %v107196 = vshll.u32 %v107187, 6 (stack44)
        %v107197 = vshrl.u32 %v107187, 26 (stack45)
        %v107198 = vor.u32 %v107197, %v107196 (stack46)
        %v107199 = vxor.u32 %v107198, %v107190 (stack47)
        %v107202 = vadd.s32 %v107199, %v8 (stack39)
        %v107206 = vadd.s32 1, %v107202 (stack39)
        %v107210 = vadd.s32 %v107206, %v107194 (stack39)
        %v107212 = vshll.u32 %v107206, 17 (stack44)
        %v107213 = vshrl.u32 %v107206, 15 (stack45)
        %v107214 = vor.u32 %v107213, %v107212 (stack46)
        %v107215 = vxor.u32 %v107214, %v107210 (stack47)
        %v107218 = vadd.s32 %v107215, %v107210 (stack39)
        %v107220 = vshll.u32 %v107215, 29 (stack44)
        %v107221 = vshrl.u32 %v107215, 3 (stack45)
        %v107222 = vor.u32 %v107221, %v107220 (stack46)
        %v107223 = vxor.u32 %v107222, %v107218 (stack47)
        %v107226 = vadd.s32 %v107223, %v107218 (stack39)
        %v107228 = vshll.u32 %v107223, 16 (stack44)
        %v107229 = vshrl.u32 %v107223, 16 (stack45)
        %v107230 = vor.u32 %v107229, %v107228 (stack46)
        %v107231 = vxor.u32 %v107230, %v107226 (stack47)
        %v107234 = vadd.s32 %v107231, %v107226 (stack39)
        %v107238 = vadd.s32 %v107234, %v8 (stack39)
        %v107240 = vshll.u32 %v107231, 24 (stack44)
        %v107241 = vshrl.u32 %v107231, 8 (stack45)
        %v107242 = vor.u32 %v107241, %v107240 (stack46)
        %v107243 = vxor.u32 %v107242, %v107234 (stack47)
        %v107246 = vadd.s32 %v107243, %v10 (stack39)
        %v107250 = vadd.s32 2, %v107246 (stack39)
        %v107254 = vadd.s32 %v107250, %v107238 (stack39)
        %v107256 = vshll.u32 %v107250, 13 (stack44)
        %v107257 = vshrl.u32 %v107250, 19 (stack45)
        %v107258 = vor.u32 %v107257, %v107256 (stack46)
        %v107259 = vxor.u32 %v107258, %v107254 (stack47)
        %v107262 = vadd.s32 %v107259, %v107254 (stack39)
        %v107264 = vshll.u32 %v107259, 15 (stack44)
        %v107265 = vshrl.u32 %v107259, 17 (stack45)
        %v107266 = vor.u32 %v107265, %v107264 (stack46)
        %v107267 = vxor.u32 %v107266, %v107262 (stack47)
        %v107270 = vadd.s32 %v107267, %v107262 (stack39)
        %v107272 = vshll.u32 %v107267, 26 (stack44)
        %v107273 = vshrl.u32 %v107267, 6 (stack45)
        %v107274 = vor.u32 %v107273, %v107272 (stack46)
        %v107275 = vxor.u32 %v107274, %v107270 (stack47)
        %v107278 = vadd.s32 %v107275, %v107270 (stack39)
        %v107282 = vadd.s32 %v107278, %v10 (stack39)
        %v107284 = vshll.u32 %v107275, 6 (stack44)
        %v107285 = vshrl.u32 %v107275, 26 (stack45)
        %v107286 = vor.u32 %v107285, %v107284 (stack46)
        %v107287 = vxor.u32 %v107286, %v107278 (stack47)
        %v107290 = vadd.s32 %v107287, %v9 (stack39)
        %v107294 = vadd.s32 3, %v107290 (stack39)
        %v107298 = vadd.s32 %v107294, %v107282 (stack39)
        %v107300 = vshll.u32 %v107294, 17 (stack44)
        %v107301 = vshrl.u32 %v107294, 15 (stack45)
        %v107302 = vor.u32 %v107301, %v107300 (stack46)
        %v107303 = vxor.u32 %v107302, %v107298 (stack47)
        %v107306 = vadd.s32 %v107303, %v107298 (stack39)
        %v107308 = vshll.u32 %v107303, 29 (stack44)
        %v107309 = vshrl.u32 %v107303, 3 (stack45)
        %v107310 = vor.u32 %v107309, %v107308 (stack46)
        %v107311 = vxor.u32 %v107310, %v107306 (stack47)
        %v107314 = vadd.s32 %v107311, %v107306 (stack39)
        %v107316 = vshll.u32 %v107311, 16 (stack44)
        %v107317 = vshrl.u32 %v107311, 16 (stack45)
        %v107318 = vor.u32 %v107317, %v107316 (stack46)
        %v107319 = vxor.u32 %v107318, %v107314 (stack47)
        %v107322 = vadd.s32 %v107319, %v107314 (stack39)
        %v107326 = vadd.s32 %v107322, %v9 (stack39)
        %v107328 = vshll.u32 %v107319, 24 (stack44)
        %v107329 = vshrl.u32 %v107319, 8 (stack45)
        %v107330 = vor.u32 %v107329, %v107328 (stack46)
        %v107331 = vxor.u32 %v107330, %v107322 (stack47)
        %v107334 = vadd.s32 %v107331, %v8 (stack39)
        %v107338 = vadd.s32 4, %v107334 (stack39)
        %v107342 = vadd.s32 %v107338, %v107326 (stack39)
        %v107344 = vshll.u32 %v107338, 13 (stack44)
        %v107345 = vshrl.u32 %v107338, 19 (stack45)
        %v107346 = vor.u32 %v107345, %v107344 (stack46)
        %v107347 = vxor.u32 %v107346, %v107342 (stack47)
        %v107350 = vadd.s32 %v107347, %v107342 (stack39)
        %v107352 = vshll.u32 %v107347, 15 (stack44)
        %v107353 = vshrl.u32 %v107347, 17 (stack45)
        %v107354 = vor.u32 %v107353, %v107352 (stack46)
        %v107355 = vxor.u32 %v107354, %v107350 (stack47)
        %v107358 = vadd.s32 %v107355, %v107350 (stack39)
        %v107360 = vshll.u32 %v107355, 26 (stack44)
        %v107361 = vshrl.u32 %v107355, 6 (stack45)
        %v107362 = vor.u32 %v107361, %v107360 (stack46)
        %v107363 = vxor.u32 %v107362, %v107358 (stack47)
        %v107366 = vadd.s32 %v107363, %v107358 (stack39)
        %v107370 = vadd.s32 %v107366, %v8 (stack39)
        %v107372 = vshll.u32 %v107363, 6 (stack44)
        %v107373 = vshrl.u32 %v107363, 26 (stack45)
        %v107374 = vor.u32 %v107373, %v107372 (stack46)
        %v107375 = vxor.u32 %v107374, %v107366 (stack47)
        %v107378 = vadd.s32 %v107375, %v10 (stack39)
        %v107382 = vadd.s32 5, %v107378 (stack39)
        %v107384 = vxor.u32 %v107382, %v107370 (stack47)
        %v107385 = vand.u32.u8 255, %v107384 (stack48)
        %v107386 = vand.u32 65535, %v107385 (stack49)
        %v107387 = vshrl.u32 %v107386, 1 (stack50)
        %v107388 = vor.u32 16256, %v107387 (stack46)
        %v107389 = vand.u32.u16 65535, %v107388 (stack51)
        %v120318 = vadd.low.f32.bf16 -1.0, %v107389 (stack52)
        %v107398 = vmul.f32 2.0, %v120318 (stack53)
        %v107402 = vadd.f32 -0.99609375, %v107398 (stack52)
        %v107406 = vmax.f32 %v107402, -0.99609375 (stack54)
        %v107408 = vand.u32 2147483647, %v107406 (stack55)
        %vm107411 = vcmp.eq.f32.partialorder %v107408, 1.0 (stack56)
        %v107416 = vmul.f32 inf, %v107406 (stack53)
        %v107418 = vxor.u32 2147483648, %v107406 (stack57)
        %v107421 = vmul.f32 %v107418, %v107406 (stack53)
        %v107423 = vadd.f32 1.0, %v107421 (stack58)
        %v107424 = vlog2.pop %v107423 (stack59)
        %v107425 = vmul.f32 0.6931472, %v107424 (stack60)
        %v107426 = vmul.f32 -0.5, %v107421 (stack61)
        %v107427 = vadd.f32 1.0, %v107426 (stack62)
        %v107428 = vmul.f32 %v107427, %v107421 (stack63)
        %v107429 = vand.u32 2147483647, %v107421 (stack64)
        %vm107430 = vcmp.lt.f32.partialorder %v107429, 0.0004427343 (stack65)
        %v107431 = vsel /*vm=*/%vm107430, /*on_true_vy=*/%v107428, /*on_false_vx=*/%v107425 (stack66)
        %v107432 = vxor.u32 2147483648, %v107431 (stack57)
        %vm107435 = vcmp.lt.f32.partialorder %v107432, 5.0 (stack56)
        %v107440 = vsel /*vm=*/%vm107435, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v107444 = vsel /*vm=*/%vm107435, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v107448 = vsel /*vm=*/%vm107435, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v107452 = vsel /*vm=*/%vm107435, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v107456 = vsel /*vm=*/%vm107435, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v107460 = vsel /*vm=*/%vm107435, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v107464 = vsel /*vm=*/%vm107435, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v107468 = vsel /*vm=*/%vm107435, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v107472 = vsel /*vm=*/%vm107435, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v107476 = vadd.f32 -2.5, %v107432 (stack52)
        %v107478 = vrsqrt.pop %v107432 (stack67)
        %v107479 = vmul.f32 %v107478, %v107432 (stack68)
        %vm107480 = vcmp.eq.f32.partialorder %v107432, inf (stack69)
        %v107481 = vsel /*vm=*/%vm107480, /*on_true_vy=*/%v107432, /*on_false_vx=*/%v107479 (stack70)
        %vm107482 = vcmp.eq.f32.partialorder %v107432, 0.0 (stack71)
        %v107483 = vand.u32 2147483648, %v107432 (stack72)
        %v107484 = vsel /*vm=*/%vm107482, /*on_true_vy=*/%v107483, /*on_false_vx=*/%v107481 (stack73)
        %v107487 = vadd.f32 -3.0, %v107484 (stack52)
        %v107491 = vsel /*vm=*/%vm107435, /*on_true_vy=*/%v107476, /*on_false_vx=*/%v107487 (stack43)
        %v107495 = vmul.f32 %v107491, %v107472 (stack53)
        %v107499 = vadd.f32 %v107495, %v107468 (stack52)
        %v107503 = vmul.f32 %v107499, %v107491 (stack53)
        %v107507 = vadd.f32 %v107503, %v107464 (stack52)
        %v107511 = vmul.f32 %v107507, %v107491 (stack53)
        %v107515 = vadd.f32 %v107511, %v107460 (stack52)
        %v107519 = vmul.f32 %v107515, %v107491 (stack53)
        %v107523 = vadd.f32 %v107519, %v107456 (stack52)
        %v107527 = vmul.f32 %v107523, %v107491 (stack53)
        %v107531 = vadd.f32 %v107527, %v107452 (stack52)
        %v107535 = vmul.f32 %v107531, %v107491 (stack53)
        %v107539 = vadd.f32 %v107535, %v107448 (stack52)
        %v107543 = vmul.f32 %v107539, %v107491 (stack53)
        %v107547 = vadd.f32 %v107543, %v107444 (stack52)
        %v107551 = vmul.f32 %v107547, %v107491 (stack53)
        %v107555 = vadd.f32 %v107551, %v107440 (stack52)
        %v107559 = vmul.f32 %v107555, %v107406 (stack53)
        %v107563 = vsel /*vm=*/%vm107411, /*on_true_vy=*/%v107416, /*on_false_vx=*/%v107559 (stack43)
        %v107567 = vmul.f32 1.4140625, %v107563 (stack53)
        %v107570 = vpack.c.bf16 0.0, %v107567 (stack74)
        %120319 = vst [vmem:[%s280 + $0x2f0] sm:$0xf] /*vst_source=*/%v107570 (stack75)
        %v107574 = vadd.s32 %v104805, %v3329 (stack39)
        %v107584 = vadd.s32 %v107574, %v415 (stack39)
        %vm107588 = vcmp.lt.u32.totalorder %v107584, %v107574 (stack42)
        %vm107593 = vcmp.lt.u32.totalorder %v107574, %v3329 (stack42)
        %v107598 = vadd.s32 %v104788, %v3316 (stack39)
        %v107602 = vadd.s32 1, %v107598 (stack39)
        %v107606 = vsel /*vm=*/%vm107593, /*on_true_vy=*/%v107602, /*on_false_vx=*/%v107598 (stack43)
        %v107610 = vadd.s32 1, %v107606 (stack39)
        %v107614 = vsel /*vm=*/%vm107588, /*on_true_vy=*/%v107610, /*on_false_vx=*/%v107606 (stack43)
        %v107619 = vadd.s32 %v107614, %v10 (stack39)
        %v107623 = vadd.s32 %v107584, %v9 (stack39)
        %v107627 = vadd.s32 %v107623, %v107619 (stack39)
        %v107629 = vshll.u32 %v107623, 13 (stack44)
        %v107630 = vshrl.u32 %v107623, 19 (stack45)
        %v107631 = vor.u32 %v107630, %v107629 (stack46)
        %v107632 = vxor.u32 %v107631, %v107627 (stack47)
        %v107635 = vadd.s32 %v107632, %v107627 (stack39)
        %v107637 = vshll.u32 %v107632, 15 (stack44)
        %v107638 = vshrl.u32 %v107632, 17 (stack45)
        %v107639 = vor.u32 %v107638, %v107637 (stack46)
        %v107640 = vxor.u32 %v107639, %v107635 (stack47)
        %v107643 = vadd.s32 %v107640, %v107635 (stack39)
        %v107645 = vshll.u32 %v107640, 26 (stack44)
        %v107646 = vshrl.u32 %v107640, 6 (stack45)
        %v107647 = vor.u32 %v107646, %v107645 (stack46)
        %v107648 = vxor.u32 %v107647, %v107643 (stack47)
        %v107651 = vadd.s32 %v107648, %v107643 (stack39)
        %v107655 = vadd.s32 %v107651, %v9 (stack39)
        %v107657 = vshll.u32 %v107648, 6 (stack44)
        %v107658 = vshrl.u32 %v107648, 26 (stack45)
        %v107659 = vor.u32 %v107658, %v107657 (stack46)
        %v107660 = vxor.u32 %v107659, %v107651 (stack47)
        %v107663 = vadd.s32 %v107660, %v8 (stack39)
        %v107667 = vadd.s32 1, %v107663 (stack39)
        %v107671 = vadd.s32 %v107667, %v107655 (stack39)
        %v107673 = vshll.u32 %v107667, 17 (stack44)
        %v107674 = vshrl.u32 %v107667, 15 (stack45)
        %v107675 = vor.u32 %v107674, %v107673 (stack46)
        %v107676 = vxor.u32 %v107675, %v107671 (stack47)
        %v107679 = vadd.s32 %v107676, %v107671 (stack39)
        %v107681 = vshll.u32 %v107676, 29 (stack44)
        %v107682 = vshrl.u32 %v107676, 3 (stack45)
        %v107683 = vor.u32 %v107682, %v107681 (stack46)
        %v107684 = vxor.u32 %v107683, %v107679 (stack47)
        %v107687 = vadd.s32 %v107684, %v107679 (stack39)
        %v107689 = vshll.u32 %v107684, 16 (stack44)
        %v107690 = vshrl.u32 %v107684, 16 (stack45)
        %v107691 = vor.u32 %v107690, %v107689 (stack46)
        %v107692 = vxor.u32 %v107691, %v107687 (stack47)
        %v107695 = vadd.s32 %v107692, %v107687 (stack39)
        %v107699 = vadd.s32 %v107695, %v8 (stack39)
        %v107701 = vshll.u32 %v107692, 24 (stack44)
        %v107702 = vshrl.u32 %v107692, 8 (stack45)
        %v107703 = vor.u32 %v107702, %v107701 (stack46)
        %v107704 = vxor.u32 %v107703, %v107695 (stack47)
        %v107707 = vadd.s32 %v107704, %v10 (stack39)
        %v107711 = vadd.s32 2, %v107707 (stack39)
        %v107715 = vadd.s32 %v107711, %v107699 (stack39)
        %v107717 = vshll.u32 %v107711, 13 (stack44)
        %v107718 = vshrl.u32 %v107711, 19 (stack45)
        %v107719 = vor.u32 %v107718, %v107717 (stack46)
        %v107720 = vxor.u32 %v107719, %v107715 (stack47)
        %v107723 = vadd.s32 %v107720, %v107715 (stack39)
        %v107725 = vshll.u32 %v107720, 15 (stack44)
        %v107726 = vshrl.u32 %v107720, 17 (stack45)
        %v107727 = vor.u32 %v107726, %v107725 (stack46)
        %v107728 = vxor.u32 %v107727, %v107723 (stack47)
        %v107731 = vadd.s32 %v107728, %v107723 (stack39)
        %v107733 = vshll.u32 %v107728, 26 (stack44)
        %v107734 = vshrl.u32 %v107728, 6 (stack45)
        %v107735 = vor.u32 %v107734, %v107733 (stack46)
        %v107736 = vxor.u32 %v107735, %v107731 (stack47)
        %v107739 = vadd.s32 %v107736, %v107731 (stack39)
        %v107743 = vadd.s32 %v107739, %v10 (stack39)
        %v107745 = vshll.u32 %v107736, 6 (stack44)
        %v107746 = vshrl.u32 %v107736, 26 (stack45)
        %v107747 = vor.u32 %v107746, %v107745 (stack46)
        %v107748 = vxor.u32 %v107747, %v107739 (stack47)
        %v107751 = vadd.s32 %v107748, %v9 (stack39)
        %v107755 = vadd.s32 3, %v107751 (stack39)
        %v107759 = vadd.s32 %v107755, %v107743 (stack39)
        %v107761 = vshll.u32 %v107755, 17 (stack44)
        %v107762 = vshrl.u32 %v107755, 15 (stack45)
        %v107763 = vor.u32 %v107762, %v107761 (stack46)
        %v107764 = vxor.u32 %v107763, %v107759 (stack47)
        %v107767 = vadd.s32 %v107764, %v107759 (stack39)
        %v107769 = vshll.u32 %v107764, 29 (stack44)
        %v107770 = vshrl.u32 %v107764, 3 (stack45)
        %v107771 = vor.u32 %v107770, %v107769 (stack46)
        %v107772 = vxor.u32 %v107771, %v107767 (stack47)
        %v107775 = vadd.s32 %v107772, %v107767 (stack39)
        %v107777 = vshll.u32 %v107772, 16 (stack44)
        %v107778 = vshrl.u32 %v107772, 16 (stack45)
        %v107779 = vor.u32 %v107778, %v107777 (stack46)
        %v107780 = vxor.u32 %v107779, %v107775 (stack47)
        %v107783 = vadd.s32 %v107780, %v107775 (stack39)
        %v107787 = vadd.s32 %v107783, %v9 (stack39)
        %v107789 = vshll.u32 %v107780, 24 (stack44)
        %v107790 = vshrl.u32 %v107780, 8 (stack45)
        %v107791 = vor.u32 %v107790, %v107789 (stack46)
        %v107792 = vxor.u32 %v107791, %v107783 (stack47)
        %v107795 = vadd.s32 %v107792, %v8 (stack39)
        %v107799 = vadd.s32 4, %v107795 (stack39)
        %v107803 = vadd.s32 %v107799, %v107787 (stack39)
        %v107805 = vshll.u32 %v107799, 13 (stack44)
        %v107806 = vshrl.u32 %v107799, 19 (stack45)
        %v107807 = vor.u32 %v107806, %v107805 (stack46)
        %v107808 = vxor.u32 %v107807, %v107803 (stack47)
        %v107811 = vadd.s32 %v107808, %v107803 (stack39)
        %v107813 = vshll.u32 %v107808, 15 (stack44)
        %v107814 = vshrl.u32 %v107808, 17 (stack45)
        %v107815 = vor.u32 %v107814, %v107813 (stack46)
        %v107816 = vxor.u32 %v107815, %v107811 (stack47)
        %v107819 = vadd.s32 %v107816, %v107811 (stack39)
        %v107821 = vshll.u32 %v107816, 26 (stack44)
        %v107822 = vshrl.u32 %v107816, 6 (stack45)
        %v107823 = vor.u32 %v107822, %v107821 (stack46)
        %v107824 = vxor.u32 %v107823, %v107819 (stack47)
        %v107827 = vadd.s32 %v107824, %v107819 (stack39)
        %v107831 = vadd.s32 %v107827, %v8 (stack39)
        %v107833 = vshll.u32 %v107824, 6 (stack44)
        %v107834 = vshrl.u32 %v107824, 26 (stack45)
        %v107835 = vor.u32 %v107834, %v107833 (stack46)
        %v107836 = vxor.u32 %v107835, %v107827 (stack47)
        %v107839 = vadd.s32 %v107836, %v10 (stack39)
        %v107843 = vadd.s32 5, %v107839 (stack39)
        %v107845 = vxor.u32 %v107843, %v107831 (stack47)
        %v107846 = vand.u32.u8 255, %v107845 (stack48)
        %v107847 = vand.u32 65535, %v107846 (stack49)
        %v107848 = vshrl.u32 %v107847, 1 (stack50)
        %v107849 = vor.u32 16256, %v107848 (stack46)
        %v107850 = vand.u32.u16 65535, %v107849 (stack51)
        %v120320 = vadd.low.f32.bf16 -1.0, %v107850 (stack52)
        %v107859 = vmul.f32 2.0, %v120320 (stack53)
        %v107863 = vadd.f32 -0.99609375, %v107859 (stack52)
        %v107867 = vmax.f32 %v107863, -0.99609375 (stack54)
        %v107869 = vand.u32 2147483647, %v107867 (stack55)
        %vm107872 = vcmp.eq.f32.partialorder %v107869, 1.0 (stack56)
        %v107877 = vmul.f32 inf, %v107867 (stack53)
        %v107879 = vxor.u32 2147483648, %v107867 (stack57)
        %v107882 = vmul.f32 %v107879, %v107867 (stack53)
        %v107884 = vadd.f32 1.0, %v107882 (stack58)
        %v107885 = vlog2.pop %v107884 (stack59)
        %v107886 = vmul.f32 0.6931472, %v107885 (stack60)
        %v107887 = vmul.f32 -0.5, %v107882 (stack61)
        %v107888 = vadd.f32 1.0, %v107887 (stack62)
        %v107889 = vmul.f32 %v107888, %v107882 (stack63)
        %v107890 = vand.u32 2147483647, %v107882 (stack64)
        %vm107891 = vcmp.lt.f32.partialorder %v107890, 0.0004427343 (stack65)
        %v107892 = vsel /*vm=*/%vm107891, /*on_true_vy=*/%v107889, /*on_false_vx=*/%v107886 (stack66)
        %v107893 = vxor.u32 2147483648, %v107892 (stack57)
        %vm107896 = vcmp.lt.f32.partialorder %v107893, 5.0 (stack56)
        %v107901 = vsel /*vm=*/%vm107896, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v107905 = vsel /*vm=*/%vm107896, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v107909 = vsel /*vm=*/%vm107896, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v107913 = vsel /*vm=*/%vm107896, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v107917 = vsel /*vm=*/%vm107896, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v107921 = vsel /*vm=*/%vm107896, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v107925 = vsel /*vm=*/%vm107896, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v107929 = vsel /*vm=*/%vm107896, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v107933 = vsel /*vm=*/%vm107896, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v107937 = vadd.f32 -2.5, %v107893 (stack52)
        %v107939 = vrsqrt.pop %v107893 (stack67)
        %v107940 = vmul.f32 %v107939, %v107893 (stack68)
        %vm107941 = vcmp.eq.f32.partialorder %v107893, inf (stack69)
        %v107942 = vsel /*vm=*/%vm107941, /*on_true_vy=*/%v107893, /*on_false_vx=*/%v107940 (stack70)
        %vm107943 = vcmp.eq.f32.partialorder %v107893, 0.0 (stack71)
        %v107944 = vand.u32 2147483648, %v107893 (stack72)
        %v107945 = vsel /*vm=*/%vm107943, /*on_true_vy=*/%v107944, /*on_false_vx=*/%v107942 (stack73)
        %v107948 = vadd.f32 -3.0, %v107945 (stack52)
        %v107952 = vsel /*vm=*/%vm107896, /*on_true_vy=*/%v107937, /*on_false_vx=*/%v107948 (stack43)
        %v107956 = vmul.f32 %v107952, %v107933 (stack53)
        %v107960 = vadd.f32 %v107956, %v107929 (stack52)
        %v107964 = vmul.f32 %v107960, %v107952 (stack53)
        %v107968 = vadd.f32 %v107964, %v107925 (stack52)
        %v107972 = vmul.f32 %v107968, %v107952 (stack53)
        %v107976 = vadd.f32 %v107972, %v107921 (stack52)
        %v107980 = vmul.f32 %v107976, %v107952 (stack53)
        %v107984 = vadd.f32 %v107980, %v107917 (stack52)
        %v107988 = vmul.f32 %v107984, %v107952 (stack53)
        %v107992 = vadd.f32 %v107988, %v107913 (stack52)
        %v107996 = vmul.f32 %v107992, %v107952 (stack53)
        %v108000 = vadd.f32 %v107996, %v107909 (stack52)
        %v108004 = vmul.f32 %v108000, %v107952 (stack53)
        %v108008 = vadd.f32 %v108004, %v107905 (stack52)
        %v108012 = vmul.f32 %v108008, %v107952 (stack53)
        %v108016 = vadd.f32 %v108012, %v107901 (stack52)
        %v108020 = vmul.f32 %v108016, %v107867 (stack53)
        %v108024 = vsel /*vm=*/%vm107872, /*on_true_vy=*/%v107877, /*on_false_vx=*/%v108020 (stack43)
        %v108028 = vmul.f32 1.4140625, %v108024 (stack53)
        %v108031 = vpack.c.bf16 0.0, %v108028 (stack74)
        %120321 = vst [vmem:[%s280 + $0x370] sm:$0xf] /*vst_source=*/%v108031 (stack75)
        %v108035 = vadd.s32 %v104805, %v3816 (stack39)
        %v108045 = vadd.s32 %v108035, %v415 (stack39)
        %vm108049 = vcmp.lt.u32.totalorder %v108045, %v108035 (stack42)
        %vm108054 = vcmp.lt.u32.totalorder %v108035, %v3816 (stack42)
        %v108059 = vadd.s32 %v104788, %v3803 (stack39)
        %v108063 = vadd.s32 1, %v108059 (stack39)
        %v108067 = vsel /*vm=*/%vm108054, /*on_true_vy=*/%v108063, /*on_false_vx=*/%v108059 (stack43)
        %v108071 = vadd.s32 1, %v108067 (stack39)
        %v108075 = vsel /*vm=*/%vm108049, /*on_true_vy=*/%v108071, /*on_false_vx=*/%v108067 (stack43)
        %v108080 = vadd.s32 %v108075, %v10 (stack39)
        %v108084 = vadd.s32 %v108045, %v9 (stack39)
        %v108088 = vadd.s32 %v108084, %v108080 (stack39)
        %v108090 = vshll.u32 %v108084, 13 (stack44)
        %v108091 = vshrl.u32 %v108084, 19 (stack45)
        %v108092 = vor.u32 %v108091, %v108090 (stack46)
        %v108093 = vxor.u32 %v108092, %v108088 (stack47)
        %v108096 = vadd.s32 %v108093, %v108088 (stack39)
        %v108098 = vshll.u32 %v108093, 15 (stack44)
        %v108099 = vshrl.u32 %v108093, 17 (stack45)
        %v108100 = vor.u32 %v108099, %v108098 (stack46)
        %v108101 = vxor.u32 %v108100, %v108096 (stack47)
        %v108104 = vadd.s32 %v108101, %v108096 (stack39)
        %v108106 = vshll.u32 %v108101, 26 (stack44)
        %v108107 = vshrl.u32 %v108101, 6 (stack45)
        %v108108 = vor.u32 %v108107, %v108106 (stack46)
        %v108109 = vxor.u32 %v108108, %v108104 (stack47)
        %v108112 = vadd.s32 %v108109, %v108104 (stack39)
        %v108116 = vadd.s32 %v108112, %v9 (stack39)
        %v108118 = vshll.u32 %v108109, 6 (stack44)
        %v108119 = vshrl.u32 %v108109, 26 (stack45)
        %v108120 = vor.u32 %v108119, %v108118 (stack46)
        %v108121 = vxor.u32 %v108120, %v108112 (stack47)
        %v108124 = vadd.s32 %v108121, %v8 (stack39)
        %v108128 = vadd.s32 1, %v108124 (stack39)
        %v108132 = vadd.s32 %v108128, %v108116 (stack39)
        %v108134 = vshll.u32 %v108128, 17 (stack44)
        %v108135 = vshrl.u32 %v108128, 15 (stack45)
        %v108136 = vor.u32 %v108135, %v108134 (stack46)
        %v108137 = vxor.u32 %v108136, %v108132 (stack47)
        %v108140 = vadd.s32 %v108137, %v108132 (stack39)
        %v108142 = vshll.u32 %v108137, 29 (stack44)
        %v108143 = vshrl.u32 %v108137, 3 (stack45)
        %v108144 = vor.u32 %v108143, %v108142 (stack46)
        %v108145 = vxor.u32 %v108144, %v108140 (stack47)
        %v108148 = vadd.s32 %v108145, %v108140 (stack39)
        %v108150 = vshll.u32 %v108145, 16 (stack44)
        %v108151 = vshrl.u32 %v108145, 16 (stack45)
        %v108152 = vor.u32 %v108151, %v108150 (stack46)
        %v108153 = vxor.u32 %v108152, %v108148 (stack47)
        %v108156 = vadd.s32 %v108153, %v108148 (stack39)
        %v108160 = vadd.s32 %v108156, %v8 (stack39)
        %v108162 = vshll.u32 %v108153, 24 (stack44)
        %v108163 = vshrl.u32 %v108153, 8 (stack45)
        %v108164 = vor.u32 %v108163, %v108162 (stack46)
        %v108165 = vxor.u32 %v108164, %v108156 (stack47)
        %v108168 = vadd.s32 %v108165, %v10 (stack39)
        %v108172 = vadd.s32 2, %v108168 (stack39)
        %v108176 = vadd.s32 %v108172, %v108160 (stack39)
        %v108178 = vshll.u32 %v108172, 13 (stack44)
        %v108179 = vshrl.u32 %v108172, 19 (stack45)
        %v108180 = vor.u32 %v108179, %v108178 (stack46)
        %v108181 = vxor.u32 %v108180, %v108176 (stack47)
        %v108184 = vadd.s32 %v108181, %v108176 (stack39)
        %v108186 = vshll.u32 %v108181, 15 (stack44)
        %v108187 = vshrl.u32 %v108181, 17 (stack45)
        %v108188 = vor.u32 %v108187, %v108186 (stack46)
        %v108189 = vxor.u32 %v108188, %v108184 (stack47)
        %v108192 = vadd.s32 %v108189, %v108184 (stack39)
        %v108194 = vshll.u32 %v108189, 26 (stack44)
        %v108195 = vshrl.u32 %v108189, 6 (stack45)
        %v108196 = vor.u32 %v108195, %v108194 (stack46)
        %v108197 = vxor.u32 %v108196, %v108192 (stack47)
        %v108200 = vadd.s32 %v108197, %v108192 (stack39)
        %v108204 = vadd.s32 %v108200, %v10 (stack39)
        %v108206 = vshll.u32 %v108197, 6 (stack44)
        %v108207 = vshrl.u32 %v108197, 26 (stack45)
        %v108208 = vor.u32 %v108207, %v108206 (stack46)
        %v108209 = vxor.u32 %v108208, %v108200 (stack47)
        %v108212 = vadd.s32 %v108209, %v9 (stack39)
        %v108216 = vadd.s32 3, %v108212 (stack39)
        %v108220 = vadd.s32 %v108216, %v108204 (stack39)
        %v108222 = vshll.u32 %v108216, 17 (stack44)
        %v108223 = vshrl.u32 %v108216, 15 (stack45)
        %v108224 = vor.u32 %v108223, %v108222 (stack46)
        %v108225 = vxor.u32 %v108224, %v108220 (stack47)
        %v108228 = vadd.s32 %v108225, %v108220 (stack39)
        %v108230 = vshll.u32 %v108225, 29 (stack44)
        %v108231 = vshrl.u32 %v108225, 3 (stack45)
        %v108232 = vor.u32 %v108231, %v108230 (stack46)
        %v108233 = vxor.u32 %v108232, %v108228 (stack47)
        %v108236 = vadd.s32 %v108233, %v108228 (stack39)
        %v108238 = vshll.u32 %v108233, 16 (stack44)
        %v108239 = vshrl.u32 %v108233, 16 (stack45)
        %v108240 = vor.u32 %v108239, %v108238 (stack46)
        %v108241 = vxor.u32 %v108240, %v108236 (stack47)
        %v108244 = vadd.s32 %v108241, %v108236 (stack39)
        %v108248 = vadd.s32 %v108244, %v9 (stack39)
        %v108250 = vshll.u32 %v108241, 24 (stack44)
        %v108251 = vshrl.u32 %v108241, 8 (stack45)
        %v108252 = vor.u32 %v108251, %v108250 (stack46)
        %v108253 = vxor.u32 %v108252, %v108244 (stack47)
        %v108256 = vadd.s32 %v108253, %v8 (stack39)
        %v108260 = vadd.s32 4, %v108256 (stack39)
        %v108264 = vadd.s32 %v108260, %v108248 (stack39)
        %v108266 = vshll.u32 %v108260, 13 (stack44)
        %v108267 = vshrl.u32 %v108260, 19 (stack45)
        %v108268 = vor.u32 %v108267, %v108266 (stack46)
        %v108269 = vxor.u32 %v108268, %v108264 (stack47)
        %v108272 = vadd.s32 %v108269, %v108264 (stack39)
        %v108274 = vshll.u32 %v108269, 15 (stack44)
        %v108275 = vshrl.u32 %v108269, 17 (stack45)
        %v108276 = vor.u32 %v108275, %v108274 (stack46)
        %v108277 = vxor.u32 %v108276, %v108272 (stack47)
        %v108280 = vadd.s32 %v108277, %v108272 (stack39)
        %v108282 = vshll.u32 %v108277, 26 (stack44)
        %v108283 = vshrl.u32 %v108277, 6 (stack45)
        %v108284 = vor.u32 %v108283, %v108282 (stack46)
        %v108285 = vxor.u32 %v108284, %v108280 (stack47)
        %v108288 = vadd.s32 %v108285, %v108280 (stack39)
        %v108292 = vadd.s32 %v108288, %v8 (stack39)
        %v108294 = vshll.u32 %v108285, 6 (stack44)
        %v108295 = vshrl.u32 %v108285, 26 (stack45)
        %v108296 = vor.u32 %v108295, %v108294 (stack46)
        %v108297 = vxor.u32 %v108296, %v108288 (stack47)
        %v108300 = vadd.s32 %v108297, %v10 (stack39)
        %v108304 = vadd.s32 5, %v108300 (stack39)
        %v108306 = vxor.u32 %v108304, %v108292 (stack47)
        %v108307 = vand.u32.u8 255, %v108306 (stack48)
        %v108308 = vand.u32 65535, %v108307 (stack49)
        %v108309 = vshrl.u32 %v108308, 1 (stack50)
        %v108310 = vor.u32 16256, %v108309 (stack46)
        %v108311 = vand.u32.u16 65535, %v108310 (stack51)
        %v120322 = vadd.low.f32.bf16 -1.0, %v108311 (stack52)
        %v108320 = vmul.f32 2.0, %v120322 (stack53)
        %v108324 = vadd.f32 -0.99609375, %v108320 (stack52)
        %v108328 = vmax.f32 %v108324, -0.99609375 (stack54)
        %v108330 = vand.u32 2147483647, %v108328 (stack55)
        %vm108333 = vcmp.eq.f32.partialorder %v108330, 1.0 (stack56)
        %v108338 = vmul.f32 inf, %v108328 (stack53)
        %v108340 = vxor.u32 2147483648, %v108328 (stack57)
        %v108343 = vmul.f32 %v108340, %v108328 (stack53)
        %v108345 = vadd.f32 1.0, %v108343 (stack58)
        %v108346 = vlog2.pop %v108345 (stack59)
        %v108347 = vmul.f32 0.6931472, %v108346 (stack60)
        %v108348 = vmul.f32 -0.5, %v108343 (stack61)
        %v108349 = vadd.f32 1.0, %v108348 (stack62)
        %v108350 = vmul.f32 %v108349, %v108343 (stack63)
        %v108351 = vand.u32 2147483647, %v108343 (stack64)
        %vm108352 = vcmp.lt.f32.partialorder %v108351, 0.0004427343 (stack65)
        %v108353 = vsel /*vm=*/%vm108352, /*on_true_vy=*/%v108350, /*on_false_vx=*/%v108347 (stack66)
        %v108354 = vxor.u32 2147483648, %v108353 (stack57)
        %vm108357 = vcmp.lt.f32.partialorder %v108354, 5.0 (stack56)
        %v108362 = vsel /*vm=*/%vm108357, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v108366 = vsel /*vm=*/%vm108357, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v108370 = vsel /*vm=*/%vm108357, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v108374 = vsel /*vm=*/%vm108357, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v108378 = vsel /*vm=*/%vm108357, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v108382 = vsel /*vm=*/%vm108357, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v108386 = vsel /*vm=*/%vm108357, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v108390 = vsel /*vm=*/%vm108357, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v108394 = vsel /*vm=*/%vm108357, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v108398 = vadd.f32 -2.5, %v108354 (stack52)
        %v108400 = vrsqrt.pop %v108354 (stack67)
        %v108401 = vmul.f32 %v108400, %v108354 (stack68)
        %vm108402 = vcmp.eq.f32.partialorder %v108354, inf (stack69)
        %v108403 = vsel /*vm=*/%vm108402, /*on_true_vy=*/%v108354, /*on_false_vx=*/%v108401 (stack70)
        %vm108404 = vcmp.eq.f32.partialorder %v108354, 0.0 (stack71)
        %v108405 = vand.u32 2147483648, %v108354 (stack72)
        %v108406 = vsel /*vm=*/%vm108404, /*on_true_vy=*/%v108405, /*on_false_vx=*/%v108403 (stack73)
        %v108409 = vadd.f32 -3.0, %v108406 (stack52)
        %v108413 = vsel /*vm=*/%vm108357, /*on_true_vy=*/%v108398, /*on_false_vx=*/%v108409 (stack43)
        %v108417 = vmul.f32 %v108413, %v108394 (stack53)
        %v108421 = vadd.f32 %v108417, %v108390 (stack52)
        %v108425 = vmul.f32 %v108421, %v108413 (stack53)
        %v108429 = vadd.f32 %v108425, %v108386 (stack52)
        %v108433 = vmul.f32 %v108429, %v108413 (stack53)
        %v108437 = vadd.f32 %v108433, %v108382 (stack52)
        %v108441 = vmul.f32 %v108437, %v108413 (stack53)
        %v108445 = vadd.f32 %v108441, %v108378 (stack52)
        %v108449 = vmul.f32 %v108445, %v108413 (stack53)
        %v108453 = vadd.f32 %v108449, %v108374 (stack52)
        %v108457 = vmul.f32 %v108453, %v108413 (stack53)
        %v108461 = vadd.f32 %v108457, %v108370 (stack52)
        %v108465 = vmul.f32 %v108461, %v108413 (stack53)
        %v108469 = vadd.f32 %v108465, %v108366 (stack52)
        %v108473 = vmul.f32 %v108469, %v108413 (stack53)
        %v108477 = vadd.f32 %v108473, %v108362 (stack52)
        %v108481 = vmul.f32 %v108477, %v108328 (stack53)
        %v108485 = vsel /*vm=*/%vm108333, /*on_true_vy=*/%v108338, /*on_false_vx=*/%v108481 (stack43)
        %v108489 = vmul.f32 1.4140625, %v108485 (stack53)
        %v108492 = vpack.c.bf16 0.0, %v108489 (stack74)
        %120323 = vst [vmem:[%s280 + $0x3f0] sm:$0xf] /*vst_source=*/%v108492 (stack75)
        %s108494 = sadd.s32 232, %s120390 (stack76)
        %s108495 = sshrl.u32 %s108494, 10 (stack23)
        %p120324 = scmp.gt.s32.totalorder %s108495, 1 (stack24)
        %s108497 = scalar_select /*predicate=*/%p120324, /*on_true=*/1, /*on_false=*/%s108495 (stack25)
        %s108498 = sand.u32 1023, %s108494 /* smod.u32 w/div 1024 */ (stack26)
        %s108499 = sshrl.u32 %s108498, 7 (stack27)
        %s108500 = sand.u32 127, %s108498 /* smod.u32 w/div 128 */ (stack28)
        %s120325 = sshll.u32 %s108497, 3 (stack29)
        %s108502 = scalar_lea.vmem %s3, %s120325 (stack30)
        %s108504 = scalar_lea.vmem %s108502, %s108499 (stack31)
        %v108505 = vld [vmem:[%s108504] ss:$0 sm:$0xff] (stack32)
        %s108506 = sand.u32 255, %s108500 (stack33)
        %s108508 = sor.u32 256, %s108506 (stack34)
        %108509 = vbcast.lane.b32.xlu0 %v108505, %s108508 (stack35)
        %v108510 = vpop.permute.xlu0 %108509 (stack36)
        %s108519 = scalar_lea.vmem %s5, %s120325 (stack30)
        %s108521 = scalar_lea.vmem %s108519, %s108499 (stack31)
        %v108522 = vld [vmem:[%s108521] ss:$0 sm:$0xff] (stack32)
        %108526 = vbcast.lane.b32.xlu0 %v108522, %s108508 (stack35)
        %v108527 = vpop.permute.xlu0 %108526 (stack36)
        %v108530 = vadd.s32 %v108527, %v408 (stack39)
        %v108540 = vadd.s32 %v108530, %v415 (stack39)
        %vm108544 = vcmp.lt.u32.totalorder %v108540, %v108530 (stack42)
        %vm108549 = vcmp.lt.u32.totalorder %v108530, %v408 (stack42)
        %v108554 = vadd.s32 %v108510, %v380 (stack39)
        %v108558 = vadd.s32 1, %v108554 (stack39)
        %v108562 = vsel /*vm=*/%vm108549, /*on_true_vy=*/%v108558, /*on_false_vx=*/%v108554 (stack43)
        %v108566 = vadd.s32 1, %v108562 (stack39)
        %v108570 = vsel /*vm=*/%vm108544, /*on_true_vy=*/%v108566, /*on_false_vx=*/%v108562 (stack43)
        %v108575 = vadd.s32 %v108570, %v10 (stack39)
        %v108579 = vadd.s32 %v108540, %v9 (stack39)
        %v108583 = vadd.s32 %v108579, %v108575 (stack39)
        %v108585 = vshll.u32 %v108579, 13 (stack44)
        %v108586 = vshrl.u32 %v108579, 19 (stack45)
        %v108587 = vor.u32 %v108586, %v108585 (stack46)
        %v108588 = vxor.u32 %v108587, %v108583 (stack47)
        %v108591 = vadd.s32 %v108588, %v108583 (stack39)
        %v108593 = vshll.u32 %v108588, 15 (stack44)
        %v108594 = vshrl.u32 %v108588, 17 (stack45)
        %v108595 = vor.u32 %v108594, %v108593 (stack46)
        %v108596 = vxor.u32 %v108595, %v108591 (stack47)
        %v108599 = vadd.s32 %v108596, %v108591 (stack39)
        %v108601 = vshll.u32 %v108596, 26 (stack44)
        %v108602 = vshrl.u32 %v108596, 6 (stack45)
        %v108603 = vor.u32 %v108602, %v108601 (stack46)
        %v108604 = vxor.u32 %v108603, %v108599 (stack47)
        %v108607 = vadd.s32 %v108604, %v108599 (stack39)
        %v108611 = vadd.s32 %v108607, %v9 (stack39)
        %v108613 = vshll.u32 %v108604, 6 (stack44)
        %v108614 = vshrl.u32 %v108604, 26 (stack45)
        %v108615 = vor.u32 %v108614, %v108613 (stack46)
        %v108616 = vxor.u32 %v108615, %v108607 (stack47)
        %v108619 = vadd.s32 %v108616, %v8 (stack39)
        %v108623 = vadd.s32 1, %v108619 (stack39)
        %v108627 = vadd.s32 %v108623, %v108611 (stack39)
        %v108629 = vshll.u32 %v108623, 17 (stack44)
        %v108630 = vshrl.u32 %v108623, 15 (stack45)
        %v108631 = vor.u32 %v108630, %v108629 (stack46)
        %v108632 = vxor.u32 %v108631, %v108627 (stack47)
        %v108635 = vadd.s32 %v108632, %v108627 (stack39)
        %v108637 = vshll.u32 %v108632, 29 (stack44)
        %v108638 = vshrl.u32 %v108632, 3 (stack45)
        %v108639 = vor.u32 %v108638, %v108637 (stack46)
        %v108640 = vxor.u32 %v108639, %v108635 (stack47)
        %v108643 = vadd.s32 %v108640, %v108635 (stack39)
        %v108645 = vshll.u32 %v108640, 16 (stack44)
        %v108646 = vshrl.u32 %v108640, 16 (stack45)
        %v108647 = vor.u32 %v108646, %v108645 (stack46)
        %v108648 = vxor.u32 %v108647, %v108643 (stack47)
        %v108651 = vadd.s32 %v108648, %v108643 (stack39)
        %v108655 = vadd.s32 %v108651, %v8 (stack39)
        %v108657 = vshll.u32 %v108648, 24 (stack44)
        %v108658 = vshrl.u32 %v108648, 8 (stack45)
        %v108659 = vor.u32 %v108658, %v108657 (stack46)
        %v108660 = vxor.u32 %v108659, %v108651 (stack47)
        %v108663 = vadd.s32 %v108660, %v10 (stack39)
        %v108667 = vadd.s32 2, %v108663 (stack39)
        %v108671 = vadd.s32 %v108667, %v108655 (stack39)
        %v108673 = vshll.u32 %v108667, 13 (stack44)
        %v108674 = vshrl.u32 %v108667, 19 (stack45)
        %v108675 = vor.u32 %v108674, %v108673 (stack46)
        %v108676 = vxor.u32 %v108675, %v108671 (stack47)
        %v108679 = vadd.s32 %v108676, %v108671 (stack39)
        %v108681 = vshll.u32 %v108676, 15 (stack44)
        %v108682 = vshrl.u32 %v108676, 17 (stack45)
        %v108683 = vor.u32 %v108682, %v108681 (stack46)
        %v108684 = vxor.u32 %v108683, %v108679 (stack47)
        %v108687 = vadd.s32 %v108684, %v108679 (stack39)
        %v108689 = vshll.u32 %v108684, 26 (stack44)
        %v108690 = vshrl.u32 %v108684, 6 (stack45)
        %v108691 = vor.u32 %v108690, %v108689 (stack46)
        %v108692 = vxor.u32 %v108691, %v108687 (stack47)
        %v108695 = vadd.s32 %v108692, %v108687 (stack39)
        %v108699 = vadd.s32 %v108695, %v10 (stack39)
        %v108701 = vshll.u32 %v108692, 6 (stack44)
        %v108702 = vshrl.u32 %v108692, 26 (stack45)
        %v108703 = vor.u32 %v108702, %v108701 (stack46)
        %v108704 = vxor.u32 %v108703, %v108695 (stack47)
        %v108707 = vadd.s32 %v108704, %v9 (stack39)
        %v108711 = vadd.s32 3, %v108707 (stack39)
        %v108715 = vadd.s32 %v108711, %v108699 (stack39)
        %v108717 = vshll.u32 %v108711, 17 (stack44)
        %v108718 = vshrl.u32 %v108711, 15 (stack45)
        %v108719 = vor.u32 %v108718, %v108717 (stack46)
        %v108720 = vxor.u32 %v108719, %v108715 (stack47)
        %v108723 = vadd.s32 %v108720, %v108715 (stack39)
        %v108725 = vshll.u32 %v108720, 29 (stack44)
        %v108726 = vshrl.u32 %v108720, 3 (stack45)
        %v108727 = vor.u32 %v108726, %v108725 (stack46)
        %v108728 = vxor.u32 %v108727, %v108723 (stack47)
        %v108731 = vadd.s32 %v108728, %v108723 (stack39)
        %v108733 = vshll.u32 %v108728, 16 (stack44)
        %v108734 = vshrl.u32 %v108728, 16 (stack45)
        %v108735 = vor.u32 %v108734, %v108733 (stack46)
        %v108736 = vxor.u32 %v108735, %v108731 (stack47)
        %v108739 = vadd.s32 %v108736, %v108731 (stack39)
        %v108743 = vadd.s32 %v108739, %v9 (stack39)
        %v108745 = vshll.u32 %v108736, 24 (stack44)
        %v108746 = vshrl.u32 %v108736, 8 (stack45)
        %v108747 = vor.u32 %v108746, %v108745 (stack46)
        %v108748 = vxor.u32 %v108747, %v108739 (stack47)
        %v108751 = vadd.s32 %v108748, %v8 (stack39)
        %v108755 = vadd.s32 4, %v108751 (stack39)
        %v108759 = vadd.s32 %v108755, %v108743 (stack39)
        %v108761 = vshll.u32 %v108755, 13 (stack44)
        %v108762 = vshrl.u32 %v108755, 19 (stack45)
        %v108763 = vor.u32 %v108762, %v108761 (stack46)
        %v108764 = vxor.u32 %v108763, %v108759 (stack47)
        %v108767 = vadd.s32 %v108764, %v108759 (stack39)
        %v108769 = vshll.u32 %v108764, 15 (stack44)
        %v108770 = vshrl.u32 %v108764, 17 (stack45)
        %v108771 = vor.u32 %v108770, %v108769 (stack46)
        %v108772 = vxor.u32 %v108771, %v108767 (stack47)
        %v108775 = vadd.s32 %v108772, %v108767 (stack39)
        %v108777 = vshll.u32 %v108772, 26 (stack44)
        %v108778 = vshrl.u32 %v108772, 6 (stack45)
        %v108779 = vor.u32 %v108778, %v108777 (stack46)
        %v108780 = vxor.u32 %v108779, %v108775 (stack47)
        %v108783 = vadd.s32 %v108780, %v108775 (stack39)
        %v108787 = vadd.s32 %v108783, %v8 (stack39)
        %v108789 = vshll.u32 %v108780, 6 (stack44)
        %v108790 = vshrl.u32 %v108780, 26 (stack45)
        %v108791 = vor.u32 %v108790, %v108789 (stack46)
        %v108792 = vxor.u32 %v108791, %v108783 (stack47)
        %v108795 = vadd.s32 %v108792, %v10 (stack39)
        %v108799 = vadd.s32 5, %v108795 (stack39)
        %v108801 = vxor.u32 %v108799, %v108787 (stack47)
        %v108802 = vand.u32.u8 255, %v108801 (stack48)
        %v108803 = vand.u32 65535, %v108802 (stack49)
        %v108804 = vshrl.u32 %v108803, 1 (stack50)
        %v108805 = vor.u32 16256, %v108804 (stack46)
        %v108806 = vand.u32.u16 65535, %v108805 (stack51)
        %v120328 = vadd.low.f32.bf16 -1.0, %v108806 (stack52)
        %v108815 = vmul.f32 2.0, %v120328 (stack53)
        %v108819 = vadd.f32 -0.99609375, %v108815 (stack52)
        %v108823 = vmax.f32 %v108819, -0.99609375 (stack54)
        %v108825 = vand.u32 2147483647, %v108823 (stack55)
        %vm108828 = vcmp.eq.f32.partialorder %v108825, 1.0 (stack56)
        %v108833 = vmul.f32 inf, %v108823 (stack53)
        %v108835 = vxor.u32 2147483648, %v108823 (stack57)
        %v108838 = vmul.f32 %v108835, %v108823 (stack53)
        %v108840 = vadd.f32 1.0, %v108838 (stack58)
        %v108841 = vlog2.pop %v108840 (stack59)
        %v108842 = vmul.f32 0.6931472, %v108841 (stack60)
        %v108843 = vmul.f32 -0.5, %v108838 (stack61)
        %v108844 = vadd.f32 1.0, %v108843 (stack62)
        %v108845 = vmul.f32 %v108844, %v108838 (stack63)
        %v108846 = vand.u32 2147483647, %v108838 (stack64)
        %vm108847 = vcmp.lt.f32.partialorder %v108846, 0.0004427343 (stack65)
        %v108848 = vsel /*vm=*/%vm108847, /*on_true_vy=*/%v108845, /*on_false_vx=*/%v108842 (stack66)
        %v108849 = vxor.u32 2147483648, %v108848 (stack57)
        %vm108852 = vcmp.lt.f32.partialorder %v108849, 5.0 (stack56)
        %v108857 = vsel /*vm=*/%vm108852, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v108861 = vsel /*vm=*/%vm108852, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v108865 = vsel /*vm=*/%vm108852, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v108869 = vsel /*vm=*/%vm108852, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v108873 = vsel /*vm=*/%vm108852, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v108877 = vsel /*vm=*/%vm108852, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v108881 = vsel /*vm=*/%vm108852, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v108885 = vsel /*vm=*/%vm108852, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v108889 = vsel /*vm=*/%vm108852, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v108893 = vadd.f32 -2.5, %v108849 (stack52)
        %v108895 = vrsqrt.pop %v108849 (stack67)
        %v108896 = vmul.f32 %v108895, %v108849 (stack68)
        %vm108897 = vcmp.eq.f32.partialorder %v108849, inf (stack69)
        %v108898 = vsel /*vm=*/%vm108897, /*on_true_vy=*/%v108849, /*on_false_vx=*/%v108896 (stack70)
        %vm108899 = vcmp.eq.f32.partialorder %v108849, 0.0 (stack71)
        %v108900 = vand.u32 2147483648, %v108849 (stack72)
        %v108901 = vsel /*vm=*/%vm108899, /*on_true_vy=*/%v108900, /*on_false_vx=*/%v108898 (stack73)
        %v108904 = vadd.f32 -3.0, %v108901 (stack52)
        %v108908 = vsel /*vm=*/%vm108852, /*on_true_vy=*/%v108893, /*on_false_vx=*/%v108904 (stack43)
        %v108912 = vmul.f32 %v108908, %v108889 (stack53)
        %v108916 = vadd.f32 %v108912, %v108885 (stack52)
        %v108920 = vmul.f32 %v108916, %v108908 (stack53)
        %v108924 = vadd.f32 %v108920, %v108881 (stack52)
        %v108928 = vmul.f32 %v108924, %v108908 (stack53)
        %v108932 = vadd.f32 %v108928, %v108877 (stack52)
        %v108936 = vmul.f32 %v108932, %v108908 (stack53)
        %v108940 = vadd.f32 %v108936, %v108873 (stack52)
        %v108944 = vmul.f32 %v108940, %v108908 (stack53)
        %v108948 = vadd.f32 %v108944, %v108869 (stack52)
        %v108952 = vmul.f32 %v108948, %v108908 (stack53)
        %v108956 = vadd.f32 %v108952, %v108865 (stack52)
        %v108960 = vmul.f32 %v108956, %v108908 (stack53)
        %v108964 = vadd.f32 %v108960, %v108861 (stack52)
        %v108968 = vmul.f32 %v108964, %v108908 (stack53)
        %v108972 = vadd.f32 %v108968, %v108857 (stack52)
        %v108976 = vmul.f32 %v108972, %v108823 (stack53)
        %v108980 = vsel /*vm=*/%vm108828, /*on_true_vy=*/%v108833, /*on_false_vx=*/%v108976 (stack43)
        %v108984 = vmul.f32 1.4140625, %v108980 (stack53)
        %v108987 = vpack.c.bf16 0.0, %v108984 (stack74)
        %120329 = vst [vmem:[%s280 + $0x74] sm:$0xf] /*vst_source=*/%v108987 (stack75)
        %v108991 = vadd.s32 %v108527, %v894 (stack39)
        %v109001 = vadd.s32 %v108991, %v415 (stack39)
        %vm109005 = vcmp.lt.u32.totalorder %v109001, %v108991 (stack42)
        %vm109010 = vcmp.lt.u32.totalorder %v108991, %v894 (stack42)
        %v109015 = vadd.s32 %v108510, %v881 (stack39)
        %v109019 = vadd.s32 1, %v109015 (stack39)
        %v109023 = vsel /*vm=*/%vm109010, /*on_true_vy=*/%v109019, /*on_false_vx=*/%v109015 (stack43)
        %v109027 = vadd.s32 1, %v109023 (stack39)
        %v109031 = vsel /*vm=*/%vm109005, /*on_true_vy=*/%v109027, /*on_false_vx=*/%v109023 (stack43)
        %v109036 = vadd.s32 %v109031, %v10 (stack39)
        %v109040 = vadd.s32 %v109001, %v9 (stack39)
        %v109044 = vadd.s32 %v109040, %v109036 (stack39)
        %v109046 = vshll.u32 %v109040, 13 (stack44)
        %v109047 = vshrl.u32 %v109040, 19 (stack45)
        %v109048 = vor.u32 %v109047, %v109046 (stack46)
        %v109049 = vxor.u32 %v109048, %v109044 (stack47)
        %v109052 = vadd.s32 %v109049, %v109044 (stack39)
        %v109054 = vshll.u32 %v109049, 15 (stack44)
        %v109055 = vshrl.u32 %v109049, 17 (stack45)
        %v109056 = vor.u32 %v109055, %v109054 (stack46)
        %v109057 = vxor.u32 %v109056, %v109052 (stack47)
        %v109060 = vadd.s32 %v109057, %v109052 (stack39)
        %v109062 = vshll.u32 %v109057, 26 (stack44)
        %v109063 = vshrl.u32 %v109057, 6 (stack45)
        %v109064 = vor.u32 %v109063, %v109062 (stack46)
        %v109065 = vxor.u32 %v109064, %v109060 (stack47)
        %v109068 = vadd.s32 %v109065, %v109060 (stack39)
        %v109072 = vadd.s32 %v109068, %v9 (stack39)
        %v109074 = vshll.u32 %v109065, 6 (stack44)
        %v109075 = vshrl.u32 %v109065, 26 (stack45)
        %v109076 = vor.u32 %v109075, %v109074 (stack46)
        %v109077 = vxor.u32 %v109076, %v109068 (stack47)
        %v109080 = vadd.s32 %v109077, %v8 (stack39)
        %v109084 = vadd.s32 1, %v109080 (stack39)
        %v109088 = vadd.s32 %v109084, %v109072 (stack39)
        %v109090 = vshll.u32 %v109084, 17 (stack44)
        %v109091 = vshrl.u32 %v109084, 15 (stack45)
        %v109092 = vor.u32 %v109091, %v109090 (stack46)
        %v109093 = vxor.u32 %v109092, %v109088 (stack47)
        %v109096 = vadd.s32 %v109093, %v109088 (stack39)
        %v109098 = vshll.u32 %v109093, 29 (stack44)
        %v109099 = vshrl.u32 %v109093, 3 (stack45)
        %v109100 = vor.u32 %v109099, %v109098 (stack46)
        %v109101 = vxor.u32 %v109100, %v109096 (stack47)
        %v109104 = vadd.s32 %v109101, %v109096 (stack39)
        %v109106 = vshll.u32 %v109101, 16 (stack44)
        %v109107 = vshrl.u32 %v109101, 16 (stack45)
        %v109108 = vor.u32 %v109107, %v109106 (stack46)
        %v109109 = vxor.u32 %v109108, %v109104 (stack47)
        %v109112 = vadd.s32 %v109109, %v109104 (stack39)
        %v109116 = vadd.s32 %v109112, %v8 (stack39)
        %v109118 = vshll.u32 %v109109, 24 (stack44)
        %v109119 = vshrl.u32 %v109109, 8 (stack45)
        %v109120 = vor.u32 %v109119, %v109118 (stack46)
        %v109121 = vxor.u32 %v109120, %v109112 (stack47)
        %v109124 = vadd.s32 %v109121, %v10 (stack39)
        %v109128 = vadd.s32 2, %v109124 (stack39)
        %v109132 = vadd.s32 %v109128, %v109116 (stack39)
        %v109134 = vshll.u32 %v109128, 13 (stack44)
        %v109135 = vshrl.u32 %v109128, 19 (stack45)
        %v109136 = vor.u32 %v109135, %v109134 (stack46)
        %v109137 = vxor.u32 %v109136, %v109132 (stack47)
        %v109140 = vadd.s32 %v109137, %v109132 (stack39)
        %v109142 = vshll.u32 %v109137, 15 (stack44)
        %v109143 = vshrl.u32 %v109137, 17 (stack45)
        %v109144 = vor.u32 %v109143, %v109142 (stack46)
        %v109145 = vxor.u32 %v109144, %v109140 (stack47)
        %v109148 = vadd.s32 %v109145, %v109140 (stack39)
        %v109150 = vshll.u32 %v109145, 26 (stack44)
        %v109151 = vshrl.u32 %v109145, 6 (stack45)
        %v109152 = vor.u32 %v109151, %v109150 (stack46)
        %v109153 = vxor.u32 %v109152, %v109148 (stack47)
        %v109156 = vadd.s32 %v109153, %v109148 (stack39)
        %v109160 = vadd.s32 %v109156, %v10 (stack39)
        %v109162 = vshll.u32 %v109153, 6 (stack44)
        %v109163 = vshrl.u32 %v109153, 26 (stack45)
        %v109164 = vor.u32 %v109163, %v109162 (stack46)
        %v109165 = vxor.u32 %v109164, %v109156 (stack47)
        %v109168 = vadd.s32 %v109165, %v9 (stack39)
        %v109172 = vadd.s32 3, %v109168 (stack39)
        %v109176 = vadd.s32 %v109172, %v109160 (stack39)
        %v109178 = vshll.u32 %v109172, 17 (stack44)
        %v109179 = vshrl.u32 %v109172, 15 (stack45)
        %v109180 = vor.u32 %v109179, %v109178 (stack46)
        %v109181 = vxor.u32 %v109180, %v109176 (stack47)
        %v109184 = vadd.s32 %v109181, %v109176 (stack39)
        %v109186 = vshll.u32 %v109181, 29 (stack44)
        %v109187 = vshrl.u32 %v109181, 3 (stack45)
        %v109188 = vor.u32 %v109187, %v109186 (stack46)
        %v109189 = vxor.u32 %v109188, %v109184 (stack47)
        %v109192 = vadd.s32 %v109189, %v109184 (stack39)
        %v109194 = vshll.u32 %v109189, 16 (stack44)
        %v109195 = vshrl.u32 %v109189, 16 (stack45)
        %v109196 = vor.u32 %v109195, %v109194 (stack46)
        %v109197 = vxor.u32 %v109196, %v109192 (stack47)
        %v109200 = vadd.s32 %v109197, %v109192 (stack39)
        %v109204 = vadd.s32 %v109200, %v9 (stack39)
        %v109206 = vshll.u32 %v109197, 24 (stack44)
        %v109207 = vshrl.u32 %v109197, 8 (stack45)
        %v109208 = vor.u32 %v109207, %v109206 (stack46)
        %v109209 = vxor.u32 %v109208, %v109200 (stack47)
        %v109212 = vadd.s32 %v109209, %v8 (stack39)
        %v109216 = vadd.s32 4, %v109212 (stack39)
        %v109220 = vadd.s32 %v109216, %v109204 (stack39)
        %v109222 = vshll.u32 %v109216, 13 (stack44)
        %v109223 = vshrl.u32 %v109216, 19 (stack45)
        %v109224 = vor.u32 %v109223, %v109222 (stack46)
        %v109225 = vxor.u32 %v109224, %v109220 (stack47)
        %v109228 = vadd.s32 %v109225, %v109220 (stack39)
        %v109230 = vshll.u32 %v109225, 15 (stack44)
        %v109231 = vshrl.u32 %v109225, 17 (stack45)
        %v109232 = vor.u32 %v109231, %v109230 (stack46)
        %v109233 = vxor.u32 %v109232, %v109228 (stack47)
        %v109236 = vadd.s32 %v109233, %v109228 (stack39)
        %v109238 = vshll.u32 %v109233, 26 (stack44)
        %v109239 = vshrl.u32 %v109233, 6 (stack45)
        %v109240 = vor.u32 %v109239, %v109238 (stack46)
        %v109241 = vxor.u32 %v109240, %v109236 (stack47)
        %v109244 = vadd.s32 %v109241, %v109236 (stack39)
        %v109248 = vadd.s32 %v109244, %v8 (stack39)
        %v109250 = vshll.u32 %v109241, 6 (stack44)
        %v109251 = vshrl.u32 %v109241, 26 (stack45)
        %v109252 = vor.u32 %v109251, %v109250 (stack46)
        %v109253 = vxor.u32 %v109252, %v109244 (stack47)
        %v109256 = vadd.s32 %v109253, %v10 (stack39)
        %v109260 = vadd.s32 5, %v109256 (stack39)
        %v109262 = vxor.u32 %v109260, %v109248 (stack47)
        %v109263 = vand.u32.u8 255, %v109262 (stack48)
        %v109264 = vand.u32 65535, %v109263 (stack49)
        %v109265 = vshrl.u32 %v109264, 1 (stack50)
        %v109266 = vor.u32 16256, %v109265 (stack46)
        %v109267 = vand.u32.u16 65535, %v109266 (stack51)
        %v120330 = vadd.low.f32.bf16 -1.0, %v109267 (stack52)
        %v109276 = vmul.f32 2.0, %v120330 (stack53)
        %v109280 = vadd.f32 -0.99609375, %v109276 (stack52)
        %v109284 = vmax.f32 %v109280, -0.99609375 (stack54)
        %v109286 = vand.u32 2147483647, %v109284 (stack55)
        %vm109289 = vcmp.eq.f32.partialorder %v109286, 1.0 (stack56)
        %v109294 = vmul.f32 inf, %v109284 (stack53)
        %v109296 = vxor.u32 2147483648, %v109284 (stack57)
        %v109299 = vmul.f32 %v109296, %v109284 (stack53)
        %v109301 = vadd.f32 1.0, %v109299 (stack58)
        %v109302 = vlog2.pop %v109301 (stack59)
        %v109303 = vmul.f32 0.6931472, %v109302 (stack60)
        %v109304 = vmul.f32 -0.5, %v109299 (stack61)
        %v109305 = vadd.f32 1.0, %v109304 (stack62)
        %v109306 = vmul.f32 %v109305, %v109299 (stack63)
        %v109307 = vand.u32 2147483647, %v109299 (stack64)
        %vm109308 = vcmp.lt.f32.partialorder %v109307, 0.0004427343 (stack65)
        %v109309 = vsel /*vm=*/%vm109308, /*on_true_vy=*/%v109306, /*on_false_vx=*/%v109303 (stack66)
        %v109310 = vxor.u32 2147483648, %v109309 (stack57)
        %vm109313 = vcmp.lt.f32.partialorder %v109310, 5.0 (stack56)
        %v109318 = vsel /*vm=*/%vm109313, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v109322 = vsel /*vm=*/%vm109313, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v109326 = vsel /*vm=*/%vm109313, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v109330 = vsel /*vm=*/%vm109313, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v109334 = vsel /*vm=*/%vm109313, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v109338 = vsel /*vm=*/%vm109313, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v109342 = vsel /*vm=*/%vm109313, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v109346 = vsel /*vm=*/%vm109313, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v109350 = vsel /*vm=*/%vm109313, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v109354 = vadd.f32 -2.5, %v109310 (stack52)
        %v109356 = vrsqrt.pop %v109310 (stack67)
        %v109357 = vmul.f32 %v109356, %v109310 (stack68)
        %vm109358 = vcmp.eq.f32.partialorder %v109310, inf (stack69)
        %v109359 = vsel /*vm=*/%vm109358, /*on_true_vy=*/%v109310, /*on_false_vx=*/%v109357 (stack70)
        %vm109360 = vcmp.eq.f32.partialorder %v109310, 0.0 (stack71)
        %v109361 = vand.u32 2147483648, %v109310 (stack72)
        %v109362 = vsel /*vm=*/%vm109360, /*on_true_vy=*/%v109361, /*on_false_vx=*/%v109359 (stack73)
        %v109365 = vadd.f32 -3.0, %v109362 (stack52)
        %v109369 = vsel /*vm=*/%vm109313, /*on_true_vy=*/%v109354, /*on_false_vx=*/%v109365 (stack43)
        %v109373 = vmul.f32 %v109369, %v109350 (stack53)
        %v109377 = vadd.f32 %v109373, %v109346 (stack52)
        %v109381 = vmul.f32 %v109377, %v109369 (stack53)
        %v109385 = vadd.f32 %v109381, %v109342 (stack52)
        %v109389 = vmul.f32 %v109385, %v109369 (stack53)
        %v109393 = vadd.f32 %v109389, %v109338 (stack52)
        %v109397 = vmul.f32 %v109393, %v109369 (stack53)
        %v109401 = vadd.f32 %v109397, %v109334 (stack52)
        %v109405 = vmul.f32 %v109401, %v109369 (stack53)
        %v109409 = vadd.f32 %v109405, %v109330 (stack52)
        %v109413 = vmul.f32 %v109409, %v109369 (stack53)
        %v109417 = vadd.f32 %v109413, %v109326 (stack52)
        %v109421 = vmul.f32 %v109417, %v109369 (stack53)
        %v109425 = vadd.f32 %v109421, %v109322 (stack52)
        %v109429 = vmul.f32 %v109425, %v109369 (stack53)
        %v109433 = vadd.f32 %v109429, %v109318 (stack52)
        %v109437 = vmul.f32 %v109433, %v109284 (stack53)
        %v109441 = vsel /*vm=*/%vm109289, /*on_true_vy=*/%v109294, /*on_false_vx=*/%v109437 (stack43)
        %v109445 = vmul.f32 1.4140625, %v109441 (stack53)
        %v109448 = vpack.c.bf16 0.0, %v109445 (stack74)
        %120331 = vst [vmem:[%s280 + $0xf4] sm:$0xf] /*vst_source=*/%v109448 (stack75)
        %v109452 = vadd.s32 %v108527, %v1381 (stack39)
        %v109462 = vadd.s32 %v109452, %v415 (stack39)
        %vm109466 = vcmp.lt.u32.totalorder %v109462, %v109452 (stack42)
        %vm109471 = vcmp.lt.u32.totalorder %v109452, %v1381 (stack42)
        %v109476 = vadd.s32 %v108510, %v1368 (stack39)
        %v109480 = vadd.s32 1, %v109476 (stack39)
        %v109484 = vsel /*vm=*/%vm109471, /*on_true_vy=*/%v109480, /*on_false_vx=*/%v109476 (stack43)
        %v109488 = vadd.s32 1, %v109484 (stack39)
        %v109492 = vsel /*vm=*/%vm109466, /*on_true_vy=*/%v109488, /*on_false_vx=*/%v109484 (stack43)
        %v109497 = vadd.s32 %v109492, %v10 (stack39)
        %v109501 = vadd.s32 %v109462, %v9 (stack39)
        %v109505 = vadd.s32 %v109501, %v109497 (stack39)
        %v109507 = vshll.u32 %v109501, 13 (stack44)
        %v109508 = vshrl.u32 %v109501, 19 (stack45)
        %v109509 = vor.u32 %v109508, %v109507 (stack46)
        %v109510 = vxor.u32 %v109509, %v109505 (stack47)
        %v109513 = vadd.s32 %v109510, %v109505 (stack39)
        %v109515 = vshll.u32 %v109510, 15 (stack44)
        %v109516 = vshrl.u32 %v109510, 17 (stack45)
        %v109517 = vor.u32 %v109516, %v109515 (stack46)
        %v109518 = vxor.u32 %v109517, %v109513 (stack47)
        %v109521 = vadd.s32 %v109518, %v109513 (stack39)
        %v109523 = vshll.u32 %v109518, 26 (stack44)
        %v109524 = vshrl.u32 %v109518, 6 (stack45)
        %v109525 = vor.u32 %v109524, %v109523 (stack46)
        %v109526 = vxor.u32 %v109525, %v109521 (stack47)
        %v109529 = vadd.s32 %v109526, %v109521 (stack39)
        %v109533 = vadd.s32 %v109529, %v9 (stack39)
        %v109535 = vshll.u32 %v109526, 6 (stack44)
        %v109536 = vshrl.u32 %v109526, 26 (stack45)
        %v109537 = vor.u32 %v109536, %v109535 (stack46)
        %v109538 = vxor.u32 %v109537, %v109529 (stack47)
        %v109541 = vadd.s32 %v109538, %v8 (stack39)
        %v109545 = vadd.s32 1, %v109541 (stack39)
        %v109549 = vadd.s32 %v109545, %v109533 (stack39)
        %v109551 = vshll.u32 %v109545, 17 (stack44)
        %v109552 = vshrl.u32 %v109545, 15 (stack45)
        %v109553 = vor.u32 %v109552, %v109551 (stack46)
        %v109554 = vxor.u32 %v109553, %v109549 (stack47)
        %v109557 = vadd.s32 %v109554, %v109549 (stack39)
        %v109559 = vshll.u32 %v109554, 29 (stack44)
        %v109560 = vshrl.u32 %v109554, 3 (stack45)
        %v109561 = vor.u32 %v109560, %v109559 (stack46)
        %v109562 = vxor.u32 %v109561, %v109557 (stack47)
        %v109565 = vadd.s32 %v109562, %v109557 (stack39)
        %v109567 = vshll.u32 %v109562, 16 (stack44)
        %v109568 = vshrl.u32 %v109562, 16 (stack45)
        %v109569 = vor.u32 %v109568, %v109567 (stack46)
        %v109570 = vxor.u32 %v109569, %v109565 (stack47)
        %v109573 = vadd.s32 %v109570, %v109565 (stack39)
        %v109577 = vadd.s32 %v109573, %v8 (stack39)
        %v109579 = vshll.u32 %v109570, 24 (stack44)
        %v109580 = vshrl.u32 %v109570, 8 (stack45)
        %v109581 = vor.u32 %v109580, %v109579 (stack46)
        %v109582 = vxor.u32 %v109581, %v109573 (stack47)
        %v109585 = vadd.s32 %v109582, %v10 (stack39)
        %v109589 = vadd.s32 2, %v109585 (stack39)
        %v109593 = vadd.s32 %v109589, %v109577 (stack39)
        %v109595 = vshll.u32 %v109589, 13 (stack44)
        %v109596 = vshrl.u32 %v109589, 19 (stack45)
        %v109597 = vor.u32 %v109596, %v109595 (stack46)
        %v109598 = vxor.u32 %v109597, %v109593 (stack47)
        %v109601 = vadd.s32 %v109598, %v109593 (stack39)
        %v109603 = vshll.u32 %v109598, 15 (stack44)
        %v109604 = vshrl.u32 %v109598, 17 (stack45)
        %v109605 = vor.u32 %v109604, %v109603 (stack46)
        %v109606 = vxor.u32 %v109605, %v109601 (stack47)
        %v109609 = vadd.s32 %v109606, %v109601 (stack39)
        %v109611 = vshll.u32 %v109606, 26 (stack44)
        %v109612 = vshrl.u32 %v109606, 6 (stack45)
        %v109613 = vor.u32 %v109612, %v109611 (stack46)
        %v109614 = vxor.u32 %v109613, %v109609 (stack47)
        %v109617 = vadd.s32 %v109614, %v109609 (stack39)
        %v109621 = vadd.s32 %v109617, %v10 (stack39)
        %v109623 = vshll.u32 %v109614, 6 (stack44)
        %v109624 = vshrl.u32 %v109614, 26 (stack45)
        %v109625 = vor.u32 %v109624, %v109623 (stack46)
        %v109626 = vxor.u32 %v109625, %v109617 (stack47)
        %v109629 = vadd.s32 %v109626, %v9 (stack39)
        %v109633 = vadd.s32 3, %v109629 (stack39)
        %v109637 = vadd.s32 %v109633, %v109621 (stack39)
        %v109639 = vshll.u32 %v109633, 17 (stack44)
        %v109640 = vshrl.u32 %v109633, 15 (stack45)
        %v109641 = vor.u32 %v109640, %v109639 (stack46)
        %v109642 = vxor.u32 %v109641, %v109637 (stack47)
        %v109645 = vadd.s32 %v109642, %v109637 (stack39)
        %v109647 = vshll.u32 %v109642, 29 (stack44)
        %v109648 = vshrl.u32 %v109642, 3 (stack45)
        %v109649 = vor.u32 %v109648, %v109647 (stack46)
        %v109650 = vxor.u32 %v109649, %v109645 (stack47)
        %v109653 = vadd.s32 %v109650, %v109645 (stack39)
        %v109655 = vshll.u32 %v109650, 16 (stack44)
        %v109656 = vshrl.u32 %v109650, 16 (stack45)
        %v109657 = vor.u32 %v109656, %v109655 (stack46)
        %v109658 = vxor.u32 %v109657, %v109653 (stack47)
        %v109661 = vadd.s32 %v109658, %v109653 (stack39)
        %v109665 = vadd.s32 %v109661, %v9 (stack39)
        %v109667 = vshll.u32 %v109658, 24 (stack44)
        %v109668 = vshrl.u32 %v109658, 8 (stack45)
        %v109669 = vor.u32 %v109668, %v109667 (stack46)
        %v109670 = vxor.u32 %v109669, %v109661 (stack47)
        %v109673 = vadd.s32 %v109670, %v8 (stack39)
        %v109677 = vadd.s32 4, %v109673 (stack39)
        %v109681 = vadd.s32 %v109677, %v109665 (stack39)
        %v109683 = vshll.u32 %v109677, 13 (stack44)
        %v109684 = vshrl.u32 %v109677, 19 (stack45)
        %v109685 = vor.u32 %v109684, %v109683 (stack46)
        %v109686 = vxor.u32 %v109685, %v109681 (stack47)
        %v109689 = vadd.s32 %v109686, %v109681 (stack39)
        %v109691 = vshll.u32 %v109686, 15 (stack44)
        %v109692 = vshrl.u32 %v109686, 17 (stack45)
        %v109693 = vor.u32 %v109692, %v109691 (stack46)
        %v109694 = vxor.u32 %v109693, %v109689 (stack47)
        %v109697 = vadd.s32 %v109694, %v109689 (stack39)
        %v109699 = vshll.u32 %v109694, 26 (stack44)
        %v109700 = vshrl.u32 %v109694, 6 (stack45)
        %v109701 = vor.u32 %v109700, %v109699 (stack46)
        %v109702 = vxor.u32 %v109701, %v109697 (stack47)
        %v109705 = vadd.s32 %v109702, %v109697 (stack39)
        %v109709 = vadd.s32 %v109705, %v8 (stack39)
        %v109711 = vshll.u32 %v109702, 6 (stack44)
        %v109712 = vshrl.u32 %v109702, 26 (stack45)
        %v109713 = vor.u32 %v109712, %v109711 (stack46)
        %v109714 = vxor.u32 %v109713, %v109705 (stack47)
        %v109717 = vadd.s32 %v109714, %v10 (stack39)
        %v109721 = vadd.s32 5, %v109717 (stack39)
        %v109723 = vxor.u32 %v109721, %v109709 (stack47)
        %v109724 = vand.u32.u8 255, %v109723 (stack48)
        %v109725 = vand.u32 65535, %v109724 (stack49)
        %v109726 = vshrl.u32 %v109725, 1 (stack50)
        %v109727 = vor.u32 16256, %v109726 (stack46)
        %v109728 = vand.u32.u16 65535, %v109727 (stack51)
        %v120332 = vadd.low.f32.bf16 -1.0, %v109728 (stack52)
        %v109737 = vmul.f32 2.0, %v120332 (stack53)
        %v109741 = vadd.f32 -0.99609375, %v109737 (stack52)
        %v109745 = vmax.f32 %v109741, -0.99609375 (stack54)
        %v109747 = vand.u32 2147483647, %v109745 (stack55)
        %vm109750 = vcmp.eq.f32.partialorder %v109747, 1.0 (stack56)
        %v109755 = vmul.f32 inf, %v109745 (stack53)
        %v109757 = vxor.u32 2147483648, %v109745 (stack57)
        %v109760 = vmul.f32 %v109757, %v109745 (stack53)
        %v109762 = vadd.f32 1.0, %v109760 (stack58)
        %v109763 = vlog2.pop %v109762 (stack59)
        %v109764 = vmul.f32 0.6931472, %v109763 (stack60)
        %v109765 = vmul.f32 -0.5, %v109760 (stack61)
        %v109766 = vadd.f32 1.0, %v109765 (stack62)
        %v109767 = vmul.f32 %v109766, %v109760 (stack63)
        %v109768 = vand.u32 2147483647, %v109760 (stack64)
        %vm109769 = vcmp.lt.f32.partialorder %v109768, 0.0004427343 (stack65)
        %v109770 = vsel /*vm=*/%vm109769, /*on_true_vy=*/%v109767, /*on_false_vx=*/%v109764 (stack66)
        %v109771 = vxor.u32 2147483648, %v109770 (stack57)
        %vm109774 = vcmp.lt.f32.partialorder %v109771, 5.0 (stack56)
        %v109779 = vsel /*vm=*/%vm109774, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v109783 = vsel /*vm=*/%vm109774, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v109787 = vsel /*vm=*/%vm109774, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v109791 = vsel /*vm=*/%vm109774, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v109795 = vsel /*vm=*/%vm109774, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v109799 = vsel /*vm=*/%vm109774, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v109803 = vsel /*vm=*/%vm109774, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v109807 = vsel /*vm=*/%vm109774, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v109811 = vsel /*vm=*/%vm109774, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v109815 = vadd.f32 -2.5, %v109771 (stack52)
        %v109817 = vrsqrt.pop %v109771 (stack67)
        %v109818 = vmul.f32 %v109817, %v109771 (stack68)
        %vm109819 = vcmp.eq.f32.partialorder %v109771, inf (stack69)
        %v109820 = vsel /*vm=*/%vm109819, /*on_true_vy=*/%v109771, /*on_false_vx=*/%v109818 (stack70)
        %vm109821 = vcmp.eq.f32.partialorder %v109771, 0.0 (stack71)
        %v109822 = vand.u32 2147483648, %v109771 (stack72)
        %v109823 = vsel /*vm=*/%vm109821, /*on_true_vy=*/%v109822, /*on_false_vx=*/%v109820 (stack73)
        %v109826 = vadd.f32 -3.0, %v109823 (stack52)
        %v109830 = vsel /*vm=*/%vm109774, /*on_true_vy=*/%v109815, /*on_false_vx=*/%v109826 (stack43)
        %v109834 = vmul.f32 %v109830, %v109811 (stack53)
        %v109838 = vadd.f32 %v109834, %v109807 (stack52)
        %v109842 = vmul.f32 %v109838, %v109830 (stack53)
        %v109846 = vadd.f32 %v109842, %v109803 (stack52)
        %v109850 = vmul.f32 %v109846, %v109830 (stack53)
        %v109854 = vadd.f32 %v109850, %v109799 (stack52)
        %v109858 = vmul.f32 %v109854, %v109830 (stack53)
        %v109862 = vadd.f32 %v109858, %v109795 (stack52)
        %v109866 = vmul.f32 %v109862, %v109830 (stack53)
        %v109870 = vadd.f32 %v109866, %v109791 (stack52)
        %v109874 = vmul.f32 %v109870, %v109830 (stack53)
        %v109878 = vadd.f32 %v109874, %v109787 (stack52)
        %v109882 = vmul.f32 %v109878, %v109830 (stack53)
        %v109886 = vadd.f32 %v109882, %v109783 (stack52)
        %v109890 = vmul.f32 %v109886, %v109830 (stack53)
        %v109894 = vadd.f32 %v109890, %v109779 (stack52)
        %v109898 = vmul.f32 %v109894, %v109745 (stack53)
        %v109902 = vsel /*vm=*/%vm109750, /*on_true_vy=*/%v109755, /*on_false_vx=*/%v109898 (stack43)
        %v109906 = vmul.f32 1.4140625, %v109902 (stack53)
        %v109909 = vpack.c.bf16 0.0, %v109906 (stack74)
        %120333 = vst [vmem:[%s280 + $0x174] sm:$0xf] /*vst_source=*/%v109909 (stack75)
        %v109913 = vadd.s32 %v108527, %v1868 (stack39)
        %v109923 = vadd.s32 %v109913, %v415 (stack39)
        %vm109927 = vcmp.lt.u32.totalorder %v109923, %v109913 (stack42)
        %vm109932 = vcmp.lt.u32.totalorder %v109913, %v1868 (stack42)
        %v109937 = vadd.s32 %v108510, %v1855 (stack39)
        %v109941 = vadd.s32 1, %v109937 (stack39)
        %v109945 = vsel /*vm=*/%vm109932, /*on_true_vy=*/%v109941, /*on_false_vx=*/%v109937 (stack43)
        %v109949 = vadd.s32 1, %v109945 (stack39)
        %v109953 = vsel /*vm=*/%vm109927, /*on_true_vy=*/%v109949, /*on_false_vx=*/%v109945 (stack43)
        %v109958 = vadd.s32 %v109953, %v10 (stack39)
        %v109962 = vadd.s32 %v109923, %v9 (stack39)
        %v109966 = vadd.s32 %v109962, %v109958 (stack39)
        %v109968 = vshll.u32 %v109962, 13 (stack44)
        %v109969 = vshrl.u32 %v109962, 19 (stack45)
        %v109970 = vor.u32 %v109969, %v109968 (stack46)
        %v109971 = vxor.u32 %v109970, %v109966 (stack47)
        %v109974 = vadd.s32 %v109971, %v109966 (stack39)
        %v109976 = vshll.u32 %v109971, 15 (stack44)
        %v109977 = vshrl.u32 %v109971, 17 (stack45)
        %v109978 = vor.u32 %v109977, %v109976 (stack46)
        %v109979 = vxor.u32 %v109978, %v109974 (stack47)
        %v109982 = vadd.s32 %v109979, %v109974 (stack39)
        %v109984 = vshll.u32 %v109979, 26 (stack44)
        %v109985 = vshrl.u32 %v109979, 6 (stack45)
        %v109986 = vor.u32 %v109985, %v109984 (stack46)
        %v109987 = vxor.u32 %v109986, %v109982 (stack47)
        %v109990 = vadd.s32 %v109987, %v109982 (stack39)
        %v109994 = vadd.s32 %v109990, %v9 (stack39)
        %v109996 = vshll.u32 %v109987, 6 (stack44)
        %v109997 = vshrl.u32 %v109987, 26 (stack45)
        %v109998 = vor.u32 %v109997, %v109996 (stack46)
        %v109999 = vxor.u32 %v109998, %v109990 (stack47)
        %v110002 = vadd.s32 %v109999, %v8 (stack39)
        %v110006 = vadd.s32 1, %v110002 (stack39)
        %v110010 = vadd.s32 %v110006, %v109994 (stack39)
        %v110012 = vshll.u32 %v110006, 17 (stack44)
        %v110013 = vshrl.u32 %v110006, 15 (stack45)
        %v110014 = vor.u32 %v110013, %v110012 (stack46)
        %v110015 = vxor.u32 %v110014, %v110010 (stack47)
        %v110018 = vadd.s32 %v110015, %v110010 (stack39)
        %v110020 = vshll.u32 %v110015, 29 (stack44)
        %v110021 = vshrl.u32 %v110015, 3 (stack45)
        %v110022 = vor.u32 %v110021, %v110020 (stack46)
        %v110023 = vxor.u32 %v110022, %v110018 (stack47)
        %v110026 = vadd.s32 %v110023, %v110018 (stack39)
        %v110028 = vshll.u32 %v110023, 16 (stack44)
        %v110029 = vshrl.u32 %v110023, 16 (stack45)
        %v110030 = vor.u32 %v110029, %v110028 (stack46)
        %v110031 = vxor.u32 %v110030, %v110026 (stack47)
        %v110034 = vadd.s32 %v110031, %v110026 (stack39)
        %v110038 = vadd.s32 %v110034, %v8 (stack39)
        %v110040 = vshll.u32 %v110031, 24 (stack44)
        %v110041 = vshrl.u32 %v110031, 8 (stack45)
        %v110042 = vor.u32 %v110041, %v110040 (stack46)
        %v110043 = vxor.u32 %v110042, %v110034 (stack47)
        %v110046 = vadd.s32 %v110043, %v10 (stack39)
        %v110050 = vadd.s32 2, %v110046 (stack39)
        %v110054 = vadd.s32 %v110050, %v110038 (stack39)
        %v110056 = vshll.u32 %v110050, 13 (stack44)
        %v110057 = vshrl.u32 %v110050, 19 (stack45)
        %v110058 = vor.u32 %v110057, %v110056 (stack46)
        %v110059 = vxor.u32 %v110058, %v110054 (stack47)
        %v110062 = vadd.s32 %v110059, %v110054 (stack39)
        %v110064 = vshll.u32 %v110059, 15 (stack44)
        %v110065 = vshrl.u32 %v110059, 17 (stack45)
        %v110066 = vor.u32 %v110065, %v110064 (stack46)
        %v110067 = vxor.u32 %v110066, %v110062 (stack47)
        %v110070 = vadd.s32 %v110067, %v110062 (stack39)
        %v110072 = vshll.u32 %v110067, 26 (stack44)
        %v110073 = vshrl.u32 %v110067, 6 (stack45)
        %v110074 = vor.u32 %v110073, %v110072 (stack46)
        %v110075 = vxor.u32 %v110074, %v110070 (stack47)
        %v110078 = vadd.s32 %v110075, %v110070 (stack39)
        %v110082 = vadd.s32 %v110078, %v10 (stack39)
        %v110084 = vshll.u32 %v110075, 6 (stack44)
        %v110085 = vshrl.u32 %v110075, 26 (stack45)
        %v110086 = vor.u32 %v110085, %v110084 (stack46)
        %v110087 = vxor.u32 %v110086, %v110078 (stack47)
        %v110090 = vadd.s32 %v110087, %v9 (stack39)
        %v110094 = vadd.s32 3, %v110090 (stack39)
        %v110098 = vadd.s32 %v110094, %v110082 (stack39)
        %v110100 = vshll.u32 %v110094, 17 (stack44)
        %v110101 = vshrl.u32 %v110094, 15 (stack45)
        %v110102 = vor.u32 %v110101, %v110100 (stack46)
        %v110103 = vxor.u32 %v110102, %v110098 (stack47)
        %v110106 = vadd.s32 %v110103, %v110098 (stack39)
        %v110108 = vshll.u32 %v110103, 29 (stack44)
        %v110109 = vshrl.u32 %v110103, 3 (stack45)
        %v110110 = vor.u32 %v110109, %v110108 (stack46)
        %v110111 = vxor.u32 %v110110, %v110106 (stack47)
        %v110114 = vadd.s32 %v110111, %v110106 (stack39)
        %v110116 = vshll.u32 %v110111, 16 (stack44)
        %v110117 = vshrl.u32 %v110111, 16 (stack45)
        %v110118 = vor.u32 %v110117, %v110116 (stack46)
        %v110119 = vxor.u32 %v110118, %v110114 (stack47)
        %v110122 = vadd.s32 %v110119, %v110114 (stack39)
        %v110126 = vadd.s32 %v110122, %v9 (stack39)
        %v110128 = vshll.u32 %v110119, 24 (stack44)
        %v110129 = vshrl.u32 %v110119, 8 (stack45)
        %v110130 = vor.u32 %v110129, %v110128 (stack46)
        %v110131 = vxor.u32 %v110130, %v110122 (stack47)
        %v110134 = vadd.s32 %v110131, %v8 (stack39)
        %v110138 = vadd.s32 4, %v110134 (stack39)
        %v110142 = vadd.s32 %v110138, %v110126 (stack39)
        %v110144 = vshll.u32 %v110138, 13 (stack44)
        %v110145 = vshrl.u32 %v110138, 19 (stack45)
        %v110146 = vor.u32 %v110145, %v110144 (stack46)
        %v110147 = vxor.u32 %v110146, %v110142 (stack47)
        %v110150 = vadd.s32 %v110147, %v110142 (stack39)
        %v110152 = vshll.u32 %v110147, 15 (stack44)
        %v110153 = vshrl.u32 %v110147, 17 (stack45)
        %v110154 = vor.u32 %v110153, %v110152 (stack46)
        %v110155 = vxor.u32 %v110154, %v110150 (stack47)
        %v110158 = vadd.s32 %v110155, %v110150 (stack39)
        %v110160 = vshll.u32 %v110155, 26 (stack44)
        %v110161 = vshrl.u32 %v110155, 6 (stack45)
        %v110162 = vor.u32 %v110161, %v110160 (stack46)
        %v110163 = vxor.u32 %v110162, %v110158 (stack47)
        %v110166 = vadd.s32 %v110163, %v110158 (stack39)
        %v110170 = vadd.s32 %v110166, %v8 (stack39)
        %v110172 = vshll.u32 %v110163, 6 (stack44)
        %v110173 = vshrl.u32 %v110163, 26 (stack45)
        %v110174 = vor.u32 %v110173, %v110172 (stack46)
        %v110175 = vxor.u32 %v110174, %v110166 (stack47)
        %v110178 = vadd.s32 %v110175, %v10 (stack39)
        %v110182 = vadd.s32 5, %v110178 (stack39)
        %v110184 = vxor.u32 %v110182, %v110170 (stack47)
        %v110185 = vand.u32.u8 255, %v110184 (stack48)
        %v110186 = vand.u32 65535, %v110185 (stack49)
        %v110187 = vshrl.u32 %v110186, 1 (stack50)
        %v110188 = vor.u32 16256, %v110187 (stack46)
        %v110189 = vand.u32.u16 65535, %v110188 (stack51)
        %v120334 = vadd.low.f32.bf16 -1.0, %v110189 (stack52)
        %v110198 = vmul.f32 2.0, %v120334 (stack53)
        %v110202 = vadd.f32 -0.99609375, %v110198 (stack52)
        %v110206 = vmax.f32 %v110202, -0.99609375 (stack54)
        %v110208 = vand.u32 2147483647, %v110206 (stack55)
        %vm110211 = vcmp.eq.f32.partialorder %v110208, 1.0 (stack56)
        %v110216 = vmul.f32 inf, %v110206 (stack53)
        %v110218 = vxor.u32 2147483648, %v110206 (stack57)
        %v110221 = vmul.f32 %v110218, %v110206 (stack53)
        %v110223 = vadd.f32 1.0, %v110221 (stack58)
        %v110224 = vlog2.pop %v110223 (stack59)
        %v110225 = vmul.f32 0.6931472, %v110224 (stack60)
        %v110226 = vmul.f32 -0.5, %v110221 (stack61)
        %v110227 = vadd.f32 1.0, %v110226 (stack62)
        %v110228 = vmul.f32 %v110227, %v110221 (stack63)
        %v110229 = vand.u32 2147483647, %v110221 (stack64)
        %vm110230 = vcmp.lt.f32.partialorder %v110229, 0.0004427343 (stack65)
        %v110231 = vsel /*vm=*/%vm110230, /*on_true_vy=*/%v110228, /*on_false_vx=*/%v110225 (stack66)
        %v110232 = vxor.u32 2147483648, %v110231 (stack57)
        %vm110235 = vcmp.lt.f32.partialorder %v110232, 5.0 (stack56)
        %v110240 = vsel /*vm=*/%vm110235, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v110244 = vsel /*vm=*/%vm110235, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v110248 = vsel /*vm=*/%vm110235, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v110252 = vsel /*vm=*/%vm110235, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v110256 = vsel /*vm=*/%vm110235, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v110260 = vsel /*vm=*/%vm110235, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v110264 = vsel /*vm=*/%vm110235, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v110268 = vsel /*vm=*/%vm110235, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v110272 = vsel /*vm=*/%vm110235, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v110276 = vadd.f32 -2.5, %v110232 (stack52)
        %v110278 = vrsqrt.pop %v110232 (stack67)
        %v110279 = vmul.f32 %v110278, %v110232 (stack68)
        %vm110280 = vcmp.eq.f32.partialorder %v110232, inf (stack69)
        %v110281 = vsel /*vm=*/%vm110280, /*on_true_vy=*/%v110232, /*on_false_vx=*/%v110279 (stack70)
        %vm110282 = vcmp.eq.f32.partialorder %v110232, 0.0 (stack71)
        %v110283 = vand.u32 2147483648, %v110232 (stack72)
        %v110284 = vsel /*vm=*/%vm110282, /*on_true_vy=*/%v110283, /*on_false_vx=*/%v110281 (stack73)
        %v110287 = vadd.f32 -3.0, %v110284 (stack52)
        %v110291 = vsel /*vm=*/%vm110235, /*on_true_vy=*/%v110276, /*on_false_vx=*/%v110287 (stack43)
        %v110295 = vmul.f32 %v110291, %v110272 (stack53)
        %v110299 = vadd.f32 %v110295, %v110268 (stack52)
        %v110303 = vmul.f32 %v110299, %v110291 (stack53)
        %v110307 = vadd.f32 %v110303, %v110264 (stack52)
        %v110311 = vmul.f32 %v110307, %v110291 (stack53)
        %v110315 = vadd.f32 %v110311, %v110260 (stack52)
        %v110319 = vmul.f32 %v110315, %v110291 (stack53)
        %v110323 = vadd.f32 %v110319, %v110256 (stack52)
        %v110327 = vmul.f32 %v110323, %v110291 (stack53)
        %v110331 = vadd.f32 %v110327, %v110252 (stack52)
        %v110335 = vmul.f32 %v110331, %v110291 (stack53)
        %v110339 = vadd.f32 %v110335, %v110248 (stack52)
        %v110343 = vmul.f32 %v110339, %v110291 (stack53)
        %v110347 = vadd.f32 %v110343, %v110244 (stack52)
        %v110351 = vmul.f32 %v110347, %v110291 (stack53)
        %v110355 = vadd.f32 %v110351, %v110240 (stack52)
        %v110359 = vmul.f32 %v110355, %v110206 (stack53)
        %v110363 = vsel /*vm=*/%vm110211, /*on_true_vy=*/%v110216, /*on_false_vx=*/%v110359 (stack43)
        %v110367 = vmul.f32 1.4140625, %v110363 (stack53)
        %v110370 = vpack.c.bf16 0.0, %v110367 (stack74)
        %120335 = vst [vmem:[%s280 + $0x1f4] sm:$0xf] /*vst_source=*/%v110370 (stack75)
        %v110374 = vadd.s32 %v108527, %v2355 (stack39)
        %v110384 = vadd.s32 %v110374, %v415 (stack39)
        %vm110388 = vcmp.lt.u32.totalorder %v110384, %v110374 (stack42)
        %vm110393 = vcmp.lt.u32.totalorder %v110374, %v2355 (stack42)
        %v110398 = vadd.s32 %v108510, %v2342 (stack39)
        %v110402 = vadd.s32 1, %v110398 (stack39)
        %v110406 = vsel /*vm=*/%vm110393, /*on_true_vy=*/%v110402, /*on_false_vx=*/%v110398 (stack43)
        %v110410 = vadd.s32 1, %v110406 (stack39)
        %v110414 = vsel /*vm=*/%vm110388, /*on_true_vy=*/%v110410, /*on_false_vx=*/%v110406 (stack43)
        %v110419 = vadd.s32 %v110414, %v10 (stack39)
        %v110423 = vadd.s32 %v110384, %v9 (stack39)
        %v110427 = vadd.s32 %v110423, %v110419 (stack39)
        %v110429 = vshll.u32 %v110423, 13 (stack44)
        %v110430 = vshrl.u32 %v110423, 19 (stack45)
        %v110431 = vor.u32 %v110430, %v110429 (stack46)
        %v110432 = vxor.u32 %v110431, %v110427 (stack47)
        %v110435 = vadd.s32 %v110432, %v110427 (stack39)
        %v110437 = vshll.u32 %v110432, 15 (stack44)
        %v110438 = vshrl.u32 %v110432, 17 (stack45)
        %v110439 = vor.u32 %v110438, %v110437 (stack46)
        %v110440 = vxor.u32 %v110439, %v110435 (stack47)
        %v110443 = vadd.s32 %v110440, %v110435 (stack39)
        %v110445 = vshll.u32 %v110440, 26 (stack44)
        %v110446 = vshrl.u32 %v110440, 6 (stack45)
        %v110447 = vor.u32 %v110446, %v110445 (stack46)
        %v110448 = vxor.u32 %v110447, %v110443 (stack47)
        %v110451 = vadd.s32 %v110448, %v110443 (stack39)
        %v110455 = vadd.s32 %v110451, %v9 (stack39)
        %v110457 = vshll.u32 %v110448, 6 (stack44)
        %v110458 = vshrl.u32 %v110448, 26 (stack45)
        %v110459 = vor.u32 %v110458, %v110457 (stack46)
        %v110460 = vxor.u32 %v110459, %v110451 (stack47)
        %v110463 = vadd.s32 %v110460, %v8 (stack39)
        %v110467 = vadd.s32 1, %v110463 (stack39)
        %v110471 = vadd.s32 %v110467, %v110455 (stack39)
        %v110473 = vshll.u32 %v110467, 17 (stack44)
        %v110474 = vshrl.u32 %v110467, 15 (stack45)
        %v110475 = vor.u32 %v110474, %v110473 (stack46)
        %v110476 = vxor.u32 %v110475, %v110471 (stack47)
        %v110479 = vadd.s32 %v110476, %v110471 (stack39)
        %v110481 = vshll.u32 %v110476, 29 (stack44)
        %v110482 = vshrl.u32 %v110476, 3 (stack45)
        %v110483 = vor.u32 %v110482, %v110481 (stack46)
        %v110484 = vxor.u32 %v110483, %v110479 (stack47)
        %v110487 = vadd.s32 %v110484, %v110479 (stack39)
        %v110489 = vshll.u32 %v110484, 16 (stack44)
        %v110490 = vshrl.u32 %v110484, 16 (stack45)
        %v110491 = vor.u32 %v110490, %v110489 (stack46)
        %v110492 = vxor.u32 %v110491, %v110487 (stack47)
        %v110495 = vadd.s32 %v110492, %v110487 (stack39)
        %v110499 = vadd.s32 %v110495, %v8 (stack39)
        %v110501 = vshll.u32 %v110492, 24 (stack44)
        %v110502 = vshrl.u32 %v110492, 8 (stack45)
        %v110503 = vor.u32 %v110502, %v110501 (stack46)
        %v110504 = vxor.u32 %v110503, %v110495 (stack47)
        %v110507 = vadd.s32 %v110504, %v10 (stack39)
        %v110511 = vadd.s32 2, %v110507 (stack39)
        %v110515 = vadd.s32 %v110511, %v110499 (stack39)
        %v110517 = vshll.u32 %v110511, 13 (stack44)
        %v110518 = vshrl.u32 %v110511, 19 (stack45)
        %v110519 = vor.u32 %v110518, %v110517 (stack46)
        %v110520 = vxor.u32 %v110519, %v110515 (stack47)
        %v110523 = vadd.s32 %v110520, %v110515 (stack39)
        %v110525 = vshll.u32 %v110520, 15 (stack44)
        %v110526 = vshrl.u32 %v110520, 17 (stack45)
        %v110527 = vor.u32 %v110526, %v110525 (stack46)
        %v110528 = vxor.u32 %v110527, %v110523 (stack47)
        %v110531 = vadd.s32 %v110528, %v110523 (stack39)
        %v110533 = vshll.u32 %v110528, 26 (stack44)
        %v110534 = vshrl.u32 %v110528, 6 (stack45)
        %v110535 = vor.u32 %v110534, %v110533 (stack46)
        %v110536 = vxor.u32 %v110535, %v110531 (stack47)
        %v110539 = vadd.s32 %v110536, %v110531 (stack39)
        %v110543 = vadd.s32 %v110539, %v10 (stack39)
        %v110545 = vshll.u32 %v110536, 6 (stack44)
        %v110546 = vshrl.u32 %v110536, 26 (stack45)
        %v110547 = vor.u32 %v110546, %v110545 (stack46)
        %v110548 = vxor.u32 %v110547, %v110539 (stack47)
        %v110551 = vadd.s32 %v110548, %v9 (stack39)
        %v110555 = vadd.s32 3, %v110551 (stack39)
        %v110559 = vadd.s32 %v110555, %v110543 (stack39)
        %v110561 = vshll.u32 %v110555, 17 (stack44)
        %v110562 = vshrl.u32 %v110555, 15 (stack45)
        %v110563 = vor.u32 %v110562, %v110561 (stack46)
        %v110564 = vxor.u32 %v110563, %v110559 (stack47)
        %v110567 = vadd.s32 %v110564, %v110559 (stack39)
        %v110569 = vshll.u32 %v110564, 29 (stack44)
        %v110570 = vshrl.u32 %v110564, 3 (stack45)
        %v110571 = vor.u32 %v110570, %v110569 (stack46)
        %v110572 = vxor.u32 %v110571, %v110567 (stack47)
        %v110575 = vadd.s32 %v110572, %v110567 (stack39)
        %v110577 = vshll.u32 %v110572, 16 (stack44)
        %v110578 = vshrl.u32 %v110572, 16 (stack45)
        %v110579 = vor.u32 %v110578, %v110577 (stack46)
        %v110580 = vxor.u32 %v110579, %v110575 (stack47)
        %v110583 = vadd.s32 %v110580, %v110575 (stack39)
        %v110587 = vadd.s32 %v110583, %v9 (stack39)
        %v110589 = vshll.u32 %v110580, 24 (stack44)
        %v110590 = vshrl.u32 %v110580, 8 (stack45)
        %v110591 = vor.u32 %v110590, %v110589 (stack46)
        %v110592 = vxor.u32 %v110591, %v110583 (stack47)
        %v110595 = vadd.s32 %v110592, %v8 (stack39)
        %v110599 = vadd.s32 4, %v110595 (stack39)
        %v110603 = vadd.s32 %v110599, %v110587 (stack39)
        %v110605 = vshll.u32 %v110599, 13 (stack44)
        %v110606 = vshrl.u32 %v110599, 19 (stack45)
        %v110607 = vor.u32 %v110606, %v110605 (stack46)
        %v110608 = vxor.u32 %v110607, %v110603 (stack47)
        %v110611 = vadd.s32 %v110608, %v110603 (stack39)
        %v110613 = vshll.u32 %v110608, 15 (stack44)
        %v110614 = vshrl.u32 %v110608, 17 (stack45)
        %v110615 = vor.u32 %v110614, %v110613 (stack46)
        %v110616 = vxor.u32 %v110615, %v110611 (stack47)
        %v110619 = vadd.s32 %v110616, %v110611 (stack39)
        %v110621 = vshll.u32 %v110616, 26 (stack44)
        %v110622 = vshrl.u32 %v110616, 6 (stack45)
        %v110623 = vor.u32 %v110622, %v110621 (stack46)
        %v110624 = vxor.u32 %v110623, %v110619 (stack47)
        %v110627 = vadd.s32 %v110624, %v110619 (stack39)
        %v110631 = vadd.s32 %v110627, %v8 (stack39)
        %v110633 = vshll.u32 %v110624, 6 (stack44)
        %v110634 = vshrl.u32 %v110624, 26 (stack45)
        %v110635 = vor.u32 %v110634, %v110633 (stack46)
        %v110636 = vxor.u32 %v110635, %v110627 (stack47)
        %v110639 = vadd.s32 %v110636, %v10 (stack39)
        %v110643 = vadd.s32 5, %v110639 (stack39)
        %v110645 = vxor.u32 %v110643, %v110631 (stack47)
        %v110646 = vand.u32.u8 255, %v110645 (stack48)
        %v110647 = vand.u32 65535, %v110646 (stack49)
        %v110648 = vshrl.u32 %v110647, 1 (stack50)
        %v110649 = vor.u32 16256, %v110648 (stack46)
        %v110650 = vand.u32.u16 65535, %v110649 (stack51)
        %v120336 = vadd.low.f32.bf16 -1.0, %v110650 (stack52)
        %v110659 = vmul.f32 2.0, %v120336 (stack53)
        %v110663 = vadd.f32 -0.99609375, %v110659 (stack52)
        %v110667 = vmax.f32 %v110663, -0.99609375 (stack54)
        %v110669 = vand.u32 2147483647, %v110667 (stack55)
        %vm110672 = vcmp.eq.f32.partialorder %v110669, 1.0 (stack56)
        %v110677 = vmul.f32 inf, %v110667 (stack53)
        %v110679 = vxor.u32 2147483648, %v110667 (stack57)
        %v110682 = vmul.f32 %v110679, %v110667 (stack53)
        %v110684 = vadd.f32 1.0, %v110682 (stack58)
        %v110685 = vlog2.pop %v110684 (stack59)
        %v110686 = vmul.f32 0.6931472, %v110685 (stack60)
        %v110687 = vmul.f32 -0.5, %v110682 (stack61)
        %v110688 = vadd.f32 1.0, %v110687 (stack62)
        %v110689 = vmul.f32 %v110688, %v110682 (stack63)
        %v110690 = vand.u32 2147483647, %v110682 (stack64)
        %vm110691 = vcmp.lt.f32.partialorder %v110690, 0.0004427343 (stack65)
        %v110692 = vsel /*vm=*/%vm110691, /*on_true_vy=*/%v110689, /*on_false_vx=*/%v110686 (stack66)
        %v110693 = vxor.u32 2147483648, %v110692 (stack57)
        %vm110696 = vcmp.lt.f32.partialorder %v110693, 5.0 (stack56)
        %v110701 = vsel /*vm=*/%vm110696, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v110705 = vsel /*vm=*/%vm110696, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v110709 = vsel /*vm=*/%vm110696, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v110713 = vsel /*vm=*/%vm110696, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v110717 = vsel /*vm=*/%vm110696, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v110721 = vsel /*vm=*/%vm110696, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v110725 = vsel /*vm=*/%vm110696, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v110729 = vsel /*vm=*/%vm110696, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v110733 = vsel /*vm=*/%vm110696, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v110737 = vadd.f32 -2.5, %v110693 (stack52)
        %v110739 = vrsqrt.pop %v110693 (stack67)
        %v110740 = vmul.f32 %v110739, %v110693 (stack68)
        %vm110741 = vcmp.eq.f32.partialorder %v110693, inf (stack69)
        %v110742 = vsel /*vm=*/%vm110741, /*on_true_vy=*/%v110693, /*on_false_vx=*/%v110740 (stack70)
        %vm110743 = vcmp.eq.f32.partialorder %v110693, 0.0 (stack71)
        %v110744 = vand.u32 2147483648, %v110693 (stack72)
        %v110745 = vsel /*vm=*/%vm110743, /*on_true_vy=*/%v110744, /*on_false_vx=*/%v110742 (stack73)
        %v110748 = vadd.f32 -3.0, %v110745 (stack52)
        %v110752 = vsel /*vm=*/%vm110696, /*on_true_vy=*/%v110737, /*on_false_vx=*/%v110748 (stack43)
        %v110756 = vmul.f32 %v110752, %v110733 (stack53)
        %v110760 = vadd.f32 %v110756, %v110729 (stack52)
        %v110764 = vmul.f32 %v110760, %v110752 (stack53)
        %v110768 = vadd.f32 %v110764, %v110725 (stack52)
        %v110772 = vmul.f32 %v110768, %v110752 (stack53)
        %v110776 = vadd.f32 %v110772, %v110721 (stack52)
        %v110780 = vmul.f32 %v110776, %v110752 (stack53)
        %v110784 = vadd.f32 %v110780, %v110717 (stack52)
        %v110788 = vmul.f32 %v110784, %v110752 (stack53)
        %v110792 = vadd.f32 %v110788, %v110713 (stack52)
        %v110796 = vmul.f32 %v110792, %v110752 (stack53)
        %v110800 = vadd.f32 %v110796, %v110709 (stack52)
        %v110804 = vmul.f32 %v110800, %v110752 (stack53)
        %v110808 = vadd.f32 %v110804, %v110705 (stack52)
        %v110812 = vmul.f32 %v110808, %v110752 (stack53)
        %v110816 = vadd.f32 %v110812, %v110701 (stack52)
        %v110820 = vmul.f32 %v110816, %v110667 (stack53)
        %v110824 = vsel /*vm=*/%vm110672, /*on_true_vy=*/%v110677, /*on_false_vx=*/%v110820 (stack43)
        %v110828 = vmul.f32 1.4140625, %v110824 (stack53)
        %v110831 = vpack.c.bf16 0.0, %v110828 (stack74)
        %120337 = vst [vmem:[%s280 + $0x274] sm:$0xf] /*vst_source=*/%v110831 (stack75)
        %v110835 = vadd.s32 %v108527, %v2842 (stack39)
        %v110845 = vadd.s32 %v110835, %v415 (stack39)
        %vm110849 = vcmp.lt.u32.totalorder %v110845, %v110835 (stack42)
        %vm110854 = vcmp.lt.u32.totalorder %v110835, %v2842 (stack42)
        %v110859 = vadd.s32 %v108510, %v2829 (stack39)
        %v110863 = vadd.s32 1, %v110859 (stack39)
        %v110867 = vsel /*vm=*/%vm110854, /*on_true_vy=*/%v110863, /*on_false_vx=*/%v110859 (stack43)
        %v110871 = vadd.s32 1, %v110867 (stack39)
        %v110875 = vsel /*vm=*/%vm110849, /*on_true_vy=*/%v110871, /*on_false_vx=*/%v110867 (stack43)
        %v110880 = vadd.s32 %v110875, %v10 (stack39)
        %v110884 = vadd.s32 %v110845, %v9 (stack39)
        %v110888 = vadd.s32 %v110884, %v110880 (stack39)
        %v110890 = vshll.u32 %v110884, 13 (stack44)
        %v110891 = vshrl.u32 %v110884, 19 (stack45)
        %v110892 = vor.u32 %v110891, %v110890 (stack46)
        %v110893 = vxor.u32 %v110892, %v110888 (stack47)
        %v110896 = vadd.s32 %v110893, %v110888 (stack39)
        %v110898 = vshll.u32 %v110893, 15 (stack44)
        %v110899 = vshrl.u32 %v110893, 17 (stack45)
        %v110900 = vor.u32 %v110899, %v110898 (stack46)
        %v110901 = vxor.u32 %v110900, %v110896 (stack47)
        %v110904 = vadd.s32 %v110901, %v110896 (stack39)
        %v110906 = vshll.u32 %v110901, 26 (stack44)
        %v110907 = vshrl.u32 %v110901, 6 (stack45)
        %v110908 = vor.u32 %v110907, %v110906 (stack46)
        %v110909 = vxor.u32 %v110908, %v110904 (stack47)
        %v110912 = vadd.s32 %v110909, %v110904 (stack39)
        %v110916 = vadd.s32 %v110912, %v9 (stack39)
        %v110918 = vshll.u32 %v110909, 6 (stack44)
        %v110919 = vshrl.u32 %v110909, 26 (stack45)
        %v110920 = vor.u32 %v110919, %v110918 (stack46)
        %v110921 = vxor.u32 %v110920, %v110912 (stack47)
        %v110924 = vadd.s32 %v110921, %v8 (stack39)
        %v110928 = vadd.s32 1, %v110924 (stack39)
        %v110932 = vadd.s32 %v110928, %v110916 (stack39)
        %v110934 = vshll.u32 %v110928, 17 (stack44)
        %v110935 = vshrl.u32 %v110928, 15 (stack45)
        %v110936 = vor.u32 %v110935, %v110934 (stack46)
        %v110937 = vxor.u32 %v110936, %v110932 (stack47)
        %v110940 = vadd.s32 %v110937, %v110932 (stack39)
        %v110942 = vshll.u32 %v110937, 29 (stack44)
        %v110943 = vshrl.u32 %v110937, 3 (stack45)
        %v110944 = vor.u32 %v110943, %v110942 (stack46)
        %v110945 = vxor.u32 %v110944, %v110940 (stack47)
        %v110948 = vadd.s32 %v110945, %v110940 (stack39)
        %v110950 = vshll.u32 %v110945, 16 (stack44)
        %v110951 = vshrl.u32 %v110945, 16 (stack45)
        %v110952 = vor.u32 %v110951, %v110950 (stack46)
        %v110953 = vxor.u32 %v110952, %v110948 (stack47)
        %v110956 = vadd.s32 %v110953, %v110948 (stack39)
        %v110960 = vadd.s32 %v110956, %v8 (stack39)
        %v110962 = vshll.u32 %v110953, 24 (stack44)
        %v110963 = vshrl.u32 %v110953, 8 (stack45)
        %v110964 = vor.u32 %v110963, %v110962 (stack46)
        %v110965 = vxor.u32 %v110964, %v110956 (stack47)
        %v110968 = vadd.s32 %v110965, %v10 (stack39)
        %v110972 = vadd.s32 2, %v110968 (stack39)
        %v110976 = vadd.s32 %v110972, %v110960 (stack39)
        %v110978 = vshll.u32 %v110972, 13 (stack44)
        %v110979 = vshrl.u32 %v110972, 19 (stack45)
        %v110980 = vor.u32 %v110979, %v110978 (stack46)
        %v110981 = vxor.u32 %v110980, %v110976 (stack47)
        %v110984 = vadd.s32 %v110981, %v110976 (stack39)
        %v110986 = vshll.u32 %v110981, 15 (stack44)
        %v110987 = vshrl.u32 %v110981, 17 (stack45)
        %v110988 = vor.u32 %v110987, %v110986 (stack46)
        %v110989 = vxor.u32 %v110988, %v110984 (stack47)
        %v110992 = vadd.s32 %v110989, %v110984 (stack39)
        %v110994 = vshll.u32 %v110989, 26 (stack44)
        %v110995 = vshrl.u32 %v110989, 6 (stack45)
        %v110996 = vor.u32 %v110995, %v110994 (stack46)
        %v110997 = vxor.u32 %v110996, %v110992 (stack47)
        %v111000 = vadd.s32 %v110997, %v110992 (stack39)
        %v111004 = vadd.s32 %v111000, %v10 (stack39)
        %v111006 = vshll.u32 %v110997, 6 (stack44)
        %v111007 = vshrl.u32 %v110997, 26 (stack45)
        %v111008 = vor.u32 %v111007, %v111006 (stack46)
        %v111009 = vxor.u32 %v111008, %v111000 (stack47)
        %v111012 = vadd.s32 %v111009, %v9 (stack39)
        %v111016 = vadd.s32 3, %v111012 (stack39)
        %v111020 = vadd.s32 %v111016, %v111004 (stack39)
        %v111022 = vshll.u32 %v111016, 17 (stack44)
        %v111023 = vshrl.u32 %v111016, 15 (stack45)
        %v111024 = vor.u32 %v111023, %v111022 (stack46)
        %v111025 = vxor.u32 %v111024, %v111020 (stack47)
        %v111028 = vadd.s32 %v111025, %v111020 (stack39)
        %v111030 = vshll.u32 %v111025, 29 (stack44)
        %v111031 = vshrl.u32 %v111025, 3 (stack45)
        %v111032 = vor.u32 %v111031, %v111030 (stack46)
        %v111033 = vxor.u32 %v111032, %v111028 (stack47)
        %v111036 = vadd.s32 %v111033, %v111028 (stack39)
        %v111038 = vshll.u32 %v111033, 16 (stack44)
        %v111039 = vshrl.u32 %v111033, 16 (stack45)
        %v111040 = vor.u32 %v111039, %v111038 (stack46)
        %v111041 = vxor.u32 %v111040, %v111036 (stack47)
        %v111044 = vadd.s32 %v111041, %v111036 (stack39)
        %v111048 = vadd.s32 %v111044, %v9 (stack39)
        %v111050 = vshll.u32 %v111041, 24 (stack44)
        %v111051 = vshrl.u32 %v111041, 8 (stack45)
        %v111052 = vor.u32 %v111051, %v111050 (stack46)
        %v111053 = vxor.u32 %v111052, %v111044 (stack47)
        %v111056 = vadd.s32 %v111053, %v8 (stack39)
        %v111060 = vadd.s32 4, %v111056 (stack39)
        %v111064 = vadd.s32 %v111060, %v111048 (stack39)
        %v111066 = vshll.u32 %v111060, 13 (stack44)
        %v111067 = vshrl.u32 %v111060, 19 (stack45)
        %v111068 = vor.u32 %v111067, %v111066 (stack46)
        %v111069 = vxor.u32 %v111068, %v111064 (stack47)
        %v111072 = vadd.s32 %v111069, %v111064 (stack39)
        %v111074 = vshll.u32 %v111069, 15 (stack44)
        %v111075 = vshrl.u32 %v111069, 17 (stack45)
        %v111076 = vor.u32 %v111075, %v111074 (stack46)
        %v111077 = vxor.u32 %v111076, %v111072 (stack47)
        %v111080 = vadd.s32 %v111077, %v111072 (stack39)
        %v111082 = vshll.u32 %v111077, 26 (stack44)
        %v111083 = vshrl.u32 %v111077, 6 (stack45)
        %v111084 = vor.u32 %v111083, %v111082 (stack46)
        %v111085 = vxor.u32 %v111084, %v111080 (stack47)
        %v111088 = vadd.s32 %v111085, %v111080 (stack39)
        %v111092 = vadd.s32 %v111088, %v8 (stack39)
        %v111094 = vshll.u32 %v111085, 6 (stack44)
        %v111095 = vshrl.u32 %v111085, 26 (stack45)
        %v111096 = vor.u32 %v111095, %v111094 (stack46)
        %v111097 = vxor.u32 %v111096, %v111088 (stack47)
        %v111100 = vadd.s32 %v111097, %v10 (stack39)
        %v111104 = vadd.s32 5, %v111100 (stack39)
        %v111106 = vxor.u32 %v111104, %v111092 (stack47)
        %v111107 = vand.u32.u8 255, %v111106 (stack48)
        %v111108 = vand.u32 65535, %v111107 (stack49)
        %v111109 = vshrl.u32 %v111108, 1 (stack50)
        %v111110 = vor.u32 16256, %v111109 (stack46)
        %v111111 = vand.u32.u16 65535, %v111110 (stack51)
        %v120338 = vadd.low.f32.bf16 -1.0, %v111111 (stack52)
        %v111120 = vmul.f32 2.0, %v120338 (stack53)
        %v111124 = vadd.f32 -0.99609375, %v111120 (stack52)
        %v111128 = vmax.f32 %v111124, -0.99609375 (stack54)
        %v111130 = vand.u32 2147483647, %v111128 (stack55)
        %vm111133 = vcmp.eq.f32.partialorder %v111130, 1.0 (stack56)
        %v111138 = vmul.f32 inf, %v111128 (stack53)
        %v111140 = vxor.u32 2147483648, %v111128 (stack57)
        %v111143 = vmul.f32 %v111140, %v111128 (stack53)
        %v111145 = vadd.f32 1.0, %v111143 (stack58)
        %v111146 = vlog2.pop %v111145 (stack59)
        %v111147 = vmul.f32 0.6931472, %v111146 (stack60)
        %v111148 = vmul.f32 -0.5, %v111143 (stack61)
        %v111149 = vadd.f32 1.0, %v111148 (stack62)
        %v111150 = vmul.f32 %v111149, %v111143 (stack63)
        %v111151 = vand.u32 2147483647, %v111143 (stack64)
        %vm111152 = vcmp.lt.f32.partialorder %v111151, 0.0004427343 (stack65)
        %v111153 = vsel /*vm=*/%vm111152, /*on_true_vy=*/%v111150, /*on_false_vx=*/%v111147 (stack66)
        %v111154 = vxor.u32 2147483648, %v111153 (stack57)
        %vm111157 = vcmp.lt.f32.partialorder %v111154, 5.0 (stack56)
        %v111162 = vsel /*vm=*/%vm111157, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v111166 = vsel /*vm=*/%vm111157, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v111170 = vsel /*vm=*/%vm111157, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v111174 = vsel /*vm=*/%vm111157, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v111178 = vsel /*vm=*/%vm111157, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v111182 = vsel /*vm=*/%vm111157, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v111186 = vsel /*vm=*/%vm111157, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v111190 = vsel /*vm=*/%vm111157, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v111194 = vsel /*vm=*/%vm111157, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v111198 = vadd.f32 -2.5, %v111154 (stack52)
        %v111200 = vrsqrt.pop %v111154 (stack67)
        %v111201 = vmul.f32 %v111200, %v111154 (stack68)
        %vm111202 = vcmp.eq.f32.partialorder %v111154, inf (stack69)
        %v111203 = vsel /*vm=*/%vm111202, /*on_true_vy=*/%v111154, /*on_false_vx=*/%v111201 (stack70)
        %vm111204 = vcmp.eq.f32.partialorder %v111154, 0.0 (stack71)
        %v111205 = vand.u32 2147483648, %v111154 (stack72)
        %v111206 = vsel /*vm=*/%vm111204, /*on_true_vy=*/%v111205, /*on_false_vx=*/%v111203 (stack73)
        %v111209 = vadd.f32 -3.0, %v111206 (stack52)
        %v111213 = vsel /*vm=*/%vm111157, /*on_true_vy=*/%v111198, /*on_false_vx=*/%v111209 (stack43)
        %v111217 = vmul.f32 %v111213, %v111194 (stack53)
        %v111221 = vadd.f32 %v111217, %v111190 (stack52)
        %v111225 = vmul.f32 %v111221, %v111213 (stack53)
        %v111229 = vadd.f32 %v111225, %v111186 (stack52)
        %v111233 = vmul.f32 %v111229, %v111213 (stack53)
        %v111237 = vadd.f32 %v111233, %v111182 (stack52)
        %v111241 = vmul.f32 %v111237, %v111213 (stack53)
        %v111245 = vadd.f32 %v111241, %v111178 (stack52)
        %v111249 = vmul.f32 %v111245, %v111213 (stack53)
        %v111253 = vadd.f32 %v111249, %v111174 (stack52)
        %v111257 = vmul.f32 %v111253, %v111213 (stack53)
        %v111261 = vadd.f32 %v111257, %v111170 (stack52)
        %v111265 = vmul.f32 %v111261, %v111213 (stack53)
        %v111269 = vadd.f32 %v111265, %v111166 (stack52)
        %v111273 = vmul.f32 %v111269, %v111213 (stack53)
        %v111277 = vadd.f32 %v111273, %v111162 (stack52)
        %v111281 = vmul.f32 %v111277, %v111128 (stack53)
        %v111285 = vsel /*vm=*/%vm111133, /*on_true_vy=*/%v111138, /*on_false_vx=*/%v111281 (stack43)
        %v111289 = vmul.f32 1.4140625, %v111285 (stack53)
        %v111292 = vpack.c.bf16 0.0, %v111289 (stack74)
        %120339 = vst [vmem:[%s280 + $0x2f4] sm:$0xf] /*vst_source=*/%v111292 (stack75)
        %v111296 = vadd.s32 %v108527, %v3329 (stack39)
        %v111306 = vadd.s32 %v111296, %v415 (stack39)
        %vm111310 = vcmp.lt.u32.totalorder %v111306, %v111296 (stack42)
        %vm111315 = vcmp.lt.u32.totalorder %v111296, %v3329 (stack42)
        %v111320 = vadd.s32 %v108510, %v3316 (stack39)
        %v111324 = vadd.s32 1, %v111320 (stack39)
        %v111328 = vsel /*vm=*/%vm111315, /*on_true_vy=*/%v111324, /*on_false_vx=*/%v111320 (stack43)
        %v111332 = vadd.s32 1, %v111328 (stack39)
        %v111336 = vsel /*vm=*/%vm111310, /*on_true_vy=*/%v111332, /*on_false_vx=*/%v111328 (stack43)
        %v111341 = vadd.s32 %v111336, %v10 (stack39)
        %v111345 = vadd.s32 %v111306, %v9 (stack39)
        %v111349 = vadd.s32 %v111345, %v111341 (stack39)
        %v111351 = vshll.u32 %v111345, 13 (stack44)
        %v111352 = vshrl.u32 %v111345, 19 (stack45)
        %v111353 = vor.u32 %v111352, %v111351 (stack46)
        %v111354 = vxor.u32 %v111353, %v111349 (stack47)
        %v111357 = vadd.s32 %v111354, %v111349 (stack39)
        %v111359 = vshll.u32 %v111354, 15 (stack44)
        %v111360 = vshrl.u32 %v111354, 17 (stack45)
        %v111361 = vor.u32 %v111360, %v111359 (stack46)
        %v111362 = vxor.u32 %v111361, %v111357 (stack47)
        %v111365 = vadd.s32 %v111362, %v111357 (stack39)
        %v111367 = vshll.u32 %v111362, 26 (stack44)
        %v111368 = vshrl.u32 %v111362, 6 (stack45)
        %v111369 = vor.u32 %v111368, %v111367 (stack46)
        %v111370 = vxor.u32 %v111369, %v111365 (stack47)
        %v111373 = vadd.s32 %v111370, %v111365 (stack39)
        %v111377 = vadd.s32 %v111373, %v9 (stack39)
        %v111379 = vshll.u32 %v111370, 6 (stack44)
        %v111380 = vshrl.u32 %v111370, 26 (stack45)
        %v111381 = vor.u32 %v111380, %v111379 (stack46)
        %v111382 = vxor.u32 %v111381, %v111373 (stack47)
        %v111385 = vadd.s32 %v111382, %v8 (stack39)
        %v111389 = vadd.s32 1, %v111385 (stack39)
        %v111393 = vadd.s32 %v111389, %v111377 (stack39)
        %v111395 = vshll.u32 %v111389, 17 (stack44)
        %v111396 = vshrl.u32 %v111389, 15 (stack45)
        %v111397 = vor.u32 %v111396, %v111395 (stack46)
        %v111398 = vxor.u32 %v111397, %v111393 (stack47)
        %v111401 = vadd.s32 %v111398, %v111393 (stack39)
        %v111403 = vshll.u32 %v111398, 29 (stack44)
        %v111404 = vshrl.u32 %v111398, 3 (stack45)
        %v111405 = vor.u32 %v111404, %v111403 (stack46)
        %v111406 = vxor.u32 %v111405, %v111401 (stack47)
        %v111409 = vadd.s32 %v111406, %v111401 (stack39)
        %v111411 = vshll.u32 %v111406, 16 (stack44)
        %v111412 = vshrl.u32 %v111406, 16 (stack45)
        %v111413 = vor.u32 %v111412, %v111411 (stack46)
        %v111414 = vxor.u32 %v111413, %v111409 (stack47)
        %v111417 = vadd.s32 %v111414, %v111409 (stack39)
        %v111421 = vadd.s32 %v111417, %v8 (stack39)
        %v111423 = vshll.u32 %v111414, 24 (stack44)
        %v111424 = vshrl.u32 %v111414, 8 (stack45)
        %v111425 = vor.u32 %v111424, %v111423 (stack46)
        %v111426 = vxor.u32 %v111425, %v111417 (stack47)
        %v111429 = vadd.s32 %v111426, %v10 (stack39)
        %v111433 = vadd.s32 2, %v111429 (stack39)
        %v111437 = vadd.s32 %v111433, %v111421 (stack39)
        %v111439 = vshll.u32 %v111433, 13 (stack44)
        %v111440 = vshrl.u32 %v111433, 19 (stack45)
        %v111441 = vor.u32 %v111440, %v111439 (stack46)
        %v111442 = vxor.u32 %v111441, %v111437 (stack47)
        %v111445 = vadd.s32 %v111442, %v111437 (stack39)
        %v111447 = vshll.u32 %v111442, 15 (stack44)
        %v111448 = vshrl.u32 %v111442, 17 (stack45)
        %v111449 = vor.u32 %v111448, %v111447 (stack46)
        %v111450 = vxor.u32 %v111449, %v111445 (stack47)
        %v111453 = vadd.s32 %v111450, %v111445 (stack39)
        %v111455 = vshll.u32 %v111450, 26 (stack44)
        %v111456 = vshrl.u32 %v111450, 6 (stack45)
        %v111457 = vor.u32 %v111456, %v111455 (stack46)
        %v111458 = vxor.u32 %v111457, %v111453 (stack47)
        %v111461 = vadd.s32 %v111458, %v111453 (stack39)
        %v111465 = vadd.s32 %v111461, %v10 (stack39)
        %v111467 = vshll.u32 %v111458, 6 (stack44)
        %v111468 = vshrl.u32 %v111458, 26 (stack45)
        %v111469 = vor.u32 %v111468, %v111467 (stack46)
        %v111470 = vxor.u32 %v111469, %v111461 (stack47)
        %v111473 = vadd.s32 %v111470, %v9 (stack39)
        %v111477 = vadd.s32 3, %v111473 (stack39)
        %v111481 = vadd.s32 %v111477, %v111465 (stack39)
        %v111483 = vshll.u32 %v111477, 17 (stack44)
        %v111484 = vshrl.u32 %v111477, 15 (stack45)
        %v111485 = vor.u32 %v111484, %v111483 (stack46)
        %v111486 = vxor.u32 %v111485, %v111481 (stack47)
        %v111489 = vadd.s32 %v111486, %v111481 (stack39)
        %v111491 = vshll.u32 %v111486, 29 (stack44)
        %v111492 = vshrl.u32 %v111486, 3 (stack45)
        %v111493 = vor.u32 %v111492, %v111491 (stack46)
        %v111494 = vxor.u32 %v111493, %v111489 (stack47)
        %v111497 = vadd.s32 %v111494, %v111489 (stack39)
        %v111499 = vshll.u32 %v111494, 16 (stack44)
        %v111500 = vshrl.u32 %v111494, 16 (stack45)
        %v111501 = vor.u32 %v111500, %v111499 (stack46)
        %v111502 = vxor.u32 %v111501, %v111497 (stack47)
        %v111505 = vadd.s32 %v111502, %v111497 (stack39)
        %v111509 = vadd.s32 %v111505, %v9 (stack39)
        %v111511 = vshll.u32 %v111502, 24 (stack44)
        %v111512 = vshrl.u32 %v111502, 8 (stack45)
        %v111513 = vor.u32 %v111512, %v111511 (stack46)
        %v111514 = vxor.u32 %v111513, %v111505 (stack47)
        %v111517 = vadd.s32 %v111514, %v8 (stack39)
        %v111521 = vadd.s32 4, %v111517 (stack39)
        %v111525 = vadd.s32 %v111521, %v111509 (stack39)
        %v111527 = vshll.u32 %v111521, 13 (stack44)
        %v111528 = vshrl.u32 %v111521, 19 (stack45)
        %v111529 = vor.u32 %v111528, %v111527 (stack46)
        %v111530 = vxor.u32 %v111529, %v111525 (stack47)
        %v111533 = vadd.s32 %v111530, %v111525 (stack39)
        %v111535 = vshll.u32 %v111530, 15 (stack44)
        %v111536 = vshrl.u32 %v111530, 17 (stack45)
        %v111537 = vor.u32 %v111536, %v111535 (stack46)
        %v111538 = vxor.u32 %v111537, %v111533 (stack47)
        %v111541 = vadd.s32 %v111538, %v111533 (stack39)
        %v111543 = vshll.u32 %v111538, 26 (stack44)
        %v111544 = vshrl.u32 %v111538, 6 (stack45)
        %v111545 = vor.u32 %v111544, %v111543 (stack46)
        %v111546 = vxor.u32 %v111545, %v111541 (stack47)
        %v111549 = vadd.s32 %v111546, %v111541 (stack39)
        %v111553 = vadd.s32 %v111549, %v8 (stack39)
        %v111555 = vshll.u32 %v111546, 6 (stack44)
        %v111556 = vshrl.u32 %v111546, 26 (stack45)
        %v111557 = vor.u32 %v111556, %v111555 (stack46)
        %v111558 = vxor.u32 %v111557, %v111549 (stack47)
        %v111561 = vadd.s32 %v111558, %v10 (stack39)
        %v111565 = vadd.s32 5, %v111561 (stack39)
        %v111567 = vxor.u32 %v111565, %v111553 (stack47)
        %v111568 = vand.u32.u8 255, %v111567 (stack48)
        %v111569 = vand.u32 65535, %v111568 (stack49)
        %v111570 = vshrl.u32 %v111569, 1 (stack50)
        %v111571 = vor.u32 16256, %v111570 (stack46)
        %v111572 = vand.u32.u16 65535, %v111571 (stack51)
        %v120340 = vadd.low.f32.bf16 -1.0, %v111572 (stack52)
        %v111581 = vmul.f32 2.0, %v120340 (stack53)
        %v111585 = vadd.f32 -0.99609375, %v111581 (stack52)
        %v111589 = vmax.f32 %v111585, -0.99609375 (stack54)
        %v111591 = vand.u32 2147483647, %v111589 (stack55)
        %vm111594 = vcmp.eq.f32.partialorder %v111591, 1.0 (stack56)
        %v111599 = vmul.f32 inf, %v111589 (stack53)
        %v111601 = vxor.u32 2147483648, %v111589 (stack57)
        %v111604 = vmul.f32 %v111601, %v111589 (stack53)
        %v111606 = vadd.f32 1.0, %v111604 (stack58)
        %v111607 = vlog2.pop %v111606 (stack59)
        %v111608 = vmul.f32 0.6931472, %v111607 (stack60)
        %v111609 = vmul.f32 -0.5, %v111604 (stack61)
        %v111610 = vadd.f32 1.0, %v111609 (stack62)
        %v111611 = vmul.f32 %v111610, %v111604 (stack63)
        %v111612 = vand.u32 2147483647, %v111604 (stack64)
        %vm111613 = vcmp.lt.f32.partialorder %v111612, 0.0004427343 (stack65)
        %v111614 = vsel /*vm=*/%vm111613, /*on_true_vy=*/%v111611, /*on_false_vx=*/%v111608 (stack66)
        %v111615 = vxor.u32 2147483648, %v111614 (stack57)
        %vm111618 = vcmp.lt.f32.partialorder %v111615, 5.0 (stack56)
        %v111623 = vsel /*vm=*/%vm111618, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v111627 = vsel /*vm=*/%vm111618, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v111631 = vsel /*vm=*/%vm111618, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v111635 = vsel /*vm=*/%vm111618, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v111639 = vsel /*vm=*/%vm111618, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v111643 = vsel /*vm=*/%vm111618, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v111647 = vsel /*vm=*/%vm111618, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v111651 = vsel /*vm=*/%vm111618, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v111655 = vsel /*vm=*/%vm111618, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v111659 = vadd.f32 -2.5, %v111615 (stack52)
        %v111661 = vrsqrt.pop %v111615 (stack67)
        %v111662 = vmul.f32 %v111661, %v111615 (stack68)
        %vm111663 = vcmp.eq.f32.partialorder %v111615, inf (stack69)
        %v111664 = vsel /*vm=*/%vm111663, /*on_true_vy=*/%v111615, /*on_false_vx=*/%v111662 (stack70)
        %vm111665 = vcmp.eq.f32.partialorder %v111615, 0.0 (stack71)
        %v111666 = vand.u32 2147483648, %v111615 (stack72)
        %v111667 = vsel /*vm=*/%vm111665, /*on_true_vy=*/%v111666, /*on_false_vx=*/%v111664 (stack73)
        %v111670 = vadd.f32 -3.0, %v111667 (stack52)
        %v111674 = vsel /*vm=*/%vm111618, /*on_true_vy=*/%v111659, /*on_false_vx=*/%v111670 (stack43)
        %v111678 = vmul.f32 %v111674, %v111655 (stack53)
        %v111682 = vadd.f32 %v111678, %v111651 (stack52)
        %v111686 = vmul.f32 %v111682, %v111674 (stack53)
        %v111690 = vadd.f32 %v111686, %v111647 (stack52)
        %v111694 = vmul.f32 %v111690, %v111674 (stack53)
        %v111698 = vadd.f32 %v111694, %v111643 (stack52)
        %v111702 = vmul.f32 %v111698, %v111674 (stack53)
        %v111706 = vadd.f32 %v111702, %v111639 (stack52)
        %v111710 = vmul.f32 %v111706, %v111674 (stack53)
        %v111714 = vadd.f32 %v111710, %v111635 (stack52)
        %v111718 = vmul.f32 %v111714, %v111674 (stack53)
        %v111722 = vadd.f32 %v111718, %v111631 (stack52)
        %v111726 = vmul.f32 %v111722, %v111674 (stack53)
        %v111730 = vadd.f32 %v111726, %v111627 (stack52)
        %v111734 = vmul.f32 %v111730, %v111674 (stack53)
        %v111738 = vadd.f32 %v111734, %v111623 (stack52)
        %v111742 = vmul.f32 %v111738, %v111589 (stack53)
        %v111746 = vsel /*vm=*/%vm111594, /*on_true_vy=*/%v111599, /*on_false_vx=*/%v111742 (stack43)
        %v111750 = vmul.f32 1.4140625, %v111746 (stack53)
        %v111753 = vpack.c.bf16 0.0, %v111750 (stack74)
        %120341 = vst [vmem:[%s280 + $0x374] sm:$0xf] /*vst_source=*/%v111753 (stack75)
        %v111757 = vadd.s32 %v108527, %v3816 (stack39)
        %v111767 = vadd.s32 %v111757, %v415 (stack39)
        %vm111771 = vcmp.lt.u32.totalorder %v111767, %v111757 (stack42)
        %vm111776 = vcmp.lt.u32.totalorder %v111757, %v3816 (stack42)
        %v111781 = vadd.s32 %v108510, %v3803 (stack39)
        %v111785 = vadd.s32 1, %v111781 (stack39)
        %v111789 = vsel /*vm=*/%vm111776, /*on_true_vy=*/%v111785, /*on_false_vx=*/%v111781 (stack43)
        %v111793 = vadd.s32 1, %v111789 (stack39)
        %v111797 = vsel /*vm=*/%vm111771, /*on_true_vy=*/%v111793, /*on_false_vx=*/%v111789 (stack43)
        %v111802 = vadd.s32 %v111797, %v10 (stack39)
        %v111806 = vadd.s32 %v111767, %v9 (stack39)
        %v111810 = vadd.s32 %v111806, %v111802 (stack39)
        %v111812 = vshll.u32 %v111806, 13 (stack44)
        %v111813 = vshrl.u32 %v111806, 19 (stack45)
        %v111814 = vor.u32 %v111813, %v111812 (stack46)
        %v111815 = vxor.u32 %v111814, %v111810 (stack47)
        %v111818 = vadd.s32 %v111815, %v111810 (stack39)
        %v111820 = vshll.u32 %v111815, 15 (stack44)
        %v111821 = vshrl.u32 %v111815, 17 (stack45)
        %v111822 = vor.u32 %v111821, %v111820 (stack46)
        %v111823 = vxor.u32 %v111822, %v111818 (stack47)
        %v111826 = vadd.s32 %v111823, %v111818 (stack39)
        %v111828 = vshll.u32 %v111823, 26 (stack44)
        %v111829 = vshrl.u32 %v111823, 6 (stack45)
        %v111830 = vor.u32 %v111829, %v111828 (stack46)
        %v111831 = vxor.u32 %v111830, %v111826 (stack47)
        %v111834 = vadd.s32 %v111831, %v111826 (stack39)
        %v111838 = vadd.s32 %v111834, %v9 (stack39)
        %v111840 = vshll.u32 %v111831, 6 (stack44)
        %v111841 = vshrl.u32 %v111831, 26 (stack45)
        %v111842 = vor.u32 %v111841, %v111840 (stack46)
        %v111843 = vxor.u32 %v111842, %v111834 (stack47)
        %v111846 = vadd.s32 %v111843, %v8 (stack39)
        %v111850 = vadd.s32 1, %v111846 (stack39)
        %v111854 = vadd.s32 %v111850, %v111838 (stack39)
        %v111856 = vshll.u32 %v111850, 17 (stack44)
        %v111857 = vshrl.u32 %v111850, 15 (stack45)
        %v111858 = vor.u32 %v111857, %v111856 (stack46)
        %v111859 = vxor.u32 %v111858, %v111854 (stack47)
        %v111862 = vadd.s32 %v111859, %v111854 (stack39)
        %v111864 = vshll.u32 %v111859, 29 (stack44)
        %v111865 = vshrl.u32 %v111859, 3 (stack45)
        %v111866 = vor.u32 %v111865, %v111864 (stack46)
        %v111867 = vxor.u32 %v111866, %v111862 (stack47)
        %v111870 = vadd.s32 %v111867, %v111862 (stack39)
        %v111872 = vshll.u32 %v111867, 16 (stack44)
        %v111873 = vshrl.u32 %v111867, 16 (stack45)
        %v111874 = vor.u32 %v111873, %v111872 (stack46)
        %v111875 = vxor.u32 %v111874, %v111870 (stack47)
        %v111878 = vadd.s32 %v111875, %v111870 (stack39)
        %v111882 = vadd.s32 %v111878, %v8 (stack39)
        %v111884 = vshll.u32 %v111875, 24 (stack44)
        %v111885 = vshrl.u32 %v111875, 8 (stack45)
        %v111886 = vor.u32 %v111885, %v111884 (stack46)
        %v111887 = vxor.u32 %v111886, %v111878 (stack47)
        %v111890 = vadd.s32 %v111887, %v10 (stack39)
        %v111894 = vadd.s32 2, %v111890 (stack39)
        %v111898 = vadd.s32 %v111894, %v111882 (stack39)
        %v111900 = vshll.u32 %v111894, 13 (stack44)
        %v111901 = vshrl.u32 %v111894, 19 (stack45)
        %v111902 = vor.u32 %v111901, %v111900 (stack46)
        %v111903 = vxor.u32 %v111902, %v111898 (stack47)
        %v111906 = vadd.s32 %v111903, %v111898 (stack39)
        %v111908 = vshll.u32 %v111903, 15 (stack44)
        %v111909 = vshrl.u32 %v111903, 17 (stack45)
        %v111910 = vor.u32 %v111909, %v111908 (stack46)
        %v111911 = vxor.u32 %v111910, %v111906 (stack47)
        %v111914 = vadd.s32 %v111911, %v111906 (stack39)
        %v111916 = vshll.u32 %v111911, 26 (stack44)
        %v111917 = vshrl.u32 %v111911, 6 (stack45)
        %v111918 = vor.u32 %v111917, %v111916 (stack46)
        %v111919 = vxor.u32 %v111918, %v111914 (stack47)
        %v111922 = vadd.s32 %v111919, %v111914 (stack39)
        %v111926 = vadd.s32 %v111922, %v10 (stack39)
        %v111928 = vshll.u32 %v111919, 6 (stack44)
        %v111929 = vshrl.u32 %v111919, 26 (stack45)
        %v111930 = vor.u32 %v111929, %v111928 (stack46)
        %v111931 = vxor.u32 %v111930, %v111922 (stack47)
        %v111934 = vadd.s32 %v111931, %v9 (stack39)
        %v111938 = vadd.s32 3, %v111934 (stack39)
        %v111942 = vadd.s32 %v111938, %v111926 (stack39)
        %v111944 = vshll.u32 %v111938, 17 (stack44)
        %v111945 = vshrl.u32 %v111938, 15 (stack45)
        %v111946 = vor.u32 %v111945, %v111944 (stack46)
        %v111947 = vxor.u32 %v111946, %v111942 (stack47)
        %v111950 = vadd.s32 %v111947, %v111942 (stack39)
        %v111952 = vshll.u32 %v111947, 29 (stack44)
        %v111953 = vshrl.u32 %v111947, 3 (stack45)
        %v111954 = vor.u32 %v111953, %v111952 (stack46)
        %v111955 = vxor.u32 %v111954, %v111950 (stack47)
        %v111958 = vadd.s32 %v111955, %v111950 (stack39)
        %v111960 = vshll.u32 %v111955, 16 (stack44)
        %v111961 = vshrl.u32 %v111955, 16 (stack45)
        %v111962 = vor.u32 %v111961, %v111960 (stack46)
        %v111963 = vxor.u32 %v111962, %v111958 (stack47)
        %v111966 = vadd.s32 %v111963, %v111958 (stack39)
        %v111970 = vadd.s32 %v111966, %v9 (stack39)
        %v111972 = vshll.u32 %v111963, 24 (stack44)
        %v111973 = vshrl.u32 %v111963, 8 (stack45)
        %v111974 = vor.u32 %v111973, %v111972 (stack46)
        %v111975 = vxor.u32 %v111974, %v111966 (stack47)
        %v111978 = vadd.s32 %v111975, %v8 (stack39)
        %v111982 = vadd.s32 4, %v111978 (stack39)
        %v111986 = vadd.s32 %v111982, %v111970 (stack39)
        %v111988 = vshll.u32 %v111982, 13 (stack44)
        %v111989 = vshrl.u32 %v111982, 19 (stack45)
        %v111990 = vor.u32 %v111989, %v111988 (stack46)
        %v111991 = vxor.u32 %v111990, %v111986 (stack47)
        %v111994 = vadd.s32 %v111991, %v111986 (stack39)
        %v111996 = vshll.u32 %v111991, 15 (stack44)
        %v111997 = vshrl.u32 %v111991, 17 (stack45)
        %v111998 = vor.u32 %v111997, %v111996 (stack46)
        %v111999 = vxor.u32 %v111998, %v111994 (stack47)
        %v112002 = vadd.s32 %v111999, %v111994 (stack39)
        %v112004 = vshll.u32 %v111999, 26 (stack44)
        %v112005 = vshrl.u32 %v111999, 6 (stack45)
        %v112006 = vor.u32 %v112005, %v112004 (stack46)
        %v112007 = vxor.u32 %v112006, %v112002 (stack47)
        %v112010 = vadd.s32 %v112007, %v112002 (stack39)
        %v112014 = vadd.s32 %v112010, %v8 (stack39)
        %v112016 = vshll.u32 %v112007, 6 (stack44)
        %v112017 = vshrl.u32 %v112007, 26 (stack45)
        %v112018 = vor.u32 %v112017, %v112016 (stack46)
        %v112019 = vxor.u32 %v112018, %v112010 (stack47)
        %v112022 = vadd.s32 %v112019, %v10 (stack39)
        %v112026 = vadd.s32 5, %v112022 (stack39)
        %v112028 = vxor.u32 %v112026, %v112014 (stack47)
        %v112029 = vand.u32.u8 255, %v112028 (stack48)
        %v112030 = vand.u32 65535, %v112029 (stack49)
        %v112031 = vshrl.u32 %v112030, 1 (stack50)
        %v112032 = vor.u32 16256, %v112031 (stack46)
        %v112033 = vand.u32.u16 65535, %v112032 (stack51)
        %v120342 = vadd.low.f32.bf16 -1.0, %v112033 (stack52)
        %v112042 = vmul.f32 2.0, %v120342 (stack53)
        %v112046 = vadd.f32 -0.99609375, %v112042 (stack52)
        %v112050 = vmax.f32 %v112046, -0.99609375 (stack54)
        %v112052 = vand.u32 2147483647, %v112050 (stack55)
        %vm112055 = vcmp.eq.f32.partialorder %v112052, 1.0 (stack56)
        %v112060 = vmul.f32 inf, %v112050 (stack53)
        %v112062 = vxor.u32 2147483648, %v112050 (stack57)
        %v112065 = vmul.f32 %v112062, %v112050 (stack53)
        %v112067 = vadd.f32 1.0, %v112065 (stack58)
        %v112068 = vlog2.pop %v112067 (stack59)
        %v112069 = vmul.f32 0.6931472, %v112068 (stack60)
        %v112070 = vmul.f32 -0.5, %v112065 (stack61)
        %v112071 = vadd.f32 1.0, %v112070 (stack62)
        %v112072 = vmul.f32 %v112071, %v112065 (stack63)
        %v112073 = vand.u32 2147483647, %v112065 (stack64)
        %vm112074 = vcmp.lt.f32.partialorder %v112073, 0.0004427343 (stack65)
        %v112075 = vsel /*vm=*/%vm112074, /*on_true_vy=*/%v112072, /*on_false_vx=*/%v112069 (stack66)
        %v112076 = vxor.u32 2147483648, %v112075 (stack57)
        %vm112079 = vcmp.lt.f32.partialorder %v112076, 5.0 (stack56)
        %v112084 = vsel /*vm=*/%vm112079, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v112088 = vsel /*vm=*/%vm112079, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v112092 = vsel /*vm=*/%vm112079, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v112096 = vsel /*vm=*/%vm112079, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v112100 = vsel /*vm=*/%vm112079, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v112104 = vsel /*vm=*/%vm112079, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v112108 = vsel /*vm=*/%vm112079, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v112112 = vsel /*vm=*/%vm112079, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v112116 = vsel /*vm=*/%vm112079, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v112120 = vadd.f32 -2.5, %v112076 (stack52)
        %v112122 = vrsqrt.pop %v112076 (stack67)
        %v112123 = vmul.f32 %v112122, %v112076 (stack68)
        %vm112124 = vcmp.eq.f32.partialorder %v112076, inf (stack69)
        %v112125 = vsel /*vm=*/%vm112124, /*on_true_vy=*/%v112076, /*on_false_vx=*/%v112123 (stack70)
        %vm112126 = vcmp.eq.f32.partialorder %v112076, 0.0 (stack71)
        %v112127 = vand.u32 2147483648, %v112076 (stack72)
        %v112128 = vsel /*vm=*/%vm112126, /*on_true_vy=*/%v112127, /*on_false_vx=*/%v112125 (stack73)
        %v112131 = vadd.f32 -3.0, %v112128 (stack52)
        %v112135 = vsel /*vm=*/%vm112079, /*on_true_vy=*/%v112120, /*on_false_vx=*/%v112131 (stack43)
        %v112139 = vmul.f32 %v112135, %v112116 (stack53)
        %v112143 = vadd.f32 %v112139, %v112112 (stack52)
        %v112147 = vmul.f32 %v112143, %v112135 (stack53)
        %v112151 = vadd.f32 %v112147, %v112108 (stack52)
        %v112155 = vmul.f32 %v112151, %v112135 (stack53)
        %v112159 = vadd.f32 %v112155, %v112104 (stack52)
        %v112163 = vmul.f32 %v112159, %v112135 (stack53)
        %v112167 = vadd.f32 %v112163, %v112100 (stack52)
        %v112171 = vmul.f32 %v112167, %v112135 (stack53)
        %v112175 = vadd.f32 %v112171, %v112096 (stack52)
        %v112179 = vmul.f32 %v112175, %v112135 (stack53)
        %v112183 = vadd.f32 %v112179, %v112092 (stack52)
        %v112187 = vmul.f32 %v112183, %v112135 (stack53)
        %v112191 = vadd.f32 %v112187, %v112088 (stack52)
        %v112195 = vmul.f32 %v112191, %v112135 (stack53)
        %v112199 = vadd.f32 %v112195, %v112084 (stack52)
        %v112203 = vmul.f32 %v112199, %v112050 (stack53)
        %v112207 = vsel /*vm=*/%vm112055, /*on_true_vy=*/%v112060, /*on_false_vx=*/%v112203 (stack43)
        %v112211 = vmul.f32 1.4140625, %v112207 (stack53)
        %v112214 = vpack.c.bf16 0.0, %v112211 (stack74)
        %120343 = vst [vmem:[%s280 + $0x3f4] sm:$0xf] /*vst_source=*/%v112214 (stack75)
        %s112216 = sadd.s32 240, %s120390 (stack76)
        %s112217 = sshrl.u32 %s112216, 10 (stack23)
        %p120344 = scmp.gt.s32.totalorder %s112217, 1 (stack24)
        %s112219 = scalar_select /*predicate=*/%p120344, /*on_true=*/1, /*on_false=*/%s112217 (stack25)
        %s112220 = sand.u32 1023, %s112216 /* smod.u32 w/div 1024 */ (stack26)
        %s112221 = sshrl.u32 %s112220, 7 (stack27)
        %s112222 = sand.u32 127, %s112220 /* smod.u32 w/div 128 */ (stack28)
        %s120345 = sshll.u32 %s112219, 3 (stack29)
        %s112224 = scalar_lea.vmem %s3, %s120345 (stack30)
        %s112226 = scalar_lea.vmem %s112224, %s112221 (stack31)
        %v112227 = vld [vmem:[%s112226] ss:$0 sm:$0xff] (stack32)
        %s112228 = sand.u32 255, %s112222 (stack33)
        %s112230 = sor.u32 256, %s112228 (stack34)
        %112231 = vbcast.lane.b32.xlu0 %v112227, %s112230 (stack35)
        %v112232 = vpop.permute.xlu0 %112231 (stack36)
        %s112241 = scalar_lea.vmem %s5, %s120345 (stack30)
        %s112243 = scalar_lea.vmem %s112241, %s112221 (stack31)
        %v112244 = vld [vmem:[%s112243] ss:$0 sm:$0xff] (stack32)
        %112248 = vbcast.lane.b32.xlu0 %v112244, %s112230 (stack35)
        %v112249 = vpop.permute.xlu0 %112248 (stack36)
        %v112252 = vadd.s32 %v112249, %v408 (stack39)
        %v112262 = vadd.s32 %v112252, %v415 (stack39)
        %vm112266 = vcmp.lt.u32.totalorder %v112262, %v112252 (stack42)
        %vm112271 = vcmp.lt.u32.totalorder %v112252, %v408 (stack42)
        %v112276 = vadd.s32 %v112232, %v380 (stack39)
        %v112280 = vadd.s32 1, %v112276 (stack39)
        %v112284 = vsel /*vm=*/%vm112271, /*on_true_vy=*/%v112280, /*on_false_vx=*/%v112276 (stack43)
        %v112288 = vadd.s32 1, %v112284 (stack39)
        %v112292 = vsel /*vm=*/%vm112266, /*on_true_vy=*/%v112288, /*on_false_vx=*/%v112284 (stack43)
        %v112297 = vadd.s32 %v112292, %v10 (stack39)
        %v112301 = vadd.s32 %v112262, %v9 (stack39)
        %v112305 = vadd.s32 %v112301, %v112297 (stack39)
        %v112307 = vshll.u32 %v112301, 13 (stack44)
        %v112308 = vshrl.u32 %v112301, 19 (stack45)
        %v112309 = vor.u32 %v112308, %v112307 (stack46)
        %v112310 = vxor.u32 %v112309, %v112305 (stack47)
        %v112313 = vadd.s32 %v112310, %v112305 (stack39)
        %v112315 = vshll.u32 %v112310, 15 (stack44)
        %v112316 = vshrl.u32 %v112310, 17 (stack45)
        %v112317 = vor.u32 %v112316, %v112315 (stack46)
        %v112318 = vxor.u32 %v112317, %v112313 (stack47)
        %v112321 = vadd.s32 %v112318, %v112313 (stack39)
        %v112323 = vshll.u32 %v112318, 26 (stack44)
        %v112324 = vshrl.u32 %v112318, 6 (stack45)
        %v112325 = vor.u32 %v112324, %v112323 (stack46)
        %v112326 = vxor.u32 %v112325, %v112321 (stack47)
        %v112329 = vadd.s32 %v112326, %v112321 (stack39)
        %v112333 = vadd.s32 %v112329, %v9 (stack39)
        %v112335 = vshll.u32 %v112326, 6 (stack44)
        %v112336 = vshrl.u32 %v112326, 26 (stack45)
        %v112337 = vor.u32 %v112336, %v112335 (stack46)
        %v112338 = vxor.u32 %v112337, %v112329 (stack47)
        %v112341 = vadd.s32 %v112338, %v8 (stack39)
        %v112345 = vadd.s32 1, %v112341 (stack39)
        %v112349 = vadd.s32 %v112345, %v112333 (stack39)
        %v112351 = vshll.u32 %v112345, 17 (stack44)
        %v112352 = vshrl.u32 %v112345, 15 (stack45)
        %v112353 = vor.u32 %v112352, %v112351 (stack46)
        %v112354 = vxor.u32 %v112353, %v112349 (stack47)
        %v112357 = vadd.s32 %v112354, %v112349 (stack39)
        %v112359 = vshll.u32 %v112354, 29 (stack44)
        %v112360 = vshrl.u32 %v112354, 3 (stack45)
        %v112361 = vor.u32 %v112360, %v112359 (stack46)
        %v112362 = vxor.u32 %v112361, %v112357 (stack47)
        %v112365 = vadd.s32 %v112362, %v112357 (stack39)
        %v112367 = vshll.u32 %v112362, 16 (stack44)
        %v112368 = vshrl.u32 %v112362, 16 (stack45)
        %v112369 = vor.u32 %v112368, %v112367 (stack46)
        %v112370 = vxor.u32 %v112369, %v112365 (stack47)
        %v112373 = vadd.s32 %v112370, %v112365 (stack39)
        %v112377 = vadd.s32 %v112373, %v8 (stack39)
        %v112379 = vshll.u32 %v112370, 24 (stack44)
        %v112380 = vshrl.u32 %v112370, 8 (stack45)
        %v112381 = vor.u32 %v112380, %v112379 (stack46)
        %v112382 = vxor.u32 %v112381, %v112373 (stack47)
        %v112385 = vadd.s32 %v112382, %v10 (stack39)
        %v112389 = vadd.s32 2, %v112385 (stack39)
        %v112393 = vadd.s32 %v112389, %v112377 (stack39)
        %v112395 = vshll.u32 %v112389, 13 (stack44)
        %v112396 = vshrl.u32 %v112389, 19 (stack45)
        %v112397 = vor.u32 %v112396, %v112395 (stack46)
        %v112398 = vxor.u32 %v112397, %v112393 (stack47)
        %v112401 = vadd.s32 %v112398, %v112393 (stack39)
        %v112403 = vshll.u32 %v112398, 15 (stack44)
        %v112404 = vshrl.u32 %v112398, 17 (stack45)
        %v112405 = vor.u32 %v112404, %v112403 (stack46)
        %v112406 = vxor.u32 %v112405, %v112401 (stack47)
        %v112409 = vadd.s32 %v112406, %v112401 (stack39)
        %v112411 = vshll.u32 %v112406, 26 (stack44)
        %v112412 = vshrl.u32 %v112406, 6 (stack45)
        %v112413 = vor.u32 %v112412, %v112411 (stack46)
        %v112414 = vxor.u32 %v112413, %v112409 (stack47)
        %v112417 = vadd.s32 %v112414, %v112409 (stack39)
        %v112421 = vadd.s32 %v112417, %v10 (stack39)
        %v112423 = vshll.u32 %v112414, 6 (stack44)
        %v112424 = vshrl.u32 %v112414, 26 (stack45)
        %v112425 = vor.u32 %v112424, %v112423 (stack46)
        %v112426 = vxor.u32 %v112425, %v112417 (stack47)
        %v112429 = vadd.s32 %v112426, %v9 (stack39)
        %v112433 = vadd.s32 3, %v112429 (stack39)
        %v112437 = vadd.s32 %v112433, %v112421 (stack39)
        %v112439 = vshll.u32 %v112433, 17 (stack44)
        %v112440 = vshrl.u32 %v112433, 15 (stack45)
        %v112441 = vor.u32 %v112440, %v112439 (stack46)
        %v112442 = vxor.u32 %v112441, %v112437 (stack47)
        %v112445 = vadd.s32 %v112442, %v112437 (stack39)
        %v112447 = vshll.u32 %v112442, 29 (stack44)
        %v112448 = vshrl.u32 %v112442, 3 (stack45)
        %v112449 = vor.u32 %v112448, %v112447 (stack46)
        %v112450 = vxor.u32 %v112449, %v112445 (stack47)
        %v112453 = vadd.s32 %v112450, %v112445 (stack39)
        %v112455 = vshll.u32 %v112450, 16 (stack44)
        %v112456 = vshrl.u32 %v112450, 16 (stack45)
        %v112457 = vor.u32 %v112456, %v112455 (stack46)
        %v112458 = vxor.u32 %v112457, %v112453 (stack47)
        %v112461 = vadd.s32 %v112458, %v112453 (stack39)
        %v112465 = vadd.s32 %v112461, %v9 (stack39)
        %v112467 = vshll.u32 %v112458, 24 (stack44)
        %v112468 = vshrl.u32 %v112458, 8 (stack45)
        %v112469 = vor.u32 %v112468, %v112467 (stack46)
        %v112470 = vxor.u32 %v112469, %v112461 (stack47)
        %v112473 = vadd.s32 %v112470, %v8 (stack39)
        %v112477 = vadd.s32 4, %v112473 (stack39)
        %v112481 = vadd.s32 %v112477, %v112465 (stack39)
        %v112483 = vshll.u32 %v112477, 13 (stack44)
        %v112484 = vshrl.u32 %v112477, 19 (stack45)
        %v112485 = vor.u32 %v112484, %v112483 (stack46)
        %v112486 = vxor.u32 %v112485, %v112481 (stack47)
        %v112489 = vadd.s32 %v112486, %v112481 (stack39)
        %v112491 = vshll.u32 %v112486, 15 (stack44)
        %v112492 = vshrl.u32 %v112486, 17 (stack45)
        %v112493 = vor.u32 %v112492, %v112491 (stack46)
        %v112494 = vxor.u32 %v112493, %v112489 (stack47)
        %v112497 = vadd.s32 %v112494, %v112489 (stack39)
        %v112499 = vshll.u32 %v112494, 26 (stack44)
        %v112500 = vshrl.u32 %v112494, 6 (stack45)
        %v112501 = vor.u32 %v112500, %v112499 (stack46)
        %v112502 = vxor.u32 %v112501, %v112497 (stack47)
        %v112505 = vadd.s32 %v112502, %v112497 (stack39)
        %v112509 = vadd.s32 %v112505, %v8 (stack39)
        %v112511 = vshll.u32 %v112502, 6 (stack44)
        %v112512 = vshrl.u32 %v112502, 26 (stack45)
        %v112513 = vor.u32 %v112512, %v112511 (stack46)
        %v112514 = vxor.u32 %v112513, %v112505 (stack47)
        %v112517 = vadd.s32 %v112514, %v10 (stack39)
        %v112521 = vadd.s32 5, %v112517 (stack39)
        %v112523 = vxor.u32 %v112521, %v112509 (stack47)
        %v112524 = vand.u32.u8 255, %v112523 (stack48)
        %v112525 = vand.u32 65535, %v112524 (stack49)
        %v112526 = vshrl.u32 %v112525, 1 (stack50)
        %v112527 = vor.u32 16256, %v112526 (stack46)
        %v112528 = vand.u32.u16 65535, %v112527 (stack51)
        %v120348 = vadd.low.f32.bf16 -1.0, %v112528 (stack52)
        %v112537 = vmul.f32 2.0, %v120348 (stack53)
        %v112541 = vadd.f32 -0.99609375, %v112537 (stack52)
        %v112545 = vmax.f32 %v112541, -0.99609375 (stack54)
        %v112547 = vand.u32 2147483647, %v112545 (stack55)
        %vm112550 = vcmp.eq.f32.partialorder %v112547, 1.0 (stack56)
        %v112555 = vmul.f32 inf, %v112545 (stack53)
        %v112557 = vxor.u32 2147483648, %v112545 (stack57)
        %v112560 = vmul.f32 %v112557, %v112545 (stack53)
        %v112562 = vadd.f32 1.0, %v112560 (stack58)
        %v112563 = vlog2.pop %v112562 (stack59)
        %v112564 = vmul.f32 0.6931472, %v112563 (stack60)
        %v112565 = vmul.f32 -0.5, %v112560 (stack61)
        %v112566 = vadd.f32 1.0, %v112565 (stack62)
        %v112567 = vmul.f32 %v112566, %v112560 (stack63)
        %v112568 = vand.u32 2147483647, %v112560 (stack64)
        %vm112569 = vcmp.lt.f32.partialorder %v112568, 0.0004427343 (stack65)
        %v112570 = vsel /*vm=*/%vm112569, /*on_true_vy=*/%v112567, /*on_false_vx=*/%v112564 (stack66)
        %v112571 = vxor.u32 2147483648, %v112570 (stack57)
        %vm112574 = vcmp.lt.f32.partialorder %v112571, 5.0 (stack56)
        %v112579 = vsel /*vm=*/%vm112574, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v112583 = vsel /*vm=*/%vm112574, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v112587 = vsel /*vm=*/%vm112574, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v112591 = vsel /*vm=*/%vm112574, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v112595 = vsel /*vm=*/%vm112574, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v112599 = vsel /*vm=*/%vm112574, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v112603 = vsel /*vm=*/%vm112574, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v112607 = vsel /*vm=*/%vm112574, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v112611 = vsel /*vm=*/%vm112574, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v112615 = vadd.f32 -2.5, %v112571 (stack52)
        %v112617 = vrsqrt.pop %v112571 (stack67)
        %v112618 = vmul.f32 %v112617, %v112571 (stack68)
        %vm112619 = vcmp.eq.f32.partialorder %v112571, inf (stack69)
        %v112620 = vsel /*vm=*/%vm112619, /*on_true_vy=*/%v112571, /*on_false_vx=*/%v112618 (stack70)
        %vm112621 = vcmp.eq.f32.partialorder %v112571, 0.0 (stack71)
        %v112622 = vand.u32 2147483648, %v112571 (stack72)
        %v112623 = vsel /*vm=*/%vm112621, /*on_true_vy=*/%v112622, /*on_false_vx=*/%v112620 (stack73)
        %v112626 = vadd.f32 -3.0, %v112623 (stack52)
        %v112630 = vsel /*vm=*/%vm112574, /*on_true_vy=*/%v112615, /*on_false_vx=*/%v112626 (stack43)
        %v112634 = vmul.f32 %v112630, %v112611 (stack53)
        %v112638 = vadd.f32 %v112634, %v112607 (stack52)
        %v112642 = vmul.f32 %v112638, %v112630 (stack53)
        %v112646 = vadd.f32 %v112642, %v112603 (stack52)
        %v112650 = vmul.f32 %v112646, %v112630 (stack53)
        %v112654 = vadd.f32 %v112650, %v112599 (stack52)
        %v112658 = vmul.f32 %v112654, %v112630 (stack53)
        %v112662 = vadd.f32 %v112658, %v112595 (stack52)
        %v112666 = vmul.f32 %v112662, %v112630 (stack53)
        %v112670 = vadd.f32 %v112666, %v112591 (stack52)
        %v112674 = vmul.f32 %v112670, %v112630 (stack53)
        %v112678 = vadd.f32 %v112674, %v112587 (stack52)
        %v112682 = vmul.f32 %v112678, %v112630 (stack53)
        %v112686 = vadd.f32 %v112682, %v112583 (stack52)
        %v112690 = vmul.f32 %v112686, %v112630 (stack53)
        %v112694 = vadd.f32 %v112690, %v112579 (stack52)
        %v112698 = vmul.f32 %v112694, %v112545 (stack53)
        %v112702 = vsel /*vm=*/%vm112550, /*on_true_vy=*/%v112555, /*on_false_vx=*/%v112698 (stack43)
        %v112706 = vmul.f32 1.4140625, %v112702 (stack53)
        %v112709 = vpack.c.bf16 0.0, %v112706 (stack74)
        %120349 = vst [vmem:[%s280 + $0x78] sm:$0xf] /*vst_source=*/%v112709 (stack75)
        %v112713 = vadd.s32 %v112249, %v894 (stack39)
        %v112723 = vadd.s32 %v112713, %v415 (stack39)
        %vm112727 = vcmp.lt.u32.totalorder %v112723, %v112713 (stack42)
        %vm112732 = vcmp.lt.u32.totalorder %v112713, %v894 (stack42)
        %v112737 = vadd.s32 %v112232, %v881 (stack39)
        %v112741 = vadd.s32 1, %v112737 (stack39)
        %v112745 = vsel /*vm=*/%vm112732, /*on_true_vy=*/%v112741, /*on_false_vx=*/%v112737 (stack43)
        %v112749 = vadd.s32 1, %v112745 (stack39)
        %v112753 = vsel /*vm=*/%vm112727, /*on_true_vy=*/%v112749, /*on_false_vx=*/%v112745 (stack43)
        %v112758 = vadd.s32 %v112753, %v10 (stack39)
        %v112762 = vadd.s32 %v112723, %v9 (stack39)
        %v112766 = vadd.s32 %v112762, %v112758 (stack39)
        %v112768 = vshll.u32 %v112762, 13 (stack44)
        %v112769 = vshrl.u32 %v112762, 19 (stack45)
        %v112770 = vor.u32 %v112769, %v112768 (stack46)
        %v112771 = vxor.u32 %v112770, %v112766 (stack47)
        %v112774 = vadd.s32 %v112771, %v112766 (stack39)
        %v112776 = vshll.u32 %v112771, 15 (stack44)
        %v112777 = vshrl.u32 %v112771, 17 (stack45)
        %v112778 = vor.u32 %v112777, %v112776 (stack46)
        %v112779 = vxor.u32 %v112778, %v112774 (stack47)
        %v112782 = vadd.s32 %v112779, %v112774 (stack39)
        %v112784 = vshll.u32 %v112779, 26 (stack44)
        %v112785 = vshrl.u32 %v112779, 6 (stack45)
        %v112786 = vor.u32 %v112785, %v112784 (stack46)
        %v112787 = vxor.u32 %v112786, %v112782 (stack47)
        %v112790 = vadd.s32 %v112787, %v112782 (stack39)
        %v112794 = vadd.s32 %v112790, %v9 (stack39)
        %v112796 = vshll.u32 %v112787, 6 (stack44)
        %v112797 = vshrl.u32 %v112787, 26 (stack45)
        %v112798 = vor.u32 %v112797, %v112796 (stack46)
        %v112799 = vxor.u32 %v112798, %v112790 (stack47)
        %v112802 = vadd.s32 %v112799, %v8 (stack39)
        %v112806 = vadd.s32 1, %v112802 (stack39)
        %v112810 = vadd.s32 %v112806, %v112794 (stack39)
        %v112812 = vshll.u32 %v112806, 17 (stack44)
        %v112813 = vshrl.u32 %v112806, 15 (stack45)
        %v112814 = vor.u32 %v112813, %v112812 (stack46)
        %v112815 = vxor.u32 %v112814, %v112810 (stack47)
        %v112818 = vadd.s32 %v112815, %v112810 (stack39)
        %v112820 = vshll.u32 %v112815, 29 (stack44)
        %v112821 = vshrl.u32 %v112815, 3 (stack45)
        %v112822 = vor.u32 %v112821, %v112820 (stack46)
        %v112823 = vxor.u32 %v112822, %v112818 (stack47)
        %v112826 = vadd.s32 %v112823, %v112818 (stack39)
        %v112828 = vshll.u32 %v112823, 16 (stack44)
        %v112829 = vshrl.u32 %v112823, 16 (stack45)
        %v112830 = vor.u32 %v112829, %v112828 (stack46)
        %v112831 = vxor.u32 %v112830, %v112826 (stack47)
        %v112834 = vadd.s32 %v112831, %v112826 (stack39)
        %v112838 = vadd.s32 %v112834, %v8 (stack39)
        %v112840 = vshll.u32 %v112831, 24 (stack44)
        %v112841 = vshrl.u32 %v112831, 8 (stack45)
        %v112842 = vor.u32 %v112841, %v112840 (stack46)
        %v112843 = vxor.u32 %v112842, %v112834 (stack47)
        %v112846 = vadd.s32 %v112843, %v10 (stack39)
        %v112850 = vadd.s32 2, %v112846 (stack39)
        %v112854 = vadd.s32 %v112850, %v112838 (stack39)
        %v112856 = vshll.u32 %v112850, 13 (stack44)
        %v112857 = vshrl.u32 %v112850, 19 (stack45)
        %v112858 = vor.u32 %v112857, %v112856 (stack46)
        %v112859 = vxor.u32 %v112858, %v112854 (stack47)
        %v112862 = vadd.s32 %v112859, %v112854 (stack39)
        %v112864 = vshll.u32 %v112859, 15 (stack44)
        %v112865 = vshrl.u32 %v112859, 17 (stack45)
        %v112866 = vor.u32 %v112865, %v112864 (stack46)
        %v112867 = vxor.u32 %v112866, %v112862 (stack47)
        %v112870 = vadd.s32 %v112867, %v112862 (stack39)
        %v112872 = vshll.u32 %v112867, 26 (stack44)
        %v112873 = vshrl.u32 %v112867, 6 (stack45)
        %v112874 = vor.u32 %v112873, %v112872 (stack46)
        %v112875 = vxor.u32 %v112874, %v112870 (stack47)
        %v112878 = vadd.s32 %v112875, %v112870 (stack39)
        %v112882 = vadd.s32 %v112878, %v10 (stack39)
        %v112884 = vshll.u32 %v112875, 6 (stack44)
        %v112885 = vshrl.u32 %v112875, 26 (stack45)
        %v112886 = vor.u32 %v112885, %v112884 (stack46)
        %v112887 = vxor.u32 %v112886, %v112878 (stack47)
        %v112890 = vadd.s32 %v112887, %v9 (stack39)
        %v112894 = vadd.s32 3, %v112890 (stack39)
        %v112898 = vadd.s32 %v112894, %v112882 (stack39)
        %v112900 = vshll.u32 %v112894, 17 (stack44)
        %v112901 = vshrl.u32 %v112894, 15 (stack45)
        %v112902 = vor.u32 %v112901, %v112900 (stack46)
        %v112903 = vxor.u32 %v112902, %v112898 (stack47)
        %v112906 = vadd.s32 %v112903, %v112898 (stack39)
        %v112908 = vshll.u32 %v112903, 29 (stack44)
        %v112909 = vshrl.u32 %v112903, 3 (stack45)
        %v112910 = vor.u32 %v112909, %v112908 (stack46)
        %v112911 = vxor.u32 %v112910, %v112906 (stack47)
        %v112914 = vadd.s32 %v112911, %v112906 (stack39)
        %v112916 = vshll.u32 %v112911, 16 (stack44)
        %v112917 = vshrl.u32 %v112911, 16 (stack45)
        %v112918 = vor.u32 %v112917, %v112916 (stack46)
        %v112919 = vxor.u32 %v112918, %v112914 (stack47)
        %v112922 = vadd.s32 %v112919, %v112914 (stack39)
        %v112926 = vadd.s32 %v112922, %v9 (stack39)
        %v112928 = vshll.u32 %v112919, 24 (stack44)
        %v112929 = vshrl.u32 %v112919, 8 (stack45)
        %v112930 = vor.u32 %v112929, %v112928 (stack46)
        %v112931 = vxor.u32 %v112930, %v112922 (stack47)
        %v112934 = vadd.s32 %v112931, %v8 (stack39)
        %v112938 = vadd.s32 4, %v112934 (stack39)
        %v112942 = vadd.s32 %v112938, %v112926 (stack39)
        %v112944 = vshll.u32 %v112938, 13 (stack44)
        %v112945 = vshrl.u32 %v112938, 19 (stack45)
        %v112946 = vor.u32 %v112945, %v112944 (stack46)
        %v112947 = vxor.u32 %v112946, %v112942 (stack47)
        %v112950 = vadd.s32 %v112947, %v112942 (stack39)
        %v112952 = vshll.u32 %v112947, 15 (stack44)
        %v112953 = vshrl.u32 %v112947, 17 (stack45)
        %v112954 = vor.u32 %v112953, %v112952 (stack46)
        %v112955 = vxor.u32 %v112954, %v112950 (stack47)
        %v112958 = vadd.s32 %v112955, %v112950 (stack39)
        %v112960 = vshll.u32 %v112955, 26 (stack44)
        %v112961 = vshrl.u32 %v112955, 6 (stack45)
        %v112962 = vor.u32 %v112961, %v112960 (stack46)
        %v112963 = vxor.u32 %v112962, %v112958 (stack47)
        %v112966 = vadd.s32 %v112963, %v112958 (stack39)
        %v112970 = vadd.s32 %v112966, %v8 (stack39)
        %v112972 = vshll.u32 %v112963, 6 (stack44)
        %v112973 = vshrl.u32 %v112963, 26 (stack45)
        %v112974 = vor.u32 %v112973, %v112972 (stack46)
        %v112975 = vxor.u32 %v112974, %v112966 (stack47)
        %v112978 = vadd.s32 %v112975, %v10 (stack39)
        %v112982 = vadd.s32 5, %v112978 (stack39)
        %v112984 = vxor.u32 %v112982, %v112970 (stack47)
        %v112985 = vand.u32.u8 255, %v112984 (stack48)
        %v112986 = vand.u32 65535, %v112985 (stack49)
        %v112987 = vshrl.u32 %v112986, 1 (stack50)
        %v112988 = vor.u32 16256, %v112987 (stack46)
        %v112989 = vand.u32.u16 65535, %v112988 (stack51)
        %v120350 = vadd.low.f32.bf16 -1.0, %v112989 (stack52)
        %v112998 = vmul.f32 2.0, %v120350 (stack53)
        %v113002 = vadd.f32 -0.99609375, %v112998 (stack52)
        %v113006 = vmax.f32 %v113002, -0.99609375 (stack54)
        %v113008 = vand.u32 2147483647, %v113006 (stack55)
        %vm113011 = vcmp.eq.f32.partialorder %v113008, 1.0 (stack56)
        %v113016 = vmul.f32 inf, %v113006 (stack53)
        %v113018 = vxor.u32 2147483648, %v113006 (stack57)
        %v113021 = vmul.f32 %v113018, %v113006 (stack53)
        %v113023 = vadd.f32 1.0, %v113021 (stack58)
        %v113024 = vlog2.pop %v113023 (stack59)
        %v113025 = vmul.f32 0.6931472, %v113024 (stack60)
        %v113026 = vmul.f32 -0.5, %v113021 (stack61)
        %v113027 = vadd.f32 1.0, %v113026 (stack62)
        %v113028 = vmul.f32 %v113027, %v113021 (stack63)
        %v113029 = vand.u32 2147483647, %v113021 (stack64)
        %vm113030 = vcmp.lt.f32.partialorder %v113029, 0.0004427343 (stack65)
        %v113031 = vsel /*vm=*/%vm113030, /*on_true_vy=*/%v113028, /*on_false_vx=*/%v113025 (stack66)
        %v113032 = vxor.u32 2147483648, %v113031 (stack57)
        %vm113035 = vcmp.lt.f32.partialorder %v113032, 5.0 (stack56)
        %v113040 = vsel /*vm=*/%vm113035, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v113044 = vsel /*vm=*/%vm113035, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v113048 = vsel /*vm=*/%vm113035, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v113052 = vsel /*vm=*/%vm113035, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v113056 = vsel /*vm=*/%vm113035, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v113060 = vsel /*vm=*/%vm113035, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v113064 = vsel /*vm=*/%vm113035, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v113068 = vsel /*vm=*/%vm113035, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v113072 = vsel /*vm=*/%vm113035, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v113076 = vadd.f32 -2.5, %v113032 (stack52)
        %v113078 = vrsqrt.pop %v113032 (stack67)
        %v113079 = vmul.f32 %v113078, %v113032 (stack68)
        %vm113080 = vcmp.eq.f32.partialorder %v113032, inf (stack69)
        %v113081 = vsel /*vm=*/%vm113080, /*on_true_vy=*/%v113032, /*on_false_vx=*/%v113079 (stack70)
        %vm113082 = vcmp.eq.f32.partialorder %v113032, 0.0 (stack71)
        %v113083 = vand.u32 2147483648, %v113032 (stack72)
        %v113084 = vsel /*vm=*/%vm113082, /*on_true_vy=*/%v113083, /*on_false_vx=*/%v113081 (stack73)
        %v113087 = vadd.f32 -3.0, %v113084 (stack52)
        %v113091 = vsel /*vm=*/%vm113035, /*on_true_vy=*/%v113076, /*on_false_vx=*/%v113087 (stack43)
        %v113095 = vmul.f32 %v113091, %v113072 (stack53)
        %v113099 = vadd.f32 %v113095, %v113068 (stack52)
        %v113103 = vmul.f32 %v113099, %v113091 (stack53)
        %v113107 = vadd.f32 %v113103, %v113064 (stack52)
        %v113111 = vmul.f32 %v113107, %v113091 (stack53)
        %v113115 = vadd.f32 %v113111, %v113060 (stack52)
        %v113119 = vmul.f32 %v113115, %v113091 (stack53)
        %v113123 = vadd.f32 %v113119, %v113056 (stack52)
        %v113127 = vmul.f32 %v113123, %v113091 (stack53)
        %v113131 = vadd.f32 %v113127, %v113052 (stack52)
        %v113135 = vmul.f32 %v113131, %v113091 (stack53)
        %v113139 = vadd.f32 %v113135, %v113048 (stack52)
        %v113143 = vmul.f32 %v113139, %v113091 (stack53)
        %v113147 = vadd.f32 %v113143, %v113044 (stack52)
        %v113151 = vmul.f32 %v113147, %v113091 (stack53)
        %v113155 = vadd.f32 %v113151, %v113040 (stack52)
        %v113159 = vmul.f32 %v113155, %v113006 (stack53)
        %v113163 = vsel /*vm=*/%vm113011, /*on_true_vy=*/%v113016, /*on_false_vx=*/%v113159 (stack43)
        %v113167 = vmul.f32 1.4140625, %v113163 (stack53)
        %v113170 = vpack.c.bf16 0.0, %v113167 (stack74)
        %120351 = vst [vmem:[%s280 + $0xf8] sm:$0xf] /*vst_source=*/%v113170 (stack75)
        %v113174 = vadd.s32 %v112249, %v1381 (stack39)
        %v113184 = vadd.s32 %v113174, %v415 (stack39)
        %vm113188 = vcmp.lt.u32.totalorder %v113184, %v113174 (stack42)
        %vm113193 = vcmp.lt.u32.totalorder %v113174, %v1381 (stack42)
        %v113198 = vadd.s32 %v112232, %v1368 (stack39)
        %v113202 = vadd.s32 1, %v113198 (stack39)
        %v113206 = vsel /*vm=*/%vm113193, /*on_true_vy=*/%v113202, /*on_false_vx=*/%v113198 (stack43)
        %v113210 = vadd.s32 1, %v113206 (stack39)
        %v113214 = vsel /*vm=*/%vm113188, /*on_true_vy=*/%v113210, /*on_false_vx=*/%v113206 (stack43)
        %v113219 = vadd.s32 %v113214, %v10 (stack39)
        %v113223 = vadd.s32 %v113184, %v9 (stack39)
        %v113227 = vadd.s32 %v113223, %v113219 (stack39)
        %v113229 = vshll.u32 %v113223, 13 (stack44)
        %v113230 = vshrl.u32 %v113223, 19 (stack45)
        %v113231 = vor.u32 %v113230, %v113229 (stack46)
        %v113232 = vxor.u32 %v113231, %v113227 (stack47)
        %v113235 = vadd.s32 %v113232, %v113227 (stack39)
        %v113237 = vshll.u32 %v113232, 15 (stack44)
        %v113238 = vshrl.u32 %v113232, 17 (stack45)
        %v113239 = vor.u32 %v113238, %v113237 (stack46)
        %v113240 = vxor.u32 %v113239, %v113235 (stack47)
        %v113243 = vadd.s32 %v113240, %v113235 (stack39)
        %v113245 = vshll.u32 %v113240, 26 (stack44)
        %v113246 = vshrl.u32 %v113240, 6 (stack45)
        %v113247 = vor.u32 %v113246, %v113245 (stack46)
        %v113248 = vxor.u32 %v113247, %v113243 (stack47)
        %v113251 = vadd.s32 %v113248, %v113243 (stack39)
        %v113255 = vadd.s32 %v113251, %v9 (stack39)
        %v113257 = vshll.u32 %v113248, 6 (stack44)
        %v113258 = vshrl.u32 %v113248, 26 (stack45)
        %v113259 = vor.u32 %v113258, %v113257 (stack46)
        %v113260 = vxor.u32 %v113259, %v113251 (stack47)
        %v113263 = vadd.s32 %v113260, %v8 (stack39)
        %v113267 = vadd.s32 1, %v113263 (stack39)
        %v113271 = vadd.s32 %v113267, %v113255 (stack39)
        %v113273 = vshll.u32 %v113267, 17 (stack44)
        %v113274 = vshrl.u32 %v113267, 15 (stack45)
        %v113275 = vor.u32 %v113274, %v113273 (stack46)
        %v113276 = vxor.u32 %v113275, %v113271 (stack47)
        %v113279 = vadd.s32 %v113276, %v113271 (stack39)
        %v113281 = vshll.u32 %v113276, 29 (stack44)
        %v113282 = vshrl.u32 %v113276, 3 (stack45)
        %v113283 = vor.u32 %v113282, %v113281 (stack46)
        %v113284 = vxor.u32 %v113283, %v113279 (stack47)
        %v113287 = vadd.s32 %v113284, %v113279 (stack39)
        %v113289 = vshll.u32 %v113284, 16 (stack44)
        %v113290 = vshrl.u32 %v113284, 16 (stack45)
        %v113291 = vor.u32 %v113290, %v113289 (stack46)
        %v113292 = vxor.u32 %v113291, %v113287 (stack47)
        %v113295 = vadd.s32 %v113292, %v113287 (stack39)
        %v113299 = vadd.s32 %v113295, %v8 (stack39)
        %v113301 = vshll.u32 %v113292, 24 (stack44)
        %v113302 = vshrl.u32 %v113292, 8 (stack45)
        %v113303 = vor.u32 %v113302, %v113301 (stack46)
        %v113304 = vxor.u32 %v113303, %v113295 (stack47)
        %v113307 = vadd.s32 %v113304, %v10 (stack39)
        %v113311 = vadd.s32 2, %v113307 (stack39)
        %v113315 = vadd.s32 %v113311, %v113299 (stack39)
        %v113317 = vshll.u32 %v113311, 13 (stack44)
        %v113318 = vshrl.u32 %v113311, 19 (stack45)
        %v113319 = vor.u32 %v113318, %v113317 (stack46)
        %v113320 = vxor.u32 %v113319, %v113315 (stack47)
        %v113323 = vadd.s32 %v113320, %v113315 (stack39)
        %v113325 = vshll.u32 %v113320, 15 (stack44)
        %v113326 = vshrl.u32 %v113320, 17 (stack45)
        %v113327 = vor.u32 %v113326, %v113325 (stack46)
        %v113328 = vxor.u32 %v113327, %v113323 (stack47)
        %v113331 = vadd.s32 %v113328, %v113323 (stack39)
        %v113333 = vshll.u32 %v113328, 26 (stack44)
        %v113334 = vshrl.u32 %v113328, 6 (stack45)
        %v113335 = vor.u32 %v113334, %v113333 (stack46)
        %v113336 = vxor.u32 %v113335, %v113331 (stack47)
        %v113339 = vadd.s32 %v113336, %v113331 (stack39)
        %v113343 = vadd.s32 %v113339, %v10 (stack39)
        %v113345 = vshll.u32 %v113336, 6 (stack44)
        %v113346 = vshrl.u32 %v113336, 26 (stack45)
        %v113347 = vor.u32 %v113346, %v113345 (stack46)
        %v113348 = vxor.u32 %v113347, %v113339 (stack47)
        %v113351 = vadd.s32 %v113348, %v9 (stack39)
        %v113355 = vadd.s32 3, %v113351 (stack39)
        %v113359 = vadd.s32 %v113355, %v113343 (stack39)
        %v113361 = vshll.u32 %v113355, 17 (stack44)
        %v113362 = vshrl.u32 %v113355, 15 (stack45)
        %v113363 = vor.u32 %v113362, %v113361 (stack46)
        %v113364 = vxor.u32 %v113363, %v113359 (stack47)
        %v113367 = vadd.s32 %v113364, %v113359 (stack39)
        %v113369 = vshll.u32 %v113364, 29 (stack44)
        %v113370 = vshrl.u32 %v113364, 3 (stack45)
        %v113371 = vor.u32 %v113370, %v113369 (stack46)
        %v113372 = vxor.u32 %v113371, %v113367 (stack47)
        %v113375 = vadd.s32 %v113372, %v113367 (stack39)
        %v113377 = vshll.u32 %v113372, 16 (stack44)
        %v113378 = vshrl.u32 %v113372, 16 (stack45)
        %v113379 = vor.u32 %v113378, %v113377 (stack46)
        %v113380 = vxor.u32 %v113379, %v113375 (stack47)
        %v113383 = vadd.s32 %v113380, %v113375 (stack39)
        %v113387 = vadd.s32 %v113383, %v9 (stack39)
        %v113389 = vshll.u32 %v113380, 24 (stack44)
        %v113390 = vshrl.u32 %v113380, 8 (stack45)
        %v113391 = vor.u32 %v113390, %v113389 (stack46)
        %v113392 = vxor.u32 %v113391, %v113383 (stack47)
        %v113395 = vadd.s32 %v113392, %v8 (stack39)
        %v113399 = vadd.s32 4, %v113395 (stack39)
        %v113403 = vadd.s32 %v113399, %v113387 (stack39)
        %v113405 = vshll.u32 %v113399, 13 (stack44)
        %v113406 = vshrl.u32 %v113399, 19 (stack45)
        %v113407 = vor.u32 %v113406, %v113405 (stack46)
        %v113408 = vxor.u32 %v113407, %v113403 (stack47)
        %v113411 = vadd.s32 %v113408, %v113403 (stack39)
        %v113413 = vshll.u32 %v113408, 15 (stack44)
        %v113414 = vshrl.u32 %v113408, 17 (stack45)
        %v113415 = vor.u32 %v113414, %v113413 (stack46)
        %v113416 = vxor.u32 %v113415, %v113411 (stack47)
        %v113419 = vadd.s32 %v113416, %v113411 (stack39)
        %v113421 = vshll.u32 %v113416, 26 (stack44)
        %v113422 = vshrl.u32 %v113416, 6 (stack45)
        %v113423 = vor.u32 %v113422, %v113421 (stack46)
        %v113424 = vxor.u32 %v113423, %v113419 (stack47)
        %v113427 = vadd.s32 %v113424, %v113419 (stack39)
        %v113431 = vadd.s32 %v113427, %v8 (stack39)
        %v113433 = vshll.u32 %v113424, 6 (stack44)
        %v113434 = vshrl.u32 %v113424, 26 (stack45)
        %v113435 = vor.u32 %v113434, %v113433 (stack46)
        %v113436 = vxor.u32 %v113435, %v113427 (stack47)
        %v113439 = vadd.s32 %v113436, %v10 (stack39)
        %v113443 = vadd.s32 5, %v113439 (stack39)
        %v113445 = vxor.u32 %v113443, %v113431 (stack47)
        %v113446 = vand.u32.u8 255, %v113445 (stack48)
        %v113447 = vand.u32 65535, %v113446 (stack49)
        %v113448 = vshrl.u32 %v113447, 1 (stack50)
        %v113449 = vor.u32 16256, %v113448 (stack46)
        %v113450 = vand.u32.u16 65535, %v113449 (stack51)
        %v120352 = vadd.low.f32.bf16 -1.0, %v113450 (stack52)
        %v113459 = vmul.f32 2.0, %v120352 (stack53)
        %v113463 = vadd.f32 -0.99609375, %v113459 (stack52)
        %v113467 = vmax.f32 %v113463, -0.99609375 (stack54)
        %v113469 = vand.u32 2147483647, %v113467 (stack55)
        %vm113472 = vcmp.eq.f32.partialorder %v113469, 1.0 (stack56)
        %v113477 = vmul.f32 inf, %v113467 (stack53)
        %v113479 = vxor.u32 2147483648, %v113467 (stack57)
        %v113482 = vmul.f32 %v113479, %v113467 (stack53)
        %v113484 = vadd.f32 1.0, %v113482 (stack58)
        %v113485 = vlog2.pop %v113484 (stack59)
        %v113486 = vmul.f32 0.6931472, %v113485 (stack60)
        %v113487 = vmul.f32 -0.5, %v113482 (stack61)
        %v113488 = vadd.f32 1.0, %v113487 (stack62)
        %v113489 = vmul.f32 %v113488, %v113482 (stack63)
        %v113490 = vand.u32 2147483647, %v113482 (stack64)
        %vm113491 = vcmp.lt.f32.partialorder %v113490, 0.0004427343 (stack65)
        %v113492 = vsel /*vm=*/%vm113491, /*on_true_vy=*/%v113489, /*on_false_vx=*/%v113486 (stack66)
        %v113493 = vxor.u32 2147483648, %v113492 (stack57)
        %vm113496 = vcmp.lt.f32.partialorder %v113493, 5.0 (stack56)
        %v113501 = vsel /*vm=*/%vm113496, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v113505 = vsel /*vm=*/%vm113496, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v113509 = vsel /*vm=*/%vm113496, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v113513 = vsel /*vm=*/%vm113496, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v113517 = vsel /*vm=*/%vm113496, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v113521 = vsel /*vm=*/%vm113496, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v113525 = vsel /*vm=*/%vm113496, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v113529 = vsel /*vm=*/%vm113496, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v113533 = vsel /*vm=*/%vm113496, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v113537 = vadd.f32 -2.5, %v113493 (stack52)
        %v113539 = vrsqrt.pop %v113493 (stack67)
        %v113540 = vmul.f32 %v113539, %v113493 (stack68)
        %vm113541 = vcmp.eq.f32.partialorder %v113493, inf (stack69)
        %v113542 = vsel /*vm=*/%vm113541, /*on_true_vy=*/%v113493, /*on_false_vx=*/%v113540 (stack70)
        %vm113543 = vcmp.eq.f32.partialorder %v113493, 0.0 (stack71)
        %v113544 = vand.u32 2147483648, %v113493 (stack72)
        %v113545 = vsel /*vm=*/%vm113543, /*on_true_vy=*/%v113544, /*on_false_vx=*/%v113542 (stack73)
        %v113548 = vadd.f32 -3.0, %v113545 (stack52)
        %v113552 = vsel /*vm=*/%vm113496, /*on_true_vy=*/%v113537, /*on_false_vx=*/%v113548 (stack43)
        %v113556 = vmul.f32 %v113552, %v113533 (stack53)
        %v113560 = vadd.f32 %v113556, %v113529 (stack52)
        %v113564 = vmul.f32 %v113560, %v113552 (stack53)
        %v113568 = vadd.f32 %v113564, %v113525 (stack52)
        %v113572 = vmul.f32 %v113568, %v113552 (stack53)
        %v113576 = vadd.f32 %v113572, %v113521 (stack52)
        %v113580 = vmul.f32 %v113576, %v113552 (stack53)
        %v113584 = vadd.f32 %v113580, %v113517 (stack52)
        %v113588 = vmul.f32 %v113584, %v113552 (stack53)
        %v113592 = vadd.f32 %v113588, %v113513 (stack52)
        %v113596 = vmul.f32 %v113592, %v113552 (stack53)
        %v113600 = vadd.f32 %v113596, %v113509 (stack52)
        %v113604 = vmul.f32 %v113600, %v113552 (stack53)
        %v113608 = vadd.f32 %v113604, %v113505 (stack52)
        %v113612 = vmul.f32 %v113608, %v113552 (stack53)
        %v113616 = vadd.f32 %v113612, %v113501 (stack52)
        %v113620 = vmul.f32 %v113616, %v113467 (stack53)
        %v113624 = vsel /*vm=*/%vm113472, /*on_true_vy=*/%v113477, /*on_false_vx=*/%v113620 (stack43)
        %v113628 = vmul.f32 1.4140625, %v113624 (stack53)
        %v113631 = vpack.c.bf16 0.0, %v113628 (stack74)
        %120353 = vst [vmem:[%s280 + $0x178] sm:$0xf] /*vst_source=*/%v113631 (stack75)
        %v113635 = vadd.s32 %v112249, %v1868 (stack39)
        %v113645 = vadd.s32 %v113635, %v415 (stack39)
        %vm113649 = vcmp.lt.u32.totalorder %v113645, %v113635 (stack42)
        %vm113654 = vcmp.lt.u32.totalorder %v113635, %v1868 (stack42)
        %v113659 = vadd.s32 %v112232, %v1855 (stack39)
        %v113663 = vadd.s32 1, %v113659 (stack39)
        %v113667 = vsel /*vm=*/%vm113654, /*on_true_vy=*/%v113663, /*on_false_vx=*/%v113659 (stack43)
        %v113671 = vadd.s32 1, %v113667 (stack39)
        %v113675 = vsel /*vm=*/%vm113649, /*on_true_vy=*/%v113671, /*on_false_vx=*/%v113667 (stack43)
        %v113680 = vadd.s32 %v113675, %v10 (stack39)
        %v113684 = vadd.s32 %v113645, %v9 (stack39)
        %v113688 = vadd.s32 %v113684, %v113680 (stack39)
        %v113690 = vshll.u32 %v113684, 13 (stack44)
        %v113691 = vshrl.u32 %v113684, 19 (stack45)
        %v113692 = vor.u32 %v113691, %v113690 (stack46)
        %v113693 = vxor.u32 %v113692, %v113688 (stack47)
        %v113696 = vadd.s32 %v113693, %v113688 (stack39)
        %v113698 = vshll.u32 %v113693, 15 (stack44)
        %v113699 = vshrl.u32 %v113693, 17 (stack45)
        %v113700 = vor.u32 %v113699, %v113698 (stack46)
        %v113701 = vxor.u32 %v113700, %v113696 (stack47)
        %v113704 = vadd.s32 %v113701, %v113696 (stack39)
        %v113706 = vshll.u32 %v113701, 26 (stack44)
        %v113707 = vshrl.u32 %v113701, 6 (stack45)
        %v113708 = vor.u32 %v113707, %v113706 (stack46)
        %v113709 = vxor.u32 %v113708, %v113704 (stack47)
        %v113712 = vadd.s32 %v113709, %v113704 (stack39)
        %v113716 = vadd.s32 %v113712, %v9 (stack39)
        %v113718 = vshll.u32 %v113709, 6 (stack44)
        %v113719 = vshrl.u32 %v113709, 26 (stack45)
        %v113720 = vor.u32 %v113719, %v113718 (stack46)
        %v113721 = vxor.u32 %v113720, %v113712 (stack47)
        %v113724 = vadd.s32 %v113721, %v8 (stack39)
        %v113728 = vadd.s32 1, %v113724 (stack39)
        %v113732 = vadd.s32 %v113728, %v113716 (stack39)
        %v113734 = vshll.u32 %v113728, 17 (stack44)
        %v113735 = vshrl.u32 %v113728, 15 (stack45)
        %v113736 = vor.u32 %v113735, %v113734 (stack46)
        %v113737 = vxor.u32 %v113736, %v113732 (stack47)
        %v113740 = vadd.s32 %v113737, %v113732 (stack39)
        %v113742 = vshll.u32 %v113737, 29 (stack44)
        %v113743 = vshrl.u32 %v113737, 3 (stack45)
        %v113744 = vor.u32 %v113743, %v113742 (stack46)
        %v113745 = vxor.u32 %v113744, %v113740 (stack47)
        %v113748 = vadd.s32 %v113745, %v113740 (stack39)
        %v113750 = vshll.u32 %v113745, 16 (stack44)
        %v113751 = vshrl.u32 %v113745, 16 (stack45)
        %v113752 = vor.u32 %v113751, %v113750 (stack46)
        %v113753 = vxor.u32 %v113752, %v113748 (stack47)
        %v113756 = vadd.s32 %v113753, %v113748 (stack39)
        %v113760 = vadd.s32 %v113756, %v8 (stack39)
        %v113762 = vshll.u32 %v113753, 24 (stack44)
        %v113763 = vshrl.u32 %v113753, 8 (stack45)
        %v113764 = vor.u32 %v113763, %v113762 (stack46)
        %v113765 = vxor.u32 %v113764, %v113756 (stack47)
        %v113768 = vadd.s32 %v113765, %v10 (stack39)
        %v113772 = vadd.s32 2, %v113768 (stack39)
        %v113776 = vadd.s32 %v113772, %v113760 (stack39)
        %v113778 = vshll.u32 %v113772, 13 (stack44)
        %v113779 = vshrl.u32 %v113772, 19 (stack45)
        %v113780 = vor.u32 %v113779, %v113778 (stack46)
        %v113781 = vxor.u32 %v113780, %v113776 (stack47)
        %v113784 = vadd.s32 %v113781, %v113776 (stack39)
        %v113786 = vshll.u32 %v113781, 15 (stack44)
        %v113787 = vshrl.u32 %v113781, 17 (stack45)
        %v113788 = vor.u32 %v113787, %v113786 (stack46)
        %v113789 = vxor.u32 %v113788, %v113784 (stack47)
        %v113792 = vadd.s32 %v113789, %v113784 (stack39)
        %v113794 = vshll.u32 %v113789, 26 (stack44)
        %v113795 = vshrl.u32 %v113789, 6 (stack45)
        %v113796 = vor.u32 %v113795, %v113794 (stack46)
        %v113797 = vxor.u32 %v113796, %v113792 (stack47)
        %v113800 = vadd.s32 %v113797, %v113792 (stack39)
        %v113804 = vadd.s32 %v113800, %v10 (stack39)
        %v113806 = vshll.u32 %v113797, 6 (stack44)
        %v113807 = vshrl.u32 %v113797, 26 (stack45)
        %v113808 = vor.u32 %v113807, %v113806 (stack46)
        %v113809 = vxor.u32 %v113808, %v113800 (stack47)
        %v113812 = vadd.s32 %v113809, %v9 (stack39)
        %v113816 = vadd.s32 3, %v113812 (stack39)
        %v113820 = vadd.s32 %v113816, %v113804 (stack39)
        %v113822 = vshll.u32 %v113816, 17 (stack44)
        %v113823 = vshrl.u32 %v113816, 15 (stack45)
        %v113824 = vor.u32 %v113823, %v113822 (stack46)
        %v113825 = vxor.u32 %v113824, %v113820 (stack47)
        %v113828 = vadd.s32 %v113825, %v113820 (stack39)
        %v113830 = vshll.u32 %v113825, 29 (stack44)
        %v113831 = vshrl.u32 %v113825, 3 (stack45)
        %v113832 = vor.u32 %v113831, %v113830 (stack46)
        %v113833 = vxor.u32 %v113832, %v113828 (stack47)
        %v113836 = vadd.s32 %v113833, %v113828 (stack39)
        %v113838 = vshll.u32 %v113833, 16 (stack44)
        %v113839 = vshrl.u32 %v113833, 16 (stack45)
        %v113840 = vor.u32 %v113839, %v113838 (stack46)
        %v113841 = vxor.u32 %v113840, %v113836 (stack47)
        %v113844 = vadd.s32 %v113841, %v113836 (stack39)
        %v113848 = vadd.s32 %v113844, %v9 (stack39)
        %v113850 = vshll.u32 %v113841, 24 (stack44)
        %v113851 = vshrl.u32 %v113841, 8 (stack45)
        %v113852 = vor.u32 %v113851, %v113850 (stack46)
        %v113853 = vxor.u32 %v113852, %v113844 (stack47)
        %v113856 = vadd.s32 %v113853, %v8 (stack39)
        %v113860 = vadd.s32 4, %v113856 (stack39)
        %v113864 = vadd.s32 %v113860, %v113848 (stack39)
        %v113866 = vshll.u32 %v113860, 13 (stack44)
        %v113867 = vshrl.u32 %v113860, 19 (stack45)
        %v113868 = vor.u32 %v113867, %v113866 (stack46)
        %v113869 = vxor.u32 %v113868, %v113864 (stack47)
        %v113872 = vadd.s32 %v113869, %v113864 (stack39)
        %v113874 = vshll.u32 %v113869, 15 (stack44)
        %v113875 = vshrl.u32 %v113869, 17 (stack45)
        %v113876 = vor.u32 %v113875, %v113874 (stack46)
        %v113877 = vxor.u32 %v113876, %v113872 (stack47)
        %v113880 = vadd.s32 %v113877, %v113872 (stack39)
        %v113882 = vshll.u32 %v113877, 26 (stack44)
        %v113883 = vshrl.u32 %v113877, 6 (stack45)
        %v113884 = vor.u32 %v113883, %v113882 (stack46)
        %v113885 = vxor.u32 %v113884, %v113880 (stack47)
        %v113888 = vadd.s32 %v113885, %v113880 (stack39)
        %v113892 = vadd.s32 %v113888, %v8 (stack39)
        %v113894 = vshll.u32 %v113885, 6 (stack44)
        %v113895 = vshrl.u32 %v113885, 26 (stack45)
        %v113896 = vor.u32 %v113895, %v113894 (stack46)
        %v113897 = vxor.u32 %v113896, %v113888 (stack47)
        %v113900 = vadd.s32 %v113897, %v10 (stack39)
        %v113904 = vadd.s32 5, %v113900 (stack39)
        %v113906 = vxor.u32 %v113904, %v113892 (stack47)
        %v113907 = vand.u32.u8 255, %v113906 (stack48)
        %v113908 = vand.u32 65535, %v113907 (stack49)
        %v113909 = vshrl.u32 %v113908, 1 (stack50)
        %v113910 = vor.u32 16256, %v113909 (stack46)
        %v113911 = vand.u32.u16 65535, %v113910 (stack51)
        %v120354 = vadd.low.f32.bf16 -1.0, %v113911 (stack52)
        %v113920 = vmul.f32 2.0, %v120354 (stack53)
        %v113924 = vadd.f32 -0.99609375, %v113920 (stack52)
        %v113928 = vmax.f32 %v113924, -0.99609375 (stack54)
        %v113930 = vand.u32 2147483647, %v113928 (stack55)
        %vm113933 = vcmp.eq.f32.partialorder %v113930, 1.0 (stack56)
        %v113938 = vmul.f32 inf, %v113928 (stack53)
        %v113940 = vxor.u32 2147483648, %v113928 (stack57)
        %v113943 = vmul.f32 %v113940, %v113928 (stack53)
        %v113945 = vadd.f32 1.0, %v113943 (stack58)
        %v113946 = vlog2.pop %v113945 (stack59)
        %v113947 = vmul.f32 0.6931472, %v113946 (stack60)
        %v113948 = vmul.f32 -0.5, %v113943 (stack61)
        %v113949 = vadd.f32 1.0, %v113948 (stack62)
        %v113950 = vmul.f32 %v113949, %v113943 (stack63)
        %v113951 = vand.u32 2147483647, %v113943 (stack64)
        %vm113952 = vcmp.lt.f32.partialorder %v113951, 0.0004427343 (stack65)
        %v113953 = vsel /*vm=*/%vm113952, /*on_true_vy=*/%v113950, /*on_false_vx=*/%v113947 (stack66)
        %v113954 = vxor.u32 2147483648, %v113953 (stack57)
        %vm113957 = vcmp.lt.f32.partialorder %v113954, 5.0 (stack56)
        %v113962 = vsel /*vm=*/%vm113957, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v113966 = vsel /*vm=*/%vm113957, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v113970 = vsel /*vm=*/%vm113957, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v113974 = vsel /*vm=*/%vm113957, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v113978 = vsel /*vm=*/%vm113957, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v113982 = vsel /*vm=*/%vm113957, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v113986 = vsel /*vm=*/%vm113957, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v113990 = vsel /*vm=*/%vm113957, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v113994 = vsel /*vm=*/%vm113957, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v113998 = vadd.f32 -2.5, %v113954 (stack52)
        %v114000 = vrsqrt.pop %v113954 (stack67)
        %v114001 = vmul.f32 %v114000, %v113954 (stack68)
        %vm114002 = vcmp.eq.f32.partialorder %v113954, inf (stack69)
        %v114003 = vsel /*vm=*/%vm114002, /*on_true_vy=*/%v113954, /*on_false_vx=*/%v114001 (stack70)
        %vm114004 = vcmp.eq.f32.partialorder %v113954, 0.0 (stack71)
        %v114005 = vand.u32 2147483648, %v113954 (stack72)
        %v114006 = vsel /*vm=*/%vm114004, /*on_true_vy=*/%v114005, /*on_false_vx=*/%v114003 (stack73)
        %v114009 = vadd.f32 -3.0, %v114006 (stack52)
        %v114013 = vsel /*vm=*/%vm113957, /*on_true_vy=*/%v113998, /*on_false_vx=*/%v114009 (stack43)
        %v114017 = vmul.f32 %v114013, %v113994 (stack53)
        %v114021 = vadd.f32 %v114017, %v113990 (stack52)
        %v114025 = vmul.f32 %v114021, %v114013 (stack53)
        %v114029 = vadd.f32 %v114025, %v113986 (stack52)
        %v114033 = vmul.f32 %v114029, %v114013 (stack53)
        %v114037 = vadd.f32 %v114033, %v113982 (stack52)
        %v114041 = vmul.f32 %v114037, %v114013 (stack53)
        %v114045 = vadd.f32 %v114041, %v113978 (stack52)
        %v114049 = vmul.f32 %v114045, %v114013 (stack53)
        %v114053 = vadd.f32 %v114049, %v113974 (stack52)
        %v114057 = vmul.f32 %v114053, %v114013 (stack53)
        %v114061 = vadd.f32 %v114057, %v113970 (stack52)
        %v114065 = vmul.f32 %v114061, %v114013 (stack53)
        %v114069 = vadd.f32 %v114065, %v113966 (stack52)
        %v114073 = vmul.f32 %v114069, %v114013 (stack53)
        %v114077 = vadd.f32 %v114073, %v113962 (stack52)
        %v114081 = vmul.f32 %v114077, %v113928 (stack53)
        %v114085 = vsel /*vm=*/%vm113933, /*on_true_vy=*/%v113938, /*on_false_vx=*/%v114081 (stack43)
        %v114089 = vmul.f32 1.4140625, %v114085 (stack53)
        %v114092 = vpack.c.bf16 0.0, %v114089 (stack74)
        %120355 = vst [vmem:[%s280 + $0x1f8] sm:$0xf] /*vst_source=*/%v114092 (stack75)
        %v114096 = vadd.s32 %v112249, %v2355 (stack39)
        %v114106 = vadd.s32 %v114096, %v415 (stack39)
        %vm114110 = vcmp.lt.u32.totalorder %v114106, %v114096 (stack42)
        %vm114115 = vcmp.lt.u32.totalorder %v114096, %v2355 (stack42)
        %v114120 = vadd.s32 %v112232, %v2342 (stack39)
        %v114124 = vadd.s32 1, %v114120 (stack39)
        %v114128 = vsel /*vm=*/%vm114115, /*on_true_vy=*/%v114124, /*on_false_vx=*/%v114120 (stack43)
        %v114132 = vadd.s32 1, %v114128 (stack39)
        %v114136 = vsel /*vm=*/%vm114110, /*on_true_vy=*/%v114132, /*on_false_vx=*/%v114128 (stack43)
        %v114141 = vadd.s32 %v114136, %v10 (stack39)
        %v114145 = vadd.s32 %v114106, %v9 (stack39)
        %v114149 = vadd.s32 %v114145, %v114141 (stack39)
        %v114151 = vshll.u32 %v114145, 13 (stack44)
        %v114152 = vshrl.u32 %v114145, 19 (stack45)
        %v114153 = vor.u32 %v114152, %v114151 (stack46)
        %v114154 = vxor.u32 %v114153, %v114149 (stack47)
        %v114157 = vadd.s32 %v114154, %v114149 (stack39)
        %v114159 = vshll.u32 %v114154, 15 (stack44)
        %v114160 = vshrl.u32 %v114154, 17 (stack45)
        %v114161 = vor.u32 %v114160, %v114159 (stack46)
        %v114162 = vxor.u32 %v114161, %v114157 (stack47)
        %v114165 = vadd.s32 %v114162, %v114157 (stack39)
        %v114167 = vshll.u32 %v114162, 26 (stack44)
        %v114168 = vshrl.u32 %v114162, 6 (stack45)
        %v114169 = vor.u32 %v114168, %v114167 (stack46)
        %v114170 = vxor.u32 %v114169, %v114165 (stack47)
        %v114173 = vadd.s32 %v114170, %v114165 (stack39)
        %v114177 = vadd.s32 %v114173, %v9 (stack39)
        %v114179 = vshll.u32 %v114170, 6 (stack44)
        %v114180 = vshrl.u32 %v114170, 26 (stack45)
        %v114181 = vor.u32 %v114180, %v114179 (stack46)
        %v114182 = vxor.u32 %v114181, %v114173 (stack47)
        %v114185 = vadd.s32 %v114182, %v8 (stack39)
        %v114189 = vadd.s32 1, %v114185 (stack39)
        %v114193 = vadd.s32 %v114189, %v114177 (stack39)
        %v114195 = vshll.u32 %v114189, 17 (stack44)
        %v114196 = vshrl.u32 %v114189, 15 (stack45)
        %v114197 = vor.u32 %v114196, %v114195 (stack46)
        %v114198 = vxor.u32 %v114197, %v114193 (stack47)
        %v114201 = vadd.s32 %v114198, %v114193 (stack39)
        %v114203 = vshll.u32 %v114198, 29 (stack44)
        %v114204 = vshrl.u32 %v114198, 3 (stack45)
        %v114205 = vor.u32 %v114204, %v114203 (stack46)
        %v114206 = vxor.u32 %v114205, %v114201 (stack47)
        %v114209 = vadd.s32 %v114206, %v114201 (stack39)
        %v114211 = vshll.u32 %v114206, 16 (stack44)
        %v114212 = vshrl.u32 %v114206, 16 (stack45)
        %v114213 = vor.u32 %v114212, %v114211 (stack46)
        %v114214 = vxor.u32 %v114213, %v114209 (stack47)
        %v114217 = vadd.s32 %v114214, %v114209 (stack39)
        %v114221 = vadd.s32 %v114217, %v8 (stack39)
        %v114223 = vshll.u32 %v114214, 24 (stack44)
        %v114224 = vshrl.u32 %v114214, 8 (stack45)
        %v114225 = vor.u32 %v114224, %v114223 (stack46)
        %v114226 = vxor.u32 %v114225, %v114217 (stack47)
        %v114229 = vadd.s32 %v114226, %v10 (stack39)
        %v114233 = vadd.s32 2, %v114229 (stack39)
        %v114237 = vadd.s32 %v114233, %v114221 (stack39)
        %v114239 = vshll.u32 %v114233, 13 (stack44)
        %v114240 = vshrl.u32 %v114233, 19 (stack45)
        %v114241 = vor.u32 %v114240, %v114239 (stack46)
        %v114242 = vxor.u32 %v114241, %v114237 (stack47)
        %v114245 = vadd.s32 %v114242, %v114237 (stack39)
        %v114247 = vshll.u32 %v114242, 15 (stack44)
        %v114248 = vshrl.u32 %v114242, 17 (stack45)
        %v114249 = vor.u32 %v114248, %v114247 (stack46)
        %v114250 = vxor.u32 %v114249, %v114245 (stack47)
        %v114253 = vadd.s32 %v114250, %v114245 (stack39)
        %v114255 = vshll.u32 %v114250, 26 (stack44)
        %v114256 = vshrl.u32 %v114250, 6 (stack45)
        %v114257 = vor.u32 %v114256, %v114255 (stack46)
        %v114258 = vxor.u32 %v114257, %v114253 (stack47)
        %v114261 = vadd.s32 %v114258, %v114253 (stack39)
        %v114265 = vadd.s32 %v114261, %v10 (stack39)
        %v114267 = vshll.u32 %v114258, 6 (stack44)
        %v114268 = vshrl.u32 %v114258, 26 (stack45)
        %v114269 = vor.u32 %v114268, %v114267 (stack46)
        %v114270 = vxor.u32 %v114269, %v114261 (stack47)
        %v114273 = vadd.s32 %v114270, %v9 (stack39)
        %v114277 = vadd.s32 3, %v114273 (stack39)
        %v114281 = vadd.s32 %v114277, %v114265 (stack39)
        %v114283 = vshll.u32 %v114277, 17 (stack44)
        %v114284 = vshrl.u32 %v114277, 15 (stack45)
        %v114285 = vor.u32 %v114284, %v114283 (stack46)
        %v114286 = vxor.u32 %v114285, %v114281 (stack47)
        %v114289 = vadd.s32 %v114286, %v114281 (stack39)
        %v114291 = vshll.u32 %v114286, 29 (stack44)
        %v114292 = vshrl.u32 %v114286, 3 (stack45)
        %v114293 = vor.u32 %v114292, %v114291 (stack46)
        %v114294 = vxor.u32 %v114293, %v114289 (stack47)
        %v114297 = vadd.s32 %v114294, %v114289 (stack39)
        %v114299 = vshll.u32 %v114294, 16 (stack44)
        %v114300 = vshrl.u32 %v114294, 16 (stack45)
        %v114301 = vor.u32 %v114300, %v114299 (stack46)
        %v114302 = vxor.u32 %v114301, %v114297 (stack47)
        %v114305 = vadd.s32 %v114302, %v114297 (stack39)
        %v114309 = vadd.s32 %v114305, %v9 (stack39)
        %v114311 = vshll.u32 %v114302, 24 (stack44)
        %v114312 = vshrl.u32 %v114302, 8 (stack45)
        %v114313 = vor.u32 %v114312, %v114311 (stack46)
        %v114314 = vxor.u32 %v114313, %v114305 (stack47)
        %v114317 = vadd.s32 %v114314, %v8 (stack39)
        %v114321 = vadd.s32 4, %v114317 (stack39)
        %v114325 = vadd.s32 %v114321, %v114309 (stack39)
        %v114327 = vshll.u32 %v114321, 13 (stack44)
        %v114328 = vshrl.u32 %v114321, 19 (stack45)
        %v114329 = vor.u32 %v114328, %v114327 (stack46)
        %v114330 = vxor.u32 %v114329, %v114325 (stack47)
        %v114333 = vadd.s32 %v114330, %v114325 (stack39)
        %v114335 = vshll.u32 %v114330, 15 (stack44)
        %v114336 = vshrl.u32 %v114330, 17 (stack45)
        %v114337 = vor.u32 %v114336, %v114335 (stack46)
        %v114338 = vxor.u32 %v114337, %v114333 (stack47)
        %v114341 = vadd.s32 %v114338, %v114333 (stack39)
        %v114343 = vshll.u32 %v114338, 26 (stack44)
        %v114344 = vshrl.u32 %v114338, 6 (stack45)
        %v114345 = vor.u32 %v114344, %v114343 (stack46)
        %v114346 = vxor.u32 %v114345, %v114341 (stack47)
        %v114349 = vadd.s32 %v114346, %v114341 (stack39)
        %v114353 = vadd.s32 %v114349, %v8 (stack39)
        %v114355 = vshll.u32 %v114346, 6 (stack44)
        %v114356 = vshrl.u32 %v114346, 26 (stack45)
        %v114357 = vor.u32 %v114356, %v114355 (stack46)
        %v114358 = vxor.u32 %v114357, %v114349 (stack47)
        %v114361 = vadd.s32 %v114358, %v10 (stack39)
        %v114365 = vadd.s32 5, %v114361 (stack39)
        %v114367 = vxor.u32 %v114365, %v114353 (stack47)
        %v114368 = vand.u32.u8 255, %v114367 (stack48)
        %v114369 = vand.u32 65535, %v114368 (stack49)
        %v114370 = vshrl.u32 %v114369, 1 (stack50)
        %v114371 = vor.u32 16256, %v114370 (stack46)
        %v114372 = vand.u32.u16 65535, %v114371 (stack51)
        %v120356 = vadd.low.f32.bf16 -1.0, %v114372 (stack52)
        %v114381 = vmul.f32 2.0, %v120356 (stack53)
        %v114385 = vadd.f32 -0.99609375, %v114381 (stack52)
        %v114389 = vmax.f32 %v114385, -0.99609375 (stack54)
        %v114391 = vand.u32 2147483647, %v114389 (stack55)
        %vm114394 = vcmp.eq.f32.partialorder %v114391, 1.0 (stack56)
        %v114399 = vmul.f32 inf, %v114389 (stack53)
        %v114401 = vxor.u32 2147483648, %v114389 (stack57)
        %v114404 = vmul.f32 %v114401, %v114389 (stack53)
        %v114406 = vadd.f32 1.0, %v114404 (stack58)
        %v114407 = vlog2.pop %v114406 (stack59)
        %v114408 = vmul.f32 0.6931472, %v114407 (stack60)
        %v114409 = vmul.f32 -0.5, %v114404 (stack61)
        %v114410 = vadd.f32 1.0, %v114409 (stack62)
        %v114411 = vmul.f32 %v114410, %v114404 (stack63)
        %v114412 = vand.u32 2147483647, %v114404 (stack64)
        %vm114413 = vcmp.lt.f32.partialorder %v114412, 0.0004427343 (stack65)
        %v114414 = vsel /*vm=*/%vm114413, /*on_true_vy=*/%v114411, /*on_false_vx=*/%v114408 (stack66)
        %v114415 = vxor.u32 2147483648, %v114414 (stack57)
        %vm114418 = vcmp.lt.f32.partialorder %v114415, 5.0 (stack56)
        %v114423 = vsel /*vm=*/%vm114418, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v114427 = vsel /*vm=*/%vm114418, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v114431 = vsel /*vm=*/%vm114418, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v114435 = vsel /*vm=*/%vm114418, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v114439 = vsel /*vm=*/%vm114418, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v114443 = vsel /*vm=*/%vm114418, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v114447 = vsel /*vm=*/%vm114418, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v114451 = vsel /*vm=*/%vm114418, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v114455 = vsel /*vm=*/%vm114418, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v114459 = vadd.f32 -2.5, %v114415 (stack52)
        %v114461 = vrsqrt.pop %v114415 (stack67)
        %v114462 = vmul.f32 %v114461, %v114415 (stack68)
        %vm114463 = vcmp.eq.f32.partialorder %v114415, inf (stack69)
        %v114464 = vsel /*vm=*/%vm114463, /*on_true_vy=*/%v114415, /*on_false_vx=*/%v114462 (stack70)
        %vm114465 = vcmp.eq.f32.partialorder %v114415, 0.0 (stack71)
        %v114466 = vand.u32 2147483648, %v114415 (stack72)
        %v114467 = vsel /*vm=*/%vm114465, /*on_true_vy=*/%v114466, /*on_false_vx=*/%v114464 (stack73)
        %v114470 = vadd.f32 -3.0, %v114467 (stack52)
        %v114474 = vsel /*vm=*/%vm114418, /*on_true_vy=*/%v114459, /*on_false_vx=*/%v114470 (stack43)
        %v114478 = vmul.f32 %v114474, %v114455 (stack53)
        %v114482 = vadd.f32 %v114478, %v114451 (stack52)
        %v114486 = vmul.f32 %v114482, %v114474 (stack53)
        %v114490 = vadd.f32 %v114486, %v114447 (stack52)
        %v114494 = vmul.f32 %v114490, %v114474 (stack53)
        %v114498 = vadd.f32 %v114494, %v114443 (stack52)
        %v114502 = vmul.f32 %v114498, %v114474 (stack53)
        %v114506 = vadd.f32 %v114502, %v114439 (stack52)
        %v114510 = vmul.f32 %v114506, %v114474 (stack53)
        %v114514 = vadd.f32 %v114510, %v114435 (stack52)
        %v114518 = vmul.f32 %v114514, %v114474 (stack53)
        %v114522 = vadd.f32 %v114518, %v114431 (stack52)
        %v114526 = vmul.f32 %v114522, %v114474 (stack53)
        %v114530 = vadd.f32 %v114526, %v114427 (stack52)
        %v114534 = vmul.f32 %v114530, %v114474 (stack53)
        %v114538 = vadd.f32 %v114534, %v114423 (stack52)
        %v114542 = vmul.f32 %v114538, %v114389 (stack53)
        %v114546 = vsel /*vm=*/%vm114394, /*on_true_vy=*/%v114399, /*on_false_vx=*/%v114542 (stack43)
        %v114550 = vmul.f32 1.4140625, %v114546 (stack53)
        %v114553 = vpack.c.bf16 0.0, %v114550 (stack74)
        %120357 = vst [vmem:[%s280 + $0x278] sm:$0xf] /*vst_source=*/%v114553 (stack75)
        %v114557 = vadd.s32 %v112249, %v2842 (stack39)
        %v114567 = vadd.s32 %v114557, %v415 (stack39)
        %vm114571 = vcmp.lt.u32.totalorder %v114567, %v114557 (stack42)
        %vm114576 = vcmp.lt.u32.totalorder %v114557, %v2842 (stack42)
        %v114581 = vadd.s32 %v112232, %v2829 (stack39)
        %v114585 = vadd.s32 1, %v114581 (stack39)
        %v114589 = vsel /*vm=*/%vm114576, /*on_true_vy=*/%v114585, /*on_false_vx=*/%v114581 (stack43)
        %v114593 = vadd.s32 1, %v114589 (stack39)
        %v114597 = vsel /*vm=*/%vm114571, /*on_true_vy=*/%v114593, /*on_false_vx=*/%v114589 (stack43)
        %v114602 = vadd.s32 %v114597, %v10 (stack39)
        %v114606 = vadd.s32 %v114567, %v9 (stack39)
        %v114610 = vadd.s32 %v114606, %v114602 (stack39)
        %v114612 = vshll.u32 %v114606, 13 (stack44)
        %v114613 = vshrl.u32 %v114606, 19 (stack45)
        %v114614 = vor.u32 %v114613, %v114612 (stack46)
        %v114615 = vxor.u32 %v114614, %v114610 (stack47)
        %v114618 = vadd.s32 %v114615, %v114610 (stack39)
        %v114620 = vshll.u32 %v114615, 15 (stack44)
        %v114621 = vshrl.u32 %v114615, 17 (stack45)
        %v114622 = vor.u32 %v114621, %v114620 (stack46)
        %v114623 = vxor.u32 %v114622, %v114618 (stack47)
        %v114626 = vadd.s32 %v114623, %v114618 (stack39)
        %v114628 = vshll.u32 %v114623, 26 (stack44)
        %v114629 = vshrl.u32 %v114623, 6 (stack45)
        %v114630 = vor.u32 %v114629, %v114628 (stack46)
        %v114631 = vxor.u32 %v114630, %v114626 (stack47)
        %v114634 = vadd.s32 %v114631, %v114626 (stack39)
        %v114638 = vadd.s32 %v114634, %v9 (stack39)
        %v114640 = vshll.u32 %v114631, 6 (stack44)
        %v114641 = vshrl.u32 %v114631, 26 (stack45)
        %v114642 = vor.u32 %v114641, %v114640 (stack46)
        %v114643 = vxor.u32 %v114642, %v114634 (stack47)
        %v114646 = vadd.s32 %v114643, %v8 (stack39)
        %v114650 = vadd.s32 1, %v114646 (stack39)
        %v114654 = vadd.s32 %v114650, %v114638 (stack39)
        %v114656 = vshll.u32 %v114650, 17 (stack44)
        %v114657 = vshrl.u32 %v114650, 15 (stack45)
        %v114658 = vor.u32 %v114657, %v114656 (stack46)
        %v114659 = vxor.u32 %v114658, %v114654 (stack47)
        %v114662 = vadd.s32 %v114659, %v114654 (stack39)
        %v114664 = vshll.u32 %v114659, 29 (stack44)
        %v114665 = vshrl.u32 %v114659, 3 (stack45)
        %v114666 = vor.u32 %v114665, %v114664 (stack46)
        %v114667 = vxor.u32 %v114666, %v114662 (stack47)
        %v114670 = vadd.s32 %v114667, %v114662 (stack39)
        %v114672 = vshll.u32 %v114667, 16 (stack44)
        %v114673 = vshrl.u32 %v114667, 16 (stack45)
        %v114674 = vor.u32 %v114673, %v114672 (stack46)
        %v114675 = vxor.u32 %v114674, %v114670 (stack47)
        %v114678 = vadd.s32 %v114675, %v114670 (stack39)
        %v114682 = vadd.s32 %v114678, %v8 (stack39)
        %v114684 = vshll.u32 %v114675, 24 (stack44)
        %v114685 = vshrl.u32 %v114675, 8 (stack45)
        %v114686 = vor.u32 %v114685, %v114684 (stack46)
        %v114687 = vxor.u32 %v114686, %v114678 (stack47)
        %v114690 = vadd.s32 %v114687, %v10 (stack39)
        %v114694 = vadd.s32 2, %v114690 (stack39)
        %v114698 = vadd.s32 %v114694, %v114682 (stack39)
        %v114700 = vshll.u32 %v114694, 13 (stack44)
        %v114701 = vshrl.u32 %v114694, 19 (stack45)
        %v114702 = vor.u32 %v114701, %v114700 (stack46)
        %v114703 = vxor.u32 %v114702, %v114698 (stack47)
        %v114706 = vadd.s32 %v114703, %v114698 (stack39)
        %v114708 = vshll.u32 %v114703, 15 (stack44)
        %v114709 = vshrl.u32 %v114703, 17 (stack45)
        %v114710 = vor.u32 %v114709, %v114708 (stack46)
        %v114711 = vxor.u32 %v114710, %v114706 (stack47)
        %v114714 = vadd.s32 %v114711, %v114706 (stack39)
        %v114716 = vshll.u32 %v114711, 26 (stack44)
        %v114717 = vshrl.u32 %v114711, 6 (stack45)
        %v114718 = vor.u32 %v114717, %v114716 (stack46)
        %v114719 = vxor.u32 %v114718, %v114714 (stack47)
        %v114722 = vadd.s32 %v114719, %v114714 (stack39)
        %v114726 = vadd.s32 %v114722, %v10 (stack39)
        %v114728 = vshll.u32 %v114719, 6 (stack44)
        %v114729 = vshrl.u32 %v114719, 26 (stack45)
        %v114730 = vor.u32 %v114729, %v114728 (stack46)
        %v114731 = vxor.u32 %v114730, %v114722 (stack47)
        %v114734 = vadd.s32 %v114731, %v9 (stack39)
        %v114738 = vadd.s32 3, %v114734 (stack39)
        %v114742 = vadd.s32 %v114738, %v114726 (stack39)
        %v114744 = vshll.u32 %v114738, 17 (stack44)
        %v114745 = vshrl.u32 %v114738, 15 (stack45)
        %v114746 = vor.u32 %v114745, %v114744 (stack46)
        %v114747 = vxor.u32 %v114746, %v114742 (stack47)
        %v114750 = vadd.s32 %v114747, %v114742 (stack39)
        %v114752 = vshll.u32 %v114747, 29 (stack44)
        %v114753 = vshrl.u32 %v114747, 3 (stack45)
        %v114754 = vor.u32 %v114753, %v114752 (stack46)
        %v114755 = vxor.u32 %v114754, %v114750 (stack47)
        %v114758 = vadd.s32 %v114755, %v114750 (stack39)
        %v114760 = vshll.u32 %v114755, 16 (stack44)
        %v114761 = vshrl.u32 %v114755, 16 (stack45)
        %v114762 = vor.u32 %v114761, %v114760 (stack46)
        %v114763 = vxor.u32 %v114762, %v114758 (stack47)
        %v114766 = vadd.s32 %v114763, %v114758 (stack39)
        %v114770 = vadd.s32 %v114766, %v9 (stack39)
        %v114772 = vshll.u32 %v114763, 24 (stack44)
        %v114773 = vshrl.u32 %v114763, 8 (stack45)
        %v114774 = vor.u32 %v114773, %v114772 (stack46)
        %v114775 = vxor.u32 %v114774, %v114766 (stack47)
        %v114778 = vadd.s32 %v114775, %v8 (stack39)
        %v114782 = vadd.s32 4, %v114778 (stack39)
        %v114786 = vadd.s32 %v114782, %v114770 (stack39)
        %v114788 = vshll.u32 %v114782, 13 (stack44)
        %v114789 = vshrl.u32 %v114782, 19 (stack45)
        %v114790 = vor.u32 %v114789, %v114788 (stack46)
        %v114791 = vxor.u32 %v114790, %v114786 (stack47)
        %v114794 = vadd.s32 %v114791, %v114786 (stack39)
        %v114796 = vshll.u32 %v114791, 15 (stack44)
        %v114797 = vshrl.u32 %v114791, 17 (stack45)
        %v114798 = vor.u32 %v114797, %v114796 (stack46)
        %v114799 = vxor.u32 %v114798, %v114794 (stack47)
        %v114802 = vadd.s32 %v114799, %v114794 (stack39)
        %v114804 = vshll.u32 %v114799, 26 (stack44)
        %v114805 = vshrl.u32 %v114799, 6 (stack45)
        %v114806 = vor.u32 %v114805, %v114804 (stack46)
        %v114807 = vxor.u32 %v114806, %v114802 (stack47)
        %v114810 = vadd.s32 %v114807, %v114802 (stack39)
        %v114814 = vadd.s32 %v114810, %v8 (stack39)
        %v114816 = vshll.u32 %v114807, 6 (stack44)
        %v114817 = vshrl.u32 %v114807, 26 (stack45)
        %v114818 = vor.u32 %v114817, %v114816 (stack46)
        %v114819 = vxor.u32 %v114818, %v114810 (stack47)
        %v114822 = vadd.s32 %v114819, %v10 (stack39)
        %v114826 = vadd.s32 5, %v114822 (stack39)
        %v114828 = vxor.u32 %v114826, %v114814 (stack47)
        %v114829 = vand.u32.u8 255, %v114828 (stack48)
        %v114830 = vand.u32 65535, %v114829 (stack49)
        %v114831 = vshrl.u32 %v114830, 1 (stack50)
        %v114832 = vor.u32 16256, %v114831 (stack46)
        %v114833 = vand.u32.u16 65535, %v114832 (stack51)
        %v120358 = vadd.low.f32.bf16 -1.0, %v114833 (stack52)
        %v114842 = vmul.f32 2.0, %v120358 (stack53)
        %v114846 = vadd.f32 -0.99609375, %v114842 (stack52)
        %v114850 = vmax.f32 %v114846, -0.99609375 (stack54)
        %v114852 = vand.u32 2147483647, %v114850 (stack55)
        %vm114855 = vcmp.eq.f32.partialorder %v114852, 1.0 (stack56)
        %v114860 = vmul.f32 inf, %v114850 (stack53)
        %v114862 = vxor.u32 2147483648, %v114850 (stack57)
        %v114865 = vmul.f32 %v114862, %v114850 (stack53)
        %v114867 = vadd.f32 1.0, %v114865 (stack58)
        %v114868 = vlog2.pop %v114867 (stack59)
        %v114869 = vmul.f32 0.6931472, %v114868 (stack60)
        %v114870 = vmul.f32 -0.5, %v114865 (stack61)
        %v114871 = vadd.f32 1.0, %v114870 (stack62)
        %v114872 = vmul.f32 %v114871, %v114865 (stack63)
        %v114873 = vand.u32 2147483647, %v114865 (stack64)
        %vm114874 = vcmp.lt.f32.partialorder %v114873, 0.0004427343 (stack65)
        %v114875 = vsel /*vm=*/%vm114874, /*on_true_vy=*/%v114872, /*on_false_vx=*/%v114869 (stack66)
        %v114876 = vxor.u32 2147483648, %v114875 (stack57)
        %vm114879 = vcmp.lt.f32.partialorder %v114876, 5.0 (stack56)
        %v114884 = vsel /*vm=*/%vm114879, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v114888 = vsel /*vm=*/%vm114879, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v114892 = vsel /*vm=*/%vm114879, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v114896 = vsel /*vm=*/%vm114879, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v114900 = vsel /*vm=*/%vm114879, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v114904 = vsel /*vm=*/%vm114879, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v114908 = vsel /*vm=*/%vm114879, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v114912 = vsel /*vm=*/%vm114879, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v114916 = vsel /*vm=*/%vm114879, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v114920 = vadd.f32 -2.5, %v114876 (stack52)
        %v114922 = vrsqrt.pop %v114876 (stack67)
        %v114923 = vmul.f32 %v114922, %v114876 (stack68)
        %vm114924 = vcmp.eq.f32.partialorder %v114876, inf (stack69)
        %v114925 = vsel /*vm=*/%vm114924, /*on_true_vy=*/%v114876, /*on_false_vx=*/%v114923 (stack70)
        %vm114926 = vcmp.eq.f32.partialorder %v114876, 0.0 (stack71)
        %v114927 = vand.u32 2147483648, %v114876 (stack72)
        %v114928 = vsel /*vm=*/%vm114926, /*on_true_vy=*/%v114927, /*on_false_vx=*/%v114925 (stack73)
        %v114931 = vadd.f32 -3.0, %v114928 (stack52)
        %v114935 = vsel /*vm=*/%vm114879, /*on_true_vy=*/%v114920, /*on_false_vx=*/%v114931 (stack43)
        %v114939 = vmul.f32 %v114935, %v114916 (stack53)
        %v114943 = vadd.f32 %v114939, %v114912 (stack52)
        %v114947 = vmul.f32 %v114943, %v114935 (stack53)
        %v114951 = vadd.f32 %v114947, %v114908 (stack52)
        %v114955 = vmul.f32 %v114951, %v114935 (stack53)
        %v114959 = vadd.f32 %v114955, %v114904 (stack52)
        %v114963 = vmul.f32 %v114959, %v114935 (stack53)
        %v114967 = vadd.f32 %v114963, %v114900 (stack52)
        %v114971 = vmul.f32 %v114967, %v114935 (stack53)
        %v114975 = vadd.f32 %v114971, %v114896 (stack52)
        %v114979 = vmul.f32 %v114975, %v114935 (stack53)
        %v114983 = vadd.f32 %v114979, %v114892 (stack52)
        %v114987 = vmul.f32 %v114983, %v114935 (stack53)
        %v114991 = vadd.f32 %v114987, %v114888 (stack52)
        %v114995 = vmul.f32 %v114991, %v114935 (stack53)
        %v114999 = vadd.f32 %v114995, %v114884 (stack52)
        %v115003 = vmul.f32 %v114999, %v114850 (stack53)
        %v115007 = vsel /*vm=*/%vm114855, /*on_true_vy=*/%v114860, /*on_false_vx=*/%v115003 (stack43)
        %v115011 = vmul.f32 1.4140625, %v115007 (stack53)
        %v115014 = vpack.c.bf16 0.0, %v115011 (stack74)
        %120359 = vst [vmem:[%s280 + $0x2f8] sm:$0xf] /*vst_source=*/%v115014 (stack75)
        %v115018 = vadd.s32 %v112249, %v3329 (stack39)
        %v115028 = vadd.s32 %v115018, %v415 (stack39)
        %vm115032 = vcmp.lt.u32.totalorder %v115028, %v115018 (stack42)
        %vm115037 = vcmp.lt.u32.totalorder %v115018, %v3329 (stack42)
        %v115042 = vadd.s32 %v112232, %v3316 (stack39)
        %v115046 = vadd.s32 1, %v115042 (stack39)
        %v115050 = vsel /*vm=*/%vm115037, /*on_true_vy=*/%v115046, /*on_false_vx=*/%v115042 (stack43)
        %v115054 = vadd.s32 1, %v115050 (stack39)
        %v115058 = vsel /*vm=*/%vm115032, /*on_true_vy=*/%v115054, /*on_false_vx=*/%v115050 (stack43)
        %v115063 = vadd.s32 %v115058, %v10 (stack39)
        %v115067 = vadd.s32 %v115028, %v9 (stack39)
        %v115071 = vadd.s32 %v115067, %v115063 (stack39)
        %v115073 = vshll.u32 %v115067, 13 (stack44)
        %v115074 = vshrl.u32 %v115067, 19 (stack45)
        %v115075 = vor.u32 %v115074, %v115073 (stack46)
        %v115076 = vxor.u32 %v115075, %v115071 (stack47)
        %v115079 = vadd.s32 %v115076, %v115071 (stack39)
        %v115081 = vshll.u32 %v115076, 15 (stack44)
        %v115082 = vshrl.u32 %v115076, 17 (stack45)
        %v115083 = vor.u32 %v115082, %v115081 (stack46)
        %v115084 = vxor.u32 %v115083, %v115079 (stack47)
        %v115087 = vadd.s32 %v115084, %v115079 (stack39)
        %v115089 = vshll.u32 %v115084, 26 (stack44)
        %v115090 = vshrl.u32 %v115084, 6 (stack45)
        %v115091 = vor.u32 %v115090, %v115089 (stack46)
        %v115092 = vxor.u32 %v115091, %v115087 (stack47)
        %v115095 = vadd.s32 %v115092, %v115087 (stack39)
        %v115099 = vadd.s32 %v115095, %v9 (stack39)
        %v115101 = vshll.u32 %v115092, 6 (stack44)
        %v115102 = vshrl.u32 %v115092, 26 (stack45)
        %v115103 = vor.u32 %v115102, %v115101 (stack46)
        %v115104 = vxor.u32 %v115103, %v115095 (stack47)
        %v115107 = vadd.s32 %v115104, %v8 (stack39)
        %v115111 = vadd.s32 1, %v115107 (stack39)
        %v115115 = vadd.s32 %v115111, %v115099 (stack39)
        %v115117 = vshll.u32 %v115111, 17 (stack44)
        %v115118 = vshrl.u32 %v115111, 15 (stack45)
        %v115119 = vor.u32 %v115118, %v115117 (stack46)
        %v115120 = vxor.u32 %v115119, %v115115 (stack47)
        %v115123 = vadd.s32 %v115120, %v115115 (stack39)
        %v115125 = vshll.u32 %v115120, 29 (stack44)
        %v115126 = vshrl.u32 %v115120, 3 (stack45)
        %v115127 = vor.u32 %v115126, %v115125 (stack46)
        %v115128 = vxor.u32 %v115127, %v115123 (stack47)
        %v115131 = vadd.s32 %v115128, %v115123 (stack39)
        %v115133 = vshll.u32 %v115128, 16 (stack44)
        %v115134 = vshrl.u32 %v115128, 16 (stack45)
        %v115135 = vor.u32 %v115134, %v115133 (stack46)
        %v115136 = vxor.u32 %v115135, %v115131 (stack47)
        %v115139 = vadd.s32 %v115136, %v115131 (stack39)
        %v115143 = vadd.s32 %v115139, %v8 (stack39)
        %v115145 = vshll.u32 %v115136, 24 (stack44)
        %v115146 = vshrl.u32 %v115136, 8 (stack45)
        %v115147 = vor.u32 %v115146, %v115145 (stack46)
        %v115148 = vxor.u32 %v115147, %v115139 (stack47)
        %v115151 = vadd.s32 %v115148, %v10 (stack39)
        %v115155 = vadd.s32 2, %v115151 (stack39)
        %v115159 = vadd.s32 %v115155, %v115143 (stack39)
        %v115161 = vshll.u32 %v115155, 13 (stack44)
        %v115162 = vshrl.u32 %v115155, 19 (stack45)
        %v115163 = vor.u32 %v115162, %v115161 (stack46)
        %v115164 = vxor.u32 %v115163, %v115159 (stack47)
        %v115167 = vadd.s32 %v115164, %v115159 (stack39)
        %v115169 = vshll.u32 %v115164, 15 (stack44)
        %v115170 = vshrl.u32 %v115164, 17 (stack45)
        %v115171 = vor.u32 %v115170, %v115169 (stack46)
        %v115172 = vxor.u32 %v115171, %v115167 (stack47)
        %v115175 = vadd.s32 %v115172, %v115167 (stack39)
        %v115177 = vshll.u32 %v115172, 26 (stack44)
        %v115178 = vshrl.u32 %v115172, 6 (stack45)
        %v115179 = vor.u32 %v115178, %v115177 (stack46)
        %v115180 = vxor.u32 %v115179, %v115175 (stack47)
        %v115183 = vadd.s32 %v115180, %v115175 (stack39)
        %v115187 = vadd.s32 %v115183, %v10 (stack39)
        %v115189 = vshll.u32 %v115180, 6 (stack44)
        %v115190 = vshrl.u32 %v115180, 26 (stack45)
        %v115191 = vor.u32 %v115190, %v115189 (stack46)
        %v115192 = vxor.u32 %v115191, %v115183 (stack47)
        %v115195 = vadd.s32 %v115192, %v9 (stack39)
        %v115199 = vadd.s32 3, %v115195 (stack39)
        %v115203 = vadd.s32 %v115199, %v115187 (stack39)
        %v115205 = vshll.u32 %v115199, 17 (stack44)
        %v115206 = vshrl.u32 %v115199, 15 (stack45)
        %v115207 = vor.u32 %v115206, %v115205 (stack46)
        %v115208 = vxor.u32 %v115207, %v115203 (stack47)
        %v115211 = vadd.s32 %v115208, %v115203 (stack39)
        %v115213 = vshll.u32 %v115208, 29 (stack44)
        %v115214 = vshrl.u32 %v115208, 3 (stack45)
        %v115215 = vor.u32 %v115214, %v115213 (stack46)
        %v115216 = vxor.u32 %v115215, %v115211 (stack47)
        %v115219 = vadd.s32 %v115216, %v115211 (stack39)
        %v115221 = vshll.u32 %v115216, 16 (stack44)
        %v115222 = vshrl.u32 %v115216, 16 (stack45)
        %v115223 = vor.u32 %v115222, %v115221 (stack46)
        %v115224 = vxor.u32 %v115223, %v115219 (stack47)
        %v115227 = vadd.s32 %v115224, %v115219 (stack39)
        %v115231 = vadd.s32 %v115227, %v9 (stack39)
        %v115233 = vshll.u32 %v115224, 24 (stack44)
        %v115234 = vshrl.u32 %v115224, 8 (stack45)
        %v115235 = vor.u32 %v115234, %v115233 (stack46)
        %v115236 = vxor.u32 %v115235, %v115227 (stack47)
        %v115239 = vadd.s32 %v115236, %v8 (stack39)
        %v115243 = vadd.s32 4, %v115239 (stack39)
        %v115247 = vadd.s32 %v115243, %v115231 (stack39)
        %v115249 = vshll.u32 %v115243, 13 (stack44)
        %v115250 = vshrl.u32 %v115243, 19 (stack45)
        %v115251 = vor.u32 %v115250, %v115249 (stack46)
        %v115252 = vxor.u32 %v115251, %v115247 (stack47)
        %v115255 = vadd.s32 %v115252, %v115247 (stack39)
        %v115257 = vshll.u32 %v115252, 15 (stack44)
        %v115258 = vshrl.u32 %v115252, 17 (stack45)
        %v115259 = vor.u32 %v115258, %v115257 (stack46)
        %v115260 = vxor.u32 %v115259, %v115255 (stack47)
        %v115263 = vadd.s32 %v115260, %v115255 (stack39)
        %v115265 = vshll.u32 %v115260, 26 (stack44)
        %v115266 = vshrl.u32 %v115260, 6 (stack45)
        %v115267 = vor.u32 %v115266, %v115265 (stack46)
        %v115268 = vxor.u32 %v115267, %v115263 (stack47)
        %v115271 = vadd.s32 %v115268, %v115263 (stack39)
        %v115275 = vadd.s32 %v115271, %v8 (stack39)
        %v115277 = vshll.u32 %v115268, 6 (stack44)
        %v115278 = vshrl.u32 %v115268, 26 (stack45)
        %v115279 = vor.u32 %v115278, %v115277 (stack46)
        %v115280 = vxor.u32 %v115279, %v115271 (stack47)
        %v115283 = vadd.s32 %v115280, %v10 (stack39)
        %v115287 = vadd.s32 5, %v115283 (stack39)
        %v115289 = vxor.u32 %v115287, %v115275 (stack47)
        %v115290 = vand.u32.u8 255, %v115289 (stack48)
        %v115291 = vand.u32 65535, %v115290 (stack49)
        %v115292 = vshrl.u32 %v115291, 1 (stack50)
        %v115293 = vor.u32 16256, %v115292 (stack46)
        %v115294 = vand.u32.u16 65535, %v115293 (stack51)
        %v120360 = vadd.low.f32.bf16 -1.0, %v115294 (stack52)
        %v115303 = vmul.f32 2.0, %v120360 (stack53)
        %v115307 = vadd.f32 -0.99609375, %v115303 (stack52)
        %v115311 = vmax.f32 %v115307, -0.99609375 (stack54)
        %v115313 = vand.u32 2147483647, %v115311 (stack55)
        %vm115316 = vcmp.eq.f32.partialorder %v115313, 1.0 (stack56)
        %v115321 = vmul.f32 inf, %v115311 (stack53)
        %v115323 = vxor.u32 2147483648, %v115311 (stack57)
        %v115326 = vmul.f32 %v115323, %v115311 (stack53)
        %v115328 = vadd.f32 1.0, %v115326 (stack58)
        %v115329 = vlog2.pop %v115328 (stack59)
        %v115330 = vmul.f32 0.6931472, %v115329 (stack60)
        %v115331 = vmul.f32 -0.5, %v115326 (stack61)
        %v115332 = vadd.f32 1.0, %v115331 (stack62)
        %v115333 = vmul.f32 %v115332, %v115326 (stack63)
        %v115334 = vand.u32 2147483647, %v115326 (stack64)
        %vm115335 = vcmp.lt.f32.partialorder %v115334, 0.0004427343 (stack65)
        %v115336 = vsel /*vm=*/%vm115335, /*on_true_vy=*/%v115333, /*on_false_vx=*/%v115330 (stack66)
        %v115337 = vxor.u32 2147483648, %v115336 (stack57)
        %vm115340 = vcmp.lt.f32.partialorder %v115337, 5.0 (stack56)
        %v115345 = vsel /*vm=*/%vm115340, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v115349 = vsel /*vm=*/%vm115340, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v115353 = vsel /*vm=*/%vm115340, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v115357 = vsel /*vm=*/%vm115340, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v115361 = vsel /*vm=*/%vm115340, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v115365 = vsel /*vm=*/%vm115340, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v115369 = vsel /*vm=*/%vm115340, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v115373 = vsel /*vm=*/%vm115340, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v115377 = vsel /*vm=*/%vm115340, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v115381 = vadd.f32 -2.5, %v115337 (stack52)
        %v115383 = vrsqrt.pop %v115337 (stack67)
        %v115384 = vmul.f32 %v115383, %v115337 (stack68)
        %vm115385 = vcmp.eq.f32.partialorder %v115337, inf (stack69)
        %v115386 = vsel /*vm=*/%vm115385, /*on_true_vy=*/%v115337, /*on_false_vx=*/%v115384 (stack70)
        %vm115387 = vcmp.eq.f32.partialorder %v115337, 0.0 (stack71)
        %v115388 = vand.u32 2147483648, %v115337 (stack72)
        %v115389 = vsel /*vm=*/%vm115387, /*on_true_vy=*/%v115388, /*on_false_vx=*/%v115386 (stack73)
        %v115392 = vadd.f32 -3.0, %v115389 (stack52)
        %v115396 = vsel /*vm=*/%vm115340, /*on_true_vy=*/%v115381, /*on_false_vx=*/%v115392 (stack43)
        %v115400 = vmul.f32 %v115396, %v115377 (stack53)
        %v115404 = vadd.f32 %v115400, %v115373 (stack52)
        %v115408 = vmul.f32 %v115404, %v115396 (stack53)
        %v115412 = vadd.f32 %v115408, %v115369 (stack52)
        %v115416 = vmul.f32 %v115412, %v115396 (stack53)
        %v115420 = vadd.f32 %v115416, %v115365 (stack52)
        %v115424 = vmul.f32 %v115420, %v115396 (stack53)
        %v115428 = vadd.f32 %v115424, %v115361 (stack52)
        %v115432 = vmul.f32 %v115428, %v115396 (stack53)
        %v115436 = vadd.f32 %v115432, %v115357 (stack52)
        %v115440 = vmul.f32 %v115436, %v115396 (stack53)
        %v115444 = vadd.f32 %v115440, %v115353 (stack52)
        %v115448 = vmul.f32 %v115444, %v115396 (stack53)
        %v115452 = vadd.f32 %v115448, %v115349 (stack52)
        %v115456 = vmul.f32 %v115452, %v115396 (stack53)
        %v115460 = vadd.f32 %v115456, %v115345 (stack52)
        %v115464 = vmul.f32 %v115460, %v115311 (stack53)
        %v115468 = vsel /*vm=*/%vm115316, /*on_true_vy=*/%v115321, /*on_false_vx=*/%v115464 (stack43)
        %v115472 = vmul.f32 1.4140625, %v115468 (stack53)
        %v115475 = vpack.c.bf16 0.0, %v115472 (stack74)
        %120361 = vst [vmem:[%s280 + $0x378] sm:$0xf] /*vst_source=*/%v115475 (stack75)
        %v115479 = vadd.s32 %v112249, %v3816 (stack39)
        %v115489 = vadd.s32 %v115479, %v415 (stack39)
        %vm115493 = vcmp.lt.u32.totalorder %v115489, %v115479 (stack42)
        %vm115498 = vcmp.lt.u32.totalorder %v115479, %v3816 (stack42)
        %v115503 = vadd.s32 %v112232, %v3803 (stack39)
        %v115507 = vadd.s32 1, %v115503 (stack39)
        %v115511 = vsel /*vm=*/%vm115498, /*on_true_vy=*/%v115507, /*on_false_vx=*/%v115503 (stack43)
        %v115515 = vadd.s32 1, %v115511 (stack39)
        %v115519 = vsel /*vm=*/%vm115493, /*on_true_vy=*/%v115515, /*on_false_vx=*/%v115511 (stack43)
        %v115524 = vadd.s32 %v115519, %v10 (stack39)
        %v115528 = vadd.s32 %v115489, %v9 (stack39)
        %v115532 = vadd.s32 %v115528, %v115524 (stack39)
        %v115534 = vshll.u32 %v115528, 13 (stack44)
        %v115535 = vshrl.u32 %v115528, 19 (stack45)
        %v115536 = vor.u32 %v115535, %v115534 (stack46)
        %v115537 = vxor.u32 %v115536, %v115532 (stack47)
        %v115540 = vadd.s32 %v115537, %v115532 (stack39)
        %v115542 = vshll.u32 %v115537, 15 (stack44)
        %v115543 = vshrl.u32 %v115537, 17 (stack45)
        %v115544 = vor.u32 %v115543, %v115542 (stack46)
        %v115545 = vxor.u32 %v115544, %v115540 (stack47)
        %v115548 = vadd.s32 %v115545, %v115540 (stack39)
        %v115550 = vshll.u32 %v115545, 26 (stack44)
        %v115551 = vshrl.u32 %v115545, 6 (stack45)
        %v115552 = vor.u32 %v115551, %v115550 (stack46)
        %v115553 = vxor.u32 %v115552, %v115548 (stack47)
        %v115556 = vadd.s32 %v115553, %v115548 (stack39)
        %v115560 = vadd.s32 %v115556, %v9 (stack39)
        %v115562 = vshll.u32 %v115553, 6 (stack44)
        %v115563 = vshrl.u32 %v115553, 26 (stack45)
        %v115564 = vor.u32 %v115563, %v115562 (stack46)
        %v115565 = vxor.u32 %v115564, %v115556 (stack47)
        %v115568 = vadd.s32 %v115565, %v8 (stack39)
        %v115572 = vadd.s32 1, %v115568 (stack39)
        %v115576 = vadd.s32 %v115572, %v115560 (stack39)
        %v115578 = vshll.u32 %v115572, 17 (stack44)
        %v115579 = vshrl.u32 %v115572, 15 (stack45)
        %v115580 = vor.u32 %v115579, %v115578 (stack46)
        %v115581 = vxor.u32 %v115580, %v115576 (stack47)
        %v115584 = vadd.s32 %v115581, %v115576 (stack39)
        %v115586 = vshll.u32 %v115581, 29 (stack44)
        %v115587 = vshrl.u32 %v115581, 3 (stack45)
        %v115588 = vor.u32 %v115587, %v115586 (stack46)
        %v115589 = vxor.u32 %v115588, %v115584 (stack47)
        %v115592 = vadd.s32 %v115589, %v115584 (stack39)
        %v115594 = vshll.u32 %v115589, 16 (stack44)
        %v115595 = vshrl.u32 %v115589, 16 (stack45)
        %v115596 = vor.u32 %v115595, %v115594 (stack46)
        %v115597 = vxor.u32 %v115596, %v115592 (stack47)
        %v115600 = vadd.s32 %v115597, %v115592 (stack39)
        %v115604 = vadd.s32 %v115600, %v8 (stack39)
        %v115606 = vshll.u32 %v115597, 24 (stack44)
        %v115607 = vshrl.u32 %v115597, 8 (stack45)
        %v115608 = vor.u32 %v115607, %v115606 (stack46)
        %v115609 = vxor.u32 %v115608, %v115600 (stack47)
        %v115612 = vadd.s32 %v115609, %v10 (stack39)
        %v115616 = vadd.s32 2, %v115612 (stack39)
        %v115620 = vadd.s32 %v115616, %v115604 (stack39)
        %v115622 = vshll.u32 %v115616, 13 (stack44)
        %v115623 = vshrl.u32 %v115616, 19 (stack45)
        %v115624 = vor.u32 %v115623, %v115622 (stack46)
        %v115625 = vxor.u32 %v115624, %v115620 (stack47)
        %v115628 = vadd.s32 %v115625, %v115620 (stack39)
        %v115630 = vshll.u32 %v115625, 15 (stack44)
        %v115631 = vshrl.u32 %v115625, 17 (stack45)
        %v115632 = vor.u32 %v115631, %v115630 (stack46)
        %v115633 = vxor.u32 %v115632, %v115628 (stack47)
        %v115636 = vadd.s32 %v115633, %v115628 (stack39)
        %v115638 = vshll.u32 %v115633, 26 (stack44)
        %v115639 = vshrl.u32 %v115633, 6 (stack45)
        %v115640 = vor.u32 %v115639, %v115638 (stack46)
        %v115641 = vxor.u32 %v115640, %v115636 (stack47)
        %v115644 = vadd.s32 %v115641, %v115636 (stack39)
        %v115648 = vadd.s32 %v115644, %v10 (stack39)
        %v115650 = vshll.u32 %v115641, 6 (stack44)
        %v115651 = vshrl.u32 %v115641, 26 (stack45)
        %v115652 = vor.u32 %v115651, %v115650 (stack46)
        %v115653 = vxor.u32 %v115652, %v115644 (stack47)
        %v115656 = vadd.s32 %v115653, %v9 (stack39)
        %v115660 = vadd.s32 3, %v115656 (stack39)
        %v115664 = vadd.s32 %v115660, %v115648 (stack39)
        %v115666 = vshll.u32 %v115660, 17 (stack44)
        %v115667 = vshrl.u32 %v115660, 15 (stack45)
        %v115668 = vor.u32 %v115667, %v115666 (stack46)
        %v115669 = vxor.u32 %v115668, %v115664 (stack47)
        %v115672 = vadd.s32 %v115669, %v115664 (stack39)
        %v115674 = vshll.u32 %v115669, 29 (stack44)
        %v115675 = vshrl.u32 %v115669, 3 (stack45)
        %v115676 = vor.u32 %v115675, %v115674 (stack46)
        %v115677 = vxor.u32 %v115676, %v115672 (stack47)
        %v115680 = vadd.s32 %v115677, %v115672 (stack39)
        %v115682 = vshll.u32 %v115677, 16 (stack44)
        %v115683 = vshrl.u32 %v115677, 16 (stack45)
        %v115684 = vor.u32 %v115683, %v115682 (stack46)
        %v115685 = vxor.u32 %v115684, %v115680 (stack47)
        %v115688 = vadd.s32 %v115685, %v115680 (stack39)
        %v115692 = vadd.s32 %v115688, %v9 (stack39)
        %v115694 = vshll.u32 %v115685, 24 (stack44)
        %v115695 = vshrl.u32 %v115685, 8 (stack45)
        %v115696 = vor.u32 %v115695, %v115694 (stack46)
        %v115697 = vxor.u32 %v115696, %v115688 (stack47)
        %v115700 = vadd.s32 %v115697, %v8 (stack39)
        %v115704 = vadd.s32 4, %v115700 (stack39)
        %v115708 = vadd.s32 %v115704, %v115692 (stack39)
        %v115710 = vshll.u32 %v115704, 13 (stack44)
        %v115711 = vshrl.u32 %v115704, 19 (stack45)
        %v115712 = vor.u32 %v115711, %v115710 (stack46)
        %v115713 = vxor.u32 %v115712, %v115708 (stack47)
        %v115716 = vadd.s32 %v115713, %v115708 (stack39)
        %v115718 = vshll.u32 %v115713, 15 (stack44)
        %v115719 = vshrl.u32 %v115713, 17 (stack45)
        %v115720 = vor.u32 %v115719, %v115718 (stack46)
        %v115721 = vxor.u32 %v115720, %v115716 (stack47)
        %v115724 = vadd.s32 %v115721, %v115716 (stack39)
        %v115726 = vshll.u32 %v115721, 26 (stack44)
        %v115727 = vshrl.u32 %v115721, 6 (stack45)
        %v115728 = vor.u32 %v115727, %v115726 (stack46)
        %v115729 = vxor.u32 %v115728, %v115724 (stack47)
        %v115732 = vadd.s32 %v115729, %v115724 (stack39)
        %v115736 = vadd.s32 %v115732, %v8 (stack39)
        %v115738 = vshll.u32 %v115729, 6 (stack44)
        %v115739 = vshrl.u32 %v115729, 26 (stack45)
        %v115740 = vor.u32 %v115739, %v115738 (stack46)
        %v115741 = vxor.u32 %v115740, %v115732 (stack47)
        %v115744 = vadd.s32 %v115741, %v10 (stack39)
        %v115748 = vadd.s32 5, %v115744 (stack39)
        %v115750 = vxor.u32 %v115748, %v115736 (stack47)
        %v115751 = vand.u32.u8 255, %v115750 (stack48)
        %v115752 = vand.u32 65535, %v115751 (stack49)
        %v115753 = vshrl.u32 %v115752, 1 (stack50)
        %v115754 = vor.u32 16256, %v115753 (stack46)
        %v115755 = vand.u32.u16 65535, %v115754 (stack51)
        %v120362 = vadd.low.f32.bf16 -1.0, %v115755 (stack52)
        %v115764 = vmul.f32 2.0, %v120362 (stack53)
        %v115768 = vadd.f32 -0.99609375, %v115764 (stack52)
        %v115772 = vmax.f32 %v115768, -0.99609375 (stack54)
        %v115774 = vand.u32 2147483647, %v115772 (stack55)
        %vm115777 = vcmp.eq.f32.partialorder %v115774, 1.0 (stack56)
        %v115782 = vmul.f32 inf, %v115772 (stack53)
        %v115784 = vxor.u32 2147483648, %v115772 (stack57)
        %v115787 = vmul.f32 %v115784, %v115772 (stack53)
        %v115789 = vadd.f32 1.0, %v115787 (stack58)
        %v115790 = vlog2.pop %v115789 (stack59)
        %v115791 = vmul.f32 0.6931472, %v115790 (stack60)
        %v115792 = vmul.f32 -0.5, %v115787 (stack61)
        %v115793 = vadd.f32 1.0, %v115792 (stack62)
        %v115794 = vmul.f32 %v115793, %v115787 (stack63)
        %v115795 = vand.u32 2147483647, %v115787 (stack64)
        %vm115796 = vcmp.lt.f32.partialorder %v115795, 0.0004427343 (stack65)
        %v115797 = vsel /*vm=*/%vm115796, /*on_true_vy=*/%v115794, /*on_false_vx=*/%v115791 (stack66)
        %v115798 = vxor.u32 2147483648, %v115797 (stack57)
        %vm115801 = vcmp.lt.f32.partialorder %v115798, 5.0 (stack56)
        %v115806 = vsel /*vm=*/%vm115801, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v115810 = vsel /*vm=*/%vm115801, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v115814 = vsel /*vm=*/%vm115801, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v115818 = vsel /*vm=*/%vm115801, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v115822 = vsel /*vm=*/%vm115801, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v115826 = vsel /*vm=*/%vm115801, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v115830 = vsel /*vm=*/%vm115801, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v115834 = vsel /*vm=*/%vm115801, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v115838 = vsel /*vm=*/%vm115801, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v115842 = vadd.f32 -2.5, %v115798 (stack52)
        %v115844 = vrsqrt.pop %v115798 (stack67)
        %v115845 = vmul.f32 %v115844, %v115798 (stack68)
        %vm115846 = vcmp.eq.f32.partialorder %v115798, inf (stack69)
        %v115847 = vsel /*vm=*/%vm115846, /*on_true_vy=*/%v115798, /*on_false_vx=*/%v115845 (stack70)
        %vm115848 = vcmp.eq.f32.partialorder %v115798, 0.0 (stack71)
        %v115849 = vand.u32 2147483648, %v115798 (stack72)
        %v115850 = vsel /*vm=*/%vm115848, /*on_true_vy=*/%v115849, /*on_false_vx=*/%v115847 (stack73)
        %v115853 = vadd.f32 -3.0, %v115850 (stack52)
        %v115857 = vsel /*vm=*/%vm115801, /*on_true_vy=*/%v115842, /*on_false_vx=*/%v115853 (stack43)
        %v115861 = vmul.f32 %v115857, %v115838 (stack53)
        %v115865 = vadd.f32 %v115861, %v115834 (stack52)
        %v115869 = vmul.f32 %v115865, %v115857 (stack53)
        %v115873 = vadd.f32 %v115869, %v115830 (stack52)
        %v115877 = vmul.f32 %v115873, %v115857 (stack53)
        %v115881 = vadd.f32 %v115877, %v115826 (stack52)
        %v115885 = vmul.f32 %v115881, %v115857 (stack53)
        %v115889 = vadd.f32 %v115885, %v115822 (stack52)
        %v115893 = vmul.f32 %v115889, %v115857 (stack53)
        %v115897 = vadd.f32 %v115893, %v115818 (stack52)
        %v115901 = vmul.f32 %v115897, %v115857 (stack53)
        %v115905 = vadd.f32 %v115901, %v115814 (stack52)
        %v115909 = vmul.f32 %v115905, %v115857 (stack53)
        %v115913 = vadd.f32 %v115909, %v115810 (stack52)
        %v115917 = vmul.f32 %v115913, %v115857 (stack53)
        %v115921 = vadd.f32 %v115917, %v115806 (stack52)
        %v115925 = vmul.f32 %v115921, %v115772 (stack53)
        %v115929 = vsel /*vm=*/%vm115777, /*on_true_vy=*/%v115782, /*on_false_vx=*/%v115925 (stack43)
        %v115933 = vmul.f32 1.4140625, %v115929 (stack53)
        %v115936 = vpack.c.bf16 0.0, %v115933 (stack74)
        %120363 = vst [vmem:[%s280 + $0x3f8] sm:$0xf] /*vst_source=*/%v115936 (stack75)
        %s115938 = sadd.s32 248, %s120390 (stack76)
        %s115939 = sshrl.u32 %s115938, 10 (stack23)
        %p120364 = scmp.gt.s32.totalorder %s115939, 1 (stack24)
        %s115941 = scalar_select /*predicate=*/%p120364, /*on_true=*/1, /*on_false=*/%s115939 (stack25)
        %s115942 = sand.u32 1023, %s115938 /* smod.u32 w/div 1024 */ (stack26)
        %s115943 = sshrl.u32 %s115942, 7 (stack27)
        %s115944 = sand.u32 127, %s115942 /* smod.u32 w/div 128 */ (stack28)
        %s120365 = sshll.u32 %s115941, 3 (stack29)
        %s115946 = scalar_lea.vmem %s3, %s120365 (stack30)
        %s115948 = scalar_lea.vmem %s115946, %s115943 (stack31)
        %v115949 = vld [vmem:[%s115948] ss:$0 sm:$0xff] (stack32)
        %s115950 = sand.u32 255, %s115944 (stack33)
        %s115952 = sor.u32 256, %s115950 (stack34)
        %115953 = vbcast.lane.b32.xlu0 %v115949, %s115952 (stack35)
        %v115954 = vpop.permute.xlu0 %115953 (stack36)
        %s115963 = scalar_lea.vmem %s5, %s120365 (stack30)
        %s115965 = scalar_lea.vmem %s115963, %s115943 (stack31)
        %v115966 = vld [vmem:[%s115965] ss:$0 sm:$0xff] (stack32)
        %115970 = vbcast.lane.b32.xlu0 %v115966, %s115952 (stack35)
        %v115971 = vpop.permute.xlu0 %115970 (stack36)
        %v115974 = vadd.s32 %v115971, %v408 (stack39)
        %v115984 = vadd.s32 %v115974, %v415 (stack39)
        %vm115988 = vcmp.lt.u32.totalorder %v115984, %v115974 (stack42)
        %vm115993 = vcmp.lt.u32.totalorder %v115974, %v408 (stack42)
        %v115998 = vadd.s32 %v115954, %v380 (stack39)
        %v116002 = vadd.s32 1, %v115998 (stack39)
        %v116006 = vsel /*vm=*/%vm115993, /*on_true_vy=*/%v116002, /*on_false_vx=*/%v115998 (stack43)
        %v116010 = vadd.s32 1, %v116006 (stack39)
        %v116014 = vsel /*vm=*/%vm115988, /*on_true_vy=*/%v116010, /*on_false_vx=*/%v116006 (stack43)
        %v116019 = vadd.s32 %v116014, %v10 (stack39)
        %v116023 = vadd.s32 %v115984, %v9 (stack39)
        %v116027 = vadd.s32 %v116023, %v116019 (stack39)
        %v116029 = vshll.u32 %v116023, 13 (stack44)
        %v116030 = vshrl.u32 %v116023, 19 (stack45)
        %v116031 = vor.u32 %v116030, %v116029 (stack46)
        %v116032 = vxor.u32 %v116031, %v116027 (stack47)
        %v116035 = vadd.s32 %v116032, %v116027 (stack39)
        %v116037 = vshll.u32 %v116032, 15 (stack44)
        %v116038 = vshrl.u32 %v116032, 17 (stack45)
        %v116039 = vor.u32 %v116038, %v116037 (stack46)
        %v116040 = vxor.u32 %v116039, %v116035 (stack47)
        %v116043 = vadd.s32 %v116040, %v116035 (stack39)
        %v116045 = vshll.u32 %v116040, 26 (stack44)
        %v116046 = vshrl.u32 %v116040, 6 (stack45)
        %v116047 = vor.u32 %v116046, %v116045 (stack46)
        %v116048 = vxor.u32 %v116047, %v116043 (stack47)
        %v116051 = vadd.s32 %v116048, %v116043 (stack39)
        %v116055 = vadd.s32 %v116051, %v9 (stack39)
        %v116057 = vshll.u32 %v116048, 6 (stack44)
        %v116058 = vshrl.u32 %v116048, 26 (stack45)
        %v116059 = vor.u32 %v116058, %v116057 (stack46)
        %v116060 = vxor.u32 %v116059, %v116051 (stack47)
        %v116063 = vadd.s32 %v116060, %v8 (stack39)
        %v116067 = vadd.s32 1, %v116063 (stack39)
        %v116071 = vadd.s32 %v116067, %v116055 (stack39)
        %v116073 = vshll.u32 %v116067, 17 (stack44)
        %v116074 = vshrl.u32 %v116067, 15 (stack45)
        %v116075 = vor.u32 %v116074, %v116073 (stack46)
        %v116076 = vxor.u32 %v116075, %v116071 (stack47)
        %v116079 = vadd.s32 %v116076, %v116071 (stack39)
        %v116081 = vshll.u32 %v116076, 29 (stack44)
        %v116082 = vshrl.u32 %v116076, 3 (stack45)
        %v116083 = vor.u32 %v116082, %v116081 (stack46)
        %v116084 = vxor.u32 %v116083, %v116079 (stack47)
        %v116087 = vadd.s32 %v116084, %v116079 (stack39)
        %v116089 = vshll.u32 %v116084, 16 (stack44)
        %v116090 = vshrl.u32 %v116084, 16 (stack45)
        %v116091 = vor.u32 %v116090, %v116089 (stack46)
        %v116092 = vxor.u32 %v116091, %v116087 (stack47)
        %v116095 = vadd.s32 %v116092, %v116087 (stack39)
        %v116099 = vadd.s32 %v116095, %v8 (stack39)
        %v116101 = vshll.u32 %v116092, 24 (stack44)
        %v116102 = vshrl.u32 %v116092, 8 (stack45)
        %v116103 = vor.u32 %v116102, %v116101 (stack46)
        %v116104 = vxor.u32 %v116103, %v116095 (stack47)
        %v116107 = vadd.s32 %v116104, %v10 (stack39)
        %v116111 = vadd.s32 2, %v116107 (stack39)
        %v116115 = vadd.s32 %v116111, %v116099 (stack39)
        %v116117 = vshll.u32 %v116111, 13 (stack44)
        %v116118 = vshrl.u32 %v116111, 19 (stack45)
        %v116119 = vor.u32 %v116118, %v116117 (stack46)
        %v116120 = vxor.u32 %v116119, %v116115 (stack47)
        %v116123 = vadd.s32 %v116120, %v116115 (stack39)
        %v116125 = vshll.u32 %v116120, 15 (stack44)
        %v116126 = vshrl.u32 %v116120, 17 (stack45)
        %v116127 = vor.u32 %v116126, %v116125 (stack46)
        %v116128 = vxor.u32 %v116127, %v116123 (stack47)
        %v116131 = vadd.s32 %v116128, %v116123 (stack39)
        %v116133 = vshll.u32 %v116128, 26 (stack44)
        %v116134 = vshrl.u32 %v116128, 6 (stack45)
        %v116135 = vor.u32 %v116134, %v116133 (stack46)
        %v116136 = vxor.u32 %v116135, %v116131 (stack47)
        %v116139 = vadd.s32 %v116136, %v116131 (stack39)
        %v116143 = vadd.s32 %v116139, %v10 (stack39)
        %v116145 = vshll.u32 %v116136, 6 (stack44)
        %v116146 = vshrl.u32 %v116136, 26 (stack45)
        %v116147 = vor.u32 %v116146, %v116145 (stack46)
        %v116148 = vxor.u32 %v116147, %v116139 (stack47)
        %v116151 = vadd.s32 %v116148, %v9 (stack39)
        %v116155 = vadd.s32 3, %v116151 (stack39)
        %v116159 = vadd.s32 %v116155, %v116143 (stack39)
        %v116161 = vshll.u32 %v116155, 17 (stack44)
        %v116162 = vshrl.u32 %v116155, 15 (stack45)
        %v116163 = vor.u32 %v116162, %v116161 (stack46)
        %v116164 = vxor.u32 %v116163, %v116159 (stack47)
        %v116167 = vadd.s32 %v116164, %v116159 (stack39)
        %v116169 = vshll.u32 %v116164, 29 (stack44)
        %v116170 = vshrl.u32 %v116164, 3 (stack45)
        %v116171 = vor.u32 %v116170, %v116169 (stack46)
        %v116172 = vxor.u32 %v116171, %v116167 (stack47)
        %v116175 = vadd.s32 %v116172, %v116167 (stack39)
        %v116177 = vshll.u32 %v116172, 16 (stack44)
        %v116178 = vshrl.u32 %v116172, 16 (stack45)
        %v116179 = vor.u32 %v116178, %v116177 (stack46)
        %v116180 = vxor.u32 %v116179, %v116175 (stack47)
        %v116183 = vadd.s32 %v116180, %v116175 (stack39)
        %v116187 = vadd.s32 %v116183, %v9 (stack39)
        %v116189 = vshll.u32 %v116180, 24 (stack44)
        %v116190 = vshrl.u32 %v116180, 8 (stack45)
        %v116191 = vor.u32 %v116190, %v116189 (stack46)
        %v116192 = vxor.u32 %v116191, %v116183 (stack47)
        %v116195 = vadd.s32 %v116192, %v8 (stack39)
        %v116199 = vadd.s32 4, %v116195 (stack39)
        %v116203 = vadd.s32 %v116199, %v116187 (stack39)
        %v116205 = vshll.u32 %v116199, 13 (stack44)
        %v116206 = vshrl.u32 %v116199, 19 (stack45)
        %v116207 = vor.u32 %v116206, %v116205 (stack46)
        %v116208 = vxor.u32 %v116207, %v116203 (stack47)
        %v116211 = vadd.s32 %v116208, %v116203 (stack39)
        %v116213 = vshll.u32 %v116208, 15 (stack44)
        %v116214 = vshrl.u32 %v116208, 17 (stack45)
        %v116215 = vor.u32 %v116214, %v116213 (stack46)
        %v116216 = vxor.u32 %v116215, %v116211 (stack47)
        %v116219 = vadd.s32 %v116216, %v116211 (stack39)
        %v116221 = vshll.u32 %v116216, 26 (stack44)
        %v116222 = vshrl.u32 %v116216, 6 (stack45)
        %v116223 = vor.u32 %v116222, %v116221 (stack46)
        %v116224 = vxor.u32 %v116223, %v116219 (stack47)
        %v116227 = vadd.s32 %v116224, %v116219 (stack39)
        %v116231 = vadd.s32 %v116227, %v8 (stack39)
        %v116233 = vshll.u32 %v116224, 6 (stack44)
        %v116234 = vshrl.u32 %v116224, 26 (stack45)
        %v116235 = vor.u32 %v116234, %v116233 (stack46)
        %v116236 = vxor.u32 %v116235, %v116227 (stack47)
        %v116239 = vadd.s32 %v116236, %v10 (stack39)
        %v116243 = vadd.s32 5, %v116239 (stack39)
        %v116245 = vxor.u32 %v116243, %v116231 (stack47)
        %v116246 = vand.u32.u8 255, %v116245 (stack48)
        %v116247 = vand.u32 65535, %v116246 (stack49)
        %v116248 = vshrl.u32 %v116247, 1 (stack50)
        %v116249 = vor.u32 16256, %v116248 (stack46)
        %v116250 = vand.u32.u16 65535, %v116249 (stack51)
        %v120368 = vadd.low.f32.bf16 -1.0, %v116250 (stack52)
        %v116259 = vmul.f32 2.0, %v120368 (stack53)
        %v116263 = vadd.f32 -0.99609375, %v116259 (stack52)
        %v116267 = vmax.f32 %v116263, -0.99609375 (stack54)
        %v116269 = vand.u32 2147483647, %v116267 (stack55)
        %vm116272 = vcmp.eq.f32.partialorder %v116269, 1.0 (stack56)
        %v116277 = vmul.f32 inf, %v116267 (stack53)
        %v116279 = vxor.u32 2147483648, %v116267 (stack57)
        %v116282 = vmul.f32 %v116279, %v116267 (stack53)
        %v116284 = vadd.f32 1.0, %v116282 (stack58)
        %v116285 = vlog2.pop %v116284 (stack59)
        %v116286 = vmul.f32 0.6931472, %v116285 (stack60)
        %v116287 = vmul.f32 -0.5, %v116282 (stack61)
        %v116288 = vadd.f32 1.0, %v116287 (stack62)
        %v116289 = vmul.f32 %v116288, %v116282 (stack63)
        %v116290 = vand.u32 2147483647, %v116282 (stack64)
        %vm116291 = vcmp.lt.f32.partialorder %v116290, 0.0004427343 (stack65)
        %v116292 = vsel /*vm=*/%vm116291, /*on_true_vy=*/%v116289, /*on_false_vx=*/%v116286 (stack66)
        %v116293 = vxor.u32 2147483648, %v116292 (stack57)
        %vm116296 = vcmp.lt.f32.partialorder %v116293, 5.0 (stack56)
        %v116301 = vsel /*vm=*/%vm116296, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v116305 = vsel /*vm=*/%vm116296, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v116309 = vsel /*vm=*/%vm116296, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v116313 = vsel /*vm=*/%vm116296, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v116317 = vsel /*vm=*/%vm116296, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v116321 = vsel /*vm=*/%vm116296, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v116325 = vsel /*vm=*/%vm116296, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v116329 = vsel /*vm=*/%vm116296, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v116333 = vsel /*vm=*/%vm116296, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v116337 = vadd.f32 -2.5, %v116293 (stack52)
        %v116339 = vrsqrt.pop %v116293 (stack67)
        %v116340 = vmul.f32 %v116339, %v116293 (stack68)
        %vm116341 = vcmp.eq.f32.partialorder %v116293, inf (stack69)
        %v116342 = vsel /*vm=*/%vm116341, /*on_true_vy=*/%v116293, /*on_false_vx=*/%v116340 (stack70)
        %vm116343 = vcmp.eq.f32.partialorder %v116293, 0.0 (stack71)
        %v116344 = vand.u32 2147483648, %v116293 (stack72)
        %v116345 = vsel /*vm=*/%vm116343, /*on_true_vy=*/%v116344, /*on_false_vx=*/%v116342 (stack73)
        %v116348 = vadd.f32 -3.0, %v116345 (stack52)
        %v116352 = vsel /*vm=*/%vm116296, /*on_true_vy=*/%v116337, /*on_false_vx=*/%v116348 (stack43)
        %v116356 = vmul.f32 %v116352, %v116333 (stack53)
        %v116360 = vadd.f32 %v116356, %v116329 (stack52)
        %v116364 = vmul.f32 %v116360, %v116352 (stack53)
        %v116368 = vadd.f32 %v116364, %v116325 (stack52)
        %v116372 = vmul.f32 %v116368, %v116352 (stack53)
        %v116376 = vadd.f32 %v116372, %v116321 (stack52)
        %v116380 = vmul.f32 %v116376, %v116352 (stack53)
        %v116384 = vadd.f32 %v116380, %v116317 (stack52)
        %v116388 = vmul.f32 %v116384, %v116352 (stack53)
        %v116392 = vadd.f32 %v116388, %v116313 (stack52)
        %v116396 = vmul.f32 %v116392, %v116352 (stack53)
        %v116400 = vadd.f32 %v116396, %v116309 (stack52)
        %v116404 = vmul.f32 %v116400, %v116352 (stack53)
        %v116408 = vadd.f32 %v116404, %v116305 (stack52)
        %v116412 = vmul.f32 %v116408, %v116352 (stack53)
        %v116416 = vadd.f32 %v116412, %v116301 (stack52)
        %v116420 = vmul.f32 %v116416, %v116267 (stack53)
        %v116424 = vsel /*vm=*/%vm116272, /*on_true_vy=*/%v116277, /*on_false_vx=*/%v116420 (stack43)
        %v116428 = vmul.f32 1.4140625, %v116424 (stack53)
        %v116431 = vpack.c.bf16 0.0, %v116428 (stack74)
        %120369 = vst [vmem:[%s280 + $0x7c] sm:$0xf] /*vst_source=*/%v116431 (stack75)
        %v116435 = vadd.s32 %v115971, %v894 (stack39)
        %v116445 = vadd.s32 %v116435, %v415 (stack39)
        %vm116449 = vcmp.lt.u32.totalorder %v116445, %v116435 (stack42)
        %vm116454 = vcmp.lt.u32.totalorder %v116435, %v894 (stack42)
        %v116459 = vadd.s32 %v115954, %v881 (stack39)
        %v116463 = vadd.s32 1, %v116459 (stack39)
        %v116467 = vsel /*vm=*/%vm116454, /*on_true_vy=*/%v116463, /*on_false_vx=*/%v116459 (stack43)
        %v116471 = vadd.s32 1, %v116467 (stack39)
        %v116475 = vsel /*vm=*/%vm116449, /*on_true_vy=*/%v116471, /*on_false_vx=*/%v116467 (stack43)
        %v116480 = vadd.s32 %v116475, %v10 (stack39)
        %v116484 = vadd.s32 %v116445, %v9 (stack39)
        %v116488 = vadd.s32 %v116484, %v116480 (stack39)
        %v116490 = vshll.u32 %v116484, 13 (stack44)
        %v116491 = vshrl.u32 %v116484, 19 (stack45)
        %v116492 = vor.u32 %v116491, %v116490 (stack46)
        %v116493 = vxor.u32 %v116492, %v116488 (stack47)
        %v116496 = vadd.s32 %v116493, %v116488 (stack39)
        %v116498 = vshll.u32 %v116493, 15 (stack44)
        %v116499 = vshrl.u32 %v116493, 17 (stack45)
        %v116500 = vor.u32 %v116499, %v116498 (stack46)
        %v116501 = vxor.u32 %v116500, %v116496 (stack47)
        %v116504 = vadd.s32 %v116501, %v116496 (stack39)
        %v116506 = vshll.u32 %v116501, 26 (stack44)
        %v116507 = vshrl.u32 %v116501, 6 (stack45)
        %v116508 = vor.u32 %v116507, %v116506 (stack46)
        %v116509 = vxor.u32 %v116508, %v116504 (stack47)
        %v116512 = vadd.s32 %v116509, %v116504 (stack39)
        %v116516 = vadd.s32 %v116512, %v9 (stack39)
        %v116518 = vshll.u32 %v116509, 6 (stack44)
        %v116519 = vshrl.u32 %v116509, 26 (stack45)
        %v116520 = vor.u32 %v116519, %v116518 (stack46)
        %v116521 = vxor.u32 %v116520, %v116512 (stack47)
        %v116524 = vadd.s32 %v116521, %v8 (stack39)
        %v116528 = vadd.s32 1, %v116524 (stack39)
        %v116532 = vadd.s32 %v116528, %v116516 (stack39)
        %v116534 = vshll.u32 %v116528, 17 (stack44)
        %v116535 = vshrl.u32 %v116528, 15 (stack45)
        %v116536 = vor.u32 %v116535, %v116534 (stack46)
        %v116537 = vxor.u32 %v116536, %v116532 (stack47)
        %v116540 = vadd.s32 %v116537, %v116532 (stack39)
        %v116542 = vshll.u32 %v116537, 29 (stack44)
        %v116543 = vshrl.u32 %v116537, 3 (stack45)
        %v116544 = vor.u32 %v116543, %v116542 (stack46)
        %v116545 = vxor.u32 %v116544, %v116540 (stack47)
        %v116548 = vadd.s32 %v116545, %v116540 (stack39)
        %v116550 = vshll.u32 %v116545, 16 (stack44)
        %v116551 = vshrl.u32 %v116545, 16 (stack45)
        %v116552 = vor.u32 %v116551, %v116550 (stack46)
        %v116553 = vxor.u32 %v116552, %v116548 (stack47)
        %v116556 = vadd.s32 %v116553, %v116548 (stack39)
        %v116560 = vadd.s32 %v116556, %v8 (stack39)
        %v116562 = vshll.u32 %v116553, 24 (stack44)
        %v116563 = vshrl.u32 %v116553, 8 (stack45)
        %v116564 = vor.u32 %v116563, %v116562 (stack46)
        %v116565 = vxor.u32 %v116564, %v116556 (stack47)
        %v116568 = vadd.s32 %v116565, %v10 (stack39)
        %v116572 = vadd.s32 2, %v116568 (stack39)
        %v116576 = vadd.s32 %v116572, %v116560 (stack39)
        %v116578 = vshll.u32 %v116572, 13 (stack44)
        %v116579 = vshrl.u32 %v116572, 19 (stack45)
        %v116580 = vor.u32 %v116579, %v116578 (stack46)
        %v116581 = vxor.u32 %v116580, %v116576 (stack47)
        %v116584 = vadd.s32 %v116581, %v116576 (stack39)
        %v116586 = vshll.u32 %v116581, 15 (stack44)
        %v116587 = vshrl.u32 %v116581, 17 (stack45)
        %v116588 = vor.u32 %v116587, %v116586 (stack46)
        %v116589 = vxor.u32 %v116588, %v116584 (stack47)
        %v116592 = vadd.s32 %v116589, %v116584 (stack39)
        %v116594 = vshll.u32 %v116589, 26 (stack44)
        %v116595 = vshrl.u32 %v116589, 6 (stack45)
        %v116596 = vor.u32 %v116595, %v116594 (stack46)
        %v116597 = vxor.u32 %v116596, %v116592 (stack47)
        %v116600 = vadd.s32 %v116597, %v116592 (stack39)
        %v116604 = vadd.s32 %v116600, %v10 (stack39)
        %v116606 = vshll.u32 %v116597, 6 (stack44)
        %v116607 = vshrl.u32 %v116597, 26 (stack45)
        %v116608 = vor.u32 %v116607, %v116606 (stack46)
        %v116609 = vxor.u32 %v116608, %v116600 (stack47)
        %v116612 = vadd.s32 %v116609, %v9 (stack39)
        %v116616 = vadd.s32 3, %v116612 (stack39)
        %v116620 = vadd.s32 %v116616, %v116604 (stack39)
        %v116622 = vshll.u32 %v116616, 17 (stack44)
        %v116623 = vshrl.u32 %v116616, 15 (stack45)
        %v116624 = vor.u32 %v116623, %v116622 (stack46)
        %v116625 = vxor.u32 %v116624, %v116620 (stack47)
        %v116628 = vadd.s32 %v116625, %v116620 (stack39)
        %v116630 = vshll.u32 %v116625, 29 (stack44)
        %v116631 = vshrl.u32 %v116625, 3 (stack45)
        %v116632 = vor.u32 %v116631, %v116630 (stack46)
        %v116633 = vxor.u32 %v116632, %v116628 (stack47)
        %v116636 = vadd.s32 %v116633, %v116628 (stack39)
        %v116638 = vshll.u32 %v116633, 16 (stack44)
        %v116639 = vshrl.u32 %v116633, 16 (stack45)
        %v116640 = vor.u32 %v116639, %v116638 (stack46)
        %v116641 = vxor.u32 %v116640, %v116636 (stack47)
        %v116644 = vadd.s32 %v116641, %v116636 (stack39)
        %v116648 = vadd.s32 %v116644, %v9 (stack39)
        %v116650 = vshll.u32 %v116641, 24 (stack44)
        %v116651 = vshrl.u32 %v116641, 8 (stack45)
        %v116652 = vor.u32 %v116651, %v116650 (stack46)
        %v116653 = vxor.u32 %v116652, %v116644 (stack47)
        %v116656 = vadd.s32 %v116653, %v8 (stack39)
        %v116660 = vadd.s32 4, %v116656 (stack39)
        %v116664 = vadd.s32 %v116660, %v116648 (stack39)
        %v116666 = vshll.u32 %v116660, 13 (stack44)
        %v116667 = vshrl.u32 %v116660, 19 (stack45)
        %v116668 = vor.u32 %v116667, %v116666 (stack46)
        %v116669 = vxor.u32 %v116668, %v116664 (stack47)
        %v116672 = vadd.s32 %v116669, %v116664 (stack39)
        %v116674 = vshll.u32 %v116669, 15 (stack44)
        %v116675 = vshrl.u32 %v116669, 17 (stack45)
        %v116676 = vor.u32 %v116675, %v116674 (stack46)
        %v116677 = vxor.u32 %v116676, %v116672 (stack47)
        %v116680 = vadd.s32 %v116677, %v116672 (stack39)
        %v116682 = vshll.u32 %v116677, 26 (stack44)
        %v116683 = vshrl.u32 %v116677, 6 (stack45)
        %v116684 = vor.u32 %v116683, %v116682 (stack46)
        %v116685 = vxor.u32 %v116684, %v116680 (stack47)
        %v116688 = vadd.s32 %v116685, %v116680 (stack39)
        %v116692 = vadd.s32 %v116688, %v8 (stack39)
        %v116694 = vshll.u32 %v116685, 6 (stack44)
        %v116695 = vshrl.u32 %v116685, 26 (stack45)
        %v116696 = vor.u32 %v116695, %v116694 (stack46)
        %v116697 = vxor.u32 %v116696, %v116688 (stack47)
        %v116700 = vadd.s32 %v116697, %v10 (stack39)
        %v116704 = vadd.s32 5, %v116700 (stack39)
        %v116706 = vxor.u32 %v116704, %v116692 (stack47)
        %v116707 = vand.u32.u8 255, %v116706 (stack48)
        %v116708 = vand.u32 65535, %v116707 (stack49)
        %v116709 = vshrl.u32 %v116708, 1 (stack50)
        %v116710 = vor.u32 16256, %v116709 (stack46)
        %v116711 = vand.u32.u16 65535, %v116710 (stack51)
        %v120370 = vadd.low.f32.bf16 -1.0, %v116711 (stack52)
        %v116720 = vmul.f32 2.0, %v120370 (stack53)
        %v116724 = vadd.f32 -0.99609375, %v116720 (stack52)
        %v116728 = vmax.f32 %v116724, -0.99609375 (stack54)
        %v116730 = vand.u32 2147483647, %v116728 (stack55)
        %vm116733 = vcmp.eq.f32.partialorder %v116730, 1.0 (stack56)
        %v116738 = vmul.f32 inf, %v116728 (stack53)
        %v116740 = vxor.u32 2147483648, %v116728 (stack57)
        %v116743 = vmul.f32 %v116740, %v116728 (stack53)
        %v116745 = vadd.f32 1.0, %v116743 (stack58)
        %v116746 = vlog2.pop %v116745 (stack59)
        %v116747 = vmul.f32 0.6931472, %v116746 (stack60)
        %v116748 = vmul.f32 -0.5, %v116743 (stack61)
        %v116749 = vadd.f32 1.0, %v116748 (stack62)
        %v116750 = vmul.f32 %v116749, %v116743 (stack63)
        %v116751 = vand.u32 2147483647, %v116743 (stack64)
        %vm116752 = vcmp.lt.f32.partialorder %v116751, 0.0004427343 (stack65)
        %v116753 = vsel /*vm=*/%vm116752, /*on_true_vy=*/%v116750, /*on_false_vx=*/%v116747 (stack66)
        %v116754 = vxor.u32 2147483648, %v116753 (stack57)
        %vm116757 = vcmp.lt.f32.partialorder %v116754, 5.0 (stack56)
        %v116762 = vsel /*vm=*/%vm116757, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v116766 = vsel /*vm=*/%vm116757, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v116770 = vsel /*vm=*/%vm116757, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v116774 = vsel /*vm=*/%vm116757, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v116778 = vsel /*vm=*/%vm116757, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v116782 = vsel /*vm=*/%vm116757, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v116786 = vsel /*vm=*/%vm116757, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v116790 = vsel /*vm=*/%vm116757, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v116794 = vsel /*vm=*/%vm116757, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v116798 = vadd.f32 -2.5, %v116754 (stack52)
        %v116800 = vrsqrt.pop %v116754 (stack67)
        %v116801 = vmul.f32 %v116800, %v116754 (stack68)
        %vm116802 = vcmp.eq.f32.partialorder %v116754, inf (stack69)
        %v116803 = vsel /*vm=*/%vm116802, /*on_true_vy=*/%v116754, /*on_false_vx=*/%v116801 (stack70)
        %vm116804 = vcmp.eq.f32.partialorder %v116754, 0.0 (stack71)
        %v116805 = vand.u32 2147483648, %v116754 (stack72)
        %v116806 = vsel /*vm=*/%vm116804, /*on_true_vy=*/%v116805, /*on_false_vx=*/%v116803 (stack73)
        %v116809 = vadd.f32 -3.0, %v116806 (stack52)
        %v116813 = vsel /*vm=*/%vm116757, /*on_true_vy=*/%v116798, /*on_false_vx=*/%v116809 (stack43)
        %v116817 = vmul.f32 %v116813, %v116794 (stack53)
        %v116821 = vadd.f32 %v116817, %v116790 (stack52)
        %v116825 = vmul.f32 %v116821, %v116813 (stack53)
        %v116829 = vadd.f32 %v116825, %v116786 (stack52)
        %v116833 = vmul.f32 %v116829, %v116813 (stack53)
        %v116837 = vadd.f32 %v116833, %v116782 (stack52)
        %v116841 = vmul.f32 %v116837, %v116813 (stack53)
        %v116845 = vadd.f32 %v116841, %v116778 (stack52)
        %v116849 = vmul.f32 %v116845, %v116813 (stack53)
        %v116853 = vadd.f32 %v116849, %v116774 (stack52)
        %v116857 = vmul.f32 %v116853, %v116813 (stack53)
        %v116861 = vadd.f32 %v116857, %v116770 (stack52)
        %v116865 = vmul.f32 %v116861, %v116813 (stack53)
        %v116869 = vadd.f32 %v116865, %v116766 (stack52)
        %v116873 = vmul.f32 %v116869, %v116813 (stack53)
        %v116877 = vadd.f32 %v116873, %v116762 (stack52)
        %v116881 = vmul.f32 %v116877, %v116728 (stack53)
        %v116885 = vsel /*vm=*/%vm116733, /*on_true_vy=*/%v116738, /*on_false_vx=*/%v116881 (stack43)
        %v116889 = vmul.f32 1.4140625, %v116885 (stack53)
        %v116892 = vpack.c.bf16 0.0, %v116889 (stack74)
        %120371 = vst [vmem:[%s280 + $0xfc] sm:$0xf] /*vst_source=*/%v116892 (stack75)
        %v116896 = vadd.s32 %v115971, %v1381 (stack39)
        %v116906 = vadd.s32 %v116896, %v415 (stack39)
        %vm116910 = vcmp.lt.u32.totalorder %v116906, %v116896 (stack42)
        %vm116915 = vcmp.lt.u32.totalorder %v116896, %v1381 (stack42)
        %v116920 = vadd.s32 %v115954, %v1368 (stack39)
        %v116924 = vadd.s32 1, %v116920 (stack39)
        %v116928 = vsel /*vm=*/%vm116915, /*on_true_vy=*/%v116924, /*on_false_vx=*/%v116920 (stack43)
        %v116932 = vadd.s32 1, %v116928 (stack39)
        %v116936 = vsel /*vm=*/%vm116910, /*on_true_vy=*/%v116932, /*on_false_vx=*/%v116928 (stack43)
        %v116941 = vadd.s32 %v116936, %v10 (stack39)
        %v116945 = vadd.s32 %v116906, %v9 (stack39)
        %v116949 = vadd.s32 %v116945, %v116941 (stack39)
        %v116951 = vshll.u32 %v116945, 13 (stack44)
        %v116952 = vshrl.u32 %v116945, 19 (stack45)
        %v116953 = vor.u32 %v116952, %v116951 (stack46)
        %v116954 = vxor.u32 %v116953, %v116949 (stack47)
        %v116957 = vadd.s32 %v116954, %v116949 (stack39)
        %v116959 = vshll.u32 %v116954, 15 (stack44)
        %v116960 = vshrl.u32 %v116954, 17 (stack45)
        %v116961 = vor.u32 %v116960, %v116959 (stack46)
        %v116962 = vxor.u32 %v116961, %v116957 (stack47)
        %v116965 = vadd.s32 %v116962, %v116957 (stack39)
        %v116967 = vshll.u32 %v116962, 26 (stack44)
        %v116968 = vshrl.u32 %v116962, 6 (stack45)
        %v116969 = vor.u32 %v116968, %v116967 (stack46)
        %v116970 = vxor.u32 %v116969, %v116965 (stack47)
        %v116973 = vadd.s32 %v116970, %v116965 (stack39)
        %v116977 = vadd.s32 %v116973, %v9 (stack39)
        %v116979 = vshll.u32 %v116970, 6 (stack44)
        %v116980 = vshrl.u32 %v116970, 26 (stack45)
        %v116981 = vor.u32 %v116980, %v116979 (stack46)
        %v116982 = vxor.u32 %v116981, %v116973 (stack47)
        %v116985 = vadd.s32 %v116982, %v8 (stack39)
        %v116989 = vadd.s32 1, %v116985 (stack39)
        %v116993 = vadd.s32 %v116989, %v116977 (stack39)
        %v116995 = vshll.u32 %v116989, 17 (stack44)
        %v116996 = vshrl.u32 %v116989, 15 (stack45)
        %v116997 = vor.u32 %v116996, %v116995 (stack46)
        %v116998 = vxor.u32 %v116997, %v116993 (stack47)
        %v117001 = vadd.s32 %v116998, %v116993 (stack39)
        %v117003 = vshll.u32 %v116998, 29 (stack44)
        %v117004 = vshrl.u32 %v116998, 3 (stack45)
        %v117005 = vor.u32 %v117004, %v117003 (stack46)
        %v117006 = vxor.u32 %v117005, %v117001 (stack47)
        %v117009 = vadd.s32 %v117006, %v117001 (stack39)
        %v117011 = vshll.u32 %v117006, 16 (stack44)
        %v117012 = vshrl.u32 %v117006, 16 (stack45)
        %v117013 = vor.u32 %v117012, %v117011 (stack46)
        %v117014 = vxor.u32 %v117013, %v117009 (stack47)
        %v117017 = vadd.s32 %v117014, %v117009 (stack39)
        %v117021 = vadd.s32 %v117017, %v8 (stack39)
        %v117023 = vshll.u32 %v117014, 24 (stack44)
        %v117024 = vshrl.u32 %v117014, 8 (stack45)
        %v117025 = vor.u32 %v117024, %v117023 (stack46)
        %v117026 = vxor.u32 %v117025, %v117017 (stack47)
        %v117029 = vadd.s32 %v117026, %v10 (stack39)
        %v117033 = vadd.s32 2, %v117029 (stack39)
        %v117037 = vadd.s32 %v117033, %v117021 (stack39)
        %v117039 = vshll.u32 %v117033, 13 (stack44)
        %v117040 = vshrl.u32 %v117033, 19 (stack45)
        %v117041 = vor.u32 %v117040, %v117039 (stack46)
        %v117042 = vxor.u32 %v117041, %v117037 (stack47)
        %v117045 = vadd.s32 %v117042, %v117037 (stack39)
        %v117047 = vshll.u32 %v117042, 15 (stack44)
        %v117048 = vshrl.u32 %v117042, 17 (stack45)
        %v117049 = vor.u32 %v117048, %v117047 (stack46)
        %v117050 = vxor.u32 %v117049, %v117045 (stack47)
        %v117053 = vadd.s32 %v117050, %v117045 (stack39)
        %v117055 = vshll.u32 %v117050, 26 (stack44)
        %v117056 = vshrl.u32 %v117050, 6 (stack45)
        %v117057 = vor.u32 %v117056, %v117055 (stack46)
        %v117058 = vxor.u32 %v117057, %v117053 (stack47)
        %v117061 = vadd.s32 %v117058, %v117053 (stack39)
        %v117065 = vadd.s32 %v117061, %v10 (stack39)
        %v117067 = vshll.u32 %v117058, 6 (stack44)
        %v117068 = vshrl.u32 %v117058, 26 (stack45)
        %v117069 = vor.u32 %v117068, %v117067 (stack46)
        %v117070 = vxor.u32 %v117069, %v117061 (stack47)
        %v117073 = vadd.s32 %v117070, %v9 (stack39)
        %v117077 = vadd.s32 3, %v117073 (stack39)
        %v117081 = vadd.s32 %v117077, %v117065 (stack39)
        %v117083 = vshll.u32 %v117077, 17 (stack44)
        %v117084 = vshrl.u32 %v117077, 15 (stack45)
        %v117085 = vor.u32 %v117084, %v117083 (stack46)
        %v117086 = vxor.u32 %v117085, %v117081 (stack47)
        %v117089 = vadd.s32 %v117086, %v117081 (stack39)
        %v117091 = vshll.u32 %v117086, 29 (stack44)
        %v117092 = vshrl.u32 %v117086, 3 (stack45)
        %v117093 = vor.u32 %v117092, %v117091 (stack46)
        %v117094 = vxor.u32 %v117093, %v117089 (stack47)
        %v117097 = vadd.s32 %v117094, %v117089 (stack39)
        %v117099 = vshll.u32 %v117094, 16 (stack44)
        %v117100 = vshrl.u32 %v117094, 16 (stack45)
        %v117101 = vor.u32 %v117100, %v117099 (stack46)
        %v117102 = vxor.u32 %v117101, %v117097 (stack47)
        %v117105 = vadd.s32 %v117102, %v117097 (stack39)
        %v117109 = vadd.s32 %v117105, %v9 (stack39)
        %v117111 = vshll.u32 %v117102, 24 (stack44)
        %v117112 = vshrl.u32 %v117102, 8 (stack45)
        %v117113 = vor.u32 %v117112, %v117111 (stack46)
        %v117114 = vxor.u32 %v117113, %v117105 (stack47)
        %v117117 = vadd.s32 %v117114, %v8 (stack39)
        %v117121 = vadd.s32 4, %v117117 (stack39)
        %v117125 = vadd.s32 %v117121, %v117109 (stack39)
        %v117127 = vshll.u32 %v117121, 13 (stack44)
        %v117128 = vshrl.u32 %v117121, 19 (stack45)
        %v117129 = vor.u32 %v117128, %v117127 (stack46)
        %v117130 = vxor.u32 %v117129, %v117125 (stack47)
        %v117133 = vadd.s32 %v117130, %v117125 (stack39)
        %v117135 = vshll.u32 %v117130, 15 (stack44)
        %v117136 = vshrl.u32 %v117130, 17 (stack45)
        %v117137 = vor.u32 %v117136, %v117135 (stack46)
        %v117138 = vxor.u32 %v117137, %v117133 (stack47)
        %v117141 = vadd.s32 %v117138, %v117133 (stack39)
        %v117143 = vshll.u32 %v117138, 26 (stack44)
        %v117144 = vshrl.u32 %v117138, 6 (stack45)
        %v117145 = vor.u32 %v117144, %v117143 (stack46)
        %v117146 = vxor.u32 %v117145, %v117141 (stack47)
        %v117149 = vadd.s32 %v117146, %v117141 (stack39)
        %v117153 = vadd.s32 %v117149, %v8 (stack39)
        %v117155 = vshll.u32 %v117146, 6 (stack44)
        %v117156 = vshrl.u32 %v117146, 26 (stack45)
        %v117157 = vor.u32 %v117156, %v117155 (stack46)
        %v117158 = vxor.u32 %v117157, %v117149 (stack47)
        %v117161 = vadd.s32 %v117158, %v10 (stack39)
        %v117165 = vadd.s32 5, %v117161 (stack39)
        %v117167 = vxor.u32 %v117165, %v117153 (stack47)
        %v117168 = vand.u32.u8 255, %v117167 (stack48)
        %v117169 = vand.u32 65535, %v117168 (stack49)
        %v117170 = vshrl.u32 %v117169, 1 (stack50)
        %v117171 = vor.u32 16256, %v117170 (stack46)
        %v117172 = vand.u32.u16 65535, %v117171 (stack51)
        %v120372 = vadd.low.f32.bf16 -1.0, %v117172 (stack52)
        %v117181 = vmul.f32 2.0, %v120372 (stack53)
        %v117185 = vadd.f32 -0.99609375, %v117181 (stack52)
        %v117189 = vmax.f32 %v117185, -0.99609375 (stack54)
        %v117191 = vand.u32 2147483647, %v117189 (stack55)
        %vm117194 = vcmp.eq.f32.partialorder %v117191, 1.0 (stack56)
        %v117199 = vmul.f32 inf, %v117189 (stack53)
        %v117201 = vxor.u32 2147483648, %v117189 (stack57)
        %v117204 = vmul.f32 %v117201, %v117189 (stack53)
        %v117206 = vadd.f32 1.0, %v117204 (stack58)
        %v117207 = vlog2.pop %v117206 (stack59)
        %v117208 = vmul.f32 0.6931472, %v117207 (stack60)
        %v117209 = vmul.f32 -0.5, %v117204 (stack61)
        %v117210 = vadd.f32 1.0, %v117209 (stack62)
        %v117211 = vmul.f32 %v117210, %v117204 (stack63)
        %v117212 = vand.u32 2147483647, %v117204 (stack64)
        %vm117213 = vcmp.lt.f32.partialorder %v117212, 0.0004427343 (stack65)
        %v117214 = vsel /*vm=*/%vm117213, /*on_true_vy=*/%v117211, /*on_false_vx=*/%v117208 (stack66)
        %v117215 = vxor.u32 2147483648, %v117214 (stack57)
        %vm117218 = vcmp.lt.f32.partialorder %v117215, 5.0 (stack56)
        %v117223 = vsel /*vm=*/%vm117218, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v117227 = vsel /*vm=*/%vm117218, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v117231 = vsel /*vm=*/%vm117218, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v117235 = vsel /*vm=*/%vm117218, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v117239 = vsel /*vm=*/%vm117218, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v117243 = vsel /*vm=*/%vm117218, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v117247 = vsel /*vm=*/%vm117218, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v117251 = vsel /*vm=*/%vm117218, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v117255 = vsel /*vm=*/%vm117218, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v117259 = vadd.f32 -2.5, %v117215 (stack52)
        %v117261 = vrsqrt.pop %v117215 (stack67)
        %v117262 = vmul.f32 %v117261, %v117215 (stack68)
        %vm117263 = vcmp.eq.f32.partialorder %v117215, inf (stack69)
        %v117264 = vsel /*vm=*/%vm117263, /*on_true_vy=*/%v117215, /*on_false_vx=*/%v117262 (stack70)
        %vm117265 = vcmp.eq.f32.partialorder %v117215, 0.0 (stack71)
        %v117266 = vand.u32 2147483648, %v117215 (stack72)
        %v117267 = vsel /*vm=*/%vm117265, /*on_true_vy=*/%v117266, /*on_false_vx=*/%v117264 (stack73)
        %v117270 = vadd.f32 -3.0, %v117267 (stack52)
        %v117274 = vsel /*vm=*/%vm117218, /*on_true_vy=*/%v117259, /*on_false_vx=*/%v117270 (stack43)
        %v117278 = vmul.f32 %v117274, %v117255 (stack53)
        %v117282 = vadd.f32 %v117278, %v117251 (stack52)
        %v117286 = vmul.f32 %v117282, %v117274 (stack53)
        %v117290 = vadd.f32 %v117286, %v117247 (stack52)
        %v117294 = vmul.f32 %v117290, %v117274 (stack53)
        %v117298 = vadd.f32 %v117294, %v117243 (stack52)
        %v117302 = vmul.f32 %v117298, %v117274 (stack53)
        %v117306 = vadd.f32 %v117302, %v117239 (stack52)
        %v117310 = vmul.f32 %v117306, %v117274 (stack53)
        %v117314 = vadd.f32 %v117310, %v117235 (stack52)
        %v117318 = vmul.f32 %v117314, %v117274 (stack53)
        %v117322 = vadd.f32 %v117318, %v117231 (stack52)
        %v117326 = vmul.f32 %v117322, %v117274 (stack53)
        %v117330 = vadd.f32 %v117326, %v117227 (stack52)
        %v117334 = vmul.f32 %v117330, %v117274 (stack53)
        %v117338 = vadd.f32 %v117334, %v117223 (stack52)
        %v117342 = vmul.f32 %v117338, %v117189 (stack53)
        %v117346 = vsel /*vm=*/%vm117194, /*on_true_vy=*/%v117199, /*on_false_vx=*/%v117342 (stack43)
        %v117350 = vmul.f32 1.4140625, %v117346 (stack53)
        %v117353 = vpack.c.bf16 0.0, %v117350 (stack74)
        %120373 = vst [vmem:[%s280 + $0x17c] sm:$0xf] /*vst_source=*/%v117353 (stack75)
        %v117357 = vadd.s32 %v115971, %v1868 (stack39)
        %v117367 = vadd.s32 %v117357, %v415 (stack39)
        %vm117371 = vcmp.lt.u32.totalorder %v117367, %v117357 (stack42)
        %vm117376 = vcmp.lt.u32.totalorder %v117357, %v1868 (stack42)
        %v117381 = vadd.s32 %v115954, %v1855 (stack39)
        %v117385 = vadd.s32 1, %v117381 (stack39)
        %v117389 = vsel /*vm=*/%vm117376, /*on_true_vy=*/%v117385, /*on_false_vx=*/%v117381 (stack43)
        %v117393 = vadd.s32 1, %v117389 (stack39)
        %v117397 = vsel /*vm=*/%vm117371, /*on_true_vy=*/%v117393, /*on_false_vx=*/%v117389 (stack43)
        %v117402 = vadd.s32 %v117397, %v10 (stack39)
        %v117406 = vadd.s32 %v117367, %v9 (stack39)
        %v117410 = vadd.s32 %v117406, %v117402 (stack39)
        %v117412 = vshll.u32 %v117406, 13 (stack44)
        %v117413 = vshrl.u32 %v117406, 19 (stack45)
        %v117414 = vor.u32 %v117413, %v117412 (stack46)
        %v117415 = vxor.u32 %v117414, %v117410 (stack47)
        %v117418 = vadd.s32 %v117415, %v117410 (stack39)
        %v117420 = vshll.u32 %v117415, 15 (stack44)
        %v117421 = vshrl.u32 %v117415, 17 (stack45)
        %v117422 = vor.u32 %v117421, %v117420 (stack46)
        %v117423 = vxor.u32 %v117422, %v117418 (stack47)
        %v117426 = vadd.s32 %v117423, %v117418 (stack39)
        %v117428 = vshll.u32 %v117423, 26 (stack44)
        %v117429 = vshrl.u32 %v117423, 6 (stack45)
        %v117430 = vor.u32 %v117429, %v117428 (stack46)
        %v117431 = vxor.u32 %v117430, %v117426 (stack47)
        %v117434 = vadd.s32 %v117431, %v117426 (stack39)
        %v117438 = vadd.s32 %v117434, %v9 (stack39)
        %v117440 = vshll.u32 %v117431, 6 (stack44)
        %v117441 = vshrl.u32 %v117431, 26 (stack45)
        %v117442 = vor.u32 %v117441, %v117440 (stack46)
        %v117443 = vxor.u32 %v117442, %v117434 (stack47)
        %v117446 = vadd.s32 %v117443, %v8 (stack39)
        %v117450 = vadd.s32 1, %v117446 (stack39)
        %v117454 = vadd.s32 %v117450, %v117438 (stack39)
        %v117456 = vshll.u32 %v117450, 17 (stack44)
        %v117457 = vshrl.u32 %v117450, 15 (stack45)
        %v117458 = vor.u32 %v117457, %v117456 (stack46)
        %v117459 = vxor.u32 %v117458, %v117454 (stack47)
        %v117462 = vadd.s32 %v117459, %v117454 (stack39)
        %v117464 = vshll.u32 %v117459, 29 (stack44)
        %v117465 = vshrl.u32 %v117459, 3 (stack45)
        %v117466 = vor.u32 %v117465, %v117464 (stack46)
        %v117467 = vxor.u32 %v117466, %v117462 (stack47)
        %v117470 = vadd.s32 %v117467, %v117462 (stack39)
        %v117472 = vshll.u32 %v117467, 16 (stack44)
        %v117473 = vshrl.u32 %v117467, 16 (stack45)
        %v117474 = vor.u32 %v117473, %v117472 (stack46)
        %v117475 = vxor.u32 %v117474, %v117470 (stack47)
        %v117478 = vadd.s32 %v117475, %v117470 (stack39)
        %v117482 = vadd.s32 %v117478, %v8 (stack39)
        %v117484 = vshll.u32 %v117475, 24 (stack44)
        %v117485 = vshrl.u32 %v117475, 8 (stack45)
        %v117486 = vor.u32 %v117485, %v117484 (stack46)
        %v117487 = vxor.u32 %v117486, %v117478 (stack47)
        %v117490 = vadd.s32 %v117487, %v10 (stack39)
        %v117494 = vadd.s32 2, %v117490 (stack39)
        %v117498 = vadd.s32 %v117494, %v117482 (stack39)
        %v117500 = vshll.u32 %v117494, 13 (stack44)
        %v117501 = vshrl.u32 %v117494, 19 (stack45)
        %v117502 = vor.u32 %v117501, %v117500 (stack46)
        %v117503 = vxor.u32 %v117502, %v117498 (stack47)
        %v117506 = vadd.s32 %v117503, %v117498 (stack39)
        %v117508 = vshll.u32 %v117503, 15 (stack44)
        %v117509 = vshrl.u32 %v117503, 17 (stack45)
        %v117510 = vor.u32 %v117509, %v117508 (stack46)
        %v117511 = vxor.u32 %v117510, %v117506 (stack47)
        %v117514 = vadd.s32 %v117511, %v117506 (stack39)
        %v117516 = vshll.u32 %v117511, 26 (stack44)
        %v117517 = vshrl.u32 %v117511, 6 (stack45)
        %v117518 = vor.u32 %v117517, %v117516 (stack46)
        %v117519 = vxor.u32 %v117518, %v117514 (stack47)
        %v117522 = vadd.s32 %v117519, %v117514 (stack39)
        %v117526 = vadd.s32 %v117522, %v10 (stack39)
        %v117528 = vshll.u32 %v117519, 6 (stack44)
        %v117529 = vshrl.u32 %v117519, 26 (stack45)
        %v117530 = vor.u32 %v117529, %v117528 (stack46)
        %v117531 = vxor.u32 %v117530, %v117522 (stack47)
        %v117534 = vadd.s32 %v117531, %v9 (stack39)
        %v117538 = vadd.s32 3, %v117534 (stack39)
        %v117542 = vadd.s32 %v117538, %v117526 (stack39)
        %v117544 = vshll.u32 %v117538, 17 (stack44)
        %v117545 = vshrl.u32 %v117538, 15 (stack45)
        %v117546 = vor.u32 %v117545, %v117544 (stack46)
        %v117547 = vxor.u32 %v117546, %v117542 (stack47)
        %v117550 = vadd.s32 %v117547, %v117542 (stack39)
        %v117552 = vshll.u32 %v117547, 29 (stack44)
        %v117553 = vshrl.u32 %v117547, 3 (stack45)
        %v117554 = vor.u32 %v117553, %v117552 (stack46)
        %v117555 = vxor.u32 %v117554, %v117550 (stack47)
        %v117558 = vadd.s32 %v117555, %v117550 (stack39)
        %v117560 = vshll.u32 %v117555, 16 (stack44)
        %v117561 = vshrl.u32 %v117555, 16 (stack45)
        %v117562 = vor.u32 %v117561, %v117560 (stack46)
        %v117563 = vxor.u32 %v117562, %v117558 (stack47)
        %v117566 = vadd.s32 %v117563, %v117558 (stack39)
        %v117570 = vadd.s32 %v117566, %v9 (stack39)
        %v117572 = vshll.u32 %v117563, 24 (stack44)
        %v117573 = vshrl.u32 %v117563, 8 (stack45)
        %v117574 = vor.u32 %v117573, %v117572 (stack46)
        %v117575 = vxor.u32 %v117574, %v117566 (stack47)
        %v117578 = vadd.s32 %v117575, %v8 (stack39)
        %v117582 = vadd.s32 4, %v117578 (stack39)
        %v117586 = vadd.s32 %v117582, %v117570 (stack39)
        %v117588 = vshll.u32 %v117582, 13 (stack44)
        %v117589 = vshrl.u32 %v117582, 19 (stack45)
        %v117590 = vor.u32 %v117589, %v117588 (stack46)
        %v117591 = vxor.u32 %v117590, %v117586 (stack47)
        %v117594 = vadd.s32 %v117591, %v117586 (stack39)
        %v117596 = vshll.u32 %v117591, 15 (stack44)
        %v117597 = vshrl.u32 %v117591, 17 (stack45)
        %v117598 = vor.u32 %v117597, %v117596 (stack46)
        %v117599 = vxor.u32 %v117598, %v117594 (stack47)
        %v117602 = vadd.s32 %v117599, %v117594 (stack39)
        %v117604 = vshll.u32 %v117599, 26 (stack44)
        %v117605 = vshrl.u32 %v117599, 6 (stack45)
        %v117606 = vor.u32 %v117605, %v117604 (stack46)
        %v117607 = vxor.u32 %v117606, %v117602 (stack47)
        %v117610 = vadd.s32 %v117607, %v117602 (stack39)
        %v117614 = vadd.s32 %v117610, %v8 (stack39)
        %v117616 = vshll.u32 %v117607, 6 (stack44)
        %v117617 = vshrl.u32 %v117607, 26 (stack45)
        %v117618 = vor.u32 %v117617, %v117616 (stack46)
        %v117619 = vxor.u32 %v117618, %v117610 (stack47)
        %v117622 = vadd.s32 %v117619, %v10 (stack39)
        %v117626 = vadd.s32 5, %v117622 (stack39)
        %v117628 = vxor.u32 %v117626, %v117614 (stack47)
        %v117629 = vand.u32.u8 255, %v117628 (stack48)
        %v117630 = vand.u32 65535, %v117629 (stack49)
        %v117631 = vshrl.u32 %v117630, 1 (stack50)
        %v117632 = vor.u32 16256, %v117631 (stack46)
        %v117633 = vand.u32.u16 65535, %v117632 (stack51)
        %v120374 = vadd.low.f32.bf16 -1.0, %v117633 (stack52)
        %v117642 = vmul.f32 2.0, %v120374 (stack53)
        %v117646 = vadd.f32 -0.99609375, %v117642 (stack52)
        %v117650 = vmax.f32 %v117646, -0.99609375 (stack54)
        %v117652 = vand.u32 2147483647, %v117650 (stack55)
        %vm117655 = vcmp.eq.f32.partialorder %v117652, 1.0 (stack56)
        %v117660 = vmul.f32 inf, %v117650 (stack53)
        %v117662 = vxor.u32 2147483648, %v117650 (stack57)
        %v117665 = vmul.f32 %v117662, %v117650 (stack53)
        %v117667 = vadd.f32 1.0, %v117665 (stack58)
        %v117668 = vlog2.pop %v117667 (stack59)
        %v117669 = vmul.f32 0.6931472, %v117668 (stack60)
        %v117670 = vmul.f32 -0.5, %v117665 (stack61)
        %v117671 = vadd.f32 1.0, %v117670 (stack62)
        %v117672 = vmul.f32 %v117671, %v117665 (stack63)
        %v117673 = vand.u32 2147483647, %v117665 (stack64)
        %vm117674 = vcmp.lt.f32.partialorder %v117673, 0.0004427343 (stack65)
        %v117675 = vsel /*vm=*/%vm117674, /*on_true_vy=*/%v117672, /*on_false_vx=*/%v117669 (stack66)
        %v117676 = vxor.u32 2147483648, %v117675 (stack57)
        %vm117679 = vcmp.lt.f32.partialorder %v117676, 5.0 (stack56)
        %v117684 = vsel /*vm=*/%vm117679, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v117688 = vsel /*vm=*/%vm117679, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v117692 = vsel /*vm=*/%vm117679, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v117696 = vsel /*vm=*/%vm117679, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v117700 = vsel /*vm=*/%vm117679, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v117704 = vsel /*vm=*/%vm117679, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v117708 = vsel /*vm=*/%vm117679, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v117712 = vsel /*vm=*/%vm117679, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v117716 = vsel /*vm=*/%vm117679, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v117720 = vadd.f32 -2.5, %v117676 (stack52)
        %v117722 = vrsqrt.pop %v117676 (stack67)
        %v117723 = vmul.f32 %v117722, %v117676 (stack68)
        %vm117724 = vcmp.eq.f32.partialorder %v117676, inf (stack69)
        %v117725 = vsel /*vm=*/%vm117724, /*on_true_vy=*/%v117676, /*on_false_vx=*/%v117723 (stack70)
        %vm117726 = vcmp.eq.f32.partialorder %v117676, 0.0 (stack71)
        %v117727 = vand.u32 2147483648, %v117676 (stack72)
        %v117728 = vsel /*vm=*/%vm117726, /*on_true_vy=*/%v117727, /*on_false_vx=*/%v117725 (stack73)
        %v117731 = vadd.f32 -3.0, %v117728 (stack52)
        %v117735 = vsel /*vm=*/%vm117679, /*on_true_vy=*/%v117720, /*on_false_vx=*/%v117731 (stack43)
        %v117739 = vmul.f32 %v117735, %v117716 (stack53)
        %v117743 = vadd.f32 %v117739, %v117712 (stack52)
        %v117747 = vmul.f32 %v117743, %v117735 (stack53)
        %v117751 = vadd.f32 %v117747, %v117708 (stack52)
        %v117755 = vmul.f32 %v117751, %v117735 (stack53)
        %v117759 = vadd.f32 %v117755, %v117704 (stack52)
        %v117763 = vmul.f32 %v117759, %v117735 (stack53)
        %v117767 = vadd.f32 %v117763, %v117700 (stack52)
        %v117771 = vmul.f32 %v117767, %v117735 (stack53)
        %v117775 = vadd.f32 %v117771, %v117696 (stack52)
        %v117779 = vmul.f32 %v117775, %v117735 (stack53)
        %v117783 = vadd.f32 %v117779, %v117692 (stack52)
        %v117787 = vmul.f32 %v117783, %v117735 (stack53)
        %v117791 = vadd.f32 %v117787, %v117688 (stack52)
        %v117795 = vmul.f32 %v117791, %v117735 (stack53)
        %v117799 = vadd.f32 %v117795, %v117684 (stack52)
        %v117803 = vmul.f32 %v117799, %v117650 (stack53)
        %v117807 = vsel /*vm=*/%vm117655, /*on_true_vy=*/%v117660, /*on_false_vx=*/%v117803 (stack43)
        %v117811 = vmul.f32 1.4140625, %v117807 (stack53)
        %v117814 = vpack.c.bf16 0.0, %v117811 (stack74)
        %120375 = vst [vmem:[%s280 + $0x1fc] sm:$0xf] /*vst_source=*/%v117814 (stack75)
        %v117818 = vadd.s32 %v115971, %v2355 (stack39)
        %v117828 = vadd.s32 %v117818, %v415 (stack39)
        %vm117832 = vcmp.lt.u32.totalorder %v117828, %v117818 (stack42)
        %vm117837 = vcmp.lt.u32.totalorder %v117818, %v2355 (stack42)
        %v117842 = vadd.s32 %v115954, %v2342 (stack39)
        %v117846 = vadd.s32 1, %v117842 (stack39)
        %v117850 = vsel /*vm=*/%vm117837, /*on_true_vy=*/%v117846, /*on_false_vx=*/%v117842 (stack43)
        %v117854 = vadd.s32 1, %v117850 (stack39)
        %v117858 = vsel /*vm=*/%vm117832, /*on_true_vy=*/%v117854, /*on_false_vx=*/%v117850 (stack43)
        %v117863 = vadd.s32 %v117858, %v10 (stack39)
        %v117867 = vadd.s32 %v117828, %v9 (stack39)
        %v117871 = vadd.s32 %v117867, %v117863 (stack39)
        %v117873 = vshll.u32 %v117867, 13 (stack44)
        %v117874 = vshrl.u32 %v117867, 19 (stack45)
        %v117875 = vor.u32 %v117874, %v117873 (stack46)
        %v117876 = vxor.u32 %v117875, %v117871 (stack47)
        %v117879 = vadd.s32 %v117876, %v117871 (stack39)
        %v117881 = vshll.u32 %v117876, 15 (stack44)
        %v117882 = vshrl.u32 %v117876, 17 (stack45)
        %v117883 = vor.u32 %v117882, %v117881 (stack46)
        %v117884 = vxor.u32 %v117883, %v117879 (stack47)
        %v117887 = vadd.s32 %v117884, %v117879 (stack39)
        %v117889 = vshll.u32 %v117884, 26 (stack44)
        %v117890 = vshrl.u32 %v117884, 6 (stack45)
        %v117891 = vor.u32 %v117890, %v117889 (stack46)
        %v117892 = vxor.u32 %v117891, %v117887 (stack47)
        %v117895 = vadd.s32 %v117892, %v117887 (stack39)
        %v117899 = vadd.s32 %v117895, %v9 (stack39)
        %v117901 = vshll.u32 %v117892, 6 (stack44)
        %v117902 = vshrl.u32 %v117892, 26 (stack45)
        %v117903 = vor.u32 %v117902, %v117901 (stack46)
        %v117904 = vxor.u32 %v117903, %v117895 (stack47)
        %v117907 = vadd.s32 %v117904, %v8 (stack39)
        %v117911 = vadd.s32 1, %v117907 (stack39)
        %v117915 = vadd.s32 %v117911, %v117899 (stack39)
        %v117917 = vshll.u32 %v117911, 17 (stack44)
        %v117918 = vshrl.u32 %v117911, 15 (stack45)
        %v117919 = vor.u32 %v117918, %v117917 (stack46)
        %v117920 = vxor.u32 %v117919, %v117915 (stack47)
        %v117923 = vadd.s32 %v117920, %v117915 (stack39)
        %v117925 = vshll.u32 %v117920, 29 (stack44)
        %v117926 = vshrl.u32 %v117920, 3 (stack45)
        %v117927 = vor.u32 %v117926, %v117925 (stack46)
        %v117928 = vxor.u32 %v117927, %v117923 (stack47)
        %v117931 = vadd.s32 %v117928, %v117923 (stack39)
        %v117933 = vshll.u32 %v117928, 16 (stack44)
        %v117934 = vshrl.u32 %v117928, 16 (stack45)
        %v117935 = vor.u32 %v117934, %v117933 (stack46)
        %v117936 = vxor.u32 %v117935, %v117931 (stack47)
        %v117939 = vadd.s32 %v117936, %v117931 (stack39)
        %v117943 = vadd.s32 %v117939, %v8 (stack39)
        %v117945 = vshll.u32 %v117936, 24 (stack44)
        %v117946 = vshrl.u32 %v117936, 8 (stack45)
        %v117947 = vor.u32 %v117946, %v117945 (stack46)
        %v117948 = vxor.u32 %v117947, %v117939 (stack47)
        %v117951 = vadd.s32 %v117948, %v10 (stack39)
        %v117955 = vadd.s32 2, %v117951 (stack39)
        %v117959 = vadd.s32 %v117955, %v117943 (stack39)
        %v117961 = vshll.u32 %v117955, 13 (stack44)
        %v117962 = vshrl.u32 %v117955, 19 (stack45)
        %v117963 = vor.u32 %v117962, %v117961 (stack46)
        %v117964 = vxor.u32 %v117963, %v117959 (stack47)
        %v117967 = vadd.s32 %v117964, %v117959 (stack39)
        %v117969 = vshll.u32 %v117964, 15 (stack44)
        %v117970 = vshrl.u32 %v117964, 17 (stack45)
        %v117971 = vor.u32 %v117970, %v117969 (stack46)
        %v117972 = vxor.u32 %v117971, %v117967 (stack47)
        %v117975 = vadd.s32 %v117972, %v117967 (stack39)
        %v117977 = vshll.u32 %v117972, 26 (stack44)
        %v117978 = vshrl.u32 %v117972, 6 (stack45)
        %v117979 = vor.u32 %v117978, %v117977 (stack46)
        %v117980 = vxor.u32 %v117979, %v117975 (stack47)
        %v117983 = vadd.s32 %v117980, %v117975 (stack39)
        %v117987 = vadd.s32 %v117983, %v10 (stack39)
        %v117989 = vshll.u32 %v117980, 6 (stack44)
        %v117990 = vshrl.u32 %v117980, 26 (stack45)
        %v117991 = vor.u32 %v117990, %v117989 (stack46)
        %v117992 = vxor.u32 %v117991, %v117983 (stack47)
        %v117995 = vadd.s32 %v117992, %v9 (stack39)
        %v117999 = vadd.s32 3, %v117995 (stack39)
        %v118003 = vadd.s32 %v117999, %v117987 (stack39)
        %v118005 = vshll.u32 %v117999, 17 (stack44)
        %v118006 = vshrl.u32 %v117999, 15 (stack45)
        %v118007 = vor.u32 %v118006, %v118005 (stack46)
        %v118008 = vxor.u32 %v118007, %v118003 (stack47)
        %v118011 = vadd.s32 %v118008, %v118003 (stack39)
        %v118013 = vshll.u32 %v118008, 29 (stack44)
        %v118014 = vshrl.u32 %v118008, 3 (stack45)
        %v118015 = vor.u32 %v118014, %v118013 (stack46)
        %v118016 = vxor.u32 %v118015, %v118011 (stack47)
        %v118019 = vadd.s32 %v118016, %v118011 (stack39)
        %v118021 = vshll.u32 %v118016, 16 (stack44)
        %v118022 = vshrl.u32 %v118016, 16 (stack45)
        %v118023 = vor.u32 %v118022, %v118021 (stack46)
        %v118024 = vxor.u32 %v118023, %v118019 (stack47)
        %v118027 = vadd.s32 %v118024, %v118019 (stack39)
        %v118031 = vadd.s32 %v118027, %v9 (stack39)
        %v118033 = vshll.u32 %v118024, 24 (stack44)
        %v118034 = vshrl.u32 %v118024, 8 (stack45)
        %v118035 = vor.u32 %v118034, %v118033 (stack46)
        %v118036 = vxor.u32 %v118035, %v118027 (stack47)
        %v118039 = vadd.s32 %v118036, %v8 (stack39)
        %v118043 = vadd.s32 4, %v118039 (stack39)
        %v118047 = vadd.s32 %v118043, %v118031 (stack39)
        %v118049 = vshll.u32 %v118043, 13 (stack44)
        %v118050 = vshrl.u32 %v118043, 19 (stack45)
        %v118051 = vor.u32 %v118050, %v118049 (stack46)
        %v118052 = vxor.u32 %v118051, %v118047 (stack47)
        %v118055 = vadd.s32 %v118052, %v118047 (stack39)
        %v118057 = vshll.u32 %v118052, 15 (stack44)
        %v118058 = vshrl.u32 %v118052, 17 (stack45)
        %v118059 = vor.u32 %v118058, %v118057 (stack46)
        %v118060 = vxor.u32 %v118059, %v118055 (stack47)
        %v118063 = vadd.s32 %v118060, %v118055 (stack39)
        %v118065 = vshll.u32 %v118060, 26 (stack44)
        %v118066 = vshrl.u32 %v118060, 6 (stack45)
        %v118067 = vor.u32 %v118066, %v118065 (stack46)
        %v118068 = vxor.u32 %v118067, %v118063 (stack47)
        %v118071 = vadd.s32 %v118068, %v118063 (stack39)
        %v118075 = vadd.s32 %v118071, %v8 (stack39)
        %v118077 = vshll.u32 %v118068, 6 (stack44)
        %v118078 = vshrl.u32 %v118068, 26 (stack45)
        %v118079 = vor.u32 %v118078, %v118077 (stack46)
        %v118080 = vxor.u32 %v118079, %v118071 (stack47)
        %v118083 = vadd.s32 %v118080, %v10 (stack39)
        %v118087 = vadd.s32 5, %v118083 (stack39)
        %v118089 = vxor.u32 %v118087, %v118075 (stack47)
        %v118090 = vand.u32.u8 255, %v118089 (stack48)
        %v118091 = vand.u32 65535, %v118090 (stack49)
        %v118092 = vshrl.u32 %v118091, 1 (stack50)
        %v118093 = vor.u32 16256, %v118092 (stack46)
        %v118094 = vand.u32.u16 65535, %v118093 (stack51)
        %v120376 = vadd.low.f32.bf16 -1.0, %v118094 (stack52)
        %v118103 = vmul.f32 2.0, %v120376 (stack53)
        %v118107 = vadd.f32 -0.99609375, %v118103 (stack52)
        %v118111 = vmax.f32 %v118107, -0.99609375 (stack54)
        %v118113 = vand.u32 2147483647, %v118111 (stack55)
        %vm118116 = vcmp.eq.f32.partialorder %v118113, 1.0 (stack56)
        %v118121 = vmul.f32 inf, %v118111 (stack53)
        %v118123 = vxor.u32 2147483648, %v118111 (stack57)
        %v118126 = vmul.f32 %v118123, %v118111 (stack53)
        %v118128 = vadd.f32 1.0, %v118126 (stack58)
        %v118129 = vlog2.pop %v118128 (stack59)
        %v118130 = vmul.f32 0.6931472, %v118129 (stack60)
        %v118131 = vmul.f32 -0.5, %v118126 (stack61)
        %v118132 = vadd.f32 1.0, %v118131 (stack62)
        %v118133 = vmul.f32 %v118132, %v118126 (stack63)
        %v118134 = vand.u32 2147483647, %v118126 (stack64)
        %vm118135 = vcmp.lt.f32.partialorder %v118134, 0.0004427343 (stack65)
        %v118136 = vsel /*vm=*/%vm118135, /*on_true_vy=*/%v118133, /*on_false_vx=*/%v118130 (stack66)
        %v118137 = vxor.u32 2147483648, %v118136 (stack57)
        %vm118140 = vcmp.lt.f32.partialorder %v118137, 5.0 (stack56)
        %v118145 = vsel /*vm=*/%vm118140, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v118149 = vsel /*vm=*/%vm118140, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v118153 = vsel /*vm=*/%vm118140, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v118157 = vsel /*vm=*/%vm118140, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v118161 = vsel /*vm=*/%vm118140, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v118165 = vsel /*vm=*/%vm118140, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v118169 = vsel /*vm=*/%vm118140, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v118173 = vsel /*vm=*/%vm118140, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v118177 = vsel /*vm=*/%vm118140, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v118181 = vadd.f32 -2.5, %v118137 (stack52)
        %v118183 = vrsqrt.pop %v118137 (stack67)
        %v118184 = vmul.f32 %v118183, %v118137 (stack68)
        %vm118185 = vcmp.eq.f32.partialorder %v118137, inf (stack69)
        %v118186 = vsel /*vm=*/%vm118185, /*on_true_vy=*/%v118137, /*on_false_vx=*/%v118184 (stack70)
        %vm118187 = vcmp.eq.f32.partialorder %v118137, 0.0 (stack71)
        %v118188 = vand.u32 2147483648, %v118137 (stack72)
        %v118189 = vsel /*vm=*/%vm118187, /*on_true_vy=*/%v118188, /*on_false_vx=*/%v118186 (stack73)
        %v118192 = vadd.f32 -3.0, %v118189 (stack52)
        %v118196 = vsel /*vm=*/%vm118140, /*on_true_vy=*/%v118181, /*on_false_vx=*/%v118192 (stack43)
        %v118200 = vmul.f32 %v118196, %v118177 (stack53)
        %v118204 = vadd.f32 %v118200, %v118173 (stack52)
        %v118208 = vmul.f32 %v118204, %v118196 (stack53)
        %v118212 = vadd.f32 %v118208, %v118169 (stack52)
        %v118216 = vmul.f32 %v118212, %v118196 (stack53)
        %v118220 = vadd.f32 %v118216, %v118165 (stack52)
        %v118224 = vmul.f32 %v118220, %v118196 (stack53)
        %v118228 = vadd.f32 %v118224, %v118161 (stack52)
        %v118232 = vmul.f32 %v118228, %v118196 (stack53)
        %v118236 = vadd.f32 %v118232, %v118157 (stack52)
        %v118240 = vmul.f32 %v118236, %v118196 (stack53)
        %v118244 = vadd.f32 %v118240, %v118153 (stack52)
        %v118248 = vmul.f32 %v118244, %v118196 (stack53)
        %v118252 = vadd.f32 %v118248, %v118149 (stack52)
        %v118256 = vmul.f32 %v118252, %v118196 (stack53)
        %v118260 = vadd.f32 %v118256, %v118145 (stack52)
        %v118264 = vmul.f32 %v118260, %v118111 (stack53)
        %v118268 = vsel /*vm=*/%vm118116, /*on_true_vy=*/%v118121, /*on_false_vx=*/%v118264 (stack43)
        %v118272 = vmul.f32 1.4140625, %v118268 (stack53)
        %v118275 = vpack.c.bf16 0.0, %v118272 (stack74)
        %120377 = vst [vmem:[%s280 + $0x27c] sm:$0xf] /*vst_source=*/%v118275 (stack75)
        %v118279 = vadd.s32 %v115971, %v2842 (stack39)
        %v118289 = vadd.s32 %v118279, %v415 (stack39)
        %vm118293 = vcmp.lt.u32.totalorder %v118289, %v118279 (stack42)
        %vm118298 = vcmp.lt.u32.totalorder %v118279, %v2842 (stack42)
        %v118303 = vadd.s32 %v115954, %v2829 (stack39)
        %v118307 = vadd.s32 1, %v118303 (stack39)
        %v118311 = vsel /*vm=*/%vm118298, /*on_true_vy=*/%v118307, /*on_false_vx=*/%v118303 (stack43)
        %v118315 = vadd.s32 1, %v118311 (stack39)
        %v118319 = vsel /*vm=*/%vm118293, /*on_true_vy=*/%v118315, /*on_false_vx=*/%v118311 (stack43)
        %v118324 = vadd.s32 %v118319, %v10 (stack39)
        %v118328 = vadd.s32 %v118289, %v9 (stack39)
        %v118332 = vadd.s32 %v118328, %v118324 (stack39)
        %v118334 = vshll.u32 %v118328, 13 (stack44)
        %v118335 = vshrl.u32 %v118328, 19 (stack45)
        %v118336 = vor.u32 %v118335, %v118334 (stack46)
        %v118337 = vxor.u32 %v118336, %v118332 (stack47)
        %v118340 = vadd.s32 %v118337, %v118332 (stack39)
        %v118342 = vshll.u32 %v118337, 15 (stack44)
        %v118343 = vshrl.u32 %v118337, 17 (stack45)
        %v118344 = vor.u32 %v118343, %v118342 (stack46)
        %v118345 = vxor.u32 %v118344, %v118340 (stack47)
        %v118348 = vadd.s32 %v118345, %v118340 (stack39)
        %v118350 = vshll.u32 %v118345, 26 (stack44)
        %v118351 = vshrl.u32 %v118345, 6 (stack45)
        %v118352 = vor.u32 %v118351, %v118350 (stack46)
        %v118353 = vxor.u32 %v118352, %v118348 (stack47)
        %v118356 = vadd.s32 %v118353, %v118348 (stack39)
        %v118360 = vadd.s32 %v118356, %v9 (stack39)
        %v118362 = vshll.u32 %v118353, 6 (stack44)
        %v118363 = vshrl.u32 %v118353, 26 (stack45)
        %v118364 = vor.u32 %v118363, %v118362 (stack46)
        %v118365 = vxor.u32 %v118364, %v118356 (stack47)
        %v118368 = vadd.s32 %v118365, %v8 (stack39)
        %v118372 = vadd.s32 1, %v118368 (stack39)
        %v118376 = vadd.s32 %v118372, %v118360 (stack39)
        %v118378 = vshll.u32 %v118372, 17 (stack44)
        %v118379 = vshrl.u32 %v118372, 15 (stack45)
        %v118380 = vor.u32 %v118379, %v118378 (stack46)
        %v118381 = vxor.u32 %v118380, %v118376 (stack47)
        %v118384 = vadd.s32 %v118381, %v118376 (stack39)
        %v118386 = vshll.u32 %v118381, 29 (stack44)
        %v118387 = vshrl.u32 %v118381, 3 (stack45)
        %v118388 = vor.u32 %v118387, %v118386 (stack46)
        %v118389 = vxor.u32 %v118388, %v118384 (stack47)
        %v118392 = vadd.s32 %v118389, %v118384 (stack39)
        %v118394 = vshll.u32 %v118389, 16 (stack44)
        %v118395 = vshrl.u32 %v118389, 16 (stack45)
        %v118396 = vor.u32 %v118395, %v118394 (stack46)
        %v118397 = vxor.u32 %v118396, %v118392 (stack47)
        %v118400 = vadd.s32 %v118397, %v118392 (stack39)
        %v118404 = vadd.s32 %v118400, %v8 (stack39)
        %v118406 = vshll.u32 %v118397, 24 (stack44)
        %v118407 = vshrl.u32 %v118397, 8 (stack45)
        %v118408 = vor.u32 %v118407, %v118406 (stack46)
        %v118409 = vxor.u32 %v118408, %v118400 (stack47)
        %v118412 = vadd.s32 %v118409, %v10 (stack39)
        %v118416 = vadd.s32 2, %v118412 (stack39)
        %v118420 = vadd.s32 %v118416, %v118404 (stack39)
        %v118422 = vshll.u32 %v118416, 13 (stack44)
        %v118423 = vshrl.u32 %v118416, 19 (stack45)
        %v118424 = vor.u32 %v118423, %v118422 (stack46)
        %v118425 = vxor.u32 %v118424, %v118420 (stack47)
        %v118428 = vadd.s32 %v118425, %v118420 (stack39)
        %v118430 = vshll.u32 %v118425, 15 (stack44)
        %v118431 = vshrl.u32 %v118425, 17 (stack45)
        %v118432 = vor.u32 %v118431, %v118430 (stack46)
        %v118433 = vxor.u32 %v118432, %v118428 (stack47)
        %v118436 = vadd.s32 %v118433, %v118428 (stack39)
        %v118438 = vshll.u32 %v118433, 26 (stack44)
        %v118439 = vshrl.u32 %v118433, 6 (stack45)
        %v118440 = vor.u32 %v118439, %v118438 (stack46)
        %v118441 = vxor.u32 %v118440, %v118436 (stack47)
        %v118444 = vadd.s32 %v118441, %v118436 (stack39)
        %v118448 = vadd.s32 %v118444, %v10 (stack39)
        %v118450 = vshll.u32 %v118441, 6 (stack44)
        %v118451 = vshrl.u32 %v118441, 26 (stack45)
        %v118452 = vor.u32 %v118451, %v118450 (stack46)
        %v118453 = vxor.u32 %v118452, %v118444 (stack47)
        %v118456 = vadd.s32 %v118453, %v9 (stack39)
        %v118460 = vadd.s32 3, %v118456 (stack39)
        %v118464 = vadd.s32 %v118460, %v118448 (stack39)
        %v118466 = vshll.u32 %v118460, 17 (stack44)
        %v118467 = vshrl.u32 %v118460, 15 (stack45)
        %v118468 = vor.u32 %v118467, %v118466 (stack46)
        %v118469 = vxor.u32 %v118468, %v118464 (stack47)
        %v118472 = vadd.s32 %v118469, %v118464 (stack39)
        %v118474 = vshll.u32 %v118469, 29 (stack44)
        %v118475 = vshrl.u32 %v118469, 3 (stack45)
        %v118476 = vor.u32 %v118475, %v118474 (stack46)
        %v118477 = vxor.u32 %v118476, %v118472 (stack47)
        %v118480 = vadd.s32 %v118477, %v118472 (stack39)
        %v118482 = vshll.u32 %v118477, 16 (stack44)
        %v118483 = vshrl.u32 %v118477, 16 (stack45)
        %v118484 = vor.u32 %v118483, %v118482 (stack46)
        %v118485 = vxor.u32 %v118484, %v118480 (stack47)
        %v118488 = vadd.s32 %v118485, %v118480 (stack39)
        %v118492 = vadd.s32 %v118488, %v9 (stack39)
        %v118494 = vshll.u32 %v118485, 24 (stack44)
        %v118495 = vshrl.u32 %v118485, 8 (stack45)
        %v118496 = vor.u32 %v118495, %v118494 (stack46)
        %v118497 = vxor.u32 %v118496, %v118488 (stack47)
        %v118500 = vadd.s32 %v118497, %v8 (stack39)
        %v118504 = vadd.s32 4, %v118500 (stack39)
        %v118508 = vadd.s32 %v118504, %v118492 (stack39)
        %v118510 = vshll.u32 %v118504, 13 (stack44)
        %v118511 = vshrl.u32 %v118504, 19 (stack45)
        %v118512 = vor.u32 %v118511, %v118510 (stack46)
        %v118513 = vxor.u32 %v118512, %v118508 (stack47)
        %v118516 = vadd.s32 %v118513, %v118508 (stack39)
        %v118518 = vshll.u32 %v118513, 15 (stack44)
        %v118519 = vshrl.u32 %v118513, 17 (stack45)
        %v118520 = vor.u32 %v118519, %v118518 (stack46)
        %v118521 = vxor.u32 %v118520, %v118516 (stack47)
        %v118524 = vadd.s32 %v118521, %v118516 (stack39)
        %v118526 = vshll.u32 %v118521, 26 (stack44)
        %v118527 = vshrl.u32 %v118521, 6 (stack45)
        %v118528 = vor.u32 %v118527, %v118526 (stack46)
        %v118529 = vxor.u32 %v118528, %v118524 (stack47)
        %v118532 = vadd.s32 %v118529, %v118524 (stack39)
        %v118536 = vadd.s32 %v118532, %v8 (stack39)
        %v118538 = vshll.u32 %v118529, 6 (stack44)
        %v118539 = vshrl.u32 %v118529, 26 (stack45)
        %v118540 = vor.u32 %v118539, %v118538 (stack46)
        %v118541 = vxor.u32 %v118540, %v118532 (stack47)
        %v118544 = vadd.s32 %v118541, %v10 (stack39)
        %v118548 = vadd.s32 5, %v118544 (stack39)
        %v118550 = vxor.u32 %v118548, %v118536 (stack47)
        %v118551 = vand.u32.u8 255, %v118550 (stack48)
        %v118552 = vand.u32 65535, %v118551 (stack49)
        %v118553 = vshrl.u32 %v118552, 1 (stack50)
        %v118554 = vor.u32 16256, %v118553 (stack46)
        %v118555 = vand.u32.u16 65535, %v118554 (stack51)
        %v120378 = vadd.low.f32.bf16 -1.0, %v118555 (stack52)
        %v118564 = vmul.f32 2.0, %v120378 (stack53)
        %v118568 = vadd.f32 -0.99609375, %v118564 (stack52)
        %v118572 = vmax.f32 %v118568, -0.99609375 (stack54)
        %v118574 = vand.u32 2147483647, %v118572 (stack55)
        %vm118577 = vcmp.eq.f32.partialorder %v118574, 1.0 (stack56)
        %v118582 = vmul.f32 inf, %v118572 (stack53)
        %v118584 = vxor.u32 2147483648, %v118572 (stack57)
        %v118587 = vmul.f32 %v118584, %v118572 (stack53)
        %v118589 = vadd.f32 1.0, %v118587 (stack58)
        %v118590 = vlog2.pop %v118589 (stack59)
        %v118591 = vmul.f32 0.6931472, %v118590 (stack60)
        %v118592 = vmul.f32 -0.5, %v118587 (stack61)
        %v118593 = vadd.f32 1.0, %v118592 (stack62)
        %v118594 = vmul.f32 %v118593, %v118587 (stack63)
        %v118595 = vand.u32 2147483647, %v118587 (stack64)
        %vm118596 = vcmp.lt.f32.partialorder %v118595, 0.0004427343 (stack65)
        %v118597 = vsel /*vm=*/%vm118596, /*on_true_vy=*/%v118594, /*on_false_vx=*/%v118591 (stack66)
        %v118598 = vxor.u32 2147483648, %v118597 (stack57)
        %vm118601 = vcmp.lt.f32.partialorder %v118598, 5.0 (stack56)
        %v118606 = vsel /*vm=*/%vm118601, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v118610 = vsel /*vm=*/%vm118601, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v118614 = vsel /*vm=*/%vm118601, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v118618 = vsel /*vm=*/%vm118601, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v118622 = vsel /*vm=*/%vm118601, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v118626 = vsel /*vm=*/%vm118601, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v118630 = vsel /*vm=*/%vm118601, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v118634 = vsel /*vm=*/%vm118601, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v118638 = vsel /*vm=*/%vm118601, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v118642 = vadd.f32 -2.5, %v118598 (stack52)
        %v118644 = vrsqrt.pop %v118598 (stack67)
        %v118645 = vmul.f32 %v118644, %v118598 (stack68)
        %vm118646 = vcmp.eq.f32.partialorder %v118598, inf (stack69)
        %v118647 = vsel /*vm=*/%vm118646, /*on_true_vy=*/%v118598, /*on_false_vx=*/%v118645 (stack70)
        %vm118648 = vcmp.eq.f32.partialorder %v118598, 0.0 (stack71)
        %v118649 = vand.u32 2147483648, %v118598 (stack72)
        %v118650 = vsel /*vm=*/%vm118648, /*on_true_vy=*/%v118649, /*on_false_vx=*/%v118647 (stack73)
        %v118653 = vadd.f32 -3.0, %v118650 (stack52)
        %v118657 = vsel /*vm=*/%vm118601, /*on_true_vy=*/%v118642, /*on_false_vx=*/%v118653 (stack43)
        %v118661 = vmul.f32 %v118657, %v118638 (stack53)
        %v118665 = vadd.f32 %v118661, %v118634 (stack52)
        %v118669 = vmul.f32 %v118665, %v118657 (stack53)
        %v118673 = vadd.f32 %v118669, %v118630 (stack52)
        %v118677 = vmul.f32 %v118673, %v118657 (stack53)
        %v118681 = vadd.f32 %v118677, %v118626 (stack52)
        %v118685 = vmul.f32 %v118681, %v118657 (stack53)
        %v118689 = vadd.f32 %v118685, %v118622 (stack52)
        %v118693 = vmul.f32 %v118689, %v118657 (stack53)
        %v118697 = vadd.f32 %v118693, %v118618 (stack52)
        %v118701 = vmul.f32 %v118697, %v118657 (stack53)
        %v118705 = vadd.f32 %v118701, %v118614 (stack52)
        %v118709 = vmul.f32 %v118705, %v118657 (stack53)
        %v118713 = vadd.f32 %v118709, %v118610 (stack52)
        %v118717 = vmul.f32 %v118713, %v118657 (stack53)
        %v118721 = vadd.f32 %v118717, %v118606 (stack52)
        %v118725 = vmul.f32 %v118721, %v118572 (stack53)
        %v118729 = vsel /*vm=*/%vm118577, /*on_true_vy=*/%v118582, /*on_false_vx=*/%v118725 (stack43)
        %v118733 = vmul.f32 1.4140625, %v118729 (stack53)
        %v118736 = vpack.c.bf16 0.0, %v118733 (stack74)
        %120379 = vst [vmem:[%s280 + $0x2fc] sm:$0xf] /*vst_source=*/%v118736 (stack75)
        %v118740 = vadd.s32 %v115971, %v3329 (stack39)
        %v118750 = vadd.s32 %v118740, %v415 (stack39)
        %vm118754 = vcmp.lt.u32.totalorder %v118750, %v118740 (stack42)
        %vm118759 = vcmp.lt.u32.totalorder %v118740, %v3329 (stack42)
        %v118764 = vadd.s32 %v115954, %v3316 (stack39)
        %v118768 = vadd.s32 1, %v118764 (stack39)
        %v118772 = vsel /*vm=*/%vm118759, /*on_true_vy=*/%v118768, /*on_false_vx=*/%v118764 (stack43)
        %v118776 = vadd.s32 1, %v118772 (stack39)
        %v118780 = vsel /*vm=*/%vm118754, /*on_true_vy=*/%v118776, /*on_false_vx=*/%v118772 (stack43)
        %v118785 = vadd.s32 %v118780, %v10 (stack39)
        %v118789 = vadd.s32 %v118750, %v9 (stack39)
        %v118793 = vadd.s32 %v118789, %v118785 (stack39)
        %v118795 = vshll.u32 %v118789, 13 (stack44)
        %v118796 = vshrl.u32 %v118789, 19 (stack45)
        %v118797 = vor.u32 %v118796, %v118795 (stack46)
        %v118798 = vxor.u32 %v118797, %v118793 (stack47)
        %v118801 = vadd.s32 %v118798, %v118793 (stack39)
        %v118803 = vshll.u32 %v118798, 15 (stack44)
        %v118804 = vshrl.u32 %v118798, 17 (stack45)
        %v118805 = vor.u32 %v118804, %v118803 (stack46)
        %v118806 = vxor.u32 %v118805, %v118801 (stack47)
        %v118809 = vadd.s32 %v118806, %v118801 (stack39)
        %v118811 = vshll.u32 %v118806, 26 (stack44)
        %v118812 = vshrl.u32 %v118806, 6 (stack45)
        %v118813 = vor.u32 %v118812, %v118811 (stack46)
        %v118814 = vxor.u32 %v118813, %v118809 (stack47)
        %v118817 = vadd.s32 %v118814, %v118809 (stack39)
        %v118821 = vadd.s32 %v118817, %v9 (stack39)
        %v118823 = vshll.u32 %v118814, 6 (stack44)
        %v118824 = vshrl.u32 %v118814, 26 (stack45)
        %v118825 = vor.u32 %v118824, %v118823 (stack46)
        %v118826 = vxor.u32 %v118825, %v118817 (stack47)
        %v118829 = vadd.s32 %v118826, %v8 (stack39)
        %v118833 = vadd.s32 1, %v118829 (stack39)
        %v118837 = vadd.s32 %v118833, %v118821 (stack39)
        %v118839 = vshll.u32 %v118833, 17 (stack44)
        %v118840 = vshrl.u32 %v118833, 15 (stack45)
        %v118841 = vor.u32 %v118840, %v118839 (stack46)
        %v118842 = vxor.u32 %v118841, %v118837 (stack47)
        %v118845 = vadd.s32 %v118842, %v118837 (stack39)
        %v118847 = vshll.u32 %v118842, 29 (stack44)
        %v118848 = vshrl.u32 %v118842, 3 (stack45)
        %v118849 = vor.u32 %v118848, %v118847 (stack46)
        %v118850 = vxor.u32 %v118849, %v118845 (stack47)
        %v118853 = vadd.s32 %v118850, %v118845 (stack39)
        %v118855 = vshll.u32 %v118850, 16 (stack44)
        %v118856 = vshrl.u32 %v118850, 16 (stack45)
        %v118857 = vor.u32 %v118856, %v118855 (stack46)
        %v118858 = vxor.u32 %v118857, %v118853 (stack47)
        %v118861 = vadd.s32 %v118858, %v118853 (stack39)
        %v118865 = vadd.s32 %v118861, %v8 (stack39)
        %v118867 = vshll.u32 %v118858, 24 (stack44)
        %v118868 = vshrl.u32 %v118858, 8 (stack45)
        %v118869 = vor.u32 %v118868, %v118867 (stack46)
        %v118870 = vxor.u32 %v118869, %v118861 (stack47)
        %v118873 = vadd.s32 %v118870, %v10 (stack39)
        %v118877 = vadd.s32 2, %v118873 (stack39)
        %v118881 = vadd.s32 %v118877, %v118865 (stack39)
        %v118883 = vshll.u32 %v118877, 13 (stack44)
        %v118884 = vshrl.u32 %v118877, 19 (stack45)
        %v118885 = vor.u32 %v118884, %v118883 (stack46)
        %v118886 = vxor.u32 %v118885, %v118881 (stack47)
        %v118889 = vadd.s32 %v118886, %v118881 (stack39)
        %v118891 = vshll.u32 %v118886, 15 (stack44)
        %v118892 = vshrl.u32 %v118886, 17 (stack45)
        %v118893 = vor.u32 %v118892, %v118891 (stack46)
        %v118894 = vxor.u32 %v118893, %v118889 (stack47)
        %v118897 = vadd.s32 %v118894, %v118889 (stack39)
        %v118899 = vshll.u32 %v118894, 26 (stack44)
        %v118900 = vshrl.u32 %v118894, 6 (stack45)
        %v118901 = vor.u32 %v118900, %v118899 (stack46)
        %v118902 = vxor.u32 %v118901, %v118897 (stack47)
        %v118905 = vadd.s32 %v118902, %v118897 (stack39)
        %v118909 = vadd.s32 %v118905, %v10 (stack39)
        %v118911 = vshll.u32 %v118902, 6 (stack44)
        %v118912 = vshrl.u32 %v118902, 26 (stack45)
        %v118913 = vor.u32 %v118912, %v118911 (stack46)
        %v118914 = vxor.u32 %v118913, %v118905 (stack47)
        %v118917 = vadd.s32 %v118914, %v9 (stack39)
        %v118921 = vadd.s32 3, %v118917 (stack39)
        %v118925 = vadd.s32 %v118921, %v118909 (stack39)
        %v118927 = vshll.u32 %v118921, 17 (stack44)
        %v118928 = vshrl.u32 %v118921, 15 (stack45)
        %v118929 = vor.u32 %v118928, %v118927 (stack46)
        %v118930 = vxor.u32 %v118929, %v118925 (stack47)
        %v118933 = vadd.s32 %v118930, %v118925 (stack39)
        %v118935 = vshll.u32 %v118930, 29 (stack44)
        %v118936 = vshrl.u32 %v118930, 3 (stack45)
        %v118937 = vor.u32 %v118936, %v118935 (stack46)
        %v118938 = vxor.u32 %v118937, %v118933 (stack47)
        %v118941 = vadd.s32 %v118938, %v118933 (stack39)
        %v118943 = vshll.u32 %v118938, 16 (stack44)
        %v118944 = vshrl.u32 %v118938, 16 (stack45)
        %v118945 = vor.u32 %v118944, %v118943 (stack46)
        %v118946 = vxor.u32 %v118945, %v118941 (stack47)
        %v118949 = vadd.s32 %v118946, %v118941 (stack39)
        %v118953 = vadd.s32 %v118949, %v9 (stack39)
        %v118955 = vshll.u32 %v118946, 24 (stack44)
        %v118956 = vshrl.u32 %v118946, 8 (stack45)
        %v118957 = vor.u32 %v118956, %v118955 (stack46)
        %v118958 = vxor.u32 %v118957, %v118949 (stack47)
        %v118961 = vadd.s32 %v118958, %v8 (stack39)
        %v118965 = vadd.s32 4, %v118961 (stack39)
        %v118969 = vadd.s32 %v118965, %v118953 (stack39)
        %v118971 = vshll.u32 %v118965, 13 (stack44)
        %v118972 = vshrl.u32 %v118965, 19 (stack45)
        %v118973 = vor.u32 %v118972, %v118971 (stack46)
        %v118974 = vxor.u32 %v118973, %v118969 (stack47)
        %v118977 = vadd.s32 %v118974, %v118969 (stack39)
        %v118979 = vshll.u32 %v118974, 15 (stack44)
        %v118980 = vshrl.u32 %v118974, 17 (stack45)
        %v118981 = vor.u32 %v118980, %v118979 (stack46)
        %v118982 = vxor.u32 %v118981, %v118977 (stack47)
        %v118985 = vadd.s32 %v118982, %v118977 (stack39)
        %v118987 = vshll.u32 %v118982, 26 (stack44)
        %v118988 = vshrl.u32 %v118982, 6 (stack45)
        %v118989 = vor.u32 %v118988, %v118987 (stack46)
        %v118990 = vxor.u32 %v118989, %v118985 (stack47)
        %v118993 = vadd.s32 %v118990, %v118985 (stack39)
        %v118997 = vadd.s32 %v118993, %v8 (stack39)
        %v118999 = vshll.u32 %v118990, 6 (stack44)
        %v119000 = vshrl.u32 %v118990, 26 (stack45)
        %v119001 = vor.u32 %v119000, %v118999 (stack46)
        %v119002 = vxor.u32 %v119001, %v118993 (stack47)
        %v119005 = vadd.s32 %v119002, %v10 (stack39)
        %v119009 = vadd.s32 5, %v119005 (stack39)
        %v119011 = vxor.u32 %v119009, %v118997 (stack47)
        %v119012 = vand.u32.u8 255, %v119011 (stack48)
        %v119013 = vand.u32 65535, %v119012 (stack49)
        %v119014 = vshrl.u32 %v119013, 1 (stack50)
        %v119015 = vor.u32 16256, %v119014 (stack46)
        %v119016 = vand.u32.u16 65535, %v119015 (stack51)
        %v120380 = vadd.low.f32.bf16 -1.0, %v119016 (stack52)
        %v119025 = vmul.f32 2.0, %v120380 (stack53)
        %v119029 = vadd.f32 -0.99609375, %v119025 (stack52)
        %v119033 = vmax.f32 %v119029, -0.99609375 (stack54)
        %v119035 = vand.u32 2147483647, %v119033 (stack55)
        %vm119038 = vcmp.eq.f32.partialorder %v119035, 1.0 (stack56)
        %v119043 = vmul.f32 inf, %v119033 (stack53)
        %v119045 = vxor.u32 2147483648, %v119033 (stack57)
        %v119048 = vmul.f32 %v119045, %v119033 (stack53)
        %v119050 = vadd.f32 1.0, %v119048 (stack58)
        %v119051 = vlog2.pop %v119050 (stack59)
        %v119052 = vmul.f32 0.6931472, %v119051 (stack60)
        %v119053 = vmul.f32 -0.5, %v119048 (stack61)
        %v119054 = vadd.f32 1.0, %v119053 (stack62)
        %v119055 = vmul.f32 %v119054, %v119048 (stack63)
        %v119056 = vand.u32 2147483647, %v119048 (stack64)
        %vm119057 = vcmp.lt.f32.partialorder %v119056, 0.0004427343 (stack65)
        %v119058 = vsel /*vm=*/%vm119057, /*on_true_vy=*/%v119055, /*on_false_vx=*/%v119052 (stack66)
        %v119059 = vxor.u32 2147483648, %v119058 (stack57)
        %vm119062 = vcmp.lt.f32.partialorder %v119059, 5.0 (stack56)
        %v119067 = vsel /*vm=*/%vm119062, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v119071 = vsel /*vm=*/%vm119062, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v119075 = vsel /*vm=*/%vm119062, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v119079 = vsel /*vm=*/%vm119062, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v119083 = vsel /*vm=*/%vm119062, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v119087 = vsel /*vm=*/%vm119062, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v119091 = vsel /*vm=*/%vm119062, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v119095 = vsel /*vm=*/%vm119062, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v119099 = vsel /*vm=*/%vm119062, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v119103 = vadd.f32 -2.5, %v119059 (stack52)
        %v119105 = vrsqrt.pop %v119059 (stack67)
        %v119106 = vmul.f32 %v119105, %v119059 (stack68)
        %vm119107 = vcmp.eq.f32.partialorder %v119059, inf (stack69)
        %v119108 = vsel /*vm=*/%vm119107, /*on_true_vy=*/%v119059, /*on_false_vx=*/%v119106 (stack70)
        %vm119109 = vcmp.eq.f32.partialorder %v119059, 0.0 (stack71)
        %v119110 = vand.u32 2147483648, %v119059 (stack72)
        %v119111 = vsel /*vm=*/%vm119109, /*on_true_vy=*/%v119110, /*on_false_vx=*/%v119108 (stack73)
        %v119114 = vadd.f32 -3.0, %v119111 (stack52)
        %v119118 = vsel /*vm=*/%vm119062, /*on_true_vy=*/%v119103, /*on_false_vx=*/%v119114 (stack43)
        %v119122 = vmul.f32 %v119118, %v119099 (stack53)
        %v119126 = vadd.f32 %v119122, %v119095 (stack52)
        %v119130 = vmul.f32 %v119126, %v119118 (stack53)
        %v119134 = vadd.f32 %v119130, %v119091 (stack52)
        %v119138 = vmul.f32 %v119134, %v119118 (stack53)
        %v119142 = vadd.f32 %v119138, %v119087 (stack52)
        %v119146 = vmul.f32 %v119142, %v119118 (stack53)
        %v119150 = vadd.f32 %v119146, %v119083 (stack52)
        %v119154 = vmul.f32 %v119150, %v119118 (stack53)
        %v119158 = vadd.f32 %v119154, %v119079 (stack52)
        %v119162 = vmul.f32 %v119158, %v119118 (stack53)
        %v119166 = vadd.f32 %v119162, %v119075 (stack52)
        %v119170 = vmul.f32 %v119166, %v119118 (stack53)
        %v119174 = vadd.f32 %v119170, %v119071 (stack52)
        %v119178 = vmul.f32 %v119174, %v119118 (stack53)
        %v119182 = vadd.f32 %v119178, %v119067 (stack52)
        %v119186 = vmul.f32 %v119182, %v119033 (stack53)
        %v119190 = vsel /*vm=*/%vm119038, /*on_true_vy=*/%v119043, /*on_false_vx=*/%v119186 (stack43)
        %v119194 = vmul.f32 1.4140625, %v119190 (stack53)
        %v119197 = vpack.c.bf16 0.0, %v119194 (stack74)
        %120381 = vst [vmem:[%s280 + $0x37c] sm:$0xf] /*vst_source=*/%v119197 (stack75)
        %v119201 = vadd.s32 %v115971, %v3816 (stack39)
        %v119211 = vadd.s32 %v119201, %v415 (stack39)
        %vm119215 = vcmp.lt.u32.totalorder %v119211, %v119201 (stack42)
        %vm119220 = vcmp.lt.u32.totalorder %v119201, %v3816 (stack42)
        %v119225 = vadd.s32 %v115954, %v3803 (stack39)
        %v119229 = vadd.s32 1, %v119225 (stack39)
        %v119233 = vsel /*vm=*/%vm119220, /*on_true_vy=*/%v119229, /*on_false_vx=*/%v119225 (stack43)
        %v119237 = vadd.s32 1, %v119233 (stack39)
        %v119241 = vsel /*vm=*/%vm119215, /*on_true_vy=*/%v119237, /*on_false_vx=*/%v119233 (stack43)
        %v119246 = vadd.s32 %v119241, %v10 (stack39)
        %v119250 = vadd.s32 %v119211, %v9 (stack39)
        %v119254 = vadd.s32 %v119250, %v119246 (stack39)
        %v119256 = vshll.u32 %v119250, 13 (stack44)
        %v119257 = vshrl.u32 %v119250, 19 (stack45)
        %v119258 = vor.u32 %v119257, %v119256 (stack46)
        %v119259 = vxor.u32 %v119258, %v119254 (stack47)
        %v119262 = vadd.s32 %v119259, %v119254 (stack39)
        %v119264 = vshll.u32 %v119259, 15 (stack44)
        %v119265 = vshrl.u32 %v119259, 17 (stack45)
        %v119266 = vor.u32 %v119265, %v119264 (stack46)
        %v119267 = vxor.u32 %v119266, %v119262 (stack47)
        %v119270 = vadd.s32 %v119267, %v119262 (stack39)
        %v119272 = vshll.u32 %v119267, 26 (stack44)
        %v119273 = vshrl.u32 %v119267, 6 (stack45)
        %v119274 = vor.u32 %v119273, %v119272 (stack46)
        %v119275 = vxor.u32 %v119274, %v119270 (stack47)
        %v119278 = vadd.s32 %v119275, %v119270 (stack39)
        %v119282 = vadd.s32 %v119278, %v9 (stack39)
        %v119284 = vshll.u32 %v119275, 6 (stack44)
        %v119285 = vshrl.u32 %v119275, 26 (stack45)
        %v119286 = vor.u32 %v119285, %v119284 (stack46)
        %v119287 = vxor.u32 %v119286, %v119278 (stack47)
        %v119290 = vadd.s32 %v119287, %v8 (stack39)
        %v119294 = vadd.s32 1, %v119290 (stack39)
        %v119298 = vadd.s32 %v119294, %v119282 (stack39)
        %v119300 = vshll.u32 %v119294, 17 (stack44)
        %v119301 = vshrl.u32 %v119294, 15 (stack45)
        %v119302 = vor.u32 %v119301, %v119300 (stack46)
        %v119303 = vxor.u32 %v119302, %v119298 (stack47)
        %v119306 = vadd.s32 %v119303, %v119298 (stack39)
        %v119308 = vshll.u32 %v119303, 29 (stack44)
        %v119309 = vshrl.u32 %v119303, 3 (stack45)
        %v119310 = vor.u32 %v119309, %v119308 (stack46)
        %v119311 = vxor.u32 %v119310, %v119306 (stack47)
        %v119314 = vadd.s32 %v119311, %v119306 (stack39)
        %v119316 = vshll.u32 %v119311, 16 (stack44)
        %v119317 = vshrl.u32 %v119311, 16 (stack45)
        %v119318 = vor.u32 %v119317, %v119316 (stack46)
        %v119319 = vxor.u32 %v119318, %v119314 (stack47)
        %v119322 = vadd.s32 %v119319, %v119314 (stack39)
        %v119326 = vadd.s32 %v119322, %v8 (stack39)
        %v119328 = vshll.u32 %v119319, 24 (stack44)
        %v119329 = vshrl.u32 %v119319, 8 (stack45)
        %v119330 = vor.u32 %v119329, %v119328 (stack46)
        %v119331 = vxor.u32 %v119330, %v119322 (stack47)
        %v119334 = vadd.s32 %v119331, %v10 (stack39)
        %v119338 = vadd.s32 2, %v119334 (stack39)
        %v119342 = vadd.s32 %v119338, %v119326 (stack39)
        %v119344 = vshll.u32 %v119338, 13 (stack44)
        %v119345 = vshrl.u32 %v119338, 19 (stack45)
        %v119346 = vor.u32 %v119345, %v119344 (stack46)
        %v119347 = vxor.u32 %v119346, %v119342 (stack47)
        %v119350 = vadd.s32 %v119347, %v119342 (stack39)
        %v119352 = vshll.u32 %v119347, 15 (stack44)
        %v119353 = vshrl.u32 %v119347, 17 (stack45)
        %v119354 = vor.u32 %v119353, %v119352 (stack46)
        %v119355 = vxor.u32 %v119354, %v119350 (stack47)
        %v119358 = vadd.s32 %v119355, %v119350 (stack39)
        %v119360 = vshll.u32 %v119355, 26 (stack44)
        %v119361 = vshrl.u32 %v119355, 6 (stack45)
        %v119362 = vor.u32 %v119361, %v119360 (stack46)
        %v119363 = vxor.u32 %v119362, %v119358 (stack47)
        %v119366 = vadd.s32 %v119363, %v119358 (stack39)
        %v119370 = vadd.s32 %v119366, %v10 (stack39)
        %v119372 = vshll.u32 %v119363, 6 (stack44)
        %v119373 = vshrl.u32 %v119363, 26 (stack45)
        %v119374 = vor.u32 %v119373, %v119372 (stack46)
        %v119375 = vxor.u32 %v119374, %v119366 (stack47)
        %v119378 = vadd.s32 %v119375, %v9 (stack39)
        %v119382 = vadd.s32 3, %v119378 (stack39)
        %v119386 = vadd.s32 %v119382, %v119370 (stack39)
        %v119388 = vshll.u32 %v119382, 17 (stack44)
        %v119389 = vshrl.u32 %v119382, 15 (stack45)
        %v119390 = vor.u32 %v119389, %v119388 (stack46)
        %v119391 = vxor.u32 %v119390, %v119386 (stack47)
        %v119394 = vadd.s32 %v119391, %v119386 (stack39)
        %v119396 = vshll.u32 %v119391, 29 (stack44)
        %v119397 = vshrl.u32 %v119391, 3 (stack45)
        %v119398 = vor.u32 %v119397, %v119396 (stack46)
        %v119399 = vxor.u32 %v119398, %v119394 (stack47)
        %v119402 = vadd.s32 %v119399, %v119394 (stack39)
        %v119404 = vshll.u32 %v119399, 16 (stack44)
        %v119405 = vshrl.u32 %v119399, 16 (stack45)
        %v119406 = vor.u32 %v119405, %v119404 (stack46)
        %v119407 = vxor.u32 %v119406, %v119402 (stack47)
        %v119410 = vadd.s32 %v119407, %v119402 (stack39)
        %v119414 = vadd.s32 %v119410, %v9 (stack39)
        %v119416 = vshll.u32 %v119407, 24 (stack44)
        %v119417 = vshrl.u32 %v119407, 8 (stack45)
        %v119418 = vor.u32 %v119417, %v119416 (stack46)
        %v119419 = vxor.u32 %v119418, %v119410 (stack47)
        %v119422 = vadd.s32 %v119419, %v8 (stack39)
        %v119426 = vadd.s32 4, %v119422 (stack39)
        %v119430 = vadd.s32 %v119426, %v119414 (stack39)
        %v119432 = vshll.u32 %v119426, 13 (stack44)
        %v119433 = vshrl.u32 %v119426, 19 (stack45)
        %v119434 = vor.u32 %v119433, %v119432 (stack46)
        %v119435 = vxor.u32 %v119434, %v119430 (stack47)
        %v119438 = vadd.s32 %v119435, %v119430 (stack39)
        %v119440 = vshll.u32 %v119435, 15 (stack44)
        %v119441 = vshrl.u32 %v119435, 17 (stack45)
        %v119442 = vor.u32 %v119441, %v119440 (stack46)
        %v119443 = vxor.u32 %v119442, %v119438 (stack47)
        %v119446 = vadd.s32 %v119443, %v119438 (stack39)
        %v119448 = vshll.u32 %v119443, 26 (stack44)
        %v119449 = vshrl.u32 %v119443, 6 (stack45)
        %v119450 = vor.u32 %v119449, %v119448 (stack46)
        %v119451 = vxor.u32 %v119450, %v119446 (stack47)
        %v119454 = vadd.s32 %v119451, %v119446 (stack39)
        %v119458 = vadd.s32 %v119454, %v8 (stack39)
        %v119460 = vshll.u32 %v119451, 6 (stack44)
        %v119461 = vshrl.u32 %v119451, 26 (stack45)
        %v119462 = vor.u32 %v119461, %v119460 (stack46)
        %v119463 = vxor.u32 %v119462, %v119454 (stack47)
        %v119466 = vadd.s32 %v119463, %v10 (stack39)
        %v119470 = vadd.s32 5, %v119466 (stack39)
        %v119472 = vxor.u32 %v119470, %v119458 (stack47)
        %v119473 = vand.u32.u8 255, %v119472 (stack48)
        %v119474 = vand.u32 65535, %v119473 (stack49)
        %v119475 = vshrl.u32 %v119474, 1 (stack50)
        %v119476 = vor.u32 16256, %v119475 (stack46)
        %v119477 = vand.u32.u16 65535, %v119476 (stack51)
        %v120382 = vadd.low.f32.bf16 -1.0, %v119477 (stack52)
        %v119486 = vmul.f32 2.0, %v120382 (stack53)
        %v119490 = vadd.f32 -0.99609375, %v119486 (stack52)
        %v119494 = vmax.f32 %v119490, -0.99609375 (stack54)
        %v119496 = vand.u32 2147483647, %v119494 (stack55)
        %vm119499 = vcmp.eq.f32.partialorder %v119496, 1.0 (stack56)
        %v119504 = vmul.f32 inf, %v119494 (stack53)
        %v119506 = vxor.u32 2147483648, %v119494 (stack57)
        %v119509 = vmul.f32 %v119506, %v119494 (stack53)
        %v119511 = vadd.f32 1.0, %v119509 (stack58)
        %v119512 = vlog2.pop %v119511 (stack59)
        %v119513 = vmul.f32 0.6931472, %v119512 (stack60)
        %v119514 = vmul.f32 -0.5, %v119509 (stack61)
        %v119515 = vadd.f32 1.0, %v119514 (stack62)
        %v119516 = vmul.f32 %v119515, %v119509 (stack63)
        %v119517 = vand.u32 2147483647, %v119509 (stack64)
        %vm119518 = vcmp.lt.f32.partialorder %v119517, 0.0004427343 (stack65)
        %v119519 = vsel /*vm=*/%vm119518, /*on_true_vy=*/%v119516, /*on_false_vx=*/%v119513 (stack66)
        %v119520 = vxor.u32 2147483648, %v119519 (stack57)
        %vm119523 = vcmp.lt.f32.partialorder %v119520, 5.0 (stack56)
        %v119528 = vsel /*vm=*/%vm119523, /*on_true_vy=*/1.5014094, /*on_false_vx=*/2.8329768 (stack43)
        %v119532 = vsel /*vm=*/%vm119523, /*on_true_vy=*/0.24664073, /*on_false_vx=*/1.001674 (stack43)
        %v119536 = vsel /*vm=*/%vm119523, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/0.0094388705 (stack43)
        %v119540 = vsel /*vm=*/%vm119523, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/-0.0076224613 (stack43)
        %v119544 = vsel /*vm=*/%vm119523, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/0.0057395077 (stack43)
        %v119548 = vsel /*vm=*/%vm119523, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/-0.0036734284 (stack43)
        %v119552 = vsel /*vm=*/%vm119523, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/0.0013493432 (stack43)
        %v119556 = vsel /*vm=*/%vm119523, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/0.00010095056 (stack43)
        %v119560 = vsel /*vm=*/%vm119523, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/-0.00020021426 (stack43)
        %v119564 = vadd.f32 -2.5, %v119520 (stack52)
        %v119566 = vrsqrt.pop %v119520 (stack67)
        %v119567 = vmul.f32 %v119566, %v119520 (stack68)
        %vm119568 = vcmp.eq.f32.partialorder %v119520, inf (stack69)
        %v119569 = vsel /*vm=*/%vm119568, /*on_true_vy=*/%v119520, /*on_false_vx=*/%v119567 (stack70)
        %vm119570 = vcmp.eq.f32.partialorder %v119520, 0.0 (stack71)
        %v119571 = vand.u32 2147483648, %v119520 (stack72)
        %v119572 = vsel /*vm=*/%vm119570, /*on_true_vy=*/%v119571, /*on_false_vx=*/%v119569 (stack73)
        %v119575 = vadd.f32 -3.0, %v119572 (stack52)
        %v119579 = vsel /*vm=*/%vm119523, /*on_true_vy=*/%v119564, /*on_false_vx=*/%v119575 (stack43)
        %v119583 = vmul.f32 %v119579, %v119560 (stack53)
        %v119587 = vadd.f32 %v119583, %v119556 (stack52)
        %v119591 = vmul.f32 %v119587, %v119579 (stack53)
        %v119595 = vadd.f32 %v119591, %v119552 (stack52)
        %v119599 = vmul.f32 %v119595, %v119579 (stack53)
        %v119603 = vadd.f32 %v119599, %v119548 (stack52)
        %v119607 = vmul.f32 %v119603, %v119579 (stack53)
        %v119611 = vadd.f32 %v119607, %v119544 (stack52)
        %v119615 = vmul.f32 %v119611, %v119579 (stack53)
        %v119619 = vadd.f32 %v119615, %v119540 (stack52)
        %v119623 = vmul.f32 %v119619, %v119579 (stack53)
        %v119627 = vadd.f32 %v119623, %v119536 (stack52)
        %v119631 = vmul.f32 %v119627, %v119579 (stack53)
        %v119635 = vadd.f32 %v119631, %v119532 (stack52)
        %v119639 = vmul.f32 %v119635, %v119579 (stack53)
        %v119643 = vadd.f32 %v119639, %v119528 (stack52)
        %v119647 = vmul.f32 %v119643, %v119494 (stack53)
        %v119651 = vsel /*vm=*/%vm119499, /*on_true_vy=*/%v119504, /*on_false_vx=*/%v119647 (stack43)
        %v119655 = vmul.f32 1.4140625, %v119651 (stack53)
        %v119658 = vpack.c.bf16 0.0, %v119655 (stack74)
        %120383 = vst [vmem:[%s280 + $0x3fc] sm:$0xf] /*vst_source=*/%v119658 (stack75)
        %s119661 = scalar_lea.sflag [#allocation2], %s278 (stack77)
        %s120392 = sshll.u32 %s120407, 11 (stack78)
        %s119674 = scalar_lea.hbm %s7, %s120392 (stack79)
        %s119675 = sshll.u32 %s280, 4 (stack80)
        %s119676 = int_to_ptr.vmem [resolvable:$true] %s119675 (stack81)
        %119681 = dma.vmem_to_hbm [thread:$0]  /*vmem=*/%s119676, /*size_in_granules=*/16384, /*hbm=*/%s119674, /*dst_syncflagno=*/%s119661, /*src_stride=*/2048, /*dst_stride=*/16384, /*steps_per_stride=*/128 /* 
base_bounds: (8, 256, 1)
dynamic_base_bounds: (8, 256, 1)
window_bounds: (8, 32, 1)
iteration_bounds: (1, 8, 1)
strides: (8, 32, 1)
pad_low: (0, 0, 0)
pad_high: (0, 0, 0)
element_size_in_bytes: 2048 */ (stack82)
      $region36: #{fusion.21} parent=50 // pred_fallthru
        _
      %p120388 = scmp.lt.s32.totalorder %s120399, 2 (stack83)
      %p120395 = scmp.ge.s32.totalorder %s120399, 2 (stack84)
      %s120389 = sadd.s32 4294967294, %s120399 (stack85)
      %s119687 = sand.u32 1, %s120389 /* smod.u32 w/div 2 */ (stack86)
      %s119688 = scalar_lea.sflag [#allocation2], %s119687 (stack87)
      %120394 = dma.done (%p120395), %s119688, 16384 /* pipeline-emitter-dma-wait */ (stack88)
    $region6: #{fusion.21} parent=1 // loop_footer
      %s19 = sadd.s32 1, %s120399 (stack89)
    $region7: #{fusion.21} parent=1 // loop_footer_branch
      _
    $region3: #{fusion.21} parent=1 // loop_header
      %p16 = scmp.ge.s32.totalorder %s19, 10 /* loop exit test */ (stack90)
      %s120397 = smov %s19 /* copy for cssa */ (stack91)
      %s120401 = smov %s37 /* copy for cssa */ (stack91)
      %s120405 = smov %s120403 /* copy for cssa :: phi copy :: iteration index, stage = 0 iter bound = 1 */ (stack91)
    $region4: #{fusion.21} parent=1 // loop_header_branch
      %18 = sbr.rel (!%p16) target = $region50 (stack92)
    $region49: #{fusion.21} parent=1 // loop_exit
      _
    %119693 = vsyncpa [#allocation2], 1 (stack93)
    %119695 = vsyncpa [#allocation2 + $0x1], 1 (stack93)

stack0
    @     0x787f0f52271e  (unknown)
    @     0x787f0f5226ce  (unknown)
    @     0x787f0f526cec  (unknown)
    @     0x787f0f526fe5  (unknown)
    @     0x787f0b748189  (unknown)
    @     0x787f0b74581b  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack1
    @     0x787f0f4f5115  (unknown)
    @     0x787f0f557ab8  (unknown)
    @     0x787f09c9a1eb  (unknown)
    @     0x787f09c972c3  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack2
    @     0x787f0f4f5115  (unknown)
    @     0x787f0f557ab8  (unknown)
    @     0x787f09c9a1eb  (unknown)
    @     0x787f09c9733c  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack3
    @     0x787f0f4df370  (unknown)
    @     0x787f0f52b3aa  (unknown)
    @     0x787f0f315bce  (unknown)
    @     0x787f0b72ea4a  (unknown)
    @     0x787f0b74d53c  (unknown)
    @     0x787f0b74b642  (unknown)
    @     0x787f0b75005f  (unknown)
    @     0x787f0b74af97  (unknown)
    @     0x787f0b74e1fb  (unknown)
    @     0x787f0b74d898  (unknown)
    @     0x787f0b74511f  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack4
    @     0x787f0f52271e  (unknown)
    @     0x787f0f5226ce  (unknown)
    @     0x787f0f526cec  (unknown)
    @     0x787f0f32b5e0  (unknown)
    @     0x787f0f32485a  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack5
    @     0x787f0f52271e  (unknown)
    @     0x787f0f5226ce  (unknown)
    @     0x787f0f526cec  (unknown)
    @     0x787f0f527060  (unknown)
    @     0x787f0f32edb3  (unknown)
    @     0x787f0f32b263  (unknown)
    @     0x787f0f32485a  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack6
    @     0x787f0f52271e  (unknown)
    @     0x787f0f5226ce  (unknown)
    @     0x787f0f526cec  (unknown)
    @     0x787f0f527060  (unknown)
    @     0x787f0f32edef  (unknown)
    @     0x787f0f32b263  (unknown)
    @     0x787f0f32485a  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack7
    @     0x787f0f4ea266  (unknown)
    @     0x787f0f55872d  (unknown)
    @     0x787f0f324e23  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack8
    @     0x787f0f4debc1  (unknown)
    @     0x787f0f565854  (unknown)
    @     0x787f09bf1d10  (unknown)
    @     0x787f09bf18b2  (unknown)
    @     0x787f09bf20ad  (unknown)
    @     0x787f09997f73  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack9
    @     0x787f09bf18fe  (unknown)
    @     0x787f09bf20ad  (unknown)
    @     0x787f09997f73  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack10
    @     0x787f0f4debc1  (unknown)
    @     0x787f09bf19dc  (unknown)
    @     0x787f09bf20ad  (unknown)
    @     0x787f09997f73  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack11
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53d2ca  (unknown)
    @     0x787f0f529008  (unknown)
    @     0x787f0f4828c4  (unknown)
    @     0x787f0f3229bc  (unknown)
    @     0x787f0f327519  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack12
    @     0x787f0f4e363c  (unknown)
    @     0x787f0f565a16  (unknown)
    @     0x787f0f52a459  (unknown)
    @     0x787f0f4828ec  (unknown)
    @     0x787f0f3229bc  (unknown)
    @     0x787f0f327519  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack13
    @     0x787f0f4e38b7  (unknown)
    @     0x787f0f532edc  (unknown)
    @     0x787f0f48290a  (unknown)
    @     0x787f0f3229bc  (unknown)
    @     0x787f0f327519  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack14
    @     0x787f0f4e363c  (unknown)
    @     0x787f0f565a16  (unknown)
    @     0x787f0f565cf9  (unknown)
    @     0x787f0f32e779  (unknown)
    @     0x787f0f327af8  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack15
    @     0x787f0f4e363c  (unknown)
    @     0x787f0f565a16  (unknown)
    @     0x787f0f52f4f9  (unknown)
    @     0x787f0f32e7f7  (unknown)
    @     0x787f0f327af8  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack16
    @     0x787f0f4de766  (unknown)
    @     0x787f0f52eb6d  (unknown)
    @     0x787f0f32e80b  (unknown)
    @     0x787f0f327af8  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack17
    @     0x787f0f4f426f  (unknown)
    @     0x787f0f57a997  (unknown)
    @     0x787f0f519b3c  (unknown)
    @     0x787f0f555576  (unknown)
    @     0x787f0f32e79f  (unknown)
    @     0x787f0f327af8  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack18
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53da6a  (unknown)
    @     0x787f0f5266c8  (unknown)
    @     0x787f0f327b27  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack19
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f530505  (unknown)
    @     0x787f0f32f97e  (unknown)
    @     0x787f0f32cdf1  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack20
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53dd92  (unknown)
    @     0x787f0f545f5c  (unknown)
    @     0x787f0f32fce7  (unknown)
    @     0x787f0f32cdf1  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack21
    @     0x787f0f4df5ff  (unknown)
    @     0x787f0f545c3a  (unknown)
    @     0x787f0f32fce7  (unknown)
    @     0x787f0f32cdf1  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack22
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53dd92  (unknown)
    @     0x787f0b77da82  (unknown)
    @     0x787f0b757234  (unknown)
    @     0x787f0b76e38a  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack23
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f56964f  (unknown)
    @     0x787f0b77cd4f  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack24
    @     0x787f0f4e363c  (unknown)
    @     0x787f0f565a16  (unknown)
    @     0x787f0f567291  (unknown)
    @     0x787f0b77cf32  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack25
    @     0x787f0f4e38b7  (unknown)
    @     0x787f0f532edc  (unknown)
    @     0x787f0f5672bd  (unknown)
    @     0x787f0b77cf32  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack26
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f530505  (unknown)
    @     0x787f0b77cf49  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack27
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f56964f  (unknown)
    @     0x787f0f527cd6  (unknown)
    @     0x787f0b77d02b  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack28
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f530505  (unknown)
    @     0x787f0f527ce7  (unknown)
    @     0x787f0b77d02b  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack29
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53dd92  (unknown)
    @     0x787f0f545f5c  (unknown)
    @     0x787f0b77d0d6  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack30
    @     0x787f0f4df5ff  (unknown)
    @     0x787f0f545c3a  (unknown)
    @     0x787f0b77d0d6  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack31
    @     0x787f0f4df5ff  (unknown)
    @     0x787f0f545c3a  (unknown)
    @     0x787f0b77d1f8  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack32
    @     0x787f0f4ebbdf  (unknown)
    @     0x787f0f549909  (unknown)
    @     0x787f0b77d205  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack33
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53a225  (unknown)
    @     0x787f0f53a847  (unknown)
    @     0x787f0c4bf709  (unknown)
    @     0x787f0b77d329  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack34
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53a2f1  (unknown)
    @     0x787f0f53a847  (unknown)
    @     0x787f0c4bf709  (unknown)
    @     0x787f0b77d329  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack35
    @     0x787f0f4e307c  (unknown)
    @     0x787f0f53a85f  (unknown)
    @     0x787f0c4bf709  (unknown)
    @     0x787f0b77d329  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack36
    @     0x787f0f4e2e33  (unknown)
    @     0x787f0f539d88  (unknown)
    @     0x787f0c4bf716  (unknown)
    @     0x787f0b77d329  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack37
    @     0x787f0f4e307c  (unknown)
    @     0x787f0f53a85f  (unknown)
    @     0x787f0f312f7f  (unknown)
    @     0x787f0b77d284  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack38
    @     0x787f0f4e2e33  (unknown)
    @     0x787f0f539d88  (unknown)
    @     0x787f0f312f8c  (unknown)
    @     0x787f0b77d284  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack39
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f5691eb  (unknown)
    @     0x787f0c15ce44  (unknown)
    @     0x787f0f557bb7  (unknown)
    @     0x787f0c158ac3  (unknown)
    @     0x787f1136d73e  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack40
    @     0x787f0f4de147  (unknown)
    @     0x787f0f52b798  (unknown)
    @     0x787f0f30a807  (unknown)
    @     0x787f0b7637de  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack41
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f52b807  (unknown)
    @     0x787f0f30a807  (unknown)
    @     0x787f0b7637de  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack42
    @     0x787f0f4e8df6  (unknown)
    @     0x787f0f568b6e  (unknown)
    @     0x787f0f56827a  (unknown)
    @     0x787f0c15bf00  (unknown)
    @     0x787f0f557bb7  (unknown)
    @     0x787f0c158ac3  (unknown)
    @     0x787f1136d73e  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack43
    @     0x787f0f4e7674  (unknown)
    @     0x787f0f52e22d  (unknown)
    @     0x787f0c15bb18  (unknown)
    @     0x787f0f557bb7  (unknown)
    @     0x787f0c158ac3  (unknown)
    @     0x787f1136d73e  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack44
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f52cb80  (unknown)
    @     0x787f0c157250  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack45
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f52c03e  (unknown)
    @     0x787f0c15759b  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack46
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f52d8e9  (unknown)
    @     0x787f0c156f76  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack47
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f565769  (unknown)
    @     0x787f0c157036  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack48
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f52b94b  (unknown)
    @     0x787f0c158583  (unknown)
    @     0x787f0c155364  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack49
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f52b94b  (unknown)
    @     0x787f0c157622  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack50
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f52c03e  (unknown)
    @     0x787f0c157640  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack51
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f52b94b  (unknown)
    @     0x787f0c158583  (unknown)
    @     0x787f0c155a1d  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack52
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f564248  (unknown)
    @     0x787f0c15cdb6  (unknown)
    @     0x787f0f557bb7  (unknown)
    @     0x787f0c158ac3  (unknown)
    @     0x787f1136d73e  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack53
    @     0x787f0f4eb946  (unknown)
    @     0x787f0f534643  (unknown)
    @     0x787f0c15caf7  (unknown)
    @     0x787f0f557bb7  (unknown)
    @     0x787f0c158ac3  (unknown)
    @     0x787f1136d73e  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack54
    @     0x787f0f4e7a26  (unknown)
    @     0x787f0f565643  (unknown)
    @     0x787f0c15c675  (unknown)
    @     0x787f0f557bb7  (unknown)
    @     0x787f0c158ac3  (unknown)
    @     0x787f1136d73e  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack55
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f531cdf  (unknown)
    @     0x787f0c152d8e  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack56
    @     0x787f0f4e8df6  (unknown)
    @     0x787f0f568b6e  (unknown)
    @     0x787f0f56825c  (unknown)
    @     0x787f0c15bf00  (unknown)
    @     0x787f0f557bb7  (unknown)
    @     0x787f0c158ac3  (unknown)
    @     0x787f1136d73e  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack57
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f534cdd  (unknown)
    @     0x787f0c1523d0  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack58
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f563f30  (unknown)
    @     0x787f0f541ddc  (unknown)
    @     0x787f0c153eb3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack59
    @     0x787f0f4e46f5  (unknown)
    @     0x787f0f563375  (unknown)
    @     0x787f0f563f59  (unknown)
    @     0x787f0f541ddc  (unknown)
    @     0x787f0c153eb3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack60
    @     0x787f0f4eb946  (unknown)
    @     0x787f0f564143  (unknown)
    @     0x787f0f541ddc  (unknown)
    @     0x787f0c153eb3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack61
    @     0x787f0f4eb946  (unknown)
    @     0x787f0f563fcd  (unknown)
    @     0x787f0f541ddc  (unknown)
    @     0x787f0c153eb3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack62
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f56400b  (unknown)
    @     0x787f0f541ddc  (unknown)
    @     0x787f0c153eb3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack63
    @     0x787f0f4eb946  (unknown)
    @     0x787f0f564044  (unknown)
    @     0x787f0f541ddc  (unknown)
    @     0x787f0c153eb3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack64
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f56409b  (unknown)
    @     0x787f0f541ddc  (unknown)
    @     0x787f0c153eb3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack65
    @     0x787f0f4e8df6  (unknown)
    @     0x787f0f568b6e  (unknown)
    @     0x787f0f5640df  (unknown)
    @     0x787f0f541ddc  (unknown)
    @     0x787f0c153eb3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack66
    @     0x787f0f4e7674  (unknown)
    @     0x787f0f564112  (unknown)
    @     0x787f0f541ddc  (unknown)
    @     0x787f0c153eb3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack67
    @     0x787f0f4e46f5  (unknown)
    @     0x787f0f5645c5  (unknown)
    @     0x787f0f5432eb  (unknown)
    @     0x787f0c1565f3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack68
    @     0x787f0f4eb946  (unknown)
    @     0x787f0f54336b  (unknown)
    @     0x787f0c1565f3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack69
    @     0x787f0f4e8df6  (unknown)
    @     0x787f0f568b6e  (unknown)
    @     0x787f0f5433ac  (unknown)
    @     0x787f0c1565f3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack70
    @     0x787f0f4e7674  (unknown)
    @     0x787f0f5433de  (unknown)
    @     0x787f0c1565f3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack71
    @     0x787f0f4e8df6  (unknown)
    @     0x787f0f568b6e  (unknown)
    @     0x787f0f54341b  (unknown)
    @     0x787f0c1565f3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack72
    @     0x787f0f4e0085  (unknown)
    @     0x787f0f531bf5  (unknown)
    @     0x787f0f54343d  (unknown)
    @     0x787f0c1565f3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack73
    @     0x787f0f4e7674  (unknown)
    @     0x787f0f54346c  (unknown)
    @     0x787f0c1565f3  (unknown)
    @     0x787f1136d715  (unknown)
    @     0x787f0b754004  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack74
    @     0x787f0f4e0a1d  (unknown)
    @     0x787f0f570e15  (unknown)
    @     0x787f0f57137e  (unknown)
    @     0x787f0b785933  (unknown)
    @     0x787f0b784874  (unknown)
    @     0x787f0b784256  (unknown)
    @     0x787f0b754fe2  (unknown)
    @     0x787f0b76ea43  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack75
    @     0x787f0f4edfa8  (unknown)
    @     0x787f0f4edc1b  (unknown)
    @     0x787f0f577bfc  (unknown)
    @     0x787f0b783feb  (unknown)
    @     0x787f0b78594f  (unknown)
    @     0x787f0b784874  (unknown)
    @     0x787f0b784256  (unknown)
    @     0x787f0b754fe2  (unknown)
    @     0x787f0b76ea43  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack76
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53d2ca  (unknown)
    @     0x787f0f529008  (unknown)
    @     0x787f0b77cd3d  (unknown)
    @     0x787f0b75282d  (unknown)
    @     0x787f0b753d2d  (unknown)
    @     0x787f0b76e88d  (unknown)
    @     0x787f0f333a09  (unknown)
    @     0x787f0f330612  (unknown)
    @     0x787f0f32d5bb  (unknown)
    @     0x787f0f327eff  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack77
    @     0x787f0f4df5ff  (unknown)
    @     0x787f0f545c3a  (unknown)
    @     0x787f0f32f95e  (unknown)
    @     0x787f0f32db2b  (unknown)
    @     0x787f0f32810b  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack78
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53dd92  (unknown)
    @     0x787f0f545f5c  (unknown)
    @     0x787f0f4725c5  (unknown)
    @     0x787f0f472c0b  (unknown)
    @     0x787f0f473b7f  (unknown)
    @     0x787f0f334dc9  (unknown)
    @     0x787f0f32e178  (unknown)
    @     0x787f0f32810b  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack79
    @     0x787f0f4df5ff  (unknown)
    @     0x787f0f545c3a  (unknown)
    @     0x787f0f4725c5  (unknown)
    @     0x787f0f472c0b  (unknown)
    @     0x787f0f473b7f  (unknown)
    @     0x787f0f334dc9  (unknown)
    @     0x787f0f32e178  (unknown)
    @     0x787f0f32810b  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack80
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f555df0  (unknown)
    @     0x787f0f54cbc7  (unknown)
    @     0x787f0f54f8ab  (unknown)
    @     0x787f0f479fa4  (unknown)
    @     0x787f0f47b136  (unknown)
    @     0x787f0f4737ce  (unknown)
    @     0x787f0f473b7f  (unknown)
    @     0x787f0f334dc9  (unknown)
    @     0x787f0f32e178  (unknown)
    @     0x787f0f32810b  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack81
    @     0x787f0f4df9d1  (unknown)
    @     0x787f0f52763d  (unknown)
    @     0x787f0f54cbd7  (unknown)
    @     0x787f0f54f8ab  (unknown)
    @     0x787f0f479fa4  (unknown)
    @     0x787f0f47b136  (unknown)
    @     0x787f0f4737ce  (unknown)
    @     0x787f0f473b7f  (unknown)
    @     0x787f0f334dc9  (unknown)
    @     0x787f0f32e178  (unknown)
    @     0x787f0f32810b  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack82
    @     0x787f0f4f13ba  (unknown)
    @     0x787f0f54fbb4  (unknown)
    @     0x787f0f479fa4  (unknown)
    @     0x787f0f47b136  (unknown)
    @     0x787f0f4737ce  (unknown)
    @     0x787f0f473b7f  (unknown)
    @     0x787f0f334dc9  (unknown)
    @     0x787f0f32e178  (unknown)
    @     0x787f0f32810b  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack83
    @     0x787f0f4de55e  (unknown)
    @     0x787f0f52ebf2  (unknown)
    @     0x787f0f519b18  (unknown)
    @     0x787f0f555576  (unknown)
    @     0x787f0f32e79f  (unknown)
    @     0x787f0f3283d7  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack84
    @     0x787f0f4de55e  (unknown)
    @     0x787f0f52ebf2  (unknown)
    @     0x787f09b683e5  (unknown)
    @     0x787f099992fd  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack85
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53da6a  (unknown)
    @     0x787f0f5266c8  (unknown)
    @     0x787f0f328406  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack86
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f530505  (unknown)
    @     0x787f0f32f91c  (unknown)
    @     0x787f0f32e659  (unknown)
    @     0x787f0f3285d0  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack87
    @     0x787f0f4df5ff  (unknown)
    @     0x787f0f545c3a  (unknown)
    @     0x787f0f32f95e  (unknown)
    @     0x787f0f32e659  (unknown)
    @     0x787f0f3285d0  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack88
    @     0x787f0f4f31b6  (unknown)
    @     0x787f0f556c30  (unknown)
    @     0x787f0f3351d6  (unknown)
    @     0x787f0f32e66a  (unknown)
    @     0x787f0f3285d0  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack89
    @     0x787f0f4df3d6  (unknown)
    @     0x787f0f53d2ca  (unknown)
    @     0x787f0f529008  (unknown)
    @     0x787f0f506741  (unknown)
    @     0x787f0f529dfb  (unknown)
    @     0x787f0f3274d3  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack90
    @     0x787f0f4e363c  (unknown)
    @     0x787f0f565a16  (unknown)
    @     0x787f0f52a459  (unknown)
    @     0x787f0f5066e6  (unknown)
    @     0x787f0f529dfb  (unknown)
    @     0x787f0f3274d3  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack91
    @     0x787f0f4debc1  (unknown)
    @     0x787f0f565854  (unknown)
    @     0x787f09bf1d10  (unknown)
    @     0x787f09bf18ec  (unknown)
    @     0x787f09bf20ad  (unknown)
    @     0x787f09997f73  (unknown)
    @     0x787f099893df  (unknown)
    @     0x787f0999709d  (unknown)
    @     0x787f099dfd34  (unknown)
    @     0x787f09c9896a  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack92
    @     0x787f0f4f426f  (unknown)
    @     0x787f0f57a997  (unknown)
    @     0x787f0f506719  (unknown)
    @     0x787f0f529dfb  (unknown)
    @     0x787f0f3274d3  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

stack93
    @     0x787f0f4ea266  (unknown)
    @     0x787f0f55872d  (unknown)
    @     0x787f0f328938  (unknown)
    @     0x787f0b7457a9  (unknown)
    @     0x787f09c95163  (unknown)
    @     0x787f09c97c13  (unknown)
    @     0x787f09c9b71d  (unknown)
    @     0x787f120c67e5  (unknown)
    @     0x787f120cbb16  (unknown)
    @     0x787f120d49d2  (unknown)
    @     0x787f12341c23  (unknown)
    @     0x787f98294ac3  (unknown)

