
%s188 = sld [smem:[#allocation18]]
%s189 = sand.u32 134217727, %s188
%s190 = sor.u32 4026531840, %s189

%191 = vtrace %s190

%s182 = sld [smem:[#allocation15]]

%183 = vtrace %s182

%s184 = sld [smem:[#allocation16]]

%185 = vtrace %s184

%s186 = sld [smem:[#allocation17]]

%187 = vtrace %s186

%v169 = vlaneseq
%v170 = vshrl.u32 %v169, 7
%v171 = vshrl.u32 %v170, 1
%v172 = vand.u32 1, %v170
%v173 = vshll.u32 %v172, 2
%v174 = vadd.s32 %v173, %v171
%v175 = vsub.s32 %v174, %v170
%176 = vsetiar.raw.iar0 %v175 /* EvenOdd Store IAR initialization */
%v180 = vsub.s32 %v171, %v170
%181 = vsetiar.raw.iar1 %v180 /* EvenOdd Load IAR initialization */
%s49 = sld [smem:[#allocation12]]

%p192 = scmp.eq.s32.totalorder %s49, 0

%53 = sbr.rel (%p192) target = $region32

%v58 = vand.u32 127, %v169
%v62 = vxor.u32 1135663077, %v58
%v63 = vmul.u32 2925155241, %v62
%v64 = vshrl.u32 %v63, 16
%v65 = vxor.u32 %v64, %v63
%s66 = sxor.u32 2925155241, %s49
%s67 = smul.u32 2223506493, %s66
%s68 = sshrl.u32 %s67, 16
%s69 = sxor.u32 %s68, %s67
%v70 = vxor.u32 2223506493, %v65
%v71 = vmul.u32 1519409121, %v70
%v72 = vshrl.u32 %v71, 16
%v73 = vxor.u32 %v72, %v71
%s74 = smul.u32 3389127133, %s69
%v75 = vmul.u32 1232336661, %v73
%v76 = vstv %s74
%v77 = vsub.s32 %v76, %v75
%v78 = vshrl.u32 %v77, 16
%v79 = vxor.u32 %v78, %v77
%v80 = vxor.u32 1519409121, %v79
%v81 = vmul.u32 2449846741, %v80
%v82 = vshrl.u32 %v81, 16
%v83 = vxor.u32 %v82, %v81
%v84 = vmul.u32 3389127133, %v65
%v85 = vmul.u32 1232336661, %v83
%v86 = vsub.s32 %v84, %v85
%v87 = vshrl.u32 %v86, 16
%v88 = vxor.u32 %v87, %v86
%v89 = vxor.u32 1135663077, %v88
%v90 = vmul.u32 2925155241, %v89
%v91 = vshrl.u32 %v90, 16
%v92 = vxor.u32 %v91, %v90
%v93 = vxor.u32 2925155241, %v79
%v94 = vmul.u32 2223506493, %v93
%v95 = vshrl.u32 %v94, 16
%v96 = vxor.u32 %v95, %v94
%v97 = vxor.u32 2223506493, %v92
%v98 = vmul.u32 1519409121, %v97
%v99 = vshrl.u32 %v98, 16
%v100 = vxor.u32 %v99, %v98
%v101 = vmul.u32 3389127133, %v96
%v102 = vmul.u32 1232336661, %v100
%v103 = vsub.s32 %v101, %v102
%v104 = vshrl.u32 %v103, 16
%v105 = vxor.u32 %v104, %v103
%v106 = vxor.u32 1519409121, %v105
%v107 = vmul.u32 2449846741, %v106
%v108 = vshrl.u32 %v107, 16
%v109 = vxor.u32 %v108, %v107
%v110 = vmul.u32 3389127133, %v92
%v111 = vmul.u32 1232336661, %v109
%v112 = vsub.s32 %v110, %v111
%v113 = vshrl.u32 %v112, 16
%v114 = vxor.u32 %v113, %v112
%v115 = vxor.u32 2337405405, %v114
%v116 = vmul.u32 1179257497, %v115
%v117 = vshrl.u32 %v116, 16
%v118 = vxor.u32 %v117, %v116
%v119 = vxor.u32 747796405, %v114
%v120 = vmul.u32 461070425, %v119
%v121 = vshrl.u32 %v120, 16
%v122 = vxor.u32 %v121, %v120
%v123 = vxor.u32 1179257497, %v105
%v124 = vmul.u32 2174555301, %v123
%v125 = vshrl.u32 %v124, 16
%v126 = vxor.u32 %v125, %v124
%v127 = vxor.u32 461070425, %v105
%v128 = vmul.u32 702470093, %v127
%v129 = vshrl.u32 %v128, 16
%v130 = vxor.u32 %v129, %v128
%v131 = vxor.u32 2174555301, %v114
%v132 = vmul.u32 3546938817, %v131
%v133 = vshrl.u32 %v132, 16
%v134 = vxor.u32 %v133, %v132
%v135 = vxor.u32 702470093, %v114
%v136 = vmul.u32 728804945, %v135
%v137 = vshrl.u32 %v136, 16
%v138 = vxor.u32 %v137, %v136
%v139 = vxor.u32 3546938817, %v105
%v140 = vmul.u32 1343633581, %v139
%v141 = vshrl.u32 %v140, 16
%v142 = vxor.u32 %v141, %v140
%v143 = vxor.u32 728804945, %v105
%v144 = vmul.u32 1920080165, %v143
%v145 = vshrl.u32 %v144, 16
%v146 = vxor.u32 %v145, %v144
%v147 = vor.u32 %v126, %v118
%v148 = vor.u32 %v147, %v134
%v149 = vor.u32 %v148, %v142
%vm150 = vcmp.eq.s32.totalorder %v149, 0
%vm193 = vcmp.eq.s32.totalorder %v170, 1
%vm194 = vcmp.eq.s32.totalorder %v170, 2
%vm195 = vcmp.eq.s32.totalorder %v170, 3
%v160 = vsel /*vm=*/%vm150, /*on_true_vy=*/%v122, /*on_false_vx=*/%v118
%v161 = vsel /*vm=*/%vm150, /*on_true_vy=*/%v130, /*on_false_vx=*/%v126
%v162 = vsel /*vm=*/%vm193, /*on_true_vy=*/%v161, /*on_false_vx=*/%v160
%v163 = vsel /*vm=*/%vm150, /*on_true_vy=*/%v138, /*on_false_vx=*/%v134
%v164 = vsel /*vm=*/%vm194, /*on_true_vy=*/%v163, /*on_false_vx=*/%v162
%v165 = vsel /*vm=*/%vm150, /*on_true_vy=*/%v146, /*on_false_vx=*/%v142
%v166 = vsel /*vm=*/%vm195, /*on_true_vy=*/%v165, /*on_false_vx=*/%v164
%167 = setrngseed %v166 /* Rng seed initialization */
%v168 = vrng /* Rng seed initialization */

%44 = vsettm 1

%s197 = smov 2147483646 /* materialized constant */

%43 = vsettm %s197

%41 = vtrace 2415919103

%0 = vtrace 2952790016

%1 = vtrace 3221225472

%s2 = sld [smem:[#allocation0]]

%p196 = scmp.ne.s32.totalorder %s2, 1

%6 = sbr.rel (%p196) target = $region4

%s7 = sld [smem:[#allocation2]]
%s8 = int_to_ptr.hbm [resolvable:$false] %s7

%s9 = scalar_parameter_address 0

%s10 = scalar_parameter_address 1

%s11 = scalar_parameter_address 2

%12 = compiler-scheduling-barrier

%13 = compiler-scheduling-barrier

%14 = compiler-scheduling-barrier

%15 = compiler-scheduling-barrier

%16 = compiler-scheduling-barrier

%18 = compiler-scheduling-barrier

%19 = compiler-scheduling-barrier

%21 = compiler-scheduling-barrier

%22 = compiler-scheduling-barrier

%24 = compiler-scheduling-barrier

%28 = vtrace 2147483648

%25 = compiler-scheduling-barrier

%s198 = smov [#allocation7] /* materialized constant */

%26 = inlined_call %s198 /* %iota.1 = iota() */

%27 = compiler-scheduling-barrier

%29 = vtrace 2415919104

%37 = vtrace 2147483649

%30 = compiler-scheduling-barrier

%s199 = smov 0 /* materialized constant */
%s200 = smov 1 /* materialized constant */
%s201 = smov [#allocation7] /* materialized constant */
%s202 = smov [#allocation8] /* materialized constant */
%s203 = smov [#allocation9] /* materialized constant */
%s204 = smov [#allocation10] /* materialized constant */

%34 = inlined_call %s199, %s200, %s9, %s10, %s11, %s201, %s202, %s203, %s204, %s8 /* %splash_mha_fwd_08d1d988.1 = custom-call(%constant.4, %constant.5, %Arg_0.1, %Arg_1.2, %Arg_2.3, %iota.1) */

%36 = compiler-scheduling-barrier

%38 = vtrace 2415919105

%39 = compiler-scheduling-barrier

%40 = compiler-scheduling-barrier

%42 = vtrace 2684354559

%s205 = smov 2147483647 /* materialized constant */

%45 = vsettm %s205

%46 = vdelay 1

%47 = sfence

%s206 = smov 0 /* materialized constant */
%48 = sst [smem:[#allocation11]] %s206
