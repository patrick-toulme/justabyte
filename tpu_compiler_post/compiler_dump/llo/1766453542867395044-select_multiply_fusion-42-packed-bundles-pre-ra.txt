= control target key start
LH: loop header
LB: loop body
LE: loop exit
PB: predicated region body
PF: predicated region fallthrough
CT: control target
= control target key end

     0   :  { %s0 = inlined_call_operand.vmem [shape: u32[64], index: 0, kind: input, shape index: {}] /* operand 0 */  ;;  %s1 = inlined_call_operand.vmem [shape: u32[64], index: 1, kind: input, shape index: {}] /* operand 1 */  ;;  %s2 = inlined_call_operand.vmem [shape: u32[64], index: 2, kind: input, shape index: {}] /* operand 2 */  ;;  %s3 = inlined_call_operand.<no memory space> [shape: u32[], index: 3, kind: input, shape index: {}] /* operand 3 */  ;;  %s4 = inlined_call_operand.<no memory space> [shape: u32[], index: 4, kind: input, shape index: {}] /* operand 4 */  ;;  %s5 = inlined_call_operand.<no memory space> [shape: u32[], index: 5, kind: input, shape index: {}] /* operand 5 */  ;;  %s6 = inlined_call_operand.hbm [shape: f32[64,32], index: 6, kind: output, shape index: {}] /* operand 6 */ } /* Start region 0 */
   0x1   :  { %v7 = vstv %s3  ;;  %v8 = vstv %s4  ;;  %v9 = vstv %s5 }
   0x2   :  { %10 = vsyncpa [#allocation2], 0  ;;  %v20 = vlaneseq  ;;  %v19 = vld [vmem:[%s2] ss:$0 sm:$0xff]  ;;  %v1793 = vmov -0.00020021426 /* materialized constant */ } /* Start region 1 */
   0x3   :  { %v17 = vld [vmem:[%s0] ss:$0 sm:$0xff]  ;;  %v1794 = vmov 0.00010095056 /* materialized constant */  ;;  %v1795 = vmov 0.0013493432 /* materialized constant */ }
   0x4   :  { %v21 = vshrl.u32 %v20, 7  ;;  %v18 = vld [vmem:[%s1] ss:$0 sm:$0xff]  ;;  %v1796 = vmov -0.0036734284 /* materialized constant */  ;;  %s1802 = smov [#allocation0] /* materialized constant */ }
   0x5   :  { %v1797 = vmov 0.0057395077 /* materialized constant */  ;;  %v1798 = vmov -0.0076224613 /* materialized constant */  ;;  %v1799 = vmov 0.0094388705 /* materialized constant */ }
   0x6   :  { %v26 = vadd.s32 %v21, %v19  ;;  %v451 = vadd.s32 8, %v21  ;;  %v880 = vadd.s32 16, %v21  ;;  %v1309 = vadd.s32 24, %v21  ;;  %s1739 = sshll.u32 %s1802, 4 }
   0x7   :  { %v1800 = vmov 1.001674 /* materialized constant */  ;;  %v1801 = vmov 2.8329768 /* materialized constant */  ;;  %s1740 = int_to_ptr.vmem [resolvable:$true] %s1739 }
   0x8   :  { %vm30 = vcmp.lt.u32.totalorder %v26, %v19  ;;  %v44 = vadd.s32 %v26, %v8  ;;  %v454 = vadd.s32 %v451, %v19  ;;  %v883 = vadd.s32 %v880, %v19  ;;  %s1771 = scalar_lea.vmem %s1740, 512  ;;  %p1776 = scmp.lt.s32.totalorder %s1740, %s1740 }
   0x9   :  { %v35 = vsel /*vm=*/%vm30, /*on_true_vy=*/%v17, /*on_false_vx=*/%v18  ;;  %v1312 = vadd.s32 %v1309, %v19  ;;  %p1772 = scmp.ne.s32.totalorder %s1740, %s1771  ;;  %p1777 = scmp.lt.s32.totalorder %s1771, %s1771 }
   0xa   :  { %v40 = vadd.s32 %v35, %v9  ;;  %v50 = vshll.u32 %v44, 13  ;;  %v51 = vshrl.u32 %v44, 19  ;;  %vm458 = vcmp.lt.u32.totalorder %v454, %v19 }
   0xb   :  { %v463 = vsel /*vm=*/%vm458, /*on_true_vy=*/%v17, /*on_false_vx=*/%v18  ;;  %v472 = vadd.s32 %v454, %v8  ;;  %vm887 = vcmp.lt.u32.totalorder %v883, %v19  ;;  %v901 = vadd.s32 %v883, %v8  ;;  %p1778 = por %p1777, %p1776 }
   0xc   :  { %v48 = vadd.s32 %v44, %v40  ;;  %v52 = vor.u32 %v51, %v50  ;;  %v468 = vadd.s32 %v463, %v9  ;;  %v892 = vsel /*vm=*/%vm887, /*on_true_vy=*/%v17, /*on_false_vx=*/%v18 }
   0xd   :  { %v478 = vshll.u32 %v472, 13  ;;  %v479 = vshrl.u32 %v472, 19  ;;  %v897 = vadd.s32 %v892, %v9  ;;  %v907 = vshll.u32 %v901, 13  ;;  %p1779 = pnand %p1778, %p1772 }
   0xe   :  { %v53 = vxor.u32 %v52, %v48  ;;  %v476 = vadd.s32 %v472, %v468  ;;  %v908 = vshrl.u32 %v901, 19  ;;  %vm1316 = vcmp.lt.u32.totalorder %v1312, %v19 }
   0xf   :  { %v480 = vor.u32 %v479, %v478  ;;  %v905 = vadd.s32 %v901, %v897  ;;  %v1321 = vsel /*vm=*/%vm1316, /*on_true_vy=*/%v17, /*on_false_vx=*/%v18  ;;  %v1330 = vadd.s32 %v1312, %v8 }
  0x10   :  { %v56 = vadd.s32 %v53, %v48  ;;  %v58 = vshll.u32 %v53, 15  ;;  %v59 = vshrl.u32 %v53, 17  ;;  %v909 = vor.u32 %v908, %v907 }
  0x11   :  { %v481 = vxor.u32 %v480, %v476  ;;  %v1326 = vadd.s32 %v1321, %v9  ;;  %v1336 = vshll.u32 %v1330, 13  ;;  %v1337 = vshrl.u32 %v1330, 19 }
  0x12   :  { %v60 = vor.u32 %v59, %v58  ;;  %v910 = vxor.u32 %v909, %v905 }
  0x13   :  { %v484 = vadd.s32 %v481, %v476  ;;  %v486 = vshll.u32 %v481, 15  ;;  %v487 = vshrl.u32 %v481, 17  ;;  %v1334 = vadd.s32 %v1330, %v1326 }
  0x14   :  { %v61 = vxor.u32 %v60, %v56  ;;  %v913 = vadd.s32 %v910, %v905  ;;  %v915 = vshll.u32 %v910, 15  ;;  %v916 = vshrl.u32 %v910, 17 }
  0x15   :  { %v488 = vor.u32 %v487, %v486  ;;  %v1338 = vor.u32 %v1337, %v1336 }
  0x16   :  { %v64 = vadd.s32 %v61, %v56  ;;  %v66 = vshll.u32 %v61, 26  ;;  %v67 = vshrl.u32 %v61, 6  ;;  %v917 = vor.u32 %v916, %v915 }
  0x17   :  { %v489 = vxor.u32 %v488, %v484  ;;  %v1339 = vxor.u32 %v1338, %v1334 }
  0x18   :  { %v68 = vor.u32 %v67, %v66  ;;  %v918 = vxor.u32 %v917, %v913 }
  0x19   :  { %v492 = vadd.s32 %v489, %v484  ;;  %v494 = vshll.u32 %v489, 26  ;;  %v495 = vshrl.u32 %v489, 6  ;;  %v1342 = vadd.s32 %v1339, %v1334 }
  0x1a   :  { %v69 = vxor.u32 %v68, %v64  ;;  %v921 = vadd.s32 %v918, %v913  ;;  %v923 = vshll.u32 %v918, 26  ;;  %v924 = vshrl.u32 %v918, 6 }
  0x1b   :  { %v496 = vor.u32 %v495, %v494  ;;  %v1344 = vshll.u32 %v1339, 15  ;;  %v1345 = vshrl.u32 %v1339, 17 }
  0x1c   :  { %v72 = vadd.s32 %v69, %v64  ;;  %v78 = vshll.u32 %v69, 6  ;;  %v79 = vshrl.u32 %v69, 26  ;;  %v925 = vor.u32 %v924, %v923 }
  0x1d   :  { %v497 = vxor.u32 %v496, %v492  ;;  %v1346 = vor.u32 %v1345, %v1344 }
  0x1e   :  { %v80 = vor.u32 %v79, %v78  ;;  %v926 = vxor.u32 %v925, %v921  ;;  %v76 = vadd.s32 %v72, %v8 }
  0x1f   :  { %v500 = vadd.s32 %v497, %v492  ;;  %v506 = vshll.u32 %v497, 6  ;;  %v507 = vshrl.u32 %v497, 26  ;;  %v1347 = vxor.u32 %v1346, %v1342 }
  0x20   :  { %v81 = vxor.u32 %v80, %v72  ;;  %v929 = vadd.s32 %v926, %v921  ;;  %v935 = vshll.u32 %v926, 6  ;;  %v936 = vshrl.u32 %v926, 26 }
  0x21   :  { %v508 = vor.u32 %v507, %v506  ;;  %v1352 = vshll.u32 %v1347, 26  ;;  %v1353 = vshrl.u32 %v1347, 6  ;;  %v1350 = vadd.s32 %v1347, %v1342 }
  0x22   :  { %v84 = vadd.s32 %v81, %v7  ;;  %v937 = vor.u32 %v936, %v935  ;;  %v504 = vadd.s32 %v500, %v8  ;;  %v933 = vadd.s32 %v929, %v8 }
  0x23   :  { %v509 = vxor.u32 %v508, %v500  ;;  %v1354 = vor.u32 %v1353, %v1352 }
  0x24   :  { %v88 = vadd.s32 1, %v84  ;;  %v938 = vxor.u32 %v937, %v929 }
  0x25   :  { %v512 = vadd.s32 %v509, %v7  ;;  %v1355 = vxor.u32 %v1354, %v1350 }
  0x26   :  { %v92 = vadd.s32 %v88, %v76  ;;  %v94 = vshll.u32 %v88, 17  ;;  %v95 = vshrl.u32 %v88, 15  ;;  %v941 = vadd.s32 %v938, %v7 }
  0x27   :  { %v516 = vadd.s32 1, %v512  ;;  %v1358 = vadd.s32 %v1355, %v1350  ;;  %v1364 = vshll.u32 %v1355, 6  ;;  %v1365 = vshrl.u32 %v1355, 26 }
  0x28   :  { %v96 = vor.u32 %v95, %v94  ;;  %v945 = vadd.s32 1, %v941 }
  0x29   :  { %v520 = vadd.s32 %v516, %v504  ;;  %v522 = vshll.u32 %v516, 17  ;;  %v523 = vshrl.u32 %v516, 15  ;;  %v1366 = vor.u32 %v1365, %v1364 }
  0x2a   :  { %v97 = vxor.u32 %v96, %v92  ;;  %v949 = vadd.s32 %v945, %v933  ;;  %v951 = vshll.u32 %v945, 17  ;;  %v952 = vshrl.u32 %v945, 15 }
  0x2b   :  { %v524 = vor.u32 %v523, %v522  ;;  %v1367 = vxor.u32 %v1366, %v1358  ;;  %v1362 = vadd.s32 %v1358, %v8 }
  0x2c   :  { %v100 = vadd.s32 %v97, %v92  ;;  %v102 = vshll.u32 %v97, 29  ;;  %v103 = vshrl.u32 %v97, 3  ;;  %v953 = vor.u32 %v952, %v951 }
  0x2d   :  { %v525 = vxor.u32 %v524, %v520  ;;  %v1370 = vadd.s32 %v1367, %v7 }
  0x2e   :  { %v104 = vor.u32 %v103, %v102  ;;  %v954 = vxor.u32 %v953, %v949 }
  0x2f   :  { %v528 = vadd.s32 %v525, %v520  ;;  %v530 = vshll.u32 %v525, 29  ;;  %v531 = vshrl.u32 %v525, 3  ;;  %v1374 = vadd.s32 1, %v1370 }
  0x30   :  { %v105 = vxor.u32 %v104, %v100  ;;  %v957 = vadd.s32 %v954, %v949  ;;  %v959 = vshll.u32 %v954, 29  ;;  %v960 = vshrl.u32 %v954, 3 }
  0x31   :  { %v532 = vor.u32 %v531, %v530  ;;  %v1380 = vshll.u32 %v1374, 17  ;;  %v1381 = vshrl.u32 %v1374, 15  ;;  %v1378 = vadd.s32 %v1374, %v1362 }
  0x32   :  { %v108 = vadd.s32 %v105, %v100  ;;  %v110 = vshll.u32 %v105, 16  ;;  %v111 = vshrl.u32 %v105, 16  ;;  %v961 = vor.u32 %v960, %v959 }
  0x33   :  { %v533 = vxor.u32 %v532, %v528  ;;  %v1382 = vor.u32 %v1381, %v1380 }
  0x34   :  { %v112 = vor.u32 %v111, %v110  ;;  %v962 = vxor.u32 %v961, %v957 }
  0x35   :  { %v536 = vadd.s32 %v533, %v528  ;;  %v538 = vshll.u32 %v533, 16  ;;  %v539 = vshrl.u32 %v533, 16  ;;  %v1383 = vxor.u32 %v1382, %v1378 }
  0x36   :  { %v113 = vxor.u32 %v112, %v108  ;;  %v965 = vadd.s32 %v962, %v957  ;;  %v967 = vshll.u32 %v962, 16  ;;  %v968 = vshrl.u32 %v962, 16 }
  0x37   :  { %v540 = vor.u32 %v539, %v538  ;;  %v1388 = vshll.u32 %v1383, 29  ;;  %v1389 = vshrl.u32 %v1383, 3  ;;  %v1386 = vadd.s32 %v1383, %v1378 }
  0x38   :  { %v116 = vadd.s32 %v113, %v108  ;;  %v122 = vshll.u32 %v113, 24  ;;  %v123 = vshrl.u32 %v113, 8  ;;  %v969 = vor.u32 %v968, %v967 }
  0x39   :  { %v541 = vxor.u32 %v540, %v536  ;;  %v1390 = vor.u32 %v1389, %v1388 }
  0x3a   :  { %v124 = vor.u32 %v123, %v122  ;;  %v970 = vxor.u32 %v969, %v965  ;;  %v120 = vadd.s32 %v116, %v7 }
  0x3b   :  { %v544 = vadd.s32 %v541, %v536  ;;  %v550 = vshll.u32 %v541, 24  ;;  %v551 = vshrl.u32 %v541, 8  ;;  %v1391 = vxor.u32 %v1390, %v1386 }
  0x3c   :  { %v125 = vxor.u32 %v124, %v116  ;;  %v979 = vshll.u32 %v970, 24  ;;  %v980 = vshrl.u32 %v970, 8  ;;  %v973 = vadd.s32 %v970, %v965 }
  0x3d   :  { %v552 = vor.u32 %v551, %v550  ;;  %v548 = vadd.s32 %v544, %v7  ;;  %v1394 = vadd.s32 %v1391, %v1386  ;;  %v1396 = vshll.u32 %v1391, 16 }
  0x3e   :  { %v128 = vadd.s32 %v125, %v9  ;;  %v981 = vor.u32 %v980, %v979  ;;  %v977 = vadd.s32 %v973, %v7  ;;  %v1397 = vshrl.u32 %v1391, 16 }
  0x3f   :  { %v553 = vxor.u32 %v552, %v544 }
  0x40   :  { %v132 = vadd.s32 2, %v128  ;;  %v982 = vxor.u32 %v981, %v973  ;;  %v1398 = vor.u32 %v1397, %v1396 }
  0x41   :  { %v556 = vadd.s32 %v553, %v9 }
  0x42   :  { %v136 = vadd.s32 %v132, %v120  ;;  %v138 = vshll.u32 %v132, 13  ;;  %v139 = vshrl.u32 %v132, 19  ;;  %v985 = vadd.s32 %v982, %v9 }
  0x43   :  { %v560 = vadd.s32 2, %v556  ;;  %v1399 = vxor.u32 %v1398, %v1394 }
  0x44   :  { %v140 = vor.u32 %v139, %v138  ;;  %v989 = vadd.s32 2, %v985 }
  0x45   :  { %v564 = vadd.s32 %v560, %v548  ;;  %v566 = vshll.u32 %v560, 13  ;;  %v567 = vshrl.u32 %v560, 19  ;;  %v1402 = vadd.s32 %v1399, %v1394 }
  0x46   :  { %v141 = vxor.u32 %v140, %v136  ;;  %v993 = vadd.s32 %v989, %v977  ;;  %v995 = vshll.u32 %v989, 13  ;;  %v996 = vshrl.u32 %v989, 19 }
  0x47   :  { %v568 = vor.u32 %v567, %v566  ;;  %v1408 = vshll.u32 %v1399, 24  ;;  %v1409 = vshrl.u32 %v1399, 8  ;;  %v1406 = vadd.s32 %v1402, %v7 }
  0x48   :  { %v144 = vadd.s32 %v141, %v136  ;;  %v146 = vshll.u32 %v141, 15  ;;  %v147 = vshrl.u32 %v141, 17  ;;  %v997 = vor.u32 %v996, %v995 }
  0x49   :  { %v569 = vxor.u32 %v568, %v564  ;;  %v1410 = vor.u32 %v1409, %v1408 }
  0x4a   :  { %v148 = vor.u32 %v147, %v146  ;;  %v998 = vxor.u32 %v997, %v993 }
  0x4b   :  { %v572 = vadd.s32 %v569, %v564  ;;  %v574 = vshll.u32 %v569, 15  ;;  %v575 = vshrl.u32 %v569, 17  ;;  %v1411 = vxor.u32 %v1410, %v1402 }
  0x4c   :  { %v149 = vxor.u32 %v148, %v144  ;;  %v1001 = vadd.s32 %v998, %v993  ;;  %v1003 = vshll.u32 %v998, 15  ;;  %v1004 = vshrl.u32 %v998, 17 }
  0x4d   :  { %v576 = vor.u32 %v575, %v574  ;;  %v1414 = vadd.s32 %v1411, %v9 }
  0x4e   :  { %v152 = vadd.s32 %v149, %v144  ;;  %v154 = vshll.u32 %v149, 26  ;;  %v155 = vshrl.u32 %v149, 6  ;;  %v1005 = vor.u32 %v1004, %v1003 }
  0x4f   :  { %v577 = vxor.u32 %v576, %v572  ;;  %v1418 = vadd.s32 2, %v1414 }
  0x50   :  { %v156 = vor.u32 %v155, %v154  ;;  %v1006 = vxor.u32 %v1005, %v1001 }
  0x51   :  { %v580 = vadd.s32 %v577, %v572  ;;  %v582 = vshll.u32 %v577, 26  ;;  %v583 = vshrl.u32 %v577, 6  ;;  %v1422 = vadd.s32 %v1418, %v1406 }
  0x52   :  { %v157 = vxor.u32 %v156, %v152  ;;  %v1009 = vadd.s32 %v1006, %v1001  ;;  %v1011 = vshll.u32 %v1006, 26  ;;  %v1012 = vshrl.u32 %v1006, 6 }
  0x53   :  { %v584 = vor.u32 %v583, %v582  ;;  %v1424 = vshll.u32 %v1418, 13  ;;  %v1425 = vshrl.u32 %v1418, 19 }
  0x54   :  { %v160 = vadd.s32 %v157, %v152  ;;  %v166 = vshll.u32 %v157, 6  ;;  %v167 = vshrl.u32 %v157, 26  ;;  %v1013 = vor.u32 %v1012, %v1011 }
  0x55   :  { %v585 = vxor.u32 %v584, %v580  ;;  %v1426 = vor.u32 %v1425, %v1424 }
  0x56   :  { %v168 = vor.u32 %v167, %v166  ;;  %v164 = vadd.s32 %v160, %v9  ;;  %v1014 = vxor.u32 %v1013, %v1009 }
  0x57   :  { %v588 = vadd.s32 %v585, %v580  ;;  %v594 = vshll.u32 %v585, 6  ;;  %v595 = vshrl.u32 %v585, 26  ;;  %v1427 = vxor.u32 %v1426, %v1422 }
  0x58   :  { %v169 = vxor.u32 %v168, %v160  ;;  %v1017 = vadd.s32 %v1014, %v1009  ;;  %v1023 = vshll.u32 %v1014, 6  ;;  %v1024 = vshrl.u32 %v1014, 26 }
  0x59   :  { %v596 = vor.u32 %v595, %v594  ;;  %v592 = vadd.s32 %v588, %v9  ;;  %v1430 = vadd.s32 %v1427, %v1422  ;;  %v1432 = vshll.u32 %v1427, 15 }
  0x5a   :  { %v172 = vadd.s32 %v169, %v8  ;;  %v1025 = vor.u32 %v1024, %v1023  ;;  %v1021 = vadd.s32 %v1017, %v9  ;;  %v1433 = vshrl.u32 %v1427, 17 }
  0x5b   :  { %v597 = vxor.u32 %v596, %v588 }
  0x5c   :  { %v176 = vadd.s32 3, %v172  ;;  %v1026 = vxor.u32 %v1025, %v1017  ;;  %v1434 = vor.u32 %v1433, %v1432 }
  0x5d   :  { %v600 = vadd.s32 %v597, %v8 }
  0x5e   :  { %v180 = vadd.s32 %v176, %v164  ;;  %v182 = vshll.u32 %v176, 17  ;;  %v183 = vshrl.u32 %v176, 15  ;;  %v1029 = vadd.s32 %v1026, %v8 }
  0x5f   :  { %v604 = vadd.s32 3, %v600  ;;  %v1435 = vxor.u32 %v1434, %v1430 }
  0x60   :  { %v184 = vor.u32 %v183, %v182  ;;  %v1033 = vadd.s32 3, %v1029 }
  0x61   :  { %v608 = vadd.s32 %v604, %v592  ;;  %v610 = vshll.u32 %v604, 17  ;;  %v611 = vshrl.u32 %v604, 15  ;;  %v1438 = vadd.s32 %v1435, %v1430 }
  0x62   :  { %v185 = vxor.u32 %v184, %v180  ;;  %v1037 = vadd.s32 %v1033, %v1021  ;;  %v1039 = vshll.u32 %v1033, 17  ;;  %v1040 = vshrl.u32 %v1033, 15 }
  0x63   :  { %v612 = vor.u32 %v611, %v610  ;;  %v1440 = vshll.u32 %v1435, 26  ;;  %v1441 = vshrl.u32 %v1435, 6 }
  0x64   :  { %v188 = vadd.s32 %v185, %v180  ;;  %v190 = vshll.u32 %v185, 29  ;;  %v191 = vshrl.u32 %v185, 3  ;;  %v1041 = vor.u32 %v1040, %v1039 }
  0x65   :  { %v613 = vxor.u32 %v612, %v608  ;;  %v1442 = vor.u32 %v1441, %v1440 }
  0x66   :  { %v192 = vor.u32 %v191, %v190  ;;  %v1042 = vxor.u32 %v1041, %v1037 }
  0x67   :  { %v616 = vadd.s32 %v613, %v608  ;;  %v618 = vshll.u32 %v613, 29  ;;  %v619 = vshrl.u32 %v613, 3  ;;  %v1443 = vxor.u32 %v1442, %v1438 }
  0x68   :  { %v193 = vxor.u32 %v192, %v188  ;;  %v1045 = vadd.s32 %v1042, %v1037  ;;  %v1047 = vshll.u32 %v1042, 29  ;;  %v1048 = vshrl.u32 %v1042, 3 }
  0x69   :  { %v620 = vor.u32 %v619, %v618  ;;  %v1446 = vadd.s32 %v1443, %v1438  ;;  %v1452 = vshll.u32 %v1443, 6  ;;  %v1453 = vshrl.u32 %v1443, 26 }
  0x6a   :  { %v196 = vadd.s32 %v193, %v188  ;;  %v198 = vshll.u32 %v193, 16  ;;  %v199 = vshrl.u32 %v193, 16  ;;  %v1049 = vor.u32 %v1048, %v1047 }
  0x6b   :  { %v621 = vxor.u32 %v620, %v616  ;;  %v1454 = vor.u32 %v1453, %v1452  ;;  %v1450 = vadd.s32 %v1446, %v9 }
  0x6c   :  { %v200 = vor.u32 %v199, %v198  ;;  %v1050 = vxor.u32 %v1049, %v1045 }
  0x6d   :  { %v624 = vadd.s32 %v621, %v616  ;;  %v626 = vshll.u32 %v621, 16  ;;  %v627 = vshrl.u32 %v621, 16  ;;  %v1455 = vxor.u32 %v1454, %v1446 }
  0x6e   :  { %v201 = vxor.u32 %v200, %v196  ;;  %v1053 = vadd.s32 %v1050, %v1045  ;;  %v1055 = vshll.u32 %v1050, 16  ;;  %v1056 = vshrl.u32 %v1050, 16 }
  0x6f   :  { %v628 = vor.u32 %v627, %v626  ;;  %v1458 = vadd.s32 %v1455, %v8 }
  0x70   :  { %v204 = vadd.s32 %v201, %v196  ;;  %v210 = vshll.u32 %v201, 24  ;;  %v211 = vshrl.u32 %v201, 8  ;;  %v1057 = vor.u32 %v1056, %v1055 }
  0x71   :  { %v629 = vxor.u32 %v628, %v624  ;;  %v1462 = vadd.s32 3, %v1458 }
  0x72   :  { %v212 = vor.u32 %v211, %v210  ;;  %v208 = vadd.s32 %v204, %v8  ;;  %v1058 = vxor.u32 %v1057, %v1053 }
  0x73   :  { %v632 = vadd.s32 %v629, %v624  ;;  %v638 = vshll.u32 %v629, 24  ;;  %v639 = vshrl.u32 %v629, 8  ;;  %v1466 = vadd.s32 %v1462, %v1450 }
  0x74   :  { %v213 = vxor.u32 %v212, %v204  ;;  %v1468 = vshll.u32 %v1462, 17  ;;  %v1469 = vshrl.u32 %v1462, 15  ;;  %v1061 = vadd.s32 %v1058, %v1053 }
  0x75   :  { %v640 = vor.u32 %v639, %v638  ;;  %v1067 = vshll.u32 %v1058, 24  ;;  %v1068 = vshrl.u32 %v1058, 8  ;;  %v636 = vadd.s32 %v632, %v8 }
  0x76   :  { %v216 = vadd.s32 %v213, %v7  ;;  %v1470 = vor.u32 %v1469, %v1468  ;;  %v1065 = vadd.s32 %v1061, %v8 }
  0x77   :  { %v641 = vxor.u32 %v640, %v632  ;;  %v1069 = vor.u32 %v1068, %v1067 }
  0x78   :  { %v220 = vadd.s32 4, %v216  ;;  %v1471 = vxor.u32 %v1470, %v1466 }
  0x79   :  { %v644 = vadd.s32 %v641, %v7  ;;  %v1070 = vxor.u32 %v1069, %v1061 }
  0x7a   :  { %v224 = vadd.s32 %v220, %v208  ;;  %v226 = vshll.u32 %v220, 13  ;;  %v227 = vshrl.u32 %v220, 19  ;;  %v1474 = vadd.s32 %v1471, %v1466 }
  0x7b   :  { %v648 = vadd.s32 4, %v644  ;;  %v1476 = vshll.u32 %v1471, 29  ;;  %v1477 = vshrl.u32 %v1471, 3  ;;  %v1073 = vadd.s32 %v1070, %v7 }
  0x7c   :  { %v228 = vor.u32 %v227, %v226 }
  0x7d   :  { %v652 = vadd.s32 %v648, %v636  ;;  %v654 = vshll.u32 %v648, 13  ;;  %v655 = vshrl.u32 %v648, 19  ;;  %v1478 = vor.u32 %v1477, %v1476 }
  0x7e   :  { %v229 = vxor.u32 %v228, %v224  ;;  %v1077 = vadd.s32 4, %v1073 }
  0x7f   :  { %v656 = vor.u32 %v655, %v654  ;;  %v1479 = vxor.u32 %v1478, %v1474 }
  0x80   :  { %v232 = vadd.s32 %v229, %v224  ;;  %v234 = vshll.u32 %v229, 15  ;;  %v235 = vshrl.u32 %v229, 17  ;;  %v1081 = vadd.s32 %v1077, %v1065 }
  0x81   :  { %v657 = vxor.u32 %v656, %v652  ;;  %v1083 = vshll.u32 %v1077, 13  ;;  %v1084 = vshrl.u32 %v1077, 19  ;;  %v1482 = vadd.s32 %v1479, %v1474 }
  0x82   :  { %v236 = vor.u32 %v235, %v234  ;;  %v1484 = vshll.u32 %v1479, 16  ;;  %v1485 = vshrl.u32 %v1479, 16 }
  0x83   :  { %v660 = vadd.s32 %v657, %v652  ;;  %v662 = vshll.u32 %v657, 15  ;;  %v663 = vshrl.u32 %v657, 17  ;;  %v1085 = vor.u32 %v1084, %v1083 }
  0x84   :  { %v237 = vxor.u32 %v236, %v232  ;;  %v1486 = vor.u32 %v1485, %v1484 }
  0x85   :  { %v664 = vor.u32 %v663, %v662  ;;  %v1086 = vxor.u32 %v1085, %v1081 }
  0x86   :  { %v240 = vadd.s32 %v237, %v232  ;;  %v242 = vshll.u32 %v237, 26  ;;  %v243 = vshrl.u32 %v237, 6  ;;  %v1487 = vxor.u32 %v1486, %v1482 }
  0x87   :  { %v665 = vxor.u32 %v664, %v660  ;;  %v1089 = vadd.s32 %v1086, %v1081  ;;  %v1091 = vshll.u32 %v1086, 15  ;;  %v1092 = vshrl.u32 %v1086, 17 }
  0x88   :  { %v244 = vor.u32 %v243, %v242  ;;  %v1490 = vadd.s32 %v1487, %v1482  ;;  %v1496 = vshll.u32 %v1487, 24  ;;  %v1497 = vshrl.u32 %v1487, 8 }
  0x89   :  { %v668 = vadd.s32 %v665, %v660  ;;  %v670 = vshll.u32 %v665, 26  ;;  %v671 = vshrl.u32 %v665, 6  ;;  %v1093 = vor.u32 %v1092, %v1091 }
  0x8a   :  { %v245 = vxor.u32 %v244, %v240  ;;  %v1498 = vor.u32 %v1497, %v1496  ;;  %v1494 = vadd.s32 %v1490, %v8 }
  0x8b   :  { %v672 = vor.u32 %v671, %v670  ;;  %v1094 = vxor.u32 %v1093, %v1089 }
  0x8c   :  { %v248 = vadd.s32 %v245, %v240  ;;  %v254 = vshll.u32 %v245, 6  ;;  %v255 = vshrl.u32 %v245, 26  ;;  %v1499 = vxor.u32 %v1498, %v1490 }
  0x8d   :  { %v673 = vxor.u32 %v672, %v668  ;;  %v1097 = vadd.s32 %v1094, %v1089  ;;  %v1099 = vshll.u32 %v1094, 26  ;;  %v1100 = vshrl.u32 %v1094, 6 }
  0x8e   :  { %v256 = vor.u32 %v255, %v254  ;;  %v1502 = vadd.s32 %v1499, %v7  ;;  %v252 = vadd.s32 %v248, %v7 }
  0x8f   :  { %v676 = vadd.s32 %v673, %v668  ;;  %v682 = vshll.u32 %v673, 6  ;;  %v683 = vshrl.u32 %v673, 26  ;;  %v1101 = vor.u32 %v1100, %v1099 }
  0x90   :  { %v257 = vxor.u32 %v256, %v248  ;;  %v1506 = vadd.s32 4, %v1502 }
  0x91   :  { %v684 = vor.u32 %v683, %v682  ;;  %v1102 = vxor.u32 %v1101, %v1097  ;;  %v680 = vadd.s32 %v676, %v7 }
  0x92   :  { %v260 = vadd.s32 %v257, %v9  ;;  %v1510 = vadd.s32 %v1506, %v1494  ;;  %v1512 = vshll.u32 %v1506, 13  ;;  %v1513 = vshrl.u32 %v1506, 19 }
  0x93   :  { %v685 = vxor.u32 %v684, %v676  ;;  %v1105 = vadd.s32 %v1102, %v1097  ;;  %v1111 = vshll.u32 %v1102, 6  ;;  %v1112 = vshrl.u32 %v1102, 26 }
  0x94   :  { %v264 = vadd.s32 5, %v260  ;;  %v1514 = vor.u32 %v1513, %v1512 }
  0x95   :  { %v688 = vadd.s32 %v685, %v9  ;;  %v1113 = vor.u32 %v1112, %v1111  ;;  %v1109 = vadd.s32 %v1105, %v7 }
  0x96   :  { %v266 = vxor.u32 %v264, %v252  ;;  %v1515 = vxor.u32 %v1514, %v1510 }
  0x97   :  { %v692 = vadd.s32 5, %v688  ;;  %v1114 = vxor.u32 %v1113, %v1105 }
  0x98   :  { %v267 = vshrl.u32 %v266, 9  ;;  %v1518 = vadd.s32 %v1515, %v1510  ;;  %v1520 = vshll.u32 %v1515, 15  ;;  %v1521 = vshrl.u32 %v1515, 17 }
  0x99   :  { %v694 = vxor.u32 %v692, %v680  ;;  %v1117 = vadd.s32 %v1114, %v9 }
  0x9a   :  { %v268 = vor.u32 1065353216, %v267  ;;  %v1522 = vor.u32 %v1521, %v1520 }
  0x9b   :  { %v695 = vshrl.u32 %v694, 9  ;;  %v1121 = vadd.s32 5, %v1117 }
  0x9c   :  { %v272 = vadd.f32 -1.0, %v268  ;;  %v1523 = vxor.u32 %v1522, %v1518 }
  0x9d   :  { %v696 = vor.u32 1065353216, %v695  ;;  %v1123 = vxor.u32 %v1121, %v1109 }
  0x9e   :  { %v276 = vmul.f32 2.0, %v272  ;;  %v1526 = vadd.s32 %v1523, %v1518  ;;  %v1528 = vshll.u32 %v1523, 26  ;;  %v1529 = vshrl.u32 %v1523, 6 }
  0x9f   :  { %v700 = vadd.f32 -1.0, %v696  ;;  %v1124 = vshrl.u32 %v1123, 9 }
  0xa0   :  { %v280 = vadd.f32 -0.99999994, %v276  ;;  %v1530 = vor.u32 %v1529, %v1528 }
  0xa1   :  { %v704 = vmul.f32 2.0, %v700  ;;  %v1125 = vor.u32 1065353216, %v1124 }
  0xa2   :  { %v284 = vmax.f32 %v280, -0.99999994  ;;  %v1531 = vxor.u32 %v1530, %v1526 }
  0xa3   :  { %v708 = vadd.f32 -0.99999994, %v704  ;;  %v1129 = vadd.f32 -1.0, %v1125 }
  0xa4   :  { %v296 = vxor.u32 2147483648, %v284  ;;  %v1540 = vshll.u32 %v1531, 6  ;;  %v1541 = vshrl.u32 %v1531, 26  ;;  %v1534 = vadd.s32 %v1531, %v1526 }
  0xa5   :  { %v712 = vmax.f32 %v708, -0.99999994  ;;  %v1133 = vmul.f32 2.0, %v1129  ;;  %v286 = vand.u32 2147483647, %v284  ;;  %v294 = vmul.f32 inf, %v284 }
  0xa6   :  { %v299 = vmul.f32 %v296, %v284  ;;  %v1542 = vor.u32 %v1541, %v1540  ;;  %v1538 = vadd.s32 %v1534, %v7 }
  0xa7   :  { %v724 = vxor.u32 2147483648, %v712  ;;  %v1137 = vadd.f32 -0.99999994, %v1133  ;;  %vm289 = vcmp.eq.f32.partialorder %v286, 1.0  ;;  %v714 = vand.u32 2147483647, %v712 }
  0xa8   :  { %v301 = vadd.f32 1.0, %v299  ;;  %v1543 = vxor.u32 %v1542, %v1534  ;;  %v304 = vmul.f32 -0.5, %v299  ;;  %v307 = vand.u32 2147483647, %v299 }
  0xa9   :  { %v727 = vmul.f32 %v724, %v712  ;;  %v1141 = vmax.f32 %v1137, -0.99999994  ;;  %v722 = vmul.f32 inf, %v712  ;;  %vm717 = vcmp.eq.f32.partialorder %v714, 1.0 }
  0xaa   :  { %1755 = vlog2.f32 %v301  ;;  %v1546 = vadd.s32 %v1543, %v9  ;;  %v305 = vadd.f32 1.0, %v304  ;;  %vm308 = vcmp.lt.f32.partialorder %v307, 0.0004427343 }
  0xab   :  { %v729 = vadd.f32 1.0, %v727  ;;  %v1153 = vxor.u32 2147483648, %v1141  ;;  %v732 = vmul.f32 -0.5, %v727  ;;  %v735 = vand.u32 2147483647, %v727 }
  0xac   :  { %v1550 = vadd.s32 5, %v1546  ;;  %v306 = vmul.f32 %v305, %v299  ;;  %v1143 = vand.u32 2147483647, %v1141  ;;  %v1151 = vmul.f32 inf, %v1141 }
  0xad   :  { %1757 = vlog2.f32 %v729  ;;  %v1156 = vmul.f32 %v1153, %v1141  ;;  %v733 = vadd.f32 1.0, %v732  ;;  %vm736 = vcmp.lt.f32.partialorder %v735, 0.0004427343 }
  0xae   :  { %v1552 = vxor.u32 %v1550, %v1538  ;;  %vm1146 = vcmp.eq.f32.partialorder %v1143, 1.0 }
  0xaf   :  { %v1158 = vadd.f32 1.0, %v1156  ;;  %v1161 = vmul.f32 -0.5, %v1156  ;;  %v734 = vmul.f32 %v733, %v727  ;;  %v1164 = vand.u32 2147483647, %v1156 }
  0xb0   :  { %v1553 = vshrl.u32 %v1552, 9 }
  0xb1   :  { %1759 = vlog2.f32 %v1158  ;;  %v1162 = vadd.f32 1.0, %v1161  ;;  %vm1165 = vcmp.lt.f32.partialorder %v1164, 0.0004427343 }
  0xb2   :  { %v1554 = vor.u32 1065353216, %v1553 }
  0xb3   :  { %v1163 = vmul.f32 %v1162, %v1156 }
  0xb4   :  { %v1558 = vadd.f32 -1.0, %v1554 }
  0xb5   :  {}
  0xb6   :  { %v1562 = vmul.f32 2.0, %v1558 }
  0xb7   :  { %v1756 = vpop.eup %1755 }
  0xb8   :  { %v303 = vmul.f32 0.6931472, %v1756  ;;  %v1566 = vadd.f32 -0.99999994, %v1562 }
  0xb9   :  {}
  0xba   :  { %v1758 = vpop.eup %1757  ;;  %v309 = vsel /*vm=*/%vm308, /*on_true_vy=*/%v306, /*on_false_vx=*/%v303  ;;  %v1570 = vmax.f32 %v1566, -0.99999994 }
  0xbb   :  { %v310 = vxor.u32 2147483648, %v309  ;;  %v731 = vmul.f32 0.6931472, %v1758 }
  0xbc   :  { %v1582 = vxor.u32 2147483648, %v1570  ;;  %v1572 = vand.u32 2147483647, %v1570  ;;  %v1580 = vmul.f32 inf, %v1570 }
  0xbd   :  { %1761 = vrsqrt.f32 %v310  ;;  %v737 = vsel /*vm=*/%vm736, /*on_true_vy=*/%v734, /*on_false_vx=*/%v731  ;;  %vm358 = vcmp.eq.f32.partialorder %v310, inf  ;;  %v361 = vand.u32 2147483648, %v310 }
  0xbe   :  { %v1760 = vpop.eup %1759  ;;  %v738 = vxor.u32 2147483648, %v737  ;;  %v1585 = vmul.f32 %v1582, %v1570  ;;  %vm360 = vcmp.eq.f32.partialorder %v310, 0.0  ;;  %vm313 = vcmp.lt.f32.partialorder %v310, 5.0 }
  0xbf   :  { %v1160 = vmul.f32 0.6931472, %v1760  ;;  %v354 = vadd.f32 -2.5, %v310  ;;  %v350 = vsel /*vm=*/%vm313, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v1793  ;;  %vm1575 = vcmp.eq.f32.partialorder %v1572, 1.0 }
  0xc0   :  { %1763 = vrsqrt.f32 %v738  ;;  %v1587 = vadd.f32 1.0, %v1585  ;;  %v1590 = vmul.f32 -0.5, %v1585  ;;  %vm786 = vcmp.eq.f32.partialorder %v738, inf }
  0xc1   :  { %v1166 = vsel /*vm=*/%vm1165, /*on_true_vy=*/%v1163, /*on_false_vx=*/%v1160  ;;  %v789 = vand.u32 2147483648, %v738  ;;  %v346 = vsel /*vm=*/%vm313, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v1794  ;;  %vm788 = vcmp.eq.f32.partialorder %v738, 0.0 }
  0xc2   :  { %v1167 = vxor.u32 2147483648, %v1166  ;;  %vm741 = vcmp.lt.f32.partialorder %v738, 5.0  ;;  %v1591 = vadd.f32 1.0, %v1590  ;;  %v782 = vadd.f32 -2.5, %v738 }
  0xc3   :  { %v1593 = vand.u32 2147483647, %v1585  ;;  %v342 = vsel /*vm=*/%vm313, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v1795  ;;  %v774 = vsel /*vm=*/%vm741, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v1794 }
  0xc4   :  { %1765 = vrsqrt.f32 %v1167  ;;  %v778 = vsel /*vm=*/%vm741, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v1793  ;;  %vm1215 = vcmp.eq.f32.partialorder %v1167, inf  ;;  %v1218 = vand.u32 2147483648, %v1167 }
  0xc5   :  { %1767 = vlog2.f32 %v1587  ;;  %v1592 = vmul.f32 %v1591, %v1585  ;;  %vm1217 = vcmp.eq.f32.partialorder %v1167, 0.0  ;;  %vm1594 = vcmp.lt.f32.partialorder %v1593, 0.0004427343 }
  0xc6   :  { %vm1170 = vcmp.lt.f32.partialorder %v1167, 5.0  ;;  %v338 = vsel /*vm=*/%vm313, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v1796  ;;  %v1211 = vadd.f32 -2.5, %v1167  ;;  %v770 = vsel /*vm=*/%vm741, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v1795 }
  0xc7   :  { %v1207 = vsel /*vm=*/%vm1170, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v1793  ;;  %v334 = vsel /*vm=*/%vm313, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v1797  ;;  %v1203 = vsel /*vm=*/%vm1170, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v1794 }
  0xc8   :  { %v766 = vsel /*vm=*/%vm741, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v1796  ;;  %v330 = vsel /*vm=*/%vm313, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v1798  ;;  %v1199 = vsel /*vm=*/%vm1170, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v1795 }
  0xc9   :  { %v762 = vsel /*vm=*/%vm741, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v1797  ;;  %v326 = vsel /*vm=*/%vm313, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v1799  ;;  %v1195 = vsel /*vm=*/%vm1170, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v1796 }
  0xca   :  { %v1762 = vpop.eup %1761  ;;  %v758 = vsel /*vm=*/%vm741, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v1798  ;;  %v322 = vsel /*vm=*/%vm313, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v1800  ;;  %v1191 = vsel /*vm=*/%vm1170, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v1797 }
  0xcb   :  { %v357 = vmul.f32 %v1762, %v310  ;;  %v754 = vsel /*vm=*/%vm741, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v1799  ;;  %v318 = vsel /*vm=*/%vm313, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v1801  ;;  %v1187 = vsel /*vm=*/%vm1170, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v1798 }
  0xcc   :  { %v750 = vsel /*vm=*/%vm741, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v1800  ;;  %v1183 = vsel /*vm=*/%vm1170, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v1799  ;;  %v746 = vsel /*vm=*/%vm741, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v1801 }
  0xcd   :  { %v359 = vsel /*vm=*/%vm358, /*on_true_vy=*/%v310, /*on_false_vx=*/%v357  ;;  %v1764 = vpop.eup %1763  ;;  %v1179 = vsel /*vm=*/%vm1170, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v1800  ;;  %v1175 = vsel /*vm=*/%vm1170, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v1801 }
  0xce   :  { %v362 = vsel /*vm=*/%vm360, /*on_true_vy=*/%v361, /*on_false_vx=*/%v359  ;;  %v785 = vmul.f32 %v1764, %v738 }
  0xcf   :  { %v365 = vadd.f32 -3.0, %v362 }
  0xd0   :  { %v787 = vsel /*vm=*/%vm786, /*on_true_vy=*/%v738, /*on_false_vx=*/%v785 }
  0xd1   :  { %v369 = vsel /*vm=*/%vm313, /*on_true_vy=*/%v354, /*on_false_vx=*/%v365  ;;  %v790 = vsel /*vm=*/%vm788, /*on_true_vy=*/%v789, /*on_false_vx=*/%v787  ;;  %v1766 = vpop.eup %1765 }
  0xd2   :  { %v373 = vmul.f32 %v369, %v350  ;;  %v793 = vadd.f32 -3.0, %v790  ;;  %v1768 = vpop.eup %1767  ;;  %v1214 = vmul.f32 %v1766, %v1167 }
  0xd3   :  { %v1589 = vmul.f32 0.6931472, %v1768 }
  0xd4   :  { %v377 = vadd.f32 %v373, %v346  ;;  %v797 = vsel /*vm=*/%vm741, /*on_true_vy=*/%v782, /*on_false_vx=*/%v793  ;;  %v1216 = vsel /*vm=*/%vm1215, /*on_true_vy=*/%v1167, /*on_false_vx=*/%v1214 }
  0xd5   :  { %v801 = vmul.f32 %v797, %v778  ;;  %v1219 = vsel /*vm=*/%vm1217, /*on_true_vy=*/%v1218, /*on_false_vx=*/%v1216  ;;  %v1595 = vsel /*vm=*/%vm1594, /*on_true_vy=*/%v1592, /*on_false_vx=*/%v1589 }
  0xd6   :  { %v381 = vmul.f32 %v377, %v369  ;;  %v1222 = vadd.f32 -3.0, %v1219  ;;  %v1596 = vxor.u32 2147483648, %v1595 }
  0xd7   :  { %v805 = vadd.f32 %v801, %v774 }
  0xd8   :  { %v385 = vadd.f32 %v381, %v342  ;;  %v1226 = vsel /*vm=*/%vm1170, /*on_true_vy=*/%v1211, /*on_false_vx=*/%v1222  ;;  %1769 = vrsqrt.f32 %v1596  ;;  %vm1644 = vcmp.eq.f32.partialorder %v1596, inf }
  0xd9   :  { %v809 = vmul.f32 %v805, %v797  ;;  %v1230 = vmul.f32 %v1226, %v1207  ;;  %v1647 = vand.u32 2147483648, %v1596  ;;  %vm1646 = vcmp.eq.f32.partialorder %v1596, 0.0 }
  0xda   :  { %v389 = vmul.f32 %v385, %v369  ;;  %vm1599 = vcmp.lt.f32.partialorder %v1596, 5.0  ;;  %v1640 = vadd.f32 -2.5, %v1596 }
  0xdb   :  { %v813 = vadd.f32 %v809, %v770  ;;  %v1234 = vadd.f32 %v1230, %v1203  ;;  %v1636 = vsel /*vm=*/%vm1599, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v1793  ;;  %v1632 = vsel /*vm=*/%vm1599, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v1794 }
  0xdc   :  { %v393 = vadd.f32 %v389, %v338  ;;  %v1628 = vsel /*vm=*/%vm1599, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v1795  ;;  %v1624 = vsel /*vm=*/%vm1599, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v1796  ;;  %v1620 = vsel /*vm=*/%vm1599, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v1797 }
  0xdd   :  { %v817 = vmul.f32 %v813, %v797  ;;  %v1238 = vmul.f32 %v1234, %v1226  ;;  %v1616 = vsel /*vm=*/%vm1599, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v1798  ;;  %v1612 = vsel /*vm=*/%vm1599, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v1799 }
  0xde   :  { %v397 = vmul.f32 %v393, %v369  ;;  %v1608 = vsel /*vm=*/%vm1599, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v1800  ;;  %v1604 = vsel /*vm=*/%vm1599, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v1801 }
  0xdf   :  { %v821 = vadd.f32 %v817, %v766  ;;  %v1242 = vadd.f32 %v1238, %v1199 }
  0xe0   :  { %v401 = vadd.f32 %v397, %v334 }
  0xe1   :  { %v825 = vmul.f32 %v821, %v797  ;;  %v1246 = vmul.f32 %v1242, %v1226 }
  0xe2   :  { %v405 = vmul.f32 %v401, %v369 }
  0xe3   :  { %v829 = vadd.f32 %v825, %v762  ;;  %v1250 = vadd.f32 %v1246, %v1195 }
  0xe4   :  { %v409 = vadd.f32 %v405, %v330 }
  0xe5   :  { %v833 = vmul.f32 %v829, %v797  ;;  %v1770 = vpop.eup %1769  ;;  %v1254 = vmul.f32 %v1250, %v1226 }
  0xe6   :  { %v413 = vmul.f32 %v409, %v369  ;;  %v1643 = vmul.f32 %v1770, %v1596 }
  0xe7   :  { %v837 = vadd.f32 %v833, %v758  ;;  %v1258 = vadd.f32 %v1254, %v1191 }
  0xe8   :  { %v417 = vadd.f32 %v413, %v326  ;;  %v1645 = vsel /*vm=*/%vm1644, /*on_true_vy=*/%v1596, /*on_false_vx=*/%v1643 }
  0xe9   :  { %v841 = vmul.f32 %v837, %v797  ;;  %v1262 = vmul.f32 %v1258, %v1226  ;;  %v1648 = vsel /*vm=*/%vm1646, /*on_true_vy=*/%v1647, /*on_false_vx=*/%v1645 }
  0xea   :  { %v421 = vmul.f32 %v417, %v369  ;;  %v1651 = vadd.f32 -3.0, %v1648 }
  0xeb   :  { %v845 = vadd.f32 %v841, %v754  ;;  %v1266 = vadd.f32 %v1262, %v1187 }
  0xec   :  { %v425 = vadd.f32 %v421, %v322  ;;  %v1655 = vsel /*vm=*/%vm1599, /*on_true_vy=*/%v1640, /*on_false_vx=*/%v1651 }
  0xed   :  { %v849 = vmul.f32 %v845, %v797  ;;  %v1270 = vmul.f32 %v1266, %v1226  ;;  %v1659 = vmul.f32 %v1655, %v1636 }
  0xee   :  { %v429 = vmul.f32 %v425, %v369 }
  0xef   :  { %v853 = vadd.f32 %v849, %v750  ;;  %v1274 = vadd.f32 %v1270, %v1183  ;;  %v1663 = vadd.f32 %v1659, %v1632 }
  0xf0   :  { %v433 = vadd.f32 %v429, %v318 }
  0xf1   :  { %v857 = vmul.f32 %v853, %v797  ;;  %v1278 = vmul.f32 %v1274, %v1226  ;;  %v1667 = vmul.f32 %v1663, %v1655 }
  0xf2   :  { %v437 = vmul.f32 %v433, %v284 }
  0xf3   :  { %v861 = vadd.f32 %v857, %v746  ;;  %v1282 = vadd.f32 %v1278, %v1179  ;;  %v1671 = vadd.f32 %v1667, %v1628 }
  0xf4   :  { %v441 = vsel /*vm=*/%vm289, /*on_true_vy=*/%v294, /*on_false_vx=*/%v437 }
  0xf5   :  { %v445 = vmul.f32 1.4142135, %v441  ;;  %v865 = vmul.f32 %v861, %v712  ;;  %v1286 = vmul.f32 %v1282, %v1226  ;;  %v1675 = vmul.f32 %v1671, %v1655 }
  0xf6   :  {}
  0xf7   :  { %447 = vst [vmem:[#allocation0] sm:$0xff] /*vst_source=*/%v445  ;;  %v869 = vsel /*vm=*/%vm717, /*on_true_vy=*/%v722, /*on_false_vx=*/%v865  ;;  %v1290 = vadd.f32 %v1286, %v1175  ;;  %v1679 = vadd.f32 %v1675, %v1624 }
  0xf8   :  { %v873 = vmul.f32 1.4142135, %v869 }
  0xf9   :  { %v1294 = vmul.f32 %v1290, %v1141  ;;  %v1683 = vmul.f32 %v1679, %v1655 }
  0xfa   :  { %876 = vst [vmem:[#allocation0 + $0x8] sm:$0xff] /*vst_source=*/%v873 }
  0xfb   :  { %v1298 = vsel /*vm=*/%vm1146, /*on_true_vy=*/%v1151, /*on_false_vx=*/%v1294  ;;  %v1687 = vadd.f32 %v1683, %v1620 }
  0xfc   :  { %v1302 = vmul.f32 1.4142135, %v1298 }
  0xfd   :  { %v1691 = vmul.f32 %v1687, %v1655 }
  0xfe   :  { %1305 = vst [vmem:[#allocation0 + $0x10] sm:$0xff] /*vst_source=*/%v1302 }
  0xff   :  { %v1695 = vadd.f32 %v1691, %v1616 }
 0x100   :  {}
 0x101   :  { %v1699 = vmul.f32 %v1695, %v1655 }
 0x102   :  {}
 0x103   :  { %v1703 = vadd.f32 %v1699, %v1612 }
 0x104   :  {}
 0x105   :  { %v1707 = vmul.f32 %v1703, %v1655 }
 0x106   :  {}
 0x107   :  { %v1711 = vadd.f32 %v1707, %v1608 }
 0x108   :  {}
 0x109   :  { %v1715 = vmul.f32 %v1711, %v1655 }
 0x10a   :  {}
 0x10b   :  { %v1719 = vadd.f32 %v1715, %v1604 }
 0x10c   :  {}
 0x10d   :  { %v1723 = vmul.f32 %v1719, %v1570 }
 0x10e   :  {}
 0x10f   :  { %v1727 = vsel /*vm=*/%vm1575, /*on_true_vy=*/%v1580, /*on_false_vx=*/%v1723 }
 0x110   :  { %v1731 = vmul.f32 1.4142135, %v1727 }
 0x111   :  {}
 0x112   :  { %1734 = vst [vmem:[#allocation0 + $0x18] sm:$0xff] /*vst_source=*/%v1731 }
 0x113   :  { %1782 = shalt.err (!%p1779) /* BoundsCheck 7 [deref of %s1740] for %1742 = dma.vmem_to_hbm [thread:$0]  /*vmem=*/%s1740, /*size_in_granules=*/512, /*hbm=*/%s6, /*dst_syncflagno=*/[#allocation2] /* 
base_bounds: (4, 1)
dynamic_base_bounds: (4, 1)
window_bounds: (4, 1)
iteration_bounds: (1, 1)
strides: (4, 1)
pad_low: (0, 0)
pad_high: (0, 0)
element_size_in_bytes: 4096 */
hlo: select_multiply_fusion
 */ }
 0x114   :  { %1742 = dma.vmem_to_hbm [thread:$0]  /*vmem=*/%s1740, /*size_in_granules=*/512, /*hbm=*/%s6, /*dst_syncflagno=*/[#allocation2] /* 
base_bounds: (4, 1)
dynamic_base_bounds: (4, 1)
window_bounds: (4, 1)
iteration_bounds: (1, 1)
strides: (4, 1)
pad_low: (0, 0)
pad_high: (0, 0)
element_size_in_bytes: 4096 */ }
 0x115   :  { %1791 = dma.done.wait [#allocation2], 512 /* pipeline-emitter-dma-wait */ }
 0x116   :  { %1792 = vsyncadd [#allocation2], 4294966784 }
 0x117   :  { %1744 = vsyncpa [#allocation2], 1 } /* End region 0 :: End region 1 */
