
%s217 = sld [smem:[#allocation21]]
%s218 = sand.u32 134217727, %s217
%s219 = sor.u32 4026531840, %s218

%220 = vtrace %s219

%s211 = sld [smem:[#allocation18]]

%212 = vtrace %s211

%s213 = sld [smem:[#allocation19]]

%214 = vtrace %s213

%s215 = sld [smem:[#allocation20]]

%216 = vtrace %s215

%v198 = vlaneseq
%v199 = vshrl.u32 %v198, 7
%v200 = vshrl.u32 %v199, 1
%v201 = vand.u32 1, %v199
%v202 = vshll.u32 %v201, 2
%v203 = vadd.s32 %v202, %v200
%v204 = vsub.s32 %v203, %v199
%205 = vsetiar.raw.iar0 %v204 /* EvenOdd Store IAR initialization */
%v209 = vsub.s32 %v200, %v199
%210 = vsetiar.raw.iar1 %v209 /* EvenOdd Load IAR initialization */
%s78 = sld [smem:[#allocation15]]

%p221 = scmp.eq.s32.totalorder %s78, 0

%82 = sbr.rel (%p221) target = $region38

%v87 = vand.u32 127, %v198
%v91 = vxor.u32 1135663077, %v87
%v92 = vmul.u32 2925155241, %v91
%v93 = vshrl.u32 %v92, 16
%v94 = vxor.u32 %v93, %v92
%s95 = sxor.u32 2925155241, %s78
%s96 = smul.u32 2223506493, %s95
%s97 = sshrl.u32 %s96, 16
%s98 = sxor.u32 %s97, %s96
%v99 = vxor.u32 2223506493, %v94
%v100 = vmul.u32 1519409121, %v99
%v101 = vshrl.u32 %v100, 16
%v102 = vxor.u32 %v101, %v100
%s103 = smul.u32 3389127133, %s98
%v104 = vmul.u32 1232336661, %v102
%v105 = vstv %s103
%v106 = vsub.s32 %v105, %v104
%v107 = vshrl.u32 %v106, 16
%v108 = vxor.u32 %v107, %v106
%v109 = vxor.u32 1519409121, %v108
%v110 = vmul.u32 2449846741, %v109
%v111 = vshrl.u32 %v110, 16
%v112 = vxor.u32 %v111, %v110
%v113 = vmul.u32 3389127133, %v94
%v114 = vmul.u32 1232336661, %v112
%v115 = vsub.s32 %v113, %v114
%v116 = vshrl.u32 %v115, 16
%v117 = vxor.u32 %v116, %v115
%v118 = vxor.u32 1135663077, %v117
%v119 = vmul.u32 2925155241, %v118
%v120 = vshrl.u32 %v119, 16
%v121 = vxor.u32 %v120, %v119
%v122 = vxor.u32 2925155241, %v108
%v123 = vmul.u32 2223506493, %v122
%v124 = vshrl.u32 %v123, 16
%v125 = vxor.u32 %v124, %v123
%v126 = vxor.u32 2223506493, %v121
%v127 = vmul.u32 1519409121, %v126
%v128 = vshrl.u32 %v127, 16
%v129 = vxor.u32 %v128, %v127
%v130 = vmul.u32 3389127133, %v125
%v131 = vmul.u32 1232336661, %v129
%v132 = vsub.s32 %v130, %v131
%v133 = vshrl.u32 %v132, 16
%v134 = vxor.u32 %v133, %v132
%v135 = vxor.u32 1519409121, %v134
%v136 = vmul.u32 2449846741, %v135
%v137 = vshrl.u32 %v136, 16
%v138 = vxor.u32 %v137, %v136
%v139 = vmul.u32 3389127133, %v121
%v140 = vmul.u32 1232336661, %v138
%v141 = vsub.s32 %v139, %v140
%v142 = vshrl.u32 %v141, 16
%v143 = vxor.u32 %v142, %v141
%v144 = vxor.u32 2337405405, %v143
%v145 = vmul.u32 1179257497, %v144
%v146 = vshrl.u32 %v145, 16
%v147 = vxor.u32 %v146, %v145
%v148 = vxor.u32 747796405, %v143
%v149 = vmul.u32 461070425, %v148
%v150 = vshrl.u32 %v149, 16
%v151 = vxor.u32 %v150, %v149
%v152 = vxor.u32 1179257497, %v134
%v153 = vmul.u32 2174555301, %v152
%v154 = vshrl.u32 %v153, 16
%v155 = vxor.u32 %v154, %v153
%v156 = vxor.u32 461070425, %v134
%v157 = vmul.u32 702470093, %v156
%v158 = vshrl.u32 %v157, 16
%v159 = vxor.u32 %v158, %v157
%v160 = vxor.u32 2174555301, %v143
%v161 = vmul.u32 3546938817, %v160
%v162 = vshrl.u32 %v161, 16
%v163 = vxor.u32 %v162, %v161
%v164 = vxor.u32 702470093, %v143
%v165 = vmul.u32 728804945, %v164
%v166 = vshrl.u32 %v165, 16
%v167 = vxor.u32 %v166, %v165
%v168 = vxor.u32 3546938817, %v134
%v169 = vmul.u32 1343633581, %v168
%v170 = vshrl.u32 %v169, 16
%v171 = vxor.u32 %v170, %v169
%v172 = vxor.u32 728804945, %v134
%v173 = vmul.u32 1920080165, %v172
%v174 = vshrl.u32 %v173, 16
%v175 = vxor.u32 %v174, %v173
%v176 = vor.u32 %v155, %v147
%v177 = vor.u32 %v176, %v163
%v178 = vor.u32 %v177, %v171
%vm179 = vcmp.eq.s32.totalorder %v178, 0
%vm222 = vcmp.eq.s32.totalorder %v199, 1
%vm223 = vcmp.eq.s32.totalorder %v199, 2
%vm224 = vcmp.eq.s32.totalorder %v199, 3
%v189 = vsel /*vm=*/%vm179, /*on_true_vy=*/%v151, /*on_false_vx=*/%v147
%v190 = vsel /*vm=*/%vm179, /*on_true_vy=*/%v159, /*on_false_vx=*/%v155
%v191 = vsel /*vm=*/%vm222, /*on_true_vy=*/%v190, /*on_false_vx=*/%v189
%v192 = vsel /*vm=*/%vm179, /*on_true_vy=*/%v167, /*on_false_vx=*/%v163
%v193 = vsel /*vm=*/%vm223, /*on_true_vy=*/%v192, /*on_false_vx=*/%v191
%v194 = vsel /*vm=*/%vm179, /*on_true_vy=*/%v175, /*on_false_vx=*/%v171
%v195 = vsel /*vm=*/%vm224, /*on_true_vy=*/%v194, /*on_false_vx=*/%v193
%196 = setrngseed %v195 /* Rng seed initialization */
%v197 = vrng /* Rng seed initialization */

%73 = vsettm 1

%s230 = smov 2147483646 /* materialized constant */

%72 = vsettm %s230

%70 = vtrace 2415919103

%0 = vtrace 2952790016

%1 = vtrace 3221225472

%s2 = sld [smem:[#allocation0]]

%p225 = scmp.ne.s32.totalorder %s2, 1

%6 = sbr.rel (%p225) target = $region4

%s7 = sld [smem:[#allocation2]]
%s8 = int_to_ptr.hbm [resolvable:$false] %s7

%s9 = scalar_parameter_address 0

%s10 = scalar_parameter_address 1

%s11 = scalar_parameter_address 2

%12 = compiler-scheduling-barrier

%14 = compiler-scheduling-barrier

%29 = vtrace 2147483648

%15 = compiler-scheduling-barrier

%17 = vsyncpa [#allocation8], 0
%s18 = sld [smem:[#allocation9]]
%p19 = scmp.ne.s32.totalorder %s18, 0
%s20 = scalar_select /*predicate=*/%p19, /*on_true=*/256, /*on_false=*/0

%21 = vsyncadd [#allocation8], %s20
%s22 = scalar_select /*predicate=*/%p19, /*on_true=*/0, /*on_false=*/256
%s231 = smov [#allocation7] /* materialized constant */
%s23 = sshll.u32 %s231, 4
%s24 = int_to_ptr.vmem [resolvable:$true] %s23
%26 = dma.hbm_to_vmem [thread:$1]  /*hbm=*/%s9, /*size_in_granules=*/%s22, /*vmem=*/%s24, /*dst_syncflagno=*/[#allocation8]

%28 = compiler-scheduling-barrier

%30 = vtrace 2415919104

%31 = compiler-scheduling-barrier

%33 = compiler-scheduling-barrier

%34 = compiler-scheduling-barrier

%36 = compiler-scheduling-barrier

%37 = compiler-scheduling-barrier

%38 = vsyncpa [#allocation11], 0
%s232 = smov [#allocation10] /* materialized constant */
%s39 = sshll.u32 %s232, 4
%s40 = int_to_ptr.vmem [resolvable:$true] %s39
%42 = dma.hbm_to_vmem [thread:$0]  /*hbm=*/%s11, /*size_in_granules=*/1, /*vmem=*/%s40, /*dst_syncflagno=*/[#allocation11]

%43 = dma.done [#allocation11], 1 /* local-dma-wait */

%44 = vsyncpa [#allocation11], 1

%v45 = vld [vmem:[#allocation10] sm:$0xff]

%226 = vpush %v45
%s227 = spop %226

%47 = compiler-scheduling-barrier

%48 = compiler-scheduling-barrier

%49 = vsyncpa [#allocation13], 0
%s233 = smov [#allocation12] /* materialized constant */
%s50 = sshll.u32 %s233, 4
%s51 = int_to_ptr.vmem [resolvable:$true] %s50
%53 = dma.hbm_to_vmem [thread:$0]  /*hbm=*/%s10, /*size_in_granules=*/1, /*vmem=*/%s51, /*dst_syncflagno=*/[#allocation13]

%54 = dma.done [#allocation13], 1 /* local-dma-wait */

%55 = vsyncpa [#allocation13], 1

%v56 = vld [vmem:[#allocation12] sm:$0xff]

%228 = vpush %v56
%s229 = spop %228

%58 = compiler-scheduling-barrier

%63 = vtrace 2147483649

%59 = compiler-scheduling-barrier

%60 = dma.done [#allocation8], 256 /* local-dma-wait */

%61 = vsyncpa [#allocation8], 1

%62 = compiler-scheduling-barrier

%64 = vtrace 2415919105

%68 = vtrace 2147483650

%65 = compiler-scheduling-barrier

%s234 = smov [#allocation7] /* materialized constant */

%66 = inlined_call %s234, %s229, %s227, %s8 /* %dynamic-slice.4 = dynamic-slice(%copy-done, %copy, %copy.1) */

%67 = compiler-scheduling-barrier

%69 = vtrace 2415919106

%71 = vtrace 2684354559

%s235 = smov 2147483647 /* materialized constant */

%74 = vsettm %s235

%75 = vdelay 1

%76 = sfence

%s236 = smov 0 /* materialized constant */
%77 = sst [smem:[#allocation14]] %s236
