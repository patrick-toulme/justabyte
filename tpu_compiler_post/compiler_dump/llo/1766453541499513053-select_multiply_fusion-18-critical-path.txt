
New basic block in region: region0 {members=11 hlo=select_multiply_fusion parent=-1}
  Length to end: 1, %s3 = inlined_call_operand.<no memory space> [shape: u32[], index: 3, kind: input, shape index: {}] /* operand 3 */

New basic block in region: region1 {members=400 hlo=select_multiply_fusion parent=0}
  Length to end: 363, %v17 = vld [vmem:[%s0] ss:$0 sm:$0xff]
  Length to end: 362, %19 = vbcast.lane.b32.xlu1 %v17, 256
  Length to end: 358, %23 = vbcast.lane.b32.xlu1 %v21, 256
  Length to end: 354, %465 = vbcast.lane.b32.xlu1 %v462, 264
  Length to end: 240, %v466 = vpop.permute.xlu1 %465
  Length to end: 239, %v487 = vsel /*vm=*/%vm482, /*on_true_vy=*/%v461, /*on_false_vx=*/%v466
  Length to end: 238, %v492 = vadd.s32 %v487, %v9
  Length to end: 236, %v500 = vadd.s32 %v496, %v492
  Length to end: 234, %v505 = vxor.u32 %v504, %v500
  Length to end: 232, %v510 = vshll.u32 %v505, 15
  Length to end: 230, %v512 = vor.u32 %v511, %v510
  Length to end: 228, %v513 = vxor.u32 %v512, %v508
  Length to end: 226, %v518 = vshll.u32 %v513, 26
  Length to end: 224, %v520 = vor.u32 %v519, %v518
  Length to end: 222, %v521 = vxor.u32 %v520, %v516
  Length to end: 220, %v530 = vshll.u32 %v521, 6
  Length to end: 218, %v532 = vor.u32 %v531, %v530
  Length to end: 216, %v533 = vxor.u32 %v532, %v524
  Length to end: 214, %v536 = vadd.s32 %v533, %v7
  Length to end: 212, %v540 = vadd.s32 1, %v536
  Length to end: 210, %v546 = vshll.u32 %v540, 17
  Length to end: 208, %v548 = vor.u32 %v547, %v546
  Length to end: 206, %v549 = vxor.u32 %v548, %v544
  Length to end: 204, %v554 = vshll.u32 %v549, 29
  Length to end: 202, %v556 = vor.u32 %v555, %v554
  Length to end: 200, %v557 = vxor.u32 %v556, %v552
  Length to end: 198, %v562 = vshll.u32 %v557, 16
  Length to end: 196, %v564 = vor.u32 %v563, %v562
  Length to end: 194, %v565 = vxor.u32 %v564, %v560
  Length to end: 192, %v574 = vshll.u32 %v565, 24
  Length to end: 190, %v576 = vor.u32 %v575, %v574
  Length to end: 188, %v577 = vxor.u32 %v576, %v568
  Length to end: 186, %v580 = vadd.s32 %v577, %v9
  Length to end: 184, %v584 = vadd.s32 2, %v580
  Length to end: 182, %v590 = vshll.u32 %v584, 13
  Length to end: 180, %v592 = vor.u32 %v591, %v590
  Length to end: 178, %v593 = vxor.u32 %v592, %v588
  Length to end: 176, %v598 = vshll.u32 %v593, 15
  Length to end: 174, %v600 = vor.u32 %v599, %v598
  Length to end: 172, %v601 = vxor.u32 %v600, %v596
  Length to end: 170, %v606 = vshll.u32 %v601, 26
  Length to end: 168, %v608 = vor.u32 %v607, %v606
  Length to end: 166, %v609 = vxor.u32 %v608, %v604
  Length to end: 164, %v618 = vshll.u32 %v609, 6
  Length to end: 162, %v620 = vor.u32 %v619, %v618
  Length to end: 160, %v621 = vxor.u32 %v620, %v612
  Length to end: 158, %v624 = vadd.s32 %v621, %v8
  Length to end: 156, %v628 = vadd.s32 3, %v624
  Length to end: 154, %v634 = vshll.u32 %v628, 17
  Length to end: 152, %v636 = vor.u32 %v635, %v634
  Length to end: 150, %v637 = vxor.u32 %v636, %v632
  Length to end: 148, %v642 = vshll.u32 %v637, 29
  Length to end: 146, %v644 = vor.u32 %v643, %v642
  Length to end: 144, %v645 = vxor.u32 %v644, %v640
  Length to end: 142, %v650 = vshll.u32 %v645, 16
  Length to end: 140, %v652 = vor.u32 %v651, %v650
  Length to end: 138, %v653 = vxor.u32 %v652, %v648
  Length to end: 136, %v662 = vshll.u32 %v653, 24
  Length to end: 134, %v664 = vor.u32 %v663, %v662
  Length to end: 132, %v665 = vxor.u32 %v664, %v656
  Length to end: 130, %v668 = vadd.s32 %v665, %v7
  Length to end: 128, %v672 = vadd.s32 4, %v668
  Length to end: 126, %v678 = vshll.u32 %v672, 13
  Length to end: 124, %v680 = vor.u32 %v679, %v678
  Length to end: 122, %v681 = vxor.u32 %v680, %v676
  Length to end: 120, %v686 = vshll.u32 %v681, 15
  Length to end: 118, %v688 = vor.u32 %v687, %v686
  Length to end: 116, %v689 = vxor.u32 %v688, %v684
  Length to end: 114, %v694 = vshll.u32 %v689, 26
  Length to end: 112, %v696 = vor.u32 %v695, %v694
  Length to end: 110, %v697 = vxor.u32 %v696, %v692
  Length to end: 108, %v706 = vshll.u32 %v697, 6
  Length to end: 106, %v708 = vor.u32 %v707, %v706
  Length to end: 104, %v709 = vxor.u32 %v708, %v700
  Length to end: 102, %v712 = vadd.s32 %v709, %v9
  Length to end: 100, %v716 = vadd.s32 5, %v712
  Length to end: 98, %v718 = vxor.u32 %v716, %v704
  Length to end: 96, %v719 = vshrl.u32 %v718, 9
  Length to end: 94, %v720 = vor.u32 1065353216, %v719
  Length to end: 92, %v724 = vadd.f32 -1.0, %v720
  Length to end: 90, %v728 = vmul.f32 2.0, %v724
  Length to end: 88, %v732 = vadd.f32 -0.99999994, %v728
  Length to end: 86, %v736 = vmax.f32 %v732, -0.99999994
  Length to end: 84, %v748 = vxor.u32 2147483648, %v736
  Length to end: 82, %v751 = vmul.f32 %v748, %v736
  Length to end: 80, %v753 = vadd.f32 1.0, %v751
  Length to end: 78, %v754 = vlog2.pop %v753
  Length to end: 64, %v755 = vmul.f32 0.6931472, %v754
  Length to end: 62, %v761 = vsel /*vm=*/%vm760, /*on_true_vy=*/%v758, /*on_false_vx=*/%v755
  Length to end: 61, %v762 = vxor.u32 2147483648, %v761
  Length to end: 59, %v808 = vrsqrt.pop %v762
  Length to end: 45, %v809 = vmul.f32 %v808, %v762
  Length to end: 43, %v811 = vsel /*vm=*/%vm810, /*on_true_vy=*/%v762, /*on_false_vx=*/%v809
  Length to end: 42, %v814 = vsel /*vm=*/%vm812, /*on_true_vy=*/%v813, /*on_false_vx=*/%v811
  Length to end: 41, %v817 = vadd.f32 -3.0, %v814
  Length to end: 39, %v821 = vsel /*vm=*/%vm765, /*on_true_vy=*/%v806, /*on_false_vx=*/%v817
  Length to end: 38, %v825 = vmul.f32 %v821, %v802
  Length to end: 36, %v829 = vadd.f32 %v825, %v798
  Length to end: 34, %v833 = vmul.f32 %v829, %v821
  Length to end: 32, %v837 = vadd.f32 %v833, %v794
  Length to end: 30, %v841 = vmul.f32 %v837, %v821
  Length to end: 28, %v845 = vadd.f32 %v841, %v790
  Length to end: 26, %v849 = vmul.f32 %v845, %v821
  Length to end: 24, %v853 = vadd.f32 %v849, %v786
  Length to end: 22, %v857 = vmul.f32 %v853, %v821
  Length to end: 20, %v861 = vadd.f32 %v857, %v782
  Length to end: 18, %v865 = vmul.f32 %v861, %v821
  Length to end: 16, %v869 = vadd.f32 %v865, %v778
  Length to end: 14, %v873 = vmul.f32 %v869, %v821
  Length to end: 12, %v877 = vadd.f32 %v873, %v774
  Length to end: 10, %v881 = vmul.f32 %v877, %v821
  Length to end: 8, %v885 = vadd.f32 %v881, %v770
  Length to end: 6, %v889 = vmul.f32 %v885, %v736
  Length to end: 4, %v893 = vsel /*vm=*/%vm741, /*on_true_vy=*/%v746, /*on_false_vx=*/%v889
  Length to end: 3, %v897 = vmul.f32 1.4142135, %v893
  Length to end: 1, %900 = vst [vmem:[#allocation0 + $0x8] sm:$0xff] /*vst_source=*/%v897
