= control target key start
LH: loop header
LB: loop body
LE: loop exit
PB: predicated region body
PF: predicated region fallthrough
CT: control target
= control target key end

     0   :  { %s1121_s0 = inlined_call_operand.vmem [shape: u32[16], index: 0, kind: input, shape index: {}] /* operand 0 */  ;;  %s1122_s1 = inlined_call_operand.vmem [shape: u32[16], index: 1, kind: input, shape index: {}] /* operand 1 */  ;;  %s1123_s2 = inlined_call_operand.vmem [shape: u32[16], index: 2, kind: input, shape index: {}] /* operand 2 */  ;;  %s1124_s3 = inlined_call_operand.<no memory space> [shape: u32[], index: 3, kind: input, shape index: {}] /* operand 3 */  ;;  %s1125_s4 = inlined_call_operand.<no memory space> [shape: u32[], index: 4, kind: input, shape index: {}] /* operand 4 */  ;;  %s1126_s5 = inlined_call_operand.<no memory space> [shape: u32[], index: 5, kind: input, shape index: {}] /* operand 5 */  ;;  %s1127_s6 = inlined_call_operand.hbm [shape: f32[16,64], index: 6, kind: output, shape index: {}] /* operand 6 */ } /* entry bundle: %select_multiply_fusion = fusion(%broadcast_add_fusion, %get-tuple-element.5, %get-tuple-element.4, %xor.50, %bitcast.1, %bitcast) */
   0x1   :  { %v999_v0 = vstv %s1124_s3  ;;  %v1004_v1 = vstv %s1125_s4  ;;  %v1009_v2 = vstv %s1126_s5 }
   0x2   :  { %v25_v3 = vld [vmem:[%s1123_s2] ss:$0 sm:$0xff] } /* Start region 1 */
   0x3   :  { %v17_v4 = vld [vmem:[%s1121_s0] ss:$0 sm:$0xff]  ;;  %27 = vbcast.lane.b32.xlu0 %v25_v3, 256 }
   0x4   :  { %19 = vbcast.lane.b32.xlu1 %v17_v4, 256 }
   0x5   :  { %10 = vsyncpa [#allocation2], 0  ;;  %v21_v5 = vld [vmem:[%s1122_s1] ss:$0 sm:$0xff]  ;;  %v29_v6 = vlaneseq  ;;  %s960_s1 = smov [#allocation0] /* materialized constant */ }
   0x6   :  { %s905_s28 = sshll.u32 %s960_s1, 4  ;;  %s906_s28 = int_to_ptr.vmem [resolvable:$true] %s905_s28 }
   0x7   :  { %470 = vbcast.lane.b32.xlu0 %v25_v3, 264  ;;  %v30_v7 = vand.u32 127, %v29_v6  ;;  %s929_s29 = scalar_lea.vmem %s906_s28, 256  ;;  %p934_p1 = scmp.lt.s32.totalorder %s906_s28, %s906_s28 }
   0x8   :  { %23 = vbcast.lane.b32.xlu1 %v21_v5, 256  ;;  %p930_p0 = scmp.ne.s32.totalorder %s906_s28, %s929_s29  ;;  %p935_p2 = scmp.lt.s32.totalorder %s929_s29, %s929_s29 }
   0x9   :  { %p936_p3 = por %p935_p2, %p934_p1 }
   0xa   :  { %460 = vbcast.lane.b32.xlu0 %v17_v4, 264 }
   0xb   :  { %465 = vbcast.lane.b32.xlu1 %v21_v5, 264  ;;  %p937_p4 = pnand %p936_p3, %p930_p0 }
   0xc   :  { %v28_v8 = vpop.permute.xlu0 %27 }
   0xd   :  { %v20_v9 = vpop.permute.xlu1 %19  ;;  %v35_v10 = vadd.s32 %v30_v7, %v28_v8 }
   0xe   :  { %vm39_vm0 = vcmp.lt.u32.totalorder %v35_v10, %v28_v8  ;;  %v53_v11 = vadd.s32 %v35_v10, %v1004_v1 }
   0xf   :  { %v471_v12 = vpop.permute.xlu0 %470 }
  0x10   :  { %v24_v13 = vpop.permute.xlu1 %23  ;;  %v59_v14 = vshll.u32 %v53_v11, 13  ;;  %v60_v15 = vshrl.u32 %v53_v11, 19  ;;  %v478_v16 = vadd.s32 %v471_v12, %v30_v7 }
  0x11   :  { %v44_v17 = vsel /*vm=*/%vm39_vm0, /*on_true_vy=*/%v20_v9, /*on_false_vx=*/%v24_v13 }
  0x12   :  { %v49_v18 = vadd.s32 %v44_v17, %v1009_v2  ;;  %v61_v19 = vor.u32 %v60_v15, %v59_v14  ;;  %vm482_vm1 = vcmp.lt.u32.totalorder %v478_v16, %v471_v12  ;;  %v496_v20 = vadd.s32 %v478_v16, %v1004_v1 }
  0x13   :  { %v461_v21 = vpop.permute.xlu0 %460 }
  0x14   :  { %v466_v22 = vpop.permute.xlu1 %465  ;;  %v57_v23 = vadd.s32 %v53_v11, %v49_v18  ;;  %v502_v24 = vshll.u32 %v496_v20, 13  ;;  %v503_v25 = vshrl.u32 %v496_v20, 19 }
  0x15   :  { %v487_v26 = vsel /*vm=*/%vm482_vm1, /*on_true_vy=*/%v461_v21, /*on_false_vx=*/%v466_v22 }
  0x16   :  { %v62_v27 = vxor.u32 %v61_v19, %v57_v23  ;;  %v492_v28 = vadd.s32 %v487_v26, %v1009_v2  ;;  %v504_v29 = vor.u32 %v503_v25, %v502_v24 }
  0x17   :  { %v65_v30 = vadd.s32 %v62_v27, %v57_v23  ;;  %v67_v31 = vshll.u32 %v62_v27, 15  ;;  %v68_v32 = vshrl.u32 %v62_v27, 17  ;;  %v500_v33 = vadd.s32 %v496_v20, %v492_v28 }
  0x18   :  { %v69_v34 = vor.u32 %v68_v32, %v67_v31  ;;  %v505_v35 = vxor.u32 %v504_v29, %v500_v33 }
  0x19   :  { %v70_v36 = vxor.u32 %v69_v34, %v65_v30  ;;  %v508_v37 = vadd.s32 %v505_v35, %v500_v33  ;;  %v510_v38 = vshll.u32 %v505_v35, 15  ;;  %v511_v39 = vshrl.u32 %v505_v35, 17 }
  0x1a   :  { %v73_v40 = vadd.s32 %v70_v36, %v65_v30  ;;  %v75_v41 = vshll.u32 %v70_v36, 26  ;;  %v76_v42 = vshrl.u32 %v70_v36, 6  ;;  %v512_v43 = vor.u32 %v511_v39, %v510_v38 }
  0x1b   :  { %v77_v44 = vor.u32 %v76_v42, %v75_v41  ;;  %v513_v45 = vxor.u32 %v512_v43, %v508_v37 }
  0x1c   :  { %v78_v46 = vxor.u32 %v77_v44, %v73_v40  ;;  %v516_v47 = vadd.s32 %v513_v45, %v508_v37  ;;  %v518_v48 = vshll.u32 %v513_v45, 26  ;;  %v519_v49 = vshrl.u32 %v513_v45, 6 }
  0x1d   :  { %v81_v50 = vadd.s32 %v78_v46, %v73_v40  ;;  %v87_v51 = vshll.u32 %v78_v46, 6  ;;  %v88_v52 = vshrl.u32 %v78_v46, 26  ;;  %v520_v53 = vor.u32 %v519_v49, %v518_v48 }
  0x1e   :  { %v89_v54 = vor.u32 %v88_v52, %v87_v51  ;;  %v521_v55 = vxor.u32 %v520_v53, %v516_v47  ;;  %v85_v62 = vadd.s32 %v81_v50, %v1004_v1 }
  0x1f   :  { %v90_v56 = vxor.u32 %v89_v54, %v81_v50  ;;  %v524_v57 = vadd.s32 %v521_v55, %v516_v47  ;;  %v530_v58 = vshll.u32 %v521_v55, 6  ;;  %v531_v59 = vshrl.u32 %v521_v55, 26 }
  0x20   :  { %v93_v60 = vadd.s32 %v90_v56, %v999_v0  ;;  %v532_v61 = vor.u32 %v531_v59, %v530_v58  ;;  %v528_v9 = vadd.s32 %v524_v57, %v1004_v1 }
  0x21   :  { %v97_v63 = vadd.s32 1, %v93_v60  ;;  %v533_v3 = vxor.u32 %v532_v61, %v524_v57 }
  0x22   :  { %v101_v4 = vadd.s32 %v97_v63, %v85_v62  ;;  %v103_v5 = vshll.u32 %v97_v63, 17  ;;  %v104_v6 = vshrl.u32 %v97_v63, 15  ;;  %v536_v7 = vadd.s32 %v533_v3, %v999_v0 }
  0x23   :  { %v105_v8 = vor.u32 %v104_v6, %v103_v5  ;;  %v540_v10 = vadd.s32 1, %v536_v7 }
  0x24   :  { %v106_v11 = vxor.u32 %v105_v8, %v101_v4  ;;  %v544_v12 = vadd.s32 %v540_v10, %v528_v9  ;;  %v546_v13 = vshll.u32 %v540_v10, 17  ;;  %v547_v14 = vshrl.u32 %v540_v10, 15 }
  0x25   :  { %v109_v15 = vadd.s32 %v106_v11, %v101_v4  ;;  %v111_v16 = vshll.u32 %v106_v11, 29  ;;  %v112_v17 = vshrl.u32 %v106_v11, 3  ;;  %v548_v18 = vor.u32 %v547_v14, %v546_v13 }
  0x26   :  { %v113_v19 = vor.u32 %v112_v17, %v111_v16  ;;  %v549_v20 = vxor.u32 %v548_v18, %v544_v12 }
  0x27   :  { %v114_v21 = vxor.u32 %v113_v19, %v109_v15  ;;  %v552_v22 = vadd.s32 %v549_v20, %v544_v12  ;;  %v554_v23 = vshll.u32 %v549_v20, 29  ;;  %v555_v24 = vshrl.u32 %v549_v20, 3 }
  0x28   :  { %v117_v25 = vadd.s32 %v114_v21, %v109_v15  ;;  %v119_v26 = vshll.u32 %v114_v21, 16  ;;  %v120_v27 = vshrl.u32 %v114_v21, 16  ;;  %v556_v28 = vor.u32 %v555_v24, %v554_v23 }
  0x29   :  { %v121_v29 = vor.u32 %v120_v27, %v119_v26  ;;  %v557_v30 = vxor.u32 %v556_v28, %v552_v22 }
  0x2a   :  { %v122_v31 = vxor.u32 %v121_v29, %v117_v25  ;;  %v560_v32 = vadd.s32 %v557_v30, %v552_v22  ;;  %v562_v33 = vshll.u32 %v557_v30, 16  ;;  %v563_v34 = vshrl.u32 %v557_v30, 16 }
  0x2b   :  { %v125_v35 = vadd.s32 %v122_v31, %v117_v25  ;;  %v131_v36 = vshll.u32 %v122_v31, 24  ;;  %v132_v37 = vshrl.u32 %v122_v31, 8  ;;  %v564_v38 = vor.u32 %v563_v34, %v562_v33 }
  0x2c   :  { %v133_v39 = vor.u32 %v132_v37, %v131_v36  ;;  %v565_v40 = vxor.u32 %v564_v38, %v560_v32  ;;  %v129_v46 = vadd.s32 %v125_v35, %v999_v0 }
  0x2d   :  { %v134_v41 = vxor.u32 %v133_v39, %v125_v35  ;;  %v568_v42 = vadd.s32 %v565_v40, %v560_v32  ;;  %v574_v43 = vshll.u32 %v565_v40, 24  ;;  %v575_v44 = vshrl.u32 %v565_v40, 8 }
  0x2e   :  { %v137_v45 = vadd.s32 %v134_v41, %v1009_v2  ;;  %v576_v48 = vor.u32 %v575_v44, %v574_v43  ;;  %v572_v56 = vadd.s32 %v568_v42, %v999_v0 }
  0x2f   :  { %v141_v47 = vadd.s32 2, %v137_v45  ;;  %v577_v52 = vxor.u32 %v576_v48, %v568_v42 }
  0x30   :  { %v145_v49 = vadd.s32 %v141_v47, %v129_v46  ;;  %v147_v50 = vshll.u32 %v141_v47, 13  ;;  %v148_v51 = vshrl.u32 %v141_v47, 19  ;;  %v580_v54 = vadd.s32 %v577_v52, %v1009_v2 }
  0x31   :  { %v149_v53 = vor.u32 %v148_v51, %v147_v50  ;;  %v584_v57 = vadd.s32 2, %v580_v54 }
  0x32   :  { %v150_v55 = vxor.u32 %v149_v53, %v145_v49  ;;  %v588_v61 = vadd.s32 %v584_v57, %v572_v56  ;;  %v590_v62 = vshll.u32 %v584_v57, 13  ;;  %v591_v63 = vshrl.u32 %v584_v57, 19 }
  0x33   :  { %v153_v58 = vadd.s32 %v150_v55, %v145_v49  ;;  %v155_v59 = vshll.u32 %v150_v55, 15  ;;  %v156_v60 = vshrl.u32 %v150_v55, 17  ;;  %v592_v4 = vor.u32 %v591_v63, %v590_v62 }
  0x34   :  { %v157_v3 = vor.u32 %v156_v60, %v155_v59  ;;  %v593_v6 = vxor.u32 %v592_v4, %v588_v61 }
  0x35   :  { %v158_v5 = vxor.u32 %v157_v3, %v153_v58  ;;  %v596_v10 = vadd.s32 %v593_v6, %v588_v61  ;;  %v598_v11 = vshll.u32 %v593_v6, 15  ;;  %v599_v12 = vshrl.u32 %v593_v6, 17 }
  0x36   :  { %v161_v7 = vadd.s32 %v158_v5, %v153_v58  ;;  %v163_v8 = vshll.u32 %v158_v5, 26  ;;  %v164_v9 = vshrl.u32 %v158_v5, 6  ;;  %v600_v14 = vor.u32 %v599_v12, %v598_v11 }
  0x37   :  { %v165_v13 = vor.u32 %v164_v9, %v163_v8  ;;  %v601_v16 = vxor.u32 %v600_v14, %v596_v10 }
  0x38   :  { %v166_v15 = vxor.u32 %v165_v13, %v161_v7  ;;  %v604_v20 = vadd.s32 %v601_v16, %v596_v10  ;;  %v606_v21 = vshll.u32 %v601_v16, 26  ;;  %v607_v22 = vshrl.u32 %v601_v16, 6 }
  0x39   :  { %v169_v17 = vadd.s32 %v166_v15, %v161_v7  ;;  %v175_v18 = vshll.u32 %v166_v15, 6  ;;  %v176_v19 = vshrl.u32 %v166_v15, 26  ;;  %v608_v24 = vor.u32 %v607_v22, %v606_v21 }
  0x3a   :  { %v177_v23 = vor.u32 %v176_v19, %v175_v18  ;;  %v609_v26 = vxor.u32 %v608_v24, %v604_v20  ;;  %v173_v31 = vadd.s32 %v169_v17, %v1009_v2 }
  0x3b   :  { %v178_v25 = vxor.u32 %v177_v23, %v169_v17  ;;  %v612_v28 = vadd.s32 %v609_v26, %v604_v20  ;;  %v618_v29 = vshll.u32 %v609_v26, 6  ;;  %v619_v30 = vshrl.u32 %v609_v26, 26 }
  0x3c   :  { %v181_v27 = vadd.s32 %v178_v25, %v1004_v1  ;;  %v620_v33 = vor.u32 %v619_v30, %v618_v29  ;;  %v616_v41 = vadd.s32 %v612_v28, %v1009_v2 }
  0x3d   :  { %v185_v32 = vadd.s32 3, %v181_v27  ;;  %v621_v37 = vxor.u32 %v620_v33, %v612_v28 }
  0x3e   :  { %v189_v34 = vadd.s32 %v185_v32, %v173_v31  ;;  %v191_v35 = vshll.u32 %v185_v32, 17  ;;  %v192_v36 = vshrl.u32 %v185_v32, 15  ;;  %v624_v39 = vadd.s32 %v621_v37, %v1004_v1 }
  0x3f   :  { %v193_v38 = vor.u32 %v192_v36, %v191_v35  ;;  %v628_v42 = vadd.s32 3, %v624_v39 }
  0x40   :  { %v194_v40 = vxor.u32 %v193_v38, %v189_v34  ;;  %v632_v46 = vadd.s32 %v628_v42, %v616_v41  ;;  %v634_v47 = vshll.u32 %v628_v42, 17  ;;  %v635_v48 = vshrl.u32 %v628_v42, 15 }
  0x41   :  { %v197_v43 = vadd.s32 %v194_v40, %v189_v34  ;;  %v199_v44 = vshll.u32 %v194_v40, 29  ;;  %v200_v45 = vshrl.u32 %v194_v40, 3  ;;  %v636_v50 = vor.u32 %v635_v48, %v634_v47 }
  0x42   :  { %v201_v49 = vor.u32 %v200_v45, %v199_v44  ;;  %v637_v52 = vxor.u32 %v636_v50, %v632_v46 }
  0x43   :  { %v202_v51 = vxor.u32 %v201_v49, %v197_v43  ;;  %v640_v56 = vadd.s32 %v637_v52, %v632_v46  ;;  %v642_v57 = vshll.u32 %v637_v52, 29  ;;  %v643_v58 = vshrl.u32 %v637_v52, 3 }
  0x44   :  { %v205_v53 = vadd.s32 %v202_v51, %v197_v43  ;;  %v207_v54 = vshll.u32 %v202_v51, 16  ;;  %v208_v55 = vshrl.u32 %v202_v51, 16  ;;  %v644_v60 = vor.u32 %v643_v58, %v642_v57 }
  0x45   :  { %v209_v59 = vor.u32 %v208_v55, %v207_v54  ;;  %v645_v62 = vxor.u32 %v644_v60, %v640_v56 }
  0x46   :  { %v210_v61 = vxor.u32 %v209_v59, %v205_v53  ;;  %v648_v5 = vadd.s32 %v645_v62, %v640_v56  ;;  %v650_v6 = vshll.u32 %v645_v62, 16  ;;  %v651_v7 = vshrl.u32 %v645_v62, 16 }
  0x47   :  { %v213_v63 = vadd.s32 %v210_v61, %v205_v53  ;;  %v219_v3 = vshll.u32 %v210_v61, 24  ;;  %v220_v4 = vshrl.u32 %v210_v61, 8  ;;  %v652_v9 = vor.u32 %v651_v7, %v650_v6 }
  0x48   :  { %v221_v8 = vor.u32 %v220_v4, %v219_v3  ;;  %v653_v11 = vxor.u32 %v652_v9, %v648_v5  ;;  %v217_v16 = vadd.s32 %v213_v63, %v1004_v1 }
  0x49   :  { %v222_v10 = vxor.u32 %v221_v8, %v213_v63  ;;  %v656_v13 = vadd.s32 %v653_v11, %v648_v5  ;;  %v662_v14 = vshll.u32 %v653_v11, 24  ;;  %v663_v15 = vshrl.u32 %v653_v11, 8 }
  0x4a   :  { %v225_v12 = vadd.s32 %v222_v10, %v999_v0  ;;  %v664_v18 = vor.u32 %v663_v15, %v662_v14  ;;  %v660_v1 = vadd.s32 %v656_v13, %v1004_v1 }
  0x4b   :  { %v229_v17 = vadd.s32 4, %v225_v12  ;;  %v665_v22 = vxor.u32 %v664_v18, %v656_v13 }
  0x4c   :  { %v233_v19 = vadd.s32 %v229_v17, %v217_v16  ;;  %v235_v20 = vshll.u32 %v229_v17, 13  ;;  %v236_v21 = vshrl.u32 %v229_v17, 19  ;;  %v668_v24 = vadd.s32 %v665_v22, %v999_v0 }
  0x4d   :  { %v237_v23 = vor.u32 %v236_v21, %v235_v20  ;;  %v672_v26 = vadd.s32 4, %v668_v24 }
  0x4e   :  { %v238_v25 = vxor.u32 %v237_v23, %v233_v19  ;;  %v676_v30 = vadd.s32 %v672_v26, %v660_v1  ;;  %v678_v31 = vshll.u32 %v672_v26, 13  ;;  %v679_v32 = vshrl.u32 %v672_v26, 19 }
  0x4f   :  { %v241_v27 = vadd.s32 %v238_v25, %v233_v19  ;;  %v243_v28 = vshll.u32 %v238_v25, 15  ;;  %v244_v29 = vshrl.u32 %v238_v25, 17  ;;  %v680_v34 = vor.u32 %v679_v32, %v678_v31 }
  0x50   :  { %v245_v33 = vor.u32 %v244_v29, %v243_v28  ;;  %v681_v36 = vxor.u32 %v680_v34, %v676_v30 }
  0x51   :  { %v246_v35 = vxor.u32 %v245_v33, %v241_v27  ;;  %v684_v40 = vadd.s32 %v681_v36, %v676_v30  ;;  %v686_v41 = vshll.u32 %v681_v36, 15  ;;  %v687_v42 = vshrl.u32 %v681_v36, 17 }
  0x52   :  { %v249_v37 = vadd.s32 %v246_v35, %v241_v27  ;;  %v251_v38 = vshll.u32 %v246_v35, 26  ;;  %v252_v39 = vshrl.u32 %v246_v35, 6  ;;  %v688_v44 = vor.u32 %v687_v42, %v686_v41 }
  0x53   :  { %v253_v43 = vor.u32 %v252_v39, %v251_v38  ;;  %v689_v46 = vxor.u32 %v688_v44, %v684_v40 }
  0x54   :  { %v254_v45 = vxor.u32 %v253_v43, %v249_v37  ;;  %v692_v50 = vadd.s32 %v689_v46, %v684_v40  ;;  %v694_v51 = vshll.u32 %v689_v46, 26  ;;  %v695_v52 = vshrl.u32 %v689_v46, 6 }
  0x55   :  { %v257_v47 = vadd.s32 %v254_v45, %v249_v37  ;;  %v263_v48 = vshll.u32 %v254_v45, 6  ;;  %v264_v49 = vshrl.u32 %v254_v45, 26  ;;  %v696_v54 = vor.u32 %v695_v52, %v694_v51 }
  0x56   :  { %v952_v52 = vmov 0.00010095056 /* materialized constant */ }
  0x57   :  { %v265_v53 = vor.u32 %v264_v49, %v263_v48  ;;  %v697_v56 = vxor.u32 %v696_v54, %v692_v50  ;;  %v261_v61 = vadd.s32 %v257_v47, %v999_v0 }
  0x58   :  { %v266_v55 = vxor.u32 %v265_v53, %v257_v47  ;;  %v700_v58 = vadd.s32 %v697_v56, %v692_v50  ;;  %v706_v59 = vshll.u32 %v697_v56, 6  ;;  %v707_v60 = vshrl.u32 %v697_v56, 26 }
  0x59   :  { %v951_v47 = vmov -0.00020021426 /* materialized constant */ }
  0x5a   :  { %v269_v57 = vadd.s32 %v266_v55, %v1009_v2  ;;  %v708_v63 = vor.u32 %v707_v60, %v706_v59  ;;  %v704_v0 = vadd.s32 %v700_v58, %v999_v0  ;;  %v953_v59 = vmov 0.0013493432 /* materialized constant */ }
  0x5b   :  { %v273_v62 = vadd.s32 5, %v269_v57  ;;  %v709_v4 = vxor.u32 %v708_v63, %v700_v58 }
  0x5c   :  { %v275_v3 = vxor.u32 %v273_v62, %v261_v61  ;;  %v712_v2 = vadd.s32 %v709_v4, %v1009_v2 }
  0x5d   :  { %v276_v5 = vshrl.u32 %v275_v3, 9  ;;  %v716_v7 = vadd.s32 5, %v712_v2 }
  0x5e   :  { %v277_v6 = vor.u32 1065353216, %v276_v5  ;;  %v718_v9 = vxor.u32 %v716_v7, %v704_v0 }
  0x5f   :  { %v281_v8 = vadd.f32 -1.0, %v277_v6  ;;  %v719_v11 = vshrl.u32 %v718_v9, 9  ;;  %v954_v6 = vmov -0.0036734284 /* materialized constant */ }
  0x60   :  { %v285_v10 = vmul.f32 2.0, %v281_v8  ;;  %v720_v13 = vor.u32 1065353216, %v719_v11 }
  0x61   :  { %v289_v12 = vadd.f32 -0.99999994, %v285_v10  ;;  %v724_v15 = vadd.f32 -1.0, %v720_v13 }
  0x62   :  { %v1044_v14 = vmax.f32 %v289_v12, -0.99999994  ;;  %v728_v17 = vmul.f32 2.0, %v724_v15  ;;  %v955_v12 = vmov 0.0057395077 /* materialized constant */ }
  0x63   :  { %v305_v16 = vxor.u32 2147483648, %v1044_v14  ;;  %v732_v19 = vadd.f32 -0.99999994, %v728_v17 }
  0x64   :  { %v308_v18 = vmul.f32 %v305_v16, %v1044_v14  ;;  %v1048_v21 = vmax.f32 %v732_v19, -0.99999994 }
  0x65   :  { %v310_v20 = vadd.f32 1.0, %v308_v18  ;;  %v748_v22 = vxor.u32 2147483648, %v1048_v21  ;;  %v313_v25 = vmul.f32 -0.5, %v308_v18  ;;  %v316_v26 = vand.u32 2147483647, %v308_v18 }
  0x66   :  { %921 = vlog2.f32 %v310_v20  ;;  %v751_v23 = vmul.f32 %v748_v22, %v1048_v21  ;;  %v314_v1 = vadd.f32 1.0, %v313_v25  ;;  %vm317_vm2 = vcmp.lt.f32.partialorder %v316_v26, 0.0004427343 }
  0x67   :  { %v956_v20 = vmov -0.0076224613 /* materialized constant */ }
  0x68   :  { %v753_v24 = vadd.f32 1.0, %v751_v23  ;;  %v315_v29 = vmul.f32 %v314_v1, %v308_v18  ;;  %v756_v30 = vmul.f32 -0.5, %v751_v23  ;;  %v759_v35 = vand.u32 2147483647, %v751_v23 }
  0x69   :  { %923 = vlog2.f32 %v753_v24  ;;  %v757_v33 = vadd.f32 1.0, %v756_v30  ;;  %vm760_vm3 = vcmp.lt.f32.partialorder %v759_v35, 0.0004427343  ;;  %v958_v35 = vmov 1.001674 /* materialized constant */ }
  0x6a   :  { %v758_v37 = vmul.f32 %v757_v33, %v751_v23 }
  0x6b   :  { %v922_v27 = vpop.eup %921 }
  0x6c   :  { %v312_v28 = vmul.f32 0.6931472, %v922_v27  ;;  %v957_v27 = vmov 0.0094388705 /* materialized constant */ }
  0x6d   :  { %v318_v31 = vsel /*vm=*/%vm317_vm2, /*on_true_vy=*/%v315_v29, /*on_false_vx=*/%v312_v28 }
  0x6e   :  { %v1052_v32 = vxor.u32 2147483648, %v318_v31  ;;  %v924_v34 = vpop.eup %923 }
  0x6f   :  { %v755_v36 = vmul.f32 0.6931472, %v924_v34 }
  0x70   :  { %925 = vrsqrt.f32 %v1052_v32  ;;  %vm367_vm4 = vcmp.eq.f32.partialorder %v1052_v32, inf  ;;  %v370_v42 = vand.u32 2147483648, %v1052_v32  ;;  %vm369_vm5 = vcmp.eq.f32.partialorder %v1052_v32, 0.0 }
  0x71   :  { %v761_v38 = vsel /*vm=*/%vm760_vm3, /*on_true_vy=*/%v758_v37, /*on_false_vx=*/%v755_v36  ;;  %vm322_vm6 = vcmp.lt.f32.partialorder %v1052_v32, 5.0  ;;  %v363_v45 = vadd.f32 -2.5, %v1052_v32 }
  0x72   :  { %v1055_v39 = vxor.u32 2147483648, %v761_v38  ;;  %v359_v48 = vsel /*vm=*/%vm322_vm6, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v951_v47  ;;  %v355_v53 = vsel /*vm=*/%vm322_vm6, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v952_v52 }
  0x73   :  { %v351_v60 = vsel /*vm=*/%vm322_vm6, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v953_v59  ;;  %v347_v0 = vsel /*vm=*/%vm322_vm6, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v954_v6  ;;  %v343_v13 = vsel /*vm=*/%vm322_vm6, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v955_v12 }
  0x74   :  { %927 = vrsqrt.f32 %v1055_v39  ;;  %vm810_vm7 = vcmp.eq.f32.partialorder %v1055_v39, inf  ;;  %v813_v56 = vand.u32 2147483648, %v1055_v39  ;;  %vm812_vm8 = vcmp.eq.f32.partialorder %v1055_v39, 0.0 }
  0x75   :  { %vm765_vm9 = vcmp.lt.f32.partialorder %v1055_v39, 5.0  ;;  %v806_v63 = vadd.f32 -2.5, %v1055_v39  ;;  %v339_v22 = vsel /*vm=*/%vm322_vm6, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v956_v20  ;;  %v335_v28 = vsel /*vm=*/%vm322_vm6, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v957_v27 }
  0x76   :  { %v802_v5 = vsel /*vm=*/%vm765_vm9, /*on_true_vy=*/2.8102264e-08, /*on_false_vx=*/%v951_v47  ;;  %v798_v9 = vsel /*vm=*/%vm765_vm9, /*on_true_vy=*/3.4327394e-07, /*on_false_vx=*/%v952_v52  ;;  %v794_v17 = vsel /*vm=*/%vm765_vm9, /*on_true_vy=*/-3.5233877e-06, /*on_false_vx=*/%v953_v59 }
  0x77   :  { %v790_v25 = vsel /*vm=*/%vm765_vm9, /*on_true_vy=*/-4.3915065e-06, /*on_false_vx=*/%v954_v6  ;;  %v786_v31 = vsel /*vm=*/%vm765_vm9, /*on_true_vy=*/0.00021858087, /*on_false_vx=*/%v955_v12  ;;  %v331_v36 = vsel /*vm=*/%vm322_vm6, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v958_v35 }
  0x78   :  { %v778_v47 = vsel /*vm=*/%vm765_vm9, /*on_true_vy=*/-0.0041776816, /*on_false_vx=*/%v957_v27  ;;  %v774_v52 = vsel /*vm=*/%vm765_vm9, /*on_true_vy=*/0.24664073, /*on_false_vx=*/%v958_v35 }
  0x79   :  { %v926_v40 = vpop.eup %925 }
  0x7a   :  { %v366_v41 = vmul.f32 %v926_v40, %v1052_v32  ;;  %v782_v40 = vsel /*vm=*/%vm765_vm9, /*on_true_vy=*/-0.001253725, /*on_false_vx=*/%v956_v20 }
  0x7b   :  { %v368_v43 = vsel /*vm=*/%vm367_vm4, /*on_true_vy=*/%v1052_v32, /*on_false_vx=*/%v366_v41 }
  0x7c   :  { %v371_v44 = vsel /*vm=*/%vm369_vm5, /*on_true_vy=*/%v370_v42, /*on_false_vx=*/%v368_v43  ;;  %v928_v51 = vpop.eup %927  ;;  %v295_v43 = vand.u32 2147483647, %v1044_v14 }
  0x7d   :  { %v374_v46 = vadd.f32 -3.0, %v371_v44  ;;  %v809_v55 = vmul.f32 %v928_v51, %v1055_v39  ;;  %v959_v44 = vmov 2.8329768 /* materialized constant */ }
  0x7e   :  { %v327_v32 = vsel /*vm=*/%vm322_vm6, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v959_v44  ;;  %vm298_vm10 = vcmp.eq.f32.partialorder %v295_v43, 1.0 }
  0x7f   :  { %v378_v49 = vsel /*vm=*/%vm322_vm6, /*on_true_vy=*/%v363_v45, /*on_false_vx=*/%v374_v46  ;;  %v811_v58 = vsel /*vm=*/%vm810_vm7, /*on_true_vy=*/%v1055_v39, /*on_false_vx=*/%v809_v55  ;;  %v770_v39 = vsel /*vm=*/%vm765_vm9, /*on_true_vy=*/1.5014094, /*on_false_vx=*/%v959_v44 }
  0x80   :  { %v382_v50 = vmul.f32 %v378_v49, %v359_v48  ;;  %v814_v61 = vsel /*vm=*/%vm812_vm8, /*on_true_vy=*/%v813_v56, /*on_false_vx=*/%v811_v58  ;;  %v738_v56 = vand.u32 2147483647, %v1048_v21  ;;  %v746_v58 = vmul.f32 inf, %v1048_v21 }
  0x81   :  { %v817_v3 = vadd.f32 -3.0, %v814_v61 }
  0x82   :  { %v386_v54 = vadd.f32 %v382_v50, %v355_v53  ;;  %vm741_vm11 = vcmp.eq.f32.partialorder %v738_v56, 1.0 }
  0x83   :  { %v821_v2 = vsel /*vm=*/%vm765_vm9, /*on_true_vy=*/%v806_v63, /*on_false_vx=*/%v817_v3 }
  0x84   :  { %v390_v57 = vmul.f32 %v386_v54, %v378_v49  ;;  %v825_v7 = vmul.f32 %v821_v2, %v802_v5 }
  0x85   :  { %v394_v62 = vadd.f32 %v390_v57, %v351_v60  ;;  %v829_v10 = vadd.f32 %v825_v7, %v798_v9 }
  0x86   :  { %v398_v4 = vmul.f32 %v394_v62, %v378_v49  ;;  %v833_v15 = vmul.f32 %v829_v10, %v821_v2 }
  0x87   :  { %v402_v8 = vadd.f32 %v398_v4, %v347_v0  ;;  %v837_v18 = vadd.f32 %v833_v15, %v794_v17 }
  0x88   :  { %v406_v11 = vmul.f32 %v402_v8, %v378_v49  ;;  %v841_v23 = vmul.f32 %v837_v18, %v821_v2 }
  0x89   :  { %v410_v16 = vadd.f32 %v406_v11, %v343_v13  ;;  %v845_v1 = vadd.f32 %v841_v23, %v790_v25 }
  0x8a   :  { %v414_v19 = vmul.f32 %v410_v16, %v378_v49  ;;  %v849_v29 = vmul.f32 %v845_v1, %v821_v2 }
  0x8b   :  { %v418_v24 = vadd.f32 %v414_v19, %v339_v22  ;;  %v853_v33 = vadd.f32 %v849_v29, %v786_v31 }
  0x8c   :  { %v422_v26 = vmul.f32 %v418_v24, %v378_v49  ;;  %v857_v37 = vmul.f32 %v853_v33, %v821_v2 }
  0x8d   :  { %v426_v30 = vadd.f32 %v422_v26, %v335_v28  ;;  %v861_v41 = vadd.f32 %v857_v37, %v782_v40 }
  0x8e   :  { %v430_v34 = vmul.f32 %v426_v30, %v378_v49  ;;  %v865_v45 = vmul.f32 %v861_v41, %v821_v2 }
  0x8f   :  { %v434_v38 = vadd.f32 %v430_v34, %v331_v36  ;;  %v869_v48 = vadd.f32 %v865_v45, %v778_v47 }
  0x90   :  { %v438_v42 = vmul.f32 %v434_v38, %v378_v49  ;;  %v303_v49 = vmul.f32 inf, %v1044_v14  ;;  %v873_v50 = vmul.f32 %v869_v48, %v821_v2 }
  0x91   :  { %v442_v46 = vadd.f32 %v438_v42, %v327_v32  ;;  %v877_v54 = vadd.f32 %v873_v50, %v774_v52 }
  0x92   :  { %v446_v14 = vmul.f32 %v442_v46, %v1044_v14  ;;  %v881_v55 = vmul.f32 %v877_v54, %v821_v2 }
  0x93   :  { %v450_v51 = vsel /*vm=*/%vm298_vm10, /*on_true_vy=*/%v303_v49, /*on_false_vx=*/%v446_v14  ;;  %v885_v57 = vadd.f32 %v881_v55, %v770_v39 }
  0x94   :  { %v454_v53 = vmul.f32 1.4142135, %v450_v51 }
  0x95   :  { %v889_v21 = vmul.f32 %v885_v57, %v1048_v21 }
  0x96   :  { %456 = vst [vmem:[#allocation0] sm:$0xff] /*vst_source=*/%v454_v53 }
  0x97   :  { %v893_v59 = vsel /*vm=*/%vm741_vm11, /*on_true_vy=*/%v746_v58, /*on_false_vx=*/%v889_v21 }
  0x98   :  { %v897_v60 = vmul.f32 1.4142135, %v893_v59 }
  0x99   :  { %900 = vst [vmem:[#allocation0 + $0x8] sm:$0xff] /*vst_source=*/%v897_v60 }
  0x9a   :  { %940 = shalt.err (!%p937_p4) /* BoundsCheck 5 [deref of %s906] for %908 = dma.vmem_to_hbm [thread:$0]  /*vmem=*/%s906, /*size_in_granules=*/256, /*hbm=*/%s6, /*dst_syncflagno=*/[#allocation2] /* 
base_bounds: (2, 1)
dynamic_base_bounds: (2, 1)
window_bounds: (2, 1)
iteration_bounds: (1, 1)
strides: (2, 1)
pad_low: (0, 0)
pad_high: (0, 0)
element_size_in_bytes: 4096 */
hlo: select_multiply_fusion
 */ }
  0x9b   :  { %908 = dma.vmem_to_hbm [thread:$0]  /*vmem=*/%s906_s28, /*size_in_granules=*/256, /*hbm=*/%s1127_s6, /*dst_syncflagno=*/[#allocation2] /* 
base_bounds: (2, 1)
dynamic_base_bounds: (2, 1)
window_bounds: (2, 1)
iteration_bounds: (1, 1)
strides: (2, 1)
pad_low: (0, 0)
pad_high: (0, 0)
element_size_in_bytes: 4096 */ }
  0x9c   :  { %949 = dma.done.wait [#allocation2], 256 /* pipeline-emitter-dma-wait */ }
  0x9d   :  { %950 = vsyncadd [#allocation2], 4294967040 }
  0x9e   :  { %910 = vsyncpa [#allocation2], 1 } /* exit bundle: %select_multiply_fusion = fusion(%broadcast_add_fusion, %get-tuple-element.5, %get-tuple-element.4, %xor.50, %bitcast.1, %bitcast) */
