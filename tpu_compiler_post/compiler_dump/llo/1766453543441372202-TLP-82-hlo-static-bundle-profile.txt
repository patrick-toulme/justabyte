HLO: <no-hlo-instruction>
 - MXU_0 matpush: (0/95) - 0
 - MXU_0 matpush_bf16_packed: (0/48) - 0
 - MXU_0 matpush_s8_packed: (0/48) - 0
 - MXU_0 matmul: (0/48) - 0
 - MXU_0 matmul_packed: (0/24) - 0
 - MXU_0 matmul_x8_packed: (0/24) - 0
 - MXU_1 matpush: (0/95) - 0
 - MXU_1 matpush_bf16_packed: (0/48) - 0
 - MXU_1 matpush_s8_packed: (0/48) - 0
 - MXU_1 matmul: (0/48) - 0
 - MXU_1 matmul_packed: (0/24) - 0
 - MXU_1 matmul_x8_packed: (0/24) - 0
 - XLU_0 transpose: (0/48) - 0
 - XLU_0 transpose_b16: (0/48) - 0
 - XLU_0 rpu: (0/48) - 0
 - XLU_0 all: (0/48) - 0
 - XLU_1 transpose: (0/48) - 0
 - XLU_1 transpose_b16: (0/48) - 0
 - XLU_1 rpu: (0/48) - 0
 - XLU_1 all: (0/48) - 0
 - VECTOR_ALU: (105/756) - 0.138889
 - VECTOR_EUP: (0/189) - 0
 - VECTOR_LOAD_AND_MISC: (10/567) - 0.0176367
 - VECTOR_STORE_AND_MISC: (13/378) - 0.0343915
 - VECTOR_LOAD_AND_STORE_AND_MISC: (13/756) - 0.0171958
 - VECTOR_MISC: (10/189) - 0.0529101
 - CMEM_LOAD: (0/95) - 0
 - SMEM_SPILL_COUNT: (1/189) - 0.00529101
 - SMEM_FILL_COUNT: (0/189) - 0
 - VMEM_SPILL_COUNT: (0/189) - 0
 - VMEM_FILL_COUNT: (0/189) - 0
 - SCALAR_ALU: (24/378) - 0.0634921
 - VMEM_TO_HBM_ESTIMATED_STARVATION: (0/189) - 0
 - HBM_TO_VMEM_ESTIMATED_STARVATION: (0/189) - 0

HLO: %copy-start = (f32[64,64]{1,0:T(8,128)S(1)}, f32[64,64]{1,0:T(8,128)}, u32[]{:S(2)}) copy-start(%Arg_1.2), cross_program_prefetch_index=0
 - MXU_0 matpush: (0/12) - 0
 - MXU_0 matpush_bf16_packed: (0/6) - 0
 - MXU_0 matpush_s8_packed: (0/6) - 0
 - MXU_0 matmul: (0/6) - 0
 - MXU_0 matmul_packed: (0/3) - 0
 - MXU_0 matmul_x8_packed: (0/3) - 0
 - MXU_1 matpush: (0/12) - 0
 - MXU_1 matpush_bf16_packed: (0/6) - 0
 - MXU_1 matpush_s8_packed: (0/6) - 0
 - MXU_1 matmul: (0/6) - 0
 - MXU_1 matmul_packed: (0/3) - 0
 - MXU_1 matmul_x8_packed: (0/3) - 0
 - XLU_0 transpose: (0/6) - 0
 - XLU_0 transpose_b16: (0/6) - 0
 - XLU_0 rpu: (0/6) - 0
 - XLU_0 all: (0/6) - 0
 - XLU_1 transpose: (0/6) - 0
 - XLU_1 transpose_b16: (0/6) - 0
 - XLU_1 rpu: (0/6) - 0
 - XLU_1 all: (0/6) - 0
 - VECTOR_ALU: (0/96) - 0
 - VECTOR_EUP: (0/24) - 0
 - VECTOR_LOAD_AND_MISC: (4/72) - 0.0555556
 - VECTOR_STORE_AND_MISC: (4/48) - 0.0833333
 - VECTOR_LOAD_AND_STORE_AND_MISC: (4/96) - 0.0416667
 - VECTOR_MISC: (4/24) - 0.166667
 - CMEM_LOAD: (0/12) - 0
 - SMEM_SPILL_COUNT: (0/24) - 0
 - SMEM_FILL_COUNT: (0/24) - 0
 - VMEM_SPILL_COUNT: (0/24) - 0
 - VMEM_FILL_COUNT: (0/24) - 0
 - SCALAR_ALU: (15/48) - 0.3125
 - VMEM_TO_HBM_ESTIMATED_STARVATION: (0/24) - 0
 - HBM_TO_VMEM_ESTIMATED_STARVATION: (0/24) - 0

HLO: %copy-done = f32[64,64]{1,0:T(8,128)S(1)} copy-done(%copy-start)
 - MXU_0 matpush: (0/3) - 0
 - MXU_0 matpush_bf16_packed: (0/2) - 0
 - MXU_0 matpush_s8_packed: (0/2) - 0
 - MXU_0 matmul: (0/2) - 0
 - MXU_0 matmul_packed: (0/1) - 0
 - MXU_0 matmul_x8_packed: (0/1) - 0
 - MXU_1 matpush: (0/3) - 0
 - MXU_1 matpush_bf16_packed: (0/2) - 0
 - MXU_1 matpush_s8_packed: (0/2) - 0
 - MXU_1 matmul: (0/2) - 0
 - MXU_1 matmul_packed: (0/1) - 0
 - MXU_1 matmul_x8_packed: (0/1) - 0
 - XLU_0 transpose: (0/2) - 0
 - XLU_0 transpose_b16: (0/2) - 0
 - XLU_0 rpu: (0/2) - 0
 - XLU_0 all: (0/2) - 0
 - XLU_1 transpose: (0/2) - 0
 - XLU_1 transpose_b16: (0/2) - 0
 - XLU_1 rpu: (0/2) - 0
 - XLU_1 all: (0/2) - 0
 - VECTOR_ALU: (0/20) - 0
 - VECTOR_EUP: (0/5) - 0
 - VECTOR_LOAD_AND_MISC: (5/15) - 0.333333
 - VECTOR_STORE_AND_MISC: (5/10) - 0.5
 - VECTOR_LOAD_AND_STORE_AND_MISC: (5/20) - 0.25
 - VECTOR_MISC: (5/5) - 1
 - CMEM_LOAD: (0/3) - 0
 - SMEM_SPILL_COUNT: (0/5) - 0
 - SMEM_FILL_COUNT: (0/5) - 0
 - VMEM_SPILL_COUNT: (0/5) - 0
 - VMEM_FILL_COUNT: (0/5) - 0
 - SCALAR_ALU: (0/10) - 0
 - VMEM_TO_HBM_ESTIMATED_STARVATION: (0/5) - 0
 - HBM_TO_VMEM_ESTIMATED_STARVATION: (0/5) - 0

HLO: %copy-start.1 = (f32[64,32]{0,1:T(8,128)S(1)}, f32[64,32]{0,1:T(8,128)}, u32[]{:S(2)}) copy-start(%Arg_2.3)
 - MXU_0 matpush: (0/7) - 0
 - MXU_0 matpush_bf16_packed: (0/4) - 0
 - MXU_0 matpush_s8_packed: (0/4) - 0
 - MXU_0 matmul: (0/4) - 0
 - MXU_0 matmul_packed: (0/2) - 0
 - MXU_0 matmul_x8_packed: (0/2) - 0
 - MXU_1 matpush: (0/7) - 0
 - MXU_1 matpush_bf16_packed: (0/4) - 0
 - MXU_1 matpush_s8_packed: (0/4) - 0
 - MXU_1 matmul: (0/4) - 0
 - MXU_1 matmul_packed: (0/2) - 0
 - MXU_1 matmul_x8_packed: (0/2) - 0
 - XLU_0 transpose: (0/4) - 0
 - XLU_0 transpose_b16: (0/4) - 0
 - XLU_0 rpu: (0/4) - 0
 - XLU_0 all: (0/4) - 0
 - XLU_1 transpose: (0/4) - 0
 - XLU_1 transpose_b16: (0/4) - 0
 - XLU_1 rpu: (0/4) - 0
 - XLU_1 all: (0/4) - 0
 - VECTOR_ALU: (0/56) - 0
 - VECTOR_EUP: (0/14) - 0
 - VECTOR_LOAD_AND_MISC: (3/42) - 0.0714286
 - VECTOR_STORE_AND_MISC: (3/28) - 0.107143
 - VECTOR_LOAD_AND_STORE_AND_MISC: (3/56) - 0.0535714
 - VECTOR_MISC: (3/14) - 0.214286
 - CMEM_LOAD: (0/7) - 0
 - SMEM_SPILL_COUNT: (0/14) - 0
 - SMEM_FILL_COUNT: (0/14) - 0
 - VMEM_SPILL_COUNT: (0/14) - 0
 - VMEM_FILL_COUNT: (0/14) - 0
 - SCALAR_ALU: (11/28) - 0.392857
 - VMEM_TO_HBM_ESTIMATED_STARVATION: (0/14) - 0
 - HBM_TO_VMEM_ESTIMATED_STARVATION: (0/14) - 0

HLO: %copy-done.1 = f32[64,32]{0,1:T(8,128)S(1)} copy-done(%copy-start.1)
 - MXU_0 matpush: (0/3) - 0
 - MXU_0 matpush_bf16_packed: (0/2) - 0
 - MXU_0 matpush_s8_packed: (0/2) - 0
 - MXU_0 matmul: (0/2) - 0
 - MXU_0 matmul_packed: (0/1) - 0
 - MXU_0 matmul_x8_packed: (0/1) - 0
 - MXU_1 matpush: (0/3) - 0
 - MXU_1 matpush_bf16_packed: (0/2) - 0
 - MXU_1 matpush_s8_packed: (0/2) - 0
 - MXU_1 matmul: (0/2) - 0
 - MXU_1 matmul_packed: (0/1) - 0
 - MXU_1 matmul_x8_packed: (0/1) - 0
 - XLU_0 transpose: (0/2) - 0
 - XLU_0 transpose_b16: (0/2) - 0
 - XLU_0 rpu: (0/2) - 0
 - XLU_0 all: (0/2) - 0
 - XLU_1 transpose: (0/2) - 0
 - XLU_1 transpose_b16: (0/2) - 0
 - XLU_1 rpu: (0/2) - 0
 - XLU_1 all: (0/2) - 0
 - VECTOR_ALU: (0/20) - 0
 - VECTOR_EUP: (0/5) - 0
 - VECTOR_LOAD_AND_MISC: (5/15) - 0.333333
 - VECTOR_STORE_AND_MISC: (5/10) - 0.5
 - VECTOR_LOAD_AND_STORE_AND_MISC: (5/20) - 0.25
 - VECTOR_MISC: (5/5) - 1
 - CMEM_LOAD: (0/3) - 0
 - SMEM_SPILL_COUNT: (0/5) - 0
 - SMEM_FILL_COUNT: (0/5) - 0
 - VMEM_SPILL_COUNT: (0/5) - 0
 - VMEM_FILL_COUNT: (0/5) - 0
 - SCALAR_ALU: (0/10) - 0
 - VMEM_TO_HBM_ESTIMATED_STARVATION: (0/5) - 0
 - HBM_TO_VMEM_ESTIMATED_STARVATION: (0/5) - 0

HLO: <no-hlo-instruction>
 - MXU_0 matpush: (0/4) - 0
 - MXU_0 matpush_bf16_packed: (0/2) - 0
 - MXU_0 matpush_s8_packed: (0/2) - 0
 - MXU_0 matmul: (0/2) - 0
 - MXU_0 matmul_packed: (0/1) - 0
 - MXU_0 matmul_x8_packed: (0/1) - 0
 - MXU_1 matpush: (0/4) - 0
 - MXU_1 matpush_bf16_packed: (0/2) - 0
 - MXU_1 matpush_s8_packed: (0/2) - 0
 - MXU_1 matmul: (0/2) - 0
 - MXU_1 matmul_packed: (0/1) - 0
 - MXU_1 matmul_x8_packed: (0/1) - 0
 - XLU_0 transpose: (0/2) - 0
 - XLU_0 transpose_b16: (0/2) - 0
 - XLU_0 rpu: (0/2) - 0
 - XLU_0 all: (0/2) - 0
 - XLU_1 transpose: (0/2) - 0
 - XLU_1 transpose_b16: (0/2) - 0
 - XLU_1 rpu: (0/2) - 0
 - XLU_1 all: (0/2) - 0
 - VECTOR_ALU: (1/28) - 0.0357143
 - VECTOR_EUP: (0/7) - 0
 - VECTOR_LOAD_AND_MISC: (3/21) - 0.142857
 - VECTOR_STORE_AND_MISC: (3/14) - 0.214286
 - VECTOR_LOAD_AND_STORE_AND_MISC: (3/28) - 0.107143
 - VECTOR_MISC: (3/7) - 0.428571
 - CMEM_LOAD: (0/4) - 0
 - SMEM_SPILL_COUNT: (0/7) - 0
 - SMEM_FILL_COUNT: (0/7) - 0
 - VMEM_SPILL_COUNT: (0/7) - 0
 - VMEM_FILL_COUNT: (0/7) - 0
 - SCALAR_ALU: (5/14) - 0.357143
 - VMEM_TO_HBM_ESTIMATED_STARVATION: (0/7) - 0
 - HBM_TO_VMEM_ESTIMATED_STARVATION: (0/7) - 0

HLO: %fusion = f32[16,32]{1,0:T(8,128)} fusion(%copy-done.1, %fusion.2, %fusion.5, %get-tuple-element.1, %add_sqrt_fusion), kind=kOutput, calls=%fused_computation, metadata={op_name="jit(mini_attention)/jit(main)/matmul_2/dot_general" source_file="/home/ptoulme/tpu.py" source_line=56}, backend_config={"flag_configs":[],"window_config":{"kernel_window_bounds":["4","1"],"output_window_bounds":["2","1"],"input_window_bounds":["2","1"],"estimated_cycles":"3140","iteration_bounds":["1","1","1"]},"scoped_memory_configs":[],"used_scoped_memory_configs":[{"memory_space":"1","offset":"0","size":"8192"}],"retry_config":{"retry_count":"0"},"convolution_algorithm_config":{"emitter":"EmitOutputBatchInSublanes"}}
 - MXU_0 matpush: (4/179) - 0.0223464
 - MXU_0 matpush_bf16_packed: (0/90) - 0
 - MXU_0 matpush_s8_packed: (0/90) - 0
 - MXU_0 matmul: (1/90) - 0.0111111
 - MXU_0 matmul_packed: (0/45) - 0
 - MXU_0 matmul_x8_packed: (0/45) - 0
 - MXU_1 matpush: (0/179) - 0
 - MXU_1 matpush_bf16_packed: (0/90) - 0
 - MXU_1 matpush_s8_packed: (0/90) - 0
 - MXU_1 matmul: (0/90) - 0
 - MXU_1 matmul_packed: (0/45) - 0
 - MXU_1 matmul_x8_packed: (0/45) - 0
 - XLU_0 transpose: (0/90) - 0
 - XLU_0 transpose_b16: (0/90) - 0
 - XLU_0 rpu: (3/90) - 0.0333333
 - XLU_0 all: (3/90) - 0.0333333
 - XLU_1 transpose: (0/90) - 0
 - XLU_1 transpose_b16: (0/90) - 0
 - XLU_1 rpu: (3/90) - 0.0333333
 - XLU_1 all: (3/90) - 0.0333333
 - VECTOR_ALU: (17/1428) - 0.0119048
 - VECTOR_EUP: (6/357) - 0.0168067
 - VECTOR_LOAD_AND_MISC: (13/1071) - 0.0121382
 - VECTOR_STORE_AND_MISC: (6/714) - 0.00840336
 - VECTOR_LOAD_AND_STORE_AND_MISC: (15/1428) - 0.0105042
 - VECTOR_MISC: (4/357) - 0.0112045
 - CMEM_LOAD: (0/179) - 0
 - SMEM_SPILL_COUNT: (0/357) - 0
 - SMEM_FILL_COUNT: (0/357) - 0
 - VMEM_SPILL_COUNT: (0/357) - 0
 - VMEM_FILL_COUNT: (0/357) - 0
 - SCALAR_ALU: (10/714) - 0.0140056
 - VMEM_TO_HBM_ESTIMATED_STARVATION: (0/357) - 0
 - HBM_TO_VMEM_ESTIMATED_STARVATION: (0/357) - 0

HLO: %multiply_reduce_fusion = (f32[16]{0:T(128)S(1)}, f32[16,64]{1,0:T(8,128)S(1)}) fusion(%Arg_0.1, %copy-done), kind=kOutput, calls=%fused_computation.3, metadata={op_name="jit(mini_attention)/jit(main)/matmul_1/dot_general" source_file="/home/ptoulme/tpu.py" source_line=35}, backend_config={"flag_configs":[],"window_config":{"kernel_window_bounds":["8","1"],"output_window_bounds":["2","1"],"input_window_bounds":["2","1"],"estimated_cycles":"2248","iteration_bounds":["1","1","1"]},"scoped_memory_configs":[],"used_scoped_memory_configs":[{"memory_space":"1","offset":"0","size":"12288"}],"retry_config":{"retry_count":"0"},"convolution_algorithm_config":{"emitter":"EmitAllBatchInSublanes"}}
 - MXU_0 matpush: (0/219) - 0
 - MXU_0 matpush_bf16_packed: (4/110) - 0.0363636
 - MXU_0 matpush_s8_packed: (0/110) - 0
 - MXU_0 matmul: (1/110) - 0.00909091
 - MXU_0 matmul_packed: (0/55) - 0
 - MXU_0 matmul_x8_packed: (0/55) - 0
 - MXU_1 matpush: (0/219) - 0
 - MXU_1 matpush_bf16_packed: (0/110) - 0
 - MXU_1 matpush_s8_packed: (0/110) - 0
 - MXU_1 matmul: (0/110) - 0
 - MXU_1 matmul_packed: (0/55) - 0
 - MXU_1 matmul_x8_packed: (0/55) - 0
 - XLU_0 transpose: (2/110) - 0.0181818
 - XLU_0 transpose_b16: (0/110) - 0
 - XLU_0 rpu: (0/110) - 0
 - XLU_0 all: (2/110) - 0.0181818
 - XLU_1 transpose: (0/110) - 0
 - XLU_1 transpose_b16: (0/110) - 0
 - XLU_1 rpu: (0/110) - 0
 - XLU_1 all: (0/110) - 0
 - VECTOR_ALU: (35/1748) - 0.0200229
 - VECTOR_EUP: (0/437) - 0
 - VECTOR_LOAD_AND_MISC: (16/1311) - 0.0122044
 - VECTOR_STORE_AND_MISC: (10/874) - 0.0114416
 - VECTOR_LOAD_AND_STORE_AND_MISC: (21/1748) - 0.0120137
 - VECTOR_MISC: (5/437) - 0.0114416
 - CMEM_LOAD: (0/219) - 0
 - SMEM_SPILL_COUNT: (0/437) - 0
 - SMEM_FILL_COUNT: (0/437) - 0
 - VMEM_SPILL_COUNT: (0/437) - 0
 - VMEM_FILL_COUNT: (0/437) - 0
 - SCALAR_ALU: (10/874) - 0.0114416
 - VMEM_TO_HBM_ESTIMATED_STARVATION: (0/437) - 0
 - HBM_TO_VMEM_ESTIMATED_STARVATION: (0/437) - 0

HLO: %fusion.2 = f32[16]{0:T(128)S(1)} fusion(%fusion.5, %get-tuple-element.1, %add_sqrt_fusion), kind=kLoop, calls=%fused_computation.4, metadata={op_name="jit(mini_attention)/jit(main)/softmax/reduce_sum" source_file="/home/ptoulme/tpu.py" source_line=50}, backend_config={"flag_configs":[],"window_config":{"kernel_window_bounds":[],"output_window_bounds":["2","1"],"input_window_bounds":[],"estimated_cycles":"2162","iteration_bounds":["1","1"]},"scoped_memory_configs":[],"used_scoped_memory_configs":[{"memory_space":"1","offset":"0","size":"4096"}],"retry_config":{"retry_count":"0"}}
 - MXU_0 matpush: (0/180) - 0
 - MXU_0 matpush_bf16_packed: (0/90) - 0
 - MXU_0 matpush_s8_packed: (0/90) - 0
 - MXU_0 matmul: (0/90) - 0
 - MXU_0 matmul_packed: (0/45) - 0
 - MXU_0 matmul_x8_packed: (0/45) - 0
 - MXU_1 matpush: (0/180) - 0
 - MXU_1 matpush_bf16_packed: (0/90) - 0
 - MXU_1 matpush_s8_packed: (0/90) - 0
 - MXU_1 matmul: (0/90) - 0
 - MXU_1 matmul_packed: (0/45) - 0
 - MXU_1 matmul_x8_packed: (0/45) - 0
 - XLU_0 transpose: (2/90) - 0.0222222
 - XLU_0 transpose_b16: (0/90) - 0
 - XLU_0 rpu: (2/90) - 0.0222222
 - XLU_0 all: (4/90) - 0.0444444
 - XLU_1 transpose: (0/90) - 0
 - XLU_1 transpose_b16: (0/90) - 0
 - XLU_1 rpu: (2/90) - 0.0222222
 - XLU_1 all: (2/90) - 0.0222222
 - VECTOR_ALU: (35/1436) - 0.0243733
 - VECTOR_EUP: (4/359) - 0.0111421
 - VECTOR_LOAD_AND_MISC: (5/1077) - 0.00464253
 - VECTOR_STORE_AND_MISC: (3/718) - 0.00417827
 - VECTOR_LOAD_AND_STORE_AND_MISC: (8/1436) - 0.00557103
 - CMEM_LOAD: (0/180) - 0
 - SMEM_SPILL_COUNT: (0/359) - 0
 - SMEM_FILL_COUNT: (0/359) - 0
 - VMEM_SPILL_COUNT: (0/359) - 0
 - VMEM_FILL_COUNT: (0/359) - 0
 - SCALAR_ALU: (0/718) - 0
 - VMEM_TO_HBM_ESTIMATED_STARVATION: (0/359) - 0
 - HBM_TO_VMEM_ESTIMATED_STARVATION: (0/359) - 0

HLO: %fusion.5 = f32[16]{0:T(128)S(1)} fusion(%get-tuple-element.1, %add_sqrt_fusion), kind=kLoop, calls=%fused_computation.8, metadata={op_name="jit(mini_attention)/jit(main)/softmax/reduce_max" source_file="/home/ptoulme/tpu.py" source_line=48}, backend_config={"flag_configs":[],"window_config":{"kernel_window_bounds":[],"output_window_bounds":["2","1"],"input_window_bounds":[],"estimated_cycles":"2143","iteration_bounds":["1","1"]},"scoped_memory_configs":[],"used_scoped_memory_configs":[{"memory_space":"1","offset":"0","size":"4096"}],"retry_config":{"retry_count":"0"}}
 - MXU_0 matpush: (0/171) - 0
 - MXU_0 matpush_bf16_packed: (0/86) - 0
 - MXU_0 matpush_s8_packed: (0/86) - 0
 - MXU_0 matmul: (0/86) - 0
 - MXU_0 matmul_packed: (0/43) - 0
 - MXU_0 matmul_x8_packed: (0/43) - 0
 - MXU_1 matpush: (0/171) - 0
 - MXU_1 matpush_bf16_packed: (0/86) - 0
 - MXU_1 matpush_s8_packed: (0/86) - 0
 - MXU_1 matmul: (0/86) - 0
 - MXU_1 matmul_packed: (0/43) - 0
 - MXU_1 matmul_x8_packed: (0/43) - 0
 - XLU_0 transpose: (0/86) - 0
 - XLU_0 transpose_b16: (0/86) - 0
 - XLU_0 rpu: (2/86) - 0.0232558
 - XLU_0 all: (2/86) - 0.0232558
 - XLU_1 transpose: (2/86) - 0.0232558
 - XLU_1 transpose_b16: (0/86) - 0
 - XLU_1 rpu: (0/86) - 0
 - XLU_1 all: (2/86) - 0.0232558
 - VECTOR_ALU: (29/1364) - 0.021261
 - VECTOR_EUP: (2/341) - 0.0058651
 - VECTOR_LOAD_AND_MISC: (4/1023) - 0.00391007
 - VECTOR_STORE_AND_MISC: (3/682) - 0.00439883
 - VECTOR_LOAD_AND_STORE_AND_MISC: (7/1364) - 0.00513196
 - CMEM_LOAD: (0/171) - 0
 - SMEM_SPILL_COUNT: (0/341) - 0
 - SMEM_FILL_COUNT: (0/341) - 0
 - VMEM_SPILL_COUNT: (0/341) - 0
 - VMEM_FILL_COUNT: (0/341) - 0
 - SCALAR_ALU: (0/682) - 0
 - VMEM_TO_HBM_ESTIMATED_STARVATION: (0/341) - 0
 - HBM_TO_VMEM_ESTIMATED_STARVATION: (0/341) - 0

HLO: %add_sqrt_fusion = f32[16]{0:T(128)S(1)} fusion(%get-tuple-element), kind=kLoop, calls=%fused_computation.9, metadata={op_name="jit(mini_attention)/jit(main)/rms_norm/sqrt" source_file="/home/ptoulme/tpu.py" source_line=41}, backend_config={"flag_configs":[],"window_config":{"kernel_window_bounds":[],"output_window_bounds":["1"],"input_window_bounds":[],"estimated_cycles":"2120","iteration_bounds":["1"]},"scoped_memory_configs":[],"used_scoped_memory_configs":[{"memory_space":"1","offset":"0","size":"0"}],"retry_config":{"retry_count":"0"}}
 - MXU_0 matpush: (0/12) - 0
 - MXU_0 matpush_bf16_packed: (0/6) - 0
 - MXU_0 matpush_s8_packed: (0/6) - 0
 - MXU_0 matmul: (0/6) - 0
 - MXU_0 matmul_packed: (0/3) - 0
 - MXU_0 matmul_x8_packed: (0/3) - 0
 - MXU_1 matpush: (0/12) - 0
 - MXU_1 matpush_bf16_packed: (0/6) - 0
 - MXU_1 matpush_s8_packed: (0/6) - 0
 - MXU_1 matmul: (0/6) - 0
 - MXU_1 matmul_packed: (0/3) - 0
 - MXU_1 matmul_x8_packed: (0/3) - 0
 - XLU_0 transpose: (0/6) - 0
 - XLU_0 transpose_b16: (0/6) - 0
 - XLU_0 rpu: (0/6) - 0
 - XLU_0 all: (0/6) - 0
 - XLU_1 transpose: (0/6) - 0
 - XLU_1 transpose_b16: (0/6) - 0
 - XLU_1 rpu: (0/6) - 0
 - XLU_1 all: (0/6) - 0
 - VECTOR_ALU: (9/96) - 0.09375
 - VECTOR_EUP: (1/24) - 0.0416667
 - VECTOR_LOAD_AND_MISC: (1/72) - 0.0138889
 - VECTOR_STORE_AND_MISC: (1/48) - 0.0208333
 - VECTOR_LOAD_AND_STORE_AND_MISC: (2/96) - 0.0208333
 - CMEM_LOAD: (0/12) - 0
 - SMEM_SPILL_COUNT: (0/24) - 0
 - SMEM_FILL_COUNT: (0/24) - 0
 - VMEM_SPILL_COUNT: (0/24) - 0
 - VMEM_FILL_COUNT: (0/24) - 0
 - SCALAR_ALU: (0/48) - 0
 - VMEM_TO_HBM_ESTIMATED_STARVATION: (0/24) - 0
 - HBM_TO_VMEM_ESTIMATED_STARVATION: (0/24) - 0

